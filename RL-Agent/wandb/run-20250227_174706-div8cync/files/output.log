Checkpoint loaded!
Learner successfully initialized!
Press (p) to pause (c) to checkpoint, (q) to checkpoint and quit (after next iteration)

--------BEGIN ITERATION REPORT--------
Policy Reward: 31.93543
Policy Entropy: 4.05478
Value Function Loss: 0.07700

Mean KL Divergence: 0.00083
SB3 Clip Fraction: 0.00800
Policy Update Magnitude: 0.28465
Value Function Update Magnitude: 0.31014

Collected Steps per Second: 7,897.00055
Overall Steps per Second: 4,416.81074

Timestep Collection Time: 6.33253
Timestep Consumption Time: 4.98967
PPO Batch Consumption Time: 1.94669
Total Iteration Time: 11.32220

Cumulative Model Updates: 92,142
Cumulative Timesteps: 768,356,050

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37.39111
Policy Entropy: 3.89796
Value Function Loss: 0.07066

Mean KL Divergence: 0.00556
SB3 Clip Fraction: 0.06227
Policy Update Magnitude: 0.80127
Value Function Update Magnitude: 0.64562

Collected Steps per Second: 22,180.36794
Overall Steps per Second: 11,970.39478

Timestep Collection Time: 2.25587
Timestep Consumption Time: 1.92411
PPO Batch Consumption Time: 0.29067
Total Iteration Time: 4.17998

Cumulative Model Updates: 92,146
Cumulative Timesteps: 768,406,086

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 768406086...
Checkpoint 768406086 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25.59036
Policy Entropy: 3.81579
Value Function Loss: 0.05749

Mean KL Divergence: 0.01496
SB3 Clip Fraction: 0.17593
Policy Update Magnitude: 1.10676
Value Function Update Magnitude: 0.95367

Collected Steps per Second: 22,448.37318
Overall Steps per Second: 10,611.20233

Timestep Collection Time: 2.22858
Timestep Consumption Time: 2.48606
PPO Batch Consumption Time: 0.28797
Total Iteration Time: 4.71464

Cumulative Model Updates: 92,152
Cumulative Timesteps: 768,456,114

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,526.44013
Policy Entropy: 3.67440
Value Function Loss: 0.05137

Mean KL Divergence: 0.01168
SB3 Clip Fraction: 0.14855
Policy Update Magnitude: 0.89563
Value Function Update Magnitude: 0.80599

Collected Steps per Second: 22,056.28477
Overall Steps per Second: 10,797.71691

Timestep Collection Time: 2.26720
Timestep Consumption Time: 2.36396
PPO Batch Consumption Time: 0.27668
Total Iteration Time: 4.63116

Cumulative Model Updates: 92,158
Cumulative Timesteps: 768,506,120

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 768506120...
Checkpoint 768506120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,824.57417
Policy Entropy: 3.65899
Value Function Loss: 0.03918

Mean KL Divergence: 0.01238
SB3 Clip Fraction: 0.15682
Policy Update Magnitude: 0.79527
Value Function Update Magnitude: 0.73036

Collected Steps per Second: 22,063.71051
Overall Steps per Second: 10,813.40702

Timestep Collection Time: 2.26653
Timestep Consumption Time: 2.35810
PPO Batch Consumption Time: 0.27760
Total Iteration Time: 4.62463

Cumulative Model Updates: 92,164
Cumulative Timesteps: 768,556,128

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,348.61825
Policy Entropy: 3.65317
Value Function Loss: 0.04362

Mean KL Divergence: 0.02039
SB3 Clip Fraction: 0.22534
Policy Update Magnitude: 0.71752
Value Function Update Magnitude: 0.72944

Collected Steps per Second: 21,959.47467
Overall Steps per Second: 10,542.22234

Timestep Collection Time: 2.27692
Timestep Consumption Time: 2.46591
PPO Batch Consumption Time: 0.29593
Total Iteration Time: 4.74283

Cumulative Model Updates: 92,170
Cumulative Timesteps: 768,606,128

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 768606128...
Checkpoint 768606128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,507.82791
Policy Entropy: 3.64594
Value Function Loss: 0.04939

Mean KL Divergence: 0.01658
SB3 Clip Fraction: 0.20018
Policy Update Magnitude: 0.59259
Value Function Update Magnitude: 0.79365

Collected Steps per Second: 21,781.09688
Overall Steps per Second: 10,587.37296

Timestep Collection Time: 2.29676
Timestep Consumption Time: 2.42830
PPO Batch Consumption Time: 0.28275
Total Iteration Time: 4.72506

Cumulative Model Updates: 92,176
Cumulative Timesteps: 768,656,154

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,507.82791
Policy Entropy: 3.61392
Value Function Loss: 0.05728

Mean KL Divergence: 0.01497
SB3 Clip Fraction: 0.18600
Policy Update Magnitude: 0.63323
Value Function Update Magnitude: 0.76994

Collected Steps per Second: 22,440.89094
Overall Steps per Second: 10,645.45574

Timestep Collection Time: 2.22834
Timestep Consumption Time: 2.46906
PPO Batch Consumption Time: 0.28822
Total Iteration Time: 4.69740

Cumulative Model Updates: 92,182
Cumulative Timesteps: 768,706,160

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 768706160...
Checkpoint 768706160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,439.70646
Policy Entropy: 3.62982
Value Function Loss: 0.05699

Mean KL Divergence: 0.01430
SB3 Clip Fraction: 0.17709
Policy Update Magnitude: 0.65504
Value Function Update Magnitude: 0.65016

Collected Steps per Second: 22,587.02847
Overall Steps per Second: 10,881.74293

Timestep Collection Time: 2.21455
Timestep Consumption Time: 2.38214
PPO Batch Consumption Time: 0.27556
Total Iteration Time: 4.59669

Cumulative Model Updates: 92,188
Cumulative Timesteps: 768,756,180

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,401.92942
Policy Entropy: 3.65046
Value Function Loss: 0.05420

Mean KL Divergence: 0.01946
SB3 Clip Fraction: 0.22319
Policy Update Magnitude: 0.67228
Value Function Update Magnitude: 0.54459

Collected Steps per Second: 22,023.76126
Overall Steps per Second: 10,544.21607

Timestep Collection Time: 2.27073
Timestep Consumption Time: 2.47216
PPO Batch Consumption Time: 0.28778
Total Iteration Time: 4.74288

Cumulative Model Updates: 92,194
Cumulative Timesteps: 768,806,190

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 768806190...
Checkpoint 768806190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,460.97846
Policy Entropy: 3.64478
Value Function Loss: 0.05054

Mean KL Divergence: 0.01370
SB3 Clip Fraction: 0.17171
Policy Update Magnitude: 0.65756
Value Function Update Magnitude: 0.63318

Collected Steps per Second: 22,347.33997
Overall Steps per Second: 10,645.06095

Timestep Collection Time: 2.23866
Timestep Consumption Time: 2.46099
PPO Batch Consumption Time: 0.28331
Total Iteration Time: 4.69964

Cumulative Model Updates: 92,200
Cumulative Timesteps: 768,856,218

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,460.97846
Policy Entropy: 3.63651
Value Function Loss: 0.04486

Mean KL Divergence: 0.01159
SB3 Clip Fraction: 0.14652
Policy Update Magnitude: 0.72899
Value Function Update Magnitude: 0.83832

Collected Steps per Second: 22,181.27194
Overall Steps per Second: 10,510.13138

Timestep Collection Time: 2.25488
Timestep Consumption Time: 2.50396
PPO Batch Consumption Time: 0.29124
Total Iteration Time: 4.75884

Cumulative Model Updates: 92,206
Cumulative Timesteps: 768,906,234

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 768906234...
Checkpoint 768906234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,733.55261
Policy Entropy: 3.62993
Value Function Loss: 0.04152

Mean KL Divergence: 0.01715
SB3 Clip Fraction: 0.19159
Policy Update Magnitude: 0.69510
Value Function Update Magnitude: 0.77701

Collected Steps per Second: 22,371.32363
Overall Steps per Second: 10,699.27208

Timestep Collection Time: 2.23590
Timestep Consumption Time: 2.43919
PPO Batch Consumption Time: 0.27655
Total Iteration Time: 4.67508

Cumulative Model Updates: 92,212
Cumulative Timesteps: 768,956,254

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,161.70998
Policy Entropy: 3.64903
Value Function Loss: 0.04204

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.12521
Policy Update Magnitude: 0.67344
Value Function Update Magnitude: 0.55635

Collected Steps per Second: 22,190.57563
Overall Steps per Second: 10,450.33924

Timestep Collection Time: 2.25357
Timestep Consumption Time: 2.53173
PPO Batch Consumption Time: 0.29101
Total Iteration Time: 4.78530

Cumulative Model Updates: 92,218
Cumulative Timesteps: 769,006,262

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 769006262...
Checkpoint 769006262 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,599.54703
Policy Entropy: 3.63516
Value Function Loss: 0.03885

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.11078
Policy Update Magnitude: 0.68673
Value Function Update Magnitude: 0.47765

Collected Steps per Second: 22,628.18990
Overall Steps per Second: 10,511.56169

Timestep Collection Time: 2.20972
Timestep Consumption Time: 2.54714
PPO Batch Consumption Time: 0.29346
Total Iteration Time: 4.75686

Cumulative Model Updates: 92,224
Cumulative Timesteps: 769,056,264

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54,340.02190
Policy Entropy: 3.63283
Value Function Loss: 0.04368

Mean KL Divergence: 0.01424
SB3 Clip Fraction: 0.18813
Policy Update Magnitude: 0.54345
Value Function Update Magnitude: 0.57553

Collected Steps per Second: 21,578.06755
Overall Steps per Second: 10,329.07314

Timestep Collection Time: 2.31819
Timestep Consumption Time: 2.52465
PPO Batch Consumption Time: 0.28807
Total Iteration Time: 4.84284

Cumulative Model Updates: 92,230
Cumulative Timesteps: 769,106,286

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 769106286...
Checkpoint 769106286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,303.22827
Policy Entropy: 3.64982
Value Function Loss: 0.05555

Mean KL Divergence: 0.01259
SB3 Clip Fraction: 0.15378
Policy Update Magnitude: 0.57591
Value Function Update Magnitude: 0.52931

Collected Steps per Second: 22,595.82893
Overall Steps per Second: 10,760.12479

Timestep Collection Time: 2.21297
Timestep Consumption Time: 2.43418
PPO Batch Consumption Time: 0.27926
Total Iteration Time: 4.64716

Cumulative Model Updates: 92,236
Cumulative Timesteps: 769,156,290

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54,764.34111
Policy Entropy: 3.65097
Value Function Loss: 0.07195

Mean KL Divergence: 0.01403
SB3 Clip Fraction: 0.16902
Policy Update Magnitude: 0.71985
Value Function Update Magnitude: 0.49629

Collected Steps per Second: 22,579.45262
Overall Steps per Second: 10,536.96564

Timestep Collection Time: 2.21538
Timestep Consumption Time: 2.53191
PPO Batch Consumption Time: 0.29248
Total Iteration Time: 4.74729

Cumulative Model Updates: 92,242
Cumulative Timesteps: 769,206,312

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 769206312...
Checkpoint 769206312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,496.00538
Policy Entropy: 3.65352
Value Function Loss: 0.07268

Mean KL Divergence: 0.02271
SB3 Clip Fraction: 0.23026
Policy Update Magnitude: 0.75965
Value Function Update Magnitude: 0.59761

Collected Steps per Second: 22,305.23856
Overall Steps per Second: 10,765.59326

Timestep Collection Time: 2.24234
Timestep Consumption Time: 2.40357
PPO Batch Consumption Time: 0.27690
Total Iteration Time: 4.64591

Cumulative Model Updates: 92,248
Cumulative Timesteps: 769,256,328

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 116,643.91511
Policy Entropy: 3.68544
Value Function Loss: 0.08240

Mean KL Divergence: 0.01455
SB3 Clip Fraction: 0.17234
Policy Update Magnitude: 0.79077
Value Function Update Magnitude: 0.64372

Collected Steps per Second: 22,636.23234
Overall Steps per Second: 10,843.70925

Timestep Collection Time: 2.20991
Timestep Consumption Time: 2.40327
PPO Batch Consumption Time: 0.27851
Total Iteration Time: 4.61318

Cumulative Model Updates: 92,254
Cumulative Timesteps: 769,306,352

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 769306352...
Checkpoint 769306352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,252.26901
Policy Entropy: 3.73503
Value Function Loss: 0.07926

Mean KL Divergence: 0.01234
SB3 Clip Fraction: 0.15134
Policy Update Magnitude: 0.83984
Value Function Update Magnitude: 0.66126

Collected Steps per Second: 21,784.15383
Overall Steps per Second: 10,622.23108

Timestep Collection Time: 2.29552
Timestep Consumption Time: 2.41215
PPO Batch Consumption Time: 0.27899
Total Iteration Time: 4.70767

Cumulative Model Updates: 92,260
Cumulative Timesteps: 769,356,358

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50,394.79229
Policy Entropy: 3.75149
Value Function Loss: 0.08021

Mean KL Divergence: 0.01240
SB3 Clip Fraction: 0.14404
Policy Update Magnitude: 0.90317
Value Function Update Magnitude: 0.69609

Collected Steps per Second: 22,413.94585
Overall Steps per Second: 10,662.14300

Timestep Collection Time: 2.23156
Timestep Consumption Time: 2.45962
PPO Batch Consumption Time: 0.28809
Total Iteration Time: 4.69118

Cumulative Model Updates: 92,266
Cumulative Timesteps: 769,406,376

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 769406376...
Checkpoint 769406376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,611.91795
Policy Entropy: 3.76016
Value Function Loss: 0.07546

Mean KL Divergence: 0.01148
SB3 Clip Fraction: 0.13952
Policy Update Magnitude: 0.86874
Value Function Update Magnitude: 0.69636

Collected Steps per Second: 22,311.34114
Overall Steps per Second: 10,578.13218

Timestep Collection Time: 2.24245
Timestep Consumption Time: 2.48731
PPO Batch Consumption Time: 0.29261
Total Iteration Time: 4.72976

Cumulative Model Updates: 92,272
Cumulative Timesteps: 769,456,408

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,950.72395
Policy Entropy: 3.73303
Value Function Loss: 0.08105

Mean KL Divergence: 0.01100
SB3 Clip Fraction: 0.13638
Policy Update Magnitude: 0.83418
Value Function Update Magnitude: 0.68791

Collected Steps per Second: 22,734.18955
Overall Steps per Second: 10,852.66707

Timestep Collection Time: 2.20083
Timestep Consumption Time: 2.40947
PPO Batch Consumption Time: 0.27834
Total Iteration Time: 4.61030

Cumulative Model Updates: 92,278
Cumulative Timesteps: 769,506,442

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 769506442...
Checkpoint 769506442 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,672.80857
Policy Entropy: 3.73066
Value Function Loss: 0.07816

Mean KL Divergence: 0.01071
SB3 Clip Fraction: 0.13175
Policy Update Magnitude: 0.86671
Value Function Update Magnitude: 0.57588

Collected Steps per Second: 22,670.78514
Overall Steps per Second: 10,623.25188

Timestep Collection Time: 2.20583
Timestep Consumption Time: 2.50158
PPO Batch Consumption Time: 0.29058
Total Iteration Time: 4.70741

Cumulative Model Updates: 92,284
Cumulative Timesteps: 769,556,450

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,366.91279
Policy Entropy: 3.73633
Value Function Loss: 0.07739

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.12397
Policy Update Magnitude: 0.82217
Value Function Update Magnitude: 0.55089

Collected Steps per Second: 22,961.75833
Overall Steps per Second: 10,752.88212

Timestep Collection Time: 2.17832
Timestep Consumption Time: 2.47327
PPO Batch Consumption Time: 0.28812
Total Iteration Time: 4.65159

Cumulative Model Updates: 92,290
Cumulative Timesteps: 769,606,468

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 769606468...
Checkpoint 769606468 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,244.86406
Policy Entropy: 3.77916
Value Function Loss: 0.07526

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.11524
Policy Update Magnitude: 0.77736
Value Function Update Magnitude: 0.58631

Collected Steps per Second: 21,590.69283
Overall Steps per Second: 10,570.43976

Timestep Collection Time: 2.31618
Timestep Consumption Time: 2.41475
PPO Batch Consumption Time: 0.27934
Total Iteration Time: 4.73093

Cumulative Model Updates: 92,296
Cumulative Timesteps: 769,656,476

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,554.13917
Policy Entropy: 3.78859
Value Function Loss: 0.07141

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.11276
Policy Update Magnitude: 0.78705
Value Function Update Magnitude: 0.57011

Collected Steps per Second: 22,895.63455
Overall Steps per Second: 10,739.05188

Timestep Collection Time: 2.18478
Timestep Consumption Time: 2.47317
PPO Batch Consumption Time: 0.29034
Total Iteration Time: 4.65795

Cumulative Model Updates: 92,302
Cumulative Timesteps: 769,706,498

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 769706498...
Checkpoint 769706498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 747.19546
Policy Entropy: 3.80282
Value Function Loss: 0.06994

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.11286
Policy Update Magnitude: 0.74674
Value Function Update Magnitude: 0.53355

Collected Steps per Second: 22,293.98309
Overall Steps per Second: 10,515.08391

Timestep Collection Time: 2.24276
Timestep Consumption Time: 2.51232
PPO Batch Consumption Time: 0.30008
Total Iteration Time: 4.75507

Cumulative Model Updates: 92,308
Cumulative Timesteps: 769,756,498

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,897.39141
Policy Entropy: 3.75333
Value Function Loss: 0.06909

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.12112
Policy Update Magnitude: 0.71691
Value Function Update Magnitude: 0.51923

Collected Steps per Second: 22,688.93084
Overall Steps per Second: 10,661.52406

Timestep Collection Time: 2.20486
Timestep Consumption Time: 2.48734
PPO Batch Consumption Time: 0.28796
Total Iteration Time: 4.69220

Cumulative Model Updates: 92,314
Cumulative Timesteps: 769,806,524

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 769806524...
Checkpoint 769806524 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 157.50099
Policy Entropy: 3.74798
Value Function Loss: 0.07215

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.12693
Policy Update Magnitude: 0.68004
Value Function Update Magnitude: 0.54005

Collected Steps per Second: 22,671.91722
Overall Steps per Second: 10,670.59895

Timestep Collection Time: 2.20599
Timestep Consumption Time: 2.48110
PPO Batch Consumption Time: 0.29243
Total Iteration Time: 4.68708

Cumulative Model Updates: 92,320
Cumulative Timesteps: 769,856,538

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,010.65576
Policy Entropy: 3.75240
Value Function Loss: 0.06798

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.12142
Policy Update Magnitude: 0.66582
Value Function Update Magnitude: 0.56620

Collected Steps per Second: 22,256.94461
Overall Steps per Second: 10,622.73072

Timestep Collection Time: 2.24703
Timestep Consumption Time: 2.46099
PPO Batch Consumption Time: 0.28814
Total Iteration Time: 4.70802

Cumulative Model Updates: 92,326
Cumulative Timesteps: 769,906,550

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 769906550...
Checkpoint 769906550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 866.03919
Policy Entropy: 3.73073
Value Function Loss: 0.06002

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.12427
Policy Update Magnitude: 0.59399
Value Function Update Magnitude: 0.53817

Collected Steps per Second: 21,789.00402
Overall Steps per Second: 10,498.49768

Timestep Collection Time: 2.29519
Timestep Consumption Time: 2.46834
PPO Batch Consumption Time: 0.27893
Total Iteration Time: 4.76354

Cumulative Model Updates: 92,332
Cumulative Timesteps: 769,956,560

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,833.13030
Policy Entropy: 3.68644
Value Function Loss: 0.05093

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.13578
Policy Update Magnitude: 0.51297
Value Function Update Magnitude: 0.47659

Collected Steps per Second: 21,594.28631
Overall Steps per Second: 10,531.87928

Timestep Collection Time: 2.31598
Timestep Consumption Time: 2.43265
PPO Batch Consumption Time: 0.27709
Total Iteration Time: 4.74863

Cumulative Model Updates: 92,338
Cumulative Timesteps: 770,006,572

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 770006572...
Checkpoint 770006572 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,833.13030
Policy Entropy: 3.64729
Value Function Loss: 0.04411

Mean KL Divergence: 0.01115
SB3 Clip Fraction: 0.15452
Policy Update Magnitude: 0.43663
Value Function Update Magnitude: 0.43644

Collected Steps per Second: 22,290.81613
Overall Steps per Second: 10,483.44081

Timestep Collection Time: 2.24370
Timestep Consumption Time: 2.52706
PPO Batch Consumption Time: 0.28911
Total Iteration Time: 4.77076

Cumulative Model Updates: 92,344
Cumulative Timesteps: 770,056,586

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,833.13030
Policy Entropy: 3.65882
Value Function Loss: 0.03956

Mean KL Divergence: 0.01070
SB3 Clip Fraction: 0.14765
Policy Update Magnitude: 0.38922
Value Function Update Magnitude: 0.46163

Collected Steps per Second: 22,891.62719
Overall Steps per Second: 10,541.63714

Timestep Collection Time: 2.18534
Timestep Consumption Time: 2.56022
PPO Batch Consumption Time: 0.29164
Total Iteration Time: 4.74556

Cumulative Model Updates: 92,350
Cumulative Timesteps: 770,106,612

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 770106612...
Checkpoint 770106612 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,833.13030
Policy Entropy: 3.65319
Value Function Loss: 0.03546

Mean KL Divergence: 0.01131
SB3 Clip Fraction: 0.15304
Policy Update Magnitude: 0.38351
Value Function Update Magnitude: 0.54386

Collected Steps per Second: 22,941.89048
Overall Steps per Second: 10,642.79096

Timestep Collection Time: 2.18073
Timestep Consumption Time: 2.52011
PPO Batch Consumption Time: 0.29359
Total Iteration Time: 4.70083

Cumulative Model Updates: 92,356
Cumulative Timesteps: 770,156,642

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,599.32012
Policy Entropy: 3.66053
Value Function Loss: 0.03780

Mean KL Divergence: 0.01104
SB3 Clip Fraction: 0.15388
Policy Update Magnitude: 0.36221
Value Function Update Magnitude: 0.54795

Collected Steps per Second: 22,508.38531
Overall Steps per Second: 10,587.73572

Timestep Collection Time: 2.22290
Timestep Consumption Time: 2.50275
PPO Batch Consumption Time: 0.29145
Total Iteration Time: 4.72566

Cumulative Model Updates: 92,362
Cumulative Timesteps: 770,206,676

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 770206676...
Checkpoint 770206676 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,646.50902
Policy Entropy: 3.65933
Value Function Loss: 0.03857

Mean KL Divergence: 0.01109
SB3 Clip Fraction: 0.15333
Policy Update Magnitude: 0.34483
Value Function Update Magnitude: 0.42835

Collected Steps per Second: 22,075.30663
Overall Steps per Second: 10,639.04190

Timestep Collection Time: 2.26506
Timestep Consumption Time: 2.43479
PPO Batch Consumption Time: 0.29146
Total Iteration Time: 4.69986

Cumulative Model Updates: 92,368
Cumulative Timesteps: 770,256,678

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,641.21684
Policy Entropy: 3.67260
Value Function Loss: 0.04149

Mean KL Divergence: 0.01146
SB3 Clip Fraction: 0.15716
Policy Update Magnitude: 0.37061
Value Function Update Magnitude: 0.44488

Collected Steps per Second: 22,288.30719
Overall Steps per Second: 10,828.90544

Timestep Collection Time: 2.24459
Timestep Consumption Time: 2.37527
PPO Batch Consumption Time: 0.28327
Total Iteration Time: 4.61986

Cumulative Model Updates: 92,374
Cumulative Timesteps: 770,306,706

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 770306706...
Checkpoint 770306706 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 96,675.33587
Policy Entropy: 3.67093
Value Function Loss: 0.05099

Mean KL Divergence: 0.01076
SB3 Clip Fraction: 0.14916
Policy Update Magnitude: 0.40870
Value Function Update Magnitude: 0.45836

Collected Steps per Second: 22,315.41131
Overall Steps per Second: 10,708.89887

Timestep Collection Time: 2.24132
Timestep Consumption Time: 2.42919
PPO Batch Consumption Time: 0.29160
Total Iteration Time: 4.67051

Cumulative Model Updates: 92,380
Cumulative Timesteps: 770,356,722

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,125.59011
Policy Entropy: 3.68425
Value Function Loss: 0.04662

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.15095
Policy Update Magnitude: 0.45761
Value Function Update Magnitude: 0.45132

Collected Steps per Second: 21,701.21467
Overall Steps per Second: 10,485.63063

Timestep Collection Time: 2.30448
Timestep Consumption Time: 2.46490
PPO Batch Consumption Time: 0.28982
Total Iteration Time: 4.76938

Cumulative Model Updates: 92,386
Cumulative Timesteps: 770,406,732

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 770406732...
Checkpoint 770406732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 54,965.45715
Policy Entropy: 3.67944
Value Function Loss: 0.04157

Mean KL Divergence: 0.01151
SB3 Clip Fraction: 0.15886
Policy Update Magnitude: 0.45162
Value Function Update Magnitude: 0.47239

Collected Steps per Second: 21,984.02267
Overall Steps per Second: 10,497.04976

Timestep Collection Time: 2.27556
Timestep Consumption Time: 2.49016
PPO Batch Consumption Time: 0.29136
Total Iteration Time: 4.76572

Cumulative Model Updates: 92,392
Cumulative Timesteps: 770,456,758

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,056.46733
Policy Entropy: 3.68290
Value Function Loss: 0.03349

Mean KL Divergence: 0.01113
SB3 Clip Fraction: 0.15414
Policy Update Magnitude: 0.40120
Value Function Update Magnitude: 0.55656

Collected Steps per Second: 22,530.52786
Overall Steps per Second: 10,809.45151

Timestep Collection Time: 2.22037
Timestep Consumption Time: 2.40762
PPO Batch Consumption Time: 0.27861
Total Iteration Time: 4.62799

Cumulative Model Updates: 92,398
Cumulative Timesteps: 770,506,784

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 770506784...
Checkpoint 770506784 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 62,583.32545
Policy Entropy: 3.67087
Value Function Loss: 0.03462

Mean KL Divergence: 0.01118
SB3 Clip Fraction: 0.15466
Policy Update Magnitude: 0.39465
Value Function Update Magnitude: 0.55558

Collected Steps per Second: 22,379.61026
Overall Steps per Second: 10,721.32727

Timestep Collection Time: 2.23480
Timestep Consumption Time: 2.43011
PPO Batch Consumption Time: 0.27740
Total Iteration Time: 4.66491

Cumulative Model Updates: 92,404
Cumulative Timesteps: 770,556,798

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62,583.32545
Policy Entropy: 3.68015
Value Function Loss: 0.03215

Mean KL Divergence: 0.01109
SB3 Clip Fraction: 0.15450
Policy Update Magnitude: 0.39686
Value Function Update Magnitude: 0.47363

Collected Steps per Second: 22,380.53514
Overall Steps per Second: 10,550.69316

Timestep Collection Time: 2.23507
Timestep Consumption Time: 2.50604
PPO Batch Consumption Time: 0.29104
Total Iteration Time: 4.74111

Cumulative Model Updates: 92,410
Cumulative Timesteps: 770,606,820

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 770606820...
Checkpoint 770606820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84,964.86404
Policy Entropy: 3.65794
Value Function Loss: 0.03048

Mean KL Divergence: 0.01114
SB3 Clip Fraction: 0.15530
Policy Update Magnitude: 0.36882
Value Function Update Magnitude: 0.48210

Collected Steps per Second: 22,615.60922
Overall Steps per Second: 10,562.32254

Timestep Collection Time: 2.21113
Timestep Consumption Time: 2.52325
PPO Batch Consumption Time: 0.29059
Total Iteration Time: 4.73438

Cumulative Model Updates: 92,416
Cumulative Timesteps: 770,656,826

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 150,441.73569
Policy Entropy: 3.65048
Value Function Loss: 0.03482

Mean KL Divergence: 0.01153
SB3 Clip Fraction: 0.16041
Policy Update Magnitude: 0.35220
Value Function Update Magnitude: 0.50853

Collected Steps per Second: 23,045.95691
Overall Steps per Second: 10,844.17400

Timestep Collection Time: 2.17036
Timestep Consumption Time: 2.44207
PPO Batch Consumption Time: 0.27870
Total Iteration Time: 4.61243

Cumulative Model Updates: 92,422
Cumulative Timesteps: 770,706,844

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 770706844...
Checkpoint 770706844 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 150,441.73569
Policy Entropy: 3.63626
Value Function Loss: 0.03692

Mean KL Divergence: 0.01107
SB3 Clip Fraction: 0.15334
Policy Update Magnitude: 0.36970
Value Function Update Magnitude: 0.49336

Collected Steps per Second: 22,692.96436
Overall Steps per Second: 10,728.72551

Timestep Collection Time: 2.20447
Timestep Consumption Time: 2.45834
PPO Batch Consumption Time: 0.28362
Total Iteration Time: 4.66281

Cumulative Model Updates: 92,428
Cumulative Timesteps: 770,756,870

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 150,441.73569
Policy Entropy: 3.64260
Value Function Loss: 0.03588

Mean KL Divergence: 0.01139
SB3 Clip Fraction: 0.15769
Policy Update Magnitude: 0.36300
Value Function Update Magnitude: 0.47250

Collected Steps per Second: 22,496.10106
Overall Steps per Second: 10,607.01526

Timestep Collection Time: 2.22323
Timestep Consumption Time: 2.49195
PPO Batch Consumption Time: 0.28899
Total Iteration Time: 4.71518

Cumulative Model Updates: 92,434
Cumulative Timesteps: 770,806,884

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 770806884...
Checkpoint 770806884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 150,441.73569
Policy Entropy: 3.65251
Value Function Loss: 0.03556

Mean KL Divergence: 0.01110
SB3 Clip Fraction: 0.15247
Policy Update Magnitude: 0.34901
Value Function Update Magnitude: 0.40965

Collected Steps per Second: 22,348.60118
Overall Steps per Second: 10,888.19860

Timestep Collection Time: 2.23817
Timestep Consumption Time: 2.35579
PPO Batch Consumption Time: 0.27951
Total Iteration Time: 4.59396

Cumulative Model Updates: 92,440
Cumulative Timesteps: 770,856,904

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 105,493.26049
Policy Entropy: 3.65478
Value Function Loss: 0.03339

Mean KL Divergence: 0.01124
SB3 Clip Fraction: 0.15666
Policy Update Magnitude: 0.32686
Value Function Update Magnitude: 0.33983

Collected Steps per Second: 22,226.00741
Overall Steps per Second: 10,866.63665

Timestep Collection Time: 2.25088
Timestep Consumption Time: 2.35294
PPO Batch Consumption Time: 0.27867
Total Iteration Time: 4.60382

Cumulative Model Updates: 92,446
Cumulative Timesteps: 770,906,932

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 770906932...
Checkpoint 770906932 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 142,497.06182
Policy Entropy: 3.65041
Value Function Loss: 0.03665

Mean KL Divergence: 0.01089
SB3 Clip Fraction: 0.15408
Policy Update Magnitude: 0.32388
Value Function Update Magnitude: 0.35777

Collected Steps per Second: 21,994.25418
Overall Steps per Second: 10,662.79374

Timestep Collection Time: 2.27414
Timestep Consumption Time: 2.41675
PPO Batch Consumption Time: 0.27845
Total Iteration Time: 4.69089

Cumulative Model Updates: 92,452
Cumulative Timesteps: 770,956,950

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 139,379.54966
Policy Entropy: 3.66090
Value Function Loss: 0.03587

Mean KL Divergence: 0.01111
SB3 Clip Fraction: 0.15575
Policy Update Magnitude: 0.35524
Value Function Update Magnitude: 0.49662

Collected Steps per Second: 22,501.36281
Overall Steps per Second: 10,565.88851

Timestep Collection Time: 2.22280
Timestep Consumption Time: 2.51093
PPO Batch Consumption Time: 0.29316
Total Iteration Time: 4.73372

Cumulative Model Updates: 92,458
Cumulative Timesteps: 771,006,966

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 771006966...
Checkpoint 771006966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 132,104.06666
Policy Entropy: 3.63972
Value Function Loss: 0.03831

Mean KL Divergence: 0.01088
SB3 Clip Fraction: 0.15062
Policy Update Magnitude: 0.36933
Value Function Update Magnitude: 0.43166

Collected Steps per Second: 22,187.98359
Overall Steps per Second: 10,577.68520

Timestep Collection Time: 2.25437
Timestep Consumption Time: 2.47445
PPO Batch Consumption Time: 0.28306
Total Iteration Time: 4.72882

Cumulative Model Updates: 92,464
Cumulative Timesteps: 771,056,986

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 132,104.06666
Policy Entropy: 3.64198
Value Function Loss: 0.03860

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.14796
Policy Update Magnitude: 0.38742
Value Function Update Magnitude: 0.48874

Collected Steps per Second: 21,660.22808
Overall Steps per Second: 10,566.05734

Timestep Collection Time: 2.30949
Timestep Consumption Time: 2.42492
PPO Batch Consumption Time: 0.27733
Total Iteration Time: 4.73441

Cumulative Model Updates: 92,470
Cumulative Timesteps: 771,107,010

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 771107010...
Checkpoint 771107010 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 257,356.99040
Policy Entropy: 3.63677
Value Function Loss: 0.04214

Mean KL Divergence: 0.01160
SB3 Clip Fraction: 0.15906
Policy Update Magnitude: 0.39803
Value Function Update Magnitude: 0.44508

Collected Steps per Second: 22,487.28430
Overall Steps per Second: 10,589.90089

Timestep Collection Time: 2.22392
Timestep Consumption Time: 2.49850
PPO Batch Consumption Time: 0.28896
Total Iteration Time: 4.72242

Cumulative Model Updates: 92,476
Cumulative Timesteps: 771,157,020

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 203,820.45895
Policy Entropy: 3.65896
Value Function Loss: 0.04161

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.14275
Policy Update Magnitude: 0.41491
Value Function Update Magnitude: 0.47192

Collected Steps per Second: 22,796.94151
Overall Steps per Second: 10,557.46001

Timestep Collection Time: 2.19477
Timestep Consumption Time: 2.54444
PPO Batch Consumption Time: 0.29199
Total Iteration Time: 4.73921

Cumulative Model Updates: 92,482
Cumulative Timesteps: 771,207,054

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 771207054...
Checkpoint 771207054 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 203,820.45895
Policy Entropy: 3.66293
Value Function Loss: 0.04325

Mean KL Divergence: 0.01127
SB3 Clip Fraction: 0.15479
Policy Update Magnitude: 0.47969
Value Function Update Magnitude: 0.53707

Collected Steps per Second: 22,996.95751
Overall Steps per Second: 10,826.79911

Timestep Collection Time: 2.17516
Timestep Consumption Time: 2.44504
PPO Batch Consumption Time: 0.27741
Total Iteration Time: 4.62020

Cumulative Model Updates: 92,488
Cumulative Timesteps: 771,257,076

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 203,820.45895
Policy Entropy: 3.66428
Value Function Loss: 0.03935

Mean KL Divergence: 0.01066
SB3 Clip Fraction: 0.14915
Policy Update Magnitude: 0.47826
Value Function Update Magnitude: 0.56574

Collected Steps per Second: 23,132.73833
Overall Steps per Second: 10,883.84136

Timestep Collection Time: 2.16282
Timestep Consumption Time: 2.43408
PPO Batch Consumption Time: 0.27786
Total Iteration Time: 4.59691

Cumulative Model Updates: 92,494
Cumulative Timesteps: 771,307,108

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 771307108...
Checkpoint 771307108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 163,364.35767
Policy Entropy: 3.67118
Value Function Loss: 0.03890

Mean KL Divergence: 0.01107
SB3 Clip Fraction: 0.15267
Policy Update Magnitude: 0.49969
Value Function Update Magnitude: 0.54166

Collected Steps per Second: 22,776.23806
Overall Steps per Second: 10,624.68675

Timestep Collection Time: 2.19571
Timestep Consumption Time: 2.51125
PPO Batch Consumption Time: 0.29278
Total Iteration Time: 4.70696

Cumulative Model Updates: 92,500
Cumulative Timesteps: 771,357,118

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 117,917.37493
Policy Entropy: 3.66107
Value Function Loss: 0.04382

Mean KL Divergence: 0.01114
SB3 Clip Fraction: 0.15407
Policy Update Magnitude: 0.48322
Value Function Update Magnitude: 0.61296

Collected Steps per Second: 22,908.14188
Overall Steps per Second: 10,795.96793

Timestep Collection Time: 2.18263
Timestep Consumption Time: 2.44873
PPO Batch Consumption Time: 0.27944
Total Iteration Time: 4.63136

Cumulative Model Updates: 92,506
Cumulative Timesteps: 771,407,118

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 771407118...
Checkpoint 771407118 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,621.96211
Policy Entropy: 3.67821
Value Function Loss: 0.04448

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.14456
Policy Update Magnitude: 0.48544
Value Function Update Magnitude: 0.65442

Collected Steps per Second: 22,824.95020
Overall Steps per Second: 10,776.42911

Timestep Collection Time: 2.19102
Timestep Consumption Time: 2.44966
PPO Batch Consumption Time: 0.27974
Total Iteration Time: 4.64068

Cumulative Model Updates: 92,512
Cumulative Timesteps: 771,457,128

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,163.63444
Policy Entropy: 3.66900
Value Function Loss: 0.04516

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.13983
Policy Update Magnitude: 0.49328
Value Function Update Magnitude: 0.59550

Collected Steps per Second: 22,382.26971
Overall Steps per Second: 10,512.06861

Timestep Collection Time: 2.23507
Timestep Consumption Time: 2.52384
PPO Batch Consumption Time: 0.29221
Total Iteration Time: 4.75891

Cumulative Model Updates: 92,518
Cumulative Timesteps: 771,507,154

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 771507154...
Checkpoint 771507154 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,163.63444
Policy Entropy: 3.66467
Value Function Loss: 0.03579

Mean KL Divergence: 0.01305
SB3 Clip Fraction: 0.15632
Policy Update Magnitude: 0.52687
Value Function Update Magnitude: 0.58056

Collected Steps per Second: 20,917.25763
Overall Steps per Second: 10,172.41441

Timestep Collection Time: 2.39094
Timestep Consumption Time: 2.52549
PPO Batch Consumption Time: 0.29161
Total Iteration Time: 4.91643

Cumulative Model Updates: 92,524
Cumulative Timesteps: 771,557,166

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 260,001.57219
Policy Entropy: 3.61282
Value Function Loss: 0.05717

Mean KL Divergence: 0.03218
SB3 Clip Fraction: 0.28126
Policy Update Magnitude: 0.52941
Value Function Update Magnitude: 0.50229

Collected Steps per Second: 22,270.44760
Overall Steps per Second: 10,472.93516

Timestep Collection Time: 2.24594
Timestep Consumption Time: 2.52999
PPO Batch Consumption Time: 0.28917
Total Iteration Time: 4.77593

Cumulative Model Updates: 92,530
Cumulative Timesteps: 771,607,184

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 771607184...
Checkpoint 771607184 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 75,846.79328
Policy Entropy: 3.62898
Value Function Loss: 0.07625

Mean KL Divergence: 0.02999
SB3 Clip Fraction: 0.28117
Policy Update Magnitude: 0.58511
Value Function Update Magnitude: 0.56545

Collected Steps per Second: 21,749.07260
Overall Steps per Second: 10,585.37259

Timestep Collection Time: 2.29895
Timestep Consumption Time: 2.42455
PPO Batch Consumption Time: 0.27878
Total Iteration Time: 4.72350

Cumulative Model Updates: 92,536
Cumulative Timesteps: 771,657,184

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 143,255.69126
Policy Entropy: 3.64415
Value Function Loss: 0.09832

Mean KL Divergence: 0.01543
SB3 Clip Fraction: 0.18292
Policy Update Magnitude: 0.79809
Value Function Update Magnitude: 0.57756

Collected Steps per Second: 22,353.04689
Overall Steps per Second: 10,347.05811

Timestep Collection Time: 2.23692
Timestep Consumption Time: 2.59556
PPO Batch Consumption Time: 0.30371
Total Iteration Time: 4.83248

Cumulative Model Updates: 92,542
Cumulative Timesteps: 771,707,186

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 771707186...
Checkpoint 771707186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 104,539.08924
Policy Entropy: 3.71606
Value Function Loss: 0.10206

Mean KL Divergence: 0.01521
SB3 Clip Fraction: 0.17822
Policy Update Magnitude: 0.92167
Value Function Update Magnitude: 0.55460

Collected Steps per Second: 22,201.31210
Overall Steps per Second: 10,571.26363

Timestep Collection Time: 2.25356
Timestep Consumption Time: 2.47927
PPO Batch Consumption Time: 0.28735
Total Iteration Time: 4.73283

Cumulative Model Updates: 92,548
Cumulative Timesteps: 771,757,218

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 131,977.92639
Policy Entropy: 3.73710
Value Function Loss: 0.09562

Mean KL Divergence: 0.01269
SB3 Clip Fraction: 0.14976
Policy Update Magnitude: 1.04554
Value Function Update Magnitude: 0.60818

Collected Steps per Second: 22,634.94920
Overall Steps per Second: 10,690.78026

Timestep Collection Time: 2.20977
Timestep Consumption Time: 2.46884
PPO Batch Consumption Time: 0.27944
Total Iteration Time: 4.67861

Cumulative Model Updates: 92,554
Cumulative Timesteps: 771,807,236

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 771807236...
Checkpoint 771807236 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,942.99564
Policy Entropy: 3.75138
Value Function Loss: 0.08448

Mean KL Divergence: 0.01249
SB3 Clip Fraction: 0.14770
Policy Update Magnitude: 1.13833
Value Function Update Magnitude: 0.63165

Collected Steps per Second: 22,890.53671
Overall Steps per Second: 10,644.75225

Timestep Collection Time: 2.18483
Timestep Consumption Time: 2.51344
PPO Batch Consumption Time: 0.29105
Total Iteration Time: 4.69828

Cumulative Model Updates: 92,560
Cumulative Timesteps: 771,857,248

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,990.59458
Policy Entropy: 3.74311
Value Function Loss: 0.07746

Mean KL Divergence: 0.01148
SB3 Clip Fraction: 0.14513
Policy Update Magnitude: 0.99784
Value Function Update Magnitude: 0.63257

Collected Steps per Second: 22,942.85398
Overall Steps per Second: 10,733.65097

Timestep Collection Time: 2.18037
Timestep Consumption Time: 2.48011
PPO Batch Consumption Time: 0.28857
Total Iteration Time: 4.66048

Cumulative Model Updates: 92,566
Cumulative Timesteps: 771,907,272

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 771907272...
Checkpoint 771907272 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,259.30623
Policy Entropy: 3.76109
Value Function Loss: 0.07027

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.11949
Policy Update Magnitude: 0.85310
Value Function Update Magnitude: 0.71616

Collected Steps per Second: 23,035.59238
Overall Steps per Second: 10,895.55464

Timestep Collection Time: 2.17125
Timestep Consumption Time: 2.41925
PPO Batch Consumption Time: 0.27828
Total Iteration Time: 4.59050

Cumulative Model Updates: 92,572
Cumulative Timesteps: 771,957,288

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 953.70434
Policy Entropy: 3.76120
Value Function Loss: 0.06931

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.12329
Policy Update Magnitude: 0.84062
Value Function Update Magnitude: 0.65795

Collected Steps per Second: 22,821.83146
Overall Steps per Second: 10,801.12030

Timestep Collection Time: 2.19202
Timestep Consumption Time: 2.43953
PPO Batch Consumption Time: 0.27927
Total Iteration Time: 4.63156

Cumulative Model Updates: 92,578
Cumulative Timesteps: 772,007,314

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 772007314...
Checkpoint 772007314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,898.35443
Policy Entropy: 3.74692
Value Function Loss: 0.06566

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.12428
Policy Update Magnitude: 0.81594
Value Function Update Magnitude: 0.67114

Collected Steps per Second: 21,933.54157
Overall Steps per Second: 10,769.88131

Timestep Collection Time: 2.27970
Timestep Consumption Time: 2.36306
PPO Batch Consumption Time: 0.27932
Total Iteration Time: 4.64276

Cumulative Model Updates: 92,584
Cumulative Timesteps: 772,057,316

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99,047.36439
Policy Entropy: 3.71685
Value Function Loss: 0.06541

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.12414
Policy Update Magnitude: 0.78922
Value Function Update Magnitude: 0.70115

Collected Steps per Second: 21,656.62064
Overall Steps per Second: 10,535.46956

Timestep Collection Time: 2.30969
Timestep Consumption Time: 2.43809
PPO Batch Consumption Time: 0.29253
Total Iteration Time: 4.74777

Cumulative Model Updates: 92,590
Cumulative Timesteps: 772,107,336

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 772107336...
Checkpoint 772107336 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,526.90191
Policy Entropy: 3.68833
Value Function Loss: 0.07176

Mean KL Divergence: 0.01047
SB3 Clip Fraction: 0.13151
Policy Update Magnitude: 0.70225
Value Function Update Magnitude: 0.53719

Collected Steps per Second: 21,734.42125
Overall Steps per Second: 10,631.77640

Timestep Collection Time: 2.30077
Timestep Consumption Time: 2.40267
PPO Batch Consumption Time: 0.28696
Total Iteration Time: 4.70345

Cumulative Model Updates: 92,596
Cumulative Timesteps: 772,157,342

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59,268.33587
Policy Entropy: 3.66993
Value Function Loss: 0.07241

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.12295
Policy Update Magnitude: 0.66841
Value Function Update Magnitude: 0.52461

Collected Steps per Second: 21,564.25879
Overall Steps per Second: 10,523.46504

Timestep Collection Time: 2.31874
Timestep Consumption Time: 2.43273
PPO Batch Consumption Time: 0.29317
Total Iteration Time: 4.75148

Cumulative Model Updates: 92,602
Cumulative Timesteps: 772,207,344

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 772207344...
Checkpoint 772207344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,567.24763
Policy Entropy: 3.68381
Value Function Loss: 0.07741

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.12702
Policy Update Magnitude: 0.73269
Value Function Update Magnitude: 0.58953

Collected Steps per Second: 21,729.16720
Overall Steps per Second: 10,721.70418

Timestep Collection Time: 2.30216
Timestep Consumption Time: 2.36352
PPO Batch Consumption Time: 0.27965
Total Iteration Time: 4.66568

Cumulative Model Updates: 92,608
Cumulative Timesteps: 772,257,368

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,857.68000
Policy Entropy: 3.70395
Value Function Loss: 0.07883

Mean KL Divergence: 0.01157
SB3 Clip Fraction: 0.13858
Policy Update Magnitude: 0.76747
Value Function Update Magnitude: 0.61481

Collected Steps per Second: 21,816.27394
Overall Steps per Second: 10,511.73467

Timestep Collection Time: 2.29251
Timestep Consumption Time: 2.46541
PPO Batch Consumption Time: 0.28042
Total Iteration Time: 4.75792

Cumulative Model Updates: 92,614
Cumulative Timesteps: 772,307,382

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 772307382...
Checkpoint 772307382 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,290.94434
Policy Entropy: 3.73024
Value Function Loss: 0.07658

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.13003
Policy Update Magnitude: 0.73452
Value Function Update Magnitude: 0.52611

Collected Steps per Second: 22,556.78644
Overall Steps per Second: 10,525.61542

Timestep Collection Time: 2.21689
Timestep Consumption Time: 2.53399
PPO Batch Consumption Time: 0.29854
Total Iteration Time: 4.75089

Cumulative Model Updates: 92,620
Cumulative Timesteps: 772,357,388

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42,474.41930
Policy Entropy: 3.70954
Value Function Loss: 0.07369

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.12190
Policy Update Magnitude: 0.73507
Value Function Update Magnitude: 0.50472

Collected Steps per Second: 22,385.60446
Overall Steps per Second: 10,448.21244

Timestep Collection Time: 2.23403
Timestep Consumption Time: 2.55244
PPO Batch Consumption Time: 0.30547
Total Iteration Time: 4.78646

Cumulative Model Updates: 92,626
Cumulative Timesteps: 772,407,398

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 772407398...
Checkpoint 772407398 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,539.37405
Policy Entropy: 3.71426
Value Function Loss: 0.07323

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.11705
Policy Update Magnitude: 0.72545
Value Function Update Magnitude: 0.51246

Collected Steps per Second: 22,453.84168
Overall Steps per Second: 10,762.98769

Timestep Collection Time: 2.22786
Timestep Consumption Time: 2.41992
PPO Batch Consumption Time: 0.27986
Total Iteration Time: 4.64778

Cumulative Model Updates: 92,632
Cumulative Timesteps: 772,457,422

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,870.63597
Policy Entropy: 3.72892
Value Function Loss: 0.07047

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.11342
Policy Update Magnitude: 0.78911
Value Function Update Magnitude: 0.49488

Collected Steps per Second: 22,417.60048
Overall Steps per Second: 10,637.02935

Timestep Collection Time: 2.23119
Timestep Consumption Time: 2.47106
PPO Batch Consumption Time: 0.29148
Total Iteration Time: 4.70225

Cumulative Model Updates: 92,638
Cumulative Timesteps: 772,507,440

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 772507440...
Checkpoint 772507440 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,617.82228
Policy Entropy: 3.75268
Value Function Loss: 0.06934

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.10814
Policy Update Magnitude: 0.85296
Value Function Update Magnitude: 0.51820

Collected Steps per Second: 22,721.43519
Overall Steps per Second: 10,729.41901

Timestep Collection Time: 2.20127
Timestep Consumption Time: 2.46031
PPO Batch Consumption Time: 0.28908
Total Iteration Time: 4.66158

Cumulative Model Updates: 92,644
Cumulative Timesteps: 772,557,456

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,977.87619
Policy Entropy: 3.75151
Value Function Loss: 0.06777

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.12230
Policy Update Magnitude: 0.82514
Value Function Update Magnitude: 0.54368

Collected Steps per Second: 22,538.21094
Overall Steps per Second: 10,722.57986

Timestep Collection Time: 2.21845
Timestep Consumption Time: 2.44460
PPO Batch Consumption Time: 0.28362
Total Iteration Time: 4.66306

Cumulative Model Updates: 92,650
Cumulative Timesteps: 772,607,456

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 772607456...
Checkpoint 772607456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,050.83621
Policy Entropy: 3.75536
Value Function Loss: 0.06324

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.12230
Policy Update Magnitude: 0.76121
Value Function Update Magnitude: 0.53014

Collected Steps per Second: 21,664.16276
Overall Steps per Second: 10,600.57533

Timestep Collection Time: 2.30833
Timestep Consumption Time: 2.40915
PPO Batch Consumption Time: 0.27913
Total Iteration Time: 4.71748

Cumulative Model Updates: 92,656
Cumulative Timesteps: 772,657,464

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,592.34709
Policy Entropy: 3.73158
Value Function Loss: 0.06036

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.12339
Policy Update Magnitude: 0.75343
Value Function Update Magnitude: 0.51832

Collected Steps per Second: 21,970.25069
Overall Steps per Second: 10,485.62150

Timestep Collection Time: 2.27662
Timestep Consumption Time: 2.49353
PPO Batch Consumption Time: 0.29196
Total Iteration Time: 4.77015

Cumulative Model Updates: 92,662
Cumulative Timesteps: 772,707,482

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 772707482...
Checkpoint 772707482 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,694.22764
Policy Entropy: 3.73591
Value Function Loss: 0.06111

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.12404
Policy Update Magnitude: 0.72403
Value Function Update Magnitude: 0.48032

Collected Steps per Second: 22,202.52552
Overall Steps per Second: 10,679.57060

Timestep Collection Time: 2.25227
Timestep Consumption Time: 2.43013
PPO Batch Consumption Time: 0.27753
Total Iteration Time: 4.68240

Cumulative Model Updates: 92,668
Cumulative Timesteps: 772,757,488

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,128.61373
Policy Entropy: 3.70929
Value Function Loss: 0.06466

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.13667
Policy Update Magnitude: 0.62539
Value Function Update Magnitude: 0.41882

Collected Steps per Second: 22,402.54131
Overall Steps per Second: 10,553.62914

Timestep Collection Time: 2.23243
Timestep Consumption Time: 2.50642
PPO Batch Consumption Time: 0.29069
Total Iteration Time: 4.73884

Cumulative Model Updates: 92,674
Cumulative Timesteps: 772,807,500

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 772807500...
Checkpoint 772807500 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,861.20900
Policy Entropy: 3.70117
Value Function Loss: 0.06357

Mean KL Divergence: 0.01101
SB3 Clip Fraction: 0.13826
Policy Update Magnitude: 0.55266
Value Function Update Magnitude: 0.41371

Collected Steps per Second: 22,770.07652
Overall Steps per Second: 10,578.12151

Timestep Collection Time: 2.19718
Timestep Consumption Time: 2.53239
PPO Batch Consumption Time: 0.29294
Total Iteration Time: 4.72957

Cumulative Model Updates: 92,680
Cumulative Timesteps: 772,857,530

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,198.38045
Policy Entropy: 3.69566
Value Function Loss: 0.05771

Mean KL Divergence: 0.01088
SB3 Clip Fraction: 0.13949
Policy Update Magnitude: 0.50488
Value Function Update Magnitude: 0.45210

Collected Steps per Second: 23,013.60171
Overall Steps per Second: 10,788.68267

Timestep Collection Time: 2.17437
Timestep Consumption Time: 2.46383
PPO Batch Consumption Time: 0.28005
Total Iteration Time: 4.63819

Cumulative Model Updates: 92,686
Cumulative Timesteps: 772,907,570

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 772907570...
Checkpoint 772907570 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,216.96056
Policy Entropy: 3.67601
Value Function Loss: 0.05355

Mean KL Divergence: 0.01073
SB3 Clip Fraction: 0.13294
Policy Update Magnitude: 0.50571
Value Function Update Magnitude: 0.47155

Collected Steps per Second: 22,553.18978
Overall Steps per Second: 10,684.58166

Timestep Collection Time: 2.21698
Timestep Consumption Time: 2.46266
PPO Batch Consumption Time: 0.27997
Total Iteration Time: 4.67964

Cumulative Model Updates: 92,692
Cumulative Timesteps: 772,957,570

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,790.82469
Policy Entropy: 3.67316
Value Function Loss: 0.05308

Mean KL Divergence: 0.01057
SB3 Clip Fraction: 0.13509
Policy Update Magnitude: 0.51268
Value Function Update Magnitude: 0.46753

Collected Steps per Second: 22,853.06809
Overall Steps per Second: 10,828.59847

Timestep Collection Time: 2.18824
Timestep Consumption Time: 2.42990
PPO Batch Consumption Time: 0.27987
Total Iteration Time: 4.61814

Cumulative Model Updates: 92,698
Cumulative Timesteps: 773,007,578

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 773007578...
Checkpoint 773007578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 65,435.84326
Policy Entropy: 3.66395
Value Function Loss: 0.05534

Mean KL Divergence: 0.01050
SB3 Clip Fraction: 0.13706
Policy Update Magnitude: 0.46350
Value Function Update Magnitude: 0.43068

Collected Steps per Second: 22,150.75955
Overall Steps per Second: 10,575.77668

Timestep Collection Time: 2.25762
Timestep Consumption Time: 2.47092
PPO Batch Consumption Time: 0.28693
Total Iteration Time: 4.72854

Cumulative Model Updates: 92,704
Cumulative Timesteps: 773,057,586

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,546.28494
Policy Entropy: 3.65960
Value Function Loss: 0.05458

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.13756
Policy Update Magnitude: 0.43775
Value Function Update Magnitude: 0.38658

Collected Steps per Second: 22,812.65292
Overall Steps per Second: 10,637.25184

Timestep Collection Time: 2.19185
Timestep Consumption Time: 2.50880
PPO Batch Consumption Time: 0.29316
Total Iteration Time: 4.70065

Cumulative Model Updates: 92,710
Cumulative Timesteps: 773,107,588

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 773107588...
Checkpoint 773107588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 54,585.61876
Policy Entropy: 3.65953
Value Function Loss: 0.05187

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.13353
Policy Update Magnitude: 0.42236
Value Function Update Magnitude: 0.36451

Collected Steps per Second: 22,867.82405
Overall Steps per Second: 10,653.12229

Timestep Collection Time: 2.18788
Timestep Consumption Time: 2.50859
PPO Batch Consumption Time: 0.29353
Total Iteration Time: 4.69646

Cumulative Model Updates: 92,716
Cumulative Timesteps: 773,157,620

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54,585.61876
Policy Entropy: 3.66767
Value Function Loss: 0.04384

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.13906
Policy Update Magnitude: 0.39567
Value Function Update Magnitude: 0.36284

Collected Steps per Second: 21,508.59387
Overall Steps per Second: 10,497.77073

Timestep Collection Time: 2.32530
Timestep Consumption Time: 2.43895
PPO Batch Consumption Time: 0.29370
Total Iteration Time: 4.76425

Cumulative Model Updates: 92,722
Cumulative Timesteps: 773,207,634

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 773207634...
Checkpoint 773207634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 78,252.97208
Policy Entropy: 3.66624
Value Function Loss: 0.04109

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.14082
Policy Update Magnitude: 0.36755
Value Function Update Magnitude: 0.38319

Collected Steps per Second: 21,621.47117
Overall Steps per Second: 10,605.61590

Timestep Collection Time: 2.31381
Timestep Consumption Time: 2.40331
PPO Batch Consumption Time: 0.28653
Total Iteration Time: 4.71712

Cumulative Model Updates: 92,728
Cumulative Timesteps: 773,257,662

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 129,255.73541
Policy Entropy: 3.65666
Value Function Loss: 0.03877

Mean KL Divergence: 0.01067
SB3 Clip Fraction: 0.14087
Policy Update Magnitude: 0.36801
Value Function Update Magnitude: 0.43599

Collected Steps per Second: 21,505.89608
Overall Steps per Second: 10,548.61666

Timestep Collection Time: 2.32541
Timestep Consumption Time: 2.41550
PPO Batch Consumption Time: 0.27735
Total Iteration Time: 4.74091

Cumulative Model Updates: 92,734
Cumulative Timesteps: 773,307,672

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 773307672...
Checkpoint 773307672 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40,225.14436
Policy Entropy: 3.65338
Value Function Loss: 0.04453

Mean KL Divergence: 0.01067
SB3 Clip Fraction: 0.14259
Policy Update Magnitude: 0.37759
Value Function Update Magnitude: 0.49210

Collected Steps per Second: 22,577.76767
Overall Steps per Second: 10,634.09021

Timestep Collection Time: 2.21519
Timestep Consumption Time: 2.48799
PPO Batch Consumption Time: 0.29324
Total Iteration Time: 4.70318

Cumulative Model Updates: 92,740
Cumulative Timesteps: 773,357,686

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46,414.09264
Policy Entropy: 3.66425
Value Function Loss: 0.04580

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.14263
Policy Update Magnitude: 0.39834
Value Function Update Magnitude: 0.49091

Collected Steps per Second: 22,972.61400
Overall Steps per Second: 10,777.58533

Timestep Collection Time: 2.17738
Timestep Consumption Time: 2.46374
PPO Batch Consumption Time: 0.27957
Total Iteration Time: 4.64111

Cumulative Model Updates: 92,746
Cumulative Timesteps: 773,407,706

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 773407706...
Checkpoint 773407706 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46,414.09264
Policy Entropy: 3.66049
Value Function Loss: 0.03841

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.13724
Policy Update Magnitude: 0.40573
Value Function Update Magnitude: 0.63814

Collected Steps per Second: 21,489.28448
Overall Steps per Second: 10,245.60490

Timestep Collection Time: 2.32776
Timestep Consumption Time: 2.55452
PPO Batch Consumption Time: 0.29483
Total Iteration Time: 4.88229

Cumulative Model Updates: 92,752
Cumulative Timesteps: 773,457,728

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79,736.97710
Policy Entropy: 3.66116
Value Function Loss: 0.03124

Mean KL Divergence: 0.01060
SB3 Clip Fraction: 0.14168
Policy Update Magnitude: 0.38569
Value Function Update Magnitude: 0.60689

Collected Steps per Second: 22,716.67315
Overall Steps per Second: 10,612.51131

Timestep Collection Time: 2.20120
Timestep Consumption Time: 2.51059
PPO Batch Consumption Time: 0.29072
Total Iteration Time: 4.71180

Cumulative Model Updates: 92,758
Cumulative Timesteps: 773,507,732

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 773507732...
Checkpoint 773507732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 111,536.37242
Policy Entropy: 3.65809
Value Function Loss: 0.03013

Mean KL Divergence: 0.01113
SB3 Clip Fraction: 0.15100
Policy Update Magnitude: 0.35345
Value Function Update Magnitude: 0.65851

Collected Steps per Second: 23,040.63489
Overall Steps per Second: 10,842.55165

Timestep Collection Time: 2.17034
Timestep Consumption Time: 2.44167
PPO Batch Consumption Time: 0.27929
Total Iteration Time: 4.61201

Cumulative Model Updates: 92,764
Cumulative Timesteps: 773,557,738

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53,694.72476
Policy Entropy: 3.68633
Value Function Loss: 0.03615

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.13943
Policy Update Magnitude: 0.36942
Value Function Update Magnitude: 0.73277

Collected Steps per Second: 22,806.46692
Overall Steps per Second: 10,631.18584

Timestep Collection Time: 2.19271
Timestep Consumption Time: 2.51119
PPO Batch Consumption Time: 0.29380
Total Iteration Time: 4.70390

Cumulative Model Updates: 92,770
Cumulative Timesteps: 773,607,746

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 773607746...
Checkpoint 773607746 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48,841.53843
Policy Entropy: 3.70697
Value Function Loss: 0.04202

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.12841
Policy Update Magnitude: 0.44485
Value Function Update Magnitude: 0.71923

Collected Steps per Second: 22,884.19045
Overall Steps per Second: 10,815.14284

Timestep Collection Time: 2.18544
Timestep Consumption Time: 2.43882
PPO Batch Consumption Time: 0.27839
Total Iteration Time: 4.62426

Cumulative Model Updates: 92,776
Cumulative Timesteps: 773,657,758

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,734.89631
Policy Entropy: 3.71698
Value Function Loss: 0.04766

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.14175
Policy Update Magnitude: 0.50655
Value Function Update Magnitude: 0.75488

Collected Steps per Second: 22,605.03135
Overall Steps per Second: 10,600.12563

Timestep Collection Time: 2.21393
Timestep Consumption Time: 2.50733
PPO Batch Consumption Time: 0.29266
Total Iteration Time: 4.72126

Cumulative Model Updates: 92,782
Cumulative Timesteps: 773,707,804

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 773707804...
Checkpoint 773707804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,674.97349
Policy Entropy: 3.70032
Value Function Loss: 0.05210

Mean KL Divergence: 0.01274
SB3 Clip Fraction: 0.16103
Policy Update Magnitude: 0.52279
Value Function Update Magnitude: 0.66984

Collected Steps per Second: 22,365.76827
Overall Steps per Second: 10,600.23834

Timestep Collection Time: 2.23619
Timestep Consumption Time: 2.48201
PPO Batch Consumption Time: 0.28955
Total Iteration Time: 4.71820

Cumulative Model Updates: 92,788
Cumulative Timesteps: 773,757,818

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 350,441.69298
Policy Entropy: 3.66021
Value Function Loss: 0.05922

Mean KL Divergence: 0.01307
SB3 Clip Fraction: 0.16419
Policy Update Magnitude: 0.52278
Value Function Update Magnitude: 0.56330

Collected Steps per Second: 22,331.58497
Overall Steps per Second: 10,548.32301

Timestep Collection Time: 2.23997
Timestep Consumption Time: 2.50221
PPO Batch Consumption Time: 0.29188
Total Iteration Time: 4.74218

Cumulative Model Updates: 92,794
Cumulative Timesteps: 773,807,840

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 773807840...
Checkpoint 773807840 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 64,104.83162
Policy Entropy: 3.62126
Value Function Loss: 0.06728

Mean KL Divergence: 0.01254
SB3 Clip Fraction: 0.15198
Policy Update Magnitude: 0.52811
Value Function Update Magnitude: 0.47348

Collected Steps per Second: 21,965.95422
Overall Steps per Second: 10,488.36725

Timestep Collection Time: 2.27725
Timestep Consumption Time: 2.49203
PPO Batch Consumption Time: 0.28699
Total Iteration Time: 4.76928

Cumulative Model Updates: 92,800
Cumulative Timesteps: 773,857,862

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53,971.25601
Policy Entropy: 3.60685
Value Function Loss: 0.07137

Mean KL Divergence: 0.01120
SB3 Clip Fraction: 0.14079
Policy Update Magnitude: 0.52134
Value Function Update Magnitude: 0.43011

Collected Steps per Second: 21,912.73217
Overall Steps per Second: 10,597.24805

Timestep Collection Time: 2.28351
Timestep Consumption Time: 2.43828
PPO Batch Consumption Time: 0.29204
Total Iteration Time: 4.72179

Cumulative Model Updates: 92,806
Cumulative Timesteps: 773,907,900

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 773907900...
Checkpoint 773907900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,375.48683
Policy Entropy: 3.60811
Value Function Loss: 0.06923

Mean KL Divergence: 0.01144
SB3 Clip Fraction: 0.14574
Policy Update Magnitude: 0.49001
Value Function Update Magnitude: 0.40774

Collected Steps per Second: 22,183.96161
Overall Steps per Second: 10,618.10460

Timestep Collection Time: 2.25442
Timestep Consumption Time: 2.45565
PPO Batch Consumption Time: 0.29259
Total Iteration Time: 4.71007

Cumulative Model Updates: 92,812
Cumulative Timesteps: 773,957,912

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,375.48683
Policy Entropy: 3.62382
Value Function Loss: 0.05918

Mean KL Divergence: 0.01127
SB3 Clip Fraction: 0.14245
Policy Update Magnitude: 0.51203
Value Function Update Magnitude: 0.39056

Collected Steps per Second: 21,638.10033
Overall Steps per Second: 10,265.83892

Timestep Collection Time: 2.31139
Timestep Consumption Time: 2.56050
PPO Batch Consumption Time: 0.29198
Total Iteration Time: 4.87189

Cumulative Model Updates: 92,818
Cumulative Timesteps: 774,007,926

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 774007926...
Checkpoint 774007926 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,375.48683
Policy Entropy: 3.63042
Value Function Loss: 0.04664

Mean KL Divergence: 0.01119
SB3 Clip Fraction: 0.14504
Policy Update Magnitude: 0.50263
Value Function Update Magnitude: 0.38465

Collected Steps per Second: 22,176.65167
Overall Steps per Second: 10,700.50973

Timestep Collection Time: 2.25462
Timestep Consumption Time: 2.41805
PPO Batch Consumption Time: 0.28004
Total Iteration Time: 4.67267

Cumulative Model Updates: 92,824
Cumulative Timesteps: 774,057,926

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,375.48683
Policy Entropy: 3.64661
Value Function Loss: 0.03533

Mean KL Divergence: 0.01092
SB3 Clip Fraction: 0.14580
Policy Update Magnitude: 0.44080
Value Function Update Magnitude: 0.35396

Collected Steps per Second: 23,020.19276
Overall Steps per Second: 10,899.52395

Timestep Collection Time: 2.17218
Timestep Consumption Time: 2.41554
PPO Batch Consumption Time: 0.27939
Total Iteration Time: 4.58772

Cumulative Model Updates: 92,830
Cumulative Timesteps: 774,107,930

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 774107930...
Checkpoint 774107930 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,375.48683
Policy Entropy: 3.63948
Value Function Loss: 0.02998

Mean KL Divergence: 0.01050
SB3 Clip Fraction: 0.14052
Policy Update Magnitude: 0.39008
Value Function Update Magnitude: 0.33070

Collected Steps per Second: 22,864.96013
Overall Steps per Second: 10,822.12758

Timestep Collection Time: 2.18798
Timestep Consumption Time: 2.43477
PPO Batch Consumption Time: 0.27726
Total Iteration Time: 4.62275

Cumulative Model Updates: 92,836
Cumulative Timesteps: 774,157,958

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,574.42156
Policy Entropy: 3.63883
Value Function Loss: 0.03197

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.13604
Policy Update Magnitude: 0.36850
Value Function Update Magnitude: 0.30108

Collected Steps per Second: 22,519.90817
Overall Steps per Second: 10,601.85310

Timestep Collection Time: 2.22266
Timestep Consumption Time: 2.49859
PPO Batch Consumption Time: 0.28878
Total Iteration Time: 4.72125

Cumulative Model Updates: 92,842
Cumulative Timesteps: 774,208,012

Timesteps Collected: 50,054
--------END ITERATION REPORT--------


Saving checkpoint 774208012...
Checkpoint 774208012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,747.58624
Policy Entropy: 3.64981
Value Function Loss: 0.03353

Mean KL Divergence: 0.01073
SB3 Clip Fraction: 0.14240
Policy Update Magnitude: 0.37654
Value Function Update Magnitude: 0.35825

Collected Steps per Second: 22,840.80776
Overall Steps per Second: 10,834.28713

Timestep Collection Time: 2.18915
Timestep Consumption Time: 2.42601
PPO Batch Consumption Time: 0.27881
Total Iteration Time: 4.61516

Cumulative Model Updates: 92,848
Cumulative Timesteps: 774,258,014

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,747.58624
Policy Entropy: 3.64549
Value Function Loss: 0.03634

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.13842
Policy Update Magnitude: 0.40822
Value Function Update Magnitude: 0.42181

Collected Steps per Second: 22,274.64970
Overall Steps per Second: 10,533.33115

Timestep Collection Time: 2.24479
Timestep Consumption Time: 2.50223
PPO Batch Consumption Time: 0.28974
Total Iteration Time: 4.74703

Cumulative Model Updates: 92,854
Cumulative Timesteps: 774,308,016

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 774308016...
Checkpoint 774308016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,747.58624
Policy Entropy: 3.64293
Value Function Loss: 0.03384

Mean KL Divergence: 0.01118
SB3 Clip Fraction: 0.15464
Policy Update Magnitude: 0.38945
Value Function Update Magnitude: 0.42813

Collected Steps per Second: 22,474.87021
Overall Steps per Second: 10,583.31260

Timestep Collection Time: 2.22586
Timestep Consumption Time: 2.50101
PPO Batch Consumption Time: 0.28476
Total Iteration Time: 4.72688

Cumulative Model Updates: 92,860
Cumulative Timesteps: 774,358,042

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,747.58624
Policy Entropy: 3.64198
Value Function Loss: 0.03157

Mean KL Divergence: 0.01104
SB3 Clip Fraction: 0.15357
Policy Update Magnitude: 0.34926
Value Function Update Magnitude: 0.37980

Collected Steps per Second: 22,190.74664
Overall Steps per Second: 10,535.31933

Timestep Collection Time: 2.25409
Timestep Consumption Time: 2.49375
PPO Batch Consumption Time: 0.28856
Total Iteration Time: 4.74784

Cumulative Model Updates: 92,866
Cumulative Timesteps: 774,408,062

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 774408062...
Checkpoint 774408062 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 67,702.37822
Policy Entropy: 3.63621
Value Function Loss: 0.03163

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.14562
Policy Update Magnitude: 0.31871
Value Function Update Magnitude: 0.33972

Collected Steps per Second: 22,339.63918
Overall Steps per Second: 10,603.16253

Timestep Collection Time: 2.23844
Timestep Consumption Time: 2.47770
PPO Batch Consumption Time: 0.28564
Total Iteration Time: 4.71614

Cumulative Model Updates: 92,872
Cumulative Timesteps: 774,458,068

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67,702.37822
Policy Entropy: 3.62514
Value Function Loss: 0.03350

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.14490
Policy Update Magnitude: 0.32142
Value Function Update Magnitude: 0.35439

Collected Steps per Second: 22,881.95302
Overall Steps per Second: 10,627.07114

Timestep Collection Time: 2.18574
Timestep Consumption Time: 2.52054
PPO Batch Consumption Time: 0.29069
Total Iteration Time: 4.70628

Cumulative Model Updates: 92,878
Cumulative Timesteps: 774,508,082

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 774508082...
Checkpoint 774508082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 67,702.37822
Policy Entropy: 3.63289
Value Function Loss: 0.03597

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.14376
Policy Update Magnitude: 0.33355
Value Function Update Magnitude: 0.36386

Collected Steps per Second: 23,081.44223
Overall Steps per Second: 10,844.91800

Timestep Collection Time: 2.16668
Timestep Consumption Time: 2.44470
PPO Batch Consumption Time: 0.27929
Total Iteration Time: 4.61138

Cumulative Model Updates: 92,884
Cumulative Timesteps: 774,558,092

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 247,445.52702
Policy Entropy: 3.65026
Value Function Loss: 0.03740

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.14308
Policy Update Magnitude: 0.37354
Value Function Update Magnitude: 0.39342

Collected Steps per Second: 21,924.30324
Overall Steps per Second: 10,588.84188

Timestep Collection Time: 2.28103
Timestep Consumption Time: 2.44187
PPO Batch Consumption Time: 0.29389
Total Iteration Time: 4.72290

Cumulative Model Updates: 92,890
Cumulative Timesteps: 774,608,102

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 774608102...
Checkpoint 774608102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 131,513.48890
Policy Entropy: 3.66173
Value Function Loss: 0.03637

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.13920
Policy Update Magnitude: 0.38924
Value Function Update Magnitude: 0.51486

Collected Steps per Second: 21,652.09305
Overall Steps per Second: 10,590.53867

Timestep Collection Time: 2.31008
Timestep Consumption Time: 2.41282
PPO Batch Consumption Time: 0.28718
Total Iteration Time: 4.72289

Cumulative Model Updates: 92,896
Cumulative Timesteps: 774,658,120

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 131,513.48890
Policy Entropy: 3.66269
Value Function Loss: 0.03389

Mean KL Divergence: 0.01101
SB3 Clip Fraction: 0.15159
Policy Update Magnitude: 0.37157
Value Function Update Magnitude: 0.53024

Collected Steps per Second: 22,028.29297
Overall Steps per Second: 10,476.17400

Timestep Collection Time: 2.27099
Timestep Consumption Time: 2.50423
PPO Batch Consumption Time: 0.29379
Total Iteration Time: 4.77522

Cumulative Model Updates: 92,902
Cumulative Timesteps: 774,708,146

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 774708146...
Checkpoint 774708146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 131,513.48890
Policy Entropy: 3.66103
Value Function Loss: 0.03052

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.14712
Policy Update Magnitude: 0.36090
Value Function Update Magnitude: 0.51411

Collected Steps per Second: 22,537.41633
Overall Steps per Second: 10,632.68946

Timestep Collection Time: 2.21871
Timestep Consumption Time: 2.48414
PPO Batch Consumption Time: 0.29163
Total Iteration Time: 4.70286

Cumulative Model Updates: 92,908
Cumulative Timesteps: 774,758,150

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 131,513.48890
Policy Entropy: 3.65374
Value Function Loss: 0.02977

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.14642
Policy Update Magnitude: 0.35872
Value Function Update Magnitude: 0.47094

Collected Steps per Second: 22,518.15285
Overall Steps per Second: 10,551.51448

Timestep Collection Time: 2.22150
Timestep Consumption Time: 2.51943
PPO Batch Consumption Time: 0.29283
Total Iteration Time: 4.74093

Cumulative Model Updates: 92,914
Cumulative Timesteps: 774,808,174

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 774808174...
Checkpoint 774808174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 127,476.50884
Policy Entropy: 3.64259
Value Function Loss: 0.03139

Mean KL Divergence: 0.01142
SB3 Clip Fraction: 0.15326
Policy Update Magnitude: 0.34067
Value Function Update Magnitude: 0.50632

Collected Steps per Second: 22,001.11497
Overall Steps per Second: 10,543.88897

Timestep Collection Time: 2.27270
Timestep Consumption Time: 2.46957
PPO Batch Consumption Time: 0.28564
Total Iteration Time: 4.74227

Cumulative Model Updates: 92,920
Cumulative Timesteps: 774,858,176

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 154,005.26690
Policy Entropy: 3.63400
Value Function Loss: 0.03906

Mean KL Divergence: 0.01129
SB3 Clip Fraction: 0.14937
Policy Update Magnitude: 0.36143
Value Function Update Magnitude: 0.61894

Collected Steps per Second: 22,327.60830
Overall Steps per Second: 10,541.75604

Timestep Collection Time: 2.23983
Timestep Consumption Time: 2.50416
PPO Batch Consumption Time: 0.29317
Total Iteration Time: 4.74399

Cumulative Model Updates: 92,926
Cumulative Timesteps: 774,908,186

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 774908186...
Checkpoint 774908186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 53,612.47663
Policy Entropy: 3.63926
Value Function Loss: 0.04200

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.14168
Policy Update Magnitude: 0.42591
Value Function Update Magnitude: 0.60980

Collected Steps per Second: 22,373.93368
Overall Steps per Second: 10,713.89676

Timestep Collection Time: 2.23537
Timestep Consumption Time: 2.43277
PPO Batch Consumption Time: 0.27900
Total Iteration Time: 4.66814

Cumulative Model Updates: 92,932
Cumulative Timesteps: 774,958,200

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,392.78290
Policy Entropy: 3.64989
Value Function Loss: 0.04612

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.13556
Policy Update Magnitude: 0.48077
Value Function Update Magnitude: 0.55258

Collected Steps per Second: 22,335.88460
Overall Steps per Second: 10,323.49156

Timestep Collection Time: 2.23909
Timestep Consumption Time: 2.60540
PPO Batch Consumption Time: 0.30539
Total Iteration Time: 4.84449

Cumulative Model Updates: 92,938
Cumulative Timesteps: 775,008,212

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 775008212...
Checkpoint 775008212 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,074.04326
Policy Entropy: 3.65266
Value Function Loss: 0.03876

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.13822
Policy Update Magnitude: 0.48411
Value Function Update Magnitude: 0.55631

Collected Steps per Second: 22,459.62878
Overall Steps per Second: 10,549.55618

Timestep Collection Time: 2.22755
Timestep Consumption Time: 2.51483
PPO Batch Consumption Time: 0.29002
Total Iteration Time: 4.74238

Cumulative Model Updates: 92,944
Cumulative Timesteps: 775,058,242

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208,183.92420
Policy Entropy: 3.65145
Value Function Loss: 0.03672

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.13978
Policy Update Magnitude: 0.45572
Value Function Update Magnitude: 0.53084

Collected Steps per Second: 22,792.70590
Overall Steps per Second: 10,737.63484

Timestep Collection Time: 2.19377
Timestep Consumption Time: 2.46293
PPO Batch Consumption Time: 0.27833
Total Iteration Time: 4.65671

Cumulative Model Updates: 92,950
Cumulative Timesteps: 775,108,244

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 775108244...
Checkpoint 775108244 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 110,652.68466
Policy Entropy: 3.64319
Value Function Loss: 0.03501

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.13561
Policy Update Magnitude: 0.45221
Value Function Update Magnitude: 0.51585

Collected Steps per Second: 21,823.93090
Overall Steps per Second: 10,647.27993

Timestep Collection Time: 2.29134
Timestep Consumption Time: 2.40526
PPO Batch Consumption Time: 0.28361
Total Iteration Time: 4.69660

Cumulative Model Updates: 92,956
Cumulative Timesteps: 775,158,250

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91,109.23827
Policy Entropy: 3.63647
Value Function Loss: 0.04295

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.13443
Policy Update Magnitude: 0.48602
Value Function Update Magnitude: 0.49756

Collected Steps per Second: 22,013.31355
Overall Steps per Second: 10,602.03290

Timestep Collection Time: 2.27163
Timestep Consumption Time: 2.44502
PPO Batch Consumption Time: 0.29367
Total Iteration Time: 4.71664

Cumulative Model Updates: 92,962
Cumulative Timesteps: 775,208,256

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 775208256...
Checkpoint 775208256 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 142,174.06285
Policy Entropy: 3.63345
Value Function Loss: 0.04124

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.14198
Policy Update Magnitude: 0.51870
Value Function Update Magnitude: 0.50435

Collected Steps per Second: 22,222.32883
Overall Steps per Second: 10,716.45006

Timestep Collection Time: 2.25134
Timestep Consumption Time: 2.41718
PPO Batch Consumption Time: 0.29108
Total Iteration Time: 4.66852

Cumulative Model Updates: 92,968
Cumulative Timesteps: 775,258,286

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 115,166.61763
Policy Entropy: 3.62437
Value Function Loss: 0.05495

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.14640
Policy Update Magnitude: 0.52420
Value Function Update Magnitude: 0.48436

Collected Steps per Second: 22,255.04642
Overall Steps per Second: 10,739.73843

Timestep Collection Time: 2.24902
Timestep Consumption Time: 2.41143
PPO Batch Consumption Time: 0.27918
Total Iteration Time: 4.66045

Cumulative Model Updates: 92,974
Cumulative Timesteps: 775,308,338

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


Saving checkpoint 775308338...
Checkpoint 775308338 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 115,166.61763
Policy Entropy: 3.64212
Value Function Loss: 0.04014

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.13873
Policy Update Magnitude: 0.48306
Value Function Update Magnitude: 0.50692

Collected Steps per Second: 21,566.56143
Overall Steps per Second: 10,580.29451

Timestep Collection Time: 2.31970
Timestep Consumption Time: 2.40871
PPO Batch Consumption Time: 0.27934
Total Iteration Time: 4.72841

Cumulative Model Updates: 92,980
Cumulative Timesteps: 775,358,366

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 115,166.61763
Policy Entropy: 3.64108
Value Function Loss: 0.04063

Mean KL Divergence: 0.01108
SB3 Clip Fraction: 0.14616
Policy Update Magnitude: 0.47686
Value Function Update Magnitude: 0.54204

Collected Steps per Second: 22,378.78664
Overall Steps per Second: 10,528.29815

Timestep Collection Time: 2.23533
Timestep Consumption Time: 2.51605
PPO Batch Consumption Time: 0.28784
Total Iteration Time: 4.75139

Cumulative Model Updates: 92,986
Cumulative Timesteps: 775,408,390

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 775408390...
Checkpoint 775408390 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 153,453.75298
Policy Entropy: 3.64129
Value Function Loss: 0.03764

Mean KL Divergence: 0.01067
SB3 Clip Fraction: 0.14413
Policy Update Magnitude: 0.43963
Value Function Update Magnitude: 0.44735

Collected Steps per Second: 22,452.08546
Overall Steps per Second: 10,758.78897

Timestep Collection Time: 2.22705
Timestep Consumption Time: 2.42050
PPO Batch Consumption Time: 0.27763
Total Iteration Time: 4.64755

Cumulative Model Updates: 92,992
Cumulative Timesteps: 775,458,392

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 325,198.91291
Policy Entropy: 3.62920
Value Function Loss: 0.04000

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.14372
Policy Update Magnitude: 0.42344
Value Function Update Magnitude: 0.43279

Collected Steps per Second: 22,257.50383
Overall Steps per Second: 9,243.00748

Timestep Collection Time: 2.24643
Timestep Consumption Time: 3.16306
PPO Batch Consumption Time: 0.31826
Total Iteration Time: 5.40949

Cumulative Model Updates: 92,998
Cumulative Timesteps: 775,508,392

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 775508392...
Checkpoint 775508392 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 140,009.23672
Policy Entropy: 3.63094
Value Function Loss: 0.04184

Mean KL Divergence: 0.01081
SB3 Clip Fraction: 0.14615
Policy Update Magnitude: 0.45363
Value Function Update Magnitude: 0.47036

Collected Steps per Second: 22,051.37789
Overall Steps per Second: 10,567.09529

Timestep Collection Time: 2.26761
Timestep Consumption Time: 2.46443
PPO Batch Consumption Time: 0.28329
Total Iteration Time: 4.73205

Cumulative Model Updates: 93,004
Cumulative Timesteps: 775,558,396

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 128,951.70294
Policy Entropy: 3.63573
Value Function Loss: 0.04766

Mean KL Divergence: 0.01053
SB3 Clip Fraction: 0.14049
Policy Update Magnitude: 0.50388
Value Function Update Magnitude: 0.50186

Collected Steps per Second: 21,611.98849
Overall Steps per Second: 10,392.59756

Timestep Collection Time: 2.31409
Timestep Consumption Time: 2.49819
PPO Batch Consumption Time: 0.28410
Total Iteration Time: 4.81227

Cumulative Model Updates: 93,010
Cumulative Timesteps: 775,608,408

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 775608408...
Checkpoint 775608408 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 104,456.54654
Policy Entropy: 3.65400
Value Function Loss: 0.04338

Mean KL Divergence: 0.01108
SB3 Clip Fraction: 0.14403
Policy Update Magnitude: 0.55472
Value Function Update Magnitude: 0.50717

Collected Steps per Second: 22,290.57472
Overall Steps per Second: 10,421.75757

Timestep Collection Time: 2.24373
Timestep Consumption Time: 2.55527
PPO Batch Consumption Time: 0.29375
Total Iteration Time: 4.79900

Cumulative Model Updates: 93,016
Cumulative Timesteps: 775,658,422

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 104,456.54654
Policy Entropy: 3.64906
Value Function Loss: 0.04186

Mean KL Divergence: 0.01234
SB3 Clip Fraction: 0.15767
Policy Update Magnitude: 0.56516
Value Function Update Magnitude: 0.52715

Collected Steps per Second: 22,290.90166
Overall Steps per Second: 10,436.27421

Timestep Collection Time: 2.24531
Timestep Consumption Time: 2.55046
PPO Batch Consumption Time: 0.29488
Total Iteration Time: 4.79577

Cumulative Model Updates: 93,022
Cumulative Timesteps: 775,708,472

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 775708472...
Checkpoint 775708472 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 104,456.54654
Policy Entropy: 3.65753
Value Function Loss: 0.03498

Mean KL Divergence: 0.01582
SB3 Clip Fraction: 0.18276
Policy Update Magnitude: 0.50762
Value Function Update Magnitude: 0.44196

Collected Steps per Second: 21,718.34976
Overall Steps per Second: 10,498.07856

Timestep Collection Time: 2.30450
Timestep Consumption Time: 2.46304
PPO Batch Consumption Time: 0.29440
Total Iteration Time: 4.76754

Cumulative Model Updates: 93,028
Cumulative Timesteps: 775,758,522

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 104,456.54654
Policy Entropy: 3.66301
Value Function Loss: 0.03338

Mean KL Divergence: 0.01272
SB3 Clip Fraction: 0.16323
Policy Update Magnitude: 0.53470
Value Function Update Magnitude: 0.43308

Collected Steps per Second: 21,568.57484
Overall Steps per Second: 10,264.70001

Timestep Collection Time: 2.31828
Timestep Consumption Time: 2.55298
PPO Batch Consumption Time: 0.30266
Total Iteration Time: 4.87126

Cumulative Model Updates: 93,034
Cumulative Timesteps: 775,808,524

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 775808524...
Checkpoint 775808524 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 536,776.33895
Policy Entropy: 3.66533
Value Function Loss: 0.04110

Mean KL Divergence: 0.01185
SB3 Clip Fraction: 0.15475
Policy Update Magnitude: 0.62908
Value Function Update Magnitude: 0.47474

Collected Steps per Second: 21,771.39849
Overall Steps per Second: 10,425.96210

Timestep Collection Time: 2.29760
Timestep Consumption Time: 2.50023
PPO Batch Consumption Time: 0.29488
Total Iteration Time: 4.79783

Cumulative Model Updates: 93,040
Cumulative Timesteps: 775,858,546

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 352,196.92129
Policy Entropy: 3.62917
Value Function Loss: 0.05458

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.12233
Policy Update Magnitude: 0.81083
Value Function Update Magnitude: 0.51589

Collected Steps per Second: 22,051.56363
Overall Steps per Second: 10,441.36941

Timestep Collection Time: 2.26759
Timestep Consumption Time: 2.52143
PPO Batch Consumption Time: 0.29459
Total Iteration Time: 4.78903

Cumulative Model Updates: 93,046
Cumulative Timesteps: 775,908,550

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 775908550...
Checkpoint 775908550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 670,011.24351
Policy Entropy: 3.60695
Value Function Loss: 0.06575

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.12649
Policy Update Magnitude: 0.93084
Value Function Update Magnitude: 0.50824

Collected Steps per Second: 21,540.30630
Overall Steps per Second: 10,387.03618

Timestep Collection Time: 2.32225
Timestep Consumption Time: 2.49356
PPO Batch Consumption Time: 0.29440
Total Iteration Time: 4.81581

Cumulative Model Updates: 93,052
Cumulative Timesteps: 775,958,572

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 503,938.98014
Policy Entropy: 3.61693
Value Function Loss: 0.06219

Mean KL Divergence: 0.01714
SB3 Clip Fraction: 0.20213
Policy Update Magnitude: 0.83665
Value Function Update Magnitude: 0.64984

Collected Steps per Second: 22,111.45319
Overall Steps per Second: 10,415.17410

Timestep Collection Time: 2.26136
Timestep Consumption Time: 2.53952
PPO Batch Consumption Time: 0.29429
Total Iteration Time: 4.80088

Cumulative Model Updates: 93,058
Cumulative Timesteps: 776,008,574

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 776008574...
Checkpoint 776008574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 503,938.98014
Policy Entropy: 3.66622
Value Function Loss: 0.04988

Mean KL Divergence: 0.01382
SB3 Clip Fraction: 0.16706
Policy Update Magnitude: 0.68864
Value Function Update Magnitude: 0.58370

Collected Steps per Second: 21,891.69168
Overall Steps per Second: 10,487.90572

Timestep Collection Time: 2.28443
Timestep Consumption Time: 2.48392
PPO Batch Consumption Time: 0.28272
Total Iteration Time: 4.76835

Cumulative Model Updates: 93,064
Cumulative Timesteps: 776,058,584

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 503,938.98014
Policy Entropy: 3.69286
Value Function Loss: 0.04091

Mean KL Divergence: 0.01169
SB3 Clip Fraction: 0.14975
Policy Update Magnitude: 0.58248
Value Function Update Magnitude: 0.64987

Collected Steps per Second: 20,961.47984
Overall Steps per Second: 10,076.73033

Timestep Collection Time: 2.38771
Timestep Consumption Time: 2.57918
PPO Batch Consumption Time: 0.29747
Total Iteration Time: 4.96689

Cumulative Model Updates: 93,070
Cumulative Timesteps: 776,108,634

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 776108634...
Checkpoint 776108634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 370,710.43078
Policy Entropy: 3.69121
Value Function Loss: 0.03672

Mean KL Divergence: 0.01210
SB3 Clip Fraction: 0.15290
Policy Update Magnitude: 0.58611
Value Function Update Magnitude: 0.60445

Collected Steps per Second: 21,587.68929
Overall Steps per Second: 10,332.60791

Timestep Collection Time: 2.31660
Timestep Consumption Time: 2.52342
PPO Batch Consumption Time: 0.29552
Total Iteration Time: 4.84002

Cumulative Model Updates: 93,076
Cumulative Timesteps: 776,158,644

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 300,278.26509
Policy Entropy: 3.68160
Value Function Loss: 0.03540

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.12440
Policy Update Magnitude: 0.59826
Value Function Update Magnitude: 0.53051

Collected Steps per Second: 21,934.15665
Overall Steps per Second: 10,377.98786

Timestep Collection Time: 2.28001
Timestep Consumption Time: 2.53885
PPO Batch Consumption Time: 0.29614
Total Iteration Time: 4.81885

Cumulative Model Updates: 93,082
Cumulative Timesteps: 776,208,654

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 776208654...
Checkpoint 776208654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 300,278.26509
Policy Entropy: 3.66791
Value Function Loss: 0.03259

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.10403
Policy Update Magnitude: 0.66080
Value Function Update Magnitude: 0.50625

Collected Steps per Second: 21,823.09386
Overall Steps per Second: 10,537.52677

Timestep Collection Time: 2.29225
Timestep Consumption Time: 2.45497
PPO Batch Consumption Time: 0.28254
Total Iteration Time: 4.74722

Cumulative Model Updates: 93,088
Cumulative Timesteps: 776,258,678

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 303,705.67575
Policy Entropy: 3.64601
Value Function Loss: 0.03326

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.11288
Policy Update Magnitude: 0.66265
Value Function Update Magnitude: 0.53150

Collected Steps per Second: 21,331.86849
Overall Steps per Second: 10,592.16161

Timestep Collection Time: 2.34400
Timestep Consumption Time: 2.37666
PPO Batch Consumption Time: 0.27961
Total Iteration Time: 4.72066

Cumulative Model Updates: 93,094
Cumulative Timesteps: 776,308,680

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 776308680...
Checkpoint 776308680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 303,705.67575
Policy Entropy: 3.63402
Value Function Loss: 0.04165

Mean KL Divergence: 0.01431
SB3 Clip Fraction: 0.17700
Policy Update Magnitude: 0.64360
Value Function Update Magnitude: 0.57806

Collected Steps per Second: 21,421.23718
Overall Steps per Second: 10,510.42661

Timestep Collection Time: 2.33581
Timestep Consumption Time: 2.42479
PPO Batch Consumption Time: 0.28568
Total Iteration Time: 4.76061

Cumulative Model Updates: 93,100
Cumulative Timesteps: 776,358,716

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 183,471.90836
Policy Entropy: 3.65351
Value Function Loss: 0.04514

Mean KL Divergence: 0.01143
SB3 Clip Fraction: 0.14280
Policy Update Magnitude: 0.70965
Value Function Update Magnitude: 0.64922

Collected Steps per Second: 21,331.49467
Overall Steps per Second: 10,129.68385

Timestep Collection Time: 2.34489
Timestep Consumption Time: 2.59307
PPO Batch Consumption Time: 0.30139
Total Iteration Time: 4.93796

Cumulative Model Updates: 93,106
Cumulative Timesteps: 776,408,736

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 776408736...
Checkpoint 776408736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 125,450.04273
Policy Entropy: 3.66276
Value Function Loss: 0.04603

Mean KL Divergence: 0.01382
SB3 Clip Fraction: 0.17285
Policy Update Magnitude: 0.62347
Value Function Update Magnitude: 0.67812

Collected Steps per Second: 22,170.55083
Overall Steps per Second: 10,455.56985

Timestep Collection Time: 2.25597
Timestep Consumption Time: 2.52770
PPO Batch Consumption Time: 0.29399
Total Iteration Time: 4.78367

Cumulative Model Updates: 93,112
Cumulative Timesteps: 776,458,752

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 125,450.04273
Policy Entropy: 3.68327
Value Function Loss: 0.03881

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.10976
Policy Update Magnitude: 0.61492
Value Function Update Magnitude: 0.66545

Collected Steps per Second: 22,396.30327
Overall Steps per Second: 10,615.09470

Timestep Collection Time: 2.23358
Timestep Consumption Time: 2.47895
PPO Batch Consumption Time: 0.28923
Total Iteration Time: 4.71253

Cumulative Model Updates: 93,118
Cumulative Timesteps: 776,508,776

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 776508776...
Checkpoint 776508776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 375,994.11421
Policy Entropy: 3.66225
Value Function Loss: 0.04440

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.13938
Policy Update Magnitude: 0.54954
Value Function Update Magnitude: 0.72964

Collected Steps per Second: 22,270.49549
Overall Steps per Second: 10,607.47479

Timestep Collection Time: 2.24647
Timestep Consumption Time: 2.47002
PPO Batch Consumption Time: 0.28319
Total Iteration Time: 4.71649

Cumulative Model Updates: 93,124
Cumulative Timesteps: 776,558,806

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 106,204.68564
Policy Entropy: 3.65170
Value Function Loss: 0.04363

Mean KL Divergence: 0.01319
SB3 Clip Fraction: 0.16287
Policy Update Magnitude: 0.53168
Value Function Update Magnitude: 0.58073

Collected Steps per Second: 22,293.79742
Overall Steps per Second: 10,455.33199

Timestep Collection Time: 2.24376
Timestep Consumption Time: 2.54059
PPO Batch Consumption Time: 0.29336
Total Iteration Time: 4.78435

Cumulative Model Updates: 93,130
Cumulative Timesteps: 776,608,828

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 776608828...
Checkpoint 776608828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 341,159.39764
Policy Entropy: 3.63149
Value Function Loss: 0.05475

Mean KL Divergence: 0.02807
SB3 Clip Fraction: 0.26933
Policy Update Magnitude: 0.46686
Value Function Update Magnitude: 0.52587

Collected Steps per Second: 22,179.92041
Overall Steps per Second: 10,616.90848

Timestep Collection Time: 2.25501
Timestep Consumption Time: 2.45596
PPO Batch Consumption Time: 0.28173
Total Iteration Time: 4.71098

Cumulative Model Updates: 93,136
Cumulative Timesteps: 776,658,844

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 304,017.14463
Policy Entropy: 3.62508
Value Function Loss: 0.05924

Mean KL Divergence: 0.01243
SB3 Clip Fraction: 0.15168
Policy Update Magnitude: 0.56483
Value Function Update Magnitude: 0.46633

Collected Steps per Second: 22,056.25359
Overall Steps per Second: 10,480.46821

Timestep Collection Time: 2.26802
Timestep Consumption Time: 2.50505
PPO Batch Consumption Time: 0.28953
Total Iteration Time: 4.77307

Cumulative Model Updates: 93,142
Cumulative Timesteps: 776,708,868

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 776708868...
Checkpoint 776708868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,963.07018
Policy Entropy: 3.65161
Value Function Loss: 0.06401

Mean KL Divergence: 0.01449
SB3 Clip Fraction: 0.17363
Policy Update Magnitude: 0.77500
Value Function Update Magnitude: 0.61288

Collected Steps per Second: 21,721.29920
Overall Steps per Second: 10,388.36913

Timestep Collection Time: 2.30299
Timestep Consumption Time: 2.51239
PPO Batch Consumption Time: 0.29465
Total Iteration Time: 4.81539

Cumulative Model Updates: 93,148
Cumulative Timesteps: 776,758,892

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 150,963.82683
Policy Entropy: 3.66800
Value Function Loss: 0.06650

Mean KL Divergence: 0.01517
SB3 Clip Fraction: 0.17803
Policy Update Magnitude: 0.68918
Value Function Update Magnitude: 0.60576

Collected Steps per Second: 21,823.14579
Overall Steps per Second: 10,328.27892

Timestep Collection Time: 2.29215
Timestep Consumption Time: 2.55105
PPO Batch Consumption Time: 0.29727
Total Iteration Time: 4.84321

Cumulative Model Updates: 93,154
Cumulative Timesteps: 776,808,914

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 776808914...
Checkpoint 776808914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 75,608.59030
Policy Entropy: 3.69906
Value Function Loss: 0.05611

Mean KL Divergence: 0.01271
SB3 Clip Fraction: 0.15654
Policy Update Magnitude: 0.60736
Value Function Update Magnitude: 0.62256

Collected Steps per Second: 21,733.01855
Overall Steps per Second: 10,535.43737

Timestep Collection Time: 2.30129
Timestep Consumption Time: 2.44593
PPO Batch Consumption Time: 0.28242
Total Iteration Time: 4.74722

Cumulative Model Updates: 93,160
Cumulative Timesteps: 776,858,928

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 204,423.64626
Policy Entropy: 3.65325
Value Function Loss: 0.06055

Mean KL Divergence: 0.01174
SB3 Clip Fraction: 0.14800
Policy Update Magnitude: 0.56200
Value Function Update Magnitude: 0.69829

Collected Steps per Second: 21,568.56989
Overall Steps per Second: 10,542.93991

Timestep Collection Time: 2.31986
Timestep Consumption Time: 2.42607
PPO Batch Consumption Time: 0.28750
Total Iteration Time: 4.74592

Cumulative Model Updates: 93,166
Cumulative Timesteps: 776,908,964

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 776908964...
Checkpoint 776908964 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 165,587.48462
Policy Entropy: 3.64502
Value Function Loss: 0.05831

Mean KL Divergence: 0.01107
SB3 Clip Fraction: 0.13952
Policy Update Magnitude: 0.61455
Value Function Update Magnitude: 0.74644

Collected Steps per Second: 21,698.54932
Overall Steps per Second: 10,609.98570

Timestep Collection Time: 2.30467
Timestep Consumption Time: 2.40863
PPO Batch Consumption Time: 0.28243
Total Iteration Time: 4.71330

Cumulative Model Updates: 93,172
Cumulative Timesteps: 776,958,972

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 191,748.00128
Policy Entropy: 3.63407
Value Function Loss: 0.05995

Mean KL Divergence: 0.01239
SB3 Clip Fraction: 0.15575
Policy Update Magnitude: 0.61492
Value Function Update Magnitude: 0.67128

Collected Steps per Second: 21,225.01289
Overall Steps per Second: 10,403.43535

Timestep Collection Time: 2.35646
Timestep Consumption Time: 2.45118
PPO Batch Consumption Time: 0.28291
Total Iteration Time: 4.80764

Cumulative Model Updates: 93,178
Cumulative Timesteps: 777,008,988

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 777008988...
Checkpoint 777008988 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,028.67750
Policy Entropy: 3.68863
Value Function Loss: 0.05467

Mean KL Divergence: 0.01066
SB3 Clip Fraction: 0.14137
Policy Update Magnitude: 0.61080
Value Function Update Magnitude: 0.56545

Collected Steps per Second: 22,208.78235
Overall Steps per Second: 10,652.07041

Timestep Collection Time: 2.25316
Timestep Consumption Time: 2.44452
PPO Batch Consumption Time: 0.28266
Total Iteration Time: 4.69768

Cumulative Model Updates: 93,184
Cumulative Timesteps: 777,059,028

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 714.73429
Policy Entropy: 3.70812
Value Function Loss: 0.06529

Mean KL Divergence: 0.01133
SB3 Clip Fraction: 0.14727
Policy Update Magnitude: 0.56906
Value Function Update Magnitude: 0.53824

Collected Steps per Second: 22,058.20301
Overall Steps per Second: 10,549.88529

Timestep Collection Time: 2.26682
Timestep Consumption Time: 2.47276
PPO Batch Consumption Time: 0.28793
Total Iteration Time: 4.73958

Cumulative Model Updates: 93,190
Cumulative Timesteps: 777,109,030

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 777109030...
Checkpoint 777109030 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 179.24846
Policy Entropy: 3.72911
Value Function Loss: 0.04896

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.13646
Policy Update Magnitude: 0.55654
Value Function Update Magnitude: 0.56606

Collected Steps per Second: 22,332.18675
Overall Steps per Second: 10,655.16253

Timestep Collection Time: 2.23937
Timestep Consumption Time: 2.45413
PPO Batch Consumption Time: 0.28176
Total Iteration Time: 4.69350

Cumulative Model Updates: 93,196
Cumulative Timesteps: 777,159,040

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,649.86189
Policy Entropy: 3.70348
Value Function Loss: 0.04798

Mean KL Divergence: 0.01157
SB3 Clip Fraction: 0.15203
Policy Update Magnitude: 0.52790
Value Function Update Magnitude: 0.60107

Collected Steps per Second: 22,433.57848
Overall Steps per Second: 10,461.50020

Timestep Collection Time: 2.22898
Timestep Consumption Time: 2.55083
PPO Batch Consumption Time: 0.29657
Total Iteration Time: 4.77981

Cumulative Model Updates: 93,202
Cumulative Timesteps: 777,209,044

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 777209044...
Checkpoint 777209044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,116.98299
Policy Entropy: 3.68642
Value Function Loss: 0.05089

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.13645
Policy Update Magnitude: 0.50466
Value Function Update Magnitude: 0.62265

Collected Steps per Second: 21,917.88648
Overall Steps per Second: 10,597.48945

Timestep Collection Time: 2.28243
Timestep Consumption Time: 2.43812
PPO Batch Consumption Time: 0.28386
Total Iteration Time: 4.72055

Cumulative Model Updates: 93,208
Cumulative Timesteps: 777,259,070

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,899.96774
Policy Entropy: 3.68556
Value Function Loss: 0.05149

Mean KL Divergence: 0.01095
SB3 Clip Fraction: 0.14781
Policy Update Magnitude: 0.54738
Value Function Update Magnitude: 0.65072

Collected Steps per Second: 21,839.82700
Overall Steps per Second: 10,523.88963

Timestep Collection Time: 2.28949
Timestep Consumption Time: 2.46180
PPO Batch Consumption Time: 0.28043
Total Iteration Time: 4.75129

Cumulative Model Updates: 93,214
Cumulative Timesteps: 777,309,072

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 777309072...
Checkpoint 777309072 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 369,661.37246
Policy Entropy: 3.68870
Value Function Loss: 0.05866

Mean KL Divergence: 0.01055
SB3 Clip Fraction: 0.14146
Policy Update Magnitude: 0.54134
Value Function Update Magnitude: 0.57652

Collected Steps per Second: 21,798.08535
Overall Steps per Second: 10,499.65846

Timestep Collection Time: 2.29461
Timestep Consumption Time: 2.46917
PPO Batch Consumption Time: 0.28292
Total Iteration Time: 4.76377

Cumulative Model Updates: 93,220
Cumulative Timesteps: 777,359,090

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,517.86511
Policy Entropy: 3.72629
Value Function Loss: 0.05695

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.13749
Policy Update Magnitude: 0.54169
Value Function Update Magnitude: 0.73909

Collected Steps per Second: 22,325.80896
Overall Steps per Second: 10,536.92648

Timestep Collection Time: 2.24010
Timestep Consumption Time: 2.50626
PPO Batch Consumption Time: 0.28812
Total Iteration Time: 4.74636

Cumulative Model Updates: 93,226
Cumulative Timesteps: 777,409,102

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 777409102...
Checkpoint 777409102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,817.38667
Policy Entropy: 3.72314
Value Function Loss: 0.06595

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.14673
Policy Update Magnitude: 0.57227
Value Function Update Magnitude: 0.75312

Collected Steps per Second: 21,614.25656
Overall Steps per Second: 10,301.28626

Timestep Collection Time: 2.31421
Timestep Consumption Time: 2.54149
PPO Batch Consumption Time: 0.29627
Total Iteration Time: 4.85570

Cumulative Model Updates: 93,232
Cumulative Timesteps: 777,459,122

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,259.39566
Policy Entropy: 3.72573
Value Function Loss: 0.05913

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.14341
Policy Update Magnitude: 0.57539
Value Function Update Magnitude: 0.73406

Collected Steps per Second: 22,382.32749
Overall Steps per Second: 10,404.18706

Timestep Collection Time: 2.23391
Timestep Consumption Time: 2.57185
PPO Batch Consumption Time: 0.29679
Total Iteration Time: 4.80576

Cumulative Model Updates: 93,238
Cumulative Timesteps: 777,509,122

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 777509122...
Checkpoint 777509122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 51,684.73655
Policy Entropy: 3.68932
Value Function Loss: 0.05591

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.14143
Policy Update Magnitude: 0.52732
Value Function Update Magnitude: 0.73839

Collected Steps per Second: 22,238.14267
Overall Steps per Second: 10,541.30737

Timestep Collection Time: 2.24938
Timestep Consumption Time: 2.49595
PPO Batch Consumption Time: 0.28340
Total Iteration Time: 4.74533

Cumulative Model Updates: 93,244
Cumulative Timesteps: 777,559,144

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,885.63268
Policy Entropy: 3.69300
Value Function Loss: 0.05059

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.14013
Policy Update Magnitude: 0.48993
Value Function Update Magnitude: 0.75849

Collected Steps per Second: 22,279.37661
Overall Steps per Second: 10,501.12577

Timestep Collection Time: 2.24557
Timestep Consumption Time: 2.51868
PPO Batch Consumption Time: 0.29068
Total Iteration Time: 4.76425

Cumulative Model Updates: 93,250
Cumulative Timesteps: 777,609,174

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 777609174...
Checkpoint 777609174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 80,533.69776
Policy Entropy: 3.67614
Value Function Loss: 0.04750

Mean KL Divergence: 0.01097
SB3 Clip Fraction: 0.14612
Policy Update Magnitude: 0.45463
Value Function Update Magnitude: 0.66191

Collected Steps per Second: 22,483.41767
Overall Steps per Second: 10,625.73677

Timestep Collection Time: 2.22404
Timestep Consumption Time: 2.48189
PPO Batch Consumption Time: 0.28267
Total Iteration Time: 4.70593

Cumulative Model Updates: 93,256
Cumulative Timesteps: 777,659,178

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 124,780.65966
Policy Entropy: 3.70365
Value Function Loss: 0.04215

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.13541
Policy Update Magnitude: 0.43656
Value Function Update Magnitude: 0.74810

Collected Steps per Second: 22,622.26916
Overall Steps per Second: 10,473.72027

Timestep Collection Time: 2.21101
Timestep Consumption Time: 2.56456
PPO Batch Consumption Time: 0.29627
Total Iteration Time: 4.77557

Cumulative Model Updates: 93,262
Cumulative Timesteps: 777,709,196

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 777709196...
Checkpoint 777709196 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 58,865.21090
Policy Entropy: 3.69797
Value Function Loss: 0.04631

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.14260
Policy Update Magnitude: 0.42910
Value Function Update Magnitude: 0.76429

Collected Steps per Second: 22,265.85066
Overall Steps per Second: 10,603.86129

Timestep Collection Time: 2.24568
Timestep Consumption Time: 2.46977
PPO Batch Consumption Time: 0.28377
Total Iteration Time: 4.71545

Cumulative Model Updates: 93,268
Cumulative Timesteps: 777,759,198

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,817.52987
Policy Entropy: 3.71190
Value Function Loss: 0.04895

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.13986
Policy Update Magnitude: 0.48244
Value Function Update Magnitude: 0.68196

Collected Steps per Second: 22,108.03548
Overall Steps per Second: 10,479.77703

Timestep Collection Time: 2.26271
Timestep Consumption Time: 2.51068
PPO Batch Consumption Time: 0.29315
Total Iteration Time: 4.77338

Cumulative Model Updates: 93,274
Cumulative Timesteps: 777,809,222

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 777809222...
Checkpoint 777809222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 51,227.19072
Policy Entropy: 3.68820
Value Function Loss: 0.04644

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.14248
Policy Update Magnitude: 0.45144
Value Function Update Magnitude: 0.60233

Collected Steps per Second: 21,944.87821
Overall Steps per Second: 10,365.92670

Timestep Collection Time: 2.28044
Timestep Consumption Time: 2.54730
PPO Batch Consumption Time: 0.29684
Total Iteration Time: 4.82774

Cumulative Model Updates: 93,280
Cumulative Timesteps: 777,859,266

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51,227.19072
Policy Entropy: 3.67822
Value Function Loss: 0.03923

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.13886
Policy Update Magnitude: 0.44838
Value Function Update Magnitude: 0.60595

Collected Steps per Second: 21,886.51754
Overall Steps per Second: 10,357.97609

Timestep Collection Time: 2.28570
Timestep Consumption Time: 2.54401
PPO Batch Consumption Time: 0.29576
Total Iteration Time: 4.82971

Cumulative Model Updates: 93,286
Cumulative Timesteps: 777,909,292

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 777909292...
Checkpoint 777909292 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89,225.85116
Policy Entropy: 3.67337
Value Function Loss: 0.03780

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.14259
Policy Update Magnitude: 0.45029
Value Function Update Magnitude: 0.56007

Collected Steps per Second: 22,017.05071
Overall Steps per Second: 10,557.61233

Timestep Collection Time: 2.27097
Timestep Consumption Time: 2.46495
PPO Batch Consumption Time: 0.28237
Total Iteration Time: 4.73592

Cumulative Model Updates: 93,292
Cumulative Timesteps: 777,959,292

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85,809.10357
Policy Entropy: 3.66690
Value Function Loss: 0.04600

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.13516
Policy Update Magnitude: 0.44740
Value Function Update Magnitude: 0.54025

Collected Steps per Second: 21,488.86893
Overall Steps per Second: 10,415.73328

Timestep Collection Time: 2.32818
Timestep Consumption Time: 2.47513
PPO Batch Consumption Time: 0.28366
Total Iteration Time: 4.80331

Cumulative Model Updates: 93,298
Cumulative Timesteps: 778,009,322

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 778009322...
Checkpoint 778009322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 69,034.03019
Policy Entropy: 3.66755
Value Function Loss: 0.04969

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.13996
Policy Update Magnitude: 0.44098
Value Function Update Magnitude: 0.41090

Collected Steps per Second: 22,088.69335
Overall Steps per Second: 10,377.35736

Timestep Collection Time: 2.26478
Timestep Consumption Time: 2.55591
PPO Batch Consumption Time: 0.29808
Total Iteration Time: 4.82069

Cumulative Model Updates: 93,304
Cumulative Timesteps: 778,059,348

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,575.85790
Policy Entropy: 3.67295
Value Function Loss: 0.05166

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.13846
Policy Update Magnitude: 0.44690
Value Function Update Magnitude: 0.45154

Collected Steps per Second: 21,586.44113
Overall Steps per Second: 10,412.95274

Timestep Collection Time: 2.31682
Timestep Consumption Time: 2.48604
PPO Batch Consumption Time: 0.28453
Total Iteration Time: 4.80286

Cumulative Model Updates: 93,310
Cumulative Timesteps: 778,109,360

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 778109360...
Checkpoint 778109360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,168.53699
Policy Entropy: 3.68451
Value Function Loss: 0.04943

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.13861
Policy Update Magnitude: 0.44218
Value Function Update Magnitude: 0.62071

Collected Steps per Second: 21,948.45615
Overall Steps per Second: 10,312.51537

Timestep Collection Time: 2.27825
Timestep Consumption Time: 2.57062
PPO Batch Consumption Time: 0.29452
Total Iteration Time: 4.84887

Cumulative Model Updates: 93,316
Cumulative Timesteps: 778,159,364

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,204.21893
Policy Entropy: 3.67329
Value Function Loss: 0.04648

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.13996
Policy Update Magnitude: 0.49421
Value Function Update Magnitude: 0.82469

Collected Steps per Second: 22,047.03011
Overall Steps per Second: 10,313.85247

Timestep Collection Time: 2.26815
Timestep Consumption Time: 2.58028
PPO Batch Consumption Time: 0.29505
Total Iteration Time: 4.84843

Cumulative Model Updates: 93,322
Cumulative Timesteps: 778,209,370

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 778209370...
Checkpoint 778209370 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,413.97669
Policy Entropy: 3.66729
Value Function Loss: 0.05009

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.13568
Policy Update Magnitude: 0.51525
Value Function Update Magnitude: 0.86554

Collected Steps per Second: 22,121.88798
Overall Steps per Second: 10,550.30870

Timestep Collection Time: 2.26111
Timestep Consumption Time: 2.47998
PPO Batch Consumption Time: 0.28298
Total Iteration Time: 4.74109

Cumulative Model Updates: 93,328
Cumulative Timesteps: 778,259,390

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82,059.15202
Policy Entropy: 3.66714
Value Function Loss: 0.05212

Mean KL Divergence: 0.01053
SB3 Clip Fraction: 0.14215
Policy Update Magnitude: 0.51584
Value Function Update Magnitude: 0.70029

Collected Steps per Second: 22,152.82035
Overall Steps per Second: 10,578.24898

Timestep Collection Time: 2.25732
Timestep Consumption Time: 2.46993
PPO Batch Consumption Time: 0.28436
Total Iteration Time: 4.72725

Cumulative Model Updates: 93,334
Cumulative Timesteps: 778,309,396

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 778309396...
Checkpoint 778309396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,415.12206
Policy Entropy: 3.68278
Value Function Loss: 0.05190

Mean KL Divergence: 0.01050
SB3 Clip Fraction: 0.14138
Policy Update Magnitude: 0.54489
Value Function Update Magnitude: 0.59615

Collected Steps per Second: 22,453.37377
Overall Steps per Second: 10,676.07084

Timestep Collection Time: 2.22799
Timestep Consumption Time: 2.45781
PPO Batch Consumption Time: 0.28259
Total Iteration Time: 4.68581

Cumulative Model Updates: 93,340
Cumulative Timesteps: 778,359,422

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,212.52100
Policy Entropy: 3.65846
Value Function Loss: 0.05215

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.14317
Policy Update Magnitude: 0.52481
Value Function Update Magnitude: 0.53352

Collected Steps per Second: 22,347.36297
Overall Steps per Second: 10,460.22874

Timestep Collection Time: 2.23856
Timestep Consumption Time: 2.54393
PPO Batch Consumption Time: 0.29622
Total Iteration Time: 4.78250

Cumulative Model Updates: 93,346
Cumulative Timesteps: 778,409,448

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 778409448...
Checkpoint 778409448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,212.52100
Policy Entropy: 3.64814
Value Function Loss: 0.04857

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.14297
Policy Update Magnitude: 0.49668
Value Function Update Magnitude: 0.50860

Collected Steps per Second: 22,315.65976
Overall Steps per Second: 10,555.83415

Timestep Collection Time: 2.24112
Timestep Consumption Time: 2.49674
PPO Batch Consumption Time: 0.28941
Total Iteration Time: 4.73785

Cumulative Model Updates: 93,352
Cumulative Timesteps: 778,459,460

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,521.79603
Policy Entropy: 3.63677
Value Function Loss: 0.04088

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.14753
Policy Update Magnitude: 0.47052
Value Function Update Magnitude: 0.47911

Collected Steps per Second: 21,194.36173
Overall Steps per Second: 10,480.03184

Timestep Collection Time: 2.36016
Timestep Consumption Time: 2.41292
PPO Batch Consumption Time: 0.28357
Total Iteration Time: 4.77308

Cumulative Model Updates: 93,358
Cumulative Timesteps: 778,509,482

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 778509482...
Checkpoint 778509482 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,926.61662
Policy Entropy: 3.64928
Value Function Loss: 0.03798

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.14674
Policy Update Magnitude: 0.43816
Value Function Update Magnitude: 0.52243

Collected Steps per Second: 21,350.53391
Overall Steps per Second: 10,445.97901

Timestep Collection Time: 2.34374
Timestep Consumption Time: 2.44662
PPO Batch Consumption Time: 0.29425
Total Iteration Time: 4.79036

Cumulative Model Updates: 93,364
Cumulative Timesteps: 778,559,522

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,926.61662
Policy Entropy: 3.65777
Value Function Loss: 0.03348

Mean KL Divergence: 0.01076
SB3 Clip Fraction: 0.15050
Policy Update Magnitude: 0.42029
Value Function Update Magnitude: 0.61739

Collected Steps per Second: 21,379.71913
Overall Steps per Second: 10,278.26502

Timestep Collection Time: 2.33895
Timestep Consumption Time: 2.52627
PPO Batch Consumption Time: 0.29388
Total Iteration Time: 4.86522

Cumulative Model Updates: 93,370
Cumulative Timesteps: 778,609,528

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 778609528...
Checkpoint 778609528 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 83,097.58629
Policy Entropy: 3.65570
Value Function Loss: 0.03792

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.14223
Policy Update Magnitude: 0.43751
Value Function Update Magnitude: 0.74182

Collected Steps per Second: 21,916.42489
Overall Steps per Second: 10,513.60420

Timestep Collection Time: 2.28158
Timestep Consumption Time: 2.47455
PPO Batch Consumption Time: 0.28682
Total Iteration Time: 4.75612

Cumulative Model Updates: 93,376
Cumulative Timesteps: 778,659,532

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 250,085.58304
Policy Entropy: 3.65536
Value Function Loss: 0.04166

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.14756
Policy Update Magnitude: 0.47520
Value Function Update Magnitude: 0.86043

Collected Steps per Second: 21,754.65992
Overall Steps per Second: 10,526.45600

Timestep Collection Time: 2.29955
Timestep Consumption Time: 2.45285
PPO Batch Consumption Time: 0.28384
Total Iteration Time: 4.75241

Cumulative Model Updates: 93,382
Cumulative Timesteps: 778,709,558

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 778709558...
Checkpoint 778709558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 141,615.62053
Policy Entropy: 3.64117
Value Function Loss: 0.04833

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.13645
Policy Update Magnitude: 0.49573
Value Function Update Magnitude: 0.75208

Collected Steps per Second: 21,929.18995
Overall Steps per Second: 10,505.40108

Timestep Collection Time: 2.28070
Timestep Consumption Time: 2.48008
PPO Batch Consumption Time: 0.28888
Total Iteration Time: 4.76079

Cumulative Model Updates: 93,388
Cumulative Timesteps: 778,759,572

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 165,238.79984
Policy Entropy: 3.65753
Value Function Loss: 0.04506

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.14337
Policy Update Magnitude: 0.52682
Value Function Update Magnitude: 0.69994

Collected Steps per Second: 22,268.41364
Overall Steps per Second: 10,500.58580

Timestep Collection Time: 2.24587
Timestep Consumption Time: 2.51691
PPO Batch Consumption Time: 0.28360
Total Iteration Time: 4.76278

Cumulative Model Updates: 93,394
Cumulative Timesteps: 778,809,584

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 778809584...
Checkpoint 778809584 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 164,269.56905
Policy Entropy: 3.65385
Value Function Loss: 0.04977

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.14370
Policy Update Magnitude: 0.52372
Value Function Update Magnitude: 0.69873

Collected Steps per Second: 22,336.21058
Overall Steps per Second: 10,530.78008

Timestep Collection Time: 2.23879
Timestep Consumption Time: 2.50977
PPO Batch Consumption Time: 0.28509
Total Iteration Time: 4.74856

Cumulative Model Updates: 93,400
Cumulative Timesteps: 778,859,590

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 477,391.27753
Policy Entropy: 3.67097
Value Function Loss: 0.04913

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.14388
Policy Update Magnitude: 0.51760
Value Function Update Magnitude: 0.59968

Collected Steps per Second: 22,227.76146
Overall Steps per Second: 10,481.41535

Timestep Collection Time: 2.25061
Timestep Consumption Time: 2.52222
PPO Batch Consumption Time: 0.28975
Total Iteration Time: 4.77283

Cumulative Model Updates: 93,406
Cumulative Timesteps: 778,909,616

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 778909616...
Checkpoint 778909616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 139,214.59678
Policy Entropy: 3.64877
Value Function Loss: 0.05350

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.13912
Policy Update Magnitude: 0.50900
Value Function Update Magnitude: 0.64323

Collected Steps per Second: 22,172.07816
Overall Steps per Second: 10,791.32903

Timestep Collection Time: 2.25590
Timestep Consumption Time: 2.37912
PPO Batch Consumption Time: 0.28268
Total Iteration Time: 4.63502

Cumulative Model Updates: 93,412
Cumulative Timesteps: 778,959,634

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,936.33930
Policy Entropy: 3.66174
Value Function Loss: 0.05203

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.13405
Policy Update Magnitude: 0.51027
Value Function Update Magnitude: 0.64897

Collected Steps per Second: 22,332.94277
Overall Steps per Second: 10,418.16798

Timestep Collection Time: 2.23947
Timestep Consumption Time: 2.56118
PPO Batch Consumption Time: 0.30026
Total Iteration Time: 4.80065

Cumulative Model Updates: 93,418
Cumulative Timesteps: 779,009,648

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 779009648...
Checkpoint 779009648 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,356.57155
Policy Entropy: 3.64440
Value Function Loss: 0.05082

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.14190
Policy Update Magnitude: 0.50443
Value Function Update Magnitude: 0.63465

Collected Steps per Second: 21,375.17104
Overall Steps per Second: 10,234.26235

Timestep Collection Time: 2.34019
Timestep Consumption Time: 2.54751
PPO Batch Consumption Time: 0.29626
Total Iteration Time: 4.88770

Cumulative Model Updates: 93,424
Cumulative Timesteps: 779,059,670

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,347.11641
Policy Entropy: 3.64777
Value Function Loss: 0.04596

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.13813
Policy Update Magnitude: 0.48128
Value Function Update Magnitude: 0.67282

Collected Steps per Second: 20,929.79527
Overall Steps per Second: 10,149.99583

Timestep Collection Time: 2.38894
Timestep Consumption Time: 2.53717
PPO Batch Consumption Time: 0.29296
Total Iteration Time: 4.92611

Cumulative Model Updates: 93,430
Cumulative Timesteps: 779,109,670

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 779109670...
Checkpoint 779109670 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 101,908.47323
Policy Entropy: 3.63597
Value Function Loss: 0.04884

Mean KL Divergence: 0.01060
SB3 Clip Fraction: 0.14396
Policy Update Magnitude: 0.47731
Value Function Update Magnitude: 0.62942

Collected Steps per Second: 22,115.39320
Overall Steps per Second: 10,446.20421

Timestep Collection Time: 2.26168
Timestep Consumption Time: 2.52647
PPO Batch Consumption Time: 0.29299
Total Iteration Time: 4.78815

Cumulative Model Updates: 93,436
Cumulative Timesteps: 779,159,688

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 101,908.47323
Policy Entropy: 3.63361
Value Function Loss: 0.04706

Mean KL Divergence: 0.01109
SB3 Clip Fraction: 0.15107
Policy Update Magnitude: 0.47886
Value Function Update Magnitude: 0.51154

Collected Steps per Second: 21,527.02236
Overall Steps per Second: 10,383.37308

Timestep Collection Time: 2.32341
Timestep Consumption Time: 2.49353
PPO Batch Consumption Time: 0.28526
Total Iteration Time: 4.81693

Cumulative Model Updates: 93,442
Cumulative Timesteps: 779,209,704

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 779209704...
Checkpoint 779209704 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 101,908.47323
Policy Entropy: 3.63331
Value Function Loss: 0.04040

Mean KL Divergence: 0.01136
SB3 Clip Fraction: 0.15466
Policy Update Magnitude: 0.44731
Value Function Update Magnitude: 0.46483

Collected Steps per Second: 21,921.06628
Overall Steps per Second: 10,278.92650

Timestep Collection Time: 2.28155
Timestep Consumption Time: 2.58413
PPO Batch Consumption Time: 0.29512
Total Iteration Time: 4.86568

Cumulative Model Updates: 93,448
Cumulative Timesteps: 779,259,718

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 117,690.65324
Policy Entropy: 3.63755
Value Function Loss: 0.03791

Mean KL Divergence: 0.01089
SB3 Clip Fraction: 0.15132
Policy Update Magnitude: 0.42545
Value Function Update Magnitude: 0.42826

Collected Steps per Second: 21,624.53977
Overall Steps per Second: 10,460.38907

Timestep Collection Time: 2.31321
Timestep Consumption Time: 2.46883
PPO Batch Consumption Time: 0.28235
Total Iteration Time: 4.78204

Cumulative Model Updates: 93,454
Cumulative Timesteps: 779,309,740

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 779309740...
Checkpoint 779309740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 110,065.57656
Policy Entropy: 3.64110
Value Function Loss: 0.03622

Mean KL Divergence: 0.01088
SB3 Clip Fraction: 0.14939
Policy Update Magnitude: 0.41331
Value Function Update Magnitude: 0.42073

Collected Steps per Second: 21,325.04361
Overall Steps per Second: 10,232.17829

Timestep Collection Time: 2.34597
Timestep Consumption Time: 2.54331
PPO Batch Consumption Time: 0.29236
Total Iteration Time: 4.88928

Cumulative Model Updates: 93,460
Cumulative Timesteps: 779,359,768

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 110,065.57656
Policy Entropy: 3.63943
Value Function Loss: 0.03674

Mean KL Divergence: 0.01074
SB3 Clip Fraction: 0.14744
Policy Update Magnitude: 0.41382
Value Function Update Magnitude: 0.52772

Collected Steps per Second: 21,926.94674
Overall Steps per Second: 10,278.94373

Timestep Collection Time: 2.28076
Timestep Consumption Time: 2.58453
PPO Batch Consumption Time: 0.29028
Total Iteration Time: 4.86529

Cumulative Model Updates: 93,466
Cumulative Timesteps: 779,409,778

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 779409778...
Checkpoint 779409778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 99,125.97247
Policy Entropy: 3.63444
Value Function Loss: 0.03523

Mean KL Divergence: 0.01092
SB3 Clip Fraction: 0.15020
Policy Update Magnitude: 0.41325
Value Function Update Magnitude: 0.55003

Collected Steps per Second: 21,557.89565
Overall Steps per Second: 10,082.65385

Timestep Collection Time: 2.32017
Timestep Consumption Time: 2.64063
PPO Batch Consumption Time: 0.30577
Total Iteration Time: 4.96080

Cumulative Model Updates: 93,472
Cumulative Timesteps: 779,459,796

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57,042.65207
Policy Entropy: 3.62783
Value Function Loss: 0.03751

Mean KL Divergence: 0.01091
SB3 Clip Fraction: 0.14933
Policy Update Magnitude: 0.42808
Value Function Update Magnitude: 0.53025

Collected Steps per Second: 22,533.13441
Overall Steps per Second: 10,387.46491

Timestep Collection Time: 2.21895
Timestep Consumption Time: 2.59454
PPO Batch Consumption Time: 0.30313
Total Iteration Time: 4.81349

Cumulative Model Updates: 93,478
Cumulative Timesteps: 779,509,796

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 779509796...
Checkpoint 779509796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86,214.35706
Policy Entropy: 3.61843
Value Function Loss: 0.04080

Mean KL Divergence: 0.01072
SB3 Clip Fraction: 0.14723
Policy Update Magnitude: 0.45460
Value Function Update Magnitude: 0.66715

Collected Steps per Second: 21,326.57283
Overall Steps per Second: 10,387.95265

Timestep Collection Time: 2.34665
Timestep Consumption Time: 2.47105
PPO Batch Consumption Time: 0.29376
Total Iteration Time: 4.81770

Cumulative Model Updates: 93,484
Cumulative Timesteps: 779,559,842

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86,214.35706
Policy Entropy: 3.63628
Value Function Loss: 0.03892

Mean KL Divergence: 0.01117
SB3 Clip Fraction: 0.15085
Policy Update Magnitude: 0.52316
Value Function Update Magnitude: 0.79845

Collected Steps per Second: 20,669.90760
Overall Steps per Second: 10,229.49153

Timestep Collection Time: 2.42062
Timestep Consumption Time: 2.47053
PPO Batch Consumption Time: 0.29409
Total Iteration Time: 4.89115

Cumulative Model Updates: 93,490
Cumulative Timesteps: 779,609,876

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 779609876...
Checkpoint 779609876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 155,234.46073
Policy Entropy: 3.64864
Value Function Loss: 0.04045

Mean KL Divergence: 0.01096
SB3 Clip Fraction: 0.14926
Policy Update Magnitude: 0.51050
Value Function Update Magnitude: 0.75968

Collected Steps per Second: 21,645.07223
Overall Steps per Second: 10,485.56300

Timestep Collection Time: 2.31055
Timestep Consumption Time: 2.45906
PPO Batch Consumption Time: 0.29309
Total Iteration Time: 4.76961

Cumulative Model Updates: 93,496
Cumulative Timesteps: 779,659,888

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49,972.01957
Policy Entropy: 3.66606
Value Function Loss: 0.03998

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.14115
Policy Update Magnitude: 0.47719
Value Function Update Magnitude: 0.61515

Collected Steps per Second: 21,361.46895
Overall Steps per Second: 10,498.15047

Timestep Collection Time: 2.34066
Timestep Consumption Time: 2.42208
PPO Batch Consumption Time: 0.28314
Total Iteration Time: 4.76274

Cumulative Model Updates: 93,502
Cumulative Timesteps: 779,709,888

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 779709888...
Checkpoint 779709888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,951.38300
Policy Entropy: 3.65730
Value Function Loss: 0.04777

Mean KL Divergence: 0.01055
SB3 Clip Fraction: 0.14549
Policy Update Magnitude: 0.47090
Value Function Update Magnitude: 0.61239

Collected Steps per Second: 21,346.40228
Overall Steps per Second: 10,361.24029

Timestep Collection Time: 2.34335
Timestep Consumption Time: 2.48445
PPO Batch Consumption Time: 0.28976
Total Iteration Time: 4.82780

Cumulative Model Updates: 93,508
Cumulative Timesteps: 779,759,910

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 206,418.73783
Policy Entropy: 3.64523
Value Function Loss: 0.04546

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.14304
Policy Update Magnitude: 0.50887
Value Function Update Magnitude: 0.63033

Collected Steps per Second: 22,400.07753
Overall Steps per Second: 10,435.33528

Timestep Collection Time: 2.23294
Timestep Consumption Time: 2.56020
PPO Batch Consumption Time: 0.29995
Total Iteration Time: 4.79314

Cumulative Model Updates: 93,514
Cumulative Timesteps: 779,809,928

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 779809928...
Checkpoint 779809928 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 135,461.29985
Policy Entropy: 3.64076
Value Function Loss: 0.05045

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.14497
Policy Update Magnitude: 0.53429
Value Function Update Magnitude: 0.56143

Collected Steps per Second: 20,719.14373
Overall Steps per Second: 10,113.72848

Timestep Collection Time: 2.41342
Timestep Consumption Time: 2.53075
PPO Batch Consumption Time: 0.29175
Total Iteration Time: 4.94417

Cumulative Model Updates: 93,520
Cumulative Timesteps: 779,859,932

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 238,514.82246
Policy Entropy: 3.64631
Value Function Loss: 0.04530

Mean KL Divergence: 0.01096
SB3 Clip Fraction: 0.15016
Policy Update Magnitude: 0.53187
Value Function Update Magnitude: 0.51916

Collected Steps per Second: 21,068.27355
Overall Steps per Second: 10,142.75810

Timestep Collection Time: 2.37324
Timestep Consumption Time: 2.55639
PPO Batch Consumption Time: 0.29276
Total Iteration Time: 4.92963

Cumulative Model Updates: 93,526
Cumulative Timesteps: 779,909,932

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 779909932...
Checkpoint 779909932 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 238,514.82246
Policy Entropy: 3.64813
Value Function Loss: 0.04082

Mean KL Divergence: 0.01061
SB3 Clip Fraction: 0.14568
Policy Update Magnitude: 0.53102
Value Function Update Magnitude: 0.56551

Collected Steps per Second: 20,907.48010
Overall Steps per Second: 10,191.14862

Timestep Collection Time: 2.39264
Timestep Consumption Time: 2.51594
PPO Batch Consumption Time: 0.28393
Total Iteration Time: 4.90857

Cumulative Model Updates: 93,532
Cumulative Timesteps: 779,959,956

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 238,514.82246
Policy Entropy: 3.65127
Value Function Loss: 0.03751

Mean KL Divergence: 0.01130
SB3 Clip Fraction: 0.15677
Policy Update Magnitude: 0.48322
Value Function Update Magnitude: 0.49395

Collected Steps per Second: 21,524.86177
Overall Steps per Second: 10,146.06796

Timestep Collection Time: 2.32355
Timestep Consumption Time: 2.60585
PPO Batch Consumption Time: 0.29906
Total Iteration Time: 4.92940

Cumulative Model Updates: 93,538
Cumulative Timesteps: 780,009,970

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 780009970...
Checkpoint 780009970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 291,529.02690
Policy Entropy: 3.65291
Value Function Loss: 0.03729

Mean KL Divergence: 0.01131
SB3 Clip Fraction: 0.15473
Policy Update Magnitude: 0.47038
Value Function Update Magnitude: 0.42518

Collected Steps per Second: 21,285.37469
Overall Steps per Second: 10,121.27462

Timestep Collection Time: 2.35016
Timestep Consumption Time: 2.59230
PPO Batch Consumption Time: 0.30208
Total Iteration Time: 4.94246

Cumulative Model Updates: 93,544
Cumulative Timesteps: 780,059,994

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92,718.92950
Policy Entropy: 3.65996
Value Function Loss: 0.04071

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.15192
Policy Update Magnitude: 0.47140
Value Function Update Magnitude: 0.44372

Collected Steps per Second: 22,067.63040
Overall Steps per Second: 10,527.03256

Timestep Collection Time: 2.26703
Timestep Consumption Time: 2.48531
PPO Batch Consumption Time: 0.28419
Total Iteration Time: 4.75234

Cumulative Model Updates: 93,550
Cumulative Timesteps: 780,110,022

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 780110022...
Checkpoint 780110022 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 60,832.67003
Policy Entropy: 3.67001
Value Function Loss: 0.04081

Mean KL Divergence: 0.01135
SB3 Clip Fraction: 0.15560
Policy Update Magnitude: 0.47640
Value Function Update Magnitude: 0.49851

Collected Steps per Second: 20,555.21944
Overall Steps per Second: 10,124.39327

Timestep Collection Time: 2.43306
Timestep Consumption Time: 2.50670
PPO Batch Consumption Time: 0.28820
Total Iteration Time: 4.93975

Cumulative Model Updates: 93,556
Cumulative Timesteps: 780,160,034

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 101,390.30425
Policy Entropy: 3.66299
Value Function Loss: 0.04076

Mean KL Divergence: 0.01099
SB3 Clip Fraction: 0.14919
Policy Update Magnitude: 0.49590
Value Function Update Magnitude: 0.51593

Collected Steps per Second: 21,593.81959
Overall Steps per Second: 10,383.53979

Timestep Collection Time: 2.31576
Timestep Consumption Time: 2.50014
PPO Batch Consumption Time: 0.28700
Total Iteration Time: 4.81589

Cumulative Model Updates: 93,562
Cumulative Timesteps: 780,210,040

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 780210040...
Checkpoint 780210040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 180,167.62878
Policy Entropy: 3.66697
Value Function Loss: 0.04022

Mean KL Divergence: 0.01281
SB3 Clip Fraction: 0.16225
Policy Update Magnitude: 0.54260
Value Function Update Magnitude: 0.55800

Collected Steps per Second: 20,944.25637
Overall Steps per Second: 10,189.77306

Timestep Collection Time: 2.38777
Timestep Consumption Time: 2.52010
PPO Batch Consumption Time: 0.28834
Total Iteration Time: 4.90786

Cumulative Model Updates: 93,568
Cumulative Timesteps: 780,260,050

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95,757.36329
Policy Entropy: 3.66035
Value Function Loss: 0.04166

Mean KL Divergence: 0.01490
SB3 Clip Fraction: 0.17906
Policy Update Magnitude: 0.64784
Value Function Update Magnitude: 0.62667

Collected Steps per Second: 21,482.32695
Overall Steps per Second: 10,276.69594

Timestep Collection Time: 2.32815
Timestep Consumption Time: 2.53859
PPO Batch Consumption Time: 0.28899
Total Iteration Time: 4.86674

Cumulative Model Updates: 93,574
Cumulative Timesteps: 780,310,064

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 780310064...
Checkpoint 780310064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 203,611.31049
Policy Entropy: 3.67424
Value Function Loss: 0.04450

Mean KL Divergence: 0.01349
SB3 Clip Fraction: 0.16654
Policy Update Magnitude: 0.62146
Value Function Update Magnitude: 0.67854

Collected Steps per Second: 20,968.13537
Overall Steps per Second: 9,993.67954

Timestep Collection Time: 2.38591
Timestep Consumption Time: 2.62006
PPO Batch Consumption Time: 0.30206
Total Iteration Time: 5.00596

Cumulative Model Updates: 93,580
Cumulative Timesteps: 780,360,092

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 203,611.31049
Policy Entropy: 3.67376
Value Function Loss: 0.04056

Mean KL Divergence: 0.01335
SB3 Clip Fraction: 0.15780
Policy Update Magnitude: 0.59489
Value Function Update Magnitude: 0.62323

Collected Steps per Second: 21,750.50840
Overall Steps per Second: 10,019.68173

Timestep Collection Time: 2.29926
Timestep Consumption Time: 2.69192
PPO Batch Consumption Time: 0.30938
Total Iteration Time: 4.99118

Cumulative Model Updates: 93,586
Cumulative Timesteps: 780,410,102

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 780410102...
Checkpoint 780410102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 203,611.31049
Policy Entropy: 3.65491
Value Function Loss: 0.04361

Mean KL Divergence: 0.01526
SB3 Clip Fraction: 0.19443
Policy Update Magnitude: 0.58818
Value Function Update Magnitude: 0.56148

Collected Steps per Second: 20,357.07070
Overall Steps per Second: 9,927.25470

Timestep Collection Time: 2.45752
Timestep Consumption Time: 2.58194
PPO Batch Consumption Time: 0.29788
Total Iteration Time: 5.03946

Cumulative Model Updates: 93,592
Cumulative Timesteps: 780,460,130

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 153,811.30833
Policy Entropy: 3.62016
Value Function Loss: 0.06161

Mean KL Divergence: 0.01749
SB3 Clip Fraction: 0.21210
Policy Update Magnitude: 0.58482
Value Function Update Magnitude: 0.52567

Collected Steps per Second: 20,550.99921
Overall Steps per Second: 10,107.78838

Timestep Collection Time: 2.43336
Timestep Consumption Time: 2.51411
PPO Batch Consumption Time: 0.28528
Total Iteration Time: 4.94747

Cumulative Model Updates: 93,598
Cumulative Timesteps: 780,510,138

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 780510138...
Checkpoint 780510138 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 387,520.90014
Policy Entropy: 3.59899
Value Function Loss: 0.07411

Mean KL Divergence: 0.01328
SB3 Clip Fraction: 0.16202
Policy Update Magnitude: 0.77533
Value Function Update Magnitude: 0.61075

Collected Steps per Second: 20,343.12847
Overall Steps per Second: 9,944.17196

Timestep Collection Time: 2.45941
Timestep Consumption Time: 2.57188
PPO Batch Consumption Time: 0.29674
Total Iteration Time: 5.03129

Cumulative Model Updates: 93,604
Cumulative Timesteps: 780,560,170

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 197,215.98092
Policy Entropy: 3.61471
Value Function Loss: 0.08436

Mean KL Divergence: 0.01070
SB3 Clip Fraction: 0.13017
Policy Update Magnitude: 0.98789
Value Function Update Magnitude: 0.59038

Collected Steps per Second: 20,878.38883
Overall Steps per Second: 10,121.84635

Timestep Collection Time: 2.39626
Timestep Consumption Time: 2.54652
PPO Batch Consumption Time: 0.29443
Total Iteration Time: 4.94277

Cumulative Model Updates: 93,610
Cumulative Timesteps: 780,610,200

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 780610200...
Checkpoint 780610200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,607.53984
Policy Entropy: 3.64085
Value Function Loss: 0.07277

Mean KL Divergence: 0.01352
SB3 Clip Fraction: 0.16534
Policy Update Magnitude: 0.95115
Value Function Update Magnitude: 0.49077

Collected Steps per Second: 20,412.46583
Overall Steps per Second: 9,870.35495

Timestep Collection Time: 2.45037
Timestep Consumption Time: 2.61713
PPO Batch Consumption Time: 0.30560
Total Iteration Time: 5.06750

Cumulative Model Updates: 93,616
Cumulative Timesteps: 780,660,218

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,631.77976
Policy Entropy: 3.67766
Value Function Loss: 0.06679

Mean KL Divergence: 0.01186
SB3 Clip Fraction: 0.15226
Policy Update Magnitude: 0.78897
Value Function Update Magnitude: 0.46382

Collected Steps per Second: 18,236.29706
Overall Steps per Second: 9,290.44876

Timestep Collection Time: 2.74288
Timestep Consumption Time: 2.64114
PPO Batch Consumption Time: 0.29379
Total Iteration Time: 5.38402

Cumulative Model Updates: 93,622
Cumulative Timesteps: 780,710,238

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 780710238...
Checkpoint 780710238 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 433,413.13613
Policy Entropy: 3.68854
Value Function Loss: 0.06852

Mean KL Divergence: 0.01171
SB3 Clip Fraction: 0.15023
Policy Update Magnitude: 0.71616
Value Function Update Magnitude: 0.49580

Collected Steps per Second: 18,760.16011
Overall Steps per Second: 10,034.62034

Timestep Collection Time: 2.66576
Timestep Consumption Time: 2.31799
PPO Batch Consumption Time: 0.28210
Total Iteration Time: 4.98375

Cumulative Model Updates: 93,628
Cumulative Timesteps: 780,760,248

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 186,570.56323
Policy Entropy: 3.67394
Value Function Loss: 0.06782

Mean KL Divergence: 0.01204
SB3 Clip Fraction: 0.15059
Policy Update Magnitude: 0.67654
Value Function Update Magnitude: 0.53303

Collected Steps per Second: 20,021.01871
Overall Steps per Second: 10,003.51446

Timestep Collection Time: 2.49977
Timestep Consumption Time: 2.50327
PPO Batch Consumption Time: 0.29596
Total Iteration Time: 5.00304

Cumulative Model Updates: 93,634
Cumulative Timesteps: 780,810,296

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 780810296...
Checkpoint 780810296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 132,953.97046
Policy Entropy: 3.66827
Value Function Loss: 0.06798

Mean KL Divergence: 0.01201
SB3 Clip Fraction: 0.15402
Policy Update Magnitude: 0.66397
Value Function Update Magnitude: 0.52742

Collected Steps per Second: 20,805.31530
Overall Steps per Second: 10,222.98566

Timestep Collection Time: 2.40381
Timestep Consumption Time: 2.48830
PPO Batch Consumption Time: 0.29924
Total Iteration Time: 4.89211

Cumulative Model Updates: 93,640
Cumulative Timesteps: 780,860,308

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 109,581.44424
Policy Entropy: 3.67596
Value Function Loss: 0.06131

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.13702
Policy Update Magnitude: 0.59723
Value Function Update Magnitude: 0.46480

Collected Steps per Second: 20,237.22393
Overall Steps per Second: 9,857.73864

Timestep Collection Time: 2.47139
Timestep Consumption Time: 2.60219
PPO Batch Consumption Time: 0.30481
Total Iteration Time: 5.07358

Cumulative Model Updates: 93,646
Cumulative Timesteps: 780,910,322

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 780910322...
Checkpoint 780910322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 91,399.66817
Policy Entropy: 3.69324
Value Function Loss: 0.05625

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.13809
Policy Update Magnitude: 0.53143
Value Function Update Magnitude: 0.46504

Collected Steps per Second: 20,723.76268
Overall Steps per Second: 10,249.54210

Timestep Collection Time: 2.41298
Timestep Consumption Time: 2.46587
PPO Batch Consumption Time: 0.28440
Total Iteration Time: 4.87885

Cumulative Model Updates: 93,652
Cumulative Timesteps: 780,960,328

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,369.12143
Policy Entropy: 3.69876
Value Function Loss: 0.05191

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.13992
Policy Update Magnitude: 0.50565
Value Function Update Magnitude: 0.46581

Collected Steps per Second: 21,727.14092
Overall Steps per Second: 10,357.19314

Timestep Collection Time: 2.30237
Timestep Consumption Time: 2.52751
PPO Batch Consumption Time: 0.29675
Total Iteration Time: 4.82988

Cumulative Model Updates: 93,658
Cumulative Timesteps: 781,010,352

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 781010352...
Checkpoint 781010352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,369.12143
Policy Entropy: 3.68766
Value Function Loss: 0.04318

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.14258
Policy Update Magnitude: 0.48497
Value Function Update Magnitude: 0.46434

Collected Steps per Second: 20,605.61786
Overall Steps per Second: 9,868.82230

Timestep Collection Time: 2.42808
Timestep Consumption Time: 2.64163
PPO Batch Consumption Time: 0.31329
Total Iteration Time: 5.06970

Cumulative Model Updates: 93,664
Cumulative Timesteps: 781,060,384

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,369.12143
Policy Entropy: 3.67911
Value Function Loss: 0.03960

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.14134
Policy Update Magnitude: 0.43742
Value Function Update Magnitude: 0.42321

Collected Steps per Second: 21,626.34004
Overall Steps per Second: 10,180.15325

Timestep Collection Time: 2.31227
Timestep Consumption Time: 2.59983
PPO Batch Consumption Time: 0.30559
Total Iteration Time: 4.91211

Cumulative Model Updates: 93,670
Cumulative Timesteps: 781,110,390

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 781110390...
Checkpoint 781110390 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 59,206.18729
Policy Entropy: 3.68541
Value Function Loss: 0.03738

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.14490
Policy Update Magnitude: 0.41706
Value Function Update Magnitude: 0.42838

Collected Steps per Second: 21,730.41103
Overall Steps per Second: 10,376.67789

Timestep Collection Time: 2.30221
Timestep Consumption Time: 2.51898
PPO Batch Consumption Time: 0.29100
Total Iteration Time: 4.82120

Cumulative Model Updates: 93,676
Cumulative Timesteps: 781,160,418

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49,474.38804
Policy Entropy: 3.68708
Value Function Loss: 0.04198

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.14401
Policy Update Magnitude: 0.41382
Value Function Update Magnitude: 0.48065

Collected Steps per Second: 21,105.90645
Overall Steps per Second: 10,235.83122

Timestep Collection Time: 2.36948
Timestep Consumption Time: 2.51630
PPO Batch Consumption Time: 0.28312
Total Iteration Time: 4.88578

Cumulative Model Updates: 93,682
Cumulative Timesteps: 781,210,428

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 781210428...
Checkpoint 781210428 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,096.08132
Policy Entropy: 3.69294
Value Function Loss: 0.04136

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.13968
Policy Update Magnitude: 0.43650
Value Function Update Magnitude: 0.55607

Collected Steps per Second: 19,761.97157
Overall Steps per Second: 9,759.84237

Timestep Collection Time: 2.53173
Timestep Consumption Time: 2.59458
PPO Batch Consumption Time: 0.29193
Total Iteration Time: 5.12631

Cumulative Model Updates: 93,688
Cumulative Timesteps: 781,260,460

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 153,969.44923
Policy Entropy: 3.68604
Value Function Loss: 0.03973

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.14302
Policy Update Magnitude: 0.41521
Value Function Update Magnitude: 0.63437

Collected Steps per Second: 20,909.56700
Overall Steps per Second: 10,168.96273

Timestep Collection Time: 2.39182
Timestep Consumption Time: 2.52628
PPO Batch Consumption Time: 0.28466
Total Iteration Time: 4.91810

Cumulative Model Updates: 93,694
Cumulative Timesteps: 781,310,472

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 781310472...
Checkpoint 781310472 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 409,839.51783
Policy Entropy: 3.69280
Value Function Loss: 0.03828

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.13812
Policy Update Magnitude: 0.39473
Value Function Update Magnitude: 0.57888

Collected Steps per Second: 21,420.59946
Overall Steps per Second: 10,101.12676

Timestep Collection Time: 2.33542
Timestep Consumption Time: 2.61710
PPO Batch Consumption Time: 0.30217
Total Iteration Time: 4.95252

Cumulative Model Updates: 93,700
Cumulative Timesteps: 781,360,498

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 409,839.51783
Policy Entropy: 3.68705
Value Function Loss: 0.03874

Mean KL Divergence: 0.01059
SB3 Clip Fraction: 0.14690
Policy Update Magnitude: 0.43356
Value Function Update Magnitude: 0.56375

Collected Steps per Second: 17,649.86608
Overall Steps per Second: 9,129.99503

Timestep Collection Time: 2.83300
Timestep Consumption Time: 2.64368
PPO Batch Consumption Time: 0.29822
Total Iteration Time: 5.47667

Cumulative Model Updates: 93,706
Cumulative Timesteps: 781,410,500

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 781410500...
Checkpoint 781410500 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 409,839.51783
Policy Entropy: 3.67726
Value Function Loss: 0.03791

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.13869
Policy Update Magnitude: 0.44406
Value Function Update Magnitude: 0.45214

Collected Steps per Second: 19,483.42088
Overall Steps per Second: 7,884.14355

Timestep Collection Time: 2.56639
Timestep Consumption Time: 3.77571
PPO Batch Consumption Time: 0.48147
Total Iteration Time: 6.34210

Cumulative Model Updates: 93,712
Cumulative Timesteps: 781,460,502

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 409,839.51783
Policy Entropy: 3.66199
Value Function Loss: 0.03924

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.14716
Policy Update Magnitude: 0.44958
Value Function Update Magnitude: 0.39824

Collected Steps per Second: 16,003.72588
Overall Steps per Second: 7,534.28420

Timestep Collection Time: 3.12452
Timestep Consumption Time: 3.51234
PPO Batch Consumption Time: 0.44614
Total Iteration Time: 6.63686

Cumulative Model Updates: 93,718
Cumulative Timesteps: 781,510,506

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 781510506...
Checkpoint 781510506 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 390,401.45999
Policy Entropy: 3.64365
Value Function Loss: 0.04426

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.14175
Policy Update Magnitude: 0.42371
Value Function Update Magnitude: 0.38212

Collected Steps per Second: 16,173.65014
Overall Steps per Second: 7,634.55988

Timestep Collection Time: 3.09145
Timestep Consumption Time: 3.45772
PPO Batch Consumption Time: 0.44473
Total Iteration Time: 6.54917

Cumulative Model Updates: 93,724
Cumulative Timesteps: 781,560,506

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 309,772.37841
Policy Entropy: 3.66278
Value Function Loss: 0.04370

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.13751
Policy Update Magnitude: 0.48601
Value Function Update Magnitude: 0.38328

Collected Steps per Second: 15,629.82135
Overall Steps per Second: 7,221.17090

Timestep Collection Time: 3.20093
Timestep Consumption Time: 3.72731
PPO Batch Consumption Time: 0.49060
Total Iteration Time: 6.92824

Cumulative Model Updates: 93,730
Cumulative Timesteps: 781,610,536

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 781610536...
Checkpoint 781610536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 133,359.48554
Policy Entropy: 3.67271
Value Function Loss: 0.04140

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.14278
Policy Update Magnitude: 0.48668
Value Function Update Magnitude: 0.49617

Collected Steps per Second: 15,259.83513
Overall Steps per Second: 7,173.74770

Timestep Collection Time: 3.27684
Timestep Consumption Time: 3.69358
PPO Batch Consumption Time: 0.49702
Total Iteration Time: 6.97042

Cumulative Model Updates: 93,736
Cumulative Timesteps: 781,660,540

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 133,359.48554
Policy Entropy: 3.68041
Value Function Loss: 0.03525

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.14012
Policy Update Magnitude: 0.49524
Value Function Update Magnitude: 0.49154

Collected Steps per Second: 15,361.80720
Overall Steps per Second: 7,285.68586

Timestep Collection Time: 3.25639
Timestep Consumption Time: 3.60968
PPO Batch Consumption Time: 0.48475
Total Iteration Time: 6.86607

Cumulative Model Updates: 93,742
Cumulative Timesteps: 781,710,564

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 781710564...
Checkpoint 781710564 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 133,359.48554
Policy Entropy: 3.66581
Value Function Loss: 0.03142

Mean KL Divergence: 0.01113
SB3 Clip Fraction: 0.15186
Policy Update Magnitude: 0.46883
Value Function Update Magnitude: 0.44532

Collected Steps per Second: 14,732.74157
Overall Steps per Second: 7,549.51392

Timestep Collection Time: 3.39570
Timestep Consumption Time: 3.23095
PPO Batch Consumption Time: 0.41046
Total Iteration Time: 6.62665

Cumulative Model Updates: 93,748
Cumulative Timesteps: 781,760,592

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 133,359.48554
Policy Entropy: 3.65647
Value Function Loss: 0.03133

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.14043
Policy Update Magnitude: 0.41014
Value Function Update Magnitude: 0.37574

Collected Steps per Second: 16,175.76187
Overall Steps per Second: 7,832.42542

Timestep Collection Time: 3.09278
Timestep Consumption Time: 3.29452
PPO Batch Consumption Time: 0.42542
Total Iteration Time: 6.38729

Cumulative Model Updates: 93,754
Cumulative Timesteps: 781,810,620

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 781810620...
Checkpoint 781810620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 133,359.48554
Policy Entropy: 3.66060
Value Function Loss: 0.03000

Mean KL Divergence: 0.01077
SB3 Clip Fraction: 0.15098
Policy Update Magnitude: 0.40008
Value Function Update Magnitude: 0.35948

Collected Steps per Second: 16,340.55972
Overall Steps per Second: 7,847.67518

Timestep Collection Time: 3.05999
Timestep Consumption Time: 3.31158
PPO Batch Consumption Time: 0.42909
Total Iteration Time: 6.37157

Cumulative Model Updates: 93,760
Cumulative Timesteps: 781,860,622

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 365,641.22620
Policy Entropy: 3.65134
Value Function Loss: 0.03954

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.14373
Policy Update Magnitude: 0.40138
Value Function Update Magnitude: 0.35850

Collected Steps per Second: 16,336.48894
Overall Steps per Second: 7,822.24640

Timestep Collection Time: 3.06125
Timestep Consumption Time: 3.33206
PPO Batch Consumption Time: 0.42629
Total Iteration Time: 6.39330

Cumulative Model Updates: 93,766
Cumulative Timesteps: 781,910,632

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 781910632...
Checkpoint 781910632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 365,641.22620
Policy Entropy: 3.66387
Value Function Loss: 0.03545

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.14214
Policy Update Magnitude: 0.46347
Value Function Update Magnitude: 0.40902

Collected Steps per Second: 16,040.80764
Overall Steps per Second: 7,706.08375

Timestep Collection Time: 3.11867
Timestep Consumption Time: 3.37308
PPO Batch Consumption Time: 0.43441
Total Iteration Time: 6.49175

Cumulative Model Updates: 93,772
Cumulative Timesteps: 781,960,658

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 505,248.20710
Policy Entropy: 3.64348
Value Function Loss: 0.04565

Mean KL Divergence: 0.01116
SB3 Clip Fraction: 0.14809
Policy Update Magnitude: 0.48615
Value Function Update Magnitude: 0.40258

Collected Steps per Second: 15,532.28708
Overall Steps per Second: 7,240.45989

Timestep Collection Time: 3.21962
Timestep Consumption Time: 3.68713
PPO Batch Consumption Time: 0.48131
Total Iteration Time: 6.90674

Cumulative Model Updates: 93,778
Cumulative Timesteps: 782,010,666

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 782010666...
Checkpoint 782010666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 331,501.28117
Policy Entropy: 3.65476
Value Function Loss: 0.04170

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.14069
Policy Update Magnitude: 0.48664
Value Function Update Magnitude: 0.39336

Collected Steps per Second: 16,284.34199
Overall Steps per Second: 7,663.80909

Timestep Collection Time: 3.07068
Timestep Consumption Time: 3.45401
PPO Batch Consumption Time: 0.44246
Total Iteration Time: 6.52469

Cumulative Model Updates: 93,784
Cumulative Timesteps: 782,060,670

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 413,467.71317
Policy Entropy: 3.63281
Value Function Loss: 0.04576

Mean KL Divergence: 0.01154
SB3 Clip Fraction: 0.15367
Policy Update Magnitude: 0.51463
Value Function Update Magnitude: 0.37359

Collected Steps per Second: 16,323.39032
Overall Steps per Second: 7,893.66211

Timestep Collection Time: 3.06431
Timestep Consumption Time: 3.27241
PPO Batch Consumption Time: 0.41736
Total Iteration Time: 6.33673

Cumulative Model Updates: 93,790
Cumulative Timesteps: 782,110,690

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 782110690...
Checkpoint 782110690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 282,809.91622
Policy Entropy: 3.63802
Value Function Loss: 0.04031

Mean KL Divergence: 0.01081
SB3 Clip Fraction: 0.14800
Policy Update Magnitude: 0.49647
Value Function Update Magnitude: 0.40662

Collected Steps per Second: 15,967.69452
Overall Steps per Second: 7,231.60217

Timestep Collection Time: 3.13220
Timestep Consumption Time: 3.78383
PPO Batch Consumption Time: 0.50295
Total Iteration Time: 6.91603

Cumulative Model Updates: 93,796
Cumulative Timesteps: 782,160,704

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 150,312.38749
Policy Entropy: 3.63628
Value Function Loss: 0.04026

Mean KL Divergence: 0.01111
SB3 Clip Fraction: 0.14941
Policy Update Magnitude: 0.51626
Value Function Update Magnitude: 0.48523

Collected Steps per Second: 15,443.95013
Overall Steps per Second: 7,479.43961

Timestep Collection Time: 3.23933
Timestep Consumption Time: 3.44941
PPO Batch Consumption Time: 0.45998
Total Iteration Time: 6.68874

Cumulative Model Updates: 93,802
Cumulative Timesteps: 782,210,732

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 782210732...
Checkpoint 782210732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 150,312.38749
Policy Entropy: 3.64517
Value Function Loss: 0.03558

Mean KL Divergence: 0.01124
SB3 Clip Fraction: 0.15192
Policy Update Magnitude: 0.48772
Value Function Update Magnitude: 0.48591

Collected Steps per Second: 16,325.29549
Overall Steps per Second: 7,752.14988

Timestep Collection Time: 3.06273
Timestep Consumption Time: 3.38709
PPO Batch Consumption Time: 0.44686
Total Iteration Time: 6.44982

Cumulative Model Updates: 93,808
Cumulative Timesteps: 782,260,732

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 150,312.38749
Policy Entropy: 3.66253
Value Function Loss: 0.03188

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.14672
Policy Update Magnitude: 0.44190
Value Function Update Magnitude: 0.43411

Collected Steps per Second: 19,353.15892
Overall Steps per Second: 9,643.97489

Timestep Collection Time: 2.58366
Timestep Consumption Time: 2.60113
PPO Batch Consumption Time: 0.29525
Total Iteration Time: 5.18479

Cumulative Model Updates: 93,814
Cumulative Timesteps: 782,310,734

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 782310734...
Checkpoint 782310734 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 150,312.38749
Policy Entropy: 3.65407
Value Function Loss: 0.02865

Mean KL Divergence: 0.01103
SB3 Clip Fraction: 0.14911
Policy Update Magnitude: 0.39524
Value Function Update Magnitude: 0.37495

Collected Steps per Second: 20,355.10300
Overall Steps per Second: 10,019.01092

Timestep Collection Time: 2.45747
Timestep Consumption Time: 2.53524
PPO Batch Consumption Time: 0.28343
Total Iteration Time: 4.99271

Cumulative Model Updates: 93,820
Cumulative Timesteps: 782,360,756

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 273,311.17526
Policy Entropy: 3.65804
Value Function Loss: 0.03255

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.13779
Policy Update Magnitude: 0.39795
Value Function Update Magnitude: 0.40485

Collected Steps per Second: 21,764.84591
Overall Steps per Second: 10,502.30634

Timestep Collection Time: 2.29747
Timestep Consumption Time: 2.46377
PPO Batch Consumption Time: 0.28421
Total Iteration Time: 4.76124

Cumulative Model Updates: 93,826
Cumulative Timesteps: 782,410,760

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 782410760...
Checkpoint 782410760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 95,317.21403
Policy Entropy: 3.65229
Value Function Loss: 0.03374

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.13956
Policy Update Magnitude: 0.43207
Value Function Update Magnitude: 0.41629

Collected Steps per Second: 21,683.24082
Overall Steps per Second: 10,408.54897

Timestep Collection Time: 2.30602
Timestep Consumption Time: 2.49792
PPO Batch Consumption Time: 0.28314
Total Iteration Time: 4.80394

Cumulative Model Updates: 93,832
Cumulative Timesteps: 782,460,762

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62,549.08819
Policy Entropy: 3.64652
Value Function Loss: 0.03420

Mean KL Divergence: 0.01091
SB3 Clip Fraction: 0.14899
Policy Update Magnitude: 0.45612
Value Function Update Magnitude: 0.51155

Collected Steps per Second: 19,592.83742
Overall Steps per Second: 9,857.20457

Timestep Collection Time: 2.55236
Timestep Consumption Time: 2.52088
PPO Batch Consumption Time: 0.29535
Total Iteration Time: 5.07324

Cumulative Model Updates: 93,838
Cumulative Timesteps: 782,510,770

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 782510770...
Checkpoint 782510770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 62,549.08819
Policy Entropy: 3.61536
Value Function Loss: 0.03561

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.14251
Policy Update Magnitude: 0.45533
Value Function Update Magnitude: 0.62846

Collected Steps per Second: 21,273.50940
Overall Steps per Second: 10,233.47938

Timestep Collection Time: 2.35147
Timestep Consumption Time: 2.53680
PPO Batch Consumption Time: 0.29010
Total Iteration Time: 4.88827

Cumulative Model Updates: 93,844
Cumulative Timesteps: 782,560,794

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57,088.95802
Policy Entropy: 3.61996
Value Function Loss: 0.03673

Mean KL Divergence: 0.01140
SB3 Clip Fraction: 0.15375
Policy Update Magnitude: 0.47209
Value Function Update Magnitude: 0.58699

Collected Steps per Second: 20,569.01916
Overall Steps per Second: 10,099.20722

Timestep Collection Time: 2.43123
Timestep Consumption Time: 2.52045
PPO Batch Consumption Time: 0.28644
Total Iteration Time: 4.95168

Cumulative Model Updates: 93,850
Cumulative Timesteps: 782,610,802

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 782610802...
Checkpoint 782610802 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 123,395.28976
Policy Entropy: 3.61863
Value Function Loss: 0.04243

Mean KL Divergence: 0.01099
SB3 Clip Fraction: 0.15238
Policy Update Magnitude: 0.48180
Value Function Update Magnitude: 0.48274

Collected Steps per Second: 19,947.75936
Overall Steps per Second: 9,946.49355

Timestep Collection Time: 2.50755
Timestep Consumption Time: 2.52136
PPO Batch Consumption Time: 0.28510
Total Iteration Time: 5.02891

Cumulative Model Updates: 93,856
Cumulative Timesteps: 782,660,822

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 123,395.28976
Policy Entropy: 3.64301
Value Function Loss: 0.03496

Mean KL Divergence: 0.01080
SB3 Clip Fraction: 0.15060
Policy Update Magnitude: 0.43712
Value Function Update Magnitude: 0.46968

Collected Steps per Second: 21,831.27852
Overall Steps per Second: 10,259.39007

Timestep Collection Time: 2.29121
Timestep Consumption Time: 2.58433
PPO Batch Consumption Time: 0.29089
Total Iteration Time: 4.87553

Cumulative Model Updates: 93,862
Cumulative Timesteps: 782,710,842

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 782710842...
Checkpoint 782710842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 123,395.28976
Policy Entropy: 3.64339
Value Function Loss: 0.03430

Mean KL Divergence: 0.01117
SB3 Clip Fraction: 0.15227
Policy Update Magnitude: 0.40546
Value Function Update Magnitude: 0.45235

Collected Steps per Second: 21,793.38876
Overall Steps per Second: 10,171.84765

Timestep Collection Time: 2.29510
Timestep Consumption Time: 2.62220
PPO Batch Consumption Time: 0.30685
Total Iteration Time: 4.91730

Cumulative Model Updates: 93,868
Cumulative Timesteps: 782,760,860

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 399,039.05428
Policy Entropy: 3.65679
Value Function Loss: 0.02963

Mean KL Divergence: 0.01084
SB3 Clip Fraction: 0.15177
Policy Update Magnitude: 0.38953
Value Function Update Magnitude: 0.46842

Collected Steps per Second: 20,904.65553
Overall Steps per Second: 10,137.74303

Timestep Collection Time: 2.39430
Timestep Consumption Time: 2.54289
PPO Batch Consumption Time: 0.29108
Total Iteration Time: 4.93719

Cumulative Model Updates: 93,874
Cumulative Timesteps: 782,810,912

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


Saving checkpoint 782810912...
Checkpoint 782810912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 234,028.09038
Policy Entropy: 3.65098
Value Function Loss: 0.03678

Mean KL Divergence: 0.01120
SB3 Clip Fraction: 0.15228
Policy Update Magnitude: 0.37808
Value Function Update Magnitude: 0.48133

Collected Steps per Second: 20,670.49233
Overall Steps per Second: 10,061.21906

Timestep Collection Time: 2.42016
Timestep Consumption Time: 2.55200
PPO Batch Consumption Time: 0.29463
Total Iteration Time: 4.97216

Cumulative Model Updates: 93,880
Cumulative Timesteps: 782,860,938

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63,898.80563
Policy Entropy: 3.66707
Value Function Loss: 0.03556

Mean KL Divergence: 0.01119
SB3 Clip Fraction: 0.15184
Policy Update Magnitude: 0.44652
Value Function Update Magnitude: 0.52964

Collected Steps per Second: 21,165.01202
Overall Steps per Second: 10,254.34900

Timestep Collection Time: 2.36447
Timestep Consumption Time: 2.51580
PPO Batch Consumption Time: 0.28763
Total Iteration Time: 4.88027

Cumulative Model Updates: 93,886
Cumulative Timesteps: 782,910,982

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 782910982...
Checkpoint 782910982 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 63,757.39636
Policy Entropy: 3.67411
Value Function Loss: 0.03761

Mean KL Divergence: 0.01164
SB3 Clip Fraction: 0.15662
Policy Update Magnitude: 0.46842
Value Function Update Magnitude: 0.52958

Collected Steps per Second: 20,375.53946
Overall Steps per Second: 10,003.71149

Timestep Collection Time: 2.45451
Timestep Consumption Time: 2.54483
PPO Batch Consumption Time: 0.29382
Total Iteration Time: 4.99934

Cumulative Model Updates: 93,892
Cumulative Timesteps: 782,960,994

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,862.27819
Policy Entropy: 3.67760
Value Function Loss: 0.03300

Mean KL Divergence: 0.01083
SB3 Clip Fraction: 0.14597
Policy Update Magnitude: 0.47110
Value Function Update Magnitude: 0.51576

Collected Steps per Second: 20,656.44473
Overall Steps per Second: 10,098.25261

Timestep Collection Time: 2.42113
Timestep Consumption Time: 2.53141
PPO Batch Consumption Time: 0.29586
Total Iteration Time: 4.95254

Cumulative Model Updates: 93,898
Cumulative Timesteps: 783,011,006

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 783011006...
Checkpoint 783011006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,862.27819
Policy Entropy: 3.66392
Value Function Loss: 0.03040

Mean KL Divergence: 0.01150
SB3 Clip Fraction: 0.15357
Policy Update Magnitude: 0.46304
Value Function Update Magnitude: 0.48790

Collected Steps per Second: 18,600.74276
Overall Steps per Second: 9,475.38274

Timestep Collection Time: 2.68806
Timestep Consumption Time: 2.58877
PPO Batch Consumption Time: 0.29494
Total Iteration Time: 5.27683

Cumulative Model Updates: 93,904
Cumulative Timesteps: 783,061,006

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 267,406.15319
Policy Entropy: 3.65196
Value Function Loss: 0.03153

Mean KL Divergence: 0.01071
SB3 Clip Fraction: 0.14470
Policy Update Magnitude: 0.45320
Value Function Update Magnitude: 0.51593

Collected Steps per Second: 20,642.23563
Overall Steps per Second: 10,206.94255

Timestep Collection Time: 2.42270
Timestep Consumption Time: 2.47690
PPO Batch Consumption Time: 0.29393
Total Iteration Time: 4.89961

Cumulative Model Updates: 93,910
Cumulative Timesteps: 783,111,016

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 783111016...
Checkpoint 783111016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 175,451.86726
Policy Entropy: 3.65838
Value Function Loss: 0.03314

Mean KL Divergence: 0.01118
SB3 Clip Fraction: 0.15129
Policy Update Magnitude: 0.44471
Value Function Update Magnitude: 0.52255

Collected Steps per Second: 20,788.58619
Overall Steps per Second: 10,006.00400

Timestep Collection Time: 2.40565
Timestep Consumption Time: 2.59235
PPO Batch Consumption Time: 0.30066
Total Iteration Time: 4.99800

Cumulative Model Updates: 93,916
Cumulative Timesteps: 783,161,026

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 155,067.57768
Policy Entropy: 3.63785
Value Function Loss: 0.04835

Mean KL Divergence: 0.01121
SB3 Clip Fraction: 0.15312
Policy Update Magnitude: 0.44494
Value Function Update Magnitude: 0.45322

Collected Steps per Second: 21,440.21186
Overall Steps per Second: 10,154.80660

Timestep Collection Time: 2.33319
Timestep Consumption Time: 2.59295
PPO Batch Consumption Time: 0.29955
Total Iteration Time: 4.92614

Cumulative Model Updates: 93,922
Cumulative Timesteps: 783,211,050

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 783211050...
Checkpoint 783211050 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 122,383.54713
Policy Entropy: 3.65398
Value Function Loss: 0.04865

Mean KL Divergence: 0.01078
SB3 Clip Fraction: 0.14568
Policy Update Magnitude: 0.47871
Value Function Update Magnitude: 0.43444

Collected Steps per Second: 21,745.43188
Overall Steps per Second: 10,294.71123

Timestep Collection Time: 2.29933
Timestep Consumption Time: 2.55753
PPO Batch Consumption Time: 0.30343
Total Iteration Time: 4.85686

Cumulative Model Updates: 93,928
Cumulative Timesteps: 783,261,050

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 122,383.54713
Policy Entropy: 3.62871
Value Function Loss: 0.05417

Mean KL Divergence: 0.01080
SB3 Clip Fraction: 0.14448
Policy Update Magnitude: 0.48399
Value Function Update Magnitude: 0.44023

Collected Steps per Second: 20,436.04970
Overall Steps per Second: 10,226.49733

Timestep Collection Time: 2.44724
Timestep Consumption Time: 2.44319
PPO Batch Consumption Time: 0.28376
Total Iteration Time: 4.89043

Cumulative Model Updates: 93,934
Cumulative Timesteps: 783,311,062

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 783311062...
Checkpoint 783311062 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87,274.81256
Policy Entropy: 3.64078
Value Function Loss: 0.04499

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.13464
Policy Update Magnitude: 0.52152
Value Function Update Magnitude: 0.42142

Collected Steps per Second: 20,592.14160
Overall Steps per Second: 10,033.54927

Timestep Collection Time: 2.42918
Timestep Consumption Time: 2.55629
PPO Batch Consumption Time: 0.29754
Total Iteration Time: 4.98547

Cumulative Model Updates: 93,940
Cumulative Timesteps: 783,361,084

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87,274.81256
Policy Entropy: 3.61361
Value Function Loss: 0.04282

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.14123
Policy Update Magnitude: 0.49629
Value Function Update Magnitude: 0.41913

Collected Steps per Second: 21,851.75401
Overall Steps per Second: 10,363.63477

Timestep Collection Time: 2.28943
Timestep Consumption Time: 2.53784
PPO Batch Consumption Time: 0.29055
Total Iteration Time: 4.82726

Cumulative Model Updates: 93,946
Cumulative Timesteps: 783,411,112

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 783411112...
Checkpoint 783411112 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87,274.81256
Policy Entropy: 3.63077
Value Function Loss: 0.03584

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.13410
Policy Update Magnitude: 0.50205
Value Function Update Magnitude: 0.43738

Collected Steps per Second: 19,722.65475
Overall Steps per Second: 9,926.51501

Timestep Collection Time: 2.53566
Timestep Consumption Time: 2.50236
PPO Batch Consumption Time: 0.29338
Total Iteration Time: 5.03802

Cumulative Model Updates: 93,952
Cumulative Timesteps: 783,461,122

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87,274.81256
Policy Entropy: 3.61254
Value Function Loss: 0.03407

Mean KL Divergence: 0.01086
SB3 Clip Fraction: 0.14895
Policy Update Magnitude: 0.48221
Value Function Update Magnitude: 0.49852

Collected Steps per Second: 20,564.17911
Overall Steps per Second: 10,130.83010

Timestep Collection Time: 2.43297
Timestep Consumption Time: 2.50562
PPO Batch Consumption Time: 0.29531
Total Iteration Time: 4.93859

Cumulative Model Updates: 93,958
Cumulative Timesteps: 783,511,154

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 783511154...
Checkpoint 783511154 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87,274.81256
Policy Entropy: 3.62620
Value Function Loss: 0.02947

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.14225
Policy Update Magnitude: 0.45188
Value Function Update Magnitude: 0.47626

Collected Steps per Second: 20,786.27257
Overall Steps per Second: 10,006.49324

Timestep Collection Time: 2.40668
Timestep Consumption Time: 2.59267
PPO Batch Consumption Time: 0.29525
Total Iteration Time: 4.99935

Cumulative Model Updates: 93,964
Cumulative Timesteps: 783,561,180

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88,780.63733
Policy Entropy: 3.61593
Value Function Loss: 0.03249

Mean KL Divergence: 0.01092
SB3 Clip Fraction: 0.14787
Policy Update Magnitude: 0.41776
Value Function Update Magnitude: 0.42194

Collected Steps per Second: 20,611.96539
Overall Steps per Second: 10,418.61444

Timestep Collection Time: 2.42587
Timestep Consumption Time: 2.37342
PPO Batch Consumption Time: 0.28471
Total Iteration Time: 4.79929

Cumulative Model Updates: 93,970
Cumulative Timesteps: 783,611,182

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 783611182...
Checkpoint 783611182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 82,818.62569
Policy Entropy: 3.62881
Value Function Loss: 0.03364

Mean KL Divergence: 0.01078
SB3 Clip Fraction: 0.14892
Policy Update Magnitude: 0.41430
Value Function Update Magnitude: 0.41041

Collected Steps per Second: 18,200.70087
Overall Steps per Second: 9,538.32526

Timestep Collection Time: 2.74759
Timestep Consumption Time: 2.49526
PPO Batch Consumption Time: 0.29311
Total Iteration Time: 5.24285

Cumulative Model Updates: 93,976
Cumulative Timesteps: 783,661,190

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54,381.97574
Policy Entropy: 3.62419
Value Function Loss: 0.03612

Mean KL Divergence: 0.01158
SB3 Clip Fraction: 0.16078
Policy Update Magnitude: 0.41435
Value Function Update Magnitude: 0.48206

Collected Steps per Second: 21,493.12078
Overall Steps per Second: 10,199.31701

Timestep Collection Time: 2.32679
Timestep Consumption Time: 2.57648
PPO Batch Consumption Time: 0.29993
Total Iteration Time: 4.90327

Cumulative Model Updates: 93,982
Cumulative Timesteps: 783,711,200

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 783711200...
Checkpoint 783711200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 101,843.25295
Policy Entropy: 3.63992
Value Function Loss: 0.03686

Mean KL Divergence: 0.01213
SB3 Clip Fraction: 0.16556
Policy Update Magnitude: 0.41325
Value Function Update Magnitude: 0.46512

Collected Steps per Second: 20,853.66041
Overall Steps per Second: 10,214.48291

Timestep Collection Time: 2.39910
Timestep Consumption Time: 2.49885
PPO Batch Consumption Time: 0.29395
Total Iteration Time: 4.89795

Cumulative Model Updates: 93,988
Cumulative Timesteps: 783,761,230

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82,507.32098
Policy Entropy: 3.64628
Value Function Loss: 0.03433

Mean KL Divergence: 0.01158
SB3 Clip Fraction: 0.15930
Policy Update Magnitude: 0.39809
Value Function Update Magnitude: 0.46018

Collected Steps per Second: 22,580.79759
Overall Steps per Second: 10,523.04223

Timestep Collection Time: 2.21569
Timestep Consumption Time: 2.53883
PPO Batch Consumption Time: 0.29512
Total Iteration Time: 4.75452

Cumulative Model Updates: 93,994
Cumulative Timesteps: 783,811,262

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 783811262...
Checkpoint 783811262 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 188,479.78459
Policy Entropy: 3.64018
Value Function Loss: 0.03710

Mean KL Divergence: 0.01146
SB3 Clip Fraction: 0.15000
Policy Update Magnitude: 0.41045
Value Function Update Magnitude: 0.45343

Collected Steps per Second: 21,519.88953
Overall Steps per Second: 10,407.10321

Timestep Collection Time: 2.32418
Timestep Consumption Time: 2.48177
PPO Batch Consumption Time: 0.28333
Total Iteration Time: 4.80595

Cumulative Model Updates: 94,000
Cumulative Timesteps: 783,861,278

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 123,883.62829
Policy Entropy: 3.63591
Value Function Loss: 0.03515

Mean KL Divergence: 0.01217
SB3 Clip Fraction: 0.15553
Policy Update Magnitude: 0.45495
Value Function Update Magnitude: 0.50815

Collected Steps per Second: 21,809.23057
Overall Steps per Second: 10,282.83152

Timestep Collection Time: 2.29380
Timestep Consumption Time: 2.57120
PPO Batch Consumption Time: 0.29901
Total Iteration Time: 4.86500

Cumulative Model Updates: 94,006
Cumulative Timesteps: 783,911,304

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 783911304...
Checkpoint 783911304 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 195,452.11496
Policy Entropy: 3.64828
Value Function Loss: 0.03708

Mean KL Divergence: 0.01206
SB3 Clip Fraction: 0.15742
Policy Update Magnitude: 0.49427
Value Function Update Magnitude: 0.56484

Collected Steps per Second: 22,071.66599
Overall Steps per Second: 10,396.41078

Timestep Collection Time: 2.26535
Timestep Consumption Time: 2.54400
PPO Batch Consumption Time: 0.29421
Total Iteration Time: 4.80935

Cumulative Model Updates: 94,012
Cumulative Timesteps: 783,961,304

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 131,445.63927
Policy Entropy: 3.67156
Value Function Loss: 0.03550

Mean KL Divergence: 0.01099
SB3 Clip Fraction: 0.14811
Policy Update Magnitude: 0.51500
Value Function Update Magnitude: 0.57902

Collected Steps per Second: 21,427.75327
Overall Steps per Second: 10,151.28173

Timestep Collection Time: 2.33538
Timestep Consumption Time: 2.59424
PPO Batch Consumption Time: 0.29870
Total Iteration Time: 4.92962

Cumulative Model Updates: 94,018
Cumulative Timesteps: 784,011,346

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 784011346...
Checkpoint 784011346 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,827.40465
Policy Entropy: 3.69260
Value Function Loss: 0.03713

Mean KL Divergence: 0.01095
SB3 Clip Fraction: 0.14750
Policy Update Magnitude: 0.50144
Value Function Update Magnitude: 0.55425

Collected Steps per Second: 21,987.30914
Overall Steps per Second: 10,468.06596

Timestep Collection Time: 2.27468
Timestep Consumption Time: 2.50309
PPO Batch Consumption Time: 0.28875
Total Iteration Time: 4.77777

Cumulative Model Updates: 94,024
Cumulative Timesteps: 784,061,360

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 150,056.22973
Policy Entropy: 3.66289
Value Function Loss: 0.04145

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.14106
Policy Update Magnitude: 0.47977
Value Function Update Magnitude: 0.53562

Collected Steps per Second: 22,264.86273
Overall Steps per Second: 10,244.95221

Timestep Collection Time: 2.24596
Timestep Consumption Time: 2.63508
PPO Batch Consumption Time: 0.30909
Total Iteration Time: 4.88104

Cumulative Model Updates: 94,030
Cumulative Timesteps: 784,111,366

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 784111366...
Checkpoint 784111366 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 150,056.22973
Policy Entropy: 3.63738
Value Function Loss: 0.03929

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.14687
Policy Update Magnitude: 0.48986
Value Function Update Magnitude: 0.54262

Collected Steps per Second: 20,884.59588
Overall Steps per Second: 10,492.29186

Timestep Collection Time: 2.39478
Timestep Consumption Time: 2.37196
PPO Batch Consumption Time: 0.28027
Total Iteration Time: 4.76674

Cumulative Model Updates: 94,036
Cumulative Timesteps: 784,161,380

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 518,210.36485
Policy Entropy: 3.60816
Value Function Loss: 0.04172

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.14223
Policy Update Magnitude: 0.45998
Value Function Update Magnitude: 0.48964

Collected Steps per Second: 21,510.82689
Overall Steps per Second: 10,431.30111

Timestep Collection Time: 2.32590
Timestep Consumption Time: 2.47044
PPO Batch Consumption Time: 0.29663
Total Iteration Time: 4.79633

Cumulative Model Updates: 94,042
Cumulative Timesteps: 784,211,412

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 784211412...
Checkpoint 784211412 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 63,009.65275
Policy Entropy: 3.64449
Value Function Loss: 0.03738

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.14237
Policy Update Magnitude: 0.41499
Value Function Update Magnitude: 0.46815

Collected Steps per Second: 21,449.03534
Overall Steps per Second: 10,577.37433

Timestep Collection Time: 2.33139
Timestep Consumption Time: 2.39625
PPO Batch Consumption Time: 0.28367
Total Iteration Time: 4.72764

Cumulative Model Updates: 94,048
Cumulative Timesteps: 784,261,418

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 170,129.93507
Policy Entropy: 3.65612
Value Function Loss: 0.04277

Mean KL Divergence: 0.01086
SB3 Clip Fraction: 0.14593
Policy Update Magnitude: 0.41626
Value Function Update Magnitude: 0.47238

Collected Steps per Second: 21,706.13953
Overall Steps per Second: 10,493.89125

Timestep Collection Time: 2.30479
Timestep Consumption Time: 2.46256
PPO Batch Consumption Time: 0.28483
Total Iteration Time: 4.76734

Cumulative Model Updates: 94,054
Cumulative Timesteps: 784,311,446

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 784311446...
Checkpoint 784311446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 322,989.87217
Policy Entropy: 3.64909
Value Function Loss: 0.04309

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.13597
Policy Update Magnitude: 0.46197
Value Function Update Magnitude: 0.55314

Collected Steps per Second: 21,463.88057
Overall Steps per Second: 10,349.71139

Timestep Collection Time: 2.33173
Timestep Consumption Time: 2.50396
PPO Batch Consumption Time: 0.29547
Total Iteration Time: 4.83569

Cumulative Model Updates: 94,060
Cumulative Timesteps: 784,361,494

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84,006.88894
Policy Entropy: 3.65335
Value Function Loss: 0.04262

Mean KL Divergence: 0.01098
SB3 Clip Fraction: 0.14884
Policy Update Magnitude: 0.51807
Value Function Update Magnitude: 0.53192

Collected Steps per Second: 22,327.12905
Overall Steps per Second: 10,659.45646

Timestep Collection Time: 2.23979
Timestep Consumption Time: 2.45163
PPO Batch Consumption Time: 0.28377
Total Iteration Time: 4.69142

Cumulative Model Updates: 94,066
Cumulative Timesteps: 784,411,502

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 784411502...
Checkpoint 784411502 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 144,364.44554
Policy Entropy: 3.66113
Value Function Loss: 0.04469

Mean KL Divergence: 0.01057
SB3 Clip Fraction: 0.14168
Policy Update Magnitude: 0.52701
Value Function Update Magnitude: 0.48126

Collected Steps per Second: 21,887.92334
Overall Steps per Second: 10,357.72387

Timestep Collection Time: 2.28446
Timestep Consumption Time: 2.54305
PPO Batch Consumption Time: 0.29655
Total Iteration Time: 4.82751

Cumulative Model Updates: 94,072
Cumulative Timesteps: 784,461,504

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 137,898.04605
Policy Entropy: 3.68375
Value Function Loss: 0.04366

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.13464
Policy Update Magnitude: 0.49081
Value Function Update Magnitude: 0.49407

Collected Steps per Second: 22,027.98726
Overall Steps per Second: 10,407.05597

Timestep Collection Time: 2.26984
Timestep Consumption Time: 2.53459
PPO Batch Consumption Time: 0.29468
Total Iteration Time: 4.80443

Cumulative Model Updates: 94,078
Cumulative Timesteps: 784,511,504

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 784511504...
Checkpoint 784511504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 137,898.04605
Policy Entropy: 3.65244
Value Function Loss: 0.04055

Mean KL Divergence: 0.01098
SB3 Clip Fraction: 0.15467
Policy Update Magnitude: 0.45325
Value Function Update Magnitude: 0.52333

Collected Steps per Second: 21,940.07745
Overall Steps per Second: 10,388.18500

Timestep Collection Time: 2.27985
Timestep Consumption Time: 2.53524
PPO Batch Consumption Time: 0.29309
Total Iteration Time: 4.81509

Cumulative Model Updates: 94,084
Cumulative Timesteps: 784,561,524

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 98,852.49168
Policy Entropy: 3.65116
Value Function Loss: 0.03947

Mean KL Divergence: 0.01089
SB3 Clip Fraction: 0.15473
Policy Update Magnitude: 0.42279
Value Function Update Magnitude: 0.50076

Collected Steps per Second: 22,403.71129
Overall Steps per Second: 10,490.56829

Timestep Collection Time: 2.23267
Timestep Consumption Time: 2.53543
PPO Batch Consumption Time: 0.29236
Total Iteration Time: 4.76809

Cumulative Model Updates: 94,090
Cumulative Timesteps: 784,611,544

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 784611544...
Checkpoint 784611544 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 602,581.49168
Policy Entropy: 3.64936
Value Function Loss: 0.03579

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.15150
Policy Update Magnitude: 0.39927
Value Function Update Magnitude: 0.47801

Collected Steps per Second: 22,303.28896
Overall Steps per Second: 10,465.59639

Timestep Collection Time: 2.24191
Timestep Consumption Time: 2.53584
PPO Batch Consumption Time: 0.29671
Total Iteration Time: 4.77775

Cumulative Model Updates: 94,096
Cumulative Timesteps: 784,661,546

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 677,018.65044
Policy Entropy: 3.64286
Value Function Loss: 0.03909

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.15357
Policy Update Magnitude: 0.39395
Value Function Update Magnitude: 0.48212

Collected Steps per Second: 22,471.65673
Overall Steps per Second: 10,516.17200

Timestep Collection Time: 2.22609
Timestep Consumption Time: 2.53077
PPO Batch Consumption Time: 0.29552
Total Iteration Time: 4.75686

Cumulative Model Updates: 94,102
Cumulative Timesteps: 784,711,570

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 784711570...
Checkpoint 784711570 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 178,632.85793
Policy Entropy: 3.65709
Value Function Loss: 0.03742

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.14381
Policy Update Magnitude: 0.41124
Value Function Update Magnitude: 0.52598

Collected Steps per Second: 20,948.90391
Overall Steps per Second: 10,467.09298

Timestep Collection Time: 2.38714
Timestep Consumption Time: 2.39050
PPO Batch Consumption Time: 0.28310
Total Iteration Time: 4.77764

Cumulative Model Updates: 94,108
Cumulative Timesteps: 784,761,578

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 117,201.37705
Policy Entropy: 3.66052
Value Function Loss: 0.03745

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.14083
Policy Update Magnitude: 0.41546
Value Function Update Magnitude: 0.57596

Collected Steps per Second: 21,264.95938
Overall Steps per Second: 10,489.91669

Timestep Collection Time: 2.35194
Timestep Consumption Time: 2.41587
PPO Batch Consumption Time: 0.28537
Total Iteration Time: 4.76782

Cumulative Model Updates: 94,114
Cumulative Timesteps: 784,811,592

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 784811592...
Checkpoint 784811592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 117,201.37705
Policy Entropy: 3.67692
Value Function Loss: 0.03478

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.14410
Policy Update Magnitude: 0.41337
Value Function Update Magnitude: 0.56563

Collected Steps per Second: 21,601.27368
Overall Steps per Second: 10,605.05819

Timestep Collection Time: 2.31486
Timestep Consumption Time: 2.40025
PPO Batch Consumption Time: 0.28300
Total Iteration Time: 4.71511

Cumulative Model Updates: 94,120
Cumulative Timesteps: 784,861,596

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 117,201.37705
Policy Entropy: 3.66848
Value Function Loss: 0.02986

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.14891
Policy Update Magnitude: 0.40657
Value Function Update Magnitude: 0.58776

Collected Steps per Second: 21,935.00313
Overall Steps per Second: 10,613.52667

Timestep Collection Time: 2.27955
Timestep Consumption Time: 2.43160
PPO Batch Consumption Time: 0.28126
Total Iteration Time: 4.71116

Cumulative Model Updates: 94,126
Cumulative Timesteps: 784,911,598

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 784911598...
Checkpoint 784911598 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 117,201.37705
Policy Entropy: 3.66584
Value Function Loss: 0.02663

Mean KL Divergence: 0.01122
SB3 Clip Fraction: 0.15765
Policy Update Magnitude: 0.38085
Value Function Update Magnitude: 0.53376

Collected Steps per Second: 21,677.19258
Overall Steps per Second: 10,504.25000

Timestep Collection Time: 2.30694
Timestep Consumption Time: 2.45380
PPO Batch Consumption Time: 0.28386
Total Iteration Time: 4.76074

Cumulative Model Updates: 94,132
Cumulative Timesteps: 784,961,606

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 125,949.40094
Policy Entropy: 3.66325
Value Function Loss: 0.03217

Mean KL Divergence: 0.01050
SB3 Clip Fraction: 0.14835
Policy Update Magnitude: 0.39649
Value Function Update Magnitude: 0.52685

Collected Steps per Second: 22,420.01135
Overall Steps per Second: 10,515.38724

Timestep Collection Time: 2.23131
Timestep Consumption Time: 2.52610
PPO Batch Consumption Time: 0.28900
Total Iteration Time: 4.75741

Cumulative Model Updates: 94,138
Cumulative Timesteps: 785,011,632

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 785011632...
Checkpoint 785011632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 199,274.94858
Policy Entropy: 3.65713
Value Function Loss: 0.03526

Mean KL Divergence: 0.01086
SB3 Clip Fraction: 0.15340
Policy Update Magnitude: 0.43939
Value Function Update Magnitude: 0.63170

Collected Steps per Second: 22,091.22030
Overall Steps per Second: 10,567.09208

Timestep Collection Time: 2.26334
Timestep Consumption Time: 2.46833
PPO Batch Consumption Time: 0.28284
Total Iteration Time: 4.73167

Cumulative Model Updates: 94,144
Cumulative Timesteps: 785,061,632

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 309,531.72352
Policy Entropy: 3.65546
Value Function Loss: 0.04345

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.14652
Policy Update Magnitude: 0.48046
Value Function Update Magnitude: 0.77539

Collected Steps per Second: 22,498.13014
Overall Steps per Second: 10,545.07325

Timestep Collection Time: 2.22276
Timestep Consumption Time: 2.51955
PPO Batch Consumption Time: 0.29705
Total Iteration Time: 4.74231

Cumulative Model Updates: 94,150
Cumulative Timesteps: 785,111,640

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 785111640...
Checkpoint 785111640 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 110,814.00137
Policy Entropy: 3.65219
Value Function Loss: 0.04535

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.14744
Policy Update Magnitude: 0.52598
Value Function Update Magnitude: 0.67507

Collected Steps per Second: 22,014.46723
Overall Steps per Second: 10,558.39002

Timestep Collection Time: 2.27214
Timestep Consumption Time: 2.46532
PPO Batch Consumption Time: 0.28301
Total Iteration Time: 4.73746

Cumulative Model Updates: 94,156
Cumulative Timesteps: 785,161,660

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 110,814.00137
Policy Entropy: 3.64555
Value Function Loss: 0.04280

Mean KL Divergence: 0.01071
SB3 Clip Fraction: 0.14696
Policy Update Magnitude: 0.52044
Value Function Update Magnitude: 0.71506

Collected Steps per Second: 22,263.09800
Overall Steps per Second: 10,553.11623

Timestep Collection Time: 2.24632
Timestep Consumption Time: 2.49257
PPO Batch Consumption Time: 0.28459
Total Iteration Time: 4.73888

Cumulative Model Updates: 94,162
Cumulative Timesteps: 785,211,670

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 785211670...
Checkpoint 785211670 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 110,814.00137
Policy Entropy: 3.63804
Value Function Loss: 0.03951

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.14363
Policy Update Magnitude: 0.48457
Value Function Update Magnitude: 0.66333

Collected Steps per Second: 22,166.95725
Overall Steps per Second: 10,537.79611

Timestep Collection Time: 2.25624
Timestep Consumption Time: 2.48991
PPO Batch Consumption Time: 0.28410
Total Iteration Time: 4.74615

Cumulative Model Updates: 94,168
Cumulative Timesteps: 785,261,684

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 190,376.19556
Policy Entropy: 3.64725
Value Function Loss: 0.03215

Mean KL Divergence: 0.01136
SB3 Clip Fraction: 0.15544
Policy Update Magnitude: 0.47255
Value Function Update Magnitude: 0.64664

Collected Steps per Second: 22,404.63018
Overall Steps per Second: 10,558.14199

Timestep Collection Time: 2.23293
Timestep Consumption Time: 2.50540
PPO Batch Consumption Time: 0.28924
Total Iteration Time: 4.73833

Cumulative Model Updates: 94,174
Cumulative Timesteps: 785,311,712

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 785311712...
Checkpoint 785311712 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 124,918.85040
Policy Entropy: 3.65452
Value Function Loss: 0.03735

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.14136
Policy Update Magnitude: 0.45089
Value Function Update Magnitude: 0.55695

Collected Steps per Second: 21,960.37887
Overall Steps per Second: 10,539.39626

Timestep Collection Time: 2.27801
Timestep Consumption Time: 2.46856
PPO Batch Consumption Time: 0.28308
Total Iteration Time: 4.74657

Cumulative Model Updates: 94,180
Cumulative Timesteps: 785,361,738

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 124,918.85040
Policy Entropy: 3.66731
Value Function Loss: 0.03337

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.14450
Policy Update Magnitude: 0.43219
Value Function Update Magnitude: 0.57566

Collected Steps per Second: 22,522.09761
Overall Steps per Second: 10,568.12325

Timestep Collection Time: 2.22093
Timestep Consumption Time: 2.51217
PPO Batch Consumption Time: 0.29086
Total Iteration Time: 4.73310

Cumulative Model Updates: 94,186
Cumulative Timesteps: 785,411,758

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 785411758...
Checkpoint 785411758 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 103,099.84187
Policy Entropy: 3.66735
Value Function Loss: 0.03218

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.14320
Policy Update Magnitude: 0.50456
Value Function Update Magnitude: 0.60974

Collected Steps per Second: 22,175.12683
Overall Steps per Second: 10,582.85192

Timestep Collection Time: 2.25514
Timestep Consumption Time: 2.47024
PPO Batch Consumption Time: 0.28431
Total Iteration Time: 4.72538

Cumulative Model Updates: 94,192
Cumulative Timesteps: 785,461,766

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93,734.67968
Policy Entropy: 3.65169
Value Function Loss: 0.03473

Mean KL Divergence: 0.01230
SB3 Clip Fraction: 0.15895
Policy Update Magnitude: 0.54731
Value Function Update Magnitude: 0.63667

Collected Steps per Second: 20,767.50317
Overall Steps per Second: 10,397.91485

Timestep Collection Time: 2.40819
Timestep Consumption Time: 2.40162
PPO Batch Consumption Time: 0.28310
Total Iteration Time: 4.80981

Cumulative Model Updates: 94,198
Cumulative Timesteps: 785,511,778

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 785511778...
Checkpoint 785511778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,489.72594
Policy Entropy: 3.65634
Value Function Loss: 0.03584

Mean KL Divergence: 0.01365
SB3 Clip Fraction: 0.16740
Policy Update Magnitude: 0.56219
Value Function Update Magnitude: 0.74293

Collected Steps per Second: 20,199.36198
Overall Steps per Second: 10,232.24835

Timestep Collection Time: 2.47602
Timestep Consumption Time: 2.41186
PPO Batch Consumption Time: 0.28331
Total Iteration Time: 4.88788

Cumulative Model Updates: 94,204
Cumulative Timesteps: 785,561,792

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,250.04655
Policy Entropy: 3.66667
Value Function Loss: 0.03597

Mean KL Divergence: 0.01423
SB3 Clip Fraction: 0.16433
Policy Update Magnitude: 0.61973
Value Function Update Magnitude: 0.63408

Collected Steps per Second: 21,574.54507
Overall Steps per Second: 10,519.39690

Timestep Collection Time: 2.31903
Timestep Consumption Time: 2.43714
PPO Batch Consumption Time: 0.28940
Total Iteration Time: 4.75617

Cumulative Model Updates: 94,210
Cumulative Timesteps: 785,611,824

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 785611824...
Checkpoint 785611824 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,292.98926
Policy Entropy: 3.67614
Value Function Loss: 0.03626

Mean KL Divergence: 0.01375
SB3 Clip Fraction: 0.17690
Policy Update Magnitude: 0.59526
Value Function Update Magnitude: 0.60866

Collected Steps per Second: 21,518.36061
Overall Steps per Second: 10,302.54256

Timestep Collection Time: 2.32490
Timestep Consumption Time: 2.53099
PPO Batch Consumption Time: 0.29631
Total Iteration Time: 4.85589

Cumulative Model Updates: 94,216
Cumulative Timesteps: 785,661,852

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,154.61668
Policy Entropy: 3.68655
Value Function Loss: 0.03230

Mean KL Divergence: 0.00701
SB3 Clip Fraction: 0.08730
Policy Update Magnitude: 0.65594
Value Function Update Magnitude: 0.56310

Collected Steps per Second: 22,058.88710
Overall Steps per Second: 10,422.70783

Timestep Collection Time: 2.26702
Timestep Consumption Time: 2.53096
PPO Batch Consumption Time: 0.29701
Total Iteration Time: 4.79799

Cumulative Model Updates: 94,222
Cumulative Timesteps: 785,711,860

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 785711860...
Checkpoint 785711860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87,204.34248
Policy Entropy: 3.67231
Value Function Loss: 0.03056

Mean KL Divergence: 0.01377
SB3 Clip Fraction: 0.17299
Policy Update Magnitude: 0.60589
Value Function Update Magnitude: 0.57148

Collected Steps per Second: 22,025.14856
Overall Steps per Second: 10,589.10099

Timestep Collection Time: 2.27104
Timestep Consumption Time: 2.45268
PPO Batch Consumption Time: 0.28415
Total Iteration Time: 4.72372

Cumulative Model Updates: 94,228
Cumulative Timesteps: 785,761,880

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46,346.44338
Policy Entropy: 3.66196
Value Function Loss: 0.03554

Mean KL Divergence: 0.01156
SB3 Clip Fraction: 0.15215
Policy Update Magnitude: 0.48759
Value Function Update Magnitude: 0.52672

Collected Steps per Second: 22,253.11796
Overall Steps per Second: 10,506.42979

Timestep Collection Time: 2.24742
Timestep Consumption Time: 2.51272
PPO Batch Consumption Time: 0.28624
Total Iteration Time: 4.76013

Cumulative Model Updates: 94,234
Cumulative Timesteps: 785,811,892

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 785811892...
Checkpoint 785811892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46,346.44338
Policy Entropy: 3.65776
Value Function Loss: 0.03775

Mean KL Divergence: 0.01275
SB3 Clip Fraction: 0.16477
Policy Update Magnitude: 0.51799
Value Function Update Magnitude: 0.49031

Collected Steps per Second: 21,501.19480
Overall Steps per Second: 10,219.16541

Timestep Collection Time: 2.32666
Timestep Consumption Time: 2.56865
PPO Batch Consumption Time: 0.29704
Total Iteration Time: 4.89531

Cumulative Model Updates: 94,240
Cumulative Timesteps: 785,861,918

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56,629.48498
Policy Entropy: 3.66859
Value Function Loss: 0.03860

Mean KL Divergence: 0.01532
SB3 Clip Fraction: 0.19490
Policy Update Magnitude: 0.50375
Value Function Update Magnitude: 0.53165

Collected Steps per Second: 22,476.83484
Overall Steps per Second: 10,500.82400

Timestep Collection Time: 2.22496
Timestep Consumption Time: 2.53753
PPO Batch Consumption Time: 0.29715
Total Iteration Time: 4.76248

Cumulative Model Updates: 94,246
Cumulative Timesteps: 785,911,928

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 785911928...
Checkpoint 785911928 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 56,629.48498
Policy Entropy: 3.67473
Value Function Loss: 0.03700

Mean KL Divergence: 0.01465
SB3 Clip Fraction: 0.17950
Policy Update Magnitude: 0.51891
Value Function Update Magnitude: 0.67134

Collected Steps per Second: 21,970.78746
Overall Steps per Second: 10,524.00477

Timestep Collection Time: 2.27602
Timestep Consumption Time: 2.47559
PPO Batch Consumption Time: 0.28361
Total Iteration Time: 4.75161

Cumulative Model Updates: 94,252
Cumulative Timesteps: 785,961,934

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 406,355.11883
Policy Entropy: 3.65413
Value Function Loss: 0.04764

Mean KL Divergence: 0.01278
SB3 Clip Fraction: 0.16494
Policy Update Magnitude: 0.51890
Value Function Update Magnitude: 0.56612

Collected Steps per Second: 22,153.02546
Overall Steps per Second: 10,497.77896

Timestep Collection Time: 2.25730
Timestep Consumption Time: 2.50618
PPO Batch Consumption Time: 0.28842
Total Iteration Time: 4.76348

Cumulative Model Updates: 94,258
Cumulative Timesteps: 786,011,940

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 786011940...
Checkpoint 786011940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 406,355.11883
Policy Entropy: 3.63117
Value Function Loss: 0.04697

Mean KL Divergence: 0.01145
SB3 Clip Fraction: 0.15170
Policy Update Magnitude: 0.53134
Value Function Update Magnitude: 0.47520

Collected Steps per Second: 21,893.46621
Overall Steps per Second: 10,379.46678

Timestep Collection Time: 2.28488
Timestep Consumption Time: 2.53463
PPO Batch Consumption Time: 0.29415
Total Iteration Time: 4.81952

Cumulative Model Updates: 94,264
Cumulative Timesteps: 786,061,964

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 284,060.01226
Policy Entropy: 3.61375
Value Function Loss: 0.05476

Mean KL Divergence: 0.01119
SB3 Clip Fraction: 0.14513
Policy Update Magnitude: 0.57146
Value Function Update Magnitude: 0.40882

Collected Steps per Second: 22,494.75882
Overall Steps per Second: 10,644.67196

Timestep Collection Time: 2.22283
Timestep Consumption Time: 2.47454
PPO Batch Consumption Time: 0.28481
Total Iteration Time: 4.69737

Cumulative Model Updates: 94,270
Cumulative Timesteps: 786,111,966

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 786111966...
Checkpoint 786111966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 294,041.10579
Policy Entropy: 3.64193
Value Function Loss: 0.05547

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.13488
Policy Update Magnitude: 0.58995
Value Function Update Magnitude: 0.45933

Collected Steps per Second: 22,077.16599
Overall Steps per Second: 10,452.19638

Timestep Collection Time: 2.26524
Timestep Consumption Time: 2.51940
PPO Batch Consumption Time: 0.29479
Total Iteration Time: 4.78464

Cumulative Model Updates: 94,276
Cumulative Timesteps: 786,161,976

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 192,919.73021
Policy Entropy: 3.62983
Value Function Loss: 0.06330

Mean KL Divergence: 0.01122
SB3 Clip Fraction: 0.14366
Policy Update Magnitude: 0.61597
Value Function Update Magnitude: 0.46955

Collected Steps per Second: 22,334.62195
Overall Steps per Second: 10,498.85763

Timestep Collection Time: 2.23868
Timestep Consumption Time: 2.52375
PPO Batch Consumption Time: 0.29207
Total Iteration Time: 4.76242

Cumulative Model Updates: 94,282
Cumulative Timesteps: 786,211,976

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 786211976...
Checkpoint 786211976 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 192,919.73021
Policy Entropy: 3.65836
Value Function Loss: 0.05296

Mean KL Divergence: 0.01143
SB3 Clip Fraction: 0.15189
Policy Update Magnitude: 0.59961
Value Function Update Magnitude: 0.43461

Collected Steps per Second: 22,152.14255
Overall Steps per Second: 10,498.12830

Timestep Collection Time: 2.25838
Timestep Consumption Time: 2.50704
PPO Batch Consumption Time: 0.29180
Total Iteration Time: 4.76542

Cumulative Model Updates: 94,288
Cumulative Timesteps: 786,262,004

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 192,919.73021
Policy Entropy: 3.65152
Value Function Loss: 0.04572

Mean KL Divergence: 0.01071
SB3 Clip Fraction: 0.14639
Policy Update Magnitude: 0.55142
Value Function Update Magnitude: 0.39636

Collected Steps per Second: 21,879.79733
Overall Steps per Second: 10,548.83689

Timestep Collection Time: 2.28604
Timestep Consumption Time: 2.45553
PPO Batch Consumption Time: 0.29613
Total Iteration Time: 4.74157

Cumulative Model Updates: 94,294
Cumulative Timesteps: 786,312,022

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 786312022...
Checkpoint 786312022 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 251,943.22948
Policy Entropy: 3.66961
Value Function Loss: 0.03913

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.13798
Policy Update Magnitude: 0.50908
Value Function Update Magnitude: 0.42470

Collected Steps per Second: 21,535.53868
Overall Steps per Second: 10,524.37239

Timestep Collection Time: 2.32249
Timestep Consumption Time: 2.42991
PPO Batch Consumption Time: 0.28927
Total Iteration Time: 4.75240

Cumulative Model Updates: 94,300
Cumulative Timesteps: 786,362,038

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 616,299.97997
Policy Entropy: 3.65515
Value Function Loss: 0.03747

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.14289
Policy Update Magnitude: 0.53115
Value Function Update Magnitude: 0.49136

Collected Steps per Second: 21,938.71166
Overall Steps per Second: 10,535.53782

Timestep Collection Time: 2.27908
Timestep Consumption Time: 2.46677
PPO Batch Consumption Time: 0.29702
Total Iteration Time: 4.74584

Cumulative Model Updates: 94,306
Cumulative Timesteps: 786,412,038

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 786412038...
Checkpoint 786412038 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 214,899.13881
Policy Entropy: 3.66033
Value Function Loss: 0.03759

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.14322
Policy Update Magnitude: 0.50188
Value Function Update Magnitude: 0.54239

Collected Steps per Second: 21,575.55296
Overall Steps per Second: 10,456.73359

Timestep Collection Time: 2.31772
Timestep Consumption Time: 2.46447
PPO Batch Consumption Time: 0.28433
Total Iteration Time: 4.78218

Cumulative Model Updates: 94,312
Cumulative Timesteps: 786,462,044

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 264,965.07487
Policy Entropy: 3.65789
Value Function Loss: 0.03790

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.14146
Policy Update Magnitude: 0.46923
Value Function Update Magnitude: 0.47518

Collected Steps per Second: 22,454.38935
Overall Steps per Second: 10,548.54701

Timestep Collection Time: 2.22798
Timestep Consumption Time: 2.51466
PPO Batch Consumption Time: 0.29312
Total Iteration Time: 4.74264

Cumulative Model Updates: 94,318
Cumulative Timesteps: 786,512,072

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 786512072...
Checkpoint 786512072 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 320,412.71143
Policy Entropy: 3.65809
Value Function Loss: 0.03886

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.14072
Policy Update Magnitude: 0.47380
Value Function Update Magnitude: 0.47566

Collected Steps per Second: 22,011.84883
Overall Steps per Second: 10,612.54685

Timestep Collection Time: 2.27214
Timestep Consumption Time: 2.44058
PPO Batch Consumption Time: 0.28275
Total Iteration Time: 4.71272

Cumulative Model Updates: 94,324
Cumulative Timesteps: 786,562,086

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 111,825.61549
Policy Entropy: 3.66269
Value Function Loss: 0.03773

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.14105
Policy Update Magnitude: 0.49516
Value Function Update Magnitude: 0.49652

Collected Steps per Second: 22,462.81362
Overall Steps per Second: 10,531.06427

Timestep Collection Time: 2.22706
Timestep Consumption Time: 2.52327
PPO Batch Consumption Time: 0.29108
Total Iteration Time: 4.75033

Cumulative Model Updates: 94,330
Cumulative Timesteps: 786,612,112

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 786612112...
Checkpoint 786612112 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 167,114.45282
Policy Entropy: 3.66471
Value Function Loss: 0.04161

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.14440
Policy Update Magnitude: 0.50581
Value Function Update Magnitude: 0.51402

Collected Steps per Second: 22,018.12627
Overall Steps per Second: 10,546.20047

Timestep Collection Time: 2.27095
Timestep Consumption Time: 2.47029
PPO Batch Consumption Time: 0.28410
Total Iteration Time: 4.74123

Cumulative Model Updates: 94,336
Cumulative Timesteps: 786,662,114

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 109,643.45260
Policy Entropy: 3.65899
Value Function Loss: 0.04100

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.14390
Policy Update Magnitude: 0.50167
Value Function Update Magnitude: 0.47656

Collected Steps per Second: 22,376.50387
Overall Steps per Second: 10,612.71141

Timestep Collection Time: 2.23574
Timestep Consumption Time: 2.47823
PPO Batch Consumption Time: 0.28130
Total Iteration Time: 4.71397

Cumulative Model Updates: 94,342
Cumulative Timesteps: 786,712,142

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 786712142...
Checkpoint 786712142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 109,643.45260
Policy Entropy: 3.65811
Value Function Loss: 0.03730

Mean KL Divergence: 0.01067
SB3 Clip Fraction: 0.14802
Policy Update Magnitude: 0.46420
Value Function Update Magnitude: 0.48322

Collected Steps per Second: 21,307.65589
Overall Steps per Second: 10,240.20950

Timestep Collection Time: 2.34761
Timestep Consumption Time: 2.53725
PPO Batch Consumption Time: 0.29622
Total Iteration Time: 4.88486

Cumulative Model Updates: 94,348
Cumulative Timesteps: 786,762,164

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 109,643.45260
Policy Entropy: 3.64169
Value Function Loss: 0.03046

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.14558
Policy Update Magnitude: 0.40940
Value Function Update Magnitude: 0.45079

Collected Steps per Second: 22,685.36037
Overall Steps per Second: 10,567.49912

Timestep Collection Time: 2.20503
Timestep Consumption Time: 2.52854
PPO Batch Consumption Time: 0.29176
Total Iteration Time: 4.73357

Cumulative Model Updates: 94,354
Cumulative Timesteps: 786,812,186

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 786812186...
Checkpoint 786812186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 109,643.45260
Policy Entropy: 3.65613
Value Function Loss: 0.02566

Mean KL Divergence: 0.01059
SB3 Clip Fraction: 0.15198
Policy Update Magnitude: 0.36737
Value Function Update Magnitude: 0.41329

Collected Steps per Second: 22,648.43835
Overall Steps per Second: 10,543.65947

Timestep Collection Time: 2.20863
Timestep Consumption Time: 2.53564
PPO Batch Consumption Time: 0.29460
Total Iteration Time: 4.74427

Cumulative Model Updates: 94,360
Cumulative Timesteps: 786,862,208

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 816,925.46227
Policy Entropy: 3.66567
Value Function Loss: 0.03085

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.13914
Policy Update Magnitude: 0.38287
Value Function Update Magnitude: 0.45025

Collected Steps per Second: 22,379.90165
Overall Steps per Second: 10,485.44486

Timestep Collection Time: 2.23504
Timestep Consumption Time: 2.53538
PPO Batch Consumption Time: 0.29510
Total Iteration Time: 4.77042

Cumulative Model Updates: 94,366
Cumulative Timesteps: 786,912,228

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 786912228...
Checkpoint 786912228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 351,680.78589
Policy Entropy: 3.67904
Value Function Loss: 0.03155

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.14486
Policy Update Magnitude: 0.44827
Value Function Update Magnitude: 0.49773

Collected Steps per Second: 22,187.07561
Overall Steps per Second: 10,538.41345

Timestep Collection Time: 2.25456
Timestep Consumption Time: 2.49208
PPO Batch Consumption Time: 0.28820
Total Iteration Time: 4.74663

Cumulative Model Updates: 94,372
Cumulative Timesteps: 786,962,250

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 351,680.78589
Policy Entropy: 3.66622
Value Function Loss: 0.02895

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.15156
Policy Update Magnitude: 0.44423
Value Function Update Magnitude: 0.53480

Collected Steps per Second: 22,276.91720
Overall Steps per Second: 10,407.11670

Timestep Collection Time: 2.24546
Timestep Consumption Time: 2.56106
PPO Batch Consumption Time: 0.29910
Total Iteration Time: 4.80652

Cumulative Model Updates: 94,378
Cumulative Timesteps: 787,012,272

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 787012272...
Checkpoint 787012272 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 351,680.78589
Policy Entropy: 3.66085
Value Function Loss: 0.02401

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.14070
Policy Update Magnitude: 0.38437
Value Function Update Magnitude: 0.48544

Collected Steps per Second: 21,461.98219
Overall Steps per Second: 10,569.55834

Timestep Collection Time: 2.32998
Timestep Consumption Time: 2.40115
PPO Batch Consumption Time: 0.28311
Total Iteration Time: 4.73113

Cumulative Model Updates: 94,384
Cumulative Timesteps: 787,062,278

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 351,680.78589
Policy Entropy: 3.66460
Value Function Loss: 0.02397

Mean KL Divergence: 0.01129
SB3 Clip Fraction: 0.15555
Policy Update Magnitude: 0.37522
Value Function Update Magnitude: 0.39307

Collected Steps per Second: 21,897.67151
Overall Steps per Second: 10,492.01205

Timestep Collection Time: 2.28390
Timestep Consumption Time: 2.48278
PPO Batch Consumption Time: 0.29554
Total Iteration Time: 4.76667

Cumulative Model Updates: 94,390
Cumulative Timesteps: 787,112,290

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 787112290...
Checkpoint 787112290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 351,680.78589
Policy Entropy: 3.66324
Value Function Loss: 0.02752

Mean KL Divergence: 0.01053
SB3 Clip Fraction: 0.14857
Policy Update Magnitude: 0.36513
Value Function Update Magnitude: 0.35429

Collected Steps per Second: 21,597.15823
Overall Steps per Second: 10,266.37422

Timestep Collection Time: 2.31512
Timestep Consumption Time: 2.55515
PPO Batch Consumption Time: 0.30366
Total Iteration Time: 4.87027

Cumulative Model Updates: 94,396
Cumulative Timesteps: 787,162,290

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 486,549.02158
Policy Entropy: 3.65791
Value Function Loss: 0.03241

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.14703
Policy Update Magnitude: 0.40710
Value Function Update Magnitude: 0.37070

Collected Steps per Second: 22,562.57568
Overall Steps per Second: 10,631.68501

Timestep Collection Time: 2.21721
Timestep Consumption Time: 2.48816
PPO Batch Consumption Time: 0.29161
Total Iteration Time: 4.70537

Cumulative Model Updates: 94,402
Cumulative Timesteps: 787,212,316

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 787212316...
Checkpoint 787212316 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 299,641.19521
Policy Entropy: 3.65480
Value Function Loss: 0.03540

Mean KL Divergence: 0.01069
SB3 Clip Fraction: 0.14951
Policy Update Magnitude: 0.44397
Value Function Update Magnitude: 0.43076

Collected Steps per Second: 22,584.49261
Overall Steps per Second: 10,589.93034

Timestep Collection Time: 2.21471
Timestep Consumption Time: 2.50846
PPO Batch Consumption Time: 0.29524
Total Iteration Time: 4.72317

Cumulative Model Updates: 94,408
Cumulative Timesteps: 787,262,334

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 544,212.68719
Policy Entropy: 3.65883
Value Function Loss: 0.03823

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.14244
Policy Update Magnitude: 0.49339
Value Function Update Magnitude: 0.44850

Collected Steps per Second: 22,406.22998
Overall Steps per Second: 10,494.81854

Timestep Collection Time: 2.23179
Timestep Consumption Time: 2.53304
PPO Batch Consumption Time: 0.29486
Total Iteration Time: 4.76483

Cumulative Model Updates: 94,414
Cumulative Timesteps: 787,312,340

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 787312340...
Checkpoint 787312340 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 544,212.68719
Policy Entropy: 3.65875
Value Function Loss: 0.03455

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.14508
Policy Update Magnitude: 0.50320
Value Function Update Magnitude: 0.47305

Collected Steps per Second: 22,003.92291
Overall Steps per Second: 10,513.87665

Timestep Collection Time: 2.27341
Timestep Consumption Time: 2.48449
PPO Batch Consumption Time: 0.28325
Total Iteration Time: 4.75790

Cumulative Model Updates: 94,420
Cumulative Timesteps: 787,362,364

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 544,212.68719
Policy Entropy: 3.66580
Value Function Loss: 0.03510

Mean KL Divergence: 0.01108
SB3 Clip Fraction: 0.14757
Policy Update Magnitude: 0.49618
Value Function Update Magnitude: 0.55769

Collected Steps per Second: 22,250.47849
Overall Steps per Second: 10,454.69130

Timestep Collection Time: 2.24831
Timestep Consumption Time: 2.53672
PPO Batch Consumption Time: 0.29633
Total Iteration Time: 4.78503

Cumulative Model Updates: 94,426
Cumulative Timesteps: 787,412,390

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 787412390...
Checkpoint 787412390 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 514,745.42676
Policy Entropy: 3.66546
Value Function Loss: 0.03622

Mean KL Divergence: 0.01109
SB3 Clip Fraction: 0.14487
Policy Update Magnitude: 0.54803
Value Function Update Magnitude: 0.63813

Collected Steps per Second: 22,185.90144
Overall Steps per Second: 10,531.57337

Timestep Collection Time: 2.25368
Timestep Consumption Time: 2.49395
PPO Batch Consumption Time: 0.28393
Total Iteration Time: 4.74763

Cumulative Model Updates: 94,432
Cumulative Timesteps: 787,462,390

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 514,745.42676
Policy Entropy: 3.67193
Value Function Loss: 0.03516

Mean KL Divergence: 0.01112
SB3 Clip Fraction: 0.14975
Policy Update Magnitude: 0.57136
Value Function Update Magnitude: 0.58655

Collected Steps per Second: 22,662.50653
Overall Steps per Second: 10,554.14716

Timestep Collection Time: 2.20717
Timestep Consumption Time: 2.53220
PPO Batch Consumption Time: 0.29526
Total Iteration Time: 4.73937

Cumulative Model Updates: 94,438
Cumulative Timesteps: 787,512,410

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 787512410...
Checkpoint 787512410 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 514,745.42676
Policy Entropy: 3.66307
Value Function Loss: 0.03681

Mean KL Divergence: 0.01093
SB3 Clip Fraction: 0.15107
Policy Update Magnitude: 0.50042
Value Function Update Magnitude: 0.49595

Collected Steps per Second: 21,418.84499
Overall Steps per Second: 10,602.26912

Timestep Collection Time: 2.33561
Timestep Consumption Time: 2.38282
PPO Batch Consumption Time: 0.28317
Total Iteration Time: 4.71842

Cumulative Model Updates: 94,444
Cumulative Timesteps: 787,562,436

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 407,584.91764
Policy Entropy: 3.67007
Value Function Loss: 0.03241

Mean KL Divergence: 0.01099
SB3 Clip Fraction: 0.15124
Policy Update Magnitude: 0.44915
Value Function Update Magnitude: 0.48041

Collected Steps per Second: 21,902.80642
Overall Steps per Second: 10,521.20100

Timestep Collection Time: 2.28363
Timestep Consumption Time: 2.47039
PPO Batch Consumption Time: 0.29703
Total Iteration Time: 4.75402

Cumulative Model Updates: 94,450
Cumulative Timesteps: 787,612,454

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 787612454...
Checkpoint 787612454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 436,362.30535
Policy Entropy: 3.66718
Value Function Loss: 0.03577

Mean KL Divergence: 0.01096
SB3 Clip Fraction: 0.15421
Policy Update Magnitude: 0.46169
Value Function Update Magnitude: 0.55955

Collected Steps per Second: 21,511.42645
Overall Steps per Second: 10,583.48355

Timestep Collection Time: 2.32574
Timestep Consumption Time: 2.40144
PPO Batch Consumption Time: 0.28501
Total Iteration Time: 4.72718

Cumulative Model Updates: 94,456
Cumulative Timesteps: 787,662,484

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 353,453.02109
Policy Entropy: 3.66788
Value Function Loss: 0.03679

Mean KL Divergence: 0.01083
SB3 Clip Fraction: 0.14852
Policy Update Magnitude: 0.50956
Value Function Update Magnitude: 0.71256

Collected Steps per Second: 21,500.72664
Overall Steps per Second: 10,454.06055

Timestep Collection Time: 2.32597
Timestep Consumption Time: 2.45782
PPO Batch Consumption Time: 0.28358
Total Iteration Time: 4.78379

Cumulative Model Updates: 94,462
Cumulative Timesteps: 787,712,494

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 787712494...
Checkpoint 787712494 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 353,453.02109
Policy Entropy: 3.64719
Value Function Loss: 0.04036

Mean KL Divergence: 0.01166
SB3 Clip Fraction: 0.15540
Policy Update Magnitude: 0.53609
Value Function Update Magnitude: 0.73221

Collected Steps per Second: 21,976.83039
Overall Steps per Second: 10,608.73548

Timestep Collection Time: 2.27603
Timestep Consumption Time: 2.43895
PPO Batch Consumption Time: 0.28247
Total Iteration Time: 4.71498

Cumulative Model Updates: 94,468
Cumulative Timesteps: 787,762,514

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 324,205.00987
Policy Entropy: 3.66393
Value Function Loss: 0.03830

Mean KL Divergence: 0.01165
SB3 Clip Fraction: 0.15002
Policy Update Magnitude: 0.53900
Value Function Update Magnitude: 0.64440

Collected Steps per Second: 22,019.04296
Overall Steps per Second: 10,490.07404

Timestep Collection Time: 2.27158
Timestep Consumption Time: 2.49655
PPO Batch Consumption Time: 0.29021
Total Iteration Time: 4.76813

Cumulative Model Updates: 94,474
Cumulative Timesteps: 787,812,532

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 787812532...
Checkpoint 787812532 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 74,183.49583
Policy Entropy: 3.66680
Value Function Loss: 0.03714

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.13719
Policy Update Magnitude: 0.54314
Value Function Update Magnitude: 0.55448

Collected Steps per Second: 21,801.15355
Overall Steps per Second: 10,343.49360

Timestep Collection Time: 2.29364
Timestep Consumption Time: 2.54070
PPO Batch Consumption Time: 0.29564
Total Iteration Time: 4.83434

Cumulative Model Updates: 94,480
Cumulative Timesteps: 787,862,536

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,954.25010
Policy Entropy: 3.68325
Value Function Loss: 0.03846

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.13078
Policy Update Magnitude: 0.54456
Value Function Update Magnitude: 0.57239

Collected Steps per Second: 22,168.61746
Overall Steps per Second: 10,416.30486

Timestep Collection Time: 2.25643
Timestep Consumption Time: 2.54585
PPO Batch Consumption Time: 0.29695
Total Iteration Time: 4.80228

Cumulative Model Updates: 94,486
Cumulative Timesteps: 787,912,558

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 787912558...
Checkpoint 787912558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 381,059.67424
Policy Entropy: 3.66762
Value Function Loss: 0.04587

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.13446
Policy Update Magnitude: 0.60274
Value Function Update Magnitude: 0.57712

Collected Steps per Second: 21,964.17402
Overall Steps per Second: 10,537.85959

Timestep Collection Time: 2.27716
Timestep Consumption Time: 2.46915
PPO Batch Consumption Time: 0.28362
Total Iteration Time: 4.74631

Cumulative Model Updates: 94,492
Cumulative Timesteps: 787,962,574

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 197,744.51479
Policy Entropy: 3.66725
Value Function Loss: 0.04812

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.13097
Policy Update Magnitude: 0.64076
Value Function Update Magnitude: 0.70142

Collected Steps per Second: 22,041.45949
Overall Steps per Second: 10,477.07000

Timestep Collection Time: 2.26863
Timestep Consumption Time: 2.50407
PPO Batch Consumption Time: 0.28491
Total Iteration Time: 4.77271

Cumulative Model Updates: 94,498
Cumulative Timesteps: 788,012,578

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 788012578...
Checkpoint 788012578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 68,965.22934
Policy Entropy: 3.66471
Value Function Loss: 0.04613

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.13764
Policy Update Magnitude: 0.70607
Value Function Update Magnitude: 0.85718

Collected Steps per Second: 21,910.09580
Overall Steps per Second: 10,353.05572

Timestep Collection Time: 2.28260
Timestep Consumption Time: 2.54805
PPO Batch Consumption Time: 0.29538
Total Iteration Time: 4.83065

Cumulative Model Updates: 94,504
Cumulative Timesteps: 788,062,590

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 366,775.68408
Policy Entropy: 3.66683
Value Function Loss: 0.03979

Mean KL Divergence: 0.01385
SB3 Clip Fraction: 0.16797
Policy Update Magnitude: 0.68457
Value Function Update Magnitude: 0.71724

Collected Steps per Second: 22,634.93016
Overall Steps per Second: 10,563.63083

Timestep Collection Time: 2.20968
Timestep Consumption Time: 2.52505
PPO Batch Consumption Time: 0.29305
Total Iteration Time: 4.73474

Cumulative Model Updates: 94,510
Cumulative Timesteps: 788,112,606

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 788112606...
Checkpoint 788112606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 348,589.32132
Policy Entropy: 3.66359
Value Function Loss: 0.03604

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.11205
Policy Update Magnitude: 0.69632
Value Function Update Magnitude: 0.59994

Collected Steps per Second: 21,993.73522
Overall Steps per Second: 10,469.29659

Timestep Collection Time: 2.27456
Timestep Consumption Time: 2.50380
PPO Batch Consumption Time: 0.28929
Total Iteration Time: 4.77835

Cumulative Model Updates: 94,516
Cumulative Timesteps: 788,162,632

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 108,910.23731
Policy Entropy: 3.66048
Value Function Loss: 0.04089

Mean KL Divergence: 0.01260
SB3 Clip Fraction: 0.16471
Policy Update Magnitude: 0.65462
Value Function Update Magnitude: 0.79966

Collected Steps per Second: 22,320.63655
Overall Steps per Second: 10,418.86656

Timestep Collection Time: 2.24053
Timestep Consumption Time: 2.55942
PPO Batch Consumption Time: 0.29576
Total Iteration Time: 4.79995

Cumulative Model Updates: 94,522
Cumulative Timesteps: 788,212,642

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 788212642...
Checkpoint 788212642 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 88,219.22652
Policy Entropy: 3.67686
Value Function Loss: 0.03871

Mean KL Divergence: 0.01581
SB3 Clip Fraction: 0.20032
Policy Update Magnitude: 0.53859
Value Function Update Magnitude: 0.80953

Collected Steps per Second: 22,211.44473
Overall Steps per Second: 10,565.11181

Timestep Collection Time: 2.25181
Timestep Consumption Time: 2.48226
PPO Batch Consumption Time: 0.28405
Total Iteration Time: 4.73407

Cumulative Model Updates: 94,528
Cumulative Timesteps: 788,262,658

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 331,446.42935
Policy Entropy: 3.68033
Value Function Loss: 0.04399

Mean KL Divergence: 0.01248
SB3 Clip Fraction: 0.16380
Policy Update Magnitude: 0.49123
Value Function Update Magnitude: 0.63923

Collected Steps per Second: 22,456.73039
Overall Steps per Second: 10,566.16811

Timestep Collection Time: 2.22739
Timestep Consumption Time: 2.50658
PPO Batch Consumption Time: 0.28939
Total Iteration Time: 4.73398

Cumulative Model Updates: 94,534
Cumulative Timesteps: 788,312,678

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 788312678...
Checkpoint 788312678 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 217,474.50959
Policy Entropy: 3.67558
Value Function Loss: 0.04306

Mean KL Divergence: 0.01171
SB3 Clip Fraction: 0.16214
Policy Update Magnitude: 0.45698
Value Function Update Magnitude: 0.48062

Collected Steps per Second: 21,922.39359
Overall Steps per Second: 10,548.92149

Timestep Collection Time: 2.28123
Timestep Consumption Time: 2.45954
PPO Batch Consumption Time: 0.28316
Total Iteration Time: 4.74077

Cumulative Model Updates: 94,540
Cumulative Timesteps: 788,362,688

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 217,474.50959
Policy Entropy: 3.64729
Value Function Loss: 0.04534

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.14104
Policy Update Magnitude: 0.44552
Value Function Update Magnitude: 0.42630

Collected Steps per Second: 22,455.35865
Overall Steps per Second: 10,532.11013

Timestep Collection Time: 2.22744
Timestep Consumption Time: 2.52165
PPO Batch Consumption Time: 0.29144
Total Iteration Time: 4.74910

Cumulative Model Updates: 94,546
Cumulative Timesteps: 788,412,706

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 788412706...
Checkpoint 788412706 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 184,785.17720
Policy Entropy: 3.65704
Value Function Loss: 0.04322

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.14167
Policy Update Magnitude: 0.45640
Value Function Update Magnitude: 0.46275

Collected Steps per Second: 22,358.94065
Overall Steps per Second: 10,630.36871

Timestep Collection Time: 2.23732
Timestep Consumption Time: 2.46845
PPO Batch Consumption Time: 0.28274
Total Iteration Time: 4.70576

Cumulative Model Updates: 94,552
Cumulative Timesteps: 788,462,730

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 184,785.17720
Policy Entropy: 3.64258
Value Function Loss: 0.04002

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.14169
Policy Update Magnitude: 0.46628
Value Function Update Magnitude: 0.57997

Collected Steps per Second: 22,739.59094
Overall Steps per Second: 10,548.36233

Timestep Collection Time: 2.19907
Timestep Consumption Time: 2.54157
PPO Batch Consumption Time: 0.29614
Total Iteration Time: 4.74064

Cumulative Model Updates: 94,558
Cumulative Timesteps: 788,512,736

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 788512736...
Checkpoint 788512736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 184,785.17720
Policy Entropy: 3.64949
Value Function Loss: 0.03588

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.14461
Policy Update Magnitude: 0.46507
Value Function Update Magnitude: 0.59921

Collected Steps per Second: 22,112.97378
Overall Steps per Second: 10,584.73218

Timestep Collection Time: 2.26202
Timestep Consumption Time: 2.46365
PPO Batch Consumption Time: 0.28253
Total Iteration Time: 4.72567

Cumulative Model Updates: 94,564
Cumulative Timesteps: 788,562,756

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 184,785.17720
Policy Entropy: 3.64507
Value Function Loss: 0.03757

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.13557
Policy Update Magnitude: 0.46525
Value Function Update Magnitude: 0.57741

Collected Steps per Second: 22,169.76393
Overall Steps per Second: 10,403.67377

Timestep Collection Time: 2.25623
Timestep Consumption Time: 2.55169
PPO Batch Consumption Time: 0.29103
Total Iteration Time: 4.80792

Cumulative Model Updates: 94,570
Cumulative Timesteps: 788,612,776

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 788612776...
Checkpoint 788612776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 184,785.17720
Policy Entropy: 3.64500
Value Function Loss: 0.03809

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.13550
Policy Update Magnitude: 0.49284
Value Function Update Magnitude: 0.52953

Collected Steps per Second: 22,113.65949
Overall Steps per Second: 10,530.24882

Timestep Collection Time: 2.26204
Timestep Consumption Time: 2.48827
PPO Batch Consumption Time: 0.28617
Total Iteration Time: 4.75032

Cumulative Model Updates: 94,576
Cumulative Timesteps: 788,662,798

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 589,762.81438
Policy Entropy: 3.61849
Value Function Loss: 0.04505

Mean KL Divergence: 0.01095
SB3 Clip Fraction: 0.14164
Policy Update Magnitude: 0.48816
Value Function Update Magnitude: 0.48255

Collected Steps per Second: 22,636.89240
Overall Steps per Second: 10,644.25862

Timestep Collection Time: 2.20905
Timestep Consumption Time: 2.48888
PPO Batch Consumption Time: 0.28764
Total Iteration Time: 4.69793

Cumulative Model Updates: 94,582
Cumulative Timesteps: 788,712,804

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 788712804...
Checkpoint 788712804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 329,915.29086
Policy Entropy: 3.61873
Value Function Loss: 0.04355

Mean KL Divergence: 0.01099
SB3 Clip Fraction: 0.14288
Policy Update Magnitude: 0.50003
Value Function Update Magnitude: 0.50568

Collected Steps per Second: 22,254.09516
Overall Steps per Second: 10,605.36450

Timestep Collection Time: 2.24705
Timestep Consumption Time: 2.46811
PPO Batch Consumption Time: 0.28324
Total Iteration Time: 4.71516

Cumulative Model Updates: 94,588
Cumulative Timesteps: 788,762,810

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 230,092.65160
Policy Entropy: 3.62481
Value Function Loss: 0.05149

Mean KL Divergence: 0.01124
SB3 Clip Fraction: 0.14474
Policy Update Magnitude: 0.57644
Value Function Update Magnitude: 0.43661

Collected Steps per Second: 21,546.71666
Overall Steps per Second: 10,432.85566

Timestep Collection Time: 2.32110
Timestep Consumption Time: 2.47261
PPO Batch Consumption Time: 0.29659
Total Iteration Time: 4.79370

Cumulative Model Updates: 94,594
Cumulative Timesteps: 788,812,822

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 788812822...
Checkpoint 788812822 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 230,590.24813
Policy Entropy: 3.65960
Value Function Loss: 0.04229

Mean KL Divergence: 0.01187
SB3 Clip Fraction: 0.15123
Policy Update Magnitude: 0.62337
Value Function Update Magnitude: 0.41980

Collected Steps per Second: 21,376.14294
Overall Steps per Second: 10,575.63779

Timestep Collection Time: 2.34009
Timestep Consumption Time: 2.38984
PPO Batch Consumption Time: 0.28305
Total Iteration Time: 4.72993

Cumulative Model Updates: 94,600
Cumulative Timesteps: 788,862,844

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 190,746.75534
Policy Entropy: 3.67493
Value Function Loss: 0.03707

Mean KL Divergence: 0.01474
SB3 Clip Fraction: 0.18386
Policy Update Magnitude: 0.65948
Value Function Update Magnitude: 0.55507

Collected Steps per Second: 21,758.61714
Overall Steps per Second: 10,565.89705

Timestep Collection Time: 2.29923
Timestep Consumption Time: 2.43563
PPO Batch Consumption Time: 0.29222
Total Iteration Time: 4.73486

Cumulative Model Updates: 94,606
Cumulative Timesteps: 788,912,872

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 788912872...
Checkpoint 788912872 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 101,373.90813
Policy Entropy: 3.71954
Value Function Loss: 0.03573

Mean KL Divergence: 0.01378
SB3 Clip Fraction: 0.17161
Policy Update Magnitude: 0.65143
Value Function Update Magnitude: 0.58368

Collected Steps per Second: 21,364.72430
Overall Steps per Second: 10,310.71330

Timestep Collection Time: 2.34143
Timestep Consumption Time: 2.51022
PPO Batch Consumption Time: 0.29545
Total Iteration Time: 4.85165

Cumulative Model Updates: 94,612
Cumulative Timesteps: 788,962,896

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 100,699.82061
Policy Entropy: 3.72278
Value Function Loss: 0.03831

Mean KL Divergence: 0.01613
SB3 Clip Fraction: 0.19765
Policy Update Magnitude: 0.63732
Value Function Update Magnitude: 0.58934

Collected Steps per Second: 22,157.22031
Overall Steps per Second: 10,533.59723

Timestep Collection Time: 2.25723
Timestep Consumption Time: 2.49081
PPO Batch Consumption Time: 0.29254
Total Iteration Time: 4.74805

Cumulative Model Updates: 94,618
Cumulative Timesteps: 789,012,910

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 789012910...
Checkpoint 789012910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,118.58453
Policy Entropy: 3.73086
Value Function Loss: 0.04061

Mean KL Divergence: 0.01359
SB3 Clip Fraction: 0.16453
Policy Update Magnitude: 0.66563
Value Function Update Magnitude: 0.58156

Collected Steps per Second: 21,973.68958
Overall Steps per Second: 10,442.32669

Timestep Collection Time: 2.27572
Timestep Consumption Time: 2.51306
PPO Batch Consumption Time: 0.29090
Total Iteration Time: 4.78878

Cumulative Model Updates: 94,624
Cumulative Timesteps: 789,062,916

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,118.58453
Policy Entropy: 3.69821
Value Function Loss: 0.04564

Mean KL Divergence: 0.01434
SB3 Clip Fraction: 0.17692
Policy Update Magnitude: 0.71101
Value Function Update Magnitude: 0.54060

Collected Steps per Second: 22,177.29774
Overall Steps per Second: 10,484.27575

Timestep Collection Time: 2.25465
Timestep Consumption Time: 2.51459
PPO Batch Consumption Time: 0.28995
Total Iteration Time: 4.76924

Cumulative Model Updates: 94,630
Cumulative Timesteps: 789,112,918

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 789112918...
Checkpoint 789112918 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 153,994.29224
Policy Entropy: 3.68083
Value Function Loss: 0.04658

Mean KL Divergence: 0.01326
SB3 Clip Fraction: 0.16856
Policy Update Magnitude: 0.63905
Value Function Update Magnitude: 0.41466

Collected Steps per Second: 21,753.41536
Overall Steps per Second: 10,384.16082

Timestep Collection Time: 2.30024
Timestep Consumption Time: 2.51845
PPO Batch Consumption Time: 0.29341
Total Iteration Time: 4.81869

Cumulative Model Updates: 94,636
Cumulative Timesteps: 789,162,956

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 73,119.29170
Policy Entropy: 3.63795
Value Function Loss: 0.05773

Mean KL Divergence: 0.01792
SB3 Clip Fraction: 0.20053
Policy Update Magnitude: 0.64389
Value Function Update Magnitude: 0.41044

Collected Steps per Second: 22,271.05055
Overall Steps per Second: 10,588.24336

Timestep Collection Time: 2.24605
Timestep Consumption Time: 2.47824
PPO Batch Consumption Time: 0.28398
Total Iteration Time: 4.72430

Cumulative Model Updates: 94,642
Cumulative Timesteps: 789,212,978

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 789212978...
Checkpoint 789212978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 160,056.64794
Policy Entropy: 3.63777
Value Function Loss: 0.07354

Mean KL Divergence: 0.01349
SB3 Clip Fraction: 0.16846
Policy Update Magnitude: 0.68905
Value Function Update Magnitude: 0.48927

Collected Steps per Second: 21,906.79221
Overall Steps per Second: 10,305.77805

Timestep Collection Time: 2.28340
Timestep Consumption Time: 2.57038
PPO Batch Consumption Time: 0.29811
Total Iteration Time: 4.85378

Cumulative Model Updates: 94,648
Cumulative Timesteps: 789,263,000

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75,383.69779
Policy Entropy: 3.62863
Value Function Loss: 0.07540

Mean KL Divergence: 0.02346
SB3 Clip Fraction: 0.23789
Policy Update Magnitude: 0.72449
Value Function Update Magnitude: 0.53672

Collected Steps per Second: 21,805.24469
Overall Steps per Second: 10,374.96512

Timestep Collection Time: 2.29468
Timestep Consumption Time: 2.52809
PPO Batch Consumption Time: 0.28883
Total Iteration Time: 4.82276

Cumulative Model Updates: 94,654
Cumulative Timesteps: 789,313,036

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 789313036...
Checkpoint 789313036 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 61,002.73599
Policy Entropy: 3.65572
Value Function Loss: 0.06615

Mean KL Divergence: 0.02070
SB3 Clip Fraction: 0.23417
Policy Update Magnitude: 0.74720
Value Function Update Magnitude: 0.60745

Collected Steps per Second: 22,052.62628
Overall Steps per Second: 10,407.30321

Timestep Collection Time: 2.26785
Timestep Consumption Time: 2.53762
PPO Batch Consumption Time: 0.29712
Total Iteration Time: 4.80547

Cumulative Model Updates: 94,660
Cumulative Timesteps: 789,363,048

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,931.61500
Policy Entropy: 3.67769
Value Function Loss: 0.06751

Mean KL Divergence: 0.01568
SB3 Clip Fraction: 0.19114
Policy Update Magnitude: 0.72619
Value Function Update Magnitude: 0.63019

Collected Steps per Second: 22,526.67730
Overall Steps per Second: 10,551.63170

Timestep Collection Time: 2.22039
Timestep Consumption Time: 2.51992
PPO Batch Consumption Time: 0.29148
Total Iteration Time: 4.74031

Cumulative Model Updates: 94,666
Cumulative Timesteps: 789,413,066

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 789413066...
Checkpoint 789413066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 243,906.85413
Policy Entropy: 3.67908
Value Function Loss: 0.07155

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.13363
Policy Update Magnitude: 0.68870
Value Function Update Magnitude: 0.56055

Collected Steps per Second: 22,171.46834
Overall Steps per Second: 10,427.07225

Timestep Collection Time: 2.25524
Timestep Consumption Time: 2.54016
PPO Batch Consumption Time: 0.29607
Total Iteration Time: 4.79540

Cumulative Model Updates: 94,672
Cumulative Timesteps: 789,463,068

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 151,808.78154
Policy Entropy: 3.69116
Value Function Loss: 0.06584

Mean KL Divergence: 0.01159
SB3 Clip Fraction: 0.14743
Policy Update Magnitude: 0.85176
Value Function Update Magnitude: 0.67812

Collected Steps per Second: 21,860.66279
Overall Steps per Second: 10,232.91814

Timestep Collection Time: 2.28849
Timestep Consumption Time: 2.60043
PPO Batch Consumption Time: 0.29689
Total Iteration Time: 4.88893

Cumulative Model Updates: 94,678
Cumulative Timesteps: 789,513,096

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 789513096...
Checkpoint 789513096 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,150.79525
Policy Entropy: 3.67859
Value Function Loss: 0.06304

Mean KL Divergence: 0.01350
SB3 Clip Fraction: 0.16342
Policy Update Magnitude: 0.81801
Value Function Update Magnitude: 0.66502

Collected Steps per Second: 21,570.50793
Overall Steps per Second: 10,615.31668

Timestep Collection Time: 2.31835
Timestep Consumption Time: 2.39258
PPO Batch Consumption Time: 0.28254
Total Iteration Time: 4.71093

Cumulative Model Updates: 94,684
Cumulative Timesteps: 789,563,104

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 126,776.85603
Policy Entropy: 3.66570
Value Function Loss: 0.06427

Mean KL Divergence: 0.01233
SB3 Clip Fraction: 0.15766
Policy Update Magnitude: 0.70885
Value Function Update Magnitude: 0.62534

Collected Steps per Second: 21,404.74891
Overall Steps per Second: 10,394.76543

Timestep Collection Time: 2.33686
Timestep Consumption Time: 2.47517
PPO Batch Consumption Time: 0.29777
Total Iteration Time: 4.81204

Cumulative Model Updates: 94,690
Cumulative Timesteps: 789,613,124

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 789613124...
Checkpoint 789613124 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 75,753.57917
Policy Entropy: 3.65152
Value Function Loss: 0.06230

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.13073
Policy Update Magnitude: 0.70373
Value Function Update Magnitude: 0.67890

Collected Steps per Second: 20,516.12986
Overall Steps per Second: 10,247.78110

Timestep Collection Time: 2.43847
Timestep Consumption Time: 2.44337
PPO Batch Consumption Time: 0.29496
Total Iteration Time: 4.88184

Cumulative Model Updates: 94,696
Cumulative Timesteps: 789,663,152

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,136.57312
Policy Entropy: 3.67981
Value Function Loss: 0.06735

Mean KL Divergence: 0.00726
SB3 Clip Fraction: 0.09086
Policy Update Magnitude: 0.93676
Value Function Update Magnitude: 0.61916

Collected Steps per Second: 21,270.60039
Overall Steps per Second: 10,362.66703

Timestep Collection Time: 2.35076
Timestep Consumption Time: 2.47445
PPO Batch Consumption Time: 0.29748
Total Iteration Time: 4.82521

Cumulative Model Updates: 94,702
Cumulative Timesteps: 789,713,154

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 789713154...
Checkpoint 789713154 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,352.97217
Policy Entropy: 3.72186
Value Function Loss: 0.05982

Mean KL Divergence: 0.01143
SB3 Clip Fraction: 0.14336
Policy Update Magnitude: 0.99887
Value Function Update Magnitude: 0.58939

Collected Steps per Second: 21,686.02258
Overall Steps per Second: 10,659.78772

Timestep Collection Time: 2.30683
Timestep Consumption Time: 2.38613
PPO Batch Consumption Time: 0.28269
Total Iteration Time: 4.69296

Cumulative Model Updates: 94,708
Cumulative Timesteps: 789,763,180

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,545.24182
Policy Entropy: 3.74364
Value Function Loss: 0.05110

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.12846
Policy Update Magnitude: 0.90037
Value Function Update Magnitude: 0.63499

Collected Steps per Second: 21,884.93570
Overall Steps per Second: 10,486.25730

Timestep Collection Time: 2.28522
Timestep Consumption Time: 2.48406
PPO Batch Consumption Time: 0.28914
Total Iteration Time: 4.76929

Cumulative Model Updates: 94,714
Cumulative Timesteps: 789,813,192

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 789813192...
Checkpoint 789813192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,301.10820
Policy Entropy: 3.74587
Value Function Loss: 0.04464

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.11217
Policy Update Magnitude: 0.80537
Value Function Update Magnitude: 0.64476

Collected Steps per Second: 21,505.46234
Overall Steps per Second: 10,333.79945

Timestep Collection Time: 2.32564
Timestep Consumption Time: 2.51420
PPO Batch Consumption Time: 0.29475
Total Iteration Time: 4.83985

Cumulative Model Updates: 94,720
Cumulative Timesteps: 789,863,206

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,785.92878
Policy Entropy: 3.74558
Value Function Loss: 0.04198

Mean KL Divergence: 0.01281
SB3 Clip Fraction: 0.16044
Policy Update Magnitude: 0.68032
Value Function Update Magnitude: 0.59851

Collected Steps per Second: 22,289.62242
Overall Steps per Second: 10,629.45795

Timestep Collection Time: 2.24427
Timestep Consumption Time: 2.46189
PPO Batch Consumption Time: 0.28436
Total Iteration Time: 4.70617

Cumulative Model Updates: 94,726
Cumulative Timesteps: 789,913,230

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 789913230...
Checkpoint 789913230 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,785.92878
Policy Entropy: 3.71088
Value Function Loss: 0.04427

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.10176
Policy Update Magnitude: 0.65038
Value Function Update Magnitude: 0.44606

Collected Steps per Second: 22,483.43376
Overall Steps per Second: 10,574.13090

Timestep Collection Time: 2.22386
Timestep Consumption Time: 2.50466
PPO Batch Consumption Time: 0.28809
Total Iteration Time: 4.72852

Cumulative Model Updates: 94,732
Cumulative Timesteps: 789,963,230

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 322,918.99702
Policy Entropy: 3.68008
Value Function Loss: 0.04402

Mean KL Divergence: 0.01593
SB3 Clip Fraction: 0.19849
Policy Update Magnitude: 0.56806
Value Function Update Magnitude: 0.36912

Collected Steps per Second: 22,678.77162
Overall Steps per Second: 10,705.45417

Timestep Collection Time: 2.20656
Timestep Consumption Time: 2.46788
PPO Batch Consumption Time: 0.28124
Total Iteration Time: 4.67444

Cumulative Model Updates: 94,738
Cumulative Timesteps: 790,013,272

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 790013272...
Checkpoint 790013272 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 79,039.55440
Policy Entropy: 3.70621
Value Function Loss: 0.05474

Mean KL Divergence: 0.01398
SB3 Clip Fraction: 0.16975
Policy Update Magnitude: 0.46244
Value Function Update Magnitude: 0.43031

Collected Steps per Second: 22,405.33680
Overall Steps per Second: 10,641.47748

Timestep Collection Time: 2.23331
Timestep Consumption Time: 2.46886
PPO Batch Consumption Time: 0.28282
Total Iteration Time: 4.70217

Cumulative Model Updates: 94,744
Cumulative Timesteps: 790,063,310

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,035.04149
Policy Entropy: 3.70600
Value Function Loss: 0.09500

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.13168
Policy Update Magnitude: 0.56338
Value Function Update Magnitude: 0.28800

Collected Steps per Second: 22,383.13037
Overall Steps per Second: 10,428.77963

Timestep Collection Time: 2.23472
Timestep Consumption Time: 2.56162
PPO Batch Consumption Time: 0.29702
Total Iteration Time: 4.79634

Cumulative Model Updates: 94,750
Cumulative Timesteps: 790,113,330

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 790113330...
Checkpoint 790113330 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 61,205.58225
Policy Entropy: 3.70694
Value Function Loss: 0.08221

Mean KL Divergence: 0.01309
SB3 Clip Fraction: 0.16651
Policy Update Magnitude: 0.48661
Value Function Update Magnitude: 0.26988

Collected Steps per Second: 22,112.68165
Overall Steps per Second: 10,451.13451

Timestep Collection Time: 2.26169
Timestep Consumption Time: 2.52363
PPO Batch Consumption Time: 0.29307
Total Iteration Time: 4.78532

Cumulative Model Updates: 94,756
Cumulative Timesteps: 790,163,342

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 462,419.06173
Policy Entropy: 3.69755
Value Function Loss: 0.03852

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.13505
Policy Update Magnitude: 0.52622
Value Function Update Magnitude: 0.44664

Collected Steps per Second: 22,501.70403
Overall Steps per Second: 10,650.85785

Timestep Collection Time: 2.22223
Timestep Consumption Time: 2.47260
PPO Batch Consumption Time: 0.28346
Total Iteration Time: 4.69483

Cumulative Model Updates: 94,762
Cumulative Timesteps: 790,213,346

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 790213346...
Checkpoint 790213346 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 161,250.60099
Policy Entropy: 3.68741
Value Function Loss: 0.04467

Mean KL Divergence: 0.01406
SB3 Clip Fraction: 0.18263
Policy Update Magnitude: 0.45245
Value Function Update Magnitude: 0.64636

Collected Steps per Second: 22,176.08008
Overall Steps per Second: 10,445.62993

Timestep Collection Time: 2.25477
Timestep Consumption Time: 2.53211
PPO Batch Consumption Time: 0.29319
Total Iteration Time: 4.78688

Cumulative Model Updates: 94,768
Cumulative Timesteps: 790,263,348

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 154,510.56453
Policy Entropy: 3.71286
Value Function Loss: 0.04434

Mean KL Divergence: 0.01620
SB3 Clip Fraction: 0.18687
Policy Update Magnitude: 0.46354
Value Function Update Magnitude: 0.55610

Collected Steps per Second: 22,639.50144
Overall Steps per Second: 10,659.36509

Timestep Collection Time: 2.20853
Timestep Consumption Time: 2.48218
PPO Batch Consumption Time: 0.28335
Total Iteration Time: 4.69071

Cumulative Model Updates: 94,774
Cumulative Timesteps: 790,313,348

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 790313348...
Checkpoint 790313348 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 154,510.56453
Policy Entropy: 3.66316
Value Function Loss: 0.04727

Mean KL Divergence: 0.01974
SB3 Clip Fraction: 0.23479
Policy Update Magnitude: 0.41602
Value Function Update Magnitude: 0.52548

Collected Steps per Second: 21,972.37249
Overall Steps per Second: 10,376.13866

Timestep Collection Time: 2.27659
Timestep Consumption Time: 2.54428
PPO Batch Consumption Time: 0.29782
Total Iteration Time: 4.82087

Cumulative Model Updates: 94,780
Cumulative Timesteps: 790,363,370

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88,592.11553
Policy Entropy: 3.66651
Value Function Loss: 0.05766

Mean KL Divergence: 0.01365
SB3 Clip Fraction: 0.17283
Policy Update Magnitude: 0.43715
Value Function Update Magnitude: 0.53917

Collected Steps per Second: 22,308.09202
Overall Steps per Second: 10,439.39812

Timestep Collection Time: 2.24259
Timestep Consumption Time: 2.54964
PPO Batch Consumption Time: 0.29725
Total Iteration Time: 4.79223

Cumulative Model Updates: 94,786
Cumulative Timesteps: 790,413,398

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 790413398...
Checkpoint 790413398 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 333,419.54400
Policy Entropy: 3.65386
Value Function Loss: 0.05804

Mean KL Divergence: 0.01201
SB3 Clip Fraction: 0.15153
Policy Update Magnitude: 0.62240
Value Function Update Magnitude: 0.66143

Collected Steps per Second: 22,057.70159
Overall Steps per Second: 10,572.31618

Timestep Collection Time: 2.26760
Timestep Consumption Time: 2.46344
PPO Batch Consumption Time: 0.28206
Total Iteration Time: 4.73104

Cumulative Model Updates: 94,792
Cumulative Timesteps: 790,463,416

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 270,069.79989
Policy Entropy: 3.66014
Value Function Loss: 0.05856

Mean KL Divergence: 0.01544
SB3 Clip Fraction: 0.18157
Policy Update Magnitude: 0.78891
Value Function Update Magnitude: 0.68834

Collected Steps per Second: 22,223.25971
Overall Steps per Second: 10,493.72771

Timestep Collection Time: 2.25115
Timestep Consumption Time: 2.51626
PPO Batch Consumption Time: 0.28979
Total Iteration Time: 4.76742

Cumulative Model Updates: 94,798
Cumulative Timesteps: 790,513,444

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 790513444...
Checkpoint 790513444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 155,033.05273
Policy Entropy: 3.67136
Value Function Loss: 0.05267

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.12760
Policy Update Magnitude: 0.65343
Value Function Update Magnitude: 0.60817

Collected Steps per Second: 21,940.40858
Overall Steps per Second: 10,475.92975

Timestep Collection Time: 2.27917
Timestep Consumption Time: 2.49425
PPO Batch Consumption Time: 0.28671
Total Iteration Time: 4.77342

Cumulative Model Updates: 94,804
Cumulative Timesteps: 790,563,450

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 275,943.42910
Policy Entropy: 3.65970
Value Function Loss: 0.05076

Mean KL Divergence: 0.01298
SB3 Clip Fraction: 0.15759
Policy Update Magnitude: 0.58813
Value Function Update Magnitude: 0.52832

Collected Steps per Second: 20,668.29755
Overall Steps per Second: 10,024.42273

Timestep Collection Time: 2.41926
Timestep Consumption Time: 2.56876
PPO Batch Consumption Time: 0.29085
Total Iteration Time: 4.98802

Cumulative Model Updates: 94,810
Cumulative Timesteps: 790,613,452

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 790613452...
Checkpoint 790613452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 77,947.09089
Policy Entropy: 3.68418
Value Function Loss: 0.04311

Mean KL Divergence: 0.01151
SB3 Clip Fraction: 0.14758
Policy Update Magnitude: 0.56127
Value Function Update Magnitude: 0.47693

Collected Steps per Second: 20,757.13373
Overall Steps per Second: 9,969.53975

Timestep Collection Time: 2.41006
Timestep Consumption Time: 2.60782
PPO Batch Consumption Time: 0.29873
Total Iteration Time: 5.01788

Cumulative Model Updates: 94,816
Cumulative Timesteps: 790,663,478

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,209.73409
Policy Entropy: 3.68938
Value Function Loss: 0.04019

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.13558
Policy Update Magnitude: 0.54249
Value Function Update Magnitude: 0.49637

Collected Steps per Second: 20,706.41660
Overall Steps per Second: 9,965.83725

Timestep Collection Time: 2.41490
Timestep Consumption Time: 2.60264
PPO Batch Consumption Time: 0.30362
Total Iteration Time: 5.01754

Cumulative Model Updates: 94,822
Cumulative Timesteps: 790,713,482

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 790713482...
Checkpoint 790713482 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,945.61211
Policy Entropy: 3.70418
Value Function Loss: 0.03810

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.13684
Policy Update Magnitude: 0.49696
Value Function Update Magnitude: 0.56242

Collected Steps per Second: 20,001.73278
Overall Steps per Second: 9,849.91907

Timestep Collection Time: 2.50118
Timestep Consumption Time: 2.57784
PPO Batch Consumption Time: 0.30832
Total Iteration Time: 5.07903

Cumulative Model Updates: 94,828
Cumulative Timesteps: 790,763,510

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,153.58630
Policy Entropy: 3.68102
Value Function Loss: 0.03864

Mean KL Divergence: 0.01170
SB3 Clip Fraction: 0.15708
Policy Update Magnitude: 0.42388
Value Function Update Magnitude: 0.55469

Collected Steps per Second: 21,433.47918
Overall Steps per Second: 10,300.14428

Timestep Collection Time: 2.33392
Timestep Consumption Time: 2.52271
PPO Batch Consumption Time: 0.29963
Total Iteration Time: 4.85663

Cumulative Model Updates: 94,834
Cumulative Timesteps: 790,813,534

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 790813534...
Checkpoint 790813534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 114,801.57939
Policy Entropy: 3.68156
Value Function Loss: 0.03837

Mean KL Divergence: 0.01119
SB3 Clip Fraction: 0.15255
Policy Update Magnitude: 0.38694
Value Function Update Magnitude: 0.51847

Collected Steps per Second: 20,314.10856
Overall Steps per Second: 9,913.78917

Timestep Collection Time: 2.46144
Timestep Consumption Time: 2.58224
PPO Batch Consumption Time: 0.29766
Total Iteration Time: 5.04368

Cumulative Model Updates: 94,840
Cumulative Timesteps: 790,863,536

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 153,683.69235
Policy Entropy: 3.66538
Value Function Loss: 0.04155

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.14424
Policy Update Magnitude: 0.37686
Value Function Update Magnitude: 0.54908

Collected Steps per Second: 21,840.51569
Overall Steps per Second: 10,319.17162

Timestep Collection Time: 2.29079
Timestep Consumption Time: 2.55766
PPO Batch Consumption Time: 0.29565
Total Iteration Time: 4.84845

Cumulative Model Updates: 94,846
Cumulative Timesteps: 790,913,568

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 790913568...
Checkpoint 790913568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 217,638.57914
Policy Entropy: 3.68224
Value Function Loss: 0.04240

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.14088
Policy Update Magnitude: 0.38819
Value Function Update Magnitude: 0.64147

Collected Steps per Second: 21,610.70909
Overall Steps per Second: 10,406.37257

Timestep Collection Time: 2.31561
Timestep Consumption Time: 2.49317
PPO Batch Consumption Time: 0.28321
Total Iteration Time: 4.80878

Cumulative Model Updates: 94,852
Cumulative Timesteps: 790,963,610

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 484,163.66838
Policy Entropy: 3.67531
Value Function Loss: 0.04229

Mean KL Divergence: 0.01071
SB3 Clip Fraction: 0.14739
Policy Update Magnitude: 0.39490
Value Function Update Magnitude: 0.69514

Collected Steps per Second: 21,918.48458
Overall Steps per Second: 10,361.62343

Timestep Collection Time: 2.28136
Timestep Consumption Time: 2.54452
PPO Batch Consumption Time: 0.28750
Total Iteration Time: 4.82588

Cumulative Model Updates: 94,858
Cumulative Timesteps: 791,013,614

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 791013614...
Checkpoint 791013614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 192,851.57985
Policy Entropy: 3.68551
Value Function Loss: 0.03953

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.14492
Policy Update Magnitude: 0.37957
Value Function Update Magnitude: 0.61067

Collected Steps per Second: 22,125.34917
Overall Steps per Second: 9,919.88720

Timestep Collection Time: 2.26048
Timestep Consumption Time: 2.78131
PPO Batch Consumption Time: 0.33447
Total Iteration Time: 5.04179

Cumulative Model Updates: 94,864
Cumulative Timesteps: 791,063,628

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 188,589.46623
Policy Entropy: 3.67078
Value Function Loss: 0.04138

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.13586
Policy Update Magnitude: 0.36551
Value Function Update Magnitude: 0.52882

Collected Steps per Second: 21,928.82402
Overall Steps per Second: 10,508.84935

Timestep Collection Time: 2.28165
Timestep Consumption Time: 2.47948
PPO Batch Consumption Time: 0.28192
Total Iteration Time: 4.76113

Cumulative Model Updates: 94,870
Cumulative Timesteps: 791,113,662

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 791113662...
Checkpoint 791113662 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 188,589.46623
Policy Entropy: 3.67915
Value Function Loss: 0.03863

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.13322
Policy Update Magnitude: 0.37102
Value Function Update Magnitude: 0.46998

Collected Steps per Second: 20,831.22603
Overall Steps per Second: 10,168.91940

Timestep Collection Time: 2.40235
Timestep Consumption Time: 2.51892
PPO Batch Consumption Time: 0.28880
Total Iteration Time: 4.92127

Cumulative Model Updates: 94,876
Cumulative Timesteps: 791,163,706

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 188,589.46623
Policy Entropy: 3.67408
Value Function Loss: 0.03674

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.14229
Policy Update Magnitude: 0.33728
Value Function Update Magnitude: 0.41631

Collected Steps per Second: 21,725.47480
Overall Steps per Second: 10,429.85938

Timestep Collection Time: 2.30292
Timestep Consumption Time: 2.49408
PPO Batch Consumption Time: 0.28410
Total Iteration Time: 4.79700

Cumulative Model Updates: 94,882
Cumulative Timesteps: 791,213,738

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 791213738...
Checkpoint 791213738 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 188,589.46623
Policy Entropy: 3.69120
Value Function Loss: 0.03268

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.14031
Policy Update Magnitude: 0.32638
Value Function Update Magnitude: 0.42295

Collected Steps per Second: 21,146.74093
Overall Steps per Second: 10,187.71411

Timestep Collection Time: 2.36500
Timestep Consumption Time: 2.54405
PPO Batch Consumption Time: 0.29521
Total Iteration Time: 4.90905

Cumulative Model Updates: 94,888
Cumulative Timesteps: 791,263,750

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 228,349.10904
Policy Entropy: 3.68061
Value Function Loss: 0.03381

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.14395
Policy Update Magnitude: 0.34273
Value Function Update Magnitude: 0.44593

Collected Steps per Second: 21,121.78376
Overall Steps per Second: 10,136.62846

Timestep Collection Time: 2.36817
Timestep Consumption Time: 2.56641
PPO Batch Consumption Time: 0.29496
Total Iteration Time: 4.93458

Cumulative Model Updates: 94,894
Cumulative Timesteps: 791,313,770

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 791313770...
Checkpoint 791313770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 228,349.10904
Policy Entropy: 3.67682
Value Function Loss: 0.03263

Mean KL Divergence: 0.01089
SB3 Clip Fraction: 0.14929
Policy Update Magnitude: 0.34364
Value Function Update Magnitude: 0.43426

Collected Steps per Second: 22,344.27993
Overall Steps per Second: 10,658.16649

Timestep Collection Time: 2.23914
Timestep Consumption Time: 2.45510
PPO Batch Consumption Time: 0.28104
Total Iteration Time: 4.69424

Cumulative Model Updates: 94,900
Cumulative Timesteps: 791,363,802

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 219,284.28363
Policy Entropy: 3.67658
Value Function Loss: 0.03464

Mean KL Divergence: 0.01136
SB3 Clip Fraction: 0.15456
Policy Update Magnitude: 0.34983
Value Function Update Magnitude: 0.41672

Collected Steps per Second: 22,501.87291
Overall Steps per Second: 10,521.54810

Timestep Collection Time: 2.22328
Timestep Consumption Time: 2.53153
PPO Batch Consumption Time: 0.29481
Total Iteration Time: 4.75481

Cumulative Model Updates: 94,906
Cumulative Timesteps: 791,413,830

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 791413830...
Checkpoint 791413830 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 219,284.28363
Policy Entropy: 3.67122
Value Function Loss: 0.03263

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.14557
Policy Update Magnitude: 0.34892
Value Function Update Magnitude: 0.41181

Collected Steps per Second: 21,604.84706
Overall Steps per Second: 10,507.54824

Timestep Collection Time: 2.31457
Timestep Consumption Time: 2.44448
PPO Batch Consumption Time: 0.29055
Total Iteration Time: 4.75905

Cumulative Model Updates: 94,912
Cumulative Timesteps: 791,463,836

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 219,284.28363
Policy Entropy: 3.65509
Value Function Loss: 0.03273

Mean KL Divergence: 0.01133
SB3 Clip Fraction: 0.15340
Policy Update Magnitude: 0.32739
Value Function Update Magnitude: 0.39253

Collected Steps per Second: 21,652.36546
Overall Steps per Second: 10,486.00870

Timestep Collection Time: 2.30986
Timestep Consumption Time: 2.45973
PPO Batch Consumption Time: 0.29298
Total Iteration Time: 4.76959

Cumulative Model Updates: 94,918
Cumulative Timesteps: 791,513,850

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 791513850...
Checkpoint 791513850 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 219,284.28363
Policy Entropy: 3.65017
Value Function Loss: 0.03287

Mean KL Divergence: 0.01109
SB3 Clip Fraction: 0.15234
Policy Update Magnitude: 0.31927
Value Function Update Magnitude: 0.35622

Collected Steps per Second: 20,380.50507
Overall Steps per Second: 9,939.01013

Timestep Collection Time: 2.45489
Timestep Consumption Time: 2.57901
PPO Batch Consumption Time: 0.30366
Total Iteration Time: 5.03390

Cumulative Model Updates: 94,924
Cumulative Timesteps: 791,563,882

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 219,284.28363
Policy Entropy: 3.66257
Value Function Loss: 0.03262

Mean KL Divergence: 0.01070
SB3 Clip Fraction: 0.14783
Policy Update Magnitude: 0.33415
Value Function Update Magnitude: 0.45522

Collected Steps per Second: 21,348.16733
Overall Steps per Second: 10,139.56601

Timestep Collection Time: 2.34287
Timestep Consumption Time: 2.58988
PPO Batch Consumption Time: 0.29585
Total Iteration Time: 4.93276

Cumulative Model Updates: 94,930
Cumulative Timesteps: 791,613,898

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 791613898...
Checkpoint 791613898 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 219,284.28363
Policy Entropy: 3.66369
Value Function Loss: 0.03218

Mean KL Divergence: 0.01089
SB3 Clip Fraction: 0.14965
Policy Update Magnitude: 0.33615
Value Function Update Magnitude: 0.40960

Collected Steps per Second: 22,279.63056
Overall Steps per Second: 10,506.43279

Timestep Collection Time: 2.24528
Timestep Consumption Time: 2.51599
PPO Batch Consumption Time: 0.29509
Total Iteration Time: 4.76127

Cumulative Model Updates: 94,936
Cumulative Timesteps: 791,663,922

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 259,228.47325
Policy Entropy: 3.65882
Value Function Loss: 0.02974

Mean KL Divergence: 0.01057
SB3 Clip Fraction: 0.14818
Policy Update Magnitude: 0.31239
Value Function Update Magnitude: 0.37624

Collected Steps per Second: 21,694.83242
Overall Steps per Second: 10,368.50260

Timestep Collection Time: 2.30470
Timestep Consumption Time: 2.51760
PPO Batch Consumption Time: 0.29034
Total Iteration Time: 4.82230

Cumulative Model Updates: 94,942
Cumulative Timesteps: 791,713,922

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 791713922...
Checkpoint 791713922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 158,685.76159
Policy Entropy: 3.67094
Value Function Loss: 0.02840

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.13705
Policy Update Magnitude: 0.31464
Value Function Update Magnitude: 0.46298

Collected Steps per Second: 22,334.97242
Overall Steps per Second: 10,636.80381

Timestep Collection Time: 2.23909
Timestep Consumption Time: 2.46251
PPO Batch Consumption Time: 0.28244
Total Iteration Time: 4.70160

Cumulative Model Updates: 94,948
Cumulative Timesteps: 791,763,932

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 73,836.57528
Policy Entropy: 3.68619
Value Function Loss: 0.02991

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.13333
Policy Update Magnitude: 0.37237
Value Function Update Magnitude: 0.53884

Collected Steps per Second: 21,838.77357
Overall Steps per Second: 10,447.26887

Timestep Collection Time: 2.29070
Timestep Consumption Time: 2.49773
PPO Batch Consumption Time: 0.28700
Total Iteration Time: 4.78843

Cumulative Model Updates: 94,954
Cumulative Timesteps: 791,813,958

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 791813958...
Checkpoint 791813958 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 73,836.57528
Policy Entropy: 3.69155
Value Function Loss: 0.03016

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.13342
Policy Update Magnitude: 0.42414
Value Function Update Magnitude: 0.64509

Collected Steps per Second: 22,212.81884
Overall Steps per Second: 10,436.03584

Timestep Collection Time: 2.25167
Timestep Consumption Time: 2.54095
PPO Batch Consumption Time: 0.29407
Total Iteration Time: 4.79262

Cumulative Model Updates: 94,960
Cumulative Timesteps: 791,863,974

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89,415.09477
Policy Entropy: 3.65810
Value Function Loss: 0.03681

Mean KL Divergence: 0.01088
SB3 Clip Fraction: 0.14698
Policy Update Magnitude: 0.42434
Value Function Update Magnitude: 0.63587

Collected Steps per Second: 21,899.13105
Overall Steps per Second: 10,460.61402

Timestep Collection Time: 2.28511
Timestep Consumption Time: 2.49874
PPO Batch Consumption Time: 0.28884
Total Iteration Time: 4.78385

Cumulative Model Updates: 94,966
Cumulative Timesteps: 791,914,016

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 791914016...
Checkpoint 791914016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 120,518.52101
Policy Entropy: 3.64481
Value Function Loss: 0.04118

Mean KL Divergence: 0.01112
SB3 Clip Fraction: 0.14869
Policy Update Magnitude: 0.44165
Value Function Update Magnitude: 0.68698

Collected Steps per Second: 22,215.95909
Overall Steps per Second: 10,434.17816

Timestep Collection Time: 2.25162
Timestep Consumption Time: 2.54243
PPO Batch Consumption Time: 0.29791
Total Iteration Time: 4.79405

Cumulative Model Updates: 94,972
Cumulative Timesteps: 791,964,038

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 249,730.27298
Policy Entropy: 3.64965
Value Function Loss: 0.04226

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.14603
Policy Update Magnitude: 0.46706
Value Function Update Magnitude: 0.77338

Collected Steps per Second: 22,049.62860
Overall Steps per Second: 10,431.79982

Timestep Collection Time: 2.26779
Timestep Consumption Time: 2.52563
PPO Batch Consumption Time: 0.29209
Total Iteration Time: 4.79342

Cumulative Model Updates: 94,978
Cumulative Timesteps: 792,014,042

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 792014042...
Checkpoint 792014042 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 202,284.38481
Policy Entropy: 3.67313
Value Function Loss: 0.03930

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.14064
Policy Update Magnitude: 0.46898
Value Function Update Magnitude: 0.83601

Collected Steps per Second: 22,433.74762
Overall Steps per Second: 10,605.34347

Timestep Collection Time: 2.22932
Timestep Consumption Time: 2.48642
PPO Batch Consumption Time: 0.28346
Total Iteration Time: 4.71574

Cumulative Model Updates: 94,984
Cumulative Timesteps: 792,064,054

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 226,272.66731
Policy Entropy: 3.66638
Value Function Loss: 0.03610

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.14283
Policy Update Magnitude: 0.44610
Value Function Update Magnitude: 0.75472

Collected Steps per Second: 22,094.88681
Overall Steps per Second: 10,475.26039

Timestep Collection Time: 2.26387
Timestep Consumption Time: 2.51119
PPO Batch Consumption Time: 0.28954
Total Iteration Time: 4.77506

Cumulative Model Updates: 94,990
Cumulative Timesteps: 792,114,074

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 792114074...
Checkpoint 792114074 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 97,444.16792
Policy Entropy: 3.67422
Value Function Loss: 0.03539

Mean KL Divergence: 0.01095
SB3 Clip Fraction: 0.15095
Policy Update Magnitude: 0.40533
Value Function Update Magnitude: 0.70636

Collected Steps per Second: 22,373.99816
Overall Steps per Second: 10,617.56741

Timestep Collection Time: 2.23501
Timestep Consumption Time: 2.47474
PPO Batch Consumption Time: 0.28330
Total Iteration Time: 4.70974

Cumulative Model Updates: 94,996
Cumulative Timesteps: 792,164,080

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 106,769.05774
Policy Entropy: 3.66439
Value Function Loss: 0.03990

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.14623
Policy Update Magnitude: 0.37699
Value Function Update Magnitude: 0.53601

Collected Steps per Second: 21,963.23089
Overall Steps per Second: 10,521.23162

Timestep Collection Time: 2.27699
Timestep Consumption Time: 2.47626
PPO Batch Consumption Time: 0.28256
Total Iteration Time: 4.75325

Cumulative Model Updates: 95,002
Cumulative Timesteps: 792,214,090

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 792214090...
Checkpoint 792214090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86,488.73531
Policy Entropy: 3.67831
Value Function Loss: 0.03939

Mean KL Divergence: 0.01065
SB3 Clip Fraction: 0.14683
Policy Update Magnitude: 0.41189
Value Function Update Magnitude: 0.48433

Collected Steps per Second: 21,702.51127
Overall Steps per Second: 10,170.24906

Timestep Collection Time: 2.30397
Timestep Consumption Time: 2.61252
PPO Batch Consumption Time: 0.29758
Total Iteration Time: 4.91650

Cumulative Model Updates: 95,008
Cumulative Timesteps: 792,264,092

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 486,332.51891
Policy Entropy: 3.64941
Value Function Loss: 0.04304

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.14044
Policy Update Magnitude: 0.44917
Value Function Update Magnitude: 0.55181

Collected Steps per Second: 20,765.02460
Overall Steps per Second: 10,325.23222

Timestep Collection Time: 2.40818
Timestep Consumption Time: 2.43490
PPO Batch Consumption Time: 0.28689
Total Iteration Time: 4.84309

Cumulative Model Updates: 95,014
Cumulative Timesteps: 792,314,098

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 792314098...
Checkpoint 792314098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 178,950.97327
Policy Entropy: 3.66457
Value Function Loss: 0.03782

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.14164
Policy Update Magnitude: 0.47477
Value Function Update Magnitude: 0.64570

Collected Steps per Second: 18,329.08077
Overall Steps per Second: 9,311.01002

Timestep Collection Time: 2.72867
Timestep Consumption Time: 2.64282
PPO Batch Consumption Time: 0.31665
Total Iteration Time: 5.37149

Cumulative Model Updates: 95,020
Cumulative Timesteps: 792,364,112

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 147,307.78790
Policy Entropy: 3.64178
Value Function Loss: 0.03835

Mean KL Divergence: 0.01059
SB3 Clip Fraction: 0.14609
Policy Update Magnitude: 0.47925
Value Function Update Magnitude: 0.65336

Collected Steps per Second: 18,093.17046
Overall Steps per Second: 7,381.69477

Timestep Collection Time: 2.76358
Timestep Consumption Time: 4.01020
PPO Batch Consumption Time: 0.52168
Total Iteration Time: 6.77378

Cumulative Model Updates: 95,026
Cumulative Timesteps: 792,414,114

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 792414114...
Checkpoint 792414114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 79,290.02628
Policy Entropy: 3.67991
Value Function Loss: 0.03553

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.14175
Policy Update Magnitude: 0.45113
Value Function Update Magnitude: 0.57697

Collected Steps per Second: 15,027.80270
Overall Steps per Second: 7,178.29078

Timestep Collection Time: 3.32903
Timestep Consumption Time: 3.64032
PPO Batch Consumption Time: 0.48055
Total Iteration Time: 6.96935

Cumulative Model Updates: 95,032
Cumulative Timesteps: 792,464,142

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 145,459.06685
Policy Entropy: 3.66217
Value Function Loss: 0.04349

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.13618
Policy Update Magnitude: 0.45437
Value Function Update Magnitude: 0.58449

Collected Steps per Second: 15,987.48627
Overall Steps per Second: 7,389.71730

Timestep Collection Time: 3.12745
Timestep Consumption Time: 3.63871
PPO Batch Consumption Time: 0.48219
Total Iteration Time: 6.76616

Cumulative Model Updates: 95,038
Cumulative Timesteps: 792,514,142

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 792514142...
Checkpoint 792514142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 117,824.75792
Policy Entropy: 3.69731
Value Function Loss: 0.04038

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.13369
Policy Update Magnitude: 0.48177
Value Function Update Magnitude: 0.57967

Collected Steps per Second: 15,742.19564
Overall Steps per Second: 7,175.72123

Timestep Collection Time: 3.17910
Timestep Consumption Time: 3.79525
PPO Batch Consumption Time: 0.50852
Total Iteration Time: 6.97435

Cumulative Model Updates: 95,044
Cumulative Timesteps: 792,564,188

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 117,824.75792
Policy Entropy: 3.66978
Value Function Loss: 0.03981

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.13937
Policy Update Magnitude: 0.49968
Value Function Update Magnitude: 0.58647

Collected Steps per Second: 15,516.56665
Overall Steps per Second: 7,093.78584

Timestep Collection Time: 3.22326
Timestep Consumption Time: 3.82713
PPO Batch Consumption Time: 0.50585
Total Iteration Time: 7.05040

Cumulative Model Updates: 95,050
Cumulative Timesteps: 792,614,202

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 792614202...
Checkpoint 792614202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 390,057.68801
Policy Entropy: 3.67956
Value Function Loss: 0.03405

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.13854
Policy Update Magnitude: 0.47378
Value Function Update Magnitude: 0.62420

Collected Steps per Second: 15,692.37426
Overall Steps per Second: 7,244.00515

Timestep Collection Time: 3.18805
Timestep Consumption Time: 3.71808
PPO Batch Consumption Time: 0.49784
Total Iteration Time: 6.90612

Cumulative Model Updates: 95,056
Cumulative Timesteps: 792,664,230

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 179,501.64204
Policy Entropy: 3.66066
Value Function Loss: 0.03990

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.14085
Policy Update Magnitude: 0.48047
Value Function Update Magnitude: 0.67755

Collected Steps per Second: 15,859.52517
Overall Steps per Second: 7,172.58887

Timestep Collection Time: 3.15432
Timestep Consumption Time: 3.82029
PPO Batch Consumption Time: 0.50664
Total Iteration Time: 6.97461

Cumulative Model Updates: 95,062
Cumulative Timesteps: 792,714,256

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 792714256...
Checkpoint 792714256 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 118,472.73453
Policy Entropy: 3.67461
Value Function Loss: 0.04288

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.13918
Policy Update Magnitude: 0.53584
Value Function Update Magnitude: 0.62253

Collected Steps per Second: 15,443.34887
Overall Steps per Second: 6,983.58320

Timestep Collection Time: 3.23906
Timestep Consumption Time: 3.92373
PPO Batch Consumption Time: 0.52518
Total Iteration Time: 7.16280

Cumulative Model Updates: 95,068
Cumulative Timesteps: 792,764,278

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62,976.43155
Policy Entropy: 3.65661
Value Function Loss: 0.04334

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.14150
Policy Update Magnitude: 0.56302
Value Function Update Magnitude: 0.64053

Collected Steps per Second: 15,858.92872
Overall Steps per Second: 7,175.06382

Timestep Collection Time: 3.15620
Timestep Consumption Time: 3.81990
PPO Batch Consumption Time: 0.50647
Total Iteration Time: 6.97611

Cumulative Model Updates: 95,074
Cumulative Timesteps: 792,814,332

Timesteps Collected: 50,054
--------END ITERATION REPORT--------


Saving checkpoint 792814332...
Checkpoint 792814332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 62,976.43155
Policy Entropy: 3.66552
Value Function Loss: 0.03983

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.14315
Policy Update Magnitude: 0.52914
Value Function Update Magnitude: 0.60522

Collected Steps per Second: 15,647.95658
Overall Steps per Second: 7,199.07598

Timestep Collection Time: 3.19646
Timestep Consumption Time: 3.75138
PPO Batch Consumption Time: 0.49538
Total Iteration Time: 6.94784

Cumulative Model Updates: 95,080
Cumulative Timesteps: 792,864,350

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 241,952.48996
Policy Entropy: 3.65870
Value Function Loss: 0.03947

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.14419
Policy Update Magnitude: 0.49260
Value Function Update Magnitude: 0.50499

Collected Steps per Second: 15,824.35454
Overall Steps per Second: 7,246.94463

Timestep Collection Time: 3.16007
Timestep Consumption Time: 3.74022
PPO Batch Consumption Time: 0.49624
Total Iteration Time: 6.90029

Cumulative Model Updates: 95,086
Cumulative Timesteps: 792,914,356

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 792914356...
Checkpoint 792914356 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55,375.31360
Policy Entropy: 3.67043
Value Function Loss: 0.03462

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.13259
Policy Update Magnitude: 0.48672
Value Function Update Magnitude: 0.57737

Collected Steps per Second: 15,916.15169
Overall Steps per Second: 7,165.33948

Timestep Collection Time: 3.14297
Timestep Consumption Time: 3.83842
PPO Batch Consumption Time: 0.51011
Total Iteration Time: 6.98139

Cumulative Model Updates: 95,092
Cumulative Timesteps: 792,964,380

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,318.10720
Policy Entropy: 3.65122
Value Function Loss: 0.04493

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.13504
Policy Update Magnitude: 0.50249
Value Function Update Magnitude: 0.56805

Collected Steps per Second: 13,674.69704
Overall Steps per Second: 7,245.88436

Timestep Collection Time: 3.65683
Timestep Consumption Time: 3.24447
PPO Batch Consumption Time: 0.41026
Total Iteration Time: 6.90130

Cumulative Model Updates: 95,098
Cumulative Timesteps: 793,014,386

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 793014386...
Checkpoint 793014386 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 133,681.01057
Policy Entropy: 3.65432
Value Function Loss: 0.04565

Mean KL Divergence: 0.01055
SB3 Clip Fraction: 0.14069
Policy Update Magnitude: 0.53745
Value Function Update Magnitude: 0.57863

Collected Steps per Second: 20,981.66672
Overall Steps per Second: 10,182.09931

Timestep Collection Time: 2.38303
Timestep Consumption Time: 2.52755
PPO Batch Consumption Time: 0.29920
Total Iteration Time: 4.91058

Cumulative Model Updates: 95,104
Cumulative Timesteps: 793,064,386

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 235,711.55685
Policy Entropy: 3.65121
Value Function Loss: 0.04708

Mean KL Divergence: 0.01061
SB3 Clip Fraction: 0.14230
Policy Update Magnitude: 0.54470
Value Function Update Magnitude: 0.74916

Collected Steps per Second: 17,484.12481
Overall Steps per Second: 9,091.62420

Timestep Collection Time: 2.86168
Timestep Consumption Time: 2.64163
PPO Batch Consumption Time: 0.29971
Total Iteration Time: 5.50331

Cumulative Model Updates: 95,110
Cumulative Timesteps: 793,114,420

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 793114420...
Checkpoint 793114420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 82,204.30446
Policy Entropy: 3.68491
Value Function Loss: 0.04062

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.14137
Policy Update Magnitude: 0.52162
Value Function Update Magnitude: 0.65512

Collected Steps per Second: 19,039.89086
Overall Steps per Second: 9,344.43816

Timestep Collection Time: 2.62712
Timestep Consumption Time: 2.72580
PPO Batch Consumption Time: 0.31033
Total Iteration Time: 5.35292

Cumulative Model Updates: 95,116
Cumulative Timesteps: 793,164,440

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 452,893.16957
Policy Entropy: 3.68136
Value Function Loss: 0.04062

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.14005
Policy Update Magnitude: 0.49162
Value Function Update Magnitude: 0.56388

Collected Steps per Second: 20,489.21838
Overall Steps per Second: 9,884.76292

Timestep Collection Time: 2.44167
Timestep Consumption Time: 2.61945
PPO Batch Consumption Time: 0.29651
Total Iteration Time: 5.06112

Cumulative Model Updates: 95,122
Cumulative Timesteps: 793,214,468

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 793214468...
Checkpoint 793214468 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 193,489.42487
Policy Entropy: 3.70111
Value Function Loss: 0.04173

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.13910
Policy Update Magnitude: 0.47379
Value Function Update Magnitude: 0.56264

Collected Steps per Second: 20,834.36765
Overall Steps per Second: 10,242.66298

Timestep Collection Time: 2.40094
Timestep Consumption Time: 2.48275
PPO Batch Consumption Time: 0.28355
Total Iteration Time: 4.88369

Cumulative Model Updates: 95,128
Cumulative Timesteps: 793,264,490

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 193,489.42487
Policy Entropy: 3.67612
Value Function Loss: 0.04407

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.14119
Policy Update Magnitude: 0.48235
Value Function Update Magnitude: 0.54510

Collected Steps per Second: 18,650.91075
Overall Steps per Second: 9,716.61429

Timestep Collection Time: 2.68234
Timestep Consumption Time: 2.46637
PPO Batch Consumption Time: 0.28934
Total Iteration Time: 5.14871

Cumulative Model Updates: 95,134
Cumulative Timesteps: 793,314,518

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 793314518...
Checkpoint 793314518 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 131,500.47111
Policy Entropy: 3.68350
Value Function Loss: 0.05026

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.14017
Policy Update Magnitude: 0.52745
Value Function Update Magnitude: 0.58580

Collected Steps per Second: 13,783.99213
Overall Steps per Second: 6,605.38158

Timestep Collection Time: 3.62914
Timestep Consumption Time: 3.94408
PPO Batch Consumption Time: 0.50757
Total Iteration Time: 7.57322

Cumulative Model Updates: 95,140
Cumulative Timesteps: 793,364,542

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 152,921.59373
Policy Entropy: 3.67614
Value Function Loss: 0.05123

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.13865
Policy Update Magnitude: 0.53839
Value Function Update Magnitude: 0.50708

Collected Steps per Second: 15,362.39431
Overall Steps per Second: 6,917.24403

Timestep Collection Time: 3.25678
Timestep Consumption Time: 3.97615
PPO Batch Consumption Time: 0.52544
Total Iteration Time: 7.23294

Cumulative Model Updates: 95,146
Cumulative Timesteps: 793,414,574

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 793414574...
Checkpoint 793414574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 152,921.59373
Policy Entropy: 3.68381
Value Function Loss: 0.04208

Mean KL Divergence: 0.01072
SB3 Clip Fraction: 0.14485
Policy Update Magnitude: 0.54061
Value Function Update Magnitude: 0.49558

Collected Steps per Second: 15,395.18147
Overall Steps per Second: 7,046.24864

Timestep Collection Time: 3.24842
Timestep Consumption Time: 3.84897
PPO Batch Consumption Time: 0.51208
Total Iteration Time: 7.09739

Cumulative Model Updates: 95,152
Cumulative Timesteps: 793,464,584

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 152,921.59373
Policy Entropy: 3.67377
Value Function Loss: 0.03774

Mean KL Divergence: 0.01074
SB3 Clip Fraction: 0.14196
Policy Update Magnitude: 0.47535
Value Function Update Magnitude: 0.46801

Collected Steps per Second: 15,394.88875
Overall Steps per Second: 7,191.51142

Timestep Collection Time: 3.24783
Timestep Consumption Time: 3.70481
PPO Batch Consumption Time: 0.48557
Total Iteration Time: 6.95264

Cumulative Model Updates: 95,158
Cumulative Timesteps: 793,514,584

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 793514584...
Checkpoint 793514584 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 152,921.59373
Policy Entropy: 3.66665
Value Function Loss: 0.03299

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.14040
Policy Update Magnitude: 0.43992
Value Function Update Magnitude: 0.46264

Collected Steps per Second: 15,445.89133
Overall Steps per Second: 7,216.78082

Timestep Collection Time: 3.23801
Timestep Consumption Time: 3.69222
PPO Batch Consumption Time: 0.48628
Total Iteration Time: 6.93024

Cumulative Model Updates: 95,164
Cumulative Timesteps: 793,564,598

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 287,395.72537
Policy Entropy: 3.66278
Value Function Loss: 0.03383

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.14020
Policy Update Magnitude: 0.46076
Value Function Update Magnitude: 0.43718

Collected Steps per Second: 15,624.10894
Overall Steps per Second: 7,108.28155

Timestep Collection Time: 3.20018
Timestep Consumption Time: 3.83387
PPO Batch Consumption Time: 0.50682
Total Iteration Time: 7.03405

Cumulative Model Updates: 95,170
Cumulative Timesteps: 793,614,598

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 793614598...
Checkpoint 793614598 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 328,432.71413
Policy Entropy: 3.64485
Value Function Loss: 0.03666

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.14140
Policy Update Magnitude: 0.47514
Value Function Update Magnitude: 0.50084

Collected Steps per Second: 15,704.58352
Overall Steps per Second: 7,186.95347

Timestep Collection Time: 3.18480
Timestep Consumption Time: 3.77447
PPO Batch Consumption Time: 0.49770
Total Iteration Time: 6.95928

Cumulative Model Updates: 95,176
Cumulative Timesteps: 793,664,614

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 141,394.36858
Policy Entropy: 3.67089
Value Function Loss: 0.03372

Mean KL Divergence: 0.01074
SB3 Clip Fraction: 0.13663
Policy Update Magnitude: 0.49643
Value Function Update Magnitude: 0.60295

Collected Steps per Second: 15,589.32054
Overall Steps per Second: 7,123.52893

Timestep Collection Time: 3.20874
Timestep Consumption Time: 3.81335
PPO Batch Consumption Time: 0.50233
Total Iteration Time: 7.02208

Cumulative Model Updates: 95,182
Cumulative Timesteps: 793,714,636

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 793714636...
Checkpoint 793714636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 141,394.36858
Policy Entropy: 3.66618
Value Function Loss: 0.03368

Mean KL Divergence: 0.01083
SB3 Clip Fraction: 0.14061
Policy Update Magnitude: 0.54740
Value Function Update Magnitude: 0.57250

Collected Steps per Second: 15,593.00979
Overall Steps per Second: 7,222.29411

Timestep Collection Time: 3.20772
Timestep Consumption Time: 3.71778
PPO Batch Consumption Time: 0.48949
Total Iteration Time: 6.92550

Cumulative Model Updates: 95,188
Cumulative Timesteps: 793,764,654

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 123,831.27916
Policy Entropy: 3.69174
Value Function Loss: 0.02880

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.13902
Policy Update Magnitude: 0.51204
Value Function Update Magnitude: 0.49051

Collected Steps per Second: 15,452.85289
Overall Steps per Second: 7,090.16639

Timestep Collection Time: 3.23824
Timestep Consumption Time: 3.81943
PPO Batch Consumption Time: 0.50432
Total Iteration Time: 7.05766

Cumulative Model Updates: 95,194
Cumulative Timesteps: 793,814,694

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 793814694...
Checkpoint 793814694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 108,590.06127
Policy Entropy: 3.68919
Value Function Loss: 0.03114

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.14131
Policy Update Magnitude: 0.46433
Value Function Update Magnitude: 0.53091

Collected Steps per Second: 15,730.34033
Overall Steps per Second: 7,186.40577

Timestep Collection Time: 3.17984
Timestep Consumption Time: 3.78052
PPO Batch Consumption Time: 0.50165
Total Iteration Time: 6.96036

Cumulative Model Updates: 95,200
Cumulative Timesteps: 793,864,714

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87,959.35077
Policy Entropy: 3.69314
Value Function Loss: 0.03792

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.13246
Policy Update Magnitude: 0.54395
Value Function Update Magnitude: 0.59843

Collected Steps per Second: 14,146.17280
Overall Steps per Second: 6,725.95395

Timestep Collection Time: 3.53749
Timestep Consumption Time: 3.90264
PPO Batch Consumption Time: 0.51623
Total Iteration Time: 7.44013

Cumulative Model Updates: 95,206
Cumulative Timesteps: 793,914,756

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 793914756...
Checkpoint 793914756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 122,984.86624
Policy Entropy: 3.69246
Value Function Loss: 0.04078

Mean KL Divergence: 0.01184
SB3 Clip Fraction: 0.14981
Policy Update Magnitude: 0.63722
Value Function Update Magnitude: 0.63330

Collected Steps per Second: 15,351.53590
Overall Steps per Second: 7,192.44380

Timestep Collection Time: 3.25831
Timestep Consumption Time: 3.69621
PPO Batch Consumption Time: 0.49939
Total Iteration Time: 6.95452

Cumulative Model Updates: 95,212
Cumulative Timesteps: 793,964,776

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65,978.74732
Policy Entropy: 3.70341
Value Function Loss: 0.04136

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.12092
Policy Update Magnitude: 0.73541
Value Function Update Magnitude: 0.67554

Collected Steps per Second: 15,434.57294
Overall Steps per Second: 7,193.76175

Timestep Collection Time: 3.24026
Timestep Consumption Time: 3.71188
PPO Batch Consumption Time: 0.50304
Total Iteration Time: 6.95213

Cumulative Model Updates: 95,218
Cumulative Timesteps: 794,014,788

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 794014788...
Checkpoint 794014788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,418.10274
Policy Entropy: 3.71606
Value Function Loss: 0.03840

Mean KL Divergence: 0.01430
SB3 Clip Fraction: 0.17356
Policy Update Magnitude: 0.67081
Value Function Update Magnitude: 0.61192

Collected Steps per Second: 15,141.75971
Overall Steps per Second: 7,007.84987

Timestep Collection Time: 3.30305
Timestep Consumption Time: 3.83380
PPO Batch Consumption Time: 0.50992
Total Iteration Time: 7.13685

Cumulative Model Updates: 95,224
Cumulative Timesteps: 794,064,802

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,317.47476
Policy Entropy: 3.71303
Value Function Loss: 0.03448

Mean KL Divergence: 0.01133
SB3 Clip Fraction: 0.13912
Policy Update Magnitude: 0.60774
Value Function Update Magnitude: 0.57017

Collected Steps per Second: 15,366.61031
Overall Steps per Second: 7,124.51943

Timestep Collection Time: 3.25498
Timestep Consumption Time: 3.76556
PPO Batch Consumption Time: 0.50261
Total Iteration Time: 7.02054

Cumulative Model Updates: 95,230
Cumulative Timesteps: 794,114,820

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 794114820...
Checkpoint 794114820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87,742.45563
Policy Entropy: 3.71016
Value Function Loss: 0.03405

Mean KL Divergence: 0.01413
SB3 Clip Fraction: 0.17326
Policy Update Magnitude: 0.57179
Value Function Update Magnitude: 0.56668

Collected Steps per Second: 15,399.48237
Overall Steps per Second: 7,147.12894

Timestep Collection Time: 3.24829
Timestep Consumption Time: 3.75060
PPO Batch Consumption Time: 0.49946
Total Iteration Time: 6.99889

Cumulative Model Updates: 95,236
Cumulative Timesteps: 794,164,842

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57,607.87144
Policy Entropy: 3.70666
Value Function Loss: 0.03781

Mean KL Divergence: 0.01337
SB3 Clip Fraction: 0.18186
Policy Update Magnitude: 0.50951
Value Function Update Magnitude: 0.61086

Collected Steps per Second: 15,174.66615
Overall Steps per Second: 7,056.29887

Timestep Collection Time: 3.29549
Timestep Consumption Time: 3.79151
PPO Batch Consumption Time: 0.49899
Total Iteration Time: 7.08700

Cumulative Model Updates: 95,242
Cumulative Timesteps: 794,214,850

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 794214850...
Checkpoint 794214850 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 437,154.18053
Policy Entropy: 3.69982
Value Function Loss: 0.04443

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.12014
Policy Update Magnitude: 0.59727
Value Function Update Magnitude: 0.70482

Collected Steps per Second: 15,554.20148
Overall Steps per Second: 7,163.26929

Timestep Collection Time: 3.21482
Timestep Consumption Time: 3.76579
PPO Batch Consumption Time: 0.49519
Total Iteration Time: 6.98061

Cumulative Model Updates: 95,248
Cumulative Timesteps: 794,264,854

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 323,142.79070
Policy Entropy: 3.68290
Value Function Loss: 0.04628

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.10457
Policy Update Magnitude: 0.81613
Value Function Update Magnitude: 0.64437

Collected Steps per Second: 15,403.59308
Overall Steps per Second: 7,067.12093

Timestep Collection Time: 3.24665
Timestep Consumption Time: 3.82979
PPO Batch Consumption Time: 0.50590
Total Iteration Time: 7.07643

Cumulative Model Updates: 95,254
Cumulative Timesteps: 794,314,864

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 794314864...
Checkpoint 794314864 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 135,093.84786
Policy Entropy: 3.68807
Value Function Loss: 0.04842

Mean KL Divergence: 0.01307
SB3 Clip Fraction: 0.16580
Policy Update Magnitude: 0.80959
Value Function Update Magnitude: 0.92942

Collected Steps per Second: 15,281.38979
Overall Steps per Second: 6,974.29923

Timestep Collection Time: 3.27261
Timestep Consumption Time: 3.89800
PPO Batch Consumption Time: 0.51775
Total Iteration Time: 7.17061

Cumulative Model Updates: 95,260
Cumulative Timesteps: 794,364,874

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 135,093.84786
Policy Entropy: 3.67919
Value Function Loss: 0.04545

Mean KL Divergence: 0.01334
SB3 Clip Fraction: 0.17236
Policy Update Magnitude: 0.65896
Value Function Update Magnitude: 0.86663

Collected Steps per Second: 15,351.34611
Overall Steps per Second: 7,057.51636

Timestep Collection Time: 3.25965
Timestep Consumption Time: 3.83066
PPO Batch Consumption Time: 0.50764
Total Iteration Time: 7.09031

Cumulative Model Updates: 95,266
Cumulative Timesteps: 794,414,914

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 794414914...
Checkpoint 794414914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 113,847.21437
Policy Entropy: 3.67821
Value Function Loss: 0.04818

Mean KL Divergence: 0.01352
SB3 Clip Fraction: 0.17631
Policy Update Magnitude: 0.63372
Value Function Update Magnitude: 0.70031

Collected Steps per Second: 15,643.48029
Overall Steps per Second: 7,120.66806

Timestep Collection Time: 3.19699
Timestep Consumption Time: 3.82651
PPO Batch Consumption Time: 0.50889
Total Iteration Time: 7.02350

Cumulative Model Updates: 95,272
Cumulative Timesteps: 794,464,926

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 165,045.17625
Policy Entropy: 3.67523
Value Function Loss: 0.04068

Mean KL Divergence: 0.01071
SB3 Clip Fraction: 0.14251
Policy Update Magnitude: 0.48844
Value Function Update Magnitude: 0.69889

Collected Steps per Second: 15,512.25361
Overall Steps per Second: 7,061.14206

Timestep Collection Time: 3.22416
Timestep Consumption Time: 3.85883
PPO Batch Consumption Time: 0.50985
Total Iteration Time: 7.08299

Cumulative Model Updates: 95,278
Cumulative Timesteps: 794,514,940

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 794514940...
Checkpoint 794514940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 238,394.48853
Policy Entropy: 3.67840
Value Function Loss: 0.04526

Mean KL Divergence: 0.01072
SB3 Clip Fraction: 0.14339
Policy Update Magnitude: 0.49221
Value Function Update Magnitude: 0.61978

Collected Steps per Second: 15,628.18821
Overall Steps per Second: 7,134.24165

Timestep Collection Time: 3.20075
Timestep Consumption Time: 3.81078
PPO Batch Consumption Time: 0.50646
Total Iteration Time: 7.01154

Cumulative Model Updates: 95,284
Cumulative Timesteps: 794,564,962

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 102,107.02028
Policy Entropy: 3.68245
Value Function Loss: 0.05254

Mean KL Divergence: 0.01096
SB3 Clip Fraction: 0.14148
Policy Update Magnitude: 0.50554
Value Function Update Magnitude: 0.52095

Collected Steps per Second: 15,428.65863
Overall Steps per Second: 7,115.29422

Timestep Collection Time: 3.24241
Timestep Consumption Time: 3.78836
PPO Batch Consumption Time: 0.50150
Total Iteration Time: 7.03077

Cumulative Model Updates: 95,290
Cumulative Timesteps: 794,614,988

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 794614988...
Checkpoint 794614988 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 102,107.02028
Policy Entropy: 3.68554
Value Function Loss: 0.05217

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.13472
Policy Update Magnitude: 0.51107
Value Function Update Magnitude: 0.54633

Collected Steps per Second: 15,193.78776
Overall Steps per Second: 7,153.26596

Timestep Collection Time: 3.29266
Timestep Consumption Time: 3.70107
PPO Batch Consumption Time: 0.50289
Total Iteration Time: 6.99373

Cumulative Model Updates: 95,296
Cumulative Timesteps: 794,665,016

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 404,516.77797
Policy Entropy: 3.66572
Value Function Loss: 0.05557

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.13888
Policy Update Magnitude: 0.51674
Value Function Update Magnitude: 0.59393

Collected Steps per Second: 15,251.17104
Overall Steps per Second: 7,172.12721

Timestep Collection Time: 3.28027
Timestep Consumption Time: 3.69506
PPO Batch Consumption Time: 0.49689
Total Iteration Time: 6.97534

Cumulative Model Updates: 95,302
Cumulative Timesteps: 794,715,044

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 794715044...
Checkpoint 794715044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 100,830.64411
Policy Entropy: 3.67185
Value Function Loss: 0.05026

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.14098
Policy Update Magnitude: 0.55743
Value Function Update Magnitude: 0.64733

Collected Steps per Second: 15,179.20877
Overall Steps per Second: 7,132.48715

Timestep Collection Time: 3.29635
Timestep Consumption Time: 3.71887
PPO Batch Consumption Time: 0.50673
Total Iteration Time: 7.01522

Cumulative Model Updates: 95,308
Cumulative Timesteps: 794,765,080

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,774.01023
Policy Entropy: 3.68564
Value Function Loss: 0.05272

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.13258
Policy Update Magnitude: 0.57021
Value Function Update Magnitude: 0.82157

Collected Steps per Second: 15,364.89286
Overall Steps per Second: 7,079.17995

Timestep Collection Time: 3.25508
Timestep Consumption Time: 3.80986
PPO Batch Consumption Time: 0.50363
Total Iteration Time: 7.06494

Cumulative Model Updates: 95,314
Cumulative Timesteps: 794,815,094

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 794815094...
Checkpoint 794815094 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 112,889.43363
Policy Entropy: 3.69423
Value Function Loss: 0.05186

Mean KL Divergence: 0.01061
SB3 Clip Fraction: 0.14097
Policy Update Magnitude: 0.60171
Value Function Update Magnitude: 0.68393

Collected Steps per Second: 15,396.52850
Overall Steps per Second: 7,113.58844

Timestep Collection Time: 3.24788
Timestep Consumption Time: 3.78177
PPO Batch Consumption Time: 0.50619
Total Iteration Time: 7.02964

Cumulative Model Updates: 95,320
Cumulative Timesteps: 794,865,100

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 140,387.56014
Policy Entropy: 3.67142
Value Function Loss: 0.05591

Mean KL Divergence: 0.01115
SB3 Clip Fraction: 0.14457
Policy Update Magnitude: 0.55276
Value Function Update Magnitude: 0.59646

Collected Steps per Second: 15,310.58196
Overall Steps per Second: 7,146.57693

Timestep Collection Time: 3.26715
Timestep Consumption Time: 3.73228
PPO Batch Consumption Time: 0.49696
Total Iteration Time: 6.99943

Cumulative Model Updates: 95,326
Cumulative Timesteps: 794,915,122

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 794915122...
Checkpoint 794915122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 141,177.79402
Policy Entropy: 3.66861
Value Function Loss: 0.04996

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.13503
Policy Update Magnitude: 0.53870
Value Function Update Magnitude: 0.73904

Collected Steps per Second: 15,415.67088
Overall Steps per Second: 7,139.28463

Timestep Collection Time: 3.24501
Timestep Consumption Time: 3.76185
PPO Batch Consumption Time: 0.50133
Total Iteration Time: 7.00686

Cumulative Model Updates: 95,332
Cumulative Timesteps: 794,965,146

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 158,776.70778
Policy Entropy: 3.68407
Value Function Loss: 0.05201

Mean KL Divergence: 0.01070
SB3 Clip Fraction: 0.14318
Policy Update Magnitude: 0.56274
Value Function Update Magnitude: 0.68229

Collected Steps per Second: 15,434.27762
Overall Steps per Second: 7,083.21771

Timestep Collection Time: 3.24032
Timestep Consumption Time: 3.82031
PPO Batch Consumption Time: 0.50611
Total Iteration Time: 7.06063

Cumulative Model Updates: 95,338
Cumulative Timesteps: 795,015,158

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 795015158...
Checkpoint 795015158 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 63,158.67599
Policy Entropy: 3.71672
Value Function Loss: 0.04529

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.14180
Policy Update Magnitude: 0.54257
Value Function Update Magnitude: 0.56456

Collected Steps per Second: 15,473.51690
Overall Steps per Second: 7,144.93607

Timestep Collection Time: 3.23314
Timestep Consumption Time: 3.76875
PPO Batch Consumption Time: 0.49934
Total Iteration Time: 7.00188

Cumulative Model Updates: 95,344
Cumulative Timesteps: 795,065,186

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,964.77208
Policy Entropy: 3.70737
Value Function Loss: 0.04121

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.14572
Policy Update Magnitude: 0.48602
Value Function Update Magnitude: 0.53712

Collected Steps per Second: 15,514.78772
Overall Steps per Second: 7,141.68939

Timestep Collection Time: 3.22389
Timestep Consumption Time: 3.77977
PPO Batch Consumption Time: 0.49865
Total Iteration Time: 7.00367

Cumulative Model Updates: 95,350
Cumulative Timesteps: 795,115,204

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 795115204...
Checkpoint 795115204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,125.20948
Policy Entropy: 3.70539
Value Function Loss: 0.03406

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.14735
Policy Update Magnitude: 0.43855
Value Function Update Magnitude: 0.52813

Collected Steps per Second: 15,580.06630
Overall Steps per Second: 7,147.88017

Timestep Collection Time: 3.20949
Timestep Consumption Time: 3.78615
PPO Batch Consumption Time: 0.50049
Total Iteration Time: 6.99564

Cumulative Model Updates: 95,356
Cumulative Timesteps: 795,165,208

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,125.20948
Policy Entropy: 3.68177
Value Function Loss: 0.02978

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.14672
Policy Update Magnitude: 0.42712
Value Function Update Magnitude: 0.56222

Collected Steps per Second: 15,584.04760
Overall Steps per Second: 7,067.88843

Timestep Collection Time: 3.21021
Timestep Consumption Time: 3.86800
PPO Batch Consumption Time: 0.51372
Total Iteration Time: 7.07821

Cumulative Model Updates: 95,362
Cumulative Timesteps: 795,215,236

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 795215236...
Checkpoint 795215236 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,125.20948
Policy Entropy: 3.67263
Value Function Loss: 0.02778

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.14511
Policy Update Magnitude: 0.39743
Value Function Update Magnitude: 0.56447

Collected Steps per Second: 15,403.67605
Overall Steps per Second: 7,098.65490

Timestep Collection Time: 3.24858
Timestep Consumption Time: 3.80065
PPO Batch Consumption Time: 0.50557
Total Iteration Time: 7.04922

Cumulative Model Updates: 95,368
Cumulative Timesteps: 795,265,276

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48,050.97063
Policy Entropy: 3.66971
Value Function Loss: 0.03047

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.14433
Policy Update Magnitude: 0.40389
Value Function Update Magnitude: 0.56228

Collected Steps per Second: 15,736.70906
Overall Steps per Second: 6,642.50690

Timestep Collection Time: 3.17856
Timestep Consumption Time: 4.35173
PPO Batch Consumption Time: 0.59592
Total Iteration Time: 7.53029

Cumulative Model Updates: 95,374
Cumulative Timesteps: 795,315,296

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 795315296...
Checkpoint 795315296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 122,042.34194
Policy Entropy: 3.67388
Value Function Loss: 0.03580

Mean KL Divergence: 0.01081
SB3 Clip Fraction: 0.14807
Policy Update Magnitude: 0.41592
Value Function Update Magnitude: 0.58023

Collected Steps per Second: 15,431.97210
Overall Steps per Second: 8,774.92028

Timestep Collection Time: 3.24080
Timestep Consumption Time: 2.45862
PPO Batch Consumption Time: 0.29507
Total Iteration Time: 5.69943

Cumulative Model Updates: 95,380
Cumulative Timesteps: 795,365,308

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,022.34093
Policy Entropy: 3.68292
Value Function Loss: 0.03808

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.13934
Policy Update Magnitude: 0.43078
Value Function Update Magnitude: 0.58943

Collected Steps per Second: 17,744.51587
Overall Steps per Second: 9,313.28203

Timestep Collection Time: 2.81879
Timestep Consumption Time: 2.55182
PPO Batch Consumption Time: 0.30151
Total Iteration Time: 5.37061

Cumulative Model Updates: 95,386
Cumulative Timesteps: 795,415,326

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 795415326...
Checkpoint 795415326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,745.93518
Policy Entropy: 3.69668
Value Function Loss: 0.03727

Mean KL Divergence: 0.01088
SB3 Clip Fraction: 0.14879
Policy Update Magnitude: 0.42690
Value Function Update Magnitude: 0.60016

Collected Steps per Second: 20,000.77034
Overall Steps per Second: 10,160.13210

Timestep Collection Time: 2.50020
Timestep Consumption Time: 2.42158
PPO Batch Consumption Time: 0.28641
Total Iteration Time: 4.92179

Cumulative Model Updates: 95,392
Cumulative Timesteps: 795,465,332

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 71,839.51472
Policy Entropy: 3.70036
Value Function Loss: 0.03846

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.14589
Policy Update Magnitude: 0.42034
Value Function Update Magnitude: 0.56150

Collected Steps per Second: 21,118.58588
Overall Steps per Second: 10,205.61769

Timestep Collection Time: 2.36853
Timestep Consumption Time: 2.53269
PPO Batch Consumption Time: 0.29774
Total Iteration Time: 4.90122

Cumulative Model Updates: 95,398
Cumulative Timesteps: 795,515,352

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 795515352...
Checkpoint 795515352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 126,486.72789
Policy Entropy: 3.70695
Value Function Loss: 0.04251

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.14237
Policy Update Magnitude: 0.47754
Value Function Update Magnitude: 0.59713

Collected Steps per Second: 21,954.96148
Overall Steps per Second: 10,542.40756

Timestep Collection Time: 2.27857
Timestep Consumption Time: 2.46664
PPO Batch Consumption Time: 0.28451
Total Iteration Time: 4.74522

Cumulative Model Updates: 95,404
Cumulative Timesteps: 795,565,378

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77,448.02808
Policy Entropy: 3.67799
Value Function Loss: 0.04645

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.14288
Policy Update Magnitude: 0.49922
Value Function Update Magnitude: 0.67577

Collected Steps per Second: 21,596.14849
Overall Steps per Second: 10,151.04280

Timestep Collection Time: 2.31782
Timestep Consumption Time: 2.61330
PPO Batch Consumption Time: 0.30535
Total Iteration Time: 4.93112

Cumulative Model Updates: 95,410
Cumulative Timesteps: 795,615,434

Timesteps Collected: 50,056
--------END ITERATION REPORT--------


Saving checkpoint 795615434...
Checkpoint 795615434 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,504.11520
Policy Entropy: 3.69362
Value Function Loss: 0.04273

Mean KL Divergence: 0.01066
SB3 Clip Fraction: 0.14445
Policy Update Magnitude: 0.53254
Value Function Update Magnitude: 0.59657

Collected Steps per Second: 19,855.47977
Overall Steps per Second: 10,116.84710

Timestep Collection Time: 2.51850
Timestep Consumption Time: 2.42435
PPO Batch Consumption Time: 0.28394
Total Iteration Time: 4.94284

Cumulative Model Updates: 95,416
Cumulative Timesteps: 795,665,440

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 151,221.34653
Policy Entropy: 3.66478
Value Function Loss: 0.04538

Mean KL Divergence: 0.01076
SB3 Clip Fraction: 0.14827
Policy Update Magnitude: 0.52622
Value Function Update Magnitude: 0.65961

Collected Steps per Second: 21,677.21422
Overall Steps per Second: 10,465.02545

Timestep Collection Time: 2.30768
Timestep Consumption Time: 2.47244
PPO Batch Consumption Time: 0.28576
Total Iteration Time: 4.78011

Cumulative Model Updates: 95,422
Cumulative Timesteps: 795,715,464

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 795715464...
Checkpoint 795715464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,997.01476
Policy Entropy: 3.68976
Value Function Loss: 0.04485

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.14376
Policy Update Magnitude: 0.52961
Value Function Update Magnitude: 0.75217

Collected Steps per Second: 21,417.86782
Overall Steps per Second: 10,256.39153

Timestep Collection Time: 2.33459
Timestep Consumption Time: 2.54061
PPO Batch Consumption Time: 0.29362
Total Iteration Time: 4.87520

Cumulative Model Updates: 95,428
Cumulative Timesteps: 795,765,466

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,006.67889
Policy Entropy: 3.67525
Value Function Loss: 0.04551

Mean KL Divergence: 0.01110
SB3 Clip Fraction: 0.15233
Policy Update Magnitude: 0.53504
Value Function Update Magnitude: 0.70133

Collected Steps per Second: 21,595.72218
Overall Steps per Second: 10,388.85877

Timestep Collection Time: 2.31740
Timestep Consumption Time: 2.49987
PPO Batch Consumption Time: 0.28513
Total Iteration Time: 4.81728

Cumulative Model Updates: 95,434
Cumulative Timesteps: 795,815,512

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 795815512...
Checkpoint 795815512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,218.41663
Policy Entropy: 3.69008
Value Function Loss: 0.03714

Mean KL Divergence: 0.01078
SB3 Clip Fraction: 0.14780
Policy Update Magnitude: 0.50310
Value Function Update Magnitude: 0.71075

Collected Steps per Second: 21,734.85398
Overall Steps per Second: 10,283.62923

Timestep Collection Time: 2.30229
Timestep Consumption Time: 2.56369
PPO Batch Consumption Time: 0.29769
Total Iteration Time: 4.86599

Cumulative Model Updates: 95,440
Cumulative Timesteps: 795,865,552

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,218.41663
Policy Entropy: 3.66096
Value Function Loss: 0.03940

Mean KL Divergence: 0.01090
SB3 Clip Fraction: 0.14749
Policy Update Magnitude: 0.46641
Value Function Update Magnitude: 0.61678

Collected Steps per Second: 22,065.26933
Overall Steps per Second: 10,519.65462

Timestep Collection Time: 2.26709
Timestep Consumption Time: 2.48820
PPO Batch Consumption Time: 0.28309
Total Iteration Time: 4.75529

Cumulative Model Updates: 95,446
Cumulative Timesteps: 795,915,576

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 795915576...
Checkpoint 795915576 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 56,595.66169
Policy Entropy: 3.65384
Value Function Loss: 0.04344

Mean KL Divergence: 0.01057
SB3 Clip Fraction: 0.14448
Policy Update Magnitude: 0.49951
Value Function Update Magnitude: 0.53970

Collected Steps per Second: 22,104.66338
Overall Steps per Second: 10,471.71910

Timestep Collection Time: 2.26296
Timestep Consumption Time: 2.51390
PPO Batch Consumption Time: 0.28790
Total Iteration Time: 4.77687

Cumulative Model Updates: 95,452
Cumulative Timesteps: 795,965,598

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95,745.37728
Policy Entropy: 3.63704
Value Function Loss: 0.04525

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.14379
Policy Update Magnitude: 0.50415
Value Function Update Magnitude: 0.53578

Collected Steps per Second: 21,923.88128
Overall Steps per Second: 10,424.08389

Timestep Collection Time: 2.28180
Timestep Consumption Time: 2.51727
PPO Batch Consumption Time: 0.29033
Total Iteration Time: 4.79908

Cumulative Model Updates: 95,458
Cumulative Timesteps: 796,015,624

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 796015624...
Checkpoint 796015624 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 95,745.37728
Policy Entropy: 3.65637
Value Function Loss: 0.04284

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.14547
Policy Update Magnitude: 0.52124
Value Function Update Magnitude: 0.60138

Collected Steps per Second: 21,868.85917
Overall Steps per Second: 10,345.40313

Timestep Collection Time: 2.28700
Timestep Consumption Time: 2.54742
PPO Batch Consumption Time: 0.29504
Total Iteration Time: 4.83442

Cumulative Model Updates: 95,464
Cumulative Timesteps: 796,065,638

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95,745.37728
Policy Entropy: 3.64895
Value Function Loss: 0.04045

Mean KL Divergence: 0.01082
SB3 Clip Fraction: 0.14835
Policy Update Magnitude: 0.53792
Value Function Update Magnitude: 0.59862

Collected Steps per Second: 22,020.77380
Overall Steps per Second: 10,490.43551

Timestep Collection Time: 2.27158
Timestep Consumption Time: 2.49676
PPO Batch Consumption Time: 0.28359
Total Iteration Time: 4.76834

Cumulative Model Updates: 95,470
Cumulative Timesteps: 796,115,660

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 796115660...
Checkpoint 796115660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 95,745.37728
Policy Entropy: 3.65096
Value Function Loss: 0.03828

Mean KL Divergence: 0.01141
SB3 Clip Fraction: 0.15348
Policy Update Magnitude: 0.54906
Value Function Update Magnitude: 0.52696

Collected Steps per Second: 22,159.04531
Overall Steps per Second: 10,562.19813

Timestep Collection Time: 2.25641
Timestep Consumption Time: 2.47745
PPO Batch Consumption Time: 0.28502
Total Iteration Time: 4.73386

Cumulative Model Updates: 95,476
Cumulative Timesteps: 796,165,660

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 165,580.57653
Policy Entropy: 3.63664
Value Function Loss: 0.03741

Mean KL Divergence: 0.01177
SB3 Clip Fraction: 0.15860
Policy Update Magnitude: 0.49761
Value Function Update Magnitude: 0.49381

Collected Steps per Second: 21,670.91067
Overall Steps per Second: 10,421.30480

Timestep Collection Time: 2.30789
Timestep Consumption Time: 2.49132
PPO Batch Consumption Time: 0.28598
Total Iteration Time: 4.79921

Cumulative Model Updates: 95,482
Cumulative Timesteps: 796,215,674

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 796215674...
Checkpoint 796215674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 134,124.99702
Policy Entropy: 3.64644
Value Function Loss: 0.03694

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.14451
Policy Update Magnitude: 0.46624
Value Function Update Magnitude: 0.52415

Collected Steps per Second: 21,929.16097
Overall Steps per Second: 10,335.99508

Timestep Collection Time: 2.28025
Timestep Consumption Time: 2.55760
PPO Batch Consumption Time: 0.29921
Total Iteration Time: 4.83785

Cumulative Model Updates: 95,488
Cumulative Timesteps: 796,265,678

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 252,943.51000
Policy Entropy: 3.65873
Value Function Loss: 0.04384

Mean KL Divergence: 0.01156
SB3 Clip Fraction: 0.15845
Policy Update Magnitude: 0.46088
Value Function Update Magnitude: 0.58972

Collected Steps per Second: 21,986.18501
Overall Steps per Second: 10,420.09568

Timestep Collection Time: 2.27507
Timestep Consumption Time: 2.52527
PPO Batch Consumption Time: 0.29022
Total Iteration Time: 4.80034

Cumulative Model Updates: 95,494
Cumulative Timesteps: 796,315,698

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 796315698...
Checkpoint 796315698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,089.54652
Policy Entropy: 3.67915
Value Function Loss: 0.03832

Mean KL Divergence: 0.01058
SB3 Clip Fraction: 0.14650
Policy Update Magnitude: 0.44298
Value Function Update Magnitude: 0.55254

Collected Steps per Second: 22,270.73489
Overall Steps per Second: 10,545.19484

Timestep Collection Time: 2.24528
Timestep Consumption Time: 2.49660
PPO Batch Consumption Time: 0.28669
Total Iteration Time: 4.74188

Cumulative Model Updates: 95,500
Cumulative Timesteps: 796,365,702

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,556.26248
Policy Entropy: 3.68980
Value Function Loss: 0.03248

Mean KL Divergence: 0.01072
SB3 Clip Fraction: 0.14907
Policy Update Magnitude: 0.47730
Value Function Update Magnitude: 0.75334

Collected Steps per Second: 21,302.67706
Overall Steps per Second: 10,501.71444

Timestep Collection Time: 2.34740
Timestep Consumption Time: 2.41429
PPO Batch Consumption Time: 0.28581
Total Iteration Time: 4.76170

Cumulative Model Updates: 95,506
Cumulative Timesteps: 796,415,708

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 796415708...
Checkpoint 796415708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,720.73261
Policy Entropy: 3.69407
Value Function Loss: 0.03435

Mean KL Divergence: 0.01060
SB3 Clip Fraction: 0.14610
Policy Update Magnitude: 0.46624
Value Function Update Magnitude: 0.70832

Collected Steps per Second: 21,120.71481
Overall Steps per Second: 10,268.88076

Timestep Collection Time: 2.36763
Timestep Consumption Time: 2.50204
PPO Batch Consumption Time: 0.29958
Total Iteration Time: 4.86966

Cumulative Model Updates: 95,512
Cumulative Timesteps: 796,465,714

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 100,782.77944
Policy Entropy: 3.69356
Value Function Loss: 0.03269

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.14127
Policy Update Magnitude: 0.47369
Value Function Update Magnitude: 0.74363

Collected Steps per Second: 21,705.64620
Overall Steps per Second: 10,486.73379

Timestep Collection Time: 2.30465
Timestep Consumption Time: 2.46556
PPO Batch Consumption Time: 0.29627
Total Iteration Time: 4.77022

Cumulative Model Updates: 95,518
Cumulative Timesteps: 796,515,738

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 796515738...
Checkpoint 796515738 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,679.90237
Policy Entropy: 3.68458
Value Function Loss: 0.03335

Mean KL Divergence: 0.01126
SB3 Clip Fraction: 0.14977
Policy Update Magnitude: 0.49569
Value Function Update Magnitude: 0.70353

Collected Steps per Second: 21,303.49220
Overall Steps per Second: 10,532.18651

Timestep Collection Time: 2.34722
Timestep Consumption Time: 2.40051
PPO Batch Consumption Time: 0.28405
Total Iteration Time: 4.74773

Cumulative Model Updates: 95,524
Cumulative Timesteps: 796,565,742

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,279.66791
Policy Entropy: 3.67401
Value Function Loss: 0.04203

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.13792
Policy Update Magnitude: 0.49563
Value Function Update Magnitude: 0.59818

Collected Steps per Second: 21,284.35823
Overall Steps per Second: 10,063.11787

Timestep Collection Time: 2.35036
Timestep Consumption Time: 2.62086
PPO Batch Consumption Time: 0.30954
Total Iteration Time: 4.97122

Cumulative Model Updates: 95,530
Cumulative Timesteps: 796,615,768

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 796615768...
Checkpoint 796615768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,279.66791
Policy Entropy: 3.66641
Value Function Loss: 0.04553

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.14801
Policy Update Magnitude: 0.54530
Value Function Update Magnitude: 0.52480

Collected Steps per Second: 21,935.19588
Overall Steps per Second: 10,449.91276

Timestep Collection Time: 2.28145
Timestep Consumption Time: 2.50749
PPO Batch Consumption Time: 0.29336
Total Iteration Time: 4.78894

Cumulative Model Updates: 95,536
Cumulative Timesteps: 796,665,812

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 117,314.23742
Policy Entropy: 3.65150
Value Function Loss: 0.05886

Mean KL Divergence: 0.01076
SB3 Clip Fraction: 0.14618
Policy Update Magnitude: 0.55670
Value Function Update Magnitude: 0.56244

Collected Steps per Second: 22,551.56615
Overall Steps per Second: 10,709.54115

Timestep Collection Time: 2.21785
Timestep Consumption Time: 2.45238
PPO Batch Consumption Time: 0.28389
Total Iteration Time: 4.67023

Cumulative Model Updates: 95,542
Cumulative Timesteps: 796,715,828

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 796715828...
Checkpoint 796715828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40,912.07404
Policy Entropy: 3.66174
Value Function Loss: 0.04620

Mean KL Divergence: 0.01082
SB3 Clip Fraction: 0.14847
Policy Update Magnitude: 0.57441
Value Function Update Magnitude: 0.45308

Collected Steps per Second: 22,011.43512
Overall Steps per Second: 10,414.22643

Timestep Collection Time: 2.27291
Timestep Consumption Time: 2.53110
PPO Batch Consumption Time: 0.29381
Total Iteration Time: 4.80401

Cumulative Model Updates: 95,548
Cumulative Timesteps: 796,765,858

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,071.65544
Policy Entropy: 3.64613
Value Function Loss: 0.04546

Mean KL Divergence: 0.01142
SB3 Clip Fraction: 0.15448
Policy Update Magnitude: 0.53184
Value Function Update Magnitude: 0.40546

Collected Steps per Second: 21,620.03419
Overall Steps per Second: 10,234.12909

Timestep Collection Time: 2.31276
Timestep Consumption Time: 2.57305
PPO Batch Consumption Time: 0.29810
Total Iteration Time: 4.88581

Cumulative Model Updates: 95,554
Cumulative Timesteps: 796,815,860

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 796815860...
Checkpoint 796815860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,963.86564
Policy Entropy: 3.65081
Value Function Loss: 0.04261

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.14431
Policy Update Magnitude: 0.50719
Value Function Update Magnitude: 0.43407

Collected Steps per Second: 21,748.42201
Overall Steps per Second: 10,169.18322

Timestep Collection Time: 2.30012
Timestep Consumption Time: 2.61905
PPO Batch Consumption Time: 0.31025
Total Iteration Time: 4.91918

Cumulative Model Updates: 95,560
Cumulative Timesteps: 796,865,884

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 106,396.52942
Policy Entropy: 3.64513
Value Function Loss: 0.04242

Mean KL Divergence: 0.01108
SB3 Clip Fraction: 0.15095
Policy Update Magnitude: 0.51772
Value Function Update Magnitude: 0.53589

Collected Steps per Second: 21,948.70492
Overall Steps per Second: 10,505.65310

Timestep Collection Time: 2.27831
Timestep Consumption Time: 2.48160
PPO Batch Consumption Time: 0.28448
Total Iteration Time: 4.75991

Cumulative Model Updates: 95,566
Cumulative Timesteps: 796,915,890

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 796915890...
Checkpoint 796915890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 106,396.52942
Policy Entropy: 3.65375
Value Function Loss: 0.03920

Mean KL Divergence: 0.01078
SB3 Clip Fraction: 0.14773
Policy Update Magnitude: 0.50861
Value Function Update Magnitude: 0.56940

Collected Steps per Second: 21,922.27099
Overall Steps per Second: 10,353.06820

Timestep Collection Time: 2.28079
Timestep Consumption Time: 2.54870
PPO Batch Consumption Time: 0.29559
Total Iteration Time: 4.82949

Cumulative Model Updates: 95,572
Cumulative Timesteps: 796,965,890

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 228,676.58436
Policy Entropy: 3.66649
Value Function Loss: 0.03663

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.14222
Policy Update Magnitude: 0.51653
Value Function Update Magnitude: 0.58246

Collected Steps per Second: 22,208.25858
Overall Steps per Second: 10,396.50138

Timestep Collection Time: 2.25268
Timestep Consumption Time: 2.55933
PPO Batch Consumption Time: 0.29796
Total Iteration Time: 4.81200

Cumulative Model Updates: 95,578
Cumulative Timesteps: 797,015,918

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 797015918...
Checkpoint 797015918 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 79,764.19603
Policy Entropy: 3.67648
Value Function Loss: 0.03623

Mean KL Divergence: 0.01083
SB3 Clip Fraction: 0.14885
Policy Update Magnitude: 0.54516
Value Function Update Magnitude: 0.66336

Collected Steps per Second: 22,011.35186
Overall Steps per Second: 10,517.19893

Timestep Collection Time: 2.27219
Timestep Consumption Time: 2.48326
PPO Batch Consumption Time: 0.28338
Total Iteration Time: 4.75545

Cumulative Model Updates: 95,584
Cumulative Timesteps: 797,065,932

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 182,220.26175
Policy Entropy: 3.69126
Value Function Loss: 0.03799

Mean KL Divergence: 0.01053
SB3 Clip Fraction: 0.14344
Policy Update Magnitude: 0.54240
Value Function Update Magnitude: 0.83663

Collected Steps per Second: 22,567.57533
Overall Steps per Second: 10,493.87800

Timestep Collection Time: 2.21557
Timestep Consumption Time: 2.54911
PPO Batch Consumption Time: 0.29300
Total Iteration Time: 4.76468

Cumulative Model Updates: 95,590
Cumulative Timesteps: 797,115,932

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 797115932...
Checkpoint 797115932 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 85,362.42889
Policy Entropy: 3.71076
Value Function Loss: 0.03657

Mean KL Divergence: 0.01104
SB3 Clip Fraction: 0.14542
Policy Update Magnitude: 0.58471
Value Function Update Magnitude: 0.73428

Collected Steps per Second: 22,132.40252
Overall Steps per Second: 10,561.47143

Timestep Collection Time: 2.26031
Timestep Consumption Time: 2.47634
PPO Batch Consumption Time: 0.28433
Total Iteration Time: 4.73665

Cumulative Model Updates: 95,596
Cumulative Timesteps: 797,165,958

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 265,335.98763
Policy Entropy: 3.70509
Value Function Loss: 0.03777

Mean KL Divergence: 0.01116
SB3 Clip Fraction: 0.14941
Policy Update Magnitude: 0.57569
Value Function Update Magnitude: 0.67438

Collected Steps per Second: 22,352.70285
Overall Steps per Second: 10,555.10644

Timestep Collection Time: 2.23812
Timestep Consumption Time: 2.50158
PPO Batch Consumption Time: 0.28517
Total Iteration Time: 4.73970

Cumulative Model Updates: 95,602
Cumulative Timesteps: 797,215,986

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 797215986...
Checkpoint 797215986 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 187,060.76552
Policy Entropy: 3.70275
Value Function Loss: 0.03737

Mean KL Divergence: 0.01085
SB3 Clip Fraction: 0.14574
Policy Update Magnitude: 0.57156
Value Function Update Magnitude: 0.65629

Collected Steps per Second: 22,031.90504
Overall Steps per Second: 10,544.56956

Timestep Collection Time: 2.27053
Timestep Consumption Time: 2.47353
PPO Batch Consumption Time: 0.28456
Total Iteration Time: 4.74405

Cumulative Model Updates: 95,608
Cumulative Timesteps: 797,266,010

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,667.69574
Policy Entropy: 3.70033
Value Function Loss: 0.03578

Mean KL Divergence: 0.01091
SB3 Clip Fraction: 0.14775
Policy Update Magnitude: 0.56977
Value Function Update Magnitude: 0.75807

Collected Steps per Second: 22,581.64067
Overall Steps per Second: 10,507.86200

Timestep Collection Time: 2.21445
Timestep Consumption Time: 2.54446
PPO Batch Consumption Time: 0.29257
Total Iteration Time: 4.75891

Cumulative Model Updates: 95,614
Cumulative Timesteps: 797,316,016

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 797316016...
Checkpoint 797316016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,836.84883
Policy Entropy: 3.67738
Value Function Loss: 0.03699

Mean KL Divergence: 0.01097
SB3 Clip Fraction: 0.15063
Policy Update Magnitude: 0.53187
Value Function Update Magnitude: 0.92913

Collected Steps per Second: 22,221.64963
Overall Steps per Second: 10,576.29540

Timestep Collection Time: 2.25096
Timestep Consumption Time: 2.47849
PPO Batch Consumption Time: 0.28542
Total Iteration Time: 4.72944

Cumulative Model Updates: 95,620
Cumulative Timesteps: 797,366,036

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,439.83227
Policy Entropy: 3.68420
Value Function Loss: 0.03277

Mean KL Divergence: 0.01067
SB3 Clip Fraction: 0.14493
Policy Update Magnitude: 0.50706
Value Function Update Magnitude: 0.88579

Collected Steps per Second: 22,360.35772
Overall Steps per Second: 10,634.26544

Timestep Collection Time: 2.23735
Timestep Consumption Time: 2.46706
PPO Batch Consumption Time: 0.28191
Total Iteration Time: 4.70442

Cumulative Model Updates: 95,626
Cumulative Timesteps: 797,416,064

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 797416064...
Checkpoint 797416064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 127,259.75925
Policy Entropy: 3.66628
Value Function Loss: 0.03519

Mean KL Divergence: 0.01083
SB3 Clip Fraction: 0.14650
Policy Update Magnitude: 0.48420
Value Function Update Magnitude: 0.65490

Collected Steps per Second: 22,184.19260
Overall Steps per Second: 10,607.18429

Timestep Collection Time: 2.25386
Timestep Consumption Time: 2.45993
PPO Batch Consumption Time: 0.28235
Total Iteration Time: 4.71379

Cumulative Model Updates: 95,632
Cumulative Timesteps: 797,466,064

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83,492.67924
Policy Entropy: 3.67064
Value Function Loss: 0.03116

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.14402
Policy Update Magnitude: 0.48497
Value Function Update Magnitude: 0.58143

Collected Steps per Second: 22,143.58254
Overall Steps per Second: 10,419.64514

Timestep Collection Time: 2.25916
Timestep Consumption Time: 2.54196
PPO Batch Consumption Time: 0.29457
Total Iteration Time: 4.80112

Cumulative Model Updates: 95,638
Cumulative Timesteps: 797,516,090

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 797516090...
Checkpoint 797516090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 58,988.83351
Policy Entropy: 3.65811
Value Function Loss: 0.03561

Mean KL Divergence: 0.01077
SB3 Clip Fraction: 0.14495
Policy Update Magnitude: 0.48389
Value Function Update Magnitude: 0.55941

Collected Steps per Second: 22,032.13707
Overall Steps per Second: 10,566.77233

Timestep Collection Time: 2.26968
Timestep Consumption Time: 2.46270
PPO Batch Consumption Time: 0.28391
Total Iteration Time: 4.73238

Cumulative Model Updates: 95,644
Cumulative Timesteps: 797,566,096

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58,705.22453
Policy Entropy: 3.66543
Value Function Loss: 0.03599

Mean KL Divergence: 0.01083
SB3 Clip Fraction: 0.14655
Policy Update Magnitude: 0.54861
Value Function Update Magnitude: 0.56898

Collected Steps per Second: 21,723.45237
Overall Steps per Second: 10,509.42825

Timestep Collection Time: 2.30258
Timestep Consumption Time: 2.45696
PPO Batch Consumption Time: 0.29189
Total Iteration Time: 4.75954

Cumulative Model Updates: 95,650
Cumulative Timesteps: 797,616,116

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 797616116...
Checkpoint 797616116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,522.72188
Policy Entropy: 3.65966
Value Function Loss: 0.04049

Mean KL Divergence: 0.01097
SB3 Clip Fraction: 0.15055
Policy Update Magnitude: 0.54969
Value Function Update Magnitude: 0.61947

Collected Steps per Second: 21,456.93912
Overall Steps per Second: 10,588.83486

Timestep Collection Time: 2.33127
Timestep Consumption Time: 2.39276
PPO Batch Consumption Time: 0.28403
Total Iteration Time: 4.72403

Cumulative Model Updates: 95,656
Cumulative Timesteps: 797,666,138

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 274,247.39145
Policy Entropy: 3.64608
Value Function Loss: 0.04411

Mean KL Divergence: 0.01128
SB3 Clip Fraction: 0.15505
Policy Update Magnitude: 0.51100
Value Function Update Magnitude: 0.62698

Collected Steps per Second: 21,482.65181
Overall Steps per Second: 10,588.54242

Timestep Collection Time: 2.32774
Timestep Consumption Time: 2.39491
PPO Batch Consumption Time: 0.28326
Total Iteration Time: 4.72265

Cumulative Model Updates: 95,662
Cumulative Timesteps: 797,716,144

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 797716144...
Checkpoint 797716144 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 198,269.77301
Policy Entropy: 3.64860
Value Function Loss: 0.04781

Mean KL Divergence: 0.01211
SB3 Clip Fraction: 0.16489
Policy Update Magnitude: 0.50530
Value Function Update Magnitude: 0.53941

Collected Steps per Second: 21,357.86238
Overall Steps per Second: 10,296.81940

Timestep Collection Time: 2.34293
Timestep Consumption Time: 2.51682
PPO Batch Consumption Time: 0.29607
Total Iteration Time: 4.85975

Cumulative Model Updates: 95,668
Cumulative Timesteps: 797,766,184

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 268,497.09202
Policy Entropy: 3.65020
Value Function Loss: 0.04931

Mean KL Divergence: 0.01139
SB3 Clip Fraction: 0.15216
Policy Update Magnitude: 0.47775
Value Function Update Magnitude: 0.47363

Collected Steps per Second: 22,146.77776
Overall Steps per Second: 10,497.82483

Timestep Collection Time: 2.25803
Timestep Consumption Time: 2.50563
PPO Batch Consumption Time: 0.29373
Total Iteration Time: 4.76365

Cumulative Model Updates: 95,674
Cumulative Timesteps: 797,816,192

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 797816192...
Checkpoint 797816192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 217,489.85154
Policy Entropy: 3.65890
Value Function Loss: 0.04379

Mean KL Divergence: 0.01118
SB3 Clip Fraction: 0.15008
Policy Update Magnitude: 0.52211
Value Function Update Magnitude: 0.53675

Collected Steps per Second: 21,901.83856
Overall Steps per Second: 10,450.96071

Timestep Collection Time: 2.28310
Timestep Consumption Time: 2.50154
PPO Batch Consumption Time: 0.29230
Total Iteration Time: 4.78463

Cumulative Model Updates: 95,680
Cumulative Timesteps: 797,866,196

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 232,466.87598
Policy Entropy: 3.63895
Value Function Loss: 0.05147

Mean KL Divergence: 0.01114
SB3 Clip Fraction: 0.15379
Policy Update Magnitude: 0.51724
Value Function Update Magnitude: 0.54144

Collected Steps per Second: 22,130.37958
Overall Steps per Second: 10,475.28495

Timestep Collection Time: 2.25988
Timestep Consumption Time: 2.51441
PPO Batch Consumption Time: 0.28714
Total Iteration Time: 4.77429

Cumulative Model Updates: 95,686
Cumulative Timesteps: 797,916,208

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 797916208...
Checkpoint 797916208 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,463.26552
Policy Entropy: 3.66864
Value Function Loss: 0.04524

Mean KL Divergence: 0.01074
SB3 Clip Fraction: 0.14736
Policy Update Magnitude: 0.49619
Value Function Update Magnitude: 0.53429

Collected Steps per Second: 22,305.66388
Overall Steps per Second: 10,494.34048

Timestep Collection Time: 2.24167
Timestep Consumption Time: 2.52299
PPO Batch Consumption Time: 0.29187
Total Iteration Time: 4.76466

Cumulative Model Updates: 95,692
Cumulative Timesteps: 797,966,210

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,578.28173
Policy Entropy: 3.66234
Value Function Loss: 0.04672

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.14067
Policy Update Magnitude: 0.48207
Value Function Update Magnitude: 0.56481

Collected Steps per Second: 22,379.11812
Overall Steps per Second: 10,630.21729

Timestep Collection Time: 2.23440
Timestep Consumption Time: 2.46954
PPO Batch Consumption Time: 0.28282
Total Iteration Time: 4.70395

Cumulative Model Updates: 95,698
Cumulative Timesteps: 798,016,214

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 798016214...
Checkpoint 798016214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,223.28152
Policy Entropy: 3.67504
Value Function Loss: 0.04023

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.14032
Policy Update Magnitude: 0.57915
Value Function Update Magnitude: 0.58106

Collected Steps per Second: 22,199.82183
Overall Steps per Second: 10,553.14953

Timestep Collection Time: 2.25353
Timestep Consumption Time: 2.48704
PPO Batch Consumption Time: 0.28537
Total Iteration Time: 4.74058

Cumulative Model Updates: 95,704
Cumulative Timesteps: 798,066,242

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,617.91221
Policy Entropy: 3.67222
Value Function Loss: 0.04071

Mean KL Divergence: 0.01176
SB3 Clip Fraction: 0.15559
Policy Update Magnitude: 0.56803
Value Function Update Magnitude: 0.56409

Collected Steps per Second: 22,223.54206
Overall Steps per Second: 10,585.21415

Timestep Collection Time: 2.25113
Timestep Consumption Time: 2.47509
PPO Batch Consumption Time: 0.28302
Total Iteration Time: 4.72622

Cumulative Model Updates: 95,710
Cumulative Timesteps: 798,116,270

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 798116270...
Checkpoint 798116270 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,617.91221
Policy Entropy: 3.66960
Value Function Loss: 0.03639

Mean KL Divergence: 0.01165
SB3 Clip Fraction: 0.15570
Policy Update Magnitude: 0.51536
Value Function Update Magnitude: 0.59843

Collected Steps per Second: 21,715.76036
Overall Steps per Second: 10,485.23039

Timestep Collection Time: 2.30386
Timestep Consumption Time: 2.46762
PPO Batch Consumption Time: 0.28464
Total Iteration Time: 4.77147

Cumulative Model Updates: 95,716
Cumulative Timesteps: 798,166,300

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,617.91221
Policy Entropy: 3.66011
Value Function Loss: 0.03706

Mean KL Divergence: 0.01155
SB3 Clip Fraction: 0.15595
Policy Update Magnitude: 0.48067
Value Function Update Magnitude: 0.58062

Collected Steps per Second: 21,849.10624
Overall Steps per Second: 10,466.43166

Timestep Collection Time: 2.28861
Timestep Consumption Time: 2.48895
PPO Batch Consumption Time: 0.28362
Total Iteration Time: 4.77756

Cumulative Model Updates: 95,722
Cumulative Timesteps: 798,216,304

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 798216304...
Checkpoint 798216304 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,617.91221
Policy Entropy: 3.63657
Value Function Loss: 0.03576

Mean KL Divergence: 0.01184
SB3 Clip Fraction: 0.15698
Policy Update Magnitude: 0.49757
Value Function Update Magnitude: 0.57332

Collected Steps per Second: 22,152.25824
Overall Steps per Second: 10,452.00098

Timestep Collection Time: 2.25783
Timestep Consumption Time: 2.52748
PPO Batch Consumption Time: 0.29314
Total Iteration Time: 4.78530

Cumulative Model Updates: 95,728
Cumulative Timesteps: 798,266,320

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,617.91221
Policy Entropy: 3.63249
Value Function Loss: 0.03748

Mean KL Divergence: 0.01123
SB3 Clip Fraction: 0.15082
Policy Update Magnitude: 0.50890
Value Function Update Magnitude: 0.54803

Collected Steps per Second: 22,708.84082
Overall Steps per Second: 10,640.89513

Timestep Collection Time: 2.20258
Timestep Consumption Time: 2.49797
PPO Batch Consumption Time: 0.28396
Total Iteration Time: 4.70054

Cumulative Model Updates: 95,734
Cumulative Timesteps: 798,316,338

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 798316338...
Checkpoint 798316338 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 76,803.35977
Policy Entropy: 3.62823
Value Function Loss: 0.03990

Mean KL Divergence: 0.01191
SB3 Clip Fraction: 0.15933
Policy Update Magnitude: 0.53766
Value Function Update Magnitude: 0.48732

Collected Steps per Second: 22,014.43624
Overall Steps per Second: 10,400.13334

Timestep Collection Time: 2.27178
Timestep Consumption Time: 2.53700
PPO Batch Consumption Time: 0.29608
Total Iteration Time: 4.80878

Cumulative Model Updates: 95,740
Cumulative Timesteps: 798,366,350

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 362,332.04135
Policy Entropy: 3.62950
Value Function Loss: 0.04078

Mean KL Divergence: 0.01174
SB3 Clip Fraction: 0.15922
Policy Update Magnitude: 0.54069
Value Function Update Magnitude: 0.47920

Collected Steps per Second: 22,003.14152
Overall Steps per Second: 10,706.95447

Timestep Collection Time: 2.27431
Timestep Consumption Time: 2.39947
PPO Batch Consumption Time: 0.28347
Total Iteration Time: 4.67378

Cumulative Model Updates: 95,746
Cumulative Timesteps: 798,416,392

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 798416392...
Checkpoint 798416392 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 330,835.48458
Policy Entropy: 3.63149
Value Function Loss: 0.04074

Mean KL Divergence: 0.01059
SB3 Clip Fraction: 0.14602
Policy Update Magnitude: 0.51796
Value Function Update Magnitude: 0.52092

Collected Steps per Second: 21,273.50138
Overall Steps per Second: 10,358.66564

Timestep Collection Time: 2.35156
Timestep Consumption Time: 2.47782
PPO Batch Consumption Time: 0.29735
Total Iteration Time: 4.82939

Cumulative Model Updates: 95,752
Cumulative Timesteps: 798,466,418

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75,744.32662
Policy Entropy: 3.64630
Value Function Loss: 0.03763

Mean KL Divergence: 0.01119
SB3 Clip Fraction: 0.15184
Policy Update Magnitude: 0.52310
Value Function Update Magnitude: 0.50899

Collected Steps per Second: 21,634.79031
Overall Steps per Second: 10,472.89186

Timestep Collection Time: 2.31146
Timestep Consumption Time: 2.46353
PPO Batch Consumption Time: 0.29708
Total Iteration Time: 4.77499

Cumulative Model Updates: 95,758
Cumulative Timesteps: 798,516,426

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 798516426...
Checkpoint 798516426 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 405,315.72140
Policy Entropy: 3.66450
Value Function Loss: 0.03993

Mean KL Divergence: 0.01072
SB3 Clip Fraction: 0.14615
Policy Update Magnitude: 0.52997
Value Function Update Magnitude: 0.61050

Collected Steps per Second: 21,575.11356
Overall Steps per Second: 10,399.04441

Timestep Collection Time: 2.31823
Timestep Consumption Time: 2.49145
PPO Batch Consumption Time: 0.29132
Total Iteration Time: 4.80967

Cumulative Model Updates: 95,764
Cumulative Timesteps: 798,566,442

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60,854.12345
Policy Entropy: 3.68013
Value Function Loss: 0.03733

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.13778
Policy Update Magnitude: 0.54725
Value Function Update Magnitude: 0.67120

Collected Steps per Second: 22,681.93063
Overall Steps per Second: 10,526.52400

Timestep Collection Time: 2.20546
Timestep Consumption Time: 2.54673
PPO Batch Consumption Time: 0.29765
Total Iteration Time: 4.75219

Cumulative Model Updates: 95,770
Cumulative Timesteps: 798,616,466

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 798616466...
Checkpoint 798616466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,221.09744
Policy Entropy: 3.68695
Value Function Loss: 0.03634

Mean KL Divergence: 0.01159
SB3 Clip Fraction: 0.15508
Policy Update Magnitude: 0.56320
Value Function Update Magnitude: 0.72282

Collected Steps per Second: 21,951.20731
Overall Steps per Second: 10,473.52786

Timestep Collection Time: 2.27823
Timestep Consumption Time: 2.49666
PPO Batch Consumption Time: 0.29466
Total Iteration Time: 4.77490

Cumulative Model Updates: 95,776
Cumulative Timesteps: 798,666,476

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,586.33500
Policy Entropy: 3.67471
Value Function Loss: 0.04086

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.14104
Policy Update Magnitude: 0.52188
Value Function Update Magnitude: 0.74813

Collected Steps per Second: 22,663.63729
Overall Steps per Second: 10,666.60045

Timestep Collection Time: 2.20635
Timestep Consumption Time: 2.48155
PPO Batch Consumption Time: 0.28410
Total Iteration Time: 4.68790

Cumulative Model Updates: 95,782
Cumulative Timesteps: 798,716,480

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 798716480...
Checkpoint 798716480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47,806.61764
Policy Entropy: 3.67472
Value Function Loss: 0.04413

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.14151
Policy Update Magnitude: 0.53983
Value Function Update Magnitude: 0.87238

Collected Steps per Second: 21,967.92214
Overall Steps per Second: 10,383.98210

Timestep Collection Time: 2.27705
Timestep Consumption Time: 2.54018
PPO Batch Consumption Time: 0.29693
Total Iteration Time: 4.81723

Cumulative Model Updates: 95,788
Cumulative Timesteps: 798,766,502

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 243,714.69781
Policy Entropy: 3.65864
Value Function Loss: 0.04549

Mean KL Divergence: 0.01076
SB3 Clip Fraction: 0.14858
Policy Update Magnitude: 0.55518
Value Function Update Magnitude: 0.80620

Collected Steps per Second: 22,400.66705
Overall Steps per Second: 10,514.92513

Timestep Collection Time: 2.23359
Timestep Consumption Time: 2.52478
PPO Batch Consumption Time: 0.29342
Total Iteration Time: 4.75838

Cumulative Model Updates: 95,794
Cumulative Timesteps: 798,816,536

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 798816536...
Checkpoint 798816536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 243,714.69781
Policy Entropy: 3.66438
Value Function Loss: 0.03923

Mean KL Divergence: 0.01103
SB3 Clip Fraction: 0.15164
Policy Update Magnitude: 0.50606
Value Function Update Magnitude: 0.74775

Collected Steps per Second: 22,090.72240
Overall Steps per Second: 10,444.57434

Timestep Collection Time: 2.26412
Timestep Consumption Time: 2.52459
PPO Batch Consumption Time: 0.28983
Total Iteration Time: 4.78871

Cumulative Model Updates: 95,800
Cumulative Timesteps: 798,866,552

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 242,000.58137
Policy Entropy: 3.64768
Value Function Loss: 0.04070

Mean KL Divergence: 0.01098
SB3 Clip Fraction: 0.15238
Policy Update Magnitude: 0.45493
Value Function Update Magnitude: 0.58496

Collected Steps per Second: 22,495.79154
Overall Steps per Second: 10,492.47835

Timestep Collection Time: 2.22344
Timestep Consumption Time: 2.54360
PPO Batch Consumption Time: 0.29488
Total Iteration Time: 4.76703

Cumulative Model Updates: 95,806
Cumulative Timesteps: 798,916,570

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 798916570...
Checkpoint 798916570 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 64,356.56555
Policy Entropy: 3.67079
Value Function Loss: 0.03342

Mean KL Divergence: 0.01150
SB3 Clip Fraction: 0.15645
Policy Update Magnitude: 0.45908
Value Function Update Magnitude: 0.54696

Collected Steps per Second: 22,155.43069
Overall Steps per Second: 10,540.37842

Timestep Collection Time: 2.25814
Timestep Consumption Time: 2.48837
PPO Batch Consumption Time: 0.28542
Total Iteration Time: 4.74651

Cumulative Model Updates: 95,812
Cumulative Timesteps: 798,966,600

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,181.69854
Policy Entropy: 3.67092
Value Function Loss: 0.03344

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.14127
Policy Update Magnitude: 0.45854
Value Function Update Magnitude: 0.72861

Collected Steps per Second: 21,767.98407
Overall Steps per Second: 10,519.37577

Timestep Collection Time: 2.29750
Timestep Consumption Time: 2.45677
PPO Batch Consumption Time: 0.29389
Total Iteration Time: 4.75427

Cumulative Model Updates: 95,818
Cumulative Timesteps: 799,016,612

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 799016612...
Checkpoint 799016612 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,181.69854
Policy Entropy: 3.68368
Value Function Loss: 0.03052

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.14229
Policy Update Magnitude: 0.48751
Value Function Update Magnitude: 0.67575

Collected Steps per Second: 21,336.27723
Overall Steps per Second: 10,404.79122

Timestep Collection Time: 2.34465
Timestep Consumption Time: 2.46333
PPO Batch Consumption Time: 0.29467
Total Iteration Time: 4.80798

Cumulative Model Updates: 95,824
Cumulative Timesteps: 799,066,638

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 209,047.00483
Policy Entropy: 3.65839
Value Function Loss: 0.04055

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.14867
Policy Update Magnitude: 0.48586
Value Function Update Magnitude: 0.61220

Collected Steps per Second: 21,545.38345
Overall Steps per Second: 10,307.88802

Timestep Collection Time: 2.32115
Timestep Consumption Time: 2.53048
PPO Batch Consumption Time: 0.30502
Total Iteration Time: 4.85162

Cumulative Model Updates: 95,830
Cumulative Timesteps: 799,116,648

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 799116648...
Checkpoint 799116648 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 111,111.42494
Policy Entropy: 3.66256
Value Function Loss: 0.03870

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.14016
Policy Update Magnitude: 0.49873
Value Function Update Magnitude: 0.62850

Collected Steps per Second: 19,210.37566
Overall Steps per Second: 9,849.22098

Timestep Collection Time: 2.60338
Timestep Consumption Time: 2.47438
PPO Batch Consumption Time: 0.28447
Total Iteration Time: 5.07776

Cumulative Model Updates: 95,836
Cumulative Timesteps: 799,166,660

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 111,111.42494
Policy Entropy: 3.65682
Value Function Loss: 0.04835

Mean KL Divergence: 0.01156
SB3 Clip Fraction: 0.15470
Policy Update Magnitude: 0.51398
Value Function Update Magnitude: 0.59194

Collected Steps per Second: 21,226.75849
Overall Steps per Second: 9,944.14394

Timestep Collection Time: 2.35712
Timestep Consumption Time: 2.67438
PPO Batch Consumption Time: 0.30998
Total Iteration Time: 5.03150

Cumulative Model Updates: 95,842
Cumulative Timesteps: 799,216,694

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 799216694...
Checkpoint 799216694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 82,295.72611
Policy Entropy: 3.66789
Value Function Loss: 0.03918

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.14411
Policy Update Magnitude: 0.51677
Value Function Update Magnitude: 0.47152

Collected Steps per Second: 21,210.23605
Overall Steps per Second: 10,110.85352

Timestep Collection Time: 2.35830
Timestep Consumption Time: 2.58886
PPO Batch Consumption Time: 0.30150
Total Iteration Time: 4.94716

Cumulative Model Updates: 95,848
Cumulative Timesteps: 799,266,714

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53,912.24001
Policy Entropy: 3.67296
Value Function Loss: 0.04178

Mean KL Divergence: 0.01104
SB3 Clip Fraction: 0.15123
Policy Update Magnitude: 0.54116
Value Function Update Magnitude: 0.58126

Collected Steps per Second: 20,988.37622
Overall Steps per Second: 10,138.52387

Timestep Collection Time: 2.38227
Timestep Consumption Time: 2.54941
PPO Batch Consumption Time: 0.29587
Total Iteration Time: 4.93168

Cumulative Model Updates: 95,854
Cumulative Timesteps: 799,316,714

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 799316714...
Checkpoint 799316714 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 53,912.24001
Policy Entropy: 3.68791
Value Function Loss: 0.03233

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.14949
Policy Update Magnitude: 0.52363
Value Function Update Magnitude: 0.60649

Collected Steps per Second: 21,322.19343
Overall Steps per Second: 10,234.07091

Timestep Collection Time: 2.34554
Timestep Consumption Time: 2.54128
PPO Batch Consumption Time: 0.29373
Total Iteration Time: 4.88681

Cumulative Model Updates: 95,860
Cumulative Timesteps: 799,366,726

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53,912.24001
Policy Entropy: 3.67241
Value Function Loss: 0.02718

Mean KL Divergence: 0.01100
SB3 Clip Fraction: 0.15114
Policy Update Magnitude: 0.48583
Value Function Update Magnitude: 0.66754

Collected Steps per Second: 22,464.38912
Overall Steps per Second: 10,478.89989

Timestep Collection Time: 2.22628
Timestep Consumption Time: 2.54636
PPO Batch Consumption Time: 0.29207
Total Iteration Time: 4.77264

Cumulative Model Updates: 95,866
Cumulative Timesteps: 799,416,738

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 799416738...
Checkpoint 799416738 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 53,912.24001
Policy Entropy: 3.65935
Value Function Loss: 0.02613

Mean KL Divergence: 0.01104
SB3 Clip Fraction: 0.15371
Policy Update Magnitude: 0.44506
Value Function Update Magnitude: 0.62928

Collected Steps per Second: 19,962.90858
Overall Steps per Second: 10,031.43716

Timestep Collection Time: 2.50495
Timestep Consumption Time: 2.47998
PPO Batch Consumption Time: 0.28368
Total Iteration Time: 4.98493

Cumulative Model Updates: 95,872
Cumulative Timesteps: 799,466,744

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84,707.36620
Policy Entropy: 3.65552
Value Function Loss: 0.02786

Mean KL Divergence: 0.01070
SB3 Clip Fraction: 0.14905
Policy Update Magnitude: 0.43074
Value Function Update Magnitude: 0.61406

Collected Steps per Second: 22,208.93414
Overall Steps per Second: 10,531.45547

Timestep Collection Time: 2.25198
Timestep Consumption Time: 2.49703
PPO Batch Consumption Time: 0.28214
Total Iteration Time: 4.74901

Cumulative Model Updates: 95,878
Cumulative Timesteps: 799,516,758

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 799516758...
Checkpoint 799516758 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84,707.36620
Policy Entropy: 3.66545
Value Function Loss: 0.02851

Mean KL Divergence: 0.01120
SB3 Clip Fraction: 0.15407
Policy Update Magnitude: 0.41776
Value Function Update Magnitude: 0.53161

Collected Steps per Second: 21,752.21941
Overall Steps per Second: 10,494.11758

Timestep Collection Time: 2.29981
Timestep Consumption Time: 2.46724
PPO Batch Consumption Time: 0.28428
Total Iteration Time: 4.76705

Cumulative Model Updates: 95,884
Cumulative Timesteps: 799,566,784

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84,707.36620
Policy Entropy: 3.66919
Value Function Loss: 0.02743

Mean KL Divergence: 0.01085
SB3 Clip Fraction: 0.15080
Policy Update Magnitude: 0.39399
Value Function Update Magnitude: 0.47171

Collected Steps per Second: 21,297.82164
Overall Steps per Second: 10,112.71145

Timestep Collection Time: 2.34860
Timestep Consumption Time: 2.59765
PPO Batch Consumption Time: 0.30272
Total Iteration Time: 4.94625

Cumulative Model Updates: 95,890
Cumulative Timesteps: 799,616,804

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 799616804...
Checkpoint 799616804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84,707.36620
Policy Entropy: 3.66216
Value Function Loss: 0.02840

Mean KL Divergence: 0.01142
SB3 Clip Fraction: 0.15820
Policy Update Magnitude: 0.40926
Value Function Update Magnitude: 0.41030

Collected Steps per Second: 22,234.54264
Overall Steps per Second: 10,499.72988

Timestep Collection Time: 2.24956
Timestep Consumption Time: 2.51418
PPO Batch Consumption Time: 0.28983
Total Iteration Time: 4.76374

Cumulative Model Updates: 95,896
Cumulative Timesteps: 799,666,822

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84,707.36620
Policy Entropy: 3.66308
Value Function Loss: 0.02945

Mean KL Divergence: 0.01121
SB3 Clip Fraction: 0.15691
Policy Update Magnitude: 0.44930
Value Function Update Magnitude: 0.42991

Collected Steps per Second: 21,588.22529
Overall Steps per Second: 10,639.62805

Timestep Collection Time: 2.31765
Timestep Consumption Time: 2.38496
PPO Batch Consumption Time: 0.28127
Total Iteration Time: 4.70261

Cumulative Model Updates: 95,902
Cumulative Timesteps: 799,716,856

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 799716856...
Checkpoint 799716856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84,707.36620
Policy Entropy: 3.67041
Value Function Loss: 0.02834

Mean KL Divergence: 0.01082
SB3 Clip Fraction: 0.14877
Policy Update Magnitude: 0.48216
Value Function Update Magnitude: 0.53521

Collected Steps per Second: 21,211.30307
Overall Steps per Second: 10,376.53627

Timestep Collection Time: 2.35789
Timestep Consumption Time: 2.46202
PPO Batch Consumption Time: 0.29472
Total Iteration Time: 4.81991

Cumulative Model Updates: 95,908
Cumulative Timesteps: 799,766,870

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 138,536.95088
Policy Entropy: 3.66752
Value Function Loss: 0.03188

Mean KL Divergence: 0.01065
SB3 Clip Fraction: 0.14589
Policy Update Magnitude: 0.49867
Value Function Update Magnitude: 0.60539

Collected Steps per Second: 21,949.80711
Overall Steps per Second: 10,408.80666

Timestep Collection Time: 2.27929
Timestep Consumption Time: 2.52722
PPO Batch Consumption Time: 0.29588
Total Iteration Time: 4.80651

Cumulative Model Updates: 95,914
Cumulative Timesteps: 799,816,900

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 799816900...
Checkpoint 799816900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 219,227.44436
Policy Entropy: 3.67402
Value Function Loss: 0.03362

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.13939
Policy Update Magnitude: 0.52773
Value Function Update Magnitude: 0.53254

Collected Steps per Second: 21,896.51970
Overall Steps per Second: 10,499.45714

Timestep Collection Time: 2.28392
Timestep Consumption Time: 2.47918
PPO Batch Consumption Time: 0.28448
Total Iteration Time: 4.76310

Cumulative Model Updates: 95,920
Cumulative Timesteps: 799,866,910

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 476,342.93672
Policy Entropy: 3.66147
Value Function Loss: 0.03835

Mean KL Divergence: 0.01080
SB3 Clip Fraction: 0.14641
Policy Update Magnitude: 0.55114
Value Function Update Magnitude: 0.50174

Collected Steps per Second: 22,395.63213
Overall Steps per Second: 10,454.73279

Timestep Collection Time: 2.23267
Timestep Consumption Time: 2.55005
PPO Batch Consumption Time: 0.29600
Total Iteration Time: 4.78271

Cumulative Model Updates: 95,926
Cumulative Timesteps: 799,916,912

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 799916912...
Checkpoint 799916912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 253,156.72756
Policy Entropy: 3.65615
Value Function Loss: 0.04060

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.14436
Policy Update Magnitude: 0.54439
Value Function Update Magnitude: 0.47644

Collected Steps per Second: 22,048.22791
Overall Steps per Second: 10,411.50684

Timestep Collection Time: 2.26821
Timestep Consumption Time: 2.53513
PPO Batch Consumption Time: 0.29476
Total Iteration Time: 4.80334

Cumulative Model Updates: 95,932
Cumulative Timesteps: 799,966,922

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208,654.42413
Policy Entropy: 3.64490
Value Function Loss: 0.03977

Mean KL Divergence: 0.01069
SB3 Clip Fraction: 0.14508
Policy Update Magnitude: 0.52086
Value Function Update Magnitude: 0.43371

Collected Steps per Second: 22,566.87664
Overall Steps per Second: 10,586.03557

Timestep Collection Time: 2.21635
Timestep Consumption Time: 2.50837
PPO Batch Consumption Time: 0.28907
Total Iteration Time: 4.72471

Cumulative Model Updates: 95,938
Cumulative Timesteps: 800,016,938

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 800016938...
Checkpoint 800016938 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 208,654.42413
Policy Entropy: 3.64244
Value Function Loss: 0.03827

Mean KL Divergence: 0.01082
SB3 Clip Fraction: 0.14912
Policy Update Magnitude: 0.50467
Value Function Update Magnitude: 0.37907

Collected Steps per Second: 22,227.12504
Overall Steps per Second: 10,445.36915

Timestep Collection Time: 2.24995
Timestep Consumption Time: 2.53781
PPO Batch Consumption Time: 0.29617
Total Iteration Time: 4.78777

Cumulative Model Updates: 95,944
Cumulative Timesteps: 800,066,948

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208,654.42413
Policy Entropy: 3.65045
Value Function Loss: 0.03462

Mean KL Divergence: 0.01091
SB3 Clip Fraction: 0.15128
Policy Update Magnitude: 0.47937
Value Function Update Magnitude: 0.35367

Collected Steps per Second: 22,596.35201
Overall Steps per Second: 10,550.56398

Timestep Collection Time: 2.21407
Timestep Consumption Time: 2.52785
PPO Batch Consumption Time: 0.29242
Total Iteration Time: 4.74193

Cumulative Model Updates: 95,950
Cumulative Timesteps: 800,116,978

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 800116978...
Checkpoint 800116978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 208,654.42413
Policy Entropy: 3.65790
Value Function Loss: 0.04221

Mean KL Divergence: 0.01120
SB3 Clip Fraction: 0.15277
Policy Update Magnitude: 0.47667
Value Function Update Magnitude: 0.34597

Collected Steps per Second: 21,790.78995
Overall Steps per Second: 10,492.95975

Timestep Collection Time: 2.29547
Timestep Consumption Time: 2.47154
PPO Batch Consumption Time: 0.28350
Total Iteration Time: 4.76701

Cumulative Model Updates: 95,956
Cumulative Timesteps: 800,166,998

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 297,308.44865
Policy Entropy: 3.66598
Value Function Loss: 0.03594

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.14279
Policy Update Magnitude: 0.52183
Value Function Update Magnitude: 0.37279

Collected Steps per Second: 22,197.68829
Overall Steps per Second: 10,414.68723

Timestep Collection Time: 2.25348
Timestep Consumption Time: 2.54955
PPO Batch Consumption Time: 0.29511
Total Iteration Time: 4.80302

Cumulative Model Updates: 95,962
Cumulative Timesteps: 800,217,020

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 800217020...
Checkpoint 800217020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 297,308.44865
Policy Entropy: 3.67155
Value Function Loss: 0.03249

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.14107
Policy Update Magnitude: 0.56966
Value Function Update Magnitude: 0.60149

Collected Steps per Second: 21,978.72220
Overall Steps per Second: 10,541.60838

Timestep Collection Time: 2.27556
Timestep Consumption Time: 2.46887
PPO Batch Consumption Time: 0.28314
Total Iteration Time: 4.74444

Cumulative Model Updates: 95,968
Cumulative Timesteps: 800,267,034

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 297,308.44865
Policy Entropy: 3.66128
Value Function Loss: 0.03195

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.14328
Policy Update Magnitude: 0.55126
Value Function Update Magnitude: 0.66082

Collected Steps per Second: 22,183.36557
Overall Steps per Second: 10,594.69669

Timestep Collection Time: 2.25421
Timestep Consumption Time: 2.46570
PPO Batch Consumption Time: 0.28265
Total Iteration Time: 4.71991

Cumulative Model Updates: 95,974
Cumulative Timesteps: 800,317,040

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 800317040...
Checkpoint 800317040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 297,308.44865
Policy Entropy: 3.66327
Value Function Loss: 0.03085

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.14799
Policy Update Magnitude: 0.50845
Value Function Update Magnitude: 0.55015

Collected Steps per Second: 21,641.91289
Overall Steps per Second: 10,346.99273

Timestep Collection Time: 2.31089
Timestep Consumption Time: 2.52260
PPO Batch Consumption Time: 0.29458
Total Iteration Time: 4.83348

Cumulative Model Updates: 95,980
Cumulative Timesteps: 800,367,052

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 297,308.44865
Policy Entropy: 3.65814
Value Function Loss: 0.03696

Mean KL Divergence: 0.01060
SB3 Clip Fraction: 0.14703
Policy Update Magnitude: 0.47492
Value Function Update Magnitude: 0.44458

Collected Steps per Second: 21,404.42487
Overall Steps per Second: 10,468.16402

Timestep Collection Time: 2.33671
Timestep Consumption Time: 2.44120
PPO Batch Consumption Time: 0.29422
Total Iteration Time: 4.77792

Cumulative Model Updates: 95,986
Cumulative Timesteps: 800,417,068

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 800417068...
Checkpoint 800417068 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 297,308.44865
Policy Entropy: 3.67382
Value Function Loss: 0.03020

Mean KL Divergence: 0.01085
SB3 Clip Fraction: 0.15147
Policy Update Magnitude: 0.47481
Value Function Update Magnitude: 0.36969

Collected Steps per Second: 21,736.11907
Overall Steps per Second: 10,399.71201

Timestep Collection Time: 2.30142
Timestep Consumption Time: 2.50871
PPO Batch Consumption Time: 0.30415
Total Iteration Time: 4.81013

Cumulative Model Updates: 95,992
Cumulative Timesteps: 800,467,092

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 836,100.17051
Policy Entropy: 3.67014
Value Function Loss: 0.03554

Mean KL Divergence: 0.01102
SB3 Clip Fraction: 0.15013
Policy Update Magnitude: 0.47626
Value Function Update Magnitude: 0.53429

Collected Steps per Second: 20,858.79839
Overall Steps per Second: 10,082.32298

Timestep Collection Time: 2.39822
Timestep Consumption Time: 2.56333
PPO Batch Consumption Time: 0.29946
Total Iteration Time: 4.96155

Cumulative Model Updates: 95,998
Cumulative Timesteps: 800,517,116

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 800517116...
Checkpoint 800517116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 836,100.17051
Policy Entropy: 3.68567
Value Function Loss: 0.03139

Mean KL Divergence: 0.01072
SB3 Clip Fraction: 0.14823
Policy Update Magnitude: 0.50267
Value Function Update Magnitude: 0.52322

Collected Steps per Second: 21,384.42638
Overall Steps per Second: 10,278.86639

Timestep Collection Time: 2.33937
Timestep Consumption Time: 2.52751
PPO Batch Consumption Time: 0.29366
Total Iteration Time: 4.86688

Cumulative Model Updates: 96,004
Cumulative Timesteps: 800,567,142

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 723,172.43037
Policy Entropy: 3.67302
Value Function Loss: 0.03867

Mean KL Divergence: 0.01077
SB3 Clip Fraction: 0.15009
Policy Update Magnitude: 0.49714
Value Function Update Magnitude: 0.48572

Collected Steps per Second: 21,716.18448
Overall Steps per Second: 10,317.90421

Timestep Collection Time: 2.30400
Timestep Consumption Time: 2.54524
PPO Batch Consumption Time: 0.29744
Total Iteration Time: 4.84924

Cumulative Model Updates: 96,010
Cumulative Timesteps: 800,617,176

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 800617176...
Checkpoint 800617176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 723,172.43037
Policy Entropy: 3.67402
Value Function Loss: 0.03260

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.14531
Policy Update Magnitude: 0.46574
Value Function Update Magnitude: 0.45381

Collected Steps per Second: 21,550.20136
Overall Steps per Second: 10,461.97642

Timestep Collection Time: 2.32248
Timestep Consumption Time: 2.46151
PPO Batch Consumption Time: 0.28139
Total Iteration Time: 4.78399

Cumulative Model Updates: 96,016
Cumulative Timesteps: 800,667,226

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 723,172.43037
Policy Entropy: 3.65606
Value Function Loss: 0.03173

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.14493
Policy Update Magnitude: 0.43704
Value Function Update Magnitude: 0.41307

Collected Steps per Second: 22,318.45598
Overall Steps per Second: 10,301.47771

Timestep Collection Time: 2.24146
Timestep Consumption Time: 2.61473
PPO Batch Consumption Time: 0.30891
Total Iteration Time: 4.85620

Cumulative Model Updates: 96,022
Cumulative Timesteps: 800,717,252

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 800717252...
Checkpoint 800717252 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,125,796.50277
Policy Entropy: 3.66356
Value Function Loss: 0.03110

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.13898
Policy Update Magnitude: 0.44334
Value Function Update Magnitude: 0.47560

Collected Steps per Second: 20,952.38047
Overall Steps per Second: 10,293.62141

Timestep Collection Time: 2.38655
Timestep Consumption Time: 2.47121
PPO Batch Consumption Time: 0.28419
Total Iteration Time: 4.85777

Cumulative Model Updates: 96,028
Cumulative Timesteps: 800,767,256

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,125,796.50277
Policy Entropy: 3.66553
Value Function Loss: 0.03232

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.14693
Policy Update Magnitude: 0.44335
Value Function Update Magnitude: 0.40572

Collected Steps per Second: 22,269.88156
Overall Steps per Second: 10,460.35342

Timestep Collection Time: 2.24617
Timestep Consumption Time: 2.53588
PPO Batch Consumption Time: 0.29215
Total Iteration Time: 4.78206

Cumulative Model Updates: 96,034
Cumulative Timesteps: 800,817,278

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 800817278...
Checkpoint 800817278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,125,796.50277
Policy Entropy: 3.66739
Value Function Loss: 0.03036

Mean KL Divergence: 0.01139
SB3 Clip Fraction: 0.15393
Policy Update Magnitude: 0.42278
Value Function Update Magnitude: 0.36174

Collected Steps per Second: 22,196.79188
Overall Steps per Second: 10,580.02897

Timestep Collection Time: 2.25339
Timestep Consumption Time: 2.47420
PPO Batch Consumption Time: 0.28399
Total Iteration Time: 4.72759

Cumulative Model Updates: 96,040
Cumulative Timesteps: 800,867,296

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,125,796.50277
Policy Entropy: 3.66564
Value Function Loss: 0.03220

Mean KL Divergence: 0.01101
SB3 Clip Fraction: 0.14827
Policy Update Magnitude: 0.42995
Value Function Update Magnitude: 0.38660

Collected Steps per Second: 22,587.45334
Overall Steps per Second: 10,591.59404

Timestep Collection Time: 2.21442
Timestep Consumption Time: 2.50801
PPO Batch Consumption Time: 0.29019
Total Iteration Time: 4.72242

Cumulative Model Updates: 96,046
Cumulative Timesteps: 800,917,314

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 800917314...
Checkpoint 800917314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,125,796.50277
Policy Entropy: 3.65817
Value Function Loss: 0.03089

Mean KL Divergence: 0.01066
SB3 Clip Fraction: 0.14487
Policy Update Magnitude: 0.46183
Value Function Update Magnitude: 0.40991

Collected Steps per Second: 22,037.72056
Overall Steps per Second: 10,543.26360

Timestep Collection Time: 2.27038
Timestep Consumption Time: 2.47521
PPO Batch Consumption Time: 0.28446
Total Iteration Time: 4.74559

Cumulative Model Updates: 96,052
Cumulative Timesteps: 800,967,348

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,125,796.50277
Policy Entropy: 3.66293
Value Function Loss: 0.03141

Mean KL Divergence: 0.01173
SB3 Clip Fraction: 0.15679
Policy Update Magnitude: 0.47562
Value Function Update Magnitude: 0.41681

Collected Steps per Second: 22,017.03270
Overall Steps per Second: 10,478.08164

Timestep Collection Time: 2.27224
Timestep Consumption Time: 2.50230
PPO Batch Consumption Time: 0.28486
Total Iteration Time: 4.77454

Cumulative Model Updates: 96,058
Cumulative Timesteps: 801,017,376

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 801017376...
Checkpoint 801017376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 647,484.33831
Policy Entropy: 3.66050
Value Function Loss: 0.03510

Mean KL Divergence: 0.01118
SB3 Clip Fraction: 0.15210
Policy Update Magnitude: 0.44416
Value Function Update Magnitude: 0.36107

Collected Steps per Second: 22,195.69908
Overall Steps per Second: 10,596.64812

Timestep Collection Time: 2.25296
Timestep Consumption Time: 2.46608
PPO Batch Consumption Time: 0.28394
Total Iteration Time: 4.71904

Cumulative Model Updates: 96,064
Cumulative Timesteps: 801,067,382

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 424,819.30964
Policy Entropy: 3.66776
Value Function Loss: 0.03357

Mean KL Divergence: 0.01130
SB3 Clip Fraction: 0.15086
Policy Update Magnitude: 0.48284
Value Function Update Magnitude: 0.38712

Collected Steps per Second: 22,131.26390
Overall Steps per Second: 10,543.87879

Timestep Collection Time: 2.25979
Timestep Consumption Time: 2.48344
PPO Batch Consumption Time: 0.28481
Total Iteration Time: 4.74323

Cumulative Model Updates: 96,070
Cumulative Timesteps: 801,117,394

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 801117394...
Checkpoint 801117394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 424,819.30964
Policy Entropy: 3.66951
Value Function Loss: 0.03457

Mean KL Divergence: 0.01134
SB3 Clip Fraction: 0.15414
Policy Update Magnitude: 0.47954
Value Function Update Magnitude: 0.37551

Collected Steps per Second: 22,063.88237
Overall Steps per Second: 10,558.94145

Timestep Collection Time: 2.26642
Timestep Consumption Time: 2.46947
PPO Batch Consumption Time: 0.28261
Total Iteration Time: 4.73589

Cumulative Model Updates: 96,076
Cumulative Timesteps: 801,167,400

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 480,442.89428
Policy Entropy: 3.68772
Value Function Loss: 0.02935

Mean KL Divergence: 0.01098
SB3 Clip Fraction: 0.14861
Policy Update Magnitude: 0.47538
Value Function Update Magnitude: 0.41415

Collected Steps per Second: 21,846.25446
Overall Steps per Second: 10,489.44661

Timestep Collection Time: 2.28900
Timestep Consumption Time: 2.47827
PPO Batch Consumption Time: 0.29370
Total Iteration Time: 4.76727

Cumulative Model Updates: 96,082
Cumulative Timesteps: 801,217,406

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 801217406...
Checkpoint 801217406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 315,227.48278
Policy Entropy: 3.68021
Value Function Loss: 0.02966

Mean KL Divergence: 0.01192
SB3 Clip Fraction: 0.15951
Policy Update Magnitude: 0.46591
Value Function Update Magnitude: 0.43765

Collected Steps per Second: 21,569.84216
Overall Steps per Second: 10,602.88518

Timestep Collection Time: 2.31944
Timestep Consumption Time: 2.39908
PPO Batch Consumption Time: 0.28392
Total Iteration Time: 4.71853

Cumulative Model Updates: 96,088
Cumulative Timesteps: 801,267,436

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 315,227.48278
Policy Entropy: 3.68144
Value Function Loss: 0.02769

Mean KL Divergence: 0.01154
SB3 Clip Fraction: 0.15809
Policy Update Magnitude: 0.44564
Value Function Update Magnitude: 0.45244

Collected Steps per Second: 21,793.71426
Overall Steps per Second: 10,497.15990

Timestep Collection Time: 2.29543
Timestep Consumption Time: 2.47024
PPO Batch Consumption Time: 0.28449
Total Iteration Time: 4.76567

Cumulative Model Updates: 96,094
Cumulative Timesteps: 801,317,462

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 801317462...
Checkpoint 801317462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 315,227.48278
Policy Entropy: 3.68416
Value Function Loss: 0.02587

Mean KL Divergence: 0.01185
SB3 Clip Fraction: 0.16169
Policy Update Magnitude: 0.41550
Value Function Update Magnitude: 0.43230

Collected Steps per Second: 22,138.23391
Overall Steps per Second: 10,640.19952

Timestep Collection Time: 2.25989
Timestep Consumption Time: 2.44209
PPO Batch Consumption Time: 0.28338
Total Iteration Time: 4.70198

Cumulative Model Updates: 96,100
Cumulative Timesteps: 801,367,492

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 315,227.48278
Policy Entropy: 3.68095
Value Function Loss: 0.02882

Mean KL Divergence: 0.01242
SB3 Clip Fraction: 0.16354
Policy Update Magnitude: 0.41539
Value Function Update Magnitude: 0.51894

Collected Steps per Second: 22,337.44422
Overall Steps per Second: 10,465.98165

Timestep Collection Time: 2.23902
Timestep Consumption Time: 2.53970
PPO Batch Consumption Time: 0.29721
Total Iteration Time: 4.77872

Cumulative Model Updates: 96,106
Cumulative Timesteps: 801,417,506

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 801417506...
Checkpoint 801417506 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 315,227.48278
Policy Entropy: 3.67394
Value Function Loss: 0.03095

Mean KL Divergence: 0.01135
SB3 Clip Fraction: 0.15153
Policy Update Magnitude: 0.51862
Value Function Update Magnitude: 0.49992

Collected Steps per Second: 21,893.92523
Overall Steps per Second: 10,335.14083

Timestep Collection Time: 2.28410
Timestep Consumption Time: 2.55453
PPO Batch Consumption Time: 0.29585
Total Iteration Time: 4.83864

Cumulative Model Updates: 96,112
Cumulative Timesteps: 801,467,514

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 370,031.47793
Policy Entropy: 3.65871
Value Function Loss: 0.03808

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.14770
Policy Update Magnitude: 0.54542
Value Function Update Magnitude: 0.55887

Collected Steps per Second: 22,399.93735
Overall Steps per Second: 10,474.38489

Timestep Collection Time: 2.23215
Timestep Consumption Time: 2.54140
PPO Batch Consumption Time: 0.29533
Total Iteration Time: 4.77355

Cumulative Model Updates: 96,118
Cumulative Timesteps: 801,517,514

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 801517514...
Checkpoint 801517514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 159,409.37081
Policy Entropy: 3.66160
Value Function Loss: 0.03958

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.14233
Policy Update Magnitude: 0.56128
Value Function Update Magnitude: 0.56527

Collected Steps per Second: 21,948.00718
Overall Steps per Second: 10,505.71138

Timestep Collection Time: 2.27902
Timestep Consumption Time: 2.48220
PPO Batch Consumption Time: 0.28500
Total Iteration Time: 4.76122

Cumulative Model Updates: 96,124
Cumulative Timesteps: 801,567,534

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84,720.04987
Policy Entropy: 3.66130
Value Function Loss: 0.04016

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.14313
Policy Update Magnitude: 0.56029
Value Function Update Magnitude: 0.50800

Collected Steps per Second: 22,126.86067
Overall Steps per Second: 10,433.26474

Timestep Collection Time: 2.26096
Timestep Consumption Time: 2.53409
PPO Batch Consumption Time: 0.29091
Total Iteration Time: 4.79505

Cumulative Model Updates: 96,130
Cumulative Timesteps: 801,617,562

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 801617562...
Checkpoint 801617562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 276,667.51743
Policy Entropy: 3.65774
Value Function Loss: 0.03683

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.13773
Policy Update Magnitude: 0.55467
Value Function Update Magnitude: 0.42748

Collected Steps per Second: 21,836.30871
Overall Steps per Second: 10,325.57219

Timestep Collection Time: 2.29068
Timestep Consumption Time: 2.55360
PPO Batch Consumption Time: 0.29810
Total Iteration Time: 4.84428

Cumulative Model Updates: 96,136
Cumulative Timesteps: 801,667,582

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 276,667.51743
Policy Entropy: 3.65496
Value Function Loss: 0.03651

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.13792
Policy Update Magnitude: 0.53734
Value Function Update Magnitude: 0.43984

Collected Steps per Second: 22,425.06630
Overall Steps per Second: 10,436.26073

Timestep Collection Time: 2.23099
Timestep Consumption Time: 2.56288
PPO Batch Consumption Time: 0.29740
Total Iteration Time: 4.79386

Cumulative Model Updates: 96,142
Cumulative Timesteps: 801,717,612

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 801717612...
Checkpoint 801717612 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 276,667.51743
Policy Entropy: 3.65720
Value Function Loss: 0.03328

Mean KL Divergence: 0.01070
SB3 Clip Fraction: 0.14394
Policy Update Magnitude: 0.50947
Value Function Update Magnitude: 0.44811

Collected Steps per Second: 22,177.72058
Overall Steps per Second: 10,601.30737

Timestep Collection Time: 2.25560
Timestep Consumption Time: 2.46307
PPO Batch Consumption Time: 0.28296
Total Iteration Time: 4.71866

Cumulative Model Updates: 96,148
Cumulative Timesteps: 801,767,636

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 276,667.51743
Policy Entropy: 3.66754
Value Function Loss: 0.03175

Mean KL Divergence: 0.01099
SB3 Clip Fraction: 0.14872
Policy Update Magnitude: 0.50562
Value Function Update Magnitude: 0.43209

Collected Steps per Second: 22,111.82177
Overall Steps per Second: 10,457.34832

Timestep Collection Time: 2.26205
Timestep Consumption Time: 2.52100
PPO Batch Consumption Time: 0.28871
Total Iteration Time: 4.78305

Cumulative Model Updates: 96,154
Cumulative Timesteps: 801,817,654

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 801817654...
Checkpoint 801817654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 311,122.20440
Policy Entropy: 3.67294
Value Function Loss: 0.03173

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.14375
Policy Update Magnitude: 0.47706
Value Function Update Magnitude: 0.46869

Collected Steps per Second: 21,935.97144
Overall Steps per Second: 10,471.37612

Timestep Collection Time: 2.27936
Timestep Consumption Time: 2.49556
PPO Batch Consumption Time: 0.28789
Total Iteration Time: 4.77492

Cumulative Model Updates: 96,160
Cumulative Timesteps: 801,867,654

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 165,346.76842
Policy Entropy: 3.66668
Value Function Loss: 0.03695

Mean KL Divergence: 0.01059
SB3 Clip Fraction: 0.14494
Policy Update Magnitude: 0.46838
Value Function Update Magnitude: 0.43442

Collected Steps per Second: 22,561.53315
Overall Steps per Second: 10,667.97499

Timestep Collection Time: 2.21740
Timestep Consumption Time: 2.47215
PPO Batch Consumption Time: 0.28269
Total Iteration Time: 4.68955

Cumulative Model Updates: 96,166
Cumulative Timesteps: 801,917,682

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 801917682...
Checkpoint 801917682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 194,737.26494
Policy Entropy: 3.66238
Value Function Loss: 0.03580

Mean KL Divergence: 0.01080
SB3 Clip Fraction: 0.14639
Policy Update Magnitude: 0.49086
Value Function Update Magnitude: 0.55834

Collected Steps per Second: 22,011.35158
Overall Steps per Second: 10,555.00486

Timestep Collection Time: 2.27346
Timestep Consumption Time: 2.46761
PPO Batch Consumption Time: 0.28362
Total Iteration Time: 4.74107

Cumulative Model Updates: 96,172
Cumulative Timesteps: 801,967,724

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 194,737.26494
Policy Entropy: 3.63709
Value Function Loss: 0.03437

Mean KL Divergence: 0.01095
SB3 Clip Fraction: 0.14732
Policy Update Magnitude: 0.49441
Value Function Update Magnitude: 0.69261

Collected Steps per Second: 21,891.14407
Overall Steps per Second: 10,501.50625

Timestep Collection Time: 2.28412
Timestep Consumption Time: 2.47729
PPO Batch Consumption Time: 0.28453
Total Iteration Time: 4.76141

Cumulative Model Updates: 96,178
Cumulative Timesteps: 802,017,726

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 802017726...
Checkpoint 802017726 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 194,737.26494
Policy Entropy: 3.66084
Value Function Loss: 0.03185

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.13334
Policy Update Magnitude: 0.49019
Value Function Update Magnitude: 0.64013

Collected Steps per Second: 20,990.09700
Overall Steps per Second: 10,324.72968

Timestep Collection Time: 2.38208
Timestep Consumption Time: 2.46067
PPO Batch Consumption Time: 0.29659
Total Iteration Time: 4.84274

Cumulative Model Updates: 96,184
Cumulative Timesteps: 802,067,726

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 194,737.26494
Policy Entropy: 3.66257
Value Function Loss: 0.02910

Mean KL Divergence: 0.01082
SB3 Clip Fraction: 0.14310
Policy Update Magnitude: 0.48059
Value Function Update Magnitude: 0.60765

Collected Steps per Second: 21,609.30696
Overall Steps per Second: 10,473.34598

Timestep Collection Time: 2.31410
Timestep Consumption Time: 2.46050
PPO Batch Consumption Time: 0.29611
Total Iteration Time: 4.77460

Cumulative Model Updates: 96,190
Cumulative Timesteps: 802,117,732

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 802117732...
Checkpoint 802117732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 327,776.50149
Policy Entropy: 3.68811
Value Function Loss: 0.02631

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.13825
Policy Update Magnitude: 0.44061
Value Function Update Magnitude: 0.53931

Collected Steps per Second: 21,410.31916
Overall Steps per Second: 10,445.81225

Timestep Collection Time: 2.33607
Timestep Consumption Time: 2.45207
PPO Batch Consumption Time: 0.28396
Total Iteration Time: 4.78814

Cumulative Model Updates: 96,196
Cumulative Timesteps: 802,167,748

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92,577.67495
Policy Entropy: 3.69178
Value Function Loss: 0.02448

Mean KL Divergence: 0.01135
SB3 Clip Fraction: 0.15191
Policy Update Magnitude: 0.43839
Value Function Update Magnitude: 0.61604

Collected Steps per Second: 22,185.68581
Overall Steps per Second: 10,511.90545

Timestep Collection Time: 2.25389
Timestep Consumption Time: 2.50301
PPO Batch Consumption Time: 0.29161
Total Iteration Time: 4.75689

Cumulative Model Updates: 96,202
Cumulative Timesteps: 802,217,752

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 802217752...
Checkpoint 802217752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,789.92453
Policy Entropy: 3.72899
Value Function Loss: 0.02348

Mean KL Divergence: 0.01131
SB3 Clip Fraction: 0.14629
Policy Update Magnitude: 0.44277
Value Function Update Magnitude: 0.76844

Collected Steps per Second: 21,826.77594
Overall Steps per Second: 10,556.78818

Timestep Collection Time: 2.29214
Timestep Consumption Time: 2.44699
PPO Batch Consumption Time: 0.28390
Total Iteration Time: 4.73913

Cumulative Model Updates: 96,208
Cumulative Timesteps: 802,267,782

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 459,609.96334
Policy Entropy: 3.71309
Value Function Loss: 0.03021

Mean KL Divergence: 0.01078
SB3 Clip Fraction: 0.14449
Policy Update Magnitude: 0.45965
Value Function Update Magnitude: 0.73910

Collected Steps per Second: 22,323.00413
Overall Steps per Second: 10,569.50161

Timestep Collection Time: 2.24128
Timestep Consumption Time: 2.49234
PPO Batch Consumption Time: 0.29167
Total Iteration Time: 4.73362

Cumulative Model Updates: 96,214
Cumulative Timesteps: 802,317,814

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 802317814...
Checkpoint 802317814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 102,261.39359
Policy Entropy: 3.72150
Value Function Loss: 0.03588

Mean KL Divergence: 0.01174
SB3 Clip Fraction: 0.15526
Policy Update Magnitude: 0.49168
Value Function Update Magnitude: 0.72293

Collected Steps per Second: 22,231.96700
Overall Steps per Second: 10,583.87402

Timestep Collection Time: 2.25009
Timestep Consumption Time: 2.47634
PPO Batch Consumption Time: 0.28375
Total Iteration Time: 4.72644

Cumulative Model Updates: 96,220
Cumulative Timesteps: 802,367,838

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,945.25999
Policy Entropy: 3.72036
Value Function Loss: 0.04127

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.14020
Policy Update Magnitude: 0.55040
Value Function Update Magnitude: 0.79145

Collected Steps per Second: 22,658.29892
Overall Steps per Second: 10,582.29917

Timestep Collection Time: 2.20749
Timestep Consumption Time: 2.51908
PPO Batch Consumption Time: 0.29675
Total Iteration Time: 4.72657

Cumulative Model Updates: 96,226
Cumulative Timesteps: 802,417,856

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 802417856...
Checkpoint 802417856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,225.65570
Policy Entropy: 3.72376
Value Function Loss: 0.03961

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.14397
Policy Update Magnitude: 0.57389
Value Function Update Magnitude: 0.95598

Collected Steps per Second: 22,078.80390
Overall Steps per Second: 10,431.29212

Timestep Collection Time: 2.26480
Timestep Consumption Time: 2.52886
PPO Batch Consumption Time: 0.28998
Total Iteration Time: 4.79365

Cumulative Model Updates: 96,232
Cumulative Timesteps: 802,467,860

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,801.33464
Policy Entropy: 3.69896
Value Function Loss: 0.03792

Mean KL Divergence: 0.01159
SB3 Clip Fraction: 0.15718
Policy Update Magnitude: 0.57298
Value Function Update Magnitude: 0.94734

Collected Steps per Second: 22,285.27052
Overall Steps per Second: 10,490.67902

Timestep Collection Time: 2.24597
Timestep Consumption Time: 2.52512
PPO Batch Consumption Time: 0.29125
Total Iteration Time: 4.77109

Cumulative Model Updates: 96,238
Cumulative Timesteps: 802,517,912

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


Saving checkpoint 802517912...
Checkpoint 802517912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 550,728.59541
Policy Entropy: 3.67533
Value Function Loss: 0.03991

Mean KL Divergence: 0.01150
SB3 Clip Fraction: 0.15633
Policy Update Magnitude: 0.56231
Value Function Update Magnitude: 0.69841

Collected Steps per Second: 22,226.42662
Overall Steps per Second: 10,480.31245

Timestep Collection Time: 2.25002
Timestep Consumption Time: 2.52178
PPO Batch Consumption Time: 0.29463
Total Iteration Time: 4.77180

Cumulative Model Updates: 96,244
Cumulative Timesteps: 802,567,922

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 149,540.91050
Policy Entropy: 3.67875
Value Function Loss: 0.03600

Mean KL Divergence: 0.01247
SB3 Clip Fraction: 0.16304
Policy Update Magnitude: 0.57052
Value Function Update Magnitude: 0.63155

Collected Steps per Second: 22,225.46494
Overall Steps per Second: 10,441.23646

Timestep Collection Time: 2.25120
Timestep Consumption Time: 2.54076
PPO Batch Consumption Time: 0.29498
Total Iteration Time: 4.79196

Cumulative Model Updates: 96,250
Cumulative Timesteps: 802,617,956

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 802617956...
Checkpoint 802617956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 98,115.83381
Policy Entropy: 3.68966
Value Function Loss: 0.03609

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.12249
Policy Update Magnitude: 0.72947
Value Function Update Magnitude: 0.86964

Collected Steps per Second: 22,410.93573
Overall Steps per Second: 10,478.33299

Timestep Collection Time: 2.23221
Timestep Consumption Time: 2.54202
PPO Batch Consumption Time: 0.29536
Total Iteration Time: 4.77423

Cumulative Model Updates: 96,256
Cumulative Timesteps: 802,667,982

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 396,498.59065
Policy Entropy: 3.68177
Value Function Loss: 0.04133

Mean KL Divergence: 0.01531
SB3 Clip Fraction: 0.18228
Policy Update Magnitude: 0.81717
Value Function Update Magnitude: 0.82544

Collected Steps per Second: 22,310.69739
Overall Steps per Second: 10,474.48776

Timestep Collection Time: 2.24126
Timestep Consumption Time: 2.53263
PPO Batch Consumption Time: 0.29198
Total Iteration Time: 4.77389

Cumulative Model Updates: 96,262
Cumulative Timesteps: 802,717,986

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 802717986...
Checkpoint 802717986 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,640.36097
Policy Entropy: 3.68475
Value Function Loss: 0.04640

Mean KL Divergence: 0.01800
SB3 Clip Fraction: 0.20371
Policy Update Magnitude: 0.69129
Value Function Update Magnitude: 0.72102

Collected Steps per Second: 22,359.81720
Overall Steps per Second: 10,616.02404

Timestep Collection Time: 2.23821
Timestep Consumption Time: 2.47598
PPO Batch Consumption Time: 0.28506
Total Iteration Time: 4.71419

Cumulative Model Updates: 96,268
Cumulative Timesteps: 802,768,032

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 155,257.16298
Policy Entropy: 3.70943
Value Function Loss: 0.04798

Mean KL Divergence: 0.01302
SB3 Clip Fraction: 0.16586
Policy Update Magnitude: 0.69552
Value Function Update Magnitude: 0.56173

Collected Steps per Second: 22,174.14131
Overall Steps per Second: 10,466.75754

Timestep Collection Time: 2.25578
Timestep Consumption Time: 2.52316
PPO Batch Consumption Time: 0.29026
Total Iteration Time: 4.77894

Cumulative Model Updates: 96,274
Cumulative Timesteps: 802,818,052

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 802818052...
Checkpoint 802818052 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 341,955.48682
Policy Entropy: 3.71123
Value Function Loss: 0.04662

Mean KL Divergence: 0.01315
SB3 Clip Fraction: 0.16301
Policy Update Magnitude: 0.70488
Value Function Update Magnitude: 0.51318

Collected Steps per Second: 21,997.87339
Overall Steps per Second: 10,546.17792

Timestep Collection Time: 2.27404
Timestep Consumption Time: 2.46929
PPO Batch Consumption Time: 0.28427
Total Iteration Time: 4.74333

Cumulative Model Updates: 96,280
Cumulative Timesteps: 802,868,076

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 170,844.36147
Policy Entropy: 3.70720
Value Function Loss: 0.04948

Mean KL Divergence: 0.01147
SB3 Clip Fraction: 0.14963
Policy Update Magnitude: 0.72729
Value Function Update Magnitude: 0.46834

Collected Steps per Second: 21,499.36375
Overall Steps per Second: 10,315.03700

Timestep Collection Time: 2.32630
Timestep Consumption Time: 2.52235
PPO Batch Consumption Time: 0.29436
Total Iteration Time: 4.84865

Cumulative Model Updates: 96,286
Cumulative Timesteps: 802,918,090

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 802918090...
Checkpoint 802918090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 59,580.21946
Policy Entropy: 3.66565
Value Function Loss: 0.06091

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.13328
Policy Update Magnitude: 0.83157
Value Function Update Magnitude: 0.39855

Collected Steps per Second: 22,082.59946
Overall Steps per Second: 10,450.61800

Timestep Collection Time: 2.26595
Timestep Consumption Time: 2.52210
PPO Batch Consumption Time: 0.29271
Total Iteration Time: 4.78804

Cumulative Model Updates: 96,292
Cumulative Timesteps: 802,968,128

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59,580.21946
Policy Entropy: 3.68920
Value Function Loss: 0.04516

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.12890
Policy Update Magnitude: 0.90054
Value Function Update Magnitude: 0.47504

Collected Steps per Second: 21,901.93049
Overall Steps per Second: 10,514.28041

Timestep Collection Time: 2.28300
Timestep Consumption Time: 2.47263
PPO Batch Consumption Time: 0.28338
Total Iteration Time: 4.75563

Cumulative Model Updates: 96,298
Cumulative Timesteps: 803,018,130

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 803018130...
Checkpoint 803018130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 586,941.56735
Policy Entropy: 3.65791
Value Function Loss: 0.04124

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.11929
Policy Update Magnitude: 0.87459
Value Function Update Magnitude: 0.54360

Collected Steps per Second: 21,414.44127
Overall Steps per Second: 10,559.65607

Timestep Collection Time: 2.33609
Timestep Consumption Time: 2.40138
PPO Batch Consumption Time: 0.28462
Total Iteration Time: 4.73746

Cumulative Model Updates: 96,304
Cumulative Timesteps: 803,068,156

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 641,201.46875
Policy Entropy: 3.65630
Value Function Loss: 0.04229

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.11585
Policy Update Magnitude: 0.89439
Value Function Update Magnitude: 0.64470

Collected Steps per Second: 21,352.41224
Overall Steps per Second: 10,462.09833

Timestep Collection Time: 2.34194
Timestep Consumption Time: 2.43779
PPO Batch Consumption Time: 0.28788
Total Iteration Time: 4.77973

Cumulative Model Updates: 96,310
Cumulative Timesteps: 803,118,162

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 803118162...
Checkpoint 803118162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 173,614.41543
Policy Entropy: 3.66407
Value Function Loss: 0.04242

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.12037
Policy Update Magnitude: 0.89165
Value Function Update Magnitude: 0.70850

Collected Steps per Second: 21,446.82258
Overall Steps per Second: 10,501.58772

Timestep Collection Time: 2.33191
Timestep Consumption Time: 2.43042
PPO Batch Consumption Time: 0.29166
Total Iteration Time: 4.76233

Cumulative Model Updates: 96,316
Cumulative Timesteps: 803,168,174

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,442.15975
Policy Entropy: 3.67211
Value Function Loss: 0.04941

Mean KL Divergence: 0.02071
SB3 Clip Fraction: 0.22520
Policy Update Magnitude: 0.78223
Value Function Update Magnitude: 0.54950

Collected Steps per Second: 21,623.00422
Overall Steps per Second: 10,372.87679

Timestep Collection Time: 2.31448
Timestep Consumption Time: 2.51022
PPO Batch Consumption Time: 0.29377
Total Iteration Time: 4.82470

Cumulative Model Updates: 96,322
Cumulative Timesteps: 803,218,220

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 803218220...
Checkpoint 803218220 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 50,409.38446
Policy Entropy: 3.70885
Value Function Loss: 0.04913

Mean KL Divergence: 0.01423
SB3 Clip Fraction: 0.16571
Policy Update Magnitude: 0.78836
Value Function Update Magnitude: 0.55926

Collected Steps per Second: 21,858.01613
Overall Steps per Second: 10,480.62941

Timestep Collection Time: 2.28895
Timestep Consumption Time: 2.48480
PPO Batch Consumption Time: 0.29246
Total Iteration Time: 4.77376

Cumulative Model Updates: 96,328
Cumulative Timesteps: 803,268,252

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,486.49605
Policy Entropy: 3.69972
Value Function Loss: 0.05239

Mean KL Divergence: 0.01341
SB3 Clip Fraction: 0.16086
Policy Update Magnitude: 0.94658
Value Function Update Magnitude: 0.58646

Collected Steps per Second: 22,013.00626
Overall Steps per Second: 10,426.99615

Timestep Collection Time: 2.27148
Timestep Consumption Time: 2.52396
PPO Batch Consumption Time: 0.29604
Total Iteration Time: 4.79544

Cumulative Model Updates: 96,334
Cumulative Timesteps: 803,318,254

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 803318254...
Checkpoint 803318254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 73,255.32901
Policy Entropy: 3.70515
Value Function Loss: 0.05174

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.12813
Policy Update Magnitude: 0.99013
Value Function Update Magnitude: 0.61247

Collected Steps per Second: 22,018.70009
Overall Steps per Second: 10,587.95445

Timestep Collection Time: 2.27198
Timestep Consumption Time: 2.45283
PPO Batch Consumption Time: 0.28344
Total Iteration Time: 4.72480

Cumulative Model Updates: 96,340
Cumulative Timesteps: 803,368,280

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 125,990.53734
Policy Entropy: 3.72726
Value Function Loss: 0.05364

Mean KL Divergence: 0.01367
SB3 Clip Fraction: 0.16901
Policy Update Magnitude: 0.90728
Value Function Update Magnitude: 0.64906

Collected Steps per Second: 21,861.84159
Overall Steps per Second: 10,495.58232

Timestep Collection Time: 2.28727
Timestep Consumption Time: 2.47702
PPO Batch Consumption Time: 0.28551
Total Iteration Time: 4.76429

Cumulative Model Updates: 96,346
Cumulative Timesteps: 803,418,284

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 803418284...
Checkpoint 803418284 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 522,310.88548
Policy Entropy: 3.71418
Value Function Loss: 0.06067

Mean KL Divergence: 0.01146
SB3 Clip Fraction: 0.14257
Policy Update Magnitude: 0.90884
Value Function Update Magnitude: 0.69608

Collected Steps per Second: 21,821.57864
Overall Steps per Second: 10,343.68052

Timestep Collection Time: 2.29177
Timestep Consumption Time: 2.54307
PPO Batch Consumption Time: 0.29720
Total Iteration Time: 4.83484

Cumulative Model Updates: 96,352
Cumulative Timesteps: 803,468,294

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,462.80259
Policy Entropy: 3.73684
Value Function Loss: 0.06362

Mean KL Divergence: 0.01093
SB3 Clip Fraction: 0.13537
Policy Update Magnitude: 1.05433
Value Function Update Magnitude: 0.76626

Collected Steps per Second: 21,899.94433
Overall Steps per Second: 10,379.47348

Timestep Collection Time: 2.28338
Timestep Consumption Time: 2.53439
PPO Batch Consumption Time: 0.29353
Total Iteration Time: 4.81778

Cumulative Model Updates: 96,358
Cumulative Timesteps: 803,518,300

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 803518300...
Checkpoint 803518300 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 140,766.50051
Policy Entropy: 3.75561
Value Function Loss: 0.05957

Mean KL Divergence: 0.01735
SB3 Clip Fraction: 0.20210
Policy Update Magnitude: 0.90536
Value Function Update Magnitude: 0.74619

Collected Steps per Second: 22,230.62897
Overall Steps per Second: 10,576.34124

Timestep Collection Time: 2.24978
Timestep Consumption Time: 2.47908
PPO Batch Consumption Time: 0.28483
Total Iteration Time: 4.72886

Cumulative Model Updates: 96,364
Cumulative Timesteps: 803,568,314

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 322,382.29512
Policy Entropy: 3.76289
Value Function Loss: 0.05451

Mean KL Divergence: 0.01287
SB3 Clip Fraction: 0.16232
Policy Update Magnitude: 0.76318
Value Function Update Magnitude: 0.81143

Collected Steps per Second: 22,525.88896
Overall Steps per Second: 10,515.76346

Timestep Collection Time: 2.21985
Timestep Consumption Time: 2.53530
PPO Batch Consumption Time: 0.29309
Total Iteration Time: 4.75515

Cumulative Model Updates: 96,370
Cumulative Timesteps: 803,618,318

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 803618318...
Checkpoint 803618318 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,691.73420
Policy Entropy: 3.77616
Value Function Loss: 0.04848

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.12256
Policy Update Magnitude: 0.77582
Value Function Update Magnitude: 0.99260

Collected Steps per Second: 22,311.51228
Overall Steps per Second: 10,590.32946

Timestep Collection Time: 2.24198
Timestep Consumption Time: 2.48138
PPO Batch Consumption Time: 0.28506
Total Iteration Time: 4.72337

Cumulative Model Updates: 96,376
Cumulative Timesteps: 803,668,340

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,182.05005
Policy Entropy: 3.75833
Value Function Loss: 0.05271

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.13552
Policy Update Magnitude: 0.78217
Value Function Update Magnitude: 0.78497

Collected Steps per Second: 22,147.52512
Overall Steps per Second: 10,504.10791

Timestep Collection Time: 2.25786
Timestep Consumption Time: 2.50275
PPO Batch Consumption Time: 0.29195
Total Iteration Time: 4.76061

Cumulative Model Updates: 96,382
Cumulative Timesteps: 803,718,346

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 803718346...
Checkpoint 803718346 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 539,461.08795
Policy Entropy: 3.74362
Value Function Loss: 0.04732

Mean KL Divergence: 0.01170
SB3 Clip Fraction: 0.15484
Policy Update Magnitude: 0.67573
Value Function Update Magnitude: 0.56305

Collected Steps per Second: 21,776.35312
Overall Steps per Second: 10,187.19433

Timestep Collection Time: 2.29634
Timestep Consumption Time: 2.61237
PPO Batch Consumption Time: 0.30734
Total Iteration Time: 4.90871

Cumulative Model Updates: 96,388
Cumulative Timesteps: 803,768,352

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57,434.28068
Policy Entropy: 3.71482
Value Function Loss: 0.05188

Mean KL Divergence: 0.01776
SB3 Clip Fraction: 0.21653
Policy Update Magnitude: 0.56261
Value Function Update Magnitude: 0.61293

Collected Steps per Second: 22,209.12106
Overall Steps per Second: 10,376.67651

Timestep Collection Time: 2.25205
Timestep Consumption Time: 2.56799
PPO Batch Consumption Time: 0.29850
Total Iteration Time: 4.82004

Cumulative Model Updates: 96,394
Cumulative Timesteps: 803,818,368

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 803818368...
Checkpoint 803818368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 840.10484
Policy Entropy: 3.74705
Value Function Loss: 0.05546

Mean KL Divergence: 0.01465
SB3 Clip Fraction: 0.18276
Policy Update Magnitude: 0.60584
Value Function Update Magnitude: 0.58044

Collected Steps per Second: 21,939.03587
Overall Steps per Second: 10,464.76139

Timestep Collection Time: 2.28005
Timestep Consumption Time: 2.50000
PPO Batch Consumption Time: 0.29531
Total Iteration Time: 4.78004

Cumulative Model Updates: 96,400
Cumulative Timesteps: 803,868,390

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,207.03970
Policy Entropy: 3.75273
Value Function Loss: 0.07100

Mean KL Divergence: 0.01310
SB3 Clip Fraction: 0.16489
Policy Update Magnitude: 0.68903
Value Function Update Magnitude: 0.62383

Collected Steps per Second: 21,874.62500
Overall Steps per Second: 10,421.70666

Timestep Collection Time: 2.28584
Timestep Consumption Time: 2.51203
PPO Batch Consumption Time: 0.29695
Total Iteration Time: 4.79787

Cumulative Model Updates: 96,406
Cumulative Timesteps: 803,918,392

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 803918392...
Checkpoint 803918392 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 67,574.54357
Policy Entropy: 3.76662
Value Function Loss: 0.08278

Mean KL Divergence: 0.01273
SB3 Clip Fraction: 0.15495
Policy Update Magnitude: 0.77631
Value Function Update Magnitude: 0.54597

Collected Steps per Second: 21,892.96852
Overall Steps per Second: 10,597.11725

Timestep Collection Time: 2.28384
Timestep Consumption Time: 2.43443
PPO Batch Consumption Time: 0.28152
Total Iteration Time: 4.71826

Cumulative Model Updates: 96,412
Cumulative Timesteps: 803,968,392

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 688.70987
Policy Entropy: 3.78683
Value Function Loss: 0.07823

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.12660
Policy Update Magnitude: 0.84547
Value Function Update Magnitude: 0.58520

Collected Steps per Second: 22,024.65921
Overall Steps per Second: 10,399.26424

Timestep Collection Time: 2.27036
Timestep Consumption Time: 2.53805
PPO Batch Consumption Time: 0.29738
Total Iteration Time: 4.80842

Cumulative Model Updates: 96,418
Cumulative Timesteps: 804,018,396

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 804018396...
Checkpoint 804018396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,538.64893
Policy Entropy: 3.76544
Value Function Loss: 0.07628

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.12521
Policy Update Magnitude: 0.88152
Value Function Update Magnitude: 0.57850

Collected Steps per Second: 22,558.26823
Overall Steps per Second: 10,628.84589

Timestep Collection Time: 2.21648
Timestep Consumption Time: 2.48770
PPO Batch Consumption Time: 0.29000
Total Iteration Time: 4.70418

Cumulative Model Updates: 96,424
Cumulative Timesteps: 804,068,396

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 64.35273
Policy Entropy: 3.78743
Value Function Loss: 0.06868

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.12223
Policy Update Magnitude: 0.88829
Value Function Update Magnitude: 0.59301

Collected Steps per Second: 22,214.77397
Overall Steps per Second: 10,471.24343

Timestep Collection Time: 2.25138
Timestep Consumption Time: 2.52493
PPO Batch Consumption Time: 0.29775
Total Iteration Time: 4.77632

Cumulative Model Updates: 96,430
Cumulative Timesteps: 804,118,410

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 804118410...
Checkpoint 804118410 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,882.17894
Policy Entropy: 3.79364
Value Function Loss: 0.07329

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.11517
Policy Update Magnitude: 0.84116
Value Function Update Magnitude: 0.55256

Collected Steps per Second: 21,799.87215
Overall Steps per Second: 10,346.65557

Timestep Collection Time: 2.29478
Timestep Consumption Time: 2.54021
PPO Batch Consumption Time: 0.30018
Total Iteration Time: 4.83499

Cumulative Model Updates: 96,436
Cumulative Timesteps: 804,168,436

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,996.28016
Policy Entropy: 3.87485
Value Function Loss: 0.06394

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.09897
Policy Update Magnitude: 0.86133
Value Function Update Magnitude: 0.69107

Collected Steps per Second: 21,740.91793
Overall Steps per Second: 10,276.15424

Timestep Collection Time: 2.30101
Timestep Consumption Time: 2.56716
PPO Batch Consumption Time: 0.30276
Total Iteration Time: 4.86816

Cumulative Model Updates: 96,442
Cumulative Timesteps: 804,218,462

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 804218462...
Checkpoint 804218462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,767.58667
Policy Entropy: 3.88186
Value Function Loss: 0.06405

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.10593
Policy Update Magnitude: 0.85965
Value Function Update Magnitude: 0.80515

Collected Steps per Second: 20,783.35836
Overall Steps per Second: 10,199.64093

Timestep Collection Time: 2.40808
Timestep Consumption Time: 2.49876
PPO Batch Consumption Time: 0.30126
Total Iteration Time: 4.90684

Cumulative Model Updates: 96,448
Cumulative Timesteps: 804,268,510

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,372.81031
Policy Entropy: 3.86289
Value Function Loss: 0.06292

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.11043
Policy Update Magnitude: 0.80725
Value Function Update Magnitude: 0.73481

Collected Steps per Second: 20,918.25311
Overall Steps per Second: 10,456.56946

Timestep Collection Time: 2.39160
Timestep Consumption Time: 2.39277
PPO Batch Consumption Time: 0.28368
Total Iteration Time: 4.78436

Cumulative Model Updates: 96,454
Cumulative Timesteps: 804,318,538

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 804318538...
Checkpoint 804318538 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,236.44719
Policy Entropy: 3.80016
Value Function Loss: 0.07834

Mean KL Divergence: 0.01082
SB3 Clip Fraction: 0.13961
Policy Update Magnitude: 0.71147
Value Function Update Magnitude: 0.67827

Collected Steps per Second: 21,404.53170
Overall Steps per Second: 10,461.42774

Timestep Collection Time: 2.33661
Timestep Consumption Time: 2.44419
PPO Batch Consumption Time: 0.29266
Total Iteration Time: 4.78080

Cumulative Model Updates: 96,460
Cumulative Timesteps: 804,368,552

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,065.01069
Policy Entropy: 3.76072
Value Function Loss: 0.06639

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.13522
Policy Update Magnitude: 0.60928
Value Function Update Magnitude: 0.49620

Collected Steps per Second: 22,134.33374
Overall Steps per Second: 10,608.87139

Timestep Collection Time: 2.25902
Timestep Consumption Time: 2.45420
PPO Batch Consumption Time: 0.29038
Total Iteration Time: 4.71323

Cumulative Model Updates: 96,466
Cumulative Timesteps: 804,418,554

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 804418554...
Checkpoint 804418554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,668.13367
Policy Entropy: 3.74589
Value Function Loss: 0.05420

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.14103
Policy Update Magnitude: 0.49991
Value Function Update Magnitude: 0.47096

Collected Steps per Second: 21,808.22349
Overall Steps per Second: 10,287.68941

Timestep Collection Time: 2.29363
Timestep Consumption Time: 2.56849
PPO Batch Consumption Time: 0.30479
Total Iteration Time: 4.86212

Cumulative Model Updates: 96,472
Cumulative Timesteps: 804,468,574

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,262.19990
Policy Entropy: 3.72428
Value Function Loss: 0.04499

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.13725
Policy Update Magnitude: 0.44941
Value Function Update Magnitude: 0.49718

Collected Steps per Second: 21,618.17704
Overall Steps per Second: 10,255.71480

Timestep Collection Time: 2.31370
Timestep Consumption Time: 2.56338
PPO Batch Consumption Time: 0.29681
Total Iteration Time: 4.87709

Cumulative Model Updates: 96,478
Cumulative Timesteps: 804,518,592

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 804518592...
Checkpoint 804518592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 80,039.38845
Policy Entropy: 3.71006
Value Function Loss: 0.04312

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.13722
Policy Update Magnitude: 0.41326
Value Function Update Magnitude: 0.56564

Collected Steps per Second: 21,066.33529
Overall Steps per Second: 10,279.92479

Timestep Collection Time: 2.37431
Timestep Consumption Time: 2.49129
PPO Batch Consumption Time: 0.28428
Total Iteration Time: 4.86560

Cumulative Model Updates: 96,484
Cumulative Timesteps: 804,568,610

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,408.74737
Policy Entropy: 3.70948
Value Function Loss: 0.04578

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.13793
Policy Update Magnitude: 0.40850
Value Function Update Magnitude: 0.49427

Collected Steps per Second: 22,667.83054
Overall Steps per Second: 10,556.49596

Timestep Collection Time: 2.20665
Timestep Consumption Time: 2.53166
PPO Batch Consumption Time: 0.28572
Total Iteration Time: 4.73831

Cumulative Model Updates: 96,490
Cumulative Timesteps: 804,618,630

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 804618630...
Checkpoint 804618630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,061.16646
Policy Entropy: 3.70947
Value Function Loss: 0.04707

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.14651
Policy Update Magnitude: 0.43245
Value Function Update Magnitude: 0.48872

Collected Steps per Second: 21,790.12538
Overall Steps per Second: 10,416.42951

Timestep Collection Time: 2.29498
Timestep Consumption Time: 2.50589
PPO Batch Consumption Time: 0.29533
Total Iteration Time: 4.80088

Cumulative Model Updates: 96,496
Cumulative Timesteps: 804,668,638

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,445.27369
Policy Entropy: 3.71461
Value Function Loss: 0.03982

Mean KL Divergence: 0.01101
SB3 Clip Fraction: 0.15218
Policy Update Magnitude: 0.40979
Value Function Update Magnitude: 0.42953

Collected Steps per Second: 22,424.64300
Overall Steps per Second: 10,542.72804

Timestep Collection Time: 2.22969
Timestep Consumption Time: 2.51292
PPO Batch Consumption Time: 0.29142
Total Iteration Time: 4.74261

Cumulative Model Updates: 96,502
Cumulative Timesteps: 804,718,638

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 804718638...
Checkpoint 804718638 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,979.06441
Policy Entropy: 3.70219
Value Function Loss: 0.03578

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.13833
Policy Update Magnitude: 0.38250
Value Function Update Magnitude: 0.49011

Collected Steps per Second: 22,583.47799
Overall Steps per Second: 10,578.78351

Timestep Collection Time: 2.21436
Timestep Consumption Time: 2.51284
PPO Batch Consumption Time: 0.29352
Total Iteration Time: 4.72720

Cumulative Model Updates: 96,508
Cumulative Timesteps: 804,768,646

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,185.46624
Policy Entropy: 3.72038
Value Function Loss: 0.03395

Mean KL Divergence: 0.01081
SB3 Clip Fraction: 0.14836
Policy Update Magnitude: 0.40345
Value Function Update Magnitude: 0.60451

Collected Steps per Second: 22,700.00957
Overall Steps per Second: 10,498.29721

Timestep Collection Time: 2.20352
Timestep Consumption Time: 2.56106
PPO Batch Consumption Time: 0.29194
Total Iteration Time: 4.76458

Cumulative Model Updates: 96,514
Cumulative Timesteps: 804,818,666

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 804818666...
Checkpoint 804818666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,412.65841
Policy Entropy: 3.72320
Value Function Loss: 0.03919

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.14721
Policy Update Magnitude: 0.41118
Value Function Update Magnitude: 0.61751

Collected Steps per Second: 20,769.99547
Overall Steps per Second: 10,083.20966

Timestep Collection Time: 2.40828
Timestep Consumption Time: 2.55244
PPO Batch Consumption Time: 0.29693
Total Iteration Time: 4.96072

Cumulative Model Updates: 96,520
Cumulative Timesteps: 804,868,686

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,192.30666
Policy Entropy: 3.72620
Value Function Loss: 0.03888

Mean KL Divergence: 0.01067
SB3 Clip Fraction: 0.14743
Policy Update Magnitude: 0.41019
Value Function Update Magnitude: 0.59968

Collected Steps per Second: 21,939.96617
Overall Steps per Second: 10,226.58081

Timestep Collection Time: 2.27913
Timestep Consumption Time: 2.61048
PPO Batch Consumption Time: 0.30388
Total Iteration Time: 4.88961

Cumulative Model Updates: 96,526
Cumulative Timesteps: 804,918,690

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 804918690...
Checkpoint 804918690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 455,277.03271
Policy Entropy: 3.69293
Value Function Loss: 0.04360

Mean KL Divergence: 0.01095
SB3 Clip Fraction: 0.15106
Policy Update Magnitude: 0.42147
Value Function Update Magnitude: 0.70243

Collected Steps per Second: 20,603.97291
Overall Steps per Second: 9,933.81232

Timestep Collection Time: 2.42749
Timestep Consumption Time: 2.60743
PPO Batch Consumption Time: 0.30448
Total Iteration Time: 5.03492

Cumulative Model Updates: 96,532
Cumulative Timesteps: 804,968,706

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 102,966.15478
Policy Entropy: 3.70203
Value Function Loss: 0.04610

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.14252
Policy Update Magnitude: 0.45531
Value Function Update Magnitude: 0.71539

Collected Steps per Second: 19,438.52677
Overall Steps per Second: 9,653.83207

Timestep Collection Time: 2.57303
Timestep Consumption Time: 2.60791
PPO Batch Consumption Time: 0.30135
Total Iteration Time: 5.18095

Cumulative Model Updates: 96,538
Cumulative Timesteps: 805,018,722

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 805018722...
Checkpoint 805018722 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 58,413.57124
Policy Entropy: 3.70813
Value Function Loss: 0.04720

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.14023
Policy Update Magnitude: 0.49381
Value Function Update Magnitude: 0.77018

Collected Steps per Second: 21,013.86743
Overall Steps per Second: 10,295.89077

Timestep Collection Time: 2.38033
Timestep Consumption Time: 2.47792
PPO Batch Consumption Time: 0.28312
Total Iteration Time: 4.85825

Cumulative Model Updates: 96,544
Cumulative Timesteps: 805,068,742

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 105,021.58614
Policy Entropy: 3.70309
Value Function Loss: 0.04764

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.13594
Policy Update Magnitude: 0.51219
Value Function Update Magnitude: 0.75097

Collected Steps per Second: 22,146.43037
Overall Steps per Second: 10,484.08087

Timestep Collection Time: 2.25896
Timestep Consumption Time: 2.51284
PPO Batch Consumption Time: 0.29142
Total Iteration Time: 4.77181

Cumulative Model Updates: 96,550
Cumulative Timesteps: 805,118,770

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 805118770...
Checkpoint 805118770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,773.65042
Policy Entropy: 3.69533
Value Function Loss: 0.04586

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.14514
Policy Update Magnitude: 0.48055
Value Function Update Magnitude: 0.62999

Collected Steps per Second: 20,678.40526
Overall Steps per Second: 10,031.66979

Timestep Collection Time: 2.41982
Timestep Consumption Time: 2.56818
PPO Batch Consumption Time: 0.29301
Total Iteration Time: 4.98800

Cumulative Model Updates: 96,556
Cumulative Timesteps: 805,168,808

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,345.89164
Policy Entropy: 3.66550
Value Function Loss: 0.04286

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.14129
Policy Update Magnitude: 0.44155
Value Function Update Magnitude: 0.55032

Collected Steps per Second: 20,874.95949
Overall Steps per Second: 10,002.43604

Timestep Collection Time: 2.39713
Timestep Consumption Time: 2.60565
PPO Batch Consumption Time: 0.30424
Total Iteration Time: 5.00278

Cumulative Model Updates: 96,562
Cumulative Timesteps: 805,218,848

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 805218848...
Checkpoint 805218848 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,345.89164
Policy Entropy: 3.66925
Value Function Loss: 0.03652

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.14825
Policy Update Magnitude: 0.41478
Value Function Update Magnitude: 0.50409

Collected Steps per Second: 20,492.71935
Overall Steps per Second: 10,063.60281

Timestep Collection Time: 2.44048
Timestep Consumption Time: 2.52912
PPO Batch Consumption Time: 0.30142
Total Iteration Time: 4.96959

Cumulative Model Updates: 96,568
Cumulative Timesteps: 805,268,860

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 100,986.66768
Policy Entropy: 3.62803
Value Function Loss: 0.04092

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.14430
Policy Update Magnitude: 0.40178
Value Function Update Magnitude: 0.48236

Collected Steps per Second: 21,231.94164
Overall Steps per Second: 10,389.60240

Timestep Collection Time: 2.35570
Timestep Consumption Time: 2.45835
PPO Batch Consumption Time: 0.29458
Total Iteration Time: 4.81404

Cumulative Model Updates: 96,574
Cumulative Timesteps: 805,318,876

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 805318876...
Checkpoint 805318876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 190,377.29509
Policy Entropy: 3.64846
Value Function Loss: 0.03911

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.14735
Policy Update Magnitude: 0.41663
Value Function Update Magnitude: 0.49947

Collected Steps per Second: 21,172.94993
Overall Steps per Second: 10,416.80898

Timestep Collection Time: 2.36226
Timestep Consumption Time: 2.43921
PPO Batch Consumption Time: 0.29111
Total Iteration Time: 4.80147

Cumulative Model Updates: 96,580
Cumulative Timesteps: 805,368,892

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 190,377.29509
Policy Entropy: 3.64064
Value Function Loss: 0.04538

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.14897
Policy Update Magnitude: 0.41433
Value Function Update Magnitude: 0.42815

Collected Steps per Second: 21,579.74592
Overall Steps per Second: 10,331.04183

Timestep Collection Time: 2.31847
Timestep Consumption Time: 2.52441
PPO Batch Consumption Time: 0.29846
Total Iteration Time: 4.84288

Cumulative Model Updates: 96,586
Cumulative Timesteps: 805,418,924

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 805418924...
Checkpoint 805418924 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 179,157.09872
Policy Entropy: 3.66338
Value Function Loss: 0.03147

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.14499
Policy Update Magnitude: 0.43291
Value Function Update Magnitude: 0.56527

Collected Steps per Second: 22,174.72831
Overall Steps per Second: 10,599.11443

Timestep Collection Time: 2.25554
Timestep Consumption Time: 2.46334
PPO Batch Consumption Time: 0.28730
Total Iteration Time: 4.71888

Cumulative Model Updates: 96,592
Cumulative Timesteps: 805,468,940

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 143,753.65629
Policy Entropy: 3.65591
Value Function Loss: 0.03333

Mean KL Divergence: 0.01099
SB3 Clip Fraction: 0.15429
Policy Update Magnitude: 0.41105
Value Function Update Magnitude: 0.70192

Collected Steps per Second: 22,278.78771
Overall Steps per Second: 10,312.05908

Timestep Collection Time: 2.24456
Timestep Consumption Time: 2.60472
PPO Batch Consumption Time: 0.31149
Total Iteration Time: 4.84927

Cumulative Model Updates: 96,598
Cumulative Timesteps: 805,518,946

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 805518946...
Checkpoint 805518946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 184,512.26553
Policy Entropy: 3.66312
Value Function Loss: 0.03479

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.14341
Policy Update Magnitude: 0.40888
Value Function Update Magnitude: 0.78875

Collected Steps per Second: 20,505.54125
Overall Steps per Second: 9,931.02526

Timestep Collection Time: 2.43924
Timestep Consumption Time: 2.59730
PPO Batch Consumption Time: 0.29917
Total Iteration Time: 5.03654

Cumulative Model Updates: 96,604
Cumulative Timesteps: 805,568,964

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 184,512.26553
Policy Entropy: 3.64924
Value Function Loss: 0.04122

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.14482
Policy Update Magnitude: 0.42431
Value Function Update Magnitude: 0.80838

Collected Steps per Second: 20,460.80833
Overall Steps per Second: 9,969.97666

Timestep Collection Time: 2.44467
Timestep Consumption Time: 2.57239
PPO Batch Consumption Time: 0.29257
Total Iteration Time: 5.01706

Cumulative Model Updates: 96,610
Cumulative Timesteps: 805,618,984

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 805618984...
Checkpoint 805618984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 261,899.55763
Policy Entropy: 3.64784
Value Function Loss: 0.04748

Mean KL Divergence: 0.01137
SB3 Clip Fraction: 0.15326
Policy Update Magnitude: 0.45789
Value Function Update Magnitude: 0.61894

Collected Steps per Second: 21,143.39716
Overall Steps per Second: 10,340.19322

Timestep Collection Time: 2.36679
Timestep Consumption Time: 2.47277
PPO Batch Consumption Time: 0.28450
Total Iteration Time: 4.83956

Cumulative Model Updates: 96,616
Cumulative Timesteps: 805,669,026

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 112,742.31244
Policy Entropy: 3.64733
Value Function Loss: 0.04549

Mean KL Divergence: 0.01149
SB3 Clip Fraction: 0.15672
Policy Update Magnitude: 0.45832
Value Function Update Magnitude: 0.55064

Collected Steps per Second: 21,007.00812
Overall Steps per Second: 10,029.56403

Timestep Collection Time: 2.38054
Timestep Consumption Time: 2.60552
PPO Batch Consumption Time: 0.29800
Total Iteration Time: 4.98606

Cumulative Model Updates: 96,622
Cumulative Timesteps: 805,719,034

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 805719034...
Checkpoint 805719034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 112,742.31244
Policy Entropy: 3.64557
Value Function Loss: 0.03633

Mean KL Divergence: 0.01224
SB3 Clip Fraction: 0.16373
Policy Update Magnitude: 0.44276
Value Function Update Magnitude: 0.61817

Collected Steps per Second: 15,922.31058
Overall Steps per Second: 7,827.02399

Timestep Collection Time: 3.14213
Timestep Consumption Time: 3.24983
PPO Batch Consumption Time: 0.38294
Total Iteration Time: 6.39196

Cumulative Model Updates: 96,628
Cumulative Timesteps: 805,769,064

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 112,742.31244
Policy Entropy: 3.64816
Value Function Loss: 0.03509

Mean KL Divergence: 0.01174
SB3 Clip Fraction: 0.15701
Policy Update Magnitude: 0.42399
Value Function Update Magnitude: 0.54784

Collected Steps per Second: 15,052.19645
Overall Steps per Second: 7,407.25019

Timestep Collection Time: 3.32244
Timestep Consumption Time: 3.42905
PPO Batch Consumption Time: 0.44243
Total Iteration Time: 6.75149

Cumulative Model Updates: 96,634
Cumulative Timesteps: 805,819,074

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 805819074...
Checkpoint 805819074 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 112,742.31244
Policy Entropy: 3.64013
Value Function Loss: 0.03571

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.13802
Policy Update Magnitude: 0.41930
Value Function Update Magnitude: 0.46422

Collected Steps per Second: 15,726.02908
Overall Steps per Second: 7,145.64526

Timestep Collection Time: 3.18097
Timestep Consumption Time: 3.81966
PPO Batch Consumption Time: 0.50583
Total Iteration Time: 7.00063

Cumulative Model Updates: 96,640
Cumulative Timesteps: 805,869,098

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 108,792.95943
Policy Entropy: 3.65375
Value Function Loss: 0.03376

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.14799
Policy Update Magnitude: 0.40293
Value Function Update Magnitude: 0.57605

Collected Steps per Second: 15,400.69218
Overall Steps per Second: 7,484.74354

Timestep Collection Time: 3.24778
Timestep Consumption Time: 3.43488
PPO Batch Consumption Time: 0.45616
Total Iteration Time: 6.68266

Cumulative Model Updates: 96,646
Cumulative Timesteps: 805,919,116

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 805919116...
Checkpoint 805919116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,895.47987
Policy Entropy: 3.66978
Value Function Loss: 0.03143

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.14365
Policy Update Magnitude: 0.39934
Value Function Update Magnitude: 0.63828

Collected Steps per Second: 15,336.91971
Overall Steps per Second: 7,182.87656

Timestep Collection Time: 3.26180
Timestep Consumption Time: 3.70282
PPO Batch Consumption Time: 0.49891
Total Iteration Time: 6.96462

Cumulative Model Updates: 96,652
Cumulative Timesteps: 805,969,142

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,336.98663
Policy Entropy: 3.68842
Value Function Loss: 0.03210

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.14317
Policy Update Magnitude: 0.38108
Value Function Update Magnitude: 0.54342

Collected Steps per Second: 15,306.34687
Overall Steps per Second: 7,290.01632

Timestep Collection Time: 3.26688
Timestep Consumption Time: 3.59236
PPO Batch Consumption Time: 0.48259
Total Iteration Time: 6.85924

Cumulative Model Updates: 96,658
Cumulative Timesteps: 806,019,146

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 806019146...
Checkpoint 806019146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,336.98663
Policy Entropy: 3.68622
Value Function Loss: 0.02909

Mean KL Divergence: 0.01071
SB3 Clip Fraction: 0.14988
Policy Update Magnitude: 0.37842
Value Function Update Magnitude: 0.48939

Collected Steps per Second: 14,994.04672
Overall Steps per Second: 7,151.76140

Timestep Collection Time: 3.33572
Timestep Consumption Time: 3.65780
PPO Batch Consumption Time: 0.48475
Total Iteration Time: 6.99352

Cumulative Model Updates: 96,664
Cumulative Timesteps: 806,069,162

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,336.98663
Policy Entropy: 3.67297
Value Function Loss: 0.03155

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.14355
Policy Update Magnitude: 0.36726
Value Function Update Magnitude: 0.43499

Collected Steps per Second: 15,626.31674
Overall Steps per Second: 7,401.30140

Timestep Collection Time: 3.20037
Timestep Consumption Time: 3.55655
PPO Batch Consumption Time: 0.46703
Total Iteration Time: 6.75692

Cumulative Model Updates: 96,670
Cumulative Timesteps: 806,119,172

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 806119172...
Checkpoint 806119172 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 100,174.58409
Policy Entropy: 3.68725
Value Function Loss: 0.02963

Mean KL Divergence: 0.01088
SB3 Clip Fraction: 0.15130
Policy Update Magnitude: 0.41392
Value Function Update Magnitude: 0.44362

Collected Steps per Second: 16,001.40682
Overall Steps per Second: 7,607.85802

Timestep Collection Time: 3.12648
Timestep Consumption Time: 3.44936
PPO Batch Consumption Time: 0.44407
Total Iteration Time: 6.57583

Cumulative Model Updates: 96,676
Cumulative Timesteps: 806,169,200

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79,473.29816
Policy Entropy: 3.69979
Value Function Loss: 0.03553

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.14090
Policy Update Magnitude: 0.41920
Value Function Update Magnitude: 0.54117

Collected Steps per Second: 16,097.14947
Overall Steps per Second: 7,733.07523

Timestep Collection Time: 3.10639
Timestep Consumption Time: 3.35986
PPO Batch Consumption Time: 0.43187
Total Iteration Time: 6.46625

Cumulative Model Updates: 96,682
Cumulative Timesteps: 806,219,204

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 806219204...
Checkpoint 806219204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 64,368.94800
Policy Entropy: 3.70317
Value Function Loss: 0.03505

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.14413
Policy Update Magnitude: 0.46881
Value Function Update Magnitude: 0.54364

Collected Steps per Second: 16,018.53536
Overall Steps per Second: 7,624.50149

Timestep Collection Time: 3.12251
Timestep Consumption Time: 3.43766
PPO Batch Consumption Time: 0.43726
Total Iteration Time: 6.56017

Cumulative Model Updates: 96,688
Cumulative Timesteps: 806,269,222

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 64,368.94800
Policy Entropy: 3.68315
Value Function Loss: 0.03487

Mean KL Divergence: 0.01077
SB3 Clip Fraction: 0.15062
Policy Update Magnitude: 0.44476
Value Function Update Magnitude: 0.59146

Collected Steps per Second: 16,397.91988
Overall Steps per Second: 7,393.91373

Timestep Collection Time: 3.05002
Timestep Consumption Time: 3.71419
PPO Batch Consumption Time: 0.48674
Total Iteration Time: 6.76421

Cumulative Model Updates: 96,694
Cumulative Timesteps: 806,319,236

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 806319236...
Checkpoint 806319236 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 64,368.94800
Policy Entropy: 3.66434
Value Function Loss: 0.03095

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.14585
Policy Update Magnitude: 0.38887
Value Function Update Magnitude: 0.49195

Collected Steps per Second: 16,382.32014
Overall Steps per Second: 7,566.37590

Timestep Collection Time: 3.05451
Timestep Consumption Time: 3.55896
PPO Batch Consumption Time: 0.46450
Total Iteration Time: 6.61347

Cumulative Model Updates: 96,700
Cumulative Timesteps: 806,369,276

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 180,558.67688
Policy Entropy: 3.64716
Value Function Loss: 0.03232

Mean KL Divergence: 0.01085
SB3 Clip Fraction: 0.15268
Policy Update Magnitude: 0.37444
Value Function Update Magnitude: 0.51285

Collected Steps per Second: 16,144.94741
Overall Steps per Second: 7,667.54664

Timestep Collection Time: 3.09707
Timestep Consumption Time: 3.42418
PPO Batch Consumption Time: 0.43987
Total Iteration Time: 6.52125

Cumulative Model Updates: 96,706
Cumulative Timesteps: 806,419,278

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 806419278...
Checkpoint 806419278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 156,980.36353
Policy Entropy: 3.65683
Value Function Loss: 0.03580

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.13938
Policy Update Magnitude: 0.39292
Value Function Update Magnitude: 0.55725

Collected Steps per Second: 17,072.44704
Overall Steps per Second: 7,832.12109

Timestep Collection Time: 2.92975
Timestep Consumption Time: 3.45652
PPO Batch Consumption Time: 0.44441
Total Iteration Time: 6.38626

Cumulative Model Updates: 96,712
Cumulative Timesteps: 806,469,296

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 156,980.36353
Policy Entropy: 3.65627
Value Function Loss: 0.03812

Mean KL Divergence: 0.01088
SB3 Clip Fraction: 0.14902
Policy Update Magnitude: 0.40426
Value Function Update Magnitude: 0.53828

Collected Steps per Second: 16,622.84108
Overall Steps per Second: 7,693.97045

Timestep Collection Time: 3.00935
Timestep Consumption Time: 3.49236
PPO Batch Consumption Time: 0.45200
Total Iteration Time: 6.50171

Cumulative Model Updates: 96,718
Cumulative Timesteps: 806,519,320

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 806519320...
Checkpoint 806519320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 156,980.36353
Policy Entropy: 3.67364
Value Function Loss: 0.03445

Mean KL Divergence: 0.01103
SB3 Clip Fraction: 0.15137
Policy Update Magnitude: 0.39800
Value Function Update Magnitude: 0.62396

Collected Steps per Second: 16,296.63260
Overall Steps per Second: 7,590.73102

Timestep Collection Time: 3.06910
Timestep Consumption Time: 3.51999
PPO Batch Consumption Time: 0.45595
Total Iteration Time: 6.58909

Cumulative Model Updates: 96,724
Cumulative Timesteps: 806,569,336

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 233,654.15020
Policy Entropy: 3.65640
Value Function Loss: 0.03177

Mean KL Divergence: 0.01070
SB3 Clip Fraction: 0.14792
Policy Update Magnitude: 0.41221
Value Function Update Magnitude: 0.61449

Collected Steps per Second: 15,830.98037
Overall Steps per Second: 7,676.30016

Timestep Collection Time: 3.15874
Timestep Consumption Time: 3.35559
PPO Batch Consumption Time: 0.43863
Total Iteration Time: 6.51434

Cumulative Model Updates: 96,730
Cumulative Timesteps: 806,619,342

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 806619342...
Checkpoint 806619342 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 289,787.36868
Policy Entropy: 3.65887
Value Function Loss: 0.03506

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.14661
Policy Update Magnitude: 0.42420
Value Function Update Magnitude: 0.64451

Collected Steps per Second: 15,865.60597
Overall Steps per Second: 7,724.74582

Timestep Collection Time: 3.15172
Timestep Consumption Time: 3.32150
PPO Batch Consumption Time: 0.43778
Total Iteration Time: 6.47322

Cumulative Model Updates: 96,736
Cumulative Timesteps: 806,669,346

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53,712.75906
Policy Entropy: 3.66747
Value Function Loss: 0.03622

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.14142
Policy Update Magnitude: 0.46262
Value Function Update Magnitude: 0.63681

Collected Steps per Second: 15,643.69666
Overall Steps per Second: 7,720.10742

Timestep Collection Time: 3.19835
Timestep Consumption Time: 3.28265
PPO Batch Consumption Time: 0.43375
Total Iteration Time: 6.48100

Cumulative Model Updates: 96,742
Cumulative Timesteps: 806,719,380

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 806719380...
Checkpoint 806719380 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 53,712.75906
Policy Entropy: 3.68825
Value Function Loss: 0.03341

Mean KL Divergence: 0.01110
SB3 Clip Fraction: 0.15223
Policy Update Magnitude: 0.46031
Value Function Update Magnitude: 0.67325

Collected Steps per Second: 15,748.42037
Overall Steps per Second: 7,284.26003

Timestep Collection Time: 3.17492
Timestep Consumption Time: 3.68919
PPO Batch Consumption Time: 0.49043
Total Iteration Time: 6.86412

Cumulative Model Updates: 96,748
Cumulative Timesteps: 806,769,380

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89,682.51174
Policy Entropy: 3.68912
Value Function Loss: 0.03181

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.14220
Policy Update Magnitude: 0.41838
Value Function Update Magnitude: 0.70943

Collected Steps per Second: 15,312.97985
Overall Steps per Second: 7,086.04669

Timestep Collection Time: 3.26520
Timestep Consumption Time: 3.79092
PPO Batch Consumption Time: 0.50250
Total Iteration Time: 7.05612

Cumulative Model Updates: 96,754
Cumulative Timesteps: 806,819,380

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 806819380...
Checkpoint 806819380 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 101,855.70845
Policy Entropy: 3.66509
Value Function Loss: 0.03508

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.14212
Policy Update Magnitude: 0.43833
Value Function Update Magnitude: 0.62085

Collected Steps per Second: 15,496.31876
Overall Steps per Second: 7,184.15767

Timestep Collection Time: 3.22748
Timestep Consumption Time: 3.73423
PPO Batch Consumption Time: 0.49090
Total Iteration Time: 6.96171

Cumulative Model Updates: 96,760
Cumulative Timesteps: 806,869,394

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 101,855.70845
Policy Entropy: 3.65076
Value Function Loss: 0.03791

Mean KL Divergence: 0.01108
SB3 Clip Fraction: 0.15132
Policy Update Magnitude: 0.46882
Value Function Update Magnitude: 0.63630

Collected Steps per Second: 15,197.96549
Overall Steps per Second: 7,012.86575

Timestep Collection Time: 3.29136
Timestep Consumption Time: 3.84153
PPO Batch Consumption Time: 0.50814
Total Iteration Time: 7.13289

Cumulative Model Updates: 96,766
Cumulative Timesteps: 806,919,416

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 806919416...
Checkpoint 806919416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 152,784.43996
Policy Entropy: 3.66161
Value Function Loss: 0.04084

Mean KL Divergence: 0.01065
SB3 Clip Fraction: 0.14628
Policy Update Magnitude: 0.47411
Value Function Update Magnitude: 0.58579

Collected Steps per Second: 15,238.12728
Overall Steps per Second: 7,399.71589

Timestep Collection Time: 3.28177
Timestep Consumption Time: 3.47633
PPO Batch Consumption Time: 0.45053
Total Iteration Time: 6.75810

Cumulative Model Updates: 96,772
Cumulative Timesteps: 806,969,424

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 152,784.43996
Policy Entropy: 3.67185
Value Function Loss: 0.03597

Mean KL Divergence: 0.01097
SB3 Clip Fraction: 0.14503
Policy Update Magnitude: 0.50283
Value Function Update Magnitude: 0.59747

Collected Steps per Second: 16,148.97737
Overall Steps per Second: 7,516.58086

Timestep Collection Time: 3.09753
Timestep Consumption Time: 3.55735
PPO Batch Consumption Time: 0.46228
Total Iteration Time: 6.65489

Cumulative Model Updates: 96,778
Cumulative Timesteps: 807,019,446

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 807019446...
Checkpoint 807019446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 152,784.43996
Policy Entropy: 3.67256
Value Function Loss: 0.03476

Mean KL Divergence: 0.01057
SB3 Clip Fraction: 0.13796
Policy Update Magnitude: 0.52656
Value Function Update Magnitude: 0.55180

Collected Steps per Second: 16,122.52812
Overall Steps per Second: 7,681.25913

Timestep Collection Time: 3.10249
Timestep Consumption Time: 3.40946
PPO Batch Consumption Time: 0.44072
Total Iteration Time: 6.51195

Cumulative Model Updates: 96,784
Cumulative Timesteps: 807,069,466

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 196,266.54179
Policy Entropy: 3.65019
Value Function Loss: 0.03277

Mean KL Divergence: 0.00665
SB3 Clip Fraction: 0.08290
Policy Update Magnitude: 0.62536
Value Function Update Magnitude: 0.60711

Collected Steps per Second: 16,178.78999
Overall Steps per Second: 7,697.58476

Timestep Collection Time: 3.09195
Timestep Consumption Time: 3.40671
PPO Batch Consumption Time: 0.43828
Total Iteration Time: 6.49866

Cumulative Model Updates: 96,790
Cumulative Timesteps: 807,119,490

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 807119490...
Checkpoint 807119490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 541,746.39748
Policy Entropy: 3.64964
Value Function Loss: 0.04039

Mean KL Divergence: 0.00671
SB3 Clip Fraction: 0.08344
Policy Update Magnitude: 0.71603
Value Function Update Magnitude: 0.67129

Collected Steps per Second: 15,678.80458
Overall Steps per Second: 7,664.72367

Timestep Collection Time: 3.18978
Timestep Consumption Time: 3.33517
PPO Batch Consumption Time: 0.43886
Total Iteration Time: 6.52496

Cumulative Model Updates: 96,796
Cumulative Timesteps: 807,169,502

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 244,294.54896
Policy Entropy: 3.66375
Value Function Loss: 0.03965

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.11322
Policy Update Magnitude: 0.73354
Value Function Update Magnitude: 0.66717

Collected Steps per Second: 15,734.47869
Overall Steps per Second: 7,554.94483

Timestep Collection Time: 3.17951
Timestep Consumption Time: 3.44237
PPO Batch Consumption Time: 0.45793
Total Iteration Time: 6.62189

Cumulative Model Updates: 96,802
Cumulative Timesteps: 807,219,530

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 807219530...
Checkpoint 807219530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 197,879.72906
Policy Entropy: 3.68302
Value Function Loss: 0.03687

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.14003
Policy Update Magnitude: 0.61545
Value Function Update Magnitude: 0.67115

Collected Steps per Second: 15,613.51130
Overall Steps per Second: 7,512.08441

Timestep Collection Time: 3.20492
Timestep Consumption Time: 3.45635
PPO Batch Consumption Time: 0.46046
Total Iteration Time: 6.66127

Cumulative Model Updates: 96,808
Cumulative Timesteps: 807,269,570

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 197,879.72906
Policy Entropy: 3.70515
Value Function Loss: 0.02665

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.12522
Policy Update Magnitude: 0.50691
Value Function Update Magnitude: 0.64796

Collected Steps per Second: 15,668.10534
Overall Steps per Second: 7,598.74402

Timestep Collection Time: 3.19196
Timestep Consumption Time: 3.38965
PPO Batch Consumption Time: 0.44020
Total Iteration Time: 6.58161

Cumulative Model Updates: 96,814
Cumulative Timesteps: 807,319,582

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 807319582...
Checkpoint 807319582 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 197,879.72906
Policy Entropy: 3.69750
Value Function Loss: 0.02373

Mean KL Divergence: 0.01108
SB3 Clip Fraction: 0.14722
Policy Update Magnitude: 0.43870
Value Function Update Magnitude: 0.51613

Collected Steps per Second: 16,357.27678
Overall Steps per Second: 7,820.47252

Timestep Collection Time: 3.05809
Timestep Consumption Time: 3.33820
PPO Batch Consumption Time: 0.43513
Total Iteration Time: 6.39629

Cumulative Model Updates: 96,820
Cumulative Timesteps: 807,369,604

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 197,879.72906
Policy Entropy: 3.70138
Value Function Loss: 0.02152

Mean KL Divergence: 0.01309
SB3 Clip Fraction: 0.17257
Policy Update Magnitude: 0.37150
Value Function Update Magnitude: 0.39436

Collected Steps per Second: 16,148.64009
Overall Steps per Second: 7,354.34342

Timestep Collection Time: 3.09636
Timestep Consumption Time: 3.70262
PPO Batch Consumption Time: 0.48435
Total Iteration Time: 6.79898

Cumulative Model Updates: 96,826
Cumulative Timesteps: 807,419,606

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 807419606...
Checkpoint 807419606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 197,879.72906
Policy Entropy: 3.70087
Value Function Loss: 0.01932

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.11559
Policy Update Magnitude: 0.40012
Value Function Update Magnitude: 0.43505

Collected Steps per Second: 15,713.06743
Overall Steps per Second: 7,456.08126

Timestep Collection Time: 3.18410
Timestep Consumption Time: 3.52613
PPO Batch Consumption Time: 0.45568
Total Iteration Time: 6.71023

Cumulative Model Updates: 96,832
Cumulative Timesteps: 807,469,638

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 197,879.72906
Policy Entropy: 3.69760
Value Function Loss: 0.01866

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.10491
Policy Update Magnitude: 0.42886
Value Function Update Magnitude: 0.45583

Collected Steps per Second: 15,474.68689
Overall Steps per Second: 7,015.59047

Timestep Collection Time: 3.23393
Timestep Consumption Time: 3.89933
PPO Batch Consumption Time: 0.51210
Total Iteration Time: 7.13326

Cumulative Model Updates: 96,838
Cumulative Timesteps: 807,519,682

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 807519682...
Checkpoint 807519682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 197,879.72906
Policy Entropy: 3.69768
Value Function Loss: 0.01866

Mean KL Divergence: 0.00721
SB3 Clip Fraction: 0.09344
Policy Update Magnitude: 0.43522
Value Function Update Magnitude: 0.46523

Collected Steps per Second: 15,473.57209
Overall Steps per Second: 7,184.34662

Timestep Collection Time: 3.23222
Timestep Consumption Time: 3.72930
PPO Batch Consumption Time: 0.48954
Total Iteration Time: 6.96152

Cumulative Model Updates: 96,844
Cumulative Timesteps: 807,569,696

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 197,879.72906
Policy Entropy: 3.70426
Value Function Loss: 0.01971

Mean KL Divergence: 0.01445
SB3 Clip Fraction: 0.17300
Policy Update Magnitude: 0.43177
Value Function Update Magnitude: 0.49380

Collected Steps per Second: 15,180.18664
Overall Steps per Second: 7,147.51204

Timestep Collection Time: 3.29469
Timestep Consumption Time: 3.70271
PPO Batch Consumption Time: 0.48390
Total Iteration Time: 6.99740

Cumulative Model Updates: 96,850
Cumulative Timesteps: 807,619,710

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 807619710...
Checkpoint 807619710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 197,879.72906
Policy Entropy: 3.69957
Value Function Loss: 0.01935

Mean KL Divergence: 0.01504
SB3 Clip Fraction: 0.19452
Policy Update Magnitude: 0.36645
Value Function Update Magnitude: 0.52913

Collected Steps per Second: 15,081.91060
Overall Steps per Second: 6,986.24249

Timestep Collection Time: 3.31616
Timestep Consumption Time: 3.84277
PPO Batch Consumption Time: 0.52153
Total Iteration Time: 7.15893

Cumulative Model Updates: 96,856
Cumulative Timesteps: 807,669,724

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 304,960.53734
Policy Entropy: 3.67070
Value Function Loss: 0.03715

Mean KL Divergence: 0.01521
SB3 Clip Fraction: 0.19478
Policy Update Magnitude: 0.42862
Value Function Update Magnitude: 0.50099

Collected Steps per Second: 14,882.32092
Overall Steps per Second: 7,505.34411

Timestep Collection Time: 3.36103
Timestep Consumption Time: 3.30355
PPO Batch Consumption Time: 0.43397
Total Iteration Time: 6.66458

Cumulative Model Updates: 96,862
Cumulative Timesteps: 807,719,744

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 807719744...
Checkpoint 807719744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 162,066.56718
Policy Entropy: 3.64086
Value Function Loss: 0.04908

Mean KL Divergence: 0.01491
SB3 Clip Fraction: 0.17926
Policy Update Magnitude: 0.49617
Value Function Update Magnitude: 0.50833

Collected Steps per Second: 15,568.58221
Overall Steps per Second: 7,540.22919

Timestep Collection Time: 3.21314
Timestep Consumption Time: 3.42114
PPO Batch Consumption Time: 0.45771
Total Iteration Time: 6.63428

Cumulative Model Updates: 96,868
Cumulative Timesteps: 807,769,768

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 169,162.82254
Policy Entropy: 3.63317
Value Function Loss: 0.05629

Mean KL Divergence: 0.01409
SB3 Clip Fraction: 0.17540
Policy Update Magnitude: 0.63233
Value Function Update Magnitude: 0.42647

Collected Steps per Second: 15,370.50854
Overall Steps per Second: 7,316.83777

Timestep Collection Time: 3.25428
Timestep Consumption Time: 3.58200
PPO Batch Consumption Time: 0.46930
Total Iteration Time: 6.83629

Cumulative Model Updates: 96,874
Cumulative Timesteps: 807,819,788

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 807819788...
Checkpoint 807819788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 169,162.82254
Policy Entropy: 3.64743
Value Function Loss: 0.04745

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.09929
Policy Update Magnitude: 0.78270
Value Function Update Magnitude: 0.40734

Collected Steps per Second: 15,712.90111
Overall Steps per Second: 7,504.41976

Timestep Collection Time: 3.18337
Timestep Consumption Time: 3.48203
PPO Batch Consumption Time: 0.45404
Total Iteration Time: 6.66541

Cumulative Model Updates: 96,880
Cumulative Timesteps: 807,869,808

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 169,162.82254
Policy Entropy: 3.64301
Value Function Loss: 0.04185

Mean KL Divergence: 0.01199
SB3 Clip Fraction: 0.15220
Policy Update Magnitude: 0.79883
Value Function Update Magnitude: 0.42965

Collected Steps per Second: 16,340.35623
Overall Steps per Second: 7,841.33771

Timestep Collection Time: 3.06028
Timestep Consumption Time: 3.31695
PPO Batch Consumption Time: 0.42883
Total Iteration Time: 6.37723

Cumulative Model Updates: 96,886
Cumulative Timesteps: 807,919,814

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 807919814...
Checkpoint 807919814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 169,162.82254
Policy Entropy: 3.63146
Value Function Loss: 0.05105

Mean KL Divergence: 0.01460
SB3 Clip Fraction: 0.18598
Policy Update Magnitude: 0.62267
Value Function Update Magnitude: 0.43791

Collected Steps per Second: 15,910.58863
Overall Steps per Second: 7,556.74358

Timestep Collection Time: 3.14281
Timestep Consumption Time: 3.47432
PPO Batch Consumption Time: 0.45062
Total Iteration Time: 6.61714

Cumulative Model Updates: 96,892
Cumulative Timesteps: 807,969,818

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 401,461.50291
Policy Entropy: 3.62982
Value Function Loss: 0.05541

Mean KL Divergence: 0.01225
SB3 Clip Fraction: 0.15815
Policy Update Magnitude: 0.63901
Value Function Update Magnitude: 0.51683

Collected Steps per Second: 15,938.99448
Overall Steps per Second: 7,609.48359

Timestep Collection Time: 3.13897
Timestep Consumption Time: 3.43598
PPO Batch Consumption Time: 0.44260
Total Iteration Time: 6.57495

Cumulative Model Updates: 96,898
Cumulative Timesteps: 808,019,850

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 808019850...
Checkpoint 808019850 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 211,315.40936
Policy Entropy: 3.60394
Value Function Loss: 0.06402

Mean KL Divergence: 0.01241
SB3 Clip Fraction: 0.15618
Policy Update Magnitude: 0.69860
Value Function Update Magnitude: 0.50848

Collected Steps per Second: 15,690.10727
Overall Steps per Second: 7,523.54731

Timestep Collection Time: 3.18698
Timestep Consumption Time: 3.45936
PPO Batch Consumption Time: 0.44675
Total Iteration Time: 6.64633

Cumulative Model Updates: 96,904
Cumulative Timesteps: 808,069,854

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,804.30901
Policy Entropy: 3.64461
Value Function Loss: 0.06787

Mean KL Divergence: 0.01066
SB3 Clip Fraction: 0.13600
Policy Update Magnitude: 0.70330
Value Function Update Magnitude: 0.58297

Collected Steps per Second: 15,915.79383
Overall Steps per Second: 7,488.14753

Timestep Collection Time: 3.14229
Timestep Consumption Time: 3.53653
PPO Batch Consumption Time: 0.45848
Total Iteration Time: 6.67882

Cumulative Model Updates: 96,910
Cumulative Timesteps: 808,119,866

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 808119866...
Checkpoint 808119866 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 123,440.83783
Policy Entropy: 3.66860
Value Function Loss: 0.08289

Mean KL Divergence: 0.01088
SB3 Clip Fraction: 0.13718
Policy Update Magnitude: 0.74420
Value Function Update Magnitude: 0.55343

Collected Steps per Second: 15,947.40607
Overall Steps per Second: 7,484.65793

Timestep Collection Time: 3.13706
Timestep Consumption Time: 3.54701
PPO Batch Consumption Time: 0.46058
Total Iteration Time: 6.68407

Cumulative Model Updates: 96,916
Cumulative Timesteps: 808,169,894

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 71,067.04867
Policy Entropy: 3.69138
Value Function Loss: 0.06053

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.12952
Policy Update Magnitude: 0.75874
Value Function Update Magnitude: 0.64785

Collected Steps per Second: 15,426.58739
Overall Steps per Second: 7,175.15518

Timestep Collection Time: 3.24245
Timestep Consumption Time: 3.72882
PPO Batch Consumption Time: 0.49161
Total Iteration Time: 6.97128

Cumulative Model Updates: 96,922
Cumulative Timesteps: 808,219,914

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 808219914...
Checkpoint 808219914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48,803.65944
Policy Entropy: 3.70605
Value Function Loss: 0.05679

Mean KL Divergence: 0.01077
SB3 Clip Fraction: 0.13751
Policy Update Magnitude: 0.77345
Value Function Update Magnitude: 0.64788

Collected Steps per Second: 15,542.39673
Overall Steps per Second: 7,243.21705

Timestep Collection Time: 3.21739
Timestep Consumption Time: 3.68645
PPO Batch Consumption Time: 0.48308
Total Iteration Time: 6.90384

Cumulative Model Updates: 96,928
Cumulative Timesteps: 808,269,920

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 139,385.91053
Policy Entropy: 3.68276
Value Function Loss: 0.05723

Mean KL Divergence: 0.01067
SB3 Clip Fraction: 0.13597
Policy Update Magnitude: 0.73889
Value Function Update Magnitude: 0.59161

Collected Steps per Second: 15,430.15966
Overall Steps per Second: 7,271.68450

Timestep Collection Time: 3.24144
Timestep Consumption Time: 3.63674
PPO Batch Consumption Time: 0.47498
Total Iteration Time: 6.87819

Cumulative Model Updates: 96,934
Cumulative Timesteps: 808,319,936

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 808319936...
Checkpoint 808319936 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 74,359.64759
Policy Entropy: 3.67304
Value Function Loss: 0.05187

Mean KL Divergence: 0.01117
SB3 Clip Fraction: 0.14620
Policy Update Magnitude: 0.72881
Value Function Update Magnitude: 0.52121

Collected Steps per Second: 15,542.51025
Overall Steps per Second: 7,275.39467

Timestep Collection Time: 3.21737
Timestep Consumption Time: 3.65593
PPO Batch Consumption Time: 0.47913
Total Iteration Time: 6.87330

Cumulative Model Updates: 96,940
Cumulative Timesteps: 808,369,942

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,837.30615
Policy Entropy: 3.63658
Value Function Loss: 0.05348

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.13723
Policy Update Magnitude: 0.67788
Value Function Update Magnitude: 0.45957

Collected Steps per Second: 15,484.16906
Overall Steps per Second: 7,175.93084

Timestep Collection Time: 3.23091
Timestep Consumption Time: 3.74073
PPO Batch Consumption Time: 0.49226
Total Iteration Time: 6.97164

Cumulative Model Updates: 96,946
Cumulative Timesteps: 808,419,970

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 808419970...
Checkpoint 808419970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,179.20519
Policy Entropy: 3.65228
Value Function Loss: 0.04781

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.13141
Policy Update Magnitude: 0.60792
Value Function Update Magnitude: 0.44820

Collected Steps per Second: 15,546.57246
Overall Steps per Second: 7,932.16444

Timestep Collection Time: 3.21730
Timestep Consumption Time: 3.08842
PPO Batch Consumption Time: 0.38338
Total Iteration Time: 6.30572

Cumulative Model Updates: 96,952
Cumulative Timesteps: 808,469,988

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 148,287.33357
Policy Entropy: 3.65739
Value Function Loss: 0.04927

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.13531
Policy Update Magnitude: 0.59290
Value Function Update Magnitude: 0.45157

Collected Steps per Second: 20,847.37563
Overall Steps per Second: 10,222.97578

Timestep Collection Time: 2.39915
Timestep Consumption Time: 2.49336
PPO Batch Consumption Time: 0.29615
Total Iteration Time: 4.89251

Cumulative Model Updates: 96,958
Cumulative Timesteps: 808,520,004

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 808520004...
Checkpoint 808520004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 114,554.58772
Policy Entropy: 3.67745
Value Function Loss: 0.04673

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.12724
Policy Update Magnitude: 0.58211
Value Function Update Magnitude: 0.51217

Collected Steps per Second: 20,629.35883
Overall Steps per Second: 10,047.05054

Timestep Collection Time: 2.42373
Timestep Consumption Time: 2.55285
PPO Batch Consumption Time: 0.29185
Total Iteration Time: 4.97658

Cumulative Model Updates: 96,964
Cumulative Timesteps: 808,570,004

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 144,504.65858
Policy Entropy: 3.67995
Value Function Loss: 0.04652

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.14256
Policy Update Magnitude: 0.55892
Value Function Update Magnitude: 0.55359

Collected Steps per Second: 20,709.71073
Overall Steps per Second: 9,919.75649

Timestep Collection Time: 2.41481
Timestep Consumption Time: 2.62665
PPO Batch Consumption Time: 0.30353
Total Iteration Time: 5.04145

Cumulative Model Updates: 96,970
Cumulative Timesteps: 808,620,014

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 808620014...
Checkpoint 808620014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 62,218.87249
Policy Entropy: 3.67868
Value Function Loss: 0.04076

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.14086
Policy Update Magnitude: 0.54767
Value Function Update Magnitude: 0.53625

Collected Steps per Second: 20,333.23814
Overall Steps per Second: 9,708.46315

Timestep Collection Time: 2.46031
Timestep Consumption Time: 2.69252
PPO Batch Consumption Time: 0.31662
Total Iteration Time: 5.15282

Cumulative Model Updates: 96,976
Cumulative Timesteps: 808,670,040

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42,004.25269
Policy Entropy: 3.68900
Value Function Loss: 0.03960

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.14319
Policy Update Magnitude: 0.49767
Value Function Update Magnitude: 0.48417

Collected Steps per Second: 20,701.02368
Overall Steps per Second: 9,931.05151

Timestep Collection Time: 2.41611
Timestep Consumption Time: 2.62021
PPO Batch Consumption Time: 0.30460
Total Iteration Time: 5.03632

Cumulative Model Updates: 96,982
Cumulative Timesteps: 808,720,056

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 808720056...
Checkpoint 808720056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,070.60851
Policy Entropy: 3.70355
Value Function Loss: 0.04466

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.13428
Policy Update Magnitude: 0.53709
Value Function Update Magnitude: 0.48091

Collected Steps per Second: 20,484.60121
Overall Steps per Second: 10,000.16460

Timestep Collection Time: 2.44096
Timestep Consumption Time: 2.55916
PPO Batch Consumption Time: 0.29487
Total Iteration Time: 5.00012

Cumulative Model Updates: 96,988
Cumulative Timesteps: 808,770,058

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,175.00080
Policy Entropy: 3.71345
Value Function Loss: 0.04774

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.14252
Policy Update Magnitude: 0.54009
Value Function Update Magnitude: 0.53083

Collected Steps per Second: 21,406.87151
Overall Steps per Second: 10,164.81185

Timestep Collection Time: 2.33701
Timestep Consumption Time: 2.58468
PPO Batch Consumption Time: 0.29893
Total Iteration Time: 4.92168

Cumulative Model Updates: 96,994
Cumulative Timesteps: 808,820,086

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 808820086...
Checkpoint 808820086 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,380.46243
Policy Entropy: 3.71740
Value Function Loss: 0.04304

Mean KL Divergence: 0.01058
SB3 Clip Fraction: 0.14577
Policy Update Magnitude: 0.49745
Value Function Update Magnitude: 0.55677

Collected Steps per Second: 20,977.85124
Overall Steps per Second: 10,122.98678

Timestep Collection Time: 2.38413
Timestep Consumption Time: 2.55650
PPO Batch Consumption Time: 0.29444
Total Iteration Time: 4.94064

Cumulative Model Updates: 97,000
Cumulative Timesteps: 808,870,100

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,267.96467
Policy Entropy: 3.70828
Value Function Loss: 0.03841

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.14124
Policy Update Magnitude: 0.43757
Value Function Update Magnitude: 0.56912

Collected Steps per Second: 21,294.18486
Overall Steps per Second: 10,127.97859

Timestep Collection Time: 2.34937
Timestep Consumption Time: 2.59021
PPO Batch Consumption Time: 0.29977
Total Iteration Time: 4.93958

Cumulative Model Updates: 97,006
Cumulative Timesteps: 808,920,128

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 808920128...
Checkpoint 808920128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,886.12163
Policy Entropy: 3.69345
Value Function Loss: 0.03555

Mean KL Divergence: 0.01092
SB3 Clip Fraction: 0.15109
Policy Update Magnitude: 0.49331
Value Function Update Magnitude: 0.64160

Collected Steps per Second: 20,173.76197
Overall Steps per Second: 10,115.66363

Timestep Collection Time: 2.47966
Timestep Consumption Time: 2.46555
PPO Batch Consumption Time: 0.29252
Total Iteration Time: 4.94520

Cumulative Model Updates: 97,012
Cumulative Timesteps: 808,970,152

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,886.12163
Policy Entropy: 3.68505
Value Function Loss: 0.03325

Mean KL Divergence: 0.01154
SB3 Clip Fraction: 0.15791
Policy Update Magnitude: 0.46258
Value Function Update Magnitude: 0.79301

Collected Steps per Second: 20,464.04401
Overall Steps per Second: 10,105.72879

Timestep Collection Time: 2.44351
Timestep Consumption Time: 2.50458
PPO Batch Consumption Time: 0.29714
Total Iteration Time: 4.94808

Cumulative Model Updates: 97,018
Cumulative Timesteps: 809,020,156

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 809020156...
Checkpoint 809020156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 274,617.62351
Policy Entropy: 3.69169
Value Function Loss: 0.03461

Mean KL Divergence: 0.01127
SB3 Clip Fraction: 0.15527
Policy Update Magnitude: 0.42528
Value Function Update Magnitude: 0.66100

Collected Steps per Second: 20,134.44324
Overall Steps per Second: 10,124.58166

Timestep Collection Time: 2.48420
Timestep Consumption Time: 2.45605
PPO Batch Consumption Time: 0.29222
Total Iteration Time: 4.94025

Cumulative Model Updates: 97,024
Cumulative Timesteps: 809,070,174

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,224.66008
Policy Entropy: 3.71350
Value Function Loss: 0.03381

Mean KL Divergence: 0.01157
SB3 Clip Fraction: 0.15699
Policy Update Magnitude: 0.44398
Value Function Update Magnitude: 0.61625

Collected Steps per Second: 20,704.86728
Overall Steps per Second: 10,092.92409

Timestep Collection Time: 2.41518
Timestep Consumption Time: 2.53938
PPO Batch Consumption Time: 0.29461
Total Iteration Time: 4.95456

Cumulative Model Updates: 97,030
Cumulative Timesteps: 809,120,180

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 809120180...
Checkpoint 809120180 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,387.84173
Policy Entropy: 3.71186
Value Function Loss: 0.03613

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.14000
Policy Update Magnitude: 0.49711
Value Function Update Magnitude: 0.58438

Collected Steps per Second: 20,929.99275
Overall Steps per Second: 10,147.78426

Timestep Collection Time: 2.38949
Timestep Consumption Time: 2.53888
PPO Batch Consumption Time: 0.29569
Total Iteration Time: 4.92837

Cumulative Model Updates: 97,036
Cumulative Timesteps: 809,170,192

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,072.37167
Policy Entropy: 3.71084
Value Function Loss: 0.03395

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.14656
Policy Update Magnitude: 0.55247
Value Function Update Magnitude: 0.60993

Collected Steps per Second: 20,890.44040
Overall Steps per Second: 10,146.29942

Timestep Collection Time: 2.39382
Timestep Consumption Time: 2.53487
PPO Batch Consumption Time: 0.29367
Total Iteration Time: 4.92869

Cumulative Model Updates: 97,042
Cumulative Timesteps: 809,220,200

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 809220200...
Checkpoint 809220200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,072.37167
Policy Entropy: 3.69310
Value Function Loss: 0.03126

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.10069
Policy Update Magnitude: 0.62509
Value Function Update Magnitude: 0.51655

Collected Steps per Second: 20,904.04476
Overall Steps per Second: 10,094.22868

Timestep Collection Time: 2.39226
Timestep Consumption Time: 2.56185
PPO Batch Consumption Time: 0.29637
Total Iteration Time: 4.95412

Cumulative Model Updates: 97,048
Cumulative Timesteps: 809,270,208

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,072.37167
Policy Entropy: 3.69598
Value Function Loss: 0.02936

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.13375
Policy Update Magnitude: 0.56366
Value Function Update Magnitude: 0.44799

Collected Steps per Second: 21,024.04927
Overall Steps per Second: 10,097.01570

Timestep Collection Time: 2.37880
Timestep Consumption Time: 2.57435
PPO Batch Consumption Time: 0.29653
Total Iteration Time: 4.95315

Cumulative Model Updates: 97,054
Cumulative Timesteps: 809,320,220

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 809320220...
Checkpoint 809320220 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,072.37167
Policy Entropy: 3.69804
Value Function Loss: 0.02848

Mean KL Divergence: 0.01163
SB3 Clip Fraction: 0.14851
Policy Update Magnitude: 0.48967
Value Function Update Magnitude: 0.41121

Collected Steps per Second: 20,976.29497
Overall Steps per Second: 10,050.80838

Timestep Collection Time: 2.38393
Timestep Consumption Time: 2.59139
PPO Batch Consumption Time: 0.30208
Total Iteration Time: 4.97532

Cumulative Model Updates: 97,060
Cumulative Timesteps: 809,370,226

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,437.89308
Policy Entropy: 3.69144
Value Function Loss: 0.02951

Mean KL Divergence: 0.01796
SB3 Clip Fraction: 0.21066
Policy Update Magnitude: 0.44554
Value Function Update Magnitude: 0.47094

Collected Steps per Second: 21,425.58676
Overall Steps per Second: 10,236.74504

Timestep Collection Time: 2.33431
Timestep Consumption Time: 2.55142
PPO Batch Consumption Time: 0.29199
Total Iteration Time: 4.88573

Cumulative Model Updates: 97,066
Cumulative Timesteps: 809,420,240

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 809420240...
Checkpoint 809420240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40,437.89308
Policy Entropy: 3.68883
Value Function Loss: 0.03064

Mean KL Divergence: 0.01621
SB3 Clip Fraction: 0.20785
Policy Update Magnitude: 0.40894
Value Function Update Magnitude: 0.46020

Collected Steps per Second: 20,182.65973
Overall Steps per Second: 9,823.10151

Timestep Collection Time: 2.47886
Timestep Consumption Time: 2.61424
PPO Batch Consumption Time: 0.30330
Total Iteration Time: 5.09310

Cumulative Model Updates: 97,072
Cumulative Timesteps: 809,470,270

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 157,653.51859
Policy Entropy: 3.67913
Value Function Loss: 0.03251

Mean KL Divergence: 0.01393
SB3 Clip Fraction: 0.17625
Policy Update Magnitude: 0.38312
Value Function Update Magnitude: 0.50656

Collected Steps per Second: 20,548.23351
Overall Steps per Second: 9,422.59676

Timestep Collection Time: 2.43515
Timestep Consumption Time: 2.87528
PPO Batch Consumption Time: 0.33097
Total Iteration Time: 5.31043

Cumulative Model Updates: 97,078
Cumulative Timesteps: 809,520,308

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 809520308...
Checkpoint 809520308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 223,783.06891
Policy Entropy: 3.65178
Value Function Loss: 0.03819

Mean KL Divergence: 0.01322
SB3 Clip Fraction: 0.15957
Policy Update Magnitude: 0.43316
Value Function Update Magnitude: 0.47584

Collected Steps per Second: 21,275.83633
Overall Steps per Second: 10,277.93901

Timestep Collection Time: 2.35065
Timestep Consumption Time: 2.51531
PPO Batch Consumption Time: 0.30088
Total Iteration Time: 4.86596

Cumulative Model Updates: 97,084
Cumulative Timesteps: 809,570,320

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 181,265.61641
Policy Entropy: 3.63561
Value Function Loss: 0.04573

Mean KL Divergence: 0.01117
SB3 Clip Fraction: 0.14320
Policy Update Magnitude: 0.49956
Value Function Update Magnitude: 0.49636

Collected Steps per Second: 19,141.89717
Overall Steps per Second: 9,445.83081

Timestep Collection Time: 2.61322
Timestep Consumption Time: 2.68245
PPO Batch Consumption Time: 0.31533
Total Iteration Time: 5.29567

Cumulative Model Updates: 97,090
Cumulative Timesteps: 809,620,342

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 809620342...
Checkpoint 809620342 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 181,265.61641
Policy Entropy: 3.62096
Value Function Loss: 0.05672

Mean KL Divergence: 0.01627
SB3 Clip Fraction: 0.18554
Policy Update Magnitude: 0.57708
Value Function Update Magnitude: 0.52700

Collected Steps per Second: 20,177.39824
Overall Steps per Second: 9,883.92877

Timestep Collection Time: 2.47812
Timestep Consumption Time: 2.58080
PPO Batch Consumption Time: 0.29539
Total Iteration Time: 5.05892

Cumulative Model Updates: 97,096
Cumulative Timesteps: 809,670,344

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 215,180.90444
Policy Entropy: 3.62705
Value Function Loss: 0.06030

Mean KL Divergence: 0.01937
SB3 Clip Fraction: 0.21206
Policy Update Magnitude: 0.62592
Value Function Update Magnitude: 0.62160

Collected Steps per Second: 19,161.12691
Overall Steps per Second: 9,669.04512

Timestep Collection Time: 2.61070
Timestep Consumption Time: 2.56292
PPO Batch Consumption Time: 0.30543
Total Iteration Time: 5.17362

Cumulative Model Updates: 97,102
Cumulative Timesteps: 809,720,368

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 809720368...
Checkpoint 809720368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 294,429.98327
Policy Entropy: 3.64413
Value Function Loss: 0.06376

Mean KL Divergence: 0.01462
SB3 Clip Fraction: 0.17056
Policy Update Magnitude: 0.70113
Value Function Update Magnitude: 0.55494

Collected Steps per Second: 18,519.71544
Overall Steps per Second: 9,461.94839

Timestep Collection Time: 2.69983
Timestep Consumption Time: 2.58450
PPO Batch Consumption Time: 0.31288
Total Iteration Time: 5.28432

Cumulative Model Updates: 97,108
Cumulative Timesteps: 809,770,368

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 213,134.82957
Policy Entropy: 3.65891
Value Function Loss: 0.05984

Mean KL Divergence: 0.01126
SB3 Clip Fraction: 0.13418
Policy Update Magnitude: 0.78023
Value Function Update Magnitude: 0.47464

Collected Steps per Second: 19,916.05452
Overall Steps per Second: 9,815.44961

Timestep Collection Time: 2.51094
Timestep Consumption Time: 2.58389
PPO Batch Consumption Time: 0.30691
Total Iteration Time: 5.09483

Cumulative Model Updates: 97,114
Cumulative Timesteps: 809,820,376

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 809820376...
Checkpoint 809820376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 79,564.42299
Policy Entropy: 3.68984
Value Function Loss: 0.05620

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.10259
Policy Update Magnitude: 0.92501
Value Function Update Magnitude: 0.45384

Collected Steps per Second: 19,883.01443
Overall Steps per Second: 9,878.74622

Timestep Collection Time: 2.51501
Timestep Consumption Time: 2.54697
PPO Batch Consumption Time: 0.29538
Total Iteration Time: 5.06198

Cumulative Model Updates: 97,120
Cumulative Timesteps: 809,870,382

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,815.45682
Policy Entropy: 3.68853
Value Function Loss: 0.05748

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.12169
Policy Update Magnitude: 0.97777
Value Function Update Magnitude: 0.49296

Collected Steps per Second: 20,220.81329
Overall Steps per Second: 9,877.25108

Timestep Collection Time: 2.47329
Timestep Consumption Time: 2.59006
PPO Batch Consumption Time: 0.30688
Total Iteration Time: 5.06335

Cumulative Model Updates: 97,126
Cumulative Timesteps: 809,920,394

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 809920394...
Checkpoint 809920394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,049.25398
Policy Entropy: 3.69231
Value Function Loss: 0.06853

Mean KL Divergence: 0.01124
SB3 Clip Fraction: 0.14750
Policy Update Magnitude: 0.83451
Value Function Update Magnitude: 0.56857

Collected Steps per Second: 19,713.59202
Overall Steps per Second: 9,781.40647

Timestep Collection Time: 2.53703
Timestep Consumption Time: 2.57614
PPO Batch Consumption Time: 0.30537
Total Iteration Time: 5.11317

Cumulative Model Updates: 97,132
Cumulative Timesteps: 809,970,408

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 272,213.67095
Policy Entropy: 3.68341
Value Function Loss: 0.05373

Mean KL Divergence: 0.01110
SB3 Clip Fraction: 0.14876
Policy Update Magnitude: 0.69226
Value Function Update Magnitude: 0.50842

Collected Steps per Second: 20,963.78143
Overall Steps per Second: 10,040.00039

Timestep Collection Time: 2.38545
Timestep Consumption Time: 2.59543
PPO Batch Consumption Time: 0.30614
Total Iteration Time: 4.98088

Cumulative Model Updates: 97,138
Cumulative Timesteps: 810,020,416

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 810020416...
Checkpoint 810020416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 88,816.02681
Policy Entropy: 3.66923
Value Function Loss: 0.04875

Mean KL Divergence: 0.01123
SB3 Clip Fraction: 0.15157
Policy Update Magnitude: 0.58734
Value Function Update Magnitude: 0.57910

Collected Steps per Second: 20,847.63888
Overall Steps per Second: 10,077.67391

Timestep Collection Time: 2.39855
Timestep Consumption Time: 2.56331
PPO Batch Consumption Time: 0.29444
Total Iteration Time: 4.96186

Cumulative Model Updates: 97,144
Cumulative Timesteps: 810,070,420

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,813.87970
Policy Entropy: 3.67109
Value Function Loss: 0.04045

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.14158
Policy Update Magnitude: 0.53086
Value Function Update Magnitude: 0.76983

Collected Steps per Second: 21,502.29759
Overall Steps per Second: 10,105.99287

Timestep Collection Time: 2.32533
Timestep Consumption Time: 2.62223
PPO Batch Consumption Time: 0.30666
Total Iteration Time: 4.94756

Cumulative Model Updates: 97,150
Cumulative Timesteps: 810,120,420

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 810120420...
Checkpoint 810120420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 180,018.95009
Policy Entropy: 3.66745
Value Function Loss: 0.04005

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.14162
Policy Update Magnitude: 0.48339
Value Function Update Magnitude: 0.74059

Collected Steps per Second: 20,611.84245
Overall Steps per Second: 9,953.14296

Timestep Collection Time: 2.42598
Timestep Consumption Time: 2.59796
PPO Batch Consumption Time: 0.30161
Total Iteration Time: 5.02394

Cumulative Model Updates: 97,156
Cumulative Timesteps: 810,170,424

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60,163.18893
Policy Entropy: 3.67987
Value Function Loss: 0.03745

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.14229
Policy Update Magnitude: 0.48708
Value Function Update Magnitude: 0.83860

Collected Steps per Second: 21,045.72636
Overall Steps per Second: 10,074.77462

Timestep Collection Time: 2.37654
Timestep Consumption Time: 2.58794
PPO Batch Consumption Time: 0.30133
Total Iteration Time: 4.96448

Cumulative Model Updates: 97,162
Cumulative Timesteps: 810,220,440

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 810220440...
Checkpoint 810220440 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,472.56223
Policy Entropy: 3.67301
Value Function Loss: 0.04344

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.13576
Policy Update Magnitude: 0.48625
Value Function Update Magnitude: 0.69850

Collected Steps per Second: 20,919.54015
Overall Steps per Second: 10,024.23354

Timestep Collection Time: 2.39231
Timestep Consumption Time: 2.60019
PPO Batch Consumption Time: 0.30178
Total Iteration Time: 4.99250

Cumulative Model Updates: 97,168
Cumulative Timesteps: 810,270,486

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,164.52270
Policy Entropy: 3.67475
Value Function Loss: 0.04491

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.13974
Policy Update Magnitude: 0.49485
Value Function Update Magnitude: 0.60799

Collected Steps per Second: 21,056.07105
Overall Steps per Second: 10,026.09426

Timestep Collection Time: 2.37613
Timestep Consumption Time: 2.61405
PPO Batch Consumption Time: 0.30399
Total Iteration Time: 4.99018

Cumulative Model Updates: 97,174
Cumulative Timesteps: 810,320,518

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 810320518...
Checkpoint 810320518 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,451.88230
Policy Entropy: 3.68494
Value Function Loss: 0.04341

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.14293
Policy Update Magnitude: 0.49033
Value Function Update Magnitude: 0.59446

Collected Steps per Second: 20,498.41080
Overall Steps per Second: 9,912.89247

Timestep Collection Time: 2.44009
Timestep Consumption Time: 2.60566
PPO Batch Consumption Time: 0.30570
Total Iteration Time: 5.04575

Cumulative Model Updates: 97,180
Cumulative Timesteps: 810,370,536

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,077.94964
Policy Entropy: 3.70020
Value Function Loss: 0.04042

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.14273
Policy Update Magnitude: 0.45986
Value Function Update Magnitude: 0.57934

Collected Steps per Second: 20,724.31519
Overall Steps per Second: 9,960.03263

Timestep Collection Time: 2.41349
Timestep Consumption Time: 2.60838
PPO Batch Consumption Time: 0.30013
Total Iteration Time: 5.02187

Cumulative Model Updates: 97,186
Cumulative Timesteps: 810,420,554

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 810420554...
Checkpoint 810420554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 704.27784
Policy Entropy: 3.68649
Value Function Loss: 0.03645

Mean KL Divergence: 0.01086
SB3 Clip Fraction: 0.14980
Policy Update Magnitude: 0.43604
Value Function Update Magnitude: 0.52318

Collected Steps per Second: 19,885.79597
Overall Steps per Second: 9,742.90856

Timestep Collection Time: 2.51627
Timestep Consumption Time: 2.61957
PPO Batch Consumption Time: 0.30073
Total Iteration Time: 5.13584

Cumulative Model Updates: 97,192
Cumulative Timesteps: 810,470,592

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 704.27784
Policy Entropy: 3.66483
Value Function Loss: 0.03285

Mean KL Divergence: 0.01050
SB3 Clip Fraction: 0.14771
Policy Update Magnitude: 0.40775
Value Function Update Magnitude: 0.42380

Collected Steps per Second: 19,365.04613
Overall Steps per Second: 9,685.32656

Timestep Collection Time: 2.58414
Timestep Consumption Time: 2.58264
PPO Batch Consumption Time: 0.30208
Total Iteration Time: 5.16679

Cumulative Model Updates: 97,198
Cumulative Timesteps: 810,520,634

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 810520634...
Checkpoint 810520634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,217.78752
Policy Entropy: 3.65887
Value Function Loss: 0.03467

Mean KL Divergence: 0.01053
SB3 Clip Fraction: 0.14935
Policy Update Magnitude: 0.37968
Value Function Update Magnitude: 0.36944

Collected Steps per Second: 19,061.54005
Overall Steps per Second: 9,721.26353

Timestep Collection Time: 2.62392
Timestep Consumption Time: 2.52109
PPO Batch Consumption Time: 0.29649
Total Iteration Time: 5.14501

Cumulative Model Updates: 97,204
Cumulative Timesteps: 810,570,650

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,627.47574
Policy Entropy: 3.65198
Value Function Loss: 0.03648

Mean KL Divergence: 0.01080
SB3 Clip Fraction: 0.15194
Policy Update Magnitude: 0.38388
Value Function Update Magnitude: 0.35816

Collected Steps per Second: 19,927.60447
Overall Steps per Second: 9,788.46760

Timestep Collection Time: 2.51159
Timestep Consumption Time: 2.60157
PPO Batch Consumption Time: 0.30717
Total Iteration Time: 5.11316

Cumulative Model Updates: 97,210
Cumulative Timesteps: 810,620,700

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 810620700...
Checkpoint 810620700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 282,664.91531
Policy Entropy: 3.66417
Value Function Loss: 0.03584

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.14541
Policy Update Magnitude: 0.39592
Value Function Update Magnitude: 0.41032

Collected Steps per Second: 19,877.59020
Overall Steps per Second: 9,816.40827

Timestep Collection Time: 2.51570
Timestep Consumption Time: 2.57843
PPO Batch Consumption Time: 0.30055
Total Iteration Time: 5.09412

Cumulative Model Updates: 97,216
Cumulative Timesteps: 810,670,706

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 185,459.64070
Policy Entropy: 3.65514
Value Function Loss: 0.03412

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.14560
Policy Update Magnitude: 0.41623
Value Function Update Magnitude: 0.46461

Collected Steps per Second: 20,758.70292
Overall Steps per Second: 10,037.27175

Timestep Collection Time: 2.41027
Timestep Consumption Time: 2.57455
PPO Batch Consumption Time: 0.30064
Total Iteration Time: 4.98482

Cumulative Model Updates: 97,222
Cumulative Timesteps: 810,720,740

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 810720740...
Checkpoint 810720740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 180,072.58583
Policy Entropy: 3.66533
Value Function Loss: 0.03340

Mean KL Divergence: 0.01055
SB3 Clip Fraction: 0.14763
Policy Update Magnitude: 0.40965
Value Function Update Magnitude: 0.52897

Collected Steps per Second: 20,354.67038
Overall Steps per Second: 9,833.24032

Timestep Collection Time: 2.45713
Timestep Consumption Time: 2.62909
PPO Batch Consumption Time: 0.30621
Total Iteration Time: 5.08622

Cumulative Model Updates: 97,228
Cumulative Timesteps: 810,770,754

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 118,155.98745
Policy Entropy: 3.65838
Value Function Loss: 0.03531

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.14931
Policy Update Magnitude: 0.39850
Value Function Update Magnitude: 0.55402

Collected Steps per Second: 20,636.62822
Overall Steps per Second: 9,965.50870

Timestep Collection Time: 2.42336
Timestep Consumption Time: 2.59495
PPO Batch Consumption Time: 0.29923
Total Iteration Time: 5.01831

Cumulative Model Updates: 97,234
Cumulative Timesteps: 810,820,764

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 810820764...
Checkpoint 810820764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 118,155.98745
Policy Entropy: 3.66439
Value Function Loss: 0.03384

Mean KL Divergence: 0.01124
SB3 Clip Fraction: 0.15745
Policy Update Magnitude: 0.38338
Value Function Update Magnitude: 0.49747

Collected Steps per Second: 20,708.50726
Overall Steps per Second: 9,886.83935

Timestep Collection Time: 2.41466
Timestep Consumption Time: 2.64297
PPO Batch Consumption Time: 0.30625
Total Iteration Time: 5.05763

Cumulative Model Updates: 97,240
Cumulative Timesteps: 810,870,768

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 118,155.98745
Policy Entropy: 3.63577
Value Function Loss: 0.03787

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.14766
Policy Update Magnitude: 0.37961
Value Function Update Magnitude: 0.44973

Collected Steps per Second: 20,676.13337
Overall Steps per Second: 9,951.70898

Timestep Collection Time: 2.41883
Timestep Consumption Time: 2.60664
PPO Batch Consumption Time: 0.29557
Total Iteration Time: 5.02547

Cumulative Model Updates: 97,246
Cumulative Timesteps: 810,920,780

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 810920780...
Checkpoint 810920780 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 118,155.98745
Policy Entropy: 3.64744
Value Function Loss: 0.03354

Mean KL Divergence: 0.01080
SB3 Clip Fraction: 0.14897
Policy Update Magnitude: 0.41005
Value Function Update Magnitude: 0.38818

Collected Steps per Second: 21,156.59104
Overall Steps per Second: 10,019.32522

Timestep Collection Time: 2.36446
Timestep Consumption Time: 2.62829
PPO Batch Consumption Time: 0.30125
Total Iteration Time: 4.99275

Cumulative Model Updates: 97,252
Cumulative Timesteps: 810,970,804

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 118,155.98745
Policy Entropy: 3.64023
Value Function Loss: 0.03395

Mean KL Divergence: 0.01080
SB3 Clip Fraction: 0.15203
Policy Update Magnitude: 0.39835
Value Function Update Magnitude: 0.37541

Collected Steps per Second: 21,282.34827
Overall Steps per Second: 10,158.21773

Timestep Collection Time: 2.35049
Timestep Consumption Time: 2.57399
PPO Batch Consumption Time: 0.29362
Total Iteration Time: 4.92449

Cumulative Model Updates: 97,258
Cumulative Timesteps: 811,020,828

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 811020828...
Checkpoint 811020828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 118,155.98745
Policy Entropy: 3.66764
Value Function Loss: 0.02639

Mean KL Divergence: 0.01083
SB3 Clip Fraction: 0.15602
Policy Update Magnitude: 0.35478
Value Function Update Magnitude: 0.33110

Collected Steps per Second: 20,419.14143
Overall Steps per Second: 10,032.06382

Timestep Collection Time: 2.44976
Timestep Consumption Time: 2.53645
PPO Batch Consumption Time: 0.30427
Total Iteration Time: 4.98621

Cumulative Model Updates: 97,264
Cumulative Timesteps: 811,070,850

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 118,155.98745
Policy Entropy: 3.65058
Value Function Loss: 0.02840

Mean KL Divergence: 0.01131
SB3 Clip Fraction: 0.16014
Policy Update Magnitude: 0.31152
Value Function Update Magnitude: 0.35068

Collected Steps per Second: 18,932.36069
Overall Steps per Second: 9,821.79862

Timestep Collection Time: 2.64140
Timestep Consumption Time: 2.45013
PPO Batch Consumption Time: 0.29899
Total Iteration Time: 5.09153

Cumulative Model Updates: 97,270
Cumulative Timesteps: 811,120,858

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 811120858...
Checkpoint 811120858 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 118,155.98745
Policy Entropy: 3.67406
Value Function Loss: 0.02546

Mean KL Divergence: 0.01050
SB3 Clip Fraction: 0.14978
Policy Update Magnitude: 0.30112
Value Function Update Magnitude: 0.38666

Collected Steps per Second: 20,151.84035
Overall Steps per Second: 9,923.09886

Timestep Collection Time: 2.48166
Timestep Consumption Time: 2.55810
PPO Batch Consumption Time: 0.29836
Total Iteration Time: 5.03976

Cumulative Model Updates: 97,276
Cumulative Timesteps: 811,170,868

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 118,155.98745
Policy Entropy: 3.65992
Value Function Loss: 0.02977

Mean KL Divergence: 0.01096
SB3 Clip Fraction: 0.15245
Policy Update Magnitude: 0.29882
Value Function Update Magnitude: 0.35697

Collected Steps per Second: 20,709.30358
Overall Steps per Second: 10,074.10704

Timestep Collection Time: 2.41553
Timestep Consumption Time: 2.55007
PPO Batch Consumption Time: 0.29554
Total Iteration Time: 4.96560

Cumulative Model Updates: 97,282
Cumulative Timesteps: 811,220,892

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 811220892...
Checkpoint 811220892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 118,155.98745
Policy Entropy: 3.66323
Value Function Loss: 0.02667

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.14480
Policy Update Magnitude: 0.30857
Value Function Update Magnitude: 0.34111

Collected Steps per Second: 20,740.32593
Overall Steps per Second: 10,138.47350

Timestep Collection Time: 2.41076
Timestep Consumption Time: 2.52095
PPO Batch Consumption Time: 0.29087
Total Iteration Time: 4.93171

Cumulative Model Updates: 97,288
Cumulative Timesteps: 811,270,892

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 284,535.61623
Policy Entropy: 3.64881
Value Function Loss: 0.03025

Mean KL Divergence: 0.01104
SB3 Clip Fraction: 0.15371
Policy Update Magnitude: 0.34679
Value Function Update Magnitude: 0.36990

Collected Steps per Second: 21,010.07134
Overall Steps per Second: 10,112.89034

Timestep Collection Time: 2.38048
Timestep Consumption Time: 2.56509
PPO Batch Consumption Time: 0.29444
Total Iteration Time: 4.94557

Cumulative Model Updates: 97,294
Cumulative Timesteps: 811,320,906

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 811320906...
Checkpoint 811320906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 122,491.58548
Policy Entropy: 3.66325
Value Function Loss: 0.02913

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.14121
Policy Update Magnitude: 0.36645
Value Function Update Magnitude: 0.44164

Collected Steps per Second: 20,880.01927
Overall Steps per Second: 10,117.87973

Timestep Collection Time: 2.39597
Timestep Consumption Time: 2.54854
PPO Batch Consumption Time: 0.29181
Total Iteration Time: 4.94451

Cumulative Model Updates: 97,300
Cumulative Timesteps: 811,370,934

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99,220.33174
Policy Entropy: 3.67182
Value Function Loss: 0.02930

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.14123
Policy Update Magnitude: 0.36992
Value Function Update Magnitude: 0.48666

Collected Steps per Second: 21,186.49092
Overall Steps per Second: 10,007.93705

Timestep Collection Time: 2.36132
Timestep Consumption Time: 2.63752
PPO Batch Consumption Time: 0.30677
Total Iteration Time: 4.99883

Cumulative Model Updates: 97,306
Cumulative Timesteps: 811,420,962

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 811420962...
Checkpoint 811420962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 155,784.33289
Policy Entropy: 3.66805
Value Function Loss: 0.02926

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.14097
Policy Update Magnitude: 0.36184
Value Function Update Magnitude: 0.45698

Collected Steps per Second: 20,135.85827
Overall Steps per Second: 9,783.28142

Timestep Collection Time: 2.48393
Timestep Consumption Time: 2.62847
PPO Batch Consumption Time: 0.29787
Total Iteration Time: 5.11240

Cumulative Model Updates: 97,312
Cumulative Timesteps: 811,470,978

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 276,361.29692
Policy Entropy: 3.65148
Value Function Loss: 0.03280

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.14268
Policy Update Magnitude: 0.37325
Value Function Update Magnitude: 0.51096

Collected Steps per Second: 19,496.37116
Overall Steps per Second: 9,732.43489

Timestep Collection Time: 2.56591
Timestep Consumption Time: 2.57422
PPO Batch Consumption Time: 0.29614
Total Iteration Time: 5.14013

Cumulative Model Updates: 97,318
Cumulative Timesteps: 811,521,004

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 811521004...
Checkpoint 811521004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 327,424.45036
Policy Entropy: 3.64701
Value Function Loss: 0.03394

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.14604
Policy Update Magnitude: 0.39439
Value Function Update Magnitude: 0.47563

Collected Steps per Second: 20,808.29217
Overall Steps per Second: 9,914.77405

Timestep Collection Time: 2.40404
Timestep Consumption Time: 2.64136
PPO Batch Consumption Time: 0.31049
Total Iteration Time: 5.04540

Cumulative Model Updates: 97,324
Cumulative Timesteps: 811,571,028

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 174,018.37332
Policy Entropy: 3.64155
Value Function Loss: 0.03490

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.14206
Policy Update Magnitude: 0.40874
Value Function Update Magnitude: 0.45560

Collected Steps per Second: 20,174.04846
Overall Steps per Second: 9,846.21757

Timestep Collection Time: 2.47913
Timestep Consumption Time: 2.60039
PPO Batch Consumption Time: 0.30135
Total Iteration Time: 5.07951

Cumulative Model Updates: 97,330
Cumulative Timesteps: 811,621,042

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 811621042...
Checkpoint 811621042 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 174,018.37332
Policy Entropy: 3.64543
Value Function Loss: 0.03071

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.14597
Policy Update Magnitude: 0.41690
Value Function Update Magnitude: 0.42844

Collected Steps per Second: 19,351.53999
Overall Steps per Second: 9,814.07077

Timestep Collection Time: 2.58419
Timestep Consumption Time: 2.51135
PPO Batch Consumption Time: 0.29699
Total Iteration Time: 5.09554

Cumulative Model Updates: 97,336
Cumulative Timesteps: 811,671,050

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 266,899.32766
Policy Entropy: 3.65813
Value Function Loss: 0.02954

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.14401
Policy Update Magnitude: 0.39891
Value Function Update Magnitude: 0.41134

Collected Steps per Second: 18,476.29359
Overall Steps per Second: 9,561.61048

Timestep Collection Time: 2.70834
Timestep Consumption Time: 2.52509
PPO Batch Consumption Time: 0.30196
Total Iteration Time: 5.23343

Cumulative Model Updates: 97,342
Cumulative Timesteps: 811,721,090

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 811721090...
Checkpoint 811721090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 266,899.32766
Policy Entropy: 3.67700
Value Function Loss: 0.02498

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.14393
Policy Update Magnitude: 0.37174
Value Function Update Magnitude: 0.38424

Collected Steps per Second: 19,635.85268
Overall Steps per Second: 9,676.36318

Timestep Collection Time: 2.54738
Timestep Consumption Time: 2.62192
PPO Batch Consumption Time: 0.30940
Total Iteration Time: 5.16930

Cumulative Model Updates: 97,348
Cumulative Timesteps: 811,771,110

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 266,899.32766
Policy Entropy: 3.67763
Value Function Loss: 0.02269

Mean KL Divergence: 0.01083
SB3 Clip Fraction: 0.15489
Policy Update Magnitude: 0.35662
Value Function Update Magnitude: 0.39623

Collected Steps per Second: 20,164.43682
Overall Steps per Second: 9,859.41957

Timestep Collection Time: 2.47971
Timestep Consumption Time: 2.59178
PPO Batch Consumption Time: 0.30438
Total Iteration Time: 5.07150

Cumulative Model Updates: 97,354
Cumulative Timesteps: 811,821,112

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 811821112...
Checkpoint 811821112 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 380,647.01799
Policy Entropy: 3.66250
Value Function Loss: 0.02310

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.14761
Policy Update Magnitude: 0.36773
Value Function Update Magnitude: 0.46825

Collected Steps per Second: 20,342.61547
Overall Steps per Second: 9,968.87878

Timestep Collection Time: 2.45996
Timestep Consumption Time: 2.55986
PPO Batch Consumption Time: 0.30939
Total Iteration Time: 5.01982

Cumulative Model Updates: 97,360
Cumulative Timesteps: 811,871,154

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 308,327.74844
Policy Entropy: 3.65011
Value Function Loss: 0.02511

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.14847
Policy Update Magnitude: 0.38328
Value Function Update Magnitude: 0.51259

Collected Steps per Second: 19,149.49532
Overall Steps per Second: 9,623.90719

Timestep Collection Time: 2.61187
Timestep Consumption Time: 2.58519
PPO Batch Consumption Time: 0.29569
Total Iteration Time: 5.19706

Cumulative Model Updates: 97,366
Cumulative Timesteps: 811,921,170

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 811921170...
Checkpoint 811921170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 308,327.74844
Policy Entropy: 3.63871
Value Function Loss: 0.02646

Mean KL Divergence: 0.01089
SB3 Clip Fraction: 0.15620
Policy Update Magnitude: 0.38024
Value Function Update Magnitude: 0.54522

Collected Steps per Second: 20,366.58883
Overall Steps per Second: 9,909.37768

Timestep Collection Time: 2.45657
Timestep Consumption Time: 2.59238
PPO Batch Consumption Time: 0.29636
Total Iteration Time: 5.04895

Cumulative Model Updates: 97,372
Cumulative Timesteps: 811,971,202

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 308,327.74844
Policy Entropy: 3.65058
Value Function Loss: 0.02681

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.14670
Policy Update Magnitude: 0.37448
Value Function Update Magnitude: 0.47001

Collected Steps per Second: 20,226.44432
Overall Steps per Second: 9,713.63721

Timestep Collection Time: 2.47330
Timestep Consumption Time: 2.67678
PPO Batch Consumption Time: 0.31055
Total Iteration Time: 5.15008

Cumulative Model Updates: 97,378
Cumulative Timesteps: 812,021,228

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 812021228...
Checkpoint 812021228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 308,327.74844
Policy Entropy: 3.66046
Value Function Loss: 0.02389

Mean KL Divergence: 0.01109
SB3 Clip Fraction: 0.15477
Policy Update Magnitude: 0.38388
Value Function Update Magnitude: 0.45634

Collected Steps per Second: 20,057.77087
Overall Steps per Second: 9,685.44723

Timestep Collection Time: 2.49330
Timestep Consumption Time: 2.67012
PPO Batch Consumption Time: 0.31057
Total Iteration Time: 5.16342

Cumulative Model Updates: 97,384
Cumulative Timesteps: 812,071,238

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 308,327.74844
Policy Entropy: 3.66964
Value Function Loss: 0.02392

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.14359
Policy Update Magnitude: 0.38201
Value Function Update Magnitude: 0.50928

Collected Steps per Second: 20,414.00873
Overall Steps per Second: 9,700.66567

Timestep Collection Time: 2.45018
Timestep Consumption Time: 2.70596
PPO Batch Consumption Time: 0.31977
Total Iteration Time: 5.15614

Cumulative Model Updates: 97,390
Cumulative Timesteps: 812,121,256

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 812121256...
Checkpoint 812121256 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 737,856.84824
Policy Entropy: 3.66650
Value Function Loss: 0.02614

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.14507
Policy Update Magnitude: 0.39975
Value Function Update Magnitude: 0.51759

Collected Steps per Second: 19,276.29106
Overall Steps per Second: 9,599.77603

Timestep Collection Time: 2.59427
Timestep Consumption Time: 2.61501
PPO Batch Consumption Time: 0.30436
Total Iteration Time: 5.20929

Cumulative Model Updates: 97,396
Cumulative Timesteps: 812,171,264

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 434,096.40450
Policy Entropy: 3.66746
Value Function Loss: 0.03127

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.14224
Policy Update Magnitude: 0.43204
Value Function Update Magnitude: 0.57418

Collected Steps per Second: 19,978.23649
Overall Steps per Second: 9,925.70504

Timestep Collection Time: 2.50382
Timestep Consumption Time: 2.53582
PPO Batch Consumption Time: 0.29806
Total Iteration Time: 5.03964

Cumulative Model Updates: 97,402
Cumulative Timesteps: 812,221,286

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 812221286...
Checkpoint 812221286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 186,895.14546
Policy Entropy: 3.66048
Value Function Loss: 0.03556

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.14093
Policy Update Magnitude: 0.44983
Value Function Update Magnitude: 0.56322

Collected Steps per Second: 19,992.75106
Overall Steps per Second: 10,008.98455

Timestep Collection Time: 2.50161
Timestep Consumption Time: 2.49530
PPO Batch Consumption Time: 0.29913
Total Iteration Time: 4.99691

Cumulative Model Updates: 97,408
Cumulative Timesteps: 812,271,300

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 186,895.14546
Policy Entropy: 3.65362
Value Function Loss: 0.03580

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.14673
Policy Update Magnitude: 0.47145
Value Function Update Magnitude: 0.54417

Collected Steps per Second: 20,703.25995
Overall Steps per Second: 10,024.43077

Timestep Collection Time: 2.41518
Timestep Consumption Time: 2.57284
PPO Batch Consumption Time: 0.30050
Total Iteration Time: 4.98801

Cumulative Model Updates: 97,414
Cumulative Timesteps: 812,321,302

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 812321302...
Checkpoint 812321302 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 186,895.14546
Policy Entropy: 3.63754
Value Function Loss: 0.03457

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.14724
Policy Update Magnitude: 0.47440
Value Function Update Magnitude: 0.50190

Collected Steps per Second: 20,919.95417
Overall Steps per Second: 10,081.82892

Timestep Collection Time: 2.39016
Timestep Consumption Time: 2.56946
PPO Batch Consumption Time: 0.30289
Total Iteration Time: 4.95962

Cumulative Model Updates: 97,420
Cumulative Timesteps: 812,371,304

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 186,895.14546
Policy Entropy: 3.64615
Value Function Loss: 0.03015

Mean KL Divergence: 0.01058
SB3 Clip Fraction: 0.14871
Policy Update Magnitude: 0.47244
Value Function Update Magnitude: 0.48778

Collected Steps per Second: 21,212.80881
Overall Steps per Second: 10,101.05927

Timestep Collection Time: 2.35735
Timestep Consumption Time: 2.59322
PPO Batch Consumption Time: 0.30346
Total Iteration Time: 4.95057

Cumulative Model Updates: 97,426
Cumulative Timesteps: 812,421,310

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 812421310...
Checkpoint 812421310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 186,895.14546
Policy Entropy: 3.65042
Value Function Loss: 0.02704

Mean KL Divergence: 0.01065
SB3 Clip Fraction: 0.14945
Policy Update Magnitude: 0.42941
Value Function Update Magnitude: 0.53328

Collected Steps per Second: 21,268.03694
Overall Steps per Second: 10,103.82978

Timestep Collection Time: 2.35095
Timestep Consumption Time: 2.59767
PPO Batch Consumption Time: 0.30118
Total Iteration Time: 4.94862

Cumulative Model Updates: 97,432
Cumulative Timesteps: 812,471,310

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 186,895.14546
Policy Entropy: 3.64482
Value Function Loss: 0.02627

Mean KL Divergence: 0.01066
SB3 Clip Fraction: 0.15012
Policy Update Magnitude: 0.40354
Value Function Update Magnitude: 0.55075

Collected Steps per Second: 21,436.27500
Overall Steps per Second: 10,130.26375

Timestep Collection Time: 2.33333
Timestep Consumption Time: 2.60415
PPO Batch Consumption Time: 0.30350
Total Iteration Time: 4.93748

Cumulative Model Updates: 97,438
Cumulative Timesteps: 812,521,328

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 812521328...
Checkpoint 812521328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 322,023.25747
Policy Entropy: 3.64639
Value Function Loss: 0.02727

Mean KL Divergence: 0.01076
SB3 Clip Fraction: 0.15309
Policy Update Magnitude: 0.41246
Value Function Update Magnitude: 0.46638

Collected Steps per Second: 21,013.23516
Overall Steps per Second: 10,106.43089

Timestep Collection Time: 2.38050
Timestep Consumption Time: 2.56902
PPO Batch Consumption Time: 0.29591
Total Iteration Time: 4.94952

Cumulative Model Updates: 97,444
Cumulative Timesteps: 812,571,350

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 171,149.99128
Policy Entropy: 3.65240
Value Function Loss: 0.02816

Mean KL Divergence: 0.01138
SB3 Clip Fraction: 0.15672
Policy Update Magnitude: 0.44065
Value Function Update Magnitude: 0.64359

Collected Steps per Second: 20,809.03615
Overall Steps per Second: 9,995.45252

Timestep Collection Time: 2.40357
Timestep Consumption Time: 2.60030
PPO Batch Consumption Time: 0.29961
Total Iteration Time: 5.00388

Cumulative Model Updates: 97,450
Cumulative Timesteps: 812,621,366

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 812621366...
Checkpoint 812621366 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 171,149.99128
Policy Entropy: 3.66538
Value Function Loss: 0.02868

Mean KL Divergence: 0.01111
SB3 Clip Fraction: 0.15557
Policy Update Magnitude: 0.44474
Value Function Update Magnitude: 0.51835

Collected Steps per Second: 20,909.82620
Overall Steps per Second: 10,137.13960

Timestep Collection Time: 2.39189
Timestep Consumption Time: 2.54185
PPO Batch Consumption Time: 0.29215
Total Iteration Time: 4.93374

Cumulative Model Updates: 97,456
Cumulative Timesteps: 812,671,380

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 171,149.99128
Policy Entropy: 3.66351
Value Function Loss: 0.02888

Mean KL Divergence: 0.01154
SB3 Clip Fraction: 0.16075
Policy Update Magnitude: 0.41851
Value Function Update Magnitude: 0.44852

Collected Steps per Second: 21,253.88944
Overall Steps per Second: 10,176.93658

Timestep Collection Time: 2.35449
Timestep Consumption Time: 2.56271
PPO Batch Consumption Time: 0.29395
Total Iteration Time: 4.91720

Cumulative Model Updates: 97,462
Cumulative Timesteps: 812,721,422

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 812721422...
Checkpoint 812721422 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 171,149.99128
Policy Entropy: 3.66531
Value Function Loss: 0.02765

Mean KL Divergence: 0.01114
SB3 Clip Fraction: 0.15572
Policy Update Magnitude: 0.40027
Value Function Update Magnitude: 0.40625

Collected Steps per Second: 21,011.49809
Overall Steps per Second: 10,174.54364

Timestep Collection Time: 2.38003
Timestep Consumption Time: 2.53498
PPO Batch Consumption Time: 0.29300
Total Iteration Time: 4.91501

Cumulative Model Updates: 97,468
Cumulative Timesteps: 812,771,430

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 171,149.99128
Policy Entropy: 3.64930
Value Function Loss: 0.02740

Mean KL Divergence: 0.01189
SB3 Clip Fraction: 0.16096
Policy Update Magnitude: 0.41522
Value Function Update Magnitude: 0.39898

Collected Steps per Second: 20,900.00375
Overall Steps per Second: 10,070.02433

Timestep Collection Time: 2.39340
Timestep Consumption Time: 2.57402
PPO Batch Consumption Time: 0.29699
Total Iteration Time: 4.96742

Cumulative Model Updates: 97,474
Cumulative Timesteps: 812,821,452

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 812821452...
Checkpoint 812821452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 193,182.61660
Policy Entropy: 3.66330
Value Function Loss: 0.02836

Mean KL Divergence: 0.01102
SB3 Clip Fraction: 0.15233
Policy Update Magnitude: 0.42618
Value Function Update Magnitude: 0.38757

Collected Steps per Second: 21,118.41295
Overall Steps per Second: 10,224.73507

Timestep Collection Time: 2.36864
Timestep Consumption Time: 2.52361
PPO Batch Consumption Time: 0.29107
Total Iteration Time: 4.89225

Cumulative Model Updates: 97,480
Cumulative Timesteps: 812,871,474

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67,376.71566
Policy Entropy: 3.65959
Value Function Loss: 0.02928

Mean KL Divergence: 0.01118
SB3 Clip Fraction: 0.15397
Policy Update Magnitude: 0.39918
Value Function Update Magnitude: 0.42039

Collected Steps per Second: 21,046.79869
Overall Steps per Second: 10,041.38786

Timestep Collection Time: 2.37708
Timestep Consumption Time: 2.60530
PPO Batch Consumption Time: 0.30408
Total Iteration Time: 4.98238

Cumulative Model Updates: 97,486
Cumulative Timesteps: 812,921,504

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 812921504...
Checkpoint 812921504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 67,376.71566
Policy Entropy: 3.66929
Value Function Loss: 0.02854

Mean KL Divergence: 0.01145
SB3 Clip Fraction: 0.15504
Policy Update Magnitude: 0.43765
Value Function Update Magnitude: 0.46731

Collected Steps per Second: 20,385.89146
Overall Steps per Second: 10,193.68573

Timestep Collection Time: 2.45474
Timestep Consumption Time: 2.45438
PPO Batch Consumption Time: 0.29182
Total Iteration Time: 4.90912

Cumulative Model Updates: 97,492
Cumulative Timesteps: 812,971,546

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 253,206.87629
Policy Entropy: 3.65963
Value Function Loss: 0.03117

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.14920
Policy Update Magnitude: 0.45974
Value Function Update Magnitude: 0.55190

Collected Steps per Second: 20,407.80517
Overall Steps per Second: 10,036.01080

Timestep Collection Time: 2.45063
Timestep Consumption Time: 2.53262
PPO Batch Consumption Time: 0.30500
Total Iteration Time: 4.98325

Cumulative Model Updates: 97,498
Cumulative Timesteps: 813,021,558

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 813021558...
Checkpoint 813021558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 88,310.40068
Policy Entropy: 3.66018
Value Function Loss: 0.03140

Mean KL Divergence: 0.01102
SB3 Clip Fraction: 0.14713
Policy Update Magnitude: 0.51150
Value Function Update Magnitude: 0.75825

Collected Steps per Second: 20,419.12397
Overall Steps per Second: 10,185.88393

Timestep Collection Time: 2.44957
Timestep Consumption Time: 2.46095
PPO Batch Consumption Time: 0.29192
Total Iteration Time: 4.91052

Cumulative Model Updates: 97,504
Cumulative Timesteps: 813,071,576

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 71,533.91426
Policy Entropy: 3.64754
Value Function Loss: 0.03394

Mean KL Divergence: 0.01459
SB3 Clip Fraction: 0.16947
Policy Update Magnitude: 0.65820
Value Function Update Magnitude: 0.70688

Collected Steps per Second: 20,261.79962
Overall Steps per Second: 10,004.11442

Timestep Collection Time: 2.46918
Timestep Consumption Time: 2.53176
PPO Batch Consumption Time: 0.29263
Total Iteration Time: 5.00094

Cumulative Model Updates: 97,510
Cumulative Timesteps: 813,121,606

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 813121606...
Checkpoint 813121606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 71,533.91426
Policy Entropy: 3.68470
Value Function Loss: 0.03588

Mean KL Divergence: 0.02560
SB3 Clip Fraction: 0.25427
Policy Update Magnitude: 0.62022
Value Function Update Magnitude: 0.53130

Collected Steps per Second: 21,019.25699
Overall Steps per Second: 9,412.03080

Timestep Collection Time: 2.37887
Timestep Consumption Time: 2.93370
PPO Batch Consumption Time: 0.36224
Total Iteration Time: 5.31256

Cumulative Model Updates: 97,516
Cumulative Timesteps: 813,171,608

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 71,533.91426
Policy Entropy: 3.72019
Value Function Loss: 0.03378

Mean KL Divergence: 0.01842
SB3 Clip Fraction: 0.22318
Policy Update Magnitude: 0.53228
Value Function Update Magnitude: 0.38882

Collected Steps per Second: 19,161.21680
Overall Steps per Second: 9,777.39043

Timestep Collection Time: 2.60954
Timestep Consumption Time: 2.50450
PPO Batch Consumption Time: 0.28829
Total Iteration Time: 5.11404

Cumulative Model Updates: 97,522
Cumulative Timesteps: 813,221,610

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 813221610...
Checkpoint 813221610 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 71,533.91426
Policy Entropy: 3.72595
Value Function Loss: 0.03790

Mean KL Divergence: 0.01648
SB3 Clip Fraction: 0.19986
Policy Update Magnitude: 0.44193
Value Function Update Magnitude: 0.30750

Collected Steps per Second: 21,051.26900
Overall Steps per Second: 10,231.25847

Timestep Collection Time: 2.37629
Timestep Consumption Time: 2.51304
PPO Batch Consumption Time: 0.28834
Total Iteration Time: 4.88933

Cumulative Model Updates: 97,528
Cumulative Timesteps: 813,271,634

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 206,777.77859
Policy Entropy: 3.69614
Value Function Loss: 0.03312

Mean KL Divergence: 0.01109
SB3 Clip Fraction: 0.14889
Policy Update Magnitude: 0.45938
Value Function Update Magnitude: 0.45886

Collected Steps per Second: 21,136.13908
Overall Steps per Second: 10,092.84123

Timestep Collection Time: 2.36704
Timestep Consumption Time: 2.58994
PPO Batch Consumption Time: 0.30217
Total Iteration Time: 4.95698

Cumulative Model Updates: 97,534
Cumulative Timesteps: 813,321,664

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 813321664...
Checkpoint 813321664 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 110,531.24681
Policy Entropy: 3.68498
Value Function Loss: 0.03721

Mean KL Divergence: 0.01260
SB3 Clip Fraction: 0.16746
Policy Update Magnitude: 0.52114
Value Function Update Magnitude: 0.55046

Collected Steps per Second: 21,366.74500
Overall Steps per Second: 10,154.10174

Timestep Collection Time: 2.34214
Timestep Consumption Time: 2.58631
PPO Batch Consumption Time: 0.30037
Total Iteration Time: 4.92845

Cumulative Model Updates: 97,540
Cumulative Timesteps: 813,371,708

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,702.31929
Policy Entropy: 3.68734
Value Function Loss: 0.03687

Mean KL Divergence: 0.01143
SB3 Clip Fraction: 0.15297
Policy Update Magnitude: 0.54240
Value Function Update Magnitude: 0.81546

Collected Steps per Second: 21,757.18108
Overall Steps per Second: 10,378.83300

Timestep Collection Time: 2.29993
Timestep Consumption Time: 2.52142
PPO Batch Consumption Time: 0.28880
Total Iteration Time: 4.82135

Cumulative Model Updates: 97,546
Cumulative Timesteps: 813,421,748

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 813421748...
Checkpoint 813421748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 381,651.89839
Policy Entropy: 3.68721
Value Function Loss: 0.03617

Mean KL Divergence: 0.01138
SB3 Clip Fraction: 0.15169
Policy Update Magnitude: 0.61332
Value Function Update Magnitude: 0.92601

Collected Steps per Second: 21,614.59606
Overall Steps per Second: 10,297.38650

Timestep Collection Time: 2.31371
Timestep Consumption Time: 2.54286
PPO Batch Consumption Time: 0.29143
Total Iteration Time: 4.85657

Cumulative Model Updates: 97,552
Cumulative Timesteps: 813,471,758

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 381,651.89839
Policy Entropy: 3.67144
Value Function Loss: 0.03940

Mean KL Divergence: 0.01201
SB3 Clip Fraction: 0.15781
Policy Update Magnitude: 0.62108
Value Function Update Magnitude: 0.80878

Collected Steps per Second: 20,609.11494
Overall Steps per Second: 10,177.15991

Timestep Collection Time: 2.42660
Timestep Consumption Time: 2.48735
PPO Batch Consumption Time: 0.29804
Total Iteration Time: 4.91394

Cumulative Model Updates: 97,558
Cumulative Timesteps: 813,521,768

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 813521768...
Checkpoint 813521768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 353,927.56427
Policy Entropy: 3.66298
Value Function Loss: 0.04122

Mean KL Divergence: 0.01065
SB3 Clip Fraction: 0.14455
Policy Update Magnitude: 0.60316
Value Function Update Magnitude: 0.70063

Collected Steps per Second: 20,845.75306
Overall Steps per Second: 10,272.48548

Timestep Collection Time: 2.39857
Timestep Consumption Time: 2.46880
PPO Batch Consumption Time: 0.29543
Total Iteration Time: 4.86737

Cumulative Model Updates: 97,564
Cumulative Timesteps: 813,571,768

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 238,974.20136
Policy Entropy: 3.65463
Value Function Loss: 0.03800

Mean KL Divergence: 0.01152
SB3 Clip Fraction: 0.15495
Policy Update Magnitude: 0.58552
Value Function Update Magnitude: 0.61925

Collected Steps per Second: 20,807.24182
Overall Steps per Second: 10,243.77830

Timestep Collection Time: 2.40532
Timestep Consumption Time: 2.48038
PPO Batch Consumption Time: 0.29594
Total Iteration Time: 4.88570

Cumulative Model Updates: 97,570
Cumulative Timesteps: 813,621,816

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 813621816...
Checkpoint 813621816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 489,578.71220
Policy Entropy: 3.67264
Value Function Loss: 0.03743

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.14580
Policy Update Magnitude: 0.52902
Value Function Update Magnitude: 0.54701

Collected Steps per Second: 20,842.34788
Overall Steps per Second: 10,215.49490

Timestep Collection Time: 2.39983
Timestep Consumption Time: 2.49646
PPO Batch Consumption Time: 0.28806
Total Iteration Time: 4.89629

Cumulative Model Updates: 97,576
Cumulative Timesteps: 813,671,834

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 444,798.99187
Policy Entropy: 3.66824
Value Function Loss: 0.03618

Mean KL Divergence: 0.01055
SB3 Clip Fraction: 0.14684
Policy Update Magnitude: 0.48028
Value Function Update Magnitude: 0.53526

Collected Steps per Second: 21,220.38377
Overall Steps per Second: 10,223.04481

Timestep Collection Time: 2.35707
Timestep Consumption Time: 2.53560
PPO Batch Consumption Time: 0.29708
Total Iteration Time: 4.89267

Cumulative Model Updates: 97,582
Cumulative Timesteps: 813,721,852

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 813721852...
Checkpoint 813721852 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 352,605.69982
Policy Entropy: 3.65611
Value Function Loss: 0.03662

Mean KL Divergence: 0.01069
SB3 Clip Fraction: 0.14473
Policy Update Magnitude: 0.50509
Value Function Update Magnitude: 0.57772

Collected Steps per Second: 21,536.65182
Overall Steps per Second: 10,357.17679

Timestep Collection Time: 2.32200
Timestep Consumption Time: 2.50635
PPO Batch Consumption Time: 0.28885
Total Iteration Time: 4.82834

Cumulative Model Updates: 97,588
Cumulative Timesteps: 813,771,860

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 172,179.65944
Policy Entropy: 3.65782
Value Function Loss: 0.03964

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.13989
Policy Update Magnitude: 0.53246
Value Function Update Magnitude: 0.63436

Collected Steps per Second: 21,284.98354
Overall Steps per Second: 10,119.58358

Timestep Collection Time: 2.34992
Timestep Consumption Time: 2.59277
PPO Batch Consumption Time: 0.30290
Total Iteration Time: 4.94269

Cumulative Model Updates: 97,594
Cumulative Timesteps: 813,821,878

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 813821878...
Checkpoint 813821878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 758,953.13979
Policy Entropy: 3.66356
Value Function Loss: 0.03923

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.14848
Policy Update Magnitude: 0.60948
Value Function Update Magnitude: 0.65652

Collected Steps per Second: 21,093.34366
Overall Steps per Second: 10,238.78200

Timestep Collection Time: 2.37080
Timestep Consumption Time: 2.51338
PPO Batch Consumption Time: 0.28695
Total Iteration Time: 4.88417

Cumulative Model Updates: 97,600
Cumulative Timesteps: 813,871,886

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 168,476.36668
Policy Entropy: 3.68449
Value Function Loss: 0.04078

Mean KL Divergence: 0.01080
SB3 Clip Fraction: 0.14834
Policy Update Magnitude: 0.61007
Value Function Update Magnitude: 0.60437

Collected Steps per Second: 21,237.62400
Overall Steps per Second: 10,159.08759

Timestep Collection Time: 2.35441
Timestep Consumption Time: 2.56749
PPO Batch Consumption Time: 0.29780
Total Iteration Time: 4.92190

Cumulative Model Updates: 97,606
Cumulative Timesteps: 813,921,888

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 813921888...
Checkpoint 813921888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 168,476.36668
Policy Entropy: 3.68075
Value Function Loss: 0.03863

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.14215
Policy Update Magnitude: 0.61047
Value Function Update Magnitude: 0.65939

Collected Steps per Second: 21,587.22925
Overall Steps per Second: 10,373.34718

Timestep Collection Time: 2.31730
Timestep Consumption Time: 2.50506
PPO Batch Consumption Time: 0.28797
Total Iteration Time: 4.82236

Cumulative Model Updates: 97,612
Cumulative Timesteps: 813,971,912

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 168,476.36668
Policy Entropy: 3.68421
Value Function Loss: 0.03767

Mean KL Divergence: 0.01070
SB3 Clip Fraction: 0.14790
Policy Update Magnitude: 0.58188
Value Function Update Magnitude: 0.67086

Collected Steps per Second: 21,230.66367
Overall Steps per Second: 10,139.65789

Timestep Collection Time: 2.35584
Timestep Consumption Time: 2.57687
PPO Batch Consumption Time: 0.29847
Total Iteration Time: 4.93271

Cumulative Model Updates: 97,618
Cumulative Timesteps: 814,021,928

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 814021928...
Checkpoint 814021928 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 168,476.36668
Policy Entropy: 3.66066
Value Function Loss: 0.04038

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.13519
Policy Update Magnitude: 0.53016
Value Function Update Magnitude: 0.53592

Collected Steps per Second: 21,118.53251
Overall Steps per Second: 10,188.39675

Timestep Collection Time: 2.36891
Timestep Consumption Time: 2.54138
PPO Batch Consumption Time: 0.29233
Total Iteration Time: 4.91029

Cumulative Model Updates: 97,624
Cumulative Timesteps: 814,071,956

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 168,476.36668
Policy Entropy: 3.66224
Value Function Loss: 0.03859

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.13434
Policy Update Magnitude: 0.54770
Value Function Update Magnitude: 0.46033

Collected Steps per Second: 21,173.44465
Overall Steps per Second: 10,148.66324

Timestep Collection Time: 2.36154
Timestep Consumption Time: 2.56541
PPO Batch Consumption Time: 0.30022
Total Iteration Time: 4.92695

Cumulative Model Updates: 97,630
Cumulative Timesteps: 814,121,958

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 814121958...
Checkpoint 814121958 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 168,476.36668
Policy Entropy: 3.63790
Value Function Loss: 0.04956

Mean KL Divergence: 0.01073
SB3 Clip Fraction: 0.14199
Policy Update Magnitude: 0.56393
Value Function Update Magnitude: 0.56611

Collected Steps per Second: 21,120.02617
Overall Steps per Second: 10,122.48068

Timestep Collection Time: 2.36771
Timestep Consumption Time: 2.57239
PPO Batch Consumption Time: 0.29989
Total Iteration Time: 4.94009

Cumulative Model Updates: 97,636
Cumulative Timesteps: 814,171,964

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 193,756.77829
Policy Entropy: 3.66316
Value Function Loss: 0.04573

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.13570
Policy Update Magnitude: 0.60814
Value Function Update Magnitude: 0.59118

Collected Steps per Second: 21,439.61709
Overall Steps per Second: 10,327.64556

Timestep Collection Time: 2.33278
Timestep Consumption Time: 2.50995
PPO Batch Consumption Time: 0.28821
Total Iteration Time: 4.84273

Cumulative Model Updates: 97,642
Cumulative Timesteps: 814,221,978

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 814221978...
Checkpoint 814221978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 193,756.77829
Policy Entropy: 3.65680
Value Function Loss: 0.05153

Mean KL Divergence: 0.01115
SB3 Clip Fraction: 0.15067
Policy Update Magnitude: 0.59423
Value Function Update Magnitude: 0.56317

Collected Steps per Second: 21,593.26698
Overall Steps per Second: 10,354.54286

Timestep Collection Time: 2.31554
Timestep Consumption Time: 2.51326
PPO Batch Consumption Time: 0.28693
Total Iteration Time: 4.82880

Cumulative Model Updates: 97,648
Cumulative Timesteps: 814,271,978

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 118,970.61525
Policy Entropy: 3.67721
Value Function Loss: 0.04879

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.14067
Policy Update Magnitude: 0.53934
Value Function Update Magnitude: 0.47867

Collected Steps per Second: 21,763.79733
Overall Steps per Second: 10,370.45505

Timestep Collection Time: 2.29739
Timestep Consumption Time: 2.52400
PPO Batch Consumption Time: 0.28894
Total Iteration Time: 4.82139

Cumulative Model Updates: 97,654
Cumulative Timesteps: 814,321,978

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 814321978...
Checkpoint 814321978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 63,252.59809
Policy Entropy: 3.67212
Value Function Loss: 0.04305

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.14823
Policy Update Magnitude: 0.54532
Value Function Update Magnitude: 0.48777

Collected Steps per Second: 21,423.37261
Overall Steps per Second: 10,253.18322

Timestep Collection Time: 2.33446
Timestep Consumption Time: 2.54324
PPO Batch Consumption Time: 0.29355
Total Iteration Time: 4.87770

Cumulative Model Updates: 97,660
Cumulative Timesteps: 814,371,990

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63,252.59809
Policy Entropy: 3.69772
Value Function Loss: 0.03181

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.14034
Policy Update Magnitude: 0.51230
Value Function Update Magnitude: 0.57854

Collected Steps per Second: 21,519.25789
Overall Steps per Second: 10,351.94416

Timestep Collection Time: 2.32443
Timestep Consumption Time: 2.50751
PPO Batch Consumption Time: 0.28867
Total Iteration Time: 4.83194

Cumulative Model Updates: 97,666
Cumulative Timesteps: 814,422,010

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 814422010...
Checkpoint 814422010 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 63,252.59809
Policy Entropy: 3.69508
Value Function Loss: 0.02858

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.14329
Policy Update Magnitude: 0.47340
Value Function Update Magnitude: 0.59774

Collected Steps per Second: 20,675.25842
Overall Steps per Second: 10,059.38629

Timestep Collection Time: 2.41961
Timestep Consumption Time: 2.55346
PPO Batch Consumption Time: 0.30328
Total Iteration Time: 4.97307

Cumulative Model Updates: 97,672
Cumulative Timesteps: 814,472,036

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 798,376.84597
Policy Entropy: 3.67644
Value Function Loss: 0.03498

Mean KL Divergence: 0.01109
SB3 Clip Fraction: 0.14830
Policy Update Magnitude: 0.50002
Value Function Update Magnitude: 0.66037

Collected Steps per Second: 20,799.14031
Overall Steps per Second: 10,315.34327

Timestep Collection Time: 2.40625
Timestep Consumption Time: 2.44555
PPO Batch Consumption Time: 0.29150
Total Iteration Time: 4.85180

Cumulative Model Updates: 97,678
Cumulative Timesteps: 814,522,084

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 814522084...
Checkpoint 814522084 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 194,323.63923
Policy Entropy: 3.69992
Value Function Loss: 0.04172

Mean KL Divergence: 0.01060
SB3 Clip Fraction: 0.13978
Policy Update Magnitude: 0.54834
Value Function Update Magnitude: 0.70303

Collected Steps per Second: 20,842.01212
Overall Steps per Second: 10,199.77098

Timestep Collection Time: 2.39929
Timestep Consumption Time: 2.50337
PPO Batch Consumption Time: 0.30102
Total Iteration Time: 4.90266

Cumulative Model Updates: 97,684
Cumulative Timesteps: 814,572,090

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,683.12110
Policy Entropy: 3.72364
Value Function Loss: 0.04147

Mean KL Divergence: 0.01091
SB3 Clip Fraction: 0.14382
Policy Update Magnitude: 0.58310
Value Function Update Magnitude: 0.70431

Collected Steps per Second: 21,016.55603
Overall Steps per Second: 10,373.56641

Timestep Collection Time: 2.37974
Timestep Consumption Time: 2.44155
PPO Batch Consumption Time: 0.28947
Total Iteration Time: 4.82129

Cumulative Model Updates: 97,690
Cumulative Timesteps: 814,622,104

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 814622104...
Checkpoint 814622104 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,181.96173
Policy Entropy: 3.72968
Value Function Loss: 0.03612

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.14499
Policy Update Magnitude: 0.54674
Value Function Update Magnitude: 0.68413

Collected Steps per Second: 20,722.76711
Overall Steps per Second: 10,199.73859

Timestep Collection Time: 2.41290
Timestep Consumption Time: 2.48938
PPO Batch Consumption Time: 0.28934
Total Iteration Time: 4.90228

Cumulative Model Updates: 97,696
Cumulative Timesteps: 814,672,106

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,181.96173
Policy Entropy: 3.69294
Value Function Loss: 0.03172

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.14404
Policy Update Magnitude: 0.49091
Value Function Update Magnitude: 0.62490

Collected Steps per Second: 21,567.15368
Overall Steps per Second: 10,320.02259

Timestep Collection Time: 2.31992
Timestep Consumption Time: 2.52833
PPO Batch Consumption Time: 0.29542
Total Iteration Time: 4.84825

Cumulative Model Updates: 97,702
Cumulative Timesteps: 814,722,140

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 814722140...
Checkpoint 814722140 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,198.93234
Policy Entropy: 3.66513
Value Function Loss: 0.03477

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.15050
Policy Update Magnitude: 0.47725
Value Function Update Magnitude: 0.58392

Collected Steps per Second: 21,522.27360
Overall Steps per Second: 10,415.65979

Timestep Collection Time: 2.32410
Timestep Consumption Time: 2.47828
PPO Batch Consumption Time: 0.28818
Total Iteration Time: 4.80238

Cumulative Model Updates: 97,708
Cumulative Timesteps: 814,772,160

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,731.50784
Policy Entropy: 3.67565
Value Function Loss: 0.03763

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.14395
Policy Update Magnitude: 0.47246
Value Function Update Magnitude: 0.46620

Collected Steps per Second: 21,778.96618
Overall Steps per Second: 10,378.13948

Timestep Collection Time: 2.29699
Timestep Consumption Time: 2.52334
PPO Batch Consumption Time: 0.28899
Total Iteration Time: 4.82032

Cumulative Model Updates: 97,714
Cumulative Timesteps: 814,822,186

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 814822186...
Checkpoint 814822186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,615.09452
Policy Entropy: 3.68239
Value Function Loss: 0.03412

Mean KL Divergence: 0.01053
SB3 Clip Fraction: 0.14612
Policy Update Magnitude: 0.44421
Value Function Update Magnitude: 0.41982

Collected Steps per Second: 21,389.36933
Overall Steps per Second: 10,334.39638

Timestep Collection Time: 2.33911
Timestep Consumption Time: 2.50220
PPO Batch Consumption Time: 0.28681
Total Iteration Time: 4.84131

Cumulative Model Updates: 97,720
Cumulative Timesteps: 814,872,218

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,615.09452
Policy Entropy: 3.66291
Value Function Loss: 0.03276

Mean KL Divergence: 0.01055
SB3 Clip Fraction: 0.14620
Policy Update Magnitude: 0.46772
Value Function Update Magnitude: 0.45653

Collected Steps per Second: 21,498.93268
Overall Steps per Second: 10,348.52931

Timestep Collection Time: 2.32653
Timestep Consumption Time: 2.50681
PPO Batch Consumption Time: 0.28848
Total Iteration Time: 4.83334

Cumulative Model Updates: 97,726
Cumulative Timesteps: 814,922,236

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 814922236...
Checkpoint 814922236 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,615.09452
Policy Entropy: 3.66084
Value Function Loss: 0.03115

Mean KL Divergence: 0.01112
SB3 Clip Fraction: 0.15363
Policy Update Magnitude: 0.47247
Value Function Update Magnitude: 0.59926

Collected Steps per Second: 21,307.94472
Overall Steps per Second: 10,321.92217

Timestep Collection Time: 2.34654
Timestep Consumption Time: 2.49752
PPO Batch Consumption Time: 0.28669
Total Iteration Time: 4.84406

Cumulative Model Updates: 97,732
Cumulative Timesteps: 814,972,236

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 113,050.37904
Policy Entropy: 3.65555
Value Function Loss: 0.03341

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.14319
Policy Update Magnitude: 0.49397
Value Function Update Magnitude: 0.70489

Collected Steps per Second: 21,120.37041
Overall Steps per Second: 10,113.49127

Timestep Collection Time: 2.36984
Timestep Consumption Time: 2.57919
PPO Batch Consumption Time: 0.30008
Total Iteration Time: 4.94903

Cumulative Model Updates: 97,738
Cumulative Timesteps: 815,022,288

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


Saving checkpoint 815022288...
Checkpoint 815022288 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 139,451.08744
Policy Entropy: 3.65863
Value Function Loss: 0.03620

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.14282
Policy Update Magnitude: 0.56024
Value Function Update Magnitude: 0.69547

Collected Steps per Second: 21,202.14366
Overall Steps per Second: 9,948.73298

Timestep Collection Time: 2.35948
Timestep Consumption Time: 2.66890
PPO Batch Consumption Time: 0.31432
Total Iteration Time: 5.02838

Cumulative Model Updates: 97,744
Cumulative Timesteps: 815,072,314

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 112,953.77038
Policy Entropy: 3.65942
Value Function Loss: 0.04005

Mean KL Divergence: 0.01124
SB3 Clip Fraction: 0.15292
Policy Update Magnitude: 0.55654
Value Function Update Magnitude: 0.65503

Collected Steps per Second: 21,797.40124
Overall Steps per Second: 10,167.72600

Timestep Collection Time: 2.29431
Timestep Consumption Time: 2.62419
PPO Batch Consumption Time: 0.30665
Total Iteration Time: 4.91850

Cumulative Model Updates: 97,750
Cumulative Timesteps: 815,122,324

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 815122324...
Checkpoint 815122324 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 205,340.53910
Policy Entropy: 3.65883
Value Function Loss: 0.03792

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.14856
Policy Update Magnitude: 0.53191
Value Function Update Magnitude: 0.65578

Collected Steps per Second: 21,125.62433
Overall Steps per Second: 10,226.25309

Timestep Collection Time: 2.36698
Timestep Consumption Time: 2.52278
PPO Batch Consumption Time: 0.28903
Total Iteration Time: 4.88977

Cumulative Model Updates: 97,756
Cumulative Timesteps: 815,172,328

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 166,330.30405
Policy Entropy: 3.66130
Value Function Loss: 0.03548

Mean KL Divergence: 0.01098
SB3 Clip Fraction: 0.14887
Policy Update Magnitude: 0.51806
Value Function Update Magnitude: 0.67468

Collected Steps per Second: 21,074.84313
Overall Steps per Second: 10,365.94798

Timestep Collection Time: 2.37269
Timestep Consumption Time: 2.45118
PPO Batch Consumption Time: 0.28895
Total Iteration Time: 4.82387

Cumulative Model Updates: 97,762
Cumulative Timesteps: 815,222,332

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 815222332...
Checkpoint 815222332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 166,330.30405
Policy Entropy: 3.65583
Value Function Loss: 0.03067

Mean KL Divergence: 0.01121
SB3 Clip Fraction: 0.14997
Policy Update Magnitude: 0.48637
Value Function Update Magnitude: 0.59381

Collected Steps per Second: 21,028.32416
Overall Steps per Second: 10,315.10128

Timestep Collection Time: 2.37822
Timestep Consumption Time: 2.47001
PPO Batch Consumption Time: 0.29449
Total Iteration Time: 4.84823

Cumulative Model Updates: 97,768
Cumulative Timesteps: 815,272,342

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 263,111.58750
Policy Entropy: 3.65830
Value Function Loss: 0.03022

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.14613
Policy Update Magnitude: 0.46570
Value Function Update Magnitude: 0.56263

Collected Steps per Second: 20,584.93423
Overall Steps per Second: 10,168.76123

Timestep Collection Time: 2.43032
Timestep Consumption Time: 2.48945
PPO Batch Consumption Time: 0.29852
Total Iteration Time: 4.91977

Cumulative Model Updates: 97,774
Cumulative Timesteps: 815,322,370

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 815322370...
Checkpoint 815322370 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 213,126.16886
Policy Entropy: 3.66375
Value Function Loss: 0.02998

Mean KL Divergence: 0.01065
SB3 Clip Fraction: 0.14456
Policy Update Magnitude: 0.45639
Value Function Update Magnitude: 0.63845

Collected Steps per Second: 20,833.62737
Overall Steps per Second: 10,088.78961

Timestep Collection Time: 2.40189
Timestep Consumption Time: 2.55807
PPO Batch Consumption Time: 0.30050
Total Iteration Time: 4.95996

Cumulative Model Updates: 97,780
Cumulative Timesteps: 815,372,410

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 213,126.16886
Policy Entropy: 3.66370
Value Function Loss: 0.03094

Mean KL Divergence: 0.01173
SB3 Clip Fraction: 0.15764
Policy Update Magnitude: 0.49270
Value Function Update Magnitude: 0.65354

Collected Steps per Second: 21,692.74174
Overall Steps per Second: 10,422.15696

Timestep Collection Time: 2.30547
Timestep Consumption Time: 2.49315
PPO Batch Consumption Time: 0.28944
Total Iteration Time: 4.79862

Cumulative Model Updates: 97,786
Cumulative Timesteps: 815,422,422

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 815422422...
Checkpoint 815422422 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 334,267.61530
Policy Entropy: 3.65656
Value Function Loss: 0.03584

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.14381
Policy Update Magnitude: 0.50390
Value Function Update Magnitude: 0.60239

Collected Steps per Second: 21,304.23285
Overall Steps per Second: 10,250.81441

Timestep Collection Time: 2.34798
Timestep Consumption Time: 2.53182
PPO Batch Consumption Time: 0.29127
Total Iteration Time: 4.87981

Cumulative Model Updates: 97,792
Cumulative Timesteps: 815,472,444

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 243,761.66936
Policy Entropy: 3.66599
Value Function Loss: 0.03459

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.14149
Policy Update Magnitude: 0.52776
Value Function Update Magnitude: 0.62565

Collected Steps per Second: 21,814.31090
Overall Steps per Second: 10,413.08297

Timestep Collection Time: 2.29272
Timestep Consumption Time: 2.51028
PPO Batch Consumption Time: 0.28870
Total Iteration Time: 4.80300

Cumulative Model Updates: 97,798
Cumulative Timesteps: 815,522,458

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 815522458...
Checkpoint 815522458 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 300,570.66889
Policy Entropy: 3.66500
Value Function Loss: 0.03600

Mean KL Divergence: 0.00733
SB3 Clip Fraction: 0.09404
Policy Update Magnitude: 0.68990
Value Function Update Magnitude: 0.79684

Collected Steps per Second: 21,325.71539
Overall Steps per Second: 10,274.18107

Timestep Collection Time: 2.34590
Timestep Consumption Time: 2.52339
PPO Batch Consumption Time: 0.29201
Total Iteration Time: 4.86929

Cumulative Model Updates: 97,804
Cumulative Timesteps: 815,572,486

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,982.74509
Policy Entropy: 3.67594
Value Function Loss: 0.03733

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.10766
Policy Update Magnitude: 0.80487
Value Function Update Magnitude: 0.77567

Collected Steps per Second: 21,352.83908
Overall Steps per Second: 10,154.94977

Timestep Collection Time: 2.34264
Timestep Consumption Time: 2.58323
PPO Batch Consumption Time: 0.29863
Total Iteration Time: 4.92587

Cumulative Model Updates: 97,810
Cumulative Timesteps: 815,622,508

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 815622508...
Checkpoint 815622508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,743.95547
Policy Entropy: 3.69629
Value Function Loss: 0.03477

Mean KL Divergence: 0.01973
SB3 Clip Fraction: 0.22354
Policy Update Magnitude: 0.69374
Value Function Update Magnitude: 0.62439

Collected Steps per Second: 21,377.23588
Overall Steps per Second: 10,190.43723

Timestep Collection Time: 2.33922
Timestep Consumption Time: 2.56793
PPO Batch Consumption Time: 0.29935
Total Iteration Time: 4.90715

Cumulative Model Updates: 97,816
Cumulative Timesteps: 815,672,514

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,261.28061
Policy Entropy: 3.71813
Value Function Loss: 0.02979

Mean KL Divergence: 0.01347
SB3 Clip Fraction: 0.17906
Policy Update Magnitude: 0.56142
Value Function Update Magnitude: 0.53799

Collected Steps per Second: 21,700.65249
Overall Steps per Second: 10,195.45114

Timestep Collection Time: 2.30454
Timestep Consumption Time: 2.60059
PPO Batch Consumption Time: 0.29811
Total Iteration Time: 4.90513

Cumulative Model Updates: 97,822
Cumulative Timesteps: 815,722,524

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 815722524...
Checkpoint 815722524 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,261.28061
Policy Entropy: 3.70550
Value Function Loss: 0.02628

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.14048
Policy Update Magnitude: 0.53739
Value Function Update Magnitude: 0.53741

Collected Steps per Second: 21,317.86523
Overall Steps per Second: 10,338.42133

Timestep Collection Time: 2.34592
Timestep Consumption Time: 2.49138
PPO Batch Consumption Time: 0.28799
Total Iteration Time: 4.83730

Cumulative Model Updates: 97,828
Cumulative Timesteps: 815,772,534

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,261.28061
Policy Entropy: 3.69499
Value Function Loss: 0.02507

Mean KL Divergence: 0.01706
SB3 Clip Fraction: 0.20194
Policy Update Magnitude: 0.55786
Value Function Update Magnitude: 0.61020

Collected Steps per Second: 21,870.17506
Overall Steps per Second: 10,395.85579

Timestep Collection Time: 2.28649
Timestep Consumption Time: 2.52369
PPO Batch Consumption Time: 0.28913
Total Iteration Time: 4.81019

Cumulative Model Updates: 97,834
Cumulative Timesteps: 815,822,540

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 815822540...
Checkpoint 815822540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,261.28061
Policy Entropy: 3.66410
Value Function Loss: 0.03287

Mean KL Divergence: 0.01282
SB3 Clip Fraction: 0.17478
Policy Update Magnitude: 0.47463
Value Function Update Magnitude: 0.57708

Collected Steps per Second: 20,848.73402
Overall Steps per Second: 10,186.54155

Timestep Collection Time: 2.39938
Timestep Consumption Time: 2.51141
PPO Batch Consumption Time: 0.28820
Total Iteration Time: 4.91079

Cumulative Model Updates: 97,840
Cumulative Timesteps: 815,872,564

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,261.28061
Policy Entropy: 3.66571
Value Function Loss: 0.03446

Mean KL Divergence: 0.01281
SB3 Clip Fraction: 0.16903
Policy Update Magnitude: 0.47508
Value Function Update Magnitude: 0.62124

Collected Steps per Second: 21,558.92164
Overall Steps per Second: 10,223.05996

Timestep Collection Time: 2.31941
Timestep Consumption Time: 2.57188
PPO Batch Consumption Time: 0.29939
Total Iteration Time: 4.89129

Cumulative Model Updates: 97,846
Cumulative Timesteps: 815,922,568

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 815922568...
Checkpoint 815922568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,261.28061
Policy Entropy: 3.64297
Value Function Loss: 0.05126

Mean KL Divergence: 0.01123
SB3 Clip Fraction: 0.14778
Policy Update Magnitude: 0.54522
Value Function Update Magnitude: 0.60728

Collected Steps per Second: 21,269.56343
Overall Steps per Second: 10,153.56599

Timestep Collection Time: 2.35115
Timestep Consumption Time: 2.57401
PPO Batch Consumption Time: 0.30184
Total Iteration Time: 4.92517

Cumulative Model Updates: 97,852
Cumulative Timesteps: 815,972,576

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,261.28061
Policy Entropy: 3.64829
Value Function Loss: 0.04805

Mean KL Divergence: 0.01142
SB3 Clip Fraction: 0.14806
Policy Update Magnitude: 0.64057
Value Function Update Magnitude: 0.49633

Collected Steps per Second: 21,497.77890
Overall Steps per Second: 10,323.25849

Timestep Collection Time: 2.32619
Timestep Consumption Time: 2.51801
PPO Batch Consumption Time: 0.28875
Total Iteration Time: 4.84421

Cumulative Model Updates: 97,858
Cumulative Timesteps: 816,022,584

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 816022584...
Checkpoint 816022584 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 344,783.50567
Policy Entropy: 3.65211
Value Function Loss: 0.06020

Mean KL Divergence: 0.01213
SB3 Clip Fraction: 0.16068
Policy Update Magnitude: 0.63421
Value Function Update Magnitude: 0.50122

Collected Steps per Second: 21,159.95967
Overall Steps per Second: 10,234.60896

Timestep Collection Time: 2.36418
Timestep Consumption Time: 2.52374
PPO Batch Consumption Time: 0.28957
Total Iteration Time: 4.88792

Cumulative Model Updates: 97,864
Cumulative Timesteps: 816,072,610

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 344,783.50567
Policy Entropy: 3.66913
Value Function Loss: 0.05901

Mean KL Divergence: 0.01218
SB3 Clip Fraction: 0.16270
Policy Update Magnitude: 0.56444
Value Function Update Magnitude: 0.47304

Collected Steps per Second: 20,705.83941
Overall Steps per Second: 10,187.19023

Timestep Collection Time: 2.41516
Timestep Consumption Time: 2.49375
PPO Batch Consumption Time: 0.29994
Total Iteration Time: 4.90891

Cumulative Model Updates: 97,870
Cumulative Timesteps: 816,122,618

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 816122618...
Checkpoint 816122618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 344,783.50567
Policy Entropy: 3.65977
Value Function Loss: 0.04684

Mean KL Divergence: 0.01244
SB3 Clip Fraction: 0.16383
Policy Update Magnitude: 0.54350
Value Function Update Magnitude: 0.50027

Collected Steps per Second: 20,738.30677
Overall Steps per Second: 10,202.19659

Timestep Collection Time: 2.41215
Timestep Consumption Time: 2.49110
PPO Batch Consumption Time: 0.30019
Total Iteration Time: 4.90326

Cumulative Model Updates: 97,876
Cumulative Timesteps: 816,172,642

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 344,783.50567
Policy Entropy: 3.65606
Value Function Loss: 0.03817

Mean KL Divergence: 0.01116
SB3 Clip Fraction: 0.15429
Policy Update Magnitude: 0.51408
Value Function Update Magnitude: 0.57330

Collected Steps per Second: 21,062.79988
Overall Steps per Second: 10,263.73667

Timestep Collection Time: 2.37518
Timestep Consumption Time: 2.49907
PPO Batch Consumption Time: 0.28889
Total Iteration Time: 4.87425

Cumulative Model Updates: 97,882
Cumulative Timesteps: 816,222,670

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 816222670...
Checkpoint 816222670 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,150,380.25099
Policy Entropy: 3.65861
Value Function Loss: 0.03782

Mean KL Divergence: 0.01077
SB3 Clip Fraction: 0.14960
Policy Update Magnitude: 0.47745
Value Function Update Magnitude: 0.60643

Collected Steps per Second: 21,554.87139
Overall Steps per Second: 10,302.90347

Timestep Collection Time: 2.32003
Timestep Consumption Time: 2.53374
PPO Batch Consumption Time: 0.29625
Total Iteration Time: 4.85378

Cumulative Model Updates: 97,888
Cumulative Timesteps: 816,272,678

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,017,806.24668
Policy Entropy: 3.66922
Value Function Loss: 0.03738

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.14935
Policy Update Magnitude: 0.46843
Value Function Update Magnitude: 0.64232

Collected Steps per Second: 21,002.63662
Overall Steps per Second: 10,141.74894

Timestep Collection Time: 2.38218
Timestep Consumption Time: 2.55109
PPO Batch Consumption Time: 0.30043
Total Iteration Time: 4.93327

Cumulative Model Updates: 97,894
Cumulative Timesteps: 816,322,710

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 816322710...
Checkpoint 816322710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 438,150.57757
Policy Entropy: 3.69198
Value Function Loss: 0.03154

Mean KL Divergence: 0.01053
SB3 Clip Fraction: 0.14627
Policy Update Magnitude: 0.48972
Value Function Update Magnitude: 0.72303

Collected Steps per Second: 21,125.43195
Overall Steps per Second: 10,139.50463

Timestep Collection Time: 2.36824
Timestep Consumption Time: 2.56593
PPO Batch Consumption Time: 0.30010
Total Iteration Time: 4.93417

Cumulative Model Updates: 97,900
Cumulative Timesteps: 816,372,740

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 438,150.57757
Policy Entropy: 3.68886
Value Function Loss: 0.02743

Mean KL Divergence: 0.01098
SB3 Clip Fraction: 0.15317
Policy Update Magnitude: 0.43830
Value Function Update Magnitude: 0.69598

Collected Steps per Second: 21,303.62460
Overall Steps per Second: 10,213.86831

Timestep Collection Time: 2.34824
Timestep Consumption Time: 2.54961
PPO Batch Consumption Time: 0.29582
Total Iteration Time: 4.89785

Cumulative Model Updates: 97,906
Cumulative Timesteps: 816,422,766

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 816422766...
Checkpoint 816422766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 438,150.57757
Policy Entropy: 3.67988
Value Function Loss: 0.02781

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.14620
Policy Update Magnitude: 0.37917
Value Function Update Magnitude: 0.57383

Collected Steps per Second: 21,583.43547
Overall Steps per Second: 10,361.42702

Timestep Collection Time: 2.31724
Timestep Consumption Time: 2.50970
PPO Batch Consumption Time: 0.28808
Total Iteration Time: 4.82694

Cumulative Model Updates: 97,912
Cumulative Timesteps: 816,472,780

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 387,983.98691
Policy Entropy: 3.65590
Value Function Loss: 0.02841

Mean KL Divergence: 0.01133
SB3 Clip Fraction: 0.15833
Policy Update Magnitude: 0.38873
Value Function Update Magnitude: 0.53165

Collected Steps per Second: 21,354.17516
Overall Steps per Second: 10,195.85777

Timestep Collection Time: 2.34165
Timestep Consumption Time: 2.56269
PPO Batch Consumption Time: 0.29954
Total Iteration Time: 4.90434

Cumulative Model Updates: 97,918
Cumulative Timesteps: 816,522,784

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 816522784...
Checkpoint 816522784 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 256,572.09257
Policy Entropy: 3.66241
Value Function Loss: 0.03335

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.14291
Policy Update Magnitude: 0.43029
Value Function Update Magnitude: 0.56067

Collected Steps per Second: 21,350.44510
Overall Steps per Second: 10,168.60594

Timestep Collection Time: 2.34281
Timestep Consumption Time: 2.57625
PPO Batch Consumption Time: 0.30094
Total Iteration Time: 4.91906

Cumulative Model Updates: 97,924
Cumulative Timesteps: 816,572,804

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 256,572.09257
Policy Entropy: 3.66893
Value Function Loss: 0.03286

Mean KL Divergence: 0.01122
SB3 Clip Fraction: 0.15697
Policy Update Magnitude: 0.47351
Value Function Update Magnitude: 0.65891

Collected Steps per Second: 21,347.66492
Overall Steps per Second: 10,298.32193

Timestep Collection Time: 2.34321
Timestep Consumption Time: 2.51409
PPO Batch Consumption Time: 0.28922
Total Iteration Time: 4.85730

Cumulative Model Updates: 97,930
Cumulative Timesteps: 816,622,826

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 816622826...
Checkpoint 816622826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 256,572.09257
Policy Entropy: 3.66109
Value Function Loss: 0.04209

Mean KL Divergence: 0.01153
SB3 Clip Fraction: 0.15905
Policy Update Magnitude: 0.46084
Value Function Update Magnitude: 0.53954

Collected Steps per Second: 21,424.33210
Overall Steps per Second: 10,335.86177

Timestep Collection Time: 2.33426
Timestep Consumption Time: 2.50423
PPO Batch Consumption Time: 0.28682
Total Iteration Time: 4.83849

Cumulative Model Updates: 97,936
Cumulative Timesteps: 816,672,836

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 256,572.09257
Policy Entropy: 3.66468
Value Function Loss: 0.03312

Mean KL Divergence: 0.01084
SB3 Clip Fraction: 0.15140
Policy Update Magnitude: 0.45820
Value Function Update Magnitude: 0.42419

Collected Steps per Second: 21,573.18144
Overall Steps per Second: 10,317.92408

Timestep Collection Time: 2.31936
Timestep Consumption Time: 2.53006
PPO Batch Consumption Time: 0.28952
Total Iteration Time: 4.84943

Cumulative Model Updates: 97,942
Cumulative Timesteps: 816,722,872

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 816722872...
Checkpoint 816722872 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 256,572.09257
Policy Entropy: 3.65161
Value Function Loss: 0.03138

Mean KL Divergence: 0.01137
SB3 Clip Fraction: 0.15706
Policy Update Magnitude: 0.43805
Value Function Update Magnitude: 0.47557

Collected Steps per Second: 21,505.31623
Overall Steps per Second: 10,353.78568

Timestep Collection Time: 2.32538
Timestep Consumption Time: 2.50455
PPO Batch Consumption Time: 0.28727
Total Iteration Time: 4.82992

Cumulative Model Updates: 97,948
Cumulative Timesteps: 816,772,880

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 256,572.09257
Policy Entropy: 3.66674
Value Function Loss: 0.02294

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.14678
Policy Update Magnitude: 0.38616
Value Function Update Magnitude: 0.38804

Collected Steps per Second: 21,342.22170
Overall Steps per Second: 10,156.92240

Timestep Collection Time: 2.34362
Timestep Consumption Time: 2.58091
PPO Batch Consumption Time: 0.29791
Total Iteration Time: 4.92452

Cumulative Model Updates: 97,954
Cumulative Timesteps: 816,822,898

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 816822898...
Checkpoint 816822898 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 256,572.09257
Policy Entropy: 3.65448
Value Function Loss: 0.02520

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.14916
Policy Update Magnitude: 0.37514
Value Function Update Magnitude: 0.38030

Collected Steps per Second: 21,194.37626
Overall Steps per Second: 10,148.86071

Timestep Collection Time: 2.35931
Timestep Consumption Time: 2.56775
PPO Batch Consumption Time: 0.29989
Total Iteration Time: 4.92706

Cumulative Model Updates: 97,960
Cumulative Timesteps: 816,872,902

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 189,158.81752
Policy Entropy: 3.66119
Value Function Loss: 0.02710

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.14491
Policy Update Magnitude: 0.39932
Value Function Update Magnitude: 0.52787

Collected Steps per Second: 21,979.15040
Overall Steps per Second: 10,371.05455

Timestep Collection Time: 2.27488
Timestep Consumption Time: 2.54623
PPO Batch Consumption Time: 0.29282
Total Iteration Time: 4.82111

Cumulative Model Updates: 97,966
Cumulative Timesteps: 816,922,902

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 816922902...
Checkpoint 816922902 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 266,825.86001
Policy Entropy: 3.66909
Value Function Loss: 0.02884

Mean KL Divergence: 0.01098
SB3 Clip Fraction: 0.15276
Policy Update Magnitude: 0.43924
Value Function Update Magnitude: 0.57038

Collected Steps per Second: 20,863.81411
Overall Steps per Second: 10,196.42964

Timestep Collection Time: 2.39803
Timestep Consumption Time: 2.50879
PPO Batch Consumption Time: 0.30062
Total Iteration Time: 4.90682

Cumulative Model Updates: 97,972
Cumulative Timesteps: 816,972,934

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93,051.16732
Policy Entropy: 3.67520
Value Function Loss: 0.02902

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.15062
Policy Update Magnitude: 0.44603
Value Function Update Magnitude: 0.61398

Collected Steps per Second: 20,580.33313
Overall Steps per Second: 10,022.54973

Timestep Collection Time: 2.43009
Timestep Consumption Time: 2.55986
PPO Batch Consumption Time: 0.31190
Total Iteration Time: 4.98995

Cumulative Model Updates: 97,978
Cumulative Timesteps: 817,022,946

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 817022946...
Checkpoint 817022946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 180,982.79008
Policy Entropy: 3.68744
Value Function Loss: 0.02813

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.14979
Policy Update Magnitude: 0.45431
Value Function Update Magnitude: 0.58883

Collected Steps per Second: 20,829.11399
Overall Steps per Second: 10,214.98746

Timestep Collection Time: 2.40164
Timestep Consumption Time: 2.49548
PPO Batch Consumption Time: 0.29793
Total Iteration Time: 4.89712

Cumulative Model Updates: 97,984
Cumulative Timesteps: 817,072,970

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 228,877.19102
Policy Entropy: 3.68363
Value Function Loss: 0.03328

Mean KL Divergence: 0.01070
SB3 Clip Fraction: 0.14979
Policy Update Magnitude: 0.48916
Value Function Update Magnitude: 0.56169

Collected Steps per Second: 20,926.90621
Overall Steps per Second: 10,093.76827

Timestep Collection Time: 2.38994
Timestep Consumption Time: 2.56500
PPO Batch Consumption Time: 0.30140
Total Iteration Time: 4.95494

Cumulative Model Updates: 97,990
Cumulative Timesteps: 817,122,984

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 817122984...
Checkpoint 817122984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,556.82419
Policy Entropy: 3.70547
Value Function Loss: 0.03390

Mean KL Divergence: 0.01126
SB3 Clip Fraction: 0.15214
Policy Update Magnitude: 0.51701
Value Function Update Magnitude: 0.62644

Collected Steps per Second: 21,148.74769
Overall Steps per Second: 10,169.25433

Timestep Collection Time: 2.36534
Timestep Consumption Time: 2.55380
PPO Batch Consumption Time: 0.29954
Total Iteration Time: 4.91914

Cumulative Model Updates: 97,996
Cumulative Timesteps: 817,173,008

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,807.84882
Policy Entropy: 3.69870
Value Function Loss: 0.03604

Mean KL Divergence: 0.01104
SB3 Clip Fraction: 0.15169
Policy Update Magnitude: 0.51229
Value Function Update Magnitude: 0.62820

Collected Steps per Second: 21,565.47775
Overall Steps per Second: 10,375.70272

Timestep Collection Time: 2.31898
Timestep Consumption Time: 2.50093
PPO Batch Consumption Time: 0.28858
Total Iteration Time: 4.81991

Cumulative Model Updates: 98,002
Cumulative Timesteps: 817,223,018

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 817223018...
Checkpoint 817223018 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,807.84882
Policy Entropy: 3.69361
Value Function Loss: 0.03229

Mean KL Divergence: 0.01144
SB3 Clip Fraction: 0.15527
Policy Update Magnitude: 0.51918
Value Function Update Magnitude: 0.62404

Collected Steps per Second: 21,413.72175
Overall Steps per Second: 10,327.92120

Timestep Collection Time: 2.33589
Timestep Consumption Time: 2.50730
PPO Batch Consumption Time: 0.28746
Total Iteration Time: 4.84318

Cumulative Model Updates: 98,008
Cumulative Timesteps: 817,273,038

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 106,713.41086
Policy Entropy: 3.67191
Value Function Loss: 0.02946

Mean KL Divergence: 0.01092
SB3 Clip Fraction: 0.15109
Policy Update Magnitude: 0.50820
Value Function Update Magnitude: 0.89043

Collected Steps per Second: 21,659.25946
Overall Steps per Second: 10,393.01747

Timestep Collection Time: 2.30987
Timestep Consumption Time: 2.50394
PPO Batch Consumption Time: 0.28839
Total Iteration Time: 4.81381

Cumulative Model Updates: 98,014
Cumulative Timesteps: 817,323,068

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 817323068...
Checkpoint 817323068 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 75,825.99917
Policy Entropy: 3.66138
Value Function Loss: 0.02730

Mean KL Divergence: 0.01159
SB3 Clip Fraction: 0.16017
Policy Update Magnitude: 0.49553
Value Function Update Magnitude: 0.82659

Collected Steps per Second: 21,457.62991
Overall Steps per Second: 10,249.16825

Timestep Collection Time: 2.33055
Timestep Consumption Time: 2.54868
PPO Batch Consumption Time: 0.29479
Total Iteration Time: 4.87923

Cumulative Model Updates: 98,020
Cumulative Timesteps: 817,373,076

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 206,534.07732
Policy Entropy: 3.66612
Value Function Loss: 0.03315

Mean KL Divergence: 0.01154
SB3 Clip Fraction: 0.15669
Policy Update Magnitude: 0.49479
Value Function Update Magnitude: 0.66196

Collected Steps per Second: 21,245.46257
Overall Steps per Second: 10,174.13793

Timestep Collection Time: 2.35420
Timestep Consumption Time: 2.56180
PPO Batch Consumption Time: 0.29852
Total Iteration Time: 4.91599

Cumulative Model Updates: 98,026
Cumulative Timesteps: 817,423,092

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 817423092...
Checkpoint 817423092 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 330,308.88756
Policy Entropy: 3.67543
Value Function Loss: 0.04256

Mean KL Divergence: 0.01113
SB3 Clip Fraction: 0.15382
Policy Update Magnitude: 0.52878
Value Function Update Magnitude: 0.67512

Collected Steps per Second: 21,327.36473
Overall Steps per Second: 10,185.13620

Timestep Collection Time: 2.34525
Timestep Consumption Time: 2.56563
PPO Batch Consumption Time: 0.29838
Total Iteration Time: 4.91088

Cumulative Model Updates: 98,032
Cumulative Timesteps: 817,473,110

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 94,073.16929
Policy Entropy: 3.67274
Value Function Loss: 0.04570

Mean KL Divergence: 0.01221
SB3 Clip Fraction: 0.16704
Policy Update Magnitude: 0.55983
Value Function Update Magnitude: 0.67020

Collected Steps per Second: 21,546.67137
Overall Steps per Second: 10,355.53971

Timestep Collection Time: 2.32119
Timestep Consumption Time: 2.50849
PPO Batch Consumption Time: 0.28703
Total Iteration Time: 4.82969

Cumulative Model Updates: 98,038
Cumulative Timesteps: 817,523,124

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 817523124...
Checkpoint 817523124 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 115,229.08998
Policy Entropy: 3.67358
Value Function Loss: 0.04506

Mean KL Divergence: 0.01084
SB3 Clip Fraction: 0.15156
Policy Update Magnitude: 0.56827
Value Function Update Magnitude: 0.71788

Collected Steps per Second: 21,393.76300
Overall Steps per Second: 10,177.43280

Timestep Collection Time: 2.33872
Timestep Consumption Time: 2.57745
PPO Batch Consumption Time: 0.29842
Total Iteration Time: 4.91617

Cumulative Model Updates: 98,044
Cumulative Timesteps: 817,573,158

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78,734.93126
Policy Entropy: 3.66138
Value Function Loss: 0.04210

Mean KL Divergence: 0.01152
SB3 Clip Fraction: 0.15678
Policy Update Magnitude: 0.60834
Value Function Update Magnitude: 0.65764

Collected Steps per Second: 21,626.85890
Overall Steps per Second: 10,177.82932

Timestep Collection Time: 2.31397
Timestep Consumption Time: 2.60299
PPO Batch Consumption Time: 0.30237
Total Iteration Time: 4.91696

Cumulative Model Updates: 98,050
Cumulative Timesteps: 817,623,202

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 817623202...
Checkpoint 817623202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 78,734.93126
Policy Entropy: 3.66377
Value Function Loss: 0.03908

Mean KL Divergence: 0.01091
SB3 Clip Fraction: 0.15044
Policy Update Magnitude: 0.54951
Value Function Update Magnitude: 0.59108

Collected Steps per Second: 21,608.85917
Overall Steps per Second: 10,273.60975

Timestep Collection Time: 2.31405
Timestep Consumption Time: 2.55318
PPO Batch Consumption Time: 0.29496
Total Iteration Time: 4.86723

Cumulative Model Updates: 98,056
Cumulative Timesteps: 817,673,206

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 409,690.57095
Policy Entropy: 3.67056
Value Function Loss: 0.03129

Mean KL Divergence: 0.01082
SB3 Clip Fraction: 0.14799
Policy Update Magnitude: 0.50843
Value Function Update Magnitude: 0.55895

Collected Steps per Second: 21,707.69234
Overall Steps per Second: 10,259.99194

Timestep Collection Time: 2.30398
Timestep Consumption Time: 2.57069
PPO Batch Consumption Time: 0.29974
Total Iteration Time: 4.87466

Cumulative Model Updates: 98,062
Cumulative Timesteps: 817,723,220

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 817723220...
Checkpoint 817723220 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 409,690.57095
Policy Entropy: 3.67111
Value Function Loss: 0.03068

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.14807
Policy Update Magnitude: 0.47845
Value Function Update Magnitude: 0.54163

Collected Steps per Second: 20,321.69450
Overall Steps per Second: 10,232.13886

Timestep Collection Time: 2.46190
Timestep Consumption Time: 2.42759
PPO Batch Consumption Time: 0.28696
Total Iteration Time: 4.88950

Cumulative Model Updates: 98,068
Cumulative Timesteps: 817,773,250

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 409,690.57095
Policy Entropy: 3.66867
Value Function Loss: 0.02611

Mean KL Divergence: 0.01058
SB3 Clip Fraction: 0.14474
Policy Update Magnitude: 0.47439
Value Function Update Magnitude: 0.49704

Collected Steps per Second: 20,809.52645
Overall Steps per Second: 10,327.29311

Timestep Collection Time: 2.40284
Timestep Consumption Time: 2.43889
PPO Batch Consumption Time: 0.28897
Total Iteration Time: 4.84173

Cumulative Model Updates: 98,074
Cumulative Timesteps: 817,823,252

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 817823252...
Checkpoint 817823252 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 409,690.57095
Policy Entropy: 3.65091
Value Function Loss: 0.03049

Mean KL Divergence: 0.01082
SB3 Clip Fraction: 0.14880
Policy Update Magnitude: 0.47792
Value Function Update Magnitude: 0.49815

Collected Steps per Second: 20,690.46325
Overall Steps per Second: 10,197.87394

Timestep Collection Time: 2.41783
Timestep Consumption Time: 2.48770
PPO Batch Consumption Time: 0.28850
Total Iteration Time: 4.90553

Cumulative Model Updates: 98,080
Cumulative Timesteps: 817,873,278

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 409,690.57095
Policy Entropy: 3.64400
Value Function Loss: 0.03001

Mean KL Divergence: 0.01122
SB3 Clip Fraction: 0.15422
Policy Update Magnitude: 0.48334
Value Function Update Magnitude: 0.48251

Collected Steps per Second: 21,460.69338
Overall Steps per Second: 10,311.88004

Timestep Collection Time: 2.33049
Timestep Consumption Time: 2.51964
PPO Batch Consumption Time: 0.29649
Total Iteration Time: 4.85013

Cumulative Model Updates: 98,086
Cumulative Timesteps: 817,923,292

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 817923292...
Checkpoint 817923292 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 409,690.57095
Policy Entropy: 3.63904
Value Function Loss: 0.03570

Mean KL Divergence: 0.01073
SB3 Clip Fraction: 0.15029
Policy Update Magnitude: 0.49494
Value Function Update Magnitude: 0.44490

Collected Steps per Second: 21,312.53266
Overall Steps per Second: 10,329.09586

Timestep Collection Time: 2.34726
Timestep Consumption Time: 2.49595
PPO Batch Consumption Time: 0.28826
Total Iteration Time: 4.84321

Cumulative Model Updates: 98,092
Cumulative Timesteps: 817,973,318

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 409,690.57095
Policy Entropy: 3.63775
Value Function Loss: 0.03726

Mean KL Divergence: 0.01099
SB3 Clip Fraction: 0.15073
Policy Update Magnitude: 0.49444
Value Function Update Magnitude: 0.38688

Collected Steps per Second: 21,685.76930
Overall Steps per Second: 10,253.92534

Timestep Collection Time: 2.30566
Timestep Consumption Time: 2.57052
PPO Batch Consumption Time: 0.29963
Total Iteration Time: 4.87618

Cumulative Model Updates: 98,098
Cumulative Timesteps: 818,023,318

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 818023318...
Checkpoint 818023318 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 663,548.94734
Policy Entropy: 3.63542
Value Function Loss: 0.04244

Mean KL Divergence: 0.01120
SB3 Clip Fraction: 0.15129
Policy Update Magnitude: 0.50042
Value Function Update Magnitude: 0.37276

Collected Steps per Second: 21,100.12599
Overall Steps per Second: 10,108.08174

Timestep Collection Time: 2.37032
Timestep Consumption Time: 2.57760
PPO Batch Consumption Time: 0.30086
Total Iteration Time: 4.94792

Cumulative Model Updates: 98,104
Cumulative Timesteps: 818,073,332

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 352,650.35918
Policy Entropy: 3.64145
Value Function Loss: 0.04687

Mean KL Divergence: 0.01100
SB3 Clip Fraction: 0.14864
Policy Update Magnitude: 0.52621
Value Function Update Magnitude: 0.38617

Collected Steps per Second: 21,489.68788
Overall Steps per Second: 10,366.58659

Timestep Collection Time: 2.32744
Timestep Consumption Time: 2.49729
PPO Batch Consumption Time: 0.28773
Total Iteration Time: 4.82473

Cumulative Model Updates: 98,110
Cumulative Timesteps: 818,123,348

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 818123348...
Checkpoint 818123348 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 123,011.46683
Policy Entropy: 3.65352
Value Function Loss: 0.04315

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.14819
Policy Update Magnitude: 0.56477
Value Function Update Magnitude: 0.50364

Collected Steps per Second: 21,203.40628
Overall Steps per Second: 10,305.66842

Timestep Collection Time: 2.35896
Timestep Consumption Time: 2.49448
PPO Batch Consumption Time: 0.28681
Total Iteration Time: 4.85345

Cumulative Model Updates: 98,116
Cumulative Timesteps: 818,173,366

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53,069.94850
Policy Entropy: 3.66622
Value Function Loss: 0.03980

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.14222
Policy Update Magnitude: 0.57794
Value Function Update Magnitude: 0.57161

Collected Steps per Second: 21,317.22244
Overall Steps per Second: 10,177.36007

Timestep Collection Time: 2.34627
Timestep Consumption Time: 2.56817
PPO Batch Consumption Time: 0.29770
Total Iteration Time: 4.91444

Cumulative Model Updates: 98,122
Cumulative Timesteps: 818,223,382

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 818223382...
Checkpoint 818223382 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 88,933.27468
Policy Entropy: 3.66979
Value Function Loss: 0.03629

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.14417
Policy Update Magnitude: 0.60278
Value Function Update Magnitude: 0.53868

Collected Steps per Second: 21,523.61757
Overall Steps per Second: 10,214.56738

Timestep Collection Time: 2.32405
Timestep Consumption Time: 2.57307
PPO Batch Consumption Time: 0.29636
Total Iteration Time: 4.89712

Cumulative Model Updates: 98,128
Cumulative Timesteps: 818,273,404

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 129,619.16080
Policy Entropy: 3.65881
Value Function Loss: 0.03920

Mean KL Divergence: 0.01081
SB3 Clip Fraction: 0.14735
Policy Update Magnitude: 0.60521
Value Function Update Magnitude: 0.52295

Collected Steps per Second: 21,445.22276
Overall Steps per Second: 10,316.67680

Timestep Collection Time: 2.33199
Timestep Consumption Time: 2.51550
PPO Batch Consumption Time: 0.28996
Total Iteration Time: 4.84749

Cumulative Model Updates: 98,134
Cumulative Timesteps: 818,323,414

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 818323414...
Checkpoint 818323414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,212.99474
Policy Entropy: 3.65308
Value Function Loss: 0.03824

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.14119
Policy Update Magnitude: 0.61578
Value Function Update Magnitude: 0.51973

Collected Steps per Second: 21,190.05623
Overall Steps per Second: 10,185.97404

Timestep Collection Time: 2.36092
Timestep Consumption Time: 2.55054
PPO Batch Consumption Time: 0.29525
Total Iteration Time: 4.91146

Cumulative Model Updates: 98,140
Cumulative Timesteps: 818,373,442

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 170,806.69895
Policy Entropy: 3.65889
Value Function Loss: 0.03824

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.14245
Policy Update Magnitude: 0.57824
Value Function Update Magnitude: 0.47079

Collected Steps per Second: 21,223.74384
Overall Steps per Second: 10,119.71413

Timestep Collection Time: 2.35632
Timestep Consumption Time: 2.58552
PPO Batch Consumption Time: 0.30088
Total Iteration Time: 4.94184

Cumulative Model Updates: 98,146
Cumulative Timesteps: 818,423,452

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 818423452...
Checkpoint 818423452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 204,479.92083
Policy Entropy: 3.66205
Value Function Loss: 0.03705

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.14245
Policy Update Magnitude: 0.52197
Value Function Update Magnitude: 0.43523

Collected Steps per Second: 21,344.52499
Overall Steps per Second: 10,159.46323

Timestep Collection Time: 2.34336
Timestep Consumption Time: 2.57993
PPO Batch Consumption Time: 0.30098
Total Iteration Time: 4.92329

Cumulative Model Updates: 98,152
Cumulative Timesteps: 818,473,470

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 271,217.77157
Policy Entropy: 3.65584
Value Function Loss: 0.04046

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.14139
Policy Update Magnitude: 0.51431
Value Function Update Magnitude: 0.47727

Collected Steps per Second: 21,462.23975
Overall Steps per Second: 10,312.99715

Timestep Collection Time: 2.33023
Timestep Consumption Time: 2.51918
PPO Batch Consumption Time: 0.28831
Total Iteration Time: 4.84941

Cumulative Model Updates: 98,158
Cumulative Timesteps: 818,523,482

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 818523482...
Checkpoint 818523482 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 177,954.10220
Policy Entropy: 3.65909
Value Function Loss: 0.03733

Mean KL Divergence: 0.01061
SB3 Clip Fraction: 0.14025
Policy Update Magnitude: 0.57005
Value Function Update Magnitude: 0.51135

Collected Steps per Second: 21,371.97079
Overall Steps per Second: 10,330.57211

Timestep Collection Time: 2.34017
Timestep Consumption Time: 2.50119
PPO Batch Consumption Time: 0.28699
Total Iteration Time: 4.84136

Cumulative Model Updates: 98,164
Cumulative Timesteps: 818,573,496

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 177,954.10220
Policy Entropy: 3.66482
Value Function Loss: 0.03271

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.14420
Policy Update Magnitude: 0.54796
Value Function Update Magnitude: 0.51250

Collected Steps per Second: 21,763.40978
Overall Steps per Second: 10,368.04550

Timestep Collection Time: 2.29780
Timestep Consumption Time: 2.52548
PPO Batch Consumption Time: 0.28874
Total Iteration Time: 4.82328

Cumulative Model Updates: 98,170
Cumulative Timesteps: 818,623,504

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 818623504...
Checkpoint 818623504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 177,954.10220
Policy Entropy: 3.65990
Value Function Loss: 0.02748

Mean KL Divergence: 0.01086
SB3 Clip Fraction: 0.15066
Policy Update Magnitude: 0.48902
Value Function Update Magnitude: 0.47162

Collected Steps per Second: 21,636.66891
Overall Steps per Second: 10,279.04727

Timestep Collection Time: 2.31228
Timestep Consumption Time: 2.55490
PPO Batch Consumption Time: 0.29298
Total Iteration Time: 4.86718

Cumulative Model Updates: 98,176
Cumulative Timesteps: 818,673,534

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 177,954.10220
Policy Entropy: 3.66892
Value Function Loss: 0.02422

Mean KL Divergence: 0.01155
SB3 Clip Fraction: 0.15612
Policy Update Magnitude: 0.45527
Value Function Update Magnitude: 0.43389

Collected Steps per Second: 21,385.04933
Overall Steps per Second: 10,215.28608

Timestep Collection Time: 2.33948
Timestep Consumption Time: 2.55808
PPO Batch Consumption Time: 0.29658
Total Iteration Time: 4.89756

Cumulative Model Updates: 98,182
Cumulative Timesteps: 818,723,564

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 818723564...
Checkpoint 818723564 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 272,952.22354
Policy Entropy: 3.65396
Value Function Loss: 0.02692

Mean KL Divergence: 0.01183
SB3 Clip Fraction: 0.15897
Policy Update Magnitude: 0.45543
Value Function Update Magnitude: 0.42738

Collected Steps per Second: 21,542.57465
Overall Steps per Second: 10,338.24681

Timestep Collection Time: 2.32136
Timestep Consumption Time: 2.51583
PPO Batch Consumption Time: 0.28786
Total Iteration Time: 4.83718

Cumulative Model Updates: 98,188
Cumulative Timesteps: 818,773,572

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 272,952.22354
Policy Entropy: 3.66957
Value Function Loss: 0.02395

Mean KL Divergence: 0.01152
SB3 Clip Fraction: 0.14878
Policy Update Magnitude: 0.47655
Value Function Update Magnitude: 0.44148

Collected Steps per Second: 21,640.90248
Overall Steps per Second: 10,259.78584

Timestep Collection Time: 2.31155
Timestep Consumption Time: 2.56419
PPO Batch Consumption Time: 0.29884
Total Iteration Time: 4.87574

Cumulative Model Updates: 98,194
Cumulative Timesteps: 818,823,596

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 818823596...
Checkpoint 818823596 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 272,952.22354
Policy Entropy: 3.63539
Value Function Loss: 0.02503

Mean KL Divergence: 0.01160
SB3 Clip Fraction: 0.15395
Policy Update Magnitude: 0.47323
Value Function Update Magnitude: 0.41332

Collected Steps per Second: 21,525.07738
Overall Steps per Second: 10,283.55129

Timestep Collection Time: 2.32399
Timestep Consumption Time: 2.54048
PPO Batch Consumption Time: 0.29542
Total Iteration Time: 4.86447

Cumulative Model Updates: 98,200
Cumulative Timesteps: 818,873,620

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 418,652.50490
Policy Entropy: 3.65361
Value Function Loss: 0.03712

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.13162
Policy Update Magnitude: 0.65611
Value Function Update Magnitude: 0.39371

Collected Steps per Second: 20,371.98613
Overall Steps per Second: 9,980.82594

Timestep Collection Time: 2.45465
Timestep Consumption Time: 2.55556
PPO Batch Consumption Time: 0.29792
Total Iteration Time: 5.01021

Cumulative Model Updates: 98,206
Cumulative Timesteps: 818,923,626

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 818923626...
Checkpoint 818923626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 243,876.21849
Policy Entropy: 3.65317
Value Function Loss: 0.04334

Mean KL Divergence: 0.01755
SB3 Clip Fraction: 0.21162
Policy Update Magnitude: 0.71845
Value Function Update Magnitude: 0.39143

Collected Steps per Second: 20,713.66680
Overall Steps per Second: 10,074.30530

Timestep Collection Time: 2.41435
Timestep Consumption Time: 2.54977
PPO Batch Consumption Time: 0.29618
Total Iteration Time: 4.96411

Cumulative Model Updates: 98,212
Cumulative Timesteps: 818,973,636

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 243,876.21849
Policy Entropy: 3.68917
Value Function Loss: 0.04194

Mean KL Divergence: 0.01403
SB3 Clip Fraction: 0.17046
Policy Update Magnitude: 0.75164
Value Function Update Magnitude: 0.38301

Collected Steps per Second: 21,235.48477
Overall Steps per Second: 10,172.59904

Timestep Collection Time: 2.35559
Timestep Consumption Time: 2.56174
PPO Batch Consumption Time: 0.29857
Total Iteration Time: 4.91733

Cumulative Model Updates: 98,218
Cumulative Timesteps: 819,023,658

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 819023658...
Checkpoint 819023658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 243,876.21849
Policy Entropy: 3.67673
Value Function Loss: 0.04086

Mean KL Divergence: 0.01256
SB3 Clip Fraction: 0.15444
Policy Update Magnitude: 0.83274
Value Function Update Magnitude: 0.44726

Collected Steps per Second: 21,290.68807
Overall Steps per Second: 10,203.08046

Timestep Collection Time: 2.34985
Timestep Consumption Time: 2.55357
PPO Batch Consumption Time: 0.29911
Total Iteration Time: 4.90342

Cumulative Model Updates: 98,224
Cumulative Timesteps: 819,073,688

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 480,798.85860
Policy Entropy: 3.66378
Value Function Loss: 0.04019

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.12539
Policy Update Magnitude: 0.90965
Value Function Update Magnitude: 0.52534

Collected Steps per Second: 20,723.51187
Overall Steps per Second: 10,340.25405

Timestep Collection Time: 2.41407
Timestep Consumption Time: 2.42411
PPO Batch Consumption Time: 0.28706
Total Iteration Time: 4.83818

Cumulative Model Updates: 98,230
Cumulative Timesteps: 819,123,716

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 819123716...
Checkpoint 819123716 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 292,258.86489
Policy Entropy: 3.67703
Value Function Loss: 0.03677

Mean KL Divergence: 0.01093
SB3 Clip Fraction: 0.13711
Policy Update Magnitude: 0.96075
Value Function Update Magnitude: 0.74589

Collected Steps per Second: 20,499.31217
Overall Steps per Second: 10,211.35509

Timestep Collection Time: 2.44028
Timestep Consumption Time: 2.45858
PPO Batch Consumption Time: 0.29536
Total Iteration Time: 4.89886

Cumulative Model Updates: 98,236
Cumulative Timesteps: 819,173,740

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 137,745.47207
Policy Entropy: 3.69487
Value Function Loss: 0.03701

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.10183
Policy Update Magnitude: 0.89681
Value Function Update Magnitude: 0.70973

Collected Steps per Second: 20,777.84454
Overall Steps per Second: 10,336.45468

Timestep Collection Time: 2.40747
Timestep Consumption Time: 2.43191
PPO Batch Consumption Time: 0.28857
Total Iteration Time: 4.83938

Cumulative Model Updates: 98,242
Cumulative Timesteps: 819,223,762

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 819223762...
Checkpoint 819223762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 367,114.42870
Policy Entropy: 3.66285
Value Function Loss: 0.03681

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.12114
Policy Update Magnitude: 0.84504
Value Function Update Magnitude: 0.67361

Collected Steps per Second: 20,706.60621
Overall Steps per Second: 10,208.33656

Timestep Collection Time: 2.41556
Timestep Consumption Time: 2.48416
PPO Batch Consumption Time: 0.28801
Total Iteration Time: 4.89972

Cumulative Model Updates: 98,248
Cumulative Timesteps: 819,273,780

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 128,030.67942
Policy Entropy: 3.64588
Value Function Loss: 0.04124

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.11323
Policy Update Magnitude: 0.81310
Value Function Update Magnitude: 0.63553

Collected Steps per Second: 21,550.52976
Overall Steps per Second: 10,295.91406

Timestep Collection Time: 2.32050
Timestep Consumption Time: 2.53657
PPO Batch Consumption Time: 0.29823
Total Iteration Time: 4.85707

Cumulative Model Updates: 98,254
Cumulative Timesteps: 819,323,788

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 819323788...
Checkpoint 819323788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40,194.20735
Policy Entropy: 3.65821
Value Function Loss: 0.04741

Mean KL Divergence: 0.01716
SB3 Clip Fraction: 0.20999
Policy Update Magnitude: 0.66576
Value Function Update Magnitude: 0.55161

Collected Steps per Second: 20,486.48208
Overall Steps per Second: 10,056.58634

Timestep Collection Time: 2.44190
Timestep Consumption Time: 2.53255
PPO Batch Consumption Time: 0.29606
Total Iteration Time: 4.97445

Cumulative Model Updates: 98,260
Cumulative Timesteps: 819,373,814

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 502,250.91496
Policy Entropy: 3.65426
Value Function Loss: 0.04837

Mean KL Divergence: 0.01624
SB3 Clip Fraction: 0.20450
Policy Update Magnitude: 0.60904
Value Function Update Magnitude: 0.53050

Collected Steps per Second: 20,969.79123
Overall Steps per Second: 10,040.43751

Timestep Collection Time: 2.38572
Timestep Consumption Time: 2.59693
PPO Batch Consumption Time: 0.30152
Total Iteration Time: 4.98265

Cumulative Model Updates: 98,266
Cumulative Timesteps: 819,423,842

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 819423842...
Checkpoint 819423842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 223,019.32340
Policy Entropy: 3.67606
Value Function Loss: 0.04862

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.10679
Policy Update Magnitude: 0.68871
Value Function Update Magnitude: 0.59033

Collected Steps per Second: 21,171.50788
Overall Steps per Second: 10,177.10850

Timestep Collection Time: 2.36299
Timestep Consumption Time: 2.55275
PPO Batch Consumption Time: 0.29504
Total Iteration Time: 4.91574

Cumulative Model Updates: 98,272
Cumulative Timesteps: 819,473,870

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,342.24654
Policy Entropy: 3.69657
Value Function Loss: 0.04017

Mean KL Divergence: 0.00758
SB3 Clip Fraction: 0.09677
Policy Update Magnitude: 0.82738
Value Function Update Magnitude: 0.66826

Collected Steps per Second: 21,064.27336
Overall Steps per Second: 10,069.14482

Timestep Collection Time: 2.37511
Timestep Consumption Time: 2.59353
PPO Batch Consumption Time: 0.30259
Total Iteration Time: 4.96864

Cumulative Model Updates: 98,278
Cumulative Timesteps: 819,523,900

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 819523900...
Checkpoint 819523900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,342.24654
Policy Entropy: 3.72898
Value Function Loss: 0.03286

Mean KL Divergence: 0.00625
SB3 Clip Fraction: 0.07328
Policy Update Magnitude: 0.79866
Value Function Update Magnitude: 0.65971

Collected Steps per Second: 21,443.38605
Overall Steps per Second: 10,032.23316

Timestep Collection Time: 2.33172
Timestep Consumption Time: 2.65221
PPO Batch Consumption Time: 0.31377
Total Iteration Time: 4.98394

Cumulative Model Updates: 98,284
Cumulative Timesteps: 819,573,900

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79,030.77954
Policy Entropy: 3.67960
Value Function Loss: 0.03531

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.13272
Policy Update Magnitude: 0.79591
Value Function Update Magnitude: 0.68482

Collected Steps per Second: 21,151.86558
Overall Steps per Second: 10,261.94649

Timestep Collection Time: 2.36528
Timestep Consumption Time: 2.51002
PPO Batch Consumption Time: 0.28759
Total Iteration Time: 4.87529

Cumulative Model Updates: 98,290
Cumulative Timesteps: 819,623,930

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 819623930...
Checkpoint 819623930 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 179,771.95604
Policy Entropy: 3.63393
Value Function Loss: 0.05600

Mean KL Divergence: 0.02012
SB3 Clip Fraction: 0.23261
Policy Update Magnitude: 0.73444
Value Function Update Magnitude: 0.57568

Collected Steps per Second: 21,030.00442
Overall Steps per Second: 10,156.91133

Timestep Collection Time: 2.37870
Timestep Consumption Time: 2.54642
PPO Batch Consumption Time: 0.29315
Total Iteration Time: 4.92512

Cumulative Model Updates: 98,296
Cumulative Timesteps: 819,673,954

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88,850.19297
Policy Entropy: 3.64487
Value Function Loss: 0.07347

Mean KL Divergence: 0.01585
SB3 Clip Fraction: 0.19314
Policy Update Magnitude: 0.89199
Value Function Update Magnitude: 0.53750

Collected Steps per Second: 21,009.21078
Overall Steps per Second: 10,045.37127

Timestep Collection Time: 2.38077
Timestep Consumption Time: 2.59844
PPO Batch Consumption Time: 0.30143
Total Iteration Time: 4.97921

Cumulative Model Updates: 98,302
Cumulative Timesteps: 819,723,972

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 819723972...
Checkpoint 819723972 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,029.75229
Policy Entropy: 3.67894
Value Function Loss: 0.07465

Mean KL Divergence: 0.01505
SB3 Clip Fraction: 0.17870
Policy Update Magnitude: 1.00117
Value Function Update Magnitude: 0.56336

Collected Steps per Second: 21,046.45279
Overall Steps per Second: 10,274.60630

Timestep Collection Time: 2.37655
Timestep Consumption Time: 2.49157
PPO Batch Consumption Time: 0.28657
Total Iteration Time: 4.86812

Cumulative Model Updates: 98,308
Cumulative Timesteps: 819,773,990

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 139,290.40799
Policy Entropy: 3.70558
Value Function Loss: 0.07638

Mean KL Divergence: 0.01368
SB3 Clip Fraction: 0.16982
Policy Update Magnitude: 0.96580
Value Function Update Magnitude: 0.64923

Collected Steps per Second: 21,249.88058
Overall Steps per Second: 10,137.94643

Timestep Collection Time: 2.35295
Timestep Consumption Time: 2.57901
PPO Batch Consumption Time: 0.29779
Total Iteration Time: 4.93197

Cumulative Model Updates: 98,314
Cumulative Timesteps: 819,823,990

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 819823990...
Checkpoint 819823990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,393.50236
Policy Entropy: 3.71114
Value Function Loss: 0.06829

Mean KL Divergence: 0.01187
SB3 Clip Fraction: 0.15164
Policy Update Magnitude: 0.83290
Value Function Update Magnitude: 0.56909

Collected Steps per Second: 19,451.52167
Overall Steps per Second: 9,611.57089

Timestep Collection Time: 2.57214
Timestep Consumption Time: 2.63325
PPO Batch Consumption Time: 0.30065
Total Iteration Time: 5.20539

Cumulative Model Updates: 98,320
Cumulative Timesteps: 819,874,022

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,188.31428
Policy Entropy: 3.74140
Value Function Loss: 0.05720

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.12836
Policy Update Magnitude: 0.75781
Value Function Update Magnitude: 0.72342

Collected Steps per Second: 20,443.46782
Overall Steps per Second: 10,103.47567

Timestep Collection Time: 2.44606
Timestep Consumption Time: 2.50332
PPO Batch Consumption Time: 0.28729
Total Iteration Time: 4.94939

Cumulative Model Updates: 98,326
Cumulative Timesteps: 819,924,028

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 819924028...
Checkpoint 819924028 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,593.80962
Policy Entropy: 3.73365
Value Function Loss: 0.05086

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.13490
Policy Update Magnitude: 0.76372
Value Function Update Magnitude: 0.87436

Collected Steps per Second: 21,331.87407
Overall Steps per Second: 10,197.82300

Timestep Collection Time: 2.34419
Timestep Consumption Time: 2.55940
PPO Batch Consumption Time: 0.29864
Total Iteration Time: 4.90360

Cumulative Model Updates: 98,332
Cumulative Timesteps: 819,974,034

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,591.91457
Policy Entropy: 3.73403
Value Function Loss: 0.04653

Mean KL Divergence: 0.01085
SB3 Clip Fraction: 0.14237
Policy Update Magnitude: 0.74416
Value Function Update Magnitude: 0.93757

Collected Steps per Second: 20,932.84962
Overall Steps per Second: 10,345.23220

Timestep Collection Time: 2.38897
Timestep Consumption Time: 2.44495
PPO Batch Consumption Time: 0.28884
Total Iteration Time: 4.83392

Cumulative Model Updates: 98,338
Cumulative Timesteps: 820,024,042

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 820024042...
Checkpoint 820024042 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,163.90461
Policy Entropy: 3.69422
Value Function Loss: 0.04863

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.14551
Policy Update Magnitude: 0.67988
Value Function Update Magnitude: 0.96935

Collected Steps per Second: 20,977.55648
Overall Steps per Second: 10,312.93810

Timestep Collection Time: 2.38417
Timestep Consumption Time: 2.46547
PPO Batch Consumption Time: 0.29476
Total Iteration Time: 4.84964

Cumulative Model Updates: 98,344
Cumulative Timesteps: 820,074,056

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,937.81475
Policy Entropy: 3.69248
Value Function Loss: 0.04774

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.14024
Policy Update Magnitude: 0.61417
Value Function Update Magnitude: 0.99489

Collected Steps per Second: 20,609.94426
Overall Steps per Second: 10,205.16457

Timestep Collection Time: 2.42708
Timestep Consumption Time: 2.47455
PPO Batch Consumption Time: 0.29727
Total Iteration Time: 4.90164

Cumulative Model Updates: 98,350
Cumulative Timesteps: 820,124,078

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 820124078...
Checkpoint 820124078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 885.43223
Policy Entropy: 3.69278
Value Function Loss: 0.05021

Mean KL Divergence: 0.01145
SB3 Clip Fraction: 0.15304
Policy Update Magnitude: 0.62379
Value Function Update Magnitude: 0.81546

Collected Steps per Second: 20,753.42738
Overall Steps per Second: 10,034.65626

Timestep Collection Time: 2.41117
Timestep Consumption Time: 2.57555
PPO Batch Consumption Time: 0.31175
Total Iteration Time: 4.98672

Cumulative Model Updates: 98,356
Cumulative Timesteps: 820,174,118

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 246.59701
Policy Entropy: 3.68856
Value Function Loss: 0.04758

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.13990
Policy Update Magnitude: 0.56512
Value Function Update Magnitude: 0.66399

Collected Steps per Second: 20,623.34176
Overall Steps per Second: 10,077.31786

Timestep Collection Time: 2.42550
Timestep Consumption Time: 2.53832
PPO Batch Consumption Time: 0.29443
Total Iteration Time: 4.96382

Cumulative Model Updates: 98,362
Cumulative Timesteps: 820,224,140

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 820224140...
Checkpoint 820224140 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,013.82486
Policy Entropy: 3.70394
Value Function Loss: 0.03688

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.13762
Policy Update Magnitude: 0.52027
Value Function Update Magnitude: 0.66901

Collected Steps per Second: 21,604.99772
Overall Steps per Second: 10,313.32582

Timestep Collection Time: 2.31539
Timestep Consumption Time: 2.53503
PPO Batch Consumption Time: 0.29876
Total Iteration Time: 4.85042

Cumulative Model Updates: 98,368
Cumulative Timesteps: 820,274,164

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 151,882.68982
Policy Entropy: 3.68604
Value Function Loss: 0.03787

Mean KL Divergence: 0.01055
SB3 Clip Fraction: 0.14554
Policy Update Magnitude: 0.48958
Value Function Update Magnitude: 0.61896

Collected Steps per Second: 21,429.67698
Overall Steps per Second: 10,335.33651

Timestep Collection Time: 2.33368
Timestep Consumption Time: 2.50506
PPO Batch Consumption Time: 0.29267
Total Iteration Time: 4.83874

Cumulative Model Updates: 98,374
Cumulative Timesteps: 820,324,174

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 820324174...
Checkpoint 820324174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 52,081.38247
Policy Entropy: 3.70735
Value Function Loss: 0.03422

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.13871
Policy Update Magnitude: 0.46496
Value Function Update Magnitude: 0.59712

Collected Steps per Second: 21,278.12257
Overall Steps per Second: 10,212.92630

Timestep Collection Time: 2.35087
Timestep Consumption Time: 2.54705
PPO Batch Consumption Time: 0.30200
Total Iteration Time: 4.89791

Cumulative Model Updates: 98,380
Cumulative Timesteps: 820,374,196

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,166.13520
Policy Entropy: 3.68340
Value Function Loss: 0.03486

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.14131
Policy Update Magnitude: 0.45022
Value Function Update Magnitude: 0.61995

Collected Steps per Second: 21,965.45110
Overall Steps per Second: 10,407.87889

Timestep Collection Time: 2.27685
Timestep Consumption Time: 2.52836
PPO Batch Consumption Time: 0.28946
Total Iteration Time: 4.80521

Cumulative Model Updates: 98,386
Cumulative Timesteps: 820,424,208

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 820424208...
Checkpoint 820424208 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 60,041.97034
Policy Entropy: 3.68806
Value Function Loss: 0.03090

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.14296
Policy Update Magnitude: 0.43328
Value Function Update Magnitude: 0.62710

Collected Steps per Second: 21,512.04275
Overall Steps per Second: 10,219.78880

Timestep Collection Time: 2.32493
Timestep Consumption Time: 2.56891
PPO Batch Consumption Time: 0.29797
Total Iteration Time: 4.89384

Cumulative Model Updates: 98,392
Cumulative Timesteps: 820,474,222

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,951.60171
Policy Entropy: 3.67062
Value Function Loss: 0.03174

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.14388
Policy Update Magnitude: 0.42424
Value Function Update Magnitude: 0.61774

Collected Steps per Second: 21,707.41473
Overall Steps per Second: 10,375.89832

Timestep Collection Time: 2.30410
Timestep Consumption Time: 2.51630
PPO Batch Consumption Time: 0.28852
Total Iteration Time: 4.82040

Cumulative Model Updates: 98,398
Cumulative Timesteps: 820,524,238

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 820524238...
Checkpoint 820524238 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 52,903.41926
Policy Entropy: 3.69090
Value Function Loss: 0.03078

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.14605
Policy Update Magnitude: 0.44570
Value Function Update Magnitude: 0.59978

Collected Steps per Second: 21,551.61927
Overall Steps per Second: 10,328.23322

Timestep Collection Time: 2.32224
Timestep Consumption Time: 2.52351
PPO Batch Consumption Time: 0.29068
Total Iteration Time: 4.84575

Cumulative Model Updates: 98,404
Cumulative Timesteps: 820,574,286

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52,903.41926
Policy Entropy: 3.69815
Value Function Loss: 0.03070

Mean KL Divergence: 0.01074
SB3 Clip Fraction: 0.15200
Policy Update Magnitude: 0.42444
Value Function Update Magnitude: 0.56308

Collected Steps per Second: 21,482.19867
Overall Steps per Second: 10,334.45704

Timestep Collection Time: 2.32769
Timestep Consumption Time: 2.51088
PPO Batch Consumption Time: 0.28801
Total Iteration Time: 4.83857

Cumulative Model Updates: 98,410
Cumulative Timesteps: 820,624,290

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 820624290...
Checkpoint 820624290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 52,903.41926
Policy Entropy: 3.68969
Value Function Loss: 0.02818

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.14592
Policy Update Magnitude: 0.39648
Value Function Update Magnitude: 0.54524

Collected Steps per Second: 21,606.54510
Overall Steps per Second: 10,308.18093

Timestep Collection Time: 2.31439
Timestep Consumption Time: 2.53671
PPO Batch Consumption Time: 0.29317
Total Iteration Time: 4.85110

Cumulative Model Updates: 98,416
Cumulative Timesteps: 820,674,296

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65,948.91659
Policy Entropy: 3.67274
Value Function Loss: 0.02900

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.14838
Policy Update Magnitude: 0.37281
Value Function Update Magnitude: 0.51627

Collected Steps per Second: 21,418.48229
Overall Steps per Second: 10,331.69677

Timestep Collection Time: 2.33462
Timestep Consumption Time: 2.50524
PPO Batch Consumption Time: 0.28831
Total Iteration Time: 4.83986

Cumulative Model Updates: 98,422
Cumulative Timesteps: 820,724,300

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 820724300...
Checkpoint 820724300 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 127,241.02167
Policy Entropy: 3.66422
Value Function Loss: 0.03222

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.14427
Policy Update Magnitude: 0.38525
Value Function Update Magnitude: 0.51203

Collected Steps per Second: 21,542.65014
Overall Steps per Second: 10,342.41649

Timestep Collection Time: 2.32191
Timestep Consumption Time: 2.51449
PPO Batch Consumption Time: 0.29057
Total Iteration Time: 4.83639

Cumulative Model Updates: 98,428
Cumulative Timesteps: 820,774,320

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86,399.21052
Policy Entropy: 3.66323
Value Function Loss: 0.03611

Mean KL Divergence: 0.01055
SB3 Clip Fraction: 0.15075
Policy Update Magnitude: 0.39523
Value Function Update Magnitude: 0.52434

Collected Steps per Second: 21,455.88937
Overall Steps per Second: 10,290.78676

Timestep Collection Time: 2.33036
Timestep Consumption Time: 2.52835
PPO Batch Consumption Time: 0.28898
Total Iteration Time: 4.85872

Cumulative Model Updates: 98,434
Cumulative Timesteps: 820,824,320

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 820824320...
Checkpoint 820824320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 998,763.32397
Policy Entropy: 3.66563
Value Function Loss: 0.03620

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.14835
Policy Update Magnitude: 0.39630
Value Function Update Magnitude: 0.51182

Collected Steps per Second: 21,352.95565
Overall Steps per Second: 10,304.56792

Timestep Collection Time: 2.34188
Timestep Consumption Time: 2.51092
PPO Batch Consumption Time: 0.28904
Total Iteration Time: 4.85280

Cumulative Model Updates: 98,440
Cumulative Timesteps: 820,874,326

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 542,301.25231
Policy Entropy: 3.66848
Value Function Loss: 0.03734

Mean KL Divergence: 0.01072
SB3 Clip Fraction: 0.15306
Policy Update Magnitude: 0.40998
Value Function Update Magnitude: 0.61488

Collected Steps per Second: 21,081.03120
Overall Steps per Second: 10,396.04339

Timestep Collection Time: 2.37209
Timestep Consumption Time: 2.43801
PPO Batch Consumption Time: 0.28892
Total Iteration Time: 4.81010

Cumulative Model Updates: 98,446
Cumulative Timesteps: 820,924,332

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 820924332...
Checkpoint 820924332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 189,101.60983
Policy Entropy: 3.67484
Value Function Loss: 0.03820

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.14634
Policy Update Magnitude: 0.41815
Value Function Update Magnitude: 0.66884

Collected Steps per Second: 20,769.58010
Overall Steps per Second: 10,309.71598

Timestep Collection Time: 2.40766
Timestep Consumption Time: 2.44272
PPO Batch Consumption Time: 0.29084
Total Iteration Time: 4.85038

Cumulative Model Updates: 98,452
Cumulative Timesteps: 820,974,338

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 269,446.56430
Policy Entropy: 3.68141
Value Function Loss: 0.04113

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.14146
Policy Update Magnitude: 0.45475
Value Function Update Magnitude: 0.61528

Collected Steps per Second: 20,849.19784
Overall Steps per Second: 10,355.91627

Timestep Collection Time: 2.39817
Timestep Consumption Time: 2.42998
PPO Batch Consumption Time: 0.28870
Total Iteration Time: 4.82816

Cumulative Model Updates: 98,458
Cumulative Timesteps: 821,024,338

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 821024338...
Checkpoint 821024338 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 93,963.61805
Policy Entropy: 3.68374
Value Function Loss: 0.03900

Mean KL Divergence: 0.01149
SB3 Clip Fraction: 0.15259
Policy Update Magnitude: 0.53727
Value Function Update Magnitude: 0.67274

Collected Steps per Second: 20,533.87922
Overall Steps per Second: 10,176.09760

Timestep Collection Time: 2.43578
Timestep Consumption Time: 2.47927
PPO Batch Consumption Time: 0.28878
Total Iteration Time: 4.91505

Cumulative Model Updates: 98,464
Cumulative Timesteps: 821,074,354

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84,396.40243
Policy Entropy: 3.67656
Value Function Loss: 0.03716

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.14510
Policy Update Magnitude: 0.52634
Value Function Update Magnitude: 0.72860

Collected Steps per Second: 21,647.84073
Overall Steps per Second: 10,390.14269

Timestep Collection Time: 2.31109
Timestep Consumption Time: 2.50406
PPO Batch Consumption Time: 0.29429
Total Iteration Time: 4.81514

Cumulative Model Updates: 98,470
Cumulative Timesteps: 821,124,384

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 821124384...
Checkpoint 821124384 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43,033.76145
Policy Entropy: 3.68444
Value Function Loss: 0.03532

Mean KL Divergence: 0.01085
SB3 Clip Fraction: 0.14958
Policy Update Magnitude: 0.46758
Value Function Update Magnitude: 0.73121

Collected Steps per Second: 21,105.35164
Overall Steps per Second: 10,308.18768

Timestep Collection Time: 2.36926
Timestep Consumption Time: 2.48164
PPO Batch Consumption Time: 0.28870
Total Iteration Time: 4.85090

Cumulative Model Updates: 98,476
Cumulative Timesteps: 821,174,388

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,059.30427
Policy Entropy: 3.69089
Value Function Loss: 0.04028

Mean KL Divergence: 0.01121
SB3 Clip Fraction: 0.15413
Policy Update Magnitude: 0.48118
Value Function Update Magnitude: 0.60346

Collected Steps per Second: 21,422.76780
Overall Steps per Second: 10,190.01520

Timestep Collection Time: 2.33499
Timestep Consumption Time: 2.57393
PPO Batch Consumption Time: 0.30039
Total Iteration Time: 4.90892

Cumulative Model Updates: 98,482
Cumulative Timesteps: 821,224,410

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 821224410...
Checkpoint 821224410 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,854.69347
Policy Entropy: 3.69928
Value Function Loss: 0.03394

Mean KL Divergence: 0.01047
SB3 Clip Fraction: 0.14753
Policy Update Magnitude: 0.46877
Value Function Update Magnitude: 0.54155

Collected Steps per Second: 21,299.79783
Overall Steps per Second: 10,131.52879

Timestep Collection Time: 2.34829
Timestep Consumption Time: 2.58858
PPO Batch Consumption Time: 0.30283
Total Iteration Time: 4.93687

Cumulative Model Updates: 98,488
Cumulative Timesteps: 821,274,428

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 823.33440
Policy Entropy: 3.69603
Value Function Loss: 0.02944

Mean KL Divergence: 0.01053
SB3 Clip Fraction: 0.14979
Policy Update Magnitude: 0.45320
Value Function Update Magnitude: 0.65521

Collected Steps per Second: 21,595.18786
Overall Steps per Second: 10,357.06076

Timestep Collection Time: 2.31579
Timestep Consumption Time: 2.51280
PPO Batch Consumption Time: 0.28885
Total Iteration Time: 4.82859

Cumulative Model Updates: 98,494
Cumulative Timesteps: 821,324,438

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 821324438...
Checkpoint 821324438 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 299,784.32140
Policy Entropy: 3.67470
Value Function Loss: 0.03315

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.14571
Policy Update Magnitude: 0.45034
Value Function Update Magnitude: 0.66805

Collected Steps per Second: 21,528.32328
Overall Steps per Second: 10,371.50880

Timestep Collection Time: 2.32317
Timestep Consumption Time: 2.49908
PPO Batch Consumption Time: 0.28640
Total Iteration Time: 4.82225

Cumulative Model Updates: 98,500
Cumulative Timesteps: 821,374,452

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 312,798.58751
Policy Entropy: 3.67138
Value Function Loss: 0.03319

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.13707
Policy Update Magnitude: 0.46321
Value Function Update Magnitude: 0.73186

Collected Steps per Second: 21,766.89228
Overall Steps per Second: 10,351.84885

Timestep Collection Time: 2.29835
Timestep Consumption Time: 2.53441
PPO Batch Consumption Time: 0.29048
Total Iteration Time: 4.83276

Cumulative Model Updates: 98,506
Cumulative Timesteps: 821,424,480

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 821424480...
Checkpoint 821424480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 186,666.08146
Policy Entropy: 3.66460
Value Function Loss: 0.03223

Mean KL Divergence: 0.01057
SB3 Clip Fraction: 0.14924
Policy Update Magnitude: 0.48601
Value Function Update Magnitude: 0.77029

Collected Steps per Second: 20,811.84935
Overall Steps per Second: 10,167.99656

Timestep Collection Time: 2.40353
Timestep Consumption Time: 2.51602
PPO Batch Consumption Time: 0.29277
Total Iteration Time: 4.91955

Cumulative Model Updates: 98,512
Cumulative Timesteps: 821,474,502

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 122,481.24292
Policy Entropy: 3.66786
Value Function Loss: 0.03004

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.14359
Policy Update Magnitude: 0.47259
Value Function Update Magnitude: 0.79857

Collected Steps per Second: 21,630.97724
Overall Steps per Second: 10,287.66645

Timestep Collection Time: 2.31178
Timestep Consumption Time: 2.54899
PPO Batch Consumption Time: 0.29806
Total Iteration Time: 4.86077

Cumulative Model Updates: 98,518
Cumulative Timesteps: 821,524,508

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 821524508...
Checkpoint 821524508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 122,481.24292
Policy Entropy: 3.66334
Value Function Loss: 0.02959

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.14699
Policy Update Magnitude: 0.42897
Value Function Update Magnitude: 0.56287

Collected Steps per Second: 21,422.39549
Overall Steps per Second: 10,253.84331

Timestep Collection Time: 2.33475
Timestep Consumption Time: 2.54303
PPO Batch Consumption Time: 0.29659
Total Iteration Time: 4.87778

Cumulative Model Updates: 98,524
Cumulative Timesteps: 821,574,524

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 122,481.24292
Policy Entropy: 3.64981
Value Function Loss: 0.02787

Mean KL Divergence: 0.01097
SB3 Clip Fraction: 0.15535
Policy Update Magnitude: 0.40384
Value Function Update Magnitude: 0.46016

Collected Steps per Second: 21,769.72583
Overall Steps per Second: 10,265.44182

Timestep Collection Time: 2.29851
Timestep Consumption Time: 2.57590
PPO Batch Consumption Time: 0.29887
Total Iteration Time: 4.87441

Cumulative Model Updates: 98,530
Cumulative Timesteps: 821,624,562

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 821624562...
Checkpoint 821624562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 122,481.24292
Policy Entropy: 3.64803
Value Function Loss: 0.02666

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.15202
Policy Update Magnitude: 0.36791
Value Function Update Magnitude: 0.41444

Collected Steps per Second: 20,512.94921
Overall Steps per Second: 10,070.30411

Timestep Collection Time: 2.43865
Timestep Consumption Time: 2.52882
PPO Batch Consumption Time: 0.30297
Total Iteration Time: 4.96748

Cumulative Model Updates: 98,536
Cumulative Timesteps: 821,674,586

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 202,532.28310
Policy Entropy: 3.65363
Value Function Loss: 0.02799

Mean KL Divergence: 0.01095
SB3 Clip Fraction: 0.15668
Policy Update Magnitude: 0.35152
Value Function Update Magnitude: 0.40672

Collected Steps per Second: 20,624.18061
Overall Steps per Second: 10,190.26673

Timestep Collection Time: 2.42521
Timestep Consumption Time: 2.48320
PPO Batch Consumption Time: 0.29803
Total Iteration Time: 4.90841

Cumulative Model Updates: 98,542
Cumulative Timesteps: 821,724,604

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 821724604...
Checkpoint 821724604 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 132,893.02771
Policy Entropy: 3.66049
Value Function Loss: 0.02889

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.14916
Policy Update Magnitude: 0.35197
Value Function Update Magnitude: 0.42891

Collected Steps per Second: 20,704.36971
Overall Steps per Second: 10,174.29332

Timestep Collection Time: 2.41727
Timestep Consumption Time: 2.50180
PPO Batch Consumption Time: 0.28853
Total Iteration Time: 4.91906

Cumulative Model Updates: 98,548
Cumulative Timesteps: 821,774,652

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 132,893.02771
Policy Entropy: 3.66981
Value Function Loss: 0.02851

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.13931
Policy Update Magnitude: 0.36927
Value Function Update Magnitude: 0.48617

Collected Steps per Second: 21,422.35327
Overall Steps per Second: 10,380.87640

Timestep Collection Time: 2.33429
Timestep Consumption Time: 2.48284
PPO Batch Consumption Time: 0.28860
Total Iteration Time: 4.81713

Cumulative Model Updates: 98,554
Cumulative Timesteps: 821,824,658

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 821824658...
Checkpoint 821824658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 132,893.02771
Policy Entropy: 3.66458
Value Function Loss: 0.02702

Mean KL Divergence: 0.01117
SB3 Clip Fraction: 0.15558
Policy Update Magnitude: 0.38608
Value Function Update Magnitude: 0.51529

Collected Steps per Second: 21,433.11686
Overall Steps per Second: 10,334.86782

Timestep Collection Time: 2.33359
Timestep Consumption Time: 2.50595
PPO Batch Consumption Time: 0.29440
Total Iteration Time: 4.83954

Cumulative Model Updates: 98,560
Cumulative Timesteps: 821,874,674

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 136,279.67946
Policy Entropy: 3.66350
Value Function Loss: 0.02782

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.13938
Policy Update Magnitude: 0.40339
Value Function Update Magnitude: 0.62257

Collected Steps per Second: 21,558.42836
Overall Steps per Second: 10,347.44481

Timestep Collection Time: 2.31937
Timestep Consumption Time: 2.51293
PPO Batch Consumption Time: 0.28878
Total Iteration Time: 4.83230

Cumulative Model Updates: 98,566
Cumulative Timesteps: 821,924,676

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 821924676...
Checkpoint 821924676 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 136,279.67946
Policy Entropy: 3.67737
Value Function Loss: 0.02689

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.14896
Policy Update Magnitude: 0.41848
Value Function Update Magnitude: 0.63461

Collected Steps per Second: 21,304.53830
Overall Steps per Second: 10,198.80616

Timestep Collection Time: 2.34729
Timestep Consumption Time: 2.55603
PPO Batch Consumption Time: 0.28836
Total Iteration Time: 4.90332

Cumulative Model Updates: 98,572
Cumulative Timesteps: 821,974,684

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 136,279.67946
Policy Entropy: 3.66938
Value Function Loss: 0.02867

Mean KL Divergence: 0.01061
SB3 Clip Fraction: 0.15013
Policy Update Magnitude: 0.41069
Value Function Update Magnitude: 0.62022

Collected Steps per Second: 21,819.25319
Overall Steps per Second: 10,296.98860

Timestep Collection Time: 2.29238
Timestep Consumption Time: 2.56516
PPO Batch Consumption Time: 0.29728
Total Iteration Time: 4.85754

Cumulative Model Updates: 98,578
Cumulative Timesteps: 822,024,702

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 822024702...
Checkpoint 822024702 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 199,190.03761
Policy Entropy: 3.66664
Value Function Loss: 0.02999

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.14939
Policy Update Magnitude: 0.41711
Value Function Update Magnitude: 0.55827

Collected Steps per Second: 21,377.88259
Overall Steps per Second: 10,213.73546

Timestep Collection Time: 2.33943
Timestep Consumption Time: 2.55712
PPO Batch Consumption Time: 0.29712
Total Iteration Time: 4.89654

Cumulative Model Updates: 98,584
Cumulative Timesteps: 822,074,714

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 214,996.56901
Policy Entropy: 3.63839
Value Function Loss: 0.03696

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.14690
Policy Update Magnitude: 0.43071
Value Function Update Magnitude: 0.54960

Collected Steps per Second: 21,422.48798
Overall Steps per Second: 10,323.67599

Timestep Collection Time: 2.33502
Timestep Consumption Time: 2.51034
PPO Batch Consumption Time: 0.28750
Total Iteration Time: 4.84537

Cumulative Model Updates: 98,590
Cumulative Timesteps: 822,124,736

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 822124736...
Checkpoint 822124736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 214,996.56901
Policy Entropy: 3.64261
Value Function Loss: 0.03766

Mean KL Divergence: 0.01059
SB3 Clip Fraction: 0.14710
Policy Update Magnitude: 0.50174
Value Function Update Magnitude: 0.55694

Collected Steps per Second: 21,348.07085
Overall Steps per Second: 10,164.51219

Timestep Collection Time: 2.34344
Timestep Consumption Time: 2.57839
PPO Batch Consumption Time: 0.29931
Total Iteration Time: 4.92183

Cumulative Model Updates: 98,596
Cumulative Timesteps: 822,174,764

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 214,996.56901
Policy Entropy: 3.64171
Value Function Loss: 0.03563

Mean KL Divergence: 0.01084
SB3 Clip Fraction: 0.15026
Policy Update Magnitude: 0.48516
Value Function Update Magnitude: 0.55130

Collected Steps per Second: 21,173.97854
Overall Steps per Second: 10,409.71028

Timestep Collection Time: 2.36224
Timestep Consumption Time: 2.44270
PPO Batch Consumption Time: 0.28871
Total Iteration Time: 4.80494

Cumulative Model Updates: 98,602
Cumulative Timesteps: 822,224,782

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 822224782...
Checkpoint 822224782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 348,659.44023
Policy Entropy: 3.66789
Value Function Loss: 0.03092

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.14703
Policy Update Magnitude: 0.45447
Value Function Update Magnitude: 0.53186

Collected Steps per Second: 20,677.69187
Overall Steps per Second: 10,187.16751

Timestep Collection Time: 2.41826
Timestep Consumption Time: 2.49027
PPO Batch Consumption Time: 0.29768
Total Iteration Time: 4.90853

Cumulative Model Updates: 98,608
Cumulative Timesteps: 822,274,786

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 164,258.12211
Policy Entropy: 3.67206
Value Function Loss: 0.02896

Mean KL Divergence: 0.01057
SB3 Clip Fraction: 0.14985
Policy Update Magnitude: 0.44204
Value Function Update Magnitude: 0.58092

Collected Steps per Second: 20,688.52195
Overall Steps per Second: 9,907.11716

Timestep Collection Time: 2.41728
Timestep Consumption Time: 2.63060
PPO Batch Consumption Time: 0.31112
Total Iteration Time: 5.04789

Cumulative Model Updates: 98,614
Cumulative Timesteps: 822,324,796

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 822324796...
Checkpoint 822324796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 126,215.89482
Policy Entropy: 3.67631
Value Function Loss: 0.02935

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.14446
Policy Update Magnitude: 0.41707
Value Function Update Magnitude: 0.59096

Collected Steps per Second: 21,615.46008
Overall Steps per Second: 10,419.99469

Timestep Collection Time: 2.31427
Timestep Consumption Time: 2.48650
PPO Batch Consumption Time: 0.28808
Total Iteration Time: 4.80077

Cumulative Model Updates: 98,620
Cumulative Timesteps: 822,374,820

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 126,215.89482
Policy Entropy: 3.65502
Value Function Loss: 0.02600

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.14742
Policy Update Magnitude: 0.38869
Value Function Update Magnitude: 0.58429

Collected Steps per Second: 21,581.22305
Overall Steps per Second: 10,375.42924

Timestep Collection Time: 2.31766
Timestep Consumption Time: 2.50315
PPO Batch Consumption Time: 0.28878
Total Iteration Time: 4.82081

Cumulative Model Updates: 98,626
Cumulative Timesteps: 822,424,838

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 822424838...
Checkpoint 822424838 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 126,215.89482
Policy Entropy: 3.65138
Value Function Loss: 0.02533

Mean KL Divergence: 0.01055
SB3 Clip Fraction: 0.15154
Policy Update Magnitude: 0.36351
Value Function Update Magnitude: 0.47393

Collected Steps per Second: 21,413.27440
Overall Steps per Second: 10,276.09974

Timestep Collection Time: 2.33509
Timestep Consumption Time: 2.53076
PPO Batch Consumption Time: 0.29042
Total Iteration Time: 4.86585

Cumulative Model Updates: 98,632
Cumulative Timesteps: 822,474,840

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 114,489.71847
Policy Entropy: 3.63129
Value Function Loss: 0.02673

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.14314
Policy Update Magnitude: 0.35386
Value Function Update Magnitude: 0.42943

Collected Steps per Second: 21,643.54478
Overall Steps per Second: 10,366.81434

Timestep Collection Time: 2.31127
Timestep Consumption Time: 2.51413
PPO Batch Consumption Time: 0.28824
Total Iteration Time: 4.82540

Cumulative Model Updates: 98,638
Cumulative Timesteps: 822,524,864

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 822524864...
Checkpoint 822524864 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 114,489.71847
Policy Entropy: 3.64794
Value Function Loss: 0.02570

Mean KL Divergence: 0.01083
SB3 Clip Fraction: 0.15416
Policy Update Magnitude: 0.37976
Value Function Update Magnitude: 0.42383

Collected Steps per Second: 21,651.49993
Overall Steps per Second: 10,307.20112

Timestep Collection Time: 2.31042
Timestep Consumption Time: 2.54289
PPO Batch Consumption Time: 0.29448
Total Iteration Time: 4.85331

Cumulative Model Updates: 98,644
Cumulative Timesteps: 822,574,888

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 114,489.71847
Policy Entropy: 3.64816
Value Function Loss: 0.02675

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.14810
Policy Update Magnitude: 0.37252
Value Function Update Magnitude: 0.39972

Collected Steps per Second: 21,587.50887
Overall Steps per Second: 10,313.26523

Timestep Collection Time: 2.31690
Timestep Consumption Time: 2.53278
PPO Batch Consumption Time: 0.28854
Total Iteration Time: 4.84968

Cumulative Model Updates: 98,650
Cumulative Timesteps: 822,624,904

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 822624904...
Checkpoint 822624904 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 114,489.71847
Policy Entropy: 3.68269
Value Function Loss: 0.02185

Mean KL Divergence: 0.01107
SB3 Clip Fraction: 0.15463
Policy Update Magnitude: 0.37554
Value Function Update Magnitude: 0.49043

Collected Steps per Second: 21,658.72414
Overall Steps per Second: 10,309.13407

Timestep Collection Time: 2.30928
Timestep Consumption Time: 2.54234
PPO Batch Consumption Time: 0.29187
Total Iteration Time: 4.85162

Cumulative Model Updates: 98,656
Cumulative Timesteps: 822,674,920

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 114,489.71847
Policy Entropy: 3.66642
Value Function Loss: 0.02193

Mean KL Divergence: 0.01123
SB3 Clip Fraction: 0.15733
Policy Update Magnitude: 0.38473
Value Function Update Magnitude: 0.57550

Collected Steps per Second: 21,566.30649
Overall Steps per Second: 10,376.66419

Timestep Collection Time: 2.31843
Timestep Consumption Time: 2.50007
PPO Batch Consumption Time: 0.28733
Total Iteration Time: 4.81850

Cumulative Model Updates: 98,662
Cumulative Timesteps: 822,724,920

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 822724920...
Checkpoint 822724920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 114,489.71847
Policy Entropy: 3.67034
Value Function Loss: 0.02205

Mean KL Divergence: 0.01077
SB3 Clip Fraction: 0.15345
Policy Update Magnitude: 0.38129
Value Function Update Magnitude: 0.49530

Collected Steps per Second: 21,905.59592
Overall Steps per Second: 10,326.17088

Timestep Collection Time: 2.28362
Timestep Consumption Time: 2.56077
PPO Batch Consumption Time: 0.29723
Total Iteration Time: 4.84439

Cumulative Model Updates: 98,668
Cumulative Timesteps: 822,774,944

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 114,489.71847
Policy Entropy: 3.65498
Value Function Loss: 0.02359

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.15261
Policy Update Magnitude: 0.38543
Value Function Update Magnitude: 0.46238

Collected Steps per Second: 21,511.22641
Overall Steps per Second: 10,334.75154

Timestep Collection Time: 2.32660
Timestep Consumption Time: 2.51609
PPO Batch Consumption Time: 0.28887
Total Iteration Time: 4.84269

Cumulative Model Updates: 98,674
Cumulative Timesteps: 822,824,992

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 822824992...
Checkpoint 822824992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 114,489.71847
Policy Entropy: 3.66194
Value Function Loss: 0.02242

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.15004
Policy Update Magnitude: 0.39067
Value Function Update Magnitude: 0.51752

Collected Steps per Second: 21,685.92731
Overall Steps per Second: 10,342.89232

Timestep Collection Time: 2.30564
Timestep Consumption Time: 2.52859
PPO Batch Consumption Time: 0.29212
Total Iteration Time: 4.83424

Cumulative Model Updates: 98,680
Cumulative Timesteps: 822,874,992

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 138,861.37584
Policy Entropy: 3.65842
Value Function Loss: 0.02490

Mean KL Divergence: 0.01061
SB3 Clip Fraction: 0.15111
Policy Update Magnitude: 0.38392
Value Function Update Magnitude: 0.51317

Collected Steps per Second: 21,508.34410
Overall Steps per Second: 10,145.27350

Timestep Collection Time: 2.32607
Timestep Consumption Time: 2.60529
PPO Batch Consumption Time: 0.30315
Total Iteration Time: 4.93136

Cumulative Model Updates: 98,686
Cumulative Timesteps: 822,925,022

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 822925022...
Checkpoint 822925022 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 112,479.45741
Policy Entropy: 3.66977
Value Function Loss: 0.02490

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.14739
Policy Update Magnitude: 0.39817
Value Function Update Magnitude: 0.47951

Collected Steps per Second: 21,844.11324
Overall Steps per Second: 10,345.31139

Timestep Collection Time: 2.28895
Timestep Consumption Time: 2.54416
PPO Batch Consumption Time: 0.29202
Total Iteration Time: 4.83311

Cumulative Model Updates: 98,692
Cumulative Timesteps: 822,975,022

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 131,411.74461
Policy Entropy: 3.66680
Value Function Loss: 0.02806

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.14483
Policy Update Magnitude: 0.42645
Value Function Update Magnitude: 0.43212

Collected Steps per Second: 20,786.68455
Overall Steps per Second: 10,179.90716

Timestep Collection Time: 2.40664
Timestep Consumption Time: 2.50755
PPO Batch Consumption Time: 0.30091
Total Iteration Time: 4.91419

Cumulative Model Updates: 98,698
Cumulative Timesteps: 823,025,048

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 823025048...
Checkpoint 823025048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,837.88352
Policy Entropy: 3.68531
Value Function Loss: 0.02814

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.14002
Policy Update Magnitude: 0.43234
Value Function Update Magnitude: 0.42390

Collected Steps per Second: 21,002.11344
Overall Steps per Second: 10,263.14391

Timestep Collection Time: 2.38109
Timestep Consumption Time: 2.49149
PPO Batch Consumption Time: 0.30130
Total Iteration Time: 4.87258

Cumulative Model Updates: 98,704
Cumulative Timesteps: 823,075,056

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 144,482.70234
Policy Entropy: 3.68787
Value Function Loss: 0.02794

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.14070
Policy Update Magnitude: 0.46084
Value Function Update Magnitude: 0.46247

Collected Steps per Second: 21,214.73558
Overall Steps per Second: 10,311.29274

Timestep Collection Time: 2.35714
Timestep Consumption Time: 2.49250
PPO Batch Consumption Time: 0.28799
Total Iteration Time: 4.84963

Cumulative Model Updates: 98,710
Cumulative Timesteps: 823,125,062

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 823125062...
Checkpoint 823125062 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40,816.57154
Policy Entropy: 3.70631
Value Function Loss: 0.02568

Mean KL Divergence: 0.01055
SB3 Clip Fraction: 0.14621
Policy Update Magnitude: 0.46508
Value Function Update Magnitude: 0.54643

Collected Steps per Second: 21,636.86215
Overall Steps per Second: 10,326.84133

Timestep Collection Time: 2.31133
Timestep Consumption Time: 2.53139
PPO Batch Consumption Time: 0.29794
Total Iteration Time: 4.84272

Cumulative Model Updates: 98,716
Cumulative Timesteps: 823,175,072

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 254,837.22019
Policy Entropy: 3.68877
Value Function Loss: 0.02834

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.14629
Policy Update Magnitude: 0.45671
Value Function Update Magnitude: 0.49327

Collected Steps per Second: 21,319.35805
Overall Steps per Second: 10,322.23054

Timestep Collection Time: 2.34547
Timestep Consumption Time: 2.49883
PPO Batch Consumption Time: 0.28896
Total Iteration Time: 4.84430

Cumulative Model Updates: 98,722
Cumulative Timesteps: 823,225,076

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 823225076...
Checkpoint 823225076 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 206,418.02481
Policy Entropy: 3.68554
Value Function Loss: 0.02807

Mean KL Divergence: 0.01055
SB3 Clip Fraction: 0.14687
Policy Update Magnitude: 0.45673
Value Function Update Magnitude: 0.44908

Collected Steps per Second: 21,746.11463
Overall Steps per Second: 10,333.96305

Timestep Collection Time: 2.30147
Timestep Consumption Time: 2.54159
PPO Batch Consumption Time: 0.29239
Total Iteration Time: 4.84306

Cumulative Model Updates: 98,728
Cumulative Timesteps: 823,275,124

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 206,418.02481
Policy Entropy: 3.66047
Value Function Loss: 0.02798

Mean KL Divergence: 0.01102
SB3 Clip Fraction: 0.14914
Policy Update Magnitude: 0.44116
Value Function Update Magnitude: 0.45612

Collected Steps per Second: 21,032.79070
Overall Steps per Second: 10,094.49075

Timestep Collection Time: 2.37734
Timestep Consumption Time: 2.57606
PPO Batch Consumption Time: 0.30148
Total Iteration Time: 4.95339

Cumulative Model Updates: 98,734
Cumulative Timesteps: 823,325,126

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 823325126...
Checkpoint 823325126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 466,785.97599
Policy Entropy: 3.65663
Value Function Loss: 0.03166

Mean KL Divergence: 0.01073
SB3 Clip Fraction: 0.14783
Policy Update Magnitude: 0.45849
Value Function Update Magnitude: 0.49019

Collected Steps per Second: 21,190.84769
Overall Steps per Second: 10,166.30051

Timestep Collection Time: 2.36045
Timestep Consumption Time: 2.55972
PPO Batch Consumption Time: 0.29857
Total Iteration Time: 4.92018

Cumulative Model Updates: 98,740
Cumulative Timesteps: 823,375,146

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 106,789.47399
Policy Entropy: 3.66404
Value Function Loss: 0.03649

Mean KL Divergence: 0.01110
SB3 Clip Fraction: 0.15084
Policy Update Magnitude: 0.47878
Value Function Update Magnitude: 0.55708

Collected Steps per Second: 21,509.87209
Overall Steps per Second: 10,173.43225

Timestep Collection Time: 2.32526
Timestep Consumption Time: 2.59108
PPO Batch Consumption Time: 0.29771
Total Iteration Time: 4.91633

Cumulative Model Updates: 98,746
Cumulative Timesteps: 823,425,162

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 823425162...
Checkpoint 823425162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,178.34758
Policy Entropy: 3.67745
Value Function Loss: 0.03544

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.13880
Policy Update Magnitude: 0.48112
Value Function Update Magnitude: 0.51429

Collected Steps per Second: 21,386.34135
Overall Steps per Second: 10,198.52801

Timestep Collection Time: 2.33794
Timestep Consumption Time: 2.56473
PPO Batch Consumption Time: 0.29839
Total Iteration Time: 4.90267

Cumulative Model Updates: 98,752
Cumulative Timesteps: 823,475,162

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81,648.26745
Policy Entropy: 3.68307
Value Function Loss: 0.03433

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.14121
Policy Update Magnitude: 0.53336
Value Function Update Magnitude: 0.76473

Collected Steps per Second: 21,650.36143
Overall Steps per Second: 10,304.84589

Timestep Collection Time: 2.30971
Timestep Consumption Time: 2.54296
PPO Batch Consumption Time: 0.29370
Total Iteration Time: 4.85267

Cumulative Model Updates: 98,758
Cumulative Timesteps: 823,525,168

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 823525168...
Checkpoint 823525168 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,928.70562
Policy Entropy: 3.70058
Value Function Loss: 0.03522

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.14011
Policy Update Magnitude: 0.56556
Value Function Update Magnitude: 0.81648

Collected Steps per Second: 21,665.98666
Overall Steps per Second: 10,188.31723

Timestep Collection Time: 2.30832
Timestep Consumption Time: 2.60044
PPO Batch Consumption Time: 0.30452
Total Iteration Time: 4.90876

Cumulative Model Updates: 98,764
Cumulative Timesteps: 823,575,180

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,558.93908
Policy Entropy: 3.69698
Value Function Loss: 0.03526

Mean KL Divergence: 0.01090
SB3 Clip Fraction: 0.14928
Policy Update Magnitude: 0.57603
Value Function Update Magnitude: 0.73573

Collected Steps per Second: 20,228.67223
Overall Steps per Second: 10,067.35586

Timestep Collection Time: 2.47302
Timestep Consumption Time: 2.49611
PPO Batch Consumption Time: 0.30103
Total Iteration Time: 4.96913

Cumulative Model Updates: 98,770
Cumulative Timesteps: 823,625,206

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 823625206...
Checkpoint 823625206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 406.21965
Policy Entropy: 3.69755
Value Function Loss: 0.03374

Mean KL Divergence: 0.01072
SB3 Clip Fraction: 0.14780
Policy Update Magnitude: 0.51134
Value Function Update Magnitude: 0.60836

Collected Steps per Second: 20,837.44894
Overall Steps per Second: 10,220.23683

Timestep Collection Time: 2.39991
Timestep Consumption Time: 2.49313
PPO Batch Consumption Time: 0.30121
Total Iteration Time: 4.89304

Cumulative Model Updates: 98,776
Cumulative Timesteps: 823,675,214

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 153.30093
Policy Entropy: 3.69527
Value Function Loss: 0.03020

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.13957
Policy Update Magnitude: 0.46521
Value Function Update Magnitude: 0.66400

Collected Steps per Second: 20,849.71792
Overall Steps per Second: 10,354.32801

Timestep Collection Time: 2.39898
Timestep Consumption Time: 2.43166
PPO Batch Consumption Time: 0.28807
Total Iteration Time: 4.83064

Cumulative Model Updates: 98,782
Cumulative Timesteps: 823,725,232

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 823725232...
Checkpoint 823725232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,024.75100
Policy Entropy: 3.72161
Value Function Loss: 0.02847

Mean KL Divergence: 0.01076
SB3 Clip Fraction: 0.14939
Policy Update Magnitude: 0.46595
Value Function Update Magnitude: 0.58204

Collected Steps per Second: 20,828.17996
Overall Steps per Second: 10,253.33867

Timestep Collection Time: 2.40175
Timestep Consumption Time: 2.47706
PPO Batch Consumption Time: 0.28858
Total Iteration Time: 4.87880

Cumulative Model Updates: 98,788
Cumulative Timesteps: 823,775,256

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,513.21517
Policy Entropy: 3.71046
Value Function Loss: 0.02596

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.14186
Policy Update Magnitude: 0.44337
Value Function Update Magnitude: 0.55818

Collected Steps per Second: 21,371.55832
Overall Steps per Second: 10,362.49053

Timestep Collection Time: 2.34003
Timestep Consumption Time: 2.48603
PPO Batch Consumption Time: 0.28851
Total Iteration Time: 4.82606

Cumulative Model Updates: 98,794
Cumulative Timesteps: 823,825,266

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 823825266...
Checkpoint 823825266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 200,307.14056
Policy Entropy: 3.70640
Value Function Loss: 0.02900

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.13552
Policy Update Magnitude: 0.44491
Value Function Update Magnitude: 0.63903

Collected Steps per Second: 21,590.00716
Overall Steps per Second: 10,329.72338

Timestep Collection Time: 2.31663
Timestep Consumption Time: 2.52532
PPO Batch Consumption Time: 0.29576
Total Iteration Time: 4.84195

Cumulative Model Updates: 98,800
Cumulative Timesteps: 823,875,282

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 113,345.09897
Policy Entropy: 3.69842
Value Function Loss: 0.03133

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.14092
Policy Update Magnitude: 0.50547
Value Function Update Magnitude: 0.61442

Collected Steps per Second: 21,379.87171
Overall Steps per Second: 10,355.53507

Timestep Collection Time: 2.33912
Timestep Consumption Time: 2.49019
PPO Batch Consumption Time: 0.28845
Total Iteration Time: 4.82930

Cumulative Model Updates: 98,806
Cumulative Timesteps: 823,925,292

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 823925292...
Checkpoint 823925292 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,526.27748
Policy Entropy: 3.70111
Value Function Loss: 0.03274

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.13866
Policy Update Magnitude: 0.52715
Value Function Update Magnitude: 0.58875

Collected Steps per Second: 21,534.38197
Overall Steps per Second: 10,291.54134

Timestep Collection Time: 2.32280
Timestep Consumption Time: 2.53751
PPO Batch Consumption Time: 0.29198
Total Iteration Time: 4.86030

Cumulative Model Updates: 98,812
Cumulative Timesteps: 823,975,312

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,526.27748
Policy Entropy: 3.69040
Value Function Loss: 0.02939

Mean KL Divergence: 0.01060
SB3 Clip Fraction: 0.14769
Policy Update Magnitude: 0.49942
Value Function Update Magnitude: 0.52668

Collected Steps per Second: 21,458.57121
Overall Steps per Second: 10,187.61046

Timestep Collection Time: 2.33147
Timestep Consumption Time: 2.57940
PPO Batch Consumption Time: 0.29838
Total Iteration Time: 4.91087

Cumulative Model Updates: 98,818
Cumulative Timesteps: 824,025,342

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 824025342...
Checkpoint 824025342 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,526.27748
Policy Entropy: 3.67276
Value Function Loss: 0.02811

Mean KL Divergence: 0.01083
SB3 Clip Fraction: 0.15145
Policy Update Magnitude: 0.45837
Value Function Update Magnitude: 0.45295

Collected Steps per Second: 21,316.09384
Overall Steps per Second: 10,124.97914

Timestep Collection Time: 2.34630
Timestep Consumption Time: 2.59336
PPO Batch Consumption Time: 0.30021
Total Iteration Time: 4.93966

Cumulative Model Updates: 98,824
Cumulative Timesteps: 824,075,356

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,526.27748
Policy Entropy: 3.65382
Value Function Loss: 0.02808

Mean KL Divergence: 0.01069
SB3 Clip Fraction: 0.14593
Policy Update Magnitude: 0.45275
Value Function Update Magnitude: 0.40824

Collected Steps per Second: 21,182.56264
Overall Steps per Second: 10,136.76896

Timestep Collection Time: 2.36119
Timestep Consumption Time: 2.57293
PPO Batch Consumption Time: 0.29795
Total Iteration Time: 4.93412

Cumulative Model Updates: 98,830
Cumulative Timesteps: 824,125,372

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 824125372...
Checkpoint 824125372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 536,276.92443
Policy Entropy: 3.65553
Value Function Loss: 0.03123

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.14163
Policy Update Magnitude: 0.48053
Value Function Update Magnitude: 0.48751

Collected Steps per Second: 21,512.50419
Overall Steps per Second: 10,356.57332

Timestep Collection Time: 2.32497
Timestep Consumption Time: 2.50442
PPO Batch Consumption Time: 0.28903
Total Iteration Time: 4.82940

Cumulative Model Updates: 98,836
Cumulative Timesteps: 824,175,388

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 351,854.56060
Policy Entropy: 3.65741
Value Function Loss: 0.03285

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.13490
Policy Update Magnitude: 0.52944
Value Function Update Magnitude: 0.49596

Collected Steps per Second: 21,068.69460
Overall Steps per Second: 10,154.20410

Timestep Collection Time: 2.37328
Timestep Consumption Time: 2.55098
PPO Batch Consumption Time: 0.29593
Total Iteration Time: 4.92427

Cumulative Model Updates: 98,842
Cumulative Timesteps: 824,225,390

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 824225390...
Checkpoint 824225390 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 426,445.25965
Policy Entropy: 3.66281
Value Function Loss: 0.03465

Mean KL Divergence: 0.01058
SB3 Clip Fraction: 0.14594
Policy Update Magnitude: 0.55423
Value Function Update Magnitude: 0.50623

Collected Steps per Second: 21,062.08338
Overall Steps per Second: 10,200.80318

Timestep Collection Time: 2.37526
Timestep Consumption Time: 2.52906
PPO Batch Consumption Time: 0.29231
Total Iteration Time: 4.90432

Cumulative Model Updates: 98,848
Cumulative Timesteps: 824,275,418

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 416,958.35400
Policy Entropy: 3.65796
Value Function Loss: 0.03746

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.14083
Policy Update Magnitude: 0.54989
Value Function Update Magnitude: 0.56049

Collected Steps per Second: 20,913.15423
Overall Steps per Second: 10,344.62440

Timestep Collection Time: 2.39247
Timestep Consumption Time: 2.44425
PPO Batch Consumption Time: 0.28879
Total Iteration Time: 4.83671

Cumulative Model Updates: 98,854
Cumulative Timesteps: 824,325,452

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 824325452...
Checkpoint 824325452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 342,097.92438
Policy Entropy: 3.68031
Value Function Loss: 0.03504

Mean KL Divergence: 0.01090
SB3 Clip Fraction: 0.14565
Policy Update Magnitude: 0.59124
Value Function Update Magnitude: 0.67529

Collected Steps per Second: 20,937.64045
Overall Steps per Second: 10,313.23854

Timestep Collection Time: 2.38900
Timestep Consumption Time: 2.46108
PPO Batch Consumption Time: 0.29374
Total Iteration Time: 4.85008

Cumulative Model Updates: 98,860
Cumulative Timesteps: 824,375,472

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 146,111.32211
Policy Entropy: 3.69628
Value Function Loss: 0.03512

Mean KL Divergence: 0.01140
SB3 Clip Fraction: 0.15276
Policy Update Magnitude: 0.60641
Value Function Update Magnitude: 0.75765

Collected Steps per Second: 20,737.15564
Overall Steps per Second: 10,229.13767

Timestep Collection Time: 2.41229
Timestep Consumption Time: 2.47806
PPO Batch Consumption Time: 0.29673
Total Iteration Time: 4.89034

Cumulative Model Updates: 98,866
Cumulative Timesteps: 824,425,496

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 824425496...
Checkpoint 824425496 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,396.71321
Policy Entropy: 3.70185
Value Function Loss: 0.03494

Mean KL Divergence: 0.01053
SB3 Clip Fraction: 0.14082
Policy Update Magnitude: 0.58841
Value Function Update Magnitude: 0.72101

Collected Steps per Second: 20,848.12097
Overall Steps per Second: 10,101.86974

Timestep Collection Time: 2.39868
Timestep Consumption Time: 2.55169
PPO Batch Consumption Time: 0.29949
Total Iteration Time: 4.95037

Cumulative Model Updates: 98,872
Cumulative Timesteps: 824,475,504

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,249.90995
Policy Entropy: 3.69262
Value Function Loss: 0.03558

Mean KL Divergence: 0.01218
SB3 Clip Fraction: 0.15646
Policy Update Magnitude: 0.61105
Value Function Update Magnitude: 0.73820

Collected Steps per Second: 21,750.91140
Overall Steps per Second: 10,381.38954

Timestep Collection Time: 2.29921
Timestep Consumption Time: 2.51806
PPO Batch Consumption Time: 0.29273
Total Iteration Time: 4.81727

Cumulative Model Updates: 98,878
Cumulative Timesteps: 824,525,514

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 824525514...
Checkpoint 824525514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 304,166.30160
Policy Entropy: 3.67650
Value Function Loss: 0.03852

Mean KL Divergence: 0.01371
SB3 Clip Fraction: 0.17794
Policy Update Magnitude: 0.69823
Value Function Update Magnitude: 0.71558

Collected Steps per Second: 21,449.40677
Overall Steps per Second: 10,221.88753

Timestep Collection Time: 2.33107
Timestep Consumption Time: 2.56040
PPO Batch Consumption Time: 0.30267
Total Iteration Time: 4.89146

Cumulative Model Updates: 98,884
Cumulative Timesteps: 824,575,514

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 543,397.90277
Policy Entropy: 3.69768
Value Function Loss: 0.03577

Mean KL Divergence: 0.02417
SB3 Clip Fraction: 0.26162
Policy Update Magnitude: 0.64373
Value Function Update Magnitude: 0.70954

Collected Steps per Second: 21,640.81839
Overall Steps per Second: 10,337.24983

Timestep Collection Time: 2.31165
Timestep Consumption Time: 2.52774
PPO Batch Consumption Time: 0.28878
Total Iteration Time: 4.83939

Cumulative Model Updates: 98,890
Cumulative Timesteps: 824,625,540

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 824625540...
Checkpoint 824625540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 213,952.41812
Policy Entropy: 3.71350
Value Function Loss: 0.03383

Mean KL Divergence: 0.01638
SB3 Clip Fraction: 0.20727
Policy Update Magnitude: 0.57511
Value Function Update Magnitude: 0.71480

Collected Steps per Second: 21,647.85112
Overall Steps per Second: 10,316.70311

Timestep Collection Time: 2.31025
Timestep Consumption Time: 2.53742
PPO Batch Consumption Time: 0.29485
Total Iteration Time: 4.84767

Cumulative Model Updates: 98,896
Cumulative Timesteps: 824,675,552

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 213,952.41812
Policy Entropy: 3.71603
Value Function Loss: 0.02953

Mean KL Divergence: 0.01391
SB3 Clip Fraction: 0.18081
Policy Update Magnitude: 0.50308
Value Function Update Magnitude: 0.68911

Collected Steps per Second: 21,661.10337
Overall Steps per Second: 10,374.73243

Timestep Collection Time: 2.30829
Timestep Consumption Time: 2.51112
PPO Batch Consumption Time: 0.28831
Total Iteration Time: 4.81940

Cumulative Model Updates: 98,902
Cumulative Timesteps: 824,725,552

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 824725552...
Checkpoint 824725552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 213,952.41812
Policy Entropy: 3.71141
Value Function Loss: 0.02436

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.11453
Policy Update Magnitude: 0.55098
Value Function Update Magnitude: 0.70599

Collected Steps per Second: 21,465.27436
Overall Steps per Second: 10,287.58318

Timestep Collection Time: 2.33121
Timestep Consumption Time: 2.53291
PPO Batch Consumption Time: 0.29318
Total Iteration Time: 4.86412

Cumulative Model Updates: 98,908
Cumulative Timesteps: 824,775,592

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 213,952.41812
Policy Entropy: 3.69900
Value Function Loss: 0.02465

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.12679
Policy Update Magnitude: 0.54600
Value Function Update Magnitude: 0.51315

Collected Steps per Second: 21,811.52723
Overall Steps per Second: 10,397.87851

Timestep Collection Time: 2.29310
Timestep Consumption Time: 2.51711
PPO Batch Consumption Time: 0.28901
Total Iteration Time: 4.81021

Cumulative Model Updates: 98,914
Cumulative Timesteps: 824,825,608

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 824825608...
Checkpoint 824825608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 213,952.41812
Policy Entropy: 3.68381
Value Function Loss: 0.02715

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.12603
Policy Update Magnitude: 0.57523
Value Function Update Magnitude: 0.43384

Collected Steps per Second: 20,884.29093
Overall Steps per Second: 10,071.75070

Timestep Collection Time: 2.39501
Timestep Consumption Time: 2.57116
PPO Batch Consumption Time: 0.30182
Total Iteration Time: 4.96617

Cumulative Model Updates: 98,920
Cumulative Timesteps: 824,875,626

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 259,210.59932
Policy Entropy: 3.68154
Value Function Loss: 0.03528

Mean KL Divergence: 0.01485
SB3 Clip Fraction: 0.19174
Policy Update Magnitude: 0.59364
Value Function Update Magnitude: 0.47745

Collected Steps per Second: 20,017.64450
Overall Steps per Second: 10,123.25990

Timestep Collection Time: 2.49880
Timestep Consumption Time: 2.44230
PPO Batch Consumption Time: 0.28869
Total Iteration Time: 4.94110

Cumulative Model Updates: 98,926
Cumulative Timesteps: 824,925,646

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 824925646...
Checkpoint 824925646 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 345,435.87534
Policy Entropy: 3.67864
Value Function Loss: 0.04267

Mean KL Divergence: 0.02330
SB3 Clip Fraction: 0.24234
Policy Update Magnitude: 0.59261
Value Function Update Magnitude: 0.52499

Collected Steps per Second: 20,512.76755
Overall Steps per Second: 10,285.97666

Timestep Collection Time: 2.43994
Timestep Consumption Time: 2.42590
PPO Batch Consumption Time: 0.28860
Total Iteration Time: 4.86585

Cumulative Model Updates: 98,932
Cumulative Timesteps: 824,975,696

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 120,473.48102
Policy Entropy: 3.70581
Value Function Loss: 0.04321

Mean KL Divergence: 0.01741
SB3 Clip Fraction: 0.20295
Policy Update Magnitude: 0.61146
Value Function Update Magnitude: 0.61203

Collected Steps per Second: 19,885.50406
Overall Steps per Second: 9,960.10640

Timestep Collection Time: 2.51480
Timestep Consumption Time: 2.50603
PPO Batch Consumption Time: 0.29090
Total Iteration Time: 5.02083

Cumulative Model Updates: 98,938
Cumulative Timesteps: 825,025,704

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 825025704...
Checkpoint 825025704 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 120,473.48102
Policy Entropy: 3.69234
Value Function Loss: 0.04576

Mean KL Divergence: 0.01531
SB3 Clip Fraction: 0.18743
Policy Update Magnitude: 0.68149
Value Function Update Magnitude: 0.59951

Collected Steps per Second: 19,003.98457
Overall Steps per Second: 9,555.01550

Timestep Collection Time: 2.63261
Timestep Consumption Time: 2.60339
PPO Batch Consumption Time: 0.30109
Total Iteration Time: 5.23599

Cumulative Model Updates: 98,944
Cumulative Timesteps: 825,075,734

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 187,006.29464
Policy Entropy: 3.69349
Value Function Loss: 0.04273

Mean KL Divergence: 0.01145
SB3 Clip Fraction: 0.14698
Policy Update Magnitude: 0.83190
Value Function Update Magnitude: 0.55266

Collected Steps per Second: 21,317.02671
Overall Steps per Second: 10,333.12766

Timestep Collection Time: 2.34611
Timestep Consumption Time: 2.49386
PPO Batch Consumption Time: 0.28854
Total Iteration Time: 4.83997

Cumulative Model Updates: 98,950
Cumulative Timesteps: 825,125,746

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 825125746...
Checkpoint 825125746 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 65,218.38797
Policy Entropy: 3.70388
Value Function Loss: 0.03811

Mean KL Divergence: 0.01209
SB3 Clip Fraction: 0.15719
Policy Update Magnitude: 0.82950
Value Function Update Magnitude: 0.59029

Collected Steps per Second: 21,252.77636
Overall Steps per Second: 10,337.90304

Timestep Collection Time: 2.35263
Timestep Consumption Time: 2.48394
PPO Batch Consumption Time: 0.28993
Total Iteration Time: 4.83657

Cumulative Model Updates: 98,956
Cumulative Timesteps: 825,175,746

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42,782.08570
Policy Entropy: 3.71093
Value Function Loss: 0.03365

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.11578
Policy Update Magnitude: 0.78050
Value Function Update Magnitude: 0.78566

Collected Steps per Second: 21,807.85086
Overall Steps per Second: 10,359.75160

Timestep Collection Time: 2.29284
Timestep Consumption Time: 2.53372
PPO Batch Consumption Time: 0.28928
Total Iteration Time: 4.82656

Cumulative Model Updates: 98,962
Cumulative Timesteps: 825,225,748

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 825225748...
Checkpoint 825225748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,782.08570
Policy Entropy: 3.67775
Value Function Loss: 0.03442

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.12882
Policy Update Magnitude: 0.71306
Value Function Update Magnitude: 0.68473

Collected Steps per Second: 21,469.14327
Overall Steps per Second: 10,288.42787

Timestep Collection Time: 2.33013
Timestep Consumption Time: 2.53222
PPO Batch Consumption Time: 0.29309
Total Iteration Time: 4.86236

Cumulative Model Updates: 98,968
Cumulative Timesteps: 825,275,774

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42,782.08570
Policy Entropy: 3.64940
Value Function Loss: 0.03146

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.11175
Policy Update Magnitude: 0.63073
Value Function Update Magnitude: 0.51528

Collected Steps per Second: 21,562.85672
Overall Steps per Second: 10,342.31876

Timestep Collection Time: 2.32019
Timestep Consumption Time: 2.51721
PPO Batch Consumption Time: 0.28915
Total Iteration Time: 4.83741

Cumulative Model Updates: 98,974
Cumulative Timesteps: 825,325,804

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 825325804...
Checkpoint 825325804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,782.08570
Policy Entropy: 3.64396
Value Function Loss: 0.03494

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.12724
Policy Update Magnitude: 0.58714
Value Function Update Magnitude: 0.42237

Collected Steps per Second: 21,360.28089
Overall Steps per Second: 10,319.86017

Timestep Collection Time: 2.34201
Timestep Consumption Time: 2.50554
PPO Batch Consumption Time: 0.28740
Total Iteration Time: 4.84755

Cumulative Model Updates: 98,980
Cumulative Timesteps: 825,375,830

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 94,303.81857
Policy Entropy: 3.62795
Value Function Loss: 0.03723

Mean KL Divergence: 0.01816
SB3 Clip Fraction: 0.22411
Policy Update Magnitude: 0.51555
Value Function Update Magnitude: 0.38097

Collected Steps per Second: 21,109.03218
Overall Steps per Second: 9,999.82022

Timestep Collection Time: 2.36884
Timestep Consumption Time: 2.63165
PPO Batch Consumption Time: 0.30172
Total Iteration Time: 5.00049

Cumulative Model Updates: 98,986
Cumulative Timesteps: 825,425,834

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 825425834...
Checkpoint 825425834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 61,873.90833
Policy Entropy: 3.63703
Value Function Loss: 0.04126

Mean KL Divergence: 0.01354
SB3 Clip Fraction: 0.17740
Policy Update Magnitude: 0.50490
Value Function Update Magnitude: 0.40233

Collected Steps per Second: 20,815.53961
Overall Steps per Second: 9,977.99235

Timestep Collection Time: 2.40253
Timestep Consumption Time: 2.60950
PPO Batch Consumption Time: 0.30435
Total Iteration Time: 5.01203

Cumulative Model Updates: 98,992
Cumulative Timesteps: 825,475,844

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 428,250.09885
Policy Entropy: 3.63624
Value Function Loss: 0.04960

Mean KL Divergence: 0.01215
SB3 Clip Fraction: 0.15467
Policy Update Magnitude: 0.50725
Value Function Update Magnitude: 0.43588

Collected Steps per Second: 21,481.81675
Overall Steps per Second: 10,297.52476

Timestep Collection Time: 2.32848
Timestep Consumption Time: 2.52900
PPO Batch Consumption Time: 0.28704
Total Iteration Time: 4.85748

Cumulative Model Updates: 98,998
Cumulative Timesteps: 825,525,864

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 825525864...
Checkpoint 825525864 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 72,632.67902
Policy Entropy: 3.63668
Value Function Loss: 0.05101

Mean KL Divergence: 0.01160
SB3 Clip Fraction: 0.14512
Policy Update Magnitude: 0.57218
Value Function Update Magnitude: 0.47997

Collected Steps per Second: 21,298.27427
Overall Steps per Second: 10,246.64099

Timestep Collection Time: 2.34883
Timestep Consumption Time: 2.53336
PPO Batch Consumption Time: 0.29195
Total Iteration Time: 4.88219

Cumulative Model Updates: 99,004
Cumulative Timesteps: 825,575,890

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,336.20133
Policy Entropy: 3.64328
Value Function Loss: 0.04644

Mean KL Divergence: 0.01148
SB3 Clip Fraction: 0.14812
Policy Update Magnitude: 0.60111
Value Function Update Magnitude: 0.46628

Collected Steps per Second: 20,997.36387
Overall Steps per Second: 10,337.46811

Timestep Collection Time: 2.38220
Timestep Consumption Time: 2.45651
PPO Batch Consumption Time: 0.28907
Total Iteration Time: 4.83871

Cumulative Model Updates: 99,010
Cumulative Timesteps: 825,625,910

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 825625910...
Checkpoint 825625910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,466.26060
Policy Entropy: 3.64786
Value Function Loss: 0.04354

Mean KL Divergence: 0.01142
SB3 Clip Fraction: 0.14690
Policy Update Magnitude: 0.56896
Value Function Update Magnitude: 0.39493

Collected Steps per Second: 20,818.40568
Overall Steps per Second: 10,283.16649

Timestep Collection Time: 2.40326
Timestep Consumption Time: 2.46217
PPO Batch Consumption Time: 0.29255
Total Iteration Time: 4.86543

Cumulative Model Updates: 99,016
Cumulative Timesteps: 825,675,942

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,466.26060
Policy Entropy: 3.65310
Value Function Loss: 0.04068

Mean KL Divergence: 0.01071
SB3 Clip Fraction: 0.14269
Policy Update Magnitude: 0.52785
Value Function Update Magnitude: 0.35976

Collected Steps per Second: 20,624.70640
Overall Steps per Second: 10,158.66296

Timestep Collection Time: 2.42573
Timestep Consumption Time: 2.49913
PPO Batch Consumption Time: 0.29942
Total Iteration Time: 4.92486

Cumulative Model Updates: 99,022
Cumulative Timesteps: 825,725,972

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 825725972...
Checkpoint 825725972 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,758.88740
Policy Entropy: 3.63968
Value Function Loss: 0.04794

Mean KL Divergence: 0.01161
SB3 Clip Fraction: 0.14751
Policy Update Magnitude: 0.53279
Value Function Update Magnitude: 0.33275

Collected Steps per Second: 20,340.06452
Overall Steps per Second: 10,147.76589

Timestep Collection Time: 2.46056
Timestep Consumption Time: 2.47136
PPO Batch Consumption Time: 0.28667
Total Iteration Time: 4.93192

Cumulative Model Updates: 99,028
Cumulative Timesteps: 825,776,020

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 561,168.45280
Policy Entropy: 3.65491
Value Function Loss: 0.04675

Mean KL Divergence: 0.01176
SB3 Clip Fraction: 0.14907
Policy Update Magnitude: 0.59695
Value Function Update Magnitude: 0.44648

Collected Steps per Second: 21,226.99010
Overall Steps per Second: 10,309.58927

Timestep Collection Time: 2.35766
Timestep Consumption Time: 2.49666
PPO Batch Consumption Time: 0.28863
Total Iteration Time: 4.85432

Cumulative Model Updates: 99,034
Cumulative Timesteps: 825,826,066

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 825826066...
Checkpoint 825826066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 454,547.12676
Policy Entropy: 3.63709
Value Function Loss: 0.05272

Mean KL Divergence: 0.01134
SB3 Clip Fraction: 0.14448
Policy Update Magnitude: 0.61127
Value Function Update Magnitude: 0.50410

Collected Steps per Second: 21,059.80613
Overall Steps per Second: 10,290.73815

Timestep Collection Time: 2.37448
Timestep Consumption Time: 2.48485
PPO Batch Consumption Time: 0.28864
Total Iteration Time: 4.85932

Cumulative Model Updates: 99,040
Cumulative Timesteps: 825,876,072

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 454,547.12676
Policy Entropy: 3.63772
Value Function Loss: 0.04653

Mean KL Divergence: 0.01069
SB3 Clip Fraction: 0.13782
Policy Update Magnitude: 0.68647
Value Function Update Magnitude: 0.52014

Collected Steps per Second: 20,981.97682
Overall Steps per Second: 10,075.94554

Timestep Collection Time: 2.38357
Timestep Consumption Time: 2.57993
PPO Batch Consumption Time: 0.29847
Total Iteration Time: 4.96350

Cumulative Model Updates: 99,046
Cumulative Timesteps: 825,926,084

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 825926084...
Checkpoint 825926084 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 246,761.79693
Policy Entropy: 3.62781
Value Function Loss: 0.05077

Mean KL Divergence: 0.01122
SB3 Clip Fraction: 0.14207
Policy Update Magnitude: 0.68884
Value Function Update Magnitude: 0.47549

Collected Steps per Second: 20,816.30002
Overall Steps per Second: 10,169.95774

Timestep Collection Time: 2.40350
Timestep Consumption Time: 2.51609
PPO Batch Consumption Time: 0.28852
Total Iteration Time: 4.91959

Cumulative Model Updates: 99,052
Cumulative Timesteps: 825,976,116

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 401,640.83447
Policy Entropy: 3.63818
Value Function Loss: 0.05211

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.13512
Policy Update Magnitude: 0.68461
Value Function Update Magnitude: 0.42475

Collected Steps per Second: 21,243.58445
Overall Steps per Second: 10,111.52058

Timestep Collection Time: 2.35516
Timestep Consumption Time: 2.59286
PPO Batch Consumption Time: 0.30096
Total Iteration Time: 4.94802

Cumulative Model Updates: 99,058
Cumulative Timesteps: 826,026,148

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 826026148...
Checkpoint 826026148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 656,578.51594
Policy Entropy: 3.65055
Value Function Loss: 0.05056

Mean KL Divergence: 0.01067
SB3 Clip Fraction: 0.13872
Policy Update Magnitude: 0.66022
Value Function Update Magnitude: 0.43372

Collected Steps per Second: 21,028.68308
Overall Steps per Second: 10,170.92660

Timestep Collection Time: 2.37809
Timestep Consumption Time: 2.53867
PPO Batch Consumption Time: 0.29173
Total Iteration Time: 4.91676

Cumulative Model Updates: 99,064
Cumulative Timesteps: 826,076,156

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 601,139.82770
Policy Entropy: 3.64514
Value Function Loss: 0.05197

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.13426
Policy Update Magnitude: 0.60828
Value Function Update Magnitude: 0.45980

Collected Steps per Second: 21,233.21934
Overall Steps per Second: 10,093.55544

Timestep Collection Time: 2.35612
Timestep Consumption Time: 2.60031
PPO Batch Consumption Time: 0.30025
Total Iteration Time: 4.95643

Cumulative Model Updates: 99,070
Cumulative Timesteps: 826,126,184

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 826126184...
Checkpoint 826126184 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 209,609.64147
Policy Entropy: 3.66823
Value Function Loss: 0.04189

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.13604
Policy Update Magnitude: 0.57349
Value Function Update Magnitude: 0.54280

Collected Steps per Second: 21,006.67978
Overall Steps per Second: 10,205.55189

Timestep Collection Time: 2.38048
Timestep Consumption Time: 2.51940
PPO Batch Consumption Time: 0.29153
Total Iteration Time: 4.89988

Cumulative Model Updates: 99,076
Cumulative Timesteps: 826,176,190

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 201,233.80360
Policy Entropy: 3.66195
Value Function Loss: 0.04203

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.13402
Policy Update Magnitude: 0.54834
Value Function Update Magnitude: 0.62465

Collected Steps per Second: 21,366.58658
Overall Steps per Second: 10,305.64080

Timestep Collection Time: 2.34066
Timestep Consumption Time: 2.51221
PPO Batch Consumption Time: 0.28878
Total Iteration Time: 4.85288

Cumulative Model Updates: 99,082
Cumulative Timesteps: 826,226,202

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 826226202...
Checkpoint 826226202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 308,534.79738
Policy Entropy: 3.67887
Value Function Loss: 0.03641

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.13567
Policy Update Magnitude: 0.51488
Value Function Update Magnitude: 0.56346

Collected Steps per Second: 21,670.72036
Overall Steps per Second: 10,323.66958

Timestep Collection Time: 2.30855
Timestep Consumption Time: 2.53740
PPO Batch Consumption Time: 0.29361
Total Iteration Time: 4.84595

Cumulative Model Updates: 99,088
Cumulative Timesteps: 826,276,230

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 531,799.36348
Policy Entropy: 3.66980
Value Function Loss: 0.04032

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.14166
Policy Update Magnitude: 0.51377
Value Function Update Magnitude: 0.53302

Collected Steps per Second: 21,551.92663
Overall Steps per Second: 10,362.14372

Timestep Collection Time: 2.32026
Timestep Consumption Time: 2.50558
PPO Batch Consumption Time: 0.28837
Total Iteration Time: 4.82584

Cumulative Model Updates: 99,094
Cumulative Timesteps: 826,326,236

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 826326236...
Checkpoint 826326236 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 185,438.67378
Policy Entropy: 3.68749
Value Function Loss: 0.03685

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.14130
Policy Update Magnitude: 0.50917
Value Function Update Magnitude: 0.64984

Collected Steps per Second: 21,554.76135
Overall Steps per Second: 10,297.91245

Timestep Collection Time: 2.32106
Timestep Consumption Time: 2.53720
PPO Batch Consumption Time: 0.29189
Total Iteration Time: 4.85827

Cumulative Model Updates: 99,100
Cumulative Timesteps: 826,376,266

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 108,251.35913
Policy Entropy: 3.67488
Value Function Loss: 0.04101

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.13837
Policy Update Magnitude: 0.51260
Value Function Update Magnitude: 0.72905

Collected Steps per Second: 21,514.39289
Overall Steps per Second: 10,336.86642

Timestep Collection Time: 2.32523
Timestep Consumption Time: 2.51434
PPO Batch Consumption Time: 0.28915
Total Iteration Time: 4.83957

Cumulative Model Updates: 99,106
Cumulative Timesteps: 826,426,292

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 826426292...
Checkpoint 826426292 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,777.40281
Policy Entropy: 3.70643
Value Function Loss: 0.04099

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.14181
Policy Update Magnitude: 0.52261
Value Function Update Magnitude: 0.76084

Collected Steps per Second: 20,993.15387
Overall Steps per Second: 10,306.48174

Timestep Collection Time: 2.38278
Timestep Consumption Time: 2.47067
PPO Batch Consumption Time: 0.29327
Total Iteration Time: 4.85345

Cumulative Model Updates: 99,112
Cumulative Timesteps: 826,476,314

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62,815.43254
Policy Entropy: 3.70286
Value Function Loss: 0.04184

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.14368
Policy Update Magnitude: 0.50897
Value Function Update Magnitude: 0.88667

Collected Steps per Second: 20,886.02157
Overall Steps per Second: 10,370.32853

Timestep Collection Time: 2.39423
Timestep Consumption Time: 2.42779
PPO Batch Consumption Time: 0.28789
Total Iteration Time: 4.82203

Cumulative Model Updates: 99,118
Cumulative Timesteps: 826,526,320

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 826526320...
Checkpoint 826526320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,515.51405
Policy Entropy: 3.73350
Value Function Loss: 0.03645

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.13738
Policy Update Magnitude: 0.48160
Value Function Update Magnitude: 0.69247

Collected Steps per Second: 20,831.47608
Overall Steps per Second: 10,328.85696

Timestep Collection Time: 2.40050
Timestep Consumption Time: 2.44089
PPO Batch Consumption Time: 0.29193
Total Iteration Time: 4.84139

Cumulative Model Updates: 99,124
Cumulative Timesteps: 826,576,326

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 119,537.77321
Policy Entropy: 3.71121
Value Function Loss: 0.03643

Mean KL Divergence: 0.01058
SB3 Clip Fraction: 0.14527
Policy Update Magnitude: 0.47187
Value Function Update Magnitude: 0.63782

Collected Steps per Second: 21,031.75798
Overall Steps per Second: 10,369.16328

Timestep Collection Time: 2.37802
Timestep Consumption Time: 2.44532
PPO Batch Consumption Time: 0.28869
Total Iteration Time: 4.82334

Cumulative Model Updates: 99,130
Cumulative Timesteps: 826,626,340

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 826626340...
Checkpoint 826626340 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 96,828.53582
Policy Entropy: 3.69412
Value Function Loss: 0.03619

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.13931
Policy Update Magnitude: 0.44924
Value Function Update Magnitude: 0.63024

Collected Steps per Second: 20,872.90171
Overall Steps per Second: 10,234.35955

Timestep Collection Time: 2.39564
Timestep Consumption Time: 2.49025
PPO Batch Consumption Time: 0.28883
Total Iteration Time: 4.88589

Cumulative Model Updates: 99,136
Cumulative Timesteps: 826,676,344

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 217,887.77855
Policy Entropy: 3.69230
Value Function Loss: 0.03784

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.14582
Policy Update Magnitude: 0.46214
Value Function Update Magnitude: 0.58175

Collected Steps per Second: 21,577.66441
Overall Steps per Second: 10,407.29831

Timestep Collection Time: 2.31832
Timestep Consumption Time: 2.48830
PPO Batch Consumption Time: 0.28853
Total Iteration Time: 4.80663

Cumulative Model Updates: 99,142
Cumulative Timesteps: 826,726,368

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 826726368...
Checkpoint 826726368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,858.64916
Policy Entropy: 3.68809
Value Function Loss: 0.03498

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.14435
Policy Update Magnitude: 0.46550
Value Function Update Magnitude: 0.57518

Collected Steps per Second: 21,137.69186
Overall Steps per Second: 10,290.75222

Timestep Collection Time: 2.36677
Timestep Consumption Time: 2.49468
PPO Batch Consumption Time: 0.29215
Total Iteration Time: 4.86145

Cumulative Model Updates: 99,148
Cumulative Timesteps: 826,776,396

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,525.52295
Policy Entropy: 3.70383
Value Function Loss: 0.03201

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.14312
Policy Update Magnitude: 0.45568
Value Function Update Magnitude: 0.57417

Collected Steps per Second: 21,318.97804
Overall Steps per Second: 10,195.38082

Timestep Collection Time: 2.34617
Timestep Consumption Time: 2.55977
PPO Batch Consumption Time: 0.29700
Total Iteration Time: 4.90595

Cumulative Model Updates: 99,154
Cumulative Timesteps: 826,826,414

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 826826414...
Checkpoint 826826414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,525.52295
Policy Entropy: 3.69055
Value Function Loss: 0.02849

Mean KL Divergence: 0.01077
SB3 Clip Fraction: 0.15242
Policy Update Magnitude: 0.42432
Value Function Update Magnitude: 0.55117

Collected Steps per Second: 21,452.23829
Overall Steps per Second: 10,202.63133

Timestep Collection Time: 2.33132
Timestep Consumption Time: 2.57055
PPO Batch Consumption Time: 0.29819
Total Iteration Time: 4.90187

Cumulative Model Updates: 99,160
Cumulative Timesteps: 826,876,426

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,525.52295
Policy Entropy: 3.68413
Value Function Loss: 0.02556

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.14661
Policy Update Magnitude: 0.38497
Value Function Update Magnitude: 0.47178

Collected Steps per Second: 21,758.07338
Overall Steps per Second: 10,314.31399

Timestep Collection Time: 2.29901
Timestep Consumption Time: 2.55076
PPO Batch Consumption Time: 0.29399
Total Iteration Time: 4.84977

Cumulative Model Updates: 99,166
Cumulative Timesteps: 826,926,448

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 826926448...
Checkpoint 826926448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 117,058.12250
Policy Entropy: 3.68747
Value Function Loss: 0.02382

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.15175
Policy Update Magnitude: 0.34264
Value Function Update Magnitude: 0.41432

Collected Steps per Second: 21,573.36786
Overall Steps per Second: 10,223.14932

Timestep Collection Time: 2.31990
Timestep Consumption Time: 2.57566
PPO Batch Consumption Time: 0.30028
Total Iteration Time: 4.89556

Cumulative Model Updates: 99,172
Cumulative Timesteps: 826,976,496

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47,801.08699
Policy Entropy: 3.68750
Value Function Loss: 0.02809

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.14900
Policy Update Magnitude: 0.33487
Value Function Update Magnitude: 0.41859

Collected Steps per Second: 21,427.92905
Overall Steps per Second: 10,311.19981

Timestep Collection Time: 2.33396
Timestep Consumption Time: 2.51630
PPO Batch Consumption Time: 0.28904
Total Iteration Time: 4.85026

Cumulative Model Updates: 99,178
Cumulative Timesteps: 827,026,508

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 827026508...
Checkpoint 827026508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,722.48312
Policy Entropy: 3.69315
Value Function Loss: 0.03044

Mean KL Divergence: 0.01073
SB3 Clip Fraction: 0.15130
Policy Update Magnitude: 0.38651
Value Function Update Magnitude: 0.46415

Collected Steps per Second: 21,878.84876
Overall Steps per Second: 10,352.23890

Timestep Collection Time: 2.28677
Timestep Consumption Time: 2.54619
PPO Batch Consumption Time: 0.29505
Total Iteration Time: 4.83296

Cumulative Model Updates: 99,184
Cumulative Timesteps: 827,076,540

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,722.48312
Policy Entropy: 3.66690
Value Function Loss: 0.03325

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.14876
Policy Update Magnitude: 0.41198
Value Function Update Magnitude: 0.49603

Collected Steps per Second: 21,603.13417
Overall Steps per Second: 10,358.66333

Timestep Collection Time: 2.31485
Timestep Consumption Time: 2.51280
PPO Batch Consumption Time: 0.28838
Total Iteration Time: 4.82765

Cumulative Model Updates: 99,190
Cumulative Timesteps: 827,126,548

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 827126548...
Checkpoint 827126548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 72,460.18828
Policy Entropy: 3.66681
Value Function Loss: 0.02961

Mean KL Divergence: 0.01078
SB3 Clip Fraction: 0.15477
Policy Update Magnitude: 0.40610
Value Function Update Magnitude: 0.50404

Collected Steps per Second: 21,547.59012
Overall Steps per Second: 10,340.07695

Timestep Collection Time: 2.32147
Timestep Consumption Time: 2.51622
PPO Batch Consumption Time: 0.28649
Total Iteration Time: 4.83768

Cumulative Model Updates: 99,196
Cumulative Timesteps: 827,176,570

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 72,460.18828
Policy Entropy: 3.65372
Value Function Loss: 0.02912

Mean KL Divergence: 0.01138
SB3 Clip Fraction: 0.15853
Policy Update Magnitude: 0.39607
Value Function Update Magnitude: 0.48824

Collected Steps per Second: 21,659.05184
Overall Steps per Second: 10,364.85199

Timestep Collection Time: 2.30887
Timestep Consumption Time: 2.51589
PPO Batch Consumption Time: 0.28889
Total Iteration Time: 4.82477

Cumulative Model Updates: 99,202
Cumulative Timesteps: 827,226,578

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 827226578...
Checkpoint 827226578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 292,873.99081
Policy Entropy: 3.68817
Value Function Loss: 0.03199

Mean KL Divergence: 0.01071
SB3 Clip Fraction: 0.15076
Policy Update Magnitude: 0.41959
Value Function Update Magnitude: 0.59595

Collected Steps per Second: 21,609.00370
Overall Steps per Second: 10,220.44660

Timestep Collection Time: 2.31468
Timestep Consumption Time: 2.57923
PPO Batch Consumption Time: 0.29793
Total Iteration Time: 4.89392

Cumulative Model Updates: 99,208
Cumulative Timesteps: 827,276,596

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 102,136.63989
Policy Entropy: 3.68560
Value Function Loss: 0.03495

Mean KL Divergence: 0.01074
SB3 Clip Fraction: 0.14906
Policy Update Magnitude: 0.45279
Value Function Update Magnitude: 0.82430

Collected Steps per Second: 21,257.08318
Overall Steps per Second: 10,133.73322

Timestep Collection Time: 2.35244
Timestep Consumption Time: 2.58217
PPO Batch Consumption Time: 0.30103
Total Iteration Time: 4.93461

Cumulative Model Updates: 99,214
Cumulative Timesteps: 827,326,602

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 827326602...
Checkpoint 827326602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 71,805.66698
Policy Entropy: 3.68720
Value Function Loss: 0.03833

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.14620
Policy Update Magnitude: 0.46621
Value Function Update Magnitude: 0.61040

Collected Steps per Second: 21,531.80152
Overall Steps per Second: 10,244.79407

Timestep Collection Time: 2.32224
Timestep Consumption Time: 2.55848
PPO Batch Consumption Time: 0.29989
Total Iteration Time: 4.88072

Cumulative Model Updates: 99,220
Cumulative Timesteps: 827,376,604

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 119,684.80966
Policy Entropy: 3.67043
Value Function Loss: 0.03465

Mean KL Divergence: 0.01070
SB3 Clip Fraction: 0.14752
Policy Update Magnitude: 0.52911
Value Function Update Magnitude: 0.57300

Collected Steps per Second: 21,262.52162
Overall Steps per Second: 10,081.09048

Timestep Collection Time: 2.35259
Timestep Consumption Time: 2.60937
PPO Batch Consumption Time: 0.30387
Total Iteration Time: 4.96196

Cumulative Model Updates: 99,226
Cumulative Timesteps: 827,426,626

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 827426626...
Checkpoint 827426626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 119,684.80966
Policy Entropy: 3.67379
Value Function Loss: 0.03353

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.14760
Policy Update Magnitude: 0.55026
Value Function Update Magnitude: 0.66141

Collected Steps per Second: 21,615.55245
Overall Steps per Second: 10,353.27859

Timestep Collection Time: 2.31565
Timestep Consumption Time: 2.51896
PPO Batch Consumption Time: 0.28838
Total Iteration Time: 4.83460

Cumulative Model Updates: 99,232
Cumulative Timesteps: 827,476,680

Timesteps Collected: 50,054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 119,684.80966
Policy Entropy: 3.68733
Value Function Loss: 0.02834

Mean KL Divergence: 0.01130
SB3 Clip Fraction: 0.15619
Policy Update Magnitude: 0.52120
Value Function Update Magnitude: 0.61249

Collected Steps per Second: 21,503.05892
Overall Steps per Second: 10,221.67901

Timestep Collection Time: 2.32646
Timestep Consumption Time: 2.56765
PPO Batch Consumption Time: 0.30064
Total Iteration Time: 4.89411

Cumulative Model Updates: 99,238
Cumulative Timesteps: 827,526,706

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 827526706...
Checkpoint 827526706 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 119,684.80966
Policy Entropy: 3.67532
Value Function Loss: 0.02384

Mean KL Divergence: 0.01105
SB3 Clip Fraction: 0.15490
Policy Update Magnitude: 0.47072
Value Function Update Magnitude: 0.63935

Collected Steps per Second: 21,537.30433
Overall Steps per Second: 10,271.33357

Timestep Collection Time: 2.32230
Timestep Consumption Time: 2.54718
PPO Batch Consumption Time: 0.29908
Total Iteration Time: 4.86947

Cumulative Model Updates: 99,244
Cumulative Timesteps: 827,576,722

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 119,684.80966
Policy Entropy: 3.67736
Value Function Loss: 0.02596

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.14738
Policy Update Magnitude: 0.43242
Value Function Update Magnitude: 0.62648

Collected Steps per Second: 21,469.87954
Overall Steps per Second: 10,290.40053

Timestep Collection Time: 2.33024
Timestep Consumption Time: 2.53157
PPO Batch Consumption Time: 0.29001
Total Iteration Time: 4.86181

Cumulative Model Updates: 99,250
Cumulative Timesteps: 827,626,752

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 827626752...
Checkpoint 827626752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 119,684.80966
Policy Entropy: 3.66776
Value Function Loss: 0.02889

Mean KL Divergence: 0.01072
SB3 Clip Fraction: 0.14993
Policy Update Magnitude: 0.47006
Value Function Update Magnitude: 0.54892

Collected Steps per Second: 21,517.11718
Overall Steps per Second: 10,234.57469

Timestep Collection Time: 2.32513
Timestep Consumption Time: 2.56321
PPO Batch Consumption Time: 0.29643
Total Iteration Time: 4.88833

Cumulative Model Updates: 99,256
Cumulative Timesteps: 827,676,782

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 318,902.12261
Policy Entropy: 3.65567
Value Function Loss: 0.03332

Mean KL Divergence: 0.01135
SB3 Clip Fraction: 0.15343
Policy Update Magnitude: 0.50459
Value Function Update Magnitude: 0.58762

Collected Steps per Second: 21,673.21237
Overall Steps per Second: 10,379.56133

Timestep Collection Time: 2.30810
Timestep Consumption Time: 2.51137
PPO Batch Consumption Time: 0.28832
Total Iteration Time: 4.81947

Cumulative Model Updates: 99,262
Cumulative Timesteps: 827,726,806

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 827726806...
Checkpoint 827726806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 111,198.24003
Policy Entropy: 3.67139
Value Function Loss: 0.03125

Mean KL Divergence: 0.01130
SB3 Clip Fraction: 0.15395
Policy Update Magnitude: 0.52105
Value Function Update Magnitude: 0.55113

Collected Steps per Second: 21,578.64448
Overall Steps per Second: 10,322.65010

Timestep Collection Time: 2.31766
Timestep Consumption Time: 2.52722
PPO Batch Consumption Time: 0.29376
Total Iteration Time: 4.84488

Cumulative Model Updates: 99,268
Cumulative Timesteps: 827,776,818

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 108,703.85117
Policy Entropy: 3.66503
Value Function Loss: 0.03912

Mean KL Divergence: 0.01090
SB3 Clip Fraction: 0.14404
Policy Update Magnitude: 0.53073
Value Function Update Magnitude: 0.51828

Collected Steps per Second: 20,601.52991
Overall Steps per Second: 10,198.94010

Timestep Collection Time: 2.42759
Timestep Consumption Time: 2.47606
PPO Batch Consumption Time: 0.29696
Total Iteration Time: 4.90365

Cumulative Model Updates: 99,274
Cumulative Timesteps: 827,826,830

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 827826830...
Checkpoint 827826830 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 57,777.72621
Policy Entropy: 3.68928
Value Function Loss: 0.04153

Mean KL Divergence: 0.01080
SB3 Clip Fraction: 0.13818
Policy Update Magnitude: 0.61651
Value Function Update Magnitude: 0.49226

Collected Steps per Second: 20,523.93394
Overall Steps per Second: 10,185.98982

Timestep Collection Time: 2.43715
Timestep Consumption Time: 2.47351
PPO Batch Consumption Time: 0.29837
Total Iteration Time: 4.91067

Cumulative Model Updates: 99,280
Cumulative Timesteps: 827,876,850

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 149,053.51795
Policy Entropy: 3.67173
Value Function Loss: 0.04855

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.13813
Policy Update Magnitude: 0.61960
Value Function Update Magnitude: 0.54868

Collected Steps per Second: 20,769.23083
Overall Steps per Second: 10,293.66064

Timestep Collection Time: 2.40741
Timestep Consumption Time: 2.44995
PPO Batch Consumption Time: 0.28859
Total Iteration Time: 4.85736

Cumulative Model Updates: 99,286
Cumulative Timesteps: 827,926,850

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 827926850...
Checkpoint 827926850 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,340.34210
Policy Entropy: 3.71220
Value Function Loss: 0.04405

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.13754
Policy Update Magnitude: 0.62241
Value Function Update Magnitude: 0.67379

Collected Steps per Second: 20,996.70255
Overall Steps per Second: 10,252.71823

Timestep Collection Time: 2.38133
Timestep Consumption Time: 2.49543
PPO Batch Consumption Time: 0.30180
Total Iteration Time: 4.87676

Cumulative Model Updates: 99,292
Cumulative Timesteps: 827,976,850

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 102,588.71803
Policy Entropy: 3.70313
Value Function Loss: 0.04319

Mean KL Divergence: 0.01070
SB3 Clip Fraction: 0.14857
Policy Update Magnitude: 0.60146
Value Function Update Magnitude: 0.73173

Collected Steps per Second: 21,159.48355
Overall Steps per Second: 10,145.24243

Timestep Collection Time: 2.36518
Timestep Consumption Time: 2.56777
PPO Batch Consumption Time: 0.30270
Total Iteration Time: 4.93295

Cumulative Model Updates: 99,298
Cumulative Timesteps: 828,026,896

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 828026896...
Checkpoint 828026896 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,263.46222
Policy Entropy: 3.70540
Value Function Loss: 0.03451

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.14461
Policy Update Magnitude: 0.56960
Value Function Update Magnitude: 0.79670

Collected Steps per Second: 20,412.51946
Overall Steps per Second: 9,964.76258

Timestep Collection Time: 2.45065
Timestep Consumption Time: 2.56944
PPO Batch Consumption Time: 0.29369
Total Iteration Time: 5.02009

Cumulative Model Updates: 99,304
Cumulative Timesteps: 828,076,920

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,442.41996
Policy Entropy: 3.68168
Value Function Loss: 0.03006

Mean KL Divergence: 0.01111
SB3 Clip Fraction: 0.15573
Policy Update Magnitude: 0.52201
Value Function Update Magnitude: 0.70264

Collected Steps per Second: 21,775.68554
Overall Steps per Second: 10,479.17619

Timestep Collection Time: 2.29742
Timestep Consumption Time: 2.47661
PPO Batch Consumption Time: 0.28754
Total Iteration Time: 4.77404

Cumulative Model Updates: 99,310
Cumulative Timesteps: 828,126,948

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 828126948...
Checkpoint 828126948 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,135.25883
Policy Entropy: 3.67645
Value Function Loss: 0.02687

Mean KL Divergence: 0.01091
SB3 Clip Fraction: 0.15072
Policy Update Magnitude: 0.46415
Value Function Update Magnitude: 0.55445

Collected Steps per Second: 21,696.34485
Overall Steps per Second: 10,348.32950

Timestep Collection Time: 2.30573
Timestep Consumption Time: 2.52848
PPO Batch Consumption Time: 0.29278
Total Iteration Time: 4.83421

Cumulative Model Updates: 99,316
Cumulative Timesteps: 828,176,974

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,135.25883
Policy Entropy: 3.69248
Value Function Loss: 0.02368

Mean KL Divergence: 0.01238
SB3 Clip Fraction: 0.16383
Policy Update Magnitude: 0.44568
Value Function Update Magnitude: 0.53683

Collected Steps per Second: 21,645.48733
Overall Steps per Second: 10,339.65248

Timestep Collection Time: 2.31004
Timestep Consumption Time: 2.52590
PPO Batch Consumption Time: 0.28871
Total Iteration Time: 4.83595

Cumulative Model Updates: 99,322
Cumulative Timesteps: 828,226,976

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 828226976...
Checkpoint 828226976 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 378,126.76910
Policy Entropy: 3.67274
Value Function Loss: 0.02782

Mean KL Divergence: 0.01202
SB3 Clip Fraction: 0.16323
Policy Update Magnitude: 0.42276
Value Function Update Magnitude: 0.58957

Collected Steps per Second: 21,391.77196
Overall Steps per Second: 10,296.60292

Timestep Collection Time: 2.33856
Timestep Consumption Time: 2.51993
PPO Batch Consumption Time: 0.29050
Total Iteration Time: 4.85850

Cumulative Model Updates: 99,328
Cumulative Timesteps: 828,277,002

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 147,928.20282
Policy Entropy: 3.69859
Value Function Loss: 0.03005

Mean KL Divergence: 0.01086
SB3 Clip Fraction: 0.15021
Policy Update Magnitude: 0.45444
Value Function Update Magnitude: 0.74425

Collected Steps per Second: 21,354.29938
Overall Steps per Second: 10,208.51955

Timestep Collection Time: 2.34248
Timestep Consumption Time: 2.55755
PPO Batch Consumption Time: 0.29692
Total Iteration Time: 4.90002

Cumulative Model Updates: 99,334
Cumulative Timesteps: 828,327,024

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 828327024...
Checkpoint 828327024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,790.19143
Policy Entropy: 3.69621
Value Function Loss: 0.03670

Mean KL Divergence: 0.01053
SB3 Clip Fraction: 0.14972
Policy Update Magnitude: 0.46441
Value Function Update Magnitude: 0.71746

Collected Steps per Second: 21,472.74083
Overall Steps per Second: 10,369.17033

Timestep Collection Time: 2.32928
Timestep Consumption Time: 2.49425
PPO Batch Consumption Time: 0.28840
Total Iteration Time: 4.82353

Cumulative Model Updates: 99,340
Cumulative Timesteps: 828,377,040

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,790.19143
Policy Entropy: 3.70254
Value Function Loss: 0.03472

Mean KL Divergence: 0.01074
SB3 Clip Fraction: 0.15270
Policy Update Magnitude: 0.45870
Value Function Update Magnitude: 0.58872

Collected Steps per Second: 21,596.78334
Overall Steps per Second: 10,229.90507

Timestep Collection Time: 2.31534
Timestep Consumption Time: 2.57268
PPO Batch Consumption Time: 0.29923
Total Iteration Time: 4.88802

Cumulative Model Updates: 99,346
Cumulative Timesteps: 828,427,044

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 828427044...
Checkpoint 828427044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,790.19143
Policy Entropy: 3.66714
Value Function Loss: 0.03531

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.15022
Policy Update Magnitude: 0.46036
Value Function Update Magnitude: 0.57423

Collected Steps per Second: 20,687.73459
Overall Steps per Second: 10,037.91969

Timestep Collection Time: 2.41737
Timestep Consumption Time: 2.56473
PPO Batch Consumption Time: 0.29404
Total Iteration Time: 4.98211

Cumulative Model Updates: 99,352
Cumulative Timesteps: 828,477,054

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,790.19143
Policy Entropy: 3.65545
Value Function Loss: 0.03808

Mean KL Divergence: 0.01080
SB3 Clip Fraction: 0.15260
Policy Update Magnitude: 0.47086
Value Function Update Magnitude: 0.50793

Collected Steps per Second: 21,622.42381
Overall Steps per Second: 10,287.08759

Timestep Collection Time: 2.31260
Timestep Consumption Time: 2.54825
PPO Batch Consumption Time: 0.29539
Total Iteration Time: 4.86085

Cumulative Model Updates: 99,358
Cumulative Timesteps: 828,527,058

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 828527058...
Checkpoint 828527058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 64,191.00226
Policy Entropy: 3.65428
Value Function Loss: 0.03376

Mean KL Divergence: 0.01116
SB3 Clip Fraction: 0.15688
Policy Update Magnitude: 0.48617
Value Function Update Magnitude: 0.48494

Collected Steps per Second: 21,547.66672
Overall Steps per Second: 10,353.09694

Timestep Collection Time: 2.32174
Timestep Consumption Time: 2.51044
PPO Batch Consumption Time: 0.28863
Total Iteration Time: 4.83218

Cumulative Model Updates: 99,364
Cumulative Timesteps: 828,577,086

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,389.55029
Policy Entropy: 3.69146
Value Function Loss: 0.03173

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.14684
Policy Update Magnitude: 0.46575
Value Function Update Magnitude: 0.54787

Collected Steps per Second: 21,441.96347
Overall Steps per Second: 10,228.16408

Timestep Collection Time: 2.33300
Timestep Consumption Time: 2.55781
PPO Batch Consumption Time: 0.29889
Total Iteration Time: 4.89081

Cumulative Model Updates: 99,370
Cumulative Timesteps: 828,627,110

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 828627110...
Checkpoint 828627110 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,327.65677
Policy Entropy: 3.68800
Value Function Loss: 0.02811

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.13950
Policy Update Magnitude: 0.44792
Value Function Update Magnitude: 0.55561

Collected Steps per Second: 20,918.74040
Overall Steps per Second: 10,252.06264

Timestep Collection Time: 2.39049
Timestep Consumption Time: 2.48716
PPO Batch Consumption Time: 0.29795
Total Iteration Time: 4.87765

Cumulative Model Updates: 99,376
Cumulative Timesteps: 828,677,116

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 102,564.04978
Policy Entropy: 3.67333
Value Function Loss: 0.02925

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.14343
Policy Update Magnitude: 0.46803
Value Function Update Magnitude: 0.48875

Collected Steps per Second: 20,676.87542
Overall Steps per Second: 10,329.36487

Timestep Collection Time: 2.41913
Timestep Consumption Time: 2.42338
PPO Batch Consumption Time: 0.28825
Total Iteration Time: 4.84250

Cumulative Model Updates: 99,382
Cumulative Timesteps: 828,727,136

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 828727136...
Checkpoint 828727136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 71,339.45320
Policy Entropy: 3.66058
Value Function Loss: 0.03407

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.13902
Policy Update Magnitude: 0.46581
Value Function Update Magnitude: 0.48605

Collected Steps per Second: 20,656.27271
Overall Steps per Second: 10,172.26891

Timestep Collection Time: 2.42173
Timestep Consumption Time: 2.49595
PPO Batch Consumption Time: 0.29820
Total Iteration Time: 4.91768

Cumulative Model Updates: 99,388
Cumulative Timesteps: 828,777,160

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 71,339.45320
Policy Entropy: 3.66628
Value Function Loss: 0.03099

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.14598
Policy Update Magnitude: 0.52949
Value Function Update Magnitude: 0.50616

Collected Steps per Second: 21,167.21977
Overall Steps per Second: 10,165.21451

Timestep Collection Time: 2.36280
Timestep Consumption Time: 2.55731
PPO Batch Consumption Time: 0.29824
Total Iteration Time: 4.92011

Cumulative Model Updates: 99,394
Cumulative Timesteps: 828,827,174

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 828827174...
Checkpoint 828827174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 194,730.00107
Policy Entropy: 3.67014
Value Function Loss: 0.02967

Mean KL Divergence: 0.01174
SB3 Clip Fraction: 0.15523
Policy Update Magnitude: 0.56180
Value Function Update Magnitude: 0.53779

Collected Steps per Second: 21,134.17658
Overall Steps per Second: 10,185.83487

Timestep Collection Time: 2.36640
Timestep Consumption Time: 2.54355
PPO Batch Consumption Time: 0.29930
Total Iteration Time: 4.90996

Cumulative Model Updates: 99,400
Cumulative Timesteps: 828,877,186

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67,909.11432
Policy Entropy: 3.69634
Value Function Loss: 0.02349

Mean KL Divergence: 0.00578
SB3 Clip Fraction: 0.06958
Policy Update Magnitude: 0.66622
Value Function Update Magnitude: 0.56519

Collected Steps per Second: 21,528.57255
Overall Steps per Second: 10,359.72165

Timestep Collection Time: 2.32333
Timestep Consumption Time: 2.50479
PPO Batch Consumption Time: 0.29203
Total Iteration Time: 4.82812

Cumulative Model Updates: 99,406
Cumulative Timesteps: 828,927,204

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 828927204...
Checkpoint 828927204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,675.80656
Policy Entropy: 3.70221
Value Function Loss: 0.02039

Mean KL Divergence: 0.00542
SB3 Clip Fraction: 0.06283
Policy Update Magnitude: 0.72155
Value Function Update Magnitude: 0.69538

Collected Steps per Second: 21,437.84720
Overall Steps per Second: 10,211.43564

Timestep Collection Time: 2.33288
Timestep Consumption Time: 2.56476
PPO Batch Consumption Time: 0.29914
Total Iteration Time: 4.89765

Cumulative Model Updates: 99,412
Cumulative Timesteps: 828,977,216

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,180.63019
Policy Entropy: 3.70694
Value Function Loss: 0.01877

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.12825
Policy Update Magnitude: 0.61636
Value Function Update Magnitude: 0.72263

Collected Steps per Second: 21,545.64501
Overall Steps per Second: 10,326.34585

Timestep Collection Time: 2.32140
Timestep Consumption Time: 2.52214
PPO Batch Consumption Time: 0.28836
Total Iteration Time: 4.84353

Cumulative Model Updates: 99,418
Cumulative Timesteps: 829,027,232

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 829027232...
Checkpoint 829027232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 638,592.41786
Policy Entropy: 3.68105
Value Function Loss: 0.02845

Mean KL Divergence: 0.01417
SB3 Clip Fraction: 0.18511
Policy Update Magnitude: 0.53374
Value Function Update Magnitude: 0.74601

Collected Steps per Second: 21,345.50492
Overall Steps per Second: 10,276.01335

Timestep Collection Time: 2.34382
Timestep Consumption Time: 2.52480
PPO Batch Consumption Time: 0.28837
Total Iteration Time: 4.86862

Cumulative Model Updates: 99,424
Cumulative Timesteps: 829,077,262

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 146,106.60262
Policy Entropy: 3.68647
Value Function Loss: 0.03183

Mean KL Divergence: 0.01654
SB3 Clip Fraction: 0.19544
Policy Update Magnitude: 0.59401
Value Function Update Magnitude: 0.76225

Collected Steps per Second: 21,708.16103
Overall Steps per Second: 10,387.72532

Timestep Collection Time: 2.30347
Timestep Consumption Time: 2.51029
PPO Batch Consumption Time: 0.28812
Total Iteration Time: 4.81376

Cumulative Model Updates: 99,430
Cumulative Timesteps: 829,127,266

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 829127266...
Checkpoint 829127266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 328,290.62415
Policy Entropy: 3.67024
Value Function Loss: 0.05016

Mean KL Divergence: 0.01930
SB3 Clip Fraction: 0.21574
Policy Update Magnitude: 0.60957
Value Function Update Magnitude: 0.62187

Collected Steps per Second: 21,310.34012
Overall Steps per Second: 10,315.97919

Timestep Collection Time: 2.34750
Timestep Consumption Time: 2.50187
PPO Batch Consumption Time: 0.28740
Total Iteration Time: 4.84937

Cumulative Model Updates: 99,436
Cumulative Timesteps: 829,177,292

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,718.56174
Policy Entropy: 3.68656
Value Function Loss: 0.05684

Mean KL Divergence: 0.01723
SB3 Clip Fraction: 0.20377
Policy Update Magnitude: 0.64503
Value Function Update Magnitude: 0.62360

Collected Steps per Second: 21,473.96104
Overall Steps per Second: 10,217.74516

Timestep Collection Time: 2.32877
Timestep Consumption Time: 2.56546
PPO Batch Consumption Time: 0.29716
Total Iteration Time: 4.89423

Cumulative Model Updates: 99,442
Cumulative Timesteps: 829,227,300

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 829227300...
Checkpoint 829227300 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,119.68705
Policy Entropy: 3.67424
Value Function Loss: 0.06262

Mean KL Divergence: 0.01620
SB3 Clip Fraction: 0.19330
Policy Update Magnitude: 0.74864
Value Function Update Magnitude: 0.72223

Collected Steps per Second: 21,214.87505
Overall Steps per Second: 10,181.81055

Timestep Collection Time: 2.35891
Timestep Consumption Time: 2.55613
PPO Batch Consumption Time: 0.29816
Total Iteration Time: 4.91504

Cumulative Model Updates: 99,448
Cumulative Timesteps: 829,277,344

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 215,517.21991
Policy Entropy: 3.68950
Value Function Loss: 0.05747

Mean KL Divergence: 0.01216
SB3 Clip Fraction: 0.15350
Policy Update Magnitude: 0.74559
Value Function Update Magnitude: 0.67659

Collected Steps per Second: 21,063.50172
Overall Steps per Second: 10,259.57883

Timestep Collection Time: 2.37425
Timestep Consumption Time: 2.50022
PPO Batch Consumption Time: 0.28818
Total Iteration Time: 4.87447

Cumulative Model Updates: 99,454
Cumulative Timesteps: 829,327,354

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 829327354...
Checkpoint 829327354 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 151,383.10775
Policy Entropy: 3.66248
Value Function Loss: 0.05862

Mean KL Divergence: 0.01181
SB3 Clip Fraction: 0.14264
Policy Update Magnitude: 0.72619
Value Function Update Magnitude: 0.64939

Collected Steps per Second: 20,670.98069
Overall Steps per Second: 10,183.26209

Timestep Collection Time: 2.42079
Timestep Consumption Time: 2.49316
PPO Batch Consumption Time: 0.28782
Total Iteration Time: 4.91395

Cumulative Model Updates: 99,460
Cumulative Timesteps: 829,377,394

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 156,561.93185
Policy Entropy: 3.66367
Value Function Loss: 0.05786

Mean KL Divergence: 0.01285
SB3 Clip Fraction: 0.15341
Policy Update Magnitude: 0.79856
Value Function Update Magnitude: 0.75587

Collected Steps per Second: 21,335.12796
Overall Steps per Second: 10,124.73997

Timestep Collection Time: 2.34477
Timestep Consumption Time: 2.59619
PPO Batch Consumption Time: 0.30131
Total Iteration Time: 4.94097

Cumulative Model Updates: 99,466
Cumulative Timesteps: 829,427,420

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 829427420...
Checkpoint 829427420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 101,415.07285
Policy Entropy: 3.67883
Value Function Loss: 0.05626

Mean KL Divergence: 0.01283
SB3 Clip Fraction: 0.16003
Policy Update Magnitude: 0.87174
Value Function Update Magnitude: 0.61645

Collected Steps per Second: 21,294.07926
Overall Steps per Second: 10,193.76491

Timestep Collection Time: 2.34835
Timestep Consumption Time: 2.55720
PPO Batch Consumption Time: 0.29451
Total Iteration Time: 4.90555

Cumulative Model Updates: 99,472
Cumulative Timesteps: 829,477,426

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 101,415.07285
Policy Entropy: 3.68441
Value Function Loss: 0.05407

Mean KL Divergence: 0.01683
SB3 Clip Fraction: 0.20190
Policy Update Magnitude: 0.86203
Value Function Update Magnitude: 0.55431

Collected Steps per Second: 21,706.81227
Overall Steps per Second: 10,369.57451

Timestep Collection Time: 2.30379
Timestep Consumption Time: 2.51878
PPO Batch Consumption Time: 0.28823
Total Iteration Time: 4.82257

Cumulative Model Updates: 99,478
Cumulative Timesteps: 829,527,434

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 829527434...
Checkpoint 829527434 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 164,871.05295
Policy Entropy: 3.69730
Value Function Loss: 0.04704

Mean KL Divergence: 0.01512
SB3 Clip Fraction: 0.18563
Policy Update Magnitude: 0.77915
Value Function Update Magnitude: 0.42752

Collected Steps per Second: 20,810.82576
Overall Steps per Second: 10,261.61580

Timestep Collection Time: 2.40317
Timestep Consumption Time: 2.47052
PPO Batch Consumption Time: 0.29491
Total Iteration Time: 4.87370

Cumulative Model Updates: 99,484
Cumulative Timesteps: 829,577,446

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 779,517.88458
Policy Entropy: 3.69257
Value Function Loss: 0.03825

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.12133
Policy Update Magnitude: 0.74040
Value Function Update Magnitude: 0.37552

Collected Steps per Second: 20,774.86077
Overall Steps per Second: 10,208.82788

Timestep Collection Time: 2.40772
Timestep Consumption Time: 2.49196
PPO Batch Consumption Time: 0.29707
Total Iteration Time: 4.89968

Cumulative Model Updates: 99,490
Cumulative Timesteps: 829,627,466

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 829627466...
Checkpoint 829627466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 220,314.41454
Policy Entropy: 3.68917
Value Function Loss: 0.03813

Mean KL Divergence: 0.01361
SB3 Clip Fraction: 0.17624
Policy Update Magnitude: 0.64611
Value Function Update Magnitude: 0.40027

Collected Steps per Second: 21,006.82010
Overall Steps per Second: 10,403.62274

Timestep Collection Time: 2.38047
Timestep Consumption Time: 2.42613
PPO Batch Consumption Time: 0.28810
Total Iteration Time: 4.80659

Cumulative Model Updates: 99,496
Cumulative Timesteps: 829,677,472

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 517,100.98993
Policy Entropy: 3.68903
Value Function Loss: 0.04015

Mean KL Divergence: 0.01067
SB3 Clip Fraction: 0.14081
Policy Update Magnitude: 0.55101
Value Function Update Magnitude: 0.69308

Collected Steps per Second: 21,071.86206
Overall Steps per Second: 10,145.84259

Timestep Collection Time: 2.37540
Timestep Consumption Time: 2.55805
PPO Batch Consumption Time: 0.29997
Total Iteration Time: 4.93345

Cumulative Model Updates: 99,502
Cumulative Timesteps: 829,727,526

Timesteps Collected: 50,054
--------END ITERATION REPORT--------


Saving checkpoint 829727526...
Checkpoint 829727526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 60,874.16622
Policy Entropy: 3.68802
Value Function Loss: 0.04660

Mean KL Divergence: 0.01258
SB3 Clip Fraction: 0.16356
Policy Update Magnitude: 0.60290
Value Function Update Magnitude: 0.81203

Collected Steps per Second: 21,484.16555
Overall Steps per Second: 10,273.98928

Timestep Collection Time: 2.32748
Timestep Consumption Time: 2.53957
PPO Batch Consumption Time: 0.29996
Total Iteration Time: 4.86705

Cumulative Model Updates: 99,508
Cumulative Timesteps: 829,777,530

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,769.91551
Policy Entropy: 3.69891
Value Function Loss: 0.04565

Mean KL Divergence: 0.01189
SB3 Clip Fraction: 0.15943
Policy Update Magnitude: 0.63632
Value Function Update Magnitude: 0.75299

Collected Steps per Second: 21,715.68586
Overall Steps per Second: 10,362.17673

Timestep Collection Time: 2.30442
Timestep Consumption Time: 2.52488
PPO Batch Consumption Time: 0.29313
Total Iteration Time: 4.82929

Cumulative Model Updates: 99,514
Cumulative Timesteps: 829,827,572

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 829827572...
Checkpoint 829827572 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 101,223.51267
Policy Entropy: 3.69795
Value Function Loss: 0.04555

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.14709
Policy Update Magnitude: 0.58252
Value Function Update Magnitude: 0.66367

Collected Steps per Second: 21,480.70671
Overall Steps per Second: 10,251.56028

Timestep Collection Time: 2.32823
Timestep Consumption Time: 2.55025
PPO Batch Consumption Time: 0.30151
Total Iteration Time: 4.87848

Cumulative Model Updates: 99,520
Cumulative Timesteps: 829,877,584

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 101,223.51267
Policy Entropy: 3.69793
Value Function Loss: 0.04072

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.14501
Policy Update Magnitude: 0.53868
Value Function Update Magnitude: 0.60380

Collected Steps per Second: 21,874.75348
Overall Steps per Second: 10,431.44354

Timestep Collection Time: 2.28684
Timestep Consumption Time: 2.50866
PPO Batch Consumption Time: 0.28712
Total Iteration Time: 4.79550

Cumulative Model Updates: 99,526
Cumulative Timesteps: 829,927,608

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 829927608...
Checkpoint 829927608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 231,000.96551
Policy Entropy: 3.67505
Value Function Loss: 0.03731

Mean KL Divergence: 0.01098
SB3 Clip Fraction: 0.14761
Policy Update Magnitude: 0.52313
Value Function Update Magnitude: 0.61902

Collected Steps per Second: 21,404.57122
Overall Steps per Second: 10,064.54711

Timestep Collection Time: 2.33688
Timestep Consumption Time: 2.63304
PPO Batch Consumption Time: 0.31181
Total Iteration Time: 4.96992

Cumulative Model Updates: 99,532
Cumulative Timesteps: 829,977,628

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 100,625.27271
Policy Entropy: 3.68957
Value Function Loss: 0.02866

Mean KL Divergence: 0.01248
SB3 Clip Fraction: 0.16416
Policy Update Magnitude: 0.51854
Value Function Update Magnitude: 0.71617

Collected Steps per Second: 21,828.42573
Overall Steps per Second: 10,276.15481

Timestep Collection Time: 2.29096
Timestep Consumption Time: 2.57545
PPO Batch Consumption Time: 0.29895
Total Iteration Time: 4.86641

Cumulative Model Updates: 99,538
Cumulative Timesteps: 830,027,636

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 830027636...
Checkpoint 830027636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 100,625.27271
Policy Entropy: 3.68007
Value Function Loss: 0.02557

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.11867
Policy Update Magnitude: 0.52214
Value Function Update Magnitude: 0.71920

Collected Steps per Second: 21,775.78470
Overall Steps per Second: 10,418.60781

Timestep Collection Time: 2.29815
Timestep Consumption Time: 2.50518
PPO Batch Consumption Time: 0.28862
Total Iteration Time: 4.80333

Cumulative Model Updates: 99,544
Cumulative Timesteps: 830,077,680

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 100,625.27271
Policy Entropy: 3.69605
Value Function Loss: 0.02389

Mean KL Divergence: 0.01145
SB3 Clip Fraction: 0.15496
Policy Update Magnitude: 0.48766
Value Function Update Magnitude: 0.61247

Collected Steps per Second: 21,931.13296
Overall Steps per Second: 10,260.03639

Timestep Collection Time: 2.28114
Timestep Consumption Time: 2.59487
PPO Batch Consumption Time: 0.30021
Total Iteration Time: 4.87601

Cumulative Model Updates: 99,550
Cumulative Timesteps: 830,127,708

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 830127708...
Checkpoint 830127708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 73,219.21987
Policy Entropy: 3.68063
Value Function Loss: 0.02277

Mean KL Divergence: 0.02703
SB3 Clip Fraction: 0.31801
Policy Update Magnitude: 0.38651
Value Function Update Magnitude: 0.53817

Collected Steps per Second: 21,778.94389
Overall Steps per Second: 10,414.09242

Timestep Collection Time: 2.29598
Timestep Consumption Time: 2.50559
PPO Batch Consumption Time: 0.28799
Total Iteration Time: 4.80157

Cumulative Model Updates: 99,556
Cumulative Timesteps: 830,177,712

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,978.29327
Policy Entropy: 3.68488
Value Function Loss: 0.03285

Mean KL Divergence: 0.02189
SB3 Clip Fraction: 0.25999
Policy Update Magnitude: 0.34408
Value Function Update Magnitude: 0.47999

Collected Steps per Second: 21,518.44282
Overall Steps per Second: 10,195.06537

Timestep Collection Time: 2.32442
Timestep Consumption Time: 2.58167
PPO Batch Consumption Time: 0.30103
Total Iteration Time: 4.90610

Cumulative Model Updates: 99,562
Cumulative Timesteps: 830,227,730

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 830227730...
Checkpoint 830227730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 251,856.08005
Policy Entropy: 3.67002
Value Function Loss: 0.04518

Mean KL Divergence: 0.02219
SB3 Clip Fraction: 0.25581
Policy Update Magnitude: 0.38783
Value Function Update Magnitude: 0.52795

Collected Steps per Second: 21,523.28282
Overall Steps per Second: 10,210.91257

Timestep Collection Time: 2.32390
Timestep Consumption Time: 2.57458
PPO Batch Consumption Time: 0.29966
Total Iteration Time: 4.89848

Cumulative Model Updates: 99,568
Cumulative Timesteps: 830,277,748

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87,822.60724
Policy Entropy: 3.61164
Value Function Loss: 0.05216

Mean KL Divergence: 0.02572
SB3 Clip Fraction: 0.26503
Policy Update Magnitude: 0.48348
Value Function Update Magnitude: 0.56523

Collected Steps per Second: 21,827.69464
Overall Steps per Second: 10,382.63609

Timestep Collection Time: 2.29195
Timestep Consumption Time: 2.52648
PPO Batch Consumption Time: 0.28897
Total Iteration Time: 4.81843

Cumulative Model Updates: 99,574
Cumulative Timesteps: 830,327,776

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 830327776...
Checkpoint 830327776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87,822.60724
Policy Entropy: 3.61266
Value Function Loss: 0.06336

Mean KL Divergence: 0.02349
SB3 Clip Fraction: 0.26509
Policy Update Magnitude: 0.47677
Value Function Update Magnitude: 0.51346

Collected Steps per Second: 21,452.52432
Overall Steps per Second: 10,244.30110

Timestep Collection Time: 2.33091
Timestep Consumption Time: 2.55024
PPO Batch Consumption Time: 0.29688
Total Iteration Time: 4.88115

Cumulative Model Updates: 99,580
Cumulative Timesteps: 830,377,780

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 260,962.85869
Policy Entropy: 3.60149
Value Function Loss: 0.06254

Mean KL Divergence: 0.01902
SB3 Clip Fraction: 0.23708
Policy Update Magnitude: 0.42351
Value Function Update Magnitude: 0.46527

Collected Steps per Second: 21,050.26884
Overall Steps per Second: 10,081.15306

Timestep Collection Time: 2.37726
Timestep Consumption Time: 2.58665
PPO Batch Consumption Time: 0.30055
Total Iteration Time: 4.96392

Cumulative Model Updates: 99,586
Cumulative Timesteps: 830,427,822

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 830427822...
Checkpoint 830427822 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 102,568.94326
Policy Entropy: 3.61401
Value Function Loss: 0.07538

Mean KL Divergence: 0.01849
SB3 Clip Fraction: 0.22202
Policy Update Magnitude: 0.46096
Value Function Update Magnitude: 0.45947

Collected Steps per Second: 21,154.84182
Overall Steps per Second: 10,150.40788

Timestep Collection Time: 2.36371
Timestep Consumption Time: 2.56259
PPO Batch Consumption Time: 0.29644
Total Iteration Time: 4.92630

Cumulative Model Updates: 99,592
Cumulative Timesteps: 830,477,826

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 165,870.69924
Policy Entropy: 3.63824
Value Function Loss: 0.07298

Mean KL Divergence: 0.01545
SB3 Clip Fraction: 0.19141
Policy Update Magnitude: 0.52133
Value Function Update Magnitude: 0.60211

Collected Steps per Second: 21,210.03918
Overall Steps per Second: 10,115.98289

Timestep Collection Time: 2.35813
Timestep Consumption Time: 2.58613
PPO Batch Consumption Time: 0.30032
Total Iteration Time: 4.94426

Cumulative Model Updates: 99,598
Cumulative Timesteps: 830,527,842

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 830527842...
Checkpoint 830527842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,208.81014
Policy Entropy: 3.70966
Value Function Loss: 0.07219

Mean KL Divergence: 0.01386
SB3 Clip Fraction: 0.16805
Policy Update Magnitude: 0.62366
Value Function Update Magnitude: 0.84060

Collected Steps per Second: 21,189.27597
Overall Steps per Second: 9,974.23883

Timestep Collection Time: 2.36053
Timestep Consumption Time: 2.65418
PPO Batch Consumption Time: 0.31443
Total Iteration Time: 5.01472

Cumulative Model Updates: 99,604
Cumulative Timesteps: 830,577,860

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,411.24407
Policy Entropy: 3.73106
Value Function Loss: 0.06961

Mean KL Divergence: 0.01318
SB3 Clip Fraction: 0.15678
Policy Update Magnitude: 0.75426
Value Function Update Magnitude: 0.76908

Collected Steps per Second: 21,551.24852
Overall Steps per Second: 10,127.58365

Timestep Collection Time: 2.32005
Timestep Consumption Time: 2.61696
PPO Batch Consumption Time: 0.30600
Total Iteration Time: 4.93701

Cumulative Model Updates: 99,610
Cumulative Timesteps: 830,627,860

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 830627860...
Checkpoint 830627860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,870.82336
Policy Entropy: 3.79969
Value Function Loss: 0.06218

Mean KL Divergence: 0.01408
SB3 Clip Fraction: 0.15755
Policy Update Magnitude: 0.85563
Value Function Update Magnitude: 0.68073

Collected Steps per Second: 21,424.36159
Overall Steps per Second: 10,273.50406

Timestep Collection Time: 2.33501
Timestep Consumption Time: 2.53441
PPO Batch Consumption Time: 0.29412
Total Iteration Time: 4.86942

Cumulative Model Updates: 99,616
Cumulative Timesteps: 830,677,886

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,199.62076
Policy Entropy: 3.80258
Value Function Loss: 0.05521

Mean KL Divergence: 0.01359
SB3 Clip Fraction: 0.15716
Policy Update Magnitude: 0.94624
Value Function Update Magnitude: 0.78596

Collected Steps per Second: 21,499.74036
Overall Steps per Second: 10,379.76798

Timestep Collection Time: 2.32645
Timestep Consumption Time: 2.49235
PPO Batch Consumption Time: 0.28905
Total Iteration Time: 4.81880

Cumulative Model Updates: 99,622
Cumulative Timesteps: 830,727,904

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 830727904...
Checkpoint 830727904 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,563.60796
Policy Entropy: 3.83767
Value Function Loss: 0.05367

Mean KL Divergence: 0.01147
SB3 Clip Fraction: 0.13932
Policy Update Magnitude: 1.00266
Value Function Update Magnitude: 0.84913

Collected Steps per Second: 21,397.83531
Overall Steps per Second: 10,300.85160

Timestep Collection Time: 2.33715
Timestep Consumption Time: 2.51779
PPO Batch Consumption Time: 0.29644
Total Iteration Time: 4.85494

Cumulative Model Updates: 99,628
Cumulative Timesteps: 830,777,914

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,588.51224
Policy Entropy: 3.90587
Value Function Loss: 0.04382

Mean KL Divergence: 0.01074
SB3 Clip Fraction: 0.13068
Policy Update Magnitude: 1.08341
Value Function Update Magnitude: 0.93242

Collected Steps per Second: 20,921.08672
Overall Steps per Second: 10,143.42264

Timestep Collection Time: 2.39041
Timestep Consumption Time: 2.53988
PPO Batch Consumption Time: 0.29795
Total Iteration Time: 4.93029

Cumulative Model Updates: 99,634
Cumulative Timesteps: 830,827,924

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 830827924...
Checkpoint 830827924 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,721.88593
Policy Entropy: 3.96082
Value Function Loss: 0.03987

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.10969
Policy Update Magnitude: 1.18564
Value Function Update Magnitude: 0.99050

Collected Steps per Second: 21,668.67513
Overall Steps per Second: 10,513.07726

Timestep Collection Time: 2.30840
Timestep Consumption Time: 2.44948
PPO Batch Consumption Time: 0.29283
Total Iteration Time: 4.75788

Cumulative Model Updates: 99,640
Cumulative Timesteps: 830,877,944

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 134.46197
Policy Entropy: 3.99297
Value Function Loss: 0.03600

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.10078
Policy Update Magnitude: 1.18659
Value Function Update Magnitude: 1.04125

Collected Steps per Second: 21,209.24412
Overall Steps per Second: 10,423.21257

Timestep Collection Time: 2.35812
Timestep Consumption Time: 2.44021
PPO Batch Consumption Time: 0.28884
Total Iteration Time: 4.79833

Cumulative Model Updates: 99,646
Cumulative Timesteps: 830,927,958

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 830927958...
Checkpoint 830927958 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,807.47516
Policy Entropy: 3.95482
Value Function Loss: 0.04279

Mean KL Divergence: 0.00675
SB3 Clip Fraction: 0.08010
Policy Update Magnitude: 1.13367
Value Function Update Magnitude: 0.80957

Collected Steps per Second: 21,489.78273
Overall Steps per Second: 10,259.78964

Timestep Collection Time: 2.32808
Timestep Consumption Time: 2.54824
PPO Batch Consumption Time: 0.29641
Total Iteration Time: 4.87632

Cumulative Model Updates: 99,652
Cumulative Timesteps: 830,977,988

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,170.63070
Policy Entropy: 3.93812
Value Function Loss: 0.04091

Mean KL Divergence: 0.00624
SB3 Clip Fraction: 0.07489
Policy Update Magnitude: 1.07616
Value Function Update Magnitude: 0.71466

Collected Steps per Second: 21,315.61078
Overall Steps per Second: 10,317.25625

Timestep Collection Time: 2.34645
Timestep Consumption Time: 2.50135
PPO Batch Consumption Time: 0.28941
Total Iteration Time: 4.84780

Cumulative Model Updates: 99,658
Cumulative Timesteps: 831,028,004

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 831028004...
Checkpoint 831028004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 52.59177
Policy Entropy: 3.90215
Value Function Loss: 0.04104

Mean KL Divergence: 0.00571
SB3 Clip Fraction: 0.06673
Policy Update Magnitude: 1.03569
Value Function Update Magnitude: 0.72200

Collected Steps per Second: 21,468.31013
Overall Steps per Second: 10,359.65223

Timestep Collection Time: 2.32911
Timestep Consumption Time: 2.49750
PPO Batch Consumption Time: 0.28729
Total Iteration Time: 4.82661

Cumulative Model Updates: 99,664
Cumulative Timesteps: 831,078,006

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,834.14872
Policy Entropy: 3.86991
Value Function Loss: 0.04264

Mean KL Divergence: 0.00683
SB3 Clip Fraction: 0.08575
Policy Update Magnitude: 0.97438
Value Function Update Magnitude: 0.75037

Collected Steps per Second: 21,147.88804
Overall Steps per Second: 9,979.10248

Timestep Collection Time: 2.36459
Timestep Consumption Time: 2.64649
PPO Batch Consumption Time: 0.30128
Total Iteration Time: 5.01107

Cumulative Model Updates: 99,670
Cumulative Timesteps: 831,128,012

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 831128012...
Checkpoint 831128012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 425.89075
Policy Entropy: 3.87356
Value Function Loss: 0.04355

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.10525
Policy Update Magnitude: 0.84406
Value Function Update Magnitude: 0.68010

Collected Steps per Second: 21,239.57817
Overall Steps per Second: 10,246.31664

Timestep Collection Time: 2.35466
Timestep Consumption Time: 2.52631
PPO Batch Consumption Time: 0.29111
Total Iteration Time: 4.88097

Cumulative Model Updates: 99,676
Cumulative Timesteps: 831,178,024

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,785.42955
Policy Entropy: 3.89130
Value Function Loss: 0.04455

Mean KL Divergence: 0.00632
SB3 Clip Fraction: 0.07869
Policy Update Magnitude: 0.79178
Value Function Update Magnitude: 0.60960

Collected Steps per Second: 21,581.84449
Overall Steps per Second: 10,339.95395

Timestep Collection Time: 2.31685
Timestep Consumption Time: 2.51895
PPO Batch Consumption Time: 0.28879
Total Iteration Time: 4.83580

Cumulative Model Updates: 99,682
Cumulative Timesteps: 831,228,026

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 831228026...
Checkpoint 831228026 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,432.83040
Policy Entropy: 3.88633
Value Function Loss: 0.04530

Mean KL Divergence: 0.00561
SB3 Clip Fraction: 0.06727
Policy Update Magnitude: 0.83643
Value Function Update Magnitude: 0.71373

Collected Steps per Second: 21,579.01221
Overall Steps per Second: 10,275.88990

Timestep Collection Time: 2.31818
Timestep Consumption Time: 2.54992
PPO Batch Consumption Time: 0.29545
Total Iteration Time: 4.86809

Cumulative Model Updates: 99,688
Cumulative Timesteps: 831,278,050

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68.20369
Policy Entropy: 3.83719
Value Function Loss: 0.04735

Mean KL Divergence: 0.00571
SB3 Clip Fraction: 0.06923
Policy Update Magnitude: 0.80535
Value Function Update Magnitude: 0.60725

Collected Steps per Second: 21,611.93993
Overall Steps per Second: 10,286.68636

Timestep Collection Time: 2.31409
Timestep Consumption Time: 2.54773
PPO Batch Consumption Time: 0.29563
Total Iteration Time: 4.86182

Cumulative Model Updates: 99,694
Cumulative Timesteps: 831,328,062

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 831328062...
Checkpoint 831328062 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,103.73665
Policy Entropy: 3.79108
Value Function Loss: 0.04359

Mean KL Divergence: 0.00725
SB3 Clip Fraction: 0.09089
Policy Update Magnitude: 0.71897
Value Function Update Magnitude: 0.48014

Collected Steps per Second: 21,706.27233
Overall Steps per Second: 10,432.79130

Timestep Collection Time: 2.30477
Timestep Consumption Time: 2.49049
PPO Batch Consumption Time: 0.28656
Total Iteration Time: 4.79527

Cumulative Model Updates: 99,700
Cumulative Timesteps: 831,378,090

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,515.80295
Policy Entropy: 3.77759
Value Function Loss: 0.04170

Mean KL Divergence: 0.00739
SB3 Clip Fraction: 0.09424
Policy Update Magnitude: 0.64845
Value Function Update Magnitude: 0.47151

Collected Steps per Second: 21,447.35194
Overall Steps per Second: 10,304.55143

Timestep Collection Time: 2.33213
Timestep Consumption Time: 2.52184
PPO Batch Consumption Time: 0.28866
Total Iteration Time: 4.85397

Cumulative Model Updates: 99,706
Cumulative Timesteps: 831,428,108

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 831428108...
Checkpoint 831428108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 288.38687
Policy Entropy: 3.76412
Value Function Loss: 0.04018

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.12907
Policy Update Magnitude: 0.60162
Value Function Update Magnitude: 0.43663

Collected Steps per Second: 21,203.67615
Overall Steps per Second: 10,283.88836

Timestep Collection Time: 2.35902
Timestep Consumption Time: 2.50489
PPO Batch Consumption Time: 0.28919
Total Iteration Time: 4.86392

Cumulative Model Updates: 99,712
Cumulative Timesteps: 831,478,128

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,393.50091
Policy Entropy: 3.76193
Value Function Loss: 0.04977

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.13666
Policy Update Magnitude: 0.57584
Value Function Update Magnitude: 0.46100

Collected Steps per Second: 20,643.98995
Overall Steps per Second: 10,156.86417

Timestep Collection Time: 2.42259
Timestep Consumption Time: 2.50137
PPO Batch Consumption Time: 0.30137
Total Iteration Time: 4.92396

Cumulative Model Updates: 99,718
Cumulative Timesteps: 831,528,140

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 831528140...
Checkpoint 831528140 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,100.78022
Policy Entropy: 3.79292
Value Function Loss: 0.04823

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.12694
Policy Update Magnitude: 0.67751
Value Function Update Magnitude: 0.42538

Collected Steps per Second: 20,680.12730
Overall Steps per Second: 10,148.42652

Timestep Collection Time: 2.41875
Timestep Consumption Time: 2.51010
PPO Batch Consumption Time: 0.30204
Total Iteration Time: 4.92884

Cumulative Model Updates: 99,724
Cumulative Timesteps: 831,578,160

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 326.14300
Policy Entropy: 3.77414
Value Function Loss: 0.04495

Mean KL Divergence: 0.01411
SB3 Clip Fraction: 0.17062
Policy Update Magnitude: 0.68754
Value Function Update Magnitude: 0.51897

Collected Steps per Second: 20,953.02711
Overall Steps per Second: 10,328.82474

Timestep Collection Time: 2.38658
Timestep Consumption Time: 2.45483
PPO Batch Consumption Time: 0.28982
Total Iteration Time: 4.84140

Cumulative Model Updates: 99,730
Cumulative Timesteps: 831,628,166

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 831628166...
Checkpoint 831628166 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,393.64107
Policy Entropy: 3.75827
Value Function Loss: 0.03621

Mean KL Divergence: 0.01548
SB3 Clip Fraction: 0.19866
Policy Update Magnitude: 0.59531
Value Function Update Magnitude: 0.54157

Collected Steps per Second: 20,974.34537
Overall Steps per Second: 10,359.95853

Timestep Collection Time: 2.38434
Timestep Consumption Time: 2.44290
PPO Batch Consumption Time: 0.29155
Total Iteration Time: 4.82724

Cumulative Model Updates: 99,736
Cumulative Timesteps: 831,678,176

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,843.04041
Policy Entropy: 3.71170
Value Function Loss: 0.04339

Mean KL Divergence: 0.01488
SB3 Clip Fraction: 0.18268
Policy Update Magnitude: 0.53939
Value Function Update Magnitude: 0.68150

Collected Steps per Second: 21,221.78264
Overall Steps per Second: 10,326.02100

Timestep Collection Time: 2.35795
Timestep Consumption Time: 2.48806
PPO Batch Consumption Time: 0.28808
Total Iteration Time: 4.84601

Cumulative Model Updates: 99,742
Cumulative Timesteps: 831,728,216

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 831728216...
Checkpoint 831728216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,201.74346
Policy Entropy: 3.71001
Value Function Loss: 0.05491

Mean KL Divergence: 0.01682
SB3 Clip Fraction: 0.19487
Policy Update Magnitude: 0.60546
Value Function Update Magnitude: 0.77611

Collected Steps per Second: 20,744.60710
Overall Steps per Second: 10,208.37485

Timestep Collection Time: 2.41046
Timestep Consumption Time: 2.48787
PPO Batch Consumption Time: 0.28879
Total Iteration Time: 4.89833

Cumulative Model Updates: 99,748
Cumulative Timesteps: 831,778,220

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,694.88351
Policy Entropy: 3.75082
Value Function Loss: 0.06292

Mean KL Divergence: 0.01147
SB3 Clip Fraction: 0.14537
Policy Update Magnitude: 0.72368
Value Function Update Magnitude: 0.76068

Collected Steps per Second: 21,061.92681
Overall Steps per Second: 10,134.38277

Timestep Collection Time: 2.37519
Timestep Consumption Time: 2.56108
PPO Batch Consumption Time: 0.30002
Total Iteration Time: 4.93627

Cumulative Model Updates: 99,754
Cumulative Timesteps: 831,828,246

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 831828246...
Checkpoint 831828246 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,580.77703
Policy Entropy: 3.75514
Value Function Loss: 0.06098

Mean KL Divergence: 0.01314
SB3 Clip Fraction: 0.16285
Policy Update Magnitude: 0.77309
Value Function Update Magnitude: 0.65998

Collected Steps per Second: 21,105.11145
Overall Steps per Second: 10,196.05391

Timestep Collection Time: 2.36919
Timestep Consumption Time: 2.53486
PPO Batch Consumption Time: 0.29371
Total Iteration Time: 4.90405

Cumulative Model Updates: 99,760
Cumulative Timesteps: 831,878,248

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,806.79229
Policy Entropy: 3.76220
Value Function Loss: 0.05778

Mean KL Divergence: 0.01233
SB3 Clip Fraction: 0.15540
Policy Update Magnitude: 0.65806
Value Function Update Magnitude: 0.57286

Collected Steps per Second: 21,608.89957
Overall Steps per Second: 10,408.26122

Timestep Collection Time: 2.31460
Timestep Consumption Time: 2.49081
PPO Batch Consumption Time: 0.28895
Total Iteration Time: 4.80541

Cumulative Model Updates: 99,766
Cumulative Timesteps: 831,928,264

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 831928264...
Checkpoint 831928264 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,379.31819
Policy Entropy: 3.73303
Value Function Loss: 0.05346

Mean KL Divergence: 0.01162
SB3 Clip Fraction: 0.14413
Policy Update Magnitude: 0.58065
Value Function Update Magnitude: 0.48890

Collected Steps per Second: 21,260.27072
Overall Steps per Second: 10,292.46736

Timestep Collection Time: 2.35209
Timestep Consumption Time: 2.50642
PPO Batch Consumption Time: 0.28798
Total Iteration Time: 4.85850

Cumulative Model Updates: 99,772
Cumulative Timesteps: 831,978,270

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,440.53682
Policy Entropy: 3.72151
Value Function Loss: 0.05424

Mean KL Divergence: 0.01120
SB3 Clip Fraction: 0.14356
Policy Update Magnitude: 0.60497
Value Function Update Magnitude: 0.43510

Collected Steps per Second: 21,348.63208
Overall Steps per Second: 10,172.10765

Timestep Collection Time: 2.34226
Timestep Consumption Time: 2.57354
PPO Batch Consumption Time: 0.29838
Total Iteration Time: 4.91580

Cumulative Model Updates: 99,778
Cumulative Timesteps: 832,028,274

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 832028274...
Checkpoint 832028274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,259.07750
Policy Entropy: 3.72873
Value Function Loss: 0.05381

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.12541
Policy Update Magnitude: 0.69048
Value Function Update Magnitude: 0.41802

Collected Steps per Second: 20,928.88376
Overall Steps per Second: 9,928.25724

Timestep Collection Time: 2.38990
Timestep Consumption Time: 2.64804
PPO Batch Consumption Time: 0.30865
Total Iteration Time: 5.03794

Cumulative Model Updates: 99,784
Cumulative Timesteps: 832,078,292

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,093.20380
Policy Entropy: 3.74410
Value Function Loss: 0.04667

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.11919
Policy Update Magnitude: 0.71765
Value Function Update Magnitude: 0.42735

Collected Steps per Second: 21,856.90734
Overall Steps per Second: 10,286.29136

Timestep Collection Time: 2.28870
Timestep Consumption Time: 2.57447
PPO Batch Consumption Time: 0.29948
Total Iteration Time: 4.86317

Cumulative Model Updates: 99,790
Cumulative Timesteps: 832,128,316

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 832128316...
Checkpoint 832128316 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,578.49129
Policy Entropy: 3.74772
Value Function Loss: 0.03501

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.11410
Policy Update Magnitude: 0.68660
Value Function Update Magnitude: 0.47403

Collected Steps per Second: 21,450.99087
Overall Steps per Second: 10,207.13933

Timestep Collection Time: 2.33127
Timestep Consumption Time: 2.56805
PPO Batch Consumption Time: 0.30058
Total Iteration Time: 4.89932

Cumulative Model Updates: 99,796
Cumulative Timesteps: 832,178,324

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57,904.85472
Policy Entropy: 3.73130
Value Function Loss: 0.02831

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.11462
Policy Update Magnitude: 0.58984
Value Function Update Magnitude: 0.45808

Collected Steps per Second: 21,925.11827
Overall Steps per Second: 10,354.03667

Timestep Collection Time: 2.28231
Timestep Consumption Time: 2.55058
PPO Batch Consumption Time: 0.29345
Total Iteration Time: 4.83290

Cumulative Model Updates: 99,802
Cumulative Timesteps: 832,228,364

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 832228364...
Checkpoint 832228364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,364.50062
Policy Entropy: 3.71605
Value Function Loss: 0.02416

Mean KL Divergence: 0.00650
SB3 Clip Fraction: 0.08039
Policy Update Magnitude: 0.56770
Value Function Update Magnitude: 0.55077

Collected Steps per Second: 21,230.68554
Overall Steps per Second: 10,213.43470

Timestep Collection Time: 2.35659
Timestep Consumption Time: 2.54206
PPO Batch Consumption Time: 0.29321
Total Iteration Time: 4.89865

Cumulative Model Updates: 99,808
Cumulative Timesteps: 832,278,396

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,364.50062
Policy Entropy: 3.69889
Value Function Loss: 0.02347

Mean KL Divergence: 0.02170
SB3 Clip Fraction: 0.26140
Policy Update Magnitude: 0.46846
Value Function Update Magnitude: 0.56725

Collected Steps per Second: 21,944.82886
Overall Steps per Second: 10,420.21193

Timestep Collection Time: 2.27844
Timestep Consumption Time: 2.51993
PPO Batch Consumption Time: 0.28933
Total Iteration Time: 4.79837

Cumulative Model Updates: 99,814
Cumulative Timesteps: 832,328,396

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 832328396...
Checkpoint 832328396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,364.50062
Policy Entropy: 3.67608
Value Function Loss: 0.02539

Mean KL Divergence: 0.03283
SB3 Clip Fraction: 0.33107
Policy Update Magnitude: 0.31112
Value Function Update Magnitude: 0.50688

Collected Steps per Second: 21,365.21712
Overall Steps per Second: 10,270.03902

Timestep Collection Time: 2.34053
Timestep Consumption Time: 2.52858
PPO Batch Consumption Time: 0.29373
Total Iteration Time: 4.86911

Cumulative Model Updates: 99,820
Cumulative Timesteps: 832,378,402

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 117,744.07201
Policy Entropy: 3.65178
Value Function Loss: 0.03260

Mean KL Divergence: 0.01602
SB3 Clip Fraction: 0.21065
Policy Update Magnitude: 0.33439
Value Function Update Magnitude: 0.56284

Collected Steps per Second: 21,936.53418
Overall Steps per Second: 10,455.17502

Timestep Collection Time: 2.27939
Timestep Consumption Time: 2.50312
PPO Batch Consumption Time: 0.28730
Total Iteration Time: 4.78251

Cumulative Model Updates: 99,826
Cumulative Timesteps: 832,428,404

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 832428404...
Checkpoint 832428404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,035.31272
Policy Entropy: 3.66874
Value Function Loss: 0.04464

Mean KL Divergence: 0.01788
SB3 Clip Fraction: 0.22276
Policy Update Magnitude: 0.36782
Value Function Update Magnitude: 0.50443

Collected Steps per Second: 20,356.63049
Overall Steps per Second: 10,175.34415

Timestep Collection Time: 2.45728
Timestep Consumption Time: 2.45872
PPO Batch Consumption Time: 0.29147
Total Iteration Time: 4.91600

Cumulative Model Updates: 99,832
Cumulative Timesteps: 832,478,426

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,111.52588
Policy Entropy: 3.71133
Value Function Loss: 0.04585

Mean KL Divergence: 0.01595
SB3 Clip Fraction: 0.20117
Policy Update Magnitude: 0.37213
Value Function Update Magnitude: 0.36613

Collected Steps per Second: 20,942.14613
Overall Steps per Second: 10,368.47870

Timestep Collection Time: 2.38772
Timestep Consumption Time: 2.43497
PPO Batch Consumption Time: 0.28811
Total Iteration Time: 4.82269

Cumulative Model Updates: 99,838
Cumulative Timesteps: 832,528,430

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 832528430...
Checkpoint 832528430 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,111.52588
Policy Entropy: 3.74349
Value Function Loss: 0.04274

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.10315
Policy Update Magnitude: 0.46125
Value Function Update Magnitude: 0.30788

Collected Steps per Second: 20,976.38104
Overall Steps per Second: 10,320.76630

Timestep Collection Time: 2.38430
Timestep Consumption Time: 2.46166
PPO Batch Consumption Time: 0.29504
Total Iteration Time: 4.84596

Cumulative Model Updates: 99,844
Cumulative Timesteps: 832,578,444

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,111.52588
Policy Entropy: 3.72722
Value Function Loss: 0.04322

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.13556
Policy Update Magnitude: 0.48869
Value Function Update Magnitude: 0.27665

Collected Steps per Second: 21,037.74428
Overall Steps per Second: 10,132.19090

Timestep Collection Time: 2.37744
Timestep Consumption Time: 2.55890
PPO Batch Consumption Time: 0.29846
Total Iteration Time: 4.93635

Cumulative Model Updates: 99,850
Cumulative Timesteps: 832,628,460

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 832628460...
Checkpoint 832628460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,111.52588
Policy Entropy: 3.67953
Value Function Loss: 0.03656

Mean KL Divergence: 0.01103
SB3 Clip Fraction: 0.15097
Policy Update Magnitude: 0.42649
Value Function Update Magnitude: 0.27347

Collected Steps per Second: 21,410.38194
Overall Steps per Second: 10,289.36239

Timestep Collection Time: 2.33569
Timestep Consumption Time: 2.52448
PPO Batch Consumption Time: 0.29439
Total Iteration Time: 4.86017

Cumulative Model Updates: 99,856
Cumulative Timesteps: 832,678,468

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 120,632.03922
Policy Entropy: 3.65912
Value Function Loss: 0.04486

Mean KL Divergence: 0.01616
SB3 Clip Fraction: 0.20610
Policy Update Magnitude: 0.42667
Value Function Update Magnitude: 0.31566

Collected Steps per Second: 21,431.76512
Overall Steps per Second: 10,099.70481

Timestep Collection Time: 2.33429
Timestep Consumption Time: 2.61912
PPO Batch Consumption Time: 0.30494
Total Iteration Time: 4.95341

Cumulative Model Updates: 99,862
Cumulative Timesteps: 832,728,496

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 832728496...
Checkpoint 832728496 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 60,499.25049
Policy Entropy: 3.65866
Value Function Loss: 0.04108

Mean KL Divergence: 0.01362
SB3 Clip Fraction: 0.17288
Policy Update Magnitude: 0.51556
Value Function Update Magnitude: 0.41501

Collected Steps per Second: 21,148.82387
Overall Steps per Second: 10,252.32038

Timestep Collection Time: 2.36439
Timestep Consumption Time: 2.51295
PPO Batch Consumption Time: 0.28885
Total Iteration Time: 4.87733

Cumulative Model Updates: 99,868
Cumulative Timesteps: 832,778,500

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,063.05954
Policy Entropy: 3.65932
Value Function Loss: 0.03887

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.11998
Policy Update Magnitude: 0.48249
Value Function Update Magnitude: 0.65001

Collected Steps per Second: 21,679.92025
Overall Steps per Second: 10,260.18408

Timestep Collection Time: 2.30656
Timestep Consumption Time: 2.56723
PPO Batch Consumption Time: 0.29943
Total Iteration Time: 4.87379

Cumulative Model Updates: 99,874
Cumulative Timesteps: 832,828,506

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 832828506...
Checkpoint 832828506 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,754.37351
Policy Entropy: 3.68193
Value Function Loss: 0.03383

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.13636
Policy Update Magnitude: 0.51489
Value Function Update Magnitude: 0.67453

Collected Steps per Second: 21,414.53986
Overall Steps per Second: 10,202.40656

Timestep Collection Time: 2.33514
Timestep Consumption Time: 2.56625
PPO Batch Consumption Time: 0.29896
Total Iteration Time: 4.90139

Cumulative Model Updates: 99,880
Cumulative Timesteps: 832,878,512

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 199,801.08556
Policy Entropy: 3.65111
Value Function Loss: 0.04565

Mean KL Divergence: 0.01716
SB3 Clip Fraction: 0.22220
Policy Update Magnitude: 0.50100
Value Function Update Magnitude: 0.53841

Collected Steps per Second: 21,621.93102
Overall Steps per Second: 10,372.67701

Timestep Collection Time: 2.31311
Timestep Consumption Time: 2.50859
PPO Batch Consumption Time: 0.28661
Total Iteration Time: 4.82171

Cumulative Model Updates: 99,886
Cumulative Timesteps: 832,928,526

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 832928526...
Checkpoint 832928526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40,194.38380
Policy Entropy: 3.69435
Value Function Loss: 0.04730

Mean KL Divergence: 0.02706
SB3 Clip Fraction: 0.28240
Policy Update Magnitude: 0.46336
Value Function Update Magnitude: 0.51452

Collected Steps per Second: 21,429.63907
Overall Steps per Second: 10,190.20957

Timestep Collection Time: 2.33359
Timestep Consumption Time: 2.57387
PPO Batch Consumption Time: 0.30028
Total Iteration Time: 4.90746

Cumulative Model Updates: 99,892
Cumulative Timesteps: 832,978,534

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,365.19597
Policy Entropy: 3.71829
Value Function Loss: 0.04786

Mean KL Divergence: 0.01218
SB3 Clip Fraction: 0.14586
Policy Update Magnitude: 0.55082
Value Function Update Magnitude: 0.45043

Collected Steps per Second: 21,369.91273
Overall Steps per Second: 10,188.94227

Timestep Collection Time: 2.34105
Timestep Consumption Time: 2.56898
PPO Batch Consumption Time: 0.29690
Total Iteration Time: 4.91003

Cumulative Model Updates: 99,898
Cumulative Timesteps: 833,028,562

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 833028562...
Checkpoint 833028562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,365.19597
Policy Entropy: 3.73010
Value Function Loss: 0.04223

Mean KL Divergence: 0.01921
SB3 Clip Fraction: 0.25120
Policy Update Magnitude: 0.56374
Value Function Update Magnitude: 0.36589

Collected Steps per Second: 21,617.09119
Overall Steps per Second: 10,361.88429

Timestep Collection Time: 2.31372
Timestep Consumption Time: 2.51320
PPO Batch Consumption Time: 0.28766
Total Iteration Time: 4.82692

Cumulative Model Updates: 99,904
Cumulative Timesteps: 833,078,578

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,365.19597
Policy Entropy: 3.74548
Value Function Loss: 0.04922

Mean KL Divergence: 0.02824
SB3 Clip Fraction: 0.31093
Policy Update Magnitude: 0.39140
Value Function Update Magnitude: 0.28333

Collected Steps per Second: 21,770.49106
Overall Steps per Second: 10,235.51067

Timestep Collection Time: 2.29761
Timestep Consumption Time: 2.58930
PPO Batch Consumption Time: 0.29862
Total Iteration Time: 4.88691

Cumulative Model Updates: 99,910
Cumulative Timesteps: 833,128,598

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 833128598...
Checkpoint 833128598 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,365.19597
Policy Entropy: 3.71289
Value Function Loss: 0.04433

Mean KL Divergence: 0.02346
SB3 Clip Fraction: 0.26648
Policy Update Magnitude: 0.31185
Value Function Update Magnitude: 0.27063

Collected Steps per Second: 21,339.59934
Overall Steps per Second: 10,162.32846

Timestep Collection Time: 2.34391
Timestep Consumption Time: 2.57800
PPO Batch Consumption Time: 0.30184
Total Iteration Time: 4.92190

Cumulative Model Updates: 99,916
Cumulative Timesteps: 833,178,616

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 180,495.76527
Policy Entropy: 3.69374
Value Function Loss: 0.04760

Mean KL Divergence: 0.02503
SB3 Clip Fraction: 0.27623
Policy Update Magnitude: 0.32871
Value Function Update Magnitude: 0.29815

Collected Steps per Second: 21,249.40718
Overall Steps per Second: 10,112.80076

Timestep Collection Time: 2.35338
Timestep Consumption Time: 2.59164
PPO Batch Consumption Time: 0.29978
Total Iteration Time: 4.94502

Cumulative Model Updates: 99,922
Cumulative Timesteps: 833,228,624

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 833228624...
Checkpoint 833228624 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,564.06175
Policy Entropy: 3.67523
Value Function Loss: 0.04758

Mean KL Divergence: 0.01753
SB3 Clip Fraction: 0.22379
Policy Update Magnitude: 0.37935
Value Function Update Magnitude: 0.46782

Collected Steps per Second: 21,282.87264
Overall Steps per Second: 10,136.63727

Timestep Collection Time: 2.35006
Timestep Consumption Time: 2.58412
PPO Batch Consumption Time: 0.30074
Total Iteration Time: 4.93418

Cumulative Model Updates: 99,928
Cumulative Timesteps: 833,278,640

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 158,775.31337
Policy Entropy: 3.66276
Value Function Loss: 0.06068

Mean KL Divergence: 0.01696
SB3 Clip Fraction: 0.20522
Policy Update Magnitude: 0.42522
Value Function Update Magnitude: 0.55069

Collected Steps per Second: 21,568.75441
Overall Steps per Second: 10,166.71836

Timestep Collection Time: 2.31826
Timestep Consumption Time: 2.59994
PPO Batch Consumption Time: 0.30081
Total Iteration Time: 4.91820

Cumulative Model Updates: 99,934
Cumulative Timesteps: 833,328,642

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 833328642...
Checkpoint 833328642 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 94,224.87631
Policy Entropy: 3.67107
Value Function Loss: 0.06787

Mean KL Divergence: 0.01541
SB3 Clip Fraction: 0.18524
Policy Update Magnitude: 0.50434
Value Function Update Magnitude: 0.53153

Collected Steps per Second: 21,528.01748
Overall Steps per Second: 10,343.82430

Timestep Collection Time: 2.32321
Timestep Consumption Time: 2.51195
PPO Batch Consumption Time: 0.29036
Total Iteration Time: 4.83516

Cumulative Model Updates: 99,940
Cumulative Timesteps: 833,378,656

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,301.38403
Policy Entropy: 3.65741
Value Function Loss: 0.06882

Mean KL Divergence: 0.01639
SB3 Clip Fraction: 0.19294
Policy Update Magnitude: 0.59820
Value Function Update Magnitude: 0.55092

Collected Steps per Second: 21,755.84220
Overall Steps per Second: 10,368.70200

Timestep Collection Time: 2.29869
Timestep Consumption Time: 2.52448
PPO Batch Consumption Time: 0.29543
Total Iteration Time: 4.82317

Cumulative Model Updates: 99,946
Cumulative Timesteps: 833,428,666

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 833428666...
Checkpoint 833428666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,626.35552
Policy Entropy: 3.64624
Value Function Loss: 0.06679

Mean KL Divergence: 0.01625
SB3 Clip Fraction: 0.19779
Policy Update Magnitude: 0.63403
Value Function Update Magnitude: 0.63205

Collected Steps per Second: 21,506.61084
Overall Steps per Second: 10,327.62478

Timestep Collection Time: 2.32561
Timestep Consumption Time: 2.51732
PPO Batch Consumption Time: 0.28837
Total Iteration Time: 4.84293

Cumulative Model Updates: 99,952
Cumulative Timesteps: 833,478,682

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 106,117.98103
Policy Entropy: 3.67003
Value Function Loss: 0.06853

Mean KL Divergence: 0.01486
SB3 Clip Fraction: 0.18320
Policy Update Magnitude: 0.60133
Value Function Update Magnitude: 0.55274

Collected Steps per Second: 21,559.18927
Overall Steps per Second: 10,337.62440

Timestep Collection Time: 2.32142
Timestep Consumption Time: 2.51992
PPO Batch Consumption Time: 0.29511
Total Iteration Time: 4.84134

Cumulative Model Updates: 99,958
Cumulative Timesteps: 833,528,730

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 833528730...
Checkpoint 833528730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,243.40146
Policy Entropy: 3.74623
Value Function Loss: 0.06630

Mean KL Divergence: 0.01401
SB3 Clip Fraction: 0.16742
Policy Update Magnitude: 0.62071
Value Function Update Magnitude: 0.53627

Collected Steps per Second: 21,496.14678
Overall Steps per Second: 10,392.25645

Timestep Collection Time: 2.32609
Timestep Consumption Time: 2.48538
PPO Batch Consumption Time: 0.28916
Total Iteration Time: 4.81147

Cumulative Model Updates: 99,964
Cumulative Timesteps: 833,578,732

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93,971.42543
Policy Entropy: 3.82737
Value Function Loss: 0.06506

Mean KL Divergence: 0.01195
SB3 Clip Fraction: 0.14077
Policy Update Magnitude: 0.70048
Value Function Update Magnitude: 0.58664

Collected Steps per Second: 21,555.61313
Overall Steps per Second: 10,362.82831

Timestep Collection Time: 2.31977
Timestep Consumption Time: 2.50556
PPO Batch Consumption Time: 0.29042
Total Iteration Time: 4.82532

Cumulative Model Updates: 99,970
Cumulative Timesteps: 833,628,736

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 833628736...
Checkpoint 833628736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,344.77783
Policy Entropy: 3.84750
Value Function Loss: 0.05689

Mean KL Divergence: 0.01187
SB3 Clip Fraction: 0.14219
Policy Update Magnitude: 0.73025
Value Function Update Magnitude: 0.64494

Collected Steps per Second: 21,698.06868
Overall Steps per Second: 10,322.33158

Timestep Collection Time: 2.30491
Timestep Consumption Time: 2.54012
PPO Batch Consumption Time: 0.29829
Total Iteration Time: 4.84503

Cumulative Model Updates: 99,976
Cumulative Timesteps: 833,678,748

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,071.13196
Policy Entropy: 3.85738
Value Function Loss: 0.05046

Mean KL Divergence: 0.01111
SB3 Clip Fraction: 0.13432
Policy Update Magnitude: 0.71662
Value Function Update Magnitude: 0.81715

Collected Steps per Second: 21,421.50558
Overall Steps per Second: 10,374.95128

Timestep Collection Time: 2.33457
Timestep Consumption Time: 2.48569
PPO Batch Consumption Time: 0.28906
Total Iteration Time: 4.82026

Cumulative Model Updates: 99,982
Cumulative Timesteps: 833,728,758

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 833728758...
Checkpoint 833728758 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,338.75871
Policy Entropy: 3.85397
Value Function Loss: 0.05314

Mean KL Divergence: 0.01146
SB3 Clip Fraction: 0.14176
Policy Update Magnitude: 0.69898
Value Function Update Magnitude: 0.71671

Collected Steps per Second: 21,483.93517
Overall Steps per Second: 10,289.57671

Timestep Collection Time: 2.32825
Timestep Consumption Time: 2.53298
PPO Batch Consumption Time: 0.29675
Total Iteration Time: 4.86123

Cumulative Model Updates: 99,988
Cumulative Timesteps: 833,778,778

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,376.08952
Policy Entropy: 3.90350
Value Function Loss: 0.05078

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.11642
Policy Update Magnitude: 0.74810
Value Function Update Magnitude: 0.59246

Collected Steps per Second: 21,552.54235
Overall Steps per Second: 10,460.97830

Timestep Collection Time: 2.32056
Timestep Consumption Time: 2.46044
PPO Batch Consumption Time: 0.29457
Total Iteration Time: 4.78101

Cumulative Model Updates: 99,994
Cumulative Timesteps: 833,828,792

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 833828792...
Checkpoint 833828792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,178.48767
Policy Entropy: 3.93700
Value Function Loss: 0.04533

Mean KL Divergence: 0.00726
SB3 Clip Fraction: 0.08854
Policy Update Magnitude: 0.87386
Value Function Update Magnitude: 0.62977

Collected Steps per Second: 20,811.16967
Overall Steps per Second: 10,187.89128

Timestep Collection Time: 2.40371
Timestep Consumption Time: 2.50643
PPO Batch Consumption Time: 0.30115
Total Iteration Time: 4.91014

Cumulative Model Updates: 100,000
Cumulative Timesteps: 833,878,816

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 244.78928
Policy Entropy: 3.92042
Value Function Loss: 0.04153

Mean KL Divergence: 0.00712
SB3 Clip Fraction: 0.08775
Policy Update Magnitude: 0.97664
Value Function Update Magnitude: 0.75967

Collected Steps per Second: 20,887.52878
Overall Steps per Second: 10,385.54693

Timestep Collection Time: 2.39550
Timestep Consumption Time: 2.42235
PPO Batch Consumption Time: 0.28771
Total Iteration Time: 4.81785

Cumulative Model Updates: 100,006
Cumulative Timesteps: 833,928,852

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 833928852...
Checkpoint 833928852 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,703.91648
Policy Entropy: 3.86388
Value Function Loss: 0.04273

Mean KL Divergence: 0.00708
SB3 Clip Fraction: 0.08513
Policy Update Magnitude: 1.00974
Value Function Update Magnitude: 0.71715

Collected Steps per Second: 20,781.96702
Overall Steps per Second: 10,284.42278

Timestep Collection Time: 2.40612
Timestep Consumption Time: 2.45599
PPO Batch Consumption Time: 0.29002
Total Iteration Time: 4.86211

Cumulative Model Updates: 100,012
Cumulative Timesteps: 833,978,856

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,575.98774
Policy Entropy: 3.82463
Value Function Loss: 0.04352

Mean KL Divergence: 0.00770
SB3 Clip Fraction: 0.09942
Policy Update Magnitude: 0.92796
Value Function Update Magnitude: 0.69878

Collected Steps per Second: 21,375.63532
Overall Steps per Second: 10,246.46994

Timestep Collection Time: 2.34033
Timestep Consumption Time: 2.54194
PPO Batch Consumption Time: 0.29487
Total Iteration Time: 4.88227

Cumulative Model Updates: 100,018
Cumulative Timesteps: 834,028,882

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 834028882...
Checkpoint 834028882 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,070.44929
Policy Entropy: 3.83880
Value Function Loss: 0.04624

Mean KL Divergence: 0.00732
SB3 Clip Fraction: 0.09505
Policy Update Magnitude: 0.83948
Value Function Update Magnitude: 0.70493

Collected Steps per Second: 21,834.36140
Overall Steps per Second: 10,456.97342

Timestep Collection Time: 2.29052
Timestep Consumption Time: 2.49213
PPO Batch Consumption Time: 0.28730
Total Iteration Time: 4.78265

Cumulative Model Updates: 100,024
Cumulative Timesteps: 834,078,894

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,394.18839
Policy Entropy: 3.86041
Value Function Loss: 0.04761

Mean KL Divergence: 0.00662
SB3 Clip Fraction: 0.08047
Policy Update Magnitude: 0.89804
Value Function Update Magnitude: 0.67829

Collected Steps per Second: 21,623.77017
Overall Steps per Second: 10,370.32753

Timestep Collection Time: 2.31357
Timestep Consumption Time: 2.51058
PPO Batch Consumption Time: 0.28963
Total Iteration Time: 4.82415

Cumulative Model Updates: 100,030
Cumulative Timesteps: 834,128,922

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 834128922...
Checkpoint 834128922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,704.15465
Policy Entropy: 3.86632
Value Function Loss: 0.04772

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.10977
Policy Update Magnitude: 0.82349
Value Function Update Magnitude: 0.62757

Collected Steps per Second: 21,243.92662
Overall Steps per Second: 10,233.98119

Timestep Collection Time: 2.35540
Timestep Consumption Time: 2.53399
PPO Batch Consumption Time: 0.28862
Total Iteration Time: 4.88940

Cumulative Model Updates: 100,036
Cumulative Timesteps: 834,178,960

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,511.98405
Policy Entropy: 3.83833
Value Function Loss: 0.04750

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.09699
Policy Update Magnitude: 0.72806
Value Function Update Magnitude: 0.73856

Collected Steps per Second: 21,502.69319
Overall Steps per Second: 10,212.31566

Timestep Collection Time: 2.32594
Timestep Consumption Time: 2.57148
PPO Batch Consumption Time: 0.29890
Total Iteration Time: 4.89742

Cumulative Model Updates: 100,042
Cumulative Timesteps: 834,228,974

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 834228974...
Checkpoint 834228974 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,227.35430
Policy Entropy: 3.82952
Value Function Loss: 0.04874

Mean KL Divergence: 0.00697
SB3 Clip Fraction: 0.08434
Policy Update Magnitude: 0.66561
Value Function Update Magnitude: 0.61890

Collected Steps per Second: 21,465.39684
Overall Steps per Second: 10,258.20145

Timestep Collection Time: 2.32980
Timestep Consumption Time: 2.54533
PPO Batch Consumption Time: 0.29655
Total Iteration Time: 4.87512

Cumulative Model Updates: 100,048
Cumulative Timesteps: 834,278,984

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 351.13168
Policy Entropy: 3.82145
Value Function Loss: 0.04508

Mean KL Divergence: 0.00593
SB3 Clip Fraction: 0.07202
Policy Update Magnitude: 0.76978
Value Function Update Magnitude: 0.58815

Collected Steps per Second: 21,435.84975
Overall Steps per Second: 10,280.68751

Timestep Collection Time: 2.33403
Timestep Consumption Time: 2.53257
PPO Batch Consumption Time: 0.29305
Total Iteration Time: 4.86660

Cumulative Model Updates: 100,054
Cumulative Timesteps: 834,329,016

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 834329016...
Checkpoint 834329016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,218.28177
Policy Entropy: 3.81109
Value Function Loss: 0.04600

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.13080
Policy Update Magnitude: 0.74482
Value Function Update Magnitude: 0.66394

Collected Steps per Second: 21,416.84874
Overall Steps per Second: 10,205.94148

Timestep Collection Time: 2.33582
Timestep Consumption Time: 2.56583
PPO Batch Consumption Time: 0.30023
Total Iteration Time: 4.90165

Cumulative Model Updates: 100,060
Cumulative Timesteps: 834,379,042

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,102.69562
Policy Entropy: 3.82021
Value Function Loss: 0.04557

Mean KL Divergence: 0.02349
SB3 Clip Fraction: 0.23700
Policy Update Magnitude: 0.57314
Value Function Update Magnitude: 0.57503

Collected Steps per Second: 21,493.58965
Overall Steps per Second: 10,319.44270

Timestep Collection Time: 2.32739
Timestep Consumption Time: 2.52016
PPO Batch Consumption Time: 0.28955
Total Iteration Time: 4.84755

Cumulative Model Updates: 100,066
Cumulative Timesteps: 834,429,066

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 834429066...
Checkpoint 834429066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,523.69452
Policy Entropy: 3.82590
Value Function Loss: 0.04964

Mean KL Divergence: 0.01200
SB3 Clip Fraction: 0.14853
Policy Update Magnitude: 0.49840
Value Function Update Magnitude: 0.56462

Collected Steps per Second: 21,863.71194
Overall Steps per Second: 10,389.88000

Timestep Collection Time: 2.28909
Timestep Consumption Time: 2.52791
PPO Batch Consumption Time: 0.28793
Total Iteration Time: 4.81700

Cumulative Model Updates: 100,072
Cumulative Timesteps: 834,479,114

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,009.97719
Policy Entropy: 3.80951
Value Function Loss: 0.05675

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.11352
Policy Update Magnitude: 0.58334
Value Function Update Magnitude: 0.61614

Collected Steps per Second: 21,637.70276
Overall Steps per Second: 10,352.43505

Timestep Collection Time: 2.31152
Timestep Consumption Time: 2.51981
PPO Batch Consumption Time: 0.28887
Total Iteration Time: 4.83133

Cumulative Model Updates: 100,078
Cumulative Timesteps: 834,529,130

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 834529130...
Checkpoint 834529130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,520.48682
Policy Entropy: 3.78327
Value Function Loss: 0.06577

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.11388
Policy Update Magnitude: 0.56856
Value Function Update Magnitude: 0.61501

Collected Steps per Second: 20,873.85629
Overall Steps per Second: 10,217.59293

Timestep Collection Time: 2.39592
Timestep Consumption Time: 2.49878
PPO Batch Consumption Time: 0.28825
Total Iteration Time: 4.89469

Cumulative Model Updates: 100,084
Cumulative Timesteps: 834,579,142

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,953.27840
Policy Entropy: 3.77299
Value Function Loss: 0.06084

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.12007
Policy Update Magnitude: 0.57530
Value Function Update Magnitude: 0.48635

Collected Steps per Second: 20,276.82686
Overall Steps per Second: 10,119.50068

Timestep Collection Time: 2.46626
Timestep Consumption Time: 2.47548
PPO Batch Consumption Time: 0.29589
Total Iteration Time: 4.94175

Cumulative Model Updates: 100,090
Cumulative Timesteps: 834,629,150

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 834629150...
Checkpoint 834629150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,844.37131
Policy Entropy: 3.76307
Value Function Loss: 0.05910

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.11463
Policy Update Magnitude: 0.56035
Value Function Update Magnitude: 0.47380

Collected Steps per Second: 20,560.30658
Overall Steps per Second: 10,224.65104

Timestep Collection Time: 2.43284
Timestep Consumption Time: 2.45926
PPO Batch Consumption Time: 0.29443
Total Iteration Time: 4.89210

Cumulative Model Updates: 100,096
Cumulative Timesteps: 834,679,170

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,432.16990
Policy Entropy: 3.77010
Value Function Loss: 0.05800

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.11981
Policy Update Magnitude: 0.55118
Value Function Update Magnitude: 0.47578

Collected Steps per Second: 20,765.24202
Overall Steps per Second: 10,334.99174

Timestep Collection Time: 2.40826
Timestep Consumption Time: 2.43045
PPO Batch Consumption Time: 0.28803
Total Iteration Time: 4.83871

Cumulative Model Updates: 100,102
Cumulative Timesteps: 834,729,178

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 834729178...
Checkpoint 834729178 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,658.99370
Policy Entropy: 3.74693
Value Function Loss: 0.05485

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.13019
Policy Update Magnitude: 0.48934
Value Function Update Magnitude: 0.42864

Collected Steps per Second: 21,091.16831
Overall Steps per Second: 10,331.44034

Timestep Collection Time: 2.37275
Timestep Consumption Time: 2.47111
PPO Batch Consumption Time: 0.29608
Total Iteration Time: 4.84386

Cumulative Model Updates: 100,108
Cumulative Timesteps: 834,779,222

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,738.54734
Policy Entropy: 3.71538
Value Function Loss: 0.05392

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.14005
Policy Update Magnitude: 0.44013
Value Function Update Magnitude: 0.50853

Collected Steps per Second: 20,981.18900
Overall Steps per Second: 10,361.14834

Timestep Collection Time: 2.38366
Timestep Consumption Time: 2.44322
PPO Batch Consumption Time: 0.28915
Total Iteration Time: 4.82688

Cumulative Model Updates: 100,114
Cumulative Timesteps: 834,829,234

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 834829234...
Checkpoint 834829234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,293.06088
Policy Entropy: 3.70034
Value Function Loss: 0.05046

Mean KL Divergence: 0.01093
SB3 Clip Fraction: 0.14184
Policy Update Magnitude: 0.40131
Value Function Update Magnitude: 0.42127

Collected Steps per Second: 20,812.58462
Overall Steps per Second: 10,214.28452

Timestep Collection Time: 2.40316
Timestep Consumption Time: 2.49351
PPO Batch Consumption Time: 0.28825
Total Iteration Time: 4.89667

Cumulative Model Updates: 100,120
Cumulative Timesteps: 834,879,250

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,168.06115
Policy Entropy: 3.68510
Value Function Loss: 0.04792

Mean KL Divergence: 0.01114
SB3 Clip Fraction: 0.14606
Policy Update Magnitude: 0.39017
Value Function Update Magnitude: 0.36542

Collected Steps per Second: 21,568.61934
Overall Steps per Second: 10,402.02766

Timestep Collection Time: 2.31957
Timestep Consumption Time: 2.49007
PPO Batch Consumption Time: 0.28872
Total Iteration Time: 4.80964

Cumulative Model Updates: 100,126
Cumulative Timesteps: 834,929,280

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 834929280...
Checkpoint 834929280 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 53,477.29326
Policy Entropy: 3.70305
Value Function Loss: 0.04948

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.13905
Policy Update Magnitude: 0.39300
Value Function Update Magnitude: 0.40509

Collected Steps per Second: 21,762.03377
Overall Steps per Second: 10,326.90901

Timestep Collection Time: 2.29822
Timestep Consumption Time: 2.54485
PPO Batch Consumption Time: 0.30002
Total Iteration Time: 4.84308

Cumulative Model Updates: 100,132
Cumulative Timesteps: 834,979,294

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,776.64302
Policy Entropy: 3.70474
Value Function Loss: 0.04523

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.13916
Policy Update Magnitude: 0.38736
Value Function Update Magnitude: 0.42911

Collected Steps per Second: 21,608.57139
Overall Steps per Second: 10,370.07092

Timestep Collection Time: 2.31538
Timestep Consumption Time: 2.50928
PPO Batch Consumption Time: 0.28873
Total Iteration Time: 4.82465

Cumulative Model Updates: 100,138
Cumulative Timesteps: 835,029,326

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 835029326...
Checkpoint 835029326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,440.44263
Policy Entropy: 3.70748
Value Function Loss: 0.04474

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.14249
Policy Update Magnitude: 0.39531
Value Function Update Magnitude: 0.48040

Collected Steps per Second: 21,574.79989
Overall Steps per Second: 10,301.11861

Timestep Collection Time: 2.31770
Timestep Consumption Time: 2.53653
PPO Batch Consumption Time: 0.29383
Total Iteration Time: 4.85423

Cumulative Model Updates: 100,144
Cumulative Timesteps: 835,079,330

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,780.60384
Policy Entropy: 3.70331
Value Function Loss: 0.05368

Mean KL Divergence: 0.01103
SB3 Clip Fraction: 0.14660
Policy Update Magnitude: 0.38720
Value Function Update Magnitude: 0.39524

Collected Steps per Second: 21,426.05070
Overall Steps per Second: 10,223.08193

Timestep Collection Time: 2.33435
Timestep Consumption Time: 2.55810
PPO Batch Consumption Time: 0.29674
Total Iteration Time: 4.89246

Cumulative Model Updates: 100,150
Cumulative Timesteps: 835,129,346

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 835129346...
Checkpoint 835129346 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,251.24021
Policy Entropy: 3.69487
Value Function Loss: 0.04762

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.14297
Policy Update Magnitude: 0.38738
Value Function Update Magnitude: 0.43212

Collected Steps per Second: 21,386.35706
Overall Steps per Second: 10,342.88092

Timestep Collection Time: 2.33803
Timestep Consumption Time: 2.49640
PPO Batch Consumption Time: 0.28767
Total Iteration Time: 4.83444

Cumulative Model Updates: 100,156
Cumulative Timesteps: 835,179,348

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,251.24021
Policy Entropy: 3.68521
Value Function Loss: 0.04846

Mean KL Divergence: 0.01076
SB3 Clip Fraction: 0.14720
Policy Update Magnitude: 0.38566
Value Function Update Magnitude: 0.49368

Collected Steps per Second: 21,813.25518
Overall Steps per Second: 10,309.18487

Timestep Collection Time: 2.29328
Timestep Consumption Time: 2.55909
PPO Batch Consumption Time: 0.29593
Total Iteration Time: 4.85237

Cumulative Model Updates: 100,162
Cumulative Timesteps: 835,229,372

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 835229372...
Checkpoint 835229372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,251.24021
Policy Entropy: 3.68481
Value Function Loss: 0.04356

Mean KL Divergence: 0.01084
SB3 Clip Fraction: 0.14376
Policy Update Magnitude: 0.37667
Value Function Update Magnitude: 0.41730

Collected Steps per Second: 21,097.80640
Overall Steps per Second: 10,026.75224

Timestep Collection Time: 2.37067
Timestep Consumption Time: 2.61758
PPO Batch Consumption Time: 0.31015
Total Iteration Time: 4.98826

Cumulative Model Updates: 100,168
Cumulative Timesteps: 835,279,388

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 74,602.60156
Policy Entropy: 3.66734
Value Function Loss: 0.04383

Mean KL Divergence: 0.01077
SB3 Clip Fraction: 0.14315
Policy Update Magnitude: 0.40472
Value Function Update Magnitude: 0.42063

Collected Steps per Second: 21,116.37291
Overall Steps per Second: 10,372.78248

Timestep Collection Time: 2.36793
Timestep Consumption Time: 2.45257
PPO Batch Consumption Time: 0.28820
Total Iteration Time: 4.82050

Cumulative Model Updates: 100,174
Cumulative Timesteps: 835,329,390

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 835329390...
Checkpoint 835329390 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 74,602.60156
Policy Entropy: 3.66287
Value Function Loss: 0.04067

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.13916
Policy Update Magnitude: 0.43614
Value Function Update Magnitude: 0.63104

Collected Steps per Second: 20,416.09963
Overall Steps per Second: 10,246.82578

Timestep Collection Time: 2.45061
Timestep Consumption Time: 2.43207
PPO Batch Consumption Time: 0.28909
Total Iteration Time: 4.88268

Cumulative Model Updates: 100,180
Cumulative Timesteps: 835,379,422

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 74,602.60156
Policy Entropy: 3.66406
Value Function Loss: 0.03833

Mean KL Divergence: 0.01050
SB3 Clip Fraction: 0.14333
Policy Update Magnitude: 0.47010
Value Function Update Magnitude: 0.67279

Collected Steps per Second: 20,949.92039
Overall Steps per Second: 10,096.53869

Timestep Collection Time: 2.38808
Timestep Consumption Time: 2.56709
PPO Batch Consumption Time: 0.30136
Total Iteration Time: 4.95516

Cumulative Model Updates: 100,186
Cumulative Timesteps: 835,429,452

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 835429452...
Checkpoint 835429452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 74,602.60156
Policy Entropy: 3.68319
Value Function Loss: 0.03334

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.13862
Policy Update Magnitude: 0.44894
Value Function Update Magnitude: 0.57731

Collected Steps per Second: 21,101.12909
Overall Steps per Second: 10,206.81228

Timestep Collection Time: 2.37134
Timestep Consumption Time: 2.53107
PPO Batch Consumption Time: 0.29251
Total Iteration Time: 4.90241

Cumulative Model Updates: 100,192
Cumulative Timesteps: 835,479,490

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 74,602.60156
Policy Entropy: 3.67359
Value Function Loss: 0.03414

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.14074
Policy Update Magnitude: 0.42516
Value Function Update Magnitude: 0.55134

Collected Steps per Second: 21,323.07830
Overall Steps per Second: 10,366.74639

Timestep Collection Time: 2.34666
Timestep Consumption Time: 2.48012
PPO Batch Consumption Time: 0.28809
Total Iteration Time: 4.82678

Cumulative Model Updates: 100,198
Cumulative Timesteps: 835,529,528

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 835529528...
Checkpoint 835529528 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 94,358.87598
Policy Entropy: 3.68060
Value Function Loss: 0.03169

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.14118
Policy Update Magnitude: 0.43080
Value Function Update Magnitude: 0.55722

Collected Steps per Second: 21,474.21094
Overall Steps per Second: 10,356.22254

Timestep Collection Time: 2.32875
Timestep Consumption Time: 2.50004
PPO Batch Consumption Time: 0.28674
Total Iteration Time: 4.82879

Cumulative Model Updates: 100,204
Cumulative Timesteps: 835,579,536

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 156,745.08058
Policy Entropy: 3.66543
Value Function Loss: 0.03664

Mean KL Divergence: 0.01111
SB3 Clip Fraction: 0.14852
Policy Update Magnitude: 0.43234
Value Function Update Magnitude: 0.60924

Collected Steps per Second: 21,753.39611
Overall Steps per Second: 10,353.71736

Timestep Collection Time: 2.29877
Timestep Consumption Time: 2.53100
PPO Batch Consumption Time: 0.28982
Total Iteration Time: 4.82976

Cumulative Model Updates: 100,210
Cumulative Timesteps: 835,629,542

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 835629542...
Checkpoint 835629542 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 124,203.48188
Policy Entropy: 3.67461
Value Function Loss: 0.04105

Mean KL Divergence: 0.01084
SB3 Clip Fraction: 0.14354
Policy Update Magnitude: 0.47379
Value Function Update Magnitude: 0.65904

Collected Steps per Second: 21,327.39353
Overall Steps per Second: 10,254.16399

Timestep Collection Time: 2.34459
Timestep Consumption Time: 2.53187
PPO Batch Consumption Time: 0.29189
Total Iteration Time: 4.87646

Cumulative Model Updates: 100,216
Cumulative Timesteps: 835,679,546

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53,482.46282
Policy Entropy: 3.68308
Value Function Loss: 0.04234

Mean KL Divergence: 0.01114
SB3 Clip Fraction: 0.14818
Policy Update Magnitude: 0.47827
Value Function Update Magnitude: 0.58148

Collected Steps per Second: 21,828.19231
Overall Steps per Second: 10,411.92425

Timestep Collection Time: 2.29062
Timestep Consumption Time: 2.51157
PPO Batch Consumption Time: 0.28895
Total Iteration Time: 4.80219

Cumulative Model Updates: 100,222
Cumulative Timesteps: 835,729,546

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 835729546...
Checkpoint 835729546 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 103,333.98457
Policy Entropy: 3.68698
Value Function Loss: 0.04363

Mean KL Divergence: 0.01093
SB3 Clip Fraction: 0.14317
Policy Update Magnitude: 0.46688
Value Function Update Magnitude: 0.51487

Collected Steps per Second: 21,319.68020
Overall Steps per Second: 10,271.28235

Timestep Collection Time: 2.34769
Timestep Consumption Time: 2.52531
PPO Batch Consumption Time: 0.29126
Total Iteration Time: 4.87300

Cumulative Model Updates: 100,228
Cumulative Timesteps: 835,779,598

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 121,584.48498
Policy Entropy: 3.67560
Value Function Loss: 0.03915

Mean KL Divergence: 0.01065
SB3 Clip Fraction: 0.13714
Policy Update Magnitude: 0.47596
Value Function Update Magnitude: 0.49408

Collected Steps per Second: 21,495.60059
Overall Steps per Second: 10,310.44083

Timestep Collection Time: 2.32680
Timestep Consumption Time: 2.52420
PPO Batch Consumption Time: 0.28963
Total Iteration Time: 4.85101

Cumulative Model Updates: 100,234
Cumulative Timesteps: 835,829,614

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 835829614...
Checkpoint 835829614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 58,880.24701
Policy Entropy: 3.66413
Value Function Loss: 0.04194

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.13367
Policy Update Magnitude: 0.47107
Value Function Update Magnitude: 0.45874

Collected Steps per Second: 21,212.51722
Overall Steps per Second: 10,148.94639

Timestep Collection Time: 2.35917
Timestep Consumption Time: 2.57178
PPO Batch Consumption Time: 0.29711
Total Iteration Time: 4.93096

Cumulative Model Updates: 100,240
Cumulative Timesteps: 835,879,658

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,379.89148
Policy Entropy: 3.67134
Value Function Loss: 0.03880

Mean KL Divergence: 0.01092
SB3 Clip Fraction: 0.14379
Policy Update Magnitude: 0.43796
Value Function Update Magnitude: 0.41967

Collected Steps per Second: 21,948.37521
Overall Steps per Second: 10,121.57523

Timestep Collection Time: 2.27944
Timestep Consumption Time: 2.66347
PPO Batch Consumption Time: 0.31428
Total Iteration Time: 4.94291

Cumulative Model Updates: 100,246
Cumulative Timesteps: 835,929,688

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 835929688...
Checkpoint 835929688 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,109.11766
Policy Entropy: 3.67181
Value Function Loss: 0.03835

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.13944
Policy Update Magnitude: 0.40022
Value Function Update Magnitude: 0.41167

Collected Steps per Second: 21,382.79056
Overall Steps per Second: 10,326.49439

Timestep Collection Time: 2.33880
Timestep Consumption Time: 2.50409
PPO Batch Consumption Time: 0.28723
Total Iteration Time: 4.84288

Cumulative Model Updates: 100,252
Cumulative Timesteps: 835,979,698

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 121,618.44707
Policy Entropy: 3.68027
Value Function Loss: 0.03446

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.13685
Policy Update Magnitude: 0.38251
Value Function Update Magnitude: 0.44203

Collected Steps per Second: 21,652.64851
Overall Steps per Second: 10,321.63381

Timestep Collection Time: 2.30928
Timestep Consumption Time: 2.53511
PPO Batch Consumption Time: 0.28958
Total Iteration Time: 4.84439

Cumulative Model Updates: 100,258
Cumulative Timesteps: 836,029,700

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 836029700...
Checkpoint 836029700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 79,801.73124
Policy Entropy: 3.68544
Value Function Loss: 0.03204

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.13855
Policy Update Magnitude: 0.37516
Value Function Update Magnitude: 0.46262

Collected Steps per Second: 21,221.57930
Overall Steps per Second: 10,156.87728

Timestep Collection Time: 2.35713
Timestep Consumption Time: 2.56781
PPO Batch Consumption Time: 0.29970
Total Iteration Time: 4.92494

Cumulative Model Updates: 100,264
Cumulative Timesteps: 836,079,722

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79,801.73124
Policy Entropy: 3.68274
Value Function Loss: 0.03037

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.13862
Policy Update Magnitude: 0.36670
Value Function Update Magnitude: 0.45773

Collected Steps per Second: 21,710.42400
Overall Steps per Second: 10,357.95857

Timestep Collection Time: 2.30323
Timestep Consumption Time: 2.52437
PPO Batch Consumption Time: 0.28834
Total Iteration Time: 4.82759

Cumulative Model Updates: 100,270
Cumulative Timesteps: 836,129,726

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 836129726...
Checkpoint 836129726 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 79,801.73124
Policy Entropy: 3.68371
Value Function Loss: 0.02724

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.14495
Policy Update Magnitude: 0.35475
Value Function Update Magnitude: 0.47521

Collected Steps per Second: 21,165.72828
Overall Steps per Second: 10,288.68278

Timestep Collection Time: 2.36297
Timestep Consumption Time: 2.49810
PPO Batch Consumption Time: 0.28630
Total Iteration Time: 4.86107

Cumulative Model Updates: 100,276
Cumulative Timesteps: 836,179,740

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68,117.19065
Policy Entropy: 3.67368
Value Function Loss: 0.02650

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.14136
Policy Update Magnitude: 0.34703
Value Function Update Magnitude: 0.51868

Collected Steps per Second: 21,065.30675
Overall Steps per Second: 10,381.90320

Timestep Collection Time: 2.37414
Timestep Consumption Time: 2.44309
PPO Batch Consumption Time: 0.28867
Total Iteration Time: 4.81723

Cumulative Model Updates: 100,282
Cumulative Timesteps: 836,229,752

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 836229752...
Checkpoint 836229752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,755.09670
Policy Entropy: 3.69490
Value Function Loss: 0.02637

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.14259
Policy Update Magnitude: 0.34461
Value Function Update Magnitude: 0.54744

Collected Steps per Second: 20,615.90628
Overall Steps per Second: 10,243.09106

Timestep Collection Time: 2.42638
Timestep Consumption Time: 2.45711
PPO Batch Consumption Time: 0.29263
Total Iteration Time: 4.88349

Cumulative Model Updates: 100,288
Cumulative Timesteps: 836,279,774

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,314.15950
Policy Entropy: 3.69181
Value Function Loss: 0.02644

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.14123
Policy Update Magnitude: 0.36671
Value Function Update Magnitude: 0.71063

Collected Steps per Second: 20,706.24913
Overall Steps per Second: 10,320.47968

Timestep Collection Time: 2.41521
Timestep Consumption Time: 2.43049
PPO Batch Consumption Time: 0.28812
Total Iteration Time: 4.84570

Cumulative Model Updates: 100,294
Cumulative Timesteps: 836,329,784

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 836329784...
Checkpoint 836329784 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,738.73983
Policy Entropy: 3.69800
Value Function Loss: 0.02783

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.14435
Policy Update Magnitude: 0.39108
Value Function Update Magnitude: 0.69703

Collected Steps per Second: 21,248.31290
Overall Steps per Second: 10,287.73430

Timestep Collection Time: 2.35426
Timestep Consumption Time: 2.50823
PPO Batch Consumption Time: 0.28811
Total Iteration Time: 4.86249

Cumulative Model Updates: 100,300
Cumulative Timesteps: 836,379,808

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,738.73983
Policy Entropy: 3.67902
Value Function Loss: 0.03012

Mean KL Divergence: 0.01047
SB3 Clip Fraction: 0.14503
Policy Update Magnitude: 0.41448
Value Function Update Magnitude: 0.64685

Collected Steps per Second: 21,822.87093
Overall Steps per Second: 10,469.24438

Timestep Collection Time: 2.29127
Timestep Consumption Time: 2.48482
PPO Batch Consumption Time: 0.28913
Total Iteration Time: 4.77608

Cumulative Model Updates: 100,306
Cumulative Timesteps: 836,429,810

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 836429810...
Checkpoint 836429810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,738.73983
Policy Entropy: 3.65670
Value Function Loss: 0.03026

Mean KL Divergence: 0.01050
SB3 Clip Fraction: 0.14214
Policy Update Magnitude: 0.43994
Value Function Update Magnitude: 0.52554

Collected Steps per Second: 21,331.31310
Overall Steps per Second: 10,252.33708

Timestep Collection Time: 2.34482
Timestep Consumption Time: 2.53388
PPO Batch Consumption Time: 0.29196
Total Iteration Time: 4.87869

Cumulative Model Updates: 100,312
Cumulative Timesteps: 836,479,828

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 129,270.18302
Policy Entropy: 3.66293
Value Function Loss: 0.03119

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.13932
Policy Update Magnitude: 0.45573
Value Function Update Magnitude: 0.55832

Collected Steps per Second: 21,853.09682
Overall Steps per Second: 10,235.80184

Timestep Collection Time: 2.28874
Timestep Consumption Time: 2.59764
PPO Batch Consumption Time: 0.30351
Total Iteration Time: 4.88638

Cumulative Model Updates: 100,318
Cumulative Timesteps: 836,529,844

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 836529844...
Checkpoint 836529844 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 77,784.77557
Policy Entropy: 3.68754
Value Function Loss: 0.03314

Mean KL Divergence: 0.01103
SB3 Clip Fraction: 0.14985
Policy Update Magnitude: 0.45640
Value Function Update Magnitude: 0.55500

Collected Steps per Second: 21,285.21896
Overall Steps per Second: 10,214.05433

Timestep Collection Time: 2.35140
Timestep Consumption Time: 2.54871
PPO Batch Consumption Time: 0.29436
Total Iteration Time: 4.90011

Cumulative Model Updates: 100,324
Cumulative Timesteps: 836,579,894

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77,784.77557
Policy Entropy: 3.68757
Value Function Loss: 0.03026

Mean KL Divergence: 0.01065
SB3 Clip Fraction: 0.14321
Policy Update Magnitude: 0.43687
Value Function Update Magnitude: 0.60344

Collected Steps per Second: 21,643.26229
Overall Steps per Second: 10,231.56575

Timestep Collection Time: 2.31047
Timestep Consumption Time: 2.57696
PPO Batch Consumption Time: 0.29758
Total Iteration Time: 4.88742

Cumulative Model Updates: 100,330
Cumulative Timesteps: 836,629,900

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 836629900...
Checkpoint 836629900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 77,784.77557
Policy Entropy: 3.67800
Value Function Loss: 0.02946

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.14509
Policy Update Magnitude: 0.40170
Value Function Update Magnitude: 0.56819

Collected Steps per Second: 21,439.46768
Overall Steps per Second: 10,232.47302

Timestep Collection Time: 2.33317
Timestep Consumption Time: 2.55538
PPO Batch Consumption Time: 0.29672
Total Iteration Time: 4.88855

Cumulative Model Updates: 100,336
Cumulative Timesteps: 836,679,922

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77,784.77557
Policy Entropy: 3.65356
Value Function Loss: 0.03113

Mean KL Divergence: 0.01110
SB3 Clip Fraction: 0.15051
Policy Update Magnitude: 0.36229
Value Function Update Magnitude: 0.42460

Collected Steps per Second: 21,618.71139
Overall Steps per Second: 10,385.19347

Timestep Collection Time: 2.31281
Timestep Consumption Time: 2.50174
PPO Batch Consumption Time: 0.28863
Total Iteration Time: 4.81455

Cumulative Model Updates: 100,342
Cumulative Timesteps: 836,729,922

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 836729922...
Checkpoint 836729922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 77,784.77557
Policy Entropy: 3.65952
Value Function Loss: 0.03076

Mean KL Divergence: 0.01058
SB3 Clip Fraction: 0.14457
Policy Update Magnitude: 0.34343
Value Function Update Magnitude: 0.37221

Collected Steps per Second: 20,603.97470
Overall Steps per Second: 10,314.60664

Timestep Collection Time: 2.42808
Timestep Consumption Time: 2.42213
PPO Batch Consumption Time: 0.28715
Total Iteration Time: 4.85021

Cumulative Model Updates: 100,348
Cumulative Timesteps: 836,779,950

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 72,116.49896
Policy Entropy: 3.67779
Value Function Loss: 0.03724

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.14049
Policy Update Magnitude: 0.34580
Value Function Update Magnitude: 0.37406

Collected Steps per Second: 20,865.80843
Overall Steps per Second: 10,345.01113

Timestep Collection Time: 2.39761
Timestep Consumption Time: 2.43835
PPO Batch Consumption Time: 0.28912
Total Iteration Time: 4.83595

Cumulative Model Updates: 100,354
Cumulative Timesteps: 836,829,978

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 836829978...
Checkpoint 836829978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 58,413.48755
Policy Entropy: 3.69820
Value Function Loss: 0.02641

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.14005
Policy Update Magnitude: 0.34600
Value Function Update Magnitude: 0.38698

Collected Steps per Second: 20,693.50188
Overall Steps per Second: 10,184.11514

Timestep Collection Time: 2.41873
Timestep Consumption Time: 2.49598
PPO Batch Consumption Time: 0.28801
Total Iteration Time: 4.91471

Cumulative Model Updates: 100,360
Cumulative Timesteps: 836,880,030

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58,413.48755
Policy Entropy: 3.69338
Value Function Loss: 0.02519

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.14110
Policy Update Magnitude: 0.35763
Value Function Update Magnitude: 0.37944

Collected Steps per Second: 21,473.94787
Overall Steps per Second: 10,242.75422

Timestep Collection Time: 2.32896
Timestep Consumption Time: 2.55371
PPO Batch Consumption Time: 0.29824
Total Iteration Time: 4.88267

Cumulative Model Updates: 100,366
Cumulative Timesteps: 836,930,042

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 836930042...
Checkpoint 836930042 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 58,413.48755
Policy Entropy: 3.67059
Value Function Loss: 0.02750

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.14339
Policy Update Magnitude: 0.37889
Value Function Update Magnitude: 0.39261

Collected Steps per Second: 21,595.22277
Overall Steps per Second: 10,449.43231

Timestep Collection Time: 2.31681
Timestep Consumption Time: 2.47120
PPO Batch Consumption Time: 0.28820
Total Iteration Time: 4.78801

Cumulative Model Updates: 100,372
Cumulative Timesteps: 836,980,074

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 215,447.18308
Policy Entropy: 3.65460
Value Function Loss: 0.03108

Mean KL Divergence: 0.01059
SB3 Clip Fraction: 0.14061
Policy Update Magnitude: 0.41941
Value Function Update Magnitude: 0.43354

Collected Steps per Second: 21,688.97483
Overall Steps per Second: 10,284.38358

Timestep Collection Time: 2.30652
Timestep Consumption Time: 2.55775
PPO Batch Consumption Time: 0.29688
Total Iteration Time: 4.86427

Cumulative Model Updates: 100,378
Cumulative Timesteps: 837,030,100

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 837030100...
Checkpoint 837030100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 245,078.09075
Policy Entropy: 3.64894
Value Function Loss: 0.03373

Mean KL Divergence: 0.01105
SB3 Clip Fraction: 0.14634
Policy Update Magnitude: 0.47890
Value Function Update Magnitude: 0.61388

Collected Steps per Second: 21,643.02671
Overall Steps per Second: 10,374.92478

Timestep Collection Time: 2.31104
Timestep Consumption Time: 2.51000
PPO Batch Consumption Time: 0.28861
Total Iteration Time: 4.82105

Cumulative Model Updates: 100,384
Cumulative Timesteps: 837,080,118

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85,461.93555
Policy Entropy: 3.67384
Value Function Loss: 0.03182

Mean KL Divergence: 0.01106
SB3 Clip Fraction: 0.14700
Policy Update Magnitude: 0.48695
Value Function Update Magnitude: 0.75660

Collected Steps per Second: 21,773.64268
Overall Steps per Second: 10,318.28070

Timestep Collection Time: 2.29654
Timestep Consumption Time: 2.54962
PPO Batch Consumption Time: 0.29584
Total Iteration Time: 4.84616

Cumulative Model Updates: 100,390
Cumulative Timesteps: 837,130,122

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 837130122...
Checkpoint 837130122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 56,077.66311
Policy Entropy: 3.68656
Value Function Loss: 0.02817

Mean KL Divergence: 0.01085
SB3 Clip Fraction: 0.14569
Policy Update Magnitude: 0.48273
Value Function Update Magnitude: 0.70158

Collected Steps per Second: 21,913.52949
Overall Steps per Second: 10,351.09960

Timestep Collection Time: 2.28233
Timestep Consumption Time: 2.54942
PPO Batch Consumption Time: 0.29045
Total Iteration Time: 4.83176

Cumulative Model Updates: 100,396
Cumulative Timesteps: 837,180,136

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56,077.66311
Policy Entropy: 3.69720
Value Function Loss: 0.02246

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.13953
Policy Update Magnitude: 0.44278
Value Function Update Magnitude: 0.61235

Collected Steps per Second: 20,962.13800
Overall Steps per Second: 10,121.90866

Timestep Collection Time: 2.38640
Timestep Consumption Time: 2.55575
PPO Batch Consumption Time: 0.29261
Total Iteration Time: 4.94215

Cumulative Model Updates: 100,402
Cumulative Timesteps: 837,230,160

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 837230160...
Checkpoint 837230160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 56,077.66311
Policy Entropy: 3.69779
Value Function Loss: 0.02029

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.14126
Policy Update Magnitude: 0.37587
Value Function Update Magnitude: 0.50217

Collected Steps per Second: 21,584.48334
Overall Steps per Second: 10,199.82369

Timestep Collection Time: 2.31759
Timestep Consumption Time: 2.58681
PPO Batch Consumption Time: 0.30101
Total Iteration Time: 4.90440

Cumulative Model Updates: 100,408
Cumulative Timesteps: 837,280,184

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56,077.66311
Policy Entropy: 3.68838
Value Function Loss: 0.02236

Mean KL Divergence: 0.01069
SB3 Clip Fraction: 0.14201
Policy Update Magnitude: 0.34411
Value Function Update Magnitude: 0.42466

Collected Steps per Second: 21,587.44029
Overall Steps per Second: 10,376.08270

Timestep Collection Time: 2.31718
Timestep Consumption Time: 2.50371
PPO Batch Consumption Time: 0.28776
Total Iteration Time: 4.82089

Cumulative Model Updates: 100,414
Cumulative Timesteps: 837,330,206

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 837330206...
Checkpoint 837330206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 56,077.66311
Policy Entropy: 3.67676
Value Function Loss: 0.02262

Mean KL Divergence: 0.01161
SB3 Clip Fraction: 0.15290
Policy Update Magnitude: 0.37646
Value Function Update Magnitude: 0.54011

Collected Steps per Second: 21,559.46201
Overall Steps per Second: 10,318.97400

Timestep Collection Time: 2.32037
Timestep Consumption Time: 2.52759
PPO Batch Consumption Time: 0.29301
Total Iteration Time: 4.84796

Cumulative Model Updates: 100,420
Cumulative Timesteps: 837,380,232

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 109,287.56008
Policy Entropy: 3.66115
Value Function Loss: 0.02939

Mean KL Divergence: 0.01157
SB3 Clip Fraction: 0.14728
Policy Update Magnitude: 0.40933
Value Function Update Magnitude: 0.54455

Collected Steps per Second: 21,213.78121
Overall Steps per Second: 10,153.68571

Timestep Collection Time: 2.35743
Timestep Consumption Time: 2.56788
PPO Batch Consumption Time: 0.29767
Total Iteration Time: 4.92531

Cumulative Model Updates: 100,426
Cumulative Timesteps: 837,430,242

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 837430242...
Checkpoint 837430242 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 71,694.72742
Policy Entropy: 3.65999
Value Function Loss: 0.03051

Mean KL Divergence: 0.01083
SB3 Clip Fraction: 0.14630
Policy Update Magnitude: 0.45798
Value Function Update Magnitude: 0.67057

Collected Steps per Second: 21,476.82075
Overall Steps per Second: 10,270.27521

Timestep Collection Time: 2.32958
Timestep Consumption Time: 2.54195
PPO Batch Consumption Time: 0.29561
Total Iteration Time: 4.87153

Cumulative Model Updates: 100,432
Cumulative Timesteps: 837,480,274

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 274,797.01352
Policy Entropy: 3.66389
Value Function Loss: 0.03733

Mean KL Divergence: 0.01154
SB3 Clip Fraction: 0.15044
Policy Update Magnitude: 0.47948
Value Function Update Magnitude: 0.56522

Collected Steps per Second: 21,407.00991
Overall Steps per Second: 10,265.28486

Timestep Collection Time: 2.33737
Timestep Consumption Time: 2.53693
PPO Batch Consumption Time: 0.29235
Total Iteration Time: 4.87429

Cumulative Model Updates: 100,438
Cumulative Timesteps: 837,530,310

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 837530310...
Checkpoint 837530310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 222,584.02395
Policy Entropy: 3.66898
Value Function Loss: 0.03723

Mean KL Divergence: 0.01111
SB3 Clip Fraction: 0.14668
Policy Update Magnitude: 0.50043
Value Function Update Magnitude: 0.45552

Collected Steps per Second: 21,601.57043
Overall Steps per Second: 10,182.70237

Timestep Collection Time: 2.31483
Timestep Consumption Time: 2.59585
PPO Batch Consumption Time: 0.30094
Total Iteration Time: 4.91068

Cumulative Model Updates: 100,444
Cumulative Timesteps: 837,580,314

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 222,584.02395
Policy Entropy: 3.65796
Value Function Loss: 0.03747

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.13463
Policy Update Magnitude: 0.51525
Value Function Update Magnitude: 0.40484

Collected Steps per Second: 20,253.62095
Overall Steps per Second: 10,035.75738

Timestep Collection Time: 2.46958
Timestep Consumption Time: 2.51440
PPO Batch Consumption Time: 0.30039
Total Iteration Time: 4.98398

Cumulative Model Updates: 100,450
Cumulative Timesteps: 837,630,332

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 837630332...
Checkpoint 837630332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 222,584.02395
Policy Entropy: 3.66278
Value Function Loss: 0.03403

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.14772
Policy Update Magnitude: 0.49781
Value Function Update Magnitude: 0.43019

Collected Steps per Second: 20,817.46940
Overall Steps per Second: 10,229.77753

Timestep Collection Time: 2.40404
Timestep Consumption Time: 2.48815
PPO Batch Consumption Time: 0.29846
Total Iteration Time: 4.89219

Cumulative Model Updates: 100,456
Cumulative Timesteps: 837,680,378

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 222,584.02395
Policy Entropy: 3.66007
Value Function Loss: 0.02800

Mean KL Divergence: 0.01081
SB3 Clip Fraction: 0.14798
Policy Update Magnitude: 0.45317
Value Function Update Magnitude: 0.42301

Collected Steps per Second: 20,869.55041
Overall Steps per Second: 10,088.99537

Timestep Collection Time: 2.39603
Timestep Consumption Time: 2.56026
PPO Batch Consumption Time: 0.30077
Total Iteration Time: 4.95629

Cumulative Model Updates: 100,462
Cumulative Timesteps: 837,730,382

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 837730382...
Checkpoint 837730382 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 222,584.02395
Policy Entropy: 3.66891
Value Function Loss: 0.02611

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.14304
Policy Update Magnitude: 0.40350
Value Function Update Magnitude: 0.36766

Collected Steps per Second: 21,537.49565
Overall Steps per Second: 10,283.86446

Timestep Collection Time: 2.32293
Timestep Consumption Time: 2.54198
PPO Batch Consumption Time: 0.29786
Total Iteration Time: 4.86490

Cumulative Model Updates: 100,468
Cumulative Timesteps: 837,780,412

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 222,584.02395
Policy Entropy: 3.67238
Value Function Loss: 0.02559

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.14396
Policy Update Magnitude: 0.37102
Value Function Update Magnitude: 0.32931

Collected Steps per Second: 20,990.96912
Overall Steps per Second: 10,191.18859

Timestep Collection Time: 2.38302
Timestep Consumption Time: 2.52533
PPO Batch Consumption Time: 0.29405
Total Iteration Time: 4.90836

Cumulative Model Updates: 100,474
Cumulative Timesteps: 837,830,434

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 837830434...
Checkpoint 837830434 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 222,584.02395
Policy Entropy: 3.69206
Value Function Loss: 0.02761

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.14115
Policy Update Magnitude: 0.37279
Value Function Update Magnitude: 0.34563

Collected Steps per Second: 21,142.80179
Overall Steps per Second: 10,253.12271

Timestep Collection Time: 2.36591
Timestep Consumption Time: 2.51280
PPO Batch Consumption Time: 0.28813
Total Iteration Time: 4.87871

Cumulative Model Updates: 100,480
Cumulative Timesteps: 837,880,456

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 222,584.02395
Policy Entropy: 3.68225
Value Function Loss: 0.02883

Mean KL Divergence: 0.01076
SB3 Clip Fraction: 0.14633
Policy Update Magnitude: 0.37675
Value Function Update Magnitude: 0.34820

Collected Steps per Second: 21,501.65771
Overall Steps per Second: 10,237.85506

Timestep Collection Time: 2.32540
Timestep Consumption Time: 2.55843
PPO Batch Consumption Time: 0.29832
Total Iteration Time: 4.88384

Cumulative Model Updates: 100,486
Cumulative Timesteps: 837,930,456

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 837930456...
Checkpoint 837930456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 222,584.02395
Policy Entropy: 3.67727
Value Function Loss: 0.02811

Mean KL Divergence: 0.01117
SB3 Clip Fraction: 0.14545
Policy Update Magnitude: 0.39206
Value Function Update Magnitude: 0.31755

Collected Steps per Second: 21,718.23913
Overall Steps per Second: 10,398.77327

Timestep Collection Time: 2.30323
Timestep Consumption Time: 2.50715
PPO Batch Consumption Time: 0.28732
Total Iteration Time: 4.81038

Cumulative Model Updates: 100,492
Cumulative Timesteps: 837,980,478

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 222,584.02395
Policy Entropy: 3.65872
Value Function Loss: 0.02775

Mean KL Divergence: 0.01092
SB3 Clip Fraction: 0.14152
Policy Update Magnitude: 0.40420
Value Function Update Magnitude: 0.30949

Collected Steps per Second: 21,595.91963
Overall Steps per Second: 10,221.75342

Timestep Collection Time: 2.31544
Timestep Consumption Time: 2.57648
PPO Batch Consumption Time: 0.29933
Total Iteration Time: 4.89192

Cumulative Model Updates: 100,498
Cumulative Timesteps: 838,030,482

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 838030482...
Checkpoint 838030482 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 222,584.02395
Policy Entropy: 3.66366
Value Function Loss: 0.02865

Mean KL Divergence: 0.01115
SB3 Clip Fraction: 0.14934
Policy Update Magnitude: 0.41856
Value Function Update Magnitude: 0.30835

Collected Steps per Second: 21,711.96213
Overall Steps per Second: 10,303.08591

Timestep Collection Time: 2.30408
Timestep Consumption Time: 2.55136
PPO Batch Consumption Time: 0.29750
Total Iteration Time: 4.85544

Cumulative Model Updates: 100,504
Cumulative Timesteps: 838,080,508

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 222,584.02395
Policy Entropy: 3.66087
Value Function Loss: 0.02697

Mean KL Divergence: 0.01165
SB3 Clip Fraction: 0.15193
Policy Update Magnitude: 0.40921
Value Function Update Magnitude: 0.32712

Collected Steps per Second: 21,047.94731
Overall Steps per Second: 10,201.67787

Timestep Collection Time: 2.37705
Timestep Consumption Time: 2.52724
PPO Batch Consumption Time: 0.28798
Total Iteration Time: 4.90429

Cumulative Model Updates: 100,510
Cumulative Timesteps: 838,130,540

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 838130540...
Checkpoint 838130540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 452,295.42467
Policy Entropy: 3.66016
Value Function Loss: 0.02880

Mean KL Divergence: 0.01110
SB3 Clip Fraction: 0.14337
Policy Update Magnitude: 0.41240
Value Function Update Magnitude: 0.35885

Collected Steps per Second: 21,507.37642
Overall Steps per Second: 10,313.83056

Timestep Collection Time: 2.32571
Timestep Consumption Time: 2.52408
PPO Batch Consumption Time: 0.29326
Total Iteration Time: 4.84980

Cumulative Model Updates: 100,516
Cumulative Timesteps: 838,180,560

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 452,295.42467
Policy Entropy: 3.67628
Value Function Loss: 0.02775

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.13808
Policy Update Magnitude: 0.42579
Value Function Update Magnitude: 0.41062

Collected Steps per Second: 21,270.31260
Overall Steps per Second: 10,298.05197

Timestep Collection Time: 2.35145
Timestep Consumption Time: 2.50539
PPO Batch Consumption Time: 0.28931
Total Iteration Time: 4.85684

Cumulative Model Updates: 100,522
Cumulative Timesteps: 838,230,576

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 838230576...
Checkpoint 838230576 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 473,492.74601
Policy Entropy: 3.68014
Value Function Loss: 0.03042

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.13736
Policy Update Magnitude: 0.42924
Value Function Update Magnitude: 0.43947

Collected Steps per Second: 21,815.87096
Overall Steps per Second: 10,338.66219

Timestep Collection Time: 2.29273
Timestep Consumption Time: 2.54522
PPO Batch Consumption Time: 0.29535
Total Iteration Time: 4.83796

Cumulative Model Updates: 100,528
Cumulative Timesteps: 838,280,594

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 383,528.71767
Policy Entropy: 3.66787
Value Function Loss: 0.03188

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.13898
Policy Update Magnitude: 0.42809
Value Function Update Magnitude: 0.45146

Collected Steps per Second: 20,929.82120
Overall Steps per Second: 10,355.02374

Timestep Collection Time: 2.38970
Timestep Consumption Time: 2.44042
PPO Batch Consumption Time: 0.28842
Total Iteration Time: 4.83012

Cumulative Model Updates: 100,534
Cumulative Timesteps: 838,330,610

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 838330610...
Checkpoint 838330610 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 383,528.71767
Policy Entropy: 3.66755
Value Function Loss: 0.03050

Mean KL Divergence: 0.01067
SB3 Clip Fraction: 0.14651
Policy Update Magnitude: 0.41281
Value Function Update Magnitude: 0.42833

Collected Steps per Second: 20,967.16762
Overall Steps per Second: 10,313.57657

Timestep Collection Time: 2.38544
Timestep Consumption Time: 2.46409
PPO Batch Consumption Time: 0.29256
Total Iteration Time: 4.84953

Cumulative Model Updates: 100,540
Cumulative Timesteps: 838,380,626

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 441,000.06975
Policy Entropy: 3.66793
Value Function Loss: 0.03219

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.13893
Policy Update Magnitude: 0.40761
Value Function Update Magnitude: 0.41591

Collected Steps per Second: 20,807.58146
Overall Steps per Second: 10,015.84828

Timestep Collection Time: 2.40355
Timestep Consumption Time: 2.58974
PPO Batch Consumption Time: 0.30287
Total Iteration Time: 4.99329

Cumulative Model Updates: 100,546
Cumulative Timesteps: 838,430,638

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 838430638...
Checkpoint 838430638 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 289,398.57293
Policy Entropy: 3.68814
Value Function Loss: 0.03142

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.14156
Policy Update Magnitude: 0.40532
Value Function Update Magnitude: 0.39539

Collected Steps per Second: 21,384.55891
Overall Steps per Second: 10,055.98060

Timestep Collection Time: 2.33898
Timestep Consumption Time: 2.63498
PPO Batch Consumption Time: 0.31691
Total Iteration Time: 4.97396

Cumulative Model Updates: 100,552
Cumulative Timesteps: 838,480,656

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 289,398.57293
Policy Entropy: 3.68713
Value Function Loss: 0.03075

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.13758
Policy Update Magnitude: 0.40721
Value Function Update Magnitude: 0.43505

Collected Steps per Second: 21,806.04952
Overall Steps per Second: 10,303.76540

Timestep Collection Time: 2.29404
Timestep Consumption Time: 2.56088
PPO Batch Consumption Time: 0.30066
Total Iteration Time: 4.85492

Cumulative Model Updates: 100,558
Cumulative Timesteps: 838,530,680

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 838530680...
Checkpoint 838530680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 289,398.57293
Policy Entropy: 3.69081
Value Function Loss: 0.02939

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.14113
Policy Update Magnitude: 0.41419
Value Function Update Magnitude: 0.50418

Collected Steps per Second: 21,155.66937
Overall Steps per Second: 10,127.74197

Timestep Collection Time: 2.36353
Timestep Consumption Time: 2.57360
PPO Batch Consumption Time: 0.29897
Total Iteration Time: 4.93713

Cumulative Model Updates: 100,564
Cumulative Timesteps: 838,580,682

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 289,398.57293
Policy Entropy: 3.67172
Value Function Loss: 0.02757

Mean KL Divergence: 0.01080
SB3 Clip Fraction: 0.14524
Policy Update Magnitude: 0.42270
Value Function Update Magnitude: 0.56604

Collected Steps per Second: 21,517.71131
Overall Steps per Second: 10,327.56922

Timestep Collection Time: 2.32367
Timestep Consumption Time: 2.51774
PPO Batch Consumption Time: 0.28874
Total Iteration Time: 4.84141

Cumulative Model Updates: 100,570
Cumulative Timesteps: 838,630,682

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 838630682...
Checkpoint 838630682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 289,398.57293
Policy Entropy: 3.65560
Value Function Loss: 0.03166

Mean KL Divergence: 0.01080
SB3 Clip Fraction: 0.14196
Policy Update Magnitude: 0.43935
Value Function Update Magnitude: 0.56622

Collected Steps per Second: 21,482.38691
Overall Steps per Second: 10,345.11127

Timestep Collection Time: 2.32851
Timestep Consumption Time: 2.50682
PPO Batch Consumption Time: 0.28740
Total Iteration Time: 4.83533

Cumulative Model Updates: 100,576
Cumulative Timesteps: 838,680,704

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 712,818.50818
Policy Entropy: 3.66825
Value Function Loss: 0.03274

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.14134
Policy Update Magnitude: 0.47268
Value Function Update Magnitude: 0.59068

Collected Steps per Second: 21,134.21855
Overall Steps per Second: 10,173.64424

Timestep Collection Time: 2.36697
Timestep Consumption Time: 2.55005
PPO Batch Consumption Time: 0.29824
Total Iteration Time: 4.91702

Cumulative Model Updates: 100,582
Cumulative Timesteps: 838,730,728

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 838730728...
Checkpoint 838730728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 577,385.83023
Policy Entropy: 3.66117
Value Function Loss: 0.03632

Mean KL Divergence: 0.01092
SB3 Clip Fraction: 0.14739
Policy Update Magnitude: 0.49822
Value Function Update Magnitude: 0.65558

Collected Steps per Second: 21,278.57400
Overall Steps per Second: 10,219.69484

Timestep Collection Time: 2.35110
Timestep Consumption Time: 2.54416
PPO Batch Consumption Time: 0.29668
Total Iteration Time: 4.89525

Cumulative Model Updates: 100,588
Cumulative Timesteps: 838,780,756

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 491,930.94090
Policy Entropy: 3.68509
Value Function Loss: 0.03081

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.13716
Policy Update Magnitude: 0.52053
Value Function Update Magnitude: 0.64979

Collected Steps per Second: 21,595.52736
Overall Steps per Second: 10,282.72161

Timestep Collection Time: 2.31659
Timestep Consumption Time: 2.54866
PPO Batch Consumption Time: 0.29432
Total Iteration Time: 4.86525

Cumulative Model Updates: 100,594
Cumulative Timesteps: 838,830,784

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 838830784...
Checkpoint 838830784 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 138,944.96206
Policy Entropy: 3.67318
Value Function Loss: 0.03172

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.13326
Policy Update Magnitude: 0.53256
Value Function Update Magnitude: 0.69458

Collected Steps per Second: 21,573.55218
Overall Steps per Second: 10,198.25392

Timestep Collection Time: 2.31867
Timestep Consumption Time: 2.58628
PPO Batch Consumption Time: 0.30036
Total Iteration Time: 4.90496

Cumulative Model Updates: 100,600
Cumulative Timesteps: 838,880,806

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,255.34070
Policy Entropy: 3.69172
Value Function Loss: 0.03143

Mean KL Divergence: 0.01082
SB3 Clip Fraction: 0.14515
Policy Update Magnitude: 0.53574
Value Function Update Magnitude: 0.57864

Collected Steps per Second: 21,580.06696
Overall Steps per Second: 10,350.77614

Timestep Collection Time: 2.31890
Timestep Consumption Time: 2.51571
PPO Batch Consumption Time: 0.28801
Total Iteration Time: 4.83461

Cumulative Model Updates: 100,606
Cumulative Timesteps: 838,930,848

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 838930848...
Checkpoint 838930848 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,766.56787
Policy Entropy: 3.69560
Value Function Loss: 0.02901

Mean KL Divergence: 0.01139
SB3 Clip Fraction: 0.15150
Policy Update Magnitude: 0.49303
Value Function Update Magnitude: 0.51356

Collected Steps per Second: 21,414.82482
Overall Steps per Second: 10,356.93338

Timestep Collection Time: 2.33548
Timestep Consumption Time: 2.49355
PPO Batch Consumption Time: 0.28656
Total Iteration Time: 4.82904

Cumulative Model Updates: 100,612
Cumulative Timesteps: 838,980,862

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,766.56787
Policy Entropy: 3.69508
Value Function Loss: 0.02889

Mean KL Divergence: 0.01232
SB3 Clip Fraction: 0.16102
Policy Update Magnitude: 0.45060
Value Function Update Magnitude: 0.52641

Collected Steps per Second: 21,654.90972
Overall Steps per Second: 10,317.84273

Timestep Collection Time: 2.31005
Timestep Consumption Time: 2.53825
PPO Batch Consumption Time: 0.28982
Total Iteration Time: 4.84830

Cumulative Model Updates: 100,618
Cumulative Timesteps: 839,030,886

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 839030886...
Checkpoint 839030886 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,766.56787
Policy Entropy: 3.68565
Value Function Loss: 0.02972

Mean KL Divergence: 0.01310
SB3 Clip Fraction: 0.16733
Policy Update Magnitude: 0.46050
Value Function Update Magnitude: 0.49021

Collected Steps per Second: 21,665.92971
Overall Steps per Second: 10,131.78902

Timestep Collection Time: 2.30860
Timestep Consumption Time: 2.62814
PPO Batch Consumption Time: 0.30799
Total Iteration Time: 4.93674

Cumulative Model Updates: 100,624
Cumulative Timesteps: 839,080,904

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,766.56787
Policy Entropy: 3.69182
Value Function Loss: 0.02631

Mean KL Divergence: 0.01266
SB3 Clip Fraction: 0.16608
Policy Update Magnitude: 0.46950
Value Function Update Magnitude: 0.47274

Collected Steps per Second: 21,758.78225
Overall Steps per Second: 10,206.65007

Timestep Collection Time: 2.29838
Timestep Consumption Time: 2.60136
PPO Batch Consumption Time: 0.30135
Total Iteration Time: 4.89975

Cumulative Model Updates: 100,630
Cumulative Timesteps: 839,130,914

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 839130914...
Checkpoint 839130914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,766.56787
Policy Entropy: 3.71966
Value Function Loss: 0.02489

Mean KL Divergence: 0.01395
SB3 Clip Fraction: 0.17836
Policy Update Magnitude: 0.42053
Value Function Update Magnitude: 0.39202

Collected Steps per Second: 21,242.51780
Overall Steps per Second: 10,241.53251

Timestep Collection Time: 2.35405
Timestep Consumption Time: 2.52862
PPO Batch Consumption Time: 0.29327
Total Iteration Time: 4.88267

Cumulative Model Updates: 100,636
Cumulative Timesteps: 839,180,920

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 543,536.90552
Policy Entropy: 3.71969
Value Function Loss: 0.03721

Mean KL Divergence: 0.01329
SB3 Clip Fraction: 0.17019
Policy Update Magnitude: 0.46036
Value Function Update Magnitude: 0.30607

Collected Steps per Second: 21,666.18711
Overall Steps per Second: 10,344.29850

Timestep Collection Time: 2.30977
Timestep Consumption Time: 2.52806
PPO Batch Consumption Time: 0.28920
Total Iteration Time: 4.83783

Cumulative Model Updates: 100,642
Cumulative Timesteps: 839,230,964

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 839230964...
Checkpoint 839230964 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 169,975.06911
Policy Entropy: 3.72954
Value Function Loss: 0.03509

Mean KL Divergence: 0.01605
SB3 Clip Fraction: 0.19414
Policy Update Magnitude: 0.56423
Value Function Update Magnitude: 0.52796

Collected Steps per Second: 20,652.16476
Overall Steps per Second: 10,328.44108

Timestep Collection Time: 2.42173
Timestep Consumption Time: 2.42063
PPO Batch Consumption Time: 0.28686
Total Iteration Time: 4.84236

Cumulative Model Updates: 100,648
Cumulative Timesteps: 839,280,978

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95,505.91296
Policy Entropy: 3.70989
Value Function Loss: 0.03681

Mean KL Divergence: 0.02002
SB3 Clip Fraction: 0.23757
Policy Update Magnitude: 0.53277
Value Function Update Magnitude: 0.64453

Collected Steps per Second: 20,730.52273
Overall Steps per Second: 10,311.24241

Timestep Collection Time: 2.41238
Timestep Consumption Time: 2.43766
PPO Batch Consumption Time: 0.28894
Total Iteration Time: 4.85005

Cumulative Model Updates: 100,654
Cumulative Timesteps: 839,330,988

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 839330988...
Checkpoint 839330988 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 640,799.78289
Policy Entropy: 3.73941
Value Function Loss: 0.03533

Mean KL Divergence: 0.01047
SB3 Clip Fraction: 0.13312
Policy Update Magnitude: 0.56163
Value Function Update Magnitude: 0.77903

Collected Steps per Second: 20,839.31955
Overall Steps per Second: 10,319.47743

Timestep Collection Time: 2.40065
Timestep Consumption Time: 2.44727
PPO Batch Consumption Time: 0.29181
Total Iteration Time: 4.84792

Cumulative Model Updates: 100,660
Cumulative Timesteps: 839,381,016

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 586,072.17708
Policy Entropy: 3.70566
Value Function Loss: 0.04683

Mean KL Divergence: 0.01512
SB3 Clip Fraction: 0.18761
Policy Update Magnitude: 0.58967
Value Function Update Magnitude: 0.62722

Collected Steps per Second: 20,849.43064
Overall Steps per Second: 10,087.93282

Timestep Collection Time: 2.39843
Timestep Consumption Time: 2.55858
PPO Batch Consumption Time: 0.30116
Total Iteration Time: 4.95701

Cumulative Model Updates: 100,666
Cumulative Timesteps: 839,431,022

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 839431022...
Checkpoint 839431022 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 327,104.23523
Policy Entropy: 3.69956
Value Function Loss: 0.05137

Mean KL Divergence: 0.01664
SB3 Clip Fraction: 0.20385
Policy Update Magnitude: 0.57091
Value Function Update Magnitude: 0.53202

Collected Steps per Second: 21,387.31792
Overall Steps per Second: 10,229.50624

Timestep Collection Time: 2.33821
Timestep Consumption Time: 2.55040
PPO Batch Consumption Time: 0.30076
Total Iteration Time: 4.88860

Cumulative Model Updates: 100,672
Cumulative Timesteps: 839,481,030

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,298.89032
Policy Entropy: 3.72551
Value Function Loss: 0.05674

Mean KL Divergence: 0.01371
SB3 Clip Fraction: 0.16531
Policy Update Magnitude: 0.62053
Value Function Update Magnitude: 0.53447

Collected Steps per Second: 21,623.12377
Overall Steps per Second: 10,419.52114

Timestep Collection Time: 2.31308
Timestep Consumption Time: 2.48714
PPO Batch Consumption Time: 0.28703
Total Iteration Time: 4.80022

Cumulative Model Updates: 100,678
Cumulative Timesteps: 839,531,046

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 839531046...
Checkpoint 839531046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 235,988.84780
Policy Entropy: 3.73093
Value Function Loss: 0.04405

Mean KL Divergence: 0.01127
SB3 Clip Fraction: 0.14795
Policy Update Magnitude: 0.63463
Value Function Update Magnitude: 0.56645

Collected Steps per Second: 21,361.17991
Overall Steps per Second: 10,244.60705

Timestep Collection Time: 2.34079
Timestep Consumption Time: 2.54002
PPO Batch Consumption Time: 0.30084
Total Iteration Time: 4.88081

Cumulative Model Updates: 100,684
Cumulative Timesteps: 839,581,048

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 191,151.51934
Policy Entropy: 3.73231
Value Function Loss: 0.03178

Mean KL Divergence: 0.01135
SB3 Clip Fraction: 0.14890
Policy Update Magnitude: 0.58138
Value Function Update Magnitude: 0.86157

Collected Steps per Second: 21,836.03965
Overall Steps per Second: 10,370.10921

Timestep Collection Time: 2.29098
Timestep Consumption Time: 2.53307
PPO Batch Consumption Time: 0.29111
Total Iteration Time: 4.82406

Cumulative Model Updates: 100,690
Cumulative Timesteps: 839,631,074

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 839631074...
Checkpoint 839631074 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 161,128.73447
Policy Entropy: 3.67468
Value Function Loss: 0.03144

Mean KL Divergence: 0.01240
SB3 Clip Fraction: 0.15991
Policy Update Magnitude: 0.56363
Value Function Update Magnitude: 1.01400

Collected Steps per Second: 21,279.84153
Overall Steps per Second: 10,223.72333

Timestep Collection Time: 2.35133
Timestep Consumption Time: 2.54277
PPO Batch Consumption Time: 0.29396
Total Iteration Time: 4.89411

Cumulative Model Updates: 100,696
Cumulative Timesteps: 839,681,110

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45,530.98484
Policy Entropy: 3.67038
Value Function Loss: 0.03395

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.09950
Policy Update Magnitude: 0.69462
Value Function Update Magnitude: 0.92164

Collected Steps per Second: 21,289.77246
Overall Steps per Second: 10,067.29676

Timestep Collection Time: 2.34892
Timestep Consumption Time: 2.61845
PPO Batch Consumption Time: 0.30329
Total Iteration Time: 4.96737

Cumulative Model Updates: 100,702
Cumulative Timesteps: 839,731,118

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 839731118...
Checkpoint 839731118 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,208.46860
Policy Entropy: 3.67485
Value Function Loss: 0.03698

Mean KL Divergence: 0.00747
SB3 Clip Fraction: 0.09416
Policy Update Magnitude: 0.85519
Value Function Update Magnitude: 0.83437

Collected Steps per Second: 20,808.70186
Overall Steps per Second: 10,195.15754

Timestep Collection Time: 2.40351
Timestep Consumption Time: 2.50215
PPO Batch Consumption Time: 0.28940
Total Iteration Time: 4.90566

Cumulative Model Updates: 100,708
Cumulative Timesteps: 839,781,132

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 514,964.02226
Policy Entropy: 3.70139
Value Function Loss: 0.03348

Mean KL Divergence: 0.00695
SB3 Clip Fraction: 0.08446
Policy Update Magnitude: 0.85605
Value Function Update Magnitude: 0.93806

Collected Steps per Second: 21,519.97208
Overall Steps per Second: 10,309.59653

Timestep Collection Time: 2.32370
Timestep Consumption Time: 2.52673
PPO Batch Consumption Time: 0.28930
Total Iteration Time: 4.85043

Cumulative Model Updates: 100,714
Cumulative Timesteps: 839,831,138

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 839831138...
Checkpoint 839831138 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 370,693.32478
Policy Entropy: 3.68978
Value Function Loss: 0.03435

Mean KL Divergence: 0.00696
SB3 Clip Fraction: 0.08526
Policy Update Magnitude: 0.85222
Value Function Update Magnitude: 0.76124

Collected Steps per Second: 21,255.63328
Overall Steps per Second: 10,282.36039

Timestep Collection Time: 2.35345
Timestep Consumption Time: 2.51158
PPO Batch Consumption Time: 0.28907
Total Iteration Time: 4.86503

Cumulative Model Updates: 100,720
Cumulative Timesteps: 839,881,162

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 243,220.87947
Policy Entropy: 3.68951
Value Function Loss: 0.03278

Mean KL Divergence: 0.00698
SB3 Clip Fraction: 0.08459
Policy Update Magnitude: 0.81563
Value Function Update Magnitude: 0.56708

Collected Steps per Second: 21,466.23786
Overall Steps per Second: 9,925.78089

Timestep Collection Time: 2.33008
Timestep Consumption Time: 2.70912
PPO Batch Consumption Time: 0.30969
Total Iteration Time: 5.03920

Cumulative Model Updates: 100,726
Cumulative Timesteps: 839,931,180

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 839931180...
Checkpoint 839931180 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 243,220.87947
Policy Entropy: 3.66250
Value Function Loss: 0.03413

Mean KL Divergence: 0.00760
SB3 Clip Fraction: 0.09468
Policy Update Magnitude: 0.76277
Value Function Update Magnitude: 0.47625

Collected Steps per Second: 21,298.18705
Overall Steps per Second: 10,294.42004

Timestep Collection Time: 2.34846
Timestep Consumption Time: 2.51029
PPO Batch Consumption Time: 0.28861
Total Iteration Time: 4.85875

Cumulative Model Updates: 100,732
Cumulative Timesteps: 839,981,198

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 243,220.87947
Policy Entropy: 3.68254
Value Function Loss: 0.03057

Mean KL Divergence: 0.01137
SB3 Clip Fraction: 0.14929
Policy Update Magnitude: 0.64492
Value Function Update Magnitude: 0.45334

Collected Steps per Second: 21,779.28142
Overall Steps per Second: 10,272.65672

Timestep Collection Time: 2.29649
Timestep Consumption Time: 2.57235
PPO Batch Consumption Time: 0.29909
Total Iteration Time: 4.86885

Cumulative Model Updates: 100,738
Cumulative Timesteps: 840,031,214

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 840031214...
Checkpoint 840031214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 243,220.87947
Policy Entropy: 3.68429
Value Function Loss: 0.02802

Mean KL Divergence: 0.01275
SB3 Clip Fraction: 0.16473
Policy Update Magnitude: 0.52625
Value Function Update Magnitude: 0.45504

Collected Steps per Second: 21,365.16676
Overall Steps per Second: 10,228.40075

Timestep Collection Time: 2.34129
Timestep Consumption Time: 2.54921
PPO Batch Consumption Time: 0.29736
Total Iteration Time: 4.89050

Cumulative Model Updates: 100,744
Cumulative Timesteps: 840,081,236

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 243,220.87947
Policy Entropy: 3.71928
Value Function Loss: 0.02266

Mean KL Divergence: 0.01147
SB3 Clip Fraction: 0.14718
Policy Update Magnitude: 0.50622
Value Function Update Magnitude: 0.46152

Collected Steps per Second: 21,961.00516
Overall Steps per Second: 10,306.84144

Timestep Collection Time: 2.27713
Timestep Consumption Time: 2.57480
PPO Batch Consumption Time: 0.29868
Total Iteration Time: 4.85192

Cumulative Model Updates: 100,750
Cumulative Timesteps: 840,131,244

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 840131244...
Checkpoint 840131244 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 156,600.54446
Policy Entropy: 3.75311
Value Function Loss: 0.02140

Mean KL Divergence: 0.01826
SB3 Clip Fraction: 0.21765
Policy Update Magnitude: 0.44580
Value Function Update Magnitude: 0.47868

Collected Steps per Second: 21,353.53263
Overall Steps per Second: 10,192.72116

Timestep Collection Time: 2.34163
Timestep Consumption Time: 2.56403
PPO Batch Consumption Time: 0.29883
Total Iteration Time: 4.90566

Cumulative Model Updates: 100,756
Cumulative Timesteps: 840,181,246

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 140,550.18032
Policy Entropy: 3.77704
Value Function Loss: 0.02514

Mean KL Divergence: 0.01501
SB3 Clip Fraction: 0.18059
Policy Update Magnitude: 0.45293
Value Function Update Magnitude: 0.50367

Collected Steps per Second: 20,646.01674
Overall Steps per Second: 10,187.56579

Timestep Collection Time: 2.42362
Timestep Consumption Time: 2.48806
PPO Batch Consumption Time: 0.29792
Total Iteration Time: 4.91167

Cumulative Model Updates: 100,762
Cumulative Timesteps: 840,231,284

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 840231284...
Checkpoint 840231284 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 113,848.30871
Policy Entropy: 3.71631
Value Function Loss: 0.02889

Mean KL Divergence: 0.01701
SB3 Clip Fraction: 0.20481
Policy Update Magnitude: 0.51219
Value Function Update Magnitude: 0.48349

Collected Steps per Second: 20,121.34917
Overall Steps per Second: 10,065.88180

Timestep Collection Time: 2.48602
Timestep Consumption Time: 2.48344
PPO Batch Consumption Time: 0.29882
Total Iteration Time: 4.96946

Cumulative Model Updates: 100,768
Cumulative Timesteps: 840,281,306

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 252,880.00293
Policy Entropy: 3.66847
Value Function Loss: 0.03750

Mean KL Divergence: 0.01352
SB3 Clip Fraction: 0.15908
Policy Update Magnitude: 0.64632
Value Function Update Magnitude: 0.44328

Collected Steps per Second: 20,348.41089
Overall Steps per Second: 10,009.97374

Timestep Collection Time: 2.45749
Timestep Consumption Time: 2.53813
PPO Batch Consumption Time: 0.29492
Total Iteration Time: 4.99562

Cumulative Model Updates: 100,774
Cumulative Timesteps: 840,331,312

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 840331312...
Checkpoint 840331312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 157,513.02549
Policy Entropy: 3.61531
Value Function Loss: 0.04569

Mean KL Divergence: 0.01231
SB3 Clip Fraction: 0.15011
Policy Update Magnitude: 0.78837
Value Function Update Magnitude: 0.41125

Collected Steps per Second: 20,662.57256
Overall Steps per Second: 10,161.06406

Timestep Collection Time: 2.42148
Timestep Consumption Time: 2.50261
PPO Batch Consumption Time: 0.28870
Total Iteration Time: 4.92409

Cumulative Model Updates: 100,780
Cumulative Timesteps: 840,381,346

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 112,728.26530
Policy Entropy: 3.64354
Value Function Loss: 0.04683

Mean KL Divergence: 0.01493
SB3 Clip Fraction: 0.17939
Policy Update Magnitude: 0.83951
Value Function Update Magnitude: 0.42431

Collected Steps per Second: 21,236.18829
Overall Steps per Second: 10,240.29214

Timestep Collection Time: 2.35579
Timestep Consumption Time: 2.52962
PPO Batch Consumption Time: 0.29890
Total Iteration Time: 4.88541

Cumulative Model Updates: 100,786
Cumulative Timesteps: 840,431,374

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 840431374...
Checkpoint 840431374 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 91,311.13509
Policy Entropy: 3.69965
Value Function Loss: 0.04068

Mean KL Divergence: 0.01427
SB3 Clip Fraction: 0.17317
Policy Update Magnitude: 0.81405
Value Function Update Magnitude: 0.50084

Collected Steps per Second: 21,543.84115
Overall Steps per Second: 10,370.19519

Timestep Collection Time: 2.32113
Timestep Consumption Time: 2.50096
PPO Batch Consumption Time: 0.28867
Total Iteration Time: 4.82209

Cumulative Model Updates: 100,792
Cumulative Timesteps: 840,481,380

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82,131.94611
Policy Entropy: 3.67426
Value Function Loss: 0.03569

Mean KL Divergence: 0.01410
SB3 Clip Fraction: 0.18044
Policy Update Magnitude: 0.63029
Value Function Update Magnitude: 0.55047

Collected Steps per Second: 21,685.20634
Overall Steps per Second: 10,081.46960

Timestep Collection Time: 2.30618
Timestep Consumption Time: 2.65441
PPO Batch Consumption Time: 0.31288
Total Iteration Time: 4.96059

Cumulative Model Updates: 100,798
Cumulative Timesteps: 840,531,390

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 840531390...
Checkpoint 840531390 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,979.21061
Policy Entropy: 3.65806
Value Function Loss: 0.04112

Mean KL Divergence: 0.01462
SB3 Clip Fraction: 0.18549
Policy Update Magnitude: 0.57989
Value Function Update Magnitude: 0.54695

Collected Steps per Second: 20,879.85827
Overall Steps per Second: 10,107.55767

Timestep Collection Time: 2.39513
Timestep Consumption Time: 2.55265
PPO Batch Consumption Time: 0.29255
Total Iteration Time: 4.94778

Cumulative Model Updates: 100,804
Cumulative Timesteps: 840,581,400

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 122,812.21942
Policy Entropy: 3.68491
Value Function Loss: 0.04366

Mean KL Divergence: 0.01220
SB3 Clip Fraction: 0.15280
Policy Update Magnitude: 0.68174
Value Function Update Magnitude: 0.56150

Collected Steps per Second: 21,579.88368
Overall Steps per Second: 10,214.84953

Timestep Collection Time: 2.31846
Timestep Consumption Time: 2.57951
PPO Batch Consumption Time: 0.29955
Total Iteration Time: 4.89797

Cumulative Model Updates: 100,810
Cumulative Timesteps: 840,631,432

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 840631432...
Checkpoint 840631432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,105.47534
Policy Entropy: 3.71879
Value Function Loss: 0.03996

Mean KL Divergence: 0.01253
SB3 Clip Fraction: 0.16197
Policy Update Magnitude: 0.65222
Value Function Update Magnitude: 0.63012

Collected Steps per Second: 21,583.53131
Overall Steps per Second: 10,217.71641

Timestep Collection Time: 2.31751
Timestep Consumption Time: 2.57791
PPO Batch Consumption Time: 0.30071
Total Iteration Time: 4.89542

Cumulative Model Updates: 100,816
Cumulative Timesteps: 840,681,452

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,105.47534
Policy Entropy: 3.72421
Value Function Loss: 0.03218

Mean KL Divergence: 0.00724
SB3 Clip Fraction: 0.09430
Policy Update Magnitude: 0.61995
Value Function Update Magnitude: 0.57235

Collected Steps per Second: 21,522.67040
Overall Steps per Second: 10,323.90275

Timestep Collection Time: 2.32350
Timestep Consumption Time: 2.52040
PPO Batch Consumption Time: 0.28856
Total Iteration Time: 4.84390

Cumulative Model Updates: 100,822
Cumulative Timesteps: 840,731,460

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 840731460...
Checkpoint 840731460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,105.47534
Policy Entropy: 3.69956
Value Function Loss: 0.02702

Mean KL Divergence: 0.00628
SB3 Clip Fraction: 0.07837
Policy Update Magnitude: 0.64397
Value Function Update Magnitude: 0.50991

Collected Steps per Second: 21,475.94377
Overall Steps per Second: 10,308.44021

Timestep Collection Time: 2.32856
Timestep Consumption Time: 2.52261
PPO Batch Consumption Time: 0.28809
Total Iteration Time: 4.85117

Cumulative Model Updates: 100,828
Cumulative Timesteps: 840,781,468

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,105.47534
Policy Entropy: 3.68386
Value Function Loss: 0.02303

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.10547
Policy Update Magnitude: 0.59940
Value Function Update Magnitude: 0.47208

Collected Steps per Second: 21,751.64976
Overall Steps per Second: 10,385.35476

Timestep Collection Time: 2.29923
Timestep Consumption Time: 2.51640
PPO Batch Consumption Time: 0.28749
Total Iteration Time: 4.81563

Cumulative Model Updates: 100,834
Cumulative Timesteps: 840,831,480

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 840831480...
Checkpoint 840831480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 50,265.34960
Policy Entropy: 3.67780
Value Function Loss: 0.03397

Mean KL Divergence: 0.01181
SB3 Clip Fraction: 0.15903
Policy Update Magnitude: 0.49543
Value Function Update Magnitude: 0.44781

Collected Steps per Second: 21,044.14044
Overall Steps per Second: 10,240.31008

Timestep Collection Time: 2.37672
Timestep Consumption Time: 2.50751
PPO Batch Consumption Time: 0.28801
Total Iteration Time: 4.88423

Cumulative Model Updates: 100,840
Cumulative Timesteps: 840,881,496

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,576.55092
Policy Entropy: 3.69010
Value Function Loss: 0.03528

Mean KL Divergence: 0.01295
SB3 Clip Fraction: 0.16708
Policy Update Magnitude: 0.51157
Value Function Update Magnitude: 0.45812

Collected Steps per Second: 19,800.62905
Overall Steps per Second: 9,793.46388

Timestep Collection Time: 2.52517
Timestep Consumption Time: 2.58027
PPO Batch Consumption Time: 0.29909
Total Iteration Time: 5.10545

Cumulative Model Updates: 100,846
Cumulative Timesteps: 840,931,496

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 840931496...
Checkpoint 840931496 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 71,932.12673
Policy Entropy: 3.69658
Value Function Loss: 0.04306

Mean KL Divergence: 0.01495
SB3 Clip Fraction: 0.18900
Policy Update Magnitude: 0.53757
Value Function Update Magnitude: 0.47535

Collected Steps per Second: 21,316.34324
Overall Steps per Second: 10,172.09520

Timestep Collection Time: 2.34571
Timestep Consumption Time: 2.56989
PPO Batch Consumption Time: 0.30042
Total Iteration Time: 4.91560

Cumulative Model Updates: 100,852
Cumulative Timesteps: 840,981,498

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 112,796.90185
Policy Entropy: 3.75055
Value Function Loss: 0.03764

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.13862
Policy Update Magnitude: 0.58799
Value Function Update Magnitude: 0.53681

Collected Steps per Second: 21,695.63327
Overall Steps per Second: 10,372.70367

Timestep Collection Time: 2.30655
Timestep Consumption Time: 2.51785
PPO Batch Consumption Time: 0.28779
Total Iteration Time: 4.82439

Cumulative Model Updates: 100,858
Cumulative Timesteps: 841,031,540

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 841031540...
Checkpoint 841031540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 75,726.14149
Policy Entropy: 3.74624
Value Function Loss: 0.03864

Mean KL Divergence: 0.01263
SB3 Clip Fraction: 0.16888
Policy Update Magnitude: 0.52882
Value Function Update Magnitude: 0.64984

Collected Steps per Second: 21,490.82718
Overall Steps per Second: 10,228.59685

Timestep Collection Time: 2.32685
Timestep Consumption Time: 2.56199
PPO Batch Consumption Time: 0.29595
Total Iteration Time: 4.88884

Cumulative Model Updates: 100,864
Cumulative Timesteps: 841,081,546

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 159,956.65503
Policy Entropy: 3.76622
Value Function Loss: 0.03845

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.13911
Policy Update Magnitude: 0.55908
Value Function Update Magnitude: 0.77752

Collected Steps per Second: 21,429.68484
Overall Steps per Second: 10,216.86495

Timestep Collection Time: 2.33452
Timestep Consumption Time: 2.56209
PPO Batch Consumption Time: 0.29630
Total Iteration Time: 4.89661

Cumulative Model Updates: 100,870
Cumulative Timesteps: 841,131,574

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 841131574...
Checkpoint 841131574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 138,828.64110
Policy Entropy: 3.76210
Value Function Loss: 0.03568

Mean KL Divergence: 0.01069
SB3 Clip Fraction: 0.14539
Policy Update Magnitude: 0.53119
Value Function Update Magnitude: 0.80313

Collected Steps per Second: 21,548.10334
Overall Steps per Second: 10,237.74359

Timestep Collection Time: 2.32076
Timestep Consumption Time: 2.56391
PPO Batch Consumption Time: 0.29150
Total Iteration Time: 4.88467

Cumulative Model Updates: 100,876
Cumulative Timesteps: 841,181,582

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,773.16846
Policy Entropy: 3.75077
Value Function Loss: 0.03265

Mean KL Divergence: 0.01053
SB3 Clip Fraction: 0.14615
Policy Update Magnitude: 0.48633
Value Function Update Magnitude: 0.88058

Collected Steps per Second: 21,167.88284
Overall Steps per Second: 10,268.07614

Timestep Collection Time: 2.36320
Timestep Consumption Time: 2.50860
PPO Batch Consumption Time: 0.28917
Total Iteration Time: 4.87180

Cumulative Model Updates: 100,882
Cumulative Timesteps: 841,231,606

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 841231606...
Checkpoint 841231606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 54,620.99433
Policy Entropy: 3.72496
Value Function Loss: 0.03303

Mean KL Divergence: 0.01053
SB3 Clip Fraction: 0.14679
Policy Update Magnitude: 0.44964
Value Function Update Magnitude: 0.92226

Collected Steps per Second: 21,417.81443
Overall Steps per Second: 10,186.72401

Timestep Collection Time: 2.33469
Timestep Consumption Time: 2.57405
PPO Batch Consumption Time: 0.30032
Total Iteration Time: 4.90874

Cumulative Model Updates: 100,888
Cumulative Timesteps: 841,281,610

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 180,437.49300
Policy Entropy: 3.70777
Value Function Loss: 0.03563

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.14042
Policy Update Magnitude: 0.44624
Value Function Update Magnitude: 0.89120

Collected Steps per Second: 21,331.59159
Overall Steps per Second: 10,209.03701

Timestep Collection Time: 2.34432
Timestep Consumption Time: 2.55409
PPO Batch Consumption Time: 0.29663
Total Iteration Time: 4.89841

Cumulative Model Updates: 100,894
Cumulative Timesteps: 841,331,618

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 841331618...
Checkpoint 841331618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 77,689.75475
Policy Entropy: 3.69173
Value Function Loss: 0.03652

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.14791
Policy Update Magnitude: 0.44504
Value Function Update Magnitude: 0.80146

Collected Steps per Second: 21,621.46088
Overall Steps per Second: 10,339.82709

Timestep Collection Time: 2.31353
Timestep Consumption Time: 2.52426
PPO Batch Consumption Time: 0.28879
Total Iteration Time: 4.83780

Cumulative Model Updates: 100,900
Cumulative Timesteps: 841,381,640

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77,689.75475
Policy Entropy: 3.69661
Value Function Loss: 0.03157

Mean KL Divergence: 0.01073
SB3 Clip Fraction: 0.14963
Policy Update Magnitude: 0.42828
Value Function Update Magnitude: 0.67322

Collected Steps per Second: 21,936.60049
Overall Steps per Second: 10,468.93719

Timestep Collection Time: 2.28039
Timestep Consumption Time: 2.49794
PPO Batch Consumption Time: 0.28841
Total Iteration Time: 4.77833

Cumulative Model Updates: 100,906
Cumulative Timesteps: 841,431,664

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 841431664...
Checkpoint 841431664 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 77,689.75475
Policy Entropy: 3.68679
Value Function Loss: 0.02877

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.14683
Policy Update Magnitude: 0.38338
Value Function Update Magnitude: 0.51308

Collected Steps per Second: 21,187.35248
Overall Steps per Second: 10,315.09886

Timestep Collection Time: 2.36075
Timestep Consumption Time: 2.48826
PPO Batch Consumption Time: 0.29908
Total Iteration Time: 4.84901

Cumulative Model Updates: 100,912
Cumulative Timesteps: 841,481,682

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91,597.89442
Policy Entropy: 3.68291
Value Function Loss: 0.03838

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.13880
Policy Update Magnitude: 0.37593
Value Function Update Magnitude: 0.43657

Collected Steps per Second: 20,715.96413
Overall Steps per Second: 10,197.47525

Timestep Collection Time: 2.41418
Timestep Consumption Time: 2.49017
PPO Batch Consumption Time: 0.29704
Total Iteration Time: 4.90435

Cumulative Model Updates: 100,918
Cumulative Timesteps: 841,531,694

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 841531694...
Checkpoint 841531694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 197,840.22695
Policy Entropy: 3.69080
Value Function Loss: 0.03708

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.14590
Policy Update Magnitude: 0.39304
Value Function Update Magnitude: 0.46116

Collected Steps per Second: 21,089.53696
Overall Steps per Second: 10,404.06040

Timestep Collection Time: 2.37141
Timestep Consumption Time: 2.43556
PPO Batch Consumption Time: 0.28842
Total Iteration Time: 4.80697

Cumulative Model Updates: 100,924
Cumulative Timesteps: 841,581,706

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 373,845.28520
Policy Entropy: 3.69298
Value Function Loss: 0.03884

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.13370
Policy Update Magnitude: 0.45061
Value Function Update Magnitude: 0.73317

Collected Steps per Second: 20,891.62610
Overall Steps per Second: 10,109.32555

Timestep Collection Time: 2.39416
Timestep Consumption Time: 2.55354
PPO Batch Consumption Time: 0.30021
Total Iteration Time: 4.94771

Cumulative Model Updates: 100,930
Cumulative Timesteps: 841,631,724

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 841631724...
Checkpoint 841631724 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,421.00784
Policy Entropy: 3.70740
Value Function Loss: 0.03877

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.13793
Policy Update Magnitude: 0.46421
Value Function Update Magnitude: 0.73536

Collected Steps per Second: 21,494.77507
Overall Steps per Second: 10,266.74174

Timestep Collection Time: 2.32717
Timestep Consumption Time: 2.54507
PPO Batch Consumption Time: 0.30060
Total Iteration Time: 4.87224

Cumulative Model Updates: 100,936
Cumulative Timesteps: 841,681,746

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,817.61915
Policy Entropy: 3.70483
Value Function Loss: 0.03721

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.14087
Policy Update Magnitude: 0.44473
Value Function Update Magnitude: 0.72802

Collected Steps per Second: 21,365.10125
Overall Steps per Second: 10,342.94216

Timestep Collection Time: 2.34148
Timestep Consumption Time: 2.49525
PPO Batch Consumption Time: 0.28949
Total Iteration Time: 4.83673

Cumulative Model Updates: 100,942
Cumulative Timesteps: 841,731,772

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 841731772...
Checkpoint 841731772 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,817.61915
Policy Entropy: 3.70250
Value Function Loss: 0.02909

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.14643
Policy Update Magnitude: 0.40406
Value Function Update Magnitude: 0.69395

Collected Steps per Second: 21,479.73656
Overall Steps per Second: 10,249.80152

Timestep Collection Time: 2.32871
Timestep Consumption Time: 2.55139
PPO Batch Consumption Time: 0.29454
Total Iteration Time: 4.88009

Cumulative Model Updates: 100,948
Cumulative Timesteps: 841,781,792

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,817.61915
Policy Entropy: 3.68422
Value Function Loss: 0.02432

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.14610
Policy Update Magnitude: 0.36312
Value Function Update Magnitude: 0.69427

Collected Steps per Second: 21,485.47386
Overall Steps per Second: 10,329.63476

Timestep Collection Time: 2.32715
Timestep Consumption Time: 2.51329
PPO Batch Consumption Time: 0.28965
Total Iteration Time: 4.84044

Cumulative Model Updates: 100,954
Cumulative Timesteps: 841,831,792

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 841831792...
Checkpoint 841831792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,817.61915
Policy Entropy: 3.68002
Value Function Loss: 0.02227

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.14875
Policy Update Magnitude: 0.33941
Value Function Update Magnitude: 0.64135

Collected Steps per Second: 21,476.83121
Overall Steps per Second: 10,372.12341

Timestep Collection Time: 2.32893
Timestep Consumption Time: 2.49342
PPO Batch Consumption Time: 0.28728
Total Iteration Time: 4.82235

Cumulative Model Updates: 100,960
Cumulative Timesteps: 841,881,810

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,102.78463
Policy Entropy: 3.68507
Value Function Loss: 0.02266

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.14545
Policy Update Magnitude: 0.35566
Value Function Update Magnitude: 0.69076

Collected Steps per Second: 21,971.22668
Overall Steps per Second: 10,412.62272

Timestep Collection Time: 2.27598
Timestep Consumption Time: 2.52646
PPO Batch Consumption Time: 0.29049
Total Iteration Time: 4.80244

Cumulative Model Updates: 100,966
Cumulative Timesteps: 841,931,816

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 841931816...
Checkpoint 841931816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,102.78463
Policy Entropy: 3.69389
Value Function Loss: 0.02359

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.14605
Policy Update Magnitude: 0.35334
Value Function Update Magnitude: 0.63697

Collected Steps per Second: 21,581.18047
Overall Steps per Second: 10,203.76146

Timestep Collection Time: 2.31757
Timestep Consumption Time: 2.58415
PPO Batch Consumption Time: 0.30113
Total Iteration Time: 4.90172

Cumulative Model Updates: 100,972
Cumulative Timesteps: 841,981,832

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,102.78463
Policy Entropy: 3.68241
Value Function Loss: 0.02365

Mean KL Divergence: 0.01069
SB3 Clip Fraction: 0.15365
Policy Update Magnitude: 0.35721
Value Function Update Magnitude: 0.54585

Collected Steps per Second: 21,545.58072
Overall Steps per Second: 10,342.08642

Timestep Collection Time: 2.32131
Timestep Consumption Time: 2.51466
PPO Batch Consumption Time: 0.28812
Total Iteration Time: 4.83597

Cumulative Model Updates: 100,978
Cumulative Timesteps: 842,031,846

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 842031846...
Checkpoint 842031846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 85,430.32743
Policy Entropy: 3.67897
Value Function Loss: 0.02467

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.15290
Policy Update Magnitude: 0.34992
Value Function Update Magnitude: 0.48230

Collected Steps per Second: 21,597.59227
Overall Steps per Second: 10,312.33480

Timestep Collection Time: 2.31591
Timestep Consumption Time: 2.53440
PPO Batch Consumption Time: 0.29306
Total Iteration Time: 4.85031

Cumulative Model Updates: 100,984
Cumulative Timesteps: 842,081,864

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 789,780.09388
Policy Entropy: 3.69193
Value Function Loss: 0.02664

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.14798
Policy Update Magnitude: 0.35712
Value Function Update Magnitude: 0.54349

Collected Steps per Second: 21,172.35670
Overall Steps per Second: 10,137.42382

Timestep Collection Time: 2.36204
Timestep Consumption Time: 2.57116
PPO Batch Consumption Time: 0.30032
Total Iteration Time: 4.93321

Cumulative Model Updates: 100,990
Cumulative Timesteps: 842,131,874

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 842131874...
Checkpoint 842131874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 789,780.09388
Policy Entropy: 3.68404
Value Function Loss: 0.02616

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.14530
Policy Update Magnitude: 0.37311
Value Function Update Magnitude: 0.72960

Collected Steps per Second: 21,712.35552
Overall Steps per Second: 10,423.18359

Timestep Collection Time: 2.30367
Timestep Consumption Time: 2.49506
PPO Batch Consumption Time: 0.28721
Total Iteration Time: 4.79873

Cumulative Model Updates: 100,996
Cumulative Timesteps: 842,181,892

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 789,780.09388
Policy Entropy: 3.67707
Value Function Loss: 0.02743

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.14469
Policy Update Magnitude: 0.38245
Value Function Update Magnitude: 0.67817

Collected Steps per Second: 21,113.59547
Overall Steps per Second: 10,321.14105

Timestep Collection Time: 2.36899
Timestep Consumption Time: 2.47717
PPO Batch Consumption Time: 0.29704
Total Iteration Time: 4.84617

Cumulative Model Updates: 101,002
Cumulative Timesteps: 842,231,910

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 842231910...
Checkpoint 842231910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 789,780.09388
Policy Entropy: 3.66679
Value Function Loss: 0.02485

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.14969
Policy Update Magnitude: 0.37873
Value Function Update Magnitude: 0.54482

Collected Steps per Second: 21,026.91012
Overall Steps per Second: 10,421.12833

Timestep Collection Time: 2.37819
Timestep Consumption Time: 2.42033
PPO Batch Consumption Time: 0.28675
Total Iteration Time: 4.79852

Cumulative Model Updates: 101,008
Cumulative Timesteps: 842,281,916

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,204,509.73201
Policy Entropy: 3.66435
Value Function Loss: 0.02403

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.14924
Policy Update Magnitude: 0.37463
Value Function Update Magnitude: 0.58800

Collected Steps per Second: 20,913.42851
Overall Steps per Second: 10,103.24586

Timestep Collection Time: 2.39148
Timestep Consumption Time: 2.55881
PPO Batch Consumption Time: 0.30122
Total Iteration Time: 4.95029

Cumulative Model Updates: 101,014
Cumulative Timesteps: 842,331,930

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 842331930...
Checkpoint 842331930 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 190,771.29530
Policy Entropy: 3.70086
Value Function Loss: 0.02689

Mean KL Divergence: 0.01059
SB3 Clip Fraction: 0.14765
Policy Update Magnitude: 0.39239
Value Function Update Magnitude: 0.68757

Collected Steps per Second: 21,126.10657
Overall Steps per Second: 10,158.12335

Timestep Collection Time: 2.36683
Timestep Consumption Time: 2.55553
PPO Batch Consumption Time: 0.29883
Total Iteration Time: 4.92237

Cumulative Model Updates: 101,020
Cumulative Timesteps: 842,381,932

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,660.69835
Policy Entropy: 3.69961
Value Function Loss: 0.03152

Mean KL Divergence: 0.01047
SB3 Clip Fraction: 0.14493
Policy Update Magnitude: 0.41600
Value Function Update Magnitude: 0.73200

Collected Steps per Second: 21,240.32853
Overall Steps per Second: 10,211.76366

Timestep Collection Time: 2.35533
Timestep Consumption Time: 2.54373
PPO Batch Consumption Time: 0.29831
Total Iteration Time: 4.89906

Cumulative Model Updates: 101,026
Cumulative Timesteps: 842,431,960

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 842431960...
Checkpoint 842431960 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,802.31631
Policy Entropy: 3.71174
Value Function Loss: 0.02835

Mean KL Divergence: 0.01058
SB3 Clip Fraction: 0.14693
Policy Update Magnitude: 0.45796
Value Function Update Magnitude: 0.80207

Collected Steps per Second: 21,069.87112
Overall Steps per Second: 10,090.40985

Timestep Collection Time: 2.37410
Timestep Consumption Time: 2.58328
PPO Batch Consumption Time: 0.30988
Total Iteration Time: 4.95738

Cumulative Model Updates: 101,032
Cumulative Timesteps: 842,481,982

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,802.31631
Policy Entropy: 3.68710
Value Function Loss: 0.02777

Mean KL Divergence: 0.01130
SB3 Clip Fraction: 0.15779
Policy Update Magnitude: 0.44613
Value Function Update Magnitude: 0.67479

Collected Steps per Second: 21,460.90900
Overall Steps per Second: 10,326.25558

Timestep Collection Time: 2.33028
Timestep Consumption Time: 2.51271
PPO Batch Consumption Time: 0.28848
Total Iteration Time: 4.84299

Cumulative Model Updates: 101,038
Cumulative Timesteps: 842,531,992

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 842531992...
Checkpoint 842531992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 79,098.44142
Policy Entropy: 3.69151
Value Function Loss: 0.02669

Mean KL Divergence: 0.01092
SB3 Clip Fraction: 0.15421
Policy Update Magnitude: 0.43187
Value Function Update Magnitude: 0.51449

Collected Steps per Second: 21,542.87604
Overall Steps per Second: 10,302.16753

Timestep Collection Time: 2.32151
Timestep Consumption Time: 2.53300
PPO Batch Consumption Time: 0.29203
Total Iteration Time: 4.85451

Cumulative Model Updates: 101,044
Cumulative Timesteps: 842,582,004

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51,905.18535
Policy Entropy: 3.67791
Value Function Loss: 0.02898

Mean KL Divergence: 0.01108
SB3 Clip Fraction: 0.15672
Policy Update Magnitude: 0.39824
Value Function Update Magnitude: 0.46352

Collected Steps per Second: 21,403.69141
Overall Steps per Second: 10,349.96740

Timestep Collection Time: 2.33707
Timestep Consumption Time: 2.49599
PPO Batch Consumption Time: 0.28822
Total Iteration Time: 4.83306

Cumulative Model Updates: 101,050
Cumulative Timesteps: 842,632,026

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 842632026...
Checkpoint 842632026 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 51,905.18535
Policy Entropy: 3.66813
Value Function Loss: 0.02922

Mean KL Divergence: 0.01057
SB3 Clip Fraction: 0.15085
Policy Update Magnitude: 0.39393
Value Function Update Magnitude: 0.43293

Collected Steps per Second: 21,533.93584
Overall Steps per Second: 10,298.29798

Timestep Collection Time: 2.32294
Timestep Consumption Time: 2.53437
PPO Batch Consumption Time: 0.29186
Total Iteration Time: 4.85731

Cumulative Model Updates: 101,056
Cumulative Timesteps: 842,682,048

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51,905.18535
Policy Entropy: 3.66016
Value Function Loss: 0.02571

Mean KL Divergence: 0.01105
SB3 Clip Fraction: 0.15488
Policy Update Magnitude: 0.40425
Value Function Update Magnitude: 0.39795

Collected Steps per Second: 21,576.96600
Overall Steps per Second: 10,354.87466

Timestep Collection Time: 2.31775
Timestep Consumption Time: 2.51186
PPO Batch Consumption Time: 0.28842
Total Iteration Time: 4.82961

Cumulative Model Updates: 101,062
Cumulative Timesteps: 842,732,058

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 842732058...
Checkpoint 842732058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 51,905.18535
Policy Entropy: 3.66375
Value Function Loss: 0.02221

Mean KL Divergence: 0.01067
SB3 Clip Fraction: 0.14814
Policy Update Magnitude: 0.37620
Value Function Update Magnitude: 0.36642

Collected Steps per Second: 21,612.54041
Overall Steps per Second: 10,331.17123

Timestep Collection Time: 2.31449
Timestep Consumption Time: 2.52736
PPO Batch Consumption Time: 0.29135
Total Iteration Time: 4.84185

Cumulative Model Updates: 101,068
Cumulative Timesteps: 842,782,080

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51,905.18535
Policy Entropy: 3.67208
Value Function Loss: 0.02121

Mean KL Divergence: 0.01109
SB3 Clip Fraction: 0.15189
Policy Update Magnitude: 0.36966
Value Function Update Magnitude: 0.33784

Collected Steps per Second: 21,874.75600
Overall Steps per Second: 10,425.65497

Timestep Collection Time: 2.28611
Timestep Consumption Time: 2.51052
PPO Batch Consumption Time: 0.28837
Total Iteration Time: 4.79663

Cumulative Model Updates: 101,074
Cumulative Timesteps: 842,832,088

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 842832088...
Checkpoint 842832088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 51,905.18535
Policy Entropy: 3.66886
Value Function Loss: 0.02711

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.14122
Policy Update Magnitude: 0.37561
Value Function Update Magnitude: 0.38386

Collected Steps per Second: 21,234.19772
Overall Steps per Second: 10,238.17443

Timestep Collection Time: 2.35479
Timestep Consumption Time: 2.52909
PPO Batch Consumption Time: 0.29247
Total Iteration Time: 4.88388

Cumulative Model Updates: 101,080
Cumulative Timesteps: 842,882,090

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51,905.18535
Policy Entropy: 3.67589
Value Function Loss: 0.02932

Mean KL Divergence: 0.01050
SB3 Clip Fraction: 0.14488
Policy Update Magnitude: 0.40428
Value Function Update Magnitude: 0.36189

Collected Steps per Second: 21,306.25516
Overall Steps per Second: 10,206.83670

Timestep Collection Time: 2.34757
Timestep Consumption Time: 2.55287
PPO Batch Consumption Time: 0.29566
Total Iteration Time: 4.90044

Cumulative Model Updates: 101,086
Cumulative Timesteps: 842,932,108

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 842932108...
Checkpoint 842932108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 51,905.18535
Policy Entropy: 3.67326
Value Function Loss: 0.03102

Mean KL Divergence: 0.01128
SB3 Clip Fraction: 0.15339
Policy Update Magnitude: 0.41860
Value Function Update Magnitude: 0.33104

Collected Steps per Second: 20,891.02915
Overall Steps per Second: 10,373.05202

Timestep Collection Time: 2.39557
Timestep Consumption Time: 2.42904
PPO Batch Consumption Time: 0.28853
Total Iteration Time: 4.82462

Cumulative Model Updates: 101,092
Cumulative Timesteps: 842,982,154

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51,905.18535
Policy Entropy: 3.67988
Value Function Loss: 0.02805

Mean KL Divergence: 0.01098
SB3 Clip Fraction: 0.15149
Policy Update Magnitude: 0.40801
Value Function Update Magnitude: 0.35938

Collected Steps per Second: 21,002.94808
Overall Steps per Second: 10,293.27331

Timestep Collection Time: 2.38186
Timestep Consumption Time: 2.47821
PPO Batch Consumption Time: 0.29695
Total Iteration Time: 4.86007

Cumulative Model Updates: 101,098
Cumulative Timesteps: 843,032,180

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 843032180...
Checkpoint 843032180 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 201,653.06022
Policy Entropy: 3.67598
Value Function Loss: 0.02762

Mean KL Divergence: 0.01110
SB3 Clip Fraction: 0.15258
Policy Update Magnitude: 0.41580
Value Function Update Magnitude: 0.45467

Collected Steps per Second: 20,899.70374
Overall Steps per Second: 10,041.48408

Timestep Collection Time: 2.39257
Timestep Consumption Time: 2.58717
PPO Batch Consumption Time: 0.30775
Total Iteration Time: 4.97974

Cumulative Model Updates: 101,104
Cumulative Timesteps: 843,082,184

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 107,179.57191
Policy Entropy: 3.67270
Value Function Loss: 0.02870

Mean KL Divergence: 0.01072
SB3 Clip Fraction: 0.14688
Policy Update Magnitude: 0.42005
Value Function Update Magnitude: 0.63065

Collected Steps per Second: 21,364.10576
Overall Steps per Second: 10,185.35235

Timestep Collection Time: 2.34094
Timestep Consumption Time: 2.56925
PPO Batch Consumption Time: 0.30047
Total Iteration Time: 4.91019

Cumulative Model Updates: 101,110
Cumulative Timesteps: 843,132,196

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 843132196...
Checkpoint 843132196 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 136,076.21731
Policy Entropy: 3.67059
Value Function Loss: 0.03250

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.14308
Policy Update Magnitude: 0.44545
Value Function Update Magnitude: 0.67661

Collected Steps per Second: 21,514.60275
Overall Steps per Second: 10,370.92674

Timestep Collection Time: 2.32596
Timestep Consumption Time: 2.49926
PPO Batch Consumption Time: 0.28909
Total Iteration Time: 4.82522

Cumulative Model Updates: 101,116
Cumulative Timesteps: 843,182,238

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 136,076.21731
Policy Entropy: 3.65523
Value Function Loss: 0.03290

Mean KL Divergence: 0.01137
SB3 Clip Fraction: 0.15031
Policy Update Magnitude: 0.49236
Value Function Update Magnitude: 0.60027

Collected Steps per Second: 21,484.23476
Overall Steps per Second: 10,170.59078

Timestep Collection Time: 2.32859
Timestep Consumption Time: 2.59030
PPO Batch Consumption Time: 0.30142
Total Iteration Time: 4.91889

Cumulative Model Updates: 101,122
Cumulative Timesteps: 843,232,266

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 843232266...
Checkpoint 843232266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 136,076.21731
Policy Entropy: 3.65260
Value Function Loss: 0.03314

Mean KL Divergence: 0.01102
SB3 Clip Fraction: 0.15102
Policy Update Magnitude: 0.48707
Value Function Update Magnitude: 0.50565

Collected Steps per Second: 21,426.30839
Overall Steps per Second: 10,180.07635

Timestep Collection Time: 2.33535
Timestep Consumption Time: 2.57993
PPO Batch Consumption Time: 0.30114
Total Iteration Time: 4.91529

Cumulative Model Updates: 101,128
Cumulative Timesteps: 843,282,304

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 136,076.21731
Policy Entropy: 3.64233
Value Function Loss: 0.03282

Mean KL Divergence: 0.01112
SB3 Clip Fraction: 0.15450
Policy Update Magnitude: 0.45471
Value Function Update Magnitude: 0.44521

Collected Steps per Second: 21,180.19880
Overall Steps per Second: 10,096.54906

Timestep Collection Time: 2.36070
Timestep Consumption Time: 2.59149
PPO Batch Consumption Time: 0.30007
Total Iteration Time: 4.95219

Cumulative Model Updates: 101,134
Cumulative Timesteps: 843,332,304

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 843332304...
Checkpoint 843332304 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 525,189.87280
Policy Entropy: 3.66360
Value Function Loss: 0.03100

Mean KL Divergence: 0.01071
SB3 Clip Fraction: 0.14820
Policy Update Magnitude: 0.46662
Value Function Update Magnitude: 0.43275

Collected Steps per Second: 21,578.47945
Overall Steps per Second: 10,251.15010

Timestep Collection Time: 2.31722
Timestep Consumption Time: 2.56048
PPO Batch Consumption Time: 0.29904
Total Iteration Time: 4.87770

Cumulative Model Updates: 101,140
Cumulative Timesteps: 843,382,306

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 425,400.98444
Policy Entropy: 3.68047
Value Function Loss: 0.02815

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.14666
Policy Update Magnitude: 0.49291
Value Function Update Magnitude: 0.49725

Collected Steps per Second: 21,855.96689
Overall Steps per Second: 10,328.92730

Timestep Collection Time: 2.28789
Timestep Consumption Time: 2.55327
PPO Batch Consumption Time: 0.29540
Total Iteration Time: 4.84116

Cumulative Model Updates: 101,146
Cumulative Timesteps: 843,432,310

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 843432310...
Checkpoint 843432310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 391,451.15983
Policy Entropy: 3.68371
Value Function Loss: 0.02671

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.14314
Policy Update Magnitude: 0.46122
Value Function Update Magnitude: 0.46015

Collected Steps per Second: 21,343.00924
Overall Steps per Second: 10,231.55051

Timestep Collection Time: 2.34325
Timestep Consumption Time: 2.54477
PPO Batch Consumption Time: 0.29503
Total Iteration Time: 4.88802

Cumulative Model Updates: 101,152
Cumulative Timesteps: 843,482,322

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 391,451.15983
Policy Entropy: 3.66459
Value Function Loss: 0.02844

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.14665
Policy Update Magnitude: 0.44761
Value Function Update Magnitude: 0.56831

Collected Steps per Second: 21,781.49355
Overall Steps per Second: 10,387.38420

Timestep Collection Time: 2.29553
Timestep Consumption Time: 2.51800
PPO Batch Consumption Time: 0.28865
Total Iteration Time: 4.81353

Cumulative Model Updates: 101,158
Cumulative Timesteps: 843,532,322

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 843532322...
Checkpoint 843532322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 391,451.15983
Policy Entropy: 3.66251
Value Function Loss: 0.03026

Mean KL Divergence: 0.01077
SB3 Clip Fraction: 0.14951
Policy Update Magnitude: 0.46479
Value Function Update Magnitude: 0.46737

Collected Steps per Second: 21,386.32122
Overall Steps per Second: 10,255.10013

Timestep Collection Time: 2.33794
Timestep Consumption Time: 2.53768
PPO Batch Consumption Time: 0.29354
Total Iteration Time: 4.87562

Cumulative Model Updates: 101,164
Cumulative Timesteps: 843,582,322

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 628,789.80829
Policy Entropy: 3.65988
Value Function Loss: 0.02807

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.14437
Policy Update Magnitude: 0.45077
Value Function Update Magnitude: 0.42183

Collected Steps per Second: 21,700.79692
Overall Steps per Second: 10,382.10630

Timestep Collection Time: 2.30517
Timestep Consumption Time: 2.51312
PPO Batch Consumption Time: 0.28832
Total Iteration Time: 4.81829

Cumulative Model Updates: 101,170
Cumulative Timesteps: 843,632,346

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 843632346...
Checkpoint 843632346 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 628,789.80829
Policy Entropy: 3.66283
Value Function Loss: 0.02618

Mean KL Divergence: 0.01109
SB3 Clip Fraction: 0.15445
Policy Update Magnitude: 0.40881
Value Function Update Magnitude: 0.38766

Collected Steps per Second: 20,892.02653
Overall Steps per Second: 10,168.74082

Timestep Collection Time: 2.39345
Timestep Consumption Time: 2.52397
PPO Batch Consumption Time: 0.28777
Total Iteration Time: 4.91742

Cumulative Model Updates: 101,176
Cumulative Timesteps: 843,682,350

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 628,789.80829
Policy Entropy: 3.65681
Value Function Loss: 0.02668

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.14555
Policy Update Magnitude: 0.38410
Value Function Update Magnitude: 0.32606

Collected Steps per Second: 21,726.54270
Overall Steps per Second: 10,108.81259

Timestep Collection Time: 2.30262
Timestep Consumption Time: 2.64633
PPO Batch Consumption Time: 0.31163
Total Iteration Time: 4.94895

Cumulative Model Updates: 101,182
Cumulative Timesteps: 843,732,378

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 843732378...
Checkpoint 843732378 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 628,789.80829
Policy Entropy: 3.67001
Value Function Loss: 0.02478

Mean KL Divergence: 0.01047
SB3 Clip Fraction: 0.14917
Policy Update Magnitude: 0.40010
Value Function Update Magnitude: 0.32875

Collected Steps per Second: 21,174.99541
Overall Steps per Second: 10,279.85254

Timestep Collection Time: 2.36128
Timestep Consumption Time: 2.50261
PPO Batch Consumption Time: 0.29053
Total Iteration Time: 4.86388

Cumulative Model Updates: 101,188
Cumulative Timesteps: 843,782,378

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 628,789.80829
Policy Entropy: 3.66635
Value Function Loss: 0.02569

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.15079
Policy Update Magnitude: 0.39637
Value Function Update Magnitude: 0.34587

Collected Steps per Second: 21,083.21118
Overall Steps per Second: 10,436.07696

Timestep Collection Time: 2.37317
Timestep Consumption Time: 2.42116
PPO Batch Consumption Time: 0.28687
Total Iteration Time: 4.79433

Cumulative Model Updates: 101,194
Cumulative Timesteps: 843,832,412

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 843832412...
Checkpoint 843832412 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 628,789.80829
Policy Entropy: 3.68375
Value Function Loss: 0.02409

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.14475
Policy Update Magnitude: 0.38128
Value Function Update Magnitude: 0.36254

Collected Steps per Second: 20,770.19304
Overall Steps per Second: 10,184.39978

Timestep Collection Time: 2.40816
Timestep Consumption Time: 2.50307
PPO Batch Consumption Time: 0.30094
Total Iteration Time: 4.91124

Cumulative Model Updates: 101,200
Cumulative Timesteps: 843,882,430

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 628,789.80829
Policy Entropy: 3.66896
Value Function Loss: 0.02424

Mean KL Divergence: 0.01124
SB3 Clip Fraction: 0.15442
Policy Update Magnitude: 0.39591
Value Function Update Magnitude: 0.39492

Collected Steps per Second: 20,820.04804
Overall Steps per Second: 10,076.57496

Timestep Collection Time: 2.40288
Timestep Consumption Time: 2.56191
PPO Batch Consumption Time: 0.30176
Total Iteration Time: 4.96478

Cumulative Model Updates: 101,206
Cumulative Timesteps: 843,932,458

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 843932458...
Checkpoint 843932458 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 628,789.80829
Policy Entropy: 3.66868
Value Function Loss: 0.02557

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.13778
Policy Update Magnitude: 0.39433
Value Function Update Magnitude: 0.41034

Collected Steps per Second: 21,418.02764
Overall Steps per Second: 10,243.80460

Timestep Collection Time: 2.33448
Timestep Consumption Time: 2.54652
PPO Batch Consumption Time: 0.30071
Total Iteration Time: 4.88100

Cumulative Model Updates: 101,212
Cumulative Timesteps: 843,982,458

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 628,789.80829
Policy Entropy: 3.66408
Value Function Loss: 0.02614

Mean KL Divergence: 0.01058
SB3 Clip Fraction: 0.15022
Policy Update Magnitude: 0.39293
Value Function Update Magnitude: 0.49456

Collected Steps per Second: 21,652.80792
Overall Steps per Second: 10,390.41215

Timestep Collection Time: 2.31009
Timestep Consumption Time: 2.50396
PPO Batch Consumption Time: 0.29081
Total Iteration Time: 4.81405

Cumulative Model Updates: 101,218
Cumulative Timesteps: 844,032,478

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 844032478...
Checkpoint 844032478 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 628,789.80829
Policy Entropy: 3.66916
Value Function Loss: 0.03156

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.14321
Policy Update Magnitude: 0.39990
Value Function Update Magnitude: 0.46772

Collected Steps per Second: 21,540.18620
Overall Steps per Second: 10,219.63760

Timestep Collection Time: 2.32161
Timestep Consumption Time: 2.57171
PPO Batch Consumption Time: 0.29819
Total Iteration Time: 4.89332

Cumulative Model Updates: 101,224
Cumulative Timesteps: 844,082,486

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 628,789.80829
Policy Entropy: 3.67351
Value Function Loss: 0.03492

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.13997
Policy Update Magnitude: 0.40846
Value Function Update Magnitude: 0.40746

Collected Steps per Second: 21,523.02703
Overall Steps per Second: 10,335.04877

Timestep Collection Time: 2.32346
Timestep Consumption Time: 2.51522
PPO Batch Consumption Time: 0.28863
Total Iteration Time: 4.83868

Cumulative Model Updates: 101,230
Cumulative Timesteps: 844,132,494

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 844132494...
Checkpoint 844132494 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 628,789.80829
Policy Entropy: 3.66817
Value Function Loss: 0.02817

Mean KL Divergence: 0.01093
SB3 Clip Fraction: 0.15120
Policy Update Magnitude: 0.39795
Value Function Update Magnitude: 0.39920

Collected Steps per Second: 21,567.41587
Overall Steps per Second: 10,216.27929

Timestep Collection Time: 2.31961
Timestep Consumption Time: 2.57728
PPO Batch Consumption Time: 0.29782
Total Iteration Time: 4.89689

Cumulative Model Updates: 101,236
Cumulative Timesteps: 844,182,522

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 628,789.80829
Policy Entropy: 3.67344
Value Function Loss: 0.02328

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.14304
Policy Update Magnitude: 0.36038
Value Function Update Magnitude: 0.42301

Collected Steps per Second: 21,213.59475
Overall Steps per Second: 10,116.97146

Timestep Collection Time: 2.35754
Timestep Consumption Time: 2.58583
PPO Batch Consumption Time: 0.30006
Total Iteration Time: 4.94338

Cumulative Model Updates: 101,242
Cumulative Timesteps: 844,232,534

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 844232534...
Checkpoint 844232534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 628,789.80829
Policy Entropy: 3.67421
Value Function Loss: 0.02028

Mean KL Divergence: 0.01058
SB3 Clip Fraction: 0.14997
Policy Update Magnitude: 0.34871
Value Function Update Magnitude: 0.42572

Collected Steps per Second: 21,491.75392
Overall Steps per Second: 10,188.22363

Timestep Collection Time: 2.32713
Timestep Consumption Time: 2.58188
PPO Batch Consumption Time: 0.30114
Total Iteration Time: 4.90900

Cumulative Model Updates: 101,248
Cumulative Timesteps: 844,282,548

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 628,789.80829
Policy Entropy: 3.66025
Value Function Loss: 0.02327

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.15008
Policy Update Magnitude: 0.33182
Value Function Update Magnitude: 0.39390

Collected Steps per Second: 21,675.53742
Overall Steps per Second: 10,374.12309

Timestep Collection Time: 2.30730
Timestep Consumption Time: 2.51354
PPO Batch Consumption Time: 0.28794
Total Iteration Time: 4.82084

Cumulative Model Updates: 101,254
Cumulative Timesteps: 844,332,560

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 844332560...
Checkpoint 844332560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 628,789.80829
Policy Entropy: 3.65463
Value Function Loss: 0.02172

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.14782
Policy Update Magnitude: 0.34312
Value Function Update Magnitude: 0.36061

Collected Steps per Second: 21,100.15357
Overall Steps per Second: 10,267.40681

Timestep Collection Time: 2.36965
Timestep Consumption Time: 2.50013
PPO Batch Consumption Time: 0.28630
Total Iteration Time: 4.86978

Cumulative Model Updates: 101,260
Cumulative Timesteps: 844,382,560

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 628,789.80829
Policy Entropy: 3.65210
Value Function Loss: 0.02345

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.14504
Policy Update Magnitude: 0.34677
Value Function Update Magnitude: 0.32309

Collected Steps per Second: 21,222.07157
Overall Steps per Second: 10,219.45929

Timestep Collection Time: 2.35679
Timestep Consumption Time: 2.53740
PPO Batch Consumption Time: 0.29422
Total Iteration Time: 4.89419

Cumulative Model Updates: 101,266
Cumulative Timesteps: 844,432,576

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 844432576...
Checkpoint 844432576 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 628,789.80829
Policy Entropy: 3.67457
Value Function Loss: 0.02204

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.14022
Policy Update Magnitude: 0.40334
Value Function Update Magnitude: 0.40457

Collected Steps per Second: 21,645.67851
Overall Steps per Second: 10,397.81499

Timestep Collection Time: 2.30993
Timestep Consumption Time: 2.49877
PPO Batch Consumption Time: 0.28808
Total Iteration Time: 4.80870

Cumulative Model Updates: 101,272
Cumulative Timesteps: 844,482,576

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 933,667.84064
Policy Entropy: 3.67507
Value Function Loss: 0.02685

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.14472
Policy Update Magnitude: 0.43354
Value Function Update Magnitude: 0.51482

Collected Steps per Second: 20,844.06982
Overall Steps per Second: 10,359.29894

Timestep Collection Time: 2.39992
Timestep Consumption Time: 2.42898
PPO Batch Consumption Time: 0.28901
Total Iteration Time: 4.82890

Cumulative Model Updates: 101,278
Cumulative Timesteps: 844,532,600

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 844532600...
Checkpoint 844532600 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 210,721.06497
Policy Entropy: 3.68433
Value Function Loss: 0.02797

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.14159
Policy Update Magnitude: 0.48700
Value Function Update Magnitude: 0.68438

Collected Steps per Second: 20,807.00480
Overall Steps per Second: 10,335.69755

Timestep Collection Time: 2.40400
Timestep Consumption Time: 2.43554
PPO Batch Consumption Time: 0.28984
Total Iteration Time: 4.83954

Cumulative Model Updates: 101,284
Cumulative Timesteps: 844,582,620

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48,229.68822
Policy Entropy: 3.68587
Value Function Loss: 0.03117

Mean KL Divergence: 0.01129
SB3 Clip Fraction: 0.15278
Policy Update Magnitude: 0.54531
Value Function Update Magnitude: 0.66529

Collected Steps per Second: 20,837.56321
Overall Steps per Second: 10,356.18252

Timestep Collection Time: 2.40009
Timestep Consumption Time: 2.42910
PPO Batch Consumption Time: 0.28806
Total Iteration Time: 4.82919

Cumulative Model Updates: 101,290
Cumulative Timesteps: 844,632,632

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 844632632...
Checkpoint 844632632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,828.06989
Policy Entropy: 3.68502
Value Function Loss: 0.02991

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.14024
Policy Update Magnitude: 0.52285
Value Function Update Magnitude: 0.67759

Collected Steps per Second: 20,708.54903
Overall Steps per Second: 10,231.32038

Timestep Collection Time: 2.41523
Timestep Consumption Time: 2.47328
PPO Batch Consumption Time: 0.28675
Total Iteration Time: 4.88852

Cumulative Model Updates: 101,296
Cumulative Timesteps: 844,682,648

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,828.06989
Policy Entropy: 3.68859
Value Function Loss: 0.02599

Mean KL Divergence: 0.01058
SB3 Clip Fraction: 0.14557
Policy Update Magnitude: 0.50666
Value Function Update Magnitude: 0.72176

Collected Steps per Second: 21,516.95709
Overall Steps per Second: 10,262.27817

Timestep Collection Time: 2.32459
Timestep Consumption Time: 2.54938
PPO Batch Consumption Time: 0.29892
Total Iteration Time: 4.87397

Cumulative Model Updates: 101,302
Cumulative Timesteps: 844,732,666

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 844732666...
Checkpoint 844732666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,828.06989
Policy Entropy: 3.67034
Value Function Loss: 0.02310

Mean KL Divergence: 0.01154
SB3 Clip Fraction: 0.15435
Policy Update Magnitude: 0.49501
Value Function Update Magnitude: 0.76649

Collected Steps per Second: 21,484.89181
Overall Steps per Second: 10,352.85026

Timestep Collection Time: 2.32759
Timestep Consumption Time: 2.50277
PPO Batch Consumption Time: 0.28823
Total Iteration Time: 4.83036

Cumulative Model Updates: 101,308
Cumulative Timesteps: 844,782,674

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,828.06989
Policy Entropy: 3.66252
Value Function Loss: 0.02333

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.14764
Policy Update Magnitude: 0.45283
Value Function Update Magnitude: 0.64840

Collected Steps per Second: 21,713.07712
Overall Steps per Second: 10,251.01898

Timestep Collection Time: 2.30322
Timestep Consumption Time: 2.57532
PPO Batch Consumption Time: 0.29842
Total Iteration Time: 4.87854

Cumulative Model Updates: 101,314
Cumulative Timesteps: 844,832,684

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 844832684...
Checkpoint 844832684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,828.06989
Policy Entropy: 3.64768
Value Function Loss: 0.02574

Mean KL Divergence: 0.01072
SB3 Clip Fraction: 0.15046
Policy Update Magnitude: 0.42897
Value Function Update Magnitude: 0.49697

Collected Steps per Second: 21,268.60610
Overall Steps per Second: 10,129.04158

Timestep Collection Time: 2.35145
Timestep Consumption Time: 2.58604
PPO Batch Consumption Time: 0.30156
Total Iteration Time: 4.93749

Cumulative Model Updates: 101,320
Cumulative Timesteps: 844,882,696

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,828.06989
Policy Entropy: 3.64992
Value Function Loss: 0.02738

Mean KL Divergence: 0.01070
SB3 Clip Fraction: 0.15032
Policy Update Magnitude: 0.43541
Value Function Update Magnitude: 0.44264

Collected Steps per Second: 21,434.27778
Overall Steps per Second: 10,324.46106

Timestep Collection Time: 2.33337
Timestep Consumption Time: 2.51086
PPO Batch Consumption Time: 0.28768
Total Iteration Time: 4.84422

Cumulative Model Updates: 101,326
Cumulative Timesteps: 844,932,710

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 844932710...
Checkpoint 844932710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,828.06989
Policy Entropy: 3.67169
Value Function Loss: 0.02601

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.14258
Policy Update Magnitude: 0.44433
Value Function Update Magnitude: 0.47283

Collected Steps per Second: 21,727.14093
Overall Steps per Second: 10,299.85639

Timestep Collection Time: 2.30256
Timestep Consumption Time: 2.55460
PPO Batch Consumption Time: 0.29456
Total Iteration Time: 4.85716

Cumulative Model Updates: 101,332
Cumulative Timesteps: 844,982,738

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,828.06989
Policy Entropy: 3.68175
Value Function Loss: 0.02422

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.14654
Policy Update Magnitude: 0.41986
Value Function Update Magnitude: 0.50549

Collected Steps per Second: 21,205.91699
Overall Steps per Second: 10,155.33693

Timestep Collection Time: 2.35793
Timestep Consumption Time: 2.56579
PPO Batch Consumption Time: 0.30143
Total Iteration Time: 4.92372

Cumulative Model Updates: 101,338
Cumulative Timesteps: 845,032,740

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 845032740...
Checkpoint 845032740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,828.06989
Policy Entropy: 3.66785
Value Function Loss: 0.02532

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.14416
Policy Update Magnitude: 0.40446
Value Function Update Magnitude: 0.50352

Collected Steps per Second: 20,610.31625
Overall Steps per Second: 10,300.17645

Timestep Collection Time: 2.42655
Timestep Consumption Time: 2.42890
PPO Batch Consumption Time: 0.28933
Total Iteration Time: 4.85545

Cumulative Model Updates: 101,344
Cumulative Timesteps: 845,082,752

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,828.06989
Policy Entropy: 3.65862
Value Function Loss: 0.02670

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.14048
Policy Update Magnitude: 0.42364
Value Function Update Magnitude: 0.40393

Collected Steps per Second: 20,759.72371
Overall Steps per Second: 10,221.00126

Timestep Collection Time: 2.40947
Timestep Consumption Time: 2.48437
PPO Batch Consumption Time: 0.29864
Total Iteration Time: 4.89385

Cumulative Model Updates: 101,350
Cumulative Timesteps: 845,132,772

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 845132772...
Checkpoint 845132772 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,828.06989
Policy Entropy: 3.64630
Value Function Loss: 0.02665

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.14512
Policy Update Magnitude: 0.44131
Value Function Update Magnitude: 0.38735

Collected Steps per Second: 20,942.77488
Overall Steps per Second: 10,123.02198

Timestep Collection Time: 2.38851
Timestep Consumption Time: 2.55290
PPO Batch Consumption Time: 0.30114
Total Iteration Time: 4.94141

Cumulative Model Updates: 101,356
Cumulative Timesteps: 845,182,794

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,828.06989
Policy Entropy: 3.65540
Value Function Loss: 0.02353

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.12894
Policy Update Magnitude: 0.48655
Value Function Update Magnitude: 0.36760

Collected Steps per Second: 21,586.40950
Overall Steps per Second: 10,423.44365

Timestep Collection Time: 2.31738
Timestep Consumption Time: 2.48180
PPO Batch Consumption Time: 0.28722
Total Iteration Time: 4.79918

Cumulative Model Updates: 101,362
Cumulative Timesteps: 845,232,818

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 845232818...
Checkpoint 845232818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,828.06989
Policy Entropy: 3.66649
Value Function Loss: 0.02127

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.10638
Policy Update Magnitude: 0.54405
Value Function Update Magnitude: 0.35125

Collected Steps per Second: 21,344.31086
Overall Steps per Second: 10,234.95388

Timestep Collection Time: 2.34292
Timestep Consumption Time: 2.54308
PPO Batch Consumption Time: 0.30017
Total Iteration Time: 4.88600

Cumulative Model Updates: 101,368
Cumulative Timesteps: 845,282,826

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,828.06989
Policy Entropy: 3.66939
Value Function Loss: 0.02694

Mean KL Divergence: 0.01432
SB3 Clip Fraction: 0.17288
Policy Update Magnitude: 0.52761
Value Function Update Magnitude: 0.35137

Collected Steps per Second: 21,300.11369
Overall Steps per Second: 10,305.65183

Timestep Collection Time: 2.34769
Timestep Consumption Time: 2.50460
PPO Batch Consumption Time: 0.28885
Total Iteration Time: 4.85229

Cumulative Model Updates: 101,374
Cumulative Timesteps: 845,332,832

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 845332832...
Checkpoint 845332832 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 72,118.67446
Policy Entropy: 3.68104
Value Function Loss: 0.03046

Mean KL Divergence: 0.01207
SB3 Clip Fraction: 0.16537
Policy Update Magnitude: 0.53189
Value Function Update Magnitude: 0.41967

Collected Steps per Second: 21,625.63032
Overall Steps per Second: 10,311.35888

Timestep Collection Time: 2.31281
Timestep Consumption Time: 2.53776
PPO Batch Consumption Time: 0.29138
Total Iteration Time: 4.85057

Cumulative Model Updates: 101,380
Cumulative Timesteps: 845,382,848

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,383.76099
Policy Entropy: 3.68039
Value Function Loss: 0.03087

Mean KL Divergence: 0.01262
SB3 Clip Fraction: 0.17234
Policy Update Magnitude: 0.53493
Value Function Update Magnitude: 0.56072

Collected Steps per Second: 21,351.75223
Overall Steps per Second: 10,190.33318

Timestep Collection Time: 2.34229
Timestep Consumption Time: 2.56550
PPO Batch Consumption Time: 0.29766
Total Iteration Time: 4.90779

Cumulative Model Updates: 101,386
Cumulative Timesteps: 845,432,860

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 845432860...
Checkpoint 845432860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,380.93956
Policy Entropy: 3.68156
Value Function Loss: 0.03176

Mean KL Divergence: 0.01223
SB3 Clip Fraction: 0.15916
Policy Update Magnitude: 0.54626
Value Function Update Magnitude: 0.59605

Collected Steps per Second: 21,558.54564
Overall Steps per Second: 10,387.15338

Timestep Collection Time: 2.32056
Timestep Consumption Time: 2.49577
PPO Batch Consumption Time: 0.28805
Total Iteration Time: 4.81633

Cumulative Model Updates: 101,392
Cumulative Timesteps: 845,482,888

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,380.93956
Policy Entropy: 3.67915
Value Function Loss: 0.03038

Mean KL Divergence: 0.01340
SB3 Clip Fraction: 0.17611
Policy Update Magnitude: 0.57076
Value Function Update Magnitude: 0.52300

Collected Steps per Second: 21,585.06090
Overall Steps per Second: 10,223.43753

Timestep Collection Time: 2.31771
Timestep Consumption Time: 2.57575
PPO Batch Consumption Time: 0.30075
Total Iteration Time: 4.89346

Cumulative Model Updates: 101,398
Cumulative Timesteps: 845,532,916

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 845532916...
Checkpoint 845532916 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,380.93956
Policy Entropy: 3.66526
Value Function Loss: 0.02898

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.13970
Policy Update Magnitude: 0.53639
Value Function Update Magnitude: 0.55704

Collected Steps per Second: 21,605.29073
Overall Steps per Second: 10,270.84854

Timestep Collection Time: 2.31443
Timestep Consumption Time: 2.55410
PPO Batch Consumption Time: 0.29719
Total Iteration Time: 4.86854

Cumulative Model Updates: 101,404
Cumulative Timesteps: 845,582,920

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 262,306.55004
Policy Entropy: 3.66172
Value Function Loss: 0.03347

Mean KL Divergence: 0.01132
SB3 Clip Fraction: 0.14915
Policy Update Magnitude: 0.54404
Value Function Update Magnitude: 0.60508

Collected Steps per Second: 21,531.66089
Overall Steps per Second: 10,268.90942

Timestep Collection Time: 2.32272
Timestep Consumption Time: 2.54752
PPO Batch Consumption Time: 0.29158
Total Iteration Time: 4.87023

Cumulative Model Updates: 101,410
Cumulative Timesteps: 845,632,932

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 845632932...
Checkpoint 845632932 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 91,471.49402
Policy Entropy: 3.67615
Value Function Loss: 0.03161

Mean KL Divergence: 0.01053
SB3 Clip Fraction: 0.13998
Policy Update Magnitude: 0.70163
Value Function Update Magnitude: 0.55176

Collected Steps per Second: 21,296.39495
Overall Steps per Second: 10,057.15956

Timestep Collection Time: 2.34922
Timestep Consumption Time: 2.62534
PPO Batch Consumption Time: 0.30872
Total Iteration Time: 4.97457

Cumulative Model Updates: 101,416
Cumulative Timesteps: 845,682,962

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,901.55834
Policy Entropy: 3.69062
Value Function Loss: 0.03246

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.12796
Policy Update Magnitude: 0.69897
Value Function Update Magnitude: 0.57249

Collected Steps per Second: 21,621.00497
Overall Steps per Second: 10,235.05775

Timestep Collection Time: 2.31414
Timestep Consumption Time: 2.57435
PPO Batch Consumption Time: 0.29956
Total Iteration Time: 4.88849

Cumulative Model Updates: 101,422
Cumulative Timesteps: 845,732,996

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 845732996...
Checkpoint 845732996 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 239,878.93844
Policy Entropy: 3.69950
Value Function Loss: 0.02952

Mean KL Divergence: 0.00722
SB3 Clip Fraction: 0.09152
Policy Update Magnitude: 0.74673
Value Function Update Magnitude: 0.52029

Collected Steps per Second: 21,510.49879
Overall Steps per Second: 10,211.07513

Timestep Collection Time: 2.32668
Timestep Consumption Time: 2.57467
PPO Batch Consumption Time: 0.29766
Total Iteration Time: 4.90134

Cumulative Model Updates: 101,428
Cumulative Timesteps: 845,783,044

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 194,303.46818
Policy Entropy: 3.67992
Value Function Loss: 0.03307

Mean KL Divergence: 0.00747
SB3 Clip Fraction: 0.09524
Policy Update Magnitude: 0.75548
Value Function Update Magnitude: 0.54229

Collected Steps per Second: 20,671.13668
Overall Steps per Second: 10,223.98102

Timestep Collection Time: 2.41980
Timestep Consumption Time: 2.47262
PPO Batch Consumption Time: 0.29683
Total Iteration Time: 4.89242

Cumulative Model Updates: 101,434
Cumulative Timesteps: 845,833,064

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 845833064...
Checkpoint 845833064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 194,303.46818
Policy Entropy: 3.68974
Value Function Loss: 0.02930

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.13260
Policy Update Magnitude: 0.72563
Value Function Update Magnitude: 0.63408

Collected Steps per Second: 20,795.83128
Overall Steps per Second: 10,212.70560

Timestep Collection Time: 2.40442
Timestep Consumption Time: 2.49163
PPO Batch Consumption Time: 0.30051
Total Iteration Time: 4.89606

Cumulative Model Updates: 101,440
Cumulative Timesteps: 845,883,066

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 194,303.46818
Policy Entropy: 3.68595
Value Function Loss: 0.03147

Mean KL Divergence: 0.01811
SB3 Clip Fraction: 0.21939
Policy Update Magnitude: 0.58453
Value Function Update Magnitude: 0.56190

Collected Steps per Second: 21,054.18156
Overall Steps per Second: 10,303.00572

Timestep Collection Time: 2.37559
Timestep Consumption Time: 2.47892
PPO Batch Consumption Time: 0.28790
Total Iteration Time: 4.85451

Cumulative Model Updates: 101,446
Cumulative Timesteps: 845,933,082

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 845933082...
Checkpoint 845933082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 194,303.46818
Policy Entropy: 3.71780
Value Function Loss: 0.03389

Mean KL Divergence: 0.02714
SB3 Clip Fraction: 0.27988
Policy Update Magnitude: 0.44298
Value Function Update Magnitude: 0.40981

Collected Steps per Second: 21,622.16102
Overall Steps per Second: 10,343.28496

Timestep Collection Time: 2.31290
Timestep Consumption Time: 2.52212
PPO Batch Consumption Time: 0.29576
Total Iteration Time: 4.83502

Cumulative Model Updates: 101,452
Cumulative Timesteps: 845,983,092

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 230,122.77696
Policy Entropy: 3.72195
Value Function Loss: 0.05107

Mean KL Divergence: 0.02365
SB3 Clip Fraction: 0.25279
Policy Update Magnitude: 0.39886
Value Function Update Magnitude: 0.29390

Collected Steps per Second: 21,629.69197
Overall Steps per Second: 10,423.78577

Timestep Collection Time: 2.31210
Timestep Consumption Time: 2.48558
PPO Batch Consumption Time: 0.28810
Total Iteration Time: 4.79768

Cumulative Model Updates: 101,458
Cumulative Timesteps: 846,033,102

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 846033102...
Checkpoint 846033102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 467,221.25622
Policy Entropy: 3.70275
Value Function Loss: 0.05353

Mean KL Divergence: 0.01988
SB3 Clip Fraction: 0.21568
Policy Update Magnitude: 0.52191
Value Function Update Magnitude: 0.29673

Collected Steps per Second: 21,058.42015
Overall Steps per Second: 10,265.17556

Timestep Collection Time: 2.37492
Timestep Consumption Time: 2.49709
PPO Batch Consumption Time: 0.28679
Total Iteration Time: 4.87201

Cumulative Model Updates: 101,464
Cumulative Timesteps: 846,083,114

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,012,209.32726
Policy Entropy: 3.67960
Value Function Loss: 0.05466

Mean KL Divergence: 0.01430
SB3 Clip Fraction: 0.17533
Policy Update Magnitude: 0.70503
Value Function Update Magnitude: 0.41888

Collected Steps per Second: 21,162.42542
Overall Steps per Second: 10,127.88972

Timestep Collection Time: 2.36343
Timestep Consumption Time: 2.57501
PPO Batch Consumption Time: 0.29799
Total Iteration Time: 4.93844

Cumulative Model Updates: 101,470
Cumulative Timesteps: 846,133,130

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 846133130...
Checkpoint 846133130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,012,209.32726
Policy Entropy: 3.63576
Value Function Loss: 0.05427

Mean KL Divergence: 0.01226
SB3 Clip Fraction: 0.15105
Policy Update Magnitude: 0.77716
Value Function Update Magnitude: 0.59106

Collected Steps per Second: 20,983.75450
Overall Steps per Second: 10,081.32626

Timestep Collection Time: 2.38280
Timestep Consumption Time: 2.57687
PPO Batch Consumption Time: 0.30099
Total Iteration Time: 4.95966

Cumulative Model Updates: 101,476
Cumulative Timesteps: 846,183,130

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 508,773.99866
Policy Entropy: 3.66088
Value Function Loss: 0.05379

Mean KL Divergence: 0.01115
SB3 Clip Fraction: 0.14002
Policy Update Magnitude: 0.85528
Value Function Update Magnitude: 0.67252

Collected Steps per Second: 21,189.30446
Overall Steps per Second: 10,164.41266

Timestep Collection Time: 2.36072
Timestep Consumption Time: 2.56057
PPO Batch Consumption Time: 0.29862
Total Iteration Time: 4.92129

Cumulative Model Updates: 101,482
Cumulative Timesteps: 846,233,152

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 846233152...
Checkpoint 846233152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 365,326.16851
Policy Entropy: 3.64549
Value Function Loss: 0.05499

Mean KL Divergence: 0.01135
SB3 Clip Fraction: 0.14119
Policy Update Magnitude: 0.82361
Value Function Update Magnitude: 0.55031

Collected Steps per Second: 20,898.66692
Overall Steps per Second: 9,938.06310

Timestep Collection Time: 2.39259
Timestep Consumption Time: 2.63877
PPO Batch Consumption Time: 0.31225
Total Iteration Time: 5.03136

Cumulative Model Updates: 101,488
Cumulative Timesteps: 846,283,154

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83,594.47725
Policy Entropy: 3.66409
Value Function Loss: 0.04989

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.13189
Policy Update Magnitude: 0.80929
Value Function Update Magnitude: 0.58996

Collected Steps per Second: 21,284.86173
Overall Steps per Second: 10,191.09110

Timestep Collection Time: 2.35134
Timestep Consumption Time: 2.55961
PPO Batch Consumption Time: 0.29688
Total Iteration Time: 4.91096

Cumulative Model Updates: 101,494
Cumulative Timesteps: 846,333,202

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 846333202...
Checkpoint 846333202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 242,787.63224
Policy Entropy: 3.66298
Value Function Loss: 0.05212

Mean KL Divergence: 0.01082
SB3 Clip Fraction: 0.13896
Policy Update Magnitude: 0.76919
Value Function Update Magnitude: 0.54249

Collected Steps per Second: 20,229.32582
Overall Steps per Second: 10,201.03862

Timestep Collection Time: 2.47235
Timestep Consumption Time: 2.43048
PPO Batch Consumption Time: 0.28721
Total Iteration Time: 4.90283

Cumulative Model Updates: 101,500
Cumulative Timesteps: 846,383,216

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,308.58036
Policy Entropy: 3.69428
Value Function Loss: 0.04618

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.13266
Policy Update Magnitude: 0.75889
Value Function Update Magnitude: 0.55348

Collected Steps per Second: 20,577.52040
Overall Steps per Second: 10,216.24348

Timestep Collection Time: 2.42993
Timestep Consumption Time: 2.46443
PPO Batch Consumption Time: 0.29621
Total Iteration Time: 4.89436

Cumulative Model Updates: 101,506
Cumulative Timesteps: 846,433,218

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 846433218...
Checkpoint 846433218 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,077.24442
Policy Entropy: 3.68247
Value Function Loss: 0.04645

Mean KL Divergence: 0.01107
SB3 Clip Fraction: 0.13889
Policy Update Magnitude: 0.74840
Value Function Update Magnitude: 0.57815

Collected Steps per Second: 20,756.05805
Overall Steps per Second: 10,257.98445

Timestep Collection Time: 2.40951
Timestep Consumption Time: 2.46591
PPO Batch Consumption Time: 0.29702
Total Iteration Time: 4.87542

Cumulative Model Updates: 101,512
Cumulative Timesteps: 846,483,230

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55,363.74939
Policy Entropy: 3.69000
Value Function Loss: 0.04130

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.13553
Policy Update Magnitude: 0.68233
Value Function Update Magnitude: 0.53782

Collected Steps per Second: 21,059.11068
Overall Steps per Second: 10,265.87884

Timestep Collection Time: 2.37655
Timestep Consumption Time: 2.49863
PPO Batch Consumption Time: 0.30112
Total Iteration Time: 4.87518

Cumulative Model Updates: 101,518
Cumulative Timesteps: 846,533,278

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 846533278...
Checkpoint 846533278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,289.72570
Policy Entropy: 3.67894
Value Function Loss: 0.03984

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.13057
Policy Update Magnitude: 0.63588
Value Function Update Magnitude: 0.51739

Collected Steps per Second: 20,716.97029
Overall Steps per Second: 10,215.82544

Timestep Collection Time: 2.41541
Timestep Consumption Time: 2.48287
PPO Batch Consumption Time: 0.28658
Total Iteration Time: 4.89828

Cumulative Model Updates: 101,524
Cumulative Timesteps: 846,583,318

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,614.24964
Policy Entropy: 3.68082
Value Function Loss: 0.03371

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.12936
Policy Update Magnitude: 0.56675
Value Function Update Magnitude: 0.50612

Collected Steps per Second: 21,527.49482
Overall Steps per Second: 10,366.39545

Timestep Collection Time: 2.32317
Timestep Consumption Time: 2.50127
PPO Batch Consumption Time: 0.28910
Total Iteration Time: 4.82443

Cumulative Model Updates: 101,530
Cumulative Timesteps: 846,633,330

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 846633330...
Checkpoint 846633330 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,614.24964
Policy Entropy: 3.67826
Value Function Loss: 0.03191

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.12977
Policy Update Magnitude: 0.50585
Value Function Update Magnitude: 0.44195

Collected Steps per Second: 21,322.44433
Overall Steps per Second: 10,302.74161

Timestep Collection Time: 2.34551
Timestep Consumption Time: 2.50873
PPO Batch Consumption Time: 0.29441
Total Iteration Time: 4.85424

Cumulative Model Updates: 101,536
Cumulative Timesteps: 846,683,342

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 330,560.02250
Policy Entropy: 3.68113
Value Function Loss: 0.03644

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.13575
Policy Update Magnitude: 0.48309
Value Function Update Magnitude: 0.41842

Collected Steps per Second: 20,223.21152
Overall Steps per Second: 10,017.94797

Timestep Collection Time: 2.47290
Timestep Consumption Time: 2.51914
PPO Batch Consumption Time: 0.28781
Total Iteration Time: 4.99204

Cumulative Model Updates: 101,542
Cumulative Timesteps: 846,733,352

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 846733352...
Checkpoint 846733352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 216,898.32520
Policy Entropy: 3.67815
Value Function Loss: 0.03445

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.13504
Policy Update Magnitude: 0.47168
Value Function Update Magnitude: 0.37454

Collected Steps per Second: 21,542.00594
Overall Steps per Second: 10,202.89174

Timestep Collection Time: 2.32123
Timestep Consumption Time: 2.57973
PPO Batch Consumption Time: 0.29902
Total Iteration Time: 4.90096

Cumulative Model Updates: 101,548
Cumulative Timesteps: 846,783,356

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 216,898.32520
Policy Entropy: 3.66153
Value Function Loss: 0.03166

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.14309
Policy Update Magnitude: 0.46797
Value Function Update Magnitude: 0.44680

Collected Steps per Second: 21,701.89975
Overall Steps per Second: 10,365.97151

Timestep Collection Time: 2.30496
Timestep Consumption Time: 2.52064
PPO Batch Consumption Time: 0.28790
Total Iteration Time: 4.82560

Cumulative Model Updates: 101,554
Cumulative Timesteps: 846,833,378

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 846833378...
Checkpoint 846833378 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 216,898.32520
Policy Entropy: 3.65859
Value Function Loss: 0.03114

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.13295
Policy Update Magnitude: 0.44556
Value Function Update Magnitude: 0.47870

Collected Steps per Second: 21,637.80480
Overall Steps per Second: 10,318.34879

Timestep Collection Time: 2.31151
Timestep Consumption Time: 2.53578
PPO Batch Consumption Time: 0.29384
Total Iteration Time: 4.84729

Cumulative Model Updates: 101,560
Cumulative Timesteps: 846,883,394

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 216,898.32520
Policy Entropy: 3.66529
Value Function Loss: 0.02911

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.14133
Policy Update Magnitude: 0.42383
Value Function Update Magnitude: 0.44251

Collected Steps per Second: 21,395.04012
Overall Steps per Second: 10,297.19177

Timestep Collection Time: 2.33764
Timestep Consumption Time: 2.51941
PPO Batch Consumption Time: 0.28886
Total Iteration Time: 4.85705

Cumulative Model Updates: 101,566
Cumulative Timesteps: 846,933,408

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 846933408...
Checkpoint 846933408 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 216,898.32520
Policy Entropy: 3.67405
Value Function Loss: 0.02598

Mean KL Divergence: 0.01074
SB3 Clip Fraction: 0.14427
Policy Update Magnitude: 0.39239
Value Function Update Magnitude: 0.42955

Collected Steps per Second: 20,589.79418
Overall Steps per Second: 10,310.16935

Timestep Collection Time: 2.42878
Timestep Consumption Time: 2.42158
PPO Batch Consumption Time: 0.28884
Total Iteration Time: 4.85036

Cumulative Model Updates: 101,572
Cumulative Timesteps: 846,983,416

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 216,898.32520
Policy Entropy: 3.66447
Value Function Loss: 0.03007

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.14078
Policy Update Magnitude: 0.38518
Value Function Update Magnitude: 0.36112

Collected Steps per Second: 20,805.01164
Overall Steps per Second: 10,223.38568

Timestep Collection Time: 2.40327
Timestep Consumption Time: 2.48748
PPO Batch Consumption Time: 0.29679
Total Iteration Time: 4.89075

Cumulative Model Updates: 101,578
Cumulative Timesteps: 847,033,416

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 847033416...
Checkpoint 847033416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 152,125.44174
Policy Entropy: 3.67726
Value Function Loss: 0.03476

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.12015
Policy Update Magnitude: 0.52537
Value Function Update Magnitude: 0.32792

Collected Steps per Second: 20,991.15399
Overall Steps per Second: 10,394.14842

Timestep Collection Time: 2.38262
Timestep Consumption Time: 2.42912
PPO Batch Consumption Time: 0.28749
Total Iteration Time: 4.81175

Cumulative Model Updates: 101,584
Cumulative Timesteps: 847,083,430

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 152,125.44174
Policy Entropy: 3.65619
Value Function Loss: 0.03890

Mean KL Divergence: 0.01358
SB3 Clip Fraction: 0.18012
Policy Update Magnitude: 0.48817
Value Function Update Magnitude: 0.31392

Collected Steps per Second: 20,918.27776
Overall Steps per Second: 10,081.14138

Timestep Collection Time: 2.39083
Timestep Consumption Time: 2.57012
PPO Batch Consumption Time: 0.29904
Total Iteration Time: 4.96095

Cumulative Model Updates: 101,590
Cumulative Timesteps: 847,133,442

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 847133442...
Checkpoint 847133442 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 152,125.44174
Policy Entropy: 3.67667
Value Function Loss: 0.03642

Mean KL Divergence: 0.01281
SB3 Clip Fraction: 0.16529
Policy Update Magnitude: 0.43370
Value Function Update Magnitude: 0.34030

Collected Steps per Second: 21,281.73983
Overall Steps per Second: 10,219.32447

Timestep Collection Time: 2.35056
Timestep Consumption Time: 2.54448
PPO Batch Consumption Time: 0.29745
Total Iteration Time: 4.89504

Cumulative Model Updates: 101,596
Cumulative Timesteps: 847,183,466

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 152,125.44174
Policy Entropy: 3.68034
Value Function Loss: 0.03736

Mean KL Divergence: 0.01304
SB3 Clip Fraction: 0.16696
Policy Update Magnitude: 0.47365
Value Function Update Magnitude: 0.35364

Collected Steps per Second: 21,389.78057
Overall Steps per Second: 10,391.52766

Timestep Collection Time: 2.33803
Timestep Consumption Time: 2.47454
PPO Batch Consumption Time: 0.28767
Total Iteration Time: 4.81257

Cumulative Model Updates: 101,602
Cumulative Timesteps: 847,233,476

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 847233476...
Checkpoint 847233476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 714,435.24213
Policy Entropy: 3.70428
Value Function Loss: 0.03046

Mean KL Divergence: 0.01078
SB3 Clip Fraction: 0.14613
Policy Update Magnitude: 0.46738
Value Function Update Magnitude: 0.37114

Collected Steps per Second: 21,524.24718
Overall Steps per Second: 10,272.09975

Timestep Collection Time: 2.32389
Timestep Consumption Time: 2.54561
PPO Batch Consumption Time: 0.29470
Total Iteration Time: 4.86950

Cumulative Model Updates: 101,608
Cumulative Timesteps: 847,283,496

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 714,435.24213
Policy Entropy: 3.71358
Value Function Loss: 0.02494

Mean KL Divergence: 0.01074
SB3 Clip Fraction: 0.14839
Policy Update Magnitude: 0.40658
Value Function Update Magnitude: 0.38150

Collected Steps per Second: 21,564.84701
Overall Steps per Second: 10,332.45284

Timestep Collection Time: 2.31942
Timestep Consumption Time: 2.52144
PPO Batch Consumption Time: 0.28799
Total Iteration Time: 4.84086

Cumulative Model Updates: 101,614
Cumulative Timesteps: 847,333,514

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 847333514...
Checkpoint 847333514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 725,000.57820
Policy Entropy: 3.70063
Value Function Loss: 0.02442

Mean KL Divergence: 0.01072
SB3 Clip Fraction: 0.14910
Policy Update Magnitude: 0.34503
Value Function Update Magnitude: 0.37013

Collected Steps per Second: 21,789.07668
Overall Steps per Second: 10,357.92407

Timestep Collection Time: 2.29473
Timestep Consumption Time: 2.53249
PPO Batch Consumption Time: 0.29339
Total Iteration Time: 4.82722

Cumulative Model Updates: 101,620
Cumulative Timesteps: 847,383,514

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 312,108.75957
Policy Entropy: 3.69124
Value Function Loss: 0.02360

Mean KL Divergence: 0.01047
SB3 Clip Fraction: 0.14778
Policy Update Magnitude: 0.34696
Value Function Update Magnitude: 0.52574

Collected Steps per Second: 21,629.04102
Overall Steps per Second: 10,362.08108

Timestep Collection Time: 2.31300
Timestep Consumption Time: 2.51499
PPO Batch Consumption Time: 0.28822
Total Iteration Time: 4.82799

Cumulative Model Updates: 101,626
Cumulative Timesteps: 847,433,542

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 847433542...
Checkpoint 847433542 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 252,811.72843
Policy Entropy: 3.65549
Value Function Loss: 0.03229

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.14331
Policy Update Magnitude: 0.38569
Value Function Update Magnitude: 0.55465

Collected Steps per Second: 21,605.86741
Overall Steps per Second: 10,300.52986

Timestep Collection Time: 2.31530
Timestep Consumption Time: 2.54115
PPO Batch Consumption Time: 0.29350
Total Iteration Time: 4.85645

Cumulative Model Updates: 101,632
Cumulative Timesteps: 847,483,566

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 225,035.55221
Policy Entropy: 3.68369
Value Function Loss: 0.03143

Mean KL Divergence: 0.01050
SB3 Clip Fraction: 0.14704
Policy Update Magnitude: 0.43461
Value Function Update Magnitude: 0.53708

Collected Steps per Second: 21,874.70414
Overall Steps per Second: 10,399.57021

Timestep Collection Time: 2.28575
Timestep Consumption Time: 2.52215
PPO Batch Consumption Time: 0.29001
Total Iteration Time: 4.80789

Cumulative Model Updates: 101,638
Cumulative Timesteps: 847,533,566

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 847533566...
Checkpoint 847533566 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 232,803.45134
Policy Entropy: 3.67837
Value Function Loss: 0.03455

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.14474
Policy Update Magnitude: 0.43006
Value Function Update Magnitude: 0.52822

Collected Steps per Second: 21,216.81002
Overall Steps per Second: 10,185.22971

Timestep Collection Time: 2.35700
Timestep Consumption Time: 2.55286
PPO Batch Consumption Time: 0.29776
Total Iteration Time: 4.90985

Cumulative Model Updates: 101,644
Cumulative Timesteps: 847,583,574

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 238,035.57687
Policy Entropy: 3.69433
Value Function Loss: 0.02808

Mean KL Divergence: 0.01050
SB3 Clip Fraction: 0.14876
Policy Update Magnitude: 0.41758
Value Function Update Magnitude: 0.54739

Collected Steps per Second: 21,338.09997
Overall Steps per Second: 10,211.09205

Timestep Collection Time: 2.34407
Timestep Consumption Time: 2.55433
PPO Batch Consumption Time: 0.29750
Total Iteration Time: 4.89840

Cumulative Model Updates: 101,650
Cumulative Timesteps: 847,633,592

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 847633592...
Checkpoint 847633592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 238,035.57687
Policy Entropy: 3.67451
Value Function Loss: 0.02871

Mean KL Divergence: 0.01072
SB3 Clip Fraction: 0.15230
Policy Update Magnitude: 0.39783
Value Function Update Magnitude: 0.53265

Collected Steps per Second: 21,563.15460
Overall Steps per Second: 10,253.47766

Timestep Collection Time: 2.32044
Timestep Consumption Time: 2.55947
PPO Batch Consumption Time: 0.29745
Total Iteration Time: 4.87991

Cumulative Model Updates: 101,656
Cumulative Timesteps: 847,683,628

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 108,719.79598
Policy Entropy: 3.69460
Value Function Loss: 0.02694

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.14769
Policy Update Magnitude: 0.40785
Value Function Update Magnitude: 0.47499

Collected Steps per Second: 21,817.32696
Overall Steps per Second: 10,271.13778

Timestep Collection Time: 2.29194
Timestep Consumption Time: 2.57646
PPO Batch Consumption Time: 0.29978
Total Iteration Time: 4.86840

Cumulative Model Updates: 101,662
Cumulative Timesteps: 847,733,632

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 847733632...
Checkpoint 847733632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 53,390.99069
Policy Entropy: 3.70251
Value Function Loss: 0.02855

Mean KL Divergence: 0.01096
SB3 Clip Fraction: 0.15267
Policy Update Magnitude: 0.39367
Value Function Update Magnitude: 0.51147

Collected Steps per Second: 21,391.17324
Overall Steps per Second: 10,216.74080

Timestep Collection Time: 2.33741
Timestep Consumption Time: 2.55652
PPO Batch Consumption Time: 0.29725
Total Iteration Time: 4.89393

Cumulative Model Updates: 101,668
Cumulative Timesteps: 847,783,632

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,620.38524
Policy Entropy: 3.71896
Value Function Loss: 0.02637

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.13735
Policy Update Magnitude: 0.38828
Value Function Update Magnitude: 0.54480

Collected Steps per Second: 20,546.37118
Overall Steps per Second: 10,134.17184

Timestep Collection Time: 2.43508
Timestep Consumption Time: 2.50188
PPO Batch Consumption Time: 0.29947
Total Iteration Time: 4.93696

Cumulative Model Updates: 101,674
Cumulative Timesteps: 847,833,664

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 847833664...
Checkpoint 847833664 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 411,710.34230
Policy Entropy: 3.70803
Value Function Loss: 0.02920

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.14490
Policy Update Magnitude: 0.39007
Value Function Update Magnitude: 0.63864

Collected Steps per Second: 20,701.67752
Overall Steps per Second: 10,241.44947

Timestep Collection Time: 2.41613
Timestep Consumption Time: 2.46775
PPO Batch Consumption Time: 0.29868
Total Iteration Time: 4.88388

Cumulative Model Updates: 101,680
Cumulative Timesteps: 847,883,682

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 107,877.59452
Policy Entropy: 3.70245
Value Function Loss: 0.02978

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.13943
Policy Update Magnitude: 0.41702
Value Function Update Magnitude: 0.58966

Collected Steps per Second: 20,680.93720
Overall Steps per Second: 10,202.12218

Timestep Collection Time: 2.41894
Timestep Consumption Time: 2.48455
PPO Batch Consumption Time: 0.28859
Total Iteration Time: 4.90349

Cumulative Model Updates: 101,686
Cumulative Timesteps: 847,933,708

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 847933708...
Checkpoint 847933708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,488.27820
Policy Entropy: 3.70183
Value Function Loss: 0.03069

Mean KL Divergence: 0.01055
SB3 Clip Fraction: 0.14753
Policy Update Magnitude: 0.44541
Value Function Update Magnitude: 0.57842

Collected Steps per Second: 20,974.82606
Overall Steps per Second: 10,271.49287

Timestep Collection Time: 2.38400
Timestep Consumption Time: 2.48423
PPO Batch Consumption Time: 0.28796
Total Iteration Time: 4.86823

Cumulative Model Updates: 101,692
Cumulative Timesteps: 847,983,712

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 128,261.49448
Policy Entropy: 3.70812
Value Function Loss: 0.03135

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.14021
Policy Update Magnitude: 0.44253
Value Function Update Magnitude: 0.59822

Collected Steps per Second: 21,405.18163
Overall Steps per Second: 10,291.74679

Timestep Collection Time: 2.33719
Timestep Consumption Time: 2.52379
PPO Batch Consumption Time: 0.29626
Total Iteration Time: 4.86098

Cumulative Model Updates: 101,698
Cumulative Timesteps: 848,033,740

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 848033740...
Checkpoint 848033740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 128,261.49448
Policy Entropy: 3.71236
Value Function Loss: 0.02658

Mean KL Divergence: 0.01066
SB3 Clip Fraction: 0.14531
Policy Update Magnitude: 0.47098
Value Function Update Magnitude: 0.56638

Collected Steps per Second: 21,610.05497
Overall Steps per Second: 10,479.18189

Timestep Collection Time: 2.31402
Timestep Consumption Time: 2.45792
PPO Batch Consumption Time: 0.28596
Total Iteration Time: 4.77194

Cumulative Model Updates: 101,704
Cumulative Timesteps: 848,083,746

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 128,261.49448
Policy Entropy: 3.69572
Value Function Loss: 0.02607

Mean KL Divergence: 0.01057
SB3 Clip Fraction: 0.14855
Policy Update Magnitude: 0.45675
Value Function Update Magnitude: 0.47271

Collected Steps per Second: 21,607.56349
Overall Steps per Second: 10,311.42176

Timestep Collection Time: 2.31456
Timestep Consumption Time: 2.53560
PPO Batch Consumption Time: 0.28869
Total Iteration Time: 4.85016

Cumulative Model Updates: 101,710
Cumulative Timesteps: 848,133,758

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 848133758...
Checkpoint 848133758 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 128,261.49448
Policy Entropy: 3.69816
Value Function Loss: 0.02277

Mean KL Divergence: 0.01080
SB3 Clip Fraction: 0.15246
Policy Update Magnitude: 0.41724
Value Function Update Magnitude: 0.50376

Collected Steps per Second: 21,988.40713
Overall Steps per Second: 10,274.00194

Timestep Collection Time: 2.27438
Timestep Consumption Time: 2.59325
PPO Batch Consumption Time: 0.30393
Total Iteration Time: 4.86763

Cumulative Model Updates: 101,716
Cumulative Timesteps: 848,183,768

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 128,261.49448
Policy Entropy: 3.68531
Value Function Loss: 0.02463

Mean KL Divergence: 0.01081
SB3 Clip Fraction: 0.15219
Policy Update Magnitude: 0.38634
Value Function Update Magnitude: 0.51498

Collected Steps per Second: 21,579.89368
Overall Steps per Second: 10,066.93061

Timestep Collection Time: 2.31725
Timestep Consumption Time: 2.65010
PPO Batch Consumption Time: 0.31178
Total Iteration Time: 4.96735

Cumulative Model Updates: 101,722
Cumulative Timesteps: 848,233,774

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 848233774...
Checkpoint 848233774 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 128,261.49448
Policy Entropy: 3.69395
Value Function Loss: 0.02260

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.14143
Policy Update Magnitude: 0.38163
Value Function Update Magnitude: 0.51222

Collected Steps per Second: 21,418.15086
Overall Steps per Second: 10,215.70359

Timestep Collection Time: 2.33522
Timestep Consumption Time: 2.56078
PPO Batch Consumption Time: 0.29709
Total Iteration Time: 4.89599

Cumulative Model Updates: 101,728
Cumulative Timesteps: 848,283,790

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 674,463.05541
Policy Entropy: 3.67823
Value Function Loss: 0.02559

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.14366
Policy Update Magnitude: 0.39294
Value Function Update Magnitude: 0.50888

Collected Steps per Second: 21,550.30502
Overall Steps per Second: 10,334.59470

Timestep Collection Time: 2.32052
Timestep Consumption Time: 2.51837
PPO Batch Consumption Time: 0.28812
Total Iteration Time: 4.83889

Cumulative Model Updates: 101,734
Cumulative Timesteps: 848,333,798

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 848333798...
Checkpoint 848333798 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 394,797.14561
Policy Entropy: 3.69876
Value Function Loss: 0.02452

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.14036
Policy Update Magnitude: 0.39573
Value Function Update Magnitude: 0.43732

Collected Steps per Second: 21,463.27943
Overall Steps per Second: 10,358.96208

Timestep Collection Time: 2.33077
Timestep Consumption Time: 2.49848
PPO Batch Consumption Time: 0.28649
Total Iteration Time: 4.82925

Cumulative Model Updates: 101,740
Cumulative Timesteps: 848,383,824

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 209,814.90847
Policy Entropy: 3.69825
Value Function Loss: 0.02669

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.15074
Policy Update Magnitude: 0.38308
Value Function Update Magnitude: 0.39323

Collected Steps per Second: 21,849.91651
Overall Steps per Second: 10,358.19925

Timestep Collection Time: 2.28980
Timestep Consumption Time: 2.54038
PPO Batch Consumption Time: 0.28959
Total Iteration Time: 4.83018

Cumulative Model Updates: 101,746
Cumulative Timesteps: 848,433,856

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 848433856...
Checkpoint 848433856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 209,814.90847
Policy Entropy: 3.70175
Value Function Loss: 0.02480

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.14830
Policy Update Magnitude: 0.38443
Value Function Update Magnitude: 0.40839

Collected Steps per Second: 21,418.39615
Overall Steps per Second: 10,262.23023

Timestep Collection Time: 2.33500
Timestep Consumption Time: 2.53840
PPO Batch Consumption Time: 0.29119
Total Iteration Time: 4.87340

Cumulative Model Updates: 101,752
Cumulative Timesteps: 848,483,868

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 209,814.90847
Policy Entropy: 3.68308
Value Function Loss: 0.02569

Mean KL Divergence: 0.01077
SB3 Clip Fraction: 0.15055
Policy Update Magnitude: 0.40244
Value Function Update Magnitude: 0.46763

Collected Steps per Second: 21,411.94517
Overall Steps per Second: 10,203.51084

Timestep Collection Time: 2.33589
Timestep Consumption Time: 2.56595
PPO Batch Consumption Time: 0.29816
Total Iteration Time: 4.90184

Cumulative Model Updates: 101,758
Cumulative Timesteps: 848,533,884

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 848533884...
Checkpoint 848533884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 209,814.90847
Policy Entropy: 3.68659
Value Function Loss: 0.02460

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.14898
Policy Update Magnitude: 0.38913
Value Function Update Magnitude: 0.42958

Collected Steps per Second: 21,436.27226
Overall Steps per Second: 10,241.92555

Timestep Collection Time: 2.33250
Timestep Consumption Time: 2.54940
PPO Batch Consumption Time: 0.29583
Total Iteration Time: 4.88189

Cumulative Model Updates: 101,764
Cumulative Timesteps: 848,583,884

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 209,814.90847
Policy Entropy: 3.68464
Value Function Loss: 0.02586

Mean KL Divergence: 0.01060
SB3 Clip Fraction: 0.15093
Policy Update Magnitude: 0.38598
Value Function Update Magnitude: 0.36420

Collected Steps per Second: 22,183.23952
Overall Steps per Second: 10,415.44975

Timestep Collection Time: 2.25468
Timestep Consumption Time: 2.54742
PPO Batch Consumption Time: 0.29717
Total Iteration Time: 4.80210

Cumulative Model Updates: 101,770
Cumulative Timesteps: 848,633,900

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 848633900...
Checkpoint 848633900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 209,814.90847
Policy Entropy: 3.67753
Value Function Loss: 0.02812

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.14620
Policy Update Magnitude: 0.40347
Value Function Update Magnitude: 0.37095

Collected Steps per Second: 21,652.25499
Overall Steps per Second: 10,375.78894

Timestep Collection Time: 2.31043
Timestep Consumption Time: 2.51099
PPO Batch Consumption Time: 0.28813
Total Iteration Time: 4.82142

Cumulative Model Updates: 101,776
Cumulative Timesteps: 848,683,926

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 209,814.90847
Policy Entropy: 3.67886
Value Function Loss: 0.02729

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.14667
Policy Update Magnitude: 0.43377
Value Function Update Magnitude: 0.39833

Collected Steps per Second: 20,952.31576
Overall Steps per Second: 10,276.87947

Timestep Collection Time: 2.38713
Timestep Consumption Time: 2.47971
PPO Batch Consumption Time: 0.29706
Total Iteration Time: 4.86685

Cumulative Model Updates: 101,782
Cumulative Timesteps: 848,733,942

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 848733942...
Checkpoint 848733942 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 241,450.27266
Policy Entropy: 3.67446
Value Function Loss: 0.02733

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.14494
Policy Update Magnitude: 0.40654
Value Function Update Magnitude: 0.40342

Collected Steps per Second: 20,989.44030
Overall Steps per Second: 10,416.47636

Timestep Collection Time: 2.38234
Timestep Consumption Time: 2.41813
PPO Batch Consumption Time: 0.28815
Total Iteration Time: 4.80047

Cumulative Model Updates: 101,788
Cumulative Timesteps: 848,783,946

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84,201.78408
Policy Entropy: 3.67693
Value Function Loss: 0.02472

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.13908
Policy Update Magnitude: 0.38487
Value Function Update Magnitude: 0.44764

Collected Steps per Second: 20,565.36705
Overall Steps per Second: 9,994.25819

Timestep Collection Time: 2.43156
Timestep Consumption Time: 2.57191
PPO Batch Consumption Time: 0.30200
Total Iteration Time: 5.00347

Cumulative Model Updates: 101,794
Cumulative Timesteps: 848,833,952

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 848833952...
Checkpoint 848833952 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84,201.78408
Policy Entropy: 3.67552
Value Function Loss: 0.02541

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.14624
Policy Update Magnitude: 0.40064
Value Function Update Magnitude: 0.53061

Collected Steps per Second: 21,998.26438
Overall Steps per Second: 10,339.59771

Timestep Collection Time: 2.27354
Timestep Consumption Time: 2.56359
PPO Batch Consumption Time: 0.29609
Total Iteration Time: 4.83713

Cumulative Model Updates: 101,800
Cumulative Timesteps: 848,883,966

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84,201.78408
Policy Entropy: 3.67897
Value Function Loss: 0.02390

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.14344
Policy Update Magnitude: 0.42058
Value Function Update Magnitude: 0.51697

Collected Steps per Second: 21,563.98997
Overall Steps per Second: 10,391.98174

Timestep Collection Time: 2.31896
Timestep Consumption Time: 2.49302
PPO Batch Consumption Time: 0.28832
Total Iteration Time: 4.81198

Cumulative Model Updates: 101,806
Cumulative Timesteps: 848,933,972

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 848933972...
Checkpoint 848933972 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84,201.78408
Policy Entropy: 3.67500
Value Function Loss: 0.02591

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.14265
Policy Update Magnitude: 0.45576
Value Function Update Magnitude: 0.51707

Collected Steps per Second: 21,245.27041
Overall Steps per Second: 10,300.47134

Timestep Collection Time: 2.35375
Timestep Consumption Time: 2.50098
PPO Batch Consumption Time: 0.28647
Total Iteration Time: 4.85473

Cumulative Model Updates: 101,812
Cumulative Timesteps: 848,983,978

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84,201.78408
Policy Entropy: 3.68092
Value Function Loss: 0.02397

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.14008
Policy Update Magnitude: 0.47143
Value Function Update Magnitude: 0.54058

Collected Steps per Second: 21,894.29462
Overall Steps per Second: 10,431.16569

Timestep Collection Time: 2.28470
Timestep Consumption Time: 2.51073
PPO Batch Consumption Time: 0.28798
Total Iteration Time: 4.79544

Cumulative Model Updates: 101,818
Cumulative Timesteps: 849,034,000

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 849034000...
Checkpoint 849034000 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84,201.78408
Policy Entropy: 3.67177
Value Function Loss: 0.02500

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.14124
Policy Update Magnitude: 0.43645
Value Function Update Magnitude: 0.49416

Collected Steps per Second: 21,044.17611
Overall Steps per Second: 10,252.73773

Timestep Collection Time: 2.37728
Timestep Consumption Time: 2.50219
PPO Batch Consumption Time: 0.28971
Total Iteration Time: 4.87948

Cumulative Model Updates: 101,824
Cumulative Timesteps: 849,084,028

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84,201.78408
Policy Entropy: 3.67850
Value Function Loss: 0.02289

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.14172
Policy Update Magnitude: 0.38682
Value Function Update Magnitude: 0.39090

Collected Steps per Second: 21,620.49894
Overall Steps per Second: 10,348.44725

Timestep Collection Time: 2.31299
Timestep Consumption Time: 2.51943
PPO Batch Consumption Time: 0.28833
Total Iteration Time: 4.83242

Cumulative Model Updates: 101,830
Cumulative Timesteps: 849,134,036

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 849134036...
Checkpoint 849134036 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 188,904.24985
Policy Entropy: 3.67049
Value Function Loss: 0.02582

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.14597
Policy Update Magnitude: 0.38957
Value Function Update Magnitude: 0.36787

Collected Steps per Second: 21,724.07643
Overall Steps per Second: 10,269.18986

Timestep Collection Time: 2.30215
Timestep Consumption Time: 2.56796
PPO Batch Consumption Time: 0.29835
Total Iteration Time: 4.87010

Cumulative Model Updates: 101,836
Cumulative Timesteps: 849,184,048

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 391,521.25410
Policy Entropy: 3.67021
Value Function Loss: 0.02774

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.14226
Policy Update Magnitude: 0.43885
Value Function Update Magnitude: 0.44280

Collected Steps per Second: 21,767.73165
Overall Steps per Second: 10,398.16450

Timestep Collection Time: 2.29771
Timestep Consumption Time: 2.51237
PPO Batch Consumption Time: 0.28801
Total Iteration Time: 4.81008

Cumulative Model Updates: 101,842
Cumulative Timesteps: 849,234,064

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 849234064...
Checkpoint 849234064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 391,521.25410
Policy Entropy: 3.67319
Value Function Loss: 0.02644

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.15225
Policy Update Magnitude: 0.45246
Value Function Update Magnitude: 0.54880

Collected Steps per Second: 21,778.55815
Overall Steps per Second: 10,300.19809

Timestep Collection Time: 2.29639
Timestep Consumption Time: 2.55905
PPO Batch Consumption Time: 0.29801
Total Iteration Time: 4.85544

Cumulative Model Updates: 101,848
Cumulative Timesteps: 849,284,076

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 391,521.25410
Policy Entropy: 3.68193
Value Function Loss: 0.02324

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.14427
Policy Update Magnitude: 0.40344
Value Function Update Magnitude: 0.48911

Collected Steps per Second: 21,285.08668
Overall Steps per Second: 10,198.90059

Timestep Collection Time: 2.34944
Timestep Consumption Time: 2.55384
PPO Batch Consumption Time: 0.29612
Total Iteration Time: 4.90327

Cumulative Model Updates: 101,854
Cumulative Timesteps: 849,334,084

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 849334084...
Checkpoint 849334084 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 391,521.25410
Policy Entropy: 3.67912
Value Function Loss: 0.02303

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.14537
Policy Update Magnitude: 0.36480
Value Function Update Magnitude: 0.42360

Collected Steps per Second: 21,672.29544
Overall Steps per Second: 10,372.86773

Timestep Collection Time: 2.30737
Timestep Consumption Time: 2.51348
PPO Batch Consumption Time: 0.28860
Total Iteration Time: 4.82085

Cumulative Model Updates: 101,860
Cumulative Timesteps: 849,384,090

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 391,521.25410
Policy Entropy: 3.67451
Value Function Loss: 0.02331

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.14475
Policy Update Magnitude: 0.37413
Value Function Update Magnitude: 0.50319

Collected Steps per Second: 21,306.03816
Overall Steps per Second: 10,131.09633

Timestep Collection Time: 2.34732
Timestep Consumption Time: 2.58917
PPO Batch Consumption Time: 0.30057
Total Iteration Time: 4.93648

Cumulative Model Updates: 101,866
Cumulative Timesteps: 849,434,102

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 849434102...
Checkpoint 849434102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 371,463.34926
Policy Entropy: 3.68052
Value Function Loss: 0.02418

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.14415
Policy Update Magnitude: 0.41478
Value Function Update Magnitude: 0.61019

Collected Steps per Second: 21,478.19118
Overall Steps per Second: 10,192.94781

Timestep Collection Time: 2.32859
Timestep Consumption Time: 2.57813
PPO Batch Consumption Time: 0.30173
Total Iteration Time: 4.90673

Cumulative Model Updates: 101,872
Cumulative Timesteps: 849,484,116

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 300,905.43287
Policy Entropy: 3.70389
Value Function Loss: 0.02527

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.14275
Policy Update Magnitude: 0.46926
Value Function Update Magnitude: 0.63070

Collected Steps per Second: 21,005.46606
Overall Steps per Second: 10,403.03011

Timestep Collection Time: 2.38243
Timestep Consumption Time: 2.42809
PPO Batch Consumption Time: 0.28819
Total Iteration Time: 4.81052

Cumulative Model Updates: 101,878
Cumulative Timesteps: 849,534,160

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 849534160...
Checkpoint 849534160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 300,905.43287
Policy Entropy: 3.69865
Value Function Loss: 0.02470

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.15178
Policy Update Magnitude: 0.50856
Value Function Update Magnitude: 0.64846

Collected Steps per Second: 20,588.77238
Overall Steps per Second: 10,240.99963

Timestep Collection Time: 2.42977
Timestep Consumption Time: 2.45510
PPO Batch Consumption Time: 0.29205
Total Iteration Time: 4.88487

Cumulative Model Updates: 101,884
Cumulative Timesteps: 849,584,186

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 269,124.40840
Policy Entropy: 3.68723
Value Function Loss: 0.02882

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.14087
Policy Update Magnitude: 0.50257
Value Function Update Magnitude: 0.65263

Collected Steps per Second: 20,956.43244
Overall Steps per Second: 10,163.68281

Timestep Collection Time: 2.38647
Timestep Consumption Time: 2.53418
PPO Batch Consumption Time: 0.29959
Total Iteration Time: 4.92066

Cumulative Model Updates: 101,890
Cumulative Timesteps: 849,634,198

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 849634198...
Checkpoint 849634198 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 269,124.40840
Policy Entropy: 3.66535
Value Function Loss: 0.03135

Mean KL Divergence: 0.01134
SB3 Clip Fraction: 0.15539
Policy Update Magnitude: 0.54441
Value Function Update Magnitude: 0.53588

Collected Steps per Second: 21,075.15220
Overall Steps per Second: 10,193.22573

Timestep Collection Time: 2.37294
Timestep Consumption Time: 2.53326
PPO Batch Consumption Time: 0.30018
Total Iteration Time: 4.90620

Cumulative Model Updates: 101,896
Cumulative Timesteps: 849,684,208

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 238,652.27905
Policy Entropy: 3.66868
Value Function Loss: 0.03581

Mean KL Divergence: 0.01098
SB3 Clip Fraction: 0.14959
Policy Update Magnitude: 0.56537
Value Function Update Magnitude: 0.51329

Collected Steps per Second: 21,248.74265
Overall Steps per Second: 10,324.03063

Timestep Collection Time: 2.35346
Timestep Consumption Time: 2.49039
PPO Batch Consumption Time: 0.28826
Total Iteration Time: 4.84384

Cumulative Model Updates: 101,902
Cumulative Timesteps: 849,734,216

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 849734216...
Checkpoint 849734216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 697,878.61601
Policy Entropy: 3.66765
Value Function Loss: 0.03748

Mean KL Divergence: 0.01122
SB3 Clip Fraction: 0.14814
Policy Update Magnitude: 0.54445
Value Function Update Magnitude: 0.58681

Collected Steps per Second: 20,751.70055
Overall Steps per Second: 10,137.71227

Timestep Collection Time: 2.41069
Timestep Consumption Time: 2.52395
PPO Batch Consumption Time: 0.28808
Total Iteration Time: 4.93464

Cumulative Model Updates: 101,908
Cumulative Timesteps: 849,784,242

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 547,251.24828
Policy Entropy: 3.67611
Value Function Loss: 0.03869

Mean KL Divergence: 0.01218
SB3 Clip Fraction: 0.15974
Policy Update Magnitude: 0.61990
Value Function Update Magnitude: 0.60256

Collected Steps per Second: 21,569.89659
Overall Steps per Second: 10,232.09606

Timestep Collection Time: 2.32009
Timestep Consumption Time: 2.57080
PPO Batch Consumption Time: 0.29937
Total Iteration Time: 4.89088

Cumulative Model Updates: 101,914
Cumulative Timesteps: 849,834,286

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 849834286...
Checkpoint 849834286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 190,825.46433
Policy Entropy: 3.67026
Value Function Loss: 0.04167

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.14879
Policy Update Magnitude: 0.63922
Value Function Update Magnitude: 0.60910

Collected Steps per Second: 21,190.65024
Overall Steps per Second: 10,136.66362

Timestep Collection Time: 2.36095
Timestep Consumption Time: 2.57460
PPO Batch Consumption Time: 0.30143
Total Iteration Time: 4.93555

Cumulative Model Updates: 101,920
Cumulative Timesteps: 849,884,316

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66,563.37626
Policy Entropy: 3.66990
Value Function Loss: 0.04162

Mean KL Divergence: 0.01070
SB3 Clip Fraction: 0.14541
Policy Update Magnitude: 0.58209
Value Function Update Magnitude: 0.52432

Collected Steps per Second: 21,562.18384
Overall Steps per Second: 10,368.66763

Timestep Collection Time: 2.31925
Timestep Consumption Time: 2.50375
PPO Batch Consumption Time: 0.28817
Total Iteration Time: 4.82299

Cumulative Model Updates: 101,926
Cumulative Timesteps: 849,934,324

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 849934324...
Checkpoint 849934324 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 305,201.55306
Policy Entropy: 3.67414
Value Function Loss: 0.04307

Mean KL Divergence: 0.01115
SB3 Clip Fraction: 0.15159
Policy Update Magnitude: 0.58270
Value Function Update Magnitude: 0.49018

Collected Steps per Second: 21,357.89903
Overall Steps per Second: 10,207.92604

Timestep Collection Time: 2.34208
Timestep Consumption Time: 2.55823
PPO Batch Consumption Time: 0.29461
Total Iteration Time: 4.90031

Cumulative Model Updates: 101,932
Cumulative Timesteps: 849,984,346

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 200,247.58905
Policy Entropy: 3.67157
Value Function Loss: 0.03775

Mean KL Divergence: 0.01115
SB3 Clip Fraction: 0.15005
Policy Update Magnitude: 0.53993
Value Function Update Magnitude: 0.50428

Collected Steps per Second: 22,114.19096
Overall Steps per Second: 10,456.30434

Timestep Collection Time: 2.26099
Timestep Consumption Time: 2.52081
PPO Batch Consumption Time: 0.28915
Total Iteration Time: 4.78180

Cumulative Model Updates: 101,938
Cumulative Timesteps: 850,034,346

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 850034346...
Checkpoint 850034346 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 200,247.58905
Policy Entropy: 3.67198
Value Function Loss: 0.03480

Mean KL Divergence: 0.01125
SB3 Clip Fraction: 0.15444
Policy Update Magnitude: 0.50414
Value Function Update Magnitude: 0.47210

Collected Steps per Second: 20,661.13825
Overall Steps per Second: 10,319.78755

Timestep Collection Time: 2.42078
Timestep Consumption Time: 2.42583
PPO Batch Consumption Time: 0.28763
Total Iteration Time: 4.84661

Cumulative Model Updates: 101,944
Cumulative Timesteps: 850,084,362

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 249,188.45930
Policy Entropy: 3.66699
Value Function Loss: 0.02994

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.15186
Policy Update Magnitude: 0.47514
Value Function Update Magnitude: 0.46507

Collected Steps per Second: 20,852.55481
Overall Steps per Second: 10,338.73417

Timestep Collection Time: 2.39923
Timestep Consumption Time: 2.43986
PPO Batch Consumption Time: 0.28874
Total Iteration Time: 4.83908

Cumulative Model Updates: 101,950
Cumulative Timesteps: 850,134,392

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 850134392...
Checkpoint 850134392 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 249,188.45930
Policy Entropy: 3.66498
Value Function Loss: 0.02737

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.14156
Policy Update Magnitude: 0.45186
Value Function Update Magnitude: 0.48377

Collected Steps per Second: 20,807.83741
Overall Steps per Second: 10,292.65472

Timestep Collection Time: 2.40496
Timestep Consumption Time: 2.45695
PPO Batch Consumption Time: 0.29437
Total Iteration Time: 4.86191

Cumulative Model Updates: 101,956
Cumulative Timesteps: 850,184,434

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 249,188.45930
Policy Entropy: 3.67912
Value Function Loss: 0.02301

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.14885
Policy Update Magnitude: 0.43332
Value Function Update Magnitude: 0.43663

Collected Steps per Second: 21,226.11346
Overall Steps per Second: 10,235.74052

Timestep Collection Time: 2.35747
Timestep Consumption Time: 2.53128
PPO Batch Consumption Time: 0.29543
Total Iteration Time: 4.88875

Cumulative Model Updates: 101,962
Cumulative Timesteps: 850,234,474

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 850234474...
Checkpoint 850234474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 249,188.45930
Policy Entropy: 3.67154
Value Function Loss: 0.02386

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.14547
Policy Update Magnitude: 0.41696
Value Function Update Magnitude: 0.41762

Collected Steps per Second: 21,485.38663
Overall Steps per Second: 10,378.54790

Timestep Collection Time: 2.32819
Timestep Consumption Time: 2.49156
PPO Batch Consumption Time: 0.28795
Total Iteration Time: 4.81975

Cumulative Model Updates: 101,968
Cumulative Timesteps: 850,284,496

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 390,071.97060
Policy Entropy: 3.68959
Value Function Loss: 0.02455

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.15046
Policy Update Magnitude: 0.42475
Value Function Update Magnitude: 0.56325

Collected Steps per Second: 21,533.49181
Overall Steps per Second: 10,228.30078

Timestep Collection Time: 2.32299
Timestep Consumption Time: 2.56756
PPO Batch Consumption Time: 0.30272
Total Iteration Time: 4.89055

Cumulative Model Updates: 101,974
Cumulative Timesteps: 850,334,518

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 850334518...
Checkpoint 850334518 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 136,017.47695
Policy Entropy: 3.68011
Value Function Loss: 0.02633

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.14750
Policy Update Magnitude: 0.44369
Value Function Update Magnitude: 0.72141

Collected Steps per Second: 21,603.20027
Overall Steps per Second: 10,381.39780

Timestep Collection Time: 2.31623
Timestep Consumption Time: 2.50374
PPO Batch Consumption Time: 0.28808
Total Iteration Time: 4.81997

Cumulative Model Updates: 101,980
Cumulative Timesteps: 850,384,556

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 136,017.47695
Policy Entropy: 3.68510
Value Function Loss: 0.02550

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.14458
Policy Update Magnitude: 0.44392
Value Function Update Magnitude: 0.74234

Collected Steps per Second: 21,795.89472
Overall Steps per Second: 10,339.40005

Timestep Collection Time: 2.29419
Timestep Consumption Time: 2.54206
PPO Batch Consumption Time: 0.29573
Total Iteration Time: 4.83626

Cumulative Model Updates: 101,986
Cumulative Timesteps: 850,434,560

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 850434560...
Checkpoint 850434560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 136,017.47695
Policy Entropy: 3.67383
Value Function Loss: 0.02328

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.14431
Policy Update Magnitude: 0.43023
Value Function Update Magnitude: 0.71671

Collected Steps per Second: 21,751.28924
Overall Steps per Second: 10,420.58423

Timestep Collection Time: 2.29982
Timestep Consumption Time: 2.50068
PPO Batch Consumption Time: 0.28786
Total Iteration Time: 4.80050

Cumulative Model Updates: 101,992
Cumulative Timesteps: 850,484,584

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 136,017.47695
Policy Entropy: 3.69000
Value Function Loss: 0.02285

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.14664
Policy Update Magnitude: 0.41624
Value Function Update Magnitude: 0.56769

Collected Steps per Second: 21,827.30516
Overall Steps per Second: 10,422.79223

Timestep Collection Time: 2.29071
Timestep Consumption Time: 2.50647
PPO Batch Consumption Time: 0.28774
Total Iteration Time: 4.79718

Cumulative Model Updates: 101,998
Cumulative Timesteps: 850,534,584

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 850534584...
Checkpoint 850534584 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 136,017.47695
Policy Entropy: 3.67330
Value Function Loss: 0.02480

Mean KL Divergence: 0.01130
SB3 Clip Fraction: 0.15647
Policy Update Magnitude: 0.41686
Value Function Update Magnitude: 0.44328

Collected Steps per Second: 21,498.64380
Overall Steps per Second: 10,268.08048

Timestep Collection Time: 2.32573
Timestep Consumption Time: 2.54373
PPO Batch Consumption Time: 0.29550
Total Iteration Time: 4.86946

Cumulative Model Updates: 102,004
Cumulative Timesteps: 850,584,584

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 136,017.47695
Policy Entropy: 3.67500
Value Function Loss: 0.02809

Mean KL Divergence: 0.01080
SB3 Clip Fraction: 0.15011
Policy Update Magnitude: 0.39941
Value Function Update Magnitude: 0.37606

Collected Steps per Second: 22,021.30096
Overall Steps per Second: 10,470.94707

Timestep Collection Time: 2.27144
Timestep Consumption Time: 2.50559
PPO Batch Consumption Time: 0.28970
Total Iteration Time: 4.77703

Cumulative Model Updates: 102,010
Cumulative Timesteps: 850,634,604

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 850634604...
Checkpoint 850634604 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 136,017.47695
Policy Entropy: 3.65679
Value Function Loss: 0.03697

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.14882
Policy Update Magnitude: 0.39673
Value Function Update Magnitude: 0.38215

Collected Steps per Second: 21,528.88645
Overall Steps per Second: 10,231.57520

Timestep Collection Time: 2.32478
Timestep Consumption Time: 2.56694
PPO Batch Consumption Time: 0.30180
Total Iteration Time: 4.89172

Cumulative Model Updates: 102,016
Cumulative Timesteps: 850,684,654

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 136,017.47695
Policy Entropy: 3.66645
Value Function Loss: 0.03481

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.13959
Policy Update Magnitude: 0.48938
Value Function Update Magnitude: 0.33443

Collected Steps per Second: 21,121.54518
Overall Steps per Second: 10,381.83359

Timestep Collection Time: 2.36867
Timestep Consumption Time: 2.45032
PPO Batch Consumption Time: 0.28905
Total Iteration Time: 4.81899

Cumulative Model Updates: 102,022
Cumulative Timesteps: 850,734,684

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 850734684...
Checkpoint 850734684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 173,461.50317
Policy Entropy: 3.68622
Value Function Loss: 0.03359

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.12349
Policy Update Magnitude: 0.53289
Value Function Update Magnitude: 0.31837

Collected Steps per Second: 20,645.30489
Overall Steps per Second: 10,227.61808

Timestep Collection Time: 2.42244
Timestep Consumption Time: 2.46746
PPO Batch Consumption Time: 0.29198
Total Iteration Time: 4.88990

Cumulative Model Updates: 102,028
Cumulative Timesteps: 850,784,696

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 173,461.50317
Policy Entropy: 3.69228
Value Function Loss: 0.02370

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.12783
Policy Update Magnitude: 0.49195
Value Function Update Magnitude: 0.45455

Collected Steps per Second: 20,973.31057
Overall Steps per Second: 10,162.17314

Timestep Collection Time: 2.38455
Timestep Consumption Time: 2.53683
PPO Batch Consumption Time: 0.29737
Total Iteration Time: 4.92139

Cumulative Model Updates: 102,034
Cumulative Timesteps: 850,834,708

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 850834708...
Checkpoint 850834708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 173,461.50317
Policy Entropy: 3.66751
Value Function Loss: 0.02834

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.12636
Policy Update Magnitude: 0.47648
Value Function Update Magnitude: 0.58192

Collected Steps per Second: 21,042.55572
Overall Steps per Second: 10,147.31173

Timestep Collection Time: 2.37671
Timestep Consumption Time: 2.55189
PPO Batch Consumption Time: 0.30032
Total Iteration Time: 4.92860

Cumulative Model Updates: 102,040
Cumulative Timesteps: 850,884,720

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 173,461.50317
Policy Entropy: 3.65041
Value Function Loss: 0.02605

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.13849
Policy Update Magnitude: 0.52990
Value Function Update Magnitude: 0.57308

Collected Steps per Second: 21,837.33733
Overall Steps per Second: 10,319.70730

Timestep Collection Time: 2.29057
Timestep Consumption Time: 2.55646
PPO Batch Consumption Time: 0.30004
Total Iteration Time: 4.84704

Cumulative Model Updates: 102,046
Cumulative Timesteps: 850,934,740

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 850934740...
Checkpoint 850934740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 173,461.50317
Policy Entropy: 3.65190
Value Function Loss: 0.02619

Mean KL Divergence: 0.01206
SB3 Clip Fraction: 0.15151
Policy Update Magnitude: 0.54031
Value Function Update Magnitude: 0.51657

Collected Steps per Second: 21,475.90780
Overall Steps per Second: 10,143.98030

Timestep Collection Time: 2.32856
Timestep Consumption Time: 2.60126
PPO Batch Consumption Time: 0.30374
Total Iteration Time: 4.92982

Cumulative Model Updates: 102,052
Cumulative Timesteps: 850,984,748

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 173,461.50317
Policy Entropy: 3.69694
Value Function Loss: 0.02352

Mean KL Divergence: 0.01572
SB3 Clip Fraction: 0.17704
Policy Update Magnitude: 0.49137
Value Function Update Magnitude: 0.45777

Collected Steps per Second: 21,912.37730
Overall Steps per Second: 10,368.94859

Timestep Collection Time: 2.28282
Timestep Consumption Time: 2.54139
PPO Batch Consumption Time: 0.29620
Total Iteration Time: 4.82421

Cumulative Model Updates: 102,058
Cumulative Timesteps: 851,034,770

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 851034770...
Checkpoint 851034770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 190,528.33748
Policy Entropy: 3.70799
Value Function Loss: 0.02938

Mean KL Divergence: 0.01374
SB3 Clip Fraction: 0.16276
Policy Update Magnitude: 0.52717
Value Function Update Magnitude: 0.39008

Collected Steps per Second: 21,411.19171
Overall Steps per Second: 10,339.41781

Timestep Collection Time: 2.33597
Timestep Consumption Time: 2.50144
PPO Batch Consumption Time: 0.28764
Total Iteration Time: 4.83741

Cumulative Model Updates: 102,064
Cumulative Timesteps: 851,084,786

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 190,528.33748
Policy Entropy: 3.71901
Value Function Loss: 0.02765

Mean KL Divergence: 0.01268
SB3 Clip Fraction: 0.15377
Policy Update Magnitude: 0.58190
Value Function Update Magnitude: 0.44082

Collected Steps per Second: 21,783.75865
Overall Steps per Second: 10,274.90317

Timestep Collection Time: 2.29602
Timestep Consumption Time: 2.57176
PPO Batch Consumption Time: 0.29952
Total Iteration Time: 4.86778

Cumulative Model Updates: 102,070
Cumulative Timesteps: 851,134,802

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 851134802...
Checkpoint 851134802 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 426,771.23513
Policy Entropy: 3.70295
Value Function Loss: 0.03347

Mean KL Divergence: 0.01581
SB3 Clip Fraction: 0.18975
Policy Update Magnitude: 0.58515
Value Function Update Magnitude: 0.44488

Collected Steps per Second: 21,537.84724
Overall Steps per Second: 10,374.49406

Timestep Collection Time: 2.32261
Timestep Consumption Time: 2.49922
PPO Batch Consumption Time: 0.28836
Total Iteration Time: 4.82183

Cumulative Model Updates: 102,076
Cumulative Timesteps: 851,184,826

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 889,337.61480
Policy Entropy: 3.70859
Value Function Loss: 0.02928

Mean KL Divergence: 0.01587
SB3 Clip Fraction: 0.20150
Policy Update Magnitude: 0.50544
Value Function Update Magnitude: 0.52650

Collected Steps per Second: 21,861.96154
Overall Steps per Second: 10,337.06415

Timestep Collection Time: 2.28753
Timestep Consumption Time: 2.55040
PPO Batch Consumption Time: 0.29631
Total Iteration Time: 4.83793

Cumulative Model Updates: 102,082
Cumulative Timesteps: 851,234,836

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 851234836...
Checkpoint 851234836 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 310,108.36705
Policy Entropy: 3.68753
Value Function Loss: 0.04039

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.13349
Policy Update Magnitude: 0.51891
Value Function Update Magnitude: 0.48450

Collected Steps per Second: 21,574.72472
Overall Steps per Second: 10,360.66907

Timestep Collection Time: 2.31984
Timestep Consumption Time: 2.51092
PPO Batch Consumption Time: 0.28793
Total Iteration Time: 4.83077

Cumulative Model Updates: 102,088
Cumulative Timesteps: 851,284,886

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 251,194.82516
Policy Entropy: 3.67873
Value Function Loss: 0.03908

Mean KL Divergence: 0.01262
SB3 Clip Fraction: 0.17234
Policy Update Magnitude: 0.53428
Value Function Update Magnitude: 0.44130

Collected Steps per Second: 21,672.03876
Overall Steps per Second: 10,303.33410

Timestep Collection Time: 2.30878
Timestep Consumption Time: 2.54751
PPO Batch Consumption Time: 0.29659
Total Iteration Time: 4.85629

Cumulative Model Updates: 102,094
Cumulative Timesteps: 851,334,922

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 851334922...
Checkpoint 851334922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 251,194.82516
Policy Entropy: 3.64889
Value Function Loss: 0.04100

Mean KL Divergence: 0.03116
SB3 Clip Fraction: 0.30456
Policy Update Magnitude: 0.52622
Value Function Update Magnitude: 0.42577

Collected Steps per Second: 20,907.23484
Overall Steps per Second: 10,366.77725

Timestep Collection Time: 2.39161
Timestep Consumption Time: 2.43168
PPO Batch Consumption Time: 0.28771
Total Iteration Time: 4.82329

Cumulative Model Updates: 102,100
Cumulative Timesteps: 851,384,924

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 698,265.16264
Policy Entropy: 3.66994
Value Function Loss: 0.05226

Mean KL Divergence: 0.02466
SB3 Clip Fraction: 0.24540
Policy Update Magnitude: 0.57278
Value Function Update Magnitude: 0.43435

Collected Steps per Second: 20,626.37337
Overall Steps per Second: 10,144.71588

Timestep Collection Time: 2.42437
Timestep Consumption Time: 2.50489
PPO Batch Consumption Time: 0.30210
Total Iteration Time: 4.92927

Cumulative Model Updates: 102,106
Cumulative Timesteps: 851,434,930

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 851434930...
Checkpoint 851434930 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 517,034.05430
Policy Entropy: 3.70758
Value Function Loss: 0.06086

Mean KL Divergence: 0.01807
SB3 Clip Fraction: 0.19523
Policy Update Magnitude: 0.82249
Value Function Update Magnitude: 0.62206

Collected Steps per Second: 20,570.61616
Overall Steps per Second: 10,200.28909

Timestep Collection Time: 2.43085
Timestep Consumption Time: 2.47137
PPO Batch Consumption Time: 0.29024
Total Iteration Time: 4.90221

Cumulative Model Updates: 102,112
Cumulative Timesteps: 851,484,934

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,624.69996
Policy Entropy: 3.75308
Value Function Loss: 0.06817

Mean KL Divergence: 0.01336
SB3 Clip Fraction: 0.16002
Policy Update Magnitude: 1.05510
Value Function Update Magnitude: 0.82995

Collected Steps per Second: 20,643.30471
Overall Steps per Second: 10,219.21121

Timestep Collection Time: 2.42277
Timestep Consumption Time: 2.47134
PPO Batch Consumption Time: 0.29533
Total Iteration Time: 4.89412

Cumulative Model Updates: 102,118
Cumulative Timesteps: 851,534,948

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 851534948...
Checkpoint 851534948 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,722.36978
Policy Entropy: 3.79009
Value Function Loss: 0.06542

Mean KL Divergence: 0.01160
SB3 Clip Fraction: 0.13941
Policy Update Magnitude: 1.19365
Value Function Update Magnitude: 0.84566

Collected Steps per Second: 20,872.99140
Overall Steps per Second: 10,174.05389

Timestep Collection Time: 2.39669
Timestep Consumption Time: 2.52033
PPO Batch Consumption Time: 0.30358
Total Iteration Time: 4.91702

Cumulative Model Updates: 102,124
Cumulative Timesteps: 851,584,974

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,046.95094
Policy Entropy: 3.80037
Value Function Loss: 0.06167

Mean KL Divergence: 0.01179
SB3 Clip Fraction: 0.14066
Policy Update Magnitude: 1.09891
Value Function Update Magnitude: 0.89650

Collected Steps per Second: 21,186.21899
Overall Steps per Second: 10,246.27362

Timestep Collection Time: 2.36050
Timestep Consumption Time: 2.52030
PPO Batch Consumption Time: 0.28650
Total Iteration Time: 4.88080

Cumulative Model Updates: 102,130
Cumulative Timesteps: 851,634,984

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 851634984...
Checkpoint 851634984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,627.78157
Policy Entropy: 3.82483
Value Function Loss: 0.05700

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.11291
Policy Update Magnitude: 1.12285
Value Function Update Magnitude: 0.98941

Collected Steps per Second: 21,199.16048
Overall Steps per Second: 10,316.46552

Timestep Collection Time: 2.35953
Timestep Consumption Time: 2.48903
PPO Batch Consumption Time: 0.28666
Total Iteration Time: 4.84856

Cumulative Model Updates: 102,136
Cumulative Timesteps: 851,685,004

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70.52547
Policy Entropy: 3.82719
Value Function Loss: 0.05513

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.11382
Policy Update Magnitude: 1.22879
Value Function Update Magnitude: 0.85233

Collected Steps per Second: 21,470.85162
Overall Steps per Second: 10,315.10793

Timestep Collection Time: 2.32995
Timestep Consumption Time: 2.51983
PPO Batch Consumption Time: 0.28861
Total Iteration Time: 4.84978

Cumulative Model Updates: 102,142
Cumulative Timesteps: 851,735,030

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 851735030...
Checkpoint 851735030 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,718.43027
Policy Entropy: 3.82482
Value Function Loss: 0.05801

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.10333
Policy Update Magnitude: 1.17264
Value Function Update Magnitude: 0.74942

Collected Steps per Second: 21,139.81253
Overall Steps per Second: 10,320.37021

Timestep Collection Time: 2.36568
Timestep Consumption Time: 2.48008
PPO Batch Consumption Time: 0.29829
Total Iteration Time: 4.84576

Cumulative Model Updates: 102,148
Cumulative Timesteps: 851,785,040

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,541.55533
Policy Entropy: 3.81086
Value Function Loss: 0.05525

Mean KL Divergence: 0.00720
SB3 Clip Fraction: 0.08824
Policy Update Magnitude: 1.11643
Value Function Update Magnitude: 0.64442

Collected Steps per Second: 20,678.22887
Overall Steps per Second: 10,202.70146

Timestep Collection Time: 2.41820
Timestep Consumption Time: 2.48286
PPO Batch Consumption Time: 0.29764
Total Iteration Time: 4.90105

Cumulative Model Updates: 102,154
Cumulative Timesteps: 851,835,044

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 851835044...
Checkpoint 851835044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 80.25989
Policy Entropy: 3.80017
Value Function Loss: 0.04848

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.10518
Policy Update Magnitude: 1.00748
Value Function Update Magnitude: 0.63308

Collected Steps per Second: 21,070.65237
Overall Steps per Second: 10,406.72214

Timestep Collection Time: 2.37363
Timestep Consumption Time: 2.43230
PPO Batch Consumption Time: 0.28864
Total Iteration Time: 4.80593

Cumulative Model Updates: 102,160
Cumulative Timesteps: 851,885,058

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 156.55182
Policy Entropy: 3.77688
Value Function Loss: 0.03860

Mean KL Divergence: 0.02360
SB3 Clip Fraction: 0.25855
Policy Update Magnitude: 0.77070
Value Function Update Magnitude: 0.69820

Collected Steps per Second: 21,217.71922
Overall Steps per Second: 10,442.93362

Timestep Collection Time: 2.35690
Timestep Consumption Time: 2.43179
PPO Batch Consumption Time: 0.28773
Total Iteration Time: 4.78869

Cumulative Model Updates: 102,166
Cumulative Timesteps: 851,935,066

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 851935066...
Checkpoint 851935066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,513.97330
Policy Entropy: 3.75321
Value Function Loss: 0.04258

Mean KL Divergence: 0.02404
SB3 Clip Fraction: 0.26608
Policy Update Magnitude: 0.54015
Value Function Update Magnitude: 0.87679

Collected Steps per Second: 20,671.39155
Overall Steps per Second: 10,277.84548

Timestep Collection Time: 2.41909
Timestep Consumption Time: 2.44632
PPO Batch Consumption Time: 0.29187
Total Iteration Time: 4.86542

Cumulative Model Updates: 102,172
Cumulative Timesteps: 851,985,072

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45,403.38759
Policy Entropy: 3.76740
Value Function Loss: 0.05300

Mean KL Divergence: 0.02317
SB3 Clip Fraction: 0.24864
Policy Update Magnitude: 0.54184
Value Function Update Magnitude: 0.83413

Collected Steps per Second: 20,762.95384
Overall Steps per Second: 10,337.72479

Timestep Collection Time: 2.40814
Timestep Consumption Time: 2.42852
PPO Batch Consumption Time: 0.28849
Total Iteration Time: 4.83665

Cumulative Model Updates: 102,178
Cumulative Timesteps: 852,035,072

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 852035072...
Checkpoint 852035072 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,856.47008
Policy Entropy: 3.85777
Value Function Loss: 0.06154

Mean KL Divergence: 0.01345
SB3 Clip Fraction: 0.16383
Policy Update Magnitude: 0.56078
Value Function Update Magnitude: 0.75580

Collected Steps per Second: 21,921.66453
Overall Steps per Second: 10,328.27883

Timestep Collection Time: 2.28112
Timestep Consumption Time: 2.56054
PPO Batch Consumption Time: 0.30234
Total Iteration Time: 4.84166

Cumulative Model Updates: 102,184
Cumulative Timesteps: 852,085,078

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91.81134
Policy Entropy: 3.96482
Value Function Loss: 0.05899

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.10988
Policy Update Magnitude: 0.69467
Value Function Update Magnitude: 0.85385

Collected Steps per Second: 21,227.83795
Overall Steps per Second: 10,186.99691

Timestep Collection Time: 2.35559
Timestep Consumption Time: 2.55302
PPO Batch Consumption Time: 0.29699
Total Iteration Time: 4.90861

Cumulative Model Updates: 102,190
Cumulative Timesteps: 852,135,082

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 852135082...
Checkpoint 852135082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48.28153
Policy Entropy: 3.97150
Value Function Loss: 0.05608

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.10818
Policy Update Magnitude: 0.83776
Value Function Update Magnitude: 0.88461

Collected Steps per Second: 21,642.93426
Overall Steps per Second: 10,383.22903

Timestep Collection Time: 2.31032
Timestep Consumption Time: 2.50534
PPO Batch Consumption Time: 0.28853
Total Iteration Time: 4.81565

Cumulative Model Updates: 102,196
Cumulative Timesteps: 852,185,084

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 273,651.20121
Policy Entropy: 3.92869
Value Function Loss: 0.05442

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.09611
Policy Update Magnitude: 0.85468
Value Function Update Magnitude: 0.79375

Collected Steps per Second: 21,416.74560
Overall Steps per Second: 10,126.15329

Timestep Collection Time: 2.33490
Timestep Consumption Time: 2.60340
PPO Batch Consumption Time: 0.30396
Total Iteration Time: 4.93830

Cumulative Model Updates: 102,202
Cumulative Timesteps: 852,235,090

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 852235090...
Checkpoint 852235090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 207.36897
Policy Entropy: 3.86359
Value Function Loss: 0.05251

Mean KL Divergence: 0.00577
SB3 Clip Fraction: 0.06852
Policy Update Magnitude: 0.97351
Value Function Update Magnitude: 0.87061

Collected Steps per Second: 21,247.74673
Overall Steps per Second: 10,193.60261

Timestep Collection Time: 2.35319
Timestep Consumption Time: 2.55185
PPO Batch Consumption Time: 0.30000
Total Iteration Time: 4.90504

Cumulative Model Updates: 102,208
Cumulative Timesteps: 852,285,090

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 188.34400
Policy Entropy: 3.84525
Value Function Loss: 0.04990

Mean KL Divergence: 0.00586
SB3 Clip Fraction: 0.07214
Policy Update Magnitude: 1.00044
Value Function Update Magnitude: 0.83195

Collected Steps per Second: 21,703.76320
Overall Steps per Second: 10,349.01089

Timestep Collection Time: 2.30476
Timestep Consumption Time: 2.52874
PPO Batch Consumption Time: 0.28948
Total Iteration Time: 4.83351

Cumulative Model Updates: 102,214
Cumulative Timesteps: 852,335,112

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 852335112...
Checkpoint 852335112 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,984.40542
Policy Entropy: 3.84807
Value Function Loss: 0.04563

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.12328
Policy Update Magnitude: 0.85127
Value Function Update Magnitude: 0.71002

Collected Steps per Second: 21,545.40708
Overall Steps per Second: 10,291.88630

Timestep Collection Time: 2.32096
Timestep Consumption Time: 2.53782
PPO Batch Consumption Time: 0.29443
Total Iteration Time: 4.85878

Cumulative Model Updates: 102,220
Cumulative Timesteps: 852,385,118

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 154.06658
Policy Entropy: 3.82438
Value Function Loss: 0.04277

Mean KL Divergence: 0.01497
SB3 Clip Fraction: 0.18880
Policy Update Magnitude: 0.62265
Value Function Update Magnitude: 0.69787

Collected Steps per Second: 21,572.69354
Overall Steps per Second: 10,347.59488

Timestep Collection Time: 2.31793
Timestep Consumption Time: 2.51450
PPO Batch Consumption Time: 0.28805
Total Iteration Time: 4.83243

Cumulative Model Updates: 102,226
Cumulative Timesteps: 852,435,122

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 852435122...
Checkpoint 852435122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34.45484
Policy Entropy: 3.80527
Value Function Loss: 0.03690

Mean KL Divergence: 0.01382
SB3 Clip Fraction: 0.17598
Policy Update Magnitude: 0.52737
Value Function Update Magnitude: 0.69785

Collected Steps per Second: 21,680.79580
Overall Steps per Second: 10,317.80545

Timestep Collection Time: 2.30656
Timestep Consumption Time: 2.54021
PPO Batch Consumption Time: 0.29412
Total Iteration Time: 4.84677

Cumulative Model Updates: 102,232
Cumulative Timesteps: 852,485,130

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,378.63600
Policy Entropy: 3.75973
Value Function Loss: 0.03721

Mean KL Divergence: 0.01122
SB3 Clip Fraction: 0.14791
Policy Update Magnitude: 0.44365
Value Function Update Magnitude: 0.66769

Collected Steps per Second: 21,654.96194
Overall Steps per Second: 10,370.86973

Timestep Collection Time: 2.30968
Timestep Consumption Time: 2.51306
PPO Batch Consumption Time: 0.28866
Total Iteration Time: 4.82274

Cumulative Model Updates: 102,238
Cumulative Timesteps: 852,535,146

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 852535146...
Checkpoint 852535146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,780.18280
Policy Entropy: 3.74673
Value Function Loss: 0.03524

Mean KL Divergence: 0.01082
SB3 Clip Fraction: 0.14925
Policy Update Magnitude: 0.41289
Value Function Update Magnitude: 0.45938

Collected Steps per Second: 20,773.68842
Overall Steps per Second: 10,291.84003

Timestep Collection Time: 2.40737
Timestep Consumption Time: 2.45182
PPO Batch Consumption Time: 0.29307
Total Iteration Time: 4.85919

Cumulative Model Updates: 102,244
Cumulative Timesteps: 852,585,156

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,451.52993
Policy Entropy: 3.71215
Value Function Loss: 0.03828

Mean KL Divergence: 0.01187
SB3 Clip Fraction: 0.16177
Policy Update Magnitude: 0.38938
Value Function Update Magnitude: 0.39015

Collected Steps per Second: 20,785.43131
Overall Steps per Second: 10,345.77488

Timestep Collection Time: 2.40630
Timestep Consumption Time: 2.42814
PPO Batch Consumption Time: 0.28761
Total Iteration Time: 4.83444

Cumulative Model Updates: 102,250
Cumulative Timesteps: 852,635,172

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 852635172...
Checkpoint 852635172 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,662.76868
Policy Entropy: 3.73148
Value Function Loss: 0.03588

Mean KL Divergence: 0.01150
SB3 Clip Fraction: 0.15037
Policy Update Magnitude: 0.40770
Value Function Update Magnitude: 0.46951

Collected Steps per Second: 20,558.69507
Overall Steps per Second: 10,323.62543

Timestep Collection Time: 2.43303
Timestep Consumption Time: 2.41216
PPO Batch Consumption Time: 0.28616
Total Iteration Time: 4.84520

Cumulative Model Updates: 102,256
Cumulative Timesteps: 852,685,192

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,319.13254
Policy Entropy: 3.70284
Value Function Loss: 0.03910

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.13629
Policy Update Magnitude: 0.40953
Value Function Update Magnitude: 0.53443

Collected Steps per Second: 21,153.93922
Overall Steps per Second: 10,173.40833

Timestep Collection Time: 2.36391
Timestep Consumption Time: 2.55145
PPO Batch Consumption Time: 0.29672
Total Iteration Time: 4.91536

Cumulative Model Updates: 102,262
Cumulative Timesteps: 852,735,198

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 852735198...
Checkpoint 852735198 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43,081.95715
Policy Entropy: 3.72513
Value Function Loss: 0.03423

Mean KL Divergence: 0.01084
SB3 Clip Fraction: 0.14474
Policy Update Magnitude: 0.40444
Value Function Update Magnitude: 0.53136

Collected Steps per Second: 21,595.38975
Overall Steps per Second: 10,407.19866

Timestep Collection Time: 2.31614
Timestep Consumption Time: 2.48995
PPO Batch Consumption Time: 0.28878
Total Iteration Time: 4.80610

Cumulative Model Updates: 102,268
Cumulative Timesteps: 852,785,216

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56,498.85231
Policy Entropy: 3.72507
Value Function Loss: 0.03181

Mean KL Divergence: 0.01104
SB3 Clip Fraction: 0.14996
Policy Update Magnitude: 0.39974
Value Function Update Magnitude: 0.61887

Collected Steps per Second: 20,836.72250
Overall Steps per Second: 10,100.77362

Timestep Collection Time: 2.39980
Timestep Consumption Time: 2.55071
PPO Batch Consumption Time: 0.29761
Total Iteration Time: 4.95051

Cumulative Model Updates: 102,274
Cumulative Timesteps: 852,835,220

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 852835220...
Checkpoint 852835220 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,986.53423
Policy Entropy: 3.71901
Value Function Loss: 0.02791

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.13401
Policy Update Magnitude: 0.39248
Value Function Update Magnitude: 0.66896

Collected Steps per Second: 21,281.99752
Overall Steps per Second: 10,233.67100

Timestep Collection Time: 2.35147
Timestep Consumption Time: 2.53866
PPO Batch Consumption Time: 0.29284
Total Iteration Time: 4.89013

Cumulative Model Updates: 102,280
Cumulative Timesteps: 852,885,264

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,630.20142
Policy Entropy: 3.71841
Value Function Loss: 0.02703

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.14001
Policy Update Magnitude: 0.37867
Value Function Update Magnitude: 0.66166

Collected Steps per Second: 20,969.80417
Overall Steps per Second: 10,096.06505

Timestep Collection Time: 2.38467
Timestep Consumption Time: 2.56835
PPO Batch Consumption Time: 0.29982
Total Iteration Time: 4.95302

Cumulative Model Updates: 102,286
Cumulative Timesteps: 852,935,270

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 852935270...
Checkpoint 852935270 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,289.75281
Policy Entropy: 3.69287
Value Function Loss: 0.02891

Mean KL Divergence: 0.01104
SB3 Clip Fraction: 0.15400
Policy Update Magnitude: 0.35689
Value Function Update Magnitude: 0.61775

Collected Steps per Second: 21,674.45663
Overall Steps per Second: 10,256.75430

Timestep Collection Time: 2.30797
Timestep Consumption Time: 2.56921
PPO Batch Consumption Time: 0.29672
Total Iteration Time: 4.87718

Cumulative Model Updates: 102,292
Cumulative Timesteps: 852,985,294

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,922.19477
Policy Entropy: 3.68702
Value Function Loss: 0.03084

Mean KL Divergence: 0.01069
SB3 Clip Fraction: 0.14530
Policy Update Magnitude: 0.37900
Value Function Update Magnitude: 0.74542

Collected Steps per Second: 21,628.22602
Overall Steps per Second: 10,347.67959

Timestep Collection Time: 2.31263
Timestep Consumption Time: 2.52111
PPO Batch Consumption Time: 0.28724
Total Iteration Time: 4.83374

Cumulative Model Updates: 102,298
Cumulative Timesteps: 853,035,312

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 853035312...
Checkpoint 853035312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,282.76275
Policy Entropy: 3.66622
Value Function Loss: 0.03323

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.14378
Policy Update Magnitude: 0.40070
Value Function Update Magnitude: 0.75558

Collected Steps per Second: 21,413.63756
Overall Steps per Second: 10,172.67050

Timestep Collection Time: 2.33496
Timestep Consumption Time: 2.58017
PPO Batch Consumption Time: 0.30054
Total Iteration Time: 4.91513

Cumulative Model Updates: 102,304
Cumulative Timesteps: 853,085,312

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47,334.01292
Policy Entropy: 3.67147
Value Function Loss: 0.03112

Mean KL Divergence: 0.01139
SB3 Clip Fraction: 0.15286
Policy Update Magnitude: 0.40648
Value Function Update Magnitude: 0.69939

Collected Steps per Second: 21,697.88864
Overall Steps per Second: 10,334.46715

Timestep Collection Time: 2.30502
Timestep Consumption Time: 2.53452
PPO Batch Consumption Time: 0.28840
Total Iteration Time: 4.83953

Cumulative Model Updates: 102,310
Cumulative Timesteps: 853,135,326

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 853135326...
Checkpoint 853135326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,339.45446
Policy Entropy: 3.67061
Value Function Loss: 0.03168

Mean KL Divergence: 0.01099
SB3 Clip Fraction: 0.14992
Policy Update Magnitude: 0.42579
Value Function Update Magnitude: 0.65793

Collected Steps per Second: 21,838.24518
Overall Steps per Second: 10,305.66564

Timestep Collection Time: 2.28984
Timestep Consumption Time: 2.56245
PPO Batch Consumption Time: 0.29612
Total Iteration Time: 4.85228

Cumulative Model Updates: 102,316
Cumulative Timesteps: 853,185,332

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,454.17999
Policy Entropy: 3.68654
Value Function Loss: 0.02962

Mean KL Divergence: 0.01106
SB3 Clip Fraction: 0.15072
Policy Update Magnitude: 0.44630
Value Function Update Magnitude: 0.77772

Collected Steps per Second: 21,582.88432
Overall Steps per Second: 10,381.20685

Timestep Collection Time: 2.31832
Timestep Consumption Time: 2.50154
PPO Batch Consumption Time: 0.28768
Total Iteration Time: 4.81986

Cumulative Model Updates: 102,322
Cumulative Timesteps: 853,235,368

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 853235368...
Checkpoint 853235368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,454.17999
Policy Entropy: 3.67875
Value Function Loss: 0.03047

Mean KL Divergence: 0.01098
SB3 Clip Fraction: 0.15234
Policy Update Magnitude: 0.43508
Value Function Update Magnitude: 0.77427

Collected Steps per Second: 21,544.69501
Overall Steps per Second: 10,295.73899

Timestep Collection Time: 2.32131
Timestep Consumption Time: 2.53623
PPO Batch Consumption Time: 0.29439
Total Iteration Time: 4.85754

Cumulative Model Updates: 102,328
Cumulative Timesteps: 853,285,380

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,454.17999
Policy Entropy: 3.68149
Value Function Loss: 0.02901

Mean KL Divergence: 0.01124
SB3 Clip Fraction: 0.15466
Policy Update Magnitude: 0.40964
Value Function Update Magnitude: 0.62998

Collected Steps per Second: 21,661.57170
Overall Steps per Second: 10,351.64784

Timestep Collection Time: 2.30888
Timestep Consumption Time: 2.52262
PPO Batch Consumption Time: 0.28788
Total Iteration Time: 4.83150

Cumulative Model Updates: 102,334
Cumulative Timesteps: 853,335,394

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 853335394...
Checkpoint 853335394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,568.76697
Policy Entropy: 3.67184
Value Function Loss: 0.02919

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.14933
Policy Update Magnitude: 0.40658
Value Function Update Magnitude: 0.60304

Collected Steps per Second: 21,449.88623
Overall Steps per Second: 10,269.25317

Timestep Collection Time: 2.33195
Timestep Consumption Time: 2.53890
PPO Batch Consumption Time: 0.29215
Total Iteration Time: 4.87085

Cumulative Model Updates: 102,340
Cumulative Timesteps: 853,385,414

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,470.26711
Policy Entropy: 3.69741
Value Function Loss: 0.02842

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.14274
Policy Update Magnitude: 0.45420
Value Function Update Magnitude: 0.55989

Collected Steps per Second: 21,574.27410
Overall Steps per Second: 10,379.29933

Timestep Collection Time: 2.31822
Timestep Consumption Time: 2.50041
PPO Batch Consumption Time: 0.28777
Total Iteration Time: 4.81863

Cumulative Model Updates: 102,346
Cumulative Timesteps: 853,435,428

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 853435428...
Checkpoint 853435428 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,733.29899
Policy Entropy: 3.71081
Value Function Loss: 0.03149

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.14581
Policy Update Magnitude: 0.49526
Value Function Update Magnitude: 0.57926

Collected Steps per Second: 21,826.38718
Overall Steps per Second: 10,331.60131

Timestep Collection Time: 2.29154
Timestep Consumption Time: 2.54953
PPO Batch Consumption Time: 0.29598
Total Iteration Time: 4.84107

Cumulative Model Updates: 102,352
Cumulative Timesteps: 853,485,444

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,317.79302
Policy Entropy: 3.70635
Value Function Loss: 0.02886

Mean KL Divergence: 0.01116
SB3 Clip Fraction: 0.15157
Policy Update Magnitude: 0.47434
Value Function Update Magnitude: 0.64625

Collected Steps per Second: 21,111.28069
Overall Steps per Second: 10,060.44982

Timestep Collection Time: 2.36859
Timestep Consumption Time: 2.60176
PPO Batch Consumption Time: 0.30733
Total Iteration Time: 4.97035

Cumulative Model Updates: 102,358
Cumulative Timesteps: 853,535,448

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 853535448...
Checkpoint 853535448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,317.79302
Policy Entropy: 3.68887
Value Function Loss: 0.02788

Mean KL Divergence: 0.01092
SB3 Clip Fraction: 0.14878
Policy Update Magnitude: 0.45024
Value Function Update Magnitude: 0.61521

Collected Steps per Second: 21,240.35974
Overall Steps per Second: 10,156.18788

Timestep Collection Time: 2.35542
Timestep Consumption Time: 2.57064
PPO Batch Consumption Time: 0.29698
Total Iteration Time: 4.92606

Cumulative Model Updates: 102,364
Cumulative Timesteps: 853,585,478

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53,456.17890
Policy Entropy: 3.69114
Value Function Loss: 0.02616

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.14728
Policy Update Magnitude: 0.41764
Value Function Update Magnitude: 0.57277

Collected Steps per Second: 21,767.72482
Overall Steps per Second: 10,375.78049

Timestep Collection Time: 2.29781
Timestep Consumption Time: 2.52284
PPO Batch Consumption Time: 0.28934
Total Iteration Time: 4.82065

Cumulative Model Updates: 102,370
Cumulative Timesteps: 853,635,496

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 853635496...
Checkpoint 853635496 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 118,524.26542
Policy Entropy: 3.69702
Value Function Loss: 0.02619

Mean KL Divergence: 0.01058
SB3 Clip Fraction: 0.14432
Policy Update Magnitude: 0.40374
Value Function Update Magnitude: 0.53295

Collected Steps per Second: 20,820.52201
Overall Steps per Second: 10,322.14318

Timestep Collection Time: 2.40282
Timestep Consumption Time: 2.44385
PPO Batch Consumption Time: 0.29193
Total Iteration Time: 4.84667

Cumulative Model Updates: 102,376
Cumulative Timesteps: 853,685,524

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81,884.18540
Policy Entropy: 3.67065
Value Function Loss: 0.02872

Mean KL Divergence: 0.01123
SB3 Clip Fraction: 0.15390
Policy Update Magnitude: 0.40776
Value Function Update Magnitude: 0.57745

Collected Steps per Second: 21,087.53185
Overall Steps per Second: 10,394.36479

Timestep Collection Time: 2.37145
Timestep Consumption Time: 2.43962
PPO Batch Consumption Time: 0.28889
Total Iteration Time: 4.81107

Cumulative Model Updates: 102,382
Cumulative Timesteps: 853,735,532

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 853735532...
Checkpoint 853735532 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43,527.33991
Policy Entropy: 3.67210
Value Function Loss: 0.02987

Mean KL Divergence: 0.01114
SB3 Clip Fraction: 0.15172
Policy Update Magnitude: 0.43906
Value Function Update Magnitude: 0.58915

Collected Steps per Second: 20,385.61449
Overall Steps per Second: 10,227.52594

Timestep Collection Time: 2.45300
Timestep Consumption Time: 2.43635
PPO Batch Consumption Time: 0.28897
Total Iteration Time: 4.88935

Cumulative Model Updates: 102,388
Cumulative Timesteps: 853,785,538

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,334.59701
Policy Entropy: 3.67258
Value Function Loss: 0.03168

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.14390
Policy Update Magnitude: 0.47640
Value Function Update Magnitude: 0.55455

Collected Steps per Second: 20,815.46780
Overall Steps per Second: 10,077.26880

Timestep Collection Time: 2.40302
Timestep Consumption Time: 2.56063
PPO Batch Consumption Time: 0.30144
Total Iteration Time: 4.96365

Cumulative Model Updates: 102,394
Cumulative Timesteps: 853,835,558

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 853835558...
Checkpoint 853835558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 95,292.99768
Policy Entropy: 3.68844
Value Function Loss: 0.03122

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.14436
Policy Update Magnitude: 0.48023
Value Function Update Magnitude: 0.59223

Collected Steps per Second: 21,246.79463
Overall Steps per Second: 10,190.00918

Timestep Collection Time: 2.35433
Timestep Consumption Time: 2.55459
PPO Batch Consumption Time: 0.29734
Total Iteration Time: 4.90893

Cumulative Model Updates: 102,400
Cumulative Timesteps: 853,885,580

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,248.38745
Policy Entropy: 3.67617
Value Function Loss: 0.03149

Mean KL Divergence: 0.01132
SB3 Clip Fraction: 0.15279
Policy Update Magnitude: 0.47134
Value Function Update Magnitude: 0.69809

Collected Steps per Second: 21,481.95058
Overall Steps per Second: 10,368.69382

Timestep Collection Time: 2.32884
Timestep Consumption Time: 2.49607
PPO Batch Consumption Time: 0.28862
Total Iteration Time: 4.82491

Cumulative Model Updates: 102,406
Cumulative Timesteps: 853,935,608

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 853935608...
Checkpoint 853935608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 83,189.58325
Policy Entropy: 3.68390
Value Function Loss: 0.03103

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.14252
Policy Update Magnitude: 0.47914
Value Function Update Magnitude: 0.77201

Collected Steps per Second: 21,091.69842
Overall Steps per Second: 10,256.26137

Timestep Collection Time: 2.37164
Timestep Consumption Time: 2.50557
PPO Batch Consumption Time: 0.28836
Total Iteration Time: 4.87722

Cumulative Model Updates: 102,412
Cumulative Timesteps: 853,985,630

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83,189.58325
Policy Entropy: 3.66906
Value Function Loss: 0.03452

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.13569
Policy Update Magnitude: 0.49083
Value Function Update Magnitude: 0.67000

Collected Steps per Second: 21,236.61433
Overall Steps per Second: 10,106.87514

Timestep Collection Time: 2.35508
Timestep Consumption Time: 2.59343
PPO Batch Consumption Time: 0.30195
Total Iteration Time: 4.94851

Cumulative Model Updates: 102,418
Cumulative Timesteps: 854,035,644

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 854035644...
Checkpoint 854035644 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 160,242.76665
Policy Entropy: 3.67534
Value Function Loss: 0.03259

Mean KL Divergence: 0.01099
SB3 Clip Fraction: 0.14765
Policy Update Magnitude: 0.48657
Value Function Update Magnitude: 0.65295

Collected Steps per Second: 21,398.75527
Overall Steps per Second: 10,196.39553

Timestep Collection Time: 2.33864
Timestep Consumption Time: 2.56937
PPO Batch Consumption Time: 0.29970
Total Iteration Time: 4.90801

Cumulative Model Updates: 102,424
Cumulative Timesteps: 854,085,688

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55,883.59271
Policy Entropy: 3.66093
Value Function Loss: 0.03802

Mean KL Divergence: 0.01133
SB3 Clip Fraction: 0.15141
Policy Update Magnitude: 0.47021
Value Function Update Magnitude: 0.69044

Collected Steps per Second: 21,705.12118
Overall Steps per Second: 10,249.12816

Timestep Collection Time: 2.30545
Timestep Consumption Time: 2.57692
PPO Batch Consumption Time: 0.29697
Total Iteration Time: 4.88237

Cumulative Model Updates: 102,430
Cumulative Timesteps: 854,135,728

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 854135728...
Checkpoint 854135728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,706.79616
Policy Entropy: 3.67350
Value Function Loss: 0.03552

Mean KL Divergence: 0.01112
SB3 Clip Fraction: 0.14899
Policy Update Magnitude: 0.49086
Value Function Update Magnitude: 0.63454

Collected Steps per Second: 21,314.96205
Overall Steps per Second: 10,141.97385

Timestep Collection Time: 2.34708
Timestep Consumption Time: 2.58568
PPO Batch Consumption Time: 0.29857
Total Iteration Time: 4.93277

Cumulative Model Updates: 102,436
Cumulative Timesteps: 854,185,756

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78,733.03888
Policy Entropy: 3.67029
Value Function Loss: 0.03335

Mean KL Divergence: 0.01078
SB3 Clip Fraction: 0.14460
Policy Update Magnitude: 0.50365
Value Function Update Magnitude: 0.76577

Collected Steps per Second: 21,784.30568
Overall Steps per Second: 10,316.76264

Timestep Collection Time: 2.29652
Timestep Consumption Time: 2.55268
PPO Batch Consumption Time: 0.29561
Total Iteration Time: 4.84920

Cumulative Model Updates: 102,442
Cumulative Timesteps: 854,235,784

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 854235784...
Checkpoint 854235784 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 78,733.03888
Policy Entropy: 3.68587
Value Function Loss: 0.03292

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.14304
Policy Update Magnitude: 0.50312
Value Function Update Magnitude: 0.80193

Collected Steps per Second: 21,208.13272
Overall Steps per Second: 10,204.87967

Timestep Collection Time: 2.35891
Timestep Consumption Time: 2.54345
PPO Batch Consumption Time: 0.29460
Total Iteration Time: 4.90236

Cumulative Model Updates: 102,448
Cumulative Timesteps: 854,285,812

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78,733.03888
Policy Entropy: 3.66758
Value Function Loss: 0.03064

Mean KL Divergence: 0.01074
SB3 Clip Fraction: 0.14747
Policy Update Magnitude: 0.46552
Value Function Update Magnitude: 0.78065

Collected Steps per Second: 21,820.10350
Overall Steps per Second: 10,387.85947

Timestep Collection Time: 2.29156
Timestep Consumption Time: 2.52195
PPO Batch Consumption Time: 0.28885
Total Iteration Time: 4.81350

Cumulative Model Updates: 102,454
Cumulative Timesteps: 854,335,814

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 854335814...
Checkpoint 854335814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 78,733.03888
Policy Entropy: 3.67350
Value Function Loss: 0.02542

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.14854
Policy Update Magnitude: 0.44193
Value Function Update Magnitude: 0.78473

Collected Steps per Second: 21,357.19905
Overall Steps per Second: 10,277.36746

Timestep Collection Time: 2.34141
Timestep Consumption Time: 2.52423
PPO Batch Consumption Time: 0.28950
Total Iteration Time: 4.86564

Cumulative Model Updates: 102,460
Cumulative Timesteps: 854,385,820

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78,733.03888
Policy Entropy: 3.66858
Value Function Loss: 0.02324

Mean KL Divergence: 0.01082
SB3 Clip Fraction: 0.14062
Policy Update Magnitude: 0.42330
Value Function Update Magnitude: 0.67581

Collected Steps per Second: 21,601.24311
Overall Steps per Second: 10,365.41959

Timestep Collection Time: 2.31542
Timestep Consumption Time: 2.50985
PPO Batch Consumption Time: 0.28740
Total Iteration Time: 4.82528

Cumulative Model Updates: 102,466
Cumulative Timesteps: 854,435,836

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 854435836...
Checkpoint 854435836 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 227,942.29326
Policy Entropy: 3.68415
Value Function Loss: 0.02347

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.14141
Policy Update Magnitude: 0.41549
Value Function Update Magnitude: 0.66099

Collected Steps per Second: 21,067.62923
Overall Steps per Second: 10,265.82268

Timestep Collection Time: 2.37483
Timestep Consumption Time: 2.49882
PPO Batch Consumption Time: 0.28806
Total Iteration Time: 4.87365

Cumulative Model Updates: 102,472
Cumulative Timesteps: 854,485,868

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 227,942.29326
Policy Entropy: 3.68104
Value Function Loss: 0.02555

Mean KL Divergence: 0.01116
SB3 Clip Fraction: 0.15412
Policy Update Magnitude: 0.39268
Value Function Update Magnitude: 0.55535

Collected Steps per Second: 21,367.66921
Overall Steps per Second: 10,041.09503

Timestep Collection Time: 2.34139
Timestep Consumption Time: 2.64114
PPO Batch Consumption Time: 0.30004
Total Iteration Time: 4.98252

Cumulative Model Updates: 102,478
Cumulative Timesteps: 854,535,898

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 854535898...
Checkpoint 854535898 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 227,942.29326
Policy Entropy: 3.67086
Value Function Loss: 0.02836

Mean KL Divergence: 0.01141
SB3 Clip Fraction: 0.15350
Policy Update Magnitude: 0.39538
Value Function Update Magnitude: 0.51032

Collected Steps per Second: 20,757.82277
Overall Steps per Second: 10,156.88619

Timestep Collection Time: 2.40998
Timestep Consumption Time: 2.51535
PPO Batch Consumption Time: 0.28833
Total Iteration Time: 4.92533

Cumulative Model Updates: 102,484
Cumulative Timesteps: 854,585,924

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 288,580.48636
Policy Entropy: 3.65982
Value Function Loss: 0.02890

Mean KL Divergence: 0.01061
SB3 Clip Fraction: 0.14225
Policy Update Magnitude: 0.47251
Value Function Update Magnitude: 0.66896

Collected Steps per Second: 21,810.41058
Overall Steps per Second: 10,428.88960

Timestep Collection Time: 2.29349
Timestep Consumption Time: 2.50299
PPO Batch Consumption Time: 0.28810
Total Iteration Time: 4.79648

Cumulative Model Updates: 102,490
Cumulative Timesteps: 854,635,946

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 854635946...
Checkpoint 854635946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 269,894.33708
Policy Entropy: 3.64700
Value Function Loss: 0.03217

Mean KL Divergence: 0.01085
SB3 Clip Fraction: 0.14385
Policy Update Magnitude: 0.51543
Value Function Update Magnitude: 0.58490

Collected Steps per Second: 20,628.07879
Overall Steps per Second: 10,316.61208

Timestep Collection Time: 2.42388
Timestep Consumption Time: 2.42267
PPO Batch Consumption Time: 0.28637
Total Iteration Time: 4.84655

Cumulative Model Updates: 102,496
Cumulative Timesteps: 854,685,946

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 94,124.92500
Policy Entropy: 3.67044
Value Function Loss: 0.03550

Mean KL Divergence: 0.01099
SB3 Clip Fraction: 0.14502
Policy Update Magnitude: 0.51644
Value Function Update Magnitude: 0.49055

Collected Steps per Second: 20,990.92068
Overall Steps per Second: 10,355.47268

Timestep Collection Time: 2.38303
Timestep Consumption Time: 2.44746
PPO Batch Consumption Time: 0.28895
Total Iteration Time: 4.83049

Cumulative Model Updates: 102,502
Cumulative Timesteps: 854,735,968

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 854735968...
Checkpoint 854735968 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 56,887.74128
Policy Entropy: 3.67996
Value Function Loss: 0.03591

Mean KL Divergence: 0.01083
SB3 Clip Fraction: 0.14186
Policy Update Magnitude: 0.52138
Value Function Update Magnitude: 0.52095

Collected Steps per Second: 20,823.31512
Overall Steps per Second: 10,034.25940

Timestep Collection Time: 2.40125
Timestep Consumption Time: 2.58188
PPO Batch Consumption Time: 0.30235
Total Iteration Time: 4.98313

Cumulative Model Updates: 102,508
Cumulative Timesteps: 854,785,970

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,848.83997
Policy Entropy: 3.70976
Value Function Loss: 0.03358

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.14153
Policy Update Magnitude: 0.51868
Value Function Update Magnitude: 0.60259

Collected Steps per Second: 21,747.28612
Overall Steps per Second: 10,332.24341

Timestep Collection Time: 2.30061
Timestep Consumption Time: 2.54171
PPO Batch Consumption Time: 0.29688
Total Iteration Time: 4.84232

Cumulative Model Updates: 102,514
Cumulative Timesteps: 854,836,002

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 854836002...
Checkpoint 854836002 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 185,720.62950
Policy Entropy: 3.69919
Value Function Loss: 0.03298

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.13789
Policy Update Magnitude: 0.50493
Value Function Update Magnitude: 0.65444

Collected Steps per Second: 21,320.32925
Overall Steps per Second: 10,232.02889

Timestep Collection Time: 2.34593
Timestep Consumption Time: 2.54225
PPO Batch Consumption Time: 0.30051
Total Iteration Time: 4.88818

Cumulative Model Updates: 102,520
Cumulative Timesteps: 854,886,018

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 185,720.62950
Policy Entropy: 3.71456
Value Function Loss: 0.02962

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.14083
Policy Update Magnitude: 0.50877
Value Function Update Magnitude: 0.64392

Collected Steps per Second: 21,617.55011
Overall Steps per Second: 10,332.23428

Timestep Collection Time: 2.31377
Timestep Consumption Time: 2.52720
PPO Batch Consumption Time: 0.28899
Total Iteration Time: 4.84097

Cumulative Model Updates: 102,526
Cumulative Timesteps: 854,936,036

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 854936036...
Checkpoint 854936036 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 181,631.87296
Policy Entropy: 3.67894
Value Function Loss: 0.03144

Mean KL Divergence: 0.01096
SB3 Clip Fraction: 0.14573
Policy Update Magnitude: 0.50993
Value Function Update Magnitude: 0.62815

Collected Steps per Second: 21,534.99475
Overall Steps per Second: 10,267.18709

Timestep Collection Time: 2.32208
Timestep Consumption Time: 2.54839
PPO Batch Consumption Time: 0.29500
Total Iteration Time: 4.87047

Cumulative Model Updates: 102,532
Cumulative Timesteps: 854,986,042

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 304,188.14911
Policy Entropy: 3.68837
Value Function Loss: 0.03348

Mean KL Divergence: 0.01070
SB3 Clip Fraction: 0.14328
Policy Update Magnitude: 0.51634
Value Function Update Magnitude: 0.54296

Collected Steps per Second: 21,467.07221
Overall Steps per Second: 10,342.26848

Timestep Collection Time: 2.33064
Timestep Consumption Time: 2.50698
PPO Batch Consumption Time: 0.28780
Total Iteration Time: 4.83762

Cumulative Model Updates: 102,538
Cumulative Timesteps: 855,036,074

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 855036074...
Checkpoint 855036074 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 308,988.17850
Policy Entropy: 3.66518
Value Function Loss: 0.03590

Mean KL Divergence: 0.01083
SB3 Clip Fraction: 0.14450
Policy Update Magnitude: 0.52843
Value Function Update Magnitude: 0.62371

Collected Steps per Second: 21,553.60599
Overall Steps per Second: 10,319.71300

Timestep Collection Time: 2.32026
Timestep Consumption Time: 2.52580
PPO Batch Consumption Time: 0.29193
Total Iteration Time: 4.84606

Cumulative Model Updates: 102,544
Cumulative Timesteps: 855,086,084

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 346,563.93524
Policy Entropy: 3.69378
Value Function Loss: 0.03722

Mean KL Divergence: 0.01092
SB3 Clip Fraction: 0.14543
Policy Update Magnitude: 0.53782
Value Function Update Magnitude: 0.60391

Collected Steps per Second: 21,784.61409
Overall Steps per Second: 10,385.84453

Timestep Collection Time: 2.29547
Timestep Consumption Time: 2.51935
PPO Batch Consumption Time: 0.28784
Total Iteration Time: 4.81482

Cumulative Model Updates: 102,550
Cumulative Timesteps: 855,136,090

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 855136090...
Checkpoint 855136090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 120,857.29188
Policy Entropy: 3.69717
Value Function Loss: 0.03265

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.14380
Policy Update Magnitude: 0.50873
Value Function Update Magnitude: 0.67886

Collected Steps per Second: 21,321.96162
Overall Steps per Second: 10,267.25691

Timestep Collection Time: 2.34650
Timestep Consumption Time: 2.52647
PPO Batch Consumption Time: 0.29178
Total Iteration Time: 4.87297

Cumulative Model Updates: 102,556
Cumulative Timesteps: 855,186,122

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,143.08162
Policy Entropy: 3.70543
Value Function Loss: 0.03088

Mean KL Divergence: 0.01078
SB3 Clip Fraction: 0.14782
Policy Update Magnitude: 0.44486
Value Function Update Magnitude: 0.67582

Collected Steps per Second: 21,022.48625
Overall Steps per Second: 10,406.30965

Timestep Collection Time: 2.37907
Timestep Consumption Time: 2.42705
PPO Batch Consumption Time: 0.28785
Total Iteration Time: 4.80612

Cumulative Model Updates: 102,562
Cumulative Timesteps: 855,236,136

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 855236136...
Checkpoint 855236136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,153.79109
Policy Entropy: 3.69604
Value Function Loss: 0.02854

Mean KL Divergence: 0.01077
SB3 Clip Fraction: 0.14440
Policy Update Magnitude: 0.41379
Value Function Update Magnitude: 0.60972

Collected Steps per Second: 20,931.67450
Overall Steps per Second: 10,293.56129

Timestep Collection Time: 2.39083
Timestep Consumption Time: 2.47085
PPO Batch Consumption Time: 0.29679
Total Iteration Time: 4.86168

Cumulative Model Updates: 102,568
Cumulative Timesteps: 855,286,180

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,153.79109
Policy Entropy: 3.69302
Value Function Loss: 0.02839

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.13607
Policy Update Magnitude: 0.41527
Value Function Update Magnitude: 0.58529

Collected Steps per Second: 20,926.94252
Overall Steps per Second: 10,379.78720

Timestep Collection Time: 2.39108
Timestep Consumption Time: 2.42964
PPO Batch Consumption Time: 0.28807
Total Iteration Time: 4.82072

Cumulative Model Updates: 102,574
Cumulative Timesteps: 855,336,218

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 855336218...
Checkpoint 855336218 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,153.79109
Policy Entropy: 3.68058
Value Function Loss: 0.02522

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.14647
Policy Update Magnitude: 0.40858
Value Function Update Magnitude: 0.49974

Collected Steps per Second: 20,845.38708
Overall Steps per Second: 10,238.70805

Timestep Collection Time: 2.39880
Timestep Consumption Time: 2.48502
PPO Batch Consumption Time: 0.28858
Total Iteration Time: 4.88382

Cumulative Model Updates: 102,580
Cumulative Timesteps: 855,386,222

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,153.79109
Policy Entropy: 3.67469
Value Function Loss: 0.02438

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.14130
Policy Update Magnitude: 0.40144
Value Function Update Magnitude: 0.48423

Collected Steps per Second: 21,547.04677
Overall Steps per Second: 10,342.49651

Timestep Collection Time: 2.32134
Timestep Consumption Time: 2.51482
PPO Batch Consumption Time: 0.29036
Total Iteration Time: 4.83616

Cumulative Model Updates: 102,586
Cumulative Timesteps: 855,436,240

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 855436240...
Checkpoint 855436240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,153.79109
Policy Entropy: 3.68433
Value Function Loss: 0.02160

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.13971
Policy Update Magnitude: 0.38015
Value Function Update Magnitude: 0.47512

Collected Steps per Second: 21,512.99523
Overall Steps per Second: 10,399.53732

Timestep Collection Time: 2.32529
Timestep Consumption Time: 2.48492
PPO Batch Consumption Time: 0.28665
Total Iteration Time: 4.81021

Cumulative Model Updates: 102,592
Cumulative Timesteps: 855,486,264

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,153.79109
Policy Entropy: 3.69430
Value Function Loss: 0.02183

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.13605
Policy Update Magnitude: 0.38495
Value Function Update Magnitude: 0.61325

Collected Steps per Second: 21,639.85845
Overall Steps per Second: 10,347.38862

Timestep Collection Time: 2.31157
Timestep Consumption Time: 2.52270
PPO Batch Consumption Time: 0.28857
Total Iteration Time: 4.83426

Cumulative Model Updates: 102,598
Cumulative Timesteps: 855,536,286

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 855536286...
Checkpoint 855536286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,479.45021
Policy Entropy: 3.69564
Value Function Loss: 0.02647

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.13890
Policy Update Magnitude: 0.38292
Value Function Update Magnitude: 0.49788

Collected Steps per Second: 21,402.02434
Overall Steps per Second: 10,279.01659

Timestep Collection Time: 2.33641
Timestep Consumption Time: 2.52825
PPO Batch Consumption Time: 0.29206
Total Iteration Time: 4.86467

Cumulative Model Updates: 102,604
Cumulative Timesteps: 855,586,290

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,479.45021
Policy Entropy: 3.69610
Value Function Loss: 0.02619

Mean KL Divergence: 0.01081
SB3 Clip Fraction: 0.14672
Policy Update Magnitude: 0.38520
Value Function Update Magnitude: 0.40615

Collected Steps per Second: 21,599.09562
Overall Steps per Second: 10,377.02162

Timestep Collection Time: 2.31593
Timestep Consumption Time: 2.50453
PPO Batch Consumption Time: 0.28858
Total Iteration Time: 4.82046

Cumulative Model Updates: 102,610
Cumulative Timesteps: 855,636,312

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 855636312...
Checkpoint 855636312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,479.45021
Policy Entropy: 3.68480
Value Function Loss: 0.02642

Mean KL Divergence: 0.01047
SB3 Clip Fraction: 0.14131
Policy Update Magnitude: 0.38947
Value Function Update Magnitude: 0.36422

Collected Steps per Second: 21,619.68753
Overall Steps per Second: 10,292.84640

Timestep Collection Time: 2.31409
Timestep Consumption Time: 2.54656
PPO Batch Consumption Time: 0.29444
Total Iteration Time: 4.86066

Cumulative Model Updates: 102,616
Cumulative Timesteps: 855,686,342

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,479.45021
Policy Entropy: 3.68346
Value Function Loss: 0.02634

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.14065
Policy Update Magnitude: 0.37557
Value Function Update Magnitude: 0.37770

Collected Steps per Second: 21,456.21959
Overall Steps per Second: 10,324.97791

Timestep Collection Time: 2.33079
Timestep Consumption Time: 2.51280
PPO Batch Consumption Time: 0.28869
Total Iteration Time: 4.84359

Cumulative Model Updates: 102,622
Cumulative Timesteps: 855,736,352

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 855736352...
Checkpoint 855736352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 136,734.27340
Policy Entropy: 3.69294
Value Function Loss: 0.02718

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.14057
Policy Update Magnitude: 0.39981
Value Function Update Magnitude: 0.37735

Collected Steps per Second: 21,022.07507
Overall Steps per Second: 10,353.06351

Timestep Collection Time: 2.37978
Timestep Consumption Time: 2.45241
PPO Batch Consumption Time: 0.29189
Total Iteration Time: 4.83219

Cumulative Model Updates: 102,628
Cumulative Timesteps: 855,786,380

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 110,762.02158
Policy Entropy: 3.68952
Value Function Loss: 0.03011

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.13532
Policy Update Magnitude: 0.43935
Value Function Update Magnitude: 0.42292

Collected Steps per Second: 20,962.33826
Overall Steps per Second: 10,366.97456

Timestep Collection Time: 2.38533
Timestep Consumption Time: 2.43788
PPO Batch Consumption Time: 0.28836
Total Iteration Time: 4.82320

Cumulative Model Updates: 102,634
Cumulative Timesteps: 855,836,382

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 855836382...
Checkpoint 855836382 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 110,762.02158
Policy Entropy: 3.71141
Value Function Loss: 0.02707

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.13698
Policy Update Magnitude: 0.43218
Value Function Update Magnitude: 0.43391

Collected Steps per Second: 20,492.57720
Overall Steps per Second: 10,062.05497

Timestep Collection Time: 2.44127
Timestep Consumption Time: 2.53067
PPO Batch Consumption Time: 0.29707
Total Iteration Time: 4.97195

Cumulative Model Updates: 102,640
Cumulative Timesteps: 855,886,410

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 110,762.02158
Policy Entropy: 3.71022
Value Function Loss: 0.02230

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.13709
Policy Update Magnitude: 0.39093
Value Function Update Magnitude: 0.44983

Collected Steps per Second: 21,454.57674
Overall Steps per Second: 10,273.29338

Timestep Collection Time: 2.33246
Timestep Consumption Time: 2.53861
PPO Batch Consumption Time: 0.29544
Total Iteration Time: 4.87108

Cumulative Model Updates: 102,646
Cumulative Timesteps: 855,936,452

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 855936452...
Checkpoint 855936452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 110,762.02158
Policy Entropy: 3.71836
Value Function Loss: 0.01848

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.13940
Policy Update Magnitude: 0.35753
Value Function Update Magnitude: 0.50462

Collected Steps per Second: 21,486.89669
Overall Steps per Second: 10,306.50363

Timestep Collection Time: 2.32840
Timestep Consumption Time: 2.52582
PPO Batch Consumption Time: 0.29412
Total Iteration Time: 4.85422

Cumulative Model Updates: 102,652
Cumulative Timesteps: 855,986,482

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 110,762.02158
Policy Entropy: 3.70992
Value Function Loss: 0.02006

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.13802
Policy Update Magnitude: 0.35367
Value Function Update Magnitude: 0.58478

Collected Steps per Second: 21,502.14514
Overall Steps per Second: 10,344.55229

Timestep Collection Time: 2.32544
Timestep Consumption Time: 2.50821
PPO Batch Consumption Time: 0.28716
Total Iteration Time: 4.83366

Cumulative Model Updates: 102,658
Cumulative Timesteps: 856,036,484

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 856036484...
Checkpoint 856036484 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 110,762.02158
Policy Entropy: 3.69307
Value Function Loss: 0.02385

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.13535
Policy Update Magnitude: 0.40483
Value Function Update Magnitude: 0.59880

Collected Steps per Second: 21,079.87658
Overall Steps per Second: 10,250.71760

Timestep Collection Time: 2.37316
Timestep Consumption Time: 2.50708
PPO Batch Consumption Time: 0.28759
Total Iteration Time: 4.88024

Cumulative Model Updates: 102,664
Cumulative Timesteps: 856,086,510

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 421,888.51432
Policy Entropy: 3.68848
Value Function Loss: 0.02585

Mean KL Divergence: 0.01053
SB3 Clip Fraction: 0.14310
Policy Update Magnitude: 0.44403
Value Function Update Magnitude: 0.53399

Collected Steps per Second: 20,671.17235
Overall Steps per Second: 10,091.76963

Timestep Collection Time: 2.41902
Timestep Consumption Time: 2.53591
PPO Batch Consumption Time: 0.29296
Total Iteration Time: 4.95493

Cumulative Model Updates: 102,670
Cumulative Timesteps: 856,136,514

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 856136514...
Checkpoint 856136514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 588,914.72311
Policy Entropy: 3.69845
Value Function Loss: 0.02820

Mean KL Divergence: 0.01091
SB3 Clip Fraction: 0.14540
Policy Update Magnitude: 0.50651
Value Function Update Magnitude: 0.54447

Collected Steps per Second: 21,233.93722
Overall Steps per Second: 10,162.46964

Timestep Collection Time: 2.35472
Timestep Consumption Time: 2.56534
PPO Batch Consumption Time: 0.29670
Total Iteration Time: 4.92006

Cumulative Model Updates: 102,676
Cumulative Timesteps: 856,186,514

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 166,352.92780
Policy Entropy: 3.69890
Value Function Loss: 0.03095

Mean KL Divergence: 0.01150
SB3 Clip Fraction: 0.15230
Policy Update Magnitude: 0.55665
Value Function Update Magnitude: 0.62744

Collected Steps per Second: 21,485.59863
Overall Steps per Second: 10,252.55979

Timestep Collection Time: 2.32770
Timestep Consumption Time: 2.55030
PPO Batch Consumption Time: 0.29619
Total Iteration Time: 4.87800

Cumulative Model Updates: 102,682
Cumulative Timesteps: 856,236,526

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 856236526...
Checkpoint 856236526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 166,352.92780
Policy Entropy: 3.71701
Value Function Loss: 0.02895

Mean KL Divergence: 0.01278
SB3 Clip Fraction: 0.16489
Policy Update Magnitude: 0.57274
Value Function Update Magnitude: 0.66469

Collected Steps per Second: 21,164.22257
Overall Steps per Second: 10,167.54773

Timestep Collection Time: 2.36427
Timestep Consumption Time: 2.55707
PPO Batch Consumption Time: 0.29827
Total Iteration Time: 4.92134

Cumulative Model Updates: 102,688
Cumulative Timesteps: 856,286,564

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 166,352.92780
Policy Entropy: 3.70855
Value Function Loss: 0.02539

Mean KL Divergence: 0.01322
SB3 Clip Fraction: 0.16028
Policy Update Magnitude: 0.59903
Value Function Update Magnitude: 0.69171

Collected Steps per Second: 21,063.53857
Overall Steps per Second: 10,223.33093

Timestep Collection Time: 2.37472
Timestep Consumption Time: 2.51801
PPO Batch Consumption Time: 0.28775
Total Iteration Time: 4.89273

Cumulative Model Updates: 102,694
Cumulative Timesteps: 856,336,584

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 856336584...
Checkpoint 856336584 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 362,496.68401
Policy Entropy: 3.71345
Value Function Loss: 0.02684

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.11101
Policy Update Magnitude: 0.70853
Value Function Update Magnitude: 0.61499

Collected Steps per Second: 19,459.22088
Overall Steps per Second: 9,758.87878

Timestep Collection Time: 2.57020
Timestep Consumption Time: 2.55478
PPO Batch Consumption Time: 0.28749
Total Iteration Time: 5.12497

Cumulative Model Updates: 102,700
Cumulative Timesteps: 856,386,598

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 293,622.42279
Policy Entropy: 3.69219
Value Function Loss: 0.02639

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.10128
Policy Update Magnitude: 0.77397
Value Function Update Magnitude: 0.68573

Collected Steps per Second: 20,540.74246
Overall Steps per Second: 10,091.21831

Timestep Collection Time: 2.43448
Timestep Consumption Time: 2.52092
PPO Batch Consumption Time: 0.28855
Total Iteration Time: 4.95540

Cumulative Model Updates: 102,706
Cumulative Timesteps: 856,436,604

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 856436604...
Checkpoint 856436604 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 580,216.27086
Policy Entropy: 3.68531
Value Function Loss: 0.03564

Mean KL Divergence: 0.01169
SB3 Clip Fraction: 0.15010
Policy Update Magnitude: 0.69068
Value Function Update Magnitude: 0.57488

Collected Steps per Second: 20,906.95868
Overall Steps per Second: 10,228.98993

Timestep Collection Time: 2.39212
Timestep Consumption Time: 2.49712
PPO Batch Consumption Time: 0.28753
Total Iteration Time: 4.88924

Cumulative Model Updates: 102,712
Cumulative Timesteps: 856,486,616

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 301,269.47829
Policy Entropy: 3.69613
Value Function Loss: 0.03593

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.09948
Policy Update Magnitude: 0.78363
Value Function Update Magnitude: 0.54797

Collected Steps per Second: 20,284.39351
Overall Steps per Second: 10,109.77683

Timestep Collection Time: 2.46603
Timestep Consumption Time: 2.48185
PPO Batch Consumption Time: 0.29461
Total Iteration Time: 4.94788

Cumulative Model Updates: 102,718
Cumulative Timesteps: 856,536,638

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 856536638...
Checkpoint 856536638 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 110,467.42052
Policy Entropy: 3.71236
Value Function Loss: 0.03414

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.11359
Policy Update Magnitude: 0.81963
Value Function Update Magnitude: 0.60502

Collected Steps per Second: 20,642.88466
Overall Steps per Second: 10,204.13658

Timestep Collection Time: 2.42350
Timestep Consumption Time: 2.47922
PPO Batch Consumption Time: 0.29669
Total Iteration Time: 4.90272

Cumulative Model Updates: 102,724
Cumulative Timesteps: 856,586,666

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 144,041.43379
Policy Entropy: 3.72728
Value Function Loss: 0.02712

Mean KL Divergence: 0.00727
SB3 Clip Fraction: 0.08988
Policy Update Magnitude: 0.76233
Value Function Update Magnitude: 0.59098

Collected Steps per Second: 20,772.20836
Overall Steps per Second: 10,348.74968

Timestep Collection Time: 2.40716
Timestep Consumption Time: 2.42454
PPO Batch Consumption Time: 0.28789
Total Iteration Time: 4.83169

Cumulative Model Updates: 102,730
Cumulative Timesteps: 856,636,668

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 856636668...
Checkpoint 856636668 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 50,258.73245
Policy Entropy: 3.72645
Value Function Loss: 0.02537

Mean KL Divergence: 0.00641
SB3 Clip Fraction: 0.07807
Policy Update Magnitude: 0.70355
Value Function Update Magnitude: 0.63294

Collected Steps per Second: 21,011.77476
Overall Steps per Second: 10,227.76992

Timestep Collection Time: 2.38038
Timestep Consumption Time: 2.50984
PPO Batch Consumption Time: 0.29298
Total Iteration Time: 4.89022

Cumulative Model Updates: 102,736
Cumulative Timesteps: 856,686,684

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,976.21927
Policy Entropy: 3.71995
Value Function Loss: 0.02618

Mean KL Divergence: 0.01095
SB3 Clip Fraction: 0.14705
Policy Update Magnitude: 0.66515
Value Function Update Magnitude: 0.74142

Collected Steps per Second: 21,119.96523
Overall Steps per Second: 10,004.02157

Timestep Collection Time: 2.36875
Timestep Consumption Time: 2.63203
PPO Batch Consumption Time: 0.31533
Total Iteration Time: 5.00079

Cumulative Model Updates: 102,742
Cumulative Timesteps: 856,736,712

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 856736712...
Checkpoint 856736712 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,976.21927
Policy Entropy: 3.71672
Value Function Loss: 0.02444

Mean KL Divergence: 0.01146
SB3 Clip Fraction: 0.15142
Policy Update Magnitude: 0.62021
Value Function Update Magnitude: 0.76039

Collected Steps per Second: 21,902.28425
Overall Steps per Second: 10,327.98455

Timestep Collection Time: 2.28341
Timestep Consumption Time: 2.55896
PPO Batch Consumption Time: 0.30101
Total Iteration Time: 4.84238

Cumulative Model Updates: 102,748
Cumulative Timesteps: 856,786,724

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,976.21927
Policy Entropy: 3.71916
Value Function Loss: 0.02453

Mean KL Divergence: 0.01676
SB3 Clip Fraction: 0.21270
Policy Update Magnitude: 0.55405
Value Function Update Magnitude: 0.61477

Collected Steps per Second: 21,221.01718
Overall Steps per Second: 10,148.64864

Timestep Collection Time: 2.35813
Timestep Consumption Time: 2.57277
PPO Batch Consumption Time: 0.29833
Total Iteration Time: 4.93090

Cumulative Model Updates: 102,754
Cumulative Timesteps: 856,836,766

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 856836766...
Checkpoint 856836766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 462,214.89194
Policy Entropy: 3.69751
Value Function Loss: 0.03660

Mean KL Divergence: 0.01319
SB3 Clip Fraction: 0.17549
Policy Update Magnitude: 0.51403
Value Function Update Magnitude: 0.56991

Collected Steps per Second: 21,567.42268
Overall Steps per Second: 10,252.05128

Timestep Collection Time: 2.31970
Timestep Consumption Time: 2.56030
PPO Batch Consumption Time: 0.29829
Total Iteration Time: 4.88000

Cumulative Model Updates: 102,760
Cumulative Timesteps: 856,886,796

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,991.63770
Policy Entropy: 3.71143
Value Function Loss: 0.03841

Mean KL Divergence: 0.01667
SB3 Clip Fraction: 0.21058
Policy Update Magnitude: 0.52818
Value Function Update Magnitude: 0.52676

Collected Steps per Second: 21,421.00153
Overall Steps per Second: 10,324.55844

Timestep Collection Time: 2.33472
Timestep Consumption Time: 2.50927
PPO Batch Consumption Time: 0.28691
Total Iteration Time: 4.84398

Cumulative Model Updates: 102,766
Cumulative Timesteps: 856,936,808

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 856936808...
Checkpoint 856936808 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,277.38199
Policy Entropy: 3.71336
Value Function Loss: 0.04060

Mean KL Divergence: 0.01625
SB3 Clip Fraction: 0.19745
Policy Update Magnitude: 0.50531
Value Function Update Magnitude: 0.58260

Collected Steps per Second: 21,293.37835
Overall Steps per Second: 10,190.26488

Timestep Collection Time: 2.34843
Timestep Consumption Time: 2.55880
PPO Batch Consumption Time: 0.30160
Total Iteration Time: 4.90723

Cumulative Model Updates: 102,772
Cumulative Timesteps: 856,986,814

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,451.48959
Policy Entropy: 3.76183
Value Function Loss: 0.03243

Mean KL Divergence: 0.01276
SB3 Clip Fraction: 0.16929
Policy Update Magnitude: 0.48936
Value Function Update Magnitude: 0.64043

Collected Steps per Second: 21,616.77386
Overall Steps per Second: 10,358.75153

Timestep Collection Time: 2.31302
Timestep Consumption Time: 2.51382
PPO Batch Consumption Time: 0.28798
Total Iteration Time: 4.82684

Cumulative Model Updates: 102,778
Cumulative Timesteps: 857,036,814

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 857036814...
Checkpoint 857036814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,485.27234
Policy Entropy: 3.75603
Value Function Loss: 0.03879

Mean KL Divergence: 0.01214
SB3 Clip Fraction: 0.16091
Policy Update Magnitude: 0.50076
Value Function Update Magnitude: 0.61328

Collected Steps per Second: 21,281.38160
Overall Steps per Second: 10,330.24471

Timestep Collection Time: 2.34957
Timestep Consumption Time: 2.49078
PPO Batch Consumption Time: 0.28656
Total Iteration Time: 4.84035

Cumulative Model Updates: 102,784
Cumulative Timesteps: 857,086,816

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,539.61029
Policy Entropy: 3.79407
Value Function Loss: 0.04127

Mean KL Divergence: 0.01092
SB3 Clip Fraction: 0.14171
Policy Update Magnitude: 0.65899
Value Function Update Magnitude: 0.64195

Collected Steps per Second: 21,651.98534
Overall Steps per Second: 10,432.18243

Timestep Collection Time: 2.30944
Timestep Consumption Time: 2.48380
PPO Batch Consumption Time: 0.28719
Total Iteration Time: 4.79324

Cumulative Model Updates: 102,790
Cumulative Timesteps: 857,136,820

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 857136820...
Checkpoint 857136820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 823.24329
Policy Entropy: 3.78713
Value Function Loss: 0.04138

Mean KL Divergence: 0.01337
SB3 Clip Fraction: 0.16729
Policy Update Magnitude: 0.67859
Value Function Update Magnitude: 0.67290

Collected Steps per Second: 21,605.22755
Overall Steps per Second: 10,211.46690

Timestep Collection Time: 2.31527
Timestep Consumption Time: 2.58334
PPO Batch Consumption Time: 0.30189
Total Iteration Time: 4.89861

Cumulative Model Updates: 102,796
Cumulative Timesteps: 857,186,842

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 168.93770
Policy Entropy: 3.78024
Value Function Loss: 0.03699

Mean KL Divergence: 0.01418
SB3 Clip Fraction: 0.17424
Policy Update Magnitude: 0.63964
Value Function Update Magnitude: 0.70151

Collected Steps per Second: 21,475.33148
Overall Steps per Second: 10,329.20333

Timestep Collection Time: 2.32835
Timestep Consumption Time: 2.51249
PPO Batch Consumption Time: 0.28757
Total Iteration Time: 4.84084

Cumulative Model Updates: 102,802
Cumulative Timesteps: 857,236,844

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 857236844...
Checkpoint 857236844 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 154,406.50009
Policy Entropy: 3.72878
Value Function Loss: 0.03754

Mean KL Divergence: 0.01329
SB3 Clip Fraction: 0.16882
Policy Update Magnitude: 0.66117
Value Function Update Magnitude: 0.76881

Collected Steps per Second: 21,293.87705
Overall Steps per Second: 10,335.57764

Timestep Collection Time: 2.34837
Timestep Consumption Time: 2.48986
PPO Batch Consumption Time: 0.28674
Total Iteration Time: 4.83824

Cumulative Model Updates: 102,808
Cumulative Timesteps: 857,286,850

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,000.71841
Policy Entropy: 3.72477
Value Function Loss: 0.03674

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.12043
Policy Update Magnitude: 0.69556
Value Function Update Magnitude: 0.74219

Collected Steps per Second: 21,533.43580
Overall Steps per Second: 10,134.70737

Timestep Collection Time: 2.32318
Timestep Consumption Time: 2.61293
PPO Batch Consumption Time: 0.30531
Total Iteration Time: 4.93611

Cumulative Model Updates: 102,814
Cumulative Timesteps: 857,336,876

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 857336876...
Checkpoint 857336876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,255.23552
Policy Entropy: 3.76129
Value Function Loss: 0.03324

Mean KL Divergence: 0.01781
SB3 Clip Fraction: 0.21015
Policy Update Magnitude: 0.69240
Value Function Update Magnitude: 0.71916

Collected Steps per Second: 21,669.44480
Overall Steps per Second: 10,326.15170

Timestep Collection Time: 2.30850
Timestep Consumption Time: 2.53590
PPO Batch Consumption Time: 0.28954
Total Iteration Time: 4.84440

Cumulative Model Updates: 102,820
Cumulative Timesteps: 857,386,900

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,852.73843
Policy Entropy: 3.75933
Value Function Loss: 0.03118

Mean KL Divergence: 0.01365
SB3 Clip Fraction: 0.17997
Policy Update Magnitude: 0.65204
Value Function Update Magnitude: 0.78435

Collected Steps per Second: 21,821.61627
Overall Steps per Second: 10,302.09728

Timestep Collection Time: 2.29186
Timestep Consumption Time: 2.56269
PPO Batch Consumption Time: 0.30012
Total Iteration Time: 4.85455

Cumulative Model Updates: 102,826
Cumulative Timesteps: 857,436,912

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 857436912...
Checkpoint 857436912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 832.66007
Policy Entropy: 3.78130
Value Function Loss: 0.02947

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.12307
Policy Update Magnitude: 0.75009
Value Function Update Magnitude: 0.88291

Collected Steps per Second: 21,340.18549
Overall Steps per Second: 10,207.64287

Timestep Collection Time: 2.34422
Timestep Consumption Time: 2.55662
PPO Batch Consumption Time: 0.30013
Total Iteration Time: 4.90084

Cumulative Model Updates: 102,832
Cumulative Timesteps: 857,486,938

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 64,559.86268
Policy Entropy: 3.76568
Value Function Loss: 0.03263

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.10512
Policy Update Magnitude: 0.81339
Value Function Update Magnitude: 0.81901

Collected Steps per Second: 21,304.84329
Overall Steps per Second: 10,293.98226

Timestep Collection Time: 2.34801
Timestep Consumption Time: 2.51153
PPO Batch Consumption Time: 0.28810
Total Iteration Time: 4.85954

Cumulative Model Updates: 102,838
Cumulative Timesteps: 857,536,962

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 857536962...
Checkpoint 857536962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,772.54249
Policy Entropy: 3.74894
Value Function Loss: 0.02992

Mean KL Divergence: 0.01305
SB3 Clip Fraction: 0.17162
Policy Update Magnitude: 0.72665
Value Function Update Magnitude: 0.76306

Collected Steps per Second: 21,063.07150
Overall Steps per Second: 10,242.00993

Timestep Collection Time: 2.37449
Timestep Consumption Time: 2.50873
PPO Batch Consumption Time: 0.28853
Total Iteration Time: 4.88322

Cumulative Model Updates: 102,844
Cumulative Timesteps: 857,586,976

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,485.99753
Policy Entropy: 3.72791
Value Function Loss: 0.03548

Mean KL Divergence: 0.02080
SB3 Clip Fraction: 0.23870
Policy Update Magnitude: 0.59105
Value Function Update Magnitude: 0.72436

Collected Steps per Second: 20,923.14114
Overall Steps per Second: 10,392.64186

Timestep Collection Time: 2.39008
Timestep Consumption Time: 2.42179
PPO Batch Consumption Time: 0.28802
Total Iteration Time: 4.81187

Cumulative Model Updates: 102,850
Cumulative Timesteps: 857,636,984

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 857636984...
Checkpoint 857636984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 303,833.61926
Policy Entropy: 3.70962
Value Function Loss: 0.03770

Mean KL Divergence: 0.01528
SB3 Clip Fraction: 0.18142
Policy Update Magnitude: 0.56743
Value Function Update Magnitude: 0.79237

Collected Steps per Second: 20,859.92683
Overall Steps per Second: 10,318.61243

Timestep Collection Time: 2.39752
Timestep Consumption Time: 2.44926
PPO Batch Consumption Time: 0.29227
Total Iteration Time: 4.84678

Cumulative Model Updates: 102,856
Cumulative Timesteps: 857,686,996

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 344,468.27241
Policy Entropy: 3.70932
Value Function Loss: 0.03633

Mean KL Divergence: 0.01091
SB3 Clip Fraction: 0.14740
Policy Update Magnitude: 0.69775
Value Function Update Magnitude: 0.73795

Collected Steps per Second: 21,210.50825
Overall Steps per Second: 10,418.35589

Timestep Collection Time: 2.35742
Timestep Consumption Time: 2.44200
PPO Batch Consumption Time: 0.28846
Total Iteration Time: 4.79941

Cumulative Model Updates: 102,862
Cumulative Timesteps: 857,736,998

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 857736998...
Checkpoint 857736998 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 148,281.53935
Policy Entropy: 3.71310
Value Function Loss: 0.03168

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.11072
Policy Update Magnitude: 0.76136
Value Function Update Magnitude: 0.82506

Collected Steps per Second: 20,880.22676
Overall Steps per Second: 10,245.12570

Timestep Collection Time: 2.39528
Timestep Consumption Time: 2.48646
PPO Batch Consumption Time: 0.28690
Total Iteration Time: 4.88174

Cumulative Model Updates: 102,868
Cumulative Timesteps: 857,787,012

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 148,281.53935
Policy Entropy: 3.69978
Value Function Loss: 0.02644

Mean KL Divergence: 0.00700
SB3 Clip Fraction: 0.08825
Policy Update Magnitude: 0.72907
Value Function Update Magnitude: 0.79218

Collected Steps per Second: 21,440.15507
Overall Steps per Second: 10,362.44565

Timestep Collection Time: 2.33254
Timestep Consumption Time: 2.49354
PPO Batch Consumption Time: 0.28846
Total Iteration Time: 4.82608

Cumulative Model Updates: 102,874
Cumulative Timesteps: 857,837,022

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 857837022...
Checkpoint 857837022 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 148,281.53935
Policy Entropy: 3.69168
Value Function Loss: 0.02442

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.09868
Policy Update Magnitude: 0.65213
Value Function Update Magnitude: 0.74503

Collected Steps per Second: 21,274.66927
Overall Steps per Second: 10,283.32383

Timestep Collection Time: 2.35134
Timestep Consumption Time: 2.51323
PPO Batch Consumption Time: 0.29430
Total Iteration Time: 4.86457

Cumulative Model Updates: 102,880
Cumulative Timesteps: 857,887,046

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95,200.72063
Policy Entropy: 3.69426
Value Function Loss: 0.02829

Mean KL Divergence: 0.00640
SB3 Clip Fraction: 0.07904
Policy Update Magnitude: 0.67320
Value Function Update Magnitude: 0.64224

Collected Steps per Second: 21,533.05297
Overall Steps per Second: 10,342.74102

Timestep Collection Time: 2.32275
Timestep Consumption Time: 2.51310
PPO Batch Consumption Time: 0.28809
Total Iteration Time: 4.83586

Cumulative Model Updates: 102,886
Cumulative Timesteps: 857,937,062

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 857937062...
Checkpoint 857937062 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,432.70262
Policy Entropy: 3.71823
Value Function Loss: 0.02547

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.12779
Policy Update Magnitude: 0.61548
Value Function Update Magnitude: 0.64279

Collected Steps per Second: 21,903.10621
Overall Steps per Second: 10,242.40481

Timestep Collection Time: 2.28406
Timestep Consumption Time: 2.60034
PPO Batch Consumption Time: 0.30216
Total Iteration Time: 4.88440

Cumulative Model Updates: 102,892
Cumulative Timesteps: 857,987,090

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 73,678.61491
Policy Entropy: 3.72469
Value Function Loss: 0.03213

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.13097
Policy Update Magnitude: 0.54737
Value Function Update Magnitude: 0.73874

Collected Steps per Second: 21,347.77454
Overall Steps per Second: 10,241.45051

Timestep Collection Time: 2.34366
Timestep Consumption Time: 2.54158
PPO Batch Consumption Time: 0.29728
Total Iteration Time: 4.88525

Cumulative Model Updates: 102,898
Cumulative Timesteps: 858,037,122

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 858037122...
Checkpoint 858037122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 126,351.88389
Policy Entropy: 3.74086
Value Function Loss: 0.02778

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.12548
Policy Update Magnitude: 0.52666
Value Function Update Magnitude: 0.72451

Collected Steps per Second: 21,396.35154
Overall Steps per Second: 10,224.31085

Timestep Collection Time: 2.33722
Timestep Consumption Time: 2.55387
PPO Batch Consumption Time: 0.29852
Total Iteration Time: 4.89109

Cumulative Model Updates: 102,904
Cumulative Timesteps: 858,087,130

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 102,345.45904
Policy Entropy: 3.71685
Value Function Loss: 0.02679

Mean KL Divergence: 0.01174
SB3 Clip Fraction: 0.15629
Policy Update Magnitude: 0.51527
Value Function Update Magnitude: 0.79926

Collected Steps per Second: 22,151.43794
Overall Steps per Second: 10,330.76147

Timestep Collection Time: 2.25945
Timestep Consumption Time: 2.58531
PPO Batch Consumption Time: 0.30026
Total Iteration Time: 4.84475

Cumulative Model Updates: 102,910
Cumulative Timesteps: 858,137,180

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 858137180...
Checkpoint 858137180 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 102,345.45904
Policy Entropy: 3.72477
Value Function Loss: 0.02104

Mean KL Divergence: 0.01280
SB3 Clip Fraction: 0.17096
Policy Update Magnitude: 0.46195
Value Function Update Magnitude: 0.78851

Collected Steps per Second: 20,845.73841
Overall Steps per Second: 9,989.53320

Timestep Collection Time: 2.39972
Timestep Consumption Time: 2.60792
PPO Batch Consumption Time: 0.29774
Total Iteration Time: 5.00764

Cumulative Model Updates: 102,916
Cumulative Timesteps: 858,187,204

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 72,262.06798
Policy Entropy: 3.68283
Value Function Loss: 0.02682

Mean KL Divergence: 0.01171
SB3 Clip Fraction: 0.15308
Policy Update Magnitude: 0.43607
Value Function Update Magnitude: 0.69551

Collected Steps per Second: 21,291.56965
Overall Steps per Second: 10,292.98564

Timestep Collection Time: 2.34919
Timestep Consumption Time: 2.51023
PPO Batch Consumption Time: 0.28615
Total Iteration Time: 4.85943

Cumulative Model Updates: 102,922
Cumulative Timesteps: 858,237,222

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 858237222...
Checkpoint 858237222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,214.20411
Policy Entropy: 3.71572
Value Function Loss: 0.02556

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.12930
Policy Update Magnitude: 0.59989
Value Function Update Magnitude: 0.72259

Collected Steps per Second: 20,576.82544
Overall Steps per Second: 10,197.56904

Timestep Collection Time: 2.43206
Timestep Consumption Time: 2.47539
PPO Batch Consumption Time: 0.29577
Total Iteration Time: 4.90744

Cumulative Model Updates: 102,928
Cumulative Timesteps: 858,287,266

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,551.28013
Policy Entropy: 3.70371
Value Function Loss: 0.02670

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.11121
Policy Update Magnitude: 0.66402
Value Function Update Magnitude: 0.64367

Collected Steps per Second: 20,834.80641
Overall Steps per Second: 10,336.40039

Timestep Collection Time: 2.40002
Timestep Consumption Time: 2.43764
PPO Batch Consumption Time: 0.28853
Total Iteration Time: 4.83766

Cumulative Model Updates: 102,934
Cumulative Timesteps: 858,337,270

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 858337270...
Checkpoint 858337270 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 97,464.64753
Policy Entropy: 3.71369
Value Function Loss: 0.02288

Mean KL Divergence: 0.02117
SB3 Clip Fraction: 0.24722
Policy Update Magnitude: 0.56201
Value Function Update Magnitude: 0.63028

Collected Steps per Second: 20,864.23230
Overall Steps per Second: 10,320.11635

Timestep Collection Time: 2.39693
Timestep Consumption Time: 2.44895
PPO Batch Consumption Time: 0.29164
Total Iteration Time: 4.84588

Cumulative Model Updates: 102,940
Cumulative Timesteps: 858,387,280

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97,464.64753
Policy Entropy: 3.64089
Value Function Loss: 0.04430

Mean KL Divergence: 0.02581
SB3 Clip Fraction: 0.26295
Policy Update Magnitude: 0.48208
Value Function Update Magnitude: 0.65584

Collected Steps per Second: 20,497.77489
Overall Steps per Second: 10,038.93035

Timestep Collection Time: 2.44085
Timestep Consumption Time: 2.54295
PPO Batch Consumption Time: 0.29728
Total Iteration Time: 4.98380

Cumulative Model Updates: 102,946
Cumulative Timesteps: 858,437,312

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 858437312...
Checkpoint 858437312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 197,828.29742
Policy Entropy: 3.60825
Value Function Loss: 0.06940

Mean KL Divergence: 0.02897
SB3 Clip Fraction: 0.27267
Policy Update Magnitude: 0.58118
Value Function Update Magnitude: 0.64926

Collected Steps per Second: 20,801.53328
Overall Steps per Second: 10,257.44169

Timestep Collection Time: 2.40415
Timestep Consumption Time: 2.47134
PPO Batch Consumption Time: 0.28656
Total Iteration Time: 4.87548

Cumulative Model Updates: 102,952
Cumulative Timesteps: 858,487,322

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 264,635.25779
Policy Entropy: 3.68252
Value Function Loss: 0.08243

Mean KL Divergence: 0.01284
SB3 Clip Fraction: 0.15856
Policy Update Magnitude: 0.71837
Value Function Update Magnitude: 0.64109

Collected Steps per Second: 21,488.53230
Overall Steps per Second: 10,386.98258

Timestep Collection Time: 2.32813
Timestep Consumption Time: 2.48829
PPO Batch Consumption Time: 0.28851
Total Iteration Time: 4.81641

Cumulative Model Updates: 102,958
Cumulative Timesteps: 858,537,350

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 858537350...
Checkpoint 858537350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,714.99290
Policy Entropy: 3.74687
Value Function Loss: 0.06879

Mean KL Divergence: 0.01195
SB3 Clip Fraction: 0.15092
Policy Update Magnitude: 1.04657
Value Function Update Magnitude: 0.64020

Collected Steps per Second: 21,239.09767
Overall Steps per Second: 10,200.66404

Timestep Collection Time: 2.35518
Timestep Consumption Time: 2.54861
PPO Batch Consumption Time: 0.29686
Total Iteration Time: 4.90380

Cumulative Model Updates: 102,964
Cumulative Timesteps: 858,587,372

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66,535.76832
Policy Entropy: 3.79623
Value Function Loss: 0.06052

Mean KL Divergence: 0.01092
SB3 Clip Fraction: 0.13785
Policy Update Magnitude: 1.14934
Value Function Update Magnitude: 0.69001

Collected Steps per Second: 21,598.53131
Overall Steps per Second: 10,439.46588

Timestep Collection Time: 2.31673
Timestep Consumption Time: 2.47643
PPO Batch Consumption Time: 0.28824
Total Iteration Time: 4.79316

Cumulative Model Updates: 102,970
Cumulative Timesteps: 858,637,410

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 858637410...
Checkpoint 858637410 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 67,268.07855
Policy Entropy: 3.75248
Value Function Loss: 0.05957

Mean KL Divergence: 0.01489
SB3 Clip Fraction: 0.18404
Policy Update Magnitude: 0.94028
Value Function Update Magnitude: 0.63277

Collected Steps per Second: 21,388.84068
Overall Steps per Second: 10,284.76535

Timestep Collection Time: 2.33898
Timestep Consumption Time: 2.52531
PPO Batch Consumption Time: 0.29214
Total Iteration Time: 4.86428

Cumulative Model Updates: 102,976
Cumulative Timesteps: 858,687,438

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,871.30482
Policy Entropy: 3.75000
Value Function Loss: 0.05166

Mean KL Divergence: 0.01229
SB3 Clip Fraction: 0.16253
Policy Update Magnitude: 0.82597
Value Function Update Magnitude: 0.64579

Collected Steps per Second: 21,795.30514
Overall Steps per Second: 10,375.94063

Timestep Collection Time: 2.29490
Timestep Consumption Time: 2.52568
PPO Batch Consumption Time: 0.28938
Total Iteration Time: 4.82057

Cumulative Model Updates: 102,982
Cumulative Timesteps: 858,737,456

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 858737456...
Checkpoint 858737456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,072.89302
Policy Entropy: 3.74341
Value Function Loss: 0.05050

Mean KL Divergence: 0.01055
SB3 Clip Fraction: 0.13809
Policy Update Magnitude: 0.82064
Value Function Update Magnitude: 0.65963

Collected Steps per Second: 21,425.28698
Overall Steps per Second: 10,196.31909

Timestep Collection Time: 2.33481
Timestep Consumption Time: 2.57127
PPO Batch Consumption Time: 0.29982
Total Iteration Time: 4.90608

Cumulative Model Updates: 102,988
Cumulative Timesteps: 858,787,480

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,409.08719
Policy Entropy: 3.74730
Value Function Loss: 0.04087

Mean KL Divergence: 0.01403
SB3 Clip Fraction: 0.18536
Policy Update Magnitude: 0.66241
Value Function Update Magnitude: 0.51798

Collected Steps per Second: 21,582.60060
Overall Steps per Second: 10,087.82342

Timestep Collection Time: 2.31687
Timestep Consumption Time: 2.64000
PPO Batch Consumption Time: 0.31162
Total Iteration Time: 4.95687

Cumulative Model Updates: 102,994
Cumulative Timesteps: 858,837,484

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 858837484...
Checkpoint 858837484 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,409.08719
Policy Entropy: 3.71949
Value Function Loss: 0.03363

Mean KL Divergence: 0.01257
SB3 Clip Fraction: 0.17117
Policy Update Magnitude: 0.46056
Value Function Update Magnitude: 0.43775

Collected Steps per Second: 21,349.67681
Overall Steps per Second: 10,238.41803

Timestep Collection Time: 2.34336
Timestep Consumption Time: 2.54314
PPO Batch Consumption Time: 0.29360
Total Iteration Time: 4.88650

Cumulative Model Updates: 103,000
Cumulative Timesteps: 858,887,514

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,409.08719
Policy Entropy: 3.69962
Value Function Loss: 0.03115

Mean KL Divergence: 0.01090
SB3 Clip Fraction: 0.15270
Policy Update Magnitude: 0.33812
Value Function Update Magnitude: 0.34963

Collected Steps per Second: 21,435.17149
Overall Steps per Second: 10,325.38614

Timestep Collection Time: 2.33299
Timestep Consumption Time: 2.51022
PPO Batch Consumption Time: 0.28862
Total Iteration Time: 4.84321

Cumulative Model Updates: 103,006
Cumulative Timesteps: 858,937,522

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 858937522...
Checkpoint 858937522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,374.91879
Policy Entropy: 3.72551
Value Function Loss: 0.02884

Mean KL Divergence: 0.01120
SB3 Clip Fraction: 0.15547
Policy Update Magnitude: 0.31175
Value Function Update Magnitude: 0.30490

Collected Steps per Second: 21,753.02873
Overall Steps per Second: 10,309.84677

Timestep Collection Time: 2.29853
Timestep Consumption Time: 2.55120
PPO Batch Consumption Time: 0.29249
Total Iteration Time: 4.84973

Cumulative Model Updates: 103,012
Cumulative Timesteps: 858,987,522

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,553.29563
Policy Entropy: 3.74081
Value Function Loss: 0.02863

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.14610
Policy Update Magnitude: 0.30061
Value Function Update Magnitude: 0.38472

Collected Steps per Second: 21,863.64924
Overall Steps per Second: 10,442.51635

Timestep Collection Time: 2.28782
Timestep Consumption Time: 2.50222
PPO Batch Consumption Time: 0.28774
Total Iteration Time: 4.79003

Cumulative Model Updates: 103,018
Cumulative Timesteps: 859,037,542

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 859037542...
Checkpoint 859037542 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,553.29563
Policy Entropy: 3.74130
Value Function Loss: 0.02608

Mean KL Divergence: 0.01109
SB3 Clip Fraction: 0.15360
Policy Update Magnitude: 0.31708
Value Function Update Magnitude: 0.39249

Collected Steps per Second: 21,315.58200
Overall Steps per Second: 10,254.79907

Timestep Collection Time: 2.34589
Timestep Consumption Time: 2.53027
PPO Batch Consumption Time: 0.29248
Total Iteration Time: 4.87616

Cumulative Model Updates: 103,024
Cumulative Timesteps: 859,087,546

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,553.29563
Policy Entropy: 3.69584
Value Function Loss: 0.02552

Mean KL Divergence: 0.01059
SB3 Clip Fraction: 0.14713
Policy Update Magnitude: 0.29970
Value Function Update Magnitude: 0.33116

Collected Steps per Second: 21,687.93253
Overall Steps per Second: 10,369.74207

Timestep Collection Time: 2.30690
Timestep Consumption Time: 2.51790
PPO Batch Consumption Time: 0.28852
Total Iteration Time: 4.82481

Cumulative Model Updates: 103,030
Cumulative Timesteps: 859,137,578

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 859137578...
Checkpoint 859137578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,553.29563
Policy Entropy: 3.69788
Value Function Loss: 0.02376

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.14711
Policy Update Magnitude: 0.27446
Value Function Update Magnitude: 0.28825

Collected Steps per Second: 21,677.02609
Overall Steps per Second: 10,282.01119

Timestep Collection Time: 2.30751
Timestep Consumption Time: 2.55729
PPO Batch Consumption Time: 0.29404
Total Iteration Time: 4.86481

Cumulative Model Updates: 103,036
Cumulative Timesteps: 859,187,598

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,553.29563
Policy Entropy: 3.67991
Value Function Loss: 0.02489

Mean KL Divergence: 0.01119
SB3 Clip Fraction: 0.15527
Policy Update Magnitude: 0.27863
Value Function Update Magnitude: 0.23901

Collected Steps per Second: 21,473.49736
Overall Steps per Second: 10,343.02940

Timestep Collection Time: 2.32910
Timestep Consumption Time: 2.50642
PPO Batch Consumption Time: 0.28773
Total Iteration Time: 4.83553

Cumulative Model Updates: 103,042
Cumulative Timesteps: 859,237,612

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 859237612...
Checkpoint 859237612 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,553.29563
Policy Entropy: 3.70394
Value Function Loss: 0.02311

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.15238
Policy Update Magnitude: 0.27777
Value Function Update Magnitude: 0.31169

Collected Steps per Second: 21,824.37705
Overall Steps per Second: 10,321.16686

Timestep Collection Time: 2.29138
Timestep Consumption Time: 2.55381
PPO Batch Consumption Time: 0.29430
Total Iteration Time: 4.84519

Cumulative Model Updates: 103,048
Cumulative Timesteps: 859,287,620

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59,458.06031
Policy Entropy: 3.69487
Value Function Loss: 0.02410

Mean KL Divergence: 0.01162
SB3 Clip Fraction: 0.16337
Policy Update Magnitude: 0.29075
Value Function Update Magnitude: 0.30439

Collected Steps per Second: 21,681.05742
Overall Steps per Second: 10,418.03723

Timestep Collection Time: 2.30699
Timestep Consumption Time: 2.49411
PPO Batch Consumption Time: 0.28664
Total Iteration Time: 4.80110

Cumulative Model Updates: 103,054
Cumulative Timesteps: 859,337,638

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 859337638...
Checkpoint 859337638 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 59,458.06031
Policy Entropy: 3.71896
Value Function Loss: 0.02232

Mean KL Divergence: 0.01111
SB3 Clip Fraction: 0.15490
Policy Update Magnitude: 0.26530
Value Function Update Magnitude: 0.27406

Collected Steps per Second: 21,549.81437
Overall Steps per Second: 10,223.87223

Timestep Collection Time: 2.32132
Timestep Consumption Time: 2.57154
PPO Batch Consumption Time: 0.29915
Total Iteration Time: 4.89286

Cumulative Model Updates: 103,060
Cumulative Timesteps: 859,387,662

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59,458.06031
Policy Entropy: 3.69272
Value Function Loss: 0.02263

Mean KL Divergence: 0.01105
SB3 Clip Fraction: 0.15358
Policy Update Magnitude: 0.26596
Value Function Update Magnitude: 0.24989

Collected Steps per Second: 20,735.31649
Overall Steps per Second: 10,046.76855

Timestep Collection Time: 2.41221
Timestep Consumption Time: 2.56630
PPO Batch Consumption Time: 0.31125
Total Iteration Time: 4.97852

Cumulative Model Updates: 103,066
Cumulative Timesteps: 859,437,680

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 859437680...
Checkpoint 859437680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 59,458.06031
Policy Entropy: 3.69742
Value Function Loss: 0.02379

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.14249
Policy Update Magnitude: 0.29228
Value Function Update Magnitude: 0.30228

Collected Steps per Second: 20,938.53959
Overall Steps per Second: 10,241.08702

Timestep Collection Time: 2.38937
Timestep Consumption Time: 2.49585
PPO Batch Consumption Time: 0.29855
Total Iteration Time: 4.88522

Cumulative Model Updates: 103,072
Cumulative Timesteps: 859,487,710

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67,139.68078
Policy Entropy: 3.69000
Value Function Loss: 0.02729

Mean KL Divergence: 0.01060
SB3 Clip Fraction: 0.14748
Policy Update Magnitude: 0.32486
Value Function Update Magnitude: 0.35436

Collected Steps per Second: 20,913.80730
Overall Steps per Second: 10,136.11669

Timestep Collection Time: 2.39210
Timestep Consumption Time: 2.54351
PPO Batch Consumption Time: 0.29832
Total Iteration Time: 4.93562

Cumulative Model Updates: 103,078
Cumulative Timesteps: 859,537,738

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 859537738...
Checkpoint 859537738 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,971.41059
Policy Entropy: 3.70648
Value Function Loss: 0.02603

Mean KL Divergence: 0.01065
SB3 Clip Fraction: 0.14466
Policy Update Magnitude: 0.36551
Value Function Update Magnitude: 0.46269

Collected Steps per Second: 21,658.12423
Overall Steps per Second: 10,438.37022

Timestep Collection Time: 2.30879
Timestep Consumption Time: 2.48162
PPO Batch Consumption Time: 0.28806
Total Iteration Time: 4.79040

Cumulative Model Updates: 103,084
Cumulative Timesteps: 859,587,742

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,622.46280
Policy Entropy: 3.70408
Value Function Loss: 0.02469

Mean KL Divergence: 0.01249
SB3 Clip Fraction: 0.16745
Policy Update Magnitude: 0.38019
Value Function Update Magnitude: 0.52626

Collected Steps per Second: 21,511.03885
Overall Steps per Second: 10,418.82636

Timestep Collection Time: 2.32467
Timestep Consumption Time: 2.47491
PPO Batch Consumption Time: 0.28776
Total Iteration Time: 4.79958

Cumulative Model Updates: 103,090
Cumulative Timesteps: 859,637,748

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 859637748...
Checkpoint 859637748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,622.46280
Policy Entropy: 3.70475
Value Function Loss: 0.02204

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.12456
Policy Update Magnitude: 0.44355
Value Function Update Magnitude: 0.53659

Collected Steps per Second: 21,530.12828
Overall Steps per Second: 10,377.77409

Timestep Collection Time: 2.32344
Timestep Consumption Time: 2.49686
PPO Batch Consumption Time: 0.28624
Total Iteration Time: 4.82030

Cumulative Model Updates: 103,096
Cumulative Timesteps: 859,687,772

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 71,905.15003
Policy Entropy: 3.69371
Value Function Loss: 0.02291

Mean KL Divergence: 0.01173
SB3 Clip Fraction: 0.15884
Policy Update Magnitude: 0.49645
Value Function Update Magnitude: 0.56150

Collected Steps per Second: 21,751.68258
Overall Steps per Second: 10,342.03610

Timestep Collection Time: 2.30014
Timestep Consumption Time: 2.53759
PPO Batch Consumption Time: 0.28916
Total Iteration Time: 4.83773

Cumulative Model Updates: 103,102
Cumulative Timesteps: 859,737,804

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 859737804...
Checkpoint 859737804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 204,724.82004
Policy Entropy: 3.67781
Value Function Loss: 0.03173

Mean KL Divergence: 0.01297
SB3 Clip Fraction: 0.17453
Policy Update Magnitude: 0.44013
Value Function Update Magnitude: 0.57789

Collected Steps per Second: 21,462.38610
Overall Steps per Second: 10,260.90612

Timestep Collection Time: 2.33096
Timestep Consumption Time: 2.54463
PPO Batch Consumption Time: 0.29358
Total Iteration Time: 4.87559

Cumulative Model Updates: 103,108
Cumulative Timesteps: 859,787,832

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63,738.31523
Policy Entropy: 3.66916
Value Function Loss: 0.04141

Mean KL Divergence: 0.01184
SB3 Clip Fraction: 0.15997
Policy Update Magnitude: 0.45233
Value Function Update Magnitude: 0.61496

Collected Steps per Second: 21,410.43624
Overall Steps per Second: 10,202.35840

Timestep Collection Time: 2.33662
Timestep Consumption Time: 2.56695
PPO Batch Consumption Time: 0.29682
Total Iteration Time: 4.90357

Cumulative Model Updates: 103,114
Cumulative Timesteps: 859,837,860

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 859837860...
Checkpoint 859837860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 101,613.97539
Policy Entropy: 3.66567
Value Function Loss: 0.04363

Mean KL Divergence: 0.01241
SB3 Clip Fraction: 0.16443
Policy Update Magnitude: 0.46153
Value Function Update Magnitude: 0.55271

Collected Steps per Second: 21,608.69158
Overall Steps per Second: 10,371.21782

Timestep Collection Time: 2.31499
Timestep Consumption Time: 2.50835
PPO Batch Consumption Time: 0.28876
Total Iteration Time: 4.82335

Cumulative Model Updates: 103,120
Cumulative Timesteps: 859,887,884

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 101,613.97539
Policy Entropy: 3.68510
Value Function Loss: 0.03365

Mean KL Divergence: 0.01189
SB3 Clip Fraction: 0.15591
Policy Update Magnitude: 0.51377
Value Function Update Magnitude: 0.59470

Collected Steps per Second: 21,852.51761
Overall Steps per Second: 10,432.54284

Timestep Collection Time: 2.28935
Timestep Consumption Time: 2.50603
PPO Batch Consumption Time: 0.28888
Total Iteration Time: 4.79538

Cumulative Model Updates: 103,126
Cumulative Timesteps: 859,937,912

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 859937912...
Checkpoint 859937912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 101,613.97539
Policy Entropy: 3.68340
Value Function Loss: 0.03168

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.13914
Policy Update Magnitude: 0.53751
Value Function Update Magnitude: 0.52395

Collected Steps per Second: 21,158.59601
Overall Steps per Second: 10,311.31971

Timestep Collection Time: 2.36367
Timestep Consumption Time: 2.48653
PPO Batch Consumption Time: 0.29796
Total Iteration Time: 4.85020

Cumulative Model Updates: 103,132
Cumulative Timesteps: 859,987,924

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 405,497.21085
Policy Entropy: 3.67121
Value Function Loss: 0.02965

Mean KL Divergence: 0.01261
SB3 Clip Fraction: 0.17014
Policy Update Magnitude: 0.49406
Value Function Update Magnitude: 0.55617

Collected Steps per Second: 20,653.77766
Overall Steps per Second: 10,176.06376

Timestep Collection Time: 2.42299
Timestep Consumption Time: 2.49482
PPO Batch Consumption Time: 0.29708
Total Iteration Time: 4.91782

Cumulative Model Updates: 103,138
Cumulative Timesteps: 860,037,968

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 860037968...
Checkpoint 860037968 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 92,766.27898
Policy Entropy: 3.65910
Value Function Loss: 0.03649

Mean KL Divergence: 0.01274
SB3 Clip Fraction: 0.16122
Policy Update Magnitude: 0.47967
Value Function Update Magnitude: 0.55303

Collected Steps per Second: 20,896.72010
Overall Steps per Second: 10,276.35367

Timestep Collection Time: 2.39387
Timestep Consumption Time: 2.47401
PPO Batch Consumption Time: 0.29594
Total Iteration Time: 4.86787

Cumulative Model Updates: 103,144
Cumulative Timesteps: 860,087,992

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 384,588.72313
Policy Entropy: 3.68433
Value Function Loss: 0.03948

Mean KL Divergence: 0.01145
SB3 Clip Fraction: 0.14973
Policy Update Magnitude: 0.52379
Value Function Update Magnitude: 0.53086

Collected Steps per Second: 20,721.22663
Overall Steps per Second: 10,206.30453

Timestep Collection Time: 2.41366
Timestep Consumption Time: 2.48664
PPO Batch Consumption Time: 0.28861
Total Iteration Time: 4.90030

Cumulative Model Updates: 103,150
Cumulative Timesteps: 860,138,006

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 860138006...
Checkpoint 860138006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 52,179.24593
Policy Entropy: 3.70002
Value Function Loss: 0.04752

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.13389
Policy Update Magnitude: 0.57942
Value Function Update Magnitude: 0.53985

Collected Steps per Second: 21,548.19582
Overall Steps per Second: 10,251.83383

Timestep Collection Time: 2.32112
Timestep Consumption Time: 2.55761
PPO Batch Consumption Time: 0.30078
Total Iteration Time: 4.87874

Cumulative Model Updates: 103,156
Cumulative Timesteps: 860,188,022

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,963.40218
Policy Entropy: 3.71771
Value Function Loss: 0.04224

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.13259
Policy Update Magnitude: 0.57101
Value Function Update Magnitude: 0.61977

Collected Steps per Second: 21,508.00827
Overall Steps per Second: 10,403.54960

Timestep Collection Time: 2.32546
Timestep Consumption Time: 2.48213
PPO Batch Consumption Time: 0.28746
Total Iteration Time: 4.80759

Cumulative Model Updates: 103,162
Cumulative Timesteps: 860,238,038

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 860238038...
Checkpoint 860238038 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,852.15628
Policy Entropy: 3.70320
Value Function Loss: 0.03887

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.14199
Policy Update Magnitude: 0.54130
Value Function Update Magnitude: 0.59394

Collected Steps per Second: 21,675.74893
Overall Steps per Second: 10,271.00325

Timestep Collection Time: 2.30783
Timestep Consumption Time: 2.56258
PPO Batch Consumption Time: 0.29836
Total Iteration Time: 4.87041

Cumulative Model Updates: 103,168
Cumulative Timesteps: 860,288,062

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,852.15628
Policy Entropy: 3.70545
Value Function Loss: 0.03019

Mean KL Divergence: 0.01071
SB3 Clip Fraction: 0.14917
Policy Update Magnitude: 0.47215
Value Function Update Magnitude: 0.52055

Collected Steps per Second: 21,579.15022
Overall Steps per Second: 10,364.23048

Timestep Collection Time: 2.31751
Timestep Consumption Time: 2.50773
PPO Batch Consumption Time: 0.28789
Total Iteration Time: 4.82525

Cumulative Model Updates: 103,174
Cumulative Timesteps: 860,338,072

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 860338072...
Checkpoint 860338072 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,852.15628
Policy Entropy: 3.68033
Value Function Loss: 0.02600

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.14400
Policy Update Magnitude: 0.39898
Value Function Update Magnitude: 0.46826

Collected Steps per Second: 19,036.98154
Overall Steps per Second: 9,327.30419

Timestep Collection Time: 2.62647
Timestep Consumption Time: 2.73414
PPO Batch Consumption Time: 0.30212
Total Iteration Time: 5.36061

Cumulative Model Updates: 103,180
Cumulative Timesteps: 860,388,072

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,852.15628
Policy Entropy: 3.67440
Value Function Loss: 0.02420

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.14312
Policy Update Magnitude: 0.36617
Value Function Update Magnitude: 0.46962

Collected Steps per Second: 21,524.23665
Overall Steps per Second: 10,245.07369

Timestep Collection Time: 2.32371
Timestep Consumption Time: 2.55825
PPO Batch Consumption Time: 0.29562
Total Iteration Time: 4.88196

Cumulative Model Updates: 103,186
Cumulative Timesteps: 860,438,088

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 860438088...
Checkpoint 860438088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,852.15628
Policy Entropy: 3.67192
Value Function Loss: 0.02627

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.14477
Policy Update Magnitude: 0.35858
Value Function Update Magnitude: 0.47145

Collected Steps per Second: 21,539.79700
Overall Steps per Second: 10,226.01852

Timestep Collection Time: 2.32175
Timestep Consumption Time: 2.56872
PPO Batch Consumption Time: 0.29984
Total Iteration Time: 4.89047

Cumulative Model Updates: 103,192
Cumulative Timesteps: 860,488,098

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,852.15628
Policy Entropy: 3.67430
Value Function Loss: 0.02877

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.14659
Policy Update Magnitude: 0.37273
Value Function Update Magnitude: 0.43449

Collected Steps per Second: 21,473.78579
Overall Steps per Second: 10,340.52991

Timestep Collection Time: 2.32954
Timestep Consumption Time: 2.50813
PPO Batch Consumption Time: 0.28809
Total Iteration Time: 4.83766

Cumulative Model Updates: 103,198
Cumulative Timesteps: 860,538,122

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 860538122...
Checkpoint 860538122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,301.43003
Policy Entropy: 3.68094
Value Function Loss: 0.02711

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.14609
Policy Update Magnitude: 0.39118
Value Function Update Magnitude: 0.39598

Collected Steps per Second: 20,725.06751
Overall Steps per Second: 10,325.72469

Timestep Collection Time: 2.41408
Timestep Consumption Time: 2.43129
PPO Batch Consumption Time: 0.29024
Total Iteration Time: 4.84537

Cumulative Model Updates: 103,204
Cumulative Timesteps: 860,588,154

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 158,794.75377
Policy Entropy: 3.68965
Value Function Loss: 0.02734

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.14397
Policy Update Magnitude: 0.41554
Value Function Update Magnitude: 0.48691

Collected Steps per Second: 20,559.20799
Overall Steps per Second: 10,218.24346

Timestep Collection Time: 2.43297
Timestep Consumption Time: 2.46219
PPO Batch Consumption Time: 0.29497
Total Iteration Time: 4.89517

Cumulative Model Updates: 103,210
Cumulative Timesteps: 860,638,174

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 860638174...
Checkpoint 860638174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,854.66310
Policy Entropy: 3.68740
Value Function Loss: 0.03092

Mean KL Divergence: 0.01047
SB3 Clip Fraction: 0.14582
Policy Update Magnitude: 0.45171
Value Function Update Magnitude: 0.66808

Collected Steps per Second: 21,115.55223
Overall Steps per Second: 10,330.78039

Timestep Collection Time: 2.36840
Timestep Consumption Time: 2.47248
PPO Batch Consumption Time: 0.28759
Total Iteration Time: 4.84087

Cumulative Model Updates: 103,216
Cumulative Timesteps: 860,688,184

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 291,876.73141
Policy Entropy: 3.68133
Value Function Loss: 0.03941

Mean KL Divergence: 0.01116
SB3 Clip Fraction: 0.14958
Policy Update Magnitude: 0.48145
Value Function Update Magnitude: 0.60921

Collected Steps per Second: 21,014.28183
Overall Steps per Second: 10,132.13005

Timestep Collection Time: 2.37943
Timestep Consumption Time: 2.55556
PPO Batch Consumption Time: 0.30239
Total Iteration Time: 4.93499

Cumulative Model Updates: 103,222
Cumulative Timesteps: 860,738,186

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 860738186...
Checkpoint 860738186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 54,104.47327
Policy Entropy: 3.68322
Value Function Loss: 0.04184

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.14747
Policy Update Magnitude: 0.50679
Value Function Update Magnitude: 0.45460

Collected Steps per Second: 21,190.59626
Overall Steps per Second: 10,205.44951

Timestep Collection Time: 2.36001
Timestep Consumption Time: 2.54031
PPO Batch Consumption Time: 0.29992
Total Iteration Time: 4.90032

Cumulative Model Updates: 103,228
Cumulative Timesteps: 860,788,196

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,872.62200
Policy Entropy: 3.68484
Value Function Loss: 0.04050

Mean KL Divergence: 0.01104
SB3 Clip Fraction: 0.15015
Policy Update Magnitude: 0.51622
Value Function Update Magnitude: 0.43017

Collected Steps per Second: 21,760.35976
Overall Steps per Second: 10,386.93870

Timestep Collection Time: 2.29840
Timestep Consumption Time: 2.51669
PPO Batch Consumption Time: 0.28794
Total Iteration Time: 4.81509

Cumulative Model Updates: 103,234
Cumulative Timesteps: 860,838,210

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 860838210...
Checkpoint 860838210 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 52,406.78408
Policy Entropy: 3.69733
Value Function Loss: 0.03453

Mean KL Divergence: 0.01116
SB3 Clip Fraction: 0.14630
Policy Update Magnitude: 0.48370
Value Function Update Magnitude: 0.44886

Collected Steps per Second: 21,630.36241
Overall Steps per Second: 10,291.02254

Timestep Collection Time: 2.31286
Timestep Consumption Time: 2.54846
PPO Batch Consumption Time: 0.29582
Total Iteration Time: 4.86132

Cumulative Model Updates: 103,240
Cumulative Timesteps: 860,888,238

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,816.16124
Policy Entropy: 3.69663
Value Function Loss: 0.03023

Mean KL Divergence: 0.01103
SB3 Clip Fraction: 0.15051
Policy Update Magnitude: 0.44832
Value Function Update Magnitude: 0.56945

Collected Steps per Second: 21,099.37096
Overall Steps per Second: 10,140.29647

Timestep Collection Time: 2.37059
Timestep Consumption Time: 2.56201
PPO Batch Consumption Time: 0.29831
Total Iteration Time: 4.93260

Cumulative Model Updates: 103,246
Cumulative Timesteps: 860,938,256

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 860938256...
Checkpoint 860938256 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,380.73553
Policy Entropy: 3.70706
Value Function Loss: 0.02726

Mean KL Divergence: 0.01085
SB3 Clip Fraction: 0.14947
Policy Update Magnitude: 0.40671
Value Function Update Magnitude: 0.60704

Collected Steps per Second: 21,422.48983
Overall Steps per Second: 10,226.20357

Timestep Collection Time: 2.33409
Timestep Consumption Time: 2.55551
PPO Batch Consumption Time: 0.29771
Total Iteration Time: 4.88960

Cumulative Model Updates: 103,252
Cumulative Timesteps: 860,988,258

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,215.33154
Policy Entropy: 3.67925
Value Function Loss: 0.02911

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.14310
Policy Update Magnitude: 0.38196
Value Function Update Magnitude: 0.45037

Collected Steps per Second: 21,788.51425
Overall Steps per Second: 10,311.46446

Timestep Collection Time: 2.29515
Timestep Consumption Time: 2.55459
PPO Batch Consumption Time: 0.29673
Total Iteration Time: 4.84975

Cumulative Model Updates: 103,258
Cumulative Timesteps: 861,038,266

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 861038266...
Checkpoint 861038266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,215.33154
Policy Entropy: 3.70060
Value Function Loss: 0.02642

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.14063
Policy Update Magnitude: 0.37831
Value Function Update Magnitude: 0.35115

Collected Steps per Second: 21,516.59801
Overall Steps per Second: 10,229.34228

Timestep Collection Time: 2.32500
Timestep Consumption Time: 2.56545
PPO Batch Consumption Time: 0.30122
Total Iteration Time: 4.89044

Cumulative Model Updates: 103,264
Cumulative Timesteps: 861,088,292

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,215.33154
Policy Entropy: 3.69731
Value Function Loss: 0.02489

Mean KL Divergence: 0.01067
SB3 Clip Fraction: 0.15008
Policy Update Magnitude: 0.38218
Value Function Update Magnitude: 0.33813

Collected Steps per Second: 20,938.53103
Overall Steps per Second: 10,366.12507

Timestep Collection Time: 2.38842
Timestep Consumption Time: 2.43595
PPO Batch Consumption Time: 0.28850
Total Iteration Time: 4.82437

Cumulative Model Updates: 103,270
Cumulative Timesteps: 861,138,302

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 861138302...
Checkpoint 861138302 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,215.33154
Policy Entropy: 3.70794
Value Function Loss: 0.02178

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.14635
Policy Update Magnitude: 0.37737
Value Function Update Magnitude: 0.34733

Collected Steps per Second: 20,702.65054
Overall Steps per Second: 10,282.30504

Timestep Collection Time: 2.41534
Timestep Consumption Time: 2.44777
PPO Batch Consumption Time: 0.29145
Total Iteration Time: 4.86311

Cumulative Model Updates: 103,276
Cumulative Timesteps: 861,188,306

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,215.33154
Policy Entropy: 3.70126
Value Function Loss: 0.02165

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.14057
Policy Update Magnitude: 0.37417
Value Function Update Magnitude: 0.31366

Collected Steps per Second: 20,752.90390
Overall Steps per Second: 10,341.95866

Timestep Collection Time: 2.41027
Timestep Consumption Time: 2.42634
PPO Batch Consumption Time: 0.28801
Total Iteration Time: 4.83661

Cumulative Model Updates: 103,282
Cumulative Timesteps: 861,238,326

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 861238326...
Checkpoint 861238326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,215.33154
Policy Entropy: 3.68557
Value Function Loss: 0.02340

Mean KL Divergence: 0.01104
SB3 Clip Fraction: 0.15114
Policy Update Magnitude: 0.37466
Value Function Update Magnitude: 0.33051

Collected Steps per Second: 21,000.12199
Overall Steps per Second: 10,282.08183

Timestep Collection Time: 2.38132
Timestep Consumption Time: 2.48229
PPO Batch Consumption Time: 0.28782
Total Iteration Time: 4.86361

Cumulative Model Updates: 103,288
Cumulative Timesteps: 861,288,334

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,215.33154
Policy Entropy: 3.69318
Value Function Loss: 0.02387

Mean KL Divergence: 0.01125
SB3 Clip Fraction: 0.15214
Policy Update Magnitude: 0.35735
Value Function Update Magnitude: 0.38466

Collected Steps per Second: 21,502.03339
Overall Steps per Second: 10,357.28469

Timestep Collection Time: 2.32555
Timestep Consumption Time: 2.50236
PPO Batch Consumption Time: 0.28796
Total Iteration Time: 4.82791

Cumulative Model Updates: 103,294
Cumulative Timesteps: 861,338,338

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 861338338...
Checkpoint 861338338 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,215.33154
Policy Entropy: 3.69532
Value Function Loss: 0.02312

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.14611
Policy Update Magnitude: 0.35654
Value Function Update Magnitude: 0.44478

Collected Steps per Second: 21,422.08178
Overall Steps per Second: 10,184.47736

Timestep Collection Time: 2.33647
Timestep Consumption Time: 2.57807
PPO Batch Consumption Time: 0.30097
Total Iteration Time: 4.91454

Cumulative Model Updates: 103,300
Cumulative Timesteps: 861,388,390

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,215.33154
Policy Entropy: 3.69691
Value Function Loss: 0.02019

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.14010
Policy Update Magnitude: 0.34749
Value Function Update Magnitude: 0.46389

Collected Steps per Second: 21,805.47369
Overall Steps per Second: 10,254.85675

Timestep Collection Time: 2.29328
Timestep Consumption Time: 2.58305
PPO Batch Consumption Time: 0.29984
Total Iteration Time: 4.87632

Cumulative Model Updates: 103,306
Cumulative Timesteps: 861,438,396

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 861438396...
Checkpoint 861438396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 190,105.02958
Policy Entropy: 3.70128
Value Function Loss: 0.02319

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.14144
Policy Update Magnitude: 0.34093
Value Function Update Magnitude: 0.43666

Collected Steps per Second: 21,575.03910
Overall Steps per Second: 10,270.30217

Timestep Collection Time: 2.31870
Timestep Consumption Time: 2.55224
PPO Batch Consumption Time: 0.29855
Total Iteration Time: 4.87094

Cumulative Model Updates: 103,312
Cumulative Timesteps: 861,488,422

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 153,981.53904
Policy Entropy: 3.70459
Value Function Loss: 0.02393

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.13749
Policy Update Magnitude: 0.37644
Value Function Update Magnitude: 0.42848

Collected Steps per Second: 21,628.40438
Overall Steps per Second: 10,306.18391

Timestep Collection Time: 2.31270
Timestep Consumption Time: 2.54070
PPO Batch Consumption Time: 0.29180
Total Iteration Time: 4.85340

Cumulative Model Updates: 103,318
Cumulative Timesteps: 861,538,442

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 861538442...
Checkpoint 861538442 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 153,981.53904
Policy Entropy: 3.68566
Value Function Loss: 0.02542

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.14068
Policy Update Magnitude: 0.40638
Value Function Update Magnitude: 0.52898

Collected Steps per Second: 21,383.51852
Overall Steps per Second: 10,240.87430

Timestep Collection Time: 2.33909
Timestep Consumption Time: 2.54506
PPO Batch Consumption Time: 0.29435
Total Iteration Time: 4.88415

Cumulative Model Updates: 103,324
Cumulative Timesteps: 861,588,460

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 153,981.53904
Policy Entropy: 3.68332
Value Function Loss: 0.02625

Mean KL Divergence: 0.01091
SB3 Clip Fraction: 0.14725
Policy Update Magnitude: 0.40748
Value Function Update Magnitude: 0.48069

Collected Steps per Second: 20,807.32418
Overall Steps per Second: 10,347.74055

Timestep Collection Time: 2.40444
Timestep Consumption Time: 2.43043
PPO Batch Consumption Time: 0.28818
Total Iteration Time: 4.83487

Cumulative Model Updates: 103,330
Cumulative Timesteps: 861,638,490

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 861638490...
Checkpoint 861638490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 153,981.53904
Policy Entropy: 3.67932
Value Function Loss: 0.02884

Mean KL Divergence: 0.01080
SB3 Clip Fraction: 0.14707
Policy Update Magnitude: 0.41460
Value Function Update Magnitude: 0.37008

Collected Steps per Second: 20,974.04681
Overall Steps per Second: 10,331.41242

Timestep Collection Time: 2.38533
Timestep Consumption Time: 2.45718
PPO Batch Consumption Time: 0.29521
Total Iteration Time: 4.84251

Cumulative Model Updates: 103,336
Cumulative Timesteps: 861,688,520

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 153,981.53904
Policy Entropy: 3.69104
Value Function Loss: 0.02568

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.13977
Policy Update Magnitude: 0.42097
Value Function Update Magnitude: 0.32799

Collected Steps per Second: 20,977.15556
Overall Steps per Second: 10,376.53375

Timestep Collection Time: 2.38383
Timestep Consumption Time: 2.43531
PPO Batch Consumption Time: 0.28853
Total Iteration Time: 4.81914

Cumulative Model Updates: 103,342
Cumulative Timesteps: 861,738,526

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 861738526...
Checkpoint 861738526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 153,981.53904
Policy Entropy: 3.67460
Value Function Loss: 0.02831

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.14184
Policy Update Magnitude: 0.44324
Value Function Update Magnitude: 0.37611

Collected Steps per Second: 20,442.75999
Overall Steps per Second: 10,136.13853

Timestep Collection Time: 2.44673
Timestep Consumption Time: 2.48789
PPO Batch Consumption Time: 0.28864
Total Iteration Time: 4.93462

Cumulative Model Updates: 103,348
Cumulative Timesteps: 861,788,544

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 153,981.53904
Policy Entropy: 3.68038
Value Function Loss: 0.02766

Mean KL Divergence: 0.01055
SB3 Clip Fraction: 0.14218
Policy Update Magnitude: 0.47155
Value Function Update Magnitude: 0.39513

Collected Steps per Second: 21,682.69766
Overall Steps per Second: 10,374.57302

Timestep Collection Time: 2.30709
Timestep Consumption Time: 2.51470
PPO Batch Consumption Time: 0.29424
Total Iteration Time: 4.82179

Cumulative Model Updates: 103,354
Cumulative Timesteps: 861,838,568

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 861838568...
Checkpoint 861838568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 298,536.09077
Policy Entropy: 3.66802
Value Function Loss: 0.03339

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.13519
Policy Update Magnitude: 0.46758
Value Function Update Magnitude: 0.34953

Collected Steps per Second: 21,352.77995
Overall Steps per Second: 10,367.68849

Timestep Collection Time: 2.34208
Timestep Consumption Time: 2.48156
PPO Batch Consumption Time: 0.28852
Total Iteration Time: 4.82364

Cumulative Model Updates: 103,360
Cumulative Timesteps: 861,888,578

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84,326.15289
Policy Entropy: 3.69387
Value Function Loss: 0.02573

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.13608
Policy Update Magnitude: 0.46091
Value Function Update Magnitude: 0.46044

Collected Steps per Second: 21,392.50297
Overall Steps per Second: 10,168.98385

Timestep Collection Time: 2.33736
Timestep Consumption Time: 2.57975
PPO Batch Consumption Time: 0.29903
Total Iteration Time: 4.91711

Cumulative Model Updates: 103,366
Cumulative Timesteps: 861,938,580

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 861938580...
Checkpoint 861938580 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,398.95184
Policy Entropy: 3.68582
Value Function Loss: 0.02698

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.13764
Policy Update Magnitude: 0.45111
Value Function Update Magnitude: 0.51556

Collected Steps per Second: 21,541.70834
Overall Steps per Second: 10,102.57168

Timestep Collection Time: 2.32219
Timestep Consumption Time: 2.62942
PPO Batch Consumption Time: 0.31068
Total Iteration Time: 4.95161

Cumulative Model Updates: 103,372
Cumulative Timesteps: 861,988,604

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,295.50094
Policy Entropy: 3.70771
Value Function Loss: 0.02615

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.13619
Policy Update Magnitude: 0.45290
Value Function Update Magnitude: 0.39602

Collected Steps per Second: 21,868.15582
Overall Steps per Second: 10,269.97074

Timestep Collection Time: 2.28698
Timestep Consumption Time: 2.58275
PPO Batch Consumption Time: 0.29633
Total Iteration Time: 4.86973

Cumulative Model Updates: 103,378
Cumulative Timesteps: 862,038,616

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 862038616...
Checkpoint 862038616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 81,443.47666
Policy Entropy: 3.69687
Value Function Loss: 0.02923

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.13473
Policy Update Magnitude: 0.43002
Value Function Update Magnitude: 0.33151

Collected Steps per Second: 21,732.49833
Overall Steps per Second: 10,450.01344

Timestep Collection Time: 2.30171
Timestep Consumption Time: 2.48507
PPO Batch Consumption Time: 0.28620
Total Iteration Time: 4.78679

Cumulative Model Updates: 103,384
Cumulative Timesteps: 862,088,638

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,008.58625
Policy Entropy: 3.70103
Value Function Loss: 0.02698

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.14136
Policy Update Magnitude: 0.43426
Value Function Update Magnitude: 0.35659

Collected Steps per Second: 21,617.81328
Overall Steps per Second: 10,348.13250

Timestep Collection Time: 2.31356
Timestep Consumption Time: 2.51959
PPO Batch Consumption Time: 0.28882
Total Iteration Time: 4.83314

Cumulative Model Updates: 103,390
Cumulative Timesteps: 862,138,652

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 862138652...
Checkpoint 862138652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,029.56547
Policy Entropy: 3.69568
Value Function Loss: 0.02673

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.13758
Policy Update Magnitude: 0.41744
Value Function Update Magnitude: 0.40619

Collected Steps per Second: 21,395.46948
Overall Steps per Second: 10,293.52860

Timestep Collection Time: 2.33713
Timestep Consumption Time: 2.52068
PPO Batch Consumption Time: 0.28995
Total Iteration Time: 4.85781

Cumulative Model Updates: 103,396
Cumulative Timesteps: 862,188,656

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,029.56547
Policy Entropy: 3.68491
Value Function Loss: 0.02750

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.13621
Policy Update Magnitude: 0.43428
Value Function Update Magnitude: 0.45580

Collected Steps per Second: 21,891.74478
Overall Steps per Second: 10,421.86222

Timestep Collection Time: 2.28433
Timestep Consumption Time: 2.51404
PPO Batch Consumption Time: 0.28843
Total Iteration Time: 4.79837

Cumulative Model Updates: 103,402
Cumulative Timesteps: 862,238,664

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 862238664...
Checkpoint 862238664 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,029.56547
Policy Entropy: 3.69327
Value Function Loss: 0.02628

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.13592
Policy Update Magnitude: 0.45594
Value Function Update Magnitude: 0.59547

Collected Steps per Second: 21,513.12105
Overall Steps per Second: 10,257.61408

Timestep Collection Time: 2.32528
Timestep Consumption Time: 2.55149
PPO Batch Consumption Time: 0.29572
Total Iteration Time: 4.87677

Cumulative Model Updates: 103,408
Cumulative Timesteps: 862,288,688

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,029.56547
Policy Entropy: 3.67229
Value Function Loss: 0.02898

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.13759
Policy Update Magnitude: 0.45542
Value Function Update Magnitude: 0.59243

Collected Steps per Second: 22,120.65257
Overall Steps per Second: 10,388.08216

Timestep Collection Time: 2.26069
Timestep Consumption Time: 2.55329
PPO Batch Consumption Time: 0.29324
Total Iteration Time: 4.81398

Cumulative Model Updates: 103,414
Cumulative Timesteps: 862,338,696

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 862338696...
Checkpoint 862338696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,029.56547
Policy Entropy: 3.68029
Value Function Loss: 0.02415

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.13858
Policy Update Magnitude: 0.48953
Value Function Update Magnitude: 0.52253

Collected Steps per Second: 21,247.05933
Overall Steps per Second: 10,265.42750

Timestep Collection Time: 2.35440
Timestep Consumption Time: 2.51866
PPO Batch Consumption Time: 0.29007
Total Iteration Time: 4.87306

Cumulative Model Updates: 103,420
Cumulative Timesteps: 862,388,720

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,029.56547
Policy Entropy: 3.63446
Value Function Loss: 0.03088

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.13839
Policy Update Magnitude: 0.49618
Value Function Update Magnitude: 0.58998

Collected Steps per Second: 21,466.56651
Overall Steps per Second: 10,351.91289

Timestep Collection Time: 2.33041
Timestep Consumption Time: 2.50212
PPO Batch Consumption Time: 0.28866
Total Iteration Time: 4.83254

Cumulative Model Updates: 103,426
Cumulative Timesteps: 862,438,746

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 862438746...
Checkpoint 862438746 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 112,807.35370
Policy Entropy: 3.66089
Value Function Loss: 0.03095

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.13862
Policy Update Magnitude: 0.57762
Value Function Update Magnitude: 0.58705

Collected Steps per Second: 21,132.29642
Overall Steps per Second: 10,269.88734

Timestep Collection Time: 2.36652
Timestep Consumption Time: 2.50306
PPO Batch Consumption Time: 0.28831
Total Iteration Time: 4.86958

Cumulative Model Updates: 103,432
Cumulative Timesteps: 862,488,756

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,334.82924
Policy Entropy: 3.65609
Value Function Loss: 0.03401

Mean KL Divergence: 0.01085
SB3 Clip Fraction: 0.14306
Policy Update Magnitude: 0.59549
Value Function Update Magnitude: 0.58764

Collected Steps per Second: 21,673.16712
Overall Steps per Second: 10,378.08171

Timestep Collection Time: 2.30866
Timestep Consumption Time: 2.51265
PPO Batch Consumption Time: 0.28825
Total Iteration Time: 4.82131

Cumulative Model Updates: 103,438
Cumulative Timesteps: 862,538,792

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 862538792...
Checkpoint 862538792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,334.82924
Policy Entropy: 3.69900
Value Function Loss: 0.03253

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.13482
Policy Update Magnitude: 0.58200
Value Function Update Magnitude: 0.61639

Collected Steps per Second: 20,673.44999
Overall Steps per Second: 10,340.54173

Timestep Collection Time: 2.41992
Timestep Consumption Time: 2.41813
PPO Batch Consumption Time: 0.28681
Total Iteration Time: 4.83804

Cumulative Model Updates: 103,444
Cumulative Timesteps: 862,588,820

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 216,603.55473
Policy Entropy: 3.67932
Value Function Loss: 0.03115

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.13610
Policy Update Magnitude: 0.56731
Value Function Update Magnitude: 0.61882

Collected Steps per Second: 20,960.78171
Overall Steps per Second: 10,182.85857

Timestep Collection Time: 2.38588
Timestep Consumption Time: 2.52531
PPO Batch Consumption Time: 0.30320
Total Iteration Time: 4.91119

Cumulative Model Updates: 103,450
Cumulative Timesteps: 862,638,830

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 862638830...
Checkpoint 862638830 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 542,915.69747
Policy Entropy: 3.68429
Value Function Loss: 0.03186

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.13942
Policy Update Magnitude: 0.55385
Value Function Update Magnitude: 0.60701

Collected Steps per Second: 20,386.16504
Overall Steps per Second: 10,164.05308

Timestep Collection Time: 2.45372
Timestep Consumption Time: 2.46774
PPO Batch Consumption Time: 0.29708
Total Iteration Time: 4.92146

Cumulative Model Updates: 103,456
Cumulative Timesteps: 862,688,852

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 233,712.77518
Policy Entropy: 3.68557
Value Function Loss: 0.02927

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.13964
Policy Update Magnitude: 0.53435
Value Function Update Magnitude: 0.56787

Collected Steps per Second: 20,925.62715
Overall Steps per Second: 10,237.27784

Timestep Collection Time: 2.38961
Timestep Consumption Time: 2.49490
PPO Batch Consumption Time: 0.28852
Total Iteration Time: 4.88450

Cumulative Model Updates: 103,462
Cumulative Timesteps: 862,738,856

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 862738856...
Checkpoint 862738856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 283,980.45274
Policy Entropy: 3.69055
Value Function Loss: 0.02900

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.13786
Policy Update Magnitude: 0.49871
Value Function Update Magnitude: 0.59331

Collected Steps per Second: 20,990.82203
Overall Steps per Second: 10,267.80552

Timestep Collection Time: 2.38257
Timestep Consumption Time: 2.48819
PPO Batch Consumption Time: 0.28838
Total Iteration Time: 4.87076

Cumulative Model Updates: 103,468
Cumulative Timesteps: 862,788,868

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 187,752.41621
Policy Entropy: 3.69547
Value Function Loss: 0.02814

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.13805
Policy Update Magnitude: 0.46030
Value Function Update Magnitude: 0.62373

Collected Steps per Second: 21,686.07922
Overall Steps per Second: 10,454.80710

Timestep Collection Time: 2.30655
Timestep Consumption Time: 2.47785
PPO Batch Consumption Time: 0.28783
Total Iteration Time: 4.78440

Cumulative Model Updates: 103,474
Cumulative Timesteps: 862,838,888

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 862838888...
Checkpoint 862838888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 461,209.51553
Policy Entropy: 3.68071
Value Function Loss: 0.02986

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.13634
Policy Update Magnitude: 0.46660
Value Function Update Magnitude: 0.67603

Collected Steps per Second: 21,407.39958
Overall Steps per Second: 10,271.14960

Timestep Collection Time: 2.33676
Timestep Consumption Time: 2.53358
PPO Batch Consumption Time: 0.29356
Total Iteration Time: 4.87034

Cumulative Model Updates: 103,480
Cumulative Timesteps: 862,888,912

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 461,209.51553
Policy Entropy: 3.68375
Value Function Loss: 0.03057

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.14274
Policy Update Magnitude: 0.48992
Value Function Update Magnitude: 0.71434

Collected Steps per Second: 21,524.28011
Overall Steps per Second: 10,328.16140

Timestep Collection Time: 2.32417
Timestep Consumption Time: 2.51948
PPO Batch Consumption Time: 0.28941
Total Iteration Time: 4.84365

Cumulative Model Updates: 103,486
Cumulative Timesteps: 862,938,938

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 862938938...
Checkpoint 862938938 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 461,209.51553
Policy Entropy: 3.68320
Value Function Loss: 0.03136

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.14831
Policy Update Magnitude: 0.46848
Value Function Update Magnitude: 0.58398

Collected Steps per Second: 21,491.94179
Overall Steps per Second: 10,330.34357

Timestep Collection Time: 2.32701
Timestep Consumption Time: 2.51426
PPO Batch Consumption Time: 0.29094
Total Iteration Time: 4.84127

Cumulative Model Updates: 103,492
Cumulative Timesteps: 862,988,950

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 461,209.51553
Policy Entropy: 3.68158
Value Function Loss: 0.03015

Mean KL Divergence: 0.01104
SB3 Clip Fraction: 0.14703
Policy Update Magnitude: 0.45631
Value Function Update Magnitude: 0.48257

Collected Steps per Second: 21,546.64393
Overall Steps per Second: 10,377.64800

Timestep Collection Time: 2.32138
Timestep Consumption Time: 2.49840
PPO Batch Consumption Time: 0.28795
Total Iteration Time: 4.81978

Cumulative Model Updates: 103,498
Cumulative Timesteps: 863,038,968

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 863038968...
Checkpoint 863038968 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 461,209.51553
Policy Entropy: 3.66880
Value Function Loss: 0.03355

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.14070
Policy Update Magnitude: 0.45516
Value Function Update Magnitude: 0.41959

Collected Steps per Second: 20,681.65771
Overall Steps per Second: 10,145.50354

Timestep Collection Time: 2.41818
Timestep Consumption Time: 2.51129
PPO Batch Consumption Time: 0.28770
Total Iteration Time: 4.92947

Cumulative Model Updates: 103,504
Cumulative Timesteps: 863,088,980

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 598,594.41478
Policy Entropy: 3.67603
Value Function Loss: 0.03212

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.13728
Policy Update Magnitude: 0.46449
Value Function Update Magnitude: 0.41878

Collected Steps per Second: 21,629.93535
Overall Steps per Second: 10,250.89320

Timestep Collection Time: 2.31281
Timestep Consumption Time: 2.56735
PPO Batch Consumption Time: 0.29865
Total Iteration Time: 4.88016

Cumulative Model Updates: 103,510
Cumulative Timesteps: 863,139,006

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 863139006...
Checkpoint 863139006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 598,594.41478
Policy Entropy: 3.68065
Value Function Loss: 0.03112

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.14495
Policy Update Magnitude: 0.45042
Value Function Update Magnitude: 0.42653

Collected Steps per Second: 20,788.34994
Overall Steps per Second: 10,215.46207

Timestep Collection Time: 2.40519
Timestep Consumption Time: 2.48935
PPO Batch Consumption Time: 0.29974
Total Iteration Time: 4.89454

Cumulative Model Updates: 103,516
Cumulative Timesteps: 863,189,006

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 598,594.41478
Policy Entropy: 3.70274
Value Function Loss: 0.02547

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.14258
Policy Update Magnitude: 0.43904
Value Function Update Magnitude: 0.50654

Collected Steps per Second: 20,839.02906
Overall Steps per Second: 10,377.55091

Timestep Collection Time: 2.39982
Timestep Consumption Time: 2.41923
PPO Batch Consumption Time: 0.28601
Total Iteration Time: 4.81906

Cumulative Model Updates: 103,522
Cumulative Timesteps: 863,239,016

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 863239016...
Checkpoint 863239016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 533,405.38579
Policy Entropy: 3.69336
Value Function Loss: 0.02801

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.14076
Policy Update Magnitude: 0.44341
Value Function Update Magnitude: 0.57422

Collected Steps per Second: 20,423.54777
Overall Steps per Second: 10,072.59407

Timestep Collection Time: 2.44972
Timestep Consumption Time: 2.51742
PPO Batch Consumption Time: 0.28961
Total Iteration Time: 4.96714

Cumulative Model Updates: 103,528
Cumulative Timesteps: 863,289,048

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 441,881.49806
Policy Entropy: 3.70634
Value Function Loss: 0.03140

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.14122
Policy Update Magnitude: 0.48057
Value Function Update Magnitude: 0.68819

Collected Steps per Second: 21,211.78884
Overall Steps per Second: 10,189.09706

Timestep Collection Time: 2.35859
Timestep Consumption Time: 2.55156
PPO Batch Consumption Time: 0.29953
Total Iteration Time: 4.91015

Cumulative Model Updates: 103,534
Cumulative Timesteps: 863,339,078

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 863339078...
Checkpoint 863339078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 124,810.24790
Policy Entropy: 3.70297
Value Function Loss: 0.03450

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.13921
Policy Update Magnitude: 0.52180
Value Function Update Magnitude: 0.72658

Collected Steps per Second: 21,363.85446
Overall Steps per Second: 10,191.36353

Timestep Collection Time: 2.34134
Timestep Consumption Time: 2.56674
PPO Batch Consumption Time: 0.29987
Total Iteration Time: 4.90808

Cumulative Model Updates: 103,540
Cumulative Timesteps: 863,389,098

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 124,810.24790
Policy Entropy: 3.70694
Value Function Loss: 0.03127

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.13756
Policy Update Magnitude: 0.53075
Value Function Update Magnitude: 0.74135

Collected Steps per Second: 21,547.08594
Overall Steps per Second: 10,326.05788

Timestep Collection Time: 2.32050
Timestep Consumption Time: 2.52162
PPO Batch Consumption Time: 0.28805
Total Iteration Time: 4.84212

Cumulative Model Updates: 103,546
Cumulative Timesteps: 863,439,098

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 863439098...
Checkpoint 863439098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 124,810.24790
Policy Entropy: 3.67576
Value Function Loss: 0.03021

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.13369
Policy Update Magnitude: 0.49016
Value Function Update Magnitude: 0.66561

Collected Steps per Second: 21,552.92584
Overall Steps per Second: 10,323.63048

Timestep Collection Time: 2.32071
Timestep Consumption Time: 2.52430
PPO Batch Consumption Time: 0.29209
Total Iteration Time: 4.84500

Cumulative Model Updates: 103,552
Cumulative Timesteps: 863,489,116

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 124,810.24790
Policy Entropy: 3.68021
Value Function Loss: 0.02710

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.13899
Policy Update Magnitude: 0.44378
Value Function Update Magnitude: 0.50035

Collected Steps per Second: 21,103.40593
Overall Steps per Second: 10,116.87306

Timestep Collection Time: 2.37061
Timestep Consumption Time: 2.57439
PPO Batch Consumption Time: 0.30001
Total Iteration Time: 4.94501

Cumulative Model Updates: 103,558
Cumulative Timesteps: 863,539,144

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 863539144...
Checkpoint 863539144 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 218,298.28776
Policy Entropy: 3.68734
Value Function Loss: 0.03065

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.13773
Policy Update Magnitude: 0.42966
Value Function Update Magnitude: 0.46478

Collected Steps per Second: 21,437.11472
Overall Steps per Second: 10,187.33407

Timestep Collection Time: 2.33324
Timestep Consumption Time: 2.57658
PPO Batch Consumption Time: 0.30001
Total Iteration Time: 4.90982

Cumulative Model Updates: 103,564
Cumulative Timesteps: 863,589,162

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 116,025.80296
Policy Entropy: 3.72085
Value Function Loss: 0.02752

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.13962
Policy Update Magnitude: 0.45449
Value Function Update Magnitude: 0.64380

Collected Steps per Second: 21,582.77448
Overall Steps per Second: 10,341.75277

Timestep Collection Time: 2.31750
Timestep Consumption Time: 2.51901
PPO Batch Consumption Time: 0.28917
Total Iteration Time: 4.83651

Cumulative Model Updates: 103,570
Cumulative Timesteps: 863,639,180

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 863639180...
Checkpoint 863639180 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 215,035.95919
Policy Entropy: 3.70330
Value Function Loss: 0.03218

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.14071
Policy Update Magnitude: 0.44730
Value Function Update Magnitude: 0.50152

Collected Steps per Second: 21,420.39353
Overall Steps per Second: 10,207.21983

Timestep Collection Time: 2.33469
Timestep Consumption Time: 2.56478
PPO Batch Consumption Time: 0.29463
Total Iteration Time: 4.89947

Cumulative Model Updates: 103,576
Cumulative Timesteps: 863,689,190

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 215,035.95919
Policy Entropy: 3.71038
Value Function Loss: 0.02846

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.13557
Policy Update Magnitude: 0.46844
Value Function Update Magnitude: 0.41543

Collected Steps per Second: 20,882.29622
Overall Steps per Second: 10,249.66805

Timestep Collection Time: 2.39552
Timestep Consumption Time: 2.48503
PPO Batch Consumption Time: 0.29661
Total Iteration Time: 4.88055

Cumulative Model Updates: 103,582
Cumulative Timesteps: 863,739,214

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 863739214...
Checkpoint 863739214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 215,035.95919
Policy Entropy: 3.68173
Value Function Loss: 0.02835

Mean KL Divergence: 0.01053
SB3 Clip Fraction: 0.14020
Policy Update Magnitude: 0.46909
Value Function Update Magnitude: 0.49774

Collected Steps per Second: 20,895.27994
Overall Steps per Second: 10,348.88330

Timestep Collection Time: 2.39346
Timestep Consumption Time: 2.43914
PPO Batch Consumption Time: 0.28851
Total Iteration Time: 4.83260

Cumulative Model Updates: 103,588
Cumulative Timesteps: 863,789,226

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 215,035.95919
Policy Entropy: 3.68117
Value Function Loss: 0.02601

Mean KL Divergence: 0.01126
SB3 Clip Fraction: 0.14821
Policy Update Magnitude: 0.46939
Value Function Update Magnitude: 0.46410

Collected Steps per Second: 21,135.87959
Overall Steps per Second: 10,157.43558

Timestep Collection Time: 2.36574
Timestep Consumption Time: 2.55696
PPO Batch Consumption Time: 0.30080
Total Iteration Time: 4.92270

Cumulative Model Updates: 103,594
Cumulative Timesteps: 863,839,228

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 863839228...
Checkpoint 863839228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 215,035.95919
Policy Entropy: 3.68389
Value Function Loss: 0.02463

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.14078
Policy Update Magnitude: 0.45722
Value Function Update Magnitude: 0.48935

Collected Steps per Second: 21,334.96600
Overall Steps per Second: 10,222.20703

Timestep Collection Time: 2.34479
Timestep Consumption Time: 2.54907
PPO Batch Consumption Time: 0.30137
Total Iteration Time: 4.89386

Cumulative Model Updates: 103,600
Cumulative Timesteps: 863,889,254

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 215,035.95919
Policy Entropy: 3.68902
Value Function Loss: 0.02543

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.13901
Policy Update Magnitude: 0.44537
Value Function Update Magnitude: 0.52597

Collected Steps per Second: 20,533.10046
Overall Steps per Second: 9,986.12012

Timestep Collection Time: 2.43636
Timestep Consumption Time: 2.57319
PPO Batch Consumption Time: 0.30548
Total Iteration Time: 5.00955

Cumulative Model Updates: 103,606
Cumulative Timesteps: 863,939,280

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 863939280...
Checkpoint 863939280 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 215,035.95919
Policy Entropy: 3.70690
Value Function Loss: 0.02436

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.13581
Policy Update Magnitude: 0.45086
Value Function Update Magnitude: 0.47666

Collected Steps per Second: 21,159.59542
Overall Steps per Second: 10,226.56402

Timestep Collection Time: 2.36328
Timestep Consumption Time: 2.52654
PPO Batch Consumption Time: 0.29157
Total Iteration Time: 4.88981

Cumulative Model Updates: 103,612
Cumulative Timesteps: 863,989,286

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 215,035.95919
Policy Entropy: 3.71002
Value Function Loss: 0.02300

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.13802
Policy Update Magnitude: 0.44328
Value Function Update Magnitude: 0.45296

Collected Steps per Second: 21,572.61387
Overall Steps per Second: 10,362.67927

Timestep Collection Time: 2.31831
Timestep Consumption Time: 2.50786
PPO Batch Consumption Time: 0.28712
Total Iteration Time: 4.82617

Cumulative Model Updates: 103,618
Cumulative Timesteps: 864,039,298

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 864039298...
Checkpoint 864039298 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 215,035.95919
Policy Entropy: 3.71441
Value Function Loss: 0.02024

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.14056
Policy Update Magnitude: 0.41103
Value Function Update Magnitude: 0.35156

Collected Steps per Second: 21,659.25179
Overall Steps per Second: 10,319.32093

Timestep Collection Time: 2.30959
Timestep Consumption Time: 2.53802
PPO Batch Consumption Time: 0.29320
Total Iteration Time: 4.84761

Cumulative Model Updates: 103,624
Cumulative Timesteps: 864,089,322

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 215,035.95919
Policy Entropy: 3.68817
Value Function Loss: 0.02048

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.14708
Policy Update Magnitude: 0.39234
Value Function Update Magnitude: 0.33498

Collected Steps per Second: 21,868.50197
Overall Steps per Second: 10,451.92758

Timestep Collection Time: 2.28694
Timestep Consumption Time: 2.49801
PPO Batch Consumption Time: 0.28671
Total Iteration Time: 4.78495

Cumulative Model Updates: 103,630
Cumulative Timesteps: 864,139,334

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 864139334...
Checkpoint 864139334 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 215,035.95919
Policy Entropy: 3.67498
Value Function Loss: 0.02284

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.14587
Policy Update Magnitude: 0.39300
Value Function Update Magnitude: 0.37495

Collected Steps per Second: 21,255.84597
Overall Steps per Second: 10,191.34758

Timestep Collection Time: 2.35286
Timestep Consumption Time: 2.55444
PPO Batch Consumption Time: 0.29660
Total Iteration Time: 4.90730

Cumulative Model Updates: 103,636
Cumulative Timesteps: 864,189,346

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 433,295.12142
Policy Entropy: 3.67583
Value Function Loss: 0.02627

Mean KL Divergence: 0.01073
SB3 Clip Fraction: 0.14737
Policy Update Magnitude: 0.41439
Value Function Update Magnitude: 0.46812

Collected Steps per Second: 21,286.46482
Overall Steps per Second: 10,184.70606

Timestep Collection Time: 2.35013
Timestep Consumption Time: 2.56174
PPO Batch Consumption Time: 0.29689
Total Iteration Time: 4.91187

Cumulative Model Updates: 103,642
Cumulative Timesteps: 864,239,372

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 864239372...
Checkpoint 864239372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 433,295.12142
Policy Entropy: 3.68766
Value Function Loss: 0.02823

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.13903
Policy Update Magnitude: 0.44558
Value Function Update Magnitude: 0.44223

Collected Steps per Second: 21,688.97611
Overall Steps per Second: 10,397.41076

Timestep Collection Time: 2.30606
Timestep Consumption Time: 2.50437
PPO Batch Consumption Time: 0.28818
Total Iteration Time: 4.81043

Cumulative Model Updates: 103,648
Cumulative Timesteps: 864,289,388

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 433,295.12142
Policy Entropy: 3.67417
Value Function Loss: 0.02787

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.13964
Policy Update Magnitude: 0.46610
Value Function Update Magnitude: 0.42989

Collected Steps per Second: 21,713.77693
Overall Steps per Second: 10,333.70568

Timestep Collection Time: 2.30351
Timestep Consumption Time: 2.53676
PPO Batch Consumption Time: 0.29415
Total Iteration Time: 4.84028

Cumulative Model Updates: 103,654
Cumulative Timesteps: 864,339,406

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 864339406...
Checkpoint 864339406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 433,295.12142
Policy Entropy: 3.68894
Value Function Loss: 0.02327

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.14152
Policy Update Magnitude: 0.42222
Value Function Update Magnitude: 0.39259

Collected Steps per Second: 21,131.44213
Overall Steps per Second: 10,447.35569

Timestep Collection Time: 2.36709
Timestep Consumption Time: 2.42073
PPO Batch Consumption Time: 0.28655
Total Iteration Time: 4.78781

Cumulative Model Updates: 103,660
Cumulative Timesteps: 864,389,426

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 433,295.12142
Policy Entropy: 3.67551
Value Function Loss: 0.02564

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.14462
Policy Update Magnitude: 0.39254
Value Function Update Magnitude: 0.36814

Collected Steps per Second: 20,794.78924
Overall Steps per Second: 10,361.72468

Timestep Collection Time: 2.40493
Timestep Consumption Time: 2.42149
PPO Batch Consumption Time: 0.28746
Total Iteration Time: 4.82642

Cumulative Model Updates: 103,666
Cumulative Timesteps: 864,439,436

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 864439436...
Checkpoint 864439436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 433,295.12142
Policy Entropy: 3.68430
Value Function Loss: 0.02471

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.13945
Policy Update Magnitude: 0.42753
Value Function Update Magnitude: 0.36813

Collected Steps per Second: 20,723.32080
Overall Steps per Second: 10,231.52194

Timestep Collection Time: 2.41351
Timestep Consumption Time: 2.47491
PPO Batch Consumption Time: 0.28788
Total Iteration Time: 4.88842

Cumulative Model Updates: 103,672
Cumulative Timesteps: 864,489,452

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 433,295.12142
Policy Entropy: 3.66480
Value Function Loss: 0.02792

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.14478
Policy Update Magnitude: 0.44639
Value Function Update Magnitude: 0.34935

Collected Steps per Second: 21,575.79879
Overall Steps per Second: 10,400.18606

Timestep Collection Time: 2.31750
Timestep Consumption Time: 2.49029
PPO Batch Consumption Time: 0.28811
Total Iteration Time: 4.80780

Cumulative Model Updates: 103,678
Cumulative Timesteps: 864,539,454

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 864539454...
Checkpoint 864539454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 433,295.12142
Policy Entropy: 3.68326
Value Function Loss: 0.02385

Mean KL Divergence: 0.01101
SB3 Clip Fraction: 0.14855
Policy Update Magnitude: 0.44272
Value Function Update Magnitude: 0.32695

Collected Steps per Second: 21,278.83755
Overall Steps per Second: 10,133.44120

Timestep Collection Time: 2.35088
Timestep Consumption Time: 2.58565
PPO Batch Consumption Time: 0.30799
Total Iteration Time: 4.93653

Cumulative Model Updates: 103,684
Cumulative Timesteps: 864,589,478

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 433,295.12142
Policy Entropy: 3.66513
Value Function Loss: 0.02423

Mean KL Divergence: 0.01130
SB3 Clip Fraction: 0.14928
Policy Update Magnitude: 0.42097
Value Function Update Magnitude: 0.32335

Collected Steps per Second: 21,633.18247
Overall Steps per Second: 10,258.31040

Timestep Collection Time: 2.31256
Timestep Consumption Time: 2.56427
PPO Batch Consumption Time: 0.30066
Total Iteration Time: 4.87683

Cumulative Model Updates: 103,690
Cumulative Timesteps: 864,639,506

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 864639506...
Checkpoint 864639506 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 433,295.12142
Policy Entropy: 3.68612
Value Function Loss: 0.02236

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.14421
Policy Update Magnitude: 0.40685
Value Function Update Magnitude: 0.28923

Collected Steps per Second: 21,484.91990
Overall Steps per Second: 10,230.78188

Timestep Collection Time: 2.32805
Timestep Consumption Time: 2.56092
PPO Batch Consumption Time: 0.30086
Total Iteration Time: 4.88897

Cumulative Model Updates: 103,696
Cumulative Timesteps: 864,689,524

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 433,295.12142
Policy Entropy: 3.67777
Value Function Loss: 0.02449

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.14048
Policy Update Magnitude: 0.42177
Value Function Update Magnitude: 0.32257

Collected Steps per Second: 21,702.23905
Overall Steps per Second: 10,409.82768

Timestep Collection Time: 2.30400
Timestep Consumption Time: 2.49934
PPO Batch Consumption Time: 0.28577
Total Iteration Time: 4.80335

Cumulative Model Updates: 103,702
Cumulative Timesteps: 864,739,526

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 864739526...
Checkpoint 864739526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 433,295.12142
Policy Entropy: 3.69779
Value Function Loss: 0.02196

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.14250
Policy Update Magnitude: 0.45315
Value Function Update Magnitude: 0.42856

Collected Steps per Second: 21,533.77505
Overall Steps per Second: 10,235.01477

Timestep Collection Time: 2.32314
Timestep Consumption Time: 2.56459
PPO Batch Consumption Time: 0.29791
Total Iteration Time: 4.88773

Cumulative Model Updates: 103,708
Cumulative Timesteps: 864,789,552

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 433,295.12142
Policy Entropy: 3.69237
Value Function Loss: 0.02143

Mean KL Divergence: 0.01070
SB3 Clip Fraction: 0.14983
Policy Update Magnitude: 0.42402
Value Function Update Magnitude: 0.48506

Collected Steps per Second: 21,483.78051
Overall Steps per Second: 10,343.14043

Timestep Collection Time: 2.32771
Timestep Consumption Time: 2.50719
PPO Batch Consumption Time: 0.28753
Total Iteration Time: 4.83490

Cumulative Model Updates: 103,714
Cumulative Timesteps: 864,839,560

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 864839560...
Checkpoint 864839560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 433,295.12142
Policy Entropy: 3.70138
Value Function Loss: 0.01792

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.14745
Policy Update Magnitude: 0.39050
Value Function Update Magnitude: 0.50669

Collected Steps per Second: 21,808.30788
Overall Steps per Second: 10,335.24045

Timestep Collection Time: 2.29335
Timestep Consumption Time: 2.54583
PPO Batch Consumption Time: 0.29519
Total Iteration Time: 4.83917

Cumulative Model Updates: 103,720
Cumulative Timesteps: 864,889,574

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 433,295.12142
Policy Entropy: 3.69063
Value Function Loss: 0.01942

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.14397
Policy Update Magnitude: 0.34990
Value Function Update Magnitude: 0.43028

Collected Steps per Second: 21,246.73085
Overall Steps per Second: 10,195.82718

Timestep Collection Time: 2.35443
Timestep Consumption Time: 2.55189
PPO Batch Consumption Time: 0.29604
Total Iteration Time: 4.90632

Cumulative Model Updates: 103,726
Cumulative Timesteps: 864,939,598

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 864939598...
Checkpoint 864939598 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 433,295.12142
Policy Entropy: 3.71108
Value Function Loss: 0.01752

Mean KL Divergence: 0.01055
SB3 Clip Fraction: 0.14606
Policy Update Magnitude: 0.32558
Value Function Update Magnitude: 0.39048

Collected Steps per Second: 21,590.19789
Overall Steps per Second: 10,342.02590

Timestep Collection Time: 2.31651
Timestep Consumption Time: 2.51948
PPO Batch Consumption Time: 0.28837
Total Iteration Time: 4.83600

Cumulative Model Updates: 103,732
Cumulative Timesteps: 864,989,612

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 433,295.12142
Policy Entropy: 3.70238
Value Function Loss: 0.01875

Mean KL Divergence: 0.01067
SB3 Clip Fraction: 0.14295
Policy Update Magnitude: 0.36121
Value Function Update Magnitude: 0.49319

Collected Steps per Second: 20,822.75622
Overall Steps per Second: 10,234.41506

Timestep Collection Time: 2.40141
Timestep Consumption Time: 2.48446
PPO Batch Consumption Time: 0.29885
Total Iteration Time: 4.88587

Cumulative Model Updates: 103,738
Cumulative Timesteps: 865,039,616

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 865039616...
Checkpoint 865039616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 433,295.12142
Policy Entropy: 3.69240
Value Function Loss: 0.02306

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.13864
Policy Update Magnitude: 0.44008
Value Function Update Magnitude: 0.50367

Collected Steps per Second: 20,806.05470
Overall Steps per Second: 10,264.59522

Timestep Collection Time: 2.40382
Timestep Consumption Time: 2.46866
PPO Batch Consumption Time: 0.29834
Total Iteration Time: 4.87248

Cumulative Model Updates: 103,744
Cumulative Timesteps: 865,089,630

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 396,885.14526
Policy Entropy: 3.67676
Value Function Loss: 0.02600

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.14127
Policy Update Magnitude: 0.48513
Value Function Update Magnitude: 0.52402

Collected Steps per Second: 20,888.38334
Overall Steps per Second: 10,221.82977

Timestep Collection Time: 2.39377
Timestep Consumption Time: 2.49792
PPO Batch Consumption Time: 0.28810
Total Iteration Time: 4.89169

Cumulative Model Updates: 103,750
Cumulative Timesteps: 865,139,632

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 865139632...
Checkpoint 865139632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 112,098.15172
Policy Entropy: 3.68086
Value Function Loss: 0.02946

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.14128
Policy Update Magnitude: 0.53257
Value Function Update Magnitude: 0.60895

Collected Steps per Second: 21,360.91736
Overall Steps per Second: 10,107.63630

Timestep Collection Time: 2.34091
Timestep Consumption Time: 2.60624
PPO Batch Consumption Time: 0.30883
Total Iteration Time: 4.94715

Cumulative Model Updates: 103,756
Cumulative Timesteps: 865,189,636

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 148,663.36869
Policy Entropy: 3.70339
Value Function Loss: 0.02933

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.13703
Policy Update Magnitude: 0.53184
Value Function Update Magnitude: 0.68827

Collected Steps per Second: 21,923.47800
Overall Steps per Second: 10,300.42728

Timestep Collection Time: 2.28194
Timestep Consumption Time: 2.57495
PPO Batch Consumption Time: 0.30130
Total Iteration Time: 4.85689

Cumulative Model Updates: 103,762
Cumulative Timesteps: 865,239,664

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 865239664...
Checkpoint 865239664 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 303,773.77374
Policy Entropy: 3.70793
Value Function Loss: 0.03241

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.13476
Policy Update Magnitude: 0.54169
Value Function Update Magnitude: 0.75125

Collected Steps per Second: 21,618.22204
Overall Steps per Second: 10,295.67354

Timestep Collection Time: 2.31444
Timestep Consumption Time: 2.54527
PPO Batch Consumption Time: 0.29653
Total Iteration Time: 4.85971

Cumulative Model Updates: 103,768
Cumulative Timesteps: 865,289,698

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97,938.25885
Policy Entropy: 3.71786
Value Function Loss: 0.03131

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.13581
Policy Update Magnitude: 0.54431
Value Function Update Magnitude: 0.80475

Collected Steps per Second: 21,710.97468
Overall Steps per Second: 10,254.12370

Timestep Collection Time: 2.30326
Timestep Consumption Time: 2.57341
PPO Batch Consumption Time: 0.29760
Total Iteration Time: 4.87667

Cumulative Model Updates: 103,774
Cumulative Timesteps: 865,339,704

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 865339704...
Checkpoint 865339704 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 97,938.25885
Policy Entropy: 3.71552
Value Function Loss: 0.02816

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.13610
Policy Update Magnitude: 0.53311
Value Function Update Magnitude: 0.83175

Collected Steps per Second: 21,474.56197
Overall Steps per Second: 10,213.27444

Timestep Collection Time: 2.32917
Timestep Consumption Time: 2.56818
PPO Batch Consumption Time: 0.29780
Total Iteration Time: 4.89735

Cumulative Model Updates: 103,780
Cumulative Timesteps: 865,389,722

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97,938.25885
Policy Entropy: 3.70729
Value Function Loss: 0.02304

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.14019
Policy Update Magnitude: 0.48452
Value Function Update Magnitude: 0.77963

Collected Steps per Second: 21,539.00307
Overall Steps per Second: 10,356.13506

Timestep Collection Time: 2.32221
Timestep Consumption Time: 2.50759
PPO Batch Consumption Time: 0.28829
Total Iteration Time: 4.82979

Cumulative Model Updates: 103,786
Cumulative Timesteps: 865,439,740

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 865439740...
Checkpoint 865439740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 97,938.25885
Policy Entropy: 3.67105
Value Function Loss: 0.02204

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.13845
Policy Update Magnitude: 0.46058
Value Function Update Magnitude: 0.68134

Collected Steps per Second: 21,357.18759
Overall Steps per Second: 10,354.57453

Timestep Collection Time: 2.34254
Timestep Consumption Time: 2.48914
PPO Batch Consumption Time: 0.28570
Total Iteration Time: 4.83168

Cumulative Model Updates: 103,792
Cumulative Timesteps: 865,489,770

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97,938.25885
Policy Entropy: 3.67274
Value Function Loss: 0.02175

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.14037
Policy Update Magnitude: 0.45050
Value Function Update Magnitude: 0.56687

Collected Steps per Second: 21,411.34730
Overall Steps per Second: 10,300.79198

Timestep Collection Time: 2.33568
Timestep Consumption Time: 2.51929
PPO Batch Consumption Time: 0.28775
Total Iteration Time: 4.85497

Cumulative Model Updates: 103,798
Cumulative Timesteps: 865,539,780

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 865539780...
Checkpoint 865539780 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 97,938.25885
Policy Entropy: 3.66864
Value Function Loss: 0.02727

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.14241
Policy Update Magnitude: 0.44225
Value Function Update Magnitude: 0.47445

Collected Steps per Second: 21,630.98529
Overall Steps per Second: 10,335.99079

Timestep Collection Time: 2.31233
Timestep Consumption Time: 2.52688
PPO Batch Consumption Time: 0.29260
Total Iteration Time: 4.83921

Cumulative Model Updates: 103,804
Cumulative Timesteps: 865,589,798

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97,938.25885
Policy Entropy: 3.68012
Value Function Loss: 0.03226

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.14092
Policy Update Magnitude: 0.47821
Value Function Update Magnitude: 0.39120

Collected Steps per Second: 20,729.03502
Overall Steps per Second: 10,329.65231

Timestep Collection Time: 2.41333
Timestep Consumption Time: 2.42962
PPO Batch Consumption Time: 0.28812
Total Iteration Time: 4.84295

Cumulative Model Updates: 103,810
Cumulative Timesteps: 865,639,824

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 865639824...
Checkpoint 865639824 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 97,938.25885
Policy Entropy: 3.67239
Value Function Loss: 0.03519

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.14295
Policy Update Magnitude: 0.54026
Value Function Update Magnitude: 0.41846

Collected Steps per Second: 20,621.83153
Overall Steps per Second: 10,331.76242

Timestep Collection Time: 2.42588
Timestep Consumption Time: 2.41609
PPO Batch Consumption Time: 0.28669
Total Iteration Time: 4.84196

Cumulative Model Updates: 103,816
Cumulative Timesteps: 865,689,850

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97,938.25885
Policy Entropy: 3.68197
Value Function Loss: 0.03502

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.14329
Policy Update Magnitude: 0.54914
Value Function Update Magnitude: 0.47295

Collected Steps per Second: 20,841.49223
Overall Steps per Second: 10,054.37573

Timestep Collection Time: 2.39973
Timestep Consumption Time: 2.57462
PPO Batch Consumption Time: 0.30162
Total Iteration Time: 4.97435

Cumulative Model Updates: 103,822
Cumulative Timesteps: 865,739,864

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 865739864...
Checkpoint 865739864 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 97,938.25885
Policy Entropy: 3.68803
Value Function Loss: 0.03812

Mean KL Divergence: 0.01059
SB3 Clip Fraction: 0.14237
Policy Update Magnitude: 0.51517
Value Function Update Magnitude: 0.38222

Collected Steps per Second: 21,090.55228
Overall Steps per Second: 10,173.52727

Timestep Collection Time: 2.37215
Timestep Consumption Time: 2.54551
PPO Batch Consumption Time: 0.29828
Total Iteration Time: 4.91767

Cumulative Model Updates: 103,828
Cumulative Timesteps: 865,789,894

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97,938.25885
Policy Entropy: 3.67688
Value Function Loss: 0.03441

Mean KL Divergence: 0.01085
SB3 Clip Fraction: 0.14359
Policy Update Magnitude: 0.51983
Value Function Update Magnitude: 0.34752

Collected Steps per Second: 21,272.19989
Overall Steps per Second: 10,179.69768

Timestep Collection Time: 2.35086
Timestep Consumption Time: 2.56166
PPO Batch Consumption Time: 0.30026
Total Iteration Time: 4.91252

Cumulative Model Updates: 103,834
Cumulative Timesteps: 865,839,902

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 865839902...
Checkpoint 865839902 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 314,413.34053
Policy Entropy: 3.69526
Value Function Loss: 0.03340

Mean KL Divergence: 0.01100
SB3 Clip Fraction: 0.13875
Policy Update Magnitude: 0.53540
Value Function Update Magnitude: 0.35925

Collected Steps per Second: 21,017.69177
Overall Steps per Second: 10,121.32841

Timestep Collection Time: 2.37895
Timestep Consumption Time: 2.56111
PPO Batch Consumption Time: 0.30041
Total Iteration Time: 4.94006

Cumulative Model Updates: 103,840
Cumulative Timesteps: 865,889,902

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 167,106.55072
Policy Entropy: 3.69692
Value Function Loss: 0.03416

Mean KL Divergence: 0.01096
SB3 Clip Fraction: 0.14081
Policy Update Magnitude: 0.58492
Value Function Update Magnitude: 0.39805

Collected Steps per Second: 21,448.42501
Overall Steps per Second: 10,305.54031

Timestep Collection Time: 2.33117
Timestep Consumption Time: 2.52059
PPO Batch Consumption Time: 0.28811
Total Iteration Time: 4.85176

Cumulative Model Updates: 103,846
Cumulative Timesteps: 865,939,902

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 865939902...
Checkpoint 865939902 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 167,106.55072
Policy Entropy: 3.71354
Value Function Loss: 0.03089

Mean KL Divergence: 0.01177
SB3 Clip Fraction: 0.15082
Policy Update Magnitude: 0.60800
Value Function Update Magnitude: 0.47074

Collected Steps per Second: 21,135.77421
Overall Steps per Second: 10,262.94460

Timestep Collection Time: 2.36613
Timestep Consumption Time: 2.50674
PPO Batch Consumption Time: 0.28822
Total Iteration Time: 4.87287

Cumulative Model Updates: 103,852
Cumulative Timesteps: 865,989,912

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 604,566.38496
Policy Entropy: 3.68988
Value Function Loss: 0.03240

Mean KL Divergence: 0.01187
SB3 Clip Fraction: 0.15206
Policy Update Magnitude: 0.60891
Value Function Update Magnitude: 0.42957

Collected Steps per Second: 21,820.91585
Overall Steps per Second: 10,412.30162

Timestep Collection Time: 2.29165
Timestep Consumption Time: 2.51093
PPO Batch Consumption Time: 0.28829
Total Iteration Time: 4.80259

Cumulative Model Updates: 103,858
Cumulative Timesteps: 866,039,918

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 866039918...
Checkpoint 866039918 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 604,566.38496
Policy Entropy: 3.68428
Value Function Loss: 0.03229

Mean KL Divergence: 0.01133
SB3 Clip Fraction: 0.14513
Policy Update Magnitude: 0.57750
Value Function Update Magnitude: 0.38284

Collected Steps per Second: 21,239.58826
Overall Steps per Second: 10,316.99079

Timestep Collection Time: 2.35513
Timestep Consumption Time: 2.49338
PPO Batch Consumption Time: 0.28589
Total Iteration Time: 4.84851

Cumulative Model Updates: 103,864
Cumulative Timesteps: 866,089,940

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 604,566.38496
Policy Entropy: 3.66190
Value Function Loss: 0.03424

Mean KL Divergence: 0.01134
SB3 Clip Fraction: 0.14794
Policy Update Magnitude: 0.53039
Value Function Update Magnitude: 0.32046

Collected Steps per Second: 20,834.17588
Overall Steps per Second: 10,043.76049

Timestep Collection Time: 2.40096
Timestep Consumption Time: 2.57945
PPO Batch Consumption Time: 0.30096
Total Iteration Time: 4.98041

Cumulative Model Updates: 103,870
Cumulative Timesteps: 866,139,962

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 866139962...
Checkpoint 866139962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 604,566.38496
Policy Entropy: 3.66570
Value Function Loss: 0.03259

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.13769
Policy Update Magnitude: 0.50492
Value Function Update Magnitude: 0.31050

Collected Steps per Second: 21,172.10433
Overall Steps per Second: 10,196.46871

Timestep Collection Time: 2.36169
Timestep Consumption Time: 2.54216
PPO Batch Consumption Time: 0.29246
Total Iteration Time: 4.90385

Cumulative Model Updates: 103,876
Cumulative Timesteps: 866,189,964

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 581,111.09311
Policy Entropy: 3.66143
Value Function Loss: 0.03563

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.14177
Policy Update Magnitude: 0.50301
Value Function Update Magnitude: 0.33575

Collected Steps per Second: 21,346.28829
Overall Steps per Second: 10,229.30086

Timestep Collection Time: 2.34355
Timestep Consumption Time: 2.54692
PPO Batch Consumption Time: 0.29512
Total Iteration Time: 4.89046

Cumulative Model Updates: 103,882
Cumulative Timesteps: 866,239,990

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 866239990...
Checkpoint 866239990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 381,264.28048
Policy Entropy: 3.68632
Value Function Loss: 0.03298

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.13696
Policy Update Magnitude: 0.52854
Value Function Update Magnitude: 0.42764

Collected Steps per Second: 21,297.34080
Overall Steps per Second: 10,336.52419

Timestep Collection Time: 2.34837
Timestep Consumption Time: 2.49020
PPO Batch Consumption Time: 0.28766
Total Iteration Time: 4.83857

Cumulative Model Updates: 103,888
Cumulative Timesteps: 866,290,004

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 381,264.28048
Policy Entropy: 3.67756
Value Function Loss: 0.03275

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.13249
Policy Update Magnitude: 0.58632
Value Function Update Magnitude: 0.46685

Collected Steps per Second: 20,443.68020
Overall Steps per Second: 10,105.27616

Timestep Collection Time: 2.44574
Timestep Consumption Time: 2.50217
PPO Batch Consumption Time: 0.29964
Total Iteration Time: 4.94791

Cumulative Model Updates: 103,894
Cumulative Timesteps: 866,340,004

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 866340004...
Checkpoint 866340004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 219,778.53256
Policy Entropy: 3.68776
Value Function Loss: 0.03124

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.13695
Policy Update Magnitude: 0.58898
Value Function Update Magnitude: 0.45195

Collected Steps per Second: 20,751.86940
Overall Steps per Second: 10,237.20930

Timestep Collection Time: 2.41019
Timestep Consumption Time: 2.47551
PPO Batch Consumption Time: 0.29722
Total Iteration Time: 4.88571

Cumulative Model Updates: 103,900
Cumulative Timesteps: 866,390,020

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76,638.43399
Policy Entropy: 3.68181
Value Function Loss: 0.03171

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.13055
Policy Update Magnitude: 0.55118
Value Function Update Magnitude: 0.42883

Collected Steps per Second: 21,135.58363
Overall Steps per Second: 10,179.00244

Timestep Collection Time: 2.36568
Timestep Consumption Time: 2.54639
PPO Batch Consumption Time: 0.29775
Total Iteration Time: 4.91207

Cumulative Model Updates: 103,906
Cumulative Timesteps: 866,440,020

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 866440020...
Checkpoint 866440020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,723.81382
Policy Entropy: 3.69747
Value Function Loss: 0.03366

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.13814
Policy Update Magnitude: 0.52352
Value Function Update Magnitude: 0.44371

Collected Steps per Second: 20,929.06165
Overall Steps per Second: 10,195.33203

Timestep Collection Time: 2.39132
Timestep Consumption Time: 2.51760
PPO Batch Consumption Time: 0.29734
Total Iteration Time: 4.90891

Cumulative Model Updates: 103,912
Cumulative Timesteps: 866,490,068

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,517.47789
Policy Entropy: 3.70700
Value Function Loss: 0.03063

Mean KL Divergence: 0.01078
SB3 Clip Fraction: 0.13871
Policy Update Magnitude: 0.50713
Value Function Update Magnitude: 0.47890

Collected Steps per Second: 21,221.71770
Overall Steps per Second: 10,343.47105

Timestep Collection Time: 2.35749
Timestep Consumption Time: 2.47938
PPO Batch Consumption Time: 0.28690
Total Iteration Time: 4.83687

Cumulative Model Updates: 103,918
Cumulative Timesteps: 866,540,098

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 866540098...
Checkpoint 866540098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,517.47789
Policy Entropy: 3.69890
Value Function Loss: 0.03095

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.13890
Policy Update Magnitude: 0.47536
Value Function Update Magnitude: 0.46880

Collected Steps per Second: 21,217.50277
Overall Steps per Second: 10,275.09088

Timestep Collection Time: 2.35777
Timestep Consumption Time: 2.51090
PPO Batch Consumption Time: 0.28699
Total Iteration Time: 4.86867

Cumulative Model Updates: 103,924
Cumulative Timesteps: 866,590,124

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,517.47789
Policy Entropy: 3.69512
Value Function Loss: 0.02880

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.14087
Policy Update Magnitude: 0.46721
Value Function Update Magnitude: 0.42479

Collected Steps per Second: 21,725.07674
Overall Steps per Second: 10,378.81018

Timestep Collection Time: 2.30204
Timestep Consumption Time: 2.51662
PPO Batch Consumption Time: 0.28825
Total Iteration Time: 4.81866

Cumulative Model Updates: 103,930
Cumulative Timesteps: 866,640,136

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 866640136...
Checkpoint 866640136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,517.47789
Policy Entropy: 3.67773
Value Function Loss: 0.02831

Mean KL Divergence: 0.01080
SB3 Clip Fraction: 0.14209
Policy Update Magnitude: 0.47907
Value Function Update Magnitude: 0.40716

Collected Steps per Second: 21,301.04027
Overall Steps per Second: 10,319.78943

Timestep Collection Time: 2.34730
Timestep Consumption Time: 2.49776
PPO Batch Consumption Time: 0.28656
Total Iteration Time: 4.84506

Cumulative Model Updates: 103,936
Cumulative Timesteps: 866,690,136

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,517.47789
Policy Entropy: 3.68728
Value Function Loss: 0.02640

Mean KL Divergence: 0.01055
SB3 Clip Fraction: 0.13852
Policy Update Magnitude: 0.48088
Value Function Update Magnitude: 0.47266

Collected Steps per Second: 21,417.39021
Overall Steps per Second: 10,298.58124

Timestep Collection Time: 2.33549
Timestep Consumption Time: 2.52149
PPO Batch Consumption Time: 0.28893
Total Iteration Time: 4.85698

Cumulative Model Updates: 103,942
Cumulative Timesteps: 866,740,156

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 866740156...
Checkpoint 866740156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 439,341.85404
Policy Entropy: 3.67808
Value Function Loss: 0.03366

Mean KL Divergence: 0.01097
SB3 Clip Fraction: 0.14460
Policy Update Magnitude: 0.50028
Value Function Update Magnitude: 0.43770

Collected Steps per Second: 21,502.86762
Overall Steps per Second: 10,305.26844

Timestep Collection Time: 2.32564
Timestep Consumption Time: 2.52702
PPO Batch Consumption Time: 0.29077
Total Iteration Time: 4.85266

Cumulative Model Updates: 103,948
Cumulative Timesteps: 866,790,164

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 153,220.28705
Policy Entropy: 3.69968
Value Function Loss: 0.03277

Mean KL Divergence: 0.01123
SB3 Clip Fraction: 0.14336
Policy Update Magnitude: 0.53743
Value Function Update Magnitude: 0.60910

Collected Steps per Second: 21,563.30374
Overall Steps per Second: 10,359.46095

Timestep Collection Time: 2.31959
Timestep Consumption Time: 2.50865
PPO Batch Consumption Time: 0.28881
Total Iteration Time: 4.82824

Cumulative Model Updates: 103,954
Cumulative Timesteps: 866,840,182

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 866840182...
Checkpoint 866840182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 408,870.21554
Policy Entropy: 3.69671
Value Function Loss: 0.03925

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.13092
Policy Update Magnitude: 0.56746
Value Function Update Magnitude: 0.56066

Collected Steps per Second: 21,079.98255
Overall Steps per Second: 10,329.90110

Timestep Collection Time: 2.37344
Timestep Consumption Time: 2.46998
PPO Batch Consumption Time: 0.29509
Total Iteration Time: 4.84342

Cumulative Model Updates: 103,960
Cumulative Timesteps: 866,890,214

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 142,572.91736
Policy Entropy: 3.71403
Value Function Loss: 0.03326

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.13636
Policy Update Magnitude: 0.58563
Value Function Update Magnitude: 0.55593

Collected Steps per Second: 20,606.44653
Overall Steps per Second: 10,189.82585

Timestep Collection Time: 2.42720
Timestep Consumption Time: 2.48122
PPO Batch Consumption Time: 0.29730
Total Iteration Time: 4.90843

Cumulative Model Updates: 103,966
Cumulative Timesteps: 866,940,230

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 866940230...
Checkpoint 866940230 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,717.81016
Policy Entropy: 3.70876
Value Function Loss: 0.03285

Mean KL Divergence: 0.01055
SB3 Clip Fraction: 0.14168
Policy Update Magnitude: 0.55479
Value Function Update Magnitude: 0.62693

Collected Steps per Second: 20,887.95183
Overall Steps per Second: 10,373.30023

Timestep Collection Time: 2.39392
Timestep Consumption Time: 2.42654
PPO Batch Consumption Time: 0.28823
Total Iteration Time: 4.82045

Cumulative Model Updates: 103,972
Cumulative Timesteps: 866,990,234

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49,717.81016
Policy Entropy: 3.72806
Value Function Loss: 0.03048

Mean KL Divergence: 0.01067
SB3 Clip Fraction: 0.14149
Policy Update Magnitude: 0.58027
Value Function Update Magnitude: 0.60048

Collected Steps per Second: 20,860.74000
Overall Steps per Second: 10,138.96444

Timestep Collection Time: 2.39685
Timestep Consumption Time: 2.53462
PPO Batch Consumption Time: 0.29685
Total Iteration Time: 4.93147

Cumulative Model Updates: 103,978
Cumulative Timesteps: 867,040,234

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 867040234...
Checkpoint 867040234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,717.81016
Policy Entropy: 3.69244
Value Function Loss: 0.03467

Mean KL Divergence: 0.01101
SB3 Clip Fraction: 0.14679
Policy Update Magnitude: 0.56665
Value Function Update Magnitude: 0.48323

Collected Steps per Second: 21,110.28891
Overall Steps per Second: 10,194.53667

Timestep Collection Time: 2.36899
Timestep Consumption Time: 2.53658
PPO Batch Consumption Time: 0.29754
Total Iteration Time: 4.90557

Cumulative Model Updates: 103,984
Cumulative Timesteps: 867,090,244

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49,717.81016
Policy Entropy: 3.68846
Value Function Loss: 0.03207

Mean KL Divergence: 0.01078
SB3 Clip Fraction: 0.14395
Policy Update Magnitude: 0.56354
Value Function Update Magnitude: 0.42641

Collected Steps per Second: 21,161.47047
Overall Steps per Second: 10,015.71533

Timestep Collection Time: 2.36392
Timestep Consumption Time: 2.63063
PPO Batch Consumption Time: 0.30942
Total Iteration Time: 4.99455

Cumulative Model Updates: 103,990
Cumulative Timesteps: 867,140,268

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 867140268...
Checkpoint 867140268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 589,007.66392
Policy Entropy: 3.68582
Value Function Loss: 0.03694

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.14052
Policy Update Magnitude: 0.57536
Value Function Update Magnitude: 0.40160

Collected Steps per Second: 21,486.77226
Overall Steps per Second: 10,267.52488

Timestep Collection Time: 2.32785
Timestep Consumption Time: 2.54363
PPO Batch Consumption Time: 0.30096
Total Iteration Time: 4.87148

Cumulative Model Updates: 103,996
Cumulative Timesteps: 867,190,286

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 235,361.70134
Policy Entropy: 3.71283
Value Function Loss: 0.03346

Mean KL Divergence: 0.01113
SB3 Clip Fraction: 0.14641
Policy Update Magnitude: 0.60285
Value Function Update Magnitude: 0.50736

Collected Steps per Second: 21,431.41416
Overall Steps per Second: 10,317.92754

Timestep Collection Time: 2.33377
Timestep Consumption Time: 2.51371
PPO Batch Consumption Time: 0.28851
Total Iteration Time: 4.84749

Cumulative Model Updates: 104,002
Cumulative Timesteps: 867,240,302

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 867240302...
Checkpoint 867240302 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 235,361.70134
Policy Entropy: 3.69890
Value Function Loss: 0.03515

Mean KL Divergence: 0.00759
SB3 Clip Fraction: 0.09690
Policy Update Magnitude: 0.73751
Value Function Update Magnitude: 0.56140

Collected Steps per Second: 21,441.49787
Overall Steps per Second: 10,351.29830

Timestep Collection Time: 2.33370
Timestep Consumption Time: 2.50028
PPO Batch Consumption Time: 0.28634
Total Iteration Time: 4.83398

Cumulative Model Updates: 104,008
Cumulative Timesteps: 867,290,340

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 458,308.97283
Policy Entropy: 3.71305
Value Function Loss: 0.02881

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.10142
Policy Update Magnitude: 0.79272
Value Function Update Magnitude: 0.52453

Collected Steps per Second: 21,294.21779
Overall Steps per Second: 10,138.90034

Timestep Collection Time: 2.34824
Timestep Consumption Time: 2.58365
PPO Batch Consumption Time: 0.29718
Total Iteration Time: 4.93190

Cumulative Model Updates: 104,014
Cumulative Timesteps: 867,340,344

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 867340344...
Checkpoint 867340344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 458,308.97283
Policy Entropy: 3.69845
Value Function Loss: 0.02907

Mean KL Divergence: 0.01431
SB3 Clip Fraction: 0.17418
Policy Update Magnitude: 0.73849
Value Function Update Magnitude: 0.45645

Collected Steps per Second: 21,649.74334
Overall Steps per Second: 10,370.16104

Timestep Collection Time: 2.30996
Timestep Consumption Time: 2.51253
PPO Batch Consumption Time: 0.28824
Total Iteration Time: 4.82249

Cumulative Model Updates: 104,020
Cumulative Timesteps: 867,390,354

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 458,308.97283
Policy Entropy: 3.71279
Value Function Loss: 0.02798

Mean KL Divergence: 0.03241
SB3 Clip Fraction: 0.30108
Policy Update Magnitude: 0.57119
Value Function Update Magnitude: 0.43584

Collected Steps per Second: 21,787.13569
Overall Steps per Second: 10,314.57495

Timestep Collection Time: 2.29613
Timestep Consumption Time: 2.55390
PPO Batch Consumption Time: 0.29717
Total Iteration Time: 4.85003

Cumulative Model Updates: 104,026
Cumulative Timesteps: 867,440,380

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 867440380...
Checkpoint 867440380 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,211,066.28647
Policy Entropy: 3.73933
Value Function Loss: 0.04292

Mean KL Divergence: 0.02300
SB3 Clip Fraction: 0.24012
Policy Update Magnitude: 0.53574
Value Function Update Magnitude: 0.37244

Collected Steps per Second: 21,133.42566
Overall Steps per Second: 10,143.91098

Timestep Collection Time: 2.36601
Timestep Consumption Time: 2.56325
PPO Batch Consumption Time: 0.29973
Total Iteration Time: 4.92926

Cumulative Model Updates: 104,032
Cumulative Timesteps: 867,490,382

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 342,053.94320
Policy Entropy: 3.76449
Value Function Loss: 0.06216

Mean KL Divergence: 0.02077
SB3 Clip Fraction: 0.21867
Policy Update Magnitude: 0.59235
Value Function Update Magnitude: 0.35291

Collected Steps per Second: 21,146.10986
Overall Steps per Second: 10,271.42661

Timestep Collection Time: 2.36592
Timestep Consumption Time: 2.50487
PPO Batch Consumption Time: 0.28833
Total Iteration Time: 4.87079

Cumulative Model Updates: 104,038
Cumulative Timesteps: 867,540,412

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 867540412...
Checkpoint 867540412 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 119,271.56851
Policy Entropy: 3.77943
Value Function Loss: 0.07264

Mean KL Divergence: 0.01649
SB3 Clip Fraction: 0.19130
Policy Update Magnitude: 0.65429
Value Function Update Magnitude: 0.28613

Collected Steps per Second: 21,064.68769
Overall Steps per Second: 10,240.80132

Timestep Collection Time: 2.37469
Timestep Consumption Time: 2.50989
PPO Batch Consumption Time: 0.28922
Total Iteration Time: 4.88458

Cumulative Model Updates: 104,044
Cumulative Timesteps: 867,590,434

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,596.23568
Policy Entropy: 3.75535
Value Function Loss: 0.05188

Mean KL Divergence: 0.02574
SB3 Clip Fraction: 0.28421
Policy Update Magnitude: 0.52746
Value Function Update Magnitude: 0.27412

Collected Steps per Second: 21,461.07640
Overall Steps per Second: 10,231.21093

Timestep Collection Time: 2.33054
Timestep Consumption Time: 2.55803
PPO Batch Consumption Time: 0.29788
Total Iteration Time: 4.88857

Cumulative Model Updates: 104,050
Cumulative Timesteps: 867,640,450

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 867640450...
Checkpoint 867640450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 51,780.73962
Policy Entropy: 3.75384
Value Function Loss: 0.04817

Mean KL Divergence: 0.02704
SB3 Clip Fraction: 0.30022
Policy Update Magnitude: 0.39992
Value Function Update Magnitude: 0.23914

Collected Steps per Second: 20,511.56435
Overall Steps per Second: 10,174.23230

Timestep Collection Time: 2.43804
Timestep Consumption Time: 2.47712
PPO Batch Consumption Time: 0.29775
Total Iteration Time: 4.91516

Cumulative Model Updates: 104,056
Cumulative Timesteps: 867,690,458

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,059.09664
Policy Entropy: 3.77107
Value Function Loss: 0.03977

Mean KL Divergence: 0.01835
SB3 Clip Fraction: 0.22224
Policy Update Magnitude: 0.41464
Value Function Update Magnitude: 0.31103

Collected Steps per Second: 20,922.16119
Overall Steps per Second: 10,360.07709

Timestep Collection Time: 2.39077
Timestep Consumption Time: 2.43738
PPO Batch Consumption Time: 0.28678
Total Iteration Time: 4.82815

Cumulative Model Updates: 104,062
Cumulative Timesteps: 867,740,478

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 867740478...
Checkpoint 867740478 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,300.50697
Policy Entropy: 3.75993
Value Function Loss: 0.03842

Mean KL Divergence: 0.01450
SB3 Clip Fraction: 0.18168
Policy Update Magnitude: 0.44764
Value Function Update Magnitude: 0.34952

Collected Steps per Second: 20,916.01882
Overall Steps per Second: 10,261.91103

Timestep Collection Time: 2.39290
Timestep Consumption Time: 2.48436
PPO Batch Consumption Time: 0.30042
Total Iteration Time: 4.87726

Cumulative Model Updates: 104,068
Cumulative Timesteps: 867,790,528

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,105.11024
Policy Entropy: 3.74473
Value Function Loss: 0.03341

Mean KL Divergence: 0.01147
SB3 Clip Fraction: 0.15075
Policy Update Magnitude: 0.52833
Value Function Update Magnitude: 0.52747

Collected Steps per Second: 20,821.14575
Overall Steps per Second: 10,130.81425

Timestep Collection Time: 2.40169
Timestep Consumption Time: 2.53434
PPO Batch Consumption Time: 0.29696
Total Iteration Time: 4.93603

Cumulative Model Updates: 104,074
Cumulative Timesteps: 867,840,534

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 867840534...
Checkpoint 867840534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,105.11024
Policy Entropy: 3.70901
Value Function Loss: 0.03872

Mean KL Divergence: 0.01188
SB3 Clip Fraction: 0.16050
Policy Update Magnitude: 0.52031
Value Function Update Magnitude: 0.42365

Collected Steps per Second: 21,506.10668
Overall Steps per Second: 10,413.70909

Timestep Collection Time: 2.32622
Timestep Consumption Time: 2.47783
PPO Batch Consumption Time: 0.28748
Total Iteration Time: 4.80405

Cumulative Model Updates: 104,080
Cumulative Timesteps: 867,890,562

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 324,100.86481
Policy Entropy: 3.66635
Value Function Loss: 0.03554

Mean KL Divergence: 0.01137
SB3 Clip Fraction: 0.15279
Policy Update Magnitude: 0.51923
Value Function Update Magnitude: 0.47774

Collected Steps per Second: 21,537.52320
Overall Steps per Second: 10,221.02831

Timestep Collection Time: 2.32227
Timestep Consumption Time: 2.57117
PPO Batch Consumption Time: 0.30005
Total Iteration Time: 4.89344

Cumulative Model Updates: 104,086
Cumulative Timesteps: 867,940,578

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 867940578...
Checkpoint 867940578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 113,021.93284
Policy Entropy: 3.67754
Value Function Loss: 0.03435

Mean KL Divergence: 0.01077
SB3 Clip Fraction: 0.14163
Policy Update Magnitude: 0.54020
Value Function Update Magnitude: 0.55654

Collected Steps per Second: 21,461.47846
Overall Steps per Second: 10,277.89054

Timestep Collection Time: 2.33087
Timestep Consumption Time: 2.53627
PPO Batch Consumption Time: 0.29348
Total Iteration Time: 4.86715

Cumulative Model Updates: 104,092
Cumulative Timesteps: 867,990,602

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91,724.54043
Policy Entropy: 3.68027
Value Function Loss: 0.03236

Mean KL Divergence: 0.01060
SB3 Clip Fraction: 0.14318
Policy Update Magnitude: 0.56643
Value Function Update Magnitude: 0.59657

Collected Steps per Second: 21,329.05592
Overall Steps per Second: 10,280.26636

Timestep Collection Time: 2.34460
Timestep Consumption Time: 2.51987
PPO Batch Consumption Time: 0.28650
Total Iteration Time: 4.86447

Cumulative Model Updates: 104,098
Cumulative Timesteps: 868,040,610

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 868040610...
Checkpoint 868040610 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 91,724.54043
Policy Entropy: 3.70700
Value Function Loss: 0.02837

Mean KL Divergence: 0.01070
SB3 Clip Fraction: 0.14531
Policy Update Magnitude: 0.49630
Value Function Update Magnitude: 0.51988

Collected Steps per Second: 21,402.93918
Overall Steps per Second: 10,191.58418

Timestep Collection Time: 2.33790
Timestep Consumption Time: 2.57183
PPO Batch Consumption Time: 0.29887
Total Iteration Time: 4.90974

Cumulative Model Updates: 104,104
Cumulative Timesteps: 868,090,648

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91,724.54043
Policy Entropy: 3.70138
Value Function Loss: 0.02599

Mean KL Divergence: 0.01083
SB3 Clip Fraction: 0.14764
Policy Update Magnitude: 0.43940
Value Function Update Magnitude: 0.39701

Collected Steps per Second: 21,844.23064
Overall Steps per Second: 10,391.66634

Timestep Collection Time: 2.28957
Timestep Consumption Time: 2.52332
PPO Batch Consumption Time: 0.28897
Total Iteration Time: 4.81290

Cumulative Model Updates: 104,110
Cumulative Timesteps: 868,140,662

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 868140662...
Checkpoint 868140662 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 91,724.54043
Policy Entropy: 3.68662
Value Function Loss: 0.02388

Mean KL Divergence: 0.01089
SB3 Clip Fraction: 0.14918
Policy Update Magnitude: 0.40360
Value Function Update Magnitude: 0.30522

Collected Steps per Second: 21,716.02637
Overall Steps per Second: 10,252.11490

Timestep Collection Time: 2.30291
Timestep Consumption Time: 2.57511
PPO Batch Consumption Time: 0.29585
Total Iteration Time: 4.87802

Cumulative Model Updates: 104,116
Cumulative Timesteps: 868,190,672

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91,724.54043
Policy Entropy: 3.67626
Value Function Loss: 0.02564

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.14116
Policy Update Magnitude: 0.42869
Value Function Update Magnitude: 0.33408

Collected Steps per Second: 21,784.56046
Overall Steps per Second: 10,412.16264

Timestep Collection Time: 2.29603
Timestep Consumption Time: 2.50778
PPO Batch Consumption Time: 0.28814
Total Iteration Time: 4.80381

Cumulative Model Updates: 104,122
Cumulative Timesteps: 868,240,690

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 868240690...
Checkpoint 868240690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 91,724.54043
Policy Entropy: 3.68105
Value Function Loss: 0.02622

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.14055
Policy Update Magnitude: 0.48126
Value Function Update Magnitude: 0.38844

Collected Steps per Second: 20,865.22350
Overall Steps per Second: 10,265.45266

Timestep Collection Time: 2.39729
Timestep Consumption Time: 2.47536
PPO Batch Consumption Time: 0.29630
Total Iteration Time: 4.87265

Cumulative Model Updates: 104,128
Cumulative Timesteps: 868,290,710

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91,724.54043
Policy Entropy: 3.69984
Value Function Loss: 0.02567

Mean KL Divergence: 0.01120
SB3 Clip Fraction: 0.14986
Policy Update Magnitude: 0.46106
Value Function Update Magnitude: 0.33447

Collected Steps per Second: 20,749.25955
Overall Steps per Second: 10,338.21689

Timestep Collection Time: 2.41011
Timestep Consumption Time: 2.42709
PPO Batch Consumption Time: 0.28779
Total Iteration Time: 4.83720

Cumulative Model Updates: 104,134
Cumulative Timesteps: 868,340,718

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 868340718...
Checkpoint 868340718 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 91,724.54043
Policy Entropy: 3.70041
Value Function Loss: 0.02659

Mean KL Divergence: 0.01115
SB3 Clip Fraction: 0.14909
Policy Update Magnitude: 0.42617
Value Function Update Magnitude: 0.29803

Collected Steps per Second: 20,678.60669
Overall Steps per Second: 10,210.55869

Timestep Collection Time: 2.41912
Timestep Consumption Time: 2.48012
PPO Batch Consumption Time: 0.28774
Total Iteration Time: 4.89924

Cumulative Model Updates: 104,140
Cumulative Timesteps: 868,390,742

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91,724.54043
Policy Entropy: 3.69018
Value Function Loss: 0.02533

Mean KL Divergence: 0.01239
SB3 Clip Fraction: 0.16468
Policy Update Magnitude: 0.44234
Value Function Update Magnitude: 0.30744

Collected Steps per Second: 21,595.97118
Overall Steps per Second: 10,365.75821

Timestep Collection Time: 2.31756
Timestep Consumption Time: 2.51084
PPO Batch Consumption Time: 0.29500
Total Iteration Time: 4.82840

Cumulative Model Updates: 104,146
Cumulative Timesteps: 868,440,792

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 868440792...
Checkpoint 868440792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 91,724.54043
Policy Entropy: 3.67858
Value Function Loss: 0.02773

Mean KL Divergence: 0.01144
SB3 Clip Fraction: 0.15403
Policy Update Magnitude: 0.45330
Value Function Update Magnitude: 0.30985

Collected Steps per Second: 21,304.16519
Overall Steps per Second: 10,322.73201

Timestep Collection Time: 2.34780
Timestep Consumption Time: 2.49762
PPO Batch Consumption Time: 0.28777
Total Iteration Time: 4.84542

Cumulative Model Updates: 104,152
Cumulative Timesteps: 868,490,810

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91,724.54043
Policy Entropy: 3.68325
Value Function Loss: 0.02648

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.14161
Policy Update Magnitude: 0.46490
Value Function Update Magnitude: 0.34782

Collected Steps per Second: 21,864.31505
Overall Steps per Second: 10,320.11873

Timestep Collection Time: 2.28683
Timestep Consumption Time: 2.55807
PPO Batch Consumption Time: 0.29588
Total Iteration Time: 4.84491

Cumulative Model Updates: 104,158
Cumulative Timesteps: 868,540,810

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 868540810...
Checkpoint 868540810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 153,162.96391
Policy Entropy: 3.67402
Value Function Loss: 0.02791

Mean KL Divergence: 0.01080
SB3 Clip Fraction: 0.14905
Policy Update Magnitude: 0.46876
Value Function Update Magnitude: 0.39680

Collected Steps per Second: 21,484.67344
Overall Steps per Second: 10,311.82867

Timestep Collection Time: 2.32724
Timestep Consumption Time: 2.52156
PPO Batch Consumption Time: 0.28737
Total Iteration Time: 4.84880

Cumulative Model Updates: 104,164
Cumulative Timesteps: 868,590,810

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 153,162.96391
Policy Entropy: 3.68244
Value Function Loss: 0.02430

Mean KL Divergence: 0.01159
SB3 Clip Fraction: 0.16227
Policy Update Magnitude: 0.42370
Value Function Update Magnitude: 0.40236

Collected Steps per Second: 21,324.06399
Overall Steps per Second: 10,194.26259

Timestep Collection Time: 2.34683
Timestep Consumption Time: 2.56220
PPO Batch Consumption Time: 0.29797
Total Iteration Time: 4.90904

Cumulative Model Updates: 104,170
Cumulative Timesteps: 868,640,854

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 868640854...
Checkpoint 868640854 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 153,162.96391
Policy Entropy: 3.67346
Value Function Loss: 0.02444

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.15462
Policy Update Magnitude: 0.36781
Value Function Update Magnitude: 0.35399

Collected Steps per Second: 21,472.64734
Overall Steps per Second: 10,190.56420

Timestep Collection Time: 2.32920
Timestep Consumption Time: 2.57868
PPO Batch Consumption Time: 0.29864
Total Iteration Time: 4.90787

Cumulative Model Updates: 104,176
Cumulative Timesteps: 868,690,868

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 153,162.96391
Policy Entropy: 3.69734
Value Function Loss: 0.02035

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.14708
Policy Update Magnitude: 0.34610
Value Function Update Magnitude: 0.31528

Collected Steps per Second: 21,929.66490
Overall Steps per Second: 10,425.92271

Timestep Collection Time: 2.28002
Timestep Consumption Time: 2.51572
PPO Batch Consumption Time: 0.28844
Total Iteration Time: 4.79574

Cumulative Model Updates: 104,182
Cumulative Timesteps: 868,740,868

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 868740868...
Checkpoint 868740868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 153,162.96391
Policy Entropy: 3.69767
Value Function Loss: 0.01994

Mean KL Divergence: 0.01050
SB3 Clip Fraction: 0.14643
Policy Update Magnitude: 0.33417
Value Function Update Magnitude: 0.31085

Collected Steps per Second: 21,356.23672
Overall Steps per Second: 10,240.08900

Timestep Collection Time: 2.34245
Timestep Consumption Time: 2.54286
PPO Batch Consumption Time: 0.29416
Total Iteration Time: 4.88531

Cumulative Model Updates: 104,188
Cumulative Timesteps: 868,790,894

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 153,162.96391
Policy Entropy: 3.71163
Value Function Loss: 0.01762

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.13584
Policy Update Magnitude: 0.30636
Value Function Update Magnitude: 0.31464

Collected Steps per Second: 21,143.31522
Overall Steps per Second: 10,434.19157

Timestep Collection Time: 2.36519
Timestep Consumption Time: 2.42751
PPO Batch Consumption Time: 0.28823
Total Iteration Time: 4.79270

Cumulative Model Updates: 104,194
Cumulative Timesteps: 868,840,902

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 868840902...
Checkpoint 868840902 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 153,162.96391
Policy Entropy: 3.70352
Value Function Loss: 0.01908

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.14209
Policy Update Magnitude: 0.32470
Value Function Update Magnitude: 0.29385

Collected Steps per Second: 20,802.46539
Overall Steps per Second: 10,233.48128

Timestep Collection Time: 2.40500
Timestep Consumption Time: 2.48385
PPO Batch Consumption Time: 0.29827
Total Iteration Time: 4.88885

Cumulative Model Updates: 104,200
Cumulative Timesteps: 868,890,932

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 153,162.96391
Policy Entropy: 3.70000
Value Function Loss: 0.01937

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.13993
Policy Update Magnitude: 0.34294
Value Function Update Magnitude: 0.33070

Collected Steps per Second: 21,214.48404
Overall Steps per Second: 10,337.30452

Timestep Collection Time: 2.35773
Timestep Consumption Time: 2.48086
PPO Batch Consumption Time: 0.28791
Total Iteration Time: 4.83859

Cumulative Model Updates: 104,206
Cumulative Timesteps: 868,940,950

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 868940950...
Checkpoint 868940950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 153,162.96391
Policy Entropy: 3.69163
Value Function Loss: 0.02149

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.14349
Policy Update Magnitude: 0.36390
Value Function Update Magnitude: 0.40179

Collected Steps per Second: 21,422.88219
Overall Steps per Second: 10,331.65748

Timestep Collection Time: 2.33461
Timestep Consumption Time: 2.50624
PPO Batch Consumption Time: 0.29274
Total Iteration Time: 4.84085

Cumulative Model Updates: 104,212
Cumulative Timesteps: 868,990,964

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 153,162.96391
Policy Entropy: 3.69236
Value Function Loss: 0.02304

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.13999
Policy Update Magnitude: 0.37479
Value Function Update Magnitude: 0.42365

Collected Steps per Second: 21,757.32072
Overall Steps per Second: 10,487.27642

Timestep Collection Time: 2.29817
Timestep Consumption Time: 2.46970
PPO Batch Consumption Time: 0.28604
Total Iteration Time: 4.76787

Cumulative Model Updates: 104,218
Cumulative Timesteps: 869,040,966

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 869040966...
Checkpoint 869040966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 153,162.96391
Policy Entropy: 3.69455
Value Function Loss: 0.02288

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.14504
Policy Update Magnitude: 0.37166
Value Function Update Magnitude: 0.40942

Collected Steps per Second: 21,427.27118
Overall Steps per Second: 10,184.77294

Timestep Collection Time: 2.33581
Timestep Consumption Time: 2.57839
PPO Batch Consumption Time: 0.30040
Total Iteration Time: 4.91420

Cumulative Model Updates: 104,224
Cumulative Timesteps: 869,091,016

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 153,162.96391
Policy Entropy: 3.69427
Value Function Loss: 0.02246

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.14690
Policy Update Magnitude: 0.36844
Value Function Update Magnitude: 0.36494

Collected Steps per Second: 21,855.21045
Overall Steps per Second: 10,401.19668

Timestep Collection Time: 2.28888
Timestep Consumption Time: 2.52056
PPO Batch Consumption Time: 0.28890
Total Iteration Time: 4.80945

Cumulative Model Updates: 104,230
Cumulative Timesteps: 869,141,040

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 869141040...
Checkpoint 869141040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 153,162.96391
Policy Entropy: 3.70317
Value Function Loss: 0.02004

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.14313
Policy Update Magnitude: 0.34476
Value Function Update Magnitude: 0.39270

Collected Steps per Second: 20,964.41947
Overall Steps per Second: 10,198.64622

Timestep Collection Time: 2.38547
Timestep Consumption Time: 2.51812
PPO Batch Consumption Time: 0.28851
Total Iteration Time: 4.90359

Cumulative Model Updates: 104,236
Cumulative Timesteps: 869,191,050

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 153,162.96391
Policy Entropy: 3.70054
Value Function Loss: 0.02081

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.13959
Policy Update Magnitude: 0.33035
Value Function Update Magnitude: 0.44156

Collected Steps per Second: 21,222.76252
Overall Steps per Second: 10,145.42177

Timestep Collection Time: 2.35728
Timestep Consumption Time: 2.57381
PPO Batch Consumption Time: 0.30231
Total Iteration Time: 4.93109

Cumulative Model Updates: 104,242
Cumulative Timesteps: 869,241,078

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 869241078...
Checkpoint 869241078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 153,162.96391
Policy Entropy: 3.70483
Value Function Loss: 0.02240

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.13858
Policy Update Magnitude: 0.32728
Value Function Update Magnitude: 0.32460

Collected Steps per Second: 21,272.56629
Overall Steps per Second: 10,185.82994

Timestep Collection Time: 2.35289
Timestep Consumption Time: 2.56100
PPO Batch Consumption Time: 0.29993
Total Iteration Time: 4.91389

Cumulative Model Updates: 104,248
Cumulative Timesteps: 869,291,130

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 153,162.96391
Policy Entropy: 3.70022
Value Function Loss: 0.02035

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.13702
Policy Update Magnitude: 0.33404
Value Function Update Magnitude: 0.33568

Collected Steps per Second: 21,587.94753
Overall Steps per Second: 10,346.46848

Timestep Collection Time: 2.31639
Timestep Consumption Time: 2.51676
PPO Batch Consumption Time: 0.28849
Total Iteration Time: 4.83315

Cumulative Model Updates: 104,254
Cumulative Timesteps: 869,341,136

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 869341136...
Checkpoint 869341136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 153,162.96391
Policy Entropy: 3.71046
Value Function Loss: 0.02006

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.14425
Policy Update Magnitude: 0.33373
Value Function Update Magnitude: 0.35934

Collected Steps per Second: 21,409.20317
Overall Steps per Second: 10,273.16200

Timestep Collection Time: 2.33582
Timestep Consumption Time: 2.53201
PPO Batch Consumption Time: 0.29342
Total Iteration Time: 4.86783

Cumulative Model Updates: 104,260
Cumulative Timesteps: 869,391,144

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 153,162.96391
Policy Entropy: 3.71263
Value Function Loss: 0.01927

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.13457
Policy Update Magnitude: 0.32776
Value Function Update Magnitude: 0.42066

Collected Steps per Second: 21,583.14026
Overall Steps per Second: 10,387.12694

Timestep Collection Time: 2.31699
Timestep Consumption Time: 2.49743
PPO Batch Consumption Time: 0.28782
Total Iteration Time: 4.81442

Cumulative Model Updates: 104,266
Cumulative Timesteps: 869,441,152

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 869441152...
Checkpoint 869441152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 153,162.96391
Policy Entropy: 3.71655
Value Function Loss: 0.01895

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.14441
Policy Update Magnitude: 0.35625
Value Function Update Magnitude: 0.49093

Collected Steps per Second: 20,875.42228
Overall Steps per Second: 10,393.90364

Timestep Collection Time: 2.39622
Timestep Consumption Time: 2.41641
PPO Batch Consumption Time: 0.28745
Total Iteration Time: 4.81263

Cumulative Model Updates: 104,272
Cumulative Timesteps: 869,491,174

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 153,162.96391
Policy Entropy: 3.70614
Value Function Loss: 0.01904

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.13781
Policy Update Magnitude: 0.34986
Value Function Update Magnitude: 0.49114

Collected Steps per Second: 20,658.73281
Overall Steps per Second: 10,213.40698

Timestep Collection Time: 2.42048
Timestep Consumption Time: 2.47544
PPO Batch Consumption Time: 0.29810
Total Iteration Time: 4.89592

Cumulative Model Updates: 104,278
Cumulative Timesteps: 869,541,178

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 869541178...
Checkpoint 869541178 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 153,162.96391
Policy Entropy: 3.70998
Value Function Loss: 0.02474

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.14291
Policy Update Magnitude: 0.37229
Value Function Update Magnitude: 0.41201

Collected Steps per Second: 20,792.72157
Overall Steps per Second: 10,091.73790

Timestep Collection Time: 2.40478
Timestep Consumption Time: 2.54996
PPO Batch Consumption Time: 0.30022
Total Iteration Time: 4.95475

Cumulative Model Updates: 104,284
Cumulative Timesteps: 869,591,180

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 153,162.96391
Policy Entropy: 3.69494
Value Function Loss: 0.02549

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.14421
Policy Update Magnitude: 0.38240
Value Function Update Magnitude: 0.33801

Collected Steps per Second: 21,473.55474
Overall Steps per Second: 10,403.97419

Timestep Collection Time: 2.32891
Timestep Consumption Time: 2.47791
PPO Batch Consumption Time: 0.28713
Total Iteration Time: 4.80682

Cumulative Model Updates: 104,290
Cumulative Timesteps: 869,641,190

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 869641190...
Checkpoint 869641190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 153,162.96391
Policy Entropy: 3.71192
Value Function Loss: 0.02391

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.14167
Policy Update Magnitude: 0.39472
Value Function Update Magnitude: 0.41302

Collected Steps per Second: 21,215.14310
Overall Steps per Second: 10,248.02255

Timestep Collection Time: 2.35784
Timestep Consumption Time: 2.52329
PPO Batch Consumption Time: 0.29693
Total Iteration Time: 4.88114

Cumulative Model Updates: 104,296
Cumulative Timesteps: 869,691,212

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 153,162.96391
Policy Entropy: 3.70079
Value Function Loss: 0.02301

Mean KL Divergence: 0.01071
SB3 Clip Fraction: 0.14797
Policy Update Magnitude: 0.37356
Value Function Update Magnitude: 0.39758

Collected Steps per Second: 21,681.80725
Overall Steps per Second: 10,340.02445

Timestep Collection Time: 2.30645
Timestep Consumption Time: 2.52990
PPO Batch Consumption Time: 0.28810
Total Iteration Time: 4.83635

Cumulative Model Updates: 104,302
Cumulative Timesteps: 869,741,220

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 869741220...
Checkpoint 869741220 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 153,162.96391
Policy Entropy: 3.70232
Value Function Loss: 0.02195

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.14119
Policy Update Magnitude: 0.36900
Value Function Update Magnitude: 0.44185

Collected Steps per Second: 21,419.81082
Overall Steps per Second: 10,335.02418

Timestep Collection Time: 2.33513
Timestep Consumption Time: 2.50453
PPO Batch Consumption Time: 0.28655
Total Iteration Time: 4.83966

Cumulative Model Updates: 104,308
Cumulative Timesteps: 869,791,238

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 615,355.30659
Policy Entropy: 3.69216
Value Function Loss: 0.02250

Mean KL Divergence: 0.01129
SB3 Clip Fraction: 0.15415
Policy Update Magnitude: 0.37645
Value Function Update Magnitude: 0.48013

Collected Steps per Second: 21,823.32988
Overall Steps per Second: 10,389.73705

Timestep Collection Time: 2.29241
Timestep Consumption Time: 2.52273
PPO Batch Consumption Time: 0.28902
Total Iteration Time: 4.81514

Cumulative Model Updates: 104,314
Cumulative Timesteps: 869,841,266

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 869841266...
Checkpoint 869841266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 615,355.30659
Policy Entropy: 3.69083
Value Function Loss: 0.02031

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.14084
Policy Update Magnitude: 0.36676
Value Function Update Magnitude: 0.47073

Collected Steps per Second: 21,172.33406
Overall Steps per Second: 10,062.49832

Timestep Collection Time: 2.36186
Timestep Consumption Time: 2.60769
PPO Batch Consumption Time: 0.30833
Total Iteration Time: 4.96954

Cumulative Model Updates: 104,320
Cumulative Timesteps: 869,891,272

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 615,355.30659
Policy Entropy: 3.70206
Value Function Loss: 0.01980

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.14242
Policy Update Magnitude: 0.38420
Value Function Update Magnitude: 0.54182

Collected Steps per Second: 21,887.76046
Overall Steps per Second: 10,280.00820

Timestep Collection Time: 2.28447
Timestep Consumption Time: 2.57953
PPO Batch Consumption Time: 0.30046
Total Iteration Time: 4.86400

Cumulative Model Updates: 104,326
Cumulative Timesteps: 869,941,274

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 869941274...
Checkpoint 869941274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 615,355.30659
Policy Entropy: 3.69309
Value Function Loss: 0.02188

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.14630
Policy Update Magnitude: 0.43963
Value Function Update Magnitude: 0.69099

Collected Steps per Second: 21,318.73972
Overall Steps per Second: 10,163.54898

Timestep Collection Time: 2.34535
Timestep Consumption Time: 2.57419
PPO Batch Consumption Time: 0.30132
Total Iteration Time: 4.91954

Cumulative Model Updates: 104,332
Cumulative Timesteps: 869,991,274

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 615,355.30659
Policy Entropy: 3.69014
Value Function Loss: 0.02023

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.14520
Policy Update Magnitude: 0.47020
Value Function Update Magnitude: 0.69409

Collected Steps per Second: 21,448.71794
Overall Steps per Second: 10,336.10553

Timestep Collection Time: 2.33142
Timestep Consumption Time: 2.50657
PPO Batch Consumption Time: 0.28793
Total Iteration Time: 4.83799

Cumulative Model Updates: 104,338
Cumulative Timesteps: 870,041,280

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 870041280...
Checkpoint 870041280 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 615,355.30659
Policy Entropy: 3.68693
Value Function Loss: 0.02107

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.14080
Policy Update Magnitude: 0.44837
Value Function Update Magnitude: 0.65968

Collected Steps per Second: 21,382.75338
Overall Steps per Second: 10,301.09326

Timestep Collection Time: 2.33861
Timestep Consumption Time: 2.51582
PPO Batch Consumption Time: 0.29127
Total Iteration Time: 4.85444

Cumulative Model Updates: 104,344
Cumulative Timesteps: 870,091,286

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 615,355.30659
Policy Entropy: 3.70191
Value Function Loss: 0.02065

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.14452
Policy Update Magnitude: 0.44517
Value Function Update Magnitude: 0.62942

Collected Steps per Second: 21,632.26065
Overall Steps per Second: 10,356.35872

Timestep Collection Time: 2.31275
Timestep Consumption Time: 2.51810
PPO Batch Consumption Time: 0.28904
Total Iteration Time: 4.83085

Cumulative Model Updates: 104,350
Cumulative Timesteps: 870,141,316

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 870141316...
Checkpoint 870141316 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 615,355.30659
Policy Entropy: 3.69698
Value Function Loss: 0.02004

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.14431
Policy Update Magnitude: 0.41694
Value Function Update Magnitude: 0.56089

Collected Steps per Second: 20,293.52397
Overall Steps per Second: 10,192.63497

Timestep Collection Time: 2.46404
Timestep Consumption Time: 2.44186
PPO Batch Consumption Time: 0.28851
Total Iteration Time: 4.90590

Cumulative Model Updates: 104,356
Cumulative Timesteps: 870,191,320

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 615,355.30659
Policy Entropy: 3.70480
Value Function Loss: 0.01928

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.14302
Policy Update Magnitude: 0.38275
Value Function Update Magnitude: 0.49464

Collected Steps per Second: 20,927.93158
Overall Steps per Second: 10,283.50539

Timestep Collection Time: 2.39039
Timestep Consumption Time: 2.47429
PPO Batch Consumption Time: 0.29741
Total Iteration Time: 4.86468

Cumulative Model Updates: 104,362
Cumulative Timesteps: 870,241,346

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 870241346...
Checkpoint 870241346 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 677,561.24131
Policy Entropy: 3.70191
Value Function Loss: 0.01949

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.14420
Policy Update Magnitude: 0.38511
Value Function Update Magnitude: 0.53779

Collected Steps per Second: 21,017.88586
Overall Steps per Second: 10,192.47273

Timestep Collection Time: 2.38121
Timestep Consumption Time: 2.52908
PPO Batch Consumption Time: 0.29950
Total Iteration Time: 4.91029

Cumulative Model Updates: 104,368
Cumulative Timesteps: 870,291,394

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 236,271.17602
Policy Entropy: 3.73268
Value Function Loss: 0.01845

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.13958
Policy Update Magnitude: 0.43955
Value Function Update Magnitude: 0.68113

Collected Steps per Second: 21,624.81644
Overall Steps per Second: 10,335.73039

Timestep Collection Time: 2.31253
Timestep Consumption Time: 2.52583
PPO Batch Consumption Time: 0.29260
Total Iteration Time: 4.83836

Cumulative Model Updates: 104,374
Cumulative Timesteps: 870,341,402

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 870341402...
Checkpoint 870341402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 101,737.62755
Policy Entropy: 3.72549
Value Function Loss: 0.02169

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.14358
Policy Update Magnitude: 0.47769
Value Function Update Magnitude: 0.65645

Collected Steps per Second: 21,369.94790
Overall Steps per Second: 10,214.86173

Timestep Collection Time: 2.34058
Timestep Consumption Time: 2.55601
PPO Batch Consumption Time: 0.30066
Total Iteration Time: 4.89659

Cumulative Model Updates: 104,380
Cumulative Timesteps: 870,391,420

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82,416.73692
Policy Entropy: 3.72073
Value Function Loss: 0.02101

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.14041
Policy Update Magnitude: 0.49071
Value Function Update Magnitude: 0.72504

Collected Steps per Second: 21,594.67105
Overall Steps per Second: 10,349.88787

Timestep Collection Time: 2.31631
Timestep Consumption Time: 2.51659
PPO Batch Consumption Time: 0.28787
Total Iteration Time: 4.83290

Cumulative Model Updates: 104,386
Cumulative Timesteps: 870,441,440

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 870441440...
Checkpoint 870441440 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,111,284.52654
Policy Entropy: 3.69025
Value Function Loss: 0.02677

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.14061
Policy Update Magnitude: 0.53259
Value Function Update Magnitude: 0.77305

Collected Steps per Second: 21,311.55925
Overall Steps per Second: 10,163.59882

Timestep Collection Time: 2.34652
Timestep Consumption Time: 2.57378
PPO Batch Consumption Time: 0.29955
Total Iteration Time: 4.92030

Cumulative Model Updates: 104,392
Cumulative Timesteps: 870,491,448

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 900,143.70530
Policy Entropy: 3.69492
Value Function Loss: 0.02407

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.14376
Policy Update Magnitude: 0.53897
Value Function Update Magnitude: 0.66438

Collected Steps per Second: 21,859.82201
Overall Steps per Second: 10,183.23200

Timestep Collection Time: 2.28767
Timestep Consumption Time: 2.62315
PPO Batch Consumption Time: 0.30379
Total Iteration Time: 4.91082

Cumulative Model Updates: 104,398
Cumulative Timesteps: 870,541,456

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 870541456...
Checkpoint 870541456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 640,184.37504
Policy Entropy: 3.69542
Value Function Loss: 0.02685

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.14204
Policy Update Magnitude: 0.53751
Value Function Update Magnitude: 0.79088

Collected Steps per Second: 21,423.68422
Overall Steps per Second: 10,179.22221

Timestep Collection Time: 2.33452
Timestep Consumption Time: 2.57882
PPO Batch Consumption Time: 0.29743
Total Iteration Time: 4.91334

Cumulative Model Updates: 104,404
Cumulative Timesteps: 870,591,470

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 223,226.99839
Policy Entropy: 3.71580
Value Function Loss: 0.02452

Mean KL Divergence: 0.01071
SB3 Clip Fraction: 0.14896
Policy Update Magnitude: 0.57377
Value Function Update Magnitude: 0.78768

Collected Steps per Second: 21,686.17697
Overall Steps per Second: 10,365.01912

Timestep Collection Time: 2.30728
Timestep Consumption Time: 2.52011
PPO Batch Consumption Time: 0.28810
Total Iteration Time: 4.82739

Cumulative Model Updates: 104,410
Cumulative Timesteps: 870,641,506

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 870641506...
Checkpoint 870641506 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,490.94225
Policy Entropy: 3.73152
Value Function Loss: 0.02504

Mean KL Divergence: 0.01077
SB3 Clip Fraction: 0.14974
Policy Update Magnitude: 0.55390
Value Function Update Magnitude: 0.81374

Collected Steps per Second: 21,892.07295
Overall Steps per Second: 10,311.92299

Timestep Collection Time: 2.28421
Timestep Consumption Time: 2.56513
PPO Batch Consumption Time: 0.29801
Total Iteration Time: 4.84934

Cumulative Model Updates: 104,416
Cumulative Timesteps: 870,691,512

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,759.66190
Policy Entropy: 3.73647
Value Function Loss: 0.02287

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.14122
Policy Update Magnitude: 0.52292
Value Function Update Magnitude: 0.71078

Collected Steps per Second: 21,587.79138
Overall Steps per Second: 10,360.47419

Timestep Collection Time: 2.31649
Timestep Consumption Time: 2.51031
PPO Batch Consumption Time: 0.28814
Total Iteration Time: 4.82681

Cumulative Model Updates: 104,422
Cumulative Timesteps: 870,741,520

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 870741520...
Checkpoint 870741520 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,759.66190
Policy Entropy: 3.72101
Value Function Loss: 0.02351

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.14771
Policy Update Magnitude: 0.49857
Value Function Update Magnitude: 0.58538

Collected Steps per Second: 21,529.79577
Overall Steps per Second: 10,312.42602

Timestep Collection Time: 2.32320
Timestep Consumption Time: 2.52707
PPO Batch Consumption Time: 0.29158
Total Iteration Time: 4.85027

Cumulative Model Updates: 104,428
Cumulative Timesteps: 870,791,538

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,759.66190
Policy Entropy: 3.69877
Value Function Loss: 0.02425

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.14003
Policy Update Magnitude: 0.46067
Value Function Update Magnitude: 0.50205

Collected Steps per Second: 21,815.29926
Overall Steps per Second: 10,396.82166

Timestep Collection Time: 2.29316
Timestep Consumption Time: 2.51850
PPO Batch Consumption Time: 0.28849
Total Iteration Time: 4.81166

Cumulative Model Updates: 104,434
Cumulative Timesteps: 870,841,564

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 870841564...
Checkpoint 870841564 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 988,649.78083
Policy Entropy: 3.69107
Value Function Loss: 0.02551

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.14355
Policy Update Magnitude: 0.48878
Value Function Update Magnitude: 0.48758

Collected Steps per Second: 21,572.74752
Overall Steps per Second: 10,272.66109

Timestep Collection Time: 2.31987
Timestep Consumption Time: 2.55189
PPO Batch Consumption Time: 0.29537
Total Iteration Time: 4.87177

Cumulative Model Updates: 104,440
Cumulative Timesteps: 870,891,610

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 276,275.96513
Policy Entropy: 3.70599
Value Function Loss: 0.02611

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.14292
Policy Update Magnitude: 0.49019
Value Function Update Magnitude: 0.53505

Collected Steps per Second: 21,591.67082
Overall Steps per Second: 10,333.26825

Timestep Collection Time: 2.31710
Timestep Consumption Time: 2.52455
PPO Batch Consumption Time: 0.28870
Total Iteration Time: 4.84164

Cumulative Model Updates: 104,446
Cumulative Timesteps: 870,941,640

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 870941640...
Checkpoint 870941640 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 96,351.32726
Policy Entropy: 3.72185
Value Function Loss: 0.02567

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.13886
Policy Update Magnitude: 0.48580
Value Function Update Magnitude: 0.59913

Collected Steps per Second: 21,570.08312
Overall Steps per Second: 10,339.77785

Timestep Collection Time: 2.31858
Timestep Consumption Time: 2.51827
PPO Batch Consumption Time: 0.29116
Total Iteration Time: 4.83685

Cumulative Model Updates: 104,452
Cumulative Timesteps: 870,991,652

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 96,351.32726
Policy Entropy: 3.71583
Value Function Loss: 0.02540

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.14028
Policy Update Magnitude: 0.47181
Value Function Update Magnitude: 0.63065

Collected Steps per Second: 21,616.90397
Overall Steps per Second: 10,357.12901

Timestep Collection Time: 2.31402
Timestep Consumption Time: 2.51569
PPO Batch Consumption Time: 0.28790
Total Iteration Time: 4.82972

Cumulative Model Updates: 104,458
Cumulative Timesteps: 871,041,674

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 871041674...
Checkpoint 871041674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 96,351.32726
Policy Entropy: 3.70154
Value Function Loss: 0.02295

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.14126
Policy Update Magnitude: 0.47097
Value Function Update Magnitude: 0.64373

Collected Steps per Second: 21,219.68881
Overall Steps per Second: 10,254.75529

Timestep Collection Time: 2.35734
Timestep Consumption Time: 2.52059
PPO Batch Consumption Time: 0.28826
Total Iteration Time: 4.87793

Cumulative Model Updates: 104,464
Cumulative Timesteps: 871,091,696

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 96,351.32726
Policy Entropy: 3.69245
Value Function Loss: 0.02199

Mean KL Divergence: 0.01081
SB3 Clip Fraction: 0.14846
Policy Update Magnitude: 0.44598
Value Function Update Magnitude: 0.57983

Collected Steps per Second: 21,799.78802
Overall Steps per Second: 10,227.45205

Timestep Collection Time: 2.29488
Timestep Consumption Time: 2.59666
PPO Batch Consumption Time: 0.30201
Total Iteration Time: 4.89154

Cumulative Model Updates: 104,470
Cumulative Timesteps: 871,141,724

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 871141724...
Checkpoint 871141724 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 96,351.32726
Policy Entropy: 3.69109
Value Function Loss: 0.02087

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.14644
Policy Update Magnitude: 0.43123
Value Function Update Magnitude: 0.55216

Collected Steps per Second: 21,552.43098
Overall Steps per Second: 10,358.52687

Timestep Collection Time: 2.32030
Timestep Consumption Time: 2.50742
PPO Batch Consumption Time: 0.28842
Total Iteration Time: 4.82771

Cumulative Model Updates: 104,476
Cumulative Timesteps: 871,191,732

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 96,351.32726
Policy Entropy: 3.70798
Value Function Loss: 0.01873

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.15305
Policy Update Magnitude: 0.41370
Value Function Update Magnitude: 0.50338

Collected Steps per Second: 21,606.99299
Overall Steps per Second: 10,274.23297

Timestep Collection Time: 2.31416
Timestep Consumption Time: 2.55258
PPO Batch Consumption Time: 0.29718
Total Iteration Time: 4.86674

Cumulative Model Updates: 104,482
Cumulative Timesteps: 871,241,734

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 871241734...
Checkpoint 871241734 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 96,351.32726
Policy Entropy: 3.70588
Value Function Loss: 0.02048

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.13921
Policy Update Magnitude: 0.39847
Value Function Update Magnitude: 0.44400

Collected Steps per Second: 21,458.35807
Overall Steps per Second: 10,250.86626

Timestep Collection Time: 2.33252
Timestep Consumption Time: 2.55019
PPO Batch Consumption Time: 0.29726
Total Iteration Time: 4.88271

Cumulative Model Updates: 104,488
Cumulative Timesteps: 871,291,786

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 96,351.32726
Policy Entropy: 3.70941
Value Function Loss: 0.02213

Mean KL Divergence: 0.01164
SB3 Clip Fraction: 0.15573
Policy Update Magnitude: 0.48276
Value Function Update Magnitude: 0.47114

Collected Steps per Second: 21,756.66655
Overall Steps per Second: 10,287.34724

Timestep Collection Time: 2.29824
Timestep Consumption Time: 2.56230
PPO Batch Consumption Time: 0.29490
Total Iteration Time: 4.86053

Cumulative Model Updates: 104,494
Cumulative Timesteps: 871,341,788

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 871341788...
Checkpoint 871341788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 937,164.89606
Policy Entropy: 3.68178
Value Function Loss: 0.02913

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.14252
Policy Update Magnitude: 0.50812
Value Function Update Magnitude: 0.53358

Collected Steps per Second: 21,543.41878
Overall Steps per Second: 10,219.48365

Timestep Collection Time: 2.32089
Timestep Consumption Time: 2.57172
PPO Batch Consumption Time: 0.30073
Total Iteration Time: 4.89262

Cumulative Model Updates: 104,500
Cumulative Timesteps: 871,391,788

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 259,847.83640
Policy Entropy: 3.70380
Value Function Loss: 0.02864

Mean KL Divergence: 0.01090
SB3 Clip Fraction: 0.14907
Policy Update Magnitude: 0.58193
Value Function Update Magnitude: 0.69203

Collected Steps per Second: 21,005.38162
Overall Steps per Second: 10,385.48573

Timestep Collection Time: 2.38120
Timestep Consumption Time: 2.43495
PPO Batch Consumption Time: 0.28863
Total Iteration Time: 4.81614

Cumulative Model Updates: 104,506
Cumulative Timesteps: 871,441,806

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 871441806...
Checkpoint 871441806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 138,110.77958
Policy Entropy: 3.68654
Value Function Loss: 0.03017

Mean KL Divergence: 0.01212
SB3 Clip Fraction: 0.16033
Policy Update Magnitude: 0.59743
Value Function Update Magnitude: 0.75716

Collected Steps per Second: 20,758.41879
Overall Steps per Second: 10,248.59421

Timestep Collection Time: 2.40866
Timestep Consumption Time: 2.47006
PPO Batch Consumption Time: 0.29493
Total Iteration Time: 4.87872

Cumulative Model Updates: 104,512
Cumulative Timesteps: 871,491,806

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 406,647.30012
Policy Entropy: 3.71303
Value Function Loss: 0.02541

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.13825
Policy Update Magnitude: 0.58783
Value Function Update Magnitude: 0.83991

Collected Steps per Second: 20,861.95765
Overall Steps per Second: 10,352.09302

Timestep Collection Time: 2.39853
Timestep Consumption Time: 2.43508
PPO Batch Consumption Time: 0.28816
Total Iteration Time: 4.83361

Cumulative Model Updates: 104,518
Cumulative Timesteps: 871,541,844

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 871541844...
Checkpoint 871541844 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 184,082.91193
Policy Entropy: 3.69506
Value Function Loss: 0.02512

Mean KL Divergence: 0.01074
SB3 Clip Fraction: 0.15067
Policy Update Magnitude: 0.53984
Value Function Update Magnitude: 0.84899

Collected Steps per Second: 20,850.94990
Overall Steps per Second: 10,257.39599

Timestep Collection Time: 2.39855
Timestep Consumption Time: 2.47715
PPO Batch Consumption Time: 0.28788
Total Iteration Time: 4.87570

Cumulative Model Updates: 104,524
Cumulative Timesteps: 871,591,856

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 426,967.26091
Policy Entropy: 3.70048
Value Function Loss: 0.02619

Mean KL Divergence: 0.01148
SB3 Clip Fraction: 0.15427
Policy Update Magnitude: 0.56548
Value Function Update Magnitude: 0.85634

Collected Steps per Second: 21,668.63849
Overall Steps per Second: 10,441.66895

Timestep Collection Time: 2.30877
Timestep Consumption Time: 2.48241
PPO Batch Consumption Time: 0.28789
Total Iteration Time: 4.79119

Cumulative Model Updates: 104,530
Cumulative Timesteps: 871,641,884

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 871641884...
Checkpoint 871641884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 426,967.26091
Policy Entropy: 3.69059
Value Function Loss: 0.02780

Mean KL Divergence: 0.01217
SB3 Clip Fraction: 0.16537
Policy Update Magnitude: 0.58028
Value Function Update Magnitude: 0.81685

Collected Steps per Second: 20,970.15717
Overall Steps per Second: 10,262.19521

Timestep Collection Time: 2.38520
Timestep Consumption Time: 2.48881
PPO Batch Consumption Time: 0.28783
Total Iteration Time: 4.87401

Cumulative Model Updates: 104,536
Cumulative Timesteps: 871,691,902

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 426,967.26091
Policy Entropy: 3.69821
Value Function Loss: 0.02717

Mean KL Divergence: 0.01287
SB3 Clip Fraction: 0.16641
Policy Update Magnitude: 0.54483
Value Function Update Magnitude: 0.62258

Collected Steps per Second: 21,545.09172
Overall Steps per Second: 10,338.91008

Timestep Collection Time: 2.32239
Timestep Consumption Time: 2.51720
PPO Batch Consumption Time: 0.28862
Total Iteration Time: 4.83958

Cumulative Model Updates: 104,542
Cumulative Timesteps: 871,741,938

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 871741938...
Checkpoint 871741938 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 426,967.26091
Policy Entropy: 3.71646
Value Function Loss: 0.02124

Mean KL Divergence: 0.01512
SB3 Clip Fraction: 0.18441
Policy Update Magnitude: 0.52206
Value Function Update Magnitude: 0.48796

Collected Steps per Second: 21,536.37356
Overall Steps per Second: 10,270.84502

Timestep Collection Time: 2.32230
Timestep Consumption Time: 2.54721
PPO Batch Consumption Time: 0.28869
Total Iteration Time: 4.86951

Cumulative Model Updates: 104,548
Cumulative Timesteps: 871,791,952

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 641,177.70300
Policy Entropy: 3.71653
Value Function Loss: 0.02259

Mean KL Divergence: 0.01489
SB3 Clip Fraction: 0.16989
Policy Update Magnitude: 0.54187
Value Function Update Magnitude: 0.68377

Collected Steps per Second: 21,160.78502
Overall Steps per Second: 10,138.55429

Timestep Collection Time: 2.36286
Timestep Consumption Time: 2.56881
PPO Batch Consumption Time: 0.29998
Total Iteration Time: 4.93167

Cumulative Model Updates: 104,554
Cumulative Timesteps: 871,841,952

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 871841952...
Checkpoint 871841952 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 83,469.91268
Policy Entropy: 3.71811
Value Function Loss: 0.02591

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.12981
Policy Update Magnitude: 0.75861
Value Function Update Magnitude: 0.92521

Collected Steps per Second: 21,409.73846
Overall Steps per Second: 10,174.59539

Timestep Collection Time: 2.33576
Timestep Consumption Time: 2.57923
PPO Batch Consumption Time: 0.30080
Total Iteration Time: 4.91499

Cumulative Model Updates: 104,560
Cumulative Timesteps: 871,891,960

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,362.36428
Policy Entropy: 3.72708
Value Function Loss: 0.03092

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.10323
Policy Update Magnitude: 0.86034
Value Function Update Magnitude: 0.93418

Collected Steps per Second: 21,371.23534
Overall Steps per Second: 10,158.75775

Timestep Collection Time: 2.34044
Timestep Consumption Time: 2.58320
PPO Batch Consumption Time: 0.29978
Total Iteration Time: 4.92363

Cumulative Model Updates: 104,566
Cumulative Timesteps: 871,941,978

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 871941978...
Checkpoint 871941978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,875.81395
Policy Entropy: 3.73711
Value Function Loss: 0.02876

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.10880
Policy Update Magnitude: 0.87440
Value Function Update Magnitude: 0.96428

Collected Steps per Second: 21,422.55700
Overall Steps per Second: 10,204.37232

Timestep Collection Time: 2.33427
Timestep Consumption Time: 2.56618
PPO Batch Consumption Time: 0.29862
Total Iteration Time: 4.90045

Cumulative Model Updates: 104,572
Cumulative Timesteps: 871,991,984

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 447,658.03730
Policy Entropy: 3.72492
Value Function Loss: 0.02900

Mean KL Divergence: 0.02952
SB3 Clip Fraction: 0.28633
Policy Update Magnitude: 0.76451
Value Function Update Magnitude: 1.06829

Collected Steps per Second: 21,510.72950
Overall Steps per Second: 10,372.70386

Timestep Collection Time: 2.32563
Timestep Consumption Time: 2.49722
PPO Batch Consumption Time: 0.28661
Total Iteration Time: 4.82285

Cumulative Model Updates: 104,578
Cumulative Timesteps: 872,042,010

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 872042010...
Checkpoint 872042010 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 182,526.68287
Policy Entropy: 3.75765
Value Function Loss: 0.03097

Mean KL Divergence: 0.03146
SB3 Clip Fraction: 0.32110
Policy Update Magnitude: 0.56143
Value Function Update Magnitude: 0.84970

Collected Steps per Second: 21,599.72697
Overall Steps per Second: 10,236.33442

Timestep Collection Time: 2.31596
Timestep Consumption Time: 2.57095
PPO Batch Consumption Time: 0.30013
Total Iteration Time: 4.88691

Cumulative Model Updates: 104,584
Cumulative Timesteps: 872,092,034

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,195.01002
Policy Entropy: 3.75940
Value Function Loss: 0.03411

Mean KL Divergence: 0.01830
SB3 Clip Fraction: 0.22400
Policy Update Magnitude: 0.51512
Value Function Update Magnitude: 0.71629

Collected Steps per Second: 20,918.92193
Overall Steps per Second: 10,407.07783

Timestep Collection Time: 2.39104
Timestep Consumption Time: 2.41511
PPO Batch Consumption Time: 0.28653
Total Iteration Time: 4.80615

Cumulative Model Updates: 104,590
Cumulative Timesteps: 872,142,052

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 872142052...
Checkpoint 872142052 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 70,467.06196
Policy Entropy: 3.74766
Value Function Loss: 0.03583

Mean KL Divergence: 0.01335
SB3 Clip Fraction: 0.16550
Policy Update Magnitude: 0.63522
Value Function Update Magnitude: 0.53020

Collected Steps per Second: 20,487.64392
Overall Steps per Second: 10,196.09534

Timestep Collection Time: 2.44264
Timestep Consumption Time: 2.46551
PPO Batch Consumption Time: 0.29252
Total Iteration Time: 4.90815

Cumulative Model Updates: 104,596
Cumulative Timesteps: 872,192,096

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70,467.06196
Policy Entropy: 3.71289
Value Function Loss: 0.03480

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.12241
Policy Update Magnitude: 0.79010
Value Function Update Magnitude: 0.56331

Collected Steps per Second: 20,624.68660
Overall Steps per Second: 10,182.68903

Timestep Collection Time: 2.42583
Timestep Consumption Time: 2.48761
PPO Batch Consumption Time: 0.29787
Total Iteration Time: 4.91344

Cumulative Model Updates: 104,602
Cumulative Timesteps: 872,242,128

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 872242128...
Checkpoint 872242128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 70,467.06196
Policy Entropy: 3.70509
Value Function Loss: 0.03086

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.11121
Policy Update Magnitude: 0.81866
Value Function Update Magnitude: 0.52686

Collected Steps per Second: 20,765.86455
Overall Steps per Second: 10,088.27279

Timestep Collection Time: 2.40895
Timestep Consumption Time: 2.54968
PPO Batch Consumption Time: 0.30058
Total Iteration Time: 4.95863

Cumulative Model Updates: 104,608
Cumulative Timesteps: 872,292,152

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70,467.06196
Policy Entropy: 3.68665
Value Function Loss: 0.02769

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.11667
Policy Update Magnitude: 0.80401
Value Function Update Magnitude: 0.56071

Collected Steps per Second: 21,141.94846
Overall Steps per Second: 10,319.29819

Timestep Collection Time: 2.36544
Timestep Consumption Time: 2.48082
PPO Batch Consumption Time: 0.28756
Total Iteration Time: 4.84626

Cumulative Model Updates: 104,614
Cumulative Timesteps: 872,342,162

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 872342162...
Checkpoint 872342162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 70,467.06196
Policy Entropy: 3.66283
Value Function Loss: 0.02727

Mean KL Divergence: 0.00713
SB3 Clip Fraction: 0.08766
Policy Update Magnitude: 0.88565
Value Function Update Magnitude: 0.75261

Collected Steps per Second: 21,335.30352
Overall Steps per Second: 10,306.46357

Timestep Collection Time: 2.34428
Timestep Consumption Time: 2.50859
PPO Batch Consumption Time: 0.29262
Total Iteration Time: 4.85288

Cumulative Model Updates: 104,620
Cumulative Timesteps: 872,392,178

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70,467.06196
Policy Entropy: 3.68856
Value Function Loss: 0.02589

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.09693
Policy Update Magnitude: 0.91796
Value Function Update Magnitude: 0.75179

Collected Steps per Second: 21,519.45528
Overall Steps per Second: 10,310.34986

Timestep Collection Time: 2.32422
Timestep Consumption Time: 2.52683
PPO Batch Consumption Time: 0.29337
Total Iteration Time: 4.85105

Cumulative Model Updates: 104,626
Cumulative Timesteps: 872,442,194

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 872442194...
Checkpoint 872442194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 70,467.06196
Policy Entropy: 3.69566
Value Function Loss: 0.02602

Mean KL Divergence: 0.00677
SB3 Clip Fraction: 0.08223
Policy Update Magnitude: 0.82391
Value Function Update Magnitude: 0.67657

Collected Steps per Second: 21,124.48074
Overall Steps per Second: 10,257.21290

Timestep Collection Time: 2.36768
Timestep Consumption Time: 2.50850
PPO Batch Consumption Time: 0.28820
Total Iteration Time: 4.87618

Cumulative Model Updates: 104,632
Cumulative Timesteps: 872,492,210

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70,467.06196
Policy Entropy: 3.70109
Value Function Loss: 0.02342

Mean KL Divergence: 0.00731
SB3 Clip Fraction: 0.09177
Policy Update Magnitude: 0.74373
Value Function Update Magnitude: 0.53640

Collected Steps per Second: 21,878.04738
Overall Steps per Second: 10,353.61430

Timestep Collection Time: 2.28649
Timestep Consumption Time: 2.54506
PPO Batch Consumption Time: 0.29472
Total Iteration Time: 4.83155

Cumulative Model Updates: 104,638
Cumulative Timesteps: 872,542,234

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 872542234...
Checkpoint 872542234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 70,467.06196
Policy Entropy: 3.69554
Value Function Loss: 0.02394

Mean KL Divergence: 0.01655
SB3 Clip Fraction: 0.20531
Policy Update Magnitude: 0.58223
Value Function Update Magnitude: 0.47775

Collected Steps per Second: 21,463.34495
Overall Steps per Second: 10,336.36814

Timestep Collection Time: 2.32965
Timestep Consumption Time: 2.50784
PPO Batch Consumption Time: 0.28839
Total Iteration Time: 4.83748

Cumulative Model Updates: 104,644
Cumulative Timesteps: 872,592,236

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70,467.06196
Policy Entropy: 3.71908
Value Function Loss: 0.02274

Mean KL Divergence: 0.01814
SB3 Clip Fraction: 0.22327
Policy Update Magnitude: 0.45612
Value Function Update Magnitude: 0.44160

Collected Steps per Second: 21,798.66541
Overall Steps per Second: 10,360.76682

Timestep Collection Time: 2.29390
Timestep Consumption Time: 2.53238
PPO Batch Consumption Time: 0.29380
Total Iteration Time: 4.82628

Cumulative Model Updates: 104,650
Cumulative Timesteps: 872,642,240

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 872642240...
Checkpoint 872642240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 70,467.06196
Policy Entropy: 3.72841
Value Function Loss: 0.02280

Mean KL Divergence: 0.01210
SB3 Clip Fraction: 0.16659
Policy Update Magnitude: 0.40755
Value Function Update Magnitude: 0.41227

Collected Steps per Second: 21,641.60891
Overall Steps per Second: 10,389.29501

Timestep Collection Time: 2.31055
Timestep Consumption Time: 2.50248
PPO Batch Consumption Time: 0.29014
Total Iteration Time: 4.81303

Cumulative Model Updates: 104,656
Cumulative Timesteps: 872,692,244

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 874,461.55053
Policy Entropy: 3.70896
Value Function Loss: 0.02478

Mean KL Divergence: 0.01255
SB3 Clip Fraction: 0.16625
Policy Update Magnitude: 0.36771
Value Function Update Magnitude: 0.41548

Collected Steps per Second: 20,571.06487
Overall Steps per Second: 10,069.62937

Timestep Collection Time: 2.43089
Timestep Consumption Time: 2.53513
PPO Batch Consumption Time: 0.30073
Total Iteration Time: 4.96602

Cumulative Model Updates: 104,662
Cumulative Timesteps: 872,742,250

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 872742250...
Checkpoint 872742250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 874,461.55053
Policy Entropy: 3.71401
Value Function Loss: 0.02619

Mean KL Divergence: 0.01267
SB3 Clip Fraction: 0.16888
Policy Update Magnitude: 0.37582
Value Function Update Magnitude: 0.41041

Collected Steps per Second: 20,810.72387
Overall Steps per Second: 10,230.76418

Timestep Collection Time: 2.40395
Timestep Consumption Time: 2.48600
PPO Batch Consumption Time: 0.30038
Total Iteration Time: 4.88996

Cumulative Model Updates: 104,668
Cumulative Timesteps: 872,792,278

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,111,689.23385
Policy Entropy: 3.68473
Value Function Loss: 0.02827

Mean KL Divergence: 0.01376
SB3 Clip Fraction: 0.17828
Policy Update Magnitude: 0.40208
Value Function Update Magnitude: 0.44406

Collected Steps per Second: 20,958.11910
Overall Steps per Second: 10,274.23951

Timestep Collection Time: 2.38581
Timestep Consumption Time: 2.48093
PPO Batch Consumption Time: 0.28776
Total Iteration Time: 4.86673

Cumulative Model Updates: 104,674
Cumulative Timesteps: 872,842,280

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 872842280...
Checkpoint 872842280 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 313,995.04384
Policy Entropy: 3.70889
Value Function Loss: 0.02509

Mean KL Divergence: 0.01143
SB3 Clip Fraction: 0.15425
Policy Update Magnitude: 0.47166
Value Function Update Magnitude: 0.47109

Collected Steps per Second: 21,649.08454
Overall Steps per Second: 10,331.31109

Timestep Collection Time: 2.31160
Timestep Consumption Time: 2.53232
PPO Batch Consumption Time: 0.29785
Total Iteration Time: 4.84392

Cumulative Model Updates: 104,680
Cumulative Timesteps: 872,892,324

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 166,876.67625
Policy Entropy: 3.66237
Value Function Loss: 0.02958

Mean KL Divergence: 0.01508
SB3 Clip Fraction: 0.20039
Policy Update Magnitude: 0.50691
Value Function Update Magnitude: 0.62224

Collected Steps per Second: 21,293.07419
Overall Steps per Second: 10,335.83635

Timestep Collection Time: 2.34865
Timestep Consumption Time: 2.48985
PPO Batch Consumption Time: 0.28807
Total Iteration Time: 4.83851

Cumulative Model Updates: 104,686
Cumulative Timesteps: 872,942,334

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 872942334...
Checkpoint 872942334 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 166,876.67625
Policy Entropy: 3.67167
Value Function Loss: 0.03012

Mean KL Divergence: 0.01098
SB3 Clip Fraction: 0.14530
Policy Update Magnitude: 0.66529
Value Function Update Magnitude: 0.65973

Collected Steps per Second: 21,621.87500
Overall Steps per Second: 10,301.66222

Timestep Collection Time: 2.31257
Timestep Consumption Time: 2.54121
PPO Batch Consumption Time: 0.29287
Total Iteration Time: 4.85378

Cumulative Model Updates: 104,692
Cumulative Timesteps: 872,992,336

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 717,401.98937
Policy Entropy: 3.66608
Value Function Loss: 0.03714

Mean KL Divergence: 0.01516
SB3 Clip Fraction: 0.19235
Policy Update Magnitude: 0.73702
Value Function Update Magnitude: 0.76395

Collected Steps per Second: 21,810.89641
Overall Steps per Second: 10,370.23772

Timestep Collection Time: 2.29390
Timestep Consumption Time: 2.53068
PPO Batch Consumption Time: 0.28867
Total Iteration Time: 4.82458

Cumulative Model Updates: 104,698
Cumulative Timesteps: 873,042,368

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 873042368...
Checkpoint 873042368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,079,132.95088
Policy Entropy: 3.67803
Value Function Loss: 0.04368

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.14002
Policy Update Magnitude: 0.66838
Value Function Update Magnitude: 0.68091

Collected Steps per Second: 21,292.89715
Overall Steps per Second: 10,145.41409

Timestep Collection Time: 2.34858
Timestep Consumption Time: 2.58055
PPO Batch Consumption Time: 0.30113
Total Iteration Time: 4.92912

Cumulative Model Updates: 104,704
Cumulative Timesteps: 873,092,376

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 94,620.31626
Policy Entropy: 3.70476
Value Function Loss: 0.04465

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.13791
Policy Update Magnitude: 0.68744
Value Function Update Magnitude: 0.85050

Collected Steps per Second: 21,540.26550
Overall Steps per Second: 10,214.09097

Timestep Collection Time: 2.32207
Timestep Consumption Time: 2.57489
PPO Batch Consumption Time: 0.30119
Total Iteration Time: 4.89696

Cumulative Model Updates: 104,710
Cumulative Timesteps: 873,142,394

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 873142394...
Checkpoint 873142394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,007,613.04845
Policy Entropy: 3.70964
Value Function Loss: 0.04799

Mean KL Divergence: 0.01153
SB3 Clip Fraction: 0.14994
Policy Update Magnitude: 0.70138
Value Function Update Magnitude: 1.00369

Collected Steps per Second: 21,335.46056
Overall Steps per Second: 10,169.32152

Timestep Collection Time: 2.34370
Timestep Consumption Time: 2.57344
PPO Batch Consumption Time: 0.29969
Total Iteration Time: 4.91714

Cumulative Model Updates: 104,716
Cumulative Timesteps: 873,192,398

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,702.17332
Policy Entropy: 3.74804
Value Function Loss: 0.04569

Mean KL Divergence: 0.01061
SB3 Clip Fraction: 0.14210
Policy Update Magnitude: 0.69109
Value Function Update Magnitude: 0.91887

Collected Steps per Second: 21,716.38087
Overall Steps per Second: 10,395.14932

Timestep Collection Time: 2.30305
Timestep Consumption Time: 2.50823
PPO Batch Consumption Time: 0.28867
Total Iteration Time: 4.81128

Cumulative Model Updates: 104,722
Cumulative Timesteps: 873,242,412

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 873242412...
Checkpoint 873242412 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,790.35010
Policy Entropy: 3.72302
Value Function Loss: 0.04397

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.14121
Policy Update Magnitude: 0.66757
Value Function Update Magnitude: 0.97271

Collected Steps per Second: 21,298.11808
Overall Steps per Second: 10,332.35472

Timestep Collection Time: 2.34838
Timestep Consumption Time: 2.49234
PPO Batch Consumption Time: 0.28652
Total Iteration Time: 4.84072

Cumulative Model Updates: 104,728
Cumulative Timesteps: 873,292,428

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 123,839.47889
Policy Entropy: 3.72797
Value Function Loss: 0.04221

Mean KL Divergence: 0.01060
SB3 Clip Fraction: 0.14042
Policy Update Magnitude: 0.64568
Value Function Update Magnitude: 0.75737

Collected Steps per Second: 21,546.76122
Overall Steps per Second: 10,324.29606

Timestep Collection Time: 2.32109
Timestep Consumption Time: 2.52302
PPO Batch Consumption Time: 0.28955
Total Iteration Time: 4.84411

Cumulative Model Updates: 104,734
Cumulative Timesteps: 873,342,440

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 873342440...
Checkpoint 873342440 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,739.61161
Policy Entropy: 3.72007
Value Function Loss: 0.04084

Mean KL Divergence: 0.01070
SB3 Clip Fraction: 0.14291
Policy Update Magnitude: 0.68902
Value Function Update Magnitude: 0.74527

Collected Steps per Second: 21,534.30155
Overall Steps per Second: 10,297.44225

Timestep Collection Time: 2.32271
Timestep Consumption Time: 2.53461
PPO Batch Consumption Time: 0.29306
Total Iteration Time: 4.85732

Cumulative Model Updates: 104,740
Cumulative Timesteps: 873,392,458

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,020.85819
Policy Entropy: 3.74688
Value Function Loss: 0.03907

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.14297
Policy Update Magnitude: 0.63274
Value Function Update Magnitude: 0.74282

Collected Steps per Second: 21,813.89490
Overall Steps per Second: 10,371.32685

Timestep Collection Time: 2.29230
Timestep Consumption Time: 2.52907
PPO Batch Consumption Time: 0.28871
Total Iteration Time: 4.82137

Cumulative Model Updates: 104,746
Cumulative Timesteps: 873,442,462

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 873442462...
Checkpoint 873442462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 108.18475
Policy Entropy: 3.74520
Value Function Loss: 0.03267

Mean KL Divergence: 0.01057
SB3 Clip Fraction: 0.14603
Policy Update Magnitude: 0.56076
Value Function Update Magnitude: 0.76697

Collected Steps per Second: 21,512.32792
Overall Steps per Second: 10,277.37701

Timestep Collection Time: 2.32546
Timestep Consumption Time: 2.54213
PPO Batch Consumption Time: 0.29392
Total Iteration Time: 4.86758

Cumulative Model Updates: 104,752
Cumulative Timesteps: 873,492,488

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 117.34313
Policy Entropy: 3.73636
Value Function Loss: 0.02986

Mean KL Divergence: 0.01108
SB3 Clip Fraction: 0.15364
Policy Update Magnitude: 0.52701
Value Function Update Magnitude: 0.72008

Collected Steps per Second: 21,812.26672
Overall Steps per Second: 10,402.82131

Timestep Collection Time: 2.29256
Timestep Consumption Time: 2.51440
PPO Batch Consumption Time: 0.28955
Total Iteration Time: 4.80697

Cumulative Model Updates: 104,758
Cumulative Timesteps: 873,542,494

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 873542494...
Checkpoint 873542494 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,357.79121
Policy Entropy: 3.73168
Value Function Loss: 0.02529

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.14430
Policy Update Magnitude: 0.51094
Value Function Update Magnitude: 0.82223

Collected Steps per Second: 20,750.18211
Overall Steps per Second: 10,277.62169

Timestep Collection Time: 2.41155
Timestep Consumption Time: 2.45729
PPO Batch Consumption Time: 0.29376
Total Iteration Time: 4.86883

Cumulative Model Updates: 104,764
Cumulative Timesteps: 873,592,534

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,174.47015
Policy Entropy: 3.73321
Value Function Loss: 0.02463

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.14711
Policy Update Magnitude: 0.47982
Value Function Update Magnitude: 0.93781

Collected Steps per Second: 20,992.38403
Overall Steps per Second: 10,388.25576

Timestep Collection Time: 2.38315
Timestep Consumption Time: 2.43267
PPO Batch Consumption Time: 0.28804
Total Iteration Time: 4.81582

Cumulative Model Updates: 104,770
Cumulative Timesteps: 873,642,562

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 873642562...
Checkpoint 873642562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 323,804.75941
Policy Entropy: 3.72223
Value Function Loss: 0.02669

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.14191
Policy Update Magnitude: 0.47795
Value Function Update Magnitude: 0.86357

Collected Steps per Second: 20,788.35706
Overall Steps per Second: 10,117.68163

Timestep Collection Time: 2.40548
Timestep Consumption Time: 2.53696
PPO Batch Consumption Time: 0.30818
Total Iteration Time: 4.94244

Cumulative Model Updates: 104,776
Cumulative Timesteps: 873,692,568

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 137,011.38153
Policy Entropy: 3.73665
Value Function Loss: 0.02820

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.13749
Policy Update Magnitude: 0.50969
Value Function Update Magnitude: 0.89170

Collected Steps per Second: 21,252.84655
Overall Steps per Second: 10,122.26354

Timestep Collection Time: 2.35394
Timestep Consumption Time: 2.58843
PPO Batch Consumption Time: 0.30143
Total Iteration Time: 4.94237

Cumulative Model Updates: 104,782
Cumulative Timesteps: 873,742,596

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 873742596...
Checkpoint 873742596 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,380.60028
Policy Entropy: 3.75136
Value Function Loss: 0.03040

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.13740
Policy Update Magnitude: 0.51198
Value Function Update Magnitude: 0.70512

Collected Steps per Second: 21,520.15079
Overall Steps per Second: 10,276.49498

Timestep Collection Time: 2.32470
Timestep Consumption Time: 2.54349
PPO Batch Consumption Time: 0.29936
Total Iteration Time: 4.86820

Cumulative Model Updates: 104,788
Cumulative Timesteps: 873,792,624

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,740.48197
Policy Entropy: 3.77443
Value Function Loss: 0.02726

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.13338
Policy Update Magnitude: 0.51741
Value Function Update Magnitude: 0.64705

Collected Steps per Second: 21,476.88215
Overall Steps per Second: 10,386.65216

Timestep Collection Time: 2.32902
Timestep Consumption Time: 2.48678
PPO Batch Consumption Time: 0.28802
Total Iteration Time: 4.81580

Cumulative Model Updates: 104,794
Cumulative Timesteps: 873,842,644

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 873842644...
Checkpoint 873842644 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,555.02495
Policy Entropy: 3.75093
Value Function Loss: 0.02865

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.13717
Policy Update Magnitude: 0.54246
Value Function Update Magnitude: 0.75146

Collected Steps per Second: 21,390.79225
Overall Steps per Second: 10,313.12689

Timestep Collection Time: 2.33904
Timestep Consumption Time: 2.51244
PPO Batch Consumption Time: 0.29433
Total Iteration Time: 4.85149

Cumulative Model Updates: 104,800
Cumulative Timesteps: 873,892,678

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,064.62543
Policy Entropy: 3.72295
Value Function Loss: 0.02824

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.13824
Policy Update Magnitude: 0.56275
Value Function Update Magnitude: 0.93064

Collected Steps per Second: 21,572.88128
Overall Steps per Second: 10,340.44862

Timestep Collection Time: 2.31865
Timestep Consumption Time: 2.51866
PPO Batch Consumption Time: 0.28860
Total Iteration Time: 4.83731

Cumulative Model Updates: 104,806
Cumulative Timesteps: 873,942,698

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 873942698...
Checkpoint 873942698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43,064.62543
Policy Entropy: 3.69694
Value Function Loss: 0.02920

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.14388
Policy Update Magnitude: 0.54626
Value Function Update Magnitude: 0.87932

Collected Steps per Second: 21,389.50967
Overall Steps per Second: 10,337.10532

Timestep Collection Time: 2.33778
Timestep Consumption Time: 2.49955
PPO Batch Consumption Time: 0.28712
Total Iteration Time: 4.83733

Cumulative Model Updates: 104,812
Cumulative Timesteps: 873,992,702

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 185,892.90294
Policy Entropy: 3.69608
Value Function Loss: 0.02666

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.14532
Policy Update Magnitude: 0.51708
Value Function Update Magnitude: 0.85408

Collected Steps per Second: 21,706.28276
Overall Steps per Second: 10,367.35102

Timestep Collection Time: 2.30385
Timestep Consumption Time: 2.51976
PPO Batch Consumption Time: 0.28801
Total Iteration Time: 4.82360

Cumulative Model Updates: 104,818
Cumulative Timesteps: 874,042,710

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 874042710...
Checkpoint 874042710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86,576.36166
Policy Entropy: 3.69573
Value Function Loss: 0.02904

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.13829
Policy Update Magnitude: 0.50700
Value Function Update Magnitude: 0.81945

Collected Steps per Second: 21,410.08411
Overall Steps per Second: 10,277.05197

Timestep Collection Time: 2.33712
Timestep Consumption Time: 2.53178
PPO Batch Consumption Time: 0.29393
Total Iteration Time: 4.86891

Cumulative Model Updates: 104,824
Cumulative Timesteps: 874,092,748

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,798.93546
Policy Entropy: 3.73014
Value Function Loss: 0.03116

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.13695
Policy Update Magnitude: 0.53813
Value Function Update Magnitude: 0.73922

Collected Steps per Second: 21,521.47908
Overall Steps per Second: 10,318.43214

Timestep Collection Time: 2.32419
Timestep Consumption Time: 2.52345
PPO Batch Consumption Time: 0.28855
Total Iteration Time: 4.84764

Cumulative Model Updates: 104,830
Cumulative Timesteps: 874,142,768

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 874142768...
Checkpoint 874142768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,713.93506
Policy Entropy: 3.76056
Value Function Loss: 0.03571

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.13745
Policy Update Magnitude: 0.54409
Value Function Update Magnitude: 0.68268

Collected Steps per Second: 21,605.73121
Overall Steps per Second: 10,301.72545

Timestep Collection Time: 2.31559
Timestep Consumption Time: 2.54088
PPO Batch Consumption Time: 0.29331
Total Iteration Time: 4.85647

Cumulative Model Updates: 104,836
Cumulative Timesteps: 874,192,798

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,614.87265
Policy Entropy: 3.78567
Value Function Loss: 0.03373

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.13433
Policy Update Magnitude: 0.54811
Value Function Update Magnitude: 0.64835

Collected Steps per Second: 21,649.92404
Overall Steps per Second: 10,387.41062

Timestep Collection Time: 2.31003
Timestep Consumption Time: 2.50464
PPO Batch Consumption Time: 0.28782
Total Iteration Time: 4.81467

Cumulative Model Updates: 104,842
Cumulative Timesteps: 874,242,810

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 874242810...
Checkpoint 874242810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,409.32657
Policy Entropy: 3.75171
Value Function Loss: 0.03161

Mean KL Divergence: 0.01117
SB3 Clip Fraction: 0.14754
Policy Update Magnitude: 0.54519
Value Function Update Magnitude: 0.72333

Collected Steps per Second: 21,573.91678
Overall Steps per Second: 10,320.77457

Timestep Collection Time: 2.31836
Timestep Consumption Time: 2.52779
PPO Batch Consumption Time: 0.29177
Total Iteration Time: 4.84615

Cumulative Model Updates: 104,848
Cumulative Timesteps: 874,292,826

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 71,254.85846
Policy Entropy: 3.72522
Value Function Loss: 0.02994

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.14374
Policy Update Magnitude: 0.51257
Value Function Update Magnitude: 0.60117

Collected Steps per Second: 21,431.00402
Overall Steps per Second: 10,134.80067

Timestep Collection Time: 2.33438
Timestep Consumption Time: 2.60188
PPO Batch Consumption Time: 0.30319
Total Iteration Time: 4.93626

Cumulative Model Updates: 104,854
Cumulative Timesteps: 874,342,854

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 874342854...
Checkpoint 874342854 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,847.91609
Policy Entropy: 3.70912
Value Function Loss: 0.02866

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.15101
Policy Update Magnitude: 0.48659
Value Function Update Magnitude: 0.58871

Collected Steps per Second: 21,280.53384
Overall Steps per Second: 10,197.77966

Timestep Collection Time: 2.34966
Timestep Consumption Time: 2.55357
PPO Batch Consumption Time: 0.29815
Total Iteration Time: 4.90322

Cumulative Model Updates: 104,860
Cumulative Timesteps: 874,392,856

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,685.82333
Policy Entropy: 3.70520
Value Function Loss: 0.03667

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.14098
Policy Update Magnitude: 0.50516
Value Function Update Magnitude: 0.51764

Collected Steps per Second: 21,330.80397
Overall Steps per Second: 10,291.08886

Timestep Collection Time: 2.34431
Timestep Consumption Time: 2.51485
PPO Batch Consumption Time: 0.28800
Total Iteration Time: 4.85916

Cumulative Model Updates: 104,866
Cumulative Timesteps: 874,442,862

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 874442862...
Checkpoint 874442862 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,040.68666
Policy Entropy: 3.72114
Value Function Loss: 0.03352

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.14275
Policy Update Magnitude: 0.51227
Value Function Update Magnitude: 0.46318

Collected Steps per Second: 21,431.85864
Overall Steps per Second: 10,249.23661

Timestep Collection Time: 2.33372
Timestep Consumption Time: 2.54625
PPO Batch Consumption Time: 0.29436
Total Iteration Time: 4.87997

Cumulative Model Updates: 104,872
Cumulative Timesteps: 874,492,878

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,040.68666
Policy Entropy: 3.72760
Value Function Loss: 0.03099

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.14121
Policy Update Magnitude: 0.48324
Value Function Update Magnitude: 0.43274

Collected Steps per Second: 20,902.24499
Overall Steps per Second: 10,340.83693

Timestep Collection Time: 2.39237
Timestep Consumption Time: 2.44340
PPO Batch Consumption Time: 0.28847
Total Iteration Time: 4.83578

Cumulative Model Updates: 104,878
Cumulative Timesteps: 874,542,884

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 874542884...
Checkpoint 874542884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,040.68666
Policy Entropy: 3.74370
Value Function Loss: 0.02446

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.14384
Policy Update Magnitude: 0.45009
Value Function Update Magnitude: 0.42812

Collected Steps per Second: 21,136.33273
Overall Steps per Second: 10,328.72981

Timestep Collection Time: 2.36616
Timestep Consumption Time: 2.47587
PPO Batch Consumption Time: 0.29696
Total Iteration Time: 4.84203

Cumulative Model Updates: 104,884
Cumulative Timesteps: 874,592,896

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,746.02456
Policy Entropy: 3.73034
Value Function Loss: 0.02643

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.13837
Policy Update Magnitude: 0.42867
Value Function Update Magnitude: 0.45959

Collected Steps per Second: 21,014.37625
Overall Steps per Second: 10,111.47839

Timestep Collection Time: 2.37980
Timestep Consumption Time: 2.56606
PPO Batch Consumption Time: 0.30031
Total Iteration Time: 4.94586

Cumulative Model Updates: 104,890
Cumulative Timesteps: 874,642,906

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 874642906...
Checkpoint 874642906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 75,408.32022
Policy Entropy: 3.72418
Value Function Loss: 0.02647

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.13843
Policy Update Magnitude: 0.44262
Value Function Update Magnitude: 0.45514

Collected Steps per Second: 21,462.73053
Overall Steps per Second: 10,312.81093

Timestep Collection Time: 2.33027
Timestep Consumption Time: 2.51942
PPO Batch Consumption Time: 0.29690
Total Iteration Time: 4.84970

Cumulative Model Updates: 104,896
Cumulative Timesteps: 874,692,920

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,702.66266
Policy Entropy: 3.70153
Value Function Loss: 0.03532

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.13441
Policy Update Magnitude: 0.46309
Value Function Update Magnitude: 0.45243

Collected Steps per Second: 21,673.07828
Overall Steps per Second: 10,256.46935

Timestep Collection Time: 2.30802
Timestep Consumption Time: 2.56909
PPO Batch Consumption Time: 0.30150
Total Iteration Time: 4.87712

Cumulative Model Updates: 104,902
Cumulative Timesteps: 874,742,942

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 874742942...
Checkpoint 874742942 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,344.61721
Policy Entropy: 3.71969
Value Function Loss: 0.03011

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.14585
Policy Update Magnitude: 0.51244
Value Function Update Magnitude: 0.48500

Collected Steps per Second: 21,310.61746
Overall Steps per Second: 10,218.92268

Timestep Collection Time: 2.34700
Timestep Consumption Time: 2.54745
PPO Batch Consumption Time: 0.29970
Total Iteration Time: 4.89445

Cumulative Model Updates: 104,908
Cumulative Timesteps: 874,792,958

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 221,343.77466
Policy Entropy: 3.72782
Value Function Loss: 0.03415

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.12953
Policy Update Magnitude: 0.52522
Value Function Update Magnitude: 0.49791

Collected Steps per Second: 21,266.92762
Overall Steps per Second: 10,190.16383

Timestep Collection Time: 2.35210
Timestep Consumption Time: 2.55675
PPO Batch Consumption Time: 0.29926
Total Iteration Time: 4.90885

Cumulative Model Updates: 104,914
Cumulative Timesteps: 874,842,980

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 874842980...
Checkpoint 874842980 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,314.93059
Policy Entropy: 3.75543
Value Function Loss: 0.03122

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.12993
Policy Update Magnitude: 0.57036
Value Function Update Magnitude: 0.76727

Collected Steps per Second: 21,448.79178
Overall Steps per Second: 10,374.93280

Timestep Collection Time: 2.33188
Timestep Consumption Time: 2.48897
PPO Batch Consumption Time: 0.28817
Total Iteration Time: 4.82085

Cumulative Model Updates: 104,920
Cumulative Timesteps: 874,892,996

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51,555.50519
Policy Entropy: 3.73794
Value Function Loss: 0.03729

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.13571
Policy Update Magnitude: 0.57370
Value Function Update Magnitude: 0.84053

Collected Steps per Second: 21,381.71648
Overall Steps per Second: 10,178.27902

Timestep Collection Time: 2.33919
Timestep Consumption Time: 2.57480
PPO Batch Consumption Time: 0.30021
Total Iteration Time: 4.91399

Cumulative Model Updates: 104,926
Cumulative Timesteps: 874,943,012

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 874943012...
Checkpoint 874943012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,192.28146
Policy Entropy: 3.76132
Value Function Loss: 0.03196

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.12884
Policy Update Magnitude: 0.59725
Value Function Update Magnitude: 0.76384

Collected Steps per Second: 21,270.65444
Overall Steps per Second: 10,185.12338

Timestep Collection Time: 2.35066
Timestep Consumption Time: 2.55846
PPO Batch Consumption Time: 0.29425
Total Iteration Time: 4.90912

Cumulative Model Updates: 104,932
Cumulative Timesteps: 874,993,012

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,897.06447
Policy Entropy: 3.73387
Value Function Loss: 0.03273

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.13646
Policy Update Magnitude: 0.57606
Value Function Update Magnitude: 0.78055

Collected Steps per Second: 21,016.42204
Overall Steps per Second: 10,147.20178

Timestep Collection Time: 2.37995
Timestep Consumption Time: 2.54929
PPO Batch Consumption Time: 0.29751
Total Iteration Time: 4.92924

Cumulative Model Updates: 104,938
Cumulative Timesteps: 875,043,030

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 875043030...
Checkpoint 875043030 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,946.06021
Policy Entropy: 3.76160
Value Function Loss: 0.03045

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.12058
Policy Update Magnitude: 0.64062
Value Function Update Magnitude: 0.95896

Collected Steps per Second: 21,587.32461
Overall Steps per Second: 10,375.44309

Timestep Collection Time: 2.31617
Timestep Consumption Time: 2.50290
PPO Batch Consumption Time: 0.28854
Total Iteration Time: 4.81907

Cumulative Model Updates: 104,944
Cumulative Timesteps: 875,093,030

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 237.15697
Policy Entropy: 3.76098
Value Function Loss: 0.03452

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.11819
Policy Update Magnitude: 0.67887
Value Function Update Magnitude: 0.79912

Collected Steps per Second: 21,926.59758
Overall Steps per Second: 10,332.37692

Timestep Collection Time: 2.28134
Timestep Consumption Time: 2.55995
PPO Batch Consumption Time: 0.29568
Total Iteration Time: 4.84129

Cumulative Model Updates: 104,950
Cumulative Timesteps: 875,143,052

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 875143052...
Checkpoint 875143052 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39.22008
Policy Entropy: 3.76718
Value Function Loss: 0.02866

Mean KL Divergence: 0.00517
SB3 Clip Fraction: 0.05941
Policy Update Magnitude: 0.72860
Value Function Update Magnitude: 0.73170

Collected Steps per Second: 21,892.28173
Overall Steps per Second: 10,452.53451

Timestep Collection Time: 2.28610
Timestep Consumption Time: 2.50202
PPO Batch Consumption Time: 0.28647
Total Iteration Time: 4.78812

Cumulative Model Updates: 104,956
Cumulative Timesteps: 875,193,100

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22.93400
Policy Entropy: 3.74761
Value Function Loss: 0.02383

Mean KL Divergence: 0.00604
SB3 Clip Fraction: 0.07387
Policy Update Magnitude: 0.72621
Value Function Update Magnitude: 0.72695

Collected Steps per Second: 20,936.25117
Overall Steps per Second: 10,050.37990

Timestep Collection Time: 2.38906
Timestep Consumption Time: 2.58767
PPO Batch Consumption Time: 0.30091
Total Iteration Time: 4.97673

Cumulative Model Updates: 104,962
Cumulative Timesteps: 875,243,118

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 875243118...
Checkpoint 875243118 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14.28591
Policy Entropy: 3.73649
Value Function Loss: 0.02140

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.13545
Policy Update Magnitude: 0.56869
Value Function Update Magnitude: 0.62997

Collected Steps per Second: 21,303.53123
Overall Steps per Second: 10,175.39223

Timestep Collection Time: 2.34722
Timestep Consumption Time: 2.56699
PPO Batch Consumption Time: 0.29762
Total Iteration Time: 4.91421

Cumulative Model Updates: 104,968
Cumulative Timesteps: 875,293,122

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14.28591
Policy Entropy: 3.72908
Value Function Loss: 0.01959

Mean KL Divergence: 0.00735
SB3 Clip Fraction: 0.09258
Policy Update Magnitude: 0.55158
Value Function Update Magnitude: 0.61180

Collected Steps per Second: 21,743.76301
Overall Steps per Second: 10,369.24576

Timestep Collection Time: 2.29988
Timestep Consumption Time: 2.52285
PPO Batch Consumption Time: 0.28886
Total Iteration Time: 4.82272

Cumulative Model Updates: 104,974
Cumulative Timesteps: 875,343,130

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 875343130...
Checkpoint 875343130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14.28591
Policy Entropy: 3.72272
Value Function Loss: 0.02237

Mean KL Divergence: 0.01171
SB3 Clip Fraction: 0.15183
Policy Update Magnitude: 0.53901
Value Function Update Magnitude: 0.51187

Collected Steps per Second: 21,408.53777
Overall Steps per Second: 10,300.82517

Timestep Collection Time: 2.33589
Timestep Consumption Time: 2.51887
PPO Batch Consumption Time: 0.29011
Total Iteration Time: 4.85476

Cumulative Model Updates: 104,980
Cumulative Timesteps: 875,393,138

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14.28591
Policy Entropy: 3.72142
Value Function Loss: 0.02403

Mean KL Divergence: 0.01357
SB3 Clip Fraction: 0.15929
Policy Update Magnitude: 0.46863
Value Function Update Magnitude: 0.38472

Collected Steps per Second: 21,125.44865
Overall Steps per Second: 10,163.97929

Timestep Collection Time: 2.36833
Timestep Consumption Time: 2.55415
PPO Batch Consumption Time: 0.29776
Total Iteration Time: 4.92248

Cumulative Model Updates: 104,986
Cumulative Timesteps: 875,443,170

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 875443170...
Checkpoint 875443170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 175,806.62429
Policy Entropy: 3.73114
Value Function Loss: 0.02377

Mean KL Divergence: 0.01739
SB3 Clip Fraction: 0.19184
Policy Update Magnitude: 0.49290
Value Function Update Magnitude: 0.34420

Collected Steps per Second: 21,869.41168
Overall Steps per Second: 10,470.00081

Timestep Collection Time: 2.28831
Timestep Consumption Time: 2.49144
PPO Batch Consumption Time: 0.28832
Total Iteration Time: 4.77975

Cumulative Model Updates: 104,992
Cumulative Timesteps: 875,493,214

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 200,384.53504
Policy Entropy: 3.73222
Value Function Loss: 0.02665

Mean KL Divergence: 0.01351
SB3 Clip Fraction: 0.17346
Policy Update Magnitude: 0.51900
Value Function Update Magnitude: 0.62755

Collected Steps per Second: 20,744.92812
Overall Steps per Second: 10,246.50772

Timestep Collection Time: 2.41148
Timestep Consumption Time: 2.47077
PPO Batch Consumption Time: 0.29497
Total Iteration Time: 4.88225

Cumulative Model Updates: 104,998
Cumulative Timesteps: 875,543,240

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 875543240...
Checkpoint 875543240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,104.79647
Policy Entropy: 3.73228
Value Function Loss: 0.03112

Mean KL Divergence: 0.01227
SB3 Clip Fraction: 0.16610
Policy Update Magnitude: 0.50192
Value Function Update Magnitude: 0.78592

Collected Steps per Second: 20,958.48841
Overall Steps per Second: 10,384.46930

Timestep Collection Time: 2.38662
Timestep Consumption Time: 2.43019
PPO Batch Consumption Time: 0.28905
Total Iteration Time: 4.81681

Cumulative Model Updates: 105,004
Cumulative Timesteps: 875,593,260

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83,840.84154
Policy Entropy: 3.71746
Value Function Loss: 0.04106

Mean KL Divergence: 0.01235
SB3 Clip Fraction: 0.15937
Policy Update Magnitude: 0.52849
Value Function Update Magnitude: 0.67389

Collected Steps per Second: 20,545.63826
Overall Steps per Second: 10,148.88137

Timestep Collection Time: 2.43458
Timestep Consumption Time: 2.49404
PPO Batch Consumption Time: 0.30316
Total Iteration Time: 4.92862

Cumulative Model Updates: 105,010
Cumulative Timesteps: 875,643,280

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 875643280...
Checkpoint 875643280 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,547.11336
Policy Entropy: 3.72774
Value Function Loss: 0.04542

Mean KL Divergence: 0.01150
SB3 Clip Fraction: 0.15229
Policy Update Magnitude: 0.56946
Value Function Update Magnitude: 0.54045

Collected Steps per Second: 20,446.42395
Overall Steps per Second: 10,134.22415

Timestep Collection Time: 2.44542
Timestep Consumption Time: 2.48836
PPO Batch Consumption Time: 0.28800
Total Iteration Time: 4.93378

Cumulative Model Updates: 105,016
Cumulative Timesteps: 875,693,280

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55,828.36734
Policy Entropy: 3.71680
Value Function Loss: 0.03521

Mean KL Divergence: 0.00662
SB3 Clip Fraction: 0.08222
Policy Update Magnitude: 0.68354
Value Function Update Magnitude: 0.57665

Collected Steps per Second: 21,236.45892
Overall Steps per Second: 10,195.73005

Timestep Collection Time: 2.35567
Timestep Consumption Time: 2.55090
PPO Batch Consumption Time: 0.29815
Total Iteration Time: 4.90656

Cumulative Model Updates: 105,022
Cumulative Timesteps: 875,743,306

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 875743306...
Checkpoint 875743306 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55,828.36734
Policy Entropy: 3.71849
Value Function Loss: 0.02937

Mean KL Divergence: 0.00549
SB3 Clip Fraction: 0.06467
Policy Update Magnitude: 0.71256
Value Function Update Magnitude: 0.52099

Collected Steps per Second: 21,461.31164
Overall Steps per Second: 10,237.14225

Timestep Collection Time: 2.33108
Timestep Consumption Time: 2.55583
PPO Batch Consumption Time: 0.29626
Total Iteration Time: 4.88691

Cumulative Model Updates: 105,028
Cumulative Timesteps: 875,793,334

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55,828.36734
Policy Entropy: 3.71150
Value Function Loss: 0.02052

Mean KL Divergence: 0.00642
SB3 Clip Fraction: 0.07767
Policy Update Magnitude: 0.66621
Value Function Update Magnitude: 0.36987

Collected Steps per Second: 21,611.55664
Overall Steps per Second: 10,282.87908

Timestep Collection Time: 2.31469
Timestep Consumption Time: 2.55010
PPO Batch Consumption Time: 0.29264
Total Iteration Time: 4.86479

Cumulative Model Updates: 105,034
Cumulative Timesteps: 875,843,358

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 875843358...
Checkpoint 875843358 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55,828.36734
Policy Entropy: 3.70756
Value Function Loss: 0.02250

Mean KL Divergence: 0.00613
SB3 Clip Fraction: 0.07487
Policy Update Magnitude: 0.59897
Value Function Update Magnitude: 0.25885

Collected Steps per Second: 21,320.28354
Overall Steps per Second: 10,215.94816

Timestep Collection Time: 2.34556
Timestep Consumption Time: 2.54953
PPO Batch Consumption Time: 0.29376
Total Iteration Time: 4.89509

Cumulative Model Updates: 105,040
Cumulative Timesteps: 875,893,366

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55,828.36734
Policy Entropy: 3.71800
Value Function Loss: 0.01999

Mean KL Divergence: 0.00590
SB3 Clip Fraction: 0.07195
Policy Update Magnitude: 0.58186
Value Function Update Magnitude: 0.24455

Collected Steps per Second: 21,606.93721
Overall Steps per Second: 10,340.76658

Timestep Collection Time: 2.31435
Timestep Consumption Time: 2.52146
PPO Batch Consumption Time: 0.28832
Total Iteration Time: 4.83581

Cumulative Model Updates: 105,046
Cumulative Timesteps: 875,943,372

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 875943372...
Checkpoint 875943372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55,828.36734
Policy Entropy: 3.71947
Value Function Loss: 0.01865

Mean KL Divergence: 0.00579
SB3 Clip Fraction: 0.07071
Policy Update Magnitude: 0.56414
Value Function Update Magnitude: 0.33946

Collected Steps per Second: 21,182.82923
Overall Steps per Second: 10,245.19837

Timestep Collection Time: 2.36125
Timestep Consumption Time: 2.52084
PPO Batch Consumption Time: 0.28786
Total Iteration Time: 4.88209

Cumulative Model Updates: 105,052
Cumulative Timesteps: 875,993,390

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56,363.72063
Policy Entropy: 3.71435
Value Function Loss: 0.01987

Mean KL Divergence: 0.00613
SB3 Clip Fraction: 0.07651
Policy Update Magnitude: 0.59893
Value Function Update Magnitude: 0.39253

Collected Steps per Second: 21,361.52659
Overall Steps per Second: 10,188.24630

Timestep Collection Time: 2.34178
Timestep Consumption Time: 2.56819
PPO Batch Consumption Time: 0.30013
Total Iteration Time: 4.90997

Cumulative Model Updates: 105,058
Cumulative Timesteps: 876,043,414

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 876043414...
Checkpoint 876043414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 56,363.72063
Policy Entropy: 3.70832
Value Function Loss: 0.01947

Mean KL Divergence: 0.00613
SB3 Clip Fraction: 0.07464
Policy Update Magnitude: 0.59847
Value Function Update Magnitude: 0.47057

Collected Steps per Second: 20,699.16747
Overall Steps per Second: 10,216.91770

Timestep Collection Time: 2.41778
Timestep Consumption Time: 2.48057
PPO Batch Consumption Time: 0.30048
Total Iteration Time: 4.89835

Cumulative Model Updates: 105,064
Cumulative Timesteps: 876,093,460

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 347,390.19114
Policy Entropy: 3.72054
Value Function Loss: 0.02322

Mean KL Divergence: 0.02089
SB3 Clip Fraction: 0.24239
Policy Update Magnitude: 0.53426
Value Function Update Magnitude: 0.41410

Collected Steps per Second: 21,049.32807
Overall Steps per Second: 10,348.12819

Timestep Collection Time: 2.37642
Timestep Consumption Time: 2.45750
PPO Batch Consumption Time: 0.29106
Total Iteration Time: 4.83392

Cumulative Model Updates: 105,070
Cumulative Timesteps: 876,143,482

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 876143482...
Checkpoint 876143482 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 291,140.09305
Policy Entropy: 3.69786
Value Function Loss: 0.03642

Mean KL Divergence: 0.02627
SB3 Clip Fraction: 0.27767
Policy Update Magnitude: 0.44001
Value Function Update Magnitude: 0.49308

Collected Steps per Second: 20,515.45722
Overall Steps per Second: 10,196.95596

Timestep Collection Time: 2.43972
Timestep Consumption Time: 2.46880
PPO Batch Consumption Time: 0.29210
Total Iteration Time: 4.90852

Cumulative Model Updates: 105,076
Cumulative Timesteps: 876,193,534

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 101,516.91834
Policy Entropy: 3.70918
Value Function Loss: 0.04301

Mean KL Divergence: 0.01665
SB3 Clip Fraction: 0.19456
Policy Update Magnitude: 0.60551
Value Function Update Magnitude: 0.48465

Collected Steps per Second: 20,712.36578
Overall Steps per Second: 9,989.21529

Timestep Collection Time: 2.41537
Timestep Consumption Time: 2.59283
PPO Batch Consumption Time: 0.30346
Total Iteration Time: 5.00820

Cumulative Model Updates: 105,082
Cumulative Timesteps: 876,243,562

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 876243562...
Checkpoint 876243562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 101,516.91834
Policy Entropy: 3.69374
Value Function Loss: 0.04446

Mean KL Divergence: 0.01459
SB3 Clip Fraction: 0.17390
Policy Update Magnitude: 0.58940
Value Function Update Magnitude: 0.45729

Collected Steps per Second: 21,328.31908
Overall Steps per Second: 10,155.43040

Timestep Collection Time: 2.34468
Timestep Consumption Time: 2.57959
PPO Batch Consumption Time: 0.30446
Total Iteration Time: 4.92426

Cumulative Model Updates: 105,088
Cumulative Timesteps: 876,293,570

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 101,516.91834
Policy Entropy: 3.72589
Value Function Loss: 0.03955

Mean KL Divergence: 0.01305
SB3 Clip Fraction: 0.15780
Policy Update Magnitude: 0.60128
Value Function Update Magnitude: 0.41122

Collected Steps per Second: 21,639.10510
Overall Steps per Second: 10,270.79720

Timestep Collection Time: 2.31137
Timestep Consumption Time: 2.55836
PPO Batch Consumption Time: 0.29937
Total Iteration Time: 4.86973

Cumulative Model Updates: 105,094
Cumulative Timesteps: 876,343,586

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 876343586...
Checkpoint 876343586 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 101,516.91834
Policy Entropy: 3.72421
Value Function Loss: 0.03167

Mean KL Divergence: 0.01059
SB3 Clip Fraction: 0.13205
Policy Update Magnitude: 0.60907
Value Function Update Magnitude: 0.31201

Collected Steps per Second: 21,596.61997
Overall Steps per Second: 10,258.78377

Timestep Collection Time: 2.31518
Timestep Consumption Time: 2.55869
PPO Batch Consumption Time: 0.29703
Total Iteration Time: 4.87387

Cumulative Model Updates: 105,100
Cumulative Timesteps: 876,393,586

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 101,516.91834
Policy Entropy: 3.74512
Value Function Loss: 0.02101

Mean KL Divergence: 0.01152
SB3 Clip Fraction: 0.15468
Policy Update Magnitude: 0.48153
Value Function Update Magnitude: 0.21903

Collected Steps per Second: 21,888.94035
Overall Steps per Second: 10,301.50536

Timestep Collection Time: 2.28453
Timestep Consumption Time: 2.56971
PPO Batch Consumption Time: 0.29738
Total Iteration Time: 4.85424

Cumulative Model Updates: 105,106
Cumulative Timesteps: 876,443,592

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 876443592...
Checkpoint 876443592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 101,516.91834
Policy Entropy: 3.73814
Value Function Loss: 0.01961

Mean KL Divergence: 0.01246
SB3 Clip Fraction: 0.16871
Policy Update Magnitude: 0.37026
Value Function Update Magnitude: 0.18243

Collected Steps per Second: 20,879.67244
Overall Steps per Second: 10,240.43782

Timestep Collection Time: 2.39601
Timestep Consumption Time: 2.48932
PPO Batch Consumption Time: 0.28623
Total Iteration Time: 4.88534

Cumulative Model Updates: 105,112
Cumulative Timesteps: 876,493,620

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 101,516.91834
Policy Entropy: 3.69064
Value Function Loss: 0.02598

Mean KL Divergence: 0.01476
SB3 Clip Fraction: 0.18725
Policy Update Magnitude: 0.43015
Value Function Update Magnitude: 0.32007

Collected Steps per Second: 21,660.38034
Overall Steps per Second: 10,340.59791

Timestep Collection Time: 2.30956
Timestep Consumption Time: 2.52826
PPO Batch Consumption Time: 0.28882
Total Iteration Time: 4.83782

Cumulative Model Updates: 105,118
Cumulative Timesteps: 876,543,646

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 876543646...
Checkpoint 876543646 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 346,770.57460
Policy Entropy: 3.67478
Value Function Loss: 0.02811

Mean KL Divergence: 0.01803
SB3 Clip Fraction: 0.22129
Policy Update Magnitude: 0.57036
Value Function Update Magnitude: 0.59110

Collected Steps per Second: 21,320.61687
Overall Steps per Second: 10,281.99552

Timestep Collection Time: 2.34665
Timestep Consumption Time: 2.51933
PPO Batch Consumption Time: 0.28765
Total Iteration Time: 4.86598

Cumulative Model Updates: 105,124
Cumulative Timesteps: 876,593,678

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 523,757.05339
Policy Entropy: 3.68029
Value Function Loss: 0.03854

Mean KL Divergence: 0.01959
SB3 Clip Fraction: 0.23663
Policy Update Magnitude: 0.58645
Value Function Update Magnitude: 0.56618

Collected Steps per Second: 21,949.94580
Overall Steps per Second: 10,407.45440

Timestep Collection Time: 2.27873
Timestep Consumption Time: 2.52725
PPO Batch Consumption Time: 0.28844
Total Iteration Time: 4.80598

Cumulative Model Updates: 105,130
Cumulative Timesteps: 876,643,696

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 876643696...
Checkpoint 876643696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,563.07129
Policy Entropy: 3.73197
Value Function Loss: 0.03313

Mean KL Divergence: 0.01115
SB3 Clip Fraction: 0.14700
Policy Update Magnitude: 0.69625
Value Function Update Magnitude: 0.58997

Collected Steps per Second: 21,333.03633
Overall Steps per Second: 10,275.69486

Timestep Collection Time: 2.34519
Timestep Consumption Time: 2.52358
PPO Batch Consumption Time: 0.29089
Total Iteration Time: 4.86877

Cumulative Model Updates: 105,136
Cumulative Timesteps: 876,693,726

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 104,368.96941
Policy Entropy: 3.75013
Value Function Loss: 0.03062

Mean KL Divergence: 0.00718
SB3 Clip Fraction: 0.09116
Policy Update Magnitude: 0.83894
Value Function Update Magnitude: 0.82247

Collected Steps per Second: 21,893.85380
Overall Steps per Second: 10,383.46205

Timestep Collection Time: 2.28493
Timestep Consumption Time: 2.53292
PPO Batch Consumption Time: 0.28906
Total Iteration Time: 4.81785

Cumulative Model Updates: 105,142
Cumulative Timesteps: 876,743,752

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 876743752...
Checkpoint 876743752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,972.50795
Policy Entropy: 3.74830
Value Function Loss: 0.02891

Mean KL Divergence: 0.00710
SB3 Clip Fraction: 0.08887
Policy Update Magnitude: 0.82525
Value Function Update Magnitude: 0.83040

Collected Steps per Second: 21,196.01357
Overall Steps per Second: 10,244.02662

Timestep Collection Time: 2.36101
Timestep Consumption Time: 2.52418
PPO Batch Consumption Time: 0.28797
Total Iteration Time: 4.88519

Cumulative Model Updates: 105,148
Cumulative Timesteps: 876,793,796

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,415.41372
Policy Entropy: 3.73915
Value Function Loss: 0.02842

Mean KL Divergence: 0.00695
SB3 Clip Fraction: 0.08535
Policy Update Magnitude: 0.79881
Value Function Update Magnitude: 0.74833

Collected Steps per Second: 21,375.08456
Overall Steps per Second: 10,199.94445

Timestep Collection Time: 2.33955
Timestep Consumption Time: 2.56323
PPO Batch Consumption Time: 0.29785
Total Iteration Time: 4.90277

Cumulative Model Updates: 105,154
Cumulative Timesteps: 876,843,804

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 876843804...
Checkpoint 876843804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,058.25802
Policy Entropy: 3.74376
Value Function Loss: 0.02611

Mean KL Divergence: 0.00612
SB3 Clip Fraction: 0.07343
Policy Update Magnitude: 0.79359
Value Function Update Magnitude: 0.70362

Collected Steps per Second: 21,521.08376
Overall Steps per Second: 10,251.17259

Timestep Collection Time: 2.32367
Timestep Consumption Time: 2.55460
PPO Batch Consumption Time: 0.29604
Total Iteration Time: 4.87827

Cumulative Model Updates: 105,160
Cumulative Timesteps: 876,893,812

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,093.42120
Policy Entropy: 3.74325
Value Function Loss: 0.02382

Mean KL Divergence: 0.00626
SB3 Clip Fraction: 0.07607
Policy Update Magnitude: 0.73642
Value Function Update Magnitude: 0.61658

Collected Steps per Second: 21,779.84993
Overall Steps per Second: 10,253.72264

Timestep Collection Time: 2.29625
Timestep Consumption Time: 2.58120
PPO Batch Consumption Time: 0.29974
Total Iteration Time: 4.87745

Cumulative Model Updates: 105,166
Cumulative Timesteps: 876,943,824

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 876943824...
Checkpoint 876943824 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43,306.96171
Policy Entropy: 3.73996
Value Function Loss: 0.02249

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.11831
Policy Update Magnitude: 0.63857
Value Function Update Magnitude: 0.61234

Collected Steps per Second: 21,375.88193
Overall Steps per Second: 10,196.10223

Timestep Collection Time: 2.34030
Timestep Consumption Time: 2.56608
PPO Batch Consumption Time: 0.29655
Total Iteration Time: 4.90638

Cumulative Model Updates: 105,172
Cumulative Timesteps: 876,993,850

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,412.52747
Policy Entropy: 3.73248
Value Function Loss: 0.02355

Mean KL Divergence: 0.01196
SB3 Clip Fraction: 0.16552
Policy Update Magnitude: 0.53093
Value Function Update Magnitude: 0.60870

Collected Steps per Second: 21,551.66008
Overall Steps per Second: 10,384.29810

Timestep Collection Time: 2.32158
Timestep Consumption Time: 2.49665
PPO Batch Consumption Time: 0.28747
Total Iteration Time: 4.81824

Cumulative Model Updates: 105,178
Cumulative Timesteps: 877,043,884

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 877043884...
Checkpoint 877043884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,403.38895
Policy Entropy: 3.75013
Value Function Loss: 0.02282

Mean KL Divergence: 0.01323
SB3 Clip Fraction: 0.17682
Policy Update Magnitude: 0.49353
Value Function Update Magnitude: 0.65090

Collected Steps per Second: 20,601.34240
Overall Steps per Second: 10,332.46763

Timestep Collection Time: 2.42809
Timestep Consumption Time: 2.41315
PPO Batch Consumption Time: 0.28696
Total Iteration Time: 4.84124

Cumulative Model Updates: 105,184
Cumulative Timesteps: 877,093,906

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95,025.70171
Policy Entropy: 3.74285
Value Function Loss: 0.02772

Mean KL Divergence: 0.01322
SB3 Clip Fraction: 0.17646
Policy Update Magnitude: 0.45297
Value Function Update Magnitude: 0.66368

Collected Steps per Second: 20,737.26871
Overall Steps per Second: 10,321.80206

Timestep Collection Time: 2.41131
Timestep Consumption Time: 2.43319
PPO Batch Consumption Time: 0.28900
Total Iteration Time: 4.84450

Cumulative Model Updates: 105,190
Cumulative Timesteps: 877,143,910

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 877143910...
Checkpoint 877143910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,386.04636
Policy Entropy: 3.72215
Value Function Loss: 0.02869

Mean KL Divergence: 0.01355
SB3 Clip Fraction: 0.17821
Policy Update Magnitude: 0.44821
Value Function Update Magnitude: 0.66845

Collected Steps per Second: 20,639.11176
Overall Steps per Second: 10,286.37457

Timestep Collection Time: 2.42326
Timestep Consumption Time: 2.43890
PPO Batch Consumption Time: 0.28872
Total Iteration Time: 4.86216

Cumulative Model Updates: 105,196
Cumulative Timesteps: 877,193,924

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,844.16109
Policy Entropy: 3.71457
Value Function Loss: 0.03079

Mean KL Divergence: 0.01222
SB3 Clip Fraction: 0.15908
Policy Update Magnitude: 0.50858
Value Function Update Magnitude: 0.66690

Collected Steps per Second: 20,626.31413
Overall Steps per Second: 10,160.14398

Timestep Collection Time: 2.42428
Timestep Consumption Time: 2.49730
PPO Batch Consumption Time: 0.30037
Total Iteration Time: 4.92158

Cumulative Model Updates: 105,202
Cumulative Timesteps: 877,243,928

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 877243928...
Checkpoint 877243928 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 69,813.95762
Policy Entropy: 3.72376
Value Function Loss: 0.03044

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.14336
Policy Update Magnitude: 0.53879
Value Function Update Magnitude: 0.67405

Collected Steps per Second: 20,388.08678
Overall Steps per Second: 10,072.05266

Timestep Collection Time: 2.45398
Timestep Consumption Time: 2.51343
PPO Batch Consumption Time: 0.28893
Total Iteration Time: 4.96741

Cumulative Model Updates: 105,208
Cumulative Timesteps: 877,293,960

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 69,813.95762
Policy Entropy: 3.71028
Value Function Loss: 0.02999

Mean KL Divergence: 0.01096
SB3 Clip Fraction: 0.15066
Policy Update Magnitude: 0.52474
Value Function Update Magnitude: 0.66545

Collected Steps per Second: 21,606.87814
Overall Steps per Second: 10,400.72083

Timestep Collection Time: 2.31417
Timestep Consumption Time: 2.49338
PPO Batch Consumption Time: 0.28875
Total Iteration Time: 4.80755

Cumulative Model Updates: 105,214
Cumulative Timesteps: 877,343,962

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 877343962...
Checkpoint 877343962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,694.97626
Policy Entropy: 3.72320
Value Function Loss: 0.03177

Mean KL Divergence: 0.01085
SB3 Clip Fraction: 0.14945
Policy Update Magnitude: 0.52724
Value Function Update Magnitude: 0.58046

Collected Steps per Second: 21,587.99163
Overall Steps per Second: 10,305.27598

Timestep Collection Time: 2.31666
Timestep Consumption Time: 2.53639
PPO Batch Consumption Time: 0.29685
Total Iteration Time: 4.85305

Cumulative Model Updates: 105,220
Cumulative Timesteps: 877,393,974

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,399.15573
Policy Entropy: 3.72173
Value Function Loss: 0.02966

Mean KL Divergence: 0.01112
SB3 Clip Fraction: 0.15227
Policy Update Magnitude: 0.52668
Value Function Update Magnitude: 0.50755

Collected Steps per Second: 21,375.66155
Overall Steps per Second: 10,165.62085

Timestep Collection Time: 2.34014
Timestep Consumption Time: 2.58056
PPO Batch Consumption Time: 0.30075
Total Iteration Time: 4.92070

Cumulative Model Updates: 105,226
Cumulative Timesteps: 877,443,996

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 877443996...
Checkpoint 877443996 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,399.15573
Policy Entropy: 3.72272
Value Function Loss: 0.02995

Mean KL Divergence: 0.01110
SB3 Clip Fraction: 0.15548
Policy Update Magnitude: 0.54073
Value Function Update Magnitude: 0.55555

Collected Steps per Second: 21,717.83167
Overall Steps per Second: 10,398.06472

Timestep Collection Time: 2.30244
Timestep Consumption Time: 2.50653
PPO Batch Consumption Time: 0.28772
Total Iteration Time: 4.80897

Cumulative Model Updates: 105,232
Cumulative Timesteps: 877,494,000

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66,235.54020
Policy Entropy: 3.69944
Value Function Loss: 0.02735

Mean KL Divergence: 0.01076
SB3 Clip Fraction: 0.15319
Policy Update Magnitude: 0.51710
Value Function Update Magnitude: 0.49544

Collected Steps per Second: 21,985.27547
Overall Steps per Second: 10,437.33863

Timestep Collection Time: 2.27552
Timestep Consumption Time: 2.51765
PPO Batch Consumption Time: 0.28918
Total Iteration Time: 4.79318

Cumulative Model Updates: 105,238
Cumulative Timesteps: 877,544,028

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 877544028...
Checkpoint 877544028 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 352,459.07501
Policy Entropy: 3.70006
Value Function Loss: 0.02686

Mean KL Divergence: 0.01082
SB3 Clip Fraction: 0.15634
Policy Update Magnitude: 0.47116
Value Function Update Magnitude: 0.46875

Collected Steps per Second: 21,436.89878
Overall Steps per Second: 10,342.00186

Timestep Collection Time: 2.33336
Timestep Consumption Time: 2.50323
PPO Batch Consumption Time: 0.28703
Total Iteration Time: 4.83659

Cumulative Model Updates: 105,244
Cumulative Timesteps: 877,594,048

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 122,902.19871
Policy Entropy: 3.70224
Value Function Loss: 0.02826

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.14953
Policy Update Magnitude: 0.43052
Value Function Update Magnitude: 0.57361

Collected Steps per Second: 21,704.70516
Overall Steps per Second: 10,383.65929

Timestep Collection Time: 2.30411
Timestep Consumption Time: 2.51211
PPO Batch Consumption Time: 0.28769
Total Iteration Time: 4.81622

Cumulative Model Updates: 105,250
Cumulative Timesteps: 877,644,058

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 877644058...
Checkpoint 877644058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,235.77954
Policy Entropy: 3.72814
Value Function Loss: 0.02969

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.14882
Policy Update Magnitude: 0.42420
Value Function Update Magnitude: 0.49642

Collected Steps per Second: 21,335.45991
Overall Steps per Second: 10,275.83373

Timestep Collection Time: 2.34492
Timestep Consumption Time: 2.52378
PPO Batch Consumption Time: 0.29079
Total Iteration Time: 4.86870

Cumulative Model Updates: 105,256
Cumulative Timesteps: 877,694,088

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,871.65938
Policy Entropy: 3.71867
Value Function Loss: 0.03063

Mean KL Divergence: 0.01047
SB3 Clip Fraction: 0.14811
Policy Update Magnitude: 0.45160
Value Function Update Magnitude: 0.48554

Collected Steps per Second: 21,432.40109
Overall Steps per Second: 10,191.38961

Timestep Collection Time: 2.33292
Timestep Consumption Time: 2.57319
PPO Batch Consumption Time: 0.30029
Total Iteration Time: 4.90610

Cumulative Model Updates: 105,262
Cumulative Timesteps: 877,744,088

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 877744088...
Checkpoint 877744088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,653.51399
Policy Entropy: 3.73381
Value Function Loss: 0.02625

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.14916
Policy Update Magnitude: 0.45466
Value Function Update Magnitude: 0.53048

Collected Steps per Second: 21,455.56012
Overall Steps per Second: 10,235.33957

Timestep Collection Time: 2.33180
Timestep Consumption Time: 2.55617
PPO Batch Consumption Time: 0.29599
Total Iteration Time: 4.88797

Cumulative Model Updates: 105,268
Cumulative Timesteps: 877,794,118

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 133,211.38675
Policy Entropy: 3.71350
Value Function Loss: 0.02914

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.14503
Policy Update Magnitude: 0.47884
Value Function Update Magnitude: 0.63031

Collected Steps per Second: 21,677.64449
Overall Steps per Second: 10,265.04934

Timestep Collection Time: 2.30809
Timestep Consumption Time: 2.56612
PPO Batch Consumption Time: 0.29817
Total Iteration Time: 4.87421

Cumulative Model Updates: 105,274
Cumulative Timesteps: 877,844,152

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 877844152...
Checkpoint 877844152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,766.70777
Policy Entropy: 3.71772
Value Function Loss: 0.02618

Mean KL Divergence: 0.01067
SB3 Clip Fraction: 0.14893
Policy Update Magnitude: 0.49480
Value Function Update Magnitude: 0.64637

Collected Steps per Second: 21,486.99843
Overall Steps per Second: 10,215.84298

Timestep Collection Time: 2.32736
Timestep Consumption Time: 2.56778
PPO Batch Consumption Time: 0.29595
Total Iteration Time: 4.89514

Cumulative Model Updates: 105,280
Cumulative Timesteps: 877,894,160

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,731.78978
Policy Entropy: 3.70036
Value Function Loss: 0.03074

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.14193
Policy Update Magnitude: 0.49501
Value Function Update Magnitude: 0.65740

Collected Steps per Second: 21,727.96127
Overall Steps per Second: 10,346.02214

Timestep Collection Time: 2.30137
Timestep Consumption Time: 2.53180
PPO Batch Consumption Time: 0.28915
Total Iteration Time: 4.83316

Cumulative Model Updates: 105,286
Cumulative Timesteps: 877,944,164

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 877944164...
Checkpoint 877944164 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,323.02918
Policy Entropy: 3.71845
Value Function Loss: 0.02637

Mean KL Divergence: 0.01080
SB3 Clip Fraction: 0.15033
Policy Update Magnitude: 0.50362
Value Function Update Magnitude: 0.69391

Collected Steps per Second: 20,720.42739
Overall Steps per Second: 10,077.07794

Timestep Collection Time: 2.41375
Timestep Consumption Time: 2.54939
PPO Batch Consumption Time: 0.29620
Total Iteration Time: 4.96315

Cumulative Model Updates: 105,292
Cumulative Timesteps: 877,994,178

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,323.02918
Policy Entropy: 3.69806
Value Function Loss: 0.02431

Mean KL Divergence: 0.01183
SB3 Clip Fraction: 0.15776
Policy Update Magnitude: 0.50040
Value Function Update Magnitude: 0.80304

Collected Steps per Second: 21,692.26277
Overall Steps per Second: 10,274.72292

Timestep Collection Time: 2.30589
Timestep Consumption Time: 2.56237
PPO Batch Consumption Time: 0.29775
Total Iteration Time: 4.86826

Cumulative Model Updates: 105,298
Cumulative Timesteps: 878,044,198

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 878044198...
Checkpoint 878044198 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,323.02918
Policy Entropy: 3.71812
Value Function Loss: 0.02035

Mean KL Divergence: 0.00678
SB3 Clip Fraction: 0.08482
Policy Update Magnitude: 0.54614
Value Function Update Magnitude: 0.61530

Collected Steps per Second: 21,733.03586
Overall Steps per Second: 10,297.99642

Timestep Collection Time: 2.30212
Timestep Consumption Time: 2.55630
PPO Batch Consumption Time: 0.29983
Total Iteration Time: 4.85842

Cumulative Model Updates: 105,304
Cumulative Timesteps: 878,094,230

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,323.02918
Policy Entropy: 3.70981
Value Function Loss: 0.01924

Mean KL Divergence: 0.00563
SB3 Clip Fraction: 0.06675
Policy Update Magnitude: 0.57073
Value Function Update Magnitude: 0.45163

Collected Steps per Second: 20,981.52476
Overall Steps per Second: 10,338.67961

Timestep Collection Time: 2.38381
Timestep Consumption Time: 2.45394
PPO Batch Consumption Time: 0.29074
Total Iteration Time: 4.83776

Cumulative Model Updates: 105,310
Cumulative Timesteps: 878,144,246

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 878144246...
Checkpoint 878144246 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,323.02918
Policy Entropy: 3.72980
Value Function Loss: 0.01565

Mean KL Divergence: 0.01167
SB3 Clip Fraction: 0.15882
Policy Update Magnitude: 0.45272
Value Function Update Magnitude: 0.32033

Collected Steps per Second: 20,863.15341
Overall Steps per Second: 10,235.48577

Timestep Collection Time: 2.39667
Timestep Consumption Time: 2.48850
PPO Batch Consumption Time: 0.29741
Total Iteration Time: 4.88516

Cumulative Model Updates: 105,316
Cumulative Timesteps: 878,194,248

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 103,012.90043
Policy Entropy: 3.73947
Value Function Loss: 0.01464

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.14196
Policy Update Magnitude: 0.34947
Value Function Update Magnitude: 0.33693

Collected Steps per Second: 20,875.39394
Overall Steps per Second: 10,358.51297

Timestep Collection Time: 2.39545
Timestep Consumption Time: 2.43208
PPO Batch Consumption Time: 0.28815
Total Iteration Time: 4.82753

Cumulative Model Updates: 105,322
Cumulative Timesteps: 878,244,254

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 878244254...
Checkpoint 878244254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 67,591.79321
Policy Entropy: 3.76025
Value Function Loss: 0.01356

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.14089
Policy Update Magnitude: 0.34998
Value Function Update Magnitude: 0.49974

Collected Steps per Second: 20,951.90160
Overall Steps per Second: 10,256.11836

Timestep Collection Time: 2.38737
Timestep Consumption Time: 2.48972
PPO Batch Consumption Time: 0.28770
Total Iteration Time: 4.87709

Cumulative Model Updates: 105,328
Cumulative Timesteps: 878,294,274

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67,591.79321
Policy Entropy: 3.71697
Value Function Loss: 0.01779

Mean KL Divergence: 0.02151
SB3 Clip Fraction: 0.24532
Policy Update Magnitude: 0.37747
Value Function Update Magnitude: 0.63942

Collected Steps per Second: 21,404.93901
Overall Steps per Second: 10,253.39175

Timestep Collection Time: 2.33647
Timestep Consumption Time: 2.54114
PPO Batch Consumption Time: 0.29733
Total Iteration Time: 4.87761

Cumulative Model Updates: 105,334
Cumulative Timesteps: 878,344,286

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 878344286...
Checkpoint 878344286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 692,191.24532
Policy Entropy: 3.65023
Value Function Loss: 0.05352

Mean KL Divergence: 0.02660
SB3 Clip Fraction: 0.25498
Policy Update Magnitude: 0.51504
Value Function Update Magnitude: 0.58811

Collected Steps per Second: 21,340.88571
Overall Steps per Second: 10,232.09499

Timestep Collection Time: 2.34423
Timestep Consumption Time: 2.54509
PPO Batch Consumption Time: 0.29687
Total Iteration Time: 4.88932

Cumulative Model Updates: 105,340
Cumulative Timesteps: 878,394,314

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76,029.96733
Policy Entropy: 3.63813
Value Function Loss: 0.06395

Mean KL Divergence: 0.01133
SB3 Clip Fraction: 0.13649
Policy Update Magnitude: 1.18296
Value Function Update Magnitude: 0.68214

Collected Steps per Second: 21,642.55709
Overall Steps per Second: 10,285.71414

Timestep Collection Time: 2.31156
Timestep Consumption Time: 2.55228
PPO Batch Consumption Time: 0.30146
Total Iteration Time: 4.86383

Cumulative Model Updates: 105,346
Cumulative Timesteps: 878,444,342

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 878444342...
Checkpoint 878444342 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,985.27037
Policy Entropy: 3.64615
Value Function Loss: 0.06871

Mean KL Divergence: 0.01488
SB3 Clip Fraction: 0.17600
Policy Update Magnitude: 1.35313
Value Function Update Magnitude: 0.67379

Collected Steps per Second: 21,604.43041
Overall Steps per Second: 10,218.55083

Timestep Collection Time: 2.31545
Timestep Consumption Time: 2.57996
PPO Batch Consumption Time: 0.30191
Total Iteration Time: 4.89541

Cumulative Model Updates: 105,352
Cumulative Timesteps: 878,494,366

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 136,928.98754
Policy Entropy: 3.66578
Value Function Loss: 0.06218

Mean KL Divergence: 0.01841
SB3 Clip Fraction: 0.22175
Policy Update Magnitude: 0.97147
Value Function Update Magnitude: 0.67281

Collected Steps per Second: 21,396.43334
Overall Steps per Second: 10,295.76577

Timestep Collection Time: 2.33815
Timestep Consumption Time: 2.52094
PPO Batch Consumption Time: 0.28875
Total Iteration Time: 4.85908

Cumulative Model Updates: 105,358
Cumulative Timesteps: 878,544,394

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 878544394...
Checkpoint 878544394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,170.71373
Policy Entropy: 3.70038
Value Function Loss: 0.05673

Mean KL Divergence: 0.01425
SB3 Clip Fraction: 0.17754
Policy Update Magnitude: 0.85080
Value Function Update Magnitude: 0.75274

Collected Steps per Second: 21,743.54208
Overall Steps per Second: 10,330.17299

Timestep Collection Time: 2.30073
Timestep Consumption Time: 2.54198
PPO Batch Consumption Time: 0.30048
Total Iteration Time: 4.84271

Cumulative Model Updates: 105,364
Cumulative Timesteps: 878,594,420

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84,229.94092
Policy Entropy: 3.67977
Value Function Loss: 0.06645

Mean KL Divergence: 0.01187
SB3 Clip Fraction: 0.14736
Policy Update Magnitude: 0.77709
Value Function Update Magnitude: 0.60423

Collected Steps per Second: 21,685.89431
Overall Steps per Second: 10,366.43820

Timestep Collection Time: 2.30740
Timestep Consumption Time: 2.51952
PPO Batch Consumption Time: 0.28849
Total Iteration Time: 4.82692

Cumulative Model Updates: 105,370
Cumulative Timesteps: 878,644,458

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 878644458...
Checkpoint 878644458 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,447.50701
Policy Entropy: 3.74807
Value Function Loss: 0.05017

Mean KL Divergence: 0.01500
SB3 Clip Fraction: 0.18193
Policy Update Magnitude: 0.72807
Value Function Update Magnitude: 0.56956

Collected Steps per Second: 21,624.79905
Overall Steps per Second: 10,308.62798

Timestep Collection Time: 2.31225
Timestep Consumption Time: 2.53825
PPO Batch Consumption Time: 0.29219
Total Iteration Time: 4.85050

Cumulative Model Updates: 105,376
Cumulative Timesteps: 878,694,460

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,974.13680
Policy Entropy: 3.72604
Value Function Loss: 0.04510

Mean KL Divergence: 0.01576
SB3 Clip Fraction: 0.18507
Policy Update Magnitude: 0.69303
Value Function Update Magnitude: 0.67928

Collected Steps per Second: 21,675.82988
Overall Steps per Second: 10,359.24241

Timestep Collection Time: 2.30718
Timestep Consumption Time: 2.52039
PPO Batch Consumption Time: 0.28897
Total Iteration Time: 4.82757

Cumulative Model Updates: 105,382
Cumulative Timesteps: 878,744,470

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 878744470...
Checkpoint 878744470 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 875,415.75686
Policy Entropy: 3.76185
Value Function Loss: 0.03791

Mean KL Divergence: 0.01618
SB3 Clip Fraction: 0.19404
Policy Update Magnitude: 0.72850
Value Function Update Magnitude: 0.59175

Collected Steps per Second: 21,427.59671
Overall Steps per Second: 10,260.54184

Timestep Collection Time: 2.33475
Timestep Consumption Time: 2.54102
PPO Batch Consumption Time: 0.29351
Total Iteration Time: 4.87577

Cumulative Model Updates: 105,388
Cumulative Timesteps: 878,794,498

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 256,534.75952
Policy Entropy: 3.73240
Value Function Loss: 0.03824

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.11829
Policy Update Magnitude: 0.78963
Value Function Update Magnitude: 0.66968

Collected Steps per Second: 21,231.82906
Overall Steps per Second: 10,175.48510

Timestep Collection Time: 2.35524
Timestep Consumption Time: 2.55912
PPO Batch Consumption Time: 0.29909
Total Iteration Time: 4.91436

Cumulative Model Updates: 105,394
Cumulative Timesteps: 878,844,504

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 878844504...
Checkpoint 878844504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 256,534.75952
Policy Entropy: 3.74750
Value Function Loss: 0.03354

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.13175
Policy Update Magnitude: 0.86679
Value Function Update Magnitude: 0.66835

Collected Steps per Second: 21,394.60071
Overall Steps per Second: 10,166.45771

Timestep Collection Time: 2.33825
Timestep Consumption Time: 2.58244
PPO Batch Consumption Time: 0.30094
Total Iteration Time: 4.92069

Cumulative Model Updates: 105,400
Cumulative Timesteps: 878,894,530

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 256,534.75952
Policy Entropy: 3.71453
Value Function Loss: 0.02591

Mean KL Divergence: 0.01258
SB3 Clip Fraction: 0.16125
Policy Update Magnitude: 0.76183
Value Function Update Magnitude: 0.64862

Collected Steps per Second: 21,220.76147
Overall Steps per Second: 10,286.00592

Timestep Collection Time: 2.35694
Timestep Consumption Time: 2.50559
PPO Batch Consumption Time: 0.28756
Total Iteration Time: 4.86253

Cumulative Model Updates: 105,406
Cumulative Timesteps: 878,944,546

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 878944546...
Checkpoint 878944546 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 144,080.15010
Policy Entropy: 3.68065
Value Function Loss: 0.02490

Mean KL Divergence: 0.01429
SB3 Clip Fraction: 0.19548
Policy Update Magnitude: 0.59377
Value Function Update Magnitude: 0.65177

Collected Steps per Second: 21,635.81168
Overall Steps per Second: 10,103.51181

Timestep Collection Time: 2.31163
Timestep Consumption Time: 2.63853
PPO Batch Consumption Time: 0.30698
Total Iteration Time: 4.95016

Cumulative Model Updates: 105,412
Cumulative Timesteps: 878,994,560

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47,478.02842
Policy Entropy: 3.67891
Value Function Loss: 0.02742

Mean KL Divergence: 0.01275
SB3 Clip Fraction: 0.17221
Policy Update Magnitude: 0.48140
Value Function Update Magnitude: 0.66514

Collected Steps per Second: 21,338.06205
Overall Steps per Second: 10,284.58901

Timestep Collection Time: 2.34482
Timestep Consumption Time: 2.52012
PPO Batch Consumption Time: 0.28658
Total Iteration Time: 4.86495

Cumulative Model Updates: 105,418
Cumulative Timesteps: 879,044,594

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 879044594...
Checkpoint 879044594 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,156.72846
Policy Entropy: 3.68324
Value Function Loss: 0.02858

Mean KL Divergence: 0.01292
SB3 Clip Fraction: 0.17039
Policy Update Magnitude: 0.51826
Value Function Update Magnitude: 0.66290

Collected Steps per Second: 21,796.92937
Overall Steps per Second: 10,321.38852

Timestep Collection Time: 2.29408
Timestep Consumption Time: 2.55061
PPO Batch Consumption Time: 0.29888
Total Iteration Time: 4.84470

Cumulative Model Updates: 105,424
Cumulative Timesteps: 879,094,598

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66,315.78569
Policy Entropy: 3.69039
Value Function Loss: 0.03281

Mean KL Divergence: 0.01122
SB3 Clip Fraction: 0.15496
Policy Update Magnitude: 0.47970
Value Function Update Magnitude: 0.64320

Collected Steps per Second: 21,344.79733
Overall Steps per Second: 10,258.32872

Timestep Collection Time: 2.34352
Timestep Consumption Time: 2.53271
PPO Batch Consumption Time: 0.28892
Total Iteration Time: 4.87623

Cumulative Model Updates: 105,430
Cumulative Timesteps: 879,144,620

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 879144620...
Checkpoint 879144620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,544.99846
Policy Entropy: 3.70353
Value Function Loss: 0.03125

Mean KL Divergence: 0.01111
SB3 Clip Fraction: 0.15458
Policy Update Magnitude: 0.47944
Value Function Update Magnitude: 0.66905

Collected Steps per Second: 21,441.14999
Overall Steps per Second: 10,268.79330

Timestep Collection Time: 2.33271
Timestep Consumption Time: 2.53797
PPO Batch Consumption Time: 0.29275
Total Iteration Time: 4.87068

Cumulative Model Updates: 105,436
Cumulative Timesteps: 879,194,636

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 142,576.04965
Policy Entropy: 3.69874
Value Function Loss: 0.03336

Mean KL Divergence: 0.01156
SB3 Clip Fraction: 0.15799
Policy Update Magnitude: 0.50912
Value Function Update Magnitude: 0.68752

Collected Steps per Second: 21,308.93445
Overall Steps per Second: 10,197.80996

Timestep Collection Time: 2.34822
Timestep Consumption Time: 2.55852
PPO Batch Consumption Time: 0.29688
Total Iteration Time: 4.90674

Cumulative Model Updates: 105,442
Cumulative Timesteps: 879,244,674

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 879244674...
Checkpoint 879244674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 121,579.14546
Policy Entropy: 3.71660
Value Function Loss: 0.02899

Mean KL Divergence: 0.01091
SB3 Clip Fraction: 0.15223
Policy Update Magnitude: 0.48467
Value Function Update Magnitude: 0.61164

Collected Steps per Second: 21,708.47014
Overall Steps per Second: 10,404.82364

Timestep Collection Time: 2.30435
Timestep Consumption Time: 2.50342
PPO Batch Consumption Time: 0.28847
Total Iteration Time: 4.80777

Cumulative Model Updates: 105,448
Cumulative Timesteps: 879,294,698

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 121,579.14546
Policy Entropy: 3.69763
Value Function Loss: 0.02845

Mean KL Divergence: 0.01129
SB3 Clip Fraction: 0.15807
Policy Update Magnitude: 0.45141
Value Function Update Magnitude: 0.68178

Collected Steps per Second: 21,268.39987
Overall Steps per Second: 10,151.13195

Timestep Collection Time: 2.35147
Timestep Consumption Time: 2.57527
PPO Batch Consumption Time: 0.30079
Total Iteration Time: 4.92674

Cumulative Model Updates: 105,454
Cumulative Timesteps: 879,344,710

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 879344710...
Checkpoint 879344710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 204,764.99606
Policy Entropy: 3.71192
Value Function Loss: 0.02778

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.14439
Policy Update Magnitude: 0.49012
Value Function Update Magnitude: 0.65282

Collected Steps per Second: 21,420.20665
Overall Steps per Second: 10,208.18592

Timestep Collection Time: 2.33462
Timestep Consumption Time: 2.56420
PPO Batch Consumption Time: 0.29981
Total Iteration Time: 4.89881

Cumulative Model Updates: 105,460
Cumulative Timesteps: 879,394,718

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 71,411.98867
Policy Entropy: 3.70629
Value Function Loss: 0.02792

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.14793
Policy Update Magnitude: 0.51010
Value Function Update Magnitude: 0.63251

Collected Steps per Second: 20,877.14722
Overall Steps per Second: 10,362.38188

Timestep Collection Time: 2.39707
Timestep Consumption Time: 2.43232
PPO Batch Consumption Time: 0.28821
Total Iteration Time: 4.82939

Cumulative Model Updates: 105,466
Cumulative Timesteps: 879,444,762

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 879444762...
Checkpoint 879444762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,184.68518
Policy Entropy: 3.71807
Value Function Loss: 0.02688

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.14137
Policy Update Magnitude: 0.48751
Value Function Update Magnitude: 0.65420

Collected Steps per Second: 20,782.74011
Overall Steps per Second: 10,243.97819

Timestep Collection Time: 2.40719
Timestep Consumption Time: 2.47646
PPO Batch Consumption Time: 0.29605
Total Iteration Time: 4.88365

Cumulative Model Updates: 105,472
Cumulative Timesteps: 879,494,790

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46,928.90537
Policy Entropy: 3.70670
Value Function Loss: 0.02607

Mean KL Divergence: 0.01061
SB3 Clip Fraction: 0.14808
Policy Update Magnitude: 0.49036
Value Function Update Magnitude: 0.72963

Collected Steps per Second: 20,581.91087
Overall Steps per Second: 10,184.84913

Timestep Collection Time: 2.42961
Timestep Consumption Time: 2.48023
PPO Batch Consumption Time: 0.29754
Total Iteration Time: 4.90984

Cumulative Model Updates: 105,478
Cumulative Timesteps: 879,544,796

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 879544796...
Checkpoint 879544796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46,928.90537
Policy Entropy: 3.71042
Value Function Loss: 0.02656

Mean KL Divergence: 0.01092
SB3 Clip Fraction: 0.14972
Policy Update Magnitude: 0.49400
Value Function Update Magnitude: 0.70444

Collected Steps per Second: 21,125.96315
Overall Steps per Second: 10,201.36312

Timestep Collection Time: 2.36770
Timestep Consumption Time: 2.53556
PPO Batch Consumption Time: 0.29766
Total Iteration Time: 4.90327

Cumulative Model Updates: 105,484
Cumulative Timesteps: 879,594,816

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46,928.90537
Policy Entropy: 3.70282
Value Function Loss: 0.02595

Mean KL Divergence: 0.01099
SB3 Clip Fraction: 0.15318
Policy Update Magnitude: 0.49973
Value Function Update Magnitude: 0.58227

Collected Steps per Second: 21,572.06557
Overall Steps per Second: 10,338.13183

Timestep Collection Time: 2.31818
Timestep Consumption Time: 2.51905
PPO Batch Consumption Time: 0.28996
Total Iteration Time: 4.83724

Cumulative Model Updates: 105,490
Cumulative Timesteps: 879,644,824

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 879644824...
Checkpoint 879644824 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 65,101.28388
Policy Entropy: 3.70491
Value Function Loss: 0.02460

Mean KL Divergence: 0.01107
SB3 Clip Fraction: 0.15465
Policy Update Magnitude: 0.49833
Value Function Update Magnitude: 0.56280

Collected Steps per Second: 21,502.49223
Overall Steps per Second: 10,238.64198

Timestep Collection Time: 2.32643
Timestep Consumption Time: 2.55938
PPO Batch Consumption Time: 0.29966
Total Iteration Time: 4.88580

Cumulative Model Updates: 105,496
Cumulative Timesteps: 879,694,848

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 110,921.80912
Policy Entropy: 3.69626
Value Function Loss: 0.02876

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.14875
Policy Update Magnitude: 0.45568
Value Function Update Magnitude: 0.60276

Collected Steps per Second: 21,548.88792
Overall Steps per Second: 10,325.29552

Timestep Collection Time: 2.32142
Timestep Consumption Time: 2.52338
PPO Batch Consumption Time: 0.28848
Total Iteration Time: 4.84480

Cumulative Model Updates: 105,502
Cumulative Timesteps: 879,744,872

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 879744872...
Checkpoint 879744872 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 56,934.78689
Policy Entropy: 3.71023
Value Function Loss: 0.02552

Mean KL Divergence: 0.01077
SB3 Clip Fraction: 0.15120
Policy Update Magnitude: 0.46834
Value Function Update Magnitude: 0.61680

Collected Steps per Second: 21,438.70388
Overall Steps per Second: 10,271.48491

Timestep Collection Time: 2.33260
Timestep Consumption Time: 2.53602
PPO Batch Consumption Time: 0.29245
Total Iteration Time: 4.86862

Cumulative Model Updates: 105,508
Cumulative Timesteps: 879,794,880

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 101,219.41596
Policy Entropy: 3.69424
Value Function Loss: 0.03293

Mean KL Divergence: 0.01093
SB3 Clip Fraction: 0.15136
Policy Update Magnitude: 0.47583
Value Function Update Magnitude: 0.60730

Collected Steps per Second: 21,155.90934
Overall Steps per Second: 10,174.31200

Timestep Collection Time: 2.36378
Timestep Consumption Time: 2.55134
PPO Batch Consumption Time: 0.29808
Total Iteration Time: 4.91512

Cumulative Model Updates: 105,514
Cumulative Timesteps: 879,844,888

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 879844888...
Checkpoint 879844888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 101,219.41596
Policy Entropy: 3.69832
Value Function Loss: 0.03153

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.14308
Policy Update Magnitude: 0.50504
Value Function Update Magnitude: 0.52565

Collected Steps per Second: 21,773.31085
Overall Steps per Second: 10,410.00696

Timestep Collection Time: 2.29657
Timestep Consumption Time: 2.50688
PPO Batch Consumption Time: 0.28809
Total Iteration Time: 4.80346

Cumulative Model Updates: 105,520
Cumulative Timesteps: 879,894,892

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 101,219.41596
Policy Entropy: 3.68224
Value Function Loss: 0.03308

Mean KL Divergence: 0.01146
SB3 Clip Fraction: 0.15639
Policy Update Magnitude: 0.50979
Value Function Update Magnitude: 0.45522

Collected Steps per Second: 21,579.80222
Overall Steps per Second: 10,285.01575

Timestep Collection Time: 2.31735
Timestep Consumption Time: 2.54487
PPO Batch Consumption Time: 0.29590
Total Iteration Time: 4.86222

Cumulative Model Updates: 105,526
Cumulative Timesteps: 879,944,900

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 879944900...
Checkpoint 879944900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 101,219.41596
Policy Entropy: 3.68409
Value Function Loss: 0.02663

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.14420
Policy Update Magnitude: 0.46989
Value Function Update Magnitude: 0.40580

Collected Steps per Second: 20,716.92876
Overall Steps per Second: 10,349.99541

Timestep Collection Time: 2.41580
Timestep Consumption Time: 2.41976
PPO Batch Consumption Time: 0.28854
Total Iteration Time: 4.83556

Cumulative Model Updates: 105,532
Cumulative Timesteps: 879,994,948

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 101,219.41596
Policy Entropy: 3.68352
Value Function Loss: 0.02419

Mean KL Divergence: 0.01055
SB3 Clip Fraction: 0.14875
Policy Update Magnitude: 0.45013
Value Function Update Magnitude: 0.34409

Collected Steps per Second: 21,095.07862
Overall Steps per Second: 10,344.63059

Timestep Collection Time: 2.37259
Timestep Consumption Time: 2.46567
PPO Batch Consumption Time: 0.29525
Total Iteration Time: 4.83826

Cumulative Model Updates: 105,538
Cumulative Timesteps: 880,044,998

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 880044998...
Checkpoint 880044998 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 101,219.41596
Policy Entropy: 3.68530
Value Function Loss: 0.02224

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.14745
Policy Update Magnitude: 0.43712
Value Function Update Magnitude: 0.30444

Collected Steps per Second: 20,963.00616
Overall Steps per Second: 10,158.59934

Timestep Collection Time: 2.38678
Timestep Consumption Time: 2.53851
PPO Batch Consumption Time: 0.29728
Total Iteration Time: 4.92529

Cumulative Model Updates: 105,544
Cumulative Timesteps: 880,095,032

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 101,219.41596
Policy Entropy: 3.69025
Value Function Loss: 0.02232

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.14771
Policy Update Magnitude: 0.42895
Value Function Update Magnitude: 0.33083

Collected Steps per Second: 21,377.99202
Overall Steps per Second: 10,308.47216

Timestep Collection Time: 2.33885
Timestep Consumption Time: 2.51153
PPO Batch Consumption Time: 0.29227
Total Iteration Time: 4.85038

Cumulative Model Updates: 105,550
Cumulative Timesteps: 880,145,032

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 880145032...
Checkpoint 880145032 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 101,219.41596
Policy Entropy: 3.69480
Value Function Loss: 0.02247

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.14590
Policy Update Magnitude: 0.43467
Value Function Update Magnitude: 0.42220

Collected Steps per Second: 21,362.09455
Overall Steps per Second: 10,179.16917

Timestep Collection Time: 2.34078
Timestep Consumption Time: 2.57160
PPO Batch Consumption Time: 0.29972
Total Iteration Time: 4.91239

Cumulative Model Updates: 105,556
Cumulative Timesteps: 880,195,036

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 101,219.41596
Policy Entropy: 3.68486
Value Function Loss: 0.02180

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.14770
Policy Update Magnitude: 0.46185
Value Function Update Magnitude: 0.58144

Collected Steps per Second: 21,571.83728
Overall Steps per Second: 10,373.20217

Timestep Collection Time: 2.31867
Timestep Consumption Time: 2.50318
PPO Batch Consumption Time: 0.28786
Total Iteration Time: 4.82185

Cumulative Model Updates: 105,562
Cumulative Timesteps: 880,245,054

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 880245054...
Checkpoint 880245054 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 101,219.41596
Policy Entropy: 3.68852
Value Function Loss: 0.02110

Mean KL Divergence: 0.01086
SB3 Clip Fraction: 0.15431
Policy Update Magnitude: 0.45380
Value Function Update Magnitude: 0.65047

Collected Steps per Second: 21,050.88418
Overall Steps per Second: 10,204.30711

Timestep Collection Time: 2.37586
Timestep Consumption Time: 2.52540
PPO Batch Consumption Time: 0.29296
Total Iteration Time: 4.90126

Cumulative Model Updates: 105,568
Cumulative Timesteps: 880,295,068

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 101,219.41596
Policy Entropy: 3.69244
Value Function Loss: 0.01828

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.15145
Policy Update Magnitude: 0.43571
Value Function Update Magnitude: 0.58510

Collected Steps per Second: 21,550.20805
Overall Steps per Second: 10,242.01296

Timestep Collection Time: 2.32137
Timestep Consumption Time: 2.56302
PPO Batch Consumption Time: 0.29898
Total Iteration Time: 4.88439

Cumulative Model Updates: 105,574
Cumulative Timesteps: 880,345,094

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 880345094...
Checkpoint 880345094 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 107,313.70510
Policy Entropy: 3.69817
Value Function Loss: 0.02048

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.14401
Policy Update Magnitude: 0.39534
Value Function Update Magnitude: 0.53131

Collected Steps per Second: 20,600.13320
Overall Steps per Second: 10,137.28456

Timestep Collection Time: 2.42843
Timestep Consumption Time: 2.50642
PPO Batch Consumption Time: 0.28635
Total Iteration Time: 4.93485

Cumulative Model Updates: 105,580
Cumulative Timesteps: 880,395,120

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 359,797.03813
Policy Entropy: 3.69994
Value Function Loss: 0.02263

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.14680
Policy Update Magnitude: 0.38581
Value Function Update Magnitude: 0.46665

Collected Steps per Second: 21,682.68958
Overall Steps per Second: 10,366.07564

Timestep Collection Time: 2.30719
Timestep Consumption Time: 2.51875
PPO Batch Consumption Time: 0.28784
Total Iteration Time: 4.82593

Cumulative Model Updates: 105,586
Cumulative Timesteps: 880,445,146

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 880445146...
Checkpoint 880445146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 359,797.03813
Policy Entropy: 3.69081
Value Function Loss: 0.02322

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.14352
Policy Update Magnitude: 0.40182
Value Function Update Magnitude: 0.42760

Collected Steps per Second: 21,331.37095
Overall Steps per Second: 10,290.51786

Timestep Collection Time: 2.34490
Timestep Consumption Time: 2.51588
PPO Batch Consumption Time: 0.29029
Total Iteration Time: 4.86079

Cumulative Model Updates: 105,592
Cumulative Timesteps: 880,495,166

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 341,484.31157
Policy Entropy: 3.67966
Value Function Loss: 0.02528

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.14616
Policy Update Magnitude: 0.39143
Value Function Update Magnitude: 0.39442

Collected Steps per Second: 21,227.78867
Overall Steps per Second: 10,177.61058

Timestep Collection Time: 2.35578
Timestep Consumption Time: 2.55775
PPO Batch Consumption Time: 0.29692
Total Iteration Time: 4.91353

Cumulative Model Updates: 105,598
Cumulative Timesteps: 880,545,174

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 880545174...
Checkpoint 880545174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 147,008.01972
Policy Entropy: 3.69687
Value Function Loss: 0.02387

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.14220
Policy Update Magnitude: 0.40220
Value Function Update Magnitude: 0.41493

Collected Steps per Second: 21,444.21972
Overall Steps per Second: 10,269.72638

Timestep Collection Time: 2.33284
Timestep Consumption Time: 2.53837
PPO Batch Consumption Time: 0.29544
Total Iteration Time: 4.87121

Cumulative Model Updates: 105,604
Cumulative Timesteps: 880,595,200

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,559.83716
Policy Entropy: 3.71129
Value Function Loss: 0.02502

Mean KL Divergence: 0.01059
SB3 Clip Fraction: 0.14734
Policy Update Magnitude: 0.41057
Value Function Update Magnitude: 0.43709

Collected Steps per Second: 21,747.97183
Overall Steps per Second: 10,245.44192

Timestep Collection Time: 2.30044
Timestep Consumption Time: 2.58270
PPO Batch Consumption Time: 0.29919
Total Iteration Time: 4.88315

Cumulative Model Updates: 105,610
Cumulative Timesteps: 880,645,230

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 880645230...
Checkpoint 880645230 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,136.64068
Policy Entropy: 3.72147
Value Function Loss: 0.02395

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.13558
Policy Update Magnitude: 0.41293
Value Function Update Magnitude: 0.52600

Collected Steps per Second: 21,203.35976
Overall Steps per Second: 10,221.67904

Timestep Collection Time: 2.35906
Timestep Consumption Time: 2.53446
PPO Batch Consumption Time: 0.29269
Total Iteration Time: 4.89352

Cumulative Model Updates: 105,616
Cumulative Timesteps: 880,695,250

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 96,212.77839
Policy Entropy: 3.72617
Value Function Loss: 0.02551

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.14155
Policy Update Magnitude: 0.49211
Value Function Update Magnitude: 0.57295

Collected Steps per Second: 21,634.93527
Overall Steps per Second: 10,375.87201

Timestep Collection Time: 2.31228
Timestep Consumption Time: 2.50910
PPO Batch Consumption Time: 0.28886
Total Iteration Time: 4.82138

Cumulative Model Updates: 105,622
Cumulative Timesteps: 880,745,276

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 880745276...
Checkpoint 880745276 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,134.20112
Policy Entropy: 3.71526
Value Function Loss: 0.03008

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.14561
Policy Update Magnitude: 0.54179
Value Function Update Magnitude: 0.67437

Collected Steps per Second: 20,723.60458
Overall Steps per Second: 10,255.39216

Timestep Collection Time: 2.41290
Timestep Consumption Time: 2.46297
PPO Batch Consumption Time: 0.29322
Total Iteration Time: 4.87587

Cumulative Model Updates: 105,628
Cumulative Timesteps: 880,795,280

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,888.61880
Policy Entropy: 3.72457
Value Function Loss: 0.02799

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.13949
Policy Update Magnitude: 0.53105
Value Function Update Magnitude: 0.65832

Collected Steps per Second: 21,142.99262
Overall Steps per Second: 10,413.37413

Timestep Collection Time: 2.36504
Timestep Consumption Time: 2.43686
PPO Batch Consumption Time: 0.28858
Total Iteration Time: 4.80190

Cumulative Model Updates: 105,634
Cumulative Timesteps: 880,845,284

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 880845284...
Checkpoint 880845284 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 70,349.21417
Policy Entropy: 3.70935
Value Function Loss: 0.02818

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.14528
Policy Update Magnitude: 0.57119
Value Function Update Magnitude: 0.75236

Collected Steps per Second: 20,487.48888
Overall Steps per Second: 10,273.00639

Timestep Collection Time: 2.44178
Timestep Consumption Time: 2.42787
PPO Batch Consumption Time: 0.28842
Total Iteration Time: 4.86966

Cumulative Model Updates: 105,640
Cumulative Timesteps: 880,895,310

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70,967.50100
Policy Entropy: 3.71073
Value Function Loss: 0.02818

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.14261
Policy Update Magnitude: 0.57297
Value Function Update Magnitude: 0.91921

Collected Steps per Second: 20,974.20444
Overall Steps per Second: 9,963.58614

Timestep Collection Time: 2.38398
Timestep Consumption Time: 2.63450
PPO Batch Consumption Time: 0.31463
Total Iteration Time: 5.01847

Cumulative Model Updates: 105,646
Cumulative Timesteps: 880,945,312

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 880945312...
Checkpoint 880945312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,732.77601
Policy Entropy: 3.70084
Value Function Loss: 0.02669

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.14495
Policy Update Magnitude: 0.52859
Value Function Update Magnitude: 0.88869

Collected Steps per Second: 21,227.25277
Overall Steps per Second: 10,291.36204

Timestep Collection Time: 2.35546
Timestep Consumption Time: 2.50298
PPO Batch Consumption Time: 0.29321
Total Iteration Time: 4.85844

Cumulative Model Updates: 105,652
Cumulative Timesteps: 880,995,312

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,732.77601
Policy Entropy: 3.68692
Value Function Loss: 0.02640

Mean KL Divergence: 0.01070
SB3 Clip Fraction: 0.14955
Policy Update Magnitude: 0.48256
Value Function Update Magnitude: 0.67078

Collected Steps per Second: 21,556.32903
Overall Steps per Second: 10,399.91996

Timestep Collection Time: 2.32043
Timestep Consumption Time: 2.48922
PPO Batch Consumption Time: 0.28851
Total Iteration Time: 4.80965

Cumulative Model Updates: 105,658
Cumulative Timesteps: 881,045,332

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 881045332...
Checkpoint 881045332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 478,597.88729
Policy Entropy: 3.69293
Value Function Loss: 0.02488

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.15004
Policy Update Magnitude: 0.48606
Value Function Update Magnitude: 0.51577

Collected Steps per Second: 21,357.41442
Overall Steps per Second: 10,266.84812

Timestep Collection Time: 2.34120
Timestep Consumption Time: 2.52904
PPO Batch Consumption Time: 0.29308
Total Iteration Time: 4.87024

Cumulative Model Updates: 105,664
Cumulative Timesteps: 881,095,334

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 478,597.88729
Policy Entropy: 3.69314
Value Function Loss: 0.02330

Mean KL Divergence: 0.01148
SB3 Clip Fraction: 0.15902
Policy Update Magnitude: 0.47057
Value Function Update Magnitude: 0.46972

Collected Steps per Second: 21,711.51295
Overall Steps per Second: 10,361.47241

Timestep Collection Time: 2.30375
Timestep Consumption Time: 2.52355
PPO Batch Consumption Time: 0.28837
Total Iteration Time: 4.82731

Cumulative Model Updates: 105,670
Cumulative Timesteps: 881,145,352

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 881145352...
Checkpoint 881145352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 478,597.88729
Policy Entropy: 3.69434
Value Function Loss: 0.02247

Mean KL Divergence: 0.01111
SB3 Clip Fraction: 0.15381
Policy Update Magnitude: 0.42868
Value Function Update Magnitude: 0.40876

Collected Steps per Second: 21,167.17780
Overall Steps per Second: 10,244.98993

Timestep Collection Time: 2.36338
Timestep Consumption Time: 2.51960
PPO Batch Consumption Time: 0.28730
Total Iteration Time: 4.88297

Cumulative Model Updates: 105,676
Cumulative Timesteps: 881,195,378

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 478,597.88729
Policy Entropy: 3.69211
Value Function Loss: 0.02100

Mean KL Divergence: 0.01105
SB3 Clip Fraction: 0.15063
Policy Update Magnitude: 0.42621
Value Function Update Magnitude: 0.38815

Collected Steps per Second: 21,598.01008
Overall Steps per Second: 10,376.80843

Timestep Collection Time: 2.31595
Timestep Consumption Time: 2.50441
PPO Batch Consumption Time: 0.28764
Total Iteration Time: 4.82036

Cumulative Model Updates: 105,682
Cumulative Timesteps: 881,245,398

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 881245398...
Checkpoint 881245398 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 478,597.88729
Policy Entropy: 3.71017
Value Function Loss: 0.02034

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.13901
Policy Update Magnitude: 0.41933
Value Function Update Magnitude: 0.42988

Collected Steps per Second: 21,296.03805
Overall Steps per Second: 10,275.47525

Timestep Collection Time: 2.34814
Timestep Consumption Time: 2.51840
PPO Batch Consumption Time: 0.28774
Total Iteration Time: 4.86654

Cumulative Model Updates: 105,688
Cumulative Timesteps: 881,295,404

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 478,597.88729
Policy Entropy: 3.71799
Value Function Loss: 0.01853

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.13906
Policy Update Magnitude: 0.40110
Value Function Update Magnitude: 0.42515

Collected Steps per Second: 21,684.34028
Overall Steps per Second: 10,385.55620

Timestep Collection Time: 2.30710
Timestep Consumption Time: 2.50997
PPO Batch Consumption Time: 0.28803
Total Iteration Time: 4.81707

Cumulative Model Updates: 105,694
Cumulative Timesteps: 881,345,432

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 881345432...
Checkpoint 881345432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 478,597.88729
Policy Entropy: 3.69640
Value Function Loss: 0.02058

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.14522
Policy Update Magnitude: 0.40847
Value Function Update Magnitude: 0.37790

Collected Steps per Second: 21,375.62513
Overall Steps per Second: 10,318.43440

Timestep Collection Time: 2.33958
Timestep Consumption Time: 2.50708
PPO Batch Consumption Time: 0.28687
Total Iteration Time: 4.84667

Cumulative Model Updates: 105,700
Cumulative Timesteps: 881,395,442

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 478,597.88729
Policy Entropy: 3.68675
Value Function Loss: 0.02216

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.14266
Policy Update Magnitude: 0.43024
Value Function Update Magnitude: 0.39044

Collected Steps per Second: 21,489.28801
Overall Steps per Second: 10,359.24542

Timestep Collection Time: 2.32721
Timestep Consumption Time: 2.50037
PPO Batch Consumption Time: 0.28763
Total Iteration Time: 4.82757

Cumulative Model Updates: 105,706
Cumulative Timesteps: 881,445,452

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 881445452...
Checkpoint 881445452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 478,597.88729
Policy Entropy: 3.67943
Value Function Loss: 0.02397

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.14700
Policy Update Magnitude: 0.45793
Value Function Update Magnitude: 0.43522

Collected Steps per Second: 21,494.12075
Overall Steps per Second: 10,304.68845

Timestep Collection Time: 2.32678
Timestep Consumption Time: 2.52655
PPO Batch Consumption Time: 0.29087
Total Iteration Time: 4.85332

Cumulative Model Updates: 105,712
Cumulative Timesteps: 881,495,464

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 478,597.88729
Policy Entropy: 3.68677
Value Function Loss: 0.02318

Mean KL Divergence: 0.01071
SB3 Clip Fraction: 0.15192
Policy Update Magnitude: 0.46570
Value Function Update Magnitude: 0.45199

Collected Steps per Second: 21,141.88147
Overall Steps per Second: 10,267.23813

Timestep Collection Time: 2.36507
Timestep Consumption Time: 2.50499
PPO Batch Consumption Time: 0.30028
Total Iteration Time: 4.87005

Cumulative Model Updates: 105,718
Cumulative Timesteps: 881,545,466

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 881545466...
Checkpoint 881545466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 408,748.99062
Policy Entropy: 3.68946
Value Function Loss: 0.02402

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.15163
Policy Update Magnitude: 0.45741
Value Function Update Magnitude: 0.48835

Collected Steps per Second: 20,979.67382
Overall Steps per Second: 10,243.64267

Timestep Collection Time: 2.38335
Timestep Consumption Time: 2.49792
PPO Batch Consumption Time: 0.29428
Total Iteration Time: 4.88127

Cumulative Model Updates: 105,724
Cumulative Timesteps: 881,595,468

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 128,078.84553
Policy Entropy: 3.70316
Value Function Loss: 0.02706

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.14354
Policy Update Magnitude: 0.49251
Value Function Update Magnitude: 0.53096

Collected Steps per Second: 21,193.85886
Overall Steps per Second: 10,176.66485

Timestep Collection Time: 2.36050
Timestep Consumption Time: 2.55546
PPO Batch Consumption Time: 0.30019
Total Iteration Time: 4.91595

Cumulative Model Updates: 105,730
Cumulative Timesteps: 881,645,496

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 881645496...
Checkpoint 881645496 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,735.89475
Policy Entropy: 3.71941
Value Function Loss: 0.02733

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.14436
Policy Update Magnitude: 0.54124
Value Function Update Magnitude: 0.55309

Collected Steps per Second: 21,266.98987
Overall Steps per Second: 10,223.78869

Timestep Collection Time: 2.35228
Timestep Consumption Time: 2.54081
PPO Batch Consumption Time: 0.29906
Total Iteration Time: 4.89310

Cumulative Model Updates: 105,736
Cumulative Timesteps: 881,695,522

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,652.38123
Policy Entropy: 3.73494
Value Function Loss: 0.02471

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.14402
Policy Update Magnitude: 0.51954
Value Function Update Magnitude: 0.61011

Collected Steps per Second: 21,428.74281
Overall Steps per Second: 10,375.99421

Timestep Collection Time: 2.33397
Timestep Consumption Time: 2.48620
PPO Batch Consumption Time: 0.28906
Total Iteration Time: 4.82016

Cumulative Model Updates: 105,742
Cumulative Timesteps: 881,745,536

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 881745536...
Checkpoint 881745536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,254.42462
Policy Entropy: 3.72429
Value Function Loss: 0.02375

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.14108
Policy Update Magnitude: 0.48648
Value Function Update Magnitude: 0.55535

Collected Steps per Second: 21,575.43759
Overall Steps per Second: 10,283.75407

Timestep Collection Time: 2.31745
Timestep Consumption Time: 2.54459
PPO Batch Consumption Time: 0.29401
Total Iteration Time: 4.86204

Cumulative Model Updates: 105,748
Cumulative Timesteps: 881,795,536

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,254.42462
Policy Entropy: 3.71639
Value Function Loss: 0.02259

Mean KL Divergence: 0.01092
SB3 Clip Fraction: 0.15285
Policy Update Magnitude: 0.44676
Value Function Update Magnitude: 0.54636

Collected Steps per Second: 21,696.82972
Overall Steps per Second: 10,371.31975

Timestep Collection Time: 2.30467
Timestep Consumption Time: 2.51670
PPO Batch Consumption Time: 0.28883
Total Iteration Time: 4.82137

Cumulative Model Updates: 105,754
Cumulative Timesteps: 881,845,540

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 881845540...
Checkpoint 881845540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,254.42462
Policy Entropy: 3.70381
Value Function Loss: 0.02151

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.14677
Policy Update Magnitude: 0.42197
Value Function Update Magnitude: 0.51643

Collected Steps per Second: 21,026.93591
Overall Steps per Second: 10,225.59179

Timestep Collection Time: 2.37828
Timestep Consumption Time: 2.51219
PPO Batch Consumption Time: 0.28867
Total Iteration Time: 4.89047

Cumulative Model Updates: 105,760
Cumulative Timesteps: 881,895,548

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,254.42462
Policy Entropy: 3.71793
Value Function Loss: 0.01944

Mean KL Divergence: 0.01081
SB3 Clip Fraction: 0.15179
Policy Update Magnitude: 0.39225
Value Function Update Magnitude: 0.41829

Collected Steps per Second: 21,568.10229
Overall Steps per Second: 10,265.10323

Timestep Collection Time: 2.31898
Timestep Consumption Time: 2.55345
PPO Batch Consumption Time: 0.29590
Total Iteration Time: 4.87243

Cumulative Model Updates: 105,766
Cumulative Timesteps: 881,945,564

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 881945564...
Checkpoint 881945564 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,254.42462
Policy Entropy: 3.72291
Value Function Loss: 0.01817

Mean KL Divergence: 0.01110
SB3 Clip Fraction: 0.15190
Policy Update Magnitude: 0.38278
Value Function Update Magnitude: 0.32601

Collected Steps per Second: 21,714.99111
Overall Steps per Second: 10,407.16553

Timestep Collection Time: 2.30339
Timestep Consumption Time: 2.50273
PPO Batch Consumption Time: 0.28777
Total Iteration Time: 4.80611

Cumulative Model Updates: 105,772
Cumulative Timesteps: 881,995,582

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,254.42462
Policy Entropy: 3.73416
Value Function Loss: 0.01712

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.13908
Policy Update Magnitude: 0.35438
Value Function Update Magnitude: 0.31896

Collected Steps per Second: 22,089.34105
Overall Steps per Second: 10,472.31203

Timestep Collection Time: 2.26516
Timestep Consumption Time: 2.51277
PPO Batch Consumption Time: 0.28803
Total Iteration Time: 4.77793

Cumulative Model Updates: 105,778
Cumulative Timesteps: 882,045,618

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 882045618...
Checkpoint 882045618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,254.42462
Policy Entropy: 3.71883
Value Function Loss: 0.01755

Mean KL Divergence: 0.01047
SB3 Clip Fraction: 0.14717
Policy Update Magnitude: 0.34040
Value Function Update Magnitude: 0.35663

Collected Steps per Second: 20,687.28702
Overall Steps per Second: 10,282.10046

Timestep Collection Time: 2.41743
Timestep Consumption Time: 2.44637
PPO Batch Consumption Time: 0.29276
Total Iteration Time: 4.86379

Cumulative Model Updates: 105,784
Cumulative Timesteps: 882,095,628

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,254.42462
Policy Entropy: 3.69209
Value Function Loss: 0.02297

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.14006
Policy Update Magnitude: 0.38686
Value Function Update Magnitude: 0.41649

Collected Steps per Second: 20,926.25439
Overall Steps per Second: 10,362.91229

Timestep Collection Time: 2.38944
Timestep Consumption Time: 2.43565
PPO Batch Consumption Time: 0.28823
Total Iteration Time: 4.82509

Cumulative Model Updates: 105,790
Cumulative Timesteps: 882,145,630

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 882145630...
Checkpoint 882145630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,254.42462
Policy Entropy: 3.67659
Value Function Loss: 0.02622

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.14692
Policy Update Magnitude: 0.47085
Value Function Update Magnitude: 0.40986

Collected Steps per Second: 20,728.24619
Overall Steps per Second: 10,045.16790

Timestep Collection Time: 2.41226
Timestep Consumption Time: 2.56545
PPO Batch Consumption Time: 0.29874
Total Iteration Time: 4.97772

Cumulative Model Updates: 105,796
Cumulative Timesteps: 882,195,632

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 349,516.19062
Policy Entropy: 3.68086
Value Function Loss: 0.03061

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.14286
Policy Update Magnitude: 0.50460
Value Function Update Magnitude: 0.38204

Collected Steps per Second: 21,230.64484
Overall Steps per Second: 10,302.66058

Timestep Collection Time: 2.35612
Timestep Consumption Time: 2.49913
PPO Batch Consumption Time: 0.28976
Total Iteration Time: 4.85525

Cumulative Model Updates: 105,802
Cumulative Timesteps: 882,245,654

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 882245654...
Checkpoint 882245654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 229,317.37683
Policy Entropy: 3.70440
Value Function Loss: 0.02694

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.14504
Policy Update Magnitude: 0.52264
Value Function Update Magnitude: 0.52380

Collected Steps per Second: 21,334.24079
Overall Steps per Second: 10,234.75001

Timestep Collection Time: 2.34384
Timestep Consumption Time: 2.54187
PPO Batch Consumption Time: 0.30088
Total Iteration Time: 4.88571

Cumulative Model Updates: 105,808
Cumulative Timesteps: 882,295,658

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 229,317.37683
Policy Entropy: 3.70724
Value Function Loss: 0.02636

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.13987
Policy Update Magnitude: 0.51306
Value Function Update Magnitude: 0.52511

Collected Steps per Second: 21,787.09982
Overall Steps per Second: 10,428.63722

Timestep Collection Time: 2.29539
Timestep Consumption Time: 2.50005
PPO Batch Consumption Time: 0.28633
Total Iteration Time: 4.79545

Cumulative Model Updates: 105,814
Cumulative Timesteps: 882,345,668

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 882345668...
Checkpoint 882345668 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 319,100.19879
Policy Entropy: 3.71111
Value Function Loss: 0.02105

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.14200
Policy Update Magnitude: 0.46659
Value Function Update Magnitude: 0.49621

Collected Steps per Second: 21,798.32711
Overall Steps per Second: 10,297.08227

Timestep Collection Time: 2.29394
Timestep Consumption Time: 2.56220
PPO Batch Consumption Time: 0.29821
Total Iteration Time: 4.85613

Cumulative Model Updates: 105,820
Cumulative Timesteps: 882,395,672

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 319,100.19879
Policy Entropy: 3.70464
Value Function Loss: 0.02195

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.14243
Policy Update Magnitude: 0.43628
Value Function Update Magnitude: 0.53027

Collected Steps per Second: 21,415.42494
Overall Steps per Second: 10,316.15729

Timestep Collection Time: 2.33495
Timestep Consumption Time: 2.51220
PPO Batch Consumption Time: 0.28743
Total Iteration Time: 4.84715

Cumulative Model Updates: 105,826
Cumulative Timesteps: 882,445,676

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 882445676...
Checkpoint 882445676 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 319,100.19879
Policy Entropy: 3.71847
Value Function Loss: 0.02012

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.13891
Policy Update Magnitude: 0.46851
Value Function Update Magnitude: 0.49301

Collected Steps per Second: 21,293.01692
Overall Steps per Second: 10,246.89242

Timestep Collection Time: 2.34894
Timestep Consumption Time: 2.53215
PPO Batch Consumption Time: 0.29262
Total Iteration Time: 4.88109

Cumulative Model Updates: 105,832
Cumulative Timesteps: 882,495,692

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 319,100.19879
Policy Entropy: 3.68925
Value Function Loss: 0.02897

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.14424
Policy Update Magnitude: 0.49537
Value Function Update Magnitude: 0.47862

Collected Steps per Second: 21,622.41956
Overall Steps per Second: 10,344.46344

Timestep Collection Time: 2.31408
Timestep Consumption Time: 2.52290
PPO Batch Consumption Time: 0.28836
Total Iteration Time: 4.83698

Cumulative Model Updates: 105,838
Cumulative Timesteps: 882,545,728

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 882545728...
Checkpoint 882545728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 319,100.19879
Policy Entropy: 3.69302
Value Function Loss: 0.02696

Mean KL Divergence: 0.01050
SB3 Clip Fraction: 0.14590
Policy Update Magnitude: 0.52553
Value Function Update Magnitude: 0.47386

Collected Steps per Second: 21,350.75793
Overall Steps per Second: 10,330.51408

Timestep Collection Time: 2.34268
Timestep Consumption Time: 2.49909
PPO Batch Consumption Time: 0.28632
Total Iteration Time: 4.84177

Cumulative Model Updates: 105,844
Cumulative Timesteps: 882,595,746

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 619,900.77661
Policy Entropy: 3.67425
Value Function Loss: 0.03287

Mean KL Divergence: 0.01072
SB3 Clip Fraction: 0.14974
Policy Update Magnitude: 0.52975
Value Function Update Magnitude: 0.54093

Collected Steps per Second: 21,549.99364
Overall Steps per Second: 10,366.41955

Timestep Collection Time: 2.32019
Timestep Consumption Time: 2.50308
PPO Batch Consumption Time: 0.28858
Total Iteration Time: 4.82327

Cumulative Model Updates: 105,850
Cumulative Timesteps: 882,645,746

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 882645746...
Checkpoint 882645746 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 114,594.33714
Policy Entropy: 3.71112
Value Function Loss: 0.03621

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.13942
Policy Update Magnitude: 0.56404
Value Function Update Magnitude: 0.50622

Collected Steps per Second: 20,738.36351
Overall Steps per Second: 10,274.25255

Timestep Collection Time: 2.41215
Timestep Consumption Time: 2.45672
PPO Batch Consumption Time: 0.29347
Total Iteration Time: 4.86887

Cumulative Model Updates: 105,856
Cumulative Timesteps: 882,695,770

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,998.06898
Policy Entropy: 3.71318
Value Function Loss: 0.03664

Mean KL Divergence: 0.01053
SB3 Clip Fraction: 0.14486
Policy Update Magnitude: 0.58782
Value Function Update Magnitude: 0.52564

Collected Steps per Second: 20,709.63869
Overall Steps per Second: 10,325.74984

Timestep Collection Time: 2.41482
Timestep Consumption Time: 2.42841
PPO Batch Consumption Time: 0.28829
Total Iteration Time: 4.84323

Cumulative Model Updates: 105,862
Cumulative Timesteps: 882,745,780

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 882745780...
Checkpoint 882745780 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 135,307.24829
Policy Entropy: 3.73748
Value Function Loss: 0.03156

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.14063
Policy Update Magnitude: 0.57636
Value Function Update Magnitude: 0.60567

Collected Steps per Second: 21,126.31516
Overall Steps per Second: 10,325.51046

Timestep Collection Time: 2.36691
Timestep Consumption Time: 2.47586
PPO Batch Consumption Time: 0.29704
Total Iteration Time: 4.84276

Cumulative Model Updates: 105,868
Cumulative Timesteps: 882,795,784

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 71,913.82653
Policy Entropy: 3.70965
Value Function Loss: 0.02881

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.13992
Policy Update Magnitude: 0.53462
Value Function Update Magnitude: 0.72119

Collected Steps per Second: 20,495.47686
Overall Steps per Second: 10,050.29225

Timestep Collection Time: 2.44044
Timestep Consumption Time: 2.53633
PPO Batch Consumption Time: 0.28899
Total Iteration Time: 4.97677

Cumulative Model Updates: 105,874
Cumulative Timesteps: 882,845,802

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 882845802...
Checkpoint 882845802 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 134,192.43162
Policy Entropy: 3.72543
Value Function Loss: 0.02508

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.14019
Policy Update Magnitude: 0.49054
Value Function Update Magnitude: 0.68619

Collected Steps per Second: 21,164.17600
Overall Steps per Second: 10,203.92394

Timestep Collection Time: 2.36475
Timestep Consumption Time: 2.54003
PPO Batch Consumption Time: 0.29971
Total Iteration Time: 4.90478

Cumulative Model Updates: 105,880
Cumulative Timesteps: 882,895,850

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 166,489.52835
Policy Entropy: 3.69746
Value Function Loss: 0.03099

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.14014
Policy Update Magnitude: 0.49362
Value Function Update Magnitude: 0.58304

Collected Steps per Second: 21,231.91278
Overall Steps per Second: 10,324.18068

Timestep Collection Time: 2.35579
Timestep Consumption Time: 2.48895
PPO Batch Consumption Time: 0.28772
Total Iteration Time: 4.84474

Cumulative Model Updates: 105,886
Cumulative Timesteps: 882,945,868

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 882945868...
Checkpoint 882945868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 189,924.52096
Policy Entropy: 3.72516
Value Function Loss: 0.03094

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.14084
Policy Update Magnitude: 0.51744
Value Function Update Magnitude: 0.63942

Collected Steps per Second: 21,652.75697
Overall Steps per Second: 10,300.13175

Timestep Collection Time: 2.30964
Timestep Consumption Time: 2.54564
PPO Batch Consumption Time: 0.29401
Total Iteration Time: 4.85528

Cumulative Model Updates: 105,892
Cumulative Timesteps: 882,995,878

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66,219.47352
Policy Entropy: 3.71041
Value Function Loss: 0.03552

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.14133
Policy Update Magnitude: 0.52985
Value Function Update Magnitude: 0.59584

Collected Steps per Second: 21,285.82554
Overall Steps per Second: 10,192.53522

Timestep Collection Time: 2.35039
Timestep Consumption Time: 2.55810
PPO Batch Consumption Time: 0.29774
Total Iteration Time: 4.90849

Cumulative Model Updates: 105,898
Cumulative Timesteps: 883,045,908

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 883045908...
Checkpoint 883045908 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 66,219.47352
Policy Entropy: 3.71443
Value Function Loss: 0.03019

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.14523
Policy Update Magnitude: 0.51455
Value Function Update Magnitude: 0.48007

Collected Steps per Second: 21,355.51809
Overall Steps per Second: 10,242.97812

Timestep Collection Time: 2.34160
Timestep Consumption Time: 2.54038
PPO Batch Consumption Time: 0.29684
Total Iteration Time: 4.88198

Cumulative Model Updates: 105,904
Cumulative Timesteps: 883,095,914

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66,219.47352
Policy Entropy: 3.69322
Value Function Loss: 0.02571

Mean KL Divergence: 0.01146
SB3 Clip Fraction: 0.15502
Policy Update Magnitude: 0.51377
Value Function Update Magnitude: 0.56004

Collected Steps per Second: 21,484.15000
Overall Steps per Second: 10,261.57788

Timestep Collection Time: 2.32730
Timestep Consumption Time: 2.54525
PPO Batch Consumption Time: 0.29218
Total Iteration Time: 4.87254

Cumulative Model Updates: 105,910
Cumulative Timesteps: 883,145,914

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 883145914...
Checkpoint 883145914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 66,219.47352
Policy Entropy: 3.69731
Value Function Loss: 0.02439

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.14530
Policy Update Magnitude: 0.51931
Value Function Update Magnitude: 0.45258

Collected Steps per Second: 21,398.90932
Overall Steps per Second: 10,219.54536

Timestep Collection Time: 2.33778
Timestep Consumption Time: 2.55735
PPO Batch Consumption Time: 0.29669
Total Iteration Time: 4.89513

Cumulative Model Updates: 105,916
Cumulative Timesteps: 883,195,940

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 191,557.11942
Policy Entropy: 3.69529
Value Function Loss: 0.02435

Mean KL Divergence: 0.01113
SB3 Clip Fraction: 0.15550
Policy Update Magnitude: 0.46430
Value Function Update Magnitude: 0.39260

Collected Steps per Second: 21,364.41510
Overall Steps per Second: 10,202.72267

Timestep Collection Time: 2.34156
Timestep Consumption Time: 2.56164
PPO Batch Consumption Time: 0.29712
Total Iteration Time: 4.90320

Cumulative Model Updates: 105,922
Cumulative Timesteps: 883,245,966

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 883245966...
Checkpoint 883245966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 155,164.63889
Policy Entropy: 3.71190
Value Function Loss: 0.02324

Mean KL Divergence: 0.01129
SB3 Clip Fraction: 0.15403
Policy Update Magnitude: 0.45393
Value Function Update Magnitude: 0.46605

Collected Steps per Second: 20,669.93512
Overall Steps per Second: 10,255.52236

Timestep Collection Time: 2.42033
Timestep Consumption Time: 2.45783
PPO Batch Consumption Time: 0.29451
Total Iteration Time: 4.87815

Cumulative Model Updates: 105,928
Cumulative Timesteps: 883,295,994

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 155,164.63889
Policy Entropy: 3.71251
Value Function Loss: 0.02382

Mean KL Divergence: 0.01089
SB3 Clip Fraction: 0.15104
Policy Update Magnitude: 0.45470
Value Function Update Magnitude: 0.48287

Collected Steps per Second: 20,844.19707
Overall Steps per Second: 10,240.68602

Timestep Collection Time: 2.39923
Timestep Consumption Time: 2.48423
PPO Batch Consumption Time: 0.29441
Total Iteration Time: 4.88346

Cumulative Model Updates: 105,934
Cumulative Timesteps: 883,346,004

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 883346004...
Checkpoint 883346004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 155,164.63889
Policy Entropy: 3.71605
Value Function Loss: 0.02305

Mean KL Divergence: 0.01073
SB3 Clip Fraction: 0.14736
Policy Update Magnitude: 0.44993
Value Function Update Magnitude: 0.46665

Collected Steps per Second: 20,863.09100
Overall Steps per Second: 10,255.66103

Timestep Collection Time: 2.39763
Timestep Consumption Time: 2.47987
PPO Batch Consumption Time: 0.28567
Total Iteration Time: 4.87750

Cumulative Model Updates: 105,940
Cumulative Timesteps: 883,396,026

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 155,164.63889
Policy Entropy: 3.68876
Value Function Loss: 0.02421

Mean KL Divergence: 0.01047
SB3 Clip Fraction: 0.14697
Policy Update Magnitude: 0.49488
Value Function Update Magnitude: 0.53725

Collected Steps per Second: 21,519.44453
Overall Steps per Second: 10,338.11109

Timestep Collection Time: 2.32432
Timestep Consumption Time: 2.51390
PPO Batch Consumption Time: 0.28834
Total Iteration Time: 4.83821

Cumulative Model Updates: 105,946
Cumulative Timesteps: 883,446,044

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 883446044...
Checkpoint 883446044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 155,164.63889
Policy Entropy: 3.69345
Value Function Loss: 0.02431

Mean KL Divergence: 0.01059
SB3 Clip Fraction: 0.14942
Policy Update Magnitude: 0.52934
Value Function Update Magnitude: 0.59647

Collected Steps per Second: 20,945.84237
Overall Steps per Second: 10,240.85085

Timestep Collection Time: 2.38759
Timestep Consumption Time: 2.49580
PPO Batch Consumption Time: 0.29188
Total Iteration Time: 4.88338

Cumulative Model Updates: 105,952
Cumulative Timesteps: 883,496,054

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 155,164.63889
Policy Entropy: 3.69354
Value Function Loss: 0.02490

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.14678
Policy Update Magnitude: 0.51710
Value Function Update Magnitude: 0.61425

Collected Steps per Second: 20,992.01460
Overall Steps per Second: 10,073.30424

Timestep Collection Time: 2.38186
Timestep Consumption Time: 2.58176
PPO Batch Consumption Time: 0.30048
Total Iteration Time: 4.96361

Cumulative Model Updates: 105,958
Cumulative Timesteps: 883,546,054

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 883546054...
Checkpoint 883546054 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 185,588.03972
Policy Entropy: 3.70982
Value Function Loss: 0.02370

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.14577
Policy Update Magnitude: 0.46577
Value Function Update Magnitude: 0.51559

Collected Steps per Second: 21,604.03830
Overall Steps per Second: 10,236.39156

Timestep Collection Time: 2.31559
Timestep Consumption Time: 2.57149
PPO Batch Consumption Time: 0.30121
Total Iteration Time: 4.88707

Cumulative Model Updates: 105,964
Cumulative Timesteps: 883,596,080

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52,430.22745
Policy Entropy: 3.71134
Value Function Loss: 0.02345

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.13523
Policy Update Magnitude: 0.49026
Value Function Update Magnitude: 0.47425

Collected Steps per Second: 21,664.30642
Overall Steps per Second: 10,387.74835

Timestep Collection Time: 2.30887
Timestep Consumption Time: 2.50642
PPO Batch Consumption Time: 0.28812
Total Iteration Time: 4.81529

Cumulative Model Updates: 105,970
Cumulative Timesteps: 883,646,100

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 883646100...
Checkpoint 883646100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,293.60276
Policy Entropy: 3.71964
Value Function Loss: 0.02306

Mean KL Divergence: 0.01055
SB3 Clip Fraction: 0.14766
Policy Update Magnitude: 0.50268
Value Function Update Magnitude: 0.52499

Collected Steps per Second: 21,696.95795
Overall Steps per Second: 10,259.61113

Timestep Collection Time: 2.30456
Timestep Consumption Time: 2.56911
PPO Batch Consumption Time: 0.30002
Total Iteration Time: 4.87367

Cumulative Model Updates: 105,976
Cumulative Timesteps: 883,696,102

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 178,565.85714
Policy Entropy: 3.72321
Value Function Loss: 0.02455

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.13772
Policy Update Magnitude: 0.50971
Value Function Update Magnitude: 0.58067

Collected Steps per Second: 21,865.38139
Overall Steps per Second: 10,370.14584

Timestep Collection Time: 2.28782
Timestep Consumption Time: 2.53603
PPO Batch Consumption Time: 0.28917
Total Iteration Time: 4.82385

Cumulative Model Updates: 105,982
Cumulative Timesteps: 883,746,126

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 883746126...
Checkpoint 883746126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 62,265.98530
Policy Entropy: 3.70589
Value Function Loss: 0.02492

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.14529
Policy Update Magnitude: 0.53720
Value Function Update Magnitude: 0.55340

Collected Steps per Second: 21,412.45923
Overall Steps per Second: 10,248.92063

Timestep Collection Time: 2.33528
Timestep Consumption Time: 2.54368
PPO Batch Consumption Time: 0.29137
Total Iteration Time: 4.87895

Cumulative Model Updates: 105,988
Cumulative Timesteps: 883,796,130

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48,118.79651
Policy Entropy: 3.71054
Value Function Loss: 0.02618

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.14730
Policy Update Magnitude: 0.54151
Value Function Update Magnitude: 0.58633

Collected Steps per Second: 21,414.31289
Overall Steps per Second: 10,208.10283

Timestep Collection Time: 2.33619
Timestep Consumption Time: 2.56462
PPO Batch Consumption Time: 0.29677
Total Iteration Time: 4.90081

Cumulative Model Updates: 105,994
Cumulative Timesteps: 883,846,158

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 883846158...
Checkpoint 883846158 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 748,548.10696
Policy Entropy: 3.68829
Value Function Loss: 0.02703

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.14149
Policy Update Magnitude: 0.58660
Value Function Update Magnitude: 0.73475

Collected Steps per Second: 21,034.25573
Overall Steps per Second: 10,090.22313

Timestep Collection Time: 2.37784
Timestep Consumption Time: 2.57904
PPO Batch Consumption Time: 0.30112
Total Iteration Time: 4.95688

Cumulative Model Updates: 106,000
Cumulative Timesteps: 883,896,174

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 748,548.10696
Policy Entropy: 3.68261
Value Function Loss: 0.02915

Mean KL Divergence: 0.01070
SB3 Clip Fraction: 0.14875
Policy Update Magnitude: 0.56593
Value Function Update Magnitude: 0.70692

Collected Steps per Second: 21,647.59823
Overall Steps per Second: 10,357.79121

Timestep Collection Time: 2.31102
Timestep Consumption Time: 2.51897
PPO Batch Consumption Time: 0.28856
Total Iteration Time: 4.82999

Cumulative Model Updates: 106,006
Cumulative Timesteps: 883,946,202

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 883946202...
Checkpoint 883946202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 748,548.10696
Policy Entropy: 3.68004
Value Function Loss: 0.02496

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.14838
Policy Update Magnitude: 0.56318
Value Function Update Magnitude: 0.54958

Collected Steps per Second: 21,522.32114
Overall Steps per Second: 10,271.47637

Timestep Collection Time: 2.32456
Timestep Consumption Time: 2.54621
PPO Batch Consumption Time: 0.29418
Total Iteration Time: 4.87077

Cumulative Model Updates: 106,012
Cumulative Timesteps: 883,996,232

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 748,548.10696
Policy Entropy: 3.70370
Value Function Loss: 0.02397

Mean KL Divergence: 0.01112
SB3 Clip Fraction: 0.15188
Policy Update Magnitude: 0.49855
Value Function Update Magnitude: 0.43001

Collected Steps per Second: 21,761.71492
Overall Steps per Second: 10,379.29663

Timestep Collection Time: 2.29881
Timestep Consumption Time: 2.52098
PPO Batch Consumption Time: 0.28797
Total Iteration Time: 4.81979

Cumulative Model Updates: 106,018
Cumulative Timesteps: 884,046,258

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 884046258...
Checkpoint 884046258 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 748,548.10696
Policy Entropy: 3.71742
Value Function Loss: 0.02235

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.14135
Policy Update Magnitude: 0.45207
Value Function Update Magnitude: 0.41327

Collected Steps per Second: 20,960.00668
Overall Steps per Second: 10,163.07419

Timestep Collection Time: 2.38683
Timestep Consumption Time: 2.53570
PPO Batch Consumption Time: 0.29159
Total Iteration Time: 4.92253

Cumulative Model Updates: 106,024
Cumulative Timesteps: 884,096,286

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 834,841.62275
Policy Entropy: 3.71274
Value Function Loss: 0.02511

Mean KL Divergence: 0.01100
SB3 Clip Fraction: 0.15111
Policy Update Magnitude: 0.43620
Value Function Update Magnitude: 0.45841

Collected Steps per Second: 21,828.08226
Overall Steps per Second: 10,161.30348

Timestep Collection Time: 2.29228
Timestep Consumption Time: 2.63189
PPO Batch Consumption Time: 0.31111
Total Iteration Time: 4.92417

Cumulative Model Updates: 106,030
Cumulative Timesteps: 884,146,322

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 884146322...
Checkpoint 884146322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 289,880.73330
Policy Entropy: 3.72992
Value Function Loss: 0.02351

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.14539
Policy Update Magnitude: 0.45209
Value Function Update Magnitude: 0.59700

Collected Steps per Second: 21,316.88780
Overall Steps per Second: 10,219.53470

Timestep Collection Time: 2.34659
Timestep Consumption Time: 2.54815
PPO Batch Consumption Time: 0.29560
Total Iteration Time: 4.89474

Cumulative Model Updates: 106,036
Cumulative Timesteps: 884,196,344

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 234,800.89605
Policy Entropy: 3.72547
Value Function Loss: 0.02273

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.14254
Policy Update Magnitude: 0.47662
Value Function Update Magnitude: 0.70088

Collected Steps per Second: 21,349.87881
Overall Steps per Second: 10,210.97843

Timestep Collection Time: 2.34221
Timestep Consumption Time: 2.55506
PPO Batch Consumption Time: 0.29670
Total Iteration Time: 4.89728

Cumulative Model Updates: 106,042
Cumulative Timesteps: 884,246,350

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 884246350...
Checkpoint 884246350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 234,800.89605
Policy Entropy: 3.72307
Value Function Loss: 0.01969

Mean KL Divergence: 0.01067
SB3 Clip Fraction: 0.14953
Policy Update Magnitude: 0.47350
Value Function Update Magnitude: 0.69576

Collected Steps per Second: 21,616.06868
Overall Steps per Second: 10,395.93889

Timestep Collection Time: 2.31365
Timestep Consumption Time: 2.49708
PPO Batch Consumption Time: 0.28777
Total Iteration Time: 4.81072

Cumulative Model Updates: 106,048
Cumulative Timesteps: 884,296,362

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 181,473.97782
Policy Entropy: 3.70825
Value Function Loss: 0.01813

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.15096
Policy Update Magnitude: 0.43002
Value Function Update Magnitude: 0.60748

Collected Steps per Second: 20,852.19483
Overall Steps per Second: 10,275.15333

Timestep Collection Time: 2.39840
Timestep Consumption Time: 2.46887
PPO Batch Consumption Time: 0.29534
Total Iteration Time: 4.86728

Cumulative Model Updates: 106,054
Cumulative Timesteps: 884,346,374

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 884346374...
Checkpoint 884346374 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 119,074.05194
Policy Entropy: 3.71027
Value Function Loss: 0.01723

Mean KL Divergence: 0.01053
SB3 Clip Fraction: 0.14802
Policy Update Magnitude: 0.41185
Value Function Update Magnitude: 0.62658

Collected Steps per Second: 20,648.27750
Overall Steps per Second: 10,317.39678

Timestep Collection Time: 2.42296
Timestep Consumption Time: 2.42613
PPO Batch Consumption Time: 0.28864
Total Iteration Time: 4.84909

Cumulative Model Updates: 106,060
Cumulative Timesteps: 884,396,404

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 192,886.82475
Policy Entropy: 3.71090
Value Function Loss: 0.02493

Mean KL Divergence: 0.01089
SB3 Clip Fraction: 0.14892
Policy Update Magnitude: 0.47160
Value Function Update Magnitude: 0.67253

Collected Steps per Second: 20,695.22261
Overall Steps per Second: 10,164.77470

Timestep Collection Time: 2.41689
Timestep Consumption Time: 2.50383
PPO Batch Consumption Time: 0.30080
Total Iteration Time: 4.92072

Cumulative Model Updates: 106,066
Cumulative Timesteps: 884,446,422

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 884446422...
Checkpoint 884446422 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,070.80808
Policy Entropy: 3.71910
Value Function Loss: 0.02776

Mean KL Divergence: 0.01188
SB3 Clip Fraction: 0.15876
Policy Update Magnitude: 0.59859
Value Function Update Magnitude: 0.68901

Collected Steps per Second: 20,634.82385
Overall Steps per Second: 10,192.80787

Timestep Collection Time: 2.42396
Timestep Consumption Time: 2.48322
PPO Batch Consumption Time: 0.28697
Total Iteration Time: 4.90719

Cumulative Model Updates: 106,072
Cumulative Timesteps: 884,496,440

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 833.97248
Policy Entropy: 3.73343
Value Function Loss: 0.02627

Mean KL Divergence: 0.01209
SB3 Clip Fraction: 0.15569
Policy Update Magnitude: 0.66324
Value Function Update Magnitude: 0.97295

Collected Steps per Second: 21,433.12003
Overall Steps per Second: 10,356.65685

Timestep Collection Time: 2.33321
Timestep Consumption Time: 2.49537
PPO Batch Consumption Time: 0.28898
Total Iteration Time: 4.82859

Cumulative Model Updates: 106,078
Cumulative Timesteps: 884,546,448

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 884546448...
Checkpoint 884546448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 305,084.75678
Policy Entropy: 3.72434
Value Function Loss: 0.03066

Mean KL Divergence: 0.01118
SB3 Clip Fraction: 0.13897
Policy Update Magnitude: 0.75651
Value Function Update Magnitude: 0.98944

Collected Steps per Second: 21,111.16226
Overall Steps per Second: 10,325.48495

Timestep Collection Time: 2.36993
Timestep Consumption Time: 2.47556
PPO Batch Consumption Time: 0.28633
Total Iteration Time: 4.84549

Cumulative Model Updates: 106,084
Cumulative Timesteps: 884,596,480

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 162,153.66209
Policy Entropy: 3.71940
Value Function Loss: 0.03220

Mean KL Divergence: 0.01221
SB3 Clip Fraction: 0.15378
Policy Update Magnitude: 0.79133
Value Function Update Magnitude: 0.79973

Collected Steps per Second: 21,190.17410
Overall Steps per Second: 10,171.87819

Timestep Collection Time: 2.36072
Timestep Consumption Time: 2.55716
PPO Batch Consumption Time: 0.29784
Total Iteration Time: 4.91787

Cumulative Model Updates: 106,090
Cumulative Timesteps: 884,646,504

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 884646504...
Checkpoint 884646504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 162,153.66209
Policy Entropy: 3.70145
Value Function Loss: 0.03641

Mean KL Divergence: 0.01535
SB3 Clip Fraction: 0.19518
Policy Update Magnitude: 0.77273
Value Function Update Magnitude: 0.66433

Collected Steps per Second: 20,659.60068
Overall Steps per Second: 10,078.59556

Timestep Collection Time: 2.42144
Timestep Consumption Time: 2.54215
PPO Batch Consumption Time: 0.29377
Total Iteration Time: 4.96359

Cumulative Model Updates: 106,096
Cumulative Timesteps: 884,696,530

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 265,707.06435
Policy Entropy: 3.72652
Value Function Loss: 0.03045

Mean KL Divergence: 0.01524
SB3 Clip Fraction: 0.19209
Policy Update Magnitude: 0.65549
Value Function Update Magnitude: 0.55550

Collected Steps per Second: 21,405.02997
Overall Steps per Second: 10,131.31385

Timestep Collection Time: 2.33627
Timestep Consumption Time: 2.59971
PPO Batch Consumption Time: 0.30371
Total Iteration Time: 4.93598

Cumulative Model Updates: 106,102
Cumulative Timesteps: 884,746,538

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 884746538...
Checkpoint 884746538 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 114,378.80725
Policy Entropy: 3.72479
Value Function Loss: 0.02681

Mean KL Divergence: 0.02596
SB3 Clip Fraction: 0.27995
Policy Update Magnitude: 0.56196
Value Function Update Magnitude: 0.54524

Collected Steps per Second: 20,933.17807
Overall Steps per Second: 10,126.71782

Timestep Collection Time: 2.38913
Timestep Consumption Time: 2.54949
PPO Batch Consumption Time: 0.29187
Total Iteration Time: 4.93862

Cumulative Model Updates: 106,108
Cumulative Timesteps: 884,796,550

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 114,378.80725
Policy Entropy: 3.73935
Value Function Loss: 0.02927

Mean KL Divergence: 0.02174
SB3 Clip Fraction: 0.26688
Policy Update Magnitude: 0.42992
Value Function Update Magnitude: 0.48176

Collected Steps per Second: 21,628.17874
Overall Steps per Second: 10,371.33901

Timestep Collection Time: 2.31282
Timestep Consumption Time: 2.51028
PPO Batch Consumption Time: 0.28815
Total Iteration Time: 4.82310

Cumulative Model Updates: 106,114
Cumulative Timesteps: 884,846,572

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 884846572...
Checkpoint 884846572 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 271,032.06034
Policy Entropy: 3.73217
Value Function Loss: 0.03822

Mean KL Divergence: 0.02346
SB3 Clip Fraction: 0.27814
Policy Update Magnitude: 0.42350
Value Function Update Magnitude: 0.54136

Collected Steps per Second: 21,287.48283
Overall Steps per Second: 10,290.19104

Timestep Collection Time: 2.34946
Timestep Consumption Time: 2.51090
PPO Batch Consumption Time: 0.29045
Total Iteration Time: 4.86036

Cumulative Model Updates: 106,120
Cumulative Timesteps: 884,896,586

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,719.15511
Policy Entropy: 3.72348
Value Function Loss: 0.04573

Mean KL Divergence: 0.01910
SB3 Clip Fraction: 0.23692
Policy Update Magnitude: 0.49695
Value Function Update Magnitude: 0.62145

Collected Steps per Second: 21,152.97677
Overall Steps per Second: 10,386.97158

Timestep Collection Time: 2.36506
Timestep Consumption Time: 2.45136
PPO Batch Consumption Time: 0.29000
Total Iteration Time: 4.81642

Cumulative Model Updates: 106,126
Cumulative Timesteps: 884,946,614

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 884946614...
Checkpoint 884946614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,621.98513
Policy Entropy: 3.73005
Value Function Loss: 0.05797

Mean KL Divergence: 0.01908
SB3 Clip Fraction: 0.22296
Policy Update Magnitude: 0.52170
Value Function Update Magnitude: 0.56198

Collected Steps per Second: 19,642.55267
Overall Steps per Second: 9,933.28649

Timestep Collection Time: 2.54600
Timestep Consumption Time: 2.48858
PPO Batch Consumption Time: 0.30095
Total Iteration Time: 5.03459

Cumulative Model Updates: 106,132
Cumulative Timesteps: 884,996,624

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,227.21131
Policy Entropy: 3.75747
Value Function Loss: 0.05591

Mean KL Divergence: 0.01335
SB3 Clip Fraction: 0.16412
Policy Update Magnitude: 0.65203
Value Function Update Magnitude: 0.42808

Collected Steps per Second: 20,306.34194
Overall Steps per Second: 10,125.49909

Timestep Collection Time: 2.46278
Timestep Consumption Time: 2.47624
PPO Batch Consumption Time: 0.29658
Total Iteration Time: 4.93902

Cumulative Model Updates: 106,138
Cumulative Timesteps: 885,046,634

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 885046634...
Checkpoint 885046634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,227.21131
Policy Entropy: 3.74560
Value Function Loss: 0.05159

Mean KL Divergence: 0.01287
SB3 Clip Fraction: 0.15501
Policy Update Magnitude: 0.66318
Value Function Update Magnitude: 0.38933

Collected Steps per Second: 20,612.57085
Overall Steps per Second: 10,048.30323

Timestep Collection Time: 2.42600
Timestep Consumption Time: 2.55057
PPO Batch Consumption Time: 0.30110
Total Iteration Time: 4.97656

Cumulative Model Updates: 106,144
Cumulative Timesteps: 885,096,640

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,227.21131
Policy Entropy: 3.72495
Value Function Loss: 0.05112

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.11984
Policy Update Magnitude: 0.70717
Value Function Update Magnitude: 0.34364

Collected Steps per Second: 21,279.97235
Overall Steps per Second: 10,335.26986

Timestep Collection Time: 2.35160
Timestep Consumption Time: 2.49027
PPO Batch Consumption Time: 0.28833
Total Iteration Time: 4.84187

Cumulative Model Updates: 106,150
Cumulative Timesteps: 885,146,682

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 885146682...
Checkpoint 885146682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 69,013.89711
Policy Entropy: 3.69790
Value Function Loss: 0.04086

Mean KL Divergence: 0.00722
SB3 Clip Fraction: 0.09101
Policy Update Magnitude: 0.83638
Value Function Update Magnitude: 0.41021

Collected Steps per Second: 20,947.84386
Overall Steps per Second: 10,255.23491

Timestep Collection Time: 2.38764
Timestep Consumption Time: 2.48947
PPO Batch Consumption Time: 0.28824
Total Iteration Time: 4.87712

Cumulative Model Updates: 106,156
Cumulative Timesteps: 885,196,698

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,695.04959
Policy Entropy: 3.69807
Value Function Loss: 0.04769

Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.10494
Policy Update Magnitude: 0.87985
Value Function Update Magnitude: 0.39760

Collected Steps per Second: 21,638.09620
Overall Steps per Second: 10,287.19471

Timestep Collection Time: 2.31157
Timestep Consumption Time: 2.55059
PPO Batch Consumption Time: 0.29541
Total Iteration Time: 4.86216

Cumulative Model Updates: 106,162
Cumulative Timesteps: 885,246,716

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 885246716...
Checkpoint 885246716 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 505,587.29379
Policy Entropy: 3.67991
Value Function Loss: 0.04810

Mean KL Divergence: 0.01081
SB3 Clip Fraction: 0.14529
Policy Update Magnitude: 0.77675
Value Function Update Magnitude: 0.41053

Collected Steps per Second: 20,787.08671
Overall Steps per Second: 10,036.56262

Timestep Collection Time: 2.40630
Timestep Consumption Time: 2.57748
PPO Batch Consumption Time: 0.30105
Total Iteration Time: 4.98378

Cumulative Model Updates: 106,168
Cumulative Timesteps: 885,296,736

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85,615.47199
Policy Entropy: 3.69160
Value Function Loss: 0.04056

Mean KL Divergence: 0.01221
SB3 Clip Fraction: 0.16070
Policy Update Magnitude: 0.74409
Value Function Update Magnitude: 0.66231

Collected Steps per Second: 21,582.30737
Overall Steps per Second: 10,347.21025

Timestep Collection Time: 2.31801
Timestep Consumption Time: 2.51692
PPO Batch Consumption Time: 0.28881
Total Iteration Time: 4.83493

Cumulative Model Updates: 106,174
Cumulative Timesteps: 885,346,764

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 885346764...
Checkpoint 885346764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,508.13432
Policy Entropy: 3.68130
Value Function Loss: 0.04617

Mean KL Divergence: 0.01154
SB3 Clip Fraction: 0.14903
Policy Update Magnitude: 0.77157
Value Function Update Magnitude: 0.86978

Collected Steps per Second: 20,963.72797
Overall Steps per Second: 10,201.41909

Timestep Collection Time: 2.38603
Timestep Consumption Time: 2.51721
PPO Batch Consumption Time: 0.28749
Total Iteration Time: 4.90324

Cumulative Model Updates: 106,180
Cumulative Timesteps: 885,396,784

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 844,350.39688
Policy Entropy: 3.71819
Value Function Loss: 0.03969

Mean KL Divergence: 0.01227
SB3 Clip Fraction: 0.16219
Policy Update Magnitude: 0.70440
Value Function Update Magnitude: 0.78897

Collected Steps per Second: 21,332.05273
Overall Steps per Second: 10,184.76912

Timestep Collection Time: 2.34473
Timestep Consumption Time: 2.56632
PPO Batch Consumption Time: 0.30069
Total Iteration Time: 4.91106

Cumulative Model Updates: 106,186
Cumulative Timesteps: 885,446,802

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 885446802...
Checkpoint 885446802 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 112,040.96135
Policy Entropy: 3.72572
Value Function Loss: 0.03741

Mean KL Divergence: 0.01139
SB3 Clip Fraction: 0.15122
Policy Update Magnitude: 0.66471
Value Function Update Magnitude: 0.62551

Collected Steps per Second: 21,294.08915
Overall Steps per Second: 10,156.93577

Timestep Collection Time: 2.34873
Timestep Consumption Time: 2.57540
PPO Batch Consumption Time: 0.29725
Total Iteration Time: 4.92412

Cumulative Model Updates: 106,192
Cumulative Timesteps: 885,496,816

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,916.26709
Policy Entropy: 3.74336
Value Function Loss: 0.03338

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.12949
Policy Update Magnitude: 0.56773
Value Function Update Magnitude: 0.58756

Collected Steps per Second: 21,613.51083
Overall Steps per Second: 10,352.18571

Timestep Collection Time: 2.31337
Timestep Consumption Time: 2.51653
PPO Batch Consumption Time: 0.28846
Total Iteration Time: 4.82990

Cumulative Model Updates: 106,198
Cumulative Timesteps: 885,546,816

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 885546816...
Checkpoint 885546816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,716.48116
Policy Entropy: 3.74229
Value Function Loss: 0.03084

Mean KL Divergence: 0.01067
SB3 Clip Fraction: 0.14803
Policy Update Magnitude: 0.52616
Value Function Update Magnitude: 0.56281

Collected Steps per Second: 20,883.91278
Overall Steps per Second: 10,037.66472

Timestep Collection Time: 2.39495
Timestep Consumption Time: 2.58788
PPO Batch Consumption Time: 0.30017
Total Iteration Time: 4.98283

Cumulative Model Updates: 106,204
Cumulative Timesteps: 885,596,832

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,236.81060
Policy Entropy: 3.72425
Value Function Loss: 0.03370

Mean KL Divergence: 0.01141
SB3 Clip Fraction: 0.15962
Policy Update Magnitude: 0.48348
Value Function Update Magnitude: 0.56065

Collected Steps per Second: 21,690.05258
Overall Steps per Second: 10,330.79888

Timestep Collection Time: 2.30650
Timestep Consumption Time: 2.53611
PPO Batch Consumption Time: 0.29177
Total Iteration Time: 4.84261

Cumulative Model Updates: 106,210
Cumulative Timesteps: 885,646,860

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 885646860...
Checkpoint 885646860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,197.92575
Policy Entropy: 3.72664
Value Function Loss: 0.03127

Mean KL Divergence: 0.01163
SB3 Clip Fraction: 0.16243
Policy Update Magnitude: 0.45505
Value Function Update Magnitude: 0.48456

Collected Steps per Second: 21,517.96783
Overall Steps per Second: 10,208.86918

Timestep Collection Time: 2.32364
Timestep Consumption Time: 2.57406
PPO Batch Consumption Time: 0.30055
Total Iteration Time: 4.89770

Cumulative Model Updates: 106,216
Cumulative Timesteps: 885,696,860

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 338,024.78015
Policy Entropy: 3.71425
Value Function Loss: 0.03405

Mean KL Divergence: 0.01183
SB3 Clip Fraction: 0.16259
Policy Update Magnitude: 0.45519
Value Function Update Magnitude: 0.44352

Collected Steps per Second: 21,038.03386
Overall Steps per Second: 10,353.63462

Timestep Collection Time: 2.37845
Timestep Consumption Time: 2.45444
PPO Batch Consumption Time: 0.29001
Total Iteration Time: 4.83289

Cumulative Model Updates: 106,222
Cumulative Timesteps: 885,746,898

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 885746898...
Checkpoint 885746898 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,462.62682
Policy Entropy: 3.73325
Value Function Loss: 0.03027

Mean KL Divergence: 0.01058
SB3 Clip Fraction: 0.14844
Policy Update Magnitude: 0.45966
Value Function Update Magnitude: 0.56054

Collected Steps per Second: 20,637.16685
Overall Steps per Second: 10,299.22034

Timestep Collection Time: 2.42291
Timestep Consumption Time: 2.43202
PPO Batch Consumption Time: 0.28955
Total Iteration Time: 4.85493

Cumulative Model Updates: 106,228
Cumulative Timesteps: 885,796,900

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 538,467.61499
Policy Entropy: 3.71934
Value Function Loss: 0.03012

Mean KL Divergence: 0.01117
SB3 Clip Fraction: 0.15629
Policy Update Magnitude: 0.43336
Value Function Update Magnitude: 0.58488

Collected Steps per Second: 21,271.73874
Overall Steps per Second: 10,473.53701

Timestep Collection Time: 2.35063
Timestep Consumption Time: 2.42350
PPO Batch Consumption Time: 0.28678
Total Iteration Time: 4.77413

Cumulative Model Updates: 106,234
Cumulative Timesteps: 885,846,902

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 885846902...
Checkpoint 885846902 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 81,355.14783
Policy Entropy: 3.74693
Value Function Loss: 0.02487

Mean KL Divergence: 0.01073
SB3 Clip Fraction: 0.14902
Policy Update Magnitude: 0.41898
Value Function Update Magnitude: 0.56767

Collected Steps per Second: 20,762.79835
Overall Steps per Second: 10,218.22074

Timestep Collection Time: 2.40950
Timestep Consumption Time: 2.48646
PPO Batch Consumption Time: 0.28682
Total Iteration Time: 4.89596

Cumulative Model Updates: 106,240
Cumulative Timesteps: 885,896,930

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,903.80208
Policy Entropy: 3.73751
Value Function Loss: 0.02464

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.14806
Policy Update Magnitude: 0.39752
Value Function Update Magnitude: 0.54330

Collected Steps per Second: 21,753.94473
Overall Steps per Second: 10,454.07651

Timestep Collection Time: 2.29963
Timestep Consumption Time: 2.48568
PPO Batch Consumption Time: 0.28653
Total Iteration Time: 4.78531

Cumulative Model Updates: 106,246
Cumulative Timesteps: 885,946,956

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 885946956...
Checkpoint 885946956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 80,590.16042
Policy Entropy: 3.74716
Value Function Loss: 0.02186

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.14440
Policy Update Magnitude: 0.38267
Value Function Update Magnitude: 0.57502

Collected Steps per Second: 21,458.65761
Overall Steps per Second: 10,230.55461

Timestep Collection Time: 2.33099
Timestep Consumption Time: 2.55828
PPO Batch Consumption Time: 0.30021
Total Iteration Time: 4.88928

Cumulative Model Updates: 106,252
Cumulative Timesteps: 885,996,976

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,957.03062
Policy Entropy: 3.74183
Value Function Loss: 0.02318

Mean KL Divergence: 0.01073
SB3 Clip Fraction: 0.15052
Policy Update Magnitude: 0.42686
Value Function Update Magnitude: 0.57319

Collected Steps per Second: 21,310.43138
Overall Steps per Second: 10,323.05305

Timestep Collection Time: 2.34777
Timestep Consumption Time: 2.49886
PPO Batch Consumption Time: 0.28882
Total Iteration Time: 4.84663

Cumulative Model Updates: 106,258
Cumulative Timesteps: 886,047,008

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 886047008...
Checkpoint 886047008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,114.74740
Policy Entropy: 3.70956
Value Function Loss: 0.02269

Mean KL Divergence: 0.01060
SB3 Clip Fraction: 0.14799
Policy Update Magnitude: 0.43398
Value Function Update Magnitude: 0.54718

Collected Steps per Second: 21,271.35082
Overall Steps per Second: 10,314.75127

Timestep Collection Time: 2.35161
Timestep Consumption Time: 2.49795
PPO Batch Consumption Time: 0.28594
Total Iteration Time: 4.84956

Cumulative Model Updates: 106,264
Cumulative Timesteps: 886,097,030

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 202,414.67285
Policy Entropy: 3.70768
Value Function Loss: 0.02315

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.14722
Policy Update Magnitude: 0.44064
Value Function Update Magnitude: 0.53033

Collected Steps per Second: 21,447.63334
Overall Steps per Second: 10,318.24931

Timestep Collection Time: 2.33191
Timestep Consumption Time: 2.51523
PPO Batch Consumption Time: 0.28808
Total Iteration Time: 4.84714

Cumulative Model Updates: 106,270
Cumulative Timesteps: 886,147,044

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 886147044...
Checkpoint 886147044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87,144.56903
Policy Entropy: 3.68695
Value Function Loss: 0.02424

Mean KL Divergence: 0.01110
SB3 Clip Fraction: 0.15417
Policy Update Magnitude: 0.46840
Value Function Update Magnitude: 0.53200

Collected Steps per Second: 21,581.51395
Overall Steps per Second: 10,304.37298

Timestep Collection Time: 2.31717
Timestep Consumption Time: 2.53592
PPO Batch Consumption Time: 0.29160
Total Iteration Time: 4.85309

Cumulative Model Updates: 106,276
Cumulative Timesteps: 886,197,052

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92,641.36332
Policy Entropy: 3.71218
Value Function Loss: 0.02533

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.14468
Policy Update Magnitude: 0.51205
Value Function Update Magnitude: 0.56723

Collected Steps per Second: 21,187.37765
Overall Steps per Second: 9,986.50097

Timestep Collection Time: 2.36065
Timestep Consumption Time: 2.64771
PPO Batch Consumption Time: 0.31420
Total Iteration Time: 5.00836

Cumulative Model Updates: 106,282
Cumulative Timesteps: 886,247,068

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 886247068...
Checkpoint 886247068 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 92,641.36332
Policy Entropy: 3.71521
Value Function Loss: 0.02276

Mean KL Divergence: 0.01071
SB3 Clip Fraction: 0.14966
Policy Update Magnitude: 0.50881
Value Function Update Magnitude: 0.61231

Collected Steps per Second: 21,452.80422
Overall Steps per Second: 10,234.54591

Timestep Collection Time: 2.33126
Timestep Consumption Time: 2.55533
PPO Batch Consumption Time: 0.29325
Total Iteration Time: 4.88659

Cumulative Model Updates: 106,288
Cumulative Timesteps: 886,297,080

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 203,939.52504
Policy Entropy: 3.71443
Value Function Loss: 0.02209

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.14401
Policy Update Magnitude: 0.47980
Value Function Update Magnitude: 0.60746

Collected Steps per Second: 20,705.44327
Overall Steps per Second: 10,049.90872

Timestep Collection Time: 2.41531
Timestep Consumption Time: 2.56086
PPO Batch Consumption Time: 0.29323
Total Iteration Time: 4.97616

Cumulative Model Updates: 106,294
Cumulative Timesteps: 886,347,090

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 886347090...
Checkpoint 886347090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 225,946.15622
Policy Entropy: 3.68516
Value Function Loss: 0.02397

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.14382
Policy Update Magnitude: 0.47897
Value Function Update Magnitude: 0.58303

Collected Steps per Second: 21,500.15685
Overall Steps per Second: 10,247.78629

Timestep Collection Time: 2.32668
Timestep Consumption Time: 2.55476
PPO Batch Consumption Time: 0.29492
Total Iteration Time: 4.88144

Cumulative Model Updates: 106,300
Cumulative Timesteps: 886,397,114

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97,294.87031
Policy Entropy: 3.68147
Value Function Loss: 0.02693

Mean KL Divergence: 0.01074
SB3 Clip Fraction: 0.14809
Policy Update Magnitude: 0.52535
Value Function Update Magnitude: 0.60576

Collected Steps per Second: 21,542.75214
Overall Steps per Second: 10,340.32996

Timestep Collection Time: 2.32236
Timestep Consumption Time: 2.51598
PPO Batch Consumption Time: 0.28791
Total Iteration Time: 4.83834

Cumulative Model Updates: 106,306
Cumulative Timesteps: 886,447,144

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 886447144...
Checkpoint 886447144 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 343,089.77068
Policy Entropy: 3.68487
Value Function Loss: 0.02905

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.14107
Policy Update Magnitude: 0.53158
Value Function Update Magnitude: 0.59722

Collected Steps per Second: 21,493.87595
Overall Steps per Second: 10,317.09045

Timestep Collection Time: 2.32680
Timestep Consumption Time: 2.52069
PPO Batch Consumption Time: 0.29038
Total Iteration Time: 4.84749

Cumulative Model Updates: 106,312
Cumulative Timesteps: 886,497,156

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 183,873.11429
Policy Entropy: 3.70272
Value Function Loss: 0.02825

Mean KL Divergence: 0.01059
SB3 Clip Fraction: 0.14707
Policy Update Magnitude: 0.53061
Value Function Update Magnitude: 0.67431

Collected Steps per Second: 21,532.16719
Overall Steps per Second: 10,325.67927

Timestep Collection Time: 2.32257
Timestep Consumption Time: 2.52069
PPO Batch Consumption Time: 0.28833
Total Iteration Time: 4.84326

Cumulative Model Updates: 106,318
Cumulative Timesteps: 886,547,166

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 886547166...
Checkpoint 886547166 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 120,641.00775
Policy Entropy: 3.67805
Value Function Loss: 0.02987

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.14674
Policy Update Magnitude: 0.53121
Value Function Update Magnitude: 0.71305

Collected Steps per Second: 21,765.49494
Overall Steps per Second: 10,321.01961

Timestep Collection Time: 2.29813
Timestep Consumption Time: 2.54829
PPO Batch Consumption Time: 0.29500
Total Iteration Time: 4.84642

Cumulative Model Updates: 106,324
Cumulative Timesteps: 886,597,186

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93,633.63525
Policy Entropy: 3.67920
Value Function Loss: 0.02748

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.14469
Policy Update Magnitude: 0.52606
Value Function Update Magnitude: 0.78589

Collected Steps per Second: 21,689.69788
Overall Steps per Second: 10,368.98875

Timestep Collection Time: 2.30635
Timestep Consumption Time: 2.51804
PPO Batch Consumption Time: 0.28982
Total Iteration Time: 4.82439

Cumulative Model Updates: 106,330
Cumulative Timesteps: 886,647,210

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 886647210...
Checkpoint 886647210 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 93,633.63525
Policy Entropy: 3.68058
Value Function Loss: 0.02618

Mean KL Divergence: 0.01080
SB3 Clip Fraction: 0.15020
Policy Update Magnitude: 0.48883
Value Function Update Magnitude: 0.71103

Collected Steps per Second: 21,423.00990
Overall Steps per Second: 10,366.48397

Timestep Collection Time: 2.33543
Timestep Consumption Time: 2.49089
PPO Batch Consumption Time: 0.28622
Total Iteration Time: 4.82632

Cumulative Model Updates: 106,336
Cumulative Timesteps: 886,697,242

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93,633.63525
Policy Entropy: 3.69546
Value Function Loss: 0.02240

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.14380
Policy Update Magnitude: 0.45653
Value Function Update Magnitude: 0.71333

Collected Steps per Second: 21,794.32157
Overall Steps per Second: 10,410.44333

Timestep Collection Time: 2.29463
Timestep Consumption Time: 2.50920
PPO Batch Consumption Time: 0.28684
Total Iteration Time: 4.80383

Cumulative Model Updates: 106,342
Cumulative Timesteps: 886,747,252

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 886747252...
Checkpoint 886747252 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 93,633.63525
Policy Entropy: 3.69459
Value Function Loss: 0.02029

Mean KL Divergence: 0.01080
SB3 Clip Fraction: 0.15367
Policy Update Magnitude: 0.41673
Value Function Update Magnitude: 0.58074

Collected Steps per Second: 21,608.03658
Overall Steps per Second: 10,247.02127

Timestep Collection Time: 2.31479
Timestep Consumption Time: 2.56644
PPO Batch Consumption Time: 0.29973
Total Iteration Time: 4.88122

Cumulative Model Updates: 106,348
Cumulative Timesteps: 886,797,270

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93,633.63525
Policy Entropy: 3.69479
Value Function Loss: 0.01890

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.14672
Policy Update Magnitude: 0.36638
Value Function Update Magnitude: 0.44497

Collected Steps per Second: 21,414.83943
Overall Steps per Second: 10,120.15171

Timestep Collection Time: 2.33558
Timestep Consumption Time: 2.60664
PPO Batch Consumption Time: 0.30266
Total Iteration Time: 4.94222

Cumulative Model Updates: 106,354
Cumulative Timesteps: 886,847,286

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 886847286...
Checkpoint 886847286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 83,309.78069
Policy Entropy: 3.71062
Value Function Loss: 0.02049

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.14943
Policy Update Magnitude: 0.39555
Value Function Update Magnitude: 0.48939

Collected Steps per Second: 21,829.89063
Overall Steps per Second: 10,380.65164

Timestep Collection Time: 2.29099
Timestep Consumption Time: 2.52682
PPO Batch Consumption Time: 0.28803
Total Iteration Time: 4.81781

Cumulative Model Updates: 106,360
Cumulative Timesteps: 886,897,298

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 424,635.32923
Policy Entropy: 3.70156
Value Function Loss: 0.02533

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.14636
Policy Update Magnitude: 0.41915
Value Function Update Magnitude: 0.59692

Collected Steps per Second: 21,885.74193
Overall Steps per Second: 10,432.90398

Timestep Collection Time: 2.28523
Timestep Consumption Time: 2.50864
PPO Batch Consumption Time: 0.28831
Total Iteration Time: 4.79387

Cumulative Model Updates: 106,366
Cumulative Timesteps: 886,947,312

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 886947312...
Checkpoint 886947312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 278,603.91979
Policy Entropy: 3.71381
Value Function Loss: 0.02563

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.14360
Policy Update Magnitude: 0.44500
Value Function Update Magnitude: 0.64766

Collected Steps per Second: 21,068.28353
Overall Steps per Second: 10,330.83411

Timestep Collection Time: 2.37428
Timestep Consumption Time: 2.46773
PPO Batch Consumption Time: 0.29418
Total Iteration Time: 4.84201

Cumulative Model Updates: 106,372
Cumulative Timesteps: 886,997,334

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 328,611.64733
Policy Entropy: 3.68391
Value Function Loss: 0.02848

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.14372
Policy Update Magnitude: 0.44979
Value Function Update Magnitude: 0.65644

Collected Steps per Second: 20,926.81338
Overall Steps per Second: 10,350.24044

Timestep Collection Time: 2.39062
Timestep Consumption Time: 2.44289
PPO Batch Consumption Time: 0.28885
Total Iteration Time: 4.83351

Cumulative Model Updates: 106,378
Cumulative Timesteps: 887,047,362

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 887047362...
Checkpoint 887047362 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 266,170.12716
Policy Entropy: 3.69199
Value Function Loss: 0.02517

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.14082
Policy Update Magnitude: 0.44853
Value Function Update Magnitude: 0.67298

Collected Steps per Second: 20,938.98781
Overall Steps per Second: 10,345.07619

Timestep Collection Time: 2.38961
Timestep Consumption Time: 2.44709
PPO Batch Consumption Time: 0.29386
Total Iteration Time: 4.83670

Cumulative Model Updates: 106,384
Cumulative Timesteps: 887,097,398

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 291,115.37422
Policy Entropy: 3.67749
Value Function Loss: 0.02780

Mean KL Divergence: 0.01070
SB3 Clip Fraction: 0.15078
Policy Update Magnitude: 0.45084
Value Function Update Magnitude: 0.65719

Collected Steps per Second: 20,583.74229
Overall Steps per Second: 10,015.35453

Timestep Collection Time: 2.42920
Timestep Consumption Time: 2.56334
PPO Batch Consumption Time: 0.29962
Total Iteration Time: 4.99253

Cumulative Model Updates: 106,390
Cumulative Timesteps: 887,147,400

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 887147400...
Checkpoint 887147400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 291,115.37422
Policy Entropy: 3.69021
Value Function Loss: 0.02261

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.14553
Policy Update Magnitude: 0.45087
Value Function Update Magnitude: 0.71250

Collected Steps per Second: 21,485.55960
Overall Steps per Second: 10,292.35486

Timestep Collection Time: 2.32789
Timestep Consumption Time: 2.53164
PPO Batch Consumption Time: 0.29965
Total Iteration Time: 4.85953

Cumulative Model Updates: 106,396
Cumulative Timesteps: 887,197,416

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 291,115.37422
Policy Entropy: 3.68577
Value Function Loss: 0.02189

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.14806
Policy Update Magnitude: 0.46141
Value Function Update Magnitude: 0.69204

Collected Steps per Second: 21,256.48691
Overall Steps per Second: 10,313.98604

Timestep Collection Time: 2.35241
Timestep Consumption Time: 2.49576
PPO Batch Consumption Time: 0.28800
Total Iteration Time: 4.84817

Cumulative Model Updates: 106,402
Cumulative Timesteps: 887,247,420

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 887247420...
Checkpoint 887247420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 278,741.76964
Policy Entropy: 3.70125
Value Function Loss: 0.01968

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.14841
Policy Update Magnitude: 0.46994
Value Function Update Magnitude: 0.68186

Collected Steps per Second: 21,285.86728
Overall Steps per Second: 10,257.59087

Timestep Collection Time: 2.35151
Timestep Consumption Time: 2.52819
PPO Batch Consumption Time: 0.29088
Total Iteration Time: 4.87970

Cumulative Model Updates: 106,408
Cumulative Timesteps: 887,297,474

Timesteps Collected: 50,054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 278,741.76964
Policy Entropy: 3.70805
Value Function Loss: 0.02019

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.14598
Policy Update Magnitude: 0.47130
Value Function Update Magnitude: 0.62783

Collected Steps per Second: 21,337.79519
Overall Steps per Second: 10,206.25530

Timestep Collection Time: 2.34354
Timestep Consumption Time: 2.55600
PPO Batch Consumption Time: 0.29644
Total Iteration Time: 4.89954

Cumulative Model Updates: 106,414
Cumulative Timesteps: 887,347,480

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 887347480...
Checkpoint 887347480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 278,741.76964
Policy Entropy: 3.71117
Value Function Loss: 0.01817

Mean KL Divergence: 0.01084
SB3 Clip Fraction: 0.15461
Policy Update Magnitude: 0.47627
Value Function Update Magnitude: 0.58639

Collected Steps per Second: 21,764.73106
Overall Steps per Second: 10,405.16183

Timestep Collection Time: 2.29886
Timestep Consumption Time: 2.50972
PPO Batch Consumption Time: 0.28838
Total Iteration Time: 4.80857

Cumulative Model Updates: 106,420
Cumulative Timesteps: 887,397,514

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 315,474.39226
Policy Entropy: 3.69689
Value Function Loss: 0.02010

Mean KL Divergence: 0.01100
SB3 Clip Fraction: 0.15638
Policy Update Magnitude: 0.45869
Value Function Update Magnitude: 0.62834

Collected Steps per Second: 21,563.39810
Overall Steps per Second: 10,190.39506

Timestep Collection Time: 2.31930
Timestep Consumption Time: 2.58846
PPO Batch Consumption Time: 0.29901
Total Iteration Time: 4.90776

Cumulative Model Updates: 106,426
Cumulative Timesteps: 887,447,526

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 887447526...
Checkpoint 887447526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 315,474.39226
Policy Entropy: 3.70774
Value Function Loss: 0.01998

Mean KL Divergence: 0.01084
SB3 Clip Fraction: 0.15394
Policy Update Magnitude: 0.45237
Value Function Update Magnitude: 0.58067

Collected Steps per Second: 21,616.18696
Overall Steps per Second: 10,164.70750

Timestep Collection Time: 2.31308
Timestep Consumption Time: 2.60590
PPO Batch Consumption Time: 0.30443
Total Iteration Time: 4.91898

Cumulative Model Updates: 106,432
Cumulative Timesteps: 887,497,526

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 275,020.28777
Policy Entropy: 3.71607
Value Function Loss: 0.02250

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.14654
Policy Update Magnitude: 0.44249
Value Function Update Magnitude: 0.60403

Collected Steps per Second: 20,938.78935
Overall Steps per Second: 10,148.77024

Timestep Collection Time: 2.38877
Timestep Consumption Time: 2.53971
PPO Batch Consumption Time: 0.29628
Total Iteration Time: 4.92848

Cumulative Model Updates: 106,438
Cumulative Timesteps: 887,547,544

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 887547544...
Checkpoint 887547544 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 246,883.07860
Policy Entropy: 3.71643
Value Function Loss: 0.02312

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.14620
Policy Update Magnitude: 0.47775
Value Function Update Magnitude: 0.64911

Collected Steps per Second: 21,574.31797
Overall Steps per Second: 10,364.54206

Timestep Collection Time: 2.31868
Timestep Consumption Time: 2.50777
PPO Batch Consumption Time: 0.28819
Total Iteration Time: 4.82646

Cumulative Model Updates: 106,444
Cumulative Timesteps: 887,597,568

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 69,740.03190
Policy Entropy: 3.71664
Value Function Loss: 0.02397

Mean KL Divergence: 0.01123
SB3 Clip Fraction: 0.15549
Policy Update Magnitude: 0.53567
Value Function Update Magnitude: 0.79435

Collected Steps per Second: 21,230.80779
Overall Steps per Second: 10,163.03987

Timestep Collection Time: 2.35554
Timestep Consumption Time: 2.56523
PPO Batch Consumption Time: 0.29588
Total Iteration Time: 4.92077

Cumulative Model Updates: 106,450
Cumulative Timesteps: 887,647,578

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 887647578...
Checkpoint 887647578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 701,448.05467
Policy Entropy: 3.72893
Value Function Loss: 0.02351

Mean KL Divergence: 0.01135
SB3 Clip Fraction: 0.15650
Policy Update Magnitude: 0.57070
Value Function Update Magnitude: 0.75236

Collected Steps per Second: 21,271.59525
Overall Steps per Second: 10,058.88704

Timestep Collection Time: 2.35168
Timestep Consumption Time: 2.62143
PPO Batch Consumption Time: 0.30694
Total Iteration Time: 4.97311

Cumulative Model Updates: 106,456
Cumulative Timesteps: 887,697,602

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 198,121.99427
Policy Entropy: 3.71746
Value Function Loss: 0.02335

Mean KL Divergence: 0.01093
SB3 Clip Fraction: 0.15237
Policy Update Magnitude: 0.55874
Value Function Update Magnitude: 0.62565

Collected Steps per Second: 21,549.31176
Overall Steps per Second: 10,120.42345

Timestep Collection Time: 2.32100
Timestep Consumption Time: 2.62108
PPO Batch Consumption Time: 0.30413
Total Iteration Time: 4.94209

Cumulative Model Updates: 106,462
Cumulative Timesteps: 887,747,618

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 887747618...
Checkpoint 887747618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 160,476.43789
Policy Entropy: 3.70904
Value Function Loss: 0.02340

Mean KL Divergence: 0.01058
SB3 Clip Fraction: 0.14980
Policy Update Magnitude: 0.52070
Value Function Update Magnitude: 0.59559

Collected Steps per Second: 21,463.51610
Overall Steps per Second: 10,253.29130

Timestep Collection Time: 2.33075
Timestep Consumption Time: 2.54827
PPO Batch Consumption Time: 0.29577
Total Iteration Time: 4.87902

Cumulative Model Updates: 106,468
Cumulative Timesteps: 887,797,644

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 133,136.97329
Policy Entropy: 3.67670
Value Function Loss: 0.02409

Mean KL Divergence: 0.01133
SB3 Clip Fraction: 0.15796
Policy Update Magnitude: 0.49917
Value Function Update Magnitude: 0.54606

Collected Steps per Second: 21,564.00136
Overall Steps per Second: 10,354.59178

Timestep Collection Time: 2.31979
Timestep Consumption Time: 2.51130
PPO Batch Consumption Time: 0.28811
Total Iteration Time: 4.83109

Cumulative Model Updates: 106,474
Cumulative Timesteps: 887,847,668

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 887847668...
Checkpoint 887847668 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 133,136.97329
Policy Entropy: 3.69007
Value Function Loss: 0.02207

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.14891
Policy Update Magnitude: 0.48766
Value Function Update Magnitude: 0.53615

Collected Steps per Second: 21,660.76740
Overall Steps per Second: 10,324.24641

Timestep Collection Time: 2.30887
Timestep Consumption Time: 2.53526
PPO Batch Consumption Time: 0.29175
Total Iteration Time: 4.84413

Cumulative Model Updates: 106,480
Cumulative Timesteps: 887,897,680

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 133,136.97329
Policy Entropy: 3.68449
Value Function Loss: 0.02264

Mean KL Divergence: 0.01119
SB3 Clip Fraction: 0.15389
Policy Update Magnitude: 0.46878
Value Function Update Magnitude: 0.53716

Collected Steps per Second: 21,417.60027
Overall Steps per Second: 10,334.30901

Timestep Collection Time: 2.33593
Timestep Consumption Time: 2.50523
PPO Batch Consumption Time: 0.28774
Total Iteration Time: 4.84116

Cumulative Model Updates: 106,486
Cumulative Timesteps: 887,947,710

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 887947710...
Checkpoint 887947710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 195,905.94981
Policy Entropy: 3.69333
Value Function Loss: 0.02099

Mean KL Divergence: 0.01146
SB3 Clip Fraction: 0.15982
Policy Update Magnitude: 0.46441
Value Function Update Magnitude: 0.50741

Collected Steps per Second: 21,137.11615
Overall Steps per Second: 10,251.87543

Timestep Collection Time: 2.36560
Timestep Consumption Time: 2.51175
PPO Batch Consumption Time: 0.28834
Total Iteration Time: 4.87735

Cumulative Model Updates: 106,492
Cumulative Timesteps: 887,997,712

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 195,905.94981
Policy Entropy: 3.70151
Value Function Loss: 0.02122

Mean KL Divergence: 0.01078
SB3 Clip Fraction: 0.15129
Policy Update Magnitude: 0.45644
Value Function Update Magnitude: 0.51392

Collected Steps per Second: 21,356.76799
Overall Steps per Second: 10,130.59375

Timestep Collection Time: 2.34174
Timestep Consumption Time: 2.59499
PPO Batch Consumption Time: 0.29983
Total Iteration Time: 4.93673

Cumulative Model Updates: 106,498
Cumulative Timesteps: 888,047,724

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 888047724...
Checkpoint 888047724 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 580,078.22370
Policy Entropy: 3.71018
Value Function Loss: 0.01882

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.14886
Policy Update Magnitude: 0.41407
Value Function Update Magnitude: 0.49954

Collected Steps per Second: 21,175.46832
Overall Steps per Second: 10,183.48242

Timestep Collection Time: 2.36264
Timestep Consumption Time: 2.55022
PPO Batch Consumption Time: 0.29427
Total Iteration Time: 4.91286

Cumulative Model Updates: 106,504
Cumulative Timesteps: 888,097,754

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 580,078.22370
Policy Entropy: 3.70409
Value Function Loss: 0.01721

Mean KL Divergence: 0.01149
SB3 Clip Fraction: 0.15919
Policy Update Magnitude: 0.37907
Value Function Update Magnitude: 0.49352

Collected Steps per Second: 21,277.96920
Overall Steps per Second: 10,274.66250

Timestep Collection Time: 2.35004
Timestep Consumption Time: 2.51669
PPO Batch Consumption Time: 0.29279
Total Iteration Time: 4.86673

Cumulative Model Updates: 106,510
Cumulative Timesteps: 888,147,758

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 888147758...
Checkpoint 888147758 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 580,078.22370
Policy Entropy: 3.70518
Value Function Loss: 0.01746

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.14308
Policy Update Magnitude: 0.37161
Value Function Update Magnitude: 0.53985

Collected Steps per Second: 21,245.26736
Overall Steps per Second: 10,286.54605

Timestep Collection Time: 2.35365
Timestep Consumption Time: 2.50745
PPO Batch Consumption Time: 0.28761
Total Iteration Time: 4.86111

Cumulative Model Updates: 106,516
Cumulative Timesteps: 888,197,762

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 287,655.11600
Policy Entropy: 3.70592
Value Function Loss: 0.01991

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.15231
Policy Update Magnitude: 0.46165
Value Function Update Magnitude: 0.69038

Collected Steps per Second: 20,987.23173
Overall Steps per Second: 10,292.65272

Timestep Collection Time: 2.38269
Timestep Consumption Time: 2.47573
PPO Batch Consumption Time: 0.29600
Total Iteration Time: 4.85842

Cumulative Model Updates: 106,522
Cumulative Timesteps: 888,247,768

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 888247768...
Checkpoint 888247768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 284,204.41725
Policy Entropy: 3.70237
Value Function Loss: 0.02673

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.14479
Policy Update Magnitude: 0.54780
Value Function Update Magnitude: 0.88553

Collected Steps per Second: 20,670.90845
Overall Steps per Second: 10,346.60999

Timestep Collection Time: 2.41944
Timestep Consumption Time: 2.41422
PPO Batch Consumption Time: 0.28779
Total Iteration Time: 4.83366

Cumulative Model Updates: 106,528
Cumulative Timesteps: 888,297,780

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 133,904.08445
Policy Entropy: 3.71148
Value Function Loss: 0.02610

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.14578
Policy Update Magnitude: 0.57386
Value Function Update Magnitude: 0.82847

Collected Steps per Second: 20,789.80388
Overall Steps per Second: 10,208.10146

Timestep Collection Time: 2.40570
Timestep Consumption Time: 2.49374
PPO Batch Consumption Time: 0.29969
Total Iteration Time: 4.89944

Cumulative Model Updates: 106,534
Cumulative Timesteps: 888,347,794

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 888347794...
Checkpoint 888347794 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 142,069.57621
Policy Entropy: 3.69578
Value Function Loss: 0.02506

Mean KL Divergence: 0.01061
SB3 Clip Fraction: 0.14705
Policy Update Magnitude: 0.55488
Value Function Update Magnitude: 0.79572

Collected Steps per Second: 20,890.74371
Overall Steps per Second: 10,137.48518

Timestep Collection Time: 2.39340
Timestep Consumption Time: 2.53879
PPO Batch Consumption Time: 0.29682
Total Iteration Time: 4.93219

Cumulative Model Updates: 106,540
Cumulative Timesteps: 888,397,794

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 142,069.57621
Policy Entropy: 3.69187
Value Function Loss: 0.01975

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.14444
Policy Update Magnitude: 0.53479
Value Function Update Magnitude: 0.81088

Collected Steps per Second: 21,600.92746
Overall Steps per Second: 10,421.59239

Timestep Collection Time: 2.31573
Timestep Consumption Time: 2.48411
PPO Batch Consumption Time: 0.28831
Total Iteration Time: 4.79984

Cumulative Model Updates: 106,546
Cumulative Timesteps: 888,447,816

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 888447816...
Checkpoint 888447816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 196,195.84009
Policy Entropy: 3.67729
Value Function Loss: 0.01913

Mean KL Divergence: 0.01085
SB3 Clip Fraction: 0.15043
Policy Update Magnitude: 0.50231
Value Function Update Magnitude: 0.73222

Collected Steps per Second: 21,282.71587
Overall Steps per Second: 10,245.67994

Timestep Collection Time: 2.34942
Timestep Consumption Time: 2.53088
PPO Batch Consumption Time: 0.29753
Total Iteration Time: 4.88030

Cumulative Model Updates: 106,552
Cumulative Timesteps: 888,497,818

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 196,195.84009
Policy Entropy: 3.68497
Value Function Loss: 0.01981

Mean KL Divergence: 0.01080
SB3 Clip Fraction: 0.15406
Policy Update Magnitude: 0.45405
Value Function Update Magnitude: 0.61575

Collected Steps per Second: 21,616.35852
Overall Steps per Second: 10,370.99974

Timestep Collection Time: 2.31371
Timestep Consumption Time: 2.50878
PPO Batch Consumption Time: 0.28796
Total Iteration Time: 4.82249

Cumulative Model Updates: 106,558
Cumulative Timesteps: 888,547,832

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 888547832...
Checkpoint 888547832 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 196,195.84009
Policy Entropy: 3.68573
Value Function Loss: 0.02680

Mean KL Divergence: 0.01050
SB3 Clip Fraction: 0.14928
Policy Update Magnitude: 0.46410
Value Function Update Magnitude: 0.49144

Collected Steps per Second: 21,479.14139
Overall Steps per Second: 10,307.15809

Timestep Collection Time: 2.32858
Timestep Consumption Time: 2.52397
PPO Batch Consumption Time: 0.29178
Total Iteration Time: 4.85255

Cumulative Model Updates: 106,564
Cumulative Timesteps: 888,597,848

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 148,089.14302
Policy Entropy: 3.68578
Value Function Loss: 0.02879

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.14296
Policy Update Magnitude: 0.53286
Value Function Update Magnitude: 0.59880

Collected Steps per Second: 21,723.94655
Overall Steps per Second: 10,389.11468

Timestep Collection Time: 2.30336
Timestep Consumption Time: 2.51303
PPO Batch Consumption Time: 0.28832
Total Iteration Time: 4.81639

Cumulative Model Updates: 106,570
Cumulative Timesteps: 888,647,886

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 888647886...
Checkpoint 888647886 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 633,849.94398
Policy Entropy: 3.68295
Value Function Loss: 0.03165

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.14449
Policy Update Magnitude: 0.58612
Value Function Update Magnitude: 0.75099

Collected Steps per Second: 21,182.65370
Overall Steps per Second: 10,296.96478

Timestep Collection Time: 2.36146
Timestep Consumption Time: 2.49648
PPO Batch Consumption Time: 0.28690
Total Iteration Time: 4.85794

Cumulative Model Updates: 106,576
Cumulative Timesteps: 888,697,908

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92,682.13423
Policy Entropy: 3.68651
Value Function Loss: 0.03191

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.14221
Policy Update Magnitude: 0.62817
Value Function Update Magnitude: 0.72961

Collected Steps per Second: 21,659.80702
Overall Steps per Second: 10,351.04336

Timestep Collection Time: 2.30879
Timestep Consumption Time: 2.52241
PPO Batch Consumption Time: 0.28922
Total Iteration Time: 4.83120

Cumulative Model Updates: 106,582
Cumulative Timesteps: 888,747,916

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 888747916...
Checkpoint 888747916 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 307,628.40227
Policy Entropy: 3.71033
Value Function Loss: 0.03361

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.14078
Policy Update Magnitude: 0.62028
Value Function Update Magnitude: 0.69455

Collected Steps per Second: 21,317.61408
Overall Steps per Second: 10,125.15724

Timestep Collection Time: 2.34576
Timestep Consumption Time: 2.59303
PPO Batch Consumption Time: 0.30544
Total Iteration Time: 4.93879

Cumulative Model Updates: 106,588
Cumulative Timesteps: 888,797,922

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 107,266.06115
Policy Entropy: 3.70966
Value Function Loss: 0.03162

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.13845
Policy Update Magnitude: 0.63815
Value Function Update Magnitude: 0.63064

Collected Steps per Second: 21,873.78616
Overall Steps per Second: 10,357.16769

Timestep Collection Time: 2.28794
Timestep Consumption Time: 2.54407
PPO Batch Consumption Time: 0.29679
Total Iteration Time: 4.83202

Cumulative Model Updates: 106,594
Cumulative Timesteps: 888,847,968

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 888847968...
Checkpoint 888847968 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 107,266.06115
Policy Entropy: 3.70439
Value Function Loss: 0.02803

Mean KL Divergence: 0.01101
SB3 Clip Fraction: 0.15271
Policy Update Magnitude: 0.60368
Value Function Update Magnitude: 0.63351

Collected Steps per Second: 21,617.97125
Overall Steps per Second: 10,377.86710

Timestep Collection Time: 2.31298
Timestep Consumption Time: 2.50516
PPO Batch Consumption Time: 0.28779
Total Iteration Time: 4.81814

Cumulative Model Updates: 106,600
Cumulative Timesteps: 888,897,970

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 107,266.06115
Policy Entropy: 3.68585
Value Function Loss: 0.02509

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.14795
Policy Update Magnitude: 0.52869
Value Function Update Magnitude: 0.55621

Collected Steps per Second: 20,882.81990
Overall Steps per Second: 10,273.92879

Timestep Collection Time: 2.39556
Timestep Consumption Time: 2.47366
PPO Batch Consumption Time: 0.29595
Total Iteration Time: 4.86922

Cumulative Model Updates: 106,606
Cumulative Timesteps: 888,947,996

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 888947996...
Checkpoint 888947996 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 153,285.97611
Policy Entropy: 3.69176
Value Function Loss: 0.02292

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.14639
Policy Update Magnitude: 0.45589
Value Function Update Magnitude: 0.42240

Collected Steps per Second: 20,668.08169
Overall Steps per Second: 10,245.49623

Timestep Collection Time: 2.41919
Timestep Consumption Time: 2.46100
PPO Batch Consumption Time: 0.29527
Total Iteration Time: 4.88019

Cumulative Model Updates: 106,612
Cumulative Timesteps: 888,997,996

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 153,285.97611
Policy Entropy: 3.68418
Value Function Loss: 0.02332

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.14348
Policy Update Magnitude: 0.43467
Value Function Update Magnitude: 0.42987

Collected Steps per Second: 21,102.65552
Overall Steps per Second: 10,272.21830

Timestep Collection Time: 2.37032
Timestep Consumption Time: 2.49913
PPO Batch Consumption Time: 0.30066
Total Iteration Time: 4.86944

Cumulative Model Updates: 106,618
Cumulative Timesteps: 889,048,016

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 889048016...
Checkpoint 889048016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 67,825.43043
Policy Entropy: 3.70924
Value Function Loss: 0.02307

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.13820
Policy Update Magnitude: 0.46473
Value Function Update Magnitude: 0.48519

Collected Steps per Second: 20,799.79832
Overall Steps per Second: 10,211.34708

Timestep Collection Time: 2.40464
Timestep Consumption Time: 2.49344
PPO Batch Consumption Time: 0.29064
Total Iteration Time: 4.89808

Cumulative Model Updates: 106,624
Cumulative Timesteps: 889,098,032

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,208.34540
Policy Entropy: 3.71833
Value Function Loss: 0.02206

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.14637
Policy Update Magnitude: 0.46638
Value Function Update Magnitude: 0.54043

Collected Steps per Second: 21,424.48093
Overall Steps per Second: 10,346.94161

Timestep Collection Time: 2.33555
Timestep Consumption Time: 2.50047
PPO Batch Consumption Time: 0.28878
Total Iteration Time: 4.83602

Cumulative Model Updates: 106,630
Cumulative Timesteps: 889,148,070

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 889148070...
Checkpoint 889148070 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,777.13463
Policy Entropy: 3.73084
Value Function Loss: 0.02310

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.13659
Policy Update Magnitude: 0.47137
Value Function Update Magnitude: 0.55242

Collected Steps per Second: 21,431.91173
Overall Steps per Second: 10,312.47581

Timestep Collection Time: 2.33362
Timestep Consumption Time: 2.51623
PPO Batch Consumption Time: 0.29638
Total Iteration Time: 4.84985

Cumulative Model Updates: 106,636
Cumulative Timesteps: 889,198,084

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,777.13463
Policy Entropy: 3.70952
Value Function Loss: 0.02219

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.13933
Policy Update Magnitude: 0.47188
Value Function Update Magnitude: 0.66522

Collected Steps per Second: 21,564.62119
Overall Steps per Second: 10,352.01614

Timestep Collection Time: 2.32010
Timestep Consumption Time: 2.51297
PPO Batch Consumption Time: 0.28826
Total Iteration Time: 4.83307

Cumulative Model Updates: 106,642
Cumulative Timesteps: 889,248,116

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 889248116...
Checkpoint 889248116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 222,893.63824
Policy Entropy: 3.70948
Value Function Loss: 0.02478

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.14812
Policy Update Magnitude: 0.50601
Value Function Update Magnitude: 0.80592

Collected Steps per Second: 21,142.19072
Overall Steps per Second: 10,248.21477

Timestep Collection Time: 2.36522
Timestep Consumption Time: 2.51426
PPO Batch Consumption Time: 0.28820
Total Iteration Time: 4.87948

Cumulative Model Updates: 106,648
Cumulative Timesteps: 889,298,122

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 150,714.56474
Policy Entropy: 3.71637
Value Function Loss: 0.02844

Mean KL Divergence: 0.01057
SB3 Clip Fraction: 0.14825
Policy Update Magnitude: 0.55961
Value Function Update Magnitude: 0.82075

Collected Steps per Second: 21,713.21607
Overall Steps per Second: 10,249.41542

Timestep Collection Time: 2.30357
Timestep Consumption Time: 2.57651
PPO Batch Consumption Time: 0.29707
Total Iteration Time: 4.88008

Cumulative Model Updates: 106,654
Cumulative Timesteps: 889,348,140

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 889348140...
Checkpoint 889348140 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,035.39641
Policy Entropy: 3.75423
Value Function Loss: 0.02651

Mean KL Divergence: 0.01111
SB3 Clip Fraction: 0.15469
Policy Update Magnitude: 0.60915
Value Function Update Magnitude: 0.91557

Collected Steps per Second: 20,801.20265
Overall Steps per Second: 9,911.50378

Timestep Collection Time: 2.40496
Timestep Consumption Time: 2.64231
PPO Batch Consumption Time: 0.31021
Total Iteration Time: 5.04727

Cumulative Model Updates: 106,660
Cumulative Timesteps: 889,398,166

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 113,612.20927
Policy Entropy: 3.74369
Value Function Loss: 0.03082

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.14744
Policy Update Magnitude: 0.58295
Value Function Update Magnitude: 0.85037

Collected Steps per Second: 21,729.68218
Overall Steps per Second: 10,156.31776

Timestep Collection Time: 2.30109
Timestep Consumption Time: 2.62215
PPO Batch Consumption Time: 0.30747
Total Iteration Time: 4.92324

Cumulative Model Updates: 106,666
Cumulative Timesteps: 889,448,168

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 889448168...
Checkpoint 889448168 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,819.24697
Policy Entropy: 3.75797
Value Function Loss: 0.02985

Mean KL Divergence: 0.01061
SB3 Clip Fraction: 0.14806
Policy Update Magnitude: 0.53449
Value Function Update Magnitude: 0.69145

Collected Steps per Second: 21,372.36455
Overall Steps per Second: 10,263.08938

Timestep Collection Time: 2.34050
Timestep Consumption Time: 2.53347
PPO Batch Consumption Time: 0.29267
Total Iteration Time: 4.87397

Cumulative Model Updates: 106,672
Cumulative Timesteps: 889,498,190

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 234,075.43904
Policy Entropy: 3.72977
Value Function Loss: 0.02988

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.15113
Policy Update Magnitude: 0.53229
Value Function Update Magnitude: 0.60320

Collected Steps per Second: 21,851.52411
Overall Steps per Second: 10,392.98336

Timestep Collection Time: 2.28881
Timestep Consumption Time: 2.52347
PPO Batch Consumption Time: 0.28865
Total Iteration Time: 4.81229

Cumulative Model Updates: 106,678
Cumulative Timesteps: 889,548,204

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 889548204...
Checkpoint 889548204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 156,062.03551
Policy Entropy: 3.73571
Value Function Loss: 0.02513

Mean KL Divergence: 0.01095
SB3 Clip Fraction: 0.15521
Policy Update Magnitude: 0.50379
Value Function Update Magnitude: 0.77443

Collected Steps per Second: 21,297.25752
Overall Steps per Second: 10,214.37297

Timestep Collection Time: 2.34857
Timestep Consumption Time: 2.54826
PPO Batch Consumption Time: 0.29382
Total Iteration Time: 4.89683

Cumulative Model Updates: 106,684
Cumulative Timesteps: 889,598,222

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 102,403.11654
Policy Entropy: 3.73291
Value Function Loss: 0.02463

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.14748
Policy Update Magnitude: 0.51202
Value Function Update Magnitude: 0.83883

Collected Steps per Second: 21,463.45583
Overall Steps per Second: 10,195.28412

Timestep Collection Time: 2.33047
Timestep Consumption Time: 2.57572
PPO Batch Consumption Time: 0.29821
Total Iteration Time: 4.90619

Cumulative Model Updates: 106,690
Cumulative Timesteps: 889,648,242

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 889648242...
Checkpoint 889648242 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 78,026.66114
Policy Entropy: 3.74096
Value Function Loss: 0.02308

Mean KL Divergence: 0.01069
SB3 Clip Fraction: 0.15007
Policy Update Magnitude: 0.49644
Value Function Update Magnitude: 0.68738

Collected Steps per Second: 21,648.02351
Overall Steps per Second: 10,400.22251

Timestep Collection Time: 2.31097
Timestep Consumption Time: 2.49931
PPO Batch Consumption Time: 0.28733
Total Iteration Time: 4.81028

Cumulative Model Updates: 106,696
Cumulative Timesteps: 889,698,270

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,252.85219
Policy Entropy: 3.73880
Value Function Loss: 0.02563

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.14337
Policy Update Magnitude: 0.48133
Value Function Update Magnitude: 0.60421

Collected Steps per Second: 21,812.12877
Overall Steps per Second: 10,299.37600

Timestep Collection Time: 2.29258
Timestep Consumption Time: 2.56267
PPO Batch Consumption Time: 0.29663
Total Iteration Time: 4.85525

Cumulative Model Updates: 106,702
Cumulative Timesteps: 889,748,276

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 889748276...
Checkpoint 889748276 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 176,287.85687
Policy Entropy: 3.72955
Value Function Loss: 0.02782

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.13763
Policy Update Magnitude: 0.53058
Value Function Update Magnitude: 0.65830

Collected Steps per Second: 21,411.28943
Overall Steps per Second: 10,224.61474

Timestep Collection Time: 2.33662
Timestep Consumption Time: 2.55648
PPO Batch Consumption Time: 0.29600
Total Iteration Time: 4.89309

Cumulative Model Updates: 106,708
Cumulative Timesteps: 889,798,306

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,378.03982
Policy Entropy: 3.72973
Value Function Loss: 0.02875

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.13885
Policy Update Magnitude: 0.53235
Value Function Update Magnitude: 0.68038

Collected Steps per Second: 21,633.24418
Overall Steps per Second: 10,279.88069

Timestep Collection Time: 2.31163
Timestep Consumption Time: 2.55302
PPO Batch Consumption Time: 0.29587
Total Iteration Time: 4.86465

Cumulative Model Updates: 106,714
Cumulative Timesteps: 889,848,314

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 889848314...
Checkpoint 889848314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,403.69603
Policy Entropy: 3.73705
Value Function Loss: 0.02580

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.13206
Policy Update Magnitude: 0.54144
Value Function Update Magnitude: 0.62656

Collected Steps per Second: 21,279.33347
Overall Steps per Second: 10,207.74952

Timestep Collection Time: 2.35092
Timestep Consumption Time: 2.54987
PPO Batch Consumption Time: 0.29612
Total Iteration Time: 4.90079

Cumulative Model Updates: 106,720
Cumulative Timesteps: 889,898,340

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,403.69603
Policy Entropy: 3.72002
Value Function Loss: 0.02139

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.14285
Policy Update Magnitude: 0.51650
Value Function Update Magnitude: 0.55624

Collected Steps per Second: 21,589.54131
Overall Steps per Second: 10,324.05104

Timestep Collection Time: 2.31621
Timestep Consumption Time: 2.52743
PPO Batch Consumption Time: 0.28871
Total Iteration Time: 4.84364

Cumulative Model Updates: 106,726
Cumulative Timesteps: 889,948,346

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 889948346...
Checkpoint 889948346 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,403.69603
Policy Entropy: 3.71515
Value Function Loss: 0.01868

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.13734
Policy Update Magnitude: 0.46829
Value Function Update Magnitude: 0.50812

Collected Steps per Second: 21,709.77456
Overall Steps per Second: 10,311.63283

Timestep Collection Time: 2.30329
Timestep Consumption Time: 2.54599
PPO Batch Consumption Time: 0.29224
Total Iteration Time: 4.84928

Cumulative Model Updates: 106,732
Cumulative Timesteps: 889,998,350

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,403.69603
Policy Entropy: 3.69599
Value Function Loss: 0.01839

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.14518
Policy Update Magnitude: 0.45395
Value Function Update Magnitude: 0.52453

Collected Steps per Second: 21,588.25002
Overall Steps per Second: 10,202.90090

Timestep Collection Time: 2.31626
Timestep Consumption Time: 2.58470
PPO Batch Consumption Time: 0.30123
Total Iteration Time: 4.90096

Cumulative Model Updates: 106,738
Cumulative Timesteps: 890,048,354

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 890048354...
Checkpoint 890048354 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,403.69603
Policy Entropy: 3.70477
Value Function Loss: 0.01840

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.14752
Policy Update Magnitude: 0.43726
Value Function Update Magnitude: 0.50963

Collected Steps per Second: 20,845.03247
Overall Steps per Second: 10,378.62536

Timestep Collection Time: 2.39904
Timestep Consumption Time: 2.41933
PPO Batch Consumption Time: 0.28860
Total Iteration Time: 4.81836

Cumulative Model Updates: 106,744
Cumulative Timesteps: 890,098,362

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,403.69603
Policy Entropy: 3.69514
Value Function Loss: 0.01880

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.14374
Policy Update Magnitude: 0.40920
Value Function Update Magnitude: 0.47796

Collected Steps per Second: 21,280.65006
Overall Steps per Second: 10,457.42978

Timestep Collection Time: 2.35106
Timestep Consumption Time: 2.43329
PPO Batch Consumption Time: 0.28813
Total Iteration Time: 4.78435

Cumulative Model Updates: 106,750
Cumulative Timesteps: 890,148,394

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 890148394...
Checkpoint 890148394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 132,510.92559
Policy Entropy: 3.70157
Value Function Loss: 0.01925

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.14576
Policy Update Magnitude: 0.39752
Value Function Update Magnitude: 0.57137

Collected Steps per Second: 20,848.09681
Overall Steps per Second: 10,221.12760

Timestep Collection Time: 2.39964
Timestep Consumption Time: 2.49492
PPO Batch Consumption Time: 0.28832
Total Iteration Time: 4.89457

Cumulative Model Updates: 106,756
Cumulative Timesteps: 890,198,422

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46,213.33686
Policy Entropy: 3.69341
Value Function Loss: 0.02262

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.14046
Policy Update Magnitude: 0.43412
Value Function Update Magnitude: 0.55796

Collected Steps per Second: 21,324.74942
Overall Steps per Second: 10,237.99332

Timestep Collection Time: 2.34497
Timestep Consumption Time: 2.53938
PPO Batch Consumption Time: 0.29904
Total Iteration Time: 4.88436

Cumulative Model Updates: 106,762
Cumulative Timesteps: 890,248,428

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 890248428...
Checkpoint 890248428 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46,213.33686
Policy Entropy: 3.70043
Value Function Loss: 0.02211

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.14430
Policy Update Magnitude: 0.45457
Value Function Update Magnitude: 0.53927

Collected Steps per Second: 21,670.51613
Overall Steps per Second: 10,448.49329

Timestep Collection Time: 2.30811
Timestep Consumption Time: 2.47899
PPO Batch Consumption Time: 0.28815
Total Iteration Time: 4.78710

Cumulative Model Updates: 106,768
Cumulative Timesteps: 890,298,446

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46,213.33686
Policy Entropy: 3.70075
Value Function Loss: 0.02130

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.14614
Policy Update Magnitude: 0.44157
Value Function Update Magnitude: 0.54267

Collected Steps per Second: 21,602.05035
Overall Steps per Second: 10,267.93610

Timestep Collection Time: 2.31691
Timestep Consumption Time: 2.55749
PPO Batch Consumption Time: 0.29675
Total Iteration Time: 4.87440

Cumulative Model Updates: 106,774
Cumulative Timesteps: 890,348,496

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 890348496...
Checkpoint 890348496 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46,213.33686
Policy Entropy: 3.71560
Value Function Loss: 0.01891

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.15367
Policy Update Magnitude: 0.41918
Value Function Update Magnitude: 0.50925

Collected Steps per Second: 21,851.04131
Overall Steps per Second: 10,419.32274

Timestep Collection Time: 2.28895
Timestep Consumption Time: 2.51136
PPO Batch Consumption Time: 0.28822
Total Iteration Time: 4.80031

Cumulative Model Updates: 106,780
Cumulative Timesteps: 890,398,512

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 553,922.94251
Policy Entropy: 3.71414
Value Function Loss: 0.02165

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.14060
Policy Update Magnitude: 0.43459
Value Function Update Magnitude: 0.49334

Collected Steps per Second: 21,480.66487
Overall Steps per Second: 10,244.77308

Timestep Collection Time: 2.32777
Timestep Consumption Time: 2.55296
PPO Batch Consumption Time: 0.29696
Total Iteration Time: 4.88073

Cumulative Model Updates: 106,786
Cumulative Timesteps: 890,448,514

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 890448514...
Checkpoint 890448514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 380,922.22882
Policy Entropy: 3.72413
Value Function Loss: 0.02261

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.14720
Policy Update Magnitude: 0.47526
Value Function Update Magnitude: 0.53730

Collected Steps per Second: 21,653.29610
Overall Steps per Second: 10,371.03130

Timestep Collection Time: 2.30930
Timestep Consumption Time: 2.51221
PPO Batch Consumption Time: 0.28811
Total Iteration Time: 4.82151

Cumulative Model Updates: 106,792
Cumulative Timesteps: 890,498,518

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 139,979.50347
Policy Entropy: 3.70203
Value Function Loss: 0.02527

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.14584
Policy Update Magnitude: 0.51221
Value Function Update Magnitude: 0.63000

Collected Steps per Second: 21,398.68772
Overall Steps per Second: 10,173.19337

Timestep Collection Time: 2.33809
Timestep Consumption Time: 2.57994
PPO Batch Consumption Time: 0.30078
Total Iteration Time: 4.91802

Cumulative Model Updates: 106,798
Cumulative Timesteps: 890,548,550

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 890548550...
Checkpoint 890548550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 139,979.50347
Policy Entropy: 3.70383
Value Function Loss: 0.02342

Mean KL Divergence: 0.01047
SB3 Clip Fraction: 0.15070
Policy Update Magnitude: 0.52380
Value Function Update Magnitude: 0.62710

Collected Steps per Second: 21,477.92704
Overall Steps per Second: 10,202.35278

Timestep Collection Time: 2.32844
Timestep Consumption Time: 2.57337
PPO Batch Consumption Time: 0.30113
Total Iteration Time: 4.90181

Cumulative Model Updates: 106,804
Cumulative Timesteps: 890,598,560

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 305,445.27562
Policy Entropy: 3.70776
Value Function Loss: 0.02501

Mean KL Divergence: 0.01091
SB3 Clip Fraction: 0.15304
Policy Update Magnitude: 0.49002
Value Function Update Magnitude: 0.56309

Collected Steps per Second: 21,791.69552
Overall Steps per Second: 10,415.82609

Timestep Collection Time: 2.29583
Timestep Consumption Time: 2.50744
PPO Batch Consumption Time: 0.28737
Total Iteration Time: 4.80327

Cumulative Model Updates: 106,810
Cumulative Timesteps: 890,648,590

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 890648590...
Checkpoint 890648590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55,339.92493
Policy Entropy: 3.72949
Value Function Loss: 0.02553

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.14247
Policy Update Magnitude: 0.48544
Value Function Update Magnitude: 0.54558

Collected Steps per Second: 21,321.00551
Overall Steps per Second: 10,233.73717

Timestep Collection Time: 2.34604
Timestep Consumption Time: 2.54171
PPO Batch Consumption Time: 0.28836
Total Iteration Time: 4.88775

Cumulative Model Updates: 106,816
Cumulative Timesteps: 890,698,610

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,752.19922
Policy Entropy: 3.73005
Value Function Loss: 0.02702

Mean KL Divergence: 0.01069
SB3 Clip Fraction: 0.14704
Policy Update Magnitude: 0.54490
Value Function Update Magnitude: 0.71053

Collected Steps per Second: 20,981.83970
Overall Steps per Second: 10,133.44674

Timestep Collection Time: 2.38416
Timestep Consumption Time: 2.55237
PPO Batch Consumption Time: 0.29857
Total Iteration Time: 4.93652

Cumulative Model Updates: 106,822
Cumulative Timesteps: 890,748,634

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 890748634...
Checkpoint 890748634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,529.48706
Policy Entropy: 3.71815
Value Function Loss: 0.02798

Mean KL Divergence: 0.01093
SB3 Clip Fraction: 0.14697
Policy Update Magnitude: 0.58181
Value Function Update Magnitude: 0.75018

Collected Steps per Second: 21,649.52775
Overall Steps per Second: 10,385.79273

Timestep Collection Time: 2.30952
Timestep Consumption Time: 2.50475
PPO Batch Consumption Time: 0.28774
Total Iteration Time: 4.81427

Cumulative Model Updates: 106,828
Cumulative Timesteps: 890,798,634

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 140,174.48901
Policy Entropy: 3.69225
Value Function Loss: 0.03098

Mean KL Divergence: 0.01191
SB3 Clip Fraction: 0.15759
Policy Update Magnitude: 0.59635
Value Function Update Magnitude: 0.72229

Collected Steps per Second: 21,052.34974
Overall Steps per Second: 10,146.31115

Timestep Collection Time: 2.37541
Timestep Consumption Time: 2.55328
PPO Batch Consumption Time: 0.29504
Total Iteration Time: 4.92869

Cumulative Model Updates: 106,834
Cumulative Timesteps: 890,848,642

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 890848642...
Checkpoint 890848642 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48,877.59085
Policy Entropy: 3.71510
Value Function Loss: 0.03164

Mean KL Divergence: 0.01269
SB3 Clip Fraction: 0.16375
Policy Update Magnitude: 0.59342
Value Function Update Magnitude: 0.66051

Collected Steps per Second: 21,358.42267
Overall Steps per Second: 10,210.90747

Timestep Collection Time: 2.34137
Timestep Consumption Time: 2.55614
PPO Batch Consumption Time: 0.29838
Total Iteration Time: 4.89751

Cumulative Model Updates: 106,840
Cumulative Timesteps: 890,898,650

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 232,416.77183
Policy Entropy: 3.71929
Value Function Loss: 0.03827

Mean KL Divergence: 0.01188
SB3 Clip Fraction: 0.15659
Policy Update Magnitude: 0.60072
Value Function Update Magnitude: 0.49195

Collected Steps per Second: 21,109.79513
Overall Steps per Second: 10,145.49698

Timestep Collection Time: 2.36857
Timestep Consumption Time: 2.55973
PPO Batch Consumption Time: 0.29941
Total Iteration Time: 4.92829

Cumulative Model Updates: 106,846
Cumulative Timesteps: 890,948,650

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 890948650...
Checkpoint 890948650 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,019.10108
Policy Entropy: 3.75458
Value Function Loss: 0.03184

Mean KL Divergence: 0.01464
SB3 Clip Fraction: 0.18541
Policy Update Magnitude: 0.66418
Value Function Update Magnitude: 0.63968

Collected Steps per Second: 21,541.57453
Overall Steps per Second: 10,078.90127

Timestep Collection Time: 2.32109
Timestep Consumption Time: 2.63977
PPO Batch Consumption Time: 0.30194
Total Iteration Time: 4.96086

Cumulative Model Updates: 106,852
Cumulative Timesteps: 890,998,650

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,973.52107
Policy Entropy: 3.76232
Value Function Loss: 0.02937

Mean KL Divergence: 0.01619
SB3 Clip Fraction: 0.20366
Policy Update Magnitude: 0.63447
Value Function Update Magnitude: 0.80865

Collected Steps per Second: 20,769.10380
Overall Steps per Second: 10,359.63162

Timestep Collection Time: 2.40819
Timestep Consumption Time: 2.41978
PPO Batch Consumption Time: 0.28772
Total Iteration Time: 4.82797

Cumulative Model Updates: 106,858
Cumulative Timesteps: 891,048,666

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 891048666...
Checkpoint 891048666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,973.52107
Policy Entropy: 3.78057
Value Function Loss: 0.02293

Mean KL Divergence: 0.01581
SB3 Clip Fraction: 0.20092
Policy Update Magnitude: 0.52421
Value Function Update Magnitude: 0.63253

Collected Steps per Second: 20,608.44325
Overall Steps per Second: 10,277.65770

Timestep Collection Time: 2.42629
Timestep Consumption Time: 2.43883
PPO Batch Consumption Time: 0.28836
Total Iteration Time: 4.86512

Cumulative Model Updates: 106,864
Cumulative Timesteps: 891,098,668

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 569,235.92630
Policy Entropy: 3.72812
Value Function Loss: 0.02226

Mean KL Divergence: 0.01358
SB3 Clip Fraction: 0.17645
Policy Update Magnitude: 0.51772
Value Function Update Magnitude: 0.53995

Collected Steps per Second: 20,754.28561
Overall Steps per Second: 10,225.08806

Timestep Collection Time: 2.41049
Timestep Consumption Time: 2.48218
PPO Batch Consumption Time: 0.29661
Total Iteration Time: 4.89267

Cumulative Model Updates: 106,870
Cumulative Timesteps: 891,148,696

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 891148696...
Checkpoint 891148696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 397,882.11563
Policy Entropy: 3.71651
Value Function Loss: 0.02154

Mean KL Divergence: 0.01093
SB3 Clip Fraction: 0.14879
Policy Update Magnitude: 0.56235
Value Function Update Magnitude: 0.57296

Collected Steps per Second: 21,058.60315
Overall Steps per Second: 10,195.85295

Timestep Collection Time: 2.37547
Timestep Consumption Time: 2.53084
PPO Batch Consumption Time: 0.29640
Total Iteration Time: 4.90631

Cumulative Model Updates: 106,876
Cumulative Timesteps: 891,198,720

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 180,185.46790
Policy Entropy: 3.70142
Value Function Loss: 0.02425

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.14490
Policy Update Magnitude: 0.59620
Value Function Update Magnitude: 0.73008

Collected Steps per Second: 21,563.64816
Overall Steps per Second: 10,326.76404

Timestep Collection Time: 2.31964
Timestep Consumption Time: 2.52408
PPO Batch Consumption Time: 0.29437
Total Iteration Time: 4.84372

Cumulative Model Updates: 106,882
Cumulative Timesteps: 891,248,740

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 891248740...
Checkpoint 891248740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,419.00092
Policy Entropy: 3.73087
Value Function Loss: 0.02420

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.14095
Policy Update Magnitude: 0.57242
Value Function Update Magnitude: 0.83428

Collected Steps per Second: 21,417.59888
Overall Steps per Second: 10,241.26816

Timestep Collection Time: 2.33668
Timestep Consumption Time: 2.55002
PPO Batch Consumption Time: 0.30173
Total Iteration Time: 4.88670

Cumulative Model Updates: 106,888
Cumulative Timesteps: 891,298,786

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 108,467.56115
Policy Entropy: 3.72248
Value Function Loss: 0.02797

Mean KL Divergence: 0.01065
SB3 Clip Fraction: 0.14565
Policy Update Magnitude: 0.55912
Value Function Update Magnitude: 0.67252

Collected Steps per Second: 21,276.28251
Overall Steps per Second: 10,180.08017

Timestep Collection Time: 2.35022
Timestep Consumption Time: 2.56172
PPO Batch Consumption Time: 0.29677
Total Iteration Time: 4.91195

Cumulative Model Updates: 106,894
Cumulative Timesteps: 891,348,790

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 891348790...
Checkpoint 891348790 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,167.22203
Policy Entropy: 3.74709
Value Function Loss: 0.02545

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.13897
Policy Update Magnitude: 0.55267
Value Function Update Magnitude: 0.56976

Collected Steps per Second: 21,383.22999
Overall Steps per Second: 10,311.99762

Timestep Collection Time: 2.33894
Timestep Consumption Time: 2.51114
PPO Batch Consumption Time: 0.28833
Total Iteration Time: 4.85008

Cumulative Model Updates: 106,900
Cumulative Timesteps: 891,398,804

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,788.70437
Policy Entropy: 3.72298
Value Function Loss: 0.02840

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.14559
Policy Update Magnitude: 0.52016
Value Function Update Magnitude: 0.66193

Collected Steps per Second: 21,630.80040
Overall Steps per Second: 10,263.19031

Timestep Collection Time: 2.31180
Timestep Consumption Time: 2.56057
PPO Batch Consumption Time: 0.29833
Total Iteration Time: 4.87236

Cumulative Model Updates: 106,906
Cumulative Timesteps: 891,448,810

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 891448810...
Checkpoint 891448810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,806.16136
Policy Entropy: 3.71562
Value Function Loss: 0.03101

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.13996
Policy Update Magnitude: 0.52958
Value Function Update Magnitude: 0.64821

Collected Steps per Second: 21,545.27376
Overall Steps per Second: 10,293.09387

Timestep Collection Time: 2.32144
Timestep Consumption Time: 2.53774
PPO Batch Consumption Time: 0.29606
Total Iteration Time: 4.85918

Cumulative Model Updates: 106,912
Cumulative Timesteps: 891,498,826

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85,837.87610
Policy Entropy: 3.69536
Value Function Loss: 0.03436

Mean KL Divergence: 0.01065
SB3 Clip Fraction: 0.14782
Policy Update Magnitude: 0.57134
Value Function Update Magnitude: 0.62379

Collected Steps per Second: 22,022.25786
Overall Steps per Second: 10,302.67698

Timestep Collection Time: 2.27079
Timestep Consumption Time: 2.58309
PPO Batch Consumption Time: 0.30142
Total Iteration Time: 4.85388

Cumulative Model Updates: 106,918
Cumulative Timesteps: 891,548,834

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 891548834...
Checkpoint 891548834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,032.07082
Policy Entropy: 3.70670
Value Function Loss: 0.03624

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.13782
Policy Update Magnitude: 0.58733
Value Function Update Magnitude: 0.63247

Collected Steps per Second: 21,523.17674
Overall Steps per Second: 10,197.38407

Timestep Collection Time: 2.32410
Timestep Consumption Time: 2.58128
PPO Batch Consumption Time: 0.30152
Total Iteration Time: 4.90538

Cumulative Model Updates: 106,924
Cumulative Timesteps: 891,598,856

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,225.74589
Policy Entropy: 3.74464
Value Function Loss: 0.03293

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.13358
Policy Update Magnitude: 0.62006
Value Function Update Magnitude: 0.71597

Collected Steps per Second: 21,437.82625
Overall Steps per Second: 10,326.34970

Timestep Collection Time: 2.33261
Timestep Consumption Time: 2.50996
PPO Batch Consumption Time: 0.28778
Total Iteration Time: 4.84256

Cumulative Model Updates: 106,930
Cumulative Timesteps: 891,648,862

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 891648862...
Checkpoint 891648862 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 975.34591
Policy Entropy: 3.72912
Value Function Loss: 0.03321

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.14077
Policy Update Magnitude: 0.62565
Value Function Update Magnitude: 0.71013

Collected Steps per Second: 21,624.64930
Overall Steps per Second: 10,318.86136

Timestep Collection Time: 2.31236
Timestep Consumption Time: 2.53352
PPO Batch Consumption Time: 0.29452
Total Iteration Time: 4.84588

Cumulative Model Updates: 106,936
Cumulative Timesteps: 891,698,866

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,399.90288
Policy Entropy: 3.73882
Value Function Loss: 0.03012

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.14218
Policy Update Magnitude: 0.59732
Value Function Update Magnitude: 0.72603

Collected Steps per Second: 21,686.49514
Overall Steps per Second: 10,356.65876

Timestep Collection Time: 2.30586
Timestep Consumption Time: 2.52253
PPO Batch Consumption Time: 0.28940
Total Iteration Time: 4.82839

Cumulative Model Updates: 106,942
Cumulative Timesteps: 891,748,872

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 891748872...
Checkpoint 891748872 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 202,494.22819
Policy Entropy: 3.70570
Value Function Loss: 0.03119

Mean KL Divergence: 0.01074
SB3 Clip Fraction: 0.14719
Policy Update Magnitude: 0.62607
Value Function Update Magnitude: 0.74290

Collected Steps per Second: 21,207.75549
Overall Steps per Second: 10,303.18783

Timestep Collection Time: 2.35970
Timestep Consumption Time: 2.49743
PPO Batch Consumption Time: 0.28664
Total Iteration Time: 4.85714

Cumulative Model Updates: 106,948
Cumulative Timesteps: 891,798,916

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 108,695.71442
Policy Entropy: 3.71303
Value Function Loss: 0.03446

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.14132
Policy Update Magnitude: 0.64308
Value Function Update Magnitude: 0.78101

Collected Steps per Second: 21,252.92691
Overall Steps per Second: 10,239.90773

Timestep Collection Time: 2.35393
Timestep Consumption Time: 2.53166
PPO Batch Consumption Time: 0.29429
Total Iteration Time: 4.88559

Cumulative Model Updates: 106,954
Cumulative Timesteps: 891,848,944

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 891848944...
Checkpoint 891848944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,695.27790
Policy Entropy: 3.71613
Value Function Loss: 0.03477

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.14144
Policy Update Magnitude: 0.63471
Value Function Update Magnitude: 0.80962

Collected Steps per Second: 21,837.52312
Overall Steps per Second: 10,467.79870

Timestep Collection Time: 2.29000
Timestep Consumption Time: 2.48731
PPO Batch Consumption Time: 0.28689
Total Iteration Time: 4.77732

Cumulative Model Updates: 106,960
Cumulative Timesteps: 891,898,952

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 138,757.28688
Policy Entropy: 3.72511
Value Function Loss: 0.03493

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.14243
Policy Update Magnitude: 0.60569
Value Function Update Magnitude: 0.77027

Collected Steps per Second: 20,795.31582
Overall Steps per Second: 10,342.68602

Timestep Collection Time: 2.40448
Timestep Consumption Time: 2.43004
PPO Batch Consumption Time: 0.28799
Total Iteration Time: 4.83453

Cumulative Model Updates: 106,966
Cumulative Timesteps: 891,948,954

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 891948954...
Checkpoint 891948954 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,062.22180
Policy Entropy: 3.74988
Value Function Loss: 0.03028

Mean KL Divergence: 0.01061
SB3 Clip Fraction: 0.14785
Policy Update Magnitude: 0.55388
Value Function Update Magnitude: 0.69529

Collected Steps per Second: 20,602.37183
Overall Steps per Second: 10,107.20753

Timestep Collection Time: 2.42788
Timestep Consumption Time: 2.52107
PPO Batch Consumption Time: 0.30626
Total Iteration Time: 4.94894

Cumulative Model Updates: 106,972
Cumulative Timesteps: 891,998,974

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,765.49710
Policy Entropy: 3.72751
Value Function Loss: 0.03100

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.14082
Policy Update Magnitude: 0.54346
Value Function Update Magnitude: 0.69042

Collected Steps per Second: 21,232.08408
Overall Steps per Second: 10,362.21144

Timestep Collection Time: 2.35559
Timestep Consumption Time: 2.47099
PPO Batch Consumption Time: 0.29739
Total Iteration Time: 4.82658

Cumulative Model Updates: 106,978
Cumulative Timesteps: 892,048,988

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 892048988...
Checkpoint 892048988 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 300,395.65212
Policy Entropy: 3.73425
Value Function Loss: 0.02808

Mean KL Divergence: 0.01070
SB3 Clip Fraction: 0.14978
Policy Update Magnitude: 0.56103
Value Function Update Magnitude: 0.68278

Collected Steps per Second: 21,071.66209
Overall Steps per Second: 10,168.83769

Timestep Collection Time: 2.37513
Timestep Consumption Time: 2.54657
PPO Batch Consumption Time: 0.29977
Total Iteration Time: 4.92170

Cumulative Model Updates: 106,984
Cumulative Timesteps: 892,099,036

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 300,395.65212
Policy Entropy: 3.69741
Value Function Loss: 0.03039

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.14573
Policy Update Magnitude: 0.55884
Value Function Update Magnitude: 0.68965

Collected Steps per Second: 21,578.25849
Overall Steps per Second: 10,357.07618

Timestep Collection Time: 2.31743
Timestep Consumption Time: 2.51077
PPO Batch Consumption Time: 0.29259
Total Iteration Time: 4.82820

Cumulative Model Updates: 106,990
Cumulative Timesteps: 892,149,042

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 892149042...
Checkpoint 892149042 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 300,395.65212
Policy Entropy: 3.70796
Value Function Loss: 0.02620

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.14757
Policy Update Magnitude: 0.57628
Value Function Update Magnitude: 0.65271

Collected Steps per Second: 19,811.15404
Overall Steps per Second: 9,754.74516

Timestep Collection Time: 2.52656
Timestep Consumption Time: 2.60469
PPO Batch Consumption Time: 0.29869
Total Iteration Time: 5.13125

Cumulative Model Updates: 106,996
Cumulative Timesteps: 892,199,096

Timesteps Collected: 50,054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 300,395.65212
Policy Entropy: 3.67461
Value Function Loss: 0.03063

Mean KL Divergence: 0.01061
SB3 Clip Fraction: 0.15041
Policy Update Magnitude: 0.55595
Value Function Update Magnitude: 0.57640

Collected Steps per Second: 21,495.21928
Overall Steps per Second: 10,250.99775

Timestep Collection Time: 2.32647
Timestep Consumption Time: 2.55188
PPO Batch Consumption Time: 0.29727
Total Iteration Time: 4.87835

Cumulative Model Updates: 107,002
Cumulative Timesteps: 892,249,104

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 892249104...
Checkpoint 892249104 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 345,080.16409
Policy Entropy: 3.70408
Value Function Loss: 0.02878

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.14477
Policy Update Magnitude: 0.53860
Value Function Update Magnitude: 0.50682

Collected Steps per Second: 21,631.07081
Overall Steps per Second: 10,394.71091

Timestep Collection Time: 2.31177
Timestep Consumption Time: 2.49895
PPO Batch Consumption Time: 0.28780
Total Iteration Time: 4.81072

Cumulative Model Updates: 107,008
Cumulative Timesteps: 892,299,110

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 345,080.16409
Policy Entropy: 3.68021
Value Function Loss: 0.03052

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.14589
Policy Update Magnitude: 0.54322
Value Function Update Magnitude: 0.49418

Collected Steps per Second: 21,425.65221
Overall Steps per Second: 10,205.53179

Timestep Collection Time: 2.33477
Timestep Consumption Time: 2.56688
PPO Batch Consumption Time: 0.29940
Total Iteration Time: 4.90166

Cumulative Model Updates: 107,014
Cumulative Timesteps: 892,349,134

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 892349134...
Checkpoint 892349134 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 345,080.16409
Policy Entropy: 3.71242
Value Function Loss: 0.02666

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.13694
Policy Update Magnitude: 0.56974
Value Function Update Magnitude: 0.51119

Collected Steps per Second: 21,058.30069
Overall Steps per Second: 10,105.66893

Timestep Collection Time: 2.37446
Timestep Consumption Time: 2.57346
PPO Batch Consumption Time: 0.29813
Total Iteration Time: 4.94792

Cumulative Model Updates: 107,020
Cumulative Timesteps: 892,399,136

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 414,719.06527
Policy Entropy: 3.68349
Value Function Loss: 0.02983

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.14354
Policy Update Magnitude: 0.56013
Value Function Update Magnitude: 0.53105

Collected Steps per Second: 21,323.92425
Overall Steps per Second: 10,186.73834

Timestep Collection Time: 2.34553
Timestep Consumption Time: 2.56438
PPO Batch Consumption Time: 0.29769
Total Iteration Time: 4.90991

Cumulative Model Updates: 107,026
Cumulative Timesteps: 892,449,152

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 892449152...
Checkpoint 892449152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 198,080.57443
Policy Entropy: 3.69657
Value Function Loss: 0.03058

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.14265
Policy Update Magnitude: 0.58969
Value Function Update Magnitude: 0.56004

Collected Steps per Second: 21,478.55644
Overall Steps per Second: 10,370.70318

Timestep Collection Time: 2.32856
Timestep Consumption Time: 2.49407
PPO Batch Consumption Time: 0.28770
Total Iteration Time: 4.82262

Cumulative Model Updates: 107,032
Cumulative Timesteps: 892,499,166

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 129,983.73905
Policy Entropy: 3.67833
Value Function Loss: 0.03111

Mean KL Divergence: 0.01092
SB3 Clip Fraction: 0.15372
Policy Update Magnitude: 0.58720
Value Function Update Magnitude: 0.64322

Collected Steps per Second: 21,866.65319
Overall Steps per Second: 10,327.06828

Timestep Collection Time: 2.28778
Timestep Consumption Time: 2.55639
PPO Batch Consumption Time: 0.29617
Total Iteration Time: 4.84416

Cumulative Model Updates: 107,038
Cumulative Timesteps: 892,549,192

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 892549192...
Checkpoint 892549192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 129,983.73905
Policy Entropy: 3.68891
Value Function Loss: 0.02633

Mean KL Divergence: 0.01065
SB3 Clip Fraction: 0.14912
Policy Update Magnitude: 0.57003
Value Function Update Magnitude: 0.75189

Collected Steps per Second: 21,438.05749
Overall Steps per Second: 10,152.89201

Timestep Collection Time: 2.33305
Timestep Consumption Time: 2.59323
PPO Batch Consumption Time: 0.30267
Total Iteration Time: 4.92628

Cumulative Model Updates: 107,044
Cumulative Timesteps: 892,599,208

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88,979.58165
Policy Entropy: 3.71940
Value Function Loss: 0.02265

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.15158
Policy Update Magnitude: 0.54753
Value Function Update Magnitude: 0.79442

Collected Steps per Second: 20,885.83863
Overall Steps per Second: 10,298.51573

Timestep Collection Time: 2.39512
Timestep Consumption Time: 2.46228
PPO Batch Consumption Time: 0.28914
Total Iteration Time: 4.85740

Cumulative Model Updates: 107,050
Cumulative Timesteps: 892,649,232

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 892649232...
Checkpoint 892649232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 88,979.58165
Policy Entropy: 3.70957
Value Function Loss: 0.02322

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.14750
Policy Update Magnitude: 0.53125
Value Function Update Magnitude: 0.72578

Collected Steps per Second: 20,353.66507
Overall Steps per Second: 10,266.89873

Timestep Collection Time: 2.45794
Timestep Consumption Time: 2.41481
PPO Batch Consumption Time: 0.28555
Total Iteration Time: 4.87275

Cumulative Model Updates: 107,056
Cumulative Timesteps: 892,699,260

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59,513.32725
Policy Entropy: 3.72553
Value Function Loss: 0.02078

Mean KL Divergence: 0.01081
SB3 Clip Fraction: 0.15158
Policy Update Magnitude: 0.52708
Value Function Update Magnitude: 0.86355

Collected Steps per Second: 21,062.47828
Overall Steps per Second: 10,368.35046

Timestep Collection Time: 2.37493
Timestep Consumption Time: 2.44956
PPO Batch Consumption Time: 0.28836
Total Iteration Time: 4.82449

Cumulative Model Updates: 107,062
Cumulative Timesteps: 892,749,282

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 892749282...
Checkpoint 892749282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,760.50174
Policy Entropy: 3.71244
Value Function Loss: 0.01916

Mean KL Divergence: 0.01060
SB3 Clip Fraction: 0.14927
Policy Update Magnitude: 0.50917
Value Function Update Magnitude: 0.88974

Collected Steps per Second: 20,795.51663
Overall Steps per Second: 10,244.17362

Timestep Collection Time: 2.40590
Timestep Consumption Time: 2.47804
PPO Batch Consumption Time: 0.28776
Total Iteration Time: 4.88395

Cumulative Model Updates: 107,068
Cumulative Timesteps: 892,799,314

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,813.95743
Policy Entropy: 3.72709
Value Function Loss: 0.01976

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.14478
Policy Update Magnitude: 0.49453
Value Function Update Magnitude: 0.73801

Collected Steps per Second: 21,616.96076
Overall Steps per Second: 10,421.97456

Timestep Collection Time: 2.31439
Timestep Consumption Time: 2.48605
PPO Batch Consumption Time: 0.28821
Total Iteration Time: 4.80043

Cumulative Model Updates: 107,074
Cumulative Timesteps: 892,849,344

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 892849344...
Checkpoint 892849344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,813.95743
Policy Entropy: 3.70713
Value Function Loss: 0.02066

Mean KL Divergence: 0.01175
SB3 Clip Fraction: 0.15827
Policy Update Magnitude: 0.52593
Value Function Update Magnitude: 0.60295

Collected Steps per Second: 21,253.52733
Overall Steps per Second: 10,169.79852

Timestep Collection Time: 2.35387
Timestep Consumption Time: 2.56540
PPO Batch Consumption Time: 0.28911
Total Iteration Time: 4.91927

Cumulative Model Updates: 107,080
Cumulative Timesteps: 892,899,372

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,813.95743
Policy Entropy: 3.70399
Value Function Loss: 0.02094

Mean KL Divergence: 0.01241
SB3 Clip Fraction: 0.16545
Policy Update Magnitude: 0.53965
Value Function Update Magnitude: 0.50631

Collected Steps per Second: 20,437.35465
Overall Steps per Second: 9,883.62312

Timestep Collection Time: 2.44670
Timestep Consumption Time: 2.61258
PPO Batch Consumption Time: 0.29649
Total Iteration Time: 5.05928

Cumulative Model Updates: 107,086
Cumulative Timesteps: 892,949,376

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 892949376...
Checkpoint 892949376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,813.95743
Policy Entropy: 3.70201
Value Function Loss: 0.02277

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.13040
Policy Update Magnitude: 0.61835
Value Function Update Magnitude: 0.45903

Collected Steps per Second: 21,058.86960
Overall Steps per Second: 10,100.06740

Timestep Collection Time: 2.37525
Timestep Consumption Time: 2.57720
PPO Batch Consumption Time: 0.30018
Total Iteration Time: 4.95244

Cumulative Model Updates: 107,092
Cumulative Timesteps: 892,999,396

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,813.95743
Policy Entropy: 3.72312
Value Function Loss: 0.02048

Mean KL Divergence: 0.00735
SB3 Clip Fraction: 0.09494
Policy Update Magnitude: 0.74468
Value Function Update Magnitude: 0.44032

Collected Steps per Second: 21,366.84048
Overall Steps per Second: 10,310.52676

Timestep Collection Time: 2.34110
Timestep Consumption Time: 2.51044
PPO Batch Consumption Time: 0.28801
Total Iteration Time: 4.85155

Cumulative Model Updates: 107,098
Cumulative Timesteps: 893,049,418

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 893049418...
Checkpoint 893049418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,813.95743
Policy Entropy: 3.71455
Value Function Loss: 0.02101

Mean KL Divergence: 0.00738
SB3 Clip Fraction: 0.09322
Policy Update Magnitude: 0.75644
Value Function Update Magnitude: 0.44535

Collected Steps per Second: 21,392.19875
Overall Steps per Second: 10,336.88228

Timestep Collection Time: 2.33786
Timestep Consumption Time: 2.50035
PPO Batch Consumption Time: 0.28654
Total Iteration Time: 4.83821

Cumulative Model Updates: 107,104
Cumulative Timesteps: 893,099,430

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,813.95743
Policy Entropy: 3.72886
Value Function Loss: 0.01778

Mean KL Divergence: 0.00631
SB3 Clip Fraction: 0.07694
Policy Update Magnitude: 0.71103
Value Function Update Magnitude: 0.41950

Collected Steps per Second: 21,366.58102
Overall Steps per Second: 10,199.89577

Timestep Collection Time: 2.34048
Timestep Consumption Time: 2.56232
PPO Batch Consumption Time: 0.29655
Total Iteration Time: 4.90280

Cumulative Model Updates: 107,110
Cumulative Timesteps: 893,149,438

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 893149438...
Checkpoint 893149438 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,813.95743
Policy Entropy: 3.72288
Value Function Loss: 0.01676

Mean KL Divergence: 0.00607
SB3 Clip Fraction: 0.07381
Policy Update Magnitude: 0.65435
Value Function Update Magnitude: 0.50310

Collected Steps per Second: 21,398.30094
Overall Steps per Second: 10,338.39178

Timestep Collection Time: 2.33776
Timestep Consumption Time: 2.50091
PPO Batch Consumption Time: 0.28819
Total Iteration Time: 4.83866

Cumulative Model Updates: 107,116
Cumulative Timesteps: 893,199,462

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 186,377.14238
Policy Entropy: 3.74050
Value Function Loss: 0.01815

Mean KL Divergence: 0.00656
SB3 Clip Fraction: 0.08030
Policy Update Magnitude: 0.62706
Value Function Update Magnitude: 0.59411

Collected Steps per Second: 20,914.92246
Overall Steps per Second: 10,134.03132

Timestep Collection Time: 2.39102
Timestep Consumption Time: 2.54364
PPO Batch Consumption Time: 0.30393
Total Iteration Time: 4.93466

Cumulative Model Updates: 107,122
Cumulative Timesteps: 893,249,470

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 893249470...
Checkpoint 893249470 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 64,993.63222
Policy Entropy: 3.74028
Value Function Loss: 0.02065

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.10527
Policy Update Magnitude: 0.62850
Value Function Update Magnitude: 0.70891

Collected Steps per Second: 20,331.44515
Overall Steps per Second: 10,275.08361

Timestep Collection Time: 2.46043
Timestep Consumption Time: 2.40805
PPO Batch Consumption Time: 0.28618
Total Iteration Time: 4.86848

Cumulative Model Updates: 107,128
Cumulative Timesteps: 893,299,494

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 64,993.63222
Policy Entropy: 3.73822
Value Function Loss: 0.02032

Mean KL Divergence: 0.01401
SB3 Clip Fraction: 0.17946
Policy Update Magnitude: 0.61815
Value Function Update Magnitude: 0.75524

Collected Steps per Second: 21,245.09911
Overall Steps per Second: 10,304.41932

Timestep Collection Time: 2.35358
Timestep Consumption Time: 2.49890
PPO Batch Consumption Time: 0.28844
Total Iteration Time: 4.85248

Cumulative Model Updates: 107,134
Cumulative Timesteps: 893,349,496

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 893349496...
Checkpoint 893349496 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 64,993.63222
Policy Entropy: 3.72921
Value Function Loss: 0.02096

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.13338
Policy Update Magnitude: 0.61682
Value Function Update Magnitude: 0.70020

Collected Steps per Second: 21,227.88073
Overall Steps per Second: 10,318.17999

Timestep Collection Time: 2.35586
Timestep Consumption Time: 2.49092
PPO Batch Consumption Time: 0.28925
Total Iteration Time: 4.84679

Cumulative Model Updates: 107,140
Cumulative Timesteps: 893,399,506

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 64,993.63222
Policy Entropy: 3.72040
Value Function Loss: 0.02155

Mean KL Divergence: 0.01173
SB3 Clip Fraction: 0.15690
Policy Update Magnitude: 0.62820
Value Function Update Magnitude: 0.62354

Collected Steps per Second: 21,503.45013
Overall Steps per Second: 10,377.41454

Timestep Collection Time: 2.32558
Timestep Consumption Time: 2.49335
PPO Batch Consumption Time: 0.28822
Total Iteration Time: 4.81893

Cumulative Model Updates: 107,146
Cumulative Timesteps: 893,449,514

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 893449514...
Checkpoint 893449514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 64,993.63222
Policy Entropy: 3.72195
Value Function Loss: 0.02299

Mean KL Divergence: 0.01922
SB3 Clip Fraction: 0.23165
Policy Update Magnitude: 0.54648
Value Function Update Magnitude: 0.53693

Collected Steps per Second: 21,500.68781
Overall Steps per Second: 10,238.83139

Timestep Collection Time: 2.32551
Timestep Consumption Time: 2.55786
PPO Batch Consumption Time: 0.29184
Total Iteration Time: 4.88337

Cumulative Model Updates: 107,152
Cumulative Timesteps: 893,499,514

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 64,993.63222
Policy Entropy: 3.73863
Value Function Loss: 0.02100

Mean KL Divergence: 0.01637
SB3 Clip Fraction: 0.20766
Policy Update Magnitude: 0.52683
Value Function Update Magnitude: 0.50828

Collected Steps per Second: 21,641.30574
Overall Steps per Second: 10,368.82737

Timestep Collection Time: 2.31077
Timestep Consumption Time: 2.51215
PPO Batch Consumption Time: 0.28766
Total Iteration Time: 4.82292

Cumulative Model Updates: 107,158
Cumulative Timesteps: 893,549,522

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 893549522...
Checkpoint 893549522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 64,993.63222
Policy Entropy: 3.70707
Value Function Loss: 0.01960

Mean KL Divergence: 0.01404
SB3 Clip Fraction: 0.17771
Policy Update Magnitude: 0.48555
Value Function Update Magnitude: 0.56474

Collected Steps per Second: 21,451.88855
Overall Steps per Second: 10,348.70099

Timestep Collection Time: 2.33192
Timestep Consumption Time: 2.50193
PPO Batch Consumption Time: 0.28570
Total Iteration Time: 4.83384

Cumulative Model Updates: 107,164
Cumulative Timesteps: 893,599,546

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 64,993.63222
Policy Entropy: 3.68769
Value Function Loss: 0.02074

Mean KL Divergence: 0.01240
SB3 Clip Fraction: 0.16466
Policy Update Magnitude: 0.47242
Value Function Update Magnitude: 0.52652

Collected Steps per Second: 21,584.84602
Overall Steps per Second: 10,337.48407

Timestep Collection Time: 2.31746
Timestep Consumption Time: 2.52144
PPO Batch Consumption Time: 0.28809
Total Iteration Time: 4.83889

Cumulative Model Updates: 107,170
Cumulative Timesteps: 893,649,568

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 893649568...
Checkpoint 893649568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 64,993.63222
Policy Entropy: 3.65567
Value Function Loss: 0.02423

Mean KL Divergence: 0.01166
SB3 Clip Fraction: 0.15493
Policy Update Magnitude: 0.44224
Value Function Update Magnitude: 0.39970

Collected Steps per Second: 21,358.14708
Overall Steps per Second: 10,321.53239

Timestep Collection Time: 2.34206
Timestep Consumption Time: 2.50432
PPO Batch Consumption Time: 0.28916
Total Iteration Time: 4.84637

Cumulative Model Updates: 107,176
Cumulative Timesteps: 893,699,590

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 388,132.59106
Policy Entropy: 3.69352
Value Function Loss: 0.02754

Mean KL Divergence: 0.01128
SB3 Clip Fraction: 0.15227
Policy Update Magnitude: 0.46000
Value Function Update Magnitude: 0.35382

Collected Steps per Second: 21,416.06228
Overall Steps per Second: 10,309.36889

Timestep Collection Time: 2.33498
Timestep Consumption Time: 2.51556
PPO Batch Consumption Time: 0.28879
Total Iteration Time: 4.85054

Cumulative Model Updates: 107,182
Cumulative Timesteps: 893,749,596

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 893749596...
Checkpoint 893749596 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 169,420.91458
Policy Entropy: 3.69810
Value Function Loss: 0.02902

Mean KL Divergence: 0.01142
SB3 Clip Fraction: 0.15607
Policy Update Magnitude: 0.48690
Value Function Update Magnitude: 0.42257

Collected Steps per Second: 21,691.42374
Overall Steps per Second: 10,329.16539

Timestep Collection Time: 2.30626
Timestep Consumption Time: 2.53692
PPO Batch Consumption Time: 0.29210
Total Iteration Time: 4.84318

Cumulative Model Updates: 107,188
Cumulative Timesteps: 893,799,622

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 738,266.32426
Policy Entropy: 3.71696
Value Function Loss: 0.02835

Mean KL Divergence: 0.01084
SB3 Clip Fraction: 0.14916
Policy Update Magnitude: 0.52841
Value Function Update Magnitude: 0.49697

Collected Steps per Second: 21,345.77570
Overall Steps per Second: 10,189.84411

Timestep Collection Time: 2.34313
Timestep Consumption Time: 2.56528
PPO Batch Consumption Time: 0.29764
Total Iteration Time: 4.90842

Cumulative Model Updates: 107,194
Cumulative Timesteps: 893,849,638

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 893849638...
Checkpoint 893849638 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 257,416.56417
Policy Entropy: 3.72014
Value Function Loss: 0.02602

Mean KL Divergence: 0.01095
SB3 Clip Fraction: 0.15129
Policy Update Magnitude: 0.53346
Value Function Update Magnitude: 0.51199

Collected Steps per Second: 21,620.69815
Overall Steps per Second: 10,401.23101

Timestep Collection Time: 2.31325
Timestep Consumption Time: 2.49522
PPO Batch Consumption Time: 0.28764
Total Iteration Time: 4.80847

Cumulative Model Updates: 107,200
Cumulative Timesteps: 893,899,652

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 190,853.05456
Policy Entropy: 3.71025
Value Function Loss: 0.02803

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.13755
Policy Update Magnitude: 0.51475
Value Function Update Magnitude: 0.50743

Collected Steps per Second: 21,104.39110
Overall Steps per Second: 10,108.80634

Timestep Collection Time: 2.36918
Timestep Consumption Time: 2.57701
PPO Batch Consumption Time: 0.29900
Total Iteration Time: 4.94618

Cumulative Model Updates: 107,206
Cumulative Timesteps: 893,949,652

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 893949652...
Checkpoint 893949652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 129,224.10738
Policy Entropy: 3.72362
Value Function Loss: 0.02809

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.14757
Policy Update Magnitude: 0.51184
Value Function Update Magnitude: 0.60588

Collected Steps per Second: 21,527.77658
Overall Steps per Second: 10,215.97235

Timestep Collection Time: 2.32332
Timestep Consumption Time: 2.57254
PPO Batch Consumption Time: 0.30046
Total Iteration Time: 4.89586

Cumulative Model Updates: 107,212
Cumulative Timesteps: 893,999,668

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55,625.85491
Policy Entropy: 3.70310
Value Function Loss: 0.03180

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.14729
Policy Update Magnitude: 0.52038
Value Function Update Magnitude: 0.69433

Collected Steps per Second: 21,360.79288
Overall Steps per Second: 10,327.68616

Timestep Collection Time: 2.34111
Timestep Consumption Time: 2.50102
PPO Batch Consumption Time: 0.28770
Total Iteration Time: 4.84213

Cumulative Model Updates: 107,218
Cumulative Timesteps: 894,049,676

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 894049676...
Checkpoint 894049676 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 98,245.24767
Policy Entropy: 3.73301
Value Function Loss: 0.02691

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.14260
Policy Update Magnitude: 0.53688
Value Function Update Magnitude: 0.63799

Collected Steps per Second: 21,363.20589
Overall Steps per Second: 10,299.05811

Timestep Collection Time: 2.34150
Timestep Consumption Time: 2.51545
PPO Batch Consumption Time: 0.28799
Total Iteration Time: 4.85695

Cumulative Model Updates: 107,224
Cumulative Timesteps: 894,099,698

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85,246.15617
Policy Entropy: 3.71840
Value Function Loss: 0.02533

Mean KL Divergence: 0.01086
SB3 Clip Fraction: 0.15199
Policy Update Magnitude: 0.52179
Value Function Update Magnitude: 0.69750

Collected Steps per Second: 21,397.68523
Overall Steps per Second: 10,203.65410

Timestep Collection Time: 2.33773
Timestep Consumption Time: 2.56463
PPO Batch Consumption Time: 0.29768
Total Iteration Time: 4.90236

Cumulative Model Updates: 107,230
Cumulative Timesteps: 894,149,720

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 894149720...
Checkpoint 894149720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 132,538.54052
Policy Entropy: 3.72663
Value Function Loss: 0.02619

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.14463
Policy Update Magnitude: 0.48836
Value Function Update Magnitude: 0.62505

Collected Steps per Second: 21,469.80660
Overall Steps per Second: 10,245.69346

Timestep Collection Time: 2.32988
Timestep Consumption Time: 2.55237
PPO Batch Consumption Time: 0.29480
Total Iteration Time: 4.88225

Cumulative Model Updates: 107,236
Cumulative Timesteps: 894,199,742

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57,072.33057
Policy Entropy: 3.71360
Value Function Loss: 0.02780

Mean KL Divergence: 0.01121
SB3 Clip Fraction: 0.15810
Policy Update Magnitude: 0.48890
Value Function Update Magnitude: 0.62121

Collected Steps per Second: 21,127.26767
Overall Steps per Second: 10,202.10726

Timestep Collection Time: 2.36917
Timestep Consumption Time: 2.53708
PPO Batch Consumption Time: 0.28875
Total Iteration Time: 4.90624

Cumulative Model Updates: 107,242
Cumulative Timesteps: 894,249,796

Timesteps Collected: 50,054
--------END ITERATION REPORT--------


Saving checkpoint 894249796...
Checkpoint 894249796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,593.24855
Policy Entropy: 3.70968
Value Function Loss: 0.02772

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.15517
Policy Update Magnitude: 0.46733
Value Function Update Magnitude: 0.56242

Collected Steps per Second: 21,341.36655
Overall Steps per Second: 10,317.88759

Timestep Collection Time: 2.34493
Timestep Consumption Time: 2.50529
PPO Batch Consumption Time: 0.28627
Total Iteration Time: 4.85022

Cumulative Model Updates: 107,248
Cumulative Timesteps: 894,299,840

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,604.07108
Policy Entropy: 3.71967
Value Function Loss: 0.02927

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.14775
Policy Update Magnitude: 0.45969
Value Function Update Magnitude: 0.50366

Collected Steps per Second: 21,546.62165
Overall Steps per Second: 10,337.77029

Timestep Collection Time: 2.32138
Timestep Consumption Time: 2.51699
PPO Batch Consumption Time: 0.28859
Total Iteration Time: 4.83837

Cumulative Model Updates: 107,254
Cumulative Timesteps: 894,349,858

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 894349858...
Checkpoint 894349858 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,146.18636
Policy Entropy: 3.72442
Value Function Loss: 0.02989

Mean KL Divergence: 0.01095
SB3 Clip Fraction: 0.15215
Policy Update Magnitude: 0.53023
Value Function Update Magnitude: 0.51610

Collected Steps per Second: 21,379.47165
Overall Steps per Second: 10,338.07198

Timestep Collection Time: 2.34000
Timestep Consumption Time: 2.49920
PPO Batch Consumption Time: 0.28583
Total Iteration Time: 4.83920

Cumulative Model Updates: 107,260
Cumulative Timesteps: 894,399,886

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,146.18636
Policy Entropy: 3.72695
Value Function Loss: 0.02698

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.15061
Policy Update Magnitude: 0.50226
Value Function Update Magnitude: 0.52286

Collected Steps per Second: 21,803.34094
Overall Steps per Second: 10,385.61818

Timestep Collection Time: 2.29469
Timestep Consumption Time: 2.52274
PPO Batch Consumption Time: 0.28908
Total Iteration Time: 4.81743

Cumulative Model Updates: 107,266
Cumulative Timesteps: 894,449,918

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 894449918...
Checkpoint 894449918 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,146.18636
Policy Entropy: 3.72809
Value Function Loss: 0.02066

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.15182
Policy Update Magnitude: 0.41996
Value Function Update Magnitude: 0.48353

Collected Steps per Second: 21,526.98283
Overall Steps per Second: 10,252.16775

Timestep Collection Time: 2.32387
Timestep Consumption Time: 2.55568
PPO Batch Consumption Time: 0.29656
Total Iteration Time: 4.87955

Cumulative Model Updates: 107,272
Cumulative Timesteps: 894,499,944

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,146.18636
Policy Entropy: 3.71823
Value Function Loss: 0.01790

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.15297
Policy Update Magnitude: 0.35042
Value Function Update Magnitude: 0.36448

Collected Steps per Second: 20,944.66739
Overall Steps per Second: 9,915.97943

Timestep Collection Time: 2.38810
Timestep Consumption Time: 2.65608
PPO Batch Consumption Time: 0.31462
Total Iteration Time: 5.04418

Cumulative Model Updates: 107,278
Cumulative Timesteps: 894,549,962

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 894549962...
Checkpoint 894549962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,146.18636
Policy Entropy: 3.72189
Value Function Loss: 0.01605

Mean KL Divergence: 0.01057
SB3 Clip Fraction: 0.15220
Policy Update Magnitude: 0.31754
Value Function Update Magnitude: 0.29840

Collected Steps per Second: 21,863.71542
Overall Steps per Second: 10,319.30276

Timestep Collection Time: 2.28772
Timestep Consumption Time: 2.55932
PPO Batch Consumption Time: 0.29529
Total Iteration Time: 4.84703

Cumulative Model Updates: 107,284
Cumulative Timesteps: 894,599,980

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,146.18636
Policy Entropy: 3.71877
Value Function Loss: 0.01772

Mean KL Divergence: 0.01082
SB3 Clip Fraction: 0.15593
Policy Update Magnitude: 0.32397
Value Function Update Magnitude: 0.29394

Collected Steps per Second: 21,402.39309
Overall Steps per Second: 10,091.65742

Timestep Collection Time: 2.33806
Timestep Consumption Time: 2.62049
PPO Batch Consumption Time: 0.30095
Total Iteration Time: 4.95855

Cumulative Model Updates: 107,290
Cumulative Timesteps: 894,650,020

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 894650020...
Checkpoint 894650020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,146.18636
Policy Entropy: 3.69840
Value Function Loss: 0.02247

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.14313
Policy Update Magnitude: 0.38028
Value Function Update Magnitude: 0.38528

Collected Steps per Second: 21,386.06392
Overall Steps per Second: 10,182.80857

Timestep Collection Time: 2.34031
Timestep Consumption Time: 2.57484
PPO Batch Consumption Time: 0.30157
Total Iteration Time: 4.91515

Cumulative Model Updates: 107,296
Cumulative Timesteps: 894,700,070

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,146.18636
Policy Entropy: 3.68904
Value Function Loss: 0.03049

Mean KL Divergence: 0.01102
SB3 Clip Fraction: 0.15676
Policy Update Magnitude: 0.46455
Value Function Update Magnitude: 0.40416

Collected Steps per Second: 21,170.93221
Overall Steps per Second: 10,226.34133

Timestep Collection Time: 2.36230
Timestep Consumption Time: 2.52821
PPO Batch Consumption Time: 0.29433
Total Iteration Time: 4.89051

Cumulative Model Updates: 107,302
Cumulative Timesteps: 894,750,082

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 894750082...
Checkpoint 894750082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 51,738.41948
Policy Entropy: 3.68533
Value Function Loss: 0.02908

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.14515
Policy Update Magnitude: 0.52329
Value Function Update Magnitude: 0.46596

Collected Steps per Second: 21,337.48778
Overall Steps per Second: 10,324.53996

Timestep Collection Time: 2.34339
Timestep Consumption Time: 2.49964
PPO Batch Consumption Time: 0.28762
Total Iteration Time: 4.84302

Cumulative Model Updates: 107,308
Cumulative Timesteps: 894,800,084

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 73,740.06636
Policy Entropy: 3.69287
Value Function Loss: 0.03085

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.14340
Policy Update Magnitude: 0.55225
Value Function Update Magnitude: 0.67399

Collected Steps per Second: 20,613.70119
Overall Steps per Second: 10,136.51778

Timestep Collection Time: 2.42683
Timestep Consumption Time: 2.50839
PPO Batch Consumption Time: 0.29968
Total Iteration Time: 4.93523

Cumulative Model Updates: 107,314
Cumulative Timesteps: 894,850,110

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 894850110...
Checkpoint 894850110 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 340,292.06436
Policy Entropy: 3.69251
Value Function Loss: 0.03082

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.14800
Policy Update Magnitude: 0.57269
Value Function Update Magnitude: 0.72181

Collected Steps per Second: 20,819.02111
Overall Steps per Second: 10,202.46609

Timestep Collection Time: 2.40194
Timestep Consumption Time: 2.49943
PPO Batch Consumption Time: 0.29972
Total Iteration Time: 4.90136

Cumulative Model Updates: 107,320
Cumulative Timesteps: 894,900,116

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 118,663.23197
Policy Entropy: 3.69830
Value Function Loss: 0.03343

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.14172
Policy Update Magnitude: 0.61522
Value Function Update Magnitude: 0.63907

Collected Steps per Second: 20,993.39432
Overall Steps per Second: 10,153.19055

Timestep Collection Time: 2.38218
Timestep Consumption Time: 2.54337
PPO Batch Consumption Time: 0.29872
Total Iteration Time: 4.92555

Cumulative Model Updates: 107,326
Cumulative Timesteps: 894,950,126

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 894950126...
Checkpoint 894950126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 118,663.23197
Policy Entropy: 3.70179
Value Function Loss: 0.03083

Mean KL Divergence: 0.01810
SB3 Clip Fraction: 0.22111
Policy Update Magnitude: 0.63758
Value Function Update Magnitude: 0.53881

Collected Steps per Second: 21,352.81856
Overall Steps per Second: 10,390.11594

Timestep Collection Time: 2.34199
Timestep Consumption Time: 2.47105
PPO Batch Consumption Time: 0.28685
Total Iteration Time: 4.81304

Cumulative Model Updates: 107,332
Cumulative Timesteps: 895,000,134

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 118,663.23197
Policy Entropy: 3.73006
Value Function Loss: 0.02449

Mean KL Divergence: 0.01586
SB3 Clip Fraction: 0.20137
Policy Update Magnitude: 0.57323
Value Function Update Magnitude: 0.51064

Collected Steps per Second: 21,988.80780
Overall Steps per Second: 10,496.20733

Timestep Collection Time: 2.27507
Timestep Consumption Time: 2.49104
PPO Batch Consumption Time: 0.28832
Total Iteration Time: 4.76610

Cumulative Model Updates: 107,338
Cumulative Timesteps: 895,050,160

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 895050160...
Checkpoint 895050160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 118,663.23197
Policy Entropy: 3.74994
Value Function Loss: 0.01870

Mean KL Divergence: 0.01417
SB3 Clip Fraction: 0.18358
Policy Update Magnitude: 0.50875
Value Function Update Magnitude: 0.52168

Collected Steps per Second: 21,537.57034
Overall Steps per Second: 10,348.82675

Timestep Collection Time: 2.32255
Timestep Consumption Time: 2.51105
PPO Batch Consumption Time: 0.28602
Total Iteration Time: 4.83359

Cumulative Model Updates: 107,344
Cumulative Timesteps: 895,100,182

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 118,663.23197
Policy Entropy: 3.74939
Value Function Loss: 0.01749

Mean KL Divergence: 0.01416
SB3 Clip Fraction: 0.18673
Policy Update Magnitude: 0.43645
Value Function Update Magnitude: 0.46701

Collected Steps per Second: 21,682.01985
Overall Steps per Second: 10,353.69278

Timestep Collection Time: 2.30624
Timestep Consumption Time: 2.52334
PPO Batch Consumption Time: 0.28900
Total Iteration Time: 4.82958

Cumulative Model Updates: 107,350
Cumulative Timesteps: 895,150,186

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 895150186...
Checkpoint 895150186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 118,663.23197
Policy Entropy: 3.73073
Value Function Loss: 0.01758

Mean KL Divergence: 0.01322
SB3 Clip Fraction: 0.18390
Policy Update Magnitude: 0.42668
Value Function Update Magnitude: 0.46829

Collected Steps per Second: 21,546.84569
Overall Steps per Second: 10,261.97586

Timestep Collection Time: 2.32108
Timestep Consumption Time: 2.55244
PPO Batch Consumption Time: 0.29397
Total Iteration Time: 4.87353

Cumulative Model Updates: 107,356
Cumulative Timesteps: 895,200,198

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 158,568.83732
Policy Entropy: 3.72287
Value Function Loss: 0.01732

Mean KL Divergence: 0.01222
SB3 Clip Fraction: 0.16865
Policy Update Magnitude: 0.42808
Value Function Update Magnitude: 0.52426

Collected Steps per Second: 21,768.97331
Overall Steps per Second: 10,363.54630

Timestep Collection Time: 2.29703
Timestep Consumption Time: 2.52796
PPO Batch Consumption Time: 0.28763
Total Iteration Time: 4.82499

Cumulative Model Updates: 107,362
Cumulative Timesteps: 895,250,202

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 895250202...
Checkpoint 895250202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 158,568.83732
Policy Entropy: 3.71938
Value Function Loss: 0.01806

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.14241
Policy Update Magnitude: 0.42338
Value Function Update Magnitude: 0.53859

Collected Steps per Second: 21,682.23090
Overall Steps per Second: 10,298.59501

Timestep Collection Time: 2.30677
Timestep Consumption Time: 2.54981
PPO Batch Consumption Time: 0.29544
Total Iteration Time: 4.85658

Cumulative Model Updates: 107,368
Cumulative Timesteps: 895,300,218

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 158,568.83732
Policy Entropy: 3.72434
Value Function Loss: 0.01653

Mean KL Divergence: 0.00691
SB3 Clip Fraction: 0.09001
Policy Update Magnitude: 0.46645
Value Function Update Magnitude: 0.49082

Collected Steps per Second: 21,287.79406
Overall Steps per Second: 10,194.43876

Timestep Collection Time: 2.34933
Timestep Consumption Time: 2.55648
PPO Batch Consumption Time: 0.29451
Total Iteration Time: 4.90581

Cumulative Model Updates: 107,374
Cumulative Timesteps: 895,350,230

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 895350230...
Checkpoint 895350230 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 293,077.49022
Policy Entropy: 3.71746
Value Function Loss: 0.01789

Mean KL Divergence: 0.00592
SB3 Clip Fraction: 0.07351
Policy Update Magnitude: 0.52835
Value Function Update Magnitude: 0.41399

Collected Steps per Second: 21,263.64729
Overall Steps per Second: 10,232.23198

Timestep Collection Time: 2.35237
Timestep Consumption Time: 2.53610
PPO Batch Consumption Time: 0.29412
Total Iteration Time: 4.88847

Cumulative Model Updates: 107,380
Cumulative Timesteps: 895,400,250

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 192,286.39968
Policy Entropy: 3.72183
Value Function Loss: 0.01673

Mean KL Divergence: 0.00456
SB3 Clip Fraction: 0.04807
Policy Update Magnitude: 0.59376
Value Function Update Magnitude: 0.47513

Collected Steps per Second: 21,832.33451
Overall Steps per Second: 10,257.41380

Timestep Collection Time: 2.29137
Timestep Consumption Time: 2.58569
PPO Batch Consumption Time: 0.29963
Total Iteration Time: 4.87706

Cumulative Model Updates: 107,386
Cumulative Timesteps: 895,450,276

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 895450276...
Checkpoint 895450276 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 192,286.39968
Policy Entropy: 3.72132
Value Function Loss: 0.01724

Mean KL Divergence: 0.00491
SB3 Clip Fraction: 0.05324
Policy Update Magnitude: 0.60887
Value Function Update Magnitude: 0.49806

Collected Steps per Second: 21,480.67699
Overall Steps per Second: 10,199.51862

Timestep Collection Time: 2.32795
Timestep Consumption Time: 2.57483
PPO Batch Consumption Time: 0.29864
Total Iteration Time: 4.90278

Cumulative Model Updates: 107,392
Cumulative Timesteps: 895,500,282

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 192,286.39968
Policy Entropy: 3.72557
Value Function Loss: 0.01745

Mean KL Divergence: 0.00487
SB3 Clip Fraction: 0.05288
Policy Update Magnitude: 0.58488
Value Function Update Magnitude: 0.45017

Collected Steps per Second: 21,511.79843
Overall Steps per Second: 10,234.17638

Timestep Collection Time: 2.32431
Timestep Consumption Time: 2.56129
PPO Batch Consumption Time: 0.29508
Total Iteration Time: 4.88559

Cumulative Model Updates: 107,398
Cumulative Timesteps: 895,550,282

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 895550282...
Checkpoint 895550282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 645,617.29330
Policy Entropy: 3.73187
Value Function Loss: 0.01824

Mean KL Divergence: 0.00686
SB3 Clip Fraction: 0.08530
Policy Update Magnitude: 0.59744
Value Function Update Magnitude: 0.52207

Collected Steps per Second: 21,547.30663
Overall Steps per Second: 10,358.47298

Timestep Collection Time: 2.32178
Timestep Consumption Time: 2.50789
PPO Batch Consumption Time: 0.28696
Total Iteration Time: 4.82967

Cumulative Model Updates: 107,404
Cumulative Timesteps: 895,600,310

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 392,268.71158
Policy Entropy: 3.75307
Value Function Loss: 0.01804

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.10188
Policy Update Magnitude: 0.62990
Value Function Update Magnitude: 0.61532

Collected Steps per Second: 21,604.35747
Overall Steps per Second: 10,268.01089

Timestep Collection Time: 2.31481
Timestep Consumption Time: 2.55566
PPO Batch Consumption Time: 0.29624
Total Iteration Time: 4.87047

Cumulative Model Updates: 107,410
Cumulative Timesteps: 895,650,320

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 895650320...
Checkpoint 895650320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 392,268.71158
Policy Entropy: 3.75249
Value Function Loss: 0.01725

Mean KL Divergence: 0.00657
SB3 Clip Fraction: 0.08130
Policy Update Magnitude: 0.61229
Value Function Update Magnitude: 0.58906

Collected Steps per Second: 21,831.45566
Overall Steps per Second: 10,431.94577

Timestep Collection Time: 2.29027
Timestep Consumption Time: 2.50270
PPO Batch Consumption Time: 0.28797
Total Iteration Time: 4.79297

Cumulative Model Updates: 107,416
Cumulative Timesteps: 895,700,320

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 392,268.71158
Policy Entropy: 3.75999
Value Function Loss: 0.01744

Mean KL Divergence: 0.00592
SB3 Clip Fraction: 0.06952
Policy Update Magnitude: 0.56636
Value Function Update Magnitude: 0.46240

Collected Steps per Second: 20,856.44029
Overall Steps per Second: 10,388.76723

Timestep Collection Time: 2.39926
Timestep Consumption Time: 2.41748
PPO Batch Consumption Time: 0.28771
Total Iteration Time: 4.81674

Cumulative Model Updates: 107,422
Cumulative Timesteps: 895,750,360

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 895750360...
Checkpoint 895750360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 392,268.71158
Policy Entropy: 3.73717
Value Function Loss: 0.01957

Mean KL Divergence: 0.00736
SB3 Clip Fraction: 0.09566
Policy Update Magnitude: 0.55536
Value Function Update Magnitude: 0.40046

Collected Steps per Second: 20,866.75137
Overall Steps per Second: 10,327.21241

Timestep Collection Time: 2.39635
Timestep Consumption Time: 2.44562
PPO Batch Consumption Time: 0.29206
Total Iteration Time: 4.84196

Cumulative Model Updates: 107,428
Cumulative Timesteps: 895,800,364

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 392,268.71158
Policy Entropy: 3.73682
Value Function Loss: 0.02036

Mean KL Divergence: 0.03102
SB3 Clip Fraction: 0.31219
Policy Update Magnitude: 0.46602
Value Function Update Magnitude: 0.40024

Collected Steps per Second: 21,177.40531
Overall Steps per Second: 10,333.75935

Timestep Collection Time: 2.36195
Timestep Consumption Time: 2.47849
PPO Batch Consumption Time: 0.28744
Total Iteration Time: 4.84045

Cumulative Model Updates: 107,434
Cumulative Timesteps: 895,850,384

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 895850384...
Checkpoint 895850384 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 622,911.62283
Policy Entropy: 3.73235
Value Function Loss: 0.02654

Mean KL Divergence: 0.03732
SB3 Clip Fraction: 0.34833
Policy Update Magnitude: 0.39927
Value Function Update Magnitude: 0.52551

Collected Steps per Second: 21,576.91317
Overall Steps per Second: 10,341.05151

Timestep Collection Time: 2.31859
Timestep Consumption Time: 2.51922
PPO Batch Consumption Time: 0.29536
Total Iteration Time: 4.83781

Cumulative Model Updates: 107,440
Cumulative Timesteps: 895,900,412

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 236,839.82583
Policy Entropy: 3.71038
Value Function Loss: 0.04546

Mean KL Divergence: 0.02957
SB3 Clip Fraction: 0.29371
Policy Update Magnitude: 0.46372
Value Function Update Magnitude: 0.64337

Collected Steps per Second: 21,301.73735
Overall Steps per Second: 10,329.71186

Timestep Collection Time: 2.34798
Timestep Consumption Time: 2.49398
PPO Batch Consumption Time: 0.28925
Total Iteration Time: 4.84195

Cumulative Model Updates: 107,446
Cumulative Timesteps: 895,950,428

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 895950428...
Checkpoint 895950428 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 439,624.72650
Policy Entropy: 3.69785
Value Function Loss: 0.06286

Mean KL Divergence: 0.02352
SB3 Clip Fraction: 0.24390
Policy Update Magnitude: 0.56756
Value Function Update Magnitude: 0.72757

Collected Steps per Second: 20,699.22583
Overall Steps per Second: 10,201.47307

Timestep Collection Time: 2.41565
Timestep Consumption Time: 2.48580
PPO Batch Consumption Time: 0.29243
Total Iteration Time: 4.90145

Cumulative Model Updates: 107,452
Cumulative Timesteps: 896,000,430

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 112,004.50715
Policy Entropy: 3.66804
Value Function Loss: 0.06781

Mean KL Divergence: 0.02016
SB3 Clip Fraction: 0.21539
Policy Update Magnitude: 0.66882
Value Function Update Magnitude: 0.56471

Collected Steps per Second: 21,429.74074
Overall Steps per Second: 10,183.52398

Timestep Collection Time: 2.33349
Timestep Consumption Time: 2.57699
PPO Batch Consumption Time: 0.30150
Total Iteration Time: 4.91048

Cumulative Model Updates: 107,458
Cumulative Timesteps: 896,050,436

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 896050436...
Checkpoint 896050436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 319,870.57170
Policy Entropy: 3.71066
Value Function Loss: 0.06975

Mean KL Divergence: 0.01867
SB3 Clip Fraction: 0.20527
Policy Update Magnitude: 0.71806
Value Function Update Magnitude: 0.51040

Collected Steps per Second: 21,023.18083
Overall Steps per Second: 10,160.02084

Timestep Collection Time: 2.37842
Timestep Consumption Time: 2.54302
PPO Batch Consumption Time: 0.29367
Total Iteration Time: 4.92145

Cumulative Model Updates: 107,464
Cumulative Timesteps: 896,100,438

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97,874.54426
Policy Entropy: 3.72340
Value Function Loss: 0.07125

Mean KL Divergence: 0.01733
SB3 Clip Fraction: 0.20472
Policy Update Magnitude: 0.73772
Value Function Update Magnitude: 0.48545

Collected Steps per Second: 21,465.73883
Overall Steps per Second: 10,365.46543

Timestep Collection Time: 2.33069
Timestep Consumption Time: 2.49591
PPO Batch Consumption Time: 0.28927
Total Iteration Time: 4.82660

Cumulative Model Updates: 107,470
Cumulative Timesteps: 896,150,468

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 896150468...
Checkpoint 896150468 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,933.44228
Policy Entropy: 3.78063
Value Function Loss: 0.07231

Mean KL Divergence: 0.01567
SB3 Clip Fraction: 0.18247
Policy Update Magnitude: 0.76639
Value Function Update Magnitude: 0.48103

Collected Steps per Second: 21,359.86135
Overall Steps per Second: 10,312.76840

Timestep Collection Time: 2.34149
Timestep Consumption Time: 2.50822
PPO Batch Consumption Time: 0.29496
Total Iteration Time: 4.84972

Cumulative Model Updates: 107,476
Cumulative Timesteps: 896,200,482

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 249,826.07738
Policy Entropy: 3.83255
Value Function Loss: 0.05466

Mean KL Divergence: 0.01578
SB3 Clip Fraction: 0.17351
Policy Update Magnitude: 0.87193
Value Function Update Magnitude: 0.66819

Collected Steps per Second: 21,366.72464
Overall Steps per Second: 10,355.36137

Timestep Collection Time: 2.34130
Timestep Consumption Time: 2.48962
PPO Batch Consumption Time: 0.28886
Total Iteration Time: 4.83093

Cumulative Model Updates: 107,482
Cumulative Timesteps: 896,250,508

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 896250508...
Checkpoint 896250508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 111,112.00177
Policy Entropy: 3.88842
Value Function Loss: 0.05155

Mean KL Divergence: 0.01291
SB3 Clip Fraction: 0.15235
Policy Update Magnitude: 1.07866
Value Function Update Magnitude: 0.95701

Collected Steps per Second: 21,106.88277
Overall Steps per Second: 10,327.55449

Timestep Collection Time: 2.37022
Timestep Consumption Time: 2.47391
PPO Batch Consumption Time: 0.28663
Total Iteration Time: 4.84413

Cumulative Model Updates: 107,488
Cumulative Timesteps: 896,300,536

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 250.48078
Policy Entropy: 3.89597
Value Function Loss: 0.04900

Mean KL Divergence: 0.01115
SB3 Clip Fraction: 0.13744
Policy Update Magnitude: 1.19216
Value Function Update Magnitude: 0.95202

Collected Steps per Second: 21,532.67591
Overall Steps per Second: 10,359.98042

Timestep Collection Time: 2.32215
Timestep Consumption Time: 2.50431
PPO Batch Consumption Time: 0.28952
Total Iteration Time: 4.82646

Cumulative Model Updates: 107,494
Cumulative Timesteps: 896,350,538

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 896350538...
Checkpoint 896350538 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 146,222.58230
Policy Entropy: 3.86543
Value Function Loss: 0.05010

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.12043
Policy Update Magnitude: 1.29007
Value Function Update Magnitude: 0.82936

Collected Steps per Second: 21,121.38631
Overall Steps per Second: 10,302.26621

Timestep Collection Time: 2.36784
Timestep Consumption Time: 2.48663
PPO Batch Consumption Time: 0.28746
Total Iteration Time: 4.85447

Cumulative Model Updates: 107,500
Cumulative Timesteps: 896,400,550

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,074.12437
Policy Entropy: 3.79830
Value Function Loss: 0.05303

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.12838
Policy Update Magnitude: 1.20347
Value Function Update Magnitude: 0.72684

Collected Steps per Second: 21,646.08751
Overall Steps per Second: 10,415.29945

Timestep Collection Time: 2.31099
Timestep Consumption Time: 2.49194
PPO Batch Consumption Time: 0.28825
Total Iteration Time: 4.80293

Cumulative Model Updates: 107,506
Cumulative Timesteps: 896,450,574

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 896450574...
Checkpoint 896450574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,346.27479
Policy Entropy: 3.78934
Value Function Loss: 0.05135

Mean KL Divergence: 0.01548
SB3 Clip Fraction: 0.19225
Policy Update Magnitude: 0.97321
Value Function Update Magnitude: 0.67902

Collected Steps per Second: 21,204.13938
Overall Steps per Second: 10,212.14447

Timestep Collection Time: 2.35869
Timestep Consumption Time: 2.53881
PPO Batch Consumption Time: 0.29770
Total Iteration Time: 4.89750

Cumulative Model Updates: 107,512
Cumulative Timesteps: 896,500,588

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,607.33354
Policy Entropy: 3.82469
Value Function Loss: 0.05126

Mean KL Divergence: 0.01156
SB3 Clip Fraction: 0.14977
Policy Update Magnitude: 0.92920
Value Function Update Magnitude: 0.70519

Collected Steps per Second: 21,708.28572
Overall Steps per Second: 10,421.75991

Timestep Collection Time: 2.30354
Timestep Consumption Time: 2.49469
PPO Batch Consumption Time: 0.28928
Total Iteration Time: 4.79823

Cumulative Model Updates: 107,518
Cumulative Timesteps: 896,550,594

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 896550594...
Checkpoint 896550594 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 226.07177
Policy Entropy: 3.85725
Value Function Loss: 0.04626

Mean KL Divergence: 0.01192
SB3 Clip Fraction: 0.15307
Policy Update Magnitude: 0.88314
Value Function Update Magnitude: 0.71614

Collected Steps per Second: 21,161.75505
Overall Steps per Second: 10,238.12241

Timestep Collection Time: 2.36379
Timestep Consumption Time: 2.52206
PPO Batch Consumption Time: 0.29509
Total Iteration Time: 4.88586

Cumulative Model Updates: 107,524
Cumulative Timesteps: 896,600,616

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,721.79769
Policy Entropy: 3.85107
Value Function Loss: 0.04783

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.12016
Policy Update Magnitude: 0.82100
Value Function Update Magnitude: 0.70856

Collected Steps per Second: 21,104.34364
Overall Steps per Second: 10,008.33101

Timestep Collection Time: 2.37013
Timestep Consumption Time: 2.62771
PPO Batch Consumption Time: 0.31467
Total Iteration Time: 4.99784

Cumulative Model Updates: 107,530
Cumulative Timesteps: 896,650,636

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 896650636...
Checkpoint 896650636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 664.14805
Policy Entropy: 3.83725
Value Function Loss: 0.04359

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.13303
Policy Update Magnitude: 0.81463
Value Function Update Magnitude: 0.78799

Collected Steps per Second: 21,207.48681
Overall Steps per Second: 10,262.51216

Timestep Collection Time: 2.35832
Timestep Consumption Time: 2.51515
PPO Batch Consumption Time: 0.29250
Total Iteration Time: 4.87347

Cumulative Model Updates: 107,536
Cumulative Timesteps: 896,700,650

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28.18979
Policy Entropy: 3.81709
Value Function Loss: 0.04134

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.13464
Policy Update Magnitude: 0.79453
Value Function Update Magnitude: 0.74213

Collected Steps per Second: 21,690.35507
Overall Steps per Second: 10,419.22953

Timestep Collection Time: 2.30600
Timestep Consumption Time: 2.49455
PPO Batch Consumption Time: 0.28883
Total Iteration Time: 4.80055

Cumulative Model Updates: 107,542
Cumulative Timesteps: 896,750,668

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 896750668...
Checkpoint 896750668 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2.24439
Policy Entropy: 3.81554
Value Function Loss: 0.03812

Mean KL Divergence: 0.01092
SB3 Clip Fraction: 0.14668
Policy Update Magnitude: 0.64360
Value Function Update Magnitude: 0.54046

Collected Steps per Second: 21,597.31323
Overall Steps per Second: 10,231.68420

Timestep Collection Time: 2.31770
Timestep Consumption Time: 2.57456
PPO Batch Consumption Time: 0.29945
Total Iteration Time: 4.89225

Cumulative Model Updates: 107,548
Cumulative Timesteps: 896,800,724

Timesteps Collected: 50,056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16.17688
Policy Entropy: 3.79951
Value Function Loss: 0.03302

Mean KL Divergence: 0.01067
SB3 Clip Fraction: 0.14754
Policy Update Magnitude: 0.46074
Value Function Update Magnitude: 0.42990

Collected Steps per Second: 21,648.64783
Overall Steps per Second: 10,364.91574

Timestep Collection Time: 2.31183
Timestep Consumption Time: 2.51677
PPO Batch Consumption Time: 0.28836
Total Iteration Time: 4.82860

Cumulative Model Updates: 107,554
Cumulative Timesteps: 896,850,772

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 896850772...
Checkpoint 896850772 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,106.32368
Policy Entropy: 3.77304
Value Function Loss: 0.03332

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.14685
Policy Update Magnitude: 0.37986
Value Function Update Magnitude: 0.35514

Collected Steps per Second: 21,815.90431
Overall Steps per Second: 10,332.88769

Timestep Collection Time: 2.29310
Timestep Consumption Time: 2.54834
PPO Batch Consumption Time: 0.29442
Total Iteration Time: 4.84143

Cumulative Model Updates: 107,560
Cumulative Timesteps: 896,900,798

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,995.56393
Policy Entropy: 3.78669
Value Function Loss: 0.03257

Mean KL Divergence: 0.01078
SB3 Clip Fraction: 0.14380
Policy Update Magnitude: 0.38665
Value Function Update Magnitude: 0.40869

Collected Steps per Second: 21,540.05120
Overall Steps per Second: 10,330.68608

Timestep Collection Time: 2.32154
Timestep Consumption Time: 2.51899
PPO Batch Consumption Time: 0.28798
Total Iteration Time: 4.84053

Cumulative Model Updates: 107,566
Cumulative Timesteps: 896,950,804

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 896950804...
Checkpoint 896950804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,995.56393
Policy Entropy: 3.74933
Value Function Loss: 0.02984

Mean KL Divergence: 0.01154
SB3 Clip Fraction: 0.15606
Policy Update Magnitude: 0.36405
Value Function Update Magnitude: 0.38714

Collected Steps per Second: 21,806.92300
Overall Steps per Second: 10,318.35216

Timestep Collection Time: 2.29322
Timestep Consumption Time: 2.55329
PPO Batch Consumption Time: 0.29663
Total Iteration Time: 4.84651

Cumulative Model Updates: 107,572
Cumulative Timesteps: 897,000,812

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,995.56393
Policy Entropy: 3.74343
Value Function Loss: 0.02631

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.14521
Policy Update Magnitude: 0.34482
Value Function Update Magnitude: 0.40204

Collected Steps per Second: 21,680.11199
Overall Steps per Second: 10,375.04925

Timestep Collection Time: 2.30635
Timestep Consumption Time: 2.51309
PPO Batch Consumption Time: 0.28732
Total Iteration Time: 4.81945

Cumulative Model Updates: 107,578
Cumulative Timesteps: 897,050,814

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 897050814...
Checkpoint 897050814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,995.56393
Policy Entropy: 3.71082
Value Function Loss: 0.02993

Mean KL Divergence: 0.01149
SB3 Clip Fraction: 0.16188
Policy Update Magnitude: 0.34113
Value Function Update Magnitude: 0.33118

Collected Steps per Second: 21,356.10362
Overall Steps per Second: 10,300.83524

Timestep Collection Time: 2.34266
Timestep Consumption Time: 2.51423
PPO Batch Consumption Time: 0.28992
Total Iteration Time: 4.85689

Cumulative Model Updates: 107,584
Cumulative Timesteps: 897,100,844

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,995.56393
Policy Entropy: 3.71386
Value Function Loss: 0.02855

Mean KL Divergence: 0.01065
SB3 Clip Fraction: 0.15062
Policy Update Magnitude: 0.32904
Value Function Update Magnitude: 0.26330

Collected Steps per Second: 21,603.53758
Overall Steps per Second: 10,367.16265

Timestep Collection Time: 2.31675
Timestep Consumption Time: 2.51099
PPO Batch Consumption Time: 0.28776
Total Iteration Time: 4.82774

Cumulative Model Updates: 107,590
Cumulative Timesteps: 897,150,894

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 897150894...
Checkpoint 897150894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,995.56393
Policy Entropy: 3.71351
Value Function Loss: 0.02613

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.15322
Policy Update Magnitude: 0.34438
Value Function Update Magnitude: 0.25675

Collected Steps per Second: 21,384.85025
Overall Steps per Second: 10,287.45459

Timestep Collection Time: 2.33997
Timestep Consumption Time: 2.52420
PPO Batch Consumption Time: 0.29108
Total Iteration Time: 4.86418

Cumulative Model Updates: 107,596
Cumulative Timesteps: 897,200,934

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,995.56393
Policy Entropy: 3.70723
Value Function Loss: 0.02681

Mean KL Divergence: 0.01132
SB3 Clip Fraction: 0.15954
Policy Update Magnitude: 0.32683
Value Function Update Magnitude: 0.24537

Collected Steps per Second: 20,945.34063
Overall Steps per Second: 10,276.70665

Timestep Collection Time: 2.38831
Timestep Consumption Time: 2.47940
PPO Batch Consumption Time: 0.29659
Total Iteration Time: 4.86771

Cumulative Model Updates: 107,602
Cumulative Timesteps: 897,250,958

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 897250958...
Checkpoint 897250958 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,995.56393
Policy Entropy: 3.70763
Value Function Loss: 0.02030

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.15385
Policy Update Magnitude: 0.30123
Value Function Update Magnitude: 0.24596

Collected Steps per Second: 20,968.80385
Overall Steps per Second: 10,213.66997

Timestep Collection Time: 2.38507
Timestep Consumption Time: 2.51151
PPO Batch Consumption Time: 0.29777
Total Iteration Time: 4.89657

Cumulative Model Updates: 107,608
Cumulative Timesteps: 897,300,970

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,995.56393
Policy Entropy: 3.70488
Value Function Loss: 0.01850

Mean KL Divergence: 0.01098
SB3 Clip Fraction: 0.15825
Policy Update Magnitude: 0.27673
Value Function Update Magnitude: 0.31098

Collected Steps per Second: 21,109.01128
Overall Steps per Second: 10,208.50048

Timestep Collection Time: 2.36998
Timestep Consumption Time: 2.53064
PPO Batch Consumption Time: 0.29536
Total Iteration Time: 4.90062

Cumulative Model Updates: 107,614
Cumulative Timesteps: 897,350,998

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 897350998...
Checkpoint 897350998 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,995.56393
Policy Entropy: 3.70020
Value Function Loss: 0.01889

Mean KL Divergence: 0.01057
SB3 Clip Fraction: 0.15321
Policy Update Magnitude: 0.29243
Value Function Update Magnitude: 0.43002

Collected Steps per Second: 21,082.88578
Overall Steps per Second: 10,224.60435

Timestep Collection Time: 2.37197
Timestep Consumption Time: 2.51898
PPO Batch Consumption Time: 0.29488
Total Iteration Time: 4.89095

Cumulative Model Updates: 107,620
Cumulative Timesteps: 897,401,006

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,995.56393
Policy Entropy: 3.69950
Value Function Loss: 0.01975

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.14862
Policy Update Magnitude: 0.34536
Value Function Update Magnitude: 0.51193

Collected Steps per Second: 21,438.77118
Overall Steps per Second: 10,387.06396

Timestep Collection Time: 2.33241
Timestep Consumption Time: 2.48166
PPO Batch Consumption Time: 0.28788
Total Iteration Time: 4.81406

Cumulative Model Updates: 107,626
Cumulative Timesteps: 897,451,010

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 897451010...
Checkpoint 897451010 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,995.56393
Policy Entropy: 3.68585
Value Function Loss: 0.02133

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.15370
Policy Update Magnitude: 0.37009
Value Function Update Magnitude: 0.52030

Collected Steps per Second: 21,574.47617
Overall Steps per Second: 10,279.51249

Timestep Collection Time: 2.31876
Timestep Consumption Time: 2.54781
PPO Batch Consumption Time: 0.29622
Total Iteration Time: 4.86657

Cumulative Model Updates: 107,632
Cumulative Timesteps: 897,501,036

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,719.46903
Policy Entropy: 3.69346
Value Function Loss: 0.02282

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.15034
Policy Update Magnitude: 0.37777
Value Function Update Magnitude: 0.55088

Collected Steps per Second: 21,742.22814
Overall Steps per Second: 10,386.23457

Timestep Collection Time: 2.30114
Timestep Consumption Time: 2.51600
PPO Batch Consumption Time: 0.28861
Total Iteration Time: 4.81715

Cumulative Model Updates: 107,638
Cumulative Timesteps: 897,551,068

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 897551068...
Checkpoint 897551068 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,149.43344
Policy Entropy: 3.69739
Value Function Loss: 0.02465

Mean KL Divergence: 0.01053
SB3 Clip Fraction: 0.15399
Policy Update Magnitude: 0.39868
Value Function Update Magnitude: 0.57697

Collected Steps per Second: 21,633.88654
Overall Steps per Second: 10,248.86917

Timestep Collection Time: 2.31202
Timestep Consumption Time: 2.56832
PPO Batch Consumption Time: 0.29753
Total Iteration Time: 4.88034

Cumulative Model Updates: 107,644
Cumulative Timesteps: 897,601,086

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 119,450.16238
Policy Entropy: 3.71238
Value Function Loss: 0.02501

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.14837
Policy Update Magnitude: 0.38382
Value Function Update Magnitude: 0.61536

Collected Steps per Second: 21,392.20494
Overall Steps per Second: 10,218.40644

Timestep Collection Time: 2.33814
Timestep Consumption Time: 2.55675
PPO Batch Consumption Time: 0.29621
Total Iteration Time: 4.89489

Cumulative Model Updates: 107,650
Cumulative Timesteps: 897,651,104

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 897651104...
Checkpoint 897651104 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 63,485.38809
Policy Entropy: 3.70635
Value Function Loss: 0.02525

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.14897
Policy Update Magnitude: 0.40368
Value Function Update Magnitude: 0.62455

Collected Steps per Second: 21,593.24207
Overall Steps per Second: 10,373.13200

Timestep Collection Time: 2.31610
Timestep Consumption Time: 2.50521
PPO Batch Consumption Time: 0.28783
Total Iteration Time: 4.82130

Cumulative Model Updates: 107,656
Cumulative Timesteps: 897,701,116

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91,459.10857
Policy Entropy: 3.70406
Value Function Loss: 0.02425

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.14635
Policy Update Magnitude: 0.39433
Value Function Update Magnitude: 0.60851

Collected Steps per Second: 21,710.66335
Overall Steps per Second: 10,318.27301

Timestep Collection Time: 2.30495
Timestep Consumption Time: 2.54489
PPO Batch Consumption Time: 0.29444
Total Iteration Time: 4.84984

Cumulative Model Updates: 107,662
Cumulative Timesteps: 897,751,158

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 897751158...
Checkpoint 897751158 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 120,775.00548
Policy Entropy: 3.69489
Value Function Loss: 0.02342

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.15179
Policy Update Magnitude: 0.39396
Value Function Update Magnitude: 0.59386

Collected Steps per Second: 21,867.78498
Overall Steps per Second: 10,382.28268

Timestep Collection Time: 2.28720
Timestep Consumption Time: 2.53024
PPO Batch Consumption Time: 0.28840
Total Iteration Time: 4.81744

Cumulative Model Updates: 107,668
Cumulative Timesteps: 897,801,174

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 153,064.46182
Policy Entropy: 3.69997
Value Function Loss: 0.02329

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.15449
Policy Update Magnitude: 0.37355
Value Function Update Magnitude: 0.60813

Collected Steps per Second: 21,696.00237
Overall Steps per Second: 10,277.82050

Timestep Collection Time: 2.30522
Timestep Consumption Time: 2.56099
PPO Batch Consumption Time: 0.29541
Total Iteration Time: 4.86621

Cumulative Model Updates: 107,674
Cumulative Timesteps: 897,851,188

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 897851188...
Checkpoint 897851188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 123,981.02666
Policy Entropy: 3.70010
Value Function Loss: 0.02027

Mean KL Divergence: 0.01057
SB3 Clip Fraction: 0.15558
Policy Update Magnitude: 0.34573
Value Function Update Magnitude: 0.67317

Collected Steps per Second: 21,799.73179
Overall Steps per Second: 10,280.37671

Timestep Collection Time: 2.29361
Timestep Consumption Time: 2.57003
PPO Batch Consumption Time: 0.29974
Total Iteration Time: 4.86363

Cumulative Model Updates: 107,680
Cumulative Timesteps: 897,901,188

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 123,981.02666
Policy Entropy: 3.70160
Value Function Loss: 0.01866

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.15390
Policy Update Magnitude: 0.31642
Value Function Update Magnitude: 0.59519

Collected Steps per Second: 21,562.44995
Overall Steps per Second: 10,226.74505

Timestep Collection Time: 2.31977
Timestep Consumption Time: 2.57132
PPO Batch Consumption Time: 0.29570
Total Iteration Time: 4.89110

Cumulative Model Updates: 107,686
Cumulative Timesteps: 897,951,208

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 897951208...
Checkpoint 897951208 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 203,453.61258
Policy Entropy: 3.69189
Value Function Loss: 0.01835

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.15066
Policy Update Magnitude: 0.32714
Value Function Update Magnitude: 0.58388

Collected Steps per Second: 21,414.48889
Overall Steps per Second: 10,196.19835

Timestep Collection Time: 2.33618
Timestep Consumption Time: 2.57036
PPO Batch Consumption Time: 0.30034
Total Iteration Time: 4.90653

Cumulative Model Updates: 107,692
Cumulative Timesteps: 898,001,236

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57,462.75354
Policy Entropy: 3.69317
Value Function Loss: 0.02200

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.15106
Policy Update Magnitude: 0.35311
Value Function Update Magnitude: 0.59974

Collected Steps per Second: 21,560.02441
Overall Steps per Second: 10,352.24405

Timestep Collection Time: 2.32050
Timestep Consumption Time: 2.51227
PPO Batch Consumption Time: 0.28793
Total Iteration Time: 4.83277

Cumulative Model Updates: 107,698
Cumulative Timesteps: 898,051,266

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 898051266...
Checkpoint 898051266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46,006.67329
Policy Entropy: 3.69880
Value Function Loss: 0.02502

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.14456
Policy Update Magnitude: 0.40016
Value Function Update Magnitude: 0.59623

Collected Steps per Second: 21,509.97106
Overall Steps per Second: 10,296.36147

Timestep Collection Time: 2.32478
Timestep Consumption Time: 2.53188
PPO Batch Consumption Time: 0.29283
Total Iteration Time: 4.85667

Cumulative Model Updates: 107,704
Cumulative Timesteps: 898,101,272

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,534.98254
Policy Entropy: 3.71684
Value Function Loss: 0.02675

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.14825
Policy Update Magnitude: 0.43106
Value Function Update Magnitude: 0.64049

Collected Steps per Second: 21,132.90416
Overall Steps per Second: 10,414.52834

Timestep Collection Time: 2.36683
Timestep Consumption Time: 2.43588
PPO Batch Consumption Time: 0.28906
Total Iteration Time: 4.80271

Cumulative Model Updates: 107,710
Cumulative Timesteps: 898,151,290

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 898151290...
Checkpoint 898151290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 126,145.72464
Policy Entropy: 3.70674
Value Function Loss: 0.02754

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.14592
Policy Update Magnitude: 0.45383
Value Function Update Magnitude: 0.63288

Collected Steps per Second: 20,751.35769
Overall Steps per Second: 10,242.76060

Timestep Collection Time: 2.40948
Timestep Consumption Time: 2.47202
PPO Batch Consumption Time: 0.29664
Total Iteration Time: 4.88150

Cumulative Model Updates: 107,716
Cumulative Timesteps: 898,201,290

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,706.82322
Policy Entropy: 3.70577
Value Function Loss: 0.02397

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.14818
Policy Update Magnitude: 0.44864
Value Function Update Magnitude: 0.67638

Collected Steps per Second: 20,877.21533
Overall Steps per Second: 10,368.03756

Timestep Collection Time: 2.39601
Timestep Consumption Time: 2.42863
PPO Batch Consumption Time: 0.28838
Total Iteration Time: 4.82464

Cumulative Model Updates: 107,722
Cumulative Timesteps: 898,251,312

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 898251312...
Checkpoint 898251312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,706.82322
Policy Entropy: 3.68067
Value Function Loss: 0.02458

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.14127
Policy Update Magnitude: 0.42809
Value Function Update Magnitude: 0.64697

Collected Steps per Second: 20,892.87110
Overall Steps per Second: 10,242.12903

Timestep Collection Time: 2.39354
Timestep Consumption Time: 2.48903
PPO Batch Consumption Time: 0.28816
Total Iteration Time: 4.88258

Cumulative Model Updates: 107,728
Cumulative Timesteps: 898,301,320

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,706.82322
Policy Entropy: 3.68449
Value Function Loss: 0.02123

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.14443
Policy Update Magnitude: 0.41073
Value Function Update Magnitude: 0.53460

Collected Steps per Second: 21,473.19102
Overall Steps per Second: 10,413.68389

Timestep Collection Time: 2.33025
Timestep Consumption Time: 2.47477
PPO Batch Consumption Time: 0.28819
Total Iteration Time: 4.80502

Cumulative Model Updates: 107,734
Cumulative Timesteps: 898,351,358

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 898351358...
Checkpoint 898351358 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,706.82322
Policy Entropy: 3.67802
Value Function Loss: 0.02119

Mean KL Divergence: 0.01108
SB3 Clip Fraction: 0.15407
Policy Update Magnitude: 0.40409
Value Function Update Magnitude: 0.44681

Collected Steps per Second: 21,388.68808
Overall Steps per Second: 10,283.51797

Timestep Collection Time: 2.33787
Timestep Consumption Time: 2.52467
PPO Batch Consumption Time: 0.29413
Total Iteration Time: 4.86254

Cumulative Model Updates: 107,740
Cumulative Timesteps: 898,401,362

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 170,141.53420
Policy Entropy: 3.68352
Value Function Loss: 0.01948

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.14577
Policy Update Magnitude: 0.37706
Value Function Update Magnitude: 0.45318

Collected Steps per Second: 21,747.22965
Overall Steps per Second: 10,380.81655

Timestep Collection Time: 2.30135
Timestep Consumption Time: 2.51985
PPO Batch Consumption Time: 0.28812
Total Iteration Time: 4.82120

Cumulative Model Updates: 107,746
Cumulative Timesteps: 898,451,410

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 898451410...
Checkpoint 898451410 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 170,141.53420
Policy Entropy: 3.68520
Value Function Loss: 0.01831

Mean KL Divergence: 0.01157
SB3 Clip Fraction: 0.16465
Policy Update Magnitude: 0.39135
Value Function Update Magnitude: 0.51157

Collected Steps per Second: 21,035.35582
Overall Steps per Second: 10,230.17819

Timestep Collection Time: 2.37705
Timestep Consumption Time: 2.51065
PPO Batch Consumption Time: 0.28756
Total Iteration Time: 4.88770

Cumulative Model Updates: 107,752
Cumulative Timesteps: 898,501,412

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 170,141.53420
Policy Entropy: 3.69210
Value Function Loss: 0.01751

Mean KL Divergence: 0.01058
SB3 Clip Fraction: 0.15094
Policy Update Magnitude: 0.38768
Value Function Update Magnitude: 0.57584

Collected Steps per Second: 21,761.64194
Overall Steps per Second: 10,299.65103

Timestep Collection Time: 2.29863
Timestep Consumption Time: 2.55804
PPO Batch Consumption Time: 0.29410
Total Iteration Time: 4.85667

Cumulative Model Updates: 107,758
Cumulative Timesteps: 898,551,434

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 898551434...
Checkpoint 898551434 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 235,898.71019
Policy Entropy: 3.70815
Value Function Loss: 0.01845

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.14577
Policy Update Magnitude: 0.34587
Value Function Update Magnitude: 0.55864

Collected Steps per Second: 21,347.26154
Overall Steps per Second: 10,329.80698

Timestep Collection Time: 2.34222
Timestep Consumption Time: 2.49814
PPO Batch Consumption Time: 0.28764
Total Iteration Time: 4.84036

Cumulative Model Updates: 107,764
Cumulative Timesteps: 898,601,434

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 235,898.71019
Policy Entropy: 3.68956
Value Function Loss: 0.01881

Mean KL Divergence: 0.01074
SB3 Clip Fraction: 0.15400
Policy Update Magnitude: 0.34889
Value Function Update Magnitude: 0.55491

Collected Steps per Second: 21,495.56907
Overall Steps per Second: 10,255.42480

Timestep Collection Time: 2.32634
Timestep Consumption Time: 2.54971
PPO Batch Consumption Time: 0.29804
Total Iteration Time: 4.87605

Cumulative Model Updates: 107,770
Cumulative Timesteps: 898,651,440

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 898651440...
Checkpoint 898651440 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 235,898.71019
Policy Entropy: 3.68299
Value Function Loss: 0.02124

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.14829
Policy Update Magnitude: 0.36406
Value Function Update Magnitude: 0.56488

Collected Steps per Second: 21,280.37007
Overall Steps per Second: 10,200.11385

Timestep Collection Time: 2.35184
Timestep Consumption Time: 2.55477
PPO Batch Consumption Time: 0.29917
Total Iteration Time: 4.90661

Cumulative Model Updates: 107,776
Cumulative Timesteps: 898,701,488

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 235,898.71019
Policy Entropy: 3.68161
Value Function Loss: 0.02151

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.14862
Policy Update Magnitude: 0.36763
Value Function Update Magnitude: 0.49091

Collected Steps per Second: 21,497.32616
Overall Steps per Second: 10,377.15631

Timestep Collection Time: 2.32680
Timestep Consumption Time: 2.49340
PPO Batch Consumption Time: 0.28643
Total Iteration Time: 4.82020

Cumulative Model Updates: 107,782
Cumulative Timesteps: 898,751,508

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 898751508...
Checkpoint 898751508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 235,898.71019
Policy Entropy: 3.68924
Value Function Loss: 0.02114

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.14767
Policy Update Magnitude: 0.34525
Value Function Update Magnitude: 0.40033

Collected Steps per Second: 21,619.97856
Overall Steps per Second: 10,259.99011

Timestep Collection Time: 2.31342
Timestep Consumption Time: 2.56144
PPO Batch Consumption Time: 0.29931
Total Iteration Time: 4.87486

Cumulative Model Updates: 107,788
Cumulative Timesteps: 898,801,524

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 156,701.47457
Policy Entropy: 3.68186
Value Function Loss: 0.02186

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.14850
Policy Update Magnitude: 0.33284
Value Function Update Magnitude: 0.40001

Collected Steps per Second: 21,768.73401
Overall Steps per Second: 10,378.54786

Timestep Collection Time: 2.29761
Timestep Consumption Time: 2.52156
PPO Batch Consumption Time: 0.28958
Total Iteration Time: 4.81917

Cumulative Model Updates: 107,794
Cumulative Timesteps: 898,851,540

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 898851540...
Checkpoint 898851540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 93,070.10832
Policy Entropy: 3.68574
Value Function Loss: 0.02400

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.14280
Policy Update Magnitude: 0.35730
Value Function Update Magnitude: 0.44140

Collected Steps per Second: 20,777.42957
Overall Steps per Second: 10,196.56914

Timestep Collection Time: 2.40655
Timestep Consumption Time: 2.49725
PPO Batch Consumption Time: 0.29982
Total Iteration Time: 4.90381

Cumulative Model Updates: 107,800
Cumulative Timesteps: 898,901,542

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,071.85701
Policy Entropy: 3.71703
Value Function Loss: 0.02366

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.14312
Policy Update Magnitude: 0.41366
Value Function Update Magnitude: 0.51945

Collected Steps per Second: 20,958.01319
Overall Steps per Second: 10,362.88347

Timestep Collection Time: 2.38629
Timestep Consumption Time: 2.43978
PPO Batch Consumption Time: 0.28844
Total Iteration Time: 4.82607

Cumulative Model Updates: 107,806
Cumulative Timesteps: 898,951,554

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 898951554...
Checkpoint 898951554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 59,348.39118
Policy Entropy: 3.73682
Value Function Loss: 0.02303

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.14163
Policy Update Magnitude: 0.43384
Value Function Update Magnitude: 0.59538

Collected Steps per Second: 20,927.73168
Overall Steps per Second: 10,313.21839

Timestep Collection Time: 2.39023
Timestep Consumption Time: 2.46005
PPO Batch Consumption Time: 0.29280
Total Iteration Time: 4.85028

Cumulative Model Updates: 107,812
Cumulative Timesteps: 899,001,576

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59,348.39118
Policy Entropy: 3.72289
Value Function Loss: 0.02013

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.14124
Policy Update Magnitude: 0.42332
Value Function Update Magnitude: 0.60893

Collected Steps per Second: 20,854.50194
Overall Steps per Second: 10,089.69907

Timestep Collection Time: 2.39939
Timestep Consumption Time: 2.55993
PPO Batch Consumption Time: 0.29941
Total Iteration Time: 4.95932

Cumulative Model Updates: 107,818
Cumulative Timesteps: 899,051,614

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 899051614...
Checkpoint 899051614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 59,348.39118
Policy Entropy: 3.69571
Value Function Loss: 0.02150

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.14545
Policy Update Magnitude: 0.39425
Value Function Update Magnitude: 0.54843

Collected Steps per Second: 21,110.97810
Overall Steps per Second: 10,165.06689

Timestep Collection Time: 2.36900
Timestep Consumption Time: 2.55098
PPO Batch Consumption Time: 0.30148
Total Iteration Time: 4.91999

Cumulative Model Updates: 107,824
Cumulative Timesteps: 899,101,626

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59,348.39118
Policy Entropy: 3.68129
Value Function Loss: 0.01939

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.14650
Policy Update Magnitude: 0.38504
Value Function Update Magnitude: 0.48617

Collected Steps per Second: 21,528.65500
Overall Steps per Second: 10,394.07977

Timestep Collection Time: 2.32379
Timestep Consumption Time: 2.48934
PPO Batch Consumption Time: 0.28819
Total Iteration Time: 4.81312

Cumulative Model Updates: 107,830
Cumulative Timesteps: 899,151,654

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 899151654...
Checkpoint 899151654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 59,348.39118
Policy Entropy: 3.69003
Value Function Loss: 0.01953

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.14844
Policy Update Magnitude: 0.36150
Value Function Update Magnitude: 0.41624

Collected Steps per Second: 21,207.72933
Overall Steps per Second: 10,270.65946

Timestep Collection Time: 2.35773
Timestep Consumption Time: 2.51071
PPO Batch Consumption Time: 0.28782
Total Iteration Time: 4.86843

Cumulative Model Updates: 107,836
Cumulative Timesteps: 899,201,656

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 135,924.08277
Policy Entropy: 3.70580
Value Function Loss: 0.01907

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.14749
Policy Update Magnitude: 0.36779
Value Function Update Magnitude: 0.46301

Collected Steps per Second: 21,142.79862
Overall Steps per Second: 10,183.95600

Timestep Collection Time: 2.36506
Timestep Consumption Time: 2.54502
PPO Batch Consumption Time: 0.29561
Total Iteration Time: 4.91008

Cumulative Model Updates: 107,842
Cumulative Timesteps: 899,251,660

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 899251660...
Checkpoint 899251660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 197,573.97677
Policy Entropy: 3.69817
Value Function Loss: 0.02150

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.14486
Policy Update Magnitude: 0.41123
Value Function Update Magnitude: 0.53860

Collected Steps per Second: 21,513.22776
Overall Steps per Second: 10,375.05657

Timestep Collection Time: 2.32517
Timestep Consumption Time: 2.49620
PPO Batch Consumption Time: 0.28828
Total Iteration Time: 4.82137

Cumulative Model Updates: 107,848
Cumulative Timesteps: 899,301,682

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 197,573.97677
Policy Entropy: 3.70799
Value Function Loss: 0.02224

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.14359
Policy Update Magnitude: 0.45258
Value Function Update Magnitude: 0.57158

Collected Steps per Second: 21,791.54717
Overall Steps per Second: 10,320.31246

Timestep Collection Time: 2.29511
Timestep Consumption Time: 2.55106
PPO Batch Consumption Time: 0.29469
Total Iteration Time: 4.84617

Cumulative Model Updates: 107,854
Cumulative Timesteps: 899,351,696

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 899351696...
Checkpoint 899351696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 197,573.97677
Policy Entropy: 3.68997
Value Function Loss: 0.02303

Mean KL Divergence: 0.01080
SB3 Clip Fraction: 0.15171
Policy Update Magnitude: 0.45165
Value Function Update Magnitude: 0.56861

Collected Steps per Second: 21,802.72166
Overall Steps per Second: 10,399.55975

Timestep Collection Time: 2.29540
Timestep Consumption Time: 2.51692
PPO Batch Consumption Time: 0.28903
Total Iteration Time: 4.81232

Cumulative Model Updates: 107,860
Cumulative Timesteps: 899,401,742

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 197,573.97677
Policy Entropy: 3.70679
Value Function Loss: 0.02054

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.14664
Policy Update Magnitude: 0.41662
Value Function Update Magnitude: 0.51202

Collected Steps per Second: 21,150.01852
Overall Steps per Second: 10,433.64814

Timestep Collection Time: 2.36539
Timestep Consumption Time: 2.42948
PPO Batch Consumption Time: 0.28792
Total Iteration Time: 4.79487

Cumulative Model Updates: 107,866
Cumulative Timesteps: 899,451,770

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 899451770...
Checkpoint 899451770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 197,573.97677
Policy Entropy: 3.69950
Value Function Loss: 0.02001

Mean KL Divergence: 0.01072
SB3 Clip Fraction: 0.15397
Policy Update Magnitude: 0.38648
Value Function Update Magnitude: 0.45866

Collected Steps per Second: 20,457.12359
Overall Steps per Second: 10,182.78819

Timestep Collection Time: 2.44521
Timestep Consumption Time: 2.46720
PPO Batch Consumption Time: 0.29347
Total Iteration Time: 4.91241

Cumulative Model Updates: 107,872
Cumulative Timesteps: 899,501,792

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 197,573.97677
Policy Entropy: 3.70655
Value Function Loss: 0.02026

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.14671
Policy Update Magnitude: 0.42440
Value Function Update Magnitude: 0.50396

Collected Steps per Second: 21,071.49841
Overall Steps per Second: 10,188.28761

Timestep Collection Time: 2.37420
Timestep Consumption Time: 2.53614
PPO Batch Consumption Time: 0.29746
Total Iteration Time: 4.91034

Cumulative Model Updates: 107,878
Cumulative Timesteps: 899,551,820

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 899551820...
Checkpoint 899551820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 197,573.97677
Policy Entropy: 3.70367
Value Function Loss: 0.02056

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.14459
Policy Update Magnitude: 0.46943
Value Function Update Magnitude: 0.59813

Collected Steps per Second: 21,404.99024
Overall Steps per Second: 10,368.39656

Timestep Collection Time: 2.33618
Timestep Consumption Time: 2.48674
PPO Batch Consumption Time: 0.28822
Total Iteration Time: 4.82293

Cumulative Model Updates: 107,884
Cumulative Timesteps: 899,601,826

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 197,573.97677
Policy Entropy: 3.69703
Value Function Loss: 0.02261

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.14746
Policy Update Magnitude: 0.46038
Value Function Update Magnitude: 0.58432

Collected Steps per Second: 21,313.78916
Overall Steps per Second: 10,245.28723

Timestep Collection Time: 2.34627
Timestep Consumption Time: 2.53480
PPO Batch Consumption Time: 0.29835
Total Iteration Time: 4.88107

Cumulative Model Updates: 107,890
Cumulative Timesteps: 899,651,834

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 899651834...
Checkpoint 899651834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 197,573.97677
Policy Entropy: 3.68970
Value Function Loss: 0.02336

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.14818
Policy Update Magnitude: 0.44502
Value Function Update Magnitude: 0.51822

Collected Steps per Second: 21,308.95220
Overall Steps per Second: 10,185.41790

Timestep Collection Time: 2.34699
Timestep Consumption Time: 2.56316
PPO Batch Consumption Time: 0.30028
Total Iteration Time: 4.91016

Cumulative Model Updates: 107,896
Cumulative Timesteps: 899,701,846

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 197,573.97677
Policy Entropy: 3.68303
Value Function Loss: 0.02379

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.14752
Policy Update Magnitude: 0.44604
Value Function Update Magnitude: 0.49164

Collected Steps per Second: 21,782.51965
Overall Steps per Second: 10,416.48643

Timestep Collection Time: 2.29670
Timestep Consumption Time: 2.50607
PPO Batch Consumption Time: 0.28633
Total Iteration Time: 4.80277

Cumulative Model Updates: 107,902
Cumulative Timesteps: 899,751,874

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 899751874...
Checkpoint 899751874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 197,573.97677
Policy Entropy: 3.69386
Value Function Loss: 0.02247

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.14329
Policy Update Magnitude: 0.43056
Value Function Update Magnitude: 0.47104

Collected Steps per Second: 21,137.08795
Overall Steps per Second: 10,178.23260

Timestep Collection Time: 2.36674
Timestep Consumption Time: 2.54826
PPO Batch Consumption Time: 0.29399
Total Iteration Time: 4.91500

Cumulative Model Updates: 107,908
Cumulative Timesteps: 899,801,900

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 197,573.97677
Policy Entropy: 3.70955
Value Function Loss: 0.02105

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.14272
Policy Update Magnitude: 0.41172
Value Function Update Magnitude: 0.47036

Collected Steps per Second: 21,490.44601
Overall Steps per Second: 10,205.26333

Timestep Collection Time: 2.32708
Timestep Consumption Time: 2.57333
PPO Batch Consumption Time: 0.30016
Total Iteration Time: 4.90041

Cumulative Model Updates: 107,914
Cumulative Timesteps: 899,851,910

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 899851910...
Checkpoint 899851910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 197,573.97677
Policy Entropy: 3.69482
Value Function Loss: 0.01984

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.14166
Policy Update Magnitude: 0.41415
Value Function Update Magnitude: 0.55919

Collected Steps per Second: 21,579.45270
Overall Steps per Second: 10,374.61610

Timestep Collection Time: 2.31804
Timestep Consumption Time: 2.50354
PPO Batch Consumption Time: 0.28750
Total Iteration Time: 4.82158

Cumulative Model Updates: 107,920
Cumulative Timesteps: 899,901,932

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 197,573.97677
Policy Entropy: 3.69551
Value Function Loss: 0.01880

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.14271
Policy Update Magnitude: 0.40164
Value Function Update Magnitude: 0.53569

Collected Steps per Second: 21,649.84920
Overall Steps per Second: 10,284.71559

Timestep Collection Time: 2.31087
Timestep Consumption Time: 2.55363
PPO Batch Consumption Time: 0.29621
Total Iteration Time: 4.86450

Cumulative Model Updates: 107,926
Cumulative Timesteps: 899,951,962

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 899951962...
Checkpoint 899951962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 197,573.97677
Policy Entropy: 3.68496
Value Function Loss: 0.01924

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.14550
Policy Update Magnitude: 0.40284
Value Function Update Magnitude: 0.39571

Collected Steps per Second: 21,489.94733
Overall Steps per Second: 10,341.93300

Timestep Collection Time: 2.32686
Timestep Consumption Time: 2.50822
PPO Batch Consumption Time: 0.28743
Total Iteration Time: 4.83507

Cumulative Model Updates: 107,932
Cumulative Timesteps: 900,001,966

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 197,573.97677
Policy Entropy: 3.70033
Value Function Loss: 0.01834

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.14318
Policy Update Magnitude: 0.39638
Value Function Update Magnitude: 0.43874

Collected Steps per Second: 21,976.13126
Overall Steps per Second: 10,492.88512

Timestep Collection Time: 2.27601
Timestep Consumption Time: 2.49083
PPO Batch Consumption Time: 0.28754
Total Iteration Time: 4.76685

Cumulative Model Updates: 107,938
Cumulative Timesteps: 900,051,984

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 900051984...
Checkpoint 900051984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 197,573.97677
Policy Entropy: 3.70354
Value Function Loss: 0.02015

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.14631
Policy Update Magnitude: 0.41819
Value Function Update Magnitude: 0.42624

Collected Steps per Second: 21,564.57193
Overall Steps per Second: 10,312.61644

Timestep Collection Time: 2.32010
Timestep Consumption Time: 2.53143
PPO Batch Consumption Time: 0.29353
Total Iteration Time: 4.85153

Cumulative Model Updates: 107,944
Cumulative Timesteps: 900,102,016

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 299,995.22543
Policy Entropy: 3.70779
Value Function Loss: 0.02114

Mean KL Divergence: 0.01057
SB3 Clip Fraction: 0.14891
Policy Update Magnitude: 0.45319
Value Function Update Magnitude: 0.41729

Collected Steps per Second: 21,151.98142
Overall Steps per Second: 10,454.33412

Timestep Collection Time: 2.36413
Timestep Consumption Time: 2.41915
PPO Batch Consumption Time: 0.28659
Total Iteration Time: 4.78328

Cumulative Model Updates: 107,950
Cumulative Timesteps: 900,152,022

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 900152022...
Checkpoint 900152022 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 539,484.10744
Policy Entropy: 3.68744
Value Function Loss: 0.02746

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.13853
Policy Update Magnitude: 0.46829
Value Function Update Magnitude: 0.44041

Collected Steps per Second: 20,524.18931
Overall Steps per Second: 10,188.34067

Timestep Collection Time: 2.43654
Timestep Consumption Time: 2.47182
PPO Batch Consumption Time: 0.29563
Total Iteration Time: 4.90836

Cumulative Model Updates: 107,956
Cumulative Timesteps: 900,202,030

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 539,484.10744
Policy Entropy: 3.68300
Value Function Loss: 0.02735

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.14615
Policy Update Magnitude: 0.52035
Value Function Update Magnitude: 0.45757

Collected Steps per Second: 20,586.34330
Overall Steps per Second: 10,056.77537

Timestep Collection Time: 2.43006
Timestep Consumption Time: 2.54430
PPO Batch Consumption Time: 0.29709
Total Iteration Time: 4.97436

Cumulative Model Updates: 107,962
Cumulative Timesteps: 900,252,056

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 900252056...
Checkpoint 900252056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 351,968.82185
Policy Entropy: 3.68142
Value Function Loss: 0.02913

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.14387
Policy Update Magnitude: 0.52337
Value Function Update Magnitude: 0.43777

Collected Steps per Second: 21,365.31697
Overall Steps per Second: 10,230.44667

Timestep Collection Time: 2.34090
Timestep Consumption Time: 2.54784
PPO Batch Consumption Time: 0.30169
Total Iteration Time: 4.88874

Cumulative Model Updates: 107,968
Cumulative Timesteps: 900,302,070

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99,420.03350
Policy Entropy: 3.69138
Value Function Loss: 0.02519

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.14066
Policy Update Magnitude: 0.51254
Value Function Update Magnitude: 0.43015

Collected Steps per Second: 21,072.19111
Overall Steps per Second: 10,193.89148

Timestep Collection Time: 2.37289
Timestep Consumption Time: 2.53220
PPO Batch Consumption Time: 0.29512
Total Iteration Time: 4.90509

Cumulative Model Updates: 107,974
Cumulative Timesteps: 900,352,072

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 900352072...
Checkpoint 900352072 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 80,545.29772
Policy Entropy: 3.68993
Value Function Loss: 0.02580

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.14245
Policy Update Magnitude: 0.51487
Value Function Update Magnitude: 0.40296

Collected Steps per Second: 20,908.56544
Overall Steps per Second: 10,081.21790

Timestep Collection Time: 2.39146
Timestep Consumption Time: 2.56846
PPO Batch Consumption Time: 0.29949
Total Iteration Time: 4.95992

Cumulative Model Updates: 107,980
Cumulative Timesteps: 900,402,074

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80,545.29772
Policy Entropy: 3.70019
Value Function Loss: 0.02325

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.14189
Policy Update Magnitude: 0.51812
Value Function Update Magnitude: 0.37760

Collected Steps per Second: 21,615.64800
Overall Steps per Second: 10,234.29813

Timestep Collection Time: 2.31323
Timestep Consumption Time: 2.57250
PPO Batch Consumption Time: 0.29801
Total Iteration Time: 4.88573

Cumulative Model Updates: 107,986
Cumulative Timesteps: 900,452,076

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 900452076...
Checkpoint 900452076 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 213,345.45453
Policy Entropy: 3.68715
Value Function Loss: 0.02592

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.14121
Policy Update Magnitude: 0.49631
Value Function Update Magnitude: 0.36767

Collected Steps per Second: 21,691.41055
Overall Steps per Second: 10,256.03091

Timestep Collection Time: 2.30617
Timestep Consumption Time: 2.57135
PPO Batch Consumption Time: 0.29516
Total Iteration Time: 4.87752

Cumulative Model Updates: 107,992
Cumulative Timesteps: 900,502,100

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 213,345.45453
Policy Entropy: 3.68624
Value Function Loss: 0.02419

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.14364
Policy Update Magnitude: 0.50552
Value Function Update Magnitude: 0.39388

Collected Steps per Second: 21,432.82061
Overall Steps per Second: 10,202.54256

Timestep Collection Time: 2.33390
Timestep Consumption Time: 2.56900
PPO Batch Consumption Time: 0.30004
Total Iteration Time: 4.90290

Cumulative Model Updates: 107,998
Cumulative Timesteps: 900,552,122

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 900552122...
Checkpoint 900552122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 213,345.45453
Policy Entropy: 3.68284
Value Function Loss: 0.02364

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.14710
Policy Update Magnitude: 0.54439
Value Function Update Magnitude: 0.41199

Collected Steps per Second: 21,314.78487
Overall Steps per Second: 10,189.47446

Timestep Collection Time: 2.34588
Timestep Consumption Time: 2.56134
PPO Batch Consumption Time: 0.30046
Total Iteration Time: 4.90722

Cumulative Model Updates: 108,004
Cumulative Timesteps: 900,602,124

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 213,345.45453
Policy Entropy: 3.69802
Value Function Loss: 0.02166

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.14092
Policy Update Magnitude: 0.51795
Value Function Update Magnitude: 0.44159

Collected Steps per Second: 21,584.88142
Overall Steps per Second: 10,373.20778

Timestep Collection Time: 2.31746
Timestep Consumption Time: 2.50478
PPO Batch Consumption Time: 0.28766
Total Iteration Time: 4.82223

Cumulative Model Updates: 108,010
Cumulative Timesteps: 900,652,146

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 900652146...
Checkpoint 900652146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 213,345.45453
Policy Entropy: 3.69517
Value Function Loss: 0.02137

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.14946
Policy Update Magnitude: 0.44808
Value Function Update Magnitude: 0.39508

Collected Steps per Second: 20,619.82294
Overall Steps per Second: 10,280.40827

Timestep Collection Time: 2.42621
Timestep Consumption Time: 2.44013
PPO Batch Consumption Time: 0.28648
Total Iteration Time: 4.86634

Cumulative Model Updates: 108,016
Cumulative Timesteps: 900,702,174

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 415,628.12632
Policy Entropy: 3.69348
Value Function Loss: 0.02483

Mean KL Divergence: 0.01065
SB3 Clip Fraction: 0.14865
Policy Update Magnitude: 0.46833
Value Function Update Magnitude: 0.40193

Collected Steps per Second: 20,867.90237
Overall Steps per Second: 10,333.82220

Timestep Collection Time: 2.39756
Timestep Consumption Time: 2.44402
PPO Batch Consumption Time: 0.28883
Total Iteration Time: 4.84158

Cumulative Model Updates: 108,022
Cumulative Timesteps: 900,752,206

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 900752206...
Checkpoint 900752206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 272,692.62287
Policy Entropy: 3.69745
Value Function Loss: 0.02438

Mean KL Divergence: 0.01078
SB3 Clip Fraction: 0.14980
Policy Update Magnitude: 0.46563
Value Function Update Magnitude: 0.53759

Collected Steps per Second: 20,807.34841
Overall Steps per Second: 10,223.10397

Timestep Collection Time: 2.40444
Timestep Consumption Time: 2.48938
PPO Batch Consumption Time: 0.28748
Total Iteration Time: 4.89382

Cumulative Model Updates: 108,028
Cumulative Timesteps: 900,802,236

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 272,692.62287
Policy Entropy: 3.70449
Value Function Loss: 0.02608

Mean KL Divergence: 0.01058
SB3 Clip Fraction: 0.14657
Policy Update Magnitude: 0.47253
Value Function Update Magnitude: 0.59939

Collected Steps per Second: 21,460.81631
Overall Steps per Second: 10,290.82849

Timestep Collection Time: 2.32983
Timestep Consumption Time: 2.52887
PPO Batch Consumption Time: 0.29591
Total Iteration Time: 4.85870

Cumulative Model Updates: 108,034
Cumulative Timesteps: 900,852,236

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 900852236...
Checkpoint 900852236 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 357,520.11526
Policy Entropy: 3.70839
Value Function Loss: 0.02734

Mean KL Divergence: 0.01050
SB3 Clip Fraction: 0.14841
Policy Update Magnitude: 0.47615
Value Function Update Magnitude: 0.52016

Collected Steps per Second: 21,504.29832
Overall Steps per Second: 10,403.08653

Timestep Collection Time: 2.32605
Timestep Consumption Time: 2.48214
PPO Batch Consumption Time: 0.28784
Total Iteration Time: 4.80819

Cumulative Model Updates: 108,040
Cumulative Timesteps: 900,902,256

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 418,014.58880
Policy Entropy: 3.69809
Value Function Loss: 0.02407

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.14283
Policy Update Magnitude: 0.49041
Value Function Update Magnitude: 0.53221

Collected Steps per Second: 21,602.40867
Overall Steps per Second: 10,254.78605

Timestep Collection Time: 2.31567
Timestep Consumption Time: 2.56244
PPO Batch Consumption Time: 0.29636
Total Iteration Time: 4.87811

Cumulative Model Updates: 108,046
Cumulative Timesteps: 900,952,280

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 900952280...
Checkpoint 900952280 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 539,828.68850
Policy Entropy: 3.68392
Value Function Loss: 0.02754

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.14310
Policy Update Magnitude: 0.52258
Value Function Update Magnitude: 0.59532

Collected Steps per Second: 21,340.71725
Overall Steps per Second: 10,218.06277

Timestep Collection Time: 2.34369
Timestep Consumption Time: 2.55117
PPO Batch Consumption Time: 0.29523
Total Iteration Time: 4.89486

Cumulative Model Updates: 108,052
Cumulative Timesteps: 901,002,296

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 188,247.78383
Policy Entropy: 3.68977
Value Function Loss: 0.02567

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.14535
Policy Update Magnitude: 0.56394
Value Function Update Magnitude: 0.73500

Collected Steps per Second: 21,783.40716
Overall Steps per Second: 10,253.13966

Timestep Collection Time: 2.29643
Timestep Consumption Time: 2.58247
PPO Batch Consumption Time: 0.29886
Total Iteration Time: 4.87890

Cumulative Model Updates: 108,058
Cumulative Timesteps: 901,052,320

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 901052320...
Checkpoint 901052320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 601,976.81062
Policy Entropy: 3.70356
Value Function Loss: 0.02792

Mean KL Divergence: 0.01070
SB3 Clip Fraction: 0.15033
Policy Update Magnitude: 0.56270
Value Function Update Magnitude: 0.67247

Collected Steps per Second: 21,371.89155
Overall Steps per Second: 10,083.11810

Timestep Collection Time: 2.34055
Timestep Consumption Time: 2.62041
PPO Batch Consumption Time: 0.30695
Total Iteration Time: 4.96097

Cumulative Model Updates: 108,064
Cumulative Timesteps: 901,102,342

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 209,898.05868
Policy Entropy: 3.71723
Value Function Loss: 0.02441

Mean KL Divergence: 0.01067
SB3 Clip Fraction: 0.14788
Policy Update Magnitude: 0.51841
Value Function Update Magnitude: 0.58335

Collected Steps per Second: 21,510.80415
Overall Steps per Second: 10,219.57728

Timestep Collection Time: 2.32534
Timestep Consumption Time: 2.56918
PPO Batch Consumption Time: 0.29956
Total Iteration Time: 4.89453

Cumulative Model Updates: 108,070
Cumulative Timesteps: 901,152,362

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 901152362...
Checkpoint 901152362 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 209,898.05868
Policy Entropy: 3.71175
Value Function Loss: 0.02526

Mean KL Divergence: 0.01050
SB3 Clip Fraction: 0.14350
Policy Update Magnitude: 0.48767
Value Function Update Magnitude: 0.56818

Collected Steps per Second: 21,405.18648
Overall Steps per Second: 10,163.81657

Timestep Collection Time: 2.33700
Timestep Consumption Time: 2.58477
PPO Batch Consumption Time: 0.29727
Total Iteration Time: 4.92177

Cumulative Model Updates: 108,076
Cumulative Timesteps: 901,202,386

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 209,898.05868
Policy Entropy: 3.70217
Value Function Loss: 0.02542

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.14226
Policy Update Magnitude: 0.50211
Value Function Update Magnitude: 0.51587

Collected Steps per Second: 20,456.46723
Overall Steps per Second: 10,020.59457

Timestep Collection Time: 2.44578
Timestep Consumption Time: 2.54714
PPO Batch Consumption Time: 0.30022
Total Iteration Time: 4.99292

Cumulative Model Updates: 108,082
Cumulative Timesteps: 901,252,418

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 901252418...
Checkpoint 901252418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 158,311.20417
Policy Entropy: 3.71242
Value Function Loss: 0.02528

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.14300
Policy Update Magnitude: 0.49343
Value Function Update Magnitude: 0.49946

Collected Steps per Second: 19,776.51635
Overall Steps per Second: 9,876.70370

Timestep Collection Time: 2.52946
Timestep Consumption Time: 2.53538
PPO Batch Consumption Time: 0.30054
Total Iteration Time: 5.06485

Cumulative Model Updates: 108,088
Cumulative Timesteps: 901,302,442

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84,142.72747
Policy Entropy: 3.71395
Value Function Loss: 0.02413

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.14806
Policy Update Magnitude: 0.48455
Value Function Update Magnitude: 0.58685

Collected Steps per Second: 19,654.93705
Overall Steps per Second: 9,712.17727

Timestep Collection Time: 2.54460
Timestep Consumption Time: 2.60502
PPO Batch Consumption Time: 0.29897
Total Iteration Time: 5.14962

Cumulative Model Updates: 108,094
Cumulative Timesteps: 901,352,456

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 901352456...
Checkpoint 901352456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84,142.72747
Policy Entropy: 3.71370
Value Function Loss: 0.02292

Mean KL Divergence: 0.01085
SB3 Clip Fraction: 0.15154
Policy Update Magnitude: 0.49117
Value Function Update Magnitude: 0.61467

Collected Steps per Second: 20,320.15266
Overall Steps per Second: 10,068.17416

Timestep Collection Time: 2.46248
Timestep Consumption Time: 2.50744
PPO Batch Consumption Time: 0.28770
Total Iteration Time: 4.96992

Cumulative Model Updates: 108,100
Cumulative Timesteps: 901,402,494

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84,142.72747
Policy Entropy: 3.70136
Value Function Loss: 0.02186

Mean KL Divergence: 0.01085
SB3 Clip Fraction: 0.14991
Policy Update Magnitude: 0.47453
Value Function Update Magnitude: 0.65047

Collected Steps per Second: 21,325.95950
Overall Steps per Second: 10,255.93312

Timestep Collection Time: 2.34559
Timestep Consumption Time: 2.53178
PPO Batch Consumption Time: 0.29737
Total Iteration Time: 4.87737

Cumulative Model Updates: 108,106
Cumulative Timesteps: 901,452,516

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 901452516...
Checkpoint 901452516 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84,142.72747
Policy Entropy: 3.69173
Value Function Loss: 0.02011

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.14523
Policy Update Magnitude: 0.44594
Value Function Update Magnitude: 0.64639

Collected Steps per Second: 21,671.51388
Overall Steps per Second: 10,213.96967

Timestep Collection Time: 2.30755
Timestep Consumption Time: 2.58849
PPO Batch Consumption Time: 0.29759
Total Iteration Time: 4.89604

Cumulative Model Updates: 108,112
Cumulative Timesteps: 901,502,524

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84,142.72747
Policy Entropy: 3.69881
Value Function Loss: 0.01909

Mean KL Divergence: 0.01055
SB3 Clip Fraction: 0.14938
Policy Update Magnitude: 0.41148
Value Function Update Magnitude: 0.60140

Collected Steps per Second: 21,481.04416
Overall Steps per Second: 10,222.00691

Timestep Collection Time: 2.32950
Timestep Consumption Time: 2.56582
PPO Batch Consumption Time: 0.28872
Total Iteration Time: 4.89532

Cumulative Model Updates: 108,118
Cumulative Timesteps: 901,552,564

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 901552564...
Checkpoint 901552564 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 331,283.09168
Policy Entropy: 3.68602
Value Function Loss: 0.02379

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.14557
Policy Update Magnitude: 0.42571
Value Function Update Magnitude: 0.57796

Collected Steps per Second: 21,529.37775
Overall Steps per Second: 10,264.67479

Timestep Collection Time: 2.32343
Timestep Consumption Time: 2.54979
PPO Batch Consumption Time: 0.29446
Total Iteration Time: 4.87322

Cumulative Model Updates: 108,124
Cumulative Timesteps: 901,602,586

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99,834.48745
Policy Entropy: 3.71295
Value Function Loss: 0.02588

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.14167
Policy Update Magnitude: 0.49352
Value Function Update Magnitude: 0.61594

Collected Steps per Second: 21,504.17259
Overall Steps per Second: 10,224.71374

Timestep Collection Time: 2.32606
Timestep Consumption Time: 2.56601
PPO Batch Consumption Time: 0.29638
Total Iteration Time: 4.89207

Cumulative Model Updates: 108,130
Cumulative Timesteps: 901,652,606

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 901652606...
Checkpoint 901652606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 91,583.34037
Policy Entropy: 3.71540
Value Function Loss: 0.02876

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.14536
Policy Update Magnitude: 0.53585
Value Function Update Magnitude: 0.71571

Collected Steps per Second: 21,713.37803
Overall Steps per Second: 10,401.24594

Timestep Collection Time: 2.30337
Timestep Consumption Time: 2.50509
PPO Batch Consumption Time: 0.28811
Total Iteration Time: 4.80846

Cumulative Model Updates: 108,136
Cumulative Timesteps: 901,702,620

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,044.98183
Policy Entropy: 3.74400
Value Function Loss: 0.02757

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.13908
Policy Update Magnitude: 0.53928
Value Function Update Magnitude: 0.70587

Collected Steps per Second: 21,026.01735
Overall Steps per Second: 10,049.39913

Timestep Collection Time: 2.37886
Timestep Consumption Time: 2.59835
PPO Batch Consumption Time: 0.30306
Total Iteration Time: 4.97721

Cumulative Model Updates: 108,142
Cumulative Timesteps: 901,752,638

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 901752638...
Checkpoint 901752638 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 137,910.40919
Policy Entropy: 3.73439
Value Function Loss: 0.02914

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.14092
Policy Update Magnitude: 0.51140
Value Function Update Magnitude: 0.66949

Collected Steps per Second: 21,316.51739
Overall Steps per Second: 10,234.57836

Timestep Collection Time: 2.34672
Timestep Consumption Time: 2.54102
PPO Batch Consumption Time: 0.29195
Total Iteration Time: 4.88774

Cumulative Model Updates: 108,148
Cumulative Timesteps: 901,802,662

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52,631.67333
Policy Entropy: 3.73629
Value Function Loss: 0.02568

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.14144
Policy Update Magnitude: 0.52594
Value Function Update Magnitude: 0.70670

Collected Steps per Second: 21,642.95542
Overall Steps per Second: 10,370.64496

Timestep Collection Time: 2.31198
Timestep Consumption Time: 2.51299
PPO Batch Consumption Time: 0.28739
Total Iteration Time: 4.82497

Cumulative Model Updates: 108,154
Cumulative Timesteps: 901,852,700

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 901852700...
Checkpoint 901852700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,054.91077
Policy Entropy: 3.73041
Value Function Loss: 0.02406

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.14074
Policy Update Magnitude: 0.53796
Value Function Update Magnitude: 0.71276

Collected Steps per Second: 21,656.73503
Overall Steps per Second: 10,289.26884

Timestep Collection Time: 2.30949
Timestep Consumption Time: 2.55150
PPO Batch Consumption Time: 0.29736
Total Iteration Time: 4.86099

Cumulative Model Updates: 108,160
Cumulative Timesteps: 901,902,716

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,207.71521
Policy Entropy: 3.73478
Value Function Loss: 0.02070

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.14357
Policy Update Magnitude: 0.53287
Value Function Update Magnitude: 0.68355

Collected Steps per Second: 21,395.60920
Overall Steps per Second: 10,195.72464

Timestep Collection Time: 2.33768
Timestep Consumption Time: 2.56791
PPO Batch Consumption Time: 0.29594
Total Iteration Time: 4.90559

Cumulative Model Updates: 108,166
Cumulative Timesteps: 901,952,732

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 901952732...
Checkpoint 901952732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 96,185.03443
Policy Entropy: 3.71999
Value Function Loss: 0.01997

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.14517
Policy Update Magnitude: 0.46875
Value Function Update Magnitude: 0.59939

Collected Steps per Second: 21,814.42441
Overall Steps per Second: 10,401.85077

Timestep Collection Time: 2.29307
Timestep Consumption Time: 2.51588
PPO Batch Consumption Time: 0.28840
Total Iteration Time: 4.80895

Cumulative Model Updates: 108,172
Cumulative Timesteps: 902,002,754

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63,107.35420
Policy Entropy: 3.70968
Value Function Loss: 0.01842

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.14526
Policy Update Magnitude: 0.43251
Value Function Update Magnitude: 0.54465

Collected Steps per Second: 21,613.77431
Overall Steps per Second: 10,265.07146

Timestep Collection Time: 2.31362
Timestep Consumption Time: 2.55785
PPO Batch Consumption Time: 0.29731
Total Iteration Time: 4.87147

Cumulative Model Updates: 108,178
Cumulative Timesteps: 902,052,760

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 902052760...
Checkpoint 902052760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 63,107.35420
Policy Entropy: 3.70068
Value Function Loss: 0.01782

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.14701
Policy Update Magnitude: 0.41789
Value Function Update Magnitude: 0.48362

Collected Steps per Second: 21,558.84551
Overall Steps per Second: 10,373.84724

Timestep Collection Time: 2.32090
Timestep Consumption Time: 2.50238
PPO Batch Consumption Time: 0.28868
Total Iteration Time: 4.82328

Cumulative Model Updates: 108,184
Cumulative Timesteps: 902,102,796

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63,107.35420
Policy Entropy: 3.70505
Value Function Loss: 0.01640

Mean KL Divergence: 0.01065
SB3 Clip Fraction: 0.14606
Policy Update Magnitude: 0.39153
Value Function Update Magnitude: 0.40250

Collected Steps per Second: 21,534.78737
Overall Steps per Second: 10,181.98906

Timestep Collection Time: 2.32266
Timestep Consumption Time: 2.58974
PPO Batch Consumption Time: 0.30158
Total Iteration Time: 4.91240

Cumulative Model Updates: 108,190
Cumulative Timesteps: 902,152,814

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 902152814...
Checkpoint 902152814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 63,107.35420
Policy Entropy: 3.68657
Value Function Loss: 0.01716

Mean KL Divergence: 0.01084
SB3 Clip Fraction: 0.14811
Policy Update Magnitude: 0.38859
Value Function Update Magnitude: 0.41796

Collected Steps per Second: 21,640.23982
Overall Steps per Second: 10,241.63299

Timestep Collection Time: 2.31079
Timestep Consumption Time: 2.57183
PPO Batch Consumption Time: 0.30059
Total Iteration Time: 4.88262

Cumulative Model Updates: 108,196
Cumulative Timesteps: 902,202,820

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 94,724.39538
Policy Entropy: 3.69146
Value Function Loss: 0.01733

Mean KL Divergence: 0.01124
SB3 Clip Fraction: 0.14886
Policy Update Magnitude: 0.41885
Value Function Update Magnitude: 0.46106

Collected Steps per Second: 21,666.58480
Overall Steps per Second: 10,363.61628

Timestep Collection Time: 2.30853
Timestep Consumption Time: 2.51778
PPO Batch Consumption Time: 0.28802
Total Iteration Time: 4.82631

Cumulative Model Updates: 108,202
Cumulative Timesteps: 902,252,838

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 902252838...
Checkpoint 902252838 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 94,724.39538
Policy Entropy: 3.69458
Value Function Loss: 0.01851

Mean KL Divergence: 0.01080
SB3 Clip Fraction: 0.14633
Policy Update Magnitude: 0.43702
Value Function Update Magnitude: 0.58397

Collected Steps per Second: 21,491.87469
Overall Steps per Second: 10,251.72130

Timestep Collection Time: 2.32851
Timestep Consumption Time: 2.55301
PPO Batch Consumption Time: 0.29544
Total Iteration Time: 4.88152

Cumulative Model Updates: 108,208
Cumulative Timesteps: 902,302,882

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 94,724.39538
Policy Entropy: 3.67764
Value Function Loss: 0.01977

Mean KL Divergence: 0.01080
SB3 Clip Fraction: 0.14971
Policy Update Magnitude: 0.44718
Value Function Update Magnitude: 0.64240

Collected Steps per Second: 21,325.64770
Overall Steps per Second: 10,317.11640

Timestep Collection Time: 2.34675
Timestep Consumption Time: 2.50402
PPO Batch Consumption Time: 0.28781
Total Iteration Time: 4.85077

Cumulative Model Updates: 108,214
Cumulative Timesteps: 902,352,928

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 902352928...
Checkpoint 902352928 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 259,783.18433
Policy Entropy: 3.66122
Value Function Loss: 0.02302

Mean KL Divergence: 0.01121
SB3 Clip Fraction: 0.15621
Policy Update Magnitude: 0.45165
Value Function Update Magnitude: 0.60781

Collected Steps per Second: 21,278.09789
Overall Steps per Second: 10,177.63163

Timestep Collection Time: 2.34983
Timestep Consumption Time: 2.56290
PPO Batch Consumption Time: 0.30086
Total Iteration Time: 4.91273

Cumulative Model Updates: 108,220
Cumulative Timesteps: 902,402,928

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 259,783.18433
Policy Entropy: 3.67214
Value Function Loss: 0.02071

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.14687
Policy Update Magnitude: 0.44965
Value Function Update Magnitude: 0.55926

Collected Steps per Second: 21,819.03929
Overall Steps per Second: 10,326.48130

Timestep Collection Time: 2.29258
Timestep Consumption Time: 2.55147
PPO Batch Consumption Time: 0.29791
Total Iteration Time: 4.84405

Cumulative Model Updates: 108,226
Cumulative Timesteps: 902,452,950

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 902452950...
Checkpoint 902452950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 259,783.18433
Policy Entropy: 3.67908
Value Function Loss: 0.01960

Mean KL Divergence: 0.01085
SB3 Clip Fraction: 0.14866
Policy Update Magnitude: 0.44837
Value Function Update Magnitude: 0.57808

Collected Steps per Second: 21,310.48622
Overall Steps per Second: 10,212.28010

Timestep Collection Time: 2.34636
Timestep Consumption Time: 2.54991
PPO Batch Consumption Time: 0.29675
Total Iteration Time: 4.89626

Cumulative Model Updates: 108,232
Cumulative Timesteps: 902,502,952

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 259,783.18433
Policy Entropy: 3.68575
Value Function Loss: 0.01725

Mean KL Divergence: 0.01061
SB3 Clip Fraction: 0.14855
Policy Update Magnitude: 0.42947
Value Function Update Magnitude: 0.50225

Collected Steps per Second: 20,929.15280
Overall Steps per Second: 10,285.04451

Timestep Collection Time: 2.39006
Timestep Consumption Time: 2.47350
PPO Batch Consumption Time: 0.29442
Total Iteration Time: 4.86357

Cumulative Model Updates: 108,238
Cumulative Timesteps: 902,552,974

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 902552974...
Checkpoint 902552974 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 146,634.57361
Policy Entropy: 3.67555
Value Function Loss: 0.01931

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.14428
Policy Update Magnitude: 0.40376
Value Function Update Magnitude: 0.49370

Collected Steps per Second: 20,332.82841
Overall Steps per Second: 10,244.63170

Timestep Collection Time: 2.45977
Timestep Consumption Time: 2.42221
PPO Batch Consumption Time: 0.28620
Total Iteration Time: 4.88197

Cumulative Model Updates: 108,244
Cumulative Timesteps: 902,602,988

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51,140.50563
Policy Entropy: 3.70540
Value Function Loss: 0.02259

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.14653
Policy Update Magnitude: 0.41314
Value Function Update Magnitude: 0.39807

Collected Steps per Second: 20,813.84810
Overall Steps per Second: 10,143.20625

Timestep Collection Time: 2.40225
Timestep Consumption Time: 2.52716
PPO Batch Consumption Time: 0.29853
Total Iteration Time: 4.92941

Cumulative Model Updates: 108,250
Cumulative Timesteps: 902,652,988

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 902652988...
Checkpoint 902652988 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,180.74049
Policy Entropy: 3.70412
Value Function Loss: 0.02458

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.14120
Policy Update Magnitude: 0.43756
Value Function Update Magnitude: 0.39089

Collected Steps per Second: 21,488.35134
Overall Steps per Second: 10,420.26992

Timestep Collection Time: 2.32852
Timestep Consumption Time: 2.47328
PPO Batch Consumption Time: 0.28769
Total Iteration Time: 4.80179

Cumulative Model Updates: 108,256
Cumulative Timesteps: 902,703,024

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 237,998.39532
Policy Entropy: 3.72238
Value Function Loss: 0.02200

Mean KL Divergence: 0.01108
SB3 Clip Fraction: 0.15155
Policy Update Magnitude: 0.52276
Value Function Update Magnitude: 0.53278

Collected Steps per Second: 21,349.25372
Overall Steps per Second: 10,268.42940

Timestep Collection Time: 2.34313
Timestep Consumption Time: 2.52850
PPO Batch Consumption Time: 0.29751
Total Iteration Time: 4.87163

Cumulative Model Updates: 108,262
Cumulative Timesteps: 902,753,048

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 902753048...
Checkpoint 902753048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 156,151.77360
Policy Entropy: 3.70509
Value Function Loss: 0.02118

Mean KL Divergence: 0.01092
SB3 Clip Fraction: 0.14996
Policy Update Magnitude: 0.50033
Value Function Update Magnitude: 0.59929

Collected Steps per Second: 21,468.51218
Overall Steps per Second: 10,354.94029

Timestep Collection Time: 2.32927
Timestep Consumption Time: 2.49992
PPO Batch Consumption Time: 0.28814
Total Iteration Time: 4.82919

Cumulative Model Updates: 108,268
Cumulative Timesteps: 902,803,054

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 156,151.77360
Policy Entropy: 3.70357
Value Function Loss: 0.01874

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.14515
Policy Update Magnitude: 0.44916
Value Function Update Magnitude: 0.58255

Collected Steps per Second: 21,746.72359
Overall Steps per Second: 10,285.23545

Timestep Collection Time: 2.29984
Timestep Consumption Time: 2.56286
PPO Batch Consumption Time: 0.29847
Total Iteration Time: 4.86270

Cumulative Model Updates: 108,274
Cumulative Timesteps: 902,853,068

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 902853068...
Checkpoint 902853068 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 156,151.77360
Policy Entropy: 3.67305
Value Function Loss: 0.02066

Mean KL Divergence: 0.01057
SB3 Clip Fraction: 0.14724
Policy Update Magnitude: 0.44973
Value Function Update Magnitude: 0.60728

Collected Steps per Second: 21,312.05661
Overall Steps per Second: 10,210.41331

Timestep Collection Time: 2.34703
Timestep Consumption Time: 2.55189
PPO Batch Consumption Time: 0.29760
Total Iteration Time: 4.89892

Cumulative Model Updates: 108,280
Cumulative Timesteps: 902,903,088

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 156,151.77360
Policy Entropy: 3.67629
Value Function Loss: 0.01922

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.14537
Policy Update Magnitude: 0.47562
Value Function Update Magnitude: 0.62162

Collected Steps per Second: 21,667.73475
Overall Steps per Second: 10,326.85604

Timestep Collection Time: 2.30896
Timestep Consumption Time: 2.53569
PPO Batch Consumption Time: 0.29131
Total Iteration Time: 4.84465

Cumulative Model Updates: 108,286
Cumulative Timesteps: 902,953,118

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 902953118...
Checkpoint 902953118 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 411,233.83041
Policy Entropy: 3.66724
Value Function Loss: 0.02528

Mean KL Divergence: 0.01057
SB3 Clip Fraction: 0.14566
Policy Update Magnitude: 0.50678
Value Function Update Magnitude: 0.57510

Collected Steps per Second: 21,397.83775
Overall Steps per Second: 10,027.74834

Timestep Collection Time: 2.33725
Timestep Consumption Time: 2.65012
PPO Batch Consumption Time: 0.31280
Total Iteration Time: 4.98736

Cumulative Model Updates: 108,292
Cumulative Timesteps: 903,003,130

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 333,103.10847
Policy Entropy: 3.68157
Value Function Loss: 0.02381

Mean KL Divergence: 0.01050
SB3 Clip Fraction: 0.14574
Policy Update Magnitude: 0.54812
Value Function Update Magnitude: 0.61494

Collected Steps per Second: 22,275.90994
Overall Steps per Second: 10,336.17871

Timestep Collection Time: 2.24574
Timestep Consumption Time: 2.59415
PPO Batch Consumption Time: 0.30104
Total Iteration Time: 4.83989

Cumulative Model Updates: 108,298
Cumulative Timesteps: 903,053,156

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 903053156...
Checkpoint 903053156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 236,356.33102
Policy Entropy: 3.67112
Value Function Loss: 0.03120

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.14375
Policy Update Magnitude: 0.56449
Value Function Update Magnitude: 0.54033

Collected Steps per Second: 20,652.25537
Overall Steps per Second: 10,187.07083

Timestep Collection Time: 2.42201
Timestep Consumption Time: 2.48813
PPO Batch Consumption Time: 0.30004
Total Iteration Time: 4.91015

Cumulative Model Updates: 108,304
Cumulative Timesteps: 903,103,176

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 435,185.10290
Policy Entropy: 3.68332
Value Function Loss: 0.02886

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.14200
Policy Update Magnitude: 0.59134
Value Function Update Magnitude: 0.51967

Collected Steps per Second: 20,945.41255
Overall Steps per Second: 10,385.24281

Timestep Collection Time: 2.38830
Timestep Consumption Time: 2.42853
PPO Batch Consumption Time: 0.28633
Total Iteration Time: 4.81683

Cumulative Model Updates: 108,310
Cumulative Timesteps: 903,153,200

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 903153200...
Checkpoint 903153200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 503,891.17492
Policy Entropy: 3.67502
Value Function Loss: 0.02855

Mean KL Divergence: 0.01083
SB3 Clip Fraction: 0.14976
Policy Update Magnitude: 0.57207
Value Function Update Magnitude: 0.62095

Collected Steps per Second: 20,111.53955
Overall Steps per Second: 9,921.48431

Timestep Collection Time: 2.48683
Timestep Consumption Time: 2.55415
PPO Batch Consumption Time: 0.29757
Total Iteration Time: 5.04098

Cumulative Model Updates: 108,316
Cumulative Timesteps: 903,203,214

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 175,702.65229
Policy Entropy: 3.69787
Value Function Loss: 0.02487

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.14329
Policy Update Magnitude: 0.56969
Value Function Update Magnitude: 0.67907

Collected Steps per Second: 21,486.42814
Overall Steps per Second: 10,258.86486

Timestep Collection Time: 2.32780
Timestep Consumption Time: 2.54760
PPO Batch Consumption Time: 0.29476
Total Iteration Time: 4.87539

Cumulative Model Updates: 108,322
Cumulative Timesteps: 903,253,230

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 903253230...
Checkpoint 903253230 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 59,509.90455
Policy Entropy: 3.71083
Value Function Loss: 0.02375

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.14631
Policy Update Magnitude: 0.54780
Value Function Update Magnitude: 0.61398

Collected Steps per Second: 21,360.78542
Overall Steps per Second: 10,253.65786

Timestep Collection Time: 2.34074
Timestep Consumption Time: 2.53557
PPO Batch Consumption Time: 0.29739
Total Iteration Time: 4.87631

Cumulative Model Updates: 108,328
Cumulative Timesteps: 903,303,230

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,955.75043
Policy Entropy: 3.72635
Value Function Loss: 0.02521

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.13931
Policy Update Magnitude: 0.53499
Value Function Update Magnitude: 0.64058

Collected Steps per Second: 21,766.07813
Overall Steps per Second: 10,398.80772

Timestep Collection Time: 2.29890
Timestep Consumption Time: 2.51300
PPO Batch Consumption Time: 0.28788
Total Iteration Time: 4.81190

Cumulative Model Updates: 108,334
Cumulative Timesteps: 903,353,268

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 903353268...
Checkpoint 903353268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,130.20965
Policy Entropy: 3.73231
Value Function Loss: 0.02399

Mean KL Divergence: 0.01105
SB3 Clip Fraction: 0.15113
Policy Update Magnitude: 0.56117
Value Function Update Magnitude: 0.57224

Collected Steps per Second: 21,526.19889
Overall Steps per Second: 10,280.14040

Timestep Collection Time: 2.32368
Timestep Consumption Time: 2.54201
PPO Batch Consumption Time: 0.29362
Total Iteration Time: 4.86569

Cumulative Model Updates: 108,340
Cumulative Timesteps: 903,403,288

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,534.98264
Policy Entropy: 3.72086
Value Function Loss: 0.02383

Mean KL Divergence: 0.01069
SB3 Clip Fraction: 0.14856
Policy Update Magnitude: 0.51447
Value Function Update Magnitude: 0.49841

Collected Steps per Second: 21,711.72409
Overall Steps per Second: 10,398.23043

Timestep Collection Time: 2.30318
Timestep Consumption Time: 2.50591
PPO Batch Consumption Time: 0.28776
Total Iteration Time: 4.80909

Cumulative Model Updates: 108,346
Cumulative Timesteps: 903,453,294

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 903453294...
Checkpoint 903453294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 438,338.87245
Policy Entropy: 3.71847
Value Function Loss: 0.02240

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.14668
Policy Update Magnitude: 0.48027
Value Function Update Magnitude: 0.51162

Collected Steps per Second: 21,064.54412
Overall Steps per Second: 10,235.25094

Timestep Collection Time: 2.37432
Timestep Consumption Time: 2.51212
PPO Batch Consumption Time: 0.28799
Total Iteration Time: 4.88645

Cumulative Model Updates: 108,352
Cumulative Timesteps: 903,503,308

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 438,338.87245
Policy Entropy: 3.69519
Value Function Loss: 0.02666

Mean KL Divergence: 0.01058
SB3 Clip Fraction: 0.14996
Policy Update Magnitude: 0.48012
Value Function Update Magnitude: 0.55930

Collected Steps per Second: 21,848.34939
Overall Steps per Second: 10,429.70836

Timestep Collection Time: 2.28942
Timestep Consumption Time: 2.50650
PPO Batch Consumption Time: 0.28821
Total Iteration Time: 4.79592

Cumulative Model Updates: 108,358
Cumulative Timesteps: 903,553,328

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 903553328...
Checkpoint 903553328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 451,033.69596
Policy Entropy: 3.69766
Value Function Loss: 0.02628

Mean KL Divergence: 0.01083
SB3 Clip Fraction: 0.15299
Policy Update Magnitude: 0.52447
Value Function Update Magnitude: 0.67855

Collected Steps per Second: 21,117.74052
Overall Steps per Second: 10,282.62118

Timestep Collection Time: 2.36844
Timestep Consumption Time: 2.49569
PPO Batch Consumption Time: 0.28662
Total Iteration Time: 4.86413

Cumulative Model Updates: 108,364
Cumulative Timesteps: 903,603,344

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 295,928.13410
Policy Entropy: 3.69430
Value Function Loss: 0.02605

Mean KL Divergence: 0.01070
SB3 Clip Fraction: 0.15091
Policy Update Magnitude: 0.52129
Value Function Update Magnitude: 0.67410

Collected Steps per Second: 21,053.24318
Overall Steps per Second: 10,242.63265

Timestep Collection Time: 2.37512
Timestep Consumption Time: 2.50683
PPO Batch Consumption Time: 0.29540
Total Iteration Time: 4.88195

Cumulative Model Updates: 108,370
Cumulative Timesteps: 903,653,348

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 903653348...
Checkpoint 903653348 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 295,928.13410
Policy Entropy: 3.71158
Value Function Loss: 0.02218

Mean KL Divergence: 0.01086
SB3 Clip Fraction: 0.15231
Policy Update Magnitude: 0.50520
Value Function Update Magnitude: 0.71871

Collected Steps per Second: 20,640.95300
Overall Steps per Second: 10,349.18294

Timestep Collection Time: 2.42373
Timestep Consumption Time: 2.41028
PPO Batch Consumption Time: 0.28786
Total Iteration Time: 4.83400

Cumulative Model Updates: 108,376
Cumulative Timesteps: 903,703,376

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 295,928.13410
Policy Entropy: 3.71578
Value Function Loss: 0.02102

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.14415
Policy Update Magnitude: 0.47044
Value Function Update Magnitude: 0.72049

Collected Steps per Second: 20,965.30599
Overall Steps per Second: 10,401.11947

Timestep Collection Time: 2.38604
Timestep Consumption Time: 2.42345
PPO Batch Consumption Time: 0.28770
Total Iteration Time: 4.80948

Cumulative Model Updates: 108,382
Cumulative Timesteps: 903,753,400

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 903753400...
Checkpoint 903753400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 217,816.64923
Policy Entropy: 3.72566
Value Function Loss: 0.01914

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.14960
Policy Update Magnitude: 0.45471
Value Function Update Magnitude: 0.56626

Collected Steps per Second: 20,605.83190
Overall Steps per Second: 10,188.38218

Timestep Collection Time: 2.42679
Timestep Consumption Time: 2.48135
PPO Batch Consumption Time: 0.28788
Total Iteration Time: 4.90814

Cumulative Model Updates: 108,388
Cumulative Timesteps: 903,803,406

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 217,816.64923
Policy Entropy: 3.71490
Value Function Loss: 0.01943

Mean KL Divergence: 0.01127
SB3 Clip Fraction: 0.15473
Policy Update Magnitude: 0.43324
Value Function Update Magnitude: 0.55117

Collected Steps per Second: 21,859.35279
Overall Steps per Second: 10,450.99043

Timestep Collection Time: 2.28781
Timestep Consumption Time: 2.49738
PPO Batch Consumption Time: 0.29043
Total Iteration Time: 4.78519

Cumulative Model Updates: 108,394
Cumulative Timesteps: 903,853,416

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 903853416...
Checkpoint 903853416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 217,816.64923
Policy Entropy: 3.71263
Value Function Loss: 0.02090

Mean KL Divergence: 0.01070
SB3 Clip Fraction: 0.14690
Policy Update Magnitude: 0.43923
Value Function Update Magnitude: 0.59665

Collected Steps per Second: 21,091.12980
Overall Steps per Second: 10,232.04985

Timestep Collection Time: 2.37085
Timestep Consumption Time: 2.51614
PPO Batch Consumption Time: 0.28750
Total Iteration Time: 4.88700

Cumulative Model Updates: 108,400
Cumulative Timesteps: 903,903,420

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 228,550.60351
Policy Entropy: 3.72591
Value Function Loss: 0.02222

Mean KL Divergence: 0.01138
SB3 Clip Fraction: 0.15518
Policy Update Magnitude: 0.51277
Value Function Update Magnitude: 0.71997

Collected Steps per Second: 22,074.63050
Overall Steps per Second: 10,494.38523

Timestep Collection Time: 2.26631
Timestep Consumption Time: 2.50081
PPO Batch Consumption Time: 0.28771
Total Iteration Time: 4.76712

Cumulative Model Updates: 108,406
Cumulative Timesteps: 903,953,448

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 903953448...
Checkpoint 903953448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 185,130.49892
Policy Entropy: 3.72813
Value Function Loss: 0.02241

Mean KL Divergence: 0.01133
SB3 Clip Fraction: 0.15841
Policy Update Magnitude: 0.56055
Value Function Update Magnitude: 0.66654

Collected Steps per Second: 21,683.83578
Overall Steps per Second: 10,281.10239

Timestep Collection Time: 2.30642
Timestep Consumption Time: 2.55804
PPO Batch Consumption Time: 0.29552
Total Iteration Time: 4.86446

Cumulative Model Updates: 108,412
Cumulative Timesteps: 904,003,460

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 315,802.52103
Policy Entropy: 3.74237
Value Function Loss: 0.02184

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.14985
Policy Update Magnitude: 0.52074
Value Function Update Magnitude: 0.65483

Collected Steps per Second: 21,806.86852
Overall Steps per Second: 10,411.40278

Timestep Collection Time: 2.29368
Timestep Consumption Time: 2.51047
PPO Batch Consumption Time: 0.28922
Total Iteration Time: 4.80416

Cumulative Model Updates: 108,418
Cumulative Timesteps: 904,053,478

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 904053478...
Checkpoint 904053478 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 255,806.25832
Policy Entropy: 3.73599
Value Function Loss: 0.02249

Mean KL Divergence: 0.01101
SB3 Clip Fraction: 0.15387
Policy Update Magnitude: 0.49167
Value Function Update Magnitude: 0.66255

Collected Steps per Second: 21,290.36989
Overall Steps per Second: 10,220.49350

Timestep Collection Time: 2.34961
Timestep Consumption Time: 2.54487
PPO Batch Consumption Time: 0.29189
Total Iteration Time: 4.89448

Cumulative Model Updates: 108,424
Cumulative Timesteps: 904,103,502

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 780,186.05135
Policy Entropy: 3.73682
Value Function Loss: 0.02215

Mean KL Divergence: 0.01177
SB3 Clip Fraction: 0.16196
Policy Update Magnitude: 0.54536
Value Function Update Magnitude: 0.69171

Collected Steps per Second: 21,775.10181
Overall Steps per Second: 10,391.57536

Timestep Collection Time: 2.29694
Timestep Consumption Time: 2.51619
PPO Batch Consumption Time: 0.28885
Total Iteration Time: 4.81313

Cumulative Model Updates: 108,430
Cumulative Timesteps: 904,153,518

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 904153518...
Checkpoint 904153518 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 780,186.05135
Policy Entropy: 3.72597
Value Function Loss: 0.02260

Mean KL Divergence: 0.01137
SB3 Clip Fraction: 0.15659
Policy Update Magnitude: 0.53219
Value Function Update Magnitude: 0.64891

Collected Steps per Second: 20,872.15984
Overall Steps per Second: 10,302.90771

Timestep Collection Time: 2.39640
Timestep Consumption Time: 2.45835
PPO Batch Consumption Time: 0.29428
Total Iteration Time: 4.85475

Cumulative Model Updates: 108,436
Cumulative Timesteps: 904,203,536

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 780,186.05135
Policy Entropy: 3.70313
Value Function Loss: 0.02125

Mean KL Divergence: 0.01116
SB3 Clip Fraction: 0.15497
Policy Update Magnitude: 0.49778
Value Function Update Magnitude: 0.60773

Collected Steps per Second: 21,497.81337
Overall Steps per Second: 10,448.66228

Timestep Collection Time: 2.32684
Timestep Consumption Time: 2.46057
PPO Batch Consumption Time: 0.29280
Total Iteration Time: 4.78741

Cumulative Model Updates: 108,442
Cumulative Timesteps: 904,253,558

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 904253558...
Checkpoint 904253558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 780,186.05135
Policy Entropy: 3.68830
Value Function Loss: 0.02229

Mean KL Divergence: 0.01153
SB3 Clip Fraction: 0.16002
Policy Update Magnitude: 0.48476
Value Function Update Magnitude: 0.70865

Collected Steps per Second: 20,850.43514
Overall Steps per Second: 10,196.69240

Timestep Collection Time: 2.39899
Timestep Consumption Time: 2.50652
PPO Batch Consumption Time: 0.29266
Total Iteration Time: 4.90551

Cumulative Model Updates: 108,448
Cumulative Timesteps: 904,303,578

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 780,186.05135
Policy Entropy: 3.68373
Value Function Loss: 0.02102

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.14361
Policy Update Magnitude: 0.47386
Value Function Update Magnitude: 0.68019

Collected Steps per Second: 22,065.71115
Overall Steps per Second: 10,474.84863

Timestep Collection Time: 2.26632
Timestep Consumption Time: 2.50778
PPO Batch Consumption Time: 0.29200
Total Iteration Time: 4.77410

Cumulative Model Updates: 108,454
Cumulative Timesteps: 904,353,586

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 904353586...
Checkpoint 904353586 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 780,186.05135
Policy Entropy: 3.69432
Value Function Loss: 0.02326

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.14745
Policy Update Magnitude: 0.48686
Value Function Update Magnitude: 0.64342

Collected Steps per Second: 21,409.88906
Overall Steps per Second: 10,269.68287

Timestep Collection Time: 2.33593
Timestep Consumption Time: 2.53394
PPO Batch Consumption Time: 0.29975
Total Iteration Time: 4.86987

Cumulative Model Updates: 108,460
Cumulative Timesteps: 904,403,598

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 748,951.10087
Policy Entropy: 3.70589
Value Function Loss: 0.02403

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.13752
Policy Update Magnitude: 0.54270
Value Function Update Magnitude: 0.64487

Collected Steps per Second: 21,940.67042
Overall Steps per Second: 10,395.97726

Timestep Collection Time: 2.27915
Timestep Consumption Time: 2.53098
PPO Batch Consumption Time: 0.29260
Total Iteration Time: 4.81013

Cumulative Model Updates: 108,466
Cumulative Timesteps: 904,453,604

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 904453604...
Checkpoint 904453604 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,248,026.08513
Policy Entropy: 3.72346
Value Function Loss: 0.02514

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.14440
Policy Update Magnitude: 0.54257
Value Function Update Magnitude: 0.63556

Collected Steps per Second: 21,221.12769
Overall Steps per Second: 10,190.41271

Timestep Collection Time: 2.35746
Timestep Consumption Time: 2.55186
PPO Batch Consumption Time: 0.29569
Total Iteration Time: 4.90932

Cumulative Model Updates: 108,472
Cumulative Timesteps: 904,503,632

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,248,026.08513
Policy Entropy: 3.71805
Value Function Loss: 0.02239

Mean KL Divergence: 0.01073
SB3 Clip Fraction: 0.15016
Policy Update Magnitude: 0.55637
Value Function Update Magnitude: 0.61697

Collected Steps per Second: 21,965.14271
Overall Steps per Second: 10,392.99605

Timestep Collection Time: 2.27643
Timestep Consumption Time: 2.53470
PPO Batch Consumption Time: 0.28866
Total Iteration Time: 4.81112

Cumulative Model Updates: 108,478
Cumulative Timesteps: 904,553,634

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 904553634...
Checkpoint 904553634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 687,143.72185
Policy Entropy: 3.73616
Value Function Loss: 0.02023

Mean KL Divergence: 0.01109
SB3 Clip Fraction: 0.15300
Policy Update Magnitude: 0.53627
Value Function Update Magnitude: 0.58265

Collected Steps per Second: 21,694.46629
Overall Steps per Second: 10,271.96389

Timestep Collection Time: 2.30556
Timestep Consumption Time: 2.56381
PPO Batch Consumption Time: 0.29075
Total Iteration Time: 4.86937

Cumulative Model Updates: 108,484
Cumulative Timesteps: 904,603,652

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 450,851.63984
Policy Entropy: 3.71482
Value Function Loss: 0.02017

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.14246
Policy Update Magnitude: 0.49459
Value Function Update Magnitude: 0.56517

Collected Steps per Second: 21,779.98954
Overall Steps per Second: 10,394.88426

Timestep Collection Time: 2.29697
Timestep Consumption Time: 2.51578
PPO Batch Consumption Time: 0.28776
Total Iteration Time: 4.81275

Cumulative Model Updates: 108,490
Cumulative Timesteps: 904,653,680

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 904653680...
Checkpoint 904653680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 490,990.79668
Policy Entropy: 3.72781
Value Function Loss: 0.02144

Mean KL Divergence: 0.01067
SB3 Clip Fraction: 0.14682
Policy Update Magnitude: 0.48453
Value Function Update Magnitude: 0.54651

Collected Steps per Second: 21,363.62388
Overall Steps per Second: 10,289.31221

Timestep Collection Time: 2.34043
Timestep Consumption Time: 2.51898
PPO Batch Consumption Time: 0.29269
Total Iteration Time: 4.85941

Cumulative Model Updates: 108,496
Cumulative Timesteps: 904,703,680

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 597,484.05722
Policy Entropy: 3.71368
Value Function Loss: 0.02492

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.13104
Policy Update Magnitude: 0.58968
Value Function Update Magnitude: 0.55283

Collected Steps per Second: 21,633.29285
Overall Steps per Second: 10,370.05732

Timestep Collection Time: 2.31255
Timestep Consumption Time: 2.51173
PPO Batch Consumption Time: 0.28812
Total Iteration Time: 4.82427

Cumulative Model Updates: 108,502
Cumulative Timesteps: 904,753,708

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 904753708...
Checkpoint 904753708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 119,786.25597
Policy Entropy: 3.71670
Value Function Loss: 0.02583

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.12229
Policy Update Magnitude: 0.70083
Value Function Update Magnitude: 0.65556

Collected Steps per Second: 21,346.87329
Overall Steps per Second: 10,280.16408

Timestep Collection Time: 2.34226
Timestep Consumption Time: 2.52147
PPO Batch Consumption Time: 0.29258
Total Iteration Time: 4.86374

Cumulative Model Updates: 108,508
Cumulative Timesteps: 904,803,708

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 138,790.37631
Policy Entropy: 3.70834
Value Function Loss: 0.02940

Mean KL Divergence: 0.01059
SB3 Clip Fraction: 0.14196
Policy Update Magnitude: 0.65792
Value Function Update Magnitude: 0.65700

Collected Steps per Second: 20,743.41709
Overall Steps per Second: 10,345.02091

Timestep Collection Time: 2.41069
Timestep Consumption Time: 2.42313
PPO Batch Consumption Time: 0.28795
Total Iteration Time: 4.83382

Cumulative Model Updates: 108,514
Cumulative Timesteps: 904,853,714

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 904853714...
Checkpoint 904853714 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 402,744.02117
Policy Entropy: 3.70870
Value Function Loss: 0.03342

Mean KL Divergence: 0.01180
SB3 Clip Fraction: 0.15011
Policy Update Magnitude: 0.68464
Value Function Update Magnitude: 0.64796

Collected Steps per Second: 20,590.92031
Overall Steps per Second: 10,344.02943

Timestep Collection Time: 2.42971
Timestep Consumption Time: 2.40689
PPO Batch Consumption Time: 0.28613
Total Iteration Time: 4.83661

Cumulative Model Updates: 108,520
Cumulative Timesteps: 904,903,744

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,653.90546
Policy Entropy: 3.72943
Value Function Loss: 0.03140

Mean KL Divergence: 0.01187
SB3 Clip Fraction: 0.15252
Policy Update Magnitude: 0.82113
Value Function Update Magnitude: 0.64091

Collected Steps per Second: 20,941.80244
Overall Steps per Second: 10,395.20722

Timestep Collection Time: 2.38824
Timestep Consumption Time: 2.42302
PPO Batch Consumption Time: 0.28779
Total Iteration Time: 4.81126

Cumulative Model Updates: 108,526
Cumulative Timesteps: 904,953,758

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 904953758...
Checkpoint 904953758 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,590.27210
Policy Entropy: 3.74501
Value Function Loss: 0.03417

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.13644
Policy Update Magnitude: 0.89510
Value Function Update Magnitude: 0.64813

Collected Steps per Second: 20,634.52335
Overall Steps per Second: 10,225.46101

Timestep Collection Time: 2.42400
Timestep Consumption Time: 2.46752
PPO Batch Consumption Time: 0.29654
Total Iteration Time: 4.89152

Cumulative Model Updates: 108,532
Cumulative Timesteps: 905,003,776

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 995,093.84526
Policy Entropy: 3.76939
Value Function Loss: 0.03591

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.12331
Policy Update Magnitude: 1.02046
Value Function Update Magnitude: 0.73416

Collected Steps per Second: 20,806.77457
Overall Steps per Second: 10,351.28649

Timestep Collection Time: 2.40402
Timestep Consumption Time: 2.42822
PPO Batch Consumption Time: 0.28835
Total Iteration Time: 4.83225

Cumulative Model Updates: 108,538
Cumulative Timesteps: 905,053,796

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 905053796...
Checkpoint 905053796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,510.88455
Policy Entropy: 3.75132
Value Function Loss: 0.03675

Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.09834
Policy Update Magnitude: 1.08808
Value Function Update Magnitude: 0.78604

Collected Steps per Second: 20,934.68615
Overall Steps per Second: 10,254.33490

Timestep Collection Time: 2.38924
Timestep Consumption Time: 2.48850
PPO Batch Consumption Time: 0.28831
Total Iteration Time: 4.87774

Cumulative Model Updates: 108,544
Cumulative Timesteps: 905,103,814

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,182.87724
Policy Entropy: 3.76901
Value Function Loss: 0.03106

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.11184
Policy Update Magnitude: 1.00660
Value Function Update Magnitude: 1.02185

Collected Steps per Second: 21,565.71862
Overall Steps per Second: 10,373.21285

Timestep Collection Time: 2.31849
Timestep Consumption Time: 2.50161
PPO Batch Consumption Time: 0.29160
Total Iteration Time: 4.82011

Cumulative Model Updates: 108,550
Cumulative Timesteps: 905,153,814

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 905153814...
Checkpoint 905153814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 216,373.39873
Policy Entropy: 3.74166
Value Function Loss: 0.03435

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.10729
Policy Update Magnitude: 0.92404
Value Function Update Magnitude: 0.94783

Collected Steps per Second: 21,282.37634
Overall Steps per Second: 10,345.24740

Timestep Collection Time: 2.35049
Timestep Consumption Time: 2.48497
PPO Batch Consumption Time: 0.29035
Total Iteration Time: 4.83546

Cumulative Model Updates: 108,556
Cumulative Timesteps: 905,203,838

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,483.41561
Policy Entropy: 3.75095
Value Function Loss: 0.03102

Mean KL Divergence: 0.00659
SB3 Clip Fraction: 0.08193
Policy Update Magnitude: 0.89136
Value Function Update Magnitude: 0.80219

Collected Steps per Second: 21,305.03022
Overall Steps per Second: 10,230.22862

Timestep Collection Time: 2.34761
Timestep Consumption Time: 2.54143
PPO Batch Consumption Time: 0.29573
Total Iteration Time: 4.88904

Cumulative Model Updates: 108,562
Cumulative Timesteps: 905,253,854

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 905253854...
Checkpoint 905253854 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,334.00167
Policy Entropy: 3.75564
Value Function Loss: 0.02858

Mean KL Divergence: 0.00694
SB3 Clip Fraction: 0.08518
Policy Update Magnitude: 0.85874
Value Function Update Magnitude: 0.84243

Collected Steps per Second: 21,699.09359
Overall Steps per Second: 10,403.91104

Timestep Collection Time: 2.30581
Timestep Consumption Time: 2.50334
PPO Batch Consumption Time: 0.28859
Total Iteration Time: 4.80915

Cumulative Model Updates: 108,568
Cumulative Timesteps: 905,303,888

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,601.70045
Policy Entropy: 3.75849
Value Function Loss: 0.02589

Mean KL Divergence: 0.00750
SB3 Clip Fraction: 0.09499
Policy Update Magnitude: 0.76523
Value Function Update Magnitude: 0.65347

Collected Steps per Second: 21,333.79162
Overall Steps per Second: 10,373.42634

Timestep Collection Time: 2.34379
Timestep Consumption Time: 2.47641
PPO Batch Consumption Time: 0.28820
Total Iteration Time: 4.82020

Cumulative Model Updates: 108,574
Cumulative Timesteps: 905,353,890

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 905353890...
Checkpoint 905353890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 336,715.03843
Policy Entropy: 3.75450
Value Function Loss: 0.02480

Mean KL Divergence: 0.00679
SB3 Clip Fraction: 0.08353
Policy Update Magnitude: 0.70244
Value Function Update Magnitude: 0.67476

Collected Steps per Second: 21,407.59839
Overall Steps per Second: 10,350.42123

Timestep Collection Time: 2.33637
Timestep Consumption Time: 2.49590
PPO Batch Consumption Time: 0.28615
Total Iteration Time: 4.83227

Cumulative Model Updates: 108,580
Cumulative Timesteps: 905,403,906

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 272,747.92314
Policy Entropy: 3.75759
Value Function Loss: 0.02302

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.09713
Policy Update Magnitude: 0.72736
Value Function Update Magnitude: 0.75623

Collected Steps per Second: 21,442.62287
Overall Steps per Second: 10,328.53827

Timestep Collection Time: 2.33311
Timestep Consumption Time: 2.51056
PPO Batch Consumption Time: 0.28795
Total Iteration Time: 4.84367

Cumulative Model Updates: 108,586
Cumulative Timesteps: 905,453,934

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 905453934...
Checkpoint 905453934 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 272,747.92314
Policy Entropy: 3.76476
Value Function Loss: 0.02164

Mean KL Divergence: 0.01231
SB3 Clip Fraction: 0.15818
Policy Update Magnitude: 0.60836
Value Function Update Magnitude: 0.74789

Collected Steps per Second: 21,537.11448
Overall Steps per Second: 10,333.99993

Timestep Collection Time: 2.32325
Timestep Consumption Time: 2.51864
PPO Batch Consumption Time: 0.29170
Total Iteration Time: 4.84188

Cumulative Model Updates: 108,592
Cumulative Timesteps: 905,503,970

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 272,747.92314
Policy Entropy: 3.76433
Value Function Loss: 0.02257

Mean KL Divergence: 0.01326
SB3 Clip Fraction: 0.17704
Policy Update Magnitude: 0.47472
Value Function Update Magnitude: 0.50909

Collected Steps per Second: 21,222.76591
Overall Steps per Second: 10,315.45006

Timestep Collection Time: 2.35747
Timestep Consumption Time: 2.49273
PPO Batch Consumption Time: 0.28778
Total Iteration Time: 4.85020

Cumulative Model Updates: 108,598
Cumulative Timesteps: 905,554,002

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 905554002...
Checkpoint 905554002 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 188,968.63775
Policy Entropy: 3.76485
Value Function Loss: 0.02508

Mean KL Divergence: 0.01255
SB3 Clip Fraction: 0.16738
Policy Update Magnitude: 0.53711
Value Function Update Magnitude: 0.40427

Collected Steps per Second: 21,008.75718
Overall Steps per Second: 10,244.31636

Timestep Collection Time: 2.38101
Timestep Consumption Time: 2.50190
PPO Batch Consumption Time: 0.28751
Total Iteration Time: 4.88290

Cumulative Model Updates: 108,604
Cumulative Timesteps: 905,604,024

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 389,259.09389
Policy Entropy: 3.73572
Value Function Loss: 0.03344

Mean KL Divergence: 0.01601
SB3 Clip Fraction: 0.19260
Policy Update Magnitude: 0.64420
Value Function Update Magnitude: 0.46510

Collected Steps per Second: 21,375.60573
Overall Steps per Second: 10,178.38723

Timestep Collection Time: 2.33911
Timestep Consumption Time: 2.57325
PPO Batch Consumption Time: 0.30035
Total Iteration Time: 4.91237

Cumulative Model Updates: 108,610
Cumulative Timesteps: 905,654,024

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 905654024...
Checkpoint 905654024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,154.34769
Policy Entropy: 3.73663
Value Function Loss: 0.03550

Mean KL Divergence: 0.01360
SB3 Clip Fraction: 0.17111
Policy Update Magnitude: 0.70604
Value Function Update Magnitude: 0.68985

Collected Steps per Second: 21,725.89646
Overall Steps per Second: 10,278.98565

Timestep Collection Time: 2.30205
Timestep Consumption Time: 2.56361
PPO Batch Consumption Time: 0.29982
Total Iteration Time: 4.86566

Cumulative Model Updates: 108,616
Cumulative Timesteps: 905,704,038

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,313.17721
Policy Entropy: 3.78040
Value Function Loss: 0.04100

Mean KL Divergence: 0.01117
SB3 Clip Fraction: 0.14369
Policy Update Magnitude: 0.82437
Value Function Update Magnitude: 0.73692

Collected Steps per Second: 21,734.03591
Overall Steps per Second: 10,321.38945

Timestep Collection Time: 2.30128
Timestep Consumption Time: 2.54458
PPO Batch Consumption Time: 0.29561
Total Iteration Time: 4.84586

Cumulative Model Updates: 108,622
Cumulative Timesteps: 905,754,054

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 905754054...
Checkpoint 905754054 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,174.32046
Policy Entropy: 3.80507
Value Function Loss: 0.03837

Mean KL Divergence: 0.01088
SB3 Clip Fraction: 0.14394
Policy Update Magnitude: 0.76866
Value Function Update Magnitude: 0.93501

Collected Steps per Second: 21,459.94268
Overall Steps per Second: 10,147.42116

Timestep Collection Time: 2.33132
Timestep Consumption Time: 2.59900
PPO Batch Consumption Time: 0.30387
Total Iteration Time: 4.93032

Cumulative Model Updates: 108,628
Cumulative Timesteps: 905,804,084

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51,400.36854
Policy Entropy: 3.81506
Value Function Loss: 0.04820

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.14153
Policy Update Magnitude: 0.72497
Value Function Update Magnitude: 1.01537

Collected Steps per Second: 21,436.27683
Overall Steps per Second: 10,245.70037

Timestep Collection Time: 2.33333
Timestep Consumption Time: 2.54852
PPO Batch Consumption Time: 0.29797
Total Iteration Time: 4.88185

Cumulative Model Updates: 108,634
Cumulative Timesteps: 905,854,102

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 905854102...
Checkpoint 905854102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,356.07646
Policy Entropy: 3.81616
Value Function Loss: 0.04583

Mean KL Divergence: 0.01105
SB3 Clip Fraction: 0.14261
Policy Update Magnitude: 0.73334
Value Function Update Magnitude: 0.84722

Collected Steps per Second: 21,811.47426
Overall Steps per Second: 10,476.81317

Timestep Collection Time: 2.29255
Timestep Consumption Time: 2.48027
PPO Batch Consumption Time: 0.28659
Total Iteration Time: 4.77283

Cumulative Model Updates: 108,640
Cumulative Timesteps: 905,904,106

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,561.30825
Policy Entropy: 3.78844
Value Function Loss: 0.04580

Mean KL Divergence: 0.01099
SB3 Clip Fraction: 0.14353
Policy Update Magnitude: 0.77849
Value Function Update Magnitude: 0.74689

Collected Steps per Second: 22,062.79653
Overall Steps per Second: 10,487.92864

Timestep Collection Time: 2.26825
Timestep Consumption Time: 2.50333
PPO Batch Consumption Time: 0.28722
Total Iteration Time: 4.77158

Cumulative Model Updates: 108,646
Cumulative Timesteps: 905,954,150

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 905954150...
Checkpoint 905954150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 121.70394
Policy Entropy: 3.78091
Value Function Loss: 0.03766

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.14056
Policy Update Magnitude: 0.74396
Value Function Update Magnitude: 0.74833

Collected Steps per Second: 21,513.21456
Overall Steps per Second: 10,187.72140

Timestep Collection Time: 2.32415
Timestep Consumption Time: 2.58372
PPO Batch Consumption Time: 0.30015
Total Iteration Time: 4.90787

Cumulative Model Updates: 108,652
Cumulative Timesteps: 906,004,150

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,999.08663
Policy Entropy: 3.76894
Value Function Loss: 0.04134

Mean KL Divergence: 0.01095
SB3 Clip Fraction: 0.14613
Policy Update Magnitude: 0.67842
Value Function Update Magnitude: 0.75519

Collected Steps per Second: 21,417.66293
Overall Steps per Second: 10,208.53363

Timestep Collection Time: 2.33527
Timestep Consumption Time: 2.56416
PPO Batch Consumption Time: 0.29591
Total Iteration Time: 4.89943

Cumulative Model Updates: 108,658
Cumulative Timesteps: 906,054,166

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 906054166...
Checkpoint 906054166 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 407.31459
Policy Entropy: 3.78164
Value Function Loss: 0.03990

Mean KL Divergence: 0.01156
SB3 Clip Fraction: 0.15111
Policy Update Magnitude: 0.65139
Value Function Update Magnitude: 0.79280

Collected Steps per Second: 21,609.69790
Overall Steps per Second: 10,375.18728

Timestep Collection Time: 2.31526
Timestep Consumption Time: 2.50702
PPO Batch Consumption Time: 0.28770
Total Iteration Time: 4.82227

Cumulative Model Updates: 108,664
Cumulative Timesteps: 906,104,198

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.91697
Policy Entropy: 3.78149
Value Function Loss: 0.04078

Mean KL Divergence: 0.01134
SB3 Clip Fraction: 0.14808
Policy Update Magnitude: 0.63174
Value Function Update Magnitude: 0.89591

Collected Steps per Second: 21,643.32753
Overall Steps per Second: 10,277.04594

Timestep Collection Time: 2.31129
Timestep Consumption Time: 2.55626
PPO Batch Consumption Time: 0.29600
Total Iteration Time: 4.86755

Cumulative Model Updates: 108,670
Cumulative Timesteps: 906,154,222

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 906154222...
Checkpoint 906154222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89.91697
Policy Entropy: 3.74585
Value Function Loss: 0.03672

Mean KL Divergence: 0.01121
SB3 Clip Fraction: 0.15114
Policy Update Magnitude: 0.59579
Value Function Update Magnitude: 0.68780

Collected Steps per Second: 21,541.15134
Overall Steps per Second: 10,343.10483

Timestep Collection Time: 2.32216
Timestep Consumption Time: 2.51411
PPO Batch Consumption Time: 0.28886
Total Iteration Time: 4.83627

Cumulative Model Updates: 108,676
Cumulative Timesteps: 906,204,244

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,711.88384
Policy Entropy: 3.71466
Value Function Loss: 0.02991

Mean KL Divergence: 0.01101
SB3 Clip Fraction: 0.15272
Policy Update Magnitude: 0.51425
Value Function Update Magnitude: 0.56944

Collected Steps per Second: 21,882.59136
Overall Steps per Second: 10,300.38069

Timestep Collection Time: 2.28611
Timestep Consumption Time: 2.57060
PPO Batch Consumption Time: 0.29822
Total Iteration Time: 4.85671

Cumulative Model Updates: 108,682
Cumulative Timesteps: 906,254,270

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 906254270...
Checkpoint 906254270 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,711.88384
Policy Entropy: 3.70613
Value Function Loss: 0.02579

Mean KL Divergence: 0.01080
SB3 Clip Fraction: 0.15058
Policy Update Magnitude: 0.46586
Value Function Update Magnitude: 0.64969

Collected Steps per Second: 21,876.86651
Overall Steps per Second: 10,419.78754

Timestep Collection Time: 2.28652
Timestep Consumption Time: 2.51415
PPO Batch Consumption Time: 0.28883
Total Iteration Time: 4.80067

Cumulative Model Updates: 108,688
Cumulative Timesteps: 906,304,292

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 729,125.13069
Policy Entropy: 3.70912
Value Function Loss: 0.02618

Mean KL Divergence: 0.01092
SB3 Clip Fraction: 0.15205
Policy Update Magnitude: 0.45990
Value Function Update Magnitude: 0.62660

Collected Steps per Second: 20,890.01123
Overall Steps per Second: 10,286.25129

Timestep Collection Time: 2.39368
Timestep Consumption Time: 2.46757
PPO Batch Consumption Time: 0.29572
Total Iteration Time: 4.86125

Cumulative Model Updates: 108,694
Cumulative Timesteps: 906,354,296

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 906354296...
Checkpoint 906354296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 313,886.35145
Policy Entropy: 3.70051
Value Function Loss: 0.02856

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.14164
Policy Update Magnitude: 0.45365
Value Function Update Magnitude: 0.55912

Collected Steps per Second: 21,077.34554
Overall Steps per Second: 10,432.79541

Timestep Collection Time: 2.37326
Timestep Consumption Time: 2.42143
PPO Batch Consumption Time: 0.28710
Total Iteration Time: 4.79469

Cumulative Model Updates: 108,700
Cumulative Timesteps: 906,404,318

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 240,949.41220
Policy Entropy: 3.70623
Value Function Loss: 0.03122

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.14076
Policy Update Magnitude: 0.45118
Value Function Update Magnitude: 0.50063

Collected Steps per Second: 21,003.56057
Overall Steps per Second: 10,343.14785

Timestep Collection Time: 2.38074
Timestep Consumption Time: 2.45377
PPO Batch Consumption Time: 0.28794
Total Iteration Time: 4.83451

Cumulative Model Updates: 108,706
Cumulative Timesteps: 906,454,322

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 906454322...
Checkpoint 906454322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 240,949.41220
Policy Entropy: 3.70470
Value Function Loss: 0.03027

Mean KL Divergence: 0.01129
SB3 Clip Fraction: 0.15168
Policy Update Magnitude: 0.42608
Value Function Update Magnitude: 0.40994

Collected Steps per Second: 20,972.88723
Overall Steps per Second: 10,296.70712

Timestep Collection Time: 2.38517
Timestep Consumption Time: 2.47308
PPO Batch Consumption Time: 0.28757
Total Iteration Time: 4.85825

Cumulative Model Updates: 108,712
Cumulative Timesteps: 906,504,346

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 240,949.41220
Policy Entropy: 3.69247
Value Function Loss: 0.02874

Mean KL Divergence: 0.01116
SB3 Clip Fraction: 0.15321
Policy Update Magnitude: 0.46413
Value Function Update Magnitude: 0.42807

Collected Steps per Second: 21,746.15051
Overall Steps per Second: 10,444.98697

Timestep Collection Time: 2.30055
Timestep Consumption Time: 2.48912
PPO Batch Consumption Time: 0.28913
Total Iteration Time: 4.78967

Cumulative Model Updates: 108,718
Cumulative Timesteps: 906,554,374

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 906554374...
Checkpoint 906554374 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 82,440.37952
Policy Entropy: 3.70416
Value Function Loss: 0.02833

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.14160
Policy Update Magnitude: 0.50070
Value Function Update Magnitude: 0.57702

Collected Steps per Second: 21,652.94005
Overall Steps per Second: 10,321.23439

Timestep Collection Time: 2.31063
Timestep Consumption Time: 2.53685
PPO Batch Consumption Time: 0.30131
Total Iteration Time: 4.84748

Cumulative Model Updates: 108,724
Cumulative Timesteps: 906,604,406

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,294.44523
Policy Entropy: 3.70264
Value Function Loss: 0.03351

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.14053
Policy Update Magnitude: 0.52136
Value Function Update Magnitude: 0.55437

Collected Steps per Second: 21,726.50639
Overall Steps per Second: 10,440.60872

Timestep Collection Time: 2.30134
Timestep Consumption Time: 2.48766
PPO Batch Consumption Time: 0.28605
Total Iteration Time: 4.78899

Cumulative Model Updates: 108,730
Cumulative Timesteps: 906,654,406

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 906654406...
Checkpoint 906654406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 112,604.95570
Policy Entropy: 3.72312
Value Function Loss: 0.03245

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.14410
Policy Update Magnitude: 0.51623
Value Function Update Magnitude: 0.54709

Collected Steps per Second: 21,453.98698
Overall Steps per Second: 10,205.06500

Timestep Collection Time: 2.33122
Timestep Consumption Time: 2.56968
PPO Batch Consumption Time: 0.30146
Total Iteration Time: 4.90090

Cumulative Model Updates: 108,736
Cumulative Timesteps: 906,704,420

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 113,987.41230
Policy Entropy: 3.70055
Value Function Loss: 0.03328

Mean KL Divergence: 0.01058
SB3 Clip Fraction: 0.14560
Policy Update Magnitude: 0.48979
Value Function Update Magnitude: 0.62268

Collected Steps per Second: 21,557.13829
Overall Steps per Second: 10,334.88846

Timestep Collection Time: 2.31951
Timestep Consumption Time: 2.51866
PPO Batch Consumption Time: 0.28837
Total Iteration Time: 4.83818

Cumulative Model Updates: 108,742
Cumulative Timesteps: 906,754,422

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 906754422...
Checkpoint 906754422 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 76,416.55874
Policy Entropy: 3.73260
Value Function Loss: 0.03133

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.14421
Policy Update Magnitude: 0.48102
Value Function Update Magnitude: 0.55175

Collected Steps per Second: 21,027.79805
Overall Steps per Second: 10,240.08586

Timestep Collection Time: 2.37904
Timestep Consumption Time: 2.50627
PPO Batch Consumption Time: 0.28890
Total Iteration Time: 4.88531

Cumulative Model Updates: 108,748
Cumulative Timesteps: 906,804,448

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,911.10834
Policy Entropy: 3.71285
Value Function Loss: 0.03233

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.13465
Policy Update Magnitude: 0.46181
Value Function Update Magnitude: 0.47828

Collected Steps per Second: 21,237.71043
Overall Steps per Second: 10,194.78619

Timestep Collection Time: 2.35581
Timestep Consumption Time: 2.55180
PPO Batch Consumption Time: 0.29905
Total Iteration Time: 4.90761

Cumulative Model Updates: 108,754
Cumulative Timesteps: 906,854,480

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 906854480...
Checkpoint 906854480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,185.68010
Policy Entropy: 3.72986
Value Function Loss: 0.02736

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.13490
Policy Update Magnitude: 0.47604
Value Function Update Magnitude: 0.53011

Collected Steps per Second: 21,475.59176
Overall Steps per Second: 10,292.46789

Timestep Collection Time: 2.32934
Timestep Consumption Time: 2.53091
PPO Batch Consumption Time: 0.29541
Total Iteration Time: 4.86025

Cumulative Model Updates: 108,760
Cumulative Timesteps: 906,904,504

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 121,538.61776
Policy Entropy: 3.71446
Value Function Loss: 0.02733

Mean KL Divergence: 0.01060
SB3 Clip Fraction: 0.14038
Policy Update Magnitude: 0.46546
Value Function Update Magnitude: 0.55390

Collected Steps per Second: 21,101.22882
Overall Steps per Second: 10,288.74858

Timestep Collection Time: 2.37029
Timestep Consumption Time: 2.49094
PPO Batch Consumption Time: 0.30056
Total Iteration Time: 4.86123

Cumulative Model Updates: 108,766
Cumulative Timesteps: 906,954,520

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 906954520...
Checkpoint 906954520 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 82,360.54326
Policy Entropy: 3.72544
Value Function Loss: 0.02861

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.14175
Policy Update Magnitude: 0.49519
Value Function Update Magnitude: 0.63333

Collected Steps per Second: 20,886.40705
Overall Steps per Second: 10,246.92188

Timestep Collection Time: 2.39400
Timestep Consumption Time: 2.48571
PPO Batch Consumption Time: 0.30115
Total Iteration Time: 4.87971

Cumulative Model Updates: 108,772
Cumulative Timesteps: 907,004,522

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,471.56650
Policy Entropy: 3.72193
Value Function Loss: 0.02789

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.14000
Policy Update Magnitude: 0.51801
Value Function Update Magnitude: 0.69677

Collected Steps per Second: 21,151.23182
Overall Steps per Second: 10,402.18452

Timestep Collection Time: 2.36440
Timestep Consumption Time: 2.44324
PPO Batch Consumption Time: 0.29119
Total Iteration Time: 4.80764

Cumulative Model Updates: 108,778
Cumulative Timesteps: 907,054,532

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 907054532...
Checkpoint 907054532 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 51,611.84637
Policy Entropy: 3.71508
Value Function Loss: 0.03003

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.13792
Policy Update Magnitude: 0.51611
Value Function Update Magnitude: 0.68345

Collected Steps per Second: 20,573.23304
Overall Steps per Second: 10,212.35485

Timestep Collection Time: 2.43054
Timestep Consumption Time: 2.46589
PPO Batch Consumption Time: 0.28679
Total Iteration Time: 4.89642

Cumulative Model Updates: 108,784
Cumulative Timesteps: 907,104,536

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,620.80263
Policy Entropy: 3.72394
Value Function Loss: 0.02754

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.14100
Policy Update Magnitude: 0.51278
Value Function Update Magnitude: 0.68385

Collected Steps per Second: 21,523.75701
Overall Steps per Second: 10,343.33681

Timestep Collection Time: 2.32339
Timestep Consumption Time: 2.51142
PPO Batch Consumption Time: 0.28902
Total Iteration Time: 4.83480

Cumulative Model Updates: 108,790
Cumulative Timesteps: 907,154,544

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 907154544...
Checkpoint 907154544 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,327.30724
Policy Entropy: 3.71434
Value Function Loss: 0.02900

Mean KL Divergence: 0.01084
SB3 Clip Fraction: 0.14335
Policy Update Magnitude: 0.51414
Value Function Update Magnitude: 0.65595

Collected Steps per Second: 21,092.15999
Overall Steps per Second: 10,275.28782

Timestep Collection Time: 2.37159
Timestep Consumption Time: 2.49659
PPO Batch Consumption Time: 0.29176
Total Iteration Time: 4.86818

Cumulative Model Updates: 108,796
Cumulative Timesteps: 907,204,566

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,874.63179
Policy Entropy: 3.72101
Value Function Loss: 0.02784

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.14991
Policy Update Magnitude: 0.48598
Value Function Update Magnitude: 0.57579

Collected Steps per Second: 21,677.99858
Overall Steps per Second: 10,372.03245

Timestep Collection Time: 2.30805
Timestep Consumption Time: 2.51588
PPO Batch Consumption Time: 0.28838
Total Iteration Time: 4.82393

Cumulative Model Updates: 108,802
Cumulative Timesteps: 907,254,600

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 907254600...
Checkpoint 907254600 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89,837.67942
Policy Entropy: 3.72032
Value Function Loss: 0.02701

Mean KL Divergence: 0.01110
SB3 Clip Fraction: 0.14453
Policy Update Magnitude: 0.48869
Value Function Update Magnitude: 0.72875

Collected Steps per Second: 21,386.27647
Overall Steps per Second: 10,325.11519

Timestep Collection Time: 2.33851
Timestep Consumption Time: 2.50521
PPO Batch Consumption Time: 0.28921
Total Iteration Time: 4.84372

Cumulative Model Updates: 108,808
Cumulative Timesteps: 907,304,612

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47,738.34044
Policy Entropy: 3.72155
Value Function Loss: 0.02811

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.13915
Policy Update Magnitude: 0.51262
Value Function Update Magnitude: 0.75574

Collected Steps per Second: 21,685.99489
Overall Steps per Second: 10,371.59064

Timestep Collection Time: 2.30776
Timestep Consumption Time: 2.51754
PPO Batch Consumption Time: 0.28868
Total Iteration Time: 4.82530

Cumulative Model Updates: 108,814
Cumulative Timesteps: 907,354,658

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 907354658...
Checkpoint 907354658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47,738.34044
Policy Entropy: 3.70729
Value Function Loss: 0.02915

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.13658
Policy Update Magnitude: 0.53020
Value Function Update Magnitude: 0.66071

Collected Steps per Second: 21,290.95040
Overall Steps per Second: 10,309.67186

Timestep Collection Time: 2.34945
Timestep Consumption Time: 2.50250
PPO Batch Consumption Time: 0.28745
Total Iteration Time: 4.85195

Cumulative Model Updates: 108,820
Cumulative Timesteps: 907,404,680

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 457,754.14980
Policy Entropy: 3.70226
Value Function Loss: 0.02946

Mean KL Divergence: 0.01147
SB3 Clip Fraction: 0.15152
Policy Update Magnitude: 0.54018
Value Function Update Magnitude: 0.51862

Collected Steps per Second: 21,815.64775
Overall Steps per Second: 10,431.62561

Timestep Collection Time: 2.29340
Timestep Consumption Time: 2.50278
PPO Batch Consumption Time: 0.28695
Total Iteration Time: 4.79618

Cumulative Model Updates: 108,826
Cumulative Timesteps: 907,454,712

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 907454712...
Checkpoint 907454712 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 457,754.14980
Policy Entropy: 3.69366
Value Function Loss: 0.02508

Mean KL Divergence: 0.01183
SB3 Clip Fraction: 0.15756
Policy Update Magnitude: 0.51533
Value Function Update Magnitude: 0.57971

Collected Steps per Second: 21,252.91298
Overall Steps per Second: 10,219.49476

Timestep Collection Time: 2.35309
Timestep Consumption Time: 2.54050
PPO Batch Consumption Time: 0.29376
Total Iteration Time: 4.89359

Cumulative Model Updates: 108,832
Cumulative Timesteps: 907,504,722

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 457,754.14980
Policy Entropy: 3.70315
Value Function Loss: 0.02590

Mean KL Divergence: 0.01092
SB3 Clip Fraction: 0.14513
Policy Update Magnitude: 0.51450
Value Function Update Magnitude: 0.52642

Collected Steps per Second: 20,439.36754
Overall Steps per Second: 10,065.76331

Timestep Collection Time: 2.44734
Timestep Consumption Time: 2.52218
PPO Batch Consumption Time: 0.28692
Total Iteration Time: 4.96952

Cumulative Model Updates: 108,838
Cumulative Timesteps: 907,554,744

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 907554744...
Checkpoint 907554744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 275,769.17814
Policy Entropy: 3.69664
Value Function Loss: 0.02566

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.14285
Policy Update Magnitude: 0.51700
Value Function Update Magnitude: 0.49498

Collected Steps per Second: 21,490.39252
Overall Steps per Second: 10,199.19702

Timestep Collection Time: 2.32839
Timestep Consumption Time: 2.57768
PPO Batch Consumption Time: 0.30037
Total Iteration Time: 4.90607

Cumulative Model Updates: 108,844
Cumulative Timesteps: 907,604,782

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77,896.21183
Policy Entropy: 3.71343
Value Function Loss: 0.03002

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.14294
Policy Update Magnitude: 0.53380
Value Function Update Magnitude: 0.60548

Collected Steps per Second: 21,690.55559
Overall Steps per Second: 10,391.06671

Timestep Collection Time: 2.30626
Timestep Consumption Time: 2.50788
PPO Batch Consumption Time: 0.28892
Total Iteration Time: 4.81414

Cumulative Model Updates: 108,850
Cumulative Timesteps: 907,654,806

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 907654806...
Checkpoint 907654806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,406.77303
Policy Entropy: 3.71314
Value Function Loss: 0.02979

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.13927
Policy Update Magnitude: 0.50450
Value Function Update Magnitude: 0.57286

Collected Steps per Second: 21,550.55303
Overall Steps per Second: 10,261.91544

Timestep Collection Time: 2.32059
Timestep Consumption Time: 2.55277
PPO Batch Consumption Time: 0.29697
Total Iteration Time: 4.87336

Cumulative Model Updates: 108,856
Cumulative Timesteps: 907,704,816

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,406.77303
Policy Entropy: 3.70566
Value Function Loss: 0.03280

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.14312
Policy Update Magnitude: 0.50734
Value Function Update Magnitude: 0.49560

Collected Steps per Second: 20,915.13938
Overall Steps per Second: 10,371.91494

Timestep Collection Time: 2.39138
Timestep Consumption Time: 2.43088
PPO Batch Consumption Time: 0.28885
Total Iteration Time: 4.82225

Cumulative Model Updates: 108,862
Cumulative Timesteps: 907,754,832

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 907754832...
Checkpoint 907754832 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,406.77303
Policy Entropy: 3.69476
Value Function Loss: 0.02909

Mean KL Divergence: 0.01057
SB3 Clip Fraction: 0.14356
Policy Update Magnitude: 0.51145
Value Function Update Magnitude: 0.47184

Collected Steps per Second: 20,765.87686
Overall Steps per Second: 10,292.94048

Timestep Collection Time: 2.40837
Timestep Consumption Time: 2.45049
PPO Batch Consumption Time: 0.29265
Total Iteration Time: 4.85886

Cumulative Model Updates: 108,868
Cumulative Timesteps: 907,804,844

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,406.77303
Policy Entropy: 3.70698
Value Function Loss: 0.02701

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.14212
Policy Update Magnitude: 0.50375
Value Function Update Magnitude: 0.50568

Collected Steps per Second: 21,204.27584
Overall Steps per Second: 10,457.75425

Timestep Collection Time: 2.35858
Timestep Consumption Time: 2.42371
PPO Batch Consumption Time: 0.28683
Total Iteration Time: 4.78229

Cumulative Model Updates: 108,874
Cumulative Timesteps: 907,854,856

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 907854856...
Checkpoint 907854856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 349,387.79446
Policy Entropy: 3.72452
Value Function Loss: 0.02289

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.14424
Policy Update Magnitude: 0.46490
Value Function Update Magnitude: 0.61627

Collected Steps per Second: 20,905.39598
Overall Steps per Second: 10,206.65517

Timestep Collection Time: 2.39173
Timestep Consumption Time: 2.50704
PPO Batch Consumption Time: 0.29349
Total Iteration Time: 4.89876

Cumulative Model Updates: 108,880
Cumulative Timesteps: 907,904,856

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 283,009.27698
Policy Entropy: 3.71563
Value Function Loss: 0.02348

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.14228
Policy Update Magnitude: 0.45223
Value Function Update Magnitude: 0.65326

Collected Steps per Second: 21,781.89150
Overall Steps per Second: 10,437.17887

Timestep Collection Time: 2.29567
Timestep Consumption Time: 2.49528
PPO Batch Consumption Time: 0.29050
Total Iteration Time: 4.79095

Cumulative Model Updates: 108,886
Cumulative Timesteps: 907,954,860

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 907954860...
Checkpoint 907954860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 340,186.46092
Policy Entropy: 3.72453
Value Function Loss: 0.02598

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.14073
Policy Update Magnitude: 0.49410
Value Function Update Magnitude: 0.66893

Collected Steps per Second: 21,372.92995
Overall Steps per Second: 10,235.72143

Timestep Collection Time: 2.34156
Timestep Consumption Time: 2.54779
PPO Batch Consumption Time: 0.30177
Total Iteration Time: 4.88935

Cumulative Model Updates: 108,892
Cumulative Timesteps: 908,004,906

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 173,419.29762
Policy Entropy: 3.72278
Value Function Loss: 0.02891

Mean KL Divergence: 0.01047
SB3 Clip Fraction: 0.14307
Policy Update Magnitude: 0.52608
Value Function Update Magnitude: 0.65311

Collected Steps per Second: 21,554.68765
Overall Steps per Second: 10,362.81646

Timestep Collection Time: 2.32061
Timestep Consumption Time: 2.50626
PPO Batch Consumption Time: 0.28753
Total Iteration Time: 4.82687

Cumulative Model Updates: 108,898
Cumulative Timesteps: 908,054,926

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 908054926...
Checkpoint 908054926 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,452.71827
Policy Entropy: 3.73783
Value Function Loss: 0.03208

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.13747
Policy Update Magnitude: 0.52744
Value Function Update Magnitude: 0.57732

Collected Steps per Second: 21,401.40879
Overall Steps per Second: 10,295.29803

Timestep Collection Time: 2.33648
Timestep Consumption Time: 2.52049
PPO Batch Consumption Time: 0.29231
Total Iteration Time: 4.85697

Cumulative Model Updates: 108,904
Cumulative Timesteps: 908,104,930

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,999.23797
Policy Entropy: 3.72640
Value Function Loss: 0.03141

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.12733
Policy Update Magnitude: 0.50825
Value Function Update Magnitude: 0.50315

Collected Steps per Second: 21,322.79696
Overall Steps per Second: 10,309.49785

Timestep Collection Time: 2.34575
Timestep Consumption Time: 2.50589
PPO Batch Consumption Time: 0.28825
Total Iteration Time: 4.85164

Cumulative Model Updates: 108,910
Cumulative Timesteps: 908,154,948

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 908154948...
Checkpoint 908154948 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 494,254.57040
Policy Entropy: 3.73290
Value Function Loss: 0.02791

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.13936
Policy Update Magnitude: 0.48139
Value Function Update Magnitude: 0.51235

Collected Steps per Second: 21,485.88994
Overall Steps per Second: 10,333.90386

Timestep Collection Time: 2.32850
Timestep Consumption Time: 2.51284
PPO Batch Consumption Time: 0.28996
Total Iteration Time: 4.84135

Cumulative Model Updates: 108,916
Cumulative Timesteps: 908,204,978

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 139,597.32267
Policy Entropy: 3.73220
Value Function Loss: 0.02562

Mean KL Divergence: 0.01076
SB3 Clip Fraction: 0.14344
Policy Update Magnitude: 0.45892
Value Function Update Magnitude: 0.54265

Collected Steps per Second: 21,887.52272
Overall Steps per Second: 10,472.72262

Timestep Collection Time: 2.28532
Timestep Consumption Time: 2.49090
PPO Batch Consumption Time: 0.28612
Total Iteration Time: 4.77622

Cumulative Model Updates: 108,922
Cumulative Timesteps: 908,254,998

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 908254998...
Checkpoint 908254998 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,870.81794
Policy Entropy: 3.73762
Value Function Loss: 0.02495

Mean KL Divergence: 0.01080
SB3 Clip Fraction: 0.14645
Policy Update Magnitude: 0.43213
Value Function Update Magnitude: 0.48874

Collected Steps per Second: 21,649.05321
Overall Steps per Second: 10,250.51260

Timestep Collection Time: 2.31077
Timestep Consumption Time: 2.56957
PPO Batch Consumption Time: 0.30063
Total Iteration Time: 4.88034

Cumulative Model Updates: 108,928
Cumulative Timesteps: 908,305,024

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,870.81794
Policy Entropy: 3.70429
Value Function Loss: 0.02704

Mean KL Divergence: 0.01136
SB3 Clip Fraction: 0.14784
Policy Update Magnitude: 0.42255
Value Function Update Magnitude: 0.52621

Collected Steps per Second: 21,964.05919
Overall Steps per Second: 10,386.26232

Timestep Collection Time: 2.27654
Timestep Consumption Time: 2.53771
PPO Batch Consumption Time: 0.29181
Total Iteration Time: 4.81424

Cumulative Model Updates: 108,934
Cumulative Timesteps: 908,355,026

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 908355026...
Checkpoint 908355026 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,870.81794
Policy Entropy: 3.70622
Value Function Loss: 0.02872

Mean KL Divergence: 0.01050
SB3 Clip Fraction: 0.13910
Policy Update Magnitude: 0.45152
Value Function Update Magnitude: 0.47489

Collected Steps per Second: 20,973.17863
Overall Steps per Second: 10,209.07938

Timestep Collection Time: 2.38505
Timestep Consumption Time: 2.51471
PPO Batch Consumption Time: 0.28731
Total Iteration Time: 4.89976

Cumulative Model Updates: 108,940
Cumulative Timesteps: 908,405,048

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 251,626.95087
Policy Entropy: 3.69244
Value Function Loss: 0.03307

Mean KL Divergence: 0.01084
SB3 Clip Fraction: 0.14344
Policy Update Magnitude: 0.47862
Value Function Update Magnitude: 0.50003

Collected Steps per Second: 21,474.01908
Overall Steps per Second: 10,187.39305

Timestep Collection Time: 2.32979
Timestep Consumption Time: 2.58118
PPO Batch Consumption Time: 0.30021
Total Iteration Time: 4.91097

Cumulative Model Updates: 108,946
Cumulative Timesteps: 908,455,078

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 908455078...
Checkpoint 908455078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 266,402.23781
Policy Entropy: 3.69188
Value Function Loss: 0.03377

Mean KL Divergence: 0.01123
SB3 Clip Fraction: 0.14308
Policy Update Magnitude: 0.49328
Value Function Update Magnitude: 0.45469

Collected Steps per Second: 21,343.38124
Overall Steps per Second: 10,232.54526

Timestep Collection Time: 2.34386
Timestep Consumption Time: 2.54505
PPO Batch Consumption Time: 0.29667
Total Iteration Time: 4.88891

Cumulative Model Updates: 108,952
Cumulative Timesteps: 908,505,104

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 266,402.23781
Policy Entropy: 3.69224
Value Function Loss: 0.03353

Mean KL Divergence: 0.01159
SB3 Clip Fraction: 0.14752
Policy Update Magnitude: 0.49675
Value Function Update Magnitude: 0.47847

Collected Steps per Second: 21,682.48655
Overall Steps per Second: 10,266.30790

Timestep Collection Time: 2.30629
Timestep Consumption Time: 2.56460
PPO Batch Consumption Time: 0.29595
Total Iteration Time: 4.87088

Cumulative Model Updates: 108,958
Cumulative Timesteps: 908,555,110

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 908555110...
Checkpoint 908555110 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 196,443.45460
Policy Entropy: 3.70764
Value Function Loss: 0.02805

Mean KL Divergence: 0.01093
SB3 Clip Fraction: 0.14562
Policy Update Magnitude: 0.51393
Value Function Update Magnitude: 0.63457

Collected Steps per Second: 21,058.39621
Overall Steps per Second: 10,237.98966

Timestep Collection Time: 2.37492
Timestep Consumption Time: 2.51002
PPO Batch Consumption Time: 0.28569
Total Iteration Time: 4.88494

Cumulative Model Updates: 108,964
Cumulative Timesteps: 908,605,122

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 104,404.09837
Policy Entropy: 3.71837
Value Function Loss: 0.02749

Mean KL Divergence: 0.01073
SB3 Clip Fraction: 0.14142
Policy Update Magnitude: 0.49517
Value Function Update Magnitude: 0.70852

Collected Steps per Second: 21,902.99621
Overall Steps per Second: 10,446.40808

Timestep Collection Time: 2.28352
Timestep Consumption Time: 2.50434
PPO Batch Consumption Time: 0.28692
Total Iteration Time: 4.78787

Cumulative Model Updates: 108,970
Cumulative Timesteps: 908,655,138

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 908655138...
Checkpoint 908655138 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 203,694.86062
Policy Entropy: 3.72037
Value Function Loss: 0.02521

Mean KL Divergence: 0.01084
SB3 Clip Fraction: 0.14480
Policy Update Magnitude: 0.47891
Value Function Update Magnitude: 0.61164

Collected Steps per Second: 21,462.59038
Overall Steps per Second: 10,200.76130

Timestep Collection Time: 2.33103
Timestep Consumption Time: 2.57350
PPO Batch Consumption Time: 0.30189
Total Iteration Time: 4.90454

Cumulative Model Updates: 108,976
Cumulative Timesteps: 908,705,168

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 179,300.71474
Policy Entropy: 3.70761
Value Function Loss: 0.02880

Mean KL Divergence: 0.01059
SB3 Clip Fraction: 0.14174
Policy Update Magnitude: 0.49710
Value Function Update Magnitude: 0.69682

Collected Steps per Second: 21,252.09299
Overall Steps per Second: 10,182.60212

Timestep Collection Time: 2.35327
Timestep Consumption Time: 2.55824
PPO Batch Consumption Time: 0.29674
Total Iteration Time: 4.91151

Cumulative Model Updates: 108,982
Cumulative Timesteps: 908,755,180

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 908755180...
Checkpoint 908755180 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,122.23213
Policy Entropy: 3.72223
Value Function Loss: 0.03010

Mean KL Divergence: 0.01102
SB3 Clip Fraction: 0.14512
Policy Update Magnitude: 0.56899
Value Function Update Magnitude: 0.75393

Collected Steps per Second: 21,247.73123
Overall Steps per Second: 10,210.64004

Timestep Collection Time: 2.35347
Timestep Consumption Time: 2.54397
PPO Batch Consumption Time: 0.29650
Total Iteration Time: 4.89744

Cumulative Model Updates: 108,988
Cumulative Timesteps: 908,805,186

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46,031.43206
Policy Entropy: 3.72040
Value Function Loss: 0.03330

Mean KL Divergence: 0.01165
SB3 Clip Fraction: 0.14335
Policy Update Magnitude: 0.66561
Value Function Update Magnitude: 0.74448

Collected Steps per Second: 20,857.11918
Overall Steps per Second: 10,194.64226

Timestep Collection Time: 2.39822
Timestep Consumption Time: 2.50828
PPO Batch Consumption Time: 0.28770
Total Iteration Time: 4.90650

Cumulative Model Updates: 108,994
Cumulative Timesteps: 908,855,206

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 908855206...
Checkpoint 908855206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 70,070.23585
Policy Entropy: 3.70865
Value Function Loss: 0.03635

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.13970
Policy Update Magnitude: 0.70916
Value Function Update Magnitude: 0.66443

Collected Steps per Second: 21,320.51858
Overall Steps per Second: 10,347.74021

Timestep Collection Time: 2.34638
Timestep Consumption Time: 2.48811
PPO Batch Consumption Time: 0.28661
Total Iteration Time: 4.83449

Cumulative Model Updates: 109,000
Cumulative Timesteps: 908,905,232

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,441.44015
Policy Entropy: 3.71545
Value Function Loss: 0.03423

Mean KL Divergence: 0.01084
SB3 Clip Fraction: 0.14118
Policy Update Magnitude: 0.65294
Value Function Update Magnitude: 0.60825

Collected Steps per Second: 21,831.50434
Overall Steps per Second: 10,437.62443

Timestep Collection Time: 2.29118
Timestep Consumption Time: 2.50109
PPO Batch Consumption Time: 0.28710
Total Iteration Time: 4.79228

Cumulative Model Updates: 109,006
Cumulative Timesteps: 908,955,252

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 908955252...
Checkpoint 908955252 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,441.44015
Policy Entropy: 3.69658
Value Function Loss: 0.03451

Mean KL Divergence: 0.01125
SB3 Clip Fraction: 0.14425
Policy Update Magnitude: 0.59444
Value Function Update Magnitude: 0.53022

Collected Steps per Second: 20,785.28828
Overall Steps per Second: 10,142.25157

Timestep Collection Time: 2.40738
Timestep Consumption Time: 2.52624
PPO Batch Consumption Time: 0.29067
Total Iteration Time: 4.93362

Cumulative Model Updates: 109,012
Cumulative Timesteps: 909,005,290

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 140,333.61763
Policy Entropy: 3.71918
Value Function Loss: 0.03094

Mean KL Divergence: 0.01067
SB3 Clip Fraction: 0.14380
Policy Update Magnitude: 0.58701
Value Function Update Magnitude: 0.53573

Collected Steps per Second: 21,136.67794
Overall Steps per Second: 10,096.71957

Timestep Collection Time: 2.36716
Timestep Consumption Time: 2.58831
PPO Batch Consumption Time: 0.30051
Total Iteration Time: 4.95547

Cumulative Model Updates: 109,018
Cumulative Timesteps: 909,055,324

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 909055324...
Checkpoint 909055324 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 92,072.57810
Policy Entropy: 3.70256
Value Function Loss: 0.03443

Mean KL Divergence: 0.01212
SB3 Clip Fraction: 0.15443
Policy Update Magnitude: 0.61135
Value Function Update Magnitude: 0.52610

Collected Steps per Second: 21,613.92716
Overall Steps per Second: 10,237.53416

Timestep Collection Time: 2.31490
Timestep Consumption Time: 2.57241
PPO Batch Consumption Time: 0.30127
Total Iteration Time: 4.88731

Cumulative Model Updates: 109,024
Cumulative Timesteps: 909,105,358

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 270,689.69962
Policy Entropy: 3.70672
Value Function Loss: 0.03218

Mean KL Divergence: 0.01211
SB3 Clip Fraction: 0.15563
Policy Update Magnitude: 0.63230
Value Function Update Magnitude: 0.81607

Collected Steps per Second: 20,816.73281
Overall Steps per Second: 10,316.33893

Timestep Collection Time: 2.40316
Timestep Consumption Time: 2.44604
PPO Batch Consumption Time: 0.28912
Total Iteration Time: 4.84920

Cumulative Model Updates: 109,030
Cumulative Timesteps: 909,155,384

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 909155384...
Checkpoint 909155384 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 96,600.56048
Policy Entropy: 3.70560
Value Function Loss: 0.03349

Mean KL Divergence: 0.01164
SB3 Clip Fraction: 0.15148
Policy Update Magnitude: 0.70744
Value Function Update Magnitude: 0.94293

Collected Steps per Second: 20,938.16193
Overall Steps per Second: 10,307.84093

Timestep Collection Time: 2.38894
Timestep Consumption Time: 2.46368
PPO Batch Consumption Time: 0.29430
Total Iteration Time: 4.85262

Cumulative Model Updates: 109,036
Cumulative Timesteps: 909,205,404

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,129.98848
Policy Entropy: 3.69880
Value Function Loss: 0.03902

Mean KL Divergence: 0.01184
SB3 Clip Fraction: 0.15022
Policy Update Magnitude: 0.70076
Value Function Update Magnitude: 0.66313

Collected Steps per Second: 21,127.76569
Overall Steps per Second: 10,421.21864

Timestep Collection Time: 2.36674
Timestep Consumption Time: 2.43154
PPO Batch Consumption Time: 0.28921
Total Iteration Time: 4.79829

Cumulative Model Updates: 109,042
Cumulative Timesteps: 909,255,408

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 909255408...
Checkpoint 909255408 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 67,999.35409
Policy Entropy: 3.73113
Value Function Loss: 0.03623

Mean KL Divergence: 0.01213
SB3 Clip Fraction: 0.15265
Policy Update Magnitude: 0.69146
Value Function Update Magnitude: 0.59680

Collected Steps per Second: 20,768.82950
Overall Steps per Second: 10,256.00756

Timestep Collection Time: 2.40851
Timestep Consumption Time: 2.46882
PPO Batch Consumption Time: 0.29633
Total Iteration Time: 4.87734

Cumulative Model Updates: 109,048
Cumulative Timesteps: 909,305,430

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,575.76059
Policy Entropy: 3.72322
Value Function Loss: 0.03550

Mean KL Divergence: 0.01333
SB3 Clip Fraction: 0.16080
Policy Update Magnitude: 0.65399
Value Function Update Magnitude: 0.62534

Collected Steps per Second: 20,868.54668
Overall Steps per Second: 10,099.93970

Timestep Collection Time: 2.39729
Timestep Consumption Time: 2.55600
PPO Batch Consumption Time: 0.30083
Total Iteration Time: 4.95330

Cumulative Model Updates: 109,054
Cumulative Timesteps: 909,355,458

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 909355458...
Checkpoint 909355458 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 225,813.14846
Policy Entropy: 3.73197
Value Function Loss: 0.03528

Mean KL Divergence: 0.01261
SB3 Clip Fraction: 0.16729
Policy Update Magnitude: 0.63313
Value Function Update Magnitude: 0.59519

Collected Steps per Second: 21,275.52240
Overall Steps per Second: 10,230.10245

Timestep Collection Time: 2.35096
Timestep Consumption Time: 2.53833
PPO Batch Consumption Time: 0.30057
Total Iteration Time: 4.88930

Cumulative Model Updates: 109,060
Cumulative Timesteps: 909,405,476

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,336.89167
Policy Entropy: 3.73622
Value Function Loss: 0.03469

Mean KL Divergence: 0.01288
SB3 Clip Fraction: 0.16877
Policy Update Magnitude: 0.61774
Value Function Update Magnitude: 0.62481

Collected Steps per Second: 21,509.76804
Overall Steps per Second: 10,382.86201

Timestep Collection Time: 2.32453
Timestep Consumption Time: 2.49110
PPO Batch Consumption Time: 0.29075
Total Iteration Time: 4.81563

Cumulative Model Updates: 109,066
Cumulative Timesteps: 909,455,476

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 909455476...
Checkpoint 909455476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,210.59278
Policy Entropy: 3.73147
Value Function Loss: 0.03619

Mean KL Divergence: 0.01177
SB3 Clip Fraction: 0.15362
Policy Update Magnitude: 0.64973
Value Function Update Magnitude: 0.63374

Collected Steps per Second: 21,562.31197
Overall Steps per Second: 10,319.86592

Timestep Collection Time: 2.31988
Timestep Consumption Time: 2.52727
PPO Batch Consumption Time: 0.29892
Total Iteration Time: 4.84716

Cumulative Model Updates: 109,072
Cumulative Timesteps: 909,505,498

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,210.59278
Policy Entropy: 3.73898
Value Function Loss: 0.03051

Mean KL Divergence: 0.00670
SB3 Clip Fraction: 0.08413
Policy Update Magnitude: 0.82066
Value Function Update Magnitude: 0.56690

Collected Steps per Second: 21,614.50524
Overall Steps per Second: 10,313.61181

Timestep Collection Time: 2.31335
Timestep Consumption Time: 2.53480
PPO Batch Consumption Time: 0.29290
Total Iteration Time: 4.84816

Cumulative Model Updates: 109,078
Cumulative Timesteps: 909,555,500

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 909555500...
Checkpoint 909555500 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,210.59278
Policy Entropy: 3.72529
Value Function Loss: 0.02693

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.10424
Policy Update Magnitude: 0.85154
Value Function Update Magnitude: 0.54803

Collected Steps per Second: 21,383.08222
Overall Steps per Second: 10,215.41744

Timestep Collection Time: 2.33876
Timestep Consumption Time: 2.55678
PPO Batch Consumption Time: 0.29775
Total Iteration Time: 4.89554

Cumulative Model Updates: 109,084
Cumulative Timesteps: 909,605,510

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,210.59278
Policy Entropy: 3.72001
Value Function Loss: 0.02056

Mean KL Divergence: 0.00658
SB3 Clip Fraction: 0.08223
Policy Update Magnitude: 0.73516
Value Function Update Magnitude: 0.53478

Collected Steps per Second: 21,494.27450
Overall Steps per Second: 10,329.38359

Timestep Collection Time: 2.32704
Timestep Consumption Time: 2.51526
PPO Batch Consumption Time: 0.28829
Total Iteration Time: 4.84230

Cumulative Model Updates: 109,090
Cumulative Timesteps: 909,655,528

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 909655528...
Checkpoint 909655528 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,210.59278
Policy Entropy: 3.72350
Value Function Loss: 0.01930

Mean KL Divergence: 0.00687
SB3 Clip Fraction: 0.08586
Policy Update Magnitude: 0.64291
Value Function Update Magnitude: 0.56979

Collected Steps per Second: 21,743.80708
Overall Steps per Second: 10,341.83248

Timestep Collection Time: 2.30052
Timestep Consumption Time: 2.53634
PPO Batch Consumption Time: 0.29295
Total Iteration Time: 4.83686

Cumulative Model Updates: 109,096
Cumulative Timesteps: 909,705,550

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 545,669.55282
Policy Entropy: 3.74479
Value Function Loss: 0.01964

Mean KL Divergence: 0.00643
SB3 Clip Fraction: 0.07868
Policy Update Magnitude: 0.64123
Value Function Update Magnitude: 0.60041

Collected Steps per Second: 21,510.63478
Overall Steps per Second: 10,343.23525

Timestep Collection Time: 2.32499
Timestep Consumption Time: 2.51025
PPO Batch Consumption Time: 0.28836
Total Iteration Time: 4.83524

Cumulative Model Updates: 109,102
Cumulative Timesteps: 909,755,562

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 909755562...
Checkpoint 909755562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 234,916.17439
Policy Entropy: 3.75340
Value Function Loss: 0.02079

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.11182
Policy Update Magnitude: 0.62549
Value Function Update Magnitude: 0.58210

Collected Steps per Second: 21,734.40368
Overall Steps per Second: 10,312.81816

Timestep Collection Time: 2.30142
Timestep Consumption Time: 2.54885
PPO Batch Consumption Time: 0.29786
Total Iteration Time: 4.85027

Cumulative Model Updates: 109,108
Cumulative Timesteps: 909,805,582

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 234,916.17439
Policy Entropy: 3.75736
Value Function Loss: 0.01797

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.10397
Policy Update Magnitude: 0.65090
Value Function Update Magnitude: 0.61484

Collected Steps per Second: 21,950.74835
Overall Steps per Second: 10,461.63436

Timestep Collection Time: 2.27874
Timestep Consumption Time: 2.50254
PPO Batch Consumption Time: 0.28737
Total Iteration Time: 4.78128

Cumulative Model Updates: 109,114
Cumulative Timesteps: 909,855,602

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 909855602...
Checkpoint 909855602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 262,188.34007
Policy Entropy: 3.73203
Value Function Loss: 0.01928

Mean KL Divergence: 0.00678
SB3 Clip Fraction: 0.08206
Policy Update Magnitude: 0.67490
Value Function Update Magnitude: 0.67996

Collected Steps per Second: 20,921.13207
Overall Steps per Second: 10,292.19742

Timestep Collection Time: 2.39098
Timestep Consumption Time: 2.46921
PPO Batch Consumption Time: 0.29911
Total Iteration Time: 4.86019

Cumulative Model Updates: 109,120
Cumulative Timesteps: 909,905,624

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63,546.83552
Policy Entropy: 3.74728
Value Function Loss: 0.02234

Mean KL Divergence: 0.00744
SB3 Clip Fraction: 0.09404
Policy Update Magnitude: 0.68719
Value Function Update Magnitude: 0.63003

Collected Steps per Second: 20,985.51064
Overall Steps per Second: 10,353.29308

Timestep Collection Time: 2.38260
Timestep Consumption Time: 2.44679
PPO Batch Consumption Time: 0.29080
Total Iteration Time: 4.82938

Cumulative Model Updates: 109,126
Cumulative Timesteps: 909,955,624

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 909955624...
Checkpoint 909955624 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,794.92634
Policy Entropy: 3.73682
Value Function Loss: 0.02465

Mean KL Divergence: 0.01919
SB3 Clip Fraction: 0.24501
Policy Update Magnitude: 0.56275
Value Function Update Magnitude: 0.56487

Collected Steps per Second: 21,065.42670
Overall Steps per Second: 10,301.56967

Timestep Collection Time: 2.37574
Timestep Consumption Time: 2.48235
PPO Batch Consumption Time: 0.29960
Total Iteration Time: 4.85809

Cumulative Model Updates: 109,132
Cumulative Timesteps: 910,005,670

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 468,145.79834
Policy Entropy: 3.75445
Value Function Loss: 0.03004

Mean KL Divergence: 0.01475
SB3 Clip Fraction: 0.18765
Policy Update Magnitude: 0.49117
Value Function Update Magnitude: 0.64267

Collected Steps per Second: 20,948.64076
Overall Steps per Second: 10,270.79063

Timestep Collection Time: 2.38679
Timestep Consumption Time: 2.48138
PPO Batch Consumption Time: 0.28773
Total Iteration Time: 4.86817

Cumulative Model Updates: 109,138
Cumulative Timesteps: 910,055,670

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 910055670...
Checkpoint 910055670 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,877.36787
Policy Entropy: 3.74870
Value Function Loss: 0.03395

Mean KL Divergence: 0.01218
SB3 Clip Fraction: 0.15204
Policy Update Magnitude: 0.63859
Value Function Update Magnitude: 0.69888

Collected Steps per Second: 21,057.64239
Overall Steps per Second: 10,324.09658

Timestep Collection Time: 2.37633
Timestep Consumption Time: 2.47058
PPO Batch Consumption Time: 0.28602
Total Iteration Time: 4.84691

Cumulative Model Updates: 109,144
Cumulative Timesteps: 910,105,710

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,342.72323
Policy Entropy: 3.75989
Value Function Loss: 0.03376

Mean KL Divergence: 0.01205
SB3 Clip Fraction: 0.15523
Policy Update Magnitude: 0.66285
Value Function Update Magnitude: 0.68991

Collected Steps per Second: 21,757.04213
Overall Steps per Second: 10,461.18824

Timestep Collection Time: 2.29847
Timestep Consumption Time: 2.48186
PPO Batch Consumption Time: 0.28726
Total Iteration Time: 4.78034

Cumulative Model Updates: 109,150
Cumulative Timesteps: 910,155,718

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 910155718...
Checkpoint 910155718 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,177.03522
Policy Entropy: 3.75651
Value Function Loss: 0.03193

Mean KL Divergence: 0.01263
SB3 Clip Fraction: 0.16405
Policy Update Magnitude: 0.62881
Value Function Update Magnitude: 0.63836

Collected Steps per Second: 21,539.80352
Overall Steps per Second: 10,307.88664

Timestep Collection Time: 2.32193
Timestep Consumption Time: 2.53008
PPO Batch Consumption Time: 0.29899
Total Iteration Time: 4.85201

Cumulative Model Updates: 109,156
Cumulative Timesteps: 910,205,732

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87,488.26755
Policy Entropy: 3.74917
Value Function Loss: 0.02708

Mean KL Divergence: 0.01423
SB3 Clip Fraction: 0.17768
Policy Update Magnitude: 0.62794
Value Function Update Magnitude: 0.63732

Collected Steps per Second: 21,812.12539
Overall Steps per Second: 10,316.83406

Timestep Collection Time: 2.29322
Timestep Consumption Time: 2.55517
PPO Batch Consumption Time: 0.29736
Total Iteration Time: 4.84839

Cumulative Model Updates: 109,162
Cumulative Timesteps: 910,255,752

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 910255752...
Checkpoint 910255752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,190.66034
Policy Entropy: 3.75940
Value Function Loss: 0.02502

Mean KL Divergence: 0.02080
SB3 Clip Fraction: 0.24458
Policy Update Magnitude: 0.55391
Value Function Update Magnitude: 0.71156

Collected Steps per Second: 21,461.21045
Overall Steps per Second: 10,225.74624

Timestep Collection Time: 2.33100
Timestep Consumption Time: 2.56117
PPO Batch Consumption Time: 0.29662
Total Iteration Time: 4.89216

Cumulative Model Updates: 109,168
Cumulative Timesteps: 910,305,778

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,705.92550
Policy Entropy: 3.79568
Value Function Loss: 0.02813

Mean KL Divergence: 0.01795
SB3 Clip Fraction: 0.21864
Policy Update Magnitude: 0.54033
Value Function Update Magnitude: 0.87046

Collected Steps per Second: 21,592.01074
Overall Steps per Second: 10,352.06760

Timestep Collection Time: 2.31595
Timestep Consumption Time: 2.51458
PPO Batch Consumption Time: 0.28889
Total Iteration Time: 4.83053

Cumulative Model Updates: 109,174
Cumulative Timesteps: 910,355,784

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 910355784...
Checkpoint 910355784 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 174,252.93497
Policy Entropy: 3.81317
Value Function Loss: 0.03520

Mean KL Divergence: 0.01412
SB3 Clip Fraction: 0.18254
Policy Update Magnitude: 0.61864
Value Function Update Magnitude: 0.88345

Collected Steps per Second: 21,475.02195
Overall Steps per Second: 10,274.50339

Timestep Collection Time: 2.32968
Timestep Consumption Time: 2.53965
PPO Batch Consumption Time: 0.29366
Total Iteration Time: 4.86934

Cumulative Model Updates: 109,180
Cumulative Timesteps: 910,405,814

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,158.93694
Policy Entropy: 3.84631
Value Function Loss: 0.03922

Mean KL Divergence: 0.01423
SB3 Clip Fraction: 0.17729
Policy Update Magnitude: 0.64915
Value Function Update Magnitude: 0.85170

Collected Steps per Second: 21,508.06604
Overall Steps per Second: 10,359.63800

Timestep Collection Time: 2.32508
Timestep Consumption Time: 2.50211
PPO Batch Consumption Time: 0.28793
Total Iteration Time: 4.82720

Cumulative Model Updates: 109,186
Cumulative Timesteps: 910,455,822

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 910455822...
Checkpoint 910455822 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,593.38187
Policy Entropy: 3.85396
Value Function Loss: 0.04433

Mean KL Divergence: 0.01278
SB3 Clip Fraction: 0.16000
Policy Update Magnitude: 0.66861
Value Function Update Magnitude: 0.75685

Collected Steps per Second: 21,733.32593
Overall Steps per Second: 10,339.67633

Timestep Collection Time: 2.30181
Timestep Consumption Time: 2.53645
PPO Batch Consumption Time: 0.29359
Total Iteration Time: 4.83826

Cumulative Model Updates: 109,192
Cumulative Timesteps: 910,505,848

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,905.47025
Policy Entropy: 3.83465
Value Function Loss: 0.03644

Mean KL Divergence: 0.01209
SB3 Clip Fraction: 0.15380
Policy Update Magnitude: 0.67300
Value Function Update Magnitude: 0.69908

Collected Steps per Second: 21,543.18379
Overall Steps per Second: 10,355.40362

Timestep Collection Time: 2.32138
Timestep Consumption Time: 2.50798
PPO Batch Consumption Time: 0.28804
Total Iteration Time: 4.82936

Cumulative Model Updates: 109,198
Cumulative Timesteps: 910,555,858

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 910555858...
Checkpoint 910555858 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 56,252.32084
Policy Entropy: 3.78756
Value Function Loss: 0.03474

Mean KL Divergence: 0.01139
SB3 Clip Fraction: 0.15232
Policy Update Magnitude: 0.64380
Value Function Update Magnitude: 0.68852

Collected Steps per Second: 21,847.16266
Overall Steps per Second: 10,294.17789

Timestep Collection Time: 2.28881
Timestep Consumption Time: 2.56869
PPO Batch Consumption Time: 0.29778
Total Iteration Time: 4.85750

Cumulative Model Updates: 109,204
Cumulative Timesteps: 910,605,862

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,894.48708
Policy Entropy: 3.75999
Value Function Loss: 0.02703

Mean KL Divergence: 0.01122
SB3 Clip Fraction: 0.15408
Policy Update Magnitude: 0.56398
Value Function Update Magnitude: 0.67800

Collected Steps per Second: 21,920.84662
Overall Steps per Second: 10,471.70601

Timestep Collection Time: 2.28166
Timestep Consumption Time: 2.49464
PPO Batch Consumption Time: 0.28634
Total Iteration Time: 4.77630

Cumulative Model Updates: 109,210
Cumulative Timesteps: 910,655,878

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 910655878...
Checkpoint 910655878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,894.48708
Policy Entropy: 3.73803
Value Function Loss: 0.02372

Mean KL Divergence: 0.01118
SB3 Clip Fraction: 0.15025
Policy Update Magnitude: 0.46814
Value Function Update Magnitude: 0.59022

Collected Steps per Second: 20,574.12902
Overall Steps per Second: 10,203.56868

Timestep Collection Time: 2.43092
Timestep Consumption Time: 2.47070
PPO Batch Consumption Time: 0.29677
Total Iteration Time: 4.90162

Cumulative Model Updates: 109,216
Cumulative Timesteps: 910,705,892

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,894.48708
Policy Entropy: 3.72977
Value Function Loss: 0.01913

Mean KL Divergence: 0.01135
SB3 Clip Fraction: 0.15663
Policy Update Magnitude: 0.43592
Value Function Update Magnitude: 0.50157

Collected Steps per Second: 21,301.59816
Overall Steps per Second: 10,493.45414

Timestep Collection Time: 2.34837
Timestep Consumption Time: 2.41879
PPO Batch Consumption Time: 0.28654
Total Iteration Time: 4.76716

Cumulative Model Updates: 109,222
Cumulative Timesteps: 910,755,916

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 910755916...
Checkpoint 910755916 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,236.85772
Policy Entropy: 3.70728
Value Function Loss: 0.01977

Mean KL Divergence: 0.01121
SB3 Clip Fraction: 0.15173
Policy Update Magnitude: 0.40952
Value Function Update Magnitude: 0.47049

Collected Steps per Second: 20,938.35729
Overall Steps per Second: 10,157.50263

Timestep Collection Time: 2.38834
Timestep Consumption Time: 2.53491
PPO Batch Consumption Time: 0.29623
Total Iteration Time: 4.92326

Cumulative Model Updates: 109,228
Cumulative Timesteps: 910,805,924

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 313,373.86351
Policy Entropy: 3.72018
Value Function Loss: 0.02104

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.14621
Policy Update Magnitude: 0.40305
Value Function Update Magnitude: 0.47159

Collected Steps per Second: 21,500.00679
Overall Steps per Second: 10,378.07726

Timestep Collection Time: 2.32614
Timestep Consumption Time: 2.49287
PPO Batch Consumption Time: 0.28786
Total Iteration Time: 4.81900

Cumulative Model Updates: 109,234
Cumulative Timesteps: 910,855,936

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 910855936...
Checkpoint 910855936 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 130,818.48594
Policy Entropy: 3.72848
Value Function Loss: 0.02279

Mean KL Divergence: 0.01111
SB3 Clip Fraction: 0.15403
Policy Update Magnitude: 0.39337
Value Function Update Magnitude: 0.45076

Collected Steps per Second: 21,378.85356
Overall Steps per Second: 10,278.55513

Timestep Collection Time: 2.33941
Timestep Consumption Time: 2.52644
PPO Batch Consumption Time: 0.29650
Total Iteration Time: 4.86586

Cumulative Model Updates: 109,240
Cumulative Timesteps: 910,905,950

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,949.65101
Policy Entropy: 3.74898
Value Function Loss: 0.02308

Mean KL Divergence: 0.01081
SB3 Clip Fraction: 0.14897
Policy Update Magnitude: 0.40757
Value Function Update Magnitude: 0.45753

Collected Steps per Second: 21,434.22642
Overall Steps per Second: 10,362.36710

Timestep Collection Time: 2.33346
Timestep Consumption Time: 2.49323
PPO Batch Consumption Time: 0.28745
Total Iteration Time: 4.82670

Cumulative Model Updates: 109,246
Cumulative Timesteps: 910,955,966

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 910955966...
Checkpoint 910955966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,246.08645
Policy Entropy: 3.73813
Value Function Loss: 0.02116

Mean KL Divergence: 0.01096
SB3 Clip Fraction: 0.15201
Policy Update Magnitude: 0.40490
Value Function Update Magnitude: 0.45665

Collected Steps per Second: 21,587.73715
Overall Steps per Second: 10,312.88734

Timestep Collection Time: 2.31687
Timestep Consumption Time: 2.53298
PPO Batch Consumption Time: 0.29183
Total Iteration Time: 4.84985

Cumulative Model Updates: 109,252
Cumulative Timesteps: 911,005,982

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 155,192.23503
Policy Entropy: 3.72580
Value Function Loss: 0.02210

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.15047
Policy Update Magnitude: 0.38410
Value Function Update Magnitude: 0.41115

Collected Steps per Second: 21,586.10948
Overall Steps per Second: 10,365.58092

Timestep Collection Time: 2.31705
Timestep Consumption Time: 2.50815
PPO Batch Consumption Time: 0.28733
Total Iteration Time: 4.82520

Cumulative Model Updates: 109,258
Cumulative Timesteps: 911,055,998

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 911055998...
Checkpoint 911055998 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 167,902.39956
Policy Entropy: 3.72716
Value Function Loss: 0.02190

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.14759
Policy Update Magnitude: 0.41296
Value Function Update Magnitude: 0.42940

Collected Steps per Second: 21,696.71145
Overall Steps per Second: 10,304.06928

Timestep Collection Time: 2.30680
Timestep Consumption Time: 2.55050
PPO Batch Consumption Time: 0.29530
Total Iteration Time: 4.85730

Cumulative Model Updates: 109,264
Cumulative Timesteps: 911,106,048

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 139,184.20573
Policy Entropy: 3.73300
Value Function Loss: 0.02432

Mean KL Divergence: 0.01071
SB3 Clip Fraction: 0.14549
Policy Update Magnitude: 0.47298
Value Function Update Magnitude: 0.61683

Collected Steps per Second: 21,672.07790
Overall Steps per Second: 10,372.43165

Timestep Collection Time: 2.30896
Timestep Consumption Time: 2.51537
PPO Batch Consumption Time: 0.28856
Total Iteration Time: 4.82433

Cumulative Model Updates: 109,270
Cumulative Timesteps: 911,156,088

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 911156088...
Checkpoint 911156088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,380.96059
Policy Entropy: 3.75109
Value Function Loss: 0.02533

Mean KL Divergence: 0.01095
SB3 Clip Fraction: 0.14325
Policy Update Magnitude: 0.50345
Value Function Update Magnitude: 0.79913

Collected Steps per Second: 21,538.42894
Overall Steps per Second: 10,297.47075

Timestep Collection Time: 2.32162
Timestep Consumption Time: 2.53433
PPO Batch Consumption Time: 0.29456
Total Iteration Time: 4.85595

Cumulative Model Updates: 109,276
Cumulative Timesteps: 911,206,092

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48,786.98792
Policy Entropy: 3.75180
Value Function Loss: 0.02758

Mean KL Divergence: 0.01057
SB3 Clip Fraction: 0.14055
Policy Update Magnitude: 0.49930
Value Function Update Magnitude: 0.88802

Collected Steps per Second: 21,706.27882
Overall Steps per Second: 10,394.98187

Timestep Collection Time: 2.30357
Timestep Consumption Time: 2.50663
PPO Batch Consumption Time: 0.28837
Total Iteration Time: 4.81021

Cumulative Model Updates: 109,282
Cumulative Timesteps: 911,256,094

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 911256094...
Checkpoint 911256094 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 56,234.27335
Policy Entropy: 3.75970
Value Function Loss: 0.03046

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.13721
Policy Update Magnitude: 0.50601
Value Function Update Magnitude: 0.80753

Collected Steps per Second: 21,465.89884
Overall Steps per Second: 10,260.20696

Timestep Collection Time: 2.33011
Timestep Consumption Time: 2.54484
PPO Batch Consumption Time: 0.29552
Total Iteration Time: 4.87495

Cumulative Model Updates: 109,288
Cumulative Timesteps: 911,306,112

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,440.16345
Policy Entropy: 3.75319
Value Function Loss: 0.03137

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.13843
Policy Update Magnitude: 0.50047
Value Function Update Magnitude: 0.79549

Collected Steps per Second: 21,173.88062
Overall Steps per Second: 10,157.29076

Timestep Collection Time: 2.36187
Timestep Consumption Time: 2.56168
PPO Batch Consumption Time: 0.29833
Total Iteration Time: 4.92356

Cumulative Model Updates: 109,294
Cumulative Timesteps: 911,356,122

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 911356122...
Checkpoint 911356122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 80,558.60198
Policy Entropy: 3.74162
Value Function Loss: 0.03154

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.12862
Policy Update Magnitude: 0.52163
Value Function Update Magnitude: 0.71054

Collected Steps per Second: 21,409.72225
Overall Steps per Second: 10,231.34999

Timestep Collection Time: 2.33595
Timestep Consumption Time: 2.55217
PPO Batch Consumption Time: 0.29607
Total Iteration Time: 4.88811

Cumulative Model Updates: 109,300
Cumulative Timesteps: 911,406,134

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,143.63604
Policy Entropy: 3.74202
Value Function Loss: 0.02742

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.13979
Policy Update Magnitude: 0.56242
Value Function Update Magnitude: 0.76763

Collected Steps per Second: 21,790.16284
Overall Steps per Second: 10,272.40877

Timestep Collection Time: 2.29590
Timestep Consumption Time: 2.57423
PPO Batch Consumption Time: 0.29931
Total Iteration Time: 4.87013

Cumulative Model Updates: 109,306
Cumulative Timesteps: 911,456,162

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 911456162...
Checkpoint 911456162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,367.31347
Policy Entropy: 3.72114
Value Function Loss: 0.03096

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.12986
Policy Update Magnitude: 0.53907
Value Function Update Magnitude: 0.92417

Collected Steps per Second: 21,244.95017
Overall Steps per Second: 10,229.30665

Timestep Collection Time: 2.35454
Timestep Consumption Time: 2.53553
PPO Batch Consumption Time: 0.29246
Total Iteration Time: 4.89007

Cumulative Model Updates: 109,312
Cumulative Timesteps: 911,506,184

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,878.56648
Policy Entropy: 3.74276
Value Function Loss: 0.02835

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.14239
Policy Update Magnitude: 0.56560
Value Function Update Magnitude: 0.87701

Collected Steps per Second: 21,397.30777
Overall Steps per Second: 10,339.62008

Timestep Collection Time: 2.33758
Timestep Consumption Time: 2.49992
PPO Batch Consumption Time: 0.28849
Total Iteration Time: 4.83751

Cumulative Model Updates: 109,318
Cumulative Timesteps: 911,556,202

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 911556202...
Checkpoint 911556202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 147,744.54986
Policy Entropy: 3.71056
Value Function Loss: 0.03524

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.13825
Policy Update Magnitude: 0.54993
Value Function Update Magnitude: 0.84423

Collected Steps per Second: 21,534.97280
Overall Steps per Second: 10,282.96661

Timestep Collection Time: 2.32264
Timestep Consumption Time: 2.54152
PPO Batch Consumption Time: 0.29362
Total Iteration Time: 4.86416

Cumulative Model Updates: 109,324
Cumulative Timesteps: 911,606,220

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,205.84801
Policy Entropy: 3.72311
Value Function Loss: 0.03166

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.14412
Policy Update Magnitude: 0.59349
Value Function Update Magnitude: 0.82159

Collected Steps per Second: 21,752.97176
Overall Steps per Second: 10,393.85238

Timestep Collection Time: 2.29982
Timestep Consumption Time: 2.51341
PPO Batch Consumption Time: 0.28806
Total Iteration Time: 4.81323

Cumulative Model Updates: 109,330
Cumulative Timesteps: 911,656,248

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 911656248...
Checkpoint 911656248 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,011.61353
Policy Entropy: 3.71577
Value Function Loss: 0.03617

Mean KL Divergence: 0.01134
SB3 Clip Fraction: 0.15190
Policy Update Magnitude: 0.58733
Value Function Update Magnitude: 0.72225

Collected Steps per Second: 21,716.06413
Overall Steps per Second: 10,325.76779

Timestep Collection Time: 2.30272
Timestep Consumption Time: 2.54012
PPO Batch Consumption Time: 0.29628
Total Iteration Time: 4.84284

Cumulative Model Updates: 109,336
Cumulative Timesteps: 911,706,254

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,486.01306
Policy Entropy: 3.73322
Value Function Loss: 0.02905

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.14231
Policy Update Magnitude: 0.57225
Value Function Update Magnitude: 0.80620

Collected Steps per Second: 20,954.20040
Overall Steps per Second: 10,375.20392

Timestep Collection Time: 2.38816
Timestep Consumption Time: 2.43507
PPO Batch Consumption Time: 0.28885
Total Iteration Time: 4.82323

Cumulative Model Updates: 109,342
Cumulative Timesteps: 911,756,296

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 911756296...
Checkpoint 911756296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,486.01306
Policy Entropy: 3.72093
Value Function Loss: 0.02572

Mean KL Divergence: 0.01197
SB3 Clip Fraction: 0.16119
Policy Update Magnitude: 0.54472
Value Function Update Magnitude: 0.79904

Collected Steps per Second: 21,053.23930
Overall Steps per Second: 10,272.10167

Timestep Collection Time: 2.37645
Timestep Consumption Time: 2.49422
PPO Batch Consumption Time: 0.30009
Total Iteration Time: 4.87067

Cumulative Model Updates: 109,348
Cumulative Timesteps: 911,806,328

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,486.01306
Policy Entropy: 3.72167
Value Function Loss: 0.02233

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.15012
Policy Update Magnitude: 0.48020
Value Function Update Magnitude: 0.62618

Collected Steps per Second: 20,939.49138
Overall Steps per Second: 10,385.79331

Timestep Collection Time: 2.38860
Timestep Consumption Time: 2.42721
PPO Batch Consumption Time: 0.28774
Total Iteration Time: 4.81581

Cumulative Model Updates: 109,354
Cumulative Timesteps: 911,856,344

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 911856344...
Checkpoint 911856344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87,396.20810
Policy Entropy: 3.71010
Value Function Loss: 0.02058

Mean KL Divergence: 0.01124
SB3 Clip Fraction: 0.15771
Policy Update Magnitude: 0.43269
Value Function Update Magnitude: 0.57590

Collected Steps per Second: 20,778.73161
Overall Steps per Second: 10,210.86700

Timestep Collection Time: 2.40640
Timestep Consumption Time: 2.49054
PPO Batch Consumption Time: 0.28777
Total Iteration Time: 4.89694

Cumulative Model Updates: 109,360
Cumulative Timesteps: 911,906,346

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,474.86553
Policy Entropy: 3.71372
Value Function Loss: 0.02118

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.14919
Policy Update Magnitude: 0.43194
Value Function Update Magnitude: 0.71572

Collected Steps per Second: 21,638.92299
Overall Steps per Second: 10,415.55247

Timestep Collection Time: 2.31121
Timestep Consumption Time: 2.49046
PPO Batch Consumption Time: 0.28872
Total Iteration Time: 4.80167

Cumulative Model Updates: 109,366
Cumulative Timesteps: 911,956,358

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 911956358...
Checkpoint 911956358 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,474.86553
Policy Entropy: 3.71075
Value Function Loss: 0.02655

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.13719
Policy Update Magnitude: 0.48976
Value Function Update Magnitude: 0.75037

Collected Steps per Second: 21,584.28515
Overall Steps per Second: 10,315.29586

Timestep Collection Time: 2.31872
Timestep Consumption Time: 2.53310
PPO Batch Consumption Time: 0.29188
Total Iteration Time: 4.85182

Cumulative Model Updates: 109,372
Cumulative Timesteps: 912,006,406

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 287,860.04617
Policy Entropy: 3.72239
Value Function Loss: 0.02829

Mean KL Divergence: 0.01067
SB3 Clip Fraction: 0.14739
Policy Update Magnitude: 0.53409
Value Function Update Magnitude: 0.71484

Collected Steps per Second: 21,777.31590
Overall Steps per Second: 10,402.79509

Timestep Collection Time: 2.29606
Timestep Consumption Time: 2.51053
PPO Batch Consumption Time: 0.28833
Total Iteration Time: 4.80659

Cumulative Model Updates: 109,378
Cumulative Timesteps: 912,056,408

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 912056408...
Checkpoint 912056408 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 123,948.66300
Policy Entropy: 3.71940
Value Function Loss: 0.02827

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.14014
Policy Update Magnitude: 0.52727
Value Function Update Magnitude: 0.67050

Collected Steps per Second: 21,635.57224
Overall Steps per Second: 10,281.33961

Timestep Collection Time: 2.31101
Timestep Consumption Time: 2.55217
PPO Batch Consumption Time: 0.29800
Total Iteration Time: 4.86318

Cumulative Model Updates: 109,384
Cumulative Timesteps: 912,106,408

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,223.07016
Policy Entropy: 3.72827
Value Function Loss: 0.02460

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.14213
Policy Update Magnitude: 0.51993
Value Function Update Magnitude: 0.65058

Collected Steps per Second: 21,620.45968
Overall Steps per Second: 10,361.21562

Timestep Collection Time: 2.31299
Timestep Consumption Time: 2.51347
PPO Batch Consumption Time: 0.28852
Total Iteration Time: 4.82646

Cumulative Model Updates: 109,390
Cumulative Timesteps: 912,156,416

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 912156416...
Checkpoint 912156416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,616.27218
Policy Entropy: 3.71479
Value Function Loss: 0.03026

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.14302
Policy Update Magnitude: 0.50848
Value Function Update Magnitude: 0.59667

Collected Steps per Second: 21,710.84911
Overall Steps per Second: 10,318.74535

Timestep Collection Time: 2.30410
Timestep Consumption Time: 2.54377
PPO Batch Consumption Time: 0.29678
Total Iteration Time: 4.84788

Cumulative Model Updates: 109,396
Cumulative Timesteps: 912,206,440

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 98,125.99789
Policy Entropy: 3.72928
Value Function Loss: 0.02949

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.14433
Policy Update Magnitude: 0.53469
Value Function Update Magnitude: 0.61329

Collected Steps per Second: 21,725.85139
Overall Steps per Second: 10,405.01428

Timestep Collection Time: 2.30242
Timestep Consumption Time: 2.50507
PPO Batch Consumption Time: 0.28802
Total Iteration Time: 4.80749

Cumulative Model Updates: 109,402
Cumulative Timesteps: 912,256,462

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 912256462...
Checkpoint 912256462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 98,125.99789
Policy Entropy: 3.70413
Value Function Loss: 0.03167

Mean KL Divergence: 0.01061
SB3 Clip Fraction: 0.14528
Policy Update Magnitude: 0.52148
Value Function Update Magnitude: 0.58782

Collected Steps per Second: 20,473.56724
Overall Steps per Second: 10,236.34593

Timestep Collection Time: 2.44393
Timestep Consumption Time: 2.44414
PPO Batch Consumption Time: 0.28933
Total Iteration Time: 4.88807

Cumulative Model Updates: 109,408
Cumulative Timesteps: 912,306,498

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 98,125.99789
Policy Entropy: 3.71463
Value Function Loss: 0.02194

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.14621
Policy Update Magnitude: 0.46190
Value Function Update Magnitude: 0.64960

Collected Steps per Second: 20,770.09087
Overall Steps per Second: 10,233.91209

Timestep Collection Time: 2.40875
Timestep Consumption Time: 2.47990
PPO Batch Consumption Time: 0.29690
Total Iteration Time: 4.88865

Cumulative Model Updates: 109,414
Cumulative Timesteps: 912,356,528

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 912356528...
Checkpoint 912356528 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 98,125.99789
Policy Entropy: 3.70021
Value Function Loss: 0.01915

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.15107
Policy Update Magnitude: 0.39841
Value Function Update Magnitude: 0.58106

Collected Steps per Second: 20,999.31957
Overall Steps per Second: 10,411.26733

Timestep Collection Time: 2.38189
Timestep Consumption Time: 2.42233
PPO Batch Consumption Time: 0.28815
Total Iteration Time: 4.80422

Cumulative Model Updates: 109,420
Cumulative Timesteps: 912,406,546

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 98,125.99789
Policy Entropy: 3.71116
Value Function Loss: 0.01707

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.14209
Policy Update Magnitude: 0.35786
Value Function Update Magnitude: 0.48473

Collected Steps per Second: 21,080.42644
Overall Steps per Second: 10,155.23086

Timestep Collection Time: 2.37234
Timestep Consumption Time: 2.55221
PPO Batch Consumption Time: 0.30035
Total Iteration Time: 4.92456

Cumulative Model Updates: 109,426
Cumulative Timesteps: 912,456,556

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 912456556...
Checkpoint 912456556 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 98,125.99789
Policy Entropy: 3.70866
Value Function Loss: 0.02034

Mean KL Divergence: 0.01072
SB3 Clip Fraction: 0.15094
Policy Update Magnitude: 0.38825
Value Function Update Magnitude: 0.43131

Collected Steps per Second: 21,363.20616
Overall Steps per Second: 10,284.73352

Timestep Collection Time: 2.34066
Timestep Consumption Time: 2.52130
PPO Batch Consumption Time: 0.29844
Total Iteration Time: 4.86196

Cumulative Model Updates: 109,432
Cumulative Timesteps: 912,506,560

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79,245.16691
Policy Entropy: 3.71302
Value Function Loss: 0.02337

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.14729
Policy Update Magnitude: 0.45335
Value Function Update Magnitude: 0.49203

Collected Steps per Second: 21,962.51403
Overall Steps per Second: 10,339.45100

Timestep Collection Time: 2.27661
Timestep Consumption Time: 2.55924
PPO Batch Consumption Time: 0.29529
Total Iteration Time: 4.83585

Cumulative Model Updates: 109,438
Cumulative Timesteps: 912,556,560

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 912556560...
Checkpoint 912556560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,896.11840
Policy Entropy: 3.73173
Value Function Loss: 0.02154

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.14789
Policy Update Magnitude: 0.49197
Value Function Update Magnitude: 0.63361

Collected Steps per Second: 21,762.89925
Overall Steps per Second: 10,269.69887

Timestep Collection Time: 2.29859
Timestep Consumption Time: 2.57244
PPO Batch Consumption Time: 0.29918
Total Iteration Time: 4.87103

Cumulative Model Updates: 109,444
Cumulative Timesteps: 912,606,584

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97,846.88119
Policy Entropy: 3.73136
Value Function Loss: 0.02353

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.14211
Policy Update Magnitude: 0.49634
Value Function Update Magnitude: 0.78697

Collected Steps per Second: 21,914.79131
Overall Steps per Second: 10,403.13912

Timestep Collection Time: 2.28193
Timestep Consumption Time: 2.52508
PPO Batch Consumption Time: 0.29148
Total Iteration Time: 4.80701

Cumulative Model Updates: 109,450
Cumulative Timesteps: 912,656,592

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 912656592...
Checkpoint 912656592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,988.60192
Policy Entropy: 3.72899
Value Function Loss: 0.02486

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.14172
Policy Update Magnitude: 0.56098
Value Function Update Magnitude: 0.80781

Collected Steps per Second: 21,546.10771
Overall Steps per Second: 10,226.64078

Timestep Collection Time: 2.32116
Timestep Consumption Time: 2.56920
PPO Batch Consumption Time: 0.30093
Total Iteration Time: 4.89036

Cumulative Model Updates: 109,456
Cumulative Timesteps: 912,706,604

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 177,949.13156
Policy Entropy: 3.70673
Value Function Loss: 0.02826

Mean KL Divergence: 0.01102
SB3 Clip Fraction: 0.15067
Policy Update Magnitude: 0.58777
Value Function Update Magnitude: 0.72979

Collected Steps per Second: 21,722.16032
Overall Steps per Second: 10,375.73824

Timestep Collection Time: 2.30226
Timestep Consumption Time: 2.51764
PPO Batch Consumption Time: 0.28893
Total Iteration Time: 4.81990

Cumulative Model Updates: 109,462
Cumulative Timesteps: 912,756,614

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 912756614...
Checkpoint 912756614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 235,466.53106
Policy Entropy: 3.69610
Value Function Loss: 0.03081

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.14785
Policy Update Magnitude: 0.55154
Value Function Update Magnitude: 0.66602

Collected Steps per Second: 21,478.03096
Overall Steps per Second: 10,261.22350

Timestep Collection Time: 2.32926
Timestep Consumption Time: 2.54618
PPO Batch Consumption Time: 0.29593
Total Iteration Time: 4.87544

Cumulative Model Updates: 109,468
Cumulative Timesteps: 912,806,642

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 125,142.54517
Policy Entropy: 3.68495
Value Function Loss: 0.03140

Mean KL Divergence: 0.01106
SB3 Clip Fraction: 0.14978
Policy Update Magnitude: 0.52374
Value Function Update Magnitude: 0.52083

Collected Steps per Second: 21,684.86388
Overall Steps per Second: 10,370.15342

Timestep Collection Time: 2.30585
Timestep Consumption Time: 2.51587
PPO Batch Consumption Time: 0.29131
Total Iteration Time: 4.82172

Cumulative Model Updates: 109,474
Cumulative Timesteps: 912,856,644

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 912856644...
Checkpoint 912856644 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 558,766.12745
Policy Entropy: 3.69183
Value Function Loss: 0.03265

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.13918
Policy Update Magnitude: 0.54877
Value Function Update Magnitude: 0.54139

Collected Steps per Second: 21,317.19552
Overall Steps per Second: 10,333.32612

Timestep Collection Time: 2.34599
Timestep Consumption Time: 2.49369
PPO Batch Consumption Time: 0.28640
Total Iteration Time: 4.83968

Cumulative Model Updates: 109,480
Cumulative Timesteps: 912,906,654

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 366,610.08939
Policy Entropy: 3.69938
Value Function Loss: 0.03261

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.13731
Policy Update Magnitude: 0.60041
Value Function Update Magnitude: 0.52491

Collected Steps per Second: 21,775.01043
Overall Steps per Second: 10,416.37979

Timestep Collection Time: 2.29630
Timestep Consumption Time: 2.50402
PPO Batch Consumption Time: 0.28692
Total Iteration Time: 4.80032

Cumulative Model Updates: 109,486
Cumulative Timesteps: 912,956,656

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 912956656...
Checkpoint 912956656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 366,610.08939
Policy Entropy: 3.69851
Value Function Loss: 0.03106

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.14470
Policy Update Magnitude: 0.57624
Value Function Update Magnitude: 0.48960

Collected Steps per Second: 21,295.71938
Overall Steps per Second: 10,168.13406

Timestep Collection Time: 2.34855
Timestep Consumption Time: 2.57015
PPO Batch Consumption Time: 0.29788
Total Iteration Time: 4.91870

Cumulative Model Updates: 109,492
Cumulative Timesteps: 913,006,670

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 259,416.89001
Policy Entropy: 3.70260
Value Function Loss: 0.02892

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.13837
Policy Update Magnitude: 0.54016
Value Function Update Magnitude: 0.49326

Collected Steps per Second: 19,066.80323
Overall Steps per Second: 9,729.67555

Timestep Collection Time: 2.62309
Timestep Consumption Time: 2.51726
PPO Batch Consumption Time: 0.28604
Total Iteration Time: 5.14036

Cumulative Model Updates: 109,498
Cumulative Timesteps: 913,056,684

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 913056684...
Checkpoint 913056684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 209,200.41332
Policy Entropy: 3.69413
Value Function Loss: 0.02732

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.15228
Policy Update Magnitude: 0.50805
Value Function Update Magnitude: 0.45619

Collected Steps per Second: 21,238.12979
Overall Steps per Second: 10,163.63856

Timestep Collection Time: 2.35444
Timestep Consumption Time: 2.56545
PPO Batch Consumption Time: 0.29762
Total Iteration Time: 4.91989

Cumulative Model Updates: 109,504
Cumulative Timesteps: 913,106,688

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 285,263.95581
Policy Entropy: 3.71190
Value Function Loss: 0.02662

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.13784
Policy Update Magnitude: 0.52141
Value Function Update Magnitude: 0.57935

Collected Steps per Second: 21,396.87089
Overall Steps per Second: 10,193.20837

Timestep Collection Time: 2.33772
Timestep Consumption Time: 2.56946
PPO Batch Consumption Time: 0.29710
Total Iteration Time: 4.90719

Cumulative Model Updates: 109,510
Cumulative Timesteps: 913,156,708

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 913156708...
Checkpoint 913156708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 98,198.76705
Policy Entropy: 3.74103
Value Function Loss: 0.02692

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.13359
Policy Update Magnitude: 0.58778
Value Function Update Magnitude: 0.80340

Collected Steps per Second: 21,528.30849
Overall Steps per Second: 10,380.90604

Timestep Collection Time: 2.32364
Timestep Consumption Time: 2.49521
PPO Batch Consumption Time: 0.28797
Total Iteration Time: 4.81885

Cumulative Model Updates: 109,516
Cumulative Timesteps: 913,206,732

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,748.49432
Policy Entropy: 3.75302
Value Function Loss: 0.02789

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.12574
Policy Update Magnitude: 0.72429
Value Function Update Magnitude: 0.69615

Collected Steps per Second: 21,858.37904
Overall Steps per Second: 10,453.15824

Timestep Collection Time: 2.28873
Timestep Consumption Time: 2.49719
PPO Batch Consumption Time: 0.28784
Total Iteration Time: 4.78592

Cumulative Model Updates: 109,522
Cumulative Timesteps: 913,256,760

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 913256760...
Checkpoint 913256760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 110,588.18223
Policy Entropy: 3.75341
Value Function Loss: 0.02579

Mean KL Divergence: 0.00716
SB3 Clip Fraction: 0.08967
Policy Update Magnitude: 0.84039
Value Function Update Magnitude: 0.77328

Collected Steps per Second: 21,364.44082
Overall Steps per Second: 10,296.37138

Timestep Collection Time: 2.34099
Timestep Consumption Time: 2.51645
PPO Batch Consumption Time: 0.29148
Total Iteration Time: 4.85744

Cumulative Model Updates: 109,528
Cumulative Timesteps: 913,306,774

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50,386.09036
Policy Entropy: 3.71692
Value Function Loss: 0.02619

Mean KL Divergence: 0.01132
SB3 Clip Fraction: 0.14818
Policy Update Magnitude: 0.82773
Value Function Update Magnitude: 0.73147

Collected Steps per Second: 20,637.32072
Overall Steps per Second: 10,020.98117

Timestep Collection Time: 2.42425
Timestep Consumption Time: 2.56828
PPO Batch Consumption Time: 0.29580
Total Iteration Time: 4.99253

Cumulative Model Updates: 109,534
Cumulative Timesteps: 913,356,804

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 913356804...
Checkpoint 913356804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 50,386.09036
Policy Entropy: 3.72225
Value Function Loss: 0.02189

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.12693
Policy Update Magnitude: 0.69936
Value Function Update Magnitude: 0.59629

Collected Steps per Second: 21,351.34294
Overall Steps per Second: 10,213.07302

Timestep Collection Time: 2.34234
Timestep Consumption Time: 2.55453
PPO Batch Consumption Time: 0.29583
Total Iteration Time: 4.89686

Cumulative Model Updates: 109,540
Cumulative Timesteps: 913,406,816

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 153,614.82038
Policy Entropy: 3.71159
Value Function Loss: 0.02112

Mean KL Divergence: 0.01111
SB3 Clip Fraction: 0.15086
Policy Update Magnitude: 0.61199
Value Function Update Magnitude: 0.61942

Collected Steps per Second: 21,755.71272
Overall Steps per Second: 10,390.40593

Timestep Collection Time: 2.29907
Timestep Consumption Time: 2.51479
PPO Batch Consumption Time: 0.28846
Total Iteration Time: 4.81386

Cumulative Model Updates: 109,546
Cumulative Timesteps: 913,456,834

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 913456834...
Checkpoint 913456834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 70,830.92206
Policy Entropy: 3.71421
Value Function Loss: 0.02407

Mean KL Divergence: 0.01269
SB3 Clip Fraction: 0.16946
Policy Update Magnitude: 0.56296
Value Function Update Magnitude: 0.63050

Collected Steps per Second: 21,531.26670
Overall Steps per Second: 10,285.73198

Timestep Collection Time: 2.32295
Timestep Consumption Time: 2.53971
PPO Batch Consumption Time: 0.29415
Total Iteration Time: 4.86266

Cumulative Model Updates: 109,552
Cumulative Timesteps: 913,506,850

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 106,880.03828
Policy Entropy: 3.74566
Value Function Loss: 0.02841

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.11684
Policy Update Magnitude: 0.74550
Value Function Update Magnitude: 0.56407

Collected Steps per Second: 21,704.90487
Overall Steps per Second: 10,383.34366

Timestep Collection Time: 2.30409
Timestep Consumption Time: 2.51228
PPO Batch Consumption Time: 0.28847
Total Iteration Time: 4.81637

Cumulative Model Updates: 109,558
Cumulative Timesteps: 913,556,860

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 913556860...
Checkpoint 913556860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86,583.37348
Policy Entropy: 3.75116
Value Function Loss: 0.02913

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.09736
Policy Update Magnitude: 0.80671
Value Function Update Magnitude: 0.53229

Collected Steps per Second: 21,589.20705
Overall Steps per Second: 10,283.65537

Timestep Collection Time: 2.31634
Timestep Consumption Time: 2.54652
PPO Batch Consumption Time: 0.29166
Total Iteration Time: 4.86286

Cumulative Model Updates: 109,564
Cumulative Timesteps: 913,606,868

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86,583.37348
Policy Entropy: 3.75782
Value Function Loss: 0.02601

Mean KL Divergence: 0.00673
SB3 Clip Fraction: 0.08325
Policy Update Magnitude: 0.75930
Value Function Update Magnitude: 0.60337

Collected Steps per Second: 21,750.54106
Overall Steps per Second: 10,345.49039

Timestep Collection Time: 2.29935
Timestep Consumption Time: 2.53484
PPO Batch Consumption Time: 0.28820
Total Iteration Time: 4.83418

Cumulative Model Updates: 109,570
Cumulative Timesteps: 913,656,880

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 913656880...
Checkpoint 913656880 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 82,045.32066
Policy Entropy: 3.74013
Value Function Loss: 0.02240

Mean KL Divergence: 0.00704
SB3 Clip Fraction: 0.08827
Policy Update Magnitude: 0.68763
Value Function Update Magnitude: 0.68979

Collected Steps per Second: 21,149.10802
Overall Steps per Second: 10,280.68485

Timestep Collection Time: 2.36530
Timestep Consumption Time: 2.50052
PPO Batch Consumption Time: 0.28788
Total Iteration Time: 4.86582

Cumulative Model Updates: 109,576
Cumulative Timesteps: 913,706,904

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53,827.40609
Policy Entropy: 3.74406
Value Function Loss: 0.02018

Mean KL Divergence: 0.00520
SB3 Clip Fraction: 0.05893
Policy Update Magnitude: 0.70346
Value Function Update Magnitude: 0.80348

Collected Steps per Second: 22,006.61157
Overall Steps per Second: 10,426.16969

Timestep Collection Time: 2.27386
Timestep Consumption Time: 2.52560
PPO Batch Consumption Time: 0.28975
Total Iteration Time: 4.79946

Cumulative Model Updates: 109,582
Cumulative Timesteps: 913,756,944

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 913756944...
Checkpoint 913756944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 53,827.40609
Policy Entropy: 3.75027
Value Function Loss: 0.01684

Mean KL Divergence: 0.00640
SB3 Clip Fraction: 0.07856
Policy Update Magnitude: 0.65435
Value Function Update Magnitude: 0.73705

Collected Steps per Second: 21,586.57440
Overall Steps per Second: 10,280.52370

Timestep Collection Time: 2.31829
Timestep Consumption Time: 2.54955
PPO Batch Consumption Time: 0.29586
Total Iteration Time: 4.86785

Cumulative Model Updates: 109,588
Cumulative Timesteps: 913,806,988

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 216,114.21760
Policy Entropy: 3.70475
Value Function Loss: 0.02570

Mean KL Divergence: 0.02219
SB3 Clip Fraction: 0.25194
Policy Update Magnitude: 0.52331
Value Function Update Magnitude: 0.65014

Collected Steps per Second: 21,303.00680
Overall Steps per Second: 10,159.31601

Timestep Collection Time: 2.34831
Timestep Consumption Time: 2.57584
PPO Batch Consumption Time: 0.29764
Total Iteration Time: 4.92415

Cumulative Model Updates: 109,594
Cumulative Timesteps: 913,857,014

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 913857014...
Checkpoint 913857014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 268,699.14475
Policy Entropy: 3.72933
Value Function Loss: 0.04964

Mean KL Divergence: 0.02529
SB3 Clip Fraction: 0.24419
Policy Update Magnitude: 0.55048
Value Function Update Magnitude: 0.59486

Collected Steps per Second: 21,445.95862
Overall Steps per Second: 10,237.34306

Timestep Collection Time: 2.33209
Timestep Consumption Time: 2.55335
PPO Batch Consumption Time: 0.29827
Total Iteration Time: 4.88545

Cumulative Model Updates: 109,600
Cumulative Timesteps: 913,907,028

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 69,189.20952
Policy Entropy: 3.76874
Value Function Loss: 0.07290

Mean KL Divergence: 0.01601
SB3 Clip Fraction: 0.18067
Policy Update Magnitude: 0.92130
Value Function Update Magnitude: 0.65181

Collected Steps per Second: 21,789.41187
Overall Steps per Second: 10,281.71318

Timestep Collection Time: 2.29469
Timestep Consumption Time: 2.56831
PPO Batch Consumption Time: 0.29849
Total Iteration Time: 4.86300

Cumulative Model Updates: 109,606
Cumulative Timesteps: 913,957,028

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 913957028...
Checkpoint 913957028 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 763.96180
Policy Entropy: 3.83656
Value Function Loss: 0.06403

Mean KL Divergence: 0.01397
SB3 Clip Fraction: 0.15957
Policy Update Magnitude: 1.03028
Value Function Update Magnitude: 0.65510

Collected Steps per Second: 21,397.96684
Overall Steps per Second: 10,217.38982

Timestep Collection Time: 2.33723
Timestep Consumption Time: 2.55756
PPO Batch Consumption Time: 0.29454
Total Iteration Time: 4.89479

Cumulative Model Updates: 109,612
Cumulative Timesteps: 914,007,040

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82,318.12099
Policy Entropy: 3.86392
Value Function Loss: 0.05857

Mean KL Divergence: 0.01058
SB3 Clip Fraction: 0.12808
Policy Update Magnitude: 1.05553
Value Function Update Magnitude: 0.70485

Collected Steps per Second: 21,571.90353
Overall Steps per Second: 10,364.21685

Timestep Collection Time: 2.31811
Timestep Consumption Time: 2.50676
PPO Batch Consumption Time: 0.28891
Total Iteration Time: 4.82487

Cumulative Model Updates: 109,618
Cumulative Timesteps: 914,057,046

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 914057046...
Checkpoint 914057046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,377.40843
Policy Entropy: 3.86434
Value Function Loss: 0.05238

Mean KL Divergence: 0.01073
SB3 Clip Fraction: 0.13172
Policy Update Magnitude: 1.15869
Value Function Update Magnitude: 0.83167

Collected Steps per Second: 21,365.82191
Overall Steps per Second: 10,313.08119

Timestep Collection Time: 2.34112
Timestep Consumption Time: 2.50903
PPO Batch Consumption Time: 0.29045
Total Iteration Time: 4.85015

Cumulative Model Updates: 109,624
Cumulative Timesteps: 914,107,066

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 269.41372
Policy Entropy: 3.86157
Value Function Loss: 0.04967

Mean KL Divergence: 0.01454
SB3 Clip Fraction: 0.17148
Policy Update Magnitude: 1.07102
Value Function Update Magnitude: 0.82182

Collected Steps per Second: 21,459.18419
Overall Steps per Second: 10,319.94044

Timestep Collection Time: 2.33066
Timestep Consumption Time: 2.51569
PPO Batch Consumption Time: 0.28933
Total Iteration Time: 4.84635

Cumulative Model Updates: 109,630
Cumulative Timesteps: 914,157,080

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 914157080...
Checkpoint 914157080 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,093.37008
Policy Entropy: 3.84488
Value Function Loss: 0.05230

Mean KL Divergence: 0.01250
SB3 Clip Fraction: 0.15672
Policy Update Magnitude: 0.94670
Value Function Update Magnitude: 0.66393

Collected Steps per Second: 21,619.13170
Overall Steps per Second: 10,309.77310

Timestep Collection Time: 2.31332
Timestep Consumption Time: 2.53761
PPO Batch Consumption Time: 0.29203
Total Iteration Time: 4.85093

Cumulative Model Updates: 109,636
Cumulative Timesteps: 914,207,092

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,024.44224
Policy Entropy: 3.81534
Value Function Loss: 0.05280

Mean KL Divergence: 0.01825
SB3 Clip Fraction: 0.21342
Policy Update Magnitude: 0.84119
Value Function Update Magnitude: 0.62599

Collected Steps per Second: 21,518.26189
Overall Steps per Second: 10,355.30287

Timestep Collection Time: 2.32435
Timestep Consumption Time: 2.50564
PPO Batch Consumption Time: 0.28864
Total Iteration Time: 4.82999

Cumulative Model Updates: 109,642
Cumulative Timesteps: 914,257,108

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 914257108...
Checkpoint 914257108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,817.01357
Policy Entropy: 3.79545
Value Function Loss: 0.05846

Mean KL Divergence: 0.01406
SB3 Clip Fraction: 0.17633
Policy Update Magnitude: 0.68747
Value Function Update Magnitude: 0.61155

Collected Steps per Second: 21,660.87333
Overall Steps per Second: 10,325.81912

Timestep Collection Time: 2.30969
Timestep Consumption Time: 2.53544
PPO Batch Consumption Time: 0.29521
Total Iteration Time: 4.84514

Cumulative Model Updates: 109,648
Cumulative Timesteps: 914,307,138

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,134.44235
Policy Entropy: 3.82799
Value Function Loss: 0.05546

Mean KL Divergence: 0.01136
SB3 Clip Fraction: 0.14122
Policy Update Magnitude: 0.82352
Value Function Update Magnitude: 0.58303

Collected Steps per Second: 21,773.93309
Overall Steps per Second: 10,460.44572

Timestep Collection Time: 2.29743
Timestep Consumption Time: 2.48478
PPO Batch Consumption Time: 0.28997
Total Iteration Time: 4.78221

Cumulative Model Updates: 109,654
Cumulative Timesteps: 914,357,162

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 914357162...
Checkpoint 914357162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,139.36642
Policy Entropy: 3.89299
Value Function Loss: 0.04919

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.11135
Policy Update Magnitude: 1.02456
Value Function Update Magnitude: 0.65172

Collected Steps per Second: 21,536.29411
Overall Steps per Second: 10,302.63183

Timestep Collection Time: 2.32250
Timestep Consumption Time: 2.53238
PPO Batch Consumption Time: 0.29905
Total Iteration Time: 4.85488

Cumulative Model Updates: 109,660
Cumulative Timesteps: 914,407,180

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12.78383
Policy Entropy: 3.95810
Value Function Loss: 0.04334

Mean KL Divergence: 0.00727
SB3 Clip Fraction: 0.09042
Policy Update Magnitude: 1.10062
Value Function Update Magnitude: 0.71204

Collected Steps per Second: 21,517.70218
Overall Steps per Second: 10,370.05778

Timestep Collection Time: 2.32469
Timestep Consumption Time: 2.49900
PPO Batch Consumption Time: 0.29242
Total Iteration Time: 4.82370

Cumulative Model Updates: 109,666
Cumulative Timesteps: 914,457,202

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 914457202...
Checkpoint 914457202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 194.55070
Policy Entropy: 3.94948
Value Function Loss: 0.04306

Mean KL Divergence: 0.00608
SB3 Clip Fraction: 0.07484
Policy Update Magnitude: 1.05094
Value Function Update Magnitude: 0.76495

Collected Steps per Second: 21,341.81420
Overall Steps per Second: 10,259.95636

Timestep Collection Time: 2.34404
Timestep Consumption Time: 2.53181
PPO Batch Consumption Time: 0.29971
Total Iteration Time: 4.87585

Cumulative Model Updates: 109,672
Cumulative Timesteps: 914,507,228

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,046.85608
Policy Entropy: 3.90059
Value Function Loss: 0.04291

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.10428
Policy Update Magnitude: 0.96320
Value Function Update Magnitude: 0.74074

Collected Steps per Second: 21,704.19084
Overall Steps per Second: 10,379.42043

Timestep Collection Time: 2.30416
Timestep Consumption Time: 2.51402
PPO Batch Consumption Time: 0.29429
Total Iteration Time: 4.81819

Cumulative Model Updates: 109,678
Cumulative Timesteps: 914,557,238

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 914557238...
Checkpoint 914557238 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 237.84421
Policy Entropy: 3.87077
Value Function Loss: 0.04100

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.13031
Policy Update Magnitude: 0.79670
Value Function Update Magnitude: 0.73263

Collected Steps per Second: 21,583.23855
Overall Steps per Second: 10,326.83199

Timestep Collection Time: 2.31763
Timestep Consumption Time: 2.52625
PPO Batch Consumption Time: 0.29907
Total Iteration Time: 4.84389

Cumulative Model Updates: 109,684
Cumulative Timesteps: 914,607,260

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40.17964
Policy Entropy: 3.81830
Value Function Loss: 0.04119

Mean KL Divergence: 0.00721
SB3 Clip Fraction: 0.09172
Policy Update Magnitude: 0.78375
Value Function Update Magnitude: 0.69525

Collected Steps per Second: 21,769.54411
Overall Steps per Second: 10,344.23107

Timestep Collection Time: 2.29688
Timestep Consumption Time: 2.53693
PPO Batch Consumption Time: 0.29816
Total Iteration Time: 4.83381

Cumulative Model Updates: 109,690
Cumulative Timesteps: 914,657,262

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 914657262...
Checkpoint 914657262 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,482.60101
Policy Entropy: 3.83081
Value Function Loss: 0.03753

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.14015
Policy Update Magnitude: 0.73364
Value Function Update Magnitude: 0.60950

Collected Steps per Second: 21,532.39649
Overall Steps per Second: 10,285.31073

Timestep Collection Time: 2.32236
Timestep Consumption Time: 2.53952
PPO Batch Consumption Time: 0.30045
Total Iteration Time: 4.86189

Cumulative Model Updates: 109,696
Cumulative Timesteps: 914,707,268

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,050.98078
Policy Entropy: 3.81348
Value Function Loss: 0.03883

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.13085
Policy Update Magnitude: 0.58598
Value Function Update Magnitude: 0.61499

Collected Steps per Second: 22,107.28106
Overall Steps per Second: 10,382.73524

Timestep Collection Time: 2.26170
Timestep Consumption Time: 2.55399
PPO Batch Consumption Time: 0.30111
Total Iteration Time: 4.81569

Cumulative Model Updates: 109,702
Cumulative Timesteps: 914,757,268

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 914757268...
Checkpoint 914757268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 327.33907
Policy Entropy: 3.84371
Value Function Loss: 0.03591

Mean KL Divergence: 0.01507
SB3 Clip Fraction: 0.17763
Policy Update Magnitude: 0.62958
Value Function Update Magnitude: 0.66864

Collected Steps per Second: 21,558.32918
Overall Steps per Second: 10,295.88697

Timestep Collection Time: 2.32059
Timestep Consumption Time: 2.53844
PPO Batch Consumption Time: 0.29944
Total Iteration Time: 4.85903

Cumulative Model Updates: 109,708
Cumulative Timesteps: 914,807,296

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,189.76313
Policy Entropy: 3.82286
Value Function Loss: 0.04005

Mean KL Divergence: 0.02564
SB3 Clip Fraction: 0.26395
Policy Update Magnitude: 0.47359
Value Function Update Magnitude: 0.64993

Collected Steps per Second: 20,536.72500
Overall Steps per Second: 9,915.62499

Timestep Collection Time: 2.43525
Timestep Consumption Time: 2.60851
PPO Batch Consumption Time: 0.29667
Total Iteration Time: 5.04376

Cumulative Model Updates: 109,714
Cumulative Timesteps: 914,857,308

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 914857308...
Checkpoint 914857308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,375.87907
Policy Entropy: 3.82830
Value Function Loss: 0.03587

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.10953
Policy Update Magnitude: 0.52160
Value Function Update Magnitude: 0.53161

Collected Steps per Second: 18,972.27841
Overall Steps per Second: 9,481.33162

Timestep Collection Time: 2.63658
Timestep Consumption Time: 2.63926
PPO Batch Consumption Time: 0.30210
Total Iteration Time: 5.27584

Cumulative Model Updates: 109,720
Cumulative Timesteps: 914,907,330

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56,249.44545
Policy Entropy: 3.76282
Value Function Loss: 0.04343

Mean KL Divergence: 0.01561
SB3 Clip Fraction: 0.19950
Policy Update Magnitude: 0.48623
Value Function Update Magnitude: 0.46967

Collected Steps per Second: 19,342.45026
Overall Steps per Second: 9,556.81859

Timestep Collection Time: 2.58623
Timestep Consumption Time: 2.64815
PPO Batch Consumption Time: 0.29980
Total Iteration Time: 5.23438

Cumulative Model Updates: 109,726
Cumulative Timesteps: 914,957,354

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 914957354...
Checkpoint 914957354 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,056.95671
Policy Entropy: 3.78254
Value Function Loss: 0.04193

Mean KL Divergence: 0.01425
SB3 Clip Fraction: 0.18637
Policy Update Magnitude: 0.46116
Value Function Update Magnitude: 0.46748

Collected Steps per Second: 21,601.44750
Overall Steps per Second: 10,319.66248

Timestep Collection Time: 2.31466
Timestep Consumption Time: 2.53046
PPO Batch Consumption Time: 0.29172
Total Iteration Time: 4.84512

Cumulative Model Updates: 109,732
Cumulative Timesteps: 915,007,354

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,063.43461
Policy Entropy: 3.75704
Value Function Loss: 0.05108

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.12860
Policy Update Magnitude: 0.45669
Value Function Update Magnitude: 0.45392

Collected Steps per Second: 21,739.63696
Overall Steps per Second: 10,394.99851

Timestep Collection Time: 2.30041
Timestep Consumption Time: 2.51056
PPO Batch Consumption Time: 0.28833
Total Iteration Time: 4.81097

Cumulative Model Updates: 109,738
Cumulative Timesteps: 915,057,364

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 915057364...
Checkpoint 915057364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,063.43461
Policy Entropy: 3.77310
Value Function Loss: 0.03891

Mean KL Divergence: 0.01097
SB3 Clip Fraction: 0.14843
Policy Update Magnitude: 0.45692
Value Function Update Magnitude: 0.58604

Collected Steps per Second: 21,446.85994
Overall Steps per Second: 10,265.80361

Timestep Collection Time: 2.33218
Timestep Consumption Time: 2.54011
PPO Batch Consumption Time: 0.29360
Total Iteration Time: 4.87229

Cumulative Model Updates: 109,744
Cumulative Timesteps: 915,107,382

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,878.13987
Policy Entropy: 3.72801
Value Function Loss: 0.04692

Mean KL Divergence: 0.01200
SB3 Clip Fraction: 0.15838
Policy Update Magnitude: 0.43275
Value Function Update Magnitude: 0.61251

Collected Steps per Second: 21,612.41044
Overall Steps per Second: 10,346.39167

Timestep Collection Time: 2.31423
Timestep Consumption Time: 2.51992
PPO Batch Consumption Time: 0.28801
Total Iteration Time: 4.83415

Cumulative Model Updates: 109,750
Cumulative Timesteps: 915,157,398

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 915157398...
Checkpoint 915157398 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,727.08003
Policy Entropy: 3.77220
Value Function Loss: 0.04293

Mean KL Divergence: 0.01090
SB3 Clip Fraction: 0.14449
Policy Update Magnitude: 0.49353
Value Function Update Magnitude: 0.52118

Collected Steps per Second: 21,920.74572
Overall Steps per Second: 10,377.94116

Timestep Collection Time: 2.28094
Timestep Consumption Time: 2.53697
PPO Batch Consumption Time: 0.30012
Total Iteration Time: 4.81791

Cumulative Model Updates: 109,756
Cumulative Timesteps: 915,207,398

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,175.74359
Policy Entropy: 3.75997
Value Function Loss: 0.05129

Mean KL Divergence: 0.01073
SB3 Clip Fraction: 0.14231
Policy Update Magnitude: 0.51498
Value Function Update Magnitude: 0.57830

Collected Steps per Second: 21,695.14141
Overall Steps per Second: 10,354.00725

Timestep Collection Time: 2.30586
Timestep Consumption Time: 2.52570
PPO Batch Consumption Time: 0.28885
Total Iteration Time: 4.83156

Cumulative Model Updates: 109,762
Cumulative Timesteps: 915,257,424

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 915257424...
Checkpoint 915257424 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,243.25232
Policy Entropy: 3.79321
Value Function Loss: 0.04169

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.13681
Policy Update Magnitude: 0.56904
Value Function Update Magnitude: 0.69085

Collected Steps per Second: 21,534.60721
Overall Steps per Second: 10,288.04723

Timestep Collection Time: 2.32314
Timestep Consumption Time: 2.53959
PPO Batch Consumption Time: 0.30080
Total Iteration Time: 4.86273

Cumulative Model Updates: 109,768
Cumulative Timesteps: 915,307,452

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,902.30854
Policy Entropy: 3.78570
Value Function Loss: 0.04620

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.13169
Policy Update Magnitude: 0.56200
Value Function Update Magnitude: 0.73893

Collected Steps per Second: 21,757.02386
Overall Steps per Second: 10,418.00110

Timestep Collection Time: 2.29912
Timestep Consumption Time: 2.50238
PPO Batch Consumption Time: 0.28678
Total Iteration Time: 4.80150

Cumulative Model Updates: 109,774
Cumulative Timesteps: 915,357,474

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 915357474...
Checkpoint 915357474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,126.87498
Policy Entropy: 3.79428
Value Function Loss: 0.03885

Mean KL Divergence: 0.01082
SB3 Clip Fraction: 0.14053
Policy Update Magnitude: 0.57044
Value Function Update Magnitude: 0.70244

Collected Steps per Second: 21,201.69692
Overall Steps per Second: 10,182.37033

Timestep Collection Time: 2.35830
Timestep Consumption Time: 2.55215
PPO Batch Consumption Time: 0.29534
Total Iteration Time: 4.91045

Cumulative Model Updates: 109,780
Cumulative Timesteps: 915,407,474

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 736.77463
Policy Entropy: 3.77392
Value Function Loss: 0.04215

Mean KL Divergence: 0.01185
SB3 Clip Fraction: 0.14935
Policy Update Magnitude: 0.56387
Value Function Update Magnitude: 0.64412

Collected Steps per Second: 21,860.45641
Overall Steps per Second: 10,442.41927

Timestep Collection Time: 2.28769
Timestep Consumption Time: 2.50143
PPO Batch Consumption Time: 0.28772
Total Iteration Time: 4.78912

Cumulative Model Updates: 109,786
Cumulative Timesteps: 915,457,484

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 915457484...
Checkpoint 915457484 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,376.82096
Policy Entropy: 3.78463
Value Function Loss: 0.03459

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.14244
Policy Update Magnitude: 0.53211
Value Function Update Magnitude: 0.49048

Collected Steps per Second: 21,458.32433
Overall Steps per Second: 10,242.92156

Timestep Collection Time: 2.33094
Timestep Consumption Time: 2.55224
PPO Batch Consumption Time: 0.29615
Total Iteration Time: 4.88318

Cumulative Model Updates: 109,792
Cumulative Timesteps: 915,507,502

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 525.30623
Policy Entropy: 3.76299
Value Function Loss: 0.03628

Mean KL Divergence: 0.01110
SB3 Clip Fraction: 0.14714
Policy Update Magnitude: 0.47644
Value Function Update Magnitude: 0.48663

Collected Steps per Second: 21,608.67323
Overall Steps per Second: 10,362.77159

Timestep Collection Time: 2.31472
Timestep Consumption Time: 2.51198
PPO Batch Consumption Time: 0.28868
Total Iteration Time: 4.82670

Cumulative Model Updates: 109,798
Cumulative Timesteps: 915,557,520

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 915557520...
Checkpoint 915557520 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,188.91754
Policy Entropy: 3.77365
Value Function Loss: 0.03636

Mean KL Divergence: 0.01053
SB3 Clip Fraction: 0.14213
Policy Update Magnitude: 0.46836
Value Function Update Magnitude: 0.54836

Collected Steps per Second: 21,013.71552
Overall Steps per Second: 10,185.48422

Timestep Collection Time: 2.37959
Timestep Consumption Time: 2.52975
PPO Batch Consumption Time: 0.28921
Total Iteration Time: 4.90934

Cumulative Model Updates: 109,804
Cumulative Timesteps: 915,607,524

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 330.80589
Policy Entropy: 3.77001
Value Function Loss: 0.03429

Mean KL Divergence: 0.01065
SB3 Clip Fraction: 0.14154
Policy Update Magnitude: 0.48100
Value Function Update Magnitude: 0.58795

Collected Steps per Second: 22,053.14536
Overall Steps per Second: 10,471.03605

Timestep Collection Time: 2.26798
Timestep Consumption Time: 2.50863
PPO Batch Consumption Time: 0.28920
Total Iteration Time: 4.77660

Cumulative Model Updates: 109,810
Cumulative Timesteps: 915,657,540

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 915657540...
Checkpoint 915657540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 256.17135
Policy Entropy: 3.78828
Value Function Loss: 0.02873

Mean KL Divergence: 0.01078
SB3 Clip Fraction: 0.14563
Policy Update Magnitude: 0.46918
Value Function Update Magnitude: 0.69838

Collected Steps per Second: 21,845.01376
Overall Steps per Second: 10,320.15736

Timestep Collection Time: 2.29013
Timestep Consumption Time: 2.55747
PPO Batch Consumption Time: 0.29624
Total Iteration Time: 4.84760

Cumulative Model Updates: 109,816
Cumulative Timesteps: 915,707,568

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,210.31983
Policy Entropy: 3.79209
Value Function Loss: 0.03204

Mean KL Divergence: 0.01070
SB3 Clip Fraction: 0.14393
Policy Update Magnitude: 0.46194
Value Function Update Magnitude: 0.71246

Collected Steps per Second: 22,049.78431
Overall Steps per Second: 10,477.91459

Timestep Collection Time: 2.26814
Timestep Consumption Time: 2.50495
PPO Batch Consumption Time: 0.28734
Total Iteration Time: 4.77309

Cumulative Model Updates: 109,822
Cumulative Timesteps: 915,757,580

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 915757580...
Checkpoint 915757580 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,889.23671
Policy Entropy: 3.76643
Value Function Loss: 0.03139

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.13141
Policy Update Magnitude: 0.58420
Value Function Update Magnitude: 0.59989

Collected Steps per Second: 21,497.55126
Overall Steps per Second: 10,209.15916

Timestep Collection Time: 2.32640
Timestep Consumption Time: 2.57233
PPO Batch Consumption Time: 0.29871
Total Iteration Time: 4.89874

Cumulative Model Updates: 109,828
Cumulative Timesteps: 915,807,592

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76,267.70848
Policy Entropy: 3.75612
Value Function Loss: 0.03487

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.13786
Policy Update Magnitude: 0.55855
Value Function Update Magnitude: 0.62924

Collected Steps per Second: 21,672.27108
Overall Steps per Second: 10,379.82202

Timestep Collection Time: 2.30848
Timestep Consumption Time: 2.51145
PPO Batch Consumption Time: 0.28789
Total Iteration Time: 4.81993

Cumulative Model Updates: 109,834
Cumulative Timesteps: 915,857,622

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 915857622...
Checkpoint 915857622 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,687.83320
Policy Entropy: 3.74900
Value Function Loss: 0.03487

Mean KL Divergence: 0.01101
SB3 Clip Fraction: 0.14713
Policy Update Magnitude: 0.47818
Value Function Update Magnitude: 0.53297

Collected Steps per Second: 21,449.17460
Overall Steps per Second: 10,304.22405

Timestep Collection Time: 2.33230
Timestep Consumption Time: 2.52260
PPO Batch Consumption Time: 0.29067
Total Iteration Time: 4.85490

Cumulative Model Updates: 109,840
Cumulative Timesteps: 915,907,648

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,792.82496
Policy Entropy: 3.74039
Value Function Loss: 0.03294

Mean KL Divergence: 0.01118
SB3 Clip Fraction: 0.14720
Policy Update Magnitude: 0.45914
Value Function Update Magnitude: 0.46575

Collected Steps per Second: 21,887.55762
Overall Steps per Second: 10,412.34819

Timestep Collection Time: 2.28477
Timestep Consumption Time: 2.51799
PPO Batch Consumption Time: 0.28849
Total Iteration Time: 4.80276

Cumulative Model Updates: 109,846
Cumulative Timesteps: 915,957,656

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 915957656...
Checkpoint 915957656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,792.82496
Policy Entropy: 3.73482
Value Function Loss: 0.02605

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.14192
Policy Update Magnitude: 0.43713
Value Function Update Magnitude: 0.46664

Collected Steps per Second: 21,266.26612
Overall Steps per Second: 10,245.96207

Timestep Collection Time: 2.35246
Timestep Consumption Time: 2.53025
PPO Batch Consumption Time: 0.29276
Total Iteration Time: 4.88270

Cumulative Model Updates: 109,852
Cumulative Timesteps: 916,007,684

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,792.82496
Policy Entropy: 3.71750
Value Function Loss: 0.02456

Mean KL Divergence: 0.01076
SB3 Clip Fraction: 0.14755
Policy Update Magnitude: 0.37961
Value Function Update Magnitude: 0.45070

Collected Steps per Second: 21,628.61050
Overall Steps per Second: 10,381.10854

Timestep Collection Time: 2.31286
Timestep Consumption Time: 2.50589
PPO Batch Consumption Time: 0.28852
Total Iteration Time: 4.81875

Cumulative Model Updates: 109,858
Cumulative Timesteps: 916,057,708

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 916057708...
Checkpoint 916057708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,792.82496
Policy Entropy: 3.69886
Value Function Loss: 0.02087

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.14714
Policy Update Magnitude: 0.36299
Value Function Update Magnitude: 0.44283

Collected Steps per Second: 21,377.63761
Overall Steps per Second: 10,296.80090

Timestep Collection Time: 2.34095
Timestep Consumption Time: 2.51920
PPO Batch Consumption Time: 0.29014
Total Iteration Time: 4.86015

Cumulative Model Updates: 109,864
Cumulative Timesteps: 916,107,752

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,747.13084
Policy Entropy: 3.70372
Value Function Loss: 0.02280

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.14089
Policy Update Magnitude: 0.38835
Value Function Update Magnitude: 0.53750

Collected Steps per Second: 21,694.07084
Overall Steps per Second: 10,395.74596

Timestep Collection Time: 2.30588
Timestep Consumption Time: 2.50608
PPO Batch Consumption Time: 0.28886
Total Iteration Time: 4.81197

Cumulative Model Updates: 109,870
Cumulative Timesteps: 916,157,776

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 916157776...
Checkpoint 916157776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,747.13084
Policy Entropy: 3.70007
Value Function Loss: 0.02482

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.14413
Policy Update Magnitude: 0.42608
Value Function Update Magnitude: 0.45974

Collected Steps per Second: 20,653.71361
Overall Steps per Second: 10,272.42755

Timestep Collection Time: 2.42213
Timestep Consumption Time: 2.44780
PPO Batch Consumption Time: 0.29313
Total Iteration Time: 4.86993

Cumulative Model Updates: 109,876
Cumulative Timesteps: 916,207,802

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,747.13084
Policy Entropy: 3.69762
Value Function Loss: 0.02450

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.14621
Policy Update Magnitude: 0.42859
Value Function Update Magnitude: 0.40056

Collected Steps per Second: 20,988.08269
Overall Steps per Second: 10,377.54797

Timestep Collection Time: 2.38373
Timestep Consumption Time: 2.43725
PPO Batch Consumption Time: 0.28853
Total Iteration Time: 4.82098

Cumulative Model Updates: 109,882
Cumulative Timesteps: 916,257,832

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 916257832...
Checkpoint 916257832 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 168,249.24750
Policy Entropy: 3.69715
Value Function Loss: 0.02576

Mean KL Divergence: 0.01073
SB3 Clip Fraction: 0.14582
Policy Update Magnitude: 0.42278
Value Function Update Magnitude: 0.40107

Collected Steps per Second: 21,074.60862
Overall Steps per Second: 10,317.85302

Timestep Collection Time: 2.37252
Timestep Consumption Time: 2.47345
PPO Batch Consumption Time: 0.28629
Total Iteration Time: 4.84597

Cumulative Model Updates: 109,888
Cumulative Timesteps: 916,307,832

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 160,712.25654
Policy Entropy: 3.71670
Value Function Loss: 0.02516

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.14248
Policy Update Magnitude: 0.43866
Value Function Update Magnitude: 0.54351

Collected Steps per Second: 21,780.65829
Overall Steps per Second: 10,422.33870

Timestep Collection Time: 2.29662
Timestep Consumption Time: 2.50287
PPO Batch Consumption Time: 0.29152
Total Iteration Time: 4.79950

Cumulative Model Updates: 109,894
Cumulative Timesteps: 916,357,854

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 916357854...
Checkpoint 916357854 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 105,447.61524
Policy Entropy: 3.71908
Value Function Loss: 0.02743

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.14470
Policy Update Magnitude: 0.46782
Value Function Update Magnitude: 0.61532

Collected Steps per Second: 21,323.20100
Overall Steps per Second: 10,217.72626

Timestep Collection Time: 2.34486
Timestep Consumption Time: 2.54859
PPO Batch Consumption Time: 0.30187
Total Iteration Time: 4.89346

Cumulative Model Updates: 109,900
Cumulative Timesteps: 916,407,854

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 105,447.61524
Policy Entropy: 3.71936
Value Function Loss: 0.02552

Mean KL Divergence: 0.01058
SB3 Clip Fraction: 0.14841
Policy Update Magnitude: 0.46507
Value Function Update Magnitude: 0.63571

Collected Steps per Second: 21,822.93779
Overall Steps per Second: 10,457.63462

Timestep Collection Time: 2.29208
Timestep Consumption Time: 2.49102
PPO Batch Consumption Time: 0.28593
Total Iteration Time: 4.78311

Cumulative Model Updates: 109,906
Cumulative Timesteps: 916,457,874

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 916457874...
Checkpoint 916457874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55,441.57947
Policy Entropy: 3.71142
Value Function Loss: 0.02608

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.14563
Policy Update Magnitude: 0.44554
Value Function Update Magnitude: 0.64662

Collected Steps per Second: 21,783.09115
Overall Steps per Second: 10,332.63041

Timestep Collection Time: 2.29573
Timestep Consumption Time: 2.54409
PPO Batch Consumption Time: 0.29822
Total Iteration Time: 4.83981

Cumulative Model Updates: 109,912
Cumulative Timesteps: 916,507,882

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,335.39537
Policy Entropy: 3.72904
Value Function Loss: 0.02426

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.14269
Policy Update Magnitude: 0.42924
Value Function Update Magnitude: 0.61312

Collected Steps per Second: 21,948.62336
Overall Steps per Second: 10,290.72703

Timestep Collection Time: 2.27805
Timestep Consumption Time: 2.58070
PPO Batch Consumption Time: 0.29758
Total Iteration Time: 4.85874

Cumulative Model Updates: 109,918
Cumulative Timesteps: 916,557,882

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 916557882...
Checkpoint 916557882 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,665.47011
Policy Entropy: 3.70656
Value Function Loss: 0.02653

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.14440
Policy Update Magnitude: 0.42015
Value Function Update Magnitude: 0.59602

Collected Steps per Second: 20,997.73189
Overall Steps per Second: 10,238.15532

Timestep Collection Time: 2.38207
Timestep Consumption Time: 2.50338
PPO Batch Consumption Time: 0.28622
Total Iteration Time: 4.88545

Cumulative Model Updates: 109,924
Cumulative Timesteps: 916,607,900

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,665.47011
Policy Entropy: 3.71586
Value Function Loss: 0.02467

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.13766
Policy Update Magnitude: 0.45143
Value Function Update Magnitude: 0.55305

Collected Steps per Second: 21,634.53760
Overall Steps per Second: 10,370.32327

Timestep Collection Time: 2.31149
Timestep Consumption Time: 2.51073
PPO Batch Consumption Time: 0.28793
Total Iteration Time: 4.82222

Cumulative Model Updates: 109,930
Cumulative Timesteps: 916,657,908

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 916657908...
Checkpoint 916657908 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 134,262.94215
Policy Entropy: 3.67707
Value Function Loss: 0.02971

Mean KL Divergence: 0.01091
SB3 Clip Fraction: 0.14770
Policy Update Magnitude: 0.45066
Value Function Update Magnitude: 0.50690

Collected Steps per Second: 21,625.62281
Overall Steps per Second: 10,263.01804

Timestep Collection Time: 2.31337
Timestep Consumption Time: 2.56122
PPO Batch Consumption Time: 0.29536
Total Iteration Time: 4.87459

Cumulative Model Updates: 109,936
Cumulative Timesteps: 916,707,936

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88,097.14560
Policy Entropy: 3.70367
Value Function Loss: 0.02995

Mean KL Divergence: 0.01135
SB3 Clip Fraction: 0.15067
Policy Update Magnitude: 0.44369
Value Function Update Magnitude: 0.45878

Collected Steps per Second: 21,961.19399
Overall Steps per Second: 10,421.90851

Timestep Collection Time: 2.27747
Timestep Consumption Time: 2.52165
PPO Batch Consumption Time: 0.28887
Total Iteration Time: 4.79912

Cumulative Model Updates: 109,942
Cumulative Timesteps: 916,757,952

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 916757952...
Checkpoint 916757952 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 312,000.81170
Policy Entropy: 3.67940
Value Function Loss: 0.03389

Mean KL Divergence: 0.01092
SB3 Clip Fraction: 0.14517
Policy Update Magnitude: 0.46123
Value Function Update Magnitude: 0.52925

Collected Steps per Second: 20,965.92672
Overall Steps per Second: 10,196.22514

Timestep Collection Time: 2.38539
Timestep Consumption Time: 2.51956
PPO Batch Consumption Time: 0.28916
Total Iteration Time: 4.90495

Cumulative Model Updates: 109,948
Cumulative Timesteps: 916,807,964

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 215,233.93498
Policy Entropy: 3.72244
Value Function Loss: 0.02976

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.14164
Policy Update Magnitude: 0.50772
Value Function Update Magnitude: 0.58870

Collected Steps per Second: 21,637.61093
Overall Steps per Second: 10,385.72501

Timestep Collection Time: 2.31209
Timestep Consumption Time: 2.50491
PPO Batch Consumption Time: 0.28807
Total Iteration Time: 4.81700

Cumulative Model Updates: 109,954
Cumulative Timesteps: 916,857,992

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 916857992...
Checkpoint 916857992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 145,529.09757
Policy Entropy: 3.70456
Value Function Loss: 0.03295

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.13330
Policy Update Magnitude: 0.51773
Value Function Update Magnitude: 0.52846

Collected Steps per Second: 21,717.89590
Overall Steps per Second: 10,358.37853

Timestep Collection Time: 2.30326
Timestep Consumption Time: 2.52587
PPO Batch Consumption Time: 0.29238
Total Iteration Time: 4.82913

Cumulative Model Updates: 109,960
Cumulative Timesteps: 916,908,014

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95,501.06651
Policy Entropy: 3.72273
Value Function Loss: 0.03050

Mean KL Divergence: 0.01105
SB3 Clip Fraction: 0.14497
Policy Update Magnitude: 0.47966
Value Function Update Magnitude: 0.49495

Collected Steps per Second: 21,996.58273
Overall Steps per Second: 10,432.89312

Timestep Collection Time: 2.27444
Timestep Consumption Time: 2.52097
PPO Batch Consumption Time: 0.29012
Total Iteration Time: 4.79541

Cumulative Model Updates: 109,966
Cumulative Timesteps: 916,958,044

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 916958044...
Checkpoint 916958044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 95,501.06651
Policy Entropy: 3.69124
Value Function Loss: 0.03162

Mean KL Divergence: 0.01153
SB3 Clip Fraction: 0.14584
Policy Update Magnitude: 0.45780
Value Function Update Magnitude: 0.41994

Collected Steps per Second: 21,458.50359
Overall Steps per Second: 10,201.84118

Timestep Collection Time: 2.33008
Timestep Consumption Time: 2.57100
PPO Batch Consumption Time: 0.29924
Total Iteration Time: 4.90108

Cumulative Model Updates: 109,972
Cumulative Timesteps: 917,008,044

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95,501.06651
Policy Entropy: 3.69029
Value Function Loss: 0.03281

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.13834
Policy Update Magnitude: 0.46660
Value Function Update Magnitude: 0.36678

Collected Steps per Second: 21,438.35688
Overall Steps per Second: 10,362.52728

Timestep Collection Time: 2.33320
Timestep Consumption Time: 2.49381
PPO Batch Consumption Time: 0.28751
Total Iteration Time: 4.82701

Cumulative Model Updates: 109,978
Cumulative Timesteps: 917,058,064

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 917058064...
Checkpoint 917058064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 161,265.07942
Policy Entropy: 3.68996
Value Function Loss: 0.03195

Mean KL Divergence: 0.01100
SB3 Clip Fraction: 0.14540
Policy Update Magnitude: 0.49776
Value Function Update Magnitude: 0.34660

Collected Steps per Second: 21,436.51379
Overall Steps per Second: 10,334.40294

Timestep Collection Time: 2.33387
Timestep Consumption Time: 2.50724
PPO Batch Consumption Time: 0.28997
Total Iteration Time: 4.84111

Cumulative Model Updates: 109,984
Cumulative Timesteps: 917,108,094

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 105,807.98170
Policy Entropy: 3.68789
Value Function Loss: 0.03090

Mean KL Divergence: 0.01178
SB3 Clip Fraction: 0.15213
Policy Update Magnitude: 0.48995
Value Function Update Magnitude: 0.34256

Collected Steps per Second: 21,626.37892
Overall Steps per Second: 10,363.74529

Timestep Collection Time: 2.31292
Timestep Consumption Time: 2.51352
PPO Batch Consumption Time: 0.28887
Total Iteration Time: 4.82644

Cumulative Model Updates: 109,990
Cumulative Timesteps: 917,158,114

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 917158114...
Checkpoint 917158114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 105,807.98170
Policy Entropy: 3.71168
Value Function Loss: 0.02552

Mean KL Divergence: 0.01061
SB3 Clip Fraction: 0.14256
Policy Update Magnitude: 0.49378
Value Function Update Magnitude: 0.38452

Collected Steps per Second: 21,441.43146
Overall Steps per Second: 10,318.16948

Timestep Collection Time: 2.33259
Timestep Consumption Time: 2.51459
PPO Batch Consumption Time: 0.29040
Total Iteration Time: 4.84718

Cumulative Model Updates: 109,996
Cumulative Timesteps: 917,208,128

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 107,417.19710
Policy Entropy: 3.70562
Value Function Loss: 0.02474

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.14018
Policy Update Magnitude: 0.47228
Value Function Update Magnitude: 0.35762

Collected Steps per Second: 21,759.52338
Overall Steps per Second: 10,417.56240

Timestep Collection Time: 2.29886
Timestep Consumption Time: 2.50284
PPO Batch Consumption Time: 0.28732
Total Iteration Time: 4.80170

Cumulative Model Updates: 110,002
Cumulative Timesteps: 917,258,150

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 917258150...
Checkpoint 917258150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46,239.67142
Policy Entropy: 3.71615
Value Function Loss: 0.02336

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.13911
Policy Update Magnitude: 0.44908
Value Function Update Magnitude: 0.37571

Collected Steps per Second: 21,550.63222
Overall Steps per Second: 10,246.47481

Timestep Collection Time: 2.32114
Timestep Consumption Time: 2.56074
PPO Batch Consumption Time: 0.29763
Total Iteration Time: 4.88187

Cumulative Model Updates: 110,008
Cumulative Timesteps: 917,308,172

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,483.24644
Policy Entropy: 3.69594
Value Function Loss: 0.02578

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.14015
Policy Update Magnitude: 0.45902
Value Function Update Magnitude: 0.42644

Collected Steps per Second: 21,647.11582
Overall Steps per Second: 10,380.42818

Timestep Collection Time: 2.31005
Timestep Consumption Time: 2.50728
PPO Batch Consumption Time: 0.28830
Total Iteration Time: 4.81733

Cumulative Model Updates: 110,014
Cumulative Timesteps: 917,358,178

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 917358178...
Checkpoint 917358178 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,483.24644
Policy Entropy: 3.71230
Value Function Loss: 0.02549

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.14318
Policy Update Magnitude: 0.47982
Value Function Update Magnitude: 0.47816

Collected Steps per Second: 19,727.11702
Overall Steps per Second: 9,885.27144

Timestep Collection Time: 2.53529
Timestep Consumption Time: 2.52415
PPO Batch Consumption Time: 0.29287
Total Iteration Time: 5.05945

Cumulative Model Updates: 110,020
Cumulative Timesteps: 917,408,192

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,483.24644
Policy Entropy: 3.70315
Value Function Loss: 0.02385

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.14338
Policy Update Magnitude: 0.48376
Value Function Update Magnitude: 0.49577

Collected Steps per Second: 21,042.58075
Overall Steps per Second: 10,409.45045

Timestep Collection Time: 2.37718
Timestep Consumption Time: 2.42826
PPO Batch Consumption Time: 0.28819
Total Iteration Time: 4.80544

Cumulative Model Updates: 110,026
Cumulative Timesteps: 917,458,214

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 917458214...
Checkpoint 917458214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 177,000.44924
Policy Entropy: 3.71234
Value Function Loss: 0.02547

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.14206
Policy Update Magnitude: 0.50235
Value Function Update Magnitude: 0.49141

Collected Steps per Second: 20,801.40869
Overall Steps per Second: 10,250.33423

Timestep Collection Time: 2.40416
Timestep Consumption Time: 2.47470
PPO Batch Consumption Time: 0.29738
Total Iteration Time: 4.87887

Cumulative Model Updates: 110,032
Cumulative Timesteps: 917,508,224

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,576.23528
Policy Entropy: 3.71347
Value Function Loss: 0.02712

Mean KL Divergence: 0.01093
SB3 Clip Fraction: 0.14750
Policy Update Magnitude: 0.57742
Value Function Update Magnitude: 0.50271

Collected Steps per Second: 21,010.67202
Overall Steps per Second: 10,398.27155

Timestep Collection Time: 2.38174
Timestep Consumption Time: 2.43079
PPO Batch Consumption Time: 0.28925
Total Iteration Time: 4.81253

Cumulative Model Updates: 110,038
Cumulative Timesteps: 917,558,266

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 917558266...
Checkpoint 917558266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,576.23528
Policy Entropy: 3.71738
Value Function Loss: 0.02611

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.12244
Policy Update Magnitude: 0.64009
Value Function Update Magnitude: 0.48968

Collected Steps per Second: 20,776.60669
Overall Steps per Second: 10,206.95745

Timestep Collection Time: 2.40694
Timestep Consumption Time: 2.49247
PPO Batch Consumption Time: 0.28818
Total Iteration Time: 4.89940

Cumulative Model Updates: 110,044
Cumulative Timesteps: 917,608,274

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,576.23528
Policy Entropy: 3.71284
Value Function Loss: 0.02212

Mean KL Divergence: 0.01841
SB3 Clip Fraction: 0.22053
Policy Update Magnitude: 0.52512
Value Function Update Magnitude: 0.38676

Collected Steps per Second: 21,346.24481
Overall Steps per Second: 10,206.73201

Timestep Collection Time: 2.34458
Timestep Consumption Time: 2.55885
PPO Batch Consumption Time: 0.29801
Total Iteration Time: 4.90343

Cumulative Model Updates: 110,050
Cumulative Timesteps: 917,658,322

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 917658322...
Checkpoint 917658322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,576.23528
Policy Entropy: 3.69957
Value Function Loss: 0.03338

Mean KL Divergence: 0.02354
SB3 Clip Fraction: 0.24189
Policy Update Magnitude: 0.42426
Value Function Update Magnitude: 0.28991

Collected Steps per Second: 21,248.36254
Overall Steps per Second: 9,955.60009

Timestep Collection Time: 2.35388
Timestep Consumption Time: 2.67003
PPO Batch Consumption Time: 0.32143
Total Iteration Time: 5.02391

Cumulative Model Updates: 110,056
Cumulative Timesteps: 917,708,338

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,576.23528
Policy Entropy: 3.75680
Value Function Loss: 0.05979

Mean KL Divergence: 0.01565
SB3 Clip Fraction: 0.18912
Policy Update Magnitude: 0.43441
Value Function Update Magnitude: 0.29395

Collected Steps per Second: 20,890.77273
Overall Steps per Second: 10,241.67700

Timestep Collection Time: 2.39426
Timestep Consumption Time: 2.48951
PPO Batch Consumption Time: 0.29196
Total Iteration Time: 4.88377

Cumulative Model Updates: 110,062
Cumulative Timesteps: 917,758,356

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 917758356...
Checkpoint 917758356 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,576.23528
Policy Entropy: 3.74584
Value Function Loss: 0.04139

Mean KL Divergence: 0.01539
SB3 Clip Fraction: 0.18707
Policy Update Magnitude: 0.43783
Value Function Update Magnitude: 0.28107

Collected Steps per Second: 20,755.78427
Overall Steps per Second: 10,146.83721

Timestep Collection Time: 2.40974
Timestep Consumption Time: 2.51948
PPO Batch Consumption Time: 0.28830
Total Iteration Time: 4.92922

Cumulative Model Updates: 110,068
Cumulative Timesteps: 917,808,372

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,576.23528
Policy Entropy: 3.77170
Value Function Loss: 0.03124

Mean KL Divergence: 0.01409
SB3 Clip Fraction: 0.17269
Policy Update Magnitude: 0.45600
Value Function Update Magnitude: 0.30854

Collected Steps per Second: 20,848.18671
Overall Steps per Second: 10,041.47378

Timestep Collection Time: 2.39887
Timestep Consumption Time: 2.58168
PPO Batch Consumption Time: 0.29731
Total Iteration Time: 4.98054

Cumulative Model Updates: 110,074
Cumulative Timesteps: 917,858,384

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 917858384...
Checkpoint 917858384 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 66,575.28479
Policy Entropy: 3.73289
Value Function Loss: 0.03424

Mean KL Divergence: 0.01321
SB3 Clip Fraction: 0.16809
Policy Update Magnitude: 0.51293
Value Function Update Magnitude: 0.39862

Collected Steps per Second: 20,854.71925
Overall Steps per Second: 9,883.66800

Timestep Collection Time: 2.39946
Timestep Consumption Time: 2.66344
PPO Batch Consumption Time: 0.31483
Total Iteration Time: 5.06290

Cumulative Model Updates: 110,080
Cumulative Timesteps: 917,908,424

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55,161.43688
Policy Entropy: 3.74225
Value Function Loss: 0.03289

Mean KL Divergence: 0.01169
SB3 Clip Fraction: 0.15438
Policy Update Magnitude: 0.56844
Value Function Update Magnitude: 0.45288

Collected Steps per Second: 17,177.84465
Overall Steps per Second: 8,590.67067

Timestep Collection Time: 2.91131
Timestep Consumption Time: 2.91012
PPO Batch Consumption Time: 0.34416
Total Iteration Time: 5.82143

Cumulative Model Updates: 110,086
Cumulative Timesteps: 917,958,434

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 917958434...
Checkpoint 917958434 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,586.23175
Policy Entropy: 3.72975
Value Function Loss: 0.03523

Mean KL Divergence: 0.01152
SB3 Clip Fraction: 0.15485
Policy Update Magnitude: 0.56612
Value Function Update Magnitude: 0.47974

Collected Steps per Second: 19,477.90903
Overall Steps per Second: 9,727.25119

Timestep Collection Time: 2.56835
Timestep Consumption Time: 2.57453
PPO Batch Consumption Time: 0.29526
Total Iteration Time: 5.14287

Cumulative Model Updates: 110,092
Cumulative Timesteps: 918,008,460

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,629.68385
Policy Entropy: 3.74886
Value Function Loss: 0.03178

Mean KL Divergence: 0.01088
SB3 Clip Fraction: 0.14786
Policy Update Magnitude: 0.59565
Value Function Update Magnitude: 0.46433

Collected Steps per Second: 20,779.45212
Overall Steps per Second: 9,928.27920

Timestep Collection Time: 2.40719
Timestep Consumption Time: 2.63095
PPO Batch Consumption Time: 0.30021
Total Iteration Time: 5.03813

Cumulative Model Updates: 110,098
Cumulative Timesteps: 918,058,480

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 918058480...
Checkpoint 918058480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,629.68385
Policy Entropy: 3.71749
Value Function Loss: 0.03091

Mean KL Divergence: 0.01121
SB3 Clip Fraction: 0.15145
Policy Update Magnitude: 0.55951
Value Function Update Magnitude: 0.42110

Collected Steps per Second: 20,545.75810
Overall Steps per Second: 9,953.85526

Timestep Collection Time: 2.43457
Timestep Consumption Time: 2.59062
PPO Batch Consumption Time: 0.30761
Total Iteration Time: 5.02519

Cumulative Model Updates: 110,104
Cumulative Timesteps: 918,108,500

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,629.68385
Policy Entropy: 3.70484
Value Function Loss: 0.02792

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.14323
Policy Update Magnitude: 0.49273
Value Function Update Magnitude: 0.40702

Collected Steps per Second: 19,315.80986
Overall Steps per Second: 9,738.55658

Timestep Collection Time: 2.59021
Timestep Consumption Time: 2.54731
PPO Batch Consumption Time: 0.29790
Total Iteration Time: 5.13752

Cumulative Model Updates: 110,110
Cumulative Timesteps: 918,158,532

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 918158532...
Checkpoint 918158532 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 200,568.15912
Policy Entropy: 3.70811
Value Function Loss: 0.02682

Mean KL Divergence: 0.01088
SB3 Clip Fraction: 0.15065
Policy Update Magnitude: 0.45184
Value Function Update Magnitude: 0.38620

Collected Steps per Second: 20,849.16549
Overall Steps per Second: 10,073.03677

Timestep Collection Time: 2.39952
Timestep Consumption Time: 2.56701
PPO Batch Consumption Time: 0.29562
Total Iteration Time: 4.96653

Cumulative Model Updates: 110,116
Cumulative Timesteps: 918,208,560

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 412,972.30647
Policy Entropy: 3.71979
Value Function Loss: 0.02591

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.14446
Policy Update Magnitude: 0.44279
Value Function Update Magnitude: 0.39611

Collected Steps per Second: 21,129.23120
Overall Steps per Second: 10,136.32389

Timestep Collection Time: 2.36667
Timestep Consumption Time: 2.56667
PPO Batch Consumption Time: 0.29721
Total Iteration Time: 4.93335

Cumulative Model Updates: 110,122
Cumulative Timesteps: 918,258,566

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 918258566...
Checkpoint 918258566 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 143,997.15683
Policy Entropy: 3.72678
Value Function Loss: 0.02502

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.13982
Policy Update Magnitude: 0.42895
Value Function Update Magnitude: 0.46863

Collected Steps per Second: 20,659.54838
Overall Steps per Second: 9,825.63052

Timestep Collection Time: 2.42106
Timestep Consumption Time: 2.66950
PPO Batch Consumption Time: 0.30495
Total Iteration Time: 5.09056

Cumulative Model Updates: 110,128
Cumulative Timesteps: 918,308,584

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76,530.79576
Policy Entropy: 3.73102
Value Function Loss: 0.02305

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.15000
Policy Update Magnitude: 0.39544
Value Function Update Magnitude: 0.59570

Collected Steps per Second: 20,274.80253
Overall Steps per Second: 9,991.66875

Timestep Collection Time: 2.46730
Timestep Consumption Time: 2.53927
PPO Batch Consumption Time: 0.30279
Total Iteration Time: 5.00657

Cumulative Model Updates: 110,134
Cumulative Timesteps: 918,358,608

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 918358608...
Checkpoint 918358608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 310,865.41303
Policy Entropy: 3.73837
Value Function Loss: 0.02246

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.14309
Policy Update Magnitude: 0.37280
Value Function Update Magnitude: 0.68265

Collected Steps per Second: 20,145.67848
Overall Steps per Second: 10,099.35181

Timestep Collection Time: 2.48351
Timestep Consumption Time: 2.47047
PPO Batch Consumption Time: 0.29483
Total Iteration Time: 4.95398

Cumulative Model Updates: 110,140
Cumulative Timesteps: 918,408,640

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 310,865.41303
Policy Entropy: 3.73622
Value Function Loss: 0.02172

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.14662
Policy Update Magnitude: 0.41826
Value Function Update Magnitude: 0.66924

Collected Steps per Second: 20,042.12437
Overall Steps per Second: 9,802.13676

Timestep Collection Time: 2.49495
Timestep Consumption Time: 2.60639
PPO Batch Consumption Time: 0.30615
Total Iteration Time: 5.10134

Cumulative Model Updates: 110,146
Cumulative Timesteps: 918,458,644

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 918458644...
Checkpoint 918458644 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 349,700.79486
Policy Entropy: 3.72462
Value Function Loss: 0.02465

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.13739
Policy Update Magnitude: 0.45273
Value Function Update Magnitude: 0.59454

Collected Steps per Second: 20,662.49230
Overall Steps per Second: 10,088.08575

Timestep Collection Time: 2.42004
Timestep Consumption Time: 2.53670
PPO Batch Consumption Time: 0.29477
Total Iteration Time: 4.95674

Cumulative Model Updates: 110,152
Cumulative Timesteps: 918,508,648

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 229,442.13439
Policy Entropy: 3.72091
Value Function Loss: 0.02349

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.14229
Policy Update Magnitude: 0.44988
Value Function Update Magnitude: 0.47829

Collected Steps per Second: 21,065.53154
Overall Steps per Second: 10,123.09000

Timestep Collection Time: 2.37487
Timestep Consumption Time: 2.56709
PPO Batch Consumption Time: 0.30237
Total Iteration Time: 4.94197

Cumulative Model Updates: 110,158
Cumulative Timesteps: 918,558,676

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 918558676...
Checkpoint 918558676 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 229,442.13439
Policy Entropy: 3.71154
Value Function Loss: 0.02337

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.14144
Policy Update Magnitude: 0.45431
Value Function Update Magnitude: 0.45912

Collected Steps per Second: 20,818.57516
Overall Steps per Second: 10,094.85426

Timestep Collection Time: 2.40305
Timestep Consumption Time: 2.55275
PPO Batch Consumption Time: 0.29426
Total Iteration Time: 4.95579

Cumulative Model Updates: 110,164
Cumulative Timesteps: 918,608,704

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 214,249.34534
Policy Entropy: 3.72381
Value Function Loss: 0.02171

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.13944
Policy Update Magnitude: 0.45646
Value Function Update Magnitude: 0.52691

Collected Steps per Second: 21,038.84734
Overall Steps per Second: 10,155.35703

Timestep Collection Time: 2.37770
Timestep Consumption Time: 2.54818
PPO Batch Consumption Time: 0.29297
Total Iteration Time: 4.92587

Cumulative Model Updates: 110,170
Cumulative Timesteps: 918,658,728

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 918658728...
Checkpoint 918658728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 286,715.63988
Policy Entropy: 3.71683
Value Function Loss: 0.02395

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.14701
Policy Update Magnitude: 0.45829
Value Function Update Magnitude: 0.56262

Collected Steps per Second: 20,798.06005
Overall Steps per Second: 10,093.11486

Timestep Collection Time: 2.40426
Timestep Consumption Time: 2.55001
PPO Batch Consumption Time: 0.29451
Total Iteration Time: 4.95427

Cumulative Model Updates: 110,176
Cumulative Timesteps: 918,708,732

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 189,436.44157
Policy Entropy: 3.75538
Value Function Loss: 0.02285

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.13538
Policy Update Magnitude: 0.45448
Value Function Update Magnitude: 0.57258

Collected Steps per Second: 21,228.57750
Overall Steps per Second: 10,130.99929

Timestep Collection Time: 2.35598
Timestep Consumption Time: 2.58075
PPO Batch Consumption Time: 0.29740
Total Iteration Time: 4.93673

Cumulative Model Updates: 110,182
Cumulative Timesteps: 918,758,746

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 918758746...
Checkpoint 918758746 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 269,454.55827
Policy Entropy: 3.73754
Value Function Loss: 0.02348

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.14387
Policy Update Magnitude: 0.46108
Value Function Update Magnitude: 0.64215

Collected Steps per Second: 20,818.98352
Overall Steps per Second: 10,027.05903

Timestep Collection Time: 2.40261
Timestep Consumption Time: 2.58589
PPO Batch Consumption Time: 0.30043
Total Iteration Time: 4.98850

Cumulative Model Updates: 110,188
Cumulative Timesteps: 918,808,766

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 176,813.79879
Policy Entropy: 3.75059
Value Function Loss: 0.02204

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.14596
Policy Update Magnitude: 0.45676
Value Function Update Magnitude: 0.70790

Collected Steps per Second: 21,165.17258
Overall Steps per Second: 10,189.50338

Timestep Collection Time: 2.36379
Timestep Consumption Time: 2.54617
PPO Batch Consumption Time: 0.29365
Total Iteration Time: 4.90995

Cumulative Model Updates: 110,194
Cumulative Timesteps: 918,858,796

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 918858796...
Checkpoint 918858796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 213,108.86399
Policy Entropy: 3.71909
Value Function Loss: 0.02380

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.14771
Policy Update Magnitude: 0.44343
Value Function Update Magnitude: 0.62640

Collected Steps per Second: 20,311.26317
Overall Steps per Second: 10,033.68006

Timestep Collection Time: 2.46307
Timestep Consumption Time: 2.52294
PPO Batch Consumption Time: 0.30168
Total Iteration Time: 4.98601

Cumulative Model Updates: 110,200
Cumulative Timesteps: 918,908,824

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 139,822.92425
Policy Entropy: 3.73445
Value Function Loss: 0.02279

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.14612
Policy Update Magnitude: 0.42919
Value Function Update Magnitude: 0.48722

Collected Steps per Second: 20,536.86271
Overall Steps per Second: 10,182.53552

Timestep Collection Time: 2.43572
Timestep Consumption Time: 2.47681
PPO Batch Consumption Time: 0.29488
Total Iteration Time: 4.91253

Cumulative Model Updates: 110,206
Cumulative Timesteps: 918,958,846

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 918958846...
Checkpoint 918958846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 139,822.92425
Policy Entropy: 3.71993
Value Function Loss: 0.02372

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.14415
Policy Update Magnitude: 0.42100
Value Function Update Magnitude: 0.44152

Collected Steps per Second: 20,494.35207
Overall Steps per Second: 9,922.35531

Timestep Collection Time: 2.44009
Timestep Consumption Time: 2.59985
PPO Batch Consumption Time: 0.30705
Total Iteration Time: 5.03993

Cumulative Model Updates: 110,212
Cumulative Timesteps: 919,008,854

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 100,832.94687
Policy Entropy: 3.74043
Value Function Loss: 0.02238

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.13992
Policy Update Magnitude: 0.43638
Value Function Update Magnitude: 0.46147

Collected Steps per Second: 21,100.01810
Overall Steps per Second: 10,093.28522

Timestep Collection Time: 2.37118
Timestep Consumption Time: 2.58578
PPO Batch Consumption Time: 0.30630
Total Iteration Time: 4.95696

Cumulative Model Updates: 110,218
Cumulative Timesteps: 919,058,886

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 919058886...
Checkpoint 919058886 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 218,579.60886
Policy Entropy: 3.73072
Value Function Loss: 0.02219

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.14606
Policy Update Magnitude: 0.41206
Value Function Update Magnitude: 0.48797

Collected Steps per Second: 20,648.12879
Overall Steps per Second: 10,077.17242

Timestep Collection Time: 2.42211
Timestep Consumption Time: 2.54079
PPO Batch Consumption Time: 0.29420
Total Iteration Time: 4.96290

Cumulative Model Updates: 110,224
Cumulative Timesteps: 919,108,898

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 218,579.60886
Policy Entropy: 3.73813
Value Function Loss: 0.02059

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.14332
Policy Update Magnitude: 0.38672
Value Function Update Magnitude: 0.45617

Collected Steps per Second: 21,109.62173
Overall Steps per Second: 10,101.08084

Timestep Collection Time: 2.37086
Timestep Consumption Time: 2.58386
PPO Batch Consumption Time: 0.29790
Total Iteration Time: 4.95472

Cumulative Model Updates: 110,230
Cumulative Timesteps: 919,158,946

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 919158946...
Checkpoint 919158946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 218,579.60886
Policy Entropy: 3.72441
Value Function Loss: 0.02135

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.14396
Policy Update Magnitude: 0.37009
Value Function Update Magnitude: 0.41983

Collected Steps per Second: 20,787.68949
Overall Steps per Second: 9,970.44238

Timestep Collection Time: 2.40691
Timestep Consumption Time: 2.61133
PPO Batch Consumption Time: 0.30209
Total Iteration Time: 5.01823

Cumulative Model Updates: 110,236
Cumulative Timesteps: 919,208,980

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 218,579.60886
Policy Entropy: 3.71221
Value Function Loss: 0.01944

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.14364
Policy Update Magnitude: 0.39122
Value Function Update Magnitude: 0.42422

Collected Steps per Second: 21,074.55711
Overall Steps per Second: 10,155.32930

Timestep Collection Time: 2.37262
Timestep Consumption Time: 2.55110
PPO Batch Consumption Time: 0.29387
Total Iteration Time: 4.92372

Cumulative Model Updates: 110,242
Cumulative Timesteps: 919,258,982

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 919258982...
Checkpoint 919258982 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 328,712.86810
Policy Entropy: 3.70525
Value Function Loss: 0.02217

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.14666
Policy Update Magnitude: 0.41929
Value Function Update Magnitude: 0.44620

Collected Steps per Second: 20,748.46950
Overall Steps per Second: 9,958.57769

Timestep Collection Time: 2.40982
Timestep Consumption Time: 2.61098
PPO Batch Consumption Time: 0.30693
Total Iteration Time: 5.02080

Cumulative Model Updates: 110,248
Cumulative Timesteps: 919,308,982

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61,308.13032
Policy Entropy: 3.71291
Value Function Loss: 0.02347

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.13801
Policy Update Magnitude: 0.45332
Value Function Update Magnitude: 0.54396

Collected Steps per Second: 21,126.43464
Overall Steps per Second: 10,025.57413

Timestep Collection Time: 2.36812
Timestep Consumption Time: 2.62211
PPO Batch Consumption Time: 0.30646
Total Iteration Time: 4.99024

Cumulative Model Updates: 110,254
Cumulative Timesteps: 919,359,012

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 919359012...
Checkpoint 919359012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,042.42211
Policy Entropy: 3.72498
Value Function Loss: 0.02465

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.14432
Policy Update Magnitude: 0.46612
Value Function Update Magnitude: 0.65953

Collected Steps per Second: 20,758.60434
Overall Steps per Second: 10,110.56736

Timestep Collection Time: 2.41018
Timestep Consumption Time: 2.53830
PPO Batch Consumption Time: 0.29324
Total Iteration Time: 4.94849

Cumulative Model Updates: 110,260
Cumulative Timesteps: 919,409,044

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 184,080.30632
Policy Entropy: 3.73738
Value Function Loss: 0.02558

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.14657
Policy Update Magnitude: 0.46584
Value Function Update Magnitude: 0.69058

Collected Steps per Second: 20,591.33708
Overall Steps per Second: 10,128.71736

Timestep Collection Time: 2.42821
Timestep Consumption Time: 2.50825
PPO Batch Consumption Time: 0.30018
Total Iteration Time: 4.93646

Cumulative Model Updates: 110,266
Cumulative Timesteps: 919,459,044

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 919459044...
Checkpoint 919459044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 251,171.75731
Policy Entropy: 3.73471
Value Function Loss: 0.02501

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.13500
Policy Update Magnitude: 0.44558
Value Function Update Magnitude: 0.66339

Collected Steps per Second: 20,102.29373
Overall Steps per Second: 10,093.57853

Timestep Collection Time: 2.48897
Timestep Consumption Time: 2.46804
PPO Batch Consumption Time: 0.29460
Total Iteration Time: 4.95701

Cumulative Model Updates: 110,272
Cumulative Timesteps: 919,509,078

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 241,216.32464
Policy Entropy: 3.71830
Value Function Loss: 0.02382

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.14047
Policy Update Magnitude: 0.43727
Value Function Update Magnitude: 0.70318

Collected Steps per Second: 20,415.60270
Overall Steps per Second: 10,157.31161

Timestep Collection Time: 2.44999
Timestep Consumption Time: 2.47435
PPO Batch Consumption Time: 0.29351
Total Iteration Time: 4.92433

Cumulative Model Updates: 110,278
Cumulative Timesteps: 919,559,096

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 919559096...
Checkpoint 919559096 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 326,704.63768
Policy Entropy: 3.71990
Value Function Loss: 0.02160

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.14273
Policy Update Magnitude: 0.42775
Value Function Update Magnitude: 0.63150

Collected Steps per Second: 20,400.84900
Overall Steps per Second: 9,939.73378

Timestep Collection Time: 2.45313
Timestep Consumption Time: 2.58181
PPO Batch Consumption Time: 0.30240
Total Iteration Time: 5.03494

Cumulative Model Updates: 110,284
Cumulative Timesteps: 919,609,142

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 173,633.88779
Policy Entropy: 3.72658
Value Function Loss: 0.02191

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.14431
Policy Update Magnitude: 0.41382
Value Function Update Magnitude: 0.56760

Collected Steps per Second: 20,589.53811
Overall Steps per Second: 9,929.46121

Timestep Collection Time: 2.42958
Timestep Consumption Time: 2.60835
PPO Batch Consumption Time: 0.30602
Total Iteration Time: 5.03794

Cumulative Model Updates: 110,290
Cumulative Timesteps: 919,659,166

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 919659166...
Checkpoint 919659166 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 346,301.23837
Policy Entropy: 3.72477
Value Function Loss: 0.02526

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.14059
Policy Update Magnitude: 0.43973
Value Function Update Magnitude: 0.57150

Collected Steps per Second: 20,738.26739
Overall Steps per Second: 10,140.82200

Timestep Collection Time: 2.41197
Timestep Consumption Time: 2.52057
PPO Batch Consumption Time: 0.29431
Total Iteration Time: 4.93254

Cumulative Model Updates: 110,296
Cumulative Timesteps: 919,709,186

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 363,736.58500
Policy Entropy: 3.72538
Value Function Loss: 0.02418

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.14899
Policy Update Magnitude: 0.50613
Value Function Update Magnitude: 0.61355

Collected Steps per Second: 21,154.69787
Overall Steps per Second: 10,102.14277

Timestep Collection Time: 2.36354
Timestep Consumption Time: 2.58590
PPO Batch Consumption Time: 0.29414
Total Iteration Time: 4.94944

Cumulative Model Updates: 110,302
Cumulative Timesteps: 919,759,186

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 919759186...
Checkpoint 919759186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 199,892.31056
Policy Entropy: 3.71581
Value Function Loss: 0.02649

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.14367
Policy Update Magnitude: 0.54688
Value Function Update Magnitude: 0.62217

Collected Steps per Second: 20,970.70944
Overall Steps per Second: 10,063.15642

Timestep Collection Time: 2.38475
Timestep Consumption Time: 2.58486
PPO Batch Consumption Time: 0.29461
Total Iteration Time: 4.96961

Cumulative Model Updates: 110,308
Cumulative Timesteps: 919,809,196

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63,067.77899
Policy Entropy: 3.73786
Value Function Loss: 0.02306

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.14480
Policy Update Magnitude: 0.54970
Value Function Update Magnitude: 0.67617

Collected Steps per Second: 20,996.10476
Overall Steps per Second: 10,060.95834

Timestep Collection Time: 2.38139
Timestep Consumption Time: 2.58831
PPO Batch Consumption Time: 0.29459
Total Iteration Time: 4.96971

Cumulative Model Updates: 110,314
Cumulative Timesteps: 919,859,196

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 919859196...
Checkpoint 919859196 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,381.38074
Policy Entropy: 3.71885
Value Function Loss: 0.02660

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.14210
Policy Update Magnitude: 0.55036
Value Function Update Magnitude: 0.86463

Collected Steps per Second: 21,001.68486
Overall Steps per Second: 10,036.43764

Timestep Collection Time: 2.38086
Timestep Consumption Time: 2.60119
PPO Batch Consumption Time: 0.30426
Total Iteration Time: 4.98205

Cumulative Model Updates: 110,320
Cumulative Timesteps: 919,909,198

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,381.38074
Policy Entropy: 3.70290
Value Function Loss: 0.02562

Mean KL Divergence: 0.01102
SB3 Clip Fraction: 0.15050
Policy Update Magnitude: 0.55483
Value Function Update Magnitude: 0.77088

Collected Steps per Second: 21,120.75245
Overall Steps per Second: 10,056.55970

Timestep Collection Time: 2.36734
Timestep Consumption Time: 2.60454
PPO Batch Consumption Time: 0.30222
Total Iteration Time: 4.97188

Cumulative Model Updates: 110,326
Cumulative Timesteps: 919,959,198

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 919959198...
Checkpoint 919959198 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 100,162.00625
Policy Entropy: 3.68563
Value Function Loss: 0.02757

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.14673
Policy Update Magnitude: 0.52227
Value Function Update Magnitude: 0.67065

Collected Steps per Second: 20,999.49922
Overall Steps per Second: 10,028.51957

Timestep Collection Time: 2.38110
Timestep Consumption Time: 2.60488
PPO Batch Consumption Time: 0.30101
Total Iteration Time: 4.98598

Cumulative Model Updates: 110,332
Cumulative Timesteps: 920,009,200

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,928.83921
Policy Entropy: 3.70313
Value Function Loss: 0.02488

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.14507
Policy Update Magnitude: 0.50593
Value Function Update Magnitude: 0.56547

Collected Steps per Second: 20,849.28644
Overall Steps per Second: 10,088.00413

Timestep Collection Time: 2.39922
Timestep Consumption Time: 2.55934
PPO Batch Consumption Time: 0.29586
Total Iteration Time: 4.95856

Cumulative Model Updates: 110,338
Cumulative Timesteps: 920,059,222

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 920059222...
Checkpoint 920059222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 78,776.15316
Policy Entropy: 3.72120
Value Function Loss: 0.02583

Mean KL Divergence: 0.01172
SB3 Clip Fraction: 0.15774
Policy Update Magnitude: 0.48310
Value Function Update Magnitude: 0.54071

Collected Steps per Second: 21,024.44804
Overall Steps per Second: 10,119.26224

Timestep Collection Time: 2.37847
Timestep Consumption Time: 2.56320
PPO Batch Consumption Time: 0.29473
Total Iteration Time: 4.94166

Cumulative Model Updates: 110,344
Cumulative Timesteps: 920,109,228

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,479.94424
Policy Entropy: 3.74219
Value Function Loss: 0.02520

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.13948
Policy Update Magnitude: 0.46700
Value Function Update Magnitude: 0.59325

Collected Steps per Second: 21,117.75817
Overall Steps per Second: 10,092.55545

Timestep Collection Time: 2.36815
Timestep Consumption Time: 2.58699
PPO Batch Consumption Time: 0.29921
Total Iteration Time: 4.95514

Cumulative Model Updates: 110,350
Cumulative Timesteps: 920,159,238

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 920159238...
Checkpoint 920159238 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,263.61395
Policy Entropy: 3.72200
Value Function Loss: 0.02619

Mean KL Divergence: 0.01127
SB3 Clip Fraction: 0.15469
Policy Update Magnitude: 0.50666
Value Function Update Magnitude: 0.54415

Collected Steps per Second: 21,000.56223
Overall Steps per Second: 10,126.23934

Timestep Collection Time: 2.38213
Timestep Consumption Time: 2.55811
PPO Batch Consumption Time: 0.29489
Total Iteration Time: 4.94023

Cumulative Model Updates: 110,356
Cumulative Timesteps: 920,209,264

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 353,086.00559
Policy Entropy: 3.71436
Value Function Loss: 0.02416

Mean KL Divergence: 0.01057
SB3 Clip Fraction: 0.14851
Policy Update Magnitude: 0.48869
Value Function Update Magnitude: 0.52263

Collected Steps per Second: 20,934.41079
Overall Steps per Second: 10,079.36345

Timestep Collection Time: 2.38946
Timestep Consumption Time: 2.57335
PPO Batch Consumption Time: 0.29463
Total Iteration Time: 4.96281

Cumulative Model Updates: 110,362
Cumulative Timesteps: 920,259,286

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 920259286...
Checkpoint 920259286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 353,086.00559
Policy Entropy: 3.71658
Value Function Loss: 0.01951

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.14745
Policy Update Magnitude: 0.45981
Value Function Update Magnitude: 0.52735

Collected Steps per Second: 21,318.87639
Overall Steps per Second: 10,226.33065

Timestep Collection Time: 2.34628
Timestep Consumption Time: 2.54502
PPO Batch Consumption Time: 0.29373
Total Iteration Time: 4.89129

Cumulative Model Updates: 110,368
Cumulative Timesteps: 920,309,306

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 174,863.10651
Policy Entropy: 3.72460
Value Function Loss: 0.02077

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.14944
Policy Update Magnitude: 0.43789
Value Function Update Magnitude: 0.51569

Collected Steps per Second: 21,035.83541
Overall Steps per Second: 10,078.03834

Timestep Collection Time: 2.37899
Timestep Consumption Time: 2.58666
PPO Batch Consumption Time: 0.29853
Total Iteration Time: 4.96565

Cumulative Model Updates: 110,374
Cumulative Timesteps: 920,359,350

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 920359350...
Checkpoint 920359350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 199,498.67547
Policy Entropy: 3.74191
Value Function Loss: 0.02001

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.14306
Policy Update Magnitude: 0.47144
Value Function Update Magnitude: 0.60979

Collected Steps per Second: 20,959.85208
Overall Steps per Second: 10,119.30779

Timestep Collection Time: 2.38589
Timestep Consumption Time: 2.55595
PPO Batch Consumption Time: 0.29479
Total Iteration Time: 4.94184

Cumulative Model Updates: 110,380
Cumulative Timesteps: 920,409,358

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 345,206.99286
Policy Entropy: 3.72158
Value Function Loss: 0.02100

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.13885
Policy Update Magnitude: 0.48637
Value Function Update Magnitude: 0.67819

Collected Steps per Second: 21,398.76747
Overall Steps per Second: 10,129.22623

Timestep Collection Time: 2.33677
Timestep Consumption Time: 2.59984
PPO Batch Consumption Time: 0.30149
Total Iteration Time: 4.93661

Cumulative Model Updates: 110,386
Cumulative Timesteps: 920,459,362

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 920459362...
Checkpoint 920459362 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 345,206.99286
Policy Entropy: 3.71530
Value Function Loss: 0.01953

Mean KL Divergence: 0.00551
SB3 Clip Fraction: 0.06551
Policy Update Magnitude: 0.57302
Value Function Update Magnitude: 0.61725

Collected Steps per Second: 21,013.30647
Overall Steps per Second: 10,149.32534

Timestep Collection Time: 2.37973
Timestep Consumption Time: 2.54730
PPO Batch Consumption Time: 0.29340
Total Iteration Time: 4.92703

Cumulative Model Updates: 110,392
Cumulative Timesteps: 920,509,368

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 409,600.05958
Policy Entropy: 3.69866
Value Function Loss: 0.02016

Mean KL Divergence: 0.00664
SB3 Clip Fraction: 0.08142
Policy Update Magnitude: 0.67066
Value Function Update Magnitude: 0.58139

Collected Steps per Second: 21,052.34277
Overall Steps per Second: 10,052.48176

Timestep Collection Time: 2.37636
Timestep Consumption Time: 2.60032
PPO Batch Consumption Time: 0.29828
Total Iteration Time: 4.97668

Cumulative Model Updates: 110,398
Cumulative Timesteps: 920,559,396

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 920559396...
Checkpoint 920559396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 274,739.08322
Policy Entropy: 3.72012
Value Function Loss: 0.01990

Mean KL Divergence: 0.00657
SB3 Clip Fraction: 0.08047
Policy Update Magnitude: 0.72710
Value Function Update Magnitude: 0.57388

Collected Steps per Second: 21,298.79460
Overall Steps per Second: 10,203.25967

Timestep Collection Time: 2.34793
Timestep Consumption Time: 2.55325
PPO Batch Consumption Time: 0.29368
Total Iteration Time: 4.90118

Cumulative Model Updates: 110,404
Cumulative Timesteps: 920,609,404

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 274,739.08322
Policy Entropy: 3.71844
Value Function Loss: 0.02060

Mean KL Divergence: 0.00668
SB3 Clip Fraction: 0.08221
Policy Update Magnitude: 0.71237
Value Function Update Magnitude: 0.56194

Collected Steps per Second: 21,221.06910
Overall Steps per Second: 10,073.69490

Timestep Collection Time: 2.35766
Timestep Consumption Time: 2.60894
PPO Batch Consumption Time: 0.30010
Total Iteration Time: 4.96660

Cumulative Model Updates: 110,410
Cumulative Timesteps: 920,659,436

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 920659436...
Checkpoint 920659436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 274,739.08322
Policy Entropy: 3.71943
Value Function Loss: 0.02017

Mean KL Divergence: 0.00667
SB3 Clip Fraction: 0.08302
Policy Update Magnitude: 0.68997
Value Function Update Magnitude: 0.50901

Collected Steps per Second: 20,906.72067
Overall Steps per Second: 10,110.69013

Timestep Collection Time: 2.39301
Timestep Consumption Time: 2.55522
PPO Batch Consumption Time: 0.29480
Total Iteration Time: 4.94823

Cumulative Model Updates: 110,416
Cumulative Timesteps: 920,709,466

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 235,407.83775
Policy Entropy: 3.71960
Value Function Loss: 0.02079

Mean KL Divergence: 0.00639
SB3 Clip Fraction: 0.07976
Policy Update Magnitude: 0.65177
Value Function Update Magnitude: 0.46396

Collected Steps per Second: 20,191.54278
Overall Steps per Second: 10,084.85140

Timestep Collection Time: 2.47767
Timestep Consumption Time: 2.48304
PPO Batch Consumption Time: 0.29400
Total Iteration Time: 4.96071

Cumulative Model Updates: 110,422
Cumulative Timesteps: 920,759,494

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 920759494...
Checkpoint 920759494 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 178,397.84014
Policy Entropy: 3.69852
Value Function Loss: 0.03123

Mean KL Divergence: 0.02255
SB3 Clip Fraction: 0.24163
Policy Update Magnitude: 0.60675
Value Function Update Magnitude: 0.40653

Collected Steps per Second: 20,196.29269
Overall Steps per Second: 10,028.63118

Timestep Collection Time: 2.47679
Timestep Consumption Time: 2.51113
PPO Batch Consumption Time: 0.30264
Total Iteration Time: 4.98792

Cumulative Model Updates: 110,428
Cumulative Timesteps: 920,809,516

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 770,691.84049
Policy Entropy: 3.69060
Value Function Loss: 0.06158

Mean KL Divergence: 0.03211
SB3 Clip Fraction: 0.27714
Policy Update Magnitude: 0.62070
Value Function Update Magnitude: 0.53269

Collected Steps per Second: 19,956.38177
Overall Steps per Second: 9,890.64023

Timestep Collection Time: 2.50657
Timestep Consumption Time: 2.55094
PPO Batch Consumption Time: 0.30769
Total Iteration Time: 5.05751

Cumulative Model Updates: 110,434
Cumulative Timesteps: 920,859,538

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 920859538...
Checkpoint 920859538 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 98,666.26116
Policy Entropy: 3.75185
Value Function Loss: 0.07425

Mean KL Divergence: 0.01633
SB3 Clip Fraction: 0.18569
Policy Update Magnitude: 1.07807
Value Function Update Magnitude: 0.63870

Collected Steps per Second: 20,023.72079
Overall Steps per Second: 10,081.17122

Timestep Collection Time: 2.49874
Timestep Consumption Time: 2.46438
PPO Batch Consumption Time: 0.29536
Total Iteration Time: 4.96311

Cumulative Model Updates: 110,440
Cumulative Timesteps: 920,909,572

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 146,180.80007
Policy Entropy: 3.82663
Value Function Loss: 0.06536

Mean KL Divergence: 0.01812
SB3 Clip Fraction: 0.20509
Policy Update Magnitude: 1.30820
Value Function Update Magnitude: 0.77927

Collected Steps per Second: 20,613.69702
Overall Steps per Second: 10,151.88616

Timestep Collection Time: 2.42644
Timestep Consumption Time: 2.50052
PPO Batch Consumption Time: 0.29674
Total Iteration Time: 4.92697

Cumulative Model Updates: 110,446
Cumulative Timesteps: 920,959,590

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 920959590...
Checkpoint 920959590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 722.38487
Policy Entropy: 3.94427
Value Function Loss: 0.04890

Mean KL Divergence: 0.02035
SB3 Clip Fraction: 0.21934
Policy Update Magnitude: 1.25069
Value Function Update Magnitude: 1.10295

Collected Steps per Second: 20,823.49983
Overall Steps per Second: 10,094.64563

Timestep Collection Time: 2.40123
Timestep Consumption Time: 2.55209
PPO Batch Consumption Time: 0.29487
Total Iteration Time: 4.95332

Cumulative Model Updates: 110,452
Cumulative Timesteps: 921,009,592

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 399.00194
Policy Entropy: 3.95375
Value Function Loss: 0.04653

Mean KL Divergence: 0.01412
SB3 Clip Fraction: 0.16407
Policy Update Magnitude: 1.28860
Value Function Update Magnitude: 1.24483

Collected Steps per Second: 21,238.70539
Overall Steps per Second: 10,191.01605

Timestep Collection Time: 2.35523
Timestep Consumption Time: 2.55321
PPO Batch Consumption Time: 0.29329
Total Iteration Time: 4.90844

Cumulative Model Updates: 110,458
Cumulative Timesteps: 921,059,614

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 921059614...
Checkpoint 921059614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,695.37526
Policy Entropy: 3.92125
Value Function Loss: 0.04877

Mean KL Divergence: 0.01310
SB3 Clip Fraction: 0.15903
Policy Update Magnitude: 1.20899
Value Function Update Magnitude: 1.20082

Collected Steps per Second: 20,860.89636
Overall Steps per Second: 10,121.02078

Timestep Collection Time: 2.39731
Timestep Consumption Time: 2.54389
PPO Batch Consumption Time: 0.29349
Total Iteration Time: 4.94120

Cumulative Model Updates: 110,464
Cumulative Timesteps: 921,109,624

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 376.42442
Policy Entropy: 3.86034
Value Function Loss: 0.04984

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.11794
Policy Update Magnitude: 1.05177
Value Function Update Magnitude: 1.03998

Collected Steps per Second: 21,444.27850
Overall Steps per Second: 10,096.71267

Timestep Collection Time: 2.33312
Timestep Consumption Time: 2.62216
PPO Batch Consumption Time: 0.30597
Total Iteration Time: 4.95528

Cumulative Model Updates: 110,470
Cumulative Timesteps: 921,159,656

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 921159656...
Checkpoint 921159656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48,115.46844
Policy Entropy: 3.81507
Value Function Loss: 0.04699

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.10243
Policy Update Magnitude: 1.00751
Value Function Update Magnitude: 0.87589

Collected Steps per Second: 20,925.29986
Overall Steps per Second: 10,129.39195

Timestep Collection Time: 2.39041
Timestep Consumption Time: 2.54770
PPO Batch Consumption Time: 0.29374
Total Iteration Time: 4.93810

Cumulative Model Updates: 110,476
Cumulative Timesteps: 921,209,676

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,779.73869
Policy Entropy: 3.77624
Value Function Loss: 0.04207

Mean KL Divergence: 0.01584
SB3 Clip Fraction: 0.19883
Policy Update Magnitude: 0.81048
Value Function Update Magnitude: 0.68170

Collected Steps per Second: 21,062.96754
Overall Steps per Second: 10,109.76256

Timestep Collection Time: 2.37393
Timestep Consumption Time: 2.57198
PPO Batch Consumption Time: 0.29656
Total Iteration Time: 4.94591

Cumulative Model Updates: 110,482
Cumulative Timesteps: 921,259,678

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 921259678...
Checkpoint 921259678 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,606.21787
Policy Entropy: 3.76206
Value Function Loss: 0.04893

Mean KL Divergence: 0.02560
SB3 Clip Fraction: 0.27257
Policy Update Magnitude: 0.61176
Value Function Update Magnitude: 0.54203

Collected Steps per Second: 20,803.15121
Overall Steps per Second: 10,116.01746

Timestep Collection Time: 2.40416
Timestep Consumption Time: 2.53989
PPO Batch Consumption Time: 0.29460
Total Iteration Time: 4.94404

Cumulative Model Updates: 110,488
Cumulative Timesteps: 921,309,692

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53,316.49901
Policy Entropy: 3.73436
Value Function Loss: 0.05525

Mean KL Divergence: 0.02130
SB3 Clip Fraction: 0.22844
Policy Update Magnitude: 0.53365
Value Function Update Magnitude: 0.47866

Collected Steps per Second: 21,002.34094
Overall Steps per Second: 10,114.80901

Timestep Collection Time: 2.38173
Timestep Consumption Time: 2.56369
PPO Batch Consumption Time: 0.29465
Total Iteration Time: 4.94542

Cumulative Model Updates: 110,494
Cumulative Timesteps: 921,359,714

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 921359714...
Checkpoint 921359714 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,863.57005
Policy Entropy: 3.77189
Value Function Loss: 0.06186

Mean KL Divergence: 0.01326
SB3 Clip Fraction: 0.16211
Policy Update Magnitude: 0.57728
Value Function Update Magnitude: 0.48955

Collected Steps per Second: 20,499.79700
Overall Steps per Second: 9,842.92120

Timestep Collection Time: 2.43993
Timestep Consumption Time: 2.64169
PPO Batch Consumption Time: 0.30745
Total Iteration Time: 5.08162

Cumulative Model Updates: 110,500
Cumulative Timesteps: 921,409,732

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,047.97114
Policy Entropy: 3.79777
Value Function Loss: 0.05618

Mean KL Divergence: 0.01122
SB3 Clip Fraction: 0.13927
Policy Update Magnitude: 0.83733
Value Function Update Magnitude: 0.53974

Collected Steps per Second: 21,120.10361
Overall Steps per Second: 10,027.46004

Timestep Collection Time: 2.36817
Timestep Consumption Time: 2.61973
PPO Batch Consumption Time: 0.30650
Total Iteration Time: 4.98790

Cumulative Model Updates: 110,506
Cumulative Timesteps: 921,459,748

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 921459748...
Checkpoint 921459748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,315.49196
Policy Entropy: 3.78775
Value Function Loss: 0.05877

Mean KL Divergence: 0.01439
SB3 Clip Fraction: 0.17141
Policy Update Magnitude: 0.82676
Value Function Update Magnitude: 0.54645

Collected Steps per Second: 20,957.55402
Overall Steps per Second: 10,139.97199

Timestep Collection Time: 2.38702
Timestep Consumption Time: 2.54653
PPO Batch Consumption Time: 0.29480
Total Iteration Time: 4.93354

Cumulative Model Updates: 110,512
Cumulative Timesteps: 921,509,774

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,210.49637
Policy Entropy: 3.78134
Value Function Loss: 0.05070

Mean KL Divergence: 0.01217
SB3 Clip Fraction: 0.15927
Policy Update Magnitude: 0.66745
Value Function Update Magnitude: 0.43213

Collected Steps per Second: 21,251.30277
Overall Steps per Second: 10,191.07491

Timestep Collection Time: 2.35411
Timestep Consumption Time: 2.55489
PPO Batch Consumption Time: 0.29305
Total Iteration Time: 4.90900

Cumulative Model Updates: 110,518
Cumulative Timesteps: 921,559,802

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 921559802...
Checkpoint 921559802 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 462.56896
Policy Entropy: 3.77683
Value Function Loss: 0.04206

Mean KL Divergence: 0.01213
SB3 Clip Fraction: 0.15219
Policy Update Magnitude: 0.56244
Value Function Update Magnitude: 0.40936

Collected Steps per Second: 20,942.16115
Overall Steps per Second: 10,098.17756

Timestep Collection Time: 2.38877
Timestep Consumption Time: 2.56519
PPO Batch Consumption Time: 0.29478
Total Iteration Time: 4.95396

Cumulative Model Updates: 110,524
Cumulative Timesteps: 921,609,828

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,772.70911
Policy Entropy: 3.78143
Value Function Loss: 0.03095

Mean KL Divergence: 0.01912
SB3 Clip Fraction: 0.22655
Policy Update Magnitude: 0.47663
Value Function Update Magnitude: 0.44772

Collected Steps per Second: 21,329.39282
Overall Steps per Second: 10,123.51822

Timestep Collection Time: 2.34446
Timestep Consumption Time: 2.59512
PPO Batch Consumption Time: 0.30125
Total Iteration Time: 4.93959

Cumulative Model Updates: 110,530
Cumulative Timesteps: 921,659,834

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 921659834...
Checkpoint 921659834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,469.05805
Policy Entropy: 3.77766
Value Function Loss: 0.03293

Mean KL Divergence: 0.03064
SB3 Clip Fraction: 0.30150
Policy Update Magnitude: 0.35643
Value Function Update Magnitude: 0.52236

Collected Steps per Second: 20,708.13577
Overall Steps per Second: 10,089.34932

Timestep Collection Time: 2.41528
Timestep Consumption Time: 2.54202
PPO Batch Consumption Time: 0.29435
Total Iteration Time: 4.95731

Cumulative Model Updates: 110,536
Cumulative Timesteps: 921,709,850

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 525.03144
Policy Entropy: 3.78211
Value Function Loss: 0.03571

Mean KL Divergence: 0.01436
SB3 Clip Fraction: 0.17735
Policy Update Magnitude: 0.37188
Value Function Update Magnitude: 0.46845

Collected Steps per Second: 21,173.45942
Overall Steps per Second: 10,150.66205

Timestep Collection Time: 2.36390
Timestep Consumption Time: 2.56701
PPO Batch Consumption Time: 0.29687
Total Iteration Time: 4.93091

Cumulative Model Updates: 110,542
Cumulative Timesteps: 921,759,902

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


Saving checkpoint 921759902...
Checkpoint 921759902 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,572.80287
Policy Entropy: 3.79217
Value Function Loss: 0.03713

Mean KL Divergence: 0.02923
SB3 Clip Fraction: 0.27842
Policy Update Magnitude: 0.40871
Value Function Update Magnitude: 0.54213

Collected Steps per Second: 20,703.21004
Overall Steps per Second: 10,016.81210

Timestep Collection Time: 2.41740
Timestep Consumption Time: 2.57900
PPO Batch Consumption Time: 0.30088
Total Iteration Time: 4.99640

Cumulative Model Updates: 110,548
Cumulative Timesteps: 921,809,950

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,615.06513
Policy Entropy: 3.82716
Value Function Loss: 0.03880

Mean KL Divergence: 0.01784
SB3 Clip Fraction: 0.20041
Policy Update Magnitude: 0.42897
Value Function Update Magnitude: 0.53876

Collected Steps per Second: 21,159.89756
Overall Steps per Second: 10,181.56438

Timestep Collection Time: 2.36296
Timestep Consumption Time: 2.54788
PPO Batch Consumption Time: 0.29381
Total Iteration Time: 4.91084

Cumulative Model Updates: 110,554
Cumulative Timesteps: 921,859,950

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 921859950...
Checkpoint 921859950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,629.98398
Policy Entropy: 3.86540
Value Function Loss: 0.03944

Mean KL Divergence: 0.01107
SB3 Clip Fraction: 0.13864
Policy Update Magnitude: 0.53995
Value Function Update Magnitude: 0.63347

Collected Steps per Second: 21,248.23953
Overall Steps per Second: 10,173.96098

Timestep Collection Time: 2.35342
Timestep Consumption Time: 2.56168
PPO Batch Consumption Time: 0.29631
Total Iteration Time: 4.91510

Cumulative Model Updates: 110,560
Cumulative Timesteps: 921,909,956

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11.73350
Policy Entropy: 3.87630
Value Function Loss: 0.03875

Mean KL Divergence: 0.00700
SB3 Clip Fraction: 0.08586
Policy Update Magnitude: 0.69858
Value Function Update Magnitude: 0.71096

Collected Steps per Second: 20,948.12443
Overall Steps per Second: 10,070.69077

Timestep Collection Time: 2.38733
Timestep Consumption Time: 2.57857
PPO Batch Consumption Time: 0.29503
Total Iteration Time: 4.96590

Cumulative Model Updates: 110,566
Cumulative Timesteps: 921,959,966

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 921959966...
Checkpoint 921959966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,641.94009
Policy Entropy: 3.86240
Value Function Loss: 0.03902

Mean KL Divergence: 0.00661
SB3 Clip Fraction: 0.08400
Policy Update Magnitude: 0.75710
Value Function Update Magnitude: 0.72768

Collected Steps per Second: 21,152.34585
Overall Steps per Second: 10,182.79453

Timestep Collection Time: 2.36541
Timestep Consumption Time: 2.54817
PPO Batch Consumption Time: 0.29452
Total Iteration Time: 4.91358

Cumulative Model Updates: 110,572
Cumulative Timesteps: 922,010,000

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,025.17021
Policy Entropy: 3.83060
Value Function Loss: 0.04042

Mean KL Divergence: 0.00622
SB3 Clip Fraction: 0.07775
Policy Update Magnitude: 0.73562
Value Function Update Magnitude: 0.68365

Collected Steps per Second: 21,046.63997
Overall Steps per Second: 10,150.17544

Timestep Collection Time: 2.37701
Timestep Consumption Time: 2.55178
PPO Batch Consumption Time: 0.29411
Total Iteration Time: 4.92878

Cumulative Model Updates: 110,578
Cumulative Timesteps: 922,060,028

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 922060028...
Checkpoint 922060028 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,560.06324
Policy Entropy: 3.83468
Value Function Loss: 0.03895

Mean KL Divergence: 0.00621
SB3 Clip Fraction: 0.07819
Policy Update Magnitude: 0.76010
Value Function Update Magnitude: 0.61135

Collected Steps per Second: 20,639.20900
Overall Steps per Second: 10,084.70052

Timestep Collection Time: 2.42383
Timestep Consumption Time: 2.53675
PPO Batch Consumption Time: 0.29555
Total Iteration Time: 4.96058

Cumulative Model Updates: 110,584
Cumulative Timesteps: 922,110,054

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,996.48861
Policy Entropy: 3.84938
Value Function Loss: 0.04093

Mean KL Divergence: 0.01058
SB3 Clip Fraction: 0.14036
Policy Update Magnitude: 0.64887
Value Function Update Magnitude: 0.68632

Collected Steps per Second: 20,885.09921
Overall Steps per Second: 10,108.10812

Timestep Collection Time: 2.39443
Timestep Consumption Time: 2.55288
PPO Batch Consumption Time: 0.29437
Total Iteration Time: 4.94732

Cumulative Model Updates: 110,590
Cumulative Timesteps: 922,160,062

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 922160062...
Checkpoint 922160062 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 210.02973
Policy Entropy: 3.85994
Value Function Loss: 0.03861

Mean KL Divergence: 0.01058
SB3 Clip Fraction: 0.13921
Policy Update Magnitude: 0.56624
Value Function Update Magnitude: 0.67640

Collected Steps per Second: 20,764.56186
Overall Steps per Second: 9,940.50637

Timestep Collection Time: 2.40949
Timestep Consumption Time: 2.62365
PPO Batch Consumption Time: 0.30596
Total Iteration Time: 5.03314

Cumulative Model Updates: 110,596
Cumulative Timesteps: 922,210,094

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,112.85520
Policy Entropy: 3.82458
Value Function Loss: 0.04705

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.13163
Policy Update Magnitude: 0.57217
Value Function Update Magnitude: 0.71111

Collected Steps per Second: 20,873.72586
Overall Steps per Second: 9,982.84796

Timestep Collection Time: 2.39545
Timestep Consumption Time: 2.61334
PPO Batch Consumption Time: 0.30668
Total Iteration Time: 5.00879

Cumulative Model Updates: 110,602
Cumulative Timesteps: 922,260,096

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 922260096...
Checkpoint 922260096 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 99,709.44446
Policy Entropy: 3.82593
Value Function Loss: 0.04786

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.12315
Policy Update Magnitude: 0.64107
Value Function Update Magnitude: 0.88472

Collected Steps per Second: 20,539.07855
Overall Steps per Second: 9,935.59757

Timestep Collection Time: 2.43555
Timestep Consumption Time: 2.59927
PPO Batch Consumption Time: 0.30328
Total Iteration Time: 5.03483

Cumulative Model Updates: 110,608
Cumulative Timesteps: 922,310,120

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,561.41913
Policy Entropy: 3.80647
Value Function Loss: 0.05142

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.13023
Policy Update Magnitude: 0.63989
Value Function Update Magnitude: 0.83998

Collected Steps per Second: 21,008.41130
Overall Steps per Second: 10,046.28239

Timestep Collection Time: 2.38095
Timestep Consumption Time: 2.59801
PPO Batch Consumption Time: 0.30244
Total Iteration Time: 4.97896

Cumulative Model Updates: 110,614
Cumulative Timesteps: 922,360,140

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 922360140...
Checkpoint 922360140 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,447.35087
Policy Entropy: 3.80467
Value Function Loss: 0.04907

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.13106
Policy Update Magnitude: 0.62566
Value Function Update Magnitude: 0.68259

Collected Steps per Second: 20,815.29413
Overall Steps per Second: 10,034.23343

Timestep Collection Time: 2.40218
Timestep Consumption Time: 2.58096
PPO Batch Consumption Time: 0.29811
Total Iteration Time: 4.98314

Cumulative Model Updates: 110,620
Cumulative Timesteps: 922,410,142

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 742.59336
Policy Entropy: 3.79347
Value Function Loss: 0.04955

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.13095
Policy Update Magnitude: 0.59209
Value Function Update Magnitude: 0.56225

Collected Steps per Second: 20,863.31085
Overall Steps per Second: 10,040.28865

Timestep Collection Time: 2.39694
Timestep Consumption Time: 2.58380
PPO Batch Consumption Time: 0.29803
Total Iteration Time: 4.98073

Cumulative Model Updates: 110,626
Cumulative Timesteps: 922,460,150

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 922460150...
Checkpoint 922460150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,274.13621
Policy Entropy: 3.79800
Value Function Loss: 0.04422

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.12398
Policy Update Magnitude: 0.59297
Value Function Update Magnitude: 0.56540

Collected Steps per Second: 20,074.08722
Overall Steps per Second: 10,099.89562

Timestep Collection Time: 2.49117
Timestep Consumption Time: 2.46017
PPO Batch Consumption Time: 0.29472
Total Iteration Time: 4.95134

Cumulative Model Updates: 110,632
Cumulative Timesteps: 922,510,158

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,197.14680
Policy Entropy: 3.77686
Value Function Loss: 0.04181

Mean KL Divergence: 0.01061
SB3 Clip Fraction: 0.13394
Policy Update Magnitude: 0.57697
Value Function Update Magnitude: 0.59477

Collected Steps per Second: 20,132.94555
Overall Steps per Second: 10,065.06980

Timestep Collection Time: 2.48439
Timestep Consumption Time: 2.48508
PPO Batch Consumption Time: 0.29523
Total Iteration Time: 4.96946

Cumulative Model Updates: 110,638
Cumulative Timesteps: 922,560,176

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 922560176...
Checkpoint 922560176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 346.62450
Policy Entropy: 3.76864
Value Function Loss: 0.04042

Mean KL Divergence: 0.01088
SB3 Clip Fraction: 0.13319
Policy Update Magnitude: 0.54035
Value Function Update Magnitude: 0.50365

Collected Steps per Second: 20,088.56090
Overall Steps per Second: 9,969.95580

Timestep Collection Time: 2.49017
Timestep Consumption Time: 2.52730
PPO Batch Consumption Time: 0.30509
Total Iteration Time: 5.01747

Cumulative Model Updates: 110,644
Cumulative Timesteps: 922,610,200

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,328.33025
Policy Entropy: 3.74686
Value Function Loss: 0.04297

Mean KL Divergence: 0.01202
SB3 Clip Fraction: 0.14535
Policy Update Magnitude: 0.53178
Value Function Update Magnitude: 0.43347

Collected Steps per Second: 20,134.56477
Overall Steps per Second: 9,903.76359

Timestep Collection Time: 2.48448
Timestep Consumption Time: 2.56653
PPO Batch Consumption Time: 0.29729
Total Iteration Time: 5.05101

Cumulative Model Updates: 110,650
Cumulative Timesteps: 922,660,224

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 922660224...
Checkpoint 922660224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 91,888.04604
Policy Entropy: 3.77604
Value Function Loss: 0.04498

Mean KL Divergence: 0.01118
SB3 Clip Fraction: 0.14032
Policy Update Magnitude: 0.53804
Value Function Update Magnitude: 0.39523

Collected Steps per Second: 20,453.57000
Overall Steps per Second: 9,782.42390

Timestep Collection Time: 2.44525
Timestep Consumption Time: 2.66739
PPO Batch Consumption Time: 0.31858
Total Iteration Time: 5.11264

Cumulative Model Updates: 110,656
Cumulative Timesteps: 922,710,238

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,180.49547
Policy Entropy: 3.77180
Value Function Loss: 0.04571

Mean KL Divergence: 0.01113
SB3 Clip Fraction: 0.13920
Policy Update Magnitude: 0.53887
Value Function Update Magnitude: 0.54577

Collected Steps per Second: 20,486.76723
Overall Steps per Second: 10,044.65083

Timestep Collection Time: 2.44304
Timestep Consumption Time: 2.53971
PPO Batch Consumption Time: 0.29412
Total Iteration Time: 4.98275

Cumulative Model Updates: 110,662
Cumulative Timesteps: 922,760,288

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 922760288...
Checkpoint 922760288 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,492.87892
Policy Entropy: 3.78627
Value Function Loss: 0.04491

Mean KL Divergence: 0.01114
SB3 Clip Fraction: 0.13961
Policy Update Magnitude: 0.55524
Value Function Update Magnitude: 0.58830

Collected Steps per Second: 20,402.06698
Overall Steps per Second: 9,923.60479

Timestep Collection Time: 2.45181
Timestep Consumption Time: 2.58890
PPO Batch Consumption Time: 0.30775
Total Iteration Time: 5.04071

Cumulative Model Updates: 110,668
Cumulative Timesteps: 922,810,310

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,338.93447
Policy Entropy: 3.77727
Value Function Loss: 0.04565

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.13068
Policy Update Magnitude: 0.53555
Value Function Update Magnitude: 0.52828

Collected Steps per Second: 20,441.63211
Overall Steps per Second: 10,008.15531

Timestep Collection Time: 2.44687
Timestep Consumption Time: 2.55086
PPO Batch Consumption Time: 0.29631
Total Iteration Time: 4.99772

Cumulative Model Updates: 110,674
Cumulative Timesteps: 922,860,328

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 922860328...
Checkpoint 922860328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,104.52913
Policy Entropy: 3.78685
Value Function Loss: 0.04296

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.12887
Policy Update Magnitude: 0.52143
Value Function Update Magnitude: 0.61264

Collected Steps per Second: 20,798.48374
Overall Steps per Second: 10,078.62822

Timestep Collection Time: 2.40402
Timestep Consumption Time: 2.55697
PPO Batch Consumption Time: 0.29502
Total Iteration Time: 4.96099

Cumulative Model Updates: 110,680
Cumulative Timesteps: 922,910,328

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 548.65013
Policy Entropy: 3.77179
Value Function Loss: 0.04156

Mean KL Divergence: 0.01077
SB3 Clip Fraction: 0.13023
Policy Update Magnitude: 0.51871
Value Function Update Magnitude: 0.67354

Collected Steps per Second: 20,797.75666
Overall Steps per Second: 10,073.73824

Timestep Collection Time: 2.40449
Timestep Consumption Time: 2.55970
PPO Batch Consumption Time: 0.29422
Total Iteration Time: 4.96419

Cumulative Model Updates: 110,686
Cumulative Timesteps: 922,960,336

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 922960336...
Checkpoint 922960336 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 95,108.31544
Policy Entropy: 3.73879
Value Function Loss: 0.04570

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.13390
Policy Update Magnitude: 0.49848
Value Function Update Magnitude: 0.54337

Collected Steps per Second: 20,721.49628
Overall Steps per Second: 9,962.57619

Timestep Collection Time: 2.41315
Timestep Consumption Time: 2.60604
PPO Batch Consumption Time: 0.30530
Total Iteration Time: 5.01918

Cumulative Model Updates: 110,692
Cumulative Timesteps: 923,010,340

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62,408.25255
Policy Entropy: 3.72402
Value Function Loss: 0.04133

Mean KL Divergence: 0.01112
SB3 Clip Fraction: 0.14390
Policy Update Magnitude: 0.47992
Value Function Update Magnitude: 0.47848

Collected Steps per Second: 20,841.92334
Overall Steps per Second: 9,957.92071

Timestep Collection Time: 2.39911
Timestep Consumption Time: 2.62222
PPO Batch Consumption Time: 0.29983
Total Iteration Time: 5.02133

Cumulative Model Updates: 110,698
Cumulative Timesteps: 923,060,342

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 923060342...
Checkpoint 923060342 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 70,784.18857
Policy Entropy: 3.71012
Value Function Loss: 0.04357

Mean KL Divergence: 0.01070
SB3 Clip Fraction: 0.14226
Policy Update Magnitude: 0.47741
Value Function Update Magnitude: 0.56205

Collected Steps per Second: 20,531.78447
Overall Steps per Second: 9,930.77803

Timestep Collection Time: 2.43593
Timestep Consumption Time: 2.60033
PPO Batch Consumption Time: 0.30507
Total Iteration Time: 5.03626

Cumulative Model Updates: 110,704
Cumulative Timesteps: 923,110,356

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,082.16494
Policy Entropy: 3.73038
Value Function Loss: 0.03716

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.13214
Policy Update Magnitude: 0.48606
Value Function Update Magnitude: 0.59269

Collected Steps per Second: 20,919.59970
Overall Steps per Second: 9,944.79072

Timestep Collection Time: 2.39020
Timestep Consumption Time: 2.63776
PPO Batch Consumption Time: 0.30684
Total Iteration Time: 5.02796

Cumulative Model Updates: 110,710
Cumulative Timesteps: 923,160,358

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 923160358...
Checkpoint 923160358 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,276.71731
Policy Entropy: 3.72701
Value Function Loss: 0.03448

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.13173
Policy Update Magnitude: 0.49218
Value Function Update Magnitude: 0.53979

Collected Steps per Second: 20,672.94034
Overall Steps per Second: 10,055.30397

Timestep Collection Time: 2.41920
Timestep Consumption Time: 2.55449
PPO Batch Consumption Time: 0.29456
Total Iteration Time: 4.97369

Cumulative Model Updates: 110,716
Cumulative Timesteps: 923,210,370

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,804.26860
Policy Entropy: 3.72819
Value Function Loss: 0.03251

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.14208
Policy Update Magnitude: 0.44910
Value Function Update Magnitude: 0.50410

Collected Steps per Second: 21,185.71823
Overall Steps per Second: 10,122.17383

Timestep Collection Time: 2.36074
Timestep Consumption Time: 2.58029
PPO Batch Consumption Time: 0.29548
Total Iteration Time: 4.94103

Cumulative Model Updates: 110,722
Cumulative Timesteps: 923,260,384

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 923260384...
Checkpoint 923260384 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,804.26860
Policy Entropy: 3.70776
Value Function Loss: 0.03376

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.14778
Policy Update Magnitude: 0.42541
Value Function Update Magnitude: 0.43525

Collected Steps per Second: 20,709.37601
Overall Steps per Second: 9,954.42522

Timestep Collection Time: 2.41610
Timestep Consumption Time: 2.61040
PPO Batch Consumption Time: 0.30329
Total Iteration Time: 5.02651

Cumulative Model Updates: 110,728
Cumulative Timesteps: 923,310,420

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 109,431.60996
Policy Entropy: 3.69621
Value Function Loss: 0.03438

Mean KL Divergence: 0.01077
SB3 Clip Fraction: 0.14609
Policy Update Magnitude: 0.42621
Value Function Update Magnitude: 0.51038

Collected Steps per Second: 20,603.85062
Overall Steps per Second: 9,902.55537

Timestep Collection Time: 2.42722
Timestep Consumption Time: 2.62300
PPO Batch Consumption Time: 0.30415
Total Iteration Time: 5.05021

Cumulative Model Updates: 110,734
Cumulative Timesteps: 923,360,430

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 923360430...
Checkpoint 923360430 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 136,959.85168
Policy Entropy: 3.71347
Value Function Loss: 0.03446

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.14188
Policy Update Magnitude: 0.43793
Value Function Update Magnitude: 0.69471

Collected Steps per Second: 20,863.82999
Overall Steps per Second: 10,021.48670

Timestep Collection Time: 2.39678
Timestep Consumption Time: 2.59310
PPO Batch Consumption Time: 0.30204
Total Iteration Time: 4.98988

Cumulative Model Updates: 110,740
Cumulative Timesteps: 923,410,436

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 136,959.85168
Policy Entropy: 3.71651
Value Function Loss: 0.03433

Mean KL Divergence: 0.01067
SB3 Clip Fraction: 0.14377
Policy Update Magnitude: 0.44496
Value Function Update Magnitude: 0.57944

Collected Steps per Second: 20,859.12651
Overall Steps per Second: 9,986.04291

Timestep Collection Time: 2.39703
Timestep Consumption Time: 2.60996
PPO Batch Consumption Time: 0.30413
Total Iteration Time: 5.00699

Cumulative Model Updates: 110,746
Cumulative Timesteps: 923,460,436

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 923460436...
Checkpoint 923460436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 136,959.85168
Policy Entropy: 3.71896
Value Function Loss: 0.02835

Mean KL Divergence: 0.01099
SB3 Clip Fraction: 0.14960
Policy Update Magnitude: 0.40995
Value Function Update Magnitude: 0.49193

Collected Steps per Second: 20,682.59513
Overall Steps per Second: 10,068.81187

Timestep Collection Time: 2.41749
Timestep Consumption Time: 2.54834
PPO Batch Consumption Time: 0.29339
Total Iteration Time: 4.96583

Cumulative Model Updates: 110,752
Cumulative Timesteps: 923,510,436

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 136,959.85168
Policy Entropy: 3.70321
Value Function Loss: 0.02650

Mean KL Divergence: 0.01151
SB3 Clip Fraction: 0.14786
Policy Update Magnitude: 0.37782
Value Function Update Magnitude: 0.46722

Collected Steps per Second: 20,705.28709
Overall Steps per Second: 10,067.69202

Timestep Collection Time: 2.41561
Timestep Consumption Time: 2.55236
PPO Batch Consumption Time: 0.29311
Total Iteration Time: 4.96797

Cumulative Model Updates: 110,758
Cumulative Timesteps: 923,560,452

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 923560452...
Checkpoint 923560452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 129,995.56151
Policy Entropy: 3.70332
Value Function Loss: 0.02844

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.13766
Policy Update Magnitude: 0.37794
Value Function Update Magnitude: 0.44614

Collected Steps per Second: 20,391.30084
Overall Steps per Second: 9,896.05659

Timestep Collection Time: 2.45310
Timestep Consumption Time: 2.60164
PPO Batch Consumption Time: 0.30411
Total Iteration Time: 5.05474

Cumulative Model Updates: 110,764
Cumulative Timesteps: 923,610,474

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42,861.63150
Policy Entropy: 3.72538
Value Function Loss: 0.02748

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.13757
Policy Update Magnitude: 0.40121
Value Function Update Magnitude: 0.48481

Collected Steps per Second: 20,925.71572
Overall Steps per Second: 10,001.94829

Timestep Collection Time: 2.39074
Timestep Consumption Time: 2.61108
PPO Batch Consumption Time: 0.30690
Total Iteration Time: 5.00183

Cumulative Model Updates: 110,770
Cumulative Timesteps: 923,660,502

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 923660502...
Checkpoint 923660502 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,442.18511
Policy Entropy: 3.72166
Value Function Loss: 0.02944

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.13814
Policy Update Magnitude: 0.41420
Value Function Update Magnitude: 0.53546

Collected Steps per Second: 20,824.95504
Overall Steps per Second: 10,085.77507

Timestep Collection Time: 2.40154
Timestep Consumption Time: 2.55713
PPO Batch Consumption Time: 0.29484
Total Iteration Time: 4.95867

Cumulative Model Updates: 110,776
Cumulative Timesteps: 923,710,514

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,179.10837
Policy Entropy: 3.72862
Value Function Loss: 0.02529

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.14496
Policy Update Magnitude: 0.42251
Value Function Update Magnitude: 0.52903

Collected Steps per Second: 20,102.23080
Overall Steps per Second: 10,082.89692

Timestep Collection Time: 2.48888
Timestep Consumption Time: 2.47319
PPO Batch Consumption Time: 0.29387
Total Iteration Time: 4.96207

Cumulative Model Updates: 110,782
Cumulative Timesteps: 923,760,546

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 923760546...
Checkpoint 923760546 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,179.10837
Policy Entropy: 3.69690
Value Function Loss: 0.02804

Mean KL Divergence: 0.01057
SB3 Clip Fraction: 0.14613
Policy Update Magnitude: 0.39828
Value Function Update Magnitude: 0.49998

Collected Steps per Second: 20,093.17849
Overall Steps per Second: 10,086.28978

Timestep Collection Time: 2.48950
Timestep Consumption Time: 2.46990
PPO Batch Consumption Time: 0.29495
Total Iteration Time: 4.95941

Cumulative Model Updates: 110,788
Cumulative Timesteps: 923,810,568

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,179.10837
Policy Entropy: 3.69771
Value Function Loss: 0.02488

Mean KL Divergence: 0.01114
SB3 Clip Fraction: 0.15405
Policy Update Magnitude: 0.37772
Value Function Update Magnitude: 0.40599

Collected Steps per Second: 20,344.02063
Overall Steps per Second: 10,113.35583

Timestep Collection Time: 2.45881
Timestep Consumption Time: 2.48733
PPO Batch Consumption Time: 0.29571
Total Iteration Time: 4.94613

Cumulative Model Updates: 110,794
Cumulative Timesteps: 923,860,590

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 923860590...
Checkpoint 923860590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,179.10837
Policy Entropy: 3.70441
Value Function Loss: 0.02498

Mean KL Divergence: 0.01098
SB3 Clip Fraction: 0.14996
Policy Update Magnitude: 0.35433
Value Function Update Magnitude: 0.43882

Collected Steps per Second: 20,622.47524
Overall Steps per Second: 9,913.74770

Timestep Collection Time: 2.42464
Timestep Consumption Time: 2.61907
PPO Batch Consumption Time: 0.31150
Total Iteration Time: 5.04370

Cumulative Model Updates: 110,800
Cumulative Timesteps: 923,910,592

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,179.10837
Policy Entropy: 3.71130
Value Function Loss: 0.02520

Mean KL Divergence: 0.01057
SB3 Clip Fraction: 0.15214
Policy Update Magnitude: 0.33800
Value Function Update Magnitude: 0.41855

Collected Steps per Second: 20,602.50082
Overall Steps per Second: 9,900.15823

Timestep Collection Time: 2.42786
Timestep Consumption Time: 2.62458
PPO Batch Consumption Time: 0.30203
Total Iteration Time: 5.05244

Cumulative Model Updates: 110,806
Cumulative Timesteps: 923,960,612

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 923960612...
Checkpoint 923960612 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84,355.92127
Policy Entropy: 3.72428
Value Function Loss: 0.02500

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.14565
Policy Update Magnitude: 0.34144
Value Function Update Magnitude: 0.42512

Collected Steps per Second: 21,218.55673
Overall Steps per Second: 10,183.90193

Timestep Collection Time: 2.35718
Timestep Consumption Time: 2.55410
PPO Batch Consumption Time: 0.29528
Total Iteration Time: 4.91128

Cumulative Model Updates: 110,812
Cumulative Timesteps: 924,010,628

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 160,828.70973
Policy Entropy: 3.70224
Value Function Loss: 0.02817

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.14301
Policy Update Magnitude: 0.34987
Value Function Update Magnitude: 0.45603

Collected Steps per Second: 20,692.43397
Overall Steps per Second: 10,041.27565

Timestep Collection Time: 2.41683
Timestep Consumption Time: 2.56362
PPO Batch Consumption Time: 0.29510
Total Iteration Time: 4.98044

Cumulative Model Updates: 110,818
Cumulative Timesteps: 924,060,638

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 924060638...
Checkpoint 924060638 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 160,828.70973
Policy Entropy: 3.71582
Value Function Loss: 0.02456

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.14824
Policy Update Magnitude: 0.37277
Value Function Update Magnitude: 0.57349

Collected Steps per Second: 21,007.17196
Overall Steps per Second: 10,026.16337

Timestep Collection Time: 2.38166
Timestep Consumption Time: 2.60848
PPO Batch Consumption Time: 0.30592
Total Iteration Time: 4.99014

Cumulative Model Updates: 110,824
Cumulative Timesteps: 924,110,670

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 160,828.70973
Policy Entropy: 3.70126
Value Function Loss: 0.02577

Mean KL Divergence: 0.01061
SB3 Clip Fraction: 0.14762
Policy Update Magnitude: 0.36758
Value Function Update Magnitude: 0.50967

Collected Steps per Second: 20,951.60514
Overall Steps per Second: 9,946.56407

Timestep Collection Time: 2.38645
Timestep Consumption Time: 2.64041
PPO Batch Consumption Time: 0.30801
Total Iteration Time: 5.02686

Cumulative Model Updates: 110,830
Cumulative Timesteps: 924,160,670

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 924160670...
Checkpoint 924160670 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 160,828.70973
Policy Entropy: 3.70719
Value Function Loss: 0.02128

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.14748
Policy Update Magnitude: 0.35386
Value Function Update Magnitude: 0.43831

Collected Steps per Second: 20,989.64617
Overall Steps per Second: 10,139.40291

Timestep Collection Time: 2.38318
Timestep Consumption Time: 2.55025
PPO Batch Consumption Time: 0.29374
Total Iteration Time: 4.93343

Cumulative Model Updates: 110,836
Cumulative Timesteps: 924,210,692

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 160,828.70973
Policy Entropy: 3.69320
Value Function Loss: 0.02197

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.14050
Policy Update Magnitude: 0.35863
Value Function Update Magnitude: 0.54180

Collected Steps per Second: 20,854.07938
Overall Steps per Second: 10,044.28681

Timestep Collection Time: 2.39905
Timestep Consumption Time: 2.58189
PPO Batch Consumption Time: 0.29622
Total Iteration Time: 4.98094

Cumulative Model Updates: 110,842
Cumulative Timesteps: 924,260,722

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 924260722...
Checkpoint 924260722 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 160,828.70973
Policy Entropy: 3.70027
Value Function Loss: 0.02080

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.14394
Policy Update Magnitude: 0.35130
Value Function Update Magnitude: 0.49949

Collected Steps per Second: 20,048.29503
Overall Steps per Second: 9,888.13249

Timestep Collection Time: 2.49438
Timestep Consumption Time: 2.56300
PPO Batch Consumption Time: 0.30740
Total Iteration Time: 5.05738

Cumulative Model Updates: 110,848
Cumulative Timesteps: 924,310,730

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 142,507.91647
Policy Entropy: 3.70931
Value Function Loss: 0.02396

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.14218
Policy Update Magnitude: 0.33700
Value Function Update Magnitude: 0.37859

Collected Steps per Second: 19,932.51116
Overall Steps per Second: 10,002.37739

Timestep Collection Time: 2.50907
Timestep Consumption Time: 2.49094
PPO Batch Consumption Time: 0.29657
Total Iteration Time: 5.00001

Cumulative Model Updates: 110,854
Cumulative Timesteps: 924,360,742

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 924360742...
Checkpoint 924360742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 93,502.39822
Policy Entropy: 3.70367
Value Function Loss: 0.02485

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.13854
Policy Update Magnitude: 0.35693
Value Function Update Magnitude: 0.35347

Collected Steps per Second: 20,239.75610
Overall Steps per Second: 9,848.88870

Timestep Collection Time: 2.47039
Timestep Consumption Time: 2.60633
PPO Batch Consumption Time: 0.30809
Total Iteration Time: 5.07671

Cumulative Model Updates: 110,860
Cumulative Timesteps: 924,410,742

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93,502.39822
Policy Entropy: 3.71037
Value Function Loss: 0.02063

Mean KL Divergence: 0.01072
SB3 Clip Fraction: 0.14912
Policy Update Magnitude: 0.35471
Value Function Update Magnitude: 0.41136

Collected Steps per Second: 20,466.69632
Overall Steps per Second: 9,984.70037

Timestep Collection Time: 2.44397
Timestep Consumption Time: 2.56569
PPO Batch Consumption Time: 0.29849
Total Iteration Time: 5.00966

Cumulative Model Updates: 110,866
Cumulative Timesteps: 924,460,762

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 924460762...
Checkpoint 924460762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 93,502.39822
Policy Entropy: 3.70605
Value Function Loss: 0.02109

Mean KL Divergence: 0.01067
SB3 Clip Fraction: 0.14778
Policy Update Magnitude: 0.35793
Value Function Update Magnitude: 0.51970

Collected Steps per Second: 20,687.00206
Overall Steps per Second: 10,119.18461

Timestep Collection Time: 2.41746
Timestep Consumption Time: 2.52464
PPO Batch Consumption Time: 0.29505
Total Iteration Time: 4.94210

Cumulative Model Updates: 110,872
Cumulative Timesteps: 924,510,772

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 110,858.68768
Policy Entropy: 3.71914
Value Function Loss: 0.02192

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.14411
Policy Update Magnitude: 0.38711
Value Function Update Magnitude: 0.62596

Collected Steps per Second: 20,827.74880
Overall Steps per Second: 10,097.08216

Timestep Collection Time: 2.40247
Timestep Consumption Time: 2.55322
PPO Batch Consumption Time: 0.29331
Total Iteration Time: 4.95569

Cumulative Model Updates: 110,878
Cumulative Timesteps: 924,560,810

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 924560810...
Checkpoint 924560810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,672.31569
Policy Entropy: 3.71142
Value Function Loss: 0.02331

Mean KL Divergence: 0.01047
SB3 Clip Fraction: 0.14206
Policy Update Magnitude: 0.41136
Value Function Update Magnitude: 0.62320

Collected Steps per Second: 20,601.49357
Overall Steps per Second: 9,903.13192

Timestep Collection Time: 2.42701
Timestep Consumption Time: 2.62190
PPO Batch Consumption Time: 0.30716
Total Iteration Time: 5.04891

Cumulative Model Updates: 110,884
Cumulative Timesteps: 924,610,810

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,672.31569
Policy Entropy: 3.71934
Value Function Loss: 0.02366

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.14433
Policy Update Magnitude: 0.40814
Value Function Update Magnitude: 0.51177

Collected Steps per Second: 20,633.82132
Overall Steps per Second: 10,051.66924

Timestep Collection Time: 2.42418
Timestep Consumption Time: 2.55211
PPO Batch Consumption Time: 0.29313
Total Iteration Time: 4.97629

Cumulative Model Updates: 110,890
Cumulative Timesteps: 924,660,830

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 924660830...
Checkpoint 924660830 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,672.31569
Policy Entropy: 3.70435
Value Function Loss: 0.02252

Mean KL Divergence: 0.01059
SB3 Clip Fraction: 0.14905
Policy Update Magnitude: 0.39289
Value Function Update Magnitude: 0.45928

Collected Steps per Second: 20,901.35812
Overall Steps per Second: 10,102.81509

Timestep Collection Time: 2.39334
Timestep Consumption Time: 2.55815
PPO Batch Consumption Time: 0.29489
Total Iteration Time: 4.95149

Cumulative Model Updates: 110,896
Cumulative Timesteps: 924,710,854

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,672.31569
Policy Entropy: 3.71912
Value Function Loss: 0.01994

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.14551
Policy Update Magnitude: 0.39437
Value Function Update Magnitude: 0.41265

Collected Steps per Second: 20,905.63911
Overall Steps per Second: 10,113.99412

Timestep Collection Time: 2.39285
Timestep Consumption Time: 2.55317
PPO Batch Consumption Time: 0.29361
Total Iteration Time: 4.94602

Cumulative Model Updates: 110,902
Cumulative Timesteps: 924,760,878

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 924760878...
Checkpoint 924760878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,672.31569
Policy Entropy: 3.72264
Value Function Loss: 0.01832

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.13832
Policy Update Magnitude: 0.36649
Value Function Update Magnitude: 0.44049

Collected Steps per Second: 20,708.15687
Overall Steps per Second: 9,947.45410

Timestep Collection Time: 2.41547
Timestep Consumption Time: 2.61295
PPO Batch Consumption Time: 0.30298
Total Iteration Time: 5.02842

Cumulative Model Updates: 110,908
Cumulative Timesteps: 924,810,898

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,672.31569
Policy Entropy: 3.71795
Value Function Loss: 0.01982

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.13999
Policy Update Magnitude: 0.34839
Value Function Update Magnitude: 0.42397

Collected Steps per Second: 20,911.80032
Overall Steps per Second: 10,008.92266

Timestep Collection Time: 2.39166
Timestep Consumption Time: 2.60528
PPO Batch Consumption Time: 0.30417
Total Iteration Time: 4.99694

Cumulative Model Updates: 110,914
Cumulative Timesteps: 924,860,912

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 924860912...
Checkpoint 924860912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,672.31569
Policy Entropy: 3.70930
Value Function Loss: 0.02200

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.14480
Policy Update Magnitude: 0.35702
Value Function Update Magnitude: 0.37236

Collected Steps per Second: 20,675.29315
Overall Steps per Second: 10,005.46602

Timestep Collection Time: 2.41922
Timestep Consumption Time: 2.57985
PPO Batch Consumption Time: 0.29546
Total Iteration Time: 4.99907

Cumulative Model Updates: 110,920
Cumulative Timesteps: 924,910,930

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49,677.25205
Policy Entropy: 3.71791
Value Function Loss: 0.02263

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.14272
Policy Update Magnitude: 0.37845
Value Function Update Magnitude: 0.31520

Collected Steps per Second: 20,939.66079
Overall Steps per Second: 10,116.55811

Timestep Collection Time: 2.38800
Timestep Consumption Time: 2.55478
PPO Batch Consumption Time: 0.29373
Total Iteration Time: 4.94279

Cumulative Model Updates: 110,926
Cumulative Timesteps: 924,960,934

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 924960934...
Checkpoint 924960934 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,677.25205
Policy Entropy: 3.71775
Value Function Loss: 0.02048

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.14190
Policy Update Magnitude: 0.38240
Value Function Update Magnitude: 0.42404

Collected Steps per Second: 20,638.03888
Overall Steps per Second: 9,999.50022

Timestep Collection Time: 2.42368
Timestep Consumption Time: 2.57857
PPO Batch Consumption Time: 0.30103
Total Iteration Time: 5.00225

Cumulative Model Updates: 110,932
Cumulative Timesteps: 925,010,954

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49,677.25205
Policy Entropy: 3.71630
Value Function Loss: 0.02100

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.14495
Policy Update Magnitude: 0.38433
Value Function Update Magnitude: 0.49605

Collected Steps per Second: 20,893.49723
Overall Steps per Second: 10,035.22182

Timestep Collection Time: 2.39318
Timestep Consumption Time: 2.58947
PPO Batch Consumption Time: 0.30118
Total Iteration Time: 4.98265

Cumulative Model Updates: 110,938
Cumulative Timesteps: 925,060,956

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 925060956...
Checkpoint 925060956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 108,845.21368
Policy Entropy: 3.70569
Value Function Loss: 0.02310

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.14211
Policy Update Magnitude: 0.39236
Value Function Update Magnitude: 0.44785

Collected Steps per Second: 19,894.04133
Overall Steps per Second: 10,033.36728

Timestep Collection Time: 2.51492
Timestep Consumption Time: 2.47164
PPO Batch Consumption Time: 0.29243
Total Iteration Time: 4.98656

Cumulative Model Updates: 110,944
Cumulative Timesteps: 925,110,988

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 108,845.21368
Policy Entropy: 3.71299
Value Function Loss: 0.02293

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.13940
Policy Update Magnitude: 0.41693
Value Function Update Magnitude: 0.55090

Collected Steps per Second: 20,275.11880
Overall Steps per Second: 9,883.84263

Timestep Collection Time: 2.46815
Timestep Consumption Time: 2.59486
PPO Batch Consumption Time: 0.31556
Total Iteration Time: 5.06301

Cumulative Model Updates: 110,950
Cumulative Timesteps: 925,161,030

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 925161030...
Checkpoint 925161030 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 108,845.21368
Policy Entropy: 3.71693
Value Function Loss: 0.02446

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.13948
Policy Update Magnitude: 0.43716
Value Function Update Magnitude: 0.54622

Collected Steps per Second: 20,142.78425
Overall Steps per Second: 9,873.58391

Timestep Collection Time: 2.48436
Timestep Consumption Time: 2.58391
PPO Batch Consumption Time: 0.29674
Total Iteration Time: 5.06827

Cumulative Model Updates: 110,956
Cumulative Timesteps: 925,211,072

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 108,845.21368
Policy Entropy: 3.71180
Value Function Loss: 0.02310

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.13629
Policy Update Magnitude: 0.44270
Value Function Update Magnitude: 0.51661

Collected Steps per Second: 21,027.25902
Overall Steps per Second: 10,162.06553

Timestep Collection Time: 2.37920
Timestep Consumption Time: 2.54382
PPO Batch Consumption Time: 0.29409
Total Iteration Time: 4.92301

Cumulative Model Updates: 110,962
Cumulative Timesteps: 925,261,100

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 925261100...
Checkpoint 925261100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 108,845.21368
Policy Entropy: 3.70224
Value Function Loss: 0.02202

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.14248
Policy Update Magnitude: 0.43289
Value Function Update Magnitude: 0.47754

Collected Steps per Second: 20,577.51021
Overall Steps per Second: 10,076.87377

Timestep Collection Time: 2.43149
Timestep Consumption Time: 2.53374
PPO Batch Consumption Time: 0.29483
Total Iteration Time: 4.96523

Cumulative Model Updates: 110,968
Cumulative Timesteps: 925,311,134

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 108,845.21368
Policy Entropy: 3.70624
Value Function Loss: 0.02137

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.14490
Policy Update Magnitude: 0.40785
Value Function Update Magnitude: 0.38461

Collected Steps per Second: 20,993.81467
Overall Steps per Second: 10,085.51701

Timestep Collection Time: 2.38270
Timestep Consumption Time: 2.57708
PPO Batch Consumption Time: 0.29541
Total Iteration Time: 4.95979

Cumulative Model Updates: 110,974
Cumulative Timesteps: 925,361,156

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 925361156...
Checkpoint 925361156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 108,845.21368
Policy Entropy: 3.69842
Value Function Loss: 0.02479

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.14310
Policy Update Magnitude: 0.40200
Value Function Update Magnitude: 0.36808

Collected Steps per Second: 20,744.39563
Overall Steps per Second: 9,976.97056

Timestep Collection Time: 2.41154
Timestep Consumption Time: 2.60260
PPO Batch Consumption Time: 0.30440
Total Iteration Time: 5.01415

Cumulative Model Updates: 110,980
Cumulative Timesteps: 925,411,182

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 108,845.21368
Policy Entropy: 3.69241
Value Function Loss: 0.02532

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.13885
Policy Update Magnitude: 0.45480
Value Function Update Magnitude: 0.45190

Collected Steps per Second: 20,774.73311
Overall Steps per Second: 9,906.89881

Timestep Collection Time: 2.40706
Timestep Consumption Time: 2.64054
PPO Batch Consumption Time: 0.30919
Total Iteration Time: 5.04759

Cumulative Model Updates: 110,986
Cumulative Timesteps: 925,461,188

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 925461188...
Checkpoint 925461188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 182,318.93922
Policy Entropy: 3.69324
Value Function Loss: 0.02769

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.13239
Policy Update Magnitude: 0.47796
Value Function Update Magnitude: 0.46433

Collected Steps per Second: 20,683.15719
Overall Steps per Second: 10,008.47029

Timestep Collection Time: 2.41762
Timestep Consumption Time: 2.57855
PPO Batch Consumption Time: 0.30074
Total Iteration Time: 4.99617

Cumulative Model Updates: 110,992
Cumulative Timesteps: 925,511,192

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 182,318.93922
Policy Entropy: 3.69456
Value Function Loss: 0.02618

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.13572
Policy Update Magnitude: 0.50438
Value Function Update Magnitude: 0.51265

Collected Steps per Second: 20,694.49329
Overall Steps per Second: 9,949.48028

Timestep Collection Time: 2.41658
Timestep Consumption Time: 2.60981
PPO Batch Consumption Time: 0.30504
Total Iteration Time: 5.02639

Cumulative Model Updates: 110,998
Cumulative Timesteps: 925,561,202

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 925561202...
Checkpoint 925561202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 351,344.33847
Policy Entropy: 3.70246
Value Function Loss: 0.02834

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.13139
Policy Update Magnitude: 0.50981
Value Function Update Magnitude: 0.43714

Collected Steps per Second: 20,458.25309
Overall Steps per Second: 9,990.53874

Timestep Collection Time: 2.44410
Timestep Consumption Time: 2.56084
PPO Batch Consumption Time: 0.29464
Total Iteration Time: 5.00494

Cumulative Model Updates: 111,004
Cumulative Timesteps: 925,611,204

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 351,344.33847
Policy Entropy: 3.70476
Value Function Loss: 0.02686

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.13811
Policy Update Magnitude: 0.51110
Value Function Update Magnitude: 0.45683

Collected Steps per Second: 20,619.09205
Overall Steps per Second: 10,026.38143

Timestep Collection Time: 2.42639
Timestep Consumption Time: 2.56344
PPO Batch Consumption Time: 0.29463
Total Iteration Time: 4.98984

Cumulative Model Updates: 111,010
Cumulative Timesteps: 925,661,234

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 925661234...
Checkpoint 925661234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 351,344.33847
Policy Entropy: 3.69885
Value Function Loss: 0.03025

Mean KL Divergence: 0.01066
SB3 Clip Fraction: 0.14090
Policy Update Magnitude: 0.47350
Value Function Update Magnitude: 0.37515

Collected Steps per Second: 21,078.81102
Overall Steps per Second: 10,006.41371

Timestep Collection Time: 2.37205
Timestep Consumption Time: 2.62474
PPO Batch Consumption Time: 0.30742
Total Iteration Time: 4.99680

Cumulative Model Updates: 111,016
Cumulative Timesteps: 925,711,234

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 351,344.33847
Policy Entropy: 3.69750
Value Function Loss: 0.02428

Mean KL Divergence: 0.01086
SB3 Clip Fraction: 0.15142
Policy Update Magnitude: 0.42724
Value Function Update Magnitude: 0.33197

Collected Steps per Second: 19,888.92844
Overall Steps per Second: 9,764.43563

Timestep Collection Time: 2.51537
Timestep Consumption Time: 2.60812
PPO Batch Consumption Time: 0.30272
Total Iteration Time: 5.12349

Cumulative Model Updates: 111,022
Cumulative Timesteps: 925,761,262

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 925761262...
Checkpoint 925761262 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 351,344.33847
Policy Entropy: 3.69180
Value Function Loss: 0.02223

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.13832
Policy Update Magnitude: 0.39263
Value Function Update Magnitude: 0.30152

Collected Steps per Second: 20,615.30939
Overall Steps per Second: 10,019.15907

Timestep Collection Time: 2.42548
Timestep Consumption Time: 2.56516
PPO Batch Consumption Time: 0.29851
Total Iteration Time: 4.99064

Cumulative Model Updates: 111,028
Cumulative Timesteps: 925,811,264

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 475,896.38082
Policy Entropy: 3.69226
Value Function Loss: 0.02312

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.14095
Policy Update Magnitude: 0.38525
Value Function Update Magnitude: 0.37818

Collected Steps per Second: 20,150.07703
Overall Steps per Second: 10,107.66843

Timestep Collection Time: 2.48247
Timestep Consumption Time: 2.46644
PPO Batch Consumption Time: 0.29243
Total Iteration Time: 4.94892

Cumulative Model Updates: 111,034
Cumulative Timesteps: 925,861,286

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 925861286...
Checkpoint 925861286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 475,896.38082
Policy Entropy: 3.69325
Value Function Loss: 0.02659

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.13864
Policy Update Magnitude: 0.42362
Value Function Update Magnitude: 0.36985

Collected Steps per Second: 20,017.76867
Overall Steps per Second: 10,073.51552

Timestep Collection Time: 2.49878
Timestep Consumption Time: 2.46672
PPO Batch Consumption Time: 0.29449
Total Iteration Time: 4.96550

Cumulative Model Updates: 111,040
Cumulative Timesteps: 925,911,306

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 346,994.99689
Policy Entropy: 3.70060
Value Function Loss: 0.02711

Mean KL Divergence: 0.01083
SB3 Clip Fraction: 0.14237
Policy Update Magnitude: 0.47463
Value Function Update Magnitude: 0.38011

Collected Steps per Second: 20,044.25438
Overall Steps per Second: 9,825.72108

Timestep Collection Time: 2.49648
Timestep Consumption Time: 2.59628
PPO Batch Consumption Time: 0.30562
Total Iteration Time: 5.09276

Cumulative Model Updates: 111,046
Cumulative Timesteps: 925,961,346

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 925961346...
Checkpoint 925961346 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 346,994.99689
Policy Entropy: 3.70853
Value Function Loss: 0.02589

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.13684
Policy Update Magnitude: 0.49828
Value Function Update Magnitude: 0.35887

Collected Steps per Second: 20,682.03763
Overall Steps per Second: 10,071.75750

Timestep Collection Time: 2.41901
Timestep Consumption Time: 2.54835
PPO Batch Consumption Time: 0.29458
Total Iteration Time: 4.96736

Cumulative Model Updates: 111,052
Cumulative Timesteps: 926,011,376

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 346,994.99689
Policy Entropy: 3.70775
Value Function Loss: 0.02176

Mean KL Divergence: 0.01097
SB3 Clip Fraction: 0.14717
Policy Update Magnitude: 0.46468
Value Function Update Magnitude: 0.42244

Collected Steps per Second: 21,170.35008
Overall Steps per Second: 10,094.62092

Timestep Collection Time: 2.36255
Timestep Consumption Time: 2.59217
PPO Batch Consumption Time: 0.30140
Total Iteration Time: 4.95472

Cumulative Model Updates: 111,058
Cumulative Timesteps: 926,061,392

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 926061392...
Checkpoint 926061392 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 556,628.48519
Policy Entropy: 3.70973
Value Function Loss: 0.02155

Mean KL Divergence: 0.01110
SB3 Clip Fraction: 0.15066
Policy Update Magnitude: 0.43973
Value Function Update Magnitude: 0.43956

Collected Steps per Second: 20,897.77227
Overall Steps per Second: 10,106.58572

Timestep Collection Time: 2.39442
Timestep Consumption Time: 2.55661
PPO Batch Consumption Time: 0.29479
Total Iteration Time: 4.95103

Cumulative Model Updates: 111,064
Cumulative Timesteps: 926,111,430

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 556,628.48519
Policy Entropy: 3.70717
Value Function Loss: 0.02256

Mean KL Divergence: 0.01080
SB3 Clip Fraction: 0.14467
Policy Update Magnitude: 0.45105
Value Function Update Magnitude: 0.42047

Collected Steps per Second: 20,872.87208
Overall Steps per Second: 10,090.10378

Timestep Collection Time: 2.39670
Timestep Consumption Time: 2.56123
PPO Batch Consumption Time: 0.29413
Total Iteration Time: 4.95793

Cumulative Model Updates: 111,070
Cumulative Timesteps: 926,161,456

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 926161456...
Checkpoint 926161456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 556,628.48519
Policy Entropy: 3.70306
Value Function Loss: 0.02640

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.14217
Policy Update Magnitude: 0.47889
Value Function Update Magnitude: 0.43630

Collected Steps per Second: 21,138.17426
Overall Steps per Second: 10,169.24149

Timestep Collection Time: 2.36558
Timestep Consumption Time: 2.55160
PPO Batch Consumption Time: 0.29474
Total Iteration Time: 4.91718

Cumulative Model Updates: 111,076
Cumulative Timesteps: 926,211,460

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 556,628.48519
Policy Entropy: 3.69972
Value Function Loss: 0.02213

Mean KL Divergence: 0.01105
SB3 Clip Fraction: 0.14910
Policy Update Magnitude: 0.43977
Value Function Update Magnitude: 0.50713

Collected Steps per Second: 21,036.07107
Overall Steps per Second: 10,156.80914

Timestep Collection Time: 2.37839
Timestep Consumption Time: 2.54757
PPO Batch Consumption Time: 0.29250
Total Iteration Time: 4.92596

Cumulative Model Updates: 111,082
Cumulative Timesteps: 926,261,492

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 926261492...
Checkpoint 926261492 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 556,628.48519
Policy Entropy: 3.69054
Value Function Loss: 0.02399

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.14309
Policy Update Magnitude: 0.42542
Value Function Update Magnitude: 0.53109

Collected Steps per Second: 20,894.92927
Overall Steps per Second: 10,115.61363

Timestep Collection Time: 2.39312
Timestep Consumption Time: 2.55013
PPO Batch Consumption Time: 0.29411
Total Iteration Time: 4.94325

Cumulative Model Updates: 111,088
Cumulative Timesteps: 926,311,496

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 271,270.37781
Policy Entropy: 3.69544
Value Function Loss: 0.02470

Mean KL Divergence: 0.01074
SB3 Clip Fraction: 0.14201
Policy Update Magnitude: 0.46012
Value Function Update Magnitude: 0.59277

Collected Steps per Second: 20,813.73064
Overall Steps per Second: 10,034.30145

Timestep Collection Time: 2.40284
Timestep Consumption Time: 2.58127
PPO Batch Consumption Time: 0.29638
Total Iteration Time: 4.98410

Cumulative Model Updates: 111,094
Cumulative Timesteps: 926,361,508

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 926361508...
Checkpoint 926361508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 271,270.37781
Policy Entropy: 3.69803
Value Function Loss: 0.02466

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.14088
Policy Update Magnitude: 0.50782
Value Function Update Magnitude: 0.69091

Collected Steps per Second: 20,911.36235
Overall Steps per Second: 9,891.83896

Timestep Collection Time: 2.39219
Timestep Consumption Time: 2.66491
PPO Batch Consumption Time: 0.31400
Total Iteration Time: 5.05710

Cumulative Model Updates: 111,100
Cumulative Timesteps: 926,411,532

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 271,270.37781
Policy Entropy: 3.70088
Value Function Loss: 0.02320

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.13728
Policy Update Magnitude: 0.47704
Value Function Update Magnitude: 0.65579

Collected Steps per Second: 20,726.67770
Overall Steps per Second: 10,010.66693

Timestep Collection Time: 2.41322
Timestep Consumption Time: 2.58325
PPO Batch Consumption Time: 0.29442
Total Iteration Time: 4.99647

Cumulative Model Updates: 111,106
Cumulative Timesteps: 926,461,550

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 926461550...
Checkpoint 926461550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 271,270.37781
Policy Entropy: 3.69056
Value Function Loss: 0.02209

Mean KL Divergence: 0.01071
SB3 Clip Fraction: 0.14772
Policy Update Magnitude: 0.42957
Value Function Update Magnitude: 0.59950

Collected Steps per Second: 20,922.80079
Overall Steps per Second: 10,131.92519

Timestep Collection Time: 2.39174
Timestep Consumption Time: 2.54730
PPO Batch Consumption Time: 0.29463
Total Iteration Time: 4.93904

Cumulative Model Updates: 111,112
Cumulative Timesteps: 926,511,592

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 271,270.37781
Policy Entropy: 3.69965
Value Function Loss: 0.02170

Mean KL Divergence: 0.01090
SB3 Clip Fraction: 0.14854
Policy Update Magnitude: 0.40731
Value Function Update Magnitude: 0.55558

Collected Steps per Second: 20,240.47094
Overall Steps per Second: 10,087.84360

Timestep Collection Time: 2.47069
Timestep Consumption Time: 2.48656
PPO Batch Consumption Time: 0.29576
Total Iteration Time: 4.95725

Cumulative Model Updates: 111,118
Cumulative Timesteps: 926,561,600

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 926561600...
Checkpoint 926561600 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 271,270.37781
Policy Entropy: 3.70109
Value Function Loss: 0.02096

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.14134
Policy Update Magnitude: 0.38569
Value Function Update Magnitude: 0.55634

Collected Steps per Second: 20,290.35561
Overall Steps per Second: 10,119.46853

Timestep Collection Time: 2.46462
Timestep Consumption Time: 2.47714
PPO Batch Consumption Time: 0.29513
Total Iteration Time: 4.94176

Cumulative Model Updates: 111,124
Cumulative Timesteps: 926,611,608

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 271,270.37781
Policy Entropy: 3.71349
Value Function Loss: 0.01967

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.13828
Policy Update Magnitude: 0.38918
Value Function Update Magnitude: 0.46962

Collected Steps per Second: 20,387.63831
Overall Steps per Second: 10,039.98041

Timestep Collection Time: 2.45256
Timestep Consumption Time: 2.52772
PPO Batch Consumption Time: 0.29483
Total Iteration Time: 4.98029

Cumulative Model Updates: 111,130
Cumulative Timesteps: 926,661,610

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 926661610...
Checkpoint 926661610 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 271,270.37781
Policy Entropy: 3.70187
Value Function Loss: 0.01901

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.13841
Policy Update Magnitude: 0.39544
Value Function Update Magnitude: 0.44121

Collected Steps per Second: 20,635.05095
Overall Steps per Second: 9,992.22753

Timestep Collection Time: 2.42384
Timestep Consumption Time: 2.58165
PPO Batch Consumption Time: 0.30658
Total Iteration Time: 5.00549

Cumulative Model Updates: 111,136
Cumulative Timesteps: 926,711,626

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 271,270.37781
Policy Entropy: 3.71918
Value Function Loss: 0.01715

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.14224
Policy Update Magnitude: 0.37988
Value Function Update Magnitude: 0.45072

Collected Steps per Second: 20,831.50726
Overall Steps per Second: 9,971.19519

Timestep Collection Time: 2.40155
Timestep Consumption Time: 2.61570
PPO Batch Consumption Time: 0.30667
Total Iteration Time: 5.01725

Cumulative Model Updates: 111,142
Cumulative Timesteps: 926,761,654

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 926761654...
Checkpoint 926761654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 271,270.37781
Policy Entropy: 3.69925
Value Function Loss: 0.02008

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.14351
Policy Update Magnitude: 0.36576
Value Function Update Magnitude: 0.46873

Collected Steps per Second: 20,856.27726
Overall Steps per Second: 10,079.99271

Timestep Collection Time: 2.39851
Timestep Consumption Time: 2.56419
PPO Batch Consumption Time: 0.29661
Total Iteration Time: 4.96270

Cumulative Model Updates: 111,148
Cumulative Timesteps: 926,811,678

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 271,270.37781
Policy Entropy: 3.70188
Value Function Loss: 0.02083

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.14018
Policy Update Magnitude: 0.43064
Value Function Update Magnitude: 0.53853

Collected Steps per Second: 21,021.77280
Overall Steps per Second: 10,096.81351

Timestep Collection Time: 2.37953
Timestep Consumption Time: 2.57470
PPO Batch Consumption Time: 0.29488
Total Iteration Time: 4.95424

Cumulative Model Updates: 111,154
Cumulative Timesteps: 926,861,700

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 926861700...
Checkpoint 926861700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 271,270.37781
Policy Entropy: 3.69105
Value Function Loss: 0.02339

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.13662
Policy Update Magnitude: 0.44289
Value Function Update Magnitude: 0.52244

Collected Steps per Second: 20,868.79793
Overall Steps per Second: 9,980.66832

Timestep Collection Time: 2.39717
Timestep Consumption Time: 2.61512
PPO Batch Consumption Time: 0.30720
Total Iteration Time: 5.01229

Cumulative Model Updates: 111,160
Cumulative Timesteps: 926,911,726

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 271,270.37781
Policy Entropy: 3.71757
Value Function Loss: 0.02191

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.13785
Policy Update Magnitude: 0.44662
Value Function Update Magnitude: 0.50702

Collected Steps per Second: 20,520.44667
Overall Steps per Second: 9,938.01752

Timestep Collection Time: 2.43776
Timestep Consumption Time: 2.59584
PPO Batch Consumption Time: 0.30073
Total Iteration Time: 5.03360

Cumulative Model Updates: 111,166
Cumulative Timesteps: 926,961,750

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 926961750...
Checkpoint 926961750 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 271,270.37781
Policy Entropy: 3.69715
Value Function Loss: 0.02264

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.13745
Policy Update Magnitude: 0.46728
Value Function Update Magnitude: 0.46841

Collected Steps per Second: 20,690.83422
Overall Steps per Second: 9,998.23399

Timestep Collection Time: 2.41692
Timestep Consumption Time: 2.58477
PPO Batch Consumption Time: 0.30111
Total Iteration Time: 5.00168

Cumulative Model Updates: 111,172
Cumulative Timesteps: 927,011,758

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 271,270.37781
Policy Entropy: 3.70919
Value Function Loss: 0.02290

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.13774
Policy Update Magnitude: 0.47178
Value Function Update Magnitude: 0.46978

Collected Steps per Second: 20,673.93831
Overall Steps per Second: 9,934.93014

Timestep Collection Time: 2.41928
Timestep Consumption Time: 2.61508
PPO Batch Consumption Time: 0.30648
Total Iteration Time: 5.03436

Cumulative Model Updates: 111,178
Cumulative Timesteps: 927,061,774

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 927061774...
Checkpoint 927061774 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 271,270.37781
Policy Entropy: 3.69035
Value Function Loss: 0.02194

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.13743
Policy Update Magnitude: 0.45628
Value Function Update Magnitude: 0.40046

Collected Steps per Second: 20,518.39911
Overall Steps per Second: 10,028.12804

Timestep Collection Time: 2.43752
Timestep Consumption Time: 2.54985
PPO Batch Consumption Time: 0.29472
Total Iteration Time: 4.98737

Cumulative Model Updates: 111,184
Cumulative Timesteps: 927,111,788

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 271,270.37781
Policy Entropy: 3.71211
Value Function Loss: 0.01895

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.14401
Policy Update Magnitude: 0.42006
Value Function Update Magnitude: 0.31820

Collected Steps per Second: 20,602.12578
Overall Steps per Second: 10,115.49368

Timestep Collection Time: 2.42703
Timestep Consumption Time: 2.51608
PPO Batch Consumption Time: 0.30178
Total Iteration Time: 4.94311

Cumulative Model Updates: 111,190
Cumulative Timesteps: 927,161,790

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 927161790...
Checkpoint 927161790 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 271,270.37781
Policy Entropy: 3.70643
Value Function Loss: 0.01972

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.14450
Policy Update Magnitude: 0.38455
Value Function Update Magnitude: 0.29351

Collected Steps per Second: 20,191.57119
Overall Steps per Second: 10,090.40135

Timestep Collection Time: 2.47648
Timestep Consumption Time: 2.47912
PPO Batch Consumption Time: 0.29569
Total Iteration Time: 4.95560

Cumulative Model Updates: 111,196
Cumulative Timesteps: 927,211,794

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 271,270.37781
Policy Entropy: 3.72423
Value Function Loss: 0.02002

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.14534
Policy Update Magnitude: 0.39433
Value Function Update Magnitude: 0.33012

Collected Steps per Second: 20,476.79409
Overall Steps per Second: 10,059.95297

Timestep Collection Time: 2.44345
Timestep Consumption Time: 2.53013
PPO Batch Consumption Time: 0.29437
Total Iteration Time: 4.97358

Cumulative Model Updates: 111,202
Cumulative Timesteps: 927,261,828

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 927261828...
Checkpoint 927261828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 549,180.42607
Policy Entropy: 3.71174
Value Function Loss: 0.02091

Mean KL Divergence: 0.01069
SB3 Clip Fraction: 0.14740
Policy Update Magnitude: 0.39471
Value Function Update Magnitude: 0.39805

Collected Steps per Second: 20,395.21051
Overall Steps per Second: 9,916.80449

Timestep Collection Time: 2.45303
Timestep Consumption Time: 2.59195
PPO Batch Consumption Time: 0.30518
Total Iteration Time: 5.04497

Cumulative Model Updates: 111,208
Cumulative Timesteps: 927,311,858

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 549,180.42607
Policy Entropy: 3.72014
Value Function Loss: 0.02079

Mean KL Divergence: 0.01122
SB3 Clip Fraction: 0.14945
Policy Update Magnitude: 0.37241
Value Function Update Magnitude: 0.37653

Collected Steps per Second: 20,398.55475
Overall Steps per Second: 9,988.82487

Timestep Collection Time: 2.45233
Timestep Consumption Time: 2.55567
PPO Batch Consumption Time: 0.29405
Total Iteration Time: 5.00800

Cumulative Model Updates: 111,214
Cumulative Timesteps: 927,361,882

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 927361882...
Checkpoint 927361882 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 452,560.02421
Policy Entropy: 3.72224
Value Function Loss: 0.02010

Mean KL Divergence: 0.01146
SB3 Clip Fraction: 0.15500
Policy Update Magnitude: 0.38762
Value Function Update Magnitude: 0.42595

Collected Steps per Second: 20,848.96342
Overall Steps per Second: 9,989.76161

Timestep Collection Time: 2.39935
Timestep Consumption Time: 2.60817
PPO Batch Consumption Time: 0.30232
Total Iteration Time: 5.00753

Cumulative Model Updates: 111,220
Cumulative Timesteps: 927,411,906

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 366,574.30775
Policy Entropy: 3.70695
Value Function Loss: 0.02274

Mean KL Divergence: 0.01077
SB3 Clip Fraction: 0.14619
Policy Update Magnitude: 0.40462
Value Function Update Magnitude: 0.55822

Collected Steps per Second: 19,711.72479
Overall Steps per Second: 9,787.77342

Timestep Collection Time: 2.53788
Timestep Consumption Time: 2.57319
PPO Batch Consumption Time: 0.29507
Total Iteration Time: 5.11107

Cumulative Model Updates: 111,226
Cumulative Timesteps: 927,461,932

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 927461932...
Checkpoint 927461932 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 366,574.30775
Policy Entropy: 3.70832
Value Function Loss: 0.02304

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.13967
Policy Update Magnitude: 0.42908
Value Function Update Magnitude: 0.50863

Collected Steps per Second: 20,915.70324
Overall Steps per Second: 9,988.90920

Timestep Collection Time: 2.39074
Timestep Consumption Time: 2.61521
PPO Batch Consumption Time: 0.30706
Total Iteration Time: 5.00595

Cumulative Model Updates: 111,232
Cumulative Timesteps: 927,511,936

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 366,574.30775
Policy Entropy: 3.70206
Value Function Loss: 0.02238

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.14081
Policy Update Magnitude: 0.41792
Value Function Update Magnitude: 0.50879

Collected Steps per Second: 20,807.07759
Overall Steps per Second: 9,963.14561

Timestep Collection Time: 2.40312
Timestep Consumption Time: 2.61557
PPO Batch Consumption Time: 0.30251
Total Iteration Time: 5.01870

Cumulative Model Updates: 111,238
Cumulative Timesteps: 927,561,938

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 927561938...
Checkpoint 927561938 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 366,574.30775
Policy Entropy: 3.71236
Value Function Loss: 0.02008

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.13805
Policy Update Magnitude: 0.40745
Value Function Update Magnitude: 0.41282

Collected Steps per Second: 20,826.96033
Overall Steps per Second: 10,099.42973

Timestep Collection Time: 2.40141
Timestep Consumption Time: 2.55075
PPO Batch Consumption Time: 0.29464
Total Iteration Time: 4.95216

Cumulative Model Updates: 111,244
Cumulative Timesteps: 927,611,952

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 366,574.30775
Policy Entropy: 3.70776
Value Function Loss: 0.02044

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.13951
Policy Update Magnitude: 0.41171
Value Function Update Magnitude: 0.47479

Collected Steps per Second: 20,797.59873
Overall Steps per Second: 9,910.56351

Timestep Collection Time: 2.40412
Timestep Consumption Time: 2.64100
PPO Batch Consumption Time: 0.30831
Total Iteration Time: 5.04512

Cumulative Model Updates: 111,250
Cumulative Timesteps: 927,661,952

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 927661952...
Checkpoint 927661952 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 630,978.28651
Policy Entropy: 3.70093
Value Function Loss: 0.02355

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.13571
Policy Update Magnitude: 0.44967
Value Function Update Magnitude: 0.40653

Collected Steps per Second: 20,562.39955
Overall Steps per Second: 10,035.13682

Timestep Collection Time: 2.43279
Timestep Consumption Time: 2.55209
PPO Batch Consumption Time: 0.29200
Total Iteration Time: 4.98488

Cumulative Model Updates: 111,256
Cumulative Timesteps: 927,711,976

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 630,978.28651
Policy Entropy: 3.70379
Value Function Loss: 0.02390

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.13193
Policy Update Magnitude: 0.46365
Value Function Update Magnitude: 0.39118

Collected Steps per Second: 20,671.20607
Overall Steps per Second: 10,051.43597

Timestep Collection Time: 2.41892
Timestep Consumption Time: 2.55569
PPO Batch Consumption Time: 0.29381
Total Iteration Time: 4.97461

Cumulative Model Updates: 111,262
Cumulative Timesteps: 927,761,978

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 927761978...
Checkpoint 927761978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 630,978.28651
Policy Entropy: 3.68550
Value Function Loss: 0.02431

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.13761
Policy Update Magnitude: 0.45773
Value Function Update Magnitude: 0.39268

Collected Steps per Second: 20,781.29507
Overall Steps per Second: 10,070.73765

Timestep Collection Time: 2.40620
Timestep Consumption Time: 2.55907
PPO Batch Consumption Time: 0.29676
Total Iteration Time: 4.96528

Cumulative Model Updates: 111,268
Cumulative Timesteps: 927,811,982

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 630,978.28651
Policy Entropy: 3.69070
Value Function Loss: 0.02447

Mean KL Divergence: 0.01047
SB3 Clip Fraction: 0.14039
Policy Update Magnitude: 0.46248
Value Function Update Magnitude: 0.36124

Collected Steps per Second: 20,362.50620
Overall Steps per Second: 10,138.21652

Timestep Collection Time: 2.45589
Timestep Consumption Time: 2.47674
PPO Batch Consumption Time: 0.29366
Total Iteration Time: 4.93262

Cumulative Model Updates: 111,274
Cumulative Timesteps: 927,861,990

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 927861990...
Checkpoint 927861990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 912,446.49769
Policy Entropy: 3.68217
Value Function Loss: 0.03295

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.13176
Policy Update Magnitude: 0.50544
Value Function Update Magnitude: 0.35959

Collected Steps per Second: 20,226.59694
Overall Steps per Second: 10,135.16266

Timestep Collection Time: 2.47249
Timestep Consumption Time: 2.46182
PPO Batch Consumption Time: 0.29424
Total Iteration Time: 4.93431

Cumulative Model Updates: 111,280
Cumulative Timesteps: 927,912,000

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208,747.39960
Policy Entropy: 3.69663
Value Function Loss: 0.03138

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.13315
Policy Update Magnitude: 0.60017
Value Function Update Magnitude: 0.45425

Collected Steps per Second: 20,187.46437
Overall Steps per Second: 9,834.29090

Timestep Collection Time: 2.47698
Timestep Consumption Time: 2.60767
PPO Batch Consumption Time: 0.30490
Total Iteration Time: 5.08466

Cumulative Model Updates: 111,286
Cumulative Timesteps: 927,962,004

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 927962004...
Checkpoint 927962004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 169,081.56358
Policy Entropy: 3.69910
Value Function Loss: 0.03259

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.13183
Policy Update Magnitude: 0.60459
Value Function Update Magnitude: 0.57361

Collected Steps per Second: 20,814.27075
Overall Steps per Second: 10,150.51270

Timestep Collection Time: 2.40316
Timestep Consumption Time: 2.52467
PPO Batch Consumption Time: 0.29272
Total Iteration Time: 4.92783

Cumulative Model Updates: 111,292
Cumulative Timesteps: 928,012,024

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 169,081.56358
Policy Entropy: 3.71632
Value Function Loss: 0.02746

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.13880
Policy Update Magnitude: 0.56453
Value Function Update Magnitude: 0.50770

Collected Steps per Second: 20,488.88779
Overall Steps per Second: 10,010.32416

Timestep Collection Time: 2.44103
Timestep Consumption Time: 2.55521
PPO Batch Consumption Time: 0.29681
Total Iteration Time: 4.99624

Cumulative Model Updates: 111,298
Cumulative Timesteps: 928,062,038

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 928062038...
Checkpoint 928062038 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 169,081.56358
Policy Entropy: 3.71208
Value Function Loss: 0.02645

Mean KL Divergence: 0.01077
SB3 Clip Fraction: 0.13647
Policy Update Magnitude: 0.50830
Value Function Update Magnitude: 0.49212

Collected Steps per Second: 20,885.29896
Overall Steps per Second: 10,117.96919

Timestep Collection Time: 2.39441
Timestep Consumption Time: 2.54808
PPO Batch Consumption Time: 0.29411
Total Iteration Time: 4.94249

Cumulative Model Updates: 111,304
Cumulative Timesteps: 928,112,046

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 169,081.56358
Policy Entropy: 3.72068
Value Function Loss: 0.02199

Mean KL Divergence: 0.01088
SB3 Clip Fraction: 0.14660
Policy Update Magnitude: 0.46073
Value Function Update Magnitude: 0.44314

Collected Steps per Second: 21,009.05090
Overall Steps per Second: 10,132.12284

Timestep Collection Time: 2.38135
Timestep Consumption Time: 2.55641
PPO Batch Consumption Time: 0.29356
Total Iteration Time: 4.93776

Cumulative Model Updates: 111,310
Cumulative Timesteps: 928,162,076

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 928162076...
Checkpoint 928162076 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 169,081.56358
Policy Entropy: 3.71205
Value Function Loss: 0.02001

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.14237
Policy Update Magnitude: 0.40980
Value Function Update Magnitude: 0.39661

Collected Steps per Second: 20,887.29297
Overall Steps per Second: 10,090.96244

Timestep Collection Time: 2.39581
Timestep Consumption Time: 2.56328
PPO Batch Consumption Time: 0.29456
Total Iteration Time: 4.95909

Cumulative Model Updates: 111,316
Cumulative Timesteps: 928,212,118

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 169,081.56358
Policy Entropy: 3.70484
Value Function Loss: 0.01920

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.14428
Policy Update Magnitude: 0.37569
Value Function Update Magnitude: 0.28942

Collected Steps per Second: 20,917.45637
Overall Steps per Second: 10,064.85288

Timestep Collection Time: 2.39035
Timestep Consumption Time: 2.57743
PPO Batch Consumption Time: 0.29397
Total Iteration Time: 4.96778

Cumulative Model Updates: 111,322
Cumulative Timesteps: 928,262,118

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 928262118...
Checkpoint 928262118 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 169,081.56358
Policy Entropy: 3.69851
Value Function Loss: 0.01888

Mean KL Divergence: 0.01096
SB3 Clip Fraction: 0.15006
Policy Update Magnitude: 0.34364
Value Function Update Magnitude: 0.26290

Collected Steps per Second: 20,664.14979
Overall Steps per Second: 9,868.44819

Timestep Collection Time: 2.41975
Timestep Consumption Time: 2.64711
PPO Batch Consumption Time: 0.31250
Total Iteration Time: 5.06686

Cumulative Model Updates: 111,328
Cumulative Timesteps: 928,312,120

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 471,744.55295
Policy Entropy: 3.69308
Value Function Loss: 0.02226

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.14067
Policy Update Magnitude: 0.33614
Value Function Update Magnitude: 0.25926

Collected Steps per Second: 20,927.59393
Overall Steps per Second: 10,073.49235

Timestep Collection Time: 2.39034
Timestep Consumption Time: 2.57557
PPO Batch Consumption Time: 0.29666
Total Iteration Time: 4.96590

Cumulative Model Updates: 111,334
Cumulative Timesteps: 928,362,144

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 928362144...
Checkpoint 928362144 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 250,708.57843
Policy Entropy: 3.70590
Value Function Loss: 0.02207

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.13480
Policy Update Magnitude: 0.37066
Value Function Update Magnitude: 0.32011

Collected Steps per Second: 20,966.31658
Overall Steps per Second: 10,087.62350

Timestep Collection Time: 2.38583
Timestep Consumption Time: 2.57292
PPO Batch Consumption Time: 0.29502
Total Iteration Time: 4.95875

Cumulative Model Updates: 111,340
Cumulative Timesteps: 928,412,166

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 529,133.62020
Policy Entropy: 3.70119
Value Function Loss: 0.02417

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.13197
Policy Update Magnitude: 0.41116
Value Function Update Magnitude: 0.40340

Collected Steps per Second: 20,882.81523
Overall Steps per Second: 10,096.21482

Timestep Collection Time: 2.39498
Timestep Consumption Time: 2.55875
PPO Batch Consumption Time: 0.29329
Total Iteration Time: 4.95374

Cumulative Model Updates: 111,346
Cumulative Timesteps: 928,462,180

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 928462180...
Checkpoint 928462180 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 182,607.06217
Policy Entropy: 3.72936
Value Function Loss: 0.02379

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.13249
Policy Update Magnitude: 0.44683
Value Function Update Magnitude: 0.47716

Collected Steps per Second: 21,076.70936
Overall Steps per Second: 10,152.94664

Timestep Collection Time: 2.37371
Timestep Consumption Time: 2.55392
PPO Batch Consumption Time: 0.29473
Total Iteration Time: 4.92763

Cumulative Model Updates: 111,352
Cumulative Timesteps: 928,512,210

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57,418.49083
Policy Entropy: 3.73999
Value Function Loss: 0.02482

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.14337
Policy Update Magnitude: 0.45137
Value Function Update Magnitude: 0.62419

Collected Steps per Second: 20,974.88764
Overall Steps per Second: 10,060.09885

Timestep Collection Time: 2.38399
Timestep Consumption Time: 2.58653
PPO Batch Consumption Time: 0.29350
Total Iteration Time: 4.97053

Cumulative Model Updates: 111,358
Cumulative Timesteps: 928,562,214

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 928562214...
Checkpoint 928562214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46,508.30329
Policy Entropy: 3.74371
Value Function Loss: 0.02171

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.13419
Policy Update Magnitude: 0.43732
Value Function Update Magnitude: 0.69399

Collected Steps per Second: 21,018.99938
Overall Steps per Second: 10,056.69051

Timestep Collection Time: 2.38099
Timestep Consumption Time: 2.59540
PPO Batch Consumption Time: 0.30332
Total Iteration Time: 4.97639

Cumulative Model Updates: 111,364
Cumulative Timesteps: 928,612,260

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46,508.30329
Policy Entropy: 3.72717
Value Function Loss: 0.02087

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.13798
Policy Update Magnitude: 0.40761
Value Function Update Magnitude: 0.71572

Collected Steps per Second: 20,789.88256
Overall Steps per Second: 9,988.29993

Timestep Collection Time: 2.40646
Timestep Consumption Time: 2.60240
PPO Batch Consumption Time: 0.30470
Total Iteration Time: 5.00886

Cumulative Model Updates: 111,370
Cumulative Timesteps: 928,662,290

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 928662290...
Checkpoint 928662290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46,508.30329
Policy Entropy: 3.71210
Value Function Loss: 0.02224

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.13980
Policy Update Magnitude: 0.40153
Value Function Update Magnitude: 0.65159

Collected Steps per Second: 20,082.27251
Overall Steps per Second: 10,068.58572

Timestep Collection Time: 2.49046
Timestep Consumption Time: 2.47688
PPO Batch Consumption Time: 0.29476
Total Iteration Time: 4.96733

Cumulative Model Updates: 111,376
Cumulative Timesteps: 928,712,304

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 250,862.31248
Policy Entropy: 3.71339
Value Function Loss: 0.02216

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.14657
Policy Update Magnitude: 0.40555
Value Function Update Magnitude: 0.65180

Collected Steps per Second: 20,188.24827
Overall Steps per Second: 10,068.44190

Timestep Collection Time: 2.47847
Timestep Consumption Time: 2.49112
PPO Batch Consumption Time: 0.29525
Total Iteration Time: 4.96959

Cumulative Model Updates: 111,382
Cumulative Timesteps: 928,762,340

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 928762340...
Checkpoint 928762340 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 250,862.31248
Policy Entropy: 3.71862
Value Function Loss: 0.01994

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.14076
Policy Update Magnitude: 0.40146
Value Function Update Magnitude: 0.62256

Collected Steps per Second: 20,290.09325
Overall Steps per Second: 10,142.58291

Timestep Collection Time: 2.46554
Timestep Consumption Time: 2.46674
PPO Batch Consumption Time: 0.29379
Total Iteration Time: 4.93227

Cumulative Model Updates: 111,388
Cumulative Timesteps: 928,812,366

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 250,862.31248
Policy Entropy: 3.72000
Value Function Loss: 0.01894

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.14104
Policy Update Magnitude: 0.36540
Value Function Update Magnitude: 0.50866

Collected Steps per Second: 20,483.22303
Overall Steps per Second: 10,051.92106

Timestep Collection Time: 2.44151
Timestep Consumption Time: 2.53366
PPO Batch Consumption Time: 0.29423
Total Iteration Time: 4.97517

Cumulative Model Updates: 111,394
Cumulative Timesteps: 928,862,376

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 928862376...
Checkpoint 928862376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 250,862.31248
Policy Entropy: 3.72401
Value Function Loss: 0.01900

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.14013
Policy Update Magnitude: 0.34310
Value Function Update Magnitude: 0.50401

Collected Steps per Second: 20,973.90299
Overall Steps per Second: 10,030.38046

Timestep Collection Time: 2.38525
Timestep Consumption Time: 2.60240
PPO Batch Consumption Time: 0.30779
Total Iteration Time: 4.98765

Cumulative Model Updates: 111,400
Cumulative Timesteps: 928,912,404

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 250,862.31248
Policy Entropy: 3.71935
Value Function Loss: 0.02015

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.14049
Policy Update Magnitude: 0.36118
Value Function Update Magnitude: 0.40879

Collected Steps per Second: 20,936.00989
Overall Steps per Second: 9,966.93860

Timestep Collection Time: 2.38833
Timestep Consumption Time: 2.62846
PPO Batch Consumption Time: 0.30422
Total Iteration Time: 5.01679

Cumulative Model Updates: 111,406
Cumulative Timesteps: 928,962,406

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 928962406...
Checkpoint 928962406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 250,862.31248
Policy Entropy: 3.72587
Value Function Loss: 0.01977

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.13702
Policy Update Magnitude: 0.35894
Value Function Update Magnitude: 0.31637

Collected Steps per Second: 20,449.16368
Overall Steps per Second: 10,016.57427

Timestep Collection Time: 2.44597
Timestep Consumption Time: 2.54756
PPO Batch Consumption Time: 0.29428
Total Iteration Time: 4.99352

Cumulative Model Updates: 111,412
Cumulative Timesteps: 929,012,424

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 250,862.31248
Policy Entropy: 3.72103
Value Function Loss: 0.01794

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.13880
Policy Update Magnitude: 0.34220
Value Function Update Magnitude: 0.29375

Collected Steps per Second: 20,789.42453
Overall Steps per Second: 10,059.79621

Timestep Collection Time: 2.40584
Timestep Consumption Time: 2.56603
PPO Batch Consumption Time: 0.29386
Total Iteration Time: 4.97187

Cumulative Model Updates: 111,418
Cumulative Timesteps: 929,062,440

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 929062440...
Checkpoint 929062440 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 250,862.31248
Policy Entropy: 3.71767
Value Function Loss: 0.01841

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.14069
Policy Update Magnitude: 0.33262
Value Function Update Magnitude: 0.43224

Collected Steps per Second: 21,106.64909
Overall Steps per Second: 10,185.33622

Timestep Collection Time: 2.36968
Timestep Consumption Time: 2.54091
PPO Batch Consumption Time: 0.29394
Total Iteration Time: 4.91059

Cumulative Model Updates: 111,424
Cumulative Timesteps: 929,112,456

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 250,862.31248
Policy Entropy: 3.73366
Value Function Loss: 0.01984

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.13679
Policy Update Magnitude: 0.36461
Value Function Update Magnitude: 0.47383

Collected Steps per Second: 21,043.92421
Overall Steps per Second: 10,098.71402

Timestep Collection Time: 2.37693
Timestep Consumption Time: 2.57617
PPO Batch Consumption Time: 0.29472
Total Iteration Time: 4.95311

Cumulative Model Updates: 111,430
Cumulative Timesteps: 929,162,476

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 929162476...
Checkpoint 929162476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 250,862.31248
Policy Entropy: 3.71877
Value Function Loss: 0.01948

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.13774
Policy Update Magnitude: 0.39950
Value Function Update Magnitude: 0.50874

Collected Steps per Second: 20,897.85677
Overall Steps per Second: 9,837.92845

Timestep Collection Time: 2.39393
Timestep Consumption Time: 2.69129
PPO Batch Consumption Time: 0.30401
Total Iteration Time: 5.08522

Cumulative Model Updates: 111,436
Cumulative Timesteps: 929,212,504

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 250,862.31248
Policy Entropy: 3.73484
Value Function Loss: 0.01785

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.13761
Policy Update Magnitude: 0.40042
Value Function Update Magnitude: 0.42294

Collected Steps per Second: 19,175.54805
Overall Steps per Second: 9,630.87654

Timestep Collection Time: 2.60822
Timestep Consumption Time: 2.58487
PPO Batch Consumption Time: 0.30391
Total Iteration Time: 5.19309

Cumulative Model Updates: 111,442
Cumulative Timesteps: 929,262,518

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 929262518...
Checkpoint 929262518 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 250,862.31248
Policy Entropy: 3.70775
Value Function Loss: 0.01730

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.13047
Policy Update Magnitude: 0.37096
Value Function Update Magnitude: 0.36206

Collected Steps per Second: 19,995.28888
Overall Steps per Second: 9,964.99319

Timestep Collection Time: 2.50089
Timestep Consumption Time: 2.51728
PPO Batch Consumption Time: 0.30401
Total Iteration Time: 5.01817

Cumulative Model Updates: 111,448
Cumulative Timesteps: 929,312,524

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 250,862.31248
Policy Entropy: 3.70796
Value Function Loss: 0.01815

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.13407
Policy Update Magnitude: 0.34704
Value Function Update Magnitude: 0.37819

Collected Steps per Second: 20,131.10368
Overall Steps per Second: 9,908.75158

Timestep Collection Time: 2.48501
Timestep Consumption Time: 2.56366
PPO Batch Consumption Time: 0.29808
Total Iteration Time: 5.04867

Cumulative Model Updates: 111,454
Cumulative Timesteps: 929,362,550

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 929362550...
Checkpoint 929362550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 179,204.16363
Policy Entropy: 3.70662
Value Function Loss: 0.01954

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.13225
Policy Update Magnitude: 0.36435
Value Function Update Magnitude: 0.47872

Collected Steps per Second: 20,588.55634
Overall Steps per Second: 10,080.15479

Timestep Collection Time: 2.42863
Timestep Consumption Time: 2.53181
PPO Batch Consumption Time: 0.29546
Total Iteration Time: 4.96044

Cumulative Model Updates: 111,460
Cumulative Timesteps: 929,412,552

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 145,155.46952
Policy Entropy: 3.71901
Value Function Loss: 0.02096

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.14026
Policy Update Magnitude: 0.39981
Value Function Update Magnitude: 0.48674

Collected Steps per Second: 21,204.33283
Overall Steps per Second: 10,162.73112

Timestep Collection Time: 2.35829
Timestep Consumption Time: 2.56224
PPO Batch Consumption Time: 0.29885
Total Iteration Time: 4.92053

Cumulative Model Updates: 111,466
Cumulative Timesteps: 929,462,558

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 929462558...
Checkpoint 929462558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 145,155.46952
Policy Entropy: 3.73397
Value Function Loss: 0.02124

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.11249
Policy Update Magnitude: 0.45719
Value Function Update Magnitude: 0.40302

Collected Steps per Second: 21,012.39042
Overall Steps per Second: 10,136.82031

Timestep Collection Time: 2.37955
Timestep Consumption Time: 2.55296
PPO Batch Consumption Time: 0.29430
Total Iteration Time: 4.93251

Cumulative Model Updates: 111,472
Cumulative Timesteps: 929,512,558

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 145,155.46952
Policy Entropy: 3.73527
Value Function Loss: 0.01835

Mean KL Divergence: 0.00650
SB3 Clip Fraction: 0.08320
Policy Update Magnitude: 0.51678
Value Function Update Magnitude: 0.34653

Collected Steps per Second: 21,048.79216
Overall Steps per Second: 10,042.19711

Timestep Collection Time: 2.37591
Timestep Consumption Time: 2.60408
PPO Batch Consumption Time: 0.30253
Total Iteration Time: 4.97999

Cumulative Model Updates: 111,478
Cumulative Timesteps: 929,562,568

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 929562568...
Checkpoint 929562568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 145,155.46952
Policy Entropy: 3.75892
Value Function Loss: 0.01485

Mean KL Divergence: 0.00431
SB3 Clip Fraction: 0.04434
Policy Update Magnitude: 0.48085
Value Function Update Magnitude: 0.30699

Collected Steps per Second: 20,533.51664
Overall Steps per Second: 9,871.05934

Timestep Collection Time: 2.43524
Timestep Consumption Time: 2.63048
PPO Batch Consumption Time: 0.30531
Total Iteration Time: 5.06572

Cumulative Model Updates: 111,484
Cumulative Timesteps: 929,612,572

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 145,155.46952
Policy Entropy: 3.76193
Value Function Loss: 0.01419

Mean KL Divergence: 0.00487
SB3 Clip Fraction: 0.05533
Policy Update Magnitude: 0.45292
Value Function Update Magnitude: 0.25322

Collected Steps per Second: 20,565.73836
Overall Steps per Second: 10,018.35650

Timestep Collection Time: 2.43133
Timestep Consumption Time: 2.55971
PPO Batch Consumption Time: 0.29446
Total Iteration Time: 4.99104

Cumulative Model Updates: 111,490
Cumulative Timesteps: 929,662,574

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 929662574...
Checkpoint 929662574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 145,155.46952
Policy Entropy: 3.74999
Value Function Loss: 0.01337

Mean KL Divergence: 0.00584
SB3 Clip Fraction: 0.07212
Policy Update Magnitude: 0.44052
Value Function Update Magnitude: 0.30656

Collected Steps per Second: 20,825.64092
Overall Steps per Second: 10,029.05470

Timestep Collection Time: 2.40117
Timestep Consumption Time: 2.58494
PPO Batch Consumption Time: 0.30138
Total Iteration Time: 4.98611

Cumulative Model Updates: 111,496
Cumulative Timesteps: 929,712,580

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 145,155.46952
Policy Entropy: 3.73438
Value Function Loss: 0.01243

Mean KL Divergence: 0.00480
SB3 Clip Fraction: 0.05377
Policy Update Magnitude: 0.44995
Value Function Update Magnitude: 0.40520

Collected Steps per Second: 21,128.06877
Overall Steps per Second: 10,127.95080

Timestep Collection Time: 2.36803
Timestep Consumption Time: 2.57196
PPO Batch Consumption Time: 0.29513
Total Iteration Time: 4.93999

Cumulative Model Updates: 111,502
Cumulative Timesteps: 929,762,612

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 929762612...
Checkpoint 929762612 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 145,155.46952
Policy Entropy: 3.73104
Value Function Loss: 0.01238

Mean KL Divergence: 0.00579
SB3 Clip Fraction: 0.06820
Policy Update Magnitude: 0.46582
Value Function Update Magnitude: 0.46323

Collected Steps per Second: 20,314.85508
Overall Steps per Second: 9,934.65300

Timestep Collection Time: 2.46243
Timestep Consumption Time: 2.57287
PPO Batch Consumption Time: 0.29790
Total Iteration Time: 5.03530

Cumulative Model Updates: 111,508
Cumulative Timesteps: 929,812,636

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 145,155.46952
Policy Entropy: 3.73950
Value Function Loss: 0.01291

Mean KL Divergence: 0.00539
SB3 Clip Fraction: 0.06331
Policy Update Magnitude: 0.50781
Value Function Update Magnitude: 0.50817

Collected Steps per Second: 20,336.84118
Overall Steps per Second: 10,025.48332

Timestep Collection Time: 2.46007
Timestep Consumption Time: 2.53022
PPO Batch Consumption Time: 0.30474
Total Iteration Time: 4.99028

Cumulative Model Updates: 111,514
Cumulative Timesteps: 929,862,666

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 929862666...
Checkpoint 929862666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 145,155.46952
Policy Entropy: 3.73109
Value Function Loss: 0.01451

Mean KL Divergence: 0.00593
SB3 Clip Fraction: 0.07080
Policy Update Magnitude: 0.54526
Value Function Update Magnitude: 0.51623

Collected Steps per Second: 19,977.23220
Overall Steps per Second: 9,992.86720

Timestep Collection Time: 2.50415
Timestep Consumption Time: 2.50202
PPO Batch Consumption Time: 0.30171
Total Iteration Time: 5.00617

Cumulative Model Updates: 111,520
Cumulative Timesteps: 929,912,692

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 145,155.46952
Policy Entropy: 3.74338
Value Function Loss: 0.01657

Mean KL Divergence: 0.00531
SB3 Clip Fraction: 0.06061
Policy Update Magnitude: 0.59751
Value Function Update Magnitude: 0.62753

Collected Steps per Second: 20,420.01462
Overall Steps per Second: 9,917.93399

Timestep Collection Time: 2.44887
Timestep Consumption Time: 2.59311
PPO Batch Consumption Time: 0.30558
Total Iteration Time: 5.04198

Cumulative Model Updates: 111,526
Cumulative Timesteps: 929,962,698

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 929962698...
Checkpoint 929962698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 292,438.57512
Policy Entropy: 3.75157
Value Function Loss: 0.01783

Mean KL Divergence: 0.00638
SB3 Clip Fraction: 0.07871
Policy Update Magnitude: 0.62240
Value Function Update Magnitude: 0.66025

Collected Steps per Second: 20,809.30501
Overall Steps per Second: 10,153.19006

Timestep Collection Time: 2.40402
Timestep Consumption Time: 2.52310
PPO Batch Consumption Time: 0.29299
Total Iteration Time: 4.92712

Cumulative Model Updates: 111,532
Cumulative Timesteps: 930,012,724

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,148,868.82112
Policy Entropy: 3.74980
Value Function Loss: 0.02391

Mean KL Divergence: 0.01338
SB3 Clip Fraction: 0.16672
Policy Update Magnitude: 0.58588
Value Function Update Magnitude: 0.73783

Collected Steps per Second: 20,655.57256
Overall Steps per Second: 10,036.56657

Timestep Collection Time: 2.42075
Timestep Consumption Time: 2.56123
PPO Batch Consumption Time: 0.30045
Total Iteration Time: 4.98198

Cumulative Model Updates: 111,538
Cumulative Timesteps: 930,062,726

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 930062726...
Checkpoint 930062726 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 139,704.68285
Policy Entropy: 3.75445
Value Function Loss: 0.02706

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.11399
Policy Update Magnitude: 0.66675
Value Function Update Magnitude: 0.78078

Collected Steps per Second: 20,724.87230
Overall Steps per Second: 10,079.48013

Timestep Collection Time: 2.41256
Timestep Consumption Time: 2.54801
PPO Batch Consumption Time: 0.29584
Total Iteration Time: 4.96057

Cumulative Model Updates: 111,544
Cumulative Timesteps: 930,112,726

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 139,704.68285
Policy Entropy: 3.73906
Value Function Loss: 0.02918

Mean KL Divergence: 0.01225
SB3 Clip Fraction: 0.15702
Policy Update Magnitude: 0.71867
Value Function Update Magnitude: 0.74628

Collected Steps per Second: 20,853.81595
Overall Steps per Second: 9,893.45159

Timestep Collection Time: 2.39899
Timestep Consumption Time: 2.65769
PPO Batch Consumption Time: 0.30866
Total Iteration Time: 5.05668

Cumulative Model Updates: 111,550
Cumulative Timesteps: 930,162,754

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 930162754...
Checkpoint 930162754 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 633,001.99102
Policy Entropy: 3.75285
Value Function Loss: 0.02627

Mean KL Divergence: 0.01142
SB3 Clip Fraction: 0.14792
Policy Update Magnitude: 0.70901
Value Function Update Magnitude: 0.62100

Collected Steps per Second: 20,549.03656
Overall Steps per Second: 10,016.58968

Timestep Collection Time: 2.43320
Timestep Consumption Time: 2.55851
PPO Batch Consumption Time: 0.29459
Total Iteration Time: 4.99172

Cumulative Model Updates: 111,556
Cumulative Timesteps: 930,212,754

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 512,729.60254
Policy Entropy: 3.73228
Value Function Loss: 0.02732

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.11297
Policy Update Magnitude: 0.73353
Value Function Update Magnitude: 0.64626

Collected Steps per Second: 20,867.16422
Overall Steps per Second: 10,120.65366

Timestep Collection Time: 2.39697
Timestep Consumption Time: 2.54520
PPO Batch Consumption Time: 0.29352
Total Iteration Time: 4.94217

Cumulative Model Updates: 111,562
Cumulative Timesteps: 930,262,772

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 930262772...
Checkpoint 930262772 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 348,765.18966
Policy Entropy: 3.71187
Value Function Loss: 0.02890

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.11296
Policy Update Magnitude: 0.81465
Value Function Update Magnitude: 0.63880

Collected Steps per Second: 20,915.33550
Overall Steps per Second: 10,102.65900

Timestep Collection Time: 2.39145
Timestep Consumption Time: 2.55952
PPO Batch Consumption Time: 0.29465
Total Iteration Time: 4.95097

Cumulative Model Updates: 111,568
Cumulative Timesteps: 930,312,790

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 399,191.17235
Policy Entropy: 3.72853
Value Function Loss: 0.02645

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.11576
Policy Update Magnitude: 0.77228
Value Function Update Magnitude: 0.62214

Collected Steps per Second: 20,847.95117
Overall Steps per Second: 10,081.83504

Timestep Collection Time: 2.39918
Timestep Consumption Time: 2.56202
PPO Batch Consumption Time: 0.29535
Total Iteration Time: 4.96120

Cumulative Model Updates: 111,574
Cumulative Timesteps: 930,362,808

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 930362808...
Checkpoint 930362808 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 261,918.80395
Policy Entropy: 3.74520
Value Function Loss: 0.02288

Mean KL Divergence: 0.00706
SB3 Clip Fraction: 0.08807
Policy Update Magnitude: 0.72587
Value Function Update Magnitude: 0.74727

Collected Steps per Second: 20,118.22848
Overall Steps per Second: 9,995.57056

Timestep Collection Time: 2.48620
Timestep Consumption Time: 2.51781
PPO Batch Consumption Time: 0.30324
Total Iteration Time: 5.00402

Cumulative Model Updates: 111,580
Cumulative Timesteps: 930,412,826

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 261,918.80395
Policy Entropy: 3.74125
Value Function Loss: 0.02209

Mean KL Divergence: 0.01146
SB3 Clip Fraction: 0.15400
Policy Update Magnitude: 0.58751
Value Function Update Magnitude: 0.63795

Collected Steps per Second: 20,050.33188
Overall Steps per Second: 9,906.23519

Timestep Collection Time: 2.49452
Timestep Consumption Time: 2.55442
PPO Batch Consumption Time: 0.30798
Total Iteration Time: 5.04894

Cumulative Model Updates: 111,586
Cumulative Timesteps: 930,462,842

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 930462842...
Checkpoint 930462842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 234,058.49462
Policy Entropy: 3.72294
Value Function Loss: 0.02271

Mean KL Divergence: 0.01247
SB3 Clip Fraction: 0.16850
Policy Update Magnitude: 0.46108
Value Function Update Magnitude: 0.50941

Collected Steps per Second: 19,996.38370
Overall Steps per Second: 10,005.03492

Timestep Collection Time: 2.50145
Timestep Consumption Time: 2.49803
PPO Batch Consumption Time: 0.30116
Total Iteration Time: 4.99948

Cumulative Model Updates: 111,592
Cumulative Timesteps: 930,512,862

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81,625.05241
Policy Entropy: 3.72978
Value Function Loss: 0.02608

Mean KL Divergence: 0.01539
SB3 Clip Fraction: 0.19321
Policy Update Magnitude: 0.47224
Value Function Update Magnitude: 0.53947

Collected Steps per Second: 20,094.56127
Overall Steps per Second: 9,825.33433

Timestep Collection Time: 2.48903
Timestep Consumption Time: 2.60148
PPO Batch Consumption Time: 0.30399
Total Iteration Time: 5.09051

Cumulative Model Updates: 111,598
Cumulative Timesteps: 930,562,878

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 930562878...
Checkpoint 930562878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43,405.77012
Policy Entropy: 3.72412
Value Function Loss: 0.02791

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.13384
Policy Update Magnitude: 0.66033
Value Function Update Magnitude: 0.67932

Collected Steps per Second: 20,969.73449
Overall Steps per Second: 10,184.10383

Timestep Collection Time: 2.38477
Timestep Consumption Time: 2.52563
PPO Batch Consumption Time: 0.29454
Total Iteration Time: 4.91040

Cumulative Model Updates: 111,604
Cumulative Timesteps: 930,612,886

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,405.77012
Policy Entropy: 3.74600
Value Function Loss: 0.02572

Mean KL Divergence: 0.01350
SB3 Clip Fraction: 0.17682
Policy Update Magnitude: 0.68128
Value Function Update Magnitude: 0.57365

Collected Steps per Second: 20,875.73665
Overall Steps per Second: 10,075.26373

Timestep Collection Time: 2.39589
Timestep Consumption Time: 2.56835
PPO Batch Consumption Time: 0.29338
Total Iteration Time: 4.96424

Cumulative Model Updates: 111,610
Cumulative Timesteps: 930,662,902

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 930662902...
Checkpoint 930662902 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43,405.77012
Policy Entropy: 3.79231
Value Function Loss: 0.02482

Mean KL Divergence: 0.01855
SB3 Clip Fraction: 0.21666
Policy Update Magnitude: 0.60674
Value Function Update Magnitude: 0.66893

Collected Steps per Second: 20,732.55526
Overall Steps per Second: 9,996.13905

Timestep Collection Time: 2.41302
Timestep Consumption Time: 2.59172
PPO Batch Consumption Time: 0.30149
Total Iteration Time: 5.00473

Cumulative Model Updates: 111,616
Cumulative Timesteps: 930,712,930

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 567,350.11614
Policy Entropy: 3.79962
Value Function Loss: 0.02583

Mean KL Divergence: 0.01174
SB3 Clip Fraction: 0.14411
Policy Update Magnitude: 0.68873
Value Function Update Magnitude: 0.77293

Collected Steps per Second: 20,386.32639
Overall Steps per Second: 9,833.42400

Timestep Collection Time: 2.45410
Timestep Consumption Time: 2.63365
PPO Batch Consumption Time: 0.30590
Total Iteration Time: 5.08775

Cumulative Model Updates: 111,622
Cumulative Timesteps: 930,762,960

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 930762960...
Checkpoint 930762960 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 567,350.11614
Policy Entropy: 3.76022
Value Function Loss: 0.02689

Mean KL Divergence: 0.01654
SB3 Clip Fraction: 0.18563
Policy Update Magnitude: 0.85763
Value Function Update Magnitude: 0.82313

Collected Steps per Second: 20,584.27072
Overall Steps per Second: 9,870.39518

Timestep Collection Time: 2.43050
Timestep Consumption Time: 2.63820
PPO Batch Consumption Time: 0.31198
Total Iteration Time: 5.06869

Cumulative Model Updates: 111,628
Cumulative Timesteps: 930,812,990

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 567,350.11614
Policy Entropy: 3.71453
Value Function Loss: 0.02573

Mean KL Divergence: 0.01157
SB3 Clip Fraction: 0.14255
Policy Update Magnitude: 0.85759
Value Function Update Magnitude: 0.74086

Collected Steps per Second: 20,773.17836
Overall Steps per Second: 9,996.50842

Timestep Collection Time: 2.40791
Timestep Consumption Time: 2.59583
PPO Batch Consumption Time: 0.29969
Total Iteration Time: 5.00375

Cumulative Model Updates: 111,634
Cumulative Timesteps: 930,863,010

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 930863010...
Checkpoint 930863010 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 567,350.11614
Policy Entropy: 3.68110
Value Function Loss: 0.02984

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.10475
Policy Update Magnitude: 0.78211
Value Function Update Magnitude: 0.61513

Collected Steps per Second: 20,662.33060
Overall Steps per Second: 10,006.21182

Timestep Collection Time: 2.42073
Timestep Consumption Time: 2.57796
PPO Batch Consumption Time: 0.30098
Total Iteration Time: 4.99869

Cumulative Model Updates: 111,640
Cumulative Timesteps: 930,913,028

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 334,243.86873
Policy Entropy: 3.71637
Value Function Loss: 0.02814

Mean KL Divergence: 0.01333
SB3 Clip Fraction: 0.17663
Policy Update Magnitude: 0.61661
Value Function Update Magnitude: 0.40615

Collected Steps per Second: 20,202.61608
Overall Steps per Second: 10,001.79872

Timestep Collection Time: 2.47493
Timestep Consumption Time: 2.52417
PPO Batch Consumption Time: 0.30071
Total Iteration Time: 4.99910

Cumulative Model Updates: 111,646
Cumulative Timesteps: 930,963,028

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 930963028...
Checkpoint 930963028 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 219,309.73290
Policy Entropy: 3.73791
Value Function Loss: 0.02615

Mean KL Divergence: 0.01109
SB3 Clip Fraction: 0.15305
Policy Update Magnitude: 0.45235
Value Function Update Magnitude: 0.36540

Collected Steps per Second: 19,760.29135
Overall Steps per Second: 9,981.07036

Timestep Collection Time: 2.53215
Timestep Consumption Time: 2.48094
PPO Batch Consumption Time: 0.29219
Total Iteration Time: 5.01309

Cumulative Model Updates: 111,652
Cumulative Timesteps: 931,013,064

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 219,309.73290
Policy Entropy: 3.73538
Value Function Loss: 0.02376

Mean KL Divergence: 0.01123
SB3 Clip Fraction: 0.15350
Policy Update Magnitude: 0.40519
Value Function Update Magnitude: 0.43047

Collected Steps per Second: 20,515.38422
Overall Steps per Second: 10,041.16585

Timestep Collection Time: 2.43798
Timestep Consumption Time: 2.54312
PPO Batch Consumption Time: 0.29457
Total Iteration Time: 4.98109

Cumulative Model Updates: 111,658
Cumulative Timesteps: 931,063,080

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 931063080...
Checkpoint 931063080 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 219,309.73290
Policy Entropy: 3.68941
Value Function Loss: 0.02722

Mean KL Divergence: 0.01329
SB3 Clip Fraction: 0.17356
Policy Update Magnitude: 0.44473
Value Function Update Magnitude: 0.45906

Collected Steps per Second: 20,986.86515
Overall Steps per Second: 10,190.92532

Timestep Collection Time: 2.38349
Timestep Consumption Time: 2.52499
PPO Batch Consumption Time: 0.29442
Total Iteration Time: 4.90848

Cumulative Model Updates: 111,664
Cumulative Timesteps: 931,113,102

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 219,309.73290
Policy Entropy: 3.69253
Value Function Loss: 0.02864

Mean KL Divergence: 0.01194
SB3 Clip Fraction: 0.15859
Policy Update Magnitude: 0.54405
Value Function Update Magnitude: 0.44102

Collected Steps per Second: 20,832.30395
Overall Steps per Second: 10,139.79592

Timestep Collection Time: 2.40031
Timestep Consumption Time: 2.53115
PPO Batch Consumption Time: 0.29341
Total Iteration Time: 4.93146

Cumulative Model Updates: 111,670
Cumulative Timesteps: 931,163,106

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 931163106...
Checkpoint 931163106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 219,309.73290
Policy Entropy: 3.70429
Value Function Loss: 0.02589

Mean KL Divergence: 0.01376
SB3 Clip Fraction: 0.17766
Policy Update Magnitude: 0.52089
Value Function Update Magnitude: 0.43319

Collected Steps per Second: 21,005.01452
Overall Steps per Second: 10,099.99614

Timestep Collection Time: 2.38115
Timestep Consumption Time: 2.57094
PPO Batch Consumption Time: 0.29494
Total Iteration Time: 4.95208

Cumulative Model Updates: 111,676
Cumulative Timesteps: 931,213,122

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 219,309.73290
Policy Entropy: 3.71435
Value Function Loss: 0.02139

Mean KL Divergence: 0.01330
SB3 Clip Fraction: 0.17395
Policy Update Magnitude: 0.45792
Value Function Update Magnitude: 0.49936

Collected Steps per Second: 21,031.37408
Overall Steps per Second: 10,146.05569

Timestep Collection Time: 2.37826
Timestep Consumption Time: 2.55154
PPO Batch Consumption Time: 0.29279
Total Iteration Time: 4.92980

Cumulative Model Updates: 111,682
Cumulative Timesteps: 931,263,140

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 931263140...
Checkpoint 931263140 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 219,309.73290
Policy Entropy: 3.70534
Value Function Loss: 0.01717

Mean KL Divergence: 0.01462
SB3 Clip Fraction: 0.19119
Policy Update Magnitude: 0.38798
Value Function Update Magnitude: 0.55407

Collected Steps per Second: 20,739.61537
Overall Steps per Second: 10,091.52524

Timestep Collection Time: 2.41171
Timestep Consumption Time: 2.54472
PPO Batch Consumption Time: 0.29387
Total Iteration Time: 4.95644

Cumulative Model Updates: 111,688
Cumulative Timesteps: 931,313,158

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 219,309.73290
Policy Entropy: 3.67730
Value Function Loss: 0.01893

Mean KL Divergence: 0.01351
SB3 Clip Fraction: 0.17311
Policy Update Magnitude: 0.36497
Value Function Update Magnitude: 0.45788

Collected Steps per Second: 20,766.30221
Overall Steps per Second: 10,067.75719

Timestep Collection Time: 2.40861
Timestep Consumption Time: 2.55952
PPO Batch Consumption Time: 0.29399
Total Iteration Time: 4.96814

Cumulative Model Updates: 111,694
Cumulative Timesteps: 931,363,176

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 931363176...
Checkpoint 931363176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 219,309.73290
Policy Entropy: 3.68121
Value Function Loss: 0.02063

Mean KL Divergence: 0.01112
SB3 Clip Fraction: 0.14384
Policy Update Magnitude: 0.44656
Value Function Update Magnitude: 0.41585

Collected Steps per Second: 21,018.08851
Overall Steps per Second: 10,037.01704

Timestep Collection Time: 2.37976
Timestep Consumption Time: 2.60359
PPO Batch Consumption Time: 0.30284
Total Iteration Time: 4.98335

Cumulative Model Updates: 111,700
Cumulative Timesteps: 931,413,194

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 219,309.73290
Policy Entropy: 3.69269
Value Function Loss: 0.02237

Mean KL Divergence: 0.01137
SB3 Clip Fraction: 0.15376
Policy Update Magnitude: 0.48708
Value Function Update Magnitude: 0.43082

Collected Steps per Second: 20,931.64085
Overall Steps per Second: 10,016.73995

Timestep Collection Time: 2.39016
Timestep Consumption Time: 2.60448
PPO Batch Consumption Time: 0.30403
Total Iteration Time: 4.99464

Cumulative Model Updates: 111,706
Cumulative Timesteps: 931,463,224

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 931463224...
Checkpoint 931463224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 684,862.09771
Policy Entropy: 3.71016
Value Function Loss: 0.02292

Mean KL Divergence: 0.01193
SB3 Clip Fraction: 0.15920
Policy Update Magnitude: 0.45949
Value Function Update Magnitude: 0.45447

Collected Steps per Second: 20,808.94828
Overall Steps per Second: 10,089.90105

Timestep Collection Time: 2.40397
Timestep Consumption Time: 2.55386
PPO Batch Consumption Time: 0.29564
Total Iteration Time: 4.95783

Cumulative Model Updates: 111,712
Cumulative Timesteps: 931,513,248

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 684,862.09771
Policy Entropy: 3.70085
Value Function Loss: 0.02072

Mean KL Divergence: 0.01156
SB3 Clip Fraction: 0.15442
Policy Update Magnitude: 0.43988
Value Function Update Magnitude: 0.44479

Collected Steps per Second: 20,851.40790
Overall Steps per Second: 10,045.22621

Timestep Collection Time: 2.39897
Timestep Consumption Time: 2.58070
PPO Batch Consumption Time: 0.30037
Total Iteration Time: 4.97968

Cumulative Model Updates: 111,718
Cumulative Timesteps: 931,563,270

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 931563270...
Checkpoint 931563270 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 684,862.09771
Policy Entropy: 3.69526
Value Function Loss: 0.01944

Mean KL Divergence: 0.01059
SB3 Clip Fraction: 0.14424
Policy Update Magnitude: 0.42490
Value Function Update Magnitude: 0.39190

Collected Steps per Second: 20,362.29480
Overall Steps per Second: 9,796.00924

Timestep Collection Time: 2.45640
Timestep Consumption Time: 2.64955
PPO Batch Consumption Time: 0.31095
Total Iteration Time: 5.10596

Cumulative Model Updates: 111,724
Cumulative Timesteps: 931,613,288

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 684,862.09771
Policy Entropy: 3.69703
Value Function Loss: 0.01951

Mean KL Divergence: 0.01059
SB3 Clip Fraction: 0.14408
Policy Update Magnitude: 0.38595
Value Function Update Magnitude: 0.30989

Collected Steps per Second: 20,270.09486
Overall Steps per Second: 10,062.76026

Timestep Collection Time: 2.46915
Timestep Consumption Time: 2.50463
PPO Batch Consumption Time: 0.29947
Total Iteration Time: 4.97378

Cumulative Model Updates: 111,730
Cumulative Timesteps: 931,663,338

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 931663338...
Checkpoint 931663338 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 750,382.77425
Policy Entropy: 3.69100
Value Function Loss: 0.02257

Mean KL Divergence: 0.01195
SB3 Clip Fraction: 0.15966
Policy Update Magnitude: 0.37857
Value Function Update Magnitude: 0.35484

Collected Steps per Second: 19,897.58814
Overall Steps per Second: 9,975.97518

Timestep Collection Time: 2.51307
Timestep Consumption Time: 2.49937
PPO Batch Consumption Time: 0.30119
Total Iteration Time: 5.01244

Cumulative Model Updates: 111,736
Cumulative Timesteps: 931,713,342

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 393,052.15057
Policy Entropy: 3.70441
Value Function Loss: 0.02224

Mean KL Divergence: 0.01170
SB3 Clip Fraction: 0.15759
Policy Update Magnitude: 0.42738
Value Function Update Magnitude: 0.43846

Collected Steps per Second: 20,221.76588
Overall Steps per Second: 9,851.11906

Timestep Collection Time: 2.47347
Timestep Consumption Time: 2.60392
PPO Batch Consumption Time: 0.30700
Total Iteration Time: 5.07739

Cumulative Model Updates: 111,742
Cumulative Timesteps: 931,763,360

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 931763360...
Checkpoint 931763360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 393,052.15057
Policy Entropy: 3.69906
Value Function Loss: 0.02245

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.14078
Policy Update Magnitude: 0.43926
Value Function Update Magnitude: 0.45566

Collected Steps per Second: 20,510.28490
Overall Steps per Second: 10,080.96582

Timestep Collection Time: 2.43829
Timestep Consumption Time: 2.52255
PPO Batch Consumption Time: 0.29528
Total Iteration Time: 4.96083

Cumulative Model Updates: 111,748
Cumulative Timesteps: 931,813,370

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 393,052.15057
Policy Entropy: 3.71127
Value Function Loss: 0.02137

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.14799
Policy Update Magnitude: 0.41822
Value Function Update Magnitude: 0.42090

Collected Steps per Second: 21,205.14764
Overall Steps per Second: 10,163.54117

Timestep Collection Time: 2.35886
Timestep Consumption Time: 2.56265
PPO Batch Consumption Time: 0.29878
Total Iteration Time: 4.92151

Cumulative Model Updates: 111,754
Cumulative Timesteps: 931,863,390

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 931863390...
Checkpoint 931863390 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 614,579.03260
Policy Entropy: 3.70078
Value Function Loss: 0.02231

Mean KL Divergence: 0.01074
SB3 Clip Fraction: 0.14754
Policy Update Magnitude: 0.38909
Value Function Update Magnitude: 0.38862

Collected Steps per Second: 20,649.88421
Overall Steps per Second: 10,004.87761

Timestep Collection Time: 2.42190
Timestep Consumption Time: 2.57686
PPO Batch Consumption Time: 0.30143
Total Iteration Time: 4.99876

Cumulative Model Updates: 111,760
Cumulative Timesteps: 931,913,402

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 614,579.03260
Policy Entropy: 3.69248
Value Function Loss: 0.02163

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.13785
Policy Update Magnitude: 0.39309
Value Function Update Magnitude: 0.37827

Collected Steps per Second: 21,241.97385
Overall Steps per Second: 10,170.55578

Timestep Collection Time: 2.35468
Timestep Consumption Time: 2.56324
PPO Batch Consumption Time: 0.29440
Total Iteration Time: 4.91792

Cumulative Model Updates: 111,766
Cumulative Timesteps: 931,963,420

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 931963420...
Checkpoint 931963420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 614,579.03260
Policy Entropy: 3.68916
Value Function Loss: 0.02231

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.14148
Policy Update Magnitude: 0.38797
Value Function Update Magnitude: 0.36218

Collected Steps per Second: 20,937.19069
Overall Steps per Second: 10,023.45762

Timestep Collection Time: 2.38857
Timestep Consumption Time: 2.60072
PPO Batch Consumption Time: 0.30346
Total Iteration Time: 4.98930

Cumulative Model Updates: 111,772
Cumulative Timesteps: 932,013,430

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 614,579.03260
Policy Entropy: 3.70099
Value Function Loss: 0.02051

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.14520
Policy Update Magnitude: 0.39870
Value Function Update Magnitude: 0.37530

Collected Steps per Second: 20,848.77423
Overall Steps per Second: 9,935.41109

Timestep Collection Time: 2.39880
Timestep Consumption Time: 2.63491
PPO Batch Consumption Time: 0.30694
Total Iteration Time: 5.03371

Cumulative Model Updates: 111,778
Cumulative Timesteps: 932,063,442

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 932063442...
Checkpoint 932063442 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 614,579.03260
Policy Entropy: 3.68241
Value Function Loss: 0.02174

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.14170
Policy Update Magnitude: 0.41732
Value Function Update Magnitude: 0.36343

Collected Steps per Second: 20,653.74119
Overall Steps per Second: 10,051.72374

Timestep Collection Time: 2.42222
Timestep Consumption Time: 2.55483
PPO Batch Consumption Time: 0.29461
Total Iteration Time: 4.97706

Cumulative Model Updates: 111,784
Cumulative Timesteps: 932,113,470

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 614,579.03260
Policy Entropy: 3.69353
Value Function Loss: 0.01983

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.14002
Policy Update Magnitude: 0.39913
Value Function Update Magnitude: 0.35678

Collected Steps per Second: 21,159.09255
Overall Steps per Second: 10,155.05386

Timestep Collection Time: 2.36305
Timestep Consumption Time: 2.56061
PPO Batch Consumption Time: 0.29375
Total Iteration Time: 4.92366

Cumulative Model Updates: 111,790
Cumulative Timesteps: 932,163,470

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 932163470...
Checkpoint 932163470 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 614,579.03260
Policy Entropy: 3.69152
Value Function Loss: 0.02141

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.14234
Policy Update Magnitude: 0.38530
Value Function Update Magnitude: 0.33784

Collected Steps per Second: 20,596.23948
Overall Steps per Second: 9,794.36110

Timestep Collection Time: 2.42899
Timestep Consumption Time: 2.67885
PPO Batch Consumption Time: 0.31523
Total Iteration Time: 5.10784

Cumulative Model Updates: 111,796
Cumulative Timesteps: 932,213,498

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 614,579.03260
Policy Entropy: 3.70053
Value Function Loss: 0.02025

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.13853
Policy Update Magnitude: 0.36142
Value Function Update Magnitude: 0.32853

Collected Steps per Second: 20,900.98968
Overall Steps per Second: 10,065.14739

Timestep Collection Time: 2.39328
Timestep Consumption Time: 2.57654
PPO Batch Consumption Time: 0.29355
Total Iteration Time: 4.96982

Cumulative Model Updates: 111,802
Cumulative Timesteps: 932,263,520

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 932263520...
Checkpoint 932263520 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 501,443.07374
Policy Entropy: 3.70143
Value Function Loss: 0.02240

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.14368
Policy Update Magnitude: 0.35512
Value Function Update Magnitude: 0.34525

Collected Steps per Second: 20,693.88771
Overall Steps per Second: 10,096.65679

Timestep Collection Time: 2.41724
Timestep Consumption Time: 2.53708
PPO Batch Consumption Time: 0.29493
Total Iteration Time: 4.95431

Cumulative Model Updates: 111,808
Cumulative Timesteps: 932,313,542

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 215,864.80343
Policy Entropy: 3.72016
Value Function Loss: 0.01979

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.14262
Policy Update Magnitude: 0.36225
Value Function Update Magnitude: 0.39521

Collected Steps per Second: 21,011.07720
Overall Steps per Second: 10,149.29433

Timestep Collection Time: 2.37989
Timestep Consumption Time: 2.54696
PPO Batch Consumption Time: 0.29374
Total Iteration Time: 4.92685

Cumulative Model Updates: 111,814
Cumulative Timesteps: 932,363,546

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 932363546...
Checkpoint 932363546 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 215,864.80343
Policy Entropy: 3.72753
Value Function Loss: 0.02051

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.14214
Policy Update Magnitude: 0.36342
Value Function Update Magnitude: 0.40788

Collected Steps per Second: 20,872.73171
Overall Steps per Second: 10,079.62692

Timestep Collection Time: 2.39662
Timestep Consumption Time: 2.56626
PPO Batch Consumption Time: 0.29473
Total Iteration Time: 4.96288

Cumulative Model Updates: 111,820
Cumulative Timesteps: 932,413,570

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 369,674.62972
Policy Entropy: 3.72536
Value Function Loss: 0.01933

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.13436
Policy Update Magnitude: 0.39469
Value Function Update Magnitude: 0.51099

Collected Steps per Second: 20,261.48613
Overall Steps per Second: 10,129.19812

Timestep Collection Time: 2.46813
Timestep Consumption Time: 2.46888
PPO Batch Consumption Time: 0.29301
Total Iteration Time: 4.93701

Cumulative Model Updates: 111,826
Cumulative Timesteps: 932,463,578

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 932463578...
Checkpoint 932463578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 242,551.16065
Policy Entropy: 3.70724
Value Function Loss: 0.02537

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.13994
Policy Update Magnitude: 0.42261
Value Function Update Magnitude: 0.51823

Collected Steps per Second: 20,306.67076
Overall Steps per Second: 10,108.36530

Timestep Collection Time: 2.46293
Timestep Consumption Time: 2.48485
PPO Batch Consumption Time: 0.29459
Total Iteration Time: 4.94778

Cumulative Model Updates: 111,832
Cumulative Timesteps: 932,513,592

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 242,551.16065
Policy Entropy: 3.71573
Value Function Loss: 0.02393

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.13956
Policy Update Magnitude: 0.47453
Value Function Update Magnitude: 0.47284

Collected Steps per Second: 20,194.44867
Overall Steps per Second: 9,875.57455

Timestep Collection Time: 2.47712
Timestep Consumption Time: 2.58831
PPO Batch Consumption Time: 0.30410
Total Iteration Time: 5.06543

Cumulative Model Updates: 111,838
Cumulative Timesteps: 932,563,616

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 932563616...
Checkpoint 932563616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 586,080.02679
Policy Entropy: 3.69312
Value Function Loss: 0.03197

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.13741
Policy Update Magnitude: 0.46756
Value Function Update Magnitude: 0.42060

Collected Steps per Second: 20,920.39537
Overall Steps per Second: 10,180.05401

Timestep Collection Time: 2.39154
Timestep Consumption Time: 2.52317
PPO Batch Consumption Time: 0.29345
Total Iteration Time: 4.91471

Cumulative Model Updates: 111,844
Cumulative Timesteps: 932,613,648

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 252,303.92730
Policy Entropy: 3.71513
Value Function Loss: 0.02169

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.14154
Policy Update Magnitude: 0.45960
Value Function Update Magnitude: 0.42598

Collected Steps per Second: 20,590.58931
Overall Steps per Second: 10,034.72774

Timestep Collection Time: 2.42927
Timestep Consumption Time: 2.55542
PPO Batch Consumption Time: 0.29947
Total Iteration Time: 4.98469

Cumulative Model Updates: 111,850
Cumulative Timesteps: 932,663,668

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 932663668...
Checkpoint 932663668 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 252,303.92730
Policy Entropy: 3.70591
Value Function Loss: 0.02445

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.13750
Policy Update Magnitude: 0.45815
Value Function Update Magnitude: 0.44487

Collected Steps per Second: 20,956.28905
Overall Steps per Second: 10,138.85578

Timestep Collection Time: 2.38850
Timestep Consumption Time: 2.54835
PPO Batch Consumption Time: 0.29430
Total Iteration Time: 4.93685

Cumulative Model Updates: 111,856
Cumulative Timesteps: 932,713,722

Timesteps Collected: 50,054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 288,274.38978
Policy Entropy: 3.71048
Value Function Loss: 0.02444

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.13318
Policy Update Magnitude: 0.46362
Value Function Update Magnitude: 0.45443

Collected Steps per Second: 20,968.64067
Overall Steps per Second: 10,053.08709

Timestep Collection Time: 2.38489
Timestep Consumption Time: 2.58950
PPO Batch Consumption Time: 0.29867
Total Iteration Time: 4.97439

Cumulative Model Updates: 111,862
Cumulative Timesteps: 932,763,730

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 932763730...
Checkpoint 932763730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 246,310.46883
Policy Entropy: 3.71396
Value Function Loss: 0.02434

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.13493
Policy Update Magnitude: 0.48716
Value Function Update Magnitude: 0.49244

Collected Steps per Second: 20,846.11885
Overall Steps per Second: 10,095.64460

Timestep Collection Time: 2.39920
Timestep Consumption Time: 2.55482
PPO Batch Consumption Time: 0.29520
Total Iteration Time: 4.95402

Cumulative Model Updates: 111,868
Cumulative Timesteps: 932,813,744

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 246,310.46883
Policy Entropy: 3.70605
Value Function Loss: 0.02488

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.13746
Policy Update Magnitude: 0.48161
Value Function Update Magnitude: 0.53680

Collected Steps per Second: 20,327.31580
Overall Steps per Second: 9,841.53472

Timestep Collection Time: 2.46014
Timestep Consumption Time: 2.62118
PPO Batch Consumption Time: 0.30736
Total Iteration Time: 5.08132

Cumulative Model Updates: 111,874
Cumulative Timesteps: 932,863,752

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 932863752...
Checkpoint 932863752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 246,310.46883
Policy Entropy: 3.73736
Value Function Loss: 0.02215

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.13438
Policy Update Magnitude: 0.48824
Value Function Update Magnitude: 0.61545

Collected Steps per Second: 20,450.41102
Overall Steps per Second: 9,957.53914

Timestep Collection Time: 2.44631
Timestep Consumption Time: 2.57783
PPO Batch Consumption Time: 0.30034
Total Iteration Time: 5.02413

Cumulative Model Updates: 111,880
Cumulative Timesteps: 932,913,780

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 246,310.46883
Policy Entropy: 3.72108
Value Function Loss: 0.02323

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.13114
Policy Update Magnitude: 0.46736
Value Function Update Magnitude: 0.60731

Collected Steps per Second: 21,026.84482
Overall Steps per Second: 10,126.41528

Timestep Collection Time: 2.38001
Timestep Consumption Time: 2.56192
PPO Batch Consumption Time: 0.29484
Total Iteration Time: 4.94193

Cumulative Model Updates: 111,886
Cumulative Timesteps: 932,963,824

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 932963824...
Checkpoint 932963824 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 246,310.46883
Policy Entropy: 3.74141
Value Function Loss: 0.02124

Mean KL Divergence: 0.01059
SB3 Clip Fraction: 0.14673
Policy Update Magnitude: 0.41095
Value Function Update Magnitude: 0.49464

Collected Steps per Second: 20,297.75862
Overall Steps per Second: 10,030.52205

Timestep Collection Time: 2.46461
Timestep Consumption Time: 2.52277
PPO Batch Consumption Time: 0.30399
Total Iteration Time: 4.98738

Cumulative Model Updates: 111,892
Cumulative Timesteps: 933,013,850

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 246,310.46883
Policy Entropy: 3.71871
Value Function Loss: 0.02221

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.14534
Policy Update Magnitude: 0.38692
Value Function Update Magnitude: 0.38364

Collected Steps per Second: 19,983.82711
Overall Steps per Second: 9,933.41163

Timestep Collection Time: 2.50332
Timestep Consumption Time: 2.53281
PPO Batch Consumption Time: 0.30362
Total Iteration Time: 5.03613

Cumulative Model Updates: 111,898
Cumulative Timesteps: 933,063,876

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 933063876...
Checkpoint 933063876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 246,310.46883
Policy Entropy: 3.72483
Value Function Loss: 0.02083

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.13600
Policy Update Magnitude: 0.40027
Value Function Update Magnitude: 0.45979

Collected Steps per Second: 20,452.20656
Overall Steps per Second: 9,977.53041

Timestep Collection Time: 2.44551
Timestep Consumption Time: 2.56736
PPO Batch Consumption Time: 0.30219
Total Iteration Time: 5.01286

Cumulative Model Updates: 111,904
Cumulative Timesteps: 933,113,892

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 246,310.46883
Policy Entropy: 3.71995
Value Function Loss: 0.02167

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.14325
Policy Update Magnitude: 0.40996
Value Function Update Magnitude: 0.51562

Collected Steps per Second: 20,747.86823
Overall Steps per Second: 10,059.11682

Timestep Collection Time: 2.41066
Timestep Consumption Time: 2.56155
PPO Batch Consumption Time: 0.30035
Total Iteration Time: 4.97221

Cumulative Model Updates: 111,910
Cumulative Timesteps: 933,163,908

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 933163908...
Checkpoint 933163908 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 246,310.46883
Policy Entropy: 3.71827
Value Function Loss: 0.02028

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.14280
Policy Update Magnitude: 0.41340
Value Function Update Magnitude: 0.44932

Collected Steps per Second: 20,690.65057
Overall Steps per Second: 10,005.29011

Timestep Collection Time: 2.41732
Timestep Consumption Time: 2.58163
PPO Batch Consumption Time: 0.29789
Total Iteration Time: 4.99896

Cumulative Model Updates: 111,916
Cumulative Timesteps: 933,213,924

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 246,310.46883
Policy Entropy: 3.71457
Value Function Loss: 0.02187

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.13688
Policy Update Magnitude: 0.40787
Value Function Update Magnitude: 0.39277

Collected Steps per Second: 20,859.55301
Overall Steps per Second: 10,063.68416

Timestep Collection Time: 2.39833
Timestep Consumption Time: 2.57282
PPO Batch Consumption Time: 0.29769
Total Iteration Time: 4.97114

Cumulative Model Updates: 111,922
Cumulative Timesteps: 933,263,952

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 933263952...
Checkpoint 933263952 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 246,310.46883
Policy Entropy: 3.71703
Value Function Loss: 0.02230

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.13950
Policy Update Magnitude: 0.42567
Value Function Update Magnitude: 0.36212

Collected Steps per Second: 20,522.52438
Overall Steps per Second: 9,927.39750

Timestep Collection Time: 2.43878
Timestep Consumption Time: 2.60282
PPO Batch Consumption Time: 0.30480
Total Iteration Time: 5.04160

Cumulative Model Updates: 111,928
Cumulative Timesteps: 933,314,002

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 246,310.46883
Policy Entropy: 3.71216
Value Function Loss: 0.02458

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.13465
Policy Update Magnitude: 0.44016
Value Function Update Magnitude: 0.34761

Collected Steps per Second: 20,895.63547
Overall Steps per Second: 9,984.97524

Timestep Collection Time: 2.39428
Timestep Consumption Time: 2.61625
PPO Batch Consumption Time: 0.30502
Total Iteration Time: 5.01053

Cumulative Model Updates: 111,934
Cumulative Timesteps: 933,364,032

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 933364032...
Checkpoint 933364032 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 246,310.46883
Policy Entropy: 3.71523
Value Function Loss: 0.02630

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.13779
Policy Update Magnitude: 0.45424
Value Function Update Magnitude: 0.37394

Collected Steps per Second: 19,952.98784
Overall Steps per Second: 9,760.11727

Timestep Collection Time: 2.50739
Timestep Consumption Time: 2.61857
PPO Batch Consumption Time: 0.30700
Total Iteration Time: 5.12596

Cumulative Model Updates: 111,940
Cumulative Timesteps: 933,414,062

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 246,310.46883
Policy Entropy: 3.71411
Value Function Loss: 0.02505

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.14274
Policy Update Magnitude: 0.44866
Value Function Update Magnitude: 0.38131

Collected Steps per Second: 21,197.17548
Overall Steps per Second: 9,891.48323

Timestep Collection Time: 2.35947
Timestep Consumption Time: 2.69680
PPO Batch Consumption Time: 0.31938
Total Iteration Time: 5.05627

Cumulative Model Updates: 111,946
Cumulative Timesteps: 933,464,076

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 933464076...
Checkpoint 933464076 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 668,548.04455
Policy Entropy: 3.72469
Value Function Loss: 0.02718

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.13880
Policy Update Magnitude: 0.47720
Value Function Update Magnitude: 0.38377

Collected Steps per Second: 20,792.98784
Overall Steps per Second: 9,981.81837

Timestep Collection Time: 2.40620
Timestep Consumption Time: 2.60612
PPO Batch Consumption Time: 0.30565
Total Iteration Time: 5.01231

Cumulative Model Updates: 111,952
Cumulative Timesteps: 933,514,108

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 100,363.29753
Policy Entropy: 3.74489
Value Function Loss: 0.02604

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.13092
Policy Update Magnitude: 0.51556
Value Function Update Magnitude: 0.53288

Collected Steps per Second: 20,323.06366
Overall Steps per Second: 9,999.46946

Timestep Collection Time: 2.46134
Timestep Consumption Time: 2.54112
PPO Batch Consumption Time: 0.30631
Total Iteration Time: 5.00247

Cumulative Model Updates: 111,958
Cumulative Timesteps: 933,564,130

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 933564130...
Checkpoint 933564130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 100,363.29753
Policy Entropy: 3.74760
Value Function Loss: 0.02553

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.13634
Policy Update Magnitude: 0.51021
Value Function Update Magnitude: 0.54336

Collected Steps per Second: 20,059.68243
Overall Steps per Second: 10,078.90026

Timestep Collection Time: 2.49286
Timestep Consumption Time: 2.46859
PPO Batch Consumption Time: 0.29454
Total Iteration Time: 4.96145

Cumulative Model Updates: 111,964
Cumulative Timesteps: 933,614,136

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 100,363.29753
Policy Entropy: 3.73377
Value Function Loss: 0.02432

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.13752
Policy Update Magnitude: 0.48627
Value Function Update Magnitude: 0.49387

Collected Steps per Second: 20,374.65680
Overall Steps per Second: 9,957.15402

Timestep Collection Time: 2.45521
Timestep Consumption Time: 2.56872
PPO Batch Consumption Time: 0.30097
Total Iteration Time: 5.02393

Cumulative Model Updates: 111,970
Cumulative Timesteps: 933,664,160

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 933664160...
Checkpoint 933664160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 100,363.29753
Policy Entropy: 3.71672
Value Function Loss: 0.02497

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.13427
Policy Update Magnitude: 0.46499
Value Function Update Magnitude: 0.43843

Collected Steps per Second: 20,620.47775
Overall Steps per Second: 10,024.24533

Timestep Collection Time: 2.42565
Timestep Consumption Time: 2.56406
PPO Batch Consumption Time: 0.30101
Total Iteration Time: 4.98970

Cumulative Model Updates: 111,976
Cumulative Timesteps: 933,714,178

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 100,363.29753
Policy Entropy: 3.71496
Value Function Loss: 0.02422

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.13332
Policy Update Magnitude: 0.46476
Value Function Update Magnitude: 0.37088

Collected Steps per Second: 20,704.35126
Overall Steps per Second: 10,026.87905

Timestep Collection Time: 2.41495
Timestep Consumption Time: 2.57165
PPO Batch Consumption Time: 0.29942
Total Iteration Time: 4.98660

Cumulative Model Updates: 111,982
Cumulative Timesteps: 933,764,178

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 933764178...
Checkpoint 933764178 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 100,363.29753
Policy Entropy: 3.72697
Value Function Loss: 0.02372

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.13642
Policy Update Magnitude: 0.44085
Value Function Update Magnitude: 0.46138

Collected Steps per Second: 20,469.06271
Overall Steps per Second: 9,889.11931

Timestep Collection Time: 2.44418
Timestep Consumption Time: 2.61492
PPO Batch Consumption Time: 0.30613
Total Iteration Time: 5.05910

Cumulative Model Updates: 111,988
Cumulative Timesteps: 933,814,208

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 777,566.96184
Policy Entropy: 3.73464
Value Function Loss: 0.02443

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.13621
Policy Update Magnitude: 0.43161
Value Function Update Magnitude: 0.48149

Collected Steps per Second: 20,787.93879
Overall Steps per Second: 9,956.31990

Timestep Collection Time: 2.40553
Timestep Consumption Time: 2.61701
PPO Batch Consumption Time: 0.30332
Total Iteration Time: 5.02254

Cumulative Model Updates: 111,994
Cumulative Timesteps: 933,864,214

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 933864214...
Checkpoint 933864214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 710,818.24964
Policy Entropy: 3.72301
Value Function Loss: 0.02225

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.13603
Policy Update Magnitude: 0.44279
Value Function Update Magnitude: 0.54376

Collected Steps per Second: 20,667.68416
Overall Steps per Second: 9,996.77817

Timestep Collection Time: 2.41933
Timestep Consumption Time: 2.58248
PPO Batch Consumption Time: 0.30106
Total Iteration Time: 5.00181

Cumulative Model Updates: 112,000
Cumulative Timesteps: 933,914,216

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 710,818.24964
Policy Entropy: 3.70527
Value Function Loss: 0.02273

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.13740
Policy Update Magnitude: 0.44881
Value Function Update Magnitude: 0.47682

Collected Steps per Second: 20,778.67074
Overall Steps per Second: 9,920.38122

Timestep Collection Time: 2.40834
Timestep Consumption Time: 2.63603
PPO Batch Consumption Time: 0.30643
Total Iteration Time: 5.04436

Cumulative Model Updates: 112,006
Cumulative Timesteps: 933,964,258

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 933964258...
Checkpoint 933964258 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 710,818.24964
Policy Entropy: 3.70120
Value Function Loss: 0.02191

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.13490
Policy Update Magnitude: 0.47439
Value Function Update Magnitude: 0.44158

Collected Steps per Second: 20,617.95857
Overall Steps per Second: 10,008.87689

Timestep Collection Time: 2.42682
Timestep Consumption Time: 2.57235
PPO Batch Consumption Time: 0.29619
Total Iteration Time: 4.99916

Cumulative Model Updates: 112,012
Cumulative Timesteps: 934,014,294

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 710,818.24964
Policy Entropy: 3.69607
Value Function Loss: 0.02177

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.13959
Policy Update Magnitude: 0.45636
Value Function Update Magnitude: 0.44978

Collected Steps per Second: 20,826.08153
Overall Steps per Second: 10,083.75093

Timestep Collection Time: 2.40199
Timestep Consumption Time: 2.55886
PPO Batch Consumption Time: 0.29425
Total Iteration Time: 4.96085

Cumulative Model Updates: 112,018
Cumulative Timesteps: 934,064,318

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 934064318...
Checkpoint 934064318 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 710,818.24964
Policy Entropy: 3.70714
Value Function Loss: 0.02083

Mean KL Divergence: 0.01053
SB3 Clip Fraction: 0.14143
Policy Update Magnitude: 0.41529
Value Function Update Magnitude: 0.36103

Collected Steps per Second: 20,737.49730
Overall Steps per Second: 9,854.84929

Timestep Collection Time: 2.41235
Timestep Consumption Time: 2.66394
PPO Batch Consumption Time: 0.31675
Total Iteration Time: 5.07628

Cumulative Model Updates: 112,024
Cumulative Timesteps: 934,114,344

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 710,818.24964
Policy Entropy: 3.70832
Value Function Loss: 0.01978

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.14020
Policy Update Magnitude: 0.39416
Value Function Update Magnitude: 0.34052

Collected Steps per Second: 20,995.89928
Overall Steps per Second: 10,080.18876

Timestep Collection Time: 2.38275
Timestep Consumption Time: 2.58025
PPO Batch Consumption Time: 0.29756
Total Iteration Time: 4.96300

Cumulative Model Updates: 112,030
Cumulative Timesteps: 934,164,372

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 934164372...
Checkpoint 934164372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,196,112.27259
Policy Entropy: 3.71763
Value Function Loss: 0.02032

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.13483
Policy Update Magnitude: 0.38922
Value Function Update Magnitude: 0.35093

Collected Steps per Second: 20,828.48570
Overall Steps per Second: 10,085.67743

Timestep Collection Time: 2.40065
Timestep Consumption Time: 2.55707
PPO Batch Consumption Time: 0.29527
Total Iteration Time: 4.95772

Cumulative Model Updates: 112,036
Cumulative Timesteps: 934,214,374

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 635,690.75388
Policy Entropy: 3.72367
Value Function Loss: 0.01884

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.13674
Policy Update Magnitude: 0.41317
Value Function Update Magnitude: 0.40237

Collected Steps per Second: 21,020.54299
Overall Steps per Second: 10,094.41369

Timestep Collection Time: 2.37901
Timestep Consumption Time: 2.57502
PPO Batch Consumption Time: 0.29494
Total Iteration Time: 4.95403

Cumulative Model Updates: 112,042
Cumulative Timesteps: 934,264,382

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 934264382...
Checkpoint 934264382 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 635,690.75388
Policy Entropy: 3.69602
Value Function Loss: 0.01962

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.12814
Policy Update Magnitude: 0.43191
Value Function Update Magnitude: 0.45629

Collected Steps per Second: 21,225.99702
Overall Steps per Second: 10,186.92448

Timestep Collection Time: 2.35579
Timestep Consumption Time: 2.55285
PPO Batch Consumption Time: 0.29434
Total Iteration Time: 4.90865

Cumulative Model Updates: 112,048
Cumulative Timesteps: 934,314,386

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 635,690.75388
Policy Entropy: 3.69390
Value Function Loss: 0.02087

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.13373
Policy Update Magnitude: 0.41469
Value Function Update Magnitude: 0.39179

Collected Steps per Second: 20,801.65714
Overall Steps per Second: 10,059.32997

Timestep Collection Time: 2.40375
Timestep Consumption Time: 2.56696
PPO Batch Consumption Time: 0.29458
Total Iteration Time: 4.97071

Cumulative Model Updates: 112,054
Cumulative Timesteps: 934,364,388

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 934364388...
Checkpoint 934364388 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 635,690.75388
Policy Entropy: 3.69206
Value Function Loss: 0.02140

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.14043
Policy Update Magnitude: 0.41454
Value Function Update Magnitude: 0.35216

Collected Steps per Second: 20,322.71242
Overall Steps per Second: 10,077.58869

Timestep Collection Time: 2.46188
Timestep Consumption Time: 2.50280
PPO Batch Consumption Time: 0.30180
Total Iteration Time: 4.96468

Cumulative Model Updates: 112,060
Cumulative Timesteps: 934,414,420

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 635,690.75388
Policy Entropy: 3.71135
Value Function Loss: 0.01966

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.13527
Policy Update Magnitude: 0.42413
Value Function Update Magnitude: 0.34906

Collected Steps per Second: 20,519.27200
Overall Steps per Second: 10,186.67622

Timestep Collection Time: 2.43712
Timestep Consumption Time: 2.47203
PPO Batch Consumption Time: 0.29339
Total Iteration Time: 4.90916

Cumulative Model Updates: 112,066
Cumulative Timesteps: 934,464,428

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 934464428...
Checkpoint 934464428 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 635,690.75388
Policy Entropy: 3.71149
Value Function Loss: 0.01914

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.13661
Policy Update Magnitude: 0.41287
Value Function Update Magnitude: 0.35542

Collected Steps per Second: 20,505.19482
Overall Steps per Second: 9,937.80263

Timestep Collection Time: 2.44006
Timestep Consumption Time: 2.59465
PPO Batch Consumption Time: 0.30610
Total Iteration Time: 5.03471

Cumulative Model Updates: 112,072
Cumulative Timesteps: 934,514,462

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 635,690.75388
Policy Entropy: 3.70634
Value Function Loss: 0.01904

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.13925
Policy Update Magnitude: 0.40702
Value Function Update Magnitude: 0.39165

Collected Steps per Second: 20,832.36076
Overall Steps per Second: 9,969.18767

Timestep Collection Time: 2.40126
Timestep Consumption Time: 2.61660
PPO Batch Consumption Time: 0.30763
Total Iteration Time: 5.01786

Cumulative Model Updates: 112,078
Cumulative Timesteps: 934,564,486

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 934564486...
Checkpoint 934564486 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 824,658.74492
Policy Entropy: 3.70397
Value Function Loss: 0.01985

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.13941
Policy Update Magnitude: 0.41751
Value Function Update Magnitude: 0.45124

Collected Steps per Second: 20,031.45168
Overall Steps per Second: 9,814.89799

Timestep Collection Time: 2.49697
Timestep Consumption Time: 2.59916
PPO Batch Consumption Time: 0.30588
Total Iteration Time: 5.09613

Cumulative Model Updates: 112,084
Cumulative Timesteps: 934,614,504

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 541,057.29859
Policy Entropy: 3.71216
Value Function Loss: 0.01980

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.14385
Policy Update Magnitude: 0.40484
Value Function Update Magnitude: 0.48742

Collected Steps per Second: 20,390.98302
Overall Steps per Second: 9,947.92443

Timestep Collection Time: 2.45334
Timestep Consumption Time: 2.57545
PPO Batch Consumption Time: 0.29436
Total Iteration Time: 5.02879

Cumulative Model Updates: 112,090
Cumulative Timesteps: 934,664,530

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 934664530...
Checkpoint 934664530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 541,057.29859
Policy Entropy: 3.73169
Value Function Loss: 0.01983

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.13422
Policy Update Magnitude: 0.39062
Value Function Update Magnitude: 0.44345

Collected Steps per Second: 20,664.93788
Overall Steps per Second: 9,849.08741

Timestep Collection Time: 2.42140
Timestep Consumption Time: 2.65907
PPO Batch Consumption Time: 0.30737
Total Iteration Time: 5.08047

Cumulative Model Updates: 112,096
Cumulative Timesteps: 934,714,568

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 541,057.29859
Policy Entropy: 3.70853
Value Function Loss: 0.01933

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.13190
Policy Update Magnitude: 0.41294
Value Function Update Magnitude: 0.49218

Collected Steps per Second: 20,604.14345
Overall Steps per Second: 10,039.59198

Timestep Collection Time: 2.42689
Timestep Consumption Time: 2.55379
PPO Batch Consumption Time: 0.29254
Total Iteration Time: 4.98068

Cumulative Model Updates: 112,102
Cumulative Timesteps: 934,764,572

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 934764572...
Checkpoint 934764572 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 541,057.29859
Policy Entropy: 3.71519
Value Function Loss: 0.01769

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.13336
Policy Update Magnitude: 0.44185
Value Function Update Magnitude: 0.59674

Collected Steps per Second: 20,686.23599
Overall Steps per Second: 9,848.11551

Timestep Collection Time: 2.41881
Timestep Consumption Time: 2.66196
PPO Batch Consumption Time: 0.30296
Total Iteration Time: 5.08077

Cumulative Model Updates: 112,108
Cumulative Timesteps: 934,814,608

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 541,057.29859
Policy Entropy: 3.70348
Value Function Loss: 0.01940

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.13805
Policy Update Magnitude: 0.44041
Value Function Update Magnitude: 0.49728

Collected Steps per Second: 20,911.65557
Overall Steps per Second: 10,070.83823

Timestep Collection Time: 2.39273
Timestep Consumption Time: 2.57567
PPO Batch Consumption Time: 0.29708
Total Iteration Time: 4.96840

Cumulative Model Updates: 112,114
Cumulative Timesteps: 934,864,644

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 934864644...
Checkpoint 934864644 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 541,057.29859
Policy Entropy: 3.71556
Value Function Loss: 0.01893

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.13814
Policy Update Magnitude: 0.43705
Value Function Update Magnitude: 0.43432

Collected Steps per Second: 20,806.60208
Overall Steps per Second: 10,078.07821

Timestep Collection Time: 2.40433
Timestep Consumption Time: 2.55951
PPO Batch Consumption Time: 0.29472
Total Iteration Time: 4.96384

Cumulative Model Updates: 112,120
Cumulative Timesteps: 934,914,670

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 541,057.29859
Policy Entropy: 3.70138
Value Function Loss: 0.01903

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.14263
Policy Update Magnitude: 0.41044
Value Function Update Magnitude: 0.41027

Collected Steps per Second: 20,947.92853
Overall Steps per Second: 10,108.25063

Timestep Collection Time: 2.38783
Timestep Consumption Time: 2.56061
PPO Batch Consumption Time: 0.29385
Total Iteration Time: 4.94843

Cumulative Model Updates: 112,126
Cumulative Timesteps: 934,964,690

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 934964690...
Checkpoint 934964690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 541,057.29859
Policy Entropy: 3.70238
Value Function Loss: 0.01761

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.14066
Policy Update Magnitude: 0.39238
Value Function Update Magnitude: 0.42693

Collected Steps per Second: 21,112.83230
Overall Steps per Second: 10,158.77985

Timestep Collection Time: 2.36832
Timestep Consumption Time: 2.55373
PPO Batch Consumption Time: 0.29459
Total Iteration Time: 4.92205

Cumulative Model Updates: 112,132
Cumulative Timesteps: 935,014,692

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 541,057.29859
Policy Entropy: 3.70733
Value Function Loss: 0.01726

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.13955
Policy Update Magnitude: 0.38083
Value Function Update Magnitude: 0.52373

Collected Steps per Second: 20,425.62157
Overall Steps per Second: 10,150.35706

Timestep Collection Time: 2.44898
Timestep Consumption Time: 2.47912
PPO Batch Consumption Time: 0.29512
Total Iteration Time: 4.92810

Cumulative Model Updates: 112,138
Cumulative Timesteps: 935,064,714

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 935064714...
Checkpoint 935064714 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 541,057.29859
Policy Entropy: 3.70545
Value Function Loss: 0.01749

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.13857
Policy Update Magnitude: 0.39140
Value Function Update Magnitude: 0.58372

Collected Steps per Second: 20,160.62326
Overall Steps per Second: 10,100.66767

Timestep Collection Time: 2.48137
Timestep Consumption Time: 2.47137
PPO Batch Consumption Time: 0.29441
Total Iteration Time: 4.95274

Cumulative Model Updates: 112,144
Cumulative Timesteps: 935,114,740

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,301,868.88459
Policy Entropy: 3.70590
Value Function Loss: 0.02357

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.14277
Policy Update Magnitude: 0.41965
Value Function Update Magnitude: 0.59215

Collected Steps per Second: 20,376.82377
Overall Steps per Second: 10,009.51885

Timestep Collection Time: 2.45475
Timestep Consumption Time: 2.54249
PPO Batch Consumption Time: 0.29573
Total Iteration Time: 4.99724

Cumulative Model Updates: 112,150
Cumulative Timesteps: 935,164,760

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 935164760...
Checkpoint 935164760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 736,663.74253
Policy Entropy: 3.70865
Value Function Loss: 0.02583

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.14167
Policy Update Magnitude: 0.49948
Value Function Update Magnitude: 0.78342

Collected Steps per Second: 20,810.65863
Overall Steps per Second: 10,032.89639

Timestep Collection Time: 2.40319
Timestep Consumption Time: 2.58161
PPO Batch Consumption Time: 0.30428
Total Iteration Time: 4.98480

Cumulative Model Updates: 112,156
Cumulative Timesteps: 935,214,772

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 240,058.91725
Policy Entropy: 3.71649
Value Function Loss: 0.03007

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.13854
Policy Update Magnitude: 0.53391
Value Function Update Magnitude: 0.80081

Collected Steps per Second: 20,817.68820
Overall Steps per Second: 10,063.02332

Timestep Collection Time: 2.40344
Timestep Consumption Time: 2.56863
PPO Batch Consumption Time: 0.30363
Total Iteration Time: 4.97206

Cumulative Model Updates: 112,162
Cumulative Timesteps: 935,264,806

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 935264806...
Checkpoint 935264806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 443,364.01516
Policy Entropy: 3.74613
Value Function Loss: 0.02948

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.13545
Policy Update Magnitude: 0.55456
Value Function Update Magnitude: 0.81731

Collected Steps per Second: 20,722.74403
Overall Steps per Second: 10,075.26284

Timestep Collection Time: 2.41300
Timestep Consumption Time: 2.55005
PPO Batch Consumption Time: 0.29801
Total Iteration Time: 4.96305

Cumulative Model Updates: 112,168
Cumulative Timesteps: 935,314,810

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 139,209.50747
Policy Entropy: 3.77015
Value Function Loss: 0.02860

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.13234
Policy Update Magnitude: 0.57664
Value Function Update Magnitude: 0.82894

Collected Steps per Second: 20,678.47510
Overall Steps per Second: 9,899.68390

Timestep Collection Time: 2.41865
Timestep Consumption Time: 2.63343
PPO Batch Consumption Time: 0.30677
Total Iteration Time: 5.05208

Cumulative Model Updates: 112,174
Cumulative Timesteps: 935,364,824

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 935364824...
Checkpoint 935364824 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,727.48172
Policy Entropy: 3.77669
Value Function Loss: 0.02623

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.13408
Policy Update Magnitude: 0.57925
Value Function Update Magnitude: 0.81262

Collected Steps per Second: 20,812.89992
Overall Steps per Second: 10,047.31523

Timestep Collection Time: 2.40303
Timestep Consumption Time: 2.57482
PPO Batch Consumption Time: 0.30455
Total Iteration Time: 4.97785

Cumulative Model Updates: 112,180
Cumulative Timesteps: 935,414,838

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,924.95706
Policy Entropy: 3.74702
Value Function Loss: 0.02526

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.13378
Policy Update Magnitude: 0.54584
Value Function Update Magnitude: 0.69206

Collected Steps per Second: 20,973.76053
Overall Steps per Second: 9,992.29075

Timestep Collection Time: 2.38393
Timestep Consumption Time: 2.61993
PPO Batch Consumption Time: 0.30531
Total Iteration Time: 5.00386

Cumulative Model Updates: 112,186
Cumulative Timesteps: 935,464,838

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 935464838...
Checkpoint 935464838 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,180.67206
Policy Entropy: 3.72769
Value Function Loss: 0.02314

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.14124
Policy Update Magnitude: 0.50023
Value Function Update Magnitude: 0.56807

Collected Steps per Second: 20,925.66099
Overall Steps per Second: 10,123.48183

Timestep Collection Time: 2.39056
Timestep Consumption Time: 2.55083
PPO Batch Consumption Time: 0.29462
Total Iteration Time: 4.94138

Cumulative Model Updates: 112,192
Cumulative Timesteps: 935,514,862

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,180.67206
Policy Entropy: 3.73760
Value Function Loss: 0.02110

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.14468
Policy Update Magnitude: 0.42521
Value Function Update Magnitude: 0.49976

Collected Steps per Second: 21,076.15626
Overall Steps per Second: 10,062.04404

Timestep Collection Time: 2.37368
Timestep Consumption Time: 2.59827
PPO Batch Consumption Time: 0.30047
Total Iteration Time: 4.97195

Cumulative Model Updates: 112,198
Cumulative Timesteps: 935,564,890

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 935564890...
Checkpoint 935564890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,180.67206
Policy Entropy: 3.71817
Value Function Loss: 0.02214

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.13427
Policy Update Magnitude: 0.38600
Value Function Update Magnitude: 0.42090

Collected Steps per Second: 20,562.47592
Overall Steps per Second: 9,938.47926

Timestep Collection Time: 2.43268
Timestep Consumption Time: 2.60048
PPO Batch Consumption Time: 0.30336
Total Iteration Time: 5.03316

Cumulative Model Updates: 112,204
Cumulative Timesteps: 935,614,912

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,180.67206
Policy Entropy: 3.70983
Value Function Loss: 0.02213

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.13539
Policy Update Magnitude: 0.39676
Value Function Update Magnitude: 0.37901

Collected Steps per Second: 20,801.28658
Overall Steps per Second: 9,980.04589

Timestep Collection Time: 2.40476
Timestep Consumption Time: 2.60745
PPO Batch Consumption Time: 0.30591
Total Iteration Time: 5.01220

Cumulative Model Updates: 112,210
Cumulative Timesteps: 935,664,934

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 935664934...
Checkpoint 935664934 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,180.67206
Policy Entropy: 3.69353
Value Function Loss: 0.02236

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.14146
Policy Update Magnitude: 0.39410
Value Function Update Magnitude: 0.35285

Collected Steps per Second: 20,370.27860
Overall Steps per Second: 9,909.46873

Timestep Collection Time: 2.45573
Timestep Consumption Time: 2.59237
PPO Batch Consumption Time: 0.30332
Total Iteration Time: 5.04810

Cumulative Model Updates: 112,216
Cumulative Timesteps: 935,714,958

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 466,523.86243
Policy Entropy: 3.70373
Value Function Loss: 0.01822

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.14187
Policy Update Magnitude: 0.37589
Value Function Update Magnitude: 0.44625

Collected Steps per Second: 21,215.36948
Overall Steps per Second: 10,170.21710

Timestep Collection Time: 2.35697
Timestep Consumption Time: 2.55974
PPO Batch Consumption Time: 0.29514
Total Iteration Time: 4.91671

Cumulative Model Updates: 112,222
Cumulative Timesteps: 935,764,962

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 935764962...
Checkpoint 935764962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 466,523.86243
Policy Entropy: 3.71507
Value Function Loss: 0.01749

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.14086
Policy Update Magnitude: 0.41722
Value Function Update Magnitude: 0.60568

Collected Steps per Second: 20,305.35465
Overall Steps per Second: 10,059.68194

Timestep Collection Time: 2.46408
Timestep Consumption Time: 2.50964
PPO Batch Consumption Time: 0.30231
Total Iteration Time: 4.97372

Cumulative Model Updates: 112,228
Cumulative Timesteps: 935,814,996

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 466,523.86243
Policy Entropy: 3.71843
Value Function Loss: 0.01861

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.13898
Policy Update Magnitude: 0.40857
Value Function Update Magnitude: 0.61262

Collected Steps per Second: 19,899.37690
Overall Steps per Second: 9,889.42099

Timestep Collection Time: 2.51284
Timestep Consumption Time: 2.54347
PPO Batch Consumption Time: 0.30685
Total Iteration Time: 5.05631

Cumulative Model Updates: 112,234
Cumulative Timesteps: 935,865,000

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 935865000...
Checkpoint 935865000 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 680,718.15438
Policy Entropy: 3.71846
Value Function Loss: 0.02411

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.14263
Policy Update Magnitude: 0.43673
Value Function Update Magnitude: 0.51060

Collected Steps per Second: 19,946.06596
Overall Steps per Second: 9,812.81524

Timestep Collection Time: 2.50806
Timestep Consumption Time: 2.58996
PPO Batch Consumption Time: 0.30714
Total Iteration Time: 5.09803

Cumulative Model Updates: 112,240
Cumulative Timesteps: 935,915,026

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 361,769.57199
Policy Entropy: 3.70604
Value Function Loss: 0.03172

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.14008
Policy Update Magnitude: 0.47524
Value Function Update Magnitude: 0.48206

Collected Steps per Second: 20,754.55806
Overall Steps per Second: 9,985.96036

Timestep Collection Time: 2.41007
Timestep Consumption Time: 2.59896
PPO Batch Consumption Time: 0.30073
Total Iteration Time: 5.00903

Cumulative Model Updates: 112,246
Cumulative Timesteps: 935,965,046

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 935965046...
Checkpoint 935965046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 361,769.57199
Policy Entropy: 3.71195
Value Function Loss: 0.02982

Mean KL Divergence: 0.01066
SB3 Clip Fraction: 0.14293
Policy Update Magnitude: 0.50743
Value Function Update Magnitude: 0.41493

Collected Steps per Second: 20,720.70848
Overall Steps per Second: 10,134.76576

Timestep Collection Time: 2.41391
Timestep Consumption Time: 2.52138
PPO Batch Consumption Time: 0.29546
Total Iteration Time: 4.93529

Cumulative Model Updates: 112,252
Cumulative Timesteps: 936,015,064

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 400,039.96754
Policy Entropy: 3.71577
Value Function Loss: 0.02810

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.14143
Policy Update Magnitude: 0.51590
Value Function Update Magnitude: 0.54712

Collected Steps per Second: 20,708.31387
Overall Steps per Second: 9,958.95731

Timestep Collection Time: 2.41681
Timestep Consumption Time: 2.60862
PPO Batch Consumption Time: 0.30107
Total Iteration Time: 5.02543

Cumulative Model Updates: 112,258
Cumulative Timesteps: 936,065,112

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 936065112...
Checkpoint 936065112 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 282,345.91361
Policy Entropy: 3.71425
Value Function Loss: 0.03211

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.13601
Policy Update Magnitude: 0.58819
Value Function Update Magnitude: 0.61455

Collected Steps per Second: 20,657.28281
Overall Steps per Second: 10,052.61560

Timestep Collection Time: 2.42065
Timestep Consumption Time: 2.55358
PPO Batch Consumption Time: 0.29323
Total Iteration Time: 4.97423

Cumulative Model Updates: 112,264
Cumulative Timesteps: 936,115,116

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 875,917.25944
Policy Entropy: 3.74397
Value Function Loss: 0.03023

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.13766
Policy Update Magnitude: 0.68663
Value Function Update Magnitude: 0.70459

Collected Steps per Second: 20,592.58420
Overall Steps per Second: 9,996.82310

Timestep Collection Time: 2.42874
Timestep Consumption Time: 2.57425
PPO Batch Consumption Time: 0.29727
Total Iteration Time: 5.00299

Cumulative Model Updates: 112,270
Cumulative Timesteps: 936,165,130

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 936165130...
Checkpoint 936165130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 396,950.51478
Policy Entropy: 3.74170
Value Function Loss: 0.03316

Mean KL Divergence: 0.01122
SB3 Clip Fraction: 0.14341
Policy Update Magnitude: 0.63311
Value Function Update Magnitude: 0.70453

Collected Steps per Second: 20,861.08292
Overall Steps per Second: 10,101.38232

Timestep Collection Time: 2.39681
Timestep Consumption Time: 2.55301
PPO Batch Consumption Time: 0.29519
Total Iteration Time: 4.94982

Cumulative Model Updates: 112,276
Cumulative Timesteps: 936,215,130

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 138,427.76074
Policy Entropy: 3.74881
Value Function Loss: 0.02532

Mean KL Divergence: 0.01242
SB3 Clip Fraction: 0.15558
Policy Update Magnitude: 0.61149
Value Function Update Magnitude: 0.74749

Collected Steps per Second: 21,063.51367
Overall Steps per Second: 10,169.23383

Timestep Collection Time: 2.37396
Timestep Consumption Time: 2.54322
PPO Batch Consumption Time: 0.29230
Total Iteration Time: 4.91718

Cumulative Model Updates: 112,282
Cumulative Timesteps: 936,265,134

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 936265134...
Checkpoint 936265134 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 90,830.05268
Policy Entropy: 3.74154
Value Function Loss: 0.02229

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.11579
Policy Update Magnitude: 0.66499
Value Function Update Magnitude: 0.78613

Collected Steps per Second: 20,948.52742
Overall Steps per Second: 10,134.77813

Timestep Collection Time: 2.38890
Timestep Consumption Time: 2.54895
PPO Batch Consumption Time: 0.29364
Total Iteration Time: 4.93785

Cumulative Model Updates: 112,288
Cumulative Timesteps: 936,315,178

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90,830.05268
Policy Entropy: 3.74645
Value Function Loss: 0.01802

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.12296
Policy Update Magnitude: 0.63353
Value Function Update Magnitude: 0.75223

Collected Steps per Second: 20,838.50294
Overall Steps per Second: 10,069.25354

Timestep Collection Time: 2.40065
Timestep Consumption Time: 2.56754
PPO Batch Consumption Time: 0.29496
Total Iteration Time: 4.96819

Cumulative Model Updates: 112,294
Cumulative Timesteps: 936,365,204

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 936365204...
Checkpoint 936365204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 188,564.08357
Policy Entropy: 3.75221
Value Function Loss: 0.01653

Mean KL Divergence: 0.02804
SB3 Clip Fraction: 0.28636
Policy Update Magnitude: 0.51718
Value Function Update Magnitude: 0.74114

Collected Steps per Second: 21,443.56190
Overall Steps per Second: 10,265.83822

Timestep Collection Time: 2.33310
Timestep Consumption Time: 2.54034
PPO Batch Consumption Time: 0.29295
Total Iteration Time: 4.87345

Cumulative Model Updates: 112,300
Cumulative Timesteps: 936,415,234

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53,265.58050
Policy Entropy: 3.77749
Value Function Loss: 0.02983

Mean KL Divergence: 0.02429
SB3 Clip Fraction: 0.26344
Policy Update Magnitude: 0.38669
Value Function Update Magnitude: 0.56950

Collected Steps per Second: 19,903.67316
Overall Steps per Second: 10,045.68219

Timestep Collection Time: 2.51290
Timestep Consumption Time: 2.46595
PPO Batch Consumption Time: 0.29240
Total Iteration Time: 4.97886

Cumulative Model Updates: 112,306
Cumulative Timesteps: 936,465,250

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 936465250...
Checkpoint 936465250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,961.12243
Policy Entropy: 3.79796
Value Function Loss: 0.02632

Mean KL Divergence: 0.01673
SB3 Clip Fraction: 0.19724
Policy Update Magnitude: 0.37443
Value Function Update Magnitude: 0.37579

Collected Steps per Second: 20,018.58560
Overall Steps per Second: 9,756.92285

Timestep Collection Time: 2.49828
Timestep Consumption Time: 2.62752
PPO Batch Consumption Time: 0.30663
Total Iteration Time: 5.12580

Cumulative Model Updates: 112,312
Cumulative Timesteps: 936,515,262

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,961.12243
Policy Entropy: 3.77628
Value Function Loss: 0.04541

Mean KL Divergence: 0.01787
SB3 Clip Fraction: 0.21941
Policy Update Magnitude: 0.34688
Value Function Update Magnitude: 0.26242

Collected Steps per Second: 20,514.73270
Overall Steps per Second: 10,023.73058

Timestep Collection Time: 2.43727
Timestep Consumption Time: 2.55089
PPO Batch Consumption Time: 0.29563
Total Iteration Time: 4.98816

Cumulative Model Updates: 112,318
Cumulative Timesteps: 936,565,262

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 936565262...
Checkpoint 936565262 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,961.12243
Policy Entropy: 3.75466
Value Function Loss: 0.02412

Mean KL Divergence: 0.01209
SB3 Clip Fraction: 0.15401
Policy Update Magnitude: 0.37474
Value Function Update Magnitude: 0.28528

Collected Steps per Second: 20,927.46221
Overall Steps per Second: 10,006.87843

Timestep Collection Time: 2.38959
Timestep Consumption Time: 2.60778
PPO Batch Consumption Time: 0.30854
Total Iteration Time: 4.99736

Cumulative Model Updates: 112,324
Cumulative Timesteps: 936,615,270

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,961.12243
Policy Entropy: 3.72296
Value Function Loss: 0.02070

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.12556
Policy Update Magnitude: 0.44707
Value Function Update Magnitude: 0.36861

Collected Steps per Second: 20,627.58087
Overall Steps per Second: 9,951.24142

Timestep Collection Time: 2.42510
Timestep Consumption Time: 2.60181
PPO Batch Consumption Time: 0.30562
Total Iteration Time: 5.02691

Cumulative Model Updates: 112,330
Cumulative Timesteps: 936,665,294

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 936665294...
Checkpoint 936665294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 67,090.14933
Policy Entropy: 3.71369
Value Function Loss: 0.02248

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.12589
Policy Update Magnitude: 0.47836
Value Function Update Magnitude: 0.43118

Collected Steps per Second: 20,795.41441
Overall Steps per Second: 10,069.42085

Timestep Collection Time: 2.40447
Timestep Consumption Time: 2.56126
PPO Batch Consumption Time: 0.29496
Total Iteration Time: 4.96573

Cumulative Model Updates: 112,336
Cumulative Timesteps: 936,715,296

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,896.55911
Policy Entropy: 3.72478
Value Function Loss: 0.02011

Mean KL Divergence: 0.01501
SB3 Clip Fraction: 0.19399
Policy Update Magnitude: 0.49475
Value Function Update Magnitude: 0.54863

Collected Steps per Second: 21,121.29753
Overall Steps per Second: 10,063.20523

Timestep Collection Time: 2.36842
Timestep Consumption Time: 2.60257
PPO Batch Consumption Time: 0.29962
Total Iteration Time: 4.97098

Cumulative Model Updates: 112,342
Cumulative Timesteps: 936,765,320

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 936765320...
Checkpoint 936765320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,404.28407
Policy Entropy: 3.74371
Value Function Loss: 0.02164

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.12431
Policy Update Magnitude: 0.53721
Value Function Update Magnitude: 0.60836

Collected Steps per Second: 21,040.70669
Overall Steps per Second: 10,142.82096

Timestep Collection Time: 2.37663
Timestep Consumption Time: 2.55356
PPO Batch Consumption Time: 0.29497
Total Iteration Time: 4.93019

Cumulative Model Updates: 112,348
Cumulative Timesteps: 936,815,326

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97,204.13146
Policy Entropy: 3.74187
Value Function Loss: 0.02389

Mean KL Divergence: 0.01216
SB3 Clip Fraction: 0.15513
Policy Update Magnitude: 0.59475
Value Function Update Magnitude: 0.53422

Collected Steps per Second: 20,828.42058
Overall Steps per Second: 10,069.35128

Timestep Collection Time: 2.40191
Timestep Consumption Time: 2.56643
PPO Batch Consumption Time: 0.29414
Total Iteration Time: 4.96834

Cumulative Model Updates: 112,354
Cumulative Timesteps: 936,865,354

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 936865354...
Checkpoint 936865354 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,193,761.07185
Policy Entropy: 3.70636
Value Function Loss: 0.03916

Mean KL Divergence: 0.01536
SB3 Clip Fraction: 0.19244
Policy Update Magnitude: 0.65361
Value Function Update Magnitude: 0.62702

Collected Steps per Second: 21,019.58385
Overall Steps per Second: 10,154.63974

Timestep Collection Time: 2.37997
Timestep Consumption Time: 2.54645
PPO Batch Consumption Time: 0.29515
Total Iteration Time: 4.92642

Cumulative Model Updates: 112,360
Cumulative Timesteps: 936,915,380

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 154,923.72242
Policy Entropy: 3.71912
Value Function Loss: 0.04147

Mean KL Divergence: 0.01736
SB3 Clip Fraction: 0.20474
Policy Update Magnitude: 0.69823
Value Function Update Magnitude: 0.63940

Collected Steps per Second: 21,030.56937
Overall Steps per Second: 10,095.41112

Timestep Collection Time: 2.37844
Timestep Consumption Time: 2.57628
PPO Batch Consumption Time: 0.29496
Total Iteration Time: 4.95473

Cumulative Model Updates: 112,366
Cumulative Timesteps: 936,965,400

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 936965400...
Checkpoint 936965400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,004.31941
Policy Entropy: 3.73140
Value Function Loss: 0.04566

Mean KL Divergence: 0.01419
SB3 Clip Fraction: 0.16740
Policy Update Magnitude: 0.70961
Value Function Update Magnitude: 0.66973

Collected Steps per Second: 20,953.13824
Overall Steps per Second: 10,149.98253

Timestep Collection Time: 2.38723
Timestep Consumption Time: 2.54086
PPO Batch Consumption Time: 0.29478
Total Iteration Time: 4.92809

Cumulative Model Updates: 112,372
Cumulative Timesteps: 937,015,420

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 288,333.76730
Policy Entropy: 3.79740
Value Function Loss: 0.03974

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.09961
Policy Update Magnitude: 0.81557
Value Function Update Magnitude: 0.70268

Collected Steps per Second: 21,068.65756
Overall Steps per Second: 10,127.32082

Timestep Collection Time: 2.37338
Timestep Consumption Time: 2.56415
PPO Batch Consumption Time: 0.29475
Total Iteration Time: 4.93753

Cumulative Model Updates: 112,378
Cumulative Timesteps: 937,065,424

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 937065424...
Checkpoint 937065424 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,043.99152
Policy Entropy: 3.81480
Value Function Loss: 0.03841

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.11079
Policy Update Magnitude: 0.93742
Value Function Update Magnitude: 0.72624

Collected Steps per Second: 21,018.22168
Overall Steps per Second: 10,158.05144

Timestep Collection Time: 2.37936
Timestep Consumption Time: 2.54382
PPO Batch Consumption Time: 0.29481
Total Iteration Time: 4.92319

Cumulative Model Updates: 112,384
Cumulative Timesteps: 937,115,434

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 989.55962
Policy Entropy: 3.81054
Value Function Loss: 0.02989

Mean KL Divergence: 0.01467
SB3 Clip Fraction: 0.19409
Policy Update Magnitude: 0.76599
Value Function Update Magnitude: 0.61649

Collected Steps per Second: 21,036.18969
Overall Steps per Second: 10,102.27911

Timestep Collection Time: 2.37686
Timestep Consumption Time: 2.57252
PPO Batch Consumption Time: 0.29493
Total Iteration Time: 4.94938

Cumulative Model Updates: 112,390
Cumulative Timesteps: 937,165,434

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 937165434...
Checkpoint 937165434 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 225.27706
Policy Entropy: 3.79024
Value Function Loss: 0.02610

Mean KL Divergence: 0.01083
SB3 Clip Fraction: 0.14699
Policy Update Magnitude: 0.61867
Value Function Update Magnitude: 0.64235

Collected Steps per Second: 20,762.06070
Overall Steps per Second: 9,816.43479

Timestep Collection Time: 2.40891
Timestep Consumption Time: 2.68601
PPO Batch Consumption Time: 0.31523
Total Iteration Time: 5.09493

Cumulative Model Updates: 112,396
Cumulative Timesteps: 937,215,448

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,676.26442
Policy Entropy: 3.71392
Value Function Loss: 0.02885

Mean KL Divergence: 0.03079
SB3 Clip Fraction: 0.31287
Policy Update Magnitude: 0.51717
Value Function Update Magnitude: 0.68519

Collected Steps per Second: 20,533.73256
Overall Steps per Second: 10,018.48224

Timestep Collection Time: 2.43619
Timestep Consumption Time: 2.55699
PPO Batch Consumption Time: 0.29438
Total Iteration Time: 4.99317

Cumulative Model Updates: 112,402
Cumulative Timesteps: 937,265,472

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 937265472...
Checkpoint 937265472 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,978.39701
Policy Entropy: 3.72803
Value Function Loss: 0.02860

Mean KL Divergence: 0.02453
SB3 Clip Fraction: 0.28288
Policy Update Magnitude: 0.45510
Value Function Update Magnitude: 0.64593

Collected Steps per Second: 20,886.98737
Overall Steps per Second: 10,127.44358

Timestep Collection Time: 2.39431
Timestep Consumption Time: 2.54375
PPO Batch Consumption Time: 0.29417
Total Iteration Time: 4.93807

Cumulative Model Updates: 112,408
Cumulative Timesteps: 937,315,482

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 426,766.71774
Policy Entropy: 3.71810
Value Function Loss: 0.02629

Mean KL Divergence: 0.02267
SB3 Clip Fraction: 0.26475
Policy Update Magnitude: 0.37147
Value Function Update Magnitude: 0.61085

Collected Steps per Second: 21,059.56544
Overall Steps per Second: 10,116.18623

Timestep Collection Time: 2.37431
Timestep Consumption Time: 2.56846
PPO Batch Consumption Time: 0.29615
Total Iteration Time: 4.94277

Cumulative Model Updates: 112,414
Cumulative Timesteps: 937,365,484

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 937365484...
Checkpoint 937365484 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 226,812.33047
Policy Entropy: 3.72044
Value Function Loss: 0.02962

Mean KL Divergence: 0.01914
SB3 Clip Fraction: 0.24499
Policy Update Magnitude: 0.33877
Value Function Update Magnitude: 0.62691

Collected Steps per Second: 20,715.62160
Overall Steps per Second: 9,980.78708

Timestep Collection Time: 2.41460
Timestep Consumption Time: 2.59703
PPO Batch Consumption Time: 0.30259
Total Iteration Time: 5.01163

Cumulative Model Updates: 112,420
Cumulative Timesteps: 937,415,504

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70,719.91528
Policy Entropy: 3.71201
Value Function Loss: 0.03653

Mean KL Divergence: 0.01749
SB3 Clip Fraction: 0.22829
Policy Update Magnitude: 0.37446
Value Function Update Magnitude: 0.60885

Collected Steps per Second: 20,918.69825
Overall Steps per Second: 10,022.81811

Timestep Collection Time: 2.39145
Timestep Consumption Time: 2.59976
PPO Batch Consumption Time: 0.30466
Total Iteration Time: 4.99121

Cumulative Model Updates: 112,426
Cumulative Timesteps: 937,465,530

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 937465530...
Checkpoint 937465530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 173,776.23963
Policy Entropy: 3.71355
Value Function Loss: 0.04255

Mean KL Divergence: 0.01769
SB3 Clip Fraction: 0.21515
Policy Update Magnitude: 0.43462
Value Function Update Magnitude: 0.62237

Collected Steps per Second: 20,830.70301
Overall Steps per Second: 10,106.88340

Timestep Collection Time: 2.40069
Timestep Consumption Time: 2.54723
PPO Batch Consumption Time: 0.29595
Total Iteration Time: 4.94791

Cumulative Model Updates: 112,432
Cumulative Timesteps: 937,515,538

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 201,779.02468
Policy Entropy: 3.74016
Value Function Loss: 0.04465

Mean KL Divergence: 0.01669
SB3 Clip Fraction: 0.20772
Policy Update Magnitude: 0.45293
Value Function Update Magnitude: 0.68919

Collected Steps per Second: 20,167.97290
Overall Steps per Second: 10,011.24449

Timestep Collection Time: 2.48027
Timestep Consumption Time: 2.51631
PPO Batch Consumption Time: 0.29687
Total Iteration Time: 4.99658

Cumulative Model Updates: 112,438
Cumulative Timesteps: 937,565,560

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 937565560...
Checkpoint 937565560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,169.81720
Policy Entropy: 3.74917
Value Function Loss: 0.04756

Mean KL Divergence: 0.01626
SB3 Clip Fraction: 0.20201
Policy Update Magnitude: 0.49029
Value Function Update Magnitude: 0.66756

Collected Steps per Second: 20,114.35194
Overall Steps per Second: 10,083.63879

Timestep Collection Time: 2.48778
Timestep Consumption Time: 2.47472
PPO Batch Consumption Time: 0.29564
Total Iteration Time: 4.96249

Cumulative Model Updates: 112,444
Cumulative Timesteps: 937,615,600

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,922.90356
Policy Entropy: 3.74450
Value Function Loss: 0.06114

Mean KL Divergence: 0.01508
SB3 Clip Fraction: 0.18989
Policy Update Magnitude: 0.50179
Value Function Update Magnitude: 0.59754

Collected Steps per Second: 20,490.03441
Overall Steps per Second: 10,124.35134

Timestep Collection Time: 2.44089
Timestep Consumption Time: 2.49908
PPO Batch Consumption Time: 0.29620
Total Iteration Time: 4.93997

Cumulative Model Updates: 112,450
Cumulative Timesteps: 937,665,614

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 937665614...
Checkpoint 937665614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 163,673.08536
Policy Entropy: 3.75482
Value Function Loss: 0.06505

Mean KL Divergence: 0.01425
SB3 Clip Fraction: 0.17860
Policy Update Magnitude: 0.54662
Value Function Update Magnitude: 0.60823

Collected Steps per Second: 20,294.58807
Overall Steps per Second: 10,158.68063

Timestep Collection Time: 2.46411
Timestep Consumption Time: 2.45858
PPO Batch Consumption Time: 0.29427
Total Iteration Time: 4.92269

Cumulative Model Updates: 112,456
Cumulative Timesteps: 937,715,622

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,882.65081
Policy Entropy: 3.75318
Value Function Loss: 0.07120

Mean KL Divergence: 0.01308
SB3 Clip Fraction: 0.16098
Policy Update Magnitude: 0.58331
Value Function Update Magnitude: 0.56061

Collected Steps per Second: 20,332.82253
Overall Steps per Second: 10,121.34239

Timestep Collection Time: 2.46006
Timestep Consumption Time: 2.48197
PPO Batch Consumption Time: 0.29474
Total Iteration Time: 4.94203

Cumulative Model Updates: 112,462
Cumulative Timesteps: 937,765,642

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 937765642...
Checkpoint 937765642 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,038.02628
Policy Entropy: 3.75614
Value Function Loss: 0.06319

Mean KL Divergence: 0.01391
SB3 Clip Fraction: 0.16994
Policy Update Magnitude: 0.58708
Value Function Update Magnitude: 0.50066

Collected Steps per Second: 20,141.46454
Overall Steps per Second: 10,116.63535

Timestep Collection Time: 2.48373
Timestep Consumption Time: 2.46119
PPO Batch Consumption Time: 0.29398
Total Iteration Time: 4.94492

Cumulative Model Updates: 112,468
Cumulative Timesteps: 937,815,668

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 116,827.38336
Policy Entropy: 3.77818
Value Function Loss: 0.05574

Mean KL Divergence: 0.01308
SB3 Clip Fraction: 0.15923
Policy Update Magnitude: 0.61321
Value Function Update Magnitude: 0.67387

Collected Steps per Second: 19,925.99236
Overall Steps per Second: 9,971.32566

Timestep Collection Time: 2.50969
Timestep Consumption Time: 2.50549
PPO Batch Consumption Time: 0.30239
Total Iteration Time: 5.01518

Cumulative Model Updates: 112,474
Cumulative Timesteps: 937,865,676

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 937865676...
Checkpoint 937865676 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,604.83356
Policy Entropy: 3.80515
Value Function Loss: 0.05146

Mean KL Divergence: 0.01265
SB3 Clip Fraction: 0.15793
Policy Update Magnitude: 0.62483
Value Function Update Magnitude: 0.96565

Collected Steps per Second: 19,754.26987
Overall Steps per Second: 10,002.10356

Timestep Collection Time: 2.53120
Timestep Consumption Time: 2.46795
PPO Batch Consumption Time: 0.29301
Total Iteration Time: 4.99915

Cumulative Model Updates: 112,480
Cumulative Timesteps: 937,915,678

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 984.64896
Policy Entropy: 3.84226
Value Function Loss: 0.04944

Mean KL Divergence: 0.01170
SB3 Clip Fraction: 0.14120
Policy Update Magnitude: 0.65820
Value Function Update Magnitude: 1.02890

Collected Steps per Second: 20,238.63325
Overall Steps per Second: 10,021.90654

Timestep Collection Time: 2.47072
Timestep Consumption Time: 2.51875
PPO Batch Consumption Time: 0.30143
Total Iteration Time: 4.98947

Cumulative Model Updates: 112,486
Cumulative Timesteps: 937,965,682

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 937965682...
Checkpoint 937965682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,354.69872
Policy Entropy: 3.84848
Value Function Loss: 0.05346

Mean KL Divergence: 0.01172
SB3 Clip Fraction: 0.13977
Policy Update Magnitude: 0.68638
Value Function Update Magnitude: 0.82605

Collected Steps per Second: 19,513.24734
Overall Steps per Second: 9,793.55819

Timestep Collection Time: 2.56277
Timestep Consumption Time: 2.54344
PPO Batch Consumption Time: 0.30710
Total Iteration Time: 5.10621

Cumulative Model Updates: 112,492
Cumulative Timesteps: 938,015,690

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 247.11116
Policy Entropy: 3.88419
Value Function Loss: 0.05221

Mean KL Divergence: 0.01177
SB3 Clip Fraction: 0.13572
Policy Update Magnitude: 0.74335
Value Function Update Magnitude: 0.75520

Collected Steps per Second: 20,846.65591
Overall Steps per Second: 10,045.83273

Timestep Collection Time: 2.39991
Timestep Consumption Time: 2.58027
PPO Batch Consumption Time: 0.29858
Total Iteration Time: 4.98017

Cumulative Model Updates: 112,498
Cumulative Timesteps: 938,065,720

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 938065720...
Checkpoint 938065720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,050.31048
Policy Entropy: 3.92781
Value Function Loss: 0.04716

Mean KL Divergence: 0.01055
SB3 Clip Fraction: 0.12572
Policy Update Magnitude: 0.78948
Value Function Update Magnitude: 0.79420

Collected Steps per Second: 20,821.14981
Overall Steps per Second: 10,105.28800

Timestep Collection Time: 2.40198
Timestep Consumption Time: 2.54711
PPO Batch Consumption Time: 0.29507
Total Iteration Time: 4.94909

Cumulative Model Updates: 112,504
Cumulative Timesteps: 938,115,732

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 993.64080
Policy Entropy: 3.95081
Value Function Loss: 0.04169

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.12495
Policy Update Magnitude: 0.81418
Value Function Update Magnitude: 0.78595

Collected Steps per Second: 20,874.49691
Overall Steps per Second: 10,073.33284

Timestep Collection Time: 2.39699
Timestep Consumption Time: 2.57018
PPO Batch Consumption Time: 0.29603
Total Iteration Time: 4.96717

Cumulative Model Updates: 112,510
Cumulative Timesteps: 938,165,768

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 938165768...
Checkpoint 938165768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 106.22704
Policy Entropy: 3.94733
Value Function Loss: 0.04112

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.12137
Policy Update Magnitude: 0.85589
Value Function Update Magnitude: 0.72982

Collected Steps per Second: 20,577.66956
Overall Steps per Second: 9,885.39631

Timestep Collection Time: 2.43108
Timestep Consumption Time: 2.62951
PPO Batch Consumption Time: 0.30880
Total Iteration Time: 5.06060

Cumulative Model Updates: 112,516
Cumulative Timesteps: 938,215,794

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,359.44100
Policy Entropy: 3.93965
Value Function Loss: 0.04087

Mean KL Divergence: 0.01115
SB3 Clip Fraction: 0.13368
Policy Update Magnitude: 0.86886
Value Function Update Magnitude: 0.71477

Collected Steps per Second: 20,528.10184
Overall Steps per Second: 10,008.63405

Timestep Collection Time: 2.43569
Timestep Consumption Time: 2.56000
PPO Batch Consumption Time: 0.29451
Total Iteration Time: 4.99569

Cumulative Model Updates: 112,522
Cumulative Timesteps: 938,265,794

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 938265794...
Checkpoint 938265794 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,078.50064
Policy Entropy: 3.96626
Value Function Loss: 0.03723

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.12218
Policy Update Magnitude: 0.93041
Value Function Update Magnitude: 0.82266

Collected Steps per Second: 20,914.00430
Overall Steps per Second: 10,181.09524

Timestep Collection Time: 2.39122
Timestep Consumption Time: 2.52082
PPO Batch Consumption Time: 0.29409
Total Iteration Time: 4.91205

Cumulative Model Updates: 112,528
Cumulative Timesteps: 938,315,804

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,166.24690
Policy Entropy: 4.01880
Value Function Loss: 0.02907

Mean KL Divergence: 0.00743
SB3 Clip Fraction: 0.08907
Policy Update Magnitude: 1.02097
Value Function Update Magnitude: 0.98633

Collected Steps per Second: 20,903.58835
Overall Steps per Second: 10,075.08459

Timestep Collection Time: 2.39203
Timestep Consumption Time: 2.57091
PPO Batch Consumption Time: 0.30016
Total Iteration Time: 4.96294

Cumulative Model Updates: 112,534
Cumulative Timesteps: 938,365,806

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 938365806...
Checkpoint 938365806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 328.99904
Policy Entropy: 4.08346
Value Function Loss: 0.02625

Mean KL Divergence: 0.00678
SB3 Clip Fraction: 0.08066
Policy Update Magnitude: 1.08640
Value Function Update Magnitude: 1.03423

Collected Steps per Second: 20,872.19916
Overall Steps per Second: 10,227.22957

Timestep Collection Time: 2.39601
Timestep Consumption Time: 2.49388
PPO Batch Consumption Time: 0.29761
Total Iteration Time: 4.88989

Cumulative Model Updates: 112,540
Cumulative Timesteps: 938,415,816

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43.78185
Policy Entropy: 4.08895
Value Function Loss: 0.02910

Mean KL Divergence: 0.00694
SB3 Clip Fraction: 0.08144
Policy Update Magnitude: 1.06418
Value Function Update Magnitude: 0.95052

Collected Steps per Second: 20,906.94603
Overall Steps per Second: 9,911.83356

Timestep Collection Time: 2.39174
Timestep Consumption Time: 2.65314
PPO Batch Consumption Time: 0.31067
Total Iteration Time: 5.04488

Cumulative Model Updates: 112,546
Cumulative Timesteps: 938,465,820

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 938465820...
Checkpoint 938465820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,152.38679
Policy Entropy: 4.01346
Value Function Loss: 0.03556

Mean KL Divergence: 0.00538
SB3 Clip Fraction: 0.06189
Policy Update Magnitude: 1.02065
Value Function Update Magnitude: 0.84848

Collected Steps per Second: 20,861.79932
Overall Steps per Second: 10,029.54651

Timestep Collection Time: 2.39701
Timestep Consumption Time: 2.58886
PPO Batch Consumption Time: 0.30464
Total Iteration Time: 4.98587

Cumulative Model Updates: 112,552
Cumulative Timesteps: 938,515,826

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,377.20546
Policy Entropy: 3.92777
Value Function Loss: 0.03874

Mean KL Divergence: 0.00618
SB3 Clip Fraction: 0.07352
Policy Update Magnitude: 0.96952
Value Function Update Magnitude: 0.68737

Collected Steps per Second: 20,756.96373
Overall Steps per Second: 9,924.20710

Timestep Collection Time: 2.40893
Timestep Consumption Time: 2.62946
PPO Batch Consumption Time: 0.30725
Total Iteration Time: 5.03839

Cumulative Model Updates: 112,558
Cumulative Timesteps: 938,565,828

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 938565828...
Checkpoint 938565828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,907.29492
Policy Entropy: 3.88331
Value Function Loss: 0.03836

Mean KL Divergence: 0.00707
SB3 Clip Fraction: 0.08968
Policy Update Magnitude: 0.89729
Value Function Update Magnitude: 0.62783

Collected Steps per Second: 20,941.67454
Overall Steps per Second: 10,130.95139

Timestep Collection Time: 2.38863
Timestep Consumption Time: 2.54891
PPO Batch Consumption Time: 0.29322
Total Iteration Time: 4.93754

Cumulative Model Updates: 112,564
Cumulative Timesteps: 938,615,850

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 527.23911
Policy Entropy: 3.89074
Value Function Loss: 0.03403

Mean KL Divergence: 0.02322
SB3 Clip Fraction: 0.25954
Policy Update Magnitude: 0.69349
Value Function Update Magnitude: 0.53395

Collected Steps per Second: 21,203.63633
Overall Steps per Second: 10,137.34269

Timestep Collection Time: 2.35931
Timestep Consumption Time: 2.57551
PPO Batch Consumption Time: 0.29908
Total Iteration Time: 4.93482

Cumulative Model Updates: 112,570
Cumulative Timesteps: 938,665,876

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 938665876...
Checkpoint 938665876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,833.29358
Policy Entropy: 3.87142
Value Function Loss: 0.03840

Mean KL Divergence: 0.01287
SB3 Clip Fraction: 0.15766
Policy Update Magnitude: 0.50637
Value Function Update Magnitude: 0.55154

Collected Steps per Second: 20,149.53227
Overall Steps per Second: 10,117.03871

Timestep Collection Time: 2.48234
Timestep Consumption Time: 2.46160
PPO Batch Consumption Time: 0.29365
Total Iteration Time: 4.94394

Cumulative Model Updates: 112,576
Cumulative Timesteps: 938,715,894

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 107.41555
Policy Entropy: 3.87636
Value Function Loss: 0.03753

Mean KL Divergence: 0.01622
SB3 Clip Fraction: 0.18813
Policy Update Magnitude: 0.53659
Value Function Update Magnitude: 0.63235

Collected Steps per Second: 20,863.79550
Overall Steps per Second: 10,068.68054

Timestep Collection Time: 2.39765
Timestep Consumption Time: 2.57063
PPO Batch Consumption Time: 0.29563
Total Iteration Time: 4.96828

Cumulative Model Updates: 112,582
Cumulative Timesteps: 938,765,918

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 938765918...
Checkpoint 938765918 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,573.84311
Policy Entropy: 3.87195
Value Function Loss: 0.03769

Mean KL Divergence: 0.01433
SB3 Clip Fraction: 0.17624
Policy Update Magnitude: 0.62221
Value Function Update Magnitude: 0.75851

Collected Steps per Second: 20,971.99133
Overall Steps per Second: 10,101.68910

Timestep Collection Time: 2.38470
Timestep Consumption Time: 2.56615
PPO Batch Consumption Time: 0.29534
Total Iteration Time: 4.95086

Cumulative Model Updates: 112,588
Cumulative Timesteps: 938,815,930

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,033.20916
Policy Entropy: 3.88596
Value Function Loss: 0.03473

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.10703
Policy Update Magnitude: 0.69318
Value Function Update Magnitude: 0.70313

Collected Steps per Second: 20,174.87094
Overall Steps per Second: 10,131.85495

Timestep Collection Time: 2.47833
Timestep Consumption Time: 2.45660
PPO Batch Consumption Time: 0.29272
Total Iteration Time: 4.93493

Cumulative Model Updates: 112,594
Cumulative Timesteps: 938,865,930

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 938865930...
Checkpoint 938865930 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 90.86376
Policy Entropy: 3.87463
Value Function Loss: 0.03381

Mean KL Divergence: 0.01398
SB3 Clip Fraction: 0.17934
Policy Update Magnitude: 0.64920
Value Function Update Magnitude: 0.67391

Collected Steps per Second: 20,333.96392
Overall Steps per Second: 10,137.96508

Timestep Collection Time: 2.46042
Timestep Consumption Time: 2.47450
PPO Batch Consumption Time: 0.29598
Total Iteration Time: 4.93492

Cumulative Model Updates: 112,600
Cumulative Timesteps: 938,915,960

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18.48427
Policy Entropy: 3.83515
Value Function Loss: 0.03698

Mean KL Divergence: 0.01740
SB3 Clip Fraction: 0.20620
Policy Update Magnitude: 0.56544
Value Function Update Magnitude: 0.71475

Collected Steps per Second: 20,313.76872
Overall Steps per Second: 10,086.44757

Timestep Collection Time: 2.46188
Timestep Consumption Time: 2.49626
PPO Batch Consumption Time: 0.29569
Total Iteration Time: 4.95814

Cumulative Model Updates: 112,606
Cumulative Timesteps: 938,965,970

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 938965970...
Checkpoint 938965970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,569.20177
Policy Entropy: 3.84633
Value Function Loss: 0.05189

Mean KL Divergence: 0.02306
SB3 Clip Fraction: 0.23129
Policy Update Magnitude: 0.49349
Value Function Update Magnitude: 0.72259

Collected Steps per Second: 20,971.86031
Overall Steps per Second: 10,147.50902

Timestep Collection Time: 2.38443
Timestep Consumption Time: 2.54348
PPO Batch Consumption Time: 0.29558
Total Iteration Time: 4.92791

Cumulative Model Updates: 112,612
Cumulative Timesteps: 939,015,976

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 101.38070
Policy Entropy: 3.87592
Value Function Loss: 0.06319

Mean KL Divergence: 0.01766
SB3 Clip Fraction: 0.17907
Policy Update Magnitude: 0.59874
Value Function Update Magnitude: 0.64597

Collected Steps per Second: 21,364.99835
Overall Steps per Second: 10,192.98601

Timestep Collection Time: 2.34084
Timestep Consumption Time: 2.56567
PPO Batch Consumption Time: 0.29353
Total Iteration Time: 4.90651

Cumulative Model Updates: 112,618
Cumulative Timesteps: 939,065,988

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 939065988...
Checkpoint 939065988 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,138.61190
Policy Entropy: 3.91083
Value Function Loss: 0.06214

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.12525
Policy Update Magnitude: 0.74530
Value Function Update Magnitude: 0.59310

Collected Steps per Second: 20,587.49692
Overall Steps per Second: 9,947.68456

Timestep Collection Time: 2.42944
Timestep Consumption Time: 2.59847
PPO Batch Consumption Time: 0.30449
Total Iteration Time: 5.02790

Cumulative Model Updates: 112,624
Cumulative Timesteps: 939,116,004

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,443.84687
Policy Entropy: 3.90394
Value Function Loss: 0.05635

Mean KL Divergence: 0.01101
SB3 Clip Fraction: 0.13569
Policy Update Magnitude: 0.84617
Value Function Update Magnitude: 0.56316

Collected Steps per Second: 20,837.27734
Overall Steps per Second: 9,936.52155

Timestep Collection Time: 2.40079
Timestep Consumption Time: 2.63377
PPO Batch Consumption Time: 0.30585
Total Iteration Time: 5.03456

Cumulative Model Updates: 112,630
Cumulative Timesteps: 939,166,030

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 939166030...
Checkpoint 939166030 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,627.81474
Policy Entropy: 3.87308
Value Function Loss: 0.04866

Mean KL Divergence: 0.01205
SB3 Clip Fraction: 0.14660
Policy Update Magnitude: 0.79600
Value Function Update Magnitude: 0.57836

Collected Steps per Second: 20,809.69210
Overall Steps per Second: 10,084.09923

Timestep Collection Time: 2.40311
Timestep Consumption Time: 2.55598
PPO Batch Consumption Time: 0.29452
Total Iteration Time: 4.95909

Cumulative Model Updates: 112,636
Cumulative Timesteps: 939,216,038

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 107.35601
Policy Entropy: 3.84969
Value Function Loss: 0.04328

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.11857
Policy Update Magnitude: 0.70812
Value Function Update Magnitude: 0.67287

Collected Steps per Second: 21,030.90732
Overall Steps per Second: 10,091.32284

Timestep Collection Time: 2.37745
Timestep Consumption Time: 2.57730
PPO Batch Consumption Time: 0.29772
Total Iteration Time: 4.95475

Cumulative Model Updates: 112,642
Cumulative Timesteps: 939,266,038

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 939266038...
Checkpoint 939266038 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 153.32868
Policy Entropy: 3.83212
Value Function Loss: 0.04055

Mean KL Divergence: 0.01143
SB3 Clip Fraction: 0.15114
Policy Update Magnitude: 0.63059
Value Function Update Magnitude: 0.59568

Collected Steps per Second: 20,742.52102
Overall Steps per Second: 10,096.29033

Timestep Collection Time: 2.41060
Timestep Consumption Time: 2.54191
PPO Batch Consumption Time: 0.29441
Total Iteration Time: 4.95251

Cumulative Model Updates: 112,648
Cumulative Timesteps: 939,316,040

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,807.74451
Policy Entropy: 3.81029
Value Function Loss: 0.03968

Mean KL Divergence: 0.01243
SB3 Clip Fraction: 0.15717
Policy Update Magnitude: 0.62425
Value Function Update Magnitude: 0.58604

Collected Steps per Second: 20,964.93446
Overall Steps per Second: 10,080.83820

Timestep Collection Time: 2.38551
Timestep Consumption Time: 2.57559
PPO Batch Consumption Time: 0.29492
Total Iteration Time: 4.96110

Cumulative Model Updates: 112,654
Cumulative Timesteps: 939,366,052

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 939366052...
Checkpoint 939366052 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 873.34035
Policy Entropy: 3.82525
Value Function Loss: 0.03392

Mean KL Divergence: 0.01092
SB3 Clip Fraction: 0.14747
Policy Update Magnitude: 0.52591
Value Function Update Magnitude: 0.55017

Collected Steps per Second: 20,789.38564
Overall Steps per Second: 9,944.59214

Timestep Collection Time: 2.40584
Timestep Consumption Time: 2.62362
PPO Batch Consumption Time: 0.30691
Total Iteration Time: 5.02947

Cumulative Model Updates: 112,660
Cumulative Timesteps: 939,416,068

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,555.24963
Policy Entropy: 3.80155
Value Function Loss: 0.03202

Mean KL Divergence: 0.01198
SB3 Clip Fraction: 0.16038
Policy Update Magnitude: 0.43819
Value Function Update Magnitude: 0.47191

Collected Steps per Second: 21,037.94692
Overall Steps per Second: 9,995.24219

Timestep Collection Time: 2.37742
Timestep Consumption Time: 2.62656
PPO Batch Consumption Time: 0.30643
Total Iteration Time: 5.00398

Cumulative Model Updates: 112,666
Cumulative Timesteps: 939,466,084

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 939466084...
Checkpoint 939466084 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,628.85099
Policy Entropy: 3.78883
Value Function Loss: 0.02997

Mean KL Divergence: 0.01113
SB3 Clip Fraction: 0.14995
Policy Update Magnitude: 0.42808
Value Function Update Magnitude: 0.45413

Collected Steps per Second: 20,109.43115
Overall Steps per Second: 10,071.66975

Timestep Collection Time: 2.48650
Timestep Consumption Time: 2.47812
PPO Batch Consumption Time: 0.29442
Total Iteration Time: 4.96462

Cumulative Model Updates: 112,672
Cumulative Timesteps: 939,516,086

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,553.38962
Policy Entropy: 3.76962
Value Function Loss: 0.03063

Mean KL Divergence: 0.01093
SB3 Clip Fraction: 0.15260
Policy Update Magnitude: 0.39245
Value Function Update Magnitude: 0.51288

Collected Steps per Second: 20,327.05343
Overall Steps per Second: 10,112.51150

Timestep Collection Time: 2.46076
Timestep Consumption Time: 2.48559
PPO Batch Consumption Time: 0.29423
Total Iteration Time: 4.94635

Cumulative Model Updates: 112,678
Cumulative Timesteps: 939,566,106

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 939566106...
Checkpoint 939566106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,549.19229
Policy Entropy: 3.77769
Value Function Loss: 0.02799

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.14245
Policy Update Magnitude: 0.37821
Value Function Update Magnitude: 0.53653

Collected Steps per Second: 20,423.02600
Overall Steps per Second: 10,159.61869

Timestep Collection Time: 2.44949
Timestep Consumption Time: 2.47451
PPO Batch Consumption Time: 0.29335
Total Iteration Time: 4.92400

Cumulative Model Updates: 112,684
Cumulative Timesteps: 939,616,132

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,143.17592
Policy Entropy: 3.76249
Value Function Loss: 0.02783

Mean KL Divergence: 0.01138
SB3 Clip Fraction: 0.15444
Policy Update Magnitude: 0.36590
Value Function Update Magnitude: 0.56960

Collected Steps per Second: 20,512.54287
Overall Steps per Second: 10,036.94939

Timestep Collection Time: 2.43812
Timestep Consumption Time: 2.54467
PPO Batch Consumption Time: 0.29480
Total Iteration Time: 4.98279

Cumulative Model Updates: 112,690
Cumulative Timesteps: 939,666,144

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 939666144...
Checkpoint 939666144 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,518.48730
Policy Entropy: 3.77355
Value Function Loss: 0.02595

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.13386
Policy Update Magnitude: 0.40077
Value Function Update Magnitude: 0.54876

Collected Steps per Second: 20,750.20343
Overall Steps per Second: 9,860.73559

Timestep Collection Time: 2.41106
Timestep Consumption Time: 2.66260
PPO Batch Consumption Time: 0.31844
Total Iteration Time: 5.07366

Cumulative Model Updates: 112,696
Cumulative Timesteps: 939,716,174

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,244.28190
Policy Entropy: 3.75391
Value Function Loss: 0.02387

Mean KL Divergence: 0.01066
SB3 Clip Fraction: 0.14688
Policy Update Magnitude: 0.40954
Value Function Update Magnitude: 0.63004

Collected Steps per Second: 21,282.74470
Overall Steps per Second: 10,131.68291

Timestep Collection Time: 2.35017
Timestep Consumption Time: 2.58662
PPO Batch Consumption Time: 0.30489
Total Iteration Time: 4.93679

Cumulative Model Updates: 112,702
Cumulative Timesteps: 939,766,192

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 939766192...
Checkpoint 939766192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,019.72466
Policy Entropy: 3.75590
Value Function Loss: 0.02351

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.12986
Policy Update Magnitude: 0.39265
Value Function Update Magnitude: 0.74860

Collected Steps per Second: 20,711.07843
Overall Steps per Second: 10,105.74478

Timestep Collection Time: 2.41475
Timestep Consumption Time: 2.53412
PPO Batch Consumption Time: 0.29543
Total Iteration Time: 4.94887

Cumulative Model Updates: 112,708
Cumulative Timesteps: 939,816,204

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,604.97851
Policy Entropy: 3.73428
Value Function Loss: 0.02240

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.15055
Policy Update Magnitude: 0.35612
Value Function Update Magnitude: 0.71080

Collected Steps per Second: 21,243.05418
Overall Steps per Second: 10,087.78104

Timestep Collection Time: 2.35465
Timestep Consumption Time: 2.60382
PPO Batch Consumption Time: 0.30083
Total Iteration Time: 4.95847

Cumulative Model Updates: 112,714
Cumulative Timesteps: 939,866,224

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 939866224...
Checkpoint 939866224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,604.97851
Policy Entropy: 3.73077
Value Function Loss: 0.02107

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.14480
Policy Update Magnitude: 0.32043
Value Function Update Magnitude: 0.55665

Collected Steps per Second: 20,558.73295
Overall Steps per Second: 9,861.95763

Timestep Collection Time: 2.43313
Timestep Consumption Time: 2.63909
PPO Batch Consumption Time: 0.30657
Total Iteration Time: 5.07222

Cumulative Model Updates: 112,720
Cumulative Timesteps: 939,916,246

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,604.97851
Policy Entropy: 3.71985
Value Function Loss: 0.01998

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.14947
Policy Update Magnitude: 0.30859
Value Function Update Magnitude: 0.44185

Collected Steps per Second: 20,873.87407
Overall Steps per Second: 9,977.75184

Timestep Collection Time: 2.39620
Timestep Consumption Time: 2.61675
PPO Batch Consumption Time: 0.30120
Total Iteration Time: 5.01295

Cumulative Model Updates: 112,726
Cumulative Timesteps: 939,966,264

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 939966264...
Checkpoint 939966264 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 81,286.79706
Policy Entropy: 3.71139
Value Function Loss: 0.02028

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.14412
Policy Update Magnitude: 0.32978
Value Function Update Magnitude: 0.44550

Collected Steps per Second: 20,744.91685
Overall Steps per Second: 9,986.63870

Timestep Collection Time: 2.41139
Timestep Consumption Time: 2.59771
PPO Batch Consumption Time: 0.30209
Total Iteration Time: 5.00909

Cumulative Model Updates: 112,732
Cumulative Timesteps: 940,016,288

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50,387.88148
Policy Entropy: 3.71114
Value Function Loss: 0.02124

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.13943
Policy Update Magnitude: 0.37467
Value Function Update Magnitude: 0.52367

Collected Steps per Second: 21,291.60984
Overall Steps per Second: 10,159.37958

Timestep Collection Time: 2.34928
Timestep Consumption Time: 2.57425
PPO Batch Consumption Time: 0.29475
Total Iteration Time: 4.92353

Cumulative Model Updates: 112,738
Cumulative Timesteps: 940,066,308

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 940066308...
Checkpoint 940066308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 50,387.88148
Policy Entropy: 3.72011
Value Function Loss: 0.02137

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.13617
Policy Update Magnitude: 0.38454
Value Function Update Magnitude: 0.59327

Collected Steps per Second: 20,890.42491
Overall Steps per Second: 10,012.76766

Timestep Collection Time: 2.39363
Timestep Consumption Time: 2.60039
PPO Batch Consumption Time: 0.30511
Total Iteration Time: 4.99402

Cumulative Model Updates: 112,744
Cumulative Timesteps: 940,116,312

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50,387.88148
Policy Entropy: 3.71705
Value Function Loss: 0.01969

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.14514
Policy Update Magnitude: 0.38721
Value Function Update Magnitude: 0.62693

Collected Steps per Second: 20,335.58142
Overall Steps per Second: 10,024.57249

Timestep Collection Time: 2.45904
Timestep Consumption Time: 2.52930
PPO Batch Consumption Time: 0.30467
Total Iteration Time: 4.98834

Cumulative Model Updates: 112,750
Cumulative Timesteps: 940,166,318

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 940166318...
Checkpoint 940166318 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 50,387.88148
Policy Entropy: 3.70942
Value Function Loss: 0.01776

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.13859
Policy Update Magnitude: 0.36103
Value Function Update Magnitude: 0.57364

Collected Steps per Second: 20,149.50611
Overall Steps per Second: 10,077.35031

Timestep Collection Time: 2.48145
Timestep Consumption Time: 2.48017
PPO Batch Consumption Time: 0.29561
Total Iteration Time: 4.96162

Cumulative Model Updates: 112,756
Cumulative Timesteps: 940,216,318

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50,387.88148
Policy Entropy: 3.69717
Value Function Loss: 0.01872

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.14163
Policy Update Magnitude: 0.34260
Value Function Update Magnitude: 0.45998

Collected Steps per Second: 20,086.20675
Overall Steps per Second: 9,846.37633

Timestep Collection Time: 2.48997
Timestep Consumption Time: 2.58946
PPO Batch Consumption Time: 0.30238
Total Iteration Time: 5.07943

Cumulative Model Updates: 112,762
Cumulative Timesteps: 940,266,332

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 940266332...
Checkpoint 940266332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 50,387.88148
Policy Entropy: 3.70051
Value Function Loss: 0.01959

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.13734
Policy Update Magnitude: 0.34992
Value Function Update Magnitude: 0.39966

Collected Steps per Second: 20,529.89777
Overall Steps per Second: 10,074.52404

Timestep Collection Time: 2.43635
Timestep Consumption Time: 2.52845
PPO Batch Consumption Time: 0.29313
Total Iteration Time: 4.96480

Cumulative Model Updates: 112,768
Cumulative Timesteps: 940,316,350

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50,387.88148
Policy Entropy: 3.71285
Value Function Loss: 0.02046

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.14056
Policy Update Magnitude: 0.35596
Value Function Update Magnitude: 0.36780

Collected Steps per Second: 20,798.29150
Overall Steps per Second: 9,998.80467

Timestep Collection Time: 2.40510
Timestep Consumption Time: 2.59770
PPO Batch Consumption Time: 0.30382
Total Iteration Time: 5.00280

Cumulative Model Updates: 112,774
Cumulative Timesteps: 940,366,372

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 940366372...
Checkpoint 940366372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 135,269.21450
Policy Entropy: 3.72076
Value Function Loss: 0.02146

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.14513
Policy Update Magnitude: 0.35179
Value Function Update Magnitude: 0.31769

Collected Steps per Second: 20,743.90850
Overall Steps per Second: 10,101.83439

Timestep Collection Time: 2.41208
Timestep Consumption Time: 2.54108
PPO Batch Consumption Time: 0.29421
Total Iteration Time: 4.95316

Cumulative Model Updates: 112,780
Cumulative Timesteps: 940,416,408

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47,169.99870
Policy Entropy: 3.72800
Value Function Loss: 0.02044

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.13793
Policy Update Magnitude: 0.36415
Value Function Update Magnitude: 0.40295

Collected Steps per Second: 20,802.69852
Overall Steps per Second: 10,065.20327

Timestep Collection Time: 2.40440
Timestep Consumption Time: 2.56500
PPO Batch Consumption Time: 0.29396
Total Iteration Time: 4.96940

Cumulative Model Updates: 112,786
Cumulative Timesteps: 940,466,426

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 940466426...
Checkpoint 940466426 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,223.02331
Policy Entropy: 3.73354
Value Function Loss: 0.01990

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.13889
Policy Update Magnitude: 0.37092
Value Function Update Magnitude: 0.53837

Collected Steps per Second: 20,730.35423
Overall Steps per Second: 9,792.56797

Timestep Collection Time: 2.41327
Timestep Consumption Time: 2.69550
PPO Batch Consumption Time: 0.32045
Total Iteration Time: 5.10877

Cumulative Model Updates: 112,792
Cumulative Timesteps: 940,516,454

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,223.02331
Policy Entropy: 3.71531
Value Function Loss: 0.01952

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.13405
Policy Update Magnitude: 0.36876
Value Function Update Magnitude: 0.55138

Collected Steps per Second: 20,749.82914
Overall Steps per Second: 10,033.52728

Timestep Collection Time: 2.41033
Timestep Consumption Time: 2.57435
PPO Batch Consumption Time: 0.29416
Total Iteration Time: 4.98469

Cumulative Model Updates: 112,798
Cumulative Timesteps: 940,566,468

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 940566468...
Checkpoint 940566468 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,223.02331
Policy Entropy: 3.71068
Value Function Loss: 0.02017

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.13717
Policy Update Magnitude: 0.36937
Value Function Update Magnitude: 0.42448

Collected Steps per Second: 20,865.19280
Overall Steps per Second: 9,931.30352

Timestep Collection Time: 2.39653
Timestep Consumption Time: 2.63846
PPO Batch Consumption Time: 0.30676
Total Iteration Time: 5.03499

Cumulative Model Updates: 112,804
Cumulative Timesteps: 940,616,472

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,223.02331
Policy Entropy: 3.70191
Value Function Loss: 0.01880

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.14339
Policy Update Magnitude: 0.37972
Value Function Update Magnitude: 0.37640

Collected Steps per Second: 20,675.26092
Overall Steps per Second: 10,033.36361

Timestep Collection Time: 2.41845
Timestep Consumption Time: 2.56513
PPO Batch Consumption Time: 0.29629
Total Iteration Time: 4.98357

Cumulative Model Updates: 112,810
Cumulative Timesteps: 940,666,474

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 940666474...
Checkpoint 940666474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,223.02331
Policy Entropy: 3.70629
Value Function Loss: 0.01798

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.13526
Policy Update Magnitude: 0.35628
Value Function Update Magnitude: 0.37921

Collected Steps per Second: 21,005.82585
Overall Steps per Second: 10,151.81208

Timestep Collection Time: 2.38162
Timestep Consumption Time: 2.54636
PPO Batch Consumption Time: 0.29311
Total Iteration Time: 4.92799

Cumulative Model Updates: 112,816
Cumulative Timesteps: 940,716,502

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,223.02331
Policy Entropy: 3.72781
Value Function Loss: 0.01552

Mean KL Divergence: 0.01059
SB3 Clip Fraction: 0.14640
Policy Update Magnitude: 0.33997
Value Function Update Magnitude: 0.32081

Collected Steps per Second: 21,227.24696
Overall Steps per Second: 10,102.35794

Timestep Collection Time: 2.35575
Timestep Consumption Time: 2.59419
PPO Batch Consumption Time: 0.30126
Total Iteration Time: 4.94993

Cumulative Model Updates: 112,822
Cumulative Timesteps: 940,766,508

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 940766508...
Checkpoint 940766508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,223.02331
Policy Entropy: 3.70816
Value Function Loss: 0.01487

Mean KL Divergence: 0.01057
SB3 Clip Fraction: 0.14576
Policy Update Magnitude: 0.30025
Value Function Update Magnitude: 0.26760

Collected Steps per Second: 21,180.96727
Overall Steps per Second: 10,155.42776

Timestep Collection Time: 2.36080
Timestep Consumption Time: 2.56307
PPO Batch Consumption Time: 0.29544
Total Iteration Time: 4.92387

Cumulative Model Updates: 112,828
Cumulative Timesteps: 940,816,512

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,223.02331
Policy Entropy: 3.70443
Value Function Loss: 0.01420

Mean KL Divergence: 0.01111
SB3 Clip Fraction: 0.15359
Policy Update Magnitude: 0.27674
Value Function Update Magnitude: 0.26363

Collected Steps per Second: 20,900.39235
Overall Steps per Second: 10,093.29793

Timestep Collection Time: 2.39335
Timestep Consumption Time: 2.56261
PPO Batch Consumption Time: 0.29664
Total Iteration Time: 4.95596

Cumulative Model Updates: 112,834
Cumulative Timesteps: 940,866,534

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 940866534...
Checkpoint 940866534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 85,056.00018
Policy Entropy: 3.68067
Value Function Loss: 0.01878

Mean KL Divergence: 0.01119
SB3 Clip Fraction: 0.15555
Policy Update Magnitude: 0.32294
Value Function Update Magnitude: 0.47331

Collected Steps per Second: 20,913.08865
Overall Steps per Second: 10,091.82202

Timestep Collection Time: 2.39190
Timestep Consumption Time: 2.56479
PPO Batch Consumption Time: 0.29505
Total Iteration Time: 4.95669

Cumulative Model Updates: 112,840
Cumulative Timesteps: 940,916,556

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,668.52909
Policy Entropy: 3.69811
Value Function Loss: 0.02020

Mean KL Divergence: 0.01050
SB3 Clip Fraction: 0.14773
Policy Update Magnitude: 0.42898
Value Function Update Magnitude: 0.64226

Collected Steps per Second: 20,671.54661
Overall Steps per Second: 10,025.95841

Timestep Collection Time: 2.41878
Timestep Consumption Time: 2.56827
PPO Batch Consumption Time: 0.29534
Total Iteration Time: 4.98705

Cumulative Model Updates: 112,846
Cumulative Timesteps: 940,966,556

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 940966556...
Checkpoint 940966556 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 103,709.36640
Policy Entropy: 3.70406
Value Function Loss: 0.03109

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.13800
Policy Update Magnitude: 0.47065
Value Function Update Magnitude: 0.61746

Collected Steps per Second: 20,197.14993
Overall Steps per Second: 9,953.75159

Timestep Collection Time: 2.47679
Timestep Consumption Time: 2.54886
PPO Batch Consumption Time: 0.30694
Total Iteration Time: 5.02564

Cumulative Model Updates: 112,852
Cumulative Timesteps: 941,016,580

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,381.24657
Policy Entropy: 3.73242
Value Function Loss: 0.02902

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.13695
Policy Update Magnitude: 0.50826
Value Function Update Magnitude: 0.44011

Collected Steps per Second: 20,085.30028
Overall Steps per Second: 10,019.42882

Timestep Collection Time: 2.48998
Timestep Consumption Time: 2.50152
PPO Batch Consumption Time: 0.29875
Total Iteration Time: 4.99150

Cumulative Model Updates: 112,858
Cumulative Timesteps: 941,066,592

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 941066592...
Checkpoint 941066592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,476.33927
Policy Entropy: 3.72851
Value Function Loss: 0.02910

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.14003
Policy Update Magnitude: 0.47463
Value Function Update Magnitude: 0.39283

Collected Steps per Second: 20,169.88421
Overall Steps per Second: 10,105.44832

Timestep Collection Time: 2.48043
Timestep Consumption Time: 2.47036
PPO Batch Consumption Time: 0.29542
Total Iteration Time: 4.95079

Cumulative Model Updates: 112,864
Cumulative Timesteps: 941,116,622

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65,391.03524
Policy Entropy: 3.75060
Value Function Loss: 0.02243

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.13184
Policy Update Magnitude: 0.46492
Value Function Update Magnitude: 0.49249

Collected Steps per Second: 20,232.59801
Overall Steps per Second: 10,072.24755

Timestep Collection Time: 2.47165
Timestep Consumption Time: 2.49327
PPO Batch Consumption Time: 0.29834
Total Iteration Time: 4.96493

Cumulative Model Updates: 112,870
Cumulative Timesteps: 941,166,630

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 941166630...
Checkpoint 941166630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,836.75085
Policy Entropy: 3.72914
Value Function Loss: 0.02121

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.14209
Policy Update Magnitude: 0.45806
Value Function Update Magnitude: 0.66293

Collected Steps per Second: 20,182.70172
Overall Steps per Second: 9,857.62991

Timestep Collection Time: 2.47777
Timestep Consumption Time: 2.59526
PPO Batch Consumption Time: 0.30389
Total Iteration Time: 5.07302

Cumulative Model Updates: 112,876
Cumulative Timesteps: 941,216,638

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,836.75085
Policy Entropy: 3.71605
Value Function Loss: 0.01987

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.13492
Policy Update Magnitude: 0.46178
Value Function Update Magnitude: 0.73680

Collected Steps per Second: 20,764.93360
Overall Steps per Second: 10,036.59775

Timestep Collection Time: 2.40906
Timestep Consumption Time: 2.57510
PPO Batch Consumption Time: 0.30133
Total Iteration Time: 4.98416

Cumulative Model Updates: 112,882
Cumulative Timesteps: 941,266,662

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 941266662...
Checkpoint 941266662 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,836.75085
Policy Entropy: 3.69249
Value Function Loss: 0.01955

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.14200
Policy Update Magnitude: 0.46214
Value Function Update Magnitude: 0.73857

Collected Steps per Second: 20,660.33186
Overall Steps per Second: 9,955.35018

Timestep Collection Time: 2.42126
Timestep Consumption Time: 2.60358
PPO Batch Consumption Time: 0.30406
Total Iteration Time: 5.02484

Cumulative Model Updates: 112,888
Cumulative Timesteps: 941,316,686

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,836.75085
Policy Entropy: 3.68668
Value Function Loss: 0.01913

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.13817
Policy Update Magnitude: 0.45296
Value Function Update Magnitude: 0.51717

Collected Steps per Second: 20,740.61228
Overall Steps per Second: 9,952.51770

Timestep Collection Time: 2.41266
Timestep Consumption Time: 2.61522
PPO Batch Consumption Time: 0.30578
Total Iteration Time: 5.02787

Cumulative Model Updates: 112,894
Cumulative Timesteps: 941,366,726

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 941366726...
Checkpoint 941366726 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,836.75085
Policy Entropy: 3.71155
Value Function Loss: 0.01764

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.14340
Policy Update Magnitude: 0.41690
Value Function Update Magnitude: 0.37672

Collected Steps per Second: 20,690.40956
Overall Steps per Second: 10,048.92963

Timestep Collection Time: 2.41803
Timestep Consumption Time: 2.56061
PPO Batch Consumption Time: 0.29488
Total Iteration Time: 4.97864

Cumulative Model Updates: 112,900
Cumulative Timesteps: 941,416,756

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,836.75085
Policy Entropy: 3.71325
Value Function Loss: 0.01734

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.14014
Policy Update Magnitude: 0.37159
Value Function Update Magnitude: 0.32332

Collected Steps per Second: 20,980.77573
Overall Steps per Second: 10,122.03797

Timestep Collection Time: 2.38313
Timestep Consumption Time: 2.55658
PPO Batch Consumption Time: 0.29332
Total Iteration Time: 4.93972

Cumulative Model Updates: 112,906
Cumulative Timesteps: 941,466,756

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 941466756...
Checkpoint 941466756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,836.75085
Policy Entropy: 3.71422
Value Function Loss: 0.01634

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.14684
Policy Update Magnitude: 0.38121
Value Function Update Magnitude: 0.34885

Collected Steps per Second: 19,975.22880
Overall Steps per Second: 9,867.61830

Timestep Collection Time: 2.50460
Timestep Consumption Time: 2.56552
PPO Batch Consumption Time: 0.29296
Total Iteration Time: 5.07012

Cumulative Model Updates: 112,912
Cumulative Timesteps: 941,516,786

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,836.75085
Policy Entropy: 3.70414
Value Function Loss: 0.01628

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.14615
Policy Update Magnitude: 0.39405
Value Function Update Magnitude: 0.39875

Collected Steps per Second: 20,746.59796
Overall Steps per Second: 10,021.55241

Timestep Collection Time: 2.41090
Timestep Consumption Time: 2.58014
PPO Batch Consumption Time: 0.29697
Total Iteration Time: 4.99104

Cumulative Model Updates: 112,918
Cumulative Timesteps: 941,566,804

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 941566804...
Checkpoint 941566804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,836.75085
Policy Entropy: 3.70879
Value Function Loss: 0.01586

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.14511
Policy Update Magnitude: 0.39930
Value Function Update Magnitude: 0.44525

Collected Steps per Second: 20,181.86104
Overall Steps per Second: 10,091.60425

Timestep Collection Time: 2.47896
Timestep Consumption Time: 2.47863
PPO Batch Consumption Time: 0.29489
Total Iteration Time: 4.95759

Cumulative Model Updates: 112,924
Cumulative Timesteps: 941,616,834

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,836.75085
Policy Entropy: 3.70880
Value Function Loss: 0.01741

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.14201
Policy Update Magnitude: 0.40875
Value Function Update Magnitude: 0.45685

Collected Steps per Second: 20,416.53569
Overall Steps per Second: 10,156.19695

Timestep Collection Time: 2.45046
Timestep Consumption Time: 2.47559
PPO Batch Consumption Time: 0.29357
Total Iteration Time: 4.92606

Cumulative Model Updates: 112,930
Cumulative Timesteps: 941,666,864

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 941666864...
Checkpoint 941666864 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,836.75085
Policy Entropy: 3.71166
Value Function Loss: 0.01948

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.13867
Policy Update Magnitude: 0.40844
Value Function Update Magnitude: 0.36007

Collected Steps per Second: 20,257.86016
Overall Steps per Second: 9,883.83636

Timestep Collection Time: 2.46867
Timestep Consumption Time: 2.59110
PPO Batch Consumption Time: 0.30755
Total Iteration Time: 5.05978

Cumulative Model Updates: 112,936
Cumulative Timesteps: 941,716,874

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,836.75085
Policy Entropy: 3.69771
Value Function Loss: 0.02341

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.13973
Policy Update Magnitude: 0.41492
Value Function Update Magnitude: 0.36526

Collected Steps per Second: 20,677.96861
Overall Steps per Second: 9,807.79468

Timestep Collection Time: 2.41852
Timestep Consumption Time: 2.68049
PPO Batch Consumption Time: 0.31932
Total Iteration Time: 5.09901

Cumulative Model Updates: 112,942
Cumulative Timesteps: 941,766,884

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 941766884...
Checkpoint 941766884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,836.75085
Policy Entropy: 3.69375
Value Function Loss: 0.02837

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.13831
Policy Update Magnitude: 0.41867
Value Function Update Magnitude: 0.32907

Collected Steps per Second: 20,306.32971
Overall Steps per Second: 9,915.14782

Timestep Collection Time: 2.46258
Timestep Consumption Time: 2.58081
PPO Batch Consumption Time: 0.29436
Total Iteration Time: 5.04339

Cumulative Model Updates: 112,948
Cumulative Timesteps: 941,816,890

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,836.75085
Policy Entropy: 3.69539
Value Function Loss: 0.02570

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.13940
Policy Update Magnitude: 0.44124
Value Function Update Magnitude: 0.32654

Collected Steps per Second: 21,113.99846
Overall Steps per Second: 10,102.37325

Timestep Collection Time: 2.36980
Timestep Consumption Time: 2.58309
PPO Batch Consumption Time: 0.29609
Total Iteration Time: 4.95290

Cumulative Model Updates: 112,954
Cumulative Timesteps: 941,866,926

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 941866926...
Checkpoint 941866926 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,836.75085
Policy Entropy: 3.70635
Value Function Loss: 0.02389

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.14233
Policy Update Magnitude: 0.44463
Value Function Update Magnitude: 0.40360

Collected Steps per Second: 20,646.58425
Overall Steps per Second: 9,967.47091

Timestep Collection Time: 2.42258
Timestep Consumption Time: 2.59554
PPO Batch Consumption Time: 0.30210
Total Iteration Time: 5.01812

Cumulative Model Updates: 112,960
Cumulative Timesteps: 941,916,944

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,836.75085
Policy Entropy: 3.70847
Value Function Loss: 0.02263

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.13564
Policy Update Magnitude: 0.45395
Value Function Update Magnitude: 0.42225

Collected Steps per Second: 21,002.69828
Overall Steps per Second: 10,000.52266

Timestep Collection Time: 2.38141
Timestep Consumption Time: 2.61993
PPO Batch Consumption Time: 0.30326
Total Iteration Time: 5.00134

Cumulative Model Updates: 112,966
Cumulative Timesteps: 941,966,960

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 941966960...
Checkpoint 941966960 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 68,514.61247
Policy Entropy: 3.71612
Value Function Loss: 0.02344

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.14011
Policy Update Magnitude: 0.48106
Value Function Update Magnitude: 0.43965

Collected Steps per Second: 20,605.80490
Overall Steps per Second: 10,036.19327

Timestep Collection Time: 2.42844
Timestep Consumption Time: 2.55751
PPO Batch Consumption Time: 0.29385
Total Iteration Time: 4.98595

Cumulative Model Updates: 112,972
Cumulative Timesteps: 942,017,000

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 189,140.08983
Policy Entropy: 3.71791
Value Function Loss: 0.02328

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.13667
Policy Update Magnitude: 0.49291
Value Function Update Magnitude: 0.51756

Collected Steps per Second: 21,081.27708
Overall Steps per Second: 10,106.67511

Timestep Collection Time: 2.37282
Timestep Consumption Time: 2.57659
PPO Batch Consumption Time: 0.29831
Total Iteration Time: 4.94940

Cumulative Model Updates: 112,978
Cumulative Timesteps: 942,067,022

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 942067022...
Checkpoint 942067022 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 189,140.08983
Policy Entropy: 3.71959
Value Function Loss: 0.02121

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.13191
Policy Update Magnitude: 0.54624
Value Function Update Magnitude: 0.55249

Collected Steps per Second: 21,012.81976
Overall Steps per Second: 10,094.45052

Timestep Collection Time: 2.38178
Timestep Consumption Time: 2.57619
PPO Batch Consumption Time: 0.29431
Total Iteration Time: 4.95797

Cumulative Model Updates: 112,984
Cumulative Timesteps: 942,117,070

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 189,140.08983
Policy Entropy: 3.72549
Value Function Loss: 0.01826

Mean KL Divergence: 0.00564
SB3 Clip Fraction: 0.06899
Policy Update Magnitude: 0.61316
Value Function Update Magnitude: 0.52914

Collected Steps per Second: 20,439.45440
Overall Steps per Second: 10,137.41151

Timestep Collection Time: 2.44752
Timestep Consumption Time: 2.48727
PPO Batch Consumption Time: 0.29399
Total Iteration Time: 4.93479

Cumulative Model Updates: 112,990
Cumulative Timesteps: 942,167,096

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 942167096...
Checkpoint 942167096 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 338,423.64420
Policy Entropy: 3.73424
Value Function Loss: 0.01609

Mean KL Divergence: 0.01677
SB3 Clip Fraction: 0.20567
Policy Update Magnitude: 0.53128
Value Function Update Magnitude: 0.47142

Collected Steps per Second: 20,367.78889
Overall Steps per Second: 10,141.03537

Timestep Collection Time: 2.45574
Timestep Consumption Time: 2.47650
PPO Batch Consumption Time: 0.29350
Total Iteration Time: 4.93224

Cumulative Model Updates: 112,996
Cumulative Timesteps: 942,217,114

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 641,673.10791
Policy Entropy: 3.72082
Value Function Loss: 0.02921

Mean KL Divergence: 0.03120
SB3 Clip Fraction: 0.30016
Policy Update Magnitude: 0.50327
Value Function Update Magnitude: 0.53603

Collected Steps per Second: 20,444.70441
Overall Steps per Second: 9,989.62366

Timestep Collection Time: 2.44611
Timestep Consumption Time: 2.56008
PPO Batch Consumption Time: 0.29489
Total Iteration Time: 5.00619

Cumulative Model Updates: 113,002
Cumulative Timesteps: 942,267,124

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 942267124...
Checkpoint 942267124 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 399,636.61524
Policy Entropy: 3.69165
Value Function Loss: 0.04459

Mean KL Divergence: 0.01886
SB3 Clip Fraction: 0.22021
Policy Update Magnitude: 0.64367
Value Function Update Magnitude: 0.66058

Collected Steps per Second: 20,531.83901
Overall Steps per Second: 9,971.53781

Timestep Collection Time: 2.43563
Timestep Consumption Time: 2.57944
PPO Batch Consumption Time: 0.30640
Total Iteration Time: 5.01507

Cumulative Model Updates: 113,008
Cumulative Timesteps: 942,317,132

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,914.30982
Policy Entropy: 3.71280
Value Function Loss: 0.05118

Mean KL Divergence: 0.01425
SB3 Clip Fraction: 0.18107
Policy Update Magnitude: 0.79688
Value Function Update Magnitude: 0.72695

Collected Steps per Second: 20,657.76719
Overall Steps per Second: 9,940.66442

Timestep Collection Time: 2.42156
Timestep Consumption Time: 2.61070
PPO Batch Consumption Time: 0.30505
Total Iteration Time: 5.03226

Cumulative Model Updates: 113,014
Cumulative Timesteps: 942,367,156

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 942367156...
Checkpoint 942367156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,258.13264
Policy Entropy: 3.72099
Value Function Loss: 0.07857

Mean KL Divergence: 0.01323
SB3 Clip Fraction: 0.16699
Policy Update Magnitude: 0.84790
Value Function Update Magnitude: 0.66548

Collected Steps per Second: 20,672.47814
Overall Steps per Second: 9,915.37724

Timestep Collection Time: 2.41887
Timestep Consumption Time: 2.62421
PPO Batch Consumption Time: 0.31065
Total Iteration Time: 5.04308

Cumulative Model Updates: 113,020
Cumulative Timesteps: 942,417,160

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 301,294.80220
Policy Entropy: 3.74502
Value Function Loss: 0.04860

Mean KL Divergence: 0.01247
SB3 Clip Fraction: 0.15365
Policy Update Magnitude: 0.81004
Value Function Update Magnitude: 0.59602

Collected Steps per Second: 20,566.06129
Overall Steps per Second: 9,969.55958

Timestep Collection Time: 2.43226
Timestep Consumption Time: 2.58521
PPO Batch Consumption Time: 0.30354
Total Iteration Time: 5.01747

Cumulative Model Updates: 113,026
Cumulative Timesteps: 942,467,182

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 942467182...
Checkpoint 942467182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 291,943.27526
Policy Entropy: 3.70785
Value Function Loss: 0.04347

Mean KL Divergence: 0.01241
SB3 Clip Fraction: 0.15553
Policy Update Magnitude: 0.80795
Value Function Update Magnitude: 0.63519

Collected Steps per Second: 20,941.96123
Overall Steps per Second: 10,092.98288

Timestep Collection Time: 2.38860
Timestep Consumption Time: 2.56752
PPO Batch Consumption Time: 0.29531
Total Iteration Time: 4.95612

Cumulative Model Updates: 113,032
Cumulative Timesteps: 942,517,204

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 291,943.27526
Policy Entropy: 3.72118
Value Function Loss: 0.03126

Mean KL Divergence: 0.00703
SB3 Clip Fraction: 0.08793
Policy Update Magnitude: 0.78983
Value Function Update Magnitude: 0.58331

Collected Steps per Second: 21,117.13885
Overall Steps per Second: 10,089.39030

Timestep Collection Time: 2.36964
Timestep Consumption Time: 2.59003
PPO Batch Consumption Time: 0.29640
Total Iteration Time: 4.95967

Cumulative Model Updates: 113,038
Cumulative Timesteps: 942,567,244

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 942567244...
Checkpoint 942567244 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 142,487.85635
Policy Entropy: 3.70568
Value Function Loss: 0.02727

Mean KL Divergence: 0.01155
SB3 Clip Fraction: 0.15207
Policy Update Magnitude: 0.73232
Value Function Update Magnitude: 0.49908

Collected Steps per Second: 20,760.63634
Overall Steps per Second: 9,978.62746

Timestep Collection Time: 2.40889
Timestep Consumption Time: 2.60283
PPO Batch Consumption Time: 0.30368
Total Iteration Time: 5.01171

Cumulative Model Updates: 113,044
Cumulative Timesteps: 942,617,254

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 142,487.85635
Policy Entropy: 3.73540
Value Function Loss: 0.02074

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.13506
Policy Update Magnitude: 0.59925
Value Function Update Magnitude: 0.44887

Collected Steps per Second: 20,965.80648
Overall Steps per Second: 9,998.54179

Timestep Collection Time: 2.38512
Timestep Consumption Time: 2.61621
PPO Batch Consumption Time: 0.30565
Total Iteration Time: 5.00133

Cumulative Model Updates: 113,050
Cumulative Timesteps: 942,667,260

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 942667260...
Checkpoint 942667260 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 162,931.01148
Policy Entropy: 3.75100
Value Function Loss: 0.02018

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.13088
Policy Update Magnitude: 0.61399
Value Function Update Magnitude: 0.52630

Collected Steps per Second: 20,867.11237
Overall Steps per Second: 10,048.90393

Timestep Collection Time: 2.39707
Timestep Consumption Time: 2.58058
PPO Batch Consumption Time: 0.29656
Total Iteration Time: 4.97766

Cumulative Model Updates: 113,056
Cumulative Timesteps: 942,717,280

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56,812.98007
Policy Entropy: 3.75591
Value Function Loss: 0.01879

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.12531
Policy Update Magnitude: 0.60369
Value Function Update Magnitude: 0.65411

Collected Steps per Second: 21,024.98748
Overall Steps per Second: 10,126.79818

Timestep Collection Time: 2.37888
Timestep Consumption Time: 2.56009
PPO Batch Consumption Time: 0.29395
Total Iteration Time: 4.93897

Cumulative Model Updates: 113,062
Cumulative Timesteps: 942,767,296

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 942767296...
Checkpoint 942767296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,475.63321
Policy Entropy: 3.74820
Value Function Loss: 0.01893

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.11748
Policy Update Magnitude: 0.57856
Value Function Update Magnitude: 0.69845

Collected Steps per Second: 20,985.78834
Overall Steps per Second: 10,129.00335

Timestep Collection Time: 2.38361
Timestep Consumption Time: 2.55488
PPO Batch Consumption Time: 0.29424
Total Iteration Time: 4.93849

Cumulative Model Updates: 113,068
Cumulative Timesteps: 942,817,318

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,830.14159
Policy Entropy: 3.74960
Value Function Loss: 0.01860

Mean KL Divergence: 0.00699
SB3 Clip Fraction: 0.08889
Policy Update Magnitude: 0.54501
Value Function Update Magnitude: 0.57605

Collected Steps per Second: 21,092.50097
Overall Steps per Second: 10,167.47405

Timestep Collection Time: 2.37127
Timestep Consumption Time: 2.54795
PPO Batch Consumption Time: 0.29292
Total Iteration Time: 4.91922

Cumulative Model Updates: 113,074
Cumulative Timesteps: 942,867,334

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 942867334...
Checkpoint 942867334 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,830.14159
Policy Entropy: 3.75103
Value Function Loss: 0.01962

Mean KL Divergence: 0.00729
SB3 Clip Fraction: 0.09457
Policy Update Magnitude: 0.49629
Value Function Update Magnitude: 0.46136

Collected Steps per Second: 20,889.54849
Overall Steps per Second: 10,104.79518

Timestep Collection Time: 2.39459
Timestep Consumption Time: 2.55573
PPO Batch Consumption Time: 0.29424
Total Iteration Time: 4.95032

Cumulative Model Updates: 113,080
Cumulative Timesteps: 942,917,356

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,830.14159
Policy Entropy: 3.74381
Value Function Loss: 0.01761

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.12547
Policy Update Magnitude: 0.45653
Value Function Update Magnitude: 0.35683

Collected Steps per Second: 21,010.65499
Overall Steps per Second: 10,112.33301

Timestep Collection Time: 2.38203
Timestep Consumption Time: 2.56717
PPO Batch Consumption Time: 0.29405
Total Iteration Time: 4.94920

Cumulative Model Updates: 113,086
Cumulative Timesteps: 942,967,404

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 942967404...
Checkpoint 942967404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,830.14159
Policy Entropy: 3.74313
Value Function Loss: 0.01857

Mean KL Divergence: 0.00688
SB3 Clip Fraction: 0.08754
Policy Update Magnitude: 0.42436
Value Function Update Magnitude: 0.28248

Collected Steps per Second: 21,158.19832
Overall Steps per Second: 9,998.34193

Timestep Collection Time: 2.36580
Timestep Consumption Time: 2.64063
PPO Batch Consumption Time: 0.30741
Total Iteration Time: 5.00643

Cumulative Model Updates: 113,092
Cumulative Timesteps: 943,017,460

Timesteps Collected: 50,056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,830.14159
Policy Entropy: 3.71382
Value Function Loss: 0.02170

Mean KL Divergence: 0.01992
SB3 Clip Fraction: 0.22888
Policy Update Magnitude: 0.39169
Value Function Update Magnitude: 0.43216

Collected Steps per Second: 20,400.43192
Overall Steps per Second: 9,860.43715

Timestep Collection Time: 2.45093
Timestep Consumption Time: 2.61984
PPO Batch Consumption Time: 0.30283
Total Iteration Time: 5.07077

Cumulative Model Updates: 113,098
Cumulative Timesteps: 943,067,460

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 943067460...
Checkpoint 943067460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 307,448.75477
Policy Entropy: 3.69260
Value Function Loss: 0.03803

Mean KL Divergence: 0.02427
SB3 Clip Fraction: 0.24104
Policy Update Magnitude: 0.47233
Value Function Update Magnitude: 0.48509

Collected Steps per Second: 20,448.60935
Overall Steps per Second: 9,880.29539

Timestep Collection Time: 2.44750
Timestep Consumption Time: 2.61793
PPO Batch Consumption Time: 0.30679
Total Iteration Time: 5.06544

Cumulative Model Updates: 113,104
Cumulative Timesteps: 943,117,508

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 107,436.88314
Policy Entropy: 3.71613
Value Function Loss: 0.04808

Mean KL Divergence: 0.01454
SB3 Clip Fraction: 0.16728
Policy Update Magnitude: 0.65849
Value Function Update Magnitude: 0.56725

Collected Steps per Second: 20,565.00774
Overall Steps per Second: 9,962.66481

Timestep Collection Time: 2.43219
Timestep Consumption Time: 2.58835
PPO Batch Consumption Time: 0.29949
Total Iteration Time: 5.02054

Cumulative Model Updates: 113,110
Cumulative Timesteps: 943,167,526

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 943167526...
Checkpoint 943167526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 74,080.44324
Policy Entropy: 3.71767
Value Function Loss: 0.05740

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.12761
Policy Update Magnitude: 0.93629
Value Function Update Magnitude: 0.58046

Collected Steps per Second: 20,401.18884
Overall Steps per Second: 9,838.20796

Timestep Collection Time: 2.45152
Timestep Consumption Time: 2.63213
PPO Batch Consumption Time: 0.30810
Total Iteration Time: 5.08365

Cumulative Model Updates: 113,116
Cumulative Timesteps: 943,217,540

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83,642.84304
Policy Entropy: 3.73641
Value Function Loss: 0.04932

Mean KL Divergence: 0.01345
SB3 Clip Fraction: 0.16015
Policy Update Magnitude: 1.01743
Value Function Update Magnitude: 0.55368

Collected Steps per Second: 20,710.71946
Overall Steps per Second: 10,019.45671

Timestep Collection Time: 2.41556
Timestep Consumption Time: 2.57752
PPO Batch Consumption Time: 0.29838
Total Iteration Time: 4.99309

Cumulative Model Updates: 113,122
Cumulative Timesteps: 943,267,568

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 943267568...
Checkpoint 943267568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 239,575.17812
Policy Entropy: 3.73024
Value Function Loss: 0.04114

Mean KL Divergence: 0.01131
SB3 Clip Fraction: 0.14630
Policy Update Magnitude: 0.76772
Value Function Update Magnitude: 0.62325

Collected Steps per Second: 20,259.77350
Overall Steps per Second: 10,100.84918

Timestep Collection Time: 2.46923
Timestep Consumption Time: 2.48342
PPO Batch Consumption Time: 0.29468
Total Iteration Time: 4.95265

Cumulative Model Updates: 113,128
Cumulative Timesteps: 943,317,594

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 127,379.44259
Policy Entropy: 3.73171
Value Function Loss: 0.03484

Mean KL Divergence: 0.01173
SB3 Clip Fraction: 0.15942
Policy Update Magnitude: 0.59747
Value Function Update Magnitude: 0.61320

Collected Steps per Second: 20,420.66421
Overall Steps per Second: 10,140.83753

Timestep Collection Time: 2.44928
Timestep Consumption Time: 2.48285
PPO Batch Consumption Time: 0.29397
Total Iteration Time: 4.93214

Cumulative Model Updates: 113,134
Cumulative Timesteps: 943,367,610

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 943367610...
Checkpoint 943367610 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,963.85684
Policy Entropy: 3.69795
Value Function Loss: 0.03169

Mean KL Divergence: 0.01194
SB3 Clip Fraction: 0.15838
Policy Update Magnitude: 0.52978
Value Function Update Magnitude: 0.62417

Collected Steps per Second: 20,134.79469
Overall Steps per Second: 10,104.17407

Timestep Collection Time: 2.48436
Timestep Consumption Time: 2.46627
PPO Batch Consumption Time: 0.29484
Total Iteration Time: 4.95063

Cumulative Model Updates: 113,140
Cumulative Timesteps: 943,417,632

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48,981.14062
Policy Entropy: 3.70248
Value Function Loss: 0.03303

Mean KL Divergence: 0.01266
SB3 Clip Fraction: 0.16443
Policy Update Magnitude: 0.48320
Value Function Update Magnitude: 0.61404

Collected Steps per Second: 20,220.02220
Overall Steps per Second: 9,922.88231

Timestep Collection Time: 2.47369
Timestep Consumption Time: 2.56699
PPO Batch Consumption Time: 0.30179
Total Iteration Time: 5.04067

Cumulative Model Updates: 113,146
Cumulative Timesteps: 943,467,650

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 943467650...
Checkpoint 943467650 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 64,868.41233
Policy Entropy: 3.70673
Value Function Loss: 0.03358

Mean KL Divergence: 0.01147
SB3 Clip Fraction: 0.15030
Policy Update Magnitude: 0.51510
Value Function Update Magnitude: 0.61576

Collected Steps per Second: 20,629.93930
Overall Steps per Second: 10,068.79768

Timestep Collection Time: 2.42512
Timestep Consumption Time: 2.54370
PPO Batch Consumption Time: 0.29877
Total Iteration Time: 4.96882

Cumulative Model Updates: 113,152
Cumulative Timesteps: 943,517,680

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,338.35718
Policy Entropy: 3.71144
Value Function Loss: 0.02970

Mean KL Divergence: 0.01047
SB3 Clip Fraction: 0.14097
Policy Update Magnitude: 0.51376
Value Function Update Magnitude: 0.60150

Collected Steps per Second: 20,652.63908
Overall Steps per Second: 9,979.49187

Timestep Collection Time: 2.42245
Timestep Consumption Time: 2.59083
PPO Batch Consumption Time: 0.30278
Total Iteration Time: 5.01328

Cumulative Model Updates: 113,158
Cumulative Timesteps: 943,567,710

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 943567710...
Checkpoint 943567710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 119,909.22737
Policy Entropy: 3.72633
Value Function Loss: 0.02732

Mean KL Divergence: 0.01086
SB3 Clip Fraction: 0.14899
Policy Update Magnitude: 0.46480
Value Function Update Magnitude: 0.59194

Collected Steps per Second: 21,004.47164
Overall Steps per Second: 10,102.90659

Timestep Collection Time: 2.38045
Timestep Consumption Time: 2.56863
PPO Batch Consumption Time: 0.29589
Total Iteration Time: 4.94907

Cumulative Model Updates: 113,164
Cumulative Timesteps: 943,617,710

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,870.71612
Policy Entropy: 3.73139
Value Function Loss: 0.02329

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.14669
Policy Update Magnitude: 0.39657
Value Function Update Magnitude: 0.51446

Collected Steps per Second: 20,913.46249
Overall Steps per Second: 9,997.54767

Timestep Collection Time: 2.39262
Timestep Consumption Time: 2.61241
PPO Batch Consumption Time: 0.30311
Total Iteration Time: 5.00503

Cumulative Model Updates: 113,170
Cumulative Timesteps: 943,667,748

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 943667748...
Checkpoint 943667748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,468.94684
Policy Entropy: 3.73490
Value Function Loss: 0.02244

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.14393
Policy Update Magnitude: 0.36792
Value Function Update Magnitude: 0.49287

Collected Steps per Second: 20,683.76090
Overall Steps per Second: 9,998.76935

Timestep Collection Time: 2.41813
Timestep Consumption Time: 2.58409
PPO Batch Consumption Time: 0.29990
Total Iteration Time: 5.00222

Cumulative Model Updates: 113,176
Cumulative Timesteps: 943,717,764

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,468.94684
Policy Entropy: 3.72475
Value Function Loss: 0.02017

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.14371
Policy Update Magnitude: 0.37231
Value Function Update Magnitude: 0.55885

Collected Steps per Second: 21,085.91271
Overall Steps per Second: 10,028.30893

Timestep Collection Time: 2.37315
Timestep Consumption Time: 2.61673
PPO Batch Consumption Time: 0.30293
Total Iteration Time: 4.98987

Cumulative Model Updates: 113,182
Cumulative Timesteps: 943,767,804

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 943767804...
Checkpoint 943767804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,468.94684
Policy Entropy: 3.71315
Value Function Loss: 0.01954

Mean KL Divergence: 0.01080
SB3 Clip Fraction: 0.14926
Policy Update Magnitude: 0.36977
Value Function Update Magnitude: 0.61720

Collected Steps per Second: 20,744.35085
Overall Steps per Second: 9,990.23910

Timestep Collection Time: 2.41068
Timestep Consumption Time: 2.59501
PPO Batch Consumption Time: 0.30068
Total Iteration Time: 5.00569

Cumulative Model Updates: 113,188
Cumulative Timesteps: 943,817,812

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,468.94684
Policy Entropy: 3.70950
Value Function Loss: 0.01775

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.14451
Policy Update Magnitude: 0.34192
Value Function Update Magnitude: 0.53812

Collected Steps per Second: 20,972.21942
Overall Steps per Second: 10,128.19857

Timestep Collection Time: 2.38458
Timestep Consumption Time: 2.55312
PPO Batch Consumption Time: 0.29462
Total Iteration Time: 4.93770

Cumulative Model Updates: 113,194
Cumulative Timesteps: 943,867,822

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 943867822...
Checkpoint 943867822 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,468.94684
Policy Entropy: 3.71962
Value Function Loss: 0.01955

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.14011
Policy Update Magnitude: 0.31598
Value Function Update Magnitude: 0.36837

Collected Steps per Second: 20,880.02440
Overall Steps per Second: 9,969.18733

Timestep Collection Time: 2.39540
Timestep Consumption Time: 2.62166
PPO Batch Consumption Time: 0.30600
Total Iteration Time: 5.01706

Cumulative Model Updates: 113,200
Cumulative Timesteps: 943,917,838

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,468.94684
Policy Entropy: 3.72002
Value Function Loss: 0.01835

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.14004
Policy Update Magnitude: 0.29766
Value Function Update Magnitude: 0.27995

Collected Steps per Second: 20,908.80588
Overall Steps per Second: 9,997.02860

Timestep Collection Time: 2.39143
Timestep Consumption Time: 2.61025
PPO Batch Consumption Time: 0.30270
Total Iteration Time: 5.00169

Cumulative Model Updates: 113,206
Cumulative Timesteps: 943,967,840

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 943967840...
Checkpoint 943967840 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,468.94684
Policy Entropy: 3.71309
Value Function Loss: 0.01592

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.14442
Policy Update Magnitude: 0.27623
Value Function Update Magnitude: 0.32930

Collected Steps per Second: 20,701.99626
Overall Steps per Second: 10,000.76258

Timestep Collection Time: 2.41610
Timestep Consumption Time: 2.58532
PPO Batch Consumption Time: 0.30031
Total Iteration Time: 5.00142

Cumulative Model Updates: 113,212
Cumulative Timesteps: 944,017,858

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,468.94684
Policy Entropy: 3.71840
Value Function Loss: 0.01493

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.14007
Policy Update Magnitude: 0.27355
Value Function Update Magnitude: 0.35979

Collected Steps per Second: 21,307.09174
Overall Steps per Second: 10,199.50528

Timestep Collection Time: 2.34701
Timestep Consumption Time: 2.55597
PPO Batch Consumption Time: 0.29365
Total Iteration Time: 4.90298

Cumulative Model Updates: 113,218
Cumulative Timesteps: 944,067,866

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 944067866...
Checkpoint 944067866 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,468.94684
Policy Entropy: 3.71930
Value Function Loss: 0.01848

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.13567
Policy Update Magnitude: 0.29957
Value Function Update Magnitude: 0.33519

Collected Steps per Second: 20,313.03778
Overall Steps per Second: 10,152.14643

Timestep Collection Time: 2.46265
Timestep Consumption Time: 2.46478
PPO Batch Consumption Time: 0.29500
Total Iteration Time: 4.92743

Cumulative Model Updates: 113,224
Cumulative Timesteps: 944,117,890

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,468.94684
Policy Entropy: 3.73673
Value Function Loss: 0.01760

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.13438
Policy Update Magnitude: 0.34301
Value Function Update Magnitude: 0.37451

Collected Steps per Second: 20,398.10065
Overall Steps per Second: 9,994.24895

Timestep Collection Time: 2.45199
Timestep Consumption Time: 2.55249
PPO Batch Consumption Time: 0.30453
Total Iteration Time: 5.00448

Cumulative Model Updates: 113,230
Cumulative Timesteps: 944,167,906

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 944167906...
Checkpoint 944167906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,468.94684
Policy Entropy: 3.72418
Value Function Loss: 0.02029

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.13144
Policy Update Magnitude: 0.35716
Value Function Update Magnitude: 0.35791

Collected Steps per Second: 19,665.76226
Overall Steps per Second: 9,538.06649

Timestep Collection Time: 2.54320
Timestep Consumption Time: 2.70042
PPO Batch Consumption Time: 0.31675
Total Iteration Time: 5.24362

Cumulative Model Updates: 113,236
Cumulative Timesteps: 944,217,920

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 164,078.04661
Policy Entropy: 3.72810
Value Function Loss: 0.01984

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.13445
Policy Update Magnitude: 0.39385
Value Function Update Magnitude: 0.39620

Collected Steps per Second: 19,216.77824
Overall Steps per Second: 9,604.18259

Timestep Collection Time: 2.60429
Timestep Consumption Time: 2.60657
PPO Batch Consumption Time: 0.29442
Total Iteration Time: 5.21085

Cumulative Model Updates: 113,242
Cumulative Timesteps: 944,267,966

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 944267966...
Checkpoint 944267966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 416,263.48880
Policy Entropy: 3.71012
Value Function Loss: 0.02291

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.13524
Policy Update Magnitude: 0.41878
Value Function Update Magnitude: 0.47132

Collected Steps per Second: 18,275.27461
Overall Steps per Second: 9,543.80054

Timestep Collection Time: 2.73769
Timestep Consumption Time: 2.50467
PPO Batch Consumption Time: 0.28807
Total Iteration Time: 5.24236

Cumulative Model Updates: 113,248
Cumulative Timesteps: 944,317,998

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 145,148.09164
Policy Entropy: 3.73417
Value Function Loss: 0.02200

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.13337
Policy Update Magnitude: 0.44994
Value Function Update Magnitude: 0.45400

Collected Steps per Second: 21,223.48454
Overall Steps per Second: 10,098.58159

Timestep Collection Time: 2.35692
Timestep Consumption Time: 2.59645
PPO Batch Consumption Time: 0.30003
Total Iteration Time: 4.95337

Cumulative Model Updates: 113,254
Cumulative Timesteps: 944,368,020

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 944368020...
Checkpoint 944368020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 50,613.49540
Policy Entropy: 3.71513
Value Function Loss: 0.02330

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.13630
Policy Update Magnitude: 0.44465
Value Function Update Magnitude: 0.43068

Collected Steps per Second: 20,370.23913
Overall Steps per Second: 9,911.52593

Timestep Collection Time: 2.45662
Timestep Consumption Time: 2.59225
PPO Batch Consumption Time: 0.29932
Total Iteration Time: 5.04887

Cumulative Model Updates: 113,260
Cumulative Timesteps: 944,418,062

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,652.21601
Policy Entropy: 3.72826
Value Function Loss: 0.02088

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.13712
Policy Update Magnitude: 0.42545
Value Function Update Magnitude: 0.40174

Collected Steps per Second: 20,486.73649
Overall Steps per Second: 9,566.66569

Timestep Collection Time: 2.44197
Timestep Consumption Time: 2.78744
PPO Batch Consumption Time: 0.33116
Total Iteration Time: 5.22941

Cumulative Model Updates: 113,266
Cumulative Timesteps: 944,468,090

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 944468090...
Checkpoint 944468090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,996.39946
Policy Entropy: 3.71565
Value Function Loss: 0.02144

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.13343
Policy Update Magnitude: 0.41588
Value Function Update Magnitude: 0.46154

Collected Steps per Second: 16,060.39912
Overall Steps per Second: 8,484.14807

Timestep Collection Time: 3.11424
Timestep Consumption Time: 2.78099
PPO Batch Consumption Time: 0.33364
Total Iteration Time: 5.89523

Cumulative Model Updates: 113,272
Cumulative Timesteps: 944,518,106

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 944518106...
Checkpoint 944518106 saved!
