{"z_vel":-2.371277389027803,"Mean KL Divergence":0.009654134511947632,"_timestamp":1.7407140762474434e+09,"Overall Steps per Second":8484.148072609583,"Timestep Collection Time":3.1142438999995647,"Policy Reward":4996.399455008828,"_wandb":{"runtime":218996},"Collected Steps per Second":16060.399122884046,"SB3 Clip Fraction":0.13342666253447533,"Value Function Loss":0.021442986093461514,"PPO Batch Consumption Time":0.3336372375488281,"Total Iteration Time":5.895229499998095,"_step":91657,"Timestep Consumption Time":2.7809855999985302,"x_vel":-4.017031086439613,"Cumulative Model Updates":113272,"Cumulative Timesteps":944518106,"Value Function Update Magnitude":0.46154189109802246,"y_vel":-0.1818181344931905,"Timesteps Collected":50016,"_runtime":218996.0513295,"Policy Entropy":3.7156490087509155,"Policy Update Magnitude":0.41587790846824646}