Checkpoint loaded!
Learner successfully initialized!
Press (p) to pause (c) to checkpoint, (q) to checkpoint and quit (after next iteration)

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00330
Policy Entropy: 0.70857
Value Function Loss: 0.04057

Mean KL Divergence: 0.00000
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.01966
Value Function Update Magnitude: 0.02315

Collected Steps per Second: 18,802.60509
Overall Steps per Second: 13,488.83928

Timestep Collection Time: 2.66016
Timestep Consumption Time: 1.04794
PPO Batch Consumption Time: 0.33095
Total Iteration Time: 3.70810

Cumulative Model Updates: 73
Cumulative Timesteps: 1,300,668

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00341
Policy Entropy: 0.70377
Value Function Loss: 0.04115

Mean KL Divergence: 0.00035
SB3 Clip Fraction: 0.00003
Policy Update Magnitude: 0.04033
Value Function Update Magnitude: 0.04264

Collected Steps per Second: 21,352.68472
Overall Steps per Second: 13,328.21030

Timestep Collection Time: 2.34275
Timestep Consumption Time: 1.41049
PPO Batch Consumption Time: 0.33553
Total Iteration Time: 3.75324

Cumulative Model Updates: 75
Cumulative Timesteps: 1,350,692

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1350692...
Checkpoint 1350692 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00522
Policy Entropy: 0.69440
Value Function Loss: 0.03639

Mean KL Divergence: 0.00249
SB3 Clip Fraction: 0.01395
Policy Update Magnitude: 0.06128
Value Function Update Magnitude: 0.06115

Collected Steps per Second: 18,935.11557
Overall Steps per Second: 11,407.53955

Timestep Collection Time: 2.64102
Timestep Consumption Time: 1.74275
PPO Batch Consumption Time: 0.32872
Total Iteration Time: 4.38377

Cumulative Model Updates: 78
Cumulative Timesteps: 1,400,700

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01367
Policy Entropy: 0.68475
Value Function Loss: 0.03082

Mean KL Divergence: 0.00418
SB3 Clip Fraction: 0.04721
Policy Update Magnitude: 0.05019
Value Function Update Magnitude: 0.05512

Collected Steps per Second: 18,894.38068
Overall Steps per Second: 11,292.82734

Timestep Collection Time: 2.64724
Timestep Consumption Time: 1.78194
PPO Batch Consumption Time: 0.32918
Total Iteration Time: 4.42918

Cumulative Model Updates: 81
Cumulative Timesteps: 1,450,718

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1450718...
Checkpoint 1450718 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00704
Policy Entropy: 0.68002
Value Function Loss: 0.01832

Mean KL Divergence: 0.00246
SB3 Clip Fraction: 0.01792
Policy Update Magnitude: 0.04807
Value Function Update Magnitude: 0.05110

Collected Steps per Second: 16,676.90848
Overall Steps per Second: 10,413.46688

Timestep Collection Time: 2.99996
Timestep Consumption Time: 1.80440
PPO Batch Consumption Time: 0.33460
Total Iteration Time: 4.80436

Cumulative Model Updates: 84
Cumulative Timesteps: 1,500,748

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04032
Policy Entropy: 0.67852
Value Function Loss: 0.03149

Mean KL Divergence: 0.00216
SB3 Clip Fraction: 0.01049
Policy Update Magnitude: 0.04421
Value Function Update Magnitude: 0.04895

Collected Steps per Second: 20,374.47403
Overall Steps per Second: 12,147.31296

Timestep Collection Time: 2.45503
Timestep Consumption Time: 1.66275
PPO Batch Consumption Time: 0.33107
Total Iteration Time: 4.11778

Cumulative Model Updates: 87
Cumulative Timesteps: 1,550,768

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1550768...
Checkpoint 1550768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.04246
Policy Entropy: 0.67713
Value Function Loss: 0.03845

Mean KL Divergence: 0.00216
SB3 Clip Fraction: 0.01409
Policy Update Magnitude: 0.04396
Value Function Update Magnitude: 0.05037

Collected Steps per Second: 21,362.35057
Overall Steps per Second: 12,323.77414

Timestep Collection Time: 2.34263
Timestep Consumption Time: 1.71814
PPO Batch Consumption Time: 0.33150
Total Iteration Time: 4.06077

Cumulative Model Updates: 90
Cumulative Timesteps: 1,600,812

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05377
Policy Entropy: 0.67712
Value Function Loss: 0.05245

Mean KL Divergence: 0.00200
SB3 Clip Fraction: 0.01166
Policy Update Magnitude: 0.05009
Value Function Update Magnitude: 0.06129

Collected Steps per Second: 20,947.08236
Overall Steps per Second: 12,288.35534

Timestep Collection Time: 2.38773
Timestep Consumption Time: 1.68246
PPO Batch Consumption Time: 0.32770
Total Iteration Time: 4.07019

Cumulative Model Updates: 93
Cumulative Timesteps: 1,650,828

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1650828...
Checkpoint 1650828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.01954
Policy Entropy: 0.67662
Value Function Loss: 0.03071

Mean KL Divergence: 0.00211
SB3 Clip Fraction: 0.01323
Policy Update Magnitude: 0.05126
Value Function Update Magnitude: 0.06021

Collected Steps per Second: 22,120.75755
Overall Steps per Second: 12,594.48761

Timestep Collection Time: 2.26159
Timestep Consumption Time: 1.71063
PPO Batch Consumption Time: 0.32691
Total Iteration Time: 3.97221

Cumulative Model Updates: 96
Cumulative Timesteps: 1,700,856

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.02152
Policy Entropy: 0.67535
Value Function Loss: 0.02909

Mean KL Divergence: 0.00177
SB3 Clip Fraction: 0.00917
Policy Update Magnitude: 0.05359
Value Function Update Magnitude: 0.05859

Collected Steps per Second: 20,672.17016
Overall Steps per Second: 11,951.10791

Timestep Collection Time: 2.42123
Timestep Consumption Time: 1.76684
PPO Batch Consumption Time: 0.32511
Total Iteration Time: 4.18806

Cumulative Model Updates: 99
Cumulative Timesteps: 1,750,908

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


Saving checkpoint 1750908...
Checkpoint 1750908 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02087
Policy Entropy: 0.67066
Value Function Loss: 0.02579

Mean KL Divergence: 0.00213
SB3 Clip Fraction: 0.01123
Policy Update Magnitude: 0.04853
Value Function Update Magnitude: 0.05248

Collected Steps per Second: 21,421.11685
Overall Steps per Second: 12,622.27322

Timestep Collection Time: 2.33452
Timestep Consumption Time: 1.62737
PPO Batch Consumption Time: 0.32832
Total Iteration Time: 3.96189

Cumulative Model Updates: 102
Cumulative Timesteps: 1,800,916

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01876
Policy Entropy: 0.66232
Value Function Loss: 0.02521

Mean KL Divergence: 0.00307
SB3 Clip Fraction: 0.02507
Policy Update Magnitude: 0.04792
Value Function Update Magnitude: 0.05073

Collected Steps per Second: 21,449.65460
Overall Steps per Second: 12,408.38348

Timestep Collection Time: 2.33179
Timestep Consumption Time: 1.69904
PPO Batch Consumption Time: 0.32978
Total Iteration Time: 4.03082

Cumulative Model Updates: 105
Cumulative Timesteps: 1,850,932

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1850932...
Checkpoint 1850932 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00707
Policy Entropy: 0.65680
Value Function Loss: 0.02644

Mean KL Divergence: 0.00270
SB3 Clip Fraction: 0.02041
Policy Update Magnitude: 0.04537
Value Function Update Magnitude: 0.04674

Collected Steps per Second: 19,881.55134
Overall Steps per Second: 11,787.31680

Timestep Collection Time: 2.51711
Timestep Consumption Time: 1.72847
PPO Batch Consumption Time: 0.33891
Total Iteration Time: 4.24558

Cumulative Model Updates: 108
Cumulative Timesteps: 1,900,976

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03892
Policy Entropy: 0.65869
Value Function Loss: 0.03704

Mean KL Divergence: 0.00215
SB3 Clip Fraction: 0.01205
Policy Update Magnitude: 0.04911
Value Function Update Magnitude: 0.04605

Collected Steps per Second: 22,183.93228
Overall Steps per Second: 12,659.48643

Timestep Collection Time: 2.25560
Timestep Consumption Time: 1.69701
PPO Batch Consumption Time: 0.32643
Total Iteration Time: 3.95261

Cumulative Model Updates: 111
Cumulative Timesteps: 1,951,014

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1951014...
Checkpoint 1951014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00337
Policy Entropy: 0.66570
Value Function Loss: 0.05319

Mean KL Divergence: 0.00441
SB3 Clip Fraction: 0.04950
Policy Update Magnitude: 0.05265
Value Function Update Magnitude: 0.06155

Collected Steps per Second: 21,308.69692
Overall Steps per Second: 12,284.51465

Timestep Collection Time: 2.34684
Timestep Consumption Time: 1.72398
PPO Batch Consumption Time: 0.33103
Total Iteration Time: 4.07082

Cumulative Model Updates: 114
Cumulative Timesteps: 2,001,022

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00346
Policy Entropy: 0.67008
Value Function Loss: 0.04791

Mean KL Divergence: 0.00340
SB3 Clip Fraction: 0.03779
Policy Update Magnitude: 0.05278
Value Function Update Magnitude: 0.07054

Collected Steps per Second: 19,643.43038
Overall Steps per Second: 11,745.89711

Timestep Collection Time: 2.54630
Timestep Consumption Time: 1.71204
PPO Batch Consumption Time: 0.33182
Total Iteration Time: 4.25834

Cumulative Model Updates: 117
Cumulative Timesteps: 2,051,040

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2051040...
Checkpoint 2051040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01558
Policy Entropy: 0.67201
Value Function Loss: 0.03473

Mean KL Divergence: 0.00145
SB3 Clip Fraction: 0.00547
Policy Update Magnitude: 0.05249
Value Function Update Magnitude: 0.06059

Collected Steps per Second: 23,845.57547
Overall Steps per Second: 13,077.90540

Timestep Collection Time: 2.09792
Timestep Consumption Time: 1.72731
PPO Batch Consumption Time: 0.33267
Total Iteration Time: 3.82523

Cumulative Model Updates: 120
Cumulative Timesteps: 2,101,066

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2101066...
Checkpoint 2101066 saved!
