Checkpoint loaded!
Learner successfully initialized!
Press (p) to pause (c) to checkpoint, (q) to checkpoint and quit (after next iteration)

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,733.74226
Policy Entropy: 0.67151
Value Function Loss: 0.12480

Mean KL Divergence: 0.00129
SB3 Clip Fraction: 0.01586
Policy Update Magnitude: 0.06751
Value Function Update Magnitude: 0.12759

Collected Steps per Second: 19,709.54884
Overall Steps per Second: 14,944.56922

Timestep Collection Time: 2.53694
Timestep Consumption Time: 0.80889
PPO Batch Consumption Time: 0.13351
Total Iteration Time: 3.34583

Cumulative Model Updates: 52,526
Cumulative Timesteps: 438,218,254

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,263.54416
Policy Entropy: 0.68183
Value Function Loss: 0.12122

Mean KL Divergence: 0.00178
SB3 Clip Fraction: 0.02062
Policy Update Magnitude: 0.07839
Value Function Update Magnitude: 0.12225

Collected Steps per Second: 21,101.48414
Overall Steps per Second: 15,318.18328

Timestep Collection Time: 2.36988
Timestep Consumption Time: 0.89474
PPO Batch Consumption Time: 0.16075
Total Iteration Time: 3.26462

Cumulative Model Updates: 52,528
Cumulative Timesteps: 438,268,262

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 438268262...
Checkpoint 438268262 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,445.51898
Policy Entropy: 0.68737
Value Function Loss: 0.11282

Mean KL Divergence: 0.00390
SB3 Clip Fraction: 0.04626
Policy Update Magnitude: 0.14561
Value Function Update Magnitude: 0.22835

Collected Steps per Second: 20,867.07569
Overall Steps per Second: 14,472.49833

Timestep Collection Time: 2.39641
Timestep Consumption Time: 1.05884
PPO Batch Consumption Time: 0.12038
Total Iteration Time: 3.45524

Cumulative Model Updates: 52,532
Cumulative Timesteps: 438,318,268

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,165.84167
Policy Entropy: 0.70537
Value Function Loss: 0.10086

Mean KL Divergence: 0.00413
SB3 Clip Fraction: 0.04908
Policy Update Magnitude: 0.20659
Value Function Update Magnitude: 0.33931

Collected Steps per Second: 21,678.64322
Overall Steps per Second: 14,283.43977

Timestep Collection Time: 2.30706
Timestep Consumption Time: 1.19447
PPO Batch Consumption Time: 0.10170
Total Iteration Time: 3.50154

Cumulative Model Updates: 52,538
Cumulative Timesteps: 438,368,282

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 438368282...
Checkpoint 438368282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,206.74885
Policy Entropy: 0.69811
Value Function Loss: 0.09320

Mean KL Divergence: 0.00443
SB3 Clip Fraction: 0.05371
Policy Update Magnitude: 0.19270
Value Function Update Magnitude: 0.37971

Collected Steps per Second: 21,532.01644
Overall Steps per Second: 14,422.34650

Timestep Collection Time: 2.32296
Timestep Consumption Time: 1.14513
PPO Batch Consumption Time: 0.09592
Total Iteration Time: 3.46809

Cumulative Model Updates: 52,544
Cumulative Timesteps: 438,418,300

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,642.57032
Policy Entropy: 0.69914
Value Function Loss: 0.10298

Mean KL Divergence: 0.00592
SB3 Clip Fraction: 0.07047
Policy Update Magnitude: 0.18878
Value Function Update Magnitude: 0.39224

Collected Steps per Second: 21,492.78035
Overall Steps per Second: 14,330.05763

Timestep Collection Time: 2.32776
Timestep Consumption Time: 1.16350
PPO Batch Consumption Time: 0.10024
Total Iteration Time: 3.49126

Cumulative Model Updates: 52,550
Cumulative Timesteps: 438,468,330

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 438468330...
Checkpoint 438468330 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,762.11330
Policy Entropy: 0.69282
Value Function Loss: 0.10225

Mean KL Divergence: 0.00569
SB3 Clip Fraction: 0.06591
Policy Update Magnitude: 0.19024
Value Function Update Magnitude: 0.37486

Collected Steps per Second: 21,170.10758
Overall Steps per Second: 14,048.41807

Timestep Collection Time: 2.36314
Timestep Consumption Time: 1.19797
PPO Batch Consumption Time: 0.10029
Total Iteration Time: 3.56111

Cumulative Model Updates: 52,556
Cumulative Timesteps: 438,518,358

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,984.52759
Policy Entropy: 0.69430
Value Function Loss: 0.10495

Mean KL Divergence: 0.00528
SB3 Clip Fraction: 0.06154
Policy Update Magnitude: 0.19754
Value Function Update Magnitude: 0.34441

Collected Steps per Second: 21,830.36238
Overall Steps per Second: 14,444.04600

Timestep Collection Time: 2.29158
Timestep Consumption Time: 1.17185
PPO Batch Consumption Time: 0.10132
Total Iteration Time: 3.46343

Cumulative Model Updates: 52,562
Cumulative Timesteps: 438,568,384

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 438568384...
Checkpoint 438568384 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,100.73568
Policy Entropy: 0.69498
Value Function Loss: 0.09651

Mean KL Divergence: 0.00492
SB3 Clip Fraction: 0.05705
Policy Update Magnitude: 0.18799
Value Function Update Magnitude: 0.34544

Collected Steps per Second: 21,321.76258
Overall Steps per Second: 14,193.48746

Timestep Collection Time: 2.34605
Timestep Consumption Time: 1.17824
PPO Batch Consumption Time: 0.10210
Total Iteration Time: 3.52429

Cumulative Model Updates: 52,568
Cumulative Timesteps: 438,618,406

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,744.34942
Policy Entropy: 0.69697
Value Function Loss: 0.11129

Mean KL Divergence: 0.00467
SB3 Clip Fraction: 0.05549
Policy Update Magnitude: 0.18355
Value Function Update Magnitude: 0.36207

Collected Steps per Second: 21,703.97891
Overall Steps per Second: 14,462.81948

Timestep Collection Time: 2.30419
Timestep Consumption Time: 1.15365
PPO Batch Consumption Time: 0.09623
Total Iteration Time: 3.45783

Cumulative Model Updates: 52,574
Cumulative Timesteps: 438,668,416

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 438668416...
Checkpoint 438668416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,377.73931
Policy Entropy: 0.69482
Value Function Loss: 0.10919

Mean KL Divergence: 0.00412
SB3 Clip Fraction: 0.04965
Policy Update Magnitude: 0.18848
Value Function Update Magnitude: 0.35234

Collected Steps per Second: 21,615.69805
Overall Steps per Second: 14,238.33420

Timestep Collection Time: 2.31489
Timestep Consumption Time: 1.19942
PPO Batch Consumption Time: 0.10090
Total Iteration Time: 3.51432

Cumulative Model Updates: 52,580
Cumulative Timesteps: 438,718,454

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,400.26921
Policy Entropy: 0.69146
Value Function Loss: 0.11571

Mean KL Divergence: 0.00389
SB3 Clip Fraction: 0.04631
Policy Update Magnitude: 0.19217
Value Function Update Magnitude: 0.38852

Collected Steps per Second: 21,550.33966
Overall Steps per Second: 14,458.21720

Timestep Collection Time: 2.32098
Timestep Consumption Time: 1.13850
PPO Batch Consumption Time: 0.09428
Total Iteration Time: 3.45949

Cumulative Model Updates: 52,586
Cumulative Timesteps: 438,768,472

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 438768472...
Checkpoint 438768472 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,175.15006
Policy Entropy: 0.68653
Value Function Loss: 0.10764

Mean KL Divergence: 0.00432
SB3 Clip Fraction: 0.05122
Policy Update Magnitude: 0.18313
Value Function Update Magnitude: 0.40380

Collected Steps per Second: 21,323.45060
Overall Steps per Second: 14,157.52374

Timestep Collection Time: 2.34559
Timestep Consumption Time: 1.18723
PPO Batch Consumption Time: 0.10339
Total Iteration Time: 3.53282

Cumulative Model Updates: 52,592
Cumulative Timesteps: 438,818,488

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,812.72744
Policy Entropy: 0.68805
Value Function Loss: 0.10561

Mean KL Divergence: 0.00737
SB3 Clip Fraction: 0.07808
Policy Update Magnitude: 0.17083
Value Function Update Magnitude: 0.39163

Collected Steps per Second: 22,144.22521
Overall Steps per Second: 14,633.33808

Timestep Collection Time: 2.25892
Timestep Consumption Time: 1.15944
PPO Batch Consumption Time: 0.09797
Total Iteration Time: 3.41836

Cumulative Model Updates: 52,598
Cumulative Timesteps: 438,868,510

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 438868510...
Checkpoint 438868510 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,838.35174
Policy Entropy: 0.68870
Value Function Loss: 0.10684

Mean KL Divergence: 0.00717
SB3 Clip Fraction: 0.07555
Policy Update Magnitude: 0.15419
Value Function Update Magnitude: 0.39497

Collected Steps per Second: 21,594.56884
Overall Steps per Second: 14,304.58527

Timestep Collection Time: 2.31595
Timestep Consumption Time: 1.18027
PPO Batch Consumption Time: 0.10204
Total Iteration Time: 3.49622

Cumulative Model Updates: 52,604
Cumulative Timesteps: 438,918,522

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,411.20831
Policy Entropy: 0.67755
Value Function Loss: 0.11386

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.08856
Policy Update Magnitude: 0.14538
Value Function Update Magnitude: 0.38504

Collected Steps per Second: 21,894.07717
Overall Steps per Second: 14,458.29338

Timestep Collection Time: 2.28400
Timestep Consumption Time: 1.17464
PPO Batch Consumption Time: 0.09802
Total Iteration Time: 3.45864

Cumulative Model Updates: 52,610
Cumulative Timesteps: 438,968,528

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 438968528...
Checkpoint 438968528 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,093.22497
Policy Entropy: 0.67596
Value Function Loss: 0.11673

Mean KL Divergence: 0.00623
SB3 Clip Fraction: 0.06815
Policy Update Magnitude: 0.16366
Value Function Update Magnitude: 0.39323

Collected Steps per Second: 21,102.28679
Overall Steps per Second: 14,128.09172

Timestep Collection Time: 2.37083
Timestep Consumption Time: 1.17034
PPO Batch Consumption Time: 0.10280
Total Iteration Time: 3.54117

Cumulative Model Updates: 52,616
Cumulative Timesteps: 439,018,558

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,028.14654
Policy Entropy: 0.67813
Value Function Loss: 0.10579

Mean KL Divergence: 0.00533
SB3 Clip Fraction: 0.06187
Policy Update Magnitude: 0.18924
Value Function Update Magnitude: 0.40994

Collected Steps per Second: 21,660.72457
Overall Steps per Second: 14,540.45410

Timestep Collection Time: 2.30842
Timestep Consumption Time: 1.13040
PPO Batch Consumption Time: 0.09386
Total Iteration Time: 3.43882

Cumulative Model Updates: 52,622
Cumulative Timesteps: 439,068,560

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 439068560...
Checkpoint 439068560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,829.90389
Policy Entropy: 0.67715
Value Function Loss: 0.09728

Mean KL Divergence: 0.00543
SB3 Clip Fraction: 0.06096
Policy Update Magnitude: 0.19698
Value Function Update Magnitude: 0.43878

Collected Steps per Second: 21,537.97954
Overall Steps per Second: 14,228.73221

Timestep Collection Time: 2.32176
Timestep Consumption Time: 1.19268
PPO Batch Consumption Time: 0.10418
Total Iteration Time: 3.51444

Cumulative Model Updates: 52,628
Cumulative Timesteps: 439,118,566

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,282.95589
Policy Entropy: 0.67628
Value Function Loss: 0.10398

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.08499
Policy Update Magnitude: 0.18646
Value Function Update Magnitude: 0.46535

Collected Steps per Second: 21,983.52541
Overall Steps per Second: 14,622.06540

Timestep Collection Time: 2.27470
Timestep Consumption Time: 1.14520
PPO Batch Consumption Time: 0.09869
Total Iteration Time: 3.41990

Cumulative Model Updates: 52,634
Cumulative Timesteps: 439,168,572

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 439168572...
Checkpoint 439168572 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,762.89501
Policy Entropy: 0.68447
Value Function Loss: 0.10205

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.08062
Policy Update Magnitude: 0.17564
Value Function Update Magnitude: 0.48506

Collected Steps per Second: 21,285.82829
Overall Steps per Second: 14,115.35405

Timestep Collection Time: 2.34992
Timestep Consumption Time: 1.19374
PPO Batch Consumption Time: 0.10354
Total Iteration Time: 3.54366

Cumulative Model Updates: 52,640
Cumulative Timesteps: 439,218,592

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,966.51965
Policy Entropy: 0.68941
Value Function Loss: 0.10054

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.07885
Policy Update Magnitude: 0.17695
Value Function Update Magnitude: 0.46445

Collected Steps per Second: 21,746.40028
Overall Steps per Second: 14,575.29536

Timestep Collection Time: 2.30015
Timestep Consumption Time: 1.13168
PPO Batch Consumption Time: 0.09222
Total Iteration Time: 3.43183

Cumulative Model Updates: 52,646
Cumulative Timesteps: 439,268,612

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 439268612...
Checkpoint 439268612 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,312.77281
Policy Entropy: 0.68053
Value Function Loss: 0.08962

Mean KL Divergence: 0.00477
SB3 Clip Fraction: 0.05515
Policy Update Magnitude: 0.18035
Value Function Update Magnitude: 0.42105

Collected Steps per Second: 21,828.15704
Overall Steps per Second: 14,474.56641

Timestep Collection Time: 2.29099
Timestep Consumption Time: 1.16390
PPO Batch Consumption Time: 0.10053
Total Iteration Time: 3.45489

Cumulative Model Updates: 52,652
Cumulative Timesteps: 439,318,620

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,968.38756
Policy Entropy: 0.68510
Value Function Loss: 0.08874

Mean KL Divergence: 0.00404
SB3 Clip Fraction: 0.04841
Policy Update Magnitude: 0.18481
Value Function Update Magnitude: 0.41993

Collected Steps per Second: 21,332.00906
Overall Steps per Second: 13,955.28906

Timestep Collection Time: 2.34474
Timestep Consumption Time: 1.23942
PPO Batch Consumption Time: 0.10158
Total Iteration Time: 3.58416

Cumulative Model Updates: 52,658
Cumulative Timesteps: 439,368,638

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 439368638...
Checkpoint 439368638 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,776.03195
Policy Entropy: 0.67559
Value Function Loss: 0.08794

Mean KL Divergence: 0.00329
SB3 Clip Fraction: 0.03972
Policy Update Magnitude: 0.18240
Value Function Update Magnitude: 0.44025

Collected Steps per Second: 21,219.72028
Overall Steps per Second: 13,982.51551

Timestep Collection Time: 2.35715
Timestep Consumption Time: 1.22003
PPO Batch Consumption Time: 0.10128
Total Iteration Time: 3.57718

Cumulative Model Updates: 52,664
Cumulative Timesteps: 439,418,656

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,330.00408
Policy Entropy: 0.68082
Value Function Loss: 0.09059

Mean KL Divergence: 0.00396
SB3 Clip Fraction: 0.04783
Policy Update Magnitude: 0.18630
Value Function Update Magnitude: 0.42061

Collected Steps per Second: 22,662.90389
Overall Steps per Second: 14,600.12997

Timestep Collection Time: 2.20713
Timestep Consumption Time: 1.21887
PPO Batch Consumption Time: 0.10002
Total Iteration Time: 3.42600

Cumulative Model Updates: 52,670
Cumulative Timesteps: 439,468,676

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 439468676...
Checkpoint 439468676 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,695.90418
Policy Entropy: 0.67868
Value Function Loss: 0.09990

Mean KL Divergence: 0.00343
SB3 Clip Fraction: 0.04113
Policy Update Magnitude: 0.19350
Value Function Update Magnitude: 0.38498

Collected Steps per Second: 22,071.95549
Overall Steps per Second: 14,181.94509

Timestep Collection Time: 2.26541
Timestep Consumption Time: 1.26034
PPO Batch Consumption Time: 0.10182
Total Iteration Time: 3.52575

Cumulative Model Updates: 52,676
Cumulative Timesteps: 439,518,678

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,842.77149
Policy Entropy: 0.67816
Value Function Loss: 0.10102

Mean KL Divergence: 0.00357
SB3 Clip Fraction: 0.04243
Policy Update Magnitude: 0.19567
Value Function Update Magnitude: 0.38815

Collected Steps per Second: 20,188.45518
Overall Steps per Second: 13,585.33757

Timestep Collection Time: 2.47755
Timestep Consumption Time: 1.20421
PPO Batch Consumption Time: 0.09824
Total Iteration Time: 3.68176

Cumulative Model Updates: 52,682
Cumulative Timesteps: 439,568,696

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 439568696...
Checkpoint 439568696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,192.34178
Policy Entropy: 0.67757
Value Function Loss: 0.09350

Mean KL Divergence: 0.00404
SB3 Clip Fraction: 0.04882
Policy Update Magnitude: 0.18969
Value Function Update Magnitude: 0.40468

Collected Steps per Second: 22,188.17129
Overall Steps per Second: 14,361.98309

Timestep Collection Time: 2.25381
Timestep Consumption Time: 1.22816
PPO Batch Consumption Time: 0.10008
Total Iteration Time: 3.48197

Cumulative Model Updates: 52,688
Cumulative Timesteps: 439,618,704

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,061.99530
Policy Entropy: 0.68568
Value Function Loss: 0.09119

Mean KL Divergence: 0.00396
SB3 Clip Fraction: 0.04723
Policy Update Magnitude: 0.17997
Value Function Update Magnitude: 0.39724

Collected Steps per Second: 22,288.41382
Overall Steps per Second: 14,410.84325

Timestep Collection Time: 2.24386
Timestep Consumption Time: 1.22659
PPO Batch Consumption Time: 0.10101
Total Iteration Time: 3.47044

Cumulative Model Updates: 52,694
Cumulative Timesteps: 439,668,716

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 439668716...
Checkpoint 439668716 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,848.71234
Policy Entropy: 0.67940
Value Function Loss: 0.09082

Mean KL Divergence: 0.00422
SB3 Clip Fraction: 0.05176
Policy Update Magnitude: 0.18689
Value Function Update Magnitude: 0.38616

Collected Steps per Second: 21,630.71697
Overall Steps per Second: 14,038.80450

Timestep Collection Time: 2.31208
Timestep Consumption Time: 1.25033
PPO Batch Consumption Time: 0.10292
Total Iteration Time: 3.56241

Cumulative Model Updates: 52,700
Cumulative Timesteps: 439,718,728

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,433.80241
Policy Entropy: 0.69167
Value Function Loss: 0.08436

Mean KL Divergence: 0.00435
SB3 Clip Fraction: 0.05194
Policy Update Magnitude: 0.18156
Value Function Update Magnitude: 0.39542

Collected Steps per Second: 22,772.91648
Overall Steps per Second: 14,634.86178

Timestep Collection Time: 2.19656
Timestep Consumption Time: 1.22145
PPO Batch Consumption Time: 0.09679
Total Iteration Time: 3.41800

Cumulative Model Updates: 52,706
Cumulative Timesteps: 439,768,750

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 439768750...
Checkpoint 439768750 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,650.80295
Policy Entropy: 0.68206
Value Function Loss: 0.07903

Mean KL Divergence: 0.00345
SB3 Clip Fraction: 0.04054
Policy Update Magnitude: 0.18029
Value Function Update Magnitude: 0.38515

Collected Steps per Second: 21,787.84061
Overall Steps per Second: 14,046.71556

Timestep Collection Time: 2.29623
Timestep Consumption Time: 1.26545
PPO Batch Consumption Time: 0.10123
Total Iteration Time: 3.56169

Cumulative Model Updates: 52,712
Cumulative Timesteps: 439,818,780

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,253.91208
Policy Entropy: 0.68986
Value Function Loss: 0.07906

Mean KL Divergence: 0.00391
SB3 Clip Fraction: 0.04722
Policy Update Magnitude: 0.17600
Value Function Update Magnitude: 0.39562

Collected Steps per Second: 21,249.05761
Overall Steps per Second: 13,888.07429

Timestep Collection Time: 2.35465
Timestep Consumption Time: 1.24801
PPO Batch Consumption Time: 0.09915
Total Iteration Time: 3.60266

Cumulative Model Updates: 52,718
Cumulative Timesteps: 439,868,814

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 439868814...
Checkpoint 439868814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,593.32242
Policy Entropy: 0.68925
Value Function Loss: 0.08007

Mean KL Divergence: 0.00332
SB3 Clip Fraction: 0.04043
Policy Update Magnitude: 0.17714
Value Function Update Magnitude: 0.40332

Collected Steps per Second: 22,377.25259
Overall Steps per Second: 14,320.08480

Timestep Collection Time: 2.23450
Timestep Consumption Time: 1.25724
PPO Batch Consumption Time: 0.10208
Total Iteration Time: 3.49174

Cumulative Model Updates: 52,724
Cumulative Timesteps: 439,918,816

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,091.54082
Policy Entropy: 0.69622
Value Function Loss: 0.08092

Mean KL Divergence: 0.00343
SB3 Clip Fraction: 0.04172
Policy Update Magnitude: 0.17988
Value Function Update Magnitude: 0.39991

Collected Steps per Second: 22,510.07843
Overall Steps per Second: 14,527.37615

Timestep Collection Time: 2.22292
Timestep Consumption Time: 1.22148
PPO Batch Consumption Time: 0.10078
Total Iteration Time: 3.44439

Cumulative Model Updates: 52,730
Cumulative Timesteps: 439,968,854

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 439968854...
Checkpoint 439968854 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,024.58195
Policy Entropy: 0.68948
Value Function Loss: 0.08553

Mean KL Divergence: 0.00404
SB3 Clip Fraction: 0.04836
Policy Update Magnitude: 0.17917
Value Function Update Magnitude: 0.39454

Collected Steps per Second: 22,208.29498
Overall Steps per Second: 14,209.64093

Timestep Collection Time: 2.25186
Timestep Consumption Time: 1.26758
PPO Batch Consumption Time: 0.10149
Total Iteration Time: 3.51944

Cumulative Model Updates: 52,736
Cumulative Timesteps: 440,018,864

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,596.44901
Policy Entropy: 0.67771
Value Function Loss: 0.08549

Mean KL Divergence: 0.00428
SB3 Clip Fraction: 0.05173
Policy Update Magnitude: 0.17532
Value Function Update Magnitude: 0.39786

Collected Steps per Second: 22,612.20444
Overall Steps per Second: 14,540.39685

Timestep Collection Time: 2.21288
Timestep Consumption Time: 1.22843
PPO Batch Consumption Time: 0.10135
Total Iteration Time: 3.44131

Cumulative Model Updates: 52,742
Cumulative Timesteps: 440,068,902

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 440068902...
Checkpoint 440068902 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,281.74337
Policy Entropy: 0.68457
Value Function Loss: 0.09232

Mean KL Divergence: 0.00606
SB3 Clip Fraction: 0.06604
Policy Update Magnitude: 0.17549
Value Function Update Magnitude: 0.38049

Collected Steps per Second: 21,745.39280
Overall Steps per Second: 14,052.75101

Timestep Collection Time: 2.29980
Timestep Consumption Time: 1.25894
PPO Batch Consumption Time: 0.10358
Total Iteration Time: 3.55873

Cumulative Model Updates: 52,748
Cumulative Timesteps: 440,118,912

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,862.01168
Policy Entropy: 0.68441
Value Function Loss: 0.08796

Mean KL Divergence: 0.00647
SB3 Clip Fraction: 0.06549
Policy Update Magnitude: 0.17216
Value Function Update Magnitude: 0.38150

Collected Steps per Second: 22,552.46487
Overall Steps per Second: 14,536.26332

Timestep Collection Time: 2.21785
Timestep Consumption Time: 1.22306
PPO Batch Consumption Time: 0.09112
Total Iteration Time: 3.44091

Cumulative Model Updates: 52,754
Cumulative Timesteps: 440,168,930

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 440168930...
Checkpoint 440168930 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,320.19745
Policy Entropy: 0.69369
Value Function Loss: 0.09024

Mean KL Divergence: 0.00592
SB3 Clip Fraction: 0.06335
Policy Update Magnitude: 0.17371
Value Function Update Magnitude: 0.41465

Collected Steps per Second: 22,549.86490
Overall Steps per Second: 14,479.84622

Timestep Collection Time: 2.21828
Timestep Consumption Time: 1.23631
PPO Batch Consumption Time: 0.10137
Total Iteration Time: 3.45459

Cumulative Model Updates: 52,760
Cumulative Timesteps: 440,218,952

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,027.42524
Policy Entropy: 0.68832
Value Function Loss: 0.09522

Mean KL Divergence: 0.00613
SB3 Clip Fraction: 0.06352
Policy Update Magnitude: 0.18539
Value Function Update Magnitude: 0.38806

Collected Steps per Second: 22,246.02895
Overall Steps per Second: 14,399.22067

Timestep Collection Time: 2.24885
Timestep Consumption Time: 1.22550
PPO Batch Consumption Time: 0.09779
Total Iteration Time: 3.47435

Cumulative Model Updates: 52,766
Cumulative Timesteps: 440,268,980

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 440268980...
Checkpoint 440268980 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,391.25239
Policy Entropy: 0.68702
Value Function Loss: 0.10026

Mean KL Divergence: 0.00499
SB3 Clip Fraction: 0.05539
Policy Update Magnitude: 0.19183
Value Function Update Magnitude: 0.39843

Collected Steps per Second: 22,388.64448
Overall Steps per Second: 14,355.32572

Timestep Collection Time: 2.23327
Timestep Consumption Time: 1.24975
PPO Batch Consumption Time: 0.10096
Total Iteration Time: 3.48303

Cumulative Model Updates: 52,772
Cumulative Timesteps: 440,318,980

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,300.79549
Policy Entropy: 0.67527
Value Function Loss: 0.09754

Mean KL Divergence: 0.00559
SB3 Clip Fraction: 0.06249
Policy Update Magnitude: 0.18111
Value Function Update Magnitude: 0.35084

Collected Steps per Second: 22,863.45712
Overall Steps per Second: 14,636.21930

Timestep Collection Time: 2.18716
Timestep Consumption Time: 1.22943
PPO Batch Consumption Time: 0.10063
Total Iteration Time: 3.41659

Cumulative Model Updates: 52,778
Cumulative Timesteps: 440,368,986

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 440368986...
Checkpoint 440368986 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,064.49621
Policy Entropy: 0.68572
Value Function Loss: 0.09816

Mean KL Divergence: 0.00507
SB3 Clip Fraction: 0.06132
Policy Update Magnitude: 0.16946
Value Function Update Magnitude: 0.33145

Collected Steps per Second: 22,135.78512
Overall Steps per Second: 14,195.92994

Timestep Collection Time: 2.25996
Timestep Consumption Time: 1.26401
PPO Batch Consumption Time: 0.10165
Total Iteration Time: 3.52397

Cumulative Model Updates: 52,784
Cumulative Timesteps: 440,419,012

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,815.86633
Policy Entropy: 0.69373
Value Function Loss: 0.09365

Mean KL Divergence: 0.00423
SB3 Clip Fraction: 0.05090
Policy Update Magnitude: 0.17683
Value Function Update Magnitude: 0.34691

Collected Steps per Second: 22,010.84046
Overall Steps per Second: 14,287.99464

Timestep Collection Time: 2.27324
Timestep Consumption Time: 1.22872
PPO Batch Consumption Time: 0.09675
Total Iteration Time: 3.50196

Cumulative Model Updates: 52,790
Cumulative Timesteps: 440,469,048

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 440469048...
Checkpoint 440469048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,961.52904
Policy Entropy: 0.70509
Value Function Loss: 0.08548

Mean KL Divergence: 0.00373
SB3 Clip Fraction: 0.04496
Policy Update Magnitude: 0.17911
Value Function Update Magnitude: 0.36001

Collected Steps per Second: 22,400.07853
Overall Steps per Second: 14,288.23546

Timestep Collection Time: 2.23294
Timestep Consumption Time: 1.26770
PPO Batch Consumption Time: 0.10031
Total Iteration Time: 3.50064

Cumulative Model Updates: 52,796
Cumulative Timesteps: 440,519,066

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,319.51771
Policy Entropy: 0.69757
Value Function Loss: 0.07848

Mean KL Divergence: 0.00486
SB3 Clip Fraction: 0.05803
Policy Update Magnitude: 0.16881
Value Function Update Magnitude: 0.38754

Collected Steps per Second: 22,398.07432
Overall Steps per Second: 14,471.43084

Timestep Collection Time: 2.23323
Timestep Consumption Time: 1.22324
PPO Batch Consumption Time: 0.09802
Total Iteration Time: 3.45647

Cumulative Model Updates: 52,802
Cumulative Timesteps: 440,569,086

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 440569086...
Checkpoint 440569086 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,805.01716
Policy Entropy: 0.70317
Value Function Loss: 0.07982

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.07933
Policy Update Magnitude: 0.15822
Value Function Update Magnitude: 0.37993

Collected Steps per Second: 21,877.01556
Overall Steps per Second: 14,046.67440

Timestep Collection Time: 2.28550
Timestep Consumption Time: 1.27406
PPO Batch Consumption Time: 0.10022
Total Iteration Time: 3.55956

Cumulative Model Updates: 52,808
Cumulative Timesteps: 440,619,086

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,357.02547
Policy Entropy: 0.69217
Value Function Loss: 0.08029

Mean KL Divergence: 0.00649
SB3 Clip Fraction: 0.06796
Policy Update Magnitude: 0.15679
Value Function Update Magnitude: 0.38037

Collected Steps per Second: 22,963.63597
Overall Steps per Second: 14,736.09850

Timestep Collection Time: 2.17797
Timestep Consumption Time: 1.21601
PPO Batch Consumption Time: 0.09767
Total Iteration Time: 3.39398

Cumulative Model Updates: 52,814
Cumulative Timesteps: 440,669,100

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 440669100...
Checkpoint 440669100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,320.28993
Policy Entropy: 0.69823
Value Function Loss: 0.07584

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.08300
Policy Update Magnitude: 0.15450
Value Function Update Magnitude: 0.37723

Collected Steps per Second: 22,243.86241
Overall Steps per Second: 14,136.44368

Timestep Collection Time: 2.24808
Timestep Consumption Time: 1.28930
PPO Batch Consumption Time: 0.10383
Total Iteration Time: 3.53738

Cumulative Model Updates: 52,820
Cumulative Timesteps: 440,719,106

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,943.87660
Policy Entropy: 0.68233
Value Function Loss: 0.07689

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.07590
Policy Update Magnitude: 0.15514
Value Function Update Magnitude: 0.38826

Collected Steps per Second: 22,778.63345
Overall Steps per Second: 14,622.84379

Timestep Collection Time: 2.19548
Timestep Consumption Time: 1.22451
PPO Batch Consumption Time: 0.09943
Total Iteration Time: 3.41999

Cumulative Model Updates: 52,826
Cumulative Timesteps: 440,769,116

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 440769116...
Checkpoint 440769116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,448.51904
Policy Entropy: 0.68038
Value Function Loss: 0.07751

Mean KL Divergence: 0.00752
SB3 Clip Fraction: 0.07266
Policy Update Magnitude: 0.16551
Value Function Update Magnitude: 0.39179

Collected Steps per Second: 22,678.51934
Overall Steps per Second: 14,786.49501

Timestep Collection Time: 2.20614
Timestep Consumption Time: 1.17749
PPO Batch Consumption Time: 0.09505
Total Iteration Time: 3.38363

Cumulative Model Updates: 52,832
Cumulative Timesteps: 440,819,148

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,681.26157
Policy Entropy: 0.69004
Value Function Loss: 0.08333

Mean KL Divergence: 0.00735
SB3 Clip Fraction: 0.07318
Policy Update Magnitude: 0.17006
Value Function Update Magnitude: 0.38506

Collected Steps per Second: 21,987.48637
Overall Steps per Second: 14,090.03488

Timestep Collection Time: 2.27411
Timestep Consumption Time: 1.27464
PPO Batch Consumption Time: 0.10360
Total Iteration Time: 3.54875

Cumulative Model Updates: 52,838
Cumulative Timesteps: 440,869,150

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 440869150...
Checkpoint 440869150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,087.28088
Policy Entropy: 0.69666
Value Function Loss: 0.08451

Mean KL Divergence: 0.00630
SB3 Clip Fraction: 0.06593
Policy Update Magnitude: 0.17568
Value Function Update Magnitude: 0.39856

Collected Steps per Second: 22,352.41867
Overall Steps per Second: 14,256.10690

Timestep Collection Time: 2.23761
Timestep Consumption Time: 1.27078
PPO Batch Consumption Time: 0.10152
Total Iteration Time: 3.50839

Cumulative Model Updates: 52,844
Cumulative Timesteps: 440,919,166

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,251.87366
Policy Entropy: 0.70552
Value Function Loss: 0.08721

Mean KL Divergence: 0.00658
SB3 Clip Fraction: 0.07170
Policy Update Magnitude: 0.17024
Value Function Update Magnitude: 0.40960

Collected Steps per Second: 22,589.27525
Overall Steps per Second: 14,438.16968

Timestep Collection Time: 2.21494
Timestep Consumption Time: 1.25045
PPO Batch Consumption Time: 0.10163
Total Iteration Time: 3.46540

Cumulative Model Updates: 52,850
Cumulative Timesteps: 440,969,200

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 440969200...
Checkpoint 440969200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,593.30220
Policy Entropy: 0.70933
Value Function Loss: 0.08852

Mean KL Divergence: 0.00692
SB3 Clip Fraction: 0.07176
Policy Update Magnitude: 0.17000
Value Function Update Magnitude: 0.40718

Collected Steps per Second: 22,282.17508
Overall Steps per Second: 14,273.96878

Timestep Collection Time: 2.24502
Timestep Consumption Time: 1.25954
PPO Batch Consumption Time: 0.10129
Total Iteration Time: 3.50456

Cumulative Model Updates: 52,856
Cumulative Timesteps: 441,019,224

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,404.00647
Policy Entropy: 0.71005
Value Function Loss: 0.08097

Mean KL Divergence: 0.00540
SB3 Clip Fraction: 0.05827
Policy Update Magnitude: 0.18368
Value Function Update Magnitude: 0.42231

Collected Steps per Second: 22,726.12490
Overall Steps per Second: 14,463.94573

Timestep Collection Time: 2.20178
Timestep Consumption Time: 1.25772
PPO Batch Consumption Time: 0.09943
Total Iteration Time: 3.45950

Cumulative Model Updates: 52,862
Cumulative Timesteps: 441,069,262

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 441069262...
Checkpoint 441069262 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,867.19068
Policy Entropy: 0.70671
Value Function Loss: 0.08149

Mean KL Divergence: 0.00479
SB3 Clip Fraction: 0.05407
Policy Update Magnitude: 0.18058
Value Function Update Magnitude: 0.42559

Collected Steps per Second: 22,381.55495
Overall Steps per Second: 14,358.06311

Timestep Collection Time: 2.23488
Timestep Consumption Time: 1.24888
PPO Batch Consumption Time: 0.10225
Total Iteration Time: 3.48376

Cumulative Model Updates: 52,868
Cumulative Timesteps: 441,119,282

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,068.48871
Policy Entropy: 0.70621
Value Function Loss: 0.07896

Mean KL Divergence: 0.00458
SB3 Clip Fraction: 0.05381
Policy Update Magnitude: 0.18032
Value Function Update Magnitude: 0.42725

Collected Steps per Second: 22,140.51084
Overall Steps per Second: 14,302.22823

Timestep Collection Time: 2.25912
Timestep Consumption Time: 1.23810
PPO Batch Consumption Time: 0.09631
Total Iteration Time: 3.49722

Cumulative Model Updates: 52,874
Cumulative Timesteps: 441,169,300

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 441169300...
Checkpoint 441169300 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,091.17685
Policy Entropy: 0.69875
Value Function Loss: 0.08035

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.08308
Policy Update Magnitude: 0.16971
Value Function Update Magnitude: 0.40086

Collected Steps per Second: 22,328.76592
Overall Steps per Second: 14,165.96581

Timestep Collection Time: 2.24025
Timestep Consumption Time: 1.29089
PPO Batch Consumption Time: 0.10369
Total Iteration Time: 3.53114

Cumulative Model Updates: 52,880
Cumulative Timesteps: 441,219,322

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,689.01639
Policy Entropy: 0.69812
Value Function Loss: 0.09641

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.08008
Policy Update Magnitude: 0.15189
Value Function Update Magnitude: 0.37455

Collected Steps per Second: 23,020.84077
Overall Steps per Second: 14,712.43588

Timestep Collection Time: 2.17194
Timestep Consumption Time: 1.22654
PPO Batch Consumption Time: 0.10275
Total Iteration Time: 3.39849

Cumulative Model Updates: 52,886
Cumulative Timesteps: 441,269,322

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 441269322...
Checkpoint 441269322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,888.89065
Policy Entropy: 0.69243
Value Function Loss: 0.09174

Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.07978
Policy Update Magnitude: 0.16331
Value Function Update Magnitude: 0.38315

Collected Steps per Second: 22,362.84444
Overall Steps per Second: 14,663.41833

Timestep Collection Time: 2.23603
Timestep Consumption Time: 1.17409
PPO Batch Consumption Time: 0.09185
Total Iteration Time: 3.41012

Cumulative Model Updates: 52,892
Cumulative Timesteps: 441,319,326

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,142.78272
Policy Entropy: 0.68998
Value Function Loss: 0.09329

Mean KL Divergence: 0.00592
SB3 Clip Fraction: 0.06771
Policy Update Magnitude: 0.17314
Value Function Update Magnitude: 0.37928

Collected Steps per Second: 22,865.78499
Overall Steps per Second: 14,482.48868

Timestep Collection Time: 2.18676
Timestep Consumption Time: 1.26582
PPO Batch Consumption Time: 0.10035
Total Iteration Time: 3.45258

Cumulative Model Updates: 52,898
Cumulative Timesteps: 441,369,328

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 441369328...
Checkpoint 441369328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,540.83195
Policy Entropy: 0.69298
Value Function Loss: 0.08081

Mean KL Divergence: 0.00564
SB3 Clip Fraction: 0.06421
Policy Update Magnitude: 0.17380
Value Function Update Magnitude: 0.38733

Collected Steps per Second: 22,423.20516
Overall Steps per Second: 14,409.81838

Timestep Collection Time: 2.23081
Timestep Consumption Time: 1.24057
PPO Batch Consumption Time: 0.09814
Total Iteration Time: 3.47138

Cumulative Model Updates: 52,904
Cumulative Timesteps: 441,419,350

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,678.96051
Policy Entropy: 0.69840
Value Function Loss: 0.07987

Mean KL Divergence: 0.00522
SB3 Clip Fraction: 0.06242
Policy Update Magnitude: 0.17092
Value Function Update Magnitude: 0.38867

Collected Steps per Second: 22,100.07061
Overall Steps per Second: 14,170.19507

Timestep Collection Time: 2.26280
Timestep Consumption Time: 1.26630
PPO Batch Consumption Time: 0.10157
Total Iteration Time: 3.52910

Cumulative Model Updates: 52,910
Cumulative Timesteps: 441,469,358

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 441469358...
Checkpoint 441469358 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,749.46260
Policy Entropy: 0.69988
Value Function Loss: 0.08423

Mean KL Divergence: 0.00526
SB3 Clip Fraction: 0.06099
Policy Update Magnitude: 0.17019
Value Function Update Magnitude: 0.39848

Collected Steps per Second: 22,886.30083
Overall Steps per Second: 14,504.89838

Timestep Collection Time: 2.18506
Timestep Consumption Time: 1.26260
PPO Batch Consumption Time: 0.09761
Total Iteration Time: 3.44766

Cumulative Model Updates: 52,916
Cumulative Timesteps: 441,519,366

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,388.23524
Policy Entropy: 0.70083
Value Function Loss: 0.08912

Mean KL Divergence: 0.00365
SB3 Clip Fraction: 0.04354
Policy Update Magnitude: 0.17739
Value Function Update Magnitude: 0.38702

Collected Steps per Second: 22,867.74778
Overall Steps per Second: 14,729.47466

Timestep Collection Time: 2.18745
Timestep Consumption Time: 1.20860
PPO Batch Consumption Time: 0.09707
Total Iteration Time: 3.39605

Cumulative Model Updates: 52,922
Cumulative Timesteps: 441,569,388

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 441569388...
Checkpoint 441569388 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,001.27467
Policy Entropy: 0.69858
Value Function Loss: 0.09690

Mean KL Divergence: 0.00527
SB3 Clip Fraction: 0.05961
Policy Update Magnitude: 0.18022
Value Function Update Magnitude: 0.40150

Collected Steps per Second: 22,244.91678
Overall Steps per Second: 14,147.25488

Timestep Collection Time: 2.24968
Timestep Consumption Time: 1.28768
PPO Batch Consumption Time: 0.10268
Total Iteration Time: 3.53736

Cumulative Model Updates: 52,928
Cumulative Timesteps: 441,619,432

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,397.81249
Policy Entropy: 0.69052
Value Function Loss: 0.08928

Mean KL Divergence: 0.00687
SB3 Clip Fraction: 0.07221
Policy Update Magnitude: 0.16223
Value Function Update Magnitude: 0.41955

Collected Steps per Second: 23,030.12438
Overall Steps per Second: 14,638.56747

Timestep Collection Time: 2.17255
Timestep Consumption Time: 1.24541
PPO Batch Consumption Time: 0.09718
Total Iteration Time: 3.41796

Cumulative Model Updates: 52,934
Cumulative Timesteps: 441,669,466

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 441669466...
Checkpoint 441669466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,624.21330
Policy Entropy: 0.69300
Value Function Loss: 0.08329

Mean KL Divergence: 0.00495
SB3 Clip Fraction: 0.05503
Policy Update Magnitude: 0.15898
Value Function Update Magnitude: 0.42336

Collected Steps per Second: 22,285.93422
Overall Steps per Second: 14,325.01157

Timestep Collection Time: 2.24482
Timestep Consumption Time: 1.24753
PPO Batch Consumption Time: 0.10112
Total Iteration Time: 3.49235

Cumulative Model Updates: 52,940
Cumulative Timesteps: 441,719,494

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,805.06520
Policy Entropy: 0.69652
Value Function Loss: 0.07477

Mean KL Divergence: 0.00354
SB3 Clip Fraction: 0.04304
Policy Update Magnitude: 0.16940
Value Function Update Magnitude: 0.39483

Collected Steps per Second: 22,634.67878
Overall Steps per Second: 14,497.89206

Timestep Collection Time: 2.21068
Timestep Consumption Time: 1.24072
PPO Batch Consumption Time: 0.09836
Total Iteration Time: 3.45140

Cumulative Model Updates: 52,946
Cumulative Timesteps: 441,769,532

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 441769532...
Checkpoint 441769532 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,874.46560
Policy Entropy: 0.70984
Value Function Loss: 0.07207

Mean KL Divergence: 0.00334
SB3 Clip Fraction: 0.04083
Policy Update Magnitude: 0.16609
Value Function Update Magnitude: 0.37289

Collected Steps per Second: 22,689.38327
Overall Steps per Second: 14,331.88996

Timestep Collection Time: 2.20438
Timestep Consumption Time: 1.28546
PPO Batch Consumption Time: 0.10158
Total Iteration Time: 3.48984

Cumulative Model Updates: 52,952
Cumulative Timesteps: 441,819,548

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,360.87543
Policy Entropy: 0.70591
Value Function Loss: 0.08098

Mean KL Divergence: 0.00379
SB3 Clip Fraction: 0.04458
Policy Update Magnitude: 0.16893
Value Function Update Magnitude: 0.35777

Collected Steps per Second: 22,871.98083
Overall Steps per Second: 14,630.03021

Timestep Collection Time: 2.18713
Timestep Consumption Time: 1.23214
PPO Batch Consumption Time: 0.10051
Total Iteration Time: 3.41927

Cumulative Model Updates: 52,958
Cumulative Timesteps: 441,869,572

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 441869572...
Checkpoint 441869572 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,559.64875
Policy Entropy: 0.70512
Value Function Loss: 0.08178

Mean KL Divergence: 0.00364
SB3 Clip Fraction: 0.04216
Policy Update Magnitude: 0.17393
Value Function Update Magnitude: 0.37205

Collected Steps per Second: 22,026.76340
Overall Steps per Second: 14,497.34122

Timestep Collection Time: 2.27115
Timestep Consumption Time: 1.17956
PPO Batch Consumption Time: 0.09156
Total Iteration Time: 3.45070

Cumulative Model Updates: 52,964
Cumulative Timesteps: 441,919,598

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,803.82477
Policy Entropy: 0.69533
Value Function Loss: 0.08642

Mean KL Divergence: 0.00458
SB3 Clip Fraction: 0.05314
Policy Update Magnitude: 0.17152
Value Function Update Magnitude: 0.37120

Collected Steps per Second: 22,739.84540
Overall Steps per Second: 14,362.54594

Timestep Collection Time: 2.19958
Timestep Consumption Time: 1.28296
PPO Batch Consumption Time: 0.10216
Total Iteration Time: 3.48253

Cumulative Model Updates: 52,970
Cumulative Timesteps: 441,969,616

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 441969616...
Checkpoint 441969616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,577.73784
Policy Entropy: 0.69429
Value Function Loss: 0.07996

Mean KL Divergence: 0.00317
SB3 Clip Fraction: 0.03906
Policy Update Magnitude: 0.17423
Value Function Update Magnitude: 0.34554

Collected Steps per Second: 22,491.18965
Overall Steps per Second: 14,582.86923

Timestep Collection Time: 2.22452
Timestep Consumption Time: 1.20636
PPO Batch Consumption Time: 0.09965
Total Iteration Time: 3.43087

Cumulative Model Updates: 52,976
Cumulative Timesteps: 442,019,648

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,836.84275
Policy Entropy: 0.70039
Value Function Loss: 0.07979

Mean KL Divergence: 0.00390
SB3 Clip Fraction: 0.04621
Policy Update Magnitude: 0.17112
Value Function Update Magnitude: 0.38191

Collected Steps per Second: 22,551.36857
Overall Steps per Second: 14,600.86884

Timestep Collection Time: 2.21938
Timestep Consumption Time: 1.20850
PPO Batch Consumption Time: 0.09413
Total Iteration Time: 3.42788

Cumulative Model Updates: 52,982
Cumulative Timesteps: 442,069,698

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 442069698...
Checkpoint 442069698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,516.27193
Policy Entropy: 0.70253
Value Function Loss: 0.08132

Mean KL Divergence: 0.00541
SB3 Clip Fraction: 0.06146
Policy Update Magnitude: 0.16316
Value Function Update Magnitude: 0.39424

Collected Steps per Second: 22,621.62585
Overall Steps per Second: 14,455.89613

Timestep Collection Time: 2.21045
Timestep Consumption Time: 1.24862
PPO Batch Consumption Time: 0.10156
Total Iteration Time: 3.45907

Cumulative Model Updates: 52,988
Cumulative Timesteps: 442,119,702

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,707.47902
Policy Entropy: 0.69740
Value Function Loss: 0.08555

Mean KL Divergence: 0.00541
SB3 Clip Fraction: 0.06055
Policy Update Magnitude: 0.17383
Value Function Update Magnitude: 0.42279

Collected Steps per Second: 22,817.76190
Overall Steps per Second: 14,565.67669

Timestep Collection Time: 2.19250
Timestep Consumption Time: 1.24215
PPO Batch Consumption Time: 0.10114
Total Iteration Time: 3.43465

Cumulative Model Updates: 52,994
Cumulative Timesteps: 442,169,730

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 442169730...
Checkpoint 442169730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,535.88744
Policy Entropy: 0.69586
Value Function Loss: 0.08844

Mean KL Divergence: 0.00451
SB3 Clip Fraction: 0.05082
Policy Update Magnitude: 0.18260
Value Function Update Magnitude: 0.43440

Collected Steps per Second: 22,036.09499
Overall Steps per Second: 14,186.13866

Timestep Collection Time: 2.26937
Timestep Consumption Time: 1.25576
PPO Batch Consumption Time: 0.10172
Total Iteration Time: 3.52513

Cumulative Model Updates: 53,000
Cumulative Timesteps: 442,219,738

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,116.49270
Policy Entropy: 0.70329
Value Function Loss: 0.09201

Mean KL Divergence: 0.00411
SB3 Clip Fraction: 0.04691
Policy Update Magnitude: 0.19116
Value Function Update Magnitude: 0.42946

Collected Steps per Second: 22,555.14388
Overall Steps per Second: 14,386.02816

Timestep Collection Time: 2.21688
Timestep Consumption Time: 1.25886
PPO Batch Consumption Time: 0.09810
Total Iteration Time: 3.47573

Cumulative Model Updates: 53,006
Cumulative Timesteps: 442,269,740

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 442269740...
Checkpoint 442269740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,090.59713
Policy Entropy: 0.70580
Value Function Loss: 0.09512

Mean KL Divergence: 0.00374
SB3 Clip Fraction: 0.04456
Policy Update Magnitude: 0.19042
Value Function Update Magnitude: 0.43553

Collected Steps per Second: 22,042.10379
Overall Steps per Second: 14,084.00177

Timestep Collection Time: 2.26911
Timestep Consumption Time: 1.28215
PPO Batch Consumption Time: 0.10339
Total Iteration Time: 3.55126

Cumulative Model Updates: 53,012
Cumulative Timesteps: 442,319,756

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,681.46746
Policy Entropy: 0.70413
Value Function Loss: 0.09666

Mean KL Divergence: 0.00361
SB3 Clip Fraction: 0.04226
Policy Update Magnitude: 0.18456
Value Function Update Magnitude: 0.45705

Collected Steps per Second: 22,049.73205
Overall Steps per Second: 14,295.90115

Timestep Collection Time: 2.26869
Timestep Consumption Time: 1.23050
PPO Batch Consumption Time: 0.09937
Total Iteration Time: 3.49918

Cumulative Model Updates: 53,018
Cumulative Timesteps: 442,369,780

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 442369780...
Checkpoint 442369780 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,574.33058
Policy Entropy: 0.69785
Value Function Loss: 0.08717

Mean KL Divergence: 0.00428
SB3 Clip Fraction: 0.05132
Policy Update Magnitude: 0.18450
Value Function Update Magnitude: 0.43628

Collected Steps per Second: 22,452.07891
Overall Steps per Second: 14,309.90500

Timestep Collection Time: 2.22768
Timestep Consumption Time: 1.26752
PPO Batch Consumption Time: 0.09811
Total Iteration Time: 3.49520

Cumulative Model Updates: 53,024
Cumulative Timesteps: 442,419,796

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,342.75158
Policy Entropy: 0.70188
Value Function Loss: 0.08661

Mean KL Divergence: 0.00418
SB3 Clip Fraction: 0.05044
Policy Update Magnitude: 0.18326
Value Function Update Magnitude: 0.43341

Collected Steps per Second: 21,431.73448
Overall Steps per Second: 14,015.52889

Timestep Collection Time: 2.33364
Timestep Consumption Time: 1.23483
PPO Batch Consumption Time: 0.10146
Total Iteration Time: 3.56847

Cumulative Model Updates: 53,030
Cumulative Timesteps: 442,469,810

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 442469810...
Checkpoint 442469810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,640.28468
Policy Entropy: 0.71045
Value Function Loss: 0.08564

Mean KL Divergence: 0.00405
SB3 Clip Fraction: 0.04901
Policy Update Magnitude: 0.18076
Value Function Update Magnitude: 0.41949

Collected Steps per Second: 22,360.76967
Overall Steps per Second: 14,342.64772

Timestep Collection Time: 2.23651
Timestep Consumption Time: 1.25030
PPO Batch Consumption Time: 0.10027
Total Iteration Time: 3.48680

Cumulative Model Updates: 53,036
Cumulative Timesteps: 442,519,820

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,753.51925
Policy Entropy: 0.70675
Value Function Loss: 0.09173

Mean KL Divergence: 0.00423
SB3 Clip Fraction: 0.05149
Policy Update Magnitude: 0.18483
Value Function Update Magnitude: 0.41877

Collected Steps per Second: 22,731.86516
Overall Steps per Second: 14,606.53387

Timestep Collection Time: 2.20026
Timestep Consumption Time: 1.22396
PPO Batch Consumption Time: 0.10119
Total Iteration Time: 3.42422

Cumulative Model Updates: 53,042
Cumulative Timesteps: 442,569,836

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 442569836...
Checkpoint 442569836 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,143.08548
Policy Entropy: 0.72237
Value Function Loss: 0.09515

Mean KL Divergence: 0.00406
SB3 Clip Fraction: 0.04830
Policy Update Magnitude: 0.18991
Value Function Update Magnitude: 0.42422

Collected Steps per Second: 22,654.71641
Overall Steps per Second: 14,575.81574

Timestep Collection Time: 2.20872
Timestep Consumption Time: 1.22422
PPO Batch Consumption Time: 0.09614
Total Iteration Time: 3.43295

Cumulative Model Updates: 53,048
Cumulative Timesteps: 442,619,874

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,820.71151
Policy Entropy: 0.72242
Value Function Loss: 0.09346

Mean KL Divergence: 0.00429
SB3 Clip Fraction: 0.05141
Policy Update Magnitude: 0.18677
Value Function Update Magnitude: 0.40368

Collected Steps per Second: 22,265.31501
Overall Steps per Second: 14,312.84654

Timestep Collection Time: 2.24565
Timestep Consumption Time: 1.24772
PPO Batch Consumption Time: 0.10248
Total Iteration Time: 3.49337

Cumulative Model Updates: 53,054
Cumulative Timesteps: 442,669,874

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 442669874...
Checkpoint 442669874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,685.57368
Policy Entropy: 0.72513
Value Function Loss: 0.09546

Mean KL Divergence: 0.00416
SB3 Clip Fraction: 0.05150
Policy Update Magnitude: 0.18631
Value Function Update Magnitude: 0.39832

Collected Steps per Second: 22,810.22293
Overall Steps per Second: 14,561.51050

Timestep Collection Time: 2.19253
Timestep Consumption Time: 1.24201
PPO Batch Consumption Time: 0.10190
Total Iteration Time: 3.43453

Cumulative Model Updates: 53,060
Cumulative Timesteps: 442,719,886

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,439.00977
Policy Entropy: 0.71421
Value Function Loss: 0.09241

Mean KL Divergence: 0.00474
SB3 Clip Fraction: 0.05676
Policy Update Magnitude: 0.18345
Value Function Update Magnitude: 0.41276

Collected Steps per Second: 23,142.62628
Overall Steps per Second: 14,656.36350

Timestep Collection Time: 2.16060
Timestep Consumption Time: 1.25102
PPO Batch Consumption Time: 0.09783
Total Iteration Time: 3.41162

Cumulative Model Updates: 53,066
Cumulative Timesteps: 442,769,888

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 442769888...
Checkpoint 442769888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,970.85123
Policy Entropy: 0.72322
Value Function Loss: 0.07776

Mean KL Divergence: 0.00468
SB3 Clip Fraction: 0.05393
Policy Update Magnitude: 0.17542
Value Function Update Magnitude: 0.40519

Collected Steps per Second: 22,103.52286
Overall Steps per Second: 14,121.23556

Timestep Collection Time: 2.26398
Timestep Consumption Time: 1.27976
PPO Batch Consumption Time: 0.10368
Total Iteration Time: 3.54374

Cumulative Model Updates: 53,072
Cumulative Timesteps: 442,819,930

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,662.56694
Policy Entropy: 0.72824
Value Function Loss: 0.07820

Mean KL Divergence: 0.00407
SB3 Clip Fraction: 0.04873
Policy Update Magnitude: 0.17031
Value Function Update Magnitude: 0.39049

Collected Steps per Second: 23,023.31455
Overall Steps per Second: 14,666.55126

Timestep Collection Time: 2.17180
Timestep Consumption Time: 1.23746
PPO Batch Consumption Time: 0.09984
Total Iteration Time: 3.40925

Cumulative Model Updates: 53,078
Cumulative Timesteps: 442,869,932

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 442869932...
Checkpoint 442869932 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,407.98271
Policy Entropy: 0.72780
Value Function Loss: 0.08106

Mean KL Divergence: 0.00715
SB3 Clip Fraction: 0.07353
Policy Update Magnitude: 0.16842
Value Function Update Magnitude: 0.39310

Collected Steps per Second: 22,638.18941
Overall Steps per Second: 14,720.58360

Timestep Collection Time: 2.20981
Timestep Consumption Time: 1.18857
PPO Batch Consumption Time: 0.09349
Total Iteration Time: 3.39837

Cumulative Model Updates: 53,084
Cumulative Timesteps: 442,919,958

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,055.19084
Policy Entropy: 0.72160
Value Function Loss: 0.09322

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.07796
Policy Update Magnitude: 0.15835
Value Function Update Magnitude: 0.38919

Collected Steps per Second: 22,485.58177
Overall Steps per Second: 14,350.90469

Timestep Collection Time: 2.22489
Timestep Consumption Time: 1.26116
PPO Batch Consumption Time: 0.10121
Total Iteration Time: 3.48605

Cumulative Model Updates: 53,090
Cumulative Timesteps: 442,969,986

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 442969986...
Checkpoint 442969986 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,015.53373
Policy Entropy: 0.73702
Value Function Loss: 0.09077

Mean KL Divergence: 0.00630
SB3 Clip Fraction: 0.06621
Policy Update Magnitude: 0.17098
Value Function Update Magnitude: 0.39845

Collected Steps per Second: 22,706.99840
Overall Steps per Second: 14,557.65131

Timestep Collection Time: 2.20240
Timestep Consumption Time: 1.23290
PPO Batch Consumption Time: 0.10209
Total Iteration Time: 3.43531

Cumulative Model Updates: 53,096
Cumulative Timesteps: 443,019,996

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,449.25628
Policy Entropy: 0.73815
Value Function Loss: 0.09175

Mean KL Divergence: 0.00590
SB3 Clip Fraction: 0.06681
Policy Update Magnitude: 0.18545
Value Function Update Magnitude: 0.39693

Collected Steps per Second: 22,976.72231
Overall Steps per Second: 14,720.94736

Timestep Collection Time: 2.17664
Timestep Consumption Time: 1.22070
PPO Batch Consumption Time: 0.09913
Total Iteration Time: 3.39734

Cumulative Model Updates: 53,102
Cumulative Timesteps: 443,070,008

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 443070008...
Checkpoint 443070008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,409.90080
Policy Entropy: 0.73874
Value Function Loss: 0.09097

Mean KL Divergence: 0.00495
SB3 Clip Fraction: 0.05794
Policy Update Magnitude: 0.18924
Value Function Update Magnitude: 0.40106

Collected Steps per Second: 21,978.86378
Overall Steps per Second: 14,272.82797

Timestep Collection Time: 2.27664
Timestep Consumption Time: 1.22918
PPO Batch Consumption Time: 0.10228
Total Iteration Time: 3.50582

Cumulative Model Updates: 53,108
Cumulative Timesteps: 443,120,046

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,430.33029
Policy Entropy: 0.73475
Value Function Loss: 0.08581

Mean KL Divergence: 0.00528
SB3 Clip Fraction: 0.05947
Policy Update Magnitude: 0.18426
Value Function Update Magnitude: 0.38239

Collected Steps per Second: 22,920.86962
Overall Steps per Second: 14,515.83897

Timestep Collection Time: 2.18264
Timestep Consumption Time: 1.26380
PPO Batch Consumption Time: 0.10137
Total Iteration Time: 3.44644

Cumulative Model Updates: 53,114
Cumulative Timesteps: 443,170,074

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 443170074...
Checkpoint 443170074 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,294.42611
Policy Entropy: 0.73289
Value Function Loss: 0.07901

Mean KL Divergence: 0.00654
SB3 Clip Fraction: 0.06917
Policy Update Magnitude: 0.17424
Value Function Update Magnitude: 0.38063

Collected Steps per Second: 21,694.48259
Overall Steps per Second: 14,085.02152

Timestep Collection Time: 2.30529
Timestep Consumption Time: 1.24544
PPO Batch Consumption Time: 0.10078
Total Iteration Time: 3.55072

Cumulative Model Updates: 53,120
Cumulative Timesteps: 443,220,086

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,614.02001
Policy Entropy: 0.73346
Value Function Loss: 0.07466

Mean KL Divergence: 0.00681
SB3 Clip Fraction: 0.06767
Policy Update Magnitude: 0.15656
Value Function Update Magnitude: 0.42018

Collected Steps per Second: 22,206.61853
Overall Steps per Second: 14,605.68804

Timestep Collection Time: 2.25203
Timestep Consumption Time: 1.17198
PPO Batch Consumption Time: 0.09560
Total Iteration Time: 3.42401

Cumulative Model Updates: 53,126
Cumulative Timesteps: 443,270,096

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 443270096...
Checkpoint 443270096 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,306.87174
Policy Entropy: 0.73692
Value Function Loss: 0.08012

Mean KL Divergence: 0.00560
SB3 Clip Fraction: 0.06176
Policy Update Magnitude: 0.16640
Value Function Update Magnitude: 0.41480

Collected Steps per Second: 22,740.57120
Overall Steps per Second: 14,799.54158

Timestep Collection Time: 2.19933
Timestep Consumption Time: 1.18010
PPO Batch Consumption Time: 0.09330
Total Iteration Time: 3.37943

Cumulative Model Updates: 53,132
Cumulative Timesteps: 443,320,110

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,865.69126
Policy Entropy: 0.73799
Value Function Loss: 0.07367

Mean KL Divergence: 0.00547
SB3 Clip Fraction: 0.05861
Policy Update Magnitude: 0.17829
Value Function Update Magnitude: 0.41702

Collected Steps per Second: 22,520.15803
Overall Steps per Second: 14,727.70830

Timestep Collection Time: 2.22130
Timestep Consumption Time: 1.17529
PPO Batch Consumption Time: 0.09211
Total Iteration Time: 3.39659

Cumulative Model Updates: 53,138
Cumulative Timesteps: 443,370,134

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 443370134...
Checkpoint 443370134 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,650.51738
Policy Entropy: 0.72456
Value Function Loss: 0.07279

Mean KL Divergence: 0.00482
SB3 Clip Fraction: 0.05585
Policy Update Magnitude: 0.17826
Value Function Update Magnitude: 0.39796

Collected Steps per Second: 22,065.31158
Overall Steps per Second: 14,153.35684

Timestep Collection Time: 2.26673
Timestep Consumption Time: 1.26714
PPO Batch Consumption Time: 0.10205
Total Iteration Time: 3.53386

Cumulative Model Updates: 53,144
Cumulative Timesteps: 443,420,150

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,576.96382
Policy Entropy: 0.72198
Value Function Loss: 0.06516

Mean KL Divergence: 0.00462
SB3 Clip Fraction: 0.05349
Policy Update Magnitude: 0.16766
Value Function Update Magnitude: 0.37874

Collected Steps per Second: 22,740.48786
Overall Steps per Second: 14,607.34796

Timestep Collection Time: 2.20013
Timestep Consumption Time: 1.22500
PPO Batch Consumption Time: 0.09278
Total Iteration Time: 3.42513

Cumulative Model Updates: 53,150
Cumulative Timesteps: 443,470,182

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 443470182...
Checkpoint 443470182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,859.01735
Policy Entropy: 0.70916
Value Function Loss: 0.07459

Mean KL Divergence: 0.00403
SB3 Clip Fraction: 0.04729
Policy Update Magnitude: 0.16892
Value Function Update Magnitude: 0.37785

Collected Steps per Second: 22,380.59938
Overall Steps per Second: 14,446.30644

Timestep Collection Time: 2.23551
Timestep Consumption Time: 1.22780
PPO Batch Consumption Time: 0.10130
Total Iteration Time: 3.46331

Cumulative Model Updates: 53,156
Cumulative Timesteps: 443,520,214

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,970.69988
Policy Entropy: 0.72142
Value Function Loss: 0.07674

Mean KL Divergence: 0.00416
SB3 Clip Fraction: 0.05127
Policy Update Magnitude: 0.17385
Value Function Update Magnitude: 0.36562

Collected Steps per Second: 22,546.25804
Overall Steps per Second: 14,393.48489

Timestep Collection Time: 2.21766
Timestep Consumption Time: 1.25613
PPO Batch Consumption Time: 0.09978
Total Iteration Time: 3.47379

Cumulative Model Updates: 53,162
Cumulative Timesteps: 443,570,214

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 443570214...
Checkpoint 443570214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,295.13412
Policy Entropy: 0.71910
Value Function Loss: 0.07925

Mean KL Divergence: 0.00357
SB3 Clip Fraction: 0.04384
Policy Update Magnitude: 0.18217
Value Function Update Magnitude: 0.38360

Collected Steps per Second: 22,490.73342
Overall Steps per Second: 14,448.07140

Timestep Collection Time: 2.22447
Timestep Consumption Time: 1.23827
PPO Batch Consumption Time: 0.10087
Total Iteration Time: 3.46275

Cumulative Model Updates: 53,168
Cumulative Timesteps: 443,620,244

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,125.51125
Policy Entropy: 0.73303
Value Function Loss: 0.07966

Mean KL Divergence: 0.00382
SB3 Clip Fraction: 0.04656
Policy Update Magnitude: 0.19365
Value Function Update Magnitude: 0.37832

Collected Steps per Second: 22,203.40230
Overall Steps per Second: 14,371.79749

Timestep Collection Time: 2.25317
Timestep Consumption Time: 1.22782
PPO Batch Consumption Time: 0.09993
Total Iteration Time: 3.48098

Cumulative Model Updates: 53,174
Cumulative Timesteps: 443,670,272

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 443670272...
Checkpoint 443670272 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,726.51959
Policy Entropy: 0.72013
Value Function Loss: 0.06891

Mean KL Divergence: 0.00393
SB3 Clip Fraction: 0.04727
Policy Update Magnitude: 0.19449
Value Function Update Magnitude: 0.37987

Collected Steps per Second: 22,414.81463
Overall Steps per Second: 14,363.15056

Timestep Collection Time: 2.23245
Timestep Consumption Time: 1.25146
PPO Batch Consumption Time: 0.10160
Total Iteration Time: 3.48392

Cumulative Model Updates: 53,180
Cumulative Timesteps: 443,720,312

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,168.56495
Policy Entropy: 0.72936
Value Function Loss: 0.07349

Mean KL Divergence: 0.00328
SB3 Clip Fraction: 0.03989
Policy Update Magnitude: 0.19554
Value Function Update Magnitude: 0.37192

Collected Steps per Second: 22,841.77213
Overall Steps per Second: 14,469.89735

Timestep Collection Time: 2.19029
Timestep Consumption Time: 1.26724
PPO Batch Consumption Time: 0.10290
Total Iteration Time: 3.45752

Cumulative Model Updates: 53,186
Cumulative Timesteps: 443,770,342

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 443770342...
Checkpoint 443770342 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,710.55109
Policy Entropy: 0.72532
Value Function Loss: 0.07309

Mean KL Divergence: 0.00436
SB3 Clip Fraction: 0.05272
Policy Update Magnitude: 0.18478
Value Function Update Magnitude: 0.36449

Collected Steps per Second: 22,630.80200
Overall Steps per Second: 14,632.78416

Timestep Collection Time: 2.21035
Timestep Consumption Time: 1.20814
PPO Batch Consumption Time: 0.09422
Total Iteration Time: 3.41849

Cumulative Model Updates: 53,192
Cumulative Timesteps: 443,820,364

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,239.88389
Policy Entropy: 0.72587
Value Function Loss: 0.08259

Mean KL Divergence: 0.00387
SB3 Clip Fraction: 0.04712
Policy Update Magnitude: 0.18252
Value Function Update Magnitude: 0.34183

Collected Steps per Second: 23,052.28697
Overall Steps per Second: 14,420.66608

Timestep Collection Time: 2.17089
Timestep Consumption Time: 1.29941
PPO Batch Consumption Time: 0.10238
Total Iteration Time: 3.47030

Cumulative Model Updates: 53,198
Cumulative Timesteps: 443,870,408

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 443870408...
Checkpoint 443870408 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,828.85503
Policy Entropy: 0.72935
Value Function Loss: 0.08364

Mean KL Divergence: 0.00359
SB3 Clip Fraction: 0.04315
Policy Update Magnitude: 0.18848
Value Function Update Magnitude: 0.32671

Collected Steps per Second: 22,364.59767
Overall Steps per Second: 14,447.27156

Timestep Collection Time: 2.23648
Timestep Consumption Time: 1.22563
PPO Batch Consumption Time: 0.09740
Total Iteration Time: 3.46211

Cumulative Model Updates: 53,204
Cumulative Timesteps: 443,920,426

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,525.34955
Policy Entropy: 0.72728
Value Function Loss: 0.08759

Mean KL Divergence: 0.00438
SB3 Clip Fraction: 0.05264
Policy Update Magnitude: 0.19158
Value Function Update Magnitude: 0.33089

Collected Steps per Second: 22,653.05346
Overall Steps per Second: 14,729.50218

Timestep Collection Time: 2.20844
Timestep Consumption Time: 1.18800
PPO Batch Consumption Time: 0.09790
Total Iteration Time: 3.39645

Cumulative Model Updates: 53,210
Cumulative Timesteps: 443,970,454

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 443970454...
Checkpoint 443970454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,224.70378
Policy Entropy: 0.72880
Value Function Loss: 0.07895

Mean KL Divergence: 0.00383
SB3 Clip Fraction: 0.04532
Policy Update Magnitude: 0.19057
Value Function Update Magnitude: 0.33348

Collected Steps per Second: 22,788.55526
Overall Steps per Second: 14,381.69617

Timestep Collection Time: 2.19505
Timestep Consumption Time: 1.28312
PPO Batch Consumption Time: 0.10128
Total Iteration Time: 3.47817

Cumulative Model Updates: 53,216
Cumulative Timesteps: 444,020,476

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,855.69324
Policy Entropy: 0.72362
Value Function Loss: 0.07895

Mean KL Divergence: 0.00352
SB3 Clip Fraction: 0.04225
Policy Update Magnitude: 0.18751
Value Function Update Magnitude: 0.33094

Collected Steps per Second: 22,902.02978
Overall Steps per Second: 14,539.23624

Timestep Collection Time: 2.18382
Timestep Consumption Time: 1.25611
PPO Batch Consumption Time: 0.10169
Total Iteration Time: 3.43993

Cumulative Model Updates: 53,222
Cumulative Timesteps: 444,070,490

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 444070490...
Checkpoint 444070490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,010.58937
Policy Entropy: 0.72690
Value Function Loss: 0.08435

Mean KL Divergence: 0.00373
SB3 Clip Fraction: 0.04506
Policy Update Magnitude: 0.18193
Value Function Update Magnitude: 0.36295

Collected Steps per Second: 21,761.06221
Overall Steps per Second: 14,027.63842

Timestep Collection Time: 2.29823
Timestep Consumption Time: 1.26701
PPO Batch Consumption Time: 0.10146
Total Iteration Time: 3.56525

Cumulative Model Updates: 53,228
Cumulative Timesteps: 444,120,502

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,708.46154
Policy Entropy: 0.72549
Value Function Loss: 0.08257

Mean KL Divergence: 0.00483
SB3 Clip Fraction: 0.05295
Policy Update Magnitude: 0.18120
Value Function Update Magnitude: 0.40384

Collected Steps per Second: 22,585.63222
Overall Steps per Second: 14,474.24677

Timestep Collection Time: 2.21451
Timestep Consumption Time: 1.24101
PPO Batch Consumption Time: 0.09093
Total Iteration Time: 3.45552

Cumulative Model Updates: 53,234
Cumulative Timesteps: 444,170,518

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 444170518...
Checkpoint 444170518 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,937.34842
Policy Entropy: 0.72225
Value Function Loss: 0.07842

Mean KL Divergence: 0.00464
SB3 Clip Fraction: 0.05405
Policy Update Magnitude: 0.17696
Value Function Update Magnitude: 0.39701

Collected Steps per Second: 22,881.11869
Overall Steps per Second: 14,821.68884

Timestep Collection Time: 2.18582
Timestep Consumption Time: 1.18856
PPO Batch Consumption Time: 0.09149
Total Iteration Time: 3.37438

Cumulative Model Updates: 53,240
Cumulative Timesteps: 444,220,532

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,737.36863
Policy Entropy: 0.72118
Value Function Loss: 0.08307

Mean KL Divergence: 0.00431
SB3 Clip Fraction: 0.05108
Policy Update Magnitude: 0.17983
Value Function Update Magnitude: 0.37999

Collected Steps per Second: 22,411.14899
Overall Steps per Second: 14,788.28175

Timestep Collection Time: 2.23228
Timestep Consumption Time: 1.15067
PPO Batch Consumption Time: 0.09147
Total Iteration Time: 3.38295

Cumulative Model Updates: 53,246
Cumulative Timesteps: 444,270,560

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 444270560...
Checkpoint 444270560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,907.94608
Policy Entropy: 0.72048
Value Function Loss: 0.09236

Mean KL Divergence: 0.00516
SB3 Clip Fraction: 0.06103
Policy Update Magnitude: 0.19427
Value Function Update Magnitude: 0.38146

Collected Steps per Second: 22,522.87636
Overall Steps per Second: 14,301.06319

Timestep Collection Time: 2.22147
Timestep Consumption Time: 1.27715
PPO Batch Consumption Time: 0.10186
Total Iteration Time: 3.49862

Cumulative Model Updates: 53,252
Cumulative Timesteps: 444,320,594

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,222.16715
Policy Entropy: 0.72885
Value Function Loss: 0.09252

Mean KL Divergence: 0.00437
SB3 Clip Fraction: 0.05188
Policy Update Magnitude: 0.19233
Value Function Update Magnitude: 0.41895

Collected Steps per Second: 22,555.36617
Overall Steps per Second: 14,501.31377

Timestep Collection Time: 2.21792
Timestep Consumption Time: 1.23184
PPO Batch Consumption Time: 0.09636
Total Iteration Time: 3.44976

Cumulative Model Updates: 53,258
Cumulative Timesteps: 444,370,620

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 444370620...
Checkpoint 444370620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,106.77071
Policy Entropy: 0.72609
Value Function Loss: 0.08761

Mean KL Divergence: 0.00407
SB3 Clip Fraction: 0.04862
Policy Update Magnitude: 0.19326
Value Function Update Magnitude: 0.41476

Collected Steps per Second: 22,095.80337
Overall Steps per Second: 14,215.40658

Timestep Collection Time: 2.26505
Timestep Consumption Time: 1.25564
PPO Batch Consumption Time: 0.10372
Total Iteration Time: 3.52069

Cumulative Model Updates: 53,264
Cumulative Timesteps: 444,420,668

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,036.35259
Policy Entropy: 0.72019
Value Function Loss: 0.08239

Mean KL Divergence: 0.00447
SB3 Clip Fraction: 0.05272
Policy Update Magnitude: 0.18479
Value Function Update Magnitude: 0.40972

Collected Steps per Second: 23,073.80804
Overall Steps per Second: 14,657.16288

Timestep Collection Time: 2.16765
Timestep Consumption Time: 1.24474
PPO Batch Consumption Time: 0.10405
Total Iteration Time: 3.41239

Cumulative Model Updates: 53,270
Cumulative Timesteps: 444,470,684

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 444470684...
Checkpoint 444470684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,652.56448
Policy Entropy: 0.70807
Value Function Loss: 0.07932

Mean KL Divergence: 0.00459
SB3 Clip Fraction: 0.05341
Policy Update Magnitude: 0.18141
Value Function Update Magnitude: 0.41818

Collected Steps per Second: 22,842.13221
Overall Steps per Second: 14,696.15514

Timestep Collection Time: 2.18999
Timestep Consumption Time: 1.21390
PPO Batch Consumption Time: 0.09430
Total Iteration Time: 3.40388

Cumulative Model Updates: 53,276
Cumulative Timesteps: 444,520,708

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,556.03248
Policy Entropy: 0.71233
Value Function Loss: 0.08298

Mean KL Divergence: 0.00399
SB3 Clip Fraction: 0.04649
Policy Update Magnitude: 0.18392
Value Function Update Magnitude: 0.42194

Collected Steps per Second: 22,476.17165
Overall Steps per Second: 14,721.31271

Timestep Collection Time: 2.22529
Timestep Consumption Time: 1.17223
PPO Batch Consumption Time: 0.09301
Total Iteration Time: 3.39752

Cumulative Model Updates: 53,282
Cumulative Timesteps: 444,570,724

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 444570724...
Checkpoint 444570724 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,533.44052
Policy Entropy: 0.70588
Value Function Loss: 0.08911

Mean KL Divergence: 0.00408
SB3 Clip Fraction: 0.04735
Policy Update Magnitude: 0.19184
Value Function Update Magnitude: 0.42081

Collected Steps per Second: 22,579.13509
Overall Steps per Second: 14,248.37054

Timestep Collection Time: 2.21523
Timestep Consumption Time: 1.29521
PPO Batch Consumption Time: 0.10368
Total Iteration Time: 3.51044

Cumulative Model Updates: 53,288
Cumulative Timesteps: 444,620,742

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,621.59605
Policy Entropy: 0.71497
Value Function Loss: 0.08997

Mean KL Divergence: 0.00488
SB3 Clip Fraction: 0.05731
Policy Update Magnitude: 0.19580
Value Function Update Magnitude: 0.41669

Collected Steps per Second: 23,227.25307
Overall Steps per Second: 14,709.82502

Timestep Collection Time: 2.15264
Timestep Consumption Time: 1.24644
PPO Batch Consumption Time: 0.10338
Total Iteration Time: 3.39909

Cumulative Model Updates: 53,294
Cumulative Timesteps: 444,670,742

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 444670742...
Checkpoint 444670742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,812.55351
Policy Entropy: 0.71989
Value Function Loss: 0.08296

Mean KL Divergence: 0.00609
SB3 Clip Fraction: 0.06442
Policy Update Magnitude: 0.18779
Value Function Update Magnitude: 0.41093

Collected Steps per Second: 22,125.31704
Overall Steps per Second: 14,188.98762

Timestep Collection Time: 2.26022
Timestep Consumption Time: 1.26421
PPO Batch Consumption Time: 0.10184
Total Iteration Time: 3.52442

Cumulative Model Updates: 53,300
Cumulative Timesteps: 444,720,750

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,515.78328
Policy Entropy: 0.72030
Value Function Loss: 0.08259

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.08418
Policy Update Magnitude: 0.17334
Value Function Update Magnitude: 0.43359

Collected Steps per Second: 22,927.65239
Overall Steps per Second: 14,506.44211

Timestep Collection Time: 2.18086
Timestep Consumption Time: 1.26602
PPO Batch Consumption Time: 0.10215
Total Iteration Time: 3.44688

Cumulative Model Updates: 53,306
Cumulative Timesteps: 444,770,752

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 444770752...
Checkpoint 444770752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,646.44826
Policy Entropy: 0.71949
Value Function Loss: 0.07445

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.07427
Policy Update Magnitude: 0.17361
Value Function Update Magnitude: 0.42588

Collected Steps per Second: 22,687.63703
Overall Steps per Second: 14,681.58897

Timestep Collection Time: 2.20411
Timestep Consumption Time: 1.20193
PPO Batch Consumption Time: 0.09403
Total Iteration Time: 3.40603

Cumulative Model Updates: 53,312
Cumulative Timesteps: 444,820,758

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,474.44177
Policy Entropy: 0.72991
Value Function Loss: 0.08078

Mean KL Divergence: 0.00750
SB3 Clip Fraction: 0.07551
Policy Update Magnitude: 0.17096
Value Function Update Magnitude: 0.41345

Collected Steps per Second: 22,433.77182
Overall Steps per Second: 14,323.81226

Timestep Collection Time: 2.22967
Timestep Consumption Time: 1.26241
PPO Batch Consumption Time: 0.10180
Total Iteration Time: 3.49209

Cumulative Model Updates: 53,318
Cumulative Timesteps: 444,870,778

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 444870778...
Checkpoint 444870778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,200.71641
Policy Entropy: 0.73283
Value Function Loss: 0.08161

Mean KL Divergence: 0.00592
SB3 Clip Fraction: 0.06615
Policy Update Magnitude: 0.17402
Value Function Update Magnitude: 0.38374

Collected Steps per Second: 22,574.56183
Overall Steps per Second: 14,467.52361

Timestep Collection Time: 2.21515
Timestep Consumption Time: 1.24128
PPO Batch Consumption Time: 0.09882
Total Iteration Time: 3.45643

Cumulative Model Updates: 53,324
Cumulative Timesteps: 444,920,784

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,625.89104
Policy Entropy: 0.73081
Value Function Loss: 0.08813

Mean KL Divergence: 0.00492
SB3 Clip Fraction: 0.05740
Policy Update Magnitude: 0.17376
Value Function Update Magnitude: 0.37893

Collected Steps per Second: 23,089.04624
Overall Steps per Second: 14,845.50899

Timestep Collection Time: 2.16743
Timestep Consumption Time: 1.20355
PPO Batch Consumption Time: 0.09932
Total Iteration Time: 3.37099

Cumulative Model Updates: 53,330
Cumulative Timesteps: 444,970,828

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 444970828...
Checkpoint 444970828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,546.27656
Policy Entropy: 0.72676
Value Function Loss: 0.08330

Mean KL Divergence: 0.00536
SB3 Clip Fraction: 0.05855
Policy Update Magnitude: 0.17388
Value Function Update Magnitude: 0.40007

Collected Steps per Second: 22,022.31769
Overall Steps per Second: 14,059.49080

Timestep Collection Time: 2.27170
Timestep Consumption Time: 1.28661
PPO Batch Consumption Time: 0.10408
Total Iteration Time: 3.55831

Cumulative Model Updates: 53,336
Cumulative Timesteps: 445,020,856

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,791.27897
Policy Entropy: 0.72992
Value Function Loss: 0.08551

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.08169
Policy Update Magnitude: 0.16511
Value Function Update Magnitude: 0.40609

Collected Steps per Second: 21,174.72865
Overall Steps per Second: 13,786.23685

Timestep Collection Time: 2.36140
Timestep Consumption Time: 1.26555
PPO Batch Consumption Time: 0.09559
Total Iteration Time: 3.62695

Cumulative Model Updates: 53,342
Cumulative Timesteps: 445,070,858

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 445070858...
Checkpoint 445070858 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,471.82724
Policy Entropy: 0.73026
Value Function Loss: 0.09321

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.07996
Policy Update Magnitude: 0.16643
Value Function Update Magnitude: 0.39925

Collected Steps per Second: 21,705.04303
Overall Steps per Second: 14,081.98359

Timestep Collection Time: 2.30380
Timestep Consumption Time: 1.24712
PPO Batch Consumption Time: 0.09822
Total Iteration Time: 3.55092

Cumulative Model Updates: 53,348
Cumulative Timesteps: 445,120,862

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,277.72047
Policy Entropy: 0.73296
Value Function Loss: 0.09091

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.07314
Policy Update Magnitude: 0.16834
Value Function Update Magnitude: 0.41559

Collected Steps per Second: 22,870.75394
Overall Steps per Second: 14,752.53799

Timestep Collection Time: 2.18629
Timestep Consumption Time: 1.20310
PPO Batch Consumption Time: 0.09883
Total Iteration Time: 3.38938

Cumulative Model Updates: 53,354
Cumulative Timesteps: 445,170,864

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 445170864...
Checkpoint 445170864 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,245.14584
Policy Entropy: 0.74435
Value Function Loss: 0.08275

Mean KL Divergence: 0.00583
SB3 Clip Fraction: 0.06404
Policy Update Magnitude: 0.17342
Value Function Update Magnitude: 0.42160

Collected Steps per Second: 22,622.33184
Overall Steps per Second: 14,397.57439

Timestep Collection Time: 2.21021
Timestep Consumption Time: 1.26260
PPO Batch Consumption Time: 0.10152
Total Iteration Time: 3.47281

Cumulative Model Updates: 53,360
Cumulative Timesteps: 445,220,864

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,529.54369
Policy Entropy: 0.75380
Value Function Loss: 0.08186

Mean KL Divergence: 0.00488
SB3 Clip Fraction: 0.05603
Policy Update Magnitude: 0.17195
Value Function Update Magnitude: 0.38662

Collected Steps per Second: 22,516.35816
Overall Steps per Second: 14,403.31055

Timestep Collection Time: 2.22070
Timestep Consumption Time: 1.25087
PPO Batch Consumption Time: 0.09954
Total Iteration Time: 3.47156

Cumulative Model Updates: 53,366
Cumulative Timesteps: 445,270,866

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 445270866...
Checkpoint 445270866 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,228.92498
Policy Entropy: 0.74558
Value Function Loss: 0.08407

Mean KL Divergence: 0.00433
SB3 Clip Fraction: 0.05139
Policy Update Magnitude: 0.17591
Value Function Update Magnitude: 0.34382

Collected Steps per Second: 22,293.47823
Overall Steps per Second: 14,329.55267

Timestep Collection Time: 2.24362
Timestep Consumption Time: 1.24693
PPO Batch Consumption Time: 0.10169
Total Iteration Time: 3.49055

Cumulative Model Updates: 53,372
Cumulative Timesteps: 445,320,884

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,883.93147
Policy Entropy: 0.73109
Value Function Loss: 0.08730

Mean KL Divergence: 0.00539
SB3 Clip Fraction: 0.06043
Policy Update Magnitude: 0.17733
Value Function Update Magnitude: 0.35070

Collected Steps per Second: 23,090.34240
Overall Steps per Second: 14,576.77963

Timestep Collection Time: 2.16714
Timestep Consumption Time: 1.26572
PPO Batch Consumption Time: 0.10165
Total Iteration Time: 3.43286

Cumulative Model Updates: 53,378
Cumulative Timesteps: 445,370,924

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 445370924...
Checkpoint 445370924 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,577.70345
Policy Entropy: 0.72869
Value Function Loss: 0.08546

Mean KL Divergence: 0.00470
SB3 Clip Fraction: 0.05435
Policy Update Magnitude: 0.17706
Value Function Update Magnitude: 0.33287

Collected Steps per Second: 22,071.03773
Overall Steps per Second: 14,179.75796

Timestep Collection Time: 2.26605
Timestep Consumption Time: 1.26109
PPO Batch Consumption Time: 0.10170
Total Iteration Time: 3.52714

Cumulative Model Updates: 53,384
Cumulative Timesteps: 445,420,938

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,374.57042
Policy Entropy: 0.73741
Value Function Loss: 0.08790

Mean KL Divergence: 0.00474
SB3 Clip Fraction: 0.05468
Policy Update Magnitude: 0.18075
Value Function Update Magnitude: 0.36737

Collected Steps per Second: 22,958.91231
Overall Steps per Second: 14,777.11267

Timestep Collection Time: 2.17911
Timestep Consumption Time: 1.20653
PPO Batch Consumption Time: 0.09980
Total Iteration Time: 3.38564

Cumulative Model Updates: 53,390
Cumulative Timesteps: 445,470,968

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 445470968...
Checkpoint 445470968 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,334.47763
Policy Entropy: 0.75399
Value Function Loss: 0.09052

Mean KL Divergence: 0.00446
SB3 Clip Fraction: 0.05266
Policy Update Magnitude: 0.18664
Value Function Update Magnitude: 0.37493

Collected Steps per Second: 22,644.16807
Overall Steps per Second: 14,460.65396

Timestep Collection Time: 2.20825
Timestep Consumption Time: 1.24968
PPO Batch Consumption Time: 0.09762
Total Iteration Time: 3.45793

Cumulative Model Updates: 53,396
Cumulative Timesteps: 445,520,972

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,591.99944
Policy Entropy: 0.75177
Value Function Loss: 0.08961

Mean KL Divergence: 0.00341
SB3 Clip Fraction: 0.04089
Policy Update Magnitude: 0.19313
Value Function Update Magnitude: 0.37143

Collected Steps per Second: 21,931.91654
Overall Steps per Second: 14,142.60100

Timestep Collection Time: 2.28106
Timestep Consumption Time: 1.25634
PPO Batch Consumption Time: 0.10262
Total Iteration Time: 3.53740

Cumulative Model Updates: 53,402
Cumulative Timesteps: 445,571,000

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 445571000...
Checkpoint 445571000 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,193.80351
Policy Entropy: 0.74921
Value Function Loss: 0.09105

Mean KL Divergence: 0.00388
SB3 Clip Fraction: 0.04762
Policy Update Magnitude: 0.18829
Value Function Update Magnitude: 0.39453

Collected Steps per Second: 22,685.72485
Overall Steps per Second: 14,646.84351

Timestep Collection Time: 2.20403
Timestep Consumption Time: 1.20968
PPO Batch Consumption Time: 0.10201
Total Iteration Time: 3.41370

Cumulative Model Updates: 53,408
Cumulative Timesteps: 445,621,000

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,787.17241
Policy Entropy: 0.73785
Value Function Loss: 0.08364

Mean KL Divergence: 0.00375
SB3 Clip Fraction: 0.04643
Policy Update Magnitude: 0.18776
Value Function Update Magnitude: 0.41303

Collected Steps per Second: 23,116.45439
Overall Steps per Second: 14,729.90577

Timestep Collection Time: 2.16313
Timestep Consumption Time: 1.23159
PPO Batch Consumption Time: 0.09861
Total Iteration Time: 3.39473

Cumulative Model Updates: 53,414
Cumulative Timesteps: 445,671,004

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 445671004...
Checkpoint 445671004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,849.57837
Policy Entropy: 0.73968
Value Function Loss: 0.08875

Mean KL Divergence: 0.00420
SB3 Clip Fraction: 0.05082
Policy Update Magnitude: 0.18583
Value Function Update Magnitude: 0.40989

Collected Steps per Second: 22,170.92633
Overall Steps per Second: 14,396.75598

Timestep Collection Time: 2.25602
Timestep Consumption Time: 1.21824
PPO Batch Consumption Time: 0.10163
Total Iteration Time: 3.47425

Cumulative Model Updates: 53,420
Cumulative Timesteps: 445,721,022

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,710.84406
Policy Entropy: 0.73298
Value Function Loss: 0.09502

Mean KL Divergence: 0.00506
SB3 Clip Fraction: 0.06012
Policy Update Magnitude: 0.19018
Value Function Update Magnitude: 0.42614

Collected Steps per Second: 22,542.25016
Overall Steps per Second: 14,358.49489

Timestep Collection Time: 2.21930
Timestep Consumption Time: 1.26491
PPO Batch Consumption Time: 0.09961
Total Iteration Time: 3.48421

Cumulative Model Updates: 53,426
Cumulative Timesteps: 445,771,050

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 445771050...
Checkpoint 445771050 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,853.42628
Policy Entropy: 0.73711
Value Function Loss: 0.09817

Mean KL Divergence: 0.00467
SB3 Clip Fraction: 0.05550
Policy Update Magnitude: 0.19068
Value Function Update Magnitude: 0.41970

Collected Steps per Second: 22,167.36538
Overall Steps per Second: 14,209.88143

Timestep Collection Time: 2.25557
Timestep Consumption Time: 1.26311
PPO Batch Consumption Time: 0.10247
Total Iteration Time: 3.51868

Cumulative Model Updates: 53,432
Cumulative Timesteps: 445,821,050

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,704.54613
Policy Entropy: 0.74752
Value Function Loss: 0.08807

Mean KL Divergence: 0.00451
SB3 Clip Fraction: 0.05344
Policy Update Magnitude: 0.19500
Value Function Update Magnitude: 0.37810

Collected Steps per Second: 22,518.29206
Overall Steps per Second: 14,465.77857

Timestep Collection Time: 2.22059
Timestep Consumption Time: 1.23612
PPO Batch Consumption Time: 0.09829
Total Iteration Time: 3.45671

Cumulative Model Updates: 53,438
Cumulative Timesteps: 445,871,054

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 445871054...
Checkpoint 445871054 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,654.85746
Policy Entropy: 0.76092
Value Function Loss: 0.09344

Mean KL Divergence: 0.00399
SB3 Clip Fraction: 0.04861
Policy Update Magnitude: 0.19331
Value Function Update Magnitude: 0.35584

Collected Steps per Second: 22,456.18761
Overall Steps per Second: 14,375.60854

Timestep Collection Time: 2.22754
Timestep Consumption Time: 1.25211
PPO Batch Consumption Time: 0.10241
Total Iteration Time: 3.47964

Cumulative Model Updates: 53,444
Cumulative Timesteps: 445,921,076

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,116.64693
Policy Entropy: 0.75639
Value Function Loss: 0.09078

Mean KL Divergence: 0.00373
SB3 Clip Fraction: 0.04564
Policy Update Magnitude: 0.19757
Value Function Update Magnitude: 0.39589

Collected Steps per Second: 22,766.27755
Overall Steps per Second: 14,452.21693

Timestep Collection Time: 2.19641
Timestep Consumption Time: 1.26355
PPO Batch Consumption Time: 0.10365
Total Iteration Time: 3.45995

Cumulative Model Updates: 53,450
Cumulative Timesteps: 445,971,080

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 445971080...
Checkpoint 445971080 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,715.98346
Policy Entropy: 0.74622
Value Function Loss: 0.09738

Mean KL Divergence: 0.00488
SB3 Clip Fraction: 0.05663
Policy Update Magnitude: 0.19640
Value Function Update Magnitude: 0.44111

Collected Steps per Second: 22,069.57370
Overall Steps per Second: 14,308.33237

Timestep Collection Time: 2.26611
Timestep Consumption Time: 1.22920
PPO Batch Consumption Time: 0.10110
Total Iteration Time: 3.49531

Cumulative Model Updates: 53,456
Cumulative Timesteps: 446,021,092

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,053.15440
Policy Entropy: 0.74861
Value Function Loss: 0.09870

Mean KL Divergence: 0.00524
SB3 Clip Fraction: 0.05911
Policy Update Magnitude: 0.20294
Value Function Update Magnitude: 0.46016

Collected Steps per Second: 22,868.00312
Overall Steps per Second: 14,571.77918

Timestep Collection Time: 2.18716
Timestep Consumption Time: 1.24523
PPO Batch Consumption Time: 0.10220
Total Iteration Time: 3.43239

Cumulative Model Updates: 53,462
Cumulative Timesteps: 446,071,108

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 446071108...
Checkpoint 446071108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,672.46094
Policy Entropy: 0.74278
Value Function Loss: 0.10063

Mean KL Divergence: 0.00635
SB3 Clip Fraction: 0.07072
Policy Update Magnitude: 0.20125
Value Function Update Magnitude: 0.46073

Collected Steps per Second: 22,256.48221
Overall Steps per Second: 14,585.69563

Timestep Collection Time: 2.24681
Timestep Consumption Time: 1.18162
PPO Batch Consumption Time: 0.09257
Total Iteration Time: 3.42843

Cumulative Model Updates: 53,468
Cumulative Timesteps: 446,121,114

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,918.15108
Policy Entropy: 0.74449
Value Function Loss: 0.10029

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.08283
Policy Update Magnitude: 0.18970
Value Function Update Magnitude: 0.44067

Collected Steps per Second: 22,244.13616
Overall Steps per Second: 14,311.02067

Timestep Collection Time: 2.24778
Timestep Consumption Time: 1.24603
PPO Batch Consumption Time: 0.10172
Total Iteration Time: 3.49381

Cumulative Model Updates: 53,474
Cumulative Timesteps: 446,171,114

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 446171114...
Checkpoint 446171114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,330.89092
Policy Entropy: 0.75037
Value Function Loss: 0.08713

Mean KL Divergence: 0.00569
SB3 Clip Fraction: 0.06569
Policy Update Magnitude: 0.18700
Value Function Update Magnitude: 0.41585

Collected Steps per Second: 22,930.73016
Overall Steps per Second: 14,591.44707

Timestep Collection Time: 2.18109
Timestep Consumption Time: 1.24653
PPO Batch Consumption Time: 0.10149
Total Iteration Time: 3.42762

Cumulative Model Updates: 53,480
Cumulative Timesteps: 446,221,128

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,336.87009
Policy Entropy: 0.76556
Value Function Loss: 0.08346

Mean KL Divergence: 0.00485
SB3 Clip Fraction: 0.05550
Policy Update Magnitude: 0.20073
Value Function Update Magnitude: 0.39754

Collected Steps per Second: 22,632.02160
Overall Steps per Second: 14,581.37226

Timestep Collection Time: 2.21050
Timestep Consumption Time: 1.22046
PPO Batch Consumption Time: 0.09307
Total Iteration Time: 3.43095

Cumulative Model Updates: 53,486
Cumulative Timesteps: 446,271,156

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 446271156...
Checkpoint 446271156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,399.95922
Policy Entropy: 0.76469
Value Function Loss: 0.07845

Mean KL Divergence: 0.00546
SB3 Clip Fraction: 0.06193
Policy Update Magnitude: 0.20662
Value Function Update Magnitude: 0.36858

Collected Steps per Second: 21,816.46456
Overall Steps per Second: 14,159.36380

Timestep Collection Time: 2.29203
Timestep Consumption Time: 1.23948
PPO Batch Consumption Time: 0.10234
Total Iteration Time: 3.53151

Cumulative Model Updates: 53,492
Cumulative Timesteps: 446,321,160

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,828.48486
Policy Entropy: 0.75851
Value Function Loss: 0.08392

Mean KL Divergence: 0.00490
SB3 Clip Fraction: 0.05639
Policy Update Magnitude: 0.20445
Value Function Update Magnitude: 0.34617

Collected Steps per Second: 22,832.43038
Overall Steps per Second: 14,640.88293

Timestep Collection Time: 2.19022
Timestep Consumption Time: 1.22542
PPO Batch Consumption Time: 0.09578
Total Iteration Time: 3.41564

Cumulative Model Updates: 53,498
Cumulative Timesteps: 446,371,168

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 446371168...
Checkpoint 446371168 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,002.20525
Policy Entropy: 0.74852
Value Function Loss: 0.08547

Mean KL Divergence: 0.00610
SB3 Clip Fraction: 0.06473
Policy Update Magnitude: 0.19358
Value Function Update Magnitude: 0.35509

Collected Steps per Second: 22,199.38853
Overall Steps per Second: 14,426.15474

Timestep Collection Time: 2.25340
Timestep Consumption Time: 1.21420
PPO Batch Consumption Time: 0.10062
Total Iteration Time: 3.46759

Cumulative Model Updates: 53,504
Cumulative Timesteps: 446,421,192

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,954.15174
Policy Entropy: 0.75185
Value Function Loss: 0.08742

Mean KL Divergence: 0.00515
SB3 Clip Fraction: 0.05905
Policy Update Magnitude: 0.19134
Value Function Update Magnitude: 0.33596

Collected Steps per Second: 22,708.21326
Overall Steps per Second: 14,461.30720

Timestep Collection Time: 2.20220
Timestep Consumption Time: 1.25586
PPO Batch Consumption Time: 0.09987
Total Iteration Time: 3.45806

Cumulative Model Updates: 53,510
Cumulative Timesteps: 446,471,200

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 446471200...
Checkpoint 446471200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,826.57667
Policy Entropy: 0.75314
Value Function Loss: 0.09771

Mean KL Divergence: 0.00666
SB3 Clip Fraction: 0.06916
Policy Update Magnitude: 0.19854
Value Function Update Magnitude: 0.32294

Collected Steps per Second: 22,618.13351
Overall Steps per Second: 14,731.97264

Timestep Collection Time: 2.21150
Timestep Consumption Time: 1.18384
PPO Batch Consumption Time: 0.09708
Total Iteration Time: 3.39534

Cumulative Model Updates: 53,516
Cumulative Timesteps: 446,521,220

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,376.04129
Policy Entropy: 0.74732
Value Function Loss: 0.09347

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.07664
Policy Update Magnitude: 0.18558
Value Function Update Magnitude: 0.37508

Collected Steps per Second: 22,598.45861
Overall Steps per Second: 14,705.21010

Timestep Collection Time: 2.21351
Timestep Consumption Time: 1.18814
PPO Batch Consumption Time: 0.09531
Total Iteration Time: 3.40165

Cumulative Model Updates: 53,522
Cumulative Timesteps: 446,571,242

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 446571242...
Checkpoint 446571242 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,255.65094
Policy Entropy: 0.74015
Value Function Loss: 0.09762

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.08451
Policy Update Magnitude: 0.18680
Value Function Update Magnitude: 0.37754

Collected Steps per Second: 22,677.04601
Overall Steps per Second: 14,325.56527

Timestep Collection Time: 2.20514
Timestep Consumption Time: 1.28555
PPO Batch Consumption Time: 0.10250
Total Iteration Time: 3.49068

Cumulative Model Updates: 53,528
Cumulative Timesteps: 446,621,248

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,466.30830
Policy Entropy: 0.74716
Value Function Loss: 0.09868

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.08112
Policy Update Magnitude: 0.17607
Value Function Update Magnitude: 0.41442

Collected Steps per Second: 22,983.36593
Overall Steps per Second: 14,742.30799

Timestep Collection Time: 2.17549
Timestep Consumption Time: 1.21611
PPO Batch Consumption Time: 0.10116
Total Iteration Time: 3.39160

Cumulative Model Updates: 53,534
Cumulative Timesteps: 446,671,248

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 446671248...
Checkpoint 446671248 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,077.14156
Policy Entropy: 0.74170
Value Function Loss: 0.10144

Mean KL Divergence: 0.00734
SB3 Clip Fraction: 0.07670
Policy Update Magnitude: 0.17748
Value Function Update Magnitude: 0.44787

Collected Steps per Second: 22,172.97258
Overall Steps per Second: 14,519.68000

Timestep Collection Time: 2.25671
Timestep Consumption Time: 1.18951
PPO Batch Consumption Time: 0.09315
Total Iteration Time: 3.44622

Cumulative Model Updates: 53,540
Cumulative Timesteps: 446,721,286

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,015.45016
Policy Entropy: 0.75262
Value Function Loss: 0.10016

Mean KL Divergence: 0.00591
SB3 Clip Fraction: 0.06296
Policy Update Magnitude: 0.19141
Value Function Update Magnitude: 0.44223

Collected Steps per Second: 22,991.25886
Overall Steps per Second: 14,732.95915

Timestep Collection Time: 2.17517
Timestep Consumption Time: 1.21926
PPO Batch Consumption Time: 0.09478
Total Iteration Time: 3.39443

Cumulative Model Updates: 53,546
Cumulative Timesteps: 446,771,296

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 446771296...
Checkpoint 446771296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,196.81206
Policy Entropy: 0.74803
Value Function Loss: 0.09462

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.07438
Policy Update Magnitude: 0.18824
Value Function Update Magnitude: 0.42282

Collected Steps per Second: 22,757.45790
Overall Steps per Second: 14,344.05467

Timestep Collection Time: 2.19840
Timestep Consumption Time: 1.28946
PPO Batch Consumption Time: 0.10661
Total Iteration Time: 3.48786

Cumulative Model Updates: 53,552
Cumulative Timesteps: 446,821,326

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,576.10268
Policy Entropy: 0.75310
Value Function Loss: 0.09543

Mean KL Divergence: 0.00531
SB3 Clip Fraction: 0.06123
Policy Update Magnitude: 0.18411
Value Function Update Magnitude: 0.42595

Collected Steps per Second: 22,372.17704
Overall Steps per Second: 14,307.78708

Timestep Collection Time: 2.23608
Timestep Consumption Time: 1.26034
PPO Batch Consumption Time: 0.09927
Total Iteration Time: 3.49642

Cumulative Model Updates: 53,558
Cumulative Timesteps: 446,871,352

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 446871352...
Checkpoint 446871352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,989.66334
Policy Entropy: 0.74504
Value Function Loss: 0.09572

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.08003
Policy Update Magnitude: 0.18628
Value Function Update Magnitude: 0.43253

Collected Steps per Second: 22,719.91324
Overall Steps per Second: 14,294.70711

Timestep Collection Time: 2.20186
Timestep Consumption Time: 1.29776
PPO Batch Consumption Time: 0.10269
Total Iteration Time: 3.49962

Cumulative Model Updates: 53,564
Cumulative Timesteps: 446,921,378

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,706.71629
Policy Entropy: 0.74852
Value Function Loss: 0.09997

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.07680
Policy Update Magnitude: 0.19011
Value Function Update Magnitude: 0.42580

Collected Steps per Second: 22,857.50317
Overall Steps per Second: 14,745.96403

Timestep Collection Time: 2.18860
Timestep Consumption Time: 1.20392
PPO Batch Consumption Time: 0.10093
Total Iteration Time: 3.39252

Cumulative Model Updates: 53,570
Cumulative Timesteps: 446,971,404

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 446971404...
Checkpoint 446971404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,995.74865
Policy Entropy: 0.75152
Value Function Loss: 0.10143

Mean KL Divergence: 0.00751
SB3 Clip Fraction: 0.07174
Policy Update Magnitude: 0.20319
Value Function Update Magnitude: 0.41985

Collected Steps per Second: 22,043.64202
Overall Steps per Second: 14,367.54697

Timestep Collection Time: 2.26877
Timestep Consumption Time: 1.21213
PPO Batch Consumption Time: 0.10092
Total Iteration Time: 3.48090

Cumulative Model Updates: 53,576
Cumulative Timesteps: 447,021,416

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,498.14867
Policy Entropy: 0.75556
Value Function Loss: 0.10054

Mean KL Divergence: 0.00750
SB3 Clip Fraction: 0.07577
Policy Update Magnitude: 0.19290
Value Function Update Magnitude: 0.38442

Collected Steps per Second: 22,767.69101
Overall Steps per Second: 14,418.89261

Timestep Collection Time: 2.19759
Timestep Consumption Time: 1.27244
PPO Batch Consumption Time: 0.10305
Total Iteration Time: 3.47003

Cumulative Model Updates: 53,582
Cumulative Timesteps: 447,071,450

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 447071450...
Checkpoint 447071450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,937.72502
Policy Entropy: 0.75873
Value Function Loss: 0.10550

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.08152
Policy Update Magnitude: 0.19082
Value Function Update Magnitude: 0.35797

Collected Steps per Second: 22,726.81422
Overall Steps per Second: 14,734.12227

Timestep Collection Time: 2.20084
Timestep Consumption Time: 1.19387
PPO Batch Consumption Time: 0.09745
Total Iteration Time: 3.39471

Cumulative Model Updates: 53,588
Cumulative Timesteps: 447,121,468

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,048.72616
Policy Entropy: 0.76484
Value Function Loss: 0.10526

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.07930
Policy Update Magnitude: 0.18882
Value Function Update Magnitude: 0.37105

Collected Steps per Second: 22,424.02651
Overall Steps per Second: 14,680.40692

Timestep Collection Time: 2.23064
Timestep Consumption Time: 1.17662
PPO Batch Consumption Time: 0.09229
Total Iteration Time: 3.40726

Cumulative Model Updates: 53,594
Cumulative Timesteps: 447,171,488

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 447171488...
Checkpoint 447171488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,123.05748
Policy Entropy: 0.76736
Value Function Loss: 0.10082

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.07338
Policy Update Magnitude: 0.19039
Value Function Update Magnitude: 0.40023

Collected Steps per Second: 22,609.16490
Overall Steps per Second: 14,368.95510

Timestep Collection Time: 2.21185
Timestep Consumption Time: 1.26843
PPO Batch Consumption Time: 0.10208
Total Iteration Time: 3.48028

Cumulative Model Updates: 53,600
Cumulative Timesteps: 447,221,496

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,448.09565
Policy Entropy: 0.75780
Value Function Loss: 0.09308

Mean KL Divergence: 0.00575
SB3 Clip Fraction: 0.06375
Policy Update Magnitude: 0.19393
Value Function Update Magnitude: 0.40234

Collected Steps per Second: 23,242.05315
Overall Steps per Second: 14,786.89848

Timestep Collection Time: 2.15222
Timestep Consumption Time: 1.23064
PPO Batch Consumption Time: 0.10049
Total Iteration Time: 3.38286

Cumulative Model Updates: 53,606
Cumulative Timesteps: 447,271,518

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 447271518...
Checkpoint 447271518 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,713.55128
Policy Entropy: 0.76098
Value Function Loss: 0.10027

Mean KL Divergence: 0.00456
SB3 Clip Fraction: 0.05276
Policy Update Magnitude: 0.21001
Value Function Update Magnitude: 0.39501

Collected Steps per Second: 22,079.00507
Overall Steps per Second: 14,461.66724

Timestep Collection Time: 2.26514
Timestep Consumption Time: 1.19311
PPO Batch Consumption Time: 0.09446
Total Iteration Time: 3.45825

Cumulative Model Updates: 53,612
Cumulative Timesteps: 447,321,530

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,395.69831
Policy Entropy: 0.76451
Value Function Loss: 0.10235

Mean KL Divergence: 0.00436
SB3 Clip Fraction: 0.05144
Policy Update Magnitude: 0.21141
Value Function Update Magnitude: 0.44176

Collected Steps per Second: 23,110.70944
Overall Steps per Second: 14,837.51911

Timestep Collection Time: 2.16471
Timestep Consumption Time: 1.20701
PPO Batch Consumption Time: 0.09893
Total Iteration Time: 3.37172

Cumulative Model Updates: 53,618
Cumulative Timesteps: 447,371,558

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 447371558...
Checkpoint 447371558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,724.80772
Policy Entropy: 0.76420
Value Function Loss: 0.10745

Mean KL Divergence: 0.00384
SB3 Clip Fraction: 0.04568
Policy Update Magnitude: 0.21771
Value Function Update Magnitude: 0.42154

Collected Steps per Second: 22,706.08084
Overall Steps per Second: 14,782.01887

Timestep Collection Time: 2.20249
Timestep Consumption Time: 1.18067
PPO Batch Consumption Time: 0.09526
Total Iteration Time: 3.38316

Cumulative Model Updates: 53,624
Cumulative Timesteps: 447,421,568

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,044.31897
Policy Entropy: 0.76888
Value Function Loss: 0.10150

Mean KL Divergence: 0.00382
SB3 Clip Fraction: 0.04610
Policy Update Magnitude: 0.22304
Value Function Update Magnitude: 0.41238

Collected Steps per Second: 22,443.45967
Overall Steps per Second: 14,364.18044

Timestep Collection Time: 2.22907
Timestep Consumption Time: 1.25376
PPO Batch Consumption Time: 0.10165
Total Iteration Time: 3.48283

Cumulative Model Updates: 53,630
Cumulative Timesteps: 447,471,596

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 447471596...
Checkpoint 447471596 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,437.14187
Policy Entropy: 0.76884
Value Function Loss: 0.09890

Mean KL Divergence: 0.00488
SB3 Clip Fraction: 0.05774
Policy Update Magnitude: 0.22155
Value Function Update Magnitude: 0.43232

Collected Steps per Second: 22,313.86909
Overall Steps per Second: 14,367.90399

Timestep Collection Time: 2.24174
Timestep Consumption Time: 1.23977
PPO Batch Consumption Time: 0.09610
Total Iteration Time: 3.48151

Cumulative Model Updates: 53,636
Cumulative Timesteps: 447,521,618

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,115.28913
Policy Entropy: 0.77721
Value Function Loss: 0.09130

Mean KL Divergence: 0.00608
SB3 Clip Fraction: 0.06732
Policy Update Magnitude: 0.21979
Value Function Update Magnitude: 0.44138

Collected Steps per Second: 23,034.96382
Overall Steps per Second: 14,732.63772

Timestep Collection Time: 2.17079
Timestep Consumption Time: 1.22331
PPO Batch Consumption Time: 0.09558
Total Iteration Time: 3.39410

Cumulative Model Updates: 53,642
Cumulative Timesteps: 447,571,622

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 447571622...
Checkpoint 447571622 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,780.65167
Policy Entropy: 0.76500
Value Function Loss: 0.09670

Mean KL Divergence: 0.00584
SB3 Clip Fraction: 0.06407
Policy Update Magnitude: 0.21197
Value Function Update Magnitude: 0.43460

Collected Steps per Second: 22,062.93470
Overall Steps per Second: 14,181.22218

Timestep Collection Time: 2.26624
Timestep Consumption Time: 1.25954
PPO Batch Consumption Time: 0.10384
Total Iteration Time: 3.52579

Cumulative Model Updates: 53,648
Cumulative Timesteps: 447,621,622

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,439.38695
Policy Entropy: 0.76812
Value Function Loss: 0.08921

Mean KL Divergence: 0.00467
SB3 Clip Fraction: 0.05572
Policy Update Magnitude: 0.20832
Value Function Update Magnitude: 0.41712

Collected Steps per Second: 21,688.02717
Overall Steps per Second: 13,892.19955

Timestep Collection Time: 2.30671
Timestep Consumption Time: 1.29445
PPO Batch Consumption Time: 0.10408
Total Iteration Time: 3.60116

Cumulative Model Updates: 53,654
Cumulative Timesteps: 447,671,650

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 447671650...
Checkpoint 447671650 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,070.52516
Policy Entropy: 0.76762
Value Function Loss: 0.09083

Mean KL Divergence: 0.00376
SB3 Clip Fraction: 0.04445
Policy Update Magnitude: 0.20386
Value Function Update Magnitude: 0.38862

Collected Steps per Second: 22,595.55466
Overall Steps per Second: 14,274.46418

Timestep Collection Time: 2.21327
Timestep Consumption Time: 1.29019
PPO Batch Consumption Time: 0.10718
Total Iteration Time: 3.50346

Cumulative Model Updates: 53,660
Cumulative Timesteps: 447,721,660

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,132.81545
Policy Entropy: 0.76270
Value Function Loss: 0.09288

Mean KL Divergence: 0.00351
SB3 Clip Fraction: 0.04299
Policy Update Magnitude: 0.21714
Value Function Update Magnitude: 0.37716

Collected Steps per Second: 22,511.60210
Overall Steps per Second: 14,389.71397

Timestep Collection Time: 2.22205
Timestep Consumption Time: 1.25418
PPO Batch Consumption Time: 0.10681
Total Iteration Time: 3.47623

Cumulative Model Updates: 53,666
Cumulative Timesteps: 447,771,682

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 447771682...
Checkpoint 447771682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,326.08224
Policy Entropy: 0.75875
Value Function Loss: 0.10020

Mean KL Divergence: 0.00372
SB3 Clip Fraction: 0.04454
Policy Update Magnitude: 0.21508
Value Function Update Magnitude: 0.33961

Collected Steps per Second: 22,497.89321
Overall Steps per Second: 14,512.96810

Timestep Collection Time: 2.22305
Timestep Consumption Time: 1.22311
PPO Batch Consumption Time: 0.10082
Total Iteration Time: 3.44616

Cumulative Model Updates: 53,672
Cumulative Timesteps: 447,821,696

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,435.33343
Policy Entropy: 0.76574
Value Function Loss: 0.09876

Mean KL Divergence: 0.00436
SB3 Clip Fraction: 0.05073
Policy Update Magnitude: 0.20442
Value Function Update Magnitude: 0.32325

Collected Steps per Second: 22,995.36911
Overall Steps per Second: 14,527.97402

Timestep Collection Time: 2.17513
Timestep Consumption Time: 1.26774
PPO Batch Consumption Time: 0.10188
Total Iteration Time: 3.44288

Cumulative Model Updates: 53,678
Cumulative Timesteps: 447,871,714

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 447871714...
Checkpoint 447871714 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,715.70589
Policy Entropy: 0.76927
Value Function Loss: 0.09024

Mean KL Divergence: 0.00568
SB3 Clip Fraction: 0.06369
Policy Update Magnitude: 0.19032
Value Function Update Magnitude: 0.34374

Collected Steps per Second: 21,653.85473
Overall Steps per Second: 14,043.33712

Timestep Collection Time: 2.30906
Timestep Consumption Time: 1.25135
PPO Batch Consumption Time: 0.10260
Total Iteration Time: 3.56041

Cumulative Model Updates: 53,684
Cumulative Timesteps: 447,921,714

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,991.90267
Policy Entropy: 0.77197
Value Function Loss: 0.08885

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.08105
Policy Update Magnitude: 0.17880
Value Function Update Magnitude: 0.35133

Collected Steps per Second: 23,106.55124
Overall Steps per Second: 14,667.84264

Timestep Collection Time: 2.16423
Timestep Consumption Time: 1.24513
PPO Batch Consumption Time: 0.10284
Total Iteration Time: 3.40936

Cumulative Model Updates: 53,690
Cumulative Timesteps: 447,971,722

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 447971722...
Checkpoint 447971722 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,820.62515
Policy Entropy: 0.77474
Value Function Loss: 0.07850

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.08676
Policy Update Magnitude: 0.16455
Value Function Update Magnitude: 0.34976

Collected Steps per Second: 22,680.99011
Overall Steps per Second: 14,595.45188

Timestep Collection Time: 2.20449
Timestep Consumption Time: 1.22124
PPO Batch Consumption Time: 0.09520
Total Iteration Time: 3.42572

Cumulative Model Updates: 53,696
Cumulative Timesteps: 448,021,722

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,657.62150
Policy Entropy: 0.76511
Value Function Loss: 0.08373

Mean KL Divergence: 0.00745
SB3 Clip Fraction: 0.07859
Policy Update Magnitude: 0.16888
Value Function Update Magnitude: 0.34544

Collected Steps per Second: 22,365.66740
Overall Steps per Second: 14,348.90893

Timestep Collection Time: 2.23664
Timestep Consumption Time: 1.24962
PPO Batch Consumption Time: 0.10198
Total Iteration Time: 3.48626

Cumulative Model Updates: 53,702
Cumulative Timesteps: 448,071,746

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 448071746...
Checkpoint 448071746 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,254.88459
Policy Entropy: 0.76673
Value Function Loss: 0.09090

Mean KL Divergence: 0.00601
SB3 Clip Fraction: 0.06856
Policy Update Magnitude: 0.17897
Value Function Update Magnitude: 0.32961

Collected Steps per Second: 22,523.08551
Overall Steps per Second: 14,443.71647

Timestep Collection Time: 2.22030
Timestep Consumption Time: 1.24197
PPO Batch Consumption Time: 0.09863
Total Iteration Time: 3.46227

Cumulative Model Updates: 53,708
Cumulative Timesteps: 448,121,754

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,466.55832
Policy Entropy: 0.75833
Value Function Loss: 0.10065

Mean KL Divergence: 0.00446
SB3 Clip Fraction: 0.05295
Policy Update Magnitude: 0.19623
Value Function Update Magnitude: 0.36387

Collected Steps per Second: 23,032.68259
Overall Steps per Second: 14,733.49464

Timestep Collection Time: 2.17178
Timestep Consumption Time: 1.22334
PPO Batch Consumption Time: 0.09802
Total Iteration Time: 3.39512

Cumulative Model Updates: 53,714
Cumulative Timesteps: 448,171,776

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 448171776...
Checkpoint 448171776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,802.97027
Policy Entropy: 0.75881
Value Function Loss: 0.10082

Mean KL Divergence: 0.00416
SB3 Clip Fraction: 0.04904
Policy Update Magnitude: 0.21914
Value Function Update Magnitude: 0.41249

Collected Steps per Second: 21,989.09530
Overall Steps per Second: 14,118.35616

Timestep Collection Time: 2.27495
Timestep Consumption Time: 1.26824
PPO Batch Consumption Time: 0.10243
Total Iteration Time: 3.54319

Cumulative Model Updates: 53,720
Cumulative Timesteps: 448,221,800

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,320.23443
Policy Entropy: 0.76120
Value Function Loss: 0.09619

Mean KL Divergence: 0.00420
SB3 Clip Fraction: 0.05029
Policy Update Magnitude: 0.22249
Value Function Update Magnitude: 0.43011

Collected Steps per Second: 22,976.22653
Overall Steps per Second: 14,682.40860

Timestep Collection Time: 2.17712
Timestep Consumption Time: 1.22981
PPO Batch Consumption Time: 0.09804
Total Iteration Time: 3.40693

Cumulative Model Updates: 53,726
Cumulative Timesteps: 448,271,822

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 448271822...
Checkpoint 448271822 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,974.59803
Policy Entropy: 0.76548
Value Function Loss: 0.08986

Mean KL Divergence: 0.00461
SB3 Clip Fraction: 0.05631
Policy Update Magnitude: 0.21641
Value Function Update Magnitude: 0.44143

Collected Steps per Second: 22,634.91623
Overall Steps per Second: 14,769.22721

Timestep Collection Time: 2.20960
Timestep Consumption Time: 1.17677
PPO Batch Consumption Time: 0.09325
Total Iteration Time: 3.38637

Cumulative Model Updates: 53,732
Cumulative Timesteps: 448,321,836

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,522.22936
Policy Entropy: 0.75767
Value Function Loss: 0.08652

Mean KL Divergence: 0.00451
SB3 Clip Fraction: 0.05530
Policy Update Magnitude: 0.20229
Value Function Update Magnitude: 0.43963

Collected Steps per Second: 22,506.99570
Overall Steps per Second: 14,363.42968

Timestep Collection Time: 2.22269
Timestep Consumption Time: 1.26019
PPO Batch Consumption Time: 0.10195
Total Iteration Time: 3.48287

Cumulative Model Updates: 53,738
Cumulative Timesteps: 448,371,862

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 448371862...
Checkpoint 448371862 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,493.82868
Policy Entropy: 0.74754
Value Function Loss: 0.08814

Mean KL Divergence: 0.00414
SB3 Clip Fraction: 0.04987
Policy Update Magnitude: 0.20586
Value Function Update Magnitude: 0.44457

Collected Steps per Second: 22,615.07198
Overall Steps per Second: 14,600.51007

Timestep Collection Time: 2.21136
Timestep Consumption Time: 1.21387
PPO Batch Consumption Time: 0.10235
Total Iteration Time: 3.42522

Cumulative Model Updates: 53,744
Cumulative Timesteps: 448,421,872

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,745.37748
Policy Entropy: 0.75389
Value Function Loss: 0.08936

Mean KL Divergence: 0.00402
SB3 Clip Fraction: 0.04850
Policy Update Magnitude: 0.20175
Value Function Update Magnitude: 0.44466

Collected Steps per Second: 22,452.24846
Overall Steps per Second: 14,570.13612

Timestep Collection Time: 2.22757
Timestep Consumption Time: 1.20507
PPO Batch Consumption Time: 0.09644
Total Iteration Time: 3.43264

Cumulative Model Updates: 53,750
Cumulative Timesteps: 448,471,886

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 448471886...
Checkpoint 448471886 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,852.17860
Policy Entropy: 0.75398
Value Function Loss: 0.08455

Mean KL Divergence: 0.00456
SB3 Clip Fraction: 0.05327
Policy Update Magnitude: 0.20030
Value Function Update Magnitude: 0.43901

Collected Steps per Second: 22,377.50673
Overall Steps per Second: 14,435.62652

Timestep Collection Time: 2.23492
Timestep Consumption Time: 1.22956
PPO Batch Consumption Time: 0.10169
Total Iteration Time: 3.46448

Cumulative Model Updates: 53,756
Cumulative Timesteps: 448,521,898

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,248.57936
Policy Entropy: 0.76162
Value Function Loss: 0.08115

Mean KL Divergence: 0.00452
SB3 Clip Fraction: 0.05550
Policy Update Magnitude: 0.18249
Value Function Update Magnitude: 0.41549

Collected Steps per Second: 23,023.01851
Overall Steps per Second: 14,603.25555

Timestep Collection Time: 2.17304
Timestep Consumption Time: 1.25291
PPO Batch Consumption Time: 0.10039
Total Iteration Time: 3.42595

Cumulative Model Updates: 53,762
Cumulative Timesteps: 448,571,928

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 448571928...
Checkpoint 448571928 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,757.70726
Policy Entropy: 0.75066
Value Function Loss: 0.08244

Mean KL Divergence: 0.00398
SB3 Clip Fraction: 0.04868
Policy Update Magnitude: 0.17974
Value Function Update Magnitude: 0.40307

Collected Steps per Second: 22,199.02988
Overall Steps per Second: 14,504.33425

Timestep Collection Time: 2.25352
Timestep Consumption Time: 1.19552
PPO Batch Consumption Time: 0.09416
Total Iteration Time: 3.44904

Cumulative Model Updates: 53,768
Cumulative Timesteps: 448,621,954

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,318.50095
Policy Entropy: 0.74547
Value Function Loss: 0.08281

Mean KL Divergence: 0.00359
SB3 Clip Fraction: 0.04270
Policy Update Magnitude: 0.18333
Value Function Update Magnitude: 0.41778

Collected Steps per Second: 21,818.06475
Overall Steps per Second: 14,072.65532

Timestep Collection Time: 2.29241
Timestep Consumption Time: 1.26171
PPO Batch Consumption Time: 0.10203
Total Iteration Time: 3.55413

Cumulative Model Updates: 53,774
Cumulative Timesteps: 448,671,970

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 448671970...
Checkpoint 448671970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,050.71137
Policy Entropy: 0.73588
Value Function Loss: 0.08350

Mean KL Divergence: 0.00392
SB3 Clip Fraction: 0.04728
Policy Update Magnitude: 0.19145
Value Function Update Magnitude: 0.43489

Collected Steps per Second: 22,492.58280
Overall Steps per Second: 14,440.09644

Timestep Collection Time: 2.22429
Timestep Consumption Time: 1.24037
PPO Batch Consumption Time: 0.10004
Total Iteration Time: 3.46466

Cumulative Model Updates: 53,780
Cumulative Timesteps: 448,722,000

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,389.84708
Policy Entropy: 0.74881
Value Function Loss: 0.07728

Mean KL Divergence: 0.00435
SB3 Clip Fraction: 0.05058
Policy Update Magnitude: 0.18712
Value Function Update Magnitude: 0.41276

Collected Steps per Second: 22,447.73991
Overall Steps per Second: 14,387.20900

Timestep Collection Time: 2.22802
Timestep Consumption Time: 1.24826
PPO Batch Consumption Time: 0.10318
Total Iteration Time: 3.47628

Cumulative Model Updates: 53,786
Cumulative Timesteps: 448,772,014

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 448772014...
Checkpoint 448772014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,127.45004
Policy Entropy: 0.75073
Value Function Loss: 0.08388

Mean KL Divergence: 0.00424
SB3 Clip Fraction: 0.04898
Policy Update Magnitude: 0.18973
Value Function Update Magnitude: 0.38782

Collected Steps per Second: 22,265.35596
Overall Steps per Second: 14,306.07636

Timestep Collection Time: 2.24645
Timestep Consumption Time: 1.24983
PPO Batch Consumption Time: 0.10093
Total Iteration Time: 3.49628

Cumulative Model Updates: 53,792
Cumulative Timesteps: 448,822,032

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,637.54957
Policy Entropy: 0.75244
Value Function Loss: 0.08213

Mean KL Divergence: 0.00362
SB3 Clip Fraction: 0.04368
Policy Update Magnitude: 0.18848
Value Function Update Magnitude: 0.40990

Collected Steps per Second: 23,027.11502
Overall Steps per Second: 14,692.79597

Timestep Collection Time: 2.17231
Timestep Consumption Time: 1.23222
PPO Batch Consumption Time: 0.10013
Total Iteration Time: 3.40453

Cumulative Model Updates: 53,798
Cumulative Timesteps: 448,872,054

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 448872054...
Checkpoint 448872054 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,830.63489
Policy Entropy: 0.74792
Value Function Loss: 0.08116

Mean KL Divergence: 0.00414
SB3 Clip Fraction: 0.04925
Policy Update Magnitude: 0.19705
Value Function Update Magnitude: 0.39685

Collected Steps per Second: 22,098.82633
Overall Steps per Second: 14,439.42531

Timestep Collection Time: 2.26265
Timestep Consumption Time: 1.20023
PPO Batch Consumption Time: 0.09710
Total Iteration Time: 3.46288

Cumulative Model Updates: 53,804
Cumulative Timesteps: 448,922,056

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,557.44526
Policy Entropy: 0.75125
Value Function Loss: 0.07681

Mean KL Divergence: 0.00450
SB3 Clip Fraction: 0.05268
Policy Update Magnitude: 0.19406
Value Function Update Magnitude: 0.37451

Collected Steps per Second: 22,463.41209
Overall Steps per Second: 14,258.11910

Timestep Collection Time: 2.22709
Timestep Consumption Time: 1.28165
PPO Batch Consumption Time: 0.10094
Total Iteration Time: 3.50874

Cumulative Model Updates: 53,810
Cumulative Timesteps: 448,972,084

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 448972084...
Checkpoint 448972084 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,113.75449
Policy Entropy: 0.74984
Value Function Loss: 0.08016

Mean KL Divergence: 0.00375
SB3 Clip Fraction: 0.04566
Policy Update Magnitude: 0.18661
Value Function Update Magnitude: 0.40073

Collected Steps per Second: 23,155.74209
Overall Steps per Second: 14,754.44844

Timestep Collection Time: 2.15998
Timestep Consumption Time: 1.22991
PPO Batch Consumption Time: 0.10073
Total Iteration Time: 3.38989

Cumulative Model Updates: 53,816
Cumulative Timesteps: 449,022,100

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,082.17427
Policy Entropy: 0.75364
Value Function Loss: 0.08784

Mean KL Divergence: 0.00358
SB3 Clip Fraction: 0.04368
Policy Update Magnitude: 0.19379
Value Function Update Magnitude: 0.40711

Collected Steps per Second: 22,758.99896
Overall Steps per Second: 14,591.17449

Timestep Collection Time: 2.19764
Timestep Consumption Time: 1.23019
PPO Batch Consumption Time: 0.10134
Total Iteration Time: 3.42783

Cumulative Model Updates: 53,822
Cumulative Timesteps: 449,072,116

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 449072116...
Checkpoint 449072116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,391.74869
Policy Entropy: 0.74410
Value Function Loss: 0.08820

Mean KL Divergence: 0.00436
SB3 Clip Fraction: 0.05047
Policy Update Magnitude: 0.20089
Value Function Update Magnitude: 0.41747

Collected Steps per Second: 22,524.15793
Overall Steps per Second: 14,209.26804

Timestep Collection Time: 2.22002
Timestep Consumption Time: 1.29910
PPO Batch Consumption Time: 0.10146
Total Iteration Time: 3.51911

Cumulative Model Updates: 53,828
Cumulative Timesteps: 449,122,120

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,700.61686
Policy Entropy: 0.74083
Value Function Loss: 0.09087

Mean KL Divergence: 0.00427
SB3 Clip Fraction: 0.04913
Policy Update Magnitude: 0.19325
Value Function Update Magnitude: 0.41446

Collected Steps per Second: 23,119.15172
Overall Steps per Second: 14,718.97951

Timestep Collection Time: 2.16366
Timestep Consumption Time: 1.23481
PPO Batch Consumption Time: 0.10196
Total Iteration Time: 3.39847

Cumulative Model Updates: 53,834
Cumulative Timesteps: 449,172,142

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 449172142...
Checkpoint 449172142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,696.67084
Policy Entropy: 0.73926
Value Function Loss: 0.09085

Mean KL Divergence: 0.00429
SB3 Clip Fraction: 0.05148
Policy Update Magnitude: 0.19861
Value Function Update Magnitude: 0.41016

Collected Steps per Second: 22,224.56622
Overall Steps per Second: 14,488.97876

Timestep Collection Time: 2.25066
Timestep Consumption Time: 1.20162
PPO Batch Consumption Time: 0.09342
Total Iteration Time: 3.45228

Cumulative Model Updates: 53,840
Cumulative Timesteps: 449,222,162

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,956.37333
Policy Entropy: 0.74724
Value Function Loss: 0.08714

Mean KL Divergence: 0.00419
SB3 Clip Fraction: 0.05016
Policy Update Magnitude: 0.20076
Value Function Update Magnitude: 0.41830

Collected Steps per Second: 23,003.24493
Overall Steps per Second: 14,759.13032

Timestep Collection Time: 2.17561
Timestep Consumption Time: 1.21524
PPO Batch Consumption Time: 0.09256
Total Iteration Time: 3.39085

Cumulative Model Updates: 53,846
Cumulative Timesteps: 449,272,208

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 449272208...
Checkpoint 449272208 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,900.77000
Policy Entropy: 0.74098
Value Function Loss: 0.08397

Mean KL Divergence: 0.00615
SB3 Clip Fraction: 0.06871
Policy Update Magnitude: 0.19220
Value Function Update Magnitude: 0.41907

Collected Steps per Second: 22,800.87818
Overall Steps per Second: 14,853.03964

Timestep Collection Time: 2.19404
Timestep Consumption Time: 1.17403
PPO Batch Consumption Time: 0.09501
Total Iteration Time: 3.36806

Cumulative Model Updates: 53,852
Cumulative Timesteps: 449,322,234

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,481.12371
Policy Entropy: 0.73346
Value Function Loss: 0.08174

Mean KL Divergence: 0.00640
SB3 Clip Fraction: 0.07142
Policy Update Magnitude: 0.18488
Value Function Update Magnitude: 0.42012

Collected Steps per Second: 22,343.21359
Overall Steps per Second: 14,208.03054

Timestep Collection Time: 2.23880
Timestep Consumption Time: 1.28188
PPO Batch Consumption Time: 0.10242
Total Iteration Time: 3.52068

Cumulative Model Updates: 53,858
Cumulative Timesteps: 449,372,256

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 449372256...
Checkpoint 449372256 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,914.89602
Policy Entropy: 0.72150
Value Function Loss: 0.08560

Mean KL Divergence: 0.00477
SB3 Clip Fraction: 0.05645
Policy Update Magnitude: 0.18021
Value Function Update Magnitude: 0.42139

Collected Steps per Second: 22,518.69593
Overall Steps per Second: 14,549.07761

Timestep Collection Time: 2.22189
Timestep Consumption Time: 1.21709
PPO Batch Consumption Time: 0.09305
Total Iteration Time: 3.43898

Cumulative Model Updates: 53,864
Cumulative Timesteps: 449,422,290

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,799.58027
Policy Entropy: 0.71993
Value Function Loss: 0.09339

Mean KL Divergence: 0.00415
SB3 Clip Fraction: 0.04988
Policy Update Magnitude: 0.18544
Value Function Update Magnitude: 0.43808

Collected Steps per Second: 23,265.38171
Overall Steps per Second: 14,806.52056

Timestep Collection Time: 2.15015
Timestep Consumption Time: 1.22836
PPO Batch Consumption Time: 0.09692
Total Iteration Time: 3.37851

Cumulative Model Updates: 53,870
Cumulative Timesteps: 449,472,314

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 449472314...
Checkpoint 449472314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,755.39486
Policy Entropy: 0.72940
Value Function Loss: 0.09045

Mean KL Divergence: 0.00344
SB3 Clip Fraction: 0.04160
Policy Update Magnitude: 0.19032
Value Function Update Magnitude: 0.44083

Collected Steps per Second: 22,185.76093
Overall Steps per Second: 14,434.32658

Timestep Collection Time: 2.25469
Timestep Consumption Time: 1.21080
PPO Batch Consumption Time: 0.10091
Total Iteration Time: 3.46549

Cumulative Model Updates: 53,876
Cumulative Timesteps: 449,522,336

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,999.35848
Policy Entropy: 0.73576
Value Function Loss: 0.08490

Mean KL Divergence: 0.00363
SB3 Clip Fraction: 0.04331
Policy Update Magnitude: 0.18778
Value Function Update Magnitude: 0.42951

Collected Steps per Second: 22,376.17570
Overall Steps per Second: 14,359.57271

Timestep Collection Time: 2.23479
Timestep Consumption Time: 1.24763
PPO Batch Consumption Time: 0.09628
Total Iteration Time: 3.48242

Cumulative Model Updates: 53,882
Cumulative Timesteps: 449,572,342

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 449572342...
Checkpoint 449572342 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,317.37581
Policy Entropy: 0.74319
Value Function Loss: 0.08603

Mean KL Divergence: 0.00282
SB3 Clip Fraction: 0.03393
Policy Update Magnitude: 0.19313
Value Function Update Magnitude: 0.41375

Collected Steps per Second: 22,353.89130
Overall Steps per Second: 14,412.73922

Timestep Collection Time: 2.23773
Timestep Consumption Time: 1.23295
PPO Batch Consumption Time: 0.10059
Total Iteration Time: 3.47068

Cumulative Model Updates: 53,888
Cumulative Timesteps: 449,622,364

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,177.56883
Policy Entropy: 0.74962
Value Function Loss: 0.09140

Mean KL Divergence: 0.00383
SB3 Clip Fraction: 0.04654
Policy Update Magnitude: 0.19602
Value Function Update Magnitude: 0.41465

Collected Steps per Second: 22,095.02122
Overall Steps per Second: 14,820.40304

Timestep Collection Time: 2.26422
Timestep Consumption Time: 1.11140
PPO Batch Consumption Time: 0.07476
Total Iteration Time: 3.37562

Cumulative Model Updates: 53,894
Cumulative Timesteps: 449,672,392

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 449672392...
Checkpoint 449672392 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,668.37332
Policy Entropy: 0.75424
Value Function Loss: 0.08929

Mean KL Divergence: 0.00730
SB3 Clip Fraction: 0.07612
Policy Update Magnitude: 0.19147
Value Function Update Magnitude: 0.42246

Collected Steps per Second: 22,632.23461
Overall Steps per Second: 14,393.58890

Timestep Collection Time: 2.20959
Timestep Consumption Time: 1.26473
PPO Batch Consumption Time: 0.09958
Total Iteration Time: 3.47432

Cumulative Model Updates: 53,900
Cumulative Timesteps: 449,722,400

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,734.23693
Policy Entropy: 0.74451
Value Function Loss: 0.08300

Mean KL Divergence: 0.00696
SB3 Clip Fraction: 0.07449
Policy Update Magnitude: 0.17305
Value Function Update Magnitude: 0.41740

Collected Steps per Second: 23,000.21959
Overall Steps per Second: 14,672.14946

Timestep Collection Time: 2.17407
Timestep Consumption Time: 1.23402
PPO Batch Consumption Time: 0.09629
Total Iteration Time: 3.40809

Cumulative Model Updates: 53,906
Cumulative Timesteps: 449,772,404

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 449772404...
Checkpoint 449772404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,662.47065
Policy Entropy: 0.73493
Value Function Loss: 0.07582

Mean KL Divergence: 0.00702
SB3 Clip Fraction: 0.07071
Policy Update Magnitude: 0.17951
Value Function Update Magnitude: 0.40631

Collected Steps per Second: 21,851.79077
Overall Steps per Second: 14,123.70727

Timestep Collection Time: 2.28961
Timestep Consumption Time: 1.25281
PPO Batch Consumption Time: 0.10181
Total Iteration Time: 3.54241

Cumulative Model Updates: 53,912
Cumulative Timesteps: 449,822,436

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,072.51139
Policy Entropy: 0.73243
Value Function Loss: 0.07620

Mean KL Divergence: 0.00689
SB3 Clip Fraction: 0.06736
Policy Update Magnitude: 0.17414
Value Function Update Magnitude: 0.39081

Collected Steps per Second: 22,988.07246
Overall Steps per Second: 14,631.06248

Timestep Collection Time: 2.17530
Timestep Consumption Time: 1.24249
PPO Batch Consumption Time: 0.09690
Total Iteration Time: 3.41780

Cumulative Model Updates: 53,918
Cumulative Timesteps: 449,872,442

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 449872442...
Checkpoint 449872442 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,065.07437
Policy Entropy: 0.73059
Value Function Loss: 0.07382

Mean KL Divergence: 0.00643
SB3 Clip Fraction: 0.06569
Policy Update Magnitude: 0.18008
Value Function Update Magnitude: 0.35334

Collected Steps per Second: 22,826.46936
Overall Steps per Second: 14,809.67062

Timestep Collection Time: 2.19097
Timestep Consumption Time: 1.18602
PPO Batch Consumption Time: 0.09011
Total Iteration Time: 3.37698

Cumulative Model Updates: 53,924
Cumulative Timesteps: 449,922,454

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,081.12400
Policy Entropy: 0.73680
Value Function Loss: 0.07466

Mean KL Divergence: 0.00584
SB3 Clip Fraction: 0.06182
Policy Update Magnitude: 0.18151
Value Function Update Magnitude: 0.34603

Collected Steps per Second: 22,381.81257
Overall Steps per Second: 14,769.04717

Timestep Collection Time: 2.23565
Timestep Consumption Time: 1.15238
PPO Batch Consumption Time: 0.09314
Total Iteration Time: 3.38803

Cumulative Model Updates: 53,930
Cumulative Timesteps: 449,972,492

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 449972492...
Checkpoint 449972492 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,483.73234
Policy Entropy: 0.73358
Value Function Loss: 0.07523

Mean KL Divergence: 0.00531
SB3 Clip Fraction: 0.05848
Policy Update Magnitude: 0.17830
Value Function Update Magnitude: 0.34526

Collected Steps per Second: 22,764.64894
Overall Steps per Second: 14,464.90105

Timestep Collection Time: 2.19683
Timestep Consumption Time: 1.26051
PPO Batch Consumption Time: 0.10169
Total Iteration Time: 3.45733

Cumulative Model Updates: 53,936
Cumulative Timesteps: 450,022,502

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,038.30531
Policy Entropy: 0.73577
Value Function Loss: 0.07628

Mean KL Divergence: 0.00414
SB3 Clip Fraction: 0.04824
Policy Update Magnitude: 0.18104
Value Function Update Magnitude: 0.34719

Collected Steps per Second: 22,570.19073
Overall Steps per Second: 14,439.14520

Timestep Collection Time: 2.21629
Timestep Consumption Time: 1.24805
PPO Batch Consumption Time: 0.10118
Total Iteration Time: 3.46433

Cumulative Model Updates: 53,942
Cumulative Timesteps: 450,072,524

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 450072524...
Checkpoint 450072524 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,698.01306
Policy Entropy: 0.74718
Value Function Loss: 0.08087

Mean KL Divergence: 0.00400
SB3 Clip Fraction: 0.04686
Policy Update Magnitude: 0.18519
Value Function Update Magnitude: 0.36169

Collected Steps per Second: 21,870.32098
Overall Steps per Second: 14,025.65815

Timestep Collection Time: 2.28620
Timestep Consumption Time: 1.27869
PPO Batch Consumption Time: 0.10383
Total Iteration Time: 3.56490

Cumulative Model Updates: 53,948
Cumulative Timesteps: 450,122,524

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,102.36415
Policy Entropy: 0.74604
Value Function Loss: 0.08358

Mean KL Divergence: 0.00336
SB3 Clip Fraction: 0.03983
Policy Update Magnitude: 0.18759
Value Function Update Magnitude: 0.38075

Collected Steps per Second: 23,095.85695
Overall Steps per Second: 14,702.82323

Timestep Collection Time: 2.16576
Timestep Consumption Time: 1.23631
PPO Batch Consumption Time: 0.09977
Total Iteration Time: 3.40207

Cumulative Model Updates: 53,954
Cumulative Timesteps: 450,172,544

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 450172544...
Checkpoint 450172544 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,034.21170
Policy Entropy: 0.74736
Value Function Loss: 0.09116

Mean KL Divergence: 0.00366
SB3 Clip Fraction: 0.04338
Policy Update Magnitude: 0.18713
Value Function Update Magnitude: 0.41543

Collected Steps per Second: 22,236.31582
Overall Steps per Second: 14,341.85187

Timestep Collection Time: 2.24956
Timestep Consumption Time: 1.23827
PPO Batch Consumption Time: 0.10080
Total Iteration Time: 3.48783

Cumulative Model Updates: 53,960
Cumulative Timesteps: 450,222,566

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,343.12281
Policy Entropy: 0.74408
Value Function Loss: 0.09453

Mean KL Divergence: 0.00424
SB3 Clip Fraction: 0.05131
Policy Update Magnitude: 0.19238
Value Function Update Magnitude: 0.42942

Collected Steps per Second: 21,971.28617
Overall Steps per Second: 13,953.09327

Timestep Collection Time: 2.27715
Timestep Consumption Time: 1.30857
PPO Batch Consumption Time: 0.10215
Total Iteration Time: 3.58573

Cumulative Model Updates: 53,966
Cumulative Timesteps: 450,272,598

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 450272598...
Checkpoint 450272598 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,806.33534
Policy Entropy: 0.75343
Value Function Loss: 0.09283

Mean KL Divergence: 0.00494
SB3 Clip Fraction: 0.05645
Policy Update Magnitude: 0.19653
Value Function Update Magnitude: 0.43143

Collected Steps per Second: 22,503.69790
Overall Steps per Second: 14,413.79759

Timestep Collection Time: 2.22275
Timestep Consumption Time: 1.24754
PPO Batch Consumption Time: 0.10031
Total Iteration Time: 3.47029

Cumulative Model Updates: 53,972
Cumulative Timesteps: 450,322,618

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,109.91001
Policy Entropy: 0.75382
Value Function Loss: 0.08089

Mean KL Divergence: 0.00414
SB3 Clip Fraction: 0.04907
Policy Update Magnitude: 0.19063
Value Function Update Magnitude: 0.40807

Collected Steps per Second: 22,939.96000
Overall Steps per Second: 14,767.18383

Timestep Collection Time: 2.18100
Timestep Consumption Time: 1.20706
PPO Batch Consumption Time: 0.09709
Total Iteration Time: 3.38805

Cumulative Model Updates: 53,978
Cumulative Timesteps: 450,372,650

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 450372650...
Checkpoint 450372650 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,963.10169
Policy Entropy: 0.74786
Value Function Loss: 0.07344

Mean KL Divergence: 0.00407
SB3 Clip Fraction: 0.04905
Policy Update Magnitude: 0.18151
Value Function Update Magnitude: 0.38834

Collected Steps per Second: 22,076.31791
Overall Steps per Second: 14,281.85182

Timestep Collection Time: 2.26569
Timestep Consumption Time: 1.23652
PPO Batch Consumption Time: 0.10085
Total Iteration Time: 3.50221

Cumulative Model Updates: 53,984
Cumulative Timesteps: 450,422,668

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,359.82047
Policy Entropy: 0.74172
Value Function Loss: 0.07785

Mean KL Divergence: 0.00391
SB3 Clip Fraction: 0.04638
Policy Update Magnitude: 0.17796
Value Function Update Magnitude: 0.36117

Collected Steps per Second: 22,605.13692
Overall Steps per Second: 14,515.66263

Timestep Collection Time: 2.21198
Timestep Consumption Time: 1.23272
PPO Batch Consumption Time: 0.09940
Total Iteration Time: 3.44469

Cumulative Model Updates: 53,990
Cumulative Timesteps: 450,472,670

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 450472670...
Checkpoint 450472670 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,149.57196
Policy Entropy: 0.74997
Value Function Loss: 0.08084

Mean KL Divergence: 0.00364
SB3 Clip Fraction: 0.04459
Policy Update Magnitude: 0.18033
Value Function Update Magnitude: 0.35152

Collected Steps per Second: 22,354.11748
Overall Steps per Second: 14,343.04425

Timestep Collection Time: 2.23672
Timestep Consumption Time: 1.24929
PPO Batch Consumption Time: 0.09947
Total Iteration Time: 3.48601

Cumulative Model Updates: 53,996
Cumulative Timesteps: 450,522,670

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,903.80371
Policy Entropy: 0.75716
Value Function Loss: 0.08002

Mean KL Divergence: 0.00368
SB3 Clip Fraction: 0.04554
Policy Update Magnitude: 0.18487
Value Function Update Magnitude: 0.37072

Collected Steps per Second: 22,243.37589
Overall Steps per Second: 14,401.90039

Timestep Collection Time: 2.24831
Timestep Consumption Time: 1.22415
PPO Batch Consumption Time: 0.09875
Total Iteration Time: 3.47246

Cumulative Model Updates: 54,002
Cumulative Timesteps: 450,572,680

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 450572680...
Checkpoint 450572680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,033.35600
Policy Entropy: 0.74914
Value Function Loss: 0.08826

Mean KL Divergence: 0.00439
SB3 Clip Fraction: 0.05202
Policy Update Magnitude: 0.18212
Value Function Update Magnitude: 0.39767

Collected Steps per Second: 22,718.55267
Overall Steps per Second: 14,726.85516

Timestep Collection Time: 2.20234
Timestep Consumption Time: 1.19513
PPO Batch Consumption Time: 0.09283
Total Iteration Time: 3.39747

Cumulative Model Updates: 54,008
Cumulative Timesteps: 450,622,714

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,048.39274
Policy Entropy: 0.73767
Value Function Loss: 0.09050

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.07598
Policy Update Magnitude: 0.17604
Value Function Update Magnitude: 0.42004

Collected Steps per Second: 22,691.04015
Overall Steps per Second: 14,720.62664

Timestep Collection Time: 2.20457
Timestep Consumption Time: 1.19365
PPO Batch Consumption Time: 0.09151
Total Iteration Time: 3.39822

Cumulative Model Updates: 54,014
Cumulative Timesteps: 450,672,738

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 450672738...
Checkpoint 450672738 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,109.64534
Policy Entropy: 0.73460
Value Function Loss: 0.09655

Mean KL Divergence: 0.00698
SB3 Clip Fraction: 0.06659
Policy Update Magnitude: 0.18013
Value Function Update Magnitude: 0.42512

Collected Steps per Second: 22,221.26823
Overall Steps per Second: 14,366.92356

Timestep Collection Time: 2.25019
Timestep Consumption Time: 1.23017
PPO Batch Consumption Time: 0.10160
Total Iteration Time: 3.48036

Cumulative Model Updates: 54,020
Cumulative Timesteps: 450,722,740

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,815.29740
Policy Entropy: 0.72673
Value Function Loss: 0.08805

Mean KL Divergence: 0.00698
SB3 Clip Fraction: 0.07015
Policy Update Magnitude: 0.17850
Value Function Update Magnitude: 0.41784

Collected Steps per Second: 23,079.17203
Overall Steps per Second: 14,557.34712

Timestep Collection Time: 2.16819
Timestep Consumption Time: 1.26925
PPO Batch Consumption Time: 0.10186
Total Iteration Time: 3.43744

Cumulative Model Updates: 54,026
Cumulative Timesteps: 450,772,780

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 450772780...
Checkpoint 450772780 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,008.20809
Policy Entropy: 0.73546
Value Function Loss: 0.07590

Mean KL Divergence: 0.00714
SB3 Clip Fraction: 0.07363
Policy Update Magnitude: 0.18471
Value Function Update Magnitude: 0.40941

Collected Steps per Second: 21,432.46325
Overall Steps per Second: 13,978.83060

Timestep Collection Time: 2.33328
Timestep Consumption Time: 1.24413
PPO Batch Consumption Time: 0.09986
Total Iteration Time: 3.57741

Cumulative Model Updates: 54,032
Cumulative Timesteps: 450,822,788

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,212.62993
Policy Entropy: 0.73859
Value Function Loss: 0.06816

Mean KL Divergence: 0.00655
SB3 Clip Fraction: 0.06904
Policy Update Magnitude: 0.17370
Value Function Update Magnitude: 0.40159

Collected Steps per Second: 22,294.50513
Overall Steps per Second: 14,289.08747

Timestep Collection Time: 2.24288
Timestep Consumption Time: 1.25657
PPO Batch Consumption Time: 0.10217
Total Iteration Time: 3.49945

Cumulative Model Updates: 54,038
Cumulative Timesteps: 450,872,792

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 450872792...
Checkpoint 450872792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,185.56954
Policy Entropy: 0.74425
Value Function Loss: 0.07262

Mean KL Divergence: 0.00507
SB3 Clip Fraction: 0.05885
Policy Update Magnitude: 0.17272
Value Function Update Magnitude: 0.39246

Collected Steps per Second: 22,631.79225
Overall Steps per Second: 14,564.63324

Timestep Collection Time: 2.21114
Timestep Consumption Time: 1.22472
PPO Batch Consumption Time: 0.10278
Total Iteration Time: 3.43586

Cumulative Model Updates: 54,044
Cumulative Timesteps: 450,922,834

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,544.38449
Policy Entropy: 0.75755
Value Function Loss: 0.08130

Mean KL Divergence: 0.00468
SB3 Clip Fraction: 0.05472
Policy Update Magnitude: 0.18560
Value Function Update Magnitude: 0.38858

Collected Steps per Second: 22,937.39531
Overall Steps per Second: 14,685.49926

Timestep Collection Time: 2.18072
Timestep Consumption Time: 1.22536
PPO Batch Consumption Time: 0.09893
Total Iteration Time: 3.40608

Cumulative Model Updates: 54,050
Cumulative Timesteps: 450,972,854

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 450972854...
Checkpoint 450972854 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,172.18049
Policy Entropy: 0.75216
Value Function Loss: 0.09322

Mean KL Divergence: 0.00515
SB3 Clip Fraction: 0.05866
Policy Update Magnitude: 0.19268
Value Function Update Magnitude: 0.40274

Collected Steps per Second: 22,054.11859
Overall Steps per Second: 14,087.48422

Timestep Collection Time: 2.26733
Timestep Consumption Time: 1.28220
PPO Batch Consumption Time: 0.10403
Total Iteration Time: 3.54953

Cumulative Model Updates: 54,056
Cumulative Timesteps: 451,022,858

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,623.63030
Policy Entropy: 0.74884
Value Function Loss: 0.08963

Mean KL Divergence: 0.00485
SB3 Clip Fraction: 0.05630
Policy Update Magnitude: 0.19626
Value Function Update Magnitude: 0.41373

Collected Steps per Second: 23,015.34620
Overall Steps per Second: 14,597.82703

Timestep Collection Time: 2.17359
Timestep Consumption Time: 1.25336
PPO Batch Consumption Time: 0.09632
Total Iteration Time: 3.42695

Cumulative Model Updates: 54,062
Cumulative Timesteps: 451,072,884

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 451072884...
Checkpoint 451072884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,266.86665
Policy Entropy: 0.73056
Value Function Loss: 0.08385

Mean KL Divergence: 0.00442
SB3 Clip Fraction: 0.05169
Policy Update Magnitude: 0.19282
Value Function Update Magnitude: 0.40251

Collected Steps per Second: 22,400.85035
Overall Steps per Second: 14,385.77220

Timestep Collection Time: 2.23268
Timestep Consumption Time: 1.24395
PPO Batch Consumption Time: 0.10140
Total Iteration Time: 3.47663

Cumulative Model Updates: 54,068
Cumulative Timesteps: 451,122,898

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,850.54989
Policy Entropy: 0.73108
Value Function Loss: 0.08194

Mean KL Divergence: 0.00394
SB3 Clip Fraction: 0.04602
Policy Update Magnitude: 0.18243
Value Function Update Magnitude: 0.39594

Collected Steps per Second: 22,621.47010
Overall Steps per Second: 14,493.71910

Timestep Collection Time: 2.21109
Timestep Consumption Time: 1.23993
PPO Batch Consumption Time: 0.09956
Total Iteration Time: 3.45101

Cumulative Model Updates: 54,074
Cumulative Timesteps: 451,172,916

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 451172916...
Checkpoint 451172916 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,950.10416
Policy Entropy: 0.72659
Value Function Loss: 0.08262

Mean KL Divergence: 0.00375
SB3 Clip Fraction: 0.04493
Policy Update Magnitude: 0.17949
Value Function Update Magnitude: 0.40259

Collected Steps per Second: 22,741.54115
Overall Steps per Second: 14,683.27896

Timestep Collection Time: 2.20003
Timestep Consumption Time: 1.20739
PPO Batch Consumption Time: 0.09215
Total Iteration Time: 3.40741

Cumulative Model Updates: 54,080
Cumulative Timesteps: 451,222,948

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,771.56937
Policy Entropy: 0.73432
Value Function Loss: 0.08412

Mean KL Divergence: 0.00438
SB3 Clip Fraction: 0.05137
Policy Update Magnitude: 0.17899
Value Function Update Magnitude: 0.41649

Collected Steps per Second: 22,455.59687
Overall Steps per Second: 14,766.38706

Timestep Collection Time: 2.22760
Timestep Consumption Time: 1.15996
PPO Batch Consumption Time: 0.09290
Total Iteration Time: 3.38756

Cumulative Model Updates: 54,086
Cumulative Timesteps: 451,272,970

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 451272970...
Checkpoint 451272970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,313.94401
Policy Entropy: 0.72900
Value Function Loss: 0.08096

Mean KL Divergence: 0.00477
SB3 Clip Fraction: 0.05403
Policy Update Magnitude: 0.17362
Value Function Update Magnitude: 0.40888

Collected Steps per Second: 22,133.63829
Overall Steps per Second: 14,178.13138

Timestep Collection Time: 2.25928
Timestep Consumption Time: 1.26770
PPO Batch Consumption Time: 0.10329
Total Iteration Time: 3.52698

Cumulative Model Updates: 54,092
Cumulative Timesteps: 451,322,976

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,667.74550
Policy Entropy: 0.74471
Value Function Loss: 0.08796

Mean KL Divergence: 0.00496
SB3 Clip Fraction: 0.05747
Policy Update Magnitude: 0.18843
Value Function Update Magnitude: 0.41208

Collected Steps per Second: 22,993.71810
Overall Steps per Second: 14,702.30651

Timestep Collection Time: 2.17520
Timestep Consumption Time: 1.22671
PPO Batch Consumption Time: 0.09594
Total Iteration Time: 3.40192

Cumulative Model Updates: 54,098
Cumulative Timesteps: 451,372,992

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 451372992...
Checkpoint 451372992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,521.09827
Policy Entropy: 0.73418
Value Function Loss: 0.08497

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.08089
Policy Update Magnitude: 0.18650
Value Function Update Magnitude: 0.40558

Collected Steps per Second: 22,103.32520
Overall Steps per Second: 14,218.08749

Timestep Collection Time: 2.26256
Timestep Consumption Time: 1.25480
PPO Batch Consumption Time: 0.10028
Total Iteration Time: 3.51735

Cumulative Model Updates: 54,104
Cumulative Timesteps: 451,423,002

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,961.07119
Policy Entropy: 0.73689
Value Function Loss: 0.09110

Mean KL Divergence: 0.00733
SB3 Clip Fraction: 0.07009
Policy Update Magnitude: 0.18626
Value Function Update Magnitude: 0.41164

Collected Steps per Second: 22,539.64451
Overall Steps per Second: 14,446.13129

Timestep Collection Time: 2.21858
Timestep Consumption Time: 1.24297
PPO Batch Consumption Time: 0.09638
Total Iteration Time: 3.46155

Cumulative Model Updates: 54,110
Cumulative Timesteps: 451,473,008

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 451473008...
Checkpoint 451473008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,318.58547
Policy Entropy: 0.73202
Value Function Loss: 0.09581

Mean KL Divergence: 0.00682
SB3 Clip Fraction: 0.07060
Policy Update Magnitude: 0.18915
Value Function Update Magnitude: 0.43555

Collected Steps per Second: 22,566.89826
Overall Steps per Second: 14,474.94713

Timestep Collection Time: 2.21608
Timestep Consumption Time: 1.23886
PPO Batch Consumption Time: 0.10074
Total Iteration Time: 3.45493

Cumulative Model Updates: 54,116
Cumulative Timesteps: 451,523,018

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,459.61450
Policy Entropy: 0.73190
Value Function Loss: 0.10184

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.07710
Policy Update Magnitude: 0.19093
Value Function Update Magnitude: 0.43212

Collected Steps per Second: 22,334.20775
Overall Steps per Second: 14,353.95332

Timestep Collection Time: 2.23997
Timestep Consumption Time: 1.24534
PPO Batch Consumption Time: 0.09786
Total Iteration Time: 3.48531

Cumulative Model Updates: 54,122
Cumulative Timesteps: 451,573,046

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 451573046...
Checkpoint 451573046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,589.58618
Policy Entropy: 0.72674
Value Function Loss: 0.09494

Mean KL Divergence: 0.00756
SB3 Clip Fraction: 0.07432
Policy Update Magnitude: 0.17686
Value Function Update Magnitude: 0.42492

Collected Steps per Second: 22,104.22381
Overall Steps per Second: 14,076.19100

Timestep Collection Time: 2.26255
Timestep Consumption Time: 1.29040
PPO Batch Consumption Time: 0.10356
Total Iteration Time: 3.55295

Cumulative Model Updates: 54,128
Cumulative Timesteps: 451,623,058

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,614.53650
Policy Entropy: 0.72529
Value Function Loss: 0.08156

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.07316
Policy Update Magnitude: 0.16824
Value Function Update Magnitude: 0.43180

Collected Steps per Second: 22,385.22572
Overall Steps per Second: 14,556.97764

Timestep Collection Time: 2.23487
Timestep Consumption Time: 1.20184
PPO Batch Consumption Time: 0.09354
Total Iteration Time: 3.43670

Cumulative Model Updates: 54,134
Cumulative Timesteps: 451,673,086

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 451673086...
Checkpoint 451673086 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,781.77465
Policy Entropy: 0.72925
Value Function Loss: 0.07717

Mean KL Divergence: 0.00734
SB3 Clip Fraction: 0.07226
Policy Update Magnitude: 0.17069
Value Function Update Magnitude: 0.41066

Collected Steps per Second: 21,886.29151
Overall Steps per Second: 14,223.09283

Timestep Collection Time: 2.28673
Timestep Consumption Time: 1.23206
PPO Batch Consumption Time: 0.10206
Total Iteration Time: 3.51878

Cumulative Model Updates: 54,140
Cumulative Timesteps: 451,723,134

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,963.54252
Policy Entropy: 0.73247
Value Function Loss: 0.08457

Mean KL Divergence: 0.00543
SB3 Clip Fraction: 0.05821
Policy Update Magnitude: 0.18445
Value Function Update Magnitude: 0.39323

Collected Steps per Second: 22,809.08688
Overall Steps per Second: 14,579.02504

Timestep Collection Time: 2.19377
Timestep Consumption Time: 1.23842
PPO Batch Consumption Time: 0.09579
Total Iteration Time: 3.43219

Cumulative Model Updates: 54,146
Cumulative Timesteps: 451,773,172

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 451773172...
Checkpoint 451773172 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,923.23084
Policy Entropy: 0.73670
Value Function Loss: 0.09190

Mean KL Divergence: 0.00418
SB3 Clip Fraction: 0.04821
Policy Update Magnitude: 0.19785
Value Function Update Magnitude: 0.41459

Collected Steps per Second: 22,612.15053
Overall Steps per Second: 14,446.78009

Timestep Collection Time: 2.21182
Timestep Consumption Time: 1.25013
PPO Batch Consumption Time: 0.10078
Total Iteration Time: 3.46195

Cumulative Model Updates: 54,152
Cumulative Timesteps: 451,823,186

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,568.37677
Policy Entropy: 0.73876
Value Function Loss: 0.09180

Mean KL Divergence: 0.00432
SB3 Clip Fraction: 0.05163
Policy Update Magnitude: 0.20238
Value Function Update Magnitude: 0.42921

Collected Steps per Second: 22,391.46385
Overall Steps per Second: 14,429.85749

Timestep Collection Time: 2.23389
Timestep Consumption Time: 1.23254
PPO Batch Consumption Time: 0.10097
Total Iteration Time: 3.46642

Cumulative Model Updates: 54,158
Cumulative Timesteps: 451,873,206

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 451873206...
Checkpoint 451873206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,222.15556
Policy Entropy: 0.73960
Value Function Loss: 0.08914

Mean KL Divergence: 0.00428
SB3 Clip Fraction: 0.05100
Policy Update Magnitude: 0.20704
Value Function Update Magnitude: 0.42741

Collected Steps per Second: 22,253.17267
Overall Steps per Second: 14,195.60240

Timestep Collection Time: 2.24732
Timestep Consumption Time: 1.27560
PPO Batch Consumption Time: 0.10193
Total Iteration Time: 3.52292

Cumulative Model Updates: 54,164
Cumulative Timesteps: 451,923,216

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,616.24555
Policy Entropy: 0.74184
Value Function Loss: 0.08183

Mean KL Divergence: 0.00540
SB3 Clip Fraction: 0.06225
Policy Update Magnitude: 0.21266
Value Function Update Magnitude: 0.41580

Collected Steps per Second: 23,022.97458
Overall Steps per Second: 14,600.07944

Timestep Collection Time: 2.17174
Timestep Consumption Time: 1.25290
PPO Batch Consumption Time: 0.10249
Total Iteration Time: 3.42464

Cumulative Model Updates: 54,170
Cumulative Timesteps: 451,973,216

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 451973216...
Checkpoint 451973216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,712.81333
Policy Entropy: 0.74945
Value Function Loss: 0.08271

Mean KL Divergence: 0.00470
SB3 Clip Fraction: 0.05589
Policy Update Magnitude: 0.19325
Value Function Update Magnitude: 0.39817

Collected Steps per Second: 22,399.54925
Overall Steps per Second: 14,309.43118

Timestep Collection Time: 2.23272
Timestep Consumption Time: 1.26231
PPO Batch Consumption Time: 0.10153
Total Iteration Time: 3.49504

Cumulative Model Updates: 54,176
Cumulative Timesteps: 452,023,228

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,599.82439
Policy Entropy: 0.74612
Value Function Loss: 0.08517

Mean KL Divergence: 0.00414
SB3 Clip Fraction: 0.05000
Policy Update Magnitude: 0.18997
Value Function Update Magnitude: 0.39521

Collected Steps per Second: 23,103.29005
Overall Steps per Second: 14,542.26524

Timestep Collection Time: 2.16480
Timestep Consumption Time: 1.27442
PPO Batch Consumption Time: 0.10224
Total Iteration Time: 3.43922

Cumulative Model Updates: 54,182
Cumulative Timesteps: 452,073,242

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 452073242...
Checkpoint 452073242 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,916.88093
Policy Entropy: 0.73956
Value Function Loss: 0.09276

Mean KL Divergence: 0.00465
SB3 Clip Fraction: 0.05488
Policy Update Magnitude: 0.19524
Value Function Update Magnitude: 0.39524

Collected Steps per Second: 22,156.93884
Overall Steps per Second: 14,563.27483

Timestep Collection Time: 2.25771
Timestep Consumption Time: 1.17723
PPO Batch Consumption Time: 0.09561
Total Iteration Time: 3.43494

Cumulative Model Updates: 54,188
Cumulative Timesteps: 452,123,266

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,314.66089
Policy Entropy: 0.73788
Value Function Loss: 0.08811

Mean KL Divergence: 0.00391
SB3 Clip Fraction: 0.04644
Policy Update Magnitude: 0.19694
Value Function Update Magnitude: 0.35871

Collected Steps per Second: 22,285.64116
Overall Steps per Second: 14,296.74413

Timestep Collection Time: 2.24440
Timestep Consumption Time: 1.25415
PPO Batch Consumption Time: 0.10109
Total Iteration Time: 3.49856

Cumulative Model Updates: 54,194
Cumulative Timesteps: 452,173,284

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 452173284...
Checkpoint 452173284 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,028.77108
Policy Entropy: 0.73499
Value Function Loss: 0.08712

Mean KL Divergence: 0.00496
SB3 Clip Fraction: 0.05661
Policy Update Magnitude: 0.20334
Value Function Update Magnitude: 0.37185

Collected Steps per Second: 22,773.06299
Overall Steps per Second: 14,479.21464

Timestep Collection Time: 2.19628
Timestep Consumption Time: 1.25805
PPO Batch Consumption Time: 0.09840
Total Iteration Time: 3.45433

Cumulative Model Updates: 54,200
Cumulative Timesteps: 452,223,300

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,138.77783
Policy Entropy: 0.73763
Value Function Loss: 0.08528

Mean KL Divergence: 0.00708
SB3 Clip Fraction: 0.07594
Policy Update Magnitude: 0.18782
Value Function Update Magnitude: 0.39509

Collected Steps per Second: 22,900.21874
Overall Steps per Second: 14,767.26788

Timestep Collection Time: 2.18373
Timestep Consumption Time: 1.20267
PPO Batch Consumption Time: 0.09609
Total Iteration Time: 3.38641

Cumulative Model Updates: 54,206
Cumulative Timesteps: 452,273,308

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 452273308...
Checkpoint 452273308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,472.97614
Policy Entropy: 0.73977
Value Function Loss: 0.09031

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.08005
Policy Update Magnitude: 0.18186
Value Function Update Magnitude: 0.38325

Collected Steps per Second: 22,240.29723
Overall Steps per Second: 14,493.35805

Timestep Collection Time: 2.24853
Timestep Consumption Time: 1.20188
PPO Batch Consumption Time: 0.09797
Total Iteration Time: 3.45041

Cumulative Model Updates: 54,212
Cumulative Timesteps: 452,323,316

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,055.92225
Policy Entropy: 0.72458
Value Function Loss: 0.09151

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.08795
Policy Update Magnitude: 0.18134
Value Function Update Magnitude: 0.37697

Collected Steps per Second: 23,212.22695
Overall Steps per Second: 14,433.12391

Timestep Collection Time: 2.15490
Timestep Consumption Time: 1.31074
PPO Batch Consumption Time: 0.10308
Total Iteration Time: 3.46564

Cumulative Model Updates: 54,218
Cumulative Timesteps: 452,373,336

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 452373336...
Checkpoint 452373336 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,392.19625
Policy Entropy: 0.73897
Value Function Loss: 0.08538

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.07650
Policy Update Magnitude: 0.19564
Value Function Update Magnitude: 0.38084

Collected Steps per Second: 22,685.90400
Overall Steps per Second: 14,650.17279

Timestep Collection Time: 2.20489
Timestep Consumption Time: 1.20940
PPO Batch Consumption Time: 0.09689
Total Iteration Time: 3.41429

Cumulative Model Updates: 54,224
Cumulative Timesteps: 452,423,356

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,215.61414
Policy Entropy: 0.72908
Value Function Loss: 0.08557

Mean KL Divergence: 0.00589
SB3 Clip Fraction: 0.06264
Policy Update Magnitude: 0.20497
Value Function Update Magnitude: 0.40075

Collected Steps per Second: 22,515.64104
Overall Steps per Second: 14,672.46670

Timestep Collection Time: 2.22166
Timestep Consumption Time: 1.18759
PPO Batch Consumption Time: 0.09169
Total Iteration Time: 3.40924

Cumulative Model Updates: 54,230
Cumulative Timesteps: 452,473,378

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 452473378...
Checkpoint 452473378 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,509.13738
Policy Entropy: 0.73353
Value Function Loss: 0.08557

Mean KL Divergence: 0.00468
SB3 Clip Fraction: 0.05566
Policy Update Magnitude: 0.21846
Value Function Update Magnitude: 0.39998

Collected Steps per Second: 22,872.27700
Overall Steps per Second: 14,326.37503

Timestep Collection Time: 2.18631
Timestep Consumption Time: 1.30417
PPO Batch Consumption Time: 0.10315
Total Iteration Time: 3.49049

Cumulative Model Updates: 54,236
Cumulative Timesteps: 452,523,384

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,564.44467
Policy Entropy: 0.73051
Value Function Loss: 0.08589

Mean KL Divergence: 0.00384
SB3 Clip Fraction: 0.04649
Policy Update Magnitude: 0.20887
Value Function Update Magnitude: 0.40183

Collected Steps per Second: 23,117.56096
Overall Steps per Second: 14,748.14382

Timestep Collection Time: 2.16329
Timestep Consumption Time: 1.22764
PPO Batch Consumption Time: 0.10177
Total Iteration Time: 3.39094

Cumulative Model Updates: 54,242
Cumulative Timesteps: 452,573,394

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 452573394...
Checkpoint 452573394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,521.19104
Policy Entropy: 0.73231
Value Function Loss: 0.08670

Mean KL Divergence: 0.00471
SB3 Clip Fraction: 0.05435
Policy Update Magnitude: 0.20417
Value Function Update Magnitude: 0.40162

Collected Steps per Second: 22,188.85738
Overall Steps per Second: 14,534.97409

Timestep Collection Time: 2.25474
Timestep Consumption Time: 1.18731
PPO Batch Consumption Time: 0.09139
Total Iteration Time: 3.44204

Cumulative Model Updates: 54,248
Cumulative Timesteps: 452,623,424

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,111.80610
Policy Entropy: 0.72460
Value Function Loss: 0.08789

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.08464
Policy Update Magnitude: 0.19228
Value Function Update Magnitude: 0.38348

Collected Steps per Second: 23,254.33618
Overall Steps per Second: 14,779.04535

Timestep Collection Time: 2.15125
Timestep Consumption Time: 1.23367
PPO Batch Consumption Time: 0.09505
Total Iteration Time: 3.38493

Cumulative Model Updates: 54,254
Cumulative Timesteps: 452,673,450

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 452673450...
Checkpoint 452673450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,248.71872
Policy Entropy: 0.72428
Value Function Loss: 0.09648

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.08297
Policy Update Magnitude: 0.18399
Value Function Update Magnitude: 0.38883

Collected Steps per Second: 22,628.77615
Overall Steps per Second: 14,423.36985

Timestep Collection Time: 2.21046
Timestep Consumption Time: 1.25752
PPO Batch Consumption Time: 0.10051
Total Iteration Time: 3.46798

Cumulative Model Updates: 54,260
Cumulative Timesteps: 452,723,470

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,367.62039
Policy Entropy: 0.72217
Value Function Loss: 0.08981

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.08487
Policy Update Magnitude: 0.18738
Value Function Update Magnitude: 0.42604

Collected Steps per Second: 22,116.06049
Overall Steps per Second: 14,346.80098

Timestep Collection Time: 2.26116
Timestep Consumption Time: 1.22449
PPO Batch Consumption Time: 0.09643
Total Iteration Time: 3.48566

Cumulative Model Updates: 54,266
Cumulative Timesteps: 452,773,478

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 452773478...
Checkpoint 452773478 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,623.50904
Policy Entropy: 0.72486
Value Function Loss: 0.09038

Mean KL Divergence: 0.00676
SB3 Clip Fraction: 0.07068
Policy Update Magnitude: 0.19428
Value Function Update Magnitude: 0.40643

Collected Steps per Second: 22,766.38897
Overall Steps per Second: 14,410.31147

Timestep Collection Time: 2.19648
Timestep Consumption Time: 1.27367
PPO Batch Consumption Time: 0.10153
Total Iteration Time: 3.47015

Cumulative Model Updates: 54,272
Cumulative Timesteps: 452,823,484

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,926.35963
Policy Entropy: 0.73518
Value Function Loss: 0.09098

Mean KL Divergence: 0.00557
SB3 Clip Fraction: 0.06125
Policy Update Magnitude: 0.19456
Value Function Update Magnitude: 0.39104

Collected Steps per Second: 22,843.49016
Overall Steps per Second: 14,390.15434

Timestep Collection Time: 2.18933
Timestep Consumption Time: 1.28610
PPO Batch Consumption Time: 0.09911
Total Iteration Time: 3.47543

Cumulative Model Updates: 54,278
Cumulative Timesteps: 452,873,496

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 452873496...
Checkpoint 452873496 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,135.76399
Policy Entropy: 0.72598
Value Function Loss: 0.09562

Mean KL Divergence: 0.00399
SB3 Clip Fraction: 0.04741
Policy Update Magnitude: 0.19287
Value Function Update Magnitude: 0.37463

Collected Steps per Second: 21,893.45599
Overall Steps per Second: 14,325.40512

Timestep Collection Time: 2.28388
Timestep Consumption Time: 1.20656
PPO Batch Consumption Time: 0.10146
Total Iteration Time: 3.49044

Cumulative Model Updates: 54,284
Cumulative Timesteps: 452,923,498

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,450.85607
Policy Entropy: 0.73640
Value Function Loss: 0.08536

Mean KL Divergence: 0.00355
SB3 Clip Fraction: 0.04280
Policy Update Magnitude: 0.19455
Value Function Update Magnitude: 0.33703

Collected Steps per Second: 23,100.37621
Overall Steps per Second: 14,454.84514

Timestep Collection Time: 2.16533
Timestep Consumption Time: 1.29510
PPO Batch Consumption Time: 0.10153
Total Iteration Time: 3.46043

Cumulative Model Updates: 54,290
Cumulative Timesteps: 452,973,518

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 452973518...
Checkpoint 452973518 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,370.11591
Policy Entropy: 0.72592
Value Function Loss: 0.08786

Mean KL Divergence: 0.00355
SB3 Clip Fraction: 0.04235
Policy Update Magnitude: 0.19155
Value Function Update Magnitude: 0.34123

Collected Steps per Second: 22,345.98039
Overall Steps per Second: 14,681.29595

Timestep Collection Time: 2.23852
Timestep Consumption Time: 1.16867
PPO Batch Consumption Time: 0.09296
Total Iteration Time: 3.40719

Cumulative Model Updates: 54,296
Cumulative Timesteps: 453,023,540

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,103.97169
Policy Entropy: 0.72826
Value Function Loss: 0.09170

Mean KL Divergence: 0.00345
SB3 Clip Fraction: 0.04092
Policy Update Magnitude: 0.19457
Value Function Update Magnitude: 0.34065

Collected Steps per Second: 22,654.49927
Overall Steps per Second: 14,422.00179

Timestep Collection Time: 2.20707
Timestep Consumption Time: 1.25986
PPO Batch Consumption Time: 0.10228
Total Iteration Time: 3.46693

Cumulative Model Updates: 54,302
Cumulative Timesteps: 453,073,540

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 453073540...
Checkpoint 453073540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,657.46956
Policy Entropy: 0.72230
Value Function Loss: 0.09436

Mean KL Divergence: 0.00366
SB3 Clip Fraction: 0.04455
Policy Update Magnitude: 0.19951
Value Function Update Magnitude: 0.36853

Collected Steps per Second: 22,494.60147
Overall Steps per Second: 14,428.85707

Timestep Collection Time: 2.22329
Timestep Consumption Time: 1.24282
PPO Batch Consumption Time: 0.09950
Total Iteration Time: 3.46611

Cumulative Model Updates: 54,308
Cumulative Timesteps: 453,123,552

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,058.13641
Policy Entropy: 0.72839
Value Function Loss: 0.08744

Mean KL Divergence: 0.00354
SB3 Clip Fraction: 0.04200
Policy Update Magnitude: 0.19422
Value Function Update Magnitude: 0.38617

Collected Steps per Second: 23,178.36103
Overall Steps per Second: 14,664.57153

Timestep Collection Time: 2.15753
Timestep Consumption Time: 1.25259
PPO Batch Consumption Time: 0.10326
Total Iteration Time: 3.41012

Cumulative Model Updates: 54,314
Cumulative Timesteps: 453,173,560

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 453173560...
Checkpoint 453173560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,850.10954
Policy Entropy: 0.73415
Value Function Loss: 0.08441

Mean KL Divergence: 0.00372
SB3 Clip Fraction: 0.04523
Policy Update Magnitude: 0.18901
Value Function Update Magnitude: 0.37459

Collected Steps per Second: 22,327.39426
Overall Steps per Second: 14,204.22919

Timestep Collection Time: 2.24012
Timestep Consumption Time: 1.28109
PPO Batch Consumption Time: 0.10617
Total Iteration Time: 3.52120

Cumulative Model Updates: 54,320
Cumulative Timesteps: 453,223,576

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,388.45701
Policy Entropy: 0.72372
Value Function Loss: 0.08209

Mean KL Divergence: 0.00377
SB3 Clip Fraction: 0.04478
Policy Update Magnitude: 0.18313
Value Function Update Magnitude: 0.39357

Collected Steps per Second: 22,773.65524
Overall Steps per Second: 14,638.65304

Timestep Collection Time: 2.19587
Timestep Consumption Time: 1.22029
PPO Batch Consumption Time: 0.09941
Total Iteration Time: 3.41616

Cumulative Model Updates: 54,326
Cumulative Timesteps: 453,273,584

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 453273584...
Checkpoint 453273584 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,727.33609
Policy Entropy: 0.73022
Value Function Loss: 0.08515

Mean KL Divergence: 0.00419
SB3 Clip Fraction: 0.04946
Policy Update Magnitude: 0.17977
Value Function Update Magnitude: 0.39382

Collected Steps per Second: 22,940.93734
Overall Steps per Second: 14,821.73024

Timestep Collection Time: 2.17995
Timestep Consumption Time: 1.19415
PPO Batch Consumption Time: 0.09679
Total Iteration Time: 3.37410

Cumulative Model Updates: 54,332
Cumulative Timesteps: 453,323,594

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,361.39832
Policy Entropy: 0.73559
Value Function Loss: 0.08220

Mean KL Divergence: 0.00415
SB3 Clip Fraction: 0.04890
Policy Update Magnitude: 0.17820
Value Function Update Magnitude: 0.39374

Collected Steps per Second: 22,481.16279
Overall Steps per Second: 14,701.28548

Timestep Collection Time: 2.22444
Timestep Consumption Time: 1.17717
PPO Batch Consumption Time: 0.09554
Total Iteration Time: 3.40161

Cumulative Model Updates: 54,338
Cumulative Timesteps: 453,373,602

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 453373602...
Checkpoint 453373602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,143.46434
Policy Entropy: 0.73561
Value Function Loss: 0.08401

Mean KL Divergence: 0.00435
SB3 Clip Fraction: 0.05057
Policy Update Magnitude: 0.18069
Value Function Update Magnitude: 0.41545

Collected Steps per Second: 22,745.59602
Overall Steps per Second: 14,815.87122

Timestep Collection Time: 2.19963
Timestep Consumption Time: 1.17728
PPO Batch Consumption Time: 0.09293
Total Iteration Time: 3.37692

Cumulative Model Updates: 54,344
Cumulative Timesteps: 453,423,634

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,883.27815
Policy Entropy: 0.72592
Value Function Loss: 0.07910

Mean KL Divergence: 0.00456
SB3 Clip Fraction: 0.05498
Policy Update Magnitude: 0.17537
Value Function Update Magnitude: 0.40604

Collected Steps per Second: 23,018.28426
Overall Steps per Second: 14,794.40713

Timestep Collection Time: 2.17306
Timestep Consumption Time: 1.20795
PPO Batch Consumption Time: 0.09428
Total Iteration Time: 3.38101

Cumulative Model Updates: 54,350
Cumulative Timesteps: 453,473,654

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 453473654...
Checkpoint 453473654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,534.65527
Policy Entropy: 0.72500
Value Function Loss: 0.07469

Mean KL Divergence: 0.00351
SB3 Clip Fraction: 0.04217
Policy Update Magnitude: 0.17776
Value Function Update Magnitude: 0.39873

Collected Steps per Second: 22,254.04874
Overall Steps per Second: 14,182.96593

Timestep Collection Time: 2.24795
Timestep Consumption Time: 1.27924
PPO Batch Consumption Time: 0.10408
Total Iteration Time: 3.52719

Cumulative Model Updates: 54,356
Cumulative Timesteps: 453,523,680

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,525.67613
Policy Entropy: 0.73029
Value Function Loss: 0.07575

Mean KL Divergence: 0.00453
SB3 Clip Fraction: 0.05261
Policy Update Magnitude: 0.18195
Value Function Update Magnitude: 0.36861

Collected Steps per Second: 23,169.67340
Overall Steps per Second: 14,673.97715

Timestep Collection Time: 2.15842
Timestep Consumption Time: 1.24965
PPO Batch Consumption Time: 0.10014
Total Iteration Time: 3.40807

Cumulative Model Updates: 54,362
Cumulative Timesteps: 453,573,690

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 453573690...
Checkpoint 453573690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,868.07485
Policy Entropy: 0.73363
Value Function Loss: 0.08570

Mean KL Divergence: 0.00411
SB3 Clip Fraction: 0.04862
Policy Update Magnitude: 0.19018
Value Function Update Magnitude: 0.36991

Collected Steps per Second: 22,243.95448
Overall Steps per Second: 14,338.82089

Timestep Collection Time: 2.24960
Timestep Consumption Time: 1.24023
PPO Batch Consumption Time: 0.10147
Total Iteration Time: 3.48983

Cumulative Model Updates: 54,368
Cumulative Timesteps: 453,623,730

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,864.78671
Policy Entropy: 0.74160
Value Function Loss: 0.08760

Mean KL Divergence: 0.00517
SB3 Clip Fraction: 0.05655
Policy Update Magnitude: 0.18971
Value Function Update Magnitude: 0.41081

Collected Steps per Second: 22,329.68061
Overall Steps per Second: 14,382.65203

Timestep Collection Time: 2.24025
Timestep Consumption Time: 1.23783
PPO Batch Consumption Time: 0.09783
Total Iteration Time: 3.47808

Cumulative Model Updates: 54,374
Cumulative Timesteps: 453,673,754

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 453673754...
Checkpoint 453673754 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,668.50934
Policy Entropy: 0.74345
Value Function Loss: 0.08530

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.07700
Policy Update Magnitude: 0.17567
Value Function Update Magnitude: 0.43529

Collected Steps per Second: 22,476.20902
Overall Steps per Second: 14,471.35712

Timestep Collection Time: 2.22529
Timestep Consumption Time: 1.23092
PPO Batch Consumption Time: 0.10167
Total Iteration Time: 3.45621

Cumulative Model Updates: 54,380
Cumulative Timesteps: 453,723,770

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,758.05779
Policy Entropy: 0.73774
Value Function Loss: 0.07729

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.09044
Policy Update Magnitude: 0.16317
Value Function Update Magnitude: 0.42390

Collected Steps per Second: 22,508.19398
Overall Steps per Second: 14,435.39483

Timestep Collection Time: 2.22230
Timestep Consumption Time: 1.24279
PPO Batch Consumption Time: 0.10281
Total Iteration Time: 3.46509

Cumulative Model Updates: 54,386
Cumulative Timesteps: 453,773,790

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 453773790...
Checkpoint 453773790 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,063.78164
Policy Entropy: 0.72331
Value Function Loss: 0.07792

Mean KL Divergence: 0.00697
SB3 Clip Fraction: 0.07029
Policy Update Magnitude: 0.18127
Value Function Update Magnitude: 0.40256

Collected Steps per Second: 22,284.41345
Overall Steps per Second: 14,298.41846

Timestep Collection Time: 2.24462
Timestep Consumption Time: 1.25367
PPO Batch Consumption Time: 0.10164
Total Iteration Time: 3.49829

Cumulative Model Updates: 54,392
Cumulative Timesteps: 453,823,810

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,771.70191
Policy Entropy: 0.71821
Value Function Loss: 0.08039

Mean KL Divergence: 0.00544
SB3 Clip Fraction: 0.05982
Policy Update Magnitude: 0.20028
Value Function Update Magnitude: 0.40002

Collected Steps per Second: 22,982.89715
Overall Steps per Second: 15,103.54134

Timestep Collection Time: 2.17605
Timestep Consumption Time: 1.13522
PPO Batch Consumption Time: 0.09009
Total Iteration Time: 3.31128

Cumulative Model Updates: 54,398
Cumulative Timesteps: 453,873,822

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 453873822...
Checkpoint 453873822 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,815.24386
Policy Entropy: 0.72351
Value Function Loss: 0.07730

Mean KL Divergence: 0.00375
SB3 Clip Fraction: 0.04409
Policy Update Magnitude: 0.19990
Value Function Update Magnitude: 0.41338

Collected Steps per Second: 21,958.76390
Overall Steps per Second: 14,171.51134

Timestep Collection Time: 2.27700
Timestep Consumption Time: 1.25121
PPO Batch Consumption Time: 0.10175
Total Iteration Time: 3.52821

Cumulative Model Updates: 54,404
Cumulative Timesteps: 453,923,822

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,868.56343
Policy Entropy: 0.72228
Value Function Loss: 0.07924

Mean KL Divergence: 0.00381
SB3 Clip Fraction: 0.04521
Policy Update Magnitude: 0.19866
Value Function Update Magnitude: 0.41764

Collected Steps per Second: 22,706.76185
Overall Steps per Second: 14,600.69405

Timestep Collection Time: 2.20304
Timestep Consumption Time: 1.22309
PPO Batch Consumption Time: 0.09266
Total Iteration Time: 3.42614

Cumulative Model Updates: 54,410
Cumulative Timesteps: 453,973,846

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 453973846...
Checkpoint 453973846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,208.85886
Policy Entropy: 0.71884
Value Function Loss: 0.08039

Mean KL Divergence: 0.00387
SB3 Clip Fraction: 0.04667
Policy Update Magnitude: 0.19349
Value Function Update Magnitude: 0.40052

Collected Steps per Second: 22,520.06996
Overall Steps per Second: 14,490.85870

Timestep Collection Time: 2.22051
Timestep Consumption Time: 1.23036
PPO Batch Consumption Time: 0.10048
Total Iteration Time: 3.45087

Cumulative Model Updates: 54,416
Cumulative Timesteps: 454,023,852

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,323.26144
Policy Entropy: 0.70822
Value Function Loss: 0.08398

Mean KL Divergence: 0.00403
SB3 Clip Fraction: 0.04724
Policy Update Magnitude: 0.19139
Value Function Update Magnitude: 0.40206

Collected Steps per Second: 22,396.14473
Overall Steps per Second: 14,230.33871

Timestep Collection Time: 2.23271
Timestep Consumption Time: 1.28120
PPO Batch Consumption Time: 0.10493
Total Iteration Time: 3.51390

Cumulative Model Updates: 54,422
Cumulative Timesteps: 454,073,856

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 454073856...
Checkpoint 454073856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,327.77380
Policy Entropy: 0.71312
Value Function Loss: 0.08355

Mean KL Divergence: 0.00399
SB3 Clip Fraction: 0.04644
Policy Update Magnitude: 0.18830
Value Function Update Magnitude: 0.38975

Collected Steps per Second: 22,721.45183
Overall Steps per Second: 14,211.01618

Timestep Collection Time: 2.20171
Timestep Consumption Time: 1.31852
PPO Batch Consumption Time: 0.10724
Total Iteration Time: 3.52023

Cumulative Model Updates: 54,428
Cumulative Timesteps: 454,123,882

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,157.58303
Policy Entropy: 0.71143
Value Function Loss: 0.08194

Mean KL Divergence: 0.00365
SB3 Clip Fraction: 0.04388
Policy Update Magnitude: 0.18849
Value Function Update Magnitude: 0.35226

Collected Steps per Second: 22,675.03271
Overall Steps per Second: 14,597.43612

Timestep Collection Time: 2.20560
Timestep Consumption Time: 1.22048
PPO Batch Consumption Time: 0.09689
Total Iteration Time: 3.42608

Cumulative Model Updates: 54,434
Cumulative Timesteps: 454,173,894

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 454173894...
Checkpoint 454173894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,950.72903
Policy Entropy: 0.72018
Value Function Loss: 0.08646

Mean KL Divergence: 0.00385
SB3 Clip Fraction: 0.04511
Policy Update Magnitude: 0.18374
Value Function Update Magnitude: 0.35903

Collected Steps per Second: 21,972.66751
Overall Steps per Second: 14,174.53600

Timestep Collection Time: 2.27683
Timestep Consumption Time: 1.25260
PPO Batch Consumption Time: 0.10334
Total Iteration Time: 3.52943

Cumulative Model Updates: 54,440
Cumulative Timesteps: 454,223,922

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,347.60806
Policy Entropy: 0.72721
Value Function Loss: 0.08534

Mean KL Divergence: 0.00389
SB3 Clip Fraction: 0.04579
Policy Update Magnitude: 0.18987
Value Function Update Magnitude: 0.38255

Collected Steps per Second: 23,069.81481
Overall Steps per Second: 14,669.13000

Timestep Collection Time: 2.16811
Timestep Consumption Time: 1.24163
PPO Batch Consumption Time: 0.09854
Total Iteration Time: 3.40975

Cumulative Model Updates: 54,446
Cumulative Timesteps: 454,273,940

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 454273940...
Checkpoint 454273940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,506.99847
Policy Entropy: 0.73643
Value Function Loss: 0.08795

Mean KL Divergence: 0.00482
SB3 Clip Fraction: 0.05306
Policy Update Magnitude: 0.20373
Value Function Update Magnitude: 0.41832

Collected Steps per Second: 22,809.01865
Overall Steps per Second: 14,759.59970

Timestep Collection Time: 2.19299
Timestep Consumption Time: 1.19599
PPO Batch Consumption Time: 0.09382
Total Iteration Time: 3.38898

Cumulative Model Updates: 54,452
Cumulative Timesteps: 454,323,960

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,437.37500
Policy Entropy: 0.72774
Value Function Loss: 0.08920

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.07925
Policy Update Magnitude: 0.18788
Value Function Update Magnitude: 0.42899

Collected Steps per Second: 22,558.46781
Overall Steps per Second: 14,692.03941

Timestep Collection Time: 2.21708
Timestep Consumption Time: 1.18707
PPO Batch Consumption Time: 0.09292
Total Iteration Time: 3.40416

Cumulative Model Updates: 54,458
Cumulative Timesteps: 454,373,974

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 454373974...
Checkpoint 454373974 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,670.95021
Policy Entropy: 0.72981
Value Function Loss: 0.09593

Mean KL Divergence: 0.00683
SB3 Clip Fraction: 0.06330
Policy Update Magnitude: 0.20148
Value Function Update Magnitude: 0.44246

Collected Steps per Second: 22,349.87822
Overall Steps per Second: 14,143.86164

Timestep Collection Time: 2.23813
Timestep Consumption Time: 1.29852
PPO Batch Consumption Time: 0.10257
Total Iteration Time: 3.53666

Cumulative Model Updates: 54,464
Cumulative Timesteps: 454,423,996

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,384.34046
Policy Entropy: 0.72898
Value Function Loss: 0.09739

Mean KL Divergence: 0.00546
SB3 Clip Fraction: 0.05546
Policy Update Magnitude: 0.20477
Value Function Update Magnitude: 0.41638

Collected Steps per Second: 23,102.53932
Overall Steps per Second: 14,803.51605

Timestep Collection Time: 2.16530
Timestep Consumption Time: 1.21389
PPO Batch Consumption Time: 0.10233
Total Iteration Time: 3.37920

Cumulative Model Updates: 54,470
Cumulative Timesteps: 454,474,020

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 454474020...
Checkpoint 454474020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,647.66147
Policy Entropy: 0.74214
Value Function Loss: 0.10155

Mean KL Divergence: 0.00450
SB3 Clip Fraction: 0.05252
Policy Update Magnitude: 0.20250
Value Function Update Magnitude: 0.40503

Collected Steps per Second: 22,420.40880
Overall Steps per Second: 14,638.78235

Timestep Collection Time: 2.23038
Timestep Consumption Time: 1.18562
PPO Batch Consumption Time: 0.09293
Total Iteration Time: 3.41599

Cumulative Model Updates: 54,476
Cumulative Timesteps: 454,524,026

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,826.64109
Policy Entropy: 0.73369
Value Function Loss: 0.09807

Mean KL Divergence: 0.00404
SB3 Clip Fraction: 0.04952
Policy Update Magnitude: 0.19815
Value Function Update Magnitude: 0.41391

Collected Steps per Second: 23,048.06968
Overall Steps per Second: 14,701.66340

Timestep Collection Time: 2.17137
Timestep Consumption Time: 1.23273
PPO Batch Consumption Time: 0.09570
Total Iteration Time: 3.40410

Cumulative Model Updates: 54,482
Cumulative Timesteps: 454,574,072

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 454574072...
Checkpoint 454574072 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,999.81024
Policy Entropy: 0.73552
Value Function Loss: 0.09397

Mean KL Divergence: 0.00460
SB3 Clip Fraction: 0.05423
Policy Update Magnitude: 0.19901
Value Function Update Magnitude: 0.44403

Collected Steps per Second: 22,796.55316
Overall Steps per Second: 14,544.26444

Timestep Collection Time: 2.19349
Timestep Consumption Time: 1.24457
PPO Batch Consumption Time: 0.10139
Total Iteration Time: 3.43806

Cumulative Model Updates: 54,488
Cumulative Timesteps: 454,624,076

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,012.36300
Policy Entropy: 0.73466
Value Function Loss: 0.08953

Mean KL Divergence: 0.00487
SB3 Clip Fraction: 0.05553
Policy Update Magnitude: 0.19158
Value Function Update Magnitude: 0.42708

Collected Steps per Second: 22,559.16796
Overall Steps per Second: 14,468.70161

Timestep Collection Time: 2.21639
Timestep Consumption Time: 1.23934
PPO Batch Consumption Time: 0.10215
Total Iteration Time: 3.45574

Cumulative Model Updates: 54,494
Cumulative Timesteps: 454,674,076

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 454674076...
Checkpoint 454674076 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,406.73176
Policy Entropy: 0.74019
Value Function Loss: 0.08544

Mean KL Divergence: 0.00483
SB3 Clip Fraction: 0.05412
Policy Update Magnitude: 0.19033
Value Function Update Magnitude: 0.38450

Collected Steps per Second: 22,945.45924
Overall Steps per Second: 14,652.08589

Timestep Collection Time: 2.18021
Timestep Consumption Time: 1.23404
PPO Batch Consumption Time: 0.09588
Total Iteration Time: 3.41426

Cumulative Model Updates: 54,500
Cumulative Timesteps: 454,724,102

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,575.26811
Policy Entropy: 0.73378
Value Function Loss: 0.08261

Mean KL Divergence: 0.00446
SB3 Clip Fraction: 0.05203
Policy Update Magnitude: 0.18226
Value Function Update Magnitude: 0.36833

Collected Steps per Second: 23,004.69052
Overall Steps per Second: 14,763.49908

Timestep Collection Time: 2.17460
Timestep Consumption Time: 1.21389
PPO Batch Consumption Time: 0.09564
Total Iteration Time: 3.38849

Cumulative Model Updates: 54,506
Cumulative Timesteps: 454,774,128

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 454774128...
Checkpoint 454774128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,774.40161
Policy Entropy: 0.73729
Value Function Loss: 0.08137

Mean KL Divergence: 0.00333
SB3 Clip Fraction: 0.03890
Policy Update Magnitude: 0.18350
Value Function Update Magnitude: 0.38176

Collected Steps per Second: 22,026.61797
Overall Steps per Second: 14,247.63857

Timestep Collection Time: 2.27062
Timestep Consumption Time: 1.23972
PPO Batch Consumption Time: 0.10249
Total Iteration Time: 3.51034

Cumulative Model Updates: 54,512
Cumulative Timesteps: 454,824,142

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,821.44057
Policy Entropy: 0.73453
Value Function Loss: 0.07665

Mean KL Divergence: 0.00408
SB3 Clip Fraction: 0.04941
Policy Update Magnitude: 0.18354
Value Function Update Magnitude: 0.38423

Collected Steps per Second: 23,275.84839
Overall Steps per Second: 14,690.80179

Timestep Collection Time: 2.14944
Timestep Consumption Time: 1.25609
PPO Batch Consumption Time: 0.10332
Total Iteration Time: 3.40553

Cumulative Model Updates: 54,518
Cumulative Timesteps: 454,874,172

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 454874172...
Checkpoint 454874172 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,850.32614
Policy Entropy: 0.74702
Value Function Loss: 0.08008

Mean KL Divergence: 0.00430
SB3 Clip Fraction: 0.05044
Policy Update Magnitude: 0.18160
Value Function Update Magnitude: 0.39427

Collected Steps per Second: 22,715.18309
Overall Steps per Second: 14,781.00682

Timestep Collection Time: 2.20117
Timestep Consumption Time: 1.18155
PPO Batch Consumption Time: 0.09898
Total Iteration Time: 3.38272

Cumulative Model Updates: 54,524
Cumulative Timesteps: 454,924,172

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,033.95941
Policy Entropy: 0.75082
Value Function Loss: 0.07958

Mean KL Divergence: 0.00358
SB3 Clip Fraction: 0.04343
Policy Update Magnitude: 0.18046
Value Function Update Magnitude: 0.41263

Collected Steps per Second: 22,791.77363
Overall Steps per Second: 14,671.43231

Timestep Collection Time: 2.19535
Timestep Consumption Time: 1.21508
PPO Batch Consumption Time: 0.09746
Total Iteration Time: 3.41044

Cumulative Model Updates: 54,530
Cumulative Timesteps: 454,974,208

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 454974208...
Checkpoint 454974208 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,705.54470
Policy Entropy: 0.76151
Value Function Loss: 0.08193

Mean KL Divergence: 0.00444
SB3 Clip Fraction: 0.05335
Policy Update Magnitude: 0.17756
Value Function Update Magnitude: 0.41193

Collected Steps per Second: 22,370.77041
Overall Steps per Second: 14,380.23449

Timestep Collection Time: 2.23622
Timestep Consumption Time: 1.24258
PPO Batch Consumption Time: 0.10144
Total Iteration Time: 3.47880

Cumulative Model Updates: 54,536
Cumulative Timesteps: 455,024,234

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,662.08109
Policy Entropy: 0.75454
Value Function Loss: 0.08805

Mean KL Divergence: 0.00417
SB3 Clip Fraction: 0.04875
Policy Update Magnitude: 0.17103
Value Function Update Magnitude: 0.38304

Collected Steps per Second: 22,853.73840
Overall Steps per Second: 14,582.88450

Timestep Collection Time: 2.18940
Timestep Consumption Time: 1.24174
PPO Batch Consumption Time: 0.10155
Total Iteration Time: 3.43115

Cumulative Model Updates: 54,542
Cumulative Timesteps: 455,074,270

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 455074270...
Checkpoint 455074270 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,478.97701
Policy Entropy: 0.75082
Value Function Loss: 0.08856

Mean KL Divergence: 0.00434
SB3 Clip Fraction: 0.05126
Policy Update Magnitude: 0.17924
Value Function Update Magnitude: 0.36874

Collected Steps per Second: 22,392.60003
Overall Steps per Second: 14,640.92721

Timestep Collection Time: 2.23404
Timestep Consumption Time: 1.18282
PPO Batch Consumption Time: 0.09653
Total Iteration Time: 3.41686

Cumulative Model Updates: 54,548
Cumulative Timesteps: 455,124,296

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,906.18788
Policy Entropy: 0.74402
Value Function Loss: 0.08613

Mean KL Divergence: 0.00473
SB3 Clip Fraction: 0.05712
Policy Update Magnitude: 0.17918
Value Function Update Magnitude: 0.36191

Collected Steps per Second: 23,050.77383
Overall Steps per Second: 14,769.50055

Timestep Collection Time: 2.16956
Timestep Consumption Time: 1.21647
PPO Batch Consumption Time: 0.09773
Total Iteration Time: 3.38603

Cumulative Model Updates: 54,554
Cumulative Timesteps: 455,174,306

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 455174306...
Checkpoint 455174306 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,578.95366
Policy Entropy: 0.74302
Value Function Loss: 0.08650

Mean KL Divergence: 0.00403
SB3 Clip Fraction: 0.04934
Policy Update Magnitude: 0.18438
Value Function Update Magnitude: 0.37197

Collected Steps per Second: 22,546.97019
Overall Steps per Second: 14,461.86366

Timestep Collection Time: 2.21866
Timestep Consumption Time: 1.24037
PPO Batch Consumption Time: 0.10112
Total Iteration Time: 3.45903

Cumulative Model Updates: 54,560
Cumulative Timesteps: 455,224,330

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,074.92997
Policy Entropy: 0.75159
Value Function Loss: 0.08594

Mean KL Divergence: 0.00397
SB3 Clip Fraction: 0.04841
Policy Update Magnitude: 0.18294
Value Function Update Magnitude: 0.39829

Collected Steps per Second: 22,631.95800
Overall Steps per Second: 14,602.87007

Timestep Collection Time: 2.21024
Timestep Consumption Time: 1.21525
PPO Batch Consumption Time: 0.09996
Total Iteration Time: 3.42549

Cumulative Model Updates: 54,566
Cumulative Timesteps: 455,274,352

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 455274352...
Checkpoint 455274352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,945.98373
Policy Entropy: 0.75559
Value Function Loss: 0.08837

Mean KL Divergence: 0.00490
SB3 Clip Fraction: 0.05649
Policy Update Magnitude: 0.18750
Value Function Update Magnitude: 0.41255

Collected Steps per Second: 22,674.43533
Overall Steps per Second: 14,593.24437

Timestep Collection Time: 2.20724
Timestep Consumption Time: 1.22229
PPO Batch Consumption Time: 0.09894
Total Iteration Time: 3.42953

Cumulative Model Updates: 54,572
Cumulative Timesteps: 455,324,400

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,173.53314
Policy Entropy: 0.76034
Value Function Loss: 0.08484

Mean KL Divergence: 0.00521
SB3 Clip Fraction: 0.06023
Policy Update Magnitude: 0.18215
Value Function Update Magnitude: 0.43205

Collected Steps per Second: 22,493.46635
Overall Steps per Second: 14,652.08503

Timestep Collection Time: 2.22402
Timestep Consumption Time: 1.19023
PPO Batch Consumption Time: 0.09316
Total Iteration Time: 3.41426

Cumulative Model Updates: 54,578
Cumulative Timesteps: 455,374,426

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 455374426...
Checkpoint 455374426 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,547.92331
Policy Entropy: 0.75140
Value Function Loss: 0.09041

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.07665
Policy Update Magnitude: 0.18257
Value Function Update Magnitude: 0.43136

Collected Steps per Second: 21,762.13777
Overall Steps per Second: 14,139.99934

Timestep Collection Time: 2.29766
Timestep Consumption Time: 1.23855
PPO Batch Consumption Time: 0.10005
Total Iteration Time: 3.53621

Cumulative Model Updates: 54,584
Cumulative Timesteps: 455,424,428

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,513.83175
Policy Entropy: 0.75699
Value Function Loss: 0.08844

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.08634
Policy Update Magnitude: 0.18260
Value Function Update Magnitude: 0.42673

Collected Steps per Second: 23,008.02484
Overall Steps per Second: 14,760.18376

Timestep Collection Time: 2.17376
Timestep Consumption Time: 1.21468
PPO Batch Consumption Time: 0.10056
Total Iteration Time: 3.38844

Cumulative Model Updates: 54,590
Cumulative Timesteps: 455,474,442

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 455474442...
Checkpoint 455474442 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,650.08390
Policy Entropy: 0.75298
Value Function Loss: 0.09466

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.07803
Policy Update Magnitude: 0.18371
Value Function Update Magnitude: 0.41603

Collected Steps per Second: 20,861.54406
Overall Steps per Second: 13,892.02991

Timestep Collection Time: 2.39714
Timestep Consumption Time: 1.20262
PPO Batch Consumption Time: 0.09370
Total Iteration Time: 3.59976

Cumulative Model Updates: 54,596
Cumulative Timesteps: 455,524,450

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,858.16253
Policy Entropy: 0.73632
Value Function Loss: 0.08439

Mean KL Divergence: 0.00690
SB3 Clip Fraction: 0.07012
Policy Update Magnitude: 0.19071
Value Function Update Magnitude: 0.39195

Collected Steps per Second: 23,076.43376
Overall Steps per Second: 14,859.97490

Timestep Collection Time: 2.16784
Timestep Consumption Time: 1.19865
PPO Batch Consumption Time: 0.09845
Total Iteration Time: 3.36649

Cumulative Model Updates: 54,602
Cumulative Timesteps: 455,574,476

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 455574476...
Checkpoint 455574476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,864.21245
Policy Entropy: 0.72547
Value Function Loss: 0.08539

Mean KL Divergence: 0.00467
SB3 Clip Fraction: 0.05523
Policy Update Magnitude: 0.18995
Value Function Update Magnitude: 0.39333

Collected Steps per Second: 22,870.60682
Overall Steps per Second: 14,789.55428

Timestep Collection Time: 2.18709
Timestep Consumption Time: 1.19503
PPO Batch Consumption Time: 0.09449
Total Iteration Time: 3.38212

Cumulative Model Updates: 54,608
Cumulative Timesteps: 455,624,496

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,304.42737
Policy Entropy: 0.72471
Value Function Loss: 0.08504

Mean KL Divergence: 0.00343
SB3 Clip Fraction: 0.04118
Policy Update Magnitude: 0.18690
Value Function Update Magnitude: 0.38360

Collected Steps per Second: 22,604.94606
Overall Steps per Second: 14,733.19423

Timestep Collection Time: 2.21191
Timestep Consumption Time: 1.18179
PPO Batch Consumption Time: 0.09351
Total Iteration Time: 3.39370

Cumulative Model Updates: 54,614
Cumulative Timesteps: 455,674,496

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 455674496...
Checkpoint 455674496 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,678.91475
Policy Entropy: 0.73429
Value Function Loss: 0.08669

Mean KL Divergence: 0.00386
SB3 Clip Fraction: 0.04702
Policy Update Magnitude: 0.19334
Value Function Update Magnitude: 0.40985

Collected Steps per Second: 22,887.76537
Overall Steps per Second: 14,809.25028

Timestep Collection Time: 2.18484
Timestep Consumption Time: 1.19184
PPO Batch Consumption Time: 0.09238
Total Iteration Time: 3.37667

Cumulative Model Updates: 54,620
Cumulative Timesteps: 455,724,502

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,235.76604
Policy Entropy: 0.74386
Value Function Loss: 0.08504

Mean KL Divergence: 0.00396
SB3 Clip Fraction: 0.04670
Policy Update Magnitude: 0.19782
Value Function Update Magnitude: 0.41393

Collected Steps per Second: 22,655.26254
Overall Steps per Second: 14,767.10003

Timestep Collection Time: 2.20761
Timestep Consumption Time: 1.17924
PPO Batch Consumption Time: 0.09263
Total Iteration Time: 3.38685

Cumulative Model Updates: 54,626
Cumulative Timesteps: 455,774,516

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 455774516...
Checkpoint 455774516 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,805.77018
Policy Entropy: 0.74910
Value Function Loss: 0.08251

Mean KL Divergence: 0.00487
SB3 Clip Fraction: 0.05447
Policy Update Magnitude: 0.19139
Value Function Update Magnitude: 0.37805

Collected Steps per Second: 22,288.41447
Overall Steps per Second: 14,422.02972

Timestep Collection Time: 2.24404
Timestep Consumption Time: 1.22399
PPO Batch Consumption Time: 0.10156
Total Iteration Time: 3.46803

Cumulative Model Updates: 54,632
Cumulative Timesteps: 455,824,532

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,742.86781
Policy Entropy: 0.76790
Value Function Loss: 0.07389

Mean KL Divergence: 0.00474
SB3 Clip Fraction: 0.05266
Policy Update Magnitude: 0.18683
Value Function Update Magnitude: 0.34537

Collected Steps per Second: 23,170.94251
Overall Steps per Second: 14,671.65263

Timestep Collection Time: 2.15900
Timestep Consumption Time: 1.25071
PPO Batch Consumption Time: 0.10076
Total Iteration Time: 3.40970

Cumulative Model Updates: 54,638
Cumulative Timesteps: 455,874,558

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 455874558...
Checkpoint 455874558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,812.97508
Policy Entropy: 0.76996
Value Function Loss: 0.06986

Mean KL Divergence: 0.00563
SB3 Clip Fraction: 0.06108
Policy Update Magnitude: 0.18122
Value Function Update Magnitude: 0.34078

Collected Steps per Second: 21,962.31700
Overall Steps per Second: 14,534.41881

Timestep Collection Time: 2.27799
Timestep Consumption Time: 1.16418
PPO Batch Consumption Time: 0.09261
Total Iteration Time: 3.44217

Cumulative Model Updates: 54,644
Cumulative Timesteps: 455,924,588

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,844.30188
Policy Entropy: 0.76600
Value Function Loss: 0.07535

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.07725
Policy Update Magnitude: 0.17544
Value Function Update Magnitude: 0.35532

Collected Steps per Second: 22,189.48225
Overall Steps per Second: 14,315.55812

Timestep Collection Time: 2.25548
Timestep Consumption Time: 1.24057
PPO Batch Consumption Time: 0.09918
Total Iteration Time: 3.49606

Cumulative Model Updates: 54,650
Cumulative Timesteps: 455,974,636

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 455974636...
Checkpoint 455974636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,497.88641
Policy Entropy: 0.75185
Value Function Loss: 0.07945

Mean KL Divergence: 0.00493
SB3 Clip Fraction: 0.05698
Policy Update Magnitude: 0.18031
Value Function Update Magnitude: 0.37164

Collected Steps per Second: 22,529.30979
Overall Steps per Second: 14,544.84256

Timestep Collection Time: 2.22031
Timestep Consumption Time: 1.21885
PPO Batch Consumption Time: 0.10016
Total Iteration Time: 3.43916

Cumulative Model Updates: 54,656
Cumulative Timesteps: 456,024,658

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,675.03601
Policy Entropy: 0.75376
Value Function Loss: 0.08193

Mean KL Divergence: 0.00427
SB3 Clip Fraction: 0.05049
Policy Update Magnitude: 0.19011
Value Function Update Magnitude: 0.38827

Collected Steps per Second: 22,036.42509
Overall Steps per Second: 14,614.54766

Timestep Collection Time: 2.26979
Timestep Consumption Time: 1.15269
PPO Batch Consumption Time: 0.09175
Total Iteration Time: 3.42248

Cumulative Model Updates: 54,662
Cumulative Timesteps: 456,074,676

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 456074676...
Checkpoint 456074676 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,520.99107
Policy Entropy: 0.75503
Value Function Loss: 0.07566

Mean KL Divergence: 0.00319
SB3 Clip Fraction: 0.03800
Policy Update Magnitude: 0.19125
Value Function Update Magnitude: 0.39731

Collected Steps per Second: 22,702.35170
Overall Steps per Second: 14,474.95811

Timestep Collection Time: 2.20250
Timestep Consumption Time: 1.25188
PPO Batch Consumption Time: 0.10106
Total Iteration Time: 3.45438

Cumulative Model Updates: 54,668
Cumulative Timesteps: 456,124,678

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,580.37738
Policy Entropy: 0.76399
Value Function Loss: 0.07344

Mean KL Divergence: 0.00331
SB3 Clip Fraction: 0.04025
Policy Update Magnitude: 0.19145
Value Function Update Magnitude: 0.40265

Collected Steps per Second: 23,129.26950
Overall Steps per Second: 14,775.69081

Timestep Collection Time: 2.16306
Timestep Consumption Time: 1.22291
PPO Batch Consumption Time: 0.09964
Total Iteration Time: 3.38597

Cumulative Model Updates: 54,674
Cumulative Timesteps: 456,174,708

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 456174708...
Checkpoint 456174708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,294.26896
Policy Entropy: 0.76243
Value Function Loss: 0.07889

Mean KL Divergence: 0.00328
SB3 Clip Fraction: 0.03968
Policy Update Magnitude: 0.19602
Value Function Update Magnitude: 0.38982

Collected Steps per Second: 22,371.62669
Overall Steps per Second: 14,519.93273

Timestep Collection Time: 2.23685
Timestep Consumption Time: 1.20958
PPO Batch Consumption Time: 0.10011
Total Iteration Time: 3.44643

Cumulative Model Updates: 54,680
Cumulative Timesteps: 456,224,750

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,877.96437
Policy Entropy: 0.75616
Value Function Loss: 0.08997

Mean KL Divergence: 0.00383
SB3 Clip Fraction: 0.04610
Policy Update Magnitude: 0.19854
Value Function Update Magnitude: 0.37446

Collected Steps per Second: 23,138.66333
Overall Steps per Second: 14,704.67537

Timestep Collection Time: 2.16184
Timestep Consumption Time: 1.23994
PPO Batch Consumption Time: 0.09975
Total Iteration Time: 3.40178

Cumulative Model Updates: 54,686
Cumulative Timesteps: 456,274,772

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 456274772...
Checkpoint 456274772 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,252.46127
Policy Entropy: 0.76051
Value Function Loss: 0.09243

Mean KL Divergence: 0.00426
SB3 Clip Fraction: 0.04990
Policy Update Magnitude: 0.20157
Value Function Update Magnitude: 0.37018

Collected Steps per Second: 22,990.17002
Overall Steps per Second: 14,784.73280

Timestep Collection Time: 2.17554
Timestep Consumption Time: 1.20741
PPO Batch Consumption Time: 0.09762
Total Iteration Time: 3.38295

Cumulative Model Updates: 54,692
Cumulative Timesteps: 456,324,788

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,092.22216
Policy Entropy: 0.76790
Value Function Loss: 0.08542

Mean KL Divergence: 0.00409
SB3 Clip Fraction: 0.04832
Policy Update Magnitude: 0.19876
Value Function Update Magnitude: 0.38912

Collected Steps per Second: 22,719.43922
Overall Steps per Second: 14,701.65211

Timestep Collection Time: 2.20208
Timestep Consumption Time: 1.20094
PPO Batch Consumption Time: 0.09506
Total Iteration Time: 3.40302

Cumulative Model Updates: 54,698
Cumulative Timesteps: 456,374,818

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 456374818...
Checkpoint 456374818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,580.41662
Policy Entropy: 0.76701
Value Function Loss: 0.08441

Mean KL Divergence: 0.00402
SB3 Clip Fraction: 0.04742
Policy Update Magnitude: 0.19528
Value Function Update Magnitude: 0.38095

Collected Steps per Second: 22,790.16307
Overall Steps per Second: 14,486.65116

Timestep Collection Time: 2.19498
Timestep Consumption Time: 1.25813
PPO Batch Consumption Time: 0.10129
Total Iteration Time: 3.45311

Cumulative Model Updates: 54,704
Cumulative Timesteps: 456,424,842

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,350.19951
Policy Entropy: 0.77089
Value Function Loss: 0.08433

Mean KL Divergence: 0.00512
SB3 Clip Fraction: 0.05976
Policy Update Magnitude: 0.19549
Value Function Update Magnitude: 0.39574

Collected Steps per Second: 23,092.82929
Overall Steps per Second: 14,644.88211

Timestep Collection Time: 2.16543
Timestep Consumption Time: 1.24914
PPO Batch Consumption Time: 0.10011
Total Iteration Time: 3.41457

Cumulative Model Updates: 54,710
Cumulative Timesteps: 456,474,848

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 456474848...
Checkpoint 456474848 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,683.09020
Policy Entropy: 0.76699
Value Function Loss: 0.08811

Mean KL Divergence: 0.00499
SB3 Clip Fraction: 0.05810
Policy Update Magnitude: 0.19925
Value Function Update Magnitude: 0.41202

Collected Steps per Second: 22,252.28636
Overall Steps per Second: 14,524.24521

Timestep Collection Time: 2.24912
Timestep Consumption Time: 1.19671
PPO Batch Consumption Time: 0.09640
Total Iteration Time: 3.44582

Cumulative Model Updates: 54,716
Cumulative Timesteps: 456,524,896

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,602.89110
Policy Entropy: 0.78062
Value Function Loss: 0.09790

Mean KL Divergence: 0.00437
SB3 Clip Fraction: 0.05171
Policy Update Magnitude: 0.20909
Value Function Update Magnitude: 0.40039

Collected Steps per Second: 23,189.43459
Overall Steps per Second: 14,829.18964

Timestep Collection Time: 2.15702
Timestep Consumption Time: 1.21606
PPO Batch Consumption Time: 0.10087
Total Iteration Time: 3.37308

Cumulative Model Updates: 54,722
Cumulative Timesteps: 456,574,916

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 456574916...
Checkpoint 456574916 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,021.20498
Policy Entropy: 0.78291
Value Function Loss: 0.09129

Mean KL Divergence: 0.00465
SB3 Clip Fraction: 0.05439
Policy Update Magnitude: 0.20732
Value Function Update Magnitude: 0.39073

Collected Steps per Second: 23,008.63855
Overall Steps per Second: 14,829.32706

Timestep Collection Time: 2.17327
Timestep Consumption Time: 1.19870
PPO Batch Consumption Time: 0.09957
Total Iteration Time: 3.37197

Cumulative Model Updates: 54,728
Cumulative Timesteps: 456,624,920

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,354.50001
Policy Entropy: 0.78672
Value Function Loss: 0.09810

Mean KL Divergence: 0.00537
SB3 Clip Fraction: 0.06224
Policy Update Magnitude: 0.20101
Value Function Update Magnitude: 0.37248

Collected Steps per Second: 22,793.88831
Overall Steps per Second: 14,696.28520

Timestep Collection Time: 2.19366
Timestep Consumption Time: 1.20870
PPO Batch Consumption Time: 0.09639
Total Iteration Time: 3.40236

Cumulative Model Updates: 54,734
Cumulative Timesteps: 456,674,922

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 456674922...
Checkpoint 456674922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,857.85749
Policy Entropy: 0.77636
Value Function Loss: 0.08883

Mean KL Divergence: 0.00434
SB3 Clip Fraction: 0.05248
Policy Update Magnitude: 0.20280
Value Function Update Magnitude: 0.35992

Collected Steps per Second: 22,742.07484
Overall Steps per Second: 14,770.23951

Timestep Collection Time: 2.20024
Timestep Consumption Time: 1.18752
PPO Batch Consumption Time: 0.09273
Total Iteration Time: 3.38776

Cumulative Model Updates: 54,740
Cumulative Timesteps: 456,724,960

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,533.52032
Policy Entropy: 0.78856
Value Function Loss: 0.08778

Mean KL Divergence: 0.00459
SB3 Clip Fraction: 0.05560
Policy Update Magnitude: 0.19682
Value Function Update Magnitude: 0.38750

Collected Steps per Second: 23,149.04282
Overall Steps per Second: 14,807.77152

Timestep Collection Time: 2.16043
Timestep Consumption Time: 1.21698
PPO Batch Consumption Time: 0.09659
Total Iteration Time: 3.37742

Cumulative Model Updates: 54,746
Cumulative Timesteps: 456,774,972

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 456774972...
Checkpoint 456774972 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,047.48066
Policy Entropy: 0.78285
Value Function Loss: 0.08281

Mean KL Divergence: 0.00457
SB3 Clip Fraction: 0.05498
Policy Update Magnitude: 0.18683
Value Function Update Magnitude: 0.37828

Collected Steps per Second: 22,362.03138
Overall Steps per Second: 14,429.04091

Timestep Collection Time: 2.23611
Timestep Consumption Time: 1.22940
PPO Batch Consumption Time: 0.10270
Total Iteration Time: 3.46551

Cumulative Model Updates: 54,752
Cumulative Timesteps: 456,824,976

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,793.83571
Policy Entropy: 0.76725
Value Function Loss: 0.09166

Mean KL Divergence: 0.00530
SB3 Clip Fraction: 0.06193
Policy Update Magnitude: 0.18784
Value Function Update Magnitude: 0.38967

Collected Steps per Second: 23,273.06583
Overall Steps per Second: 15,011.78996

Timestep Collection Time: 2.14901
Timestep Consumption Time: 1.18264
PPO Batch Consumption Time: 0.09712
Total Iteration Time: 3.33165

Cumulative Model Updates: 54,758
Cumulative Timesteps: 456,874,990

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 456874990...
Checkpoint 456874990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,757.99014
Policy Entropy: 0.75188
Value Function Loss: 0.09209

Mean KL Divergence: 0.00496
SB3 Clip Fraction: 0.05983
Policy Update Magnitude: 0.18990
Value Function Update Magnitude: 0.40456

Collected Steps per Second: 22,305.05341
Overall Steps per Second: 14,450.80446

Timestep Collection Time: 2.24371
Timestep Consumption Time: 1.21949
PPO Batch Consumption Time: 0.10200
Total Iteration Time: 3.46320

Cumulative Model Updates: 54,764
Cumulative Timesteps: 456,925,036

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,086.30503
Policy Entropy: 0.76501
Value Function Loss: 0.08846

Mean KL Divergence: 0.00439
SB3 Clip Fraction: 0.05159
Policy Update Magnitude: 0.18956
Value Function Update Magnitude: 0.40513

Collected Steps per Second: 22,680.43416
Overall Steps per Second: 14,642.51205

Timestep Collection Time: 2.20472
Timestep Consumption Time: 1.21027
PPO Batch Consumption Time: 0.10283
Total Iteration Time: 3.41499

Cumulative Model Updates: 54,770
Cumulative Timesteps: 456,975,040

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 456975040...
Checkpoint 456975040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,961.23749
Policy Entropy: 0.76591
Value Function Loss: 0.07370

Mean KL Divergence: 0.00440
SB3 Clip Fraction: 0.05104
Policy Update Magnitude: 0.19051
Value Function Update Magnitude: 0.40830

Collected Steps per Second: 23,056.94504
Overall Steps per Second: 14,739.81822

Timestep Collection Time: 2.16915
Timestep Consumption Time: 1.22397
PPO Batch Consumption Time: 0.09843
Total Iteration Time: 3.39312

Cumulative Model Updates: 54,776
Cumulative Timesteps: 457,025,054

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,072.45287
Policy Entropy: 0.77562
Value Function Loss: 0.07456

Mean KL Divergence: 0.00489
SB3 Clip Fraction: 0.05689
Policy Update Magnitude: 0.17898
Value Function Update Magnitude: 0.37897

Collected Steps per Second: 22,743.39948
Overall Steps per Second: 14,676.24981

Timestep Collection Time: 2.19906
Timestep Consumption Time: 1.20876
PPO Batch Consumption Time: 0.09617
Total Iteration Time: 3.40782

Cumulative Model Updates: 54,782
Cumulative Timesteps: 457,075,068

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 457075068...
Checkpoint 457075068 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,085.56036
Policy Entropy: 0.77346
Value Function Loss: 0.08625

Mean KL Divergence: 0.00538
SB3 Clip Fraction: 0.06070
Policy Update Magnitude: 0.17678
Value Function Update Magnitude: 0.34470

Collected Steps per Second: 21,698.03540
Overall Steps per Second: 14,074.38316

Timestep Collection Time: 2.30611
Timestep Consumption Time: 1.24915
PPO Batch Consumption Time: 0.09892
Total Iteration Time: 3.55525

Cumulative Model Updates: 54,788
Cumulative Timesteps: 457,125,106

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,926.72819
Policy Entropy: 0.79676
Value Function Loss: 0.09803

Mean KL Divergence: 0.00599
SB3 Clip Fraction: 0.06654
Policy Update Magnitude: 0.18934
Value Function Update Magnitude: 0.33996

Collected Steps per Second: 22,886.19819
Overall Steps per Second: 14,698.11628

Timestep Collection Time: 2.18586
Timestep Consumption Time: 1.21771
PPO Batch Consumption Time: 0.09409
Total Iteration Time: 3.40357

Cumulative Model Updates: 54,794
Cumulative Timesteps: 457,175,132

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 457175132...
Checkpoint 457175132 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,149.67126
Policy Entropy: 0.79099
Value Function Loss: 0.09552

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.09349
Policy Update Magnitude: 0.17825
Value Function Update Magnitude: 0.38403

Collected Steps per Second: 22,248.10956
Overall Steps per Second: 14,473.21326

Timestep Collection Time: 2.24846
Timestep Consumption Time: 1.20786
PPO Batch Consumption Time: 0.10133
Total Iteration Time: 3.45632

Cumulative Model Updates: 54,800
Cumulative Timesteps: 457,225,156

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,473.30582
Policy Entropy: 0.78747
Value Function Loss: 0.08843

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.08942
Policy Update Magnitude: 0.15039
Value Function Update Magnitude: 0.40589

Collected Steps per Second: 22,754.76462
Overall Steps per Second: 14,436.45938

Timestep Collection Time: 2.19734
Timestep Consumption Time: 1.26611
PPO Batch Consumption Time: 0.10274
Total Iteration Time: 3.46345

Cumulative Model Updates: 54,806
Cumulative Timesteps: 457,275,156

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 457275156...
Checkpoint 457275156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,539.06700
Policy Entropy: 0.78534
Value Function Loss: 0.08454

Mean KL Divergence: 0.00621
SB3 Clip Fraction: 0.06699
Policy Update Magnitude: 0.15089
Value Function Update Magnitude: 0.40519

Collected Steps per Second: 23,034.35816
Overall Steps per Second: 14,712.28034

Timestep Collection Time: 2.17189
Timestep Consumption Time: 1.22854
PPO Batch Consumption Time: 0.09712
Total Iteration Time: 3.40042

Cumulative Model Updates: 54,812
Cumulative Timesteps: 457,325,184

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,116.53650
Policy Entropy: 0.78814
Value Function Loss: 0.08129

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.08899
Policy Update Magnitude: 0.16378
Value Function Update Magnitude: 0.41869

Collected Steps per Second: 22,670.13245
Overall Steps per Second: 14,703.54309

Timestep Collection Time: 2.20749
Timestep Consumption Time: 1.19605
PPO Batch Consumption Time: 0.09296
Total Iteration Time: 3.40353

Cumulative Model Updates: 54,818
Cumulative Timesteps: 457,375,228

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 457375228...
Checkpoint 457375228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,379.42694
Policy Entropy: 0.79392
Value Function Loss: 0.09296

Mean KL Divergence: 0.01160
SB3 Clip Fraction: 0.09971
Policy Update Magnitude: 0.15780
Value Function Update Magnitude: 0.41700

Collected Steps per Second: 22,373.35573
Overall Steps per Second: 14,335.46244

Timestep Collection Time: 2.23480
Timestep Consumption Time: 1.25305
PPO Batch Consumption Time: 0.10068
Total Iteration Time: 3.48785

Cumulative Model Updates: 54,824
Cumulative Timesteps: 457,425,228

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,810.23313
Policy Entropy: 0.78011
Value Function Loss: 0.08423

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.08435
Policy Update Magnitude: 0.16415
Value Function Update Magnitude: 0.40507

Collected Steps per Second: 23,577.26059
Overall Steps per Second: 14,988.94939

Timestep Collection Time: 2.12247
Timestep Consumption Time: 1.21612
PPO Batch Consumption Time: 0.10003
Total Iteration Time: 3.33859

Cumulative Model Updates: 54,830
Cumulative Timesteps: 457,475,270

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 457475270...
Checkpoint 457475270 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,284.58888
Policy Entropy: 0.78868
Value Function Loss: 0.08058

Mean KL Divergence: 0.00589
SB3 Clip Fraction: 0.06406
Policy Update Magnitude: 0.17312
Value Function Update Magnitude: 0.35961

Collected Steps per Second: 22,489.73644
Overall Steps per Second: 14,487.94037

Timestep Collection Time: 2.22484
Timestep Consumption Time: 1.22879
PPO Batch Consumption Time: 0.10235
Total Iteration Time: 3.45363

Cumulative Model Updates: 54,836
Cumulative Timesteps: 457,525,306

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,626.43000
Policy Entropy: 0.77645
Value Function Loss: 0.07240

Mean KL Divergence: 0.00442
SB3 Clip Fraction: 0.05109
Policy Update Magnitude: 0.17836
Value Function Update Magnitude: 0.31889

Collected Steps per Second: 23,407.56731
Overall Steps per Second: 14,682.09011

Timestep Collection Time: 2.13615
Timestep Consumption Time: 1.26950
PPO Batch Consumption Time: 0.10058
Total Iteration Time: 3.40565

Cumulative Model Updates: 54,842
Cumulative Timesteps: 457,575,308

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 457575308...
Checkpoint 457575308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,602.68644
Policy Entropy: 0.78378
Value Function Loss: 0.08524

Mean KL Divergence: 0.00375
SB3 Clip Fraction: 0.04457
Policy Update Magnitude: 0.18606
Value Function Update Magnitude: 0.33271

Collected Steps per Second: 22,873.82635
Overall Steps per Second: 14,748.31715

Timestep Collection Time: 2.18687
Timestep Consumption Time: 1.20484
PPO Batch Consumption Time: 0.09691
Total Iteration Time: 3.39171

Cumulative Model Updates: 54,848
Cumulative Timesteps: 457,625,330

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,408.77254
Policy Entropy: 0.78204
Value Function Loss: 0.09098

Mean KL Divergence: 0.00476
SB3 Clip Fraction: 0.05512
Policy Update Magnitude: 0.18784
Value Function Update Magnitude: 0.40661

Collected Steps per Second: 22,390.55211
Overall Steps per Second: 14,697.55978

Timestep Collection Time: 2.23335
Timestep Consumption Time: 1.16898
PPO Batch Consumption Time: 0.09303
Total Iteration Time: 3.40233

Cumulative Model Updates: 54,854
Cumulative Timesteps: 457,675,336

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 457675336...
Checkpoint 457675336 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,007.72233
Policy Entropy: 0.78720
Value Function Loss: 0.09775

Mean KL Divergence: 0.00390
SB3 Clip Fraction: 0.04737
Policy Update Magnitude: 0.19358
Value Function Update Magnitude: 0.42862

Collected Steps per Second: 22,618.49062
Overall Steps per Second: 14,223.08980

Timestep Collection Time: 2.21191
Timestep Consumption Time: 1.30561
PPO Batch Consumption Time: 0.10723
Total Iteration Time: 3.51752

Cumulative Model Updates: 54,860
Cumulative Timesteps: 457,725,366

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,723.63933
Policy Entropy: 0.79680
Value Function Loss: 0.09293

Mean KL Divergence: 0.00420
SB3 Clip Fraction: 0.05115
Policy Update Magnitude: 0.19437
Value Function Update Magnitude: 0.42179

Collected Steps per Second: 23,073.96085
Overall Steps per Second: 14,631.89569

Timestep Collection Time: 2.16703
Timestep Consumption Time: 1.25030
PPO Batch Consumption Time: 0.10504
Total Iteration Time: 3.41733

Cumulative Model Updates: 54,866
Cumulative Timesteps: 457,775,368

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 457775368...
Checkpoint 457775368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,184.26394
Policy Entropy: 0.79953
Value Function Loss: 0.09151

Mean KL Divergence: 0.00430
SB3 Clip Fraction: 0.05311
Policy Update Magnitude: 0.19305
Value Function Update Magnitude: 0.41247

Collected Steps per Second: 22,436.32796
Overall Steps per Second: 14,368.72110

Timestep Collection Time: 2.22969
Timestep Consumption Time: 1.25190
PPO Batch Consumption Time: 0.10111
Total Iteration Time: 3.48159

Cumulative Model Updates: 54,872
Cumulative Timesteps: 457,825,394

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,581.62217
Policy Entropy: 0.78713
Value Function Loss: 0.08325

Mean KL Divergence: 0.00447
SB3 Clip Fraction: 0.05353
Policy Update Magnitude: 0.19042
Value Function Update Magnitude: 0.39417

Collected Steps per Second: 23,277.45896
Overall Steps per Second: 14,799.01895

Timestep Collection Time: 2.14852
Timestep Consumption Time: 1.23090
PPO Batch Consumption Time: 0.09986
Total Iteration Time: 3.37941

Cumulative Model Updates: 54,878
Cumulative Timesteps: 457,875,406

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 457875406...
Checkpoint 457875406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,395.13527
Policy Entropy: 0.78446
Value Function Loss: 0.08346

Mean KL Divergence: 0.00490
SB3 Clip Fraction: 0.05566
Policy Update Magnitude: 0.19185
Value Function Update Magnitude: 0.40008

Collected Steps per Second: 22,446.13229
Overall Steps per Second: 14,527.61868

Timestep Collection Time: 2.22925
Timestep Consumption Time: 1.21509
PPO Batch Consumption Time: 0.10221
Total Iteration Time: 3.44434

Cumulative Model Updates: 54,884
Cumulative Timesteps: 457,925,444

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,307.77167
Policy Entropy: 0.78626
Value Function Loss: 0.08037

Mean KL Divergence: 0.00387
SB3 Clip Fraction: 0.04574
Policy Update Magnitude: 0.18666
Value Function Update Magnitude: 0.37582

Collected Steps per Second: 22,783.18258
Overall Steps per Second: 14,672.93587

Timestep Collection Time: 2.19574
Timestep Consumption Time: 1.21366
PPO Batch Consumption Time: 0.09903
Total Iteration Time: 3.40941

Cumulative Model Updates: 54,890
Cumulative Timesteps: 457,975,470

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 457975470...
Checkpoint 457975470 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,549.58294
Policy Entropy: 0.79638
Value Function Loss: 0.08212

Mean KL Divergence: 0.00502
SB3 Clip Fraction: 0.05623
Policy Update Magnitude: 0.18345
Value Function Update Magnitude: 0.36056

Collected Steps per Second: 21,057.42872
Overall Steps per Second: 13,917.97818

Timestep Collection Time: 2.37598
Timestep Consumption Time: 1.21880
PPO Batch Consumption Time: 0.09692
Total Iteration Time: 3.59478

Cumulative Model Updates: 54,896
Cumulative Timesteps: 458,025,502

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,733.73600
Policy Entropy: 0.80013
Value Function Loss: 0.08423

Mean KL Divergence: 0.00390
SB3 Clip Fraction: 0.04519
Policy Update Magnitude: 0.18820
Value Function Update Magnitude: 0.36198

Collected Steps per Second: 23,195.72199
Overall Steps per Second: 14,892.28151

Timestep Collection Time: 2.15635
Timestep Consumption Time: 1.20231
PPO Batch Consumption Time: 0.10152
Total Iteration Time: 3.35865

Cumulative Model Updates: 54,902
Cumulative Timesteps: 458,075,520

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 458075520...
Checkpoint 458075520 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,863.00332
Policy Entropy: 0.80240
Value Function Loss: 0.08438

Mean KL Divergence: 0.00453
SB3 Clip Fraction: 0.05253
Policy Update Magnitude: 0.18718
Value Function Update Magnitude: 0.39859

Collected Steps per Second: 21,915.61838
Overall Steps per Second: 13,966.27295

Timestep Collection Time: 2.28203
Timestep Consumption Time: 1.29889
PPO Batch Consumption Time: 0.10143
Total Iteration Time: 3.58091

Cumulative Model Updates: 54,908
Cumulative Timesteps: 458,125,532

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,933.53455
Policy Entropy: 0.80562
Value Function Loss: 0.08537

Mean KL Divergence: 0.00438
SB3 Clip Fraction: 0.05179
Policy Update Magnitude: 0.18540
Value Function Update Magnitude: 0.39366

Collected Steps per Second: 22,830.42283
Overall Steps per Second: 14,722.99044

Timestep Collection Time: 2.19067
Timestep Consumption Time: 1.20633
PPO Batch Consumption Time: 0.09871
Total Iteration Time: 3.39700

Cumulative Model Updates: 54,914
Cumulative Timesteps: 458,175,546

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 458175546...
Checkpoint 458175546 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,513.59915
Policy Entropy: 0.79391
Value Function Loss: 0.08393

Mean KL Divergence: 0.00449
SB3 Clip Fraction: 0.05242
Policy Update Magnitude: 0.18802
Value Function Update Magnitude: 0.37540

Collected Steps per Second: 22,680.97879
Overall Steps per Second: 14,749.75550

Timestep Collection Time: 2.20449
Timestep Consumption Time: 1.18540
PPO Batch Consumption Time: 0.09206
Total Iteration Time: 3.38989

Cumulative Model Updates: 54,920
Cumulative Timesteps: 458,225,546

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,279.53827
Policy Entropy: 0.80541
Value Function Loss: 0.08200

Mean KL Divergence: 0.00493
SB3 Clip Fraction: 0.05656
Policy Update Magnitude: 0.19044
Value Function Update Magnitude: 0.39099

Collected Steps per Second: 22,309.32665
Overall Steps per Second: 14,422.71134

Timestep Collection Time: 2.24193
Timestep Consumption Time: 1.22593
PPO Batch Consumption Time: 0.10252
Total Iteration Time: 3.46786

Cumulative Model Updates: 54,926
Cumulative Timesteps: 458,275,562

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 458275562...
Checkpoint 458275562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,942.92156
Policy Entropy: 0.80659
Value Function Loss: 0.07494

Mean KL Divergence: 0.00673
SB3 Clip Fraction: 0.06742
Policy Update Magnitude: 0.17291
Value Function Update Magnitude: 0.39725

Collected Steps per Second: 22,836.78203
Overall Steps per Second: 14,711.76521

Timestep Collection Time: 2.18998
Timestep Consumption Time: 1.20948
PPO Batch Consumption Time: 0.10030
Total Iteration Time: 3.39946

Cumulative Model Updates: 54,932
Cumulative Timesteps: 458,325,574

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,346.92953
Policy Entropy: 0.81810
Value Function Loss: 0.08138

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.07508
Policy Update Magnitude: 0.15630
Value Function Update Magnitude: 0.38342

Collected Steps per Second: 22,971.78830
Overall Steps per Second: 14,569.02818

Timestep Collection Time: 2.17737
Timestep Consumption Time: 1.25581
PPO Batch Consumption Time: 0.10192
Total Iteration Time: 3.43317

Cumulative Model Updates: 54,938
Cumulative Timesteps: 458,375,592

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 458375592...
Checkpoint 458375592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,704.20027
Policy Entropy: 0.81705
Value Function Loss: 0.08024

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.08464
Policy Update Magnitude: 0.16312
Value Function Update Magnitude: 0.39666

Collected Steps per Second: 22,146.87155
Overall Steps per Second: 14,229.75641

Timestep Collection Time: 2.25892
Timestep Consumption Time: 1.25681
PPO Batch Consumption Time: 0.10160
Total Iteration Time: 3.51573

Cumulative Model Updates: 54,944
Cumulative Timesteps: 458,425,620

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,439.66207
Policy Entropy: 0.81303
Value Function Loss: 0.08714

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.08578
Policy Update Magnitude: 0.17908
Value Function Update Magnitude: 0.40265

Collected Steps per Second: 23,295.59383
Overall Steps per Second: 14,791.69394

Timestep Collection Time: 2.14822
Timestep Consumption Time: 1.23503
PPO Batch Consumption Time: 0.10067
Total Iteration Time: 3.38325

Cumulative Model Updates: 54,950
Cumulative Timesteps: 458,475,664

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 458475664...
Checkpoint 458475664 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,781.11939
Policy Entropy: 0.81871
Value Function Loss: 0.08802

Mean KL Divergence: 0.00635
SB3 Clip Fraction: 0.06664
Policy Update Magnitude: 0.18918
Value Function Update Magnitude: 0.41697

Collected Steps per Second: 22,459.99067
Overall Steps per Second: 14,533.61541

Timestep Collection Time: 2.22618
Timestep Consumption Time: 1.21412
PPO Batch Consumption Time: 0.09839
Total Iteration Time: 3.44030

Cumulative Model Updates: 54,956
Cumulative Timesteps: 458,525,664

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,733.88359
Policy Entropy: 0.81930
Value Function Loss: 0.08846

Mean KL Divergence: 0.00542
SB3 Clip Fraction: 0.05962
Policy Update Magnitude: 0.18814
Value Function Update Magnitude: 0.42629

Collected Steps per Second: 22,557.10936
Overall Steps per Second: 14,688.89428

Timestep Collection Time: 2.21677
Timestep Consumption Time: 1.18743
PPO Batch Consumption Time: 0.09700
Total Iteration Time: 3.40420

Cumulative Model Updates: 54,962
Cumulative Timesteps: 458,575,668

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 458575668...
Checkpoint 458575668 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,554.94058
Policy Entropy: 0.81274
Value Function Loss: 0.08300

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.08406
Policy Update Magnitude: 0.17736
Value Function Update Magnitude: 0.41815

Collected Steps per Second: 22,718.67818
Overall Steps per Second: 14,791.02349

Timestep Collection Time: 2.20145
Timestep Consumption Time: 1.17993
PPO Batch Consumption Time: 0.09206
Total Iteration Time: 3.38138

Cumulative Model Updates: 54,968
Cumulative Timesteps: 458,625,682

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,635.32123
Policy Entropy: 0.81070
Value Function Loss: 0.07737

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.07660
Policy Update Magnitude: 0.17908
Value Function Update Magnitude: 0.39853

Collected Steps per Second: 22,401.79687
Overall Steps per Second: 14,749.34082

Timestep Collection Time: 2.23286
Timestep Consumption Time: 1.15848
PPO Batch Consumption Time: 0.09040
Total Iteration Time: 3.39134

Cumulative Model Updates: 54,974
Cumulative Timesteps: 458,675,702

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 458675702...
Checkpoint 458675702 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,480.69495
Policy Entropy: 0.81176
Value Function Loss: 0.07142

Mean KL Divergence: 0.00623
SB3 Clip Fraction: 0.06727
Policy Update Magnitude: 0.17487
Value Function Update Magnitude: 0.38857

Collected Steps per Second: 22,208.28113
Overall Steps per Second: 14,466.04786

Timestep Collection Time: 2.25249
Timestep Consumption Time: 1.20554
PPO Batch Consumption Time: 0.09912
Total Iteration Time: 3.45803

Cumulative Model Updates: 54,980
Cumulative Timesteps: 458,725,726

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,842.40350
Policy Entropy: 0.79990
Value Function Loss: 0.07144

Mean KL Divergence: 0.00373
SB3 Clip Fraction: 0.04404
Policy Update Magnitude: 0.17488
Value Function Update Magnitude: 0.36116

Collected Steps per Second: 22,975.53465
Overall Steps per Second: 14,727.90369

Timestep Collection Time: 2.17832
Timestep Consumption Time: 1.21986
PPO Batch Consumption Time: 0.09977
Total Iteration Time: 3.39818

Cumulative Model Updates: 54,986
Cumulative Timesteps: 458,775,774

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 458775774...
Checkpoint 458775774 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,580.26877
Policy Entropy: 0.81245
Value Function Loss: 0.07328

Mean KL Divergence: 0.00351
SB3 Clip Fraction: 0.04372
Policy Update Magnitude: 0.16769
Value Function Update Magnitude: 0.31795

Collected Steps per Second: 22,058.24821
Overall Steps per Second: 14,485.27430

Timestep Collection Time: 2.26727
Timestep Consumption Time: 1.18534
PPO Batch Consumption Time: 0.09544
Total Iteration Time: 3.45261

Cumulative Model Updates: 54,992
Cumulative Timesteps: 458,825,786

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,152.70560
Policy Entropy: 0.81906
Value Function Loss: 0.07909

Mean KL Divergence: 0.00397
SB3 Clip Fraction: 0.04637
Policy Update Magnitude: 0.16852
Value Function Update Magnitude: 0.32710

Collected Steps per Second: 23,188.18857
Overall Steps per Second: 14,712.89781

Timestep Collection Time: 2.15627
Timestep Consumption Time: 1.24211
PPO Batch Consumption Time: 0.09514
Total Iteration Time: 3.39838

Cumulative Model Updates: 54,998
Cumulative Timesteps: 458,875,786

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 458875786...
Checkpoint 458875786 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,705.42224
Policy Entropy: 0.82640
Value Function Loss: 0.08541

Mean KL Divergence: 0.00406
SB3 Clip Fraction: 0.04731
Policy Update Magnitude: 0.17888
Value Function Update Magnitude: 0.35025

Collected Steps per Second: 22,533.29212
Overall Steps per Second: 14,811.36640

Timestep Collection Time: 2.21929
Timestep Consumption Time: 1.15703
PPO Batch Consumption Time: 0.09314
Total Iteration Time: 3.37633

Cumulative Model Updates: 55,004
Cumulative Timesteps: 458,925,794

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,012.59990
Policy Entropy: 0.83077
Value Function Loss: 0.08607

Mean KL Divergence: 0.00366
SB3 Clip Fraction: 0.04351
Policy Update Magnitude: 0.18800
Value Function Update Magnitude: 0.38315

Collected Steps per Second: 22,732.59337
Overall Steps per Second: 14,737.06576

Timestep Collection Time: 2.19984
Timestep Consumption Time: 1.19351
PPO Batch Consumption Time: 0.09131
Total Iteration Time: 3.39335

Cumulative Model Updates: 55,010
Cumulative Timesteps: 458,975,802

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 458975802...
Checkpoint 458975802 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,015.88787
Policy Entropy: 0.82439
Value Function Loss: 0.08467

Mean KL Divergence: 0.00404
SB3 Clip Fraction: 0.04877
Policy Update Magnitude: 0.19247
Value Function Update Magnitude: 0.37801

Collected Steps per Second: 22,690.20390
Overall Steps per Second: 14,487.66811

Timestep Collection Time: 2.20536
Timestep Consumption Time: 1.24861
PPO Batch Consumption Time: 0.10100
Total Iteration Time: 3.45397

Cumulative Model Updates: 55,016
Cumulative Timesteps: 459,025,842

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,736.51591
Policy Entropy: 0.83370
Value Function Loss: 0.09500

Mean KL Divergence: 0.00429
SB3 Clip Fraction: 0.05114
Policy Update Magnitude: 0.19543
Value Function Update Magnitude: 0.39682

Collected Steps per Second: 23,450.76750
Overall Steps per Second: 14,825.29863

Timestep Collection Time: 2.13315
Timestep Consumption Time: 1.24108
PPO Batch Consumption Time: 0.09919
Total Iteration Time: 3.37423

Cumulative Model Updates: 55,022
Cumulative Timesteps: 459,075,866

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 459075866...
Checkpoint 459075866 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,369.66083
Policy Entropy: 0.83988
Value Function Loss: 0.09997

Mean KL Divergence: 0.00497
SB3 Clip Fraction: 0.05972
Policy Update Magnitude: 0.19959
Value Function Update Magnitude: 0.41556

Collected Steps per Second: 22,236.16578
Overall Steps per Second: 14,464.05066

Timestep Collection Time: 2.24859
Timestep Consumption Time: 1.20826
PPO Batch Consumption Time: 0.10176
Total Iteration Time: 3.45685

Cumulative Model Updates: 55,028
Cumulative Timesteps: 459,125,866

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,072.88002
Policy Entropy: 0.84983
Value Function Loss: 0.09768

Mean KL Divergence: 0.00515
SB3 Clip Fraction: 0.06056
Policy Update Magnitude: 0.20136
Value Function Update Magnitude: 0.37794

Collected Steps per Second: 23,113.10069
Overall Steps per Second: 14,610.66106

Timestep Collection Time: 2.16353
Timestep Consumption Time: 1.25903
PPO Batch Consumption Time: 0.09890
Total Iteration Time: 3.42257

Cumulative Model Updates: 55,034
Cumulative Timesteps: 459,175,872

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 459175872...
Checkpoint 459175872 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,790.33764
Policy Entropy: 0.84259
Value Function Loss: 0.09117

Mean KL Divergence: 0.00508
SB3 Clip Fraction: 0.05797
Policy Update Magnitude: 0.20029
Value Function Update Magnitude: 0.35686

Collected Steps per Second: 23,096.94031
Overall Steps per Second: 14,859.48838

Timestep Collection Time: 2.16479
Timestep Consumption Time: 1.20006
PPO Batch Consumption Time: 0.09534
Total Iteration Time: 3.36485

Cumulative Model Updates: 55,040
Cumulative Timesteps: 459,225,872

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,011.59807
Policy Entropy: 0.83747
Value Function Loss: 0.08308

Mean KL Divergence: 0.00458
SB3 Clip Fraction: 0.05521
Policy Update Magnitude: 0.18230
Value Function Update Magnitude: 0.35397

Collected Steps per Second: 22,671.80977
Overall Steps per Second: 14,725.81446

Timestep Collection Time: 2.20741
Timestep Consumption Time: 1.19111
PPO Batch Consumption Time: 0.09368
Total Iteration Time: 3.39852

Cumulative Model Updates: 55,046
Cumulative Timesteps: 459,275,918

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 459275918...
Checkpoint 459275918 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,091.13875
Policy Entropy: 0.83299
Value Function Loss: 0.08254

Mean KL Divergence: 0.00416
SB3 Clip Fraction: 0.04724
Policy Update Magnitude: 0.18123
Value Function Update Magnitude: 0.35226

Collected Steps per Second: 22,952.23357
Overall Steps per Second: 14,834.26300

Timestep Collection Time: 2.17931
Timestep Consumption Time: 1.19261
PPO Batch Consumption Time: 0.09293
Total Iteration Time: 3.37192

Cumulative Model Updates: 55,052
Cumulative Timesteps: 459,325,938

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,847.64277
Policy Entropy: 0.84317
Value Function Loss: 0.08575

Mean KL Divergence: 0.00472
SB3 Clip Fraction: 0.05481
Policy Update Magnitude: 0.17764
Value Function Update Magnitude: 0.37662

Collected Steps per Second: 23,191.65175
Overall Steps per Second: 14,817.07813

Timestep Collection Time: 2.15707
Timestep Consumption Time: 1.21917
PPO Batch Consumption Time: 0.09703
Total Iteration Time: 3.37624

Cumulative Model Updates: 55,058
Cumulative Timesteps: 459,375,964

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 459375964...
Checkpoint 459375964 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,232.61426
Policy Entropy: 0.83652
Value Function Loss: 0.08307

Mean KL Divergence: 0.00484
SB3 Clip Fraction: 0.05630
Policy Update Magnitude: 0.18236
Value Function Update Magnitude: 0.37787

Collected Steps per Second: 22,309.42870
Overall Steps per Second: 14,338.85122

Timestep Collection Time: 2.24165
Timestep Consumption Time: 1.24607
PPO Batch Consumption Time: 0.10135
Total Iteration Time: 3.48773

Cumulative Model Updates: 55,064
Cumulative Timesteps: 459,425,974

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,210.00311
Policy Entropy: 0.83755
Value Function Loss: 0.08312

Mean KL Divergence: 0.00737
SB3 Clip Fraction: 0.07779
Policy Update Magnitude: 0.17875
Value Function Update Magnitude: 0.35785

Collected Steps per Second: 23,028.62850
Overall Steps per Second: 14,836.67506

Timestep Collection Time: 2.17121
Timestep Consumption Time: 1.19882
PPO Batch Consumption Time: 0.09985
Total Iteration Time: 3.37003

Cumulative Model Updates: 55,070
Cumulative Timesteps: 459,475,974

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 459475974...
Checkpoint 459475974 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,947.92307
Policy Entropy: 0.82722
Value Function Loss: 0.08413

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.09614
Policy Update Magnitude: 0.15568
Value Function Update Magnitude: 0.35429

Collected Steps per Second: 22,542.20161
Overall Steps per Second: 14,539.23388

Timestep Collection Time: 2.21859
Timestep Consumption Time: 1.22120
PPO Batch Consumption Time: 0.10099
Total Iteration Time: 3.43980

Cumulative Model Updates: 55,076
Cumulative Timesteps: 459,525,986

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,042.68995
Policy Entropy: 0.82432
Value Function Loss: 0.08300

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.09017
Policy Update Magnitude: 0.15521
Value Function Update Magnitude: 0.35148

Collected Steps per Second: 21,196.47984
Overall Steps per Second: 13,810.14044

Timestep Collection Time: 2.35983
Timestep Consumption Time: 1.26215
PPO Batch Consumption Time: 0.09869
Total Iteration Time: 3.62198

Cumulative Model Updates: 55,082
Cumulative Timesteps: 459,576,006

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 459576006...
Checkpoint 459576006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,095.65150
Policy Entropy: 0.82741
Value Function Loss: 0.07798

Mean KL Divergence: 0.01080
SB3 Clip Fraction: 0.09769
Policy Update Magnitude: 0.15232
Value Function Update Magnitude: 0.35932

Collected Steps per Second: 23,212.01459
Overall Steps per Second: 14,945.67640

Timestep Collection Time: 2.15587
Timestep Consumption Time: 1.19239
PPO Batch Consumption Time: 0.09854
Total Iteration Time: 3.34826

Cumulative Model Updates: 55,088
Cumulative Timesteps: 459,626,048

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,455.49315
Policy Entropy: 0.83069
Value Function Loss: 0.07373

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.08803
Policy Update Magnitude: 0.15629
Value Function Update Magnitude: 0.35788

Collected Steps per Second: 23,176.37742
Overall Steps per Second: 14,840.42876

Timestep Collection Time: 2.15866
Timestep Consumption Time: 1.21253
PPO Batch Consumption Time: 0.10079
Total Iteration Time: 3.37120

Cumulative Model Updates: 55,094
Cumulative Timesteps: 459,676,078

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 459676078...
Checkpoint 459676078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,562.51252
Policy Entropy: 0.82723
Value Function Loss: 0.07302

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.08868
Policy Update Magnitude: 0.15787
Value Function Update Magnitude: 0.34783

Collected Steps per Second: 22,301.34430
Overall Steps per Second: 14,784.27496

Timestep Collection Time: 2.24300
Timestep Consumption Time: 1.14046
PPO Batch Consumption Time: 0.10016
Total Iteration Time: 3.38346

Cumulative Model Updates: 55,100
Cumulative Timesteps: 459,726,100

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,149.06922
Policy Entropy: 0.82265
Value Function Loss: 0.08040

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.09113
Policy Update Magnitude: 0.16136
Value Function Update Magnitude: 0.37403

Collected Steps per Second: 22,836.23312
Overall Steps per Second: 15,061.26952

Timestep Collection Time: 2.19020
Timestep Consumption Time: 1.13063
PPO Batch Consumption Time: 0.09948
Total Iteration Time: 3.32084

Cumulative Model Updates: 55,106
Cumulative Timesteps: 459,776,116

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 459776116...
Checkpoint 459776116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,594.52413
Policy Entropy: 0.81491
Value Function Loss: 0.08057

Mean KL Divergence: 0.00644
SB3 Clip Fraction: 0.07113
Policy Update Magnitude: 0.17198
Value Function Update Magnitude: 0.38956

Collected Steps per Second: 21,890.61939
Overall Steps per Second: 14,583.60101

Timestep Collection Time: 2.28454
Timestep Consumption Time: 1.14465
PPO Batch Consumption Time: 0.09918
Total Iteration Time: 3.42919

Cumulative Model Updates: 55,112
Cumulative Timesteps: 459,826,126

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,736.84489
Policy Entropy: 0.81816
Value Function Loss: 0.08749

Mean KL Divergence: 0.00594
SB3 Clip Fraction: 0.06765
Policy Update Magnitude: 0.18260
Value Function Update Magnitude: 0.38118

Collected Steps per Second: 22,536.60159
Overall Steps per Second: 14,764.21496

Timestep Collection Time: 2.21977
Timestep Consumption Time: 1.16856
PPO Batch Consumption Time: 0.09943
Total Iteration Time: 3.38833

Cumulative Model Updates: 55,118
Cumulative Timesteps: 459,876,152

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 459876152...
Checkpoint 459876152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,755.58588
Policy Entropy: 0.80767
Value Function Loss: 0.08741

Mean KL Divergence: 0.00563
SB3 Clip Fraction: 0.06510
Policy Update Magnitude: 0.18869
Value Function Update Magnitude: 0.38883

Collected Steps per Second: 22,559.27992
Overall Steps per Second: 14,879.57248

Timestep Collection Time: 2.21638
Timestep Consumption Time: 1.14393
PPO Batch Consumption Time: 0.10173
Total Iteration Time: 3.36031

Cumulative Model Updates: 55,124
Cumulative Timesteps: 459,926,152

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,052.18743
Policy Entropy: 0.81598
Value Function Loss: 0.07784

Mean KL Divergence: 0.00465
SB3 Clip Fraction: 0.05606
Policy Update Magnitude: 0.18893
Value Function Update Magnitude: 0.38223

Collected Steps per Second: 22,490.69313
Overall Steps per Second: 14,792.74010

Timestep Collection Time: 2.22314
Timestep Consumption Time: 1.15689
PPO Batch Consumption Time: 0.10194
Total Iteration Time: 3.38004

Cumulative Model Updates: 55,130
Cumulative Timesteps: 459,976,152

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 459976152...
Checkpoint 459976152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,757.27094
Policy Entropy: 0.82138
Value Function Loss: 0.07307

Mean KL Divergence: 0.00412
SB3 Clip Fraction: 0.04942
Policy Update Magnitude: 0.18387
Value Function Update Magnitude: 0.35777

Collected Steps per Second: 22,745.55650
Overall Steps per Second: 14,683.46303

Timestep Collection Time: 2.19867
Timestep Consumption Time: 1.20720
PPO Batch Consumption Time: 0.09695
Total Iteration Time: 3.40587

Cumulative Model Updates: 55,136
Cumulative Timesteps: 460,026,162

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,314.01713
Policy Entropy: 0.81580
Value Function Loss: 0.06942

Mean KL Divergence: 0.00357
SB3 Clip Fraction: 0.04352
Policy Update Magnitude: 0.18481
Value Function Update Magnitude: 0.35459

Collected Steps per Second: 23,511.84781
Overall Steps per Second: 15,108.17973

Timestep Collection Time: 2.12829
Timestep Consumption Time: 1.18382
PPO Batch Consumption Time: 0.09856
Total Iteration Time: 3.31211

Cumulative Model Updates: 55,142
Cumulative Timesteps: 460,076,202

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 460076202...
Checkpoint 460076202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,965.39826
Policy Entropy: 0.81492
Value Function Loss: 0.08234

Mean KL Divergence: 0.00361
SB3 Clip Fraction: 0.04461
Policy Update Magnitude: 0.18615
Value Function Update Magnitude: 0.37225

Collected Steps per Second: 22,504.97091
Overall Steps per Second: 14,687.47305

Timestep Collection Time: 2.22253
Timestep Consumption Time: 1.18296
PPO Batch Consumption Time: 0.10059
Total Iteration Time: 3.40549

Cumulative Model Updates: 55,148
Cumulative Timesteps: 460,126,220

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,527.48370
Policy Entropy: 0.81851
Value Function Loss: 0.09162

Mean KL Divergence: 0.00364
SB3 Clip Fraction: 0.04413
Policy Update Magnitude: 0.19602
Value Function Update Magnitude: 0.41828

Collected Steps per Second: 23,819.25298
Overall Steps per Second: 15,329.66802

Timestep Collection Time: 2.09948
Timestep Consumption Time: 1.16269
PPO Batch Consumption Time: 0.08992
Total Iteration Time: 3.26217

Cumulative Model Updates: 55,154
Cumulative Timesteps: 460,176,228

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 460176228...
Checkpoint 460176228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,280.03804
Policy Entropy: 0.81186
Value Function Loss: 0.09265

Mean KL Divergence: 0.00398
SB3 Clip Fraction: 0.04821
Policy Update Magnitude: 0.19801
Value Function Update Magnitude: 0.43917

Collected Steps per Second: 23,347.60858
Overall Steps per Second: 15,025.70186

Timestep Collection Time: 2.14189
Timestep Consumption Time: 1.18627
PPO Batch Consumption Time: 0.09797
Total Iteration Time: 3.32816

Cumulative Model Updates: 55,160
Cumulative Timesteps: 460,226,236

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,287.46241
Policy Entropy: 0.80703
Value Function Loss: 0.08687

Mean KL Divergence: 0.00393
SB3 Clip Fraction: 0.04826
Policy Update Magnitude: 0.19438
Value Function Update Magnitude: 0.43043

Collected Steps per Second: 22,712.32118
Overall Steps per Second: 14,739.01235

Timestep Collection Time: 2.20242
Timestep Consumption Time: 1.19143
PPO Batch Consumption Time: 0.09815
Total Iteration Time: 3.39385

Cumulative Model Updates: 55,166
Cumulative Timesteps: 460,276,258

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 460276258...
Checkpoint 460276258 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,414.78353
Policy Entropy: 0.80463
Value Function Loss: 0.08235

Mean KL Divergence: 0.00332
SB3 Clip Fraction: 0.04018
Policy Update Magnitude: 0.18903
Value Function Update Magnitude: 0.42558

Collected Steps per Second: 23,173.18735
Overall Steps per Second: 14,842.42720

Timestep Collection Time: 2.15810
Timestep Consumption Time: 1.21130
PPO Batch Consumption Time: 0.10081
Total Iteration Time: 3.36939

Cumulative Model Updates: 55,172
Cumulative Timesteps: 460,326,268

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,969.72023
Policy Entropy: 0.80689
Value Function Loss: 0.08957

Mean KL Divergence: 0.00329
SB3 Clip Fraction: 0.04002
Policy Update Magnitude: 0.19377
Value Function Update Magnitude: 0.42346

Collected Steps per Second: 23,104.51496
Overall Steps per Second: 14,810.66610

Timestep Collection Time: 2.16546
Timestep Consumption Time: 1.21264
PPO Batch Consumption Time: 0.10181
Total Iteration Time: 3.37811

Cumulative Model Updates: 55,178
Cumulative Timesteps: 460,376,300

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 460376300...
Checkpoint 460376300 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,198.16757
Policy Entropy: 0.80388
Value Function Loss: 0.08783

Mean KL Divergence: 0.00443
SB3 Clip Fraction: 0.05231
Policy Update Magnitude: 0.19901
Value Function Update Magnitude: 0.43732

Collected Steps per Second: 22,969.71477
Overall Steps per Second: 14,830.24591

Timestep Collection Time: 2.17713
Timestep Consumption Time: 1.19490
PPO Batch Consumption Time: 0.09949
Total Iteration Time: 3.37203

Cumulative Model Updates: 55,184
Cumulative Timesteps: 460,426,308

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,829.84805
Policy Entropy: 0.80162
Value Function Loss: 0.08064

Mean KL Divergence: 0.00429
SB3 Clip Fraction: 0.04849
Policy Update Magnitude: 0.19115
Value Function Update Magnitude: 0.42015

Collected Steps per Second: 23,538.46719
Overall Steps per Second: 14,887.85541

Timestep Collection Time: 2.12469
Timestep Consumption Time: 1.23456
PPO Batch Consumption Time: 0.09972
Total Iteration Time: 3.35925

Cumulative Model Updates: 55,190
Cumulative Timesteps: 460,476,320

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 460476320...
Checkpoint 460476320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,656.15630
Policy Entropy: 0.79826
Value Function Loss: 0.07668

Mean KL Divergence: 0.00395
SB3 Clip Fraction: 0.04726
Policy Update Magnitude: 0.18251
Value Function Update Magnitude: 0.39187

Collected Steps per Second: 22,506.13913
Overall Steps per Second: 14,594.36293

Timestep Collection Time: 2.22250
Timestep Consumption Time: 1.20485
PPO Batch Consumption Time: 0.09628
Total Iteration Time: 3.42735

Cumulative Model Updates: 55,196
Cumulative Timesteps: 460,526,340

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,891.72998
Policy Entropy: 0.79032
Value Function Loss: 0.08915

Mean KL Divergence: 0.00483
SB3 Clip Fraction: 0.05703
Policy Update Magnitude: 0.18141
Value Function Update Magnitude: 0.38838

Collected Steps per Second: 22,873.46719
Overall Steps per Second: 14,739.40271

Timestep Collection Time: 2.18611
Timestep Consumption Time: 1.20643
PPO Batch Consumption Time: 0.09545
Total Iteration Time: 3.39254

Cumulative Model Updates: 55,202
Cumulative Timesteps: 460,576,344

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 460576344...
Checkpoint 460576344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,055.27416
Policy Entropy: 0.79537
Value Function Loss: 0.08733

Mean KL Divergence: 0.00492
SB3 Clip Fraction: 0.05827
Policy Update Magnitude: 0.18884
Value Function Update Magnitude: 0.42226

Collected Steps per Second: 23,362.80316
Overall Steps per Second: 14,911.93898

Timestep Collection Time: 2.14092
Timestep Consumption Time: 1.21330
PPO Batch Consumption Time: 0.09708
Total Iteration Time: 3.35423

Cumulative Model Updates: 55,208
Cumulative Timesteps: 460,626,362

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,708.21251
Policy Entropy: 0.79375
Value Function Loss: 0.08842

Mean KL Divergence: 0.00480
SB3 Clip Fraction: 0.05741
Policy Update Magnitude: 0.19247
Value Function Update Magnitude: 0.42733

Collected Steps per Second: 22,843.88979
Overall Steps per Second: 14,806.23540

Timestep Collection Time: 2.18929
Timestep Consumption Time: 1.18847
PPO Batch Consumption Time: 0.09939
Total Iteration Time: 3.37777

Cumulative Model Updates: 55,214
Cumulative Timesteps: 460,676,374

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 460676374...
Checkpoint 460676374 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,888.31286
Policy Entropy: 0.80437
Value Function Loss: 0.08679

Mean KL Divergence: 0.00540
SB3 Clip Fraction: 0.06422
Policy Update Magnitude: 0.19542
Value Function Update Magnitude: 0.41085

Collected Steps per Second: 23,208.79992
Overall Steps per Second: 14,736.44503

Timestep Collection Time: 2.15453
Timestep Consumption Time: 1.23869
PPO Batch Consumption Time: 0.09641
Total Iteration Time: 3.39322

Cumulative Model Updates: 55,220
Cumulative Timesteps: 460,726,378

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,499.00861
Policy Entropy: 0.80051
Value Function Loss: 0.08634

Mean KL Divergence: 0.00522
SB3 Clip Fraction: 0.06167
Policy Update Magnitude: 0.19521
Value Function Update Magnitude: 0.37795

Collected Steps per Second: 23,216.32005
Overall Steps per Second: 14,785.94862

Timestep Collection Time: 2.15417
Timestep Consumption Time: 1.22823
PPO Batch Consumption Time: 0.09877
Total Iteration Time: 3.38240

Cumulative Model Updates: 55,226
Cumulative Timesteps: 460,776,390

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 460776390...
Checkpoint 460776390 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,056.82919
Policy Entropy: 0.81219
Value Function Loss: 0.08851

Mean KL Divergence: 0.00498
SB3 Clip Fraction: 0.05844
Policy Update Magnitude: 0.19482
Value Function Update Magnitude: 0.39131

Collected Steps per Second: 21,467.58978
Overall Steps per Second: 14,084.08624

Timestep Collection Time: 2.32984
Timestep Consumption Time: 1.22140
PPO Batch Consumption Time: 0.10092
Total Iteration Time: 3.55124

Cumulative Model Updates: 55,232
Cumulative Timesteps: 460,826,406

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,261.33100
Policy Entropy: 0.81508
Value Function Loss: 0.07909

Mean KL Divergence: 0.00530
SB3 Clip Fraction: 0.06203
Policy Update Magnitude: 0.18757
Value Function Update Magnitude: 0.39198

Collected Steps per Second: 23,533.25778
Overall Steps per Second: 14,754.56439

Timestep Collection Time: 2.12474
Timestep Consumption Time: 1.26418
PPO Batch Consumption Time: 0.10087
Total Iteration Time: 3.38892

Cumulative Model Updates: 55,238
Cumulative Timesteps: 460,876,408

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 460876408...
Checkpoint 460876408 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,341.30204
Policy Entropy: 0.81578
Value Function Loss: 0.07957

Mean KL Divergence: 0.00555
SB3 Clip Fraction: 0.06488
Policy Update Magnitude: 0.19093
Value Function Update Magnitude: 0.38217

Collected Steps per Second: 23,345.65437
Overall Steps per Second: 14,859.94515

Timestep Collection Time: 2.14233
Timestep Consumption Time: 1.22337
PPO Batch Consumption Time: 0.09953
Total Iteration Time: 3.36569

Cumulative Model Updates: 55,244
Cumulative Timesteps: 460,926,422

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,260.52806
Policy Entropy: 0.79997
Value Function Loss: 0.08690

Mean KL Divergence: 0.00418
SB3 Clip Fraction: 0.04980
Policy Update Magnitude: 0.19290
Value Function Update Magnitude: 0.41220

Collected Steps per Second: 22,758.14622
Overall Steps per Second: 14,688.11751

Timestep Collection Time: 2.19702
Timestep Consumption Time: 1.20710
PPO Batch Consumption Time: 0.09784
Total Iteration Time: 3.40411

Cumulative Model Updates: 55,250
Cumulative Timesteps: 460,976,422

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 460976422...
Checkpoint 460976422 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,041.27261
Policy Entropy: 0.79918
Value Function Loss: 0.08276

Mean KL Divergence: 0.00479
SB3 Clip Fraction: 0.05678
Policy Update Magnitude: 0.18562
Value Function Update Magnitude: 0.44375

Collected Steps per Second: 23,325.29948
Overall Steps per Second: 14,858.97348

Timestep Collection Time: 2.14360
Timestep Consumption Time: 1.22137
PPO Batch Consumption Time: 0.09831
Total Iteration Time: 3.36497

Cumulative Model Updates: 55,256
Cumulative Timesteps: 461,026,422

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,562.93360
Policy Entropy: 0.79526
Value Function Loss: 0.08063

Mean KL Divergence: 0.00458
SB3 Clip Fraction: 0.05327
Policy Update Magnitude: 0.17966
Value Function Update Magnitude: 0.42970

Collected Steps per Second: 23,753.03000
Overall Steps per Second: 15,119.88835

Timestep Collection Time: 2.10685
Timestep Consumption Time: 1.20297
PPO Batch Consumption Time: 0.09955
Total Iteration Time: 3.30981

Cumulative Model Updates: 55,262
Cumulative Timesteps: 461,076,466

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 461076466...
Checkpoint 461076466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,360.24509
Policy Entropy: 0.81224
Value Function Loss: 0.07841

Mean KL Divergence: 0.00497
SB3 Clip Fraction: 0.05599
Policy Update Magnitude: 0.18379
Value Function Update Magnitude: 0.39746

Collected Steps per Second: 22,749.59149
Overall Steps per Second: 14,825.50862

Timestep Collection Time: 2.19872
Timestep Consumption Time: 1.17519
PPO Batch Consumption Time: 0.09926
Total Iteration Time: 3.37391

Cumulative Model Updates: 55,268
Cumulative Timesteps: 461,126,486

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,231.08177
Policy Entropy: 0.79902
Value Function Loss: 0.08451

Mean KL Divergence: 0.00426
SB3 Clip Fraction: 0.05118
Policy Update Magnitude: 0.18669
Value Function Update Magnitude: 0.38783

Collected Steps per Second: 23,502.86788
Overall Steps per Second: 15,158.18404

Timestep Collection Time: 2.12851
Timestep Consumption Time: 1.17176
PPO Batch Consumption Time: 0.09121
Total Iteration Time: 3.30026

Cumulative Model Updates: 55,274
Cumulative Timesteps: 461,176,512

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 461176512...
Checkpoint 461176512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,824.52642
Policy Entropy: 0.79655
Value Function Loss: 0.08562

Mean KL Divergence: 0.00477
SB3 Clip Fraction: 0.05495
Policy Update Magnitude: 0.19554
Value Function Update Magnitude: 0.42013

Collected Steps per Second: 22,940.65955
Overall Steps per Second: 14,970.05809

Timestep Collection Time: 2.18137
Timestep Consumption Time: 1.16144
PPO Batch Consumption Time: 0.09203
Total Iteration Time: 3.34281

Cumulative Model Updates: 55,280
Cumulative Timesteps: 461,226,554

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,579.27405
Policy Entropy: 0.79753
Value Function Loss: 0.08374

Mean KL Divergence: 0.00680
SB3 Clip Fraction: 0.06929
Policy Update Magnitude: 0.18231
Value Function Update Magnitude: 0.42483

Collected Steps per Second: 22,982.11164
Overall Steps per Second: 14,859.23612

Timestep Collection Time: 2.17621
Timestep Consumption Time: 1.18964
PPO Batch Consumption Time: 0.09715
Total Iteration Time: 3.36585

Cumulative Model Updates: 55,286
Cumulative Timesteps: 461,276,568

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 461276568...
Checkpoint 461276568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,117.34150
Policy Entropy: 0.80620
Value Function Loss: 0.08895

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.08024
Policy Update Magnitude: 0.16887
Value Function Update Magnitude: 0.41281

Collected Steps per Second: 22,768.45328
Overall Steps per Second: 14,709.92916

Timestep Collection Time: 2.19681
Timestep Consumption Time: 1.20348
PPO Batch Consumption Time: 0.09069
Total Iteration Time: 3.40029

Cumulative Model Updates: 55,292
Cumulative Timesteps: 461,326,586

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,065.45440
Policy Entropy: 0.80037
Value Function Loss: 0.09003

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.08389
Policy Update Magnitude: 0.17542
Value Function Update Magnitude: 0.36505

Collected Steps per Second: 22,535.90590
Overall Steps per Second: 14,756.69585

Timestep Collection Time: 2.21904
Timestep Consumption Time: 1.16980
PPO Batch Consumption Time: 0.08894
Total Iteration Time: 3.38883

Cumulative Model Updates: 55,298
Cumulative Timesteps: 461,376,594

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 461376594...
Checkpoint 461376594 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,562.66664
Policy Entropy: 0.80067
Value Function Loss: 0.09386

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.07986
Policy Update Magnitude: 0.19641
Value Function Update Magnitude: 0.31318

Collected Steps per Second: 20,894.78110
Overall Steps per Second: 13,548.36940

Timestep Collection Time: 2.39438
Timestep Consumption Time: 1.29832
PPO Batch Consumption Time: 0.10354
Total Iteration Time: 3.69270

Cumulative Model Updates: 55,304
Cumulative Timesteps: 461,426,624

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,782.78848
Policy Entropy: 0.80044
Value Function Loss: 0.09487

Mean KL Divergence: 0.00625
SB3 Clip Fraction: 0.06947
Policy Update Magnitude: 0.19387
Value Function Update Magnitude: 0.36760

Collected Steps per Second: 21,447.75706
Overall Steps per Second: 13,770.73814

Timestep Collection Time: 2.33143
Timestep Consumption Time: 1.29975
PPO Batch Consumption Time: 0.10418
Total Iteration Time: 3.63118

Cumulative Model Updates: 55,310
Cumulative Timesteps: 461,476,628

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 461476628...
Checkpoint 461476628 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,824.40803
Policy Entropy: 0.80725
Value Function Loss: 0.09042

Mean KL Divergence: 0.00576
SB3 Clip Fraction: 0.06504
Policy Update Magnitude: 0.18354
Value Function Update Magnitude: 0.40253

Collected Steps per Second: 21,981.45647
Overall Steps per Second: 14,213.78516

Timestep Collection Time: 2.27555
Timestep Consumption Time: 1.24356
PPO Batch Consumption Time: 0.10245
Total Iteration Time: 3.51912

Cumulative Model Updates: 55,316
Cumulative Timesteps: 461,526,648

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,632.37255
Policy Entropy: 0.79885
Value Function Loss: 0.08907

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.08092
Policy Update Magnitude: 0.16728
Value Function Update Magnitude: 0.36532

Collected Steps per Second: 23,150.88198
Overall Steps per Second: 14,740.82953

Timestep Collection Time: 2.16000
Timestep Consumption Time: 1.23234
PPO Batch Consumption Time: 0.10146
Total Iteration Time: 3.39235

Cumulative Model Updates: 55,322
Cumulative Timesteps: 461,576,654

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 461576654...
Checkpoint 461576654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,940.37807
Policy Entropy: 0.79937
Value Function Loss: 0.08821

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.08709
Policy Update Magnitude: 0.16820
Value Function Update Magnitude: 0.33286

Collected Steps per Second: 22,559.14760
Overall Steps per Second: 14,687.01257

Timestep Collection Time: 2.21640
Timestep Consumption Time: 1.18797
PPO Batch Consumption Time: 0.09768
Total Iteration Time: 3.40437

Cumulative Model Updates: 55,328
Cumulative Timesteps: 461,626,654

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,509.88180
Policy Entropy: 0.80355
Value Function Loss: 0.08979

Mean KL Divergence: 0.00701
SB3 Clip Fraction: 0.07168
Policy Update Magnitude: 0.18045
Value Function Update Magnitude: 0.35682

Collected Steps per Second: 22,618.19126
Overall Steps per Second: 14,686.89571

Timestep Collection Time: 2.21202
Timestep Consumption Time: 1.19455
PPO Batch Consumption Time: 0.09548
Total Iteration Time: 3.40657

Cumulative Model Updates: 55,334
Cumulative Timesteps: 461,676,686

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 461676686...
Checkpoint 461676686 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,397.85186
Policy Entropy: 0.80962
Value Function Loss: 0.09767

Mean KL Divergence: 0.00545
SB3 Clip Fraction: 0.06217
Policy Update Magnitude: 0.19108
Value Function Update Magnitude: 0.29748

Collected Steps per Second: 21,442.44925
Overall Steps per Second: 14,067.33868

Timestep Collection Time: 2.33276
Timestep Consumption Time: 1.22300
PPO Batch Consumption Time: 0.09823
Total Iteration Time: 3.55575

Cumulative Model Updates: 55,340
Cumulative Timesteps: 461,726,706

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,963.88658
Policy Entropy: 0.80795
Value Function Loss: 0.09364

Mean KL Divergence: 0.00613
SB3 Clip Fraction: 0.06489
Policy Update Magnitude: 0.18912
Value Function Update Magnitude: 0.26732

Collected Steps per Second: 23,471.91128
Overall Steps per Second: 14,911.48719

Timestep Collection Time: 2.13089
Timestep Consumption Time: 1.22331
PPO Batch Consumption Time: 0.10153
Total Iteration Time: 3.35419

Cumulative Model Updates: 55,346
Cumulative Timesteps: 461,776,722

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 461776722...
Checkpoint 461776722 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,854.35365
Policy Entropy: 0.80327
Value Function Loss: 0.09264

Mean KL Divergence: 0.00783
SB3 Clip Fraction: 0.07689
Policy Update Magnitude: 0.18776
Value Function Update Magnitude: 0.31105

Collected Steps per Second: 23,152.75242
Overall Steps per Second: 14,972.21266

Timestep Collection Time: 2.15983
Timestep Consumption Time: 1.18009
PPO Batch Consumption Time: 0.09895
Total Iteration Time: 3.33992

Cumulative Model Updates: 55,352
Cumulative Timesteps: 461,826,728

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,460.42236
Policy Entropy: 0.80398
Value Function Loss: 0.09396

Mean KL Divergence: 0.00655
SB3 Clip Fraction: 0.07049
Policy Update Magnitude: 0.18531
Value Function Update Magnitude: 0.36531

Collected Steps per Second: 23,370.19411
Overall Steps per Second: 14,764.33616

Timestep Collection Time: 2.14033
Timestep Consumption Time: 1.24756
PPO Batch Consumption Time: 0.09890
Total Iteration Time: 3.38789

Cumulative Model Updates: 55,358
Cumulative Timesteps: 461,876,748

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 461876748...
Checkpoint 461876748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,145.48406
Policy Entropy: 0.81222
Value Function Loss: 0.09945

Mean KL Divergence: 0.00579
SB3 Clip Fraction: 0.06216
Policy Update Magnitude: 0.20138
Value Function Update Magnitude: 0.36756

Collected Steps per Second: 23,355.34758
Overall Steps per Second: 14,869.76382

Timestep Collection Time: 2.14178
Timestep Consumption Time: 1.22223
PPO Batch Consumption Time: 0.09875
Total Iteration Time: 3.36401

Cumulative Model Updates: 55,364
Cumulative Timesteps: 461,926,770

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,527.80612
Policy Entropy: 0.80057
Value Function Loss: 0.10022

Mean KL Divergence: 0.00711
SB3 Clip Fraction: 0.07433
Policy Update Magnitude: 0.19709
Value Function Update Magnitude: 0.32676

Collected Steps per Second: 22,996.91998
Overall Steps per Second: 14,786.10961

Timestep Collection Time: 2.17420
Timestep Consumption Time: 1.20735
PPO Batch Consumption Time: 0.09901
Total Iteration Time: 3.38155

Cumulative Model Updates: 55,370
Cumulative Timesteps: 461,976,770

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 461976770...
Checkpoint 461976770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,875.41947
Policy Entropy: 0.79264
Value Function Loss: 0.10266

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.08305
Policy Update Magnitude: 0.17789
Value Function Update Magnitude: 0.27414

Collected Steps per Second: 22,902.48145
Overall Steps per Second: 14,562.91944

Timestep Collection Time: 2.18465
Timestep Consumption Time: 1.25106
PPO Batch Consumption Time: 0.10232
Total Iteration Time: 3.43571

Cumulative Model Updates: 55,376
Cumulative Timesteps: 462,026,804

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,426.17140
Policy Entropy: 0.78647
Value Function Loss: 0.09100

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.08160
Policy Update Magnitude: 0.16927
Value Function Update Magnitude: 0.32673

Collected Steps per Second: 23,618.96463
Overall Steps per Second: 14,978.09975

Timestep Collection Time: 2.11703
Timestep Consumption Time: 1.22131
PPO Batch Consumption Time: 0.10065
Total Iteration Time: 3.33834

Cumulative Model Updates: 55,382
Cumulative Timesteps: 462,076,806

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 462076806...
Checkpoint 462076806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,923.95656
Policy Entropy: 0.79251
Value Function Loss: 0.08774

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.07843
Policy Update Magnitude: 0.17435
Value Function Update Magnitude: 0.40259

Collected Steps per Second: 22,832.45216
Overall Steps per Second: 14,683.91186

Timestep Collection Time: 2.19039
Timestep Consumption Time: 1.21551
PPO Batch Consumption Time: 0.10086
Total Iteration Time: 3.40590

Cumulative Model Updates: 55,388
Cumulative Timesteps: 462,126,818

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,187.22997
Policy Entropy: 0.79166
Value Function Loss: 0.08292

Mean KL Divergence: 0.00614
SB3 Clip Fraction: 0.06711
Policy Update Magnitude: 0.17542
Value Function Update Magnitude: 0.41054

Collected Steps per Second: 23,663.96116
Overall Steps per Second: 15,039.56288

Timestep Collection Time: 2.11393
Timestep Consumption Time: 1.21223
PPO Batch Consumption Time: 0.10039
Total Iteration Time: 3.32616

Cumulative Model Updates: 55,394
Cumulative Timesteps: 462,176,842

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 462176842...
Checkpoint 462176842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,995.82077
Policy Entropy: 0.78921
Value Function Loss: 0.08399

Mean KL Divergence: 0.00564
SB3 Clip Fraction: 0.06452
Policy Update Magnitude: 0.18001
Value Function Update Magnitude: 0.40540

Collected Steps per Second: 23,337.98032
Overall Steps per Second: 14,894.26740

Timestep Collection Time: 2.14440
Timestep Consumption Time: 1.21568
PPO Batch Consumption Time: 0.09939
Total Iteration Time: 3.36008

Cumulative Model Updates: 55,400
Cumulative Timesteps: 462,226,888

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,802.41222
Policy Entropy: 0.78257
Value Function Loss: 0.08412

Mean KL Divergence: 0.00450
SB3 Clip Fraction: 0.05392
Policy Update Magnitude: 0.18543
Value Function Update Magnitude: 0.38054

Collected Steps per Second: 23,282.37466
Overall Steps per Second: 15,124.83962

Timestep Collection Time: 2.14918
Timestep Consumption Time: 1.15915
PPO Batch Consumption Time: 0.09444
Total Iteration Time: 3.30833

Cumulative Model Updates: 55,406
Cumulative Timesteps: 462,276,926

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 462276926...
Checkpoint 462276926 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,291.18857
Policy Entropy: 0.79088
Value Function Loss: 0.08597

Mean KL Divergence: 0.00426
SB3 Clip Fraction: 0.05124
Policy Update Magnitude: 0.18600
Value Function Update Magnitude: 0.38394

Collected Steps per Second: 23,268.34537
Overall Steps per Second: 14,917.03973

Timestep Collection Time: 2.15013
Timestep Consumption Time: 1.20375
PPO Batch Consumption Time: 0.09858
Total Iteration Time: 3.35388

Cumulative Model Updates: 55,412
Cumulative Timesteps: 462,326,956

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,225.18559
Policy Entropy: 0.79918
Value Function Loss: 0.08709

Mean KL Divergence: 0.00522
SB3 Clip Fraction: 0.06065
Policy Update Magnitude: 0.18051
Value Function Update Magnitude: 0.40504

Collected Steps per Second: 23,531.07480
Overall Steps per Second: 14,899.13024

Timestep Collection Time: 2.12510
Timestep Consumption Time: 1.23120
PPO Batch Consumption Time: 0.10177
Total Iteration Time: 3.35630

Cumulative Model Updates: 55,418
Cumulative Timesteps: 462,376,962

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 462376962...
Checkpoint 462376962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,342.64445
Policy Entropy: 0.79592
Value Function Loss: 0.08583

Mean KL Divergence: 0.00465
SB3 Clip Fraction: 0.05477
Policy Update Magnitude: 0.17760
Value Function Update Magnitude: 0.43038

Collected Steps per Second: 22,339.05466
Overall Steps per Second: 14,573.80098

Timestep Collection Time: 2.23859
Timestep Consumption Time: 1.19277
PPO Batch Consumption Time: 0.08960
Total Iteration Time: 3.43136

Cumulative Model Updates: 55,424
Cumulative Timesteps: 462,426,970

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,582.65200
Policy Entropy: 0.79293
Value Function Loss: 0.08337

Mean KL Divergence: 0.00462
SB3 Clip Fraction: 0.05468
Policy Update Magnitude: 0.17737
Value Function Update Magnitude: 0.43065

Collected Steps per Second: 23,527.48250
Overall Steps per Second: 14,939.00439

Timestep Collection Time: 2.12577
Timestep Consumption Time: 1.22211
PPO Batch Consumption Time: 0.10110
Total Iteration Time: 3.34788

Cumulative Model Updates: 55,430
Cumulative Timesteps: 462,476,984

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 462476984...
Checkpoint 462476984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,821.63139
Policy Entropy: 0.78261
Value Function Loss: 0.08093

Mean KL Divergence: 0.00421
SB3 Clip Fraction: 0.05008
Policy Update Magnitude: 0.17766
Value Function Update Magnitude: 0.42490

Collected Steps per Second: 22,924.58295
Overall Steps per Second: 14,814.95743

Timestep Collection Time: 2.18176
Timestep Consumption Time: 1.19428
PPO Batch Consumption Time: 0.09836
Total Iteration Time: 3.37605

Cumulative Model Updates: 55,436
Cumulative Timesteps: 462,527,000

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,451.16238
Policy Entropy: 0.78182
Value Function Loss: 0.07605

Mean KL Divergence: 0.00608
SB3 Clip Fraction: 0.06385
Policy Update Magnitude: 0.18162
Value Function Update Magnitude: 0.41993

Collected Steps per Second: 23,691.16895
Overall Steps per Second: 15,046.23638

Timestep Collection Time: 2.11243
Timestep Consumption Time: 1.21371
PPO Batch Consumption Time: 0.10012
Total Iteration Time: 3.32615

Cumulative Model Updates: 55,442
Cumulative Timesteps: 462,577,046

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 462577046...
Checkpoint 462577046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,817.97594
Policy Entropy: 0.76813
Value Function Loss: 0.08010

Mean KL Divergence: 0.00635
SB3 Clip Fraction: 0.06590
Policy Update Magnitude: 0.17764
Value Function Update Magnitude: 0.42902

Collected Steps per Second: 22,534.54105
Overall Steps per Second: 14,592.67206

Timestep Collection Time: 2.21917
Timestep Consumption Time: 1.20775
PPO Batch Consumption Time: 0.10004
Total Iteration Time: 3.42693

Cumulative Model Updates: 55,448
Cumulative Timesteps: 462,627,054

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,594.17127
Policy Entropy: 0.77091
Value Function Loss: 0.07087

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.07210
Policy Update Magnitude: 0.16390
Value Function Update Magnitude: 0.43419

Collected Steps per Second: 23,100.63355
Overall Steps per Second: 14,889.28438

Timestep Collection Time: 2.16600
Timestep Consumption Time: 1.19454
PPO Batch Consumption Time: 0.09999
Total Iteration Time: 3.36054

Cumulative Model Updates: 55,454
Cumulative Timesteps: 462,677,090

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 462677090...
Checkpoint 462677090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,331.37258
Policy Entropy: 0.77886
Value Function Loss: 0.08363

Mean KL Divergence: 0.00496
SB3 Clip Fraction: 0.05422
Policy Update Magnitude: 0.17140
Value Function Update Magnitude: 0.41607

Collected Steps per Second: 23,460.09041
Overall Steps per Second: 14,505.49871

Timestep Collection Time: 2.13247
Timestep Consumption Time: 1.31643
PPO Batch Consumption Time: 0.09225
Total Iteration Time: 3.44890

Cumulative Model Updates: 55,460
Cumulative Timesteps: 462,727,118

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,646.80212
Policy Entropy: 0.78665
Value Function Loss: 0.08007

Mean KL Divergence: 0.00479
SB3 Clip Fraction: 0.05513
Policy Update Magnitude: 0.18326
Value Function Update Magnitude: 0.39395

Collected Steps per Second: 21,869.46233
Overall Steps per Second: 14,016.35082

Timestep Collection Time: 2.28831
Timestep Consumption Time: 1.28210
PPO Batch Consumption Time: 0.09940
Total Iteration Time: 3.57040

Cumulative Model Updates: 55,466
Cumulative Timesteps: 462,777,162

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 462777162...
Checkpoint 462777162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,108.07876
Policy Entropy: 0.78774
Value Function Loss: 0.09166

Mean KL Divergence: 0.00401
SB3 Clip Fraction: 0.04878
Policy Update Magnitude: 0.19305
Value Function Update Magnitude: 0.39860

Collected Steps per Second: 21,868.62750
Overall Steps per Second: 14,218.57088

Timestep Collection Time: 2.28830
Timestep Consumption Time: 1.23118
PPO Batch Consumption Time: 0.10176
Total Iteration Time: 3.51948

Cumulative Model Updates: 55,472
Cumulative Timesteps: 462,827,204

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,287.91679
Policy Entropy: 0.78233
Value Function Loss: 0.08583

Mean KL Divergence: 0.00404
SB3 Clip Fraction: 0.04893
Policy Update Magnitude: 0.20158
Value Function Update Magnitude: 0.37678

Collected Steps per Second: 23,945.96072
Overall Steps per Second: 15,404.47252

Timestep Collection Time: 2.08987
Timestep Consumption Time: 1.15879
PPO Batch Consumption Time: 0.09164
Total Iteration Time: 3.24867

Cumulative Model Updates: 55,478
Cumulative Timesteps: 462,877,248

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 462877248...
Checkpoint 462877248 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,636.82277
Policy Entropy: 0.77557
Value Function Loss: 0.09261

Mean KL Divergence: 0.00418
SB3 Clip Fraction: 0.04927
Policy Update Magnitude: 0.20260
Value Function Update Magnitude: 0.36159

Collected Steps per Second: 23,225.84337
Overall Steps per Second: 14,906.99953

Timestep Collection Time: 2.15312
Timestep Consumption Time: 1.20155
PPO Batch Consumption Time: 0.09501
Total Iteration Time: 3.35467

Cumulative Model Updates: 55,484
Cumulative Timesteps: 462,927,256

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,226.58291
Policy Entropy: 0.78785
Value Function Loss: 0.09140

Mean KL Divergence: 0.00466
SB3 Clip Fraction: 0.05475
Policy Update Magnitude: 0.19494
Value Function Update Magnitude: 0.32819

Collected Steps per Second: 23,275.97041
Overall Steps per Second: 14,833.11148

Timestep Collection Time: 2.14831
Timestep Consumption Time: 1.22280
PPO Batch Consumption Time: 0.09986
Total Iteration Time: 3.37111

Cumulative Model Updates: 55,490
Cumulative Timesteps: 462,977,260

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 462977260...
Checkpoint 462977260 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,925.92416
Policy Entropy: 0.78764
Value Function Loss: 0.08643

Mean KL Divergence: 0.00469
SB3 Clip Fraction: 0.05505
Policy Update Magnitude: 0.19417
Value Function Update Magnitude: 0.34021

Collected Steps per Second: 23,565.92763
Overall Steps per Second: 14,867.80561

Timestep Collection Time: 2.12323
Timestep Consumption Time: 1.24216
PPO Batch Consumption Time: 0.10220
Total Iteration Time: 3.36539

Cumulative Model Updates: 55,496
Cumulative Timesteps: 463,027,296

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,129.04315
Policy Entropy: 0.79064
Value Function Loss: 0.08539

Mean KL Divergence: 0.00417
SB3 Clip Fraction: 0.04996
Policy Update Magnitude: 0.18884
Value Function Update Magnitude: 0.30908

Collected Steps per Second: 23,513.81314
Overall Steps per Second: 14,906.62342

Timestep Collection Time: 2.12794
Timestep Consumption Time: 1.22869
PPO Batch Consumption Time: 0.10070
Total Iteration Time: 3.35663

Cumulative Model Updates: 55,502
Cumulative Timesteps: 463,077,332

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 463077332...
Checkpoint 463077332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,551.59064
Policy Entropy: 0.77799
Value Function Loss: 0.09004

Mean KL Divergence: 0.00391
SB3 Clip Fraction: 0.04699
Policy Update Magnitude: 0.18967
Value Function Update Magnitude: 0.32101

Collected Steps per Second: 22,752.10396
Overall Steps per Second: 14,650.70016

Timestep Collection Time: 2.19848
Timestep Consumption Time: 1.21569
PPO Batch Consumption Time: 0.09861
Total Iteration Time: 3.41417

Cumulative Model Updates: 55,508
Cumulative Timesteps: 463,127,352

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,288.15295
Policy Entropy: 0.78073
Value Function Loss: 0.09588

Mean KL Divergence: 0.00665
SB3 Clip Fraction: 0.06649
Policy Update Magnitude: 0.18812
Value Function Update Magnitude: 0.37068

Collected Steps per Second: 23,821.19039
Overall Steps per Second: 14,939.10270

Timestep Collection Time: 2.09981
Timestep Consumption Time: 1.24845
PPO Batch Consumption Time: 0.10156
Total Iteration Time: 3.34826

Cumulative Model Updates: 55,514
Cumulative Timesteps: 463,177,372

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 463177372...
Checkpoint 463177372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,684.56324
Policy Entropy: 0.77772
Value Function Loss: 0.08177

Mean KL Divergence: 0.01232
SB3 Clip Fraction: 0.09614
Policy Update Magnitude: 0.17026
Value Function Update Magnitude: 0.40017

Collected Steps per Second: 13,069.86338
Overall Steps per Second: 9,171.64958

Timestep Collection Time: 3.82820
Timestep Consumption Time: 1.62709
PPO Batch Consumption Time: 0.09018
Total Iteration Time: 5.45529

Cumulative Model Updates: 55,520
Cumulative Timesteps: 463,227,406

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,052.24406
Policy Entropy: 0.77391
Value Function Loss: 0.08427

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.07536
Policy Update Magnitude: 0.17790
Value Function Update Magnitude: 0.37864

Collected Steps per Second: 14,021.83320
Overall Steps per Second: 10,522.67684

Timestep Collection Time: 3.56772
Timestep Consumption Time: 1.18639
PPO Batch Consumption Time: 0.08101
Total Iteration Time: 4.75411

Cumulative Model Updates: 55,526
Cumulative Timesteps: 463,277,432

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 463277432...
Checkpoint 463277432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,380.91256
Policy Entropy: 0.75898
Value Function Loss: 0.07953

Mean KL Divergence: 0.00724
SB3 Clip Fraction: 0.07225
Policy Update Magnitude: 0.18915
Value Function Update Magnitude: 0.37523

Collected Steps per Second: 20,874.07442
Overall Steps per Second: 13,934.63990

Timestep Collection Time: 2.39541
Timestep Consumption Time: 1.19291
PPO Batch Consumption Time: 0.09200
Total Iteration Time: 3.58832

Cumulative Model Updates: 55,532
Cumulative Timesteps: 463,327,434

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,100.45476
Policy Entropy: 0.76928
Value Function Loss: 0.08885

Mean KL Divergence: 0.00537
SB3 Clip Fraction: 0.05966
Policy Update Magnitude: 0.20165
Value Function Update Magnitude: 0.38172

Collected Steps per Second: 22,754.68761
Overall Steps per Second: 14,713.76531

Timestep Collection Time: 2.19788
Timestep Consumption Time: 1.20112
PPO Batch Consumption Time: 0.09199
Total Iteration Time: 3.39899

Cumulative Model Updates: 55,538
Cumulative Timesteps: 463,377,446

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 463377446...
Checkpoint 463377446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,409.65505
Policy Entropy: 0.76721
Value Function Loss: 0.09241

Mean KL Divergence: 0.00752
SB3 Clip Fraction: 0.07881
Policy Update Magnitude: 0.19623
Value Function Update Magnitude: 0.38857

Collected Steps per Second: 22,503.51719
Overall Steps per Second: 14,478.64670

Timestep Collection Time: 2.22259
Timestep Consumption Time: 1.23188
PPO Batch Consumption Time: 0.10038
Total Iteration Time: 3.45447

Cumulative Model Updates: 55,544
Cumulative Timesteps: 463,427,462

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,503.86526
Policy Entropy: 0.76721
Value Function Loss: 0.08922

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.08322
Policy Update Magnitude: 0.17440
Value Function Update Magnitude: 0.39201

Collected Steps per Second: 22,331.43385
Overall Steps per Second: 14,490.32261

Timestep Collection Time: 2.23900
Timestep Consumption Time: 1.21158
PPO Batch Consumption Time: 0.10199
Total Iteration Time: 3.45058

Cumulative Model Updates: 55,550
Cumulative Timesteps: 463,477,462

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 463477462...
Checkpoint 463477462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,019.71983
Policy Entropy: 0.76455
Value Function Loss: 0.09064

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.07982
Policy Update Magnitude: 0.18013
Value Function Update Magnitude: 0.37512

Collected Steps per Second: 23,059.31851
Overall Steps per Second: 14,800.01526

Timestep Collection Time: 2.16858
Timestep Consumption Time: 1.21020
PPO Batch Consumption Time: 0.09951
Total Iteration Time: 3.37878

Cumulative Model Updates: 55,556
Cumulative Timesteps: 463,527,468

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,604.16709
Policy Entropy: 0.75484
Value Function Loss: 0.08311

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.07746
Policy Update Magnitude: 0.18392
Value Function Update Magnitude: 0.36965

Collected Steps per Second: 23,131.20579
Overall Steps per Second: 14,757.26512

Timestep Collection Time: 2.16201
Timestep Consumption Time: 1.22682
PPO Batch Consumption Time: 0.09942
Total Iteration Time: 3.38884

Cumulative Model Updates: 55,562
Cumulative Timesteps: 463,577,478

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 463577478...
Checkpoint 463577478 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,885.10368
Policy Entropy: 0.76382
Value Function Loss: 0.08385

Mean KL Divergence: 0.00644
SB3 Clip Fraction: 0.06621
Policy Update Magnitude: 0.18925
Value Function Update Magnitude: 0.40058

Collected Steps per Second: 22,248.66389
Overall Steps per Second: 14,392.35118

Timestep Collection Time: 2.24814
Timestep Consumption Time: 1.22718
PPO Batch Consumption Time: 0.10142
Total Iteration Time: 3.47532

Cumulative Model Updates: 55,568
Cumulative Timesteps: 463,627,496

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,825.83420
Policy Entropy: 0.76494
Value Function Loss: 0.07422

Mean KL Divergence: 0.00467
SB3 Clip Fraction: 0.05405
Policy Update Magnitude: 0.19307
Value Function Update Magnitude: 0.41310

Collected Steps per Second: 22,915.33903
Overall Steps per Second: 14,611.64584

Timestep Collection Time: 2.18308
Timestep Consumption Time: 1.24063
PPO Batch Consumption Time: 0.10048
Total Iteration Time: 3.42371

Cumulative Model Updates: 55,574
Cumulative Timesteps: 463,677,522

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 463677522...
Checkpoint 463677522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,621.95957
Policy Entropy: 0.77293
Value Function Loss: 0.08184

Mean KL Divergence: 0.00529
SB3 Clip Fraction: 0.06178
Policy Update Magnitude: 0.19462
Value Function Update Magnitude: 0.42099

Collected Steps per Second: 22,179.13899
Overall Steps per Second: 14,567.10875

Timestep Collection Time: 2.25455
Timestep Consumption Time: 1.17811
PPO Batch Consumption Time: 0.09699
Total Iteration Time: 3.43266

Cumulative Model Updates: 55,580
Cumulative Timesteps: 463,727,526

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,502.98933
Policy Entropy: 0.76357
Value Function Loss: 0.08481

Mean KL Divergence: 0.00536
SB3 Clip Fraction: 0.05969
Policy Update Magnitude: 0.19400
Value Function Update Magnitude: 0.44477

Collected Steps per Second: 22,713.65603
Overall Steps per Second: 14,691.13392

Timestep Collection Time: 2.20334
Timestep Consumption Time: 1.20320
PPO Batch Consumption Time: 0.09566
Total Iteration Time: 3.40654

Cumulative Model Updates: 55,586
Cumulative Timesteps: 463,777,572

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 463777572...
Checkpoint 463777572 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,333.04491
Policy Entropy: 0.76151
Value Function Loss: 0.09406

Mean KL Divergence: 0.00422
SB3 Clip Fraction: 0.04832
Policy Update Magnitude: 0.19768
Value Function Update Magnitude: 0.45329

Collected Steps per Second: 22,639.50638
Overall Steps per Second: 14,820.36970

Timestep Collection Time: 2.20871
Timestep Consumption Time: 1.16530
PPO Batch Consumption Time: 0.09391
Total Iteration Time: 3.37400

Cumulative Model Updates: 55,592
Cumulative Timesteps: 463,827,576

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,303.82499
Policy Entropy: 0.76399
Value Function Loss: 0.09342

Mean KL Divergence: 0.00376
SB3 Clip Fraction: 0.04580
Policy Update Magnitude: 0.19820
Value Function Update Magnitude: 0.46733

Collected Steps per Second: 22,581.42679
Overall Steps per Second: 14,748.66823

Timestep Collection Time: 2.21580
Timestep Consumption Time: 1.17677
PPO Batch Consumption Time: 0.09351
Total Iteration Time: 3.39258

Cumulative Model Updates: 55,598
Cumulative Timesteps: 463,877,612

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 463877612...
Checkpoint 463877612 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,529.14981
Policy Entropy: 0.77051
Value Function Loss: 0.09213

Mean KL Divergence: 0.00431
SB3 Clip Fraction: 0.04987
Policy Update Magnitude: 0.20009
Value Function Update Magnitude: 0.45318

Collected Steps per Second: 22,216.68234
Overall Steps per Second: 14,232.03110

Timestep Collection Time: 2.25155
Timestep Consumption Time: 1.26320
PPO Batch Consumption Time: 0.10288
Total Iteration Time: 3.51475

Cumulative Model Updates: 55,604
Cumulative Timesteps: 463,927,634

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,794.62423
Policy Entropy: 0.77244
Value Function Loss: 0.09764

Mean KL Divergence: 0.00328
SB3 Clip Fraction: 0.03962
Policy Update Magnitude: 0.20009
Value Function Update Magnitude: 0.43824

Collected Steps per Second: 23,270.54909
Overall Steps per Second: 14,878.44231

Timestep Collection Time: 2.14958
Timestep Consumption Time: 1.21246
PPO Batch Consumption Time: 0.10131
Total Iteration Time: 3.36205

Cumulative Model Updates: 55,610
Cumulative Timesteps: 463,977,656

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 463977656...
Checkpoint 463977656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,980.64578
Policy Entropy: 0.76485
Value Function Loss: 0.09858

Mean KL Divergence: 0.00413
SB3 Clip Fraction: 0.05012
Policy Update Magnitude: 0.20528
Value Function Update Magnitude: 0.41149

Collected Steps per Second: 22,213.68863
Overall Steps per Second: 14,510.38785

Timestep Collection Time: 2.25149
Timestep Consumption Time: 1.19528
PPO Batch Consumption Time: 0.09565
Total Iteration Time: 3.44677

Cumulative Model Updates: 55,616
Cumulative Timesteps: 464,027,670

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,761.09542
Policy Entropy: 0.76117
Value Function Loss: 0.09486

Mean KL Divergence: 0.00501
SB3 Clip Fraction: 0.05830
Policy Update Magnitude: 0.20165
Value Function Update Magnitude: 0.37491

Collected Steps per Second: 23,103.15694
Overall Steps per Second: 14,710.34424

Timestep Collection Time: 2.16447
Timestep Consumption Time: 1.23491
PPO Batch Consumption Time: 0.09325
Total Iteration Time: 3.39938

Cumulative Model Updates: 55,622
Cumulative Timesteps: 464,077,676

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 464077676...
Checkpoint 464077676 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,157.33232
Policy Entropy: 0.77289
Value Function Loss: 0.09134

Mean KL Divergence: 0.00492
SB3 Clip Fraction: 0.05653
Policy Update Magnitude: 0.19533
Value Function Update Magnitude: 0.38332

Collected Steps per Second: 22,913.93831
Overall Steps per Second: 14,941.76870

Timestep Collection Time: 2.18347
Timestep Consumption Time: 1.16499
PPO Batch Consumption Time: 0.09694
Total Iteration Time: 3.34847

Cumulative Model Updates: 55,628
Cumulative Timesteps: 464,127,708

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,964.22570
Policy Entropy: 0.76632
Value Function Loss: 0.09019

Mean KL Divergence: 0.00464
SB3 Clip Fraction: 0.05517
Policy Update Magnitude: 0.19684
Value Function Update Magnitude: 0.42751

Collected Steps per Second: 22,479.94558
Overall Steps per Second: 14,694.98479

Timestep Collection Time: 2.22581
Timestep Consumption Time: 1.17917
PPO Batch Consumption Time: 0.09060
Total Iteration Time: 3.40497

Cumulative Model Updates: 55,634
Cumulative Timesteps: 464,177,744

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 464177744...
Checkpoint 464177744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,864.84994
Policy Entropy: 0.76997
Value Function Loss: 0.08499

Mean KL Divergence: 0.00450
SB3 Clip Fraction: 0.05395
Policy Update Magnitude: 0.19970
Value Function Update Magnitude: 0.43848

Collected Steps per Second: 22,570.66949
Overall Steps per Second: 14,376.33039

Timestep Collection Time: 2.21633
Timestep Consumption Time: 1.26328
PPO Batch Consumption Time: 0.10045
Total Iteration Time: 3.47961

Cumulative Model Updates: 55,640
Cumulative Timesteps: 464,227,768

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,153.98334
Policy Entropy: 0.77121
Value Function Loss: 0.08306

Mean KL Divergence: 0.00335
SB3 Clip Fraction: 0.03866
Policy Update Magnitude: 0.19985
Value Function Update Magnitude: 0.40951

Collected Steps per Second: 23,246.96530
Overall Steps per Second: 14,758.53455

Timestep Collection Time: 2.15116
Timestep Consumption Time: 1.23725
PPO Batch Consumption Time: 0.10033
Total Iteration Time: 3.38841

Cumulative Model Updates: 55,646
Cumulative Timesteps: 464,277,776

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 464277776...
Checkpoint 464277776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,336.53506
Policy Entropy: 0.77652
Value Function Loss: 0.07878

Mean KL Divergence: 0.00366
SB3 Clip Fraction: 0.04450
Policy Update Magnitude: 0.19553
Value Function Update Magnitude: 0.40987

Collected Steps per Second: 22,483.51994
Overall Steps per Second: 14,547.67457

Timestep Collection Time: 2.22438
Timestep Consumption Time: 1.21342
PPO Batch Consumption Time: 0.09758
Total Iteration Time: 3.43780

Cumulative Model Updates: 55,652
Cumulative Timesteps: 464,327,788

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,717.05936
Policy Entropy: 0.76988
Value Function Loss: 0.07832

Mean KL Divergence: 0.00322
SB3 Clip Fraction: 0.03825
Policy Update Magnitude: 0.19373
Value Function Update Magnitude: 0.42087

Collected Steps per Second: 23,023.31015
Overall Steps per Second: 14,750.72826

Timestep Collection Time: 2.17267
Timestep Consumption Time: 1.21849
PPO Batch Consumption Time: 0.09840
Total Iteration Time: 3.39115

Cumulative Model Updates: 55,658
Cumulative Timesteps: 464,377,810

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 464377810...
Checkpoint 464377810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,693.40711
Policy Entropy: 0.77488
Value Function Loss: 0.07206

Mean KL Divergence: 0.00410
SB3 Clip Fraction: 0.04927
Policy Update Magnitude: 0.19059
Value Function Update Magnitude: 0.42094

Collected Steps per Second: 22,680.70297
Overall Steps per Second: 14,789.95949

Timestep Collection Time: 2.20593
Timestep Consumption Time: 1.17691
PPO Batch Consumption Time: 0.09390
Total Iteration Time: 3.38284

Cumulative Model Updates: 55,664
Cumulative Timesteps: 464,427,842

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,201.26695
Policy Entropy: 0.77784
Value Function Loss: 0.07859

Mean KL Divergence: 0.00418
SB3 Clip Fraction: 0.05181
Policy Update Magnitude: 0.19079
Value Function Update Magnitude: 0.39596

Collected Steps per Second: 22,509.08817
Overall Steps per Second: 14,721.24801

Timestep Collection Time: 2.22168
Timestep Consumption Time: 1.17531
PPO Batch Consumption Time: 0.09287
Total Iteration Time: 3.39699

Cumulative Model Updates: 55,670
Cumulative Timesteps: 464,477,850

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 464477850...
Checkpoint 464477850 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,496.08448
Policy Entropy: 0.77744
Value Function Loss: 0.07747

Mean KL Divergence: 0.00440
SB3 Clip Fraction: 0.05223
Policy Update Magnitude: 0.19541
Value Function Update Magnitude: 0.39153

Collected Steps per Second: 22,913.39297
Overall Steps per Second: 14,821.93526

Timestep Collection Time: 2.18274
Timestep Consumption Time: 1.19158
PPO Batch Consumption Time: 0.09150
Total Iteration Time: 3.37432

Cumulative Model Updates: 55,676
Cumulative Timesteps: 464,527,864

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,764.90395
Policy Entropy: 0.77653
Value Function Loss: 0.08128

Mean KL Divergence: 0.00441
SB3 Clip Fraction: 0.05003
Policy Update Magnitude: 0.19776
Value Function Update Magnitude: 0.43144

Collected Steps per Second: 22,962.03765
Overall Steps per Second: 14,775.80306

Timestep Collection Time: 2.17777
Timestep Consumption Time: 1.20655
PPO Batch Consumption Time: 0.09427
Total Iteration Time: 3.38432

Cumulative Model Updates: 55,682
Cumulative Timesteps: 464,577,870

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 464577870...
Checkpoint 464577870 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,233.04204
Policy Entropy: 0.77217
Value Function Loss: 0.07852

Mean KL Divergence: 0.00443
SB3 Clip Fraction: 0.05157
Policy Update Magnitude: 0.18919
Value Function Update Magnitude: 0.44336

Collected Steps per Second: 22,266.09006
Overall Steps per Second: 14,365.92274

Timestep Collection Time: 2.24584
Timestep Consumption Time: 1.23504
PPO Batch Consumption Time: 0.10205
Total Iteration Time: 3.48088

Cumulative Model Updates: 55,688
Cumulative Timesteps: 464,627,876

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,928.43901
Policy Entropy: 0.76935
Value Function Loss: 0.08616

Mean KL Divergence: 0.00342
SB3 Clip Fraction: 0.04001
Policy Update Magnitude: 0.19354
Value Function Update Magnitude: 0.45469

Collected Steps per Second: 22,944.75231
Overall Steps per Second: 14,661.36644

Timestep Collection Time: 2.18098
Timestep Consumption Time: 1.23221
PPO Batch Consumption Time: 0.10180
Total Iteration Time: 3.41319

Cumulative Model Updates: 55,694
Cumulative Timesteps: 464,677,918

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 464677918...
Checkpoint 464677918 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,845.14885
Policy Entropy: 0.77341
Value Function Loss: 0.08503

Mean KL Divergence: 0.00342
SB3 Clip Fraction: 0.04178
Policy Update Magnitude: 0.20452
Value Function Update Magnitude: 0.45023

Collected Steps per Second: 22,387.61536
Overall Steps per Second: 14,579.32618

Timestep Collection Time: 2.23374
Timestep Consumption Time: 1.19633
PPO Batch Consumption Time: 0.09350
Total Iteration Time: 3.43006

Cumulative Model Updates: 55,700
Cumulative Timesteps: 464,727,926

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,455.35536
Policy Entropy: 0.78208
Value Function Loss: 0.08421

Mean KL Divergence: 0.00378
SB3 Clip Fraction: 0.04535
Policy Update Magnitude: 0.20568
Value Function Update Magnitude: 0.42423

Collected Steps per Second: 22,677.24969
Overall Steps per Second: 14,743.62996

Timestep Collection Time: 2.20503
Timestep Consumption Time: 1.18654
PPO Batch Consumption Time: 0.09310
Total Iteration Time: 3.39157

Cumulative Model Updates: 55,706
Cumulative Timesteps: 464,777,930

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 464777930...
Checkpoint 464777930 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,372.79452
Policy Entropy: 0.78856
Value Function Loss: 0.07932

Mean KL Divergence: 0.00420
SB3 Clip Fraction: 0.05031
Policy Update Magnitude: 0.20160
Value Function Update Magnitude: 0.37711

Collected Steps per Second: 22,539.38850
Overall Steps per Second: 14,464.12245

Timestep Collection Time: 2.21914
Timestep Consumption Time: 1.23894
PPO Batch Consumption Time: 0.10117
Total Iteration Time: 3.45807

Cumulative Model Updates: 55,712
Cumulative Timesteps: 464,827,948

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,038.42636
Policy Entropy: 0.78909
Value Function Loss: 0.07431

Mean KL Divergence: 0.00359
SB3 Clip Fraction: 0.04329
Policy Update Magnitude: 0.18654
Value Function Update Magnitude: 0.33780

Collected Steps per Second: 22,567.80289
Overall Steps per Second: 14,431.07432

Timestep Collection Time: 2.21652
Timestep Consumption Time: 1.24975
PPO Batch Consumption Time: 0.10064
Total Iteration Time: 3.46627

Cumulative Model Updates: 55,718
Cumulative Timesteps: 464,877,970

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 464877970...
Checkpoint 464877970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,989.43413
Policy Entropy: 0.77744
Value Function Loss: 0.07753

Mean KL Divergence: 0.00396
SB3 Clip Fraction: 0.04747
Policy Update Magnitude: 0.18633
Value Function Update Magnitude: 0.35981

Collected Steps per Second: 22,190.70573
Overall Steps per Second: 14,671.89284

Timestep Collection Time: 2.25392
Timestep Consumption Time: 1.15505
PPO Batch Consumption Time: 0.09250
Total Iteration Time: 3.40897

Cumulative Model Updates: 55,724
Cumulative Timesteps: 464,927,986

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,497.01711
Policy Entropy: 0.77679
Value Function Loss: 0.08075

Mean KL Divergence: 0.00373
SB3 Clip Fraction: 0.04623
Policy Update Magnitude: 0.17969
Value Function Update Magnitude: 0.39311

Collected Steps per Second: 23,032.59102
Overall Steps per Second: 14,737.32269

Timestep Collection Time: 2.17171
Timestep Consumption Time: 1.22240
PPO Batch Consumption Time: 0.09384
Total Iteration Time: 3.39410

Cumulative Model Updates: 55,730
Cumulative Timesteps: 464,978,006

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 464978006...
Checkpoint 464978006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,099.76770
Policy Entropy: 0.77871
Value Function Loss: 0.08179

Mean KL Divergence: 0.00363
SB3 Clip Fraction: 0.04419
Policy Update Magnitude: 0.18231
Value Function Update Magnitude: 0.41327

Collected Steps per Second: 22,053.31834
Overall Steps per Second: 14,211.19850

Timestep Collection Time: 2.26805
Timestep Consumption Time: 1.25157
PPO Batch Consumption Time: 0.10398
Total Iteration Time: 3.51962

Cumulative Model Updates: 55,736
Cumulative Timesteps: 465,028,024

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,747.69096
Policy Entropy: 0.77491
Value Function Loss: 0.08910

Mean KL Divergence: 0.00407
SB3 Clip Fraction: 0.05094
Policy Update Magnitude: 0.18877
Value Function Update Magnitude: 0.41419

Collected Steps per Second: 22,445.69100
Overall Steps per Second: 14,536.50985

Timestep Collection Time: 2.22867
Timestep Consumption Time: 1.21260
PPO Batch Consumption Time: 0.09513
Total Iteration Time: 3.44127

Cumulative Model Updates: 55,742
Cumulative Timesteps: 465,078,048

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 465078048...
Checkpoint 465078048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,892.62139
Policy Entropy: 0.77228
Value Function Loss: 0.09091

Mean KL Divergence: 0.00445
SB3 Clip Fraction: 0.05396
Policy Update Magnitude: 0.18864
Value Function Update Magnitude: 0.44311

Collected Steps per Second: 23,045.25824
Overall Steps per Second: 14,812.03335

Timestep Collection Time: 2.17042
Timestep Consumption Time: 1.20642
PPO Batch Consumption Time: 0.09572
Total Iteration Time: 3.37685

Cumulative Model Updates: 55,748
Cumulative Timesteps: 465,128,066

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,844.49901
Policy Entropy: 0.77389
Value Function Loss: 0.09336

Mean KL Divergence: 0.00441
SB3 Clip Fraction: 0.05274
Policy Update Magnitude: 0.19344
Value Function Update Magnitude: 0.45631

Collected Steps per Second: 22,457.61654
Overall Steps per Second: 14,486.12764

Timestep Collection Time: 2.22651
Timestep Consumption Time: 1.22521
PPO Batch Consumption Time: 0.10171
Total Iteration Time: 3.45172

Cumulative Model Updates: 55,754
Cumulative Timesteps: 465,178,068

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 465178068...
Checkpoint 465178068 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,054.92266
Policy Entropy: 0.77508
Value Function Loss: 0.07837

Mean KL Divergence: 0.00472
SB3 Clip Fraction: 0.05636
Policy Update Magnitude: 0.19505
Value Function Update Magnitude: 0.43661

Collected Steps per Second: 22,783.47972
Overall Steps per Second: 14,481.60082

Timestep Collection Time: 2.19501
Timestep Consumption Time: 1.25834
PPO Batch Consumption Time: 0.10027
Total Iteration Time: 3.45335

Cumulative Model Updates: 55,760
Cumulative Timesteps: 465,228,078

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,284.99412
Policy Entropy: 0.77194
Value Function Loss: 0.07332

Mean KL Divergence: 0.00428
SB3 Clip Fraction: 0.05134
Policy Update Magnitude: 0.18754
Value Function Update Magnitude: 0.40099

Collected Steps per Second: 23,196.71551
Overall Steps per Second: 14,930.27103

Timestep Collection Time: 2.15651
Timestep Consumption Time: 1.19400
PPO Batch Consumption Time: 0.10135
Total Iteration Time: 3.35051

Cumulative Model Updates: 55,766
Cumulative Timesteps: 465,278,102

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 465278102...
Checkpoint 465278102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,312.86858
Policy Entropy: 0.78984
Value Function Loss: 0.07559

Mean KL Divergence: 0.00580
SB3 Clip Fraction: 0.06172
Policy Update Magnitude: 0.18181
Value Function Update Magnitude: 0.35640

Collected Steps per Second: 22,082.69619
Overall Steps per Second: 14,552.31447

Timestep Collection Time: 2.26557
Timestep Consumption Time: 1.17237
PPO Batch Consumption Time: 0.09372
Total Iteration Time: 3.43794

Cumulative Model Updates: 55,772
Cumulative Timesteps: 465,328,132

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,056.98355
Policy Entropy: 0.78003
Value Function Loss: 0.07683

Mean KL Divergence: 0.01752
SB3 Clip Fraction: 0.11769
Policy Update Magnitude: 0.15780
Value Function Update Magnitude: 0.39167

Collected Steps per Second: 22,935.33375
Overall Steps per Second: 14,725.81078

Timestep Collection Time: 2.18013
Timestep Consumption Time: 1.21541
PPO Batch Consumption Time: 0.09391
Total Iteration Time: 3.39553

Cumulative Model Updates: 55,778
Cumulative Timesteps: 465,378,134

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 465378134...
Checkpoint 465378134 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,845.94892
Policy Entropy: 0.78420
Value Function Loss: 0.08010

Mean KL Divergence: 0.01379
SB3 Clip Fraction: 0.10972
Policy Update Magnitude: 0.16229
Value Function Update Magnitude: 0.41517

Collected Steps per Second: 22,774.50648
Overall Steps per Second: 14,841.11085

Timestep Collection Time: 2.19667
Timestep Consumption Time: 1.17424
PPO Batch Consumption Time: 0.09077
Total Iteration Time: 3.37091

Cumulative Model Updates: 55,784
Cumulative Timesteps: 465,428,162

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,671.35163
Policy Entropy: 0.76745
Value Function Loss: 0.07652

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.08629
Policy Update Magnitude: 0.17953
Value Function Update Magnitude: 0.42818

Collected Steps per Second: 22,859.56405
Overall Steps per Second: 14,795.63124

Timestep Collection Time: 2.18736
Timestep Consumption Time: 1.19216
PPO Batch Consumption Time: 0.09415
Total Iteration Time: 3.37951

Cumulative Model Updates: 55,790
Cumulative Timesteps: 465,478,164

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 465478164...
Checkpoint 465478164 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,752.26546
Policy Entropy: 0.75582
Value Function Loss: 0.09082

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.08968
Policy Update Magnitude: 0.18823
Value Function Update Magnitude: 0.39487

Collected Steps per Second: 22,509.24381
Overall Steps per Second: 14,406.92841

Timestep Collection Time: 2.22211
Timestep Consumption Time: 1.24969
PPO Batch Consumption Time: 0.10242
Total Iteration Time: 3.47180

Cumulative Model Updates: 55,796
Cumulative Timesteps: 465,528,182

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,931.93895
Policy Entropy: 0.76202
Value Function Loss: 0.09250

Mean KL Divergence: 0.00694
SB3 Clip Fraction: 0.07735
Policy Update Magnitude: 0.19346
Value Function Update Magnitude: 0.34318

Collected Steps per Second: 23,083.89416
Overall Steps per Second: 14,761.80881

Timestep Collection Time: 2.16653
Timestep Consumption Time: 1.22140
PPO Batch Consumption Time: 0.09944
Total Iteration Time: 3.38793

Cumulative Model Updates: 55,802
Cumulative Timesteps: 465,578,194

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 465578194...
Checkpoint 465578194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,328.90704
Policy Entropy: 0.76051
Value Function Loss: 0.10814

Mean KL Divergence: 0.00499
SB3 Clip Fraction: 0.05880
Policy Update Magnitude: 0.20160
Value Function Update Magnitude: 0.35782

Collected Steps per Second: 22,102.51915
Overall Steps per Second: 14,518.75953

Timestep Collection Time: 2.26273
Timestep Consumption Time: 1.18192
PPO Batch Consumption Time: 0.09980
Total Iteration Time: 3.44465

Cumulative Model Updates: 55,808
Cumulative Timesteps: 465,628,206

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,296.66532
Policy Entropy: 0.76021
Value Function Loss: 0.10406

Mean KL Divergence: 0.00451
SB3 Clip Fraction: 0.05268
Policy Update Magnitude: 0.21003
Value Function Update Magnitude: 0.32768

Collected Steps per Second: 22,868.89282
Overall Steps per Second: 14,698.35298

Timestep Collection Time: 2.18690
Timestep Consumption Time: 1.21566
PPO Batch Consumption Time: 0.09958
Total Iteration Time: 3.40256

Cumulative Model Updates: 55,814
Cumulative Timesteps: 465,678,218

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 465678218...
Checkpoint 465678218 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,673.70437
Policy Entropy: 0.76633
Value Function Loss: 0.09813

Mean KL Divergence: 0.00466
SB3 Clip Fraction: 0.05369
Policy Update Magnitude: 0.20489
Value Function Update Magnitude: 0.33376

Collected Steps per Second: 22,792.34413
Overall Steps per Second: 14,764.06836

Timestep Collection Time: 2.19521
Timestep Consumption Time: 1.19369
PPO Batch Consumption Time: 0.09355
Total Iteration Time: 3.38890

Cumulative Model Updates: 55,820
Cumulative Timesteps: 465,728,252

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,547.74559
Policy Entropy: 0.76724
Value Function Loss: 0.07865

Mean KL Divergence: 0.00365
SB3 Clip Fraction: 0.04269
Policy Update Magnitude: 0.20166
Value Function Update Magnitude: 0.35049

Collected Steps per Second: 22,534.12673
Overall Steps per Second: 14,714.69723

Timestep Collection Time: 2.22019
Timestep Consumption Time: 1.17981
PPO Batch Consumption Time: 0.09176
Total Iteration Time: 3.40000

Cumulative Model Updates: 55,826
Cumulative Timesteps: 465,778,282

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 465778282...
Checkpoint 465778282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,097.71314
Policy Entropy: 0.77870
Value Function Loss: 0.07460

Mean KL Divergence: 0.00356
SB3 Clip Fraction: 0.04402
Policy Update Magnitude: 0.19241
Value Function Update Magnitude: 0.33838

Collected Steps per Second: 22,673.40456
Overall Steps per Second: 14,468.27233

Timestep Collection Time: 2.20593
Timestep Consumption Time: 1.25101
PPO Batch Consumption Time: 0.10104
Total Iteration Time: 3.45694

Cumulative Model Updates: 55,832
Cumulative Timesteps: 465,828,298

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,261.56374
Policy Entropy: 0.77954
Value Function Loss: 0.07859

Mean KL Divergence: 0.00507
SB3 Clip Fraction: 0.05798
Policy Update Magnitude: 0.19007
Value Function Update Magnitude: 0.35249

Collected Steps per Second: 22,281.05148
Overall Steps per Second: 14,462.31133

Timestep Collection Time: 2.24541
Timestep Consumption Time: 1.21393
PPO Batch Consumption Time: 0.09991
Total Iteration Time: 3.45934

Cumulative Model Updates: 55,838
Cumulative Timesteps: 465,878,328

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 465878328...
Checkpoint 465878328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,138.57689
Policy Entropy: 0.77520
Value Function Loss: 0.07733

Mean KL Divergence: 0.00562
SB3 Clip Fraction: 0.06372
Policy Update Magnitude: 0.18717
Value Function Update Magnitude: 0.39859

Collected Steps per Second: 22,554.12957
Overall Steps per Second: 14,696.44307

Timestep Collection Time: 2.21733
Timestep Consumption Time: 1.18553
PPO Batch Consumption Time: 0.09251
Total Iteration Time: 3.40286

Cumulative Model Updates: 55,844
Cumulative Timesteps: 465,928,338

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,909.38909
Policy Entropy: 0.77881
Value Function Loss: 0.07534

Mean KL Divergence: 0.00445
SB3 Clip Fraction: 0.05179
Policy Update Magnitude: 0.18356
Value Function Update Magnitude: 0.41668

Collected Steps per Second: 23,367.07020
Overall Steps per Second: 14,779.00618

Timestep Collection Time: 2.14096
Timestep Consumption Time: 1.24411
PPO Batch Consumption Time: 0.10073
Total Iteration Time: 3.38507

Cumulative Model Updates: 55,850
Cumulative Timesteps: 465,978,366

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 465978366...
Checkpoint 465978366 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,413.30671
Policy Entropy: 0.78069
Value Function Loss: 0.07491

Mean KL Divergence: 0.00464
SB3 Clip Fraction: 0.05493
Policy Update Magnitude: 0.17976
Value Function Update Magnitude: 0.40642

Collected Steps per Second: 20,775.03931
Overall Steps per Second: 13,434.12265

Timestep Collection Time: 2.40741
Timestep Consumption Time: 1.31550
PPO Batch Consumption Time: 0.10698
Total Iteration Time: 3.72291

Cumulative Model Updates: 55,856
Cumulative Timesteps: 466,028,380

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,409.96266
Policy Entropy: 0.78546
Value Function Loss: 0.08517

Mean KL Divergence: 0.00587
SB3 Clip Fraction: 0.06513
Policy Update Magnitude: 0.18008
Value Function Update Magnitude: 0.42541

Collected Steps per Second: 22,018.59258
Overall Steps per Second: 14,533.09082

Timestep Collection Time: 2.27144
Timestep Consumption Time: 1.16994
PPO Batch Consumption Time: 0.09121
Total Iteration Time: 3.44139

Cumulative Model Updates: 55,862
Cumulative Timesteps: 466,078,394

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 466078394...
Checkpoint 466078394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,423.96445
Policy Entropy: 0.79674
Value Function Loss: 0.08055

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.08656
Policy Update Magnitude: 0.16746
Value Function Update Magnitude: 0.45464

Collected Steps per Second: 22,670.97075
Overall Steps per Second: 14,431.52105

Timestep Collection Time: 2.20705
Timestep Consumption Time: 1.26008
PPO Batch Consumption Time: 0.10156
Total Iteration Time: 3.46713

Cumulative Model Updates: 55,868
Cumulative Timesteps: 466,128,430

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,070.63026
Policy Entropy: 0.79168
Value Function Loss: 0.07703

Mean KL Divergence: 0.00634
SB3 Clip Fraction: 0.06982
Policy Update Magnitude: 0.16911
Value Function Update Magnitude: 0.45254

Collected Steps per Second: 23,224.53565
Overall Steps per Second: 14,819.18716

Timestep Collection Time: 2.15358
Timestep Consumption Time: 1.22150
PPO Batch Consumption Time: 0.10030
Total Iteration Time: 3.37508

Cumulative Model Updates: 55,874
Cumulative Timesteps: 466,178,446

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 466178446...
Checkpoint 466178446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,266.91387
Policy Entropy: 0.79008
Value Function Loss: 0.07821

Mean KL Divergence: 0.00759
SB3 Clip Fraction: 0.07644
Policy Update Magnitude: 0.17870
Value Function Update Magnitude: 0.44196

Collected Steps per Second: 22,251.22394
Overall Steps per Second: 14,513.12011

Timestep Collection Time: 2.24761
Timestep Consumption Time: 1.19838
PPO Batch Consumption Time: 0.09725
Total Iteration Time: 3.44599

Cumulative Model Updates: 55,880
Cumulative Timesteps: 466,228,458

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,552.17475
Policy Entropy: 0.77925
Value Function Loss: 0.08044

Mean KL Divergence: 0.00747
SB3 Clip Fraction: 0.07892
Policy Update Magnitude: 0.18002
Value Function Update Magnitude: 0.45057

Collected Steps per Second: 22,963.45103
Overall Steps per Second: 14,801.72917

Timestep Collection Time: 2.17868
Timestep Consumption Time: 1.20133
PPO Batch Consumption Time: 0.10126
Total Iteration Time: 3.38001

Cumulative Model Updates: 55,886
Cumulative Timesteps: 466,278,488

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 466278488...
Checkpoint 466278488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,681.98229
Policy Entropy: 0.77437
Value Function Loss: 0.08721

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.08226
Policy Update Magnitude: 0.18057
Value Function Update Magnitude: 0.44285

Collected Steps per Second: 22,373.18358
Overall Steps per Second: 14,676.20545

Timestep Collection Time: 2.23723
Timestep Consumption Time: 1.17332
PPO Batch Consumption Time: 0.09250
Total Iteration Time: 3.41055

Cumulative Model Updates: 55,892
Cumulative Timesteps: 466,328,542

Timesteps Collected: 50,054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,223.58904
Policy Entropy: 0.76956
Value Function Loss: 0.08227

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.09342
Policy Update Magnitude: 0.17360
Value Function Update Magnitude: 0.43614

Collected Steps per Second: 22,803.24950
Overall Steps per Second: 14,775.20690

Timestep Collection Time: 2.19328
Timestep Consumption Time: 1.19171
PPO Batch Consumption Time: 0.09370
Total Iteration Time: 3.38499

Cumulative Model Updates: 55,898
Cumulative Timesteps: 466,378,556

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 466378556...
Checkpoint 466378556 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,446.92925
Policy Entropy: 0.78259
Value Function Loss: 0.07567

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.08140
Policy Update Magnitude: 0.17714
Value Function Update Magnitude: 0.42898

Collected Steps per Second: 22,636.20280
Overall Steps per Second: 14,474.16768

Timestep Collection Time: 2.21026
Timestep Consumption Time: 1.24638
PPO Batch Consumption Time: 0.10099
Total Iteration Time: 3.45664

Cumulative Model Updates: 55,904
Cumulative Timesteps: 466,428,588

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,800.62509
Policy Entropy: 0.79288
Value Function Loss: 0.07156

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.08158
Policy Update Magnitude: 0.17359
Value Function Update Magnitude: 0.40407

Collected Steps per Second: 22,123.20770
Overall Steps per Second: 14,334.57508

Timestep Collection Time: 2.26043
Timestep Consumption Time: 1.22820
PPO Batch Consumption Time: 0.09803
Total Iteration Time: 3.48863

Cumulative Model Updates: 55,910
Cumulative Timesteps: 466,478,596

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 466478596...
Checkpoint 466478596 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,739.59475
Policy Entropy: 0.79106
Value Function Loss: 0.07279

Mean KL Divergence: 0.00544
SB3 Clip Fraction: 0.06537
Policy Update Magnitude: 0.18164
Value Function Update Magnitude: 0.41016

Collected Steps per Second: 21,826.93355
Overall Steps per Second: 14,123.02590

Timestep Collection Time: 2.29075
Timestep Consumption Time: 1.24957
PPO Batch Consumption Time: 0.10378
Total Iteration Time: 3.54032

Cumulative Model Updates: 55,916
Cumulative Timesteps: 466,528,596

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,882.59352
Policy Entropy: 0.79025
Value Function Loss: 0.07868

Mean KL Divergence: 0.00579
SB3 Clip Fraction: 0.06516
Policy Update Magnitude: 0.18553
Value Function Update Magnitude: 0.42870

Collected Steps per Second: 23,289.48466
Overall Steps per Second: 14,769.81878

Timestep Collection Time: 2.14775
Timestep Consumption Time: 1.23889
PPO Batch Consumption Time: 0.10190
Total Iteration Time: 3.38664

Cumulative Model Updates: 55,922
Cumulative Timesteps: 466,578,616

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 466578616...
Checkpoint 466578616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,656.69825
Policy Entropy: 0.77963
Value Function Loss: 0.08025

Mean KL Divergence: 0.00492
SB3 Clip Fraction: 0.05573
Policy Update Magnitude: 0.18526
Value Function Update Magnitude: 0.43632

Collected Steps per Second: 22,391.69414
Overall Steps per Second: 14,628.47182

Timestep Collection Time: 2.23422
Timestep Consumption Time: 1.18568
PPO Batch Consumption Time: 0.09124
Total Iteration Time: 3.41991

Cumulative Model Updates: 55,928
Cumulative Timesteps: 466,628,644

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,512.77105
Policy Entropy: 0.77982
Value Function Loss: 0.07821

Mean KL Divergence: 0.00385
SB3 Clip Fraction: 0.04555
Policy Update Magnitude: 0.18170
Value Function Update Magnitude: 0.43024

Collected Steps per Second: 23,134.73911
Overall Steps per Second: 14,759.54558

Timestep Collection Time: 2.16168
Timestep Consumption Time: 1.22663
PPO Batch Consumption Time: 0.09228
Total Iteration Time: 3.38832

Cumulative Model Updates: 55,934
Cumulative Timesteps: 466,678,654

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 466678654...
Checkpoint 466678654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,120.27176
Policy Entropy: 0.78943
Value Function Loss: 0.07255

Mean KL Divergence: 0.00450
SB3 Clip Fraction: 0.05312
Policy Update Magnitude: 0.18017
Value Function Update Magnitude: 0.42138

Collected Steps per Second: 22,332.11922
Overall Steps per Second: 14,429.78963

Timestep Collection Time: 2.23973
Timestep Consumption Time: 1.22657
PPO Batch Consumption Time: 0.10091
Total Iteration Time: 3.46630

Cumulative Model Updates: 55,940
Cumulative Timesteps: 466,728,672

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,357.03740
Policy Entropy: 0.78022
Value Function Loss: 0.06885

Mean KL Divergence: 0.00454
SB3 Clip Fraction: 0.05358
Policy Update Magnitude: 0.17789
Value Function Update Magnitude: 0.41254

Collected Steps per Second: 22,629.47026
Overall Steps per Second: 14,566.41803

Timestep Collection Time: 2.21083
Timestep Consumption Time: 1.22378
PPO Batch Consumption Time: 0.10149
Total Iteration Time: 3.43461

Cumulative Model Updates: 55,946
Cumulative Timesteps: 466,778,702

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 466778702...
Checkpoint 466778702 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,056.61951
Policy Entropy: 0.79128
Value Function Loss: 0.06982

Mean KL Divergence: 0.00370
SB3 Clip Fraction: 0.04519
Policy Update Magnitude: 0.17437
Value Function Update Magnitude: 0.40616

Collected Steps per Second: 23,205.97385
Overall Steps per Second: 14,688.09811

Timestep Collection Time: 2.15582
Timestep Consumption Time: 1.25020
PPO Batch Consumption Time: 0.09776
Total Iteration Time: 3.40602

Cumulative Model Updates: 55,952
Cumulative Timesteps: 466,828,730

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,043.73686
Policy Entropy: 0.77760
Value Function Loss: 0.07591

Mean KL Divergence: 0.00449
SB3 Clip Fraction: 0.05168
Policy Update Magnitude: 0.16832
Value Function Update Magnitude: 0.42020

Collected Steps per Second: 23,099.95162
Overall Steps per Second: 14,846.09655

Timestep Collection Time: 2.16537
Timestep Consumption Time: 1.20386
PPO Batch Consumption Time: 0.10058
Total Iteration Time: 3.36924

Cumulative Model Updates: 55,958
Cumulative Timesteps: 466,878,750

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 466878750...
Checkpoint 466878750 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,477.83869
Policy Entropy: 0.77952
Value Function Loss: 0.08188

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.08368
Policy Update Magnitude: 0.14876
Value Function Update Magnitude: 0.43693

Collected Steps per Second: 21,868.31879
Overall Steps per Second: 14,322.19257

Timestep Collection Time: 2.28687
Timestep Consumption Time: 1.20491
PPO Batch Consumption Time: 0.09931
Total Iteration Time: 3.49178

Cumulative Model Updates: 55,964
Cumulative Timesteps: 466,928,760

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,454.83580
Policy Entropy: 0.78082
Value Function Loss: 0.08209

Mean KL Divergence: 0.00538
SB3 Clip Fraction: 0.06184
Policy Update Magnitude: 0.16329
Value Function Update Magnitude: 0.46161

Collected Steps per Second: 22,985.62945
Overall Steps per Second: 14,500.02336

Timestep Collection Time: 2.17553
Timestep Consumption Time: 1.27315
PPO Batch Consumption Time: 0.10176
Total Iteration Time: 3.44868

Cumulative Model Updates: 55,970
Cumulative Timesteps: 466,978,766

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 466978766...
Checkpoint 466978766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,437.87131
Policy Entropy: 0.78828
Value Function Loss: 0.09076

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.08541
Policy Update Magnitude: 0.17047
Value Function Update Magnitude: 0.46559

Collected Steps per Second: 23,055.24453
Overall Steps per Second: 14,784.18828

Timestep Collection Time: 2.16896
Timestep Consumption Time: 1.21343
PPO Batch Consumption Time: 0.10047
Total Iteration Time: 3.38240

Cumulative Model Updates: 55,976
Cumulative Timesteps: 467,028,772

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,452.25998
Policy Entropy: 0.79248
Value Function Loss: 0.09026

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.08129
Policy Update Magnitude: 0.16335
Value Function Update Magnitude: 0.42330

Collected Steps per Second: 22,615.79166
Overall Steps per Second: 14,627.60050

Timestep Collection Time: 2.21173
Timestep Consumption Time: 1.20783
PPO Batch Consumption Time: 0.09474
Total Iteration Time: 3.41956

Cumulative Model Updates: 55,982
Cumulative Timesteps: 467,078,792

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 467078792...
Checkpoint 467078792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,814.37342
Policy Entropy: 0.79666
Value Function Loss: 0.10237

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.08471
Policy Update Magnitude: 0.16736
Value Function Update Magnitude: 0.40326

Collected Steps per Second: 22,631.41801
Overall Steps per Second: 14,439.02962

Timestep Collection Time: 2.21073
Timestep Consumption Time: 1.25432
PPO Batch Consumption Time: 0.10171
Total Iteration Time: 3.46505

Cumulative Model Updates: 55,988
Cumulative Timesteps: 467,128,824

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,629.50453
Policy Entropy: 0.79441
Value Function Loss: 0.08699

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.07320
Policy Update Magnitude: 0.17552
Value Function Update Magnitude: 0.38810

Collected Steps per Second: 23,105.10880
Overall Steps per Second: 14,789.96339

Timestep Collection Time: 2.16506
Timestep Consumption Time: 1.21723
PPO Batch Consumption Time: 0.09924
Total Iteration Time: 3.38229

Cumulative Model Updates: 55,994
Cumulative Timesteps: 467,178,848

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 467178848...
Checkpoint 467178848 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,050.44903
Policy Entropy: 0.80401
Value Function Loss: 0.08941

Mean KL Divergence: 0.00692
SB3 Clip Fraction: 0.06857
Policy Update Magnitude: 0.18220
Value Function Update Magnitude: 0.37908

Collected Steps per Second: 22,443.12383
Overall Steps per Second: 14,619.85398

Timestep Collection Time: 2.22812
Timestep Consumption Time: 1.19230
PPO Batch Consumption Time: 0.10092
Total Iteration Time: 3.42042

Cumulative Model Updates: 56,000
Cumulative Timesteps: 467,228,854

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,503.95304
Policy Entropy: 0.78963
Value Function Loss: 0.07073

Mean KL Divergence: 0.00505
SB3 Clip Fraction: 0.05622
Policy Update Magnitude: 0.17851
Value Function Update Magnitude: 0.40449

Collected Steps per Second: 23,173.58413
Overall Steps per Second: 14,768.35846

Timestep Collection Time: 2.15892
Timestep Consumption Time: 1.22872
PPO Batch Consumption Time: 0.10134
Total Iteration Time: 3.38765

Cumulative Model Updates: 56,006
Cumulative Timesteps: 467,278,884

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 467278884...
Checkpoint 467278884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,724.52883
Policy Entropy: 0.79029
Value Function Loss: 0.07969

Mean KL Divergence: 0.00490
SB3 Clip Fraction: 0.05421
Policy Update Magnitude: 0.17519
Value Function Update Magnitude: 0.43456

Collected Steps per Second: 22,557.11444
Overall Steps per Second: 14,673.03981

Timestep Collection Time: 2.21677
Timestep Consumption Time: 1.19111
PPO Batch Consumption Time: 0.09984
Total Iteration Time: 3.40788

Cumulative Model Updates: 56,012
Cumulative Timesteps: 467,328,888

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,074.59019
Policy Entropy: 0.78968
Value Function Loss: 0.07807

Mean KL Divergence: 0.00502
SB3 Clip Fraction: 0.05769
Policy Update Magnitude: 0.18263
Value Function Update Magnitude: 0.45081

Collected Steps per Second: 22,681.26950
Overall Steps per Second: 14,749.36733

Timestep Collection Time: 2.20587
Timestep Consumption Time: 1.18627
PPO Batch Consumption Time: 0.09901
Total Iteration Time: 3.39215

Cumulative Model Updates: 56,018
Cumulative Timesteps: 467,378,920

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 467378920...
Checkpoint 467378920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,936.18629
Policy Entropy: 0.79657
Value Function Loss: 0.08649

Mean KL Divergence: 0.00545
SB3 Clip Fraction: 0.06291
Policy Update Magnitude: 0.18122
Value Function Update Magnitude: 0.44600

Collected Steps per Second: 23,018.10025
Overall Steps per Second: 14,788.60078

Timestep Collection Time: 2.17359
Timestep Consumption Time: 1.20955
PPO Batch Consumption Time: 0.09767
Total Iteration Time: 3.38315

Cumulative Model Updates: 56,024
Cumulative Timesteps: 467,428,952

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,605.49601
Policy Entropy: 0.80512
Value Function Loss: 0.08477

Mean KL Divergence: 0.00532
SB3 Clip Fraction: 0.05961
Policy Update Magnitude: 0.18254
Value Function Update Magnitude: 0.42675

Collected Steps per Second: 22,964.59136
Overall Steps per Second: 14,784.95681

Timestep Collection Time: 2.17779
Timestep Consumption Time: 1.20484
PPO Batch Consumption Time: 0.09801
Total Iteration Time: 3.38263

Cumulative Model Updates: 56,030
Cumulative Timesteps: 467,478,964

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 467478964...
Checkpoint 467478964 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,970.10832
Policy Entropy: 0.81495
Value Function Loss: 0.07668

Mean KL Divergence: 0.00547
SB3 Clip Fraction: 0.06294
Policy Update Magnitude: 0.17535
Value Function Update Magnitude: 0.41670

Collected Steps per Second: 22,045.43922
Overall Steps per Second: 14,278.11023

Timestep Collection Time: 2.27049
Timestep Consumption Time: 1.23515
PPO Batch Consumption Time: 0.10123
Total Iteration Time: 3.50565

Cumulative Model Updates: 56,036
Cumulative Timesteps: 467,529,018

Timesteps Collected: 50,054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,798.39507
Policy Entropy: 0.81089
Value Function Loss: 0.07985

Mean KL Divergence: 0.00547
SB3 Clip Fraction: 0.06241
Policy Update Magnitude: 0.17434
Value Function Update Magnitude: 0.41514

Collected Steps per Second: 23,244.91354
Overall Steps per Second: 14,817.27528

Timestep Collection Time: 2.15204
Timestep Consumption Time: 1.22402
PPO Batch Consumption Time: 0.09986
Total Iteration Time: 3.37606

Cumulative Model Updates: 56,042
Cumulative Timesteps: 467,579,042

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 467579042...
Checkpoint 467579042 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,545.26023
Policy Entropy: 0.82430
Value Function Loss: 0.07311

Mean KL Divergence: 0.00585
SB3 Clip Fraction: 0.06423
Policy Update Magnitude: 0.17446
Value Function Update Magnitude: 0.41867

Collected Steps per Second: 22,179.79102
Overall Steps per Second: 14,498.90878

Timestep Collection Time: 2.25521
Timestep Consumption Time: 1.19471
PPO Batch Consumption Time: 0.09561
Total Iteration Time: 3.44991

Cumulative Model Updates: 56,048
Cumulative Timesteps: 467,629,062

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,512.15825
Policy Entropy: 0.81310
Value Function Loss: 0.07609

Mean KL Divergence: 0.00668
SB3 Clip Fraction: 0.07392
Policy Update Magnitude: 0.16662
Value Function Update Magnitude: 0.41124

Collected Steps per Second: 22,805.38721
Overall Steps per Second: 14,710.34030

Timestep Collection Time: 2.19360
Timestep Consumption Time: 1.20713
PPO Batch Consumption Time: 0.09513
Total Iteration Time: 3.40074

Cumulative Model Updates: 56,054
Cumulative Timesteps: 467,679,088

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 467679088...
Checkpoint 467679088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,453.70335
Policy Entropy: 0.82424
Value Function Loss: 0.07420

Mean KL Divergence: 0.01241
SB3 Clip Fraction: 0.10459
Policy Update Magnitude: 0.15313
Value Function Update Magnitude: 0.35818

Collected Steps per Second: 22,425.50419
Overall Steps per Second: 14,465.51760

Timestep Collection Time: 2.23059
Timestep Consumption Time: 1.22743
PPO Batch Consumption Time: 0.10142
Total Iteration Time: 3.45802

Cumulative Model Updates: 56,060
Cumulative Timesteps: 467,729,110

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,897.89490
Policy Entropy: 0.80902
Value Function Loss: 0.08033

Mean KL Divergence: 0.01143
SB3 Clip Fraction: 0.09571
Policy Update Magnitude: 0.15213
Value Function Update Magnitude: 0.35508

Collected Steps per Second: 22,767.57847
Overall Steps per Second: 14,637.60468

Timestep Collection Time: 2.19628
Timestep Consumption Time: 1.21985
PPO Batch Consumption Time: 0.10013
Total Iteration Time: 3.41613

Cumulative Model Updates: 56,066
Cumulative Timesteps: 467,779,114

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 467779114...
Checkpoint 467779114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,970.98507
Policy Entropy: 0.81189
Value Function Loss: 0.08985

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.07788
Policy Update Magnitude: 0.15723
Value Function Update Magnitude: 0.39537

Collected Steps per Second: 22,318.19216
Overall Steps per Second: 14,510.79200

Timestep Collection Time: 2.24221
Timestep Consumption Time: 1.20640
PPO Batch Consumption Time: 0.09395
Total Iteration Time: 3.44861

Cumulative Model Updates: 56,072
Cumulative Timesteps: 467,829,156

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,891.58155
Policy Entropy: 0.81028
Value Function Loss: 0.08949

Mean KL Divergence: 0.00596
SB3 Clip Fraction: 0.06628
Policy Update Magnitude: 0.16660
Value Function Update Magnitude: 0.40133

Collected Steps per Second: 23,084.26342
Overall Steps per Second: 14,765.57873

Timestep Collection Time: 2.16684
Timestep Consumption Time: 1.22076
PPO Batch Consumption Time: 0.09628
Total Iteration Time: 3.38761

Cumulative Model Updates: 56,078
Cumulative Timesteps: 467,879,176

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 467879176...
Checkpoint 467879176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,713.51810
Policy Entropy: 0.80744
Value Function Loss: 0.09071

Mean KL Divergence: 0.00710
SB3 Clip Fraction: 0.07376
Policy Update Magnitude: 0.16920
Value Function Update Magnitude: 0.43502

Collected Steps per Second: 21,591.21076
Overall Steps per Second: 14,132.85808

Timestep Collection Time: 2.31631
Timestep Consumption Time: 1.22239
PPO Batch Consumption Time: 0.10342
Total Iteration Time: 3.53870

Cumulative Model Updates: 56,084
Cumulative Timesteps: 467,929,188

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,827.04189
Policy Entropy: 0.80420
Value Function Loss: 0.08368

Mean KL Divergence: 0.00689
SB3 Clip Fraction: 0.07583
Policy Update Magnitude: 0.17060
Value Function Update Magnitude: 0.45655

Collected Steps per Second: 23,027.60821
Overall Steps per Second: 14,648.76123

Timestep Collection Time: 2.17131
Timestep Consumption Time: 1.24195
PPO Batch Consumption Time: 0.10066
Total Iteration Time: 3.41326

Cumulative Model Updates: 56,090
Cumulative Timesteps: 467,979,188

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 467979188...
Checkpoint 467979188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,814.77391
Policy Entropy: 0.79830
Value Function Loss: 0.09200

Mean KL Divergence: 0.00567
SB3 Clip Fraction: 0.06336
Policy Update Magnitude: 0.17986
Value Function Update Magnitude: 0.46161

Collected Steps per Second: 22,838.72981
Overall Steps per Second: 14,768.16855

Timestep Collection Time: 2.19137
Timestep Consumption Time: 1.19755
PPO Batch Consumption Time: 0.09355
Total Iteration Time: 3.38891

Cumulative Model Updates: 56,096
Cumulative Timesteps: 468,029,236

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,192.96548
Policy Entropy: 0.80775
Value Function Loss: 0.09012

Mean KL Divergence: 0.00424
SB3 Clip Fraction: 0.05034
Policy Update Magnitude: 0.18369
Value Function Update Magnitude: 0.45702

Collected Steps per Second: 22,345.65166
Overall Steps per Second: 14,324.01671

Timestep Collection Time: 2.23757
Timestep Consumption Time: 1.25307
PPO Batch Consumption Time: 0.10117
Total Iteration Time: 3.49064

Cumulative Model Updates: 56,102
Cumulative Timesteps: 468,079,236

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 468079236...
Checkpoint 468079236 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,485.28090
Policy Entropy: 0.81287
Value Function Loss: 0.08817

Mean KL Divergence: 0.00397
SB3 Clip Fraction: 0.04738
Policy Update Magnitude: 0.18539
Value Function Update Magnitude: 0.43134

Collected Steps per Second: 22,491.24116
Overall Steps per Second: 14,436.87281

Timestep Collection Time: 2.22487
Timestep Consumption Time: 1.24126
PPO Batch Consumption Time: 0.09361
Total Iteration Time: 3.46612

Cumulative Model Updates: 56,108
Cumulative Timesteps: 468,129,276

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,510.20925
Policy Entropy: 0.82389
Value Function Loss: 0.08496

Mean KL Divergence: 0.00565
SB3 Clip Fraction: 0.06126
Policy Update Magnitude: 0.18273
Value Function Update Magnitude: 0.41433

Collected Steps per Second: 23,193.47775
Overall Steps per Second: 14,826.21468

Timestep Collection Time: 2.15724
Timestep Consumption Time: 1.21745
PPO Batch Consumption Time: 0.09825
Total Iteration Time: 3.37470

Cumulative Model Updates: 56,114
Cumulative Timesteps: 468,179,310

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 468179310...
Checkpoint 468179310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,457.94974
Policy Entropy: 0.81696
Value Function Loss: 0.07759

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.07699
Policy Update Magnitude: 0.16734
Value Function Update Magnitude: 0.44481

Collected Steps per Second: 22,288.16486
Overall Steps per Second: 14,288.97333

Timestep Collection Time: 2.24451
Timestep Consumption Time: 1.25651
PPO Batch Consumption Time: 0.10203
Total Iteration Time: 3.50102

Cumulative Model Updates: 56,120
Cumulative Timesteps: 468,229,336

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,530.38948
Policy Entropy: 0.80810
Value Function Loss: 0.08295

Mean KL Divergence: 0.00574
SB3 Clip Fraction: 0.06179
Policy Update Magnitude: 0.17069
Value Function Update Magnitude: 0.42722

Collected Steps per Second: 23,393.81520
Overall Steps per Second: 14,600.34020

Timestep Collection Time: 2.13903
Timestep Consumption Time: 1.28829
PPO Batch Consumption Time: 0.10294
Total Iteration Time: 3.42732

Cumulative Model Updates: 56,126
Cumulative Timesteps: 468,279,376

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 468279376...
Checkpoint 468279376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,745.83399
Policy Entropy: 0.80515
Value Function Loss: 0.09093

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.07590
Policy Update Magnitude: 0.18834
Value Function Update Magnitude: 0.39568

Collected Steps per Second: 22,968.65582
Overall Steps per Second: 14,803.51681

Timestep Collection Time: 2.17714
Timestep Consumption Time: 1.20084
PPO Batch Consumption Time: 0.10153
Total Iteration Time: 3.37798

Cumulative Model Updates: 56,132
Cumulative Timesteps: 468,329,382

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,498.05434
Policy Entropy: 0.81184
Value Function Loss: 0.09857

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.09350
Policy Update Magnitude: 0.17778
Value Function Update Magnitude: 0.43070

Collected Steps per Second: 22,503.99969
Overall Steps per Second: 14,664.69050

Timestep Collection Time: 2.22236
Timestep Consumption Time: 1.18801
PPO Batch Consumption Time: 0.09834
Total Iteration Time: 3.41037

Cumulative Model Updates: 56,138
Cumulative Timesteps: 468,379,394

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 468379394...
Checkpoint 468379394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,647.42785
Policy Entropy: 0.81503
Value Function Loss: 0.10583

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.09021
Policy Update Magnitude: 0.17494
Value Function Update Magnitude: 0.44206

Collected Steps per Second: 22,884.43434
Overall Steps per Second: 14,734.49756

Timestep Collection Time: 2.18559
Timestep Consumption Time: 1.20889
PPO Batch Consumption Time: 0.09607
Total Iteration Time: 3.39448

Cumulative Model Updates: 56,144
Cumulative Timesteps: 468,429,410

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,725.54614
Policy Entropy: 0.80949
Value Function Loss: 0.09680

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.08660
Policy Update Magnitude: 0.17890
Value Function Update Magnitude: 0.45553

Collected Steps per Second: 23,025.79296
Overall Steps per Second: 14,793.09358

Timestep Collection Time: 2.17313
Timestep Consumption Time: 1.20940
PPO Batch Consumption Time: 0.09531
Total Iteration Time: 3.38252

Cumulative Model Updates: 56,150
Cumulative Timesteps: 468,479,448

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 468479448...
Checkpoint 468479448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,635.13940
Policy Entropy: 0.80384
Value Function Loss: 0.08991

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.08629
Policy Update Magnitude: 0.18522
Value Function Update Magnitude: 0.47304

Collected Steps per Second: 22,005.88772
Overall Steps per Second: 14,197.27056

Timestep Collection Time: 2.27212
Timestep Consumption Time: 1.24968
PPO Batch Consumption Time: 0.10322
Total Iteration Time: 3.52180

Cumulative Model Updates: 56,156
Cumulative Timesteps: 468,529,448

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,613.05825
Policy Entropy: 0.80952
Value Function Loss: 0.07540

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.09225
Policy Update Magnitude: 0.16611
Value Function Update Magnitude: 0.43706

Collected Steps per Second: 23,435.39124
Overall Steps per Second: 14,760.74227

Timestep Collection Time: 2.13395
Timestep Consumption Time: 1.25409
PPO Batch Consumption Time: 0.10339
Total Iteration Time: 3.38804

Cumulative Model Updates: 56,162
Cumulative Timesteps: 468,579,458

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 468579458...
Checkpoint 468579458 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,489.92269
Policy Entropy: 0.81552
Value Function Loss: 0.07924

Mean KL Divergence: 0.00690
SB3 Clip Fraction: 0.07732
Policy Update Magnitude: 0.16481
Value Function Update Magnitude: 0.41856

Collected Steps per Second: 22,772.84046
Overall Steps per Second: 14,666.27440

Timestep Collection Time: 2.19718
Timestep Consumption Time: 1.21446
PPO Batch Consumption Time: 0.09747
Total Iteration Time: 3.41164

Cumulative Model Updates: 56,168
Cumulative Timesteps: 468,629,494

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,963.60693
Policy Entropy: 0.80983
Value Function Loss: 0.07402

Mean KL Divergence: 0.00605
SB3 Clip Fraction: 0.06701
Policy Update Magnitude: 0.17373
Value Function Update Magnitude: 0.42164

Collected Steps per Second: 21,236.92004
Overall Steps per Second: 13,951.41215

Timestep Collection Time: 2.35543
Timestep Consumption Time: 1.23002
PPO Batch Consumption Time: 0.09875
Total Iteration Time: 3.58544

Cumulative Model Updates: 56,174
Cumulative Timesteps: 468,679,516

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 468679516...
Checkpoint 468679516 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,459.08530
Policy Entropy: 0.80495
Value Function Loss: 0.08371

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.09238
Policy Update Magnitude: 0.17108
Value Function Update Magnitude: 0.41933

Collected Steps per Second: 22,640.58470
Overall Steps per Second: 14,638.74321

Timestep Collection Time: 2.20931
Timestep Consumption Time: 1.20765
PPO Batch Consumption Time: 0.09675
Total Iteration Time: 3.41696

Cumulative Model Updates: 56,180
Cumulative Timesteps: 468,729,536

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,509.45237
Policy Entropy: 0.80689
Value Function Loss: 0.08019

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.08754
Policy Update Magnitude: 0.17049
Value Function Update Magnitude: 0.41154

Collected Steps per Second: 23,077.61813
Overall Steps per Second: 14,771.01953

Timestep Collection Time: 2.16807
Timestep Consumption Time: 1.21923
PPO Batch Consumption Time: 0.09881
Total Iteration Time: 3.38731

Cumulative Model Updates: 56,186
Cumulative Timesteps: 468,779,570

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 468779570...
Checkpoint 468779570 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,893.83706
Policy Entropy: 0.81721
Value Function Loss: 0.08608

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.07888
Policy Update Magnitude: 0.18257
Value Function Update Magnitude: 0.43920

Collected Steps per Second: 22,495.42247
Overall Steps per Second: 14,498.19351

Timestep Collection Time: 2.22374
Timestep Consumption Time: 1.22662
PPO Batch Consumption Time: 0.10127
Total Iteration Time: 3.45036

Cumulative Model Updates: 56,192
Cumulative Timesteps: 468,829,594

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,712.35654
Policy Entropy: 0.82134
Value Function Loss: 0.08243

Mean KL Divergence: 0.00612
SB3 Clip Fraction: 0.06851
Policy Update Magnitude: 0.18533
Value Function Update Magnitude: 0.44412

Collected Steps per Second: 23,473.80283
Overall Steps per Second: 14,851.11071

Timestep Collection Time: 2.13131
Timestep Consumption Time: 1.23746
PPO Batch Consumption Time: 0.10072
Total Iteration Time: 3.36877

Cumulative Model Updates: 56,198
Cumulative Timesteps: 468,879,624

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 468879624...
Checkpoint 468879624 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,808.50280
Policy Entropy: 0.81676
Value Function Loss: 0.08561

Mean KL Divergence: 0.00667
SB3 Clip Fraction: 0.07068
Policy Update Magnitude: 0.18501
Value Function Update Magnitude: 0.42691

Collected Steps per Second: 22,252.50430
Overall Steps per Second: 14,516.35460

Timestep Collection Time: 2.24739
Timestep Consumption Time: 1.19769
PPO Batch Consumption Time: 0.09934
Total Iteration Time: 3.44508

Cumulative Model Updates: 56,204
Cumulative Timesteps: 468,929,634

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,879.12125
Policy Entropy: 0.82384
Value Function Loss: 0.08472

Mean KL Divergence: 0.00517
SB3 Clip Fraction: 0.06073
Policy Update Magnitude: 0.18328
Value Function Update Magnitude: 0.42842

Collected Steps per Second: 22,721.10415
Overall Steps per Second: 14,632.41607

Timestep Collection Time: 2.20104
Timestep Consumption Time: 1.21672
PPO Batch Consumption Time: 0.09607
Total Iteration Time: 3.41775

Cumulative Model Updates: 56,210
Cumulative Timesteps: 468,979,644

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 468979644...
Checkpoint 468979644 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,636.83725
Policy Entropy: 0.81341
Value Function Loss: 0.07506

Mean KL Divergence: 0.00562
SB3 Clip Fraction: 0.06604
Policy Update Magnitude: 0.18871
Value Function Update Magnitude: 0.42917

Collected Steps per Second: 22,919.11604
Overall Steps per Second: 14,816.45913

Timestep Collection Time: 2.18185
Timestep Consumption Time: 1.19318
PPO Batch Consumption Time: 0.09357
Total Iteration Time: 3.37503

Cumulative Model Updates: 56,216
Cumulative Timesteps: 469,029,650

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,826.57734
Policy Entropy: 0.81802
Value Function Loss: 0.06871

Mean KL Divergence: 0.00487
SB3 Clip Fraction: 0.05762
Policy Update Magnitude: 0.18423
Value Function Update Magnitude: 0.42170

Collected Steps per Second: 22,264.79135
Overall Steps per Second: 14,344.35476

Timestep Collection Time: 2.24597
Timestep Consumption Time: 1.24014
PPO Batch Consumption Time: 0.10197
Total Iteration Time: 3.48611

Cumulative Model Updates: 56,222
Cumulative Timesteps: 469,079,656

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 469079656...
Checkpoint 469079656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,477.39780
Policy Entropy: 0.80687
Value Function Loss: 0.07298

Mean KL Divergence: 0.00387
SB3 Clip Fraction: 0.04784
Policy Update Magnitude: 0.19242
Value Function Update Magnitude: 0.40397

Collected Steps per Second: 21,958.59559
Overall Steps per Second: 14,089.28063

Timestep Collection Time: 2.27820
Timestep Consumption Time: 1.27245
PPO Batch Consumption Time: 0.10147
Total Iteration Time: 3.55064

Cumulative Model Updates: 56,228
Cumulative Timesteps: 469,129,682

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,415.34816
Policy Entropy: 0.81601
Value Function Loss: 0.07111

Mean KL Divergence: 0.00355
SB3 Clip Fraction: 0.04239
Policy Update Magnitude: 0.19178
Value Function Update Magnitude: 0.41107

Collected Steps per Second: 22,915.43432
Overall Steps per Second: 14,620.17229

Timestep Collection Time: 2.18316
Timestep Consumption Time: 1.23869
PPO Batch Consumption Time: 0.10099
Total Iteration Time: 3.42185

Cumulative Model Updates: 56,234
Cumulative Timesteps: 469,179,710

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 469179710...
Checkpoint 469179710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,271.72406
Policy Entropy: 0.81696
Value Function Loss: 0.08193

Mean KL Divergence: 0.00367
SB3 Clip Fraction: 0.04272
Policy Update Magnitude: 0.19181
Value Function Update Magnitude: 0.38220

Collected Steps per Second: 22,319.51623
Overall Steps per Second: 14,511.46803

Timestep Collection Time: 2.24109
Timestep Consumption Time: 1.20584
PPO Batch Consumption Time: 0.09608
Total Iteration Time: 3.44693

Cumulative Model Updates: 56,240
Cumulative Timesteps: 469,229,730

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,377.37904
Policy Entropy: 0.82759
Value Function Loss: 0.07461

Mean KL Divergence: 0.00454
SB3 Clip Fraction: 0.05368
Policy Update Magnitude: 0.18153
Value Function Update Magnitude: 0.41029

Collected Steps per Second: 22,702.39452
Overall Steps per Second: 14,327.19653

Timestep Collection Time: 2.20364
Timestep Consumption Time: 1.28818
PPO Batch Consumption Time: 0.10191
Total Iteration Time: 3.49182

Cumulative Model Updates: 56,246
Cumulative Timesteps: 469,279,758

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 469279758...
Checkpoint 469279758 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,923.25187
Policy Entropy: 0.82200
Value Function Loss: 0.07728

Mean KL Divergence: 0.00463
SB3 Clip Fraction: 0.05376
Policy Update Magnitude: 0.18063
Value Function Update Magnitude: 0.41737

Collected Steps per Second: 22,611.81825
Overall Steps per Second: 14,511.78092

Timestep Collection Time: 2.21221
Timestep Consumption Time: 1.23479
PPO Batch Consumption Time: 0.09954
Total Iteration Time: 3.44699

Cumulative Model Updates: 56,252
Cumulative Timesteps: 469,329,780

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,151.84634
Policy Entropy: 0.81775
Value Function Loss: 0.07731

Mean KL Divergence: 0.00523
SB3 Clip Fraction: 0.06109
Policy Update Magnitude: 0.17721
Value Function Update Magnitude: 0.41791

Collected Steps per Second: 22,583.56957
Overall Steps per Second: 14,629.50973

Timestep Collection Time: 2.21462
Timestep Consumption Time: 1.20409
PPO Batch Consumption Time: 0.09448
Total Iteration Time: 3.41871

Cumulative Model Updates: 56,258
Cumulative Timesteps: 469,379,794

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 469379794...
Checkpoint 469379794 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,792.57846
Policy Entropy: 0.82310
Value Function Loss: 0.07940

Mean KL Divergence: 0.00563
SB3 Clip Fraction: 0.06451
Policy Update Magnitude: 0.17386
Value Function Update Magnitude: 0.41054

Collected Steps per Second: 22,672.48261
Overall Steps per Second: 14,411.38278

Timestep Collection Time: 2.20532
Timestep Consumption Time: 1.26416
PPO Batch Consumption Time: 0.10119
Total Iteration Time: 3.46948

Cumulative Model Updates: 56,264
Cumulative Timesteps: 469,429,794

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,311.16928
Policy Entropy: 0.82468
Value Function Loss: 0.08150

Mean KL Divergence: 0.00491
SB3 Clip Fraction: 0.05541
Policy Update Magnitude: 0.17457
Value Function Update Magnitude: 0.39060

Collected Steps per Second: 22,904.38715
Overall Steps per Second: 14,652.14260

Timestep Collection Time: 2.18299
Timestep Consumption Time: 1.22948
PPO Batch Consumption Time: 0.10107
Total Iteration Time: 3.41247

Cumulative Model Updates: 56,270
Cumulative Timesteps: 469,479,794

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 469479794...
Checkpoint 469479794 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,027.03137
Policy Entropy: 0.83612
Value Function Loss: 0.07542

Mean KL Divergence: 0.00357
SB3 Clip Fraction: 0.04379
Policy Update Magnitude: 0.17649
Value Function Update Magnitude: 0.41488

Collected Steps per Second: 22,207.39579
Overall Steps per Second: 14,503.23212

Timestep Collection Time: 2.25303
Timestep Consumption Time: 1.19682
PPO Batch Consumption Time: 0.09155
Total Iteration Time: 3.44985

Cumulative Model Updates: 56,276
Cumulative Timesteps: 469,529,828

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,736.49000
Policy Entropy: 0.84344
Value Function Loss: 0.07691

Mean KL Divergence: 0.00342
SB3 Clip Fraction: 0.04131
Policy Update Magnitude: 0.17900
Value Function Update Magnitude: 0.44158

Collected Steps per Second: 23,190.48809
Overall Steps per Second: 14,761.88992

Timestep Collection Time: 2.15649
Timestep Consumption Time: 1.23129
PPO Batch Consumption Time: 0.09505
Total Iteration Time: 3.38778

Cumulative Model Updates: 56,282
Cumulative Timesteps: 469,579,838

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 469579838...
Checkpoint 469579838 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,217.71856
Policy Entropy: 0.85204
Value Function Loss: 0.07465

Mean KL Divergence: 0.00356
SB3 Clip Fraction: 0.04302
Policy Update Magnitude: 0.18363
Value Function Update Magnitude: 0.42862

Collected Steps per Second: 22,830.89917
Overall Steps per Second: 14,401.74223

Timestep Collection Time: 2.19150
Timestep Consumption Time: 1.28266
PPO Batch Consumption Time: 0.10637
Total Iteration Time: 3.47416

Cumulative Model Updates: 56,288
Cumulative Timesteps: 469,629,872

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,860.72568
Policy Entropy: 0.84879
Value Function Loss: 0.07564

Mean KL Divergence: 0.00335
SB3 Clip Fraction: 0.04066
Policy Update Magnitude: 0.18443
Value Function Update Magnitude: 0.43695

Collected Steps per Second: 22,898.25010
Overall Steps per Second: 14,457.85195

Timestep Collection Time: 2.18384
Timestep Consumption Time: 1.27491
PPO Batch Consumption Time: 0.10633
Total Iteration Time: 3.45874

Cumulative Model Updates: 56,294
Cumulative Timesteps: 469,679,878

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 469679878...
Checkpoint 469679878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,827.43717
Policy Entropy: 0.85754
Value Function Loss: 0.07874

Mean KL Divergence: 0.00379
SB3 Clip Fraction: 0.04636
Policy Update Magnitude: 0.18118
Value Function Update Magnitude: 0.43965

Collected Steps per Second: 22,533.73415
Overall Steps per Second: 14,339.37082

Timestep Collection Time: 2.21978
Timestep Consumption Time: 1.26852
PPO Batch Consumption Time: 0.10096
Total Iteration Time: 3.48830

Cumulative Model Updates: 56,300
Cumulative Timesteps: 469,729,898

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,526.31364
Policy Entropy: 0.86042
Value Function Loss: 0.07909

Mean KL Divergence: 0.00438
SB3 Clip Fraction: 0.05224
Policy Update Magnitude: 0.18086
Value Function Update Magnitude: 0.43610

Collected Steps per Second: 23,055.96466
Overall Steps per Second: 14,725.65401

Timestep Collection Time: 2.16898
Timestep Consumption Time: 1.22699
PPO Batch Consumption Time: 0.09930
Total Iteration Time: 3.39598

Cumulative Model Updates: 56,306
Cumulative Timesteps: 469,779,906

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 469779906...
Checkpoint 469779906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,952.22433
Policy Entropy: 0.86050
Value Function Loss: 0.07874

Mean KL Divergence: 0.00372
SB3 Clip Fraction: 0.04436
Policy Update Magnitude: 0.17975
Value Function Update Magnitude: 0.45136

Collected Steps per Second: 22,416.52286
Overall Steps per Second: 14,581.14437

Timestep Collection Time: 2.23059
Timestep Consumption Time: 1.19864
PPO Batch Consumption Time: 0.10142
Total Iteration Time: 3.42922

Cumulative Model Updates: 56,312
Cumulative Timesteps: 469,829,908

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,646.90961
Policy Entropy: 0.86344
Value Function Loss: 0.07277

Mean KL Divergence: 0.00432
SB3 Clip Fraction: 0.05298
Policy Update Magnitude: 0.18135
Value Function Update Magnitude: 0.43630

Collected Steps per Second: 22,921.92379
Overall Steps per Second: 14,677.16388

Timestep Collection Time: 2.18184
Timestep Consumption Time: 1.22563
PPO Batch Consumption Time: 0.09816
Total Iteration Time: 3.40747

Cumulative Model Updates: 56,318
Cumulative Timesteps: 469,879,920

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 469879920...
Checkpoint 469879920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,160.49592
Policy Entropy: 0.86412
Value Function Loss: 0.06889

Mean KL Divergence: 0.00418
SB3 Clip Fraction: 0.05120
Policy Update Magnitude: 0.18186
Value Function Update Magnitude: 0.43698

Collected Steps per Second: 22,733.99643
Overall Steps per Second: 14,766.25885

Timestep Collection Time: 2.20049
Timestep Consumption Time: 1.18737
PPO Batch Consumption Time: 0.09381
Total Iteration Time: 3.38786

Cumulative Model Updates: 56,324
Cumulative Timesteps: 469,929,946

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,026.06057
Policy Entropy: 0.87118
Value Function Loss: 0.06558

Mean KL Divergence: 0.00412
SB3 Clip Fraction: 0.04956
Policy Update Magnitude: 0.18175
Value Function Update Magnitude: 0.42379

Collected Steps per Second: 22,391.44141
Overall Steps per Second: 14,743.82624

Timestep Collection Time: 2.23326
Timestep Consumption Time: 1.15839
PPO Batch Consumption Time: 0.09261
Total Iteration Time: 3.39166

Cumulative Model Updates: 56,330
Cumulative Timesteps: 469,979,952

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 469979952...
Checkpoint 469979952 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,429.98116
Policy Entropy: 0.88102
Value Function Loss: 0.06661

Mean KL Divergence: 0.00455
SB3 Clip Fraction: 0.05345
Policy Update Magnitude: 0.17605
Value Function Update Magnitude: 0.39419

Collected Steps per Second: 22,837.90511
Overall Steps per Second: 14,794.72219

Timestep Collection Time: 2.19022
Timestep Consumption Time: 1.19072
PPO Batch Consumption Time: 0.09153
Total Iteration Time: 3.38094

Cumulative Model Updates: 56,336
Cumulative Timesteps: 470,029,972

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,370.23812
Policy Entropy: 0.87109
Value Function Loss: 0.07386

Mean KL Divergence: 0.00399
SB3 Clip Fraction: 0.04846
Policy Update Magnitude: 0.17278
Value Function Update Magnitude: 0.38627

Collected Steps per Second: 23,341.90096
Overall Steps per Second: 14,988.94088

Timestep Collection Time: 2.14361
Timestep Consumption Time: 1.19458
PPO Batch Consumption Time: 0.10274
Total Iteration Time: 3.33819

Cumulative Model Updates: 56,342
Cumulative Timesteps: 470,080,008

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 470080008...
Checkpoint 470080008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,057.68219
Policy Entropy: 0.87414
Value Function Loss: 0.07585

Mean KL Divergence: 0.00380
SB3 Clip Fraction: 0.04547
Policy Update Magnitude: 0.18467
Value Function Update Magnitude: 0.41005

Collected Steps per Second: 22,164.13987
Overall Steps per Second: 14,663.10867

Timestep Collection Time: 2.25653
Timestep Consumption Time: 1.15434
PPO Batch Consumption Time: 0.09234
Total Iteration Time: 3.41087

Cumulative Model Updates: 56,348
Cumulative Timesteps: 470,130,022

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,393.75127
Policy Entropy: 0.87627
Value Function Loss: 0.08077

Mean KL Divergence: 0.00438
SB3 Clip Fraction: 0.05244
Policy Update Magnitude: 0.19047
Value Function Update Magnitude: 0.38910

Collected Steps per Second: 23,234.93881
Overall Steps per Second: 14,805.80907

Timestep Collection Time: 2.15322
Timestep Consumption Time: 1.22586
PPO Batch Consumption Time: 0.09820
Total Iteration Time: 3.37908

Cumulative Model Updates: 56,354
Cumulative Timesteps: 470,180,052

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 470180052...
Checkpoint 470180052 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,247.91261
Policy Entropy: 0.88691
Value Function Loss: 0.07955

Mean KL Divergence: 0.00489
SB3 Clip Fraction: 0.05562
Policy Update Magnitude: 0.18796
Value Function Update Magnitude: 0.38250

Collected Steps per Second: 22,700.50224
Overall Steps per Second: 14,806.88165

Timestep Collection Time: 2.20400
Timestep Consumption Time: 1.17497
PPO Batch Consumption Time: 0.09234
Total Iteration Time: 3.37897

Cumulative Model Updates: 56,360
Cumulative Timesteps: 470,230,084

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,721.26381
Policy Entropy: 0.89564
Value Function Loss: 0.07812

Mean KL Divergence: 0.00777
SB3 Clip Fraction: 0.08244
Policy Update Magnitude: 0.16817
Value Function Update Magnitude: 0.39309

Collected Steps per Second: 22,634.48304
Overall Steps per Second: 14,749.17994

Timestep Collection Time: 2.21096
Timestep Consumption Time: 1.18204
PPO Batch Consumption Time: 0.09463
Total Iteration Time: 3.39300

Cumulative Model Updates: 56,366
Cumulative Timesteps: 470,280,128

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 470280128...
Checkpoint 470280128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,578.33700
Policy Entropy: 0.89282
Value Function Loss: 0.08077

Mean KL Divergence: 0.00690
SB3 Clip Fraction: 0.06952
Policy Update Magnitude: 0.15659
Value Function Update Magnitude: 0.42338

Collected Steps per Second: 22,702.69593
Overall Steps per Second: 14,520.18110

Timestep Collection Time: 2.20256
Timestep Consumption Time: 1.24120
PPO Batch Consumption Time: 0.10160
Total Iteration Time: 3.44376

Cumulative Model Updates: 56,372
Cumulative Timesteps: 470,330,132

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,691.19966
Policy Entropy: 0.88858
Value Function Loss: 0.08088

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.08507
Policy Update Magnitude: 0.15757
Value Function Update Magnitude: 0.43077

Collected Steps per Second: 22,730.30358
Overall Steps per Second: 14,523.45877

Timestep Collection Time: 2.20085
Timestep Consumption Time: 1.24365
PPO Batch Consumption Time: 0.10123
Total Iteration Time: 3.44450

Cumulative Model Updates: 56,378
Cumulative Timesteps: 470,380,158

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 470380158...
Checkpoint 470380158 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,394.16784
Policy Entropy: 0.88265
Value Function Loss: 0.08854

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.08187
Policy Update Magnitude: 0.15887
Value Function Update Magnitude: 0.40593

Collected Steps per Second: 21,996.00629
Overall Steps per Second: 14,545.72486

Timestep Collection Time: 2.27378
Timestep Consumption Time: 1.16462
PPO Batch Consumption Time: 0.09318
Total Iteration Time: 3.43840

Cumulative Model Updates: 56,384
Cumulative Timesteps: 470,430,172

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,996.09563
Policy Entropy: 0.87722
Value Function Loss: 0.08963

Mean KL Divergence: 0.00587
SB3 Clip Fraction: 0.06791
Policy Update Magnitude: 0.17122
Value Function Update Magnitude: 0.38364

Collected Steps per Second: 23,185.43351
Overall Steps per Second: 14,899.79166

Timestep Collection Time: 2.15791
Timestep Consumption Time: 1.19999
PPO Batch Consumption Time: 0.09988
Total Iteration Time: 3.35790

Cumulative Model Updates: 56,390
Cumulative Timesteps: 470,480,204

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 470480204...
Checkpoint 470480204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,843.91528
Policy Entropy: 0.87034
Value Function Loss: 0.08906

Mean KL Divergence: 0.00554
SB3 Clip Fraction: 0.06481
Policy Update Magnitude: 0.18929
Value Function Update Magnitude: 0.36266

Collected Steps per Second: 22,082.11264
Overall Steps per Second: 14,703.61710

Timestep Collection Time: 2.26554
Timestep Consumption Time: 1.13688
PPO Batch Consumption Time: 0.09187
Total Iteration Time: 3.40243

Cumulative Model Updates: 56,396
Cumulative Timesteps: 470,530,232

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,251.14270
Policy Entropy: 0.86252
Value Function Loss: 0.08311

Mean KL Divergence: 0.00592
SB3 Clip Fraction: 0.06833
Policy Update Magnitude: 0.18375
Value Function Update Magnitude: 0.38601

Collected Steps per Second: 22,287.34467
Overall Steps per Second: 14,425.18648

Timestep Collection Time: 2.24459
Timestep Consumption Time: 1.22337
PPO Batch Consumption Time: 0.09887
Total Iteration Time: 3.46796

Cumulative Model Updates: 56,402
Cumulative Timesteps: 470,580,258

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 470580258...
Checkpoint 470580258 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,507.84311
Policy Entropy: 0.86502
Value Function Loss: 0.07889

Mean KL Divergence: 0.00497
SB3 Clip Fraction: 0.05712
Policy Update Magnitude: 0.17809
Value Function Update Magnitude: 0.41020

Collected Steps per Second: 22,376.26902
Overall Steps per Second: 14,484.03997

Timestep Collection Time: 2.23469
Timestep Consumption Time: 1.21766
PPO Batch Consumption Time: 0.09894
Total Iteration Time: 3.45235

Cumulative Model Updates: 56,408
Cumulative Timesteps: 470,630,262

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,289.06545
Policy Entropy: 0.88143
Value Function Loss: 0.07525

Mean KL Divergence: 0.00456
SB3 Clip Fraction: 0.05435
Policy Update Magnitude: 0.17355
Value Function Update Magnitude: 0.40608

Collected Steps per Second: 22,536.91468
Overall Steps per Second: 14,629.28942

Timestep Collection Time: 2.21858
Timestep Consumption Time: 1.19922
PPO Batch Consumption Time: 0.09540
Total Iteration Time: 3.41780

Cumulative Model Updates: 56,414
Cumulative Timesteps: 470,680,262

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 470680262...
Checkpoint 470680262 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,502.43128
Policy Entropy: 0.87034
Value Function Loss: 0.06999

Mean KL Divergence: 0.00419
SB3 Clip Fraction: 0.05077
Policy Update Magnitude: 0.17355
Value Function Update Magnitude: 0.38879

Collected Steps per Second: 22,591.57336
Overall Steps per Second: 14,301.80011

Timestep Collection Time: 2.21445
Timestep Consumption Time: 1.28357
PPO Batch Consumption Time: 0.10190
Total Iteration Time: 3.49802

Cumulative Model Updates: 56,420
Cumulative Timesteps: 470,730,290

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,604.63800
Policy Entropy: 0.87326
Value Function Loss: 0.06788

Mean KL Divergence: 0.00383
SB3 Clip Fraction: 0.04649
Policy Update Magnitude: 0.17170
Value Function Update Magnitude: 0.38041

Collected Steps per Second: 23,116.67466
Overall Steps per Second: 14,759.89329

Timestep Collection Time: 2.16415
Timestep Consumption Time: 1.22530
PPO Batch Consumption Time: 0.10070
Total Iteration Time: 3.38946

Cumulative Model Updates: 56,426
Cumulative Timesteps: 470,780,318

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 470780318...
Checkpoint 470780318 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40,910.92096
Policy Entropy: 0.87257
Value Function Loss: 0.06983

Mean KL Divergence: 0.00395
SB3 Clip Fraction: 0.04764
Policy Update Magnitude: 0.17024
Value Function Update Magnitude: 0.38591

Collected Steps per Second: 22,770.92920
Overall Steps per Second: 14,570.76963

Timestep Collection Time: 2.19675
Timestep Consumption Time: 1.23629
PPO Batch Consumption Time: 0.09839
Total Iteration Time: 3.43304

Cumulative Model Updates: 56,432
Cumulative Timesteps: 470,830,340

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,924.61124
Policy Entropy: 0.88737
Value Function Loss: 0.07810

Mean KL Divergence: 0.00523
SB3 Clip Fraction: 0.05656
Policy Update Magnitude: 0.17365
Value Function Update Magnitude: 0.39792

Collected Steps per Second: 22,971.76702
Overall Steps per Second: 14,714.16034

Timestep Collection Time: 2.17693
Timestep Consumption Time: 1.22170
PPO Batch Consumption Time: 0.09650
Total Iteration Time: 3.39863

Cumulative Model Updates: 56,438
Cumulative Timesteps: 470,880,348

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 470880348...
Checkpoint 470880348 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,556.47828
Policy Entropy: 0.88537
Value Function Loss: 0.07589

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.08205
Policy Update Magnitude: 0.16606
Value Function Update Magnitude: 0.42822

Collected Steps per Second: 22,804.60330
Overall Steps per Second: 14,805.10786

Timestep Collection Time: 2.19342
Timestep Consumption Time: 1.18515
PPO Batch Consumption Time: 0.09243
Total Iteration Time: 3.37856

Cumulative Model Updates: 56,444
Cumulative Timesteps: 470,930,368

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,231.83557
Policy Entropy: 0.88311
Value Function Loss: 0.08390

Mean KL Divergence: 0.00632
SB3 Clip Fraction: 0.06641
Policy Update Magnitude: 0.18171
Value Function Update Magnitude: 0.40616

Collected Steps per Second: 22,599.60191
Overall Steps per Second: 14,821.67747

Timestep Collection Time: 2.21402
Timestep Consumption Time: 1.16184
PPO Batch Consumption Time: 0.09595
Total Iteration Time: 3.37587

Cumulative Model Updates: 56,450
Cumulative Timesteps: 470,980,404

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 470980404...
Checkpoint 470980404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,432.02369
Policy Entropy: 0.86425
Value Function Loss: 0.08309

Mean KL Divergence: 0.00621
SB3 Clip Fraction: 0.06551
Policy Update Magnitude: 0.18799
Value Function Update Magnitude: 0.35643

Collected Steps per Second: 22,825.81385
Overall Steps per Second: 14,362.74475

Timestep Collection Time: 2.19094
Timestep Consumption Time: 1.29098
PPO Batch Consumption Time: 0.10237
Total Iteration Time: 3.48193

Cumulative Model Updates: 56,456
Cumulative Timesteps: 471,030,414

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,779.54658
Policy Entropy: 0.86891
Value Function Loss: 0.08986

Mean KL Divergence: 0.00441
SB3 Clip Fraction: 0.05298
Policy Update Magnitude: 0.19035
Value Function Update Magnitude: 0.37412

Collected Steps per Second: 22,881.09941
Overall Steps per Second: 14,899.40089

Timestep Collection Time: 2.18538
Timestep Consumption Time: 1.17072
PPO Batch Consumption Time: 0.09840
Total Iteration Time: 3.35611

Cumulative Model Updates: 56,462
Cumulative Timesteps: 471,080,418

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 471080418...
Checkpoint 471080418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,378.63755
Policy Entropy: 0.86239
Value Function Loss: 0.08460

Mean KL Divergence: 0.00396
SB3 Clip Fraction: 0.04832
Policy Update Magnitude: 0.19476
Value Function Update Magnitude: 0.42214

Collected Steps per Second: 22,171.21455
Overall Steps per Second: 14,354.27773

Timestep Collection Time: 2.25635
Timestep Consumption Time: 1.22874
PPO Batch Consumption Time: 0.09889
Total Iteration Time: 3.48509

Cumulative Model Updates: 56,468
Cumulative Timesteps: 471,130,444

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,142.86810
Policy Entropy: 0.86838
Value Function Loss: 0.08129

Mean KL Divergence: 0.00405
SB3 Clip Fraction: 0.04864
Policy Update Magnitude: 0.19437
Value Function Update Magnitude: 0.46358

Collected Steps per Second: 23,262.50872
Overall Steps per Second: 14,755.25269

Timestep Collection Time: 2.15058
Timestep Consumption Time: 1.23994
PPO Batch Consumption Time: 0.10015
Total Iteration Time: 3.39052

Cumulative Model Updates: 56,474
Cumulative Timesteps: 471,180,472

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 471180472...
Checkpoint 471180472 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,244.62753
Policy Entropy: 0.84932
Value Function Loss: 0.08491

Mean KL Divergence: 0.00435
SB3 Clip Fraction: 0.05300
Policy Update Magnitude: 0.19116
Value Function Update Magnitude: 0.44816

Collected Steps per Second: 22,755.20230
Overall Steps per Second: 14,756.07573

Timestep Collection Time: 2.19879
Timestep Consumption Time: 1.19195
PPO Batch Consumption Time: 0.09387
Total Iteration Time: 3.39074

Cumulative Model Updates: 56,480
Cumulative Timesteps: 471,230,506

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,739.34273
Policy Entropy: 0.84554
Value Function Loss: 0.08162

Mean KL Divergence: 0.00485
SB3 Clip Fraction: 0.05667
Policy Update Magnitude: 0.19393
Value Function Update Magnitude: 0.46218

Collected Steps per Second: 22,000.55274
Overall Steps per Second: 14,112.87495

Timestep Collection Time: 2.27303
Timestep Consumption Time: 1.27040
PPO Batch Consumption Time: 0.10383
Total Iteration Time: 3.54343

Cumulative Model Updates: 56,486
Cumulative Timesteps: 471,280,514

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 471280514...
Checkpoint 471280514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,264.11026
Policy Entropy: 0.84722
Value Function Loss: 0.07883

Mean KL Divergence: 0.00483
SB3 Clip Fraction: 0.05474
Policy Update Magnitude: 0.18184
Value Function Update Magnitude: 0.45594

Collected Steps per Second: 22,670.24073
Overall Steps per Second: 14,638.48231

Timestep Collection Time: 2.20642
Timestep Consumption Time: 1.21060
PPO Batch Consumption Time: 0.09396
Total Iteration Time: 3.41702

Cumulative Model Updates: 56,492
Cumulative Timesteps: 471,330,534

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,488.17245
Policy Entropy: 0.85126
Value Function Loss: 0.07382

Mean KL Divergence: 0.00442
SB3 Clip Fraction: 0.05175
Policy Update Magnitude: 0.17886
Value Function Update Magnitude: 0.43427

Collected Steps per Second: 22,733.68958
Overall Steps per Second: 14,768.69975

Timestep Collection Time: 2.19982
Timestep Consumption Time: 1.18640
PPO Batch Consumption Time: 0.09390
Total Iteration Time: 3.38622

Cumulative Model Updates: 56,498
Cumulative Timesteps: 471,380,544

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 471380544...
Checkpoint 471380544 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,910.02016
Policy Entropy: 0.85611
Value Function Loss: 0.09098

Mean KL Divergence: 0.00463
SB3 Clip Fraction: 0.05466
Policy Update Magnitude: 0.18377
Value Function Update Magnitude: 0.42744

Collected Steps per Second: 22,482.84290
Overall Steps per Second: 14,823.61376

Timestep Collection Time: 2.22401
Timestep Consumption Time: 1.14912
PPO Batch Consumption Time: 0.09211
Total Iteration Time: 3.37313

Cumulative Model Updates: 56,504
Cumulative Timesteps: 471,430,546

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,850.79941
Policy Entropy: 0.84849
Value Function Loss: 0.08618

Mean KL Divergence: 0.00463
SB3 Clip Fraction: 0.05532
Policy Update Magnitude: 0.18295
Value Function Update Magnitude: 0.42927

Collected Steps per Second: 23,403.06534
Overall Steps per Second: 14,818.47472

Timestep Collection Time: 2.13681
Timestep Consumption Time: 1.23789
PPO Batch Consumption Time: 0.10077
Total Iteration Time: 3.37471

Cumulative Model Updates: 56,510
Cumulative Timesteps: 471,480,554

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 471480554...
Checkpoint 471480554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,873.29367
Policy Entropy: 0.85910
Value Function Loss: 0.08348

Mean KL Divergence: 0.00414
SB3 Clip Fraction: 0.04882
Policy Update Magnitude: 0.18307
Value Function Update Magnitude: 0.43807

Collected Steps per Second: 22,611.10264
Overall Steps per Second: 14,707.03792

Timestep Collection Time: 2.21175
Timestep Consumption Time: 1.18867
PPO Batch Consumption Time: 0.09463
Total Iteration Time: 3.40041

Cumulative Model Updates: 56,516
Cumulative Timesteps: 471,530,564

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,293.24715
Policy Entropy: 0.86010
Value Function Loss: 0.07216

Mean KL Divergence: 0.00427
SB3 Clip Fraction: 0.04960
Policy Update Magnitude: 0.18188
Value Function Update Magnitude: 0.41356

Collected Steps per Second: 22,350.49004
Overall Steps per Second: 14,413.13021

Timestep Collection Time: 2.23771
Timestep Consumption Time: 1.23232
PPO Batch Consumption Time: 0.10195
Total Iteration Time: 3.47003

Cumulative Model Updates: 56,522
Cumulative Timesteps: 471,580,578

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 471580578...
Checkpoint 471580578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,213.90674
Policy Entropy: 0.85207
Value Function Loss: 0.07507

Mean KL Divergence: 0.00517
SB3 Clip Fraction: 0.06042
Policy Update Magnitude: 0.18021
Value Function Update Magnitude: 0.40933

Collected Steps per Second: 22,169.34211
Overall Steps per Second: 14,461.60324

Timestep Collection Time: 2.25609
Timestep Consumption Time: 1.20245
PPO Batch Consumption Time: 0.09439
Total Iteration Time: 3.45854

Cumulative Model Updates: 56,528
Cumulative Timesteps: 471,630,594

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,585.86367
Policy Entropy: 0.84066
Value Function Loss: 0.07043

Mean KL Divergence: 0.00449
SB3 Clip Fraction: 0.05294
Policy Update Magnitude: 0.18195
Value Function Update Magnitude: 0.40901

Collected Steps per Second: 22,881.44358
Overall Steps per Second: 14,755.98003

Timestep Collection Time: 2.18623
Timestep Consumption Time: 1.20386
PPO Batch Consumption Time: 0.09533
Total Iteration Time: 3.39008

Cumulative Model Updates: 56,534
Cumulative Timesteps: 471,680,618

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 471680618...
Checkpoint 471680618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,268.05161
Policy Entropy: 0.83348
Value Function Loss: 0.06949

Mean KL Divergence: 0.00429
SB3 Clip Fraction: 0.05290
Policy Update Magnitude: 0.18383
Value Function Update Magnitude: 0.41298

Collected Steps per Second: 22,501.25724
Overall Steps per Second: 14,339.09859

Timestep Collection Time: 2.22352
Timestep Consumption Time: 1.26568
PPO Batch Consumption Time: 0.10246
Total Iteration Time: 3.48920

Cumulative Model Updates: 56,540
Cumulative Timesteps: 471,730,650

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,826.34799
Policy Entropy: 0.82407
Value Function Loss: 0.06891

Mean KL Divergence: 0.00444
SB3 Clip Fraction: 0.05316
Policy Update Magnitude: 0.17623
Value Function Update Magnitude: 0.38811

Collected Steps per Second: 23,158.64100
Overall Steps per Second: 14,787.55486

Timestep Collection Time: 2.15954
Timestep Consumption Time: 1.22249
PPO Batch Consumption Time: 0.10054
Total Iteration Time: 3.38203

Cumulative Model Updates: 56,546
Cumulative Timesteps: 471,780,662

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 471780662...
Checkpoint 471780662 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,321.75541
Policy Entropy: 0.83229
Value Function Loss: 0.07282

Mean KL Divergence: 0.00427
SB3 Clip Fraction: 0.04990
Policy Update Magnitude: 0.17723
Value Function Update Magnitude: 0.38456

Collected Steps per Second: 22,291.25718
Overall Steps per Second: 14,496.49006

Timestep Collection Time: 2.24321
Timestep Consumption Time: 1.20618
PPO Batch Consumption Time: 0.09585
Total Iteration Time: 3.44939

Cumulative Model Updates: 56,552
Cumulative Timesteps: 471,830,666

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,421.30337
Policy Entropy: 0.83065
Value Function Loss: 0.06895

Mean KL Divergence: 0.00365
SB3 Clip Fraction: 0.04470
Policy Update Magnitude: 0.17837
Value Function Update Magnitude: 0.37966

Collected Steps per Second: 22,141.76021
Overall Steps per Second: 14,356.87165

Timestep Collection Time: 2.25890
Timestep Consumption Time: 1.22487
PPO Batch Consumption Time: 0.10115
Total Iteration Time: 3.48377

Cumulative Model Updates: 56,558
Cumulative Timesteps: 471,880,682

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 471880682...
Checkpoint 471880682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,396.53686
Policy Entropy: 0.83140
Value Function Loss: 0.07102

Mean KL Divergence: 0.00425
SB3 Clip Fraction: 0.05192
Policy Update Magnitude: 0.18474
Value Function Update Magnitude: 0.36827

Collected Steps per Second: 22,502.18264
Overall Steps per Second: 14,491.96551

Timestep Collection Time: 2.22414
Timestep Consumption Time: 1.22936
PPO Batch Consumption Time: 0.09992
Total Iteration Time: 3.45350

Cumulative Model Updates: 56,564
Cumulative Timesteps: 471,930,730

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,128.53051
Policy Entropy: 0.83340
Value Function Loss: 0.07126

Mean KL Divergence: 0.00507
SB3 Clip Fraction: 0.06018
Policy Update Magnitude: 0.18478
Value Function Update Magnitude: 0.36138

Collected Steps per Second: 22,568.03065
Overall Steps per Second: 14,647.13056

Timestep Collection Time: 2.21552
Timestep Consumption Time: 1.19811
PPO Batch Consumption Time: 0.09714
Total Iteration Time: 3.41364

Cumulative Model Updates: 56,570
Cumulative Timesteps: 471,980,730

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 471980730...
Checkpoint 471980730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,972.26669
Policy Entropy: 0.84316
Value Function Loss: 0.07706

Mean KL Divergence: 0.00569
SB3 Clip Fraction: 0.06541
Policy Update Magnitude: 0.17994
Value Function Update Magnitude: 0.37064

Collected Steps per Second: 22,326.14680
Overall Steps per Second: 14,285.72244

Timestep Collection Time: 2.24150
Timestep Consumption Time: 1.26158
PPO Batch Consumption Time: 0.10193
Total Iteration Time: 3.50308

Cumulative Model Updates: 56,576
Cumulative Timesteps: 472,030,774

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,766.18611
Policy Entropy: 0.84844
Value Function Loss: 0.08255

Mean KL Divergence: 0.00572
SB3 Clip Fraction: 0.06580
Policy Update Magnitude: 0.18624
Value Function Update Magnitude: 0.39194

Collected Steps per Second: 23,296.00290
Overall Steps per Second: 14,827.49231

Timestep Collection Time: 2.14672
Timestep Consumption Time: 1.22607
PPO Batch Consumption Time: 0.10101
Total Iteration Time: 3.37279

Cumulative Model Updates: 56,582
Cumulative Timesteps: 472,080,784

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 472080784...
Checkpoint 472080784 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,319.79595
Policy Entropy: 0.84591
Value Function Loss: 0.08235

Mean KL Divergence: 0.00621
SB3 Clip Fraction: 0.07251
Policy Update Magnitude: 0.18983
Value Function Update Magnitude: 0.41134

Collected Steps per Second: 22,131.84462
Overall Steps per Second: 14,470.07796

Timestep Collection Time: 2.25919
Timestep Consumption Time: 1.19622
PPO Batch Consumption Time: 0.09563
Total Iteration Time: 3.45541

Cumulative Model Updates: 56,588
Cumulative Timesteps: 472,130,784

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,910.00635
Policy Entropy: 0.85102
Value Function Loss: 0.08340

Mean KL Divergence: 0.00629
SB3 Clip Fraction: 0.07071
Policy Update Magnitude: 0.19385
Value Function Update Magnitude: 0.42597

Collected Steps per Second: 22,989.29481
Overall Steps per Second: 14,698.88584

Timestep Collection Time: 2.17632
Timestep Consumption Time: 1.22748
PPO Batch Consumption Time: 0.09195
Total Iteration Time: 3.40380

Cumulative Model Updates: 56,594
Cumulative Timesteps: 472,180,816

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 472180816...
Checkpoint 472180816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,849.38183
Policy Entropy: 0.85842
Value Function Loss: 0.07537

Mean KL Divergence: 0.00611
SB3 Clip Fraction: 0.07023
Policy Update Magnitude: 0.19782
Value Function Update Magnitude: 0.40614

Collected Steps per Second: 23,050.76704
Overall Steps per Second: 14,889.91767

Timestep Collection Time: 2.16991
Timestep Consumption Time: 1.18928
PPO Batch Consumption Time: 0.09423
Total Iteration Time: 3.35919

Cumulative Model Updates: 56,600
Cumulative Timesteps: 472,230,834

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,867.25408
Policy Entropy: 0.86956
Value Function Loss: 0.07384

Mean KL Divergence: 0.00485
SB3 Clip Fraction: 0.05739
Policy Update Magnitude: 0.19761
Value Function Update Magnitude: 0.38894

Collected Steps per Second: 21,978.01715
Overall Steps per Second: 14,779.44460

Timestep Collection Time: 2.27555
Timestep Consumption Time: 1.10834
PPO Batch Consumption Time: 0.09546
Total Iteration Time: 3.38389

Cumulative Model Updates: 56,606
Cumulative Timesteps: 472,280,846

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 472280846...
Checkpoint 472280846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,543.95775
Policy Entropy: 0.86882
Value Function Loss: 0.06779

Mean KL Divergence: 0.00466
SB3 Clip Fraction: 0.05515
Policy Update Magnitude: 0.18587
Value Function Update Magnitude: 0.38589

Collected Steps per Second: 21,985.43876
Overall Steps per Second: 14,445.05513

Timestep Collection Time: 2.27551
Timestep Consumption Time: 1.18782
PPO Batch Consumption Time: 0.10108
Total Iteration Time: 3.46333

Cumulative Model Updates: 56,612
Cumulative Timesteps: 472,330,874

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,522.46272
Policy Entropy: 0.86461
Value Function Loss: 0.06683

Mean KL Divergence: 0.00375
SB3 Clip Fraction: 0.04518
Policy Update Magnitude: 0.18544
Value Function Update Magnitude: 0.38180

Collected Steps per Second: 22,527.90923
Overall Steps per Second: 14,979.17677

Timestep Collection Time: 2.22018
Timestep Consumption Time: 1.11886
PPO Batch Consumption Time: 0.09542
Total Iteration Time: 3.33904

Cumulative Model Updates: 56,618
Cumulative Timesteps: 472,380,890

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 472380890...
Checkpoint 472380890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,323.60290
Policy Entropy: 0.87388
Value Function Loss: 0.06707

Mean KL Divergence: 0.00355
SB3 Clip Fraction: 0.04310
Policy Update Magnitude: 0.18664
Value Function Update Magnitude: 0.37392

Collected Steps per Second: 21,566.65307
Overall Steps per Second: 14,237.20354

Timestep Collection Time: 2.31932
Timestep Consumption Time: 1.19401
PPO Batch Consumption Time: 0.10812
Total Iteration Time: 3.51333

Cumulative Model Updates: 56,624
Cumulative Timesteps: 472,430,910

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,208.77241
Policy Entropy: 0.86914
Value Function Loss: 0.07363

Mean KL Divergence: 0.00441
SB3 Clip Fraction: 0.05475
Policy Update Magnitude: 0.18606
Value Function Update Magnitude: 0.38031

Collected Steps per Second: 22,225.56214
Overall Steps per Second: 14,713.40064

Timestep Collection Time: 2.25155
Timestep Consumption Time: 1.14957
PPO Batch Consumption Time: 0.09699
Total Iteration Time: 3.40112

Cumulative Model Updates: 56,630
Cumulative Timesteps: 472,480,952

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 472480952...
Checkpoint 472480952 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,715.54437
Policy Entropy: 0.87788
Value Function Loss: 0.07186

Mean KL Divergence: 0.00472
SB3 Clip Fraction: 0.05695
Policy Update Magnitude: 0.18954
Value Function Update Magnitude: 0.38935

Collected Steps per Second: 22,088.91892
Overall Steps per Second: 14,775.40690

Timestep Collection Time: 2.26439
Timestep Consumption Time: 1.12083
PPO Batch Consumption Time: 0.09249
Total Iteration Time: 3.38522

Cumulative Model Updates: 56,636
Cumulative Timesteps: 472,530,970

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,100.21734
Policy Entropy: 0.86428
Value Function Loss: 0.07089

Mean KL Divergence: 0.00497
SB3 Clip Fraction: 0.05801
Policy Update Magnitude: 0.19566
Value Function Update Magnitude: 0.37150

Collected Steps per Second: 22,244.10588
Overall Steps per Second: 14,768.25276

Timestep Collection Time: 2.24967
Timestep Consumption Time: 1.13881
PPO Batch Consumption Time: 0.09209
Total Iteration Time: 3.38848

Cumulative Model Updates: 56,642
Cumulative Timesteps: 472,581,012

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 472581012...
Checkpoint 472581012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,925.67390
Policy Entropy: 0.86690
Value Function Loss: 0.07433

Mean KL Divergence: 0.00422
SB3 Clip Fraction: 0.05067
Policy Update Magnitude: 0.19625
Value Function Update Magnitude: 0.37947

Collected Steps per Second: 22,427.70843
Overall Steps per Second: 14,546.02845

Timestep Collection Time: 2.23063
Timestep Consumption Time: 1.20866
PPO Batch Consumption Time: 0.10111
Total Iteration Time: 3.43929

Cumulative Model Updates: 56,648
Cumulative Timesteps: 472,631,040

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,811.54759
Policy Entropy: 0.86363
Value Function Loss: 0.07390

Mean KL Divergence: 0.00472
SB3 Clip Fraction: 0.05539
Policy Update Magnitude: 0.20514
Value Function Update Magnitude: 0.40414

Collected Steps per Second: 23,141.34800
Overall Steps per Second: 15,076.67039

Timestep Collection Time: 2.16124
Timestep Consumption Time: 1.15607
PPO Batch Consumption Time: 0.09244
Total Iteration Time: 3.31731

Cumulative Model Updates: 56,654
Cumulative Timesteps: 472,681,054

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 472681054...
Checkpoint 472681054 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,754.70020
Policy Entropy: 0.86702
Value Function Loss: 0.07202

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.09057
Policy Update Magnitude: 0.19028
Value Function Update Magnitude: 0.39953

Collected Steps per Second: 22,109.87458
Overall Steps per Second: 14,413.15125

Timestep Collection Time: 2.26143
Timestep Consumption Time: 1.20762
PPO Batch Consumption Time: 0.09994
Total Iteration Time: 3.46905

Cumulative Model Updates: 56,660
Cumulative Timesteps: 472,731,054

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,084.16960
Policy Entropy: 0.88722
Value Function Loss: 0.07345

Mean KL Divergence: 0.01464
SB3 Clip Fraction: 0.10691
Policy Update Magnitude: 0.16626
Value Function Update Magnitude: 0.37845

Collected Steps per Second: 23,103.14525
Overall Steps per Second: 14,832.78916

Timestep Collection Time: 2.16473
Timestep Consumption Time: 1.20699
PPO Batch Consumption Time: 0.09960
Total Iteration Time: 3.37172

Cumulative Model Updates: 56,666
Cumulative Timesteps: 472,781,066

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 472781066...
Checkpoint 472781066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,692.55990
Policy Entropy: 0.89940
Value Function Loss: 0.07343

Mean KL Divergence: 0.01088
SB3 Clip Fraction: 0.09036
Policy Update Magnitude: 0.15512
Value Function Update Magnitude: 0.37224

Collected Steps per Second: 22,754.46301
Overall Steps per Second: 14,534.34386

Timestep Collection Time: 2.19781
Timestep Consumption Time: 1.24301
PPO Batch Consumption Time: 0.10300
Total Iteration Time: 3.44082

Cumulative Model Updates: 56,672
Cumulative Timesteps: 472,831,076

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,203.90583
Policy Entropy: 0.91089
Value Function Loss: 0.07235

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.08304
Policy Update Magnitude: 0.15845
Value Function Update Magnitude: 0.37716

Collected Steps per Second: 22,793.76455
Overall Steps per Second: 14,610.03759

Timestep Collection Time: 2.19446
Timestep Consumption Time: 1.22921
PPO Batch Consumption Time: 0.09795
Total Iteration Time: 3.42367

Cumulative Model Updates: 56,678
Cumulative Timesteps: 472,881,096

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 472881096...
Checkpoint 472881096 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,319.21228
Policy Entropy: 0.89662
Value Function Loss: 0.07527

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.08040
Policy Update Magnitude: 0.16695
Value Function Update Magnitude: 0.38393

Collected Steps per Second: 23,186.17078
Overall Steps per Second: 14,955.89414

Timestep Collection Time: 2.15698
Timestep Consumption Time: 1.18699
PPO Batch Consumption Time: 0.10148
Total Iteration Time: 3.34397

Cumulative Model Updates: 56,684
Cumulative Timesteps: 472,931,108

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,017.82777
Policy Entropy: 0.88661
Value Function Loss: 0.07875

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.08397
Policy Update Magnitude: 0.17764
Value Function Update Magnitude: 0.38755

Collected Steps per Second: 22,792.30269
Overall Steps per Second: 14,648.70835

Timestep Collection Time: 2.19451
Timestep Consumption Time: 1.21999
PPO Batch Consumption Time: 0.09829
Total Iteration Time: 3.41450

Cumulative Model Updates: 56,690
Cumulative Timesteps: 472,981,126

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 472981126...
Checkpoint 472981126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,962.90864
Policy Entropy: 0.89195
Value Function Loss: 0.08297

Mean KL Divergence: 0.00614
SB3 Clip Fraction: 0.06443
Policy Update Magnitude: 0.18202
Value Function Update Magnitude: 0.39101

Collected Steps per Second: 22,370.27327
Overall Steps per Second: 14,747.62077

Timestep Collection Time: 2.23636
Timestep Consumption Time: 1.15592
PPO Batch Consumption Time: 0.09127
Total Iteration Time: 3.39228

Cumulative Model Updates: 56,696
Cumulative Timesteps: 473,031,154

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,033.29916
Policy Entropy: 0.91022
Value Function Loss: 0.08562

Mean KL Divergence: 0.00622
SB3 Clip Fraction: 0.06959
Policy Update Magnitude: 0.19629
Value Function Update Magnitude: 0.39546

Collected Steps per Second: 22,924.21814
Overall Steps per Second: 14,799.54483

Timestep Collection Time: 2.18136
Timestep Consumption Time: 1.19753
PPO Batch Consumption Time: 0.09400
Total Iteration Time: 3.37889

Cumulative Model Updates: 56,702
Cumulative Timesteps: 473,081,160

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 473081160...
Checkpoint 473081160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,432.71134
Policy Entropy: 0.91104
Value Function Loss: 0.08885

Mean KL Divergence: 0.00609
SB3 Clip Fraction: 0.07159
Policy Update Magnitude: 0.20387
Value Function Update Magnitude: 0.36931

Collected Steps per Second: 22,594.75258
Overall Steps per Second: 14,808.82188

Timestep Collection Time: 2.21352
Timestep Consumption Time: 1.16379
PPO Batch Consumption Time: 0.09083
Total Iteration Time: 3.37731

Cumulative Model Updates: 56,708
Cumulative Timesteps: 473,131,174

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,542.08709
Policy Entropy: 0.90730
Value Function Loss: 0.08880

Mean KL Divergence: 0.00661
SB3 Clip Fraction: 0.07586
Policy Update Magnitude: 0.19795
Value Function Update Magnitude: 0.33620

Collected Steps per Second: 23,240.54752
Overall Steps per Second: 14,787.55832

Timestep Collection Time: 2.15262
Timestep Consumption Time: 1.23050
PPO Batch Consumption Time: 0.09384
Total Iteration Time: 3.38311

Cumulative Model Updates: 56,714
Cumulative Timesteps: 473,181,202

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 473181202...
Checkpoint 473181202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,991.24163
Policy Entropy: 0.87766
Value Function Loss: 0.08331

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.09066
Policy Update Magnitude: 0.18547
Value Function Update Magnitude: 0.32272

Collected Steps per Second: 22,788.58624
Overall Steps per Second: 14,824.03161

Timestep Collection Time: 2.19461
Timestep Consumption Time: 1.17910
PPO Batch Consumption Time: 0.09134
Total Iteration Time: 3.37371

Cumulative Model Updates: 56,720
Cumulative Timesteps: 473,231,214

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,961.87026
Policy Entropy: 0.88638
Value Function Loss: 0.08264

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.09436
Policy Update Magnitude: 0.18871
Value Function Update Magnitude: 0.31514

Collected Steps per Second: 22,507.91561
Overall Steps per Second: 14,773.16267

Timestep Collection Time: 2.22251
Timestep Consumption Time: 1.16363
PPO Batch Consumption Time: 0.09027
Total Iteration Time: 3.38614

Cumulative Model Updates: 56,726
Cumulative Timesteps: 473,281,238

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 473281238...
Checkpoint 473281238 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,753.81644
Policy Entropy: 0.88221
Value Function Loss: 0.08237

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.08505
Policy Update Magnitude: 0.17552
Value Function Update Magnitude: 0.31743

Collected Steps per Second: 22,147.27508
Overall Steps per Second: 14,163.73229

Timestep Collection Time: 2.25807
Timestep Consumption Time: 1.27278
PPO Batch Consumption Time: 0.10131
Total Iteration Time: 3.53085

Cumulative Model Updates: 56,732
Cumulative Timesteps: 473,331,248

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,459.88519
Policy Entropy: 0.89827
Value Function Loss: 0.08418

Mean KL Divergence: 0.01099
SB3 Clip Fraction: 0.10045
Policy Update Magnitude: 0.17172
Value Function Update Magnitude: 0.33622

Collected Steps per Second: 22,704.01753
Overall Steps per Second: 14,665.15444

Timestep Collection Time: 2.20322
Timestep Consumption Time: 1.20772
PPO Batch Consumption Time: 0.09609
Total Iteration Time: 3.41094

Cumulative Model Updates: 56,738
Cumulative Timesteps: 473,381,270

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 473381270...
Checkpoint 473381270 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,724.87153
Policy Entropy: 0.88575
Value Function Loss: 0.07842

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.08797
Policy Update Magnitude: 0.16378
Value Function Update Magnitude: 0.37192

Collected Steps per Second: 22,046.54788
Overall Steps per Second: 14,247.72264

Timestep Collection Time: 2.26920
Timestep Consumption Time: 1.24210
PPO Batch Consumption Time: 0.10186
Total Iteration Time: 3.51130

Cumulative Model Updates: 56,744
Cumulative Timesteps: 473,431,298

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,556.47881
Policy Entropy: 0.87204
Value Function Loss: 0.07282

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.08557
Policy Update Magnitude: 0.16315
Value Function Update Magnitude: 0.36994

Collected Steps per Second: 23,282.58258
Overall Steps per Second: 14,605.50196

Timestep Collection Time: 2.14864
Timestep Consumption Time: 1.27650
PPO Batch Consumption Time: 0.10345
Total Iteration Time: 3.42515

Cumulative Model Updates: 56,750
Cumulative Timesteps: 473,481,324

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 473481324...
Checkpoint 473481324 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,882.87694
Policy Entropy: 0.87522
Value Function Loss: 0.07130

Mean KL Divergence: 0.00640
SB3 Clip Fraction: 0.07126
Policy Update Magnitude: 0.17448
Value Function Update Magnitude: 0.33193

Collected Steps per Second: 22,847.26584
Overall Steps per Second: 14,734.35876

Timestep Collection Time: 2.18967
Timestep Consumption Time: 1.20566
PPO Batch Consumption Time: 0.09772
Total Iteration Time: 3.39533

Cumulative Model Updates: 56,756
Cumulative Timesteps: 473,531,352

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,437.05788
Policy Entropy: 0.88143
Value Function Loss: 0.07539

Mean KL Divergence: 0.00486
SB3 Clip Fraction: 0.05711
Policy Update Magnitude: 0.18842
Value Function Update Magnitude: 0.31098

Collected Steps per Second: 22,676.58712
Overall Steps per Second: 14,728.35880

Timestep Collection Time: 2.20580
Timestep Consumption Time: 1.19037
PPO Batch Consumption Time: 0.09576
Total Iteration Time: 3.39617

Cumulative Model Updates: 56,762
Cumulative Timesteps: 473,581,372

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 473581372...
Checkpoint 473581372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,996.12065
Policy Entropy: 0.89355
Value Function Loss: 0.07684

Mean KL Divergence: 0.00425
SB3 Clip Fraction: 0.05134
Policy Update Magnitude: 0.19374
Value Function Update Magnitude: 0.30622

Collected Steps per Second: 22,877.45537
Overall Steps per Second: 14,520.11347

Timestep Collection Time: 2.18652
Timestep Consumption Time: 1.25850
PPO Batch Consumption Time: 0.10075
Total Iteration Time: 3.44501

Cumulative Model Updates: 56,768
Cumulative Timesteps: 473,631,394

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,192.96166
Policy Entropy: 0.90342
Value Function Loss: 0.07324

Mean KL Divergence: 0.00403
SB3 Clip Fraction: 0.04910
Policy Update Magnitude: 0.19287
Value Function Update Magnitude: 0.34485

Collected Steps per Second: 23,230.81687
Overall Steps per Second: 15,068.11076

Timestep Collection Time: 2.15309
Timestep Consumption Time: 1.16637
PPO Batch Consumption Time: 0.09150
Total Iteration Time: 3.31946

Cumulative Model Updates: 56,774
Cumulative Timesteps: 473,681,412

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 473681412...
Checkpoint 473681412 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,023.80304
Policy Entropy: 0.90368
Value Function Loss: 0.08113

Mean KL Divergence: 0.00427
SB3 Clip Fraction: 0.05077
Policy Update Magnitude: 0.19668
Value Function Update Magnitude: 0.35334

Collected Steps per Second: 22,214.40977
Overall Steps per Second: 14,431.20371

Timestep Collection Time: 2.25196
Timestep Consumption Time: 1.21455
PPO Batch Consumption Time: 0.10054
Total Iteration Time: 3.46652

Cumulative Model Updates: 56,780
Cumulative Timesteps: 473,731,438

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,395.83668
Policy Entropy: 0.91620
Value Function Loss: 0.07398

Mean KL Divergence: 0.00482
SB3 Clip Fraction: 0.05791
Policy Update Magnitude: 0.19967
Value Function Update Magnitude: 0.36706

Collected Steps per Second: 23,244.92542
Overall Steps per Second: 14,860.32412

Timestep Collection Time: 2.15204
Timestep Consumption Time: 1.21424
PPO Batch Consumption Time: 0.09914
Total Iteration Time: 3.36628

Cumulative Model Updates: 56,786
Cumulative Timesteps: 473,781,462

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 473781462...
Checkpoint 473781462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,088.40503
Policy Entropy: 0.92408
Value Function Loss: 0.07556

Mean KL Divergence: 0.00457
SB3 Clip Fraction: 0.05388
Policy Update Magnitude: 0.19542
Value Function Update Magnitude: 0.37211

Collected Steps per Second: 22,571.69370
Overall Steps per Second: 14,510.83200

Timestep Collection Time: 2.21578
Timestep Consumption Time: 1.23088
PPO Batch Consumption Time: 0.10303
Total Iteration Time: 3.44667

Cumulative Model Updates: 56,792
Cumulative Timesteps: 473,831,476

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,246.43831
Policy Entropy: 0.92932
Value Function Loss: 0.06607

Mean KL Divergence: 0.00392
SB3 Clip Fraction: 0.04718
Policy Update Magnitude: 0.19692
Value Function Update Magnitude: 0.36527

Collected Steps per Second: 22,685.95728
Overall Steps per Second: 14,682.40929

Timestep Collection Time: 2.20427
Timestep Consumption Time: 1.20157
PPO Batch Consumption Time: 0.09924
Total Iteration Time: 3.40584

Cumulative Model Updates: 56,798
Cumulative Timesteps: 473,881,482

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 473881482...
Checkpoint 473881482 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,753.90107
Policy Entropy: 0.91532
Value Function Loss: 0.07168

Mean KL Divergence: 0.00477
SB3 Clip Fraction: 0.05409
Policy Update Magnitude: 0.19360
Value Function Update Magnitude: 0.34902

Collected Steps per Second: 21,628.54445
Overall Steps per Second: 13,951.98595

Timestep Collection Time: 2.31213
Timestep Consumption Time: 1.27216
PPO Batch Consumption Time: 0.10217
Total Iteration Time: 3.58429

Cumulative Model Updates: 56,804
Cumulative Timesteps: 473,931,490

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,672.95912
Policy Entropy: 0.90304
Value Function Loss: 0.07169

Mean KL Divergence: 0.00679
SB3 Clip Fraction: 0.07123
Policy Update Magnitude: 0.18329
Value Function Update Magnitude: 0.34726

Collected Steps per Second: 23,045.21500
Overall Steps per Second: 14,770.80096

Timestep Collection Time: 2.17026
Timestep Consumption Time: 1.21575
PPO Batch Consumption Time: 0.09888
Total Iteration Time: 3.38600

Cumulative Model Updates: 56,810
Cumulative Timesteps: 473,981,504

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 473981504...
Checkpoint 473981504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,883.31773
Policy Entropy: 0.92072
Value Function Loss: 0.07123

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.07520
Policy Update Magnitude: 0.18704
Value Function Update Magnitude: 0.35547

Collected Steps per Second: 22,101.35823
Overall Steps per Second: 14,297.50891

Timestep Collection Time: 2.26348
Timestep Consumption Time: 1.23545
PPO Batch Consumption Time: 0.10172
Total Iteration Time: 3.49893

Cumulative Model Updates: 56,816
Cumulative Timesteps: 474,031,530

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,170.46767
Policy Entropy: 0.92201
Value Function Loss: 0.08000

Mean KL Divergence: 0.00667
SB3 Clip Fraction: 0.07109
Policy Update Magnitude: 0.19711
Value Function Update Magnitude: 0.35282

Collected Steps per Second: 23,383.72364
Overall Steps per Second: 14,913.82598

Timestep Collection Time: 2.13901
Timestep Consumption Time: 1.21479
PPO Batch Consumption Time: 0.09930
Total Iteration Time: 3.35380

Cumulative Model Updates: 56,822
Cumulative Timesteps: 474,081,548

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 474081548...
Checkpoint 474081548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,956.27814
Policy Entropy: 0.93479
Value Function Loss: 0.07960

Mean KL Divergence: 0.00556
SB3 Clip Fraction: 0.06600
Policy Update Magnitude: 0.20571
Value Function Update Magnitude: 0.38727

Collected Steps per Second: 22,683.89817
Overall Steps per Second: 14,623.52991

Timestep Collection Time: 2.20500
Timestep Consumption Time: 1.21538
PPO Batch Consumption Time: 0.10068
Total Iteration Time: 3.42038

Cumulative Model Updates: 56,828
Cumulative Timesteps: 474,131,566

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,109.38591
Policy Entropy: 0.93215
Value Function Loss: 0.07619

Mean KL Divergence: 0.00618
SB3 Clip Fraction: 0.07065
Policy Update Magnitude: 0.20407
Value Function Update Magnitude: 0.41139

Collected Steps per Second: 21,966.99078
Overall Steps per Second: 14,511.57847

Timestep Collection Time: 2.27805
Timestep Consumption Time: 1.17036
PPO Batch Consumption Time: 0.10413
Total Iteration Time: 3.44842

Cumulative Model Updates: 56,834
Cumulative Timesteps: 474,181,608

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 474181608...
Checkpoint 474181608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,291.82001
Policy Entropy: 0.93521
Value Function Loss: 0.06814

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.08884
Policy Update Magnitude: 0.18521
Value Function Update Magnitude: 0.40760

Collected Steps per Second: 21,755.86978
Overall Steps per Second: 14,429.70242

Timestep Collection Time: 2.30062
Timestep Consumption Time: 1.16806
PPO Batch Consumption Time: 0.09972
Total Iteration Time: 3.46868

Cumulative Model Updates: 56,840
Cumulative Timesteps: 474,231,660

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,036.94350
Policy Entropy: 0.92451
Value Function Loss: 0.06782

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.08413
Policy Update Magnitude: 0.18216
Value Function Update Magnitude: 0.40873

Collected Steps per Second: 21,795.83764
Overall Steps per Second: 14,473.91401

Timestep Collection Time: 2.29585
Timestep Consumption Time: 1.16140
PPO Batch Consumption Time: 0.10210
Total Iteration Time: 3.45725

Cumulative Model Updates: 56,846
Cumulative Timesteps: 474,281,700

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 474281700...
Checkpoint 474281700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,376.33440
Policy Entropy: 0.93068
Value Function Loss: 0.07095

Mean KL Divergence: 0.00739
SB3 Clip Fraction: 0.08299
Policy Update Magnitude: 0.18440
Value Function Update Magnitude: 0.38572

Collected Steps per Second: 21,876.81564
Overall Steps per Second: 14,631.74347

Timestep Collection Time: 2.28690
Timestep Consumption Time: 1.13238
PPO Batch Consumption Time: 0.09433
Total Iteration Time: 3.41928

Cumulative Model Updates: 56,852
Cumulative Timesteps: 474,331,730

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,212.99968
Policy Entropy: 0.93083
Value Function Loss: 0.07276

Mean KL Divergence: 0.00602
SB3 Clip Fraction: 0.06971
Policy Update Magnitude: 0.17974
Value Function Update Magnitude: 0.38730

Collected Steps per Second: 22,146.60493
Overall Steps per Second: 14,781.11609

Timestep Collection Time: 2.25777
Timestep Consumption Time: 1.12506
PPO Batch Consumption Time: 0.09716
Total Iteration Time: 3.38283

Cumulative Model Updates: 56,858
Cumulative Timesteps: 474,381,732

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 474381732...
Checkpoint 474381732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,693.07987
Policy Entropy: 0.93484
Value Function Loss: 0.07230

Mean KL Divergence: 0.00542
SB3 Clip Fraction: 0.06445
Policy Update Magnitude: 0.18795
Value Function Update Magnitude: 0.38947

Collected Steps per Second: 21,249.76780
Overall Steps per Second: 14,142.05978

Timestep Collection Time: 2.35353
Timestep Consumption Time: 1.18287
PPO Batch Consumption Time: 0.10339
Total Iteration Time: 3.53640

Cumulative Model Updates: 56,864
Cumulative Timesteps: 474,431,744

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,436.48327
Policy Entropy: 0.92172
Value Function Loss: 0.07766

Mean KL Divergence: 0.00432
SB3 Clip Fraction: 0.05226
Policy Update Magnitude: 0.19524
Value Function Update Magnitude: 0.39524

Collected Steps per Second: 21,673.35964
Overall Steps per Second: 14,573.23761

Timestep Collection Time: 2.30772
Timestep Consumption Time: 1.12433
PPO Batch Consumption Time: 0.09426
Total Iteration Time: 3.43204

Cumulative Model Updates: 56,870
Cumulative Timesteps: 474,481,760

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 474481760...
Checkpoint 474481760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,410.69350
Policy Entropy: 0.93289
Value Function Loss: 0.07833

Mean KL Divergence: 0.00468
SB3 Clip Fraction: 0.05791
Policy Update Magnitude: 0.20504
Value Function Update Magnitude: 0.40783

Collected Steps per Second: 22,077.37112
Overall Steps per Second: 14,823.12762

Timestep Collection Time: 2.26476
Timestep Consumption Time: 1.10834
PPO Batch Consumption Time: 0.09090
Total Iteration Time: 3.37311

Cumulative Model Updates: 56,876
Cumulative Timesteps: 474,531,760

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,920.22176
Policy Entropy: 0.92905
Value Function Loss: 0.08562

Mean KL Divergence: 0.00502
SB3 Clip Fraction: 0.06031
Policy Update Magnitude: 0.21003
Value Function Update Magnitude: 0.41671

Collected Steps per Second: 22,124.30180
Overall Steps per Second: 14,808.89545

Timestep Collection Time: 2.26122
Timestep Consumption Time: 1.11702
PPO Batch Consumption Time: 0.09456
Total Iteration Time: 3.37824

Cumulative Model Updates: 56,882
Cumulative Timesteps: 474,581,788

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 474581788...
Checkpoint 474581788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,085.82179
Policy Entropy: 0.94000
Value Function Loss: 0.08728

Mean KL Divergence: 0.00458
SB3 Clip Fraction: 0.05433
Policy Update Magnitude: 0.21243
Value Function Update Magnitude: 0.43143

Collected Steps per Second: 21,809.46925
Overall Steps per Second: 14,431.40473

Timestep Collection Time: 2.29387
Timestep Consumption Time: 1.17274
PPO Batch Consumption Time: 0.10051
Total Iteration Time: 3.46661

Cumulative Model Updates: 56,888
Cumulative Timesteps: 474,631,816

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,854.99427
Policy Entropy: 0.93059
Value Function Loss: 0.08965

Mean KL Divergence: 0.00425
SB3 Clip Fraction: 0.05101
Policy Update Magnitude: 0.22584
Value Function Update Magnitude: 0.42428

Collected Steps per Second: 22,459.69126
Overall Steps per Second: 14,748.26216

Timestep Collection Time: 2.22772
Timestep Consumption Time: 1.16481
PPO Batch Consumption Time: 0.09959
Total Iteration Time: 3.39254

Cumulative Model Updates: 56,894
Cumulative Timesteps: 474,681,850

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 474681850...
Checkpoint 474681850 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,284.65208
Policy Entropy: 0.92378
Value Function Loss: 0.08306

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.08692
Policy Update Magnitude: 0.21065
Value Function Update Magnitude: 0.42659

Collected Steps per Second: 21,246.55125
Overall Steps per Second: 14,370.34106

Timestep Collection Time: 2.35502
Timestep Consumption Time: 1.12688
PPO Batch Consumption Time: 0.09096
Total Iteration Time: 3.48189

Cumulative Model Updates: 56,900
Cumulative Timesteps: 474,731,886

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,350.54547
Policy Entropy: 0.92679
Value Function Loss: 0.08526

Mean KL Divergence: 0.00729
SB3 Clip Fraction: 0.07964
Policy Update Magnitude: 0.20241
Value Function Update Magnitude: 0.42468

Collected Steps per Second: 22,524.19108
Overall Steps per Second: 14,786.88921

Timestep Collection Time: 2.22046
Timestep Consumption Time: 1.16186
PPO Batch Consumption Time: 0.09414
Total Iteration Time: 3.38232

Cumulative Model Updates: 56,906
Cumulative Timesteps: 474,781,900

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 474781900...
Checkpoint 474781900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,240.38892
Policy Entropy: 0.93358
Value Function Loss: 0.07656

Mean KL Divergence: 0.00591
SB3 Clip Fraction: 0.06818
Policy Update Magnitude: 0.21625
Value Function Update Magnitude: 0.43351

Collected Steps per Second: 22,086.13513
Overall Steps per Second: 14,865.24916

Timestep Collection Time: 2.26450
Timestep Consumption Time: 1.09999
PPO Batch Consumption Time: 0.09213
Total Iteration Time: 3.36449

Cumulative Model Updates: 56,912
Cumulative Timesteps: 474,831,914

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,783.83036
Policy Entropy: 0.95428
Value Function Loss: 0.07838

Mean KL Divergence: 0.00450
SB3 Clip Fraction: 0.05316
Policy Update Magnitude: 0.21493
Value Function Update Magnitude: 0.41603

Collected Steps per Second: 22,170.97841
Overall Steps per Second: 14,405.63590

Timestep Collection Time: 2.25601
Timestep Consumption Time: 1.21610
PPO Batch Consumption Time: 0.10082
Total Iteration Time: 3.47211

Cumulative Model Updates: 56,918
Cumulative Timesteps: 474,881,932

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 474881932...
Checkpoint 474881932 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,855.01562
Policy Entropy: 0.96037
Value Function Loss: 0.07953

Mean KL Divergence: 0.00461
SB3 Clip Fraction: 0.05538
Policy Update Magnitude: 0.20526
Value Function Update Magnitude: 0.39328

Collected Steps per Second: 22,723.53060
Overall Steps per Second: 14,508.94705

Timestep Collection Time: 2.20159
Timestep Consumption Time: 1.24648
PPO Batch Consumption Time: 0.10207
Total Iteration Time: 3.44808

Cumulative Model Updates: 56,924
Cumulative Timesteps: 474,931,960

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,278.87233
Policy Entropy: 0.95017
Value Function Loss: 0.08152

Mean KL Divergence: 0.00392
SB3 Clip Fraction: 0.04865
Policy Update Magnitude: 0.20125
Value Function Update Magnitude: 0.37286

Collected Steps per Second: 22,995.06731
Overall Steps per Second: 14,775.61851

Timestep Collection Time: 2.17603
Timestep Consumption Time: 1.21049
PPO Batch Consumption Time: 0.10269
Total Iteration Time: 3.38652

Cumulative Model Updates: 56,930
Cumulative Timesteps: 474,981,998

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 474981998...
Checkpoint 474981998 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,029.66250
Policy Entropy: 0.93657
Value Function Loss: 0.08193

Mean KL Divergence: 0.00410
SB3 Clip Fraction: 0.05030
Policy Update Magnitude: 0.19688
Value Function Update Magnitude: 0.37482

Collected Steps per Second: 22,188.11935
Overall Steps per Second: 14,657.18431

Timestep Collection Time: 2.25364
Timestep Consumption Time: 1.15793
PPO Batch Consumption Time: 0.09383
Total Iteration Time: 3.41157

Cumulative Model Updates: 56,936
Cumulative Timesteps: 475,032,002

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,126.84239
Policy Entropy: 0.92559
Value Function Loss: 0.07283

Mean KL Divergence: 0.00344
SB3 Clip Fraction: 0.04143
Policy Update Magnitude: 0.19305
Value Function Update Magnitude: 0.38214

Collected Steps per Second: 23,041.98834
Overall Steps per Second: 14,841.43967

Timestep Collection Time: 2.17099
Timestep Consumption Time: 1.19957
PPO Batch Consumption Time: 0.10138
Total Iteration Time: 3.37056

Cumulative Model Updates: 56,942
Cumulative Timesteps: 475,082,026

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 475082026...
Checkpoint 475082026 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,056.70341
Policy Entropy: 0.91216
Value Function Loss: 0.07041

Mean KL Divergence: 0.00333
SB3 Clip Fraction: 0.03999
Policy Update Magnitude: 0.19890
Value Function Update Magnitude: 0.37477

Collected Steps per Second: 22,984.84326
Overall Steps per Second: 14,709.03676

Timestep Collection Time: 2.17552
Timestep Consumption Time: 1.22402
PPO Batch Consumption Time: 0.10450
Total Iteration Time: 3.39954

Cumulative Model Updates: 56,948
Cumulative Timesteps: 475,132,030

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,255.24245
Policy Entropy: 0.91773
Value Function Loss: 0.06443

Mean KL Divergence: 0.00381
SB3 Clip Fraction: 0.04700
Policy Update Magnitude: 0.20139
Value Function Update Magnitude: 0.38103

Collected Steps per Second: 22,509.91644
Overall Steps per Second: 14,614.07835

Timestep Collection Time: 2.22187
Timestep Consumption Time: 1.20045
PPO Batch Consumption Time: 0.09698
Total Iteration Time: 3.42232

Cumulative Model Updates: 56,954
Cumulative Timesteps: 475,182,044

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 475182044...
Checkpoint 475182044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,250.42267
Policy Entropy: 0.92028
Value Function Loss: 0.07315

Mean KL Divergence: 0.00452
SB3 Clip Fraction: 0.05542
Policy Update Magnitude: 0.20636
Value Function Update Magnitude: 0.38988

Collected Steps per Second: 22,515.26244
Overall Steps per Second: 14,383.52568

Timestep Collection Time: 2.22152
Timestep Consumption Time: 1.25594
PPO Batch Consumption Time: 0.10408
Total Iteration Time: 3.47745

Cumulative Model Updates: 56,960
Cumulative Timesteps: 475,232,062

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,860.70385
Policy Entropy: 0.92455
Value Function Loss: 0.07305

Mean KL Divergence: 0.00436
SB3 Clip Fraction: 0.05174
Policy Update Magnitude: 0.20001
Value Function Update Magnitude: 0.40674

Collected Steps per Second: 23,270.91719
Overall Steps per Second: 14,708.09661

Timestep Collection Time: 2.14878
Timestep Consumption Time: 1.25098
PPO Batch Consumption Time: 0.10258
Total Iteration Time: 3.39976

Cumulative Model Updates: 56,966
Cumulative Timesteps: 475,282,066

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 475282066...
Checkpoint 475282066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,776.47780
Policy Entropy: 0.93226
Value Function Loss: 0.07646

Mean KL Divergence: 0.00638
SB3 Clip Fraction: 0.06897
Policy Update Magnitude: 0.19022
Value Function Update Magnitude: 0.39079

Collected Steps per Second: 22,323.28216
Overall Steps per Second: 14,610.04898

Timestep Collection Time: 2.24107
Timestep Consumption Time: 1.18315
PPO Batch Consumption Time: 0.09210
Total Iteration Time: 3.42422

Cumulative Model Updates: 56,972
Cumulative Timesteps: 475,332,094

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,234.48368
Policy Entropy: 0.92630
Value Function Loss: 0.07351

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.08347
Policy Update Magnitude: 0.16902
Value Function Update Magnitude: 0.37232

Collected Steps per Second: 22,970.98443
Overall Steps per Second: 14,800.61368

Timestep Collection Time: 2.17666
Timestep Consumption Time: 1.20158
PPO Batch Consumption Time: 0.09765
Total Iteration Time: 3.37824

Cumulative Model Updates: 56,978
Cumulative Timesteps: 475,382,094

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 475382094...
Checkpoint 475382094 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,017.63011
Policy Entropy: 0.92802
Value Function Loss: 0.07515

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.08405
Policy Update Magnitude: 0.16531
Value Function Update Magnitude: 0.37268

Collected Steps per Second: 22,323.09476
Overall Steps per Second: 14,526.48530

Timestep Collection Time: 2.23992
Timestep Consumption Time: 1.20220
PPO Batch Consumption Time: 0.10086
Total Iteration Time: 3.44213

Cumulative Model Updates: 56,984
Cumulative Timesteps: 475,432,096

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,624.17790
Policy Entropy: 0.91930
Value Function Loss: 0.08346

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.07808
Policy Update Magnitude: 0.16857
Value Function Update Magnitude: 0.40173

Collected Steps per Second: 22,532.75644
Overall Steps per Second: 14,384.76783

Timestep Collection Time: 2.21926
Timestep Consumption Time: 1.25706
PPO Batch Consumption Time: 0.10321
Total Iteration Time: 3.47632

Cumulative Model Updates: 56,990
Cumulative Timesteps: 475,482,102

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 475482102...
Checkpoint 475482102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,079.24042
Policy Entropy: 0.90707
Value Function Loss: 0.08124

Mean KL Divergence: 0.00592
SB3 Clip Fraction: 0.06197
Policy Update Magnitude: 0.18448
Value Function Update Magnitude: 0.42588

Collected Steps per Second: 22,559.89896
Overall Steps per Second: 14,630.92417

Timestep Collection Time: 2.21685
Timestep Consumption Time: 1.20139
PPO Batch Consumption Time: 0.09198
Total Iteration Time: 3.41824

Cumulative Model Updates: 56,996
Cumulative Timesteps: 475,532,114

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,355.97874
Policy Entropy: 0.89446
Value Function Loss: 0.07889

Mean KL Divergence: 0.00447
SB3 Clip Fraction: 0.05095
Policy Update Magnitude: 0.20221
Value Function Update Magnitude: 0.41994

Collected Steps per Second: 22,718.80273
Overall Steps per Second: 14,764.41668

Timestep Collection Time: 2.20108
Timestep Consumption Time: 1.18584
PPO Batch Consumption Time: 0.09249
Total Iteration Time: 3.38693

Cumulative Model Updates: 57,002
Cumulative Timesteps: 475,582,120

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 475582120...
Checkpoint 475582120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,466.16905
Policy Entropy: 0.90026
Value Function Loss: 0.07708

Mean KL Divergence: 0.00355
SB3 Clip Fraction: 0.04316
Policy Update Magnitude: 0.21108
Value Function Update Magnitude: 0.40947

Collected Steps per Second: 21,078.40730
Overall Steps per Second: 14,005.57478

Timestep Collection Time: 2.37229
Timestep Consumption Time: 1.19801
PPO Batch Consumption Time: 0.09484
Total Iteration Time: 3.57029

Cumulative Model Updates: 57,008
Cumulative Timesteps: 475,632,124

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,965.07019
Policy Entropy: 0.90693
Value Function Loss: 0.06853

Mean KL Divergence: 0.00384
SB3 Clip Fraction: 0.04706
Policy Update Magnitude: 0.19504
Value Function Update Magnitude: 0.38823

Collected Steps per Second: 23,040.26955
Overall Steps per Second: 14,847.75880

Timestep Collection Time: 2.17011
Timestep Consumption Time: 1.19740
PPO Batch Consumption Time: 0.09697
Total Iteration Time: 3.36751

Cumulative Model Updates: 57,014
Cumulative Timesteps: 475,682,124

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 475682124...
Checkpoint 475682124 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,958.44031
Policy Entropy: 0.92093
Value Function Loss: 0.06437

Mean KL Divergence: 0.00366
SB3 Clip Fraction: 0.04413
Policy Update Magnitude: 0.19436
Value Function Update Magnitude: 0.36832

Collected Steps per Second: 21,813.70633
Overall Steps per Second: 14,153.81187

Timestep Collection Time: 2.29305
Timestep Consumption Time: 1.24098
PPO Batch Consumption Time: 0.10316
Total Iteration Time: 3.53403

Cumulative Model Updates: 57,020
Cumulative Timesteps: 475,732,144

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,676.67999
Policy Entropy: 0.92784
Value Function Loss: 0.05985

Mean KL Divergence: 0.00367
SB3 Clip Fraction: 0.04348
Policy Update Magnitude: 0.19011
Value Function Update Magnitude: 0.33086

Collected Steps per Second: 22,877.33338
Overall Steps per Second: 14,656.02407

Timestep Collection Time: 2.18592
Timestep Consumption Time: 1.22619
PPO Batch Consumption Time: 0.09956
Total Iteration Time: 3.41211

Cumulative Model Updates: 57,026
Cumulative Timesteps: 475,782,152

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 475782152...
Checkpoint 475782152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,920.35747
Policy Entropy: 0.92923
Value Function Loss: 0.06396

Mean KL Divergence: 0.00363
SB3 Clip Fraction: 0.04264
Policy Update Magnitude: 0.18420
Value Function Update Magnitude: 0.29084

Collected Steps per Second: 23,218.38959
Overall Steps per Second: 14,831.39560

Timestep Collection Time: 2.15467
Timestep Consumption Time: 1.21844
PPO Batch Consumption Time: 0.09787
Total Iteration Time: 3.37311

Cumulative Model Updates: 57,032
Cumulative Timesteps: 475,832,180

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,862.62025
Policy Entropy: 0.92482
Value Function Loss: 0.06832

Mean KL Divergence: 0.00371
SB3 Clip Fraction: 0.04433
Policy Update Magnitude: 0.18395
Value Function Update Magnitude: 0.29612

Collected Steps per Second: 22,746.69762
Overall Steps per Second: 14,698.04986

Timestep Collection Time: 2.19856
Timestep Consumption Time: 1.20393
PPO Batch Consumption Time: 0.09703
Total Iteration Time: 3.40249

Cumulative Model Updates: 57,038
Cumulative Timesteps: 475,882,190

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 475882190...
Checkpoint 475882190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,073.98471
Policy Entropy: 0.93445
Value Function Loss: 0.07410

Mean KL Divergence: 0.00481
SB3 Clip Fraction: 0.05597
Policy Update Magnitude: 0.18474
Value Function Update Magnitude: 0.33954

Collected Steps per Second: 22,506.61951
Overall Steps per Second: 14,199.37181

Timestep Collection Time: 2.22237
Timestep Consumption Time: 1.30018
PPO Batch Consumption Time: 0.10324
Total Iteration Time: 3.52255

Cumulative Model Updates: 57,044
Cumulative Timesteps: 475,932,208

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,744.85669
Policy Entropy: 0.94249
Value Function Loss: 0.07782

Mean KL Divergence: 0.00442
SB3 Clip Fraction: 0.05482
Policy Update Magnitude: 0.18699
Value Function Update Magnitude: 0.36441

Collected Steps per Second: 22,665.17880
Overall Steps per Second: 14,625.95556

Timestep Collection Time: 2.20612
Timestep Consumption Time: 1.21260
PPO Batch Consumption Time: 0.09937
Total Iteration Time: 3.41872

Cumulative Model Updates: 57,050
Cumulative Timesteps: 475,982,210

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 475982210...
Checkpoint 475982210 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,773.74338
Policy Entropy: 0.95394
Value Function Loss: 0.07112

Mean KL Divergence: 0.00452
SB3 Clip Fraction: 0.05370
Policy Update Magnitude: 0.18423
Value Function Update Magnitude: 0.36547

Collected Steps per Second: 22,472.42185
Overall Steps per Second: 14,707.75466

Timestep Collection Time: 2.22637
Timestep Consumption Time: 1.17537
PPO Batch Consumption Time: 0.09221
Total Iteration Time: 3.40174

Cumulative Model Updates: 57,056
Cumulative Timesteps: 476,032,242

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,170.32738
Policy Entropy: 0.94108
Value Function Loss: 0.06450

Mean KL Divergence: 0.00465
SB3 Clip Fraction: 0.05621
Policy Update Magnitude: 0.17774
Value Function Update Magnitude: 0.33949

Collected Steps per Second: 23,024.15967
Overall Steps per Second: 14,800.16595

Timestep Collection Time: 2.17267
Timestep Consumption Time: 1.20729
PPO Batch Consumption Time: 0.09455
Total Iteration Time: 3.37996

Cumulative Model Updates: 57,062
Cumulative Timesteps: 476,082,266

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 476082266...
Checkpoint 476082266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,375.96666
Policy Entropy: 0.94782
Value Function Loss: 0.05798

Mean KL Divergence: 0.00395
SB3 Clip Fraction: 0.04776
Policy Update Magnitude: 0.17557
Value Function Update Magnitude: 0.33095

Collected Steps per Second: 21,939.44058
Overall Steps per Second: 14,269.61044

Timestep Collection Time: 2.27964
Timestep Consumption Time: 1.22529
PPO Batch Consumption Time: 0.10132
Total Iteration Time: 3.50493

Cumulative Model Updates: 57,068
Cumulative Timesteps: 476,132,280

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,430.73577
Policy Entropy: 0.94270
Value Function Loss: 0.06525

Mean KL Divergence: 0.00353
SB3 Clip Fraction: 0.04262
Policy Update Magnitude: 0.18008
Value Function Update Magnitude: 0.33310

Collected Steps per Second: 20,634.61550
Overall Steps per Second: 13,634.07564

Timestep Collection Time: 2.42408
Timestep Consumption Time: 1.24467
PPO Batch Consumption Time: 0.09418
Total Iteration Time: 3.66875

Cumulative Model Updates: 57,074
Cumulative Timesteps: 476,182,300

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 476182300...
Checkpoint 476182300 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,481.19380
Policy Entropy: 0.94781
Value Function Loss: 0.06582

Mean KL Divergence: 0.00431
SB3 Clip Fraction: 0.05088
Policy Update Magnitude: 0.18817
Value Function Update Magnitude: 0.33783

Collected Steps per Second: 22,485.69083
Overall Steps per Second: 14,380.63089

Timestep Collection Time: 2.22408
Timestep Consumption Time: 1.25351
PPO Batch Consumption Time: 0.10170
Total Iteration Time: 3.47759

Cumulative Model Updates: 57,080
Cumulative Timesteps: 476,232,310

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,242.85363
Policy Entropy: 0.94641
Value Function Loss: 0.06951

Mean KL Divergence: 0.00427
SB3 Clip Fraction: 0.05171
Policy Update Magnitude: 0.19507
Value Function Update Magnitude: 0.34960

Collected Steps per Second: 23,473.78280
Overall Steps per Second: 14,959.92512

Timestep Collection Time: 2.13021
Timestep Consumption Time: 1.21232
PPO Batch Consumption Time: 0.10020
Total Iteration Time: 3.34253

Cumulative Model Updates: 57,086
Cumulative Timesteps: 476,282,314

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 476282314...
Checkpoint 476282314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,878.03566
Policy Entropy: 0.94638
Value Function Loss: 0.06652

Mean KL Divergence: 0.00357
SB3 Clip Fraction: 0.04302
Policy Update Magnitude: 0.19111
Value Function Update Magnitude: 0.36577

Collected Steps per Second: 21,823.03820
Overall Steps per Second: 14,477.72271

Timestep Collection Time: 2.29216
Timestep Consumption Time: 1.16294
PPO Batch Consumption Time: 0.10163
Total Iteration Time: 3.45510

Cumulative Model Updates: 57,092
Cumulative Timesteps: 476,332,336

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,088.51760
Policy Entropy: 0.94812
Value Function Loss: 0.07299

Mean KL Divergence: 0.00337
SB3 Clip Fraction: 0.04037
Policy Update Magnitude: 0.19440
Value Function Update Magnitude: 0.39193

Collected Steps per Second: 22,648.36034
Overall Steps per Second: 14,720.93368

Timestep Collection Time: 2.20855
Timestep Consumption Time: 1.18933
PPO Batch Consumption Time: 0.10060
Total Iteration Time: 3.39788

Cumulative Model Updates: 57,098
Cumulative Timesteps: 476,382,356

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 476382356...
Checkpoint 476382356 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,663.07296
Policy Entropy: 0.93818
Value Function Loss: 0.07214

Mean KL Divergence: 0.00403
SB3 Clip Fraction: 0.04979
Policy Update Magnitude: 0.19746
Value Function Update Magnitude: 0.40525

Collected Steps per Second: 22,027.10094
Overall Steps per Second: 14,724.86875

Timestep Collection Time: 2.27102
Timestep Consumption Time: 1.12623
PPO Batch Consumption Time: 0.09661
Total Iteration Time: 3.39725

Cumulative Model Updates: 57,104
Cumulative Timesteps: 476,432,380

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,187.82139
Policy Entropy: 0.94047
Value Function Loss: 0.07051

Mean KL Divergence: 0.00540
SB3 Clip Fraction: 0.06365
Policy Update Magnitude: 0.19466
Value Function Update Magnitude: 0.41004

Collected Steps per Second: 22,064.04821
Overall Steps per Second: 14,736.40626

Timestep Collection Time: 2.26667
Timestep Consumption Time: 1.12710
PPO Batch Consumption Time: 0.09441
Total Iteration Time: 3.39377

Cumulative Model Updates: 57,110
Cumulative Timesteps: 476,482,392

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 476482392...
Checkpoint 476482392 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,083.55589
Policy Entropy: 0.93993
Value Function Loss: 0.06308

Mean KL Divergence: 0.00646
SB3 Clip Fraction: 0.07292
Policy Update Magnitude: 0.19371
Value Function Update Magnitude: 0.39919

Collected Steps per Second: 22,046.63175
Overall Steps per Second: 14,413.09413

Timestep Collection Time: 2.26828
Timestep Consumption Time: 1.20134
PPO Batch Consumption Time: 0.10112
Total Iteration Time: 3.46962

Cumulative Model Updates: 57,116
Cumulative Timesteps: 476,532,400

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,594.44788
Policy Entropy: 0.94958
Value Function Loss: 0.06479

Mean KL Divergence: 0.00484
SB3 Clip Fraction: 0.05762
Policy Update Magnitude: 0.19307
Value Function Update Magnitude: 0.39780

Collected Steps per Second: 21,152.97549
Overall Steps per Second: 14,337.81493

Timestep Collection Time: 2.36402
Timestep Consumption Time: 1.12368
PPO Batch Consumption Time: 0.09616
Total Iteration Time: 3.48770

Cumulative Model Updates: 57,122
Cumulative Timesteps: 476,582,406

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 476582406...
Checkpoint 476582406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,305.56582
Policy Entropy: 0.94467
Value Function Loss: 0.06980

Mean KL Divergence: 0.00474
SB3 Clip Fraction: 0.05785
Policy Update Magnitude: 0.19824
Value Function Update Magnitude: 0.37964

Collected Steps per Second: 21,495.65505
Overall Steps per Second: 14,349.03836

Timestep Collection Time: 2.32745
Timestep Consumption Time: 1.15920
PPO Batch Consumption Time: 0.10130
Total Iteration Time: 3.48664

Cumulative Model Updates: 57,128
Cumulative Timesteps: 476,632,436

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,226.69704
Policy Entropy: 0.94621
Value Function Loss: 0.08595

Mean KL Divergence: 0.00563
SB3 Clip Fraction: 0.06561
Policy Update Magnitude: 0.21153
Value Function Update Magnitude: 0.41511

Collected Steps per Second: 22,769.68097
Overall Steps per Second: 14,890.50458

Timestep Collection Time: 2.19608
Timestep Consumption Time: 1.16203
PPO Batch Consumption Time: 0.10052
Total Iteration Time: 3.35811

Cumulative Model Updates: 57,134
Cumulative Timesteps: 476,682,440

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 476682440...
Checkpoint 476682440 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,327.27116
Policy Entropy: 0.95242
Value Function Loss: 0.08141

Mean KL Divergence: 0.00499
SB3 Clip Fraction: 0.05986
Policy Update Magnitude: 0.20680
Value Function Update Magnitude: 0.42903

Collected Steps per Second: 21,948.01157
Overall Steps per Second: 14,518.79951

Timestep Collection Time: 2.27811
Timestep Consumption Time: 1.16570
PPO Batch Consumption Time: 0.10147
Total Iteration Time: 3.44381

Cumulative Model Updates: 57,140
Cumulative Timesteps: 476,732,440

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,681.40159
Policy Entropy: 0.96056
Value Function Loss: 0.08337

Mean KL Divergence: 0.00491
SB3 Clip Fraction: 0.05954
Policy Update Magnitude: 0.20490
Value Function Update Magnitude: 0.41483

Collected Steps per Second: 21,991.40963
Overall Steps per Second: 14,567.95075

Timestep Collection Time: 2.27452
Timestep Consumption Time: 1.15904
PPO Batch Consumption Time: 0.09332
Total Iteration Time: 3.43356

Cumulative Model Updates: 57,146
Cumulative Timesteps: 476,782,460

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 476782460...
Checkpoint 476782460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,473.22906
Policy Entropy: 0.95058
Value Function Loss: 0.07199

Mean KL Divergence: 0.00446
SB3 Clip Fraction: 0.05394
Policy Update Magnitude: 0.20320
Value Function Update Magnitude: 0.42593

Collected Steps per Second: 23,117.62751
Overall Steps per Second: 14,905.47123

Timestep Collection Time: 2.16346
Timestep Consumption Time: 1.19195
PPO Batch Consumption Time: 0.09650
Total Iteration Time: 3.35541

Cumulative Model Updates: 57,152
Cumulative Timesteps: 476,832,474

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,298.02338
Policy Entropy: 0.94545
Value Function Loss: 0.07537

Mean KL Divergence: 0.00487
SB3 Clip Fraction: 0.05928
Policy Update Magnitude: 0.20452
Value Function Update Magnitude: 0.41380

Collected Steps per Second: 23,036.06875
Overall Steps per Second: 14,844.89348

Timestep Collection Time: 2.17120
Timestep Consumption Time: 1.19804
PPO Batch Consumption Time: 0.10008
Total Iteration Time: 3.36924

Cumulative Model Updates: 57,158
Cumulative Timesteps: 476,882,490

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 476882490...
Checkpoint 476882490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,243.24929
Policy Entropy: 0.94116
Value Function Loss: 0.07856

Mean KL Divergence: 0.00535
SB3 Clip Fraction: 0.06154
Policy Update Magnitude: 0.20779
Value Function Update Magnitude: 0.39854

Collected Steps per Second: 22,139.36806
Overall Steps per Second: 14,357.17412

Timestep Collection Time: 2.25896
Timestep Consumption Time: 1.22445
PPO Batch Consumption Time: 0.10291
Total Iteration Time: 3.48342

Cumulative Model Updates: 57,164
Cumulative Timesteps: 476,932,502

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,736.52647
Policy Entropy: 0.95552
Value Function Loss: 0.07638

Mean KL Divergence: 0.00650
SB3 Clip Fraction: 0.07452
Policy Update Magnitude: 0.19351
Value Function Update Magnitude: 0.39089

Collected Steps per Second: 22,871.73671
Overall Steps per Second: 14,804.64860

Timestep Collection Time: 2.18707
Timestep Consumption Time: 1.19174
PPO Batch Consumption Time: 0.09787
Total Iteration Time: 3.37880

Cumulative Model Updates: 57,170
Cumulative Timesteps: 476,982,524

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 476982524...
Checkpoint 476982524 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,162.26287
Policy Entropy: 0.96974
Value Function Loss: 0.08158

Mean KL Divergence: 0.00690
SB3 Clip Fraction: 0.07789
Policy Update Magnitude: 0.18435
Value Function Update Magnitude: 0.37226

Collected Steps per Second: 21,946.14267
Overall Steps per Second: 14,400.22861

Timestep Collection Time: 2.27830
Timestep Consumption Time: 1.19386
PPO Batch Consumption Time: 0.09684
Total Iteration Time: 3.47217

Cumulative Model Updates: 57,176
Cumulative Timesteps: 477,032,524

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,553.26772
Policy Entropy: 0.96040
Value Function Loss: 0.07541

Mean KL Divergence: 0.00591
SB3 Clip Fraction: 0.06577
Policy Update Magnitude: 0.19123
Value Function Update Magnitude: 0.36618

Collected Steps per Second: 22,988.33040
Overall Steps per Second: 14,674.73923

Timestep Collection Time: 2.17632
Timestep Consumption Time: 1.23294
PPO Batch Consumption Time: 0.09817
Total Iteration Time: 3.40926

Cumulative Model Updates: 57,182
Cumulative Timesteps: 477,082,554

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 477082554...
Checkpoint 477082554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,958.70282
Policy Entropy: 0.95963
Value Function Loss: 0.07769

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.07689
Policy Update Magnitude: 0.18042
Value Function Update Magnitude: 0.38139

Collected Steps per Second: 22,896.04530
Overall Steps per Second: 14,828.97900

Timestep Collection Time: 2.18439
Timestep Consumption Time: 1.18833
PPO Batch Consumption Time: 0.09382
Total Iteration Time: 3.37272

Cumulative Model Updates: 57,188
Cumulative Timesteps: 477,132,568

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,745.85718
Policy Entropy: 0.94237
Value Function Loss: 0.06780

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.07910
Policy Update Magnitude: 0.16291
Value Function Update Magnitude: 0.38542

Collected Steps per Second: 22,370.01493
Overall Steps per Second: 14,373.74891

Timestep Collection Time: 2.23594
Timestep Consumption Time: 1.24388
PPO Batch Consumption Time: 0.10162
Total Iteration Time: 3.47982

Cumulative Model Updates: 57,194
Cumulative Timesteps: 477,182,586

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 477182586...
Checkpoint 477182586 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,210.40537
Policy Entropy: 0.95042
Value Function Loss: 0.06698

Mean KL Divergence: 0.00562
SB3 Clip Fraction: 0.06288
Policy Update Magnitude: 0.17266
Value Function Update Magnitude: 0.37280

Collected Steps per Second: 22,445.38690
Overall Steps per Second: 14,431.53051

Timestep Collection Time: 2.22879
Timestep Consumption Time: 1.23765
PPO Batch Consumption Time: 0.09652
Total Iteration Time: 3.46644

Cumulative Model Updates: 57,200
Cumulative Timesteps: 477,232,612

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,795.26536
Policy Entropy: 0.96007
Value Function Loss: 0.07095

Mean KL Divergence: 0.00548
SB3 Clip Fraction: 0.06144
Policy Update Magnitude: 0.18693
Value Function Update Magnitude: 0.37278

Collected Steps per Second: 22,982.28440
Overall Steps per Second: 14,753.63666

Timestep Collection Time: 2.17568
Timestep Consumption Time: 1.21345
PPO Batch Consumption Time: 0.09846
Total Iteration Time: 3.38913

Cumulative Model Updates: 57,206
Cumulative Timesteps: 477,282,614

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 477282614...
Checkpoint 477282614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,856.26167
Policy Entropy: 0.96373
Value Function Loss: 0.07192

Mean KL Divergence: 0.00496
SB3 Clip Fraction: 0.05788
Policy Update Magnitude: 0.19123
Value Function Update Magnitude: 0.36766

Collected Steps per Second: 22,461.59237
Overall Steps per Second: 14,359.46361

Timestep Collection Time: 2.22656
Timestep Consumption Time: 1.25630
PPO Batch Consumption Time: 0.10085
Total Iteration Time: 3.48286

Cumulative Model Updates: 57,212
Cumulative Timesteps: 477,332,626

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,238.32720
Policy Entropy: 0.94774
Value Function Loss: 0.06972

Mean KL Divergence: 0.00465
SB3 Clip Fraction: 0.05237
Policy Update Magnitude: 0.18722
Value Function Update Magnitude: 0.35783

Collected Steps per Second: 22,886.98840
Overall Steps per Second: 14,543.02479

Timestep Collection Time: 2.18535
Timestep Consumption Time: 1.25383
PPO Batch Consumption Time: 0.10192
Total Iteration Time: 3.43917

Cumulative Model Updates: 57,218
Cumulative Timesteps: 477,382,642

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 477382642...
Checkpoint 477382642 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,067.01683
Policy Entropy: 0.93718
Value Function Loss: 0.07255

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.08452
Policy Update Magnitude: 0.17262
Value Function Update Magnitude: 0.35922

Collected Steps per Second: 22,725.90096
Overall Steps per Second: 14,638.89658

Timestep Collection Time: 2.20022
Timestep Consumption Time: 1.21547
PPO Batch Consumption Time: 0.09453
Total Iteration Time: 3.41569

Cumulative Model Updates: 57,224
Cumulative Timesteps: 477,432,644

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,066.34416
Policy Entropy: 0.93468
Value Function Loss: 0.06954

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.07896
Policy Update Magnitude: 0.16908
Value Function Update Magnitude: 0.38638

Collected Steps per Second: 22,553.60494
Overall Steps per Second: 14,704.95080

Timestep Collection Time: 2.21809
Timestep Consumption Time: 1.18389
PPO Batch Consumption Time: 0.09179
Total Iteration Time: 3.40198

Cumulative Model Updates: 57,230
Cumulative Timesteps: 477,482,670

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 477482670...
Checkpoint 477482670 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,634.27248
Policy Entropy: 0.93997
Value Function Loss: 0.07377

Mean KL Divergence: 0.00713
SB3 Clip Fraction: 0.06803
Policy Update Magnitude: 0.17715
Value Function Update Magnitude: 0.38504

Collected Steps per Second: 22,765.82720
Overall Steps per Second: 14,442.87392

Timestep Collection Time: 2.19654
Timestep Consumption Time: 1.26579
PPO Batch Consumption Time: 0.10092
Total Iteration Time: 3.46233

Cumulative Model Updates: 57,236
Cumulative Timesteps: 477,532,676

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,053.31566
Policy Entropy: 0.94089
Value Function Loss: 0.06658

Mean KL Divergence: 0.00614
SB3 Clip Fraction: 0.06200
Policy Update Magnitude: 0.18848
Value Function Update Magnitude: 0.35869

Collected Steps per Second: 23,335.42044
Overall Steps per Second: 14,805.20383

Timestep Collection Time: 2.14284
Timestep Consumption Time: 1.23462
PPO Batch Consumption Time: 0.09980
Total Iteration Time: 3.37746

Cumulative Model Updates: 57,242
Cumulative Timesteps: 477,582,680

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 477582680...
Checkpoint 477582680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,632.85154
Policy Entropy: 0.95342
Value Function Loss: 0.07573

Mean KL Divergence: 0.00535
SB3 Clip Fraction: 0.05873
Policy Update Magnitude: 0.19093
Value Function Update Magnitude: 0.32173

Collected Steps per Second: 21,947.37333
Overall Steps per Second: 14,380.38661

Timestep Collection Time: 2.27936
Timestep Consumption Time: 1.19940
PPO Batch Consumption Time: 0.09552
Total Iteration Time: 3.47877

Cumulative Model Updates: 57,248
Cumulative Timesteps: 477,632,706

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,351.64725
Policy Entropy: 0.96113
Value Function Loss: 0.07734

Mean KL Divergence: 0.00511
SB3 Clip Fraction: 0.05859
Policy Update Magnitude: 0.19550
Value Function Update Magnitude: 0.37602

Collected Steps per Second: 23,416.93334
Overall Steps per Second: 14,785.55128

Timestep Collection Time: 2.13623
Timestep Consumption Time: 1.24707
PPO Batch Consumption Time: 0.09806
Total Iteration Time: 3.38330

Cumulative Model Updates: 57,254
Cumulative Timesteps: 477,682,730

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 477682730...
Checkpoint 477682730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,306.73669
Policy Entropy: 0.95319
Value Function Loss: 0.07955

Mean KL Divergence: 0.00478
SB3 Clip Fraction: 0.05799
Policy Update Magnitude: 0.19692
Value Function Update Magnitude: 0.36950

Collected Steps per Second: 22,948.90281
Overall Steps per Second: 14,827.30485

Timestep Collection Time: 2.17945
Timestep Consumption Time: 1.19379
PPO Batch Consumption Time: 0.09456
Total Iteration Time: 3.37324

Cumulative Model Updates: 57,260
Cumulative Timesteps: 477,732,746

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,505.95503
Policy Entropy: 0.94448
Value Function Loss: 0.07144

Mean KL Divergence: 0.00370
SB3 Clip Fraction: 0.04481
Policy Update Magnitude: 0.20066
Value Function Update Magnitude: 0.36398

Collected Steps per Second: 22,554.53521
Overall Steps per Second: 14,702.31949

Timestep Collection Time: 2.21703
Timestep Consumption Time: 1.18407
PPO Batch Consumption Time: 0.09289
Total Iteration Time: 3.40110

Cumulative Model Updates: 57,266
Cumulative Timesteps: 477,782,750

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 477782750...
Checkpoint 477782750 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,294.79928
Policy Entropy: 0.94196
Value Function Loss: 0.06837

Mean KL Divergence: 0.00381
SB3 Clip Fraction: 0.04456
Policy Update Magnitude: 0.19361
Value Function Update Magnitude: 0.38219

Collected Steps per Second: 22,871.31318
Overall Steps per Second: 14,526.73418

Timestep Collection Time: 2.18711
Timestep Consumption Time: 1.25634
PPO Batch Consumption Time: 0.10241
Total Iteration Time: 3.44344

Cumulative Model Updates: 57,272
Cumulative Timesteps: 477,832,772

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,656.35436
Policy Entropy: 0.94708
Value Function Loss: 0.06951

Mean KL Divergence: 0.00543
SB3 Clip Fraction: 0.05954
Policy Update Magnitude: 0.18722
Value Function Update Magnitude: 0.37869

Collected Steps per Second: 23,234.40111
Overall Steps per Second: 15,072.24332

Timestep Collection Time: 2.15215
Timestep Consumption Time: 1.16547
PPO Batch Consumption Time: 0.09426
Total Iteration Time: 3.31762

Cumulative Model Updates: 57,278
Cumulative Timesteps: 477,882,776

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 477882776...
Checkpoint 477882776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,630.77358
Policy Entropy: 0.96215
Value Function Loss: 0.06958

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.07748
Policy Update Magnitude: 0.17654
Value Function Update Magnitude: 0.35639

Collected Steps per Second: 21,872.77518
Overall Steps per Second: 14,115.30948

Timestep Collection Time: 2.28768
Timestep Consumption Time: 1.25726
PPO Batch Consumption Time: 0.10409
Total Iteration Time: 3.54495

Cumulative Model Updates: 57,284
Cumulative Timesteps: 477,932,814

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,799.57225
Policy Entropy: 0.96303
Value Function Loss: 0.06955

Mean KL Divergence: 0.00651
SB3 Clip Fraction: 0.06463
Policy Update Magnitude: 0.18444
Value Function Update Magnitude: 0.37279

Collected Steps per Second: 23,212.46994
Overall Steps per Second: 14,835.71387

Timestep Collection Time: 2.15453
Timestep Consumption Time: 1.21652
PPO Batch Consumption Time: 0.10236
Total Iteration Time: 3.37105

Cumulative Model Updates: 57,290
Cumulative Timesteps: 477,982,826

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 477982826...
Checkpoint 477982826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,385.11907
Policy Entropy: 0.96120
Value Function Loss: 0.06943

Mean KL Divergence: 0.00512
SB3 Clip Fraction: 0.05797
Policy Update Magnitude: 0.18804
Value Function Update Magnitude: 0.34728

Collected Steps per Second: 22,894.32280
Overall Steps per Second: 14,781.60112

Timestep Collection Time: 2.18403
Timestep Consumption Time: 1.19868
PPO Batch Consumption Time: 0.09740
Total Iteration Time: 3.38272

Cumulative Model Updates: 57,296
Cumulative Timesteps: 478,032,828

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,044.63252
Policy Entropy: 0.94617
Value Function Loss: 0.06892

Mean KL Divergence: 0.00420
SB3 Clip Fraction: 0.04909
Policy Update Magnitude: 0.18926
Value Function Update Magnitude: 0.35923

Collected Steps per Second: 22,491.22778
Overall Steps per Second: 14,634.31897

Timestep Collection Time: 2.22478
Timestep Consumption Time: 1.19444
PPO Batch Consumption Time: 0.09298
Total Iteration Time: 3.41922

Cumulative Model Updates: 57,302
Cumulative Timesteps: 478,082,866

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 478082866...
Checkpoint 478082866 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,896.63243
Policy Entropy: 0.94981
Value Function Loss: 0.06687

Mean KL Divergence: 0.00409
SB3 Clip Fraction: 0.04936
Policy Update Magnitude: 0.18772
Value Function Update Magnitude: 0.33953

Collected Steps per Second: 23,190.51531
Overall Steps per Second: 14,868.63580

Timestep Collection Time: 2.15614
Timestep Consumption Time: 1.20678
PPO Batch Consumption Time: 0.09771
Total Iteration Time: 3.36292

Cumulative Model Updates: 57,308
Cumulative Timesteps: 478,132,868

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,166.57114
Policy Entropy: 0.94910
Value Function Loss: 0.06428

Mean KL Divergence: 0.00490
SB3 Clip Fraction: 0.05634
Policy Update Magnitude: 0.18345
Value Function Update Magnitude: 0.34945

Collected Steps per Second: 22,753.33138
Overall Steps per Second: 14,734.13267

Timestep Collection Time: 2.19871
Timestep Consumption Time: 1.19667
PPO Batch Consumption Time: 0.09393
Total Iteration Time: 3.39538

Cumulative Model Updates: 57,314
Cumulative Timesteps: 478,182,896

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 478182896...
Checkpoint 478182896 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,215.99383
Policy Entropy: 0.95505
Value Function Loss: 0.06860

Mean KL Divergence: 0.00466
SB3 Clip Fraction: 0.05641
Policy Update Magnitude: 0.17632
Value Function Update Magnitude: 0.36039

Collected Steps per Second: 21,665.37646
Overall Steps per Second: 14,129.54941

Timestep Collection Time: 2.30829
Timestep Consumption Time: 1.23110
PPO Batch Consumption Time: 0.10017
Total Iteration Time: 3.53939

Cumulative Model Updates: 57,320
Cumulative Timesteps: 478,232,906

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,553.81928
Policy Entropy: 0.95036
Value Function Loss: 0.06364

Mean KL Divergence: 0.00414
SB3 Clip Fraction: 0.04943
Policy Update Magnitude: 0.18116
Value Function Update Magnitude: 0.36143

Collected Steps per Second: 23,440.28771
Overall Steps per Second: 14,801.64422

Timestep Collection Time: 2.13521
Timestep Consumption Time: 1.24617
PPO Batch Consumption Time: 0.10345
Total Iteration Time: 3.38138

Cumulative Model Updates: 57,326
Cumulative Timesteps: 478,282,956

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 478282956...
Checkpoint 478282956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,994.93423
Policy Entropy: 0.95471
Value Function Loss: 0.06587

Mean KL Divergence: 0.00421
SB3 Clip Fraction: 0.05036
Policy Update Magnitude: 0.18162
Value Function Update Magnitude: 0.35989

Collected Steps per Second: 22,312.29268
Overall Steps per Second: 14,419.15419

Timestep Collection Time: 2.24145
Timestep Consumption Time: 1.22699
PPO Batch Consumption Time: 0.10081
Total Iteration Time: 3.46844

Cumulative Model Updates: 57,332
Cumulative Timesteps: 478,332,968

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,081.71014
Policy Entropy: 0.94923
Value Function Loss: 0.07253

Mean KL Divergence: 0.00429
SB3 Clip Fraction: 0.04954
Policy Update Magnitude: 0.18531
Value Function Update Magnitude: 0.35613

Collected Steps per Second: 22,733.08907
Overall Steps per Second: 14,548.04495

Timestep Collection Time: 2.19953
Timestep Consumption Time: 1.23750
PPO Batch Consumption Time: 0.10034
Total Iteration Time: 3.43703

Cumulative Model Updates: 57,338
Cumulative Timesteps: 478,382,970

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 478382970...
Checkpoint 478382970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,907.40554
Policy Entropy: 0.94492
Value Function Loss: 0.07549

Mean KL Divergence: 0.00478
SB3 Clip Fraction: 0.05795
Policy Update Magnitude: 0.18960
Value Function Update Magnitude: 0.39591

Collected Steps per Second: 23,068.16037
Overall Steps per Second: 14,655.97773

Timestep Collection Time: 2.16758
Timestep Consumption Time: 1.24414
PPO Batch Consumption Time: 0.10112
Total Iteration Time: 3.41171

Cumulative Model Updates: 57,344
Cumulative Timesteps: 478,432,972

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,359.95933
Policy Entropy: 0.94135
Value Function Loss: 0.07253

Mean KL Divergence: 0.00463
SB3 Clip Fraction: 0.05598
Policy Update Magnitude: 0.19147
Value Function Update Magnitude: 0.43683

Collected Steps per Second: 22,570.41066
Overall Steps per Second: 14,605.52081

Timestep Collection Time: 2.21547
Timestep Consumption Time: 1.20817
PPO Batch Consumption Time: 0.09607
Total Iteration Time: 3.42364

Cumulative Model Updates: 57,350
Cumulative Timesteps: 478,482,976

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 478482976...
Checkpoint 478482976 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,042.64562
Policy Entropy: 0.93004
Value Function Loss: 0.07009

Mean KL Divergence: 0.00415
SB3 Clip Fraction: 0.04745
Policy Update Magnitude: 0.19072
Value Function Update Magnitude: 0.42114

Collected Steps per Second: 22,419.57009
Overall Steps per Second: 14,374.47581

Timestep Collection Time: 2.23118
Timestep Consumption Time: 1.24874
PPO Batch Consumption Time: 0.10163
Total Iteration Time: 3.47992

Cumulative Model Updates: 57,356
Cumulative Timesteps: 478,532,998

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,335.01776
Policy Entropy: 0.92662
Value Function Loss: 0.07188

Mean KL Divergence: 0.00541
SB3 Clip Fraction: 0.06237
Policy Update Magnitude: 0.18868
Value Function Update Magnitude: 0.40592

Collected Steps per Second: 23,387.92511
Overall Steps per Second: 14,785.14692

Timestep Collection Time: 2.13897
Timestep Consumption Time: 1.24456
PPO Batch Consumption Time: 0.10049
Total Iteration Time: 3.38353

Cumulative Model Updates: 57,362
Cumulative Timesteps: 478,583,024

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 478583024...
Checkpoint 478583024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,280.87902
Policy Entropy: 0.93393
Value Function Loss: 0.06905

Mean KL Divergence: 0.00502
SB3 Clip Fraction: 0.05931
Policy Update Magnitude: 0.18857
Value Function Update Magnitude: 0.39459

Collected Steps per Second: 21,989.57675
Overall Steps per Second: 14,465.99733

Timestep Collection Time: 2.27526
Timestep Consumption Time: 1.18333
PPO Batch Consumption Time: 0.09502
Total Iteration Time: 3.45859

Cumulative Model Updates: 57,368
Cumulative Timesteps: 478,633,056

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,289.62255
Policy Entropy: 0.94264
Value Function Loss: 0.06565

Mean KL Divergence: 0.00461
SB3 Clip Fraction: 0.05504
Policy Update Magnitude: 0.18408
Value Function Update Magnitude: 0.37946

Collected Steps per Second: 23,114.94683
Overall Steps per Second: 14,707.92315

Timestep Collection Time: 2.16371
Timestep Consumption Time: 1.23677
PPO Batch Consumption Time: 0.09435
Total Iteration Time: 3.40048

Cumulative Model Updates: 57,374
Cumulative Timesteps: 478,683,070

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 478683070...
Checkpoint 478683070 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,984.01587
Policy Entropy: 0.93593
Value Function Loss: 0.07246

Mean KL Divergence: 0.00446
SB3 Clip Fraction: 0.05413
Policy Update Magnitude: 0.18154
Value Function Update Magnitude: 0.35513

Collected Steps per Second: 22,992.61935
Overall Steps per Second: 14,854.47223

Timestep Collection Time: 2.17557
Timestep Consumption Time: 1.19190
PPO Batch Consumption Time: 0.09317
Total Iteration Time: 3.36747

Cumulative Model Updates: 57,380
Cumulative Timesteps: 478,733,092

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,835.87401
Policy Entropy: 0.93973
Value Function Loss: 0.07418

Mean KL Divergence: 0.00696
SB3 Clip Fraction: 0.07174
Policy Update Magnitude: 0.17960
Value Function Update Magnitude: 0.36002

Collected Steps per Second: 22,870.07872
Overall Steps per Second: 14,671.09068

Timestep Collection Time: 2.18661
Timestep Consumption Time: 1.22200
PPO Batch Consumption Time: 0.10306
Total Iteration Time: 3.40861

Cumulative Model Updates: 57,386
Cumulative Timesteps: 478,783,100

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 478783100...
Checkpoint 478783100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,461.59711
Policy Entropy: 0.93768
Value Function Loss: 0.07224

Mean KL Divergence: 0.00745
SB3 Clip Fraction: 0.07503
Policy Update Magnitude: 0.17700
Value Function Update Magnitude: 0.36949

Collected Steps per Second: 22,652.41471
Overall Steps per Second: 14,163.94956

Timestep Collection Time: 2.20921
Timestep Consumption Time: 1.32398
PPO Batch Consumption Time: 0.10794
Total Iteration Time: 3.53320

Cumulative Model Updates: 57,392
Cumulative Timesteps: 478,833,144

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,413.61392
Policy Entropy: 0.95012
Value Function Loss: 0.07211

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.07820
Policy Update Magnitude: 0.18965
Value Function Update Magnitude: 0.37735

Collected Steps per Second: 22,771.98137
Overall Steps per Second: 14,693.75871

Timestep Collection Time: 2.19568
Timestep Consumption Time: 1.20712
PPO Batch Consumption Time: 0.09805
Total Iteration Time: 3.40281

Cumulative Model Updates: 57,398
Cumulative Timesteps: 478,883,144

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 478883144...
Checkpoint 478883144 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,075.93966
Policy Entropy: 0.94531
Value Function Loss: 0.07547

Mean KL Divergence: 0.00592
SB3 Clip Fraction: 0.06629
Policy Update Magnitude: 0.19746
Value Function Update Magnitude: 0.38904

Collected Steps per Second: 22,165.19509
Overall Steps per Second: 14,245.05725

Timestep Collection Time: 2.25678
Timestep Consumption Time: 1.25475
PPO Batch Consumption Time: 0.10220
Total Iteration Time: 3.51153

Cumulative Model Updates: 57,404
Cumulative Timesteps: 478,933,166

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,415.54598
Policy Entropy: 0.94521
Value Function Loss: 0.07543

Mean KL Divergence: 0.00568
SB3 Clip Fraction: 0.06313
Policy Update Magnitude: 0.20548
Value Function Update Magnitude: 0.38182

Collected Steps per Second: 23,272.88095
Overall Steps per Second: 14,582.90695

Timestep Collection Time: 2.15049
Timestep Consumption Time: 1.28148
PPO Batch Consumption Time: 0.10114
Total Iteration Time: 3.43196

Cumulative Model Updates: 57,410
Cumulative Timesteps: 478,983,214

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 478983214...
Checkpoint 478983214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,774.63367
Policy Entropy: 0.95551
Value Function Loss: 0.07802

Mean KL Divergence: 0.00482
SB3 Clip Fraction: 0.05566
Policy Update Magnitude: 0.20772
Value Function Update Magnitude: 0.39573

Collected Steps per Second: 23,059.88414
Overall Steps per Second: 14,766.74539

Timestep Collection Time: 2.16879
Timestep Consumption Time: 1.21801
PPO Batch Consumption Time: 0.09652
Total Iteration Time: 3.38680

Cumulative Model Updates: 57,416
Cumulative Timesteps: 479,033,226

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,135.73185
Policy Entropy: 0.95570
Value Function Loss: 0.07554

Mean KL Divergence: 0.00444
SB3 Clip Fraction: 0.05253
Policy Update Magnitude: 0.20130
Value Function Update Magnitude: 0.38739

Collected Steps per Second: 22,813.99864
Overall Steps per Second: 14,736.15564

Timestep Collection Time: 2.19251
Timestep Consumption Time: 1.20186
PPO Batch Consumption Time: 0.09587
Total Iteration Time: 3.39437

Cumulative Model Updates: 57,422
Cumulative Timesteps: 479,083,246

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 479083246...
Checkpoint 479083246 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,971.01970
Policy Entropy: 0.96478
Value Function Loss: 0.07443

Mean KL Divergence: 0.00483
SB3 Clip Fraction: 0.05599
Policy Update Magnitude: 0.19899
Value Function Update Magnitude: 0.38342

Collected Steps per Second: 22,360.27810
Overall Steps per Second: 14,162.63946

Timestep Collection Time: 2.23682
Timestep Consumption Time: 1.29472
PPO Batch Consumption Time: 0.10407
Total Iteration Time: 3.53155

Cumulative Model Updates: 57,428
Cumulative Timesteps: 479,133,262

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,273.88339
Policy Entropy: 0.95588
Value Function Loss: 0.07576

Mean KL Divergence: 0.00435
SB3 Clip Fraction: 0.05256
Policy Update Magnitude: 0.19846
Value Function Update Magnitude: 0.37940

Collected Steps per Second: 22,571.90008
Overall Steps per Second: 14,536.58543

Timestep Collection Time: 2.21514
Timestep Consumption Time: 1.22445
PPO Batch Consumption Time: 0.09438
Total Iteration Time: 3.43960

Cumulative Model Updates: 57,434
Cumulative Timesteps: 479,183,262

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 479183262...
Checkpoint 479183262 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,034.20902
Policy Entropy: 0.95118
Value Function Loss: 0.07398

Mean KL Divergence: 0.00402
SB3 Clip Fraction: 0.04946
Policy Update Magnitude: 0.19958
Value Function Update Magnitude: 0.39204

Collected Steps per Second: 22,110.72987
Overall Steps per Second: 14,281.16680

Timestep Collection Time: 2.26198
Timestep Consumption Time: 1.24012
PPO Batch Consumption Time: 0.10270
Total Iteration Time: 3.50209

Cumulative Model Updates: 57,440
Cumulative Timesteps: 479,233,276

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,095.75280
Policy Entropy: 0.93883
Value Function Loss: 0.07800

Mean KL Divergence: 0.00490
SB3 Clip Fraction: 0.05957
Policy Update Magnitude: 0.19502
Value Function Update Magnitude: 0.38653

Collected Steps per Second: 23,236.40847
Overall Steps per Second: 14,640.86175

Timestep Collection Time: 2.15343
Timestep Consumption Time: 1.26426
PPO Batch Consumption Time: 0.10168
Total Iteration Time: 3.41769

Cumulative Model Updates: 57,446
Cumulative Timesteps: 479,283,314

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 479283314...
Checkpoint 479283314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,945.95012
Policy Entropy: 0.94853
Value Function Loss: 0.07398

Mean KL Divergence: 0.00473
SB3 Clip Fraction: 0.05629
Policy Update Magnitude: 0.19053
Value Function Update Magnitude: 0.39116

Collected Steps per Second: 22,944.99444
Overall Steps per Second: 14,779.32207

Timestep Collection Time: 2.18017
Timestep Consumption Time: 1.20456
PPO Batch Consumption Time: 0.09697
Total Iteration Time: 3.38473

Cumulative Model Updates: 57,452
Cumulative Timesteps: 479,333,338

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,109.66123
Policy Entropy: 0.94359
Value Function Loss: 0.07541

Mean KL Divergence: 0.00438
SB3 Clip Fraction: 0.05296
Policy Update Magnitude: 0.19427
Value Function Update Magnitude: 0.38736

Collected Steps per Second: 22,575.21981
Overall Steps per Second: 14,651.43608

Timestep Collection Time: 2.21553
Timestep Consumption Time: 1.19820
PPO Batch Consumption Time: 0.09328
Total Iteration Time: 3.41373

Cumulative Model Updates: 57,458
Cumulative Timesteps: 479,383,354

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 479383354...
Checkpoint 479383354 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,448.69543
Policy Entropy: 0.95115
Value Function Loss: 0.07866

Mean KL Divergence: 0.00532
SB3 Clip Fraction: 0.06185
Policy Update Magnitude: 0.19489
Value Function Update Magnitude: 0.38511

Collected Steps per Second: 22,502.82444
Overall Steps per Second: 14,491.30281

Timestep Collection Time: 2.22194
Timestep Consumption Time: 1.22840
PPO Batch Consumption Time: 0.10254
Total Iteration Time: 3.45035

Cumulative Model Updates: 57,464
Cumulative Timesteps: 479,433,354

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,350.00212
Policy Entropy: 0.94053
Value Function Loss: 0.07738

Mean KL Divergence: 0.00758
SB3 Clip Fraction: 0.07719
Policy Update Magnitude: 0.18942
Value Function Update Magnitude: 0.40811

Collected Steps per Second: 23,024.77562
Overall Steps per Second: 14,848.13836

Timestep Collection Time: 2.17209
Timestep Consumption Time: 1.19614
PPO Batch Consumption Time: 0.09831
Total Iteration Time: 3.36823

Cumulative Model Updates: 57,470
Cumulative Timesteps: 479,483,366

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 479483366...
Checkpoint 479483366 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,735.09551
Policy Entropy: 0.93920
Value Function Loss: 0.07412

Mean KL Divergence: 0.00708
SB3 Clip Fraction: 0.07545
Policy Update Magnitude: 0.19421
Value Function Update Magnitude: 0.40433

Collected Steps per Second: 22,239.45029
Overall Steps per Second: 14,344.16013

Timestep Collection Time: 2.24853
Timestep Consumption Time: 1.23763
PPO Batch Consumption Time: 0.09785
Total Iteration Time: 3.48616

Cumulative Model Updates: 57,476
Cumulative Timesteps: 479,533,372

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,300.58431
Policy Entropy: 0.94011
Value Function Loss: 0.07641

Mean KL Divergence: 0.00633
SB3 Clip Fraction: 0.07166
Policy Update Magnitude: 0.20021
Value Function Update Magnitude: 0.40083

Collected Steps per Second: 23,167.89833
Overall Steps per Second: 14,733.94725

Timestep Collection Time: 2.15868
Timestep Consumption Time: 1.23566
PPO Batch Consumption Time: 0.09936
Total Iteration Time: 3.39434

Cumulative Model Updates: 57,482
Cumulative Timesteps: 479,583,384

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 479583384...
Checkpoint 479583384 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,308.24010
Policy Entropy: 0.95363
Value Function Loss: 0.07220

Mean KL Divergence: 0.00723
SB3 Clip Fraction: 0.07996
Policy Update Magnitude: 0.19664
Value Function Update Magnitude: 0.40490

Collected Steps per Second: 22,589.38935
Overall Steps per Second: 14,463.09699

Timestep Collection Time: 2.21467
Timestep Consumption Time: 1.24434
PPO Batch Consumption Time: 0.10078
Total Iteration Time: 3.45901

Cumulative Model Updates: 57,488
Cumulative Timesteps: 479,633,412

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,809.44980
Policy Entropy: 0.95499
Value Function Loss: 0.06675

Mean KL Divergence: 0.00651
SB3 Clip Fraction: 0.07101
Policy Update Magnitude: 0.18010
Value Function Update Magnitude: 0.37765

Collected Steps per Second: 22,490.09594
Overall Steps per Second: 14,424.78280

Timestep Collection Time: 2.22373
Timestep Consumption Time: 1.24335
PPO Batch Consumption Time: 0.10260
Total Iteration Time: 3.46709

Cumulative Model Updates: 57,494
Cumulative Timesteps: 479,683,424

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 479683424...
Checkpoint 479683424 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,872.43924
Policy Entropy: 0.96056
Value Function Loss: 0.06190

Mean KL Divergence: 0.01122
SB3 Clip Fraction: 0.09957
Policy Update Magnitude: 0.15858
Value Function Update Magnitude: 0.35163

Collected Steps per Second: 22,707.31619
Overall Steps per Second: 14,689.70855

Timestep Collection Time: 2.20229
Timestep Consumption Time: 1.20200
PPO Batch Consumption Time: 0.09558
Total Iteration Time: 3.40429

Cumulative Model Updates: 57,500
Cumulative Timesteps: 479,733,432

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,950.33915
Policy Entropy: 0.96232
Value Function Loss: 0.06692

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.09121
Policy Update Magnitude: 0.16231
Value Function Update Magnitude: 0.36712

Collected Steps per Second: 22,558.78628
Overall Steps per Second: 14,720.69874

Timestep Collection Time: 2.21643
Timestep Consumption Time: 1.18015
PPO Batch Consumption Time: 0.09228
Total Iteration Time: 3.39658

Cumulative Model Updates: 57,506
Cumulative Timesteps: 479,783,432

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 479783432...
Checkpoint 479783432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,225.02618
Policy Entropy: 0.96355
Value Function Loss: 0.07085

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.08765
Policy Update Magnitude: 0.17799
Value Function Update Magnitude: 0.38825

Collected Steps per Second: 21,848.14331
Overall Steps per Second: 14,164.12189

Timestep Collection Time: 2.28990
Timestep Consumption Time: 1.24227
PPO Batch Consumption Time: 0.10408
Total Iteration Time: 3.53216

Cumulative Model Updates: 57,512
Cumulative Timesteps: 479,833,462

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,958.95647
Policy Entropy: 0.94216
Value Function Loss: 0.07547

Mean KL Divergence: 0.00653
SB3 Clip Fraction: 0.07169
Policy Update Magnitude: 0.18131
Value Function Update Magnitude: 0.38720

Collected Steps per Second: 23,404.40364
Overall Steps per Second: 14,823.40529

Timestep Collection Time: 2.13746
Timestep Consumption Time: 1.23734
PPO Batch Consumption Time: 0.10298
Total Iteration Time: 3.37480

Cumulative Model Updates: 57,518
Cumulative Timesteps: 479,883,488

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 479883488...
Checkpoint 479883488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,268.69976
Policy Entropy: 0.93179
Value Function Loss: 0.07843

Mean KL Divergence: 0.00482
SB3 Clip Fraction: 0.05698
Policy Update Magnitude: 0.19218
Value Function Update Magnitude: 0.40102

Collected Steps per Second: 22,725.43499
Overall Steps per Second: 14,703.22505

Timestep Collection Time: 2.20132
Timestep Consumption Time: 1.20106
PPO Batch Consumption Time: 0.09731
Total Iteration Time: 3.40238

Cumulative Model Updates: 57,524
Cumulative Timesteps: 479,933,514

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,147.06623
Policy Entropy: 0.95060
Value Function Loss: 0.08193

Mean KL Divergence: 0.00454
SB3 Clip Fraction: 0.05405
Policy Update Magnitude: 0.19996
Value Function Update Magnitude: 0.39933

Collected Steps per Second: 22,900.47714
Overall Steps per Second: 14,762.49375

Timestep Collection Time: 2.18432
Timestep Consumption Time: 1.20413
PPO Batch Consumption Time: 0.09825
Total Iteration Time: 3.38845

Cumulative Model Updates: 57,530
Cumulative Timesteps: 479,983,536

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 479983536...
Checkpoint 479983536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,204.06607
Policy Entropy: 0.97272
Value Function Loss: 0.08031

Mean KL Divergence: 0.00582
SB3 Clip Fraction: 0.06693
Policy Update Magnitude: 0.19828
Value Function Update Magnitude: 0.40353

Collected Steps per Second: 22,869.60721
Overall Steps per Second: 14,771.89669

Timestep Collection Time: 2.18736
Timestep Consumption Time: 1.19907
PPO Batch Consumption Time: 0.09433
Total Iteration Time: 3.38643

Cumulative Model Updates: 57,536
Cumulative Timesteps: 480,033,560

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,027.00950
Policy Entropy: 0.96925
Value Function Loss: 0.07700

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.09972
Policy Update Magnitude: 0.17699
Value Function Update Magnitude: 0.39716

Collected Steps per Second: 22,494.36404
Overall Steps per Second: 14,717.72969

Timestep Collection Time: 2.22278
Timestep Consumption Time: 1.17448
PPO Batch Consumption Time: 0.09135
Total Iteration Time: 3.39726

Cumulative Model Updates: 57,542
Cumulative Timesteps: 480,083,560

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 480083560...
Checkpoint 480083560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,378.93013
Policy Entropy: 0.95866
Value Function Loss: 0.07761

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.09059
Policy Update Magnitude: 0.17419
Value Function Update Magnitude: 0.39747

Collected Steps per Second: 22,406.68888
Overall Steps per Second: 14,370.38470

Timestep Collection Time: 2.23282
Timestep Consumption Time: 1.24865
PPO Batch Consumption Time: 0.10084
Total Iteration Time: 3.48147

Cumulative Model Updates: 57,548
Cumulative Timesteps: 480,133,590

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,586.58700
Policy Entropy: 0.95838
Value Function Loss: 0.07259

Mean KL Divergence: 0.00587
SB3 Clip Fraction: 0.06777
Policy Update Magnitude: 0.18608
Value Function Update Magnitude: 0.38382

Collected Steps per Second: 23,083.85897
Overall Steps per Second: 14,707.45642

Timestep Collection Time: 2.16610
Timestep Consumption Time: 1.23367
PPO Batch Consumption Time: 0.10156
Total Iteration Time: 3.39977

Cumulative Model Updates: 57,554
Cumulative Timesteps: 480,183,592

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 480183592...
Checkpoint 480183592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,881.44209
Policy Entropy: 0.95908
Value Function Loss: 0.07629

Mean KL Divergence: 0.00672
SB3 Clip Fraction: 0.07568
Policy Update Magnitude: 0.19520
Value Function Update Magnitude: 0.35093

Collected Steps per Second: 22,258.25773
Overall Steps per Second: 14,567.06111

Timestep Collection Time: 2.24717
Timestep Consumption Time: 1.18647
PPO Batch Consumption Time: 0.09586
Total Iteration Time: 3.43364

Cumulative Model Updates: 57,560
Cumulative Timesteps: 480,233,610

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,229.74546
Policy Entropy: 0.96182
Value Function Loss: 0.06981

Mean KL Divergence: 0.00667
SB3 Clip Fraction: 0.07610
Policy Update Magnitude: 0.18872
Value Function Update Magnitude: 0.32321

Collected Steps per Second: 23,244.85130
Overall Steps per Second: 14,744.29891

Timestep Collection Time: 2.15170
Timestep Consumption Time: 1.24052
PPO Batch Consumption Time: 0.09576
Total Iteration Time: 3.39223

Cumulative Model Updates: 57,566
Cumulative Timesteps: 480,283,626

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 480283626...
Checkpoint 480283626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,264.18287
Policy Entropy: 0.95504
Value Function Loss: 0.07250

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.08414
Policy Update Magnitude: 0.17681
Value Function Update Magnitude: 0.32008

Collected Steps per Second: 22,631.66394
Overall Steps per Second: 14,803.18940

Timestep Collection Time: 2.20938
Timestep Consumption Time: 1.16840
PPO Batch Consumption Time: 0.09267
Total Iteration Time: 3.37779

Cumulative Model Updates: 57,572
Cumulative Timesteps: 480,333,628

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,154.61126
Policy Entropy: 0.94848
Value Function Loss: 0.08438

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.08945
Policy Update Magnitude: 0.16381
Value Function Update Magnitude: 0.32526

Collected Steps per Second: 22,694.34495
Overall Steps per Second: 14,773.40101

Timestep Collection Time: 2.20372
Timestep Consumption Time: 1.18155
PPO Batch Consumption Time: 0.09484
Total Iteration Time: 3.38527

Cumulative Model Updates: 57,578
Cumulative Timesteps: 480,383,640

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 480383640...
Checkpoint 480383640 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,182.59501
Policy Entropy: 0.93552
Value Function Loss: 0.08026

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.08700
Policy Update Magnitude: 0.16721
Value Function Update Magnitude: 0.38626

Collected Steps per Second: 22,266.46886
Overall Steps per Second: 14,824.78003

Timestep Collection Time: 2.24625
Timestep Consumption Time: 1.12756
PPO Batch Consumption Time: 0.09182
Total Iteration Time: 3.37381

Cumulative Model Updates: 57,584
Cumulative Timesteps: 480,433,656

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,764.62195
Policy Entropy: 0.93682
Value Function Loss: 0.08234

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.07968
Policy Update Magnitude: 0.17503
Value Function Update Magnitude: 0.41190

Collected Steps per Second: 22,529.14197
Overall Steps per Second: 14,826.99927

Timestep Collection Time: 2.21944
Timestep Consumption Time: 1.15292
PPO Batch Consumption Time: 0.09745
Total Iteration Time: 3.37236

Cumulative Model Updates: 57,590
Cumulative Timesteps: 480,483,658

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 480483658...
Checkpoint 480483658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,912.26767
Policy Entropy: 0.94834
Value Function Loss: 0.07339

Mean KL Divergence: 0.00548
SB3 Clip Fraction: 0.06502
Policy Update Magnitude: 0.18309
Value Function Update Magnitude: 0.39908

Collected Steps per Second: 21,527.87009
Overall Steps per Second: 14,393.01164

Timestep Collection Time: 2.32304
Timestep Consumption Time: 1.15157
PPO Batch Consumption Time: 0.09987
Total Iteration Time: 3.47460

Cumulative Model Updates: 57,596
Cumulative Timesteps: 480,533,668

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,374.65487
Policy Entropy: 0.96366
Value Function Loss: 0.08131

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.07851
Policy Update Magnitude: 0.18872
Value Function Update Magnitude: 0.37711

Collected Steps per Second: 22,343.04261
Overall Steps per Second: 14,146.60897

Timestep Collection Time: 2.23792
Timestep Consumption Time: 1.29663
PPO Batch Consumption Time: 0.12195
Total Iteration Time: 3.53456

Cumulative Model Updates: 57,602
Cumulative Timesteps: 480,583,670

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 480583670...
Checkpoint 480583670 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,303.09213
Policy Entropy: 0.96229
Value Function Loss: 0.08639

Mean KL Divergence: 0.01072
SB3 Clip Fraction: 0.09551
Policy Update Magnitude: 0.18298
Value Function Update Magnitude: 0.38347

Collected Steps per Second: 21,434.07612
Overall Steps per Second: 14,341.44585

Timestep Collection Time: 2.33385
Timestep Consumption Time: 1.15422
PPO Batch Consumption Time: 0.10218
Total Iteration Time: 3.48807

Cumulative Model Updates: 57,608
Cumulative Timesteps: 480,633,694

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,797.88795
Policy Entropy: 0.95655
Value Function Loss: 0.08988

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.08876
Policy Update Magnitude: 0.19697
Value Function Update Magnitude: 0.41340

Collected Steps per Second: 22,101.06244
Overall Steps per Second: 14,747.75760

Timestep Collection Time: 2.26342
Timestep Consumption Time: 1.12855
PPO Batch Consumption Time: 0.09865
Total Iteration Time: 3.39197

Cumulative Model Updates: 57,614
Cumulative Timesteps: 480,683,718

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 480683718...
Checkpoint 480683718 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,626.48366
Policy Entropy: 0.95512
Value Function Loss: 0.09474

Mean KL Divergence: 0.00628
SB3 Clip Fraction: 0.07477
Policy Update Magnitude: 0.20314
Value Function Update Magnitude: 0.41021

Collected Steps per Second: 22,702.61077
Overall Steps per Second: 14,810.80333

Timestep Collection Time: 2.20380
Timestep Consumption Time: 1.17428
PPO Batch Consumption Time: 0.10305
Total Iteration Time: 3.37807

Cumulative Model Updates: 57,620
Cumulative Timesteps: 480,733,750

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,951.77889
Policy Entropy: 0.94788
Value Function Loss: 0.08638

Mean KL Divergence: 0.00623
SB3 Clip Fraction: 0.07197
Policy Update Magnitude: 0.20886
Value Function Update Magnitude: 0.38026

Collected Steps per Second: 23,186.83274
Overall Steps per Second: 15,522.00347

Timestep Collection Time: 2.15735
Timestep Consumption Time: 1.06531
PPO Batch Consumption Time: 0.08901
Total Iteration Time: 3.22265

Cumulative Model Updates: 57,626
Cumulative Timesteps: 480,783,772

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 480783772...
Checkpoint 480783772 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,913.43669
Policy Entropy: 0.95159
Value Function Loss: 0.07816

Mean KL Divergence: 0.00546
SB3 Clip Fraction: 0.06421
Policy Update Magnitude: 0.20375
Value Function Update Magnitude: 0.36710

Collected Steps per Second: 22,253.55476
Overall Steps per Second: 14,892.61308

Timestep Collection Time: 2.24800
Timestep Consumption Time: 1.11111
PPO Batch Consumption Time: 0.09414
Total Iteration Time: 3.35912

Cumulative Model Updates: 57,632
Cumulative Timesteps: 480,833,798

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,170.97357
Policy Entropy: 0.94577
Value Function Loss: 0.07065

Mean KL Divergence: 0.00578
SB3 Clip Fraction: 0.06535
Policy Update Magnitude: 0.18700
Value Function Update Magnitude: 0.33905

Collected Steps per Second: 22,977.08100
Overall Steps per Second: 14,796.14838

Timestep Collection Time: 2.17817
Timestep Consumption Time: 1.20433
PPO Batch Consumption Time: 0.09653
Total Iteration Time: 3.38250

Cumulative Model Updates: 57,638
Cumulative Timesteps: 480,883,846

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 480883846...
Checkpoint 480883846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,207.60600
Policy Entropy: 0.95084
Value Function Loss: 0.07354

Mean KL Divergence: 0.00397
SB3 Clip Fraction: 0.04779
Policy Update Magnitude: 0.17626
Value Function Update Magnitude: 0.32858

Collected Steps per Second: 22,933.29407
Overall Steps per Second: 14,876.76713

Timestep Collection Time: 2.18032
Timestep Consumption Time: 1.18076
PPO Batch Consumption Time: 0.09815
Total Iteration Time: 3.36108

Cumulative Model Updates: 57,644
Cumulative Timesteps: 480,933,848

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,935.58591
Policy Entropy: 0.94874
Value Function Loss: 0.07575

Mean KL Divergence: 0.00456
SB3 Clip Fraction: 0.05412
Policy Update Magnitude: 0.18170
Value Function Update Magnitude: 0.33727

Collected Steps per Second: 23,026.56720
Overall Steps per Second: 14,811.05305

Timestep Collection Time: 2.17193
Timestep Consumption Time: 1.20474
PPO Batch Consumption Time: 0.10065
Total Iteration Time: 3.37667

Cumulative Model Updates: 57,650
Cumulative Timesteps: 480,983,860

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 480983860...
Checkpoint 480983860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,596.47512
Policy Entropy: 0.96168
Value Function Loss: 0.07827

Mean KL Divergence: 0.00374
SB3 Clip Fraction: 0.04426
Policy Update Magnitude: 0.19207
Value Function Update Magnitude: 0.35804

Collected Steps per Second: 23,122.25437
Overall Steps per Second: 14,861.90015

Timestep Collection Time: 2.16259
Timestep Consumption Time: 1.20198
PPO Batch Consumption Time: 0.10142
Total Iteration Time: 3.36458

Cumulative Model Updates: 57,656
Cumulative Timesteps: 481,033,864

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,594.00956
Policy Entropy: 0.95463
Value Function Loss: 0.08014

Mean KL Divergence: 0.00536
SB3 Clip Fraction: 0.06019
Policy Update Magnitude: 0.19741
Value Function Update Magnitude: 0.36527

Collected Steps per Second: 23,287.59339
Overall Steps per Second: 14,989.07941

Timestep Collection Time: 2.14707
Timestep Consumption Time: 1.18870
PPO Batch Consumption Time: 0.09908
Total Iteration Time: 3.33576

Cumulative Model Updates: 57,662
Cumulative Timesteps: 481,083,864

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 481083864...
Checkpoint 481083864 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,994.27154
Policy Entropy: 0.93919
Value Function Loss: 0.07330

Mean KL Divergence: 0.00502
SB3 Clip Fraction: 0.05806
Policy Update Magnitude: 0.19100
Value Function Update Magnitude: 0.39266

Collected Steps per Second: 22,367.59880
Overall Steps per Second: 14,477.88414

Timestep Collection Time: 2.23663
Timestep Consumption Time: 1.21885
PPO Batch Consumption Time: 0.09656
Total Iteration Time: 3.45548

Cumulative Model Updates: 57,668
Cumulative Timesteps: 481,133,892

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,390.92043
Policy Entropy: 0.93992
Value Function Loss: 0.07479

Mean KL Divergence: 0.00405
SB3 Clip Fraction: 0.04786
Policy Update Magnitude: 0.18988
Value Function Update Magnitude: 0.39394

Collected Steps per Second: 23,662.73691
Overall Steps per Second: 15,199.77824

Timestep Collection Time: 2.11337
Timestep Consumption Time: 1.17668
PPO Batch Consumption Time: 0.09946
Total Iteration Time: 3.29005

Cumulative Model Updates: 57,674
Cumulative Timesteps: 481,183,900

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 481183900...
Checkpoint 481183900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,675.82673
Policy Entropy: 0.94308
Value Function Loss: 0.07988

Mean KL Divergence: 0.00457
SB3 Clip Fraction: 0.05494
Policy Update Magnitude: 0.19519
Value Function Update Magnitude: 0.38231

Collected Steps per Second: 23,042.06686
Overall Steps per Second: 14,720.15651

Timestep Collection Time: 2.17107
Timestep Consumption Time: 1.22740
PPO Batch Consumption Time: 0.10034
Total Iteration Time: 3.39847

Cumulative Model Updates: 57,680
Cumulative Timesteps: 481,233,926

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,846.23900
Policy Entropy: 0.94665
Value Function Loss: 0.08621

Mean KL Divergence: 0.00504
SB3 Clip Fraction: 0.06019
Policy Update Magnitude: 0.20680
Value Function Update Magnitude: 0.41349

Collected Steps per Second: 23,619.64944
Overall Steps per Second: 14,883.96643

Timestep Collection Time: 2.11841
Timestep Consumption Time: 1.24333
PPO Batch Consumption Time: 0.09964
Total Iteration Time: 3.36174

Cumulative Model Updates: 57,686
Cumulative Timesteps: 481,283,962

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 481283962...
Checkpoint 481283962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,474.53181
Policy Entropy: 0.93447
Value Function Loss: 0.09681

Mean KL Divergence: 0.00507
SB3 Clip Fraction: 0.06145
Policy Update Magnitude: 0.21147
Value Function Update Magnitude: 0.42032

Collected Steps per Second: 22,836.60968
Overall Steps per Second: 14,581.23446

Timestep Collection Time: 2.19052
Timestep Consumption Time: 1.24019
PPO Batch Consumption Time: 0.10167
Total Iteration Time: 3.43071

Cumulative Model Updates: 57,692
Cumulative Timesteps: 481,333,986

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,257.07464
Policy Entropy: 0.93731
Value Function Loss: 0.09698

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.08891
Policy Update Magnitude: 0.20664
Value Function Update Magnitude: 0.35284

Collected Steps per Second: 23,074.57687
Overall Steps per Second: 14,896.28372

Timestep Collection Time: 2.16749
Timestep Consumption Time: 1.18999
PPO Batch Consumption Time: 0.10056
Total Iteration Time: 3.35748

Cumulative Model Updates: 57,698
Cumulative Timesteps: 481,384,000

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 481384000...
Checkpoint 481384000 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,575.98894
Policy Entropy: 0.92753
Value Function Loss: 0.09801

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.09792
Policy Update Magnitude: 0.17987
Value Function Update Magnitude: 0.31841

Collected Steps per Second: 23,463.12914
Overall Steps per Second: 14,855.68149

Timestep Collection Time: 2.13109
Timestep Consumption Time: 1.23476
PPO Batch Consumption Time: 0.10048
Total Iteration Time: 3.36585

Cumulative Model Updates: 57,704
Cumulative Timesteps: 481,434,002

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,279.03623
Policy Entropy: 0.92760
Value Function Loss: 0.09651

Mean KL Divergence: 0.00685
SB3 Clip Fraction: 0.07401
Policy Update Magnitude: 0.19723
Value Function Update Magnitude: 0.35579

Collected Steps per Second: 23,272.42806
Overall Steps per Second: 14,891.98664

Timestep Collection Time: 2.14864
Timestep Consumption Time: 1.20914
PPO Batch Consumption Time: 0.09999
Total Iteration Time: 3.35778

Cumulative Model Updates: 57,710
Cumulative Timesteps: 481,484,006

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 481484006...
Checkpoint 481484006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,874.50666
Policy Entropy: 0.92115
Value Function Loss: 0.08838

Mean KL Divergence: 0.00485
SB3 Clip Fraction: 0.05525
Policy Update Magnitude: 0.21625
Value Function Update Magnitude: 0.42955

Collected Steps per Second: 22,817.98253
Overall Steps per Second: 14,700.69937

Timestep Collection Time: 2.19248
Timestep Consumption Time: 1.21062
PPO Batch Consumption Time: 0.09960
Total Iteration Time: 3.40310

Cumulative Model Updates: 57,716
Cumulative Timesteps: 481,534,034

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,460.56903
Policy Entropy: 0.91434
Value Function Loss: 0.08178

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.08386
Policy Update Magnitude: 0.20322
Value Function Update Magnitude: 0.44065

Collected Steps per Second: 23,368.69806
Overall Steps per Second: 15,275.01813

Timestep Collection Time: 2.14004
Timestep Consumption Time: 1.13393
PPO Batch Consumption Time: 0.09322
Total Iteration Time: 3.27397

Cumulative Model Updates: 57,722
Cumulative Timesteps: 481,584,044

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 481584044...
Checkpoint 481584044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,709.09688
Policy Entropy: 0.92202
Value Function Loss: 0.07415

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.07853
Policy Update Magnitude: 0.16387
Value Function Update Magnitude: 0.41744

Collected Steps per Second: 23,119.01144
Overall Steps per Second: 14,888.89949

Timestep Collection Time: 2.16437
Timestep Consumption Time: 1.19639
PPO Batch Consumption Time: 0.09469
Total Iteration Time: 3.36076

Cumulative Model Updates: 57,728
Cumulative Timesteps: 481,634,082

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,112.78962
Policy Entropy: 0.93157
Value Function Loss: 0.07923

Mean KL Divergence: 0.00355
SB3 Clip Fraction: 0.04151
Policy Update Magnitude: 0.17283
Value Function Update Magnitude: 0.40588

Collected Steps per Second: 23,232.85810
Overall Steps per Second: 14,859.79533

Timestep Collection Time: 2.15307
Timestep Consumption Time: 1.21319
PPO Batch Consumption Time: 0.10192
Total Iteration Time: 3.36626

Cumulative Model Updates: 57,734
Cumulative Timesteps: 481,684,104

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 481684104...
Checkpoint 481684104 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,062.08048
Policy Entropy: 0.93412
Value Function Loss: 0.08004

Mean KL Divergence: 0.00422
SB3 Clip Fraction: 0.05018
Policy Update Magnitude: 0.19464
Value Function Update Magnitude: 0.41939

Collected Steps per Second: 23,373.82562
Overall Steps per Second: 14,854.97920

Timestep Collection Time: 2.13966
Timestep Consumption Time: 1.22702
PPO Batch Consumption Time: 0.10072
Total Iteration Time: 3.36668

Cumulative Model Updates: 57,740
Cumulative Timesteps: 481,734,116

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,754.40088
Policy Entropy: 0.93081
Value Function Loss: 0.08768

Mean KL Divergence: 0.00455
SB3 Clip Fraction: 0.05341
Policy Update Magnitude: 0.20185
Value Function Update Magnitude: 0.42336

Collected Steps per Second: 22,747.99572
Overall Steps per Second: 14,690.97574

Timestep Collection Time: 2.19914
Timestep Consumption Time: 1.20608
PPO Batch Consumption Time: 0.09780
Total Iteration Time: 3.40522

Cumulative Model Updates: 57,746
Cumulative Timesteps: 481,784,142

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 481784142...
Checkpoint 481784142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,985.70077
Policy Entropy: 0.91817
Value Function Loss: 0.08931

Mean KL Divergence: 0.00513
SB3 Clip Fraction: 0.06052
Policy Update Magnitude: 0.20148
Value Function Update Magnitude: 0.41239

Collected Steps per Second: 23,235.93722
Overall Steps per Second: 14,792.05363

Timestep Collection Time: 2.15339
Timestep Consumption Time: 1.22924
PPO Batch Consumption Time: 0.09606
Total Iteration Time: 3.38263

Cumulative Model Updates: 57,752
Cumulative Timesteps: 481,834,178

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,126.53911
Policy Entropy: 0.92318
Value Function Loss: 0.09515

Mean KL Divergence: 0.00478
SB3 Clip Fraction: 0.05699
Policy Update Magnitude: 0.19116
Value Function Update Magnitude: 0.37217

Collected Steps per Second: 23,149.49387
Overall Steps per Second: 14,865.81075

Timestep Collection Time: 2.16048
Timestep Consumption Time: 1.20388
PPO Batch Consumption Time: 0.10092
Total Iteration Time: 3.36436

Cumulative Model Updates: 57,758
Cumulative Timesteps: 481,884,192

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 481884192...
Checkpoint 481884192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,893.10834
Policy Entropy: 0.92490
Value Function Loss: 0.09879

Mean KL Divergence: 0.00559
SB3 Clip Fraction: 0.06407
Policy Update Magnitude: 0.19776
Value Function Update Magnitude: 0.40883

Collected Steps per Second: 22,572.87149
Overall Steps per Second: 14,700.82983

Timestep Collection Time: 2.21629
Timestep Consumption Time: 1.18678
PPO Batch Consumption Time: 0.09426
Total Iteration Time: 3.40307

Cumulative Model Updates: 57,764
Cumulative Timesteps: 481,934,220

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,613.57585
Policy Entropy: 0.93603
Value Function Loss: 0.09590

Mean KL Divergence: 0.00481
SB3 Clip Fraction: 0.05513
Policy Update Magnitude: 0.20529
Value Function Update Magnitude: 0.46679

Collected Steps per Second: 23,767.51187
Overall Steps per Second: 14,896.38220

Timestep Collection Time: 2.10388
Timestep Consumption Time: 1.25291
PPO Batch Consumption Time: 0.10263
Total Iteration Time: 3.35679

Cumulative Model Updates: 57,770
Cumulative Timesteps: 481,984,224

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 481984224...
Checkpoint 481984224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,352.76791
Policy Entropy: 0.94388
Value Function Loss: 0.08725

Mean KL Divergence: 0.00399
SB3 Clip Fraction: 0.04708
Policy Update Magnitude: 0.19838
Value Function Update Magnitude: 0.46639

Collected Steps per Second: 23,195.34709
Overall Steps per Second: 14,847.35293

Timestep Collection Time: 2.15655
Timestep Consumption Time: 1.21253
PPO Batch Consumption Time: 0.09962
Total Iteration Time: 3.36909

Cumulative Model Updates: 57,776
Cumulative Timesteps: 482,034,246

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,212.62664
Policy Entropy: 0.94641
Value Function Loss: 0.09163

Mean KL Divergence: 0.00441
SB3 Clip Fraction: 0.05146
Policy Update Magnitude: 0.19813
Value Function Update Magnitude: 0.44795

Collected Steps per Second: 23,110.48927
Overall Steps per Second: 14,755.50890

Timestep Collection Time: 2.16447
Timestep Consumption Time: 1.22558
PPO Batch Consumption Time: 0.10274
Total Iteration Time: 3.39006

Cumulative Model Updates: 57,782
Cumulative Timesteps: 482,084,268

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 482084268...
Checkpoint 482084268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,030.71298
Policy Entropy: 0.94640
Value Function Loss: 0.09380

Mean KL Divergence: 0.00511
SB3 Clip Fraction: 0.06160
Policy Update Magnitude: 0.19606
Value Function Update Magnitude: 0.40104

Collected Steps per Second: 23,441.88803
Overall Steps per Second: 14,841.48904

Timestep Collection Time: 2.13293
Timestep Consumption Time: 1.23600
PPO Batch Consumption Time: 0.10209
Total Iteration Time: 3.36893

Cumulative Model Updates: 57,788
Cumulative Timesteps: 482,134,268

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,652.95093
Policy Entropy: 0.94772
Value Function Loss: 0.09846

Mean KL Divergence: 0.00525
SB3 Clip Fraction: 0.06467
Policy Update Magnitude: 0.20148
Value Function Update Magnitude: 0.40154

Collected Steps per Second: 22,751.17180
Overall Steps per Second: 14,678.68405

Timestep Collection Time: 2.19769
Timestep Consumption Time: 1.20861
PPO Batch Consumption Time: 0.09728
Total Iteration Time: 3.40630

Cumulative Model Updates: 57,794
Cumulative Timesteps: 482,184,268

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 482184268...
Checkpoint 482184268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,084.74324
Policy Entropy: 0.94239
Value Function Loss: 0.09564

Mean KL Divergence: 0.00519
SB3 Clip Fraction: 0.06105
Policy Update Magnitude: 0.20410
Value Function Update Magnitude: 0.43008

Collected Steps per Second: 23,013.61832
Overall Steps per Second: 14,928.84048

Timestep Collection Time: 2.17384
Timestep Consumption Time: 1.17725
PPO Batch Consumption Time: 0.09827
Total Iteration Time: 3.35110

Cumulative Model Updates: 57,800
Cumulative Timesteps: 482,234,296

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,737.96599
Policy Entropy: 0.94439
Value Function Loss: 0.10043

Mean KL Divergence: 0.00508
SB3 Clip Fraction: 0.05813
Policy Update Magnitude: 0.20277
Value Function Update Magnitude: 0.47507

Collected Steps per Second: 23,834.42293
Overall Steps per Second: 15,472.21903

Timestep Collection Time: 2.09923
Timestep Consumption Time: 1.13456
PPO Batch Consumption Time: 0.08932
Total Iteration Time: 3.23380

Cumulative Model Updates: 57,806
Cumulative Timesteps: 482,284,330

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 482284330...
Checkpoint 482284330 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,521.78999
Policy Entropy: 0.95474
Value Function Loss: 0.10543

Mean KL Divergence: 0.01190
SB3 Clip Fraction: 0.09752
Policy Update Magnitude: 0.17605
Value Function Update Magnitude: 0.50613

Collected Steps per Second: 22,907.12699
Overall Steps per Second: 14,955.09493

Timestep Collection Time: 2.18273
Timestep Consumption Time: 1.16062
PPO Batch Consumption Time: 0.09676
Total Iteration Time: 3.34334

Cumulative Model Updates: 57,812
Cumulative Timesteps: 482,334,330

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,845.09500
Policy Entropy: 0.94897
Value Function Loss: 0.09872

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.07983
Policy Update Magnitude: 0.16628
Value Function Update Magnitude: 0.51012

Collected Steps per Second: 23,769.28849
Overall Steps per Second: 14,872.08199

Timestep Collection Time: 2.10423
Timestep Consumption Time: 1.25885
PPO Batch Consumption Time: 0.10265
Total Iteration Time: 3.36308

Cumulative Model Updates: 57,818
Cumulative Timesteps: 482,384,346

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 482384346...
Checkpoint 482384346 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,265.81329
Policy Entropy: 0.95400
Value Function Loss: 0.08965

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.07316
Policy Update Magnitude: 0.16453
Value Function Update Magnitude: 0.48132

Collected Steps per Second: 23,191.17052
Overall Steps per Second: 14,779.85016

Timestep Collection Time: 2.15720
Timestep Consumption Time: 1.22768
PPO Batch Consumption Time: 0.09977
Total Iteration Time: 3.38488

Cumulative Model Updates: 57,824
Cumulative Timesteps: 482,434,374

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,680.93286
Policy Entropy: 0.94018
Value Function Loss: 0.10420

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.07522
Policy Update Magnitude: 0.15831
Value Function Update Magnitude: 0.45653

Collected Steps per Second: 23,090.24402
Overall Steps per Second: 14,780.65833

Timestep Collection Time: 2.16646
Timestep Consumption Time: 1.21797
PPO Batch Consumption Time: 0.10030
Total Iteration Time: 3.38442

Cumulative Model Updates: 57,830
Cumulative Timesteps: 482,484,398

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 482484398...
Checkpoint 482484398 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,282.68062
Policy Entropy: 0.93898
Value Function Loss: 0.09899

Mean KL Divergence: 0.00675
SB3 Clip Fraction: 0.06999
Policy Update Magnitude: 0.19257
Value Function Update Magnitude: 0.40998

Collected Steps per Second: 23,446.91063
Overall Steps per Second: 14,855.55350

Timestep Collection Time: 2.13256
Timestep Consumption Time: 1.23332
PPO Batch Consumption Time: 0.10167
Total Iteration Time: 3.36588

Cumulative Model Updates: 57,836
Cumulative Timesteps: 482,534,400

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,159.26881
Policy Entropy: 0.93948
Value Function Loss: 0.10209

Mean KL Divergence: 0.00683
SB3 Clip Fraction: 0.06864
Policy Update Magnitude: 0.21451
Value Function Update Magnitude: 0.39090

Collected Steps per Second: 23,803.11072
Overall Steps per Second: 15,055.96493

Timestep Collection Time: 2.10099
Timestep Consumption Time: 1.22062
PPO Batch Consumption Time: 0.09921
Total Iteration Time: 3.32161

Cumulative Model Updates: 57,842
Cumulative Timesteps: 482,584,410

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 482584410...
Checkpoint 482584410 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,878.86615
Policy Entropy: 0.94620
Value Function Loss: 0.09468

Mean KL Divergence: 0.00473
SB3 Clip Fraction: 0.05687
Policy Update Magnitude: 0.20612
Value Function Update Magnitude: 0.35132

Collected Steps per Second: 22,574.26892
Overall Steps per Second: 14,535.16960

Timestep Collection Time: 2.21624
Timestep Consumption Time: 1.22576
PPO Batch Consumption Time: 0.09904
Total Iteration Time: 3.44200

Cumulative Model Updates: 57,848
Cumulative Timesteps: 482,634,440

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,532.76146
Policy Entropy: 0.93743
Value Function Loss: 0.09782

Mean KL Divergence: 0.00512
SB3 Clip Fraction: 0.05999
Policy Update Magnitude: 0.20167
Value Function Update Magnitude: 0.36083

Collected Steps per Second: 23,742.07806
Overall Steps per Second: 15,103.33146

Timestep Collection Time: 2.10681
Timestep Consumption Time: 1.20504
PPO Batch Consumption Time: 0.09945
Total Iteration Time: 3.31185

Cumulative Model Updates: 57,854
Cumulative Timesteps: 482,684,460

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 482684460...
Checkpoint 482684460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,226.12308
Policy Entropy: 0.94772
Value Function Loss: 0.10268

Mean KL Divergence: 0.00393
SB3 Clip Fraction: 0.04673
Policy Update Magnitude: 0.21014
Value Function Update Magnitude: 0.37630

Collected Steps per Second: 23,207.35739
Overall Steps per Second: 14,783.08972

Timestep Collection Time: 2.15518
Timestep Consumption Time: 1.22815
PPO Batch Consumption Time: 0.09849
Total Iteration Time: 3.38333

Cumulative Model Updates: 57,860
Cumulative Timesteps: 482,734,476

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,733.08189
Policy Entropy: 0.94799
Value Function Loss: 0.10279

Mean KL Divergence: 0.00378
SB3 Clip Fraction: 0.04511
Policy Update Magnitude: 0.22750
Value Function Update Magnitude: 0.36399

Collected Steps per Second: 22,913.63404
Overall Steps per Second: 14,688.45299

Timestep Collection Time: 2.18403
Timestep Consumption Time: 1.22300
PPO Batch Consumption Time: 0.09952
Total Iteration Time: 3.40703

Cumulative Model Updates: 57,866
Cumulative Timesteps: 482,784,520

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 482784520...
Checkpoint 482784520 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,343.06572
Policy Entropy: 0.94506
Value Function Loss: 0.10026

Mean KL Divergence: 0.00447
SB3 Clip Fraction: 0.05273
Policy Update Magnitude: 0.22725
Value Function Update Magnitude: 0.36798

Collected Steps per Second: 23,029.16284
Overall Steps per Second: 14,699.38808

Timestep Collection Time: 2.17168
Timestep Consumption Time: 1.23064
PPO Batch Consumption Time: 0.10207
Total Iteration Time: 3.40232

Cumulative Model Updates: 57,872
Cumulative Timesteps: 482,834,532

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,274.93086
Policy Entropy: 0.94820
Value Function Loss: 0.08888

Mean KL Divergence: 0.00596
SB3 Clip Fraction: 0.07096
Policy Update Magnitude: 0.21761
Value Function Update Magnitude: 0.32501

Collected Steps per Second: 23,145.04649
Overall Steps per Second: 15,038.09079

Timestep Collection Time: 2.16133
Timestep Consumption Time: 1.16516
PPO Batch Consumption Time: 0.09945
Total Iteration Time: 3.32649

Cumulative Model Updates: 57,878
Cumulative Timesteps: 482,884,556

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 482884556...
Checkpoint 482884556 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,143.20620
Policy Entropy: 0.94348
Value Function Loss: 0.08825

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.08921
Policy Update Magnitude: 0.19218
Value Function Update Magnitude: 0.35289

Collected Steps per Second: 22,732.33545
Overall Steps per Second: 14,562.16321

Timestep Collection Time: 2.20013
Timestep Consumption Time: 1.23439
PPO Batch Consumption Time: 0.10174
Total Iteration Time: 3.43452

Cumulative Model Updates: 57,884
Cumulative Timesteps: 482,934,570

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,224.36271
Policy Entropy: 0.94878
Value Function Loss: 0.08220

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.08670
Policy Update Magnitude: 0.16584
Value Function Update Magnitude: 0.39317

Collected Steps per Second: 23,592.07522
Overall Steps per Second: 14,941.09564

Timestep Collection Time: 2.12080
Timestep Consumption Time: 1.22795
PPO Batch Consumption Time: 0.10001
Total Iteration Time: 3.34875

Cumulative Model Updates: 57,890
Cumulative Timesteps: 482,984,604

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 482984604...
Checkpoint 482984604 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,810.78404
Policy Entropy: 0.93592
Value Function Loss: 0.08122

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.08495
Policy Update Magnitude: 0.16504
Value Function Update Magnitude: 0.43871

Collected Steps per Second: 22,692.89196
Overall Steps per Second: 14,701.44551

Timestep Collection Time: 2.20439
Timestep Consumption Time: 1.19827
PPO Batch Consumption Time: 0.10200
Total Iteration Time: 3.40266

Cumulative Model Updates: 57,896
Cumulative Timesteps: 483,034,628

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,251.41416
Policy Entropy: 0.94473
Value Function Loss: 0.08399

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.07851
Policy Update Magnitude: 0.17369
Value Function Update Magnitude: 0.45046

Collected Steps per Second: 23,763.22646
Overall Steps per Second: 14,969.79326

Timestep Collection Time: 2.10451
Timestep Consumption Time: 1.23622
PPO Batch Consumption Time: 0.10010
Total Iteration Time: 3.34073

Cumulative Model Updates: 57,902
Cumulative Timesteps: 483,084,638

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 483084638...
Checkpoint 483084638 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,603.37312
Policy Entropy: 0.94538
Value Function Loss: 0.08299

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.07557
Policy Update Magnitude: 0.17742
Value Function Update Magnitude: 0.46247

Collected Steps per Second: 23,166.32813
Overall Steps per Second: 14,810.45995

Timestep Collection Time: 2.15986
Timestep Consumption Time: 1.21856
PPO Batch Consumption Time: 0.09946
Total Iteration Time: 3.37842

Cumulative Model Updates: 57,908
Cumulative Timesteps: 483,134,674

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,048.62631
Policy Entropy: 0.96049
Value Function Loss: 0.08729

Mean KL Divergence: 0.00456
SB3 Clip Fraction: 0.05358
Policy Update Magnitude: 0.19427
Value Function Update Magnitude: 0.46009

Collected Steps per Second: 23,003.69523
Overall Steps per Second: 14,722.29239

Timestep Collection Time: 2.17513
Timestep Consumption Time: 1.22353
PPO Batch Consumption Time: 0.09898
Total Iteration Time: 3.39866

Cumulative Model Updates: 57,914
Cumulative Timesteps: 483,184,710

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 483184710...
Checkpoint 483184710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,756.43689
Policy Entropy: 0.96136
Value Function Loss: 0.08209

Mean KL Divergence: 0.00455
SB3 Clip Fraction: 0.05334
Policy Update Magnitude: 0.21306
Value Function Update Magnitude: 0.45101

Collected Steps per Second: 23,132.18665
Overall Steps per Second: 14,664.34101

Timestep Collection Time: 2.16305
Timestep Consumption Time: 1.24904
PPO Batch Consumption Time: 0.10093
Total Iteration Time: 3.41209

Cumulative Model Updates: 57,920
Cumulative Timesteps: 483,234,746

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,412.95926
Policy Entropy: 0.95674
Value Function Loss: 0.08701

Mean KL Divergence: 0.00471
SB3 Clip Fraction: 0.05590
Policy Update Magnitude: 0.21792
Value Function Update Magnitude: 0.45093

Collected Steps per Second: 23,353.00642
Overall Steps per Second: 14,905.05321

Timestep Collection Time: 2.14217
Timestep Consumption Time: 1.21415
PPO Batch Consumption Time: 0.09980
Total Iteration Time: 3.35631

Cumulative Model Updates: 57,926
Cumulative Timesteps: 483,284,772

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 483284772...
Checkpoint 483284772 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,051.06803
Policy Entropy: 0.94246
Value Function Loss: 0.08041

Mean KL Divergence: 0.00429
SB3 Clip Fraction: 0.05165
Policy Update Magnitude: 0.22074
Value Function Update Magnitude: 0.45659

Collected Steps per Second: 22,835.75324
Overall Steps per Second: 14,676.06983

Timestep Collection Time: 2.19086
Timestep Consumption Time: 1.21809
PPO Batch Consumption Time: 0.09981
Total Iteration Time: 3.40895

Cumulative Model Updates: 57,932
Cumulative Timesteps: 483,334,802

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,199.25291
Policy Entropy: 0.94058
Value Function Loss: 0.07463

Mean KL Divergence: 0.00426
SB3 Clip Fraction: 0.05137
Policy Update Magnitude: 0.20906
Value Function Update Magnitude: 0.44165

Collected Steps per Second: 23,611.91396
Overall Steps per Second: 14,951.90242

Timestep Collection Time: 2.11885
Timestep Consumption Time: 1.22722
PPO Batch Consumption Time: 0.10038
Total Iteration Time: 3.34606

Cumulative Model Updates: 57,938
Cumulative Timesteps: 483,384,832

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 483384832...
Checkpoint 483384832 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,154.97525
Policy Entropy: 0.94335
Value Function Loss: 0.07263

Mean KL Divergence: 0.00681
SB3 Clip Fraction: 0.07138
Policy Update Magnitude: 0.19933
Value Function Update Magnitude: 0.41857

Collected Steps per Second: 23,061.25716
Overall Steps per Second: 14,664.26131

Timestep Collection Time: 2.16875
Timestep Consumption Time: 1.24186
PPO Batch Consumption Time: 0.10189
Total Iteration Time: 3.41060

Cumulative Model Updates: 57,944
Cumulative Timesteps: 483,434,846

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,865.73235
Policy Entropy: 0.95092
Value Function Loss: 0.06905

Mean KL Divergence: 0.00585
SB3 Clip Fraction: 0.06274
Policy Update Magnitude: 0.19388
Value Function Update Magnitude: 0.40486

Collected Steps per Second: 23,431.78950
Overall Steps per Second: 14,744.52389

Timestep Collection Time: 2.13505
Timestep Consumption Time: 1.25794
PPO Batch Consumption Time: 0.10156
Total Iteration Time: 3.39299

Cumulative Model Updates: 57,950
Cumulative Timesteps: 483,484,874

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 483484874...
Checkpoint 483484874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,240.43510
Policy Entropy: 0.94810
Value Function Loss: 0.06797

Mean KL Divergence: 0.00557
SB3 Clip Fraction: 0.06334
Policy Update Magnitude: 0.20086
Value Function Update Magnitude: 0.38135

Collected Steps per Second: 23,314.37541
Overall Steps per Second: 14,844.95650

Timestep Collection Time: 2.14563
Timestep Consumption Time: 1.22413
PPO Batch Consumption Time: 0.10151
Total Iteration Time: 3.36976

Cumulative Model Updates: 57,956
Cumulative Timesteps: 483,534,898

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,039.84400
Policy Entropy: 0.93503
Value Function Loss: 0.06749

Mean KL Divergence: 0.00436
SB3 Clip Fraction: 0.05251
Policy Update Magnitude: 0.20916
Value Function Update Magnitude: 0.37176

Collected Steps per Second: 23,161.91279
Overall Steps per Second: 14,878.14425

Timestep Collection Time: 2.15915
Timestep Consumption Time: 1.20216
PPO Batch Consumption Time: 0.10086
Total Iteration Time: 3.36131

Cumulative Model Updates: 57,962
Cumulative Timesteps: 483,584,908

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 483584908...
Checkpoint 483584908 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,278.90165
Policy Entropy: 0.92478
Value Function Loss: 0.07541

Mean KL Divergence: 0.00419
SB3 Clip Fraction: 0.05055
Policy Update Magnitude: 0.21607
Value Function Update Magnitude: 0.40518

Collected Steps per Second: 22,695.83857
Overall Steps per Second: 14,727.45425

Timestep Collection Time: 2.20490
Timestep Consumption Time: 1.19297
PPO Batch Consumption Time: 0.10057
Total Iteration Time: 3.39787

Cumulative Model Updates: 57,968
Cumulative Timesteps: 483,634,950

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,777.02067
Policy Entropy: 0.91752
Value Function Loss: 0.07467

Mean KL Divergence: 0.00490
SB3 Clip Fraction: 0.05828
Policy Update Magnitude: 0.22293
Value Function Update Magnitude: 0.45998

Collected Steps per Second: 23,724.01486
Overall Steps per Second: 14,962.25709

Timestep Collection Time: 2.10841
Timestep Consumption Time: 1.23467
PPO Batch Consumption Time: 0.10037
Total Iteration Time: 3.34308

Cumulative Model Updates: 57,974
Cumulative Timesteps: 483,684,970

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 483684970...
Checkpoint 483684970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,123.06282
Policy Entropy: 0.92552
Value Function Loss: 0.08002

Mean KL Divergence: 0.00511
SB3 Clip Fraction: 0.06029
Policy Update Magnitude: 0.21603
Value Function Update Magnitude: 0.47582

Collected Steps per Second: 22,800.96219
Overall Steps per Second: 14,661.32598

Timestep Collection Time: 2.19394
Timestep Consumption Time: 1.21803
PPO Batch Consumption Time: 0.10017
Total Iteration Time: 3.41197

Cumulative Model Updates: 57,980
Cumulative Timesteps: 483,734,994

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,774.12883
Policy Entropy: 0.94162
Value Function Loss: 0.07872

Mean KL Divergence: 0.00554
SB3 Clip Fraction: 0.06328
Policy Update Magnitude: 0.22176
Value Function Update Magnitude: 0.46456

Collected Steps per Second: 23,400.18870
Overall Steps per Second: 14,830.49151

Timestep Collection Time: 2.13759
Timestep Consumption Time: 1.23519
PPO Batch Consumption Time: 0.10141
Total Iteration Time: 3.37278

Cumulative Model Updates: 57,986
Cumulative Timesteps: 483,785,014

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 483785014...
Checkpoint 483785014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,157.58050
Policy Entropy: 0.93981
Value Function Loss: 0.08551

Mean KL Divergence: 0.00559
SB3 Clip Fraction: 0.06475
Policy Update Magnitude: 0.22741
Value Function Update Magnitude: 0.44979

Collected Steps per Second: 23,017.84548
Overall Steps per Second: 14,744.98353

Timestep Collection Time: 2.17249
Timestep Consumption Time: 1.21890
PPO Batch Consumption Time: 0.09913
Total Iteration Time: 3.39139

Cumulative Model Updates: 57,992
Cumulative Timesteps: 483,835,020

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,071.44808
Policy Entropy: 0.94506
Value Function Loss: 0.07798

Mean KL Divergence: 0.00505
SB3 Clip Fraction: 0.06001
Policy Update Magnitude: 0.23113
Value Function Update Magnitude: 0.45104

Collected Steps per Second: 23,262.33431
Overall Steps per Second: 14,748.70816

Timestep Collection Time: 2.15069
Timestep Consumption Time: 1.24147
PPO Batch Consumption Time: 0.10006
Total Iteration Time: 3.39216

Cumulative Model Updates: 57,998
Cumulative Timesteps: 483,885,050

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 483885050...
Checkpoint 483885050 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,002.36389
Policy Entropy: 0.93505
Value Function Loss: 0.07461

Mean KL Divergence: 0.00560
SB3 Clip Fraction: 0.06572
Policy Update Magnitude: 0.21928
Value Function Update Magnitude: 0.43260

Collected Steps per Second: 23,144.22803
Overall Steps per Second: 14,799.91802

Timestep Collection Time: 2.16063
Timestep Consumption Time: 1.21818
PPO Batch Consumption Time: 0.09701
Total Iteration Time: 3.37880

Cumulative Model Updates: 58,004
Cumulative Timesteps: 483,935,056

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,322.74202
Policy Entropy: 0.93905
Value Function Loss: 0.07022

Mean KL Divergence: 0.00461
SB3 Clip Fraction: 0.05486
Policy Update Magnitude: 0.20544
Value Function Update Magnitude: 0.41441

Collected Steps per Second: 23,585.90428
Overall Steps per Second: 15,104.59803

Timestep Collection Time: 2.12084
Timestep Consumption Time: 1.19086
PPO Batch Consumption Time: 0.10000
Total Iteration Time: 3.31171

Cumulative Model Updates: 58,010
Cumulative Timesteps: 483,985,078

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 483985078...
Checkpoint 483985078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,701.96178
Policy Entropy: 0.92663
Value Function Loss: 0.06781

Mean KL Divergence: 0.00416
SB3 Clip Fraction: 0.04941
Policy Update Magnitude: 0.20454
Value Function Update Magnitude: 0.40926

Collected Steps per Second: 22,447.25203
Overall Steps per Second: 14,554.70870

Timestep Collection Time: 2.22905
Timestep Consumption Time: 1.20874
PPO Batch Consumption Time: 0.09893
Total Iteration Time: 3.43779

Cumulative Model Updates: 58,016
Cumulative Timesteps: 484,035,114

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,394.34925
Policy Entropy: 0.92780
Value Function Loss: 0.07224

Mean KL Divergence: 0.00382
SB3 Clip Fraction: 0.04490
Policy Update Magnitude: 0.20482
Value Function Update Magnitude: 0.42151

Collected Steps per Second: 23,549.74004
Overall Steps per Second: 14,911.62590

Timestep Collection Time: 2.12385
Timestep Consumption Time: 1.23032
PPO Batch Consumption Time: 0.10051
Total Iteration Time: 3.35416

Cumulative Model Updates: 58,022
Cumulative Timesteps: 484,085,130

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 484085130...
Checkpoint 484085130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,844.19525
Policy Entropy: 0.91315
Value Function Loss: 0.07233

Mean KL Divergence: 0.00459
SB3 Clip Fraction: 0.05503
Policy Update Magnitude: 0.20943
Value Function Update Magnitude: 0.42777

Collected Steps per Second: 22,919.84762
Overall Steps per Second: 14,684.36455

Timestep Collection Time: 2.18213
Timestep Consumption Time: 1.22381
PPO Batch Consumption Time: 0.10010
Total Iteration Time: 3.40594

Cumulative Model Updates: 58,028
Cumulative Timesteps: 484,135,144

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,233.69527
Policy Entropy: 0.91942
Value Function Loss: 0.07893

Mean KL Divergence: 0.00426
SB3 Clip Fraction: 0.05104
Policy Update Magnitude: 0.21216
Value Function Update Magnitude: 0.43014

Collected Steps per Second: 23,109.10253
Overall Steps per Second: 14,770.86039

Timestep Collection Time: 2.16538
Timestep Consumption Time: 1.22237
PPO Batch Consumption Time: 0.10223
Total Iteration Time: 3.38775

Cumulative Model Updates: 58,034
Cumulative Timesteps: 484,185,184

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 484185184...
Checkpoint 484185184 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,566.92759
Policy Entropy: 0.91100
Value Function Loss: 0.07359

Mean KL Divergence: 0.00468
SB3 Clip Fraction: 0.05400
Policy Update Magnitude: 0.21893
Value Function Update Magnitude: 0.43637

Collected Steps per Second: 22,972.98458
Overall Steps per Second: 14,782.97922

Timestep Collection Time: 2.17708
Timestep Consumption Time: 1.20614
PPO Batch Consumption Time: 0.09824
Total Iteration Time: 3.38322

Cumulative Model Updates: 58,040
Cumulative Timesteps: 484,235,198

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,739.33029
Policy Entropy: 0.91685
Value Function Loss: 0.06953

Mean KL Divergence: 0.00478
SB3 Clip Fraction: 0.05478
Policy Update Magnitude: 0.21537
Value Function Update Magnitude: 0.42519

Collected Steps per Second: 23,474.26325
Overall Steps per Second: 15,030.22396

Timestep Collection Time: 2.13025
Timestep Consumption Time: 1.19678
PPO Batch Consumption Time: 0.09930
Total Iteration Time: 3.32703

Cumulative Model Updates: 58,046
Cumulative Timesteps: 484,285,204

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 484285204...
Checkpoint 484285204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,351.69916
Policy Entropy: 0.90915
Value Function Loss: 0.06329

Mean KL Divergence: 0.00508
SB3 Clip Fraction: 0.05761
Policy Update Magnitude: 0.21303
Value Function Update Magnitude: 0.42087

Collected Steps per Second: 22,761.20037
Overall Steps per Second: 14,583.52401

Timestep Collection Time: 2.19672
Timestep Consumption Time: 1.23181
PPO Batch Consumption Time: 0.09954
Total Iteration Time: 3.42853

Cumulative Model Updates: 58,052
Cumulative Timesteps: 484,335,204

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,554.32599
Policy Entropy: 0.91177
Value Function Loss: 0.06478

Mean KL Divergence: 0.00504
SB3 Clip Fraction: 0.06112
Policy Update Magnitude: 0.21094
Value Function Update Magnitude: 0.39877

Collected Steps per Second: 22,652.12421
Overall Steps per Second: 14,661.20009

Timestep Collection Time: 2.20959
Timestep Consumption Time: 1.20431
PPO Batch Consumption Time: 0.09570
Total Iteration Time: 3.41391

Cumulative Model Updates: 58,058
Cumulative Timesteps: 484,385,256

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


Saving checkpoint 484385256...
Checkpoint 484385256 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,943.77233
Policy Entropy: 0.93097
Value Function Loss: 0.06094

Mean KL Divergence: 0.00626
SB3 Clip Fraction: 0.07049
Policy Update Magnitude: 0.20603
Value Function Update Magnitude: 0.38748

Collected Steps per Second: 22,941.39475
Overall Steps per Second: 14,816.48335

Timestep Collection Time: 2.17964
Timestep Consumption Time: 1.19525
PPO Batch Consumption Time: 0.09354
Total Iteration Time: 3.37489

Cumulative Model Updates: 58,064
Cumulative Timesteps: 484,435,260

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42,198.04292
Policy Entropy: 0.93419
Value Function Loss: 0.06001

Mean KL Divergence: 0.00550
SB3 Clip Fraction: 0.06309
Policy Update Magnitude: 0.19521
Value Function Update Magnitude: 0.38984

Collected Steps per Second: 22,871.37269
Overall Steps per Second: 14,779.64092

Timestep Collection Time: 2.18728
Timestep Consumption Time: 1.19752
PPO Batch Consumption Time: 0.09509
Total Iteration Time: 3.38479

Cumulative Model Updates: 58,070
Cumulative Timesteps: 484,485,286

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 484485286...
Checkpoint 484485286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,961.41889
Policy Entropy: 0.95041
Value Function Loss: 0.06014

Mean KL Divergence: 0.00475
SB3 Clip Fraction: 0.05571
Policy Update Magnitude: 0.19399
Value Function Update Magnitude: 0.39639

Collected Steps per Second: 22,328.08386
Overall Steps per Second: 14,433.26390

Timestep Collection Time: 2.24077
Timestep Consumption Time: 1.22567
PPO Batch Consumption Time: 0.10073
Total Iteration Time: 3.46644

Cumulative Model Updates: 58,076
Cumulative Timesteps: 484,535,318

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42,113.71256
Policy Entropy: 0.94848
Value Function Loss: 0.06240

Mean KL Divergence: 0.00557
SB3 Clip Fraction: 0.06763
Policy Update Magnitude: 0.19577
Value Function Update Magnitude: 0.38427

Collected Steps per Second: 22,627.96720
Overall Steps per Second: 14,446.85588

Timestep Collection Time: 2.21133
Timestep Consumption Time: 1.25226
PPO Batch Consumption Time: 0.10011
Total Iteration Time: 3.46359

Cumulative Model Updates: 58,082
Cumulative Timesteps: 484,585,356

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 484585356...
Checkpoint 484585356 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,894.76448
Policy Entropy: 0.95341
Value Function Loss: 0.06679

Mean KL Divergence: 0.00462
SB3 Clip Fraction: 0.05526
Policy Update Magnitude: 0.19509
Value Function Update Magnitude: 0.38790

Collected Steps per Second: 23,226.94988
Overall Steps per Second: 14,840.66880

Timestep Collection Time: 2.15267
Timestep Consumption Time: 1.21645
PPO Batch Consumption Time: 0.10047
Total Iteration Time: 3.36912

Cumulative Model Updates: 58,088
Cumulative Timesteps: 484,635,356

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,525.82359
Policy Entropy: 0.94942
Value Function Loss: 0.06691

Mean KL Divergence: 0.00488
SB3 Clip Fraction: 0.05697
Policy Update Magnitude: 0.19258
Value Function Update Magnitude: 0.40581

Collected Steps per Second: 23,665.69510
Overall Steps per Second: 15,056.37181

Timestep Collection Time: 2.11285
Timestep Consumption Time: 1.20814
PPO Batch Consumption Time: 0.09977
Total Iteration Time: 3.32099

Cumulative Model Updates: 58,094
Cumulative Timesteps: 484,685,358

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 484685358...
Checkpoint 484685358 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,610.01062
Policy Entropy: 0.94562
Value Function Loss: 0.06568

Mean KL Divergence: 0.00501
SB3 Clip Fraction: 0.05941
Policy Update Magnitude: 0.19336
Value Function Update Magnitude: 0.40357

Collected Steps per Second: 22,121.77691
Overall Steps per Second: 14,424.85603

Timestep Collection Time: 2.26058
Timestep Consumption Time: 1.20622
PPO Batch Consumption Time: 0.09474
Total Iteration Time: 3.46679

Cumulative Model Updates: 58,100
Cumulative Timesteps: 484,735,366

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,218.83766
Policy Entropy: 0.94955
Value Function Loss: 0.07275

Mean KL Divergence: 0.00515
SB3 Clip Fraction: 0.06033
Policy Update Magnitude: 0.19235
Value Function Update Magnitude: 0.40108

Collected Steps per Second: 23,466.90090
Overall Steps per Second: 14,885.57927

Timestep Collection Time: 2.13211
Timestep Consumption Time: 1.22913
PPO Batch Consumption Time: 0.10228
Total Iteration Time: 3.36124

Cumulative Model Updates: 58,106
Cumulative Timesteps: 484,785,400

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 484785400...
Checkpoint 484785400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,221.47189
Policy Entropy: 0.96053
Value Function Loss: 0.06626

Mean KL Divergence: 0.00633
SB3 Clip Fraction: 0.07226
Policy Update Magnitude: 0.18705
Value Function Update Magnitude: 0.42087

Collected Steps per Second: 22,772.38469
Overall Steps per Second: 14,719.68023

Timestep Collection Time: 2.19731
Timestep Consumption Time: 1.20208
PPO Batch Consumption Time: 0.09260
Total Iteration Time: 3.39939

Cumulative Model Updates: 58,112
Cumulative Timesteps: 484,835,438

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,919.74211
Policy Entropy: 0.94522
Value Function Loss: 0.06465

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.08914
Policy Update Magnitude: 0.16946
Value Function Update Magnitude: 0.42132

Collected Steps per Second: 22,946.77004
Overall Steps per Second: 14,796.92023

Timestep Collection Time: 2.18000
Timestep Consumption Time: 1.20070
PPO Batch Consumption Time: 0.09533
Total Iteration Time: 3.38070

Cumulative Model Updates: 58,118
Cumulative Timesteps: 484,885,462

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 484885462...
Checkpoint 484885462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,011.31026
Policy Entropy: 0.94737
Value Function Loss: 0.06580

Mean KL Divergence: 0.00706
SB3 Clip Fraction: 0.07272
Policy Update Magnitude: 0.18402
Value Function Update Magnitude: 0.41560

Collected Steps per Second: 23,479.51543
Overall Steps per Second: 14,986.48537

Timestep Collection Time: 2.12969
Timestep Consumption Time: 1.20692
PPO Batch Consumption Time: 0.10155
Total Iteration Time: 3.33661

Cumulative Model Updates: 58,124
Cumulative Timesteps: 484,935,466

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,274.37737
Policy Entropy: 0.95158
Value Function Loss: 0.06429

Mean KL Divergence: 0.00575
SB3 Clip Fraction: 0.06393
Policy Update Magnitude: 0.19218
Value Function Update Magnitude: 0.40817

Collected Steps per Second: 23,369.94210
Overall Steps per Second: 14,919.22907

Timestep Collection Time: 2.14027
Timestep Consumption Time: 1.21232
PPO Batch Consumption Time: 0.09997
Total Iteration Time: 3.35259

Cumulative Model Updates: 58,130
Cumulative Timesteps: 484,985,484

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 484985484...
Checkpoint 484985484 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,803.43152
Policy Entropy: 0.95844
Value Function Loss: 0.06208

Mean KL Divergence: 0.00460
SB3 Clip Fraction: 0.05434
Policy Update Magnitude: 0.19472
Value Function Update Magnitude: 0.39415

Collected Steps per Second: 22,059.21731
Overall Steps per Second: 14,655.57123

Timestep Collection Time: 2.26871
Timestep Consumption Time: 1.14610
PPO Batch Consumption Time: 0.10082
Total Iteration Time: 3.41481

Cumulative Model Updates: 58,136
Cumulative Timesteps: 485,035,530

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,899.22592
Policy Entropy: 0.95492
Value Function Loss: 0.05661

Mean KL Divergence: 0.00396
SB3 Clip Fraction: 0.04786
Policy Update Magnitude: 0.19174
Value Function Update Magnitude: 0.37793

Collected Steps per Second: 22,961.96073
Overall Steps per Second: 15,140.74977

Timestep Collection Time: 2.17847
Timestep Consumption Time: 1.12533
PPO Batch Consumption Time: 0.09878
Total Iteration Time: 3.30380

Cumulative Model Updates: 58,142
Cumulative Timesteps: 485,085,552

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 485085552...
Checkpoint 485085552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,196.88454
Policy Entropy: 0.93878
Value Function Loss: 0.05809

Mean KL Divergence: 0.00555
SB3 Clip Fraction: 0.06055
Policy Update Magnitude: 0.18391
Value Function Update Magnitude: 0.37079

Collected Steps per Second: 21,625.24602
Overall Steps per Second: 14,436.26148

Timestep Collection Time: 2.31285
Timestep Consumption Time: 1.15176
PPO Batch Consumption Time: 0.09856
Total Iteration Time: 3.46461

Cumulative Model Updates: 58,148
Cumulative Timesteps: 485,135,568

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,013.03476
Policy Entropy: 0.94072
Value Function Loss: 0.07300

Mean KL Divergence: 0.01159
SB3 Clip Fraction: 0.09597
Policy Update Magnitude: 0.18401
Value Function Update Magnitude: 0.39914

Collected Steps per Second: 22,735.55693
Overall Steps per Second: 14,796.29745

Timestep Collection Time: 2.20052
Timestep Consumption Time: 1.18073
PPO Batch Consumption Time: 0.10141
Total Iteration Time: 3.38125

Cumulative Model Updates: 58,154
Cumulative Timesteps: 485,185,598

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 485185598...
Checkpoint 485185598 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,023.82885
Policy Entropy: 0.94826
Value Function Loss: 0.07922

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.08971
Policy Update Magnitude: 0.18832
Value Function Update Magnitude: 0.45050

Collected Steps per Second: 22,590.18191
Overall Steps per Second: 14,858.26025

Timestep Collection Time: 2.21459
Timestep Consumption Time: 1.15243
PPO Batch Consumption Time: 0.10100
Total Iteration Time: 3.36702

Cumulative Model Updates: 58,160
Cumulative Timesteps: 485,235,626

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,079.55590
Policy Entropy: 0.95703
Value Function Loss: 0.09097

Mean KL Divergence: 0.01057
SB3 Clip Fraction: 0.09901
Policy Update Magnitude: 0.20501
Value Function Update Magnitude: 0.45889

Collected Steps per Second: 22,629.13353
Overall Steps per Second: 14,990.96265

Timestep Collection Time: 2.20989
Timestep Consumption Time: 1.12598
PPO Batch Consumption Time: 0.09949
Total Iteration Time: 3.33588

Cumulative Model Updates: 58,166
Cumulative Timesteps: 485,285,634

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 485285634...
Checkpoint 485285634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,615.63580
Policy Entropy: 0.95442
Value Function Loss: 0.08494

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.08973
Policy Update Magnitude: 0.21381
Value Function Update Magnitude: 0.45486

Collected Steps per Second: 22,408.02055
Overall Steps per Second: 14,847.48737

Timestep Collection Time: 2.23250
Timestep Consumption Time: 1.13682
PPO Batch Consumption Time: 0.09994
Total Iteration Time: 3.36932

Cumulative Model Updates: 58,172
Cumulative Timesteps: 485,335,660

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,510.30804
Policy Entropy: 0.95300
Value Function Loss: 0.07947

Mean KL Divergence: 0.00624
SB3 Clip Fraction: 0.07338
Policy Update Magnitude: 0.21059
Value Function Update Magnitude: 0.45752

Collected Steps per Second: 22,907.45599
Overall Steps per Second: 15,272.10460

Timestep Collection Time: 2.18435
Timestep Consumption Time: 1.09208
PPO Batch Consumption Time: 0.09198
Total Iteration Time: 3.27643

Cumulative Model Updates: 58,178
Cumulative Timesteps: 485,385,698

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 485385698...
Checkpoint 485385698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,317.78095
Policy Entropy: 0.94342
Value Function Loss: 0.07200

Mean KL Divergence: 0.00713
SB3 Clip Fraction: 0.08023
Policy Update Magnitude: 0.20311
Value Function Update Magnitude: 0.44812

Collected Steps per Second: 22,157.31749
Overall Steps per Second: 14,807.52599

Timestep Collection Time: 2.25822
Timestep Consumption Time: 1.12088
PPO Batch Consumption Time: 0.09294
Total Iteration Time: 3.37909

Cumulative Model Updates: 58,184
Cumulative Timesteps: 485,435,734

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,964.30482
Policy Entropy: 0.93421
Value Function Loss: 0.07621

Mean KL Divergence: 0.01050
SB3 Clip Fraction: 0.10683
Policy Update Magnitude: 0.18155
Value Function Update Magnitude: 0.44885

Collected Steps per Second: 22,624.79877
Overall Steps per Second: 14,772.40919

Timestep Collection Time: 2.21041
Timestep Consumption Time: 1.17496
PPO Batch Consumption Time: 0.09469
Total Iteration Time: 3.38537

Cumulative Model Updates: 58,190
Cumulative Timesteps: 485,485,744

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 485485744...
Checkpoint 485485744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,922.75473
Policy Entropy: 0.94241
Value Function Loss: 0.08590

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.09296
Policy Update Magnitude: 0.16231
Value Function Update Magnitude: 0.46254

Collected Steps per Second: 23,265.69030
Overall Steps per Second: 14,966.27441

Timestep Collection Time: 2.14960
Timestep Consumption Time: 1.19204
PPO Batch Consumption Time: 0.09855
Total Iteration Time: 3.34165

Cumulative Model Updates: 58,196
Cumulative Timesteps: 485,535,756

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,148.81032
Policy Entropy: 0.96686
Value Function Loss: 0.08480

Mean KL Divergence: 0.00660
SB3 Clip Fraction: 0.07249
Policy Update Magnitude: 0.19621
Value Function Update Magnitude: 0.50039

Collected Steps per Second: 23,210.52359
Overall Steps per Second: 14,802.11890

Timestep Collection Time: 2.15437
Timestep Consumption Time: 1.22380
PPO Batch Consumption Time: 0.10143
Total Iteration Time: 3.37817

Cumulative Model Updates: 58,202
Cumulative Timesteps: 485,585,760

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 485585760...
Checkpoint 485585760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,806.02349
Policy Entropy: 0.95751
Value Function Loss: 0.07704

Mean KL Divergence: 0.00613
SB3 Clip Fraction: 0.06575
Policy Update Magnitude: 0.21007
Value Function Update Magnitude: 0.49523

Collected Steps per Second: 23,226.10183
Overall Steps per Second: 14,917.63240

Timestep Collection Time: 2.15447
Timestep Consumption Time: 1.19995
PPO Batch Consumption Time: 0.10073
Total Iteration Time: 3.35442

Cumulative Model Updates: 58,208
Cumulative Timesteps: 485,635,800

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,719.93721
Policy Entropy: 0.95536
Value Function Loss: 0.06594

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.08701
Policy Update Magnitude: 0.18501
Value Function Update Magnitude: 0.46362

Collected Steps per Second: 23,056.56374
Overall Steps per Second: 14,830.53857

Timestep Collection Time: 2.16884
Timestep Consumption Time: 1.20299
PPO Batch Consumption Time: 0.10077
Total Iteration Time: 3.37183

Cumulative Model Updates: 58,214
Cumulative Timesteps: 485,685,806

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 485685806...
Checkpoint 485685806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,930.51735
Policy Entropy: 0.94750
Value Function Loss: 0.06726

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.07652
Policy Update Magnitude: 0.16410
Value Function Update Magnitude: 0.40421

Collected Steps per Second: 22,662.82737
Overall Steps per Second: 14,535.26188

Timestep Collection Time: 2.20634
Timestep Consumption Time: 1.23370
PPO Batch Consumption Time: 0.09542
Total Iteration Time: 3.44005

Cumulative Model Updates: 58,220
Cumulative Timesteps: 485,735,808

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,496.08817
Policy Entropy: 0.95709
Value Function Loss: 0.07027

Mean KL Divergence: 0.00522
SB3 Clip Fraction: 0.05638
Policy Update Magnitude: 0.17826
Value Function Update Magnitude: 0.40908

Collected Steps per Second: 23,400.66423
Overall Steps per Second: 14,866.08327

Timestep Collection Time: 2.13797
Timestep Consumption Time: 1.22741
PPO Batch Consumption Time: 0.09960
Total Iteration Time: 3.36538

Cumulative Model Updates: 58,226
Cumulative Timesteps: 485,785,838

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 485785838...
Checkpoint 485785838 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,016.00081
Policy Entropy: 0.94199
Value Function Loss: 0.07709

Mean KL Divergence: 0.00595
SB3 Clip Fraction: 0.06564
Policy Update Magnitude: 0.18945
Value Function Update Magnitude: 0.41622

Collected Steps per Second: 22,298.61256
Overall Steps per Second: 14,336.89003

Timestep Collection Time: 2.24310
Timestep Consumption Time: 1.24566
PPO Batch Consumption Time: 0.09990
Total Iteration Time: 3.48876

Cumulative Model Updates: 58,232
Cumulative Timesteps: 485,835,856

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,341.80586
Policy Entropy: 0.94931
Value Function Loss: 0.06717

Mean KL Divergence: 0.01071
SB3 Clip Fraction: 0.09963
Policy Update Magnitude: 0.17960
Value Function Update Magnitude: 0.42369

Collected Steps per Second: 23,527.15553
Overall Steps per Second: 15,172.16394

Timestep Collection Time: 2.12639
Timestep Consumption Time: 1.17096
PPO Batch Consumption Time: 0.09162
Total Iteration Time: 3.29735

Cumulative Model Updates: 58,238
Cumulative Timesteps: 485,885,884

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 485885884...
Checkpoint 485885884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,815.88045
Policy Entropy: 0.94807
Value Function Loss: 0.06896

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.08562
Policy Update Magnitude: 0.17280
Value Function Update Magnitude: 0.40626

Collected Steps per Second: 23,373.78518
Overall Steps per Second: 14,946.42038

Timestep Collection Time: 2.13992
Timestep Consumption Time: 1.20657
PPO Batch Consumption Time: 0.09753
Total Iteration Time: 3.34649

Cumulative Model Updates: 58,244
Cumulative Timesteps: 485,935,902

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,273.42845
Policy Entropy: 0.96378
Value Function Loss: 0.06589

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.09122
Policy Update Magnitude: 0.17944
Value Function Update Magnitude: 0.39552

Collected Steps per Second: 23,261.31486
Overall Steps per Second: 14,878.52119

Timestep Collection Time: 2.14975
Timestep Consumption Time: 1.21120
PPO Batch Consumption Time: 0.10105
Total Iteration Time: 3.36095

Cumulative Model Updates: 58,250
Cumulative Timesteps: 485,985,908

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 485985908...
Checkpoint 485985908 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47,798.69743
Policy Entropy: 0.96337
Value Function Loss: 0.07208

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.08055
Policy Update Magnitude: 0.18148
Value Function Update Magnitude: 0.40293

Collected Steps per Second: 23,177.76606
Overall Steps per Second: 14,715.32766

Timestep Collection Time: 2.15828
Timestep Consumption Time: 1.24117
PPO Batch Consumption Time: 0.09902
Total Iteration Time: 3.39945

Cumulative Model Updates: 58,256
Cumulative Timesteps: 486,035,932

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,986.58046
Policy Entropy: 0.96262
Value Function Loss: 0.05962

Mean KL Divergence: 0.00592
SB3 Clip Fraction: 0.06849
Policy Update Magnitude: 0.18176
Value Function Update Magnitude: 0.39639

Collected Steps per Second: 23,417.08655
Overall Steps per Second: 14,888.52818

Timestep Collection Time: 2.13596
Timestep Consumption Time: 1.22354
PPO Batch Consumption Time: 0.10231
Total Iteration Time: 3.35950

Cumulative Model Updates: 58,262
Cumulative Timesteps: 486,085,950

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 486085950...
Checkpoint 486085950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,723.77306
Policy Entropy: 0.95791
Value Function Loss: 0.05814

Mean KL Divergence: 0.00601
SB3 Clip Fraction: 0.07005
Policy Update Magnitude: 0.17285
Value Function Update Magnitude: 0.36949

Collected Steps per Second: 22,847.15579
Overall Steps per Second: 14,701.63405

Timestep Collection Time: 2.19003
Timestep Consumption Time: 1.21340
PPO Batch Consumption Time: 0.09730
Total Iteration Time: 3.40343

Cumulative Model Updates: 58,268
Cumulative Timesteps: 486,135,986

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,923.80082
Policy Entropy: 0.95291
Value Function Loss: 0.05540

Mean KL Divergence: 0.00565
SB3 Clip Fraction: 0.06817
Policy Update Magnitude: 0.16568
Value Function Update Magnitude: 0.35660

Collected Steps per Second: 23,668.77788
Overall Steps per Second: 14,905.64726

Timestep Collection Time: 2.11409
Timestep Consumption Time: 1.24289
PPO Batch Consumption Time: 0.10200
Total Iteration Time: 3.35698

Cumulative Model Updates: 58,274
Cumulative Timesteps: 486,186,024

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 486186024...
Checkpoint 486186024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,696.67683
Policy Entropy: 0.96333
Value Function Loss: 0.06237

Mean KL Divergence: 0.00612
SB3 Clip Fraction: 0.07091
Policy Update Magnitude: 0.17151
Value Function Update Magnitude: 0.35434

Collected Steps per Second: 22,909.03112
Overall Steps per Second: 14,731.53150

Timestep Collection Time: 2.18359
Timestep Consumption Time: 1.21212
PPO Batch Consumption Time: 0.09881
Total Iteration Time: 3.39571

Cumulative Model Updates: 58,280
Cumulative Timesteps: 486,236,048

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,564.57318
Policy Entropy: 0.96987
Value Function Loss: 0.07025

Mean KL Divergence: 0.00476
SB3 Clip Fraction: 0.05794
Policy Update Magnitude: 0.17738
Value Function Update Magnitude: 0.37698

Collected Steps per Second: 23,213.47021
Overall Steps per Second: 14,961.69933

Timestep Collection Time: 2.15556
Timestep Consumption Time: 1.18885
PPO Batch Consumption Time: 0.10012
Total Iteration Time: 3.34441

Cumulative Model Updates: 58,286
Cumulative Timesteps: 486,286,086

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 486286086...
Checkpoint 486286086 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,359.94945
Policy Entropy: 0.97696
Value Function Loss: 0.06874

Mean KL Divergence: 0.00431
SB3 Clip Fraction: 0.05214
Policy Update Magnitude: 0.18740
Value Function Update Magnitude: 0.39982

Collected Steps per Second: 23,550.52755
Overall Steps per Second: 15,011.77452

Timestep Collection Time: 2.12420
Timestep Consumption Time: 1.20825
PPO Batch Consumption Time: 0.09894
Total Iteration Time: 3.33245

Cumulative Model Updates: 58,292
Cumulative Timesteps: 486,336,112

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,741.36520
Policy Entropy: 0.97462
Value Function Loss: 0.07208

Mean KL Divergence: 0.00561
SB3 Clip Fraction: 0.06350
Policy Update Magnitude: 0.18125
Value Function Update Magnitude: 0.40382

Collected Steps per Second: 22,583.64970
Overall Steps per Second: 14,651.21735

Timestep Collection Time: 2.21514
Timestep Consumption Time: 1.19932
PPO Batch Consumption Time: 0.09942
Total Iteration Time: 3.41446

Cumulative Model Updates: 58,298
Cumulative Timesteps: 486,386,138

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 486386138...
Checkpoint 486386138 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,252.81927
Policy Entropy: 0.96093
Value Function Loss: 0.07879

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.08029
Policy Update Magnitude: 0.17647
Value Function Update Magnitude: 0.40221

Collected Steps per Second: 22,466.01197
Overall Steps per Second: 14,590.06460

Timestep Collection Time: 2.22656
Timestep Consumption Time: 1.20193
PPO Batch Consumption Time: 0.09632
Total Iteration Time: 3.42850

Cumulative Model Updates: 58,304
Cumulative Timesteps: 486,436,160

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,547.67643
Policy Entropy: 0.96201
Value Function Loss: 0.07531

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.07816
Policy Update Magnitude: 0.16482
Value Function Update Magnitude: 0.39687

Collected Steps per Second: 23,579.82932
Overall Steps per Second: 14,908.06287

Timestep Collection Time: 2.12046
Timestep Consumption Time: 1.23343
PPO Batch Consumption Time: 0.10143
Total Iteration Time: 3.35389

Cumulative Model Updates: 58,310
Cumulative Timesteps: 486,486,160

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 486486160...
Checkpoint 486486160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,996.96838
Policy Entropy: 0.96093
Value Function Loss: 0.06851

Mean KL Divergence: 0.00525
SB3 Clip Fraction: 0.05870
Policy Update Magnitude: 0.17593
Value Function Update Magnitude: 0.38957

Collected Steps per Second: 22,993.39903
Overall Steps per Second: 14,709.90781

Timestep Collection Time: 2.17610
Timestep Consumption Time: 1.22541
PPO Batch Consumption Time: 0.09859
Total Iteration Time: 3.40152

Cumulative Model Updates: 58,316
Cumulative Timesteps: 486,536,196

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,401.60173
Policy Entropy: 0.96905
Value Function Loss: 0.06447

Mean KL Divergence: 0.00525
SB3 Clip Fraction: 0.05978
Policy Update Magnitude: 0.17669
Value Function Update Magnitude: 0.38926

Collected Steps per Second: 23,644.65063
Overall Steps per Second: 14,776.57953

Timestep Collection Time: 2.11650
Timestep Consumption Time: 1.27021
PPO Batch Consumption Time: 0.10157
Total Iteration Time: 3.38671

Cumulative Model Updates: 58,322
Cumulative Timesteps: 486,586,240

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 486586240...
Checkpoint 486586240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,549.92118
Policy Entropy: 0.96658
Value Function Loss: 0.07490

Mean KL Divergence: 0.00554
SB3 Clip Fraction: 0.06341
Policy Update Magnitude: 0.17894
Value Function Update Magnitude: 0.37312

Collected Steps per Second: 23,236.02649
Overall Steps per Second: 14,840.71735

Timestep Collection Time: 2.15347
Timestep Consumption Time: 1.21820
PPO Batch Consumption Time: 0.10093
Total Iteration Time: 3.37167

Cumulative Model Updates: 58,328
Cumulative Timesteps: 486,636,278

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,753.53038
Policy Entropy: 0.96089
Value Function Loss: 0.07905

Mean KL Divergence: 0.00595
SB3 Clip Fraction: 0.06770
Policy Update Magnitude: 0.17969
Value Function Update Magnitude: 0.37214

Collected Steps per Second: 22,692.24621
Overall Steps per Second: 14,682.00337

Timestep Collection Time: 2.20340
Timestep Consumption Time: 1.20213
PPO Batch Consumption Time: 0.09695
Total Iteration Time: 3.40553

Cumulative Model Updates: 58,334
Cumulative Timesteps: 486,686,278

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 486686278...
Checkpoint 486686278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,679.02920
Policy Entropy: 0.95729
Value Function Loss: 0.07949

Mean KL Divergence: 0.00531
SB3 Clip Fraction: 0.06247
Policy Update Magnitude: 0.17547
Value Function Update Magnitude: 0.38120

Collected Steps per Second: 23,354.32001
Overall Steps per Second: 14,863.26730

Timestep Collection Time: 2.14179
Timestep Consumption Time: 1.22356
PPO Batch Consumption Time: 0.09891
Total Iteration Time: 3.36534

Cumulative Model Updates: 58,340
Cumulative Timesteps: 486,736,298

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,480.20049
Policy Entropy: 0.95399
Value Function Loss: 0.07505

Mean KL Divergence: 0.00475
SB3 Clip Fraction: 0.05749
Policy Update Magnitude: 0.18183
Value Function Update Magnitude: 0.40065

Collected Steps per Second: 23,723.92724
Overall Steps per Second: 14,958.77814

Timestep Collection Time: 2.10876
Timestep Consumption Time: 1.23563
PPO Batch Consumption Time: 0.10058
Total Iteration Time: 3.34439

Cumulative Model Updates: 58,346
Cumulative Timesteps: 486,786,326

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 486786326...
Checkpoint 486786326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,801.13424
Policy Entropy: 0.95748
Value Function Loss: 0.07031

Mean KL Divergence: 0.00450
SB3 Clip Fraction: 0.05449
Policy Update Magnitude: 0.18923
Value Function Update Magnitude: 0.42947

Collected Steps per Second: 22,545.42469
Overall Steps per Second: 14,647.81801

Timestep Collection Time: 2.21890
Timestep Consumption Time: 1.19635
PPO Batch Consumption Time: 0.09787
Total Iteration Time: 3.41525

Cumulative Model Updates: 58,352
Cumulative Timesteps: 486,836,352

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,219.80770
Policy Entropy: 0.95949
Value Function Loss: 0.06444

Mean KL Divergence: 0.00380
SB3 Clip Fraction: 0.04604
Policy Update Magnitude: 0.19462
Value Function Update Magnitude: 0.41269

Collected Steps per Second: 23,605.01954
Overall Steps per Second: 14,983.13678

Timestep Collection Time: 2.11836
Timestep Consumption Time: 1.21899
PPO Batch Consumption Time: 0.10167
Total Iteration Time: 3.33735

Cumulative Model Updates: 58,358
Cumulative Timesteps: 486,886,356

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 486886356...
Checkpoint 486886356 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,296.63732
Policy Entropy: 0.95858
Value Function Loss: 0.06269

Mean KL Divergence: 0.00386
SB3 Clip Fraction: 0.04725
Policy Update Magnitude: 0.19675
Value Function Update Magnitude: 0.38665

Collected Steps per Second: 23,305.46129
Overall Steps per Second: 14,762.06012

Timestep Collection Time: 2.14654
Timestep Consumption Time: 1.24229
PPO Batch Consumption Time: 0.10106
Total Iteration Time: 3.38882

Cumulative Model Updates: 58,364
Cumulative Timesteps: 486,936,382

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,340.78337
Policy Entropy: 0.96043
Value Function Loss: 0.06488

Mean KL Divergence: 0.00449
SB3 Clip Fraction: 0.05338
Policy Update Magnitude: 0.19247
Value Function Update Magnitude: 0.38082

Collected Steps per Second: 22,774.09311
Overall Steps per Second: 14,602.26181

Timestep Collection Time: 2.19592
Timestep Consumption Time: 1.22890
PPO Batch Consumption Time: 0.09879
Total Iteration Time: 3.42481

Cumulative Model Updates: 58,370
Cumulative Timesteps: 486,986,392

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 486986392...
Checkpoint 486986392 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,201.66662
Policy Entropy: 0.96556
Value Function Loss: 0.06775

Mean KL Divergence: 0.00576
SB3 Clip Fraction: 0.06372
Policy Update Magnitude: 0.19438
Value Function Update Magnitude: 0.38304

Collected Steps per Second: 23,339.67989
Overall Steps per Second: 14,883.30480

Timestep Collection Time: 2.14279
Timestep Consumption Time: 1.21749
PPO Batch Consumption Time: 0.09984
Total Iteration Time: 3.36028

Cumulative Model Updates: 58,376
Cumulative Timesteps: 487,036,404

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,606.20880
Policy Entropy: 0.98091
Value Function Loss: 0.07118

Mean KL Divergence: 0.01117
SB3 Clip Fraction: 0.09225
Policy Update Magnitude: 0.17945
Value Function Update Magnitude: 0.38477

Collected Steps per Second: 23,573.09557
Overall Steps per Second: 14,992.94686

Timestep Collection Time: 2.12183
Timestep Consumption Time: 1.21428
PPO Batch Consumption Time: 0.09975
Total Iteration Time: 3.33610

Cumulative Model Updates: 58,382
Cumulative Timesteps: 487,086,422

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 487086422...
Checkpoint 487086422 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,913.28750
Policy Entropy: 0.97985
Value Function Loss: 0.07279

Mean KL Divergence: 0.00715
SB3 Clip Fraction: 0.07591
Policy Update Magnitude: 0.17615
Value Function Update Magnitude: 0.40167

Collected Steps per Second: 22,493.73864
Overall Steps per Second: 14,588.02995

Timestep Collection Time: 2.22284
Timestep Consumption Time: 1.20463
PPO Batch Consumption Time: 0.09788
Total Iteration Time: 3.42747

Cumulative Model Updates: 58,388
Cumulative Timesteps: 487,136,422

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,414.35058
Policy Entropy: 0.98311
Value Function Loss: 0.07624

Mean KL Divergence: 0.00499
SB3 Clip Fraction: 0.05641
Policy Update Magnitude: 0.18799
Value Function Update Magnitude: 0.38218

Collected Steps per Second: 22,284.42444
Overall Steps per Second: 14,593.06000

Timestep Collection Time: 2.24408
Timestep Consumption Time: 1.18276
PPO Batch Consumption Time: 0.09235
Total Iteration Time: 3.42683

Cumulative Model Updates: 58,394
Cumulative Timesteps: 487,186,430

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 487186430...
Checkpoint 487186430 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,617.21202
Policy Entropy: 0.97646
Value Function Loss: 0.07006

Mean KL Divergence: 0.00486
SB3 Clip Fraction: 0.05900
Policy Update Magnitude: 0.19279
Value Function Update Magnitude: 0.37520

Collected Steps per Second: 22,873.24812
Overall Steps per Second: 14,870.72032

Timestep Collection Time: 2.18605
Timestep Consumption Time: 1.17640
PPO Batch Consumption Time: 0.09148
Total Iteration Time: 3.36245

Cumulative Model Updates: 58,400
Cumulative Timesteps: 487,236,432

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,608.00772
Policy Entropy: 0.97969
Value Function Loss: 0.07168

Mean KL Divergence: 0.00462
SB3 Clip Fraction: 0.05557
Policy Update Magnitude: 0.19255
Value Function Update Magnitude: 0.36452

Collected Steps per Second: 22,934.95319
Overall Steps per Second: 14,787.21844

Timestep Collection Time: 2.18086
Timestep Consumption Time: 1.20165
PPO Batch Consumption Time: 0.09433
Total Iteration Time: 3.38252

Cumulative Model Updates: 58,406
Cumulative Timesteps: 487,286,450

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 487286450...
Checkpoint 487286450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,734.11023
Policy Entropy: 0.97962
Value Function Loss: 0.06487

Mean KL Divergence: 0.00479
SB3 Clip Fraction: 0.05760
Policy Update Magnitude: 0.19166
Value Function Update Magnitude: 0.37231

Collected Steps per Second: 22,446.37099
Overall Steps per Second: 14,953.51452

Timestep Collection Time: 2.22967
Timestep Consumption Time: 1.11724
PPO Batch Consumption Time: 0.09671
Total Iteration Time: 3.34691

Cumulative Model Updates: 58,412
Cumulative Timesteps: 487,336,498

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,298.91745
Policy Entropy: 0.97531
Value Function Loss: 0.06242

Mean KL Divergence: 0.00431
SB3 Clip Fraction: 0.05174
Policy Update Magnitude: 0.18872
Value Function Update Magnitude: 0.38189

Collected Steps per Second: 22,281.01179
Overall Steps per Second: 14,764.00245

Timestep Collection Time: 2.24541
Timestep Consumption Time: 1.14324
PPO Batch Consumption Time: 0.09794
Total Iteration Time: 3.38865

Cumulative Model Updates: 58,418
Cumulative Timesteps: 487,386,528

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 487386528...
Checkpoint 487386528 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,348.85107
Policy Entropy: 0.97455
Value Function Loss: 0.05690

Mean KL Divergence: 0.00378
SB3 Clip Fraction: 0.04529
Policy Update Magnitude: 0.18539
Value Function Update Magnitude: 0.36430

Collected Steps per Second: 22,790.88252
Overall Steps per Second: 14,865.15726

Timestep Collection Time: 2.19570
Timestep Consumption Time: 1.17069
PPO Batch Consumption Time: 0.09805
Total Iteration Time: 3.36640

Cumulative Model Updates: 58,424
Cumulative Timesteps: 487,436,570

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,569.02534
Policy Entropy: 0.98033
Value Function Loss: 0.05808

Mean KL Divergence: 0.00425
SB3 Clip Fraction: 0.04992
Policy Update Magnitude: 0.18272
Value Function Update Magnitude: 0.36504

Collected Steps per Second: 23,182.54440
Overall Steps per Second: 15,227.92955

Timestep Collection Time: 2.15826
Timestep Consumption Time: 1.12741
PPO Batch Consumption Time: 0.09833
Total Iteration Time: 3.28567

Cumulative Model Updates: 58,430
Cumulative Timesteps: 487,486,604

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 487486604...
Checkpoint 487486604 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,597.18690
Policy Entropy: 0.98150
Value Function Loss: 0.06231

Mean KL Divergence: 0.00429
SB3 Clip Fraction: 0.05176
Policy Update Magnitude: 0.18257
Value Function Update Magnitude: 0.36354

Collected Steps per Second: 22,037.62909
Overall Steps per Second: 14,444.97100

Timestep Collection Time: 2.26984
Timestep Consumption Time: 1.19309
PPO Batch Consumption Time: 0.10203
Total Iteration Time: 3.46294

Cumulative Model Updates: 58,436
Cumulative Timesteps: 487,536,626

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,235.09114
Policy Entropy: 0.97155
Value Function Loss: 0.06680

Mean KL Divergence: 0.00417
SB3 Clip Fraction: 0.04878
Policy Update Magnitude: 0.18589
Value Function Update Magnitude: 0.36519

Collected Steps per Second: 23,572.06864
Overall Steps per Second: 14,999.50169

Timestep Collection Time: 2.12166
Timestep Consumption Time: 1.21258
PPO Batch Consumption Time: 0.09939
Total Iteration Time: 3.33424

Cumulative Model Updates: 58,442
Cumulative Timesteps: 487,586,638

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 487586638...
Checkpoint 487586638 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,889.39560
Policy Entropy: 0.96856
Value Function Loss: 0.06375

Mean KL Divergence: 0.00369
SB3 Clip Fraction: 0.04389
Policy Update Magnitude: 0.18918
Value Function Update Magnitude: 0.37865

Collected Steps per Second: 23,099.78277
Overall Steps per Second: 14,944.42361

Timestep Collection Time: 2.16461
Timestep Consumption Time: 1.18125
PPO Batch Consumption Time: 0.09867
Total Iteration Time: 3.34586

Cumulative Model Updates: 58,448
Cumulative Timesteps: 487,636,640

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,617.49589
Policy Entropy: 0.97688
Value Function Loss: 0.05692

Mean KL Divergence: 0.00355
SB3 Clip Fraction: 0.04224
Policy Update Magnitude: 0.18726
Value Function Update Magnitude: 0.35569

Collected Steps per Second: 22,885.39290
Overall Steps per Second: 14,772.39513

Timestep Collection Time: 2.18611
Timestep Consumption Time: 1.20061
PPO Batch Consumption Time: 0.09974
Total Iteration Time: 3.38672

Cumulative Model Updates: 58,454
Cumulative Timesteps: 487,686,670

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 487686670...
Checkpoint 487686670 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,504.27340
Policy Entropy: 0.96965
Value Function Loss: 0.05956

Mean KL Divergence: 0.00417
SB3 Clip Fraction: 0.04799
Policy Update Magnitude: 0.19030
Value Function Update Magnitude: 0.35952

Collected Steps per Second: 22,670.11445
Overall Steps per Second: 14,571.31599

Timestep Collection Time: 2.20687
Timestep Consumption Time: 1.22659
PPO Batch Consumption Time: 0.10207
Total Iteration Time: 3.43346

Cumulative Model Updates: 58,460
Cumulative Timesteps: 487,736,700

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,309.82030
Policy Entropy: 0.97032
Value Function Loss: 0.06781

Mean KL Divergence: 0.00425
SB3 Clip Fraction: 0.05137
Policy Update Magnitude: 0.19531
Value Function Update Magnitude: 0.38270

Collected Steps per Second: 23,591.42848
Overall Steps per Second: 15,384.83057

Timestep Collection Time: 2.12136
Timestep Consumption Time: 1.13158
PPO Batch Consumption Time: 0.08976
Total Iteration Time: 3.25294

Cumulative Model Updates: 58,466
Cumulative Timesteps: 487,786,746

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 487786746...
Checkpoint 487786746 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,024.94852
Policy Entropy: 0.96965
Value Function Loss: 0.06811

Mean KL Divergence: 0.00455
SB3 Clip Fraction: 0.05291
Policy Update Magnitude: 0.20458
Value Function Update Magnitude: 0.41683

Collected Steps per Second: 22,552.24999
Overall Steps per Second: 14,443.14193

Timestep Collection Time: 2.21752
Timestep Consumption Time: 1.24503
PPO Batch Consumption Time: 0.10111
Total Iteration Time: 3.46254

Cumulative Model Updates: 58,472
Cumulative Timesteps: 487,836,756

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,313.98549
Policy Entropy: 0.97373
Value Function Loss: 0.07027

Mean KL Divergence: 0.00372
SB3 Clip Fraction: 0.04482
Policy Update Magnitude: 0.19816
Value Function Update Magnitude: 0.41859

Collected Steps per Second: 23,238.37485
Overall Steps per Second: 14,784.17062

Timestep Collection Time: 2.15247
Timestep Consumption Time: 1.23087
PPO Batch Consumption Time: 0.09857
Total Iteration Time: 3.38335

Cumulative Model Updates: 58,478
Cumulative Timesteps: 487,886,776

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 487886776...
Checkpoint 487886776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,260.41960
Policy Entropy: 0.97914
Value Function Loss: 0.06608

Mean KL Divergence: 0.00327
SB3 Clip Fraction: 0.03842
Policy Update Magnitude: 0.19761
Value Function Update Magnitude: 0.40832

Collected Steps per Second: 22,425.83697
Overall Steps per Second: 14,554.64142

Timestep Collection Time: 2.23055
Timestep Consumption Time: 1.20629
PPO Batch Consumption Time: 0.10097
Total Iteration Time: 3.43684

Cumulative Model Updates: 58,484
Cumulative Timesteps: 487,936,798

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,703.85006
Policy Entropy: 0.97780
Value Function Loss: 0.06353

Mean KL Divergence: 0.00422
SB3 Clip Fraction: 0.05060
Policy Update Magnitude: 0.18945
Value Function Update Magnitude: 0.40345

Collected Steps per Second: 22,973.87378
Overall Steps per Second: 14,712.27806

Timestep Collection Time: 2.17882
Timestep Consumption Time: 1.22351
PPO Batch Consumption Time: 0.09726
Total Iteration Time: 3.40233

Cumulative Model Updates: 58,490
Cumulative Timesteps: 487,986,854

Timesteps Collected: 50,056
--------END ITERATION REPORT--------


Saving checkpoint 487986854...
Checkpoint 487986854 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,185.48326
Policy Entropy: 0.98024
Value Function Loss: 0.05520

Mean KL Divergence: 0.00523
SB3 Clip Fraction: 0.05871
Policy Update Magnitude: 0.18151
Value Function Update Magnitude: 0.37590

Collected Steps per Second: 23,245.61589
Overall Steps per Second: 14,870.59159

Timestep Collection Time: 2.15112
Timestep Consumption Time: 1.21149
PPO Batch Consumption Time: 0.09990
Total Iteration Time: 3.36261

Cumulative Model Updates: 58,496
Cumulative Timesteps: 488,036,858

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,505.26317
Policy Entropy: 0.97248
Value Function Loss: 0.05226

Mean KL Divergence: 0.00507
SB3 Clip Fraction: 0.05844
Policy Update Magnitude: 0.17568
Value Function Update Magnitude: 0.33339

Collected Steps per Second: 23,061.41215
Overall Steps per Second: 14,771.72509

Timestep Collection Time: 2.16830
Timestep Consumption Time: 1.21682
PPO Batch Consumption Time: 0.10175
Total Iteration Time: 3.38512

Cumulative Model Updates: 58,502
Cumulative Timesteps: 488,086,862

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 488086862...
Checkpoint 488086862 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,409.30283
Policy Entropy: 0.97523
Value Function Loss: 0.05528

Mean KL Divergence: 0.00487
SB3 Clip Fraction: 0.05793
Policy Update Magnitude: 0.17603
Value Function Update Magnitude: 0.31913

Collected Steps per Second: 22,655.46082
Overall Steps per Second: 14,679.54165

Timestep Collection Time: 2.20918
Timestep Consumption Time: 1.20033
PPO Batch Consumption Time: 0.09430
Total Iteration Time: 3.40951

Cumulative Model Updates: 58,508
Cumulative Timesteps: 488,136,912

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,635.63164
Policy Entropy: 0.98199
Value Function Loss: 0.06072

Mean KL Divergence: 0.00432
SB3 Clip Fraction: 0.05306
Policy Update Magnitude: 0.18550
Value Function Update Magnitude: 0.31756

Collected Steps per Second: 23,344.86333
Overall Steps per Second: 14,918.88775

Timestep Collection Time: 2.14360
Timestep Consumption Time: 1.21067
PPO Batch Consumption Time: 0.10010
Total Iteration Time: 3.35427

Cumulative Model Updates: 58,514
Cumulative Timesteps: 488,186,954

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 488186954...
Checkpoint 488186954 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,149.51154
Policy Entropy: 0.99253
Value Function Loss: 0.06217

Mean KL Divergence: 0.00532
SB3 Clip Fraction: 0.06063
Policy Update Magnitude: 0.18225
Value Function Update Magnitude: 0.33928

Collected Steps per Second: 22,735.47803
Overall Steps per Second: 14,820.36770

Timestep Collection Time: 2.20035
Timestep Consumption Time: 1.17514
PPO Batch Consumption Time: 0.09714
Total Iteration Time: 3.37549

Cumulative Model Updates: 58,520
Cumulative Timesteps: 488,236,980

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,399.61785
Policy Entropy: 0.99654
Value Function Loss: 0.06027

Mean KL Divergence: 0.00564
SB3 Clip Fraction: 0.06309
Policy Update Magnitude: 0.18492
Value Function Update Magnitude: 0.35063

Collected Steps per Second: 23,636.01537
Overall Steps per Second: 14,794.98394

Timestep Collection Time: 2.11753
Timestep Consumption Time: 1.26537
PPO Batch Consumption Time: 0.10180
Total Iteration Time: 3.38290

Cumulative Model Updates: 58,526
Cumulative Timesteps: 488,287,030

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 488287030...
Checkpoint 488287030 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,708.83440
Policy Entropy: 0.99284
Value Function Loss: 0.06409

Mean KL Divergence: 0.00517
SB3 Clip Fraction: 0.06005
Policy Update Magnitude: 0.18235
Value Function Update Magnitude: 0.37502

Collected Steps per Second: 22,897.45757
Overall Steps per Second: 14,767.24729

Timestep Collection Time: 2.18470
Timestep Consumption Time: 1.20280
PPO Batch Consumption Time: 0.09764
Total Iteration Time: 3.38750

Cumulative Model Updates: 58,532
Cumulative Timesteps: 488,337,054

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,120.98608
Policy Entropy: 0.99444
Value Function Loss: 0.06245

Mean KL Divergence: 0.00459
SB3 Clip Fraction: 0.05326
Policy Update Magnitude: 0.18309
Value Function Update Magnitude: 0.39881

Collected Steps per Second: 23,145.42582
Overall Steps per Second: 14,830.16545

Timestep Collection Time: 2.16233
Timestep Consumption Time: 1.21242
PPO Batch Consumption Time: 0.09874
Total Iteration Time: 3.37474

Cumulative Model Updates: 58,538
Cumulative Timesteps: 488,387,102

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 488387102...
Checkpoint 488387102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40,482.65977
Policy Entropy: 0.99515
Value Function Loss: 0.06127

Mean KL Divergence: 0.00355
SB3 Clip Fraction: 0.04312
Policy Update Magnitude: 0.18977
Value Function Update Magnitude: 0.38197

Collected Steps per Second: 23,161.17536
Overall Steps per Second: 14,751.84263

Timestep Collection Time: 2.15948
Timestep Consumption Time: 1.23102
PPO Batch Consumption Time: 0.09739
Total Iteration Time: 3.39049

Cumulative Model Updates: 58,544
Cumulative Timesteps: 488,437,118

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,872.43917
Policy Entropy: 1.00604
Value Function Loss: 0.05947

Mean KL Divergence: 0.00367
SB3 Clip Fraction: 0.04370
Policy Update Magnitude: 0.19363
Value Function Update Magnitude: 0.37602

Collected Steps per Second: 23,436.12849
Overall Steps per Second: 14,897.54431

Timestep Collection Time: 2.13440
Timestep Consumption Time: 1.22334
PPO Batch Consumption Time: 0.10189
Total Iteration Time: 3.35773

Cumulative Model Updates: 58,550
Cumulative Timesteps: 488,487,140

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 488487140...
Checkpoint 488487140 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,904.20041
Policy Entropy: 1.00070
Value Function Loss: 0.06579

Mean KL Divergence: 0.00520
SB3 Clip Fraction: 0.05904
Policy Update Magnitude: 0.18897
Value Function Update Magnitude: 0.38870

Collected Steps per Second: 22,456.48859
Overall Steps per Second: 14,672.42435

Timestep Collection Time: 2.22715
Timestep Consumption Time: 1.18156
PPO Batch Consumption Time: 0.09381
Total Iteration Time: 3.40871

Cumulative Model Updates: 58,556
Cumulative Timesteps: 488,537,154

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,938.71252
Policy Entropy: 1.00868
Value Function Loss: 0.06918

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.07992
Policy Update Magnitude: 0.16949
Value Function Update Magnitude: 0.38449

Collected Steps per Second: 23,474.96500
Overall Steps per Second: 14,923.53137

Timestep Collection Time: 2.13078
Timestep Consumption Time: 1.22097
PPO Batch Consumption Time: 0.10188
Total Iteration Time: 3.35175

Cumulative Model Updates: 58,562
Cumulative Timesteps: 488,587,174

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 488587174...
Checkpoint 488587174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,399.02231
Policy Entropy: 0.99332
Value Function Loss: 0.06616

Mean KL Divergence: 0.00401
SB3 Clip Fraction: 0.04707
Policy Update Magnitude: 0.18222
Value Function Update Magnitude: 0.38563

Collected Steps per Second: 23,354.09014
Overall Steps per Second: 14,821.68329

Timestep Collection Time: 2.14095
Timestep Consumption Time: 1.23248
PPO Batch Consumption Time: 0.10063
Total Iteration Time: 3.37344

Cumulative Model Updates: 58,568
Cumulative Timesteps: 488,637,174

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,809.31980
Policy Entropy: 1.00468
Value Function Loss: 0.05711

Mean KL Divergence: 0.00367
SB3 Clip Fraction: 0.04353
Policy Update Magnitude: 0.18733
Value Function Update Magnitude: 0.36889

Collected Steps per Second: 23,110.26016
Overall Steps per Second: 14,820.60693

Timestep Collection Time: 2.16354
Timestep Consumption Time: 1.21014
PPO Batch Consumption Time: 0.10147
Total Iteration Time: 3.37368

Cumulative Model Updates: 58,574
Cumulative Timesteps: 488,687,174

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 488687174...
Checkpoint 488687174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,779.46465
Policy Entropy: 1.01297
Value Function Loss: 0.05435

Mean KL Divergence: 0.00371
SB3 Clip Fraction: 0.04520
Policy Update Magnitude: 0.18086
Value Function Update Magnitude: 0.34688

Collected Steps per Second: 23,333.75523
Overall Steps per Second: 14,791.58828

Timestep Collection Time: 2.14350
Timestep Consumption Time: 1.23788
PPO Batch Consumption Time: 0.10240
Total Iteration Time: 3.38138

Cumulative Model Updates: 58,580
Cumulative Timesteps: 488,737,190

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,546.17382
Policy Entropy: 1.02331
Value Function Loss: 0.05384

Mean KL Divergence: 0.00392
SB3 Clip Fraction: 0.04692
Policy Update Magnitude: 0.17641
Value Function Update Magnitude: 0.34157

Collected Steps per Second: 22,925.49320
Overall Steps per Second: 14,696.73314

Timestep Collection Time: 2.18107
Timestep Consumption Time: 1.22119
PPO Batch Consumption Time: 0.09969
Total Iteration Time: 3.40225

Cumulative Model Updates: 58,586
Cumulative Timesteps: 488,787,192

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 488787192...
Checkpoint 488787192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,358.49595
Policy Entropy: 1.00046
Value Function Loss: 0.05966

Mean KL Divergence: 0.00376
SB3 Clip Fraction: 0.04469
Policy Update Magnitude: 0.18665
Value Function Update Magnitude: 0.33644

Collected Steps per Second: 22,688.09513
Overall Steps per Second: 14,755.71154

Timestep Collection Time: 2.20424
Timestep Consumption Time: 1.18496
PPO Batch Consumption Time: 0.09488
Total Iteration Time: 3.38920

Cumulative Model Updates: 58,592
Cumulative Timesteps: 488,837,202

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,806.41948
Policy Entropy: 0.99836
Value Function Loss: 0.06166

Mean KL Divergence: 0.00394
SB3 Clip Fraction: 0.04778
Policy Update Magnitude: 0.18688
Value Function Update Magnitude: 0.35087

Collected Steps per Second: 23,766.38056
Overall Steps per Second: 15,012.23200

Timestep Collection Time: 2.10406
Timestep Consumption Time: 1.22695
PPO Batch Consumption Time: 0.09934
Total Iteration Time: 3.33102

Cumulative Model Updates: 58,598
Cumulative Timesteps: 488,887,208

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 488887208...
Checkpoint 488887208 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,613.69511
Policy Entropy: 0.99501
Value Function Loss: 0.05885

Mean KL Divergence: 0.00413
SB3 Clip Fraction: 0.05028
Policy Update Magnitude: 0.18368
Value Function Update Magnitude: 0.34632

Collected Steps per Second: 22,707.40589
Overall Steps per Second: 14,682.92495

Timestep Collection Time: 2.20228
Timestep Consumption Time: 1.20358
PPO Batch Consumption Time: 0.10048
Total Iteration Time: 3.40586

Cumulative Model Updates: 58,604
Cumulative Timesteps: 488,937,216

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,553.41020
Policy Entropy: 1.01032
Value Function Loss: 0.06096

Mean KL Divergence: 0.00422
SB3 Clip Fraction: 0.05182
Policy Update Magnitude: 0.18112
Value Function Update Magnitude: 0.34584

Collected Steps per Second: 23,797.13563
Overall Steps per Second: 15,025.95521

Timestep Collection Time: 2.10185
Timestep Consumption Time: 1.22692
PPO Batch Consumption Time: 0.09831
Total Iteration Time: 3.32877

Cumulative Model Updates: 58,610
Cumulative Timesteps: 488,987,234

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 488987234...
Checkpoint 488987234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,083.12508
Policy Entropy: 1.02261
Value Function Loss: 0.05680

Mean KL Divergence: 0.00356
SB3 Clip Fraction: 0.04314
Policy Update Magnitude: 0.18273
Value Function Update Magnitude: 0.33078

Collected Steps per Second: 23,390.02875
Overall Steps per Second: 14,937.80985

Timestep Collection Time: 2.13843
Timestep Consumption Time: 1.20998
PPO Batch Consumption Time: 0.09846
Total Iteration Time: 3.34842

Cumulative Model Updates: 58,616
Cumulative Timesteps: 489,037,252

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,791.54178
Policy Entropy: 1.03229
Value Function Loss: 0.07327

Mean KL Divergence: 0.00407
SB3 Clip Fraction: 0.04984
Policy Update Magnitude: 0.18607
Value Function Update Magnitude: 0.34477

Collected Steps per Second: 22,732.03903
Overall Steps per Second: 14,651.37538

Timestep Collection Time: 2.19963
Timestep Consumption Time: 1.21316
PPO Batch Consumption Time: 0.09958
Total Iteration Time: 3.41279

Cumulative Model Updates: 58,622
Cumulative Timesteps: 489,087,254

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 489087254...
Checkpoint 489087254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,111.36762
Policy Entropy: 1.02979
Value Function Loss: 0.06747

Mean KL Divergence: 0.00455
SB3 Clip Fraction: 0.05526
Policy Update Magnitude: 0.19538
Value Function Update Magnitude: 0.36876

Collected Steps per Second: 23,294.75927
Overall Steps per Second: 14,760.60404

Timestep Collection Time: 2.14744
Timestep Consumption Time: 1.24159
PPO Batch Consumption Time: 0.09950
Total Iteration Time: 3.38902

Cumulative Model Updates: 58,628
Cumulative Timesteps: 489,137,278

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,618.27391
Policy Entropy: 1.03660
Value Function Loss: 0.07132

Mean KL Divergence: 0.00488
SB3 Clip Fraction: 0.05477
Policy Update Magnitude: 0.19416
Value Function Update Magnitude: 0.37650

Collected Steps per Second: 23,696.97770
Overall Steps per Second: 15,291.91845

Timestep Collection Time: 2.11090
Timestep Consumption Time: 1.16024
PPO Batch Consumption Time: 0.09035
Total Iteration Time: 3.27114

Cumulative Model Updates: 58,634
Cumulative Timesteps: 489,187,300

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 489187300...
Checkpoint 489187300 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,145.06947
Policy Entropy: 1.01824
Value Function Loss: 0.06271

Mean KL Divergence: 0.00429
SB3 Clip Fraction: 0.05110
Policy Update Magnitude: 0.19213
Value Function Update Magnitude: 0.37693

Collected Steps per Second: 22,517.26710
Overall Steps per Second: 14,823.38588

Timestep Collection Time: 2.22078
Timestep Consumption Time: 1.15267
PPO Batch Consumption Time: 0.09014
Total Iteration Time: 3.37345

Cumulative Model Updates: 58,640
Cumulative Timesteps: 489,237,306

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,774.76029
Policy Entropy: 1.01811
Value Function Loss: 0.06175

Mean KL Divergence: 0.00446
SB3 Clip Fraction: 0.05339
Policy Update Magnitude: 0.19246
Value Function Update Magnitude: 0.36299

Collected Steps per Second: 23,677.41111
Overall Steps per Second: 14,972.96289

Timestep Collection Time: 2.11214
Timestep Consumption Time: 1.22788
PPO Batch Consumption Time: 0.10140
Total Iteration Time: 3.34002

Cumulative Model Updates: 58,646
Cumulative Timesteps: 489,287,316

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 489287316...
Checkpoint 489287316 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,948.04918
Policy Entropy: 1.00010
Value Function Loss: 0.06416

Mean KL Divergence: 0.00432
SB3 Clip Fraction: 0.05168
Policy Update Magnitude: 0.18989
Value Function Update Magnitude: 0.37234

Collected Steps per Second: 23,287.98108
Overall Steps per Second: 14,823.77869

Timestep Collection Time: 2.14866
Timestep Consumption Time: 1.22686
PPO Batch Consumption Time: 0.10057
Total Iteration Time: 3.37552

Cumulative Model Updates: 58,652
Cumulative Timesteps: 489,337,354

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,827.94634
Policy Entropy: 0.99770
Value Function Loss: 0.06448

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.07908
Policy Update Magnitude: 0.18451
Value Function Update Magnitude: 0.42720

Collected Steps per Second: 23,144.67960
Overall Steps per Second: 14,784.43144

Timestep Collection Time: 2.16162
Timestep Consumption Time: 1.22235
PPO Batch Consumption Time: 0.10185
Total Iteration Time: 3.38397

Cumulative Model Updates: 58,658
Cumulative Timesteps: 489,387,384

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 489387384...
Checkpoint 489387384 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,314.55727
Policy Entropy: 0.99285
Value Function Loss: 0.06725

Mean KL Divergence: 0.00710
SB3 Clip Fraction: 0.07445
Policy Update Magnitude: 0.17874
Value Function Update Magnitude: 0.43264

Collected Steps per Second: 23,367.33708
Overall Steps per Second: 14,846.31858

Timestep Collection Time: 2.14051
Timestep Consumption Time: 1.22854
PPO Batch Consumption Time: 0.10087
Total Iteration Time: 3.36905

Cumulative Model Updates: 58,664
Cumulative Timesteps: 489,437,402

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,795.59902
Policy Entropy: 1.00667
Value Function Loss: 0.06531

Mean KL Divergence: 0.00561
SB3 Clip Fraction: 0.05854
Policy Update Magnitude: 0.18957
Value Function Update Magnitude: 0.40402

Collected Steps per Second: 23,417.58752
Overall Steps per Second: 15,015.71823

Timestep Collection Time: 2.13583
Timestep Consumption Time: 1.19508
PPO Batch Consumption Time: 0.09828
Total Iteration Time: 3.33091

Cumulative Model Updates: 58,670
Cumulative Timesteps: 489,487,418

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 489487418...
Checkpoint 489487418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,682.68798
Policy Entropy: 1.00983
Value Function Loss: 0.06141

Mean KL Divergence: 0.00413
SB3 Clip Fraction: 0.04894
Policy Update Magnitude: 0.19301
Value Function Update Magnitude: 0.37676

Collected Steps per Second: 22,717.15341
Overall Steps per Second: 14,565.13141

Timestep Collection Time: 2.20168
Timestep Consumption Time: 1.23227
PPO Batch Consumption Time: 0.10095
Total Iteration Time: 3.43395

Cumulative Model Updates: 58,676
Cumulative Timesteps: 489,537,434

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,355.99606
Policy Entropy: 1.02357
Value Function Loss: 0.05494

Mean KL Divergence: 0.00406
SB3 Clip Fraction: 0.04827
Policy Update Magnitude: 0.18867
Value Function Update Magnitude: 0.34786

Collected Steps per Second: 23,042.41421
Overall Steps per Second: 15,123.91494

Timestep Collection Time: 2.17035
Timestep Consumption Time: 1.13634
PPO Batch Consumption Time: 0.09844
Total Iteration Time: 3.30668

Cumulative Model Updates: 58,682
Cumulative Timesteps: 489,587,444

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 489587444...
Checkpoint 489587444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,551.22854
Policy Entropy: 1.02205
Value Function Loss: 0.05756

Mean KL Divergence: 0.00386
SB3 Clip Fraction: 0.04531
Policy Update Magnitude: 0.18680
Value Function Update Magnitude: 0.32396

Collected Steps per Second: 21,967.74658
Overall Steps per Second: 14,513.87951

Timestep Collection Time: 2.27643
Timestep Consumption Time: 1.16910
PPO Batch Consumption Time: 0.10156
Total Iteration Time: 3.44553

Cumulative Model Updates: 58,688
Cumulative Timesteps: 489,637,452

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,112.87911
Policy Entropy: 1.01221
Value Function Loss: 0.06134

Mean KL Divergence: 0.00382
SB3 Clip Fraction: 0.04590
Policy Update Magnitude: 0.18204
Value Function Update Magnitude: 0.32713

Collected Steps per Second: 22,582.96233
Overall Steps per Second: 14,756.53111

Timestep Collection Time: 2.21432
Timestep Consumption Time: 1.17441
PPO Batch Consumption Time: 0.10133
Total Iteration Time: 3.38874

Cumulative Model Updates: 58,694
Cumulative Timesteps: 489,687,458

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 489687458...
Checkpoint 489687458 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,013.99262
Policy Entropy: 1.01851
Value Function Loss: 0.06849

Mean KL Divergence: 0.00382
SB3 Clip Fraction: 0.04518
Policy Update Magnitude: 0.18955
Value Function Update Magnitude: 0.36438

Collected Steps per Second: 22,525.18800
Overall Steps per Second: 14,794.25453

Timestep Collection Time: 2.21974
Timestep Consumption Time: 1.15995
PPO Batch Consumption Time: 0.10142
Total Iteration Time: 3.37969

Cumulative Model Updates: 58,700
Cumulative Timesteps: 489,737,458

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,768.02149
Policy Entropy: 1.02368
Value Function Loss: 0.06095

Mean KL Divergence: 0.00528
SB3 Clip Fraction: 0.06305
Policy Update Magnitude: 0.18777
Value Function Update Magnitude: 0.38140

Collected Steps per Second: 22,275.06036
Overall Steps per Second: 14,728.13616

Timestep Collection Time: 2.24619
Timestep Consumption Time: 1.15098
PPO Batch Consumption Time: 0.07846
Total Iteration Time: 3.39717

Cumulative Model Updates: 58,706
Cumulative Timesteps: 489,787,492

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 489787492...
Checkpoint 489787492 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,186.21087
Policy Entropy: 1.01476
Value Function Loss: 0.06533

Mean KL Divergence: 0.00527
SB3 Clip Fraction: 0.06152
Policy Update Magnitude: 0.18414
Value Function Update Magnitude: 0.37186

Collected Steps per Second: 22,976.74180
Overall Steps per Second: 14,884.20859

Timestep Collection Time: 2.17829
Timestep Consumption Time: 1.18433
PPO Batch Consumption Time: 0.09799
Total Iteration Time: 3.36262

Cumulative Model Updates: 58,712
Cumulative Timesteps: 489,837,542

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,212.90665
Policy Entropy: 1.01858
Value Function Loss: 0.06347

Mean KL Divergence: 0.00686
SB3 Clip Fraction: 0.07282
Policy Update Magnitude: 0.18012
Value Function Update Magnitude: 0.36660

Collected Steps per Second: 22,912.96968
Overall Steps per Second: 14,686.82678

Timestep Collection Time: 2.18427
Timestep Consumption Time: 1.22341
PPO Batch Consumption Time: 0.09751
Total Iteration Time: 3.40768

Cumulative Model Updates: 58,718
Cumulative Timesteps: 489,887,590

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 489887590...
Checkpoint 489887590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,606.97232
Policy Entropy: 1.00405
Value Function Loss: 0.06249

Mean KL Divergence: 0.01074
SB3 Clip Fraction: 0.10406
Policy Update Magnitude: 0.16657
Value Function Update Magnitude: 0.35971

Collected Steps per Second: 12.23574
Overall Steps per Second: 12.22908

Timestep Collection Time: 4,087.69566
Timestep Consumption Time: 2.22646
PPO Batch Consumption Time: 0.15619
Total Iteration Time: 4,089.92212

Cumulative Model Updates: 58,724
Cumulative Timesteps: 489,937,606

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53,606.99956
Policy Entropy: 0.99639
Value Function Loss: 0.06000

Mean KL Divergence: 0.01373
SB3 Clip Fraction: 0.11990
Policy Update Magnitude: 0.15637
Value Function Update Magnitude: 0.33955

Collected Steps per Second: 12,554.63219
Overall Steps per Second: 8,565.70363

Timestep Collection Time: 3.98371
Timestep Consumption Time: 1.85516
PPO Batch Consumption Time: 0.18234
Total Iteration Time: 5.83887

Cumulative Model Updates: 58,730
Cumulative Timesteps: 489,987,620

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 489987620...
Checkpoint 489987620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,034.41595
Policy Entropy: 0.97762
Value Function Loss: 0.06098

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.08070
Policy Update Magnitude: 0.16671
Value Function Update Magnitude: 0.33043

Collected Steps per Second: 10,280.78471
Overall Steps per Second: 8,118.36731

Timestep Collection Time: 4.86403
Timestep Consumption Time: 1.29559
PPO Batch Consumption Time: 0.09602
Total Iteration Time: 6.15961

Cumulative Model Updates: 58,736
Cumulative Timesteps: 490,037,626

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,963.24830
Policy Entropy: 0.97433
Value Function Loss: 0.06211

Mean KL Divergence: 0.00549
SB3 Clip Fraction: 0.06327
Policy Update Magnitude: 0.17210
Value Function Update Magnitude: 0.33982

Collected Steps per Second: 18,653.92782
Overall Steps per Second: 12,275.42361

Timestep Collection Time: 2.68083
Timestep Consumption Time: 1.39300
PPO Batch Consumption Time: 0.09864
Total Iteration Time: 4.07383

Cumulative Model Updates: 58,742
Cumulative Timesteps: 490,087,634

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 490087634...
Checkpoint 490087634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,403.25586
Policy Entropy: 0.97531
Value Function Loss: 0.06179

Mean KL Divergence: 0.00473
SB3 Clip Fraction: 0.05751
Policy Update Magnitude: 0.17454
Value Function Update Magnitude: 0.35548

Collected Steps per Second: 16,264.60896
Overall Steps per Second: 11,329.82104

Timestep Collection Time: 3.07477
Timestep Consumption Time: 1.33924
PPO Batch Consumption Time: 0.09720
Total Iteration Time: 4.41401

Cumulative Model Updates: 58,748
Cumulative Timesteps: 490,137,644

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,272.20865
Policy Entropy: 0.99072
Value Function Loss: 0.06928

Mean KL Divergence: 0.00472
SB3 Clip Fraction: 0.05529
Policy Update Magnitude: 0.18225
Value Function Update Magnitude: 0.35457

Collected Steps per Second: 19,408.51859
Overall Steps per Second: 12,645.70642

Timestep Collection Time: 2.57732
Timestep Consumption Time: 1.37833
PPO Batch Consumption Time: 0.11691
Total Iteration Time: 3.95565

Cumulative Model Updates: 58,754
Cumulative Timesteps: 490,187,666

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 490187666...
Checkpoint 490187666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,341.61423
Policy Entropy: 0.98768
Value Function Loss: 0.06307

Mean KL Divergence: 0.00462
SB3 Clip Fraction: 0.05496
Policy Update Magnitude: 0.18692
Value Function Update Magnitude: 0.36128

Collected Steps per Second: 20,363.79486
Overall Steps per Second: 12,904.42243

Timestep Collection Time: 2.45583
Timestep Consumption Time: 1.41959
PPO Batch Consumption Time: 0.12404
Total Iteration Time: 3.87542

Cumulative Model Updates: 58,760
Cumulative Timesteps: 490,237,676

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,825.25966
Policy Entropy: 0.99427
Value Function Loss: 0.06169

Mean KL Divergence: 0.00481
SB3 Clip Fraction: 0.05602
Policy Update Magnitude: 0.17982
Value Function Update Magnitude: 0.35329

Collected Steps per Second: 20,304.78694
Overall Steps per Second: 13,105.93704

Timestep Collection Time: 2.46356
Timestep Consumption Time: 1.35319
PPO Batch Consumption Time: 0.11380
Total Iteration Time: 3.81674

Cumulative Model Updates: 58,766
Cumulative Timesteps: 490,287,698

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 490287698...
Checkpoint 490287698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,049.35639
Policy Entropy: 0.99577
Value Function Loss: 0.05396

Mean KL Divergence: 0.00489
SB3 Clip Fraction: 0.05777
Policy Update Magnitude: 0.17557
Value Function Update Magnitude: 0.35666

Collected Steps per Second: 20,378.19323
Overall Steps per Second: 12,669.66332

Timestep Collection Time: 2.45517
Timestep Consumption Time: 1.49379
PPO Batch Consumption Time: 0.13489
Total Iteration Time: 3.94896

Cumulative Model Updates: 58,772
Cumulative Timesteps: 490,337,730

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,921.83369
Policy Entropy: 0.98883
Value Function Loss: 0.06155

Mean KL Divergence: 0.00499
SB3 Clip Fraction: 0.05816
Policy Update Magnitude: 0.17565
Value Function Update Magnitude: 0.36833

Collected Steps per Second: 18,771.94507
Overall Steps per Second: 12,654.02440

Timestep Collection Time: 2.66472
Timestep Consumption Time: 1.28833
PPO Batch Consumption Time: 0.10247
Total Iteration Time: 3.95305

Cumulative Model Updates: 58,778
Cumulative Timesteps: 490,387,752

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 490387752...
Checkpoint 490387752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,031.02856
Policy Entropy: 0.98964
Value Function Loss: 0.06342

Mean KL Divergence: 0.00540
SB3 Clip Fraction: 0.06165
Policy Update Magnitude: 0.18094
Value Function Update Magnitude: 0.37528

Collected Steps per Second: 19,491.62673
Overall Steps per Second: 12,516.66354

Timestep Collection Time: 2.56572
Timestep Consumption Time: 1.42976
PPO Batch Consumption Time: 0.12448
Total Iteration Time: 3.99547

Cumulative Model Updates: 58,784
Cumulative Timesteps: 490,437,762

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,759.09412
Policy Entropy: 0.99473
Value Function Loss: 0.06461

Mean KL Divergence: 0.00375
SB3 Clip Fraction: 0.04585
Policy Update Magnitude: 0.18986
Value Function Update Magnitude: 0.38257

Collected Steps per Second: 20,394.73741
Overall Steps per Second: 13,102.78456

Timestep Collection Time: 2.45171
Timestep Consumption Time: 1.36442
PPO Batch Consumption Time: 0.11344
Total Iteration Time: 3.81614

Cumulative Model Updates: 58,790
Cumulative Timesteps: 490,487,764

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 490487764...
Checkpoint 490487764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,121.50035
Policy Entropy: 1.00661
Value Function Loss: 0.06732

Mean KL Divergence: 0.00421
SB3 Clip Fraction: 0.05155
Policy Update Magnitude: 0.19759
Value Function Update Magnitude: 0.37919

Collected Steps per Second: 19,804.38173
Overall Steps per Second: 12,715.96277

Timestep Collection Time: 2.52479
Timestep Consumption Time: 1.40743
PPO Batch Consumption Time: 0.12253
Total Iteration Time: 3.93222

Cumulative Model Updates: 58,796
Cumulative Timesteps: 490,537,766

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,987.46175
Policy Entropy: 1.01527
Value Function Loss: 0.07794

Mean KL Divergence: 0.00534
SB3 Clip Fraction: 0.06603
Policy Update Magnitude: 0.20840
Value Function Update Magnitude: 0.40401

Collected Steps per Second: 20,953.94161
Overall Steps per Second: 13,128.56742

Timestep Collection Time: 2.38800
Timestep Consumption Time: 1.42338
PPO Batch Consumption Time: 0.11858
Total Iteration Time: 3.81138

Cumulative Model Updates: 58,802
Cumulative Timesteps: 490,587,804

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 490587804...
Checkpoint 490587804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,909.79706
Policy Entropy: 1.02511
Value Function Loss: 0.07817

Mean KL Divergence: 0.00675
SB3 Clip Fraction: 0.07514
Policy Update Magnitude: 0.21336
Value Function Update Magnitude: 0.44170

Collected Steps per Second: 20,539.05637
Overall Steps per Second: 13,248.07320

Timestep Collection Time: 2.43448
Timestep Consumption Time: 1.33980
PPO Batch Consumption Time: 0.11245
Total Iteration Time: 3.77428

Cumulative Model Updates: 58,808
Cumulative Timesteps: 490,637,806

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,477.25447
Policy Entropy: 1.03074
Value Function Loss: 0.07087

Mean KL Divergence: 0.01083
SB3 Clip Fraction: 0.09856
Policy Update Magnitude: 0.19860
Value Function Update Magnitude: 0.42853

Collected Steps per Second: 20,541.28163
Overall Steps per Second: 13,166.90536

Timestep Collection Time: 2.43441
Timestep Consumption Time: 1.36344
PPO Batch Consumption Time: 0.11575
Total Iteration Time: 3.79786

Cumulative Model Updates: 58,814
Cumulative Timesteps: 490,687,812

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 490687812...
Checkpoint 490687812 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,022.85352
Policy Entropy: 1.01726
Value Function Loss: 0.06495

Mean KL Divergence: 0.02266
SB3 Clip Fraction: 0.13852
Policy Update Magnitude: 0.18501
Value Function Update Magnitude: 0.37890

Collected Steps per Second: 19,343.33991
Overall Steps per Second: 12,632.01620

Timestep Collection Time: 2.58518
Timestep Consumption Time: 1.37349
PPO Batch Consumption Time: 0.11608
Total Iteration Time: 3.95867

Cumulative Model Updates: 58,820
Cumulative Timesteps: 490,737,818

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,357.48518
Policy Entropy: 1.01017
Value Function Loss: 0.06506

Mean KL Divergence: 0.02412
SB3 Clip Fraction: 0.13034
Policy Update Magnitude: 0.17505
Value Function Update Magnitude: 0.36858

Collected Steps per Second: 20,371.39153
Overall Steps per Second: 13,279.28612

Timestep Collection Time: 2.45491
Timestep Consumption Time: 1.31110
PPO Batch Consumption Time: 0.11819
Total Iteration Time: 3.76602

Cumulative Model Updates: 58,826
Cumulative Timesteps: 490,787,828

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 490787828...
Checkpoint 490787828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,498.42612
Policy Entropy: 1.01529
Value Function Loss: 0.07325

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.07988
Policy Update Magnitude: 0.19313
Value Function Update Magnitude: 0.36210

Collected Steps per Second: 20,030.99623
Overall Steps per Second: 13,225.73680

Timestep Collection Time: 2.49753
Timestep Consumption Time: 1.28510
PPO Batch Consumption Time: 0.11622
Total Iteration Time: 3.78262

Cumulative Model Updates: 58,832
Cumulative Timesteps: 490,837,856

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,698.96966
Policy Entropy: 1.03064
Value Function Loss: 0.06913

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.09380
Policy Update Magnitude: 0.21257
Value Function Update Magnitude: 0.40449

Collected Steps per Second: 19,974.89541
Overall Steps per Second: 13,138.85730

Timestep Collection Time: 2.50424
Timestep Consumption Time: 1.30294
PPO Batch Consumption Time: 0.11654
Total Iteration Time: 3.80718

Cumulative Model Updates: 58,838
Cumulative Timesteps: 490,887,878

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 490887878...
Checkpoint 490887878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,032.72363
Policy Entropy: 1.05314
Value Function Loss: 0.06454

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.08260
Policy Update Magnitude: 0.21727
Value Function Update Magnitude: 0.40657

Collected Steps per Second: 19,856.88684
Overall Steps per Second: 13,019.74523

Timestep Collection Time: 2.51862
Timestep Consumption Time: 1.32262
PPO Batch Consumption Time: 0.12083
Total Iteration Time: 3.84124

Cumulative Model Updates: 58,844
Cumulative Timesteps: 490,937,890

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,470.85493
Policy Entropy: 1.03788
Value Function Loss: 0.06313

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.08511
Policy Update Magnitude: 0.20466
Value Function Update Magnitude: 0.39238

Collected Steps per Second: 20,107.56797
Overall Steps per Second: 13,474.21130

Timestep Collection Time: 2.48871
Timestep Consumption Time: 1.22519
PPO Batch Consumption Time: 0.10779
Total Iteration Time: 3.71391

Cumulative Model Updates: 58,850
Cumulative Timesteps: 490,987,932

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 490987932...
Checkpoint 490987932 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,644.34284
Policy Entropy: 1.02119
Value Function Loss: 0.06446

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.08594
Policy Update Magnitude: 0.20084
Value Function Update Magnitude: 0.39651

Collected Steps per Second: 20,264.18657
Overall Steps per Second: 13,265.93962

Timestep Collection Time: 2.46760
Timestep Consumption Time: 1.30175
PPO Batch Consumption Time: 0.10987
Total Iteration Time: 3.76935

Cumulative Model Updates: 58,856
Cumulative Timesteps: 491,037,936

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,510.77012
Policy Entropy: 1.01183
Value Function Loss: 0.06155

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.08713
Policy Update Magnitude: 0.18649
Value Function Update Magnitude: 0.38458

Collected Steps per Second: 20,367.13348
Overall Steps per Second: 13,190.69937

Timestep Collection Time: 2.45680
Timestep Consumption Time: 1.33663
PPO Batch Consumption Time: 0.11381
Total Iteration Time: 3.79343

Cumulative Model Updates: 58,862
Cumulative Timesteps: 491,087,974

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 491087974...
Checkpoint 491087974 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,624.58006
Policy Entropy: 0.99880
Value Function Loss: 0.05506

Mean KL Divergence: 0.00646
SB3 Clip Fraction: 0.07060
Policy Update Magnitude: 0.18330
Value Function Update Magnitude: 0.36853

Collected Steps per Second: 20,906.05008
Overall Steps per Second: 13,264.59463

Timestep Collection Time: 2.39184
Timestep Consumption Time: 1.37789
PPO Batch Consumption Time: 0.11574
Total Iteration Time: 3.76973

Cumulative Model Updates: 58,868
Cumulative Timesteps: 491,137,978

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,731.95042
Policy Entropy: 1.00718
Value Function Loss: 0.05502

Mean KL Divergence: 0.00668
SB3 Clip Fraction: 0.07413
Policy Update Magnitude: 0.18574
Value Function Update Magnitude: 0.34378

Collected Steps per Second: 21,182.01148
Overall Steps per Second: 13,280.83188

Timestep Collection Time: 2.36059
Timestep Consumption Time: 1.40439
PPO Batch Consumption Time: 0.12183
Total Iteration Time: 3.76498

Cumulative Model Updates: 58,874
Cumulative Timesteps: 491,187,980

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 491187980...
Checkpoint 491187980 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,497.63340
Policy Entropy: 1.01055
Value Function Loss: 0.05538

Mean KL Divergence: 0.00552
SB3 Clip Fraction: 0.06268
Policy Update Magnitude: 0.18847
Value Function Update Magnitude: 0.34068

Collected Steps per Second: 19,990.41976
Overall Steps per Second: 13,118.70264

Timestep Collection Time: 2.50140
Timestep Consumption Time: 1.31026
PPO Batch Consumption Time: 0.11180
Total Iteration Time: 3.81166

Cumulative Model Updates: 58,880
Cumulative Timesteps: 491,237,984

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,065.96008
Policy Entropy: 1.01127
Value Function Loss: 0.06329

Mean KL Divergence: 0.00614
SB3 Clip Fraction: 0.06770
Policy Update Magnitude: 0.19282
Value Function Update Magnitude: 0.35294

Collected Steps per Second: 20,729.13107
Overall Steps per Second: 13,612.39227

Timestep Collection Time: 2.41342
Timestep Consumption Time: 1.26177
PPO Batch Consumption Time: 0.10219
Total Iteration Time: 3.67518

Cumulative Model Updates: 58,886
Cumulative Timesteps: 491,288,012

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 491288012...
Checkpoint 491288012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,843.80359
Policy Entropy: 1.01404
Value Function Loss: 0.06208

Mean KL Divergence: 0.00723
SB3 Clip Fraction: 0.07784
Policy Update Magnitude: 0.19188
Value Function Update Magnitude: 0.36480

Collected Steps per Second: 20,812.29873
Overall Steps per Second: 13,051.85364

Timestep Collection Time: 2.40358
Timestep Consumption Time: 1.42913
PPO Batch Consumption Time: 0.12437
Total Iteration Time: 3.83271

Cumulative Model Updates: 58,892
Cumulative Timesteps: 491,338,036

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,881.16900
Policy Entropy: 1.01301
Value Function Loss: 0.06213

Mean KL Divergence: 0.00590
SB3 Clip Fraction: 0.06760
Policy Update Magnitude: 0.18827
Value Function Update Magnitude: 0.36345

Collected Steps per Second: 20,711.18931
Overall Steps per Second: 13,176.34398

Timestep Collection Time: 2.41580
Timestep Consumption Time: 1.38146
PPO Batch Consumption Time: 0.11895
Total Iteration Time: 3.79726

Cumulative Model Updates: 58,898
Cumulative Timesteps: 491,388,070

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 491388070...
Checkpoint 491388070 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,040.70201
Policy Entropy: 1.02402
Value Function Loss: 0.06325

Mean KL Divergence: 0.01081
SB3 Clip Fraction: 0.09871
Policy Update Magnitude: 0.17692
Value Function Update Magnitude: 0.36230

Collected Steps per Second: 20,162.75839
Overall Steps per Second: 13,215.46670

Timestep Collection Time: 2.48022
Timestep Consumption Time: 1.30383
PPO Batch Consumption Time: 0.10986
Total Iteration Time: 3.78405

Cumulative Model Updates: 58,904
Cumulative Timesteps: 491,438,078

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,071.66007
Policy Entropy: 1.01533
Value Function Loss: 0.06379

Mean KL Divergence: 0.00764
SB3 Clip Fraction: 0.08150
Policy Update Magnitude: 0.18861
Value Function Update Magnitude: 0.37094

Collected Steps per Second: 22,861.43247
Overall Steps per Second: 14,542.56188

Timestep Collection Time: 2.18788
Timestep Consumption Time: 1.25154
PPO Batch Consumption Time: 0.09808
Total Iteration Time: 3.43942

Cumulative Model Updates: 58,910
Cumulative Timesteps: 491,488,096

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 491488096...
Checkpoint 491488096 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,425.73408
Policy Entropy: 1.00850
Value Function Loss: 0.07126

Mean KL Divergence: 0.00617
SB3 Clip Fraction: 0.06957
Policy Update Magnitude: 0.19588
Value Function Update Magnitude: 0.39272

Collected Steps per Second: 22,802.13998
Overall Steps per Second: 14,137.53452

Timestep Collection Time: 2.19400
Timestep Consumption Time: 1.34466
PPO Batch Consumption Time: 0.11793
Total Iteration Time: 3.53867

Cumulative Model Updates: 58,916
Cumulative Timesteps: 491,538,124

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,582.43276
Policy Entropy: 1.01315
Value Function Loss: 0.07111

Mean KL Divergence: 0.00586
SB3 Clip Fraction: 0.06600
Policy Update Magnitude: 0.19894
Value Function Update Magnitude: 0.41259

Collected Steps per Second: 21,970.19855
Overall Steps per Second: 14,824.59831

Timestep Collection Time: 2.27690
Timestep Consumption Time: 1.09749
PPO Batch Consumption Time: 0.07976
Total Iteration Time: 3.37439

Cumulative Model Updates: 58,922
Cumulative Timesteps: 491,588,148

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 491588148...
Checkpoint 491588148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,037.36095
Policy Entropy: 1.01211
Value Function Loss: 0.06908

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.08357
Policy Update Magnitude: 0.18646
Value Function Update Magnitude: 0.41008

Collected Steps per Second: 22,303.96129
Overall Steps per Second: 14,237.38397

Timestep Collection Time: 2.24220
Timestep Consumption Time: 1.27038
PPO Batch Consumption Time: 0.10335
Total Iteration Time: 3.51258

Cumulative Model Updates: 58,928
Cumulative Timesteps: 491,638,158

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,917.19836
Policy Entropy: 1.03162
Value Function Loss: 0.06567

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.10362
Policy Update Magnitude: 0.17606
Value Function Update Magnitude: 0.39675

Collected Steps per Second: 21,156.71874
Overall Steps per Second: 13,959.42806

Timestep Collection Time: 2.36379
Timestep Consumption Time: 1.21874
PPO Batch Consumption Time: 0.09763
Total Iteration Time: 3.58252

Cumulative Model Updates: 58,934
Cumulative Timesteps: 491,688,168

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 491688168...
Checkpoint 491688168 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,855.65124
Policy Entropy: 1.01863
Value Function Loss: 0.06380

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.08025
Policy Update Magnitude: 0.17848
Value Function Update Magnitude: 0.40150

Collected Steps per Second: 22,485.35715
Overall Steps per Second: 14,419.53547

Timestep Collection Time: 2.22563
Timestep Consumption Time: 1.24494
PPO Batch Consumption Time: 0.10091
Total Iteration Time: 3.47057

Cumulative Model Updates: 58,940
Cumulative Timesteps: 491,738,212

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,290.18775
Policy Entropy: 1.01811
Value Function Loss: 0.06173

Mean KL Divergence: 0.00604
SB3 Clip Fraction: 0.06646
Policy Update Magnitude: 0.18800
Value Function Update Magnitude: 0.40603

Collected Steps per Second: 22,942.09849
Overall Steps per Second: 14,714.53251

Timestep Collection Time: 2.18045
Timestep Consumption Time: 1.21919
PPO Batch Consumption Time: 0.09721
Total Iteration Time: 3.39963

Cumulative Model Updates: 58,946
Cumulative Timesteps: 491,788,236

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 491788236...
Checkpoint 491788236 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,923.84001
Policy Entropy: 0.99478
Value Function Loss: 0.06328

Mean KL Divergence: 0.00752
SB3 Clip Fraction: 0.07653
Policy Update Magnitude: 0.18163
Value Function Update Magnitude: 0.39047

Collected Steps per Second: 22,278.86170
Overall Steps per Second: 14,335.38937

Timestep Collection Time: 2.24563
Timestep Consumption Time: 1.24434
PPO Batch Consumption Time: 0.10103
Total Iteration Time: 3.48996

Cumulative Model Updates: 58,952
Cumulative Timesteps: 491,838,266

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,196.70260
Policy Entropy: 1.00725
Value Function Loss: 0.06867

Mean KL Divergence: 0.00599
SB3 Clip Fraction: 0.06816
Policy Update Magnitude: 0.17473
Value Function Update Magnitude: 0.38012

Collected Steps per Second: 22,709.72966
Overall Steps per Second: 14,473.15279

Timestep Collection Time: 2.20302
Timestep Consumption Time: 1.25372
PPO Batch Consumption Time: 0.10117
Total Iteration Time: 3.45675

Cumulative Model Updates: 58,958
Cumulative Timesteps: 491,888,296

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 491888296...
Checkpoint 491888296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,000.69987
Policy Entropy: 0.99704
Value Function Loss: 0.07173

Mean KL Divergence: 0.00489
SB3 Clip Fraction: 0.05941
Policy Update Magnitude: 0.18931
Value Function Update Magnitude: 0.36655

Collected Steps per Second: 22,844.17833
Overall Steps per Second: 14,386.25456

Timestep Collection Time: 2.18883
Timestep Consumption Time: 1.28685
PPO Batch Consumption Time: 0.10141
Total Iteration Time: 3.47568

Cumulative Model Updates: 58,964
Cumulative Timesteps: 491,938,298

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,812.70736
Policy Entropy: 1.01395
Value Function Loss: 0.06626

Mean KL Divergence: 0.00587
SB3 Clip Fraction: 0.07103
Policy Update Magnitude: 0.18817
Value Function Update Magnitude: 0.37787

Collected Steps per Second: 22,220.85221
Overall Steps per Second: 14,412.90572

Timestep Collection Time: 2.25140
Timestep Consumption Time: 1.21966
PPO Batch Consumption Time: 0.10228
Total Iteration Time: 3.47106

Cumulative Model Updates: 58,970
Cumulative Timesteps: 491,988,326

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 491988326...
Checkpoint 491988326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,310.29929
Policy Entropy: 1.02043
Value Function Loss: 0.06037

Mean KL Divergence: 0.00455
SB3 Clip Fraction: 0.05549
Policy Update Magnitude: 0.18451
Value Function Update Magnitude: 0.36858

Collected Steps per Second: 22,366.49723
Overall Steps per Second: 14,252.92455

Timestep Collection Time: 2.23602
Timestep Consumption Time: 1.27287
PPO Batch Consumption Time: 0.10169
Total Iteration Time: 3.50889

Cumulative Model Updates: 58,976
Cumulative Timesteps: 492,038,338

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,214.69954
Policy Entropy: 1.04033
Value Function Loss: 0.06018

Mean KL Divergence: 0.00458
SB3 Clip Fraction: 0.05609
Policy Update Magnitude: 0.18362
Value Function Update Magnitude: 0.36989

Collected Steps per Second: 22,894.55087
Overall Steps per Second: 14,559.71324

Timestep Collection Time: 2.18410
Timestep Consumption Time: 1.25031
PPO Batch Consumption Time: 0.10128
Total Iteration Time: 3.43441

Cumulative Model Updates: 58,982
Cumulative Timesteps: 492,088,342

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 492088342...
Checkpoint 492088342 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,499.16452
Policy Entropy: 1.02206
Value Function Loss: 0.06347

Mean KL Divergence: 0.00389
SB3 Clip Fraction: 0.04809
Policy Update Magnitude: 0.19239
Value Function Update Magnitude: 0.37971

Collected Steps per Second: 22,363.22440
Overall Steps per Second: 14,598.43791

Timestep Collection Time: 2.23707
Timestep Consumption Time: 1.18988
PPO Batch Consumption Time: 0.09211
Total Iteration Time: 3.42694

Cumulative Model Updates: 58,988
Cumulative Timesteps: 492,138,370

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,238.15990
Policy Entropy: 1.03081
Value Function Loss: 0.06310

Mean KL Divergence: 0.00397
SB3 Clip Fraction: 0.04835
Policy Update Magnitude: 0.19724
Value Function Update Magnitude: 0.41596

Collected Steps per Second: 23,123.18959
Overall Steps per Second: 14,725.82810

Timestep Collection Time: 2.16294
Timestep Consumption Time: 1.23341
PPO Batch Consumption Time: 0.09130
Total Iteration Time: 3.39635

Cumulative Model Updates: 58,994
Cumulative Timesteps: 492,188,384

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 492188384...
Checkpoint 492188384 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47,060.72250
Policy Entropy: 1.02903
Value Function Loss: 0.06452

Mean KL Divergence: 0.00388
SB3 Clip Fraction: 0.04681
Policy Update Magnitude: 0.20584
Value Function Update Magnitude: 0.39317

Collected Steps per Second: 22,284.49366
Overall Steps per Second: 15,106.80987

Timestep Collection Time: 2.24587
Timestep Consumption Time: 1.06708
PPO Batch Consumption Time: 0.07372
Total Iteration Time: 3.31294

Cumulative Model Updates: 59,000
Cumulative Timesteps: 492,238,432

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,843.81394
Policy Entropy: 1.02593
Value Function Loss: 0.06572

Mean KL Divergence: 0.00339
SB3 Clip Fraction: 0.04074
Policy Update Magnitude: 0.20137
Value Function Update Magnitude: 0.39106

Collected Steps per Second: 22,578.13014
Overall Steps per Second: 14,573.32012

Timestep Collection Time: 2.21675
Timestep Consumption Time: 1.21761
PPO Batch Consumption Time: 0.09566
Total Iteration Time: 3.43436

Cumulative Model Updates: 59,006
Cumulative Timesteps: 492,288,482

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 492288482...
Checkpoint 492288482 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,693.25407
Policy Entropy: 1.01413
Value Function Loss: 0.06794

Mean KL Divergence: 0.00347
SB3 Clip Fraction: 0.04149
Policy Update Magnitude: 0.20480
Value Function Update Magnitude: 0.39376

Collected Steps per Second: 22,777.74370
Overall Steps per Second: 14,310.78847

Timestep Collection Time: 2.19627
Timestep Consumption Time: 1.29942
PPO Batch Consumption Time: 0.10187
Total Iteration Time: 3.49568

Cumulative Model Updates: 59,012
Cumulative Timesteps: 492,338,508

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,031.90426
Policy Entropy: 1.01792
Value Function Loss: 0.06489

Mean KL Divergence: 0.00396
SB3 Clip Fraction: 0.04819
Policy Update Magnitude: 0.20639
Value Function Update Magnitude: 0.38425

Collected Steps per Second: 22,964.69724
Overall Steps per Second: 14,488.79777

Timestep Collection Time: 2.17830
Timestep Consumption Time: 1.27430
PPO Batch Consumption Time: 0.10184
Total Iteration Time: 3.45260

Cumulative Model Updates: 59,018
Cumulative Timesteps: 492,388,532

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 492388532...
Checkpoint 492388532 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,940.07569
Policy Entropy: 1.02363
Value Function Loss: 0.06554

Mean KL Divergence: 0.00414
SB3 Clip Fraction: 0.05009
Policy Update Magnitude: 0.19574
Value Function Update Magnitude: 0.37338

Collected Steps per Second: 21,768.79890
Overall Steps per Second: 14,082.02841

Timestep Collection Time: 2.29778
Timestep Consumption Time: 1.25426
PPO Batch Consumption Time: 0.10259
Total Iteration Time: 3.55205

Cumulative Model Updates: 59,024
Cumulative Timesteps: 492,438,552

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,764.49170
Policy Entropy: 1.02674
Value Function Loss: 0.06233

Mean KL Divergence: 0.00427
SB3 Clip Fraction: 0.04991
Policy Update Magnitude: 0.19131
Value Function Update Magnitude: 0.38350

Collected Steps per Second: 23,146.45778
Overall Steps per Second: 14,634.97474

Timestep Collection Time: 2.16094
Timestep Consumption Time: 1.25677
PPO Batch Consumption Time: 0.09726
Total Iteration Time: 3.41770

Cumulative Model Updates: 59,030
Cumulative Timesteps: 492,488,570

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 492488570...
Checkpoint 492488570 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,385.19652
Policy Entropy: 1.02898
Value Function Loss: 0.06562

Mean KL Divergence: 0.00621
SB3 Clip Fraction: 0.06655
Policy Update Magnitude: 0.18984
Value Function Update Magnitude: 0.39069

Collected Steps per Second: 22,687.62205
Overall Steps per Second: 14,341.98511

Timestep Collection Time: 2.20517
Timestep Consumption Time: 1.28319
PPO Batch Consumption Time: 0.10201
Total Iteration Time: 3.48836

Cumulative Model Updates: 59,036
Cumulative Timesteps: 492,538,600

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,330.51161
Policy Entropy: 1.01682
Value Function Loss: 0.06371

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.09493
Policy Update Magnitude: 0.18283
Value Function Update Magnitude: 0.39864

Collected Steps per Second: 22,668.85729
Overall Steps per Second: 14,500.10261

Timestep Collection Time: 2.20637
Timestep Consumption Time: 1.24298
PPO Batch Consumption Time: 0.09976
Total Iteration Time: 3.44935

Cumulative Model Updates: 59,042
Cumulative Timesteps: 492,588,616

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 492588616...
Checkpoint 492588616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,915.24422
Policy Entropy: 1.01565
Value Function Loss: 0.05480

Mean KL Divergence: 0.00740
SB3 Clip Fraction: 0.07674
Policy Update Magnitude: 0.18423
Value Function Update Magnitude: 0.39472

Collected Steps per Second: 22,495.01844
Overall Steps per Second: 14,338.35010

Timestep Collection Time: 2.22440
Timestep Consumption Time: 1.26540
PPO Batch Consumption Time: 0.10151
Total Iteration Time: 3.48980

Cumulative Model Updates: 59,048
Cumulative Timesteps: 492,638,654

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,929.30476
Policy Entropy: 1.02570
Value Function Loss: 0.05221

Mean KL Divergence: 0.00544
SB3 Clip Fraction: 0.06377
Policy Update Magnitude: 0.17973
Value Function Update Magnitude: 0.36060

Collected Steps per Second: 22,797.93303
Overall Steps per Second: 14,499.97122

Timestep Collection Time: 2.19485
Timestep Consumption Time: 1.25606
PPO Batch Consumption Time: 0.10109
Total Iteration Time: 3.45090

Cumulative Model Updates: 59,054
Cumulative Timesteps: 492,688,692

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 492688692...
Checkpoint 492688692 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,135.79644
Policy Entropy: 1.02728
Value Function Loss: 0.05297

Mean KL Divergence: 0.00431
SB3 Clip Fraction: 0.04927
Policy Update Magnitude: 0.17600
Value Function Update Magnitude: 0.34535

Collected Steps per Second: 22,258.78026
Overall Steps per Second: 14,269.00259

Timestep Collection Time: 2.24720
Timestep Consumption Time: 1.25830
PPO Batch Consumption Time: 0.10105
Total Iteration Time: 3.50550

Cumulative Model Updates: 59,060
Cumulative Timesteps: 492,738,712

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,725.38107
Policy Entropy: 1.01760
Value Function Loss: 0.05502

Mean KL Divergence: 0.00401
SB3 Clip Fraction: 0.04781
Policy Update Magnitude: 0.18895
Value Function Update Magnitude: 0.35615

Collected Steps per Second: 22,736.10585
Overall Steps per Second: 14,460.63571

Timestep Collection Time: 2.20117
Timestep Consumption Time: 1.25968
PPO Batch Consumption Time: 0.10029
Total Iteration Time: 3.46084

Cumulative Model Updates: 59,066
Cumulative Timesteps: 492,788,758

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 492788758...
Checkpoint 492788758 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,930.00512
Policy Entropy: 1.00797
Value Function Loss: 0.05414

Mean KL Divergence: 0.00367
SB3 Clip Fraction: 0.04454
Policy Update Magnitude: 0.19342
Value Function Update Magnitude: 0.35108

Collected Steps per Second: 22,759.26951
Overall Steps per Second: 14,718.70308

Timestep Collection Time: 2.19752
Timestep Consumption Time: 1.20047
PPO Batch Consumption Time: 0.09397
Total Iteration Time: 3.39799

Cumulative Model Updates: 59,072
Cumulative Timesteps: 492,838,772

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,158.71226
Policy Entropy: 1.00659
Value Function Loss: 0.04915

Mean KL Divergence: 0.00357
SB3 Clip Fraction: 0.04202
Policy Update Magnitude: 0.19411
Value Function Update Magnitude: 0.35004

Collected Steps per Second: 22,802.88301
Overall Steps per Second: 14,699.76611

Timestep Collection Time: 2.19385
Timestep Consumption Time: 1.20934
PPO Batch Consumption Time: 0.09139
Total Iteration Time: 3.40318

Cumulative Model Updates: 59,078
Cumulative Timesteps: 492,888,798

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 492888798...
Checkpoint 492888798 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,108.45962
Policy Entropy: 1.00891
Value Function Loss: 0.05808

Mean KL Divergence: 0.00416
SB3 Clip Fraction: 0.04869
Policy Update Magnitude: 0.18866
Value Function Update Magnitude: 0.34455

Collected Steps per Second: 22,544.31289
Overall Steps per Second: 14,399.08607

Timestep Collection Time: 2.21821
Timestep Consumption Time: 1.25479
PPO Batch Consumption Time: 0.10185
Total Iteration Time: 3.47300

Cumulative Model Updates: 59,084
Cumulative Timesteps: 492,938,806

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,340.20230
Policy Entropy: 1.01135
Value Function Loss: 0.05981

Mean KL Divergence: 0.00480
SB3 Clip Fraction: 0.05657
Policy Update Magnitude: 0.19122
Value Function Update Magnitude: 0.37354

Collected Steps per Second: 23,099.80330
Overall Steps per Second: 14,578.70006

Timestep Collection Time: 2.16495
Timestep Consumption Time: 1.26539
PPO Batch Consumption Time: 0.10310
Total Iteration Time: 3.43035

Cumulative Model Updates: 59,090
Cumulative Timesteps: 492,988,816

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 492988816...
Checkpoint 492988816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,167.24901
Policy Entropy: 1.02258
Value Function Loss: 0.05213

Mean KL Divergence: 0.00581
SB3 Clip Fraction: 0.06712
Policy Update Magnitude: 0.18879
Value Function Update Magnitude: 0.36645

Collected Steps per Second: 22,323.89118
Overall Steps per Second: 14,630.48372

Timestep Collection Time: 2.23975
Timestep Consumption Time: 1.17777
PPO Batch Consumption Time: 0.09477
Total Iteration Time: 3.41752

Cumulative Model Updates: 59,096
Cumulative Timesteps: 493,038,816

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,993.02744
Policy Entropy: 1.01410
Value Function Loss: 0.04214

Mean KL Divergence: 0.00450
SB3 Clip Fraction: 0.05425
Policy Update Magnitude: 0.17739
Value Function Update Magnitude: 0.34014

Collected Steps per Second: 22,675.19303
Overall Steps per Second: 14,702.01057

Timestep Collection Time: 2.20532
Timestep Consumption Time: 1.19599
PPO Batch Consumption Time: 0.09301
Total Iteration Time: 3.40130

Cumulative Model Updates: 59,102
Cumulative Timesteps: 493,088,822

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 493088822...
Checkpoint 493088822 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,786.63304
Policy Entropy: 1.01862
Value Function Loss: 0.04520

Mean KL Divergence: 0.00414
SB3 Clip Fraction: 0.04901
Policy Update Magnitude: 0.17135
Value Function Update Magnitude: 0.31478

Collected Steps per Second: 19,534.11938
Overall Steps per Second: 13,273.34775

Timestep Collection Time: 2.56003
Timestep Consumption Time: 1.20752
PPO Batch Consumption Time: 0.10437
Total Iteration Time: 3.76755

Cumulative Model Updates: 59,108
Cumulative Timesteps: 493,138,830

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,711.38403
Policy Entropy: 1.01304
Value Function Loss: 0.05404

Mean KL Divergence: 0.00486
SB3 Clip Fraction: 0.05822
Policy Update Magnitude: 0.17637
Value Function Update Magnitude: 0.34468

Collected Steps per Second: 20,412.07863
Overall Steps per Second: 14,048.33012

Timestep Collection Time: 2.45031
Timestep Consumption Time: 1.10997
PPO Batch Consumption Time: 0.08837
Total Iteration Time: 3.56028

Cumulative Model Updates: 59,114
Cumulative Timesteps: 493,188,846

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 493188846...
Checkpoint 493188846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,735.97450
Policy Entropy: 1.01601
Value Function Loss: 0.05520

Mean KL Divergence: 0.00477
SB3 Clip Fraction: 0.05801
Policy Update Magnitude: 0.18714
Value Function Update Magnitude: 0.35850

Collected Steps per Second: 20,397.73960
Overall Steps per Second: 13,953.93243

Timestep Collection Time: 2.45125
Timestep Consumption Time: 1.13197
PPO Batch Consumption Time: 0.09453
Total Iteration Time: 3.58322

Cumulative Model Updates: 59,120
Cumulative Timesteps: 493,238,846

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,194.92558
Policy Entropy: 1.01290
Value Function Loss: 0.05758

Mean KL Divergence: 0.00452
SB3 Clip Fraction: 0.05460
Policy Update Magnitude: 0.19271
Value Function Update Magnitude: 0.34848

Collected Steps per Second: 19,728.28927
Overall Steps per Second: 13,318.62186

Timestep Collection Time: 2.53494
Timestep Consumption Time: 1.21995
PPO Batch Consumption Time: 0.10820
Total Iteration Time: 3.75489

Cumulative Model Updates: 59,126
Cumulative Timesteps: 493,288,856

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 493288856...
Checkpoint 493288856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,713.11519
Policy Entropy: 1.01550
Value Function Loss: 0.05796

Mean KL Divergence: 0.00384
SB3 Clip Fraction: 0.04672
Policy Update Magnitude: 0.19397
Value Function Update Magnitude: 0.35145

Collected Steps per Second: 19,838.07509
Overall Steps per Second: 13,216.01996

Timestep Collection Time: 2.52212
Timestep Consumption Time: 1.26374
PPO Batch Consumption Time: 0.10031
Total Iteration Time: 3.78586

Cumulative Model Updates: 59,132
Cumulative Timesteps: 493,338,890

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,887.95708
Policy Entropy: 1.02133
Value Function Loss: 0.05647

Mean KL Divergence: 0.00507
SB3 Clip Fraction: 0.05776
Policy Update Magnitude: 0.19094
Value Function Update Magnitude: 0.34000

Collected Steps per Second: 20,108.53965
Overall Steps per Second: 13,348.61333

Timestep Collection Time: 2.48820
Timestep Consumption Time: 1.26006
PPO Batch Consumption Time: 0.10371
Total Iteration Time: 3.74825

Cumulative Model Updates: 59,138
Cumulative Timesteps: 493,388,924

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 493388924...
Checkpoint 493388924 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,408.65005
Policy Entropy: 1.01387
Value Function Loss: 0.06086

Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.07857
Policy Update Magnitude: 0.17257
Value Function Update Magnitude: 0.34596

Collected Steps per Second: 19,545.11468
Overall Steps per Second: 13,109.76972

Timestep Collection Time: 2.55849
Timestep Consumption Time: 1.25592
PPO Batch Consumption Time: 0.09721
Total Iteration Time: 3.81441

Cumulative Model Updates: 59,144
Cumulative Timesteps: 493,438,930

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,281.37634
Policy Entropy: 1.01551
Value Function Loss: 0.05655

Mean KL Divergence: 0.00437
SB3 Clip Fraction: 0.05250
Policy Update Magnitude: 0.18017
Value Function Update Magnitude: 0.35857

Collected Steps per Second: 20,479.61509
Overall Steps per Second: 13,364.63827

Timestep Collection Time: 2.44223
Timestep Consumption Time: 1.30018
PPO Batch Consumption Time: 0.10538
Total Iteration Time: 3.74241

Cumulative Model Updates: 59,150
Cumulative Timesteps: 493,488,946

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 493488946...
Checkpoint 493488946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,666.10349
Policy Entropy: 1.01291
Value Function Loss: 0.05786

Mean KL Divergence: 0.00481
SB3 Clip Fraction: 0.05481
Policy Update Magnitude: 0.19267
Value Function Update Magnitude: 0.37419

Collected Steps per Second: 20,216.39071
Overall Steps per Second: 13,215.13220

Timestep Collection Time: 2.47463
Timestep Consumption Time: 1.31103
PPO Batch Consumption Time: 0.10246
Total Iteration Time: 3.78566

Cumulative Model Updates: 59,156
Cumulative Timesteps: 493,538,974

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,043.58208
Policy Entropy: 1.04022
Value Function Loss: 0.06350

Mean KL Divergence: 0.00466
SB3 Clip Fraction: 0.05589
Policy Update Magnitude: 0.18603
Value Function Update Magnitude: 0.37429

Collected Steps per Second: 21,783.94187
Overall Steps per Second: 14,214.90003

Timestep Collection Time: 2.29610
Timestep Consumption Time: 1.22261
PPO Batch Consumption Time: 0.09707
Total Iteration Time: 3.51870

Cumulative Model Updates: 59,162
Cumulative Timesteps: 493,588,992

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 493588992...
Checkpoint 493588992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,915.03126
Policy Entropy: 1.04047
Value Function Loss: 0.06439

Mean KL Divergence: 0.00410
SB3 Clip Fraction: 0.04889
Policy Update Magnitude: 0.18999
Value Function Update Magnitude: 0.36183

Collected Steps per Second: 14,524.32361
Overall Steps per Second: 10,379.45037

Timestep Collection Time: 3.44319
Timestep Consumption Time: 1.37498
PPO Batch Consumption Time: 0.11006
Total Iteration Time: 4.81817

Cumulative Model Updates: 59,168
Cumulative Timesteps: 493,639,002

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,583.55700
Policy Entropy: 1.02883
Value Function Loss: 0.06089

Mean KL Divergence: 0.00378
SB3 Clip Fraction: 0.04464
Policy Update Magnitude: 0.19026
Value Function Update Magnitude: 0.34676

Collected Steps per Second: 13,947.91643
Overall Steps per Second: 10,431.99043

Timestep Collection Time: 3.58491
Timestep Consumption Time: 1.20823
PPO Batch Consumption Time: 0.09131
Total Iteration Time: 4.79314

Cumulative Model Updates: 59,174
Cumulative Timesteps: 493,689,004

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 493689004...
Checkpoint 493689004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,883.39398
Policy Entropy: 1.01661
Value Function Loss: 0.05538

Mean KL Divergence: 0.00324
SB3 Clip Fraction: 0.03883
Policy Update Magnitude: 0.18725
Value Function Update Magnitude: 0.34322

Collected Steps per Second: 13,872.60723
Overall Steps per Second: 10,003.54950

Timestep Collection Time: 3.60682
Timestep Consumption Time: 1.39500
PPO Batch Consumption Time: 0.11263
Total Iteration Time: 5.00182

Cumulative Model Updates: 59,180
Cumulative Timesteps: 493,739,040

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,045.56038
Policy Entropy: 1.01458
Value Function Loss: 0.06167

Mean KL Divergence: 0.00358
SB3 Clip Fraction: 0.04329
Policy Update Magnitude: 0.18945
Value Function Update Magnitude: 0.36756

Collected Steps per Second: 13,992.84783
Overall Steps per Second: 9,776.41195

Timestep Collection Time: 3.57640
Timestep Consumption Time: 1.54245
PPO Batch Consumption Time: 0.13869
Total Iteration Time: 5.11885

Cumulative Model Updates: 59,186
Cumulative Timesteps: 493,789,084

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 493789084...
Checkpoint 493789084 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,208.05015
Policy Entropy: 1.03137
Value Function Loss: 0.06065

Mean KL Divergence: 0.00404
SB3 Clip Fraction: 0.04806
Policy Update Magnitude: 0.19758
Value Function Update Magnitude: 0.37684

Collected Steps per Second: 14,931.47088
Overall Steps per Second: 10,483.98009

Timestep Collection Time: 3.34917
Timestep Consumption Time: 1.42078
PPO Batch Consumption Time: 0.12508
Total Iteration Time: 4.76994

Cumulative Model Updates: 59,192
Cumulative Timesteps: 493,839,092

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,056.57090
Policy Entropy: 1.05113
Value Function Loss: 0.05973

Mean KL Divergence: 0.00417
SB3 Clip Fraction: 0.05076
Policy Update Magnitude: 0.19635
Value Function Update Magnitude: 0.37473

Collected Steps per Second: 15,044.89400
Overall Steps per Second: 10,509.17861

Timestep Collection Time: 3.32392
Timestep Consumption Time: 1.43459
PPO Batch Consumption Time: 0.12265
Total Iteration Time: 4.75851

Cumulative Model Updates: 59,198
Cumulative Timesteps: 493,889,100

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 493889100...
Checkpoint 493889100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,357.67507
Policy Entropy: 1.04822
Value Function Loss: 0.06075

Mean KL Divergence: 0.00484
SB3 Clip Fraction: 0.05675
Policy Update Magnitude: 0.19299
Value Function Update Magnitude: 0.35823

Collected Steps per Second: 15,509.90270
Overall Steps per Second: 10,748.88743

Timestep Collection Time: 3.22568
Timestep Consumption Time: 1.42875
PPO Batch Consumption Time: 0.12406
Total Iteration Time: 4.65444

Cumulative Model Updates: 59,204
Cumulative Timesteps: 493,939,130

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,556.37410
Policy Entropy: 1.04422
Value Function Loss: 0.06921

Mean KL Divergence: 0.00497
SB3 Clip Fraction: 0.05828
Policy Update Magnitude: 0.20165
Value Function Update Magnitude: 0.36675

Collected Steps per Second: 15,328.16732
Overall Steps per Second: 10,740.79276

Timestep Collection Time: 3.26484
Timestep Consumption Time: 1.39441
PPO Batch Consumption Time: 0.12427
Total Iteration Time: 4.65925

Cumulative Model Updates: 59,210
Cumulative Timesteps: 493,989,174

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 493989174...
Checkpoint 493989174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,030.74589
Policy Entropy: 1.04153
Value Function Loss: 0.08476

Mean KL Divergence: 0.00565
SB3 Clip Fraction: 0.06591
Policy Update Magnitude: 0.21161
Value Function Update Magnitude: 0.39448

Collected Steps per Second: 15,431.11404
Overall Steps per Second: 10,815.53503

Timestep Collection Time: 3.24085
Timestep Consumption Time: 1.38305
PPO Batch Consumption Time: 0.12183
Total Iteration Time: 4.62390

Cumulative Model Updates: 59,216
Cumulative Timesteps: 494,039,184

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,574.46823
Policy Entropy: 1.03911
Value Function Loss: 0.08024

Mean KL Divergence: 0.00695
SB3 Clip Fraction: 0.07611
Policy Update Magnitude: 0.21914
Value Function Update Magnitude: 0.40452

Collected Steps per Second: 15,667.81869
Overall Steps per Second: 10,861.13862

Timestep Collection Time: 3.19304
Timestep Consumption Time: 1.41311
PPO Batch Consumption Time: 0.12297
Total Iteration Time: 4.60615

Cumulative Model Updates: 59,222
Cumulative Timesteps: 494,089,212

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 494089212...
Checkpoint 494089212 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,327.07336
Policy Entropy: 1.04050
Value Function Loss: 0.08663

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.09007
Policy Update Magnitude: 0.20740
Value Function Update Magnitude: 0.40891

Collected Steps per Second: 15,214.97885
Overall Steps per Second: 10,624.18205

Timestep Collection Time: 3.28900
Timestep Consumption Time: 1.42120
PPO Batch Consumption Time: 0.12443
Total Iteration Time: 4.71020

Cumulative Model Updates: 59,228
Cumulative Timesteps: 494,139,254

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,202.40865
Policy Entropy: 1.03413
Value Function Loss: 0.07851

Mean KL Divergence: 0.00500
SB3 Clip Fraction: 0.05957
Policy Update Magnitude: 0.19920
Value Function Update Magnitude: 0.38718

Collected Steps per Second: 15,706.41981
Overall Steps per Second: 10,923.69512

Timestep Collection Time: 3.18494
Timestep Consumption Time: 1.39446
PPO Batch Consumption Time: 0.12438
Total Iteration Time: 4.57940

Cumulative Model Updates: 59,234
Cumulative Timesteps: 494,189,278

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 494189278...
Checkpoint 494189278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,506.33465
Policy Entropy: 1.03567
Value Function Loss: 0.08227

Mean KL Divergence: 0.00621
SB3 Clip Fraction: 0.06796
Policy Update Magnitude: 0.21505
Value Function Update Magnitude: 0.39390

Collected Steps per Second: 15,736.35068
Overall Steps per Second: 10,900.94373

Timestep Collection Time: 3.17837
Timestep Consumption Time: 1.40985
PPO Batch Consumption Time: 0.12176
Total Iteration Time: 4.58823

Cumulative Model Updates: 59,240
Cumulative Timesteps: 494,239,294

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,098.00858
Policy Entropy: 1.04403
Value Function Loss: 0.07462

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.08692
Policy Update Magnitude: 0.19695
Value Function Update Magnitude: 0.39702

Collected Steps per Second: 15,966.01681
Overall Steps per Second: 10,960.46745

Timestep Collection Time: 3.13228
Timestep Consumption Time: 1.43048
PPO Batch Consumption Time: 0.12543
Total Iteration Time: 4.56276

Cumulative Model Updates: 59,246
Cumulative Timesteps: 494,289,304

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 494289304...
Checkpoint 494289304 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,646.27687
Policy Entropy: 1.04741
Value Function Loss: 0.06960

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.08876
Policy Update Magnitude: 0.18105
Value Function Update Magnitude: 0.38580

Collected Steps per Second: 15,585.20391
Overall Steps per Second: 10,810.61480

Timestep Collection Time: 3.20984
Timestep Consumption Time: 1.41765
PPO Batch Consumption Time: 0.12571
Total Iteration Time: 4.62749

Cumulative Model Updates: 59,252
Cumulative Timesteps: 494,339,330

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,021.59602
Policy Entropy: 1.07052
Value Function Loss: 0.06832

Mean KL Divergence: 0.00624
SB3 Clip Fraction: 0.06654
Policy Update Magnitude: 0.19236
Value Function Update Magnitude: 0.38269

Collected Steps per Second: 15,762.18668
Overall Steps per Second: 10,816.39581

Timestep Collection Time: 3.17215
Timestep Consumption Time: 1.45046
PPO Batch Consumption Time: 0.12255
Total Iteration Time: 4.62261

Cumulative Model Updates: 59,258
Cumulative Timesteps: 494,389,330

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 494389330...
Checkpoint 494389330 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,078.71780
Policy Entropy: 1.07951
Value Function Loss: 0.07044

Mean KL Divergence: 0.00578
SB3 Clip Fraction: 0.06200
Policy Update Magnitude: 0.20621
Value Function Update Magnitude: 0.39990

Collected Steps per Second: 16,096.11585
Overall Steps per Second: 11,248.41937

Timestep Collection Time: 3.10733
Timestep Consumption Time: 1.33916
PPO Batch Consumption Time: 0.11141
Total Iteration Time: 4.44649

Cumulative Model Updates: 59,264
Cumulative Timesteps: 494,439,346

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,646.82605
Policy Entropy: 1.08536
Value Function Loss: 0.06535

Mean KL Divergence: 0.00538
SB3 Clip Fraction: 0.06311
Policy Update Magnitude: 0.20756
Value Function Update Magnitude: 0.41473

Collected Steps per Second: 16,373.44731
Overall Steps per Second: 11,171.28621

Timestep Collection Time: 3.05629
Timestep Consumption Time: 1.42323
PPO Batch Consumption Time: 0.12468
Total Iteration Time: 4.47952

Cumulative Model Updates: 59,270
Cumulative Timesteps: 494,489,388

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 494489388...
Checkpoint 494489388 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,624.61828
Policy Entropy: 1.06678
Value Function Loss: 0.06245

Mean KL Divergence: 0.00409
SB3 Clip Fraction: 0.04994
Policy Update Magnitude: 0.20787
Value Function Update Magnitude: 0.41598

Collected Steps per Second: 15,300.74547
Overall Steps per Second: 10,646.29445

Timestep Collection Time: 3.27056
Timestep Consumption Time: 1.42986
PPO Batch Consumption Time: 0.12701
Total Iteration Time: 4.70041

Cumulative Model Updates: 59,276
Cumulative Timesteps: 494,539,430

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,369.37547
Policy Entropy: 1.05327
Value Function Loss: 0.06601

Mean KL Divergence: 0.00426
SB3 Clip Fraction: 0.05194
Policy Update Magnitude: 0.20317
Value Function Update Magnitude: 0.40625

Collected Steps per Second: 15,389.35616
Overall Steps per Second: 10,679.96321

Timestep Collection Time: 3.25004
Timestep Consumption Time: 1.43312
PPO Batch Consumption Time: 0.12598
Total Iteration Time: 4.68316

Cumulative Model Updates: 59,282
Cumulative Timesteps: 494,589,446

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 494589446...
Checkpoint 494589446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,692.49735
Policy Entropy: 1.04776
Value Function Loss: 0.07387

Mean KL Divergence: 0.00436
SB3 Clip Fraction: 0.05214
Policy Update Magnitude: 0.20673
Value Function Update Magnitude: 0.40215

Collected Steps per Second: 15,419.99417
Overall Steps per Second: 10,694.63131

Timestep Collection Time: 3.24410
Timestep Consumption Time: 1.43339
PPO Batch Consumption Time: 0.12611
Total Iteration Time: 4.67749

Cumulative Model Updates: 59,288
Cumulative Timesteps: 494,639,470

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,241.56679
Policy Entropy: 1.04324
Value Function Loss: 0.07192

Mean KL Divergence: 0.00485
SB3 Clip Fraction: 0.05846
Policy Update Magnitude: 0.20789
Value Function Update Magnitude: 0.41914

Collected Steps per Second: 15,433.67453
Overall Steps per Second: 10,741.59380

Timestep Collection Time: 3.24161
Timestep Consumption Time: 1.41598
PPO Batch Consumption Time: 0.12460
Total Iteration Time: 4.65760

Cumulative Model Updates: 59,294
Cumulative Timesteps: 494,689,500

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 494689500...
Checkpoint 494689500 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,585.00101
Policy Entropy: 1.05784
Value Function Loss: 0.07069

Mean KL Divergence: 0.00474
SB3 Clip Fraction: 0.05504
Policy Update Magnitude: 0.20777
Value Function Update Magnitude: 0.43139

Collected Steps per Second: 15,183.69069
Overall Steps per Second: 10,543.25726

Timestep Collection Time: 3.29419
Timestep Consumption Time: 1.44988
PPO Batch Consumption Time: 0.12912
Total Iteration Time: 4.74407

Cumulative Model Updates: 59,300
Cumulative Timesteps: 494,739,518

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,846.93632
Policy Entropy: 1.05445
Value Function Loss: 0.06292

Mean KL Divergence: 0.00356
SB3 Clip Fraction: 0.04163
Policy Update Magnitude: 0.20598
Value Function Update Magnitude: 0.43890

Collected Steps per Second: 15,358.93813
Overall Steps per Second: 10,646.14794

Timestep Collection Time: 3.25778
Timestep Consumption Time: 1.44214
PPO Batch Consumption Time: 0.13024
Total Iteration Time: 4.69992

Cumulative Model Updates: 59,306
Cumulative Timesteps: 494,789,554

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 494789554...
Checkpoint 494789554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,456.24229
Policy Entropy: 1.07271
Value Function Loss: 0.06619

Mean KL Divergence: 0.00391
SB3 Clip Fraction: 0.04606
Policy Update Magnitude: 0.21197
Value Function Update Magnitude: 0.41419

Collected Steps per Second: 14,957.97312
Overall Steps per Second: 10,667.49749

Timestep Collection Time: 3.34470
Timestep Consumption Time: 1.34524
PPO Batch Consumption Time: 0.12596
Total Iteration Time: 4.68995

Cumulative Model Updates: 59,312
Cumulative Timesteps: 494,839,584

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,064.18032
Policy Entropy: 1.06545
Value Function Loss: 0.06909

Mean KL Divergence: 0.00416
SB3 Clip Fraction: 0.04907
Policy Update Magnitude: 0.21925
Value Function Update Magnitude: 0.41715

Collected Steps per Second: 15,140.88781
Overall Steps per Second: 10,708.49580

Timestep Collection Time: 3.30337
Timestep Consumption Time: 1.36731
PPO Batch Consumption Time: 0.12759
Total Iteration Time: 4.67068

Cumulative Model Updates: 59,318
Cumulative Timesteps: 494,889,600

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 494889600...
Checkpoint 494889600 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,360.87796
Policy Entropy: 1.07607
Value Function Loss: 0.08029

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.08363
Policy Update Magnitude: 0.21687
Value Function Update Magnitude: 0.36935

Collected Steps per Second: 15,180.90769
Overall Steps per Second: 10,801.09683

Timestep Collection Time: 3.29361
Timestep Consumption Time: 1.33555
PPO Batch Consumption Time: 0.12350
Total Iteration Time: 4.62916

Cumulative Model Updates: 59,324
Cumulative Timesteps: 494,939,600

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,991.36357
Policy Entropy: 1.06688
Value Function Loss: 0.07724

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.09648
Policy Update Magnitude: 0.19121
Value Function Update Magnitude: 0.38131

Collected Steps per Second: 15,519.15637
Overall Steps per Second: 11,133.28424

Timestep Collection Time: 3.22286
Timestep Consumption Time: 1.26962
PPO Batch Consumption Time: 0.11374
Total Iteration Time: 4.49247

Cumulative Model Updates: 59,330
Cumulative Timesteps: 494,989,616

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 494989616...
Checkpoint 494989616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,110.27504
Policy Entropy: 1.07351
Value Function Loss: 0.07070

Mean KL Divergence: 0.00695
SB3 Clip Fraction: 0.07632
Policy Update Magnitude: 0.20672
Value Function Update Magnitude: 0.37430

Collected Steps per Second: 15,567.68720
Overall Steps per Second: 11,165.96579

Timestep Collection Time: 3.21345
Timestep Consumption Time: 1.26677
PPO Batch Consumption Time: 0.11298
Total Iteration Time: 4.48022

Cumulative Model Updates: 59,336
Cumulative Timesteps: 495,039,642

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,441.15743
Policy Entropy: 1.07903
Value Function Loss: 0.06055

Mean KL Divergence: 0.00722
SB3 Clip Fraction: 0.07546
Policy Update Magnitude: 0.21296
Value Function Update Magnitude: 0.39187

Collected Steps per Second: 15,154.74219
Overall Steps per Second: 10,757.31335

Timestep Collection Time: 3.29930
Timestep Consumption Time: 1.34870
PPO Batch Consumption Time: 0.12689
Total Iteration Time: 4.64800

Cumulative Model Updates: 59,342
Cumulative Timesteps: 495,089,642

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 495089642...
Checkpoint 495089642 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,875.62104
Policy Entropy: 1.08475
Value Function Loss: 0.06446

Mean KL Divergence: 0.00616
SB3 Clip Fraction: 0.06892
Policy Update Magnitude: 0.20664
Value Function Update Magnitude: 0.38793

Collected Steps per Second: 15,091.14539
Overall Steps per Second: 10,561.11376

Timestep Collection Time: 3.31400
Timestep Consumption Time: 1.42149
PPO Batch Consumption Time: 0.12800
Total Iteration Time: 4.73549

Cumulative Model Updates: 59,348
Cumulative Timesteps: 495,139,654

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,340.58348
Policy Entropy: 1.08569
Value Function Loss: 0.06857

Mean KL Divergence: 0.00544
SB3 Clip Fraction: 0.06164
Policy Update Magnitude: 0.21081
Value Function Update Magnitude: 0.40260

Collected Steps per Second: 16,786.45861
Overall Steps per Second: 11,654.32310

Timestep Collection Time: 2.97907
Timestep Consumption Time: 1.31187
PPO Batch Consumption Time: 0.11058
Total Iteration Time: 4.29094

Cumulative Model Updates: 59,354
Cumulative Timesteps: 495,189,662

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 495189662...
Checkpoint 495189662 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,807.89172
Policy Entropy: 1.08307
Value Function Loss: 0.07771

Mean KL Divergence: 0.00516
SB3 Clip Fraction: 0.05982
Policy Update Magnitude: 0.20673
Value Function Update Magnitude: 0.41866

Collected Steps per Second: 16,256.72227
Overall Steps per Second: 11,441.68268

Timestep Collection Time: 3.07590
Timestep Consumption Time: 1.29444
PPO Batch Consumption Time: 0.10653
Total Iteration Time: 4.37034

Cumulative Model Updates: 59,360
Cumulative Timesteps: 495,239,666

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,339.01638
Policy Entropy: 1.08093
Value Function Loss: 0.07929

Mean KL Divergence: 0.00493
SB3 Clip Fraction: 0.05819
Policy Update Magnitude: 0.21331
Value Function Update Magnitude: 0.39396

Collected Steps per Second: 17,021.24241
Overall Steps per Second: 11,668.27846

Timestep Collection Time: 2.93798
Timestep Consumption Time: 1.34783
PPO Batch Consumption Time: 0.11822
Total Iteration Time: 4.28581

Cumulative Model Updates: 59,366
Cumulative Timesteps: 495,289,674

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 495289674...
Checkpoint 495289674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,525.88299
Policy Entropy: 1.09071
Value Function Loss: 0.07618

Mean KL Divergence: 0.00496
SB3 Clip Fraction: 0.05884
Policy Update Magnitude: 0.22022
Value Function Update Magnitude: 0.37664

Collected Steps per Second: 15,924.30761
Overall Steps per Second: 11,117.11934

Timestep Collection Time: 3.14073
Timestep Consumption Time: 1.35809
PPO Batch Consumption Time: 0.11619
Total Iteration Time: 4.49883

Cumulative Model Updates: 59,372
Cumulative Timesteps: 495,339,688

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,290.77220
Policy Entropy: 1.09380
Value Function Loss: 0.07041

Mean KL Divergence: 0.00467
SB3 Clip Fraction: 0.05538
Policy Update Magnitude: 0.21901
Value Function Update Magnitude: 0.38576

Collected Steps per Second: 16,084.16856
Overall Steps per Second: 11,219.24183

Timestep Collection Time: 3.10877
Timestep Consumption Time: 1.34804
PPO Batch Consumption Time: 0.11323
Total Iteration Time: 4.45681

Cumulative Model Updates: 59,378
Cumulative Timesteps: 495,389,690

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 495389690...
Checkpoint 495389690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,883.30394
Policy Entropy: 1.07741
Value Function Loss: 0.06529

Mean KL Divergence: 0.00427
SB3 Clip Fraction: 0.04912
Policy Update Magnitude: 0.21468
Value Function Update Magnitude: 0.39947

Collected Steps per Second: 15,970.64069
Overall Steps per Second: 11,130.37669

Timestep Collection Time: 3.13125
Timestep Consumption Time: 1.36168
PPO Batch Consumption Time: 0.11503
Total Iteration Time: 4.49293

Cumulative Model Updates: 59,384
Cumulative Timesteps: 495,439,698

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,115.67161
Policy Entropy: 1.06694
Value Function Loss: 0.06554

Mean KL Divergence: 0.00513
SB3 Clip Fraction: 0.05966
Policy Update Magnitude: 0.22219
Value Function Update Magnitude: 0.39202

Collected Steps per Second: 16,382.82639
Overall Steps per Second: 11,433.12543

Timestep Collection Time: 3.05332
Timestep Consumption Time: 1.32186
PPO Batch Consumption Time: 0.11171
Total Iteration Time: 4.37518

Cumulative Model Updates: 59,390
Cumulative Timesteps: 495,489,720

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 495489720...
Checkpoint 495489720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,578.80732
Policy Entropy: 1.07135
Value Function Loss: 0.06573

Mean KL Divergence: 0.00478
SB3 Clip Fraction: 0.05871
Policy Update Magnitude: 0.21903
Value Function Update Magnitude: 0.39515

Collected Steps per Second: 16,186.47555
Overall Steps per Second: 11,164.46106

Timestep Collection Time: 3.08986
Timestep Consumption Time: 1.38989
PPO Batch Consumption Time: 0.11992
Total Iteration Time: 4.47975

Cumulative Model Updates: 59,396
Cumulative Timesteps: 495,539,734

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,869.53071
Policy Entropy: 1.07925
Value Function Loss: 0.05717

Mean KL Divergence: 0.00404
SB3 Clip Fraction: 0.04728
Policy Update Magnitude: 0.20779
Value Function Update Magnitude: 0.39150

Collected Steps per Second: 15,945.22508
Overall Steps per Second: 11,132.16415

Timestep Collection Time: 3.13711
Timestep Consumption Time: 1.35635
PPO Batch Consumption Time: 0.11239
Total Iteration Time: 4.49347

Cumulative Model Updates: 59,402
Cumulative Timesteps: 495,589,756

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 495589756...
Checkpoint 495589756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,061.03099
Policy Entropy: 1.06520
Value Function Loss: 0.05980

Mean KL Divergence: 0.00379
SB3 Clip Fraction: 0.04541
Policy Update Magnitude: 0.20296
Value Function Update Magnitude: 0.37584

Collected Steps per Second: 16,208.09097
Overall Steps per Second: 11,325.36657

Timestep Collection Time: 3.08574
Timestep Consumption Time: 1.33036
PPO Batch Consumption Time: 0.11044
Total Iteration Time: 4.41610

Cumulative Model Updates: 59,408
Cumulative Timesteps: 495,639,770

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,123.59962
Policy Entropy: 1.06137
Value Function Loss: 0.06252

Mean KL Divergence: 0.00361
SB3 Clip Fraction: 0.04334
Policy Update Magnitude: 0.20303
Value Function Update Magnitude: 0.38173

Collected Steps per Second: 16,144.89739
Overall Steps per Second: 11,116.22846

Timestep Collection Time: 3.09819
Timestep Consumption Time: 1.40154
PPO Batch Consumption Time: 0.11970
Total Iteration Time: 4.49973

Cumulative Model Updates: 59,414
Cumulative Timesteps: 495,689,790

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 495689790...
Checkpoint 495689790 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,066.23587
Policy Entropy: 1.06657
Value Function Loss: 0.06624

Mean KL Divergence: 0.00365
SB3 Clip Fraction: 0.04269
Policy Update Magnitude: 0.21574
Value Function Update Magnitude: 0.38209

Collected Steps per Second: 15,699.62305
Overall Steps per Second: 10,918.06495

Timestep Collection Time: 3.18543
Timestep Consumption Time: 1.39506
PPO Batch Consumption Time: 0.11947
Total Iteration Time: 4.58048

Cumulative Model Updates: 59,420
Cumulative Timesteps: 495,739,800

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,266.59591
Policy Entropy: 1.06883
Value Function Loss: 0.06594

Mean KL Divergence: 0.00547
SB3 Clip Fraction: 0.06575
Policy Update Magnitude: 0.21196
Value Function Update Magnitude: 0.38803

Collected Steps per Second: 15,869.49947
Overall Steps per Second: 10,973.14957

Timestep Collection Time: 3.15347
Timestep Consumption Time: 1.40712
PPO Batch Consumption Time: 0.12256
Total Iteration Time: 4.56059

Cumulative Model Updates: 59,426
Cumulative Timesteps: 495,789,844

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 495789844...
Checkpoint 495789844 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,855.09067
Policy Entropy: 1.05067
Value Function Loss: 0.06595

Mean KL Divergence: 0.00424
SB3 Clip Fraction: 0.05019
Policy Update Magnitude: 0.21060
Value Function Update Magnitude: 0.36654

Collected Steps per Second: 15,937.73256
Overall Steps per Second: 10,974.70546

Timestep Collection Time: 3.13746
Timestep Consumption Time: 1.41884
PPO Batch Consumption Time: 0.12142
Total Iteration Time: 4.55630

Cumulative Model Updates: 59,432
Cumulative Timesteps: 495,839,848

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,143.54487
Policy Entropy: 1.04047
Value Function Loss: 0.06637

Mean KL Divergence: 0.00423
SB3 Clip Fraction: 0.05067
Policy Update Magnitude: 0.20855
Value Function Update Magnitude: 0.36928

Collected Steps per Second: 16,218.21455
Overall Steps per Second: 11,169.06655

Timestep Collection Time: 3.08419
Timestep Consumption Time: 1.39425
PPO Batch Consumption Time: 0.11892
Total Iteration Time: 4.47844

Cumulative Model Updates: 59,438
Cumulative Timesteps: 495,889,868

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 495889868...
Checkpoint 495889868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,503.08666
Policy Entropy: 1.04977
Value Function Loss: 0.06586

Mean KL Divergence: 0.00507
SB3 Clip Fraction: 0.06001
Policy Update Magnitude: 0.20875
Value Function Update Magnitude: 0.37677

Collected Steps per Second: 15,995.10840
Overall Steps per Second: 11,075.25065

Timestep Collection Time: 3.12896
Timestep Consumption Time: 1.38995
PPO Batch Consumption Time: 0.11953
Total Iteration Time: 4.51890

Cumulative Model Updates: 59,444
Cumulative Timesteps: 495,939,916

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,533.95388
Policy Entropy: 1.04853
Value Function Loss: 0.06660

Mean KL Divergence: 0.00429
SB3 Clip Fraction: 0.05285
Policy Update Magnitude: 0.19882
Value Function Update Magnitude: 0.38602

Collected Steps per Second: 15,537.56326
Overall Steps per Second: 11,002.16826

Timestep Collection Time: 3.21981
Timestep Consumption Time: 1.32729
PPO Batch Consumption Time: 0.12205
Total Iteration Time: 4.54710

Cumulative Model Updates: 59,450
Cumulative Timesteps: 495,989,944

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 495989944...
Checkpoint 495989944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,876.83842
Policy Entropy: 1.04480
Value Function Loss: 0.07023

Mean KL Divergence: 0.00448
SB3 Clip Fraction: 0.05563
Policy Update Magnitude: 0.20055
Value Function Update Magnitude: 0.41694

Collected Steps per Second: 15,459.18380
Overall Steps per Second: 11,032.56154

Timestep Collection Time: 3.23626
Timestep Consumption Time: 1.29849
PPO Batch Consumption Time: 0.12080
Total Iteration Time: 4.53476

Cumulative Model Updates: 59,456
Cumulative Timesteps: 496,039,974

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,969.51249
Policy Entropy: 1.05065
Value Function Loss: 0.07204

Mean KL Divergence: 0.00443
SB3 Clip Fraction: 0.05357
Policy Update Magnitude: 0.21075
Value Function Update Magnitude: 0.43540

Collected Steps per Second: 15,604.07418
Overall Steps per Second: 11,060.38653

Timestep Collection Time: 3.20544
Timestep Consumption Time: 1.31682
PPO Batch Consumption Time: 0.11873
Total Iteration Time: 4.52227

Cumulative Model Updates: 59,462
Cumulative Timesteps: 496,089,992

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 496089992...
Checkpoint 496089992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,370.49734
Policy Entropy: 1.05507
Value Function Loss: 0.06660

Mean KL Divergence: 0.00577
SB3 Clip Fraction: 0.06650
Policy Update Magnitude: 0.21383
Value Function Update Magnitude: 0.43467

Collected Steps per Second: 15,787.37290
Overall Steps per Second: 11,274.59080

Timestep Collection Time: 3.16899
Timestep Consumption Time: 1.26842
PPO Batch Consumption Time: 0.11493
Total Iteration Time: 4.43741

Cumulative Model Updates: 59,468
Cumulative Timesteps: 496,140,022

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,750.68045
Policy Entropy: 1.05926
Value Function Loss: 0.06273

Mean KL Divergence: 0.00509
SB3 Clip Fraction: 0.06052
Policy Update Magnitude: 0.20661
Value Function Update Magnitude: 0.40337

Collected Steps per Second: 16,087.53523
Overall Steps per Second: 11,397.45852

Timestep Collection Time: 3.10924
Timestep Consumption Time: 1.27946
PPO Batch Consumption Time: 0.11540
Total Iteration Time: 4.38870

Cumulative Model Updates: 59,474
Cumulative Timesteps: 496,190,042

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 496190042...
Checkpoint 496190042 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,132.31699
Policy Entropy: 1.05662
Value Function Loss: 0.06180

Mean KL Divergence: 0.00424
SB3 Clip Fraction: 0.05132
Policy Update Magnitude: 0.20941
Value Function Update Magnitude: 0.40561

Collected Steps per Second: 15,893.34472
Overall Steps per Second: 11,388.92132

Timestep Collection Time: 3.14597
Timestep Consumption Time: 1.24426
PPO Batch Consumption Time: 0.10905
Total Iteration Time: 4.39023

Cumulative Model Updates: 59,480
Cumulative Timesteps: 496,240,042

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,541.87589
Policy Entropy: 1.06543
Value Function Loss: 0.06933

Mean KL Divergence: 0.00373
SB3 Clip Fraction: 0.04386
Policy Update Magnitude: 0.21696
Value Function Update Magnitude: 0.41915

Collected Steps per Second: 16,137.93308
Overall Steps per Second: 11,400.83695

Timestep Collection Time: 3.10102
Timestep Consumption Time: 1.28849
PPO Batch Consumption Time: 0.11611
Total Iteration Time: 4.38950

Cumulative Model Updates: 59,486
Cumulative Timesteps: 496,290,086

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 496290086...
Checkpoint 496290086 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,856.97265
Policy Entropy: 1.06540
Value Function Loss: 0.07983

Mean KL Divergence: 0.00525
SB3 Clip Fraction: 0.06119
Policy Update Magnitude: 0.22116
Value Function Update Magnitude: 0.44280

Collected Steps per Second: 15,882.82591
Overall Steps per Second: 11,245.86955

Timestep Collection Time: 3.15032
Timestep Consumption Time: 1.29896
PPO Batch Consumption Time: 0.11720
Total Iteration Time: 4.44928

Cumulative Model Updates: 59,492
Cumulative Timesteps: 496,340,122

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,883.58537
Policy Entropy: 1.04986
Value Function Loss: 0.07998

Mean KL Divergence: 0.00572
SB3 Clip Fraction: 0.06653
Policy Update Magnitude: 0.22472
Value Function Update Magnitude: 0.46362

Collected Steps per Second: 16,594.44341
Overall Steps per Second: 10,221.02601

Timestep Collection Time: 3.01595
Timestep Consumption Time: 1.88062
PPO Batch Consumption Time: 0.19536
Total Iteration Time: 4.89657

Cumulative Model Updates: 59,498
Cumulative Timesteps: 496,390,170

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 496390170...
Checkpoint 496390170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,289.11872
Policy Entropy: 1.04726
Value Function Loss: 0.07602

Mean KL Divergence: 0.00579
SB3 Clip Fraction: 0.06616
Policy Update Magnitude: 0.21949
Value Function Update Magnitude: 0.48027

Collected Steps per Second: 14,856.29668
Overall Steps per Second: 10,822.81302

Timestep Collection Time: 3.36558
Timestep Consumption Time: 1.25429
PPO Batch Consumption Time: 0.09958
Total Iteration Time: 4.61987

Cumulative Model Updates: 59,504
Cumulative Timesteps: 496,440,170

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,587.96680
Policy Entropy: 1.03660
Value Function Loss: 0.06906

Mean KL Divergence: 0.00646
SB3 Clip Fraction: 0.06835
Policy Update Magnitude: 0.20727
Value Function Update Magnitude: 0.45566

Collected Steps per Second: 18,097.10556
Overall Steps per Second: 12,371.74258

Timestep Collection Time: 2.76464
Timestep Consumption Time: 1.27941
PPO Batch Consumption Time: 0.09758
Total Iteration Time: 4.04405

Cumulative Model Updates: 59,510
Cumulative Timesteps: 496,490,202

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 496490202...
Checkpoint 496490202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,176.87867
Policy Entropy: 1.02535
Value Function Loss: 0.07588

Mean KL Divergence: 0.01116
SB3 Clip Fraction: 0.09791
Policy Update Magnitude: 0.18778
Value Function Update Magnitude: 0.42217

Collected Steps per Second: 16,868.59865
Overall Steps per Second: 11,322.91016

Timestep Collection Time: 2.96622
Timestep Consumption Time: 1.45278
PPO Batch Consumption Time: 0.11920
Total Iteration Time: 4.41901

Cumulative Model Updates: 59,516
Cumulative Timesteps: 496,540,238

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,210.67672
Policy Entropy: 1.02475
Value Function Loss: 0.07593

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.08456
Policy Update Magnitude: 0.21020
Value Function Update Magnitude: 0.41590

Collected Steps per Second: 17,586.14657
Overall Steps per Second: 12,218.87617

Timestep Collection Time: 2.84531
Timestep Consumption Time: 1.24983
PPO Batch Consumption Time: 0.10124
Total Iteration Time: 4.09514

Cumulative Model Updates: 59,522
Cumulative Timesteps: 496,590,276

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 496590276...
Checkpoint 496590276 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,267.70234
Policy Entropy: 1.03825
Value Function Loss: 0.07462

Mean KL Divergence: 0.01510
SB3 Clip Fraction: 0.12614
Policy Update Magnitude: 0.21849
Value Function Update Magnitude: 0.41600

Collected Steps per Second: 21,223.26473
Overall Steps per Second: 13,988.05254

Timestep Collection Time: 2.35770
Timestep Consumption Time: 1.21950
PPO Batch Consumption Time: 0.09846
Total Iteration Time: 3.57720

Cumulative Model Updates: 59,528
Cumulative Timesteps: 496,640,314

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,902.99867
Policy Entropy: 1.04619
Value Function Loss: 0.07314

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.10547
Policy Update Magnitude: 0.20287
Value Function Update Magnitude: 0.41109

Collected Steps per Second: 21,447.37955
Overall Steps per Second: 13,975.67575

Timestep Collection Time: 2.33231
Timestep Consumption Time: 1.24691
PPO Batch Consumption Time: 0.10368
Total Iteration Time: 3.57922

Cumulative Model Updates: 59,534
Cumulative Timesteps: 496,690,336

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 496690336...
Checkpoint 496690336 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,406.32906
Policy Entropy: 1.06014
Value Function Loss: 0.07825

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.09383
Policy Update Magnitude: 0.21590
Value Function Update Magnitude: 0.41593

Collected Steps per Second: 20,216.63999
Overall Steps per Second: 13,392.88092

Timestep Collection Time: 2.47499
Timestep Consumption Time: 1.26102
PPO Batch Consumption Time: 0.10717
Total Iteration Time: 3.73601

Cumulative Model Updates: 59,540
Cumulative Timesteps: 496,740,372

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,353.78837
Policy Entropy: 1.04883
Value Function Loss: 0.07538

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.09007
Policy Update Magnitude: 0.21919
Value Function Update Magnitude: 0.41765

Collected Steps per Second: 19,447.62023
Overall Steps per Second: 12,989.39099

Timestep Collection Time: 2.57163
Timestep Consumption Time: 1.27859
PPO Batch Consumption Time: 0.09636
Total Iteration Time: 3.85022

Cumulative Model Updates: 59,546
Cumulative Timesteps: 496,790,384

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 496790384...
Checkpoint 496790384 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,411.59323
Policy Entropy: 1.04396
Value Function Loss: 0.06946

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.09781
Policy Update Magnitude: 0.20953
Value Function Update Magnitude: 0.41761

Collected Steps per Second: 19,174.37371
Overall Steps per Second: 12,602.11176

Timestep Collection Time: 2.60765
Timestep Consumption Time: 1.35994
PPO Batch Consumption Time: 0.10833
Total Iteration Time: 3.96759

Cumulative Model Updates: 59,552
Cumulative Timesteps: 496,840,384

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,173.40543
Policy Entropy: 1.03657
Value Function Loss: 0.07287

Mean KL Divergence: 0.01231
SB3 Clip Fraction: 0.11237
Policy Update Magnitude: 0.19378
Value Function Update Magnitude: 0.44370

Collected Steps per Second: 21,483.07854
Overall Steps per Second: 14,020.60150

Timestep Collection Time: 2.32937
Timestep Consumption Time: 1.23981
PPO Batch Consumption Time: 0.09757
Total Iteration Time: 3.56918

Cumulative Model Updates: 59,558
Cumulative Timesteps: 496,890,426

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 496890426...
Checkpoint 496890426 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,476.12597
Policy Entropy: 1.04166
Value Function Loss: 0.06981

Mean KL Divergence: 0.01110
SB3 Clip Fraction: 0.10711
Policy Update Magnitude: 0.21027
Value Function Update Magnitude: 0.45057

Collected Steps per Second: 19,396.51654
Overall Steps per Second: 13,135.33823

Timestep Collection Time: 2.57912
Timestep Consumption Time: 1.22938
PPO Batch Consumption Time: 0.09958
Total Iteration Time: 3.80850

Cumulative Model Updates: 59,564
Cumulative Timesteps: 496,940,452

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,454.47505
Policy Entropy: 1.04072
Value Function Loss: 0.06893

Mean KL Divergence: 0.01167
SB3 Clip Fraction: 0.11321
Policy Update Magnitude: 0.19656
Value Function Update Magnitude: 0.43698

Collected Steps per Second: 16,416.02188
Overall Steps per Second: 11,574.83644

Timestep Collection Time: 3.04654
Timestep Consumption Time: 1.27422
PPO Batch Consumption Time: 0.10400
Total Iteration Time: 4.32075

Cumulative Model Updates: 59,570
Cumulative Timesteps: 496,990,464

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 496990464...
Checkpoint 496990464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,236.78633
Policy Entropy: 1.04251
Value Function Loss: 0.06457

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.10198
Policy Update Magnitude: 0.17328
Value Function Update Magnitude: 0.41940

Collected Steps per Second: 21,162.12934
Overall Steps per Second: 13,910.78021

Timestep Collection Time: 2.36271
Timestep Consumption Time: 1.23162
PPO Batch Consumption Time: 0.09493
Total Iteration Time: 3.59433

Cumulative Model Updates: 59,576
Cumulative Timesteps: 497,040,464

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,133.63039
Policy Entropy: 1.03658
Value Function Loss: 0.06463

Mean KL Divergence: 0.01082
SB3 Clip Fraction: 0.10248
Policy Update Magnitude: 0.16912
Value Function Update Magnitude: 0.39866

Collected Steps per Second: 22,303.01323
Overall Steps per Second: 14,079.17961

Timestep Collection Time: 2.24337
Timestep Consumption Time: 1.31038
PPO Batch Consumption Time: 0.10828
Total Iteration Time: 3.55376

Cumulative Model Updates: 59,582
Cumulative Timesteps: 497,090,498

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 497090498...
Checkpoint 497090498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,346.28052
Policy Entropy: 1.04086
Value Function Loss: 0.07256

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.09060
Policy Update Magnitude: 0.17061
Value Function Update Magnitude: 0.38499

Collected Steps per Second: 21,749.43057
Overall Steps per Second: 14,031.90280

Timestep Collection Time: 2.29946
Timestep Consumption Time: 1.26470
PPO Batch Consumption Time: 0.10399
Total Iteration Time: 3.56416

Cumulative Model Updates: 59,588
Cumulative Timesteps: 497,140,510

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,647.36985
Policy Entropy: 1.02702
Value Function Loss: 0.08081

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.09207
Policy Update Magnitude: 0.18610
Value Function Update Magnitude: 0.42740

Collected Steps per Second: 22,153.83624
Overall Steps per Second: 14,594.28134

Timestep Collection Time: 2.25839
Timestep Consumption Time: 1.16980
PPO Batch Consumption Time: 0.09388
Total Iteration Time: 3.42819

Cumulative Model Updates: 59,594
Cumulative Timesteps: 497,190,542

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 497190542...
Checkpoint 497190542 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,819.10927
Policy Entropy: 1.03698
Value Function Loss: 0.07604

Mean KL Divergence: 0.00702
SB3 Clip Fraction: 0.07811
Policy Update Magnitude: 0.20977
Value Function Update Magnitude: 0.46178

Collected Steps per Second: 21,834.82248
Overall Steps per Second: 14,161.93244

Timestep Collection Time: 2.29139
Timestep Consumption Time: 1.24147
PPO Batch Consumption Time: 0.10258
Total Iteration Time: 3.53285

Cumulative Model Updates: 59,600
Cumulative Timesteps: 497,240,574

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,366.14653
Policy Entropy: 1.02492
Value Function Loss: 0.07858

Mean KL Divergence: 0.00552
SB3 Clip Fraction: 0.06249
Policy Update Magnitude: 0.21290
Value Function Update Magnitude: 0.41849

Collected Steps per Second: 22,019.46241
Overall Steps per Second: 14,190.62214

Timestep Collection Time: 2.27145
Timestep Consumption Time: 1.25314
PPO Batch Consumption Time: 0.10325
Total Iteration Time: 3.52458

Cumulative Model Updates: 59,606
Cumulative Timesteps: 497,290,590

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 497290590...
Checkpoint 497290590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,528.98991
Policy Entropy: 1.03022
Value Function Loss: 0.08461

Mean KL Divergence: 0.00534
SB3 Clip Fraction: 0.06118
Policy Update Magnitude: 0.21519
Value Function Update Magnitude: 0.36875

Collected Steps per Second: 21,364.80614
Overall Steps per Second: 13,962.11259

Timestep Collection Time: 2.34039
Timestep Consumption Time: 1.24087
PPO Batch Consumption Time: 0.10413
Total Iteration Time: 3.58126

Cumulative Model Updates: 59,612
Cumulative Timesteps: 497,340,592

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,785.89540
Policy Entropy: 1.02939
Value Function Loss: 0.08876

Mean KL Divergence: 0.00507
SB3 Clip Fraction: 0.05921
Policy Update Magnitude: 0.22295
Value Function Update Magnitude: 0.35793

Collected Steps per Second: 22,111.35846
Overall Steps per Second: 14,144.91431

Timestep Collection Time: 2.26228
Timestep Consumption Time: 1.27412
PPO Batch Consumption Time: 0.10265
Total Iteration Time: 3.53639

Cumulative Model Updates: 59,618
Cumulative Timesteps: 497,390,614

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 497390614...
Checkpoint 497390614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,639.34908
Policy Entropy: 1.03400
Value Function Loss: 0.08377

Mean KL Divergence: 0.00514
SB3 Clip Fraction: 0.06083
Policy Update Magnitude: 0.22309
Value Function Update Magnitude: 0.36681

Collected Steps per Second: 21,437.60469
Overall Steps per Second: 13,989.95330

Timestep Collection Time: 2.33431
Timestep Consumption Time: 1.24269
PPO Batch Consumption Time: 0.10207
Total Iteration Time: 3.57700

Cumulative Model Updates: 59,624
Cumulative Timesteps: 497,440,656

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,962.57144
Policy Entropy: 1.04324
Value Function Loss: 0.06868

Mean KL Divergence: 0.00464
SB3 Clip Fraction: 0.05503
Policy Update Magnitude: 0.22367
Value Function Update Magnitude: 0.40879

Collected Steps per Second: 22,292.70254
Overall Steps per Second: 14,417.63921

Timestep Collection Time: 2.24504
Timestep Consumption Time: 1.22626
PPO Batch Consumption Time: 0.10166
Total Iteration Time: 3.47130

Cumulative Model Updates: 59,630
Cumulative Timesteps: 497,490,704

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 497490704...
Checkpoint 497490704 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,358.29805
Policy Entropy: 1.04754
Value Function Loss: 0.06362

Mean KL Divergence: 0.00542
SB3 Clip Fraction: 0.06439
Policy Update Magnitude: 0.21561
Value Function Update Magnitude: 0.41007

Collected Steps per Second: 21,523.05281
Overall Steps per Second: 13,587.42366

Timestep Collection Time: 2.32458
Timestep Consumption Time: 1.35765
PPO Batch Consumption Time: 0.12275
Total Iteration Time: 3.68223

Cumulative Model Updates: 59,636
Cumulative Timesteps: 497,540,736

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,003.97894
Policy Entropy: 1.04845
Value Function Loss: 0.05983

Mean KL Divergence: 0.00599
SB3 Clip Fraction: 0.06849
Policy Update Magnitude: 0.20961
Value Function Update Magnitude: 0.39223

Collected Steps per Second: 21,012.60067
Overall Steps per Second: 13,771.86490

Timestep Collection Time: 2.38048
Timestep Consumption Time: 1.25157
PPO Batch Consumption Time: 0.10427
Total Iteration Time: 3.63204

Cumulative Model Updates: 59,642
Cumulative Timesteps: 497,590,756

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 497590756...
Checkpoint 497590756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,217.06721
Policy Entropy: 1.03503
Value Function Loss: 0.06249

Mean KL Divergence: 0.00624
SB3 Clip Fraction: 0.06775
Policy Update Magnitude: 0.20515
Value Function Update Magnitude: 0.37958

Collected Steps per Second: 22,065.56581
Overall Steps per Second: 14,253.29132

Timestep Collection Time: 2.26697
Timestep Consumption Time: 1.24253
PPO Batch Consumption Time: 0.10336
Total Iteration Time: 3.50951

Cumulative Model Updates: 59,648
Cumulative Timesteps: 497,640,778

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,729.79899
Policy Entropy: 1.03601
Value Function Loss: 0.06713

Mean KL Divergence: 0.00573
SB3 Clip Fraction: 0.06570
Policy Update Magnitude: 0.20703
Value Function Update Magnitude: 0.38492

Collected Steps per Second: 21,794.27568
Overall Steps per Second: 14,263.50870

Timestep Collection Time: 2.29501
Timestep Consumption Time: 1.21170
PPO Batch Consumption Time: 0.09737
Total Iteration Time: 3.50671

Cumulative Model Updates: 59,654
Cumulative Timesteps: 497,690,796

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 497690796...
Checkpoint 497690796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,131.79133
Policy Entropy: 1.05239
Value Function Loss: 0.06949

Mean KL Divergence: 0.00620
SB3 Clip Fraction: 0.06689
Policy Update Magnitude: 0.21035
Value Function Update Magnitude: 0.40824

Collected Steps per Second: 21,433.34314
Overall Steps per Second: 13,760.99692

Timestep Collection Time: 2.33309
Timestep Consumption Time: 1.30080
PPO Batch Consumption Time: 0.10552
Total Iteration Time: 3.63389

Cumulative Model Updates: 59,660
Cumulative Timesteps: 497,740,802

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,472.81224
Policy Entropy: 1.05593
Value Function Loss: 0.06943

Mean KL Divergence: 0.00718
SB3 Clip Fraction: 0.07896
Policy Update Magnitude: 0.19921
Value Function Update Magnitude: 0.40399

Collected Steps per Second: 22,010.17620
Overall Steps per Second: 14,301.06689

Timestep Collection Time: 2.27195
Timestep Consumption Time: 1.22471
PPO Batch Consumption Time: 0.10199
Total Iteration Time: 3.49666

Cumulative Model Updates: 59,666
Cumulative Timesteps: 497,790,808

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 497790808...
Checkpoint 497790808 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,659.97468
Policy Entropy: 1.05030
Value Function Loss: 0.07359

Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.08158
Policy Update Magnitude: 0.19743
Value Function Update Magnitude: 0.40857

Collected Steps per Second: 21,601.29426
Overall Steps per Second: 14,117.69287

Timestep Collection Time: 2.31625
Timestep Consumption Time: 1.22781
PPO Batch Consumption Time: 0.10331
Total Iteration Time: 3.54406

Cumulative Model Updates: 59,672
Cumulative Timesteps: 497,840,842

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,417.02679
Policy Entropy: 1.03931
Value Function Loss: 0.06994

Mean KL Divergence: 0.00752
SB3 Clip Fraction: 0.07519
Policy Update Magnitude: 0.20281
Value Function Update Magnitude: 0.41813

Collected Steps per Second: 21,867.44061
Overall Steps per Second: 14,248.49243

Timestep Collection Time: 2.28751
Timestep Consumption Time: 1.22318
PPO Batch Consumption Time: 0.10048
Total Iteration Time: 3.51069

Cumulative Model Updates: 59,678
Cumulative Timesteps: 497,890,864

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 497890864...
Checkpoint 497890864 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,586.18435
Policy Entropy: 1.03004
Value Function Loss: 0.07434

Mean KL Divergence: 0.00728
SB3 Clip Fraction: 0.07496
Policy Update Magnitude: 0.21082
Value Function Update Magnitude: 0.41842

Collected Steps per Second: 21,929.31993
Overall Steps per Second: 14,321.20079

Timestep Collection Time: 2.28151
Timestep Consumption Time: 1.21205
PPO Batch Consumption Time: 0.09943
Total Iteration Time: 3.49356

Cumulative Model Updates: 59,684
Cumulative Timesteps: 497,940,896

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,276.88463
Policy Entropy: 1.03281
Value Function Loss: 0.07505

Mean KL Divergence: 0.00512
SB3 Clip Fraction: 0.05955
Policy Update Magnitude: 0.21760
Value Function Update Magnitude: 0.42308

Collected Steps per Second: 22,041.91684
Overall Steps per Second: 14,168.51770

Timestep Collection Time: 2.26877
Timestep Consumption Time: 1.26075
PPO Batch Consumption Time: 0.10434
Total Iteration Time: 3.52952

Cumulative Model Updates: 59,690
Cumulative Timesteps: 497,990,904

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 497990904...
Checkpoint 497990904 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,314.75123
Policy Entropy: 1.04611
Value Function Loss: 0.06773

Mean KL Divergence: 0.00557
SB3 Clip Fraction: 0.06495
Policy Update Magnitude: 0.21150
Value Function Update Magnitude: 0.42574

Collected Steps per Second: 21,763.03475
Overall Steps per Second: 14,117.98641

Timestep Collection Time: 2.29757
Timestep Consumption Time: 1.24416
PPO Batch Consumption Time: 0.10380
Total Iteration Time: 3.54172

Cumulative Model Updates: 59,696
Cumulative Timesteps: 498,040,906

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,581.78535
Policy Entropy: 1.06327
Value Function Loss: 0.05886

Mean KL Divergence: 0.00407
SB3 Clip Fraction: 0.04942
Policy Update Magnitude: 0.20450
Value Function Update Magnitude: 0.39563

Collected Steps per Second: 22,511.24504
Overall Steps per Second: 14,440.89614

Timestep Collection Time: 2.22120
Timestep Consumption Time: 1.24133
PPO Batch Consumption Time: 0.10299
Total Iteration Time: 3.46253

Cumulative Model Updates: 59,702
Cumulative Timesteps: 498,090,908

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 498090908...
Checkpoint 498090908 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,388.72584
Policy Entropy: 1.05819
Value Function Loss: 0.05918

Mean KL Divergence: 0.00407
SB3 Clip Fraction: 0.04867
Policy Update Magnitude: 0.20372
Value Function Update Magnitude: 0.37460

Collected Steps per Second: 21,545.03564
Overall Steps per Second: 13,939.09087

Timestep Collection Time: 2.32128
Timestep Consumption Time: 1.26662
PPO Batch Consumption Time: 0.09990
Total Iteration Time: 3.58790

Cumulative Model Updates: 59,708
Cumulative Timesteps: 498,140,920

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,535.25597
Policy Entropy: 1.06371
Value Function Loss: 0.06311

Mean KL Divergence: 0.00420
SB3 Clip Fraction: 0.05169
Policy Update Magnitude: 0.20403
Value Function Update Magnitude: 0.37076

Collected Steps per Second: 21,946.57456
Overall Steps per Second: 14,155.58305

Timestep Collection Time: 2.27926
Timestep Consumption Time: 1.25447
PPO Batch Consumption Time: 0.10484
Total Iteration Time: 3.53373

Cumulative Model Updates: 59,714
Cumulative Timesteps: 498,190,942

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 498190942...
Checkpoint 498190942 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,639.20249
Policy Entropy: 1.05534
Value Function Loss: 0.06380

Mean KL Divergence: 0.00354
SB3 Clip Fraction: 0.04456
Policy Update Magnitude: 0.20760
Value Function Update Magnitude: 0.37194

Collected Steps per Second: 21,350.15640
Overall Steps per Second: 13,905.42067

Timestep Collection Time: 2.34237
Timestep Consumption Time: 1.25407
PPO Batch Consumption Time: 0.10402
Total Iteration Time: 3.59644

Cumulative Model Updates: 59,720
Cumulative Timesteps: 498,240,952

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,299.16840
Policy Entropy: 1.06520
Value Function Loss: 0.05901

Mean KL Divergence: 0.00343
SB3 Clip Fraction: 0.04076
Policy Update Magnitude: 0.20453
Value Function Update Magnitude: 0.37341

Collected Steps per Second: 20,933.92993
Overall Steps per Second: 13,832.51672

Timestep Collection Time: 2.38856
Timestep Consumption Time: 1.22625
PPO Batch Consumption Time: 0.10175
Total Iteration Time: 3.61482

Cumulative Model Updates: 59,726
Cumulative Timesteps: 498,290,954

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 498290954...
Checkpoint 498290954 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,948.50650
Policy Entropy: 1.06589
Value Function Loss: 0.05783

Mean KL Divergence: 0.00369
SB3 Clip Fraction: 0.04294
Policy Update Magnitude: 0.20566
Value Function Update Magnitude: 0.38125

Collected Steps per Second: 21,904.74267
Overall Steps per Second: 14,122.67407

Timestep Collection Time: 2.28261
Timestep Consumption Time: 1.25780
PPO Batch Consumption Time: 0.10588
Total Iteration Time: 3.54041

Cumulative Model Updates: 59,732
Cumulative Timesteps: 498,340,954

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,255.96321
Policy Entropy: 1.07474
Value Function Loss: 0.06584

Mean KL Divergence: 0.00353
SB3 Clip Fraction: 0.04205
Policy Update Magnitude: 0.20687
Value Function Update Magnitude: 0.38747

Collected Steps per Second: 21,976.48797
Overall Steps per Second: 14,190.78080

Timestep Collection Time: 2.27516
Timestep Consumption Time: 1.24826
PPO Batch Consumption Time: 0.10358
Total Iteration Time: 3.52341

Cumulative Model Updates: 59,738
Cumulative Timesteps: 498,390,954

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 498390954...
Checkpoint 498390954 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,953.40694
Policy Entropy: 1.07060
Value Function Loss: 0.06866

Mean KL Divergence: 0.00373
SB3 Clip Fraction: 0.04549
Policy Update Magnitude: 0.21443
Value Function Update Magnitude: 0.39743

Collected Steps per Second: 21,737.87899
Overall Steps per Second: 14,339.69932

Timestep Collection Time: 2.30170
Timestep Consumption Time: 1.18750
PPO Batch Consumption Time: 0.09439
Total Iteration Time: 3.48919

Cumulative Model Updates: 59,744
Cumulative Timesteps: 498,440,988

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,862.12300
Policy Entropy: 1.05361
Value Function Loss: 0.06992

Mean KL Divergence: 0.00509
SB3 Clip Fraction: 0.05909
Policy Update Magnitude: 0.21537
Value Function Update Magnitude: 0.40238

Collected Steps per Second: 22,013.39063
Overall Steps per Second: 14,084.15995

Timestep Collection Time: 2.27171
Timestep Consumption Time: 1.27895
PPO Batch Consumption Time: 0.10517
Total Iteration Time: 3.55066

Cumulative Model Updates: 59,750
Cumulative Timesteps: 498,490,996

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 498490996...
Checkpoint 498490996 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,925.10283
Policy Entropy: 1.04899
Value Function Loss: 0.06438

Mean KL Divergence: 0.00523
SB3 Clip Fraction: 0.06210
Policy Update Magnitude: 0.20693
Value Function Update Magnitude: 0.42163

Collected Steps per Second: 21,720.34078
Overall Steps per Second: 14,053.08209

Timestep Collection Time: 2.30319
Timestep Consumption Time: 1.25660
PPO Batch Consumption Time: 0.10533
Total Iteration Time: 3.55979

Cumulative Model Updates: 59,756
Cumulative Timesteps: 498,541,022

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,998.44927
Policy Entropy: 1.04714
Value Function Loss: 0.07148

Mean KL Divergence: 0.00535
SB3 Clip Fraction: 0.06036
Policy Update Magnitude: 0.20657
Value Function Update Magnitude: 0.41635

Collected Steps per Second: 21,934.78733
Overall Steps per Second: 14,215.92404

Timestep Collection Time: 2.28058
Timestep Consumption Time: 1.23829
PPO Batch Consumption Time: 0.10288
Total Iteration Time: 3.51887

Cumulative Model Updates: 59,762
Cumulative Timesteps: 498,591,046

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 498591046...
Checkpoint 498591046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,680.38462
Policy Entropy: 1.06310
Value Function Loss: 0.07403

Mean KL Divergence: 0.00369
SB3 Clip Fraction: 0.04369
Policy Update Magnitude: 0.21588
Value Function Update Magnitude: 0.43217

Collected Steps per Second: 22,172.33764
Overall Steps per Second: 14,384.55154

Timestep Collection Time: 2.25587
Timestep Consumption Time: 1.22133
PPO Batch Consumption Time: 0.09492
Total Iteration Time: 3.47720

Cumulative Model Updates: 59,768
Cumulative Timesteps: 498,641,064

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47,419.69570
Policy Entropy: 1.06839
Value Function Loss: 0.07630

Mean KL Divergence: 0.00456
SB3 Clip Fraction: 0.05454
Policy Update Magnitude: 0.21923
Value Function Update Magnitude: 0.42758

Collected Steps per Second: 21,781.46065
Overall Steps per Second: 13,953.83752

Timestep Collection Time: 2.29654
Timestep Consumption Time: 1.28828
PPO Batch Consumption Time: 0.10392
Total Iteration Time: 3.58482

Cumulative Model Updates: 59,774
Cumulative Timesteps: 498,691,086

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 498691086...
Checkpoint 498691086 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,654.11722
Policy Entropy: 1.07377
Value Function Loss: 0.06981

Mean KL Divergence: 0.00557
SB3 Clip Fraction: 0.06467
Policy Update Magnitude: 0.20729
Value Function Update Magnitude: 0.40373

Collected Steps per Second: 21,472.32466
Overall Steps per Second: 13,957.63022

Timestep Collection Time: 2.32858
Timestep Consumption Time: 1.25369
PPO Batch Consumption Time: 0.10082
Total Iteration Time: 3.58227

Cumulative Model Updates: 59,780
Cumulative Timesteps: 498,741,086

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,177.44335
Policy Entropy: 1.06006
Value Function Loss: 0.06934

Mean KL Divergence: 0.00580
SB3 Clip Fraction: 0.06821
Policy Update Magnitude: 0.20353
Value Function Update Magnitude: 0.38731

Collected Steps per Second: 22,183.89327
Overall Steps per Second: 14,336.27030

Timestep Collection Time: 2.25452
Timestep Consumption Time: 1.23412
PPO Batch Consumption Time: 0.10238
Total Iteration Time: 3.48863

Cumulative Model Updates: 59,786
Cumulative Timesteps: 498,791,100

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 498791100...
Checkpoint 498791100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,495.20663
Policy Entropy: 1.04679
Value Function Loss: 0.06830

Mean KL Divergence: 0.00546
SB3 Clip Fraction: 0.06621
Policy Update Magnitude: 0.20517
Value Function Update Magnitude: 0.40871

Collected Steps per Second: 22,002.00863
Overall Steps per Second: 14,457.67381

Timestep Collection Time: 2.27379
Timestep Consumption Time: 1.18652
PPO Batch Consumption Time: 0.09594
Total Iteration Time: 3.46031

Cumulative Model Updates: 59,792
Cumulative Timesteps: 498,841,128

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,983.70438
Policy Entropy: 1.03136
Value Function Loss: 0.07068

Mean KL Divergence: 0.00604
SB3 Clip Fraction: 0.07274
Policy Update Magnitude: 0.20225
Value Function Update Magnitude: 0.41386

Collected Steps per Second: 22,107.21127
Overall Steps per Second: 14,324.04884

Timestep Collection Time: 2.26324
Timestep Consumption Time: 1.22976
PPO Batch Consumption Time: 0.10294
Total Iteration Time: 3.49301

Cumulative Model Updates: 59,798
Cumulative Timesteps: 498,891,162

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 498891162...
Checkpoint 498891162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,454.33014
Policy Entropy: 1.03764
Value Function Loss: 0.06614

Mean KL Divergence: 0.00523
SB3 Clip Fraction: 0.06069
Policy Update Magnitude: 0.20002
Value Function Update Magnitude: 0.39836

Collected Steps per Second: 22,289.88045
Overall Steps per Second: 14,430.71160

Timestep Collection Time: 2.24452
Timestep Consumption Time: 1.22240
PPO Batch Consumption Time: 0.09488
Total Iteration Time: 3.46691

Cumulative Model Updates: 59,804
Cumulative Timesteps: 498,941,192

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,425.24835
Policy Entropy: 1.05073
Value Function Loss: 0.07265

Mean KL Divergence: 0.00527
SB3 Clip Fraction: 0.06225
Policy Update Magnitude: 0.19863
Value Function Update Magnitude: 0.39632

Collected Steps per Second: 21,916.33868
Overall Steps per Second: 14,098.40553

Timestep Collection Time: 2.28195
Timestep Consumption Time: 1.26540
PPO Batch Consumption Time: 0.10547
Total Iteration Time: 3.54735

Cumulative Model Updates: 59,810
Cumulative Timesteps: 498,991,204

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 498991204...
Checkpoint 498991204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,389.70028
Policy Entropy: 1.06230
Value Function Loss: 0.07537

Mean KL Divergence: 0.00602
SB3 Clip Fraction: 0.06845
Policy Update Magnitude: 0.20732
Value Function Update Magnitude: 0.40990

Collected Steps per Second: 21,882.02383
Overall Steps per Second: 14,230.22691

Timestep Collection Time: 2.28535
Timestep Consumption Time: 1.22886
PPO Batch Consumption Time: 0.10320
Total Iteration Time: 3.51421

Cumulative Model Updates: 59,816
Cumulative Timesteps: 499,041,212

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,190.62628
Policy Entropy: 1.06024
Value Function Loss: 0.08205

Mean KL Divergence: 0.00632
SB3 Clip Fraction: 0.07287
Policy Update Magnitude: 0.21134
Value Function Update Magnitude: 0.42916

Collected Steps per Second: 22,180.70141
Overall Steps per Second: 14,382.49931

Timestep Collection Time: 2.25493
Timestep Consumption Time: 1.22263
PPO Batch Consumption Time: 0.09795
Total Iteration Time: 3.47756

Cumulative Model Updates: 59,822
Cumulative Timesteps: 499,091,228

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 499091228...
Checkpoint 499091228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,673.69935
Policy Entropy: 1.06836
Value Function Loss: 0.07543

Mean KL Divergence: 0.00642
SB3 Clip Fraction: 0.07238
Policy Update Magnitude: 0.21060
Value Function Update Magnitude: 0.43165

Collected Steps per Second: 21,734.12728
Overall Steps per Second: 14,111.86983

Timestep Collection Time: 2.30246
Timestep Consumption Time: 1.24363
PPO Batch Consumption Time: 0.10418
Total Iteration Time: 3.54609

Cumulative Model Updates: 59,828
Cumulative Timesteps: 499,141,270

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,082.13676
Policy Entropy: 1.05925
Value Function Loss: 0.07052

Mean KL Divergence: 0.00517
SB3 Clip Fraction: 0.06001
Policy Update Magnitude: 0.20952
Value Function Update Magnitude: 0.42356

Collected Steps per Second: 22,149.17387
Overall Steps per Second: 14,141.73568

Timestep Collection Time: 2.25850
Timestep Consumption Time: 1.27883
PPO Batch Consumption Time: 0.10358
Total Iteration Time: 3.53733

Cumulative Model Updates: 59,834
Cumulative Timesteps: 499,191,294

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 499191294...
Checkpoint 499191294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,400.56731
Policy Entropy: 1.07433
Value Function Loss: 0.06758

Mean KL Divergence: 0.00434
SB3 Clip Fraction: 0.05164
Policy Update Magnitude: 0.21427
Value Function Update Magnitude: 0.40424

Collected Steps per Second: 21,619.84053
Overall Steps per Second: 13,453.12995

Timestep Collection Time: 2.31380
Timestep Consumption Time: 1.40459
PPO Batch Consumption Time: 0.11530
Total Iteration Time: 3.71839

Cumulative Model Updates: 59,840
Cumulative Timesteps: 499,241,318

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,077.84650
Policy Entropy: 1.06986
Value Function Loss: 0.06835

Mean KL Divergence: 0.00505
SB3 Clip Fraction: 0.06066
Policy Update Magnitude: 0.21462
Value Function Update Magnitude: 0.39063

Collected Steps per Second: 20,161.00030
Overall Steps per Second: 13,538.79484

Timestep Collection Time: 2.48172
Timestep Consumption Time: 1.21388
PPO Batch Consumption Time: 0.09423
Total Iteration Time: 3.69560

Cumulative Model Updates: 59,846
Cumulative Timesteps: 499,291,352

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 499291352...
Checkpoint 499291352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,353.32327
Policy Entropy: 1.07865
Value Function Loss: 0.06649

Mean KL Divergence: 0.00590
SB3 Clip Fraction: 0.06978
Policy Update Magnitude: 0.20843
Value Function Update Magnitude: 0.39692

Collected Steps per Second: 21,812.32228
Overall Steps per Second: 14,065.77773

Timestep Collection Time: 2.29320
Timestep Consumption Time: 1.26295
PPO Batch Consumption Time: 0.10292
Total Iteration Time: 3.55615

Cumulative Model Updates: 59,852
Cumulative Timesteps: 499,341,372

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,798.75717
Policy Entropy: 1.07359
Value Function Loss: 0.06487

Mean KL Divergence: 0.00476
SB3 Clip Fraction: 0.05642
Policy Update Magnitude: 0.20627
Value Function Update Magnitude: 0.40118

Collected Steps per Second: 22,207.20037
Overall Steps per Second: 14,586.60222

Timestep Collection Time: 2.25242
Timestep Consumption Time: 1.17675
PPO Batch Consumption Time: 0.09366
Total Iteration Time: 3.42917

Cumulative Model Updates: 59,858
Cumulative Timesteps: 499,391,392

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 499391392...
Checkpoint 499391392 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,189.11951
Policy Entropy: 1.07107
Value Function Loss: 0.06395

Mean KL Divergence: 0.00508
SB3 Clip Fraction: 0.06092
Policy Update Magnitude: 0.20245
Value Function Update Magnitude: 0.39334

Collected Steps per Second: 21,798.46157
Overall Steps per Second: 14,086.14917

Timestep Collection Time: 2.29402
Timestep Consumption Time: 1.25600
PPO Batch Consumption Time: 0.10126
Total Iteration Time: 3.55001

Cumulative Model Updates: 59,864
Cumulative Timesteps: 499,441,398

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,290.54534
Policy Entropy: 1.06750
Value Function Loss: 0.06573

Mean KL Divergence: 0.00533
SB3 Clip Fraction: 0.06325
Policy Update Magnitude: 0.19615
Value Function Update Magnitude: 0.39170

Collected Steps per Second: 21,817.30310
Overall Steps per Second: 14,106.63616

Timestep Collection Time: 2.29258
Timestep Consumption Time: 1.25312
PPO Batch Consumption Time: 0.10599
Total Iteration Time: 3.54571

Cumulative Model Updates: 59,870
Cumulative Timesteps: 499,491,416

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 499491416...
Checkpoint 499491416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,862.44082
Policy Entropy: 1.06035
Value Function Loss: 0.06103

Mean KL Divergence: 0.00465
SB3 Clip Fraction: 0.05530
Policy Update Magnitude: 0.19430
Value Function Update Magnitude: 0.39369

Collected Steps per Second: 21,632.77644
Overall Steps per Second: 13,959.44873

Timestep Collection Time: 2.31242
Timestep Consumption Time: 1.27111
PPO Batch Consumption Time: 0.10553
Total Iteration Time: 3.58352

Cumulative Model Updates: 59,876
Cumulative Timesteps: 499,541,440

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,329.08914
Policy Entropy: 1.06841
Value Function Loss: 0.06262

Mean KL Divergence: 0.00461
SB3 Clip Fraction: 0.05417
Policy Update Magnitude: 0.19133
Value Function Update Magnitude: 0.38442

Collected Steps per Second: 22,046.06646
Overall Steps per Second: 14,155.09772

Timestep Collection Time: 2.26852
Timestep Consumption Time: 1.26462
PPO Batch Consumption Time: 0.10669
Total Iteration Time: 3.53314

Cumulative Model Updates: 59,882
Cumulative Timesteps: 499,591,452

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 499591452...
Checkpoint 499591452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,220.43160
Policy Entropy: 1.05804
Value Function Loss: 0.06147

Mean KL Divergence: 0.00408
SB3 Clip Fraction: 0.04899
Policy Update Magnitude: 0.19163
Value Function Update Magnitude: 0.39001

Collected Steps per Second: 22,231.54586
Overall Steps per Second: 14,364.94384

Timestep Collection Time: 2.24996
Timestep Consumption Time: 1.23213
PPO Batch Consumption Time: 0.10045
Total Iteration Time: 3.48209

Cumulative Model Updates: 59,888
Cumulative Timesteps: 499,641,472

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,641.33098
Policy Entropy: 1.05819
Value Function Loss: 0.05910

Mean KL Divergence: 0.00400
SB3 Clip Fraction: 0.04732
Policy Update Magnitude: 0.18998
Value Function Update Magnitude: 0.39151

Collected Steps per Second: 22,140.74642
Overall Steps per Second: 14,173.80777

Timestep Collection Time: 2.25891
Timestep Consumption Time: 1.26971
PPO Batch Consumption Time: 0.10611
Total Iteration Time: 3.52862

Cumulative Model Updates: 59,894
Cumulative Timesteps: 499,691,486

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 499691486...
Checkpoint 499691486 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,479.32486
Policy Entropy: 1.05572
Value Function Loss: 0.05698

Mean KL Divergence: 0.00385
SB3 Clip Fraction: 0.04628
Policy Update Magnitude: 0.18811
Value Function Update Magnitude: 0.39069

Collected Steps per Second: 21,908.67904
Overall Steps per Second: 14,020.40275

Timestep Collection Time: 2.28357
Timestep Consumption Time: 1.28480
PPO Batch Consumption Time: 0.10483
Total Iteration Time: 3.56837

Cumulative Model Updates: 59,900
Cumulative Timesteps: 499,741,516

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,104.06743
Policy Entropy: 1.05889
Value Function Loss: 0.06328

Mean KL Divergence: 0.00369
SB3 Clip Fraction: 0.04350
Policy Update Magnitude: 0.19269
Value Function Update Magnitude: 0.38983

Collected Steps per Second: 21,454.41032
Overall Steps per Second: 13,797.16229

Timestep Collection Time: 2.33118
Timestep Consumption Time: 1.29377
PPO Batch Consumption Time: 0.09777
Total Iteration Time: 3.62495

Cumulative Model Updates: 59,906
Cumulative Timesteps: 499,791,530

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 499791530...
Checkpoint 499791530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,692.35775
Policy Entropy: 1.06017
Value Function Loss: 0.05954

Mean KL Divergence: 0.00329
SB3 Clip Fraction: 0.03897
Policy Update Magnitude: 0.20113
Value Function Update Magnitude: 0.38076

Collected Steps per Second: 21,147.10287
Overall Steps per Second: 13,976.64691

Timestep Collection Time: 2.36543
Timestep Consumption Time: 1.21354
PPO Batch Consumption Time: 0.09215
Total Iteration Time: 3.57897

Cumulative Model Updates: 59,912
Cumulative Timesteps: 499,841,552

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,931.86039
Policy Entropy: 1.07947
Value Function Loss: 0.05750

Mean KL Divergence: 0.00371
SB3 Clip Fraction: 0.04430
Policy Update Magnitude: 0.19765
Value Function Update Magnitude: 0.36462

Collected Steps per Second: 22,185.20796
Overall Steps per Second: 14,253.61632

Timestep Collection Time: 2.25547
Timestep Consumption Time: 1.25508
PPO Batch Consumption Time: 0.10370
Total Iteration Time: 3.51055

Cumulative Model Updates: 59,918
Cumulative Timesteps: 499,891,590

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 499891590...
Checkpoint 499891590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,531.04399
Policy Entropy: 1.07696
Value Function Loss: 0.05214

Mean KL Divergence: 0.00440
SB3 Clip Fraction: 0.05313
Policy Update Magnitude: 0.18653
Value Function Update Magnitude: 0.35642

Collected Steps per Second: 21,990.60230
Overall Steps per Second: 14,138.32793

Timestep Collection Time: 2.27479
Timestep Consumption Time: 1.26339
PPO Batch Consumption Time: 0.10364
Total Iteration Time: 3.53818

Cumulative Model Updates: 59,924
Cumulative Timesteps: 499,941,614

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,401.41097
Policy Entropy: 1.08209
Value Function Loss: 0.05615

Mean KL Divergence: 0.00459
SB3 Clip Fraction: 0.05425
Policy Update Magnitude: 0.18673
Value Function Update Magnitude: 0.36686

Collected Steps per Second: 22,147.33815
Overall Steps per Second: 14,362.01877

Timestep Collection Time: 2.25869
Timestep Consumption Time: 1.22438
PPO Batch Consumption Time: 0.09889
Total Iteration Time: 3.48308

Cumulative Model Updates: 59,930
Cumulative Timesteps: 499,991,638

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 499991638...
Checkpoint 499991638 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43,489.30430
Policy Entropy: 1.07878
Value Function Loss: 0.05415

Mean KL Divergence: 0.00434
SB3 Clip Fraction: 0.05219
Policy Update Magnitude: 0.18848
Value Function Update Magnitude: 0.36950

Collected Steps per Second: 21,723.60494
Overall Steps per Second: 14,046.14421

Timestep Collection Time: 2.30210
Timestep Consumption Time: 1.25830
PPO Batch Consumption Time: 0.10131
Total Iteration Time: 3.56041

Cumulative Model Updates: 59,936
Cumulative Timesteps: 500,041,648

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49,897.36547
Policy Entropy: 1.09272
Value Function Loss: 0.05752

Mean KL Divergence: 0.00577
SB3 Clip Fraction: 0.06411
Policy Update Magnitude: 0.19130
Value Function Update Magnitude: 0.36684

Collected Steps per Second: 22,114.56455
Overall Steps per Second: 14,113.78090

Timestep Collection Time: 2.26213
Timestep Consumption Time: 1.28235
PPO Batch Consumption Time: 0.10483
Total Iteration Time: 3.54448

Cumulative Model Updates: 59,942
Cumulative Timesteps: 500,091,674

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 500091674...
Checkpoint 500091674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,757.20467
Policy Entropy: 1.07887
Value Function Loss: 0.06006

Mean KL Divergence: 0.00505
SB3 Clip Fraction: 0.06001
Policy Update Magnitude: 0.19178
Value Function Update Magnitude: 0.36594

Collected Steps per Second: 20,320.82606
Overall Steps per Second: 13,614.15090

Timestep Collection Time: 2.46102
Timestep Consumption Time: 1.21236
PPO Batch Consumption Time: 0.09802
Total Iteration Time: 3.67338

Cumulative Model Updates: 59,948
Cumulative Timesteps: 500,141,684

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,721.58500
Policy Entropy: 1.07652
Value Function Loss: 0.06059

Mean KL Divergence: 0.00524
SB3 Clip Fraction: 0.05930
Policy Update Magnitude: 0.19548
Value Function Update Magnitude: 0.35507

Collected Steps per Second: 21,954.87568
Overall Steps per Second: 14,141.65553

Timestep Collection Time: 2.27867
Timestep Consumption Time: 1.25896
PPO Batch Consumption Time: 0.09880
Total Iteration Time: 3.53763

Cumulative Model Updates: 59,954
Cumulative Timesteps: 500,191,712

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 500191712...
Checkpoint 500191712 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,608.48033
Policy Entropy: 1.06389
Value Function Loss: 0.05672

Mean KL Divergence: 0.00487
SB3 Clip Fraction: 0.05615
Policy Update Magnitude: 0.20362
Value Function Update Magnitude: 0.34223

Collected Steps per Second: 21,834.20792
Overall Steps per Second: 14,125.83676

Timestep Collection Time: 2.29072
Timestep Consumption Time: 1.25003
PPO Batch Consumption Time: 0.10540
Total Iteration Time: 3.54075

Cumulative Model Updates: 59,960
Cumulative Timesteps: 500,241,728

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,100.70140
Policy Entropy: 1.06467
Value Function Loss: 0.05201

Mean KL Divergence: 0.00684
SB3 Clip Fraction: 0.07513
Policy Update Magnitude: 0.18616
Value Function Update Magnitude: 0.32751

Collected Steps per Second: 22,265.75322
Overall Steps per Second: 14,533.26631

Timestep Collection Time: 2.24596
Timestep Consumption Time: 1.19497
PPO Batch Consumption Time: 0.09460
Total Iteration Time: 3.44093

Cumulative Model Updates: 59,966
Cumulative Timesteps: 500,291,736

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 500291736...
Checkpoint 500291736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,368.15962
Policy Entropy: 1.06900
Value Function Loss: 0.05590

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.08167
Policy Update Magnitude: 0.17294
Value Function Update Magnitude: 0.33573

Collected Steps per Second: 21,855.39740
Overall Steps per Second: 14,182.39915

Timestep Collection Time: 2.28868
Timestep Consumption Time: 1.23823
PPO Batch Consumption Time: 0.10313
Total Iteration Time: 3.52691

Cumulative Model Updates: 59,972
Cumulative Timesteps: 500,341,756

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,417.88769
Policy Entropy: 1.07204
Value Function Loss: 0.06060

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.09220
Policy Update Magnitude: 0.17458
Value Function Update Magnitude: 0.35412

Collected Steps per Second: 21,993.00313
Overall Steps per Second: 14,168.48539

Timestep Collection Time: 2.27436
Timestep Consumption Time: 1.25601
PPO Batch Consumption Time: 0.10328
Total Iteration Time: 3.53037

Cumulative Model Updates: 59,978
Cumulative Timesteps: 500,391,776

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 500391776...
Checkpoint 500391776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,469.50844
Policy Entropy: 1.05744
Value Function Loss: 0.06593

Mean KL Divergence: 0.00713
SB3 Clip Fraction: 0.07810
Policy Update Magnitude: 0.19592
Value Function Update Magnitude: 0.39458

Collected Steps per Second: 21,867.87573
Overall Steps per Second: 14,445.24407

Timestep Collection Time: 2.28655
Timestep Consumption Time: 1.17493
PPO Batch Consumption Time: 0.09431
Total Iteration Time: 3.46149

Cumulative Model Updates: 59,984
Cumulative Timesteps: 500,441,778

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49,402.38635
Policy Entropy: 1.05849
Value Function Loss: 0.06163

Mean KL Divergence: 0.00543
SB3 Clip Fraction: 0.05978
Policy Update Magnitude: 0.20710
Value Function Update Magnitude: 0.41138

Collected Steps per Second: 22,090.06285
Overall Steps per Second: 14,169.59919

Timestep Collection Time: 2.26419
Timestep Consumption Time: 1.26562
PPO Batch Consumption Time: 0.10382
Total Iteration Time: 3.52981

Cumulative Model Updates: 59,990
Cumulative Timesteps: 500,491,794

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 500491794...
Checkpoint 500491794 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,635.54068
Policy Entropy: 1.04575
Value Function Loss: 0.06224

Mean KL Divergence: 0.00338
SB3 Clip Fraction: 0.03984
Policy Update Magnitude: 0.21594
Value Function Update Magnitude: 0.40028

Collected Steps per Second: 21,665.59770
Overall Steps per Second: 13,866.20599

Timestep Collection Time: 2.30956
Timestep Consumption Time: 1.29907
PPO Batch Consumption Time: 0.10080
Total Iteration Time: 3.60863

Cumulative Model Updates: 59,996
Cumulative Timesteps: 500,541,832

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,912.82512
Policy Entropy: 1.06801
Value Function Loss: 0.06245

Mean KL Divergence: 0.00385
SB3 Clip Fraction: 0.04701
Policy Update Magnitude: 0.21167
Value Function Update Magnitude: 0.38349

Collected Steps per Second: 22,222.15708
Overall Steps per Second: 14,060.72383

Timestep Collection Time: 2.25136
Timestep Consumption Time: 1.30678
PPO Batch Consumption Time: 0.10573
Total Iteration Time: 3.55814

Cumulative Model Updates: 60,002
Cumulative Timesteps: 500,591,862

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 500591862...
Checkpoint 500591862 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,937.67209
Policy Entropy: 1.06634
Value Function Loss: 0.07347

Mean KL Divergence: 0.00399
SB3 Clip Fraction: 0.04746
Policy Update Magnitude: 0.22088
Value Function Update Magnitude: 0.38566

Collected Steps per Second: 22,124.35390
Overall Steps per Second: 14,198.03237

Timestep Collection Time: 2.26004
Timestep Consumption Time: 1.26171
PPO Batch Consumption Time: 0.10317
Total Iteration Time: 3.52176

Cumulative Model Updates: 60,008
Cumulative Timesteps: 500,641,864

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,995.42311
Policy Entropy: 1.07615
Value Function Loss: 0.07243

Mean KL Divergence: 0.00508
SB3 Clip Fraction: 0.06107
Policy Update Magnitude: 0.22362
Value Function Update Magnitude: 0.41596

Collected Steps per Second: 21,496.82662
Overall Steps per Second: 13,957.93258

Timestep Collection Time: 2.32592
Timestep Consumption Time: 1.25627
PPO Batch Consumption Time: 0.10375
Total Iteration Time: 3.58219

Cumulative Model Updates: 60,014
Cumulative Timesteps: 500,691,864

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 500691864...
Checkpoint 500691864 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,762.60279
Policy Entropy: 1.06774
Value Function Loss: 0.06274

Mean KL Divergence: 0.00405
SB3 Clip Fraction: 0.04855
Policy Update Magnitude: 0.21769
Value Function Update Magnitude: 0.41588

Collected Steps per Second: 21,697.22209
Overall Steps per Second: 13,968.12248

Timestep Collection Time: 2.30472
Timestep Consumption Time: 1.27529
PPO Batch Consumption Time: 0.10393
Total Iteration Time: 3.58001

Cumulative Model Updates: 60,020
Cumulative Timesteps: 500,741,870

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,706.11615
Policy Entropy: 1.06345
Value Function Loss: 0.05831

Mean KL Divergence: 0.00370
SB3 Clip Fraction: 0.04455
Policy Update Magnitude: 0.20426
Value Function Update Magnitude: 0.39039

Collected Steps per Second: 22,104.04002
Overall Steps per Second: 14,375.90527

Timestep Collection Time: 2.26312
Timestep Consumption Time: 1.21660
PPO Batch Consumption Time: 0.09609
Total Iteration Time: 3.47971

Cumulative Model Updates: 60,026
Cumulative Timesteps: 500,791,894

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 500791894...
Checkpoint 500791894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,931.38577
Policy Entropy: 1.07044
Value Function Loss: 0.05699

Mean KL Divergence: 0.00393
SB3 Clip Fraction: 0.04612
Policy Update Magnitude: 0.20827
Value Function Update Magnitude: 0.37390

Collected Steps per Second: 21,573.78209
Overall Steps per Second: 14,054.09080

Timestep Collection Time: 2.31883
Timestep Consumption Time: 1.24070
PPO Batch Consumption Time: 0.09929
Total Iteration Time: 3.55953

Cumulative Model Updates: 60,032
Cumulative Timesteps: 500,841,920

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,193.98585
Policy Entropy: 1.07559
Value Function Loss: 0.06722

Mean KL Divergence: 0.00506
SB3 Clip Fraction: 0.05909
Policy Update Magnitude: 0.20324
Value Function Update Magnitude: 0.38491

Collected Steps per Second: 22,217.18699
Overall Steps per Second: 14,181.44110

Timestep Collection Time: 2.25213
Timestep Consumption Time: 1.27614
PPO Batch Consumption Time: 0.10460
Total Iteration Time: 3.52827

Cumulative Model Updates: 60,038
Cumulative Timesteps: 500,891,956

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 500891956...
Checkpoint 500891956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,939.83851
Policy Entropy: 1.08089
Value Function Loss: 0.07028

Mean KL Divergence: 0.00541
SB3 Clip Fraction: 0.06397
Policy Update Magnitude: 0.20535
Value Function Update Magnitude: 0.41222

Collected Steps per Second: 21,746.34322
Overall Steps per Second: 13,918.06177

Timestep Collection Time: 2.30117
Timestep Consumption Time: 1.29430
PPO Batch Consumption Time: 0.10682
Total Iteration Time: 3.59547

Cumulative Model Updates: 60,044
Cumulative Timesteps: 500,941,998

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,579.75734
Policy Entropy: 1.08616
Value Function Loss: 0.07180

Mean KL Divergence: 0.00504
SB3 Clip Fraction: 0.05819
Policy Update Magnitude: 0.21188
Value Function Update Magnitude: 0.42215

Collected Steps per Second: 20,206.66825
Overall Steps per Second: 13,115.15322

Timestep Collection Time: 2.47611
Timestep Consumption Time: 1.33886
PPO Batch Consumption Time: 0.10488
Total Iteration Time: 3.81498

Cumulative Model Updates: 60,050
Cumulative Timesteps: 500,992,032

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 500992032...
Checkpoint 500992032 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,694.88438
Policy Entropy: 1.09067
Value Function Loss: 0.06822

Mean KL Divergence: 0.00526
SB3 Clip Fraction: 0.06074
Policy Update Magnitude: 0.20601
Value Function Update Magnitude: 0.41644

Collected Steps per Second: 20,080.58157
Overall Steps per Second: 13,180.71159

Timestep Collection Time: 2.49186
Timestep Consumption Time: 1.30444
PPO Batch Consumption Time: 0.09763
Total Iteration Time: 3.79630

Cumulative Model Updates: 60,056
Cumulative Timesteps: 501,042,070

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,986.47811
Policy Entropy: 1.06833
Value Function Loss: 0.06985

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.08563
Policy Update Magnitude: 0.19220
Value Function Update Magnitude: 0.43051

Collected Steps per Second: 21,957.60968
Overall Steps per Second: 14,131.50471

Timestep Collection Time: 2.27766
Timestep Consumption Time: 1.26138
PPO Batch Consumption Time: 0.10572
Total Iteration Time: 3.53904

Cumulative Model Updates: 60,062
Cumulative Timesteps: 501,092,082

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 501092082...
Checkpoint 501092082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,085.37405
Policy Entropy: 1.07917
Value Function Loss: 0.06577

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.09394
Policy Update Magnitude: 0.18144
Value Function Update Magnitude: 0.43631

Collected Steps per Second: 21,891.76203
Overall Steps per Second: 14,085.78487

Timestep Collection Time: 2.28433
Timestep Consumption Time: 1.26592
PPO Batch Consumption Time: 0.10495
Total Iteration Time: 3.55025

Cumulative Model Updates: 60,068
Cumulative Timesteps: 501,142,090

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,744.40378
Policy Entropy: 1.08055
Value Function Loss: 0.06273

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.07812
Policy Update Magnitude: 0.19231
Value Function Update Magnitude: 0.41687

Collected Steps per Second: 22,007.21937
Overall Steps per Second: 14,108.56217

Timestep Collection Time: 2.27380
Timestep Consumption Time: 1.27298
PPO Batch Consumption Time: 0.10432
Total Iteration Time: 3.54678

Cumulative Model Updates: 60,074
Cumulative Timesteps: 501,192,130

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 501192130...
Checkpoint 501192130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,841.16887
Policy Entropy: 1.09639
Value Function Loss: 0.05560

Mean KL Divergence: 0.00606
SB3 Clip Fraction: 0.06970
Policy Update Magnitude: 0.19995
Value Function Update Magnitude: 0.39437

Collected Steps per Second: 22,002.52835
Overall Steps per Second: 14,059.38500

Timestep Collection Time: 2.27310
Timestep Consumption Time: 1.28424
PPO Batch Consumption Time: 0.10306
Total Iteration Time: 3.55734

Cumulative Model Updates: 60,080
Cumulative Timesteps: 501,242,144

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,345.90254
Policy Entropy: 1.08062
Value Function Loss: 0.05884

Mean KL Divergence: 0.00491
SB3 Clip Fraction: 0.05797
Policy Update Magnitude: 0.19591
Value Function Update Magnitude: 0.37280

Collected Steps per Second: 22,420.85461
Overall Steps per Second: 14,416.93409

Timestep Collection Time: 2.23194
Timestep Consumption Time: 1.23912
PPO Batch Consumption Time: 0.10407
Total Iteration Time: 3.47106

Cumulative Model Updates: 60,086
Cumulative Timesteps: 501,292,186

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 501292186...
Checkpoint 501292186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,425.33209
Policy Entropy: 1.08371
Value Function Loss: 0.05532

Mean KL Divergence: 0.00418
SB3 Clip Fraction: 0.04914
Policy Update Magnitude: 0.19750
Value Function Update Magnitude: 0.37273

Collected Steps per Second: 21,676.54427
Overall Steps per Second: 13,848.02884

Timestep Collection Time: 2.30673
Timestep Consumption Time: 1.30403
PPO Batch Consumption Time: 0.10660
Total Iteration Time: 3.61077

Cumulative Model Updates: 60,092
Cumulative Timesteps: 501,342,188

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,529.75224
Policy Entropy: 1.07710
Value Function Loss: 0.05884

Mean KL Divergence: 0.00643
SB3 Clip Fraction: 0.06916
Policy Update Magnitude: 0.19513
Value Function Update Magnitude: 0.37015

Collected Steps per Second: 21,999.30299
Overall Steps per Second: 13,989.89986

Timestep Collection Time: 2.27371
Timestep Consumption Time: 1.30173
PPO Batch Consumption Time: 0.10944
Total Iteration Time: 3.57544

Cumulative Model Updates: 60,098
Cumulative Timesteps: 501,392,208

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 501392208...
Checkpoint 501392208 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,520.91059
Policy Entropy: 1.07989
Value Function Loss: 0.06165

Mean KL Divergence: 0.00594
SB3 Clip Fraction: 0.06282
Policy Update Magnitude: 0.18906
Value Function Update Magnitude: 0.39638

Collected Steps per Second: 21,642.03195
Overall Steps per Second: 14,082.84534

Timestep Collection Time: 2.31097
Timestep Consumption Time: 1.24045
PPO Batch Consumption Time: 0.10225
Total Iteration Time: 3.55141

Cumulative Model Updates: 60,104
Cumulative Timesteps: 501,442,222

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,094.08298
Policy Entropy: 1.08277
Value Function Loss: 0.06385

Mean KL Divergence: 0.00651
SB3 Clip Fraction: 0.07197
Policy Update Magnitude: 0.19324
Value Function Update Magnitude: 0.40566

Collected Steps per Second: 21,910.72569
Overall Steps per Second: 14,129.60849

Timestep Collection Time: 2.28244
Timestep Consumption Time: 1.25693
PPO Batch Consumption Time: 0.10458
Total Iteration Time: 3.53938

Cumulative Model Updates: 60,110
Cumulative Timesteps: 501,492,232

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 501492232...
Checkpoint 501492232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,176.39437
Policy Entropy: 1.09848
Value Function Loss: 0.06251

Mean KL Divergence: 0.00540
SB3 Clip Fraction: 0.06417
Policy Update Magnitude: 0.19688
Value Function Update Magnitude: 0.37274

Collected Steps per Second: 21,870.25282
Overall Steps per Second: 13,948.18458

Timestep Collection Time: 2.28767
Timestep Consumption Time: 1.29932
PPO Batch Consumption Time: 0.10627
Total Iteration Time: 3.58699

Cumulative Model Updates: 60,116
Cumulative Timesteps: 501,542,264

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,889.44269
Policy Entropy: 1.10179
Value Function Loss: 0.06296

Mean KL Divergence: 0.00552
SB3 Clip Fraction: 0.06310
Policy Update Magnitude: 0.20626
Value Function Update Magnitude: 0.35548

Collected Steps per Second: 21,813.74345
Overall Steps per Second: 14,021.78387

Timestep Collection Time: 2.29241
Timestep Consumption Time: 1.27390
PPO Batch Consumption Time: 0.10406
Total Iteration Time: 3.56631

Cumulative Model Updates: 60,122
Cumulative Timesteps: 501,592,270

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 501592270...
Checkpoint 501592270 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,576.59007
Policy Entropy: 1.10747
Value Function Loss: 0.06203

Mean KL Divergence: 0.00469
SB3 Clip Fraction: 0.05465
Policy Update Magnitude: 0.20639
Value Function Update Magnitude: 0.37547

Collected Steps per Second: 21,215.69198
Overall Steps per Second: 13,694.88801

Timestep Collection Time: 2.35778
Timestep Consumption Time: 1.29482
PPO Batch Consumption Time: 0.09923
Total Iteration Time: 3.65260

Cumulative Model Updates: 60,128
Cumulative Timesteps: 501,642,292

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,961.52643
Policy Entropy: 1.10507
Value Function Loss: 0.06558

Mean KL Divergence: 0.00419
SB3 Clip Fraction: 0.04963
Policy Update Magnitude: 0.21322
Value Function Update Magnitude: 0.39853

Collected Steps per Second: 20,731.81267
Overall Steps per Second: 13,602.68925

Timestep Collection Time: 2.41223
Timestep Consumption Time: 1.26424
PPO Batch Consumption Time: 0.10389
Total Iteration Time: 3.67648

Cumulative Model Updates: 60,134
Cumulative Timesteps: 501,692,302

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 501692302...
Checkpoint 501692302 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,415.29933
Policy Entropy: 1.09861
Value Function Loss: 0.06501

Mean KL Divergence: 0.00503
SB3 Clip Fraction: 0.05963
Policy Update Magnitude: 0.21261
Value Function Update Magnitude: 0.42259

Collected Steps per Second: 22,149.17621
Overall Steps per Second: 14,344.88159

Timestep Collection Time: 2.25742
Timestep Consumption Time: 1.22814
PPO Batch Consumption Time: 0.09471
Total Iteration Time: 3.48556

Cumulative Model Updates: 60,140
Cumulative Timesteps: 501,742,302

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,991.60861
Policy Entropy: 1.09665
Value Function Loss: 0.06905

Mean KL Divergence: 0.00553
SB3 Clip Fraction: 0.06580
Policy Update Magnitude: 0.21864
Value Function Update Magnitude: 0.42830

Collected Steps per Second: 22,208.74193
Overall Steps per Second: 14,384.15979

Timestep Collection Time: 2.25218
Timestep Consumption Time: 1.22512
PPO Batch Consumption Time: 0.10302
Total Iteration Time: 3.47730

Cumulative Model Updates: 60,146
Cumulative Timesteps: 501,792,320

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 501792320...
Checkpoint 501792320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,591.91263
Policy Entropy: 1.09933
Value Function Loss: 0.07482

Mean KL Divergence: 0.00532
SB3 Clip Fraction: 0.06247
Policy Update Magnitude: 0.22948
Value Function Update Magnitude: 0.39700

Collected Steps per Second: 21,633.42101
Overall Steps per Second: 14,119.51057

Timestep Collection Time: 2.31272
Timestep Consumption Time: 1.23075
PPO Batch Consumption Time: 0.10274
Total Iteration Time: 3.54347

Cumulative Model Updates: 60,152
Cumulative Timesteps: 501,842,352

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,744.25047
Policy Entropy: 1.09575
Value Function Loss: 0.07961

Mean KL Divergence: 0.00525
SB3 Clip Fraction: 0.06238
Policy Update Magnitude: 0.23870
Value Function Update Magnitude: 0.39334

Collected Steps per Second: 22,024.13556
Overall Steps per Second: 14,316.35333

Timestep Collection Time: 2.27060
Timestep Consumption Time: 1.22247
PPO Batch Consumption Time: 0.10029
Total Iteration Time: 3.49307

Cumulative Model Updates: 60,158
Cumulative Timesteps: 501,892,360

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 501892360...
Checkpoint 501892360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,060.21530
Policy Entropy: 1.09469
Value Function Loss: 0.07161

Mean KL Divergence: 0.00477
SB3 Clip Fraction: 0.05637
Policy Update Magnitude: 0.24969
Value Function Update Magnitude: 0.41879

Collected Steps per Second: 21,632.65191
Overall Steps per Second: 14,026.17839

Timestep Collection Time: 2.31206
Timestep Consumption Time: 1.25384
PPO Batch Consumption Time: 0.10322
Total Iteration Time: 3.56590

Cumulative Model Updates: 60,164
Cumulative Timesteps: 501,942,376

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,295.58180
Policy Entropy: 1.11243
Value Function Loss: 0.06447

Mean KL Divergence: 0.00398
SB3 Clip Fraction: 0.04789
Policy Update Magnitude: 0.23561
Value Function Update Magnitude: 0.42199

Collected Steps per Second: 22,228.29556
Overall Steps per Second: 14,605.78324

Timestep Collection Time: 2.25100
Timestep Consumption Time: 1.17476
PPO Batch Consumption Time: 0.09333
Total Iteration Time: 3.42577

Cumulative Model Updates: 60,170
Cumulative Timesteps: 501,992,412

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 501992412...
Checkpoint 501992412 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,594.70364
Policy Entropy: 1.12279
Value Function Loss: 0.06102

Mean KL Divergence: 0.00547
SB3 Clip Fraction: 0.06261
Policy Update Magnitude: 0.22068
Value Function Update Magnitude: 0.41667

Collected Steps per Second: 21,894.76796
Overall Steps per Second: 14,153.96393

Timestep Collection Time: 2.28365
Timestep Consumption Time: 1.24893
PPO Batch Consumption Time: 0.10236
Total Iteration Time: 3.53258

Cumulative Model Updates: 60,176
Cumulative Timesteps: 502,042,412

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,892.36127
Policy Entropy: 1.10846
Value Function Loss: 0.06532

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.09539
Policy Update Magnitude: 0.20072
Value Function Update Magnitude: 0.43154

Collected Steps per Second: 22,219.79313
Overall Steps per Second: 14,580.32060

Timestep Collection Time: 2.25142
Timestep Consumption Time: 1.17965
PPO Batch Consumption Time: 0.09390
Total Iteration Time: 3.43106

Cumulative Model Updates: 60,182
Cumulative Timesteps: 502,092,438

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 502092438...
Checkpoint 502092438 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,895.72147
Policy Entropy: 1.10066
Value Function Loss: 0.06450

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.08613
Policy Update Magnitude: 0.21285
Value Function Update Magnitude: 0.43462

Collected Steps per Second: 21,675.99016
Overall Steps per Second: 14,087.90481

Timestep Collection Time: 2.30670
Timestep Consumption Time: 1.24244
PPO Batch Consumption Time: 0.09983
Total Iteration Time: 3.54914

Cumulative Model Updates: 60,188
Cumulative Timesteps: 502,142,438

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,828.17551
Policy Entropy: 1.09579
Value Function Loss: 0.06445

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.08015
Policy Update Magnitude: 0.22040
Value Function Update Magnitude: 0.41742

Collected Steps per Second: 22,139.08165
Overall Steps per Second: 14,165.51986

Timestep Collection Time: 2.25917
Timestep Consumption Time: 1.27165
PPO Batch Consumption Time: 0.10422
Total Iteration Time: 3.53083

Cumulative Model Updates: 60,194
Cumulative Timesteps: 502,192,454

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 502192454...
Checkpoint 502192454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,980.45664
Policy Entropy: 1.09218
Value Function Loss: 0.06096

Mean KL Divergence: 0.00615
SB3 Clip Fraction: 0.07017
Policy Update Magnitude: 0.21444
Value Function Update Magnitude: 0.41306

Collected Steps per Second: 21,953.15954
Overall Steps per Second: 14,068.57406

Timestep Collection Time: 2.27794
Timestep Consumption Time: 1.27665
PPO Batch Consumption Time: 0.10319
Total Iteration Time: 3.55459

Cumulative Model Updates: 60,200
Cumulative Timesteps: 502,242,462

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,001.78252
Policy Entropy: 1.09413
Value Function Loss: 0.06179

Mean KL Divergence: 0.00616
SB3 Clip Fraction: 0.06835
Policy Update Magnitude: 0.20779
Value Function Update Magnitude: 0.41075

Collected Steps per Second: 22,224.41694
Overall Steps per Second: 14,424.04994

Timestep Collection Time: 2.25086
Timestep Consumption Time: 1.21724
PPO Batch Consumption Time: 0.09857
Total Iteration Time: 3.46810

Cumulative Model Updates: 60,206
Cumulative Timesteps: 502,292,486

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 502292486...
Checkpoint 502292486 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,883.93649
Policy Entropy: 1.10895
Value Function Loss: 0.05752

Mean KL Divergence: 0.00570
SB3 Clip Fraction: 0.06461
Policy Update Magnitude: 0.20844
Value Function Update Magnitude: 0.40554

Collected Steps per Second: 21,541.05966
Overall Steps per Second: 14,025.67298

Timestep Collection Time: 2.32180
Timestep Consumption Time: 1.24409
PPO Batch Consumption Time: 0.09781
Total Iteration Time: 3.56589

Cumulative Model Updates: 60,212
Cumulative Timesteps: 502,342,500

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,472.10539
Policy Entropy: 1.10994
Value Function Loss: 0.06559

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.08785
Policy Update Magnitude: 0.19899
Value Function Update Magnitude: 0.40367

Collected Steps per Second: 22,038.45729
Overall Steps per Second: 14,058.90457

Timestep Collection Time: 2.26976
Timestep Consumption Time: 1.28827
PPO Batch Consumption Time: 0.10580
Total Iteration Time: 3.55803

Cumulative Model Updates: 60,218
Cumulative Timesteps: 502,392,522

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 502392522...
Checkpoint 502392522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,725.02746
Policy Entropy: 1.11096
Value Function Loss: 0.06832

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.09538
Policy Update Magnitude: 0.17997
Value Function Update Magnitude: 0.39079

Collected Steps per Second: 19,885.99396
Overall Steps per Second: 13,048.71620

Timestep Collection Time: 2.51604
Timestep Consumption Time: 1.31836
PPO Batch Consumption Time: 0.10624
Total Iteration Time: 3.83440

Cumulative Model Updates: 60,224
Cumulative Timesteps: 502,442,556

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,646.01781
Policy Entropy: 1.10596
Value Function Loss: 0.07292

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.09244
Policy Update Magnitude: 0.18586
Value Function Update Magnitude: 0.37888

Collected Steps per Second: 20,000.88240
Overall Steps per Second: 13,347.13586

Timestep Collection Time: 2.49999
Timestep Consumption Time: 1.24628
PPO Batch Consumption Time: 0.10253
Total Iteration Time: 3.74627

Cumulative Model Updates: 60,230
Cumulative Timesteps: 502,492,558

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 502492558...
Checkpoint 502492558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,921.31175
Policy Entropy: 1.10365
Value Function Loss: 0.07054

Mean KL Divergence: 0.01069
SB3 Clip Fraction: 0.09918
Policy Update Magnitude: 0.18755
Value Function Update Magnitude: 0.36789

Collected Steps per Second: 21,698.79718
Overall Steps per Second: 14,051.48975

Timestep Collection Time: 2.30520
Timestep Consumption Time: 1.25457
PPO Batch Consumption Time: 0.10178
Total Iteration Time: 3.55976

Cumulative Model Updates: 60,236
Cumulative Timesteps: 502,542,578

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,134.44788
Policy Entropy: 1.09112
Value Function Loss: 0.07449

Mean KL Divergence: 0.00611
SB3 Clip Fraction: 0.06926
Policy Update Magnitude: 0.20025
Value Function Update Magnitude: 0.36513

Collected Steps per Second: 21,759.58255
Overall Steps per Second: 14,007.57507

Timestep Collection Time: 2.29784
Timestep Consumption Time: 1.27166
PPO Batch Consumption Time: 0.10607
Total Iteration Time: 3.56950

Cumulative Model Updates: 60,242
Cumulative Timesteps: 502,592,578

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 502592578...
Checkpoint 502592578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,064.33085
Policy Entropy: 1.09529
Value Function Loss: 0.06679

Mean KL Divergence: 0.00621
SB3 Clip Fraction: 0.07211
Policy Update Magnitude: 0.20327
Value Function Update Magnitude: 0.38796

Collected Steps per Second: 21,749.45329
Overall Steps per Second: 13,992.54188

Timestep Collection Time: 2.30093
Timestep Consumption Time: 1.27555
PPO Batch Consumption Time: 0.10770
Total Iteration Time: 3.57648

Cumulative Model Updates: 60,248
Cumulative Timesteps: 502,642,622

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,346.98278
Policy Entropy: 1.09356
Value Function Loss: 0.07252

Mean KL Divergence: 0.00450
SB3 Clip Fraction: 0.05358
Policy Update Magnitude: 0.21335
Value Function Update Magnitude: 0.38625

Collected Steps per Second: 21,801.66050
Overall Steps per Second: 13,904.25414

Timestep Collection Time: 2.29469
Timestep Consumption Time: 1.30335
PPO Batch Consumption Time: 0.11140
Total Iteration Time: 3.59804

Cumulative Model Updates: 60,254
Cumulative Timesteps: 502,692,650

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 502692650...
Checkpoint 502692650 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,131.73945
Policy Entropy: 1.10350
Value Function Loss: 0.06950

Mean KL Divergence: 0.00499
SB3 Clip Fraction: 0.05832
Policy Update Magnitude: 0.22282
Value Function Update Magnitude: 0.42902

Collected Steps per Second: 21,595.05204
Overall Steps per Second: 14,085.63013

Timestep Collection Time: 2.31738
Timestep Consumption Time: 1.23546
PPO Batch Consumption Time: 0.09863
Total Iteration Time: 3.55284

Cumulative Model Updates: 60,260
Cumulative Timesteps: 502,742,694

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,862.36491
Policy Entropy: 1.09553
Value Function Loss: 0.06894

Mean KL Divergence: 0.00430
SB3 Clip Fraction: 0.05002
Policy Update Magnitude: 0.22643
Value Function Update Magnitude: 0.44681

Collected Steps per Second: 22,268.44477
Overall Steps per Second: 14,051.96570

Timestep Collection Time: 2.24614
Timestep Consumption Time: 1.31336
PPO Batch Consumption Time: 0.11095
Total Iteration Time: 3.55950

Cumulative Model Updates: 60,266
Cumulative Timesteps: 502,792,712

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 502792712...
Checkpoint 502792712 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,718.75111
Policy Entropy: 1.10220
Value Function Loss: 0.07037

Mean KL Divergence: 0.00443
SB3 Clip Fraction: 0.05301
Policy Update Magnitude: 0.22767
Value Function Update Magnitude: 0.42222

Collected Steps per Second: 21,417.97532
Overall Steps per Second: 13,784.24870

Timestep Collection Time: 2.33495
Timestep Consumption Time: 1.29310
PPO Batch Consumption Time: 0.10826
Total Iteration Time: 3.62805

Cumulative Model Updates: 60,272
Cumulative Timesteps: 502,842,722

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,831.15542
Policy Entropy: 1.10638
Value Function Loss: 0.06674

Mean KL Divergence: 0.00419
SB3 Clip Fraction: 0.05077
Policy Update Magnitude: 0.22890
Value Function Update Magnitude: 0.43309

Collected Steps per Second: 22,192.43336
Overall Steps per Second: 14,099.32388

Timestep Collection Time: 2.25401
Timestep Consumption Time: 1.29382
PPO Batch Consumption Time: 0.10541
Total Iteration Time: 3.54783

Cumulative Model Updates: 60,278
Cumulative Timesteps: 502,892,744

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 502892744...
Checkpoint 502892744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,366.59868
Policy Entropy: 1.12165
Value Function Loss: 0.06571

Mean KL Divergence: 0.00392
SB3 Clip Fraction: 0.04607
Policy Update Magnitude: 0.22574
Value Function Update Magnitude: 0.44402

Collected Steps per Second: 21,397.56339
Overall Steps per Second: 13,855.20247

Timestep Collection Time: 2.33718
Timestep Consumption Time: 1.27229
PPO Batch Consumption Time: 0.10679
Total Iteration Time: 3.60947

Cumulative Model Updates: 60,284
Cumulative Timesteps: 502,942,754

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,019.67279
Policy Entropy: 1.13448
Value Function Loss: 0.06613

Mean KL Divergence: 0.00371
SB3 Clip Fraction: 0.04350
Policy Update Magnitude: 0.21975
Value Function Update Magnitude: 0.43243

Collected Steps per Second: 21,959.96676
Overall Steps per Second: 14,185.32031

Timestep Collection Time: 2.27787
Timestep Consumption Time: 1.24845
PPO Batch Consumption Time: 0.10318
Total Iteration Time: 3.52632

Cumulative Model Updates: 60,290
Cumulative Timesteps: 502,992,776

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 502992776...
Checkpoint 502992776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,237.06459
Policy Entropy: 1.13068
Value Function Loss: 0.06613

Mean KL Divergence: 0.00491
SB3 Clip Fraction: 0.05720
Policy Update Magnitude: 0.21278
Value Function Update Magnitude: 0.38103

Collected Steps per Second: 21,822.49421
Overall Steps per Second: 14,050.91727

Timestep Collection Time: 2.29158
Timestep Consumption Time: 1.26748
PPO Batch Consumption Time: 0.10759
Total Iteration Time: 3.55906

Cumulative Model Updates: 60,296
Cumulative Timesteps: 503,042,784

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,320.71629
Policy Entropy: 1.11353
Value Function Loss: 0.06446

Mean KL Divergence: 0.00432
SB3 Clip Fraction: 0.05204
Policy Update Magnitude: 0.20745
Value Function Update Magnitude: 0.37691

Collected Steps per Second: 20,905.55192
Overall Steps per Second: 13,759.79875

Timestep Collection Time: 2.39401
Timestep Consumption Time: 1.24326
PPO Batch Consumption Time: 0.10041
Total Iteration Time: 3.63726

Cumulative Model Updates: 60,302
Cumulative Timesteps: 503,092,832

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 503092832...
Checkpoint 503092832 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,817.33621
Policy Entropy: 1.09845
Value Function Loss: 0.05949

Mean KL Divergence: 0.00557
SB3 Clip Fraction: 0.06220
Policy Update Magnitude: 0.19832
Value Function Update Magnitude: 0.37833

Collected Steps per Second: 20,661.26458
Overall Steps per Second: 13,835.65303

Timestep Collection Time: 2.42047
Timestep Consumption Time: 1.19410
PPO Batch Consumption Time: 0.09501
Total Iteration Time: 3.61457

Cumulative Model Updates: 60,308
Cumulative Timesteps: 503,142,842

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,037.19606
Policy Entropy: 1.08428
Value Function Loss: 0.05899

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.08131
Policy Update Magnitude: 0.17678
Value Function Update Magnitude: 0.38742

Collected Steps per Second: 21,520.54273
Overall Steps per Second: 13,999.74774

Timestep Collection Time: 2.32503
Timestep Consumption Time: 1.24903
PPO Batch Consumption Time: 0.09805
Total Iteration Time: 3.57406

Cumulative Model Updates: 60,314
Cumulative Timesteps: 503,192,878

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 503192878...
Checkpoint 503192878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,088.19597
Policy Entropy: 1.10253
Value Function Loss: 0.05869

Mean KL Divergence: 0.00474
SB3 Clip Fraction: 0.05486
Policy Update Magnitude: 0.18658
Value Function Update Magnitude: 0.38807

Collected Steps per Second: 21,334.52905
Overall Steps per Second: 13,988.05109

Timestep Collection Time: 2.34437
Timestep Consumption Time: 1.23125
PPO Batch Consumption Time: 0.09778
Total Iteration Time: 3.57562

Cumulative Model Updates: 60,320
Cumulative Timesteps: 503,242,894

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,185.75288
Policy Entropy: 1.10918
Value Function Loss: 0.05725

Mean KL Divergence: 0.00498
SB3 Clip Fraction: 0.05824
Policy Update Magnitude: 0.20771
Value Function Update Magnitude: 0.38589

Collected Steps per Second: 22,029.66862
Overall Steps per Second: 14,187.39621

Timestep Collection Time: 2.27076
Timestep Consumption Time: 1.25519
PPO Batch Consumption Time: 0.10472
Total Iteration Time: 3.52595

Cumulative Model Updates: 60,326
Cumulative Timesteps: 503,292,918

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 503292918...
Checkpoint 503292918 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,807.19160
Policy Entropy: 1.12162
Value Function Loss: 0.06671

Mean KL Divergence: 0.00387
SB3 Clip Fraction: 0.04642
Policy Update Magnitude: 0.20856
Value Function Update Magnitude: 0.39622

Collected Steps per Second: 20,340.76476
Overall Steps per Second: 13,331.76907

Timestep Collection Time: 2.45812
Timestep Consumption Time: 1.29232
PPO Batch Consumption Time: 0.10533
Total Iteration Time: 3.75044

Cumulative Model Updates: 60,332
Cumulative Timesteps: 503,342,918

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,429.26149
Policy Entropy: 1.12087
Value Function Loss: 0.07222

Mean KL Divergence: 0.00470
SB3 Clip Fraction: 0.05557
Policy Update Magnitude: 0.21583
Value Function Update Magnitude: 0.41920

Collected Steps per Second: 19,744.75591
Overall Steps per Second: 13,176.48253

Timestep Collection Time: 2.53455
Timestep Consumption Time: 1.26343
PPO Batch Consumption Time: 0.10272
Total Iteration Time: 3.79798

Cumulative Model Updates: 60,338
Cumulative Timesteps: 503,392,962

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 503392962...
Checkpoint 503392962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,008.20292
Policy Entropy: 1.11236
Value Function Loss: 0.07045

Mean KL Divergence: 0.00491
SB3 Clip Fraction: 0.05869
Policy Update Magnitude: 0.22151
Value Function Update Magnitude: 0.42429

Collected Steps per Second: 20,003.25099
Overall Steps per Second: 13,252.39544

Timestep Collection Time: 2.50139
Timestep Consumption Time: 1.27423
PPO Batch Consumption Time: 0.10559
Total Iteration Time: 3.77562

Cumulative Model Updates: 60,344
Cumulative Timesteps: 503,442,998

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,519.54280
Policy Entropy: 1.09003
Value Function Loss: 0.06938

Mean KL Divergence: 0.01131
SB3 Clip Fraction: 0.09962
Policy Update Magnitude: 0.20822
Value Function Update Magnitude: 0.41547

Collected Steps per Second: 20,846.23960
Overall Steps per Second: 13,669.82207

Timestep Collection Time: 2.39871
Timestep Consumption Time: 1.25928
PPO Batch Consumption Time: 0.10195
Total Iteration Time: 3.65798

Cumulative Model Updates: 60,350
Cumulative Timesteps: 503,493,002

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 503493002...
Checkpoint 503493002 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,699.67775
Policy Entropy: 1.10225
Value Function Loss: 0.06593

Mean KL Divergence: 0.00752
SB3 Clip Fraction: 0.08079
Policy Update Magnitude: 0.20374
Value Function Update Magnitude: 0.40919

Collected Steps per Second: 20,595.23329
Overall Steps per Second: 13,411.54797

Timestep Collection Time: 2.42843
Timestep Consumption Time: 1.30075
PPO Batch Consumption Time: 0.10573
Total Iteration Time: 3.72917

Cumulative Model Updates: 60,356
Cumulative Timesteps: 503,543,016

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,153.99416
Policy Entropy: 1.11262
Value Function Loss: 0.06775

Mean KL Divergence: 0.00516
SB3 Clip Fraction: 0.06081
Policy Update Magnitude: 0.22369
Value Function Update Magnitude: 0.41949

Collected Steps per Second: 22,108.02230
Overall Steps per Second: 14,263.49598

Timestep Collection Time: 2.26180
Timestep Consumption Time: 1.24393
PPO Batch Consumption Time: 0.10342
Total Iteration Time: 3.50573

Cumulative Model Updates: 60,362
Cumulative Timesteps: 503,593,020

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 503593020...
Checkpoint 503593020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,729.06920
Policy Entropy: 1.12959
Value Function Loss: 0.06234

Mean KL Divergence: 0.00443
SB3 Clip Fraction: 0.05359
Policy Update Magnitude: 0.22403
Value Function Update Magnitude: 0.41454

Collected Steps per Second: 21,637.69375
Overall Steps per Second: 13,927.92840

Timestep Collection Time: 2.31134
Timestep Consumption Time: 1.27943
PPO Batch Consumption Time: 0.10329
Total Iteration Time: 3.59077

Cumulative Model Updates: 60,368
Cumulative Timesteps: 503,643,032

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,880.35747
Policy Entropy: 1.13091
Value Function Loss: 0.06131

Mean KL Divergence: 0.00383
SB3 Clip Fraction: 0.04572
Policy Update Magnitude: 0.21668
Value Function Update Magnitude: 0.39260

Collected Steps per Second: 21,858.86227
Overall Steps per Second: 14,357.71523

Timestep Collection Time: 2.28877
Timestep Consumption Time: 1.19576
PPO Batch Consumption Time: 0.09702
Total Iteration Time: 3.48454

Cumulative Model Updates: 60,374
Cumulative Timesteps: 503,693,062

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 503693062...
Checkpoint 503693062 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,198.37421
Policy Entropy: 1.12901
Value Function Loss: 0.05676

Mean KL Divergence: 0.00464
SB3 Clip Fraction: 0.05255
Policy Update Magnitude: 0.21053
Value Function Update Magnitude: 0.38581

Collected Steps per Second: 21,975.29372
Overall Steps per Second: 14,012.75006

Timestep Collection Time: 2.27574
Timestep Consumption Time: 1.29316
PPO Batch Consumption Time: 0.11260
Total Iteration Time: 3.56889

Cumulative Model Updates: 60,380
Cumulative Timesteps: 503,743,072

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,770.05455
Policy Entropy: 1.11514
Value Function Loss: 0.05251

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.08103
Policy Update Magnitude: 0.19452
Value Function Update Magnitude: 0.37098

Collected Steps per Second: 21,698.51004
Overall Steps per Second: 14,043.09004

Timestep Collection Time: 2.30458
Timestep Consumption Time: 1.25631
PPO Batch Consumption Time: 0.10390
Total Iteration Time: 3.56090

Cumulative Model Updates: 60,386
Cumulative Timesteps: 503,793,078

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 503793078...
Checkpoint 503793078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,205.12004
Policy Entropy: 1.10886
Value Function Loss: 0.05212

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.08180
Policy Update Magnitude: 0.18741
Value Function Update Magnitude: 0.35137

Collected Steps per Second: 19,069.77560
Overall Steps per Second: 12,936.16495

Timestep Collection Time: 2.62289
Timestep Consumption Time: 1.24363
PPO Batch Consumption Time: 0.09873
Total Iteration Time: 3.86652

Cumulative Model Updates: 60,392
Cumulative Timesteps: 503,843,096

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,701.31451
Policy Entropy: 1.10282
Value Function Loss: 0.05882

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.09038
Policy Update Magnitude: 0.19261
Value Function Update Magnitude: 0.36286

Collected Steps per Second: 21,237.81112
Overall Steps per Second: 13,863.50478

Timestep Collection Time: 2.35457
Timestep Consumption Time: 1.25245
PPO Batch Consumption Time: 0.10228
Total Iteration Time: 3.60702

Cumulative Model Updates: 60,398
Cumulative Timesteps: 503,893,102

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 503893102...
Checkpoint 503893102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,654.40240
Policy Entropy: 1.09609
Value Function Loss: 0.05990

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.09096
Policy Update Magnitude: 0.19962
Value Function Update Magnitude: 0.37952

Collected Steps per Second: 19,905.34757
Overall Steps per Second: 13,142.75731

Timestep Collection Time: 2.51400
Timestep Consumption Time: 1.29357
PPO Batch Consumption Time: 0.10292
Total Iteration Time: 3.80757

Cumulative Model Updates: 60,404
Cumulative Timesteps: 503,943,144

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,293.24810
Policy Entropy: 1.10571
Value Function Loss: 0.06267

Mean KL Divergence: 0.00727
SB3 Clip Fraction: 0.07717
Policy Update Magnitude: 0.20708
Value Function Update Magnitude: 0.39000

Collected Steps per Second: 21,862.15997
Overall Steps per Second: 13,951.25235

Timestep Collection Time: 2.28925
Timestep Consumption Time: 1.29810
PPO Batch Consumption Time: 0.10435
Total Iteration Time: 3.58735

Cumulative Model Updates: 60,410
Cumulative Timesteps: 503,993,192

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 503993192...
Checkpoint 503993192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,271.27674
Policy Entropy: 1.10975
Value Function Loss: 0.05891

Mean KL Divergence: 0.00643
SB3 Clip Fraction: 0.07177
Policy Update Magnitude: 0.21309
Value Function Update Magnitude: 0.38821

Collected Steps per Second: 21,816.23635
Overall Steps per Second: 14,027.82068

Timestep Collection Time: 2.29270
Timestep Consumption Time: 1.27293
PPO Batch Consumption Time: 0.10462
Total Iteration Time: 3.56563

Cumulative Model Updates: 60,416
Cumulative Timesteps: 504,043,210

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,144.36897
Policy Entropy: 1.11581
Value Function Loss: 0.05933

Mean KL Divergence: 0.00448
SB3 Clip Fraction: 0.05381
Policy Update Magnitude: 0.22204
Value Function Update Magnitude: 0.40368

Collected Steps per Second: 21,497.96123
Overall Steps per Second: 14,026.36562

Timestep Collection Time: 2.32655
Timestep Consumption Time: 1.23931
PPO Batch Consumption Time: 0.10330
Total Iteration Time: 3.56586

Cumulative Model Updates: 60,422
Cumulative Timesteps: 504,093,226

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 504093226...
Checkpoint 504093226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,480.84183
Policy Entropy: 1.11864
Value Function Loss: 0.05724

Mean KL Divergence: 0.00439
SB3 Clip Fraction: 0.05288
Policy Update Magnitude: 0.21595
Value Function Update Magnitude: 0.40815

Collected Steps per Second: 21,833.70748
Overall Steps per Second: 14,157.29849

Timestep Collection Time: 2.29050
Timestep Consumption Time: 1.24196
PPO Batch Consumption Time: 0.09971
Total Iteration Time: 3.53245

Cumulative Model Updates: 60,428
Cumulative Timesteps: 504,143,236

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,273.69685
Policy Entropy: 1.11135
Value Function Loss: 0.05983

Mean KL Divergence: 0.00502
SB3 Clip Fraction: 0.05954
Policy Update Magnitude: 0.20838
Value Function Update Magnitude: 0.39014

Collected Steps per Second: 21,601.84753
Overall Steps per Second: 14,187.77551

Timestep Collection Time: 2.31665
Timestep Consumption Time: 1.21061
PPO Batch Consumption Time: 0.09433
Total Iteration Time: 3.52726

Cumulative Model Updates: 60,434
Cumulative Timesteps: 504,193,280

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 504193280...
Checkpoint 504193280 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,600.29168
Policy Entropy: 1.11283
Value Function Loss: 0.06323

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.09315
Policy Update Magnitude: 0.19777
Value Function Update Magnitude: 0.37366

Collected Steps per Second: 21,507.65496
Overall Steps per Second: 14,112.44034

Timestep Collection Time: 2.32550
Timestep Consumption Time: 1.21861
PPO Batch Consumption Time: 0.09597
Total Iteration Time: 3.54411

Cumulative Model Updates: 60,440
Cumulative Timesteps: 504,243,296

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,940.64404
Policy Entropy: 1.11066
Value Function Loss: 0.07634

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.08155
Policy Update Magnitude: 0.18830
Value Function Update Magnitude: 0.40737

Collected Steps per Second: 22,148.43152
Overall Steps per Second: 14,224.18262

Timestep Collection Time: 2.25795
Timestep Consumption Time: 1.25790
PPO Batch Consumption Time: 0.10576
Total Iteration Time: 3.51584

Cumulative Model Updates: 60,446
Cumulative Timesteps: 504,293,306

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 504293306...
Checkpoint 504293306 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,272.77079
Policy Entropy: 1.11566
Value Function Loss: 0.07868

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.08764
Policy Update Magnitude: 0.20125
Value Function Update Magnitude: 0.44632

Collected Steps per Second: 21,163.56790
Overall Steps per Second: 13,479.71793

Timestep Collection Time: 2.36265
Timestep Consumption Time: 1.34678
PPO Batch Consumption Time: 0.11205
Total Iteration Time: 3.70942

Cumulative Model Updates: 60,452
Cumulative Timesteps: 504,343,308

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,161.04805
Policy Entropy: 1.11427
Value Function Loss: 0.07234

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.09155
Policy Update Magnitude: 0.20040
Value Function Update Magnitude: 0.44385

Collected Steps per Second: 21,696.07901
Overall Steps per Second: 14,188.83171

Timestep Collection Time: 2.30604
Timestep Consumption Time: 1.22011
PPO Batch Consumption Time: 0.10271
Total Iteration Time: 3.52615

Cumulative Model Updates: 60,458
Cumulative Timesteps: 504,393,340

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 504393340...
Checkpoint 504393340 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,670.85343
Policy Entropy: 1.11199
Value Function Loss: 0.06292

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.09298
Policy Update Magnitude: 0.20108
Value Function Update Magnitude: 0.41510

Collected Steps per Second: 21,245.22668
Overall Steps per Second: 13,959.07719

Timestep Collection Time: 2.35413
Timestep Consumption Time: 1.22877
PPO Batch Consumption Time: 0.09853
Total Iteration Time: 3.58290

Cumulative Model Updates: 60,464
Cumulative Timesteps: 504,443,354

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,936.71659
Policy Entropy: 1.11993
Value Function Loss: 0.06611

Mean KL Divergence: 0.00735
SB3 Clip Fraction: 0.08049
Policy Update Magnitude: 0.20729
Value Function Update Magnitude: 0.41264

Collected Steps per Second: 21,699.66287
Overall Steps per Second: 13,950.25464

Timestep Collection Time: 2.30464
Timestep Consumption Time: 1.28024
PPO Batch Consumption Time: 0.10277
Total Iteration Time: 3.58488

Cumulative Model Updates: 60,470
Cumulative Timesteps: 504,493,364

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 504493364...
Checkpoint 504493364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,622.27497
Policy Entropy: 1.13066
Value Function Loss: 0.06259

Mean KL Divergence: 0.00686
SB3 Clip Fraction: 0.07223
Policy Update Magnitude: 0.21250
Value Function Update Magnitude: 0.42719

Collected Steps per Second: 21,598.04831
Overall Steps per Second: 14,084.49673

Timestep Collection Time: 2.31586
Timestep Consumption Time: 1.23542
PPO Batch Consumption Time: 0.10255
Total Iteration Time: 3.55128

Cumulative Model Updates: 60,476
Cumulative Timesteps: 504,543,382

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,085.00089
Policy Entropy: 1.12756
Value Function Loss: 0.06446

Mean KL Divergence: 0.00622
SB3 Clip Fraction: 0.06965
Policy Update Magnitude: 0.21061
Value Function Update Magnitude: 0.41819

Collected Steps per Second: 22,071.56466
Overall Steps per Second: 14,092.67444

Timestep Collection Time: 2.26536
Timestep Consumption Time: 1.28258
PPO Batch Consumption Time: 0.10314
Total Iteration Time: 3.54794

Cumulative Model Updates: 60,482
Cumulative Timesteps: 504,593,382

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 504593382...
Checkpoint 504593382 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,757.20358
Policy Entropy: 1.13104
Value Function Loss: 0.05413

Mean KL Divergence: 0.00671
SB3 Clip Fraction: 0.08030
Policy Update Magnitude: 0.19838
Value Function Update Magnitude: 0.40310

Collected Steps per Second: 21,760.41250
Overall Steps per Second: 13,943.54543

Timestep Collection Time: 2.29812
Timestep Consumption Time: 1.28834
PPO Batch Consumption Time: 0.10601
Total Iteration Time: 3.58646

Cumulative Model Updates: 60,488
Cumulative Timesteps: 504,643,390

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47,940.30254
Policy Entropy: 1.12251
Value Function Loss: 0.05847

Mean KL Divergence: 0.00532
SB3 Clip Fraction: 0.06396
Policy Update Magnitude: 0.20033
Value Function Update Magnitude: 0.38683

Collected Steps per Second: 22,126.38633
Overall Steps per Second: 14,529.31815

Timestep Collection Time: 2.26074
Timestep Consumption Time: 1.18209
PPO Batch Consumption Time: 0.09428
Total Iteration Time: 3.44283

Cumulative Model Updates: 60,494
Cumulative Timesteps: 504,693,412

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 504693412...
Checkpoint 504693412 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,512.62281
Policy Entropy: 1.12365
Value Function Loss: 0.05821

Mean KL Divergence: 0.00534
SB3 Clip Fraction: 0.06262
Policy Update Magnitude: 0.20242
Value Function Update Magnitude: 0.36087

Collected Steps per Second: 21,971.36886
Overall Steps per Second: 14,177.19509

Timestep Collection Time: 2.27605
Timestep Consumption Time: 1.25130
PPO Batch Consumption Time: 0.10410
Total Iteration Time: 3.52736

Cumulative Model Updates: 60,500
Cumulative Timesteps: 504,743,420

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,448.96201
Policy Entropy: 1.10616
Value Function Loss: 0.06758

Mean KL Divergence: 0.00587
SB3 Clip Fraction: 0.06828
Policy Update Magnitude: 0.20448
Value Function Update Magnitude: 0.36453

Collected Steps per Second: 21,460.05787
Overall Steps per Second: 14,060.90382

Timestep Collection Time: 2.33093
Timestep Consumption Time: 1.22659
PPO Batch Consumption Time: 0.10124
Total Iteration Time: 3.55752

Cumulative Model Updates: 60,506
Cumulative Timesteps: 504,793,442

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 504793442...
Checkpoint 504793442 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,550.28464
Policy Entropy: 1.11466
Value Function Loss: 0.06789

Mean KL Divergence: 0.00656
SB3 Clip Fraction: 0.07701
Policy Update Magnitude: 0.21166
Value Function Update Magnitude: 0.38533

Collected Steps per Second: 21,471.13653
Overall Steps per Second: 13,859.68119

Timestep Collection Time: 2.32899
Timestep Consumption Time: 1.27903
PPO Batch Consumption Time: 0.10716
Total Iteration Time: 3.60802

Cumulative Model Updates: 60,512
Cumulative Timesteps: 504,843,448

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,840.28695
Policy Entropy: 1.11293
Value Function Loss: 0.06603

Mean KL Divergence: 0.00514
SB3 Clip Fraction: 0.06031
Policy Update Magnitude: 0.21782
Value Function Update Magnitude: 0.39431

Collected Steps per Second: 21,583.99094
Overall Steps per Second: 13,963.19029

Timestep Collection Time: 2.31829
Timestep Consumption Time: 1.26527
PPO Batch Consumption Time: 0.10537
Total Iteration Time: 3.58357

Cumulative Model Updates: 60,518
Cumulative Timesteps: 504,893,486

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 504893486...
Checkpoint 504893486 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,987.03529
Policy Entropy: 1.12042
Value Function Loss: 0.06251

Mean KL Divergence: 0.00429
SB3 Clip Fraction: 0.05128
Policy Update Magnitude: 0.22129
Value Function Update Magnitude: 0.38488

Collected Steps per Second: 21,673.10419
Overall Steps per Second: 13,963.99464

Timestep Collection Time: 2.30775
Timestep Consumption Time: 1.27404
PPO Batch Consumption Time: 0.10773
Total Iteration Time: 3.58178

Cumulative Model Updates: 60,524
Cumulative Timesteps: 504,943,502

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,499.18570
Policy Entropy: 1.11834
Value Function Loss: 0.06600

Mean KL Divergence: 0.00369
SB3 Clip Fraction: 0.04419
Policy Update Magnitude: 0.22207
Value Function Update Magnitude: 0.38688

Collected Steps per Second: 21,648.03122
Overall Steps per Second: 14,198.16219

Timestep Collection Time: 2.31153
Timestep Consumption Time: 1.21287
PPO Batch Consumption Time: 0.10068
Total Iteration Time: 3.52440

Cumulative Model Updates: 60,530
Cumulative Timesteps: 504,993,542

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 504993542...
Checkpoint 504993542 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,515.52984
Policy Entropy: 1.13096
Value Function Loss: 0.06507

Mean KL Divergence: 0.00463
SB3 Clip Fraction: 0.05656
Policy Update Magnitude: 0.21994
Value Function Update Magnitude: 0.41255

Collected Steps per Second: 21,592.88206
Overall Steps per Second: 13,820.80151

Timestep Collection Time: 2.31567
Timestep Consumption Time: 1.30221
PPO Batch Consumption Time: 0.11125
Total Iteration Time: 3.61788

Cumulative Model Updates: 60,536
Cumulative Timesteps: 505,043,544

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,200.82042
Policy Entropy: 1.12170
Value Function Loss: 0.06178

Mean KL Divergence: 0.00379
SB3 Clip Fraction: 0.04554
Policy Update Magnitude: 0.21242
Value Function Update Magnitude: 0.40277

Collected Steps per Second: 22,023.83432
Overall Steps per Second: 14,099.47788

Timestep Collection Time: 2.27099
Timestep Consumption Time: 1.27637
PPO Batch Consumption Time: 0.10668
Total Iteration Time: 3.54737

Cumulative Model Updates: 60,542
Cumulative Timesteps: 505,093,560

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 505093560...
Checkpoint 505093560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,491.31574
Policy Entropy: 1.12301
Value Function Loss: 0.06096

Mean KL Divergence: 0.00411
SB3 Clip Fraction: 0.04945
Policy Update Magnitude: 0.20643
Value Function Update Magnitude: 0.37834

Collected Steps per Second: 21,893.88923
Overall Steps per Second: 14,116.64373

Timestep Collection Time: 2.28566
Timestep Consumption Time: 1.25923
PPO Batch Consumption Time: 0.10375
Total Iteration Time: 3.54489

Cumulative Model Updates: 60,548
Cumulative Timesteps: 505,143,602

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,377.02237
Policy Entropy: 1.11576
Value Function Loss: 0.06325

Mean KL Divergence: 0.00409
SB3 Clip Fraction: 0.04913
Policy Update Magnitude: 0.20414
Value Function Update Magnitude: 0.37892

Collected Steps per Second: 21,995.68081
Overall Steps per Second: 14,344.59774

Timestep Collection Time: 2.27399
Timestep Consumption Time: 1.21290
PPO Batch Consumption Time: 0.09612
Total Iteration Time: 3.48689

Cumulative Model Updates: 60,554
Cumulative Timesteps: 505,193,620

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 505193620...
Checkpoint 505193620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,356.72264
Policy Entropy: 1.11510
Value Function Loss: 0.06751

Mean KL Divergence: 0.00484
SB3 Clip Fraction: 0.05865
Policy Update Magnitude: 0.21170
Value Function Update Magnitude: 0.39666

Collected Steps per Second: 21,615.10076
Overall Steps per Second: 14,042.14710

Timestep Collection Time: 2.31440
Timestep Consumption Time: 1.24816
PPO Batch Consumption Time: 0.09995
Total Iteration Time: 3.56256

Cumulative Model Updates: 60,560
Cumulative Timesteps: 505,243,646

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,850.42923
Policy Entropy: 1.12304
Value Function Loss: 0.06605

Mean KL Divergence: 0.00485
SB3 Clip Fraction: 0.05874
Policy Update Magnitude: 0.21550
Value Function Update Magnitude: 0.40181

Collected Steps per Second: 18,916.57517
Overall Steps per Second: 12,865.33077

Timestep Collection Time: 2.64361
Timestep Consumption Time: 1.24343
PPO Batch Consumption Time: 0.10041
Total Iteration Time: 3.88704

Cumulative Model Updates: 60,566
Cumulative Timesteps: 505,293,654

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 505293654...
Checkpoint 505293654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,267.93026
Policy Entropy: 1.12471
Value Function Loss: 0.05747

Mean KL Divergence: 0.00506
SB3 Clip Fraction: 0.06021
Policy Update Magnitude: 0.21440
Value Function Update Magnitude: 0.38725

Collected Steps per Second: 19,597.89372
Overall Steps per Second: 13,288.46043

Timestep Collection Time: 2.55252
Timestep Consumption Time: 1.21195
PPO Batch Consumption Time: 0.10031
Total Iteration Time: 3.76447

Cumulative Model Updates: 60,572
Cumulative Timesteps: 505,343,678

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,349.64093
Policy Entropy: 1.13191
Value Function Loss: 0.05694

Mean KL Divergence: 0.00490
SB3 Clip Fraction: 0.05845
Policy Update Magnitude: 0.20583
Value Function Update Magnitude: 0.37125

Collected Steps per Second: 21,843.14532
Overall Steps per Second: 14,869.69439

Timestep Collection Time: 2.28960
Timestep Consumption Time: 1.07375
PPO Batch Consumption Time: 0.07609
Total Iteration Time: 3.36335

Cumulative Model Updates: 60,578
Cumulative Timesteps: 505,393,690

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 505393690...
Checkpoint 505393690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,060.59320
Policy Entropy: 1.13616
Value Function Loss: 0.05457

Mean KL Divergence: 0.00423
SB3 Clip Fraction: 0.05015
Policy Update Magnitude: 0.19848
Value Function Update Magnitude: 0.34591

Collected Steps per Second: 22,107.21864
Overall Steps per Second: 14,361.68652

Timestep Collection Time: 2.26252
Timestep Consumption Time: 1.22022
PPO Batch Consumption Time: 0.09437
Total Iteration Time: 3.48274

Cumulative Model Updates: 60,584
Cumulative Timesteps: 505,443,708

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,149.51699
Policy Entropy: 1.12721
Value Function Loss: 0.06322

Mean KL Divergence: 0.00343
SB3 Clip Fraction: 0.04051
Policy Update Magnitude: 0.20721
Value Function Update Magnitude: 0.35483

Collected Steps per Second: 22,415.70316
Overall Steps per Second: 14,387.09541

Timestep Collection Time: 2.23156
Timestep Consumption Time: 1.24531
PPO Batch Consumption Time: 0.10273
Total Iteration Time: 3.47687

Cumulative Model Updates: 60,590
Cumulative Timesteps: 505,493,730

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 505493730...
Checkpoint 505493730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,968.38151
Policy Entropy: 1.12040
Value Function Loss: 0.05741

Mean KL Divergence: 0.00438
SB3 Clip Fraction: 0.05400
Policy Update Magnitude: 0.20564
Value Function Update Magnitude: 0.38592

Collected Steps per Second: 21,451.60033
Overall Steps per Second: 13,940.75244

Timestep Collection Time: 2.33129
Timestep Consumption Time: 1.25603
PPO Batch Consumption Time: 0.10191
Total Iteration Time: 3.58732

Cumulative Model Updates: 60,596
Cumulative Timesteps: 505,543,740

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,306.67262
Policy Entropy: 1.11788
Value Function Loss: 0.06155

Mean KL Divergence: 0.00433
SB3 Clip Fraction: 0.05144
Policy Update Magnitude: 0.20508
Value Function Update Magnitude: 0.40557

Collected Steps per Second: 22,325.36987
Overall Steps per Second: 14,353.22144

Timestep Collection Time: 2.24104
Timestep Consumption Time: 1.24473
PPO Batch Consumption Time: 0.09683
Total Iteration Time: 3.48577

Cumulative Model Updates: 60,602
Cumulative Timesteps: 505,593,772

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 505593772...
Checkpoint 505593772 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,601.21077
Policy Entropy: 1.12872
Value Function Loss: 0.05865

Mean KL Divergence: 0.00534
SB3 Clip Fraction: 0.06376
Policy Update Magnitude: 0.20157
Value Function Update Magnitude: 0.40089

Collected Steps per Second: 22,047.01933
Overall Steps per Second: 14,107.44385

Timestep Collection Time: 2.26870
Timestep Consumption Time: 1.27681
PPO Batch Consumption Time: 0.10411
Total Iteration Time: 3.54550

Cumulative Model Updates: 60,608
Cumulative Timesteps: 505,643,790

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,405.04998
Policy Entropy: 1.13837
Value Function Loss: 0.06341

Mean KL Divergence: 0.00500
SB3 Clip Fraction: 0.06011
Policy Update Magnitude: 0.20277
Value Function Update Magnitude: 0.39473

Collected Steps per Second: 21,532.10244
Overall Steps per Second: 13,892.21438

Timestep Collection Time: 2.32249
Timestep Consumption Time: 1.27723
PPO Batch Consumption Time: 0.10292
Total Iteration Time: 3.59971

Cumulative Model Updates: 60,614
Cumulative Timesteps: 505,693,798

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 505693798...
Checkpoint 505693798 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,982.01249
Policy Entropy: 1.14381
Value Function Loss: 0.06933

Mean KL Divergence: 0.00524
SB3 Clip Fraction: 0.06166
Policy Update Magnitude: 0.19937
Value Function Update Magnitude: 0.39758

Collected Steps per Second: 22,003.36774
Overall Steps per Second: 14,089.11523

Timestep Collection Time: 2.27274
Timestep Consumption Time: 1.27666
PPO Batch Consumption Time: 0.10560
Total Iteration Time: 3.54941

Cumulative Model Updates: 60,620
Cumulative Timesteps: 505,743,806

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,526.33811
Policy Entropy: 1.15250
Value Function Loss: 0.06816

Mean KL Divergence: 0.00529
SB3 Clip Fraction: 0.06275
Policy Update Magnitude: 0.20469
Value Function Update Magnitude: 0.40580

Collected Steps per Second: 22,266.01051
Overall Steps per Second: 14,578.57076

Timestep Collection Time: 2.24692
Timestep Consumption Time: 1.18483
PPO Batch Consumption Time: 0.09517
Total Iteration Time: 3.43175

Cumulative Model Updates: 60,626
Cumulative Timesteps: 505,793,836

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 505793836...
Checkpoint 505793836 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,123.98902
Policy Entropy: 1.15500
Value Function Loss: 0.06272

Mean KL Divergence: 0.00456
SB3 Clip Fraction: 0.05455
Policy Update Magnitude: 0.20799
Value Function Update Magnitude: 0.38541

Collected Steps per Second: 21,662.71870
Overall Steps per Second: 14,134.53608

Timestep Collection Time: 2.30857
Timestep Consumption Time: 1.22957
PPO Batch Consumption Time: 0.10182
Total Iteration Time: 3.53814

Cumulative Model Updates: 60,632
Cumulative Timesteps: 505,843,846

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,368.23363
Policy Entropy: 1.14229
Value Function Loss: 0.05587

Mean KL Divergence: 0.00523
SB3 Clip Fraction: 0.06269
Policy Update Magnitude: 0.20312
Value Function Update Magnitude: 0.36176

Collected Steps per Second: 22,367.65046
Overall Steps per Second: 14,629.27598

Timestep Collection Time: 2.23582
Timestep Consumption Time: 1.18267
PPO Batch Consumption Time: 0.09524
Total Iteration Time: 3.41849

Cumulative Model Updates: 60,638
Cumulative Timesteps: 505,893,856

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 505893856...
Checkpoint 505893856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,277.23439
Policy Entropy: 1.13019
Value Function Loss: 0.05110

Mean KL Divergence: 0.00454
SB3 Clip Fraction: 0.05460
Policy Update Magnitude: 0.19722
Value Function Update Magnitude: 0.34867

Collected Steps per Second: 21,832.46371
Overall Steps per Second: 14,091.60444

Timestep Collection Time: 2.29081
Timestep Consumption Time: 1.25840
PPO Batch Consumption Time: 0.10083
Total Iteration Time: 3.54921

Cumulative Model Updates: 60,644
Cumulative Timesteps: 505,943,870

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,214.62776
Policy Entropy: 1.12989
Value Function Loss: 0.05067

Mean KL Divergence: 0.00418
SB3 Clip Fraction: 0.04987
Policy Update Magnitude: 0.19622
Value Function Update Magnitude: 0.34413

Collected Steps per Second: 21,868.30415
Overall Steps per Second: 14,057.79509

Timestep Collection Time: 2.28715
Timestep Consumption Time: 1.27074
PPO Batch Consumption Time: 0.10534
Total Iteration Time: 3.55788

Cumulative Model Updates: 60,650
Cumulative Timesteps: 505,993,886

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 505993886...
Checkpoint 505993886 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,595.05101
Policy Entropy: 1.14162
Value Function Loss: 0.05122

Mean KL Divergence: 0.00428
SB3 Clip Fraction: 0.05231
Policy Update Magnitude: 0.19550
Value Function Update Magnitude: 0.33935

Collected Steps per Second: 21,954.56544
Overall Steps per Second: 14,166.57334

Timestep Collection Time: 2.27871
Timestep Consumption Time: 1.25271
PPO Batch Consumption Time: 0.10280
Total Iteration Time: 3.53141

Cumulative Model Updates: 60,656
Cumulative Timesteps: 506,043,914

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,039.38361
Policy Entropy: 1.14665
Value Function Loss: 0.05312

Mean KL Divergence: 0.00381
SB3 Clip Fraction: 0.04520
Policy Update Magnitude: 0.19590
Value Function Update Magnitude: 0.33601

Collected Steps per Second: 21,990.50419
Overall Steps per Second: 14,391.99559

Timestep Collection Time: 2.27471
Timestep Consumption Time: 1.20097
PPO Batch Consumption Time: 0.09704
Total Iteration Time: 3.47568

Cumulative Model Updates: 60,662
Cumulative Timesteps: 506,093,936

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 506093936...
Checkpoint 506093936 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,348.76438
Policy Entropy: 1.15082
Value Function Loss: 0.05812

Mean KL Divergence: 0.00473
SB3 Clip Fraction: 0.05609
Policy Update Magnitude: 0.19671
Value Function Update Magnitude: 0.34106

Collected Steps per Second: 21,401.09906
Overall Steps per Second: 14,034.34276

Timestep Collection Time: 2.33754
Timestep Consumption Time: 1.22700
PPO Batch Consumption Time: 0.09754
Total Iteration Time: 3.56454

Cumulative Model Updates: 60,668
Cumulative Timesteps: 506,143,962

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,768.82769
Policy Entropy: 1.15388
Value Function Loss: 0.05761

Mean KL Divergence: 0.00542
SB3 Clip Fraction: 0.06303
Policy Update Magnitude: 0.19497
Value Function Update Magnitude: 0.36039

Collected Steps per Second: 22,150.10453
Overall Steps per Second: 14,343.49385

Timestep Collection Time: 2.25850
Timestep Consumption Time: 1.22921
PPO Batch Consumption Time: 0.10243
Total Iteration Time: 3.48771

Cumulative Model Updates: 60,674
Cumulative Timesteps: 506,193,988

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 506193988...
Checkpoint 506193988 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,940.32812
Policy Entropy: 1.15071
Value Function Loss: 0.05990

Mean KL Divergence: 0.00447
SB3 Clip Fraction: 0.05369
Policy Update Magnitude: 0.20223
Value Function Update Magnitude: 0.36927

Collected Steps per Second: 21,482.21166
Overall Steps per Second: 14,077.21945

Timestep Collection Time: 2.32993
Timestep Consumption Time: 1.22560
PPO Batch Consumption Time: 0.10273
Total Iteration Time: 3.55553

Cumulative Model Updates: 60,680
Cumulative Timesteps: 506,244,040

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,456.06024
Policy Entropy: 1.15178
Value Function Loss: 0.05936

Mean KL Divergence: 0.00432
SB3 Clip Fraction: 0.05308
Policy Update Magnitude: 0.20716
Value Function Update Magnitude: 0.37904

Collected Steps per Second: 22,184.55411
Overall Steps per Second: 14,366.70394

Timestep Collection Time: 2.25472
Timestep Consumption Time: 1.22694
PPO Batch Consumption Time: 0.10116
Total Iteration Time: 3.48166

Cumulative Model Updates: 60,686
Cumulative Timesteps: 506,294,060

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 506294060...
Checkpoint 506294060 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,546.05707
Policy Entropy: 1.14242
Value Function Loss: 0.05384

Mean KL Divergence: 0.00329
SB3 Clip Fraction: 0.03836
Policy Update Magnitude: 0.20677
Value Function Update Magnitude: 0.38239

Collected Steps per Second: 21,338.65181
Overall Steps per Second: 13,967.50413

Timestep Collection Time: 2.34513
Timestep Consumption Time: 1.23761
PPO Batch Consumption Time: 0.10326
Total Iteration Time: 3.58274

Cumulative Model Updates: 60,692
Cumulative Timesteps: 506,344,102

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,957.52176
Policy Entropy: 1.14186
Value Function Loss: 0.05341

Mean KL Divergence: 0.00381
SB3 Clip Fraction: 0.04633
Policy Update Magnitude: 0.20722
Value Function Update Magnitude: 0.36399

Collected Steps per Second: 22,021.24051
Overall Steps per Second: 14,017.89390

Timestep Collection Time: 2.27172
Timestep Consumption Time: 1.29701
PPO Batch Consumption Time: 0.10571
Total Iteration Time: 3.56872

Cumulative Model Updates: 60,698
Cumulative Timesteps: 506,394,128

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 506394128...
Checkpoint 506394128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,555.92617
Policy Entropy: 1.13646
Value Function Loss: 0.05616

Mean KL Divergence: 0.00404
SB3 Clip Fraction: 0.04889
Policy Update Magnitude: 0.20728
Value Function Update Magnitude: 0.37419

Collected Steps per Second: 21,974.84796
Overall Steps per Second: 14,167.95736

Timestep Collection Time: 2.27742
Timestep Consumption Time: 1.25492
PPO Batch Consumption Time: 0.10384
Total Iteration Time: 3.53234

Cumulative Model Updates: 60,704
Cumulative Timesteps: 506,444,174

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,721.28975
Policy Entropy: 1.13782
Value Function Loss: 0.06042

Mean KL Divergence: 0.00435
SB3 Clip Fraction: 0.05206
Policy Update Magnitude: 0.21375
Value Function Update Magnitude: 0.39042

Collected Steps per Second: 22,498.24338
Overall Steps per Second: 14,542.23183

Timestep Collection Time: 2.22302
Timestep Consumption Time: 1.21621
PPO Batch Consumption Time: 0.10151
Total Iteration Time: 3.43922

Cumulative Model Updates: 60,710
Cumulative Timesteps: 506,494,188

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 506494188...
Checkpoint 506494188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,671.50840
Policy Entropy: 1.14630
Value Function Loss: 0.05690

Mean KL Divergence: 0.00501
SB3 Clip Fraction: 0.05938
Policy Update Magnitude: 0.21660
Value Function Update Magnitude: 0.39258

Collected Steps per Second: 20,898.45120
Overall Steps per Second: 13,599.06170

Timestep Collection Time: 2.39300
Timestep Consumption Time: 1.28446
PPO Batch Consumption Time: 0.10480
Total Iteration Time: 3.67746

Cumulative Model Updates: 60,716
Cumulative Timesteps: 506,544,198

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,071.87569
Policy Entropy: 1.12389
Value Function Loss: 0.05667

Mean KL Divergence: 0.00576
SB3 Clip Fraction: 0.06846
Policy Update Magnitude: 0.21242
Value Function Update Magnitude: 0.37188

Collected Steps per Second: 22,088.89440
Overall Steps per Second: 14,292.15599

Timestep Collection Time: 2.26458
Timestep Consumption Time: 1.23538
PPO Batch Consumption Time: 0.09641
Total Iteration Time: 3.49996

Cumulative Model Updates: 60,722
Cumulative Timesteps: 506,594,220

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 506594220...
Checkpoint 506594220 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,123.77235
Policy Entropy: 1.12574
Value Function Loss: 0.06108

Mean KL Divergence: 0.00487
SB3 Clip Fraction: 0.05884
Policy Update Magnitude: 0.21150
Value Function Update Magnitude: 0.39298

Collected Steps per Second: 20,886.07479
Overall Steps per Second: 13,614.09822

Timestep Collection Time: 2.39423
Timestep Consumption Time: 1.27888
PPO Batch Consumption Time: 0.10536
Total Iteration Time: 3.67310

Cumulative Model Updates: 60,728
Cumulative Timesteps: 506,644,226

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,168.85468
Policy Entropy: 1.12456
Value Function Loss: 0.05524

Mean KL Divergence: 0.00516
SB3 Clip Fraction: 0.06077
Policy Update Magnitude: 0.21822
Value Function Update Magnitude: 0.42027

Collected Steps per Second: 20,499.08875
Overall Steps per Second: 13,569.88084

Timestep Collection Time: 2.44001
Timestep Consumption Time: 1.24595
PPO Batch Consumption Time: 0.10083
Total Iteration Time: 3.68596

Cumulative Model Updates: 60,734
Cumulative Timesteps: 506,694,244

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 506694244...
Checkpoint 506694244 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,151.63418
Policy Entropy: 1.14087
Value Function Loss: 0.05457

Mean KL Divergence: 0.00584
SB3 Clip Fraction: 0.06964
Policy Update Magnitude: 0.21406
Value Function Update Magnitude: 0.39825

Collected Steps per Second: 21,211.19440
Overall Steps per Second: 13,975.76740

Timestep Collection Time: 2.35772
Timestep Consumption Time: 1.22062
PPO Batch Consumption Time: 0.09426
Total Iteration Time: 3.57834

Cumulative Model Updates: 60,740
Cumulative Timesteps: 506,744,254

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,006.28021
Policy Entropy: 1.13032
Value Function Loss: 0.04957

Mean KL Divergence: 0.00499
SB3 Clip Fraction: 0.05846
Policy Update Magnitude: 0.20329
Value Function Update Magnitude: 0.39151

Collected Steps per Second: 22,014.91002
Overall Steps per Second: 14,239.67954

Timestep Collection Time: 2.27210
Timestep Consumption Time: 1.24062
PPO Batch Consumption Time: 0.10387
Total Iteration Time: 3.51272

Cumulative Model Updates: 60,746
Cumulative Timesteps: 506,794,274

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 506794274...
Checkpoint 506794274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,094.91066
Policy Entropy: 1.11685
Value Function Loss: 0.05897

Mean KL Divergence: 0.00505
SB3 Clip Fraction: 0.05972
Policy Update Magnitude: 0.21114
Value Function Update Magnitude: 0.40123

Collected Steps per Second: 21,532.44301
Overall Steps per Second: 14,046.88774

Timestep Collection Time: 2.32226
Timestep Consumption Time: 1.23753
PPO Batch Consumption Time: 0.10347
Total Iteration Time: 3.55979

Cumulative Model Updates: 60,752
Cumulative Timesteps: 506,844,278

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,200.55761
Policy Entropy: 1.12169
Value Function Loss: 0.05687

Mean KL Divergence: 0.00490
SB3 Clip Fraction: 0.05853
Policy Update Magnitude: 0.22702
Value Function Update Magnitude: 0.39876

Collected Steps per Second: 22,432.97278
Overall Steps per Second: 14,508.08266

Timestep Collection Time: 2.23038
Timestep Consumption Time: 1.21832
PPO Batch Consumption Time: 0.09981
Total Iteration Time: 3.44870

Cumulative Model Updates: 60,758
Cumulative Timesteps: 506,894,312

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 506894312...
Checkpoint 506894312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,121.98265
Policy Entropy: 1.11959
Value Function Loss: 0.05955

Mean KL Divergence: 0.00436
SB3 Clip Fraction: 0.05278
Policy Update Magnitude: 0.23255
Value Function Update Magnitude: 0.39415

Collected Steps per Second: 21,742.35711
Overall Steps per Second: 13,991.83303

Timestep Collection Time: 2.30012
Timestep Consumption Time: 1.27411
PPO Batch Consumption Time: 0.10726
Total Iteration Time: 3.57423

Cumulative Model Updates: 60,764
Cumulative Timesteps: 506,944,322

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46,587.75444
Policy Entropy: 1.12999
Value Function Loss: 0.05818

Mean KL Divergence: 0.00510
SB3 Clip Fraction: 0.06108
Policy Update Magnitude: 0.23275
Value Function Update Magnitude: 0.39518

Collected Steps per Second: 21,878.89969
Overall Steps per Second: 14,081.27766

Timestep Collection Time: 2.28768
Timestep Consumption Time: 1.26682
PPO Batch Consumption Time: 0.10924
Total Iteration Time: 3.55451

Cumulative Model Updates: 60,770
Cumulative Timesteps: 506,994,374

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


Saving checkpoint 506994374...
Checkpoint 506994374 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,379.14026
Policy Entropy: 1.13044
Value Function Loss: 0.05914

Mean KL Divergence: 0.00570
SB3 Clip Fraction: 0.06797
Policy Update Magnitude: 0.23465
Value Function Update Magnitude: 0.40668

Collected Steps per Second: 22,049.37180
Overall Steps per Second: 14,341.86405

Timestep Collection Time: 2.26927
Timestep Consumption Time: 1.21954
PPO Batch Consumption Time: 0.10226
Total Iteration Time: 3.48881

Cumulative Model Updates: 60,776
Cumulative Timesteps: 507,044,410

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,954.91938
Policy Entropy: 1.13345
Value Function Loss: 0.06647

Mean KL Divergence: 0.00581
SB3 Clip Fraction: 0.06788
Policy Update Magnitude: 0.23523
Value Function Update Magnitude: 0.39111

Collected Steps per Second: 22,076.89692
Overall Steps per Second: 14,298.16132

Timestep Collection Time: 2.26535
Timestep Consumption Time: 1.23244
PPO Batch Consumption Time: 0.09423
Total Iteration Time: 3.49779

Cumulative Model Updates: 60,782
Cumulative Timesteps: 507,094,422

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 507094422...
Checkpoint 507094422 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,495.53641
Policy Entropy: 1.13464
Value Function Loss: 0.05953

Mean KL Divergence: 0.00567
SB3 Clip Fraction: 0.06817
Policy Update Magnitude: 0.22333
Value Function Update Magnitude: 0.38903

Collected Steps per Second: 21,163.62809
Overall Steps per Second: 14,040.88220

Timestep Collection Time: 2.36368
Timestep Consumption Time: 1.19906
PPO Batch Consumption Time: 0.09651
Total Iteration Time: 3.56274

Cumulative Model Updates: 60,788
Cumulative Timesteps: 507,144,446

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,396.63148
Policy Entropy: 1.14243
Value Function Loss: 0.06214

Mean KL Divergence: 0.00659
SB3 Clip Fraction: 0.07656
Policy Update Magnitude: 0.21163
Value Function Update Magnitude: 0.38456

Collected Steps per Second: 22,274.46911
Overall Steps per Second: 14,254.43560

Timestep Collection Time: 2.24481
Timestep Consumption Time: 1.26301
PPO Batch Consumption Time: 0.10788
Total Iteration Time: 3.50782

Cumulative Model Updates: 60,794
Cumulative Timesteps: 507,194,448

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 507194448...
Checkpoint 507194448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,844.51342
Policy Entropy: 1.15768
Value Function Loss: 0.06439

Mean KL Divergence: 0.00655
SB3 Clip Fraction: 0.07521
Policy Update Magnitude: 0.21192
Value Function Update Magnitude: 0.36958

Collected Steps per Second: 19,794.39559
Overall Steps per Second: 13,357.36927

Timestep Collection Time: 2.52779
Timestep Consumption Time: 1.21816
PPO Batch Consumption Time: 0.09900
Total Iteration Time: 3.74595

Cumulative Model Updates: 60,800
Cumulative Timesteps: 507,244,484

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,152.06923
Policy Entropy: 1.14367
Value Function Loss: 0.07175

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.08920
Policy Update Magnitude: 0.21603
Value Function Update Magnitude: 0.40520

Collected Steps per Second: 21,486.83081
Overall Steps per Second: 14,294.35599

Timestep Collection Time: 2.32905
Timestep Consumption Time: 1.17191
PPO Batch Consumption Time: 0.09247
Total Iteration Time: 3.50096

Cumulative Model Updates: 60,806
Cumulative Timesteps: 507,294,528

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 507294528...
Checkpoint 507294528 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,278.71045
Policy Entropy: 1.15660
Value Function Loss: 0.07761

Mean KL Divergence: 0.00679
SB3 Clip Fraction: 0.07916
Policy Update Magnitude: 0.21927
Value Function Update Magnitude: 0.42699

Collected Steps per Second: 21,824.40660
Overall Steps per Second: 14,142.50709

Timestep Collection Time: 2.29184
Timestep Consumption Time: 1.24488
PPO Batch Consumption Time: 0.10427
Total Iteration Time: 3.53671

Cumulative Model Updates: 60,812
Cumulative Timesteps: 507,344,546

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,961.89162
Policy Entropy: 1.16810
Value Function Loss: 0.07131

Mean KL Divergence: 0.00691
SB3 Clip Fraction: 0.08017
Policy Update Magnitude: 0.22479
Value Function Update Magnitude: 0.43425

Collected Steps per Second: 21,678.46039
Overall Steps per Second: 14,084.02195

Timestep Collection Time: 2.30699
Timestep Consumption Time: 1.24398
PPO Batch Consumption Time: 0.10365
Total Iteration Time: 3.55097

Cumulative Model Updates: 60,818
Cumulative Timesteps: 507,394,558

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 507394558...
Checkpoint 507394558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,258.85413
Policy Entropy: 1.18829
Value Function Loss: 0.06566

Mean KL Divergence: 0.00546
SB3 Clip Fraction: 0.06412
Policy Update Magnitude: 0.22165
Value Function Update Magnitude: 0.42871

Collected Steps per Second: 22,014.64849
Overall Steps per Second: 14,117.43437

Timestep Collection Time: 2.27158
Timestep Consumption Time: 1.27071
PPO Batch Consumption Time: 0.10306
Total Iteration Time: 3.54229

Cumulative Model Updates: 60,824
Cumulative Timesteps: 507,444,566

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,136.35834
Policy Entropy: 1.19101
Value Function Loss: 0.06102

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.09313
Policy Update Magnitude: 0.19403
Value Function Update Magnitude: 0.41836

Collected Steps per Second: 22,316.36360
Overall Steps per Second: 14,430.45978

Timestep Collection Time: 2.24185
Timestep Consumption Time: 1.22512
PPO Batch Consumption Time: 0.10049
Total Iteration Time: 3.46697

Cumulative Model Updates: 60,830
Cumulative Timesteps: 507,494,596

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 507494596...
Checkpoint 507494596 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,331.02687
Policy Entropy: 1.18680
Value Function Loss: 0.05975

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.08502
Policy Update Magnitude: 0.17587
Value Function Update Magnitude: 0.39590

Collected Steps per Second: 20,972.32256
Overall Steps per Second: 13,920.16415

Timestep Collection Time: 2.38476
Timestep Consumption Time: 1.20816
PPO Batch Consumption Time: 0.09423
Total Iteration Time: 3.59292

Cumulative Model Updates: 60,836
Cumulative Timesteps: 507,544,610

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,030.42737
Policy Entropy: 1.18380
Value Function Loss: 0.06434

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.08081
Policy Update Magnitude: 0.17136
Value Function Update Magnitude: 0.39814

Collected Steps per Second: 22,270.01394
Overall Steps per Second: 14,097.07645

Timestep Collection Time: 2.24553
Timestep Consumption Time: 1.30187
PPO Batch Consumption Time: 0.11119
Total Iteration Time: 3.54740

Cumulative Model Updates: 60,842
Cumulative Timesteps: 507,594,618

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 507594618...
Checkpoint 507594618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,152.18933
Policy Entropy: 1.14660
Value Function Loss: 0.06871

Mean KL Divergence: 0.01082
SB3 Clip Fraction: 0.09333
Policy Update Magnitude: 0.16932
Value Function Update Magnitude: 0.41329

Collected Steps per Second: 20,477.89421
Overall Steps per Second: 13,632.78334

Timestep Collection Time: 2.44312
Timestep Consumption Time: 1.22671
PPO Batch Consumption Time: 0.09921
Total Iteration Time: 3.66983

Cumulative Model Updates: 60,848
Cumulative Timesteps: 507,644,648

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,835.79635
Policy Entropy: 1.15203
Value Function Loss: 0.07748

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.08093
Policy Update Magnitude: 0.19188
Value Function Update Magnitude: 0.42920

Collected Steps per Second: 21,585.69529
Overall Steps per Second: 13,869.29182

Timestep Collection Time: 2.31802
Timestep Consumption Time: 1.28967
PPO Batch Consumption Time: 0.09998
Total Iteration Time: 3.60768

Cumulative Model Updates: 60,854
Cumulative Timesteps: 507,694,684

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 507694684...
Checkpoint 507694684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,799.75156
Policy Entropy: 1.15930
Value Function Loss: 0.07005

Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.08403
Policy Update Magnitude: 0.20919
Value Function Update Magnitude: 0.44115

Collected Steps per Second: 21,719.77230
Overall Steps per Second: 14,303.79705

Timestep Collection Time: 2.30315
Timestep Consumption Time: 1.19410
PPO Batch Consumption Time: 0.09364
Total Iteration Time: 3.49725

Cumulative Model Updates: 60,860
Cumulative Timesteps: 507,744,708

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,374.49821
Policy Entropy: 1.17070
Value Function Loss: 0.06685

Mean KL Divergence: 0.01093
SB3 Clip Fraction: 0.10162
Policy Update Magnitude: 0.19139
Value Function Update Magnitude: 0.43922

Collected Steps per Second: 21,771.71675
Overall Steps per Second: 14,077.96861

Timestep Collection Time: 2.29784
Timestep Consumption Time: 1.25579
PPO Batch Consumption Time: 0.10058
Total Iteration Time: 3.55364

Cumulative Model Updates: 60,866
Cumulative Timesteps: 507,794,736

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 507794736...
Checkpoint 507794736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,960.38099
Policy Entropy: 1.17843
Value Function Loss: 0.06481

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.10128
Policy Update Magnitude: 0.17895
Value Function Update Magnitude: 0.42302

Collected Steps per Second: 21,352.86649
Overall Steps per Second: 14,022.12224

Timestep Collection Time: 2.34236
Timestep Consumption Time: 1.22458
PPO Batch Consumption Time: 0.09951
Total Iteration Time: 3.56694

Cumulative Model Updates: 60,872
Cumulative Timesteps: 507,844,752

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,574.25792
Policy Entropy: 1.16097
Value Function Loss: 0.07157

Mean KL Divergence: 0.01404
SB3 Clip Fraction: 0.12691
Policy Update Magnitude: 0.18932
Value Function Update Magnitude: 0.41297

Collected Steps per Second: 22,212.45210
Overall Steps per Second: 14,610.82042

Timestep Collection Time: 2.25108
Timestep Consumption Time: 1.17118
PPO Batch Consumption Time: 0.09211
Total Iteration Time: 3.42226

Cumulative Model Updates: 60,878
Cumulative Timesteps: 507,894,754

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 507894754...
Checkpoint 507894754 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,421.58641
Policy Entropy: 1.17285
Value Function Loss: 0.07285

Mean KL Divergence: 0.01059
SB3 Clip Fraction: 0.10973
Policy Update Magnitude: 0.20086
Value Function Update Magnitude: 0.39434

Collected Steps per Second: 21,543.33034
Overall Steps per Second: 14,079.32428

Timestep Collection Time: 2.32109
Timestep Consumption Time: 1.23050
PPO Batch Consumption Time: 0.10127
Total Iteration Time: 3.55159

Cumulative Model Updates: 60,884
Cumulative Timesteps: 507,944,758

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,511.88440
Policy Entropy: 1.16165
Value Function Loss: 0.07049

Mean KL Divergence: 0.00677
SB3 Clip Fraction: 0.07793
Policy Update Magnitude: 0.21461
Value Function Update Magnitude: 0.38990

Collected Steps per Second: 22,063.78263
Overall Steps per Second: 14,264.75848

Timestep Collection Time: 2.26752
Timestep Consumption Time: 1.23973
PPO Batch Consumption Time: 0.10293
Total Iteration Time: 3.50724

Cumulative Model Updates: 60,890
Cumulative Timesteps: 507,994,788

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 507994788...
Checkpoint 507994788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,440.15184
Policy Entropy: 1.16485
Value Function Loss: 0.07532

Mean KL Divergence: 0.00583
SB3 Clip Fraction: 0.06871
Policy Update Magnitude: 0.21782
Value Function Update Magnitude: 0.35666

Collected Steps per Second: 21,077.36952
Overall Steps per Second: 13,855.05127

Timestep Collection Time: 2.37326
Timestep Consumption Time: 1.23712
PPO Batch Consumption Time: 0.10188
Total Iteration Time: 3.61038

Cumulative Model Updates: 60,896
Cumulative Timesteps: 508,044,810

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,860.89298
Policy Entropy: 1.15690
Value Function Loss: 0.07538

Mean KL Divergence: 0.00463
SB3 Clip Fraction: 0.05483
Policy Update Magnitude: 0.22128
Value Function Update Magnitude: 0.35537

Collected Steps per Second: 21,647.65185
Overall Steps per Second: 13,944.00914

Timestep Collection Time: 2.31000
Timestep Consumption Time: 1.27620
PPO Batch Consumption Time: 0.10647
Total Iteration Time: 3.58620

Cumulative Model Updates: 60,902
Cumulative Timesteps: 508,094,816

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 508094816...
Checkpoint 508094816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,344.45267
Policy Entropy: 1.15424
Value Function Loss: 0.06937

Mean KL Divergence: 0.00478
SB3 Clip Fraction: 0.05724
Policy Update Magnitude: 0.22538
Value Function Update Magnitude: 0.36605

Collected Steps per Second: 22,189.57194
Overall Steps per Second: 14,179.90251

Timestep Collection Time: 2.25385
Timestep Consumption Time: 1.27311
PPO Batch Consumption Time: 0.10344
Total Iteration Time: 3.52696

Cumulative Model Updates: 60,908
Cumulative Timesteps: 508,144,828

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,560.92966
Policy Entropy: 1.15624
Value Function Loss: 0.07485

Mean KL Divergence: 0.00627
SB3 Clip Fraction: 0.07067
Policy Update Magnitude: 0.22376
Value Function Update Magnitude: 0.37379

Collected Steps per Second: 22,392.37441
Overall Steps per Second: 14,318.46143

Timestep Collection Time: 2.23290
Timestep Consumption Time: 1.25909
PPO Batch Consumption Time: 0.09751
Total Iteration Time: 3.49200

Cumulative Model Updates: 60,914
Cumulative Timesteps: 508,194,828

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 508194828...
Checkpoint 508194828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,137.27789
Policy Entropy: 1.16350
Value Function Loss: 0.07556

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.08722
Policy Update Magnitude: 0.21387
Value Function Update Magnitude: 0.34900

Collected Steps per Second: 21,922.91816
Overall Steps per Second: 14,187.41886

Timestep Collection Time: 2.28081
Timestep Consumption Time: 1.24358
PPO Batch Consumption Time: 0.10570
Total Iteration Time: 3.52439

Cumulative Model Updates: 60,920
Cumulative Timesteps: 508,244,830

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,009.58096
Policy Entropy: 1.16994
Value Function Loss: 0.07679

Mean KL Divergence: 0.01221
SB3 Clip Fraction: 0.11628
Policy Update Magnitude: 0.19991
Value Function Update Magnitude: 0.36671

Collected Steps per Second: 22,055.99736
Overall Steps per Second: 14,149.42037

Timestep Collection Time: 2.26741
Timestep Consumption Time: 1.26701
PPO Batch Consumption Time: 0.10264
Total Iteration Time: 3.53442

Cumulative Model Updates: 60,926
Cumulative Timesteps: 508,294,840

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 508294840...
Checkpoint 508294840 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,171.54702
Policy Entropy: 1.17849
Value Function Loss: 0.07734

Mean KL Divergence: 0.01110
SB3 Clip Fraction: 0.10586
Policy Update Magnitude: 0.18639
Value Function Update Magnitude: 0.39384

Collected Steps per Second: 22,191.61123
Overall Steps per Second: 14,435.06971

Timestep Collection Time: 2.25446
Timestep Consumption Time: 1.21141
PPO Batch Consumption Time: 0.09672
Total Iteration Time: 3.46586

Cumulative Model Updates: 60,932
Cumulative Timesteps: 508,344,870

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,555.67077
Policy Entropy: 1.16298
Value Function Loss: 0.07493

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.09222
Policy Update Magnitude: 0.19170
Value Function Update Magnitude: 0.39776

Collected Steps per Second: 21,670.62000
Overall Steps per Second: 14,040.88354

Timestep Collection Time: 2.30847
Timestep Consumption Time: 1.25441
PPO Batch Consumption Time: 0.10363
Total Iteration Time: 3.56288

Cumulative Model Updates: 60,938
Cumulative Timesteps: 508,394,896

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 508394896...
Checkpoint 508394896 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,691.27193
Policy Entropy: 1.17118
Value Function Loss: 0.07139

Mean KL Divergence: 0.00712
SB3 Clip Fraction: 0.07360
Policy Update Magnitude: 0.20333
Value Function Update Magnitude: 0.35773

Collected Steps per Second: 21,944.11798
Overall Steps per Second: 14,089.90437

Timestep Collection Time: 2.28006
Timestep Consumption Time: 1.27099
PPO Batch Consumption Time: 0.10557
Total Iteration Time: 3.55105

Cumulative Model Updates: 60,944
Cumulative Timesteps: 508,444,930

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,851.48574
Policy Entropy: 1.16120
Value Function Loss: 0.06127

Mean KL Divergence: 0.00637
SB3 Clip Fraction: 0.07104
Policy Update Magnitude: 0.20663
Value Function Update Magnitude: 0.38642

Collected Steps per Second: 22,332.57224
Overall Steps per Second: 14,173.04015

Timestep Collection Time: 2.23942
Timestep Consumption Time: 1.28925
PPO Batch Consumption Time: 0.10381
Total Iteration Time: 3.52867

Cumulative Model Updates: 60,950
Cumulative Timesteps: 508,494,942

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 508494942...
Checkpoint 508494942 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,336.49861
Policy Entropy: 1.16628
Value Function Loss: 0.05906

Mean KL Divergence: 0.00502
SB3 Clip Fraction: 0.06011
Policy Update Magnitude: 0.20765
Value Function Update Magnitude: 0.39948

Collected Steps per Second: 21,095.22512
Overall Steps per Second: 13,716.78653

Timestep Collection Time: 2.37115
Timestep Consumption Time: 1.27547
PPO Batch Consumption Time: 0.10240
Total Iteration Time: 3.64663

Cumulative Model Updates: 60,956
Cumulative Timesteps: 508,544,962

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,671.36553
Policy Entropy: 1.16629
Value Function Loss: 0.05753

Mean KL Divergence: 0.00484
SB3 Clip Fraction: 0.05901
Policy Update Magnitude: 0.21051
Value Function Update Magnitude: 0.40206

Collected Steps per Second: 22,412.61752
Overall Steps per Second: 14,299.48080

Timestep Collection Time: 2.23205
Timestep Consumption Time: 1.26640
PPO Batch Consumption Time: 0.10197
Total Iteration Time: 3.49845

Cumulative Model Updates: 60,962
Cumulative Timesteps: 508,594,988

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 508594988...
Checkpoint 508594988 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,980.11764
Policy Entropy: 1.16640
Value Function Loss: 0.05785

Mean KL Divergence: 0.00445
SB3 Clip Fraction: 0.05376
Policy Update Magnitude: 0.20470
Value Function Update Magnitude: 0.39815

Collected Steps per Second: 19,180.89217
Overall Steps per Second: 12,893.40969

Timestep Collection Time: 2.60822
Timestep Consumption Time: 1.27190
PPO Batch Consumption Time: 0.10093
Total Iteration Time: 3.88012

Cumulative Model Updates: 60,968
Cumulative Timesteps: 508,645,016

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,360.27528
Policy Entropy: 1.16977
Value Function Loss: 0.06518

Mean KL Divergence: 0.00397
SB3 Clip Fraction: 0.04732
Policy Update Magnitude: 0.21364
Value Function Update Magnitude: 0.39753

Collected Steps per Second: 21,911.08964
Overall Steps per Second: 14,183.49337

Timestep Collection Time: 2.28277
Timestep Consumption Time: 1.24372
PPO Batch Consumption Time: 0.10393
Total Iteration Time: 3.52649

Cumulative Model Updates: 60,974
Cumulative Timesteps: 508,695,034

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 508695034...
Checkpoint 508695034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,708.09496
Policy Entropy: 1.18075
Value Function Loss: 0.06552

Mean KL Divergence: 0.00409
SB3 Clip Fraction: 0.04775
Policy Update Magnitude: 0.22971
Value Function Update Magnitude: 0.42450

Collected Steps per Second: 21,819.19989
Overall Steps per Second: 14,040.46116

Timestep Collection Time: 2.29238
Timestep Consumption Time: 1.27003
PPO Batch Consumption Time: 0.10600
Total Iteration Time: 3.56242

Cumulative Model Updates: 60,980
Cumulative Timesteps: 508,745,052

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,853.24334
Policy Entropy: 1.18435
Value Function Loss: 0.06533

Mean KL Divergence: 0.00380
SB3 Clip Fraction: 0.04489
Policy Update Magnitude: 0.23409
Value Function Update Magnitude: 0.44644

Collected Steps per Second: 21,244.37078
Overall Steps per Second: 13,630.70537

Timestep Collection Time: 2.35479
Timestep Consumption Time: 1.31531
PPO Batch Consumption Time: 0.11013
Total Iteration Time: 3.67010

Cumulative Model Updates: 60,986
Cumulative Timesteps: 508,795,078

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 508795078...
Checkpoint 508795078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,289.85744
Policy Entropy: 1.17212
Value Function Loss: 0.05736

Mean KL Divergence: 0.00445
SB3 Clip Fraction: 0.05424
Policy Update Magnitude: 0.22687
Value Function Update Magnitude: 0.44233

Collected Steps per Second: 20,653.69344
Overall Steps per Second: 13,492.00435

Timestep Collection Time: 2.42223
Timestep Consumption Time: 1.28574
PPO Batch Consumption Time: 0.10324
Total Iteration Time: 3.70797

Cumulative Model Updates: 60,992
Cumulative Timesteps: 508,845,106

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,962.96343
Policy Entropy: 1.15227
Value Function Loss: 0.05757

Mean KL Divergence: 0.00431
SB3 Clip Fraction: 0.05211
Policy Update Magnitude: 0.22821
Value Function Update Magnitude: 0.41823

Collected Steps per Second: 21,972.48706
Overall Steps per Second: 13,985.48549

Timestep Collection Time: 2.27566
Timestep Consumption Time: 1.29961
PPO Batch Consumption Time: 0.10459
Total Iteration Time: 3.57528

Cumulative Model Updates: 60,998
Cumulative Timesteps: 508,895,108

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 508895108...
Checkpoint 508895108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,654.52252
Policy Entropy: 1.16883
Value Function Loss: 0.05903

Mean KL Divergence: 0.00483
SB3 Clip Fraction: 0.05859
Policy Update Magnitude: 0.22683
Value Function Update Magnitude: 0.39437

Collected Steps per Second: 17,874.72660
Overall Steps per Second: 12,246.34217

Timestep Collection Time: 2.79814
Timestep Consumption Time: 1.28602
PPO Batch Consumption Time: 0.10634
Total Iteration Time: 4.08416

Cumulative Model Updates: 61,004
Cumulative Timesteps: 508,945,124

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,139.38354
Policy Entropy: 1.17264
Value Function Loss: 0.06246

Mean KL Divergence: 0.00518
SB3 Clip Fraction: 0.06193
Policy Update Magnitude: 0.21845
Value Function Update Magnitude: 0.38643

Collected Steps per Second: 20,674.49293
Overall Steps per Second: 13,315.40730

Timestep Collection Time: 2.41921
Timestep Consumption Time: 1.33704
PPO Batch Consumption Time: 0.11096
Total Iteration Time: 3.75625

Cumulative Model Updates: 61,010
Cumulative Timesteps: 508,995,140

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 508995140...
Checkpoint 508995140 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,996.96690
Policy Entropy: 1.17924
Value Function Loss: 0.06685

Mean KL Divergence: 0.00535
SB3 Clip Fraction: 0.06455
Policy Update Magnitude: 0.22023
Value Function Update Magnitude: 0.42013

Collected Steps per Second: 18,899.68264
Overall Steps per Second: 12,912.64528

Timestep Collection Time: 2.64618
Timestep Consumption Time: 1.22692
PPO Batch Consumption Time: 0.09568
Total Iteration Time: 3.87310

Cumulative Model Updates: 61,016
Cumulative Timesteps: 509,045,152

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,827.80268
Policy Entropy: 1.17900
Value Function Loss: 0.07338

Mean KL Divergence: 0.00482
SB3 Clip Fraction: 0.05820
Policy Update Magnitude: 0.23072
Value Function Update Magnitude: 0.43381

Collected Steps per Second: 19,659.70765
Overall Steps per Second: 13,371.90434

Timestep Collection Time: 2.54388
Timestep Consumption Time: 1.19620
PPO Batch Consumption Time: 0.09937
Total Iteration Time: 3.74008

Cumulative Model Updates: 61,022
Cumulative Timesteps: 509,095,164

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 509095164...
Checkpoint 509095164 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,791.27301
Policy Entropy: 1.18079
Value Function Loss: 0.07009

Mean KL Divergence: 0.00470
SB3 Clip Fraction: 0.05511
Policy Update Magnitude: 0.22711
Value Function Update Magnitude: 0.45887

Collected Steps per Second: 21,855.70942
Overall Steps per Second: 14,116.01317

Timestep Collection Time: 2.28938
Timestep Consumption Time: 1.25525
PPO Batch Consumption Time: 0.10178
Total Iteration Time: 3.54463

Cumulative Model Updates: 61,028
Cumulative Timesteps: 509,145,200

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,604.45212
Policy Entropy: 1.20239
Value Function Loss: 0.06735

Mean KL Divergence: 0.00375
SB3 Clip Fraction: 0.04255
Policy Update Magnitude: 0.22769
Value Function Update Magnitude: 0.47546

Collected Steps per Second: 21,844.69445
Overall Steps per Second: 14,172.80401

Timestep Collection Time: 2.28889
Timestep Consumption Time: 1.23900
PPO Batch Consumption Time: 0.09981
Total Iteration Time: 3.52788

Cumulative Model Updates: 61,034
Cumulative Timesteps: 509,195,200

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 509195200...
Checkpoint 509195200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,809.42092
Policy Entropy: 1.20723
Value Function Loss: 0.06599

Mean KL Divergence: 0.00422
SB3 Clip Fraction: 0.05050
Policy Update Magnitude: 0.21918
Value Function Update Magnitude: 0.44993

Collected Steps per Second: 22,020.57508
Overall Steps per Second: 14,098.62885

Timestep Collection Time: 2.27160
Timestep Consumption Time: 1.27640
PPO Batch Consumption Time: 0.10416
Total Iteration Time: 3.54800

Cumulative Model Updates: 61,040
Cumulative Timesteps: 509,245,222

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,078.62741
Policy Entropy: 1.20329
Value Function Loss: 0.07369

Mean KL Divergence: 0.00521
SB3 Clip Fraction: 0.06191
Policy Update Magnitude: 0.21425
Value Function Update Magnitude: 0.43719

Collected Steps per Second: 22,457.25356
Overall Steps per Second: 14,260.17131

Timestep Collection Time: 2.22779
Timestep Consumption Time: 1.28058
PPO Batch Consumption Time: 0.10315
Total Iteration Time: 3.50837

Cumulative Model Updates: 61,046
Cumulative Timesteps: 509,295,252

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 509295252...
Checkpoint 509295252 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,638.76833
Policy Entropy: 1.19845
Value Function Loss: 0.07336

Mean KL Divergence: 0.00445
SB3 Clip Fraction: 0.05384
Policy Update Magnitude: 0.21491
Value Function Update Magnitude: 0.44173

Collected Steps per Second: 20,739.32143
Overall Steps per Second: 13,588.57232

Timestep Collection Time: 2.41098
Timestep Consumption Time: 1.26873
PPO Batch Consumption Time: 0.09787
Total Iteration Time: 3.67971

Cumulative Model Updates: 61,052
Cumulative Timesteps: 509,345,254

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,468.17721
Policy Entropy: 1.18122
Value Function Loss: 0.06783

Mean KL Divergence: 0.00447
SB3 Clip Fraction: 0.05331
Policy Update Magnitude: 0.21612
Value Function Update Magnitude: 0.43722

Collected Steps per Second: 22,157.30241
Overall Steps per Second: 14,324.46840

Timestep Collection Time: 2.25731
Timestep Consumption Time: 1.23433
PPO Batch Consumption Time: 0.10324
Total Iteration Time: 3.49165

Cumulative Model Updates: 61,058
Cumulative Timesteps: 509,395,270

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 509395270...
Checkpoint 509395270 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,373.35756
Policy Entropy: 1.18318
Value Function Loss: 0.06401

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.10188
Policy Update Magnitude: 0.20238
Value Function Update Magnitude: 0.41810

Collected Steps per Second: 19,256.11659
Overall Steps per Second: 12,840.35788

Timestep Collection Time: 2.59699
Timestep Consumption Time: 1.29760
PPO Batch Consumption Time: 0.10872
Total Iteration Time: 3.89460

Cumulative Model Updates: 61,064
Cumulative Timesteps: 509,445,278

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,163.36884
Policy Entropy: 1.18224
Value Function Loss: 0.06700

Mean KL Divergence: 0.01156
SB3 Clip Fraction: 0.10571
Policy Update Magnitude: 0.17704
Value Function Update Magnitude: 0.42005

Collected Steps per Second: 20,243.28672
Overall Steps per Second: 13,517.65378

Timestep Collection Time: 2.47223
Timestep Consumption Time: 1.23004
PPO Batch Consumption Time: 0.10162
Total Iteration Time: 3.70227

Cumulative Model Updates: 61,070
Cumulative Timesteps: 509,495,324

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 509495324...
Checkpoint 509495324 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,022.15642
Policy Entropy: 1.18525
Value Function Loss: 0.06834

Mean KL Divergence: 0.01099
SB3 Clip Fraction: 0.09352
Policy Update Magnitude: 0.17801
Value Function Update Magnitude: 0.43851

Collected Steps per Second: 21,885.73345
Overall Steps per Second: 14,117.07175

Timestep Collection Time: 2.28459
Timestep Consumption Time: 1.25722
PPO Batch Consumption Time: 0.10448
Total Iteration Time: 3.54181

Cumulative Model Updates: 61,076
Cumulative Timesteps: 509,545,324

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,429.65048
Policy Entropy: 1.19124
Value Function Loss: 0.06591

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.08856
Policy Update Magnitude: 0.18620
Value Function Update Magnitude: 0.45709

Collected Steps per Second: 18,311.07786
Overall Steps per Second: 12,441.38759

Timestep Collection Time: 2.73113
Timestep Consumption Time: 1.28851
PPO Batch Consumption Time: 0.10273
Total Iteration Time: 4.01965

Cumulative Model Updates: 61,082
Cumulative Timesteps: 509,595,334

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 509595334...
Checkpoint 509595334 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,393.94961
Policy Entropy: 1.18853
Value Function Loss: 0.06335

Mean KL Divergence: 0.00752
SB3 Clip Fraction: 0.08149
Policy Update Magnitude: 0.20675
Value Function Update Magnitude: 0.45615

Collected Steps per Second: 21,608.41931
Overall Steps per Second: 13,781.49278

Timestep Collection Time: 2.31475
Timestep Consumption Time: 1.31461
PPO Batch Consumption Time: 0.11596
Total Iteration Time: 3.62936

Cumulative Model Updates: 61,088
Cumulative Timesteps: 509,645,352

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,333.90342
Policy Entropy: 1.18694
Value Function Loss: 0.06229

Mean KL Divergence: 0.00604
SB3 Clip Fraction: 0.06847
Policy Update Magnitude: 0.21185
Value Function Update Magnitude: 0.46067

Collected Steps per Second: 20,169.44267
Overall Steps per Second: 13,270.48980

Timestep Collection Time: 2.48049
Timestep Consumption Time: 1.28953
PPO Batch Consumption Time: 0.10508
Total Iteration Time: 3.77002

Cumulative Model Updates: 61,094
Cumulative Timesteps: 509,695,382

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 509695382...
Checkpoint 509695382 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,407.49321
Policy Entropy: 1.16906
Value Function Loss: 0.06890

Mean KL Divergence: 0.00530
SB3 Clip Fraction: 0.06257
Policy Update Magnitude: 0.21671
Value Function Update Magnitude: 0.43922

Collected Steps per Second: 19,473.34549
Overall Steps per Second: 12,858.15653

Timestep Collection Time: 2.56926
Timestep Consumption Time: 1.32182
PPO Batch Consumption Time: 0.10758
Total Iteration Time: 3.89107

Cumulative Model Updates: 61,100
Cumulative Timesteps: 509,745,414

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,212.16810
Policy Entropy: 1.17876
Value Function Loss: 0.06875

Mean KL Divergence: 0.00628
SB3 Clip Fraction: 0.07056
Policy Update Magnitude: 0.21450
Value Function Update Magnitude: 0.43615

Collected Steps per Second: 21,555.30806
Overall Steps per Second: 13,934.46230

Timestep Collection Time: 2.32119
Timestep Consumption Time: 1.26947
PPO Batch Consumption Time: 0.10288
Total Iteration Time: 3.59067

Cumulative Model Updates: 61,106
Cumulative Timesteps: 509,795,448

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 509795448...
Checkpoint 509795448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,381.93672
Policy Entropy: 1.17985
Value Function Loss: 0.07151

Mean KL Divergence: 0.00502
SB3 Clip Fraction: 0.05878
Policy Update Magnitude: 0.21738
Value Function Update Magnitude: 0.43448

Collected Steps per Second: 22,256.08041
Overall Steps per Second: 14,173.38502

Timestep Collection Time: 2.24676
Timestep Consumption Time: 1.28126
PPO Batch Consumption Time: 0.10293
Total Iteration Time: 3.52802

Cumulative Model Updates: 61,112
Cumulative Timesteps: 509,845,452

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,045.85148
Policy Entropy: 1.18630
Value Function Loss: 0.06681

Mean KL Divergence: 0.00525
SB3 Clip Fraction: 0.06186
Policy Update Magnitude: 0.21910
Value Function Update Magnitude: 0.46112

Collected Steps per Second: 22,213.16583
Overall Steps per Second: 14,401.68706

Timestep Collection Time: 2.25182
Timestep Consumption Time: 1.22139
PPO Batch Consumption Time: 0.09991
Total Iteration Time: 3.47320

Cumulative Model Updates: 61,118
Cumulative Timesteps: 509,895,472

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 509895472...
Checkpoint 509895472 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,402.07658
Policy Entropy: 1.19751
Value Function Loss: 0.06834

Mean KL Divergence: 0.00617
SB3 Clip Fraction: 0.07077
Policy Update Magnitude: 0.21222
Value Function Update Magnitude: 0.45473

Collected Steps per Second: 22,730.88343
Overall Steps per Second: 14,705.93424

Timestep Collection Time: 2.20053
Timestep Consumption Time: 1.20082
PPO Batch Consumption Time: 0.09262
Total Iteration Time: 3.40135

Cumulative Model Updates: 61,124
Cumulative Timesteps: 509,945,492

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,697.84637
Policy Entropy: 1.19685
Value Function Loss: 0.07259

Mean KL Divergence: 0.00447
SB3 Clip Fraction: 0.05410
Policy Update Magnitude: 0.20966
Value Function Update Magnitude: 0.43784

Collected Steps per Second: 22,209.17947
Overall Steps per Second: 14,183.52136

Timestep Collection Time: 2.25276
Timestep Consumption Time: 1.27471
PPO Batch Consumption Time: 0.10324
Total Iteration Time: 3.52747

Cumulative Model Updates: 61,130
Cumulative Timesteps: 509,995,524

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 509995524...
Checkpoint 509995524 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,855.04989
Policy Entropy: 1.21816
Value Function Loss: 0.07120

Mean KL Divergence: 0.00552
SB3 Clip Fraction: 0.06568
Policy Update Magnitude: 0.21181
Value Function Update Magnitude: 0.44532

Collected Steps per Second: 22,485.41072
Overall Steps per Second: 14,638.94514

Timestep Collection Time: 2.22429
Timestep Consumption Time: 1.19222
PPO Batch Consumption Time: 0.09563
Total Iteration Time: 3.41650

Cumulative Model Updates: 61,136
Cumulative Timesteps: 510,045,538

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,491.00098
Policy Entropy: 1.21561
Value Function Loss: 0.06720

Mean KL Divergence: 0.01091
SB3 Clip Fraction: 0.10370
Policy Update Magnitude: 0.18923
Value Function Update Magnitude: 0.44184

Collected Steps per Second: 22,989.92368
Overall Steps per Second: 14,799.95021

Timestep Collection Time: 2.17574
Timestep Consumption Time: 1.20401
PPO Batch Consumption Time: 0.09816
Total Iteration Time: 3.37974

Cumulative Model Updates: 61,142
Cumulative Timesteps: 510,095,558

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 510095558...
Checkpoint 510095558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,972.59166
Policy Entropy: 1.21924
Value Function Loss: 0.06594

Mean KL Divergence: 0.02415
SB3 Clip Fraction: 0.14764
Policy Update Magnitude: 0.16353
Value Function Update Magnitude: 0.41823

Collected Steps per Second: 22,570.31767
Overall Steps per Second: 14,774.93132

Timestep Collection Time: 2.21601
Timestep Consumption Time: 1.16919
PPO Batch Consumption Time: 0.09532
Total Iteration Time: 3.38519

Cumulative Model Updates: 61,148
Cumulative Timesteps: 510,145,574

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,326.94614
Policy Entropy: 1.18476
Value Function Loss: 0.06327

Mean KL Divergence: 0.01103
SB3 Clip Fraction: 0.09876
Policy Update Magnitude: 0.19255
Value Function Update Magnitude: 0.37714

Collected Steps per Second: 22,732.28583
Overall Steps per Second: 14,757.75475

Timestep Collection Time: 2.19969
Timestep Consumption Time: 1.18863
PPO Batch Consumption Time: 0.09507
Total Iteration Time: 3.38832

Cumulative Model Updates: 61,154
Cumulative Timesteps: 510,195,578

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 510195578...
Checkpoint 510195578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,746.38655
Policy Entropy: 1.17323
Value Function Loss: 0.07128

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.09505
Policy Update Magnitude: 0.19786
Value Function Update Magnitude: 0.35566

Collected Steps per Second: 22,750.59517
Overall Steps per Second: 14,826.83929

Timestep Collection Time: 2.19862
Timestep Consumption Time: 1.17499
PPO Batch Consumption Time: 0.09303
Total Iteration Time: 3.37361

Cumulative Model Updates: 61,160
Cumulative Timesteps: 510,245,598

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,120.09196
Policy Entropy: 1.16971
Value Function Loss: 0.07062

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.09606
Policy Update Magnitude: 0.18367
Value Function Update Magnitude: 0.40991

Collected Steps per Second: 22,793.48399
Overall Steps per Second: 14,764.62257

Timestep Collection Time: 2.19466
Timestep Consumption Time: 1.19344
PPO Batch Consumption Time: 0.09394
Total Iteration Time: 3.38810

Cumulative Model Updates: 61,166
Cumulative Timesteps: 510,295,622

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 510295622...
Checkpoint 510295622 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,451.79977
Policy Entropy: 1.17868
Value Function Loss: 0.07260

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.08591
Policy Update Magnitude: 0.20010
Value Function Update Magnitude: 0.44346

Collected Steps per Second: 21,902.21925
Overall Steps per Second: 14,195.16839

Timestep Collection Time: 2.28479
Timestep Consumption Time: 1.24049
PPO Batch Consumption Time: 0.10398
Total Iteration Time: 3.52528

Cumulative Model Updates: 61,172
Cumulative Timesteps: 510,345,664

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,359.25026
Policy Entropy: 1.16955
Value Function Loss: 0.06931

Mean KL Divergence: 0.00688
SB3 Clip Fraction: 0.07217
Policy Update Magnitude: 0.21335
Value Function Update Magnitude: 0.45343

Collected Steps per Second: 22,972.63298
Overall Steps per Second: 14,695.21533

Timestep Collection Time: 2.17694
Timestep Consumption Time: 1.22621
PPO Batch Consumption Time: 0.10166
Total Iteration Time: 3.40315

Cumulative Model Updates: 61,178
Cumulative Timesteps: 510,395,674

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 510395674...
Checkpoint 510395674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,689.86129
Policy Entropy: 1.16152
Value Function Loss: 0.06753

Mean KL Divergence: 0.00426
SB3 Clip Fraction: 0.05053
Policy Update Magnitude: 0.21322
Value Function Update Magnitude: 0.45154

Collected Steps per Second: 22,542.24587
Overall Steps per Second: 14,572.34694

Timestep Collection Time: 2.21921
Timestep Consumption Time: 1.21373
PPO Batch Consumption Time: 0.09850
Total Iteration Time: 3.43294

Cumulative Model Updates: 61,184
Cumulative Timesteps: 510,445,700

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,031.05163
Policy Entropy: 1.14871
Value Function Loss: 0.06906

Mean KL Divergence: 0.00556
SB3 Clip Fraction: 0.06101
Policy Update Magnitude: 0.20716
Value Function Update Magnitude: 0.44226

Collected Steps per Second: 22,296.58079
Overall Steps per Second: 14,334.32641

Timestep Collection Time: 2.24456
Timestep Consumption Time: 1.24678
PPO Batch Consumption Time: 0.10604
Total Iteration Time: 3.49134

Cumulative Model Updates: 61,190
Cumulative Timesteps: 510,495,746

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 510495746...
Checkpoint 510495746 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,712.54351
Policy Entropy: 1.14924
Value Function Loss: 0.07218

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.09169
Policy Update Magnitude: 0.19217
Value Function Update Magnitude: 0.43012

Collected Steps per Second: 22,634.58993
Overall Steps per Second: 14,660.60704

Timestep Collection Time: 2.21131
Timestep Consumption Time: 1.20274
PPO Batch Consumption Time: 0.09885
Total Iteration Time: 3.41405

Cumulative Model Updates: 61,196
Cumulative Timesteps: 510,545,798

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,789.45102
Policy Entropy: 1.15745
Value Function Loss: 0.07273

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.08147
Policy Update Magnitude: 0.18954
Value Function Update Magnitude: 0.41457

Collected Steps per Second: 22,849.65683
Overall Steps per Second: 14,747.54989

Timestep Collection Time: 2.18830
Timestep Consumption Time: 1.20223
PPO Batch Consumption Time: 0.09920
Total Iteration Time: 3.39053

Cumulative Model Updates: 61,202
Cumulative Timesteps: 510,595,800

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 510595800...
Checkpoint 510595800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,451.85733
Policy Entropy: 1.19278
Value Function Loss: 0.06990

Mean KL Divergence: 0.01071
SB3 Clip Fraction: 0.10052
Policy Update Magnitude: 0.19731
Value Function Update Magnitude: 0.39903

Collected Steps per Second: 22,516.07173
Overall Steps per Second: 14,226.00637

Timestep Collection Time: 2.22090
Timestep Consumption Time: 1.29421
PPO Batch Consumption Time: 0.10221
Total Iteration Time: 3.51511

Cumulative Model Updates: 61,208
Cumulative Timesteps: 510,645,806

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,027.42598
Policy Entropy: 1.18936
Value Function Loss: 0.06584

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.08340
Policy Update Magnitude: 0.21154
Value Function Update Magnitude: 0.42154

Collected Steps per Second: 22,910.84693
Overall Steps per Second: 14,701.80433

Timestep Collection Time: 2.18237
Timestep Consumption Time: 1.21857
PPO Batch Consumption Time: 0.10256
Total Iteration Time: 3.40094

Cumulative Model Updates: 61,214
Cumulative Timesteps: 510,695,806

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 510695806...
Checkpoint 510695806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,375.05515
Policy Entropy: 1.18810
Value Function Loss: 0.06660

Mean KL Divergence: 0.00721
SB3 Clip Fraction: 0.07815
Policy Update Magnitude: 0.22487
Value Function Update Magnitude: 0.42458

Collected Steps per Second: 22,809.28509
Overall Steps per Second: 14,606.89356

Timestep Collection Time: 2.19288
Timestep Consumption Time: 1.23139
PPO Batch Consumption Time: 0.09792
Total Iteration Time: 3.42427

Cumulative Model Updates: 61,220
Cumulative Timesteps: 510,745,824

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,215.68826
Policy Entropy: 1.16700
Value Function Loss: 0.06231

Mean KL Divergence: 0.00568
SB3 Clip Fraction: 0.06582
Policy Update Magnitude: 0.21894
Value Function Update Magnitude: 0.42445

Collected Steps per Second: 22,985.35576
Overall Steps per Second: 14,770.46429

Timestep Collection Time: 2.17626
Timestep Consumption Time: 1.21037
PPO Batch Consumption Time: 0.09937
Total Iteration Time: 3.38662

Cumulative Model Updates: 61,226
Cumulative Timesteps: 510,795,846

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 510795846...
Checkpoint 510795846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,925.03404
Policy Entropy: 1.17121
Value Function Loss: 0.06344

Mean KL Divergence: 0.00500
SB3 Clip Fraction: 0.05994
Policy Update Magnitude: 0.21493
Value Function Update Magnitude: 0.40741

Collected Steps per Second: 22,025.64169
Overall Steps per Second: 14,234.27747

Timestep Collection Time: 2.27226
Timestep Consumption Time: 1.24376
PPO Batch Consumption Time: 0.10372
Total Iteration Time: 3.51602

Cumulative Model Updates: 61,232
Cumulative Timesteps: 510,845,894

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,707.44182
Policy Entropy: 1.17103
Value Function Loss: 0.06561

Mean KL Divergence: 0.00476
SB3 Clip Fraction: 0.05648
Policy Update Magnitude: 0.21189
Value Function Update Magnitude: 0.41363

Collected Steps per Second: 22,929.53139
Overall Steps per Second: 14,601.60121

Timestep Collection Time: 2.18147
Timestep Consumption Time: 1.24419
PPO Batch Consumption Time: 0.10333
Total Iteration Time: 3.42565

Cumulative Model Updates: 61,238
Cumulative Timesteps: 510,895,914

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 510895914...
Checkpoint 510895914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,862.34392
Policy Entropy: 1.16252
Value Function Loss: 0.07388

Mean KL Divergence: 0.00538
SB3 Clip Fraction: 0.06358
Policy Update Magnitude: 0.21835
Value Function Update Magnitude: 0.44853

Collected Steps per Second: 22,695.83906
Overall Steps per Second: 14,729.66568

Timestep Collection Time: 2.20428
Timestep Consumption Time: 1.19213
PPO Batch Consumption Time: 0.09675
Total Iteration Time: 3.39641

Cumulative Model Updates: 61,244
Cumulative Timesteps: 510,945,942

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,347.53415
Policy Entropy: 1.14513
Value Function Loss: 0.07419

Mean KL Divergence: 0.00598
SB3 Clip Fraction: 0.07020
Policy Update Magnitude: 0.22304
Value Function Update Magnitude: 0.48106

Collected Steps per Second: 22,856.12742
Overall Steps per Second: 14,734.64541

Timestep Collection Time: 2.18795
Timestep Consumption Time: 1.20596
PPO Batch Consumption Time: 0.09742
Total Iteration Time: 3.39391

Cumulative Model Updates: 61,250
Cumulative Timesteps: 510,995,950

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 510995950...
Checkpoint 510995950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,381.79412
Policy Entropy: 1.16359
Value Function Loss: 0.07059

Mean KL Divergence: 0.00591
SB3 Clip Fraction: 0.07145
Policy Update Magnitude: 0.22338
Value Function Update Magnitude: 0.48667

Collected Steps per Second: 22,655.12709
Overall Steps per Second: 14,491.93659

Timestep Collection Time: 2.20807
Timestep Consumption Time: 1.24379
PPO Batch Consumption Time: 0.10206
Total Iteration Time: 3.45185

Cumulative Model Updates: 61,256
Cumulative Timesteps: 511,045,974

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,017.05938
Policy Entropy: 1.16561
Value Function Loss: 0.06941

Mean KL Divergence: 0.00492
SB3 Clip Fraction: 0.05787
Policy Update Magnitude: 0.22443
Value Function Update Magnitude: 0.44349

Collected Steps per Second: 22,647.94409
Overall Steps per Second: 14,596.67132

Timestep Collection Time: 2.20868
Timestep Consumption Time: 1.21827
PPO Batch Consumption Time: 0.10166
Total Iteration Time: 3.42695

Cumulative Model Updates: 61,262
Cumulative Timesteps: 511,095,996

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 511095996...
Checkpoint 511095996 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,911.83862
Policy Entropy: 1.18271
Value Function Loss: 0.07127

Mean KL Divergence: 0.00449
SB3 Clip Fraction: 0.05279
Policy Update Magnitude: 0.21860
Value Function Update Magnitude: 0.44922

Collected Steps per Second: 22,719.17079
Overall Steps per Second: 14,612.48691

Timestep Collection Time: 2.20290
Timestep Consumption Time: 1.22212
PPO Batch Consumption Time: 0.10186
Total Iteration Time: 3.42502

Cumulative Model Updates: 61,268
Cumulative Timesteps: 511,146,044

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,059.03972
Policy Entropy: 1.17805
Value Function Loss: 0.07906

Mean KL Divergence: 0.00570
SB3 Clip Fraction: 0.06651
Policy Update Magnitude: 0.21240
Value Function Update Magnitude: 0.43593

Collected Steps per Second: 22,945.38318
Overall Steps per Second: 14,728.42468

Timestep Collection Time: 2.18005
Timestep Consumption Time: 1.21624
PPO Batch Consumption Time: 0.09889
Total Iteration Time: 3.39629

Cumulative Model Updates: 61,274
Cumulative Timesteps: 511,196,066

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 511196066...
Checkpoint 511196066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,861.98685
Policy Entropy: 1.17213
Value Function Loss: 0.07233

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.09108
Policy Update Magnitude: 0.19397
Value Function Update Magnitude: 0.45044

Collected Steps per Second: 22,533.94363
Overall Steps per Second: 14,710.67539

Timestep Collection Time: 2.21950
Timestep Consumption Time: 1.18035
PPO Batch Consumption Time: 0.09244
Total Iteration Time: 3.39984

Cumulative Model Updates: 61,280
Cumulative Timesteps: 511,246,080

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,936.04798
Policy Entropy: 1.18041
Value Function Loss: 0.07457

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.09167
Policy Update Magnitude: 0.19598
Value Function Update Magnitude: 0.44918

Collected Steps per Second: 22,635.15985
Overall Steps per Second: 14,769.75591

Timestep Collection Time: 2.21045
Timestep Consumption Time: 1.17714
PPO Batch Consumption Time: 0.09381
Total Iteration Time: 3.38760

Cumulative Model Updates: 61,286
Cumulative Timesteps: 511,296,114

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 511296114...
Checkpoint 511296114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,241.38977
Policy Entropy: 1.17666
Value Function Loss: 0.07032

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.08390
Policy Update Magnitude: 0.20893
Value Function Update Magnitude: 0.44558

Collected Steps per Second: 22,082.94147
Overall Steps per Second: 14,241.37302

Timestep Collection Time: 2.26537
Timestep Consumption Time: 1.24735
PPO Batch Consumption Time: 0.10426
Total Iteration Time: 3.51272

Cumulative Model Updates: 61,292
Cumulative Timesteps: 511,346,140

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,624.79959
Policy Entropy: 1.17952
Value Function Loss: 0.07523

Mean KL Divergence: 0.00735
SB3 Clip Fraction: 0.07943
Policy Update Magnitude: 0.21613
Value Function Update Magnitude: 0.46329

Collected Steps per Second: 22,762.53171
Overall Steps per Second: 14,668.42095

Timestep Collection Time: 2.19809
Timestep Consumption Time: 1.21292
PPO Batch Consumption Time: 0.09997
Total Iteration Time: 3.41100

Cumulative Model Updates: 61,298
Cumulative Timesteps: 511,396,174

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 511396174...
Checkpoint 511396174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,889.14488
Policy Entropy: 1.17917
Value Function Loss: 0.07112

Mean KL Divergence: 0.00594
SB3 Clip Fraction: 0.06813
Policy Update Magnitude: 0.22113
Value Function Update Magnitude: 0.46799

Collected Steps per Second: 22,393.90154
Overall Steps per Second: 14,702.53933

Timestep Collection Time: 2.23338
Timestep Consumption Time: 1.16835
PPO Batch Consumption Time: 0.09334
Total Iteration Time: 3.40173

Cumulative Model Updates: 61,304
Cumulative Timesteps: 511,446,188

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,571.30980
Policy Entropy: 1.17814
Value Function Loss: 0.06797

Mean KL Divergence: 0.00480
SB3 Clip Fraction: 0.05632
Policy Update Magnitude: 0.22019
Value Function Update Magnitude: 0.47074

Collected Steps per Second: 22,781.24560
Overall Steps per Second: 14,726.44672

Timestep Collection Time: 2.19689
Timestep Consumption Time: 1.20162
PPO Batch Consumption Time: 0.09158
Total Iteration Time: 3.39851

Cumulative Model Updates: 61,310
Cumulative Timesteps: 511,496,236

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 511496236...
Checkpoint 511496236 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,617.66410
Policy Entropy: 1.16645
Value Function Loss: 0.06578

Mean KL Divergence: 0.00428
SB3 Clip Fraction: 0.05073
Policy Update Magnitude: 0.22135
Value Function Update Magnitude: 0.46786

Collected Steps per Second: 22,569.72738
Overall Steps per Second: 14,306.62014

Timestep Collection Time: 2.21633
Timestep Consumption Time: 1.28009
PPO Batch Consumption Time: 0.10353
Total Iteration Time: 3.49642

Cumulative Model Updates: 61,316
Cumulative Timesteps: 511,546,258

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,083.29456
Policy Entropy: 1.16130
Value Function Loss: 0.06825

Mean KL Divergence: 0.00474
SB3 Clip Fraction: 0.05589
Policy Update Magnitude: 0.21688
Value Function Update Magnitude: 0.47697

Collected Steps per Second: 22,785.65596
Overall Steps per Second: 14,527.07375

Timestep Collection Time: 2.19603
Timestep Consumption Time: 1.24843
PPO Batch Consumption Time: 0.09969
Total Iteration Time: 3.44447

Cumulative Model Updates: 61,322
Cumulative Timesteps: 511,596,296

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 511596296...
Checkpoint 511596296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,251.42643
Policy Entropy: 1.15524
Value Function Loss: 0.06589

Mean KL Divergence: 0.00402
SB3 Clip Fraction: 0.04841
Policy Update Magnitude: 0.21589
Value Function Update Magnitude: 0.48175

Collected Steps per Second: 22,412.39260
Overall Steps per Second: 14,212.09503

Timestep Collection Time: 2.23109
Timestep Consumption Time: 1.28732
PPO Batch Consumption Time: 0.10400
Total Iteration Time: 3.51841

Cumulative Model Updates: 61,328
Cumulative Timesteps: 511,646,300

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,069.86231
Policy Entropy: 1.15933
Value Function Loss: 0.06721

Mean KL Divergence: 0.00381
SB3 Clip Fraction: 0.04542
Policy Update Magnitude: 0.21765
Value Function Update Magnitude: 0.46038

Collected Steps per Second: 22,869.65890
Overall Steps per Second: 14,597.85419

Timestep Collection Time: 2.18709
Timestep Consumption Time: 1.23930
PPO Batch Consumption Time: 0.10106
Total Iteration Time: 3.42639

Cumulative Model Updates: 61,334
Cumulative Timesteps: 511,696,318

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 511696318...
Checkpoint 511696318 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,927.53124
Policy Entropy: 1.16420
Value Function Loss: 0.06390

Mean KL Divergence: 0.00431
SB3 Clip Fraction: 0.05146
Policy Update Magnitude: 0.21246
Value Function Update Magnitude: 0.42675

Collected Steps per Second: 22,652.60737
Overall Steps per Second: 14,372.02763

Timestep Collection Time: 2.20840
Timestep Consumption Time: 1.27239
PPO Batch Consumption Time: 0.10265
Total Iteration Time: 3.48079

Cumulative Model Updates: 61,340
Cumulative Timesteps: 511,746,344

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,824.95203
Policy Entropy: 1.15590
Value Function Loss: 0.06478

Mean KL Divergence: 0.00545
SB3 Clip Fraction: 0.06315
Policy Update Magnitude: 0.20613
Value Function Update Magnitude: 0.41290

Collected Steps per Second: 22,335.86123
Overall Steps per Second: 14,400.49122

Timestep Collection Time: 2.24070
Timestep Consumption Time: 1.23474
PPO Batch Consumption Time: 0.10033
Total Iteration Time: 3.47544

Cumulative Model Updates: 61,346
Cumulative Timesteps: 511,796,392

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 511796392...
Checkpoint 511796392 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,112.53300
Policy Entropy: 1.15057
Value Function Loss: 0.06210

Mean KL Divergence: 0.00436
SB3 Clip Fraction: 0.05239
Policy Update Magnitude: 0.20964
Value Function Update Magnitude: 0.42441

Collected Steps per Second: 22,559.70754
Overall Steps per Second: 14,702.83272

Timestep Collection Time: 2.21785
Timestep Consumption Time: 1.18517
PPO Batch Consumption Time: 0.09090
Total Iteration Time: 3.40302

Cumulative Model Updates: 61,352
Cumulative Timesteps: 511,846,426

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,284.01952
Policy Entropy: 1.15640
Value Function Loss: 0.06267

Mean KL Divergence: 0.00398
SB3 Clip Fraction: 0.04682
Policy Update Magnitude: 0.21943
Value Function Update Magnitude: 0.43411

Collected Steps per Second: 22,975.64302
Overall Steps per Second: 14,822.21346

Timestep Collection Time: 2.17665
Timestep Consumption Time: 1.19734
PPO Batch Consumption Time: 0.09587
Total Iteration Time: 3.37399

Cumulative Model Updates: 61,358
Cumulative Timesteps: 511,896,436

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 511896436...
Checkpoint 511896436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,198.03419
Policy Entropy: 1.15866
Value Function Loss: 0.06703

Mean KL Divergence: 0.00484
SB3 Clip Fraction: 0.05874
Policy Update Magnitude: 0.21728
Value Function Update Magnitude: 0.43517

Collected Steps per Second: 22,387.69925
Overall Steps per Second: 14,450.65577

Timestep Collection Time: 2.23391
Timestep Consumption Time: 1.22698
PPO Batch Consumption Time: 0.10287
Total Iteration Time: 3.46088

Cumulative Model Updates: 61,364
Cumulative Timesteps: 511,946,448

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42,408.07019
Policy Entropy: 1.16295
Value Function Loss: 0.06334

Mean KL Divergence: 0.00457
SB3 Clip Fraction: 0.05350
Policy Update Magnitude: 0.21800
Value Function Update Magnitude: 0.43079

Collected Steps per Second: 23,061.05524
Overall Steps per Second: 14,755.81950

Timestep Collection Time: 2.16946
Timestep Consumption Time: 1.22107
PPO Batch Consumption Time: 0.10006
Total Iteration Time: 3.39053

Cumulative Model Updates: 61,370
Cumulative Timesteps: 511,996,478

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 511996478...
Checkpoint 511996478 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,062.40785
Policy Entropy: 1.14870
Value Function Loss: 0.06728

Mean KL Divergence: 0.00397
SB3 Clip Fraction: 0.04614
Policy Update Magnitude: 0.22527
Value Function Update Magnitude: 0.42969

Collected Steps per Second: 22,753.83615
Overall Steps per Second: 14,520.71795

Timestep Collection Time: 2.19945
Timestep Consumption Time: 1.24707
PPO Batch Consumption Time: 0.10072
Total Iteration Time: 3.44652

Cumulative Model Updates: 61,376
Cumulative Timesteps: 512,046,524

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,216.48491
Policy Entropy: 1.14743
Value Function Loss: 0.06562

Mean KL Divergence: 0.00430
SB3 Clip Fraction: 0.05087
Policy Update Magnitude: 0.22016
Value Function Update Magnitude: 0.43823

Collected Steps per Second: 22,331.59332
Overall Steps per Second: 14,591.87917

Timestep Collection Time: 2.24032
Timestep Consumption Time: 1.18830
PPO Batch Consumption Time: 0.09294
Total Iteration Time: 3.42862

Cumulative Model Updates: 61,382
Cumulative Timesteps: 512,096,554

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 512096554...
Checkpoint 512096554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,855.09909
Policy Entropy: 1.15377
Value Function Loss: 0.06768

Mean KL Divergence: 0.00461
SB3 Clip Fraction: 0.05415
Policy Update Magnitude: 0.21501
Value Function Update Magnitude: 0.43905

Collected Steps per Second: 22,727.33055
Overall Steps per Second: 14,824.32649

Timestep Collection Time: 2.20123
Timestep Consumption Time: 1.17350
PPO Batch Consumption Time: 0.09426
Total Iteration Time: 3.37472

Cumulative Model Updates: 61,388
Cumulative Timesteps: 512,146,582

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,243.32424
Policy Entropy: 1.15262
Value Function Loss: 0.06712

Mean KL Divergence: 0.00552
SB3 Clip Fraction: 0.06117
Policy Update Magnitude: 0.21327
Value Function Update Magnitude: 0.42388

Collected Steps per Second: 22,808.76964
Overall Steps per Second: 14,792.17967

Timestep Collection Time: 2.19267
Timestep Consumption Time: 1.18831
PPO Batch Consumption Time: 0.09590
Total Iteration Time: 3.38098

Cumulative Model Updates: 61,394
Cumulative Timesteps: 512,196,594

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 512196594...
Checkpoint 512196594 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,474.76910
Policy Entropy: 1.15385
Value Function Loss: 0.06447

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.08122
Policy Update Magnitude: 0.19631
Value Function Update Magnitude: 0.39865

Collected Steps per Second: 21,106.19752
Overall Steps per Second: 14,026.81759

Timestep Collection Time: 2.36973
Timestep Consumption Time: 1.19601
PPO Batch Consumption Time: 0.09843
Total Iteration Time: 3.56574

Cumulative Model Updates: 61,400
Cumulative Timesteps: 512,246,610

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,387.96498
Policy Entropy: 1.14573
Value Function Loss: 0.07063

Mean KL Divergence: 0.00690
SB3 Clip Fraction: 0.07167
Policy Update Magnitude: 0.20468
Value Function Update Magnitude: 0.41570

Collected Steps per Second: 22,750.66469
Overall Steps per Second: 14,741.52239

Timestep Collection Time: 2.19879
Timestep Consumption Time: 1.19462
PPO Batch Consumption Time: 0.09458
Total Iteration Time: 3.39341

Cumulative Model Updates: 61,406
Cumulative Timesteps: 512,296,634

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 512296634...
Checkpoint 512296634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,841.88697
Policy Entropy: 1.13717
Value Function Loss: 0.07186

Mean KL Divergence: 0.00584
SB3 Clip Fraction: 0.06383
Policy Update Magnitude: 0.21694
Value Function Update Magnitude: 0.43981

Collected Steps per Second: 22,650.91946
Overall Steps per Second: 14,837.65899

Timestep Collection Time: 2.20768
Timestep Consumption Time: 1.16253
PPO Batch Consumption Time: 0.09252
Total Iteration Time: 3.37021

Cumulative Model Updates: 61,412
Cumulative Timesteps: 512,346,640

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,002.20738
Policy Entropy: 1.11981
Value Function Loss: 0.07009

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.09063
Policy Update Magnitude: 0.21086
Value Function Update Magnitude: 0.45080

Collected Steps per Second: 22,690.04638
Overall Steps per Second: 14,729.68778

Timestep Collection Time: 2.20396
Timestep Consumption Time: 1.19109
PPO Batch Consumption Time: 0.09392
Total Iteration Time: 3.39505

Cumulative Model Updates: 61,418
Cumulative Timesteps: 512,396,648

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 512396648...
Checkpoint 512396648 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,332.46482
Policy Entropy: 1.14187
Value Function Loss: 0.06556

Mean KL Divergence: 0.01107
SB3 Clip Fraction: 0.10157
Policy Update Magnitude: 0.18524
Value Function Update Magnitude: 0.44945

Collected Steps per Second: 22,612.69213
Overall Steps per Second: 14,530.44031

Timestep Collection Time: 2.21230
Timestep Consumption Time: 1.23054
PPO Batch Consumption Time: 0.10179
Total Iteration Time: 3.44284

Cumulative Model Updates: 61,424
Cumulative Timesteps: 512,446,674

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,040.62032
Policy Entropy: 1.14396
Value Function Loss: 0.06072

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.08250
Policy Update Magnitude: 0.17598
Value Function Update Magnitude: 0.42559

Collected Steps per Second: 22,919.15581
Overall Steps per Second: 14,719.17555

Timestep Collection Time: 2.18306
Timestep Consumption Time: 1.21617
PPO Batch Consumption Time: 0.10138
Total Iteration Time: 3.39924

Cumulative Model Updates: 61,430
Cumulative Timesteps: 512,496,708

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 512496708...
Checkpoint 512496708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,464.04922
Policy Entropy: 1.13992
Value Function Loss: 0.05824

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.09653
Policy Update Magnitude: 0.17378
Value Function Update Magnitude: 0.41182

Collected Steps per Second: 22,406.36214
Overall Steps per Second: 14,413.79894

Timestep Collection Time: 2.23276
Timestep Consumption Time: 1.23808
PPO Batch Consumption Time: 0.09875
Total Iteration Time: 3.47084

Cumulative Model Updates: 61,436
Cumulative Timesteps: 512,546,736

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,650.29118
Policy Entropy: 1.13584
Value Function Loss: 0.05531

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.09109
Policy Update Magnitude: 0.17371
Value Function Update Magnitude: 0.41467

Collected Steps per Second: 22,894.44649
Overall Steps per Second: 14,720.30421

Timestep Collection Time: 2.18402
Timestep Consumption Time: 1.21278
PPO Batch Consumption Time: 0.09761
Total Iteration Time: 3.39680

Cumulative Model Updates: 61,442
Cumulative Timesteps: 512,596,738

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 512596738...
Checkpoint 512596738 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,091.50451
Policy Entropy: 1.13777
Value Function Loss: 0.06140

Mean KL Divergence: 0.00608
SB3 Clip Fraction: 0.06981
Policy Update Magnitude: 0.18778
Value Function Update Magnitude: 0.40969

Collected Steps per Second: 22,314.17815
Overall Steps per Second: 14,354.93861

Timestep Collection Time: 2.24279
Timestep Consumption Time: 1.24354
PPO Batch Consumption Time: 0.10231
Total Iteration Time: 3.48633

Cumulative Model Updates: 61,448
Cumulative Timesteps: 512,646,784

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,008.63989
Policy Entropy: 1.14177
Value Function Loss: 0.06507

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.08565
Policy Update Magnitude: 0.19770
Value Function Update Magnitude: 0.41096

Collected Steps per Second: 22,633.37182
Overall Steps per Second: 14,539.54259

Timestep Collection Time: 2.21019
Timestep Consumption Time: 1.23036
PPO Batch Consumption Time: 0.10273
Total Iteration Time: 3.44055

Cumulative Model Updates: 61,454
Cumulative Timesteps: 512,696,808

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 512696808...
Checkpoint 512696808 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,932.83872
Policy Entropy: 1.13138
Value Function Loss: 0.06453

Mean KL Divergence: 0.00627
SB3 Clip Fraction: 0.07273
Policy Update Magnitude: 0.19932
Value Function Update Magnitude: 0.41849

Collected Steps per Second: 22,620.25492
Overall Steps per Second: 14,677.48725

Timestep Collection Time: 2.21076
Timestep Consumption Time: 1.19636
PPO Batch Consumption Time: 0.09647
Total Iteration Time: 3.40712

Cumulative Model Updates: 61,460
Cumulative Timesteps: 512,746,816

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,099.34173
Policy Entropy: 1.13592
Value Function Loss: 0.06022

Mean KL Divergence: 0.00536
SB3 Clip Fraction: 0.06296
Policy Update Magnitude: 0.19903
Value Function Update Magnitude: 0.40185

Collected Steps per Second: 22,762.93973
Overall Steps per Second: 14,748.64473

Timestep Collection Time: 2.19805
Timestep Consumption Time: 1.19440
PPO Batch Consumption Time: 0.09479
Total Iteration Time: 3.39245

Cumulative Model Updates: 61,466
Cumulative Timesteps: 512,796,850

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 512796850...
Checkpoint 512796850 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,149.79734
Policy Entropy: 1.13804
Value Function Loss: 0.06012

Mean KL Divergence: 0.00434
SB3 Clip Fraction: 0.05247
Policy Update Magnitude: 0.20219
Value Function Update Magnitude: 0.38840

Collected Steps per Second: 22,728.38741
Overall Steps per Second: 14,839.56314

Timestep Collection Time: 2.19998
Timestep Consumption Time: 1.16953
PPO Batch Consumption Time: 0.09317
Total Iteration Time: 3.36951

Cumulative Model Updates: 61,472
Cumulative Timesteps: 512,846,852

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,508.20885
Policy Entropy: 1.14143
Value Function Loss: 0.05840

Mean KL Divergence: 0.00396
SB3 Clip Fraction: 0.04832
Policy Update Magnitude: 0.20443
Value Function Update Magnitude: 0.40915

Collected Steps per Second: 22,352.94023
Overall Steps per Second: 14,723.45920

Timestep Collection Time: 2.23854
Timestep Consumption Time: 1.15998
PPO Batch Consumption Time: 0.09207
Total Iteration Time: 3.39852

Cumulative Model Updates: 61,478
Cumulative Timesteps: 512,896,890

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 512896890...
Checkpoint 512896890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,823.00405
Policy Entropy: 1.14384
Value Function Loss: 0.06342

Mean KL Divergence: 0.00443
SB3 Clip Fraction: 0.05273
Policy Update Magnitude: 0.20926
Value Function Update Magnitude: 0.41959

Collected Steps per Second: 22,643.50030
Overall Steps per Second: 14,816.53890

Timestep Collection Time: 2.20858
Timestep Consumption Time: 1.16670
PPO Batch Consumption Time: 0.09069
Total Iteration Time: 3.37528

Cumulative Model Updates: 61,484
Cumulative Timesteps: 512,946,900

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,562.30993
Policy Entropy: 1.14361
Value Function Loss: 0.06418

Mean KL Divergence: 0.00506
SB3 Clip Fraction: 0.06093
Policy Update Magnitude: 0.20629
Value Function Update Magnitude: 0.41502

Collected Steps per Second: 22,754.66722
Overall Steps per Second: 14,765.56368

Timestep Collection Time: 2.19744
Timestep Consumption Time: 1.18895
PPO Batch Consumption Time: 0.09411
Total Iteration Time: 3.38639

Cumulative Model Updates: 61,490
Cumulative Timesteps: 512,996,902

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 512996902...
Checkpoint 512996902 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,043.58738
Policy Entropy: 1.16016
Value Function Loss: 0.06656

Mean KL Divergence: 0.00480
SB3 Clip Fraction: 0.05842
Policy Update Magnitude: 0.20278
Value Function Update Magnitude: 0.42225

Collected Steps per Second: 22,664.72427
Overall Steps per Second: 14,857.89911

Timestep Collection Time: 2.20792
Timestep Consumption Time: 1.16012
PPO Batch Consumption Time: 0.09334
Total Iteration Time: 3.36804

Cumulative Model Updates: 61,496
Cumulative Timesteps: 513,046,944

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,652.96970
Policy Entropy: 1.16317
Value Function Loss: 0.06382

Mean KL Divergence: 0.00452
SB3 Clip Fraction: 0.05478
Policy Update Magnitude: 0.20501
Value Function Update Magnitude: 0.43335

Collected Steps per Second: 23,079.29506
Overall Steps per Second: 14,777.11689

Timestep Collection Time: 2.16826
Timestep Consumption Time: 1.21819
PPO Batch Consumption Time: 0.09449
Total Iteration Time: 3.38645

Cumulative Model Updates: 61,502
Cumulative Timesteps: 513,096,986

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 513096986...
Checkpoint 513096986 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,589.52923
Policy Entropy: 1.16799
Value Function Loss: 0.06665

Mean KL Divergence: 0.00502
SB3 Clip Fraction: 0.05995
Policy Update Magnitude: 0.20834
Value Function Update Magnitude: 0.43634

Collected Steps per Second: 22,420.90555
Overall Steps per Second: 14,339.58181

Timestep Collection Time: 2.23086
Timestep Consumption Time: 1.25724
PPO Batch Consumption Time: 0.10281
Total Iteration Time: 3.48811

Cumulative Model Updates: 61,508
Cumulative Timesteps: 513,147,004

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,077.32212
Policy Entropy: 1.15439
Value Function Loss: 0.06543

Mean KL Divergence: 0.00723
SB3 Clip Fraction: 0.07744
Policy Update Magnitude: 0.20094
Value Function Update Magnitude: 0.45165

Collected Steps per Second: 22,909.97635
Overall Steps per Second: 14,396.70279

Timestep Collection Time: 2.18394
Timestep Consumption Time: 1.29144
PPO Batch Consumption Time: 0.10707
Total Iteration Time: 3.47538

Cumulative Model Updates: 61,514
Cumulative Timesteps: 513,197,038

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 513197038...
Checkpoint 513197038 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,115.81550
Policy Entropy: 1.16516
Value Function Loss: 0.07459

Mean KL Divergence: 0.01205
SB3 Clip Fraction: 0.10575
Policy Update Magnitude: 0.18267
Value Function Update Magnitude: 0.45277

Collected Steps per Second: 22,335.57628
Overall Steps per Second: 14,099.49095

Timestep Collection Time: 2.24055
Timestep Consumption Time: 1.30880
PPO Batch Consumption Time: 0.10917
Total Iteration Time: 3.54935

Cumulative Model Updates: 61,520
Cumulative Timesteps: 513,247,082

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,938.76144
Policy Entropy: 1.16178
Value Function Loss: 0.07534

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.08586
Policy Update Magnitude: 0.18848
Value Function Update Magnitude: 0.43866

Collected Steps per Second: 22,121.23532
Overall Steps per Second: 14,659.26285

Timestep Collection Time: 2.26109
Timestep Consumption Time: 1.15096
PPO Batch Consumption Time: 0.09179
Total Iteration Time: 3.41204

Cumulative Model Updates: 61,526
Cumulative Timesteps: 513,297,100

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 513297100...
Checkpoint 513297100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,769.49574
Policy Entropy: 1.18286
Value Function Loss: 0.07066

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.09061
Policy Update Magnitude: 0.18584
Value Function Update Magnitude: 0.43997

Collected Steps per Second: 22,761.35636
Overall Steps per Second: 14,862.89479

Timestep Collection Time: 2.19794
Timestep Consumption Time: 1.16803
PPO Batch Consumption Time: 0.09212
Total Iteration Time: 3.36597

Cumulative Model Updates: 61,532
Cumulative Timesteps: 513,347,128

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,504.62435
Policy Entropy: 1.16959
Value Function Loss: 0.06758

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.09038
Policy Update Magnitude: 0.18297
Value Function Update Magnitude: 0.44281

Collected Steps per Second: 22,884.16448
Overall Steps per Second: 14,806.45082

Timestep Collection Time: 2.18492
Timestep Consumption Time: 1.19199
PPO Batch Consumption Time: 0.09773
Total Iteration Time: 3.37691

Cumulative Model Updates: 61,538
Cumulative Timesteps: 513,397,128

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 513397128...
Checkpoint 513397128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,893.23195
Policy Entropy: 1.17712
Value Function Loss: 0.06554

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.08937
Policy Update Magnitude: 0.18745
Value Function Update Magnitude: 0.46564

Collected Steps per Second: 22,281.01874
Overall Steps per Second: 14,478.00875

Timestep Collection Time: 2.24541
Timestep Consumption Time: 1.21018
PPO Batch Consumption Time: 0.10184
Total Iteration Time: 3.45559

Cumulative Model Updates: 61,544
Cumulative Timesteps: 513,447,158

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,112.84873
Policy Entropy: 1.16301
Value Function Loss: 0.06627

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.08985
Policy Update Magnitude: 0.19011
Value Function Update Magnitude: 0.44086

Collected Steps per Second: 22,922.79371
Overall Steps per Second: 14,774.81190

Timestep Collection Time: 2.18158
Timestep Consumption Time: 1.20310
PPO Batch Consumption Time: 0.10034
Total Iteration Time: 3.38468

Cumulative Model Updates: 61,550
Cumulative Timesteps: 513,497,166

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 513497166...
Checkpoint 513497166 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,155.36071
Policy Entropy: 1.16763
Value Function Loss: 0.07628

Mean KL Divergence: 0.01065
SB3 Clip Fraction: 0.10478
Policy Update Magnitude: 0.18344
Value Function Update Magnitude: 0.44583

Collected Steps per Second: 22,621.69339
Overall Steps per Second: 14,481.05513

Timestep Collection Time: 2.21044
Timestep Consumption Time: 1.24262
PPO Batch Consumption Time: 0.10298
Total Iteration Time: 3.45306

Cumulative Model Updates: 61,556
Cumulative Timesteps: 513,547,170

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,091.75829
Policy Entropy: 1.15729
Value Function Loss: 0.06676

Mean KL Divergence: 0.01112
SB3 Clip Fraction: 0.09978
Policy Update Magnitude: 0.17831
Value Function Update Magnitude: 0.44578

Collected Steps per Second: 22,885.20163
Overall Steps per Second: 14,732.63154

Timestep Collection Time: 2.18578
Timestep Consumption Time: 1.20954
PPO Batch Consumption Time: 0.10063
Total Iteration Time: 3.39532

Cumulative Model Updates: 61,562
Cumulative Timesteps: 513,597,192

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 513597192...
Checkpoint 513597192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,718.51751
Policy Entropy: 1.16604
Value Function Loss: 0.06736

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.09033
Policy Update Magnitude: 0.18996
Value Function Update Magnitude: 0.42940

Collected Steps per Second: 22,621.01722
Overall Steps per Second: 14,718.11896

Timestep Collection Time: 2.21201
Timestep Consumption Time: 1.18774
PPO Batch Consumption Time: 0.09485
Total Iteration Time: 3.39976

Cumulative Model Updates: 61,568
Cumulative Timesteps: 513,647,230

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,799.39053
Policy Entropy: 1.16489
Value Function Loss: 0.06308

Mean KL Divergence: 0.00678
SB3 Clip Fraction: 0.07612
Policy Update Magnitude: 0.19287
Value Function Update Magnitude: 0.43108

Collected Steps per Second: 22,782.85415
Overall Steps per Second: 14,695.66404

Timestep Collection Time: 2.19490
Timestep Consumption Time: 1.20788
PPO Batch Consumption Time: 0.09325
Total Iteration Time: 3.40277

Cumulative Model Updates: 61,574
Cumulative Timesteps: 513,697,236

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 513697236...
Checkpoint 513697236 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,080.12273
Policy Entropy: 1.18271
Value Function Loss: 0.06683

Mean KL Divergence: 0.00595
SB3 Clip Fraction: 0.06763
Policy Update Magnitude: 0.19550
Value Function Update Magnitude: 0.44056

Collected Steps per Second: 22,471.92122
Overall Steps per Second: 14,491.93820

Timestep Collection Time: 2.22589
Timestep Consumption Time: 1.22569
PPO Batch Consumption Time: 0.10276
Total Iteration Time: 3.45157

Cumulative Model Updates: 61,580
Cumulative Timesteps: 513,747,256

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,153.60322
Policy Entropy: 1.18323
Value Function Loss: 0.06703

Mean KL Divergence: 0.00490
SB3 Clip Fraction: 0.06092
Policy Update Magnitude: 0.20165
Value Function Update Magnitude: 0.42919

Collected Steps per Second: 22,646.48622
Overall Steps per Second: 14,542.31234

Timestep Collection Time: 2.20829
Timestep Consumption Time: 1.23064
PPO Batch Consumption Time: 0.10240
Total Iteration Time: 3.43893

Cumulative Model Updates: 61,586
Cumulative Timesteps: 513,797,266

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 513797266...
Checkpoint 513797266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,976.15767
Policy Entropy: 1.18364
Value Function Loss: 0.06095

Mean KL Divergence: 0.00407
SB3 Clip Fraction: 0.04912
Policy Update Magnitude: 0.20310
Value Function Update Magnitude: 0.40976

Collected Steps per Second: 22,520.49953
Overall Steps per Second: 14,654.86590

Timestep Collection Time: 2.22109
Timestep Consumption Time: 1.19211
PPO Batch Consumption Time: 0.09905
Total Iteration Time: 3.41320

Cumulative Model Updates: 61,592
Cumulative Timesteps: 513,847,286

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,444.81386
Policy Entropy: 1.18094
Value Function Loss: 0.06219

Mean KL Divergence: 0.00553
SB3 Clip Fraction: 0.06302
Policy Update Magnitude: 0.20108
Value Function Update Magnitude: 0.41101

Collected Steps per Second: 22,898.62528
Overall Steps per Second: 14,726.99474

Timestep Collection Time: 2.18502
Timestep Consumption Time: 1.21241
PPO Batch Consumption Time: 0.09867
Total Iteration Time: 3.39743

Cumulative Model Updates: 61,598
Cumulative Timesteps: 513,897,320

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 513897320...
Checkpoint 513897320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,982.73695
Policy Entropy: 1.18816
Value Function Loss: 0.07097

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.09001
Policy Update Magnitude: 0.18169
Value Function Update Magnitude: 0.42576

Collected Steps per Second: 22,655.72108
Overall Steps per Second: 14,764.66928

Timestep Collection Time: 2.20924
Timestep Consumption Time: 1.18074
PPO Batch Consumption Time: 0.09202
Total Iteration Time: 3.38998

Cumulative Model Updates: 61,604
Cumulative Timesteps: 513,947,372

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,388.44739
Policy Entropy: 1.17500
Value Function Loss: 0.07402

Mean KL Divergence: 0.00737
SB3 Clip Fraction: 0.07920
Policy Update Magnitude: 0.19773
Value Function Update Magnitude: 0.46388

Collected Steps per Second: 22,863.50577
Overall Steps per Second: 14,804.59740

Timestep Collection Time: 2.18768
Timestep Consumption Time: 1.19087
PPO Batch Consumption Time: 0.09523
Total Iteration Time: 3.37855

Cumulative Model Updates: 61,610
Cumulative Timesteps: 513,997,390

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 513997390...
Checkpoint 513997390 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,948.89466
Policy Entropy: 1.16875
Value Function Loss: 0.06991

Mean KL Divergence: 0.00663
SB3 Clip Fraction: 0.07399
Policy Update Magnitude: 0.20832
Value Function Update Magnitude: 0.48331

Collected Steps per Second: 22,643.21029
Overall Steps per Second: 14,819.30701

Timestep Collection Time: 2.20932
Timestep Consumption Time: 1.16642
PPO Batch Consumption Time: 0.09211
Total Iteration Time: 3.37573

Cumulative Model Updates: 61,616
Cumulative Timesteps: 514,047,416

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,321.34613
Policy Entropy: 1.16729
Value Function Loss: 0.07226

Mean KL Divergence: 0.00522
SB3 Clip Fraction: 0.06205
Policy Update Magnitude: 0.20681
Value Function Update Magnitude: 0.45416

Collected Steps per Second: 22,835.54215
Overall Steps per Second: 14,809.54685

Timestep Collection Time: 2.19115
Timestep Consumption Time: 1.18749
PPO Batch Consumption Time: 0.09500
Total Iteration Time: 3.37863

Cumulative Model Updates: 61,622
Cumulative Timesteps: 514,097,452

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 514097452...
Checkpoint 514097452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,999.57031
Policy Entropy: 1.17358
Value Function Loss: 0.07008

Mean KL Divergence: 0.00430
SB3 Clip Fraction: 0.05158
Policy Update Magnitude: 0.20939
Value Function Update Magnitude: 0.44669

Collected Steps per Second: 22,096.63503
Overall Steps per Second: 14,350.68775

Timestep Collection Time: 2.26378
Timestep Consumption Time: 1.22190
PPO Batch Consumption Time: 0.10172
Total Iteration Time: 3.48569

Cumulative Model Updates: 61,628
Cumulative Timesteps: 514,147,474

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,286.72321
Policy Entropy: 1.18145
Value Function Loss: 0.07202

Mean KL Divergence: 0.00491
SB3 Clip Fraction: 0.05790
Policy Update Magnitude: 0.21147
Value Function Update Magnitude: 0.43971

Collected Steps per Second: 22,402.46231
Overall Steps per Second: 14,518.07919

Timestep Collection Time: 2.23270
Timestep Consumption Time: 1.21252
PPO Batch Consumption Time: 0.10000
Total Iteration Time: 3.44522

Cumulative Model Updates: 61,634
Cumulative Timesteps: 514,197,492

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 514197492...
Checkpoint 514197492 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,632.74970
Policy Entropy: 1.18015
Value Function Loss: 0.06325

Mean KL Divergence: 0.00467
SB3 Clip Fraction: 0.05627
Policy Update Magnitude: 0.21103
Value Function Update Magnitude: 0.41217

Collected Steps per Second: 22,870.13626
Overall Steps per Second: 14,778.63297

Timestep Collection Time: 2.18696
Timestep Consumption Time: 1.19739
PPO Batch Consumption Time: 0.09728
Total Iteration Time: 3.38435

Cumulative Model Updates: 61,640
Cumulative Timesteps: 514,247,508

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,435.30436
Policy Entropy: 1.18682
Value Function Loss: 0.06332

Mean KL Divergence: 0.00450
SB3 Clip Fraction: 0.05559
Policy Update Magnitude: 0.20713
Value Function Update Magnitude: 0.39299

Collected Steps per Second: 22,625.86889
Overall Steps per Second: 14,694.14920

Timestep Collection Time: 2.21119
Timestep Consumption Time: 1.19357
PPO Batch Consumption Time: 0.09486
Total Iteration Time: 3.40476

Cumulative Model Updates: 61,646
Cumulative Timesteps: 514,297,538

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 514297538...
Checkpoint 514297538 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,509.16837
Policy Entropy: 1.19935
Value Function Loss: 0.06075

Mean KL Divergence: 0.00382
SB3 Clip Fraction: 0.04460
Policy Update Magnitude: 0.20902
Value Function Update Magnitude: 0.38358

Collected Steps per Second: 22,744.83324
Overall Steps per Second: 14,839.20179

Timestep Collection Time: 2.19980
Timestep Consumption Time: 1.17195
PPO Batch Consumption Time: 0.09226
Total Iteration Time: 3.37174

Cumulative Model Updates: 61,652
Cumulative Timesteps: 514,347,572

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,947.88780
Policy Entropy: 1.21268
Value Function Loss: 0.06203

Mean KL Divergence: 0.00411
SB3 Clip Fraction: 0.04882
Policy Update Magnitude: 0.21753
Value Function Update Magnitude: 0.38612

Collected Steps per Second: 23,057.90963
Overall Steps per Second: 14,779.82195

Timestep Collection Time: 2.16984
Timestep Consumption Time: 1.21531
PPO Batch Consumption Time: 0.09525
Total Iteration Time: 3.38516

Cumulative Model Updates: 61,658
Cumulative Timesteps: 514,397,604

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 514397604...
Checkpoint 514397604 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,707.37320
Policy Entropy: 1.21361
Value Function Loss: 0.05670

Mean KL Divergence: 0.00525
SB3 Clip Fraction: 0.06251
Policy Update Magnitude: 0.21036
Value Function Update Magnitude: 0.38005

Collected Steps per Second: 21,813.74180
Overall Steps per Second: 14,073.81436

Timestep Collection Time: 2.29287
Timestep Consumption Time: 1.26097
PPO Batch Consumption Time: 0.10103
Total Iteration Time: 3.55383

Cumulative Model Updates: 61,664
Cumulative Timesteps: 514,447,620

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,002.49179
Policy Entropy: 1.20937
Value Function Loss: 0.05576

Mean KL Divergence: 0.00513
SB3 Clip Fraction: 0.06183
Policy Update Magnitude: 0.20196
Value Function Update Magnitude: 0.36370

Collected Steps per Second: 22,939.30362
Overall Steps per Second: 14,689.54137

Timestep Collection Time: 2.18045
Timestep Consumption Time: 1.22456
PPO Batch Consumption Time: 0.09759
Total Iteration Time: 3.40501

Cumulative Model Updates: 61,670
Cumulative Timesteps: 514,497,638

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 514497638...
Checkpoint 514497638 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,549.63793
Policy Entropy: 1.21230
Value Function Loss: 0.05627

Mean KL Divergence: 0.00486
SB3 Clip Fraction: 0.05771
Policy Update Magnitude: 0.19686
Value Function Update Magnitude: 0.36374

Collected Steps per Second: 22,508.78389
Overall Steps per Second: 14,489.11158

Timestep Collection Time: 2.22313
Timestep Consumption Time: 1.23050
PPO Batch Consumption Time: 0.10318
Total Iteration Time: 3.45363

Cumulative Model Updates: 61,676
Cumulative Timesteps: 514,547,678

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,307.76647
Policy Entropy: 1.21862
Value Function Loss: 0.05959

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.08524
Policy Update Magnitude: 0.20277
Value Function Update Magnitude: 0.37632

Collected Steps per Second: 22,987.68007
Overall Steps per Second: 14,724.93339

Timestep Collection Time: 2.17725
Timestep Consumption Time: 1.22174
PPO Batch Consumption Time: 0.10067
Total Iteration Time: 3.39900

Cumulative Model Updates: 61,682
Cumulative Timesteps: 514,597,728

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 514597728...
Checkpoint 514597728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,673.65741
Policy Entropy: 1.20704
Value Function Loss: 0.06763

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.10922
Policy Update Magnitude: 0.18575
Value Function Update Magnitude: 0.38548

Collected Steps per Second: 22,498.40174
Overall Steps per Second: 14,563.13152

Timestep Collection Time: 2.22398
Timestep Consumption Time: 1.21182
PPO Batch Consumption Time: 0.10156
Total Iteration Time: 3.43580

Cumulative Model Updates: 61,688
Cumulative Timesteps: 514,647,764

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,010.77549
Policy Entropy: 1.21111
Value Function Loss: 0.07037

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.09374
Policy Update Magnitude: 0.19861
Value Function Update Magnitude: 0.39861

Collected Steps per Second: 22,967.08293
Overall Steps per Second: 14,746.59716

Timestep Collection Time: 2.17729
Timestep Consumption Time: 1.21373
PPO Batch Consumption Time: 0.10339
Total Iteration Time: 3.39102

Cumulative Model Updates: 61,694
Cumulative Timesteps: 514,697,770

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 514697770...
Checkpoint 514697770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,700.61117
Policy Entropy: 1.21402
Value Function Loss: 0.06609

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.09476
Policy Update Magnitude: 0.21012
Value Function Update Magnitude: 0.42194

Collected Steps per Second: 22,526.22079
Overall Steps per Second: 14,665.97511

Timestep Collection Time: 2.21981
Timestep Consumption Time: 1.18971
PPO Batch Consumption Time: 0.09553
Total Iteration Time: 3.40952

Cumulative Model Updates: 61,700
Cumulative Timesteps: 514,747,774

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,141.81090
Policy Entropy: 1.21828
Value Function Loss: 0.05821

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.08471
Policy Update Magnitude: 0.20718
Value Function Update Magnitude: 0.41936

Collected Steps per Second: 22,970.73643
Overall Steps per Second: 14,772.32392

Timestep Collection Time: 2.17668
Timestep Consumption Time: 1.20803
PPO Batch Consumption Time: 0.09623
Total Iteration Time: 3.38471

Cumulative Model Updates: 61,706
Cumulative Timesteps: 514,797,774

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 514797774...
Checkpoint 514797774 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,684.49546
Policy Entropy: 1.21185
Value Function Loss: 0.05705

Mean KL Divergence: 0.00604
SB3 Clip Fraction: 0.07024
Policy Update Magnitude: 0.20411
Value Function Update Magnitude: 0.40320

Collected Steps per Second: 22,521.16042
Overall Steps per Second: 14,460.52319

Timestep Collection Time: 2.22067
Timestep Consumption Time: 1.23785
PPO Batch Consumption Time: 0.10225
Total Iteration Time: 3.45852

Cumulative Model Updates: 61,712
Cumulative Timesteps: 514,847,786

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,367.92729
Policy Entropy: 1.19693
Value Function Loss: 0.05232

Mean KL Divergence: 0.00633
SB3 Clip Fraction: 0.07370
Policy Update Magnitude: 0.20149
Value Function Update Magnitude: 0.40269

Collected Steps per Second: 22,626.20378
Overall Steps per Second: 14,464.72912

Timestep Collection Time: 2.21080
Timestep Consumption Time: 1.24741
PPO Batch Consumption Time: 0.10326
Total Iteration Time: 3.45821

Cumulative Model Updates: 61,718
Cumulative Timesteps: 514,897,808

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 514897808...
Checkpoint 514897808 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,825.39557
Policy Entropy: 1.19877
Value Function Loss: 0.05554

Mean KL Divergence: 0.00486
SB3 Clip Fraction: 0.05699
Policy Update Magnitude: 0.19626
Value Function Update Magnitude: 0.41337

Collected Steps per Second: 22,611.44204
Overall Steps per Second: 14,672.81035

Timestep Collection Time: 2.21154
Timestep Consumption Time: 1.19654
PPO Batch Consumption Time: 0.09809
Total Iteration Time: 3.40807

Cumulative Model Updates: 61,724
Cumulative Timesteps: 514,947,814

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,762.91493
Policy Entropy: 1.19829
Value Function Loss: 0.05342

Mean KL Divergence: 0.00455
SB3 Clip Fraction: 0.05428
Policy Update Magnitude: 0.19311
Value Function Update Magnitude: 0.40095

Collected Steps per Second: 22,726.25438
Overall Steps per Second: 14,716.69436

Timestep Collection Time: 2.20054
Timestep Consumption Time: 1.19764
PPO Batch Consumption Time: 0.09624
Total Iteration Time: 3.39818

Cumulative Model Updates: 61,730
Cumulative Timesteps: 514,997,824

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 514997824...
Checkpoint 514997824 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,668.18486
Policy Entropy: 1.19688
Value Function Loss: 0.05843

Mean KL Divergence: 0.00530
SB3 Clip Fraction: 0.06284
Policy Update Magnitude: 0.19884
Value Function Update Magnitude: 0.38467

Collected Steps per Second: 22,074.31678
Overall Steps per Second: 14,311.81819

Timestep Collection Time: 2.26607
Timestep Consumption Time: 1.22908
PPO Batch Consumption Time: 0.10084
Total Iteration Time: 3.49515

Cumulative Model Updates: 61,736
Cumulative Timesteps: 515,047,846

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,185.16011
Policy Entropy: 1.19717
Value Function Loss: 0.06120

Mean KL Divergence: 0.00466
SB3 Clip Fraction: 0.05776
Policy Update Magnitude: 0.20573
Value Function Update Magnitude: 0.39396

Collected Steps per Second: 22,835.35490
Overall Steps per Second: 14,629.49146

Timestep Collection Time: 2.19046
Timestep Consumption Time: 1.22866
PPO Batch Consumption Time: 0.10066
Total Iteration Time: 3.41912

Cumulative Model Updates: 61,742
Cumulative Timesteps: 515,097,866

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 515097866...
Checkpoint 515097866 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,754.65876
Policy Entropy: 1.18992
Value Function Loss: 0.05873

Mean KL Divergence: 0.00544
SB3 Clip Fraction: 0.06478
Policy Update Magnitude: 0.21071
Value Function Update Magnitude: 0.40139

Collected Steps per Second: 22,462.85693
Overall Steps per Second: 14,635.05769

Timestep Collection Time: 2.22803
Timestep Consumption Time: 1.19170
PPO Batch Consumption Time: 0.09357
Total Iteration Time: 3.41973

Cumulative Model Updates: 61,748
Cumulative Timesteps: 515,147,914

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,161.86253
Policy Entropy: 1.19489
Value Function Loss: 0.06156

Mean KL Divergence: 0.00570
SB3 Clip Fraction: 0.06726
Policy Update Magnitude: 0.21554
Value Function Update Magnitude: 0.41760

Collected Steps per Second: 22,582.23267
Overall Steps per Second: 14,758.09539

Timestep Collection Time: 2.21528
Timestep Consumption Time: 1.17445
PPO Batch Consumption Time: 0.09381
Total Iteration Time: 3.38973

Cumulative Model Updates: 61,754
Cumulative Timesteps: 515,197,940

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 515197940...
Checkpoint 515197940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,154.30641
Policy Entropy: 1.21661
Value Function Loss: 0.06097

Mean KL Divergence: 0.00584
SB3 Clip Fraction: 0.06780
Policy Update Magnitude: 0.21644
Value Function Update Magnitude: 0.41576

Collected Steps per Second: 22,770.38121
Overall Steps per Second: 14,863.19938

Timestep Collection Time: 2.19689
Timestep Consumption Time: 1.16874
PPO Batch Consumption Time: 0.09381
Total Iteration Time: 3.36563

Cumulative Model Updates: 61,760
Cumulative Timesteps: 515,247,964

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,674.20284
Policy Entropy: 1.23242
Value Function Loss: 0.06205

Mean KL Divergence: 0.00556
SB3 Clip Fraction: 0.06705
Policy Update Magnitude: 0.22200
Value Function Update Magnitude: 0.37353

Collected Steps per Second: 22,836.58242
Overall Steps per Second: 14,778.45263

Timestep Collection Time: 2.19017
Timestep Consumption Time: 1.19422
PPO Batch Consumption Time: 0.09738
Total Iteration Time: 3.38439

Cumulative Model Updates: 61,766
Cumulative Timesteps: 515,297,980

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 515297980...
Checkpoint 515297980 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,105.27990
Policy Entropy: 1.22461
Value Function Loss: 0.06081

Mean KL Divergence: 0.00468
SB3 Clip Fraction: 0.05651
Policy Update Magnitude: 0.21783
Value Function Update Magnitude: 0.36749

Collected Steps per Second: 22,350.20515
Overall Steps per Second: 14,441.10840

Timestep Collection Time: 2.23729
Timestep Consumption Time: 1.22532
PPO Batch Consumption Time: 0.10260
Total Iteration Time: 3.46262

Cumulative Model Updates: 61,772
Cumulative Timesteps: 515,347,984

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,782.94923
Policy Entropy: 1.21347
Value Function Loss: 0.06014

Mean KL Divergence: 0.00441
SB3 Clip Fraction: 0.05324
Policy Update Magnitude: 0.20806
Value Function Update Magnitude: 0.37271

Collected Steps per Second: 22,746.23309
Overall Steps per Second: 14,455.25372

Timestep Collection Time: 2.19861
Timestep Consumption Time: 1.26104
PPO Batch Consumption Time: 0.10278
Total Iteration Time: 3.45964

Cumulative Model Updates: 61,778
Cumulative Timesteps: 515,397,994

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 515397994...
Checkpoint 515397994 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,543.74813
Policy Entropy: 1.21516
Value Function Loss: 0.06232

Mean KL Divergence: 0.00409
SB3 Clip Fraction: 0.04886
Policy Update Magnitude: 0.20007
Value Function Update Magnitude: 0.38551

Collected Steps per Second: 22,355.66758
Overall Steps per Second: 14,305.21393

Timestep Collection Time: 2.23755
Timestep Consumption Time: 1.25921
PPO Batch Consumption Time: 0.10274
Total Iteration Time: 3.49677

Cumulative Model Updates: 61,784
Cumulative Timesteps: 515,448,016

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,068.07330
Policy Entropy: 1.22274
Value Function Loss: 0.06333

Mean KL Divergence: 0.00455
SB3 Clip Fraction: 0.05480
Policy Update Magnitude: 0.19719
Value Function Update Magnitude: 0.40170

Collected Steps per Second: 22,664.14563
Overall Steps per Second: 14,474.78923

Timestep Collection Time: 2.20745
Timestep Consumption Time: 1.24890
PPO Batch Consumption Time: 0.10318
Total Iteration Time: 3.45635

Cumulative Model Updates: 61,790
Cumulative Timesteps: 515,498,046

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 515498046...
Checkpoint 515498046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,480.47533
Policy Entropy: 1.21673
Value Function Loss: 0.06494

Mean KL Divergence: 0.00464
SB3 Clip Fraction: 0.05526
Policy Update Magnitude: 0.20160
Value Function Update Magnitude: 0.41674

Collected Steps per Second: 22,586.47565
Overall Steps per Second: 14,669.39164

Timestep Collection Time: 2.21478
Timestep Consumption Time: 1.19532
PPO Batch Consumption Time: 0.09710
Total Iteration Time: 3.41009

Cumulative Model Updates: 61,796
Cumulative Timesteps: 515,548,070

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,707.71762
Policy Entropy: 1.23284
Value Function Loss: 0.06455

Mean KL Divergence: 0.00476
SB3 Clip Fraction: 0.05827
Policy Update Magnitude: 0.21689
Value Function Update Magnitude: 0.41955

Collected Steps per Second: 22,921.60710
Overall Steps per Second: 14,746.99531

Timestep Collection Time: 2.18309
Timestep Consumption Time: 1.21014
PPO Batch Consumption Time: 0.09653
Total Iteration Time: 3.39323

Cumulative Model Updates: 61,802
Cumulative Timesteps: 515,598,110

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 515598110...
Checkpoint 515598110 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,374.17209
Policy Entropy: 1.23622
Value Function Loss: 0.06482

Mean KL Divergence: 0.00530
SB3 Clip Fraction: 0.06378
Policy Update Magnitude: 0.21747
Value Function Update Magnitude: 0.40237

Collected Steps per Second: 22,369.57830
Overall Steps per Second: 14,454.10366

Timestep Collection Time: 2.23670
Timestep Consumption Time: 1.22488
PPO Batch Consumption Time: 0.10218
Total Iteration Time: 3.46158

Cumulative Model Updates: 61,808
Cumulative Timesteps: 515,648,144

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,124.35101
Policy Entropy: 1.22801
Value Function Loss: 0.06496

Mean KL Divergence: 0.00456
SB3 Clip Fraction: 0.05499
Policy Update Magnitude: 0.21241
Value Function Update Magnitude: 0.40652

Collected Steps per Second: 22,771.95337
Overall Steps per Second: 14,578.17582

Timestep Collection Time: 2.19568
Timestep Consumption Time: 1.23410
PPO Batch Consumption Time: 0.10175
Total Iteration Time: 3.42978

Cumulative Model Updates: 61,814
Cumulative Timesteps: 515,698,144

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 515698144...
Checkpoint 515698144 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,293.62899
Policy Entropy: 1.22032
Value Function Loss: 0.06009

Mean KL Divergence: 0.00579
SB3 Clip Fraction: 0.06793
Policy Update Magnitude: 0.20960
Value Function Update Magnitude: 0.41265

Collected Steps per Second: 22,445.65285
Overall Steps per Second: 14,581.97177

Timestep Collection Time: 2.22894
Timestep Consumption Time: 1.20201
PPO Batch Consumption Time: 0.09686
Total Iteration Time: 3.43095

Cumulative Model Updates: 61,820
Cumulative Timesteps: 515,748,174

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,233.81121
Policy Entropy: 1.22231
Value Function Loss: 0.04922

Mean KL Divergence: 0.00614
SB3 Clip Fraction: 0.07073
Policy Update Magnitude: 0.19529
Value Function Update Magnitude: 0.39979

Collected Steps per Second: 22,920.25144
Overall Steps per Second: 14,774.41081

Timestep Collection Time: 2.18348
Timestep Consumption Time: 1.20386
PPO Batch Consumption Time: 0.09850
Total Iteration Time: 3.38734

Cumulative Model Updates: 61,826
Cumulative Timesteps: 515,798,220

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 515798220...
Checkpoint 515798220 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,143.95494
Policy Entropy: 1.23917
Value Function Loss: 0.05276

Mean KL Divergence: 0.00529
SB3 Clip Fraction: 0.06026
Policy Update Magnitude: 0.19249
Value Function Update Magnitude: 0.37617

Collected Steps per Second: 22,471.42332
Overall Steps per Second: 14,769.63330

Timestep Collection Time: 2.22505
Timestep Consumption Time: 1.16028
PPO Batch Consumption Time: 0.09238
Total Iteration Time: 3.38532

Cumulative Model Updates: 61,832
Cumulative Timesteps: 515,848,220

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,107.01926
Policy Entropy: 1.25022
Value Function Loss: 0.04899

Mean KL Divergence: 0.00441
SB3 Clip Fraction: 0.05381
Policy Update Magnitude: 0.19106
Value Function Update Magnitude: 0.35321

Collected Steps per Second: 22,867.16381
Overall Steps per Second: 14,787.96666

Timestep Collection Time: 2.18742
Timestep Consumption Time: 1.19506
PPO Batch Consumption Time: 0.09658
Total Iteration Time: 3.38248

Cumulative Model Updates: 61,838
Cumulative Timesteps: 515,898,240

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 515898240...
Checkpoint 515898240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,685.97495
Policy Entropy: 1.24230
Value Function Loss: 0.04994

Mean KL Divergence: 0.00438
SB3 Clip Fraction: 0.05347
Policy Update Magnitude: 0.18653
Value Function Update Magnitude: 0.33937

Collected Steps per Second: 22,282.21631
Overall Steps per Second: 14,061.00545

Timestep Collection Time: 2.24448
Timestep Consumption Time: 1.31231
PPO Batch Consumption Time: 0.10820
Total Iteration Time: 3.55679

Cumulative Model Updates: 61,844
Cumulative Timesteps: 515,948,252

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,090.07783
Policy Entropy: 1.25673
Value Function Loss: 0.05173

Mean KL Divergence: 0.00388
SB3 Clip Fraction: 0.04659
Policy Update Magnitude: 0.19015
Value Function Update Magnitude: 0.33593

Collected Steps per Second: 22,748.60567
Overall Steps per Second: 14,532.81582

Timestep Collection Time: 2.19890
Timestep Consumption Time: 1.24310
PPO Batch Consumption Time: 0.09852
Total Iteration Time: 3.44200

Cumulative Model Updates: 61,850
Cumulative Timesteps: 515,998,274

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 515998274...
Checkpoint 515998274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,711.01808
Policy Entropy: 1.24922
Value Function Loss: 0.05807

Mean KL Divergence: 0.00449
SB3 Clip Fraction: 0.05291
Policy Update Magnitude: 0.20139
Value Function Update Magnitude: 0.35107

Collected Steps per Second: 22,481.19024
Overall Steps per Second: 14,327.18433

Timestep Collection Time: 2.22488
Timestep Consumption Time: 1.26624
PPO Batch Consumption Time: 0.10409
Total Iteration Time: 3.49113

Cumulative Model Updates: 61,856
Cumulative Timesteps: 516,048,292

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,973.90024
Policy Entropy: 1.23881
Value Function Loss: 0.06549

Mean KL Divergence: 0.00467
SB3 Clip Fraction: 0.05603
Policy Update Magnitude: 0.21093
Value Function Update Magnitude: 0.37335

Collected Steps per Second: 22,939.79146
Overall Steps per Second: 14,641.53699

Timestep Collection Time: 2.18058
Timestep Consumption Time: 1.23587
PPO Batch Consumption Time: 0.09828
Total Iteration Time: 3.41644

Cumulative Model Updates: 61,862
Cumulative Timesteps: 516,098,314

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 516098314...
Checkpoint 516098314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,622.81665
Policy Entropy: 1.22564
Value Function Loss: 0.06494

Mean KL Divergence: 0.00493
SB3 Clip Fraction: 0.05895
Policy Update Magnitude: 0.22223
Value Function Update Magnitude: 0.39358

Collected Steps per Second: 22,384.04389
Overall Steps per Second: 14,748.39705

Timestep Collection Time: 2.23445
Timestep Consumption Time: 1.15684
PPO Batch Consumption Time: 0.09152
Total Iteration Time: 3.39128

Cumulative Model Updates: 61,868
Cumulative Timesteps: 516,148,330

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,166.52417
Policy Entropy: 1.22405
Value Function Loss: 0.08147

Mean KL Divergence: 0.00480
SB3 Clip Fraction: 0.05802
Policy Update Magnitude: 0.22952
Value Function Update Magnitude: 0.40837

Collected Steps per Second: 22,736.46032
Overall Steps per Second: 14,787.13374

Timestep Collection Time: 2.19911
Timestep Consumption Time: 1.18221
PPO Batch Consumption Time: 0.09525
Total Iteration Time: 3.38132

Cumulative Model Updates: 61,874
Cumulative Timesteps: 516,198,330

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 516198330...
Checkpoint 516198330 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,837.00769
Policy Entropy: 1.23134
Value Function Loss: 0.08076

Mean KL Divergence: 0.00539
SB3 Clip Fraction: 0.06248
Policy Update Magnitude: 0.23864
Value Function Update Magnitude: 0.43537

Collected Steps per Second: 22,750.62314
Overall Steps per Second: 14,841.60843

Timestep Collection Time: 2.19774
Timestep Consumption Time: 1.17117
PPO Batch Consumption Time: 0.09429
Total Iteration Time: 3.36891

Cumulative Model Updates: 61,880
Cumulative Timesteps: 516,248,330

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,630.63347
Policy Entropy: 1.24321
Value Function Loss: 0.07751

Mean KL Divergence: 0.00567
SB3 Clip Fraction: 0.06876
Policy Update Magnitude: 0.23068
Value Function Update Magnitude: 0.43086

Collected Steps per Second: 22,923.68001
Overall Steps per Second: 14,786.98798

Timestep Collection Time: 2.18159
Timestep Consumption Time: 1.20044
PPO Batch Consumption Time: 0.09752
Total Iteration Time: 3.38203

Cumulative Model Updates: 61,886
Cumulative Timesteps: 516,298,340

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 516298340...
Checkpoint 516298340 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,262.36975
Policy Entropy: 1.26230
Value Function Loss: 0.06695

Mean KL Divergence: 0.00612
SB3 Clip Fraction: 0.07166
Policy Update Magnitude: 0.22585
Value Function Update Magnitude: 0.42460

Collected Steps per Second: 22,599.82300
Overall Steps per Second: 14,808.15453

Timestep Collection Time: 2.21258
Timestep Consumption Time: 1.16420
PPO Batch Consumption Time: 0.09352
Total Iteration Time: 3.37679

Cumulative Model Updates: 61,892
Cumulative Timesteps: 516,348,344

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,481.63601
Policy Entropy: 1.27427
Value Function Loss: 0.06187

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.08838
Policy Update Magnitude: 0.21373
Value Function Update Magnitude: 0.39646

Collected Steps per Second: 23,054.16018
Overall Steps per Second: 14,828.67085

Timestep Collection Time: 2.17037
Timestep Consumption Time: 1.20391
PPO Batch Consumption Time: 0.09840
Total Iteration Time: 3.37427

Cumulative Model Updates: 61,898
Cumulative Timesteps: 516,398,380

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 516398380...
Checkpoint 516398380 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,655.13258
Policy Entropy: 1.26249
Value Function Loss: 0.05811

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.10258
Policy Update Magnitude: 0.18880
Value Function Update Magnitude: 0.37148

Collected Steps per Second: 22,533.19647
Overall Steps per Second: 14,770.47526

Timestep Collection Time: 2.22019
Timestep Consumption Time: 1.16684
PPO Batch Consumption Time: 0.09362
Total Iteration Time: 3.38703

Cumulative Model Updates: 61,904
Cumulative Timesteps: 516,448,408

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,246.44705
Policy Entropy: 1.26883
Value Function Loss: 0.05911

Mean KL Divergence: 0.00534
SB3 Clip Fraction: 0.06455
Policy Update Magnitude: 0.19300
Value Function Update Magnitude: 0.39040

Collected Steps per Second: 22,623.45507
Overall Steps per Second: 14,747.80307

Timestep Collection Time: 2.21089
Timestep Consumption Time: 1.18066
PPO Batch Consumption Time: 0.09320
Total Iteration Time: 3.39156

Cumulative Model Updates: 61,910
Cumulative Timesteps: 516,498,426

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 516498426...
Checkpoint 516498426 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,599.41308
Policy Entropy: 1.25320
Value Function Loss: 0.05965

Mean KL Divergence: 0.00543
SB3 Clip Fraction: 0.06673
Policy Update Magnitude: 0.20088
Value Function Update Magnitude: 0.38728

Collected Steps per Second: 22,710.36127
Overall Steps per Second: 14,868.50427

Timestep Collection Time: 2.20278
Timestep Consumption Time: 1.16178
PPO Batch Consumption Time: 0.09341
Total Iteration Time: 3.36456

Cumulative Model Updates: 61,916
Cumulative Timesteps: 516,548,452

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,529.32962
Policy Entropy: 1.24652
Value Function Loss: 0.06012

Mean KL Divergence: 0.00572
SB3 Clip Fraction: 0.06832
Policy Update Magnitude: 0.20252
Value Function Update Magnitude: 0.38258

Collected Steps per Second: 22,659.96360
Overall Steps per Second: 14,690.47975

Timestep Collection Time: 2.20671
Timestep Consumption Time: 1.19713
PPO Batch Consumption Time: 0.09259
Total Iteration Time: 3.40384

Cumulative Model Updates: 61,922
Cumulative Timesteps: 516,598,456

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 516598456...
Checkpoint 516598456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,448.33616
Policy Entropy: 1.23197
Value Function Loss: 0.05758

Mean KL Divergence: 0.00577
SB3 Clip Fraction: 0.06636
Policy Update Magnitude: 0.19369
Value Function Update Magnitude: 0.37179

Collected Steps per Second: 22,450.31873
Overall Steps per Second: 14,292.64779

Timestep Collection Time: 2.22821
Timestep Consumption Time: 1.27177
PPO Batch Consumption Time: 0.10450
Total Iteration Time: 3.49998

Cumulative Model Updates: 61,928
Cumulative Timesteps: 516,648,480

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,794.90108
Policy Entropy: 1.23368
Value Function Loss: 0.06137

Mean KL Divergence: 0.00532
SB3 Clip Fraction: 0.06368
Policy Update Magnitude: 0.19529
Value Function Update Magnitude: 0.35951

Collected Steps per Second: 23,080.33061
Overall Steps per Second: 14,589.07942

Timestep Collection Time: 2.16669
Timestep Consumption Time: 1.26108
PPO Batch Consumption Time: 0.10088
Total Iteration Time: 3.42777

Cumulative Model Updates: 61,934
Cumulative Timesteps: 516,698,488

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 516698488...
Checkpoint 516698488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,829.60035
Policy Entropy: 1.25057
Value Function Loss: 0.06721

Mean KL Divergence: 0.00504
SB3 Clip Fraction: 0.06270
Policy Update Magnitude: 0.20985
Value Function Update Magnitude: 0.37768

Collected Steps per Second: 22,305.33124
Overall Steps per Second: 14,396.02045

Timestep Collection Time: 2.24305
Timestep Consumption Time: 1.23235
PPO Batch Consumption Time: 0.10223
Total Iteration Time: 3.47540

Cumulative Model Updates: 61,940
Cumulative Timesteps: 516,748,520

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,700.94938
Policy Entropy: 1.25350
Value Function Loss: 0.06690

Mean KL Divergence: 0.00482
SB3 Clip Fraction: 0.05991
Policy Update Magnitude: 0.21581
Value Function Update Magnitude: 0.38836

Collected Steps per Second: 22,596.90730
Overall Steps per Second: 14,604.39954

Timestep Collection Time: 2.21296
Timestep Consumption Time: 1.21108
PPO Batch Consumption Time: 0.10113
Total Iteration Time: 3.42404

Cumulative Model Updates: 61,946
Cumulative Timesteps: 516,798,526

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 516798526...
Checkpoint 516798526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,647.13672
Policy Entropy: 1.26448
Value Function Loss: 0.06064

Mean KL Divergence: 0.00493
SB3 Clip Fraction: 0.05989
Policy Update Magnitude: 0.20783
Value Function Update Magnitude: 0.37505

Collected Steps per Second: 22,483.46611
Overall Steps per Second: 14,460.56733

Timestep Collection Time: 2.22386
Timestep Consumption Time: 1.23382
PPO Batch Consumption Time: 0.09688
Total Iteration Time: 3.45768

Cumulative Model Updates: 61,952
Cumulative Timesteps: 516,848,526

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,592.93121
Policy Entropy: 1.26159
Value Function Loss: 0.05625

Mean KL Divergence: 0.00442
SB3 Clip Fraction: 0.05278
Policy Update Magnitude: 0.20094
Value Function Update Magnitude: 0.35684

Collected Steps per Second: 22,410.66246
Overall Steps per Second: 14,739.19463

Timestep Collection Time: 2.23117
Timestep Consumption Time: 1.16128
PPO Batch Consumption Time: 0.09123
Total Iteration Time: 3.39245

Cumulative Model Updates: 61,958
Cumulative Timesteps: 516,898,528

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 516898528...
Checkpoint 516898528 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,187.57085
Policy Entropy: 1.26928
Value Function Loss: 0.06167

Mean KL Divergence: 0.00609
SB3 Clip Fraction: 0.07028
Policy Update Magnitude: 0.20016
Value Function Update Magnitude: 0.36044

Collected Steps per Second: 22,307.38041
Overall Steps per Second: 14,412.55151

Timestep Collection Time: 2.24213
Timestep Consumption Time: 1.22818
PPO Batch Consumption Time: 0.10155
Total Iteration Time: 3.47031

Cumulative Model Updates: 61,964
Cumulative Timesteps: 516,948,544

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,520.70140
Policy Entropy: 1.27089
Value Function Loss: 0.06455

Mean KL Divergence: 0.00644
SB3 Clip Fraction: 0.07620
Policy Update Magnitude: 0.20489
Value Function Update Magnitude: 0.37902

Collected Steps per Second: 23,200.50847
Overall Steps per Second: 14,855.55345

Timestep Collection Time: 2.15547
Timestep Consumption Time: 1.21081
PPO Batch Consumption Time: 0.10085
Total Iteration Time: 3.36628

Cumulative Model Updates: 61,970
Cumulative Timesteps: 516,998,552

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 516998552...
Checkpoint 516998552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,274.31919
Policy Entropy: 1.27539
Value Function Loss: 0.06620

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.10004
Policy Update Magnitude: 0.19107
Value Function Update Magnitude: 0.38134

Collected Steps per Second: 22,098.83644
Overall Steps per Second: 14,443.43815

Timestep Collection Time: 2.26392
Timestep Consumption Time: 1.19994
PPO Batch Consumption Time: 0.09820
Total Iteration Time: 3.46386

Cumulative Model Updates: 61,976
Cumulative Timesteps: 517,048,582

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,182.11657
Policy Entropy: 1.25885
Value Function Loss: 0.06266

Mean KL Divergence: 0.00664
SB3 Clip Fraction: 0.07956
Policy Update Magnitude: 0.19275
Value Function Update Magnitude: 0.38415

Collected Steps per Second: 22,742.18265
Overall Steps per Second: 14,712.82480

Timestep Collection Time: 2.19988
Timestep Consumption Time: 1.20056
PPO Batch Consumption Time: 0.09746
Total Iteration Time: 3.40043

Cumulative Model Updates: 61,982
Cumulative Timesteps: 517,098,612

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 517098612...
Checkpoint 517098612 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,692.17457
Policy Entropy: 1.26067
Value Function Loss: 0.05846

Mean KL Divergence: 0.00529
SB3 Clip Fraction: 0.06207
Policy Update Magnitude: 0.20013
Value Function Update Magnitude: 0.37978

Collected Steps per Second: 22,423.41306
Overall Steps per Second: 14,326.52893

Timestep Collection Time: 2.22981
Timestep Consumption Time: 1.26022
PPO Batch Consumption Time: 0.10313
Total Iteration Time: 3.49003

Cumulative Model Updates: 61,988
Cumulative Timesteps: 517,148,612

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,882.58077
Policy Entropy: 1.25797
Value Function Loss: 0.05221

Mean KL Divergence: 0.00461
SB3 Clip Fraction: 0.05499
Policy Update Magnitude: 0.20254
Value Function Update Magnitude: 0.35544

Collected Steps per Second: 23,057.11580
Overall Steps per Second: 14,515.03513

Timestep Collection Time: 2.16948
Timestep Consumption Time: 1.27674
PPO Batch Consumption Time: 0.10407
Total Iteration Time: 3.44622

Cumulative Model Updates: 61,994
Cumulative Timesteps: 517,198,634

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 517198634...
Checkpoint 517198634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,508.41839
Policy Entropy: 1.26924
Value Function Loss: 0.06203

Mean KL Divergence: 0.00611
SB3 Clip Fraction: 0.07132
Policy Update Magnitude: 0.19653
Value Function Update Magnitude: 0.33382

Collected Steps per Second: 22,222.41284
Overall Steps per Second: 14,344.68652

Timestep Collection Time: 2.24998
Timestep Consumption Time: 1.23563
PPO Batch Consumption Time: 0.10242
Total Iteration Time: 3.48561

Cumulative Model Updates: 62,000
Cumulative Timesteps: 517,248,634

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,190.07059
Policy Entropy: 1.26987
Value Function Loss: 0.06702

Mean KL Divergence: 0.00577
SB3 Clip Fraction: 0.06805
Policy Update Magnitude: 0.20071
Value Function Update Magnitude: 0.34651

Collected Steps per Second: 22,915.91481
Overall Steps per Second: 14,743.19798

Timestep Collection Time: 2.18320
Timestep Consumption Time: 1.21023
PPO Batch Consumption Time: 0.10052
Total Iteration Time: 3.39343

Cumulative Model Updates: 62,006
Cumulative Timesteps: 517,298,664

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 517298664...
Checkpoint 517298664 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,457.11216
Policy Entropy: 1.26892
Value Function Loss: 0.06266

Mean KL Divergence: 0.00600
SB3 Clip Fraction: 0.07043
Policy Update Magnitude: 0.20355
Value Function Update Magnitude: 0.38307

Collected Steps per Second: 22,463.76610
Overall Steps per Second: 14,510.59752

Timestep Collection Time: 2.22732
Timestep Consumption Time: 1.22078
PPO Batch Consumption Time: 0.10178
Total Iteration Time: 3.44810

Cumulative Model Updates: 62,012
Cumulative Timesteps: 517,348,698

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,614.51893
Policy Entropy: 1.28316
Value Function Loss: 0.06093

Mean KL Divergence: 0.00566
SB3 Clip Fraction: 0.06752
Policy Update Magnitude: 0.19933
Value Function Update Magnitude: 0.37957

Collected Steps per Second: 23,026.97222
Overall Steps per Second: 14,744.64569

Timestep Collection Time: 2.17284
Timestep Consumption Time: 1.22052
PPO Batch Consumption Time: 0.10158
Total Iteration Time: 3.39337

Cumulative Model Updates: 62,018
Cumulative Timesteps: 517,398,732

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 517398732...
Checkpoint 517398732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,309.32571
Policy Entropy: 1.27915
Value Function Loss: 0.06161

Mean KL Divergence: 0.00516
SB3 Clip Fraction: 0.06250
Policy Update Magnitude: 0.19722
Value Function Update Magnitude: 0.37839

Collected Steps per Second: 22,687.53679
Overall Steps per Second: 14,671.99042

Timestep Collection Time: 2.20438
Timestep Consumption Time: 1.20429
PPO Batch Consumption Time: 0.09450
Total Iteration Time: 3.40867

Cumulative Model Updates: 62,024
Cumulative Timesteps: 517,448,744

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,174.36932
Policy Entropy: 1.27495
Value Function Loss: 0.06237

Mean KL Divergence: 0.00546
SB3 Clip Fraction: 0.06649
Policy Update Magnitude: 0.20313
Value Function Update Magnitude: 0.39132

Collected Steps per Second: 22,327.10082
Overall Steps per Second: 14,287.87943

Timestep Collection Time: 2.23952
Timestep Consumption Time: 1.26009
PPO Batch Consumption Time: 0.10270
Total Iteration Time: 3.49961

Cumulative Model Updates: 62,030
Cumulative Timesteps: 517,498,746

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 517498746...
Checkpoint 517498746 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,632.15378
Policy Entropy: 1.28696
Value Function Loss: 0.05951

Mean KL Divergence: 0.00503
SB3 Clip Fraction: 0.05956
Policy Update Magnitude: 0.20754
Value Function Update Magnitude: 0.41821

Collected Steps per Second: 22,370.96052
Overall Steps per Second: 14,529.61736

Timestep Collection Time: 2.23638
Timestep Consumption Time: 1.20693
PPO Batch Consumption Time: 0.09727
Total Iteration Time: 3.44331

Cumulative Model Updates: 62,036
Cumulative Timesteps: 517,548,776

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,747.22603
Policy Entropy: 1.29920
Value Function Loss: 0.05301

Mean KL Divergence: 0.00616
SB3 Clip Fraction: 0.07192
Policy Update Magnitude: 0.20464
Value Function Update Magnitude: 0.40702

Collected Steps per Second: 22,955.89913
Overall Steps per Second: 14,768.87621

Timestep Collection Time: 2.17966
Timestep Consumption Time: 1.20828
PPO Batch Consumption Time: 0.09884
Total Iteration Time: 3.38794

Cumulative Model Updates: 62,042
Cumulative Timesteps: 517,598,812

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 517598812...
Checkpoint 517598812 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,469.67761
Policy Entropy: 1.29168
Value Function Loss: 0.05616

Mean KL Divergence: 0.00671
SB3 Clip Fraction: 0.07693
Policy Update Magnitude: 0.19603
Value Function Update Magnitude: 0.37839

Collected Steps per Second: 22,611.78403
Overall Steps per Second: 14,406.46914

Timestep Collection Time: 2.21177
Timestep Consumption Time: 1.25973
PPO Batch Consumption Time: 0.10259
Total Iteration Time: 3.47150

Cumulative Model Updates: 62,048
Cumulative Timesteps: 517,648,824

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,030.32390
Policy Entropy: 1.27457
Value Function Loss: 0.06034

Mean KL Divergence: 0.00676
SB3 Clip Fraction: 0.07660
Policy Update Magnitude: 0.18958
Value Function Update Magnitude: 0.37121

Collected Steps per Second: 22,761.72019
Overall Steps per Second: 14,484.69525

Timestep Collection Time: 2.19729
Timestep Consumption Time: 1.25560
PPO Batch Consumption Time: 0.10290
Total Iteration Time: 3.45289

Cumulative Model Updates: 62,054
Cumulative Timesteps: 517,698,838

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 517698838...
Checkpoint 517698838 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,405.82693
Policy Entropy: 1.25646
Value Function Loss: 0.07188

Mean KL Divergence: 0.00727
SB3 Clip Fraction: 0.08331
Policy Update Magnitude: 0.19386
Value Function Update Magnitude: 0.40618

Collected Steps per Second: 22,760.96109
Overall Steps per Second: 14,657.73389

Timestep Collection Time: 2.19789
Timestep Consumption Time: 1.21506
PPO Batch Consumption Time: 0.09537
Total Iteration Time: 3.41294

Cumulative Model Updates: 62,060
Cumulative Timesteps: 517,748,864

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,860.33744
Policy Entropy: 1.26651
Value Function Loss: 0.06596

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.08907
Policy Update Magnitude: 0.19646
Value Function Update Magnitude: 0.42784

Collected Steps per Second: 22,330.84687
Overall Steps per Second: 14,369.12933

Timestep Collection Time: 2.24013
Timestep Consumption Time: 1.24122
PPO Batch Consumption Time: 0.10099
Total Iteration Time: 3.48135

Cumulative Model Updates: 62,066
Cumulative Timesteps: 517,798,888

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 517798888...
Checkpoint 517798888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,551.57682
Policy Entropy: 1.26122
Value Function Loss: 0.05923

Mean KL Divergence: 0.01329
SB3 Clip Fraction: 0.12124
Policy Update Magnitude: 0.18348
Value Function Update Magnitude: 0.40673

Collected Steps per Second: 22,235.28030
Overall Steps per Second: 14,428.79220

Timestep Collection Time: 2.25012
Timestep Consumption Time: 1.21739
PPO Batch Consumption Time: 0.09595
Total Iteration Time: 3.46751

Cumulative Model Updates: 62,072
Cumulative Timesteps: 517,848,920

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,762.26725
Policy Entropy: 1.26440
Value Function Loss: 0.05783

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.08904
Policy Update Magnitude: 0.17158
Value Function Update Magnitude: 0.38104

Collected Steps per Second: 22,761.26336
Overall Steps per Second: 14,707.13254

Timestep Collection Time: 2.19733
Timestep Consumption Time: 1.20333
PPO Batch Consumption Time: 0.09790
Total Iteration Time: 3.40066

Cumulative Model Updates: 62,078
Cumulative Timesteps: 517,898,934

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 517898934...
Checkpoint 517898934 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,755.25256
Policy Entropy: 1.25532
Value Function Loss: 0.05933

Mean KL Divergence: 0.00608
SB3 Clip Fraction: 0.07063
Policy Update Magnitude: 0.18677
Value Function Update Magnitude: 0.38621

Collected Steps per Second: 22,538.48853
Overall Steps per Second: 14,351.83989

Timestep Collection Time: 2.21896
Timestep Consumption Time: 1.26575
PPO Batch Consumption Time: 0.10233
Total Iteration Time: 3.48471

Cumulative Model Updates: 62,084
Cumulative Timesteps: 517,948,946

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,288.86463
Policy Entropy: 1.24761
Value Function Loss: 0.06886

Mean KL Divergence: 0.00652
SB3 Clip Fraction: 0.07473
Policy Update Magnitude: 0.19953
Value Function Update Magnitude: 0.40541

Collected Steps per Second: 22,864.51541
Overall Steps per Second: 14,530.50203

Timestep Collection Time: 2.18819
Timestep Consumption Time: 1.25505
PPO Batch Consumption Time: 0.10366
Total Iteration Time: 3.44324

Cumulative Model Updates: 62,090
Cumulative Timesteps: 517,998,978

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 517998978...
Checkpoint 517998978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,925.77955
Policy Entropy: 1.26021
Value Function Loss: 0.06662

Mean KL Divergence: 0.00595
SB3 Clip Fraction: 0.06988
Policy Update Magnitude: 0.19723
Value Function Update Magnitude: 0.41666

Collected Steps per Second: 22,396.20610
Overall Steps per Second: 14,653.57669

Timestep Collection Time: 2.23457
Timestep Consumption Time: 1.18070
PPO Batch Consumption Time: 0.09238
Total Iteration Time: 3.41528

Cumulative Model Updates: 62,096
Cumulative Timesteps: 518,049,024

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,878.95587
Policy Entropy: 1.26154
Value Function Loss: 0.07300

Mean KL Divergence: 0.00545
SB3 Clip Fraction: 0.06403
Policy Update Magnitude: 0.20004
Value Function Update Magnitude: 0.41065

Collected Steps per Second: 22,734.25262
Overall Steps per Second: 14,797.97322

Timestep Collection Time: 2.19950
Timestep Consumption Time: 1.17961
PPO Batch Consumption Time: 0.09466
Total Iteration Time: 3.37911

Cumulative Model Updates: 62,102
Cumulative Timesteps: 518,099,028

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 518099028...
Checkpoint 518099028 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,869.41954
Policy Entropy: 1.25313
Value Function Loss: 0.06980

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.09295
Policy Update Magnitude: 0.19239
Value Function Update Magnitude: 0.40424

Collected Steps per Second: 22,393.01145
Overall Steps per Second: 14,398.31755

Timestep Collection Time: 2.23364
Timestep Consumption Time: 1.24023
PPO Batch Consumption Time: 0.10321
Total Iteration Time: 3.47388

Cumulative Model Updates: 62,108
Cumulative Timesteps: 518,149,046

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,834.16614
Policy Entropy: 1.25338
Value Function Loss: 0.06995

Mean KL Divergence: 0.01088
SB3 Clip Fraction: 0.09469
Policy Update Magnitude: 0.18937
Value Function Update Magnitude: 0.39468

Collected Steps per Second: 22,850.80231
Overall Steps per Second: 14,658.12624

Timestep Collection Time: 2.18854
Timestep Consumption Time: 1.22321
PPO Batch Consumption Time: 0.10156
Total Iteration Time: 3.41176

Cumulative Model Updates: 62,114
Cumulative Timesteps: 518,199,056

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 518199056...
Checkpoint 518199056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,754.44352
Policy Entropy: 1.24999
Value Function Loss: 0.06701

Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.08395
Policy Update Magnitude: 0.19337
Value Function Update Magnitude: 0.38181

Collected Steps per Second: 22,643.58591
Overall Steps per Second: 14,636.71997

Timestep Collection Time: 2.20875
Timestep Consumption Time: 1.20827
PPO Batch Consumption Time: 0.09960
Total Iteration Time: 3.41702

Cumulative Model Updates: 62,120
Cumulative Timesteps: 518,249,070

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,055.00481
Policy Entropy: 1.26555
Value Function Loss: 0.06769

Mean KL Divergence: 0.00560
SB3 Clip Fraction: 0.06430
Policy Update Magnitude: 0.20631
Value Function Update Magnitude: 0.40814

Collected Steps per Second: 22,944.91495
Overall Steps per Second: 14,713.75575

Timestep Collection Time: 2.17931
Timestep Consumption Time: 1.21915
PPO Batch Consumption Time: 0.09926
Total Iteration Time: 3.39845

Cumulative Model Updates: 62,126
Cumulative Timesteps: 518,299,074

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 518299074...
Checkpoint 518299074 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,084.59320
Policy Entropy: 1.25161
Value Function Loss: 0.06717

Mean KL Divergence: 0.00570
SB3 Clip Fraction: 0.06489
Policy Update Magnitude: 0.20667
Value Function Update Magnitude: 0.41730

Collected Steps per Second: 22,737.82042
Overall Steps per Second: 14,749.05866

Timestep Collection Time: 2.20083
Timestep Consumption Time: 1.19207
PPO Batch Consumption Time: 0.09309
Total Iteration Time: 3.39289

Cumulative Model Updates: 62,132
Cumulative Timesteps: 518,349,116

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,429.79542
Policy Entropy: 1.25205
Value Function Loss: 0.06667

Mean KL Divergence: 0.00483
SB3 Clip Fraction: 0.05725
Policy Update Magnitude: 0.20923
Value Function Update Magnitude: 0.40455

Collected Steps per Second: 22,783.44077
Overall Steps per Second: 14,789.74763

Timestep Collection Time: 2.19581
Timestep Consumption Time: 1.18681
PPO Batch Consumption Time: 0.09446
Total Iteration Time: 3.38261

Cumulative Model Updates: 62,138
Cumulative Timesteps: 518,399,144

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 518399144...
Checkpoint 518399144 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,202.77763
Policy Entropy: 1.26039
Value Function Loss: 0.06642

Mean KL Divergence: 0.00518
SB3 Clip Fraction: 0.06235
Policy Update Magnitude: 0.20383
Value Function Update Magnitude: 0.41848

Collected Steps per Second: 22,563.25426
Overall Steps per Second: 14,475.94098

Timestep Collection Time: 2.21644
Timestep Consumption Time: 1.23826
PPO Batch Consumption Time: 0.10267
Total Iteration Time: 3.45470

Cumulative Model Updates: 62,144
Cumulative Timesteps: 518,449,154

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,384.90922
Policy Entropy: 1.28171
Value Function Loss: 0.06671

Mean KL Divergence: 0.00495
SB3 Clip Fraction: 0.05838
Policy Update Magnitude: 0.20905
Value Function Update Magnitude: 0.40260

Collected Steps per Second: 23,000.19798
Overall Steps per Second: 14,823.19347

Timestep Collection Time: 2.17494
Timestep Consumption Time: 1.19977
PPO Batch Consumption Time: 0.10054
Total Iteration Time: 3.37471

Cumulative Model Updates: 62,150
Cumulative Timesteps: 518,499,178

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 518499178...
Checkpoint 518499178 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,717.43206
Policy Entropy: 1.26708
Value Function Loss: 0.06967

Mean KL Divergence: 0.00477
SB3 Clip Fraction: 0.05700
Policy Update Magnitude: 0.21028
Value Function Update Magnitude: 0.41996

Collected Steps per Second: 22,281.25093
Overall Steps per Second: 14,428.05962

Timestep Collection Time: 2.24422
Timestep Consumption Time: 1.22153
PPO Batch Consumption Time: 0.10202
Total Iteration Time: 3.46575

Cumulative Model Updates: 62,156
Cumulative Timesteps: 518,549,182

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,750.02852
Policy Entropy: 1.26732
Value Function Loss: 0.06967

Mean KL Divergence: 0.00477
SB3 Clip Fraction: 0.05613
Policy Update Magnitude: 0.21226
Value Function Update Magnitude: 0.43302

Collected Steps per Second: 23,038.97560
Overall Steps per Second: 14,707.48750

Timestep Collection Time: 2.17041
Timestep Consumption Time: 1.22949
PPO Batch Consumption Time: 0.10015
Total Iteration Time: 3.39990

Cumulative Model Updates: 62,162
Cumulative Timesteps: 518,599,186

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 518599186...
Checkpoint 518599186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,950.03641
Policy Entropy: 1.26727
Value Function Loss: 0.07271

Mean KL Divergence: 0.00402
SB3 Clip Fraction: 0.04738
Policy Update Magnitude: 0.21849
Value Function Update Magnitude: 0.43385

Collected Steps per Second: 22,940.23818
Overall Steps per Second: 14,760.05271

Timestep Collection Time: 2.18176
Timestep Consumption Time: 1.20915
PPO Batch Consumption Time: 0.09484
Total Iteration Time: 3.39091

Cumulative Model Updates: 62,168
Cumulative Timesteps: 518,649,236

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,619.10524
Policy Entropy: 1.27564
Value Function Loss: 0.06863

Mean KL Divergence: 0.00613
SB3 Clip Fraction: 0.07207
Policy Update Magnitude: 0.21974
Value Function Update Magnitude: 0.41379

Collected Steps per Second: 22,761.50131
Overall Steps per Second: 14,743.80451

Timestep Collection Time: 2.19766
Timestep Consumption Time: 1.19509
PPO Batch Consumption Time: 0.09233
Total Iteration Time: 3.39275

Cumulative Model Updates: 62,174
Cumulative Timesteps: 518,699,258

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 518699258...
Checkpoint 518699258 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,041.72708
Policy Entropy: 1.28116
Value Function Loss: 0.06884

Mean KL Divergence: 0.00576
SB3 Clip Fraction: 0.06929
Policy Update Magnitude: 0.21775
Value Function Update Magnitude: 0.40153

Collected Steps per Second: 22,410.95031
Overall Steps per Second: 14,385.47674

Timestep Collection Time: 2.23105
Timestep Consumption Time: 1.24468
PPO Batch Consumption Time: 0.10303
Total Iteration Time: 3.47573

Cumulative Model Updates: 62,180
Cumulative Timesteps: 518,749,258

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,768.76281
Policy Entropy: 1.26652
Value Function Loss: 0.06879

Mean KL Divergence: 0.00722
SB3 Clip Fraction: 0.08075
Policy Update Magnitude: 0.21196
Value Function Update Magnitude: 0.39188

Collected Steps per Second: 22,838.01912
Overall Steps per Second: 14,537.89466

Timestep Collection Time: 2.18977
Timestep Consumption Time: 1.25021
PPO Batch Consumption Time: 0.10451
Total Iteration Time: 3.43998

Cumulative Model Updates: 62,186
Cumulative Timesteps: 518,799,268

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 518799268...
Checkpoint 518799268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,378.38941
Policy Entropy: 1.26513
Value Function Loss: 0.06500

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.09547
Policy Update Magnitude: 0.19400
Value Function Update Magnitude: 0.37831

Collected Steps per Second: 22,430.89942
Overall Steps per Second: 14,654.41503

Timestep Collection Time: 2.23121
Timestep Consumption Time: 1.18401
PPO Batch Consumption Time: 0.09431
Total Iteration Time: 3.41522

Cumulative Model Updates: 62,192
Cumulative Timesteps: 518,849,316

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,814.75871
Policy Entropy: 1.25945
Value Function Loss: 0.06700

Mean KL Divergence: 0.00716
SB3 Clip Fraction: 0.07647
Policy Update Magnitude: 0.18975
Value Function Update Magnitude: 0.37836

Collected Steps per Second: 22,922.29271
Overall Steps per Second: 14,801.38176

Timestep Collection Time: 2.18285
Timestep Consumption Time: 1.19764
PPO Batch Consumption Time: 0.09724
Total Iteration Time: 3.38050

Cumulative Model Updates: 62,198
Cumulative Timesteps: 518,899,352

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 518899352...
Checkpoint 518899352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,410.19001
Policy Entropy: 1.25510
Value Function Loss: 0.06452

Mean KL Divergence: 0.00669
SB3 Clip Fraction: 0.07268
Policy Update Magnitude: 0.18758
Value Function Update Magnitude: 0.37837

Collected Steps per Second: 22,306.58433
Overall Steps per Second: 14,316.38161

Timestep Collection Time: 2.24158
Timestep Consumption Time: 1.25106
PPO Batch Consumption Time: 0.10303
Total Iteration Time: 3.49264

Cumulative Model Updates: 62,204
Cumulative Timesteps: 518,949,354

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,018.74962
Policy Entropy: 1.25724
Value Function Loss: 0.06242

Mean KL Divergence: 0.00463
SB3 Clip Fraction: 0.05387
Policy Update Magnitude: 0.19113
Value Function Update Magnitude: 0.39016

Collected Steps per Second: 23,000.68901
Overall Steps per Second: 14,775.58299

Timestep Collection Time: 2.17559
Timestep Consumption Time: 1.21108
PPO Batch Consumption Time: 0.10098
Total Iteration Time: 3.38667

Cumulative Model Updates: 62,210
Cumulative Timesteps: 518,999,394

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 518999394...
Checkpoint 518999394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,060.76179
Policy Entropy: 1.25978
Value Function Loss: 0.06275

Mean KL Divergence: 0.00424
SB3 Clip Fraction: 0.05160
Policy Update Magnitude: 0.20108
Value Function Update Magnitude: 0.38886

Collected Steps per Second: 22,763.12390
Overall Steps per Second: 14,605.69526

Timestep Collection Time: 2.19829
Timestep Consumption Time: 1.22777
PPO Batch Consumption Time: 0.10115
Total Iteration Time: 3.42606

Cumulative Model Updates: 62,216
Cumulative Timesteps: 519,049,434

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,761.84478
Policy Entropy: 1.26142
Value Function Loss: 0.05834

Mean KL Divergence: 0.00462
SB3 Clip Fraction: 0.05662
Policy Update Magnitude: 0.20628
Value Function Update Magnitude: 0.39329

Collected Steps per Second: 22,642.51049
Overall Steps per Second: 14,616.77802

Timestep Collection Time: 2.20974
Timestep Consumption Time: 1.21332
PPO Batch Consumption Time: 0.09457
Total Iteration Time: 3.42305

Cumulative Model Updates: 62,222
Cumulative Timesteps: 519,099,468

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 519099468...
Checkpoint 519099468 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,466.48681
Policy Entropy: 1.26113
Value Function Loss: 0.05607

Mean KL Divergence: 0.00520
SB3 Clip Fraction: 0.06051
Policy Update Magnitude: 0.20245
Value Function Update Magnitude: 0.38546

Collected Steps per Second: 22,676.77036
Overall Steps per Second: 14,510.34239

Timestep Collection Time: 2.20525
Timestep Consumption Time: 1.24112
PPO Batch Consumption Time: 0.10228
Total Iteration Time: 3.44637

Cumulative Model Updates: 62,228
Cumulative Timesteps: 519,149,476

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,179.24560
Policy Entropy: 1.26474
Value Function Loss: 0.05996

Mean KL Divergence: 0.00437
SB3 Clip Fraction: 0.05121
Policy Update Magnitude: 0.19921
Value Function Update Magnitude: 0.37095

Collected Steps per Second: 23,003.61818
Overall Steps per Second: 15,073.43325

Timestep Collection Time: 2.17375
Timestep Consumption Time: 1.14361
PPO Batch Consumption Time: 0.09029
Total Iteration Time: 3.31736

Cumulative Model Updates: 62,234
Cumulative Timesteps: 519,199,480

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 519199480...
Checkpoint 519199480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,132.52102
Policy Entropy: 1.25843
Value Function Loss: 0.07064

Mean KL Divergence: 0.00414
SB3 Clip Fraction: 0.05042
Policy Update Magnitude: 0.20605
Value Function Update Magnitude: 0.36394

Collected Steps per Second: 22,624.79851
Overall Steps per Second: 14,863.31312

Timestep Collection Time: 2.21200
Timestep Consumption Time: 1.15508
PPO Batch Consumption Time: 0.09159
Total Iteration Time: 3.36708

Cumulative Model Updates: 62,240
Cumulative Timesteps: 519,249,526

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,341.72527
Policy Entropy: 1.26544
Value Function Loss: 0.07130

Mean KL Divergence: 0.00473
SB3 Clip Fraction: 0.05628
Policy Update Magnitude: 0.21111
Value Function Update Magnitude: 0.35563

Collected Steps per Second: 22,220.36626
Overall Steps per Second: 14,383.52485

Timestep Collection Time: 2.25100
Timestep Consumption Time: 1.22645
PPO Batch Consumption Time: 0.10150
Total Iteration Time: 3.47745

Cumulative Model Updates: 62,246
Cumulative Timesteps: 519,299,544

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 519299544...
Checkpoint 519299544 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,387.36332
Policy Entropy: 1.26829
Value Function Loss: 0.07028

Mean KL Divergence: 0.00454
SB3 Clip Fraction: 0.05356
Policy Update Magnitude: 0.21063
Value Function Update Magnitude: 0.35570

Collected Steps per Second: 22,581.05115
Overall Steps per Second: 14,539.98005

Timestep Collection Time: 2.21602
Timestep Consumption Time: 1.22553
PPO Batch Consumption Time: 0.10111
Total Iteration Time: 3.44155

Cumulative Model Updates: 62,252
Cumulative Timesteps: 519,349,584

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,695.11350
Policy Entropy: 1.26585
Value Function Loss: 0.06185

Mean KL Divergence: 0.00644
SB3 Clip Fraction: 0.07264
Policy Update Magnitude: 0.19943
Value Function Update Magnitude: 0.34910

Collected Steps per Second: 22,739.37335
Overall Steps per Second: 14,606.63459

Timestep Collection Time: 2.20068
Timestep Consumption Time: 1.22530
PPO Batch Consumption Time: 0.09452
Total Iteration Time: 3.42598

Cumulative Model Updates: 62,258
Cumulative Timesteps: 519,399,626

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 519399626...
Checkpoint 519399626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,133.61549
Policy Entropy: 1.26549
Value Function Loss: 0.05962

Mean KL Divergence: 0.02393
SB3 Clip Fraction: 0.15583
Policy Update Magnitude: 0.17068
Value Function Update Magnitude: 0.34879

Collected Steps per Second: 22,101.48899
Overall Steps per Second: 14,185.81201

Timestep Collection Time: 2.26247
Timestep Consumption Time: 1.26246
PPO Batch Consumption Time: 0.10435
Total Iteration Time: 3.52493

Cumulative Model Updates: 62,264
Cumulative Timesteps: 519,449,630

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,668.26713
Policy Entropy: 1.26756
Value Function Loss: 0.06845

Mean KL Divergence: 0.01756
SB3 Clip Fraction: 0.13453
Policy Update Magnitude: 0.15403
Value Function Update Magnitude: 0.35855

Collected Steps per Second: 23,022.02659
Overall Steps per Second: 14,650.53012

Timestep Collection Time: 2.17192
Timestep Consumption Time: 1.24106
PPO Batch Consumption Time: 0.09998
Total Iteration Time: 3.41298

Cumulative Model Updates: 62,270
Cumulative Timesteps: 519,499,632

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 519499632...
Checkpoint 519499632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,848.67579
Policy Entropy: 1.28140
Value Function Loss: 0.07045

Mean KL Divergence: 0.01136
SB3 Clip Fraction: 0.10697
Policy Update Magnitude: 0.18446
Value Function Update Magnitude: 0.36663

Collected Steps per Second: 22,270.99520
Overall Steps per Second: 14,327.51607

Timestep Collection Time: 2.24660
Timestep Consumption Time: 1.24556
PPO Batch Consumption Time: 0.10282
Total Iteration Time: 3.49216

Cumulative Model Updates: 62,276
Cumulative Timesteps: 519,549,666

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,046.56261
Policy Entropy: 1.27566
Value Function Loss: 0.07165

Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.08834
Policy Update Magnitude: 0.20608
Value Function Update Magnitude: 0.33467

Collected Steps per Second: 22,824.49289
Overall Steps per Second: 14,330.12552

Timestep Collection Time: 2.19107
Timestep Consumption Time: 1.29878
PPO Batch Consumption Time: 0.10698
Total Iteration Time: 3.48985

Cumulative Model Updates: 62,282
Cumulative Timesteps: 519,599,676

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 519599676...
Checkpoint 519599676 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,433.64654
Policy Entropy: 1.25614
Value Function Loss: 0.06896

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.09266
Policy Update Magnitude: 0.19808
Value Function Update Magnitude: 0.35304

Collected Steps per Second: 22,695.47022
Overall Steps per Second: 14,278.55833

Timestep Collection Time: 2.20423
Timestep Consumption Time: 1.29935
PPO Batch Consumption Time: 0.10742
Total Iteration Time: 3.50358

Cumulative Model Updates: 62,288
Cumulative Timesteps: 519,649,702

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,124.13881
Policy Entropy: 1.25322
Value Function Loss: 0.06477

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.08542
Policy Update Magnitude: 0.19576
Value Function Update Magnitude: 0.39954

Collected Steps per Second: 22,589.07849
Overall Steps per Second: 14,533.27357

Timestep Collection Time: 2.21567
Timestep Consumption Time: 1.22815
PPO Batch Consumption Time: 0.09838
Total Iteration Time: 3.44382

Cumulative Model Updates: 62,294
Cumulative Timesteps: 519,699,752

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 519699752...
Checkpoint 519699752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,667.79920
Policy Entropy: 1.24808
Value Function Loss: 0.06486

Mean KL Divergence: 0.00692
SB3 Clip Fraction: 0.07897
Policy Update Magnitude: 0.21117
Value Function Update Magnitude: 0.39549

Collected Steps per Second: 22,337.56230
Overall Steps per Second: 14,392.62178

Timestep Collection Time: 2.23910
Timestep Consumption Time: 1.23602
PPO Batch Consumption Time: 0.10251
Total Iteration Time: 3.47511

Cumulative Model Updates: 62,300
Cumulative Timesteps: 519,749,768

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,972.67731
Policy Entropy: 1.24748
Value Function Loss: 0.05723

Mean KL Divergence: 0.00695
SB3 Clip Fraction: 0.08127
Policy Update Magnitude: 0.21876
Value Function Update Magnitude: 0.38938

Collected Steps per Second: 22,731.04767
Overall Steps per Second: 14,479.63654

Timestep Collection Time: 2.20051
Timestep Consumption Time: 1.25399
PPO Batch Consumption Time: 0.10208
Total Iteration Time: 3.45451

Cumulative Model Updates: 62,306
Cumulative Timesteps: 519,799,788

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 519799788...
Checkpoint 519799788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,681.46855
Policy Entropy: 1.25130
Value Function Loss: 0.05619

Mean KL Divergence: 0.00664
SB3 Clip Fraction: 0.07779
Policy Update Magnitude: 0.21692
Value Function Update Magnitude: 0.38360

Collected Steps per Second: 22,499.49904
Overall Steps per Second: 14,663.63087

Timestep Collection Time: 2.22325
Timestep Consumption Time: 1.18805
PPO Batch Consumption Time: 0.09342
Total Iteration Time: 3.41130

Cumulative Model Updates: 62,312
Cumulative Timesteps: 519,849,810

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,227.01751
Policy Entropy: 1.24725
Value Function Loss: 0.06066

Mean KL Divergence: 0.00578
SB3 Clip Fraction: 0.06883
Policy Update Magnitude: 0.20975
Value Function Update Magnitude: 0.37761

Collected Steps per Second: 22,638.62855
Overall Steps per Second: 14,725.69759

Timestep Collection Time: 2.20870
Timestep Consumption Time: 1.18686
PPO Batch Consumption Time: 0.09382
Total Iteration Time: 3.39556

Cumulative Model Updates: 62,318
Cumulative Timesteps: 519,899,812

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 519899812...
Checkpoint 519899812 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,882.02493
Policy Entropy: 1.25095
Value Function Loss: 0.06536

Mean KL Divergence: 0.00557
SB3 Clip Fraction: 0.06829
Policy Update Magnitude: 0.20500
Value Function Update Magnitude: 0.39480

Collected Steps per Second: 22,286.17083
Overall Steps per Second: 14,387.99090

Timestep Collection Time: 2.24444
Timestep Consumption Time: 1.23207
PPO Batch Consumption Time: 0.10220
Total Iteration Time: 3.47651

Cumulative Model Updates: 62,324
Cumulative Timesteps: 519,949,832

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,574.52671
Policy Entropy: 1.25686
Value Function Loss: 0.07467

Mean KL Divergence: 0.00556
SB3 Clip Fraction: 0.06422
Policy Update Magnitude: 0.21281
Value Function Update Magnitude: 0.41633

Collected Steps per Second: 23,107.05402
Overall Steps per Second: 14,763.02134

Timestep Collection Time: 2.16514
Timestep Consumption Time: 1.22373
PPO Batch Consumption Time: 0.10214
Total Iteration Time: 3.38887

Cumulative Model Updates: 62,330
Cumulative Timesteps: 519,999,862

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 519999862...
Checkpoint 519999862 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,884.01364
Policy Entropy: 1.28158
Value Function Loss: 0.06633

Mean KL Divergence: 0.00629
SB3 Clip Fraction: 0.07361
Policy Update Magnitude: 0.21675
Value Function Update Magnitude: 0.42715

Collected Steps per Second: 22,715.99475
Overall Steps per Second: 14,606.69383

Timestep Collection Time: 2.20180
Timestep Consumption Time: 1.22239
PPO Batch Consumption Time: 0.10301
Total Iteration Time: 3.42418

Cumulative Model Updates: 62,336
Cumulative Timesteps: 520,049,878

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,332.04036
Policy Entropy: 1.26715
Value Function Loss: 0.06261

Mean KL Divergence: 0.00493
SB3 Clip Fraction: 0.05875
Policy Update Magnitude: 0.21864
Value Function Update Magnitude: 0.41598

Collected Steps per Second: 22,694.45224
Overall Steps per Second: 14,670.48586

Timestep Collection Time: 2.20345
Timestep Consumption Time: 1.20517
PPO Batch Consumption Time: 0.09920
Total Iteration Time: 3.40861

Cumulative Model Updates: 62,342
Cumulative Timesteps: 520,099,884

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 520099884...
Checkpoint 520099884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,920.47645
Policy Entropy: 1.27595
Value Function Loss: 0.05084

Mean KL Divergence: 0.00497
SB3 Clip Fraction: 0.05892
Policy Update Magnitude: 0.20700
Value Function Update Magnitude: 0.38628

Collected Steps per Second: 22,675.98983
Overall Steps per Second: 14,758.22715

Timestep Collection Time: 2.20595
Timestep Consumption Time: 1.18349
PPO Batch Consumption Time: 0.09103
Total Iteration Time: 3.38943

Cumulative Model Updates: 62,348
Cumulative Timesteps: 520,149,906

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,874.26163
Policy Entropy: 1.25024
Value Function Loss: 0.05311

Mean KL Divergence: 0.00416
SB3 Clip Fraction: 0.05065
Policy Update Magnitude: 0.20237
Value Function Update Magnitude: 0.37450

Collected Steps per Second: 22,577.21779
Overall Steps per Second: 14,346.45810

Timestep Collection Time: 2.21613
Timestep Consumption Time: 1.27142
PPO Batch Consumption Time: 0.10188
Total Iteration Time: 3.48755

Cumulative Model Updates: 62,354
Cumulative Timesteps: 520,199,940

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 520199940...
Checkpoint 520199940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,618.66994
Policy Entropy: 1.25945
Value Function Loss: 0.05344

Mean KL Divergence: 0.00417
SB3 Clip Fraction: 0.05088
Policy Update Magnitude: 0.20706
Value Function Update Magnitude: 0.37220

Collected Steps per Second: 22,784.42807
Overall Steps per Second: 14,533.20958

Timestep Collection Time: 2.19466
Timestep Consumption Time: 1.24601
PPO Batch Consumption Time: 0.09969
Total Iteration Time: 3.44067

Cumulative Model Updates: 62,360
Cumulative Timesteps: 520,249,944

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,698.50607
Policy Entropy: 1.25666
Value Function Loss: 0.05796

Mean KL Divergence: 0.00493
SB3 Clip Fraction: 0.06056
Policy Update Magnitude: 0.20968
Value Function Update Magnitude: 0.38005

Collected Steps per Second: 22,862.70467
Overall Steps per Second: 14,653.95100

Timestep Collection Time: 2.18880
Timestep Consumption Time: 1.22611
PPO Batch Consumption Time: 0.09557
Total Iteration Time: 3.41492

Cumulative Model Updates: 62,366
Cumulative Timesteps: 520,299,986

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 520299986...
Checkpoint 520299986 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,014.65120
Policy Entropy: 1.26095
Value Function Loss: 0.05518

Mean KL Divergence: 0.00502
SB3 Clip Fraction: 0.06144
Policy Update Magnitude: 0.20815
Value Function Update Magnitude: 0.38933

Collected Steps per Second: 22,420.16755
Overall Steps per Second: 14,800.03979

Timestep Collection Time: 2.23040
Timestep Consumption Time: 1.14837
PPO Batch Consumption Time: 0.09189
Total Iteration Time: 3.37877

Cumulative Model Updates: 62,372
Cumulative Timesteps: 520,349,992

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,351.94168
Policy Entropy: 1.27466
Value Function Loss: 0.05849

Mean KL Divergence: 0.00450
SB3 Clip Fraction: 0.05347
Policy Update Magnitude: 0.21167
Value Function Update Magnitude: 0.39645

Collected Steps per Second: 22,801.54261
Overall Steps per Second: 14,821.41053

Timestep Collection Time: 2.19485
Timestep Consumption Time: 1.18175
PPO Batch Consumption Time: 0.09559
Total Iteration Time: 3.37660

Cumulative Model Updates: 62,378
Cumulative Timesteps: 520,400,038

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 520400038...
Checkpoint 520400038 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,975.65112
Policy Entropy: 1.27937
Value Function Loss: 0.06219

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.08525
Policy Update Magnitude: 0.20684
Value Function Update Magnitude: 0.39499

Collected Steps per Second: 22,287.92283
Overall Steps per Second: 14,378.52839

Timestep Collection Time: 2.24409
Timestep Consumption Time: 1.23443
PPO Batch Consumption Time: 0.10219
Total Iteration Time: 3.47852

Cumulative Model Updates: 62,384
Cumulative Timesteps: 520,450,054

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,242.28079
Policy Entropy: 1.28302
Value Function Loss: 0.06279

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.09101
Policy Update Magnitude: 0.19777
Value Function Update Magnitude: 0.39974

Collected Steps per Second: 22,584.39764
Overall Steps per Second: 14,543.22387

Timestep Collection Time: 2.21454
Timestep Consumption Time: 1.22445
PPO Batch Consumption Time: 0.10268
Total Iteration Time: 3.43899

Cumulative Model Updates: 62,390
Cumulative Timesteps: 520,500,068

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 520500068...
Checkpoint 520500068 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,114.56203
Policy Entropy: 1.28577
Value Function Loss: 0.06337

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.08012
Policy Update Magnitude: 0.20470
Value Function Update Magnitude: 0.39231

Collected Steps per Second: 22,100.40753
Overall Steps per Second: 14,315.78287

Timestep Collection Time: 2.26285
Timestep Consumption Time: 1.23049
PPO Batch Consumption Time: 0.10173
Total Iteration Time: 3.49335

Cumulative Model Updates: 62,396
Cumulative Timesteps: 520,550,078

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,349.49442
Policy Entropy: 1.28721
Value Function Loss: 0.06428

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.07851
Policy Update Magnitude: 0.20716
Value Function Update Magnitude: 0.37949

Collected Steps per Second: 22,306.87866
Overall Steps per Second: 14,430.64581

Timestep Collection Time: 2.24290
Timestep Consumption Time: 1.22417
PPO Batch Consumption Time: 0.10245
Total Iteration Time: 3.46707

Cumulative Model Updates: 62,402
Cumulative Timesteps: 520,600,110

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 520600110...
Checkpoint 520600110 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,356.97572
Policy Entropy: 1.29086
Value Function Loss: 0.07030

Mean KL Divergence: 0.00675
SB3 Clip Fraction: 0.07385
Policy Update Magnitude: 0.21230
Value Function Update Magnitude: 0.39224

Collected Steps per Second: 22,638.23252
Overall Steps per Second: 14,699.46411

Timestep Collection Time: 2.20962
Timestep Consumption Time: 1.19336
PPO Batch Consumption Time: 0.09598
Total Iteration Time: 3.40298

Cumulative Model Updates: 62,408
Cumulative Timesteps: 520,650,132

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,129.78688
Policy Entropy: 1.29537
Value Function Loss: 0.06543

Mean KL Divergence: 0.00705
SB3 Clip Fraction: 0.07961
Policy Update Magnitude: 0.21944
Value Function Update Magnitude: 0.38684

Collected Steps per Second: 22,592.88900
Overall Steps per Second: 14,723.72111

Timestep Collection Time: 2.21415
Timestep Consumption Time: 1.18336
PPO Batch Consumption Time: 0.09559
Total Iteration Time: 3.39751

Cumulative Model Updates: 62,414
Cumulative Timesteps: 520,700,156

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 520700156...
Checkpoint 520700156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,410.88652
Policy Entropy: 1.28362
Value Function Loss: 0.06607

Mean KL Divergence: 0.00683
SB3 Clip Fraction: 0.07838
Policy Update Magnitude: 0.22301
Value Function Update Magnitude: 0.43272

Collected Steps per Second: 22,654.71165
Overall Steps per Second: 14,799.56330

Timestep Collection Time: 2.20758
Timestep Consumption Time: 1.17171
PPO Batch Consumption Time: 0.09104
Total Iteration Time: 3.37929

Cumulative Model Updates: 62,420
Cumulative Timesteps: 520,750,168

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,646.23179
Policy Entropy: 1.28411
Value Function Loss: 0.06450

Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.08938
Policy Update Magnitude: 0.21746
Value Function Update Magnitude: 0.42957

Collected Steps per Second: 22,345.31150
Overall Steps per Second: 14,423.82420

Timestep Collection Time: 2.23841
Timestep Consumption Time: 1.22932
PPO Batch Consumption Time: 0.10307
Total Iteration Time: 3.46774

Cumulative Model Updates: 62,426
Cumulative Timesteps: 520,800,186

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 520800186...
Checkpoint 520800186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,209.16731
Policy Entropy: 1.28834
Value Function Loss: 0.06595

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.10476
Policy Update Magnitude: 0.20368
Value Function Update Magnitude: 0.43040

Collected Steps per Second: 22,386.01464
Overall Steps per Second: 14,512.96327

Timestep Collection Time: 2.23363
Timestep Consumption Time: 1.21171
PPO Batch Consumption Time: 0.10171
Total Iteration Time: 3.44533

Cumulative Model Updates: 62,432
Cumulative Timesteps: 520,850,188

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,217.17794
Policy Entropy: 1.29136
Value Function Loss: 0.06725

Mean KL Divergence: 0.00688
SB3 Clip Fraction: 0.07792
Policy Update Magnitude: 0.20467
Value Function Update Magnitude: 0.44793

Collected Steps per Second: 22,855.39773
Overall Steps per Second: 14,674.71532

Timestep Collection Time: 2.18863
Timestep Consumption Time: 1.22009
PPO Batch Consumption Time: 0.09963
Total Iteration Time: 3.40872

Cumulative Model Updates: 62,438
Cumulative Timesteps: 520,900,210

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 520900210...
Checkpoint 520900210 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,926.65933
Policy Entropy: 1.27883
Value Function Loss: 0.06401

Mean KL Divergence: 0.00746
SB3 Clip Fraction: 0.08380
Policy Update Magnitude: 0.21104
Value Function Update Magnitude: 0.48108

Collected Steps per Second: 22,633.20124
Overall Steps per Second: 14,775.20467

Timestep Collection Time: 2.20932
Timestep Consumption Time: 1.17500
PPO Batch Consumption Time: 0.09659
Total Iteration Time: 3.38432

Cumulative Model Updates: 62,444
Cumulative Timesteps: 520,950,214

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,809.57953
Policy Entropy: 1.26984
Value Function Loss: 0.06144

Mean KL Divergence: 0.00629
SB3 Clip Fraction: 0.07141
Policy Update Magnitude: 0.21080
Value Function Update Magnitude: 0.44707

Collected Steps per Second: 22,671.99664
Overall Steps per Second: 14,707.90885

Timestep Collection Time: 2.20554
Timestep Consumption Time: 1.19426
PPO Batch Consumption Time: 0.09413
Total Iteration Time: 3.39980

Cumulative Model Updates: 62,450
Cumulative Timesteps: 521,000,218

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 521000218...
Checkpoint 521000218 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,532.01732
Policy Entropy: 1.27693
Value Function Loss: 0.05867

Mean KL Divergence: 0.00556
SB3 Clip Fraction: 0.06224
Policy Update Magnitude: 0.20285
Value Function Update Magnitude: 0.42282

Collected Steps per Second: 22,591.28088
Overall Steps per Second: 14,385.69654

Timestep Collection Time: 2.21457
Timestep Consumption Time: 1.26319
PPO Batch Consumption Time: 0.10166
Total Iteration Time: 3.47776

Cumulative Model Updates: 62,456
Cumulative Timesteps: 521,050,248

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,327.26681
Policy Entropy: 1.26821
Value Function Loss: 0.06515

Mean KL Divergence: 0.00593
SB3 Clip Fraction: 0.06731
Policy Update Magnitude: 0.20907
Value Function Update Magnitude: 0.42592

Collected Steps per Second: 22,891.05169
Overall Steps per Second: 14,509.71285

Timestep Collection Time: 2.18522
Timestep Consumption Time: 1.26226
PPO Batch Consumption Time: 0.10191
Total Iteration Time: 3.44748

Cumulative Model Updates: 62,462
Cumulative Timesteps: 521,100,270

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 521100270...
Checkpoint 521100270 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,484.16703
Policy Entropy: 1.28563
Value Function Loss: 0.07030

Mean KL Divergence: 0.00631
SB3 Clip Fraction: 0.07487
Policy Update Magnitude: 0.20851
Value Function Update Magnitude: 0.44591

Collected Steps per Second: 22,026.47829
Overall Steps per Second: 14,066.11439

Timestep Collection Time: 2.27018
Timestep Consumption Time: 1.28475
PPO Batch Consumption Time: 0.10467
Total Iteration Time: 3.55493

Cumulative Model Updates: 62,468
Cumulative Timesteps: 521,150,274

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,266.08519
Policy Entropy: 1.28417
Value Function Loss: 0.07099

Mean KL Divergence: 0.00620
SB3 Clip Fraction: 0.07263
Policy Update Magnitude: 0.20998
Value Function Update Magnitude: 0.45118

Collected Steps per Second: 23,203.66830
Overall Steps per Second: 14,688.49765

Timestep Collection Time: 2.15483
Timestep Consumption Time: 1.24919
PPO Batch Consumption Time: 0.10353
Total Iteration Time: 3.40402

Cumulative Model Updates: 62,474
Cumulative Timesteps: 521,200,274

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 521200274...
Checkpoint 521200274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,366.77037
Policy Entropy: 1.29499
Value Function Loss: 0.06743

Mean KL Divergence: 0.00476
SB3 Clip Fraction: 0.05609
Policy Update Magnitude: 0.21319
Value Function Update Magnitude: 0.44466

Collected Steps per Second: 22,541.53206
Overall Steps per Second: 14,722.87126

Timestep Collection Time: 2.21937
Timestep Consumption Time: 1.17861
PPO Batch Consumption Time: 0.09509
Total Iteration Time: 3.39798

Cumulative Model Updates: 62,480
Cumulative Timesteps: 521,250,302

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,761.57683
Policy Entropy: 1.28348
Value Function Loss: 0.06484

Mean KL Divergence: 0.00507
SB3 Clip Fraction: 0.06068
Policy Update Magnitude: 0.21614
Value Function Update Magnitude: 0.44756

Collected Steps per Second: 22,611.33030
Overall Steps per Second: 14,742.20063

Timestep Collection Time: 2.21305
Timestep Consumption Time: 1.18129
PPO Batch Consumption Time: 0.09487
Total Iteration Time: 3.39434

Cumulative Model Updates: 62,486
Cumulative Timesteps: 521,300,342

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 521300342...
Checkpoint 521300342 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,132.63383
Policy Entropy: 1.29089
Value Function Loss: 0.06751

Mean KL Divergence: 0.00458
SB3 Clip Fraction: 0.05531
Policy Update Magnitude: 0.21585
Value Function Update Magnitude: 0.45288

Collected Steps per Second: 22,782.30104
Overall Steps per Second: 14,814.11916

Timestep Collection Time: 2.19486
Timestep Consumption Time: 1.18057
PPO Batch Consumption Time: 0.09197
Total Iteration Time: 3.37543

Cumulative Model Updates: 62,492
Cumulative Timesteps: 521,350,346

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,472.21992
Policy Entropy: 1.28995
Value Function Loss: 0.06703

Mean KL Divergence: 0.00466
SB3 Clip Fraction: 0.05511
Policy Update Magnitude: 0.22423
Value Function Update Magnitude: 0.44951

Collected Steps per Second: 22,827.94706
Overall Steps per Second: 14,767.48499

Timestep Collection Time: 2.19249
Timestep Consumption Time: 1.19671
PPO Batch Consumption Time: 0.09206
Total Iteration Time: 3.38920

Cumulative Model Updates: 62,498
Cumulative Timesteps: 521,400,396

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 521400396...
Checkpoint 521400396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,389.46360
Policy Entropy: 1.29809
Value Function Loss: 0.06340

Mean KL Divergence: 0.00530
SB3 Clip Fraction: 0.06219
Policy Update Magnitude: 0.22793
Value Function Update Magnitude: 0.43676

Collected Steps per Second: 22,083.42218
Overall Steps per Second: 14,206.71512

Timestep Collection Time: 2.26423
Timestep Consumption Time: 1.25537
PPO Batch Consumption Time: 0.10285
Total Iteration Time: 3.51960

Cumulative Model Updates: 62,504
Cumulative Timesteps: 521,450,398

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,711.03214
Policy Entropy: 1.29206
Value Function Loss: 0.06897

Mean KL Divergence: 0.00553
SB3 Clip Fraction: 0.06772
Policy Update Magnitude: 0.22373
Value Function Update Magnitude: 0.42659

Collected Steps per Second: 22,024.36511
Overall Steps per Second: 14,255.46866

Timestep Collection Time: 2.27021
Timestep Consumption Time: 1.23721
PPO Batch Consumption Time: 0.10017
Total Iteration Time: 3.50743

Cumulative Model Updates: 62,510
Cumulative Timesteps: 521,500,398

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 521500398...
Checkpoint 521500398 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,459.69681
Policy Entropy: 1.29668
Value Function Loss: 0.06618

Mean KL Divergence: 0.00566
SB3 Clip Fraction: 0.06832
Policy Update Magnitude: 0.22195
Value Function Update Magnitude: 0.39291

Collected Steps per Second: 22,528.57334
Overall Steps per Second: 14,453.65811

Timestep Collection Time: 2.21994
Timestep Consumption Time: 1.24023
PPO Batch Consumption Time: 0.10209
Total Iteration Time: 3.46016

Cumulative Model Updates: 62,516
Cumulative Timesteps: 521,550,410

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,751.03243
Policy Entropy: 1.27941
Value Function Loss: 0.06442

Mean KL Divergence: 0.00588
SB3 Clip Fraction: 0.07131
Policy Update Magnitude: 0.22033
Value Function Update Magnitude: 0.41807

Collected Steps per Second: 22,850.42754
Overall Steps per Second: 14,633.74837

Timestep Collection Time: 2.18928
Timestep Consumption Time: 1.22926
PPO Batch Consumption Time: 0.09800
Total Iteration Time: 3.41854

Cumulative Model Updates: 62,522
Cumulative Timesteps: 521,600,436

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 521600436...
Checkpoint 521600436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,991.93793
Policy Entropy: 1.26381
Value Function Loss: 0.05961

Mean KL Divergence: 0.00439
SB3 Clip Fraction: 0.05156
Policy Update Magnitude: 0.21490
Value Function Update Magnitude: 0.43182

Collected Steps per Second: 22,353.60947
Overall Steps per Second: 14,456.95792

Timestep Collection Time: 2.23749
Timestep Consumption Time: 1.22216
PPO Batch Consumption Time: 0.10250
Total Iteration Time: 3.45965

Cumulative Model Updates: 62,528
Cumulative Timesteps: 521,650,452

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,287.30638
Policy Entropy: 1.26901
Value Function Loss: 0.05940

Mean KL Divergence: 0.00424
SB3 Clip Fraction: 0.05099
Policy Update Magnitude: 0.21531
Value Function Update Magnitude: 0.44180

Collected Steps per Second: 22,605.19750
Overall Steps per Second: 14,616.29864

Timestep Collection Time: 2.21294
Timestep Consumption Time: 1.20954
PPO Batch Consumption Time: 0.10048
Total Iteration Time: 3.42248

Cumulative Model Updates: 62,534
Cumulative Timesteps: 521,700,476

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 521700476...
Checkpoint 521700476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,910.04940
Policy Entropy: 1.26066
Value Function Loss: 0.05270

Mean KL Divergence: 0.00374
SB3 Clip Fraction: 0.04464
Policy Update Magnitude: 0.21324
Value Function Update Magnitude: 0.41406

Collected Steps per Second: 22,250.93215
Overall Steps per Second: 14,471.39797

Timestep Collection Time: 2.24916
Timestep Consumption Time: 1.20911
PPO Batch Consumption Time: 0.09528
Total Iteration Time: 3.45827

Cumulative Model Updates: 62,540
Cumulative Timesteps: 521,750,522

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,703.17596
Policy Entropy: 1.24641
Value Function Loss: 0.04937

Mean KL Divergence: 0.00432
SB3 Clip Fraction: 0.05115
Policy Update Magnitude: 0.20810
Value Function Update Magnitude: 0.37304

Collected Steps per Second: 22,733.95893
Overall Steps per Second: 14,767.53586

Timestep Collection Time: 2.20094
Timestep Consumption Time: 1.18731
PPO Batch Consumption Time: 0.09511
Total Iteration Time: 3.38824

Cumulative Model Updates: 62,546
Cumulative Timesteps: 521,800,558

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 521800558...
Checkpoint 521800558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,480.45988
Policy Entropy: 1.24464
Value Function Loss: 0.05387

Mean KL Divergence: 0.00420
SB3 Clip Fraction: 0.05094
Policy Update Magnitude: 0.20137
Value Function Update Magnitude: 0.37247

Collected Steps per Second: 22,682.19263
Overall Steps per Second: 14,831.01724

Timestep Collection Time: 2.20552
Timestep Consumption Time: 1.16755
PPO Batch Consumption Time: 0.09163
Total Iteration Time: 3.37307

Cumulative Model Updates: 62,552
Cumulative Timesteps: 521,850,584

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,881.50879
Policy Entropy: 1.25824
Value Function Loss: 0.06080

Mean KL Divergence: 0.00495
SB3 Clip Fraction: 0.05757
Policy Update Magnitude: 0.20348
Value Function Update Magnitude: 0.39609

Collected Steps per Second: 22,791.38959
Overall Steps per Second: 14,765.13682

Timestep Collection Time: 2.19390
Timestep Consumption Time: 1.19259
PPO Batch Consumption Time: 0.09444
Total Iteration Time: 3.38649

Cumulative Model Updates: 62,558
Cumulative Timesteps: 521,900,586

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 521900586...
Checkpoint 521900586 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,398.86616
Policy Entropy: 1.23953
Value Function Loss: 0.06242

Mean KL Divergence: 0.00489
SB3 Clip Fraction: 0.05565
Policy Update Magnitude: 0.19890
Value Function Update Magnitude: 0.40063

Collected Steps per Second: 22,448.94743
Overall Steps per Second: 14,462.63686

Timestep Collection Time: 2.22745
Timestep Consumption Time: 1.23001
PPO Batch Consumption Time: 0.10259
Total Iteration Time: 3.45746

Cumulative Model Updates: 62,564
Cumulative Timesteps: 521,950,590

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,476.18147
Policy Entropy: 1.24284
Value Function Loss: 0.06842

Mean KL Divergence: 0.00432
SB3 Clip Fraction: 0.05208
Policy Update Magnitude: 0.20530
Value Function Update Magnitude: 0.41658

Collected Steps per Second: 22,755.92400
Overall Steps per Second: 14,489.55333

Timestep Collection Time: 2.19925
Timestep Consumption Time: 1.25469
PPO Batch Consumption Time: 0.10285
Total Iteration Time: 3.45394

Cumulative Model Updates: 62,570
Cumulative Timesteps: 522,000,636

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 522000636...
Checkpoint 522000636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,011.98981
Policy Entropy: 1.23200
Value Function Loss: 0.06828

Mean KL Divergence: 0.00445
SB3 Clip Fraction: 0.05277
Policy Update Magnitude: 0.21340
Value Function Update Magnitude: 0.42715

Collected Steps per Second: 22,446.57431
Overall Steps per Second: 14,625.92389

Timestep Collection Time: 2.22903
Timestep Consumption Time: 1.19189
PPO Batch Consumption Time: 0.09152
Total Iteration Time: 3.42091

Cumulative Model Updates: 62,576
Cumulative Timesteps: 522,050,670

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,218.16385
Policy Entropy: 1.24480
Value Function Loss: 0.06174

Mean KL Divergence: 0.00440
SB3 Clip Fraction: 0.05309
Policy Update Magnitude: 0.21274
Value Function Update Magnitude: 0.40928

Collected Steps per Second: 22,796.04243
Overall Steps per Second: 14,805.06219

Timestep Collection Time: 2.19521
Timestep Consumption Time: 1.18485
PPO Batch Consumption Time: 0.09564
Total Iteration Time: 3.38006

Cumulative Model Updates: 62,582
Cumulative Timesteps: 522,100,712

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 522100712...
Checkpoint 522100712 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,714.20814
Policy Entropy: 1.25992
Value Function Loss: 0.05819

Mean KL Divergence: 0.00465
SB3 Clip Fraction: 0.05420
Policy Update Magnitude: 0.20366
Value Function Update Magnitude: 0.38922

Collected Steps per Second: 22,454.91068
Overall Steps per Second: 14,458.51463

Timestep Collection Time: 2.22704
Timestep Consumption Time: 1.23168
PPO Batch Consumption Time: 0.10186
Total Iteration Time: 3.45872

Cumulative Model Updates: 62,588
Cumulative Timesteps: 522,150,720

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,800.13685
Policy Entropy: 1.26876
Value Function Loss: 0.05810

Mean KL Divergence: 0.00496
SB3 Clip Fraction: 0.05870
Policy Update Magnitude: 0.20265
Value Function Update Magnitude: 0.40616

Collected Steps per Second: 22,896.67789
Overall Steps per Second: 14,628.23496

Timestep Collection Time: 2.18425
Timestep Consumption Time: 1.23462
PPO Batch Consumption Time: 0.10022
Total Iteration Time: 3.41887

Cumulative Model Updates: 62,594
Cumulative Timesteps: 522,200,732

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 522200732...
Checkpoint 522200732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,420.22359
Policy Entropy: 1.27615
Value Function Loss: 0.06881

Mean KL Divergence: 0.00433
SB3 Clip Fraction: 0.05252
Policy Update Magnitude: 0.21182
Value Function Update Magnitude: 0.43078

Collected Steps per Second: 22,608.88699
Overall Steps per Second: 14,564.96461

Timestep Collection Time: 2.21320
Timestep Consumption Time: 1.22230
PPO Batch Consumption Time: 0.09972
Total Iteration Time: 3.43550

Cumulative Model Updates: 62,600
Cumulative Timesteps: 522,250,770

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,627.20243
Policy Entropy: 1.28199
Value Function Loss: 0.06437

Mean KL Divergence: 0.00433
SB3 Clip Fraction: 0.05280
Policy Update Magnitude: 0.21006
Value Function Update Magnitude: 0.45621

Collected Steps per Second: 22,697.69999
Overall Steps per Second: 14,656.13049

Timestep Collection Time: 2.20304
Timestep Consumption Time: 1.20877
PPO Batch Consumption Time: 0.09493
Total Iteration Time: 3.41181

Cumulative Model Updates: 62,606
Cumulative Timesteps: 522,300,774

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 522300774...
Checkpoint 522300774 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,798.53959
Policy Entropy: 1.29523
Value Function Loss: 0.06056

Mean KL Divergence: 0.00485
SB3 Clip Fraction: 0.05428
Policy Update Magnitude: 0.20470
Value Function Update Magnitude: 0.45865

Collected Steps per Second: 22,394.95500
Overall Steps per Second: 14,234.83738

Timestep Collection Time: 2.23416
Timestep Consumption Time: 1.28073
PPO Batch Consumption Time: 0.10294
Total Iteration Time: 3.51490

Cumulative Model Updates: 62,612
Cumulative Timesteps: 522,350,808

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48,112.67307
Policy Entropy: 1.27429
Value Function Loss: 0.05625

Mean KL Divergence: 0.00526
SB3 Clip Fraction: 0.06063
Policy Update Magnitude: 0.19036
Value Function Update Magnitude: 0.42287

Collected Steps per Second: 22,924.10931
Overall Steps per Second: 14,683.19652

Timestep Collection Time: 2.18224
Timestep Consumption Time: 1.22478
PPO Batch Consumption Time: 0.10216
Total Iteration Time: 3.40702

Cumulative Model Updates: 62,618
Cumulative Timesteps: 522,400,834

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 522400834...
Checkpoint 522400834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,714.46218
Policy Entropy: 1.27102
Value Function Loss: 0.05673

Mean KL Divergence: 0.00668
SB3 Clip Fraction: 0.07413
Policy Update Magnitude: 0.18618
Value Function Update Magnitude: 0.39825

Collected Steps per Second: 22,727.78289
Overall Steps per Second: 14,660.61116

Timestep Collection Time: 2.20074
Timestep Consumption Time: 1.21098
PPO Batch Consumption Time: 0.09199
Total Iteration Time: 3.41173

Cumulative Model Updates: 62,624
Cumulative Timesteps: 522,450,852

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,606.44243
Policy Entropy: 1.26109
Value Function Loss: 0.06081

Mean KL Divergence: 0.00629
SB3 Clip Fraction: 0.07003
Policy Update Magnitude: 0.19320
Value Function Update Magnitude: 0.40698

Collected Steps per Second: 22,978.42202
Overall Steps per Second: 14,781.91272

Timestep Collection Time: 2.17717
Timestep Consumption Time: 1.20723
PPO Batch Consumption Time: 0.09398
Total Iteration Time: 3.38441

Cumulative Model Updates: 62,630
Cumulative Timesteps: 522,500,880

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 522500880...
Checkpoint 522500880 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,038.30072
Policy Entropy: 1.27674
Value Function Loss: 0.06065

Mean KL Divergence: 0.00697
SB3 Clip Fraction: 0.07526
Policy Update Magnitude: 0.20798
Value Function Update Magnitude: 0.42058

Collected Steps per Second: 22,585.71647
Overall Steps per Second: 14,834.15134

Timestep Collection Time: 2.21512
Timestep Consumption Time: 1.15751
PPO Batch Consumption Time: 0.09249
Total Iteration Time: 3.37262

Cumulative Model Updates: 62,636
Cumulative Timesteps: 522,550,910

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,955.21866
Policy Entropy: 1.27602
Value Function Loss: 0.05951

Mean KL Divergence: 0.01140
SB3 Clip Fraction: 0.10061
Policy Update Magnitude: 0.19997
Value Function Update Magnitude: 0.41784

Collected Steps per Second: 22,569.71298
Overall Steps per Second: 14,722.37506

Timestep Collection Time: 2.21562
Timestep Consumption Time: 1.18097
PPO Batch Consumption Time: 0.09179
Total Iteration Time: 3.39660

Cumulative Model Updates: 62,642
Cumulative Timesteps: 522,600,916

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 522600916...
Checkpoint 522600916 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,363.31164
Policy Entropy: 1.27877
Value Function Loss: 0.05478

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.08051
Policy Update Magnitude: 0.20623
Value Function Update Magnitude: 0.42173

Collected Steps per Second: 22,512.41544
Overall Steps per Second: 14,534.78364

Timestep Collection Time: 2.22215
Timestep Consumption Time: 1.21966
PPO Batch Consumption Time: 0.10228
Total Iteration Time: 3.44181

Cumulative Model Updates: 62,648
Cumulative Timesteps: 522,650,942

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,691.97434
Policy Entropy: 1.25017
Value Function Loss: 0.05302

Mean KL Divergence: 0.01116
SB3 Clip Fraction: 0.10085
Policy Update Magnitude: 0.20455
Value Function Update Magnitude: 0.40456

Collected Steps per Second: 22,846.32149
Overall Steps per Second: 14,655.04618

Timestep Collection Time: 2.19037
Timestep Consumption Time: 1.22429
PPO Batch Consumption Time: 0.10080
Total Iteration Time: 3.41466

Cumulative Model Updates: 62,654
Cumulative Timesteps: 522,700,984

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 522700984...
Checkpoint 522700984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,274.28645
Policy Entropy: 1.24212
Value Function Loss: 0.06011

Mean KL Divergence: 0.01114
SB3 Clip Fraction: 0.09068
Policy Update Magnitude: 0.18691
Value Function Update Magnitude: 0.40275

Collected Steps per Second: 22,753.79296
Overall Steps per Second: 14,559.29128

Timestep Collection Time: 2.19858
Timestep Consumption Time: 1.23744
PPO Batch Consumption Time: 0.10012
Total Iteration Time: 3.43602

Cumulative Model Updates: 62,660
Cumulative Timesteps: 522,751,010

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,996.13656
Policy Entropy: 1.25047
Value Function Loss: 0.06374

Mean KL Divergence: 0.01104
SB3 Clip Fraction: 0.09387
Policy Update Magnitude: 0.19115
Value Function Update Magnitude: 0.41826

Collected Steps per Second: 22,987.71944
Overall Steps per Second: 14,746.50562

Timestep Collection Time: 2.17516
Timestep Consumption Time: 1.21561
PPO Batch Consumption Time: 0.10098
Total Iteration Time: 3.39077

Cumulative Model Updates: 62,666
Cumulative Timesteps: 522,801,012

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 522801012...
Checkpoint 522801012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,288.58565
Policy Entropy: 1.25748
Value Function Loss: 0.06233

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.09021
Policy Update Magnitude: 0.19023
Value Function Update Magnitude: 0.41450

Collected Steps per Second: 22,774.81253
Overall Steps per Second: 14,750.62615

Timestep Collection Time: 2.19620
Timestep Consumption Time: 1.19471
PPO Batch Consumption Time: 0.09503
Total Iteration Time: 3.39091

Cumulative Model Updates: 62,672
Cumulative Timesteps: 522,851,030

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,739.24825
Policy Entropy: 1.24436
Value Function Loss: 0.06502

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.09007
Policy Update Magnitude: 0.18336
Value Function Update Magnitude: 0.40339

Collected Steps per Second: 22,934.30313
Overall Steps per Second: 14,799.36552

Timestep Collection Time: 2.18223
Timestep Consumption Time: 1.19953
PPO Batch Consumption Time: 0.09658
Total Iteration Time: 3.38177

Cumulative Model Updates: 62,678
Cumulative Timesteps: 522,901,078

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 522901078...
Checkpoint 522901078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,120.21566
Policy Entropy: 1.22568
Value Function Loss: 0.06730

Mean KL Divergence: 0.01070
SB3 Clip Fraction: 0.09137
Policy Update Magnitude: 0.19538
Value Function Update Magnitude: 0.42582

Collected Steps per Second: 22,782.13460
Overall Steps per Second: 14,821.43417

Timestep Collection Time: 2.19514
Timestep Consumption Time: 1.17903
PPO Batch Consumption Time: 0.09514
Total Iteration Time: 3.37417

Cumulative Model Updates: 62,684
Cumulative Timesteps: 522,951,088

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,790.52321
Policy Entropy: 1.22315
Value Function Loss: 0.07493

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.08884
Policy Update Magnitude: 0.20477
Value Function Update Magnitude: 0.44486

Collected Steps per Second: 22,982.01847
Overall Steps per Second: 14,768.48224

Timestep Collection Time: 2.17579
Timestep Consumption Time: 1.21007
PPO Batch Consumption Time: 0.09878
Total Iteration Time: 3.38586

Cumulative Model Updates: 62,690
Cumulative Timesteps: 523,001,092

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 523001092...
Checkpoint 523001092 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,196.01145
Policy Entropy: 1.24559
Value Function Loss: 0.07668

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.09133
Policy Update Magnitude: 0.20783
Value Function Update Magnitude: 0.47310

Collected Steps per Second: 22,485.03272
Overall Steps per Second: 14,755.90886

Timestep Collection Time: 2.22397
Timestep Consumption Time: 1.16491
PPO Batch Consumption Time: 0.09212
Total Iteration Time: 3.38888

Cumulative Model Updates: 62,696
Cumulative Timesteps: 523,051,098

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,709.95752
Policy Entropy: 1.23836
Value Function Loss: 0.06816

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.08052
Policy Update Magnitude: 0.21687
Value Function Update Magnitude: 0.46375

Collected Steps per Second: 22,848.90428
Overall Steps per Second: 14,823.24898

Timestep Collection Time: 2.18873
Timestep Consumption Time: 1.18503
PPO Batch Consumption Time: 0.09729
Total Iteration Time: 3.37375

Cumulative Model Updates: 62,702
Cumulative Timesteps: 523,101,108

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 523101108...
Checkpoint 523101108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,469.98517
Policy Entropy: 1.24422
Value Function Loss: 0.06612

Mean KL Divergence: 0.00576
SB3 Clip Fraction: 0.06389
Policy Update Magnitude: 0.21146
Value Function Update Magnitude: 0.41889

Collected Steps per Second: 22,481.53899
Overall Steps per Second: 14,330.83617

Timestep Collection Time: 2.22458
Timestep Consumption Time: 1.26524
PPO Batch Consumption Time: 0.10257
Total Iteration Time: 3.48982

Cumulative Model Updates: 62,708
Cumulative Timesteps: 523,151,120

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,061.62871
Policy Entropy: 1.24470
Value Function Loss: 0.06387

Mean KL Divergence: 0.00514
SB3 Clip Fraction: 0.05844
Policy Update Magnitude: 0.21046
Value Function Update Magnitude: 0.40499

Collected Steps per Second: 22,896.01206
Overall Steps per Second: 14,499.85425

Timestep Collection Time: 2.18614
Timestep Consumption Time: 1.26589
PPO Batch Consumption Time: 0.10111
Total Iteration Time: 3.45203

Cumulative Model Updates: 62,714
Cumulative Timesteps: 523,201,174

Timesteps Collected: 50,054
--------END ITERATION REPORT--------


Saving checkpoint 523201174...
Checkpoint 523201174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,990.13384
Policy Entropy: 1.25577
Value Function Loss: 0.06564

Mean KL Divergence: 0.00644
SB3 Clip Fraction: 0.07340
Policy Update Magnitude: 0.20679
Value Function Update Magnitude: 0.40118

Collected Steps per Second: 22,412.72165
Overall Steps per Second: 14,608.39671

Timestep Collection Time: 2.23221
Timestep Consumption Time: 1.19253
PPO Batch Consumption Time: 0.09577
Total Iteration Time: 3.42474

Cumulative Model Updates: 62,720
Cumulative Timesteps: 523,251,204

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,691.19488
Policy Entropy: 1.24428
Value Function Loss: 0.06508

Mean KL Divergence: 0.00757
SB3 Clip Fraction: 0.08513
Policy Update Magnitude: 0.19384
Value Function Update Magnitude: 0.40579

Collected Steps per Second: 22,781.70169
Overall Steps per Second: 14,800.63545

Timestep Collection Time: 2.19615
Timestep Consumption Time: 1.18425
PPO Batch Consumption Time: 0.09423
Total Iteration Time: 3.38040

Cumulative Model Updates: 62,726
Cumulative Timesteps: 523,301,236

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 523301236...
Checkpoint 523301236 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,740.53505
Policy Entropy: 1.25689
Value Function Loss: 0.06893

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.08726
Policy Update Magnitude: 0.17734
Value Function Update Magnitude: 0.42056

Collected Steps per Second: 22,141.68553
Overall Steps per Second: 14,428.23849

Timestep Collection Time: 2.25818
Timestep Consumption Time: 1.20724
PPO Batch Consumption Time: 0.10153
Total Iteration Time: 3.46543

Cumulative Model Updates: 62,732
Cumulative Timesteps: 523,351,236

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,773.47947
Policy Entropy: 1.25991
Value Function Loss: 0.06763

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.09136
Policy Update Magnitude: 0.18961
Value Function Update Magnitude: 0.42716

Collected Steps per Second: 23,083.20470
Overall Steps per Second: 14,623.78228

Timestep Collection Time: 2.16798
Timestep Consumption Time: 1.25411
PPO Batch Consumption Time: 0.10385
Total Iteration Time: 3.42210

Cumulative Model Updates: 62,738
Cumulative Timesteps: 523,401,280

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 523401280...
Checkpoint 523401280 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,254.48134
Policy Entropy: 1.27285
Value Function Loss: 0.06720

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.09601
Policy Update Magnitude: 0.19231
Value Function Update Magnitude: 0.42461

Collected Steps per Second: 22,871.78816
Overall Steps per Second: 14,746.67548

Timestep Collection Time: 2.18750
Timestep Consumption Time: 1.20527
PPO Batch Consumption Time: 0.09992
Total Iteration Time: 3.39276

Cumulative Model Updates: 62,744
Cumulative Timesteps: 523,451,312

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,216.77229
Policy Entropy: 1.25610
Value Function Loss: 0.06079

Mean KL Divergence: 0.00718
SB3 Clip Fraction: 0.08055
Policy Update Magnitude: 0.19273
Value Function Update Magnitude: 0.40938

Collected Steps per Second: 22,932.02594
Overall Steps per Second: 14,703.08462

Timestep Collection Time: 2.18184
Timestep Consumption Time: 1.22112
PPO Batch Consumption Time: 0.09768
Total Iteration Time: 3.40296

Cumulative Model Updates: 62,750
Cumulative Timesteps: 523,501,346

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 523501346...
Checkpoint 523501346 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,814.99061
Policy Entropy: 1.25899
Value Function Loss: 0.06270

Mean KL Divergence: 0.00565
SB3 Clip Fraction: 0.06577
Policy Update Magnitude: 0.20430
Value Function Update Magnitude: 0.39540

Collected Steps per Second: 22,598.56571
Overall Steps per Second: 14,410.13333

Timestep Collection Time: 2.21280
Timestep Consumption Time: 1.25740
PPO Batch Consumption Time: 0.10233
Total Iteration Time: 3.47020

Cumulative Model Updates: 62,756
Cumulative Timesteps: 523,551,352

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,701.13253
Policy Entropy: 1.25437
Value Function Loss: 0.05973

Mean KL Divergence: 0.00398
SB3 Clip Fraction: 0.04798
Policy Update Magnitude: 0.20770
Value Function Update Magnitude: 0.39910

Collected Steps per Second: 22,776.63506
Overall Steps per Second: 14,503.59598

Timestep Collection Time: 2.19541
Timestep Consumption Time: 1.25229
PPO Batch Consumption Time: 0.10302
Total Iteration Time: 3.44770

Cumulative Model Updates: 62,762
Cumulative Timesteps: 523,601,356

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 523601356...
Checkpoint 523601356 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,686.29368
Policy Entropy: 1.24661
Value Function Loss: 0.05497

Mean KL Divergence: 0.00374
SB3 Clip Fraction: 0.04436
Policy Update Magnitude: 0.20113
Value Function Update Magnitude: 0.40014

Collected Steps per Second: 22,726.31447
Overall Steps per Second: 14,644.26841

Timestep Collection Time: 2.20097
Timestep Consumption Time: 1.21470
PPO Batch Consumption Time: 0.09569
Total Iteration Time: 3.41567

Cumulative Model Updates: 62,768
Cumulative Timesteps: 523,651,376

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,964.14518
Policy Entropy: 1.25190
Value Function Loss: 0.05242

Mean KL Divergence: 0.00396
SB3 Clip Fraction: 0.04835
Policy Update Magnitude: 0.19740
Value Function Update Magnitude: 0.38539

Collected Steps per Second: 22,701.93806
Overall Steps per Second: 14,728.20464

Timestep Collection Time: 2.20404
Timestep Consumption Time: 1.19325
PPO Batch Consumption Time: 0.09428
Total Iteration Time: 3.39729

Cumulative Model Updates: 62,774
Cumulative Timesteps: 523,701,412

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 523701412...
Checkpoint 523701412 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40,419.65454
Policy Entropy: 1.25963
Value Function Loss: 0.05389

Mean KL Divergence: 0.00417
SB3 Clip Fraction: 0.05011
Policy Update Magnitude: 0.19645
Value Function Update Magnitude: 0.36261

Collected Steps per Second: 22,249.39636
Overall Steps per Second: 14,365.24046

Timestep Collection Time: 2.24887
Timestep Consumption Time: 1.23426
PPO Batch Consumption Time: 0.10305
Total Iteration Time: 3.48313

Cumulative Model Updates: 62,780
Cumulative Timesteps: 523,751,448

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,166.65188
Policy Entropy: 1.25169
Value Function Loss: 0.05717

Mean KL Divergence: 0.00588
SB3 Clip Fraction: 0.06453
Policy Update Magnitude: 0.19410
Value Function Update Magnitude: 0.35095

Collected Steps per Second: 22,605.53957
Overall Steps per Second: 14,585.44486

Timestep Collection Time: 2.21194
Timestep Consumption Time: 1.21628
PPO Batch Consumption Time: 0.10333
Total Iteration Time: 3.42821

Cumulative Model Updates: 62,786
Cumulative Timesteps: 523,801,450

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 523801450...
Checkpoint 523801450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43,447.15741
Policy Entropy: 1.25324
Value Function Loss: 0.05518

Mean KL Divergence: 0.00538
SB3 Clip Fraction: 0.06108
Policy Update Magnitude: 0.19360
Value Function Update Magnitude: 0.36618

Collected Steps per Second: 22,759.43135
Overall Steps per Second: 14,737.29447

Timestep Collection Time: 2.19777
Timestep Consumption Time: 1.19634
PPO Batch Consumption Time: 0.09955
Total Iteration Time: 3.39411

Cumulative Model Updates: 62,792
Cumulative Timesteps: 523,851,470

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,114.11558
Policy Entropy: 1.24716
Value Function Loss: 0.04967

Mean KL Divergence: 0.00489
SB3 Clip Fraction: 0.05598
Policy Update Magnitude: 0.19145
Value Function Update Magnitude: 0.36385

Collected Steps per Second: 22,723.89832
Overall Steps per Second: 14,700.14778

Timestep Collection Time: 2.20173
Timestep Consumption Time: 1.20177
PPO Batch Consumption Time: 0.09745
Total Iteration Time: 3.40350

Cumulative Model Updates: 62,798
Cumulative Timesteps: 523,901,502

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 523901502...
Checkpoint 523901502 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,545.69208
Policy Entropy: 1.25517
Value Function Loss: 0.05276

Mean KL Divergence: 0.00526
SB3 Clip Fraction: 0.06164
Policy Update Magnitude: 0.18940
Value Function Update Magnitude: 0.35507

Collected Steps per Second: 22,656.09744
Overall Steps per Second: 14,446.81922

Timestep Collection Time: 2.20771
Timestep Consumption Time: 1.25451
PPO Batch Consumption Time: 0.10241
Total Iteration Time: 3.46222

Cumulative Model Updates: 62,804
Cumulative Timesteps: 523,951,520

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,221.57308
Policy Entropy: 1.25828
Value Function Loss: 0.05501

Mean KL Divergence: 0.00757
SB3 Clip Fraction: 0.07607
Policy Update Magnitude: 0.19707
Value Function Update Magnitude: 0.40095

Collected Steps per Second: 22,691.91439
Overall Steps per Second: 14,656.75881

Timestep Collection Time: 2.20528
Timestep Consumption Time: 1.20898
PPO Batch Consumption Time: 0.10015
Total Iteration Time: 3.41426

Cumulative Model Updates: 62,810
Cumulative Timesteps: 524,001,562

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 524001562...
Checkpoint 524001562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,688.96160
Policy Entropy: 1.24883
Value Function Loss: 0.05975

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.08585
Policy Update Magnitude: 0.20802
Value Function Update Magnitude: 0.41056

Collected Steps per Second: 22,720.40084
Overall Steps per Second: 14,568.37149

Timestep Collection Time: 2.20067
Timestep Consumption Time: 1.23143
PPO Batch Consumption Time: 0.10254
Total Iteration Time: 3.43209

Cumulative Model Updates: 62,816
Cumulative Timesteps: 524,051,562

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,087.50311
Policy Entropy: 1.27262
Value Function Loss: 0.05455

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.08834
Policy Update Magnitude: 0.21428
Value Function Update Magnitude: 0.41231

Collected Steps per Second: 22,810.16841
Overall Steps per Second: 14,708.81079

Timestep Collection Time: 2.19227
Timestep Consumption Time: 1.20746
PPO Batch Consumption Time: 0.09929
Total Iteration Time: 3.39973

Cumulative Model Updates: 62,822
Cumulative Timesteps: 524,101,568

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 524101568...
Checkpoint 524101568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,722.34945
Policy Entropy: 1.27062
Value Function Loss: 0.05661

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.08749
Policy Update Magnitude: 0.21375
Value Function Update Magnitude: 0.40571

Collected Steps per Second: 22,204.36970
Overall Steps per Second: 14,377.27563

Timestep Collection Time: 2.25253
Timestep Consumption Time: 1.22629
PPO Batch Consumption Time: 0.10161
Total Iteration Time: 3.47882

Cumulative Model Updates: 62,828
Cumulative Timesteps: 524,151,584

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,997.56694
Policy Entropy: 1.28239
Value Function Loss: 0.05598

Mean KL Divergence: 0.00535
SB3 Clip Fraction: 0.06449
Policy Update Magnitude: 0.20879
Value Function Update Magnitude: 0.40751

Collected Steps per Second: 22,410.00152
Overall Steps per Second: 14,600.19107

Timestep Collection Time: 2.23240
Timestep Consumption Time: 1.19413
PPO Batch Consumption Time: 0.10008
Total Iteration Time: 3.42653

Cumulative Model Updates: 62,834
Cumulative Timesteps: 524,201,612

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 524201612...
Checkpoint 524201612 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,571.64598
Policy Entropy: 1.27339
Value Function Loss: 0.05829

Mean KL Divergence: 0.00440
SB3 Clip Fraction: 0.05375
Policy Update Magnitude: 0.20791
Value Function Update Magnitude: 0.40242

Collected Steps per Second: 22,447.12511
Overall Steps per Second: 14,586.65631

Timestep Collection Time: 2.22924
Timestep Consumption Time: 1.20129
PPO Batch Consumption Time: 0.09539
Total Iteration Time: 3.43053

Cumulative Model Updates: 62,840
Cumulative Timesteps: 524,251,652

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,361.74417
Policy Entropy: 1.28896
Value Function Loss: 0.05732

Mean KL Divergence: 0.00460
SB3 Clip Fraction: 0.05664
Policy Update Magnitude: 0.20568
Value Function Update Magnitude: 0.38055

Collected Steps per Second: 22,407.71026
Overall Steps per Second: 14,693.16758

Timestep Collection Time: 2.23137
Timestep Consumption Time: 1.17157
PPO Batch Consumption Time: 0.09485
Total Iteration Time: 3.40294

Cumulative Model Updates: 62,846
Cumulative Timesteps: 524,301,652

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 524301652...
Checkpoint 524301652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,246.03646
Policy Entropy: 1.28979
Value Function Loss: 0.06056

Mean KL Divergence: 0.00472
SB3 Clip Fraction: 0.05599
Policy Update Magnitude: 0.20686
Value Function Update Magnitude: 0.36651

Collected Steps per Second: 22,430.48881
Overall Steps per Second: 14,397.45002

Timestep Collection Time: 2.22911
Timestep Consumption Time: 1.24373
PPO Batch Consumption Time: 0.10202
Total Iteration Time: 3.47284

Cumulative Model Updates: 62,852
Cumulative Timesteps: 524,351,652

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,225.08163
Policy Entropy: 1.27961
Value Function Loss: 0.06051

Mean KL Divergence: 0.00463
SB3 Clip Fraction: 0.05458
Policy Update Magnitude: 0.21157
Value Function Update Magnitude: 0.39365

Collected Steps per Second: 22,605.73811
Overall Steps per Second: 14,538.95209

Timestep Collection Time: 2.21183
Timestep Consumption Time: 1.22721
PPO Batch Consumption Time: 0.10386
Total Iteration Time: 3.43904

Cumulative Model Updates: 62,858
Cumulative Timesteps: 524,401,652

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 524401652...
Checkpoint 524401652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,864.53508
Policy Entropy: 1.27107
Value Function Loss: 0.06437

Mean KL Divergence: 0.00615
SB3 Clip Fraction: 0.06990
Policy Update Magnitude: 0.20844
Value Function Update Magnitude: 0.42443

Collected Steps per Second: 22,563.45249
Overall Steps per Second: 14,672.98276

Timestep Collection Time: 2.21704
Timestep Consumption Time: 1.19222
PPO Batch Consumption Time: 0.09562
Total Iteration Time: 3.40926

Cumulative Model Updates: 62,864
Cumulative Timesteps: 524,451,676

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,448.23428
Policy Entropy: 1.26098
Value Function Loss: 0.05802

Mean KL Divergence: 0.00566
SB3 Clip Fraction: 0.06536
Policy Update Magnitude: 0.20204
Value Function Update Magnitude: 0.42215

Collected Steps per Second: 23,042.15299
Overall Steps per Second: 14,787.07196

Timestep Collection Time: 2.17054
Timestep Consumption Time: 1.21174
PPO Batch Consumption Time: 0.09915
Total Iteration Time: 3.38228

Cumulative Model Updates: 62,870
Cumulative Timesteps: 524,501,690

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 524501690...
Checkpoint 524501690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,482.32180
Policy Entropy: 1.26282
Value Function Loss: 0.05677

Mean KL Divergence: 0.00484
SB3 Clip Fraction: 0.05579
Policy Update Magnitude: 0.20497
Value Function Update Magnitude: 0.39993

Collected Steps per Second: 22,675.90040
Overall Steps per Second: 14,798.42975

Timestep Collection Time: 2.20595
Timestep Consumption Time: 1.17427
PPO Batch Consumption Time: 0.09474
Total Iteration Time: 3.38022

Cumulative Model Updates: 62,876
Cumulative Timesteps: 524,551,712

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,079.45482
Policy Entropy: 1.27058
Value Function Loss: 0.05812

Mean KL Divergence: 0.00553
SB3 Clip Fraction: 0.06206
Policy Update Magnitude: 0.21030
Value Function Update Magnitude: 0.39857

Collected Steps per Second: 22,735.59026
Overall Steps per Second: 14,756.99421

Timestep Collection Time: 2.19990
Timestep Consumption Time: 1.18941
PPO Batch Consumption Time: 0.09625
Total Iteration Time: 3.38931

Cumulative Model Updates: 62,882
Cumulative Timesteps: 524,601,728

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 524601728...
Checkpoint 524601728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,758.42801
Policy Entropy: 1.29286
Value Function Loss: 0.05859

Mean KL Divergence: 0.00548
SB3 Clip Fraction: 0.06396
Policy Update Magnitude: 0.21070
Value Function Update Magnitude: 0.40809

Collected Steps per Second: 22,268.41596
Overall Steps per Second: 14,416.70125

Timestep Collection Time: 2.24542
Timestep Consumption Time: 1.22292
PPO Batch Consumption Time: 0.10174
Total Iteration Time: 3.46834

Cumulative Model Updates: 62,888
Cumulative Timesteps: 524,651,730

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,707.76740
Policy Entropy: 1.28518
Value Function Loss: 0.06150

Mean KL Divergence: 0.00424
SB3 Clip Fraction: 0.05065
Policy Update Magnitude: 0.20832
Value Function Update Magnitude: 0.42601

Collected Steps per Second: 22,763.22866
Overall Steps per Second: 14,662.68398

Timestep Collection Time: 2.19802
Timestep Consumption Time: 1.21432
PPO Batch Consumption Time: 0.10120
Total Iteration Time: 3.41234

Cumulative Model Updates: 62,894
Cumulative Timesteps: 524,701,764

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 524701764...
Checkpoint 524701764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,043.02769
Policy Entropy: 1.28004
Value Function Loss: 0.05771

Mean KL Divergence: 0.00488
SB3 Clip Fraction: 0.05718
Policy Update Magnitude: 0.20963
Value Function Update Magnitude: 0.44482

Collected Steps per Second: 21,600.03785
Overall Steps per Second: 13,994.85640

Timestep Collection Time: 2.31676
Timestep Consumption Time: 1.25899
PPO Batch Consumption Time: 0.10283
Total Iteration Time: 3.57574

Cumulative Model Updates: 62,900
Cumulative Timesteps: 524,751,806

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,138.84827
Policy Entropy: 1.26761
Value Function Loss: 0.05812

Mean KL Divergence: 0.00501
SB3 Clip Fraction: 0.05993
Policy Update Magnitude: 0.21089
Value Function Update Magnitude: 0.44218

Collected Steps per Second: 22,495.78935
Overall Steps per Second: 14,521.65488

Timestep Collection Time: 2.22317
Timestep Consumption Time: 1.22079
PPO Batch Consumption Time: 0.10067
Total Iteration Time: 3.44396

Cumulative Model Updates: 62,906
Cumulative Timesteps: 524,801,818

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 524801818...
Checkpoint 524801818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,906.11712
Policy Entropy: 1.27667
Value Function Loss: 0.06205

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.08227
Policy Update Magnitude: 0.21303
Value Function Update Magnitude: 0.42942

Collected Steps per Second: 22,609.31141
Overall Steps per Second: 14,744.55151

Timestep Collection Time: 2.21263
Timestep Consumption Time: 1.18022
PPO Batch Consumption Time: 0.09415
Total Iteration Time: 3.39285

Cumulative Model Updates: 62,912
Cumulative Timesteps: 524,851,844

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,868.56611
Policy Entropy: 1.27883
Value Function Loss: 0.05569

Mean KL Divergence: 0.01231
SB3 Clip Fraction: 0.11623
Policy Update Magnitude: 0.20094
Value Function Update Magnitude: 0.44632

Collected Steps per Second: 23,024.16456
Overall Steps per Second: 14,842.89896

Timestep Collection Time: 2.17302
Timestep Consumption Time: 1.19775
PPO Batch Consumption Time: 0.09963
Total Iteration Time: 3.37077

Cumulative Model Updates: 62,918
Cumulative Timesteps: 524,901,876

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 524901876...
Checkpoint 524901876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,480.48440
Policy Entropy: 1.27225
Value Function Loss: 0.06192

Mean KL Divergence: 0.01265
SB3 Clip Fraction: 0.11807
Policy Update Magnitude: 0.19988
Value Function Update Magnitude: 0.45808

Collected Steps per Second: 22,636.83809
Overall Steps per Second: 14,751.71564

Timestep Collection Time: 2.20905
Timestep Consumption Time: 1.18079
PPO Batch Consumption Time: 0.09333
Total Iteration Time: 3.38984

Cumulative Model Updates: 62,924
Cumulative Timesteps: 524,951,882

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,366.69534
Policy Entropy: 1.27835
Value Function Loss: 0.06154

Mean KL Divergence: 0.01155
SB3 Clip Fraction: 0.10827
Policy Update Magnitude: 0.19916
Value Function Update Magnitude: 0.45718

Collected Steps per Second: 22,816.83834
Overall Steps per Second: 14,779.45444

Timestep Collection Time: 2.19171
Timestep Consumption Time: 1.19190
PPO Batch Consumption Time: 0.09618
Total Iteration Time: 3.38362

Cumulative Model Updates: 62,930
Cumulative Timesteps: 525,001,890

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 525001890...
Checkpoint 525001890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,664.43876
Policy Entropy: 1.27506
Value Function Loss: 0.05842

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.09110
Policy Update Magnitude: 0.19475
Value Function Update Magnitude: 0.45495

Collected Steps per Second: 22,563.13129
Overall Steps per Second: 14,485.48320

Timestep Collection Time: 2.21627
Timestep Consumption Time: 1.23588
PPO Batch Consumption Time: 0.10231
Total Iteration Time: 3.45215

Cumulative Model Updates: 62,936
Cumulative Timesteps: 525,051,896

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,585.89099
Policy Entropy: 1.27329
Value Function Loss: 0.05854

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.09000
Policy Update Magnitude: 0.18408
Value Function Update Magnitude: 0.41117

Collected Steps per Second: 22,611.01580
Overall Steps per Second: 14,526.28817

Timestep Collection Time: 2.21193
Timestep Consumption Time: 1.23107
PPO Batch Consumption Time: 0.10116
Total Iteration Time: 3.44300

Cumulative Model Updates: 62,942
Cumulative Timesteps: 525,101,910

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 525101910...
Checkpoint 525101910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,678.55199
Policy Entropy: 1.28366
Value Function Loss: 0.06048

Mean KL Divergence: 0.00559
SB3 Clip Fraction: 0.06616
Policy Update Magnitude: 0.19397
Value Function Update Magnitude: 0.38095

Collected Steps per Second: 22,049.50973
Overall Steps per Second: 14,590.33680

Timestep Collection Time: 2.26917
Timestep Consumption Time: 1.16009
PPO Batch Consumption Time: 0.09106
Total Iteration Time: 3.42926

Cumulative Model Updates: 62,948
Cumulative Timesteps: 525,151,944

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,559.30753
Policy Entropy: 1.29025
Value Function Loss: 0.05943

Mean KL Divergence: 0.00473
SB3 Clip Fraction: 0.05596
Policy Update Magnitude: 0.20701
Value Function Update Magnitude: 0.35867

Collected Steps per Second: 22,726.62711
Overall Steps per Second: 14,751.01736

Timestep Collection Time: 2.20015
Timestep Consumption Time: 1.18958
PPO Batch Consumption Time: 0.09593
Total Iteration Time: 3.38973

Cumulative Model Updates: 62,954
Cumulative Timesteps: 525,201,946

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 525201946...
Checkpoint 525201946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,793.93158
Policy Entropy: 1.26781
Value Function Loss: 0.04870

Mean KL Divergence: 0.00364
SB3 Clip Fraction: 0.04327
Policy Update Magnitude: 0.20502
Value Function Update Magnitude: 0.39278

Collected Steps per Second: 22,581.99954
Overall Steps per Second: 14,817.27249

Timestep Collection Time: 2.21575
Timestep Consumption Time: 1.16112
PPO Batch Consumption Time: 0.09190
Total Iteration Time: 3.37687

Cumulative Model Updates: 62,960
Cumulative Timesteps: 525,251,982

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,185.53969
Policy Entropy: 1.25651
Value Function Loss: 0.04909

Mean KL Divergence: 0.00357
SB3 Clip Fraction: 0.04144
Policy Update Magnitude: 0.20224
Value Function Update Magnitude: 0.37624

Collected Steps per Second: 22,992.62074
Overall Steps per Second: 14,803.09761

Timestep Collection Time: 2.17539
Timestep Consumption Time: 1.20349
PPO Batch Consumption Time: 0.09669
Total Iteration Time: 3.37889

Cumulative Model Updates: 62,966
Cumulative Timesteps: 525,302,000

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 525302000...
Checkpoint 525302000 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,910.64384
Policy Entropy: 1.25828
Value Function Loss: 0.05498

Mean KL Divergence: 0.00455
SB3 Clip Fraction: 0.05343
Policy Update Magnitude: 0.20123
Value Function Update Magnitude: 0.37015

Collected Steps per Second: 22,075.64485
Overall Steps per Second: 14,347.14342

Timestep Collection Time: 2.26494
Timestep Consumption Time: 1.22007
PPO Batch Consumption Time: 0.10197
Total Iteration Time: 3.48501

Cumulative Model Updates: 62,972
Cumulative Timesteps: 525,352,000

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,854.26944
Policy Entropy: 1.27088
Value Function Loss: 0.05858

Mean KL Divergence: 0.00478
SB3 Clip Fraction: 0.05785
Policy Update Magnitude: 0.20772
Value Function Update Magnitude: 0.38970

Collected Steps per Second: 22,929.95009
Overall Steps per Second: 14,662.11741

Timestep Collection Time: 2.18116
Timestep Consumption Time: 1.22994
PPO Batch Consumption Time: 0.10217
Total Iteration Time: 3.41110

Cumulative Model Updates: 62,978
Cumulative Timesteps: 525,402,014

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 525402014...
Checkpoint 525402014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,516.24761
Policy Entropy: 1.26451
Value Function Loss: 0.06061

Mean KL Divergence: 0.00487
SB3 Clip Fraction: 0.05760
Policy Update Magnitude: 0.20628
Value Function Update Magnitude: 0.40085

Collected Steps per Second: 22,753.40497
Overall Steps per Second: 14,617.21561

Timestep Collection Time: 2.19782
Timestep Consumption Time: 1.22335
PPO Batch Consumption Time: 0.09978
Total Iteration Time: 3.42117

Cumulative Model Updates: 62,984
Cumulative Timesteps: 525,452,022

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,772.33547
Policy Entropy: 1.28143
Value Function Loss: 0.06153

Mean KL Divergence: 0.00460
SB3 Clip Fraction: 0.05411
Policy Update Magnitude: 0.21442
Value Function Update Magnitude: 0.39762

Collected Steps per Second: 22,593.77269
Overall Steps per Second: 14,683.61053

Timestep Collection Time: 2.21362
Timestep Consumption Time: 1.19249
PPO Batch Consumption Time: 0.09564
Total Iteration Time: 3.40611

Cumulative Model Updates: 62,990
Cumulative Timesteps: 525,502,036

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 525502036...
Checkpoint 525502036 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,791.55474
Policy Entropy: 1.29293
Value Function Loss: 0.06445

Mean KL Divergence: 0.00507
SB3 Clip Fraction: 0.06010
Policy Update Magnitude: 0.22035
Value Function Update Magnitude: 0.40342

Collected Steps per Second: 22,723.03006
Overall Steps per Second: 14,805.87015

Timestep Collection Time: 2.20059
Timestep Consumption Time: 1.17672
PPO Batch Consumption Time: 0.09273
Total Iteration Time: 3.37731

Cumulative Model Updates: 62,996
Cumulative Timesteps: 525,552,040

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,690.21668
Policy Entropy: 1.29777
Value Function Loss: 0.05994

Mean KL Divergence: 0.00696
SB3 Clip Fraction: 0.08121
Policy Update Magnitude: 0.21388
Value Function Update Magnitude: 0.42990

Collected Steps per Second: 22,846.13082
Overall Steps per Second: 14,788.69758

Timestep Collection Time: 2.18960
Timestep Consumption Time: 1.19298
PPO Batch Consumption Time: 0.09493
Total Iteration Time: 3.38258

Cumulative Model Updates: 63,002
Cumulative Timesteps: 525,602,064

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 525602064...
Checkpoint 525602064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,391.06260
Policy Entropy: 1.29691
Value Function Loss: 0.05667

Mean KL Divergence: 0.00619
SB3 Clip Fraction: 0.07518
Policy Update Magnitude: 0.21038
Value Function Update Magnitude: 0.41739

Collected Steps per Second: 22,720.18640
Overall Steps per Second: 14,439.68834

Timestep Collection Time: 2.20174
Timestep Consumption Time: 1.26260
PPO Batch Consumption Time: 0.10099
Total Iteration Time: 3.46434

Cumulative Model Updates: 63,008
Cumulative Timesteps: 525,652,088

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,270.25266
Policy Entropy: 1.29201
Value Function Loss: 0.05808

Mean KL Divergence: 0.00524
SB3 Clip Fraction: 0.06002
Policy Update Magnitude: 0.20816
Value Function Update Magnitude: 0.40762

Collected Steps per Second: 22,686.12460
Overall Steps per Second: 14,569.34179

Timestep Collection Time: 2.20478
Timestep Consumption Time: 1.22832
PPO Batch Consumption Time: 0.10235
Total Iteration Time: 3.43310

Cumulative Model Updates: 63,014
Cumulative Timesteps: 525,702,106

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 525702106...
Checkpoint 525702106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,841.40340
Policy Entropy: 1.31419
Value Function Loss: 0.05945

Mean KL Divergence: 0.00413
SB3 Clip Fraction: 0.04851
Policy Update Magnitude: 0.20804
Value Function Update Magnitude: 0.40319

Collected Steps per Second: 22,648.34551
Overall Steps per Second: 14,623.56365

Timestep Collection Time: 2.20926
Timestep Consumption Time: 1.21234
PPO Batch Consumption Time: 0.09804
Total Iteration Time: 3.42160

Cumulative Model Updates: 63,020
Cumulative Timesteps: 525,752,142

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,904.17674
Policy Entropy: 1.29934
Value Function Loss: 0.06442

Mean KL Divergence: 0.00562
SB3 Clip Fraction: 0.06438
Policy Update Magnitude: 0.20838
Value Function Update Magnitude: 0.40094

Collected Steps per Second: 22,775.97386
Overall Steps per Second: 14,740.98245

Timestep Collection Time: 2.19670
Timestep Consumption Time: 1.19737
PPO Batch Consumption Time: 0.09877
Total Iteration Time: 3.39408

Cumulative Model Updates: 63,026
Cumulative Timesteps: 525,802,174

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 525802174...
Checkpoint 525802174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,043.14767
Policy Entropy: 1.30224
Value Function Loss: 0.06008

Mean KL Divergence: 0.00563
SB3 Clip Fraction: 0.06607
Policy Update Magnitude: 0.19834
Value Function Update Magnitude: 0.41735

Collected Steps per Second: 22,366.80196
Overall Steps per Second: 14,294.68910

Timestep Collection Time: 2.23581
Timestep Consumption Time: 1.26255
PPO Batch Consumption Time: 0.10228
Total Iteration Time: 3.49836

Cumulative Model Updates: 63,032
Cumulative Timesteps: 525,852,182

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,189.15661
Policy Entropy: 1.29490
Value Function Loss: 0.06154

Mean KL Divergence: 0.00508
SB3 Clip Fraction: 0.05966
Policy Update Magnitude: 0.19831
Value Function Update Magnitude: 0.43042

Collected Steps per Second: 22,684.76641
Overall Steps per Second: 14,480.06846

Timestep Collection Time: 2.20518
Timestep Consumption Time: 1.24950
PPO Batch Consumption Time: 0.10024
Total Iteration Time: 3.45468

Cumulative Model Updates: 63,038
Cumulative Timesteps: 525,902,206

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 525902206...
Checkpoint 525902206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,086.76292
Policy Entropy: 1.27933
Value Function Loss: 0.05635

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.09334
Policy Update Magnitude: 0.18861
Value Function Update Magnitude: 0.41832

Collected Steps per Second: 21,970.01489
Overall Steps per Second: 14,199.11758

Timestep Collection Time: 2.27738
Timestep Consumption Time: 1.24636
PPO Batch Consumption Time: 0.10357
Total Iteration Time: 3.52374

Cumulative Model Updates: 63,044
Cumulative Timesteps: 525,952,240

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,234.62951
Policy Entropy: 1.26154
Value Function Loss: 0.05903

Mean KL Divergence: 0.00643
SB3 Clip Fraction: 0.06896
Policy Update Magnitude: 0.19325
Value Function Update Magnitude: 0.39542

Collected Steps per Second: 22,797.66717
Overall Steps per Second: 14,512.39611

Timestep Collection Time: 2.19365
Timestep Consumption Time: 1.25237
PPO Batch Consumption Time: 0.10762
Total Iteration Time: 3.44602

Cumulative Model Updates: 63,050
Cumulative Timesteps: 526,002,250

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 526002250...
Checkpoint 526002250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,760.59016
Policy Entropy: 1.26784
Value Function Loss: 0.06327

Mean KL Divergence: 0.00431
SB3 Clip Fraction: 0.04885
Policy Update Magnitude: 0.20024
Value Function Update Magnitude: 0.38142

Collected Steps per Second: 22,760.97882
Overall Steps per Second: 14,670.45351

Timestep Collection Time: 2.19727
Timestep Consumption Time: 1.21176
PPO Batch Consumption Time: 0.09786
Total Iteration Time: 3.40903

Cumulative Model Updates: 63,056
Cumulative Timesteps: 526,052,262

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,609.58552
Policy Entropy: 1.28433
Value Function Loss: 0.06529

Mean KL Divergence: 0.00480
SB3 Clip Fraction: 0.05727
Policy Update Magnitude: 0.20780
Value Function Update Magnitude: 0.38234

Collected Steps per Second: 22,608.11852
Overall Steps per Second: 14,537.06756

Timestep Collection Time: 2.21213
Timestep Consumption Time: 1.22818
PPO Batch Consumption Time: 0.10191
Total Iteration Time: 3.44031

Cumulative Model Updates: 63,062
Cumulative Timesteps: 526,102,274

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 526102274...
Checkpoint 526102274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,035.45108
Policy Entropy: 1.29346
Value Function Loss: 0.06380

Mean KL Divergence: 0.00529
SB3 Clip Fraction: 0.06322
Policy Update Magnitude: 0.20292
Value Function Update Magnitude: 0.39812

Collected Steps per Second: 22,443.41305
Overall Steps per Second: 14,508.33055

Timestep Collection Time: 2.22818
Timestep Consumption Time: 1.21867
PPO Batch Consumption Time: 0.10354
Total Iteration Time: 3.44685

Cumulative Model Updates: 63,068
Cumulative Timesteps: 526,152,282

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,668.93502
Policy Entropy: 1.28610
Value Function Loss: 0.05628

Mean KL Divergence: 0.00504
SB3 Clip Fraction: 0.06034
Policy Update Magnitude: 0.20718
Value Function Update Magnitude: 0.40432

Collected Steps per Second: 22,874.94806
Overall Steps per Second: 14,726.53321

Timestep Collection Time: 2.18658
Timestep Consumption Time: 1.20987
PPO Batch Consumption Time: 0.10140
Total Iteration Time: 3.39645

Cumulative Model Updates: 63,074
Cumulative Timesteps: 526,202,300

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 526202300...
Checkpoint 526202300 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,262.38137
Policy Entropy: 1.27507
Value Function Loss: 0.05624

Mean KL Divergence: 0.00516
SB3 Clip Fraction: 0.06244
Policy Update Magnitude: 0.20361
Value Function Update Magnitude: 0.39410

Collected Steps per Second: 22,741.89684
Overall Steps per Second: 14,685.34935

Timestep Collection Time: 2.19920
Timestep Consumption Time: 1.20651
PPO Batch Consumption Time: 0.09391
Total Iteration Time: 3.40571

Cumulative Model Updates: 63,080
Cumulative Timesteps: 526,252,314

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,839.81102
Policy Entropy: 1.29232
Value Function Loss: 0.05802

Mean KL Divergence: 0.00505
SB3 Clip Fraction: 0.05958
Policy Update Magnitude: 0.21076
Value Function Update Magnitude: 0.37768

Collected Steps per Second: 22,963.21853
Overall Steps per Second: 14,753.69995

Timestep Collection Time: 2.17783
Timestep Consumption Time: 1.21183
PPO Batch Consumption Time: 0.09460
Total Iteration Time: 3.38966

Cumulative Model Updates: 63,086
Cumulative Timesteps: 526,302,324

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 526302324...
Checkpoint 526302324 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,154.20916
Policy Entropy: 1.29968
Value Function Loss: 0.06200

Mean KL Divergence: 0.00446
SB3 Clip Fraction: 0.05342
Policy Update Magnitude: 0.21193
Value Function Update Magnitude: 0.41116

Collected Steps per Second: 22,489.21949
Overall Steps per Second: 14,482.50459

Timestep Collection Time: 2.22364
Timestep Consumption Time: 1.22935
PPO Batch Consumption Time: 0.10193
Total Iteration Time: 3.45299

Cumulative Model Updates: 63,092
Cumulative Timesteps: 526,352,332

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,933.96721
Policy Entropy: 1.30868
Value Function Loss: 0.06281

Mean KL Divergence: 0.00472
SB3 Clip Fraction: 0.05624
Policy Update Magnitude: 0.22160
Value Function Update Magnitude: 0.43289

Collected Steps per Second: 22,657.67285
Overall Steps per Second: 14,653.03283

Timestep Collection Time: 2.20844
Timestep Consumption Time: 1.20642
PPO Batch Consumption Time: 0.10044
Total Iteration Time: 3.41486

Cumulative Model Updates: 63,098
Cumulative Timesteps: 526,402,370

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 526402370...
Checkpoint 526402370 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,781.05121
Policy Entropy: 1.29814
Value Function Loss: 0.06578

Mean KL Divergence: 0.00431
SB3 Clip Fraction: 0.05160
Policy Update Magnitude: 0.22524
Value Function Update Magnitude: 0.42052

Collected Steps per Second: 22,472.90765
Overall Steps per Second: 14,473.53465

Timestep Collection Time: 2.22570
Timestep Consumption Time: 1.23012
PPO Batch Consumption Time: 0.09747
Total Iteration Time: 3.45582

Cumulative Model Updates: 63,104
Cumulative Timesteps: 526,452,388

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,359.67672
Policy Entropy: 1.27592
Value Function Loss: 0.06413

Mean KL Divergence: 0.00523
SB3 Clip Fraction: 0.06226
Policy Update Magnitude: 0.21866
Value Function Update Magnitude: 0.42469

Collected Steps per Second: 22,712.59784
Overall Steps per Second: 14,707.65745

Timestep Collection Time: 2.20274
Timestep Consumption Time: 1.19889
PPO Batch Consumption Time: 0.09292
Total Iteration Time: 3.40163

Cumulative Model Updates: 63,110
Cumulative Timesteps: 526,502,418

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 526502418...
Checkpoint 526502418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,388.26833
Policy Entropy: 1.26542
Value Function Loss: 0.05814

Mean KL Divergence: 0.00477
SB3 Clip Fraction: 0.05499
Policy Update Magnitude: 0.21467
Value Function Update Magnitude: 0.42182

Collected Steps per Second: 22,641.98815
Overall Steps per Second: 14,524.10890

Timestep Collection Time: 2.20873
Timestep Consumption Time: 1.23451
PPO Batch Consumption Time: 0.10224
Total Iteration Time: 3.44324

Cumulative Model Updates: 63,116
Cumulative Timesteps: 526,552,428

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,523.27024
Policy Entropy: 1.24976
Value Function Loss: 0.05297

Mean KL Divergence: 0.00469
SB3 Clip Fraction: 0.05402
Policy Update Magnitude: 0.21399
Value Function Update Magnitude: 0.40326

Collected Steps per Second: 22,882.00641
Overall Steps per Second: 14,664.66935

Timestep Collection Time: 2.18573
Timestep Consumption Time: 1.22477
PPO Batch Consumption Time: 0.10056
Total Iteration Time: 3.41051

Cumulative Model Updates: 63,122
Cumulative Timesteps: 526,602,442

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 526602442...
Checkpoint 526602442 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,947.60483
Policy Entropy: 1.24570
Value Function Loss: 0.05176

Mean KL Divergence: 0.00481
SB3 Clip Fraction: 0.05628
Policy Update Magnitude: 0.21099
Value Function Update Magnitude: 0.37440

Collected Steps per Second: 22,368.13720
Overall Steps per Second: 14,543.86936

Timestep Collection Time: 2.23613
Timestep Consumption Time: 1.20299
PPO Batch Consumption Time: 0.09884
Total Iteration Time: 3.43911

Cumulative Model Updates: 63,128
Cumulative Timesteps: 526,652,460

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,331.46689
Policy Entropy: 1.25464
Value Function Loss: 0.05347

Mean KL Divergence: 0.00557
SB3 Clip Fraction: 0.06340
Policy Update Magnitude: 0.19956
Value Function Update Magnitude: 0.37013

Collected Steps per Second: 22,942.84661
Overall Steps per Second: 14,686.14932

Timestep Collection Time: 2.18037
Timestep Consumption Time: 1.22583
PPO Batch Consumption Time: 0.09767
Total Iteration Time: 3.40620

Cumulative Model Updates: 63,134
Cumulative Timesteps: 526,702,484

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 526702484...
Checkpoint 526702484 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,116.36260
Policy Entropy: 1.26031
Value Function Loss: 0.05764

Mean KL Divergence: 0.00575
SB3 Clip Fraction: 0.06418
Policy Update Magnitude: 0.20094
Value Function Update Magnitude: 0.38909

Collected Steps per Second: 22,655.01979
Overall Steps per Second: 14,444.76634

Timestep Collection Time: 2.20834
Timestep Consumption Time: 1.25520
PPO Batch Consumption Time: 0.10261
Total Iteration Time: 3.46354

Cumulative Model Updates: 63,140
Cumulative Timesteps: 526,752,514

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,868.19947
Policy Entropy: 1.25835
Value Function Loss: 0.05693

Mean KL Divergence: 0.00666
SB3 Clip Fraction: 0.07649
Policy Update Magnitude: 0.20002
Value Function Update Magnitude: 0.39988

Collected Steps per Second: 22,539.65761
Overall Steps per Second: 14,578.06737

Timestep Collection Time: 2.21964
Timestep Consumption Time: 1.21222
PPO Batch Consumption Time: 0.10146
Total Iteration Time: 3.43187

Cumulative Model Updates: 63,146
Cumulative Timesteps: 526,802,544

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 526802544...
Checkpoint 526802544 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,525.92122
Policy Entropy: 1.25750
Value Function Loss: 0.06828

Mean KL Divergence: 0.00640
SB3 Clip Fraction: 0.07225
Policy Update Magnitude: 0.19955
Value Function Update Magnitude: 0.41250

Collected Steps per Second: 22,634.73346
Overall Steps per Second: 14,594.38257

Timestep Collection Time: 2.21058
Timestep Consumption Time: 1.21786
PPO Batch Consumption Time: 0.09983
Total Iteration Time: 3.42844

Cumulative Model Updates: 63,152
Cumulative Timesteps: 526,852,580

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,780.82303
Policy Entropy: 1.24208
Value Function Loss: 0.07112

Mean KL Divergence: 0.00560
SB3 Clip Fraction: 0.06655
Policy Update Magnitude: 0.21124
Value Function Update Magnitude: 0.42645

Collected Steps per Second: 22,819.93215
Overall Steps per Second: 14,732.70857

Timestep Collection Time: 2.19212
Timestep Consumption Time: 1.20332
PPO Batch Consumption Time: 0.09819
Total Iteration Time: 3.39544

Cumulative Model Updates: 63,158
Cumulative Timesteps: 526,902,604

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 526902604...
Checkpoint 526902604 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,182.05295
Policy Entropy: 1.25335
Value Function Loss: 0.07210

Mean KL Divergence: 0.00560
SB3 Clip Fraction: 0.06779
Policy Update Magnitude: 0.21911
Value Function Update Magnitude: 0.42105

Collected Steps per Second: 21,844.76316
Overall Steps per Second: 14,081.57609

Timestep Collection Time: 2.28888
Timestep Consumption Time: 1.26186
PPO Batch Consumption Time: 0.10211
Total Iteration Time: 3.55074

Cumulative Model Updates: 63,164
Cumulative Timesteps: 526,952,604

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,793.57826
Policy Entropy: 1.24348
Value Function Loss: 0.06350

Mean KL Divergence: 0.00690
SB3 Clip Fraction: 0.07653
Policy Update Magnitude: 0.20710
Value Function Update Magnitude: 0.40153

Collected Steps per Second: 22,390.76914
Overall Steps per Second: 14,625.01817

Timestep Collection Time: 2.23431
Timestep Consumption Time: 1.18640
PPO Batch Consumption Time: 0.09408
Total Iteration Time: 3.42071

Cumulative Model Updates: 63,170
Cumulative Timesteps: 527,002,632

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 527002632...
Checkpoint 527002632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,907.34551
Policy Entropy: 1.25127
Value Function Loss: 0.05919

Mean KL Divergence: 0.00536
SB3 Clip Fraction: 0.06258
Policy Update Magnitude: 0.19831
Value Function Update Magnitude: 0.39816

Collected Steps per Second: 22,605.54468
Overall Steps per Second: 14,814.96845

Timestep Collection Time: 2.21194
Timestep Consumption Time: 1.16316
PPO Batch Consumption Time: 0.09249
Total Iteration Time: 3.37510

Cumulative Model Updates: 63,176
Cumulative Timesteps: 527,052,634

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,031.31090
Policy Entropy: 1.25331
Value Function Loss: 0.05864

Mean KL Divergence: 0.00426
SB3 Clip Fraction: 0.05016
Policy Update Magnitude: 0.20531
Value Function Update Magnitude: 0.39207

Collected Steps per Second: 22,244.41033
Overall Steps per Second: 14,348.71707

Timestep Collection Time: 2.24955
Timestep Consumption Time: 1.23787
PPO Batch Consumption Time: 0.10257
Total Iteration Time: 3.48742

Cumulative Model Updates: 63,182
Cumulative Timesteps: 527,102,674

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 527102674...
Checkpoint 527102674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,836.79967
Policy Entropy: 1.26099
Value Function Loss: 0.05914

Mean KL Divergence: 0.00489
SB3 Clip Fraction: 0.05847
Policy Update Magnitude: 0.20699
Value Function Update Magnitude: 0.39455

Collected Steps per Second: 22,678.51804
Overall Steps per Second: 14,530.92235

Timestep Collection Time: 2.20473
Timestep Consumption Time: 1.23621
PPO Batch Consumption Time: 0.10039
Total Iteration Time: 3.44094

Cumulative Model Updates: 63,188
Cumulative Timesteps: 527,152,674

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,596.96924
Policy Entropy: 1.28506
Value Function Loss: 0.05446

Mean KL Divergence: 0.00456
SB3 Clip Fraction: 0.05351
Policy Update Magnitude: 0.20373
Value Function Update Magnitude: 0.38263

Collected Steps per Second: 22,881.57281
Overall Steps per Second: 14,621.92722

Timestep Collection Time: 2.18551
Timestep Consumption Time: 1.23455
PPO Batch Consumption Time: 0.09503
Total Iteration Time: 3.42007

Cumulative Model Updates: 63,194
Cumulative Timesteps: 527,202,682

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 527202682...
Checkpoint 527202682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 52,202.07707
Policy Entropy: 1.27145
Value Function Loss: 0.05155

Mean KL Divergence: 0.00413
SB3 Clip Fraction: 0.05040
Policy Update Magnitude: 0.19646
Value Function Update Magnitude: 0.35137

Collected Steps per Second: 22,410.16382
Overall Steps per Second: 14,439.77055

Timestep Collection Time: 2.23113
Timestep Consumption Time: 1.23153
PPO Batch Consumption Time: 0.10269
Total Iteration Time: 3.46266

Cumulative Model Updates: 63,200
Cumulative Timesteps: 527,252,682

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55,303.26092
Policy Entropy: 1.27902
Value Function Loss: 0.04530

Mean KL Divergence: 0.00396
SB3 Clip Fraction: 0.04724
Policy Update Magnitude: 0.18751
Value Function Update Magnitude: 0.32039

Collected Steps per Second: 22,592.92288
Overall Steps per Second: 14,543.55743

Timestep Collection Time: 2.21308
Timestep Consumption Time: 1.22487
PPO Batch Consumption Time: 0.10208
Total Iteration Time: 3.43795

Cumulative Model Updates: 63,206
Cumulative Timesteps: 527,302,682

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 527302682...
Checkpoint 527302682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,412.07961
Policy Entropy: 1.26465
Value Function Loss: 0.05280

Mean KL Divergence: 0.00378
SB3 Clip Fraction: 0.04411
Policy Update Magnitude: 0.19120
Value Function Update Magnitude: 0.33415

Collected Steps per Second: 22,840.21399
Overall Steps per Second: 14,482.98601

Timestep Collection Time: 2.18973
Timestep Consumption Time: 1.26356
PPO Batch Consumption Time: 0.09644
Total Iteration Time: 3.45329

Cumulative Model Updates: 63,212
Cumulative Timesteps: 527,352,696

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,114.21156
Policy Entropy: 1.27320
Value Function Loss: 0.05449

Mean KL Divergence: 0.00479
SB3 Clip Fraction: 0.05705
Policy Update Magnitude: 0.19963
Value Function Update Magnitude: 0.36959

Collected Steps per Second: 19,526.16435
Overall Steps per Second: 12,958.71125

Timestep Collection Time: 2.56159
Timestep Consumption Time: 1.29821
PPO Batch Consumption Time: 0.09837
Total Iteration Time: 3.85980

Cumulative Model Updates: 63,218
Cumulative Timesteps: 527,402,714

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 527402714...
Checkpoint 527402714 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,693.95613
Policy Entropy: 1.28486
Value Function Loss: 0.05404

Mean KL Divergence: 0.00495
SB3 Clip Fraction: 0.06031
Policy Update Magnitude: 0.20166
Value Function Update Magnitude: 0.37907

Collected Steps per Second: 19,771.82916
Overall Steps per Second: 13,031.61139

Timestep Collection Time: 2.53017
Timestep Consumption Time: 1.30865
PPO Batch Consumption Time: 0.10285
Total Iteration Time: 3.83882

Cumulative Model Updates: 63,224
Cumulative Timesteps: 527,452,740

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,587.01667
Policy Entropy: 1.28576
Value Function Loss: 0.06262

Mean KL Divergence: 0.00527
SB3 Clip Fraction: 0.06167
Policy Update Magnitude: 0.19961
Value Function Update Magnitude: 0.36694

Collected Steps per Second: 17,820.07476
Overall Steps per Second: 12,454.07950

Timestep Collection Time: 2.80627
Timestep Consumption Time: 1.20912
PPO Batch Consumption Time: 0.09044
Total Iteration Time: 4.01539

Cumulative Model Updates: 63,230
Cumulative Timesteps: 527,502,748

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 527502748...
Checkpoint 527502748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,810.76002
Policy Entropy: 1.30380
Value Function Loss: 0.06273

Mean KL Divergence: 0.00459
SB3 Clip Fraction: 0.05474
Policy Update Magnitude: 0.20107
Value Function Update Magnitude: 0.37371

Collected Steps per Second: 20,644.64060
Overall Steps per Second: 13,575.06503

Timestep Collection Time: 2.42358
Timestep Consumption Time: 1.26215
PPO Batch Consumption Time: 0.10283
Total Iteration Time: 3.68573

Cumulative Model Updates: 63,236
Cumulative Timesteps: 527,552,782

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,480.46135
Policy Entropy: 1.28755
Value Function Loss: 0.07070

Mean KL Divergence: 0.00595
SB3 Clip Fraction: 0.06518
Policy Update Magnitude: 0.19859
Value Function Update Magnitude: 0.39491

Collected Steps per Second: 22,093.98265
Overall Steps per Second: 14,381.91164

Timestep Collection Time: 2.26378
Timestep Consumption Time: 1.21392
PPO Batch Consumption Time: 0.09417
Total Iteration Time: 3.47770

Cumulative Model Updates: 63,242
Cumulative Timesteps: 527,602,798

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 527602798...
Checkpoint 527602798 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,511.01695
Policy Entropy: 1.25921
Value Function Loss: 0.06646

Mean KL Divergence: 0.01078
SB3 Clip Fraction: 0.09766
Policy Update Magnitude: 0.18620
Value Function Update Magnitude: 0.39842

Collected Steps per Second: 20,473.87193
Overall Steps per Second: 13,324.05418

Timestep Collection Time: 2.44477
Timestep Consumption Time: 1.31189
PPO Batch Consumption Time: 0.10443
Total Iteration Time: 3.75666

Cumulative Model Updates: 63,248
Cumulative Timesteps: 527,652,852

Timesteps Collected: 50,054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,079.92202
Policy Entropy: 1.24694
Value Function Loss: 0.07115

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.08748
Policy Update Magnitude: 0.18085
Value Function Update Magnitude: 0.40668

Collected Steps per Second: 18,417.27640
Overall Steps per Second: 12,688.57814

Timestep Collection Time: 2.71560
Timestep Consumption Time: 1.22605
PPO Batch Consumption Time: 0.10008
Total Iteration Time: 3.94166

Cumulative Model Updates: 63,254
Cumulative Timesteps: 527,702,866

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 527702866...
Checkpoint 527702866 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,031.25838
Policy Entropy: 1.25205
Value Function Loss: 0.06784

Mean KL Divergence: 0.00739
SB3 Clip Fraction: 0.08003
Policy Update Magnitude: 0.19572
Value Function Update Magnitude: 0.42066

Collected Steps per Second: 19,844.43043
Overall Steps per Second: 12,876.49485

Timestep Collection Time: 2.52051
Timestep Consumption Time: 1.36394
PPO Batch Consumption Time: 0.11645
Total Iteration Time: 3.88444

Cumulative Model Updates: 63,260
Cumulative Timesteps: 527,752,884

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,168.86477
Policy Entropy: 1.26065
Value Function Loss: 0.06374

Mean KL Divergence: 0.00661
SB3 Clip Fraction: 0.07456
Policy Update Magnitude: 0.19381
Value Function Update Magnitude: 0.40867

Collected Steps per Second: 20,422.17752
Overall Steps per Second: 13,440.58653

Timestep Collection Time: 2.44998
Timestep Consumption Time: 1.27262
PPO Batch Consumption Time: 0.09876
Total Iteration Time: 3.72261

Cumulative Model Updates: 63,266
Cumulative Timesteps: 527,802,918

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 527802918...
Checkpoint 527802918 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,707.13745
Policy Entropy: 1.26735
Value Function Loss: 0.05991

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.09635
Policy Update Magnitude: 0.17999
Value Function Update Magnitude: 0.38308

Collected Steps per Second: 17,078.26207
Overall Steps per Second: 11,531.80157

Timestep Collection Time: 2.92817
Timestep Consumption Time: 1.40836
PPO Batch Consumption Time: 0.10925
Total Iteration Time: 4.33653

Cumulative Model Updates: 63,272
Cumulative Timesteps: 527,852,926

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,610.80685
Policy Entropy: 1.26349
Value Function Loss: 0.06694

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.09186
Policy Update Magnitude: 0.20106
Value Function Update Magnitude: 0.37423

Collected Steps per Second: 18,828.54636
Overall Steps per Second: 12,568.66905

Timestep Collection Time: 2.65735
Timestep Consumption Time: 1.32350
PPO Batch Consumption Time: 0.09962
Total Iteration Time: 3.98085

Cumulative Model Updates: 63,278
Cumulative Timesteps: 527,902,960

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 527902960...
Checkpoint 527902960 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40,768.86996
Policy Entropy: 1.28331
Value Function Loss: 0.06585

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.07973
Policy Update Magnitude: 0.21422
Value Function Update Magnitude: 0.38024

Collected Steps per Second: 21,128.28415
Overall Steps per Second: 13,287.22352

Timestep Collection Time: 2.36839
Timestep Consumption Time: 1.39763
PPO Batch Consumption Time: 0.11218
Total Iteration Time: 3.76602

Cumulative Model Updates: 63,284
Cumulative Timesteps: 527,953,000

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,336.47718
Policy Entropy: 1.28831
Value Function Loss: 0.06460

Mean KL Divergence: 0.00702
SB3 Clip Fraction: 0.07805
Policy Update Magnitude: 0.21587
Value Function Update Magnitude: 0.40854

Collected Steps per Second: 20,879.22559
Overall Steps per Second: 13,500.33621

Timestep Collection Time: 2.39587
Timestep Consumption Time: 1.30951
PPO Batch Consumption Time: 0.09946
Total Iteration Time: 3.70539

Cumulative Model Updates: 63,290
Cumulative Timesteps: 528,003,024

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 528003024...
Checkpoint 528003024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,199.67824
Policy Entropy: 1.30249
Value Function Loss: 0.05678

Mean KL Divergence: 0.00572
SB3 Clip Fraction: 0.06934
Policy Update Magnitude: 0.21145
Value Function Update Magnitude: 0.39417

Collected Steps per Second: 19,962.05892
Overall Steps per Second: 13,548.94031

Timestep Collection Time: 2.50625
Timestep Consumption Time: 1.18629
PPO Batch Consumption Time: 0.09235
Total Iteration Time: 3.69254

Cumulative Model Updates: 63,296
Cumulative Timesteps: 528,053,054

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,235.94547
Policy Entropy: 1.27926
Value Function Loss: 0.06796

Mean KL Divergence: 0.00596
SB3 Clip Fraction: 0.07054
Policy Update Magnitude: 0.21978
Value Function Update Magnitude: 0.39507

Collected Steps per Second: 21,511.77088
Overall Steps per Second: 13,864.83263

Timestep Collection Time: 2.32524
Timestep Consumption Time: 1.28245
PPO Batch Consumption Time: 0.10285
Total Iteration Time: 3.60769

Cumulative Model Updates: 63,302
Cumulative Timesteps: 528,103,074

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 528103074...
Checkpoint 528103074 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,283.28524
Policy Entropy: 1.27345
Value Function Loss: 0.06775

Mean KL Divergence: 0.00551
SB3 Clip Fraction: 0.06494
Policy Update Magnitude: 0.22377
Value Function Update Magnitude: 0.42521

Collected Steps per Second: 18,264.32417
Overall Steps per Second: 12,156.51758

Timestep Collection Time: 2.73966
Timestep Consumption Time: 1.37649
PPO Batch Consumption Time: 0.11128
Total Iteration Time: 4.11615

Cumulative Model Updates: 63,308
Cumulative Timesteps: 528,153,112

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,103.22448
Policy Entropy: 1.26069
Value Function Loss: 0.06455

Mean KL Divergence: 0.00472
SB3 Clip Fraction: 0.05786
Policy Update Magnitude: 0.22599
Value Function Update Magnitude: 0.43542

Collected Steps per Second: 14,190.67212
Overall Steps per Second: 10,221.86286

Timestep Collection Time: 3.52725
Timestep Consumption Time: 1.36951
PPO Batch Consumption Time: 0.07820
Total Iteration Time: 4.89676

Cumulative Model Updates: 63,314
Cumulative Timesteps: 528,203,166

Timesteps Collected: 50,054
--------END ITERATION REPORT--------


Saving checkpoint 528203166...
Checkpoint 528203166 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,412.93596
Policy Entropy: 1.28243
Value Function Loss: 0.06183

Mean KL Divergence: 0.00517
SB3 Clip Fraction: 0.06193
Policy Update Magnitude: 0.22232
Value Function Update Magnitude: 0.43021

Collected Steps per Second: 14,498.41101
Overall Steps per Second: 10,300.21089

Timestep Collection Time: 3.45169
Timestep Consumption Time: 1.40685
PPO Batch Consumption Time: 0.10559
Total Iteration Time: 4.85854

Cumulative Model Updates: 63,320
Cumulative Timesteps: 528,253,210

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,834.34332
Policy Entropy: 1.28718
Value Function Loss: 0.05814

Mean KL Divergence: 0.00531
SB3 Clip Fraction: 0.06446
Policy Update Magnitude: 0.21185
Value Function Update Magnitude: 0.39636

Collected Steps per Second: 13,237.72752
Overall Steps per Second: 9,360.42943

Timestep Collection Time: 3.77739
Timestep Consumption Time: 1.56468
PPO Batch Consumption Time: 0.13911
Total Iteration Time: 5.34206

Cumulative Model Updates: 63,326
Cumulative Timesteps: 528,303,214

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 528303214...
Checkpoint 528303214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,234.41593
Policy Entropy: 1.29427
Value Function Loss: 0.05926

Mean KL Divergence: 0.00579
SB3 Clip Fraction: 0.06814
Policy Update Magnitude: 0.20469
Value Function Update Magnitude: 0.39284

Collected Steps per Second: 14,321.37718
Overall Steps per Second: 10,095.95580

Timestep Collection Time: 3.49142
Timestep Consumption Time: 1.46125
PPO Batch Consumption Time: 0.12639
Total Iteration Time: 4.95268

Cumulative Model Updates: 63,332
Cumulative Timesteps: 528,353,216

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,107.59587
Policy Entropy: 1.29376
Value Function Loss: 0.06029

Mean KL Divergence: 0.00632
SB3 Clip Fraction: 0.06924
Policy Update Magnitude: 0.19856
Value Function Update Magnitude: 0.38734

Collected Steps per Second: 15,526.29452
Overall Steps per Second: 10,709.12403

Timestep Collection Time: 3.22228
Timestep Consumption Time: 1.44944
PPO Batch Consumption Time: 0.12506
Total Iteration Time: 4.67172

Cumulative Model Updates: 63,338
Cumulative Timesteps: 528,403,246

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 528403246...
Checkpoint 528403246 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,134.88084
Policy Entropy: 1.28556
Value Function Loss: 0.06107

Mean KL Divergence: 0.01073
SB3 Clip Fraction: 0.09473
Policy Update Magnitude: 0.19241
Value Function Update Magnitude: 0.39790

Collected Steps per Second: 13,585.39840
Overall Steps per Second: 9,693.50696

Timestep Collection Time: 3.68337
Timestep Consumption Time: 1.47885
PPO Batch Consumption Time: 0.12664
Total Iteration Time: 5.16222

Cumulative Model Updates: 63,344
Cumulative Timesteps: 528,453,286

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,131.57122
Policy Entropy: 1.29299
Value Function Loss: 0.06126

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.08435
Policy Update Magnitude: 0.19915
Value Function Update Magnitude: 0.39314

Collected Steps per Second: 15,210.82306
Overall Steps per Second: 10,558.70750

Timestep Collection Time: 3.28805
Timestep Consumption Time: 1.44870
PPO Batch Consumption Time: 0.11632
Total Iteration Time: 4.73675

Cumulative Model Updates: 63,350
Cumulative Timesteps: 528,503,300

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 528503300...
Checkpoint 528503300 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,217.01353
Policy Entropy: 1.30434
Value Function Loss: 0.06177

Mean KL Divergence: 0.00614
SB3 Clip Fraction: 0.07019
Policy Update Magnitude: 0.21150
Value Function Update Magnitude: 0.37509

Collected Steps per Second: 15,600.56028
Overall Steps per Second: 11,074.20766

Timestep Collection Time: 3.20617
Timestep Consumption Time: 1.31045
PPO Batch Consumption Time: 0.11813
Total Iteration Time: 4.51662

Cumulative Model Updates: 63,356
Cumulative Timesteps: 528,553,318

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,066.68330
Policy Entropy: 1.30576
Value Function Loss: 0.06415

Mean KL Divergence: 0.00568
SB3 Clip Fraction: 0.06536
Policy Update Magnitude: 0.21732
Value Function Update Magnitude: 0.37915

Collected Steps per Second: 15,965.38520
Overall Steps per Second: 11,336.78635

Timestep Collection Time: 3.13290
Timestep Consumption Time: 1.27911
PPO Batch Consumption Time: 0.11360
Total Iteration Time: 4.41201

Cumulative Model Updates: 63,362
Cumulative Timesteps: 528,603,336

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 528603336...
Checkpoint 528603336 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,282.56920
Policy Entropy: 1.30113
Value Function Loss: 0.06757

Mean KL Divergence: 0.00453
SB3 Clip Fraction: 0.05376
Policy Update Magnitude: 0.22548
Value Function Update Magnitude: 0.37265

Collected Steps per Second: 15,667.94506
Overall Steps per Second: 11,250.50985

Timestep Collection Time: 3.19263
Timestep Consumption Time: 1.25357
PPO Batch Consumption Time: 0.11104
Total Iteration Time: 4.44620

Cumulative Model Updates: 63,368
Cumulative Timesteps: 528,653,358

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,071.94871
Policy Entropy: 1.29674
Value Function Loss: 0.07306

Mean KL Divergence: 0.00561
SB3 Clip Fraction: 0.06516
Policy Update Magnitude: 0.22810
Value Function Update Magnitude: 0.39356

Collected Steps per Second: 15,808.31925
Overall Steps per Second: 11,233.64586

Timestep Collection Time: 3.16378
Timestep Consumption Time: 1.28838
PPO Batch Consumption Time: 0.11722
Total Iteration Time: 4.45216

Cumulative Model Updates: 63,374
Cumulative Timesteps: 528,703,372

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 528703372...
Checkpoint 528703372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,423.25659
Policy Entropy: 1.30059
Value Function Loss: 0.07189

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.08101
Policy Update Magnitude: 0.21477
Value Function Update Magnitude: 0.40266

Collected Steps per Second: 15,856.27766
Overall Steps per Second: 11,308.83936

Timestep Collection Time: 3.15522
Timestep Consumption Time: 1.26876
PPO Batch Consumption Time: 0.11515
Total Iteration Time: 4.42397

Cumulative Model Updates: 63,380
Cumulative Timesteps: 528,753,402

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,458.91880
Policy Entropy: 1.29119
Value Function Loss: 0.07621

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.08591
Policy Update Magnitude: 0.20462
Value Function Update Magnitude: 0.41456

Collected Steps per Second: 15,950.11408
Overall Steps per Second: 11,351.60965

Timestep Collection Time: 3.13640
Timestep Consumption Time: 1.27055
PPO Batch Consumption Time: 0.11329
Total Iteration Time: 4.40695

Cumulative Model Updates: 63,386
Cumulative Timesteps: 528,803,428

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 528803428...
Checkpoint 528803428 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,594.84798
Policy Entropy: 1.29690
Value Function Loss: 0.06976

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.08425
Policy Update Magnitude: 0.22265
Value Function Update Magnitude: 0.44869

Collected Steps per Second: 15,767.29013
Overall Steps per Second: 11,163.33392

Timestep Collection Time: 3.17264
Timestep Consumption Time: 1.30845
PPO Batch Consumption Time: 0.11915
Total Iteration Time: 4.48110

Cumulative Model Updates: 63,392
Cumulative Timesteps: 528,853,452

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,131.46995
Policy Entropy: 1.29839
Value Function Loss: 0.06395

Mean KL Divergence: 0.00714
SB3 Clip Fraction: 0.07814
Policy Update Magnitude: 0.23111
Value Function Update Magnitude: 0.44452

Collected Steps per Second: 15,594.27348
Overall Steps per Second: 10,737.90433

Timestep Collection Time: 3.20682
Timestep Consumption Time: 1.45033
PPO Batch Consumption Time: 0.13254
Total Iteration Time: 4.65715

Cumulative Model Updates: 63,398
Cumulative Timesteps: 528,903,460

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 528903460...
Checkpoint 528903460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,511.42656
Policy Entropy: 1.30120
Value Function Loss: 0.06315

Mean KL Divergence: 0.00665
SB3 Clip Fraction: 0.07586
Policy Update Magnitude: 0.22012
Value Function Update Magnitude: 0.41899

Collected Steps per Second: 13,422.60701
Overall Steps per Second: 9,516.99446

Timestep Collection Time: 3.72685
Timestep Consumption Time: 1.52943
PPO Batch Consumption Time: 0.13448
Total Iteration Time: 5.25628

Cumulative Model Updates: 63,404
Cumulative Timesteps: 528,953,484

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,205.08142
Policy Entropy: 1.29004
Value Function Loss: 0.06522

Mean KL Divergence: 0.00552
SB3 Clip Fraction: 0.06616
Policy Update Magnitude: 0.22086
Value Function Update Magnitude: 0.41159

Collected Steps per Second: 14,067.36339
Overall Steps per Second: 9,943.80371

Timestep Collection Time: 3.55603
Timestep Consumption Time: 1.47464
PPO Batch Consumption Time: 0.13509
Total Iteration Time: 5.03067

Cumulative Model Updates: 63,410
Cumulative Timesteps: 529,003,508

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 529003508...
Checkpoint 529003508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,084.19824
Policy Entropy: 1.29774
Value Function Loss: 0.07643

Mean KL Divergence: 0.00602
SB3 Clip Fraction: 0.06988
Policy Update Magnitude: 0.22920
Value Function Update Magnitude: 0.42405

Collected Steps per Second: 14,623.27720
Overall Steps per Second: 10,304.93975

Timestep Collection Time: 3.41962
Timestep Consumption Time: 1.43301
PPO Batch Consumption Time: 0.12517
Total Iteration Time: 4.85262

Cumulative Model Updates: 63,416
Cumulative Timesteps: 529,053,514

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,011.53588
Policy Entropy: 1.28823
Value Function Loss: 0.07885

Mean KL Divergence: 0.00699
SB3 Clip Fraction: 0.08012
Policy Update Magnitude: 0.23150
Value Function Update Magnitude: 0.44016

Collected Steps per Second: 14,895.91992
Overall Steps per Second: 10,398.36785

Timestep Collection Time: 3.35756
Timestep Consumption Time: 1.45223
PPO Batch Consumption Time: 0.12633
Total Iteration Time: 4.80979

Cumulative Model Updates: 63,422
Cumulative Timesteps: 529,103,528

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 529103528...
Checkpoint 529103528 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,307.52943
Policy Entropy: 1.30002
Value Function Loss: 0.08139

Mean KL Divergence: 0.00632
SB3 Clip Fraction: 0.07136
Policy Update Magnitude: 0.22475
Value Function Update Magnitude: 0.45109

Collected Steps per Second: 13,166.07853
Overall Steps per Second: 9,436.68960

Timestep Collection Time: 3.80068
Timestep Consumption Time: 1.50203
PPO Batch Consumption Time: 0.13085
Total Iteration Time: 5.30271

Cumulative Model Updates: 63,428
Cumulative Timesteps: 529,153,568

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,769.39278
Policy Entropy: 1.29403
Value Function Loss: 0.07095

Mean KL Divergence: 0.00592
SB3 Clip Fraction: 0.06959
Policy Update Magnitude: 0.21979
Value Function Update Magnitude: 0.43430

Collected Steps per Second: 14,535.84457
Overall Steps per Second: 10,259.45856

Timestep Collection Time: 3.44294
Timestep Consumption Time: 1.43510
PPO Batch Consumption Time: 0.12516
Total Iteration Time: 4.87804

Cumulative Model Updates: 63,434
Cumulative Timesteps: 529,203,614

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 529203614...
Checkpoint 529203614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,594.97171
Policy Entropy: 1.30041
Value Function Loss: 0.06995

Mean KL Divergence: 0.00570
SB3 Clip Fraction: 0.06765
Policy Update Magnitude: 0.21051
Value Function Update Magnitude: 0.41076

Collected Steps per Second: 15,286.97029
Overall Steps per Second: 10,653.06386

Timestep Collection Time: 3.27298
Timestep Consumption Time: 1.42369
PPO Batch Consumption Time: 0.12339
Total Iteration Time: 4.69668

Cumulative Model Updates: 63,440
Cumulative Timesteps: 529,253,648

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,428.30938
Policy Entropy: 1.30044
Value Function Loss: 0.06770

Mean KL Divergence: 0.00520
SB3 Clip Fraction: 0.06276
Policy Update Magnitude: 0.21050
Value Function Update Magnitude: 0.39907

Collected Steps per Second: 14,877.74392
Overall Steps per Second: 10,396.08696

Timestep Collection Time: 3.36072
Timestep Consumption Time: 1.44878
PPO Batch Consumption Time: 0.12428
Total Iteration Time: 4.80950

Cumulative Model Updates: 63,446
Cumulative Timesteps: 529,303,648

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 529303648...
Checkpoint 529303648 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,750.10595
Policy Entropy: 1.29228
Value Function Loss: 0.06456

Mean KL Divergence: 0.00531
SB3 Clip Fraction: 0.06207
Policy Update Magnitude: 0.21336
Value Function Update Magnitude: 0.42288

Collected Steps per Second: 14,821.90635
Overall Steps per Second: 10,144.69882

Timestep Collection Time: 3.37554
Timestep Consumption Time: 1.55629
PPO Batch Consumption Time: 0.14390
Total Iteration Time: 4.93184

Cumulative Model Updates: 63,452
Cumulative Timesteps: 529,353,680

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,959.99030
Policy Entropy: 1.28806
Value Function Loss: 0.06084

Mean KL Divergence: 0.00520
SB3 Clip Fraction: 0.06001
Policy Update Magnitude: 0.20160
Value Function Update Magnitude: 0.41953

Collected Steps per Second: 15,096.25902
Overall Steps per Second: 10,523.41472

Timestep Collection Time: 3.31393
Timestep Consumption Time: 1.44004
PPO Batch Consumption Time: 0.12539
Total Iteration Time: 4.75397

Cumulative Model Updates: 63,458
Cumulative Timesteps: 529,403,708

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 529403708...
Checkpoint 529403708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,684.28170
Policy Entropy: 1.28438
Value Function Loss: 0.05814

Mean KL Divergence: 0.00588
SB3 Clip Fraction: 0.06660
Policy Update Magnitude: 0.20094
Value Function Update Magnitude: 0.39955

Collected Steps per Second: 15,089.31191
Overall Steps per Second: 10,516.51473

Timestep Collection Time: 3.31506
Timestep Consumption Time: 1.44146
PPO Batch Consumption Time: 0.12450
Total Iteration Time: 4.75652

Cumulative Model Updates: 63,464
Cumulative Timesteps: 529,453,730

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,506.72215
Policy Entropy: 1.26831
Value Function Loss: 0.05856

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.08472
Policy Update Magnitude: 0.18823
Value Function Update Magnitude: 0.38126

Collected Steps per Second: 15,066.87348
Overall Steps per Second: 10,483.93718

Timestep Collection Time: 3.32040
Timestep Consumption Time: 1.45147
PPO Batch Consumption Time: 0.12531
Total Iteration Time: 4.77187

Cumulative Model Updates: 63,470
Cumulative Timesteps: 529,503,758

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 529503758...
Checkpoint 529503758 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,174.81735
Policy Entropy: 1.26062
Value Function Loss: 0.06112

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.08551
Policy Update Magnitude: 0.17982
Value Function Update Magnitude: 0.37415

Collected Steps per Second: 15,024.29831
Overall Steps per Second: 10,457.98392

Timestep Collection Time: 3.32914
Timestep Consumption Time: 1.45362
PPO Batch Consumption Time: 0.12616
Total Iteration Time: 4.78276

Cumulative Model Updates: 63,476
Cumulative Timesteps: 529,553,776

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,301.22768
Policy Entropy: 1.26817
Value Function Loss: 0.06245

Mean KL Divergence: 0.00656
SB3 Clip Fraction: 0.07126
Policy Update Magnitude: 0.19566
Value Function Update Magnitude: 0.38943

Collected Steps per Second: 14,468.20927
Overall Steps per Second: 10,341.55609

Timestep Collection Time: 3.45668
Timestep Consumption Time: 1.37934
PPO Batch Consumption Time: 0.11624
Total Iteration Time: 4.83602

Cumulative Model Updates: 63,482
Cumulative Timesteps: 529,603,788

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 529603788...
Checkpoint 529603788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,833.14044
Policy Entropy: 1.28280
Value Function Loss: 0.06470

Mean KL Divergence: 0.00656
SB3 Clip Fraction: 0.07362
Policy Update Magnitude: 0.20071
Value Function Update Magnitude: 0.39849

Collected Steps per Second: 15,126.73601
Overall Steps per Second: 10,626.96411

Timestep Collection Time: 3.30673
Timestep Consumption Time: 1.40017
PPO Batch Consumption Time: 0.11232
Total Iteration Time: 4.70689

Cumulative Model Updates: 63,488
Cumulative Timesteps: 529,653,808

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,993.84076
Policy Entropy: 1.28604
Value Function Loss: 0.06723

Mean KL Divergence: 0.00567
SB3 Clip Fraction: 0.06610
Policy Update Magnitude: 0.19934
Value Function Update Magnitude: 0.41784

Collected Steps per Second: 16,048.76752
Overall Steps per Second: 11,202.61202

Timestep Collection Time: 3.11837
Timestep Consumption Time: 1.34898
PPO Batch Consumption Time: 0.11151
Total Iteration Time: 4.46735

Cumulative Model Updates: 63,494
Cumulative Timesteps: 529,703,854

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 529703854...
Checkpoint 529703854 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,818.79753
Policy Entropy: 1.28638
Value Function Loss: 0.06617

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.08828
Policy Update Magnitude: 0.19866
Value Function Update Magnitude: 0.43521

Collected Steps per Second: 15,087.51055
Overall Steps per Second: 10,538.36968

Timestep Collection Time: 3.31479
Timestep Consumption Time: 1.43091
PPO Batch Consumption Time: 0.12319
Total Iteration Time: 4.74571

Cumulative Model Updates: 63,500
Cumulative Timesteps: 529,753,866

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,478.11148
Policy Entropy: 1.28390
Value Function Loss: 0.06855

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.09673
Policy Update Magnitude: 0.19901
Value Function Update Magnitude: 0.43850

Collected Steps per Second: 15,529.82973
Overall Steps per Second: 10,707.12141

Timestep Collection Time: 3.21974
Timestep Consumption Time: 1.45024
PPO Batch Consumption Time: 0.12620
Total Iteration Time: 4.66998

Cumulative Model Updates: 63,506
Cumulative Timesteps: 529,803,868

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 529803868...
Checkpoint 529803868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,115.90459
Policy Entropy: 1.29236
Value Function Loss: 0.06191

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.08749
Policy Update Magnitude: 0.21013
Value Function Update Magnitude: 0.44329

Collected Steps per Second: 14,943.14490
Overall Steps per Second: 10,489.99512

Timestep Collection Time: 3.34776
Timestep Consumption Time: 1.42117
PPO Batch Consumption Time: 0.12482
Total Iteration Time: 4.76893

Cumulative Model Updates: 63,512
Cumulative Timesteps: 529,853,894

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,011.15823
Policy Entropy: 1.29358
Value Function Loss: 0.05864

Mean KL Divergence: 0.00640
SB3 Clip Fraction: 0.07365
Policy Update Magnitude: 0.21003
Value Function Update Magnitude: 0.45148

Collected Steps per Second: 15,371.55059
Overall Steps per Second: 10,542.83858

Timestep Collection Time: 3.25419
Timestep Consumption Time: 1.49045
PPO Batch Consumption Time: 0.13577
Total Iteration Time: 4.74464

Cumulative Model Updates: 63,518
Cumulative Timesteps: 529,903,916

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 529903916...
Checkpoint 529903916 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,056.25687
Policy Entropy: 1.28758
Value Function Loss: 0.05160

Mean KL Divergence: 0.00529
SB3 Clip Fraction: 0.06308
Policy Update Magnitude: 0.20315
Value Function Update Magnitude: 0.42471

Collected Steps per Second: 14,128.48667
Overall Steps per Second: 9,893.66085

Timestep Collection Time: 3.53909
Timestep Consumption Time: 1.51485
PPO Batch Consumption Time: 0.13474
Total Iteration Time: 5.05394

Cumulative Model Updates: 63,524
Cumulative Timesteps: 529,953,918

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,093.57584
Policy Entropy: 1.28723
Value Function Loss: 0.05460

Mean KL Divergence: 0.00657
SB3 Clip Fraction: 0.06999
Policy Update Magnitude: 0.19892
Value Function Update Magnitude: 0.39598

Collected Steps per Second: 14,812.48663
Overall Steps per Second: 10,177.44576

Timestep Collection Time: 3.37634
Timestep Consumption Time: 1.53766
PPO Batch Consumption Time: 0.13388
Total Iteration Time: 4.91400

Cumulative Model Updates: 63,530
Cumulative Timesteps: 530,003,930

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 530003930...
Checkpoint 530003930 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,387.43958
Policy Entropy: 1.27338
Value Function Loss: 0.05870

Mean KL Divergence: 0.00564
SB3 Clip Fraction: 0.06551
Policy Update Magnitude: 0.20509
Value Function Update Magnitude: 0.40242

Collected Steps per Second: 13,735.46543
Overall Steps per Second: 9,592.22591

Timestep Collection Time: 3.64269
Timestep Consumption Time: 1.57341
PPO Batch Consumption Time: 0.14410
Total Iteration Time: 5.21610

Cumulative Model Updates: 63,536
Cumulative Timesteps: 530,053,964

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,300.40134
Policy Entropy: 1.27675
Value Function Loss: 0.06327

Mean KL Divergence: 0.00687
SB3 Clip Fraction: 0.07448
Policy Update Magnitude: 0.20723
Value Function Update Magnitude: 0.42634

Collected Steps per Second: 12,965.54864
Overall Steps per Second: 9,180.69290

Timestep Collection Time: 3.85822
Timestep Consumption Time: 1.59060
PPO Batch Consumption Time: 0.14127
Total Iteration Time: 5.44883

Cumulative Model Updates: 63,542
Cumulative Timesteps: 530,103,988

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 530103988...
Checkpoint 530103988 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,751.29825
Policy Entropy: 1.28570
Value Function Loss: 0.06600

Mean KL Divergence: 0.00522
SB3 Clip Fraction: 0.06163
Policy Update Magnitude: 0.21164
Value Function Update Magnitude: 0.43504

Collected Steps per Second: 13,705.31119
Overall Steps per Second: 9,541.40861

Timestep Collection Time: 3.64822
Timestep Consumption Time: 1.59210
PPO Batch Consumption Time: 0.14295
Total Iteration Time: 5.24032

Cumulative Model Updates: 63,548
Cumulative Timesteps: 530,153,988

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,423.65402
Policy Entropy: 1.29808
Value Function Loss: 0.06714

Mean KL Divergence: 0.00605
SB3 Clip Fraction: 0.06799
Policy Update Magnitude: 0.21657
Value Function Update Magnitude: 0.43919

Collected Steps per Second: 14,121.22998
Overall Steps per Second: 9,731.22283

Timestep Collection Time: 3.54190
Timestep Consumption Time: 1.59784
PPO Batch Consumption Time: 0.14187
Total Iteration Time: 5.13974

Cumulative Model Updates: 63,554
Cumulative Timesteps: 530,204,004

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 530204004...
Checkpoint 530204004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,645.09457
Policy Entropy: 1.30320
Value Function Loss: 0.07188

Mean KL Divergence: 0.00582
SB3 Clip Fraction: 0.06657
Policy Update Magnitude: 0.21516
Value Function Update Magnitude: 0.43773

Collected Steps per Second: 13,827.92446
Overall Steps per Second: 9,996.77851

Timestep Collection Time: 3.61775
Timestep Consumption Time: 1.38646
PPO Batch Consumption Time: 0.11536
Total Iteration Time: 5.00421

Cumulative Model Updates: 63,560
Cumulative Timesteps: 530,254,030

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,627.58890
Policy Entropy: 1.29632
Value Function Loss: 0.06563

Mean KL Divergence: 0.01055
SB3 Clip Fraction: 0.10589
Policy Update Magnitude: 0.20482
Value Function Update Magnitude: 0.42674

Collected Steps per Second: 15,684.99733
Overall Steps per Second: 10,754.90347

Timestep Collection Time: 3.18840
Timestep Consumption Time: 1.46157
PPO Batch Consumption Time: 0.12812
Total Iteration Time: 4.64997

Cumulative Model Updates: 63,566
Cumulative Timesteps: 530,304,040

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 530304040...
Checkpoint 530304040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,703.50167
Policy Entropy: 1.32257
Value Function Loss: 0.06484

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.09283
Policy Update Magnitude: 0.20384
Value Function Update Magnitude: 0.41865

Collected Steps per Second: 15,139.64822
Overall Steps per Second: 10,635.39807

Timestep Collection Time: 3.30470
Timestep Consumption Time: 1.39959
PPO Batch Consumption Time: 0.12152
Total Iteration Time: 4.70429

Cumulative Model Updates: 63,572
Cumulative Timesteps: 530,354,072

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,046.59690
Policy Entropy: 1.34133
Value Function Loss: 0.06155

Mean KL Divergence: 0.00695
SB3 Clip Fraction: 0.07967
Policy Update Magnitude: 0.20708
Value Function Update Magnitude: 0.40726

Collected Steps per Second: 15,798.67106
Overall Steps per Second: 11,267.22739

Timestep Collection Time: 3.16761
Timestep Consumption Time: 1.27395
PPO Batch Consumption Time: 0.11412
Total Iteration Time: 4.44155

Cumulative Model Updates: 63,578
Cumulative Timesteps: 530,404,116

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 530404116...
Checkpoint 530404116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,926.20217
Policy Entropy: 1.33460
Value Function Loss: 0.06512

Mean KL Divergence: 0.00595
SB3 Clip Fraction: 0.07028
Policy Update Magnitude: 0.21256
Value Function Update Magnitude: 0.40405

Collected Steps per Second: 15,577.35575
Overall Steps per Second: 11,369.15872

Timestep Collection Time: 3.21261
Timestep Consumption Time: 1.18912
PPO Batch Consumption Time: 0.09868
Total Iteration Time: 4.40173

Cumulative Model Updates: 63,584
Cumulative Timesteps: 530,454,160

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,216.08969
Policy Entropy: 1.32652
Value Function Loss: 0.06356

Mean KL Divergence: 0.00485
SB3 Clip Fraction: 0.05714
Policy Update Magnitude: 0.20959
Value Function Update Magnitude: 0.40320

Collected Steps per Second: 16,259.25509
Overall Steps per Second: 11,450.89371

Timestep Collection Time: 3.07640
Timestep Consumption Time: 1.29182
PPO Batch Consumption Time: 0.10651
Total Iteration Time: 4.36822

Cumulative Model Updates: 63,590
Cumulative Timesteps: 530,504,180

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 530504180...
Checkpoint 530504180 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,467.08172
Policy Entropy: 1.32757
Value Function Loss: 0.05950

Mean KL Divergence: 0.00416
SB3 Clip Fraction: 0.04899
Policy Update Magnitude: 0.20713
Value Function Update Magnitude: 0.39578

Collected Steps per Second: 17,602.67919
Overall Steps per Second: 12,463.11813

Timestep Collection Time: 2.84229
Timestep Consumption Time: 1.17211
PPO Batch Consumption Time: 0.09257
Total Iteration Time: 4.01440

Cumulative Model Updates: 63,596
Cumulative Timesteps: 530,554,212

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,836.56735
Policy Entropy: 1.34752
Value Function Loss: 0.05964

Mean KL Divergence: 0.00468
SB3 Clip Fraction: 0.05550
Policy Update Magnitude: 0.20422
Value Function Update Magnitude: 0.37753

Collected Steps per Second: 18,100.55153
Overall Steps per Second: 12,563.48330

Timestep Collection Time: 2.76356
Timestep Consumption Time: 1.21798
PPO Batch Consumption Time: 0.10624
Total Iteration Time: 3.98154

Cumulative Model Updates: 63,602
Cumulative Timesteps: 530,604,234

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 530604234...
Checkpoint 530604234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,934.77284
Policy Entropy: 1.32886
Value Function Loss: 0.06099

Mean KL Divergence: 0.00488
SB3 Clip Fraction: 0.05790
Policy Update Magnitude: 0.20493
Value Function Update Magnitude: 0.38580

Collected Steps per Second: 19,958.75505
Overall Steps per Second: 13,261.07346

Timestep Collection Time: 2.50557
Timestep Consumption Time: 1.26547
PPO Batch Consumption Time: 0.10507
Total Iteration Time: 3.77104

Cumulative Model Updates: 63,608
Cumulative Timesteps: 530,654,242

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,830.69486
Policy Entropy: 1.31853
Value Function Loss: 0.06227

Mean KL Divergence: 0.00573
SB3 Clip Fraction: 0.06772
Policy Update Magnitude: 0.20836
Value Function Update Magnitude: 0.38394

Collected Steps per Second: 21,691.22128
Overall Steps per Second: 14,077.01045

Timestep Collection Time: 2.30554
Timestep Consumption Time: 1.24706
PPO Batch Consumption Time: 0.09663
Total Iteration Time: 3.55260

Cumulative Model Updates: 63,614
Cumulative Timesteps: 530,704,252

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 530704252...
Checkpoint 530704252 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,124.26929
Policy Entropy: 1.33095
Value Function Loss: 0.06556

Mean KL Divergence: 0.00556
SB3 Clip Fraction: 0.06551
Policy Update Magnitude: 0.20663
Value Function Update Magnitude: 0.39646

Collected Steps per Second: 20,706.86980
Overall Steps per Second: 13,790.37001

Timestep Collection Time: 2.41659
Timestep Consumption Time: 1.21203
PPO Batch Consumption Time: 0.08487
Total Iteration Time: 3.62862

Cumulative Model Updates: 63,620
Cumulative Timesteps: 530,754,292

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,064.43006
Policy Entropy: 1.32949
Value Function Loss: 0.06759

Mean KL Divergence: 0.00511
SB3 Clip Fraction: 0.06049
Policy Update Magnitude: 0.21450
Value Function Update Magnitude: 0.39120

Collected Steps per Second: 21,211.53850
Overall Steps per Second: 14,044.46688

Timestep Collection Time: 2.35730
Timestep Consumption Time: 1.20296
PPO Batch Consumption Time: 0.09096
Total Iteration Time: 3.56026

Cumulative Model Updates: 63,626
Cumulative Timesteps: 530,804,294

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 530804294...
Checkpoint 530804294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,661.60797
Policy Entropy: 1.34703
Value Function Loss: 0.06562

Mean KL Divergence: 0.00740
SB3 Clip Fraction: 0.07754
Policy Update Magnitude: 0.20359
Value Function Update Magnitude: 0.39938

Collected Steps per Second: 19,285.52539
Overall Steps per Second: 12,785.81137

Timestep Collection Time: 2.59293
Timestep Consumption Time: 1.31813
PPO Batch Consumption Time: 0.10497
Total Iteration Time: 3.91105

Cumulative Model Updates: 63,632
Cumulative Timesteps: 530,854,300

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,145.44591
Policy Entropy: 1.33396
Value Function Loss: 0.05814

Mean KL Divergence: 0.01097
SB3 Clip Fraction: 0.09329
Policy Update Magnitude: 0.18551
Value Function Update Magnitude: 0.38023

Collected Steps per Second: 22,344.37844
Overall Steps per Second: 14,510.95319

Timestep Collection Time: 2.23994
Timestep Consumption Time: 1.20918
PPO Batch Consumption Time: 0.09441
Total Iteration Time: 3.44912

Cumulative Model Updates: 63,638
Cumulative Timesteps: 530,904,350

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 530904350...
Checkpoint 530904350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,053.48420
Policy Entropy: 1.35530
Value Function Loss: 0.06128

Mean KL Divergence: 0.01449
SB3 Clip Fraction: 0.11645
Policy Update Magnitude: 0.17308
Value Function Update Magnitude: 0.37237

Collected Steps per Second: 20,260.95593
Overall Steps per Second: 13,319.47284

Timestep Collection Time: 2.46829
Timestep Consumption Time: 1.28636
PPO Batch Consumption Time: 0.10217
Total Iteration Time: 3.75465

Cumulative Model Updates: 63,644
Cumulative Timesteps: 530,954,360

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,492.53382
Policy Entropy: 1.36293
Value Function Loss: 0.06654

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.09031
Policy Update Magnitude: 0.19417
Value Function Update Magnitude: 0.39250

Collected Steps per Second: 19,223.85778
Overall Steps per Second: 12,771.07806

Timestep Collection Time: 2.60187
Timestep Consumption Time: 1.31463
PPO Batch Consumption Time: 0.10478
Total Iteration Time: 3.91651

Cumulative Model Updates: 63,650
Cumulative Timesteps: 531,004,378

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 531004378...
Checkpoint 531004378 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,727.94308
Policy Entropy: 1.37721
Value Function Loss: 0.06695

Mean KL Divergence: 0.00667
SB3 Clip Fraction: 0.07364
Policy Update Magnitude: 0.20503
Value Function Update Magnitude: 0.41906

Collected Steps per Second: 19,554.93898
Overall Steps per Second: 12,923.36758

Timestep Collection Time: 2.55690
Timestep Consumption Time: 1.31206
PPO Batch Consumption Time: 0.10858
Total Iteration Time: 3.86896

Cumulative Model Updates: 63,656
Cumulative Timesteps: 531,054,378

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,042.89054
Policy Entropy: 1.37699
Value Function Loss: 0.05899

Mean KL Divergence: 0.00745
SB3 Clip Fraction: 0.08001
Policy Update Magnitude: 0.19235
Value Function Update Magnitude: 0.44550

Collected Steps per Second: 20,207.15465
Overall Steps per Second: 13,428.09164

Timestep Collection Time: 2.47487
Timestep Consumption Time: 1.24942
PPO Batch Consumption Time: 0.10129
Total Iteration Time: 3.72428

Cumulative Model Updates: 63,662
Cumulative Timesteps: 531,104,388

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 531104388...
Checkpoint 531104388 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,193.79337
Policy Entropy: 1.35280
Value Function Loss: 0.06283

Mean KL Divergence: 0.00530
SB3 Clip Fraction: 0.06048
Policy Update Magnitude: 0.19589
Value Function Update Magnitude: 0.38711

Collected Steps per Second: 17,791.18982
Overall Steps per Second: 11,899.34642

Timestep Collection Time: 2.81207
Timestep Consumption Time: 1.39237
PPO Batch Consumption Time: 0.11125
Total Iteration Time: 4.20443

Cumulative Model Updates: 63,668
Cumulative Timesteps: 531,154,418

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,532.38857
Policy Entropy: 1.33500
Value Function Loss: 0.06441

Mean KL Divergence: 0.00576
SB3 Clip Fraction: 0.06304
Policy Update Magnitude: 0.20737
Value Function Update Magnitude: 0.33558

Collected Steps per Second: 17,916.48628
Overall Steps per Second: 11,917.35663

Timestep Collection Time: 2.79084
Timestep Consumption Time: 1.40489
PPO Batch Consumption Time: 0.11533
Total Iteration Time: 4.19573

Cumulative Model Updates: 63,674
Cumulative Timesteps: 531,204,420

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 531204420...
Checkpoint 531204420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,910.54680
Policy Entropy: 1.32443
Value Function Loss: 0.07176

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.09538
Policy Update Magnitude: 0.20042
Value Function Update Magnitude: 0.37672

Collected Steps per Second: 17,515.67356
Overall Steps per Second: 11,804.90994

Timestep Collection Time: 2.85596
Timestep Consumption Time: 1.38160
PPO Batch Consumption Time: 0.10789
Total Iteration Time: 4.23756

Cumulative Model Updates: 63,680
Cumulative Timesteps: 531,254,444

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,864.14227
Policy Entropy: 1.32761
Value Function Loss: 0.06971

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.08486
Policy Update Magnitude: 0.20071
Value Function Update Magnitude: 0.39116

Collected Steps per Second: 17,487.24617
Overall Steps per Second: 11,938.90596

Timestep Collection Time: 2.86083
Timestep Consumption Time: 1.32951
PPO Batch Consumption Time: 0.10378
Total Iteration Time: 4.19033

Cumulative Model Updates: 63,686
Cumulative Timesteps: 531,304,472

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 531304472...
Checkpoint 531304472 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,610.00419
Policy Entropy: 1.34471
Value Function Loss: 0.07329

Mean KL Divergence: 0.00725
SB3 Clip Fraction: 0.08023
Policy Update Magnitude: 0.22010
Value Function Update Magnitude: 0.41365

Collected Steps per Second: 17,452.61746
Overall Steps per Second: 11,994.10807

Timestep Collection Time: 2.86731
Timestep Consumption Time: 1.30491
PPO Batch Consumption Time: 0.09973
Total Iteration Time: 4.17222

Cumulative Model Updates: 63,692
Cumulative Timesteps: 531,354,514

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,861.13576
Policy Entropy: 1.34603
Value Function Loss: 0.07044

Mean KL Divergence: 0.00551
SB3 Clip Fraction: 0.06455
Policy Update Magnitude: 0.22195
Value Function Update Magnitude: 0.40638

Collected Steps per Second: 21,914.66560
Overall Steps per Second: 13,820.32745

Timestep Collection Time: 2.28167
Timestep Consumption Time: 1.33634
PPO Batch Consumption Time: 0.10929
Total Iteration Time: 3.61800

Cumulative Model Updates: 63,698
Cumulative Timesteps: 531,404,516

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 531404516...
Checkpoint 531404516 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,365.98491
Policy Entropy: 1.35876
Value Function Loss: 0.06930

Mean KL Divergence: 0.00535
SB3 Clip Fraction: 0.06113
Policy Update Magnitude: 0.22504
Value Function Update Magnitude: 0.43683

Collected Steps per Second: 17,352.89784
Overall Steps per Second: 11,723.96841

Timestep Collection Time: 2.88194
Timestep Consumption Time: 1.38368
PPO Batch Consumption Time: 0.10706
Total Iteration Time: 4.26562

Cumulative Model Updates: 63,704
Cumulative Timesteps: 531,454,526

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,604.48556
Policy Entropy: 1.37619
Value Function Loss: 0.07283

Mean KL Divergence: 0.00473
SB3 Clip Fraction: 0.05629
Policy Update Magnitude: 0.22839
Value Function Update Magnitude: 0.43110

Collected Steps per Second: 19,700.55922
Overall Steps per Second: 13,426.99788

Timestep Collection Time: 2.54044
Timestep Consumption Time: 1.18698
PPO Batch Consumption Time: 0.09336
Total Iteration Time: 3.72742

Cumulative Model Updates: 63,710
Cumulative Timesteps: 531,504,574

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 531504574...
Checkpoint 531504574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,043.61077
Policy Entropy: 1.37470
Value Function Loss: 0.07269

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.09132
Policy Update Magnitude: 0.22367
Value Function Update Magnitude: 0.43012

Collected Steps per Second: 18,020.94224
Overall Steps per Second: 12,496.71092

Timestep Collection Time: 2.77644
Timestep Consumption Time: 1.22734
PPO Batch Consumption Time: 0.09375
Total Iteration Time: 4.00377

Cumulative Model Updates: 63,716
Cumulative Timesteps: 531,554,608

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,916.31573
Policy Entropy: 1.36716
Value Function Loss: 0.07274

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.09727
Policy Update Magnitude: 0.19544
Value Function Update Magnitude: 0.42505

Collected Steps per Second: 20,168.07319
Overall Steps per Second: 13,344.63296

Timestep Collection Time: 2.48016
Timestep Consumption Time: 1.26817
PPO Batch Consumption Time: 0.10042
Total Iteration Time: 3.74832

Cumulative Model Updates: 63,722
Cumulative Timesteps: 531,604,628

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 531604628...
Checkpoint 531604628 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,668.30081
Policy Entropy: 1.33780
Value Function Loss: 0.06173

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.09502
Policy Update Magnitude: 0.19158
Value Function Update Magnitude: 0.41450

Collected Steps per Second: 21,557.51819
Overall Steps per Second: 13,936.52540

Timestep Collection Time: 2.32030
Timestep Consumption Time: 1.26883
PPO Batch Consumption Time: 0.10209
Total Iteration Time: 3.58913

Cumulative Model Updates: 63,728
Cumulative Timesteps: 531,654,648

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,475.84698
Policy Entropy: 1.33749
Value Function Loss: 0.06382

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.10280
Policy Update Magnitude: 0.20301
Value Function Update Magnitude: 0.42593

Collected Steps per Second: 22,308.13241
Overall Steps per Second: 14,272.06642

Timestep Collection Time: 2.24286
Timestep Consumption Time: 1.26287
PPO Batch Consumption Time: 0.10245
Total Iteration Time: 3.50573

Cumulative Model Updates: 63,734
Cumulative Timesteps: 531,704,682

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 531704682...
Checkpoint 531704682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,796.77598
Policy Entropy: 1.33171
Value Function Loss: 0.05950

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.08440
Policy Update Magnitude: 0.20059
Value Function Update Magnitude: 0.42968

Collected Steps per Second: 22,176.18291
Overall Steps per Second: 14,447.17811

Timestep Collection Time: 2.25575
Timestep Consumption Time: 1.20679
PPO Batch Consumption Time: 0.09219
Total Iteration Time: 3.46254

Cumulative Model Updates: 63,740
Cumulative Timesteps: 531,754,706

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,368.05736
Policy Entropy: 1.34612
Value Function Loss: 0.06608

Mean KL Divergence: 0.00585
SB3 Clip Fraction: 0.06543
Policy Update Magnitude: 0.21011
Value Function Update Magnitude: 0.41912

Collected Steps per Second: 22,260.14203
Overall Steps per Second: 14,289.15878

Timestep Collection Time: 2.24644
Timestep Consumption Time: 1.25314
PPO Batch Consumption Time: 0.09995
Total Iteration Time: 3.49958

Cumulative Model Updates: 63,746
Cumulative Timesteps: 531,804,712

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 531804712...
Checkpoint 531804712 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,170.23969
Policy Entropy: 1.33806
Value Function Loss: 0.06851

Mean KL Divergence: 0.00607
SB3 Clip Fraction: 0.06898
Policy Update Magnitude: 0.21374
Value Function Update Magnitude: 0.41836

Collected Steps per Second: 22,155.49110
Overall Steps per Second: 14,368.67405

Timestep Collection Time: 2.25795
Timestep Consumption Time: 1.22365
PPO Batch Consumption Time: 0.10045
Total Iteration Time: 3.48160

Cumulative Model Updates: 63,752
Cumulative Timesteps: 531,854,738

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,521.65889
Policy Entropy: 1.33527
Value Function Loss: 0.07214

Mean KL Divergence: 0.00566
SB3 Clip Fraction: 0.06500
Policy Update Magnitude: 0.21328
Value Function Update Magnitude: 0.43574

Collected Steps per Second: 22,119.73724
Overall Steps per Second: 14,204.55917

Timestep Collection Time: 2.26106
Timestep Consumption Time: 1.25992
PPO Batch Consumption Time: 0.10352
Total Iteration Time: 3.52098

Cumulative Model Updates: 63,758
Cumulative Timesteps: 531,904,752

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 531904752...
Checkpoint 531904752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,840.52621
Policy Entropy: 1.32594
Value Function Loss: 0.06651

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.08747
Policy Update Magnitude: 0.20973
Value Function Update Magnitude: 0.44739

Collected Steps per Second: 21,864.41883
Overall Steps per Second: 14,039.21741

Timestep Collection Time: 2.28764
Timestep Consumption Time: 1.27509
PPO Batch Consumption Time: 0.10368
Total Iteration Time: 3.56273

Cumulative Model Updates: 63,764
Cumulative Timesteps: 531,954,770

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,596.16783
Policy Entropy: 1.31293
Value Function Loss: 0.06792

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.08540
Policy Update Magnitude: 0.20251
Value Function Update Magnitude: 0.43554

Collected Steps per Second: 22,844.61200
Overall Steps per Second: 14,531.55287

Timestep Collection Time: 2.18870
Timestep Consumption Time: 1.25209
PPO Batch Consumption Time: 0.09898
Total Iteration Time: 3.44079

Cumulative Model Updates: 63,770
Cumulative Timesteps: 532,004,770

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 532004770...
Checkpoint 532004770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,657.91190
Policy Entropy: 1.30967
Value Function Loss: 0.07011

Mean KL Divergence: 0.00777
SB3 Clip Fraction: 0.07816
Policy Update Magnitude: 0.21381
Value Function Update Magnitude: 0.42255

Collected Steps per Second: 18,731.82959
Overall Steps per Second: 12,626.51349

Timestep Collection Time: 2.67000
Timestep Consumption Time: 1.29103
PPO Batch Consumption Time: 0.09956
Total Iteration Time: 3.96103

Cumulative Model Updates: 63,776
Cumulative Timesteps: 532,054,784

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,786.00647
Policy Entropy: 1.32063
Value Function Loss: 0.07101

Mean KL Divergence: 0.00662
SB3 Clip Fraction: 0.07252
Policy Update Magnitude: 0.22989
Value Function Update Magnitude: 0.42138

Collected Steps per Second: 20,283.29639
Overall Steps per Second: 13,514.78314

Timestep Collection Time: 2.46656
Timestep Consumption Time: 1.23531
PPO Batch Consumption Time: 0.09873
Total Iteration Time: 3.70187

Cumulative Model Updates: 63,782
Cumulative Timesteps: 532,104,814

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 532104814...
Checkpoint 532104814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,791.73746
Policy Entropy: 1.34164
Value Function Loss: 0.06671

Mean KL Divergence: 0.00531
SB3 Clip Fraction: 0.06191
Policy Update Magnitude: 0.22669
Value Function Update Magnitude: 0.41222

Collected Steps per Second: 20,961.55752
Overall Steps per Second: 13,576.95119

Timestep Collection Time: 2.38732
Timestep Consumption Time: 1.29848
PPO Batch Consumption Time: 0.10398
Total Iteration Time: 3.68581

Cumulative Model Updates: 63,788
Cumulative Timesteps: 532,154,856

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,421.09822
Policy Entropy: 1.35123
Value Function Loss: 0.06744

Mean KL Divergence: 0.00502
SB3 Clip Fraction: 0.05908
Policy Update Magnitude: 0.21665
Value Function Update Magnitude: 0.40446

Collected Steps per Second: 22,139.12487
Overall Steps per Second: 14,132.78322

Timestep Collection Time: 2.25872
Timestep Consumption Time: 1.27958
PPO Batch Consumption Time: 0.10459
Total Iteration Time: 3.53830

Cumulative Model Updates: 63,794
Cumulative Timesteps: 532,204,862

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 532204862...
Checkpoint 532204862 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,102.08361
Policy Entropy: 1.33875
Value Function Loss: 0.06620

Mean KL Divergence: 0.00448
SB3 Clip Fraction: 0.05313
Policy Update Magnitude: 0.21437
Value Function Update Magnitude: 0.41196

Collected Steps per Second: 21,957.11038
Overall Steps per Second: 14,003.90422

Timestep Collection Time: 2.27835
Timestep Consumption Time: 1.29394
PPO Batch Consumption Time: 0.10452
Total Iteration Time: 3.57229

Cumulative Model Updates: 63,800
Cumulative Timesteps: 532,254,888

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,280.23330
Policy Entropy: 1.35138
Value Function Loss: 0.06236

Mean KL Divergence: 0.00447
SB3 Clip Fraction: 0.05237
Policy Update Magnitude: 0.21606
Value Function Update Magnitude: 0.37750

Collected Steps per Second: 21,769.93429
Overall Steps per Second: 13,942.74881

Timestep Collection Time: 2.29877
Timestep Consumption Time: 1.29048
PPO Batch Consumption Time: 0.10353
Total Iteration Time: 3.58925

Cumulative Model Updates: 63,806
Cumulative Timesteps: 532,304,932

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 532304932...
Checkpoint 532304932 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,029.63350
Policy Entropy: 1.33722
Value Function Loss: 0.05500

Mean KL Divergence: 0.00460
SB3 Clip Fraction: 0.05379
Policy Update Magnitude: 0.21397
Value Function Update Magnitude: 0.35722

Collected Steps per Second: 21,684.74784
Overall Steps per Second: 14,082.54864

Timestep Collection Time: 2.30724
Timestep Consumption Time: 1.24552
PPO Batch Consumption Time: 0.10154
Total Iteration Time: 3.55277

Cumulative Model Updates: 63,812
Cumulative Timesteps: 532,354,964

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,313.41493
Policy Entropy: 1.33998
Value Function Loss: 0.05215

Mean KL Divergence: 0.00490
SB3 Clip Fraction: 0.05683
Policy Update Magnitude: 0.20480
Value Function Update Magnitude: 0.35185

Collected Steps per Second: 22,511.33095
Overall Steps per Second: 14,603.61394

Timestep Collection Time: 2.22155
Timestep Consumption Time: 1.20295
PPO Batch Consumption Time: 0.09564
Total Iteration Time: 3.42449

Cumulative Model Updates: 63,818
Cumulative Timesteps: 532,404,974

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 532404974...
Checkpoint 532404974 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,287.28268
Policy Entropy: 1.32596
Value Function Loss: 0.05947

Mean KL Divergence: 0.00549
SB3 Clip Fraction: 0.06495
Policy Update Magnitude: 0.20354
Value Function Update Magnitude: 0.35631

Collected Steps per Second: 21,703.92468
Overall Steps per Second: 14,369.18577

Timestep Collection Time: 2.30502
Timestep Consumption Time: 1.17660
PPO Batch Consumption Time: 0.10142
Total Iteration Time: 3.48162

Cumulative Model Updates: 63,824
Cumulative Timesteps: 532,455,002

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,436.18495
Policy Entropy: 1.34430
Value Function Loss: 0.06625

Mean KL Divergence: 0.00487
SB3 Clip Fraction: 0.05641
Policy Update Magnitude: 0.21408
Value Function Update Magnitude: 0.38870

Collected Steps per Second: 20,087.05031
Overall Steps per Second: 13,684.01329

Timestep Collection Time: 2.48966
Timestep Consumption Time: 1.16497
PPO Batch Consumption Time: 0.10151
Total Iteration Time: 3.65463

Cumulative Model Updates: 63,830
Cumulative Timesteps: 532,505,012

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 532505012...
Checkpoint 532505012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,333.95420
Policy Entropy: 1.33960
Value Function Loss: 0.06888

Mean KL Divergence: 0.00578
SB3 Clip Fraction: 0.06783
Policy Update Magnitude: 0.21943
Value Function Update Magnitude: 0.41846

Collected Steps per Second: 20,187.10794
Overall Steps per Second: 13,700.46286

Timestep Collection Time: 2.47752
Timestep Consumption Time: 1.17301
PPO Batch Consumption Time: 0.09844
Total Iteration Time: 3.65053

Cumulative Model Updates: 63,836
Cumulative Timesteps: 532,555,026

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,526.60018
Policy Entropy: 1.32885
Value Function Loss: 0.06643

Mean KL Divergence: 0.00615
SB3 Clip Fraction: 0.07182
Policy Update Magnitude: 0.22171
Value Function Update Magnitude: 0.42241

Collected Steps per Second: 21,821.32468
Overall Steps per Second: 14,369.43346

Timestep Collection Time: 2.29253
Timestep Consumption Time: 1.18889
PPO Batch Consumption Time: 0.10207
Total Iteration Time: 3.48142

Cumulative Model Updates: 63,842
Cumulative Timesteps: 532,605,052

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 532605052...
Checkpoint 532605052 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,954.13511
Policy Entropy: 1.32047
Value Function Loss: 0.06356

Mean KL Divergence: 0.00635
SB3 Clip Fraction: 0.07212
Policy Update Magnitude: 0.22092
Value Function Update Magnitude: 0.42708

Collected Steps per Second: 21,918.85475
Overall Steps per Second: 14,525.96879

Timestep Collection Time: 2.28178
Timestep Consumption Time: 1.16130
PPO Batch Consumption Time: 0.09993
Total Iteration Time: 3.44307

Cumulative Model Updates: 63,848
Cumulative Timesteps: 532,655,066

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,293.74627
Policy Entropy: 1.33422
Value Function Loss: 0.06296

Mean KL Divergence: 0.00598
SB3 Clip Fraction: 0.06849
Policy Update Magnitude: 0.21677
Value Function Update Magnitude: 0.42655

Collected Steps per Second: 21,880.19837
Overall Steps per Second: 14,243.25578

Timestep Collection Time: 2.28599
Timestep Consumption Time: 1.22570
PPO Batch Consumption Time: 0.10794
Total Iteration Time: 3.51170

Cumulative Model Updates: 63,854
Cumulative Timesteps: 532,705,084

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 532705084...
Checkpoint 532705084 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,294.86783
Policy Entropy: 1.33954
Value Function Loss: 0.06132

Mean KL Divergence: 0.00484
SB3 Clip Fraction: 0.05726
Policy Update Magnitude: 0.20549
Value Function Update Magnitude: 0.40415

Collected Steps per Second: 21,120.07876
Overall Steps per Second: 13,945.97341

Timestep Collection Time: 2.36779
Timestep Consumption Time: 1.21804
PPO Batch Consumption Time: 0.10156
Total Iteration Time: 3.58584

Cumulative Model Updates: 63,860
Cumulative Timesteps: 532,755,092

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,827.67073
Policy Entropy: 1.33392
Value Function Loss: 0.06381

Mean KL Divergence: 0.00477
SB3 Clip Fraction: 0.05708
Policy Update Magnitude: 0.20449
Value Function Update Magnitude: 0.40392

Collected Steps per Second: 22,052.35440
Overall Steps per Second: 14,186.26903

Timestep Collection Time: 2.26869
Timestep Consumption Time: 1.25796
PPO Batch Consumption Time: 0.10142
Total Iteration Time: 3.52665

Cumulative Model Updates: 63,866
Cumulative Timesteps: 532,805,122

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 532805122...
Checkpoint 532805122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,995.07174
Policy Entropy: 1.32857
Value Function Loss: 0.06768

Mean KL Divergence: 0.00503
SB3 Clip Fraction: 0.06095
Policy Update Magnitude: 0.21390
Value Function Update Magnitude: 0.36894

Collected Steps per Second: 21,198.04689
Overall Steps per Second: 14,125.07750

Timestep Collection Time: 2.35975
Timestep Consumption Time: 1.18162
PPO Batch Consumption Time: 0.09630
Total Iteration Time: 3.54136

Cumulative Model Updates: 63,872
Cumulative Timesteps: 532,855,144

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,406.47651
Policy Entropy: 1.32414
Value Function Loss: 0.06219

Mean KL Divergence: 0.00486
SB3 Clip Fraction: 0.05870
Policy Update Magnitude: 0.21066
Value Function Update Magnitude: 0.37883

Collected Steps per Second: 22,815.30454
Overall Steps per Second: 14,539.88857

Timestep Collection Time: 2.19151
Timestep Consumption Time: 1.24730
PPO Batch Consumption Time: 0.10471
Total Iteration Time: 3.43882

Cumulative Model Updates: 63,878
Cumulative Timesteps: 532,905,144

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 532905144...
Checkpoint 532905144 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,040.92121
Policy Entropy: 1.31746
Value Function Loss: 0.06300

Mean KL Divergence: 0.00424
SB3 Clip Fraction: 0.04977
Policy Update Magnitude: 0.21114
Value Function Update Magnitude: 0.38438

Collected Steps per Second: 20,891.29426
Overall Steps per Second: 13,769.01180

Timestep Collection Time: 2.39554
Timestep Consumption Time: 1.23914
PPO Batch Consumption Time: 0.10515
Total Iteration Time: 3.63468

Cumulative Model Updates: 63,884
Cumulative Timesteps: 532,955,190

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,551.51756
Policy Entropy: 1.30762
Value Function Loss: 0.06285

Mean KL Divergence: 0.00487
SB3 Clip Fraction: 0.05689
Policy Update Magnitude: 0.21003
Value Function Update Magnitude: 0.38836

Collected Steps per Second: 22,597.08899
Overall Steps per Second: 14,442.60579

Timestep Collection Time: 2.21285
Timestep Consumption Time: 1.24940
PPO Batch Consumption Time: 0.10038
Total Iteration Time: 3.46226

Cumulative Model Updates: 63,890
Cumulative Timesteps: 533,005,194

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 533005194...
Checkpoint 533005194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,329.64056
Policy Entropy: 1.31559
Value Function Loss: 0.07006

Mean KL Divergence: 0.00453
SB3 Clip Fraction: 0.05287
Policy Update Magnitude: 0.21775
Value Function Update Magnitude: 0.40277

Collected Steps per Second: 21,282.92849
Overall Steps per Second: 13,620.09512

Timestep Collection Time: 2.34949
Timestep Consumption Time: 1.32185
PPO Batch Consumption Time: 0.10952
Total Iteration Time: 3.67134

Cumulative Model Updates: 63,896
Cumulative Timesteps: 533,055,198

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,557.54187
Policy Entropy: 1.33362
Value Function Loss: 0.06779

Mean KL Divergence: 0.00573
SB3 Clip Fraction: 0.06592
Policy Update Magnitude: 0.22306
Value Function Update Magnitude: 0.40227

Collected Steps per Second: 21,535.32753
Overall Steps per Second: 14,071.84276

Timestep Collection Time: 2.32242
Timestep Consumption Time: 1.23177
PPO Batch Consumption Time: 0.09709
Total Iteration Time: 3.55419

Cumulative Model Updates: 63,902
Cumulative Timesteps: 533,105,212

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 533105212...
Checkpoint 533105212 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,592.09171
Policy Entropy: 1.34018
Value Function Loss: 0.06952

Mean KL Divergence: 0.00526
SB3 Clip Fraction: 0.06032
Policy Update Magnitude: 0.22893
Value Function Update Magnitude: 0.39334

Collected Steps per Second: 22,377.58783
Overall Steps per Second: 14,274.87359

Timestep Collection Time: 2.23456
Timestep Consumption Time: 1.26838
PPO Batch Consumption Time: 0.10122
Total Iteration Time: 3.50294

Cumulative Model Updates: 63,908
Cumulative Timesteps: 533,155,216

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,533.51004
Policy Entropy: 1.35093
Value Function Loss: 0.06100

Mean KL Divergence: 0.00556
SB3 Clip Fraction: 0.06211
Policy Update Magnitude: 0.21290
Value Function Update Magnitude: 0.38753

Collected Steps per Second: 21,117.80115
Overall Steps per Second: 13,725.86068

Timestep Collection Time: 2.36843
Timestep Consumption Time: 1.27550
PPO Batch Consumption Time: 0.09889
Total Iteration Time: 3.64392

Cumulative Model Updates: 63,914
Cumulative Timesteps: 533,205,232

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 533205232...
Checkpoint 533205232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,749.21522
Policy Entropy: 1.34606
Value Function Loss: 0.06191

Mean KL Divergence: 0.00460
SB3 Clip Fraction: 0.05220
Policy Update Magnitude: 0.20115
Value Function Update Magnitude: 0.37684

Collected Steps per Second: 20,501.72920
Overall Steps per Second: 13,795.77476

Timestep Collection Time: 2.43979
Timestep Consumption Time: 1.18595
PPO Batch Consumption Time: 0.09186
Total Iteration Time: 3.62575

Cumulative Model Updates: 63,920
Cumulative Timesteps: 533,255,252

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,394.07298
Policy Entropy: 1.35325
Value Function Loss: 0.05936

Mean KL Divergence: 0.00453
SB3 Clip Fraction: 0.05249
Policy Update Magnitude: 0.20664
Value Function Update Magnitude: 0.36579

Collected Steps per Second: 21,035.10255
Overall Steps per Second: 13,937.47180

Timestep Collection Time: 2.37717
Timestep Consumption Time: 1.21057
PPO Batch Consumption Time: 0.09390
Total Iteration Time: 3.58774

Cumulative Model Updates: 63,926
Cumulative Timesteps: 533,305,256

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 533305256...
Checkpoint 533305256 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,427.37188
Policy Entropy: 1.33992
Value Function Loss: 0.05891

Mean KL Divergence: 0.00503
SB3 Clip Fraction: 0.05690
Policy Update Magnitude: 0.20619
Value Function Update Magnitude: 0.37904

Collected Steps per Second: 21,862.31121
Overall Steps per Second: 14,103.99910

Timestep Collection Time: 2.28905
Timestep Consumption Time: 1.25916
PPO Batch Consumption Time: 0.10063
Total Iteration Time: 3.54821

Cumulative Model Updates: 63,932
Cumulative Timesteps: 533,355,300

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,096.68222
Policy Entropy: 1.33576
Value Function Loss: 0.05928

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.08908
Policy Update Magnitude: 0.19115
Value Function Update Magnitude: 0.38656

Collected Steps per Second: 22,793.80848
Overall Steps per Second: 14,698.66085

Timestep Collection Time: 2.19472
Timestep Consumption Time: 1.20872
PPO Batch Consumption Time: 0.09600
Total Iteration Time: 3.40344

Cumulative Model Updates: 63,938
Cumulative Timesteps: 533,405,326

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 533405326...
Checkpoint 533405326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,963.68194
Policy Entropy: 1.32299
Value Function Loss: 0.06354

Mean KL Divergence: 0.00678
SB3 Clip Fraction: 0.07260
Policy Update Magnitude: 0.19304
Value Function Update Magnitude: 0.40034

Collected Steps per Second: 21,593.86248
Overall Steps per Second: 14,105.31485

Timestep Collection Time: 2.31575
Timestep Consumption Time: 1.22944
PPO Batch Consumption Time: 0.09721
Total Iteration Time: 3.54519

Cumulative Model Updates: 63,944
Cumulative Timesteps: 533,455,332

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,478.85800
Policy Entropy: 1.34391
Value Function Loss: 0.05767

Mean KL Divergence: 0.00693
SB3 Clip Fraction: 0.07778
Policy Update Magnitude: 0.21114
Value Function Update Magnitude: 0.40352

Collected Steps per Second: 22,274.85050
Overall Steps per Second: 14,393.80593

Timestep Collection Time: 2.24594
Timestep Consumption Time: 1.22972
PPO Batch Consumption Time: 0.09851
Total Iteration Time: 3.47566

Cumulative Model Updates: 63,950
Cumulative Timesteps: 533,505,360

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 533505360...
Checkpoint 533505360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,813.08909
Policy Entropy: 1.34284
Value Function Loss: 0.06148

Mean KL Divergence: 0.00599
SB3 Clip Fraction: 0.06744
Policy Update Magnitude: 0.20369
Value Function Update Magnitude: 0.38959

Collected Steps per Second: 21,054.32043
Overall Steps per Second: 13,845.13963

Timestep Collection Time: 2.37595
Timestep Consumption Time: 1.23716
PPO Batch Consumption Time: 0.10032
Total Iteration Time: 3.61311

Cumulative Model Updates: 63,956
Cumulative Timesteps: 533,555,384

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,147.58248
Policy Entropy: 1.34952
Value Function Loss: 0.06595

Mean KL Divergence: 0.00534
SB3 Clip Fraction: 0.06316
Policy Update Magnitude: 0.20976
Value Function Update Magnitude: 0.42336

Collected Steps per Second: 22,499.67099
Overall Steps per Second: 14,521.56826

Timestep Collection Time: 2.22332
Timestep Consumption Time: 1.22149
PPO Batch Consumption Time: 0.10168
Total Iteration Time: 3.44481

Cumulative Model Updates: 63,962
Cumulative Timesteps: 533,605,408

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 533605408...
Checkpoint 533605408 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,360.65360
Policy Entropy: 1.34091
Value Function Loss: 0.06960

Mean KL Divergence: 0.00722
SB3 Clip Fraction: 0.07548
Policy Update Magnitude: 0.20552
Value Function Update Magnitude: 0.43129

Collected Steps per Second: 20,064.70893
Overall Steps per Second: 13,349.18384

Timestep Collection Time: 2.49313
Timestep Consumption Time: 1.25421
PPO Batch Consumption Time: 0.10056
Total Iteration Time: 3.74735

Cumulative Model Updates: 63,968
Cumulative Timesteps: 533,655,432

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,341.48934
Policy Entropy: 1.32764
Value Function Loss: 0.06467

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.08925
Policy Update Magnitude: 0.18825
Value Function Update Magnitude: 0.41954

Collected Steps per Second: 22,370.70370
Overall Steps per Second: 14,507.25857

Timestep Collection Time: 2.23730
Timestep Consumption Time: 1.21270
PPO Batch Consumption Time: 0.09528
Total Iteration Time: 3.45000

Cumulative Model Updates: 63,974
Cumulative Timesteps: 533,705,482

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 533705482...
Checkpoint 533705482 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,337.45907
Policy Entropy: 1.31425
Value Function Loss: 0.05822

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.09265
Policy Update Magnitude: 0.19706
Value Function Update Magnitude: 0.38171

Collected Steps per Second: 21,851.17305
Overall Steps per Second: 13,990.48521

Timestep Collection Time: 2.28894
Timestep Consumption Time: 1.28606
PPO Batch Consumption Time: 0.10318
Total Iteration Time: 3.57500

Cumulative Model Updates: 63,980
Cumulative Timesteps: 533,755,498

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,351.62224
Policy Entropy: 1.32271
Value Function Loss: 0.05348

Mean KL Divergence: 0.00762
SB3 Clip Fraction: 0.08199
Policy Update Magnitude: 0.20307
Value Function Update Magnitude: 0.37801

Collected Steps per Second: 21,880.03219
Overall Steps per Second: 14,143.87768

Timestep Collection Time: 2.28647
Timestep Consumption Time: 1.25061
PPO Batch Consumption Time: 0.10218
Total Iteration Time: 3.53708

Cumulative Model Updates: 63,986
Cumulative Timesteps: 533,805,526

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 533805526...
Checkpoint 533805526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,249.87729
Policy Entropy: 1.32079
Value Function Loss: 0.05533

Mean KL Divergence: 0.00499
SB3 Clip Fraction: 0.05780
Policy Update Magnitude: 0.20254
Value Function Update Magnitude: 0.39625

Collected Steps per Second: 21,517.73897
Overall Steps per Second: 13,937.63105

Timestep Collection Time: 2.32404
Timestep Consumption Time: 1.26395
PPO Batch Consumption Time: 0.10392
Total Iteration Time: 3.58798

Cumulative Model Updates: 63,992
Cumulative Timesteps: 533,855,534

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,634.58371
Policy Entropy: 1.32329
Value Function Loss: 0.05350

Mean KL Divergence: 0.00430
SB3 Clip Fraction: 0.05059
Policy Update Magnitude: 0.20550
Value Function Update Magnitude: 0.38168

Collected Steps per Second: 19,907.71968
Overall Steps per Second: 13,206.07445

Timestep Collection Time: 2.51189
Timestep Consumption Time: 1.27470
PPO Batch Consumption Time: 0.10211
Total Iteration Time: 3.78659

Cumulative Model Updates: 63,998
Cumulative Timesteps: 533,905,540

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 533905540...
Checkpoint 533905540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,029.86825
Policy Entropy: 1.31367
Value Function Loss: 0.05749

Mean KL Divergence: 0.00495
SB3 Clip Fraction: 0.05827
Policy Update Magnitude: 0.20318
Value Function Update Magnitude: 0.37747

Collected Steps per Second: 22,011.14578
Overall Steps per Second: 14,166.52083

Timestep Collection Time: 2.27239
Timestep Consumption Time: 1.25832
PPO Batch Consumption Time: 0.10320
Total Iteration Time: 3.53072

Cumulative Model Updates: 64,004
Cumulative Timesteps: 533,955,558

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,586.25493
Policy Entropy: 1.32645
Value Function Loss: 0.05778

Mean KL Divergence: 0.00490
SB3 Clip Fraction: 0.05816
Policy Update Magnitude: 0.20868
Value Function Update Magnitude: 0.38602

Collected Steps per Second: 22,937.28562
Overall Steps per Second: 14,574.92591

Timestep Collection Time: 2.18116
Timestep Consumption Time: 1.25144
PPO Batch Consumption Time: 0.09923
Total Iteration Time: 3.43261

Cumulative Model Updates: 64,010
Cumulative Timesteps: 534,005,588

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 534005588...
Checkpoint 534005588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,160.73822
Policy Entropy: 1.34301
Value Function Loss: 0.06049

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.09012
Policy Update Magnitude: 0.20149
Value Function Update Magnitude: 0.37618

Collected Steps per Second: 22,545.96337
Overall Steps per Second: 14,032.75010

Timestep Collection Time: 2.21787
Timestep Consumption Time: 1.34551
PPO Batch Consumption Time: 0.11015
Total Iteration Time: 3.56338

Cumulative Model Updates: 64,016
Cumulative Timesteps: 534,055,592

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50,365.17814
Policy Entropy: 1.33012
Value Function Loss: 0.05781

Mean KL Divergence: 0.00733
SB3 Clip Fraction: 0.07662
Policy Update Magnitude: 0.18497
Value Function Update Magnitude: 0.36997

Collected Steps per Second: 22,507.33554
Overall Steps per Second: 14,314.95166

Timestep Collection Time: 2.22230
Timestep Consumption Time: 1.27181
PPO Batch Consumption Time: 0.09787
Total Iteration Time: 3.49411

Cumulative Model Updates: 64,022
Cumulative Timesteps: 534,105,610

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 534105610...
Checkpoint 534105610 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,803.87116
Policy Entropy: 1.33035
Value Function Loss: 0.05453

Mean KL Divergence: 0.00669
SB3 Clip Fraction: 0.07417
Policy Update Magnitude: 0.19593
Value Function Update Magnitude: 0.36127

Collected Steps per Second: 22,244.95989
Overall Steps per Second: 14,177.14742

Timestep Collection Time: 2.24923
Timestep Consumption Time: 1.27997
PPO Batch Consumption Time: 0.10852
Total Iteration Time: 3.52920

Cumulative Model Updates: 64,028
Cumulative Timesteps: 534,155,644

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42,470.98446
Policy Entropy: 1.32439
Value Function Loss: 0.05688

Mean KL Divergence: 0.00569
SB3 Clip Fraction: 0.06518
Policy Update Magnitude: 0.20086
Value Function Update Magnitude: 0.36665

Collected Steps per Second: 22,643.24002
Overall Steps per Second: 14,510.46148

Timestep Collection Time: 2.20931
Timestep Consumption Time: 1.23827
PPO Batch Consumption Time: 0.10069
Total Iteration Time: 3.44758

Cumulative Model Updates: 64,034
Cumulative Timesteps: 534,205,670

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 534205670...
Checkpoint 534205670 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,489.27620
Policy Entropy: 1.32399
Value Function Loss: 0.05314

Mean KL Divergence: 0.00586
SB3 Clip Fraction: 0.06956
Policy Update Magnitude: 0.20242
Value Function Update Magnitude: 0.41608

Collected Steps per Second: 21,111.71661
Overall Steps per Second: 13,891.26634

Timestep Collection Time: 2.36940
Timestep Consumption Time: 1.23157
PPO Batch Consumption Time: 0.10128
Total Iteration Time: 3.60097

Cumulative Model Updates: 64,040
Cumulative Timesteps: 534,255,692

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,476.63748
Policy Entropy: 1.31518
Value Function Loss: 0.05594

Mean KL Divergence: 0.00576
SB3 Clip Fraction: 0.06875
Policy Update Magnitude: 0.19579
Value Function Update Magnitude: 0.39324

Collected Steps per Second: 21,561.80546
Overall Steps per Second: 14,424.09629

Timestep Collection Time: 2.31929
Timestep Consumption Time: 1.14769
PPO Batch Consumption Time: 0.09474
Total Iteration Time: 3.46698

Cumulative Model Updates: 64,046
Cumulative Timesteps: 534,305,700

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 534305700...
Checkpoint 534305700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,000.00204
Policy Entropy: 1.31905
Value Function Loss: 0.05417

Mean KL Divergence: 0.00496
SB3 Clip Fraction: 0.05834
Policy Update Magnitude: 0.19884
Value Function Update Magnitude: 0.39099

Collected Steps per Second: 21,088.99140
Overall Steps per Second: 14,087.91732

Timestep Collection Time: 2.37214
Timestep Consumption Time: 1.17885
PPO Batch Consumption Time: 0.10015
Total Iteration Time: 3.55099

Cumulative Model Updates: 64,052
Cumulative Timesteps: 534,355,726

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,068.04216
Policy Entropy: 1.31667
Value Function Loss: 0.05296

Mean KL Divergence: 0.00493
SB3 Clip Fraction: 0.05810
Policy Update Magnitude: 0.19793
Value Function Update Magnitude: 0.38393

Collected Steps per Second: 21,447.41529
Overall Steps per Second: 14,328.25440

Timestep Collection Time: 2.33138
Timestep Consumption Time: 1.15837
PPO Batch Consumption Time: 0.09869
Total Iteration Time: 3.48975

Cumulative Model Updates: 64,058
Cumulative Timesteps: 534,405,728

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 534405728...
Checkpoint 534405728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,317.98077
Policy Entropy: 1.32029
Value Function Loss: 0.04991

Mean KL Divergence: 0.00407
SB3 Clip Fraction: 0.04817
Policy Update Magnitude: 0.19988
Value Function Update Magnitude: 0.37186

Collected Steps per Second: 19,076.02975
Overall Steps per Second: 12,869.33459

Timestep Collection Time: 2.62161
Timestep Consumption Time: 1.26437
PPO Batch Consumption Time: 0.10469
Total Iteration Time: 3.88598

Cumulative Model Updates: 64,064
Cumulative Timesteps: 534,455,738

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,227.16025
Policy Entropy: 1.33789
Value Function Loss: 0.04827

Mean KL Divergence: 0.00557
SB3 Clip Fraction: 0.06600
Policy Update Magnitude: 0.20140
Value Function Update Magnitude: 0.36146

Collected Steps per Second: 19,768.65153
Overall Steps per Second: 13,295.10585

Timestep Collection Time: 2.53057
Timestep Consumption Time: 1.23217
PPO Batch Consumption Time: 0.10402
Total Iteration Time: 3.76274

Cumulative Model Updates: 64,070
Cumulative Timesteps: 534,505,764

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 534505764...
Checkpoint 534505764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,682.99937
Policy Entropy: 1.33203
Value Function Loss: 0.04838

Mean KL Divergence: 0.00542
SB3 Clip Fraction: 0.06402
Policy Update Magnitude: 0.20104
Value Function Update Magnitude: 0.35914

Collected Steps per Second: 21,359.61575
Overall Steps per Second: 13,847.36517

Timestep Collection Time: 2.34227
Timestep Consumption Time: 1.27069
PPO Batch Consumption Time: 0.09198
Total Iteration Time: 3.61296

Cumulative Model Updates: 64,076
Cumulative Timesteps: 534,555,794

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,237.95689
Policy Entropy: 1.33271
Value Function Loss: 0.05081

Mean KL Divergence: 0.00670
SB3 Clip Fraction: 0.07697
Policy Update Magnitude: 0.19776
Value Function Update Magnitude: 0.36257

Collected Steps per Second: 21,564.21737
Overall Steps per Second: 14,073.65771

Timestep Collection Time: 2.31884
Timestep Consumption Time: 1.23418
PPO Batch Consumption Time: 0.09607
Total Iteration Time: 3.55302

Cumulative Model Updates: 64,082
Cumulative Timesteps: 534,605,798

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 534605798...
Checkpoint 534605798 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,373.73542
Policy Entropy: 1.31763
Value Function Loss: 0.05802

Mean KL Divergence: 0.00711
SB3 Clip Fraction: 0.08155
Policy Update Magnitude: 0.19938
Value Function Update Magnitude: 0.36295

Collected Steps per Second: 21,968.50010
Overall Steps per Second: 14,068.30378

Timestep Collection Time: 2.27608
Timestep Consumption Time: 1.27815
PPO Batch Consumption Time: 0.10407
Total Iteration Time: 3.55423

Cumulative Model Updates: 64,088
Cumulative Timesteps: 534,655,800

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,345.64359
Policy Entropy: 1.32560
Value Function Loss: 0.06788

Mean KL Divergence: 0.00656
SB3 Clip Fraction: 0.07521
Policy Update Magnitude: 0.21383
Value Function Update Magnitude: 0.41810

Collected Steps per Second: 20,667.07656
Overall Steps per Second: 13,384.10679

Timestep Collection Time: 2.41950
Timestep Consumption Time: 1.31657
PPO Batch Consumption Time: 0.10587
Total Iteration Time: 3.73607

Cumulative Model Updates: 64,094
Cumulative Timesteps: 534,705,804

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 534705804...
Checkpoint 534705804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,275.20575
Policy Entropy: 1.31663
Value Function Loss: 0.07579

Mean KL Divergence: 0.00494
SB3 Clip Fraction: 0.05798
Policy Update Magnitude: 0.23046
Value Function Update Magnitude: 0.43091

Collected Steps per Second: 21,319.37747
Overall Steps per Second: 13,827.41704

Timestep Collection Time: 2.34660
Timestep Consumption Time: 1.27143
PPO Batch Consumption Time: 0.10678
Total Iteration Time: 3.61803

Cumulative Model Updates: 64,100
Cumulative Timesteps: 534,755,832

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,938.58850
Policy Entropy: 1.32544
Value Function Loss: 0.06912

Mean KL Divergence: 0.00420
SB3 Clip Fraction: 0.04972
Policy Update Magnitude: 0.23162
Value Function Update Magnitude: 0.41450

Collected Steps per Second: 21,289.66261
Overall Steps per Second: 13,891.49142

Timestep Collection Time: 2.34978
Timestep Consumption Time: 1.25142
PPO Batch Consumption Time: 0.09978
Total Iteration Time: 3.60120

Cumulative Model Updates: 64,106
Cumulative Timesteps: 534,805,858

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 534805858...
Checkpoint 534805858 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,006.42634
Policy Entropy: 1.30207
Value Function Loss: 0.05910

Mean KL Divergence: 0.00507
SB3 Clip Fraction: 0.05892
Policy Update Magnitude: 0.21985
Value Function Update Magnitude: 0.41879

Collected Steps per Second: 21,066.09345
Overall Steps per Second: 13,895.22577

Timestep Collection Time: 2.37396
Timestep Consumption Time: 1.22512
PPO Batch Consumption Time: 0.09907
Total Iteration Time: 3.59908

Cumulative Model Updates: 64,112
Cumulative Timesteps: 534,855,868

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,266.90636
Policy Entropy: 1.30705
Value Function Loss: 0.05288

Mean KL Divergence: 0.00504
SB3 Clip Fraction: 0.05858
Policy Update Magnitude: 0.20337
Value Function Update Magnitude: 0.40373

Collected Steps per Second: 22,094.79288
Overall Steps per Second: 14,101.10249

Timestep Collection Time: 2.26424
Timestep Consumption Time: 1.28356
PPO Batch Consumption Time: 0.10541
Total Iteration Time: 3.54781

Cumulative Model Updates: 64,118
Cumulative Timesteps: 534,905,896

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 534905896...
Checkpoint 534905896 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 52,376.65352
Policy Entropy: 1.29269
Value Function Loss: 0.05113

Mean KL Divergence: 0.00630
SB3 Clip Fraction: 0.07268
Policy Update Magnitude: 0.18861
Value Function Update Magnitude: 0.37290

Collected Steps per Second: 22,011.57792
Overall Steps per Second: 14,233.78093

Timestep Collection Time: 2.27326
Timestep Consumption Time: 1.24218
PPO Batch Consumption Time: 0.10183
Total Iteration Time: 3.51544

Cumulative Model Updates: 64,124
Cumulative Timesteps: 534,955,934

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,531.27514
Policy Entropy: 1.30696
Value Function Loss: 0.05982

Mean KL Divergence: 0.00626
SB3 Clip Fraction: 0.07468
Policy Update Magnitude: 0.19374
Value Function Update Magnitude: 0.35226

Collected Steps per Second: 22,990.79265
Overall Steps per Second: 14,520.07553

Timestep Collection Time: 2.17531
Timestep Consumption Time: 1.26903
PPO Batch Consumption Time: 0.10172
Total Iteration Time: 3.44433

Cumulative Model Updates: 64,130
Cumulative Timesteps: 535,005,946

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 535005946...
Checkpoint 535005946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,374.69081
Policy Entropy: 1.31632
Value Function Loss: 0.05343

Mean KL Divergence: 0.00652
SB3 Clip Fraction: 0.07644
Policy Update Magnitude: 0.19107
Value Function Update Magnitude: 0.35263

Collected Steps per Second: 21,326.23778
Overall Steps per Second: 13,854.85406

Timestep Collection Time: 2.34453
Timestep Consumption Time: 1.26431
PPO Batch Consumption Time: 0.10183
Total Iteration Time: 3.60884

Cumulative Model Updates: 64,136
Cumulative Timesteps: 535,055,946

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,001.11350
Policy Entropy: 1.32477
Value Function Loss: 0.05913

Mean KL Divergence: 0.00563
SB3 Clip Fraction: 0.06741
Policy Update Magnitude: 0.18540
Value Function Update Magnitude: 0.35194

Collected Steps per Second: 19,646.73983
Overall Steps per Second: 13,162.12497

Timestep Collection Time: 2.54495
Timestep Consumption Time: 1.25383
PPO Batch Consumption Time: 0.09904
Total Iteration Time: 3.79878

Cumulative Model Updates: 64,142
Cumulative Timesteps: 535,105,946

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 535105946...
Checkpoint 535105946 saved!
