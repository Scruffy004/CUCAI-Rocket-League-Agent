Checkpoint loaded!
Learner successfully initialized!
Press (p) to pause (c) to checkpoint, (q) to checkpoint and quit (after next iteration)

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,502.51006
Policy Entropy: 2.12061
Value Function Loss: 0.02853

Mean KL Divergence: 0.00067
SB3 Clip Fraction: 0.00472
Policy Update Magnitude: 0.11577
Value Function Update Magnitude: 0.10678

Collected Steps per Second: 18,864.00097
Overall Steps per Second: 12,633.69643

Timestep Collection Time: 2.65066
Timestep Consumption Time: 1.30717
PPO Batch Consumption Time: 0.34454
Total Iteration Time: 3.95783

Cumulative Model Updates: 227,852
Cumulative Timesteps: 1,900,911,894

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,170.76566
Policy Entropy: 2.07755
Value Function Loss: 0.02946

Mean KL Divergence: 0.00305
SB3 Clip Fraction: 0.02526
Policy Update Magnitude: 0.12749
Value Function Update Magnitude: 0.11295

Collected Steps per Second: 17,241.37277
Overall Steps per Second: 11,664.09931

Timestep Collection Time: 2.90105
Timestep Consumption Time: 1.38716
PPO Batch Consumption Time: 0.32472
Total Iteration Time: 4.28820

Cumulative Model Updates: 227,854
Cumulative Timesteps: 1,900,961,912

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1900961912...
Checkpoint 1900961912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,027.51188
Policy Entropy: 2.06313
Value Function Loss: 0.02816

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.06387
Policy Update Magnitude: 0.24588
Value Function Update Magnitude: 0.24008

Collected Steps per Second: 17,187.84537
Overall Steps per Second: 10,335.48837

Timestep Collection Time: 2.90950
Timestep Consumption Time: 1.92898
PPO Batch Consumption Time: 0.29141
Total Iteration Time: 4.83847

Cumulative Model Updates: 227,858
Cumulative Timesteps: 1,901,011,920

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,998.78997
Policy Entropy: 2.03338
Value Function Loss: 0.02580

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.08615
Policy Update Magnitude: 0.33690
Value Function Update Magnitude: 0.36573

Collected Steps per Second: 16,777.64924
Overall Steps per Second: 8,385.39123

Timestep Collection Time: 2.98242
Timestep Consumption Time: 2.98486
PPO Batch Consumption Time: 0.36097
Total Iteration Time: 5.96728

Cumulative Model Updates: 227,864
Cumulative Timesteps: 1,901,061,958

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1901061958...
Checkpoint 1901061958 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,315.37204
Policy Entropy: 2.02411
Value Function Loss: 0.02130

Mean KL Divergence: 0.01080
SB3 Clip Fraction: 0.09604
Policy Update Magnitude: 0.31147
Value Function Update Magnitude: 0.34461

Collected Steps per Second: 16,085.90109
Overall Steps per Second: 8,127.03368

Timestep Collection Time: 3.10893
Timestep Consumption Time: 3.04460
PPO Batch Consumption Time: 0.35894
Total Iteration Time: 6.15354

Cumulative Model Updates: 227,870
Cumulative Timesteps: 1,901,111,968

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,448.62822
Policy Entropy: 2.00945
Value Function Loss: 0.02405

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.09501
Policy Update Magnitude: 0.30755
Value Function Update Magnitude: 0.31863

Collected Steps per Second: 16,560.52845
Overall Steps per Second: 8,409.44118

Timestep Collection Time: 3.01971
Timestep Consumption Time: 2.92694
PPO Batch Consumption Time: 0.36232
Total Iteration Time: 5.94665

Cumulative Model Updates: 227,876
Cumulative Timesteps: 1,901,161,976

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1901161976...
Checkpoint 1901161976 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,452.67136
Policy Entropy: 2.02037
Value Function Loss: 0.02752

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.09217
Policy Update Magnitude: 0.31906
Value Function Update Magnitude: 0.34827

Collected Steps per Second: 18,071.25217
Overall Steps per Second: 9,394.97521

Timestep Collection Time: 2.76694
Timestep Consumption Time: 2.55527
PPO Batch Consumption Time: 0.29249
Total Iteration Time: 5.32221

Cumulative Model Updates: 227,882
Cumulative Timesteps: 1,901,211,978

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,735.72197
Policy Entropy: 2.02373
Value Function Loss: 0.02920

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.08807
Policy Update Magnitude: 0.32452
Value Function Update Magnitude: 0.38209

Collected Steps per Second: 16,267.90007
Overall Steps per Second: 8,123.63991

Timestep Collection Time: 3.07489
Timestep Consumption Time: 3.08269
PPO Batch Consumption Time: 0.36497
Total Iteration Time: 6.15758

Cumulative Model Updates: 227,888
Cumulative Timesteps: 1,901,262,000

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1901262000...
Checkpoint 1901262000 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,891.69499
Policy Entropy: 2.02219
Value Function Loss: 0.02637

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.08338
Policy Update Magnitude: 0.31957
Value Function Update Magnitude: 0.35849

Collected Steps per Second: 18,435.20063
Overall Steps per Second: 9,516.42066

Timestep Collection Time: 2.71448
Timestep Consumption Time: 2.54401
PPO Batch Consumption Time: 0.29196
Total Iteration Time: 5.25849

Cumulative Model Updates: 227,894
Cumulative Timesteps: 1,901,312,042

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,221.40973
Policy Entropy: 2.02001
Value Function Loss: 0.02557

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.07687
Policy Update Magnitude: 0.31449
Value Function Update Magnitude: 0.36556

Collected Steps per Second: 19,749.23393
Overall Steps per Second: 9,734.93905

Timestep Collection Time: 2.53266
Timestep Consumption Time: 2.60533
PPO Batch Consumption Time: 0.30355
Total Iteration Time: 5.13799

Cumulative Model Updates: 227,900
Cumulative Timesteps: 1,901,362,060

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1901362060...
Checkpoint 1901362060 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,573.92743
Policy Entropy: 2.00497
Value Function Loss: 0.02241

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.07777
Policy Update Magnitude: 0.30704
Value Function Update Magnitude: 0.35440

Collected Steps per Second: 19,188.98368
Overall Steps per Second: 9,708.13189

Timestep Collection Time: 2.60681
Timestep Consumption Time: 2.54578
PPO Batch Consumption Time: 0.29279
Total Iteration Time: 5.15259

Cumulative Model Updates: 227,906
Cumulative Timesteps: 1,901,412,082

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,825.10291
Policy Entropy: 2.00543
Value Function Loss: 0.02240

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.07852
Policy Update Magnitude: 0.29734
Value Function Update Magnitude: 0.29313

Collected Steps per Second: 19,831.50120
Overall Steps per Second: 9,762.88386

Timestep Collection Time: 2.52326
Timestep Consumption Time: 2.60228
PPO Batch Consumption Time: 0.30400
Total Iteration Time: 5.12553

Cumulative Model Updates: 227,912
Cumulative Timesteps: 1,901,462,122

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1901462122...
Checkpoint 1901462122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 51,740.89056
Policy Entropy: 1.99556
Value Function Loss: 0.02241

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.07197
Policy Update Magnitude: 0.29474
Value Function Update Magnitude: 0.27083

Collected Steps per Second: 19,429.03983
Overall Steps per Second: 9,766.92987

Timestep Collection Time: 2.57408
Timestep Consumption Time: 2.54646
PPO Batch Consumption Time: 0.29144
Total Iteration Time: 5.12054

Cumulative Model Updates: 227,918
Cumulative Timesteps: 1,901,512,134

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45,481.54069
Policy Entropy: 2.01577
Value Function Loss: 0.02110

Mean KL Divergence: 0.00693
SB3 Clip Fraction: 0.06736
Policy Update Magnitude: 0.29193
Value Function Update Magnitude: 0.31998

Collected Steps per Second: 19,710.34219
Overall Steps per Second: 9,749.25301

Timestep Collection Time: 2.53846
Timestep Consumption Time: 2.59362
PPO Batch Consumption Time: 0.30304
Total Iteration Time: 5.13209

Cumulative Model Updates: 227,924
Cumulative Timesteps: 1,901,562,168

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1901562168...
Checkpoint 1901562168 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,405.95313
Policy Entropy: 2.02728
Value Function Loss: 0.02179

Mean KL Divergence: 0.00704
SB3 Clip Fraction: 0.06842
Policy Update Magnitude: 0.29161
Value Function Update Magnitude: 0.35808

Collected Steps per Second: 17,677.10285
Overall Steps per Second: 8,536.16789

Timestep Collection Time: 2.82908
Timestep Consumption Time: 3.02952
PPO Batch Consumption Time: 0.37099
Total Iteration Time: 5.85860

Cumulative Model Updates: 227,930
Cumulative Timesteps: 1,901,612,178

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,015.15795
Policy Entropy: 2.03457
Value Function Loss: 0.01930

Mean KL Divergence: 0.00677
SB3 Clip Fraction: 0.06694
Policy Update Magnitude: 0.29177
Value Function Update Magnitude: 0.36039

Collected Steps per Second: 16,172.90199
Overall Steps per Second: 8,430.10608

Timestep Collection Time: 3.09196
Timestep Consumption Time: 2.83987
PPO Batch Consumption Time: 0.32290
Total Iteration Time: 5.93184

Cumulative Model Updates: 227,936
Cumulative Timesteps: 1,901,662,184

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1901662184...
Checkpoint 1901662184 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,706.63770
Policy Entropy: 2.01893
Value Function Loss: 0.01901

Mean KL Divergence: 0.00702
SB3 Clip Fraction: 0.06679
Policy Update Magnitude: 0.28638
Value Function Update Magnitude: 0.32878

Collected Steps per Second: 15,787.45289
Overall Steps per Second: 8,505.75679

Timestep Collection Time: 3.16707
Timestep Consumption Time: 2.71130
PPO Batch Consumption Time: 0.30920
Total Iteration Time: 5.87837

Cumulative Model Updates: 227,942
Cumulative Timesteps: 1,901,712,184

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,655.49607
Policy Entropy: 2.00041
Value Function Loss: 0.01954

Mean KL Divergence: 0.00777
SB3 Clip Fraction: 0.07468
Policy Update Magnitude: 0.29153
Value Function Update Magnitude: 0.31322

Collected Steps per Second: 20,687.79127
Overall Steps per Second: 10,245.35305

Timestep Collection Time: 2.41688
Timestep Consumption Time: 2.46338
PPO Batch Consumption Time: 0.28394
Total Iteration Time: 4.88026

Cumulative Model Updates: 227,948
Cumulative Timesteps: 1,901,762,184

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1901762184...
Checkpoint 1901762184 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,580.57104
Policy Entropy: 1.99508
Value Function Loss: 0.02189

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.07816
Policy Update Magnitude: 0.29754
Value Function Update Magnitude: 0.27699

Collected Steps per Second: 20,013.67111
Overall Steps per Second: 10,214.09969

Timestep Collection Time: 2.49899
Timestep Consumption Time: 2.39757
PPO Batch Consumption Time: 0.28540
Total Iteration Time: 4.89656

Cumulative Model Updates: 227,954
Cumulative Timesteps: 1,901,812,198

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,119.89214
Policy Entropy: 1.99288
Value Function Loss: 0.02136

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.07513
Policy Update Magnitude: 0.29885
Value Function Update Magnitude: 0.30837

Collected Steps per Second: 19,975.30188
Overall Steps per Second: 10,112.57801

Timestep Collection Time: 2.50359
Timestep Consumption Time: 2.44173
PPO Batch Consumption Time: 0.29358
Total Iteration Time: 4.94533

Cumulative Model Updates: 227,960
Cumulative Timesteps: 1,901,862,208

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1901862208...
Checkpoint 1901862208 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 50,763.85711
Policy Entropy: 1.99480
Value Function Loss: 0.02121

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.07904
Policy Update Magnitude: 0.29713
Value Function Update Magnitude: 0.31870

Collected Steps per Second: 20,239.53475
Overall Steps per Second: 10,124.39298

Timestep Collection Time: 2.47091
Timestep Consumption Time: 2.46865
PPO Batch Consumption Time: 0.28807
Total Iteration Time: 4.93956

Cumulative Model Updates: 227,966
Cumulative Timesteps: 1,901,912,218

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42,705.39196
Policy Entropy: 2.01511
Value Function Loss: 0.02165

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.07613
Policy Update Magnitude: 0.30001
Value Function Update Magnitude: 0.29401

Collected Steps per Second: 20,825.87233
Overall Steps per Second: 10,344.29589

Timestep Collection Time: 2.40249
Timestep Consumption Time: 2.43438
PPO Batch Consumption Time: 0.28056
Total Iteration Time: 4.83687

Cumulative Model Updates: 227,972
Cumulative Timesteps: 1,901,962,252

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1901962252...
Checkpoint 1901962252 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,063.59701
Policy Entropy: 2.02393
Value Function Loss: 0.02246

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.08101
Policy Update Magnitude: 0.30146
Value Function Update Magnitude: 0.30666

Collected Steps per Second: 20,695.56177
Overall Steps per Second: 10,334.95954

Timestep Collection Time: 2.41810
Timestep Consumption Time: 2.42410
PPO Batch Consumption Time: 0.27928
Total Iteration Time: 4.84221

Cumulative Model Updates: 227,978
Cumulative Timesteps: 1,902,012,296

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,785.79142
Policy Entropy: 2.02602
Value Function Loss: 0.02374

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.08213
Policy Update Magnitude: 0.30862
Value Function Update Magnitude: 0.31132

Collected Steps per Second: 20,693.78606
Overall Steps per Second: 10,362.95610

Timestep Collection Time: 2.41628
Timestep Consumption Time: 2.40879
PPO Batch Consumption Time: 0.28004
Total Iteration Time: 4.82507

Cumulative Model Updates: 227,984
Cumulative Timesteps: 1,902,062,298

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1902062298...
Checkpoint 1902062298 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 54,523.41588
Policy Entropy: 2.02433
Value Function Loss: 0.02480

Mean KL Divergence: 0.01208
SB3 Clip Fraction: 0.10026
Policy Update Magnitude: 0.31343
Value Function Update Magnitude: 0.32406

Collected Steps per Second: 20,919.10221
Overall Steps per Second: 10,309.23054

Timestep Collection Time: 2.39112
Timestep Consumption Time: 2.46085
PPO Batch Consumption Time: 0.28472
Total Iteration Time: 4.85196

Cumulative Model Updates: 227,990
Cumulative Timesteps: 1,902,112,318

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48,536.31027
Policy Entropy: 2.00882
Value Function Loss: 0.02424

Mean KL Divergence: 0.01127
SB3 Clip Fraction: 0.09320
Policy Update Magnitude: 0.31142
Value Function Update Magnitude: 0.36621

Collected Steps per Second: 20,863.48286
Overall Steps per Second: 10,213.72021

Timestep Collection Time: 2.39701
Timestep Consumption Time: 2.49934
PPO Batch Consumption Time: 0.28763
Total Iteration Time: 4.89635

Cumulative Model Updates: 227,996
Cumulative Timesteps: 1,902,162,328

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1902162328...
Checkpoint 1902162328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 58,642.06045
Policy Entropy: 2.00691
Value Function Loss: 0.02422

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.08790
Policy Update Magnitude: 0.30810
Value Function Update Magnitude: 0.36373

Collected Steps per Second: 20,994.36184
Overall Steps per Second: 10,353.09564

Timestep Collection Time: 2.38159
Timestep Consumption Time: 2.44788
PPO Batch Consumption Time: 0.28069
Total Iteration Time: 4.82947

Cumulative Model Updates: 228,002
Cumulative Timesteps: 1,902,212,328

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,498.63918
Policy Entropy: 2.00311
Value Function Loss: 0.02401

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.08371
Policy Update Magnitude: 0.30748
Value Function Update Magnitude: 0.33519

Collected Steps per Second: 20,480.12625
Overall Steps per Second: 10,127.96522

Timestep Collection Time: 2.44139
Timestep Consumption Time: 2.49543
PPO Batch Consumption Time: 0.28424
Total Iteration Time: 4.93683

Cumulative Model Updates: 228,008
Cumulative Timesteps: 1,902,262,328

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1902262328...
Checkpoint 1902262328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47,468.19262
Policy Entropy: 2.01520
Value Function Loss: 0.02503

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.08704
Policy Update Magnitude: 0.30597
Value Function Update Magnitude: 0.34095

Collected Steps per Second: 20,505.12979
Overall Steps per Second: 10,198.21717

Timestep Collection Time: 2.43890
Timestep Consumption Time: 2.46490
PPO Batch Consumption Time: 0.28380
Total Iteration Time: 4.90380

Cumulative Model Updates: 228,014
Cumulative Timesteps: 1,902,312,338

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,647.74929
Policy Entropy: 2.02174
Value Function Loss: 0.02521

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.08225
Policy Update Magnitude: 0.30723
Value Function Update Magnitude: 0.35346

Collected Steps per Second: 21,062.83999
Overall Steps per Second: 10,341.20732

Timestep Collection Time: 2.37451
Timestep Consumption Time: 2.46187
PPO Batch Consumption Time: 0.28018
Total Iteration Time: 4.83638

Cumulative Model Updates: 228,020
Cumulative Timesteps: 1,902,362,352

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1902362352...
Checkpoint 1902362352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,721.03215
Policy Entropy: 2.02092
Value Function Loss: 0.02171

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.07713
Policy Update Magnitude: 0.30276
Value Function Update Magnitude: 0.32273

Collected Steps per Second: 20,859.63047
Overall Steps per Second: 10,342.73326

Timestep Collection Time: 2.39784
Timestep Consumption Time: 2.43822
PPO Batch Consumption Time: 0.27881
Total Iteration Time: 4.83605

Cumulative Model Updates: 228,026
Cumulative Timesteps: 1,902,412,370

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,627.91722
Policy Entropy: 2.02302
Value Function Loss: 0.02132

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.07475
Policy Update Magnitude: 0.30122
Value Function Update Magnitude: 0.30783

Collected Steps per Second: 21,078.44195
Overall Steps per Second: 10,377.50811

Timestep Collection Time: 2.37228
Timestep Consumption Time: 2.44622
PPO Batch Consumption Time: 0.28003
Total Iteration Time: 4.81850

Cumulative Model Updates: 228,032
Cumulative Timesteps: 1,902,462,374

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1902462374...
Checkpoint 1902462374 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,706.55775
Policy Entropy: 2.01658
Value Function Loss: 0.01803

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.07559
Policy Update Magnitude: 0.29265
Value Function Update Magnitude: 0.30393

Collected Steps per Second: 20,828.63589
Overall Steps per Second: 10,261.66929

Timestep Collection Time: 2.40246
Timestep Consumption Time: 2.47394
PPO Batch Consumption Time: 0.28674
Total Iteration Time: 4.87640

Cumulative Model Updates: 228,038
Cumulative Timesteps: 1,902,512,414

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50,876.87274
Policy Entropy: 2.01362
Value Function Loss: 0.02345

Mean KL Divergence: 0.01111
SB3 Clip Fraction: 0.08695
Policy Update Magnitude: 0.29840
Value Function Update Magnitude: 0.30478

Collected Steps per Second: 21,062.66790
Overall Steps per Second: 10,365.65902

Timestep Collection Time: 2.37453
Timestep Consumption Time: 2.45044
PPO Batch Consumption Time: 0.28110
Total Iteration Time: 4.82497

Cumulative Model Updates: 228,044
Cumulative Timesteps: 1,902,562,428

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1902562428...
Checkpoint 1902562428 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,959.86624
Policy Entropy: 2.00767
Value Function Loss: 0.02156

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.08593
Policy Update Magnitude: 0.29621
Value Function Update Magnitude: 0.32107

Collected Steps per Second: 20,903.65040
Overall Steps per Second: 10,267.02752

Timestep Collection Time: 2.39202
Timestep Consumption Time: 2.47813
PPO Batch Consumption Time: 0.28607
Total Iteration Time: 4.87015

Cumulative Model Updates: 228,050
Cumulative Timesteps: 1,902,612,430

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50,412.12534
Policy Entropy: 2.01216
Value Function Loss: 0.02371

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.08201
Policy Update Magnitude: 0.29648
Value Function Update Magnitude: 0.31982

Collected Steps per Second: 19,944.40151
Overall Steps per Second: 9,779.59441

Timestep Collection Time: 2.50737
Timestep Consumption Time: 2.60613
PPO Batch Consumption Time: 0.28914
Total Iteration Time: 5.11350

Cumulative Model Updates: 228,056
Cumulative Timesteps: 1,902,662,438

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1902662438...
Checkpoint 1902662438 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 77,778.47896
Policy Entropy: 1.99267
Value Function Loss: 0.02046

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.07958
Policy Update Magnitude: 0.29796
Value Function Update Magnitude: 0.30970

Collected Steps per Second: 18,370.96723
Overall Steps per Second: 9,458.77403

Timestep Collection Time: 2.72190
Timestep Consumption Time: 2.56462
PPO Batch Consumption Time: 0.28987
Total Iteration Time: 5.28652

Cumulative Model Updates: 228,062
Cumulative Timesteps: 1,902,712,442

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56,540.54352
Policy Entropy: 1.98801
Value Function Loss: 0.02097

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.07197
Policy Update Magnitude: 0.29581
Value Function Update Magnitude: 0.30357

Collected Steps per Second: 19,067.34977
Overall Steps per Second: 9,483.32284

Timestep Collection Time: 2.62438
Timestep Consumption Time: 2.65225
PPO Batch Consumption Time: 0.30976
Total Iteration Time: 5.27663

Cumulative Model Updates: 228,068
Cumulative Timesteps: 1,902,762,482

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1902762482...
Checkpoint 1902762482 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40,199.33977
Policy Entropy: 1.99102
Value Function Loss: 0.02294

Mean KL Divergence: 0.00747
SB3 Clip Fraction: 0.06714
Policy Update Magnitude: 0.30695
Value Function Update Magnitude: 0.31478

Collected Steps per Second: 19,354.86616
Overall Steps per Second: 9,785.07778

Timestep Collection Time: 2.58498
Timestep Consumption Time: 2.52811
PPO Batch Consumption Time: 0.29264
Total Iteration Time: 5.11309

Cumulative Model Updates: 228,074
Cumulative Timesteps: 1,902,812,514

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47,967.65076
Policy Entropy: 2.00517
Value Function Loss: 0.02287

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.06833
Policy Update Magnitude: 0.30136
Value Function Update Magnitude: 0.31623

Collected Steps per Second: 21,433.49230
Overall Steps per Second: 10,402.10332

Timestep Collection Time: 2.33336
Timestep Consumption Time: 2.47452
PPO Batch Consumption Time: 0.28303
Total Iteration Time: 4.80787

Cumulative Model Updates: 228,080
Cumulative Timesteps: 1,902,862,526

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1902862526...
Checkpoint 1902862526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40,474.35171
Policy Entropy: 2.00547
Value Function Loss: 0.02345

Mean KL Divergence: 0.00735
SB3 Clip Fraction: 0.06475
Policy Update Magnitude: 0.29923
Value Function Update Magnitude: 0.30687

Collected Steps per Second: 21,100.10874
Overall Steps per Second: 10,124.01094

Timestep Collection Time: 2.37127
Timestep Consumption Time: 2.57084
PPO Batch Consumption Time: 0.30270
Total Iteration Time: 4.94211

Cumulative Model Updates: 228,086
Cumulative Timesteps: 1,902,912,560

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42,355.61829
Policy Entropy: 1.98840
Value Function Loss: 0.02239

Mean KL Divergence: 0.00748
SB3 Clip Fraction: 0.06926
Policy Update Magnitude: 0.30153
Value Function Update Magnitude: 0.28736

Collected Steps per Second: 21,189.04955
Overall Steps per Second: 10,254.77232

Timestep Collection Time: 2.36075
Timestep Consumption Time: 2.51718
PPO Batch Consumption Time: 0.29308
Total Iteration Time: 4.87792

Cumulative Model Updates: 228,092
Cumulative Timesteps: 1,902,962,582

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1902962582...
Checkpoint 1902962582 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55,780.73842
Policy Entropy: 1.99247
Value Function Loss: 0.02223

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.07688
Policy Update Magnitude: 0.30131
Value Function Update Magnitude: 0.25989

Collected Steps per Second: 20,715.29721
Overall Steps per Second: 10,314.53497

Timestep Collection Time: 2.41503
Timestep Consumption Time: 2.43522
PPO Batch Consumption Time: 0.29084
Total Iteration Time: 4.85024

Cumulative Model Updates: 228,098
Cumulative Timesteps: 1,903,012,610

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55,657.05293
Policy Entropy: 1.99738
Value Function Loss: 0.02351

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.08254
Policy Update Magnitude: 0.31027
Value Function Update Magnitude: 0.21548

Collected Steps per Second: 20,950.26912
Overall Steps per Second: 10,347.63554

Timestep Collection Time: 2.38737
Timestep Consumption Time: 2.44620
PPO Batch Consumption Time: 0.29389
Total Iteration Time: 4.83357

Cumulative Model Updates: 228,104
Cumulative Timesteps: 1,903,062,626

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1903062626...
Checkpoint 1903062626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47,767.52993
Policy Entropy: 1.99840
Value Function Loss: 0.02285

Mean KL Divergence: 0.01177
SB3 Clip Fraction: 0.09849
Policy Update Magnitude: 0.30966
Value Function Update Magnitude: 0.20349

Collected Steps per Second: 21,120.40356
Overall Steps per Second: 10,512.51802

Timestep Collection Time: 2.36946
Timestep Consumption Time: 2.39096
PPO Batch Consumption Time: 0.27906
Total Iteration Time: 4.76042

Cumulative Model Updates: 228,110
Cumulative Timesteps: 1,903,112,670

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45,061.51091
Policy Entropy: 2.00236
Value Function Loss: 0.02265

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.08875
Policy Update Magnitude: 0.29858
Value Function Update Magnitude: 0.17327

Collected Steps per Second: 21,365.32045
Overall Steps per Second: 10,474.66266

Timestep Collection Time: 2.34071
Timestep Consumption Time: 2.43367
PPO Batch Consumption Time: 0.28916
Total Iteration Time: 4.77438

Cumulative Model Updates: 228,116
Cumulative Timesteps: 1,903,162,680

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1903162680...
Checkpoint 1903162680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,347.09656
Policy Entropy: 1.99656
Value Function Loss: 0.02383

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.08043
Policy Update Magnitude: 0.30095
Value Function Update Magnitude: 0.18657

Collected Steps per Second: 21,352.56762
Overall Steps per Second: 10,341.46163

Timestep Collection Time: 2.34398
Timestep Consumption Time: 2.49576
PPO Batch Consumption Time: 0.29287
Total Iteration Time: 4.83974

Cumulative Model Updates: 228,122
Cumulative Timesteps: 1,903,212,730

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,493.08186
Policy Entropy: 2.02101
Value Function Loss: 0.02401

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.07898
Policy Update Magnitude: 0.30602
Value Function Update Magnitude: 0.19998

Collected Steps per Second: 22,007.10266
Overall Steps per Second: 10,548.16845

Timestep Collection Time: 2.27318
Timestep Consumption Time: 2.46945
PPO Batch Consumption Time: 0.29139
Total Iteration Time: 4.74262

Cumulative Model Updates: 228,128
Cumulative Timesteps: 1,903,262,756

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1903262756...
Checkpoint 1903262756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,167.90687
Policy Entropy: 2.01403
Value Function Loss: 0.02630

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.07784
Policy Update Magnitude: 0.31254
Value Function Update Magnitude: 0.25338

Collected Steps per Second: 21,750.90288
Overall Steps per Second: 10,464.25041

Timestep Collection Time: 2.29903
Timestep Consumption Time: 2.47972
PPO Batch Consumption Time: 0.29230
Total Iteration Time: 4.77875

Cumulative Model Updates: 228,134
Cumulative Timesteps: 1,903,312,762

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70,796.04234
Policy Entropy: 2.01795
Value Function Loss: 0.02702

Mean KL Divergence: 0.01111
SB3 Clip Fraction: 0.09523
Policy Update Magnitude: 0.31649
Value Function Update Magnitude: 0.31087

Collected Steps per Second: 22,025.27894
Overall Steps per Second: 10,494.26415

Timestep Collection Time: 2.27184
Timestep Consumption Time: 2.49628
PPO Batch Consumption Time: 0.29426
Total Iteration Time: 4.76813

Cumulative Model Updates: 228,140
Cumulative Timesteps: 1,903,362,800

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1903362800...
Checkpoint 1903362800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,347.91851
Policy Entropy: 2.00530
Value Function Loss: 0.02628

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.08741
Policy Update Magnitude: 0.32045
Value Function Update Magnitude: 0.30415

Collected Steps per Second: 21,763.72500
Overall Steps per Second: 10,560.53940

Timestep Collection Time: 2.29823
Timestep Consumption Time: 2.43808
PPO Batch Consumption Time: 0.27960
Total Iteration Time: 4.73631

Cumulative Model Updates: 228,146
Cumulative Timesteps: 1,903,412,818

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,614.63605
Policy Entropy: 2.01706
Value Function Loss: 0.02326

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.07918
Policy Update Magnitude: 0.31268
Value Function Update Magnitude: 0.31798

Collected Steps per Second: 21,061.52601
Overall Steps per Second: 10,412.98382

Timestep Collection Time: 2.37476
Timestep Consumption Time: 2.42848
PPO Batch Consumption Time: 0.27879
Total Iteration Time: 4.80323

Cumulative Model Updates: 228,152
Cumulative Timesteps: 1,903,462,834

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1903462834...
Checkpoint 1903462834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,287.02505
Policy Entropy: 2.00916
Value Function Loss: 0.02014

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.08177
Policy Update Magnitude: 0.29940
Value Function Update Magnitude: 0.30703

Collected Steps per Second: 21,416.51172
Overall Steps per Second: 10,209.10709

Timestep Collection Time: 2.33558
Timestep Consumption Time: 2.56397
PPO Batch Consumption Time: 0.30188
Total Iteration Time: 4.89955

Cumulative Model Updates: 228,158
Cumulative Timesteps: 1,903,512,854

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,670.08528
Policy Entropy: 2.00885
Value Function Loss: 0.02035

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.07898
Policy Update Magnitude: 0.29580
Value Function Update Magnitude: 0.28784

Collected Steps per Second: 21,403.94836
Overall Steps per Second: 10,305.41385

Timestep Collection Time: 2.33648
Timestep Consumption Time: 2.51630
PPO Batch Consumption Time: 0.29000
Total Iteration Time: 4.85279

Cumulative Model Updates: 228,164
Cumulative Timesteps: 1,903,562,864

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1903562864...
Checkpoint 1903562864 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 51,745.92419
Policy Entropy: 2.00133
Value Function Loss: 0.02256

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.07540
Policy Update Magnitude: 0.29582
Value Function Update Magnitude: 0.27488

Collected Steps per Second: 21,418.22849
Overall Steps per Second: 10,484.16024

Timestep Collection Time: 2.33493
Timestep Consumption Time: 2.43513
PPO Batch Consumption Time: 0.27775
Total Iteration Time: 4.77005

Cumulative Model Updates: 228,170
Cumulative Timesteps: 1,903,612,874

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51,022.07925
Policy Entropy: 2.01121
Value Function Loss: 0.02334

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.07562
Policy Update Magnitude: 0.30390
Value Function Update Magnitude: 0.27010

Collected Steps per Second: 21,822.38893
Overall Steps per Second: 10,391.81406

Timestep Collection Time: 2.29205
Timestep Consumption Time: 2.52116
PPO Batch Consumption Time: 0.29026
Total Iteration Time: 4.81321

Cumulative Model Updates: 228,176
Cumulative Timesteps: 1,903,662,892

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1903662892...
Checkpoint 1903662892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 56,369.89704
Policy Entropy: 2.02044
Value Function Loss: 0.02362

Mean KL Divergence: 0.00777
SB3 Clip Fraction: 0.07360
Policy Update Magnitude: 0.29497
Value Function Update Magnitude: 0.24407

Collected Steps per Second: 20,412.03448
Overall Steps per Second: 10,155.11153

Timestep Collection Time: 2.45032
Timestep Consumption Time: 2.47489
PPO Batch Consumption Time: 0.29277
Total Iteration Time: 4.92520

Cumulative Model Updates: 228,182
Cumulative Timesteps: 1,903,712,908

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50,505.00232
Policy Entropy: 2.03249
Value Function Loss: 0.02549

Mean KL Divergence: 0.00783
SB3 Clip Fraction: 0.07440
Policy Update Magnitude: 0.29872
Value Function Update Magnitude: 0.25452

Collected Steps per Second: 21,399.56639
Overall Steps per Second: 10,477.01535

Timestep Collection Time: 2.33659
Timestep Consumption Time: 2.43595
PPO Batch Consumption Time: 0.29181
Total Iteration Time: 4.77254

Cumulative Model Updates: 228,188
Cumulative Timesteps: 1,903,762,910

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1903762910...
Checkpoint 1903762910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,347.70872
Policy Entropy: 2.02621
Value Function Loss: 0.02631

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.07832
Policy Update Magnitude: 0.30558
Value Function Update Magnitude: 0.29027

Collected Steps per Second: 20,807.31898
Overall Steps per Second: 10,307.79212

Timestep Collection Time: 2.40300
Timestep Consumption Time: 2.44770
PPO Batch Consumption Time: 0.29370
Total Iteration Time: 4.85070

Cumulative Model Updates: 228,194
Cumulative Timesteps: 1,903,812,910

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51,005.73384
Policy Entropy: 2.03683
Value Function Loss: 0.02536

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.08315
Policy Update Magnitude: 0.30595
Value Function Update Magnitude: 0.25600

Collected Steps per Second: 21,407.51523
Overall Steps per Second: 10,502.93719

Timestep Collection Time: 2.33572
Timestep Consumption Time: 2.42504
PPO Batch Consumption Time: 0.29176
Total Iteration Time: 4.76076

Cumulative Model Updates: 228,200
Cumulative Timesteps: 1,903,862,912

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1903862912...
Checkpoint 1903862912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47,798.67397
Policy Entropy: 2.03331
Value Function Loss: 0.02589

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.08022
Policy Update Magnitude: 0.30596
Value Function Update Magnitude: 0.24458

Collected Steps per Second: 21,029.79900
Overall Steps per Second: 10,428.99694

Timestep Collection Time: 2.37767
Timestep Consumption Time: 2.41684
PPO Batch Consumption Time: 0.28037
Total Iteration Time: 4.79452

Cumulative Model Updates: 228,206
Cumulative Timesteps: 1,903,912,914

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,793.58543
Policy Entropy: 2.04031
Value Function Loss: 0.02324

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.08156
Policy Update Magnitude: 0.30005
Value Function Update Magnitude: 0.28070

Collected Steps per Second: 21,878.20114
Overall Steps per Second: 10,511.44793

Timestep Collection Time: 2.28629
Timestep Consumption Time: 2.47233
PPO Batch Consumption Time: 0.28712
Total Iteration Time: 4.75862

Cumulative Model Updates: 228,212
Cumulative Timesteps: 1,903,962,934

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1903962934...
Checkpoint 1903962934 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,224.52292
Policy Entropy: 2.02388
Value Function Loss: 0.02409

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.08689
Policy Update Magnitude: 0.30363
Value Function Update Magnitude: 0.26872

Collected Steps per Second: 21,420.45323
Overall Steps per Second: 10,378.38936

Timestep Collection Time: 2.33496
Timestep Consumption Time: 2.48428
PPO Batch Consumption Time: 0.29121
Total Iteration Time: 4.81924

Cumulative Model Updates: 228,218
Cumulative Timesteps: 1,904,012,950

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50,104.51822
Policy Entropy: 2.01616
Value Function Loss: 0.02122

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.08234
Policy Update Magnitude: 0.30258
Value Function Update Magnitude: 0.28967

Collected Steps per Second: 21,486.81952
Overall Steps per Second: 10,310.25656

Timestep Collection Time: 2.32775
Timestep Consumption Time: 2.52334
PPO Batch Consumption Time: 0.29412
Total Iteration Time: 4.85109

Cumulative Model Updates: 228,224
Cumulative Timesteps: 1,904,062,966

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1904062966...
Checkpoint 1904062966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40,576.88423
Policy Entropy: 2.01642
Value Function Loss: 0.01964

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.07513
Policy Update Magnitude: 0.29481
Value Function Update Magnitude: 0.32483

Collected Steps per Second: 20,936.02584
Overall Steps per Second: 10,190.44089

Timestep Collection Time: 2.38937
Timestep Consumption Time: 2.51954
PPO Batch Consumption Time: 0.29270
Total Iteration Time: 4.90891

Cumulative Model Updates: 228,230
Cumulative Timesteps: 1,904,112,990

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,032.95727
Policy Entropy: 2.02563
Value Function Loss: 0.02010

Mean KL Divergence: 0.00735
SB3 Clip Fraction: 0.06729
Policy Update Magnitude: 0.29782
Value Function Update Magnitude: 0.31034

Collected Steps per Second: 21,391.52266
Overall Steps per Second: 10,283.95334

Timestep Collection Time: 2.33775
Timestep Consumption Time: 2.52497
PPO Batch Consumption Time: 0.29242
Total Iteration Time: 4.86272

Cumulative Model Updates: 228,236
Cumulative Timesteps: 1,904,162,998

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1904162998...
Checkpoint 1904162998 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 63,419.76257
Policy Entropy: 2.03540
Value Function Loss: 0.02329

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.07549
Policy Update Magnitude: 0.30091
Value Function Update Magnitude: 0.25844

Collected Steps per Second: 21,284.03430
Overall Steps per Second: 10,298.64739

Timestep Collection Time: 2.34946
Timestep Consumption Time: 2.50613
PPO Batch Consumption Time: 0.28425
Total Iteration Time: 4.85559

Cumulative Model Updates: 228,242
Cumulative Timesteps: 1,904,213,004

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52,782.41943
Policy Entropy: 2.03881
Value Function Loss: 0.02365

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.07074
Policy Update Magnitude: 0.30041
Value Function Update Magnitude: 0.20923

Collected Steps per Second: 21,464.29746
Overall Steps per Second: 10,452.25163

Timestep Collection Time: 2.33131
Timestep Consumption Time: 2.45617
PPO Batch Consumption Time: 0.27978
Total Iteration Time: 4.78749

Cumulative Model Updates: 228,248
Cumulative Timesteps: 1,904,263,044

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1904263044...
Checkpoint 1904263044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,830.72006
Policy Entropy: 2.03022
Value Function Loss: 0.02192

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.07427
Policy Update Magnitude: 0.29196
Value Function Update Magnitude: 0.20125

Collected Steps per Second: 21,177.18206
Overall Steps per Second: 10,265.17247

Timestep Collection Time: 2.36198
Timestep Consumption Time: 2.51081
PPO Batch Consumption Time: 0.28627
Total Iteration Time: 4.87279

Cumulative Model Updates: 228,254
Cumulative Timesteps: 1,904,313,064

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46,831.10970
Policy Entropy: 2.02655
Value Function Loss: 0.02024

Mean KL Divergence: 0.00708
SB3 Clip Fraction: 0.06821
Policy Update Magnitude: 0.29221
Value Function Update Magnitude: 0.22789

Collected Steps per Second: 21,949.46409
Overall Steps per Second: 10,450.16872

Timestep Collection Time: 2.27823
Timestep Consumption Time: 2.50695
PPO Batch Consumption Time: 0.28636
Total Iteration Time: 4.78519

Cumulative Model Updates: 228,260
Cumulative Timesteps: 1,904,363,070

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1904363070...
Checkpoint 1904363070 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 51,011.01971
Policy Entropy: 2.03954
Value Function Loss: 0.02007

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.07911
Policy Update Magnitude: 0.29318
Value Function Update Magnitude: 0.24483

Collected Steps per Second: 21,714.43868
Overall Steps per Second: 10,520.32601

Timestep Collection Time: 2.30344
Timestep Consumption Time: 2.45097
PPO Batch Consumption Time: 0.28055
Total Iteration Time: 4.75442

Cumulative Model Updates: 228,266
Cumulative Timesteps: 1,904,413,088

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46,637.37093
Policy Entropy: 2.05043
Value Function Loss: 0.01827

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.07817
Policy Update Magnitude: 0.28469
Value Function Update Magnitude: 0.22821

Collected Steps per Second: 19,627.51367
Overall Steps per Second: 9,754.83587

Timestep Collection Time: 2.54795
Timestep Consumption Time: 2.57873
PPO Batch Consumption Time: 0.29505
Total Iteration Time: 5.12669

Cumulative Model Updates: 228,272
Cumulative Timesteps: 1,904,463,098

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1904463098...
Checkpoint 1904463098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46,637.37093
Policy Entropy: 2.03478
Value Function Loss: 0.01778

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.07429
Policy Update Magnitude: 0.28109
Value Function Update Magnitude: 0.22611

Collected Steps per Second: 19,747.61574
Overall Steps per Second: 10,147.57136

Timestep Collection Time: 2.53256
Timestep Consumption Time: 2.39591
PPO Batch Consumption Time: 0.27971
Total Iteration Time: 4.92847

Cumulative Model Updates: 228,278
Cumulative Timesteps: 1,904,513,110

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59,364.38976
Policy Entropy: 2.03489
Value Function Loss: 0.01845

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.07925
Policy Update Magnitude: 0.28155
Value Function Update Magnitude: 0.23796

Collected Steps per Second: 21,246.05245
Overall Steps per Second: 10,573.43520

Timestep Collection Time: 2.35564
Timestep Consumption Time: 2.37773
PPO Batch Consumption Time: 0.27927
Total Iteration Time: 4.73337

Cumulative Model Updates: 228,284
Cumulative Timesteps: 1,904,563,158

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 1904563158...
Checkpoint 1904563158 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 94,949.97144
Policy Entropy: 2.03719
Value Function Loss: 0.01971

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.08043
Policy Update Magnitude: 0.28862
Value Function Update Magnitude: 0.23705

Collected Steps per Second: 21,327.25266
Overall Steps per Second: 10,628.20353

Timestep Collection Time: 2.34536
Timestep Consumption Time: 2.36099
PPO Batch Consumption Time: 0.27814
Total Iteration Time: 4.70635

Cumulative Model Updates: 228,290
Cumulative Timesteps: 1,904,613,178

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78,376.62357
Policy Entropy: 2.05133
Value Function Loss: 0.02001

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.07442
Policy Update Magnitude: 0.28756
Value Function Update Magnitude: 0.25646

Collected Steps per Second: 21,438.55674
Overall Steps per Second: 10,413.25657

Timestep Collection Time: 2.33271
Timestep Consumption Time: 2.46982
PPO Batch Consumption Time: 0.28733
Total Iteration Time: 4.80253

Cumulative Model Updates: 228,296
Cumulative Timesteps: 1,904,663,188

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1904663188...
Checkpoint 1904663188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84,435.58547
Policy Entropy: 2.03776
Value Function Loss: 0.02073

Mean KL Divergence: 0.00763
SB3 Clip Fraction: 0.07170
Policy Update Magnitude: 0.28940
Value Function Update Magnitude: 0.27101

Collected Steps per Second: 21,349.37856
Overall Steps per Second: 10,392.03319

Timestep Collection Time: 2.34264
Timestep Consumption Time: 2.47008
PPO Batch Consumption Time: 0.29002
Total Iteration Time: 4.81273

Cumulative Model Updates: 228,302
Cumulative Timesteps: 1,904,713,202

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 73,827.91361
Policy Entropy: 2.01480
Value Function Loss: 0.02428

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.07456
Policy Update Magnitude: 0.30601
Value Function Update Magnitude: 0.29294

Collected Steps per Second: 21,820.34553
Overall Steps per Second: 10,623.02175

Timestep Collection Time: 2.29236
Timestep Consumption Time: 2.41629
PPO Batch Consumption Time: 0.27981
Total Iteration Time: 4.70864

Cumulative Model Updates: 228,308
Cumulative Timesteps: 1,904,763,222

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1904763222...
Checkpoint 1904763222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 64,254.46403
Policy Entropy: 2.02777
Value Function Loss: 0.02352

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.07382
Policy Update Magnitude: 0.29934
Value Function Update Magnitude: 0.31444

Collected Steps per Second: 21,163.62969
Overall Steps per Second: 10,267.39521

Timestep Collection Time: 2.36254
Timestep Consumption Time: 2.50724
PPO Batch Consumption Time: 0.28832
Total Iteration Time: 4.86978

Cumulative Model Updates: 228,314
Cumulative Timesteps: 1,904,813,222

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63,766.89240
Policy Entropy: 2.03709
Value Function Loss: 0.02510

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.07315
Policy Update Magnitude: 0.30319
Value Function Update Magnitude: 0.29197

Collected Steps per Second: 21,615.44066
Overall Steps per Second: 10,512.32218

Timestep Collection Time: 2.31399
Timestep Consumption Time: 2.44404
PPO Batch Consumption Time: 0.27826
Total Iteration Time: 4.75804

Cumulative Model Updates: 228,320
Cumulative Timesteps: 1,904,863,240

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1904863240...
Checkpoint 1904863240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 51,174.69262
Policy Entropy: 2.04144
Value Function Loss: 0.02474

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.07905
Policy Update Magnitude: 0.30031
Value Function Update Magnitude: 0.28794

Collected Steps per Second: 21,387.31999
Overall Steps per Second: 10,286.82178

Timestep Collection Time: 2.33839
Timestep Consumption Time: 2.52336
PPO Batch Consumption Time: 0.29349
Total Iteration Time: 4.86175

Cumulative Model Updates: 228,326
Cumulative Timesteps: 1,904,913,252

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,156.56625
Policy Entropy: 2.04906
Value Function Loss: 0.02675

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.08793
Policy Update Magnitude: 0.30680
Value Function Update Magnitude: 0.29664

Collected Steps per Second: 22,118.83587
Overall Steps per Second: 10,381.97186

Timestep Collection Time: 2.26097
Timestep Consumption Time: 2.55604
PPO Batch Consumption Time: 0.29376
Total Iteration Time: 4.81700

Cumulative Model Updates: 228,332
Cumulative Timesteps: 1,904,963,262

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1904963262...
Checkpoint 1904963262 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,286.27089
Policy Entropy: 2.02961
Value Function Loss: 0.02378

Mean KL Divergence: 0.01061
SB3 Clip Fraction: 0.09013
Policy Update Magnitude: 0.30755
Value Function Update Magnitude: 0.32865

Collected Steps per Second: 21,994.69797
Overall Steps per Second: 10,571.77675

Timestep Collection Time: 2.27464
Timestep Consumption Time: 2.45777
PPO Batch Consumption Time: 0.28053
Total Iteration Time: 4.73241

Cumulative Model Updates: 228,338
Cumulative Timesteps: 1,905,013,292

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,076.18446
Policy Entropy: 2.04289
Value Function Loss: 0.02224

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.07919
Policy Update Magnitude: 0.29898
Value Function Update Magnitude: 0.32426

Collected Steps per Second: 22,274.89040
Overall Steps per Second: 10,301.72866

Timestep Collection Time: 2.24648
Timestep Consumption Time: 2.61096
PPO Batch Consumption Time: 0.30907
Total Iteration Time: 4.85744

Cumulative Model Updates: 228,344
Cumulative Timesteps: 1,905,063,332

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1905063332...
Checkpoint 1905063332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,584.38886
Policy Entropy: 2.02651
Value Function Loss: 0.02185

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.07254
Policy Update Magnitude: 0.29652
Value Function Update Magnitude: 0.30962

Collected Steps per Second: 21,567.19303
Overall Steps per Second: 10,379.41804

Timestep Collection Time: 2.31889
Timestep Consumption Time: 2.49949
PPO Batch Consumption Time: 0.28672
Total Iteration Time: 4.81838

Cumulative Model Updates: 228,350
Cumulative Timesteps: 1,905,113,344

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,891.48345
Policy Entropy: 2.01937
Value Function Loss: 0.01949

Mean KL Divergence: 0.00735
SB3 Clip Fraction: 0.06886
Policy Update Magnitude: 0.29316
Value Function Update Magnitude: 0.31650

Collected Steps per Second: 22,146.28208
Overall Steps per Second: 10,436.78886

Timestep Collection Time: 2.25871
Timestep Consumption Time: 2.53414
PPO Batch Consumption Time: 0.29378
Total Iteration Time: 4.79285

Cumulative Model Updates: 228,356
Cumulative Timesteps: 1,905,163,366

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1905163366...
Checkpoint 1905163366 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 52,510.89983
Policy Entropy: 2.00277
Value Function Loss: 0.02042

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.07469
Policy Update Magnitude: 0.29333
Value Function Update Magnitude: 0.32968

Collected Steps per Second: 21,769.57010
Overall Steps per Second: 10,560.82511

Timestep Collection Time: 2.29835
Timestep Consumption Time: 2.43935
PPO Batch Consumption Time: 0.28026
Total Iteration Time: 4.73770

Cumulative Model Updates: 228,362
Cumulative Timesteps: 1,905,213,400

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68,627.13250
Policy Entropy: 2.01466
Value Function Loss: 0.02145

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.08221
Policy Update Magnitude: 0.29840
Value Function Update Magnitude: 0.32682

Collected Steps per Second: 21,862.67184
Overall Steps per Second: 10,552.82046

Timestep Collection Time: 2.28737
Timestep Consumption Time: 2.45146
PPO Batch Consumption Time: 0.28036
Total Iteration Time: 4.73883

Cumulative Model Updates: 228,368
Cumulative Timesteps: 1,905,263,408

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1905263408...
Checkpoint 1905263408 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,222.74322
Policy Entropy: 2.02983
Value Function Loss: 0.02324

Mean KL Divergence: 0.01080
SB3 Clip Fraction: 0.09342
Policy Update Magnitude: 0.30373
Value Function Update Magnitude: 0.32794

Collected Steps per Second: 20,695.15384
Overall Steps per Second: 10,312.04551

Timestep Collection Time: 2.41776
Timestep Consumption Time: 2.43443
PPO Batch Consumption Time: 0.29350
Total Iteration Time: 4.85219

Cumulative Model Updates: 228,374
Cumulative Timesteps: 1,905,313,444

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,545.11780
Policy Entropy: 2.04080
Value Function Loss: 0.02541

Mean KL Divergence: 0.01066
SB3 Clip Fraction: 0.09335
Policy Update Magnitude: 0.31485
Value Function Update Magnitude: 0.34065

Collected Steps per Second: 20,559.32861
Overall Steps per Second: 10,433.65817

Timestep Collection Time: 2.43403
Timestep Consumption Time: 2.36218
PPO Batch Consumption Time: 0.27878
Total Iteration Time: 4.79621

Cumulative Model Updates: 228,380
Cumulative Timesteps: 1,905,363,486

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1905363486...
Checkpoint 1905363486 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,291.14478
Policy Entropy: 2.03678
Value Function Loss: 0.02369

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.09623
Policy Update Magnitude: 0.31250
Value Function Update Magnitude: 0.30970

Collected Steps per Second: 20,692.85572
Overall Steps per Second: 10,356.97503

Timestep Collection Time: 2.41726
Timestep Consumption Time: 2.41234
PPO Batch Consumption Time: 0.28858
Total Iteration Time: 4.82960

Cumulative Model Updates: 228,386
Cumulative Timesteps: 1,905,413,506

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63,842.71501
Policy Entropy: 2.01550
Value Function Loss: 0.02327

Mean KL Divergence: 0.01053
SB3 Clip Fraction: 0.08731
Policy Update Magnitude: 0.30866
Value Function Update Magnitude: 0.29165

Collected Steps per Second: 21,172.79807
Overall Steps per Second: 10,245.94698

Timestep Collection Time: 2.36190
Timestep Consumption Time: 2.51886
PPO Batch Consumption Time: 0.29532
Total Iteration Time: 4.88076

Cumulative Model Updates: 228,392
Cumulative Timesteps: 1,905,463,514

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1905463514...
Checkpoint 1905463514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 52,819.94620
Policy Entropy: 2.01806
Value Function Loss: 0.02145

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.08463
Policy Update Magnitude: 0.30240
Value Function Update Magnitude: 0.30439

Collected Steps per Second: 21,713.45771
Overall Steps per Second: 10,567.27193

Timestep Collection Time: 2.30392
Timestep Consumption Time: 2.43013
PPO Batch Consumption Time: 0.27948
Total Iteration Time: 4.73405

Cumulative Model Updates: 228,398
Cumulative Timesteps: 1,905,513,540

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,592.47147
Policy Entropy: 2.01115
Value Function Loss: 0.02281

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.07841
Policy Update Magnitude: 0.30134
Value Function Update Magnitude: 0.32446

Collected Steps per Second: 21,793.59320
Overall Steps per Second: 10,386.02795

Timestep Collection Time: 2.29499
Timestep Consumption Time: 2.52071
PPO Batch Consumption Time: 0.29226
Total Iteration Time: 4.81570

Cumulative Model Updates: 228,404
Cumulative Timesteps: 1,905,563,556

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1905563556...
Checkpoint 1905563556 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,682.17071
Policy Entropy: 2.00937
Value Function Loss: 0.02447

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.07850
Policy Update Magnitude: 0.30738
Value Function Update Magnitude: 0.30003

Collected Steps per Second: 21,793.24361
Overall Steps per Second: 10,396.16541

Timestep Collection Time: 2.29475
Timestep Consumption Time: 2.51568
PPO Batch Consumption Time: 0.29359
Total Iteration Time: 4.81043

Cumulative Model Updates: 228,410
Cumulative Timesteps: 1,905,613,566

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,989.17757
Policy Entropy: 2.01825
Value Function Loss: 0.02288

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.09253
Policy Update Magnitude: 0.30101
Value Function Update Magnitude: 0.28371

Collected Steps per Second: 21,949.60589
Overall Steps per Second: 10,447.05970

Timestep Collection Time: 2.27831
Timestep Consumption Time: 2.50849
PPO Batch Consumption Time: 0.29402
Total Iteration Time: 4.78680

Cumulative Model Updates: 228,416
Cumulative Timesteps: 1,905,663,574

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1905663574...
Checkpoint 1905663574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43,384.65763
Policy Entropy: 2.02104
Value Function Loss: 0.02174

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.07859
Policy Update Magnitude: 0.29734
Value Function Update Magnitude: 0.27711

Collected Steps per Second: 21,853.48897
Overall Steps per Second: 10,408.77301

Timestep Collection Time: 2.28806
Timestep Consumption Time: 2.51578
PPO Batch Consumption Time: 0.29259
Total Iteration Time: 4.80383

Cumulative Model Updates: 228,422
Cumulative Timesteps: 1,905,713,576

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54,404.20835
Policy Entropy: 2.03460
Value Function Loss: 0.02069

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.07985
Policy Update Magnitude: 0.29289
Value Function Update Magnitude: 0.27575

Collected Steps per Second: 22,005.82090
Overall Steps per Second: 10,538.19248

Timestep Collection Time: 2.27394
Timestep Consumption Time: 2.47450
PPO Batch Consumption Time: 0.28035
Total Iteration Time: 4.74844

Cumulative Model Updates: 228,428
Cumulative Timesteps: 1,905,763,616

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1905763616...
Checkpoint 1905763616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47,407.16824
Policy Entropy: 2.03298
Value Function Loss: 0.02035

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.07395
Policy Update Magnitude: 0.29278
Value Function Update Magnitude: 0.29274

Collected Steps per Second: 21,660.51192
Overall Steps per Second: 10,347.05541

Timestep Collection Time: 2.30909
Timestep Consumption Time: 2.52475
PPO Batch Consumption Time: 0.29414
Total Iteration Time: 4.83384

Cumulative Model Updates: 228,434
Cumulative Timesteps: 1,905,813,632

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81,054.61821
Policy Entropy: 2.02711
Value Function Loss: 0.01920

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.07064
Policy Update Magnitude: 0.28999
Value Function Update Magnitude: 0.26703

Collected Steps per Second: 21,075.87805
Overall Steps per Second: 10,414.50609

Timestep Collection Time: 2.37238
Timestep Consumption Time: 2.42862
PPO Batch Consumption Time: 0.27877
Total Iteration Time: 4.80100

Cumulative Model Updates: 228,440
Cumulative Timesteps: 1,905,863,632

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1905863632...
Checkpoint 1905863632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 50,172.75507
Policy Entropy: 2.02828
Value Function Loss: 0.02341

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.06988
Policy Update Magnitude: 0.30109
Value Function Update Magnitude: 0.24603

Collected Steps per Second: 21,289.88741
Overall Steps per Second: 10,282.29856

Timestep Collection Time: 2.34910
Timestep Consumption Time: 2.51480
PPO Batch Consumption Time: 0.29385
Total Iteration Time: 4.86389

Cumulative Model Updates: 228,446
Cumulative Timesteps: 1,905,913,644

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,950.65687
Policy Entropy: 2.02789
Value Function Loss: 0.02303

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.07450
Policy Update Magnitude: 0.29975
Value Function Update Magnitude: 0.29299

Collected Steps per Second: 21,616.98693
Overall Steps per Second: 10,350.18841

Timestep Collection Time: 2.31346
Timestep Consumption Time: 2.51834
PPO Batch Consumption Time: 0.29215
Total Iteration Time: 4.83180

Cumulative Model Updates: 228,452
Cumulative Timesteps: 1,905,963,654

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1905963654...
Checkpoint 1905963654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 50,118.91008
Policy Entropy: 2.04068
Value Function Loss: 0.02253

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.07307
Policy Update Magnitude: 0.29364
Value Function Update Magnitude: 0.28525

Collected Steps per Second: 21,400.93835
Overall Steps per Second: 10,286.23171

Timestep Collection Time: 2.33747
Timestep Consumption Time: 2.52573
PPO Batch Consumption Time: 0.29375
Total Iteration Time: 4.86320

Cumulative Model Updates: 228,458
Cumulative Timesteps: 1,906,013,678

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61,192.60132
Policy Entropy: 2.02529
Value Function Loss: 0.02006

Mean KL Divergence: 0.00718
SB3 Clip Fraction: 0.06890
Policy Update Magnitude: 0.29085
Value Function Update Magnitude: 0.26987

Collected Steps per Second: 21,592.64583
Overall Steps per Second: 10,361.15751

Timestep Collection Time: 2.31671
Timestep Consumption Time: 2.51132
PPO Batch Consumption Time: 0.28850
Total Iteration Time: 4.82803

Cumulative Model Updates: 228,464
Cumulative Timesteps: 1,906,063,702

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1906063702...
Checkpoint 1906063702 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 53,954.26484
Policy Entropy: 2.02346
Value Function Loss: 0.01828

Mean KL Divergence: 0.00705
SB3 Clip Fraction: 0.06636
Policy Update Magnitude: 0.29282
Value Function Update Magnitude: 0.27081

Collected Steps per Second: 21,362.96630
Overall Steps per Second: 10,287.49884

Timestep Collection Time: 2.34172
Timestep Consumption Time: 2.52108
PPO Batch Consumption Time: 0.29340
Total Iteration Time: 4.86280

Cumulative Model Updates: 228,470
Cumulative Timesteps: 1,906,113,728

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60,822.42073
Policy Entropy: 2.02834
Value Function Loss: 0.01930

Mean KL Divergence: 0.00676
SB3 Clip Fraction: 0.06375
Policy Update Magnitude: 0.28892
Value Function Update Magnitude: 0.28695

Collected Steps per Second: 22,174.56171
Overall Steps per Second: 10,371.96826

Timestep Collection Time: 2.25619
Timestep Consumption Time: 2.56739
PPO Batch Consumption Time: 0.29266
Total Iteration Time: 4.82358

Cumulative Model Updates: 228,476
Cumulative Timesteps: 1,906,163,758

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1906163758...
Checkpoint 1906163758 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 67,427.86250
Policy Entropy: 2.02954
Value Function Loss: 0.02071

Mean KL Divergence: 0.00672
SB3 Clip Fraction: 0.06318
Policy Update Magnitude: 0.28933
Value Function Update Magnitude: 0.29129

Collected Steps per Second: 21,824.39362
Overall Steps per Second: 10,550.13990

Timestep Collection Time: 2.29147
Timestep Consumption Time: 2.44875
PPO Batch Consumption Time: 0.27997
Total Iteration Time: 4.74022

Cumulative Model Updates: 228,482
Cumulative Timesteps: 1,906,213,768

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58,749.75928
Policy Entropy: 2.01335
Value Function Loss: 0.02171

Mean KL Divergence: 0.00695
SB3 Clip Fraction: 0.06468
Policy Update Magnitude: 0.29231
Value Function Update Magnitude: 0.30941

Collected Steps per Second: 21,995.22756
Overall Steps per Second: 10,594.34801

Timestep Collection Time: 2.27322
Timestep Consumption Time: 2.44628
PPO Batch Consumption Time: 0.27909
Total Iteration Time: 4.71950

Cumulative Model Updates: 228,488
Cumulative Timesteps: 1,906,263,768

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1906263768...
Checkpoint 1906263768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 52,720.07302
Policy Entropy: 2.02234
Value Function Loss: 0.02231

Mean KL Divergence: 0.00720
SB3 Clip Fraction: 0.06821
Policy Update Magnitude: 0.29404
Value Function Update Magnitude: 0.31632

Collected Steps per Second: 21,530.98430
Overall Steps per Second: 10,493.65810

Timestep Collection Time: 2.32270
Timestep Consumption Time: 2.44304
PPO Batch Consumption Time: 0.27977
Total Iteration Time: 4.76574

Cumulative Model Updates: 228,494
Cumulative Timesteps: 1,906,313,778

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51,607.00024
Policy Entropy: 2.02955
Value Function Loss: 0.01984

Mean KL Divergence: 0.00740
SB3 Clip Fraction: 0.07008
Policy Update Magnitude: 0.28891
Value Function Update Magnitude: 0.31637

Collected Steps per Second: 22,054.65803
Overall Steps per Second: 10,523.46841

Timestep Collection Time: 2.26864
Timestep Consumption Time: 2.48588
PPO Batch Consumption Time: 0.28722
Total Iteration Time: 4.75452

Cumulative Model Updates: 228,500
Cumulative Timesteps: 1,906,363,812

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1906363812...
Checkpoint 1906363812 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 60,053.45600
Policy Entropy: 2.04506
Value Function Loss: 0.01851

Mean KL Divergence: 0.00641
SB3 Clip Fraction: 0.06186
Policy Update Magnitude: 0.28797
Value Function Update Magnitude: 0.31577

Collected Steps per Second: 21,410.77518
Overall Steps per Second: 10,320.24041

Timestep Collection Time: 2.33649
Timestep Consumption Time: 2.51088
PPO Batch Consumption Time: 0.29416
Total Iteration Time: 4.84737

Cumulative Model Updates: 228,506
Cumulative Timesteps: 1,906,413,838

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54,814.17227
Policy Entropy: 2.01879
Value Function Loss: 0.01879

Mean KL Divergence: 0.00662
SB3 Clip Fraction: 0.06247
Policy Update Magnitude: 0.29023
Value Function Update Magnitude: 0.28646

Collected Steps per Second: 21,762.99102
Overall Steps per Second: 10,362.60481

Timestep Collection Time: 2.29932
Timestep Consumption Time: 2.52959
PPO Batch Consumption Time: 0.28778
Total Iteration Time: 4.82890

Cumulative Model Updates: 228,512
Cumulative Timesteps: 1,906,463,878

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1906463878...
Checkpoint 1906463878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,066.53709
Policy Entropy: 2.02155
Value Function Loss: 0.01812

Mean KL Divergence: 0.00714
SB3 Clip Fraction: 0.06638
Policy Update Magnitude: 0.29004
Value Function Update Magnitude: 0.28002

Collected Steps per Second: 20,443.87284
Overall Steps per Second: 10,259.16029

Timestep Collection Time: 2.44689
Timestep Consumption Time: 2.42914
PPO Batch Consumption Time: 0.27915
Total Iteration Time: 4.87603

Cumulative Model Updates: 228,518
Cumulative Timesteps: 1,906,513,902

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54,685.02447
Policy Entropy: 2.02515
Value Function Loss: 0.01958

Mean KL Divergence: 0.00737
SB3 Clip Fraction: 0.06665
Policy Update Magnitude: 0.28797
Value Function Update Magnitude: 0.30017

Collected Steps per Second: 21,729.49588
Overall Steps per Second: 10,443.16618

Timestep Collection Time: 2.30240
Timestep Consumption Time: 2.48829
PPO Batch Consumption Time: 0.28771
Total Iteration Time: 4.79069

Cumulative Model Updates: 228,524
Cumulative Timesteps: 1,906,563,932

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1906563932...
Checkpoint 1906563932 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 59,322.23935
Policy Entropy: 2.03573
Value Function Loss: 0.01921

Mean KL Divergence: 0.00719
SB3 Clip Fraction: 0.06764
Policy Update Magnitude: 0.29467
Value Function Update Magnitude: 0.31469

Collected Steps per Second: 21,233.80119
Overall Steps per Second: 10,265.18940

Timestep Collection Time: 2.35549
Timestep Consumption Time: 2.51690
PPO Batch Consumption Time: 0.29411
Total Iteration Time: 4.87239

Cumulative Model Updates: 228,530
Cumulative Timesteps: 1,906,613,948

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63,028.31983
Policy Entropy: 2.02841
Value Function Loss: 0.02267

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.06925
Policy Update Magnitude: 0.30564
Value Function Update Magnitude: 0.28828

Collected Steps per Second: 21,195.48696
Overall Steps per Second: 10,405.71064

Timestep Collection Time: 2.36097
Timestep Consumption Time: 2.44812
PPO Batch Consumption Time: 0.29368
Total Iteration Time: 4.80909

Cumulative Model Updates: 228,536
Cumulative Timesteps: 1,906,663,990

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1906663990...
Checkpoint 1906663990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 66,654.13164
Policy Entropy: 2.03020
Value Function Loss: 0.02205

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.08164
Policy Update Magnitude: 0.30286
Value Function Update Magnitude: 0.26414

Collected Steps per Second: 20,883.74821
Overall Steps per Second: 10,344.66317

Timestep Collection Time: 2.39459
Timestep Consumption Time: 2.43959
PPO Batch Consumption Time: 0.29127
Total Iteration Time: 4.83418

Cumulative Model Updates: 228,542
Cumulative Timesteps: 1,906,713,998

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51,790.93848
Policy Entropy: 2.03091
Value Function Loss: 0.02228

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.07745
Policy Update Magnitude: 0.29639
Value Function Update Magnitude: 0.25612

Collected Steps per Second: 21,596.04892
Overall Steps per Second: 10,681.37425

Timestep Collection Time: 2.31700
Timestep Consumption Time: 2.36761
PPO Batch Consumption Time: 0.27962
Total Iteration Time: 4.68460

Cumulative Model Updates: 228,548
Cumulative Timesteps: 1,906,764,036

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1906764036...
Checkpoint 1906764036 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 53,137.81105
Policy Entropy: 2.04924
Value Function Loss: 0.01939

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.07364
Policy Update Magnitude: 0.29087
Value Function Update Magnitude: 0.26687

Collected Steps per Second: 20,919.16029
Overall Steps per Second: 10,258.88102

Timestep Collection Time: 2.39015
Timestep Consumption Time: 2.48367
PPO Batch Consumption Time: 0.29103
Total Iteration Time: 4.87383

Cumulative Model Updates: 228,554
Cumulative Timesteps: 1,906,814,036

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49,430.68815
Policy Entropy: 2.04269
Value Function Loss: 0.02215

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.07509
Policy Update Magnitude: 0.29318
Value Function Update Magnitude: 0.29604

Collected Steps per Second: 21,997.08906
Overall Steps per Second: 10,456.92985

Timestep Collection Time: 2.27548
Timestep Consumption Time: 2.51120
PPO Batch Consumption Time: 0.29464
Total Iteration Time: 4.78668

Cumulative Model Updates: 228,560
Cumulative Timesteps: 1,906,864,090

Timesteps Collected: 50,054
--------END ITERATION REPORT--------


Saving checkpoint 1906864090...
Checkpoint 1906864090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 64,565.24273
Policy Entropy: 2.03972
Value Function Loss: 0.01990

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.07316
Policy Update Magnitude: 0.28588
Value Function Update Magnitude: 0.32078

Collected Steps per Second: 21,609.70910
Overall Steps per Second: 10,579.80691

Timestep Collection Time: 2.31526
Timestep Consumption Time: 2.41375
PPO Batch Consumption Time: 0.28008
Total Iteration Time: 4.72901

Cumulative Model Updates: 228,566
Cumulative Timesteps: 1,906,914,122

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,532.51423
Policy Entropy: 2.02717
Value Function Loss: 0.02063

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.07432
Policy Update Magnitude: 0.29004
Value Function Update Magnitude: 0.33571

Collected Steps per Second: 22,317.67492
Overall Steps per Second: 10,517.77501

Timestep Collection Time: 2.24127
Timestep Consumption Time: 2.51449
PPO Batch Consumption Time: 0.29028
Total Iteration Time: 4.75576

Cumulative Model Updates: 228,572
Cumulative Timesteps: 1,906,964,142

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1906964142...
Checkpoint 1906964142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,750.46073
Policy Entropy: 2.03954
Value Function Loss: 0.02395

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.08597
Policy Update Magnitude: 0.29848
Value Function Update Magnitude: 0.31271

Collected Steps per Second: 21,707.79283
Overall Steps per Second: 10,552.13412

Timestep Collection Time: 2.30415
Timestep Consumption Time: 2.43593
PPO Batch Consumption Time: 0.27993
Total Iteration Time: 4.74008

Cumulative Model Updates: 228,578
Cumulative Timesteps: 1,907,014,160

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,557.66350
Policy Entropy: 2.04345
Value Function Loss: 0.02761

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.08922
Policy Update Magnitude: 0.30947
Value Function Update Magnitude: 0.29096

Collected Steps per Second: 21,725.67091
Overall Steps per Second: 10,544.31705

Timestep Collection Time: 2.30142
Timestep Consumption Time: 2.44047
PPO Batch Consumption Time: 0.27929
Total Iteration Time: 4.74189

Cumulative Model Updates: 228,584
Cumulative Timesteps: 1,907,064,160

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1907064160...
Checkpoint 1907064160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,169.95690
Policy Entropy: 2.05000
Value Function Loss: 0.02563

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.08999
Policy Update Magnitude: 0.30876
Value Function Update Magnitude: 0.31740

Collected Steps per Second: 21,200.49520
Overall Steps per Second: 10,233.38554

Timestep Collection Time: 2.35976
Timestep Consumption Time: 2.52895
PPO Batch Consumption Time: 0.29168
Total Iteration Time: 4.88870

Cumulative Model Updates: 228,590
Cumulative Timesteps: 1,907,114,188

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,788.14816
Policy Entropy: 2.05040
Value Function Loss: 0.02136

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.08725
Policy Update Magnitude: 0.29461
Value Function Update Magnitude: 0.33140

Collected Steps per Second: 21,417.18146
Overall Steps per Second: 10,422.10896

Timestep Collection Time: 2.33476
Timestep Consumption Time: 2.46312
PPO Batch Consumption Time: 0.28436
Total Iteration Time: 4.79788

Cumulative Model Updates: 228,596
Cumulative Timesteps: 1,907,164,192

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1907164192...
Checkpoint 1907164192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48,067.35773
Policy Entropy: 2.03478
Value Function Loss: 0.02003

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.08096
Policy Update Magnitude: 0.28850
Value Function Update Magnitude: 0.32388

Collected Steps per Second: 21,242.06210
Overall Steps per Second: 10,249.80072

Timestep Collection Time: 2.35410
Timestep Consumption Time: 2.52463
PPO Batch Consumption Time: 0.29409
Total Iteration Time: 4.87873

Cumulative Model Updates: 228,602
Cumulative Timesteps: 1,907,214,198

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57,598.25746
Policy Entropy: 2.02665
Value Function Loss: 0.01970

Mean KL Divergence: 0.00763
SB3 Clip Fraction: 0.07065
Policy Update Magnitude: 0.29469
Value Function Update Magnitude: 0.30911

Collected Steps per Second: 22,157.83572
Overall Steps per Second: 10,421.02330

Timestep Collection Time: 2.25789
Timestep Consumption Time: 2.54298
PPO Batch Consumption Time: 0.29088
Total Iteration Time: 4.80087

Cumulative Model Updates: 228,608
Cumulative Timesteps: 1,907,264,228

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1907264228...
Checkpoint 1907264228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 54,133.89369
Policy Entropy: 2.01555
Value Function Loss: 0.02121

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.06981
Policy Update Magnitude: 0.29880
Value Function Update Magnitude: 0.30482

Collected Steps per Second: 21,806.44446
Overall Steps per Second: 10,513.49282

Timestep Collection Time: 2.29428
Timestep Consumption Time: 2.46437
PPO Batch Consumption Time: 0.27935
Total Iteration Time: 4.75865

Cumulative Model Updates: 228,614
Cumulative Timesteps: 1,907,314,258

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46,212.14279
Policy Entropy: 2.00103
Value Function Loss: 0.02097

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.07159
Policy Update Magnitude: 0.29933
Value Function Update Magnitude: 0.30555

Collected Steps per Second: 22,106.86120
Overall Steps per Second: 10,620.92005

Timestep Collection Time: 2.26310
Timestep Consumption Time: 2.44742
PPO Batch Consumption Time: 0.27942
Total Iteration Time: 4.71051

Cumulative Model Updates: 228,620
Cumulative Timesteps: 1,907,364,288

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1907364288...
Checkpoint 1907364288 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 57,172.05704
Policy Entropy: 2.00945
Value Function Loss: 0.02221

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.08388
Policy Update Magnitude: 0.30378
Value Function Update Magnitude: 0.32103

Collected Steps per Second: 21,831.30095
Overall Steps per Second: 10,553.86142

Timestep Collection Time: 2.29084
Timestep Consumption Time: 2.44790
PPO Batch Consumption Time: 0.28006
Total Iteration Time: 4.73874

Cumulative Model Updates: 228,626
Cumulative Timesteps: 1,907,414,300

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,859.04565
Policy Entropy: 2.01839
Value Function Loss: 0.02332

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.08336
Policy Update Magnitude: 0.30735
Value Function Update Magnitude: 0.33092

Collected Steps per Second: 22,213.83100
Overall Steps per Second: 10,490.93854

Timestep Collection Time: 2.25103
Timestep Consumption Time: 2.51537
PPO Batch Consumption Time: 0.29205
Total Iteration Time: 4.76640

Cumulative Model Updates: 228,632
Cumulative Timesteps: 1,907,464,304

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1907464304...
Checkpoint 1907464304 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,129.71578
Policy Entropy: 2.03291
Value Function Loss: 0.02302

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.07793
Policy Update Magnitude: 0.30693
Value Function Update Magnitude: 0.31596

Collected Steps per Second: 21,713.46422
Overall Steps per Second: 10,541.96098

Timestep Collection Time: 2.30382
Timestep Consumption Time: 2.44140
PPO Batch Consumption Time: 0.27955
Total Iteration Time: 4.74523

Cumulative Model Updates: 228,638
Cumulative Timesteps: 1,907,514,328

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,742.10443
Policy Entropy: 2.04023
Value Function Loss: 0.02205

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.07987
Policy Update Magnitude: 0.30218
Value Function Update Magnitude: 0.35150

Collected Steps per Second: 21,719.25404
Overall Steps per Second: 10,547.95048

Timestep Collection Time: 2.30238
Timestep Consumption Time: 2.43845
PPO Batch Consumption Time: 0.27989
Total Iteration Time: 4.74083

Cumulative Model Updates: 228,644
Cumulative Timesteps: 1,907,564,334

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1907564334...
Checkpoint 1907564334 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,195.28067
Policy Entropy: 2.05412
Value Function Loss: 0.02085

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.07352
Policy Update Magnitude: 0.29739
Value Function Update Magnitude: 0.33940

Collected Steps per Second: 21,205.24142
Overall Steps per Second: 10,272.53240

Timestep Collection Time: 2.35904
Timestep Consumption Time: 2.51065
PPO Batch Consumption Time: 0.29496
Total Iteration Time: 4.86969

Cumulative Model Updates: 228,650
Cumulative Timesteps: 1,907,614,358

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47,386.04874
Policy Entropy: 2.06188
Value Function Loss: 0.01867

Mean KL Divergence: 0.00695
SB3 Clip Fraction: 0.06869
Policy Update Magnitude: 0.28952
Value Function Update Magnitude: 0.30217

Collected Steps per Second: 21,303.75017
Overall Steps per Second: 10,438.93977

Timestep Collection Time: 2.34851
Timestep Consumption Time: 2.44432
PPO Batch Consumption Time: 0.29408
Total Iteration Time: 4.79282

Cumulative Model Updates: 228,656
Cumulative Timesteps: 1,907,664,390

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1907664390...
Checkpoint 1907664390 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,449.40590
Policy Entropy: 2.05840
Value Function Loss: 0.01792

Mean KL Divergence: 0.00648
SB3 Clip Fraction: 0.06384
Policy Update Magnitude: 0.28527
Value Function Update Magnitude: 0.28587

Collected Steps per Second: 20,542.71285
Overall Steps per Second: 10,260.05401

Timestep Collection Time: 2.43493
Timestep Consumption Time: 2.44029
PPO Batch Consumption Time: 0.29294
Total Iteration Time: 4.87522

Cumulative Model Updates: 228,662
Cumulative Timesteps: 1,907,714,410

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,400.77342
Policy Entropy: 2.04655
Value Function Loss: 0.01821

Mean KL Divergence: 0.00677
SB3 Clip Fraction: 0.06555
Policy Update Magnitude: 0.28744
Value Function Update Magnitude: 0.26926

Collected Steps per Second: 20,801.34001
Overall Steps per Second: 10,347.59200

Timestep Collection Time: 2.40571
Timestep Consumption Time: 2.43039
PPO Batch Consumption Time: 0.28741
Total Iteration Time: 4.83610

Cumulative Model Updates: 228,668
Cumulative Timesteps: 1,907,764,452

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1907764452...
Checkpoint 1907764452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 59,201.91212
Policy Entropy: 2.04003
Value Function Loss: 0.02117

Mean KL Divergence: 0.00689
SB3 Clip Fraction: 0.06444
Policy Update Magnitude: 0.29629
Value Function Update Magnitude: 0.27732

Collected Steps per Second: 20,374.36190
Overall Steps per Second: 10,291.94956

Timestep Collection Time: 2.45534
Timestep Consumption Time: 2.40535
PPO Batch Consumption Time: 0.27814
Total Iteration Time: 4.86069

Cumulative Model Updates: 228,674
Cumulative Timesteps: 1,907,814,478

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51,744.96334
Policy Entropy: 2.05143
Value Function Loss: 0.02703

Mean KL Divergence: 0.00770
SB3 Clip Fraction: 0.07025
Policy Update Magnitude: 0.31066
Value Function Update Magnitude: 0.25591

Collected Steps per Second: 21,950.86851
Overall Steps per Second: 10,478.35888

Timestep Collection Time: 2.27781
Timestep Consumption Time: 2.49393
PPO Batch Consumption Time: 0.29352
Total Iteration Time: 4.77174

Cumulative Model Updates: 228,680
Cumulative Timesteps: 1,907,864,478

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1907864478...
Checkpoint 1907864478 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,193.44486
Policy Entropy: 2.05856
Value Function Loss: 0.02655

Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.07440
Policy Update Magnitude: 0.32047
Value Function Update Magnitude: 0.21234

Collected Steps per Second: 21,516.92052
Overall Steps per Second: 10,472.02068

Timestep Collection Time: 2.32375
Timestep Consumption Time: 2.45088
PPO Batch Consumption Time: 0.28019
Total Iteration Time: 4.77463

Cumulative Model Updates: 228,686
Cumulative Timesteps: 1,907,914,478

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,101.44837
Policy Entropy: 2.06783
Value Function Loss: 0.02837

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.07788
Policy Update Magnitude: 0.31536
Value Function Update Magnitude: 0.18793

Collected Steps per Second: 22,313.23275
Overall Steps per Second: 10,481.82770

Timestep Collection Time: 2.24145
Timestep Consumption Time: 2.53005
PPO Batch Consumption Time: 0.29180
Total Iteration Time: 4.77150

Cumulative Model Updates: 228,692
Cumulative Timesteps: 1,907,964,492

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1907964492...
Checkpoint 1907964492 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,954.04828
Policy Entropy: 2.06970
Value Function Loss: 0.02726

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.07654
Policy Update Magnitude: 0.30458
Value Function Update Magnitude: 0.18356

Collected Steps per Second: 21,736.21587
Overall Steps per Second: 10,422.60961

Timestep Collection Time: 2.30178
Timestep Consumption Time: 2.49855
PPO Batch Consumption Time: 0.29027
Total Iteration Time: 4.80033

Cumulative Model Updates: 228,698
Cumulative Timesteps: 1,908,014,524

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,079.93878
Policy Entropy: 2.06141
Value Function Loss: 0.02510

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.07497
Policy Update Magnitude: 0.29843
Value Function Update Magnitude: 0.18702

Collected Steps per Second: 22,044.67660
Overall Steps per Second: 10,625.35625

Timestep Collection Time: 2.26821
Timestep Consumption Time: 2.43770
PPO Batch Consumption Time: 0.27965
Total Iteration Time: 4.70591

Cumulative Model Updates: 228,704
Cumulative Timesteps: 1,908,064,526

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1908064526...
Checkpoint 1908064526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,494.01150
Policy Entropy: 2.03817
Value Function Loss: 0.02055

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.07462
Policy Update Magnitude: 0.29318
Value Function Update Magnitude: 0.22888

Collected Steps per Second: 21,594.30203
Overall Steps per Second: 10,338.96968

Timestep Collection Time: 2.31644
Timestep Consumption Time: 2.52176
PPO Batch Consumption Time: 0.29529
Total Iteration Time: 4.83820

Cumulative Model Updates: 228,710
Cumulative Timesteps: 1,908,114,548

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,494.01150
Policy Entropy: 2.02371
Value Function Loss: 0.01811

Mean KL Divergence: 0.00744
SB3 Clip Fraction: 0.07052
Policy Update Magnitude: 0.28944
Value Function Update Magnitude: 0.26821

Collected Steps per Second: 21,968.86049
Overall Steps per Second: 10,417.01496

Timestep Collection Time: 2.27613
Timestep Consumption Time: 2.52409
PPO Batch Consumption Time: 0.29411
Total Iteration Time: 4.80022

Cumulative Model Updates: 228,716
Cumulative Timesteps: 1,908,164,552

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1908164552...
Checkpoint 1908164552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,832.98467
Policy Entropy: 2.02834
Value Function Loss: 0.01873

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.07535
Policy Update Magnitude: 0.29281
Value Function Update Magnitude: 0.28514

Collected Steps per Second: 21,646.38636
Overall Steps per Second: 10,532.08772

Timestep Collection Time: 2.31087
Timestep Consumption Time: 2.43862
PPO Batch Consumption Time: 0.27931
Total Iteration Time: 4.74949

Cumulative Model Updates: 228,722
Cumulative Timesteps: 1,908,214,574

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57,648.34450
Policy Entropy: 2.03689
Value Function Loss: 0.01956

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.07619
Policy Update Magnitude: 0.29300
Value Function Update Magnitude: 0.29916

Collected Steps per Second: 20,094.09098
Overall Steps per Second: 10,074.79406

Timestep Collection Time: 2.48829
Timestep Consumption Time: 2.47459
PPO Batch Consumption Time: 0.27942
Total Iteration Time: 4.96288

Cumulative Model Updates: 228,728
Cumulative Timesteps: 1,908,264,574

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1908264574...
Checkpoint 1908264574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 57,648.34450
Policy Entropy: 2.03179
Value Function Loss: 0.01864

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.07673
Policy Update Magnitude: 0.29057
Value Function Update Magnitude: 0.31016

Collected Steps per Second: 20,271.35244
Overall Steps per Second: 10,236.25342

Timestep Collection Time: 2.46752
Timestep Consumption Time: 2.41903
PPO Batch Consumption Time: 0.28906
Total Iteration Time: 4.88655

Cumulative Model Updates: 228,734
Cumulative Timesteps: 1,908,314,594

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49,212.31885
Policy Entropy: 2.03908
Value Function Loss: 0.01993

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.07677
Policy Update Magnitude: 0.29817
Value Function Update Magnitude: 0.32148

Collected Steps per Second: 20,984.46860
Overall Steps per Second: 10,396.87287

Timestep Collection Time: 2.38367
Timestep Consumption Time: 2.42739
PPO Batch Consumption Time: 0.28760
Total Iteration Time: 4.81106

Cumulative Model Updates: 228,740
Cumulative Timesteps: 1,908,364,614

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1908364614...
Checkpoint 1908364614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 57,922.24620
Policy Entropy: 2.03468
Value Function Loss: 0.02104

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.07726
Policy Update Magnitude: 0.30675
Value Function Update Magnitude: 0.30776

Collected Steps per Second: 19,702.75590
Overall Steps per Second: 10,182.71302

Timestep Collection Time: 2.53822
Timestep Consumption Time: 2.37304
PPO Batch Consumption Time: 0.28031
Total Iteration Time: 4.91126

Cumulative Model Updates: 228,746
Cumulative Timesteps: 1,908,414,624

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48,353.48272
Policy Entropy: 2.05991
Value Function Loss: 0.02090

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.07662
Policy Update Magnitude: 0.29834
Value Function Update Magnitude: 0.29418

Collected Steps per Second: 20,666.40219
Overall Steps per Second: 10,458.67349

Timestep Collection Time: 2.41939
Timestep Consumption Time: 2.36134
PPO Batch Consumption Time: 0.27947
Total Iteration Time: 4.78072

Cumulative Model Updates: 228,752
Cumulative Timesteps: 1,908,464,624

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1908464624...
Checkpoint 1908464624 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,190.76853
Policy Entropy: 2.07105
Value Function Loss: 0.02153

Mean KL Divergence: 0.00708
SB3 Clip Fraction: 0.06573
Policy Update Magnitude: 0.29248
Value Function Update Magnitude: 0.26424

Collected Steps per Second: 20,778.91484
Overall Steps per Second: 10,272.89579

Timestep Collection Time: 2.40773
Timestep Consumption Time: 2.46237
PPO Batch Consumption Time: 0.28558
Total Iteration Time: 4.87010

Cumulative Model Updates: 228,758
Cumulative Timesteps: 1,908,514,654

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,018.91057
Policy Entropy: 2.06777
Value Function Loss: 0.02184

Mean KL Divergence: 0.00762
SB3 Clip Fraction: 0.07382
Policy Update Magnitude: 0.29302
Value Function Update Magnitude: 0.23821

Collected Steps per Second: 21,859.44600
Overall Steps per Second: 10,438.91066

Timestep Collection Time: 2.28844
Timestep Consumption Time: 2.50363
PPO Batch Consumption Time: 0.28802
Total Iteration Time: 4.79207

Cumulative Model Updates: 228,764
Cumulative Timesteps: 1,908,564,678

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1908564678...
Checkpoint 1908564678 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 59,917.20148
Policy Entropy: 2.07788
Value Function Loss: 0.02084

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.07866
Policy Update Magnitude: 0.28945
Value Function Update Magnitude: 0.21668

Collected Steps per Second: 21,736.83200
Overall Steps per Second: 10,567.99262

Timestep Collection Time: 2.30024
Timestep Consumption Time: 2.43102
PPO Batch Consumption Time: 0.28053
Total Iteration Time: 4.73127

Cumulative Model Updates: 228,770
Cumulative Timesteps: 1,908,614,678

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51,186.10921
Policy Entropy: 2.07091
Value Function Loss: 0.02385

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.07805
Policy Update Magnitude: 0.30298
Value Function Update Magnitude: 0.20335

Collected Steps per Second: 22,238.89139
Overall Steps per Second: 10,537.54829

Timestep Collection Time: 2.24966
Timestep Consumption Time: 2.49812
PPO Batch Consumption Time: 0.28819
Total Iteration Time: 4.74778

Cumulative Model Updates: 228,776
Cumulative Timesteps: 1,908,664,708

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1908664708...
Checkpoint 1908664708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,698.14759
Policy Entropy: 2.08513
Value Function Loss: 0.02408

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.07873
Policy Update Magnitude: 0.29991
Value Function Update Magnitude: 0.19741

Collected Steps per Second: 21,692.62038
Overall Steps per Second: 10,558.64813

Timestep Collection Time: 2.30539
Timestep Consumption Time: 2.43101
PPO Batch Consumption Time: 0.28030
Total Iteration Time: 4.73640

Cumulative Model Updates: 228,782
Cumulative Timesteps: 1,908,714,718

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,548.00396
Policy Entropy: 2.08167
Value Function Loss: 0.02217

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.08055
Policy Update Magnitude: 0.28557
Value Function Update Magnitude: 0.22630

Collected Steps per Second: 22,091.72314
Overall Steps per Second: 10,534.37569

Timestep Collection Time: 2.26420
Timestep Consumption Time: 2.48407
PPO Batch Consumption Time: 0.28622
Total Iteration Time: 4.74826

Cumulative Model Updates: 228,788
Cumulative Timesteps: 1,908,764,738

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1908764738...
Checkpoint 1908764738 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,596.65485
Policy Entropy: 2.07094
Value Function Loss: 0.01965

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.06956
Policy Update Magnitude: 0.28781
Value Function Update Magnitude: 0.27353

Collected Steps per Second: 21,736.84069
Overall Steps per Second: 10,569.69457

Timestep Collection Time: 2.30043
Timestep Consumption Time: 2.43046
PPO Batch Consumption Time: 0.27989
Total Iteration Time: 4.73088

Cumulative Model Updates: 228,794
Cumulative Timesteps: 1,908,814,742

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,451.05888
Policy Entropy: 2.07874
Value Function Loss: 0.02085

Mean KL Divergence: 0.00782
SB3 Clip Fraction: 0.07033
Policy Update Magnitude: 0.29229
Value Function Update Magnitude: 0.29447

Collected Steps per Second: 21,790.58696
Overall Steps per Second: 10,539.65152

Timestep Collection Time: 2.29539
Timestep Consumption Time: 2.45030
PPO Batch Consumption Time: 0.27983
Total Iteration Time: 4.74570

Cumulative Model Updates: 228,800
Cumulative Timesteps: 1,908,864,760

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1908864760...
Checkpoint 1908864760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,578.21197
Policy Entropy: 2.08048
Value Function Loss: 0.01978

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.06611
Policy Update Magnitude: 0.28897
Value Function Update Magnitude: 0.32686

Collected Steps per Second: 21,275.32964
Overall Steps per Second: 10,284.63379

Timestep Collection Time: 2.35099
Timestep Consumption Time: 2.51239
PPO Batch Consumption Time: 0.29397
Total Iteration Time: 4.86337

Cumulative Model Updates: 228,806
Cumulative Timesteps: 1,908,914,778

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 72,285.59502
Policy Entropy: 2.09346
Value Function Loss: 0.01911

Mean KL Divergence: 0.00753
SB3 Clip Fraction: 0.06858
Policy Update Magnitude: 0.28896
Value Function Update Magnitude: 0.33282

Collected Steps per Second: 21,534.92373
Overall Steps per Second: 10,329.16215

Timestep Collection Time: 2.32330
Timestep Consumption Time: 2.52047
PPO Batch Consumption Time: 0.29044
Total Iteration Time: 4.84376

Cumulative Model Updates: 228,812
Cumulative Timesteps: 1,908,964,810

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1908964810...
Checkpoint 1908964810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,961.62251
Policy Entropy: 2.07618
Value Function Loss: 0.02041

Mean KL Divergence: 0.00782
SB3 Clip Fraction: 0.07238
Policy Update Magnitude: 0.29546
Value Function Update Magnitude: 0.33421

Collected Steps per Second: 21,048.43552
Overall Steps per Second: 10,222.70132

Timestep Collection Time: 2.37566
Timestep Consumption Time: 2.51580
PPO Batch Consumption Time: 0.29026
Total Iteration Time: 4.89147

Cumulative Model Updates: 228,818
Cumulative Timesteps: 1,909,014,814

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42,781.10047
Policy Entropy: 2.07962
Value Function Loss: 0.02261

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.07507
Policy Update Magnitude: 0.30217
Value Function Update Magnitude: 0.32820

Collected Steps per Second: 21,460.16033
Overall Steps per Second: 10,456.91324

Timestep Collection Time: 2.33027
Timestep Consumption Time: 2.45202
PPO Batch Consumption Time: 0.27895
Total Iteration Time: 4.78229

Cumulative Model Updates: 228,824
Cumulative Timesteps: 1,909,064,822

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1909064822...
Checkpoint 1909064822 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,884.09990
Policy Entropy: 2.07059
Value Function Loss: 0.02430

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.07522
Policy Update Magnitude: 0.31100
Value Function Update Magnitude: 0.35129

Collected Steps per Second: 20,979.09723
Overall Steps per Second: 10,250.98437

Timestep Collection Time: 2.38456
Timestep Consumption Time: 2.49555
PPO Batch Consumption Time: 0.28947
Total Iteration Time: 4.88012

Cumulative Model Updates: 228,830
Cumulative Timesteps: 1,909,114,848

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,603.93298
Policy Entropy: 2.06710
Value Function Loss: 0.02365

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.06969
Policy Update Magnitude: 0.30891
Value Function Update Magnitude: 0.35878

Collected Steps per Second: 22,233.52893
Overall Steps per Second: 10,413.99382

Timestep Collection Time: 2.25039
Timestep Consumption Time: 2.55411
PPO Batch Consumption Time: 0.29048
Total Iteration Time: 4.80450

Cumulative Model Updates: 228,836
Cumulative Timesteps: 1,909,164,882

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1909164882...
Checkpoint 1909164882 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,799.18883
Policy Entropy: 2.06161
Value Function Loss: 0.02422

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.06812
Policy Update Magnitude: 0.30387
Value Function Update Magnitude: 0.32862

Collected Steps per Second: 21,779.38147
Overall Steps per Second: 10,539.85013

Timestep Collection Time: 2.29694
Timestep Consumption Time: 2.44942
PPO Batch Consumption Time: 0.28015
Total Iteration Time: 4.74637

Cumulative Model Updates: 228,842
Cumulative Timesteps: 1,909,214,908

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,017.62313
Policy Entropy: 2.05428
Value Function Loss: 0.02234

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.07453
Policy Update Magnitude: 0.29931
Value Function Update Magnitude: 0.33407

Collected Steps per Second: 21,819.01013
Overall Steps per Second: 10,537.31523

Timestep Collection Time: 2.29250
Timestep Consumption Time: 2.45444
PPO Batch Consumption Time: 0.27954
Total Iteration Time: 4.74694

Cumulative Model Updates: 228,848
Cumulative Timesteps: 1,909,264,928

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1909264928...
Checkpoint 1909264928 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,416.38074
Policy Entropy: 2.07963
Value Function Loss: 0.02406

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.07609
Policy Update Magnitude: 0.30573
Value Function Update Magnitude: 0.34855

Collected Steps per Second: 21,556.41859
Overall Steps per Second: 10,373.70776

Timestep Collection Time: 2.32024
Timestep Consumption Time: 2.50118
PPO Batch Consumption Time: 0.29197
Total Iteration Time: 4.82142

Cumulative Model Updates: 228,854
Cumulative Timesteps: 1,909,314,944

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55,030.93209
Policy Entropy: 2.08429
Value Function Loss: 0.02456

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.07506
Policy Update Magnitude: 0.30732
Value Function Update Magnitude: 0.33422

Collected Steps per Second: 21,450.47183
Overall Steps per Second: 10,484.28804

Timestep Collection Time: 2.33179
Timestep Consumption Time: 2.43897
PPO Batch Consumption Time: 0.29197
Total Iteration Time: 4.77076

Cumulative Model Updates: 228,860
Cumulative Timesteps: 1,909,364,962

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1909364962...
Checkpoint 1909364962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,173.59140
Policy Entropy: 2.09906
Value Function Loss: 0.02302

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.08002
Policy Update Magnitude: 0.30308
Value Function Update Magnitude: 0.33543

Collected Steps per Second: 20,976.68865
Overall Steps per Second: 10,426.00612

Timestep Collection Time: 2.38484
Timestep Consumption Time: 2.41336
PPO Batch Consumption Time: 0.28662
Total Iteration Time: 4.79819

Cumulative Model Updates: 228,866
Cumulative Timesteps: 1,909,414,988

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77,353.18192
Policy Entropy: 2.09469
Value Function Loss: 0.02501

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.07865
Policy Update Magnitude: 0.30552
Value Function Update Magnitude: 0.34874

Collected Steps per Second: 21,385.71754
Overall Steps per Second: 10,493.29412

Timestep Collection Time: 2.33894
Timestep Consumption Time: 2.42791
PPO Batch Consumption Time: 0.28951
Total Iteration Time: 4.76685

Cumulative Model Updates: 228,872
Cumulative Timesteps: 1,909,465,008

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1909465008...
Checkpoint 1909465008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 51,432.86025
Policy Entropy: 2.10523
Value Function Loss: 0.02305

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.07969
Policy Update Magnitude: 0.31125
Value Function Update Magnitude: 0.35252

Collected Steps per Second: 20,916.60976
Overall Steps per Second: 10,412.44960

Timestep Collection Time: 2.39178
Timestep Consumption Time: 2.41285
PPO Batch Consumption Time: 0.28937
Total Iteration Time: 4.80463

Cumulative Model Updates: 228,878
Cumulative Timesteps: 1,909,515,036

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49,139.16509
Policy Entropy: 2.11056
Value Function Loss: 0.02081

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.07365
Policy Update Magnitude: 0.30246
Value Function Update Magnitude: 0.33902

Collected Steps per Second: 21,096.33987
Overall Steps per Second: 10,260.99266

Timestep Collection Time: 2.37084
Timestep Consumption Time: 2.50354
PPO Batch Consumption Time: 0.29311
Total Iteration Time: 4.87438

Cumulative Model Updates: 228,884
Cumulative Timesteps: 1,909,565,052

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1909565052...
Checkpoint 1909565052 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 56,233.00528
Policy Entropy: 2.10754
Value Function Loss: 0.01705

Mean KL Divergence: 0.00721
SB3 Clip Fraction: 0.06829
Policy Update Magnitude: 0.28456
Value Function Update Magnitude: 0.31526

Collected Steps per Second: 21,092.07807
Overall Steps per Second: 10,233.06726

Timestep Collection Time: 2.37198
Timestep Consumption Time: 2.51707
PPO Batch Consumption Time: 0.29462
Total Iteration Time: 4.88905

Cumulative Model Updates: 228,890
Cumulative Timesteps: 1,909,615,082

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57,083.96579
Policy Entropy: 2.08999
Value Function Loss: 0.01720

Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.07362
Policy Update Magnitude: 0.28194
Value Function Update Magnitude: 0.28951

Collected Steps per Second: 21,734.34870
Overall Steps per Second: 10,433.23438

Timestep Collection Time: 2.30087
Timestep Consumption Time: 2.49227
PPO Batch Consumption Time: 0.29147
Total Iteration Time: 4.79314

Cumulative Model Updates: 228,896
Cumulative Timesteps: 1,909,665,090

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1909665090...
Checkpoint 1909665090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 64,574.27176
Policy Entropy: 2.08487
Value Function Loss: 0.01999

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.07095
Policy Update Magnitude: 0.29017
Value Function Update Magnitude: 0.27386

Collected Steps per Second: 20,779.06191
Overall Steps per Second: 10,218.23371

Timestep Collection Time: 2.40665
Timestep Consumption Time: 2.48734
PPO Batch Consumption Time: 0.28824
Total Iteration Time: 4.89400

Cumulative Model Updates: 228,902
Cumulative Timesteps: 1,909,715,098

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56,144.39082
Policy Entropy: 2.08351
Value Function Loss: 0.02113

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.07670
Policy Update Magnitude: 0.29450
Value Function Update Magnitude: 0.25150

Collected Steps per Second: 21,341.99313
Overall Steps per Second: 10,423.89499

Timestep Collection Time: 2.34364
Timestep Consumption Time: 2.45476
PPO Batch Consumption Time: 0.28009
Total Iteration Time: 4.79840

Cumulative Model Updates: 228,908
Cumulative Timesteps: 1,909,765,116

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1909765116...
Checkpoint 1909765116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 81,381.15824
Policy Entropy: 2.07495
Value Function Loss: 0.01991

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.07648
Policy Update Magnitude: 0.28814
Value Function Update Magnitude: 0.21300

Collected Steps per Second: 21,628.88409
Overall Steps per Second: 10,293.05404

Timestep Collection Time: 2.31237
Timestep Consumption Time: 2.54663
PPO Batch Consumption Time: 0.29402
Total Iteration Time: 4.85900

Cumulative Model Updates: 228,914
Cumulative Timesteps: 1,909,815,130

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61,240.37588
Policy Entropy: 2.07814
Value Function Loss: 0.01922

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.07326
Policy Update Magnitude: 0.28250
Value Function Update Magnitude: 0.19954

Collected Steps per Second: 22,200.58359
Overall Steps per Second: 10,495.81677

Timestep Collection Time: 2.25327
Timestep Consumption Time: 2.51282
PPO Batch Consumption Time: 0.29286
Total Iteration Time: 4.76609

Cumulative Model Updates: 228,920
Cumulative Timesteps: 1,909,865,154

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1909865154...
Checkpoint 1909865154 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,753.32397
Policy Entropy: 2.09573
Value Function Loss: 0.01749

Mean KL Divergence: 0.00750
SB3 Clip Fraction: 0.06784
Policy Update Magnitude: 0.28032
Value Function Update Magnitude: 0.21740

Collected Steps per Second: 21,871.41122
Overall Steps per Second: 10,502.90457

Timestep Collection Time: 2.28664
Timestep Consumption Time: 2.47509
PPO Batch Consumption Time: 0.28581
Total Iteration Time: 4.76173

Cumulative Model Updates: 228,926
Cumulative Timesteps: 1,909,915,166

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,824.05467
Policy Entropy: 2.10297
Value Function Loss: 0.02178

Mean KL Divergence: 0.00749
SB3 Clip Fraction: 0.07086
Policy Update Magnitude: 0.29427
Value Function Update Magnitude: 0.24577

Collected Steps per Second: 22,188.86977
Overall Steps per Second: 10,493.38833

Timestep Collection Time: 2.25437
Timestep Consumption Time: 2.51263
PPO Batch Consumption Time: 0.29344
Total Iteration Time: 4.76700

Cumulative Model Updates: 228,932
Cumulative Timesteps: 1,909,965,188

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1909965188...
Checkpoint 1909965188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,325.71414
Policy Entropy: 2.11002
Value Function Loss: 0.02039

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.07741
Policy Update Magnitude: 0.29623
Value Function Update Magnitude: 0.27534

Collected Steps per Second: 21,831.65585
Overall Steps per Second: 10,571.08747

Timestep Collection Time: 2.29117
Timestep Consumption Time: 2.44061
PPO Batch Consumption Time: 0.28084
Total Iteration Time: 4.73177

Cumulative Model Updates: 228,938
Cumulative Timesteps: 1,910,015,208

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,420.26228
Policy Entropy: 2.09419
Value Function Loss: 0.02232

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.07948
Policy Update Magnitude: 0.29511
Value Function Update Magnitude: 0.31513

Collected Steps per Second: 21,393.63532
Overall Steps per Second: 10,478.38893

Timestep Collection Time: 2.33780
Timestep Consumption Time: 2.43526
PPO Batch Consumption Time: 0.29100
Total Iteration Time: 4.77306

Cumulative Model Updates: 228,944
Cumulative Timesteps: 1,910,065,222

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1910065222...
Checkpoint 1910065222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,889.71881
Policy Entropy: 2.09032
Value Function Loss: 0.02155

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.08608
Policy Update Magnitude: 0.29959
Value Function Update Magnitude: 0.28376

Collected Steps per Second: 20,920.22724
Overall Steps per Second: 10,292.22233

Timestep Collection Time: 2.39003
Timestep Consumption Time: 2.46801
PPO Batch Consumption Time: 0.29178
Total Iteration Time: 4.85804

Cumulative Model Updates: 228,950
Cumulative Timesteps: 1,910,115,222

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,197.63532
Policy Entropy: 2.07875
Value Function Loss: 0.02296

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.08617
Policy Update Magnitude: 0.30465
Value Function Update Magnitude: 0.23713

Collected Steps per Second: 21,383.52062
Overall Steps per Second: 10,471.38043

Timestep Collection Time: 2.33918
Timestep Consumption Time: 2.43765
PPO Batch Consumption Time: 0.29272
Total Iteration Time: 4.77683

Cumulative Model Updates: 228,956
Cumulative Timesteps: 1,910,165,242

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1910165242...
Checkpoint 1910165242 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,949.20180
Policy Entropy: 2.09428
Value Function Loss: 0.02028

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.07309
Policy Update Magnitude: 0.29568
Value Function Update Magnitude: 0.17917

Collected Steps per Second: 20,600.29970
Overall Steps per Second: 10,152.55234

Timestep Collection Time: 2.42822
Timestep Consumption Time: 2.49882
PPO Batch Consumption Time: 0.29411
Total Iteration Time: 4.92704

Cumulative Model Updates: 228,962
Cumulative Timesteps: 1,910,215,264

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,719.26311
Policy Entropy: 2.08498
Value Function Loss: 0.01830

Mean KL Divergence: 0.00645
SB3 Clip Fraction: 0.06108
Policy Update Magnitude: 0.28542
Value Function Update Magnitude: 0.17276

Collected Steps per Second: 21,574.97489
Overall Steps per Second: 10,390.68476

Timestep Collection Time: 2.31843
Timestep Consumption Time: 2.49550
PPO Batch Consumption Time: 0.29138
Total Iteration Time: 4.81393

Cumulative Model Updates: 228,968
Cumulative Timesteps: 1,910,265,284

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1910265284...
Checkpoint 1910265284 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 54,872.34303
Policy Entropy: 2.06610
Value Function Loss: 0.01709

Mean KL Divergence: 0.00667
SB3 Clip Fraction: 0.06185
Policy Update Magnitude: 0.29078
Value Function Update Magnitude: 0.18049

Collected Steps per Second: 21,298.39934
Overall Steps per Second: 10,366.71138

Timestep Collection Time: 2.34863
Timestep Consumption Time: 2.47663
PPO Batch Consumption Time: 0.29181
Total Iteration Time: 4.82525

Cumulative Model Updates: 228,974
Cumulative Timesteps: 1,910,315,306

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48,332.90871
Policy Entropy: 2.06739
Value Function Loss: 0.01829

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.07172
Policy Update Magnitude: 0.29302
Value Function Update Magnitude: 0.24020

Collected Steps per Second: 21,788.33227
Overall Steps per Second: 10,284.02247

Timestep Collection Time: 2.29600
Timestep Consumption Time: 2.56844
PPO Batch Consumption Time: 0.29204
Total Iteration Time: 4.86444

Cumulative Model Updates: 228,980
Cumulative Timesteps: 1,910,365,332

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1910365332...
Checkpoint 1910365332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 60,926.62588
Policy Entropy: 2.08577
Value Function Loss: 0.01734

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.07655
Policy Update Magnitude: 0.28611
Value Function Update Magnitude: 0.27950

Collected Steps per Second: 21,381.24026
Overall Steps per Second: 10,254.08375

Timestep Collection Time: 2.33878
Timestep Consumption Time: 2.53791
PPO Batch Consumption Time: 0.29371
Total Iteration Time: 4.87669

Cumulative Model Updates: 228,986
Cumulative Timesteps: 1,910,415,338

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68,485.26479
Policy Entropy: 2.08902
Value Function Loss: 0.01958

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.08977
Policy Update Magnitude: 0.28607
Value Function Update Magnitude: 0.28018

Collected Steps per Second: 21,991.17619
Overall Steps per Second: 10,390.00150

Timestep Collection Time: 2.27546
Timestep Consumption Time: 2.54071
PPO Batch Consumption Time: 0.28864
Total Iteration Time: 4.81617

Cumulative Model Updates: 228,992
Cumulative Timesteps: 1,910,465,378

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1910465378...
Checkpoint 1910465378 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 59,185.41763
Policy Entropy: 2.07443
Value Function Loss: 0.01975

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.09260
Policy Update Magnitude: 0.29700
Value Function Update Magnitude: 0.31443

Collected Steps per Second: 21,607.31963
Overall Steps per Second: 10,380.30659

Timestep Collection Time: 2.31440
Timestep Consumption Time: 2.50318
PPO Batch Consumption Time: 0.29226
Total Iteration Time: 4.81758

Cumulative Model Updates: 228,998
Cumulative Timesteps: 1,910,515,386

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 72,999.21840
Policy Entropy: 2.06363
Value Function Loss: 0.02639

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.08653
Policy Update Magnitude: 0.31307
Value Function Update Magnitude: 0.34076

Collected Steps per Second: 22,099.95909
Overall Steps per Second: 10,490.33102

Timestep Collection Time: 2.26362
Timestep Consumption Time: 2.50515
PPO Batch Consumption Time: 0.29129
Total Iteration Time: 4.76877

Cumulative Model Updates: 229,004
Cumulative Timesteps: 1,910,565,412

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1910565412...
Checkpoint 1910565412 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55,166.78908
Policy Entropy: 2.07655
Value Function Loss: 0.02793

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.08341
Policy Update Magnitude: 0.32148
Value Function Update Magnitude: 0.37311

Collected Steps per Second: 21,793.32230
Overall Steps per Second: 10,429.27248

Timestep Collection Time: 2.29446
Timestep Consumption Time: 2.50012
PPO Batch Consumption Time: 0.28898
Total Iteration Time: 4.79458

Cumulative Model Updates: 229,010
Cumulative Timesteps: 1,910,615,416

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66,621.42611
Policy Entropy: 2.08535
Value Function Loss: 0.02657

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.07703
Policy Update Magnitude: 0.31478
Value Function Update Magnitude: 0.35545

Collected Steps per Second: 22,015.24192
Overall Steps per Second: 10,471.73668

Timestep Collection Time: 2.27197
Timestep Consumption Time: 2.50450
PPO Batch Consumption Time: 0.28990
Total Iteration Time: 4.77648

Cumulative Model Updates: 229,016
Cumulative Timesteps: 1,910,665,434

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1910665434...
Checkpoint 1910665434 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 83,941.83672
Policy Entropy: 2.08735
Value Function Loss: 0.02105

Mean KL Divergence: 0.00762
SB3 Clip Fraction: 0.07205
Policy Update Magnitude: 0.30387
Value Function Update Magnitude: 0.31020

Collected Steps per Second: 21,744.94770
Overall Steps per Second: 10,571.01602

Timestep Collection Time: 2.29975
Timestep Consumption Time: 2.43092
PPO Batch Consumption Time: 0.27942
Total Iteration Time: 4.73067

Cumulative Model Updates: 229,022
Cumulative Timesteps: 1,910,715,442

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57,282.99619
Policy Entropy: 2.07308
Value Function Loss: 0.02133

Mean KL Divergence: 0.00725
SB3 Clip Fraction: 0.07032
Policy Update Magnitude: 0.29855
Value Function Update Magnitude: 0.27834

Collected Steps per Second: 21,248.23169
Overall Steps per Second: 10,439.27759

Timestep Collection Time: 2.35464
Timestep Consumption Time: 2.43803
PPO Batch Consumption Time: 0.27935
Total Iteration Time: 4.79267

Cumulative Model Updates: 229,028
Cumulative Timesteps: 1,910,765,474

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1910765474...
Checkpoint 1910765474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43,595.58879
Policy Entropy: 2.05743
Value Function Loss: 0.02198

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.07587
Policy Update Magnitude: 0.30550
Value Function Update Magnitude: 0.29937

Collected Steps per Second: 21,357.83351
Overall Steps per Second: 10,279.31994

Timestep Collection Time: 2.34190
Timestep Consumption Time: 2.52398
PPO Batch Consumption Time: 0.29525
Total Iteration Time: 4.86589

Cumulative Model Updates: 229,034
Cumulative Timesteps: 1,910,815,492

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,991.39686
Policy Entropy: 2.05396
Value Function Loss: 0.02226

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.08249
Policy Update Magnitude: 0.30588
Value Function Update Magnitude: 0.28080

Collected Steps per Second: 21,646.37946
Overall Steps per Second: 10,433.88388

Timestep Collection Time: 2.30986
Timestep Consumption Time: 2.48222
PPO Batch Consumption Time: 0.28634
Total Iteration Time: 4.79208

Cumulative Model Updates: 229,040
Cumulative Timesteps: 1,910,865,492

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1910865492...
Checkpoint 1910865492 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40,643.53035
Policy Entropy: 2.06501
Value Function Loss: 0.01939

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.07196
Policy Update Magnitude: 0.29464
Value Function Update Magnitude: 0.25566

Collected Steps per Second: 21,179.32719
Overall Steps per Second: 10,251.11565

Timestep Collection Time: 2.36183
Timestep Consumption Time: 2.51783
PPO Batch Consumption Time: 0.29437
Total Iteration Time: 4.87966

Cumulative Model Updates: 229,046
Cumulative Timesteps: 1,910,915,514

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,531.33183
Policy Entropy: 2.07710
Value Function Loss: 0.01912

Mean KL Divergence: 0.00738
SB3 Clip Fraction: 0.06992
Policy Update Magnitude: 0.29069
Value Function Update Magnitude: 0.29292

Collected Steps per Second: 21,632.83889
Overall Steps per Second: 10,402.16864

Timestep Collection Time: 2.31130
Timestep Consumption Time: 2.49539
PPO Batch Consumption Time: 0.28692
Total Iteration Time: 4.80669

Cumulative Model Updates: 229,052
Cumulative Timesteps: 1,910,965,514

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1910965514...
Checkpoint 1910965514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 56,153.76156
Policy Entropy: 2.08181
Value Function Loss: 0.01995

Mean KL Divergence: 0.00752
SB3 Clip Fraction: 0.06666
Policy Update Magnitude: 0.29568
Value Function Update Magnitude: 0.31621

Collected Steps per Second: 21,374.20380
Overall Steps per Second: 10,162.67121

Timestep Collection Time: 2.34030
Timestep Consumption Time: 2.58183
PPO Batch Consumption Time: 0.30069
Total Iteration Time: 4.92213

Cumulative Model Updates: 229,058
Cumulative Timesteps: 1,911,015,536

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57,351.89607
Policy Entropy: 2.07344
Value Function Loss: 0.02256

Mean KL Divergence: 0.01129
SB3 Clip Fraction: 0.09145
Policy Update Magnitude: 0.30078
Value Function Update Magnitude: 0.31680

Collected Steps per Second: 21,726.53182
Overall Steps per Second: 10,504.78466

Timestep Collection Time: 2.30253
Timestep Consumption Time: 2.45968
PPO Batch Consumption Time: 0.27925
Total Iteration Time: 4.76221

Cumulative Model Updates: 229,064
Cumulative Timesteps: 1,911,065,562

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1911065562...
Checkpoint 1911065562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 60,508.42629
Policy Entropy: 2.08186
Value Function Loss: 0.02326

Mean KL Divergence: 0.01860
SB3 Clip Fraction: 0.12727
Policy Update Magnitude: 0.28186
Value Function Update Magnitude: 0.28611

Collected Steps per Second: 21,765.33657
Overall Steps per Second: 10,558.00282

Timestep Collection Time: 2.29833
Timestep Consumption Time: 2.43968
PPO Batch Consumption Time: 0.27945
Total Iteration Time: 4.73802

Cumulative Model Updates: 229,070
Cumulative Timesteps: 1,911,115,586

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51,437.64127
Policy Entropy: 2.06844
Value Function Loss: 0.02242

Mean KL Divergence: 0.01165
SB3 Clip Fraction: 0.09722
Policy Update Magnitude: 0.29800
Value Function Update Magnitude: 0.26290

Collected Steps per Second: 22,057.40464
Overall Steps per Second: 10,526.73625

Timestep Collection Time: 2.26772
Timestep Consumption Time: 2.48399
PPO Batch Consumption Time: 0.28650
Total Iteration Time: 4.75171

Cumulative Model Updates: 229,076
Cumulative Timesteps: 1,911,165,606

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1911165606...
Checkpoint 1911165606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47,115.48480
Policy Entropy: 2.06888
Value Function Loss: 0.02246

Mean KL Divergence: 0.01105
SB3 Clip Fraction: 0.09539
Policy Update Magnitude: 0.30503
Value Function Update Magnitude: 0.26520

Collected Steps per Second: 21,820.73234
Overall Steps per Second: 10,573.19091

Timestep Collection Time: 2.29287
Timestep Consumption Time: 2.43910
PPO Batch Consumption Time: 0.28058
Total Iteration Time: 4.73197

Cumulative Model Updates: 229,082
Cumulative Timesteps: 1,911,215,638

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97,671.02258
Policy Entropy: 2.07314
Value Function Loss: 0.02075

Mean KL Divergence: 0.01239
SB3 Clip Fraction: 0.10532
Policy Update Magnitude: 0.29567
Value Function Update Magnitude: 0.29624

Collected Steps per Second: 21,240.28196
Overall Steps per Second: 10,615.49901

Timestep Collection Time: 2.35477
Timestep Consumption Time: 2.35683
PPO Batch Consumption Time: 0.27819
Total Iteration Time: 4.71160

Cumulative Model Updates: 229,088
Cumulative Timesteps: 1,911,265,654

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1911265654...
Checkpoint 1911265654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 79,218.55527
Policy Entropy: 2.07282
Value Function Loss: 0.02108

Mean KL Divergence: 0.01443
SB3 Clip Fraction: 0.11551
Policy Update Magnitude: 0.28035
Value Function Update Magnitude: 0.29564

Collected Steps per Second: 21,198.77936
Overall Steps per Second: 10,597.41071

Timestep Collection Time: 2.35995
Timestep Consumption Time: 2.36083
PPO Batch Consumption Time: 0.27878
Total Iteration Time: 4.72078

Cumulative Model Updates: 229,094
Cumulative Timesteps: 1,911,315,682

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57,154.99456
Policy Entropy: 2.07256
Value Function Loss: 0.02340

Mean KL Divergence: 0.01116
SB3 Clip Fraction: 0.09856
Policy Update Magnitude: 0.29945
Value Function Update Magnitude: 0.32374

Collected Steps per Second: 20,745.32550
Overall Steps per Second: 10,483.51723

Timestep Collection Time: 2.41134
Timestep Consumption Time: 2.36034
PPO Batch Consumption Time: 0.27837
Total Iteration Time: 4.77168

Cumulative Model Updates: 229,100
Cumulative Timesteps: 1,911,365,706

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1911365706...
Checkpoint 1911365706 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,873.85652
Policy Entropy: 2.06261
Value Function Loss: 0.02510

Mean KL Divergence: 0.01248
SB3 Clip Fraction: 0.10172
Policy Update Magnitude: 0.31548
Value Function Update Magnitude: 0.36143

Collected Steps per Second: 20,718.49395
Overall Steps per Second: 10,174.99209

Timestep Collection Time: 2.41533
Timestep Consumption Time: 2.50281
PPO Batch Consumption Time: 0.29424
Total Iteration Time: 4.91814

Cumulative Model Updates: 229,106
Cumulative Timesteps: 1,911,415,748

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,574.02816
Policy Entropy: 2.07668
Value Function Loss: 0.02432

Mean KL Divergence: 0.01349
SB3 Clip Fraction: 0.10337
Policy Update Magnitude: 0.32044
Value Function Update Magnitude: 0.38017

Collected Steps per Second: 21,314.04601
Overall Steps per Second: 10,478.97536

Timestep Collection Time: 2.34672
Timestep Consumption Time: 2.42646
PPO Batch Consumption Time: 0.27894
Total Iteration Time: 4.77318

Cumulative Model Updates: 229,112
Cumulative Timesteps: 1,911,465,766

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1911465766...
Checkpoint 1911465766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,430.73665
Policy Entropy: 2.08748
Value Function Loss: 0.02237

Mean KL Divergence: 0.01151
SB3 Clip Fraction: 0.09303
Policy Update Magnitude: 0.31423
Value Function Update Magnitude: 0.36602

Collected Steps per Second: 21,155.92692
Overall Steps per Second: 10,309.26220

Timestep Collection Time: 2.36369
Timestep Consumption Time: 2.48690
PPO Batch Consumption Time: 0.29405
Total Iteration Time: 4.85059

Cumulative Model Updates: 229,118
Cumulative Timesteps: 1,911,515,772

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48,832.23772
Policy Entropy: 2.08251
Value Function Loss: 0.02047

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.08471
Policy Update Magnitude: 0.30404
Value Function Update Magnitude: 0.33650

Collected Steps per Second: 21,936.61586
Overall Steps per Second: 10,338.49891

Timestep Collection Time: 2.27975
Timestep Consumption Time: 2.55751
PPO Batch Consumption Time: 0.28982
Total Iteration Time: 4.83726

Cumulative Model Updates: 229,124
Cumulative Timesteps: 1,911,565,782

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1911565782...
Checkpoint 1911565782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 60,294.29290
Policy Entropy: 2.07549
Value Function Loss: 0.02000

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.07935
Policy Update Magnitude: 0.29825
Value Function Update Magnitude: 0.31157

Collected Steps per Second: 21,881.68106
Overall Steps per Second: 10,536.48139

Timestep Collection Time: 2.28556
Timestep Consumption Time: 2.46099
PPO Batch Consumption Time: 0.28039
Total Iteration Time: 4.74656

Cumulative Model Updates: 229,130
Cumulative Timesteps: 1,911,615,794

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47,244.45842
Policy Entropy: 2.06606
Value Function Loss: 0.01782

Mean KL Divergence: 0.00783
SB3 Clip Fraction: 0.07254
Policy Update Magnitude: 0.28864
Value Function Update Magnitude: 0.29065

Collected Steps per Second: 21,425.81263
Overall Steps per Second: 10,442.22114

Timestep Collection Time: 2.33513
Timestep Consumption Time: 2.45619
PPO Batch Consumption Time: 0.28452
Total Iteration Time: 4.79132

Cumulative Model Updates: 229,136
Cumulative Timesteps: 1,911,665,826

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1911665826...
Checkpoint 1911665826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,283.81837
Policy Entropy: 2.06503
Value Function Loss: 0.01871

Mean KL Divergence: 0.00740
SB3 Clip Fraction: 0.06955
Policy Update Magnitude: 0.29213
Value Function Update Magnitude: 0.27815

Collected Steps per Second: 21,555.61530
Overall Steps per Second: 10,335.46287

Timestep Collection Time: 2.31958
Timestep Consumption Time: 2.51813
PPO Batch Consumption Time: 0.29474
Total Iteration Time: 4.83771

Cumulative Model Updates: 229,142
Cumulative Timesteps: 1,911,715,826

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50,023.48854
Policy Entropy: 2.07671
Value Function Loss: 0.01780

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.07181
Policy Update Magnitude: 0.28805
Value Function Update Magnitude: 0.26747

Collected Steps per Second: 21,878.76776
Overall Steps per Second: 10,408.34229

Timestep Collection Time: 2.28559
Timestep Consumption Time: 2.51882
PPO Batch Consumption Time: 0.29018
Total Iteration Time: 4.80442

Cumulative Model Updates: 229,148
Cumulative Timesteps: 1,911,765,832

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1911765832...
Checkpoint 1911765832 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,865.80475
Policy Entropy: 2.09601
Value Function Loss: 0.02185

Mean KL Divergence: 0.00782
SB3 Clip Fraction: 0.07087
Policy Update Magnitude: 0.29679
Value Function Update Magnitude: 0.24626

Collected Steps per Second: 21,508.37462
Overall Steps per Second: 10,316.17435

Timestep Collection Time: 2.32607
Timestep Consumption Time: 2.52360
PPO Batch Consumption Time: 0.29421
Total Iteration Time: 4.84967

Cumulative Model Updates: 229,154
Cumulative Timesteps: 1,911,815,862

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,021.97316
Policy Entropy: 2.08784
Value Function Loss: 0.02021

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.07409
Policy Update Magnitude: 0.30162
Value Function Update Magnitude: 0.24811

Collected Steps per Second: 21,999.55381
Overall Steps per Second: 10,431.91869

Timestep Collection Time: 2.27305
Timestep Consumption Time: 2.52051
PPO Batch Consumption Time: 0.29379
Total Iteration Time: 4.79356

Cumulative Model Updates: 229,160
Cumulative Timesteps: 1,911,865,868

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1911865868...
Checkpoint 1911865868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,519.48909
Policy Entropy: 2.07334
Value Function Loss: 0.02313

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.07974
Policy Update Magnitude: 0.29942
Value Function Update Magnitude: 0.24070

Collected Steps per Second: 21,912.35863
Overall Steps per Second: 10,575.41189

Timestep Collection Time: 2.28264
Timestep Consumption Time: 2.44701
PPO Batch Consumption Time: 0.27993
Total Iteration Time: 4.72965

Cumulative Model Updates: 229,166
Cumulative Timesteps: 1,911,915,886

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,335.35013
Policy Entropy: 2.05956
Value Function Loss: 0.01946

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.08122
Policy Update Magnitude: 0.29808
Value Function Update Magnitude: 0.27489

Collected Steps per Second: 21,281.89747
Overall Steps per Second: 10,408.45495

Timestep Collection Time: 2.34970
Timestep Consumption Time: 2.45467
PPO Batch Consumption Time: 0.28033
Total Iteration Time: 4.80436

Cumulative Model Updates: 229,172
Cumulative Timesteps: 1,911,965,892

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1911965892...
Checkpoint 1911965892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,292.53476
Policy Entropy: 2.02952
Value Function Loss: 0.01881

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.08229
Policy Update Magnitude: 0.29228
Value Function Update Magnitude: 0.28101

Collected Steps per Second: 20,969.74836
Overall Steps per Second: 10,254.88530

Timestep Collection Time: 2.38525
Timestep Consumption Time: 2.49223
PPO Batch Consumption Time: 0.28812
Total Iteration Time: 4.87748

Cumulative Model Updates: 229,178
Cumulative Timesteps: 1,912,015,910

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,078.92367
Policy Entropy: 2.03401
Value Function Loss: 0.02078

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.07501
Policy Update Magnitude: 0.30055
Value Function Update Magnitude: 0.28265

Collected Steps per Second: 21,135.07024
Overall Steps per Second: 10,362.05195

Timestep Collection Time: 2.36649
Timestep Consumption Time: 2.46035
PPO Batch Consumption Time: 0.28009
Total Iteration Time: 4.82684

Cumulative Model Updates: 229,184
Cumulative Timesteps: 1,912,065,926

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1912065926...
Checkpoint 1912065926 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48,303.14311
Policy Entropy: 2.04816
Value Function Loss: 0.02351

Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.07208
Policy Update Magnitude: 0.31466
Value Function Update Magnitude: 0.31968

Collected Steps per Second: 21,191.49727
Overall Steps per Second: 10,303.48399

Timestep Collection Time: 2.36057
Timestep Consumption Time: 2.49449
PPO Batch Consumption Time: 0.29013
Total Iteration Time: 4.85506

Cumulative Model Updates: 229,190
Cumulative Timesteps: 1,912,115,950

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 72,338.10562
Policy Entropy: 2.07114
Value Function Loss: 0.02517

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.08184
Policy Update Magnitude: 0.31803
Value Function Update Magnitude: 0.34654

Collected Steps per Second: 21,538.21502
Overall Steps per Second: 10,404.88621

Timestep Collection Time: 2.32155
Timestep Consumption Time: 2.48408
PPO Batch Consumption Time: 0.28674
Total Iteration Time: 4.80563

Cumulative Model Updates: 229,196
Cumulative Timesteps: 1,912,165,952

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1912165952...
Checkpoint 1912165952 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 81,813.82345
Policy Entropy: 2.06869
Value Function Loss: 0.02359

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.08413
Policy Update Magnitude: 0.31839
Value Function Update Magnitude: 0.35307

Collected Steps per Second: 21,852.35944
Overall Steps per Second: 10,365.21500

Timestep Collection Time: 2.28909
Timestep Consumption Time: 2.53686
PPO Batch Consumption Time: 0.29214
Total Iteration Time: 4.82595

Cumulative Model Updates: 229,202
Cumulative Timesteps: 1,912,215,974

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 103,398.39004
Policy Entropy: 2.06754
Value Function Loss: 0.02196

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.08781
Policy Update Magnitude: 0.31354
Value Function Update Magnitude: 0.36577

Collected Steps per Second: 22,247.01128
Overall Steps per Second: 10,531.10648

Timestep Collection Time: 2.24893
Timestep Consumption Time: 2.50195
PPO Batch Consumption Time: 0.28941
Total Iteration Time: 4.75088

Cumulative Model Updates: 229,208
Cumulative Timesteps: 1,912,266,006

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1912266006...
Checkpoint 1912266006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,374.48481
Policy Entropy: 2.09199
Value Function Loss: 0.02137

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.07987
Policy Update Magnitude: 0.31361
Value Function Update Magnitude: 0.37036

Collected Steps per Second: 21,721.54701
Overall Steps per Second: 10,344.47905

Timestep Collection Time: 2.30306
Timestep Consumption Time: 2.53295
PPO Batch Consumption Time: 0.29779
Total Iteration Time: 4.83601

Cumulative Model Updates: 229,214
Cumulative Timesteps: 1,912,316,032

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,656.95617
Policy Entropy: 2.09741
Value Function Loss: 0.02200

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.07455
Policy Update Magnitude: 0.31074
Value Function Update Magnitude: 0.36085

Collected Steps per Second: 21,536.70202
Overall Steps per Second: 10,499.88322

Timestep Collection Time: 2.32301
Timestep Consumption Time: 2.44180
PPO Batch Consumption Time: 0.28078
Total Iteration Time: 4.76481

Cumulative Model Updates: 229,220
Cumulative Timesteps: 1,912,366,062

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1912366062...
Checkpoint 1912366062 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,769.86910
Policy Entropy: 2.08370
Value Function Loss: 0.02227

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.07236
Policy Update Magnitude: 0.31227
Value Function Update Magnitude: 0.35340

Collected Steps per Second: 21,801.72306
Overall Steps per Second: 10,430.12939

Timestep Collection Time: 2.29413
Timestep Consumption Time: 2.50121
PPO Batch Consumption Time: 0.29066
Total Iteration Time: 4.79534

Cumulative Model Updates: 229,226
Cumulative Timesteps: 1,912,416,078

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,325.88378
Policy Entropy: 2.08138
Value Function Loss: 0.02024

Mean KL Divergence: 0.00764
SB3 Clip Fraction: 0.07151
Policy Update Magnitude: 0.30838
Value Function Update Magnitude: 0.33485

Collected Steps per Second: 21,759.67161
Overall Steps per Second: 10,744.74446

Timestep Collection Time: 2.29856
Timestep Consumption Time: 2.35636
PPO Batch Consumption Time: 0.27941
Total Iteration Time: 4.65493

Cumulative Model Updates: 229,232
Cumulative Timesteps: 1,912,466,094

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1912466094...
Checkpoint 1912466094 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,607.67972
Policy Entropy: 2.07122
Value Function Loss: 0.01893

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.07253
Policy Update Magnitude: 0.29992
Value Function Update Magnitude: 0.32030

Collected Steps per Second: 21,216.42265
Overall Steps per Second: 10,614.90015

Timestep Collection Time: 2.35798
Timestep Consumption Time: 2.35501
PPO Batch Consumption Time: 0.27928
Total Iteration Time: 4.71300

Cumulative Model Updates: 229,238
Cumulative Timesteps: 1,912,516,122

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,972.00168
Policy Entropy: 2.08733
Value Function Loss: 0.02047

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.07791
Policy Update Magnitude: 0.30172
Value Function Update Magnitude: 0.28440

Collected Steps per Second: 20,821.46158
Overall Steps per Second: 10,519.56519

Timestep Collection Time: 2.40329
Timestep Consumption Time: 2.35356
PPO Batch Consumption Time: 0.27866
Total Iteration Time: 4.75685

Cumulative Model Updates: 229,244
Cumulative Timesteps: 1,912,566,162

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1912566162...
Checkpoint 1912566162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43,938.34470
Policy Entropy: 2.07603
Value Function Loss: 0.02260

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.08674
Policy Update Magnitude: 0.30322
Value Function Update Magnitude: 0.25863

Collected Steps per Second: 20,604.94674
Overall Steps per Second: 10,329.27848

Timestep Collection Time: 2.42757
Timestep Consumption Time: 2.41497
PPO Batch Consumption Time: 0.29077
Total Iteration Time: 4.84255

Cumulative Model Updates: 229,250
Cumulative Timesteps: 1,912,616,182

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45,216.24225
Policy Entropy: 2.08483
Value Function Loss: 0.02223

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.09269
Policy Update Magnitude: 0.29983
Value Function Update Magnitude: 0.29191

Collected Steps per Second: 21,057.15665
Overall Steps per Second: 10,282.93024

Timestep Collection Time: 2.37553
Timestep Consumption Time: 2.48903
PPO Batch Consumption Time: 0.29108
Total Iteration Time: 4.86457

Cumulative Model Updates: 229,256
Cumulative Timesteps: 1,912,666,204

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1912666204...
Checkpoint 1912666204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,639.66538
Policy Entropy: 2.08888
Value Function Loss: 0.02128

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.08659
Policy Update Magnitude: 0.29959
Value Function Update Magnitude: 0.31362

Collected Steps per Second: 21,200.72896
Overall Steps per Second: 10,310.91658

Timestep Collection Time: 2.36030
Timestep Consumption Time: 2.49281
PPO Batch Consumption Time: 0.29339
Total Iteration Time: 4.85311

Cumulative Model Updates: 229,262
Cumulative Timesteps: 1,912,716,244

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,456.45756
Policy Entropy: 2.09617
Value Function Loss: 0.02089

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.09041
Policy Update Magnitude: 0.29475
Value Function Update Magnitude: 0.29975

Collected Steps per Second: 21,958.65554
Overall Steps per Second: 10,423.01753

Timestep Collection Time: 2.27810
Timestep Consumption Time: 2.52128
PPO Batch Consumption Time: 0.29401
Total Iteration Time: 4.79938

Cumulative Model Updates: 229,268
Cumulative Timesteps: 1,912,766,268

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1912766268...
Checkpoint 1912766268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,978.34628
Policy Entropy: 2.09077
Value Function Loss: 0.02427

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.08446
Policy Update Magnitude: 0.30791
Value Function Update Magnitude: 0.28828

Collected Steps per Second: 21,659.04172
Overall Steps per Second: 10,485.99519

Timestep Collection Time: 2.30961
Timestep Consumption Time: 2.46094
PPO Batch Consumption Time: 0.27945
Total Iteration Time: 4.77055

Cumulative Model Updates: 229,274
Cumulative Timesteps: 1,912,816,292

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52,227.74736
Policy Entropy: 2.09494
Value Function Loss: 0.02686

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.08133
Policy Update Magnitude: 0.31493
Value Function Update Magnitude: 0.34812

Collected Steps per Second: 21,936.82659
Overall Steps per Second: 10,497.08934

Timestep Collection Time: 2.27973
Timestep Consumption Time: 2.48445
PPO Batch Consumption Time: 0.28683
Total Iteration Time: 4.76418

Cumulative Model Updates: 229,280
Cumulative Timesteps: 1,912,866,302

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1912866302...
Checkpoint 1912866302 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55,526.92272
Policy Entropy: 2.07560
Value Function Loss: 0.02561

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.08146
Policy Update Magnitude: 0.31708
Value Function Update Magnitude: 0.37817

Collected Steps per Second: 21,668.97331
Overall Steps per Second: 10,388.00631

Timestep Collection Time: 2.30985
Timestep Consumption Time: 2.50840
PPO Batch Consumption Time: 0.29246
Total Iteration Time: 4.81825

Cumulative Model Updates: 229,286
Cumulative Timesteps: 1,912,916,354

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,632.49124
Policy Entropy: 2.07498
Value Function Loss: 0.02928

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.07826
Policy Update Magnitude: 0.31901
Value Function Update Magnitude: 0.34714

Collected Steps per Second: 21,612.87296
Overall Steps per Second: 10,285.10038

Timestep Collection Time: 2.31399
Timestep Consumption Time: 2.54858
PPO Batch Consumption Time: 0.30226
Total Iteration Time: 4.86257

Cumulative Model Updates: 229,292
Cumulative Timesteps: 1,912,966,366

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1912966366...
Checkpoint 1912966366 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,971.83634
Policy Entropy: 2.07133
Value Function Loss: 0.02841

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.08196
Policy Update Magnitude: 0.32863
Value Function Update Magnitude: 0.38640

Collected Steps per Second: 21,426.90471
Overall Steps per Second: 10,303.16260

Timestep Collection Time: 2.33435
Timestep Consumption Time: 2.52027
PPO Batch Consumption Time: 0.29396
Total Iteration Time: 4.85463

Cumulative Model Updates: 229,298
Cumulative Timesteps: 1,913,016,384

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,267.83330
Policy Entropy: 2.08696
Value Function Loss: 0.02648

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.08021
Policy Update Magnitude: 0.32562
Value Function Update Magnitude: 0.40759

Collected Steps per Second: 21,753.54077
Overall Steps per Second: 10,376.30144

Timestep Collection Time: 2.30013
Timestep Consumption Time: 2.52201
PPO Batch Consumption Time: 0.29410
Total Iteration Time: 4.82214

Cumulative Model Updates: 229,304
Cumulative Timesteps: 1,913,066,420

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1913066420...
Checkpoint 1913066420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,990.69529
Policy Entropy: 2.09304
Value Function Loss: 0.02412

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.07576
Policy Update Magnitude: 0.32537
Value Function Update Magnitude: 0.35164

Collected Steps per Second: 21,602.65367
Overall Steps per Second: 10,564.11482

Timestep Collection Time: 2.31583
Timestep Consumption Time: 2.41983
PPO Batch Consumption Time: 0.27956
Total Iteration Time: 4.73565

Cumulative Model Updates: 229,310
Cumulative Timesteps: 1,913,116,448

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,630.40183
Policy Entropy: 2.08578
Value Function Loss: 0.02290

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.07988
Policy Update Magnitude: 0.31749
Value Function Update Magnitude: 0.27187

Collected Steps per Second: 21,398.97990
Overall Steps per Second: 10,450.79962

Timestep Collection Time: 2.33899
Timestep Consumption Time: 2.45031
PPO Batch Consumption Time: 0.27997
Total Iteration Time: 4.78930

Cumulative Model Updates: 229,316
Cumulative Timesteps: 1,913,166,500

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


Saving checkpoint 1913166500...
Checkpoint 1913166500 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,485.23728
Policy Entropy: 2.08001
Value Function Loss: 0.02273

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.07924
Policy Update Magnitude: 0.30569
Value Function Update Magnitude: 0.23004

Collected Steps per Second: 21,019.29682
Overall Steps per Second: 10,267.06793

Timestep Collection Time: 2.38000
Timestep Consumption Time: 2.49247
PPO Batch Consumption Time: 0.28945
Total Iteration Time: 4.87247

Cumulative Model Updates: 229,322
Cumulative Timesteps: 1,913,216,526

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,524.89087
Policy Entropy: 2.07323
Value Function Loss: 0.02200

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.08088
Policy Update Magnitude: 0.30819
Value Function Update Magnitude: 0.21789

Collected Steps per Second: 20,890.59652
Overall Steps per Second: 10,535.53967

Timestep Collection Time: 2.39352
Timestep Consumption Time: 2.35251
PPO Batch Consumption Time: 0.27762
Total Iteration Time: 4.74603

Cumulative Model Updates: 229,328
Cumulative Timesteps: 1,913,266,528

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1913266528...
Checkpoint 1913266528 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,805.96848
Policy Entropy: 2.07960
Value Function Loss: 0.01995

Mean KL Divergence: 0.01332
SB3 Clip Fraction: 0.10537
Policy Update Magnitude: 0.29672
Value Function Update Magnitude: 0.24293

Collected Steps per Second: 20,775.72052
Overall Steps per Second: 10,499.71381

Timestep Collection Time: 2.40694
Timestep Consumption Time: 2.35566
PPO Batch Consumption Time: 0.27945
Total Iteration Time: 4.76261

Cumulative Model Updates: 229,334
Cumulative Timesteps: 1,913,316,534

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,029.24435
Policy Entropy: 2.07762
Value Function Loss: 0.02509

Mean KL Divergence: 0.01299
SB3 Clip Fraction: 0.10252
Policy Update Magnitude: 0.30737
Value Function Update Magnitude: 0.31909

Collected Steps per Second: 20,920.03307
Overall Steps per Second: 10,494.82020

Timestep Collection Time: 2.39082
Timestep Consumption Time: 2.37496
PPO Batch Consumption Time: 0.27997
Total Iteration Time: 4.76578

Cumulative Model Updates: 229,340
Cumulative Timesteps: 1,913,366,550

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1913366550...
Checkpoint 1913366550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43,811.62556
Policy Entropy: 2.07797
Value Function Loss: 0.02485

Mean KL Divergence: 0.01112
SB3 Clip Fraction: 0.09283
Policy Update Magnitude: 0.32267
Value Function Update Magnitude: 0.41301

Collected Steps per Second: 21,018.41055
Overall Steps per Second: 10,342.67319

Timestep Collection Time: 2.37896
Timestep Consumption Time: 2.45557
PPO Batch Consumption Time: 0.29288
Total Iteration Time: 4.83453

Cumulative Model Updates: 229,346
Cumulative Timesteps: 1,913,416,552

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,565.11636
Policy Entropy: 2.07825
Value Function Loss: 0.02636

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.08375
Policy Update Magnitude: 0.32697
Value Function Update Magnitude: 0.45031

Collected Steps per Second: 21,683.49493
Overall Steps per Second: 10,435.17148

Timestep Collection Time: 2.30682
Timestep Consumption Time: 2.48658
PPO Batch Consumption Time: 0.29245
Total Iteration Time: 4.79340

Cumulative Model Updates: 229,352
Cumulative Timesteps: 1,913,466,572

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1913466572...
Checkpoint 1913466572 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,998.32158
Policy Entropy: 2.07495
Value Function Loss: 0.02308

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.08041
Policy Update Magnitude: 0.32644
Value Function Update Magnitude: 0.41148

Collected Steps per Second: 21,510.99729
Overall Steps per Second: 10,561.09317

Timestep Collection Time: 2.32579
Timestep Consumption Time: 2.41141
PPO Batch Consumption Time: 0.27906
Total Iteration Time: 4.73720

Cumulative Model Updates: 229,358
Cumulative Timesteps: 1,913,516,602

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,026.94669
Policy Entropy: 2.06765
Value Function Loss: 0.02341

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.07666
Policy Update Magnitude: 0.31679
Value Function Update Magnitude: 0.37669

Collected Steps per Second: 21,990.22621
Overall Steps per Second: 10,494.67788

Timestep Collection Time: 2.27556
Timestep Consumption Time: 2.49257
PPO Batch Consumption Time: 0.29436
Total Iteration Time: 4.76813

Cumulative Model Updates: 229,364
Cumulative Timesteps: 1,913,566,642

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1913566642...
Checkpoint 1913566642 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,062.05426
Policy Entropy: 2.07785
Value Function Loss: 0.02015

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.07653
Policy Update Magnitude: 0.30365
Value Function Update Magnitude: 0.33256

Collected Steps per Second: 21,706.25352
Overall Steps per Second: 10,453.64357

Timestep Collection Time: 2.30431
Timestep Consumption Time: 2.48043
PPO Batch Consumption Time: 0.28833
Total Iteration Time: 4.78474

Cumulative Model Updates: 229,370
Cumulative Timesteps: 1,913,616,660

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,276.61994
Policy Entropy: 2.07236
Value Function Loss: 0.01977

Mean KL Divergence: 0.00707
SB3 Clip Fraction: 0.06820
Policy Update Magnitude: 0.29397
Value Function Update Magnitude: 0.28137

Collected Steps per Second: 21,771.75381
Overall Steps per Second: 10,540.00939

Timestep Collection Time: 2.29830
Timestep Consumption Time: 2.44914
PPO Batch Consumption Time: 0.27964
Total Iteration Time: 4.74743

Cumulative Model Updates: 229,376
Cumulative Timesteps: 1,913,666,698

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1913666698...
Checkpoint 1913666698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,870.36665
Policy Entropy: 2.06230
Value Function Loss: 0.01928

Mean KL Divergence: 0.00733
SB3 Clip Fraction: 0.06916
Policy Update Magnitude: 0.29898
Value Function Update Magnitude: 0.25415

Collected Steps per Second: 21,485.18558
Overall Steps per Second: 10,327.69403

Timestep Collection Time: 2.32737
Timestep Consumption Time: 2.51437
PPO Batch Consumption Time: 0.29462
Total Iteration Time: 4.84174

Cumulative Model Updates: 229,382
Cumulative Timesteps: 1,913,716,702

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,205.40863
Policy Entropy: 2.05940
Value Function Loss: 0.02164

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.07168
Policy Update Magnitude: 0.30246
Value Function Update Magnitude: 0.27871

Collected Steps per Second: 21,707.50519
Overall Steps per Second: 10,382.98459

Timestep Collection Time: 2.30436
Timestep Consumption Time: 2.51333
PPO Batch Consumption Time: 0.29159
Total Iteration Time: 4.81769

Cumulative Model Updates: 229,388
Cumulative Timesteps: 1,913,766,724

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1913766724...
Checkpoint 1913766724 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 52,809.22805
Policy Entropy: 2.06573
Value Function Loss: 0.02249

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.07360
Policy Update Magnitude: 0.30514
Value Function Update Magnitude: 0.33472

Collected Steps per Second: 21,396.94648
Overall Steps per Second: 10,338.34414

Timestep Collection Time: 2.33688
Timestep Consumption Time: 2.49968
PPO Batch Consumption Time: 0.29316
Total Iteration Time: 4.83656

Cumulative Model Updates: 229,394
Cumulative Timesteps: 1,913,816,726

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53,674.65834
Policy Entropy: 2.07044
Value Function Loss: 0.02049

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.07351
Policy Update Magnitude: 0.30008
Value Function Update Magnitude: 0.32900

Collected Steps per Second: 20,382.62226
Overall Steps per Second: 10,010.30973

Timestep Collection Time: 2.45376
Timestep Consumption Time: 2.54249
PPO Batch Consumption Time: 0.29478
Total Iteration Time: 4.99625

Cumulative Model Updates: 229,400
Cumulative Timesteps: 1,913,866,740

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1913866740...
Checkpoint 1913866740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 101,288.47982
Policy Entropy: 2.06315
Value Function Loss: 0.02010

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.07689
Policy Update Magnitude: 0.31475
Value Function Update Magnitude: 0.29757

Collected Steps per Second: 21,196.43703
Overall Steps per Second: 10,304.49033

Timestep Collection Time: 2.35955
Timestep Consumption Time: 2.49406
PPO Batch Consumption Time: 0.29017
Total Iteration Time: 4.85361

Cumulative Model Updates: 229,406
Cumulative Timesteps: 1,913,916,754

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48,450.39380
Policy Entropy: 2.06440
Value Function Loss: 0.02054

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.08388
Policy Update Magnitude: 0.31382
Value Function Update Magnitude: 0.29418

Collected Steps per Second: 22,140.91931
Overall Steps per Second: 10,600.71480

Timestep Collection Time: 2.25871
Timestep Consumption Time: 2.45889
PPO Batch Consumption Time: 0.27945
Total Iteration Time: 4.71761

Cumulative Model Updates: 229,412
Cumulative Timesteps: 1,913,966,764

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1913966764...
Checkpoint 1913966764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46,871.45651
Policy Entropy: 2.07179
Value Function Loss: 0.02653

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.08512
Policy Update Magnitude: 0.32661
Value Function Update Magnitude: 0.31300

Collected Steps per Second: 21,573.00750
Overall Steps per Second: 10,350.06917

Timestep Collection Time: 2.31827
Timestep Consumption Time: 2.51378
PPO Batch Consumption Time: 0.29400
Total Iteration Time: 4.83205

Cumulative Model Updates: 229,418
Cumulative Timesteps: 1,914,016,776

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,524.02579
Policy Entropy: 2.07678
Value Function Loss: 0.02523

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.08300
Policy Update Magnitude: 0.32591
Value Function Update Magnitude: 0.35935

Collected Steps per Second: 22,049.18980
Overall Steps per Second: 10,495.64887

Timestep Collection Time: 2.26884
Timestep Consumption Time: 2.49752
PPO Batch Consumption Time: 0.29305
Total Iteration Time: 4.76636

Cumulative Model Updates: 229,424
Cumulative Timesteps: 1,914,066,802

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1914066802...
Checkpoint 1914066802 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,103.41791
Policy Entropy: 2.05847
Value Function Loss: 0.02560

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.08145
Policy Update Magnitude: 0.32369
Value Function Update Magnitude: 0.39040

Collected Steps per Second: 21,096.96722
Overall Steps per Second: 10,585.62102

Timestep Collection Time: 2.37096
Timestep Consumption Time: 2.35432
PPO Batch Consumption Time: 0.27912
Total Iteration Time: 4.72528

Cumulative Model Updates: 229,430
Cumulative Timesteps: 1,914,116,822

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63,184.11512
Policy Entropy: 2.06693
Value Function Loss: 0.02042

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.07898
Policy Update Magnitude: 0.31268
Value Function Update Magnitude: 0.37066

Collected Steps per Second: 21,506.35480
Overall Steps per Second: 10,476.61014

Timestep Collection Time: 2.32536
Timestep Consumption Time: 2.44813
PPO Batch Consumption Time: 0.29357
Total Iteration Time: 4.77349

Cumulative Model Updates: 229,436
Cumulative Timesteps: 1,914,166,832

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1914166832...
Checkpoint 1914166832 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 70,067.43218
Policy Entropy: 2.06671
Value Function Loss: 0.01893

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.07134
Policy Update Magnitude: 0.29833
Value Function Update Magnitude: 0.30610

Collected Steps per Second: 21,192.68982
Overall Steps per Second: 10,501.95553

Timestep Collection Time: 2.36100
Timestep Consumption Time: 2.40344
PPO Batch Consumption Time: 0.27928
Total Iteration Time: 4.76445

Cumulative Model Updates: 229,442
Cumulative Timesteps: 1,914,216,868

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46,526.80563
Policy Entropy: 2.07478
Value Function Loss: 0.01913

Mean KL Divergence: 0.00708
SB3 Clip Fraction: 0.06705
Policy Update Magnitude: 0.29301
Value Function Update Magnitude: 0.23907

Collected Steps per Second: 21,456.62762
Overall Steps per Second: 10,477.08331

Timestep Collection Time: 2.33093
Timestep Consumption Time: 2.44272
PPO Batch Consumption Time: 0.28757
Total Iteration Time: 4.77366

Cumulative Model Updates: 229,448
Cumulative Timesteps: 1,914,266,882

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1914266882...
Checkpoint 1914266882 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,880.69020
Policy Entropy: 2.05355
Value Function Loss: 0.02198

Mean KL Divergence: 0.00704
SB3 Clip Fraction: 0.06437
Policy Update Magnitude: 0.29975
Value Function Update Magnitude: 0.22369

Collected Steps per Second: 20,866.54123
Overall Steps per Second: 10,261.51837

Timestep Collection Time: 2.39752
Timestep Consumption Time: 2.47778
PPO Batch Consumption Time: 0.29100
Total Iteration Time: 4.87530

Cumulative Model Updates: 229,454
Cumulative Timesteps: 1,914,316,910

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50,883.11546
Policy Entropy: 2.07750
Value Function Loss: 0.02447

Mean KL Divergence: 0.00748
SB3 Clip Fraction: 0.06487
Policy Update Magnitude: 0.30771
Value Function Update Magnitude: 0.22612

Collected Steps per Second: 20,689.75470
Overall Steps per Second: 10,370.53865

Timestep Collection Time: 2.41820
Timestep Consumption Time: 2.40623
PPO Batch Consumption Time: 0.27971
Total Iteration Time: 4.82444

Cumulative Model Updates: 229,460
Cumulative Timesteps: 1,914,366,942

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1914366942...
Checkpoint 1914366942 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,575.65740
Policy Entropy: 2.07898
Value Function Loss: 0.02618

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.06947
Policy Update Magnitude: 0.30990
Value Function Update Magnitude: 0.22639

Collected Steps per Second: 21,228.16522
Overall Steps per Second: 10,270.50586

Timestep Collection Time: 2.35630
Timestep Consumption Time: 2.51395
PPO Batch Consumption Time: 0.29091
Total Iteration Time: 4.87026

Cumulative Model Updates: 229,466
Cumulative Timesteps: 1,914,416,962

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50,857.34947
Policy Entropy: 2.09167
Value Function Loss: 0.02543

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.07079
Policy Update Magnitude: 0.31259
Value Function Update Magnitude: 0.27075

Collected Steps per Second: 21,574.37370
Overall Steps per Second: 10,512.59295

Timestep Collection Time: 2.31831
Timestep Consumption Time: 2.43942
PPO Batch Consumption Time: 0.27801
Total Iteration Time: 4.75772

Cumulative Model Updates: 229,472
Cumulative Timesteps: 1,914,466,978

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1914466978...
Checkpoint 1914466978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,119.26337
Policy Entropy: 2.08739
Value Function Loss: 0.02730

Mean KL Divergence: 0.00772
SB3 Clip Fraction: 0.07357
Policy Update Magnitude: 0.31590
Value Function Update Magnitude: 0.25007

Collected Steps per Second: 21,370.57005
Overall Steps per Second: 10,308.37750

Timestep Collection Time: 2.34163
Timestep Consumption Time: 2.51287
PPO Batch Consumption Time: 0.29132
Total Iteration Time: 4.85450

Cumulative Model Updates: 229,478
Cumulative Timesteps: 1,914,517,020

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,564.76819
Policy Entropy: 2.07587
Value Function Loss: 0.02276

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.07694
Policy Update Magnitude: 0.31254
Value Function Update Magnitude: 0.29890

Collected Steps per Second: 21,575.74275
Overall Steps per Second: 10,281.74730

Timestep Collection Time: 2.31807
Timestep Consumption Time: 2.54628
PPO Batch Consumption Time: 0.28742
Total Iteration Time: 4.86435

Cumulative Model Updates: 229,484
Cumulative Timesteps: 1,914,567,034

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1914567034...
Checkpoint 1914567034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,198.41156
Policy Entropy: 2.08592
Value Function Loss: 0.02537

Mean KL Divergence: 0.00770
SB3 Clip Fraction: 0.07184
Policy Update Magnitude: 0.31112
Value Function Update Magnitude: 0.34232

Collected Steps per Second: 21,641.04774
Overall Steps per Second: 10,331.49336

Timestep Collection Time: 2.31107
Timestep Consumption Time: 2.52986
PPO Batch Consumption Time: 0.29333
Total Iteration Time: 4.84093

Cumulative Model Updates: 229,490
Cumulative Timesteps: 1,914,617,048

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,731.26604
Policy Entropy: 2.07780
Value Function Loss: 0.02572

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.07403
Policy Update Magnitude: 0.32070
Value Function Update Magnitude: 0.31701

Collected Steps per Second: 21,899.95789
Overall Steps per Second: 10,419.44014

Timestep Collection Time: 2.28494
Timestep Consumption Time: 2.51763
PPO Batch Consumption Time: 0.29251
Total Iteration Time: 4.80256

Cumulative Model Updates: 229,496
Cumulative Timesteps: 1,914,667,088

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1914667088...
Checkpoint 1914667088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,195.23816
Policy Entropy: 2.09443
Value Function Loss: 0.02600

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.08322
Policy Update Magnitude: 0.31496
Value Function Update Magnitude: 0.26094

Collected Steps per Second: 21,716.49191
Overall Steps per Second: 10,529.26046

Timestep Collection Time: 2.30359
Timestep Consumption Time: 2.44755
PPO Batch Consumption Time: 0.28044
Total Iteration Time: 4.75114

Cumulative Model Updates: 229,502
Cumulative Timesteps: 1,914,717,114

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,190.99946
Policy Entropy: 2.06968
Value Function Loss: 0.02116

Mean KL Divergence: 0.00743
SB3 Clip Fraction: 0.06821
Policy Update Magnitude: 0.30290
Value Function Update Magnitude: 0.28043

Collected Steps per Second: 21,641.34961
Overall Steps per Second: 10,474.47205

Timestep Collection Time: 2.31067
Timestep Consumption Time: 2.46341
PPO Batch Consumption Time: 0.28037
Total Iteration Time: 4.77408

Cumulative Model Updates: 229,508
Cumulative Timesteps: 1,914,767,120

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1914767120...
Checkpoint 1914767120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 60,078.28640
Policy Entropy: 2.06288
Value Function Loss: 0.01926

Mean KL Divergence: 0.00724
SB3 Clip Fraction: 0.06652
Policy Update Magnitude: 0.29851
Value Function Update Magnitude: 0.32677

Collected Steps per Second: 21,418.39615
Overall Steps per Second: 10,344.40228

Timestep Collection Time: 2.33500
Timestep Consumption Time: 2.49969
PPO Batch Consumption Time: 0.29240
Total Iteration Time: 4.83469

Cumulative Model Updates: 229,514
Cumulative Timesteps: 1,914,817,132

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,914.21236
Policy Entropy: 2.05880
Value Function Loss: 0.01875

Mean KL Divergence: 0.00777
SB3 Clip Fraction: 0.06854
Policy Update Magnitude: 0.29556
Value Function Update Magnitude: 0.31034

Collected Steps per Second: 21,973.97121
Overall Steps per Second: 10,474.15823

Timestep Collection Time: 2.27660
Timestep Consumption Time: 2.49953
PPO Batch Consumption Time: 0.29216
Total Iteration Time: 4.77614

Cumulative Model Updates: 229,520
Cumulative Timesteps: 1,914,867,158

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1914867158...
Checkpoint 1914867158 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,370.33551
Policy Entropy: 2.07275
Value Function Loss: 0.01900

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.07037
Policy Update Magnitude: 0.29716
Value Function Update Magnitude: 0.30529

Collected Steps per Second: 21,655.72123
Overall Steps per Second: 10,334.05652

Timestep Collection Time: 2.30923
Timestep Consumption Time: 2.52992
PPO Batch Consumption Time: 0.29652
Total Iteration Time: 4.83915

Cumulative Model Updates: 229,526
Cumulative Timesteps: 1,914,917,166

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67,997.42669
Policy Entropy: 2.08679
Value Function Loss: 0.01784

Mean KL Divergence: 0.00740
SB3 Clip Fraction: 0.06803
Policy Update Magnitude: 0.29673
Value Function Update Magnitude: 0.29629

Collected Steps per Second: 21,521.55408
Overall Steps per Second: 10,518.36753

Timestep Collection Time: 2.32418
Timestep Consumption Time: 2.43131
PPO Batch Consumption Time: 0.27921
Total Iteration Time: 4.75549

Cumulative Model Updates: 229,532
Cumulative Timesteps: 1,914,967,186

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1914967186...
Checkpoint 1914967186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 68,518.00390
Policy Entropy: 2.09275
Value Function Loss: 0.01879

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.07041
Policy Update Magnitude: 0.29542
Value Function Update Magnitude: 0.28660

Collected Steps per Second: 20,560.25059
Overall Steps per Second: 10,282.40893

Timestep Collection Time: 2.43256
Timestep Consumption Time: 2.43148
PPO Batch Consumption Time: 0.29105
Total Iteration Time: 4.86404

Cumulative Model Updates: 229,538
Cumulative Timesteps: 1,915,017,200

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42,632.96062
Policy Entropy: 2.09030
Value Function Loss: 0.02083

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.07795
Policy Update Magnitude: 0.30056
Value Function Update Magnitude: 0.27467

Collected Steps per Second: 21,137.79635
Overall Steps per Second: 10,442.05928

Timestep Collection Time: 2.36676
Timestep Consumption Time: 2.42425
PPO Batch Consumption Time: 0.28876
Total Iteration Time: 4.79101

Cumulative Model Updates: 229,544
Cumulative Timesteps: 1,915,067,228

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1915067228...
Checkpoint 1915067228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 50,347.88512
Policy Entropy: 2.07740
Value Function Loss: 0.02129

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.08391
Policy Update Magnitude: 0.30477
Value Function Update Magnitude: 0.27302

Collected Steps per Second: 20,343.89842
Overall Steps per Second: 10,218.94187

Timestep Collection Time: 2.45912
Timestep Consumption Time: 2.43650
PPO Batch Consumption Time: 0.29093
Total Iteration Time: 4.89561

Cumulative Model Updates: 229,550
Cumulative Timesteps: 1,915,117,256

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45,761.20559
Policy Entropy: 2.09238
Value Function Loss: 0.02403

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.08368
Policy Update Magnitude: 0.31262
Value Function Update Magnitude: 0.32411

Collected Steps per Second: 21,450.43806
Overall Steps per Second: 10,463.68493

Timestep Collection Time: 2.33235
Timestep Consumption Time: 2.44895
PPO Batch Consumption Time: 0.28965
Total Iteration Time: 4.78130

Cumulative Model Updates: 229,556
Cumulative Timesteps: 1,915,167,286

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1915167286...
Checkpoint 1915167286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 50,438.71348
Policy Entropy: 2.10790
Value Function Loss: 0.02297

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.07917
Policy Update Magnitude: 0.31289
Value Function Update Magnitude: 0.35925

Collected Steps per Second: 21,064.84782
Overall Steps per Second: 10,254.48144

Timestep Collection Time: 2.37372
Timestep Consumption Time: 2.50239
PPO Batch Consumption Time: 0.29413
Total Iteration Time: 4.87611

Cumulative Model Updates: 229,562
Cumulative Timesteps: 1,915,217,288

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 72,806.78771
Policy Entropy: 2.11894
Value Function Loss: 0.02369

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.07455
Policy Update Magnitude: 0.31259
Value Function Update Magnitude: 0.35731

Collected Steps per Second: 22,095.67647
Overall Steps per Second: 10,517.93821

Timestep Collection Time: 2.26325
Timestep Consumption Time: 2.49130
PPO Batch Consumption Time: 0.29431
Total Iteration Time: 4.75454

Cumulative Model Updates: 229,568
Cumulative Timesteps: 1,915,267,296

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1915267296...
Checkpoint 1915267296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55,457.17369
Policy Entropy: 2.12679
Value Function Loss: 0.02463

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.07902
Policy Update Magnitude: 0.31392
Value Function Update Magnitude: 0.38003

Collected Steps per Second: 21,374.15018
Overall Steps per Second: 10,502.34510

Timestep Collection Time: 2.34021
Timestep Consumption Time: 2.42254
PPO Batch Consumption Time: 0.28108
Total Iteration Time: 4.76275

Cumulative Model Updates: 229,574
Cumulative Timesteps: 1,915,317,316

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63,454.73584
Policy Entropy: 2.12023
Value Function Loss: 0.02501

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.08236
Policy Update Magnitude: 0.31497
Value Function Update Magnitude: 0.37364

Collected Steps per Second: 22,001.39023
Overall Steps per Second: 10,489.49399

Timestep Collection Time: 2.27358
Timestep Consumption Time: 2.49519
PPO Batch Consumption Time: 0.28895
Total Iteration Time: 4.76877

Cumulative Model Updates: 229,580
Cumulative Timesteps: 1,915,367,338

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1915367338...
Checkpoint 1915367338 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 66,813.80761
Policy Entropy: 2.12466
Value Function Loss: 0.02477

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.08595
Policy Update Magnitude: 0.31106
Value Function Update Magnitude: 0.34633

Collected Steps per Second: 21,605.19703
Overall Steps per Second: 10,535.00092

Timestep Collection Time: 2.31518
Timestep Consumption Time: 2.43280
PPO Batch Consumption Time: 0.27929
Total Iteration Time: 4.74798

Cumulative Model Updates: 229,586
Cumulative Timesteps: 1,915,417,358

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55,251.34671
Policy Entropy: 2.11580
Value Function Loss: 0.02252

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.08506
Policy Update Magnitude: 0.30252
Value Function Update Magnitude: 0.32729

Collected Steps per Second: 22,017.45410
Overall Steps per Second: 10,525.49959

Timestep Collection Time: 2.27192
Timestep Consumption Time: 2.48053
PPO Batch Consumption Time: 0.28587
Total Iteration Time: 4.75246

Cumulative Model Updates: 229,592
Cumulative Timesteps: 1,915,467,380

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1915467380...
Checkpoint 1915467380 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 54,347.53515
Policy Entropy: 2.11528
Value Function Loss: 0.02034

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.07917
Policy Update Magnitude: 0.29595
Value Function Update Magnitude: 0.32665

Collected Steps per Second: 21,172.71411
Overall Steps per Second: 10,212.84802

Timestep Collection Time: 2.36304
Timestep Consumption Time: 2.53589
PPO Batch Consumption Time: 0.29585
Total Iteration Time: 4.89893

Cumulative Model Updates: 229,598
Cumulative Timesteps: 1,915,517,412

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,808.70933
Policy Entropy: 2.11239
Value Function Loss: 0.01979

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.07695
Policy Update Magnitude: 0.29541
Value Function Update Magnitude: 0.31548

Collected Steps per Second: 21,207.59483
Overall Steps per Second: 10,244.08963

Timestep Collection Time: 2.35849
Timestep Consumption Time: 2.52413
PPO Batch Consumption Time: 0.29353
Total Iteration Time: 4.88262

Cumulative Model Updates: 229,604
Cumulative Timesteps: 1,915,567,430

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1915567430...
Checkpoint 1915567430 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 60,435.11129
Policy Entropy: 2.12188
Value Function Loss: 0.01988

Mean KL Divergence: 0.00757
SB3 Clip Fraction: 0.06909
Policy Update Magnitude: 0.29856
Value Function Update Magnitude: 0.31994

Collected Steps per Second: 21,006.17389
Overall Steps per Second: 10,369.43872

Timestep Collection Time: 2.38120
Timestep Consumption Time: 2.44259
PPO Batch Consumption Time: 0.27965
Total Iteration Time: 4.82379

Cumulative Model Updates: 229,610
Cumulative Timesteps: 1,915,617,450

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66,372.97790
Policy Entropy: 2.12955
Value Function Loss: 0.01993

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.06969
Policy Update Magnitude: 0.29663
Value Function Update Magnitude: 0.27869

Collected Steps per Second: 21,687.98689
Overall Steps per Second: 10,530.11347

Timestep Collection Time: 2.30625
Timestep Consumption Time: 2.44374
PPO Batch Consumption Time: 0.27940
Total Iteration Time: 4.75000

Cumulative Model Updates: 229,616
Cumulative Timesteps: 1,915,667,468

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1915667468...
Checkpoint 1915667468 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,451.96831
Policy Entropy: 2.13581
Value Function Loss: 0.02092

Mean KL Divergence: 0.00675
SB3 Clip Fraction: 0.06376
Policy Update Magnitude: 0.30186
Value Function Update Magnitude: 0.27481

Collected Steps per Second: 21,558.34126
Overall Steps per Second: 10,402.75773

Timestep Collection Time: 2.32124
Timestep Consumption Time: 2.48922
PPO Batch Consumption Time: 0.28027
Total Iteration Time: 4.81046

Cumulative Model Updates: 229,622
Cumulative Timesteps: 1,915,717,510

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47,682.32532
Policy Entropy: 2.12827
Value Function Loss: 0.02035

Mean KL Divergence: 0.00716
SB3 Clip Fraction: 0.06839
Policy Update Magnitude: 0.30119
Value Function Update Magnitude: 0.31015

Collected Steps per Second: 21,371.81371
Overall Steps per Second: 10,448.44520

Timestep Collection Time: 2.34019
Timestep Consumption Time: 2.44656
PPO Batch Consumption Time: 0.29310
Total Iteration Time: 4.78674

Cumulative Model Updates: 229,628
Cumulative Timesteps: 1,915,767,524

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1915767524...
Checkpoint 1915767524 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 64,406.17272
Policy Entropy: 2.12308
Value Function Loss: 0.02098

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.06690
Policy Update Magnitude: 0.30607
Value Function Update Magnitude: 0.34325

Collected Steps per Second: 20,847.35180
Overall Steps per Second: 10,376.78792

Timestep Collection Time: 2.39877
Timestep Consumption Time: 2.42045
PPO Batch Consumption Time: 0.29174
Total Iteration Time: 4.81922

Cumulative Model Updates: 229,634
Cumulative Timesteps: 1,915,817,532

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,146.04146
Policy Entropy: 2.11192
Value Function Loss: 0.02121

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.06815
Policy Update Magnitude: 0.30318
Value Function Update Magnitude: 0.32831

Collected Steps per Second: 21,412.73900
Overall Steps per Second: 10,649.95858

Timestep Collection Time: 2.33571
Timestep Consumption Time: 2.36046
PPO Batch Consumption Time: 0.27982
Total Iteration Time: 4.69617

Cumulative Model Updates: 229,640
Cumulative Timesteps: 1,915,867,546

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1915867546...
Checkpoint 1915867546 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,443.53817
Policy Entropy: 2.09684
Value Function Loss: 0.02460

Mean KL Divergence: 0.01114
SB3 Clip Fraction: 0.07128
Policy Update Magnitude: 0.31377
Value Function Update Magnitude: 0.30038

Collected Steps per Second: 21,023.92122
Overall Steps per Second: 10,269.34850

Timestep Collection Time: 2.37853
Timestep Consumption Time: 2.49091
PPO Batch Consumption Time: 0.29220
Total Iteration Time: 4.86944

Cumulative Model Updates: 229,646
Cumulative Timesteps: 1,915,917,552

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,865.64967
Policy Entropy: 2.10008
Value Function Loss: 0.02593

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.07360
Policy Update Magnitude: 0.31493
Value Function Update Magnitude: 0.25329

Collected Steps per Second: 21,963.00732
Overall Steps per Second: 10,465.57544

Timestep Collection Time: 2.27792
Timestep Consumption Time: 2.50251
PPO Batch Consumption Time: 0.29337
Total Iteration Time: 4.78043

Cumulative Model Updates: 229,652
Cumulative Timesteps: 1,915,967,582

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1915967582...
Checkpoint 1915967582 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 51,879.02840
Policy Entropy: 2.10931
Value Function Loss: 0.02230

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.07520
Policy Update Magnitude: 0.31095
Value Function Update Magnitude: 0.31740

Collected Steps per Second: 21,095.92134
Overall Steps per Second: 10,304.71174

Timestep Collection Time: 2.37022
Timestep Consumption Time: 2.48212
PPO Batch Consumption Time: 0.29306
Total Iteration Time: 4.85234

Cumulative Model Updates: 229,658
Cumulative Timesteps: 1,916,017,584

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,665.64783
Policy Entropy: 2.11720
Value Function Loss: 0.02207

Mean KL Divergence: 0.00743
SB3 Clip Fraction: 0.06686
Policy Update Magnitude: 0.30293
Value Function Update Magnitude: 0.34523

Collected Steps per Second: 21,219.08686
Overall Steps per Second: 10,441.04958

Timestep Collection Time: 2.35693
Timestep Consumption Time: 2.43301
PPO Batch Consumption Time: 0.27798
Total Iteration Time: 4.78994

Cumulative Model Updates: 229,664
Cumulative Timesteps: 1,916,067,596

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1916067596...
Checkpoint 1916067596 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,712.64945
Policy Entropy: 2.11590
Value Function Loss: 0.02181

Mean KL Divergence: 0.00695
SB3 Clip Fraction: 0.06538
Policy Update Magnitude: 0.30584
Value Function Update Magnitude: 0.31052

Collected Steps per Second: 21,169.27252
Overall Steps per Second: 10,294.21498

Timestep Collection Time: 2.36210
Timestep Consumption Time: 2.49538
PPO Batch Consumption Time: 0.29133
Total Iteration Time: 4.85749

Cumulative Model Updates: 229,670
Cumulative Timesteps: 1,916,117,600

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46,350.57309
Policy Entropy: 2.11111
Value Function Loss: 0.02368

Mean KL Divergence: 0.00710
SB3 Clip Fraction: 0.06709
Policy Update Magnitude: 0.30797
Value Function Update Magnitude: 0.31005

Collected Steps per Second: 21,720.14198
Overall Steps per Second: 10,281.72954

Timestep Collection Time: 2.30312
Timestep Consumption Time: 2.56221
PPO Batch Consumption Time: 0.30021
Total Iteration Time: 4.86533

Cumulative Model Updates: 229,676
Cumulative Timesteps: 1,916,167,624

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1916167624...
Checkpoint 1916167624 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46,350.57309
Policy Entropy: 2.11070
Value Function Loss: 0.02032

Mean KL Divergence: 0.00758
SB3 Clip Fraction: 0.07070
Policy Update Magnitude: 0.30226
Value Function Update Magnitude: 0.30460

Collected Steps per Second: 21,419.97001
Overall Steps per Second: 10,145.24463

Timestep Collection Time: 2.33558
Timestep Consumption Time: 2.59560
PPO Batch Consumption Time: 0.30312
Total Iteration Time: 4.93118

Cumulative Model Updates: 229,682
Cumulative Timesteps: 1,916,217,652

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,176.44537
Policy Entropy: 2.12400
Value Function Loss: 0.01888

Mean KL Divergence: 0.00663
SB3 Clip Fraction: 0.06398
Policy Update Magnitude: 0.29440
Value Function Update Magnitude: 0.26872

Collected Steps per Second: 22,083.28719
Overall Steps per Second: 10,593.19141

Timestep Collection Time: 2.26570
Timestep Consumption Time: 2.45753
PPO Batch Consumption Time: 0.27811
Total Iteration Time: 4.72322

Cumulative Model Updates: 229,688
Cumulative Timesteps: 1,916,267,686

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1916267686...
Checkpoint 1916267686 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47,385.23756
Policy Entropy: 2.11620
Value Function Loss: 0.01980

Mean KL Divergence: 0.00719
SB3 Clip Fraction: 0.06888
Policy Update Magnitude: 0.29601
Value Function Update Magnitude: 0.23766

Collected Steps per Second: 21,668.57941
Overall Steps per Second: 10,492.19731

Timestep Collection Time: 2.30786
Timestep Consumption Time: 2.45835
PPO Batch Consumption Time: 0.28033
Total Iteration Time: 4.76621

Cumulative Model Updates: 229,694
Cumulative Timesteps: 1,916,317,694

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47,975.48930
Policy Entropy: 2.11452
Value Function Loss: 0.02016

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.07466
Policy Update Magnitude: 0.29497
Value Function Update Magnitude: 0.24536

Collected Steps per Second: 21,814.92403
Overall Steps per Second: 10,481.87249

Timestep Collection Time: 2.29247
Timestep Consumption Time: 2.47863
PPO Batch Consumption Time: 0.28673
Total Iteration Time: 4.77109

Cumulative Model Updates: 229,700
Cumulative Timesteps: 1,916,367,704

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1916367704...
Checkpoint 1916367704 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,020.82564
Policy Entropy: 2.09379
Value Function Loss: 0.02405

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.07288
Policy Update Magnitude: 0.30109
Value Function Update Magnitude: 0.30036

Collected Steps per Second: 21,516.87103
Overall Steps per Second: 10,351.85764

Timestep Collection Time: 2.32534
Timestep Consumption Time: 2.50800
PPO Batch Consumption Time: 0.29415
Total Iteration Time: 4.83334

Cumulative Model Updates: 229,706
Cumulative Timesteps: 1,916,417,738

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,041.48631
Policy Entropy: 2.10463
Value Function Loss: 0.02276

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.07618
Policy Update Magnitude: 0.30672
Value Function Update Magnitude: 0.30523

Collected Steps per Second: 22,024.13459
Overall Steps per Second: 10,457.51153

Timestep Collection Time: 2.27060
Timestep Consumption Time: 2.51142
PPO Batch Consumption Time: 0.29389
Total Iteration Time: 4.78202

Cumulative Model Updates: 229,712
Cumulative Timesteps: 1,916,467,746

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1916467746...
Checkpoint 1916467746 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 70,109.59760
Policy Entropy: 2.11500
Value Function Loss: 0.02372

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.07262
Policy Update Magnitude: 0.30526
Value Function Update Magnitude: 0.30209

Collected Steps per Second: 20,817.40942
Overall Steps per Second: 10,465.56040

Timestep Collection Time: 2.40414
Timestep Consumption Time: 2.37802
PPO Batch Consumption Time: 0.27927
Total Iteration Time: 4.78216

Cumulative Model Updates: 229,718
Cumulative Timesteps: 1,916,517,794

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49,494.16818
Policy Entropy: 2.11616
Value Function Loss: 0.02132

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.06968
Policy Update Magnitude: 0.30593
Value Function Update Magnitude: 0.31156

Collected Steps per Second: 21,249.54622
Overall Steps per Second: 10,466.81102

Timestep Collection Time: 2.35384
Timestep Consumption Time: 2.42489
PPO Batch Consumption Time: 0.28788
Total Iteration Time: 4.77872

Cumulative Model Updates: 229,724
Cumulative Timesteps: 1,916,567,812

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1916567812...
Checkpoint 1916567812 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40,366.20819
Policy Entropy: 2.12260
Value Function Loss: 0.02147

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.07316
Policy Update Magnitude: 0.30881
Value Function Update Magnitude: 0.30961

Collected Steps per Second: 20,621.99645
Overall Steps per Second: 10,287.72500

Timestep Collection Time: 2.42586
Timestep Consumption Time: 2.43683
PPO Batch Consumption Time: 0.29273
Total Iteration Time: 4.86269

Cumulative Model Updates: 229,730
Cumulative Timesteps: 1,916,617,838

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80,974.85126
Policy Entropy: 2.11936
Value Function Loss: 0.02471

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.07140
Policy Update Magnitude: 0.31177
Value Function Update Magnitude: 0.30648

Collected Steps per Second: 20,969.13462
Overall Steps per Second: 10,377.75915

Timestep Collection Time: 2.38493
Timestep Consumption Time: 2.43403
PPO Batch Consumption Time: 0.27999
Total Iteration Time: 4.81896

Cumulative Model Updates: 229,736
Cumulative Timesteps: 1,916,667,848

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1916667848...
Checkpoint 1916667848 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 53,682.11991
Policy Entropy: 2.11988
Value Function Loss: 0.02430

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.07480
Policy Update Magnitude: 0.31193
Value Function Update Magnitude: 0.34468

Collected Steps per Second: 21,284.78568
Overall Steps per Second: 10,321.82103

Timestep Collection Time: 2.35032
Timestep Consumption Time: 2.49631
PPO Batch Consumption Time: 0.29408
Total Iteration Time: 4.84663

Cumulative Model Updates: 229,742
Cumulative Timesteps: 1,916,717,874

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,935.82853
Policy Entropy: 2.12379
Value Function Loss: 0.02334

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.07474
Policy Update Magnitude: 0.31117
Value Function Update Magnitude: 0.35701

Collected Steps per Second: 21,675.36782
Overall Steps per Second: 10,414.62874

Timestep Collection Time: 2.30686
Timestep Consumption Time: 2.49427
PPO Batch Consumption Time: 0.29371
Total Iteration Time: 4.80113

Cumulative Model Updates: 229,748
Cumulative Timesteps: 1,916,767,876

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1916767876...
Checkpoint 1916767876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,785.34202
Policy Entropy: 2.11740
Value Function Loss: 0.02002

Mean KL Divergence: 0.00747
SB3 Clip Fraction: 0.07006
Policy Update Magnitude: 0.30564
Value Function Update Magnitude: 0.35321

Collected Steps per Second: 21,023.24501
Overall Steps per Second: 10,050.07902

Timestep Collection Time: 2.37946
Timestep Consumption Time: 2.59801
PPO Batch Consumption Time: 0.30516
Total Iteration Time: 4.97747

Cumulative Model Updates: 229,754
Cumulative Timesteps: 1,916,817,900

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,591.05239
Policy Entropy: 2.11976
Value Function Loss: 0.02072

Mean KL Divergence: 0.00708
SB3 Clip Fraction: 0.06516
Policy Update Magnitude: 0.30095
Value Function Update Magnitude: 0.32132

Collected Steps per Second: 22,006.17365
Overall Steps per Second: 10,470.59734

Timestep Collection Time: 2.27418
Timestep Consumption Time: 2.50549
PPO Batch Consumption Time: 0.28656
Total Iteration Time: 4.77967

Cumulative Model Updates: 229,760
Cumulative Timesteps: 1,916,867,946

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1916867946...
Checkpoint 1916867946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40,222.23670
Policy Entropy: 2.11060
Value Function Loss: 0.02366

Mean KL Divergence: 0.01114
SB3 Clip Fraction: 0.09342
Policy Update Magnitude: 0.30058
Value Function Update Magnitude: 0.30987

Collected Steps per Second: 21,619.37682
Overall Steps per Second: 10,303.89464

Timestep Collection Time: 2.31357
Timestep Consumption Time: 2.54071
PPO Batch Consumption Time: 0.28948
Total Iteration Time: 4.85428

Cumulative Model Updates: 229,766
Cumulative Timesteps: 1,916,917,964

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,845.77054
Policy Entropy: 2.10799
Value Function Loss: 0.02404

Mean KL Divergence: 0.01775
SB3 Clip Fraction: 0.12701
Policy Update Magnitude: 0.28758
Value Function Update Magnitude: 0.35410

Collected Steps per Second: 22,087.42697
Overall Steps per Second: 10,406.60499

Timestep Collection Time: 2.26500
Timestep Consumption Time: 2.54233
PPO Batch Consumption Time: 0.29387
Total Iteration Time: 4.80733

Cumulative Model Updates: 229,772
Cumulative Timesteps: 1,916,967,992

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1916967992...
Checkpoint 1916967992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,710.82412
Policy Entropy: 2.10941
Value Function Loss: 0.02473

Mean KL Divergence: 0.01441
SB3 Clip Fraction: 0.11296
Policy Update Magnitude: 0.30740
Value Function Update Magnitude: 0.37940

Collected Steps per Second: 21,386.37766
Overall Steps per Second: 10,237.97980

Timestep Collection Time: 2.33831
Timestep Consumption Time: 2.54625
PPO Batch Consumption Time: 0.29524
Total Iteration Time: 4.88456

Cumulative Model Updates: 229,778
Cumulative Timesteps: 1,917,018,000

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 72,723.66387
Policy Entropy: 2.10708
Value Function Loss: 0.02556

Mean KL Divergence: 0.01047
SB3 Clip Fraction: 0.08863
Policy Update Magnitude: 0.31786
Value Function Update Magnitude: 0.37831

Collected Steps per Second: 21,720.94463
Overall Steps per Second: 10,500.41404

Timestep Collection Time: 2.30220
Timestep Consumption Time: 2.46009
PPO Batch Consumption Time: 0.27859
Total Iteration Time: 4.76229

Cumulative Model Updates: 229,784
Cumulative Timesteps: 1,917,068,006

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1917068006...
Checkpoint 1917068006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 125,572.37594
Policy Entropy: 2.10791
Value Function Loss: 0.02451

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.08405
Policy Update Magnitude: 0.32167
Value Function Update Magnitude: 0.37150

Collected Steps per Second: 21,457.55041
Overall Steps per Second: 10,362.43586

Timestep Collection Time: 2.33139
Timestep Consumption Time: 2.49624
PPO Batch Consumption Time: 0.29066
Total Iteration Time: 4.82763

Cumulative Model Updates: 229,790
Cumulative Timesteps: 1,917,118,032

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83,073.97144
Policy Entropy: 2.10866
Value Function Loss: 0.02277

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.07873
Policy Update Magnitude: 0.31586
Value Function Update Magnitude: 0.37268

Collected Steps per Second: 22,171.69191
Overall Steps per Second: 10,627.22625

Timestep Collection Time: 2.25594
Timestep Consumption Time: 2.45065
PPO Batch Consumption Time: 0.28046
Total Iteration Time: 4.70659

Cumulative Model Updates: 229,796
Cumulative Timesteps: 1,917,168,050

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1917168050...
Checkpoint 1917168050 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 51,895.87568
Policy Entropy: 2.11444
Value Function Loss: 0.02449

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.07338
Policy Update Magnitude: 0.32066
Value Function Update Magnitude: 0.36548

Collected Steps per Second: 21,678.37730
Overall Steps per Second: 10,382.18605

Timestep Collection Time: 2.30709
Timestep Consumption Time: 2.51020
PPO Batch Consumption Time: 0.29331
Total Iteration Time: 4.81729

Cumulative Model Updates: 229,802
Cumulative Timesteps: 1,917,218,064

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,560.61815
Policy Entropy: 2.12348
Value Function Loss: 0.02594

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.07857
Policy Update Magnitude: 0.33015
Value Function Update Magnitude: 0.40011

Collected Steps per Second: 21,725.95857
Overall Steps per Second: 10,364.68115

Timestep Collection Time: 2.30333
Timestep Consumption Time: 2.52480
PPO Batch Consumption Time: 0.29461
Total Iteration Time: 4.82813

Cumulative Model Updates: 229,808
Cumulative Timesteps: 1,917,268,106

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1917268106...
Checkpoint 1917268106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,729.24321
Policy Entropy: 2.10288
Value Function Loss: 0.02823

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.08646
Policy Update Magnitude: 0.33538
Value Function Update Magnitude: 0.41832

Collected Steps per Second: 20,883.73636
Overall Steps per Second: 10,222.44935

Timestep Collection Time: 2.39507
Timestep Consumption Time: 2.49789
PPO Batch Consumption Time: 0.28875
Total Iteration Time: 4.89296

Cumulative Model Updates: 229,814
Cumulative Timesteps: 1,917,318,124

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47,826.95358
Policy Entropy: 2.11288
Value Function Loss: 0.02641

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.09132
Policy Update Magnitude: 0.33512
Value Function Update Magnitude: 0.41139

Collected Steps per Second: 21,050.47164
Overall Steps per Second: 10,360.02012

Timestep Collection Time: 2.37629
Timestep Consumption Time: 2.45208
PPO Batch Consumption Time: 0.27919
Total Iteration Time: 4.82837

Cumulative Model Updates: 229,820
Cumulative Timesteps: 1,917,368,146

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1917368146...
Checkpoint 1917368146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,845.84197
Policy Entropy: 2.09907
Value Function Loss: 0.02627

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.09377
Policy Update Magnitude: 0.33447
Value Function Update Magnitude: 0.40880

Collected Steps per Second: 21,041.08446
Overall Steps per Second: 10,265.31986

Timestep Collection Time: 2.37744
Timestep Consumption Time: 2.49566
PPO Batch Consumption Time: 0.28665
Total Iteration Time: 4.87311

Cumulative Model Updates: 229,826
Cumulative Timesteps: 1,917,418,170

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,922.75092
Policy Entropy: 2.11876
Value Function Loss: 0.02400

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.08929
Policy Update Magnitude: 0.32502
Value Function Update Magnitude: 0.39279

Collected Steps per Second: 22,130.46674
Overall Steps per Second: 10,311.43005

Timestep Collection Time: 2.25987
Timestep Consumption Time: 2.59028
PPO Batch Consumption Time: 0.30145
Total Iteration Time: 4.85015

Cumulative Model Updates: 229,832
Cumulative Timesteps: 1,917,468,182

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1917468182...
Checkpoint 1917468182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,011.50966
Policy Entropy: 2.11545
Value Function Loss: 0.02802

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.08345
Policy Update Magnitude: 0.32663
Value Function Update Magnitude: 0.38396

Collected Steps per Second: 20,894.37359
Overall Steps per Second: 10,362.69366

Timestep Collection Time: 2.39395
Timestep Consumption Time: 2.43298
PPO Batch Consumption Time: 0.27970
Total Iteration Time: 4.82693

Cumulative Model Updates: 229,838
Cumulative Timesteps: 1,917,518,202

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,245.68847
Policy Entropy: 2.11606
Value Function Loss: 0.02839

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.08390
Policy Update Magnitude: 0.33275
Value Function Update Magnitude: 0.40429

Collected Steps per Second: 21,196.68732
Overall Steps per Second: 10,406.97551

Timestep Collection Time: 2.36084
Timestep Consumption Time: 2.44767
PPO Batch Consumption Time: 0.28918
Total Iteration Time: 4.80851

Cumulative Model Updates: 229,844
Cumulative Timesteps: 1,917,568,244

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1917568244...
Checkpoint 1917568244 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,337.80125
Policy Entropy: 2.11619
Value Function Loss: 0.03111

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.08198
Policy Update Magnitude: 0.33411
Value Function Update Magnitude: 0.41552

Collected Steps per Second: 20,821.92716
Overall Steps per Second: 10,336.13341

Timestep Collection Time: 2.40276
Timestep Consumption Time: 2.43755
PPO Batch Consumption Time: 0.29457
Total Iteration Time: 4.84030

Cumulative Model Updates: 229,850
Cumulative Timesteps: 1,917,618,274

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,316.04467
Policy Entropy: 2.10205
Value Function Loss: 0.02762

Mean KL Divergence: 0.01306
SB3 Clip Fraction: 0.08641
Policy Update Magnitude: 0.35391
Value Function Update Magnitude: 0.42142

Collected Steps per Second: 21,256.33644
Overall Steps per Second: 10,415.86595

Timestep Collection Time: 2.35290
Timestep Consumption Time: 2.44881
PPO Batch Consumption Time: 0.29495
Total Iteration Time: 4.80171

Cumulative Model Updates: 229,856
Cumulative Timesteps: 1,917,668,288

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1917668288...
Checkpoint 1917668288 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,811.61173
Policy Entropy: 2.11611
Value Function Loss: 0.02616

Mean KL Divergence: 0.02334
SB3 Clip Fraction: 0.07465
Policy Update Magnitude: 0.33720
Value Function Update Magnitude: 0.41244

Collected Steps per Second: 21,007.12486
Overall Steps per Second: 10,264.00668

Timestep Collection Time: 2.38100
Timestep Consumption Time: 2.49214
PPO Batch Consumption Time: 0.29346
Total Iteration Time: 4.87315

Cumulative Model Updates: 229,862
Cumulative Timesteps: 1,917,718,306

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,324.10945
Policy Entropy: 2.09261
Value Function Loss: 0.02395

Mean KL Divergence: 0.02728
SB3 Clip Fraction: 0.07466
Policy Update Magnitude: 0.32072
Value Function Update Magnitude: 0.39287

Collected Steps per Second: 21,584.62606
Overall Steps per Second: 10,393.86899

Timestep Collection Time: 2.31730
Timestep Consumption Time: 2.49496
PPO Batch Consumption Time: 0.29478
Total Iteration Time: 4.81226

Cumulative Model Updates: 229,868
Cumulative Timesteps: 1,917,768,324

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1917768324...
Checkpoint 1917768324 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,714.94412
Policy Entropy: 2.10201
Value Function Loss: 0.02282

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.07588
Policy Update Magnitude: 0.31351
Value Function Update Magnitude: 0.37878

Collected Steps per Second: 20,821.15593
Overall Steps per Second: 10,222.56316

Timestep Collection Time: 2.40284
Timestep Consumption Time: 2.49123
PPO Batch Consumption Time: 0.29397
Total Iteration Time: 4.89408

Cumulative Model Updates: 229,874
Cumulative Timesteps: 1,917,818,354

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,927.55686
Policy Entropy: 2.10065
Value Function Loss: 0.02117

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.07925
Policy Update Magnitude: 0.30436
Value Function Update Magnitude: 0.36853

Collected Steps per Second: 21,299.81055
Overall Steps per Second: 10,456.40922

Timestep Collection Time: 2.34819
Timestep Consumption Time: 2.43510
PPO Batch Consumption Time: 0.27754
Total Iteration Time: 4.78329

Cumulative Model Updates: 229,880
Cumulative Timesteps: 1,917,868,370

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1917868370...
Checkpoint 1917868370 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,321.13355
Policy Entropy: 2.11341
Value Function Loss: 0.02165

Mean KL Divergence: 0.01156
SB3 Clip Fraction: 0.07455
Policy Update Magnitude: 0.30261
Value Function Update Magnitude: 0.35134

Collected Steps per Second: 21,386.50771
Overall Steps per Second: 10,352.65889

Timestep Collection Time: 2.33895
Timestep Consumption Time: 2.49285
PPO Batch Consumption Time: 0.28929
Total Iteration Time: 4.83180

Cumulative Model Updates: 229,886
Cumulative Timesteps: 1,917,918,392

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,204.58264
Policy Entropy: 2.10397
Value Function Loss: 0.02265

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.07854
Policy Update Magnitude: 0.30991
Value Function Update Magnitude: 0.35482

Collected Steps per Second: 22,183.90201
Overall Steps per Second: 10,614.17047

Timestep Collection Time: 2.25515
Timestep Consumption Time: 2.45817
PPO Batch Consumption Time: 0.27950
Total Iteration Time: 4.71332

Cumulative Model Updates: 229,892
Cumulative Timesteps: 1,917,968,420

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1917968420...
Checkpoint 1917968420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 50,805.87913
Policy Entropy: 2.10887
Value Function Loss: 0.02264

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.08020
Policy Update Magnitude: 0.31297
Value Function Update Magnitude: 0.36866

Collected Steps per Second: 21,593.04765
Overall Steps per Second: 10,334.34265

Timestep Collection Time: 2.31713
Timestep Consumption Time: 2.52439
PPO Batch Consumption Time: 0.29353
Total Iteration Time: 4.84153

Cumulative Model Updates: 229,898
Cumulative Timesteps: 1,918,018,454

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,947.97016
Policy Entropy: 2.10625
Value Function Loss: 0.02414

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.07527
Policy Update Magnitude: 0.31913
Value Function Update Magnitude: 0.34970

Collected Steps per Second: 22,033.75117
Overall Steps per Second: 10,407.97459

Timestep Collection Time: 2.27052
Timestep Consumption Time: 2.53618
PPO Batch Consumption Time: 0.29585
Total Iteration Time: 4.80670

Cumulative Model Updates: 229,904
Cumulative Timesteps: 1,918,068,482

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1918068482...
Checkpoint 1918068482 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,012.05095
Policy Entropy: 2.11192
Value Function Loss: 0.02394

Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.07503
Policy Update Magnitude: 0.32009
Value Function Update Magnitude: 0.32790

Collected Steps per Second: 21,666.50690
Overall Steps per Second: 10,087.65559

Timestep Collection Time: 2.30854
Timestep Consumption Time: 2.64980
PPO Batch Consumption Time: 0.29822
Total Iteration Time: 4.95834

Cumulative Model Updates: 229,910
Cumulative Timesteps: 1,918,118,500

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,015.32041
Policy Entropy: 2.10378
Value Function Loss: 0.02375

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.06911
Policy Update Magnitude: 0.31460
Value Function Update Magnitude: 0.33568

Collected Steps per Second: 22,195.52454
Overall Steps per Second: 10,640.76009

Timestep Collection Time: 2.25280
Timestep Consumption Time: 2.44630
PPO Batch Consumption Time: 0.27823
Total Iteration Time: 4.69910

Cumulative Model Updates: 229,916
Cumulative Timesteps: 1,918,168,502

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1918168502...
Checkpoint 1918168502 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,243.66916
Policy Entropy: 2.10195
Value Function Loss: 0.02070

Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.07272
Policy Update Magnitude: 0.30574
Value Function Update Magnitude: 0.35288

Collected Steps per Second: 21,984.11277
Overall Steps per Second: 10,645.80914

Timestep Collection Time: 2.27510
Timestep Consumption Time: 2.42309
PPO Batch Consumption Time: 0.27746
Total Iteration Time: 4.69819

Cumulative Model Updates: 229,922
Cumulative Timesteps: 1,918,218,518

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,429.38162
Policy Entropy: 2.08362
Value Function Loss: 0.01912

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.07003
Policy Update Magnitude: 0.30070
Value Function Update Magnitude: 0.32399

Collected Steps per Second: 22,142.78684
Overall Steps per Second: 10,504.32193

Timestep Collection Time: 2.25852
Timestep Consumption Time: 2.50237
PPO Batch Consumption Time: 0.29159
Total Iteration Time: 4.76090

Cumulative Model Updates: 229,928
Cumulative Timesteps: 1,918,268,528

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1918268528...
Checkpoint 1918268528 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,612.58964
Policy Entropy: 2.07964
Value Function Loss: 0.01925

Mean KL Divergence: 0.00726
SB3 Clip Fraction: 0.06785
Policy Update Magnitude: 0.29792
Value Function Update Magnitude: 0.29248

Collected Steps per Second: 21,733.06747
Overall Steps per Second: 10,590.98918

Timestep Collection Time: 2.30193
Timestep Consumption Time: 2.42171
PPO Batch Consumption Time: 0.27748
Total Iteration Time: 4.72364

Cumulative Model Updates: 229,934
Cumulative Timesteps: 1,918,318,556

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46,600.68605
Policy Entropy: 2.09452
Value Function Loss: 0.01882

Mean KL Divergence: 0.00756
SB3 Clip Fraction: 0.06993
Policy Update Magnitude: 0.28994
Value Function Update Magnitude: 0.28719

Collected Steps per Second: 21,801.24660
Overall Steps per Second: 10,385.47786

Timestep Collection Time: 2.29409
Timestep Consumption Time: 2.52167
PPO Batch Consumption Time: 0.29299
Total Iteration Time: 4.81576

Cumulative Model Updates: 229,940
Cumulative Timesteps: 1,918,368,570

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1918368570...
Checkpoint 1918368570 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,364.01959
Policy Entropy: 2.09249
Value Function Loss: 0.01809

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.08406
Policy Update Magnitude: 0.28221
Value Function Update Magnitude: 0.27498

Collected Steps per Second: 21,352.58538
Overall Steps per Second: 10,349.47305

Timestep Collection Time: 2.34276
Timestep Consumption Time: 2.49072
PPO Batch Consumption Time: 0.29209
Total Iteration Time: 4.83348

Cumulative Model Updates: 229,946
Cumulative Timesteps: 1,918,418,594

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49,260.25453
Policy Entropy: 2.09802
Value Function Loss: 0.01723

Mean KL Divergence: 0.01188
SB3 Clip Fraction: 0.09757
Policy Update Magnitude: 0.27958
Value Function Update Magnitude: 0.27825

Collected Steps per Second: 21,842.18148
Overall Steps per Second: 10,428.32205

Timestep Collection Time: 2.28979
Timestep Consumption Time: 2.50619
PPO Batch Consumption Time: 0.29222
Total Iteration Time: 4.79598

Cumulative Model Updates: 229,952
Cumulative Timesteps: 1,918,468,608

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1918468608...
Checkpoint 1918468608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46,991.15593
Policy Entropy: 2.07990
Value Function Loss: 0.02169

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.08662
Policy Update Magnitude: 0.29008
Value Function Update Magnitude: 0.24971

Collected Steps per Second: 21,873.99913
Overall Steps per Second: 10,502.82809

Timestep Collection Time: 2.28646
Timestep Consumption Time: 2.47550
PPO Batch Consumption Time: 0.27989
Total Iteration Time: 4.76196

Cumulative Model Updates: 229,958
Cumulative Timesteps: 1,918,518,622

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,906.56942
Policy Entropy: 2.07106
Value Function Loss: 0.02106

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.07318
Policy Update Magnitude: 0.30254
Value Function Update Magnitude: 0.22185

Collected Steps per Second: 22,317.00918
Overall Steps per Second: 10,492.81611

Timestep Collection Time: 2.24053
Timestep Consumption Time: 2.52482
PPO Batch Consumption Time: 0.29127
Total Iteration Time: 4.76536

Cumulative Model Updates: 229,964
Cumulative Timesteps: 1,918,568,624

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1918568624...
Checkpoint 1918568624 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 73,079.23309
Policy Entropy: 2.07848
Value Function Loss: 0.02185

Mean KL Divergence: 0.00777
SB3 Clip Fraction: 0.07042
Policy Update Magnitude: 0.30521
Value Function Update Magnitude: 0.20751

Collected Steps per Second: 22,046.63013
Overall Steps per Second: 10,592.47792

Timestep Collection Time: 2.26846
Timestep Consumption Time: 2.45300
PPO Batch Consumption Time: 0.28044
Total Iteration Time: 4.72146

Cumulative Model Updates: 229,970
Cumulative Timesteps: 1,918,618,636

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75,393.59226
Policy Entropy: 2.07953
Value Function Loss: 0.01966

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.07752
Policy Update Magnitude: 0.30235
Value Function Update Magnitude: 0.19349

Collected Steps per Second: 21,973.50503
Overall Steps per Second: 10,465.05766

Timestep Collection Time: 2.27665
Timestep Consumption Time: 2.50364
PPO Batch Consumption Time: 0.28877
Total Iteration Time: 4.78029

Cumulative Model Updates: 229,976
Cumulative Timesteps: 1,918,668,662

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1918668662...
Checkpoint 1918668662 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 62,352.25569
Policy Entropy: 2.10060
Value Function Loss: 0.02529

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.07648
Policy Update Magnitude: 0.30785
Value Function Update Magnitude: 0.23456

Collected Steps per Second: 21,969.61928
Overall Steps per Second: 10,584.24159

Timestep Collection Time: 2.27687
Timestep Consumption Time: 2.44921
PPO Batch Consumption Time: 0.27963
Total Iteration Time: 4.72608

Cumulative Model Updates: 229,982
Cumulative Timesteps: 1,918,718,684

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75,449.04705
Policy Entropy: 2.09716
Value Function Loss: 0.02500

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.08219
Policy Update Magnitude: 0.31674
Value Function Update Magnitude: 0.25486

Collected Steps per Second: 22,012.65045
Overall Steps per Second: 10,514.60489

Timestep Collection Time: 2.27197
Timestep Consumption Time: 2.48447
PPO Batch Consumption Time: 0.28701
Total Iteration Time: 4.75643

Cumulative Model Updates: 229,988
Cumulative Timesteps: 1,918,768,696

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1918768696...
Checkpoint 1918768696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 66,847.55372
Policy Entropy: 2.09095
Value Function Loss: 0.02616

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.08008
Policy Update Magnitude: 0.31457
Value Function Update Magnitude: 0.24854

Collected Steps per Second: 21,327.88309
Overall Steps per Second: 10,322.93525

Timestep Collection Time: 2.34519
Timestep Consumption Time: 2.50013
PPO Batch Consumption Time: 0.29192
Total Iteration Time: 4.84533

Cumulative Model Updates: 229,994
Cumulative Timesteps: 1,918,818,714

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60,808.73860
Policy Entropy: 2.08821
Value Function Loss: 0.02287

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.08144
Policy Update Magnitude: 0.31040
Value Function Update Magnitude: 0.27839

Collected Steps per Second: 21,662.23208
Overall Steps per Second: 10,355.77494

Timestep Collection Time: 2.30946
Timestep Consumption Time: 2.52147
PPO Batch Consumption Time: 0.29243
Total Iteration Time: 4.83093

Cumulative Model Updates: 230,000
Cumulative Timesteps: 1,918,868,742

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1918868742...
Checkpoint 1918868742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 56,324.84346
Policy Entropy: 2.08820
Value Function Loss: 0.02262

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.07853
Policy Update Magnitude: 0.30511
Value Function Update Magnitude: 0.28821

Collected Steps per Second: 21,288.85719
Overall Steps per Second: 10,276.08141

Timestep Collection Time: 2.34987
Timestep Consumption Time: 2.51833
PPO Batch Consumption Time: 0.29363
Total Iteration Time: 4.86820

Cumulative Model Updates: 230,006
Cumulative Timesteps: 1,918,918,768

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47,565.94965
Policy Entropy: 2.08705
Value Function Loss: 0.02008

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.07418
Policy Update Magnitude: 0.29824
Value Function Update Magnitude: 0.28651

Collected Steps per Second: 21,485.60813
Overall Steps per Second: 10,383.28154

Timestep Collection Time: 2.32751
Timestep Consumption Time: 2.48869
PPO Batch Consumption Time: 0.28722
Total Iteration Time: 4.81620

Cumulative Model Updates: 230,012
Cumulative Timesteps: 1,918,968,776

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1918968776...
Checkpoint 1918968776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,732.48385
Policy Entropy: 2.09583
Value Function Loss: 0.01961

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.06922
Policy Update Magnitude: 0.29782
Value Function Update Magnitude: 0.24469

Collected Steps per Second: 21,364.03505
Overall Steps per Second: 10,277.44986

Timestep Collection Time: 2.34188
Timestep Consumption Time: 2.52625
PPO Batch Consumption Time: 0.29354
Total Iteration Time: 4.86813

Cumulative Model Updates: 230,018
Cumulative Timesteps: 1,919,018,808

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,555.90288
Policy Entropy: 2.10483
Value Function Loss: 0.01949

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.07423
Policy Update Magnitude: 0.29949
Value Function Update Magnitude: 0.22598

Collected Steps per Second: 22,140.17338
Overall Steps per Second: 10,388.51643

Timestep Collection Time: 2.25933
Timestep Consumption Time: 2.55579
PPO Batch Consumption Time: 0.29220
Total Iteration Time: 4.81512

Cumulative Model Updates: 230,024
Cumulative Timesteps: 1,919,068,830

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1919068830...
Checkpoint 1919068830 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,790.82879
Policy Entropy: 2.11526
Value Function Loss: 0.01771

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.07735
Policy Update Magnitude: 0.29131
Value Function Update Magnitude: 0.23870

Collected Steps per Second: 21,694.53424
Overall Steps per Second: 10,514.99619

Timestep Collection Time: 2.30537
Timestep Consumption Time: 2.45107
PPO Batch Consumption Time: 0.27915
Total Iteration Time: 4.75644

Cumulative Model Updates: 230,030
Cumulative Timesteps: 1,919,118,844

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59,454.74779
Policy Entropy: 2.11069
Value Function Loss: 0.01772

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.08204
Policy Update Magnitude: 0.27722
Value Function Update Magnitude: 0.22376

Collected Steps per Second: 21,986.63130
Overall Steps per Second: 10,630.38515

Timestep Collection Time: 2.27584
Timestep Consumption Time: 2.43124
PPO Batch Consumption Time: 0.27765
Total Iteration Time: 4.70707

Cumulative Model Updates: 230,036
Cumulative Timesteps: 1,919,168,882

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1919168882...
Checkpoint 1919168882 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 54,037.13936
Policy Entropy: 2.10810
Value Function Loss: 0.01717

Mean KL Divergence: 0.00696
SB3 Clip Fraction: 0.06839
Policy Update Magnitude: 0.28012
Value Function Update Magnitude: 0.19041

Collected Steps per Second: 21,787.30190
Overall Steps per Second: 10,560.35303

Timestep Collection Time: 2.29565
Timestep Consumption Time: 2.44056
PPO Batch Consumption Time: 0.27961
Total Iteration Time: 4.73621

Cumulative Model Updates: 230,042
Cumulative Timesteps: 1,919,218,898

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46,675.88088
Policy Entropy: 2.10336
Value Function Loss: 0.01875

Mean KL Divergence: 0.00758
SB3 Clip Fraction: 0.07128
Policy Update Magnitude: 0.28657
Value Function Update Magnitude: 0.24168

Collected Steps per Second: 21,932.15785
Overall Steps per Second: 10,420.08412

Timestep Collection Time: 2.28012
Timestep Consumption Time: 2.51907
PPO Batch Consumption Time: 0.29190
Total Iteration Time: 4.79919

Cumulative Model Updates: 230,048
Cumulative Timesteps: 1,919,268,906

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1919268906...
Checkpoint 1919268906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 54,438.47135
Policy Entropy: 2.09636
Value Function Loss: 0.02118

Mean KL Divergence: 0.00760
SB3 Clip Fraction: 0.07065
Policy Update Magnitude: 0.30162
Value Function Update Magnitude: 0.30764

Collected Steps per Second: 21,914.56919
Overall Steps per Second: 10,585.62148

Timestep Collection Time: 2.28277
Timestep Consumption Time: 2.44307
PPO Batch Consumption Time: 0.27990
Total Iteration Time: 4.72584

Cumulative Model Updates: 230,054
Cumulative Timesteps: 1,919,318,932

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66,069.50009
Policy Entropy: 2.08832
Value Function Loss: 0.02086

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.07208
Policy Update Magnitude: 0.31185
Value Function Update Magnitude: 0.34252

Collected Steps per Second: 22,128.24952
Overall Steps per Second: 10,545.49535

Timestep Collection Time: 2.26028
Timestep Consumption Time: 2.48260
PPO Batch Consumption Time: 0.28792
Total Iteration Time: 4.74288

Cumulative Model Updates: 230,060
Cumulative Timesteps: 1,919,368,948

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1919368948...
Checkpoint 1919368948 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,102.83347
Policy Entropy: 2.10039
Value Function Loss: 0.02100

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.06961
Policy Update Magnitude: 0.30931
Value Function Update Magnitude: 0.34993

Collected Steps per Second: 21,528.14249
Overall Steps per Second: 10,356.83847

Timestep Collection Time: 2.32263
Timestep Consumption Time: 2.50529
PPO Batch Consumption Time: 0.29104
Total Iteration Time: 4.82792

Cumulative Model Updates: 230,066
Cumulative Timesteps: 1,919,418,950

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63,357.05319
Policy Entropy: 2.10495
Value Function Loss: 0.01958

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.07051
Policy Update Magnitude: 0.30318
Value Function Update Magnitude: 0.33192

Collected Steps per Second: 20,162.67427
Overall Steps per Second: 10,047.87333

Timestep Collection Time: 2.48092
Timestep Consumption Time: 2.49745
PPO Batch Consumption Time: 0.29038
Total Iteration Time: 4.97837

Cumulative Model Updates: 230,072
Cumulative Timesteps: 1,919,468,972

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1919468972...
Checkpoint 1919468972 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 58,574.76595
Policy Entropy: 2.11223
Value Function Loss: 0.01876

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.07194
Policy Update Magnitude: 0.29304
Value Function Update Magnitude: 0.30526

Collected Steps per Second: 21,452.30344
Overall Steps per Second: 10,527.74811

Timestep Collection Time: 2.33094
Timestep Consumption Time: 2.41880
PPO Batch Consumption Time: 0.27746
Total Iteration Time: 4.74973

Cumulative Model Updates: 230,078
Cumulative Timesteps: 1,919,518,976

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47,987.19297
Policy Entropy: 2.10504
Value Function Loss: 0.01953

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.07605
Policy Update Magnitude: 0.29010
Value Function Update Magnitude: 0.29956

Collected Steps per Second: 21,703.00190
Overall Steps per Second: 10,396.18648

Timestep Collection Time: 2.30493
Timestep Consumption Time: 2.50683
PPO Batch Consumption Time: 0.29094
Total Iteration Time: 4.81176

Cumulative Model Updates: 230,084
Cumulative Timesteps: 1,919,569,000

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1919569000...
Checkpoint 1919569000 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 108,039.37807
Policy Entropy: 2.11427
Value Function Loss: 0.02139

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.07497
Policy Update Magnitude: 0.29873
Value Function Update Magnitude: 0.31252

Collected Steps per Second: 21,858.81866
Overall Steps per Second: 10,581.16317

Timestep Collection Time: 2.28796
Timestep Consumption Time: 2.43856
PPO Batch Consumption Time: 0.27900
Total Iteration Time: 4.72651

Cumulative Model Updates: 230,090
Cumulative Timesteps: 1,919,619,012

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88,408.56344
Policy Entropy: 2.11078
Value Function Loss: 0.01984

Mean KL Divergence: 0.00760
SB3 Clip Fraction: 0.07053
Policy Update Magnitude: 0.29605
Value Function Update Magnitude: 0.31962

Collected Steps per Second: 21,898.09038
Overall Steps per Second: 10,577.61436

Timestep Collection Time: 2.28495
Timestep Consumption Time: 2.44542
PPO Batch Consumption Time: 0.27793
Total Iteration Time: 4.73037

Cumulative Model Updates: 230,096
Cumulative Timesteps: 1,919,669,048

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1919669048...
Checkpoint 1919669048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 80,803.00937
Policy Entropy: 2.10032
Value Function Loss: 0.01956

Mean KL Divergence: 0.00685
SB3 Clip Fraction: 0.06408
Policy Update Magnitude: 0.29700
Value Function Update Magnitude: 0.31169

Collected Steps per Second: 22,031.81167
Overall Steps per Second: 10,555.45507

Timestep Collection Time: 2.26981
Timestep Consumption Time: 2.46784
PPO Batch Consumption Time: 0.28543
Total Iteration Time: 4.73765

Cumulative Model Updates: 230,102
Cumulative Timesteps: 1,919,719,056

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83,514.57984
Policy Entropy: 2.08764
Value Function Loss: 0.02148

Mean KL Divergence: 0.00706
SB3 Clip Fraction: 0.06808
Policy Update Magnitude: 0.30721
Value Function Update Magnitude: 0.33311

Collected Steps per Second: 22,179.78468
Overall Steps per Second: 10,514.12773

Timestep Collection Time: 2.25503
Timestep Consumption Time: 2.50200
PPO Batch Consumption Time: 0.29433
Total Iteration Time: 4.75703

Cumulative Model Updates: 230,108
Cumulative Timesteps: 1,919,769,072

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1919769072...
Checkpoint 1919769072 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 54,615.19702
Policy Entropy: 2.10044
Value Function Loss: 0.02388

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.07097
Policy Update Magnitude: 0.32149
Value Function Update Magnitude: 0.34573

Collected Steps per Second: 22,275.55949
Overall Steps per Second: 10,642.66848

Timestep Collection Time: 2.24596
Timestep Consumption Time: 2.45493
PPO Batch Consumption Time: 0.28468
Total Iteration Time: 4.70089

Cumulative Model Updates: 230,114
Cumulative Timesteps: 1,919,819,102

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59,142.24270
Policy Entropy: 2.10269
Value Function Loss: 0.02556

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.07549
Policy Update Magnitude: 0.32246
Value Function Update Magnitude: 0.36959

Collected Steps per Second: 21,297.87355
Overall Steps per Second: 10,422.21404

Timestep Collection Time: 2.34897
Timestep Consumption Time: 2.45116
PPO Batch Consumption Time: 0.29420
Total Iteration Time: 4.80013

Cumulative Model Updates: 230,120
Cumulative Timesteps: 1,919,869,130

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1919869130...
Checkpoint 1919869130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,729.49714
Policy Entropy: 2.09556
Value Function Loss: 0.02295

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.07697
Policy Update Magnitude: 0.32194
Value Function Update Magnitude: 0.37863

Collected Steps per Second: 21,137.61918
Overall Steps per Second: 10,581.83516

Timestep Collection Time: 2.36763
Timestep Consumption Time: 2.36180
PPO Batch Consumption Time: 0.27952
Total Iteration Time: 4.72943

Cumulative Model Updates: 230,126
Cumulative Timesteps: 1,919,919,176

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63,191.38266
Policy Entropy: 2.08496
Value Function Loss: 0.02224

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.07213
Policy Update Magnitude: 0.31416
Value Function Update Magnitude: 0.34245

Collected Steps per Second: 20,721.81743
Overall Steps per Second: 10,476.75630

Timestep Collection Time: 2.41369
Timestep Consumption Time: 2.36031
PPO Batch Consumption Time: 0.27881
Total Iteration Time: 4.77400

Cumulative Model Updates: 230,132
Cumulative Timesteps: 1,919,969,192

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1919969192...
Checkpoint 1919969192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 77,550.82352
Policy Entropy: 2.09356
Value Function Loss: 0.02316

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.07243
Policy Update Magnitude: 0.30696
Value Function Update Magnitude: 0.31742

Collected Steps per Second: 20,924.81614
Overall Steps per Second: 10,414.44998

Timestep Collection Time: 2.39075
Timestep Consumption Time: 2.41277
PPO Batch Consumption Time: 0.29071
Total Iteration Time: 4.80352

Cumulative Model Updates: 230,138
Cumulative Timesteps: 1,920,019,218

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,676.80885
Policy Entropy: 2.11156
Value Function Loss: 0.02232

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.07153
Policy Update Magnitude: 0.30546
Value Function Update Magnitude: 0.31816

Collected Steps per Second: 21,440.77390
Overall Steps per Second: 10,399.97418

Timestep Collection Time: 2.33378
Timestep Consumption Time: 2.47758
PPO Batch Consumption Time: 0.29242
Total Iteration Time: 4.81136

Cumulative Model Updates: 230,144
Cumulative Timesteps: 1,920,069,256

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1920069256...
Checkpoint 1920069256 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,457.95270
Policy Entropy: 2.11423
Value Function Loss: 0.02163

Mean KL Divergence: 0.00752
SB3 Clip Fraction: 0.07281
Policy Update Magnitude: 0.30610
Value Function Update Magnitude: 0.33258

Collected Steps per Second: 21,437.83008
Overall Steps per Second: 10,505.38217

Timestep Collection Time: 2.33372
Timestep Consumption Time: 2.42860
PPO Batch Consumption Time: 0.28023
Total Iteration Time: 4.76232

Cumulative Model Updates: 230,150
Cumulative Timesteps: 1,920,119,286

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53,395.06623
Policy Entropy: 2.11478
Value Function Loss: 0.01979

Mean KL Divergence: 0.00727
SB3 Clip Fraction: 0.06797
Policy Update Magnitude: 0.31018
Value Function Update Magnitude: 0.32460

Collected Steps per Second: 21,961.27953
Overall Steps per Second: 10,484.70649

Timestep Collection Time: 2.27874
Timestep Consumption Time: 2.49431
PPO Batch Consumption Time: 0.28977
Total Iteration Time: 4.77305

Cumulative Model Updates: 230,156
Cumulative Timesteps: 1,920,169,330

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1920169330...
Checkpoint 1920169330 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,946.41033
Policy Entropy: 2.10571
Value Function Loss: 0.01963

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.07534
Policy Update Magnitude: 0.30947
Value Function Update Magnitude: 0.32010

Collected Steps per Second: 21,973.63857
Overall Steps per Second: 10,566.04319

Timestep Collection Time: 2.27682
Timestep Consumption Time: 2.45816
PPO Batch Consumption Time: 0.27920
Total Iteration Time: 4.73498

Cumulative Model Updates: 230,162
Cumulative Timesteps: 1,920,219,360

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46,317.40478
Policy Entropy: 2.10852
Value Function Loss: 0.02086

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.07875
Policy Update Magnitude: 0.30683
Value Function Update Magnitude: 0.30864

Collected Steps per Second: 18,622.68495
Overall Steps per Second: 8,960.16243

Timestep Collection Time: 2.68715
Timestep Consumption Time: 2.89779
PPO Batch Consumption Time: 0.36331
Total Iteration Time: 5.58494

Cumulative Model Updates: 230,168
Cumulative Timesteps: 1,920,269,402

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1920269402...
Checkpoint 1920269402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,729.04937
Policy Entropy: 2.10787
Value Function Loss: 0.02497

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.07832
Policy Update Magnitude: 0.32056
Value Function Update Magnitude: 0.30740

Collected Steps per Second: 10,194.89726
Overall Steps per Second: 6,581.08441

Timestep Collection Time: 4.90618
Timestep Consumption Time: 2.69409
PPO Batch Consumption Time: 0.30480
Total Iteration Time: 7.60027

Cumulative Model Updates: 230,174
Cumulative Timesteps: 1,920,319,420

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,505.85907
Policy Entropy: 2.11621
Value Function Loss: 0.02448

Mean KL Divergence: 0.00764
SB3 Clip Fraction: 0.07027
Policy Update Magnitude: 0.32131
Value Function Update Magnitude: 0.32170

Collected Steps per Second: 21,456.56598
Overall Steps per Second: 10,343.35891

Timestep Collection Time: 2.33178
Timestep Consumption Time: 2.50533
PPO Batch Consumption Time: 0.28948
Total Iteration Time: 4.83711

Cumulative Model Updates: 230,180
Cumulative Timesteps: 1,920,369,452

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1920369452...
Checkpoint 1920369452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 70,118.63930
Policy Entropy: 2.11108
Value Function Loss: 0.02345

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.07351
Policy Update Magnitude: 0.31641
Value Function Update Magnitude: 0.35515

Collected Steps per Second: 21,146.28954
Overall Steps per Second: 10,243.60530

Timestep Collection Time: 2.36543
Timestep Consumption Time: 2.51762
PPO Batch Consumption Time: 0.29406
Total Iteration Time: 4.88305

Cumulative Model Updates: 230,186
Cumulative Timesteps: 1,920,419,472

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,133.86840
Policy Entropy: 2.12176
Value Function Loss: 0.02367

Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.07481
Policy Update Magnitude: 0.31539
Value Function Update Magnitude: 0.35900

Collected Steps per Second: 21,745.19000
Overall Steps per Second: 10,373.85372

Timestep Collection Time: 2.29963
Timestep Consumption Time: 2.52075
PPO Batch Consumption Time: 0.29133
Total Iteration Time: 4.82039

Cumulative Model Updates: 230,192
Cumulative Timesteps: 1,920,469,478

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1920469478...
Checkpoint 1920469478 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40,907.50314
Policy Entropy: 2.11195
Value Function Loss: 0.02375

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.08822
Policy Update Magnitude: 0.31823
Value Function Update Magnitude: 0.38385

Collected Steps per Second: 20,289.52946
Overall Steps per Second: 10,199.91940

Timestep Collection Time: 2.46492
Timestep Consumption Time: 2.43826
PPO Batch Consumption Time: 0.28970
Total Iteration Time: 4.90318

Cumulative Model Updates: 230,198
Cumulative Timesteps: 1,920,519,490

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77,273.40448
Policy Entropy: 2.12238
Value Function Loss: 0.02444

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.08422
Policy Update Magnitude: 0.31325
Value Function Update Magnitude: 0.35101

Collected Steps per Second: 18,709.33347
Overall Steps per Second: 10,025.20729

Timestep Collection Time: 2.67407
Timestep Consumption Time: 2.31635
PPO Batch Consumption Time: 0.27874
Total Iteration Time: 4.99042

Cumulative Model Updates: 230,204
Cumulative Timesteps: 1,920,569,520

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1920569520...
Checkpoint 1920569520 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 59,576.01160
Policy Entropy: 2.12155
Value Function Loss: 0.02158

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.07753
Policy Update Magnitude: 0.31042
Value Function Update Magnitude: 0.32688

Collected Steps per Second: 20,891.33727
Overall Steps per Second: 10,294.37089

Timestep Collection Time: 2.39420
Timestep Consumption Time: 2.46457
PPO Batch Consumption Time: 0.29355
Total Iteration Time: 4.85877

Cumulative Model Updates: 230,210
Cumulative Timesteps: 1,920,619,538

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47,511.71773
Policy Entropy: 2.11904
Value Function Loss: 0.02324

Mean KL Divergence: 0.00694
SB3 Clip Fraction: 0.06437
Policy Update Magnitude: 0.31381
Value Function Update Magnitude: 0.28325

Collected Steps per Second: 21,236.33370
Overall Steps per Second: 10,459.26648

Timestep Collection Time: 2.35521
Timestep Consumption Time: 2.42677
PPO Batch Consumption Time: 0.27884
Total Iteration Time: 4.78198

Cumulative Model Updates: 230,216
Cumulative Timesteps: 1,920,669,554

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1920669554...
Checkpoint 1920669554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,994.83661
Policy Entropy: 2.11903
Value Function Loss: 0.02516

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.06820
Policy Update Magnitude: 0.31596
Value Function Update Magnitude: 0.22833

Collected Steps per Second: 21,080.81561
Overall Steps per Second: 10,308.22053

Timestep Collection Time: 2.37372
Timestep Consumption Time: 2.48066
PPO Batch Consumption Time: 0.29176
Total Iteration Time: 4.85438

Cumulative Model Updates: 230,222
Cumulative Timesteps: 1,920,719,594

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,918.43607
Policy Entropy: 2.12085
Value Function Loss: 0.02596

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.07890
Policy Update Magnitude: 0.31218
Value Function Update Magnitude: 0.20943

Collected Steps per Second: 22,051.05118
Overall Steps per Second: 10,692.09824

Timestep Collection Time: 2.26747
Timestep Consumption Time: 2.40889
PPO Batch Consumption Time: 0.27915
Total Iteration Time: 4.67635

Cumulative Model Updates: 230,228
Cumulative Timesteps: 1,920,769,594

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1920769594...
Checkpoint 1920769594 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,221.70598
Policy Entropy: 2.12884
Value Function Loss: 0.02675

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.07846
Policy Update Magnitude: 0.31490
Value Function Update Magnitude: 0.29732

Collected Steps per Second: 21,422.33694
Overall Steps per Second: 10,407.26840

Timestep Collection Time: 2.33448
Timestep Consumption Time: 2.47082
PPO Batch Consumption Time: 0.29141
Total Iteration Time: 4.80530

Cumulative Model Updates: 230,234
Cumulative Timesteps: 1,920,819,604

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,797.07687
Policy Entropy: 2.11796
Value Function Loss: 0.02252

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.07734
Policy Update Magnitude: 0.31937
Value Function Update Magnitude: 0.33729

Collected Steps per Second: 22,134.01824
Overall Steps per Second: 10,653.34387

Timestep Collection Time: 2.25906
Timestep Consumption Time: 2.43449
PPO Batch Consumption Time: 0.27913
Total Iteration Time: 4.69355

Cumulative Model Updates: 230,240
Cumulative Timesteps: 1,920,869,606

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1920869606...
Checkpoint 1920869606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,445.80289
Policy Entropy: 2.10705
Value Function Loss: 0.02155

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.08206
Policy Update Magnitude: 0.31441
Value Function Update Magnitude: 0.33050

Collected Steps per Second: 21,523.40497
Overall Steps per Second: 10,198.47663

Timestep Collection Time: 2.32426
Timestep Consumption Time: 2.58098
PPO Batch Consumption Time: 0.30503
Total Iteration Time: 4.90524

Cumulative Model Updates: 230,246
Cumulative Timesteps: 1,920,919,632

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59,222.79562
Policy Entropy: 2.09367
Value Function Loss: 0.02349

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.07492
Policy Update Magnitude: 0.31606
Value Function Update Magnitude: 0.31614

Collected Steps per Second: 21,271.15381
Overall Steps per Second: 10,172.69529

Timestep Collection Time: 2.35211
Timestep Consumption Time: 2.56616
PPO Batch Consumption Time: 0.29786
Total Iteration Time: 4.91826

Cumulative Model Updates: 230,252
Cumulative Timesteps: 1,920,969,664

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1920969664...
Checkpoint 1920969664 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 61,762.65594
Policy Entropy: 2.09229
Value Function Loss: 0.02326

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.07512
Policy Update Magnitude: 0.32193
Value Function Update Magnitude: 0.33345

Collected Steps per Second: 21,279.77905
Overall Steps per Second: 10,310.63212

Timestep Collection Time: 2.35002
Timestep Consumption Time: 2.50011
PPO Batch Consumption Time: 0.29261
Total Iteration Time: 4.85014

Cumulative Model Updates: 230,258
Cumulative Timesteps: 1,921,019,672

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48,232.79289
Policy Entropy: 2.10372
Value Function Loss: 0.02517

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.08331
Policy Update Magnitude: 0.32192
Value Function Update Magnitude: 0.36708

Collected Steps per Second: 21,567.34865
Overall Steps per Second: 10,309.88891

Timestep Collection Time: 2.31897
Timestep Consumption Time: 2.53210
PPO Batch Consumption Time: 0.29254
Total Iteration Time: 4.85107

Cumulative Model Updates: 230,264
Cumulative Timesteps: 1,921,069,686

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1921069686...
Checkpoint 1921069686 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 52,836.88930
Policy Entropy: 2.10103
Value Function Loss: 0.02137

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.08054
Policy Update Magnitude: 0.31503
Value Function Update Magnitude: 0.35525

Collected Steps per Second: 21,231.09164
Overall Steps per Second: 10,225.69541

Timestep Collection Time: 2.35504
Timestep Consumption Time: 2.53461
PPO Batch Consumption Time: 0.29410
Total Iteration Time: 4.88964

Cumulative Model Updates: 230,270
Cumulative Timesteps: 1,921,119,686

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 72,885.64592
Policy Entropy: 2.09169
Value Function Loss: 0.02143

Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.07765
Policy Update Magnitude: 0.31021
Value Function Update Magnitude: 0.29761

Collected Steps per Second: 22,116.81882
Overall Steps per Second: 10,390.57142

Timestep Collection Time: 2.26118
Timestep Consumption Time: 2.55184
PPO Batch Consumption Time: 0.28923
Total Iteration Time: 4.81302

Cumulative Model Updates: 230,276
Cumulative Timesteps: 1,921,169,696

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1921169696...
Checkpoint 1921169696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,439.81885
Policy Entropy: 2.07749
Value Function Loss: 0.02299

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.07910
Policy Update Magnitude: 0.31642
Value Function Update Magnitude: 0.28342

Collected Steps per Second: 21,781.39006
Overall Steps per Second: 10,392.68854

Timestep Collection Time: 2.29636
Timestep Consumption Time: 2.51644
PPO Batch Consumption Time: 0.29018
Total Iteration Time: 4.81281

Cumulative Model Updates: 230,282
Cumulative Timesteps: 1,921,219,714

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82,420.90056
Policy Entropy: 2.08181
Value Function Loss: 0.02458

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.08656
Policy Update Magnitude: 0.32318
Value Function Update Magnitude: 0.31042

Collected Steps per Second: 21,940.55992
Overall Steps per Second: 10,387.57834

Timestep Collection Time: 2.27952
Timestep Consumption Time: 2.53527
PPO Batch Consumption Time: 0.29424
Total Iteration Time: 4.81479

Cumulative Model Updates: 230,288
Cumulative Timesteps: 1,921,269,728

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1921269728...
Checkpoint 1921269728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 52,026.13937
Policy Entropy: 2.08384
Value Function Loss: 0.02570

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.08050
Policy Update Magnitude: 0.32415
Value Function Update Magnitude: 0.36030

Collected Steps per Second: 21,677.21341
Overall Steps per Second: 10,518.34741

Timestep Collection Time: 2.30814
Timestep Consumption Time: 2.44869
PPO Batch Consumption Time: 0.28018
Total Iteration Time: 4.75683

Cumulative Model Updates: 230,294
Cumulative Timesteps: 1,921,319,762

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,590.30436
Policy Entropy: 2.10150
Value Function Loss: 0.02453

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.07550
Policy Update Magnitude: 0.32588
Value Function Update Magnitude: 0.39022

Collected Steps per Second: 21,997.61267
Overall Steps per Second: 10,502.90006

Timestep Collection Time: 2.27334
Timestep Consumption Time: 2.48801
PPO Batch Consumption Time: 0.28638
Total Iteration Time: 4.76135

Cumulative Model Updates: 230,300
Cumulative Timesteps: 1,921,369,770

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1921369770...
Checkpoint 1921369770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,225.16151
Policy Entropy: 2.12013
Value Function Loss: 0.02518

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.07107
Policy Update Magnitude: 0.32789
Value Function Update Magnitude: 0.40020

Collected Steps per Second: 21,717.25103
Overall Steps per Second: 10,549.20374

Timestep Collection Time: 2.30324
Timestep Consumption Time: 2.43835
PPO Batch Consumption Time: 0.27900
Total Iteration Time: 4.74159

Cumulative Model Updates: 230,306
Cumulative Timesteps: 1,921,419,790

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,886.28786
Policy Entropy: 2.12929
Value Function Loss: 0.02428

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.07988
Policy Update Magnitude: 0.32341
Value Function Update Magnitude: 0.40033

Collected Steps per Second: 21,677.13195
Overall Steps per Second: 10,516.89907

Timestep Collection Time: 2.30658
Timestep Consumption Time: 2.44767
PPO Batch Consumption Time: 0.27951
Total Iteration Time: 4.75425

Cumulative Model Updates: 230,312
Cumulative Timesteps: 1,921,469,790

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1921469790...
Checkpoint 1921469790 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,232.96376
Policy Entropy: 2.12374
Value Function Loss: 0.02295

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.08826
Policy Update Magnitude: 0.31169
Value Function Update Magnitude: 0.37181

Collected Steps per Second: 21,251.01813
Overall Steps per Second: 10,267.03299

Timestep Collection Time: 2.35320
Timestep Consumption Time: 2.51753
PPO Batch Consumption Time: 0.29447
Total Iteration Time: 4.87074

Cumulative Model Updates: 230,318
Cumulative Timesteps: 1,921,519,798

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,838.22700
Policy Entropy: 2.09827
Value Function Loss: 0.02379

Mean KL Divergence: 0.01341
SB3 Clip Fraction: 0.10770
Policy Update Magnitude: 0.31228
Value Function Update Magnitude: 0.33395

Collected Steps per Second: 21,171.58527
Overall Steps per Second: 10,222.62501

Timestep Collection Time: 2.36203
Timestep Consumption Time: 2.52986
PPO Batch Consumption Time: 0.29347
Total Iteration Time: 4.89189

Cumulative Model Updates: 230,324
Cumulative Timesteps: 1,921,569,806

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1921569806...
Checkpoint 1921569806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,029.37154
Policy Entropy: 2.10249
Value Function Loss: 0.02389

Mean KL Divergence: 0.01723
SB3 Clip Fraction: 0.12563
Policy Update Magnitude: 0.30345
Value Function Update Magnitude: 0.34235

Collected Steps per Second: 20,814.52562
Overall Steps per Second: 10,313.70843

Timestep Collection Time: 2.40294
Timestep Consumption Time: 2.44653
PPO Batch Consumption Time: 0.27923
Total Iteration Time: 4.84947

Cumulative Model Updates: 230,330
Cumulative Timesteps: 1,921,619,822

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,543.99014
Policy Entropy: 2.10879
Value Function Loss: 0.02311

Mean KL Divergence: 0.01680
SB3 Clip Fraction: 0.11917
Policy Update Magnitude: 0.29757
Value Function Update Magnitude: 0.34742

Collected Steps per Second: 21,234.92419
Overall Steps per Second: 10,450.12591

Timestep Collection Time: 2.35555
Timestep Consumption Time: 2.43099
PPO Batch Consumption Time: 0.27961
Total Iteration Time: 4.78655

Cumulative Model Updates: 230,336
Cumulative Timesteps: 1,921,669,842

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1921669842...
Checkpoint 1921669842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 64,334.20008
Policy Entropy: 2.12087
Value Function Loss: 0.02268

Mean KL Divergence: 0.01385
SB3 Clip Fraction: 0.11330
Policy Update Magnitude: 0.30946
Value Function Update Magnitude: 0.30225

Collected Steps per Second: 21,528.60127
Overall Steps per Second: 10,346.20830

Timestep Collection Time: 2.32351
Timestep Consumption Time: 2.51130
PPO Batch Consumption Time: 0.29432
Total Iteration Time: 4.83481

Cumulative Model Updates: 230,342
Cumulative Timesteps: 1,921,719,864

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66,242.89628
Policy Entropy: 2.10775
Value Function Loss: 0.02229

Mean KL Divergence: 0.01196
SB3 Clip Fraction: 0.10790
Policy Update Magnitude: 0.31017
Value Function Update Magnitude: 0.24747

Collected Steps per Second: 21,176.67947
Overall Steps per Second: 10,398.92265

Timestep Collection Time: 2.36213
Timestep Consumption Time: 2.44818
PPO Batch Consumption Time: 0.29039
Total Iteration Time: 4.81031

Cumulative Model Updates: 230,348
Cumulative Timesteps: 1,921,769,886

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1921769886...
Checkpoint 1921769886 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 63,256.62861
Policy Entropy: 2.08998
Value Function Loss: 0.02045

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.09617
Policy Update Magnitude: 0.30366
Value Function Update Magnitude: 0.27277

Collected Steps per Second: 21,182.72442
Overall Steps per Second: 10,533.22016

Timestep Collection Time: 2.36136
Timestep Consumption Time: 2.38743
PPO Batch Consumption Time: 0.28002
Total Iteration Time: 4.74879

Cumulative Model Updates: 230,354
Cumulative Timesteps: 1,921,819,906

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49,332.00184
Policy Entropy: 2.10027
Value Function Loss: 0.02467

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.08662
Policy Update Magnitude: 0.31546
Value Function Update Magnitude: 0.25767

Collected Steps per Second: 21,112.06923
Overall Steps per Second: 10,580.12191

Timestep Collection Time: 2.36841
Timestep Consumption Time: 2.35762
PPO Batch Consumption Time: 0.27854
Total Iteration Time: 4.72603

Cumulative Model Updates: 230,360
Cumulative Timesteps: 1,921,869,908

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1921869908...
Checkpoint 1921869908 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,920.03195
Policy Entropy: 2.11264
Value Function Loss: 0.02313

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.09315
Policy Update Magnitude: 0.31802
Value Function Update Magnitude: 0.25908

Collected Steps per Second: 21,155.76491
Overall Steps per Second: 10,332.56302

Timestep Collection Time: 2.36371
Timestep Consumption Time: 2.47595
PPO Batch Consumption Time: 0.29116
Total Iteration Time: 4.83965

Cumulative Model Updates: 230,366
Cumulative Timesteps: 1,921,919,914

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48,528.68079
Policy Entropy: 2.10722
Value Function Loss: 0.02589

Mean KL Divergence: 0.01124
SB3 Clip Fraction: 0.09117
Policy Update Magnitude: 0.33083
Value Function Update Magnitude: 0.27517

Collected Steps per Second: 21,975.94403
Overall Steps per Second: 10,646.68841

Timestep Collection Time: 2.27613
Timestep Consumption Time: 2.42205
PPO Batch Consumption Time: 0.28016
Total Iteration Time: 4.69817

Cumulative Model Updates: 230,372
Cumulative Timesteps: 1,921,969,934

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1921969934...
Checkpoint 1921969934 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47,344.38146
Policy Entropy: 2.11611
Value Function Loss: 0.02220

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.08516
Policy Update Magnitude: 0.32380
Value Function Update Magnitude: 0.31244

Collected Steps per Second: 21,592.29790
Overall Steps per Second: 10,451.35185

Timestep Collection Time: 2.31592
Timestep Consumption Time: 2.46873
PPO Batch Consumption Time: 0.29033
Total Iteration Time: 4.78464

Cumulative Model Updates: 230,378
Cumulative Timesteps: 1,922,019,940

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55,490.83307
Policy Entropy: 2.12381
Value Function Loss: 0.02523

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.08198
Policy Update Magnitude: 0.32291
Value Function Update Magnitude: 0.32002

Collected Steps per Second: 21,660.83560
Overall Steps per Second: 10,593.04238

Timestep Collection Time: 2.30850
Timestep Consumption Time: 2.41196
PPO Batch Consumption Time: 0.27952
Total Iteration Time: 4.72046

Cumulative Model Updates: 230,384
Cumulative Timesteps: 1,922,069,944

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1922069944...
Checkpoint 1922069944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,133.40595
Policy Entropy: 2.13512
Value Function Loss: 0.02501

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.08574
Policy Update Magnitude: 0.32497
Value Function Update Magnitude: 0.34203

Collected Steps per Second: 20,961.34822
Overall Steps per Second: 10,386.26538

Timestep Collection Time: 2.38639
Timestep Consumption Time: 2.42978
PPO Batch Consumption Time: 0.27829
Total Iteration Time: 4.81617

Cumulative Model Updates: 230,390
Cumulative Timesteps: 1,922,119,966

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81,384.73011
Policy Entropy: 2.14088
Value Function Loss: 0.02582

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.08507
Policy Update Magnitude: 0.32205
Value Function Update Magnitude: 0.34581

Collected Steps per Second: 21,382.29907
Overall Steps per Second: 10,450.89496

Timestep Collection Time: 2.33922
Timestep Consumption Time: 2.44678
PPO Batch Consumption Time: 0.27784
Total Iteration Time: 4.78600

Cumulative Model Updates: 230,396
Cumulative Timesteps: 1,922,169,984

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1922169984...
Checkpoint 1922169984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,486.62931
Policy Entropy: 2.13715
Value Function Loss: 0.02742

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.08825
Policy Update Magnitude: 0.32285
Value Function Update Magnitude: 0.32949

Collected Steps per Second: 21,001.13970
Overall Steps per Second: 10,042.14106

Timestep Collection Time: 2.38178
Timestep Consumption Time: 2.59923
PPO Batch Consumption Time: 0.30793
Total Iteration Time: 4.98101

Cumulative Model Updates: 230,402
Cumulative Timesteps: 1,922,220,004

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60,434.30902
Policy Entropy: 2.14825
Value Function Loss: 0.02600

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.08101
Policy Update Magnitude: 0.32501
Value Function Update Magnitude: 0.35046

Collected Steps per Second: 21,365.41299
Overall Steps per Second: 10,288.21518

Timestep Collection Time: 2.34210
Timestep Consumption Time: 2.52171
PPO Batch Consumption Time: 0.29011
Total Iteration Time: 4.86382

Cumulative Model Updates: 230,408
Cumulative Timesteps: 1,922,270,044

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1922270044...
Checkpoint 1922270044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43,620.36487
Policy Entropy: 2.13794
Value Function Loss: 0.02538

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.07797
Policy Update Magnitude: 0.32336
Value Function Update Magnitude: 0.37266

Collected Steps per Second: 21,516.65762
Overall Steps per Second: 10,441.54486

Timestep Collection Time: 2.32434
Timestep Consumption Time: 2.46537
PPO Batch Consumption Time: 0.28050
Total Iteration Time: 4.78971

Cumulative Model Updates: 230,414
Cumulative Timesteps: 1,922,320,056

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49,527.27181
Policy Entropy: 2.11488
Value Function Loss: 0.02256

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.07880
Policy Update Magnitude: 0.31918
Value Function Update Magnitude: 0.38175

Collected Steps per Second: 21,648.88488
Overall Steps per Second: 10,443.20728

Timestep Collection Time: 2.31060
Timestep Consumption Time: 2.47930
PPO Batch Consumption Time: 0.28002
Total Iteration Time: 4.78991

Cumulative Model Updates: 230,420
Cumulative Timesteps: 1,922,370,078

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1922370078...
Checkpoint 1922370078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,782.26294
Policy Entropy: 2.10708
Value Function Loss: 0.02605

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.07925
Policy Update Magnitude: 0.32849
Value Function Update Magnitude: 0.37665

Collected Steps per Second: 21,806.70542
Overall Steps per Second: 10,419.79045

Timestep Collection Time: 2.29397
Timestep Consumption Time: 2.50689
PPO Batch Consumption Time: 0.28959
Total Iteration Time: 4.80086

Cumulative Model Updates: 230,426
Cumulative Timesteps: 1,922,420,102

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59,960.54048
Policy Entropy: 2.09426
Value Function Loss: 0.02671

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.08024
Policy Update Magnitude: 0.33621
Value Function Update Magnitude: 0.38747

Collected Steps per Second: 21,928.94648
Overall Steps per Second: 10,462.95248

Timestep Collection Time: 2.28018
Timestep Consumption Time: 2.49877
PPO Batch Consumption Time: 0.29058
Total Iteration Time: 4.77896

Cumulative Model Updates: 230,432
Cumulative Timesteps: 1,922,470,104

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1922470104...
Checkpoint 1922470104 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40,860.13274
Policy Entropy: 2.11445
Value Function Loss: 0.02740

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.08172
Policy Update Magnitude: 0.33197
Value Function Update Magnitude: 0.41997

Collected Steps per Second: 21,827.24731
Overall Steps per Second: 10,425.54967

Timestep Collection Time: 2.29273
Timestep Consumption Time: 2.50740
PPO Batch Consumption Time: 0.29018
Total Iteration Time: 4.80013

Cumulative Model Updates: 230,438
Cumulative Timesteps: 1,922,520,148

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,806.32891
Policy Entropy: 2.11692
Value Function Loss: 0.02633

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.08243
Policy Update Magnitude: 0.33951
Value Function Update Magnitude: 0.42676

Collected Steps per Second: 21,980.20507
Overall Steps per Second: 10,488.12523

Timestep Collection Time: 2.27523
Timestep Consumption Time: 2.49302
PPO Batch Consumption Time: 0.29001
Total Iteration Time: 4.76825

Cumulative Model Updates: 230,444
Cumulative Timesteps: 1,922,570,158

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1922570158...
Checkpoint 1922570158 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,147.09620
Policy Entropy: 2.12171
Value Function Loss: 0.02529

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.08245
Policy Update Magnitude: 0.34102
Value Function Update Magnitude: 0.42694

Collected Steps per Second: 21,728.96415
Overall Steps per Second: 10,575.74024

Timestep Collection Time: 2.30301
Timestep Consumption Time: 2.42876
PPO Batch Consumption Time: 0.27895
Total Iteration Time: 4.73177

Cumulative Model Updates: 230,450
Cumulative Timesteps: 1,922,620,200

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,103.98660
Policy Entropy: 2.12125
Value Function Loss: 0.02459

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.08090
Policy Update Magnitude: 0.32987
Value Function Update Magnitude: 0.41699

Collected Steps per Second: 21,868.63472
Overall Steps per Second: 10,566.07174

Timestep Collection Time: 2.28839
Timestep Consumption Time: 2.44790
PPO Batch Consumption Time: 0.27859
Total Iteration Time: 4.73629

Cumulative Model Updates: 230,456
Cumulative Timesteps: 1,922,670,244

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1922670244...
Checkpoint 1922670244 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,673.52260
Policy Entropy: 2.11252
Value Function Loss: 0.02262

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.08162
Policy Update Magnitude: 0.31655
Value Function Update Magnitude: 0.38117

Collected Steps per Second: 21,338.76214
Overall Steps per Second: 10,353.62435

Timestep Collection Time: 2.34522
Timestep Consumption Time: 2.48826
PPO Batch Consumption Time: 0.29100
Total Iteration Time: 4.83348

Cumulative Model Updates: 230,462
Cumulative Timesteps: 1,922,720,288

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42,655.34971
Policy Entropy: 2.11643
Value Function Loss: 0.02224

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.07840
Policy Update Magnitude: 0.30775
Value Function Update Magnitude: 0.34435

Collected Steps per Second: 21,411.84686
Overall Steps per Second: 10,307.84632

Timestep Collection Time: 2.33553
Timestep Consumption Time: 2.51592
PPO Batch Consumption Time: 0.29435
Total Iteration Time: 4.85145

Cumulative Model Updates: 230,468
Cumulative Timesteps: 1,922,770,296

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1922770296...
Checkpoint 1922770296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,231.11634
Policy Entropy: 2.11232
Value Function Loss: 0.02254

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.07555
Policy Update Magnitude: 0.30756
Value Function Update Magnitude: 0.32061

Collected Steps per Second: 20,367.02933
Overall Steps per Second: 10,206.09507

Timestep Collection Time: 2.45505
Timestep Consumption Time: 2.44418
PPO Batch Consumption Time: 0.29467
Total Iteration Time: 4.89923

Cumulative Model Updates: 230,474
Cumulative Timesteps: 1,922,820,298

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,373.38172
Policy Entropy: 2.10575
Value Function Loss: 0.02409

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.07286
Policy Update Magnitude: 0.31753
Value Function Update Magnitude: 0.32408

Collected Steps per Second: 20,891.79937
Overall Steps per Second: 10,194.74868

Timestep Collection Time: 2.39462
Timestep Consumption Time: 2.51261
PPO Batch Consumption Time: 0.30328
Total Iteration Time: 4.90723

Cumulative Model Updates: 230,480
Cumulative Timesteps: 1,922,870,326

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1922870326...
Checkpoint 1922870326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,471.21173
Policy Entropy: 2.09799
Value Function Loss: 0.02474

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.07175
Policy Update Magnitude: 0.32550
Value Function Update Magnitude: 0.33126

Collected Steps per Second: 20,594.20551
Overall Steps per Second: 10,475.27461

Timestep Collection Time: 2.42991
Timestep Consumption Time: 2.34725
PPO Batch Consumption Time: 0.27864
Total Iteration Time: 4.77715

Cumulative Model Updates: 230,486
Cumulative Timesteps: 1,922,920,368

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,341.98212
Policy Entropy: 2.09380
Value Function Loss: 0.02379

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.07514
Policy Update Magnitude: 0.32227
Value Function Update Magnitude: 0.33989

Collected Steps per Second: 21,176.15764
Overall Steps per Second: 10,412.30358

Timestep Collection Time: 2.36237
Timestep Consumption Time: 2.44213
PPO Batch Consumption Time: 0.28918
Total Iteration Time: 4.80451

Cumulative Model Updates: 230,492
Cumulative Timesteps: 1,922,970,394

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1922970394...
Checkpoint 1922970394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,811.09656
Policy Entropy: 2.08983
Value Function Loss: 0.02139

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.07636
Policy Update Magnitude: 0.31730
Value Function Update Magnitude: 0.33831

Collected Steps per Second: 21,037.17107
Overall Steps per Second: 10,179.55221

Timestep Collection Time: 2.37713
Timestep Consumption Time: 2.53547
PPO Batch Consumption Time: 0.29417
Total Iteration Time: 4.91259

Cumulative Model Updates: 230,498
Cumulative Timesteps: 1,923,020,402

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,324.75779
Policy Entropy: 2.10203
Value Function Loss: 0.02106

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.07748
Policy Update Magnitude: 0.31037
Value Function Update Magnitude: 0.33314

Collected Steps per Second: 21,858.09921
Overall Steps per Second: 10,440.97619

Timestep Collection Time: 2.28895
Timestep Consumption Time: 2.50294
PPO Batch Consumption Time: 0.29237
Total Iteration Time: 4.79189

Cumulative Model Updates: 230,504
Cumulative Timesteps: 1,923,070,434

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1923070434...
Checkpoint 1923070434 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,411.04617
Policy Entropy: 2.09873
Value Function Loss: 0.02085

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.07650
Policy Update Magnitude: 0.31394
Value Function Update Magnitude: 0.32309

Collected Steps per Second: 21,693.53101
Overall Steps per Second: 10,580.28902

Timestep Collection Time: 2.30566
Timestep Consumption Time: 2.42181
PPO Batch Consumption Time: 0.28060
Total Iteration Time: 4.72747

Cumulative Model Updates: 230,510
Cumulative Timesteps: 1,923,120,452

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57,995.59650
Policy Entropy: 2.10044
Value Function Loss: 0.02092

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.07341
Policy Update Magnitude: 0.30776
Value Function Update Magnitude: 0.31384

Collected Steps per Second: 21,542.60451
Overall Steps per Second: 10,498.99930

Timestep Collection Time: 2.32163
Timestep Consumption Time: 2.44206
PPO Batch Consumption Time: 0.27986
Total Iteration Time: 4.76369

Cumulative Model Updates: 230,516
Cumulative Timesteps: 1,923,170,466

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1923170466...
Checkpoint 1923170466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48,156.13032
Policy Entropy: 2.09818
Value Function Loss: 0.02076

Mean KL Divergence: 0.00777
SB3 Clip Fraction: 0.06990
Policy Update Magnitude: 0.30463
Value Function Update Magnitude: 0.31634

Collected Steps per Second: 21,489.56042
Overall Steps per Second: 10,288.01695

Timestep Collection Time: 2.32718
Timestep Consumption Time: 2.53382
PPO Batch Consumption Time: 0.29698
Total Iteration Time: 4.86100

Cumulative Model Updates: 230,522
Cumulative Timesteps: 1,923,220,476

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45,923.76154
Policy Entropy: 2.08626
Value Function Loss: 0.02251

Mean KL Divergence: 0.00753
SB3 Clip Fraction: 0.07090
Policy Update Magnitude: 0.31237
Value Function Update Magnitude: 0.31630

Collected Steps per Second: 21,904.68864
Overall Steps per Second: 10,401.67385

Timestep Collection Time: 2.28399
Timestep Consumption Time: 2.52582
PPO Batch Consumption Time: 0.29363
Total Iteration Time: 4.80980

Cumulative Model Updates: 230,528
Cumulative Timesteps: 1,923,270,506

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1923270506...
Checkpoint 1923270506 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,623.78925
Policy Entropy: 2.09226
Value Function Loss: 0.02268

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.07119
Policy Update Magnitude: 0.32038
Value Function Update Magnitude: 0.33758

Collected Steps per Second: 21,260.62808
Overall Steps per Second: 10,285.52320

Timestep Collection Time: 2.35289
Timestep Consumption Time: 2.51064
PPO Batch Consumption Time: 0.29392
Total Iteration Time: 4.86353

Cumulative Model Updates: 230,534
Cumulative Timesteps: 1,923,320,530

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,358.87269
Policy Entropy: 2.09173
Value Function Loss: 0.02617

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.07849
Policy Update Magnitude: 0.32753
Value Function Update Magnitude: 0.34536

Collected Steps per Second: 21,630.11168
Overall Steps per Second: 10,454.94370

Timestep Collection Time: 2.31215
Timestep Consumption Time: 2.47143
PPO Batch Consumption Time: 0.27830
Total Iteration Time: 4.78357

Cumulative Model Updates: 230,540
Cumulative Timesteps: 1,923,370,542

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1923370542...
Checkpoint 1923370542 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40,567.35545
Policy Entropy: 2.11173
Value Function Loss: 0.02505

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.07372
Policy Update Magnitude: 0.32890
Value Function Update Magnitude: 0.36534

Collected Steps per Second: 21,315.02550
Overall Steps per Second: 10,312.62508

Timestep Collection Time: 2.34642
Timestep Consumption Time: 2.50336
PPO Batch Consumption Time: 0.29153
Total Iteration Time: 4.84978

Cumulative Model Updates: 230,546
Cumulative Timesteps: 1,923,420,556

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,939.95223
Policy Entropy: 2.10633
Value Function Loss: 0.02441

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.07173
Policy Update Magnitude: 0.32226
Value Function Update Magnitude: 0.38649

Collected Steps per Second: 21,494.90757
Overall Steps per Second: 10,278.73697

Timestep Collection Time: 2.32725
Timestep Consumption Time: 2.53950
PPO Batch Consumption Time: 0.29605
Total Iteration Time: 4.86675

Cumulative Model Updates: 230,552
Cumulative Timesteps: 1,923,470,580

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1923470580...
Checkpoint 1923470580 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 65,352.28157
Policy Entropy: 2.11381
Value Function Loss: 0.02280

Mean KL Divergence: 0.00753
SB3 Clip Fraction: 0.07091
Policy Update Magnitude: 0.32142
Value Function Update Magnitude: 0.39216

Collected Steps per Second: 20,945.45803
Overall Steps per Second: 10,206.12055

Timestep Collection Time: 2.38839
Timestep Consumption Time: 2.51317
PPO Batch Consumption Time: 0.28406
Total Iteration Time: 4.90157

Cumulative Model Updates: 230,558
Cumulative Timesteps: 1,923,520,606

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54,482.05763
Policy Entropy: 2.12106
Value Function Loss: 0.02378

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.07652
Policy Update Magnitude: 0.31757
Value Function Update Magnitude: 0.37381

Collected Steps per Second: 21,704.56713
Overall Steps per Second: 10,462.28261

Timestep Collection Time: 2.30422
Timestep Consumption Time: 2.47600
PPO Batch Consumption Time: 0.27995
Total Iteration Time: 4.78022

Cumulative Model Updates: 230,564
Cumulative Timesteps: 1,923,570,618

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1923570618...
Checkpoint 1923570618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,727.41657
Policy Entropy: 2.13021
Value Function Loss: 0.02472

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.07715
Policy Update Magnitude: 0.31752
Value Function Update Magnitude: 0.36478

Collected Steps per Second: 21,669.20186
Overall Steps per Second: 10,356.60543

Timestep Collection Time: 2.30798
Timestep Consumption Time: 2.52102
PPO Batch Consumption Time: 0.29229
Total Iteration Time: 4.82900

Cumulative Model Updates: 230,570
Cumulative Timesteps: 1,923,620,630

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61,399.67016
Policy Entropy: 2.12575
Value Function Loss: 0.02415

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.07949
Policy Update Magnitude: 0.31794
Value Function Update Magnitude: 0.34436

Collected Steps per Second: 21,930.25434
Overall Steps per Second: 10,403.81161

Timestep Collection Time: 2.28087
Timestep Consumption Time: 2.52699
PPO Batch Consumption Time: 0.29348
Total Iteration Time: 4.80785

Cumulative Model Updates: 230,576
Cumulative Timesteps: 1,923,670,650

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1923670650...
Checkpoint 1923670650 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 62,407.25298
Policy Entropy: 2.12183
Value Function Loss: 0.02432

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.08267
Policy Update Magnitude: 0.32358
Value Function Update Magnitude: 0.33507

Collected Steps per Second: 21,703.12391
Overall Steps per Second: 10,520.76548

Timestep Collection Time: 2.30520
Timestep Consumption Time: 2.45016
PPO Batch Consumption Time: 0.28086
Total Iteration Time: 4.75536

Cumulative Model Updates: 230,582
Cumulative Timesteps: 1,923,720,680

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51,883.66626
Policy Entropy: 2.12314
Value Function Loss: 0.02408

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.08205
Policy Update Magnitude: 0.32449
Value Function Update Magnitude: 0.33307

Collected Steps per Second: 21,347.33698
Overall Steps per Second: 10,466.43976

Timestep Collection Time: 2.34240
Timestep Consumption Time: 2.43516
PPO Batch Consumption Time: 0.29204
Total Iteration Time: 4.77756

Cumulative Model Updates: 230,588
Cumulative Timesteps: 1,923,770,684

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1923770684...
Checkpoint 1923770684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 57,103.99295
Policy Entropy: 2.12807
Value Function Loss: 0.02345

Mean KL Divergence: 0.01071
SB3 Clip Fraction: 0.08405
Policy Update Magnitude: 0.32377
Value Function Update Magnitude: 0.36720

Collected Steps per Second: 21,120.85450
Overall Steps per Second: 10,565.04397

Timestep Collection Time: 2.36818
Timestep Consumption Time: 2.36611
PPO Batch Consumption Time: 0.27964
Total Iteration Time: 4.73429

Cumulative Model Updates: 230,594
Cumulative Timesteps: 1,923,820,702

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46,433.01475
Policy Entropy: 2.13106
Value Function Loss: 0.02206

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.09020
Policy Update Magnitude: 0.31514
Value Function Update Magnitude: 0.36252

Collected Steps per Second: 21,246.90592
Overall Steps per Second: 10,496.89639

Timestep Collection Time: 2.35441
Timestep Consumption Time: 2.41119
PPO Batch Consumption Time: 0.28705
Total Iteration Time: 4.76560

Cumulative Model Updates: 230,600
Cumulative Timesteps: 1,923,870,726

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1923870726...
Checkpoint 1923870726 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,534.06088
Policy Entropy: 2.11474
Value Function Loss: 0.02276

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.08585
Policy Update Magnitude: 0.31182
Value Function Update Magnitude: 0.34110

Collected Steps per Second: 20,950.91009
Overall Steps per Second: 10,208.26272

Timestep Collection Time: 2.38720
Timestep Consumption Time: 2.51217
PPO Batch Consumption Time: 0.29255
Total Iteration Time: 4.89936

Cumulative Model Updates: 230,606
Cumulative Timesteps: 1,923,920,740

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47,209.98285
Policy Entropy: 2.10203
Value Function Loss: 0.02277

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.08049
Policy Update Magnitude: 0.31394
Value Function Update Magnitude: 0.31768

Collected Steps per Second: 21,215.64357
Overall Steps per Second: 10,462.61338

Timestep Collection Time: 2.35835
Timestep Consumption Time: 2.42382
PPO Batch Consumption Time: 0.27961
Total Iteration Time: 4.78217

Cumulative Model Updates: 230,612
Cumulative Timesteps: 1,923,970,774

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1923970774...
Checkpoint 1923970774 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,637.97268
Policy Entropy: 2.11027
Value Function Loss: 0.02164

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.07460
Policy Update Magnitude: 0.31236
Value Function Update Magnitude: 0.30205

Collected Steps per Second: 21,245.43345
Overall Steps per Second: 10,356.27972

Timestep Collection Time: 2.35364
Timestep Consumption Time: 2.47474
PPO Batch Consumption Time: 0.29247
Total Iteration Time: 4.82837

Cumulative Model Updates: 230,618
Cumulative Timesteps: 1,924,020,778

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,254.26939
Policy Entropy: 2.11939
Value Function Loss: 0.01875

Mean KL Divergence: 0.00700
SB3 Clip Fraction: 0.06427
Policy Update Magnitude: 0.29959
Value Function Update Magnitude: 0.28433

Collected Steps per Second: 21,496.62197
Overall Steps per Second: 10,332.35238

Timestep Collection Time: 2.32781
Timestep Consumption Time: 2.51523
PPO Batch Consumption Time: 0.29341
Total Iteration Time: 4.84304

Cumulative Model Updates: 230,624
Cumulative Timesteps: 1,924,070,818

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1924070818...
Checkpoint 1924070818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,380.57813
Policy Entropy: 2.12800
Value Function Loss: 0.01909

Mean KL Divergence: 0.00701
SB3 Clip Fraction: 0.06317
Policy Update Magnitude: 0.29948
Value Function Update Magnitude: 0.27531

Collected Steps per Second: 21,369.15171
Overall Steps per Second: 10,322.17678

Timestep Collection Time: 2.34207
Timestep Consumption Time: 2.50652
PPO Batch Consumption Time: 0.29161
Total Iteration Time: 4.84859

Cumulative Model Updates: 230,630
Cumulative Timesteps: 1,924,120,866

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47,515.05840
Policy Entropy: 2.12658
Value Function Loss: 0.02069

Mean KL Divergence: 0.00673
SB3 Clip Fraction: 0.06485
Policy Update Magnitude: 0.30494
Value Function Update Magnitude: 0.25884

Collected Steps per Second: 21,909.50209
Overall Steps per Second: 10,326.67746

Timestep Collection Time: 2.28239
Timestep Consumption Time: 2.56002
PPO Batch Consumption Time: 0.29548
Total Iteration Time: 4.84241

Cumulative Model Updates: 230,636
Cumulative Timesteps: 1,924,170,872

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1924170872...
Checkpoint 1924170872 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,835.66612
Policy Entropy: 2.12743
Value Function Loss: 0.02320

Mean KL Divergence: 0.00736
SB3 Clip Fraction: 0.06823
Policy Update Magnitude: 0.30961
Value Function Update Magnitude: 0.32426

Collected Steps per Second: 21,439.10197
Overall Steps per Second: 10,241.38650

Timestep Collection Time: 2.33321
Timestep Consumption Time: 2.55109
PPO Batch Consumption Time: 0.29395
Total Iteration Time: 4.88430

Cumulative Model Updates: 230,642
Cumulative Timesteps: 1,924,220,894

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,801.62441
Policy Entropy: 2.12525
Value Function Loss: 0.02736

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.07210
Policy Update Magnitude: 0.32623
Value Function Update Magnitude: 0.37922

Collected Steps per Second: 21,616.89089
Overall Steps per Second: 10,471.91290

Timestep Collection Time: 2.31402
Timestep Consumption Time: 2.46275
PPO Batch Consumption Time: 0.27908
Total Iteration Time: 4.77678

Cumulative Model Updates: 230,648
Cumulative Timesteps: 1,924,270,916

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1924270916...
Checkpoint 1924270916 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,421.14896
Policy Entropy: 2.12148
Value Function Loss: 0.02491

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.07643
Policy Update Magnitude: 0.33029
Value Function Update Magnitude: 0.36178

Collected Steps per Second: 21,624.23035
Overall Steps per Second: 10,501.79264

Timestep Collection Time: 2.31241
Timestep Consumption Time: 2.44907
PPO Batch Consumption Time: 0.28019
Total Iteration Time: 4.76147

Cumulative Model Updates: 230,654
Cumulative Timesteps: 1,924,320,920

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,399.49777
Policy Entropy: 2.11834
Value Function Loss: 0.02535

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.07922
Policy Update Magnitude: 0.32407
Value Function Update Magnitude: 0.36357

Collected Steps per Second: 21,839.26134
Overall Steps per Second: 10,589.73058

Timestep Collection Time: 2.28955
Timestep Consumption Time: 2.43220
PPO Batch Consumption Time: 0.27886
Total Iteration Time: 4.72174

Cumulative Model Updates: 230,660
Cumulative Timesteps: 1,924,370,922

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1924370922...
Checkpoint 1924370922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,301.60411
Policy Entropy: 2.11311
Value Function Loss: 0.02436

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.07420
Policy Update Magnitude: 0.33454
Value Function Update Magnitude: 0.39554

Collected Steps per Second: 21,690.87716
Overall Steps per Second: 10,517.92230

Timestep Collection Time: 2.30604
Timestep Consumption Time: 2.44965
PPO Batch Consumption Time: 0.28035
Total Iteration Time: 4.75569

Cumulative Model Updates: 230,666
Cumulative Timesteps: 1,924,420,942

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,669.49281
Policy Entropy: 2.11560
Value Function Loss: 0.02558

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.07899
Policy Update Magnitude: 0.32380
Value Function Update Magnitude: 0.43051

Collected Steps per Second: 21,829.33170
Overall Steps per Second: 10,586.56909

Timestep Collection Time: 2.29077
Timestep Consumption Time: 2.43276
PPO Batch Consumption Time: 0.27865
Total Iteration Time: 4.72353

Cumulative Model Updates: 230,672
Cumulative Timesteps: 1,924,470,948

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1924470948...
Checkpoint 1924470948 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 64,518.22382
Policy Entropy: 2.11640
Value Function Loss: 0.02450

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.07625
Policy Update Magnitude: 0.32669
Value Function Update Magnitude: 0.45017

Collected Steps per Second: 21,844.64493
Overall Steps per Second: 10,604.29712

Timestep Collection Time: 2.28907
Timestep Consumption Time: 2.42637
PPO Batch Consumption Time: 0.27889
Total Iteration Time: 4.71545

Cumulative Model Updates: 230,678
Cumulative Timesteps: 1,924,520,952

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49,580.49517
Policy Entropy: 2.11156
Value Function Loss: 0.02222

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.07610
Policy Update Magnitude: 0.32974
Value Function Update Magnitude: 0.42104

Collected Steps per Second: 21,316.16629
Overall Steps per Second: 10,463.04081

Timestep Collection Time: 2.34620
Timestep Consumption Time: 2.43367
PPO Batch Consumption Time: 0.27869
Total Iteration Time: 4.77987

Cumulative Model Updates: 230,684
Cumulative Timesteps: 1,924,570,964

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1924570964...
Checkpoint 1924570964 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,548.12462
Policy Entropy: 2.10510
Value Function Loss: 0.02019

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.07770
Policy Update Magnitude: 0.31463
Value Function Update Magnitude: 0.37869

Collected Steps per Second: 20,808.08401
Overall Steps per Second: 10,522.91490

Timestep Collection Time: 2.40378
Timestep Consumption Time: 2.34947
PPO Batch Consumption Time: 0.27904
Total Iteration Time: 4.75325

Cumulative Model Updates: 230,690
Cumulative Timesteps: 1,924,620,982

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42,490.16746
Policy Entropy: 2.10235
Value Function Loss: 0.02098

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.08112
Policy Update Magnitude: 0.31316
Value Function Update Magnitude: 0.35379

Collected Steps per Second: 20,530.90984
Overall Steps per Second: 10,284.16921

Timestep Collection Time: 2.43623
Timestep Consumption Time: 2.42736
PPO Batch Consumption Time: 0.29057
Total Iteration Time: 4.86359

Cumulative Model Updates: 230,696
Cumulative Timesteps: 1,924,671,000

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1924671000...
Checkpoint 1924671000 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 58,867.53104
Policy Entropy: 2.12566
Value Function Loss: 0.02249

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.08442
Policy Update Magnitude: 0.31656
Value Function Update Magnitude: 0.34999

Collected Steps per Second: 20,546.32722
Overall Steps per Second: 10,433.16841

Timestep Collection Time: 2.43411
Timestep Consumption Time: 2.35945
PPO Batch Consumption Time: 0.27986
Total Iteration Time: 4.79356

Cumulative Model Updates: 230,702
Cumulative Timesteps: 1,924,721,012

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45,040.50282
Policy Entropy: 2.13562
Value Function Loss: 0.02370

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.07973
Policy Update Magnitude: 0.31736
Value Function Update Magnitude: 0.33080

Collected Steps per Second: 21,180.01091
Overall Steps per Second: 10,419.29212

Timestep Collection Time: 2.36091
Timestep Consumption Time: 2.43827
PPO Batch Consumption Time: 0.27999
Total Iteration Time: 4.79917

Cumulative Model Updates: 230,708
Cumulative Timesteps: 1,924,771,016

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1924771016...
Checkpoint 1924771016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47,271.91768
Policy Entropy: 2.14917
Value Function Loss: 0.02388

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.07882
Policy Update Magnitude: 0.31135
Value Function Update Magnitude: 0.31530

Collected Steps per Second: 21,244.99637
Overall Steps per Second: 10,189.29609

Timestep Collection Time: 2.35481
Timestep Consumption Time: 2.55505
PPO Batch Consumption Time: 0.29352
Total Iteration Time: 4.90986

Cumulative Model Updates: 230,714
Cumulative Timesteps: 1,924,821,044

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49,470.55662
Policy Entropy: 2.16623
Value Function Loss: 0.02047

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.07677
Policy Update Magnitude: 0.30021
Value Function Update Magnitude: 0.31693

Collected Steps per Second: 21,360.13065
Overall Steps per Second: 10,451.46289

Timestep Collection Time: 2.34268
Timestep Consumption Time: 2.44516
PPO Batch Consumption Time: 0.27999
Total Iteration Time: 4.78785

Cumulative Model Updates: 230,720
Cumulative Timesteps: 1,924,871,084

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1924871084...
Checkpoint 1924871084 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 50,453.66487
Policy Entropy: 2.15843
Value Function Loss: 0.01930

Mean KL Divergence: 0.00783
SB3 Clip Fraction: 0.06992
Policy Update Magnitude: 0.29194
Value Function Update Magnitude: 0.31610

Collected Steps per Second: 21,643.62406
Overall Steps per Second: 10,449.26712

Timestep Collection Time: 2.31227
Timestep Consumption Time: 2.47715
PPO Batch Consumption Time: 0.29041
Total Iteration Time: 4.78943

Cumulative Model Updates: 230,726
Cumulative Timesteps: 1,924,921,130

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63,564.22875
Policy Entropy: 2.15739
Value Function Loss: 0.01892

Mean KL Divergence: 0.00694
SB3 Clip Fraction: 0.06675
Policy Update Magnitude: 0.29294
Value Function Update Magnitude: 0.31031

Collected Steps per Second: 21,943.13483
Overall Steps per Second: 10,474.58292

Timestep Collection Time: 2.27944
Timestep Consumption Time: 2.49574
PPO Batch Consumption Time: 0.29050
Total Iteration Time: 4.77518

Cumulative Model Updates: 230,732
Cumulative Timesteps: 1,924,971,148

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1924971148...
Checkpoint 1924971148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 75,010.27860
Policy Entropy: 2.12799
Value Function Loss: 0.02079

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.07506
Policy Update Magnitude: 0.30458
Value Function Update Magnitude: 0.31879

Collected Steps per Second: 20,125.25177
Overall Steps per Second: 9,976.60492

Timestep Collection Time: 2.48563
Timestep Consumption Time: 2.52850
PPO Batch Consumption Time: 0.29038
Total Iteration Time: 5.01413

Cumulative Model Updates: 230,738
Cumulative Timesteps: 1,925,021,172

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57,930.81546
Policy Entropy: 2.14471
Value Function Loss: 0.02152

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.06995
Policy Update Magnitude: 0.31522
Value Function Update Magnitude: 0.34845

Collected Steps per Second: 21,846.20771
Overall Steps per Second: 10,567.41270

Timestep Collection Time: 2.28882
Timestep Consumption Time: 2.44290
PPO Batch Consumption Time: 0.27872
Total Iteration Time: 4.73172

Cumulative Model Updates: 230,744
Cumulative Timesteps: 1,925,071,174

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1925071174...
Checkpoint 1925071174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 77,196.72598
Policy Entropy: 2.15385
Value Function Loss: 0.01892

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.06671
Policy Update Magnitude: 0.30427
Value Function Update Magnitude: 0.33122

Collected Steps per Second: 21,851.31588
Overall Steps per Second: 10,570.57605

Timestep Collection Time: 2.28847
Timestep Consumption Time: 2.44221
PPO Batch Consumption Time: 0.27964
Total Iteration Time: 4.73068

Cumulative Model Updates: 230,750
Cumulative Timesteps: 1,925,121,180

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60,486.89329
Policy Entropy: 2.15819
Value Function Loss: 0.01965

Mean KL Divergence: 0.00759
SB3 Clip Fraction: 0.06253
Policy Update Magnitude: 0.29819
Value Function Update Magnitude: 0.29435

Collected Steps per Second: 21,963.10237
Overall Steps per Second: 10,473.12663

Timestep Collection Time: 2.27682
Timestep Consumption Time: 2.49788
PPO Batch Consumption Time: 0.28768
Total Iteration Time: 4.77470

Cumulative Model Updates: 230,756
Cumulative Timesteps: 1,925,171,186

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1925171186...
Checkpoint 1925171186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 53,833.78114
Policy Entropy: 2.14808
Value Function Loss: 0.02071

Mean KL Divergence: 0.00681
SB3 Clip Fraction: 0.06494
Policy Update Magnitude: 0.30714
Value Function Update Magnitude: 0.31140

Collected Steps per Second: 21,042.69942
Overall Steps per Second: 10,198.33144

Timestep Collection Time: 2.37612
Timestep Consumption Time: 2.52664
PPO Batch Consumption Time: 0.29305
Total Iteration Time: 4.90276

Cumulative Model Updates: 230,762
Cumulative Timesteps: 1,925,221,186

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,608.67957
Policy Entropy: 2.14021
Value Function Loss: 0.02259

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.07106
Policy Update Magnitude: 0.31215
Value Function Update Magnitude: 0.34030

Collected Steps per Second: 21,488.01288
Overall Steps per Second: 10,456.99288

Timestep Collection Time: 2.32697
Timestep Consumption Time: 2.45471
PPO Batch Consumption Time: 0.28048
Total Iteration Time: 4.78168

Cumulative Model Updates: 230,768
Cumulative Timesteps: 1,925,271,188

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1925271188...
Checkpoint 1925271188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,030.16453
Policy Entropy: 2.13830
Value Function Loss: 0.02337

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.07418
Policy Update Magnitude: 0.31822
Value Function Update Magnitude: 0.37345

Collected Steps per Second: 21,145.53047
Overall Steps per Second: 10,223.50658

Timestep Collection Time: 2.36504
Timestep Consumption Time: 2.52663
PPO Batch Consumption Time: 0.29514
Total Iteration Time: 4.89167

Cumulative Model Updates: 230,774
Cumulative Timesteps: 1,925,321,198

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,988.76942
Policy Entropy: 2.14298
Value Function Loss: 0.02257

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.07984
Policy Update Magnitude: 0.31621
Value Function Update Magnitude: 0.36110

Collected Steps per Second: 21,496.10502
Overall Steps per Second: 10,486.89321

Timestep Collection Time: 2.32721
Timestep Consumption Time: 2.44312
PPO Batch Consumption Time: 0.27813
Total Iteration Time: 4.77034

Cumulative Model Updates: 230,780
Cumulative Timesteps: 1,925,371,224

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1925371224...
Checkpoint 1925371224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,607.29655
Policy Entropy: 2.14084
Value Function Loss: 0.02345

Mean KL Divergence: 0.01272
SB3 Clip Fraction: 0.07363
Policy Update Magnitude: 0.31092
Value Function Update Magnitude: 0.35923

Collected Steps per Second: 21,342.87397
Overall Steps per Second: 10,355.70943

Timestep Collection Time: 2.34383
Timestep Consumption Time: 2.48675
PPO Batch Consumption Time: 0.28991
Total Iteration Time: 4.83057

Cumulative Model Updates: 230,786
Cumulative Timesteps: 1,925,421,248

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47,311.24255
Policy Entropy: 2.14847
Value Function Loss: 0.02614

Mean KL Divergence: 0.01429
SB3 Clip Fraction: 0.07949
Policy Update Magnitude: 0.32303
Value Function Update Magnitude: 0.37525

Collected Steps per Second: 21,822.51703
Overall Steps per Second: 10,299.23465

Timestep Collection Time: 2.29176
Timestep Consumption Time: 2.56413
PPO Batch Consumption Time: 0.29026
Total Iteration Time: 4.85589

Cumulative Model Updates: 230,792
Cumulative Timesteps: 1,925,471,260

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1925471260...
Checkpoint 1925471260 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,986.69687
Policy Entropy: 2.15848
Value Function Loss: 0.02529

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.08623
Policy Update Magnitude: 0.32166
Value Function Update Magnitude: 0.39137

Collected Steps per Second: 21,433.04680
Overall Steps per Second: 10,315.58359

Timestep Collection Time: 2.33341
Timestep Consumption Time: 2.51479
PPO Batch Consumption Time: 0.29041
Total Iteration Time: 4.84820

Cumulative Model Updates: 230,798
Cumulative Timesteps: 1,925,521,272

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58,980.56818
Policy Entropy: 2.16885
Value Function Loss: 0.02592

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.08168
Policy Update Magnitude: 0.31723
Value Function Update Magnitude: 0.36669

Collected Steps per Second: 22,142.60974
Overall Steps per Second: 10,632.38145

Timestep Collection Time: 2.25944
Timestep Consumption Time: 2.44599
PPO Batch Consumption Time: 0.28009
Total Iteration Time: 4.70544

Cumulative Model Updates: 230,804
Cumulative Timesteps: 1,925,571,302

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1925571302...
Checkpoint 1925571302 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 54,039.57138
Policy Entropy: 2.15968
Value Function Loss: 0.02326

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.07791
Policy Update Magnitude: 0.31673
Value Function Update Magnitude: 0.33616

Collected Steps per Second: 21,144.19647
Overall Steps per Second: 10,423.02297

Timestep Collection Time: 2.36528
Timestep Consumption Time: 2.43294
PPO Batch Consumption Time: 0.29206
Total Iteration Time: 4.79822

Cumulative Model Updates: 230,810
Cumulative Timesteps: 1,925,621,314

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,996.59512
Policy Entropy: 2.15114
Value Function Loss: 0.02670

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.07858
Policy Update Magnitude: 0.32392
Value Function Update Magnitude: 0.35975

Collected Steps per Second: 21,558.68704
Overall Steps per Second: 10,689.19504

Timestep Collection Time: 2.31925
Timestep Consumption Time: 2.35837
PPO Batch Consumption Time: 0.28002
Total Iteration Time: 4.67762

Cumulative Model Updates: 230,816
Cumulative Timesteps: 1,925,671,314

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1925671314...
Checkpoint 1925671314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 61,821.34873
Policy Entropy: 2.15240
Value Function Loss: 0.02543

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.07383
Policy Update Magnitude: 0.32798
Value Function Update Magnitude: 0.38130

Collected Steps per Second: 20,920.56161
Overall Steps per Second: 10,386.38071

Timestep Collection Time: 2.39038
Timestep Consumption Time: 2.42439
PPO Batch Consumption Time: 0.29274
Total Iteration Time: 4.81477

Cumulative Model Updates: 230,822
Cumulative Timesteps: 1,925,721,322

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49,719.65672
Policy Entropy: 2.16171
Value Function Loss: 0.02657

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.07345
Policy Update Magnitude: 0.32653
Value Function Update Magnitude: 0.33429

Collected Steps per Second: 21,384.51233
Overall Steps per Second: 10,516.41982

Timestep Collection Time: 2.33973
Timestep Consumption Time: 2.41797
PPO Batch Consumption Time: 0.29108
Total Iteration Time: 4.75770

Cumulative Model Updates: 230,828
Cumulative Timesteps: 1,925,771,356

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1925771356...
Checkpoint 1925771356 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 52,856.01248
Policy Entropy: 2.16184
Value Function Loss: 0.02533

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.07867
Policy Update Magnitude: 0.32471
Value Function Update Magnitude: 0.28882

Collected Steps per Second: 21,024.83920
Overall Steps per Second: 10,426.26690

Timestep Collection Time: 2.37862
Timestep Consumption Time: 2.41792
PPO Batch Consumption Time: 0.27914
Total Iteration Time: 4.79654

Cumulative Model Updates: 230,834
Cumulative Timesteps: 1,925,821,366

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46,007.48169
Policy Entropy: 2.17181
Value Function Loss: 0.02408

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.08224
Policy Update Magnitude: 0.31406
Value Function Update Magnitude: 0.23865

Collected Steps per Second: 21,298.73222
Overall Steps per Second: 10,481.09807

Timestep Collection Time: 2.34887
Timestep Consumption Time: 2.42429
PPO Batch Consumption Time: 0.28012
Total Iteration Time: 4.77316

Cumulative Model Updates: 230,840
Cumulative Timesteps: 1,925,871,394

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1925871394...
Checkpoint 1925871394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,371.30860
Policy Entropy: 2.15680
Value Function Loss: 0.02326

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.08023
Policy Update Magnitude: 0.30942
Value Function Update Magnitude: 0.24558

Collected Steps per Second: 20,923.03090
Overall Steps per Second: 10,246.08422

Timestep Collection Time: 2.39086
Timestep Consumption Time: 2.49140
PPO Batch Consumption Time: 0.29413
Total Iteration Time: 4.88226

Cumulative Model Updates: 230,846
Cumulative Timesteps: 1,925,921,418

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,944.61920
Policy Entropy: 2.15873
Value Function Loss: 0.02362

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.07921
Policy Update Magnitude: 0.32471
Value Function Update Magnitude: 0.22389

Collected Steps per Second: 21,176.10069
Overall Steps per Second: 10,364.76201

Timestep Collection Time: 2.36125
Timestep Consumption Time: 2.46298
PPO Batch Consumption Time: 0.27997
Total Iteration Time: 4.82423

Cumulative Model Updates: 230,852
Cumulative Timesteps: 1,925,971,420

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1925971420...
Checkpoint 1925971420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,762.82069
Policy Entropy: 2.14255
Value Function Loss: 0.02333

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.08141
Policy Update Magnitude: 0.32253
Value Function Update Magnitude: 0.21973

Collected Steps per Second: 21,101.88405
Overall Steps per Second: 10,249.42543

Timestep Collection Time: 2.37021
Timestep Consumption Time: 2.50967
PPO Batch Consumption Time: 0.28995
Total Iteration Time: 4.87988

Cumulative Model Updates: 230,858
Cumulative Timesteps: 1,926,021,436

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,327.99481
Policy Entropy: 2.13566
Value Function Loss: 0.02232

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.07691
Policy Update Magnitude: 0.31002
Value Function Update Magnitude: 0.22167

Collected Steps per Second: 21,602.94976
Overall Steps per Second: 10,475.60513

Timestep Collection Time: 2.31468
Timestep Consumption Time: 2.45869
PPO Batch Consumption Time: 0.27963
Total Iteration Time: 4.77338

Cumulative Model Updates: 230,864
Cumulative Timesteps: 1,926,071,440

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1926071440...
Checkpoint 1926071440 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,110.04658
Policy Entropy: 2.13435
Value Function Loss: 0.02057

Mean KL Divergence: 0.01191
SB3 Clip Fraction: 0.08898
Policy Update Magnitude: 0.37716
Value Function Update Magnitude: 0.22949

Collected Steps per Second: 20,809.35148
Overall Steps per Second: 10,245.31592

Timestep Collection Time: 2.40373
Timestep Consumption Time: 2.47850
PPO Batch Consumption Time: 0.27806
Total Iteration Time: 4.88223

Cumulative Model Updates: 230,870
Cumulative Timesteps: 1,926,121,460

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58,482.89702
Policy Entropy: 2.13999
Value Function Loss: 0.02184

Mean KL Divergence: 0.01823
SB3 Clip Fraction: 0.10392
Policy Update Magnitude: 0.37448
Value Function Update Magnitude: 0.26382

Collected Steps per Second: 21,626.78484
Overall Steps per Second: 10,421.34171

Timestep Collection Time: 2.31324
Timestep Consumption Time: 2.48729
PPO Batch Consumption Time: 0.28561
Total Iteration Time: 4.80053

Cumulative Model Updates: 230,876
Cumulative Timesteps: 1,926,171,488

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1926171488...
Checkpoint 1926171488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 70,021.40362
Policy Entropy: 2.15633
Value Function Loss: 0.02113

Mean KL Divergence: 0.02463
SB3 Clip Fraction: 0.08966
Policy Update Magnitude: 0.33984
Value Function Update Magnitude: 0.29629

Collected Steps per Second: 21,529.03584
Overall Steps per Second: 10,387.70313

Timestep Collection Time: 2.32347
Timestep Consumption Time: 2.49203
PPO Batch Consumption Time: 0.28993
Total Iteration Time: 4.81550

Cumulative Model Updates: 230,882
Cumulative Timesteps: 1,926,221,510

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,842.29354
Policy Entropy: 2.15684
Value Function Loss: 0.02310

Mean KL Divergence: 0.01070
SB3 Clip Fraction: 0.08511
Policy Update Magnitude: 0.32151
Value Function Update Magnitude: 0.32423

Collected Steps per Second: 22,215.53958
Overall Steps per Second: 10,687.54077

Timestep Collection Time: 2.25194
Timestep Consumption Time: 2.42903
PPO Batch Consumption Time: 0.28010
Total Iteration Time: 4.68096

Cumulative Model Updates: 230,888
Cumulative Timesteps: 1,926,271,538

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1926271538...
Checkpoint 1926271538 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,650.98197
Policy Entropy: 2.16400
Value Function Loss: 0.02321

Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.07310
Policy Update Magnitude: 0.31413
Value Function Update Magnitude: 0.33333

Collected Steps per Second: 21,726.96168
Overall Steps per Second: 10,599.58028

Timestep Collection Time: 2.30276
Timestep Consumption Time: 2.41743
PPO Batch Consumption Time: 0.27991
Total Iteration Time: 4.72019

Cumulative Model Updates: 230,894
Cumulative Timesteps: 1,926,321,570

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,026.70570
Policy Entropy: 2.16963
Value Function Loss: 0.02251

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.07391
Policy Update Magnitude: 0.31019
Value Function Update Magnitude: 0.33933

Collected Steps per Second: 21,253.30311
Overall Steps per Second: 10,473.72899

Timestep Collection Time: 2.35286
Timestep Consumption Time: 2.42156
PPO Batch Consumption Time: 0.28759
Total Iteration Time: 4.77442

Cumulative Model Updates: 230,900
Cumulative Timesteps: 1,926,371,576

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1926371576...
Checkpoint 1926371576 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,816.42959
Policy Entropy: 2.18455
Value Function Loss: 0.02123

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.07220
Policy Update Magnitude: 0.29598
Value Function Update Magnitude: 0.30071

Collected Steps per Second: 20,959.36417
Overall Steps per Second: 10,433.11267

Timestep Collection Time: 2.38662
Timestep Consumption Time: 2.40792
PPO Batch Consumption Time: 0.28958
Total Iteration Time: 4.79454

Cumulative Model Updates: 230,906
Cumulative Timesteps: 1,926,421,598

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,375.52740
Policy Entropy: 2.18610
Value Function Loss: 0.01901

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.07594
Policy Update Magnitude: 0.28898
Value Function Update Magnitude: 0.24421

Collected Steps per Second: 21,245.98018
Overall Steps per Second: 10,622.18071

Timestep Collection Time: 2.35508
Timestep Consumption Time: 2.35544
PPO Batch Consumption Time: 0.27930
Total Iteration Time: 4.71052

Cumulative Model Updates: 230,912
Cumulative Timesteps: 1,926,471,634

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1926471634...
Checkpoint 1926471634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,951.59416
Policy Entropy: 2.18485
Value Function Loss: 0.01941

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.07560
Policy Update Magnitude: 0.28430
Value Function Update Magnitude: 0.21785

Collected Steps per Second: 20,539.91780
Overall Steps per Second: 10,326.94993

Timestep Collection Time: 2.43438
Timestep Consumption Time: 2.40751
PPO Batch Consumption Time: 0.27820
Total Iteration Time: 4.84189

Cumulative Model Updates: 230,918
Cumulative Timesteps: 1,926,521,636

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52,093.13425
Policy Entropy: 2.17809
Value Function Loss: 0.02056

Mean KL Divergence: 0.00751
SB3 Clip Fraction: 0.07125
Policy Update Magnitude: 0.29439
Value Function Update Magnitude: 0.21892

Collected Steps per Second: 21,647.46793
Overall Steps per Second: 10,406.22162

Timestep Collection Time: 2.31112
Timestep Consumption Time: 2.49658
PPO Batch Consumption Time: 0.29188
Total Iteration Time: 4.80770

Cumulative Model Updates: 230,924
Cumulative Timesteps: 1,926,571,666

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1926571666...
Checkpoint 1926571666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43,330.73516
Policy Entropy: 2.16625
Value Function Loss: 0.02090

Mean KL Divergence: 0.00738
SB3 Clip Fraction: 0.06859
Policy Update Magnitude: 0.29497
Value Function Update Magnitude: 0.21464

Collected Steps per Second: 21,415.91338
Overall Steps per Second: 10,336.62890

Timestep Collection Time: 2.33527
Timestep Consumption Time: 2.50306
PPO Batch Consumption Time: 0.29238
Total Iteration Time: 4.83833

Cumulative Model Updates: 230,930
Cumulative Timesteps: 1,926,621,678

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52,319.61194
Policy Entropy: 2.15683
Value Function Loss: 0.02034

Mean KL Divergence: 0.00705
SB3 Clip Fraction: 0.06688
Policy Update Magnitude: 0.30067
Value Function Update Magnitude: 0.20676

Collected Steps per Second: 21,997.02968
Overall Steps per Second: 10,371.01303

Timestep Collection Time: 2.27403
Timestep Consumption Time: 2.54922
PPO Batch Consumption Time: 0.29444
Total Iteration Time: 4.82325

Cumulative Model Updates: 230,936
Cumulative Timesteps: 1,926,671,700

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1926671700...
Checkpoint 1926671700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,122.80656
Policy Entropy: 2.16105
Value Function Loss: 0.02100

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.08023
Policy Update Magnitude: 0.29780
Value Function Update Magnitude: 0.18620

Collected Steps per Second: 21,560.02780
Overall Steps per Second: 10,490.09187

Timestep Collection Time: 2.31929
Timestep Consumption Time: 2.44749
PPO Batch Consumption Time: 0.27982
Total Iteration Time: 4.76678

Cumulative Model Updates: 230,942
Cumulative Timesteps: 1,926,721,704

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 71,833.57351
Policy Entropy: 2.16733
Value Function Loss: 0.02093

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.08404
Policy Update Magnitude: 0.29308
Value Function Update Magnitude: 0.20093

Collected Steps per Second: 21,820.30566
Overall Steps per Second: 10,479.51898

Timestep Collection Time: 2.29190
Timestep Consumption Time: 2.48026
PPO Batch Consumption Time: 0.28056
Total Iteration Time: 4.77217

Cumulative Model Updates: 230,948
Cumulative Timesteps: 1,926,771,714

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1926771714...
Checkpoint 1926771714 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 60,475.96523
Policy Entropy: 2.15059
Value Function Loss: 0.02023

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.07952
Policy Update Magnitude: 0.29177
Value Function Update Magnitude: 0.23873

Collected Steps per Second: 21,338.06143
Overall Steps per Second: 10,291.03085

Timestep Collection Time: 2.34332
Timestep Consumption Time: 2.51547
PPO Batch Consumption Time: 0.29424
Total Iteration Time: 4.85879

Cumulative Model Updates: 230,954
Cumulative Timesteps: 1,926,821,716

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52,512.70652
Policy Entropy: 2.13953
Value Function Loss: 0.01980

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.07586
Policy Update Magnitude: 0.29209
Value Function Update Magnitude: 0.27068

Collected Steps per Second: 21,844.95022
Overall Steps per Second: 10,325.08638

Timestep Collection Time: 2.28886
Timestep Consumption Time: 2.55372
PPO Batch Consumption Time: 0.29180
Total Iteration Time: 4.84257

Cumulative Model Updates: 230,960
Cumulative Timesteps: 1,926,871,716

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1926871716...
Checkpoint 1926871716 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55,389.28266
Policy Entropy: 2.12776
Value Function Loss: 0.02284

Mean KL Divergence: 0.00758
SB3 Clip Fraction: 0.07284
Policy Update Magnitude: 0.30675
Value Function Update Magnitude: 0.27417

Collected Steps per Second: 21,525.34573
Overall Steps per Second: 10,342.83970

Timestep Collection Time: 2.32377
Timestep Consumption Time: 2.51242
PPO Batch Consumption Time: 0.29397
Total Iteration Time: 4.83620

Cumulative Model Updates: 230,966
Cumulative Timesteps: 1,926,921,736

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62,976.40106
Policy Entropy: 2.12514
Value Function Loss: 0.02357

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.07630
Policy Update Magnitude: 0.31619
Value Function Update Magnitude: 0.32883

Collected Steps per Second: 21,823.80207
Overall Steps per Second: 10,394.14564

Timestep Collection Time: 2.29236
Timestep Consumption Time: 2.52073
PPO Batch Consumption Time: 0.29243
Total Iteration Time: 4.81309

Cumulative Model Updates: 230,972
Cumulative Timesteps: 1,926,971,764

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1926971764...
Checkpoint 1926971764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 62,976.40106
Policy Entropy: 2.14614
Value Function Loss: 0.02014

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.07154
Policy Update Magnitude: 0.30970
Value Function Update Magnitude: 0.32875

Collected Steps per Second: 21,563.11368
Overall Steps per Second: 10,382.82355

Timestep Collection Time: 2.32007
Timestep Consumption Time: 2.49827
PPO Batch Consumption Time: 0.29155
Total Iteration Time: 4.81834

Cumulative Model Updates: 230,978
Cumulative Timesteps: 1,927,021,792

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46,848.10818
Policy Entropy: 2.13981
Value Function Loss: 0.01962

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.07210
Policy Update Magnitude: 0.29838
Value Function Update Magnitude: 0.31639

Collected Steps per Second: 21,638.62944
Overall Steps per Second: 10,383.34600

Timestep Collection Time: 2.31105
Timestep Consumption Time: 2.50512
PPO Batch Consumption Time: 0.29251
Total Iteration Time: 4.81617

Cumulative Model Updates: 230,984
Cumulative Timesteps: 1,927,071,800

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1927071800...
Checkpoint 1927071800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55,703.92268
Policy Entropy: 2.15073
Value Function Loss: 0.02081

Mean KL Divergence: 0.00717
SB3 Clip Fraction: 0.06767
Policy Update Magnitude: 0.30224
Value Function Update Magnitude: 0.31844

Collected Steps per Second: 20,817.79905
Overall Steps per Second: 10,178.69486

Timestep Collection Time: 2.40208
Timestep Consumption Time: 2.51073
PPO Batch Consumption Time: 0.29464
Total Iteration Time: 4.91281

Cumulative Model Updates: 230,990
Cumulative Timesteps: 1,927,121,806

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57,671.13921
Policy Entropy: 2.13635
Value Function Loss: 0.02208

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.07702
Policy Update Magnitude: 0.30943
Value Function Update Magnitude: 0.34960

Collected Steps per Second: 21,685.66027
Overall Steps per Second: 10,365.94278

Timestep Collection Time: 2.30604
Timestep Consumption Time: 2.51822
PPO Batch Consumption Time: 0.29272
Total Iteration Time: 4.82426

Cumulative Model Updates: 230,996
Cumulative Timesteps: 1,927,171,814

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1927171814...
Checkpoint 1927171814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48,313.25666
Policy Entropy: 2.14174
Value Function Loss: 0.02401

Mean KL Divergence: 0.01129
SB3 Clip Fraction: 0.09921
Policy Update Magnitude: 0.30984
Value Function Update Magnitude: 0.38075

Collected Steps per Second: 20,956.29095
Overall Steps per Second: 10,209.74993

Timestep Collection Time: 2.38802
Timestep Consumption Time: 2.51357
PPO Batch Consumption Time: 0.29214
Total Iteration Time: 4.90159

Cumulative Model Updates: 231,002
Cumulative Timesteps: 1,927,221,858

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,657.26793
Policy Entropy: 2.15022
Value Function Loss: 0.02648

Mean KL Divergence: 0.01092
SB3 Clip Fraction: 0.09736
Policy Update Magnitude: 0.31648
Value Function Update Magnitude: 0.37986

Collected Steps per Second: 21,835.16762
Overall Steps per Second: 10,424.04965

Timestep Collection Time: 2.29098
Timestep Consumption Time: 2.50792
PPO Batch Consumption Time: 0.28907
Total Iteration Time: 4.79890

Cumulative Model Updates: 231,008
Cumulative Timesteps: 1,927,271,882

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1927271882...
Checkpoint 1927271882 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,951.12628
Policy Entropy: 2.14299
Value Function Loss: 0.02492

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.08949
Policy Update Magnitude: 0.31707
Value Function Update Magnitude: 0.33849

Collected Steps per Second: 20,463.76487
Overall Steps per Second: 10,251.36673

Timestep Collection Time: 2.44403
Timestep Consumption Time: 2.43474
PPO Batch Consumption Time: 0.29020
Total Iteration Time: 4.87876

Cumulative Model Updates: 231,014
Cumulative Timesteps: 1,927,321,896

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,222.03174
Policy Entropy: 2.13317
Value Function Loss: 0.02308

Mean KL Divergence: 0.01050
SB3 Clip Fraction: 0.08859
Policy Update Magnitude: 0.30665
Value Function Update Magnitude: 0.28912

Collected Steps per Second: 21,232.20215
Overall Steps per Second: 10,447.58438

Timestep Collection Time: 2.35557
Timestep Consumption Time: 2.43156
PPO Batch Consumption Time: 0.28044
Total Iteration Time: 4.78714

Cumulative Model Updates: 231,020
Cumulative Timesteps: 1,927,371,910

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1927371910...
Checkpoint 1927371910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,402.22649
Policy Entropy: 2.12696
Value Function Loss: 0.01891

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.08401
Policy Update Magnitude: 0.30222
Value Function Update Magnitude: 0.30606

Collected Steps per Second: 20,874.66698
Overall Steps per Second: 10,420.56481

Timestep Collection Time: 2.39726
Timestep Consumption Time: 2.40498
PPO Batch Consumption Time: 0.28781
Total Iteration Time: 4.80223

Cumulative Model Updates: 231,026
Cumulative Timesteps: 1,927,421,952

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46,036.78976
Policy Entropy: 2.13164
Value Function Loss: 0.02054

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.08071
Policy Update Magnitude: 0.30629
Value Function Update Magnitude: 0.31795

Collected Steps per Second: 21,411.78645
Overall Steps per Second: 10,660.85885

Timestep Collection Time: 2.33712
Timestep Consumption Time: 2.35687
PPO Batch Consumption Time: 0.28005
Total Iteration Time: 4.69399

Cumulative Model Updates: 231,032
Cumulative Timesteps: 1,927,471,994

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1927471994...
Checkpoint 1927471994 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,830.27044
Policy Entropy: 2.12473
Value Function Loss: 0.02012

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.08337
Policy Update Magnitude: 0.30196
Value Function Update Magnitude: 0.28931

Collected Steps per Second: 21,093.10668
Overall Steps per Second: 10,278.62443

Timestep Collection Time: 2.37063
Timestep Consumption Time: 2.49422
PPO Batch Consumption Time: 0.29454
Total Iteration Time: 4.86485

Cumulative Model Updates: 231,038
Cumulative Timesteps: 1,927,521,998

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59,802.42510
Policy Entropy: 2.12125
Value Function Loss: 0.02197

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.07749
Policy Update Magnitude: 0.30456
Value Function Update Magnitude: 0.26266

Collected Steps per Second: 21,962.70247
Overall Steps per Second: 10,477.62536

Timestep Collection Time: 2.27850
Timestep Consumption Time: 2.49758
PPO Batch Consumption Time: 0.29415
Total Iteration Time: 4.77608

Cumulative Model Updates: 231,044
Cumulative Timesteps: 1,927,572,040

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1927572040...
Checkpoint 1927572040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 68,041.30626
Policy Entropy: 2.13365
Value Function Loss: 0.02229

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.08005
Policy Update Magnitude: 0.31284
Value Function Update Magnitude: 0.29072

Collected Steps per Second: 21,105.80926
Overall Steps per Second: 10,478.33507

Timestep Collection Time: 2.37072
Timestep Consumption Time: 2.40446
PPO Batch Consumption Time: 0.27938
Total Iteration Time: 4.77519

Cumulative Model Updates: 231,050
Cumulative Timesteps: 1,927,622,076

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49,769.25875
Policy Entropy: 2.13991
Value Function Loss: 0.02290

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.09211
Policy Update Magnitude: 0.31117
Value Function Update Magnitude: 0.31568

Collected Steps per Second: 21,688.33375
Overall Steps per Second: 10,532.27338

Timestep Collection Time: 2.30612
Timestep Consumption Time: 2.44271
PPO Batch Consumption Time: 0.27927
Total Iteration Time: 4.74883

Cumulative Model Updates: 231,056
Cumulative Timesteps: 1,927,672,092

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1927672092...
Checkpoint 1927672092 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,407.87987
Policy Entropy: 2.13232
Value Function Loss: 0.02464

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.08732
Policy Update Magnitude: 0.32018
Value Function Update Magnitude: 0.31259

Collected Steps per Second: 21,100.74335
Overall Steps per Second: 10,239.93091

Timestep Collection Time: 2.36996
Timestep Consumption Time: 2.51366
PPO Batch Consumption Time: 0.29286
Total Iteration Time: 4.88363

Cumulative Model Updates: 231,062
Cumulative Timesteps: 1,927,722,100

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,298.24589
Policy Entropy: 2.11657
Value Function Loss: 0.02254

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.08927
Policy Update Magnitude: 0.31828
Value Function Update Magnitude: 0.31541

Collected Steps per Second: 21,208.40396
Overall Steps per Second: 10,372.25053

Timestep Collection Time: 2.35756
Timestep Consumption Time: 2.46300
PPO Batch Consumption Time: 0.27979
Total Iteration Time: 4.82055

Cumulative Model Updates: 231,068
Cumulative Timesteps: 1,927,772,100

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1927772100...
Checkpoint 1927772100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 52,573.23067
Policy Entropy: 2.12067
Value Function Loss: 0.02488

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.08520
Policy Update Magnitude: 0.32040
Value Function Update Magnitude: 0.30779

Collected Steps per Second: 21,106.33320
Overall Steps per Second: 10,283.74329

Timestep Collection Time: 2.36896
Timestep Consumption Time: 2.49309
PPO Batch Consumption Time: 0.28853
Total Iteration Time: 4.86204

Cumulative Model Updates: 231,074
Cumulative Timesteps: 1,927,822,100

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45,420.58803
Policy Entropy: 2.11463
Value Function Loss: 0.02562

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.08416
Policy Update Magnitude: 0.32190
Value Function Update Magnitude: 0.30873

Collected Steps per Second: 21,499.95944
Overall Steps per Second: 10,513.96844

Timestep Collection Time: 2.32605
Timestep Consumption Time: 2.43048
PPO Batch Consumption Time: 0.27714
Total Iteration Time: 4.75653

Cumulative Model Updates: 231,080
Cumulative Timesteps: 1,927,872,110

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1927872110...
Checkpoint 1927872110 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,420.58803
Policy Entropy: 2.12427
Value Function Loss: 0.02375

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.08181
Policy Update Magnitude: 0.31473
Value Function Update Magnitude: 0.28099

Collected Steps per Second: 21,292.43542
Overall Steps per Second: 10,330.42806

Timestep Collection Time: 2.34853
Timestep Consumption Time: 2.49212
PPO Batch Consumption Time: 0.29010
Total Iteration Time: 4.84065

Cumulative Model Updates: 231,086
Cumulative Timesteps: 1,927,922,116

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,859.69371
Policy Entropy: 2.11976
Value Function Loss: 0.02146

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.07691
Policy Update Magnitude: 0.30360
Value Function Update Magnitude: 0.29788

Collected Steps per Second: 21,846.97836
Overall Steps per Second: 10,368.03863

Timestep Collection Time: 2.28901
Timestep Consumption Time: 2.53427
PPO Batch Consumption Time: 0.29238
Total Iteration Time: 4.82328

Cumulative Model Updates: 231,092
Cumulative Timesteps: 1,927,972,124

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1927972124...
Checkpoint 1927972124 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 51,694.04930
Policy Entropy: 2.12591
Value Function Loss: 0.01899

Mean KL Divergence: 0.00760
SB3 Clip Fraction: 0.06977
Policy Update Magnitude: 0.29900
Value Function Update Magnitude: 0.29369

Collected Steps per Second: 21,818.29764
Overall Steps per Second: 10,496.64412

Timestep Collection Time: 2.29193
Timestep Consumption Time: 2.47207
PPO Batch Consumption Time: 0.27978
Total Iteration Time: 4.76400

Cumulative Model Updates: 231,098
Cumulative Timesteps: 1,928,022,130

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,427.89973
Policy Entropy: 2.11988
Value Function Loss: 0.01867

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.07593
Policy Update Magnitude: 0.29616
Value Function Update Magnitude: 0.29711

Collected Steps per Second: 21,638.31244
Overall Steps per Second: 10,480.91856

Timestep Collection Time: 2.31220
Timestep Consumption Time: 2.46143
PPO Batch Consumption Time: 0.28381
Total Iteration Time: 4.77363

Cumulative Model Updates: 231,104
Cumulative Timesteps: 1,928,072,162

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1928072162...
Checkpoint 1928072162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,912.11786
Policy Entropy: 2.11479
Value Function Loss: 0.02033

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.07541
Policy Update Magnitude: 0.29644
Value Function Update Magnitude: 0.27956

Collected Steps per Second: 21,438.07440
Overall Steps per Second: 10,337.81027

Timestep Collection Time: 2.33258
Timestep Consumption Time: 2.50462
PPO Batch Consumption Time: 0.29203
Total Iteration Time: 4.83719

Cumulative Model Updates: 231,110
Cumulative Timesteps: 1,928,122,168

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54,697.50819
Policy Entropy: 2.11146
Value Function Loss: 0.02283

Mean KL Divergence: 0.00766
SB3 Clip Fraction: 0.07160
Policy Update Magnitude: 0.30982
Value Function Update Magnitude: 0.29739

Collected Steps per Second: 22,162.40260
Overall Steps per Second: 10,507.11976

Timestep Collection Time: 2.25716
Timestep Consumption Time: 2.50381
PPO Batch Consumption Time: 0.28987
Total Iteration Time: 4.76096

Cumulative Model Updates: 231,116
Cumulative Timesteps: 1,928,172,192

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1928172192...
Checkpoint 1928172192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,545.64155
Policy Entropy: 2.11474
Value Function Loss: 0.02293

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.07764
Policy Update Magnitude: 0.31186
Value Function Update Magnitude: 0.30280

Collected Steps per Second: 21,812.47560
Overall Steps per Second: 10,412.39570

Timestep Collection Time: 2.29300
Timestep Consumption Time: 2.51051
PPO Batch Consumption Time: 0.29138
Total Iteration Time: 4.80351

Cumulative Model Updates: 231,122
Cumulative Timesteps: 1,928,222,208

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,803.99138
Policy Entropy: 2.12632
Value Function Loss: 0.02281

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.07920
Policy Update Magnitude: 0.30274
Value Function Update Magnitude: 0.25902

Collected Steps per Second: 22,100.63481
Overall Steps per Second: 10,461.81547

Timestep Collection Time: 2.26337
Timestep Consumption Time: 2.51801
PPO Batch Consumption Time: 0.29177
Total Iteration Time: 4.78139

Cumulative Model Updates: 231,128
Cumulative Timesteps: 1,928,272,230

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1928272230...
Checkpoint 1928272230 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,537.72854
Policy Entropy: 2.12498
Value Function Loss: 0.02068

Mean KL Divergence: 0.00757
SB3 Clip Fraction: 0.07141
Policy Update Magnitude: 0.29532
Value Function Update Magnitude: 0.26099

Collected Steps per Second: 21,416.64770
Overall Steps per Second: 10,331.50912

Timestep Collection Time: 2.33538
Timestep Consumption Time: 2.50573
PPO Batch Consumption Time: 0.29348
Total Iteration Time: 4.84111

Cumulative Model Updates: 231,134
Cumulative Timesteps: 1,928,322,246

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,378.69074
Policy Entropy: 2.14077
Value Function Loss: 0.02189

Mean KL Divergence: 0.00676
SB3 Clip Fraction: 0.06672
Policy Update Magnitude: 0.29770
Value Function Update Magnitude: 0.25550

Collected Steps per Second: 21,232.49175
Overall Steps per Second: 10,326.09047

Timestep Collection Time: 2.35498
Timestep Consumption Time: 2.48732
PPO Batch Consumption Time: 0.28671
Total Iteration Time: 4.84230

Cumulative Model Updates: 231,140
Cumulative Timesteps: 1,928,372,248

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1928372248...
Checkpoint 1928372248 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,110.81125
Policy Entropy: 2.12782
Value Function Loss: 0.02249

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.07072
Policy Update Magnitude: 0.30205
Value Function Update Magnitude: 0.25584

Collected Steps per Second: 21,223.21080
Overall Steps per Second: 10,277.08181

Timestep Collection Time: 2.35695
Timestep Consumption Time: 2.51039
PPO Batch Consumption Time: 0.29272
Total Iteration Time: 4.86733

Cumulative Model Updates: 231,146
Cumulative Timesteps: 1,928,422,270

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,080.71010
Policy Entropy: 2.13219
Value Function Loss: 0.02365

Mean KL Divergence: 0.00709
SB3 Clip Fraction: 0.06801
Policy Update Magnitude: 0.30780
Value Function Update Magnitude: 0.22894

Collected Steps per Second: 21,755.33427
Overall Steps per Second: 10,402.93830

Timestep Collection Time: 2.29884
Timestep Consumption Time: 2.50865
PPO Batch Consumption Time: 0.28922
Total Iteration Time: 4.80749

Cumulative Model Updates: 231,152
Cumulative Timesteps: 1,928,472,282

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1928472282...
Checkpoint 1928472282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,195.89162
Policy Entropy: 2.11848
Value Function Loss: 0.02456

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.07017
Policy Update Magnitude: 0.30928
Value Function Update Magnitude: 0.22413

Collected Steps per Second: 21,460.73414
Overall Steps per Second: 10,356.54572

Timestep Collection Time: 2.33012
Timestep Consumption Time: 2.49833
PPO Batch Consumption Time: 0.29145
Total Iteration Time: 4.82844

Cumulative Model Updates: 231,158
Cumulative Timesteps: 1,928,522,288

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,611.73559
Policy Entropy: 2.11206
Value Function Loss: 0.02566

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.07398
Policy Update Magnitude: 0.31343
Value Function Update Magnitude: 0.22210

Collected Steps per Second: 21,537.72295
Overall Steps per Second: 10,467.63035

Timestep Collection Time: 2.32169
Timestep Consumption Time: 2.45532
PPO Batch Consumption Time: 0.29156
Total Iteration Time: 4.77701

Cumulative Model Updates: 231,164
Cumulative Timesteps: 1,928,572,292

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1928572292...
Checkpoint 1928572292 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,428.21121
Policy Entropy: 2.09914
Value Function Loss: 0.02411

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.07356
Policy Update Magnitude: 0.31226
Value Function Update Magnitude: 0.25996

Collected Steps per Second: 21,086.30633
Overall Steps per Second: 10,450.59219

Timestep Collection Time: 2.37310
Timestep Consumption Time: 2.41514
PPO Batch Consumption Time: 0.28762
Total Iteration Time: 4.78825

Cumulative Model Updates: 231,170
Cumulative Timesteps: 1,928,622,332

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,946.51101
Policy Entropy: 2.09943
Value Function Loss: 0.02414

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.07893
Policy Update Magnitude: 0.30876
Value Function Update Magnitude: 0.27963

Collected Steps per Second: 21,371.21098
Overall Steps per Second: 10,468.86376

Timestep Collection Time: 2.34025
Timestep Consumption Time: 2.43715
PPO Batch Consumption Time: 0.29240
Total Iteration Time: 4.77740

Cumulative Model Updates: 231,176
Cumulative Timesteps: 1,928,672,346

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1928672346...
Checkpoint 1928672346 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46,597.05212
Policy Entropy: 2.11501
Value Function Loss: 0.02221

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.07528
Policy Update Magnitude: 0.30552
Value Function Update Magnitude: 0.27790

Collected Steps per Second: 20,710.52688
Overall Steps per Second: 10,166.76227

Timestep Collection Time: 2.41452
Timestep Consumption Time: 2.50406
PPO Batch Consumption Time: 0.29781
Total Iteration Time: 4.91858

Cumulative Model Updates: 231,182
Cumulative Timesteps: 1,928,722,352

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57,756.02667
Policy Entropy: 2.12544
Value Function Loss: 0.02418

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.07789
Policy Update Magnitude: 0.30764
Value Function Update Magnitude: 0.27171

Collected Steps per Second: 21,461.80195
Overall Steps per Second: 10,549.11278

Timestep Collection Time: 2.33140
Timestep Consumption Time: 2.41175
PPO Batch Consumption Time: 0.27911
Total Iteration Time: 4.74315

Cumulative Model Updates: 231,188
Cumulative Timesteps: 1,928,772,388

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1928772388...
Checkpoint 1928772388 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,007.07373
Policy Entropy: 2.12782
Value Function Loss: 0.02570

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.08271
Policy Update Magnitude: 0.31645
Value Function Update Magnitude: 0.30482

Collected Steps per Second: 21,304.97123
Overall Steps per Second: 10,503.63220

Timestep Collection Time: 2.34800
Timestep Consumption Time: 2.41455
PPO Batch Consumption Time: 0.27977
Total Iteration Time: 4.76254

Cumulative Model Updates: 231,194
Cumulative Timesteps: 1,928,822,412

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47,090.27205
Policy Entropy: 2.11065
Value Function Loss: 0.02517

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.08453
Policy Update Magnitude: 0.32164
Value Function Update Magnitude: 0.34244

Collected Steps per Second: 21,484.09362
Overall Steps per Second: 10,499.93680

Timestep Collection Time: 2.32740
Timestep Consumption Time: 2.43473
PPO Batch Consumption Time: 0.27906
Total Iteration Time: 4.76212

Cumulative Model Updates: 231,200
Cumulative Timesteps: 1,928,872,414

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1928872414...
Checkpoint 1928872414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47,090.27205
Policy Entropy: 2.11306
Value Function Loss: 0.02317

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.07768
Policy Update Magnitude: 0.31770
Value Function Update Magnitude: 0.35598

Collected Steps per Second: 20,865.79537
Overall Steps per Second: 10,261.24833

Timestep Collection Time: 2.39761
Timestep Consumption Time: 2.47782
PPO Batch Consumption Time: 0.28563
Total Iteration Time: 4.87543

Cumulative Model Updates: 231,206
Cumulative Timesteps: 1,928,922,442

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49,839.52716
Policy Entropy: 2.11582
Value Function Loss: 0.02151

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.08135
Policy Update Magnitude: 0.31008
Value Function Update Magnitude: 0.34018

Collected Steps per Second: 21,580.10262
Overall Steps per Second: 10,509.00601

Timestep Collection Time: 2.31834
Timestep Consumption Time: 2.44234
PPO Batch Consumption Time: 0.27824
Total Iteration Time: 4.76068

Cumulative Model Updates: 231,212
Cumulative Timesteps: 1,928,972,472

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1928972472...
Checkpoint 1928972472 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 88,301.74871
Policy Entropy: 2.13205
Value Function Loss: 0.01922

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.07631
Policy Update Magnitude: 0.30189
Value Function Update Magnitude: 0.30591

Collected Steps per Second: 21,365.38488
Overall Steps per Second: 10,270.41773

Timestep Collection Time: 2.34229
Timestep Consumption Time: 2.53034
PPO Batch Consumption Time: 0.29247
Total Iteration Time: 4.87264

Cumulative Model Updates: 231,218
Cumulative Timesteps: 1,929,022,516

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61,710.79953
Policy Entropy: 2.15021
Value Function Loss: 0.01845

Mean KL Divergence: 0.00743
SB3 Clip Fraction: 0.06763
Policy Update Magnitude: 0.28664
Value Function Update Magnitude: 0.23512

Collected Steps per Second: 22,209.93766
Overall Steps per Second: 10,444.39654

Timestep Collection Time: 2.25124
Timestep Consumption Time: 2.53601
PPO Batch Consumption Time: 0.29251
Total Iteration Time: 4.78726

Cumulative Model Updates: 231,224
Cumulative Timesteps: 1,929,072,516

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1929072516...
Checkpoint 1929072516 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,999.04338
Policy Entropy: 2.14347
Value Function Loss: 0.02292

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.07132
Policy Update Magnitude: 0.30289
Value Function Update Magnitude: 0.19825

Collected Steps per Second: 21,505.68060
Overall Steps per Second: 10,480.43522

Timestep Collection Time: 2.32543
Timestep Consumption Time: 2.44632
PPO Batch Consumption Time: 0.27986
Total Iteration Time: 4.77175

Cumulative Model Updates: 231,230
Cumulative Timesteps: 1,929,122,526

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82,372.75992
Policy Entropy: 2.13470
Value Function Loss: 0.02451

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.08110
Policy Update Magnitude: 0.30583
Value Function Update Magnitude: 0.22602

Collected Steps per Second: 21,859.00987
Overall Steps per Second: 10,465.83887

Timestep Collection Time: 2.28766
Timestep Consumption Time: 2.49036
PPO Batch Consumption Time: 0.28817
Total Iteration Time: 4.77802

Cumulative Model Updates: 231,236
Cumulative Timesteps: 1,929,172,532

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1929172532...
Checkpoint 1929172532 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 71,610.50831
Policy Entropy: 2.11625
Value Function Loss: 0.02378

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.07934
Policy Update Magnitude: 0.29890
Value Function Update Magnitude: 0.25274

Collected Steps per Second: 21,547.83872
Overall Steps per Second: 10,326.50842

Timestep Collection Time: 2.32135
Timestep Consumption Time: 2.52250
PPO Batch Consumption Time: 0.29413
Total Iteration Time: 4.84384

Cumulative Model Updates: 231,242
Cumulative Timesteps: 1,929,222,552

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51,807.11573
Policy Entropy: 2.12257
Value Function Loss: 0.02171

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.07556
Policy Update Magnitude: 0.29901
Value Function Update Magnitude: 0.27121

Collected Steps per Second: 21,470.41099
Overall Steps per Second: 10,501.74821

Timestep Collection Time: 2.32888
Timestep Consumption Time: 2.43242
PPO Batch Consumption Time: 0.29315
Total Iteration Time: 4.76130

Cumulative Model Updates: 231,248
Cumulative Timesteps: 1,929,272,554

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1929272554...
Checkpoint 1929272554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 50,192.34351
Policy Entropy: 2.10797
Value Function Loss: 0.01900

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.07214
Policy Update Magnitude: 0.29944
Value Function Update Magnitude: 0.29619

Collected Steps per Second: 21,096.86136
Overall Steps per Second: 10,574.01149

Timestep Collection Time: 2.37135
Timestep Consumption Time: 2.35987
PPO Batch Consumption Time: 0.27865
Total Iteration Time: 4.73122

Cumulative Model Updates: 231,254
Cumulative Timesteps: 1,929,322,582

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,883.64635
Policy Entropy: 2.10456
Value Function Loss: 0.01969

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.07711
Policy Update Magnitude: 0.29888
Value Function Update Magnitude: 0.31962

Collected Steps per Second: 21,246.84569
Overall Steps per Second: 10,411.03876

Timestep Collection Time: 2.35480
Timestep Consumption Time: 2.45087
PPO Batch Consumption Time: 0.29773
Total Iteration Time: 4.80567

Cumulative Model Updates: 231,260
Cumulative Timesteps: 1,929,372,614

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1929372614...
Checkpoint 1929372614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,060.88855
Policy Entropy: 2.11058
Value Function Loss: 0.02117

Mean KL Divergence: 0.00720
SB3 Clip Fraction: 0.06791
Policy Update Magnitude: 0.30548
Value Function Update Magnitude: 0.30894

Collected Steps per Second: 20,478.37782
Overall Steps per Second: 10,181.97200

Timestep Collection Time: 2.44199
Timestep Consumption Time: 2.46944
PPO Batch Consumption Time: 0.28748
Total Iteration Time: 4.91143

Cumulative Model Updates: 231,266
Cumulative Timesteps: 1,929,422,622

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,440.98477
Policy Entropy: 2.12279
Value Function Loss: 0.02287

Mean KL Divergence: 0.00757
SB3 Clip Fraction: 0.06913
Policy Update Magnitude: 0.31618
Value Function Update Magnitude: 0.32586

Collected Steps per Second: 21,480.89857
Overall Steps per Second: 10,554.21747

Timestep Collection Time: 2.32970
Timestep Consumption Time: 2.41191
PPO Batch Consumption Time: 0.27791
Total Iteration Time: 4.74161

Cumulative Model Updates: 231,272
Cumulative Timesteps: 1,929,472,666

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1929472666...
Checkpoint 1929472666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,129.84605
Policy Entropy: 2.13984
Value Function Loss: 0.02222

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.07893
Policy Update Magnitude: 0.31928
Value Function Update Magnitude: 0.34219

Collected Steps per Second: 21,119.80040
Overall Steps per Second: 10,332.65911

Timestep Collection Time: 2.36820
Timestep Consumption Time: 2.47237
PPO Batch Consumption Time: 0.29149
Total Iteration Time: 4.84057

Cumulative Model Updates: 231,278
Cumulative Timesteps: 1,929,522,682

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,526.44841
Policy Entropy: 2.14506
Value Function Loss: 0.02188

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.08320
Policy Update Magnitude: 0.30330
Value Function Update Magnitude: 0.33372

Collected Steps per Second: 21,296.93986
Overall Steps per Second: 10,258.81519

Timestep Collection Time: 2.34832
Timestep Consumption Time: 2.52671
PPO Batch Consumption Time: 0.29185
Total Iteration Time: 4.87503

Cumulative Model Updates: 231,284
Cumulative Timesteps: 1,929,572,694

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1929572694...
Checkpoint 1929572694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 58,335.68123
Policy Entropy: 2.12857
Value Function Loss: 0.02049

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.08921
Policy Update Magnitude: 0.29416
Value Function Update Magnitude: 0.33526

Collected Steps per Second: 21,616.76310
Overall Steps per Second: 10,278.86666

Timestep Collection Time: 2.31413
Timestep Consumption Time: 2.55255
PPO Batch Consumption Time: 0.29379
Total Iteration Time: 4.86668

Cumulative Model Updates: 231,290
Cumulative Timesteps: 1,929,622,718

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,301.32889
Policy Entropy: 2.12869
Value Function Loss: 0.02154

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.09122
Policy Update Magnitude: 0.29937
Value Function Update Magnitude: 0.32388

Collected Steps per Second: 22,065.90345
Overall Steps per Second: 10,405.29099

Timestep Collection Time: 2.26739
Timestep Consumption Time: 2.54093
PPO Batch Consumption Time: 0.29361
Total Iteration Time: 4.80832

Cumulative Model Updates: 231,296
Cumulative Timesteps: 1,929,672,750

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1929672750...
Checkpoint 1929672750 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,334.00465
Policy Entropy: 2.13561
Value Function Loss: 0.01887

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.08488
Policy Update Magnitude: 0.30012
Value Function Update Magnitude: 0.31484

Collected Steps per Second: 21,737.47325
Overall Steps per Second: 10,528.02699

Timestep Collection Time: 2.30091
Timestep Consumption Time: 2.44984
PPO Batch Consumption Time: 0.27954
Total Iteration Time: 4.75075

Cumulative Model Updates: 231,302
Cumulative Timesteps: 1,929,722,766

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,916.21624
Policy Entropy: 2.14074
Value Function Loss: 0.01670

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.07303
Policy Update Magnitude: 0.29325
Value Function Update Magnitude: 0.29683

Collected Steps per Second: 21,816.28894
Overall Steps per Second: 10,526.57127

Timestep Collection Time: 2.29223
Timestep Consumption Time: 2.45841
PPO Batch Consumption Time: 0.28119
Total Iteration Time: 4.75064

Cumulative Model Updates: 231,308
Cumulative Timesteps: 1,929,772,774

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1929772774...
Checkpoint 1929772774 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,226.48355
Policy Entropy: 2.13990
Value Function Loss: 0.01700

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.07393
Policy Update Magnitude: 0.28736
Value Function Update Magnitude: 0.28635

Collected Steps per Second: 21,651.89231
Overall Steps per Second: 10,379.56927

Timestep Collection Time: 2.31047
Timestep Consumption Time: 2.50919
PPO Batch Consumption Time: 0.29033
Total Iteration Time: 4.81966

Cumulative Model Updates: 231,314
Cumulative Timesteps: 1,929,822,800

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 64,921.36847
Policy Entropy: 2.15071
Value Function Loss: 0.02053

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.07035
Policy Update Magnitude: 0.29218
Value Function Update Magnitude: 0.30062

Collected Steps per Second: 22,221.76806
Overall Steps per Second: 10,669.65572

Timestep Collection Time: 2.25077
Timestep Consumption Time: 2.43692
PPO Batch Consumption Time: 0.27906
Total Iteration Time: 4.68769

Cumulative Model Updates: 231,320
Cumulative Timesteps: 1,929,872,816

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1929872816...
Checkpoint 1929872816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55,365.38962
Policy Entropy: 2.15891
Value Function Loss: 0.02328

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.07603
Policy Update Magnitude: 0.30320
Value Function Update Magnitude: 0.32920

Collected Steps per Second: 21,609.66038
Overall Steps per Second: 10,384.41786

Timestep Collection Time: 2.31378
Timestep Consumption Time: 2.50113
PPO Batch Consumption Time: 0.29271
Total Iteration Time: 4.81491

Cumulative Model Updates: 231,326
Cumulative Timesteps: 1,929,922,816

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 74,687.67516
Policy Entropy: 2.14634
Value Function Loss: 0.02229

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.07993
Policy Update Magnitude: 0.30665
Value Function Update Magnitude: 0.33116

Collected Steps per Second: 21,259.97823
Overall Steps per Second: 10,312.63991

Timestep Collection Time: 2.35268
Timestep Consumption Time: 2.49748
PPO Batch Consumption Time: 0.28934
Total Iteration Time: 4.85016

Cumulative Model Updates: 231,332
Cumulative Timesteps: 1,929,972,834

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1929972834...
Checkpoint 1929972834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 56,957.37961
Policy Entropy: 2.13435
Value Function Loss: 0.02283

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.07476
Policy Update Magnitude: 0.30854
Value Function Update Magnitude: 0.33798

Collected Steps per Second: 21,055.84245
Overall Steps per Second: 10,133.13756

Timestep Collection Time: 2.37483
Timestep Consumption Time: 2.55987
PPO Batch Consumption Time: 0.30245
Total Iteration Time: 4.93470

Cumulative Model Updates: 231,338
Cumulative Timesteps: 1,930,022,838

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,364.46774
Policy Entropy: 2.11891
Value Function Loss: 0.02322

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.07512
Policy Update Magnitude: 0.31843
Value Function Update Magnitude: 0.34064

Collected Steps per Second: 21,306.74438
Overall Steps per Second: 10,493.25646

Timestep Collection Time: 2.34808
Timestep Consumption Time: 2.41974
PPO Batch Consumption Time: 0.27865
Total Iteration Time: 4.76782

Cumulative Model Updates: 231,344
Cumulative Timesteps: 1,930,072,868

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1930072868...
Checkpoint 1930072868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55,484.91430
Policy Entropy: 2.14427
Value Function Loss: 0.02555

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.08264
Policy Update Magnitude: 0.32325
Value Function Update Magnitude: 0.33525

Collected Steps per Second: 21,426.79392
Overall Steps per Second: 10,302.11488

Timestep Collection Time: 2.33353
Timestep Consumption Time: 2.51985
PPO Batch Consumption Time: 0.29542
Total Iteration Time: 4.85337

Cumulative Model Updates: 231,350
Cumulative Timesteps: 1,930,122,868

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54,418.35005
Policy Entropy: 2.12864
Value Function Loss: 0.02243

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.07715
Policy Update Magnitude: 0.31305
Value Function Update Magnitude: 0.33214

Collected Steps per Second: 21,096.13361
Overall Steps per Second: 10,408.27156

Timestep Collection Time: 2.37133
Timestep Consumption Time: 2.43503
PPO Batch Consumption Time: 0.28540
Total Iteration Time: 4.80637

Cumulative Model Updates: 231,356
Cumulative Timesteps: 1,930,172,894

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1930172894...
Checkpoint 1930172894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 63,860.78024
Policy Entropy: 2.13927
Value Function Loss: 0.02216

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.07269
Policy Update Magnitude: 0.30954
Value Function Update Magnitude: 0.33518

Collected Steps per Second: 21,164.29969
Overall Steps per Second: 10,512.46181

Timestep Collection Time: 2.36313
Timestep Consumption Time: 2.39446
PPO Batch Consumption Time: 0.28321
Total Iteration Time: 4.75759

Cumulative Model Updates: 231,362
Cumulative Timesteps: 1,930,222,908

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53,872.08792
Policy Entropy: 2.13421
Value Function Loss: 0.01965

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.07620
Policy Update Magnitude: 0.29723
Value Function Update Magnitude: 0.33136

Collected Steps per Second: 21,452.24097
Overall Steps per Second: 10,518.85695

Timestep Collection Time: 2.33160
Timestep Consumption Time: 2.42348
PPO Batch Consumption Time: 0.27994
Total Iteration Time: 4.75508

Cumulative Model Updates: 231,368
Cumulative Timesteps: 1,930,272,926

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1930272926...
Checkpoint 1930272926 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,809.99196
Policy Entropy: 2.13380
Value Function Loss: 0.02394

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.06797
Policy Update Magnitude: 0.29847
Value Function Update Magnitude: 0.33797

Collected Steps per Second: 21,856.41864
Overall Steps per Second: 10,634.96153

Timestep Collection Time: 2.28912
Timestep Consumption Time: 2.41536
PPO Batch Consumption Time: 0.27997
Total Iteration Time: 4.70448

Cumulative Model Updates: 231,374
Cumulative Timesteps: 1,930,322,958

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,151.27735
Policy Entropy: 2.13052
Value Function Loss: 0.02474

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.07028
Policy Update Magnitude: 0.31228
Value Function Update Magnitude: 0.34107

Collected Steps per Second: 21,734.33342
Overall Steps per Second: 10,496.45047

Timestep Collection Time: 2.30170
Timestep Consumption Time: 2.46429
PPO Batch Consumption Time: 0.28718
Total Iteration Time: 4.76599

Cumulative Model Updates: 231,380
Cumulative Timesteps: 1,930,372,984

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1930372984...
Checkpoint 1930372984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,646.03412
Policy Entropy: 2.12088
Value Function Loss: 0.02432

Mean KL Divergence: 0.01206
SB3 Clip Fraction: 0.08305
Policy Update Magnitude: 0.31466
Value Function Update Magnitude: 0.34463

Collected Steps per Second: 21,639.05056
Overall Steps per Second: 10,582.84846

Timestep Collection Time: 2.31128
Timestep Consumption Time: 2.41466
PPO Batch Consumption Time: 0.27986
Total Iteration Time: 4.72595

Cumulative Model Updates: 231,386
Cumulative Timesteps: 1,930,422,998

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45,365.50367
Policy Entropy: 2.13497
Value Function Loss: 0.02115

Mean KL Divergence: 0.01383
SB3 Clip Fraction: 0.08386
Policy Update Magnitude: 0.30136
Value Function Update Magnitude: 0.34203

Collected Steps per Second: 21,556.49480
Overall Steps per Second: 10,471.84887

Timestep Collection Time: 2.31976
Timestep Consumption Time: 2.45551
PPO Batch Consumption Time: 0.27979
Total Iteration Time: 4.77528

Cumulative Model Updates: 231,392
Cumulative Timesteps: 1,930,473,004

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1930473004...
Checkpoint 1930473004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,573.02250
Policy Entropy: 2.12655
Value Function Loss: 0.01992

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.08788
Policy Update Magnitude: 0.28674
Value Function Update Magnitude: 0.32659

Collected Steps per Second: 20,965.71375
Overall Steps per Second: 10,257.62317

Timestep Collection Time: 2.38590
Timestep Consumption Time: 2.49067
PPO Batch Consumption Time: 0.28810
Total Iteration Time: 4.87657

Cumulative Model Updates: 231,398
Cumulative Timesteps: 1,930,523,026

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,141.28520
Policy Entropy: 2.12395
Value Function Loss: 0.01821

Mean KL Divergence: 0.01100
SB3 Clip Fraction: 0.09188
Policy Update Magnitude: 0.29082
Value Function Update Magnitude: 0.31934

Collected Steps per Second: 21,058.44909
Overall Steps per Second: 10,389.69907

Timestep Collection Time: 2.37577
Timestep Consumption Time: 2.43958
PPO Batch Consumption Time: 0.27930
Total Iteration Time: 4.81535

Cumulative Model Updates: 231,404
Cumulative Timesteps: 1,930,573,056

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1930573056...
Checkpoint 1930573056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 76,180.30652
Policy Entropy: 2.13114
Value Function Loss: 0.01703

Mean KL Divergence: 0.01133
SB3 Clip Fraction: 0.09360
Policy Update Magnitude: 0.28489
Value Function Update Magnitude: 0.29580

Collected Steps per Second: 20,217.98664
Overall Steps per Second: 10,185.11265

Timestep Collection Time: 2.47324
Timestep Consumption Time: 2.43628
PPO Batch Consumption Time: 0.27970
Total Iteration Time: 4.90952

Cumulative Model Updates: 231,410
Cumulative Timesteps: 1,930,623,060

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97,803.19881
Policy Entropy: 2.12495
Value Function Loss: 0.02081

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.08405
Policy Update Magnitude: 0.29955
Value Function Update Magnitude: 0.27968

Collected Steps per Second: 21,193.91064
Overall Steps per Second: 10,194.98687

Timestep Collection Time: 2.36030
Timestep Consumption Time: 2.54642
PPO Batch Consumption Time: 0.30089
Total Iteration Time: 4.90673

Cumulative Model Updates: 231,416
Cumulative Timesteps: 1,930,673,084

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1930673084...
Checkpoint 1930673084 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 58,156.26740
Policy Entropy: 2.12919
Value Function Loss: 0.02184

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.08004
Policy Update Magnitude: 0.30595
Value Function Update Magnitude: 0.31549

Collected Steps per Second: 21,168.16410
Overall Steps per Second: 10,274.69233

Timestep Collection Time: 2.36317
Timestep Consumption Time: 2.50549
PPO Batch Consumption Time: 0.29294
Total Iteration Time: 4.86866

Cumulative Model Updates: 231,422
Cumulative Timesteps: 1,930,723,108

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,068.11925
Policy Entropy: 2.12019
Value Function Loss: 0.02457

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.07384
Policy Update Magnitude: 0.30619
Value Function Update Magnitude: 0.31591

Collected Steps per Second: 20,986.90569
Overall Steps per Second: 10,311.88472

Timestep Collection Time: 2.38330
Timestep Consumption Time: 2.46722
PPO Batch Consumption Time: 0.29493
Total Iteration Time: 4.85052

Cumulative Model Updates: 231,428
Cumulative Timesteps: 1,930,773,126

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1930773126...
Checkpoint 1930773126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,438.51767
Policy Entropy: 2.12769
Value Function Loss: 0.02419

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.07384
Policy Update Magnitude: 0.30429
Value Function Update Magnitude: 0.29912

Collected Steps per Second: 21,074.07614
Overall Steps per Second: 10,326.12896

Timestep Collection Time: 2.37410
Timestep Consumption Time: 2.47108
PPO Batch Consumption Time: 0.29286
Total Iteration Time: 4.84518

Cumulative Model Updates: 231,434
Cumulative Timesteps: 1,930,823,158

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,769.54706
Policy Entropy: 2.13627
Value Function Loss: 0.02193

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.07726
Policy Update Magnitude: 0.29904
Value Function Update Magnitude: 0.32010

Collected Steps per Second: 21,169.23031
Overall Steps per Second: 10,425.36998

Timestep Collection Time: 2.36296
Timestep Consumption Time: 2.43515
PPO Batch Consumption Time: 0.29238
Total Iteration Time: 4.79810

Cumulative Model Updates: 231,440
Cumulative Timesteps: 1,930,873,180

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1930873180...
Checkpoint 1930873180 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 56,777.04319
Policy Entropy: 2.13942
Value Function Loss: 0.01811

Mean KL Divergence: 0.00756
SB3 Clip Fraction: 0.07042
Policy Update Magnitude: 0.29477
Value Function Update Magnitude: 0.31033

Collected Steps per Second: 21,271.61896
Overall Steps per Second: 10,561.49284

Timestep Collection Time: 2.35177
Timestep Consumption Time: 2.38487
PPO Batch Consumption Time: 0.28493
Total Iteration Time: 4.73664

Cumulative Model Updates: 231,446
Cumulative Timesteps: 1,930,923,206

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65,236.56343
Policy Entropy: 2.14433
Value Function Loss: 0.01716

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.07151
Policy Update Magnitude: 0.28775
Value Function Update Magnitude: 0.29517

Collected Steps per Second: 21,390.57561
Overall Steps per Second: 10,511.93878

Timestep Collection Time: 2.33795
Timestep Consumption Time: 2.41950
PPO Batch Consumption Time: 0.27904
Total Iteration Time: 4.75745

Cumulative Model Updates: 231,452
Cumulative Timesteps: 1,930,973,216

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1930973216...
Checkpoint 1930973216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,698.45181
Policy Entropy: 2.13132
Value Function Loss: 0.01968

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.07448
Policy Update Magnitude: 0.29325
Value Function Update Magnitude: 0.29160

Collected Steps per Second: 21,641.21459
Overall Steps per Second: 10,557.18341

Timestep Collection Time: 2.31059
Timestep Consumption Time: 2.42590
PPO Batch Consumption Time: 0.28004
Total Iteration Time: 4.73649

Cumulative Model Updates: 231,458
Cumulative Timesteps: 1,931,023,220

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48,329.86424
Policy Entropy: 2.12695
Value Function Loss: 0.02013

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.07591
Policy Update Magnitude: 0.30816
Value Function Update Magnitude: 0.34295

Collected Steps per Second: 22,132.67486
Overall Steps per Second: 10,517.68967

Timestep Collection Time: 2.26100
Timestep Consumption Time: 2.49689
PPO Batch Consumption Time: 0.29352
Total Iteration Time: 4.75789

Cumulative Model Updates: 231,464
Cumulative Timesteps: 1,931,073,262

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1931073262...
Checkpoint 1931073262 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 70,335.58705
Policy Entropy: 2.11421
Value Function Loss: 0.02408

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.07659
Policy Update Magnitude: 0.30983
Value Function Update Magnitude: 0.34563

Collected Steps per Second: 21,788.91023
Overall Steps per Second: 10,574.07840

Timestep Collection Time: 2.29502
Timestep Consumption Time: 2.43409
PPO Batch Consumption Time: 0.27956
Total Iteration Time: 4.72911

Cumulative Model Updates: 231,470
Cumulative Timesteps: 1,931,123,268

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55,574.03541
Policy Entropy: 2.12406
Value Function Loss: 0.02506

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.07249
Policy Update Magnitude: 0.31454
Value Function Update Magnitude: 0.33809

Collected Steps per Second: 21,411.16539
Overall Steps per Second: 10,439.05359

Timestep Collection Time: 2.33626
Timestep Consumption Time: 2.45556
PPO Batch Consumption Time: 0.28068
Total Iteration Time: 4.79181

Cumulative Model Updates: 231,476
Cumulative Timesteps: 1,931,173,290

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1931173290...
Checkpoint 1931173290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,100.46518
Policy Entropy: 2.10480
Value Function Loss: 0.02613

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.07231
Policy Update Magnitude: 0.31244
Value Function Update Magnitude: 0.33360

Collected Steps per Second: 21,183.82706
Overall Steps per Second: 10,237.16802

Timestep Collection Time: 2.36133
Timestep Consumption Time: 2.52498
PPO Batch Consumption Time: 0.29548
Total Iteration Time: 4.88631

Cumulative Model Updates: 231,482
Cumulative Timesteps: 1,931,223,312

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46,448.90224
Policy Entropy: 2.13216
Value Function Loss: 0.02369

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.08000
Policy Update Magnitude: 0.30701
Value Function Update Magnitude: 0.33620

Collected Steps per Second: 21,527.93237
Overall Steps per Second: 10,505.86101

Timestep Collection Time: 2.32377
Timestep Consumption Time: 2.43795
PPO Batch Consumption Time: 0.27803
Total Iteration Time: 4.76172

Cumulative Model Updates: 231,488
Cumulative Timesteps: 1,931,273,338

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1931273338...
Checkpoint 1931273338 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,100.56338
Policy Entropy: 2.11836
Value Function Loss: 0.02147

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.07940
Policy Update Magnitude: 0.29976
Value Function Update Magnitude: 0.32120

Collected Steps per Second: 20,841.67869
Overall Steps per Second: 10,032.20831

Timestep Collection Time: 2.40029
Timestep Consumption Time: 2.58625
PPO Batch Consumption Time: 0.30725
Total Iteration Time: 4.98654

Cumulative Model Updates: 231,494
Cumulative Timesteps: 1,931,323,364

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,567.05904
Policy Entropy: 2.12950
Value Function Loss: 0.02296

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.07268
Policy Update Magnitude: 0.30835
Value Function Update Magnitude: 0.33361

Collected Steps per Second: 21,381.13531
Overall Steps per Second: 10,329.76625

Timestep Collection Time: 2.33860
Timestep Consumption Time: 2.50197
PPO Batch Consumption Time: 0.29148
Total Iteration Time: 4.84057

Cumulative Model Updates: 231,500
Cumulative Timesteps: 1,931,373,366

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1931373366...
Checkpoint 1931373366 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 52,416.49348
Policy Entropy: 2.10985
Value Function Loss: 0.02317

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.07022
Policy Update Magnitude: 0.31506
Value Function Update Magnitude: 0.37224

Collected Steps per Second: 21,294.08371
Overall Steps per Second: 10,407.91714

Timestep Collection Time: 2.34873
Timestep Consumption Time: 2.45665
PPO Batch Consumption Time: 0.27922
Total Iteration Time: 4.80538

Cumulative Model Updates: 231,506
Cumulative Timesteps: 1,931,423,380

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,532.98381
Policy Entropy: 2.11713
Value Function Loss: 0.02618

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.07879
Policy Update Magnitude: 0.32102
Value Function Update Magnitude: 0.39941

Collected Steps per Second: 21,759.73782
Overall Steps per Second: 10,511.42694

Timestep Collection Time: 2.29994
Timestep Consumption Time: 2.46117
PPO Batch Consumption Time: 0.28033
Total Iteration Time: 4.76110

Cumulative Model Updates: 231,512
Cumulative Timesteps: 1,931,473,426

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1931473426...
Checkpoint 1931473426 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,218.40406
Policy Entropy: 2.12517
Value Function Loss: 0.02417

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.08482
Policy Update Magnitude: 0.31926
Value Function Update Magnitude: 0.40415

Collected Steps per Second: 21,345.82108
Overall Steps per Second: 10,586.51368

Timestep Collection Time: 2.34350
Timestep Consumption Time: 2.38175
PPO Batch Consumption Time: 0.28060
Total Iteration Time: 4.72526

Cumulative Model Updates: 231,518
Cumulative Timesteps: 1,931,523,450

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,356.65530
Policy Entropy: 2.12973
Value Function Loss: 0.02286

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.08953
Policy Update Magnitude: 0.31177
Value Function Update Magnitude: 0.39554

Collected Steps per Second: 21,056.87897
Overall Steps per Second: 10,545.52331

Timestep Collection Time: 2.37471
Timestep Consumption Time: 2.36702
PPO Batch Consumption Time: 0.27914
Total Iteration Time: 4.74173

Cumulative Model Updates: 231,524
Cumulative Timesteps: 1,931,573,454

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1931573454...
Checkpoint 1931573454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,631.82023
Policy Entropy: 2.13151
Value Function Loss: 0.02104

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.07513
Policy Update Magnitude: 0.30753
Value Function Update Magnitude: 0.36617

Collected Steps per Second: 21,148.81017
Overall Steps per Second: 10,558.07445

Timestep Collection Time: 2.36448
Timestep Consumption Time: 2.37180
PPO Batch Consumption Time: 0.28021
Total Iteration Time: 4.73628

Cumulative Model Updates: 231,530
Cumulative Timesteps: 1,931,623,460

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,071.14978
Policy Entropy: 2.12778
Value Function Loss: 0.01789

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.07241
Policy Update Magnitude: 0.29939
Value Function Update Magnitude: 0.32118

Collected Steps per Second: 21,539.48719
Overall Steps per Second: 10,569.23824

Timestep Collection Time: 2.32197
Timestep Consumption Time: 2.41007
PPO Batch Consumption Time: 0.27859
Total Iteration Time: 4.73203

Cumulative Model Updates: 231,536
Cumulative Timesteps: 1,931,673,474

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1931673474...
Checkpoint 1931673474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40,910.92495
Policy Entropy: 2.10973
Value Function Loss: 0.02008

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.07276
Policy Update Magnitude: 0.29541
Value Function Update Magnitude: 0.31486

Collected Steps per Second: 21,330.33587
Overall Steps per Second: 10,531.94337

Timestep Collection Time: 2.34474
Timestep Consumption Time: 2.40406
PPO Batch Consumption Time: 0.27973
Total Iteration Time: 4.74879

Cumulative Model Updates: 231,542
Cumulative Timesteps: 1,931,723,488

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85,557.57050
Policy Entropy: 2.13081
Value Function Loss: 0.02039

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.07258
Policy Update Magnitude: 0.29965
Value Function Update Magnitude: 0.31298

Collected Steps per Second: 21,448.25778
Overall Steps per Second: 10,556.99670

Timestep Collection Time: 2.33222
Timestep Consumption Time: 2.40606
PPO Batch Consumption Time: 0.27823
Total Iteration Time: 4.73828

Cumulative Model Updates: 231,548
Cumulative Timesteps: 1,931,773,510

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1931773510...
Checkpoint 1931773510 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,983.76657
Policy Entropy: 2.12727
Value Function Loss: 0.02554

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.07841
Policy Update Magnitude: 0.30478
Value Function Update Magnitude: 0.30845

Collected Steps per Second: 21,026.08682
Overall Steps per Second: 10,325.42141

Timestep Collection Time: 2.38009
Timestep Consumption Time: 2.46659
PPO Batch Consumption Time: 0.29009
Total Iteration Time: 4.84668

Cumulative Model Updates: 231,554
Cumulative Timesteps: 1,931,823,554

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46,061.00340
Policy Entropy: 2.13472
Value Function Loss: 0.02552

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.07978
Policy Update Magnitude: 0.30772
Value Function Update Magnitude: 0.32934

Collected Steps per Second: 21,562.04387
Overall Steps per Second: 10,349.51907

Timestep Collection Time: 2.31917
Timestep Consumption Time: 2.51255
PPO Batch Consumption Time: 0.29429
Total Iteration Time: 4.83172

Cumulative Model Updates: 231,560
Cumulative Timesteps: 1,931,873,560

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1931873560...
Checkpoint 1931873560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,090.62283
Policy Entropy: 2.12566
Value Function Loss: 0.02396

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.08976
Policy Update Magnitude: 0.30850
Value Function Update Magnitude: 0.33390

Collected Steps per Second: 21,314.95053
Overall Steps per Second: 10,477.10995

Timestep Collection Time: 2.34718
Timestep Consumption Time: 2.42799
PPO Batch Consumption Time: 0.27928
Total Iteration Time: 4.77517

Cumulative Model Updates: 231,566
Cumulative Timesteps: 1,931,923,590

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,624.63859
Policy Entropy: 2.12648
Value Function Loss: 0.02078

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.08653
Policy Update Magnitude: 0.30517
Value Function Update Magnitude: 0.29580

Collected Steps per Second: 21,340.46549
Overall Steps per Second: 10,135.03967

Timestep Collection Time: 2.34297
Timestep Consumption Time: 2.59041
PPO Batch Consumption Time: 0.30212
Total Iteration Time: 4.93338

Cumulative Model Updates: 231,572
Cumulative Timesteps: 1,931,973,590

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1931973590...
Checkpoint 1931973590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,946.32105
Policy Entropy: 2.12339
Value Function Loss: 0.01906

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.08460
Policy Update Magnitude: 0.30322
Value Function Update Magnitude: 0.31006

Collected Steps per Second: 21,282.88602
Overall Steps per Second: 10,236.71084

Timestep Collection Time: 2.35081
Timestep Consumption Time: 2.53670
PPO Batch Consumption Time: 0.29341
Total Iteration Time: 4.88751

Cumulative Model Updates: 231,578
Cumulative Timesteps: 1,932,023,622

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60,863.64071
Policy Entropy: 2.11971
Value Function Loss: 0.02068

Mean KL Divergence: 0.01286
SB3 Clip Fraction: 0.10406
Policy Update Magnitude: 0.29097
Value Function Update Magnitude: 0.32061

Collected Steps per Second: 22,071.06240
Overall Steps per Second: 10,465.27804

Timestep Collection Time: 2.26623
Timestep Consumption Time: 2.51320
PPO Batch Consumption Time: 0.29474
Total Iteration Time: 4.77942

Cumulative Model Updates: 231,584
Cumulative Timesteps: 1,932,073,640

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1932073640...
Checkpoint 1932073640 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 51,664.62432
Policy Entropy: 2.12965
Value Function Loss: 0.02171

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.08399
Policy Update Magnitude: 0.30311
Value Function Update Magnitude: 0.32478

Collected Steps per Second: 21,902.60603
Overall Steps per Second: 10,632.47107

Timestep Collection Time: 2.28302
Timestep Consumption Time: 2.41994
PPO Batch Consumption Time: 0.27855
Total Iteration Time: 4.70295

Cumulative Model Updates: 231,590
Cumulative Timesteps: 1,932,123,644

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68,205.74657
Policy Entropy: 2.13632
Value Function Loss: 0.02063

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.08948
Policy Update Magnitude: 0.30240
Value Function Update Magnitude: 0.32420

Collected Steps per Second: 21,553.68332
Overall Steps per Second: 10,524.76179

Timestep Collection Time: 2.31997
Timestep Consumption Time: 2.43111
PPO Batch Consumption Time: 0.29243
Total Iteration Time: 4.75108

Cumulative Model Updates: 231,596
Cumulative Timesteps: 1,932,173,648

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1932173648...
Checkpoint 1932173648 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 65,562.87124
Policy Entropy: 2.13435
Value Function Loss: 0.01922

Mean KL Divergence: 0.01400
SB3 Clip Fraction: 0.10790
Policy Update Magnitude: 0.29024
Value Function Update Magnitude: 0.29992

Collected Steps per Second: 21,240.96790
Overall Steps per Second: 10,492.85428

Timestep Collection Time: 2.35460
Timestep Consumption Time: 2.41188
PPO Batch Consumption Time: 0.28794
Total Iteration Time: 4.76648

Cumulative Model Updates: 231,602
Cumulative Timesteps: 1,932,223,662

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 69,708.87539
Policy Entropy: 2.10070
Value Function Loss: 0.01937

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.07920
Policy Update Magnitude: 0.29609
Value Function Update Magnitude: 0.28800

Collected Steps per Second: 21,411.55597
Overall Steps per Second: 10,469.17657

Timestep Collection Time: 2.33519
Timestep Consumption Time: 2.44074
PPO Batch Consumption Time: 0.29490
Total Iteration Time: 4.77592

Cumulative Model Updates: 231,608
Cumulative Timesteps: 1,932,273,662

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1932273662...
Checkpoint 1932273662 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 70,449.53074
Policy Entropy: 2.09062
Value Function Loss: 0.02285

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.08386
Policy Update Magnitude: 0.31099
Value Function Update Magnitude: 0.33172

Collected Steps per Second: 20,887.37087
Overall Steps per Second: 10,222.03396

Timestep Collection Time: 2.39494
Timestep Consumption Time: 2.49880
PPO Batch Consumption Time: 0.29373
Total Iteration Time: 4.89374

Cumulative Model Updates: 231,614
Cumulative Timesteps: 1,932,323,686

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50,893.16940
Policy Entropy: 2.09001
Value Function Loss: 0.02256

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.07916
Policy Update Magnitude: 0.31467
Value Function Update Magnitude: 0.33152

Collected Steps per Second: 21,224.64649
Overall Steps per Second: 10,478.73407

Timestep Collection Time: 2.35688
Timestep Consumption Time: 2.41698
PPO Batch Consumption Time: 0.27917
Total Iteration Time: 4.77386

Cumulative Model Updates: 231,620
Cumulative Timesteps: 1,932,373,710

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1932373710...
Checkpoint 1932373710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55,177.77851
Policy Entropy: 2.10956
Value Function Loss: 0.02172

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.07541
Policy Update Magnitude: 0.30689
Value Function Update Magnitude: 0.31258

Collected Steps per Second: 21,258.54640
Overall Steps per Second: 10,351.72288

Timestep Collection Time: 2.35312
Timestep Consumption Time: 2.47931
PPO Batch Consumption Time: 0.29071
Total Iteration Time: 4.83243

Cumulative Model Updates: 231,626
Cumulative Timesteps: 1,932,423,734

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56,745.35272
Policy Entropy: 2.12796
Value Function Loss: 0.01969

Mean KL Divergence: 0.00684
SB3 Clip Fraction: 0.06488
Policy Update Magnitude: 0.29778
Value Function Update Magnitude: 0.26206

Collected Steps per Second: 20,985.52767
Overall Steps per Second: 10,237.71001

Timestep Collection Time: 2.38345
Timestep Consumption Time: 2.50221
PPO Batch Consumption Time: 0.27995
Total Iteration Time: 4.88566

Cumulative Model Updates: 231,632
Cumulative Timesteps: 1,932,473,752

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1932473752...
Checkpoint 1932473752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 74,204.75981
Policy Entropy: 2.13195
Value Function Loss: 0.01964

Mean KL Divergence: 0.00660
SB3 Clip Fraction: 0.06357
Policy Update Magnitude: 0.29778
Value Function Update Magnitude: 0.23402

Collected Steps per Second: 20,791.15501
Overall Steps per Second: 10,281.46893

Timestep Collection Time: 2.40670
Timestep Consumption Time: 2.46012
PPO Batch Consumption Time: 0.27923
Total Iteration Time: 4.86681

Cumulative Model Updates: 231,638
Cumulative Timesteps: 1,932,523,790

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47,832.52092
Policy Entropy: 2.13273
Value Function Loss: 0.02017

Mean KL Divergence: 0.00721
SB3 Clip Fraction: 0.06766
Policy Update Magnitude: 0.30253
Value Function Update Magnitude: 0.23854

Collected Steps per Second: 21,672.37325
Overall Steps per Second: 10,210.40795

Timestep Collection Time: 2.30745
Timestep Consumption Time: 2.59029
PPO Batch Consumption Time: 0.30880
Total Iteration Time: 4.89775

Cumulative Model Updates: 231,644
Cumulative Timesteps: 1,932,573,798

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1932573798...
Checkpoint 1932573798 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47,064.41380
Policy Entropy: 2.13177
Value Function Loss: 0.02053

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.08846
Policy Update Magnitude: 0.29941
Value Function Update Magnitude: 0.22885

Collected Steps per Second: 21,950.71618
Overall Steps per Second: 10,412.87441

Timestep Collection Time: 2.27847
Timestep Consumption Time: 2.52462
PPO Batch Consumption Time: 0.29038
Total Iteration Time: 4.80309

Cumulative Model Updates: 231,650
Cumulative Timesteps: 1,932,623,812

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,522.71191
Policy Entropy: 2.14399
Value Function Loss: 0.02256

Mean KL Divergence: 0.01382
SB3 Clip Fraction: 0.10428
Policy Update Magnitude: 0.29860
Value Function Update Magnitude: 0.26782

Collected Steps per Second: 22,004.90557
Overall Steps per Second: 10,472.48779

Timestep Collection Time: 2.27313
Timestep Consumption Time: 2.50320
PPO Batch Consumption Time: 0.28655
Total Iteration Time: 4.77632

Cumulative Model Updates: 231,656
Cumulative Timesteps: 1,932,673,832

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1932673832...
Checkpoint 1932673832 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,783.72046
Policy Entropy: 2.13622
Value Function Loss: 0.02343

Mean KL Divergence: 0.01234
SB3 Clip Fraction: 0.09814
Policy Update Magnitude: 0.30653
Value Function Update Magnitude: 0.29218

Collected Steps per Second: 21,984.96907
Overall Steps per Second: 10,615.75654

Timestep Collection Time: 2.27528
Timestep Consumption Time: 2.43677
PPO Batch Consumption Time: 0.27918
Total Iteration Time: 4.71205

Cumulative Model Updates: 231,662
Cumulative Timesteps: 1,932,723,854

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,425.80553
Policy Entropy: 2.12897
Value Function Loss: 0.02407

Mean KL Divergence: 0.01291
SB3 Clip Fraction: 0.10229
Policy Update Magnitude: 0.30733
Value Function Update Magnitude: 0.26954

Collected Steps per Second: 22,047.75088
Overall Steps per Second: 10,455.72748

Timestep Collection Time: 2.26844
Timestep Consumption Time: 2.51497
PPO Batch Consumption Time: 0.29197
Total Iteration Time: 4.78341

Cumulative Model Updates: 231,668
Cumulative Timesteps: 1,932,773,868

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1932773868...
Checkpoint 1932773868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,678.19421
Policy Entropy: 2.10702
Value Function Loss: 0.02449

Mean KL Divergence: 0.01351
SB3 Clip Fraction: 0.10905
Policy Update Magnitude: 0.29397
Value Function Update Magnitude: 0.28911

Collected Steps per Second: 21,661.07922
Overall Steps per Second: 10,560.08956

Timestep Collection Time: 2.30866
Timestep Consumption Time: 2.42691
PPO Batch Consumption Time: 0.27991
Total Iteration Time: 4.73557

Cumulative Model Updates: 231,674
Cumulative Timesteps: 1,932,823,876

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46,488.92692
Policy Entropy: 2.11799
Value Function Loss: 0.02435

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.09312
Policy Update Magnitude: 0.29411
Value Function Update Magnitude: 0.31693

Collected Steps per Second: 22,110.80286
Overall Steps per Second: 10,525.72663

Timestep Collection Time: 2.26242
Timestep Consumption Time: 2.49012
PPO Batch Consumption Time: 0.28815
Total Iteration Time: 4.75255

Cumulative Model Updates: 231,680
Cumulative Timesteps: 1,932,873,900

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1932873900...
Checkpoint 1932873900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,297.97397
Policy Entropy: 2.12350
Value Function Loss: 0.02301

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.08243
Policy Update Magnitude: 0.30769
Value Function Update Magnitude: 0.32238

Collected Steps per Second: 21,631.08064
Overall Steps per Second: 10,441.63257

Timestep Collection Time: 2.31371
Timestep Consumption Time: 2.47941
PPO Batch Consumption Time: 0.29025
Total Iteration Time: 4.79312

Cumulative Model Updates: 231,686
Cumulative Timesteps: 1,932,923,948

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53,976.04453
Policy Entropy: 2.13274
Value Function Loss: 0.02355

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.08204
Policy Update Magnitude: 0.30517
Value Function Update Magnitude: 0.31246

Collected Steps per Second: 21,790.12925
Overall Steps per Second: 10,448.82792

Timestep Collection Time: 2.29553
Timestep Consumption Time: 2.49160
PPO Batch Consumption Time: 0.28997
Total Iteration Time: 4.78714

Cumulative Model Updates: 231,692
Cumulative Timesteps: 1,932,973,968

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1932973968...
Checkpoint 1932973968 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,971.86167
Policy Entropy: 2.14701
Value Function Loss: 0.03256

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.08201
Policy Update Magnitude: 0.31992
Value Function Update Magnitude: 0.29521

Collected Steps per Second: 21,093.35374
Overall Steps per Second: 10,398.87917

Timestep Collection Time: 2.37041
Timestep Consumption Time: 2.43780
PPO Batch Consumption Time: 0.27884
Total Iteration Time: 4.80821

Cumulative Model Updates: 231,698
Cumulative Timesteps: 1,933,023,968

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 64,475.07307
Policy Entropy: 2.13761
Value Function Loss: 0.03196

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.08901
Policy Update Magnitude: 0.33107
Value Function Update Magnitude: 0.24021

Collected Steps per Second: 21,377.71476
Overall Steps per Second: 10,464.43479

Timestep Collection Time: 2.33916
Timestep Consumption Time: 2.43950
PPO Batch Consumption Time: 0.27921
Total Iteration Time: 4.77866

Cumulative Model Updates: 231,704
Cumulative Timesteps: 1,933,073,974

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1933073974...
Checkpoint 1933073974 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,942.12520
Policy Entropy: 2.13561
Value Function Loss: 0.03271

Mean KL Divergence: 0.01107
SB3 Clip Fraction: 0.09701
Policy Update Magnitude: 0.31884
Value Function Update Magnitude: 0.20631

Collected Steps per Second: 21,529.80272
Overall Steps per Second: 10,307.13914

Timestep Collection Time: 2.32236
Timestep Consumption Time: 2.52864
PPO Batch Consumption Time: 0.29361
Total Iteration Time: 4.85101

Cumulative Model Updates: 231,710
Cumulative Timesteps: 1,933,123,974

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,281.63597
Policy Entropy: 2.11880
Value Function Loss: 0.03161

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.08929
Policy Update Magnitude: 0.32402
Value Function Update Magnitude: 0.17640

Collected Steps per Second: 22,235.94603
Overall Steps per Second: 10,457.76873

Timestep Collection Time: 2.24978
Timestep Consumption Time: 2.53384
PPO Batch Consumption Time: 0.29417
Total Iteration Time: 4.78362

Cumulative Model Updates: 231,716
Cumulative Timesteps: 1,933,174,000

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1933174000...
Checkpoint 1933174000 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43,083.14326
Policy Entropy: 2.11736
Value Function Loss: 0.03283

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.08263
Policy Update Magnitude: 0.32560
Value Function Update Magnitude: 0.15757

Collected Steps per Second: 21,940.80291
Overall Steps per Second: 10,565.67070

Timestep Collection Time: 2.27941
Timestep Consumption Time: 2.45404
PPO Batch Consumption Time: 0.27899
Total Iteration Time: 4.73344

Cumulative Model Updates: 231,722
Cumulative Timesteps: 1,933,224,012

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50,549.56112
Policy Entropy: 2.11324
Value Function Loss: 0.02868

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.08693
Policy Update Magnitude: 0.32650
Value Function Update Magnitude: 0.23099

Collected Steps per Second: 21,815.98961
Overall Steps per Second: 10,609.47311

Timestep Collection Time: 2.29208
Timestep Consumption Time: 2.42107
PPO Batch Consumption Time: 0.29050
Total Iteration Time: 4.71315

Cumulative Model Updates: 231,728
Cumulative Timesteps: 1,933,274,016

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1933274016...
Checkpoint 1933274016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,275.04697
Policy Entropy: 2.13065
Value Function Loss: 0.02372

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.07594
Policy Update Magnitude: 0.31475
Value Function Update Magnitude: 0.30020

Collected Steps per Second: 21,516.27405
Overall Steps per Second: 10,520.95313

Timestep Collection Time: 2.32484
Timestep Consumption Time: 2.42967
PPO Batch Consumption Time: 0.29328
Total Iteration Time: 4.75451

Cumulative Model Updates: 231,734
Cumulative Timesteps: 1,933,324,038

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42,088.41981
Policy Entropy: 2.13533
Value Function Loss: 0.02204

Mean KL Divergence: 0.00718
SB3 Clip Fraction: 0.06622
Policy Update Magnitude: 0.31384
Value Function Update Magnitude: 0.30603

Collected Steps per Second: 21,651.83648
Overall Steps per Second: 10,603.19708

Timestep Collection Time: 2.31066
Timestep Consumption Time: 2.40773
PPO Batch Consumption Time: 0.28884
Total Iteration Time: 4.71839

Cumulative Model Updates: 231,740
Cumulative Timesteps: 1,933,374,068

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1933374068...
Checkpoint 1933374068 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,971.66569
Policy Entropy: 2.14707
Value Function Loss: 0.02254

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.07847
Policy Update Magnitude: 0.30867
Value Function Update Magnitude: 0.27473

Collected Steps per Second: 21,318.62850
Overall Steps per Second: 10,418.60617

Timestep Collection Time: 2.34706
Timestep Consumption Time: 2.45551
PPO Batch Consumption Time: 0.28673
Total Iteration Time: 4.80256

Cumulative Model Updates: 231,746
Cumulative Timesteps: 1,933,424,104

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,597.27034
Policy Entropy: 2.12709
Value Function Loss: 0.02137

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.07202
Policy Update Magnitude: 0.30382
Value Function Update Magnitude: 0.26850

Collected Steps per Second: 21,707.22031
Overall Steps per Second: 10,497.31777

Timestep Collection Time: 2.30559
Timestep Consumption Time: 2.46210
PPO Batch Consumption Time: 0.28766
Total Iteration Time: 4.76769

Cumulative Model Updates: 231,752
Cumulative Timesteps: 1,933,474,152

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 1933474152...
Checkpoint 1933474152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,978.14725
Policy Entropy: 2.12387
Value Function Loss: 0.02150

Mean KL Divergence: 0.00738
SB3 Clip Fraction: 0.06911
Policy Update Magnitude: 0.30204
Value Function Update Magnitude: 0.30990

Collected Steps per Second: 21,280.65296
Overall Steps per Second: 10,533.87081

Timestep Collection Time: 2.35200
Timestep Consumption Time: 2.39953
PPO Batch Consumption Time: 0.27864
Total Iteration Time: 4.75153

Cumulative Model Updates: 231,758
Cumulative Timesteps: 1,933,524,204

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,347.78785
Policy Entropy: 2.10582
Value Function Loss: 0.02207

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.07293
Policy Update Magnitude: 0.30050
Value Function Update Magnitude: 0.32915

Collected Steps per Second: 21,619.67725
Overall Steps per Second: 10,477.70661

Timestep Collection Time: 2.31299
Timestep Consumption Time: 2.45962
PPO Batch Consumption Time: 0.27912
Total Iteration Time: 4.77261

Cumulative Model Updates: 231,764
Cumulative Timesteps: 1,933,574,210

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1933574210...
Checkpoint 1933574210 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,911.13302
Policy Entropy: 2.12693
Value Function Loss: 0.02502

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.07663
Policy Update Magnitude: 0.31239
Value Function Update Magnitude: 0.34988

Collected Steps per Second: 21,592.82313
Overall Steps per Second: 10,334.85116

Timestep Collection Time: 2.31679
Timestep Consumption Time: 2.52373
PPO Batch Consumption Time: 0.29351
Total Iteration Time: 4.84051

Cumulative Model Updates: 231,770
Cumulative Timesteps: 1,933,624,236

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,908.07096
Policy Entropy: 2.12420
Value Function Loss: 0.02262

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.07394
Policy Update Magnitude: 0.31116
Value Function Update Magnitude: 0.34193

Collected Steps per Second: 22,197.08268
Overall Steps per Second: 10,437.11836

Timestep Collection Time: 2.25435
Timestep Consumption Time: 2.54008
PPO Batch Consumption Time: 0.29408
Total Iteration Time: 4.79443

Cumulative Model Updates: 231,776
Cumulative Timesteps: 1,933,674,276

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1933674276...
Checkpoint 1933674276 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47,141.51141
Policy Entropy: 2.12691
Value Function Loss: 0.02463

Mean KL Divergence: 0.00763
SB3 Clip Fraction: 0.06923
Policy Update Magnitude: 0.30511
Value Function Update Magnitude: 0.29248

Collected Steps per Second: 21,990.82618
Overall Steps per Second: 10,627.22603

Timestep Collection Time: 2.27449
Timestep Consumption Time: 2.43210
PPO Batch Consumption Time: 0.27803
Total Iteration Time: 4.70659

Cumulative Model Updates: 231,782
Cumulative Timesteps: 1,933,724,294

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,623.28174
Policy Entropy: 2.09884
Value Function Loss: 0.02293

Mean KL Divergence: 0.00692
SB3 Clip Fraction: 0.06900
Policy Update Magnitude: 0.30929
Value Function Update Magnitude: 0.27953

Collected Steps per Second: 22,303.24664
Overall Steps per Second: 10,523.60191

Timestep Collection Time: 2.24210
Timestep Consumption Time: 2.50970
PPO Batch Consumption Time: 0.29240
Total Iteration Time: 4.75180

Cumulative Model Updates: 231,788
Cumulative Timesteps: 1,933,774,300

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1933774300...
Checkpoint 1933774300 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,498.43418
Policy Entropy: 2.10744
Value Function Loss: 0.02519

Mean KL Divergence: 0.00734
SB3 Clip Fraction: 0.07006
Policy Update Magnitude: 0.31685
Value Function Update Magnitude: 0.31013

Collected Steps per Second: 21,821.94757
Overall Steps per Second: 10,501.36896

Timestep Collection Time: 2.29127
Timestep Consumption Time: 2.47001
PPO Batch Consumption Time: 0.28507
Total Iteration Time: 4.76128

Cumulative Model Updates: 231,794
Cumulative Timesteps: 1,933,824,300

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,127.96542
Policy Entropy: 2.10989
Value Function Loss: 0.02573

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.07090
Policy Update Magnitude: 0.32390
Value Function Update Magnitude: 0.29861

Collected Steps per Second: 22,129.21124
Overall Steps per Second: 10,469.50596

Timestep Collection Time: 2.25964
Timestep Consumption Time: 2.51652
PPO Batch Consumption Time: 0.29388
Total Iteration Time: 4.77616

Cumulative Model Updates: 231,800
Cumulative Timesteps: 1,933,874,304

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1933874304...
Checkpoint 1933874304 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,222.61386
Policy Entropy: 2.10328
Value Function Loss: 0.02368

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.07340
Policy Update Magnitude: 0.32000
Value Function Update Magnitude: 0.26222

Collected Steps per Second: 21,348.36335
Overall Steps per Second: 10,321.70455

Timestep Collection Time: 2.34219
Timestep Consumption Time: 2.50216
PPO Batch Consumption Time: 0.29308
Total Iteration Time: 4.84435

Cumulative Model Updates: 231,806
Cumulative Timesteps: 1,933,924,306

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,749.54243
Policy Entropy: 2.09785
Value Function Loss: 0.02727

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.07754
Policy Update Magnitude: 0.32443
Value Function Update Magnitude: 0.24609

Collected Steps per Second: 21,963.40779
Overall Steps per Second: 10,451.62087

Timestep Collection Time: 2.27688
Timestep Consumption Time: 2.50783
PPO Batch Consumption Time: 0.29247
Total Iteration Time: 4.78471

Cumulative Model Updates: 231,812
Cumulative Timesteps: 1,933,974,314

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1933974314...
Checkpoint 1933974314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,795.49797
Policy Entropy: 2.11216
Value Function Loss: 0.02885

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.07641
Policy Update Magnitude: 0.32958
Value Function Update Magnitude: 0.24485

Collected Steps per Second: 21,436.80333
Overall Steps per Second: 10,477.36713

Timestep Collection Time: 2.33300
Timestep Consumption Time: 2.44034
PPO Batch Consumption Time: 0.27905
Total Iteration Time: 4.77334

Cumulative Model Updates: 231,818
Cumulative Timesteps: 1,934,024,326

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,759.19935
Policy Entropy: 2.12477
Value Function Loss: 0.02842

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.07726
Policy Update Magnitude: 0.32550
Value Function Update Magnitude: 0.28108

Collected Steps per Second: 21,625.98201
Overall Steps per Second: 10,555.17488

Timestep Collection Time: 2.31222
Timestep Consumption Time: 2.42517
PPO Batch Consumption Time: 0.27728
Total Iteration Time: 4.73739

Cumulative Model Updates: 231,824
Cumulative Timesteps: 1,934,074,330

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1934074330...
Checkpoint 1934074330 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40,190.63981
Policy Entropy: 2.12970
Value Function Loss: 0.02528

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.07472
Policy Update Magnitude: 0.32188
Value Function Update Magnitude: 0.36214

Collected Steps per Second: 21,405.63254
Overall Steps per Second: 10,518.78574

Timestep Collection Time: 2.33695
Timestep Consumption Time: 2.41873
PPO Batch Consumption Time: 0.27861
Total Iteration Time: 4.75568

Cumulative Model Updates: 231,830
Cumulative Timesteps: 1,934,124,354

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,366.38750
Policy Entropy: 2.12098
Value Function Loss: 0.02293

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.08068
Policy Update Magnitude: 0.32209
Value Function Update Magnitude: 0.34861

Collected Steps per Second: 21,702.15071
Overall Steps per Second: 10,522.20617

Timestep Collection Time: 2.30567
Timestep Consumption Time: 2.44980
PPO Batch Consumption Time: 0.28013
Total Iteration Time: 4.75547

Cumulative Model Updates: 231,836
Cumulative Timesteps: 1,934,174,392

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1934174392...
Checkpoint 1934174392 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,601.94685
Policy Entropy: 2.11959
Value Function Loss: 0.02313

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.08334
Policy Update Magnitude: 0.31921
Value Function Update Magnitude: 0.34917

Collected Steps per Second: 21,302.44204
Overall Steps per Second: 10,234.21498

Timestep Collection Time: 2.34809
Timestep Consumption Time: 2.53944
PPO Batch Consumption Time: 0.29315
Total Iteration Time: 4.88753

Cumulative Model Updates: 231,842
Cumulative Timesteps: 1,934,224,412

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,898.74155
Policy Entropy: 2.12965
Value Function Loss: 0.02079

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.08512
Policy Update Magnitude: 0.30832
Value Function Update Magnitude: 0.33107

Collected Steps per Second: 21,738.55152
Overall Steps per Second: 10,483.31738

Timestep Collection Time: 2.30190
Timestep Consumption Time: 2.47140
PPO Batch Consumption Time: 0.29372
Total Iteration Time: 4.77330

Cumulative Model Updates: 231,848
Cumulative Timesteps: 1,934,274,452

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1934274452...
Checkpoint 1934274452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,231.62971
Policy Entropy: 2.13235
Value Function Loss: 0.01961

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.08877
Policy Update Magnitude: 0.30090
Value Function Update Magnitude: 0.31100

Collected Steps per Second: 21,181.65550
Overall Steps per Second: 10,549.56763

Timestep Collection Time: 2.36119
Timestep Consumption Time: 2.37966
PPO Batch Consumption Time: 0.27990
Total Iteration Time: 4.74086

Cumulative Model Updates: 231,854
Cumulative Timesteps: 1,934,324,466

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75,424.16928
Policy Entropy: 2.13297
Value Function Loss: 0.02089

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.09047
Policy Update Magnitude: 0.30385
Value Function Update Magnitude: 0.28868

Collected Steps per Second: 21,062.71153
Overall Steps per Second: 10,465.21042

Timestep Collection Time: 2.37491
Timestep Consumption Time: 2.40493
PPO Batch Consumption Time: 0.28573
Total Iteration Time: 4.77984

Cumulative Model Updates: 231,860
Cumulative Timesteps: 1,934,374,488

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1934374488...
Checkpoint 1934374488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,430.45787
Policy Entropy: 2.13041
Value Function Loss: 0.02000

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.07944
Policy Update Magnitude: 0.30218
Value Function Update Magnitude: 0.28371

Collected Steps per Second: 20,392.36927
Overall Steps per Second: 10,219.47376

Timestep Collection Time: 2.45327
Timestep Consumption Time: 2.44209
PPO Batch Consumption Time: 0.29262
Total Iteration Time: 4.89536

Cumulative Model Updates: 231,866
Cumulative Timesteps: 1,934,424,516

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,246.79880
Policy Entropy: 2.12059
Value Function Loss: 0.02137

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.07219
Policy Update Magnitude: 0.30331
Value Function Update Magnitude: 0.29718

Collected Steps per Second: 21,467.90410
Overall Steps per Second: 10,548.31191

Timestep Collection Time: 2.33027
Timestep Consumption Time: 2.41229
PPO Batch Consumption Time: 0.27748
Total Iteration Time: 4.74256

Cumulative Model Updates: 231,872
Cumulative Timesteps: 1,934,474,542

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1934474542...
Checkpoint 1934474542 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,776.56939
Policy Entropy: 2.14015
Value Function Loss: 0.02046

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.07462
Policy Update Magnitude: 0.30305
Value Function Update Magnitude: 0.30431

Collected Steps per Second: 21,501.87128
Overall Steps per Second: 10,543.17477

Timestep Collection Time: 2.32659
Timestep Consumption Time: 2.41828
PPO Batch Consumption Time: 0.27918
Total Iteration Time: 4.74487

Cumulative Model Updates: 231,878
Cumulative Timesteps: 1,934,524,568

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53,079.82992
Policy Entropy: 2.15370
Value Function Loss: 0.02014

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.08308
Policy Update Magnitude: 0.30231
Value Function Update Magnitude: 0.28002

Collected Steps per Second: 22,039.79579
Overall Steps per Second: 10,458.35064

Timestep Collection Time: 2.26971
Timestep Consumption Time: 2.51345
PPO Batch Consumption Time: 0.28926
Total Iteration Time: 4.78316

Cumulative Model Updates: 231,884
Cumulative Timesteps: 1,934,574,592

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1934574592...
Checkpoint 1934574592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,774.53238
Policy Entropy: 2.16669
Value Function Loss: 0.02042

Mean KL Divergence: 0.01130
SB3 Clip Fraction: 0.07634
Policy Update Magnitude: 0.29932
Value Function Update Magnitude: 0.27432

Collected Steps per Second: 21,641.17509
Overall Steps per Second: 10,335.63665

Timestep Collection Time: 2.31106
Timestep Consumption Time: 2.52793
PPO Batch Consumption Time: 0.29134
Total Iteration Time: 4.83899

Cumulative Model Updates: 231,890
Cumulative Timesteps: 1,934,624,606

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61,005.29333
Policy Entropy: 2.15119
Value Function Loss: 0.02218

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.08015
Policy Update Magnitude: 0.30069
Value Function Update Magnitude: 0.30476

Collected Steps per Second: 22,349.53098
Overall Steps per Second: 10,705.42481

Timestep Collection Time: 2.23727
Timestep Consumption Time: 2.43344
PPO Batch Consumption Time: 0.27919
Total Iteration Time: 4.67072

Cumulative Model Updates: 231,896
Cumulative Timesteps: 1,934,674,608

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1934674608...
Checkpoint 1934674608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 65,367.21837
Policy Entropy: 2.13226
Value Function Loss: 0.02304

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.07934
Policy Update Magnitude: 0.30783
Value Function Update Magnitude: 0.32953

Collected Steps per Second: 21,425.89778
Overall Steps per Second: 10,328.86218

Timestep Collection Time: 2.33549
Timestep Consumption Time: 2.50919
PPO Batch Consumption Time: 0.29419
Total Iteration Time: 4.84468

Cumulative Model Updates: 231,902
Cumulative Timesteps: 1,934,724,648

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,062.24858
Policy Entropy: 2.10953
Value Function Loss: 0.02238

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.07450
Policy Update Magnitude: 0.32023
Value Function Update Magnitude: 0.33520

Collected Steps per Second: 22,309.97348
Overall Steps per Second: 10,568.99777

Timestep Collection Time: 2.24187
Timestep Consumption Time: 2.49046
PPO Batch Consumption Time: 0.29089
Total Iteration Time: 4.73233

Cumulative Model Updates: 231,908
Cumulative Timesteps: 1,934,774,664

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1934774664...
Checkpoint 1934774664 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 67,199.23300
Policy Entropy: 2.12504
Value Function Loss: 0.02290

Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.07447
Policy Update Magnitude: 0.31929
Value Function Update Magnitude: 0.33751

Collected Steps per Second: 21,807.98393
Overall Steps per Second: 10,419.57069

Timestep Collection Time: 2.29274
Timestep Consumption Time: 2.50592
PPO Batch Consumption Time: 0.28989
Total Iteration Time: 4.79866

Cumulative Model Updates: 231,914
Cumulative Timesteps: 1,934,824,664

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49,614.76663
Policy Entropy: 2.12842
Value Function Loss: 0.02201

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.07323
Policy Update Magnitude: 0.31188
Value Function Update Magnitude: 0.33425

Collected Steps per Second: 22,200.78017
Overall Steps per Second: 10,480.30520

Timestep Collection Time: 2.25289
Timestep Consumption Time: 2.51949
PPO Batch Consumption Time: 0.29408
Total Iteration Time: 4.77238

Cumulative Model Updates: 231,920
Cumulative Timesteps: 1,934,874,680

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1934874680...
Checkpoint 1934874680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 73,999.58543
Policy Entropy: 2.15469
Value Function Loss: 0.02072

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.07434
Policy Update Magnitude: 0.29605
Value Function Update Magnitude: 0.31141

Collected Steps per Second: 20,940.72698
Overall Steps per Second: 10,204.36617

Timestep Collection Time: 2.38893
Timestep Consumption Time: 2.51348
PPO Batch Consumption Time: 0.29252
Total Iteration Time: 4.90241

Cumulative Model Updates: 231,926
Cumulative Timesteps: 1,934,924,706

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61,928.43578
Policy Entropy: 2.15165
Value Function Loss: 0.01960

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.07683
Policy Update Magnitude: 0.28993
Value Function Update Magnitude: 0.29236

Collected Steps per Second: 21,783.38542
Overall Steps per Second: 10,463.33492

Timestep Collection Time: 2.29579
Timestep Consumption Time: 2.48376
PPO Batch Consumption Time: 0.28782
Total Iteration Time: 4.77955

Cumulative Model Updates: 231,932
Cumulative Timesteps: 1,934,974,716

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1934974716...
Checkpoint 1934974716 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 56,022.26853
Policy Entropy: 2.15330
Value Function Loss: 0.02035

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.07884
Policy Update Magnitude: 0.29110
Value Function Update Magnitude: 0.28892

Collected Steps per Second: 21,050.03639
Overall Steps per Second: 10,192.00298

Timestep Collection Time: 2.37605
Timestep Consumption Time: 2.53132
PPO Batch Consumption Time: 0.29446
Total Iteration Time: 4.90738

Cumulative Model Updates: 231,938
Cumulative Timesteps: 1,935,024,732

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61,241.68789
Policy Entropy: 2.15789
Value Function Loss: 0.02116

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.07558
Policy Update Magnitude: 0.30802
Value Function Update Magnitude: 0.32089

Collected Steps per Second: 21,558.71891
Overall Steps per Second: 10,542.21372

Timestep Collection Time: 2.32008
Timestep Consumption Time: 2.42446
PPO Batch Consumption Time: 0.27705
Total Iteration Time: 4.74454

Cumulative Model Updates: 231,944
Cumulative Timesteps: 1,935,074,750

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1935074750...
Checkpoint 1935074750 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 54,690.86882
Policy Entropy: 2.16659
Value Function Loss: 0.02509

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.07496
Policy Update Magnitude: 0.31166
Value Function Update Magnitude: 0.36048

Collected Steps per Second: 21,404.88020
Overall Steps per Second: 10,488.51760

Timestep Collection Time: 2.33592
Timestep Consumption Time: 2.43120
PPO Batch Consumption Time: 0.27885
Total Iteration Time: 4.76712

Cumulative Model Updates: 231,950
Cumulative Timesteps: 1,935,124,750

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42,708.84818
Policy Entropy: 2.18174
Value Function Loss: 0.02333

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.07127
Policy Update Magnitude: 0.31031
Value Function Update Magnitude: 0.35076

Collected Steps per Second: 22,153.40993
Overall Steps per Second: 10,576.33522

Timestep Collection Time: 2.25825
Timestep Consumption Time: 2.47193
PPO Batch Consumption Time: 0.27805
Total Iteration Time: 4.73018

Cumulative Model Updates: 231,956
Cumulative Timesteps: 1,935,174,778

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1935174778...
Checkpoint 1935174778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 54,223.12618
Policy Entropy: 2.16995
Value Function Loss: 0.02253

Mean KL Divergence: 0.00731
SB3 Clip Fraction: 0.06923
Policy Update Magnitude: 0.30270
Value Function Update Magnitude: 0.32091

Collected Steps per Second: 21,483.00595
Overall Steps per Second: 10,470.53900

Timestep Collection Time: 2.32854
Timestep Consumption Time: 2.44906
PPO Batch Consumption Time: 0.27964
Total Iteration Time: 4.77760

Cumulative Model Updates: 231,962
Cumulative Timesteps: 1,935,224,802

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,631.99919
Policy Entropy: 2.15089
Value Function Loss: 0.02173

Mean KL Divergence: 0.00701
SB3 Clip Fraction: 0.06858
Policy Update Magnitude: 0.30474
Value Function Update Magnitude: 0.30856

Collected Steps per Second: 21,899.65304
Overall Steps per Second: 10,616.73180

Timestep Collection Time: 2.28387
Timestep Consumption Time: 2.42718
PPO Batch Consumption Time: 0.27820
Total Iteration Time: 4.71105

Cumulative Model Updates: 231,968
Cumulative Timesteps: 1,935,274,818

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1935274818...
Checkpoint 1935274818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43,852.76772
Policy Entropy: 2.12170
Value Function Loss: 0.02233

Mean KL Divergence: 0.00766
SB3 Clip Fraction: 0.07099
Policy Update Magnitude: 0.30842
Value Function Update Magnitude: 0.31101

Collected Steps per Second: 22,027.05931
Overall Steps per Second: 10,665.37136

Timestep Collection Time: 2.27075
Timestep Consumption Time: 2.41900
PPO Batch Consumption Time: 0.27806
Total Iteration Time: 4.68976

Cumulative Model Updates: 231,974
Cumulative Timesteps: 1,935,324,836

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59,196.44171
Policy Entropy: 2.12222
Value Function Loss: 0.02246

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.07529
Policy Update Magnitude: 0.31491
Value Function Update Magnitude: 0.34573

Collected Steps per Second: 22,317.74020
Overall Steps per Second: 10,599.64278

Timestep Collection Time: 2.24100
Timestep Consumption Time: 2.47746
PPO Batch Consumption Time: 0.28798
Total Iteration Time: 4.71846

Cumulative Model Updates: 231,980
Cumulative Timesteps: 1,935,374,850

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1935374850...
Checkpoint 1935374850 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,487.88386
Policy Entropy: 2.14147
Value Function Loss: 0.02143

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.07767
Policy Update Magnitude: 0.31208
Value Function Update Magnitude: 0.35660

Collected Steps per Second: 21,828.25654
Overall Steps per Second: 10,427.66104

Timestep Collection Time: 2.29189
Timestep Consumption Time: 2.50573
PPO Batch Consumption Time: 0.29457
Total Iteration Time: 4.79762

Cumulative Model Updates: 231,986
Cumulative Timesteps: 1,935,424,878

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,873.05631
Policy Entropy: 2.15561
Value Function Loss: 0.02204

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.07242
Policy Update Magnitude: 0.30918
Value Function Update Magnitude: 0.36466

Collected Steps per Second: 20,950.66952
Overall Steps per Second: 10,467.51027

Timestep Collection Time: 2.38675
Timestep Consumption Time: 2.39032
PPO Batch Consumption Time: 0.28390
Total Iteration Time: 4.77707

Cumulative Model Updates: 231,992
Cumulative Timesteps: 1,935,474,882

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1935474882...
Checkpoint 1935474882 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,638.58101
Policy Entropy: 2.15920
Value Function Loss: 0.02118

Mean KL Divergence: 0.00760
SB3 Clip Fraction: 0.06879
Policy Update Magnitude: 0.31148
Value Function Update Magnitude: 0.37109

Collected Steps per Second: 20,893.29727
Overall Steps per Second: 10,544.42104

Timestep Collection Time: 2.39397
Timestep Consumption Time: 2.34958
PPO Batch Consumption Time: 0.27825
Total Iteration Time: 4.74355

Cumulative Model Updates: 231,998
Cumulative Timesteps: 1,935,524,900

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,760.92924
Policy Entropy: 2.15179
Value Function Loss: 0.02096

Mean KL Divergence: 0.00732
SB3 Clip Fraction: 0.06732
Policy Update Magnitude: 0.31486
Value Function Update Magnitude: 0.33376

Collected Steps per Second: 21,038.98504
Overall Steps per Second: 10,568.12112

Timestep Collection Time: 2.37778
Timestep Consumption Time: 2.35589
PPO Batch Consumption Time: 0.27820
Total Iteration Time: 4.73367

Cumulative Model Updates: 232,004
Cumulative Timesteps: 1,935,574,926

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1935574926...
Checkpoint 1935574926 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40,745.87425
Policy Entropy: 2.14534
Value Function Loss: 0.02073

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.07124
Policy Update Magnitude: 0.30316
Value Function Update Magnitude: 0.33132

Collected Steps per Second: 20,905.80945
Overall Steps per Second: 10,536.68561

Timestep Collection Time: 2.39225
Timestep Consumption Time: 2.35421
PPO Batch Consumption Time: 0.27926
Total Iteration Time: 4.74646

Cumulative Model Updates: 232,010
Cumulative Timesteps: 1,935,624,938

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,049.59128
Policy Entropy: 2.16031
Value Function Loss: 0.02354

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.07283
Policy Update Magnitude: 0.30240
Value Function Update Magnitude: 0.35244

Collected Steps per Second: 20,945.64116
Overall Steps per Second: 10,421.90666

Timestep Collection Time: 2.38914
Timestep Consumption Time: 2.41248
PPO Batch Consumption Time: 0.27865
Total Iteration Time: 4.80162

Cumulative Model Updates: 232,016
Cumulative Timesteps: 1,935,674,980

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1935674980...
Checkpoint 1935674980 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,478.76292
Policy Entropy: 2.16350
Value Function Loss: 0.02366

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.07442
Policy Update Magnitude: 0.30958
Value Function Update Magnitude: 0.37986

Collected Steps per Second: 21,523.03793
Overall Steps per Second: 10,337.55980

Timestep Collection Time: 2.32337
Timestep Consumption Time: 2.51394
PPO Batch Consumption Time: 0.29413
Total Iteration Time: 4.83731

Cumulative Model Updates: 232,022
Cumulative Timesteps: 1,935,724,986

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,496.19187
Policy Entropy: 2.15698
Value Function Loss: 0.02266

Mean KL Divergence: 0.00749
SB3 Clip Fraction: 0.06943
Policy Update Magnitude: 0.31130
Value Function Update Magnitude: 0.37961

Collected Steps per Second: 22,046.75354
Overall Steps per Second: 10,483.01721

Timestep Collection Time: 2.26900
Timestep Consumption Time: 2.50291
PPO Batch Consumption Time: 0.29329
Total Iteration Time: 4.77191

Cumulative Model Updates: 232,028
Cumulative Timesteps: 1,935,775,010

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1935775010...
Checkpoint 1935775010 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,581.00610
Policy Entropy: 2.15964
Value Function Loss: 0.02381

Mean KL Divergence: 0.00716
SB3 Clip Fraction: 0.06598
Policy Update Magnitude: 0.31239
Value Function Update Magnitude: 0.34812

Collected Steps per Second: 22,087.83581
Overall Steps per Second: 10,505.16443

Timestep Collection Time: 2.26405
Timestep Consumption Time: 2.49627
PPO Batch Consumption Time: 0.28760
Total Iteration Time: 4.76033

Cumulative Model Updates: 232,034
Cumulative Timesteps: 1,935,825,018

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52,046.79943
Policy Entropy: 2.14656
Value Function Loss: 0.02452

Mean KL Divergence: 0.00756
SB3 Clip Fraction: 0.07188
Policy Update Magnitude: 0.31356
Value Function Update Magnitude: 0.34165

Collected Steps per Second: 21,942.52548
Overall Steps per Second: 10,485.48082

Timestep Collection Time: 2.27950
Timestep Consumption Time: 2.49071
PPO Batch Consumption Time: 0.28694
Total Iteration Time: 4.77022

Cumulative Model Updates: 232,040
Cumulative Timesteps: 1,935,875,036

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1935875036...
Checkpoint 1935875036 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,173.07094
Policy Entropy: 2.14567
Value Function Loss: 0.02376

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.08545
Policy Update Magnitude: 0.30876
Value Function Update Magnitude: 0.34920

Collected Steps per Second: 21,827.20773
Overall Steps per Second: 10,587.26058

Timestep Collection Time: 2.29255
Timestep Consumption Time: 2.43388
PPO Batch Consumption Time: 0.27855
Total Iteration Time: 4.72644

Cumulative Model Updates: 232,046
Cumulative Timesteps: 1,935,925,076

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81,688.50887
Policy Entropy: 2.13411
Value Function Loss: 0.02294

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.08011
Policy Update Magnitude: 0.31015
Value Function Update Magnitude: 0.32244

Collected Steps per Second: 21,777.69965
Overall Steps per Second: 10,570.46797

Timestep Collection Time: 2.29666
Timestep Consumption Time: 2.43501
PPO Batch Consumption Time: 0.27845
Total Iteration Time: 4.73167

Cumulative Model Updates: 232,052
Cumulative Timesteps: 1,935,975,092

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1935975092...
Checkpoint 1935975092 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55,699.37259
Policy Entropy: 2.12439
Value Function Loss: 0.02641

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.07678
Policy Update Magnitude: 0.32532
Value Function Update Magnitude: 0.35652

Collected Steps per Second: 22,066.73807
Overall Steps per Second: 10,645.42814

Timestep Collection Time: 2.26640
Timestep Consumption Time: 2.43158
PPO Batch Consumption Time: 0.27783
Total Iteration Time: 4.69798

Cumulative Model Updates: 232,058
Cumulative Timesteps: 1,936,025,104

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,675.28976
Policy Entropy: 2.11920
Value Function Loss: 0.02653

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.07868
Policy Update Magnitude: 0.32588
Value Function Update Magnitude: 0.38508

Collected Steps per Second: 21,428.30870
Overall Steps per Second: 10,502.56970

Timestep Collection Time: 2.33542
Timestep Consumption Time: 2.42951
PPO Batch Consumption Time: 0.27731
Total Iteration Time: 4.76493

Cumulative Model Updates: 232,064
Cumulative Timesteps: 1,936,075,148

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1936075148...
Checkpoint 1936075148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,653.77984
Policy Entropy: 2.12463
Value Function Loss: 0.02597

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.07842
Policy Update Magnitude: 0.32684
Value Function Update Magnitude: 0.38905

Collected Steps per Second: 20,771.91655
Overall Steps per Second: 10,184.03337

Timestep Collection Time: 2.40729
Timestep Consumption Time: 2.50275
PPO Batch Consumption Time: 0.29403
Total Iteration Time: 4.91004

Cumulative Model Updates: 232,070
Cumulative Timesteps: 1,936,125,152

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48,039.44670
Policy Entropy: 2.13961
Value Function Loss: 0.02375

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.08698
Policy Update Magnitude: 0.31959
Value Function Update Magnitude: 0.39686

Collected Steps per Second: 21,350.98072
Overall Steps per Second: 10,368.24472

Timestep Collection Time: 2.34284
Timestep Consumption Time: 2.48170
PPO Batch Consumption Time: 0.28703
Total Iteration Time: 4.82454

Cumulative Model Updates: 232,076
Cumulative Timesteps: 1,936,175,174

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1936175174...
Checkpoint 1936175174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,101.05549
Policy Entropy: 2.14703
Value Function Loss: 0.02455

Mean KL Divergence: 0.01258
SB3 Clip Fraction: 0.10307
Policy Update Magnitude: 0.31944
Value Function Update Magnitude: 0.40973

Collected Steps per Second: 20,759.47020
Overall Steps per Second: 10,253.08351

Timestep Collection Time: 2.40921
Timestep Consumption Time: 2.46873
PPO Batch Consumption Time: 0.29367
Total Iteration Time: 4.87795

Cumulative Model Updates: 232,082
Cumulative Timesteps: 1,936,225,188

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,149.72781
Policy Entropy: 2.15770
Value Function Loss: 0.02303

Mean KL Divergence: 0.01180
SB3 Clip Fraction: 0.09989
Policy Update Magnitude: 0.31522
Value Function Update Magnitude: 0.39990

Collected Steps per Second: 21,192.45094
Overall Steps per Second: 10,434.75235

Timestep Collection Time: 2.36037
Timestep Consumption Time: 2.43342
PPO Batch Consumption Time: 0.29265
Total Iteration Time: 4.79379

Cumulative Model Updates: 232,088
Cumulative Timesteps: 1,936,275,210

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1936275210...
Checkpoint 1936275210 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,246.65507
Policy Entropy: 2.14086
Value Function Loss: 0.02127

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.08882
Policy Update Magnitude: 0.30195
Value Function Update Magnitude: 0.36297

Collected Steps per Second: 21,246.69342
Overall Steps per Second: 10,615.15898

Timestep Collection Time: 2.35575
Timestep Consumption Time: 2.35939
PPO Batch Consumption Time: 0.27907
Total Iteration Time: 4.71514

Cumulative Model Updates: 232,094
Cumulative Timesteps: 1,936,325,262

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 72,566.54840
Policy Entropy: 2.12812
Value Function Loss: 0.02056

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.08260
Policy Update Magnitude: 0.30775
Value Function Update Magnitude: 0.34037

Collected Steps per Second: 21,527.14576
Overall Steps per Second: 10,427.51716

Timestep Collection Time: 2.32367
Timestep Consumption Time: 2.47344
PPO Batch Consumption Time: 0.28740
Total Iteration Time: 4.79712

Cumulative Model Updates: 232,100
Cumulative Timesteps: 1,936,375,284

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1936375284...
Checkpoint 1936375284 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40,104.55165
Policy Entropy: 2.10968
Value Function Loss: 0.02358

Mean KL Divergence: 0.01145
SB3 Clip Fraction: 0.07868
Policy Update Magnitude: 0.31341
Value Function Update Magnitude: 0.32575

Collected Steps per Second: 21,560.20375
Overall Steps per Second: 10,448.75816

Timestep Collection Time: 2.31946
Timestep Consumption Time: 2.46656
PPO Batch Consumption Time: 0.28953
Total Iteration Time: 4.78602

Cumulative Model Updates: 232,106
Cumulative Timesteps: 1,936,425,292

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,332.96235
Policy Entropy: 2.11882
Value Function Loss: 0.02248

Mean KL Divergence: 0.01477
SB3 Clip Fraction: 0.08385
Policy Update Magnitude: 0.31207
Value Function Update Magnitude: 0.27764

Collected Steps per Second: 22,045.27552
Overall Steps per Second: 10,656.25109

Timestep Collection Time: 2.26824
Timestep Consumption Time: 2.42422
PPO Batch Consumption Time: 0.27857
Total Iteration Time: 4.69246

Cumulative Model Updates: 232,112
Cumulative Timesteps: 1,936,475,296

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1936475296...
Checkpoint 1936475296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 82,454.07517
Policy Entropy: 2.12586
Value Function Loss: 0.02409

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.08567
Policy Update Magnitude: 0.31171
Value Function Update Magnitude: 0.26990

Collected Steps per Second: 21,578.41965
Overall Steps per Second: 10,615.96443

Timestep Collection Time: 2.31861
Timestep Consumption Time: 2.39429
PPO Batch Consumption Time: 0.27827
Total Iteration Time: 4.71290

Cumulative Model Updates: 232,118
Cumulative Timesteps: 1,936,525,328

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57,468.60095
Policy Entropy: 2.12705
Value Function Loss: 0.02189

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.08579
Policy Update Magnitude: 0.30608
Value Function Update Magnitude: 0.21975

Collected Steps per Second: 21,562.10458
Overall Steps per Second: 10,497.37668

Timestep Collection Time: 2.32055
Timestep Consumption Time: 2.44597
PPO Batch Consumption Time: 0.27929
Total Iteration Time: 4.76652

Cumulative Model Updates: 232,124
Cumulative Timesteps: 1,936,575,364

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1936575364...
Checkpoint 1936575364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,820.32351
Policy Entropy: 2.13433
Value Function Loss: 0.02475

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.07636
Policy Update Magnitude: 0.30686
Value Function Update Magnitude: 0.20206

Collected Steps per Second: 21,487.81995
Overall Steps per Second: 10,329.38466

Timestep Collection Time: 2.32774
Timestep Consumption Time: 2.51456
PPO Batch Consumption Time: 0.29324
Total Iteration Time: 4.84230

Cumulative Model Updates: 232,130
Cumulative Timesteps: 1,936,625,382

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46,460.00754
Policy Entropy: 2.13295
Value Function Loss: 0.02398

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.07895
Policy Update Magnitude: 0.30714
Value Function Update Magnitude: 0.17974

Collected Steps per Second: 21,804.46800
Overall Steps per Second: 10,372.17264

Timestep Collection Time: 2.29311
Timestep Consumption Time: 2.52748
PPO Batch Consumption Time: 0.29398
Total Iteration Time: 4.82059

Cumulative Model Updates: 232,136
Cumulative Timesteps: 1,936,675,382

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1936675382...
Checkpoint 1936675382 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 60,189.43652
Policy Entropy: 2.16033
Value Function Loss: 0.02636

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.08153
Policy Update Magnitude: 0.30866
Value Function Update Magnitude: 0.20885

Collected Steps per Second: 22,090.07636
Overall Steps per Second: 10,563.58623

Timestep Collection Time: 2.26391
Timestep Consumption Time: 2.47028
PPO Batch Consumption Time: 0.27963
Total Iteration Time: 4.73419

Cumulative Model Updates: 232,142
Cumulative Timesteps: 1,936,725,392

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54,300.85110
Policy Entropy: 2.16774
Value Function Loss: 0.02328

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.08263
Policy Update Magnitude: 0.30666
Value Function Update Magnitude: 0.19341

Collected Steps per Second: 21,909.92527
Overall Steps per Second: 10,380.30272

Timestep Collection Time: 2.28244
Timestep Consumption Time: 2.53515
PPO Batch Consumption Time: 0.29224
Total Iteration Time: 4.81759

Cumulative Model Updates: 232,148
Cumulative Timesteps: 1,936,775,400

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1936775400...
Checkpoint 1936775400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 53,984.97391
Policy Entropy: 2.17447
Value Function Loss: 0.02695

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.07722
Policy Update Magnitude: 0.31062
Value Function Update Magnitude: 0.16563

Collected Steps per Second: 21,904.61345
Overall Steps per Second: 10,454.36959

Timestep Collection Time: 2.28326
Timestep Consumption Time: 2.50077
PPO Batch Consumption Time: 0.29173
Total Iteration Time: 4.78403

Cumulative Model Updates: 232,154
Cumulative Timesteps: 1,936,825,414

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,418.05424
Policy Entropy: 2.16382
Value Function Loss: 0.02243

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.09075
Policy Update Magnitude: 0.30243
Value Function Update Magnitude: 0.18064

Collected Steps per Second: 22,073.72297
Overall Steps per Second: 10,668.46079

Timestep Collection Time: 2.26514
Timestep Consumption Time: 2.42158
PPO Batch Consumption Time: 0.27954
Total Iteration Time: 4.68671

Cumulative Model Updates: 232,160
Cumulative Timesteps: 1,936,875,414

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1936875414...
Checkpoint 1936875414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,355.08464
Policy Entropy: 2.15423
Value Function Loss: 0.02106

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.08441
Policy Update Magnitude: 0.29346
Value Function Update Magnitude: 0.17496

Collected Steps per Second: 21,888.33536
Overall Steps per Second: 10,630.10848

Timestep Collection Time: 2.28542
Timestep Consumption Time: 2.42046
PPO Batch Consumption Time: 0.27943
Total Iteration Time: 4.70588

Cumulative Model Updates: 232,166
Cumulative Timesteps: 1,936,925,438

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,718.26689
Policy Entropy: 2.15236
Value Function Loss: 0.02020

Mean KL Divergence: 0.00723
SB3 Clip Fraction: 0.06953
Policy Update Magnitude: 0.28792
Value Function Update Magnitude: 0.21406

Collected Steps per Second: 22,031.33295
Overall Steps per Second: 10,526.95060

Timestep Collection Time: 2.26995
Timestep Consumption Time: 2.48071
PPO Batch Consumption Time: 0.28688
Total Iteration Time: 4.75066

Cumulative Model Updates: 232,172
Cumulative Timesteps: 1,936,975,448

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1936975448...
Checkpoint 1936975448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,963.72220
Policy Entropy: 2.15347
Value Function Loss: 0.02303

Mean KL Divergence: 0.00647
SB3 Clip Fraction: 0.06037
Policy Update Magnitude: 0.29708
Value Function Update Magnitude: 0.27560

Collected Steps per Second: 20,882.81737
Overall Steps per Second: 10,388.41451

Timestep Collection Time: 2.39517
Timestep Consumption Time: 2.41961
PPO Batch Consumption Time: 0.29016
Total Iteration Time: 4.81479

Cumulative Model Updates: 232,178
Cumulative Timesteps: 1,937,025,466

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,236.46054
Policy Entropy: 2.14974
Value Function Loss: 0.02394

Mean KL Divergence: 0.00693
SB3 Clip Fraction: 0.06208
Policy Update Magnitude: 0.30856
Value Function Update Magnitude: 0.34145

Collected Steps per Second: 20,890.63923
Overall Steps per Second: 10,361.73256

Timestep Collection Time: 2.39428
Timestep Consumption Time: 2.43291
PPO Batch Consumption Time: 0.29317
Total Iteration Time: 4.82719

Cumulative Model Updates: 232,184
Cumulative Timesteps: 1,937,075,484

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1937075484...
Checkpoint 1937075484 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,771.79827
Policy Entropy: 2.14165
Value Function Loss: 0.02249

Mean KL Divergence: 0.00770
SB3 Clip Fraction: 0.06496
Policy Update Magnitude: 0.30518
Value Function Update Magnitude: 0.37501

Collected Steps per Second: 20,591.42716
Overall Steps per Second: 10,491.16199

Timestep Collection Time: 2.42897
Timestep Consumption Time: 2.33847
PPO Batch Consumption Time: 0.27828
Total Iteration Time: 4.76744

Cumulative Model Updates: 232,190
Cumulative Timesteps: 1,937,125,500

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,708.70088
Policy Entropy: 2.12649
Value Function Loss: 0.02486

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.07015
Policy Update Magnitude: 0.31145
Value Function Update Magnitude: 0.37459

Collected Steps per Second: 21,094.98961
Overall Steps per Second: 10,449.36772

Timestep Collection Time: 2.37146
Timestep Consumption Time: 2.41600
PPO Batch Consumption Time: 0.27906
Total Iteration Time: 4.78747

Cumulative Model Updates: 232,196
Cumulative Timesteps: 1,937,175,526

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1937175526...
Checkpoint 1937175526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,903.98809
Policy Entropy: 2.11782
Value Function Loss: 0.02329

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.07821
Policy Update Magnitude: 0.32722
Value Function Update Magnitude: 0.37407

Collected Steps per Second: 21,452.97028
Overall Steps per Second: 10,375.20383

Timestep Collection Time: 2.33105
Timestep Consumption Time: 2.48890
PPO Batch Consumption Time: 0.29276
Total Iteration Time: 4.81995

Cumulative Model Updates: 232,202
Cumulative Timesteps: 1,937,225,534

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,227.96583
Policy Entropy: 2.12491
Value Function Loss: 0.02255

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.08021
Policy Update Magnitude: 0.30950
Value Function Update Magnitude: 0.37177

Collected Steps per Second: 21,335.91735
Overall Steps per Second: 10,336.89860

Timestep Collection Time: 2.34384
Timestep Consumption Time: 2.49397
PPO Batch Consumption Time: 0.29115
Total Iteration Time: 4.83781

Cumulative Model Updates: 232,208
Cumulative Timesteps: 1,937,275,542

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1937275542...
Checkpoint 1937275542 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 68,529.14045
Policy Entropy: 2.14157
Value Function Loss: 0.01934

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.07354
Policy Update Magnitude: 0.29808
Value Function Update Magnitude: 0.35155

Collected Steps per Second: 21,757.57823
Overall Steps per Second: 10,353.89116

Timestep Collection Time: 2.29814
Timestep Consumption Time: 2.53115
PPO Batch Consumption Time: 0.29220
Total Iteration Time: 4.82930

Cumulative Model Updates: 232,214
Cumulative Timesteps: 1,937,325,544

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,779.08802
Policy Entropy: 2.13354
Value Function Loss: 0.02124

Mean KL Divergence: 0.00752
SB3 Clip Fraction: 0.06901
Policy Update Magnitude: 0.29736
Value Function Update Magnitude: 0.32280

Collected Steps per Second: 22,045.34625
Overall Steps per Second: 10,481.85762

Timestep Collection Time: 2.26896
Timestep Consumption Time: 2.50310
PPO Batch Consumption Time: 0.29041
Total Iteration Time: 4.77205

Cumulative Model Updates: 232,220
Cumulative Timesteps: 1,937,375,564

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1937375564...
Checkpoint 1937375564 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46,568.81168
Policy Entropy: 2.13426
Value Function Loss: 0.02102

Mean KL Divergence: 0.00733
SB3 Clip Fraction: 0.06914
Policy Update Magnitude: 0.30075
Value Function Update Magnitude: 0.32632

Collected Steps per Second: 21,998.27673
Overall Steps per Second: 10,464.55074

Timestep Collection Time: 2.27509
Timestep Consumption Time: 2.50754
PPO Batch Consumption Time: 0.29110
Total Iteration Time: 4.78262

Cumulative Model Updates: 232,226
Cumulative Timesteps: 1,937,425,612

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,123.96436
Policy Entropy: 2.11470
Value Function Loss: 0.02069

Mean KL Divergence: 0.00720
SB3 Clip Fraction: 0.06986
Policy Update Magnitude: 0.30276
Value Function Update Magnitude: 0.32969

Collected Steps per Second: 21,901.57317
Overall Steps per Second: 10,457.99441

Timestep Collection Time: 2.28331
Timestep Consumption Time: 2.49849
PPO Batch Consumption Time: 0.28970
Total Iteration Time: 4.78180

Cumulative Model Updates: 232,232
Cumulative Timesteps: 1,937,475,620

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1937475620...
Checkpoint 1937475620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 56,132.34801
Policy Entropy: 2.12110
Value Function Loss: 0.01783

Mean KL Divergence: 0.00740
SB3 Clip Fraction: 0.06883
Policy Update Magnitude: 0.29892
Value Function Update Magnitude: 0.32492

Collected Steps per Second: 21,809.00709
Overall Steps per Second: 10,576.65722

Timestep Collection Time: 2.29373
Timestep Consumption Time: 2.43593
PPO Batch Consumption Time: 0.27945
Total Iteration Time: 4.72966

Cumulative Model Updates: 232,238
Cumulative Timesteps: 1,937,525,644

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48,826.27060
Policy Entropy: 2.13067
Value Function Loss: 0.02015

Mean KL Divergence: 0.00707
SB3 Clip Fraction: 0.06552
Policy Update Magnitude: 0.30225
Value Function Update Magnitude: 0.29965

Collected Steps per Second: 22,125.28001
Overall Steps per Second: 10,490.86449

Timestep Collection Time: 2.25995
Timestep Consumption Time: 2.50629
PPO Batch Consumption Time: 0.29088
Total Iteration Time: 4.76624

Cumulative Model Updates: 232,244
Cumulative Timesteps: 1,937,575,646

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1937575646...
Checkpoint 1937575646 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,081.75425
Policy Entropy: 2.15036
Value Function Loss: 0.02305

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.07350
Policy Update Magnitude: 0.31099
Value Function Update Magnitude: 0.33610

Collected Steps per Second: 21,997.35025
Overall Steps per Second: 10,619.58073

Timestep Collection Time: 2.27327
Timestep Consumption Time: 2.43557
PPO Batch Consumption Time: 0.27920
Total Iteration Time: 4.70885

Cumulative Model Updates: 232,250
Cumulative Timesteps: 1,937,625,652

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76,919.55688
Policy Entropy: 2.15114
Value Function Loss: 0.02763

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.07544
Policy Update Magnitude: 0.31931
Value Function Update Magnitude: 0.36042

Collected Steps per Second: 21,339.81479
Overall Steps per Second: 10,439.68317

Timestep Collection Time: 2.34416
Timestep Consumption Time: 2.44755
PPO Batch Consumption Time: 0.27897
Total Iteration Time: 4.79172

Cumulative Model Updates: 232,256
Cumulative Timesteps: 1,937,675,676

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1937675676...
Checkpoint 1937675676 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,749.62163
Policy Entropy: 2.14617
Value Function Loss: 0.03049

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.08529
Policy Update Magnitude: 0.32592
Value Function Update Magnitude: 0.38125

Collected Steps per Second: 21,099.36369
Overall Steps per Second: 10,246.39693

Timestep Collection Time: 2.36983
Timestep Consumption Time: 2.51012
PPO Batch Consumption Time: 0.29162
Total Iteration Time: 4.87996

Cumulative Model Updates: 232,262
Cumulative Timesteps: 1,937,725,678

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51,402.59788
Policy Entropy: 2.14400
Value Function Loss: 0.03030

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.08792
Policy Update Magnitude: 0.33177
Value Function Update Magnitude: 0.37111

Collected Steps per Second: 21,707.17932
Overall Steps per Second: 10,455.34306

Timestep Collection Time: 2.30468
Timestep Consumption Time: 2.48025
PPO Batch Consumption Time: 0.28586
Total Iteration Time: 4.78492

Cumulative Model Updates: 232,268
Cumulative Timesteps: 1,937,775,706

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1937775706...
Checkpoint 1937775706 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,391.60796
Policy Entropy: 2.16496
Value Function Loss: 0.02910

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.09495
Policy Update Magnitude: 0.32908
Value Function Update Magnitude: 0.33137

Collected Steps per Second: 21,566.49017
Overall Steps per Second: 10,361.72421

Timestep Collection Time: 2.31878
Timestep Consumption Time: 2.50744
PPO Batch Consumption Time: 0.29069
Total Iteration Time: 4.82622

Cumulative Model Updates: 232,274
Cumulative Timesteps: 1,937,825,714

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,809.20167
Policy Entropy: 2.17355
Value Function Loss: 0.02698

Mean KL Divergence: 0.01136
SB3 Clip Fraction: 0.09629
Policy Update Magnitude: 0.32340
Value Function Update Magnitude: 0.27341

Collected Steps per Second: 22,198.49932
Overall Steps per Second: 10,459.18142

Timestep Collection Time: 2.25502
Timestep Consumption Time: 2.53102
PPO Batch Consumption Time: 0.29169
Total Iteration Time: 4.78603

Cumulative Model Updates: 232,280
Cumulative Timesteps: 1,937,875,772

Timesteps Collected: 50,058
--------END ITERATION REPORT--------


Saving checkpoint 1937875772...
Checkpoint 1937875772 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,778.62560
Policy Entropy: 2.16564
Value Function Loss: 0.02595

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.08840
Policy Update Magnitude: 0.30811
Value Function Update Magnitude: 0.24382

Collected Steps per Second: 21,779.76171
Overall Steps per Second: 10,469.05624

Timestep Collection Time: 2.29690
Timestep Consumption Time: 2.48156
PPO Batch Consumption Time: 0.29164
Total Iteration Time: 4.77846

Cumulative Model Updates: 232,286
Cumulative Timesteps: 1,937,925,798

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,190.51603
Policy Entropy: 2.14002
Value Function Loss: 0.02158

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.07695
Policy Update Magnitude: 0.30160
Value Function Update Magnitude: 0.27141

Collected Steps per Second: 22,179.94851
Overall Steps per Second: 10,474.81938

Timestep Collection Time: 2.25483
Timestep Consumption Time: 2.51967
PPO Batch Consumption Time: 0.29489
Total Iteration Time: 4.77450

Cumulative Model Updates: 232,292
Cumulative Timesteps: 1,937,975,810

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1937975810...
Checkpoint 1937975810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,458.73455
Policy Entropy: 2.10755
Value Function Loss: 0.01998

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.07496
Policy Update Magnitude: 0.29800
Value Function Update Magnitude: 0.29026

Collected Steps per Second: 22,020.74558
Overall Steps per Second: 10,643.93259

Timestep Collection Time: 2.27077
Timestep Consumption Time: 2.42712
PPO Batch Consumption Time: 0.27791
Total Iteration Time: 4.69789

Cumulative Model Updates: 232,298
Cumulative Timesteps: 1,938,025,814

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,238.69906
Policy Entropy: 2.10662
Value Function Loss: 0.02162

Mean KL Divergence: 0.00738
SB3 Clip Fraction: 0.06719
Policy Update Magnitude: 0.30603
Value Function Update Magnitude: 0.29401

Collected Steps per Second: 22,119.57128
Overall Steps per Second: 10,490.32353

Timestep Collection Time: 2.26126
Timestep Consumption Time: 2.50676
PPO Batch Consumption Time: 0.29305
Total Iteration Time: 4.76801

Cumulative Model Updates: 232,304
Cumulative Timesteps: 1,938,075,832

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1938075832...
Checkpoint 1938075832 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,702.17973
Policy Entropy: 2.11582
Value Function Loss: 0.01971

Mean KL Divergence: 0.00708
SB3 Clip Fraction: 0.06495
Policy Update Magnitude: 0.30233
Value Function Update Magnitude: 0.28342

Collected Steps per Second: 20,678.03628
Overall Steps per Second: 10,160.57753

Timestep Collection Time: 2.41996
Timestep Consumption Time: 2.50496
PPO Batch Consumption Time: 0.29179
Total Iteration Time: 4.92492

Cumulative Model Updates: 232,310
Cumulative Timesteps: 1,938,125,872

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46,624.79338
Policy Entropy: 2.13413
Value Function Loss: 0.02051

Mean KL Divergence: 0.00710
SB3 Clip Fraction: 0.06714
Policy Update Magnitude: 0.29520
Value Function Update Magnitude: 0.30181

Collected Steps per Second: 21,436.42474
Overall Steps per Second: 10,487.47006

Timestep Collection Time: 2.33341
Timestep Consumption Time: 2.43609
PPO Batch Consumption Time: 0.27803
Total Iteration Time: 4.76950

Cumulative Model Updates: 232,316
Cumulative Timesteps: 1,938,175,892

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1938175892...
Checkpoint 1938175892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46,624.79338
Policy Entropy: 2.11902
Value Function Loss: 0.01852

Mean KL Divergence: 0.00671
SB3 Clip Fraction: 0.06465
Policy Update Magnitude: 0.29445
Value Function Update Magnitude: 0.29327

Collected Steps per Second: 21,335.91260
Overall Steps per Second: 10,331.98601

Timestep Collection Time: 2.34403
Timestep Consumption Time: 2.49647
PPO Batch Consumption Time: 0.29119
Total Iteration Time: 4.84050

Cumulative Model Updates: 232,322
Cumulative Timesteps: 1,938,225,904

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54,147.22462
Policy Entropy: 2.13042
Value Function Loss: 0.01999

Mean KL Divergence: 0.00650
SB3 Clip Fraction: 0.06237
Policy Update Magnitude: 0.29642
Value Function Update Magnitude: 0.26495

Collected Steps per Second: 21,676.75163
Overall Steps per Second: 10,341.50956

Timestep Collection Time: 2.30837
Timestep Consumption Time: 2.53019
PPO Batch Consumption Time: 0.29346
Total Iteration Time: 4.83856

Cumulative Model Updates: 232,328
Cumulative Timesteps: 1,938,275,942

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1938275942...
Checkpoint 1938275942 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 72,159.00295
Policy Entropy: 2.14199
Value Function Loss: 0.01895

Mean KL Divergence: 0.00716
SB3 Clip Fraction: 0.06737
Policy Update Magnitude: 0.29737
Value Function Update Magnitude: 0.28567

Collected Steps per Second: 21,548.22826
Overall Steps per Second: 10,297.87937

Timestep Collection Time: 2.32047
Timestep Consumption Time: 2.53509
PPO Batch Consumption Time: 0.29136
Total Iteration Time: 4.85556

Cumulative Model Updates: 232,334
Cumulative Timesteps: 1,938,325,944

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46,538.29841
Policy Entropy: 2.16465
Value Function Loss: 0.02149

Mean KL Divergence: 0.00683
SB3 Clip Fraction: 0.06497
Policy Update Magnitude: 0.30563
Value Function Update Magnitude: 0.33359

Collected Steps per Second: 22,171.27521
Overall Steps per Second: 10,657.11724

Timestep Collection Time: 2.25598
Timestep Consumption Time: 2.43741
PPO Batch Consumption Time: 0.27930
Total Iteration Time: 4.69339

Cumulative Model Updates: 232,340
Cumulative Timesteps: 1,938,375,962

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1938375962...
Checkpoint 1938375962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40,006.33139
Policy Entropy: 2.16279
Value Function Loss: 0.01994

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.07860
Policy Update Magnitude: 0.30170
Value Function Update Magnitude: 0.33516

Collected Steps per Second: 21,364.59108
Overall Steps per Second: 10,315.89862

Timestep Collection Time: 2.34144
Timestep Consumption Time: 2.50777
PPO Batch Consumption Time: 0.29458
Total Iteration Time: 4.84921

Cumulative Model Updates: 232,346
Cumulative Timesteps: 1,938,425,986

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42,485.93620
Policy Entropy: 2.15905
Value Function Loss: 0.01971

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.07216
Policy Update Magnitude: 0.29260
Value Function Update Magnitude: 0.29932

Collected Steps per Second: 22,201.19223
Overall Steps per Second: 10,533.68109

Timestep Collection Time: 2.25276
Timestep Consumption Time: 2.49525
PPO Batch Consumption Time: 0.29326
Total Iteration Time: 4.74801

Cumulative Model Updates: 232,352
Cumulative Timesteps: 1,938,476,000

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1938476000...
Checkpoint 1938476000 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46,078.78575
Policy Entropy: 2.17165
Value Function Loss: 0.01855

Mean KL Divergence: 0.00740
SB3 Clip Fraction: 0.07260
Policy Update Magnitude: 0.28584
Value Function Update Magnitude: 0.25345

Collected Steps per Second: 21,734.03389
Overall Steps per Second: 10,567.52448

Timestep Collection Time: 2.30164
Timestep Consumption Time: 2.43210
PPO Batch Consumption Time: 0.27896
Total Iteration Time: 4.73375

Cumulative Model Updates: 232,358
Cumulative Timesteps: 1,938,526,024

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42,498.32548
Policy Entropy: 2.16395
Value Function Loss: 0.01744

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.07408
Policy Update Magnitude: 0.27995
Value Function Update Magnitude: 0.28710

Collected Steps per Second: 21,517.08022
Overall Steps per Second: 10,512.83616

Timestep Collection Time: 2.32420
Timestep Consumption Time: 2.43284
PPO Batch Consumption Time: 0.29294
Total Iteration Time: 4.75704

Cumulative Model Updates: 232,364
Cumulative Timesteps: 1,938,576,034

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1938576034...
Checkpoint 1938576034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47,429.13022
Policy Entropy: 2.15730
Value Function Loss: 0.02000

Mean KL Divergence: 0.00723
SB3 Clip Fraction: 0.07049
Policy Update Magnitude: 0.29166
Value Function Update Magnitude: 0.30764

Collected Steps per Second: 21,163.66203
Overall Steps per Second: 10,605.98490

Timestep Collection Time: 2.36311
Timestep Consumption Time: 2.35234
PPO Batch Consumption Time: 0.27755
Total Iteration Time: 4.71545

Cumulative Model Updates: 232,370
Cumulative Timesteps: 1,938,626,046

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,180.10309
Policy Entropy: 2.13863
Value Function Loss: 0.01983

Mean KL Divergence: 0.00734
SB3 Clip Fraction: 0.07120
Policy Update Magnitude: 0.30428
Value Function Update Magnitude: 0.30944

Collected Steps per Second: 20,726.32930
Overall Steps per Second: 10,422.01142

Timestep Collection Time: 2.41249
Timestep Consumption Time: 2.38524
PPO Batch Consumption Time: 0.28424
Total Iteration Time: 4.79773

Cumulative Model Updates: 232,376
Cumulative Timesteps: 1,938,676,048

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1938676048...
Checkpoint 1938676048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,743.74739
Policy Entropy: 2.15272
Value Function Loss: 0.02318

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.08064
Policy Update Magnitude: 0.30923
Value Function Update Magnitude: 0.29594

Collected Steps per Second: 20,716.73819
Overall Steps per Second: 10,316.11154

Timestep Collection Time: 2.41505
Timestep Consumption Time: 2.43484
PPO Batch Consumption Time: 0.29359
Total Iteration Time: 4.84989

Cumulative Model Updates: 232,382
Cumulative Timesteps: 1,938,726,080

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,389.80745
Policy Entropy: 2.15594
Value Function Loss: 0.02233

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.07925
Policy Update Magnitude: 0.30750
Value Function Update Magnitude: 0.29577

Collected Steps per Second: 21,268.98057
Overall Steps per Second: 10,348.29423

Timestep Collection Time: 2.35169
Timestep Consumption Time: 2.48177
PPO Batch Consumption Time: 0.29128
Total Iteration Time: 4.83345

Cumulative Model Updates: 232,388
Cumulative Timesteps: 1,938,776,098

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1938776098...
Checkpoint 1938776098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,464.24084
Policy Entropy: 2.16375
Value Function Loss: 0.02323

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.07558
Policy Update Magnitude: 0.30722
Value Function Update Magnitude: 0.34284

Collected Steps per Second: 21,460.96688
Overall Steps per Second: 10,556.65156

Timestep Collection Time: 2.33046
Timestep Consumption Time: 2.40721
PPO Batch Consumption Time: 0.27872
Total Iteration Time: 4.73768

Cumulative Model Updates: 232,394
Cumulative Timesteps: 1,938,826,112

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,233.22250
Policy Entropy: 2.15768
Value Function Loss: 0.02056

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.07097
Policy Update Magnitude: 0.30775
Value Function Update Magnitude: 0.34048

Collected Steps per Second: 21,970.03743
Overall Steps per Second: 10,531.59381

Timestep Collection Time: 2.27610
Timestep Consumption Time: 2.47209
PPO Batch Consumption Time: 0.28823
Total Iteration Time: 4.74819

Cumulative Model Updates: 232,400
Cumulative Timesteps: 1,938,876,118

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1938876118...
Checkpoint 1938876118 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,097.99361
Policy Entropy: 2.16372
Value Function Loss: 0.01935

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.07201
Policy Update Magnitude: 0.29579
Value Function Update Magnitude: 0.32297

Collected Steps per Second: 21,674.55924
Overall Steps per Second: 10,374.28174

Timestep Collection Time: 2.30787
Timestep Consumption Time: 2.51386
PPO Batch Consumption Time: 0.29101
Total Iteration Time: 4.82173

Cumulative Model Updates: 232,406
Cumulative Timesteps: 1,938,926,140

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,226.06785
Policy Entropy: 2.14934
Value Function Loss: 0.01825

Mean KL Divergence: 0.00676
SB3 Clip Fraction: 0.06431
Policy Update Magnitude: 0.28915
Value Function Update Magnitude: 0.29910

Collected Steps per Second: 22,239.95569
Overall Steps per Second: 10,600.48393

Timestep Collection Time: 2.24911
Timestep Consumption Time: 2.46955
PPO Batch Consumption Time: 0.27883
Total Iteration Time: 4.71865

Cumulative Model Updates: 232,412
Cumulative Timesteps: 1,938,976,160

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1938976160...
Checkpoint 1938976160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 76,345.75510
Policy Entropy: 2.14610
Value Function Loss: 0.02072

Mean KL Divergence: 0.00703
SB3 Clip Fraction: 0.06923
Policy Update Magnitude: 0.29758
Value Function Update Magnitude: 0.27362

Collected Steps per Second: 21,900.38259
Overall Steps per Second: 10,437.24509

Timestep Collection Time: 2.28453
Timestep Consumption Time: 2.50908
PPO Batch Consumption Time: 0.29066
Total Iteration Time: 4.79360

Cumulative Model Updates: 232,418
Cumulative Timesteps: 1,939,026,192

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92,500.37997
Policy Entropy: 2.14568
Value Function Loss: 0.02152

Mean KL Divergence: 0.00727
SB3 Clip Fraction: 0.07125
Policy Update Magnitude: 0.29833
Value Function Update Magnitude: 0.29380

Collected Steps per Second: 22,292.63498
Overall Steps per Second: 10,685.05328

Timestep Collection Time: 2.24388
Timestep Consumption Time: 2.43761
PPO Batch Consumption Time: 0.27950
Total Iteration Time: 4.68149

Cumulative Model Updates: 232,424
Cumulative Timesteps: 1,939,076,214

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1939076214...
Checkpoint 1939076214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 65,437.53939
Policy Entropy: 2.14029
Value Function Loss: 0.02230

Mean KL Divergence: 0.00733
SB3 Clip Fraction: 0.06873
Policy Update Magnitude: 0.29836
Value Function Update Magnitude: 0.31505

Collected Steps per Second: 21,523.34857
Overall Steps per Second: 10,342.45781

Timestep Collection Time: 2.32306
Timestep Consumption Time: 2.51138
PPO Batch Consumption Time: 0.29498
Total Iteration Time: 4.83444

Cumulative Model Updates: 232,430
Cumulative Timesteps: 1,939,126,214

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89,591.91020
Policy Entropy: 2.14769
Value Function Loss: 0.02095

Mean KL Divergence: 0.00751
SB3 Clip Fraction: 0.07061
Policy Update Magnitude: 0.30624
Value Function Update Magnitude: 0.33963

Collected Steps per Second: 22,142.10251
Overall Steps per Second: 10,501.13971

Timestep Collection Time: 2.25823
Timestep Consumption Time: 2.50335
PPO Batch Consumption Time: 0.29239
Total Iteration Time: 4.76158

Cumulative Model Updates: 232,436
Cumulative Timesteps: 1,939,176,216

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1939176216...
Checkpoint 1939176216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 64,257.86039
Policy Entropy: 2.14242
Value Function Loss: 0.02014

Mean KL Divergence: 0.00734
SB3 Clip Fraction: 0.06836
Policy Update Magnitude: 0.30467
Value Function Update Magnitude: 0.34172

Collected Steps per Second: 21,451.96907
Overall Steps per Second: 10,489.84494

Timestep Collection Time: 2.33265
Timestep Consumption Time: 2.43767
PPO Batch Consumption Time: 0.27858
Total Iteration Time: 4.77033

Cumulative Model Updates: 232,442
Cumulative Timesteps: 1,939,226,256

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,594.17941
Policy Entropy: 2.14037
Value Function Loss: 0.01968

Mean KL Divergence: 0.00766
SB3 Clip Fraction: 0.06972
Policy Update Magnitude: 0.30837
Value Function Update Magnitude: 0.35015

Collected Steps per Second: 21,219.72502
Overall Steps per Second: 10,444.29404

Timestep Collection Time: 2.35847
Timestep Consumption Time: 2.43324
PPO Batch Consumption Time: 0.27851
Total Iteration Time: 4.79171

Cumulative Model Updates: 232,448
Cumulative Timesteps: 1,939,276,302

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1939276302...
Checkpoint 1939276302 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 50,270.11616
Policy Entropy: 2.13363
Value Function Loss: 0.02031

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.07416
Policy Update Magnitude: 0.30829
Value Function Update Magnitude: 0.34331

Collected Steps per Second: 21,330.85303
Overall Steps per Second: 10,298.66117

Timestep Collection Time: 2.34552
Timestep Consumption Time: 2.51258
PPO Batch Consumption Time: 0.29383
Total Iteration Time: 4.85811

Cumulative Model Updates: 232,454
Cumulative Timesteps: 1,939,326,334

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,464.25794
Policy Entropy: 2.13424
Value Function Loss: 0.02057

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.07619
Policy Update Magnitude: 0.31153
Value Function Update Magnitude: 0.34839

Collected Steps per Second: 21,805.49708
Overall Steps per Second: 10,417.42216

Timestep Collection Time: 2.29493
Timestep Consumption Time: 2.50876
PPO Batch Consumption Time: 0.29081
Total Iteration Time: 4.80368

Cumulative Model Updates: 232,460
Cumulative Timesteps: 1,939,376,376

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1939376376...
Checkpoint 1939376376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43,943.45555
Policy Entropy: 2.14590
Value Function Loss: 0.02003

Mean KL Divergence: 0.00741
SB3 Clip Fraction: 0.06994
Policy Update Magnitude: 0.30629
Value Function Update Magnitude: 0.35883

Collected Steps per Second: 20,871.74363
Overall Steps per Second: 10,357.38724

Timestep Collection Time: 2.39568
Timestep Consumption Time: 2.43199
PPO Batch Consumption Time: 0.28948
Total Iteration Time: 4.82767

Cumulative Model Updates: 232,466
Cumulative Timesteps: 1,939,426,378

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,498.36443
Policy Entropy: 2.14702
Value Function Loss: 0.02134

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.07136
Policy Update Magnitude: 0.30599
Value Function Update Magnitude: 0.35398

Collected Steps per Second: 21,505.20989
Overall Steps per Second: 10,454.55840

Timestep Collection Time: 2.32558
Timestep Consumption Time: 2.45817
PPO Batch Consumption Time: 0.29117
Total Iteration Time: 4.78375

Cumulative Model Updates: 232,472
Cumulative Timesteps: 1,939,476,390

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1939476390...
Checkpoint 1939476390 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,528.46988
Policy Entropy: 2.15094
Value Function Loss: 0.02269

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.07598
Policy Update Magnitude: 0.31352
Value Function Update Magnitude: 0.37786

Collected Steps per Second: 21,373.50029
Overall Steps per Second: 10,461.09702

Timestep Collection Time: 2.34084
Timestep Consumption Time: 2.44183
PPO Batch Consumption Time: 0.29260
Total Iteration Time: 4.78267

Cumulative Model Updates: 232,478
Cumulative Timesteps: 1,939,526,422

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,554.22541
Policy Entropy: 2.14841
Value Function Loss: 0.02027

Mean KL Divergence: 0.00744
SB3 Clip Fraction: 0.06825
Policy Update Magnitude: 0.31184
Value Function Update Magnitude: 0.37394

Collected Steps per Second: 21,670.05302
Overall Steps per Second: 10,477.47578

Timestep Collection Time: 2.30853
Timestep Consumption Time: 2.46609
PPO Batch Consumption Time: 0.28784
Total Iteration Time: 4.77462

Cumulative Model Updates: 232,484
Cumulative Timesteps: 1,939,576,448

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1939576448...
Checkpoint 1939576448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48,703.38923
Policy Entropy: 2.16863
Value Function Loss: 0.01997

Mean KL Divergence: 0.00735
SB3 Clip Fraction: 0.06904
Policy Update Magnitude: 0.30922
Value Function Update Magnitude: 0.34616

Collected Steps per Second: 21,869.01534
Overall Steps per Second: 10,667.19617

Timestep Collection Time: 2.28652
Timestep Consumption Time: 2.40112
PPO Batch Consumption Time: 0.27776
Total Iteration Time: 4.68764

Cumulative Model Updates: 232,490
Cumulative Timesteps: 1,939,626,452

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 69,203.93582
Policy Entropy: 2.16923
Value Function Loss: 0.02077

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.07204
Policy Update Magnitude: 0.30055
Value Function Update Magnitude: 0.32147

Collected Steps per Second: 22,165.68247
Overall Steps per Second: 10,568.32013

Timestep Collection Time: 2.25619
Timestep Consumption Time: 2.47588
PPO Batch Consumption Time: 0.29199
Total Iteration Time: 4.73207

Cumulative Model Updates: 232,496
Cumulative Timesteps: 1,939,676,462

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1939676462...
Checkpoint 1939676462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 65,377.91002
Policy Entropy: 2.17073
Value Function Loss: 0.02063

Mean KL Divergence: 0.00709
SB3 Clip Fraction: 0.06416
Policy Update Magnitude: 0.30021
Value Function Update Magnitude: 0.31906

Collected Steps per Second: 21,666.67829
Overall Steps per Second: 10,497.54320

Timestep Collection Time: 2.30806
Timestep Consumption Time: 2.45572
PPO Batch Consumption Time: 0.27956
Total Iteration Time: 4.76378

Cumulative Model Updates: 232,502
Cumulative Timesteps: 1,939,726,470

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65,702.06924
Policy Entropy: 2.16521
Value Function Loss: 0.02156

Mean KL Divergence: 0.00690
SB3 Clip Fraction: 0.06501
Policy Update Magnitude: 0.29973
Value Function Update Magnitude: 0.31227

Collected Steps per Second: 22,056.42017
Overall Steps per Second: 10,455.98546

Timestep Collection Time: 2.26827
Timestep Consumption Time: 2.51655
PPO Batch Consumption Time: 0.29199
Total Iteration Time: 4.78482

Cumulative Model Updates: 232,508
Cumulative Timesteps: 1,939,776,500

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1939776500...
Checkpoint 1939776500 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,508.31792
Policy Entropy: 2.15391
Value Function Loss: 0.02145

Mean KL Divergence: 0.00733
SB3 Clip Fraction: 0.07138
Policy Update Magnitude: 0.30235
Value Function Update Magnitude: 0.32572

Collected Steps per Second: 21,390.57193
Overall Steps per Second: 10,365.00458

Timestep Collection Time: 2.33823
Timestep Consumption Time: 2.48724
PPO Batch Consumption Time: 0.29089
Total Iteration Time: 4.82547

Cumulative Model Updates: 232,514
Cumulative Timesteps: 1,939,826,516

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,836.40559
Policy Entropy: 2.15143
Value Function Loss: 0.02170

Mean KL Divergence: 0.00713
SB3 Clip Fraction: 0.06678
Policy Update Magnitude: 0.30146
Value Function Update Magnitude: 0.35578

Collected Steps per Second: 21,345.19449
Overall Steps per Second: 10,321.64796

Timestep Collection Time: 2.34329
Timestep Consumption Time: 2.50264
PPO Batch Consumption Time: 0.29319
Total Iteration Time: 4.84593

Cumulative Model Updates: 232,520
Cumulative Timesteps: 1,939,876,534

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1939876534...
Checkpoint 1939876534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 85,770.38146
Policy Entropy: 2.14822
Value Function Loss: 0.02260

Mean KL Divergence: 0.00723
SB3 Clip Fraction: 0.06396
Policy Update Magnitude: 0.31707
Value Function Update Magnitude: 0.35934

Collected Steps per Second: 21,030.60036
Overall Steps per Second: 10,249.19070

Timestep Collection Time: 2.37758
Timestep Consumption Time: 2.50105
PPO Batch Consumption Time: 0.29423
Total Iteration Time: 4.87863

Cumulative Model Updates: 232,526
Cumulative Timesteps: 1,939,926,536

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54,988.94188
Policy Entropy: 2.15370
Value Function Loss: 0.02356

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.07740
Policy Update Magnitude: 0.32165
Value Function Update Magnitude: 0.36306

Collected Steps per Second: 21,371.29882
Overall Steps per Second: 10,309.06302

Timestep Collection Time: 2.34183
Timestep Consumption Time: 2.51292
PPO Batch Consumption Time: 0.27910
Total Iteration Time: 4.85476

Cumulative Model Updates: 232,532
Cumulative Timesteps: 1,939,976,584

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 1939976584...
Checkpoint 1939976584 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,341.44864
Policy Entropy: 2.13495
Value Function Loss: 0.02434

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.07737
Policy Update Magnitude: 0.32115
Value Function Update Magnitude: 0.37961

Collected Steps per Second: 21,658.35325
Overall Steps per Second: 10,340.63842

Timestep Collection Time: 2.30858
Timestep Consumption Time: 2.52671
PPO Batch Consumption Time: 0.29312
Total Iteration Time: 4.83529

Cumulative Model Updates: 232,538
Cumulative Timesteps: 1,940,026,584

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,225.66657
Policy Entropy: 2.13077
Value Function Loss: 0.02242

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.07533
Policy Update Magnitude: 0.32001
Value Function Update Magnitude: 0.37519

Collected Steps per Second: 22,196.57391
Overall Steps per Second: 10,533.06284

Timestep Collection Time: 2.25278
Timestep Consumption Time: 2.49456
PPO Batch Consumption Time: 0.29235
Total Iteration Time: 4.74734

Cumulative Model Updates: 232,544
Cumulative Timesteps: 1,940,076,588

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1940076588...
Checkpoint 1940076588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,904.44905
Policy Entropy: 2.12475
Value Function Loss: 0.02296

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.08036
Policy Update Magnitude: 0.31838
Value Function Update Magnitude: 0.38388

Collected Steps per Second: 21,726.32262
Overall Steps per Second: 10,475.01346

Timestep Collection Time: 2.30209
Timestep Consumption Time: 2.47270
PPO Batch Consumption Time: 0.28675
Total Iteration Time: 4.77479

Cumulative Model Updates: 232,550
Cumulative Timesteps: 1,940,126,604

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,728.03733
Policy Entropy: 2.13170
Value Function Loss: 0.02433

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.09055
Policy Update Magnitude: 0.32009
Value Function Update Magnitude: 0.40633

Collected Steps per Second: 21,967.70315
Overall Steps per Second: 10,434.89917

Timestep Collection Time: 2.27643
Timestep Consumption Time: 2.51595
PPO Batch Consumption Time: 0.29172
Total Iteration Time: 4.79238

Cumulative Model Updates: 232,556
Cumulative Timesteps: 1,940,176,612

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1940176612...
Checkpoint 1940176612 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40,904.10949
Policy Entropy: 2.14053
Value Function Loss: 0.02314

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.08646
Policy Update Magnitude: 0.31777
Value Function Update Magnitude: 0.39743

Collected Steps per Second: 21,133.36175
Overall Steps per Second: 10,603.07315

Timestep Collection Time: 2.36716
Timestep Consumption Time: 2.35091
PPO Batch Consumption Time: 0.27917
Total Iteration Time: 4.71807

Cumulative Model Updates: 232,562
Cumulative Timesteps: 1,940,226,638

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52,664.83786
Policy Entropy: 2.15046
Value Function Loss: 0.02460

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.08206
Policy Update Magnitude: 0.31467
Value Function Update Magnitude: 0.38763

Collected Steps per Second: 21,257.29747
Overall Steps per Second: 10,523.90302

Timestep Collection Time: 2.35232
Timestep Consumption Time: 2.39915
PPO Batch Consumption Time: 0.28609
Total Iteration Time: 4.75147

Cumulative Model Updates: 232,568
Cumulative Timesteps: 1,940,276,642

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1940276642...
Checkpoint 1940276642 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,353.33452
Policy Entropy: 2.15980
Value Function Loss: 0.02077

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.08807
Policy Update Magnitude: 0.31163
Value Function Update Magnitude: 0.36022

Collected Steps per Second: 20,969.46630
Overall Steps per Second: 10,576.82261

Timestep Collection Time: 2.38480
Timestep Consumption Time: 2.34327
PPO Batch Consumption Time: 0.27827
Total Iteration Time: 4.72807

Cumulative Model Updates: 232,574
Cumulative Timesteps: 1,940,326,650

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,808.86297
Policy Entropy: 2.14946
Value Function Loss: 0.02097

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.07653
Policy Update Magnitude: 0.30578
Value Function Update Magnitude: 0.31136

Collected Steps per Second: 20,868.48265
Overall Steps per Second: 10,260.39541

Timestep Collection Time: 2.39816
Timestep Consumption Time: 2.47943
PPO Batch Consumption Time: 0.29068
Total Iteration Time: 4.87759

Cumulative Model Updates: 232,580
Cumulative Timesteps: 1,940,376,696

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1940376696...
Checkpoint 1940376696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,902.18944
Policy Entropy: 2.15599
Value Function Loss: 0.02134

Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.07596
Policy Update Magnitude: 0.29915
Value Function Update Magnitude: 0.29810

Collected Steps per Second: 20,976.98346
Overall Steps per Second: 10,416.70702

Timestep Collection Time: 2.38395
Timestep Consumption Time: 2.41680
PPO Batch Consumption Time: 0.27899
Total Iteration Time: 4.80075

Cumulative Model Updates: 232,586
Cumulative Timesteps: 1,940,426,704

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,490.67537
Policy Entropy: 2.15569
Value Function Loss: 0.02147

Mean KL Divergence: 0.00730
SB3 Clip Fraction: 0.06981
Policy Update Magnitude: 0.29790
Value Function Update Magnitude: 0.27965

Collected Steps per Second: 21,544.09143
Overall Steps per Second: 10,474.30140

Timestep Collection Time: 2.32156
Timestep Consumption Time: 2.45355
PPO Batch Consumption Time: 0.28523
Total Iteration Time: 4.77512

Cumulative Model Updates: 232,592
Cumulative Timesteps: 1,940,476,720

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1940476720...
Checkpoint 1940476720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,710.21686
Policy Entropy: 2.15268
Value Function Loss: 0.02081

Mean KL Divergence: 0.00772
SB3 Clip Fraction: 0.07265
Policy Update Magnitude: 0.29549
Value Function Update Magnitude: 0.28248

Collected Steps per Second: 21,678.32359
Overall Steps per Second: 10,572.36201

Timestep Collection Time: 2.30691
Timestep Consumption Time: 2.42335
PPO Batch Consumption Time: 0.27858
Total Iteration Time: 4.73026

Cumulative Model Updates: 232,598
Cumulative Timesteps: 1,940,526,730

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70,476.73356
Policy Entropy: 2.14456
Value Function Loss: 0.01963

Mean KL Divergence: 0.00752
SB3 Clip Fraction: 0.07245
Policy Update Magnitude: 0.29303
Value Function Update Magnitude: 0.29988

Collected Steps per Second: 22,140.81158
Overall Steps per Second: 10,563.56972

Timestep Collection Time: 2.25963
Timestep Consumption Time: 2.47646
PPO Batch Consumption Time: 0.27873
Total Iteration Time: 4.73609

Cumulative Model Updates: 232,604
Cumulative Timesteps: 1,940,576,760

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1940576760...
Checkpoint 1940576760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55,165.48129
Policy Entropy: 2.14976
Value Function Loss: 0.01895

Mean KL Divergence: 0.00704
SB3 Clip Fraction: 0.06733
Policy Update Magnitude: 0.29435
Value Function Update Magnitude: 0.28769

Collected Steps per Second: 21,951.11696
Overall Steps per Second: 10,598.21515

Timestep Collection Time: 2.27843
Timestep Consumption Time: 2.44067
PPO Batch Consumption Time: 0.27895
Total Iteration Time: 4.71910

Cumulative Model Updates: 232,610
Cumulative Timesteps: 1,940,626,774

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51,803.21076
Policy Entropy: 2.13403
Value Function Loss: 0.02117

Mean KL Divergence: 0.00734
SB3 Clip Fraction: 0.06975
Policy Update Magnitude: 0.30231
Value Function Update Magnitude: 0.29635

Collected Steps per Second: 22,002.42968
Overall Steps per Second: 10,448.04961

Timestep Collection Time: 2.27257
Timestep Consumption Time: 2.51321
PPO Batch Consumption Time: 0.29208
Total Iteration Time: 4.78577

Cumulative Model Updates: 232,616
Cumulative Timesteps: 1,940,676,776

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1940676776...
Checkpoint 1940676776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48,448.38432
Policy Entropy: 2.13131
Value Function Loss: 0.02334

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.07773
Policy Update Magnitude: 0.31461
Value Function Update Magnitude: 0.27680

Collected Steps per Second: 21,931.95039
Overall Steps per Second: 10,597.07933

Timestep Collection Time: 2.28188
Timestep Consumption Time: 2.44075
PPO Batch Consumption Time: 0.27991
Total Iteration Time: 4.72262

Cumulative Model Updates: 232,622
Cumulative Timesteps: 1,940,726,822

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60,856.44341
Policy Entropy: 2.12052
Value Function Loss: 0.02437

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.07989
Policy Update Magnitude: 0.31717
Value Function Update Magnitude: 0.25761

Collected Steps per Second: 21,877.18554
Overall Steps per Second: 10,496.77015

Timestep Collection Time: 2.28576
Timestep Consumption Time: 2.47818
PPO Batch Consumption Time: 0.28570
Total Iteration Time: 4.76394

Cumulative Model Updates: 232,628
Cumulative Timesteps: 1,940,776,828

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1940776828...
Checkpoint 1940776828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47,361.19144
Policy Entropy: 2.12653
Value Function Loss: 0.02274

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.09116
Policy Update Magnitude: 0.31402
Value Function Update Magnitude: 0.27657

Collected Steps per Second: 21,773.89998
Overall Steps per Second: 10,575.86033

Timestep Collection Time: 2.29761
Timestep Consumption Time: 2.43278
PPO Batch Consumption Time: 0.27916
Total Iteration Time: 4.73040

Cumulative Model Updates: 232,634
Cumulative Timesteps: 1,940,826,856

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,726.33302
Policy Entropy: 2.12940
Value Function Loss: 0.02171

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.08699
Policy Update Magnitude: 0.30738
Value Function Update Magnitude: 0.31675

Collected Steps per Second: 21,908.80508
Overall Steps per Second: 10,624.73145

Timestep Collection Time: 2.28401
Timestep Consumption Time: 2.42575
PPO Batch Consumption Time: 0.27769
Total Iteration Time: 4.70977

Cumulative Model Updates: 232,640
Cumulative Timesteps: 1,940,876,896

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1940876896...
Checkpoint 1940876896 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 51,309.36579
Policy Entropy: 2.13787
Value Function Loss: 0.02315

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.09011
Policy Update Magnitude: 0.31021
Value Function Update Magnitude: 0.32107

Collected Steps per Second: 21,273.08762
Overall Steps per Second: 10,504.32959

Timestep Collection Time: 2.35199
Timestep Consumption Time: 2.41119
PPO Batch Consumption Time: 0.27832
Total Iteration Time: 4.76318

Cumulative Model Updates: 232,646
Cumulative Timesteps: 1,940,926,930

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,641.21218
Policy Entropy: 2.15174
Value Function Loss: 0.02432

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.08044
Policy Update Magnitude: 0.31916
Value Function Update Magnitude: 0.33253

Collected Steps per Second: 21,360.10909
Overall Steps per Second: 10,475.83962

Timestep Collection Time: 2.34250
Timestep Consumption Time: 2.43383
PPO Batch Consumption Time: 0.27985
Total Iteration Time: 4.77632

Cumulative Model Updates: 232,652
Cumulative Timesteps: 1,940,976,966

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1940976966...
Checkpoint 1940976966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,620.07496
Policy Entropy: 2.13360
Value Function Loss: 0.02364

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.08360
Policy Update Magnitude: 0.31500
Value Function Update Magnitude: 0.31720

Collected Steps per Second: 21,442.42850
Overall Steps per Second: 10,332.02067

Timestep Collection Time: 2.33192
Timestep Consumption Time: 2.50760
PPO Batch Consumption Time: 0.29349
Total Iteration Time: 4.83952

Cumulative Model Updates: 232,658
Cumulative Timesteps: 1,941,026,968

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,911.03505
Policy Entropy: 2.13543
Value Function Loss: 0.02429

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.08596
Policy Update Magnitude: 0.30817
Value Function Update Magnitude: 0.32004

Collected Steps per Second: 21,046.81682
Overall Steps per Second: 10,414.84892

Timestep Collection Time: 2.37689
Timestep Consumption Time: 2.42644
PPO Batch Consumption Time: 0.29318
Total Iteration Time: 4.80333

Cumulative Model Updates: 232,664
Cumulative Timesteps: 1,941,076,994

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1941076994...
Checkpoint 1941076994 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,796.44868
Policy Entropy: 2.12435
Value Function Loss: 0.02234

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.08110
Policy Update Magnitude: 0.30919
Value Function Update Magnitude: 0.34855

Collected Steps per Second: 20,885.03639
Overall Steps per Second: 10,546.33003

Timestep Collection Time: 2.39597
Timestep Consumption Time: 2.34880
PPO Batch Consumption Time: 0.27880
Total Iteration Time: 4.74478

Cumulative Model Updates: 232,670
Cumulative Timesteps: 1,941,127,034

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,958.39358
Policy Entropy: 2.12235
Value Function Loss: 0.02130

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.07886
Policy Update Magnitude: 0.30941
Value Function Update Magnitude: 0.36175

Collected Steps per Second: 21,202.42914
Overall Steps per Second: 10,538.80899

Timestep Collection Time: 2.35869
Timestep Consumption Time: 2.38663
PPO Batch Consumption Time: 0.27861
Total Iteration Time: 4.74532

Cumulative Model Updates: 232,676
Cumulative Timesteps: 1,941,177,044

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1941177044...
Checkpoint 1941177044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,366.22394
Policy Entropy: 2.13045
Value Function Loss: 0.02237

Mean KL Divergence: 0.01078
SB3 Clip Fraction: 0.09039
Policy Update Magnitude: 0.31585
Value Function Update Magnitude: 0.35053

Collected Steps per Second: 21,489.89318
Overall Steps per Second: 10,531.03801

Timestep Collection Time: 2.32761
Timestep Consumption Time: 2.42216
PPO Batch Consumption Time: 0.27910
Total Iteration Time: 4.74977

Cumulative Model Updates: 232,682
Cumulative Timesteps: 1,941,227,064

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,908.04503
Policy Entropy: 2.14293
Value Function Loss: 0.02152

Mean KL Divergence: 0.01513
SB3 Clip Fraction: 0.11139
Policy Update Magnitude: 0.29709
Value Function Update Magnitude: 0.34458

Collected Steps per Second: 21,997.19303
Overall Steps per Second: 10,539.55530

Timestep Collection Time: 2.27484
Timestep Consumption Time: 2.47299
PPO Batch Consumption Time: 0.28877
Total Iteration Time: 4.74783

Cumulative Model Updates: 232,688
Cumulative Timesteps: 1,941,277,104

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1941277104...
Checkpoint 1941277104 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,344.26568
Policy Entropy: 2.14613
Value Function Loss: 0.02315

Mean KL Divergence: 0.01467
SB3 Clip Fraction: 0.11125
Policy Update Magnitude: 0.28754
Value Function Update Magnitude: 0.33759

Collected Steps per Second: 21,796.04063
Overall Steps per Second: 10,625.81790

Timestep Collection Time: 2.29519
Timestep Consumption Time: 2.41278
PPO Batch Consumption Time: 0.28057
Total Iteration Time: 4.70797

Cumulative Model Updates: 232,694
Cumulative Timesteps: 1,941,327,130

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42,161.89080
Policy Entropy: 2.14085
Value Function Loss: 0.02132

Mean KL Divergence: 0.01298
SB3 Clip Fraction: 0.10115
Policy Update Magnitude: 0.29855
Value Function Update Magnitude: 0.34121

Collected Steps per Second: 22,029.93832
Overall Steps per Second: 10,470.10035

Timestep Collection Time: 2.27136
Timestep Consumption Time: 2.50777
PPO Batch Consumption Time: 0.29167
Total Iteration Time: 4.77913

Cumulative Model Updates: 232,700
Cumulative Timesteps: 1,941,377,168

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1941377168...
Checkpoint 1941377168 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,163.20868
Policy Entropy: 2.12281
Value Function Loss: 0.02515

Mean KL Divergence: 0.01180
SB3 Clip Fraction: 0.09501
Policy Update Magnitude: 0.31569
Value Function Update Magnitude: 0.37492

Collected Steps per Second: 21,504.61648
Overall Steps per Second: 10,326.25074

Timestep Collection Time: 2.32638
Timestep Consumption Time: 2.51836
PPO Batch Consumption Time: 0.29300
Total Iteration Time: 4.84474

Cumulative Model Updates: 232,706
Cumulative Timesteps: 1,941,427,196

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,280.56031
Policy Entropy: 2.12452
Value Function Loss: 0.02207

Mean KL Divergence: 0.01312
SB3 Clip Fraction: 0.10183
Policy Update Magnitude: 0.32039
Value Function Update Magnitude: 0.37631

Collected Steps per Second: 21,862.47035
Overall Steps per Second: 10,434.95652

Timestep Collection Time: 2.28730
Timestep Consumption Time: 2.50486
PPO Batch Consumption Time: 0.29259
Total Iteration Time: 4.79216

Cumulative Model Updates: 232,712
Cumulative Timesteps: 1,941,477,202

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1941477202...
Checkpoint 1941477202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 71,047.68519
Policy Entropy: 2.12388
Value Function Loss: 0.02147

Mean KL Divergence: 0.01554
SB3 Clip Fraction: 0.11186
Policy Update Magnitude: 0.30898
Value Function Update Magnitude: 0.34193

Collected Steps per Second: 21,683.73594
Overall Steps per Second: 10,580.92220

Timestep Collection Time: 2.30717
Timestep Consumption Time: 2.42097
PPO Batch Consumption Time: 0.27804
Total Iteration Time: 4.72813

Cumulative Model Updates: 232,718
Cumulative Timesteps: 1,941,527,230

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66,605.09479
Policy Entropy: 2.12402
Value Function Loss: 0.02106

Mean KL Divergence: 0.01172
SB3 Clip Fraction: 0.09574
Policy Update Magnitude: 0.30246
Value Function Update Magnitude: 0.33462

Collected Steps per Second: 21,462.16309
Overall Steps per Second: 10,468.39975

Timestep Collection Time: 2.32968
Timestep Consumption Time: 2.44660
PPO Batch Consumption Time: 0.27934
Total Iteration Time: 4.77628

Cumulative Model Updates: 232,724
Cumulative Timesteps: 1,941,577,230

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1941577230...
Checkpoint 1941577230 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,133.69694
Policy Entropy: 2.10969
Value Function Loss: 0.01997

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.08547
Policy Update Magnitude: 0.31391
Value Function Update Magnitude: 0.33540

Collected Steps per Second: 21,192.90245
Overall Steps per Second: 10,264.00761

Timestep Collection Time: 2.36004
Timestep Consumption Time: 2.51292
PPO Batch Consumption Time: 0.29329
Total Iteration Time: 4.87295

Cumulative Model Updates: 232,730
Cumulative Timesteps: 1,941,627,246

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54,999.47264
Policy Entropy: 2.10734
Value Function Loss: 0.02127

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.08068
Policy Update Magnitude: 0.31797
Value Function Update Magnitude: 0.34187

Collected Steps per Second: 21,802.14432
Overall Steps per Second: 10,384.23109

Timestep Collection Time: 2.29335
Timestep Consumption Time: 2.52164
PPO Batch Consumption Time: 0.29142
Total Iteration Time: 4.81499

Cumulative Model Updates: 232,736
Cumulative Timesteps: 1,941,677,246

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1941677246...
Checkpoint 1941677246 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 72,154.49512
Policy Entropy: 2.13543
Value Function Loss: 0.02243

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.07714
Policy Update Magnitude: 0.31295
Value Function Update Magnitude: 0.33937

Collected Steps per Second: 21,159.63585
Overall Steps per Second: 10,215.89043

Timestep Collection Time: 2.36431
Timestep Consumption Time: 2.53276
PPO Batch Consumption Time: 0.29437
Total Iteration Time: 4.89708

Cumulative Model Updates: 232,742
Cumulative Timesteps: 1,941,727,274

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 72,405.57758
Policy Entropy: 2.14761
Value Function Loss: 0.02348

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.07470
Policy Update Magnitude: 0.31719
Value Function Update Magnitude: 0.32388

Collected Steps per Second: 22,218.84008
Overall Steps per Second: 10,439.71874

Timestep Collection Time: 2.25169
Timestep Consumption Time: 2.54058
PPO Batch Consumption Time: 0.29018
Total Iteration Time: 4.79227

Cumulative Model Updates: 232,748
Cumulative Timesteps: 1,941,777,304

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1941777304...
Checkpoint 1941777304 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 82,539.33101
Policy Entropy: 2.16070
Value Function Loss: 0.02232

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.07551
Policy Update Magnitude: 0.31148
Value Function Update Magnitude: 0.34045

Collected Steps per Second: 21,612.58969
Overall Steps per Second: 10,330.47910

Timestep Collection Time: 2.31467
Timestep Consumption Time: 2.52789
PPO Batch Consumption Time: 0.29252
Total Iteration Time: 4.84256

Cumulative Model Updates: 232,754
Cumulative Timesteps: 1,941,827,330

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82,475.84698
Policy Entropy: 2.14026
Value Function Loss: 0.01924

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.07758
Policy Update Magnitude: 0.30707
Value Function Update Magnitude: 0.36211

Collected Steps per Second: 21,608.80937
Overall Steps per Second: 10,352.91368

Timestep Collection Time: 2.31535
Timestep Consumption Time: 2.51730
PPO Batch Consumption Time: 0.29220
Total Iteration Time: 4.83265

Cumulative Model Updates: 232,760
Cumulative Timesteps: 1,941,877,362

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1941877362...
Checkpoint 1941877362 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 67,456.18266
Policy Entropy: 2.14152
Value Function Loss: 0.02024

Mean KL Divergence: 0.00763
SB3 Clip Fraction: 0.07147
Policy Update Magnitude: 0.30913
Value Function Update Magnitude: 0.35378

Collected Steps per Second: 21,556.23988
Overall Steps per Second: 10,407.30960

Timestep Collection Time: 2.32091
Timestep Consumption Time: 2.48629
PPO Batch Consumption Time: 0.28994
Total Iteration Time: 4.80720

Cumulative Model Updates: 232,766
Cumulative Timesteps: 1,941,927,392

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,661.44511
Policy Entropy: 2.13111
Value Function Loss: 0.02274

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.07823
Policy Update Magnitude: 0.32005
Value Function Update Magnitude: 0.34236

Collected Steps per Second: 22,528.87805
Overall Steps per Second: 10,728.73820

Timestep Collection Time: 2.21946
Timestep Consumption Time: 2.44110
PPO Batch Consumption Time: 0.28226
Total Iteration Time: 4.66057

Cumulative Model Updates: 232,772
Cumulative Timesteps: 1,941,977,394

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1941977394...
Checkpoint 1941977394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,375.24061
Policy Entropy: 2.13707
Value Function Loss: 0.02257

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.07990
Policy Update Magnitude: 0.32136
Value Function Update Magnitude: 0.33484

Collected Steps per Second: 21,939.36435
Overall Steps per Second: 10,657.86520

Timestep Collection Time: 2.27946
Timestep Consumption Time: 2.41284
PPO Batch Consumption Time: 0.27760
Total Iteration Time: 4.69231

Cumulative Model Updates: 232,778
Cumulative Timesteps: 1,942,027,404

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 69,965.09277
Policy Entropy: 2.14298
Value Function Loss: 0.02346

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.08254
Policy Update Magnitude: 0.31915
Value Function Update Magnitude: 0.33320

Collected Steps per Second: 21,273.89745
Overall Steps per Second: 10,440.35124

Timestep Collection Time: 2.35058
Timestep Consumption Time: 2.43911
PPO Batch Consumption Time: 0.29373
Total Iteration Time: 4.78969

Cumulative Model Updates: 232,784
Cumulative Timesteps: 1,942,077,410

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1942077410...
Checkpoint 1942077410 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,561.23547
Policy Entropy: 2.15226
Value Function Loss: 0.02502

Mean KL Divergence: 0.01136
SB3 Clip Fraction: 0.09701
Policy Update Magnitude: 0.30903
Value Function Update Magnitude: 0.33928

Collected Steps per Second: 20,981.05824
Overall Steps per Second: 10,542.24269

Timestep Collection Time: 2.38425
Timestep Consumption Time: 2.36085
PPO Batch Consumption Time: 0.27878
Total Iteration Time: 4.74510

Cumulative Model Updates: 232,790
Cumulative Timesteps: 1,942,127,434

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 71,358.65835
Policy Entropy: 2.15919
Value Function Loss: 0.02567

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.08771
Policy Update Magnitude: 0.31331
Value Function Update Magnitude: 0.35003

Collected Steps per Second: 21,111.45743
Overall Steps per Second: 10,508.53800

Timestep Collection Time: 2.36838
Timestep Consumption Time: 2.38965
PPO Batch Consumption Time: 0.28467
Total Iteration Time: 4.75804

Cumulative Model Updates: 232,796
Cumulative Timesteps: 1,942,177,434

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1942177434...
Checkpoint 1942177434 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 53,910.83821
Policy Entropy: 2.14954
Value Function Loss: 0.02317

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.08168
Policy Update Magnitude: 0.31812
Value Function Update Magnitude: 0.33187

Collected Steps per Second: 19,796.51005
Overall Steps per Second: 9,863.64216

Timestep Collection Time: 2.52640
Timestep Consumption Time: 2.54414
PPO Batch Consumption Time: 0.29499
Total Iteration Time: 5.07054

Cumulative Model Updates: 232,802
Cumulative Timesteps: 1,942,227,448

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45,221.21635
Policy Entropy: 2.14611
Value Function Loss: 0.02188

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.07425
Policy Update Magnitude: 0.31280
Value Function Update Magnitude: 0.33388

Collected Steps per Second: 21,488.70567
Overall Steps per Second: 10,404.14775

Timestep Collection Time: 2.32783
Timestep Consumption Time: 2.48006
PPO Batch Consumption Time: 0.29113
Total Iteration Time: 4.80789

Cumulative Model Updates: 232,808
Cumulative Timesteps: 1,942,277,470

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1942277470...
Checkpoint 1942277470 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 51,624.17220
Policy Entropy: 2.14496
Value Function Loss: 0.02068

Mean KL Divergence: 0.00730
SB3 Clip Fraction: 0.06768
Policy Update Magnitude: 0.31216
Value Function Update Magnitude: 0.32419

Collected Steps per Second: 21,388.00112
Overall Steps per Second: 10,363.99217

Timestep Collection Time: 2.33804
Timestep Consumption Time: 2.48693
PPO Batch Consumption Time: 0.29054
Total Iteration Time: 4.82497

Cumulative Model Updates: 232,814
Cumulative Timesteps: 1,942,327,476

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50,147.62238
Policy Entropy: 2.15201
Value Function Loss: 0.02297

Mean KL Divergence: 0.00740
SB3 Clip Fraction: 0.06976
Policy Update Magnitude: 0.31979
Value Function Update Magnitude: 0.32713

Collected Steps per Second: 21,938.64845
Overall Steps per Second: 10,386.79106

Timestep Collection Time: 2.27999
Timestep Consumption Time: 2.53574
PPO Batch Consumption Time: 0.29344
Total Iteration Time: 4.81573

Cumulative Model Updates: 232,820
Cumulative Timesteps: 1,942,377,496

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1942377496...
Checkpoint 1942377496 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 50,397.47547
Policy Entropy: 2.13986
Value Function Loss: 0.02216

Mean KL Divergence: 0.00745
SB3 Clip Fraction: 0.07004
Policy Update Magnitude: 0.31373
Value Function Update Magnitude: 0.32932

Collected Steps per Second: 21,913.32133
Overall Steps per Second: 10,567.07779

Timestep Collection Time: 2.28172
Timestep Consumption Time: 2.44996
PPO Batch Consumption Time: 0.27905
Total Iteration Time: 4.73168

Cumulative Model Updates: 232,826
Cumulative Timesteps: 1,942,427,496

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49,670.16328
Policy Entropy: 2.14003
Value Function Loss: 0.02134

Mean KL Divergence: 0.00699
SB3 Clip Fraction: 0.06842
Policy Update Magnitude: 0.30563
Value Function Update Magnitude: 0.31845

Collected Steps per Second: 22,186.41961
Overall Steps per Second: 10,478.37097

Timestep Collection Time: 2.25390
Timestep Consumption Time: 2.51841
PPO Batch Consumption Time: 0.29302
Total Iteration Time: 4.77231

Cumulative Model Updates: 232,832
Cumulative Timesteps: 1,942,477,502

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1942477502...
Checkpoint 1942477502 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,642.16613
Policy Entropy: 2.14445
Value Function Loss: 0.02040

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.07613
Policy Update Magnitude: 0.30062
Value Function Update Magnitude: 0.30085

Collected Steps per Second: 21,580.15175
Overall Steps per Second: 10,525.67048

Timestep Collection Time: 2.31843
Timestep Consumption Time: 2.43490
PPO Batch Consumption Time: 0.27904
Total Iteration Time: 4.75333

Cumulative Model Updates: 232,838
Cumulative Timesteps: 1,942,527,534

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,004.37013
Policy Entropy: 2.14469
Value Function Loss: 0.02552

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.08461
Policy Update Magnitude: 0.31395
Value Function Update Magnitude: 0.30434

Collected Steps per Second: 22,316.63322
Overall Steps per Second: 10,494.31479

Timestep Collection Time: 2.24129
Timestep Consumption Time: 2.52491
PPO Batch Consumption Time: 0.29431
Total Iteration Time: 4.76620

Cumulative Model Updates: 232,844
Cumulative Timesteps: 1,942,577,552

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1942577552...
Checkpoint 1942577552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,991.83120
Policy Entropy: 2.14327
Value Function Loss: 0.02452

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.09083
Policy Update Magnitude: 0.31332
Value Function Update Magnitude: 0.32583

Collected Steps per Second: 21,629.46964
Overall Steps per Second: 10,558.00920

Timestep Collection Time: 2.31203
Timestep Consumption Time: 2.42447
PPO Batch Consumption Time: 0.27880
Total Iteration Time: 4.73650

Cumulative Model Updates: 232,850
Cumulative Timesteps: 1,942,627,560

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,776.75353
Policy Entropy: 2.14973
Value Function Loss: 0.02339

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.08415
Policy Update Magnitude: 0.30401
Value Function Update Magnitude: 0.33402

Collected Steps per Second: 21,683.36306
Overall Steps per Second: 10,534.20171

Timestep Collection Time: 2.30601
Timestep Consumption Time: 2.44063
PPO Batch Consumption Time: 0.27941
Total Iteration Time: 4.74663

Cumulative Model Updates: 232,856
Cumulative Timesteps: 1,942,677,562

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1942677562...
Checkpoint 1942677562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,988.82900
Policy Entropy: 2.14208
Value Function Loss: 0.02108

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.07931
Policy Update Magnitude: 0.30353
Value Function Update Magnitude: 0.30143

Collected Steps per Second: 21,297.72944
Overall Steps per Second: 10,344.30234

Timestep Collection Time: 2.34908
Timestep Consumption Time: 2.48740
PPO Batch Consumption Time: 0.29193
Total Iteration Time: 4.83648

Cumulative Model Updates: 232,862
Cumulative Timesteps: 1,942,727,592

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 71,371.38970
Policy Entropy: 2.14502
Value Function Loss: 0.02241

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.08930
Policy Update Magnitude: 0.30741
Value Function Update Magnitude: 0.27756

Collected Steps per Second: 21,815.86347
Overall Steps per Second: 10,437.76618

Timestep Collection Time: 2.29191
Timestep Consumption Time: 2.49839
PPO Batch Consumption Time: 0.29230
Total Iteration Time: 4.79030

Cumulative Model Updates: 232,868
Cumulative Timesteps: 1,942,777,592

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1942777592...
Checkpoint 1942777592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 72,572.78853
Policy Entropy: 2.13524
Value Function Loss: 0.02290

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.08783
Policy Update Magnitude: 0.31288
Value Function Update Magnitude: 0.28853

Collected Steps per Second: 21,331.38814
Overall Steps per Second: 10,460.44448

Timestep Collection Time: 2.34425
Timestep Consumption Time: 2.43624
PPO Batch Consumption Time: 0.27953
Total Iteration Time: 4.78049

Cumulative Model Updates: 232,874
Cumulative Timesteps: 1,942,827,598

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54,802.61361
Policy Entropy: 2.14828
Value Function Loss: 0.02429

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.08580
Policy Update Magnitude: 0.31736
Value Function Update Magnitude: 0.32965

Collected Steps per Second: 21,152.99965
Overall Steps per Second: 10,516.93514

Timestep Collection Time: 2.36401
Timestep Consumption Time: 2.39079
PPO Batch Consumption Time: 0.28583
Total Iteration Time: 4.75481

Cumulative Model Updates: 232,880
Cumulative Timesteps: 1,942,877,604

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1942877604...
Checkpoint 1942877604 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 61,226.79144
Policy Entropy: 2.15085
Value Function Loss: 0.02396

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.07765
Policy Update Magnitude: 0.32173
Value Function Update Magnitude: 0.34540

Collected Steps per Second: 20,936.80725
Overall Steps per Second: 10,405.10183

Timestep Collection Time: 2.38957
Timestep Consumption Time: 2.41865
PPO Batch Consumption Time: 0.28978
Total Iteration Time: 4.80822

Cumulative Model Updates: 232,886
Cumulative Timesteps: 1,942,927,634

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48,720.65816
Policy Entropy: 2.15647
Value Function Loss: 0.02287

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.07508
Policy Update Magnitude: 0.31657
Value Function Update Magnitude: 0.34466

Collected Steps per Second: 21,681.91522
Overall Steps per Second: 10,625.45453

Timestep Collection Time: 2.30727
Timestep Consumption Time: 2.40086
PPO Batch Consumption Time: 0.27942
Total Iteration Time: 4.70813

Cumulative Model Updates: 232,892
Cumulative Timesteps: 1,942,977,660

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1942977660...
Checkpoint 1942977660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,701.84136
Policy Entropy: 2.16161
Value Function Loss: 0.02415

Mean KL Divergence: 0.00763
SB3 Clip Fraction: 0.07304
Policy Update Magnitude: 0.31404
Value Function Update Magnitude: 0.32543

Collected Steps per Second: 21,243.08314
Overall Steps per Second: 10,319.96983

Timestep Collection Time: 2.35408
Timestep Consumption Time: 2.49167
PPO Batch Consumption Time: 0.29321
Total Iteration Time: 4.84575

Cumulative Model Updates: 232,898
Cumulative Timesteps: 1,943,027,668

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,219.19644
Policy Entropy: 2.17086
Value Function Loss: 0.02276

Mean KL Divergence: 0.00741
SB3 Clip Fraction: 0.07033
Policy Update Magnitude: 0.31305
Value Function Update Magnitude: 0.30455

Collected Steps per Second: 22,016.37593
Overall Steps per Second: 10,543.20078

Timestep Collection Time: 2.27213
Timestep Consumption Time: 2.47254
PPO Batch Consumption Time: 0.29205
Total Iteration Time: 4.74467

Cumulative Model Updates: 232,904
Cumulative Timesteps: 1,943,077,692

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1943077692...
Checkpoint 1943077692 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47,057.10893
Policy Entropy: 2.17082
Value Function Loss: 0.02411

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.07274
Policy Update Magnitude: 0.31189
Value Function Update Magnitude: 0.30936

Collected Steps per Second: 21,831.40684
Overall Steps per Second: 10,516.97004

Timestep Collection Time: 2.29092
Timestep Consumption Time: 2.46463
PPO Batch Consumption Time: 0.29059
Total Iteration Time: 4.75555

Cumulative Model Updates: 232,910
Cumulative Timesteps: 1,943,127,706

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48,894.94686
Policy Entropy: 2.16490
Value Function Loss: 0.02236

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.07260
Policy Update Magnitude: 0.31075
Value Function Update Magnitude: 0.29085

Collected Steps per Second: 22,368.51730
Overall Steps per Second: 10,537.91126

Timestep Collection Time: 2.23528
Timestep Consumption Time: 2.50949
PPO Batch Consumption Time: 0.29278
Total Iteration Time: 4.74477

Cumulative Model Updates: 232,916
Cumulative Timesteps: 1,943,177,706

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1943177706...
Checkpoint 1943177706 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,463.79576
Policy Entropy: 2.16964
Value Function Loss: 0.02333

Mean KL Divergence: 0.00725
SB3 Clip Fraction: 0.06772
Policy Update Magnitude: 0.31808
Value Function Update Magnitude: 0.25027

Collected Steps per Second: 21,805.46704
Overall Steps per Second: 10,523.36546

Timestep Collection Time: 2.29420
Timestep Consumption Time: 2.45961
PPO Batch Consumption Time: 0.28926
Total Iteration Time: 4.75380

Cumulative Model Updates: 232,922
Cumulative Timesteps: 1,943,227,732

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,418.57310
Policy Entropy: 2.16252
Value Function Loss: 0.02534

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.08391
Policy Update Magnitude: 0.31508
Value Function Update Magnitude: 0.27559

Collected Steps per Second: 22,372.58388
Overall Steps per Second: 10,532.51600

Timestep Collection Time: 2.23488
Timestep Consumption Time: 2.51233
PPO Batch Consumption Time: 0.29351
Total Iteration Time: 4.74720

Cumulative Model Updates: 232,928
Cumulative Timesteps: 1,943,277,732

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1943277732...
Checkpoint 1943277732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,537.84646
Policy Entropy: 2.15697
Value Function Loss: 0.02420

Mean KL Divergence: 0.01387
SB3 Clip Fraction: 0.10667
Policy Update Magnitude: 0.29981
Value Function Update Magnitude: 0.32537

Collected Steps per Second: 21,478.93344
Overall Steps per Second: 10,508.75420

Timestep Collection Time: 2.32833
Timestep Consumption Time: 2.43056
PPO Batch Consumption Time: 0.27896
Total Iteration Time: 4.75889

Cumulative Model Updates: 232,934
Cumulative Timesteps: 1,943,327,742

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52,856.81460
Policy Entropy: 2.15107
Value Function Loss: 0.02429

Mean KL Divergence: 0.01549
SB3 Clip Fraction: 0.11051
Policy Update Magnitude: 0.30135
Value Function Update Magnitude: 0.31143

Collected Steps per Second: 21,750.89674
Overall Steps per Second: 10,481.43930

Timestep Collection Time: 2.29931
Timestep Consumption Time: 2.47217
PPO Batch Consumption Time: 0.28536
Total Iteration Time: 4.77148

Cumulative Model Updates: 232,940
Cumulative Timesteps: 1,943,377,754

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1943377754...
Checkpoint 1943377754 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,886.53273
Policy Entropy: 2.14726
Value Function Loss: 0.02356

Mean KL Divergence: 0.01270
SB3 Clip Fraction: 0.09891
Policy Update Magnitude: 0.31098
Value Function Update Magnitude: 0.28673

Collected Steps per Second: 21,156.53108
Overall Steps per Second: 10,248.86478

Timestep Collection Time: 2.36334
Timestep Consumption Time: 2.51525
PPO Batch Consumption Time: 0.29418
Total Iteration Time: 4.87859

Cumulative Model Updates: 232,946
Cumulative Timesteps: 1,943,427,754

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,959.41453
Policy Entropy: 2.14421
Value Function Loss: 0.02354

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.08722
Policy Update Magnitude: 0.31047
Value Function Update Magnitude: 0.33007

Collected Steps per Second: 21,517.19261
Overall Steps per Second: 10,512.73585

Timestep Collection Time: 2.32502
Timestep Consumption Time: 2.43377
PPO Batch Consumption Time: 0.27814
Total Iteration Time: 4.75880

Cumulative Model Updates: 232,952
Cumulative Timesteps: 1,943,477,782

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1943477782...
Checkpoint 1943477782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 51,162.60525
Policy Entropy: 2.13462
Value Function Loss: 0.02239

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.07847
Policy Update Magnitude: 0.31287
Value Function Update Magnitude: 0.33836

Collected Steps per Second: 21,560.88627
Overall Steps per Second: 10,498.47591

Timestep Collection Time: 2.32003
Timestep Consumption Time: 2.44466
PPO Batch Consumption Time: 0.27945
Total Iteration Time: 4.76469

Cumulative Model Updates: 232,958
Cumulative Timesteps: 1,943,527,804

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48,061.33217
Policy Entropy: 2.13117
Value Function Loss: 0.02266

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.08376
Policy Update Magnitude: 0.31672
Value Function Update Magnitude: 0.34639

Collected Steps per Second: 22,001.59635
Overall Steps per Second: 10,537.33854

Timestep Collection Time: 2.27356
Timestep Consumption Time: 2.47356
PPO Batch Consumption Time: 0.27856
Total Iteration Time: 4.74712

Cumulative Model Updates: 232,964
Cumulative Timesteps: 1,943,577,826

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1943577826...
Checkpoint 1943577826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,937.39736
Policy Entropy: 2.14186
Value Function Loss: 0.02606

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.08281
Policy Update Magnitude: 0.32217
Value Function Update Magnitude: 0.40044

Collected Steps per Second: 21,827.61525
Overall Steps per Second: 10,554.16342

Timestep Collection Time: 2.29150
Timestep Consumption Time: 2.44767
PPO Batch Consumption Time: 0.27980
Total Iteration Time: 4.73917

Cumulative Model Updates: 232,970
Cumulative Timesteps: 1,943,627,844

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,977.65245
Policy Entropy: 2.13669
Value Function Loss: 0.02297

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.07554
Policy Update Magnitude: 0.31935
Value Function Update Magnitude: 0.36435

Collected Steps per Second: 21,977.64151
Overall Steps per Second: 10,517.58194

Timestep Collection Time: 2.27595
Timestep Consumption Time: 2.47990
PPO Batch Consumption Time: 0.28594
Total Iteration Time: 4.75585

Cumulative Model Updates: 232,976
Cumulative Timesteps: 1,943,677,864

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1943677864...
Checkpoint 1943677864 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 52,571.58335
Policy Entropy: 2.13020
Value Function Loss: 0.02217

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.07401
Policy Update Magnitude: 0.31305
Value Function Update Magnitude: 0.29971

Collected Steps per Second: 20,942.85719
Overall Steps per Second: 10,259.93707

Timestep Collection Time: 2.38907
Timestep Consumption Time: 2.48757
PPO Batch Consumption Time: 0.27844
Total Iteration Time: 4.87664

Cumulative Model Updates: 232,982
Cumulative Timesteps: 1,943,727,898

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45,126.88121
Policy Entropy: 2.11970
Value Function Loss: 0.02055

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.07320
Policy Update Magnitude: 0.31004
Value Function Update Magnitude: 0.29115

Collected Steps per Second: 22,178.94988
Overall Steps per Second: 10,524.50734

Timestep Collection Time: 2.25466
Timestep Consumption Time: 2.49673
PPO Batch Consumption Time: 0.29116
Total Iteration Time: 4.75139

Cumulative Model Updates: 232,988
Cumulative Timesteps: 1,943,777,904

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1943777904...
Checkpoint 1943777904 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,553.22486
Policy Entropy: 2.12049
Value Function Loss: 0.02233

Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.07933
Policy Update Magnitude: 0.32008
Value Function Update Magnitude: 0.30486

Collected Steps per Second: 21,930.12461
Overall Steps per Second: 10,475.10030

Timestep Collection Time: 2.28033
Timestep Consumption Time: 2.49365
PPO Batch Consumption Time: 0.29052
Total Iteration Time: 4.77399

Cumulative Model Updates: 232,994
Cumulative Timesteps: 1,943,827,912

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55,216.45231
Policy Entropy: 2.12897
Value Function Loss: 0.02274

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.07715
Policy Update Magnitude: 0.32009
Value Function Update Magnitude: 0.31373

Collected Steps per Second: 21,442.72831
Overall Steps per Second: 10,487.70314

Timestep Collection Time: 2.33319
Timestep Consumption Time: 2.43716
PPO Batch Consumption Time: 0.29138
Total Iteration Time: 4.77035

Cumulative Model Updates: 233,000
Cumulative Timesteps: 1,943,877,942

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1943877942...
Checkpoint 1943877942 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,826.77269
Policy Entropy: 2.14015
Value Function Loss: 0.02145

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.07513
Policy Update Magnitude: 0.31133
Value Function Update Magnitude: 0.28876

Collected Steps per Second: 20,801.72504
Overall Steps per Second: 10,395.81584

Timestep Collection Time: 2.40384
Timestep Consumption Time: 2.40617
PPO Batch Consumption Time: 0.29016
Total Iteration Time: 4.81001

Cumulative Model Updates: 233,006
Cumulative Timesteps: 1,943,927,946

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52,455.12700
Policy Entropy: 2.14038
Value Function Loss: 0.02521

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.07218
Policy Update Magnitude: 0.31201
Value Function Update Magnitude: 0.24125

Collected Steps per Second: 21,142.74320
Overall Steps per Second: 10,601.59875

Timestep Collection Time: 2.36507
Timestep Consumption Time: 2.35158
PPO Batch Consumption Time: 0.27896
Total Iteration Time: 4.71665

Cumulative Model Updates: 233,012
Cumulative Timesteps: 1,943,977,950

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1943977950...
Checkpoint 1943977950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 56,376.61151
Policy Entropy: 2.14401
Value Function Loss: 0.02352

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.07626
Policy Update Magnitude: 0.31524
Value Function Update Magnitude: 0.22969

Collected Steps per Second: 20,697.76731
Overall Steps per Second: 10,261.47422

Timestep Collection Time: 2.41775
Timestep Consumption Time: 2.45894
PPO Batch Consumption Time: 0.28655
Total Iteration Time: 4.87669

Cumulative Model Updates: 233,018
Cumulative Timesteps: 1,944,027,992

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57,050.36710
Policy Entropy: 2.16196
Value Function Loss: 0.02268

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.07113
Policy Update Magnitude: 0.31392
Value Function Update Magnitude: 0.28229

Collected Steps per Second: 21,718.05973
Overall Steps per Second: 10,463.03534

Timestep Collection Time: 2.30260
Timestep Consumption Time: 2.47689
PPO Batch Consumption Time: 0.28694
Total Iteration Time: 4.77949

Cumulative Model Updates: 233,024
Cumulative Timesteps: 1,944,078,000

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1944078000...
Checkpoint 1944078000 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 92,224.50258
Policy Entropy: 2.16539
Value Function Loss: 0.02116

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.06633
Policy Update Magnitude: 0.31973
Value Function Update Magnitude: 0.30449

Collected Steps per Second: 21,484.25682
Overall Steps per Second: 10,586.67623

Timestep Collection Time: 2.32868
Timestep Consumption Time: 2.39707
PPO Batch Consumption Time: 0.27776
Total Iteration Time: 4.72575

Cumulative Model Updates: 233,030
Cumulative Timesteps: 1,944,128,030

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47,943.76451
Policy Entropy: 2.14584
Value Function Loss: 0.02512

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.06979
Policy Update Magnitude: 0.32946
Value Function Update Magnitude: 0.33457

Collected Steps per Second: 22,121.57891
Overall Steps per Second: 10,519.90059

Timestep Collection Time: 2.26123
Timestep Consumption Time: 2.49376
PPO Batch Consumption Time: 0.28424
Total Iteration Time: 4.75499

Cumulative Model Updates: 233,036
Cumulative Timesteps: 1,944,178,052

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1944178052...
Checkpoint 1944178052 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,447.64027
Policy Entropy: 2.12587
Value Function Loss: 0.02765

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.08285
Policy Update Magnitude: 0.34143
Value Function Update Magnitude: 0.36634

Collected Steps per Second: 21,745.60546
Overall Steps per Second: 10,606.71680

Timestep Collection Time: 2.30014
Timestep Consumption Time: 2.41555
PPO Batch Consumption Time: 0.27853
Total Iteration Time: 4.71569

Cumulative Model Updates: 233,042
Cumulative Timesteps: 1,944,228,070

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,425.76477
Policy Entropy: 2.11121
Value Function Loss: 0.03005

Mean KL Divergence: 0.01083
SB3 Clip Fraction: 0.09639
Policy Update Magnitude: 0.34684
Value Function Update Magnitude: 0.39017

Collected Steps per Second: 21,946.64552
Overall Steps per Second: 10,470.42125

Timestep Collection Time: 2.27916
Timestep Consumption Time: 2.49810
PPO Batch Consumption Time: 0.28824
Total Iteration Time: 4.77727

Cumulative Model Updates: 233,048
Cumulative Timesteps: 1,944,278,090

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1944278090...
Checkpoint 1944278090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,029.24542
Policy Entropy: 2.13843
Value Function Loss: 0.02933

Mean KL Divergence: 0.01092
SB3 Clip Fraction: 0.09627
Policy Update Magnitude: 0.33401
Value Function Update Magnitude: 0.41530

Collected Steps per Second: 22,040.24259
Overall Steps per Second: 10,633.44960

Timestep Collection Time: 2.26885
Timestep Consumption Time: 2.43386
PPO Batch Consumption Time: 0.27965
Total Iteration Time: 4.70271

Cumulative Model Updates: 233,054
Cumulative Timesteps: 1,944,328,096

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54,307.61543
Policy Entropy: 2.13012
Value Function Loss: 0.02706

Mean KL Divergence: 0.01059
SB3 Clip Fraction: 0.09478
Policy Update Magnitude: 0.33240
Value Function Update Magnitude: 0.40787

Collected Steps per Second: 22,221.84720
Overall Steps per Second: 10,461.98646

Timestep Collection Time: 2.25175
Timestep Consumption Time: 2.53109
PPO Batch Consumption Time: 0.29469
Total Iteration Time: 4.78284

Cumulative Model Updates: 233,060
Cumulative Timesteps: 1,944,378,134

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1944378134...
Checkpoint 1944378134 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,258.37073
Policy Entropy: 2.13284
Value Function Loss: 0.02644

Mean KL Divergence: 0.01074
SB3 Clip Fraction: 0.09698
Policy Update Magnitude: 0.32814
Value Function Update Magnitude: 0.38908

Collected Steps per Second: 22,016.23278
Overall Steps per Second: 10,617.16162

Timestep Collection Time: 2.27241
Timestep Consumption Time: 2.43977
PPO Batch Consumption Time: 0.27934
Total Iteration Time: 4.71218

Cumulative Model Updates: 233,066
Cumulative Timesteps: 1,944,428,164

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,920.77374
Policy Entropy: 2.13126
Value Function Loss: 0.02705

Mean KL Divergence: 0.01074
SB3 Clip Fraction: 0.09634
Policy Update Magnitude: 0.32845
Value Function Update Magnitude: 0.37545

Collected Steps per Second: 21,825.58726
Overall Steps per Second: 10,528.88628

Timestep Collection Time: 2.29217
Timestep Consumption Time: 2.45933
PPO Batch Consumption Time: 0.28487
Total Iteration Time: 4.75150

Cumulative Model Updates: 233,072
Cumulative Timesteps: 1,944,478,192

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1944478192...
Checkpoint 1944478192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,638.32272
Policy Entropy: 2.14500
Value Function Loss: 0.02639

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.09140
Policy Update Magnitude: 0.33169
Value Function Update Magnitude: 0.38555

Collected Steps per Second: 21,146.22087
Overall Steps per Second: 10,257.67077

Timestep Collection Time: 2.36581
Timestep Consumption Time: 2.51132
PPO Batch Consumption Time: 0.29411
Total Iteration Time: 4.87713

Cumulative Model Updates: 233,078
Cumulative Timesteps: 1,944,528,220

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42,198.12824
Policy Entropy: 2.15078
Value Function Loss: 0.02521

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.08166
Policy Update Magnitude: 0.32572
Value Function Update Magnitude: 0.37873

Collected Steps per Second: 21,389.30449
Overall Steps per Second: 10,339.73626

Timestep Collection Time: 2.33930
Timestep Consumption Time: 2.49990
PPO Batch Consumption Time: 0.28815
Total Iteration Time: 4.83920

Cumulative Model Updates: 233,084
Cumulative Timesteps: 1,944,578,256

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1944578256...
Checkpoint 1944578256 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43,076.00362
Policy Entropy: 2.14781
Value Function Loss: 0.02392

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.07740
Policy Update Magnitude: 0.31968
Value Function Update Magnitude: 0.36972

Collected Steps per Second: 21,553.80834
Overall Steps per Second: 10,377.22034

Timestep Collection Time: 2.32145
Timestep Consumption Time: 2.50027
PPO Batch Consumption Time: 0.29231
Total Iteration Time: 4.82172

Cumulative Model Updates: 233,090
Cumulative Timesteps: 1,944,628,292

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,454.86425
Policy Entropy: 2.15271
Value Function Loss: 0.02359

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.07750
Policy Update Magnitude: 0.31762
Value Function Update Magnitude: 0.36845

Collected Steps per Second: 22,083.60227
Overall Steps per Second: 10,411.23699

Timestep Collection Time: 2.26430
Timestep Consumption Time: 2.53858
PPO Batch Consumption Time: 0.29314
Total Iteration Time: 4.80289

Cumulative Model Updates: 233,096
Cumulative Timesteps: 1,944,678,296

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1944678296...
Checkpoint 1944678296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,697.66592
Policy Entropy: 2.13542
Value Function Loss: 0.02120

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.07964
Policy Update Magnitude: 0.31168
Value Function Update Magnitude: 0.34137

Collected Steps per Second: 22,160.14098
Overall Steps per Second: 10,514.42520

Timestep Collection Time: 2.25694
Timestep Consumption Time: 2.49977
PPO Batch Consumption Time: 0.28935
Total Iteration Time: 4.75670

Cumulative Model Updates: 233,102
Cumulative Timesteps: 1,944,728,310

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,332.92142
Policy Entropy: 2.16689
Value Function Loss: 0.02132

Mean KL Divergence: 0.00747
SB3 Clip Fraction: 0.07113
Policy Update Magnitude: 0.30560
Value Function Update Magnitude: 0.31671

Collected Steps per Second: 22,070.27919
Overall Steps per Second: 10,466.25113

Timestep Collection Time: 2.26667
Timestep Consumption Time: 2.51308
PPO Batch Consumption Time: 0.29181
Total Iteration Time: 4.77974

Cumulative Model Updates: 233,108
Cumulative Timesteps: 1,944,778,336

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1944778336...
Checkpoint 1944778336 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,248.41036
Policy Entropy: 2.15405
Value Function Loss: 0.02104

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.07311
Policy Update Magnitude: 0.30649
Value Function Update Magnitude: 0.31989

Collected Steps per Second: 22,040.60324
Overall Steps per Second: 10,590.96716

Timestep Collection Time: 2.26908
Timestep Consumption Time: 2.45305
PPO Batch Consumption Time: 0.27976
Total Iteration Time: 4.72214

Cumulative Model Updates: 233,114
Cumulative Timesteps: 1,944,828,348

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,624.78421
Policy Entropy: 2.16702
Value Function Loss: 0.02275

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.07585
Policy Update Magnitude: 0.31260
Value Function Update Magnitude: 0.32388

Collected Steps per Second: 21,918.04732
Overall Steps per Second: 10,495.23174

Timestep Collection Time: 2.28250
Timestep Consumption Time: 2.48423
PPO Batch Consumption Time: 0.28626
Total Iteration Time: 4.76674

Cumulative Model Updates: 233,120
Cumulative Timesteps: 1,944,878,376

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1944878376...
Checkpoint 1944878376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46,073.69830
Policy Entropy: 2.14657
Value Function Loss: 0.02374

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.07624
Policy Update Magnitude: 0.31968
Value Function Update Magnitude: 0.34204

Collected Steps per Second: 21,914.37849
Overall Steps per Second: 10,611.90248

Timestep Collection Time: 2.28270
Timestep Consumption Time: 2.43125
PPO Batch Consumption Time: 0.27927
Total Iteration Time: 4.71395

Cumulative Model Updates: 233,126
Cumulative Timesteps: 1,944,928,400

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,284.90501
Policy Entropy: 2.15713
Value Function Loss: 0.02368

Mean KL Divergence: 0.00782
SB3 Clip Fraction: 0.07299
Policy Update Magnitude: 0.31886
Value Function Update Magnitude: 0.35572

Collected Steps per Second: 21,901.50113
Overall Steps per Second: 10,576.71607

Timestep Collection Time: 2.28377
Timestep Consumption Time: 2.44530
PPO Batch Consumption Time: 0.27751
Total Iteration Time: 4.72907

Cumulative Model Updates: 233,132
Cumulative Timesteps: 1,944,978,418

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1944978418...
Checkpoint 1944978418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,217.32375
Policy Entropy: 2.15225
Value Function Loss: 0.02343

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.07552
Policy Update Magnitude: 0.31951
Value Function Update Magnitude: 0.35869

Collected Steps per Second: 21,335.05181
Overall Steps per Second: 10,461.60925

Timestep Collection Time: 2.34440
Timestep Consumption Time: 2.43670
PPO Batch Consumption Time: 0.27961
Total Iteration Time: 4.78110

Cumulative Model Updates: 233,138
Cumulative Timesteps: 1,945,028,436

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48,504.63422
Policy Entropy: 2.15350
Value Function Loss: 0.02122

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.07530
Policy Update Magnitude: 0.31337
Value Function Update Magnitude: 0.33718

Collected Steps per Second: 21,583.35268
Overall Steps per Second: 10,532.54377

Timestep Collection Time: 2.31799
Timestep Consumption Time: 2.43205
PPO Batch Consumption Time: 0.27849
Total Iteration Time: 4.75004

Cumulative Model Updates: 233,144
Cumulative Timesteps: 1,945,078,466

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1945078466...
Checkpoint 1945078466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,785.90420
Policy Entropy: 2.15471
Value Function Loss: 0.02369

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.08104
Policy Update Magnitude: 0.31386
Value Function Update Magnitude: 0.33533

Collected Steps per Second: 21,190.92202
Overall Steps per Second: 10,254.22199

Timestep Collection Time: 2.36101
Timestep Consumption Time: 2.51815
PPO Batch Consumption Time: 0.29387
Total Iteration Time: 4.87916

Cumulative Model Updates: 233,150
Cumulative Timesteps: 1,945,128,498

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,778.30631
Policy Entropy: 2.14985
Value Function Loss: 0.02001

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.07780
Policy Update Magnitude: 0.31274
Value Function Update Magnitude: 0.34829

Collected Steps per Second: 21,694.04707
Overall Steps per Second: 10,401.12263

Timestep Collection Time: 2.30616
Timestep Consumption Time: 2.50390
PPO Batch Consumption Time: 0.28987
Total Iteration Time: 4.81006

Cumulative Model Updates: 233,156
Cumulative Timesteps: 1,945,178,528

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1945178528...
Checkpoint 1945178528 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,823.68926
Policy Entropy: 2.14590
Value Function Loss: 0.02271

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.08397
Policy Update Magnitude: 0.30805
Value Function Update Magnitude: 0.30510

Collected Steps per Second: 21,309.11405
Overall Steps per Second: 10,243.17611

Timestep Collection Time: 2.34735
Timestep Consumption Time: 2.53590
PPO Batch Consumption Time: 0.29417
Total Iteration Time: 4.88325

Cumulative Model Updates: 233,162
Cumulative Timesteps: 1,945,228,548

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55,724.94374
Policy Entropy: 2.14411
Value Function Loss: 0.02106

Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.07556
Policy Update Magnitude: 0.30965
Value Function Update Magnitude: 0.30747

Collected Steps per Second: 22,080.14738
Overall Steps per Second: 10,453.69129

Timestep Collection Time: 2.26638
Timestep Consumption Time: 2.52064
PPO Batch Consumption Time: 0.28697
Total Iteration Time: 4.78702

Cumulative Model Updates: 233,168
Cumulative Timesteps: 1,945,278,590

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1945278590...
Checkpoint 1945278590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 58,862.58136
Policy Entropy: 2.14898
Value Function Loss: 0.02280

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.07292
Policy Update Magnitude: 0.30501
Value Function Update Magnitude: 0.29879

Collected Steps per Second: 21,853.75466
Overall Steps per Second: 10,574.62863

Timestep Collection Time: 2.28812
Timestep Consumption Time: 2.44056
PPO Batch Consumption Time: 0.27936
Total Iteration Time: 4.72868

Cumulative Model Updates: 233,174
Cumulative Timesteps: 1,945,328,594

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46,083.17911
Policy Entropy: 2.15920
Value Function Loss: 0.02211

Mean KL Divergence: 0.00699
SB3 Clip Fraction: 0.06919
Policy Update Magnitude: 0.30044
Value Function Update Magnitude: 0.27262

Collected Steps per Second: 21,618.90856
Overall Steps per Second: 10,532.88377

Timestep Collection Time: 2.31353
Timestep Consumption Time: 2.43503
PPO Batch Consumption Time: 0.29324
Total Iteration Time: 4.74856

Cumulative Model Updates: 233,180
Cumulative Timesteps: 1,945,378,610

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1945378610...
Checkpoint 1945378610 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,383.74707
Policy Entropy: 2.15247
Value Function Loss: 0.02192

Mean KL Divergence: 0.00695
SB3 Clip Fraction: 0.06859
Policy Update Magnitude: 0.29952
Value Function Update Magnitude: 0.29090

Collected Steps per Second: 21,038.24461
Overall Steps per Second: 10,539.86123

Timestep Collection Time: 2.37700
Timestep Consumption Time: 2.36765
PPO Batch Consumption Time: 0.28047
Total Iteration Time: 4.74465

Cumulative Model Updates: 233,186
Cumulative Timesteps: 1,945,428,618

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,429.50613
Policy Entropy: 2.14254
Value Function Loss: 0.02249

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.07570
Policy Update Magnitude: 0.29874
Value Function Update Magnitude: 0.30929

Collected Steps per Second: 21,231.90199
Overall Steps per Second: 10,501.22038

Timestep Collection Time: 2.35570
Timestep Consumption Time: 2.40717
PPO Batch Consumption Time: 0.28746
Total Iteration Time: 4.76288

Cumulative Model Updates: 233,192
Cumulative Timesteps: 1,945,478,634

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1945478634...
Checkpoint 1945478634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,913.32528
Policy Entropy: 2.12208
Value Function Loss: 0.02117

Mean KL Divergence: 0.00753
SB3 Clip Fraction: 0.07043
Policy Update Magnitude: 0.30252
Value Function Update Magnitude: 0.31776

Collected Steps per Second: 21,189.62580
Overall Steps per Second: 10,328.78158

Timestep Collection Time: 2.36068
Timestep Consumption Time: 2.48229
PPO Batch Consumption Time: 0.29268
Total Iteration Time: 4.84297

Cumulative Model Updates: 233,198
Cumulative Timesteps: 1,945,528,656

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,019.39789
Policy Entropy: 2.13274
Value Function Loss: 0.02406

Mean KL Divergence: 0.00717
SB3 Clip Fraction: 0.06796
Policy Update Magnitude: 0.31172
Value Function Update Magnitude: 0.29953

Collected Steps per Second: 22,284.96817
Overall Steps per Second: 10,748.13475

Timestep Collection Time: 2.24393
Timestep Consumption Time: 2.40859
PPO Batch Consumption Time: 0.27996
Total Iteration Time: 4.65253

Cumulative Model Updates: 233,204
Cumulative Timesteps: 1,945,578,662

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1945578662...
Checkpoint 1945578662 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 57,698.60667
Policy Entropy: 2.14913
Value Function Loss: 0.02489

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.07702
Policy Update Magnitude: 0.31781
Value Function Update Magnitude: 0.31917

Collected Steps per Second: 20,375.23869
Overall Steps per Second: 10,266.24383

Timestep Collection Time: 2.45651
Timestep Consumption Time: 2.41888
PPO Batch Consumption Time: 0.27835
Total Iteration Time: 4.87540

Cumulative Model Updates: 233,210
Cumulative Timesteps: 1,945,628,714

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48,794.12032
Policy Entropy: 2.16095
Value Function Loss: 0.02372

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.07086
Policy Update Magnitude: 0.31167
Value Function Update Magnitude: 0.34410

Collected Steps per Second: 21,728.64442
Overall Steps per Second: 10,412.02844

Timestep Collection Time: 2.30203
Timestep Consumption Time: 2.50203
PPO Batch Consumption Time: 0.29050
Total Iteration Time: 4.80406

Cumulative Model Updates: 233,216
Cumulative Timesteps: 1,945,678,734

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1945678734...
Checkpoint 1945678734 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,409.20962
Policy Entropy: 2.16309
Value Function Loss: 0.02121

Mean KL Divergence: 0.00736
SB3 Clip Fraction: 0.06815
Policy Update Magnitude: 0.29970
Value Function Update Magnitude: 0.32778

Collected Steps per Second: 21,349.38532
Overall Steps per Second: 10,303.94516

Timestep Collection Time: 2.34246
Timestep Consumption Time: 2.51102
PPO Batch Consumption Time: 0.29336
Total Iteration Time: 4.85348

Cumulative Model Updates: 233,222
Cumulative Timesteps: 1,945,728,744

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76,006.02960
Policy Entropy: 2.14645
Value Function Loss: 0.02190

Mean KL Divergence: 0.00721
SB3 Clip Fraction: 0.07008
Policy Update Magnitude: 0.29867
Value Function Update Magnitude: 0.29254

Collected Steps per Second: 21,703.20421
Overall Steps per Second: 10,442.23639

Timestep Collection Time: 2.30436
Timestep Consumption Time: 2.48504
PPO Batch Consumption Time: 0.29280
Total Iteration Time: 4.78940

Cumulative Model Updates: 233,228
Cumulative Timesteps: 1,945,778,756

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1945778756...
Checkpoint 1945778756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 56,348.18914
Policy Entropy: 2.15882
Value Function Loss: 0.02542

Mean KL Divergence: 0.00744
SB3 Clip Fraction: 0.07386
Policy Update Magnitude: 0.31041
Value Function Update Magnitude: 0.30207

Collected Steps per Second: 21,739.70881
Overall Steps per Second: 10,463.50735

Timestep Collection Time: 2.30031
Timestep Consumption Time: 2.47897
PPO Batch Consumption Time: 0.27853
Total Iteration Time: 4.77928

Cumulative Model Updates: 233,234
Cumulative Timesteps: 1,945,828,764

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,687.12946
Policy Entropy: 2.16885
Value Function Loss: 0.02494

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.07369
Policy Update Magnitude: 0.30937
Value Function Update Magnitude: 0.30434

Collected Steps per Second: 22,087.46498
Overall Steps per Second: 10,477.14109

Timestep Collection Time: 2.26518
Timestep Consumption Time: 2.51017
PPO Batch Consumption Time: 0.28960
Total Iteration Time: 4.77535

Cumulative Model Updates: 233,240
Cumulative Timesteps: 1,945,878,796

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1945878796...
Checkpoint 1945878796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,063.93762
Policy Entropy: 2.18165
Value Function Loss: 0.02292

Mean KL Divergence: 0.00709
SB3 Clip Fraction: 0.06549
Policy Update Magnitude: 0.30210
Value Function Update Magnitude: 0.30292

Collected Steps per Second: 21,774.73494
Overall Steps per Second: 10,417.76222

Timestep Collection Time: 2.29679
Timestep Consumption Time: 2.50386
PPO Batch Consumption Time: 0.29212
Total Iteration Time: 4.80065

Cumulative Model Updates: 233,246
Cumulative Timesteps: 1,945,928,808

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,815.44422
Policy Entropy: 2.17953
Value Function Loss: 0.02415

Mean KL Divergence: 0.00678
SB3 Clip Fraction: 0.06551
Policy Update Magnitude: 0.30456
Value Function Update Magnitude: 0.30735

Collected Steps per Second: 22,117.06276
Overall Steps per Second: 10,648.31869

Timestep Collection Time: 2.26160
Timestep Consumption Time: 2.43585
PPO Batch Consumption Time: 0.27957
Total Iteration Time: 4.69746

Cumulative Model Updates: 233,252
Cumulative Timesteps: 1,945,978,828

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1945978828...
Checkpoint 1945978828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46,090.18381
Policy Entropy: 2.18227
Value Function Loss: 0.02442

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.07944
Policy Update Magnitude: 0.31359
Value Function Update Magnitude: 0.34144

Collected Steps per Second: 21,918.41617
Overall Steps per Second: 10,464.70640

Timestep Collection Time: 2.28210
Timestep Consumption Time: 2.49778
PPO Batch Consumption Time: 0.29129
Total Iteration Time: 4.77988

Cumulative Model Updates: 233,258
Cumulative Timesteps: 1,946,028,848

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51,575.12820
Policy Entropy: 2.16369
Value Function Loss: 0.02455

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.08273
Policy Update Magnitude: 0.31891
Value Function Update Magnitude: 0.36060

Collected Steps per Second: 21,977.36604
Overall Steps per Second: 10,491.76959

Timestep Collection Time: 2.27507
Timestep Consumption Time: 2.49057
PPO Batch Consumption Time: 0.28983
Total Iteration Time: 4.76564

Cumulative Model Updates: 233,264
Cumulative Timesteps: 1,946,078,848

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1946078848...
Checkpoint 1946078848 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 53,120.11345
Policy Entropy: 2.13848
Value Function Loss: 0.02226

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.08091
Policy Update Magnitude: 0.31406
Value Function Update Magnitude: 0.35345

Collected Steps per Second: 22,059.10932
Overall Steps per Second: 10,464.58093

Timestep Collection Time: 2.26664
Timestep Consumption Time: 2.51138
PPO Batch Consumption Time: 0.29316
Total Iteration Time: 4.77802

Cumulative Model Updates: 233,270
Cumulative Timesteps: 1,946,128,848

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,304.57580
Policy Entropy: 2.12277
Value Function Loss: 0.02299

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.07549
Policy Update Magnitude: 0.31918
Value Function Update Magnitude: 0.34020

Collected Steps per Second: 21,835.29182
Overall Steps per Second: 10,407.31534

Timestep Collection Time: 2.29042
Timestep Consumption Time: 2.51505
PPO Batch Consumption Time: 0.29254
Total Iteration Time: 4.80547

Cumulative Model Updates: 233,276
Cumulative Timesteps: 1,946,178,860

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1946178860...
Checkpoint 1946178860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55,943.76897
Policy Entropy: 2.14334
Value Function Loss: 0.02220

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.07697
Policy Update Magnitude: 0.32001
Value Function Update Magnitude: 0.32992

Collected Steps per Second: 21,396.73975
Overall Steps per Second: 10,298.42794

Timestep Collection Time: 2.33783
Timestep Consumption Time: 2.51941
PPO Batch Consumption Time: 0.29403
Total Iteration Time: 4.85725

Cumulative Model Updates: 233,282
Cumulative Timesteps: 1,946,228,882

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,006.95646
Policy Entropy: 2.16033
Value Function Loss: 0.02085

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.07481
Policy Update Magnitude: 0.30515
Value Function Update Magnitude: 0.28187

Collected Steps per Second: 21,814.40964
Overall Steps per Second: 10,402.64655

Timestep Collection Time: 2.29335
Timestep Consumption Time: 2.51581
PPO Batch Consumption Time: 0.29388
Total Iteration Time: 4.80916

Cumulative Model Updates: 233,288
Cumulative Timesteps: 1,946,278,910

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1946278910...
Checkpoint 1946278910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,282.41900
Policy Entropy: 2.15817
Value Function Loss: 0.02090

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.07623
Policy Update Magnitude: 0.30087
Value Function Update Magnitude: 0.25509

Collected Steps per Second: 21,394.36091
Overall Steps per Second: 10,293.24891

Timestep Collection Time: 2.33725
Timestep Consumption Time: 2.52069
PPO Batch Consumption Time: 0.29345
Total Iteration Time: 4.85794

Cumulative Model Updates: 233,294
Cumulative Timesteps: 1,946,328,914

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,556.73644
Policy Entropy: 2.14197
Value Function Loss: 0.02235

Mean KL Divergence: 0.00772
SB3 Clip Fraction: 0.07290
Policy Update Magnitude: 0.30738
Value Function Update Magnitude: 0.28073

Collected Steps per Second: 22,201.29792
Overall Steps per Second: 10,435.89100

Timestep Collection Time: 2.25320
Timestep Consumption Time: 2.54026
PPO Batch Consumption Time: 0.29327
Total Iteration Time: 4.79346

Cumulative Model Updates: 233,300
Cumulative Timesteps: 1,946,378,938

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1946378938...
Checkpoint 1946378938 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,006.37615
Policy Entropy: 2.14114
Value Function Loss: 0.02369

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.07689
Policy Update Magnitude: 0.31841
Value Function Update Magnitude: 0.32600

Collected Steps per Second: 21,876.36150
Overall Steps per Second: 10,581.03702

Timestep Collection Time: 2.28585
Timestep Consumption Time: 2.44016
PPO Batch Consumption Time: 0.27816
Total Iteration Time: 4.72600

Cumulative Model Updates: 233,306
Cumulative Timesteps: 1,946,428,944

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,389.59602
Policy Entropy: 2.14825
Value Function Loss: 0.02414

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.07532
Policy Update Magnitude: 0.32504
Value Function Update Magnitude: 0.34359

Collected Steps per Second: 21,919.06578
Overall Steps per Second: 10,413.95979

Timestep Collection Time: 2.28231
Timestep Consumption Time: 2.52144
PPO Batch Consumption Time: 0.29309
Total Iteration Time: 4.80374

Cumulative Model Updates: 233,312
Cumulative Timesteps: 1,946,478,970

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1946478970...
Checkpoint 1946478970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,899.97317
Policy Entropy: 2.16102
Value Function Loss: 0.02464

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.07430
Policy Update Magnitude: 0.32664
Value Function Update Magnitude: 0.36950

Collected Steps per Second: 21,657.43190
Overall Steps per Second: 10,559.58204

Timestep Collection Time: 2.30905
Timestep Consumption Time: 2.42675
PPO Batch Consumption Time: 0.27909
Total Iteration Time: 4.73579

Cumulative Model Updates: 233,318
Cumulative Timesteps: 1,946,528,978

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42,750.21691
Policy Entropy: 2.16145
Value Function Loss: 0.02387

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.07973
Policy Update Magnitude: 0.32568
Value Function Update Magnitude: 0.39522

Collected Steps per Second: 22,032.50521
Overall Steps per Second: 10,508.08904

Timestep Collection Time: 2.27065
Timestep Consumption Time: 2.49026
PPO Batch Consumption Time: 0.28623
Total Iteration Time: 4.76090

Cumulative Model Updates: 233,324
Cumulative Timesteps: 1,946,579,006

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1946579006...
Checkpoint 1946579006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,531.11437
Policy Entropy: 2.15158
Value Function Loss: 0.02289

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.08030
Policy Update Magnitude: 0.31685
Value Function Update Magnitude: 0.38638

Collected Steps per Second: 21,750.99276
Overall Steps per Second: 10,576.59849

Timestep Collection Time: 2.29884
Timestep Consumption Time: 2.42877
PPO Batch Consumption Time: 0.27938
Total Iteration Time: 4.72761

Cumulative Model Updates: 233,330
Cumulative Timesteps: 1,946,629,008

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,225.07900
Policy Entropy: 2.16245
Value Function Loss: 0.02077

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.07996
Policy Update Magnitude: 0.30655
Value Function Update Magnitude: 0.34526

Collected Steps per Second: 22,046.63548
Overall Steps per Second: 10,530.14716

Timestep Collection Time: 2.26874
Timestep Consumption Time: 2.48124
PPO Batch Consumption Time: 0.28730
Total Iteration Time: 4.74998

Cumulative Model Updates: 233,336
Cumulative Timesteps: 1,946,679,026

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1946679026...
Checkpoint 1946679026 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 56,733.51844
Policy Entropy: 2.18754
Value Function Loss: 0.02321

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.08055
Policy Update Magnitude: 0.30666
Value Function Update Magnitude: 0.31044

Collected Steps per Second: 21,187.44020
Overall Steps per Second: 10,289.87628

Timestep Collection Time: 2.36130
Timestep Consumption Time: 2.50076
PPO Batch Consumption Time: 0.29398
Total Iteration Time: 4.86206

Cumulative Model Updates: 233,342
Cumulative Timesteps: 1,946,729,056

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,530.02247
Policy Entropy: 2.18739
Value Function Loss: 0.02435

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.08842
Policy Update Magnitude: 0.31101
Value Function Update Magnitude: 0.34058

Collected Steps per Second: 21,639.03306
Overall Steps per Second: 10,374.48765

Timestep Collection Time: 2.31212
Timestep Consumption Time: 2.51048
PPO Batch Consumption Time: 0.29377
Total Iteration Time: 4.82260

Cumulative Model Updates: 233,348
Cumulative Timesteps: 1,946,779,088

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1946779088...
Checkpoint 1946779088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,336.51560
Policy Entropy: 2.17091
Value Function Loss: 0.02436

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.08445
Policy Update Magnitude: 0.31238
Value Function Update Magnitude: 0.36688

Collected Steps per Second: 20,447.86206
Overall Steps per Second: 10,235.15943

Timestep Collection Time: 2.44612
Timestep Consumption Time: 2.44076
PPO Batch Consumption Time: 0.29353
Total Iteration Time: 4.88688

Cumulative Model Updates: 233,354
Cumulative Timesteps: 1,946,829,106

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,997.18971
Policy Entropy: 2.14218
Value Function Loss: 0.02550

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.08727
Policy Update Magnitude: 0.31967
Value Function Update Magnitude: 0.36820

Collected Steps per Second: 21,008.49334
Overall Steps per Second: 10,411.16940

Timestep Collection Time: 2.38151
Timestep Consumption Time: 2.42410
PPO Batch Consumption Time: 0.29002
Total Iteration Time: 4.80561

Cumulative Model Updates: 233,360
Cumulative Timesteps: 1,946,879,138

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1946879138...
Checkpoint 1946879138 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,775.32739
Policy Entropy: 2.14454
Value Function Loss: 0.02731

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.08763
Policy Update Magnitude: 0.31811
Value Function Update Magnitude: 0.37410

Collected Steps per Second: 20,864.38650
Overall Steps per Second: 10,558.20624

Timestep Collection Time: 2.39643
Timestep Consumption Time: 2.33922
PPO Batch Consumption Time: 0.27780
Total Iteration Time: 4.73565

Cumulative Model Updates: 233,366
Cumulative Timesteps: 1,946,929,138

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,163.92660
Policy Entropy: 2.15456
Value Function Loss: 0.02740

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.09414
Policy Update Magnitude: 0.31738
Value Function Update Magnitude: 0.37956

Collected Steps per Second: 21,541.20490
Overall Steps per Second: 10,538.53823

Timestep Collection Time: 2.32169
Timestep Consumption Time: 2.42394
PPO Batch Consumption Time: 0.28536
Total Iteration Time: 4.74563

Cumulative Model Updates: 233,372
Cumulative Timesteps: 1,946,979,150

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1946979150...
Checkpoint 1946979150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,195.37125
Policy Entropy: 2.15463
Value Function Loss: 0.02341

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.08483
Policy Update Magnitude: 0.31295
Value Function Update Magnitude: 0.36881

Collected Steps per Second: 21,372.97960
Overall Steps per Second: 10,306.95741

Timestep Collection Time: 2.34062
Timestep Consumption Time: 2.51300
PPO Batch Consumption Time: 0.29264
Total Iteration Time: 4.85361

Cumulative Model Updates: 233,378
Cumulative Timesteps: 1,947,029,176

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,578.50127
Policy Entropy: 2.16237
Value Function Loss: 0.02401

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.07437
Policy Update Magnitude: 0.31403
Value Function Update Magnitude: 0.33680

Collected Steps per Second: 22,099.12633
Overall Steps per Second: 10,718.35083

Timestep Collection Time: 2.26371
Timestep Consumption Time: 2.40361
PPO Batch Consumption Time: 0.27903
Total Iteration Time: 4.66732

Cumulative Model Updates: 233,384
Cumulative Timesteps: 1,947,079,202

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1947079202...
Checkpoint 1947079202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,969.89943
Policy Entropy: 2.15836
Value Function Loss: 0.02215

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.07268
Policy Update Magnitude: 0.30958
Value Function Update Magnitude: 0.30812

Collected Steps per Second: 21,436.91092
Overall Steps per Second: 10,417.48326

Timestep Collection Time: 2.33271
Timestep Consumption Time: 2.46749
PPO Batch Consumption Time: 0.29253
Total Iteration Time: 4.80020

Cumulative Model Updates: 233,390
Cumulative Timesteps: 1,947,129,208

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,821.25020
Policy Entropy: 2.15657
Value Function Loss: 0.02031

Mean KL Divergence: 0.00745
SB3 Clip Fraction: 0.06946
Policy Update Magnitude: 0.30087
Value Function Update Magnitude: 0.30757

Collected Steps per Second: 22,380.87978
Overall Steps per Second: 10,690.44610

Timestep Collection Time: 2.23405
Timestep Consumption Time: 2.44302
PPO Batch Consumption Time: 0.27889
Total Iteration Time: 4.67707

Cumulative Model Updates: 233,396
Cumulative Timesteps: 1,947,179,208

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1947179208...
Checkpoint 1947179208 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 65,489.00470
Policy Entropy: 2.15499
Value Function Loss: 0.02018

Mean KL Divergence: 0.00696
SB3 Clip Fraction: 0.06574
Policy Update Magnitude: 0.30252
Value Function Update Magnitude: 0.31555

Collected Steps per Second: 21,934.07963
Overall Steps per Second: 10,614.90997

Timestep Collection Time: 2.28056
Timestep Consumption Time: 2.43187
PPO Batch Consumption Time: 0.27880
Total Iteration Time: 4.71243

Cumulative Model Updates: 233,402
Cumulative Timesteps: 1,947,229,230

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52,705.66318
Policy Entropy: 2.15412
Value Function Loss: 0.02024

Mean KL Divergence: 0.00721
SB3 Clip Fraction: 0.06747
Policy Update Magnitude: 0.30523
Value Function Update Magnitude: 0.33313

Collected Steps per Second: 21,936.22584
Overall Steps per Second: 10,519.81803

Timestep Collection Time: 2.28025
Timestep Consumption Time: 2.47459
PPO Batch Consumption Time: 0.28533
Total Iteration Time: 4.75484

Cumulative Model Updates: 233,408
Cumulative Timesteps: 1,947,279,250

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1947279250...
Checkpoint 1947279250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 52,376.40597
Policy Entropy: 2.16741
Value Function Loss: 0.02037

Mean KL Divergence: 0.00744
SB3 Clip Fraction: 0.07054
Policy Update Magnitude: 0.30349
Value Function Update Magnitude: 0.33867

Collected Steps per Second: 21,256.27680
Overall Steps per Second: 10,322.40293

Timestep Collection Time: 2.35385
Timestep Consumption Time: 2.49328
PPO Batch Consumption Time: 0.29264
Total Iteration Time: 4.84713

Cumulative Model Updates: 233,414
Cumulative Timesteps: 1,947,329,284

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46,724.11522
Policy Entropy: 2.16051
Value Function Loss: 0.02013

Mean KL Divergence: 0.00685
SB3 Clip Fraction: 0.06655
Policy Update Magnitude: 0.29764
Value Function Update Magnitude: 0.32981

Collected Steps per Second: 21,789.87201
Overall Steps per Second: 10,413.16859

Timestep Collection Time: 2.29556
Timestep Consumption Time: 2.50797
PPO Batch Consumption Time: 0.29333
Total Iteration Time: 4.80353

Cumulative Model Updates: 233,420
Cumulative Timesteps: 1,947,379,304

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1947379304...
Checkpoint 1947379304 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,760.52700
Policy Entropy: 2.16336
Value Function Loss: 0.02011

Mean KL Divergence: 0.00653
SB3 Clip Fraction: 0.06359
Policy Update Magnitude: 0.30135
Value Function Update Magnitude: 0.30841

Collected Steps per Second: 21,266.39222
Overall Steps per Second: 10,496.60366

Timestep Collection Time: 2.35150
Timestep Consumption Time: 2.41270
PPO Batch Consumption Time: 0.27919
Total Iteration Time: 4.76421

Cumulative Model Updates: 233,426
Cumulative Timesteps: 1,947,429,312

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 94,259.70029
Policy Entropy: 2.16641
Value Function Loss: 0.02200

Mean KL Divergence: 0.00710
SB3 Clip Fraction: 0.06564
Policy Update Magnitude: 0.30647
Value Function Update Magnitude: 0.28756

Collected Steps per Second: 21,800.12594
Overall Steps per Second: 10,456.23154

Timestep Collection Time: 2.29457
Timestep Consumption Time: 2.48937
PPO Batch Consumption Time: 0.27861
Total Iteration Time: 4.78394

Cumulative Model Updates: 233,432
Cumulative Timesteps: 1,947,479,334

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1947479334...
Checkpoint 1947479334 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 62,130.66906
Policy Entropy: 2.17524
Value Function Loss: 0.02208

Mean KL Divergence: 0.00783
SB3 Clip Fraction: 0.06962
Policy Update Magnitude: 0.30950
Value Function Update Magnitude: 0.28974

Collected Steps per Second: 21,125.67649
Overall Steps per Second: 10,453.96328

Timestep Collection Time: 2.36783
Timestep Consumption Time: 2.41715
PPO Batch Consumption Time: 0.29052
Total Iteration Time: 4.78498

Cumulative Model Updates: 233,438
Cumulative Timesteps: 1,947,529,356

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56,915.15850
Policy Entropy: 2.17682
Value Function Loss: 0.02049

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.07694
Policy Update Magnitude: 0.30112
Value Function Update Magnitude: 0.29669

Collected Steps per Second: 21,662.47895
Overall Steps per Second: 10,698.48122

Timestep Collection Time: 2.30842
Timestep Consumption Time: 2.36571
PPO Batch Consumption Time: 0.27998
Total Iteration Time: 4.67412

Cumulative Model Updates: 233,444
Cumulative Timesteps: 1,947,579,362

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1947579362...
Checkpoint 1947579362 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46,184.53579
Policy Entropy: 2.16917
Value Function Loss: 0.02295

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.07813
Policy Update Magnitude: 0.30576
Value Function Update Magnitude: 0.29322

Collected Steps per Second: 21,138.36181
Overall Steps per Second: 10,584.71156

Timestep Collection Time: 2.36612
Timestep Consumption Time: 2.35918
PPO Batch Consumption Time: 0.27946
Total Iteration Time: 4.72531

Cumulative Model Updates: 233,450
Cumulative Timesteps: 1,947,629,378

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54,213.81302
Policy Entropy: 2.15570
Value Function Loss: 0.02284

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.08617
Policy Update Magnitude: 0.30979
Value Function Update Magnitude: 0.31668

Collected Steps per Second: 21,596.74062
Overall Steps per Second: 10,500.66194

Timestep Collection Time: 2.31563
Timestep Consumption Time: 2.44693
PPO Batch Consumption Time: 0.29484
Total Iteration Time: 4.76256

Cumulative Model Updates: 233,456
Cumulative Timesteps: 1,947,679,388

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1947679388...
Checkpoint 1947679388 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 57,963.52490
Policy Entropy: 2.15983
Value Function Loss: 0.02798

Mean KL Divergence: 0.01076
SB3 Clip Fraction: 0.09332
Policy Update Magnitude: 0.31969
Value Function Update Magnitude: 0.34331

Collected Steps per Second: 21,193.91633
Overall Steps per Second: 10,343.02484

Timestep Collection Time: 2.36021
Timestep Consumption Time: 2.47610
PPO Batch Consumption Time: 0.29267
Total Iteration Time: 4.83630

Cumulative Model Updates: 233,462
Cumulative Timesteps: 1,947,729,410

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,432.19796
Policy Entropy: 2.16410
Value Function Loss: 0.02668

Mean KL Divergence: 0.01175
SB3 Clip Fraction: 0.10050
Policy Update Magnitude: 0.32358
Value Function Update Magnitude: 0.33502

Collected Steps per Second: 21,804.23909
Overall Steps per Second: 10,525.33414

Timestep Collection Time: 2.29359
Timestep Consumption Time: 2.45780
PPO Batch Consumption Time: 0.28890
Total Iteration Time: 4.75139

Cumulative Model Updates: 233,468
Cumulative Timesteps: 1,947,779,420

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1947779420...
Checkpoint 1947779420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 68,141.75675
Policy Entropy: 2.17236
Value Function Loss: 0.02575

Mean KL Divergence: 0.01171
SB3 Clip Fraction: 0.10110
Policy Update Magnitude: 0.31877
Value Function Update Magnitude: 0.34428

Collected Steps per Second: 21,287.71302
Overall Steps per Second: 10,412.93882

Timestep Collection Time: 2.34999
Timestep Consumption Time: 2.45422
PPO Batch Consumption Time: 0.28722
Total Iteration Time: 4.80422

Cumulative Model Updates: 233,474
Cumulative Timesteps: 1,947,829,446

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,904.61184
Policy Entropy: 2.15300
Value Function Loss: 0.02329

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.09677
Policy Update Magnitude: 0.31701
Value Function Update Magnitude: 0.35424

Collected Steps per Second: 21,838.53231
Overall Steps per Second: 10,483.89124

Timestep Collection Time: 2.29026
Timestep Consumption Time: 2.48048
PPO Batch Consumption Time: 0.28634
Total Iteration Time: 4.77075

Cumulative Model Updates: 233,480
Cumulative Timesteps: 1,947,879,462

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1947879462...
Checkpoint 1947879462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,821.58882
Policy Entropy: 2.14661
Value Function Loss: 0.02067

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.08418
Policy Update Magnitude: 0.31614
Value Function Update Magnitude: 0.33671

Collected Steps per Second: 20,989.39388
Overall Steps per Second: 10,216.00684

Timestep Collection Time: 2.38282
Timestep Consumption Time: 2.51283
PPO Batch Consumption Time: 0.29341
Total Iteration Time: 4.89565

Cumulative Model Updates: 233,486
Cumulative Timesteps: 1,947,929,476

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,417.74402
Policy Entropy: 2.14090
Value Function Loss: 0.02413

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.08345
Policy Update Magnitude: 0.31696
Value Function Update Magnitude: 0.32046

Collected Steps per Second: 22,329.81749
Overall Steps per Second: 10,442.53030

Timestep Collection Time: 2.24041
Timestep Consumption Time: 2.55038
PPO Batch Consumption Time: 0.29369
Total Iteration Time: 4.79079

Cumulative Model Updates: 233,492
Cumulative Timesteps: 1,947,979,504

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1947979504...
Checkpoint 1947979504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,077.10747
Policy Entropy: 2.15901
Value Function Loss: 0.02269

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.08709
Policy Update Magnitude: 0.31530
Value Function Update Magnitude: 0.33669

Collected Steps per Second: 21,479.96559
Overall Steps per Second: 10,356.16269

Timestep Collection Time: 2.32896
Timestep Consumption Time: 2.50159
PPO Batch Consumption Time: 0.29010
Total Iteration Time: 4.83055

Cumulative Model Updates: 233,498
Cumulative Timesteps: 1,948,029,530

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,665.10587
Policy Entropy: 2.16514
Value Function Loss: 0.02342

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.07899
Policy Update Magnitude: 0.31528
Value Function Update Magnitude: 0.35465

Collected Steps per Second: 22,122.67422
Overall Steps per Second: 10,664.07726

Timestep Collection Time: 2.26211
Timestep Consumption Time: 2.43065
PPO Batch Consumption Time: 0.27875
Total Iteration Time: 4.69276

Cumulative Model Updates: 233,504
Cumulative Timesteps: 1,948,079,574

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1948079574...
Checkpoint 1948079574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 51,489.76801
Policy Entropy: 2.15037
Value Function Loss: 0.02151

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.07703
Policy Update Magnitude: 0.31665
Value Function Update Magnitude: 0.37024

Collected Steps per Second: 21,805.74581
Overall Steps per Second: 10,489.86129

Timestep Collection Time: 2.29334
Timestep Consumption Time: 2.47393
PPO Batch Consumption Time: 0.28877
Total Iteration Time: 4.76727

Cumulative Model Updates: 233,510
Cumulative Timesteps: 1,948,129,582

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51,927.32227
Policy Entropy: 2.14418
Value Function Loss: 0.02104

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.07801
Policy Update Magnitude: 0.30863
Value Function Update Magnitude: 0.35444

Collected Steps per Second: 22,499.44449
Overall Steps per Second: 10,650.89216

Timestep Collection Time: 2.22317
Timestep Consumption Time: 2.47315
PPO Batch Consumption Time: 0.28516
Total Iteration Time: 4.69632

Cumulative Model Updates: 233,516
Cumulative Timesteps: 1,948,179,602

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1948179602...
Checkpoint 1948179602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,663.57899
Policy Entropy: 2.14525
Value Function Loss: 0.02062

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.07329
Policy Update Magnitude: 0.30542
Value Function Update Magnitude: 0.33721

Collected Steps per Second: 22,014.17030
Overall Steps per Second: 10,641.90716

Timestep Collection Time: 2.27263
Timestep Consumption Time: 2.42860
PPO Batch Consumption Time: 0.27895
Total Iteration Time: 4.70122

Cumulative Model Updates: 233,522
Cumulative Timesteps: 1,948,229,632

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,370.08530
Policy Entropy: 2.15911
Value Function Loss: 0.02021

Mean KL Divergence: 0.00759
SB3 Clip Fraction: 0.07378
Policy Update Magnitude: 0.30235
Value Function Update Magnitude: 0.31852

Collected Steps per Second: 22,169.37382
Overall Steps per Second: 10,470.47781

Timestep Collection Time: 2.25563
Timestep Consumption Time: 2.52027
PPO Batch Consumption Time: 0.29211
Total Iteration Time: 4.77590

Cumulative Model Updates: 233,528
Cumulative Timesteps: 1,948,279,638

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1948279638...
Checkpoint 1948279638 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 56,076.40216
Policy Entropy: 2.16721
Value Function Loss: 0.02152

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.07927
Policy Update Magnitude: 0.30960
Value Function Update Magnitude: 0.30361

Collected Steps per Second: 21,318.92503
Overall Steps per Second: 10,336.86468

Timestep Collection Time: 2.34665
Timestep Consumption Time: 2.49312
PPO Batch Consumption Time: 0.29153
Total Iteration Time: 4.83977

Cumulative Model Updates: 233,534
Cumulative Timesteps: 1,948,329,666

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55,114.07505
Policy Entropy: 2.17532
Value Function Loss: 0.02026

Mean KL Divergence: 0.01131
SB3 Clip Fraction: 0.09648
Policy Update Magnitude: 0.30014
Value Function Update Magnitude: 0.29017

Collected Steps per Second: 21,899.49179
Overall Steps per Second: 10,489.35691

Timestep Collection Time: 2.28453
Timestep Consumption Time: 2.48507
PPO Batch Consumption Time: 0.29083
Total Iteration Time: 4.76960

Cumulative Model Updates: 233,540
Cumulative Timesteps: 1,948,379,696

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1948379696...
Checkpoint 1948379696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,360.12175
Policy Entropy: 2.19006
Value Function Loss: 0.02004

Mean KL Divergence: 0.01340
SB3 Clip Fraction: 0.10900
Policy Update Magnitude: 0.29001
Value Function Update Magnitude: 0.28308

Collected Steps per Second: 21,393.32371
Overall Steps per Second: 10,507.29114

Timestep Collection Time: 2.33821
Timestep Consumption Time: 2.42249
PPO Batch Consumption Time: 0.27755
Total Iteration Time: 4.76069

Cumulative Model Updates: 233,546
Cumulative Timesteps: 1,948,429,718

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46,873.16025
Policy Entropy: 2.17408
Value Function Loss: 0.01856

Mean KL Divergence: 0.01083
SB3 Clip Fraction: 0.09443
Policy Update Magnitude: 0.29177
Value Function Update Magnitude: 0.26107

Collected Steps per Second: 21,246.79816
Overall Steps per Second: 10,443.44242

Timestep Collection Time: 2.35490
Timestep Consumption Time: 2.43605
PPO Batch Consumption Time: 0.29326
Total Iteration Time: 4.79095

Cumulative Model Updates: 233,552
Cumulative Timesteps: 1,948,479,752

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1948479752...
Checkpoint 1948479752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,728.52391
Policy Entropy: 2.15857
Value Function Loss: 0.02068

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.08797
Policy Update Magnitude: 0.30197
Value Function Update Magnitude: 0.29283

Collected Steps per Second: 20,751.45600
Overall Steps per Second: 10,516.88111

Timestep Collection Time: 2.40986
Timestep Consumption Time: 2.34517
PPO Batch Consumption Time: 0.27828
Total Iteration Time: 4.75502

Cumulative Model Updates: 233,558
Cumulative Timesteps: 1,948,529,760

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,930.94560
Policy Entropy: 2.14231
Value Function Loss: 0.01971

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.08080
Policy Update Magnitude: 0.30486
Value Function Update Magnitude: 0.28970

Collected Steps per Second: 21,574.13487
Overall Steps per Second: 10,531.88171

Timestep Collection Time: 2.31926
Timestep Consumption Time: 2.43165
PPO Batch Consumption Time: 0.28942
Total Iteration Time: 4.75091

Cumulative Model Updates: 233,564
Cumulative Timesteps: 1,948,579,796

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1948579796...
Checkpoint 1948579796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 64,386.69776
Policy Entropy: 2.15155
Value Function Loss: 0.02024

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.07454
Policy Update Magnitude: 0.30194
Value Function Update Magnitude: 0.25791

Collected Steps per Second: 21,432.32779
Overall Steps per Second: 10,531.54825

Timestep Collection Time: 2.33414
Timestep Consumption Time: 2.41597
PPO Batch Consumption Time: 0.28014
Total Iteration Time: 4.75011

Cumulative Model Updates: 233,570
Cumulative Timesteps: 1,948,629,822

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 71,685.94400
Policy Entropy: 2.16518
Value Function Loss: 0.02199

Mean KL Divergence: 0.00772
SB3 Clip Fraction: 0.07296
Policy Update Magnitude: 0.30504
Value Function Update Magnitude: 0.20348

Collected Steps per Second: 22,089.00574
Overall Steps per Second: 10,554.68741

Timestep Collection Time: 2.26375
Timestep Consumption Time: 2.47386
PPO Batch Consumption Time: 0.28869
Total Iteration Time: 4.73761

Cumulative Model Updates: 233,576
Cumulative Timesteps: 1,948,679,826

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1948679826...
Checkpoint 1948679826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 64,686.21548
Policy Entropy: 2.16446
Value Function Loss: 0.02136

Mean KL Divergence: 0.00746
SB3 Clip Fraction: 0.07028
Policy Update Magnitude: 0.30937
Value Function Update Magnitude: 0.22017

Collected Steps per Second: 21,693.28377
Overall Steps per Second: 10,590.99892

Timestep Collection Time: 2.30532
Timestep Consumption Time: 2.41661
PPO Batch Consumption Time: 0.27995
Total Iteration Time: 4.72193

Cumulative Model Updates: 233,582
Cumulative Timesteps: 1,948,729,836

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 73,785.13962
Policy Entropy: 2.16342
Value Function Loss: 0.02075

Mean KL Divergence: 0.00747
SB3 Clip Fraction: 0.07006
Policy Update Magnitude: 0.30816
Value Function Update Magnitude: 0.24969

Collected Steps per Second: 21,994.93855
Overall Steps per Second: 10,497.64995

Timestep Collection Time: 2.27334
Timestep Consumption Time: 2.48982
PPO Batch Consumption Time: 0.28792
Total Iteration Time: 4.76316

Cumulative Model Updates: 233,588
Cumulative Timesteps: 1,948,779,838

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1948779838...
Checkpoint 1948779838 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,958.82955
Policy Entropy: 2.15663
Value Function Loss: 0.02154

Mean KL Divergence: 0.00734
SB3 Clip Fraction: 0.07039
Policy Update Magnitude: 0.30831
Value Function Update Magnitude: 0.29478

Collected Steps per Second: 21,985.61526
Overall Steps per Second: 10,622.55723

Timestep Collection Time: 2.27558
Timestep Consumption Time: 2.43421
PPO Batch Consumption Time: 0.27881
Total Iteration Time: 4.70979

Cumulative Model Updates: 233,594
Cumulative Timesteps: 1,948,829,868

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,738.46403
Policy Entropy: 2.16451
Value Function Loss: 0.02139

Mean KL Divergence: 0.00783
SB3 Clip Fraction: 0.07358
Policy Update Magnitude: 0.30772
Value Function Update Magnitude: 0.34021

Collected Steps per Second: 21,429.19199
Overall Steps per Second: 10,472.19636

Timestep Collection Time: 2.33429
Timestep Consumption Time: 2.44236
PPO Batch Consumption Time: 0.27886
Total Iteration Time: 4.77665

Cumulative Model Updates: 233,600
Cumulative Timesteps: 1,948,879,890

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1948879890...
Checkpoint 1948879890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 59,840.71621
Policy Entropy: 2.15683
Value Function Loss: 0.02206

Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.07766
Policy Update Magnitude: 0.30806
Value Function Update Magnitude: 0.34148

Collected Steps per Second: 21,450.09486
Overall Steps per Second: 10,341.32257

Timestep Collection Time: 2.33164
Timestep Consumption Time: 2.50468
PPO Batch Consumption Time: 0.29242
Total Iteration Time: 4.83633

Cumulative Model Updates: 233,606
Cumulative Timesteps: 1,948,929,904

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62,062.71802
Policy Entropy: 2.15645
Value Function Loss: 0.02246

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.08141
Policy Update Magnitude: 0.31090
Value Function Update Magnitude: 0.33913

Collected Steps per Second: 21,287.24657
Overall Steps per Second: 10,290.90896

Timestep Collection Time: 2.35023
Timestep Consumption Time: 2.51134
PPO Batch Consumption Time: 0.28909
Total Iteration Time: 4.86157

Cumulative Model Updates: 233,612
Cumulative Timesteps: 1,948,979,934

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1948979934...
Checkpoint 1948979934 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,694.43810
Policy Entropy: 2.15552
Value Function Loss: 0.02296

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.07890
Policy Update Magnitude: 0.31655
Value Function Update Magnitude: 0.33484

Collected Steps per Second: 21,613.12837
Overall Steps per Second: 10,371.90240

Timestep Collection Time: 2.31535
Timestep Consumption Time: 2.50941
PPO Batch Consumption Time: 0.29207
Total Iteration Time: 4.82477

Cumulative Model Updates: 233,618
Cumulative Timesteps: 1,949,029,976

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55,806.32426
Policy Entropy: 2.15317
Value Function Loss: 0.02091

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.07783
Policy Update Magnitude: 0.31385
Value Function Update Magnitude: 0.34074

Collected Steps per Second: 21,939.18057
Overall Steps per Second: 10,334.60548

Timestep Collection Time: 2.27994
Timestep Consumption Time: 2.56011
PPO Batch Consumption Time: 0.29198
Total Iteration Time: 4.84005

Cumulative Model Updates: 233,624
Cumulative Timesteps: 1,949,079,996

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1949079996...
Checkpoint 1949079996 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,888.95351
Policy Entropy: 2.15716
Value Function Loss: 0.02261

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.07935
Policy Update Magnitude: 0.31139
Value Function Update Magnitude: 0.31971

Collected Steps per Second: 21,643.33341
Overall Steps per Second: 10,517.31435

Timestep Collection Time: 2.31036
Timestep Consumption Time: 2.44408
PPO Batch Consumption Time: 0.27868
Total Iteration Time: 4.75445

Cumulative Model Updates: 233,630
Cumulative Timesteps: 1,949,130,000

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,179.06719
Policy Entropy: 2.15469
Value Function Loss: 0.02255

Mean KL Divergence: 0.00739
SB3 Clip Fraction: 0.07359
Policy Update Magnitude: 0.31384
Value Function Update Magnitude: 0.29552

Collected Steps per Second: 22,011.39365
Overall Steps per Second: 10,611.19219

Timestep Collection Time: 2.27191
Timestep Consumption Time: 2.44085
PPO Batch Consumption Time: 0.27868
Total Iteration Time: 4.71276

Cumulative Model Updates: 233,636
Cumulative Timesteps: 1,949,180,008

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1949180008...
Checkpoint 1949180008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 60,980.59381
Policy Entropy: 2.17541
Value Function Loss: 0.02306

Mean KL Divergence: 0.00719
SB3 Clip Fraction: 0.06939
Policy Update Magnitude: 0.31786
Value Function Update Magnitude: 0.31844

Collected Steps per Second: 21,925.53232
Overall Steps per Second: 10,606.94041

Timestep Collection Time: 2.28227
Timestep Consumption Time: 2.43540
PPO Batch Consumption Time: 0.27867
Total Iteration Time: 4.71767

Cumulative Model Updates: 233,642
Cumulative Timesteps: 1,949,230,048

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,265.03529
Policy Entropy: 2.17021
Value Function Loss: 0.02173

Mean KL Divergence: 0.00744
SB3 Clip Fraction: 0.07160
Policy Update Magnitude: 0.31046
Value Function Update Magnitude: 0.33412

Collected Steps per Second: 21,862.72439
Overall Steps per Second: 10,433.46450

Timestep Collection Time: 2.28919
Timestep Consumption Time: 2.50768
PPO Batch Consumption Time: 0.29093
Total Iteration Time: 4.79687

Cumulative Model Updates: 233,648
Cumulative Timesteps: 1,949,280,096

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 1949280096...
Checkpoint 1949280096 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,250.05749
Policy Entropy: 2.18698
Value Function Loss: 0.02235

Mean KL Divergence: 0.00723
SB3 Clip Fraction: 0.07075
Policy Update Magnitude: 0.30530
Value Function Update Magnitude: 0.32146

Collected Steps per Second: 22,066.52285
Overall Steps per Second: 10,650.98643

Timestep Collection Time: 2.26615
Timestep Consumption Time: 2.42882
PPO Batch Consumption Time: 0.27897
Total Iteration Time: 4.69496

Cumulative Model Updates: 233,654
Cumulative Timesteps: 1,949,330,102

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,018.98653
Policy Entropy: 2.17963
Value Function Loss: 0.02271

Mean KL Divergence: 0.00696
SB3 Clip Fraction: 0.06663
Policy Update Magnitude: 0.30632
Value Function Update Magnitude: 0.28825

Collected Steps per Second: 20,184.70501
Overall Steps per Second: 10,044.95421

Timestep Collection Time: 2.47940
Timestep Consumption Time: 2.50280
PPO Batch Consumption Time: 0.28938
Total Iteration Time: 4.98220

Cumulative Model Updates: 233,660
Cumulative Timesteps: 1,949,380,148

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1949380148...
Checkpoint 1949380148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,254.80929
Policy Entropy: 2.16883
Value Function Loss: 0.02510

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.07380
Policy Update Magnitude: 0.30632
Value Function Update Magnitude: 0.26956

Collected Steps per Second: 21,192.06623
Overall Steps per Second: 10,255.47689

Timestep Collection Time: 2.35947
Timestep Consumption Time: 2.51617
PPO Batch Consumption Time: 0.29395
Total Iteration Time: 4.87564

Cumulative Model Updates: 233,666
Cumulative Timesteps: 1,949,430,150

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,243.33478
Policy Entropy: 2.15350
Value Function Loss: 0.02545

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.07072
Policy Update Magnitude: 0.31321
Value Function Update Magnitude: 0.26904

Collected Steps per Second: 21,659.69407
Overall Steps per Second: 10,423.38727

Timestep Collection Time: 2.31093
Timestep Consumption Time: 2.49116
PPO Batch Consumption Time: 0.28846
Total Iteration Time: 4.80209

Cumulative Model Updates: 233,672
Cumulative Timesteps: 1,949,480,204

Timesteps Collected: 50,054
--------END ITERATION REPORT--------


Saving checkpoint 1949480204...
Checkpoint 1949480204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 64,581.22508
Policy Entropy: 2.15700
Value Function Loss: 0.02613

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.07335
Policy Update Magnitude: 0.31864
Value Function Update Magnitude: 0.30176

Collected Steps per Second: 21,249.02104
Overall Steps per Second: 10,294.32522

Timestep Collection Time: 2.35314
Timestep Consumption Time: 2.50410
PPO Batch Consumption Time: 0.29320
Total Iteration Time: 4.85724

Cumulative Model Updates: 233,678
Cumulative Timesteps: 1,949,530,206

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51,282.04493
Policy Entropy: 2.17790
Value Function Loss: 0.02735

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.07698
Policy Update Magnitude: 0.32179
Value Function Update Magnitude: 0.30565

Collected Steps per Second: 22,142.08886
Overall Steps per Second: 10,424.92912

Timestep Collection Time: 2.25932
Timestep Consumption Time: 2.53937
PPO Batch Consumption Time: 0.29286
Total Iteration Time: 4.79869

Cumulative Model Updates: 233,684
Cumulative Timesteps: 1,949,580,232

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1949580232...
Checkpoint 1949580232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,700.59694
Policy Entropy: 2.18472
Value Function Loss: 0.02433

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.07836
Policy Update Magnitude: 0.31548
Value Function Update Magnitude: 0.28959

Collected Steps per Second: 22,360.11031
Overall Steps per Second: 10,539.35880

Timestep Collection Time: 2.23747
Timestep Consumption Time: 2.50950
PPO Batch Consumption Time: 0.29193
Total Iteration Time: 4.74697

Cumulative Model Updates: 233,690
Cumulative Timesteps: 1,949,630,262

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,290.92579
Policy Entropy: 2.19760
Value Function Loss: 0.02562

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.07546
Policy Update Magnitude: 0.31230
Value Function Update Magnitude: 0.29648

Collected Steps per Second: 22,384.66306
Overall Steps per Second: 10,576.98498

Timestep Collection Time: 2.23421
Timestep Consumption Time: 2.49417
PPO Batch Consumption Time: 0.29238
Total Iteration Time: 4.72838

Cumulative Model Updates: 233,696
Cumulative Timesteps: 1,949,680,274

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1949680274...
Checkpoint 1949680274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 50,877.05952
Policy Entropy: 2.19626
Value Function Loss: 0.02223

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.07608
Policy Update Magnitude: 0.30744
Value Function Update Magnitude: 0.29066

Collected Steps per Second: 22,260.87662
Overall Steps per Second: 10,548.52343

Timestep Collection Time: 2.24807
Timestep Consumption Time: 2.49610
PPO Batch Consumption Time: 0.29217
Total Iteration Time: 4.74417

Cumulative Model Updates: 233,702
Cumulative Timesteps: 1,949,730,318

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,096.38748
Policy Entropy: 2.19657
Value Function Loss: 0.02504

Mean KL Divergence: 0.00782
SB3 Clip Fraction: 0.07551
Policy Update Magnitude: 0.31278
Value Function Update Magnitude: 0.28318

Collected Steps per Second: 21,653.43440
Overall Steps per Second: 10,557.33964

Timestep Collection Time: 2.30993
Timestep Consumption Time: 2.42781
PPO Batch Consumption Time: 0.29185
Total Iteration Time: 4.73775

Cumulative Model Updates: 233,708
Cumulative Timesteps: 1,949,780,336

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1949780336...
Checkpoint 1949780336 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,837.73809
Policy Entropy: 2.18189
Value Function Loss: 0.02192

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.07329
Policy Update Magnitude: 0.31649
Value Function Update Magnitude: 0.29158

Collected Steps per Second: 21,394.62782
Overall Steps per Second: 10,501.12335

Timestep Collection Time: 2.33844
Timestep Consumption Time: 2.42581
PPO Batch Consumption Time: 0.29051
Total Iteration Time: 4.76425

Cumulative Model Updates: 233,714
Cumulative Timesteps: 1,949,830,366

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,403.10173
Policy Entropy: 2.17636
Value Function Loss: 0.02234

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.07546
Policy Update Magnitude: 0.32095
Value Function Update Magnitude: 0.32715

Collected Steps per Second: 21,232.53003
Overall Steps per Second: 10,491.84091

Timestep Collection Time: 2.35601
Timestep Consumption Time: 2.41189
PPO Batch Consumption Time: 0.28836
Total Iteration Time: 4.76790

Cumulative Model Updates: 233,720
Cumulative Timesteps: 1,949,880,390

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1949880390...
Checkpoint 1949880390 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,735.20886
Policy Entropy: 2.19491
Value Function Loss: 0.02074

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.07474
Policy Update Magnitude: 0.31487
Value Function Update Magnitude: 0.34317

Collected Steps per Second: 20,928.84827
Overall Steps per Second: 10,261.68360

Timestep Collection Time: 2.39029
Timestep Consumption Time: 2.48474
PPO Batch Consumption Time: 0.29380
Total Iteration Time: 4.87503

Cumulative Model Updates: 233,726
Cumulative Timesteps: 1,949,930,416

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56,899.03742
Policy Entropy: 2.19239
Value Function Loss: 0.02204

Mean KL Divergence: 0.00708
SB3 Clip Fraction: 0.06914
Policy Update Magnitude: 0.31218
Value Function Update Magnitude: 0.33796

Collected Steps per Second: 21,444.97329
Overall Steps per Second: 10,379.47865

Timestep Collection Time: 2.33257
Timestep Consumption Time: 2.48674
PPO Batch Consumption Time: 0.29220
Total Iteration Time: 4.81932

Cumulative Model Updates: 233,732
Cumulative Timesteps: 1,949,980,438

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1949980438...
Checkpoint 1949980438 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,724.57012
Policy Entropy: 2.19053
Value Function Loss: 0.02192

Mean KL Divergence: 0.00753
SB3 Clip Fraction: 0.07419
Policy Update Magnitude: 0.31248
Value Function Update Magnitude: 0.33573

Collected Steps per Second: 21,459.96756
Overall Steps per Second: 10,575.11298

Timestep Collection Time: 2.33122
Timestep Consumption Time: 2.39951
PPO Batch Consumption Time: 0.27845
Total Iteration Time: 4.73073

Cumulative Model Updates: 233,738
Cumulative Timesteps: 1,950,030,466

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,355.78768
Policy Entropy: 2.17882
Value Function Loss: 0.02473

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.07692
Policy Update Magnitude: 0.32203
Value Function Update Magnitude: 0.35215

Collected Steps per Second: 21,605.65076
Overall Steps per Second: 10,615.05577

Timestep Collection Time: 2.31625
Timestep Consumption Time: 2.39819
PPO Batch Consumption Time: 0.27734
Total Iteration Time: 4.71444

Cumulative Model Updates: 233,744
Cumulative Timesteps: 1,950,080,510

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1950080510...
Checkpoint 1950080510 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,420.41534
Policy Entropy: 2.19018
Value Function Loss: 0.02441

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.07872
Policy Update Magnitude: 0.32550
Value Function Update Magnitude: 0.38848

Collected Steps per Second: 21,502.01424
Overall Steps per Second: 10,480.89335

Timestep Collection Time: 2.32574
Timestep Consumption Time: 2.44561
PPO Batch Consumption Time: 0.27841
Total Iteration Time: 4.77135

Cumulative Model Updates: 233,750
Cumulative Timesteps: 1,950,130,518

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,420.41534
Policy Entropy: 2.18681
Value Function Loss: 0.02061

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.07451
Policy Update Magnitude: 0.31485
Value Function Update Magnitude: 0.37490

Collected Steps per Second: 22,008.47748
Overall Steps per Second: 10,573.82007

Timestep Collection Time: 2.27303
Timestep Consumption Time: 2.45809
PPO Batch Consumption Time: 0.27753
Total Iteration Time: 4.73112

Cumulative Model Updates: 233,756
Cumulative Timesteps: 1,950,180,544

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1950180544...
Checkpoint 1950180544 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,389.92060
Policy Entropy: 2.16628
Value Function Loss: 0.01818

Mean KL Divergence: 0.00738
SB3 Clip Fraction: 0.06877
Policy Update Magnitude: 0.30111
Value Function Update Magnitude: 0.32507

Collected Steps per Second: 21,658.88802
Overall Steps per Second: 10,514.33808

Timestep Collection Time: 2.30852
Timestep Consumption Time: 2.44689
PPO Batch Consumption Time: 0.27926
Total Iteration Time: 4.75541

Cumulative Model Updates: 233,762
Cumulative Timesteps: 1,950,230,544

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,632.74307
Policy Entropy: 2.16853
Value Function Loss: 0.01700

Mean KL Divergence: 0.00690
SB3 Clip Fraction: 0.06156
Policy Update Magnitude: 0.29574
Value Function Update Magnitude: 0.31684

Collected Steps per Second: 22,010.60804
Overall Steps per Second: 10,534.70257

Timestep Collection Time: 2.27354
Timestep Consumption Time: 2.47667
PPO Batch Consumption Time: 0.28657
Total Iteration Time: 4.75021

Cumulative Model Updates: 233,768
Cumulative Timesteps: 1,950,280,586

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1950280586...
Checkpoint 1950280586 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,727.39583
Policy Entropy: 2.18098
Value Function Loss: 0.02072

Mean KL Divergence: 0.00719
SB3 Clip Fraction: 0.06340
Policy Update Magnitude: 0.29751
Value Function Update Magnitude: 0.31744

Collected Steps per Second: 21,980.32969
Overall Steps per Second: 10,669.16622

Timestep Collection Time: 2.27522
Timestep Consumption Time: 2.41212
PPO Batch Consumption Time: 0.27755
Total Iteration Time: 4.68734

Cumulative Model Updates: 233,774
Cumulative Timesteps: 1,950,330,596

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46,146.39087
Policy Entropy: 2.21301
Value Function Loss: 0.02316

Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.07546
Policy Update Magnitude: 0.29938
Value Function Update Magnitude: 0.31522

Collected Steps per Second: 22,162.34072
Overall Steps per Second: 10,508.05379

Timestep Collection Time: 2.25653
Timestep Consumption Time: 2.50268
PPO Batch Consumption Time: 0.29237
Total Iteration Time: 4.75921

Cumulative Model Updates: 233,780
Cumulative Timesteps: 1,950,380,606

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1950380606...
Checkpoint 1950380606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,100.13945
Policy Entropy: 2.22766
Value Function Loss: 0.02836

Mean KL Divergence: 0.00770
SB3 Clip Fraction: 0.07232
Policy Update Magnitude: 0.30943
Value Function Update Magnitude: 0.34510

Collected Steps per Second: 21,987.61844
Overall Steps per Second: 10,517.41257

Timestep Collection Time: 2.27419
Timestep Consumption Time: 2.48021
PPO Batch Consumption Time: 0.28743
Total Iteration Time: 4.75440

Cumulative Model Updates: 233,786
Cumulative Timesteps: 1,950,430,610

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,112.31820
Policy Entropy: 2.21388
Value Function Loss: 0.02892

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.07799
Policy Update Magnitude: 0.31326
Value Function Update Magnitude: 0.36105

Collected Steps per Second: 21,371.77998
Overall Steps per Second: 10,478.46628

Timestep Collection Time: 2.34066
Timestep Consumption Time: 2.43332
PPO Batch Consumption Time: 0.29177
Total Iteration Time: 4.77398

Cumulative Model Updates: 233,792
Cumulative Timesteps: 1,950,480,634

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1950480634...
Checkpoint 1950480634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,163.79982
Policy Entropy: 2.19129
Value Function Loss: 0.02871

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.07464
Policy Update Magnitude: 0.31330
Value Function Update Magnitude: 0.35246

Collected Steps per Second: 20,739.57817
Overall Steps per Second: 10,342.79910

Timestep Collection Time: 2.41278
Timestep Consumption Time: 2.42537
PPO Batch Consumption Time: 0.29283
Total Iteration Time: 4.83815

Cumulative Model Updates: 233,798
Cumulative Timesteps: 1,950,530,674

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,141.78874
Policy Entropy: 2.18450
Value Function Loss: 0.02390

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.07900
Policy Update Magnitude: 0.30797
Value Function Update Magnitude: 0.33038

Collected Steps per Second: 20,900.49132
Overall Steps per Second: 10,376.23316

Timestep Collection Time: 2.39296
Timestep Consumption Time: 2.42710
PPO Batch Consumption Time: 0.29272
Total Iteration Time: 4.82005

Cumulative Model Updates: 233,804
Cumulative Timesteps: 1,950,580,688

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1950580688...
Checkpoint 1950580688 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,890.01285
Policy Entropy: 2.18771
Value Function Loss: 0.02148

Mean KL Divergence: 0.00764
SB3 Clip Fraction: 0.07084
Policy Update Magnitude: 0.30090
Value Function Update Magnitude: 0.32844

Collected Steps per Second: 21,094.89417
Overall Steps per Second: 10,260.63679

Timestep Collection Time: 2.37119
Timestep Consumption Time: 2.50375
PPO Batch Consumption Time: 0.29204
Total Iteration Time: 4.87494

Cumulative Model Updates: 233,810
Cumulative Timesteps: 1,950,630,708

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50,782.30017
Policy Entropy: 2.19852
Value Function Loss: 0.02333

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.07069
Policy Update Magnitude: 0.30938
Value Function Update Magnitude: 0.32079

Collected Steps per Second: 22,165.10099
Overall Steps per Second: 10,498.59361

Timestep Collection Time: 2.25769
Timestep Consumption Time: 2.50885
PPO Batch Consumption Time: 0.29190
Total Iteration Time: 4.76654

Cumulative Model Updates: 233,816
Cumulative Timesteps: 1,950,680,750

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1950680750...
Checkpoint 1950680750 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,953.89858
Policy Entropy: 2.19329
Value Function Loss: 0.02334

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.07200
Policy Update Magnitude: 0.31164
Value Function Update Magnitude: 0.28900

Collected Steps per Second: 22,139.11226
Overall Steps per Second: 10,544.45478

Timestep Collection Time: 2.25899
Timestep Consumption Time: 2.48398
PPO Batch Consumption Time: 0.29286
Total Iteration Time: 4.74297

Cumulative Model Updates: 233,822
Cumulative Timesteps: 1,950,730,762

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89,629.73974
Policy Entropy: 2.20279
Value Function Loss: 0.02569

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.07657
Policy Update Magnitude: 0.30752
Value Function Update Magnitude: 0.27634

Collected Steps per Second: 22,234.41122
Overall Steps per Second: 10,561.47798

Timestep Collection Time: 2.25012
Timestep Consumption Time: 2.48691
PPO Batch Consumption Time: 0.29057
Total Iteration Time: 4.73703

Cumulative Model Updates: 233,828
Cumulative Timesteps: 1,950,780,792

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1950780792...
Checkpoint 1950780792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 73,674.71126
Policy Entropy: 2.18424
Value Function Loss: 0.01975

Mean KL Divergence: 0.00750
SB3 Clip Fraction: 0.07084
Policy Update Magnitude: 0.29785
Value Function Update Magnitude: 0.31327

Collected Steps per Second: 22,247.30130
Overall Steps per Second: 10,515.44810

Timestep Collection Time: 2.24782
Timestep Consumption Time: 2.50785
PPO Batch Consumption Time: 0.29494
Total Iteration Time: 4.75567

Cumulative Model Updates: 233,834
Cumulative Timesteps: 1,950,830,800

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65,693.15885
Policy Entropy: 2.19343
Value Function Loss: 0.01847

Mean KL Divergence: 0.00670
SB3 Clip Fraction: 0.06547
Policy Update Magnitude: 0.28922
Value Function Update Magnitude: 0.31065

Collected Steps per Second: 22,099.04218
Overall Steps per Second: 10,471.58466

Timestep Collection Time: 2.26263
Timestep Consumption Time: 2.51239
PPO Batch Consumption Time: 0.29313
Total Iteration Time: 4.77502

Cumulative Model Updates: 233,840
Cumulative Timesteps: 1,950,880,802

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1950880802...
Checkpoint 1950880802 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43,845.95500
Policy Entropy: 2.17836
Value Function Loss: 0.01879

Mean KL Divergence: 0.00695
SB3 Clip Fraction: 0.06971
Policy Update Magnitude: 0.28875
Value Function Update Magnitude: 0.27669

Collected Steps per Second: 21,929.22564
Overall Steps per Second: 10,634.15051

Timestep Collection Time: 2.28116
Timestep Consumption Time: 2.42293
PPO Batch Consumption Time: 0.27826
Total Iteration Time: 4.70409

Cumulative Model Updates: 233,846
Cumulative Timesteps: 1,950,930,826

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,733.16685
Policy Entropy: 2.18947
Value Function Loss: 0.01974

Mean KL Divergence: 0.00692
SB3 Clip Fraction: 0.06448
Policy Update Magnitude: 0.29803
Value Function Update Magnitude: 0.21670

Collected Steps per Second: 21,988.51074
Overall Steps per Second: 10,471.43949

Timestep Collection Time: 2.27391
Timestep Consumption Time: 2.50098
PPO Batch Consumption Time: 0.29264
Total Iteration Time: 4.77489

Cumulative Model Updates: 233,852
Cumulative Timesteps: 1,950,980,826

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1950980826...
Checkpoint 1950980826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48,548.12854
Policy Entropy: 2.18627
Value Function Loss: 0.02474

Mean KL Divergence: 0.00717
SB3 Clip Fraction: 0.06575
Policy Update Magnitude: 0.30039
Value Function Update Magnitude: 0.20571

Collected Steps per Second: 21,484.46001
Overall Steps per Second: 10,516.69766

Timestep Collection Time: 2.32745
Timestep Consumption Time: 2.42727
PPO Batch Consumption Time: 0.27866
Total Iteration Time: 4.75472

Cumulative Model Updates: 233,858
Cumulative Timesteps: 1,951,030,830

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,332.98492
Policy Entropy: 2.19390
Value Function Loss: 0.02230

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.07459
Policy Update Magnitude: 0.29601
Value Function Update Magnitude: 0.24688

Collected Steps per Second: 21,505.05926
Overall Steps per Second: 10,500.70091

Timestep Collection Time: 2.32634
Timestep Consumption Time: 2.43792
PPO Batch Consumption Time: 0.27879
Total Iteration Time: 4.76425

Cumulative Model Updates: 233,864
Cumulative Timesteps: 1,951,080,858

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1951080858...
Checkpoint 1951080858 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,790.72634
Policy Entropy: 2.20710
Value Function Loss: 0.02114

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.07769
Policy Update Magnitude: 0.28993
Value Function Update Magnitude: 0.33463

Collected Steps per Second: 21,424.25061
Overall Steps per Second: 10,342.79427

Timestep Collection Time: 2.33520
Timestep Consumption Time: 2.50198
PPO Batch Consumption Time: 0.29139
Total Iteration Time: 4.83718

Cumulative Model Updates: 233,870
Cumulative Timesteps: 1,951,130,888

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65,853.67434
Policy Entropy: 2.19659
Value Function Loss: 0.02186

Mean KL Divergence: 0.00690
SB3 Clip Fraction: 0.07065
Policy Update Magnitude: 0.29491
Value Function Update Magnitude: 0.31988

Collected Steps per Second: 21,016.25961
Overall Steps per Second: 10,415.78110

Timestep Collection Time: 2.37968
Timestep Consumption Time: 2.42188
PPO Batch Consumption Time: 0.29184
Total Iteration Time: 4.80156

Cumulative Model Updates: 233,876
Cumulative Timesteps: 1,951,180,900

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1951180900...
Checkpoint 1951180900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 71,653.00019
Policy Entropy: 2.20066
Value Function Loss: 0.02132

Mean KL Divergence: 0.00753
SB3 Clip Fraction: 0.07546
Policy Update Magnitude: 0.29681
Value Function Update Magnitude: 0.29403

Collected Steps per Second: 20,942.19969
Overall Steps per Second: 10,477.08262

Timestep Collection Time: 2.38838
Timestep Consumption Time: 2.38566
PPO Batch Consumption Time: 0.27915
Total Iteration Time: 4.77404

Cumulative Model Updates: 233,882
Cumulative Timesteps: 1,951,230,918

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91,346.04003
Policy Entropy: 2.17956
Value Function Loss: 0.02206

Mean KL Divergence: 0.00750
SB3 Clip Fraction: 0.07370
Policy Update Magnitude: 0.29026
Value Function Update Magnitude: 0.28834

Collected Steps per Second: 21,365.15952
Overall Steps per Second: 10,488.71686

Timestep Collection Time: 2.34045
Timestep Consumption Time: 2.42696
PPO Batch Consumption Time: 0.29051
Total Iteration Time: 4.76741

Cumulative Model Updates: 233,888
Cumulative Timesteps: 1,951,280,922

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1951280922...
Checkpoint 1951280922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 83,932.47211
Policy Entropy: 2.16636
Value Function Loss: 0.01969

Mean KL Divergence: 0.00743
SB3 Clip Fraction: 0.07198
Policy Update Magnitude: 0.29410
Value Function Update Magnitude: 0.28490

Collected Steps per Second: 21,453.42749
Overall Steps per Second: 10,565.11791

Timestep Collection Time: 2.33277
Timestep Consumption Time: 2.40413
PPO Batch Consumption Time: 0.27931
Total Iteration Time: 4.73691

Cumulative Model Updates: 233,894
Cumulative Timesteps: 1,951,330,968

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58,223.85402
Policy Entropy: 2.16675
Value Function Loss: 0.02087

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.08129
Policy Update Magnitude: 0.30468
Value Function Update Magnitude: 0.29336

Collected Steps per Second: 21,921.47463
Overall Steps per Second: 10,527.73918

Timestep Collection Time: 2.28151
Timestep Consumption Time: 2.46918
PPO Batch Consumption Time: 0.28800
Total Iteration Time: 4.75069

Cumulative Model Updates: 233,900
Cumulative Timesteps: 1,951,380,982

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1951380982...
Checkpoint 1951380982 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 71,088.97021
Policy Entropy: 2.18322
Value Function Loss: 0.02140

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.08262
Policy Update Magnitude: 0.30798
Value Function Update Magnitude: 0.32007

Collected Steps per Second: 21,735.09628
Overall Steps per Second: 10,610.53677

Timestep Collection Time: 2.30208
Timestep Consumption Time: 2.41361
PPO Batch Consumption Time: 0.27926
Total Iteration Time: 4.71569

Cumulative Model Updates: 233,906
Cumulative Timesteps: 1,951,431,018

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52,969.21279
Policy Entropy: 2.19832
Value Function Loss: 0.02009

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.09037
Policy Update Magnitude: 0.30106
Value Function Update Magnitude: 0.32618

Collected Steps per Second: 21,312.00184
Overall Steps per Second: 10,444.80602

Timestep Collection Time: 2.34675
Timestep Consumption Time: 2.44166
PPO Batch Consumption Time: 0.27904
Total Iteration Time: 4.78841

Cumulative Model Updates: 233,912
Cumulative Timesteps: 1,951,481,032

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1951481032...
Checkpoint 1951481032 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 59,820.21478
Policy Entropy: 2.18530
Value Function Loss: 0.01874

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.07977
Policy Update Magnitude: 0.29861
Value Function Update Magnitude: 0.33338

Collected Steps per Second: 21,055.58125
Overall Steps per Second: 10,276.19988

Timestep Collection Time: 2.37600
Timestep Consumption Time: 2.49234
PPO Batch Consumption Time: 0.28931
Total Iteration Time: 4.86834

Cumulative Model Updates: 233,918
Cumulative Timesteps: 1,951,531,060

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,658.29414
Policy Entropy: 2.18807
Value Function Loss: 0.01843

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.07929
Policy Update Magnitude: 0.29407
Value Function Update Magnitude: 0.33358

Collected Steps per Second: 21,526.28346
Overall Steps per Second: 10,499.42979

Timestep Collection Time: 2.32395
Timestep Consumption Time: 2.44069
PPO Batch Consumption Time: 0.27770
Total Iteration Time: 4.76464

Cumulative Model Updates: 233,924
Cumulative Timesteps: 1,951,581,086

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1951581086...
Checkpoint 1951581086 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 64,448.03066
Policy Entropy: 2.18268
Value Function Loss: 0.01769

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.07377
Policy Update Magnitude: 0.28980
Value Function Update Magnitude: 0.30158

Collected Steps per Second: 21,245.71511
Overall Steps per Second: 10,472.37714

Timestep Collection Time: 2.35464
Timestep Consumption Time: 2.42231
PPO Batch Consumption Time: 0.27932
Total Iteration Time: 4.77695

Cumulative Model Updates: 233,930
Cumulative Timesteps: 1,951,631,112

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,041.10453
Policy Entropy: 2.20406
Value Function Loss: 0.02148

Mean KL Divergence: 0.00705
SB3 Clip Fraction: 0.06887
Policy Update Magnitude: 0.29753
Value Function Update Magnitude: 0.29348

Collected Steps per Second: 21,662.60446
Overall Steps per Second: 10,490.74656

Timestep Collection Time: 2.30868
Timestep Consumption Time: 2.45857
PPO Batch Consumption Time: 0.27880
Total Iteration Time: 4.76725

Cumulative Model Updates: 233,936
Cumulative Timesteps: 1,951,681,124

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1951681124...
Checkpoint 1951681124 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 50,857.96510
Policy Entropy: 2.18794
Value Function Loss: 0.02178

Mean KL Divergence: 0.00739
SB3 Clip Fraction: 0.07058
Policy Update Magnitude: 0.30603
Value Function Update Magnitude: 0.31877

Collected Steps per Second: 21,938.95869
Overall Steps per Second: 10,416.90755

Timestep Collection Time: 2.27914
Timestep Consumption Time: 2.52094
PPO Batch Consumption Time: 0.29059
Total Iteration Time: 4.80008

Cumulative Model Updates: 233,942
Cumulative Timesteps: 1,951,731,126

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,290.37592
Policy Entropy: 2.20494
Value Function Loss: 0.02330

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.07981
Policy Update Magnitude: 0.30282
Value Function Update Magnitude: 0.32258

Collected Steps per Second: 22,410.41556
Overall Steps per Second: 10,663.77650

Timestep Collection Time: 2.23244
Timestep Consumption Time: 2.45914
PPO Batch Consumption Time: 0.27975
Total Iteration Time: 4.69158

Cumulative Model Updates: 233,948
Cumulative Timesteps: 1,951,781,156

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1951781156...
Checkpoint 1951781156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,110.83240
Policy Entropy: 2.16923
Value Function Loss: 0.02431

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.08011
Policy Update Magnitude: 0.31508
Value Function Update Magnitude: 0.30375

Collected Steps per Second: 21,660.99605
Overall Steps per Second: 10,409.50853

Timestep Collection Time: 2.30848
Timestep Consumption Time: 2.49520
PPO Batch Consumption Time: 0.29131
Total Iteration Time: 4.80368

Cumulative Model Updates: 233,954
Cumulative Timesteps: 1,951,831,160

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,039.42919
Policy Entropy: 2.18698
Value Function Loss: 0.02251

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.08539
Policy Update Magnitude: 0.30881
Value Function Update Magnitude: 0.34650

Collected Steps per Second: 22,444.55182
Overall Steps per Second: 10,743.73425

Timestep Collection Time: 2.22860
Timestep Consumption Time: 2.42713
PPO Batch Consumption Time: 0.27965
Total Iteration Time: 4.65574

Cumulative Model Updates: 233,960
Cumulative Timesteps: 1,951,881,180

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1951881180...
Checkpoint 1951881180 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,755.89977
Policy Entropy: 2.16950
Value Function Loss: 0.02101

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.08330
Policy Update Magnitude: 0.30215
Value Function Update Magnitude: 0.35027

Collected Steps per Second: 20,920.13288
Overall Steps per Second: 10,566.47715

Timestep Collection Time: 2.39119
Timestep Consumption Time: 2.34303
PPO Batch Consumption Time: 0.27917
Total Iteration Time: 4.73422

Cumulative Model Updates: 233,966
Cumulative Timesteps: 1,951,931,204

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50,601.15591
Policy Entropy: 2.18442
Value Function Loss: 0.01819

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.07057
Policy Update Magnitude: 0.29611
Value Function Update Magnitude: 0.32609

Collected Steps per Second: 21,865.91535
Overall Steps per Second: 10,588.38029

Timestep Collection Time: 2.28703
Timestep Consumption Time: 2.43588
PPO Batch Consumption Time: 0.29370
Total Iteration Time: 4.72291

Cumulative Model Updates: 233,972
Cumulative Timesteps: 1,951,981,212

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1951981212...
Checkpoint 1951981212 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 51,761.35633
Policy Entropy: 2.17092
Value Function Loss: 0.02023

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.07259
Policy Update Magnitude: 0.29264
Value Function Update Magnitude: 0.31471

Collected Steps per Second: 21,029.22954
Overall Steps per Second: 10,288.00662

Timestep Collection Time: 2.37964
Timestep Consumption Time: 2.48447
PPO Batch Consumption Time: 0.29246
Total Iteration Time: 4.86411

Cumulative Model Updates: 233,978
Cumulative Timesteps: 1,952,031,254

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78,147.79477
Policy Entropy: 2.18298
Value Function Loss: 0.02149

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.08620
Policy Update Magnitude: 0.29114
Value Function Update Magnitude: 0.32136

Collected Steps per Second: 21,696.13795
Overall Steps per Second: 10,468.54172

Timestep Collection Time: 2.30622
Timestep Consumption Time: 2.47344
PPO Batch Consumption Time: 0.29293
Total Iteration Time: 4.77965

Cumulative Model Updates: 233,984
Cumulative Timesteps: 1,952,081,290

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1952081290...
Checkpoint 1952081290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 62,243.44238
Policy Entropy: 2.16525
Value Function Loss: 0.02168

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.08993
Policy Update Magnitude: 0.29131
Value Function Update Magnitude: 0.30289

Collected Steps per Second: 21,495.64722
Overall Steps per Second: 10,524.39541

Timestep Collection Time: 2.32624
Timestep Consumption Time: 2.42501
PPO Batch Consumption Time: 0.28368
Total Iteration Time: 4.75125

Cumulative Model Updates: 233,990
Cumulative Timesteps: 1,952,131,294

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,405.85987
Policy Entropy: 2.19194
Value Function Loss: 0.02398

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.07495
Policy Update Magnitude: 0.30256
Value Function Update Magnitude: 0.30685

Collected Steps per Second: 21,969.56915
Overall Steps per Second: 10,439.58264

Timestep Collection Time: 2.27715
Timestep Consumption Time: 2.51500
PPO Batch Consumption Time: 0.29079
Total Iteration Time: 4.79215

Cumulative Model Updates: 233,996
Cumulative Timesteps: 1,952,181,322

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1952181322...
Checkpoint 1952181322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,422.62692
Policy Entropy: 2.18805
Value Function Loss: 0.02344

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.07762
Policy Update Magnitude: 0.31193
Value Function Update Magnitude: 0.33888

Collected Steps per Second: 21,142.19916
Overall Steps per Second: 10,261.08845

Timestep Collection Time: 2.36740
Timestep Consumption Time: 2.51045
PPO Batch Consumption Time: 0.29323
Total Iteration Time: 4.87785

Cumulative Model Updates: 234,002
Cumulative Timesteps: 1,952,231,374

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,069.47492
Policy Entropy: 2.20899
Value Function Loss: 0.02140

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.07355
Policy Update Magnitude: 0.31003
Value Function Update Magnitude: 0.36204

Collected Steps per Second: 21,765.69051
Overall Steps per Second: 10,432.17298

Timestep Collection Time: 2.29774
Timestep Consumption Time: 2.49627
PPO Batch Consumption Time: 0.29389
Total Iteration Time: 4.79402

Cumulative Model Updates: 234,008
Cumulative Timesteps: 1,952,281,386

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1952281386...
Checkpoint 1952281386 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,434.32852
Policy Entropy: 2.20696
Value Function Loss: 0.01815

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.07118
Policy Update Magnitude: 0.29721
Value Function Update Magnitude: 0.32262

Collected Steps per Second: 21,979.46206
Overall Steps per Second: 10,585.67363

Timestep Collection Time: 2.27703
Timestep Consumption Time: 2.45086
PPO Batch Consumption Time: 0.27861
Total Iteration Time: 4.72790

Cumulative Model Updates: 234,014
Cumulative Timesteps: 1,952,331,434

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,360.00469
Policy Entropy: 2.20050
Value Function Loss: 0.02014

Mean KL Divergence: 0.00691
SB3 Clip Fraction: 0.06733
Policy Update Magnitude: 0.29307
Value Function Update Magnitude: 0.26095

Collected Steps per Second: 22,156.64511
Overall Steps per Second: 10,455.88512

Timestep Collection Time: 2.25675
Timestep Consumption Time: 2.52544
PPO Batch Consumption Time: 0.29280
Total Iteration Time: 4.78219

Cumulative Model Updates: 234,020
Cumulative Timesteps: 1,952,381,436

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1952381436...
Checkpoint 1952381436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,036.10320
Policy Entropy: 2.18158
Value Function Loss: 0.02396

Mean KL Divergence: 0.00713
SB3 Clip Fraction: 0.06884
Policy Update Magnitude: 0.30777
Value Function Update Magnitude: 0.29876

Collected Steps per Second: 21,651.31426
Overall Steps per Second: 10,562.53805

Timestep Collection Time: 2.30979
Timestep Consumption Time: 2.42487
PPO Batch Consumption Time: 0.27904
Total Iteration Time: 4.73466

Cumulative Model Updates: 234,026
Cumulative Timesteps: 1,952,431,446

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,304.72697
Policy Entropy: 2.18590
Value Function Loss: 0.02263

Mean KL Divergence: 0.00749
SB3 Clip Fraction: 0.07002
Policy Update Magnitude: 0.31531
Value Function Update Magnitude: 0.31791

Collected Steps per Second: 22,300.39054
Overall Steps per Second: 10,536.48116

Timestep Collection Time: 2.24211
Timestep Consumption Time: 2.50330
PPO Batch Consumption Time: 0.29144
Total Iteration Time: 4.74542

Cumulative Model Updates: 234,032
Cumulative Timesteps: 1,952,481,446

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1952481446...
Checkpoint 1952481446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,014.55854
Policy Entropy: 2.19407
Value Function Loss: 0.02295

Mean KL Divergence: 0.00782
SB3 Clip Fraction: 0.07073
Policy Update Magnitude: 0.30873
Value Function Update Magnitude: 0.30717

Collected Steps per Second: 21,855.39649
Overall Steps per Second: 10,595.97518

Timestep Collection Time: 2.28786
Timestep Consumption Time: 2.43111
PPO Batch Consumption Time: 0.27934
Total Iteration Time: 4.71896

Cumulative Model Updates: 234,038
Cumulative Timesteps: 1,952,531,448

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,300.30754
Policy Entropy: 2.19436
Value Function Loss: 0.02054

Mean KL Divergence: 0.00744
SB3 Clip Fraction: 0.06841
Policy Update Magnitude: 0.31073
Value Function Update Magnitude: 0.32272

Collected Steps per Second: 22,385.51959
Overall Steps per Second: 10,551.36093

Timestep Collection Time: 2.23430
Timestep Consumption Time: 2.50594
PPO Batch Consumption Time: 0.29268
Total Iteration Time: 4.74024

Cumulative Model Updates: 234,044
Cumulative Timesteps: 1,952,581,464

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1952581464...
Checkpoint 1952581464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,668.59588
Policy Entropy: 2.18584
Value Function Loss: 0.02215

Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.07079
Policy Update Magnitude: 0.31204
Value Function Update Magnitude: 0.33245

Collected Steps per Second: 21,683.60731
Overall Steps per Second: 10,511.30924

Timestep Collection Time: 2.30773
Timestep Consumption Time: 2.45285
PPO Batch Consumption Time: 0.27934
Total Iteration Time: 4.76059

Cumulative Model Updates: 234,050
Cumulative Timesteps: 1,952,631,504

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,925.05546
Policy Entropy: 2.20744
Value Function Loss: 0.02223

Mean KL Divergence: 0.00728
SB3 Clip Fraction: 0.06696
Policy Update Magnitude: 0.31362
Value Function Update Magnitude: 0.32552

Collected Steps per Second: 21,362.01220
Overall Steps per Second: 10,483.39627

Timestep Collection Time: 2.34070
Timestep Consumption Time: 2.42894
PPO Batch Consumption Time: 0.27905
Total Iteration Time: 4.76964

Cumulative Model Updates: 234,056
Cumulative Timesteps: 1,952,681,506

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1952681506...
Checkpoint 1952681506 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,980.39255
Policy Entropy: 2.23860
Value Function Loss: 0.02196

Mean KL Divergence: 0.00699
SB3 Clip Fraction: 0.06590
Policy Update Magnitude: 0.31334
Value Function Update Magnitude: 0.35397

Collected Steps per Second: 21,411.24219
Overall Steps per Second: 10,361.11960

Timestep Collection Time: 2.33709
Timestep Consumption Time: 2.49250
PPO Batch Consumption Time: 0.29285
Total Iteration Time: 4.82959

Cumulative Model Updates: 234,062
Cumulative Timesteps: 1,952,731,546

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,434.74044
Policy Entropy: 2.24489
Value Function Loss: 0.01857

Mean KL Divergence: 0.00758
SB3 Clip Fraction: 0.07269
Policy Update Magnitude: 0.30867
Value Function Update Magnitude: 0.33398

Collected Steps per Second: 21,579.75602
Overall Steps per Second: 10,325.30725

Timestep Collection Time: 2.31764
Timestep Consumption Time: 2.52619
PPO Batch Consumption Time: 0.29345
Total Iteration Time: 4.84383

Cumulative Model Updates: 234,068
Cumulative Timesteps: 1,952,781,560

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1952781560...
Checkpoint 1952781560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46,033.01620
Policy Entropy: 2.24544
Value Function Loss: 0.02060

Mean KL Divergence: 0.00687
SB3 Clip Fraction: 0.06584
Policy Update Magnitude: 0.30177
Value Function Update Magnitude: 0.31009

Collected Steps per Second: 21,205.06311
Overall Steps per Second: 10,281.60977

Timestep Collection Time: 2.35830
Timestep Consumption Time: 2.50553
PPO Batch Consumption Time: 0.29386
Total Iteration Time: 4.86383

Cumulative Model Updates: 234,074
Cumulative Timesteps: 1,952,831,568

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,278.88159
Policy Entropy: 2.23199
Value Function Loss: 0.01987

Mean KL Divergence: 0.00678
SB3 Clip Fraction: 0.06467
Policy Update Magnitude: 0.30212
Value Function Update Magnitude: 0.31590

Collected Steps per Second: 21,744.84512
Overall Steps per Second: 10,395.94040

Timestep Collection Time: 2.29995
Timestep Consumption Time: 2.51078
PPO Batch Consumption Time: 0.28920
Total Iteration Time: 4.81072

Cumulative Model Updates: 234,080
Cumulative Timesteps: 1,952,881,580

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1952881580...
Checkpoint 1952881580 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,593.41164
Policy Entropy: 2.24397
Value Function Loss: 0.02124

Mean KL Divergence: 0.00759
SB3 Clip Fraction: 0.07019
Policy Update Magnitude: 0.29875
Value Function Update Magnitude: 0.27841

Collected Steps per Second: 21,805.04513
Overall Steps per Second: 10,327.96831

Timestep Collection Time: 2.29470
Timestep Consumption Time: 2.55001
PPO Batch Consumption Time: 0.29240
Total Iteration Time: 4.84471

Cumulative Model Updates: 234,086
Cumulative Timesteps: 1,952,931,616

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 64,313.77177
Policy Entropy: 2.24008
Value Function Loss: 0.01965

Mean KL Divergence: 0.00712
SB3 Clip Fraction: 0.06782
Policy Update Magnitude: 0.29618
Value Function Update Magnitude: 0.27465

Collected Steps per Second: 22,205.45038
Overall Steps per Second: 10,658.58352

Timestep Collection Time: 2.25179
Timestep Consumption Time: 2.43945
PPO Batch Consumption Time: 0.27905
Total Iteration Time: 4.69124

Cumulative Model Updates: 234,092
Cumulative Timesteps: 1,952,981,618

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1952981618...
Checkpoint 1952981618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 64,313.77177
Policy Entropy: 2.23417
Value Function Loss: 0.01726

Mean KL Divergence: 0.00730
SB3 Clip Fraction: 0.07068
Policy Update Magnitude: 0.28708
Value Function Update Magnitude: 0.29013

Collected Steps per Second: 21,694.42300
Overall Steps per Second: 10,390.53630

Timestep Collection Time: 2.30557
Timestep Consumption Time: 2.50823
PPO Batch Consumption Time: 0.29288
Total Iteration Time: 4.81380

Cumulative Model Updates: 234,098
Cumulative Timesteps: 1,953,031,636

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 64,891.82210
Policy Entropy: 2.23537
Value Function Loss: 0.01659

Mean KL Divergence: 0.00701
SB3 Clip Fraction: 0.06755
Policy Update Magnitude: 0.28680
Value Function Update Magnitude: 0.27586

Collected Steps per Second: 22,269.18896
Overall Steps per Second: 10,580.63201

Timestep Collection Time: 2.24660
Timestep Consumption Time: 2.48185
PPO Batch Consumption Time: 0.28909
Total Iteration Time: 4.72845

Cumulative Model Updates: 234,104
Cumulative Timesteps: 1,953,081,666

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1953081666...
Checkpoint 1953081666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86,826.73597
Policy Entropy: 2.22426
Value Function Loss: 0.01722

Mean KL Divergence: 0.00727
SB3 Clip Fraction: 0.06917
Policy Update Magnitude: 0.28670
Value Function Update Magnitude: 0.27787

Collected Steps per Second: 19,879.39079
Overall Steps per Second: 10,138.04863

Timestep Collection Time: 2.51637
Timestep Consumption Time: 2.41791
PPO Batch Consumption Time: 0.29261
Total Iteration Time: 4.93428

Cumulative Model Updates: 234,110
Cumulative Timesteps: 1,953,131,690

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87,721.53134
Policy Entropy: 2.21769
Value Function Loss: 0.01871

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.06999
Policy Update Magnitude: 0.29276
Value Function Update Magnitude: 0.30461

Collected Steps per Second: 21,194.41031
Overall Steps per Second: 10,454.94535

Timestep Collection Time: 2.36119
Timestep Consumption Time: 2.42545
PPO Batch Consumption Time: 0.29178
Total Iteration Time: 4.78663

Cumulative Model Updates: 234,116
Cumulative Timesteps: 1,953,181,734

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1953181734...
Checkpoint 1953181734 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 72,192.24248
Policy Entropy: 2.20562
Value Function Loss: 0.02129

Mean KL Divergence: 0.00723
SB3 Clip Fraction: 0.06525
Policy Update Magnitude: 0.29748
Value Function Update Magnitude: 0.32524

Collected Steps per Second: 20,769.54538
Overall Steps per Second: 10,483.01537

Timestep Collection Time: 2.40814
Timestep Consumption Time: 2.36300
PPO Batch Consumption Time: 0.27953
Total Iteration Time: 4.77115

Cumulative Model Updates: 234,122
Cumulative Timesteps: 1,953,231,750

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,317.77297
Policy Entropy: 2.21018
Value Function Loss: 0.02268

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.07009
Policy Update Magnitude: 0.30863
Value Function Update Magnitude: 0.33125

Collected Steps per Second: 21,124.77099
Overall Steps per Second: 10,440.80072

Timestep Collection Time: 2.36869
Timestep Consumption Time: 2.42386
PPO Batch Consumption Time: 0.27915
Total Iteration Time: 4.79254

Cumulative Model Updates: 234,128
Cumulative Timesteps: 1,953,281,788

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1953281788...
Checkpoint 1953281788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,955.34381
Policy Entropy: 2.19900
Value Function Loss: 0.02442

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.08125
Policy Update Magnitude: 0.31600
Value Function Update Magnitude: 0.35546

Collected Steps per Second: 21,832.37255
Overall Steps per Second: 10,573.34051

Timestep Collection Time: 2.29256
Timestep Consumption Time: 2.44123
PPO Batch Consumption Time: 0.27810
Total Iteration Time: 4.73379

Cumulative Model Updates: 234,134
Cumulative Timesteps: 1,953,331,840

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45,041.70272
Policy Entropy: 2.19311
Value Function Loss: 0.02328

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.08154
Policy Update Magnitude: 0.31171
Value Function Update Magnitude: 0.36555

Collected Steps per Second: 21,986.93975
Overall Steps per Second: 10,515.99146

Timestep Collection Time: 2.27426
Timestep Consumption Time: 2.48078
PPO Batch Consumption Time: 0.28897
Total Iteration Time: 4.75504

Cumulative Model Updates: 234,140
Cumulative Timesteps: 1,953,381,844

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1953381844...
Checkpoint 1953381844 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,729.53226
Policy Entropy: 2.19011
Value Function Loss: 0.02187

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.08242
Policy Update Magnitude: 0.31218
Value Function Update Magnitude: 0.36560

Collected Steps per Second: 22,094.75509
Overall Steps per Second: 10,740.25760

Timestep Collection Time: 2.26343
Timestep Consumption Time: 2.39288
PPO Batch Consumption Time: 0.27823
Total Iteration Time: 4.65631

Cumulative Model Updates: 234,146
Cumulative Timesteps: 1,953,431,854

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49,968.53616
Policy Entropy: 2.20008
Value Function Loss: 0.02059

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.08089
Policy Update Magnitude: 0.31415
Value Function Update Magnitude: 0.33877

Collected Steps per Second: 22,281.69493
Overall Steps per Second: 10,551.92800

Timestep Collection Time: 2.24435
Timestep Consumption Time: 2.49488
PPO Batch Consumption Time: 0.29081
Total Iteration Time: 4.73923

Cumulative Model Updates: 234,152
Cumulative Timesteps: 1,953,481,862

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1953481862...
Checkpoint 1953481862 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,499.42215
Policy Entropy: 2.20466
Value Function Loss: 0.02079

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.08054
Policy Update Magnitude: 0.31130
Value Function Update Magnitude: 0.31506

Collected Steps per Second: 22,292.02102
Overall Steps per Second: 10,525.18040

Timestep Collection Time: 2.24295
Timestep Consumption Time: 2.50756
PPO Batch Consumption Time: 0.29405
Total Iteration Time: 4.75051

Cumulative Model Updates: 234,158
Cumulative Timesteps: 1,953,531,862

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63,488.40326
Policy Entropy: 2.21242
Value Function Loss: 0.01922

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.08139
Policy Update Magnitude: 0.30491
Value Function Update Magnitude: 0.32938

Collected Steps per Second: 22,187.50007
Overall Steps per Second: 10,512.79603

Timestep Collection Time: 2.25568
Timestep Consumption Time: 2.50499
PPO Batch Consumption Time: 0.29324
Total Iteration Time: 4.76067

Cumulative Model Updates: 234,164
Cumulative Timesteps: 1,953,581,910

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 1953581910...
Checkpoint 1953581910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 54,963.80378
Policy Entropy: 2.19729
Value Function Loss: 0.01803

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.07890
Policy Update Magnitude: 0.29720
Value Function Update Magnitude: 0.28840

Collected Steps per Second: 21,439.58504
Overall Steps per Second: 10,494.76329

Timestep Collection Time: 2.33335
Timestep Consumption Time: 2.43341
PPO Batch Consumption Time: 0.27901
Total Iteration Time: 4.76676

Cumulative Model Updates: 234,170
Cumulative Timesteps: 1,953,631,936

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,004.15079
Policy Entropy: 2.20214
Value Function Loss: 0.01860

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.08292
Policy Update Magnitude: 0.29575
Value Function Update Magnitude: 0.26510

Collected Steps per Second: 21,272.20069
Overall Steps per Second: 10,468.63236

Timestep Collection Time: 2.35274
Timestep Consumption Time: 2.42802
PPO Batch Consumption Time: 0.27840
Total Iteration Time: 4.78076

Cumulative Model Updates: 234,176
Cumulative Timesteps: 1,953,681,984

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 1953681984...
Checkpoint 1953681984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,045.06412
Policy Entropy: 2.18463
Value Function Loss: 0.01841

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.08064
Policy Update Magnitude: 0.29536
Value Function Update Magnitude: 0.29052

Collected Steps per Second: 21,524.32439
Overall Steps per Second: 10,394.60298

Timestep Collection Time: 2.32509
Timestep Consumption Time: 2.48952
PPO Batch Consumption Time: 0.29226
Total Iteration Time: 4.81461

Cumulative Model Updates: 234,182
Cumulative Timesteps: 1,953,732,030

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45,545.20861
Policy Entropy: 2.20244
Value Function Loss: 0.01867

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.07352
Policy Update Magnitude: 0.29846
Value Function Update Magnitude: 0.31289

Collected Steps per Second: 21,739.59247
Overall Steps per Second: 10,395.91501

Timestep Collection Time: 2.30078
Timestep Consumption Time: 2.51053
PPO Batch Consumption Time: 0.29339
Total Iteration Time: 4.81131

Cumulative Model Updates: 234,188
Cumulative Timesteps: 1,953,782,048

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1953782048...
Checkpoint 1953782048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 51,906.47298
Policy Entropy: 2.19841
Value Function Loss: 0.02005

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.07604
Policy Update Magnitude: 0.30774
Value Function Update Magnitude: 0.31140

Collected Steps per Second: 21,478.28077
Overall Steps per Second: 10,570.56017

Timestep Collection Time: 2.32812
Timestep Consumption Time: 2.40238
PPO Batch Consumption Time: 0.28451
Total Iteration Time: 4.73050

Cumulative Model Updates: 234,194
Cumulative Timesteps: 1,953,832,052

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 71,250.88205
Policy Entropy: 2.19706
Value Function Loss: 0.02166

Mean KL Divergence: 0.00766
SB3 Clip Fraction: 0.07084
Policy Update Magnitude: 0.31652
Value Function Update Magnitude: 0.29054

Collected Steps per Second: 21,476.48241
Overall Steps per Second: 10,496.08143

Timestep Collection Time: 2.32999
Timestep Consumption Time: 2.43750
PPO Batch Consumption Time: 0.29205
Total Iteration Time: 4.76749

Cumulative Model Updates: 234,200
Cumulative Timesteps: 1,953,882,092

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1953882092...
Checkpoint 1953882092 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 58,100.60062
Policy Entropy: 2.20567
Value Function Loss: 0.02347

Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.07420
Policy Update Magnitude: 0.30804
Value Function Update Magnitude: 0.28002

Collected Steps per Second: 21,036.28846
Overall Steps per Second: 10,563.24771

Timestep Collection Time: 2.37808
Timestep Consumption Time: 2.35777
PPO Batch Consumption Time: 0.27991
Total Iteration Time: 4.73585

Cumulative Model Updates: 234,206
Cumulative Timesteps: 1,953,932,118

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78,085.93986
Policy Entropy: 2.21338
Value Function Loss: 0.02275

Mean KL Divergence: 0.00749
SB3 Clip Fraction: 0.07294
Policy Update Magnitude: 0.30470
Value Function Update Magnitude: 0.30338

Collected Steps per Second: 21,437.49341
Overall Steps per Second: 10,426.64779

Timestep Collection Time: 2.33292
Timestep Consumption Time: 2.46363
PPO Batch Consumption Time: 0.28616
Total Iteration Time: 4.79656

Cumulative Model Updates: 234,212
Cumulative Timesteps: 1,953,982,130

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1953982130...
Checkpoint 1953982130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,173.99456
Policy Entropy: 2.22645
Value Function Loss: 0.02228

Mean KL Divergence: 0.00682
SB3 Clip Fraction: 0.06515
Policy Update Magnitude: 0.30706
Value Function Update Magnitude: 0.31505

Collected Steps per Second: 21,529.92725
Overall Steps per Second: 10,587.57798

Timestep Collection Time: 2.32337
Timestep Consumption Time: 2.40122
PPO Batch Consumption Time: 0.27925
Total Iteration Time: 4.72459

Cumulative Model Updates: 234,218
Cumulative Timesteps: 1,954,032,152

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,687.66176
Policy Entropy: 2.20630
Value Function Loss: 0.02377

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.07937
Policy Update Magnitude: 0.31452
Value Function Update Magnitude: 0.29376

Collected Steps per Second: 21,980.91318
Overall Steps per Second: 10,554.11063

Timestep Collection Time: 2.27670
Timestep Consumption Time: 2.46496
PPO Batch Consumption Time: 0.28970
Total Iteration Time: 4.74166

Cumulative Model Updates: 234,224
Cumulative Timesteps: 1,954,082,196

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1954082196...
Checkpoint 1954082196 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55,483.89379
Policy Entropy: 2.20202
Value Function Loss: 0.02357

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.08307
Policy Update Magnitude: 0.31304
Value Function Update Magnitude: 0.27167

Collected Steps per Second: 21,902.34714
Overall Steps per Second: 10,678.05044

Timestep Collection Time: 2.28313
Timestep Consumption Time: 2.39993
PPO Batch Consumption Time: 0.27739
Total Iteration Time: 4.68306

Cumulative Model Updates: 234,230
Cumulative Timesteps: 1,954,132,202

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42,222.64352
Policy Entropy: 2.19225
Value Function Loss: 0.02348

Mean KL Divergence: 0.01185
SB3 Clip Fraction: 0.08865
Policy Update Magnitude: 0.30825
Value Function Update Magnitude: 0.31219

Collected Steps per Second: 21,583.88456
Overall Steps per Second: 10,394.22652

Timestep Collection Time: 2.31691
Timestep Consumption Time: 2.49422
PPO Batch Consumption Time: 0.28823
Total Iteration Time: 4.81113

Cumulative Model Updates: 234,236
Cumulative Timesteps: 1,954,182,210

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1954182210...
Checkpoint 1954182210 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,290.45804
Policy Entropy: 2.20576
Value Function Loss: 0.02176

Mean KL Divergence: 0.02305
SB3 Clip Fraction: 0.07734
Policy Update Magnitude: 0.31106
Value Function Update Magnitude: 0.31596

Collected Steps per Second: 21,468.15641
Overall Steps per Second: 10,363.63261

Timestep Collection Time: 2.32931
Timestep Consumption Time: 2.49583
PPO Batch Consumption Time: 0.29055
Total Iteration Time: 4.82514

Cumulative Model Updates: 234,242
Cumulative Timesteps: 1,954,232,216

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,456.88139
Policy Entropy: 2.21119
Value Function Loss: 0.02172

Mean KL Divergence: 0.02443
SB3 Clip Fraction: 0.08592
Policy Update Magnitude: 0.30167
Value Function Update Magnitude: 0.29404

Collected Steps per Second: 21,745.36467
Overall Steps per Second: 10,403.34876

Timestep Collection Time: 2.30146
Timestep Consumption Time: 2.50911
PPO Batch Consumption Time: 0.29258
Total Iteration Time: 4.81057

Cumulative Model Updates: 234,248
Cumulative Timesteps: 1,954,282,262

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1954282262...
Checkpoint 1954282262 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43,763.04630
Policy Entropy: 2.20885
Value Function Loss: 0.02050

Mean KL Divergence: 0.00689
SB3 Clip Fraction: 0.06680
Policy Update Magnitude: 0.30115
Value Function Update Magnitude: 0.28957

Collected Steps per Second: 21,890.55659
Overall Steps per Second: 10,526.78848

Timestep Collection Time: 2.28418
Timestep Consumption Time: 2.46580
PPO Batch Consumption Time: 0.28586
Total Iteration Time: 4.74998

Cumulative Model Updates: 234,254
Cumulative Timesteps: 1,954,332,264

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,064.49410
Policy Entropy: 2.19747
Value Function Loss: 0.02021

Mean KL Divergence: 0.00744
SB3 Clip Fraction: 0.06997
Policy Update Magnitude: 0.30644
Value Function Update Magnitude: 0.31576

Collected Steps per Second: 21,663.59204
Overall Steps per Second: 10,476.94652

Timestep Collection Time: 2.30922
Timestep Consumption Time: 2.46564
PPO Batch Consumption Time: 0.27942
Total Iteration Time: 4.77486

Cumulative Model Updates: 234,260
Cumulative Timesteps: 1,954,382,290

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1954382290...
Checkpoint 1954382290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 59,508.16246
Policy Entropy: 2.17896
Value Function Loss: 0.02193

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.07712
Policy Update Magnitude: 0.31472
Value Function Update Magnitude: 0.34355

Collected Steps per Second: 21,609.47695
Overall Steps per Second: 10,293.15443

Timestep Collection Time: 2.31426
Timestep Consumption Time: 2.54431
PPO Batch Consumption Time: 0.29343
Total Iteration Time: 4.85857

Cumulative Model Updates: 234,266
Cumulative Timesteps: 1,954,432,300

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42,418.37260
Policy Entropy: 2.19040
Value Function Loss: 0.02343

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.07800
Policy Update Magnitude: 0.31972
Value Function Update Magnitude: 0.36361

Collected Steps per Second: 21,936.49702
Overall Steps per Second: 10,400.92501

Timestep Collection Time: 2.28058
Timestep Consumption Time: 2.52937
PPO Batch Consumption Time: 0.29204
Total Iteration Time: 4.80996

Cumulative Model Updates: 234,272
Cumulative Timesteps: 1,954,482,328

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1954482328...
Checkpoint 1954482328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,200.60707
Policy Entropy: 2.19082
Value Function Loss: 0.02128

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.08540
Policy Update Magnitude: 0.31318
Value Function Update Magnitude: 0.35943

Collected Steps per Second: 21,998.02693
Overall Steps per Second: 10,653.12758

Timestep Collection Time: 2.27493
Timestep Consumption Time: 2.42266
PPO Batch Consumption Time: 0.27797
Total Iteration Time: 4.69759

Cumulative Model Updates: 234,278
Cumulative Timesteps: 1,954,532,372

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,475.17540
Policy Entropy: 2.17809
Value Function Loss: 0.01990

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.08548
Policy Update Magnitude: 0.30868
Value Function Update Magnitude: 0.32533

Collected Steps per Second: 22,099.08933
Overall Steps per Second: 10,458.19606

Timestep Collection Time: 2.26435
Timestep Consumption Time: 2.52042
PPO Batch Consumption Time: 0.29455
Total Iteration Time: 4.78476

Cumulative Model Updates: 234,284
Cumulative Timesteps: 1,954,582,412

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1954582412...
Checkpoint 1954582412 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 51,338.02156
Policy Entropy: 2.15057
Value Function Loss: 0.01945

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.08488
Policy Update Magnitude: 0.30531
Value Function Update Magnitude: 0.30943

Collected Steps per Second: 21,726.61014
Overall Steps per Second: 10,563.98472

Timestep Collection Time: 2.30252
Timestep Consumption Time: 2.43300
PPO Batch Consumption Time: 0.27956
Total Iteration Time: 4.73552

Cumulative Model Updates: 234,290
Cumulative Timesteps: 1,954,632,438

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61,641.09887
Policy Entropy: 2.15610
Value Function Loss: 0.02125

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.07671
Policy Update Magnitude: 0.31150
Value Function Update Magnitude: 0.31325

Collected Steps per Second: 21,653.78487
Overall Steps per Second: 10,567.13667

Timestep Collection Time: 2.30943
Timestep Consumption Time: 2.42297
PPO Batch Consumption Time: 0.27793
Total Iteration Time: 4.73241

Cumulative Model Updates: 234,296
Cumulative Timesteps: 1,954,682,446

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1954682446...
Checkpoint 1954682446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 69,823.72295
Policy Entropy: 2.16874
Value Function Loss: 0.02060

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.08585
Policy Update Magnitude: 0.30959
Value Function Update Magnitude: 0.31605

Collected Steps per Second: 21,956.56150
Overall Steps per Second: 10,582.26639

Timestep Collection Time: 2.27886
Timestep Consumption Time: 2.44942
PPO Batch Consumption Time: 0.28368
Total Iteration Time: 4.72829

Cumulative Model Updates: 234,302
Cumulative Timesteps: 1,954,732,482

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60,306.42015
Policy Entropy: 2.18157
Value Function Loss: 0.01845

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.07370
Policy Update Magnitude: 0.30238
Value Function Update Magnitude: 0.30275

Collected Steps per Second: 21,676.85640
Overall Steps per Second: 10,407.72683

Timestep Collection Time: 2.30744
Timestep Consumption Time: 2.49841
PPO Batch Consumption Time: 0.28975
Total Iteration Time: 4.80585

Cumulative Model Updates: 234,308
Cumulative Timesteps: 1,954,782,500

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1954782500...
Checkpoint 1954782500 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 64,333.61901
Policy Entropy: 2.19006
Value Function Loss: 0.02014

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.08794
Policy Update Magnitude: 0.29862
Value Function Update Magnitude: 0.27348

Collected Steps per Second: 21,038.55921
Overall Steps per Second: 10,232.50630

Timestep Collection Time: 2.37763
Timestep Consumption Time: 2.51090
PPO Batch Consumption Time: 0.29405
Total Iteration Time: 4.88854

Cumulative Model Updates: 234,314
Cumulative Timesteps: 1,954,832,522

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,640.14373
Policy Entropy: 2.19469
Value Function Loss: 0.02143

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.08806
Policy Update Magnitude: 0.31104
Value Function Update Magnitude: 0.28883

Collected Steps per Second: 21,068.20882
Overall Steps per Second: 10,487.57032

Timestep Collection Time: 2.37391
Timestep Consumption Time: 2.39497
PPO Batch Consumption Time: 0.28514
Total Iteration Time: 4.76888

Cumulative Model Updates: 234,320
Cumulative Timesteps: 1,954,882,536

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1954882536...
Checkpoint 1954882536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,170.86483
Policy Entropy: 2.21846
Value Function Loss: 0.02280

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.08766
Policy Update Magnitude: 0.30788
Value Function Update Magnitude: 0.29563

Collected Steps per Second: 20,710.16903
Overall Steps per Second: 10,332.77150

Timestep Collection Time: 2.41562
Timestep Consumption Time: 2.42606
PPO Batch Consumption Time: 0.29251
Total Iteration Time: 4.84168

Cumulative Model Updates: 234,326
Cumulative Timesteps: 1,954,932,564

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51,346.61006
Policy Entropy: 2.21832
Value Function Loss: 0.02001

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.08232
Policy Update Magnitude: 0.30400
Value Function Update Magnitude: 0.29516

Collected Steps per Second: 21,198.55929
Overall Steps per Second: 10,357.73267

Timestep Collection Time: 2.35997
Timestep Consumption Time: 2.47004
PPO Batch Consumption Time: 0.29362
Total Iteration Time: 4.83001

Cumulative Model Updates: 234,332
Cumulative Timesteps: 1,954,982,592

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1954982592...
Checkpoint 1954982592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40,663.86150
Policy Entropy: 2.21129
Value Function Loss: 0.02067

Mean KL Divergence: 0.00732
SB3 Clip Fraction: 0.06974
Policy Update Magnitude: 0.29751
Value Function Update Magnitude: 0.30443

Collected Steps per Second: 20,853.59701
Overall Steps per Second: 10,206.31601

Timestep Collection Time: 2.39920
Timestep Consumption Time: 2.50286
PPO Batch Consumption Time: 0.29317
Total Iteration Time: 4.90206

Cumulative Model Updates: 234,338
Cumulative Timesteps: 1,955,032,624

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,663.86150
Policy Entropy: 2.20381
Value Function Loss: 0.01875

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.07678
Policy Update Magnitude: 0.29678
Value Function Update Magnitude: 0.28030

Collected Steps per Second: 22,128.57097
Overall Steps per Second: 10,460.26702

Timestep Collection Time: 2.25961
Timestep Consumption Time: 2.52057
PPO Batch Consumption Time: 0.29359
Total Iteration Time: 4.78018

Cumulative Model Updates: 234,344
Cumulative Timesteps: 1,955,082,626

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1955082626...
Checkpoint 1955082626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 50,515.68244
Policy Entropy: 2.19298
Value Function Loss: 0.01751

Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.07589
Policy Update Magnitude: 0.28986
Value Function Update Magnitude: 0.27391

Collected Steps per Second: 21,793.50830
Overall Steps per Second: 10,643.39869

Timestep Collection Time: 2.29481
Timestep Consumption Time: 2.40406
PPO Batch Consumption Time: 0.27779
Total Iteration Time: 4.69887

Cumulative Model Updates: 234,350
Cumulative Timesteps: 1,955,132,638

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47,864.72367
Policy Entropy: 2.19181
Value Function Loss: 0.01868

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.08208
Policy Update Magnitude: 0.29697
Value Function Update Magnitude: 0.28734

Collected Steps per Second: 22,154.48442
Overall Steps per Second: 10,518.69282

Timestep Collection Time: 2.25841
Timestep Consumption Time: 2.49826
PPO Batch Consumption Time: 0.29170
Total Iteration Time: 4.75667

Cumulative Model Updates: 234,356
Cumulative Timesteps: 1,955,182,672

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1955182672...
Checkpoint 1955182672 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,647.76557
Policy Entropy: 2.19628
Value Function Loss: 0.02077

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.08667
Policy Update Magnitude: 0.30482
Value Function Update Magnitude: 0.32251

Collected Steps per Second: 22,083.40457
Overall Steps per Second: 10,497.18156

Timestep Collection Time: 2.26478
Timestep Consumption Time: 2.49974
PPO Batch Consumption Time: 0.28977
Total Iteration Time: 4.76452

Cumulative Model Updates: 234,362
Cumulative Timesteps: 1,955,232,686

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,369.29574
Policy Entropy: 2.19131
Value Function Loss: 0.02307

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.08093
Policy Update Magnitude: 0.30803
Value Function Update Magnitude: 0.32574

Collected Steps per Second: 21,997.02672
Overall Steps per Second: 10,453.84687

Timestep Collection Time: 2.27358
Timestep Consumption Time: 2.51050
PPO Batch Consumption Time: 0.29106
Total Iteration Time: 4.78408

Cumulative Model Updates: 234,368
Cumulative Timesteps: 1,955,282,698

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1955282698...
Checkpoint 1955282698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 57,480.14002
Policy Entropy: 2.20259
Value Function Loss: 0.02601

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.07930
Policy Update Magnitude: 0.32309
Value Function Update Magnitude: 0.33905

Collected Steps per Second: 21,889.17488
Overall Steps per Second: 10,625.51715

Timestep Collection Time: 2.28487
Timestep Consumption Time: 2.42210
PPO Batch Consumption Time: 0.27851
Total Iteration Time: 4.70697

Cumulative Model Updates: 234,374
Cumulative Timesteps: 1,955,332,712

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 64,631.24862
Policy Entropy: 2.19790
Value Function Loss: 0.02219

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.08626
Policy Update Magnitude: 0.31639
Value Function Update Magnitude: 0.36217

Collected Steps per Second: 21,799.45850
Overall Steps per Second: 10,449.92724

Timestep Collection Time: 2.29373
Timestep Consumption Time: 2.49119
PPO Batch Consumption Time: 0.28811
Total Iteration Time: 4.78491

Cumulative Model Updates: 234,380
Cumulative Timesteps: 1,955,382,714

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1955382714...
Checkpoint 1955382714 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 64,630.24914
Policy Entropy: 2.19674
Value Function Loss: 0.02184

Mean KL Divergence: 0.01103
SB3 Clip Fraction: 0.09384
Policy Update Magnitude: 0.30641
Value Function Update Magnitude: 0.33747

Collected Steps per Second: 21,358.57700
Overall Steps per Second: 10,313.19542

Timestep Collection Time: 2.34164
Timestep Consumption Time: 2.50788
PPO Batch Consumption Time: 0.29391
Total Iteration Time: 4.84952

Cumulative Model Updates: 234,386
Cumulative Timesteps: 1,955,432,728

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57,529.23277
Policy Entropy: 2.18130
Value Function Loss: 0.02200

Mean KL Divergence: 0.01302
SB3 Clip Fraction: 0.10744
Policy Update Magnitude: 0.29132
Value Function Update Magnitude: 0.31812

Collected Steps per Second: 21,491.07823
Overall Steps per Second: 10,379.63169

Timestep Collection Time: 2.32785
Timestep Consumption Time: 2.49197
PPO Batch Consumption Time: 0.28991
Total Iteration Time: 4.81982

Cumulative Model Updates: 234,392
Cumulative Timesteps: 1,955,482,756

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1955482756...
Checkpoint 1955482756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46,881.36664
Policy Entropy: 2.18430
Value Function Loss: 0.02563

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.08826
Policy Update Magnitude: 0.30971
Value Function Update Magnitude: 0.36309

Collected Steps per Second: 21,264.91064
Overall Steps per Second: 10,221.61176

Timestep Collection Time: 2.35251
Timestep Consumption Time: 2.54163
PPO Batch Consumption Time: 0.29518
Total Iteration Time: 4.89414

Cumulative Model Updates: 234,398
Cumulative Timesteps: 1,955,532,782

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,784.73963
Policy Entropy: 2.18396
Value Function Loss: 0.02480

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.08243
Policy Update Magnitude: 0.32462
Value Function Update Magnitude: 0.38835

Collected Steps per Second: 22,107.71242
Overall Steps per Second: 10,429.36253

Timestep Collection Time: 2.26238
Timestep Consumption Time: 2.53331
PPO Batch Consumption Time: 0.28737
Total Iteration Time: 4.79569

Cumulative Model Updates: 234,404
Cumulative Timesteps: 1,955,582,798

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1955582798...
Checkpoint 1955582798 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,093.09446
Policy Entropy: 2.20078
Value Function Loss: 0.02180

Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.07547
Policy Update Magnitude: 0.31778
Value Function Update Magnitude: 0.37766

Collected Steps per Second: 21,930.38971
Overall Steps per Second: 10,597.74856

Timestep Collection Time: 2.28167
Timestep Consumption Time: 2.43989
PPO Batch Consumption Time: 0.27817
Total Iteration Time: 4.72157

Cumulative Model Updates: 234,410
Cumulative Timesteps: 1,955,632,836

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66,436.49570
Policy Entropy: 2.20132
Value Function Loss: 0.01857

Mean KL Divergence: 0.00757
SB3 Clip Fraction: 0.07024
Policy Update Magnitude: 0.30004
Value Function Update Magnitude: 0.33084

Collected Steps per Second: 22,032.99962
Overall Steps per Second: 10,511.02342

Timestep Collection Time: 2.26941
Timestep Consumption Time: 2.48769
PPO Batch Consumption Time: 0.28938
Total Iteration Time: 4.75710

Cumulative Model Updates: 234,416
Cumulative Timesteps: 1,955,682,838

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1955682838...
Checkpoint 1955682838 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 63,189.37798
Policy Entropy: 2.19540
Value Function Loss: 0.01835

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.07474
Policy Update Magnitude: 0.29679
Value Function Update Magnitude: 0.30547

Collected Steps per Second: 22,101.64149
Overall Steps per Second: 10,655.63927

Timestep Collection Time: 2.26436
Timestep Consumption Time: 2.43231
PPO Batch Consumption Time: 0.27795
Total Iteration Time: 4.69667

Cumulative Model Updates: 234,422
Cumulative Timesteps: 1,955,732,884

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,222.12833
Policy Entropy: 2.18730
Value Function Loss: 0.02276

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.07455
Policy Update Magnitude: 0.30746
Value Function Update Magnitude: 0.31492

Collected Steps per Second: 22,252.72767
Overall Steps per Second: 10,544.53739

Timestep Collection Time: 2.24790
Timestep Consumption Time: 2.49597
PPO Batch Consumption Time: 0.29248
Total Iteration Time: 4.74388

Cumulative Model Updates: 234,428
Cumulative Timesteps: 1,955,782,906

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1955782906...
Checkpoint 1955782906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,074.95244
Policy Entropy: 2.15901
Value Function Loss: 0.02315

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.07610
Policy Update Magnitude: 0.31613
Value Function Update Magnitude: 0.34467

Collected Steps per Second: 21,165.65354
Overall Steps per Second: 10,594.24287

Timestep Collection Time: 2.36355
Timestep Consumption Time: 2.35845
PPO Batch Consumption Time: 0.27775
Total Iteration Time: 4.72200

Cumulative Model Updates: 234,434
Cumulative Timesteps: 1,955,832,932

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66,056.79581
Policy Entropy: 2.18049
Value Function Loss: 0.02366

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.07374
Policy Update Magnitude: 0.32260
Value Function Update Magnitude: 0.35373

Collected Steps per Second: 21,330.09928
Overall Steps per Second: 10,487.58792

Timestep Collection Time: 2.34504
Timestep Consumption Time: 2.42440
PPO Batch Consumption Time: 0.29339
Total Iteration Time: 4.76945

Cumulative Model Updates: 234,440
Cumulative Timesteps: 1,955,882,952

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1955882952...
Checkpoint 1955882952 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,851.18233
Policy Entropy: 2.19860
Value Function Loss: 0.02519

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.07203
Policy Update Magnitude: 0.32186
Value Function Update Magnitude: 0.32728

Collected Steps per Second: 20,910.30364
Overall Steps per Second: 10,537.95961

Timestep Collection Time: 2.39145
Timestep Consumption Time: 2.35387
PPO Batch Consumption Time: 0.27942
Total Iteration Time: 4.74532

Cumulative Model Updates: 234,446
Cumulative Timesteps: 1,955,932,958

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42,999.15196
Policy Entropy: 2.21616
Value Function Loss: 0.02789

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.07635
Policy Update Magnitude: 0.32818
Value Function Update Magnitude: 0.27680

Collected Steps per Second: 21,123.55034
Overall Steps per Second: 10,476.96002

Timestep Collection Time: 2.36722
Timestep Consumption Time: 2.40554
PPO Batch Consumption Time: 0.27878
Total Iteration Time: 4.77276

Cumulative Model Updates: 234,452
Cumulative Timesteps: 1,955,982,962

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1955982962...
Checkpoint 1955982962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,433.61880
Policy Entropy: 2.21882
Value Function Loss: 0.02631

Mean KL Divergence: 0.00777
SB3 Clip Fraction: 0.07545
Policy Update Magnitude: 0.32638
Value Function Update Magnitude: 0.28295

Collected Steps per Second: 21,587.96895
Overall Steps per Second: 10,585.71817

Timestep Collection Time: 2.31722
Timestep Consumption Time: 2.40840
PPO Batch Consumption Time: 0.27894
Total Iteration Time: 4.72561

Cumulative Model Updates: 234,458
Cumulative Timesteps: 1,956,032,986

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,678.99811
Policy Entropy: 2.19697
Value Function Loss: 0.02120

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.07544
Policy Update Magnitude: 0.31350
Value Function Update Magnitude: 0.28792

Collected Steps per Second: 21,431.50781
Overall Steps per Second: 10,563.69321

Timestep Collection Time: 2.33329
Timestep Consumption Time: 2.40047
PPO Batch Consumption Time: 0.27823
Total Iteration Time: 4.73376

Cumulative Model Updates: 234,464
Cumulative Timesteps: 1,956,082,992

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1956082992...
Checkpoint 1956082992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47,643.51547
Policy Entropy: 2.20445
Value Function Loss: 0.01924

Mean KL Divergence: 0.00684
SB3 Clip Fraction: 0.06589
Policy Update Magnitude: 0.30551
Value Function Update Magnitude: 0.24634

Collected Steps per Second: 21,509.67529
Overall Steps per Second: 10,489.32082

Timestep Collection Time: 2.32565
Timestep Consumption Time: 2.44339
PPO Batch Consumption Time: 0.27908
Total Iteration Time: 4.76904

Cumulative Model Updates: 234,470
Cumulative Timesteps: 1,956,133,016

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42,738.62270
Policy Entropy: 2.19033
Value Function Loss: 0.02100

Mean KL Divergence: 0.00675
SB3 Clip Fraction: 0.06495
Policy Update Magnitude: 0.30819
Value Function Update Magnitude: 0.21236

Collected Steps per Second: 22,097.89023
Overall Steps per Second: 10,519.37351

Timestep Collection Time: 2.26347
Timestep Consumption Time: 2.49137
PPO Batch Consumption Time: 0.28953
Total Iteration Time: 4.75485

Cumulative Model Updates: 234,476
Cumulative Timesteps: 1,956,183,034

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1956183034...
Checkpoint 1956183034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,805.52942
Policy Entropy: 2.19796
Value Function Loss: 0.02192

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.07325
Policy Update Magnitude: 0.30918
Value Function Update Magnitude: 0.29559

Collected Steps per Second: 21,802.40129
Overall Steps per Second: 10,530.05834

Timestep Collection Time: 2.29424
Timestep Consumption Time: 2.45597
PPO Batch Consumption Time: 0.27920
Total Iteration Time: 4.75021

Cumulative Model Updates: 234,482
Cumulative Timesteps: 1,956,233,054

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45,233.58587
Policy Entropy: 2.20564
Value Function Loss: 0.02133

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.08110
Policy Update Magnitude: 0.30724
Value Function Update Magnitude: 0.34074

Collected Steps per Second: 21,703.76414
Overall Steps per Second: 10,554.02980

Timestep Collection Time: 2.30458
Timestep Consumption Time: 2.43466
PPO Batch Consumption Time: 0.27933
Total Iteration Time: 4.73923

Cumulative Model Updates: 234,488
Cumulative Timesteps: 1,956,283,072

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1956283072...
Checkpoint 1956283072 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 52,613.76342
Policy Entropy: 2.20259
Value Function Loss: 0.02232

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.07764
Policy Update Magnitude: 0.30959
Value Function Update Magnitude: 0.31015

Collected Steps per Second: 21,605.97597
Overall Steps per Second: 10,553.22912

Timestep Collection Time: 2.31519
Timestep Consumption Time: 2.42478
PPO Batch Consumption Time: 0.27960
Total Iteration Time: 4.73997

Cumulative Model Updates: 234,494
Cumulative Timesteps: 1,956,333,094

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,085.28094
Policy Entropy: 2.19382
Value Function Loss: 0.02328

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.07697
Policy Update Magnitude: 0.30826
Value Function Update Magnitude: 0.30557

Collected Steps per Second: 21,741.10131
Overall Steps per Second: 10,541.38651

Timestep Collection Time: 2.30090
Timestep Consumption Time: 2.44459
PPO Batch Consumption Time: 0.27954
Total Iteration Time: 4.74549

Cumulative Model Updates: 234,500
Cumulative Timesteps: 1,956,383,118

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1956383118...
Checkpoint 1956383118 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,368.14135
Policy Entropy: 2.18590
Value Function Loss: 0.02184

Mean KL Divergence: 0.00753
SB3 Clip Fraction: 0.07204
Policy Update Magnitude: 0.30850
Value Function Update Magnitude: 0.29525

Collected Steps per Second: 21,855.97157
Overall Steps per Second: 10,591.92081

Timestep Collection Time: 2.28889
Timestep Consumption Time: 2.43414
PPO Batch Consumption Time: 0.27886
Total Iteration Time: 4.72303

Cumulative Model Updates: 234,506
Cumulative Timesteps: 1,956,433,144

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,551.84016
Policy Entropy: 2.20700
Value Function Loss: 0.02138

Mean KL Divergence: 0.00751
SB3 Clip Fraction: 0.06971
Policy Update Magnitude: 0.30573
Value Function Update Magnitude: 0.32227

Collected Steps per Second: 21,518.39694
Overall Steps per Second: 10,540.00455

Timestep Collection Time: 2.32452
Timestep Consumption Time: 2.42121
PPO Batch Consumption Time: 0.27840
Total Iteration Time: 4.74573

Cumulative Model Updates: 234,512
Cumulative Timesteps: 1,956,483,164

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1956483164...
Checkpoint 1956483164 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,098.13793
Policy Entropy: 2.21891
Value Function Loss: 0.01932

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.06921
Policy Update Magnitude: 0.30323
Value Function Update Magnitude: 0.30977

Collected Steps per Second: 21,334.57758
Overall Steps per Second: 10,337.66309

Timestep Collection Time: 2.34380
Timestep Consumption Time: 2.49327
PPO Batch Consumption Time: 0.29097
Total Iteration Time: 4.83707

Cumulative Model Updates: 234,518
Cumulative Timesteps: 1,956,533,168

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,845.59701
Policy Entropy: 2.22514
Value Function Loss: 0.01906

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.06978
Policy Update Magnitude: 0.29489
Value Function Update Magnitude: 0.29483

Collected Steps per Second: 21,780.02790
Overall Steps per Second: 10,394.70194

Timestep Collection Time: 2.29678
Timestep Consumption Time: 2.51567
PPO Batch Consumption Time: 0.29218
Total Iteration Time: 4.81245

Cumulative Model Updates: 234,524
Cumulative Timesteps: 1,956,583,192

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1956583192...
Checkpoint 1956583192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 68,751.31851
Policy Entropy: 2.21055
Value Function Loss: 0.01946

Mean KL Divergence: 0.00751
SB3 Clip Fraction: 0.07052
Policy Update Magnitude: 0.29209
Value Function Update Magnitude: 0.28017

Collected Steps per Second: 21,536.36985
Overall Steps per Second: 10,474.67247

Timestep Collection Time: 2.32230
Timestep Consumption Time: 2.45245
PPO Batch Consumption Time: 0.27963
Total Iteration Time: 4.77476

Cumulative Model Updates: 234,530
Cumulative Timesteps: 1,956,633,206

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67,287.70989
Policy Entropy: 2.21399
Value Function Loss: 0.01943

Mean KL Divergence: 0.00724
SB3 Clip Fraction: 0.06907
Policy Update Magnitude: 0.29006
Value Function Update Magnitude: 0.26325

Collected Steps per Second: 21,986.09448
Overall Steps per Second: 10,561.39930

Timestep Collection Time: 2.27607
Timestep Consumption Time: 2.46212
PPO Batch Consumption Time: 0.27706
Total Iteration Time: 4.73820

Cumulative Model Updates: 234,536
Cumulative Timesteps: 1,956,683,248

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1956683248...
Checkpoint 1956683248 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 69,294.95624
Policy Entropy: 2.19833
Value Function Loss: 0.02054

Mean KL Divergence: 0.00730
SB3 Clip Fraction: 0.06896
Policy Update Magnitude: 0.29353
Value Function Update Magnitude: 0.27345

Collected Steps per Second: 21,956.97716
Overall Steps per Second: 10,596.22371

Timestep Collection Time: 2.27782
Timestep Consumption Time: 2.44217
PPO Batch Consumption Time: 0.27894
Total Iteration Time: 4.71998

Cumulative Model Updates: 234,542
Cumulative Timesteps: 1,956,733,262

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93,564.63269
Policy Entropy: 2.19538
Value Function Loss: 0.02069

Mean KL Divergence: 0.00706
SB3 Clip Fraction: 0.06790
Policy Update Magnitude: 0.30328
Value Function Update Magnitude: 0.31863

Collected Steps per Second: 22,162.60047
Overall Steps per Second: 10,452.97965

Timestep Collection Time: 2.25768
Timestep Consumption Time: 2.52909
PPO Batch Consumption Time: 0.29486
Total Iteration Time: 4.78677

Cumulative Model Updates: 234,548
Cumulative Timesteps: 1,956,783,298

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1956783298...
Checkpoint 1956783298 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47,141.91747
Policy Entropy: 2.19993
Value Function Loss: 0.01888

Mean KL Divergence: 0.00686
SB3 Clip Fraction: 0.06367
Policy Update Magnitude: 0.30142
Value Function Update Magnitude: 0.34724

Collected Steps per Second: 21,892.57708
Overall Steps per Second: 10,614.21192

Timestep Collection Time: 2.28415
Timestep Consumption Time: 2.42708
PPO Batch Consumption Time: 0.27902
Total Iteration Time: 4.71123

Cumulative Model Updates: 234,554
Cumulative Timesteps: 1,956,833,304

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47,105.50281
Policy Entropy: 2.20639
Value Function Loss: 0.01870

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.07267
Policy Update Magnitude: 0.30300
Value Function Update Magnitude: 0.33307

Collected Steps per Second: 20,977.25347
Overall Steps per Second: 10,235.10996

Timestep Collection Time: 2.38573
Timestep Consumption Time: 2.50391
PPO Batch Consumption Time: 0.29090
Total Iteration Time: 4.88964

Cumulative Model Updates: 234,560
Cumulative Timesteps: 1,956,883,350

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1956883350...
Checkpoint 1956883350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 56,201.48311
Policy Entropy: 2.21172
Value Function Loss: 0.02023

Mean KL Divergence: 0.00714
SB3 Clip Fraction: 0.06531
Policy Update Magnitude: 0.30425
Value Function Update Magnitude: 0.32631

Collected Steps per Second: 21,722.86186
Overall Steps per Second: 10,455.74342

Timestep Collection Time: 2.30292
Timestep Consumption Time: 2.48163
PPO Batch Consumption Time: 0.28927
Total Iteration Time: 4.78455

Cumulative Model Updates: 234,566
Cumulative Timesteps: 1,956,933,376

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,083.12038
Policy Entropy: 2.21301
Value Function Loss: 0.02211

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.07119
Policy Update Magnitude: 0.31127
Value Function Update Magnitude: 0.31661

Collected Steps per Second: 21,260.56656
Overall Steps per Second: 10,437.96080

Timestep Collection Time: 2.35196
Timestep Consumption Time: 2.43863
PPO Batch Consumption Time: 0.29265
Total Iteration Time: 4.79059

Cumulative Model Updates: 234,572
Cumulative Timesteps: 1,956,983,380

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1956983380...
Checkpoint 1956983380 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 72,343.09891
Policy Entropy: 2.21153
Value Function Loss: 0.02296

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.07282
Policy Update Magnitude: 0.30331
Value Function Update Magnitude: 0.32165

Collected Steps per Second: 20,700.17191
Overall Steps per Second: 10,310.67022

Timestep Collection Time: 2.41612
Timestep Consumption Time: 2.43459
PPO Batch Consumption Time: 0.29340
Total Iteration Time: 4.85070

Cumulative Model Updates: 234,578
Cumulative Timesteps: 1,957,033,394

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50,992.54069
Policy Entropy: 2.19875
Value Function Loss: 0.02110

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.08824
Policy Update Magnitude: 0.30322
Value Function Update Magnitude: 0.33988

Collected Steps per Second: 21,232.15871
Overall Steps per Second: 10,455.78538

Timestep Collection Time: 2.35614
Timestep Consumption Time: 2.42839
PPO Batch Consumption Time: 0.29286
Total Iteration Time: 4.78453

Cumulative Model Updates: 234,584
Cumulative Timesteps: 1,957,083,420

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1957083420...
Checkpoint 1957083420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,171.82769
Policy Entropy: 2.20105
Value Function Loss: 0.02313

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.08703
Policy Update Magnitude: 0.31035
Value Function Update Magnitude: 0.34187

Collected Steps per Second: 20,712.77463
Overall Steps per Second: 10,466.26827

Timestep Collection Time: 2.41397
Timestep Consumption Time: 2.36328
PPO Batch Consumption Time: 0.27970
Total Iteration Time: 4.77725

Cumulative Model Updates: 234,590
Cumulative Timesteps: 1,957,133,420

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,796.41811
Policy Entropy: 2.21172
Value Function Loss: 0.02325

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.08432
Policy Update Magnitude: 0.31502
Value Function Update Magnitude: 0.33179

Collected Steps per Second: 21,176.31775
Overall Steps per Second: 10,460.21825

Timestep Collection Time: 2.36311
Timestep Consumption Time: 2.42092
PPO Batch Consumption Time: 0.27911
Total Iteration Time: 4.78403

Cumulative Model Updates: 234,596
Cumulative Timesteps: 1,957,183,462

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1957183462...
Checkpoint 1957183462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,266.85687
Policy Entropy: 2.22981
Value Function Loss: 0.02513

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.08452
Policy Update Magnitude: 0.31714
Value Function Update Magnitude: 0.33836

Collected Steps per Second: 21,317.63576
Overall Steps per Second: 10,340.19096

Timestep Collection Time: 2.34716
Timestep Consumption Time: 2.49182
PPO Batch Consumption Time: 0.29359
Total Iteration Time: 4.83898

Cumulative Model Updates: 234,602
Cumulative Timesteps: 1,957,233,498

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,881.99041
Policy Entropy: 2.18772
Value Function Loss: 0.02379

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.08310
Policy Update Magnitude: 0.31769
Value Function Update Magnitude: 0.32164

Collected Steps per Second: 22,007.59126
Overall Steps per Second: 10,430.63751

Timestep Collection Time: 2.27203
Timestep Consumption Time: 2.52173
PPO Batch Consumption Time: 0.29337
Total Iteration Time: 4.79376

Cumulative Model Updates: 234,608
Cumulative Timesteps: 1,957,283,500

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1957283500...
Checkpoint 1957283500 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,635.38058
Policy Entropy: 2.19892
Value Function Loss: 0.02156

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.09556
Policy Update Magnitude: 0.31055
Value Function Update Magnitude: 0.30542

Collected Steps per Second: 21,809.51124
Overall Steps per Second: 10,562.98484

Timestep Collection Time: 2.29432
Timestep Consumption Time: 2.44279
PPO Batch Consumption Time: 0.27953
Total Iteration Time: 4.73711

Cumulative Model Updates: 234,614
Cumulative Timesteps: 1,957,333,538

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46,763.74762
Policy Entropy: 2.20501
Value Function Loss: 0.02002

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.09001
Policy Update Magnitude: 0.30036
Value Function Update Magnitude: 0.28913

Collected Steps per Second: 22,096.98935
Overall Steps per Second: 10,470.43039

Timestep Collection Time: 2.26284
Timestep Consumption Time: 2.51270
PPO Batch Consumption Time: 0.29378
Total Iteration Time: 4.77554

Cumulative Model Updates: 234,620
Cumulative Timesteps: 1,957,383,540

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1957383540...
Checkpoint 1957383540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 51,714.17613
Policy Entropy: 2.22545
Value Function Loss: 0.02220

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.08469
Policy Update Magnitude: 0.30114
Value Function Update Magnitude: 0.26862

Collected Steps per Second: 21,913.59255
Overall Steps per Second: 10,574.27090

Timestep Collection Time: 2.28242
Timestep Consumption Time: 2.44755
PPO Batch Consumption Time: 0.28003
Total Iteration Time: 4.72997

Cumulative Model Updates: 234,626
Cumulative Timesteps: 1,957,433,556

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56,777.54783
Policy Entropy: 2.22221
Value Function Loss: 0.02280

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.08811
Policy Update Magnitude: 0.30516
Value Function Update Magnitude: 0.24861

Collected Steps per Second: 21,943.57821
Overall Steps per Second: 10,544.56493

Timestep Collection Time: 2.27866
Timestep Consumption Time: 2.46331
PPO Batch Consumption Time: 0.28630
Total Iteration Time: 4.74197

Cumulative Model Updates: 234,632
Cumulative Timesteps: 1,957,483,558

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1957483558...
Checkpoint 1957483558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 56,068.89368
Policy Entropy: 2.22414
Value Function Loss: 0.02325

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.08791
Policy Update Magnitude: 0.31343
Value Function Update Magnitude: 0.30247

Collected Steps per Second: 21,626.15564
Overall Steps per Second: 10,539.16495

Timestep Collection Time: 2.31285
Timestep Consumption Time: 2.43307
PPO Batch Consumption Time: 0.27929
Total Iteration Time: 4.74592

Cumulative Model Updates: 234,638
Cumulative Timesteps: 1,957,533,576

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47,576.21294
Policy Entropy: 2.22164
Value Function Loss: 0.02131

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.08024
Policy Update Magnitude: 0.30385
Value Function Update Magnitude: 0.33858

Collected Steps per Second: 22,147.50347
Overall Steps per Second: 10,497.04721

Timestep Collection Time: 2.25768
Timestep Consumption Time: 2.50575
PPO Batch Consumption Time: 0.29119
Total Iteration Time: 4.76343

Cumulative Model Updates: 234,644
Cumulative Timesteps: 1,957,583,578

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1957583578...
Checkpoint 1957583578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,044.69745
Policy Entropy: 2.21837
Value Function Loss: 0.02115

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.08642
Policy Update Magnitude: 0.30203
Value Function Update Magnitude: 0.32769

Collected Steps per Second: 21,402.72871
Overall Steps per Second: 10,310.07943

Timestep Collection Time: 2.33652
Timestep Consumption Time: 2.51387
PPO Batch Consumption Time: 0.29357
Total Iteration Time: 4.85040

Cumulative Model Updates: 234,650
Cumulative Timesteps: 1,957,633,586

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,781.45466
Policy Entropy: 2.21407
Value Function Loss: 0.02071

Mean KL Divergence: 0.01389
SB3 Clip Fraction: 0.10871
Policy Update Magnitude: 0.29298
Value Function Update Magnitude: 0.32390

Collected Steps per Second: 21,922.76821
Overall Steps per Second: 10,444.16854

Timestep Collection Time: 2.28083
Timestep Consumption Time: 2.50673
PPO Batch Consumption Time: 0.29254
Total Iteration Time: 4.78755

Cumulative Model Updates: 234,656
Cumulative Timesteps: 1,957,683,588

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1957683588...
Checkpoint 1957683588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,470.20890
Policy Entropy: 2.21434
Value Function Loss: 0.02023

Mean KL Divergence: 0.01110
SB3 Clip Fraction: 0.09509
Policy Update Magnitude: 0.30265
Value Function Update Magnitude: 0.32458

Collected Steps per Second: 21,056.36675
Overall Steps per Second: 10,267.95351

Timestep Collection Time: 2.37515
Timestep Consumption Time: 2.49554
PPO Batch Consumption Time: 0.29210
Total Iteration Time: 4.87069

Cumulative Model Updates: 234,662
Cumulative Timesteps: 1,957,733,600

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,552.24350
Policy Entropy: 2.21615
Value Function Loss: 0.01846

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.08491
Policy Update Magnitude: 0.29928
Value Function Update Magnitude: 0.29905

Collected Steps per Second: 21,743.93129
Overall Steps per Second: 10,429.35086

Timestep Collection Time: 2.29986
Timestep Consumption Time: 2.49507
PPO Batch Consumption Time: 0.29238
Total Iteration Time: 4.79493

Cumulative Model Updates: 234,668
Cumulative Timesteps: 1,957,783,608

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1957783608...
Checkpoint 1957783608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,568.28009
Policy Entropy: 2.21362
Value Function Loss: 0.01853

Mean KL Divergence: 0.00753
SB3 Clip Fraction: 0.07136
Policy Update Magnitude: 0.29097
Value Function Update Magnitude: 0.29051

Collected Steps per Second: 21,539.67172
Overall Steps per Second: 10,504.40557

Timestep Collection Time: 2.32158
Timestep Consumption Time: 2.43890
PPO Batch Consumption Time: 0.27948
Total Iteration Time: 4.76048

Cumulative Model Updates: 234,674
Cumulative Timesteps: 1,957,833,614

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,105.07148
Policy Entropy: 2.21783
Value Function Loss: 0.01948

Mean KL Divergence: 0.00705
SB3 Clip Fraction: 0.06867
Policy Update Magnitude: 0.29957
Value Function Update Magnitude: 0.30689

Collected Steps per Second: 22,149.16008
Overall Steps per Second: 10,453.88365

Timestep Collection Time: 2.25869
Timestep Consumption Time: 2.52690
PPO Batch Consumption Time: 0.28998
Total Iteration Time: 4.78559

Cumulative Model Updates: 234,680
Cumulative Timesteps: 1,957,883,642

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1957883642...
Checkpoint 1957883642 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 51,178.60233
Policy Entropy: 2.23242
Value Function Loss: 0.02071

Mean KL Divergence: 0.00678
SB3 Clip Fraction: 0.06470
Policy Update Magnitude: 0.30252
Value Function Update Magnitude: 0.32953

Collected Steps per Second: 21,639.33288
Overall Steps per Second: 10,557.69779

Timestep Collection Time: 2.31070
Timestep Consumption Time: 2.42537
PPO Batch Consumption Time: 0.27947
Total Iteration Time: 4.73607

Cumulative Model Updates: 234,686
Cumulative Timesteps: 1,957,933,644

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89,825.09829
Policy Entropy: 2.22037
Value Function Loss: 0.02381

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.07177
Policy Update Magnitude: 0.31133
Value Function Update Magnitude: 0.34139

Collected Steps per Second: 22,045.13593
Overall Steps per Second: 10,513.47884

Timestep Collection Time: 2.26880
Timestep Consumption Time: 2.48852
PPO Batch Consumption Time: 0.28887
Total Iteration Time: 4.75732

Cumulative Model Updates: 234,692
Cumulative Timesteps: 1,957,983,660

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1957983660...
Checkpoint 1957983660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 68,752.52833
Policy Entropy: 2.20931
Value Function Loss: 0.02241

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.07784
Policy Update Magnitude: 0.31121
Value Function Update Magnitude: 0.31703

Collected Steps per Second: 21,497.77275
Overall Steps per Second: 10,347.36984

Timestep Collection Time: 2.32601
Timestep Consumption Time: 2.50652
PPO Batch Consumption Time: 0.29226
Total Iteration Time: 4.83253

Cumulative Model Updates: 234,698
Cumulative Timesteps: 1,958,033,664

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86,102.58043
Policy Entropy: 2.20681
Value Function Loss: 0.02471

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.07979
Policy Update Magnitude: 0.31228
Value Function Update Magnitude: 0.28889

Collected Steps per Second: 22,310.28674
Overall Steps per Second: 10,697.37890

Timestep Collection Time: 2.24219
Timestep Consumption Time: 2.43409
PPO Batch Consumption Time: 0.27936
Total Iteration Time: 4.67629

Cumulative Model Updates: 234,704
Cumulative Timesteps: 1,958,083,688

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1958083688...
Checkpoint 1958083688 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 65,209.69092
Policy Entropy: 2.21092
Value Function Loss: 0.02110

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.08700
Policy Update Magnitude: 0.29886
Value Function Update Magnitude: 0.33654

Collected Steps per Second: 22,121.41542
Overall Steps per Second: 10,671.99458

Timestep Collection Time: 2.26025
Timestep Consumption Time: 2.42491
PPO Batch Consumption Time: 0.27930
Total Iteration Time: 4.68516

Cumulative Model Updates: 234,710
Cumulative Timesteps: 1,958,133,688

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59,454.56099
Policy Entropy: 2.20303
Value Function Loss: 0.02157

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.08190
Policy Update Magnitude: 0.29965
Value Function Update Magnitude: 0.33377

Collected Steps per Second: 21,086.96422
Overall Steps per Second: 10,488.23728

Timestep Collection Time: 2.37123
Timestep Consumption Time: 2.39621
PPO Batch Consumption Time: 0.28622
Total Iteration Time: 4.76744

Cumulative Model Updates: 234,716
Cumulative Timesteps: 1,958,183,690

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1958183690...
Checkpoint 1958183690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40,098.30380
Policy Entropy: 2.20678
Value Function Loss: 0.02058

Mean KL Divergence: 0.00783
SB3 Clip Fraction: 0.07213
Policy Update Magnitude: 0.30604
Value Function Update Magnitude: 0.28751

Collected Steps per Second: 21,017.06082
Overall Steps per Second: 10,546.79254

Timestep Collection Time: 2.37931
Timestep Consumption Time: 2.36204
PPO Batch Consumption Time: 0.27949
Total Iteration Time: 4.74135

Cumulative Model Updates: 234,722
Cumulative Timesteps: 1,958,233,696

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77,742.65083
Policy Entropy: 2.19602
Value Function Loss: 0.02272

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.07817
Policy Update Magnitude: 0.31408
Value Function Update Magnitude: 0.31783

Collected Steps per Second: 21,000.00647
Overall Steps per Second: 10,559.87794

Timestep Collection Time: 2.38133
Timestep Consumption Time: 2.35433
PPO Batch Consumption Time: 0.27842
Total Iteration Time: 4.73566

Cumulative Model Updates: 234,728
Cumulative Timesteps: 1,958,283,704

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1958283704...
Checkpoint 1958283704 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 65,389.65090
Policy Entropy: 2.20683
Value Function Loss: 0.02155

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.08236
Policy Update Magnitude: 0.31532
Value Function Update Magnitude: 0.34185

Collected Steps per Second: 20,850.03662
Overall Steps per Second: 10,244.80631

Timestep Collection Time: 2.39923
Timestep Consumption Time: 2.48364
PPO Batch Consumption Time: 0.29432
Total Iteration Time: 4.88286

Cumulative Model Updates: 234,734
Cumulative Timesteps: 1,958,333,728

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47,987.90868
Policy Entropy: 2.19671
Value Function Loss: 0.02142

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.08373
Policy Update Magnitude: 0.31050
Value Function Update Magnitude: 0.34466

Collected Steps per Second: 21,076.72238
Overall Steps per Second: 10,452.63865

Timestep Collection Time: 2.37409
Timestep Consumption Time: 2.41303
PPO Batch Consumption Time: 0.27833
Total Iteration Time: 4.78712

Cumulative Model Updates: 234,740
Cumulative Timesteps: 1,958,383,766

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1958383766...
Checkpoint 1958383766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 53,430.56548
Policy Entropy: 2.20186
Value Function Loss: 0.02531

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.08893
Policy Update Magnitude: 0.32331
Value Function Update Magnitude: 0.35337

Collected Steps per Second: 21,608.80262
Overall Steps per Second: 10,544.07419

Timestep Collection Time: 2.31396
Timestep Consumption Time: 2.42823
PPO Batch Consumption Time: 0.28003
Total Iteration Time: 4.74219

Cumulative Model Updates: 234,746
Cumulative Timesteps: 1,958,433,768

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,709.35985
Policy Entropy: 2.21686
Value Function Loss: 0.02541

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.09153
Policy Update Magnitude: 0.33335
Value Function Update Magnitude: 0.39539

Collected Steps per Second: 22,135.67472
Overall Steps per Second: 10,498.03788

Timestep Collection Time: 2.25898
Timestep Consumption Time: 2.50420
PPO Batch Consumption Time: 0.29385
Total Iteration Time: 4.76318

Cumulative Model Updates: 234,752
Cumulative Timesteps: 1,958,483,772

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1958483772...
Checkpoint 1958483772 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,507.91372
Policy Entropy: 2.23535
Value Function Loss: 0.02220

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.08133
Policy Update Magnitude: 0.31844
Value Function Update Magnitude: 0.40525

Collected Steps per Second: 21,998.28418
Overall Steps per Second: 10,597.17985

Timestep Collection Time: 2.27436
Timestep Consumption Time: 2.44690
PPO Batch Consumption Time: 0.27966
Total Iteration Time: 4.72126

Cumulative Model Updates: 234,758
Cumulative Timesteps: 1,958,533,804

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51,496.13980
Policy Entropy: 2.24688
Value Function Loss: 0.02167

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.07837
Policy Update Magnitude: 0.31214
Value Function Update Magnitude: 0.37164

Collected Steps per Second: 22,107.87140
Overall Steps per Second: 10,456.81119

Timestep Collection Time: 2.26218
Timestep Consumption Time: 2.52054
PPO Batch Consumption Time: 0.29219
Total Iteration Time: 4.78272

Cumulative Model Updates: 234,764
Cumulative Timesteps: 1,958,583,816

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1958583816...
Checkpoint 1958583816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 56,956.00776
Policy Entropy: 2.24479
Value Function Loss: 0.02249

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.07793
Policy Update Magnitude: 0.31222
Value Function Update Magnitude: 0.31171

Collected Steps per Second: 21,947.98290
Overall Steps per Second: 10,635.29137

Timestep Collection Time: 2.27820
Timestep Consumption Time: 2.42331
PPO Batch Consumption Time: 0.27984
Total Iteration Time: 4.70152

Cumulative Model Updates: 234,770
Cumulative Timesteps: 1,958,633,818

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51,316.37756
Policy Entropy: 2.23757
Value Function Loss: 0.02374

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.08987
Policy Update Magnitude: 0.30935
Value Function Update Magnitude: 0.32685

Collected Steps per Second: 22,090.23151
Overall Steps per Second: 10,466.52336

Timestep Collection Time: 2.26390
Timestep Consumption Time: 2.51419
PPO Batch Consumption Time: 0.29167
Total Iteration Time: 4.77809

Cumulative Model Updates: 234,776
Cumulative Timesteps: 1,958,683,828

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1958683828...
Checkpoint 1958683828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46,313.63315
Policy Entropy: 2.23389
Value Function Loss: 0.02123

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.08729
Policy Update Magnitude: 0.30281
Value Function Update Magnitude: 0.35249

Collected Steps per Second: 22,180.73687
Overall Steps per Second: 10,716.77650

Timestep Collection Time: 2.25520
Timestep Consumption Time: 2.41243
PPO Batch Consumption Time: 0.27781
Total Iteration Time: 4.66763

Cumulative Model Updates: 234,782
Cumulative Timesteps: 1,958,733,850

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54,336.79733
Policy Entropy: 2.22520
Value Function Loss: 0.02074

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.07986
Policy Update Magnitude: 0.29959
Value Function Update Magnitude: 0.34652

Collected Steps per Second: 21,320.89810
Overall Steps per Second: 10,364.33716

Timestep Collection Time: 2.34568
Timestep Consumption Time: 2.47971
PPO Batch Consumption Time: 0.28661
Total Iteration Time: 4.82539

Cumulative Model Updates: 234,788
Cumulative Timesteps: 1,958,783,862

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1958783862...
Checkpoint 1958783862 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 53,316.89695
Policy Entropy: 2.22031
Value Function Loss: 0.02114

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.08086
Policy Update Magnitude: 0.30062
Value Function Update Magnitude: 0.32150

Collected Steps per Second: 21,221.34520
Overall Steps per Second: 10,297.43809

Timestep Collection Time: 2.35631
Timestep Consumption Time: 2.49966
PPO Batch Consumption Time: 0.29255
Total Iteration Time: 4.85597

Cumulative Model Updates: 234,794
Cumulative Timesteps: 1,958,833,866

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,433.26659
Policy Entropy: 2.21736
Value Function Loss: 0.02066

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.07942
Policy Update Magnitude: 0.30024
Value Function Update Magnitude: 0.30800

Collected Steps per Second: 21,806.92040
Overall Steps per Second: 10,428.68730

Timestep Collection Time: 2.29404
Timestep Consumption Time: 2.50292
PPO Batch Consumption Time: 0.29292
Total Iteration Time: 4.79696

Cumulative Model Updates: 234,800
Cumulative Timesteps: 1,958,883,892

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1958883892...
Checkpoint 1958883892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,293.39765
Policy Entropy: 2.23101
Value Function Loss: 0.01856

Mean KL Divergence: 0.01067
SB3 Clip Fraction: 0.09240
Policy Update Magnitude: 0.29809
Value Function Update Magnitude: 0.30996

Collected Steps per Second: 21,089.31011
Overall Steps per Second: 10,615.36034

Timestep Collection Time: 2.37087
Timestep Consumption Time: 2.33929
PPO Batch Consumption Time: 0.27753
Total Iteration Time: 4.71016

Cumulative Model Updates: 234,806
Cumulative Timesteps: 1,958,933,892

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,016.75048
Policy Entropy: 2.22091
Value Function Loss: 0.01820

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.08698
Policy Update Magnitude: 0.29825
Value Function Update Magnitude: 0.27709

Collected Steps per Second: 21,285.81162
Overall Steps per Second: 10,409.76824

Timestep Collection Time: 2.35002
Timestep Consumption Time: 2.45528
PPO Batch Consumption Time: 0.29094
Total Iteration Time: 4.80529

Cumulative Model Updates: 234,812
Cumulative Timesteps: 1,958,983,914

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1958983914...
Checkpoint 1958983914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,114.34051
Policy Entropy: 2.22407
Value Function Loss: 0.01911

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.08148
Policy Update Magnitude: 0.30409
Value Function Update Magnitude: 0.23035

Collected Steps per Second: 21,261.11570
Overall Steps per Second: 10,593.17480

Timestep Collection Time: 2.35265
Timestep Consumption Time: 2.36926
PPO Batch Consumption Time: 0.28003
Total Iteration Time: 4.72191

Cumulative Model Updates: 234,818
Cumulative Timesteps: 1,959,033,934

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50,046.14284
Policy Entropy: 2.22334
Value Function Loss: 0.02160

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.07825
Policy Update Magnitude: 0.30546
Value Function Update Magnitude: 0.22200

Collected Steps per Second: 21,543.47717
Overall Steps per Second: 10,590.67005

Timestep Collection Time: 2.32191
Timestep Consumption Time: 2.40130
PPO Batch Consumption Time: 0.27749
Total Iteration Time: 4.72321

Cumulative Model Updates: 234,824
Cumulative Timesteps: 1,959,083,956

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1959083956...
Checkpoint 1959083956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,482.24918
Policy Entropy: 2.23576
Value Function Loss: 0.02092

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.07984
Policy Update Magnitude: 0.30365
Value Function Update Magnitude: 0.24877

Collected Steps per Second: 21,699.68077
Overall Steps per Second: 10,610.49666

Timestep Collection Time: 2.30492
Timestep Consumption Time: 2.40890
PPO Batch Consumption Time: 0.27901
Total Iteration Time: 4.71382

Cumulative Model Updates: 234,830
Cumulative Timesteps: 1,959,133,972

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,267.76743
Policy Entropy: 2.21968
Value Function Loss: 0.01987

Mean KL Divergence: 0.00758
SB3 Clip Fraction: 0.07438
Policy Update Magnitude: 0.30053
Value Function Update Magnitude: 0.29374

Collected Steps per Second: 22,000.86258
Overall Steps per Second: 10,504.53704

Timestep Collection Time: 2.27318
Timestep Consumption Time: 2.48781
PPO Batch Consumption Time: 0.29408
Total Iteration Time: 4.76099

Cumulative Model Updates: 234,836
Cumulative Timesteps: 1,959,183,984

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1959183984...
Checkpoint 1959183984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 71,487.71676
Policy Entropy: 2.21118
Value Function Loss: 0.01911

Mean KL Divergence: 0.00704
SB3 Clip Fraction: 0.06784
Policy Update Magnitude: 0.29872
Value Function Update Magnitude: 0.29756

Collected Steps per Second: 21,963.32005
Overall Steps per Second: 10,641.61664

Timestep Collection Time: 2.27734
Timestep Consumption Time: 2.42288
PPO Batch Consumption Time: 0.27711
Total Iteration Time: 4.70023

Cumulative Model Updates: 234,842
Cumulative Timesteps: 1,959,234,002

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 71,502.60628
Policy Entropy: 2.22001
Value Function Loss: 0.01797

Mean KL Divergence: 0.00724
SB3 Clip Fraction: 0.06918
Policy Update Magnitude: 0.29789
Value Function Update Magnitude: 0.28707

Collected Steps per Second: 21,510.63516
Overall Steps per Second: 10,373.50744

Timestep Collection Time: 2.32564
Timestep Consumption Time: 2.49684
PPO Batch Consumption Time: 0.28801
Total Iteration Time: 4.82248

Cumulative Model Updates: 234,848
Cumulative Timesteps: 1,959,284,028

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1959284028...
Checkpoint 1959284028 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 59,446.51936
Policy Entropy: 2.21647
Value Function Loss: 0.02071

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.07333
Policy Update Magnitude: 0.30169
Value Function Update Magnitude: 0.30618

Collected Steps per Second: 21,359.83307
Overall Steps per Second: 10,336.72800

Timestep Collection Time: 2.34150
Timestep Consumption Time: 2.49698
PPO Batch Consumption Time: 0.29292
Total Iteration Time: 4.83847

Cumulative Model Updates: 234,854
Cumulative Timesteps: 1,959,334,042

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45,213.70269
Policy Entropy: 2.21339
Value Function Loss: 0.02106

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.07659
Policy Update Magnitude: 0.30821
Value Function Update Magnitude: 0.32689

Collected Steps per Second: 21,615.59895
Overall Steps per Second: 10,381.50764

Timestep Collection Time: 2.31342
Timestep Consumption Time: 2.50341
PPO Batch Consumption Time: 0.29295
Total Iteration Time: 4.81683

Cumulative Model Updates: 234,860
Cumulative Timesteps: 1,959,384,048

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1959384048...
Checkpoint 1959384048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 74,527.19730
Policy Entropy: 2.21402
Value Function Loss: 0.02401

Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.07545
Policy Update Magnitude: 0.31171
Value Function Update Magnitude: 0.33085

Collected Steps per Second: 21,040.05749
Overall Steps per Second: 10,228.12798

Timestep Collection Time: 2.37766
Timestep Consumption Time: 2.51337
PPO Batch Consumption Time: 0.29365
Total Iteration Time: 4.89102

Cumulative Model Updates: 234,866
Cumulative Timesteps: 1,959,434,074

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62,168.86727
Policy Entropy: 2.23544
Value Function Loss: 0.02324

Mean KL Divergence: 0.00772
SB3 Clip Fraction: 0.07255
Policy Update Magnitude: 0.31236
Value Function Update Magnitude: 0.30628

Collected Steps per Second: 22,289.64344
Overall Steps per Second: 10,437.01151

Timestep Collection Time: 2.24400
Timestep Consumption Time: 2.54837
PPO Batch Consumption Time: 0.29167
Total Iteration Time: 4.79237

Cumulative Model Updates: 234,872
Cumulative Timesteps: 1,959,484,092

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1959484092...
Checkpoint 1959484092 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,044.80396
Policy Entropy: 2.24551
Value Function Loss: 0.02343

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.07224
Policy Update Magnitude: 0.30821
Value Function Update Magnitude: 0.26742

Collected Steps per Second: 21,804.80101
Overall Steps per Second: 10,565.43091

Timestep Collection Time: 2.29436
Timestep Consumption Time: 2.44071
PPO Batch Consumption Time: 0.27887
Total Iteration Time: 4.73506

Cumulative Model Updates: 234,878
Cumulative Timesteps: 1,959,534,120

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48,625.43106
Policy Entropy: 2.24994
Value Function Loss: 0.02120

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.07251
Policy Update Magnitude: 0.30424
Value Function Update Magnitude: 0.22858

Collected Steps per Second: 22,113.55955
Overall Steps per Second: 10,456.73855

Timestep Collection Time: 2.26115
Timestep Consumption Time: 2.52065
PPO Batch Consumption Time: 0.29340
Total Iteration Time: 4.78180

Cumulative Model Updates: 234,884
Cumulative Timesteps: 1,959,584,122

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1959584122...
Checkpoint 1959584122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43,544.70909
Policy Entropy: 2.25095
Value Function Loss: 0.02081

Mean KL Divergence: 0.00719
SB3 Clip Fraction: 0.07017
Policy Update Magnitude: 0.29843
Value Function Update Magnitude: 0.20198

Collected Steps per Second: 21,835.70251
Overall Steps per Second: 10,557.98100

Timestep Collection Time: 2.29065
Timestep Consumption Time: 2.44681
PPO Batch Consumption Time: 0.28079
Total Iteration Time: 4.73746

Cumulative Model Updates: 234,890
Cumulative Timesteps: 1,959,634,140

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65,782.01345
Policy Entropy: 2.26110
Value Function Loss: 0.01975

Mean KL Divergence: 0.00722
SB3 Clip Fraction: 0.06939
Policy Update Magnitude: 0.29280
Value Function Update Magnitude: 0.18586

Collected Steps per Second: 22,079.18032
Overall Steps per Second: 10,563.38132

Timestep Collection Time: 2.26630
Timestep Consumption Time: 2.47063
PPO Batch Consumption Time: 0.28691
Total Iteration Time: 4.73693

Cumulative Model Updates: 234,896
Cumulative Timesteps: 1,959,684,178

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1959684178...
Checkpoint 1959684178 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,610.65024
Policy Entropy: 2.25507
Value Function Loss: 0.01979

Mean KL Divergence: 0.00764
SB3 Clip Fraction: 0.07433
Policy Update Magnitude: 0.29202
Value Function Update Magnitude: 0.21131

Collected Steps per Second: 22,124.98128
Overall Steps per Second: 10,687.20881

Timestep Collection Time: 2.26025
Timestep Consumption Time: 2.41899
PPO Batch Consumption Time: 0.27752
Total Iteration Time: 4.67924

Cumulative Model Updates: 234,902
Cumulative Timesteps: 1,959,734,186

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,132.21723
Policy Entropy: 2.25919
Value Function Loss: 0.01943

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.07593
Policy Update Magnitude: 0.30413
Value Function Update Magnitude: 0.28582

Collected Steps per Second: 22,273.47129
Overall Steps per Second: 10,575.21294

Timestep Collection Time: 2.24572
Timestep Consumption Time: 2.48421
PPO Batch Consumption Time: 0.28828
Total Iteration Time: 4.72993

Cumulative Model Updates: 234,908
Cumulative Timesteps: 1,959,784,206

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1959784206...
Checkpoint 1959784206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,061.54677
Policy Entropy: 2.25401
Value Function Loss: 0.02052

Mean KL Divergence: 0.00772
SB3 Clip Fraction: 0.07265
Policy Update Magnitude: 0.30725
Value Function Update Magnitude: 0.33088

Collected Steps per Second: 21,126.20064
Overall Steps per Second: 10,431.19623

Timestep Collection Time: 2.36701
Timestep Consumption Time: 2.42688
PPO Batch Consumption Time: 0.28972
Total Iteration Time: 4.79389

Cumulative Model Updates: 234,914
Cumulative Timesteps: 1,959,834,212

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55,931.26844
Policy Entropy: 2.25004
Value Function Loss: 0.02036

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.07586
Policy Update Magnitude: 0.30032
Value Function Update Magnitude: 0.32839

Collected Steps per Second: 21,066.64742
Overall Steps per Second: 10,477.84558

Timestep Collection Time: 2.37370
Timestep Consumption Time: 2.39884
PPO Batch Consumption Time: 0.28791
Total Iteration Time: 4.77255

Cumulative Model Updates: 234,920
Cumulative Timesteps: 1,959,884,218

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1959884218...
Checkpoint 1959884218 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,996.26229
Policy Entropy: 2.23352
Value Function Loss: 0.02242

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.07488
Policy Update Magnitude: 0.30985
Value Function Update Magnitude: 0.33773

Collected Steps per Second: 20,812.17586
Overall Steps per Second: 10,519.29934

Timestep Collection Time: 2.40321
Timestep Consumption Time: 2.35148
PPO Batch Consumption Time: 0.27871
Total Iteration Time: 4.75469

Cumulative Model Updates: 234,926
Cumulative Timesteps: 1,959,934,234

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68,422.41207
Policy Entropy: 2.23544
Value Function Loss: 0.02082

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.07344
Policy Update Magnitude: 0.31512
Value Function Update Magnitude: 0.36762

Collected Steps per Second: 20,700.89736
Overall Steps per Second: 10,196.93140

Timestep Collection Time: 2.41651
Timestep Consumption Time: 2.48928
PPO Batch Consumption Time: 0.29351
Total Iteration Time: 4.90579

Cumulative Model Updates: 234,932
Cumulative Timesteps: 1,959,984,258

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1959984258...
Checkpoint 1959984258 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40,722.17963
Policy Entropy: 2.24368
Value Function Loss: 0.02299

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.06941
Policy Update Magnitude: 0.31719
Value Function Update Magnitude: 0.31361

Collected Steps per Second: 21,442.03677
Overall Steps per Second: 10,534.91739

Timestep Collection Time: 2.33271
Timestep Consumption Time: 2.41512
PPO Batch Consumption Time: 0.27942
Total Iteration Time: 4.74783

Cumulative Model Updates: 234,938
Cumulative Timesteps: 1,960,034,276

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,722.17963
Policy Entropy: 2.25775
Value Function Loss: 0.01971

Mean KL Divergence: 0.01172
SB3 Clip Fraction: 0.07449
Policy Update Magnitude: 0.30727
Value Function Update Magnitude: 0.27880

Collected Steps per Second: 22,036.13092
Overall Steps per Second: 10,469.33260

Timestep Collection Time: 2.27027
Timestep Consumption Time: 2.50826
PPO Batch Consumption Time: 0.28948
Total Iteration Time: 4.77853

Cumulative Model Updates: 234,944
Cumulative Timesteps: 1,960,084,304

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1960084304...
Checkpoint 1960084304 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,909.45965
Policy Entropy: 2.26146
Value Function Loss: 0.01900

Mean KL Divergence: 0.00777
SB3 Clip Fraction: 0.07331
Policy Update Magnitude: 0.29180
Value Function Update Magnitude: 0.25532

Collected Steps per Second: 21,804.66756
Overall Steps per Second: 10,619.51492

Timestep Collection Time: 2.29538
Timestep Consumption Time: 2.41764
PPO Batch Consumption Time: 0.27925
Total Iteration Time: 4.71302

Cumulative Model Updates: 234,950
Cumulative Timesteps: 1,960,134,354

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,193.61210
Policy Entropy: 2.25509
Value Function Loss: 0.01936

Mean KL Divergence: 0.00746
SB3 Clip Fraction: 0.07295
Policy Update Magnitude: 0.29255
Value Function Update Magnitude: 0.25747

Collected Steps per Second: 21,954.37302
Overall Steps per Second: 10,478.31803

Timestep Collection Time: 2.27745
Timestep Consumption Time: 2.49431
PPO Batch Consumption Time: 0.29039
Total Iteration Time: 4.77176

Cumulative Model Updates: 234,956
Cumulative Timesteps: 1,960,184,354

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1960184354...
Checkpoint 1960184354 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,760.73607
Policy Entropy: 2.26206
Value Function Loss: 0.02045

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.07658
Policy Update Magnitude: 0.29701
Value Function Update Magnitude: 0.26794

Collected Steps per Second: 21,766.51824
Overall Steps per Second: 10,589.73506

Timestep Collection Time: 2.29720
Timestep Consumption Time: 2.42454
PPO Batch Consumption Time: 0.27892
Total Iteration Time: 4.72174

Cumulative Model Updates: 234,962
Cumulative Timesteps: 1,960,234,356

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46,847.56933
Policy Entropy: 2.26988
Value Function Loss: 0.02035

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.07895
Policy Update Magnitude: 0.29681
Value Function Update Magnitude: 0.27566

Collected Steps per Second: 21,948.26784
Overall Steps per Second: 10,533.56887

Timestep Collection Time: 2.27808
Timestep Consumption Time: 2.46865
PPO Batch Consumption Time: 0.28654
Total Iteration Time: 4.74673

Cumulative Model Updates: 234,968
Cumulative Timesteps: 1,960,284,356

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1960284356...
Checkpoint 1960284356 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,415.43185
Policy Entropy: 2.27192
Value Function Loss: 0.01994

Mean KL Divergence: 0.00740
SB3 Clip Fraction: 0.07045
Policy Update Magnitude: 0.28976
Value Function Update Magnitude: 0.25898

Collected Steps per Second: 21,873.92931
Overall Steps per Second: 10,632.21807

Timestep Collection Time: 2.28592
Timestep Consumption Time: 2.41696
PPO Batch Consumption Time: 0.27825
Total Iteration Time: 4.70288

Cumulative Model Updates: 234,974
Cumulative Timesteps: 1,960,334,358

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,788.99028
Policy Entropy: 2.25551
Value Function Loss: 0.02189

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.08508
Policy Update Magnitude: 0.29344
Value Function Update Magnitude: 0.24094

Collected Steps per Second: 21,900.37980
Overall Steps per Second: 10,432.82784

Timestep Collection Time: 2.28416
Timestep Consumption Time: 2.51070
PPO Batch Consumption Time: 0.29199
Total Iteration Time: 4.79486

Cumulative Model Updates: 234,980
Cumulative Timesteps: 1,960,384,382

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1960384382...
Checkpoint 1960384382 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48,171.33910
Policy Entropy: 2.23915
Value Function Loss: 0.02376

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.08393
Policy Update Magnitude: 0.31375
Value Function Update Magnitude: 0.31397

Collected Steps per Second: 21,091.40648
Overall Steps per Second: 10,239.94564

Timestep Collection Time: 2.37120
Timestep Consumption Time: 2.51281
PPO Batch Consumption Time: 0.29468
Total Iteration Time: 4.88401

Cumulative Model Updates: 234,986
Cumulative Timesteps: 1,960,434,394

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,422.69644
Policy Entropy: 2.23328
Value Function Loss: 0.02511

Mean KL Divergence: 0.01129
SB3 Clip Fraction: 0.08428
Policy Update Magnitude: 0.33533
Value Function Update Magnitude: 0.36564

Collected Steps per Second: 21,255.27217
Overall Steps per Second: 10,459.01195

Timestep Collection Time: 2.35320
Timestep Consumption Time: 2.42908
PPO Batch Consumption Time: 0.27781
Total Iteration Time: 4.78229

Cumulative Model Updates: 234,992
Cumulative Timesteps: 1,960,484,412

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1960484412...
Checkpoint 1960484412 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,509.05424
Policy Entropy: 2.23472
Value Function Loss: 0.02331

Mean KL Divergence: 0.01352
SB3 Clip Fraction: 0.08888
Policy Update Magnitude: 0.33097
Value Function Update Magnitude: 0.35255

Collected Steps per Second: 21,684.99526
Overall Steps per Second: 10,537.34362

Timestep Collection Time: 2.30574
Timestep Consumption Time: 2.43929
PPO Batch Consumption Time: 0.27922
Total Iteration Time: 4.74503

Cumulative Model Updates: 234,998
Cumulative Timesteps: 1,960,534,412

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45,699.27653
Policy Entropy: 2.24169
Value Function Loss: 0.02281

Mean KL Divergence: 0.01308
SB3 Clip Fraction: 0.10539
Policy Update Magnitude: 0.31185
Value Function Update Magnitude: 0.37112

Collected Steps per Second: 21,739.95352
Overall Steps per Second: 10,491.99356

Timestep Collection Time: 2.30046
Timestep Consumption Time: 2.46622
PPO Batch Consumption Time: 0.27991
Total Iteration Time: 4.76668

Cumulative Model Updates: 235,004
Cumulative Timesteps: 1,960,584,424

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1960584424...
Checkpoint 1960584424 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 50,688.40251
Policy Entropy: 2.24853
Value Function Loss: 0.02250

Mean KL Divergence: 0.01472
SB3 Clip Fraction: 0.11813
Policy Update Magnitude: 0.29005
Value Function Update Magnitude: 0.35885

Collected Steps per Second: 19,988.41418
Overall Steps per Second: 10,203.17459

Timestep Collection Time: 2.50375
Timestep Consumption Time: 2.40119
PPO Batch Consumption Time: 0.27954
Total Iteration Time: 4.90494

Cumulative Model Updates: 235,010
Cumulative Timesteps: 1,960,634,470

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,148.30282
Policy Entropy: 2.24520
Value Function Loss: 0.02238

Mean KL Divergence: 0.01115
SB3 Clip Fraction: 0.10367
Policy Update Magnitude: 0.30538
Value Function Update Magnitude: 0.34422

Collected Steps per Second: 21,392.91311
Overall Steps per Second: 10,489.47214

Timestep Collection Time: 2.33806
Timestep Consumption Time: 2.43034
PPO Batch Consumption Time: 0.28936
Total Iteration Time: 4.76840

Cumulative Model Updates: 235,016
Cumulative Timesteps: 1,960,684,488

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1960684488...
Checkpoint 1960684488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43,846.01285
Policy Entropy: 2.26224
Value Function Loss: 0.02194

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.09470
Policy Update Magnitude: 0.31274
Value Function Update Magnitude: 0.33965

Collected Steps per Second: 21,312.14923
Overall Steps per Second: 10,593.33588

Timestep Collection Time: 2.34702
Timestep Consumption Time: 2.37482
PPO Batch Consumption Time: 0.27915
Total Iteration Time: 4.72184

Cumulative Model Updates: 235,022
Cumulative Timesteps: 1,960,734,508

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,305.94382
Policy Entropy: 2.25705
Value Function Loss: 0.02325

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.08021
Policy Update Magnitude: 0.31448
Value Function Update Magnitude: 0.33680

Collected Steps per Second: 21,411.37503
Overall Steps per Second: 10,496.71436

Timestep Collection Time: 2.33595
Timestep Consumption Time: 2.42897
PPO Batch Consumption Time: 0.29046
Total Iteration Time: 4.76492

Cumulative Model Updates: 235,028
Cumulative Timesteps: 1,960,784,524

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1960784524...
Checkpoint 1960784524 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,080.89966
Policy Entropy: 2.27086
Value Function Loss: 0.02214

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.07355
Policy Update Magnitude: 0.31673
Value Function Update Magnitude: 0.31529

Collected Steps per Second: 21,316.85096
Overall Steps per Second: 10,383.47088

Timestep Collection Time: 2.34678
Timestep Consumption Time: 2.47107
PPO Batch Consumption Time: 0.29046
Total Iteration Time: 4.81785

Cumulative Model Updates: 235,034
Cumulative Timesteps: 1,960,834,550

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,993.77264
Policy Entropy: 2.27069
Value Function Loss: 0.02405

Mean KL Divergence: 0.00715
SB3 Clip Fraction: 0.06768
Policy Update Magnitude: 0.31552
Value Function Update Magnitude: 0.30403

Collected Steps per Second: 21,945.37080
Overall Steps per Second: 10,673.97221

Timestep Collection Time: 2.27984
Timestep Consumption Time: 2.40745
PPO Batch Consumption Time: 0.27867
Total Iteration Time: 4.68729

Cumulative Model Updates: 235,040
Cumulative Timesteps: 1,960,884,582

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1960884582...
Checkpoint 1960884582 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,758.87169
Policy Entropy: 2.27496
Value Function Loss: 0.02178

Mean KL Divergence: 0.00717
SB3 Clip Fraction: 0.06704
Policy Update Magnitude: 0.31292
Value Function Update Magnitude: 0.32552

Collected Steps per Second: 21,246.40265
Overall Steps per Second: 10,354.18211

Timestep Collection Time: 2.35343
Timestep Consumption Time: 2.47573
PPO Batch Consumption Time: 0.29254
Total Iteration Time: 4.82916

Cumulative Model Updates: 235,046
Cumulative Timesteps: 1,960,934,584

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,666.16102
Policy Entropy: 2.27312
Value Function Loss: 0.02224

Mean KL Divergence: 0.00740
SB3 Clip Fraction: 0.06898
Policy Update Magnitude: 0.30998
Value Function Update Magnitude: 0.32827

Collected Steps per Second: 21,705.61448
Overall Steps per Second: 10,393.45296

Timestep Collection Time: 2.30429
Timestep Consumption Time: 2.50797
PPO Batch Consumption Time: 0.29299
Total Iteration Time: 4.81226

Cumulative Model Updates: 235,052
Cumulative Timesteps: 1,960,984,600

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1960984600...
Checkpoint 1960984600 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,410.08447
Policy Entropy: 2.26221
Value Function Loss: 0.02271

Mean KL Divergence: 0.00758
SB3 Clip Fraction: 0.06937
Policy Update Magnitude: 0.31320
Value Function Update Magnitude: 0.33925

Collected Steps per Second: 21,026.19076
Overall Steps per Second: 10,247.46228

Timestep Collection Time: 2.37894
Timestep Consumption Time: 2.50227
PPO Batch Consumption Time: 0.29357
Total Iteration Time: 4.88121

Cumulative Model Updates: 235,058
Cumulative Timesteps: 1,961,034,620

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63,058.50231
Policy Entropy: 2.26591
Value Function Loss: 0.02178

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.07829
Policy Update Magnitude: 0.31501
Value Function Update Magnitude: 0.34609

Collected Steps per Second: 21,808.21058
Overall Steps per Second: 10,424.46904

Timestep Collection Time: 2.29409
Timestep Consumption Time: 2.50520
PPO Batch Consumption Time: 0.29302
Total Iteration Time: 4.79929

Cumulative Model Updates: 235,064
Cumulative Timesteps: 1,961,084,650

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1961084650...
Checkpoint 1961084650 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,452.53015
Policy Entropy: 2.28378
Value Function Loss: 0.01990

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.07173
Policy Update Magnitude: 0.30930
Value Function Update Magnitude: 0.34061

Collected Steps per Second: 21,481.52046
Overall Steps per Second: 10,516.58934

Timestep Collection Time: 2.32805
Timestep Consumption Time: 2.42730
PPO Batch Consumption Time: 0.27832
Total Iteration Time: 4.75534

Cumulative Model Updates: 235,070
Cumulative Timesteps: 1,961,134,660

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 69,438.85611
Policy Entropy: 2.29879
Value Function Loss: 0.02086

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.07303
Policy Update Magnitude: 0.30393
Value Function Update Magnitude: 0.31763

Collected Steps per Second: 22,131.08901
Overall Steps per Second: 10,600.00587

Timestep Collection Time: 2.26152
Timestep Consumption Time: 2.46017
PPO Batch Consumption Time: 0.27765
Total Iteration Time: 4.72170

Cumulative Model Updates: 235,076
Cumulative Timesteps: 1,961,184,710

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 1961184710...
Checkpoint 1961184710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,977.07443
Policy Entropy: 2.28518
Value Function Loss: 0.02102

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.07276
Policy Update Magnitude: 0.30700
Value Function Update Magnitude: 0.31747

Collected Steps per Second: 21,904.16359
Overall Steps per Second: 10,587.37986

Timestep Collection Time: 2.28340
Timestep Consumption Time: 2.44071
PPO Batch Consumption Time: 0.27759
Total Iteration Time: 4.72411

Cumulative Model Updates: 235,082
Cumulative Timesteps: 1,961,234,726

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55,490.13302
Policy Entropy: 2.25845
Value Function Loss: 0.02159

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.07515
Policy Update Magnitude: 0.31104
Value Function Update Magnitude: 0.33058

Collected Steps per Second: 22,079.32841
Overall Steps per Second: 10,456.76446

Timestep Collection Time: 2.26628
Timestep Consumption Time: 2.51895
PPO Batch Consumption Time: 0.29648
Total Iteration Time: 4.78523

Cumulative Model Updates: 235,088
Cumulative Timesteps: 1,961,284,764

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1961284764...
Checkpoint 1961284764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,500.38810
Policy Entropy: 2.24450
Value Function Loss: 0.02111

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.07563
Policy Update Magnitude: 0.31106
Value Function Update Magnitude: 0.35913

Collected Steps per Second: 21,846.58748
Overall Steps per Second: 10,592.05777

Timestep Collection Time: 2.29107
Timestep Consumption Time: 2.43436
PPO Batch Consumption Time: 0.27919
Total Iteration Time: 4.72543

Cumulative Model Updates: 235,094
Cumulative Timesteps: 1,961,334,816

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,934.70113
Policy Entropy: 2.25794
Value Function Loss: 0.01972

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.07359
Policy Update Magnitude: 0.30065
Value Function Update Magnitude: 0.33813

Collected Steps per Second: 21,885.22944
Overall Steps per Second: 10,456.01225

Timestep Collection Time: 2.28538
Timestep Consumption Time: 2.49809
PPO Batch Consumption Time: 0.29044
Total Iteration Time: 4.78347

Cumulative Model Updates: 235,100
Cumulative Timesteps: 1,961,384,832

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1961384832...
Checkpoint 1961384832 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 58,335.92632
Policy Entropy: 2.26715
Value Function Loss: 0.02248

Mean KL Divergence: 0.00717
SB3 Clip Fraction: 0.06660
Policy Update Magnitude: 0.30389
Value Function Update Magnitude: 0.29515

Collected Steps per Second: 20,799.30245
Overall Steps per Second: 10,363.58679

Timestep Collection Time: 2.40498
Timestep Consumption Time: 2.42172
PPO Batch Consumption Time: 0.29127
Total Iteration Time: 4.82671

Cumulative Model Updates: 235,106
Cumulative Timesteps: 1,961,434,854

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49,353.78873
Policy Entropy: 2.27017
Value Function Loss: 0.02329

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.08191
Policy Update Magnitude: 0.31435
Value Function Update Magnitude: 0.26721

Collected Steps per Second: 21,285.46522
Overall Steps per Second: 10,514.24726

Timestep Collection Time: 2.34968
Timestep Consumption Time: 2.40711
PPO Batch Consumption Time: 0.28948
Total Iteration Time: 4.75678

Cumulative Model Updates: 235,112
Cumulative Timesteps: 1,961,484,868

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1961484868...
Checkpoint 1961484868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43,740.27231
Policy Entropy: 2.26409
Value Function Loss: 0.02184

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.07470
Policy Update Magnitude: 0.31616
Value Function Update Magnitude: 0.28878

Collected Steps per Second: 20,812.99887
Overall Steps per Second: 10,441.10811

Timestep Collection Time: 2.40263
Timestep Consumption Time: 2.38671
PPO Batch Consumption Time: 0.28429
Total Iteration Time: 4.78934

Cumulative Model Updates: 235,118
Cumulative Timesteps: 1,961,534,874

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51,481.08153
Policy Entropy: 2.25966
Value Function Loss: 0.02029

Mean KL Divergence: 0.00671
SB3 Clip Fraction: 0.06368
Policy Update Magnitude: 0.31050
Value Function Update Magnitude: 0.29439

Collected Steps per Second: 21,101.01202
Overall Steps per Second: 10,445.80766

Timestep Collection Time: 2.37060
Timestep Consumption Time: 2.41812
PPO Batch Consumption Time: 0.27972
Total Iteration Time: 4.78872

Cumulative Model Updates: 235,124
Cumulative Timesteps: 1,961,584,896

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1961584896...
Checkpoint 1961584896 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47,625.98746
Policy Entropy: 2.23814
Value Function Loss: 0.02410

Mean KL Divergence: 0.00706
SB3 Clip Fraction: 0.06667
Policy Update Magnitude: 0.31912
Value Function Update Magnitude: 0.28052

Collected Steps per Second: 21,107.90859
Overall Steps per Second: 10,280.94768

Timestep Collection Time: 2.36935
Timestep Consumption Time: 2.49518
PPO Batch Consumption Time: 0.29364
Total Iteration Time: 4.86453

Cumulative Model Updates: 235,130
Cumulative Timesteps: 1,961,634,908

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52,388.01873
Policy Entropy: 2.24696
Value Function Loss: 0.02485

Mean KL Divergence: 0.00678
SB3 Clip Fraction: 0.06470
Policy Update Magnitude: 0.32866
Value Function Update Magnitude: 0.29425

Collected Steps per Second: 21,722.64952
Overall Steps per Second: 10,467.18209

Timestep Collection Time: 2.30359
Timestep Consumption Time: 2.47707
PPO Batch Consumption Time: 0.29363
Total Iteration Time: 4.78066

Cumulative Model Updates: 235,136
Cumulative Timesteps: 1,961,684,948

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1961684948...
Checkpoint 1961684948 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,368.46193
Policy Entropy: 2.24033
Value Function Loss: 0.02389

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.07564
Policy Update Magnitude: 0.32387
Value Function Update Magnitude: 0.33100

Collected Steps per Second: 21,630.31773
Overall Steps per Second: 10,494.38684

Timestep Collection Time: 2.31231
Timestep Consumption Time: 2.45367
PPO Batch Consumption Time: 0.27925
Total Iteration Time: 4.76598

Cumulative Model Updates: 235,142
Cumulative Timesteps: 1,961,734,964

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,351.53749
Policy Entropy: 2.27355
Value Function Loss: 0.02116

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.07397
Policy Update Magnitude: 0.32357
Value Function Update Magnitude: 0.31195

Collected Steps per Second: 22,050.61748
Overall Steps per Second: 10,403.54141

Timestep Collection Time: 2.26805
Timestep Consumption Time: 2.53915
PPO Batch Consumption Time: 0.29164
Total Iteration Time: 4.80721

Cumulative Model Updates: 235,148
Cumulative Timesteps: 1,961,784,976

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1961784976...
Checkpoint 1961784976 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,964.34921
Policy Entropy: 2.26699
Value Function Loss: 0.02140

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.07529
Policy Update Magnitude: 0.32077
Value Function Update Magnitude: 0.30799

Collected Steps per Second: 21,725.29350
Overall Steps per Second: 10,426.05246

Timestep Collection Time: 2.30275
Timestep Consumption Time: 2.49561
PPO Batch Consumption Time: 0.29238
Total Iteration Time: 4.79836

Cumulative Model Updates: 235,154
Cumulative Timesteps: 1,961,835,004

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45,903.08574
Policy Entropy: 2.27992
Value Function Loss: 0.01966

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.07743
Policy Update Magnitude: 0.31136
Value Function Update Magnitude: 0.33251

Collected Steps per Second: 22,339.32837
Overall Steps per Second: 10,696.35518

Timestep Collection Time: 2.23865
Timestep Consumption Time: 2.43677
PPO Batch Consumption Time: 0.27919
Total Iteration Time: 4.67542

Cumulative Model Updates: 235,160
Cumulative Timesteps: 1,961,885,014

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1961885014...
Checkpoint 1961885014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43,825.78411
Policy Entropy: 2.25311
Value Function Loss: 0.02084

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.07999
Policy Update Magnitude: 0.30407
Value Function Update Magnitude: 0.34089

Collected Steps per Second: 21,819.26809
Overall Steps per Second: 10,622.04022

Timestep Collection Time: 2.29174
Timestep Consumption Time: 2.41583
PPO Batch Consumption Time: 0.27965
Total Iteration Time: 4.70757

Cumulative Model Updates: 235,166
Cumulative Timesteps: 1,961,935,018

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56,569.13947
Policy Entropy: 2.26264
Value Function Loss: 0.02205

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.07828
Policy Update Magnitude: 0.31218
Value Function Update Magnitude: 0.30632

Collected Steps per Second: 22,050.72442
Overall Steps per Second: 10,521.49945

Timestep Collection Time: 2.26868
Timestep Consumption Time: 2.48597
PPO Batch Consumption Time: 0.28788
Total Iteration Time: 4.75465

Cumulative Model Updates: 235,172
Cumulative Timesteps: 1,961,985,044

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1961985044...
Checkpoint 1961985044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 54,557.65143
Policy Entropy: 2.26312
Value Function Loss: 0.02259

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.08160
Policy Update Magnitude: 0.31789
Value Function Update Magnitude: 0.31329

Collected Steps per Second: 21,734.53733
Overall Steps per Second: 10,587.93079

Timestep Collection Time: 2.30260
Timestep Consumption Time: 2.42410
PPO Batch Consumption Time: 0.27924
Total Iteration Time: 4.72670

Cumulative Model Updates: 235,178
Cumulative Timesteps: 1,962,035,090

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,745.21439
Policy Entropy: 2.25979
Value Function Loss: 0.02170

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.08496
Policy Update Magnitude: 0.31112
Value Function Update Magnitude: 0.32462

Collected Steps per Second: 21,610.97650
Overall Steps per Second: 10,555.54502

Timestep Collection Time: 2.31447
Timestep Consumption Time: 2.42408
PPO Batch Consumption Time: 0.27814
Total Iteration Time: 4.73855

Cumulative Model Updates: 235,184
Cumulative Timesteps: 1,962,085,108

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1962085108...
Checkpoint 1962085108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,027.69545
Policy Entropy: 2.27433
Value Function Loss: 0.02071

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.08092
Policy Update Magnitude: 0.30640
Value Function Update Magnitude: 0.29002

Collected Steps per Second: 21,404.97481
Overall Steps per Second: 10,545.27435

Timestep Collection Time: 2.33777
Timestep Consumption Time: 2.40748
PPO Batch Consumption Time: 0.27858
Total Iteration Time: 4.74525

Cumulative Model Updates: 235,190
Cumulative Timesteps: 1,962,135,148

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 73,268.94204
Policy Entropy: 2.27483
Value Function Loss: 0.02273

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.08245
Policy Update Magnitude: 0.30704
Value Function Update Magnitude: 0.24474

Collected Steps per Second: 21,777.80121
Overall Steps per Second: 10,598.30641

Timestep Collection Time: 2.29693
Timestep Consumption Time: 2.42288
PPO Batch Consumption Time: 0.27795
Total Iteration Time: 4.71981

Cumulative Model Updates: 235,196
Cumulative Timesteps: 1,962,185,170

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1962185170...
Checkpoint 1962185170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,194.52457
Policy Entropy: 2.29125
Value Function Loss: 0.02607

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.09269
Policy Update Magnitude: 0.31554
Value Function Update Magnitude: 0.23054

Collected Steps per Second: 20,581.17551
Overall Steps per Second: 10,470.78300

Timestep Collection Time: 2.43096
Timestep Consumption Time: 2.34729
PPO Batch Consumption Time: 0.27880
Total Iteration Time: 4.77825

Cumulative Model Updates: 235,202
Cumulative Timesteps: 1,962,235,202

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48,409.43349
Policy Entropy: 2.26253
Value Function Loss: 0.02527

Mean KL Divergence: 0.01204
SB3 Clip Fraction: 0.10411
Policy Update Magnitude: 0.31986
Value Function Update Magnitude: 0.23643

Collected Steps per Second: 21,102.08810
Overall Steps per Second: 10,554.62829

Timestep Collection Time: 2.37095
Timestep Consumption Time: 2.36934
PPO Batch Consumption Time: 0.27895
Total Iteration Time: 4.74029

Cumulative Model Updates: 235,208
Cumulative Timesteps: 1,962,285,234

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1962285234...
Checkpoint 1962285234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,460.97447
Policy Entropy: 2.26341
Value Function Loss: 0.02554

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.09654
Policy Update Magnitude: 0.32693
Value Function Update Magnitude: 0.32186

Collected Steps per Second: 21,367.83532
Overall Steps per Second: 10,606.01275

Timestep Collection Time: 2.34128
Timestep Consumption Time: 2.37567
PPO Batch Consumption Time: 0.27874
Total Iteration Time: 4.71695

Cumulative Model Updates: 235,214
Cumulative Timesteps: 1,962,335,262

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,437.00258
Policy Entropy: 2.26997
Value Function Loss: 0.02200

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.08433
Policy Update Magnitude: 0.32411
Value Function Update Magnitude: 0.32762

Collected Steps per Second: 21,734.48793
Overall Steps per Second: 10,476.64789

Timestep Collection Time: 2.30104
Timestep Consumption Time: 2.47262
PPO Batch Consumption Time: 0.29041
Total Iteration Time: 4.77366

Cumulative Model Updates: 235,220
Cumulative Timesteps: 1,962,385,274

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1962385274...
Checkpoint 1962385274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,437.00258
Policy Entropy: 2.27876
Value Function Loss: 0.01971

Mean KL Divergence: 0.00723
SB3 Clip Fraction: 0.07017
Policy Update Magnitude: 0.31138
Value Function Update Magnitude: 0.29722

Collected Steps per Second: 21,775.66182
Overall Steps per Second: 10,638.05775

Timestep Collection Time: 2.29642
Timestep Consumption Time: 2.40425
PPO Batch Consumption Time: 0.27912
Total Iteration Time: 4.70067

Cumulative Model Updates: 235,226
Cumulative Timesteps: 1,962,435,280

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,464.19545
Policy Entropy: 2.28016
Value Function Loss: 0.02110

Mean KL Divergence: 0.00745
SB3 Clip Fraction: 0.07038
Policy Update Magnitude: 0.30679
Value Function Update Magnitude: 0.28576

Collected Steps per Second: 21,823.75774
Overall Steps per Second: 10,465.50604

Timestep Collection Time: 2.29246
Timestep Consumption Time: 2.48801
PPO Batch Consumption Time: 0.29208
Total Iteration Time: 4.78047

Cumulative Model Updates: 235,232
Cumulative Timesteps: 1,962,485,310

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1962485310...
Checkpoint 1962485310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,966.44817
Policy Entropy: 2.26261
Value Function Loss: 0.02002

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.07780
Policy Update Magnitude: 0.30741
Value Function Update Magnitude: 0.32080

Collected Steps per Second: 20,870.93792
Overall Steps per Second: 10,183.75262

Timestep Collection Time: 2.39654
Timestep Consumption Time: 2.51501
PPO Batch Consumption Time: 0.28992
Total Iteration Time: 4.91155

Cumulative Model Updates: 235,238
Cumulative Timesteps: 1,962,535,328

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45,155.13698
Policy Entropy: 2.28358
Value Function Loss: 0.02041

Mean KL Divergence: 0.00725
SB3 Clip Fraction: 0.06882
Policy Update Magnitude: 0.31156
Value Function Update Magnitude: 0.30832

Collected Steps per Second: 21,714.70540
Overall Steps per Second: 10,448.30682

Timestep Collection Time: 2.30323
Timestep Consumption Time: 2.48357
PPO Batch Consumption Time: 0.28642
Total Iteration Time: 4.78680

Cumulative Model Updates: 235,244
Cumulative Timesteps: 1,962,585,342

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1962585342...
Checkpoint 1962585342 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,688.40339
Policy Entropy: 2.28633
Value Function Loss: 0.01814

Mean KL Divergence: 0.00740
SB3 Clip Fraction: 0.07020
Policy Update Magnitude: 0.29970
Value Function Update Magnitude: 0.29940

Collected Steps per Second: 21,302.90590
Overall Steps per Second: 10,283.21408

Timestep Collection Time: 2.34729
Timestep Consumption Time: 2.51540
PPO Batch Consumption Time: 0.29417
Total Iteration Time: 4.86268

Cumulative Model Updates: 235,250
Cumulative Timesteps: 1,962,635,346

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47,731.19018
Policy Entropy: 2.29496
Value Function Loss: 0.01831

Mean KL Divergence: 0.00614
SB3 Clip Fraction: 0.05925
Policy Update Magnitude: 0.28960
Value Function Update Magnitude: 0.28490

Collected Steps per Second: 21,686.50125
Overall Steps per Second: 10,438.31776

Timestep Collection Time: 2.30724
Timestep Consumption Time: 2.48625
PPO Batch Consumption Time: 0.28845
Total Iteration Time: 4.79349

Cumulative Model Updates: 235,256
Cumulative Timesteps: 1,962,685,382

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1962685382...
Checkpoint 1962685382 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47,906.68710
Policy Entropy: 2.29166
Value Function Loss: 0.01890

Mean KL Divergence: 0.00625
SB3 Clip Fraction: 0.06167
Policy Update Magnitude: 0.29751
Value Function Update Magnitude: 0.27834

Collected Steps per Second: 21,542.29390
Overall Steps per Second: 10,319.93511

Timestep Collection Time: 2.32241
Timestep Consumption Time: 2.52549
PPO Batch Consumption Time: 0.29209
Total Iteration Time: 4.84790

Cumulative Model Updates: 235,262
Cumulative Timesteps: 1,962,735,412

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51,174.67478
Policy Entropy: 2.28126
Value Function Loss: 0.02142

Mean KL Divergence: 0.00667
SB3 Clip Fraction: 0.06456
Policy Update Magnitude: 0.30814
Value Function Update Magnitude: 0.26374

Collected Steps per Second: 22,052.25148
Overall Steps per Second: 10,508.10399

Timestep Collection Time: 2.26852
Timestep Consumption Time: 2.49219
PPO Batch Consumption Time: 0.28880
Total Iteration Time: 4.76071

Cumulative Model Updates: 235,268
Cumulative Timesteps: 1,962,785,438

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1962785438...
Checkpoint 1962785438 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 60,493.34430
Policy Entropy: 2.28251
Value Function Loss: 0.02241

Mean KL Divergence: 0.00713
SB3 Clip Fraction: 0.06811
Policy Update Magnitude: 0.31175
Value Function Update Magnitude: 0.29197

Collected Steps per Second: 21,582.06340
Overall Steps per Second: 10,537.25990

Timestep Collection Time: 2.31683
Timestep Consumption Time: 2.42843
PPO Batch Consumption Time: 0.29369
Total Iteration Time: 4.74526

Cumulative Model Updates: 235,274
Cumulative Timesteps: 1,962,835,440

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52,551.65870
Policy Entropy: 2.26769
Value Function Loss: 0.02126

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.07581
Policy Update Magnitude: 0.30067
Value Function Update Magnitude: 0.32876

Collected Steps per Second: 21,536.81334
Overall Steps per Second: 10,579.10960

Timestep Collection Time: 2.32272
Timestep Consumption Time: 2.40584
PPO Batch Consumption Time: 0.28927
Total Iteration Time: 4.72856

Cumulative Model Updates: 235,280
Cumulative Timesteps: 1,962,885,464

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1962885464...
Checkpoint 1962885464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,315.79036
Policy Entropy: 2.26689
Value Function Loss: 0.02064

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.07090
Policy Update Magnitude: 0.30091
Value Function Update Magnitude: 0.28951

Collected Steps per Second: 21,315.32369
Overall Steps per Second: 10,472.43122

Timestep Collection Time: 2.34582
Timestep Consumption Time: 2.42881
PPO Batch Consumption Time: 0.29432
Total Iteration Time: 4.77463

Cumulative Model Updates: 235,286
Cumulative Timesteps: 1,962,935,466

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,315.79036
Policy Entropy: 2.28122
Value Function Loss: 0.01885

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.08837
Policy Update Magnitude: 0.29492
Value Function Update Magnitude: 0.26164

Collected Steps per Second: 21,552.89728
Overall Steps per Second: 10,383.10152

Timestep Collection Time: 2.32024
Timestep Consumption Time: 2.49604
PPO Batch Consumption Time: 0.29301
Total Iteration Time: 4.81629

Cumulative Model Updates: 235,292
Cumulative Timesteps: 1,962,985,474

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1962985474...
Checkpoint 1962985474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,402.36024
Policy Entropy: 2.27616
Value Function Loss: 0.01938

Mean KL Divergence: 0.01294
SB3 Clip Fraction: 0.10613
Policy Update Magnitude: 0.29162
Value Function Update Magnitude: 0.28236

Collected Steps per Second: 21,731.90298
Overall Steps per Second: 10,604.20284

Timestep Collection Time: 2.30251
Timestep Consumption Time: 2.41618
PPO Batch Consumption Time: 0.27917
Total Iteration Time: 4.71870

Cumulative Model Updates: 235,298
Cumulative Timesteps: 1,963,035,512

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57,204.13529
Policy Entropy: 2.28192
Value Function Loss: 0.01968

Mean KL Divergence: 0.01107
SB3 Clip Fraction: 0.09658
Policy Update Magnitude: 0.30231
Value Function Update Magnitude: 0.31291

Collected Steps per Second: 21,411.11014
Overall Steps per Second: 10,561.85785

Timestep Collection Time: 2.33598
Timestep Consumption Time: 2.39955
PPO Batch Consumption Time: 0.27710
Total Iteration Time: 4.73553

Cumulative Model Updates: 235,304
Cumulative Timesteps: 1,963,085,528

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1963085528...
Checkpoint 1963085528 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 61,170.85461
Policy Entropy: 2.27519
Value Function Loss: 0.02000

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.08876
Policy Update Magnitude: 0.30814
Value Function Update Magnitude: 0.35792

Collected Steps per Second: 21,544.88108
Overall Steps per Second: 10,574.57338

Timestep Collection Time: 2.32176
Timestep Consumption Time: 2.40865
PPO Batch Consumption Time: 0.27942
Total Iteration Time: 4.73040

Cumulative Model Updates: 235,310
Cumulative Timesteps: 1,963,135,550

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75,793.33708
Policy Entropy: 2.27882
Value Function Loss: 0.02104

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.08091
Policy Update Magnitude: 0.31042
Value Function Update Magnitude: 0.34948

Collected Steps per Second: 21,665.04272
Overall Steps per Second: 10,442.34205

Timestep Collection Time: 2.30796
Timestep Consumption Time: 2.48043
PPO Batch Consumption Time: 0.28648
Total Iteration Time: 4.78839

Cumulative Model Updates: 235,316
Cumulative Timesteps: 1,963,185,552

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1963185552...
Checkpoint 1963185552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 99,288.88889
Policy Entropy: 2.28668
Value Function Loss: 0.01952

Mean KL Divergence: 0.00772
SB3 Clip Fraction: 0.07261
Policy Update Magnitude: 0.30517
Value Function Update Magnitude: 0.33673

Collected Steps per Second: 21,609.50739
Overall Steps per Second: 10,296.68725

Timestep Collection Time: 2.31472
Timestep Consumption Time: 2.54315
PPO Batch Consumption Time: 0.29318
Total Iteration Time: 4.85787

Cumulative Model Updates: 235,322
Cumulative Timesteps: 1,963,235,572

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81,867.64510
Policy Entropy: 2.26541
Value Function Loss: 0.01815

Mean KL Divergence: 0.00763
SB3 Clip Fraction: 0.07429
Policy Update Magnitude: 0.29792
Value Function Update Magnitude: 0.31492

Collected Steps per Second: 22,321.42060
Overall Steps per Second: 10,492.61255

Timestep Collection Time: 2.24054
Timestep Consumption Time: 2.52586
PPO Batch Consumption Time: 0.29239
Total Iteration Time: 4.76640

Cumulative Model Updates: 235,328
Cumulative Timesteps: 1,963,285,584

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1963285584...
Checkpoint 1963285584 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 70,164.18276
Policy Entropy: 2.25645
Value Function Loss: 0.01596

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.07739
Policy Update Magnitude: 0.28888
Value Function Update Magnitude: 0.28507

Collected Steps per Second: 22,020.34073
Overall Steps per Second: 10,467.56680

Timestep Collection Time: 2.27135
Timestep Consumption Time: 2.50683
PPO Batch Consumption Time: 0.28882
Total Iteration Time: 4.77819

Cumulative Model Updates: 235,334
Cumulative Timesteps: 1,963,335,600

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55,263.85755
Policy Entropy: 2.22187
Value Function Loss: 0.01731

Mean KL Divergence: 0.00718
SB3 Clip Fraction: 0.06688
Policy Update Magnitude: 0.29214
Value Function Update Magnitude: 0.27487

Collected Steps per Second: 22,055.99233
Overall Steps per Second: 10,502.34635

Timestep Collection Time: 2.26832
Timestep Consumption Time: 2.49538
PPO Batch Consumption Time: 0.29073
Total Iteration Time: 4.76370

Cumulative Model Updates: 235,340
Cumulative Timesteps: 1,963,385,630

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1963385630...
Checkpoint 1963385630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 59,023.43589
Policy Entropy: 2.23673
Value Function Loss: 0.01848

Mean KL Divergence: 0.00745
SB3 Clip Fraction: 0.06970
Policy Update Magnitude: 0.30631
Value Function Update Magnitude: 0.30191

Collected Steps per Second: 22,183.40873
Overall Steps per Second: 10,688.29252

Timestep Collection Time: 2.25403
Timestep Consumption Time: 2.42418
PPO Batch Consumption Time: 0.27754
Total Iteration Time: 4.67820

Cumulative Model Updates: 235,346
Cumulative Timesteps: 1,963,435,632

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55,185.48290
Policy Entropy: 2.22977
Value Function Loss: 0.02167

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.07683
Policy Update Magnitude: 0.31219
Value Function Update Magnitude: 0.33291

Collected Steps per Second: 22,074.31474
Overall Steps per Second: 10,464.20757

Timestep Collection Time: 2.26580
Timestep Consumption Time: 2.51392
PPO Batch Consumption Time: 0.29392
Total Iteration Time: 4.77972

Cumulative Model Updates: 235,352
Cumulative Timesteps: 1,963,485,648

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1963485648...
Checkpoint 1963485648 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 66,799.21825
Policy Entropy: 2.23998
Value Function Loss: 0.02105

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.06997
Policy Update Magnitude: 0.31530
Value Function Update Magnitude: 0.28932

Collected Steps per Second: 21,632.40296
Overall Steps per Second: 10,517.21604

Timestep Collection Time: 2.31190
Timestep Consumption Time: 2.44335
PPO Batch Consumption Time: 0.27993
Total Iteration Time: 4.75525

Cumulative Model Updates: 235,358
Cumulative Timesteps: 1,963,535,660

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47,820.51002
Policy Entropy: 2.23502
Value Function Loss: 0.02173

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.07040
Policy Update Magnitude: 0.31547
Value Function Update Magnitude: 0.28163

Collected Steps per Second: 22,166.61205
Overall Steps per Second: 10,512.39205

Timestep Collection Time: 2.25790
Timestep Consumption Time: 2.50315
PPO Batch Consumption Time: 0.29072
Total Iteration Time: 4.76105

Cumulative Model Updates: 235,364
Cumulative Timesteps: 1,963,585,710

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 1963585710...
Checkpoint 1963585710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,422.25753
Policy Entropy: 2.24174
Value Function Loss: 0.02111

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.06733
Policy Update Magnitude: 0.31280
Value Function Update Magnitude: 0.25559

Collected Steps per Second: 21,362.96156
Overall Steps per Second: 10,312.80228

Timestep Collection Time: 2.34069
Timestep Consumption Time: 2.50804
PPO Batch Consumption Time: 0.29229
Total Iteration Time: 4.84873

Cumulative Model Updates: 235,370
Cumulative Timesteps: 1,963,635,714

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,703.29260
Policy Entropy: 2.25530
Value Function Loss: 0.02017

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.07487
Policy Update Magnitude: 0.30541
Value Function Update Magnitude: 0.26314

Collected Steps per Second: 21,558.71779
Overall Steps per Second: 10,360.39903

Timestep Collection Time: 2.32045
Timestep Consumption Time: 2.50813
PPO Batch Consumption Time: 0.29128
Total Iteration Time: 4.82858

Cumulative Model Updates: 235,376
Cumulative Timesteps: 1,963,685,740

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1963685740...
Checkpoint 1963685740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,302.66651
Policy Entropy: 2.25971
Value Function Loss: 0.02003

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.07441
Policy Update Magnitude: 0.30384
Value Function Update Magnitude: 0.29409

Collected Steps per Second: 21,367.03563
Overall Steps per Second: 10,341.97086

Timestep Collection Time: 2.34024
Timestep Consumption Time: 2.49481
PPO Batch Consumption Time: 0.29185
Total Iteration Time: 4.83506

Cumulative Model Updates: 235,382
Cumulative Timesteps: 1,963,735,744

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58,257.20988
Policy Entropy: 2.27447
Value Function Loss: 0.01819

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.07835
Policy Update Magnitude: 0.30043
Value Function Update Magnitude: 0.28426

Collected Steps per Second: 21,440.18125
Overall Steps per Second: 10,316.37481

Timestep Collection Time: 2.33282
Timestep Consumption Time: 2.51540
PPO Batch Consumption Time: 0.29372
Total Iteration Time: 4.84821

Cumulative Model Updates: 235,388
Cumulative Timesteps: 1,963,785,760

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1963785760...
Checkpoint 1963785760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 65,464.58006
Policy Entropy: 2.27918
Value Function Loss: 0.01881

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.07856
Policy Update Magnitude: 0.30096
Value Function Update Magnitude: 0.28416

Collected Steps per Second: 21,046.46642
Overall Steps per Second: 10,199.96711

Timestep Collection Time: 2.37703
Timestep Consumption Time: 2.52770
PPO Batch Consumption Time: 0.29405
Total Iteration Time: 4.90472

Cumulative Model Updates: 235,394
Cumulative Timesteps: 1,963,835,788

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65,303.11317
Policy Entropy: 2.25751
Value Function Loss: 0.01990

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.07506
Policy Update Magnitude: 0.30630
Value Function Update Magnitude: 0.30342

Collected Steps per Second: 22,010.83083
Overall Steps per Second: 10,474.35690

Timestep Collection Time: 2.27170
Timestep Consumption Time: 2.50205
PPO Batch Consumption Time: 0.28573
Total Iteration Time: 4.77375

Cumulative Model Updates: 235,400
Cumulative Timesteps: 1,963,885,790

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1963885790...
Checkpoint 1963885790 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 72,764.71750
Policy Entropy: 2.24664
Value Function Loss: 0.01885

Mean KL Divergence: 0.00783
SB3 Clip Fraction: 0.07216
Policy Update Magnitude: 0.30608
Value Function Update Magnitude: 0.29520

Collected Steps per Second: 21,983.91850
Overall Steps per Second: 10,623.39370

Timestep Collection Time: 2.27439
Timestep Consumption Time: 2.43220
PPO Batch Consumption Time: 0.27827
Total Iteration Time: 4.70659

Cumulative Model Updates: 235,406
Cumulative Timesteps: 1,963,935,790

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81,941.98139
Policy Entropy: 2.24917
Value Function Loss: 0.01744

Mean KL Divergence: 0.00684
SB3 Clip Fraction: 0.06244
Policy Update Magnitude: 0.30051
Value Function Update Magnitude: 0.28143

Collected Steps per Second: 22,068.03823
Overall Steps per Second: 10,499.07831

Timestep Collection Time: 2.26572
Timestep Consumption Time: 2.49660
PPO Batch Consumption Time: 0.29239
Total Iteration Time: 4.76232

Cumulative Model Updates: 235,412
Cumulative Timesteps: 1,963,985,790

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1963985790...
Checkpoint 1963985790 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 65,766.72562
Policy Entropy: 2.27324
Value Function Loss: 0.01944

Mean KL Divergence: 0.00708
SB3 Clip Fraction: 0.06688
Policy Update Magnitude: 0.30049
Value Function Update Magnitude: 0.28734

Collected Steps per Second: 21,090.99005
Overall Steps per Second: 10,552.21627

Timestep Collection Time: 2.37153
Timestep Consumption Time: 2.36851
PPO Batch Consumption Time: 0.28009
Total Iteration Time: 4.74005

Cumulative Model Updates: 235,418
Cumulative Timesteps: 1,964,035,808

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,903.66794
Policy Entropy: 2.28713
Value Function Loss: 0.02264

Mean KL Divergence: 0.00729
SB3 Clip Fraction: 0.06451
Policy Update Magnitude: 0.30923
Value Function Update Magnitude: 0.29733

Collected Steps per Second: 21,585.53282
Overall Steps per Second: 10,533.64176

Timestep Collection Time: 2.31711
Timestep Consumption Time: 2.43111
PPO Batch Consumption Time: 0.29379
Total Iteration Time: 4.74822

Cumulative Model Updates: 235,424
Cumulative Timesteps: 1,964,085,824

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1964085824...
Checkpoint 1964085824 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,141.14982
Policy Entropy: 2.28562
Value Function Loss: 0.02308

Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.07194
Policy Update Magnitude: 0.31291
Value Function Update Magnitude: 0.30178

Collected Steps per Second: 21,367.26205
Overall Steps per Second: 10,560.08738

Timestep Collection Time: 2.34012
Timestep Consumption Time: 2.39488
PPO Batch Consumption Time: 0.28487
Total Iteration Time: 4.73500

Cumulative Model Updates: 235,430
Cumulative Timesteps: 1,964,135,826

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,665.59849
Policy Entropy: 2.29198
Value Function Loss: 0.02342

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.07243
Policy Update Magnitude: 0.31241
Value Function Update Magnitude: 0.26081

Collected Steps per Second: 21,393.71429
Overall Steps per Second: 10,462.98861

Timestep Collection Time: 2.33760
Timestep Consumption Time: 2.44210
PPO Batch Consumption Time: 0.29452
Total Iteration Time: 4.77971

Cumulative Model Updates: 235,436
Cumulative Timesteps: 1,964,185,836

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1964185836...
Checkpoint 1964185836 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 64,730.76702
Policy Entropy: 2.28058
Value Function Loss: 0.02126

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.07504
Policy Update Magnitude: 0.30660
Value Function Update Magnitude: 0.27225

Collected Steps per Second: 20,889.58976
Overall Steps per Second: 10,253.37903

Timestep Collection Time: 2.39536
Timestep Consumption Time: 2.48479
PPO Batch Consumption Time: 0.29352
Total Iteration Time: 4.88015

Cumulative Model Updates: 235,442
Cumulative Timesteps: 1,964,235,874

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58,239.25210
Policy Entropy: 2.29552
Value Function Loss: 0.02146

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.07582
Policy Update Magnitude: 0.30025
Value Function Update Magnitude: 0.30424

Collected Steps per Second: 21,319.33281
Overall Steps per Second: 10,398.88222

Timestep Collection Time: 2.34566
Timestep Consumption Time: 2.46331
PPO Batch Consumption Time: 0.28798
Total Iteration Time: 4.80898

Cumulative Model Updates: 235,448
Cumulative Timesteps: 1,964,285,882

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1964285882...
Checkpoint 1964285882 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 65,064.60692
Policy Entropy: 2.28106
Value Function Loss: 0.02336

Mean KL Divergence: 0.00764
SB3 Clip Fraction: 0.07134
Policy Update Magnitude: 0.30468
Value Function Update Magnitude: 0.27381

Collected Steps per Second: 21,367.18187
Overall Steps per Second: 10,381.72448

Timestep Collection Time: 2.34135
Timestep Consumption Time: 2.47750
PPO Batch Consumption Time: 0.29099
Total Iteration Time: 4.81885

Cumulative Model Updates: 235,454
Cumulative Timesteps: 1,964,335,910

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67,559.82046
Policy Entropy: 2.27896
Value Function Loss: 0.02480

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.08087
Policy Update Magnitude: 0.31066
Value Function Update Magnitude: 0.28250

Collected Steps per Second: 21,557.07353
Overall Steps per Second: 10,214.01082

Timestep Collection Time: 2.32100
Timestep Consumption Time: 2.57756
PPO Batch Consumption Time: 0.29567
Total Iteration Time: 4.89857

Cumulative Model Updates: 235,460
Cumulative Timesteps: 1,964,385,944

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1964385944...
Checkpoint 1964385944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 54,298.11123
Policy Entropy: 2.27242
Value Function Loss: 0.02571

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.08047
Policy Update Magnitude: 0.31665
Value Function Update Magnitude: 0.28472

Collected Steps per Second: 22,087.09594
Overall Steps per Second: 10,603.14426

Timestep Collection Time: 2.26549
Timestep Consumption Time: 2.45368
PPO Batch Consumption Time: 0.27986
Total Iteration Time: 4.71917

Cumulative Model Updates: 235,466
Cumulative Timesteps: 1,964,435,982

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61,145.50867
Policy Entropy: 2.26163
Value Function Loss: 0.02627

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.09099
Policy Update Magnitude: 0.32150
Value Function Update Magnitude: 0.22749

Collected Steps per Second: 21,854.16907
Overall Steps per Second: 10,608.20458

Timestep Collection Time: 2.28917
Timestep Consumption Time: 2.42680
PPO Batch Consumption Time: 0.27710
Total Iteration Time: 4.71597

Cumulative Model Updates: 235,472
Cumulative Timesteps: 1,964,486,010

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1964486010...
Checkpoint 1964486010 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40,140.06234
Policy Entropy: 2.25846
Value Function Loss: 0.02494

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.08583
Policy Update Magnitude: 0.31632
Value Function Update Magnitude: 0.16451

Collected Steps per Second: 22,127.86478
Overall Steps per Second: 10,583.35609

Timestep Collection Time: 2.26032
Timestep Consumption Time: 2.46559
PPO Batch Consumption Time: 0.28524
Total Iteration Time: 4.72591

Cumulative Model Updates: 235,478
Cumulative Timesteps: 1,964,536,026

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,230.84382
Policy Entropy: 2.25547
Value Function Loss: 0.02425

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.07943
Policy Update Magnitude: 0.31817
Value Function Update Magnitude: 0.15375

Collected Steps per Second: 21,785.38038
Overall Steps per Second: 10,440.01281

Timestep Collection Time: 2.29622
Timestep Consumption Time: 2.49535
PPO Batch Consumption Time: 0.28800
Total Iteration Time: 4.79156

Cumulative Model Updates: 235,484
Cumulative Timesteps: 1,964,586,050

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1964586050...
Checkpoint 1964586050 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,633.81994
Policy Entropy: 2.27810
Value Function Loss: 0.02347

Mean KL Divergence: 0.00739
SB3 Clip Fraction: 0.07068
Policy Update Magnitude: 0.31565
Value Function Update Magnitude: 0.13756

Collected Steps per Second: 21,931.21903
Overall Steps per Second: 10,622.67888

Timestep Collection Time: 2.28031
Timestep Consumption Time: 2.42754
PPO Batch Consumption Time: 0.27844
Total Iteration Time: 4.70785

Cumulative Model Updates: 235,490
Cumulative Timesteps: 1,964,636,060

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,759.01507
Policy Entropy: 2.25471
Value Function Loss: 0.02426

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.07000
Policy Update Magnitude: 0.31359
Value Function Update Magnitude: 0.14713

Collected Steps per Second: 21,496.07397
Overall Steps per Second: 10,507.31324

Timestep Collection Time: 2.32684
Timestep Consumption Time: 2.43346
PPO Batch Consumption Time: 0.27856
Total Iteration Time: 4.76030

Cumulative Model Updates: 235,496
Cumulative Timesteps: 1,964,686,078

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1964686078...
Checkpoint 1964686078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,448.93570
Policy Entropy: 2.24424
Value Function Loss: 0.02212

Mean KL Divergence: 0.00689
SB3 Clip Fraction: 0.06525
Policy Update Magnitude: 0.30403
Value Function Update Magnitude: 0.14067

Collected Steps per Second: 20,944.82838
Overall Steps per Second: 10,219.83013

Timestep Collection Time: 2.38847
Timestep Consumption Time: 2.50653
PPO Batch Consumption Time: 0.29354
Total Iteration Time: 4.89499

Cumulative Model Updates: 235,502
Cumulative Timesteps: 1,964,736,104

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,676.36646
Policy Entropy: 2.23447
Value Function Loss: 0.02084

Mean KL Divergence: 0.00685
SB3 Clip Fraction: 0.06606
Policy Update Magnitude: 0.29348
Value Function Update Magnitude: 0.13231

Collected Steps per Second: 21,703.80932
Overall Steps per Second: 10,406.63730

Timestep Collection Time: 2.30549
Timestep Consumption Time: 2.50278
PPO Batch Consumption Time: 0.28988
Total Iteration Time: 4.80828

Cumulative Model Updates: 235,508
Cumulative Timesteps: 1,964,786,142

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1964786142...
Checkpoint 1964786142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 70,163.53173
Policy Entropy: 2.26244
Value Function Loss: 0.02120

Mean KL Divergence: 0.00646
SB3 Clip Fraction: 0.06387
Policy Update Magnitude: 0.29571
Value Function Update Magnitude: 0.15631

Collected Steps per Second: 21,178.83520
Overall Steps per Second: 10,260.30373

Timestep Collection Time: 2.36198
Timestep Consumption Time: 2.51351
PPO Batch Consumption Time: 0.29358
Total Iteration Time: 4.87549

Cumulative Model Updates: 235,514
Cumulative Timesteps: 1,964,836,166

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60,285.43178
Policy Entropy: 2.28135
Value Function Loss: 0.02258

Mean KL Divergence: 0.00743
SB3 Clip Fraction: 0.07258
Policy Update Magnitude: 0.30424
Value Function Update Magnitude: 0.23220

Collected Steps per Second: 21,779.38622
Overall Steps per Second: 10,410.64615

Timestep Collection Time: 2.29694
Timestep Consumption Time: 2.50833
PPO Batch Consumption Time: 0.29032
Total Iteration Time: 4.80527

Cumulative Model Updates: 235,520
Cumulative Timesteps: 1,964,886,192

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1964886192...
Checkpoint 1964886192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 61,023.96814
Policy Entropy: 2.28203
Value Function Loss: 0.02212

Mean KL Divergence: 0.00724
SB3 Clip Fraction: 0.06858
Policy Update Magnitude: 0.30869
Value Function Update Magnitude: 0.30556

Collected Steps per Second: 21,748.15403
Overall Steps per Second: 10,305.23912

Timestep Collection Time: 2.29905
Timestep Consumption Time: 2.55286
PPO Batch Consumption Time: 0.29298
Total Iteration Time: 4.85190

Cumulative Model Updates: 235,526
Cumulative Timesteps: 1,964,936,192

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60,858.83846
Policy Entropy: 2.27379
Value Function Loss: 0.01925

Mean KL Divergence: 0.00702
SB3 Clip Fraction: 0.06450
Policy Update Magnitude: 0.30175
Value Function Update Magnitude: 0.30336

Collected Steps per Second: 22,212.81325
Overall Steps per Second: 10,505.07869

Timestep Collection Time: 2.25104
Timestep Consumption Time: 2.50875
PPO Batch Consumption Time: 0.29070
Total Iteration Time: 4.75979

Cumulative Model Updates: 235,532
Cumulative Timesteps: 1,964,986,194

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1964986194...
Checkpoint 1964986194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 50,767.26482
Policy Entropy: 2.27607
Value Function Loss: 0.01851

Mean KL Divergence: 0.00706
SB3 Clip Fraction: 0.06567
Policy Update Magnitude: 0.29662
Value Function Update Magnitude: 0.27321

Collected Steps per Second: 22,116.40484
Overall Steps per Second: 10,494.36784

Timestep Collection Time: 2.26203
Timestep Consumption Time: 2.50510
PPO Batch Consumption Time: 0.29410
Total Iteration Time: 4.76713

Cumulative Model Updates: 235,538
Cumulative Timesteps: 1,965,036,222

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,113.05116
Policy Entropy: 2.26609
Value Function Loss: 0.02102

Mean KL Divergence: 0.00718
SB3 Clip Fraction: 0.06792
Policy Update Magnitude: 0.30454
Value Function Update Magnitude: 0.27408

Collected Steps per Second: 22,222.91846
Overall Steps per Second: 10,535.19112

Timestep Collection Time: 2.25020
Timestep Consumption Time: 2.49637
PPO Batch Consumption Time: 0.29318
Total Iteration Time: 4.74657

Cumulative Model Updates: 235,544
Cumulative Timesteps: 1,965,086,228

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1965086228...
Checkpoint 1965086228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 74,602.84930
Policy Entropy: 2.26328
Value Function Loss: 0.02128

Mean KL Divergence: 0.00740
SB3 Clip Fraction: 0.06951
Policy Update Magnitude: 0.31551
Value Function Update Magnitude: 0.31886

Collected Steps per Second: 21,880.33679
Overall Steps per Second: 10,615.50483

Timestep Collection Time: 2.28543
Timestep Consumption Time: 2.42523
PPO Batch Consumption Time: 0.27799
Total Iteration Time: 4.71066

Cumulative Model Updates: 235,550
Cumulative Timesteps: 1,965,136,234

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53,397.83350
Policy Entropy: 2.25269
Value Function Loss: 0.02126

Mean KL Divergence: 0.00759
SB3 Clip Fraction: 0.07059
Policy Update Magnitude: 0.32125
Value Function Update Magnitude: 0.32256

Collected Steps per Second: 22,085.72782
Overall Steps per Second: 10,533.20181

Timestep Collection Time: 2.26508
Timestep Consumption Time: 2.48428
PPO Batch Consumption Time: 0.29130
Total Iteration Time: 4.74936

Cumulative Model Updates: 235,556
Cumulative Timesteps: 1,965,186,260

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1965186260...
Checkpoint 1965186260 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,625.10726
Policy Entropy: 2.27441
Value Function Loss: 0.01893

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.07087
Policy Update Magnitude: 0.30935
Value Function Update Magnitude: 0.31825

Collected Steps per Second: 21,831.48794
Overall Steps per Second: 10,515.52345

Timestep Collection Time: 2.29100
Timestep Consumption Time: 2.46539
PPO Batch Consumption Time: 0.28635
Total Iteration Time: 4.75640

Cumulative Model Updates: 235,562
Cumulative Timesteps: 1,965,236,276

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,787.23335
Policy Entropy: 2.29335
Value Function Loss: 0.01910

Mean KL Divergence: 0.00752
SB3 Clip Fraction: 0.06711
Policy Update Magnitude: 0.29739
Value Function Update Magnitude: 0.33322

Collected Steps per Second: 21,643.57218
Overall Steps per Second: 10,434.70501

Timestep Collection Time: 2.31015
Timestep Consumption Time: 2.48155
PPO Batch Consumption Time: 0.28511
Total Iteration Time: 4.79170

Cumulative Model Updates: 235,568
Cumulative Timesteps: 1,965,286,276

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1965286276...
Checkpoint 1965286276 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,256.36125
Policy Entropy: 2.29652
Value Function Loss: 0.01892

Mean KL Divergence: 0.00620
SB3 Clip Fraction: 0.06234
Policy Update Magnitude: 0.29350
Value Function Update Magnitude: 0.32897

Collected Steps per Second: 21,543.83959
Overall Steps per Second: 10,577.88392

Timestep Collection Time: 2.32094
Timestep Consumption Time: 2.40609
PPO Batch Consumption Time: 0.27773
Total Iteration Time: 4.72703

Cumulative Model Updates: 235,574
Cumulative Timesteps: 1,965,336,278

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,602.16304
Policy Entropy: 2.28048
Value Function Loss: 0.01754

Mean KL Divergence: 0.00608
SB3 Clip Fraction: 0.05926
Policy Update Magnitude: 0.28994
Value Function Update Magnitude: 0.31717

Collected Steps per Second: 21,270.64149
Overall Steps per Second: 10,475.36634

Timestep Collection Time: 2.35197
Timestep Consumption Time: 2.42380
PPO Batch Consumption Time: 0.28734
Total Iteration Time: 4.77578

Cumulative Model Updates: 235,580
Cumulative Timesteps: 1,965,386,306

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1965386306...
Checkpoint 1965386306 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,680.54736
Policy Entropy: 2.24925
Value Function Loss: 0.01975

Mean KL Divergence: 0.00719
SB3 Clip Fraction: 0.07118
Policy Update Magnitude: 0.29686
Value Function Update Magnitude: 0.30232

Collected Steps per Second: 20,845.64234
Overall Steps per Second: 10,353.12902

Timestep Collection Time: 2.39916
Timestep Consumption Time: 2.43146
PPO Batch Consumption Time: 0.29134
Total Iteration Time: 4.83062

Cumulative Model Updates: 235,586
Cumulative Timesteps: 1,965,436,318

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,993.14574
Policy Entropy: 2.25974
Value Function Loss: 0.02239

Mean KL Divergence: 0.00714
SB3 Clip Fraction: 0.06843
Policy Update Magnitude: 0.31116
Value Function Update Magnitude: 0.33019

Collected Steps per Second: 21,681.58833
Overall Steps per Second: 10,541.95592

Timestep Collection Time: 2.30629
Timestep Consumption Time: 2.43704
PPO Batch Consumption Time: 0.28876
Total Iteration Time: 4.74333

Cumulative Model Updates: 235,592
Cumulative Timesteps: 1,965,486,322

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1965486322...
Checkpoint 1965486322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 50,061.02037
Policy Entropy: 2.28061
Value Function Loss: 0.02266

Mean KL Divergence: 0.00747
SB3 Clip Fraction: 0.06839
Policy Update Magnitude: 0.31624
Value Function Update Magnitude: 0.34527

Collected Steps per Second: 21,162.99183
Overall Steps per Second: 10,349.64724

Timestep Collection Time: 2.36450
Timestep Consumption Time: 2.47044
PPO Batch Consumption Time: 0.29532
Total Iteration Time: 4.83495

Cumulative Model Updates: 235,598
Cumulative Timesteps: 1,965,536,362

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53,873.79461
Policy Entropy: 2.29249
Value Function Loss: 0.02263

Mean KL Divergence: 0.00740
SB3 Clip Fraction: 0.07099
Policy Update Magnitude: 0.31022
Value Function Update Magnitude: 0.31906

Collected Steps per Second: 21,355.72150
Overall Steps per Second: 10,504.55206

Timestep Collection Time: 2.34176
Timestep Consumption Time: 2.41903
PPO Batch Consumption Time: 0.27958
Total Iteration Time: 4.76079

Cumulative Model Updates: 235,604
Cumulative Timesteps: 1,965,586,372

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1965586372...
Checkpoint 1965586372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47,151.79837
Policy Entropy: 2.29657
Value Function Loss: 0.02324

Mean KL Divergence: 0.00763
SB3 Clip Fraction: 0.07409
Policy Update Magnitude: 0.30296
Value Function Update Magnitude: 0.30714

Collected Steps per Second: 21,645.55757
Overall Steps per Second: 10,595.12342

Timestep Collection Time: 2.31022
Timestep Consumption Time: 2.40950
PPO Batch Consumption Time: 0.27910
Total Iteration Time: 4.71972

Cumulative Model Updates: 235,610
Cumulative Timesteps: 1,965,636,378

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,104.02529
Policy Entropy: 2.27175
Value Function Loss: 0.02364

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.08537
Policy Update Magnitude: 0.30600
Value Function Update Magnitude: 0.28220

Collected Steps per Second: 21,989.05489
Overall Steps per Second: 10,519.27593

Timestep Collection Time: 2.27431
Timestep Consumption Time: 2.47982
PPO Batch Consumption Time: 0.29140
Total Iteration Time: 4.75413

Cumulative Model Updates: 235,616
Cumulative Timesteps: 1,965,686,388

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1965686388...
Checkpoint 1965686388 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,459.61232
Policy Entropy: 2.28670
Value Function Loss: 0.02318

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.08699
Policy Update Magnitude: 0.29951
Value Function Update Magnitude: 0.26633

Collected Steps per Second: 21,710.25268
Overall Steps per Second: 10,611.37392

Timestep Collection Time: 2.30499
Timestep Consumption Time: 2.41089
PPO Batch Consumption Time: 0.27914
Total Iteration Time: 4.71588

Cumulative Model Updates: 235,622
Cumulative Timesteps: 1,965,736,430

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82,574.85648
Policy Entropy: 2.28802
Value Function Loss: 0.01856

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.08561
Policy Update Magnitude: 0.29014
Value Function Update Magnitude: 0.27102

Collected Steps per Second: 21,706.73711
Overall Steps per Second: 10,474.12300

Timestep Collection Time: 2.30509
Timestep Consumption Time: 2.47202
PPO Batch Consumption Time: 0.28654
Total Iteration Time: 4.77711

Cumulative Model Updates: 235,628
Cumulative Timesteps: 1,965,786,466

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1965786466...
Checkpoint 1965786466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 68,820.50051
Policy Entropy: 2.29298
Value Function Loss: 0.01736

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.07969
Policy Update Magnitude: 0.27988
Value Function Update Magnitude: 0.28292

Collected Steps per Second: 21,344.97128
Overall Steps per Second: 10,295.93772

Timestep Collection Time: 2.34369
Timestep Consumption Time: 2.51512
PPO Batch Consumption Time: 0.29329
Total Iteration Time: 4.85881

Cumulative Model Updates: 235,634
Cumulative Timesteps: 1,965,836,492

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92,866.46100
Policy Entropy: 2.29341
Value Function Loss: 0.01846

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.08656
Policy Update Magnitude: 0.28831
Value Function Update Magnitude: 0.29067

Collected Steps per Second: 21,781.82317
Overall Steps per Second: 10,376.50829

Timestep Collection Time: 2.29613
Timestep Consumption Time: 2.52379
PPO Batch Consumption Time: 0.29274
Total Iteration Time: 4.81993

Cumulative Model Updates: 235,640
Cumulative Timesteps: 1,965,886,506

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1965886506...
Checkpoint 1965886506 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 65,604.62481
Policy Entropy: 2.28673
Value Function Loss: 0.01818

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.08671
Policy Update Magnitude: 0.29297
Value Function Update Magnitude: 0.28395

Collected Steps per Second: 21,227.82961
Overall Steps per Second: 10,212.48714

Timestep Collection Time: 2.35662
Timestep Consumption Time: 2.54189
PPO Batch Consumption Time: 0.29504
Total Iteration Time: 4.89851

Cumulative Model Updates: 235,646
Cumulative Timesteps: 1,965,936,532

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63,263.80930
Policy Entropy: 2.30432
Value Function Loss: 0.02075

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.09033
Policy Update Magnitude: 0.29195
Value Function Update Magnitude: 0.25079

Collected Steps per Second: 22,134.98696
Overall Steps per Second: 10,437.43035

Timestep Collection Time: 2.26022
Timestep Consumption Time: 2.53310
PPO Batch Consumption Time: 0.28857
Total Iteration Time: 4.79333

Cumulative Model Updates: 235,652
Cumulative Timesteps: 1,965,986,562

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1965986562...
Checkpoint 1965986562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,681.87193
Policy Entropy: 2.28890
Value Function Loss: 0.01926

Mean KL Divergence: 0.01091
SB3 Clip Fraction: 0.09838
Policy Update Magnitude: 0.28869
Value Function Update Magnitude: 0.21499

Collected Steps per Second: 21,754.26005
Overall Steps per Second: 10,514.58793

Timestep Collection Time: 2.29840
Timestep Consumption Time: 2.45690
PPO Batch Consumption Time: 0.27862
Total Iteration Time: 4.75530

Cumulative Model Updates: 235,658
Cumulative Timesteps: 1,966,036,562

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,481.82150
Policy Entropy: 2.28351
Value Function Loss: 0.02036

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.08249
Policy Update Magnitude: 0.28352
Value Function Update Magnitude: 0.18295

Collected Steps per Second: 22,232.78640
Overall Steps per Second: 10,589.85878

Timestep Collection Time: 2.24911
Timestep Consumption Time: 2.47277
PPO Batch Consumption Time: 0.28904
Total Iteration Time: 4.72188

Cumulative Model Updates: 235,664
Cumulative Timesteps: 1,966,086,566

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1966086566...
Checkpoint 1966086566 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,987.01664
Policy Entropy: 2.27827
Value Function Loss: 0.01981

Mean KL Divergence: 0.00728
SB3 Clip Fraction: 0.06969
Policy Update Magnitude: 0.28946
Value Function Update Magnitude: 0.19202

Collected Steps per Second: 21,869.39906
Overall Steps per Second: 10,597.84210

Timestep Collection Time: 2.28740
Timestep Consumption Time: 2.43281
PPO Batch Consumption Time: 0.27943
Total Iteration Time: 4.72021

Cumulative Model Updates: 235,670
Cumulative Timesteps: 1,966,136,590

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42,920.72280
Policy Entropy: 2.26939
Value Function Loss: 0.02097

Mean KL Divergence: 0.00719
SB3 Clip Fraction: 0.06793
Policy Update Magnitude: 0.30232
Value Function Update Magnitude: 0.20567

Collected Steps per Second: 22,185.66993
Overall Steps per Second: 10,477.83011

Timestep Collection Time: 2.25461
Timestep Consumption Time: 2.51928
PPO Batch Consumption Time: 0.29306
Total Iteration Time: 4.77389

Cumulative Model Updates: 235,676
Cumulative Timesteps: 1,966,186,610

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1966186610...
Checkpoint 1966186610 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,534.58933
Policy Entropy: 2.27580
Value Function Loss: 0.02160

Mean KL Divergence: 0.00760
SB3 Clip Fraction: 0.07186
Policy Update Magnitude: 0.31636
Value Function Update Magnitude: 0.19425

Collected Steps per Second: 21,710.67948
Overall Steps per Second: 10,566.68078

Timestep Collection Time: 2.30366
Timestep Consumption Time: 2.42952
PPO Batch Consumption Time: 0.27955
Total Iteration Time: 4.73318

Cumulative Model Updates: 235,682
Cumulative Timesteps: 1,966,236,624

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,314.88599
Policy Entropy: 2.28200
Value Function Loss: 0.02248

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.07347
Policy Update Magnitude: 0.31168
Value Function Update Magnitude: 0.24364

Collected Steps per Second: 20,641.76184
Overall Steps per Second: 10,132.48797

Timestep Collection Time: 2.42286
Timestep Consumption Time: 2.51295
PPO Batch Consumption Time: 0.29476
Total Iteration Time: 4.93581

Cumulative Model Updates: 235,688
Cumulative Timesteps: 1,966,286,636

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1966286636...
Checkpoint 1966286636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40,655.71085
Policy Entropy: 2.30679
Value Function Loss: 0.02316

Mean KL Divergence: 0.00718
SB3 Clip Fraction: 0.06995
Policy Update Magnitude: 0.31186
Value Function Update Magnitude: 0.27752

Collected Steps per Second: 21,619.92101
Overall Steps per Second: 10,551.17836

Timestep Collection Time: 2.31268
Timestep Consumption Time: 2.42613
PPO Batch Consumption Time: 0.27930
Total Iteration Time: 4.73881

Cumulative Model Updates: 235,694
Cumulative Timesteps: 1,966,336,636

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48,518.34441
Policy Entropy: 2.30541
Value Function Loss: 0.02180

Mean KL Divergence: 0.00675
SB3 Clip Fraction: 0.06833
Policy Update Magnitude: 0.31145
Value Function Update Magnitude: 0.29914

Collected Steps per Second: 21,883.88543
Overall Steps per Second: 10,484.95858

Timestep Collection Time: 2.28506
Timestep Consumption Time: 2.48425
PPO Batch Consumption Time: 0.28681
Total Iteration Time: 4.76931

Cumulative Model Updates: 235,700
Cumulative Timesteps: 1,966,386,642

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1966386642...
Checkpoint 1966386642 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,668.59432
Policy Entropy: 2.31423
Value Function Loss: 0.02151

Mean KL Divergence: 0.00710
SB3 Clip Fraction: 0.06794
Policy Update Magnitude: 0.30561
Value Function Update Magnitude: 0.31380

Collected Steps per Second: 21,296.83758
Overall Steps per Second: 10,247.44330

Timestep Collection Time: 2.34852
Timestep Consumption Time: 2.53231
PPO Batch Consumption Time: 0.29262
Total Iteration Time: 4.88083

Cumulative Model Updates: 235,706
Cumulative Timesteps: 1,966,436,658

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,972.15183
Policy Entropy: 2.27627
Value Function Loss: 0.02098

Mean KL Divergence: 0.00697
SB3 Clip Fraction: 0.06614
Policy Update Magnitude: 0.30393
Value Function Update Magnitude: 0.32235

Collected Steps per Second: 22,075.13702
Overall Steps per Second: 10,475.77971

Timestep Collection Time: 2.26599
Timestep Consumption Time: 2.50903
PPO Batch Consumption Time: 0.28767
Total Iteration Time: 4.77501

Cumulative Model Updates: 235,712
Cumulative Timesteps: 1,966,486,680

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1966486680...
Checkpoint 1966486680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 57,740.78651
Policy Entropy: 2.27276
Value Function Loss: 0.02147

Mean KL Divergence: 0.00665
SB3 Clip Fraction: 0.06524
Policy Update Magnitude: 0.30732
Value Function Update Magnitude: 0.33714

Collected Steps per Second: 21,783.40700
Overall Steps per Second: 10,571.80515

Timestep Collection Time: 2.29560
Timestep Consumption Time: 2.43453
PPO Batch Consumption Time: 0.27892
Total Iteration Time: 4.73013

Cumulative Model Updates: 235,718
Cumulative Timesteps: 1,966,536,686

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,195.84060
Policy Entropy: 2.27808
Value Function Loss: 0.02163

Mean KL Divergence: 0.00731
SB3 Clip Fraction: 0.07000
Policy Update Magnitude: 0.31211
Value Function Update Magnitude: 0.31562

Collected Steps per Second: 21,977.60285
Overall Steps per Second: 10,482.96923

Timestep Collection Time: 2.27577
Timestep Consumption Time: 2.49540
PPO Batch Consumption Time: 0.28996
Total Iteration Time: 4.77117

Cumulative Model Updates: 235,724
Cumulative Timesteps: 1,966,586,702

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1966586702...
Checkpoint 1966586702 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 74,713.04888
Policy Entropy: 2.30852
Value Function Loss: 0.02024

Mean KL Divergence: 0.00720
SB3 Clip Fraction: 0.06926
Policy Update Magnitude: 0.30319
Value Function Update Magnitude: 0.25891

Collected Steps per Second: 21,930.74123
Overall Steps per Second: 10,602.20908

Timestep Collection Time: 2.27990
Timestep Consumption Time: 2.43609
PPO Batch Consumption Time: 0.27913
Total Iteration Time: 4.71600

Cumulative Model Updates: 235,730
Cumulative Timesteps: 1,966,636,702

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,800.85709
Policy Entropy: 2.30337
Value Function Loss: 0.02255

Mean KL Divergence: 0.00680
SB3 Clip Fraction: 0.06495
Policy Update Magnitude: 0.30288
Value Function Update Magnitude: 0.24567

Collected Steps per Second: 21,919.85038
Overall Steps per Second: 10,480.11767

Timestep Collection Time: 2.28177
Timestep Consumption Time: 2.49070
PPO Batch Consumption Time: 0.28852
Total Iteration Time: 4.77247

Cumulative Model Updates: 235,736
Cumulative Timesteps: 1,966,686,718

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1966686718...
Checkpoint 1966686718 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,422.82941
Policy Entropy: 2.30193
Value Function Loss: 0.01984

Mean KL Divergence: 0.00678
SB3 Clip Fraction: 0.06787
Policy Update Magnitude: 0.30375
Value Function Update Magnitude: 0.30983

Collected Steps per Second: 21,741.39996
Overall Steps per Second: 10,574.58114

Timestep Collection Time: 2.29985
Timestep Consumption Time: 2.42866
PPO Batch Consumption Time: 0.27912
Total Iteration Time: 4.72851

Cumulative Model Updates: 235,742
Cumulative Timesteps: 1,966,736,720

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66,753.44251
Policy Entropy: 2.28798
Value Function Loss: 0.02192

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.07239
Policy Update Magnitude: 0.30962
Value Function Update Magnitude: 0.29755

Collected Steps per Second: 21,582.06000
Overall Steps per Second: 10,490.75384

Timestep Collection Time: 2.31794
Timestep Consumption Time: 2.45064
PPO Batch Consumption Time: 0.27867
Total Iteration Time: 4.76858

Cumulative Model Updates: 235,748
Cumulative Timesteps: 1,966,786,746

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1966786746...
Checkpoint 1966786746 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 51,725.55622
Policy Entropy: 2.27566
Value Function Loss: 0.02000

Mean KL Divergence: 0.00751
SB3 Clip Fraction: 0.07173
Policy Update Magnitude: 0.30779
Value Function Update Magnitude: 0.30172

Collected Steps per Second: 21,430.95196
Overall Steps per Second: 10,342.69134

Timestep Collection Time: 2.33531
Timestep Consumption Time: 2.50366
PPO Batch Consumption Time: 0.29277
Total Iteration Time: 4.83897

Cumulative Model Updates: 235,754
Cumulative Timesteps: 1,966,836,794

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,743.53630
Policy Entropy: 2.26785
Value Function Loss: 0.02094

Mean KL Divergence: 0.00723
SB3 Clip Fraction: 0.06814
Policy Update Magnitude: 0.30628
Value Function Update Magnitude: 0.31958

Collected Steps per Second: 21,448.94142
Overall Steps per Second: 10,359.71666

Timestep Collection Time: 2.33242
Timestep Consumption Time: 2.49667
PPO Batch Consumption Time: 0.29116
Total Iteration Time: 4.82909

Cumulative Model Updates: 235,760
Cumulative Timesteps: 1,966,886,822

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1966886822...
Checkpoint 1966886822 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 70,809.89283
Policy Entropy: 2.25455
Value Function Loss: 0.02042

Mean KL Divergence: 0.00717
SB3 Clip Fraction: 0.06905
Policy Update Magnitude: 0.30446
Value Function Update Magnitude: 0.31255

Collected Steps per Second: 21,140.43429
Overall Steps per Second: 10,279.01830

Timestep Collection Time: 2.36693
Timestep Consumption Time: 2.50104
PPO Batch Consumption Time: 0.29428
Total Iteration Time: 4.86797

Cumulative Model Updates: 235,766
Cumulative Timesteps: 1,966,936,860

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83,847.12881
Policy Entropy: 2.27196
Value Function Loss: 0.01853

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.07976
Policy Update Magnitude: 0.30008
Value Function Update Magnitude: 0.30493

Collected Steps per Second: 21,602.20329
Overall Steps per Second: 10,363.34556

Timestep Collection Time: 2.31523
Timestep Consumption Time: 2.51082
PPO Batch Consumption Time: 0.29208
Total Iteration Time: 4.82605

Cumulative Model Updates: 235,772
Cumulative Timesteps: 1,966,986,874

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1966986874...
Checkpoint 1966986874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 64,713.85733
Policy Entropy: 2.27606
Value Function Loss: 0.02105

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.08071
Policy Update Magnitude: 0.29979
Value Function Update Magnitude: 0.29659

Collected Steps per Second: 21,204.15249
Overall Steps per Second: 10,261.86553

Timestep Collection Time: 2.35850
Timestep Consumption Time: 2.51488
PPO Batch Consumption Time: 0.29350
Total Iteration Time: 4.87338

Cumulative Model Updates: 235,778
Cumulative Timesteps: 1,967,036,884

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58,196.45989
Policy Entropy: 2.29226
Value Function Loss: 0.02009

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.07452
Policy Update Magnitude: 0.29748
Value Function Update Magnitude: 0.27509

Collected Steps per Second: 22,135.07048
Overall Steps per Second: 10,419.38786

Timestep Collection Time: 2.25976
Timestep Consumption Time: 2.54090
PPO Batch Consumption Time: 0.29361
Total Iteration Time: 4.80067

Cumulative Model Updates: 235,784
Cumulative Timesteps: 1,967,086,904

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1967086904...
Checkpoint 1967086904 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 58,196.45989
Policy Entropy: 2.28548
Value Function Loss: 0.02007

Mean KL Divergence: 0.00757
SB3 Clip Fraction: 0.06904
Policy Update Magnitude: 0.30006
Value Function Update Magnitude: 0.22464

Collected Steps per Second: 21,142.22192
Overall Steps per Second: 10,538.40317

Timestep Collection Time: 2.36560
Timestep Consumption Time: 2.38028
PPO Batch Consumption Time: 0.27974
Total Iteration Time: 4.74588

Cumulative Model Updates: 235,790
Cumulative Timesteps: 1,967,136,918

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 69,258.33582
Policy Entropy: 2.28006
Value Function Loss: 0.01984

Mean KL Divergence: 0.00752
SB3 Clip Fraction: 0.07042
Policy Update Magnitude: 0.30080
Value Function Update Magnitude: 0.20536

Collected Steps per Second: 21,069.18309
Overall Steps per Second: 10,536.46281

Timestep Collection Time: 2.37332
Timestep Consumption Time: 2.37248
PPO Batch Consumption Time: 0.27904
Total Iteration Time: 4.74581

Cumulative Model Updates: 235,796
Cumulative Timesteps: 1,967,186,922

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1967186922...
Checkpoint 1967186922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 50,249.61277
Policy Entropy: 2.26484
Value Function Loss: 0.02107

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.09303
Policy Update Magnitude: 0.30145
Value Function Update Magnitude: 0.26663

Collected Steps per Second: 21,362.65933
Overall Steps per Second: 10,609.68117

Timestep Collection Time: 2.34109
Timestep Consumption Time: 2.37271
PPO Batch Consumption Time: 0.27951
Total Iteration Time: 4.71381

Cumulative Model Updates: 235,802
Cumulative Timesteps: 1,967,236,934

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57,765.62295
Policy Entropy: 2.27839
Value Function Loss: 0.02135

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.08600
Policy Update Magnitude: 0.30569
Value Function Update Magnitude: 0.33022

Collected Steps per Second: 21,517.68446
Overall Steps per Second: 10,482.71827

Timestep Collection Time: 2.32367
Timestep Consumption Time: 2.44609
PPO Batch Consumption Time: 0.28496
Total Iteration Time: 4.76976

Cumulative Model Updates: 235,808
Cumulative Timesteps: 1,967,286,934

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1967286934...
Checkpoint 1967286934 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 51,289.74924
Policy Entropy: 2.27626
Value Function Loss: 0.01964

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.08247
Policy Update Magnitude: 0.30222
Value Function Update Magnitude: 0.34526

Collected Steps per Second: 22,034.86321
Overall Steps per Second: 10,612.58831

Timestep Collection Time: 2.26913
Timestep Consumption Time: 2.44225
PPO Batch Consumption Time: 0.28524
Total Iteration Time: 4.71139

Cumulative Model Updates: 235,814
Cumulative Timesteps: 1,967,336,934

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58,116.23601
Policy Entropy: 2.29278
Value Function Loss: 0.02009

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.07726
Policy Update Magnitude: 0.30687
Value Function Update Magnitude: 0.33459

Collected Steps per Second: 21,926.05876
Overall Steps per Second: 10,490.29249

Timestep Collection Time: 2.28103
Timestep Consumption Time: 2.48662
PPO Batch Consumption Time: 0.29364
Total Iteration Time: 4.76765

Cumulative Model Updates: 235,820
Cumulative Timesteps: 1,967,386,948

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1967386948...
Checkpoint 1967386948 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 65,719.39444
Policy Entropy: 2.29307
Value Function Loss: 0.02293

Mean KL Divergence: 0.00699
SB3 Clip Fraction: 0.06623
Policy Update Magnitude: 0.32412
Value Function Update Magnitude: 0.34694

Collected Steps per Second: 21,585.29071
Overall Steps per Second: 10,543.20711

Timestep Collection Time: 2.31648
Timestep Consumption Time: 2.42609
PPO Batch Consumption Time: 0.27887
Total Iteration Time: 4.74258

Cumulative Model Updates: 235,826
Cumulative Timesteps: 1,967,436,950

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65,212.69676
Policy Entropy: 2.30118
Value Function Loss: 0.02225

Mean KL Divergence: 0.00736
SB3 Clip Fraction: 0.06760
Policy Update Magnitude: 0.31880
Value Function Update Magnitude: 0.37600

Collected Steps per Second: 21,556.00382
Overall Steps per Second: 10,509.92204

Timestep Collection Time: 2.32000
Timestep Consumption Time: 2.43836
PPO Batch Consumption Time: 0.27932
Total Iteration Time: 4.75836

Cumulative Model Updates: 235,832
Cumulative Timesteps: 1,967,486,960

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1967486960...
Checkpoint 1967486960 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 76,541.05741
Policy Entropy: 2.29974
Value Function Loss: 0.02080

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.07194
Policy Update Magnitude: 0.30825
Value Function Update Magnitude: 0.38201

Collected Steps per Second: 21,539.51776
Overall Steps per Second: 10,403.73871

Timestep Collection Time: 2.32178
Timestep Consumption Time: 2.48515
PPO Batch Consumption Time: 0.29087
Total Iteration Time: 4.80693

Cumulative Model Updates: 235,838
Cumulative Timesteps: 1,967,536,970

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 64,576.29131
Policy Entropy: 2.28773
Value Function Loss: 0.01977

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.07945
Policy Update Magnitude: 0.30193
Value Function Update Magnitude: 0.35492

Collected Steps per Second: 21,798.42784
Overall Steps per Second: 10,433.21830

Timestep Collection Time: 2.29393
Timestep Consumption Time: 2.49884
PPO Batch Consumption Time: 0.29083
Total Iteration Time: 4.79277

Cumulative Model Updates: 235,844
Cumulative Timesteps: 1,967,586,974

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1967586974...
Checkpoint 1967586974 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 50,282.05256
Policy Entropy: 2.30043
Value Function Loss: 0.02189

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.07471
Policy Update Magnitude: 0.30547
Value Function Update Magnitude: 0.33378

Collected Steps per Second: 21,791.41650
Overall Steps per Second: 10,465.64483

Timestep Collection Time: 2.29540
Timestep Consumption Time: 2.48405
PPO Batch Consumption Time: 0.28657
Total Iteration Time: 4.77945

Cumulative Model Updates: 235,850
Cumulative Timesteps: 1,967,636,994

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,154.48701
Policy Entropy: 2.30756
Value Function Loss: 0.02253

Mean KL Divergence: 0.00749
SB3 Clip Fraction: 0.07217
Policy Update Magnitude: 0.30819
Value Function Update Magnitude: 0.30852

Collected Steps per Second: 21,861.35960
Overall Steps per Second: 10,547.90045

Timestep Collection Time: 2.28751
Timestep Consumption Time: 2.45353
PPO Batch Consumption Time: 0.27798
Total Iteration Time: 4.74104

Cumulative Model Updates: 235,856
Cumulative Timesteps: 1,967,687,002

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1967687002...
Checkpoint 1967687002 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,615.99839
Policy Entropy: 2.30010
Value Function Loss: 0.02072

Mean KL Divergence: 0.00750
SB3 Clip Fraction: 0.07142
Policy Update Magnitude: 0.30732
Value Function Update Magnitude: 0.22537

Collected Steps per Second: 22,038.14079
Overall Steps per Second: 10,496.99294

Timestep Collection Time: 2.26997
Timestep Consumption Time: 2.49577
PPO Batch Consumption Time: 0.28901
Total Iteration Time: 4.76575

Cumulative Model Updates: 235,862
Cumulative Timesteps: 1,967,737,028

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56,515.30649
Policy Entropy: 2.28522
Value Function Loss: 0.02302

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.07507
Policy Update Magnitude: 0.30703
Value Function Update Magnitude: 0.26961

Collected Steps per Second: 22,031.13039
Overall Steps per Second: 10,521.63688

Timestep Collection Time: 2.27124
Timestep Consumption Time: 2.48448
PPO Batch Consumption Time: 0.28811
Total Iteration Time: 4.75572

Cumulative Model Updates: 235,868
Cumulative Timesteps: 1,967,787,066

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1967787066...
Checkpoint 1967787066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,143.42928
Policy Entropy: 2.28542
Value Function Loss: 0.02028

Mean KL Divergence: 0.00783
SB3 Clip Fraction: 0.07351
Policy Update Magnitude: 0.30548
Value Function Update Magnitude: 0.32495

Collected Steps per Second: 21,191.13837
Overall Steps per Second: 10,586.49885

Timestep Collection Time: 2.36052
Timestep Consumption Time: 2.36456
PPO Batch Consumption Time: 0.27987
Total Iteration Time: 4.72507

Cumulative Model Updates: 235,874
Cumulative Timesteps: 1,967,837,088

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65,738.38556
Policy Entropy: 2.31005
Value Function Loss: 0.02079

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.07998
Policy Update Magnitude: 0.29694
Value Function Update Magnitude: 0.32924

Collected Steps per Second: 21,566.78599
Overall Steps per Second: 10,499.57566

Timestep Collection Time: 2.31903
Timestep Consumption Time: 2.44440
PPO Batch Consumption Time: 0.29443
Total Iteration Time: 4.76343

Cumulative Model Updates: 235,880
Cumulative Timesteps: 1,967,887,102

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1967887102...
Checkpoint 1967887102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 59,026.50241
Policy Entropy: 2.29907
Value Function Loss: 0.01620

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.07672
Policy Update Magnitude: 0.28609
Value Function Update Magnitude: 0.27908

Collected Steps per Second: 21,377.41993
Overall Steps per Second: 10,681.76314

Timestep Collection Time: 2.33976
Timestep Consumption Time: 2.34280
PPO Batch Consumption Time: 0.27797
Total Iteration Time: 4.68256

Cumulative Model Updates: 235,886
Cumulative Timesteps: 1,967,937,120

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49,151.63909
Policy Entropy: 2.30461
Value Function Loss: 0.01784

Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.07809
Policy Update Magnitude: 0.29010
Value Function Update Magnitude: 0.26183

Collected Steps per Second: 21,045.96379
Overall Steps per Second: 10,468.17692

Timestep Collection Time: 2.37718
Timestep Consumption Time: 2.40207
PPO Batch Consumption Time: 0.27784
Total Iteration Time: 4.77925

Cumulative Model Updates: 235,892
Cumulative Timesteps: 1,967,987,150

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1967987150...
Checkpoint 1967987150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,151.63909
Policy Entropy: 2.29823
Value Function Loss: 0.01731

Mean KL Divergence: 0.00723
SB3 Clip Fraction: 0.06862
Policy Update Magnitude: 0.29179
Value Function Update Magnitude: 0.31077

Collected Steps per Second: 21,385.45669
Overall Steps per Second: 10,530.65284

Timestep Collection Time: 2.33841
Timestep Consumption Time: 2.41039
PPO Batch Consumption Time: 0.27844
Total Iteration Time: 4.74880

Cumulative Model Updates: 235,898
Cumulative Timesteps: 1,968,037,158

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55,066.44422
Policy Entropy: 2.28964
Value Function Loss: 0.01700

Mean KL Divergence: 0.00740
SB3 Clip Fraction: 0.07065
Policy Update Magnitude: 0.29431
Value Function Update Magnitude: 0.32852

Collected Steps per Second: 21,702.13045
Overall Steps per Second: 10,513.25709

Timestep Collection Time: 2.30429
Timestep Consumption Time: 2.45237
PPO Batch Consumption Time: 0.28623
Total Iteration Time: 4.75666

Cumulative Model Updates: 235,904
Cumulative Timesteps: 1,968,087,166

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1968087166...
Checkpoint 1968087166 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,587.87331
Policy Entropy: 2.28285
Value Function Loss: 0.01653

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.07247
Policy Update Magnitude: 0.29591
Value Function Update Magnitude: 0.30364

Collected Steps per Second: 21,487.09444
Overall Steps per Second: 10,286.97805

Timestep Collection Time: 2.32735
Timestep Consumption Time: 2.53394
PPO Batch Consumption Time: 0.29294
Total Iteration Time: 4.86129

Cumulative Model Updates: 235,910
Cumulative Timesteps: 1,968,137,174

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49,975.41888
Policy Entropy: 2.27651
Value Function Loss: 0.01712

Mean KL Divergence: 0.00740
SB3 Clip Fraction: 0.06826
Policy Update Magnitude: 0.29873
Value Function Update Magnitude: 0.29012

Collected Steps per Second: 21,943.30048
Overall Steps per Second: 10,452.48925

Timestep Collection Time: 2.28006
Timestep Consumption Time: 2.50655
PPO Batch Consumption Time: 0.29321
Total Iteration Time: 4.78661

Cumulative Model Updates: 235,916
Cumulative Timesteps: 1,968,187,206

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1968187206...
Checkpoint 1968187206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,086.99417
Policy Entropy: 2.28933
Value Function Loss: 0.01676

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.07202
Policy Update Magnitude: 0.28909
Value Function Update Magnitude: 0.28160

Collected Steps per Second: 21,813.43134
Overall Steps per Second: 10,541.64950

Timestep Collection Time: 2.29244
Timestep Consumption Time: 2.45122
PPO Batch Consumption Time: 0.27963
Total Iteration Time: 4.74366

Cumulative Model Updates: 235,922
Cumulative Timesteps: 1,968,237,212

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45,366.86357
Policy Entropy: 2.31095
Value Function Loss: 0.01854

Mean KL Divergence: 0.00731
SB3 Clip Fraction: 0.06898
Policy Update Magnitude: 0.29434
Value Function Update Magnitude: 0.29341

Collected Steps per Second: 22,158.70511
Overall Steps per Second: 10,460.99576

Timestep Collection Time: 2.25654
Timestep Consumption Time: 2.52331
PPO Batch Consumption Time: 0.29471
Total Iteration Time: 4.77985

Cumulative Model Updates: 235,928
Cumulative Timesteps: 1,968,287,214

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1968287214...
Checkpoint 1968287214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 73,398.33983
Policy Entropy: 2.30236
Value Function Loss: 0.01796

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.07475
Policy Update Magnitude: 0.29107
Value Function Update Magnitude: 0.31581

Collected Steps per Second: 21,845.59705
Overall Steps per Second: 10,569.63946

Timestep Collection Time: 2.28998
Timestep Consumption Time: 2.44301
PPO Batch Consumption Time: 0.27967
Total Iteration Time: 4.73299

Cumulative Model Updates: 235,934
Cumulative Timesteps: 1,968,337,240

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60,014.25991
Policy Entropy: 2.28548
Value Function Loss: 0.01739

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.07631
Policy Update Magnitude: 0.28827
Value Function Update Magnitude: 0.31417

Collected Steps per Second: 21,801.29767
Overall Steps per Second: 10,596.11395

Timestep Collection Time: 2.29353
Timestep Consumption Time: 2.42537
PPO Batch Consumption Time: 0.27770
Total Iteration Time: 4.71890

Cumulative Model Updates: 235,940
Cumulative Timesteps: 1,968,387,242

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1968387242...
Checkpoint 1968387242 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84,761.75399
Policy Entropy: 2.28742
Value Function Loss: 0.01960

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.07787
Policy Update Magnitude: 0.29606
Value Function Update Magnitude: 0.30806

Collected Steps per Second: 21,629.62802
Overall Steps per Second: 10,533.36506

Timestep Collection Time: 2.31248
Timestep Consumption Time: 2.43605
PPO Batch Consumption Time: 0.27895
Total Iteration Time: 4.74853

Cumulative Model Updates: 235,946
Cumulative Timesteps: 1,968,437,260

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48,951.23507
Policy Entropy: 2.29416
Value Function Loss: 0.01883

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.07632
Policy Update Magnitude: 0.29760
Value Function Update Magnitude: 0.29691

Collected Steps per Second: 21,741.21851
Overall Steps per Second: 10,561.28371

Timestep Collection Time: 2.30189
Timestep Consumption Time: 2.43673
PPO Batch Consumption Time: 0.27725
Total Iteration Time: 4.73863

Cumulative Model Updates: 235,952
Cumulative Timesteps: 1,968,487,306

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1968487306...
Checkpoint 1968487306 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,708.37921
Policy Entropy: 2.28299
Value Function Loss: 0.02096

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.07663
Policy Update Magnitude: 0.29705
Value Function Update Magnitude: 0.28771

Collected Steps per Second: 21,704.08857
Overall Steps per Second: 10,550.86995

Timestep Collection Time: 2.30463
Timestep Consumption Time: 2.43621
PPO Batch Consumption Time: 0.27543
Total Iteration Time: 4.74084

Cumulative Model Updates: 235,958
Cumulative Timesteps: 1,968,537,326

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51,420.43286
Policy Entropy: 2.25975
Value Function Loss: 0.01814

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.08077
Policy Update Magnitude: 0.29222
Value Function Update Magnitude: 0.27213

Collected Steps per Second: 21,973.85749
Overall Steps per Second: 10,449.38954

Timestep Collection Time: 2.27671
Timestep Consumption Time: 2.51094
PPO Batch Consumption Time: 0.28842
Total Iteration Time: 4.78765

Cumulative Model Updates: 235,964
Cumulative Timesteps: 1,968,587,354

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1968587354...
Checkpoint 1968587354 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 59,726.53555
Policy Entropy: 2.25760
Value Function Loss: 0.01869

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.08050
Policy Update Magnitude: 0.28008
Value Function Update Magnitude: 0.25098

Collected Steps per Second: 22,020.94998
Overall Steps per Second: 10,621.48812

Timestep Collection Time: 2.27066
Timestep Consumption Time: 2.43697
PPO Batch Consumption Time: 0.27965
Total Iteration Time: 4.70763

Cumulative Model Updates: 235,970
Cumulative Timesteps: 1,968,637,356

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55,781.66079
Policy Entropy: 2.27121
Value Function Loss: 0.01877

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.08707
Policy Update Magnitude: 0.31262
Value Function Update Magnitude: 0.26877

Collected Steps per Second: 22,150.40274
Overall Steps per Second: 10,500.33619

Timestep Collection Time: 2.25730
Timestep Consumption Time: 2.50446
PPO Batch Consumption Time: 0.29194
Total Iteration Time: 4.76175

Cumulative Model Updates: 235,976
Cumulative Timesteps: 1,968,687,356

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1968687356...
Checkpoint 1968687356 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 70,383.52950
Policy Entropy: 2.28114
Value Function Loss: 0.02047

Mean KL Divergence: 0.01147
SB3 Clip Fraction: 0.09972
Policy Update Magnitude: 0.30455
Value Function Update Magnitude: 0.29949

Collected Steps per Second: 21,761.39668
Overall Steps per Second: 10,592.64067

Timestep Collection Time: 2.29857
Timestep Consumption Time: 2.42358
PPO Batch Consumption Time: 0.27925
Total Iteration Time: 4.72215

Cumulative Model Updates: 235,982
Cumulative Timesteps: 1,968,737,376

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83,877.67029
Policy Entropy: 2.29115
Value Function Loss: 0.01904

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.08512
Policy Update Magnitude: 0.29510
Value Function Update Magnitude: 0.31771

Collected Steps per Second: 21,597.03009
Overall Steps per Second: 10,503.53935

Timestep Collection Time: 2.31624
Timestep Consumption Time: 2.44634
PPO Batch Consumption Time: 0.29438
Total Iteration Time: 4.76259

Cumulative Model Updates: 235,988
Cumulative Timesteps: 1,968,787,400

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1968787400...
Checkpoint 1968787400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 53,601.57093
Policy Entropy: 2.29763
Value Function Loss: 0.01830

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.08318
Policy Update Magnitude: 0.29172
Value Function Update Magnitude: 0.31178

Collected Steps per Second: 21,282.61743
Overall Steps per Second: 10,610.33209

Timestep Collection Time: 2.35037
Timestep Consumption Time: 2.36409
PPO Batch Consumption Time: 0.27928
Total Iteration Time: 4.71446

Cumulative Model Updates: 235,994
Cumulative Timesteps: 1,968,837,422

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47,925.71095
Policy Entropy: 2.28922
Value Function Loss: 0.01866

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.07366
Policy Update Magnitude: 0.29815
Value Function Update Magnitude: 0.27962

Collected Steps per Second: 20,866.91374
Overall Steps per Second: 10,556.23697

Timestep Collection Time: 2.39748
Timestep Consumption Time: 2.34171
PPO Batch Consumption Time: 0.27714
Total Iteration Time: 4.73919

Cumulative Model Updates: 236,000
Cumulative Timesteps: 1,968,887,450

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1968887450...
Checkpoint 1968887450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 59,445.19929
Policy Entropy: 2.26571
Value Function Loss: 0.02119

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.07581
Policy Update Magnitude: 0.30655
Value Function Update Magnitude: 0.32440

Collected Steps per Second: 21,124.04503
Overall Steps per Second: 10,619.54322

Timestep Collection Time: 2.36744
Timestep Consumption Time: 2.34180
PPO Batch Consumption Time: 0.27724
Total Iteration Time: 4.70924

Cumulative Model Updates: 236,006
Cumulative Timesteps: 1,968,937,460

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80,813.33526
Policy Entropy: 2.27107
Value Function Loss: 0.01947

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.08662
Policy Update Magnitude: 0.30005
Value Function Update Magnitude: 0.33713

Collected Steps per Second: 21,129.77486
Overall Steps per Second: 10,395.72229

Timestep Collection Time: 2.36642
Timestep Consumption Time: 2.44344
PPO Batch Consumption Time: 0.28534
Total Iteration Time: 4.80986

Cumulative Model Updates: 236,012
Cumulative Timesteps: 1,968,987,462

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1968987462...
Checkpoint 1968987462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 68,530.03079
Policy Entropy: 2.26187
Value Function Loss: 0.02027

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.08777
Policy Update Magnitude: 0.29060
Value Function Update Magnitude: 0.31965

Collected Steps per Second: 21,454.62807
Overall Steps per Second: 10,332.12921

Timestep Collection Time: 2.33143
Timestep Consumption Time: 2.50978
PPO Batch Consumption Time: 0.29217
Total Iteration Time: 4.84121

Cumulative Model Updates: 236,018
Cumulative Timesteps: 1,969,037,482

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54,083.22036
Policy Entropy: 2.26666
Value Function Loss: 0.01795

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.08634
Policy Update Magnitude: 0.29510
Value Function Update Magnitude: 0.31329

Collected Steps per Second: 22,144.90892
Overall Steps per Second: 10,438.74237

Timestep Collection Time: 2.25975
Timestep Consumption Time: 2.53412
PPO Batch Consumption Time: 0.29410
Total Iteration Time: 4.79387

Cumulative Model Updates: 236,024
Cumulative Timesteps: 1,969,087,524

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1969087524...
Checkpoint 1969087524 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,500.56626
Policy Entropy: 2.27744
Value Function Loss: 0.01763

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.08242
Policy Update Magnitude: 0.28984
Value Function Update Magnitude: 0.29578

Collected Steps per Second: 21,929.97843
Overall Steps per Second: 10,607.64722

Timestep Collection Time: 2.28044
Timestep Consumption Time: 2.43408
PPO Batch Consumption Time: 0.27780
Total Iteration Time: 4.71452

Cumulative Model Updates: 236,030
Cumulative Timesteps: 1,969,137,534

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57,852.33233
Policy Entropy: 2.29154
Value Function Loss: 0.01850

Mean KL Divergence: 0.00782
SB3 Clip Fraction: 0.07292
Policy Update Magnitude: 0.28832
Value Function Update Magnitude: 0.27007

Collected Steps per Second: 22,184.75456
Overall Steps per Second: 10,487.91151

Timestep Collection Time: 2.25569
Timestep Consumption Time: 2.51570
PPO Batch Consumption Time: 0.29366
Total Iteration Time: 4.77140

Cumulative Model Updates: 236,036
Cumulative Timesteps: 1,969,187,576

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1969187576...
Checkpoint 1969187576 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 53,368.54171
Policy Entropy: 2.28635
Value Function Loss: 0.01837

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.07203
Policy Update Magnitude: 0.28499
Value Function Update Magnitude: 0.29389

Collected Steps per Second: 21,735.14315
Overall Steps per Second: 10,581.44767

Timestep Collection Time: 2.30079
Timestep Consumption Time: 2.42522
PPO Batch Consumption Time: 0.27831
Total Iteration Time: 4.72601

Cumulative Model Updates: 236,042
Cumulative Timesteps: 1,969,237,584

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47,751.90050
Policy Entropy: 2.25731
Value Function Loss: 0.01961

Mean KL Divergence: 0.00688
SB3 Clip Fraction: 0.06444
Policy Update Magnitude: 0.29183
Value Function Update Magnitude: 0.30885

Collected Steps per Second: 22,009.20952
Overall Steps per Second: 10,482.38110

Timestep Collection Time: 2.27232
Timestep Consumption Time: 2.49873
PPO Batch Consumption Time: 0.29362
Total Iteration Time: 4.77105

Cumulative Model Updates: 236,048
Cumulative Timesteps: 1,969,287,596

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1969287596...
Checkpoint 1969287596 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 53,194.45241
Policy Entropy: 2.26977
Value Function Loss: 0.01822

Mean KL Divergence: 0.00670
SB3 Clip Fraction: 0.06275
Policy Update Magnitude: 0.29836
Value Function Update Magnitude: 0.24839

Collected Steps per Second: 21,960.41873
Overall Steps per Second: 10,580.22517

Timestep Collection Time: 2.27755
Timestep Consumption Time: 2.44976
PPO Batch Consumption Time: 0.28364
Total Iteration Time: 4.72731

Cumulative Model Updates: 236,054
Cumulative Timesteps: 1,969,337,612

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48,370.46743
Policy Entropy: 2.29425
Value Function Loss: 0.01994

Mean KL Divergence: 0.00722
SB3 Clip Fraction: 0.06705
Policy Update Magnitude: 0.29443
Value Function Update Magnitude: 0.24562

Collected Steps per Second: 21,887.48109
Overall Steps per Second: 10,462.66790

Timestep Collection Time: 2.28551
Timestep Consumption Time: 2.49568
PPO Batch Consumption Time: 0.28810
Total Iteration Time: 4.78119

Cumulative Model Updates: 236,060
Cumulative Timesteps: 1,969,387,636

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1969387636...
Checkpoint 1969387636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 52,553.22699
Policy Entropy: 2.31295
Value Function Loss: 0.01929

Mean KL Divergence: 0.00690
SB3 Clip Fraction: 0.06549
Policy Update Magnitude: 0.29061
Value Function Update Magnitude: 0.26801

Collected Steps per Second: 21,364.21723
Overall Steps per Second: 10,358.27594

Timestep Collection Time: 2.34102
Timestep Consumption Time: 2.48739
PPO Batch Consumption Time: 0.29118
Total Iteration Time: 4.82841

Cumulative Model Updates: 236,066
Cumulative Timesteps: 1,969,437,650

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,972.61073
Policy Entropy: 2.28283
Value Function Loss: 0.02023

Mean KL Divergence: 0.00711
SB3 Clip Fraction: 0.06869
Policy Update Magnitude: 0.29489
Value Function Update Magnitude: 0.28354

Collected Steps per Second: 21,266.34017
Overall Steps per Second: 10,463.05392

Timestep Collection Time: 2.35264
Timestep Consumption Time: 2.42914
PPO Batch Consumption Time: 0.29130
Total Iteration Time: 4.78178

Cumulative Model Updates: 236,072
Cumulative Timesteps: 1,969,487,682

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1969487682...
Checkpoint 1969487682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 72,907.40452
Policy Entropy: 2.25102
Value Function Loss: 0.01843

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.07772
Policy Update Magnitude: 0.29554
Value Function Update Magnitude: 0.27732

Collected Steps per Second: 20,933.08194
Overall Steps per Second: 10,510.06533

Timestep Collection Time: 2.38942
Timestep Consumption Time: 2.36963
PPO Batch Consumption Time: 0.27719
Total Iteration Time: 4.75906

Cumulative Model Updates: 236,078
Cumulative Timesteps: 1,969,537,700

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47,384.27181
Policy Entropy: 2.25471
Value Function Loss: 0.01840

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.07680
Policy Update Magnitude: 0.29823
Value Function Update Magnitude: 0.24832

Collected Steps per Second: 21,727.47358
Overall Steps per Second: 10,565.54586

Timestep Collection Time: 2.30225
Timestep Consumption Time: 2.43220
PPO Batch Consumption Time: 0.29049
Total Iteration Time: 4.73445

Cumulative Model Updates: 236,084
Cumulative Timesteps: 1,969,587,722

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1969587722...
Checkpoint 1969587722 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86,551.19995
Policy Entropy: 2.27601
Value Function Loss: 0.01947

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.07312
Policy Update Magnitude: 0.30183
Value Function Update Magnitude: 0.26925

Collected Steps per Second: 21,389.39888
Overall Steps per Second: 10,502.46988

Timestep Collection Time: 2.33761
Timestep Consumption Time: 2.42318
PPO Batch Consumption Time: 0.27861
Total Iteration Time: 4.76078

Cumulative Model Updates: 236,090
Cumulative Timesteps: 1,969,637,722

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 64,797.42629
Policy Entropy: 2.27251
Value Function Loss: 0.02109

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.06979
Policy Update Magnitude: 0.31065
Value Function Update Magnitude: 0.32035

Collected Steps per Second: 22,114.45062
Overall Steps per Second: 10,585.84677

Timestep Collection Time: 2.26178
Timestep Consumption Time: 2.46321
PPO Batch Consumption Time: 0.29094
Total Iteration Time: 4.72499

Cumulative Model Updates: 236,096
Cumulative Timesteps: 1,969,687,740

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1969687740...
Checkpoint 1969687740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,221.67591
Policy Entropy: 2.26553
Value Function Loss: 0.02088

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.07822
Policy Update Magnitude: 0.31232
Value Function Update Magnitude: 0.31511

Collected Steps per Second: 21,899.38832
Overall Steps per Second: 10,501.21461

Timestep Collection Time: 2.28353
Timestep Consumption Time: 2.47858
PPO Batch Consumption Time: 0.29427
Total Iteration Time: 4.76212

Cumulative Model Updates: 236,102
Cumulative Timesteps: 1,969,737,748

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68,011.78125
Policy Entropy: 2.25087
Value Function Loss: 0.02069

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.06823
Policy Update Magnitude: 0.30719
Value Function Update Magnitude: 0.29453

Collected Steps per Second: 22,416.94294
Overall Steps per Second: 10,601.91199

Timestep Collection Time: 2.23054
Timestep Consumption Time: 2.48577
PPO Batch Consumption Time: 0.29035
Total Iteration Time: 4.71632

Cumulative Model Updates: 236,108
Cumulative Timesteps: 1,969,787,750

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1969787750...
Checkpoint 1969787750 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 65,361.57447
Policy Entropy: 2.25326
Value Function Loss: 0.01933

Mean KL Divergence: 0.00709
SB3 Clip Fraction: 0.06508
Policy Update Magnitude: 0.30699
Value Function Update Magnitude: 0.30607

Collected Steps per Second: 21,718.49160
Overall Steps per Second: 10,434.22986

Timestep Collection Time: 2.30338
Timestep Consumption Time: 2.49103
PPO Batch Consumption Time: 0.28735
Total Iteration Time: 4.79441

Cumulative Model Updates: 236,114
Cumulative Timesteps: 1,969,837,776

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53,529.96931
Policy Entropy: 2.25663
Value Function Loss: 0.01873

Mean KL Divergence: 0.00673
SB3 Clip Fraction: 0.06591
Policy Update Magnitude: 0.30385
Value Function Update Magnitude: 0.30468

Collected Steps per Second: 21,859.83799
Overall Steps per Second: 10,479.54670

Timestep Collection Time: 2.28913
Timestep Consumption Time: 2.48589
PPO Batch Consumption Time: 0.28661
Total Iteration Time: 4.77502

Cumulative Model Updates: 236,120
Cumulative Timesteps: 1,969,887,816

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1969887816...
Checkpoint 1969887816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,336.54708
Policy Entropy: 2.26374
Value Function Loss: 0.01970

Mean KL Divergence: 0.00670
SB3 Clip Fraction: 0.06489
Policy Update Magnitude: 0.30179
Value Function Update Magnitude: 0.30864

Collected Steps per Second: 21,354.18877
Overall Steps per Second: 10,353.74516

Timestep Collection Time: 2.34212
Timestep Consumption Time: 2.48841
PPO Batch Consumption Time: 0.29190
Total Iteration Time: 4.83052

Cumulative Model Updates: 236,126
Cumulative Timesteps: 1,969,937,830

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 71,130.14677
Policy Entropy: 2.25937
Value Function Loss: 0.02236

Mean KL Divergence: 0.00737
SB3 Clip Fraction: 0.06935
Policy Update Magnitude: 0.31509
Value Function Update Magnitude: 0.33417

Collected Steps per Second: 21,898.87449
Overall Steps per Second: 10,460.66167

Timestep Collection Time: 2.28523
Timestep Consumption Time: 2.49879
PPO Batch Consumption Time: 0.29056
Total Iteration Time: 4.78402

Cumulative Model Updates: 236,132
Cumulative Timesteps: 1,969,987,874

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1969987874...
Checkpoint 1969987874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,323.83459
Policy Entropy: 2.24684
Value Function Loss: 0.02557

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.07553
Policy Update Magnitude: 0.32403
Value Function Update Magnitude: 0.34629

Collected Steps per Second: 20,443.73247
Overall Steps per Second: 10,044.41921

Timestep Collection Time: 2.44691
Timestep Consumption Time: 2.53337
PPO Batch Consumption Time: 0.29188
Total Iteration Time: 4.98028

Cumulative Model Updates: 236,138
Cumulative Timesteps: 1,970,037,898

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,385.06729
Policy Entropy: 2.25268
Value Function Loss: 0.02612

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.07778
Policy Update Magnitude: 0.33279
Value Function Update Magnitude: 0.35073

Collected Steps per Second: 21,734.45544
Overall Steps per Second: 10,474.07549

Timestep Collection Time: 2.30086
Timestep Consumption Time: 2.47359
PPO Batch Consumption Time: 0.28587
Total Iteration Time: 4.77445

Cumulative Model Updates: 236,144
Cumulative Timesteps: 1,970,087,906

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1970087906...
Checkpoint 1970087906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 57,353.13075
Policy Entropy: 2.26536
Value Function Loss: 0.02546

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.08327
Policy Update Magnitude: 0.32533
Value Function Update Magnitude: 0.29376

Collected Steps per Second: 21,379.36658
Overall Steps per Second: 10,314.80442

Timestep Collection Time: 2.34001
Timestep Consumption Time: 2.51010
PPO Batch Consumption Time: 0.29370
Total Iteration Time: 4.85012

Cumulative Model Updates: 236,150
Cumulative Timesteps: 1,970,137,934

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47,544.58227
Policy Entropy: 2.26767
Value Function Loss: 0.02448

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.08016
Policy Update Magnitude: 0.32508
Value Function Update Magnitude: 0.25321

Collected Steps per Second: 21,995.53045
Overall Steps per Second: 10,469.58743

Timestep Collection Time: 2.27419
Timestep Consumption Time: 2.50365
PPO Batch Consumption Time: 0.29081
Total Iteration Time: 4.77784

Cumulative Model Updates: 236,156
Cumulative Timesteps: 1,970,187,956

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1970187956...
Checkpoint 1970187956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,511.02636
Policy Entropy: 2.27304
Value Function Loss: 0.02330

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.07747
Policy Update Magnitude: 0.32009
Value Function Update Magnitude: 0.24568

Collected Steps per Second: 21,766.72196
Overall Steps per Second: 10,436.74965

Timestep Collection Time: 2.29718
Timestep Consumption Time: 2.49378
PPO Batch Consumption Time: 0.28002
Total Iteration Time: 4.79096

Cumulative Model Updates: 236,162
Cumulative Timesteps: 1,970,237,958

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,727.50018
Policy Entropy: 2.27927
Value Function Loss: 0.02253

Mean KL Divergence: 0.00760
SB3 Clip Fraction: 0.06992
Policy Update Magnitude: 0.31943
Value Function Update Magnitude: 0.25227

Collected Steps per Second: 21,662.28904
Overall Steps per Second: 10,525.98711

Timestep Collection Time: 2.30936
Timestep Consumption Time: 2.44326
PPO Batch Consumption Time: 0.27917
Total Iteration Time: 4.75262

Cumulative Model Updates: 236,168
Cumulative Timesteps: 1,970,287,984

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1970287984...
Checkpoint 1970287984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,447.68175
Policy Entropy: 2.28164
Value Function Loss: 0.02097

Mean KL Divergence: 0.00710
SB3 Clip Fraction: 0.07071
Policy Update Magnitude: 0.31413
Value Function Update Magnitude: 0.25088

Collected Steps per Second: 21,618.87349
Overall Steps per Second: 10,526.65337

Timestep Collection Time: 2.31390
Timestep Consumption Time: 2.43822
PPO Batch Consumption Time: 0.27990
Total Iteration Time: 4.75213

Cumulative Model Updates: 236,174
Cumulative Timesteps: 1,970,338,008

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50,750.96372
Policy Entropy: 2.29612
Value Function Loss: 0.02030

Mean KL Divergence: 0.00687
SB3 Clip Fraction: 0.06447
Policy Update Magnitude: 0.31107
Value Function Update Magnitude: 0.23199

Collected Steps per Second: 22,183.87195
Overall Steps per Second: 10,525.66531

Timestep Collection Time: 2.25506
Timestep Consumption Time: 2.49770
PPO Batch Consumption Time: 0.28824
Total Iteration Time: 4.75276

Cumulative Model Updates: 236,180
Cumulative Timesteps: 1,970,388,034

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1970388034...
Checkpoint 1970388034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,837.67064
Policy Entropy: 2.30608
Value Function Loss: 0.02429

Mean KL Divergence: 0.00747
SB3 Clip Fraction: 0.07180
Policy Update Magnitude: 0.32140
Value Function Update Magnitude: 0.28360

Collected Steps per Second: 21,814.29345
Overall Steps per Second: 10,599.15081

Timestep Collection Time: 2.29290
Timestep Consumption Time: 2.42616
PPO Batch Consumption Time: 0.27884
Total Iteration Time: 4.71906

Cumulative Model Updates: 236,186
Cumulative Timesteps: 1,970,438,052

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46,835.21100
Policy Entropy: 2.30942
Value Function Loss: 0.02443

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.08562
Policy Update Magnitude: 0.32120
Value Function Update Magnitude: 0.33939

Collected Steps per Second: 22,271.84184
Overall Steps per Second: 10,547.10543

Timestep Collection Time: 2.24615
Timestep Consumption Time: 2.49695
PPO Batch Consumption Time: 0.29031
Total Iteration Time: 4.74310

Cumulative Model Updates: 236,192
Cumulative Timesteps: 1,970,488,078

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1970488078...
Checkpoint 1970488078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,551.16696
Policy Entropy: 2.29479
Value Function Loss: 0.02349

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.08839
Policy Update Magnitude: 0.31556
Value Function Update Magnitude: 0.38318

Collected Steps per Second: 21,706.22786
Overall Steps per Second: 10,557.55015

Timestep Collection Time: 2.30496
Timestep Consumption Time: 2.43402
PPO Batch Consumption Time: 0.27946
Total Iteration Time: 4.73898

Cumulative Model Updates: 236,198
Cumulative Timesteps: 1,970,538,110

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,297.48957
Policy Entropy: 2.28117
Value Function Loss: 0.01972

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.07990
Policy Update Magnitude: 0.30944
Value Function Update Magnitude: 0.36582

Collected Steps per Second: 21,825.68703
Overall Steps per Second: 10,505.31326

Timestep Collection Time: 2.29106
Timestep Consumption Time: 2.46882
PPO Batch Consumption Time: 0.28594
Total Iteration Time: 4.75988

Cumulative Model Updates: 236,204
Cumulative Timesteps: 1,970,588,114

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1970588114...
Checkpoint 1970588114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48,475.62617
Policy Entropy: 2.26679
Value Function Loss: 0.02106

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.08050
Policy Update Magnitude: 0.30956
Value Function Update Magnitude: 0.33230

Collected Steps per Second: 21,307.50210
Overall Steps per Second: 10,323.93118

Timestep Collection Time: 2.34903
Timestep Consumption Time: 2.49912
PPO Batch Consumption Time: 0.29245
Total Iteration Time: 4.84815

Cumulative Model Updates: 236,210
Cumulative Timesteps: 1,970,638,166

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53,473.29957
Policy Entropy: 2.27781
Value Function Loss: 0.02137

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.08383
Policy Update Magnitude: 0.31125
Value Function Update Magnitude: 0.33133

Collected Steps per Second: 21,993.70085
Overall Steps per Second: 10,508.37829

Timestep Collection Time: 2.27520
Timestep Consumption Time: 2.48672
PPO Batch Consumption Time: 0.29201
Total Iteration Time: 4.76191

Cumulative Model Updates: 236,216
Cumulative Timesteps: 1,970,688,206

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1970688206...
Checkpoint 1970688206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,777.39787
Policy Entropy: 2.28732
Value Function Loss: 0.02098

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.08572
Policy Update Magnitude: 0.30408
Value Function Update Magnitude: 0.33643

Collected Steps per Second: 21,431.81169
Overall Steps per Second: 10,481.96272

Timestep Collection Time: 2.33513
Timestep Consumption Time: 2.43936
PPO Batch Consumption Time: 0.27941
Total Iteration Time: 4.77449

Cumulative Model Updates: 236,222
Cumulative Timesteps: 1,970,738,252

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47,062.45206
Policy Entropy: 2.29115
Value Function Loss: 0.02354

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.09257
Policy Update Magnitude: 0.30614
Value Function Update Magnitude: 0.31944

Collected Steps per Second: 21,840.79405
Overall Steps per Second: 10,447.45918

Timestep Collection Time: 2.28948
Timestep Consumption Time: 2.49676
PPO Batch Consumption Time: 0.28618
Total Iteration Time: 4.78624

Cumulative Model Updates: 236,228
Cumulative Timesteps: 1,970,788,256

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1970788256...
Checkpoint 1970788256 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,789.41856
Policy Entropy: 2.27909
Value Function Loss: 0.02146

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.09348
Policy Update Magnitude: 0.30768
Value Function Update Magnitude: 0.33618

Collected Steps per Second: 21,708.87096
Overall Steps per Second: 10,336.80890

Timestep Collection Time: 2.30348
Timestep Consumption Time: 2.53418
PPO Batch Consumption Time: 0.29179
Total Iteration Time: 4.83766

Cumulative Model Updates: 236,234
Cumulative Timesteps: 1,970,838,262

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,072.49154
Policy Entropy: 2.28643
Value Function Loss: 0.02262

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.09427
Policy Update Magnitude: 0.30948
Value Function Update Magnitude: 0.35624

Collected Steps per Second: 22,574.73704
Overall Steps per Second: 10,735.72678

Timestep Collection Time: 2.21690
Timestep Consumption Time: 2.44473
PPO Batch Consumption Time: 0.27897
Total Iteration Time: 4.66163

Cumulative Model Updates: 236,240
Cumulative Timesteps: 1,970,888,308

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1970888308...
Checkpoint 1970888308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,417.66755
Policy Entropy: 2.26192
Value Function Loss: 0.02000

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.08303
Policy Update Magnitude: 0.30899
Value Function Update Magnitude: 0.32998

Collected Steps per Second: 21,592.72492
Overall Steps per Second: 10,446.73005

Timestep Collection Time: 2.31587
Timestep Consumption Time: 2.47089
PPO Batch Consumption Time: 0.28960
Total Iteration Time: 4.78676

Cumulative Model Updates: 236,246
Cumulative Timesteps: 1,970,938,314

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45,555.11458
Policy Entropy: 2.24185
Value Function Loss: 0.02200

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.07335
Policy Update Magnitude: 0.31156
Value Function Update Magnitude: 0.30951

Collected Steps per Second: 22,395.39702
Overall Steps per Second: 10,733.43087

Timestep Collection Time: 2.23403
Timestep Consumption Time: 2.42729
PPO Batch Consumption Time: 0.27835
Total Iteration Time: 4.66132

Cumulative Model Updates: 236,252
Cumulative Timesteps: 1,970,988,346

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1970988346...
Checkpoint 1970988346 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,352.39484
Policy Entropy: 2.21795
Value Function Loss: 0.02090

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.08398
Policy Update Magnitude: 0.31680
Value Function Update Magnitude: 0.32755

Collected Steps per Second: 21,205.77000
Overall Steps per Second: 10,568.65961

Timestep Collection Time: 2.35832
Timestep Consumption Time: 2.37359
PPO Batch Consumption Time: 0.28060
Total Iteration Time: 4.73192

Cumulative Model Updates: 236,258
Cumulative Timesteps: 1,971,038,356

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,575.67364
Policy Entropy: 2.22425
Value Function Loss: 0.01861

Mean KL Divergence: 0.01078
SB3 Clip Fraction: 0.09725
Policy Update Magnitude: 0.30790
Value Function Update Magnitude: 0.32787

Collected Steps per Second: 21,612.81738
Overall Steps per Second: 10,532.31318

Timestep Collection Time: 2.31363
Timestep Consumption Time: 2.43405
PPO Batch Consumption Time: 0.29305
Total Iteration Time: 4.74768

Cumulative Model Updates: 236,264
Cumulative Timesteps: 1,971,088,360

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1971088360...
Checkpoint 1971088360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,836.65984
Policy Entropy: 2.25260
Value Function Loss: 0.01785

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.08681
Policy Update Magnitude: 0.29868
Value Function Update Magnitude: 0.28441

Collected Steps per Second: 21,187.98752
Overall Steps per Second: 10,368.63653

Timestep Collection Time: 2.35992
Timestep Consumption Time: 2.46251
PPO Batch Consumption Time: 0.28909
Total Iteration Time: 4.82243

Cumulative Model Updates: 236,270
Cumulative Timesteps: 1,971,138,362

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,135.39543
Policy Entropy: 2.26192
Value Function Loss: 0.01829

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.08499
Policy Update Magnitude: 0.30255
Value Function Update Magnitude: 0.29431

Collected Steps per Second: 21,251.56108
Overall Steps per Second: 10,312.90720

Timestep Collection Time: 2.35333
Timestep Consumption Time: 2.49612
PPO Batch Consumption Time: 0.29320
Total Iteration Time: 4.84946

Cumulative Model Updates: 236,276
Cumulative Timesteps: 1,971,188,374

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1971188374...
Checkpoint 1971188374 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,917.20813
Policy Entropy: 2.26470
Value Function Loss: 0.01822

Mean KL Divergence: 0.01084
SB3 Clip Fraction: 0.09637
Policy Update Magnitude: 0.29923
Value Function Update Magnitude: 0.30502

Collected Steps per Second: 21,355.26300
Overall Steps per Second: 10,519.65789

Timestep Collection Time: 2.34237
Timestep Consumption Time: 2.41272
PPO Batch Consumption Time: 0.27894
Total Iteration Time: 4.75510

Cumulative Model Updates: 236,282
Cumulative Timesteps: 1,971,238,396

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54,538.38064
Policy Entropy: 2.26568
Value Function Loss: 0.01788

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.08703
Policy Update Magnitude: 0.29603
Value Function Update Magnitude: 0.30651

Collected Steps per Second: 21,663.07817
Overall Steps per Second: 10,518.93519

Timestep Collection Time: 2.30937
Timestep Consumption Time: 2.44663
PPO Batch Consumption Time: 0.28533
Total Iteration Time: 4.75599

Cumulative Model Updates: 236,288
Cumulative Timesteps: 1,971,288,424

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1971288424...
Checkpoint 1971288424 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,856.21735
Policy Entropy: 2.26296
Value Function Loss: 0.01636

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.07237
Policy Update Magnitude: 0.29371
Value Function Update Magnitude: 0.31203

Collected Steps per Second: 21,256.78647
Overall Steps per Second: 10,308.01149

Timestep Collection Time: 2.35351
Timestep Consumption Time: 2.49981
PPO Batch Consumption Time: 0.29262
Total Iteration Time: 4.85331

Cumulative Model Updates: 236,294
Cumulative Timesteps: 1,971,338,452

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49,931.44741
Policy Entropy: 2.26464
Value Function Loss: 0.01851

Mean KL Divergence: 0.00770
SB3 Clip Fraction: 0.07369
Policy Update Magnitude: 0.30293
Value Function Update Magnitude: 0.31019

Collected Steps per Second: 21,785.61655
Overall Steps per Second: 10,389.19456

Timestep Collection Time: 2.29601
Timestep Consumption Time: 2.51861
PPO Batch Consumption Time: 0.29388
Total Iteration Time: 4.81462

Cumulative Model Updates: 236,300
Cumulative Timesteps: 1,971,388,472

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1971388472...
Checkpoint 1971388472 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 52,897.19633
Policy Entropy: 2.24490
Value Function Loss: 0.02056

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.07654
Policy Update Magnitude: 0.31099
Value Function Update Magnitude: 0.33225

Collected Steps per Second: 21,942.40177
Overall Steps per Second: 10,515.33553

Timestep Collection Time: 2.27960
Timestep Consumption Time: 2.47726
PPO Batch Consumption Time: 0.27966
Total Iteration Time: 4.75686

Cumulative Model Updates: 236,306
Cumulative Timesteps: 1,971,438,492

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51,605.94658
Policy Entropy: 2.24334
Value Function Loss: 0.01979

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.08686
Policy Update Magnitude: 0.30563
Value Function Update Magnitude: 0.34368

Collected Steps per Second: 21,925.17021
Overall Steps per Second: 10,421.84925

Timestep Collection Time: 2.28140
Timestep Consumption Time: 2.51814
PPO Batch Consumption Time: 0.29010
Total Iteration Time: 4.79953

Cumulative Model Updates: 236,312
Cumulative Timesteps: 1,971,488,512

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1971488512...
Checkpoint 1971488512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,953.75933
Policy Entropy: 2.25802
Value Function Loss: 0.01747

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.07845
Policy Update Magnitude: 0.29761
Value Function Update Magnitude: 0.31386

Collected Steps per Second: 22,038.30865
Overall Steps per Second: 10,636.68627

Timestep Collection Time: 2.26905
Timestep Consumption Time: 2.43223
PPO Batch Consumption Time: 0.27943
Total Iteration Time: 4.70128

Cumulative Model Updates: 236,318
Cumulative Timesteps: 1,971,538,518

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50,385.54503
Policy Entropy: 2.25796
Value Function Loss: 0.01770

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.07003
Policy Update Magnitude: 0.29708
Value Function Update Magnitude: 0.27995

Collected Steps per Second: 22,182.16727
Overall Steps per Second: 10,524.16026

Timestep Collection Time: 2.25596
Timestep Consumption Time: 2.49901
PPO Batch Consumption Time: 0.28989
Total Iteration Time: 4.75496

Cumulative Model Updates: 236,324
Cumulative Timesteps: 1,971,588,560

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1971588560...
Checkpoint 1971588560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 66,396.51059
Policy Entropy: 2.27447
Value Function Loss: 0.01862

Mean KL Divergence: 0.00749
SB3 Clip Fraction: 0.07093
Policy Update Magnitude: 0.30126
Value Function Update Magnitude: 0.28856

Collected Steps per Second: 22,076.25978
Overall Steps per Second: 10,631.12425

Timestep Collection Time: 2.26506
Timestep Consumption Time: 2.43849
PPO Batch Consumption Time: 0.27944
Total Iteration Time: 4.70355

Cumulative Model Updates: 236,330
Cumulative Timesteps: 1,971,638,564

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 74,755.18346
Policy Entropy: 2.27505
Value Function Loss: 0.01753

Mean KL Divergence: 0.00684
SB3 Clip Fraction: 0.06661
Policy Update Magnitude: 0.29676
Value Function Update Magnitude: 0.31050

Collected Steps per Second: 22,191.50644
Overall Steps per Second: 10,485.45607

Timestep Collection Time: 2.25356
Timestep Consumption Time: 2.51590
PPO Batch Consumption Time: 0.29160
Total Iteration Time: 4.76946

Cumulative Model Updates: 236,336
Cumulative Timesteps: 1,971,688,574

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1971688574...
Checkpoint 1971688574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,097.90689
Policy Entropy: 2.28302
Value Function Loss: 0.02005

Mean KL Divergence: 0.00683
SB3 Clip Fraction: 0.06525
Policy Update Magnitude: 0.30189
Value Function Update Magnitude: 0.31663

Collected Steps per Second: 21,922.08285
Overall Steps per Second: 10,603.12520

Timestep Collection Time: 2.28144
Timestep Consumption Time: 2.43547
PPO Batch Consumption Time: 0.27863
Total Iteration Time: 4.71691

Cumulative Model Updates: 236,342
Cumulative Timesteps: 1,971,738,588

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,924.96925
Policy Entropy: 2.28409
Value Function Loss: 0.01986

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.07823
Policy Update Magnitude: 0.30661
Value Function Update Magnitude: 0.33753

Collected Steps per Second: 21,552.68058
Overall Steps per Second: 10,540.12105

Timestep Collection Time: 2.32092
Timestep Consumption Time: 2.42495
PPO Batch Consumption Time: 0.27784
Total Iteration Time: 4.74587

Cumulative Model Updates: 236,348
Cumulative Timesteps: 1,971,788,610

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1971788610...
Checkpoint 1971788610 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,029.35157
Policy Entropy: 2.27641
Value Function Loss: 0.02139

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.07769
Policy Update Magnitude: 0.30544
Value Function Update Magnitude: 0.32304

Collected Steps per Second: 21,234.69226
Overall Steps per Second: 10,281.41725

Timestep Collection Time: 2.35511
Timestep Consumption Time: 2.50901
PPO Batch Consumption Time: 0.29370
Total Iteration Time: 4.86412

Cumulative Model Updates: 236,354
Cumulative Timesteps: 1,971,838,620

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,010.73523
Policy Entropy: 2.28015
Value Function Loss: 0.02020

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.08245
Policy Update Magnitude: 0.30090
Value Function Update Magnitude: 0.31483

Collected Steps per Second: 21,110.39691
Overall Steps per Second: 10,292.08076

Timestep Collection Time: 2.36879
Timestep Consumption Time: 2.48990
PPO Batch Consumption Time: 0.28824
Total Iteration Time: 4.85869

Cumulative Model Updates: 236,360
Cumulative Timesteps: 1,971,888,626

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1971888626...
Checkpoint 1971888626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40,648.75950
Policy Entropy: 2.29278
Value Function Loss: 0.01833

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.08170
Policy Update Magnitude: 0.29452
Value Function Update Magnitude: 0.31833

Collected Steps per Second: 21,391.00620
Overall Steps per Second: 10,355.13447

Timestep Collection Time: 2.33921
Timestep Consumption Time: 2.49298
PPO Batch Consumption Time: 0.29286
Total Iteration Time: 4.83219

Cumulative Model Updates: 236,366
Cumulative Timesteps: 1,971,938,664

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45,692.16465
Policy Entropy: 2.26928
Value Function Loss: 0.01689

Mean KL Divergence: 0.00712
SB3 Clip Fraction: 0.06719
Policy Update Magnitude: 0.29536
Value Function Update Magnitude: 0.31651

Collected Steps per Second: 21,739.06428
Overall Steps per Second: 10,400.25292

Timestep Collection Time: 2.30028
Timestep Consumption Time: 2.50787
PPO Batch Consumption Time: 0.29342
Total Iteration Time: 4.80815

Cumulative Model Updates: 236,372
Cumulative Timesteps: 1,971,988,670

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1971988670...
Checkpoint 1971988670 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47,767.79720
Policy Entropy: 2.26094
Value Function Loss: 0.01681

Mean KL Divergence: 0.00710
SB3 Clip Fraction: 0.06383
Policy Update Magnitude: 0.29665
Value Function Update Magnitude: 0.31737

Collected Steps per Second: 21,314.60069
Overall Steps per Second: 10,548.56771

Timestep Collection Time: 2.34628
Timestep Consumption Time: 2.39465
PPO Batch Consumption Time: 0.27918
Total Iteration Time: 4.74093

Cumulative Model Updates: 236,378
Cumulative Timesteps: 1,972,038,680

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45,552.53339
Policy Entropy: 2.24896
Value Function Loss: 0.02142

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.08007
Policy Update Magnitude: 0.31239
Value Function Update Magnitude: 0.30977

Collected Steps per Second: 21,205.89817
Overall Steps per Second: 10,351.60181

Timestep Collection Time: 2.35868
Timestep Consumption Time: 2.47323
PPO Batch Consumption Time: 0.29725
Total Iteration Time: 4.83191

Cumulative Model Updates: 236,384
Cumulative Timesteps: 1,972,088,698

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1972088698...
Checkpoint 1972088698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 73,651.69570
Policy Entropy: 2.26620
Value Function Loss: 0.02365

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.07724
Policy Update Magnitude: 0.32061
Value Function Update Magnitude: 0.31950

Collected Steps per Second: 21,183.32698
Overall Steps per Second: 10,469.72462

Timestep Collection Time: 2.36176
Timestep Consumption Time: 2.41678
PPO Batch Consumption Time: 0.29132
Total Iteration Time: 4.77854

Cumulative Model Updates: 236,390
Cumulative Timesteps: 1,972,138,728

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75,643.97569
Policy Entropy: 2.26120
Value Function Loss: 0.02596

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.07910
Policy Update Magnitude: 0.32062
Value Function Update Magnitude: 0.30540

Collected Steps per Second: 21,565.28935
Overall Steps per Second: 10,663.80003

Timestep Collection Time: 2.32021
Timestep Consumption Time: 2.37193
PPO Batch Consumption Time: 0.27929
Total Iteration Time: 4.69214

Cumulative Model Updates: 236,396
Cumulative Timesteps: 1,972,188,764

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1972188764...
Checkpoint 1972188764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,666.87300
Policy Entropy: 2.27826
Value Function Loss: 0.02343

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.07744
Policy Update Magnitude: 0.31572
Value Function Update Magnitude: 0.29447

Collected Steps per Second: 21,381.21229
Overall Steps per Second: 10,398.82027

Timestep Collection Time: 2.33934
Timestep Consumption Time: 2.47063
PPO Batch Consumption Time: 0.29262
Total Iteration Time: 4.80997

Cumulative Model Updates: 236,402
Cumulative Timesteps: 1,972,238,782

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,527.41378
Policy Entropy: 2.29280
Value Function Loss: 0.02126

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.08211
Policy Update Magnitude: 0.31570
Value Function Update Magnitude: 0.31622

Collected Steps per Second: 21,977.10113
Overall Steps per Second: 10,684.47059

Timestep Collection Time: 2.27692
Timestep Consumption Time: 2.40652
PPO Batch Consumption Time: 0.28082
Total Iteration Time: 4.68343

Cumulative Model Updates: 236,408
Cumulative Timesteps: 1,972,288,822

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1972288822...
Checkpoint 1972288822 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,023.70516
Policy Entropy: 2.27214
Value Function Loss: 0.01846

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.07039
Policy Update Magnitude: 0.30213
Value Function Update Magnitude: 0.31082

Collected Steps per Second: 21,712.65426
Overall Steps per Second: 10,662.26332

Timestep Collection Time: 2.30511
Timestep Consumption Time: 2.38902
PPO Batch Consumption Time: 0.27846
Total Iteration Time: 4.69413

Cumulative Model Updates: 236,414
Cumulative Timesteps: 1,972,338,872

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,022.85414
Policy Entropy: 2.26301
Value Function Loss: 0.01722

Mean KL Divergence: 0.00711
SB3 Clip Fraction: 0.06557
Policy Update Magnitude: 0.29320
Value Function Update Magnitude: 0.25750

Collected Steps per Second: 21,555.75336
Overall Steps per Second: 10,486.09709

Timestep Collection Time: 2.32087
Timestep Consumption Time: 2.45002
PPO Batch Consumption Time: 0.27970
Total Iteration Time: 4.77089

Cumulative Model Updates: 236,420
Cumulative Timesteps: 1,972,388,900

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1972388900...
Checkpoint 1972388900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,816.65199
Policy Entropy: 2.24605
Value Function Loss: 0.01775

Mean KL Divergence: 0.00701
SB3 Clip Fraction: 0.06813
Policy Update Magnitude: 0.29512
Value Function Update Magnitude: 0.26235

Collected Steps per Second: 21,427.56319
Overall Steps per Second: 10,350.50549

Timestep Collection Time: 2.33363
Timestep Consumption Time: 2.49744
PPO Batch Consumption Time: 0.29341
Total Iteration Time: 4.83107

Cumulative Model Updates: 236,426
Cumulative Timesteps: 1,972,438,904

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,714.78823
Policy Entropy: 2.26769
Value Function Loss: 0.01840

Mean KL Divergence: 0.00670
SB3 Clip Fraction: 0.06510
Policy Update Magnitude: 0.29485
Value Function Update Magnitude: 0.29283

Collected Steps per Second: 21,490.85711
Overall Steps per Second: 10,345.22290

Timestep Collection Time: 2.32750
Timestep Consumption Time: 2.50758
PPO Batch Consumption Time: 0.29103
Total Iteration Time: 4.83508

Cumulative Model Updates: 236,432
Cumulative Timesteps: 1,972,488,924

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1972488924...
Checkpoint 1972488924 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,856.27195
Policy Entropy: 2.26584
Value Function Loss: 0.02052

Mean KL Divergence: 0.00644
SB3 Clip Fraction: 0.06283
Policy Update Magnitude: 0.29796
Value Function Update Magnitude: 0.32995

Collected Steps per Second: 21,331.36512
Overall Steps per Second: 10,333.75069

Timestep Collection Time: 2.34500
Timestep Consumption Time: 2.49565
PPO Batch Consumption Time: 0.29338
Total Iteration Time: 4.84064

Cumulative Model Updates: 236,438
Cumulative Timesteps: 1,972,538,946

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,180.16563
Policy Entropy: 2.26561
Value Function Loss: 0.02131

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.07519
Policy Update Magnitude: 0.30380
Value Function Update Magnitude: 0.36418

Collected Steps per Second: 21,788.27125
Overall Steps per Second: 10,416.50163

Timestep Collection Time: 2.29637
Timestep Consumption Time: 2.50697
PPO Batch Consumption Time: 0.29333
Total Iteration Time: 4.80334

Cumulative Model Updates: 236,444
Cumulative Timesteps: 1,972,588,980

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1972588980...
Checkpoint 1972588980 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,635.96214
Policy Entropy: 2.24719
Value Function Loss: 0.02018

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.07795
Policy Update Magnitude: 0.30302
Value Function Update Magnitude: 0.32712

Collected Steps per Second: 21,856.82552
Overall Steps per Second: 10,494.94758

Timestep Collection Time: 2.28935
Timestep Consumption Time: 2.47846
PPO Batch Consumption Time: 0.27933
Total Iteration Time: 4.76782

Cumulative Model Updates: 236,450
Cumulative Timesteps: 1,972,639,018

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45,023.92952
Policy Entropy: 2.25836
Value Function Loss: 0.01952

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.07740
Policy Update Magnitude: 0.30190
Value Function Update Magnitude: 0.27448

Collected Steps per Second: 21,940.95286
Overall Steps per Second: 10,515.82365

Timestep Collection Time: 2.27884
Timestep Consumption Time: 2.47590
PPO Batch Consumption Time: 0.28612
Total Iteration Time: 4.75474

Cumulative Model Updates: 236,456
Cumulative Timesteps: 1,972,689,018

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1972689018...
Checkpoint 1972689018 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55,235.33970
Policy Entropy: 2.25622
Value Function Loss: 0.01812

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.08304
Policy Update Magnitude: 0.30076
Value Function Update Magnitude: 0.30453

Collected Steps per Second: 21,364.77419
Overall Steps per Second: 10,629.76387

Timestep Collection Time: 2.34039
Timestep Consumption Time: 2.36357
PPO Batch Consumption Time: 0.28012
Total Iteration Time: 4.70396

Cumulative Model Updates: 236,462
Cumulative Timesteps: 1,972,739,020

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,350.55178
Policy Entropy: 2.24627
Value Function Loss: 0.01986

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.07670
Policy Update Magnitude: 0.30496
Value Function Update Magnitude: 0.32730

Collected Steps per Second: 21,444.91435
Overall Steps per Second: 10,469.74294

Timestep Collection Time: 2.33211
Timestep Consumption Time: 2.44470
PPO Batch Consumption Time: 0.29399
Total Iteration Time: 4.77681

Cumulative Model Updates: 236,468
Cumulative Timesteps: 1,972,789,032

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1972789032...
Checkpoint 1972789032 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,126.74689
Policy Entropy: 2.22817
Value Function Loss: 0.01991

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.07690
Policy Update Magnitude: 0.31345
Value Function Update Magnitude: 0.33774

Collected Steps per Second: 21,196.31065
Overall Steps per Second: 10,600.12279

Timestep Collection Time: 2.35928
Timestep Consumption Time: 2.35840
PPO Batch Consumption Time: 0.27933
Total Iteration Time: 4.71768

Cumulative Model Updates: 236,474
Cumulative Timesteps: 1,972,839,040

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,747.32999
Policy Entropy: 2.22207
Value Function Loss: 0.02169

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.07027
Policy Update Magnitude: 0.31905
Value Function Update Magnitude: 0.34088

Collected Steps per Second: 21,316.84962
Overall Steps per Second: 10,511.78855

Timestep Collection Time: 2.34575
Timestep Consumption Time: 2.41119
PPO Batch Consumption Time: 0.27748
Total Iteration Time: 4.75695

Cumulative Model Updates: 236,480
Cumulative Timesteps: 1,972,889,044

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1972889044...
Checkpoint 1972889044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47,269.76232
Policy Entropy: 2.24133
Value Function Loss: 0.02047

Mean KL Divergence: 0.00763
SB3 Clip Fraction: 0.07046
Policy Update Magnitude: 0.31496
Value Function Update Magnitude: 0.33687

Collected Steps per Second: 21,882.17887
Overall Steps per Second: 10,626.96434

Timestep Collection Time: 2.28579
Timestep Consumption Time: 2.42092
PPO Batch Consumption Time: 0.28256
Total Iteration Time: 4.70671

Cumulative Model Updates: 236,486
Cumulative Timesteps: 1,972,939,062

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45,848.72934
Policy Entropy: 2.24569
Value Function Loss: 0.02090

Mean KL Divergence: 0.00723
SB3 Clip Fraction: 0.06739
Policy Update Magnitude: 0.31442
Value Function Update Magnitude: 0.35376

Collected Steps per Second: 21,654.98069
Overall Steps per Second: 10,414.90386

Timestep Collection Time: 2.30968
Timestep Consumption Time: 2.49267
PPO Batch Consumption Time: 0.29369
Total Iteration Time: 4.80235

Cumulative Model Updates: 236,492
Cumulative Timesteps: 1,972,989,078

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1972989078...
Checkpoint 1972989078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 50,565.93388
Policy Entropy: 2.24434
Value Function Loss: 0.01889

Mean KL Divergence: 0.00695
SB3 Clip Fraction: 0.06675
Policy Update Magnitude: 0.30847
Value Function Update Magnitude: 0.34638

Collected Steps per Second: 20,997.25503
Overall Steps per Second: 10,201.56586

Timestep Collection Time: 2.38250
Timestep Consumption Time: 2.52126
PPO Batch Consumption Time: 0.29270
Total Iteration Time: 4.90376

Cumulative Model Updates: 236,498
Cumulative Timesteps: 1,973,039,104

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,136.30388
Policy Entropy: 2.24370
Value Function Loss: 0.01835

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.07497
Policy Update Magnitude: 0.30247
Value Function Update Magnitude: 0.31195

Collected Steps per Second: 21,713.82001
Overall Steps per Second: 10,494.65478

Timestep Collection Time: 2.30314
Timestep Consumption Time: 2.46214
PPO Batch Consumption Time: 0.28428
Total Iteration Time: 4.76528

Cumulative Model Updates: 236,504
Cumulative Timesteps: 1,973,089,114

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1973089114...
Checkpoint 1973089114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,410.16407
Policy Entropy: 2.23323
Value Function Loss: 0.01988

Mean KL Divergence: 0.00756
SB3 Clip Fraction: 0.07064
Policy Update Magnitude: 0.30450
Value Function Update Magnitude: 0.28577

Collected Steps per Second: 21,093.65129
Overall Steps per Second: 10,247.29502

Timestep Collection Time: 2.37123
Timestep Consumption Time: 2.50986
PPO Batch Consumption Time: 0.29338
Total Iteration Time: 4.88109

Cumulative Model Updates: 236,510
Cumulative Timesteps: 1,973,139,132

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53,916.89196
Policy Entropy: 2.23880
Value Function Loss: 0.02180

Mean KL Divergence: 0.00750
SB3 Clip Fraction: 0.06938
Policy Update Magnitude: 0.31106
Value Function Update Magnitude: 0.32391

Collected Steps per Second: 21,641.21551
Overall Steps per Second: 10,378.92799

Timestep Collection Time: 2.31115
Timestep Consumption Time: 2.50785
PPO Batch Consumption Time: 0.29179
Total Iteration Time: 4.81899

Cumulative Model Updates: 236,516
Cumulative Timesteps: 1,973,189,148

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1973189148...
Checkpoint 1973189148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46,377.28703
Policy Entropy: 2.24000
Value Function Loss: 0.02122

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.07218
Policy Update Magnitude: 0.31420
Value Function Update Magnitude: 0.36367

Collected Steps per Second: 21,849.68125
Overall Steps per Second: 10,329.73061

Timestep Collection Time: 2.29074
Timestep Consumption Time: 2.55469
PPO Batch Consumption Time: 0.29259
Total Iteration Time: 4.84543

Cumulative Model Updates: 236,522
Cumulative Timesteps: 1,973,239,200

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42,759.88667
Policy Entropy: 2.23479
Value Function Loss: 0.01993

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.06929
Policy Update Magnitude: 0.31161
Value Function Update Magnitude: 0.36396

Collected Steps per Second: 22,263.61332
Overall Steps per Second: 10,697.90211

Timestep Collection Time: 2.24707
Timestep Consumption Time: 2.42936
PPO Batch Consumption Time: 0.27866
Total Iteration Time: 4.67643

Cumulative Model Updates: 236,528
Cumulative Timesteps: 1,973,289,228

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1973289228...
Checkpoint 1973289228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,393.79938
Policy Entropy: 2.23347
Value Function Loss: 0.01750

Mean KL Divergence: 0.00737
SB3 Clip Fraction: 0.06739
Policy Update Magnitude: 0.30896
Value Function Update Magnitude: 0.33312

Collected Steps per Second: 21,724.42343
Overall Steps per Second: 10,393.80861

Timestep Collection Time: 2.30340
Timestep Consumption Time: 2.51101
PPO Batch Consumption Time: 0.29238
Total Iteration Time: 4.81440

Cumulative Model Updates: 236,534
Cumulative Timesteps: 1,973,339,268

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 73,079.13302
Policy Entropy: 2.22860
Value Function Loss: 0.01663

Mean KL Divergence: 0.00697
SB3 Clip Fraction: 0.06702
Policy Update Magnitude: 0.29847
Value Function Update Magnitude: 0.30696

Collected Steps per Second: 21,563.18942
Overall Steps per Second: 10,689.81190

Timestep Collection Time: 2.31997
Timestep Consumption Time: 2.35981
PPO Batch Consumption Time: 0.27949
Total Iteration Time: 4.67978

Cumulative Model Updates: 236,540
Cumulative Timesteps: 1,973,389,294

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1973389294...
Checkpoint 1973389294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47,250.41839
Policy Entropy: 2.21975
Value Function Loss: 0.01845

Mean KL Divergence: 0.00686
SB3 Clip Fraction: 0.06629
Policy Update Magnitude: 0.30180
Value Function Update Magnitude: 0.29895

Collected Steps per Second: 21,142.84096
Overall Steps per Second: 10,436.49599

Timestep Collection Time: 2.36619
Timestep Consumption Time: 2.42737
PPO Batch Consumption Time: 0.29173
Total Iteration Time: 4.79356

Cumulative Model Updates: 236,546
Cumulative Timesteps: 1,973,439,322

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 114,946.34207
Policy Entropy: 2.22557
Value Function Loss: 0.02232

Mean KL Divergence: 0.00691
SB3 Clip Fraction: 0.06638
Policy Update Magnitude: 0.31173
Value Function Update Magnitude: 0.33066

Collected Steps per Second: 21,585.04376
Overall Steps per Second: 10,702.00588

Timestep Collection Time: 2.31716
Timestep Consumption Time: 2.35636
PPO Batch Consumption Time: 0.27924
Total Iteration Time: 4.67352

Cumulative Model Updates: 236,552
Cumulative Timesteps: 1,973,489,338

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1973489338...
Checkpoint 1973489338 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 114,293.10675
Policy Entropy: 2.22558
Value Function Loss: 0.02143

Mean KL Divergence: 0.00719
SB3 Clip Fraction: 0.06698
Policy Update Magnitude: 0.31334
Value Function Update Magnitude: 0.35994

Collected Steps per Second: 21,314.95430
Overall Steps per Second: 10,354.10141

Timestep Collection Time: 2.34784
Timestep Consumption Time: 2.48542
PPO Batch Consumption Time: 0.29239
Total Iteration Time: 4.83325

Cumulative Model Updates: 236,558
Cumulative Timesteps: 1,973,539,382

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 102,051.22245
Policy Entropy: 2.24276
Value Function Loss: 0.01897

Mean KL Divergence: 0.00691
SB3 Clip Fraction: 0.06518
Policy Update Magnitude: 0.30297
Value Function Update Magnitude: 0.35664

Collected Steps per Second: 21,618.80356
Overall Steps per Second: 10,434.83639

Timestep Collection Time: 2.31326
Timestep Consumption Time: 2.47934
PPO Batch Consumption Time: 0.29359
Total Iteration Time: 4.79260

Cumulative Model Updates: 236,564
Cumulative Timesteps: 1,973,589,392

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1973589392...
Checkpoint 1973589392 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 106,231.52504
Policy Entropy: 2.22795
Value Function Loss: 0.01721

Mean KL Divergence: 0.00688
SB3 Clip Fraction: 0.06297
Policy Update Magnitude: 0.29938
Value Function Update Magnitude: 0.32448

Collected Steps per Second: 21,245.57729
Overall Steps per Second: 10,457.06436

Timestep Collection Time: 2.35447
Timestep Consumption Time: 2.42909
PPO Batch Consumption Time: 0.27876
Total Iteration Time: 4.78356

Cumulative Model Updates: 236,570
Cumulative Timesteps: 1,973,639,414

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54,710.84403
Policy Entropy: 2.23489
Value Function Loss: 0.02074

Mean KL Divergence: 0.00700
SB3 Clip Fraction: 0.06377
Policy Update Magnitude: 0.30816
Value Function Update Magnitude: 0.32795

Collected Steps per Second: 21,897.58876
Overall Steps per Second: 10,627.32042

Timestep Collection Time: 2.28409
Timestep Consumption Time: 2.42227
PPO Batch Consumption Time: 0.27665
Total Iteration Time: 4.70636

Cumulative Model Updates: 236,576
Cumulative Timesteps: 1,973,689,430

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1973689430...
Checkpoint 1973689430 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 57,618.01715
Policy Entropy: 2.23017
Value Function Loss: 0.02229

Mean KL Divergence: 0.00739
SB3 Clip Fraction: 0.07123
Policy Update Magnitude: 0.32171
Value Function Update Magnitude: 0.34912

Collected Steps per Second: 21,442.91502
Overall Steps per Second: 10,317.66877

Timestep Collection Time: 2.33280
Timestep Consumption Time: 2.51539
PPO Batch Consumption Time: 0.29105
Total Iteration Time: 4.84819

Cumulative Model Updates: 236,582
Cumulative Timesteps: 1,973,739,452

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66,504.51378
Policy Entropy: 2.25238
Value Function Loss: 0.02395

Mean KL Divergence: 0.00741
SB3 Clip Fraction: 0.07210
Policy Update Magnitude: 0.33466
Value Function Update Magnitude: 0.36807

Collected Steps per Second: 21,085.34253
Overall Steps per Second: 10,306.75250

Timestep Collection Time: 2.37236
Timestep Consumption Time: 2.48096
PPO Batch Consumption Time: 0.27806
Total Iteration Time: 4.85332

Cumulative Model Updates: 236,588
Cumulative Timesteps: 1,973,789,474

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1973789474...
Checkpoint 1973789474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,594.42819
Policy Entropy: 2.24415
Value Function Loss: 0.02231

Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.07487
Policy Update Magnitude: 0.33110
Value Function Update Magnitude: 0.38332

Collected Steps per Second: 21,885.31288
Overall Steps per Second: 10,585.93403

Timestep Collection Time: 2.28592
Timestep Consumption Time: 2.43998
PPO Batch Consumption Time: 0.27939
Total Iteration Time: 4.72589

Cumulative Model Updates: 236,594
Cumulative Timesteps: 1,973,839,502

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,919.61150
Policy Entropy: 2.24117
Value Function Loss: 0.02125

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.07615
Policy Update Magnitude: 0.32611
Value Function Update Magnitude: 0.38225

Collected Steps per Second: 22,190.23757
Overall Steps per Second: 10,481.06377

Timestep Collection Time: 2.25441
Timestep Consumption Time: 2.51857
PPO Batch Consumption Time: 0.29425
Total Iteration Time: 4.77299

Cumulative Model Updates: 236,600
Cumulative Timesteps: 1,973,889,528

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1973889528...
Checkpoint 1973889528 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,825.94035
Policy Entropy: 2.21763
Value Function Loss: 0.01936

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.07424
Policy Update Magnitude: 0.31894
Value Function Update Magnitude: 0.36342

Collected Steps per Second: 21,775.90522
Overall Steps per Second: 10,574.19901

Timestep Collection Time: 2.29694
Timestep Consumption Time: 2.43325
PPO Batch Consumption Time: 0.27903
Total Iteration Time: 4.73019

Cumulative Model Updates: 236,606
Cumulative Timesteps: 1,973,939,546

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,846.31527
Policy Entropy: 2.22197
Value Function Loss: 0.01699

Mean KL Divergence: 0.00727
SB3 Clip Fraction: 0.07084
Policy Update Magnitude: 0.31009
Value Function Update Magnitude: 0.33153

Collected Steps per Second: 22,058.67043
Overall Steps per Second: 10,506.94022

Timestep Collection Time: 2.26695
Timestep Consumption Time: 2.49238
PPO Batch Consumption Time: 0.29134
Total Iteration Time: 4.75933

Cumulative Model Updates: 236,612
Cumulative Timesteps: 1,973,989,552

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1973989552...
Checkpoint 1973989552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,964.98746
Policy Entropy: 2.21643
Value Function Loss: 0.01763

Mean KL Divergence: 0.00704
SB3 Clip Fraction: 0.06798
Policy Update Magnitude: 0.30382
Value Function Update Magnitude: 0.30678

Collected Steps per Second: 21,875.22768
Overall Steps per Second: 10,609.11893

Timestep Collection Time: 2.28670
Timestep Consumption Time: 2.42830
PPO Batch Consumption Time: 0.27894
Total Iteration Time: 4.71500

Cumulative Model Updates: 236,618
Cumulative Timesteps: 1,974,039,574

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,095.26035
Policy Entropy: 2.24101
Value Function Loss: 0.01803

Mean KL Divergence: 0.00698
SB3 Clip Fraction: 0.06543
Policy Update Magnitude: 0.29957
Value Function Update Magnitude: 0.29887

Collected Steps per Second: 22,025.63481
Overall Steps per Second: 10,513.78591

Timestep Collection Time: 2.27199
Timestep Consumption Time: 2.48767
PPO Batch Consumption Time: 0.29021
Total Iteration Time: 4.75966

Cumulative Model Updates: 236,624
Cumulative Timesteps: 1,974,089,616

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1974089616...
Checkpoint 1974089616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,029.14692
Policy Entropy: 2.22871
Value Function Loss: 0.01928

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.07733
Policy Update Magnitude: 0.30484
Value Function Update Magnitude: 0.31020

Collected Steps per Second: 21,275.64174
Overall Steps per Second: 10,327.85381

Timestep Collection Time: 2.35067
Timestep Consumption Time: 2.49177
PPO Batch Consumption Time: 0.29059
Total Iteration Time: 4.84244

Cumulative Model Updates: 236,630
Cumulative Timesteps: 1,974,139,628

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54,129.72225
Policy Entropy: 2.24497
Value Function Loss: 0.01868

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.07993
Policy Update Magnitude: 0.30912
Value Function Update Magnitude: 0.30381

Collected Steps per Second: 20,996.69043
Overall Steps per Second: 10,395.48636

Timestep Collection Time: 2.38209
Timestep Consumption Time: 2.42923
PPO Batch Consumption Time: 0.29268
Total Iteration Time: 4.81132

Cumulative Model Updates: 236,636
Cumulative Timesteps: 1,974,189,644

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1974189644...
Checkpoint 1974189644 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 56,456.60113
Policy Entropy: 2.24308
Value Function Loss: 0.01920

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.08521
Policy Update Magnitude: 0.31424
Value Function Update Magnitude: 0.31245

Collected Steps per Second: 20,946.24295
Overall Steps per Second: 10,555.47440

Timestep Collection Time: 2.38830
Timestep Consumption Time: 2.35104
PPO Batch Consumption Time: 0.27796
Total Iteration Time: 4.73934

Cumulative Model Updates: 236,642
Cumulative Timesteps: 1,974,239,670

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57,713.80397
Policy Entropy: 2.25815
Value Function Loss: 0.01914

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.08223
Policy Update Magnitude: 0.31117
Value Function Update Magnitude: 0.32150

Collected Steps per Second: 21,073.11150
Overall Steps per Second: 10,431.03645

Timestep Collection Time: 2.37450
Timestep Consumption Time: 2.42254
PPO Batch Consumption Time: 0.28947
Total Iteration Time: 4.79703

Cumulative Model Updates: 236,648
Cumulative Timesteps: 1,974,289,708

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1974289708...
Checkpoint 1974289708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 62,713.57241
Policy Entropy: 2.24280
Value Function Loss: 0.02041

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.07951
Policy Update Magnitude: 0.31129
Value Function Update Magnitude: 0.31707

Collected Steps per Second: 20,783.77099
Overall Steps per Second: 10,216.43464

Timestep Collection Time: 2.40640
Timestep Consumption Time: 2.48905
PPO Batch Consumption Time: 0.29391
Total Iteration Time: 4.89545

Cumulative Model Updates: 236,654
Cumulative Timesteps: 1,974,339,722

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45,808.87085
Policy Entropy: 2.24660
Value Function Loss: 0.02063

Mean KL Divergence: 0.00744
SB3 Clip Fraction: 0.07177
Policy Update Magnitude: 0.31594
Value Function Update Magnitude: 0.31654

Collected Steps per Second: 21,840.32330
Overall Steps per Second: 10,418.88849

Timestep Collection Time: 2.28934
Timestep Consumption Time: 2.50963
PPO Batch Consumption Time: 0.28731
Total Iteration Time: 4.79898

Cumulative Model Updates: 236,660
Cumulative Timesteps: 1,974,389,722

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1974389722...
Checkpoint 1974389722 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,323.08122
Policy Entropy: 2.23937
Value Function Loss: 0.02070

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.07581
Policy Update Magnitude: 0.31392
Value Function Update Magnitude: 0.32369

Collected Steps per Second: 22,001.13366
Overall Steps per Second: 10,675.89475

Timestep Collection Time: 2.27334
Timestep Consumption Time: 2.41161
PPO Batch Consumption Time: 0.27825
Total Iteration Time: 4.68495

Cumulative Model Updates: 236,666
Cumulative Timesteps: 1,974,439,738

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,009.50678
Policy Entropy: 2.25237
Value Function Loss: 0.02025

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.07338
Policy Update Magnitude: 0.30972
Value Function Update Magnitude: 0.34404

Collected Steps per Second: 22,366.64927
Overall Steps per Second: 10,547.04542

Timestep Collection Time: 2.23601
Timestep Consumption Time: 2.50579
PPO Batch Consumption Time: 0.29240
Total Iteration Time: 4.74180

Cumulative Model Updates: 236,672
Cumulative Timesteps: 1,974,489,750

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1974489750...
Checkpoint 1974489750 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47,766.25349
Policy Entropy: 2.24669
Value Function Loss: 0.02062

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.07544
Policy Update Magnitude: 0.32276
Value Function Update Magnitude: 0.36477

Collected Steps per Second: 22,040.99858
Overall Steps per Second: 10,492.75468

Timestep Collection Time: 2.26859
Timestep Consumption Time: 2.49679
PPO Batch Consumption Time: 0.29028
Total Iteration Time: 4.76538

Cumulative Model Updates: 236,678
Cumulative Timesteps: 1,974,539,752

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55,299.97250
Policy Entropy: 2.25232
Value Function Loss: 0.02002

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.07501
Policy Update Magnitude: 0.31840
Value Function Update Magnitude: 0.34651

Collected Steps per Second: 22,348.65193
Overall Steps per Second: 10,503.74095

Timestep Collection Time: 2.23736
Timestep Consumption Time: 2.52304
PPO Batch Consumption Time: 0.29331
Total Iteration Time: 4.76040

Cumulative Model Updates: 236,684
Cumulative Timesteps: 1,974,589,754

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1974589754...
Checkpoint 1974589754 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48,261.65695
Policy Entropy: 2.24953
Value Function Loss: 0.02028

Mean KL Divergence: 0.00756
SB3 Clip Fraction: 0.07077
Policy Update Magnitude: 0.31001
Value Function Update Magnitude: 0.33708

Collected Steps per Second: 21,829.29396
Overall Steps per Second: 10,566.25585

Timestep Collection Time: 2.29187
Timestep Consumption Time: 2.44301
PPO Batch Consumption Time: 0.27975
Total Iteration Time: 4.73488

Cumulative Model Updates: 236,690
Cumulative Timesteps: 1,974,639,784

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42,638.30096
Policy Entropy: 2.24032
Value Function Loss: 0.01835

Mean KL Divergence: 0.00718
SB3 Clip Fraction: 0.06814
Policy Update Magnitude: 0.30792
Value Function Update Magnitude: 0.32476

Collected Steps per Second: 22,094.64811
Overall Steps per Second: 10,499.05557

Timestep Collection Time: 2.26317
Timestep Consumption Time: 2.49954
PPO Batch Consumption Time: 0.29238
Total Iteration Time: 4.76271

Cumulative Model Updates: 236,696
Cumulative Timesteps: 1,974,689,788

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1974689788...
Checkpoint 1974689788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,670.01603
Policy Entropy: 2.24879
Value Function Loss: 0.01897

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.07659
Policy Update Magnitude: 0.30104
Value Function Update Magnitude: 0.30197

Collected Steps per Second: 21,277.82731
Overall Steps per Second: 10,360.01883

Timestep Collection Time: 2.35127
Timestep Consumption Time: 2.47787
PPO Batch Consumption Time: 0.29126
Total Iteration Time: 4.82914

Cumulative Model Updates: 236,702
Cumulative Timesteps: 1,974,739,818

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68,029.08920
Policy Entropy: 2.25521
Value Function Loss: 0.02255

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.07907
Policy Update Magnitude: 0.31235
Value Function Update Magnitude: 0.27265

Collected Steps per Second: 21,546.79151
Overall Steps per Second: 10,363.53103

Timestep Collection Time: 2.32137
Timestep Consumption Time: 2.50498
PPO Batch Consumption Time: 0.29261
Total Iteration Time: 4.82635

Cumulative Model Updates: 236,708
Cumulative Timesteps: 1,974,789,836

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1974789836...
Checkpoint 1974789836 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 58,178.08644
Policy Entropy: 2.26861
Value Function Loss: 0.02202

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.08050
Policy Update Magnitude: 0.31411
Value Function Update Magnitude: 0.28192

Collected Steps per Second: 21,459.81015
Overall Steps per Second: 10,511.03753

Timestep Collection Time: 2.33124
Timestep Consumption Time: 2.42833
PPO Batch Consumption Time: 0.27844
Total Iteration Time: 4.75957

Cumulative Model Updates: 236,714
Cumulative Timesteps: 1,974,839,864

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61,572.38459
Policy Entropy: 2.26802
Value Function Loss: 0.02069

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.07812
Policy Update Magnitude: 0.32128
Value Function Update Magnitude: 0.31614

Collected Steps per Second: 21,658.91492
Overall Steps per Second: 10,589.38352

Timestep Collection Time: 2.30935
Timestep Consumption Time: 2.41406
PPO Batch Consumption Time: 0.27717
Total Iteration Time: 4.72341

Cumulative Model Updates: 236,720
Cumulative Timesteps: 1,974,889,882

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1974889882...
Checkpoint 1974889882 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46,539.61508
Policy Entropy: 2.27997
Value Function Loss: 0.02122

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.07803
Policy Update Magnitude: 0.31431
Value Function Update Magnitude: 0.30688

Collected Steps per Second: 20,807.43237
Overall Steps per Second: 10,493.90105

Timestep Collection Time: 2.40395
Timestep Consumption Time: 2.36263
PPO Batch Consumption Time: 0.27830
Total Iteration Time: 4.76658

Cumulative Model Updates: 236,726
Cumulative Timesteps: 1,974,939,902

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62,192.29708
Policy Entropy: 2.27086
Value Function Loss: 0.02277

Mean KL Divergence: 0.01118
SB3 Clip Fraction: 0.09702
Policy Update Magnitude: 0.31622
Value Function Update Magnitude: 0.31689

Collected Steps per Second: 21,449.84822
Overall Steps per Second: 10,481.39819

Timestep Collection Time: 2.33279
Timestep Consumption Time: 2.44119
PPO Batch Consumption Time: 0.28770
Total Iteration Time: 4.77398

Cumulative Model Updates: 236,732
Cumulative Timesteps: 1,974,989,940

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1974989940...
Checkpoint 1974989940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,632.45097
Policy Entropy: 2.26981
Value Function Loss: 0.02402

Mean KL Divergence: 0.01098
SB3 Clip Fraction: 0.09802
Policy Update Magnitude: 0.32070
Value Function Update Magnitude: 0.35429

Collected Steps per Second: 20,939.94929
Overall Steps per Second: 10,369.45565

Timestep Collection Time: 2.38883
Timestep Consumption Time: 2.43514
PPO Batch Consumption Time: 0.29105
Total Iteration Time: 4.82398

Cumulative Model Updates: 236,738
Cumulative Timesteps: 1,975,039,962

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,632.45097
Policy Entropy: 2.24906
Value Function Loss: 0.01961

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.09443
Policy Update Magnitude: 0.31732
Value Function Update Magnitude: 0.36009

Collected Steps per Second: 21,696.77619
Overall Steps per Second: 10,742.83256

Timestep Collection Time: 2.30596
Timestep Consumption Time: 2.35128
PPO Batch Consumption Time: 0.27918
Total Iteration Time: 4.65724

Cumulative Model Updates: 236,744
Cumulative Timesteps: 1,975,089,994

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1975089994...
Checkpoint 1975089994 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,888.93236
Policy Entropy: 2.26050
Value Function Loss: 0.01923

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.08567
Policy Update Magnitude: 0.30845
Value Function Update Magnitude: 0.33131

Collected Steps per Second: 21,444.50432
Overall Steps per Second: 10,427.48149

Timestep Collection Time: 2.33188
Timestep Consumption Time: 2.46372
PPO Batch Consumption Time: 0.29078
Total Iteration Time: 4.79560

Cumulative Model Updates: 236,750
Cumulative Timesteps: 1,975,140,000

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,860.96678
Policy Entropy: 2.25661
Value Function Loss: 0.01982

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.07676
Policy Update Magnitude: 0.31458
Value Function Update Magnitude: 0.32069

Collected Steps per Second: 22,549.07951
Overall Steps per Second: 10,720.02024

Timestep Collection Time: 2.21765
Timestep Consumption Time: 2.44708
PPO Batch Consumption Time: 0.28781
Total Iteration Time: 4.66473

Cumulative Model Updates: 236,756
Cumulative Timesteps: 1,975,190,006

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1975190006...
Checkpoint 1975190006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47,627.05792
Policy Entropy: 2.26384
Value Function Loss: 0.02483

Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.07837
Policy Update Magnitude: 0.33159
Value Function Update Magnitude: 0.36825

Collected Steps per Second: 21,686.41924
Overall Steps per Second: 10,582.45650

Timestep Collection Time: 2.30559
Timestep Consumption Time: 2.41921
PPO Batch Consumption Time: 0.27940
Total Iteration Time: 4.72480

Cumulative Model Updates: 236,762
Cumulative Timesteps: 1,975,240,006

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,580.38264
Policy Entropy: 2.23772
Value Function Loss: 0.02361

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.09418
Policy Update Magnitude: 0.33357
Value Function Update Magnitude: 0.40197

Collected Steps per Second: 21,574.84178
Overall Steps per Second: 10,494.77141

Timestep Collection Time: 2.31779
Timestep Consumption Time: 2.44706
PPO Batch Consumption Time: 0.27864
Total Iteration Time: 4.76485

Cumulative Model Updates: 236,768
Cumulative Timesteps: 1,975,290,012

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1975290012...
Checkpoint 1975290012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,125.31148
Policy Entropy: 2.23891
Value Function Loss: 0.02285

Mean KL Divergence: 0.01200
SB3 Clip Fraction: 0.10181
Policy Update Magnitude: 0.32299
Value Function Update Magnitude: 0.37780

Collected Steps per Second: 21,118.43962
Overall Steps per Second: 10,243.60920

Timestep Collection Time: 2.36845
Timestep Consumption Time: 2.51440
PPO Batch Consumption Time: 0.29396
Total Iteration Time: 4.88285

Cumulative Model Updates: 236,774
Cumulative Timesteps: 1,975,340,030

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,331.28884
Policy Entropy: 2.23395
Value Function Loss: 0.01889

Mean KL Divergence: 0.01578
SB3 Clip Fraction: 0.13031
Policy Update Magnitude: 0.30663
Value Function Update Magnitude: 0.30946

Collected Steps per Second: 21,722.35829
Overall Steps per Second: 10,382.54809

Timestep Collection Time: 2.30325
Timestep Consumption Time: 2.51561
PPO Batch Consumption Time: 0.29135
Total Iteration Time: 4.81886

Cumulative Model Updates: 236,780
Cumulative Timesteps: 1,975,390,062

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1975390062...
Checkpoint 1975390062 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,064.09942
Policy Entropy: 2.22991
Value Function Loss: 0.01899

Mean KL Divergence: 0.01125
SB3 Clip Fraction: 0.10095
Policy Update Magnitude: 0.30594
Value Function Update Magnitude: 0.23909

Collected Steps per Second: 21,397.56962
Overall Steps per Second: 10,321.83006

Timestep Collection Time: 2.33784
Timestep Consumption Time: 2.50859
PPO Batch Consumption Time: 0.29352
Total Iteration Time: 4.84643

Cumulative Model Updates: 236,786
Cumulative Timesteps: 1,975,440,086

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46,967.75506
Policy Entropy: 2.21869
Value Function Loss: 0.01793

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.09409
Policy Update Magnitude: 0.31098
Value Function Update Magnitude: 0.21772

Collected Steps per Second: 22,123.93589
Overall Steps per Second: 10,440.98167

Timestep Collection Time: 2.26027
Timestep Consumption Time: 2.52913
PPO Batch Consumption Time: 0.29245
Total Iteration Time: 4.78940

Cumulative Model Updates: 236,792
Cumulative Timesteps: 1,975,490,092

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1975490092...
Checkpoint 1975490092 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,782.81431
Policy Entropy: 2.22028
Value Function Loss: 0.01859

Mean KL Divergence: 0.01086
SB3 Clip Fraction: 0.09458
Policy Update Magnitude: 0.30847
Value Function Update Magnitude: 0.20670

Collected Steps per Second: 21,809.90557
Overall Steps per Second: 10,529.73156

Timestep Collection Time: 2.29318
Timestep Consumption Time: 2.45661
PPO Batch Consumption Time: 0.27963
Total Iteration Time: 4.74979

Cumulative Model Updates: 236,798
Cumulative Timesteps: 1,975,540,106

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65,455.54397
Policy Entropy: 2.23197
Value Function Loss: 0.01884

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.08297
Policy Update Magnitude: 0.30268
Value Function Update Magnitude: 0.25845

Collected Steps per Second: 22,027.57954
Overall Steps per Second: 10,455.84239

Timestep Collection Time: 2.27206
Timestep Consumption Time: 2.51455
PPO Batch Consumption Time: 0.29185
Total Iteration Time: 4.78661

Cumulative Model Updates: 236,804
Cumulative Timesteps: 1,975,590,154

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 1975590154...
Checkpoint 1975590154 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,601.87648
Policy Entropy: 2.25964
Value Function Loss: 0.02000

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.08020
Policy Update Magnitude: 0.31114
Value Function Update Magnitude: 0.30456

Collected Steps per Second: 21,965.02017
Overall Steps per Second: 10,607.72750

Timestep Collection Time: 2.27762
Timestep Consumption Time: 2.43856
PPO Batch Consumption Time: 0.27954
Total Iteration Time: 4.71618

Cumulative Model Updates: 236,810
Cumulative Timesteps: 1,975,640,182

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,146.72790
Policy Entropy: 2.25066
Value Function Loss: 0.02163

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.08499
Policy Update Magnitude: 0.31882
Value Function Update Magnitude: 0.34924

Collected Steps per Second: 21,637.24035
Overall Steps per Second: 10,577.57552

Timestep Collection Time: 2.31102
Timestep Consumption Time: 2.41634
PPO Batch Consumption Time: 0.27740
Total Iteration Time: 4.72736

Cumulative Model Updates: 236,816
Cumulative Timesteps: 1,975,690,186

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1975690186...
Checkpoint 1975690186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,788.92414
Policy Entropy: 2.24699
Value Function Loss: 0.01995

Mean KL Divergence: 0.01115
SB3 Clip Fraction: 0.09756
Policy Update Magnitude: 0.32057
Value Function Update Magnitude: 0.37456

Collected Steps per Second: 21,356.88454
Overall Steps per Second: 10,511.42725

Timestep Collection Time: 2.34229
Timestep Consumption Time: 2.41672
PPO Batch Consumption Time: 0.27880
Total Iteration Time: 4.75901

Cumulative Model Updates: 236,822
Cumulative Timesteps: 1,975,740,210

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,600.25888
Policy Entropy: 2.24667
Value Function Loss: 0.01842

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.09206
Policy Update Magnitude: 0.31256
Value Function Update Magnitude: 0.36759

Collected Steps per Second: 21,072.23186
Overall Steps per Second: 10,573.44397

Timestep Collection Time: 2.37279
Timestep Consumption Time: 2.35604
PPO Batch Consumption Time: 0.27772
Total Iteration Time: 4.72883

Cumulative Model Updates: 236,828
Cumulative Timesteps: 1,975,790,210

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1975790210...
Checkpoint 1975790210 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 52,931.77047
Policy Entropy: 2.25371
Value Function Loss: 0.01792

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.08224
Policy Update Magnitude: 0.31177
Value Function Update Magnitude: 0.33488

Collected Steps per Second: 21,002.03733
Overall Steps per Second: 10,545.45227

Timestep Collection Time: 2.38101
Timestep Consumption Time: 2.36094
PPO Batch Consumption Time: 0.27903
Total Iteration Time: 4.74195

Cumulative Model Updates: 236,834
Cumulative Timesteps: 1,975,840,216

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54,578.98773
Policy Entropy: 2.25823
Value Function Loss: 0.01915

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.07916
Policy Update Magnitude: 0.31198
Value Function Update Magnitude: 0.31138

Collected Steps per Second: 21,371.76919
Overall Steps per Second: 10,470.00795

Timestep Collection Time: 2.34056
Timestep Consumption Time: 2.43708
PPO Batch Consumption Time: 0.29218
Total Iteration Time: 4.77765

Cumulative Model Updates: 236,840
Cumulative Timesteps: 1,975,890,238

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1975890238...
Checkpoint 1975890238 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,266.77244
Policy Entropy: 2.26349
Value Function Loss: 0.02080

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.07353
Policy Update Magnitude: 0.31438
Value Function Update Magnitude: 0.32437

Collected Steps per Second: 20,979.99486
Overall Steps per Second: 10,210.67669

Timestep Collection Time: 2.38322
Timestep Consumption Time: 2.51361
PPO Batch Consumption Time: 0.29442
Total Iteration Time: 4.89684

Cumulative Model Updates: 236,846
Cumulative Timesteps: 1,975,940,238

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52,508.10570
Policy Entropy: 2.26892
Value Function Loss: 0.02105

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.07378
Policy Update Magnitude: 0.31299
Value Function Update Magnitude: 0.33216

Collected Steps per Second: 21,808.49874
Overall Steps per Second: 10,430.96776

Timestep Collection Time: 2.29296
Timestep Consumption Time: 2.50104
PPO Batch Consumption Time: 0.28680
Total Iteration Time: 4.79399

Cumulative Model Updates: 236,852
Cumulative Timesteps: 1,975,990,244

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1975990244...
Checkpoint 1975990244 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 78,085.53864
Policy Entropy: 2.26896
Value Function Loss: 0.02136

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.07040
Policy Update Magnitude: 0.31849
Value Function Update Magnitude: 0.33569

Collected Steps per Second: 21,810.09964
Overall Steps per Second: 10,609.71955

Timestep Collection Time: 2.29380
Timestep Consumption Time: 2.42150
PPO Batch Consumption Time: 0.27963
Total Iteration Time: 4.71530

Cumulative Model Updates: 236,858
Cumulative Timesteps: 1,976,040,272

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60,220.12079
Policy Entropy: 2.25926
Value Function Loss: 0.02273

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.07546
Policy Update Magnitude: 0.32823
Value Function Update Magnitude: 0.36966

Collected Steps per Second: 22,099.14791
Overall Steps per Second: 10,487.94425

Timestep Collection Time: 2.26452
Timestep Consumption Time: 2.50705
PPO Batch Consumption Time: 0.29089
Total Iteration Time: 4.77157

Cumulative Model Updates: 236,864
Cumulative Timesteps: 1,976,090,316

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1976090316...
Checkpoint 1976090316 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55,032.78808
Policy Entropy: 2.23254
Value Function Loss: 0.02100

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.08565
Policy Update Magnitude: 0.32582
Value Function Update Magnitude: 0.34774

Collected Steps per Second: 22,045.63757
Overall Steps per Second: 10,638.89264

Timestep Collection Time: 2.26929
Timestep Consumption Time: 2.43308
PPO Batch Consumption Time: 0.27976
Total Iteration Time: 4.70237

Cumulative Model Updates: 236,870
Cumulative Timesteps: 1,976,140,344

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50,015.50909
Policy Entropy: 2.23709
Value Function Loss: 0.02042

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.07923
Policy Update Magnitude: 0.32032
Value Function Update Magnitude: 0.35193

Collected Steps per Second: 22,085.23211
Overall Steps per Second: 10,485.58509

Timestep Collection Time: 2.26414
Timestep Consumption Time: 2.50470
PPO Batch Consumption Time: 0.29169
Total Iteration Time: 4.76883

Cumulative Model Updates: 236,876
Cumulative Timesteps: 1,976,190,348

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1976190348...
Checkpoint 1976190348 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 67,809.02488
Policy Entropy: 2.24043
Value Function Loss: 0.02005

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.07585
Policy Update Magnitude: 0.31154
Value Function Update Magnitude: 0.31416

Collected Steps per Second: 21,921.91856
Overall Steps per Second: 10,609.60748

Timestep Collection Time: 2.28091
Timestep Consumption Time: 2.43198
PPO Batch Consumption Time: 0.27979
Total Iteration Time: 4.71290

Cumulative Model Updates: 236,882
Cumulative Timesteps: 1,976,240,350

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49,839.52782
Policy Entropy: 2.24651
Value Function Loss: 0.02051

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.08224
Policy Update Magnitude: 0.30929
Value Function Update Magnitude: 0.30067

Collected Steps per Second: 21,459.84177
Overall Steps per Second: 10,558.66201

Timestep Collection Time: 2.33003
Timestep Consumption Time: 2.40561
PPO Batch Consumption Time: 0.27680
Total Iteration Time: 4.73564

Cumulative Model Updates: 236,888
Cumulative Timesteps: 1,976,290,352

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1976290352...
Checkpoint 1976290352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,077.41822
Policy Entropy: 2.24421
Value Function Loss: 0.02340

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.08299
Policy Update Magnitude: 0.31922
Value Function Update Magnitude: 0.31682

Collected Steps per Second: 21,429.28744
Overall Steps per Second: 10,495.79568

Timestep Collection Time: 2.33335
Timestep Consumption Time: 2.43065
PPO Batch Consumption Time: 0.27932
Total Iteration Time: 4.76400

Cumulative Model Updates: 236,894
Cumulative Timesteps: 1,976,340,354

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,848.69630
Policy Entropy: 2.24824
Value Function Loss: 0.02302

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.07930
Policy Update Magnitude: 0.32765
Value Function Update Magnitude: 0.34899

Collected Steps per Second: 21,459.09948
Overall Steps per Second: 10,476.77496

Timestep Collection Time: 2.33057
Timestep Consumption Time: 2.44303
PPO Batch Consumption Time: 0.27931
Total Iteration Time: 4.77361

Cumulative Model Updates: 236,900
Cumulative Timesteps: 1,976,390,366

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1976390366...
Checkpoint 1976390366 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47,930.38105
Policy Entropy: 2.26393
Value Function Loss: 0.02221

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.08382
Policy Update Magnitude: 0.31753
Value Function Update Magnitude: 0.36856

Collected Steps per Second: 21,565.88292
Overall Steps per Second: 10,331.30313

Timestep Collection Time: 2.32005
Timestep Consumption Time: 2.52290
PPO Batch Consumption Time: 0.29405
Total Iteration Time: 4.84295

Cumulative Model Updates: 236,906
Cumulative Timesteps: 1,976,440,400

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,941.01048
Policy Entropy: 2.27096
Value Function Loss: 0.02069

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.08461
Policy Update Magnitude: 0.31353
Value Function Update Magnitude: 0.34475

Collected Steps per Second: 21,527.03596
Overall Steps per Second: 10,497.85279

Timestep Collection Time: 2.32294
Timestep Consumption Time: 2.44051
PPO Batch Consumption Time: 0.29162
Total Iteration Time: 4.76345

Cumulative Model Updates: 236,912
Cumulative Timesteps: 1,976,490,406

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1976490406...
Checkpoint 1976490406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,838.84937
Policy Entropy: 2.27156
Value Function Loss: 0.01959

Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.08194
Policy Update Magnitude: 0.30588
Value Function Update Magnitude: 0.30682

Collected Steps per Second: 21,239.73612
Overall Steps per Second: 10,510.65674

Timestep Collection Time: 2.35615
Timestep Consumption Time: 2.40511
PPO Batch Consumption Time: 0.28653
Total Iteration Time: 4.76126

Cumulative Model Updates: 236,918
Cumulative Timesteps: 1,976,540,450

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,165.70512
Policy Entropy: 2.27056
Value Function Loss: 0.02011

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.07362
Policy Update Magnitude: 0.30308
Value Function Update Magnitude: 0.29505

Collected Steps per Second: 21,195.95513
Overall Steps per Second: 10,437.71870

Timestep Collection Time: 2.35904
Timestep Consumption Time: 2.43148
PPO Batch Consumption Time: 0.28992
Total Iteration Time: 4.79051

Cumulative Model Updates: 236,924
Cumulative Timesteps: 1,976,590,452

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1976590452...
Checkpoint 1976590452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,090.31954
Policy Entropy: 2.26252
Value Function Loss: 0.01944

Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.08014
Policy Update Magnitude: 0.30206
Value Function Update Magnitude: 0.30106

Collected Steps per Second: 21,311.17217
Overall Steps per Second: 10,391.71234

Timestep Collection Time: 2.34731
Timestep Consumption Time: 2.46652
PPO Batch Consumption Time: 0.29078
Total Iteration Time: 4.81384

Cumulative Model Updates: 236,930
Cumulative Timesteps: 1,976,640,476

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47,731.38591
Policy Entropy: 2.24871
Value Function Loss: 0.01781

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.07851
Policy Update Magnitude: 0.30143
Value Function Update Magnitude: 0.30866

Collected Steps per Second: 21,844.70271
Overall Steps per Second: 10,653.00836

Timestep Collection Time: 2.28916
Timestep Consumption Time: 2.40491
PPO Batch Consumption Time: 0.27943
Total Iteration Time: 4.69407

Cumulative Model Updates: 236,936
Cumulative Timesteps: 1,976,690,482

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1976690482...
Checkpoint 1976690482 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 65,372.30299
Policy Entropy: 2.24530
Value Function Loss: 0.01926

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.07023
Policy Update Magnitude: 0.30696
Value Function Update Magnitude: 0.31096

Collected Steps per Second: 21,635.18880
Overall Steps per Second: 10,627.52064

Timestep Collection Time: 2.31114
Timestep Consumption Time: 2.39381
PPO Batch Consumption Time: 0.27902
Total Iteration Time: 4.70495

Cumulative Model Updates: 236,942
Cumulative Timesteps: 1,976,740,484

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49,872.25930
Policy Entropy: 2.23797
Value Function Loss: 0.02027

Mean KL Divergence: 0.00757
SB3 Clip Fraction: 0.07023
Policy Update Magnitude: 0.32572
Value Function Update Magnitude: 0.32733

Collected Steps per Second: 21,919.64140
Overall Steps per Second: 10,484.11827

Timestep Collection Time: 2.28124
Timestep Consumption Time: 2.48826
PPO Batch Consumption Time: 0.28642
Total Iteration Time: 4.76950

Cumulative Model Updates: 236,948
Cumulative Timesteps: 1,976,790,488

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1976790488...
Checkpoint 1976790488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,941.53202
Policy Entropy: 2.25783
Value Function Loss: 0.02321

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.07097
Policy Update Magnitude: 0.32734
Value Function Update Magnitude: 0.33783

Collected Steps per Second: 21,313.18159
Overall Steps per Second: 10,310.02110

Timestep Collection Time: 2.34662
Timestep Consumption Time: 2.50439
PPO Batch Consumption Time: 0.29234
Total Iteration Time: 4.85101

Cumulative Model Updates: 236,954
Cumulative Timesteps: 1,976,840,502

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45,246.94137
Policy Entropy: 2.26722
Value Function Loss: 0.02248

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.07109
Policy Update Magnitude: 0.32632
Value Function Update Magnitude: 0.37159

Collected Steps per Second: 21,784.48306
Overall Steps per Second: 10,385.37057

Timestep Collection Time: 2.29650
Timestep Consumption Time: 2.52066
PPO Batch Consumption Time: 0.29185
Total Iteration Time: 4.81716

Cumulative Model Updates: 236,960
Cumulative Timesteps: 1,976,890,530

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1976890530...
Checkpoint 1976890530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,017.95473
Policy Entropy: 2.28687
Value Function Loss: 0.02044

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.07818
Policy Update Magnitude: 0.31825
Value Function Update Magnitude: 0.35394

Collected Steps per Second: 21,458.00185
Overall Steps per Second: 10,396.58320

Timestep Collection Time: 2.33218
Timestep Consumption Time: 2.48132
PPO Batch Consumption Time: 0.29023
Total Iteration Time: 4.81350

Cumulative Model Updates: 236,966
Cumulative Timesteps: 1,976,940,574

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,524.32563
Policy Entropy: 2.29510
Value Function Loss: 0.01938

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.08058
Policy Update Magnitude: 0.30467
Value Function Update Magnitude: 0.32264

Collected Steps per Second: 21,496.09465
Overall Steps per Second: 10,319.60455

Timestep Collection Time: 2.32600
Timestep Consumption Time: 2.51914
PPO Batch Consumption Time: 0.29392
Total Iteration Time: 4.84515

Cumulative Model Updates: 236,972
Cumulative Timesteps: 1,976,990,574

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1976990574...
Checkpoint 1976990574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55,194.34843
Policy Entropy: 2.28649
Value Function Loss: 0.01995

Mean KL Divergence: 0.00763
SB3 Clip Fraction: 0.07008
Policy Update Magnitude: 0.30405
Value Function Update Magnitude: 0.31802

Collected Steps per Second: 21,451.10729
Overall Steps per Second: 10,495.95749

Timestep Collection Time: 2.33219
Timestep Consumption Time: 2.43422
PPO Batch Consumption Time: 0.27874
Total Iteration Time: 4.76641

Cumulative Model Updates: 236,978
Cumulative Timesteps: 1,977,040,602

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,104.78963
Policy Entropy: 2.28796
Value Function Loss: 0.01988

Mean KL Divergence: 0.00723
SB3 Clip Fraction: 0.06895
Policy Update Magnitude: 0.31283
Value Function Update Magnitude: 0.33971

Collected Steps per Second: 22,085.21983
Overall Steps per Second: 10,604.25529

Timestep Collection Time: 2.26405
Timestep Consumption Time: 2.45123
PPO Batch Consumption Time: 0.27769
Total Iteration Time: 4.71528

Cumulative Model Updates: 236,984
Cumulative Timesteps: 1,977,090,604

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1977090604...
Checkpoint 1977090604 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46,686.22487
Policy Entropy: 2.28237
Value Function Loss: 0.01824

Mean KL Divergence: 0.00692
SB3 Clip Fraction: 0.06489
Policy Update Magnitude: 0.30952
Value Function Update Magnitude: 0.32463

Collected Steps per Second: 22,153.65777
Overall Steps per Second: 10,515.26457

Timestep Collection Time: 2.25796
Timestep Consumption Time: 2.49913
PPO Batch Consumption Time: 0.28712
Total Iteration Time: 4.75708

Cumulative Model Updates: 236,990
Cumulative Timesteps: 1,977,140,626

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84,435.38359
Policy Entropy: 2.26896
Value Function Loss: 0.01950

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.06833
Policy Update Magnitude: 0.30931
Value Function Update Magnitude: 0.30000

Collected Steps per Second: 22,041.15186
Overall Steps per Second: 10,498.52128

Timestep Collection Time: 2.26921
Timestep Consumption Time: 2.49489
PPO Batch Consumption Time: 0.28783
Total Iteration Time: 4.76410

Cumulative Model Updates: 236,996
Cumulative Timesteps: 1,977,190,642

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1977190642...
Checkpoint 1977190642 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 64,706.01272
Policy Entropy: 2.25943
Value Function Loss: 0.02184

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.07462
Policy Update Magnitude: 0.31763
Value Function Update Magnitude: 0.31887

Collected Steps per Second: 22,020.60459
Overall Steps per Second: 10,580.54866

Timestep Collection Time: 2.27214
Timestep Consumption Time: 2.45672
PPO Batch Consumption Time: 0.27918
Total Iteration Time: 4.72887

Cumulative Model Updates: 237,002
Cumulative Timesteps: 1,977,240,676

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,718.72903
Policy Entropy: 2.25767
Value Function Loss: 0.02274

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.07885
Policy Update Magnitude: 0.32107
Value Function Update Magnitude: 0.33752

Collected Steps per Second: 22,345.38422
Overall Steps per Second: 10,524.39874

Timestep Collection Time: 2.23805
Timestep Consumption Time: 2.51377
PPO Batch Consumption Time: 0.29322
Total Iteration Time: 4.75182

Cumulative Model Updates: 237,008
Cumulative Timesteps: 1,977,290,686

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1977290686...
Checkpoint 1977290686 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,262.58337
Policy Entropy: 2.27101
Value Function Loss: 0.02025

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.07515
Policy Update Magnitude: 0.31631
Value Function Update Magnitude: 0.32838

Collected Steps per Second: 22,120.58910
Overall Steps per Second: 10,642.88381

Timestep Collection Time: 2.26079
Timestep Consumption Time: 2.43812
PPO Batch Consumption Time: 0.27897
Total Iteration Time: 4.69891

Cumulative Model Updates: 237,014
Cumulative Timesteps: 1,977,340,696

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50,638.51792
Policy Entropy: 2.25860
Value Function Loss: 0.02101

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.07609
Policy Update Magnitude: 0.31388
Value Function Update Magnitude: 0.27119

Collected Steps per Second: 21,803.48063
Overall Steps per Second: 10,457.49556

Timestep Collection Time: 2.29340
Timestep Consumption Time: 2.48825
PPO Batch Consumption Time: 0.28764
Total Iteration Time: 4.78164

Cumulative Model Updates: 237,020
Cumulative Timesteps: 1,977,390,700

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1977390700...
Checkpoint 1977390700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55,788.20431
Policy Entropy: 2.26303
Value Function Loss: 0.02340

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.08728
Policy Update Magnitude: 0.32657
Value Function Update Magnitude: 0.23786

Collected Steps per Second: 21,200.25415
Overall Steps per Second: 10,302.71306

Timestep Collection Time: 2.35922
Timestep Consumption Time: 2.49543
PPO Batch Consumption Time: 0.29358
Total Iteration Time: 4.85464

Cumulative Model Updates: 237,026
Cumulative Timesteps: 1,977,440,716

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49,192.99193
Policy Entropy: 2.25310
Value Function Loss: 0.02739

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.08485
Policy Update Magnitude: 0.33453
Value Function Update Magnitude: 0.27443

Collected Steps per Second: 21,556.30803
Overall Steps per Second: 10,338.88135

Timestep Collection Time: 2.32025
Timestep Consumption Time: 2.51741
PPO Batch Consumption Time: 0.29282
Total Iteration Time: 4.83766

Cumulative Model Updates: 237,032
Cumulative Timesteps: 1,977,490,732

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1977490732...
Checkpoint 1977490732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,231.31096
Policy Entropy: 2.25600
Value Function Loss: 0.02507

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.07566
Policy Update Magnitude: 0.33301
Value Function Update Magnitude: 0.36271

Collected Steps per Second: 21,038.09368
Overall Steps per Second: 10,251.04575

Timestep Collection Time: 2.37883
Timestep Consumption Time: 2.50321
PPO Batch Consumption Time: 0.27815
Total Iteration Time: 4.88204

Cumulative Model Updates: 237,038
Cumulative Timesteps: 1,977,540,778

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,586.28260
Policy Entropy: 2.24428
Value Function Loss: 0.02209

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.07646
Policy Update Magnitude: 0.32296
Value Function Update Magnitude: 0.36938

Collected Steps per Second: 22,294.51548
Overall Steps per Second: 10,505.70539

Timestep Collection Time: 2.24333
Timestep Consumption Time: 2.51732
PPO Batch Consumption Time: 0.29272
Total Iteration Time: 4.76065

Cumulative Model Updates: 237,044
Cumulative Timesteps: 1,977,590,792

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1977590792...
Checkpoint 1977590792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,277.97291
Policy Entropy: 2.23270
Value Function Loss: 0.01995

Mean KL Divergence: 0.00764
SB3 Clip Fraction: 0.07231
Policy Update Magnitude: 0.32130
Value Function Update Magnitude: 0.35840

Collected Steps per Second: 21,721.14335
Overall Steps per Second: 10,586.67862

Timestep Collection Time: 2.30310
Timestep Consumption Time: 2.42227
PPO Batch Consumption Time: 0.27778
Total Iteration Time: 4.72537

Cumulative Model Updates: 237,050
Cumulative Timesteps: 1,977,640,818

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45,392.95389
Policy Entropy: 2.24030
Value Function Loss: 0.02082

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.06900
Policy Update Magnitude: 0.32115
Value Function Update Magnitude: 0.35784

Collected Steps per Second: 22,104.76051
Overall Steps per Second: 10,472.21946

Timestep Collection Time: 2.26277
Timestep Consumption Time: 2.51349
PPO Batch Consumption Time: 0.29389
Total Iteration Time: 4.77626

Cumulative Model Updates: 237,056
Cumulative Timesteps: 1,977,690,836

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1977690836...
Checkpoint 1977690836 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,969.48085
Policy Entropy: 2.24750
Value Function Loss: 0.02199

Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.07573
Policy Update Magnitude: 0.32747
Value Function Update Magnitude: 0.34230

Collected Steps per Second: 21,656.13924
Overall Steps per Second: 10,546.53775

Timestep Collection Time: 2.31001
Timestep Consumption Time: 2.43334
PPO Batch Consumption Time: 0.27879
Total Iteration Time: 4.74336

Cumulative Model Updates: 237,062
Cumulative Timesteps: 1,977,740,862

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,034.40687
Policy Entropy: 2.24330
Value Function Loss: 0.02106

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.07298
Policy Update Magnitude: 0.32523
Value Function Update Magnitude: 0.31472

Collected Steps per Second: 22,098.16067
Overall Steps per Second: 10,506.50743

Timestep Collection Time: 2.26345
Timestep Consumption Time: 2.49722
PPO Batch Consumption Time: 0.29206
Total Iteration Time: 4.76067

Cumulative Model Updates: 237,068
Cumulative Timesteps: 1,977,790,880

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1977790880...
Checkpoint 1977790880 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43,710.36952
Policy Entropy: 2.23327
Value Function Loss: 0.02053

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.08822
Policy Update Magnitude: 0.31653
Value Function Update Magnitude: 0.31901

Collected Steps per Second: 21,764.24952
Overall Steps per Second: 10,575.44752

Timestep Collection Time: 2.29836
Timestep Consumption Time: 2.43166
PPO Batch Consumption Time: 0.27859
Total Iteration Time: 4.73001

Cumulative Model Updates: 237,074
Cumulative Timesteps: 1,977,840,902

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 64,987.05065
Policy Entropy: 2.22914
Value Function Loss: 0.02026

Mean KL Divergence: 0.01328
SB3 Clip Fraction: 0.11043
Policy Update Magnitude: 0.31331
Value Function Update Magnitude: 0.34348

Collected Steps per Second: 21,392.64548
Overall Steps per Second: 10,478.15509

Timestep Collection Time: 2.33763
Timestep Consumption Time: 2.43497
PPO Batch Consumption Time: 0.27886
Total Iteration Time: 4.77260

Cumulative Model Updates: 237,080
Cumulative Timesteps: 1,977,890,910

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1977890910...
Checkpoint 1977890910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 73,446.75276
Policy Entropy: 2.24697
Value Function Loss: 0.02108

Mean KL Divergence: 0.01433
SB3 Clip Fraction: 0.11329
Policy Update Magnitude: 0.32234
Value Function Update Magnitude: 0.35797

Collected Steps per Second: 21,111.10867
Overall Steps per Second: 10,232.74370

Timestep Collection Time: 2.37041
Timestep Consumption Time: 2.51997
PPO Batch Consumption Time: 0.29376
Total Iteration Time: 4.89038

Cumulative Model Updates: 237,086
Cumulative Timesteps: 1,977,940,952

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50,978.10857
Policy Entropy: 2.25317
Value Function Loss: 0.02230

Mean KL Divergence: 0.01315
SB3 Clip Fraction: 0.11055
Policy Update Magnitude: 0.32962
Value Function Update Magnitude: 0.36446

Collected Steps per Second: 21,716.48063
Overall Steps per Second: 10,480.48424

Timestep Collection Time: 2.30350
Timestep Consumption Time: 2.46956
PPO Batch Consumption Time: 0.28653
Total Iteration Time: 4.77306

Cumulative Model Updates: 237,092
Cumulative Timesteps: 1,977,990,976

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1977990976...
Checkpoint 1977990976 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43,356.88820
Policy Entropy: 2.26469
Value Function Loss: 0.02191

Mean KL Divergence: 0.01065
SB3 Clip Fraction: 0.09315
Policy Update Magnitude: 0.32681
Value Function Update Magnitude: 0.35302

Collected Steps per Second: 21,303.42115
Overall Steps per Second: 10,317.88824

Timestep Collection Time: 2.34789
Timestep Consumption Time: 2.49981
PPO Batch Consumption Time: 0.29274
Total Iteration Time: 4.84770

Cumulative Model Updates: 237,098
Cumulative Timesteps: 1,978,040,994

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,274.73218
Policy Entropy: 2.25027
Value Function Loss: 0.02292

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.08301
Policy Update Magnitude: 0.32951
Value Function Update Magnitude: 0.34127

Collected Steps per Second: 21,811.52522
Overall Steps per Second: 10,410.40471

Timestep Collection Time: 2.29328
Timestep Consumption Time: 2.51153
PPO Batch Consumption Time: 0.29312
Total Iteration Time: 4.80481

Cumulative Model Updates: 237,104
Cumulative Timesteps: 1,978,091,014

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1978091014...
Checkpoint 1978091014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,419.16299
Policy Entropy: 2.23548
Value Function Loss: 0.02352

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.08280
Policy Update Magnitude: 0.33259
Value Function Update Magnitude: 0.33764

Collected Steps per Second: 21,891.61607
Overall Steps per Second: 10,482.97378

Timestep Collection Time: 2.28553
Timestep Consumption Time: 2.48735
PPO Batch Consumption Time: 0.27914
Total Iteration Time: 4.77288

Cumulative Model Updates: 237,110
Cumulative Timesteps: 1,978,141,048

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,382.00589
Policy Entropy: 2.24018
Value Function Loss: 0.02396

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.08576
Policy Update Magnitude: 0.33096
Value Function Update Magnitude: 0.32672

Collected Steps per Second: 22,135.19843
Overall Steps per Second: 10,555.36416

Timestep Collection Time: 2.26002
Timestep Consumption Time: 2.47937
PPO Batch Consumption Time: 0.28665
Total Iteration Time: 4.73939

Cumulative Model Updates: 237,116
Cumulative Timesteps: 1,978,191,074

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1978191074...
Checkpoint 1978191074 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,737.73742
Policy Entropy: 2.25729
Value Function Loss: 0.02134

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.08256
Policy Update Magnitude: 0.32256
Value Function Update Magnitude: 0.30747

Collected Steps per Second: 21,803.57727
Overall Steps per Second: 10,595.37314

Timestep Collection Time: 2.29458
Timestep Consumption Time: 2.42729
PPO Batch Consumption Time: 0.27906
Total Iteration Time: 4.72187

Cumulative Model Updates: 237,122
Cumulative Timesteps: 1,978,241,104

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,737.73742
Policy Entropy: 2.26982
Value Function Loss: 0.01813

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.07484
Policy Update Magnitude: 0.30788
Value Function Update Magnitude: 0.29079

Collected Steps per Second: 21,409.91081
Overall Steps per Second: 10,465.60060

Timestep Collection Time: 2.33639
Timestep Consumption Time: 2.44326
PPO Batch Consumption Time: 0.29402
Total Iteration Time: 4.77966

Cumulative Model Updates: 237,128
Cumulative Timesteps: 1,978,291,126

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1978291126...
Checkpoint 1978291126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,811.12239
Policy Entropy: 2.28039
Value Function Loss: 0.01773

Mean KL Divergence: 0.00711
SB3 Clip Fraction: 0.07031
Policy Update Magnitude: 0.29828
Value Function Update Magnitude: 0.25883

Collected Steps per Second: 21,152.05408
Overall Steps per Second: 10,578.39128

Timestep Collection Time: 2.36469
Timestep Consumption Time: 2.36363
PPO Batch Consumption Time: 0.27922
Total Iteration Time: 4.72832

Cumulative Model Updates: 237,134
Cumulative Timesteps: 1,978,341,144

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70,894.03874
Policy Entropy: 2.26592
Value Function Loss: 0.01878

Mean KL Divergence: 0.00676
SB3 Clip Fraction: 0.06617
Policy Update Magnitude: 0.30283
Value Function Update Magnitude: 0.24638

Collected Steps per Second: 21,579.85825
Overall Steps per Second: 10,533.23801

Timestep Collection Time: 2.31772
Timestep Consumption Time: 2.43068
PPO Batch Consumption Time: 0.29432
Total Iteration Time: 4.74840

Cumulative Model Updates: 237,140
Cumulative Timesteps: 1,978,391,160

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1978391160...
Checkpoint 1978391160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 63,068.73762
Policy Entropy: 2.25963
Value Function Loss: 0.01894

Mean KL Divergence: 0.00694
SB3 Clip Fraction: 0.06501
Policy Update Magnitude: 0.30727
Value Function Update Magnitude: 0.25407

Collected Steps per Second: 20,841.01712
Overall Steps per Second: 10,228.91732

Timestep Collection Time: 2.40007
Timestep Consumption Time: 2.48998
PPO Batch Consumption Time: 0.29443
Total Iteration Time: 4.89006

Cumulative Model Updates: 237,146
Cumulative Timesteps: 1,978,441,180

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,811.77119
Policy Entropy: 2.24468
Value Function Loss: 0.01982

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.07696
Policy Update Magnitude: 0.31408
Value Function Update Magnitude: 0.21799

Collected Steps per Second: 21,439.61073
Overall Steps per Second: 10,405.10912

Timestep Collection Time: 2.33400
Timestep Consumption Time: 2.47518
PPO Batch Consumption Time: 0.28824
Total Iteration Time: 4.80918

Cumulative Model Updates: 237,152
Cumulative Timesteps: 1,978,491,220

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1978491220...
Checkpoint 1978491220 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,256.95196
Policy Entropy: 2.26654
Value Function Loss: 0.01961

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.08423
Policy Update Magnitude: 0.31311
Value Function Update Magnitude: 0.26334

Collected Steps per Second: 21,441.95865
Overall Steps per Second: 10,405.04606

Timestep Collection Time: 2.33346
Timestep Consumption Time: 2.47517
PPO Batch Consumption Time: 0.29008
Total Iteration Time: 4.80863

Cumulative Model Updates: 237,158
Cumulative Timesteps: 1,978,541,254

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46,243.27373
Policy Entropy: 2.27825
Value Function Loss: 0.02000

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.07628
Policy Update Magnitude: 0.30995
Value Function Update Magnitude: 0.29419

Collected Steps per Second: 21,835.13149
Overall Steps per Second: 10,395.30247

Timestep Collection Time: 2.29080
Timestep Consumption Time: 2.52099
PPO Batch Consumption Time: 0.29358
Total Iteration Time: 4.81179

Cumulative Model Updates: 237,164
Cumulative Timesteps: 1,978,591,274

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1978591274...
Checkpoint 1978591274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40,260.84102
Policy Entropy: 2.27835
Value Function Loss: 0.01840

Mean KL Divergence: 0.00749
SB3 Clip Fraction: 0.07272
Policy Update Magnitude: 0.30053
Value Function Update Magnitude: 0.26839

Collected Steps per Second: 21,530.88677
Overall Steps per Second: 10,464.28589

Timestep Collection Time: 2.32290
Timestep Consumption Time: 2.45660
PPO Batch Consumption Time: 0.27806
Total Iteration Time: 4.77949

Cumulative Model Updates: 237,170
Cumulative Timesteps: 1,978,641,288

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52,025.83798
Policy Entropy: 2.27490
Value Function Loss: 0.01885

Mean KL Divergence: 0.00675
SB3 Clip Fraction: 0.06529
Policy Update Magnitude: 0.29788
Value Function Update Magnitude: 0.25286

Collected Steps per Second: 22,018.25719
Overall Steps per Second: 10,506.09048

Timestep Collection Time: 2.27175
Timestep Consumption Time: 2.48930
PPO Batch Consumption Time: 0.27935
Total Iteration Time: 4.76105

Cumulative Model Updates: 237,176
Cumulative Timesteps: 1,978,691,308

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1978691308...
Checkpoint 1978691308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,743.51677
Policy Entropy: 2.28565
Value Function Loss: 0.02035

Mean KL Divergence: 0.00726
SB3 Clip Fraction: 0.06885
Policy Update Magnitude: 0.31004
Value Function Update Magnitude: 0.28390

Collected Steps per Second: 21,808.24368
Overall Steps per Second: 10,560.59522

Timestep Collection Time: 2.29280
Timestep Consumption Time: 2.44197
PPO Batch Consumption Time: 0.27890
Total Iteration Time: 4.73477

Cumulative Model Updates: 237,182
Cumulative Timesteps: 1,978,741,310

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,924.51348
Policy Entropy: 2.27989
Value Function Loss: 0.02081

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.06964
Policy Update Magnitude: 0.31512
Value Function Update Magnitude: 0.31363

Collected Steps per Second: 21,874.45511
Overall Steps per Second: 10,518.58509

Timestep Collection Time: 2.28659
Timestep Consumption Time: 2.46861
PPO Batch Consumption Time: 0.28567
Total Iteration Time: 4.75520

Cumulative Model Updates: 237,188
Cumulative Timesteps: 1,978,791,328

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1978791328...
Checkpoint 1978791328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 62,468.53861
Policy Entropy: 2.27529
Value Function Loss: 0.02122

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.07100
Policy Update Magnitude: 0.31266
Value Function Update Magnitude: 0.30521

Collected Steps per Second: 21,788.28935
Overall Steps per Second: 10,600.40088

Timestep Collection Time: 2.29628
Timestep Consumption Time: 2.42354
PPO Batch Consumption Time: 0.27949
Total Iteration Time: 4.71982

Cumulative Model Updates: 237,194
Cumulative Timesteps: 1,978,841,360

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58,359.89309
Policy Entropy: 2.27516
Value Function Loss: 0.01817

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.07500
Policy Update Magnitude: 0.30805
Value Function Update Magnitude: 0.28514

Collected Steps per Second: 21,542.44789
Overall Steps per Second: 10,510.54267

Timestep Collection Time: 2.32100
Timestep Consumption Time: 2.43613
PPO Batch Consumption Time: 0.29425
Total Iteration Time: 4.75713

Cumulative Model Updates: 237,200
Cumulative Timesteps: 1,978,891,360

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1978891360...
Checkpoint 1978891360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 52,722.30541
Policy Entropy: 2.27485
Value Function Loss: 0.01765

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.07170
Policy Update Magnitude: 0.29687
Value Function Update Magnitude: 0.29323

Collected Steps per Second: 21,363.57093
Overall Steps per Second: 10,614.52112

Timestep Collection Time: 2.34043
Timestep Consumption Time: 2.37010
PPO Batch Consumption Time: 0.28021
Total Iteration Time: 4.71053

Cumulative Model Updates: 237,206
Cumulative Timesteps: 1,978,941,360

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50,492.29472
Policy Entropy: 2.27754
Value Function Loss: 0.01859

Mean KL Divergence: 0.00753
SB3 Clip Fraction: 0.07042
Policy Update Magnitude: 0.30574
Value Function Update Magnitude: 0.29963

Collected Steps per Second: 21,267.81148
Overall Steps per Second: 10,505.58782

Timestep Collection Time: 2.35116
Timestep Consumption Time: 2.40859
PPO Batch Consumption Time: 0.28997
Total Iteration Time: 4.75975

Cumulative Model Updates: 237,212
Cumulative Timesteps: 1,978,991,364

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1978991364...
Checkpoint 1978991364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 52,391.53104
Policy Entropy: 2.27295
Value Function Loss: 0.01918

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.07446
Policy Update Magnitude: 0.30858
Value Function Update Magnitude: 0.29204

Collected Steps per Second: 20,811.80698
Overall Steps per Second: 10,234.28912

Timestep Collection Time: 2.40258
Timestep Consumption Time: 2.48315
PPO Batch Consumption Time: 0.29378
Total Iteration Time: 4.88573

Cumulative Model Updates: 237,218
Cumulative Timesteps: 1,979,041,366

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,094.15108
Policy Entropy: 2.27349
Value Function Loss: 0.01907

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.07494
Policy Update Magnitude: 0.30302
Value Function Update Magnitude: 0.29473

Collected Steps per Second: 21,532.72220
Overall Steps per Second: 10,390.63177

Timestep Collection Time: 2.32372
Timestep Consumption Time: 2.49177
PPO Batch Consumption Time: 0.29276
Total Iteration Time: 4.81549

Cumulative Model Updates: 237,224
Cumulative Timesteps: 1,979,091,402

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1979091402...
Checkpoint 1979091402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,815.50180
Policy Entropy: 2.27387
Value Function Loss: 0.01789

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.08296
Policy Update Magnitude: 0.30014
Value Function Update Magnitude: 0.31618

Collected Steps per Second: 21,265.20851
Overall Steps per Second: 10,352.35732

Timestep Collection Time: 2.35295
Timestep Consumption Time: 2.48034
PPO Batch Consumption Time: 0.29231
Total Iteration Time: 4.83330

Cumulative Model Updates: 237,230
Cumulative Timesteps: 1,979,141,438

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,293.03447
Policy Entropy: 2.28462
Value Function Loss: 0.01798

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.07802
Policy Update Magnitude: 0.29581
Value Function Update Magnitude: 0.31174

Collected Steps per Second: 22,549.64683
Overall Steps per Second: 10,502.31465

Timestep Collection Time: 2.21768
Timestep Consumption Time: 2.54393
PPO Batch Consumption Time: 0.28982
Total Iteration Time: 4.76162

Cumulative Model Updates: 237,236
Cumulative Timesteps: 1,979,191,446

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1979191446...
Checkpoint 1979191446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 56,945.42224
Policy Entropy: 2.28689
Value Function Loss: 0.01768

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.07582
Policy Update Magnitude: 0.29197
Value Function Update Magnitude: 0.30395

Collected Steps per Second: 22,067.69288
Overall Steps per Second: 10,487.63190

Timestep Collection Time: 2.26648
Timestep Consumption Time: 2.50257
PPO Batch Consumption Time: 0.29227
Total Iteration Time: 4.76905

Cumulative Model Updates: 237,242
Cumulative Timesteps: 1,979,241,462

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42,997.34389
Policy Entropy: 2.28622
Value Function Loss: 0.01810

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.07611
Policy Update Magnitude: 0.29853
Value Function Update Magnitude: 0.31341

Collected Steps per Second: 21,984.32922
Overall Steps per Second: 10,415.87466

Timestep Collection Time: 2.27508
Timestep Consumption Time: 2.52683
PPO Batch Consumption Time: 0.29433
Total Iteration Time: 4.80190

Cumulative Model Updates: 237,248
Cumulative Timesteps: 1,979,291,478

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1979291478...
Checkpoint 1979291478 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 66,161.52173
Policy Entropy: 2.28474
Value Function Loss: 0.01936

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.08340
Policy Update Magnitude: 0.30715
Value Function Update Magnitude: 0.32809

Collected Steps per Second: 21,790.16737
Overall Steps per Second: 10,564.09719

Timestep Collection Time: 2.29544
Timestep Consumption Time: 2.43928
PPO Batch Consumption Time: 0.27952
Total Iteration Time: 4.73472

Cumulative Model Updates: 237,254
Cumulative Timesteps: 1,979,341,496

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93,534.00175
Policy Entropy: 2.29010
Value Function Loss: 0.01749

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.08322
Policy Update Magnitude: 0.29781
Value Function Update Magnitude: 0.30103

Collected Steps per Second: 22,143.76589
Overall Steps per Second: 10,534.36613

Timestep Collection Time: 2.25869
Timestep Consumption Time: 2.48919
PPO Batch Consumption Time: 0.29050
Total Iteration Time: 4.74789

Cumulative Model Updates: 237,260
Cumulative Timesteps: 1,979,391,512

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1979391512...
Checkpoint 1979391512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 76,035.68704
Policy Entropy: 2.27486
Value Function Loss: 0.01756

Mean KL Divergence: 0.00753
SB3 Clip Fraction: 0.07198
Policy Update Magnitude: 0.30553
Value Function Update Magnitude: 0.27773

Collected Steps per Second: 20,904.98204
Overall Steps per Second: 10,204.90775

Timestep Collection Time: 2.39197
Timestep Consumption Time: 2.50803
PPO Batch Consumption Time: 0.29372
Total Iteration Time: 4.90000

Cumulative Model Updates: 237,266
Cumulative Timesteps: 1,979,441,516

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50,887.52901
Policy Entropy: 2.26438
Value Function Loss: 0.01881

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.07088
Policy Update Magnitude: 0.30980
Value Function Update Magnitude: 0.29693

Collected Steps per Second: 19,659.30165
Overall Steps per Second: 9,948.11357

Timestep Collection Time: 2.54444
Timestep Consumption Time: 2.48385
PPO Batch Consumption Time: 0.27920
Total Iteration Time: 5.02829

Cumulative Model Updates: 237,272
Cumulative Timesteps: 1,979,491,538

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1979491538...
Checkpoint 1979491538 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43,979.94237
Policy Entropy: 2.27011
Value Function Loss: 0.02132

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.07599
Policy Update Magnitude: 0.31907
Value Function Update Magnitude: 0.33336

Collected Steps per Second: 20,191.03904
Overall Steps per Second: 10,212.59220

Timestep Collection Time: 2.47734
Timestep Consumption Time: 2.42054
PPO Batch Consumption Time: 0.27892
Total Iteration Time: 4.89787

Cumulative Model Updates: 237,278
Cumulative Timesteps: 1,979,541,558

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,472.10424
Policy Entropy: 2.28861
Value Function Loss: 0.02116

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.07215
Policy Update Magnitude: 0.31094
Value Function Update Magnitude: 0.33108

Collected Steps per Second: 21,201.20285
Overall Steps per Second: 10,614.62656

Timestep Collection Time: 2.35930
Timestep Consumption Time: 2.35307
PPO Batch Consumption Time: 0.27727
Total Iteration Time: 4.71237

Cumulative Model Updates: 237,284
Cumulative Timesteps: 1,979,591,578

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1979591578...
Checkpoint 1979591578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 72,319.44667
Policy Entropy: 2.27528
Value Function Loss: 0.01904

Mean KL Divergence: 0.00707
SB3 Clip Fraction: 0.06658
Policy Update Magnitude: 0.30558
Value Function Update Magnitude: 0.33628

Collected Steps per Second: 20,873.31010
Overall Steps per Second: 10,520.33669

Timestep Collection Time: 2.39780
Timestep Consumption Time: 2.35965
PPO Batch Consumption Time: 0.27807
Total Iteration Time: 4.75745

Cumulative Model Updates: 237,290
Cumulative Timesteps: 1,979,641,628

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82,967.83503
Policy Entropy: 2.26572
Value Function Loss: 0.01893

Mean KL Divergence: 0.00709
SB3 Clip Fraction: 0.06593
Policy Update Magnitude: 0.30485
Value Function Update Magnitude: 0.32168

Collected Steps per Second: 21,212.04900
Overall Steps per Second: 10,413.18938

Timestep Collection Time: 2.35838
Timestep Consumption Time: 2.44572
PPO Batch Consumption Time: 0.27958
Total Iteration Time: 4.80410

Cumulative Model Updates: 237,296
Cumulative Timesteps: 1,979,691,654

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1979691654...
Checkpoint 1979691654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87,003.58468
Policy Entropy: 2.27454
Value Function Loss: 0.01819

Mean KL Divergence: 0.00726
SB3 Clip Fraction: 0.06711
Policy Update Magnitude: 0.30178
Value Function Update Magnitude: 0.32416

Collected Steps per Second: 21,466.29633
Overall Steps per Second: 10,356.95836

Timestep Collection Time: 2.33054
Timestep Consumption Time: 2.49984
PPO Batch Consumption Time: 0.29300
Total Iteration Time: 4.83038

Cumulative Model Updates: 237,302
Cumulative Timesteps: 1,979,741,682

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55,181.98927
Policy Entropy: 2.27938
Value Function Loss: 0.02046

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.07462
Policy Update Magnitude: 0.30380
Value Function Update Magnitude: 0.33689

Collected Steps per Second: 22,100.28333
Overall Steps per Second: 10,611.84319

Timestep Collection Time: 2.26332
Timestep Consumption Time: 2.45028
PPO Batch Consumption Time: 0.28898
Total Iteration Time: 4.71360

Cumulative Model Updates: 237,308
Cumulative Timesteps: 1,979,791,702

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1979791702...
Checkpoint 1979791702 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47,913.02920
Policy Entropy: 2.27830
Value Function Loss: 0.01850

Mean KL Divergence: 0.00724
SB3 Clip Fraction: 0.06769
Policy Update Magnitude: 0.30427
Value Function Update Magnitude: 0.33846

Collected Steps per Second: 21,754.68070
Overall Steps per Second: 10,444.23277

Timestep Collection Time: 2.29928
Timestep Consumption Time: 2.48997
PPO Batch Consumption Time: 0.29435
Total Iteration Time: 4.78925

Cumulative Model Updates: 237,314
Cumulative Timesteps: 1,979,841,722

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50,566.47231
Policy Entropy: 2.27288
Value Function Loss: 0.01896

Mean KL Divergence: 0.00747
SB3 Clip Fraction: 0.06599
Policy Update Magnitude: 0.30347
Value Function Update Magnitude: 0.30440

Collected Steps per Second: 22,072.07750
Overall Steps per Second: 10,474.02556

Timestep Collection Time: 2.26630
Timestep Consumption Time: 2.50951
PPO Batch Consumption Time: 0.29343
Total Iteration Time: 4.77581

Cumulative Model Updates: 237,320
Cumulative Timesteps: 1,979,891,744

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1979891744...
Checkpoint 1979891744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 50,905.50897
Policy Entropy: 2.28553
Value Function Loss: 0.01871

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.08179
Policy Update Magnitude: 0.30699
Value Function Update Magnitude: 0.29014

Collected Steps per Second: 21,984.52858
Overall Steps per Second: 10,647.02577

Timestep Collection Time: 2.27596
Timestep Consumption Time: 2.42356
PPO Batch Consumption Time: 0.27728
Total Iteration Time: 4.69953

Cumulative Model Updates: 237,326
Cumulative Timesteps: 1,979,941,780

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50,183.49184
Policy Entropy: 2.27901
Value Function Loss: 0.01979

Mean KL Divergence: 0.00718
SB3 Clip Fraction: 0.06679
Policy Update Magnitude: 0.31056
Value Function Update Magnitude: 0.30664

Collected Steps per Second: 21,755.19323
Overall Steps per Second: 10,395.71558

Timestep Collection Time: 2.29913
Timestep Consumption Time: 2.51228
PPO Batch Consumption Time: 0.29203
Total Iteration Time: 4.81141

Cumulative Model Updates: 237,332
Cumulative Timesteps: 1,979,991,798

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1979991798...
Checkpoint 1979991798 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,439.87312
Policy Entropy: 2.26877
Value Function Loss: 0.02103

Mean KL Divergence: 0.00710
SB3 Clip Fraction: 0.06565
Policy Update Magnitude: 0.30612
Value Function Update Magnitude: 0.29335

Collected Steps per Second: 21,358.99670
Overall Steps per Second: 10,329.29171

Timestep Collection Time: 2.34187
Timestep Consumption Time: 2.50067
PPO Batch Consumption Time: 0.29285
Total Iteration Time: 4.84254

Cumulative Model Updates: 237,338
Cumulative Timesteps: 1,980,041,818

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46,603.37064
Policy Entropy: 2.24605
Value Function Loss: 0.01952

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.07613
Policy Update Magnitude: 0.31046
Value Function Update Magnitude: 0.31599

Collected Steps per Second: 21,317.74777
Overall Steps per Second: 10,315.98388

Timestep Collection Time: 2.34631
Timestep Consumption Time: 2.50228
PPO Batch Consumption Time: 0.28983
Total Iteration Time: 4.84859

Cumulative Model Updates: 237,344
Cumulative Timesteps: 1,980,091,836

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1980091836...
Checkpoint 1980091836 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,621.07156
Policy Entropy: 2.22832
Value Function Loss: 0.02096

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.09003
Policy Update Magnitude: 0.31995
Value Function Update Magnitude: 0.32157

Collected Steps per Second: 21,418.58080
Overall Steps per Second: 10,323.24416

Timestep Collection Time: 2.33648
Timestep Consumption Time: 2.51122
PPO Batch Consumption Time: 0.29318
Total Iteration Time: 4.84770

Cumulative Model Updates: 237,350
Cumulative Timesteps: 1,980,141,880

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,803.62051
Policy Entropy: 2.23990
Value Function Loss: 0.02199

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.09318
Policy Update Magnitude: 0.31654
Value Function Update Magnitude: 0.30012

Collected Steps per Second: 22,066.66082
Overall Steps per Second: 10,379.17593

Timestep Collection Time: 2.26631
Timestep Consumption Time: 2.55199
PPO Batch Consumption Time: 0.29409
Total Iteration Time: 4.81830

Cumulative Model Updates: 237,356
Cumulative Timesteps: 1,980,191,890

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1980191890...
Checkpoint 1980191890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,337.53144
Policy Entropy: 2.25957
Value Function Loss: 0.02146

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.08627
Policy Update Magnitude: 0.31012
Value Function Update Magnitude: 0.28094

Collected Steps per Second: 21,831.26815
Overall Steps per Second: 10,556.59523

Timestep Collection Time: 2.29130
Timestep Consumption Time: 2.44716
PPO Batch Consumption Time: 0.27904
Total Iteration Time: 4.73846

Cumulative Model Updates: 237,362
Cumulative Timesteps: 1,980,241,912

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,053.83124
Policy Entropy: 2.27583
Value Function Loss: 0.01971

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.08340
Policy Update Magnitude: 0.30267
Value Function Update Magnitude: 0.28885

Collected Steps per Second: 21,953.03904
Overall Steps per Second: 10,485.88332

Timestep Collection Time: 2.27786
Timestep Consumption Time: 2.49103
PPO Batch Consumption Time: 0.29020
Total Iteration Time: 4.76889

Cumulative Model Updates: 237,368
Cumulative Timesteps: 1,980,291,918

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1980291918...
Checkpoint 1980291918 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,972.98983
Policy Entropy: 2.27196
Value Function Loss: 0.01820

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.08031
Policy Update Magnitude: 0.29657
Value Function Update Magnitude: 0.28851

Collected Steps per Second: 21,179.01574
Overall Steps per Second: 10,594.01166

Timestep Collection Time: 2.36177
Timestep Consumption Time: 2.35976
PPO Batch Consumption Time: 0.27978
Total Iteration Time: 4.72154

Cumulative Model Updates: 237,374
Cumulative Timesteps: 1,980,341,938

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,638.49522
Policy Entropy: 2.24609
Value Function Loss: 0.02238

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.08533
Policy Update Magnitude: 0.30742
Value Function Update Magnitude: 0.26322

Collected Steps per Second: 21,422.84495
Overall Steps per Second: 10,525.16893

Timestep Collection Time: 2.33452
Timestep Consumption Time: 2.41714
PPO Batch Consumption Time: 0.28975
Total Iteration Time: 4.75166

Cumulative Model Updates: 237,380
Cumulative Timesteps: 1,980,391,950

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1980391950...
Checkpoint 1980391950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,577.63003
Policy Entropy: 2.23276
Value Function Loss: 0.02244

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.08374
Policy Update Magnitude: 0.32294
Value Function Update Magnitude: 0.27754

Collected Steps per Second: 21,056.37767
Overall Steps per Second: 10,579.75022

Timestep Collection Time: 2.37553
Timestep Consumption Time: 2.35237
PPO Batch Consumption Time: 0.27935
Total Iteration Time: 4.72790

Cumulative Model Updates: 237,386
Cumulative Timesteps: 1,980,441,970

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52,913.68979
Policy Entropy: 2.20176
Value Function Loss: 0.02386

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.09193
Policy Update Magnitude: 0.32789
Value Function Update Magnitude: 0.29193

Collected Steps per Second: 21,359.68654
Overall Steps per Second: 10,480.42400

Timestep Collection Time: 2.34189
Timestep Consumption Time: 2.43101
PPO Batch Consumption Time: 0.27986
Total Iteration Time: 4.77290

Cumulative Model Updates: 237,392
Cumulative Timesteps: 1,980,491,992

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1980491992...
Checkpoint 1980491992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 52,140.91837
Policy Entropy: 2.22044
Value Function Loss: 0.02279

Mean KL Divergence: 0.01317
SB3 Clip Fraction: 0.10959
Policy Update Magnitude: 0.32449
Value Function Update Magnitude: 0.25368

Collected Steps per Second: 21,358.33860
Overall Steps per Second: 10,387.44493

Timestep Collection Time: 2.34250
Timestep Consumption Time: 2.47408
PPO Batch Consumption Time: 0.29215
Total Iteration Time: 4.81658

Cumulative Model Updates: 237,398
Cumulative Timesteps: 1,980,542,024

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63,291.57971
Policy Entropy: 2.23566
Value Function Loss: 0.02133

Mean KL Divergence: 0.01280
SB3 Clip Fraction: 0.10426
Policy Update Magnitude: 0.31560
Value Function Update Magnitude: 0.25530

Collected Steps per Second: 21,525.63138
Overall Steps per Second: 10,413.12149

Timestep Collection Time: 2.32328
Timestep Consumption Time: 2.47932
PPO Batch Consumption Time: 0.29342
Total Iteration Time: 4.80259

Cumulative Model Updates: 237,404
Cumulative Timesteps: 1,980,592,034

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1980592034...
Checkpoint 1980592034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 95,949.96018
Policy Entropy: 2.26895
Value Function Loss: 0.01863

Mean KL Divergence: 0.01090
SB3 Clip Fraction: 0.09649
Policy Update Magnitude: 0.30436
Value Function Update Magnitude: 0.26665

Collected Steps per Second: 21,328.84451
Overall Steps per Second: 10,472.93060

Timestep Collection Time: 2.34443
Timestep Consumption Time: 2.43016
PPO Batch Consumption Time: 0.27863
Total Iteration Time: 4.77459

Cumulative Model Updates: 237,410
Cumulative Timesteps: 1,980,642,038

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 64,856.36279
Policy Entropy: 2.27062
Value Function Loss: 0.01660

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.08946
Policy Update Magnitude: 0.29540
Value Function Update Magnitude: 0.28055

Collected Steps per Second: 21,443.32315
Overall Steps per Second: 10,475.43813

Timestep Collection Time: 2.33275
Timestep Consumption Time: 2.44242
PPO Batch Consumption Time: 0.27849
Total Iteration Time: 4.77517

Cumulative Model Updates: 237,416
Cumulative Timesteps: 1,980,692,060

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1980692060...
Checkpoint 1980692060 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48,715.81107
Policy Entropy: 2.27772
Value Function Loss: 0.01702

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.07542
Policy Update Magnitude: 0.29191
Value Function Update Magnitude: 0.27649

Collected Steps per Second: 21,167.02316
Overall Steps per Second: 10,239.57589

Timestep Collection Time: 2.36245
Timestep Consumption Time: 2.52115
PPO Batch Consumption Time: 0.29329
Total Iteration Time: 4.88360

Cumulative Model Updates: 237,422
Cumulative Timesteps: 1,980,742,066

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,514.47465
Policy Entropy: 2.26625
Value Function Loss: 0.01915

Mean KL Divergence: 0.00714
SB3 Clip Fraction: 0.06791
Policy Update Magnitude: 0.30326
Value Function Update Magnitude: 0.26515

Collected Steps per Second: 22,234.06165
Overall Steps per Second: 10,465.22798

Timestep Collection Time: 2.24898
Timestep Consumption Time: 2.52913
PPO Batch Consumption Time: 0.28770
Total Iteration Time: 4.77811

Cumulative Model Updates: 237,428
Cumulative Timesteps: 1,980,792,070

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1980792070...
Checkpoint 1980792070 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 93,361.54472
Policy Entropy: 2.26045
Value Function Loss: 0.02032

Mean KL Divergence: 0.00731
SB3 Clip Fraction: 0.06730
Policy Update Magnitude: 0.31103
Value Function Update Magnitude: 0.26958

Collected Steps per Second: 21,969.41927
Overall Steps per Second: 10,565.65897

Timestep Collection Time: 2.27707
Timestep Consumption Time: 2.45770
PPO Batch Consumption Time: 0.27925
Total Iteration Time: 4.73477

Cumulative Model Updates: 237,434
Cumulative Timesteps: 1,980,842,096

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63,220.84638
Policy Entropy: 2.26601
Value Function Loss: 0.02062

Mean KL Divergence: 0.00723
SB3 Clip Fraction: 0.06829
Policy Update Magnitude: 0.30841
Value Function Update Magnitude: 0.21909

Collected Steps per Second: 22,141.35597
Overall Steps per Second: 10,500.82144

Timestep Collection Time: 2.25975
Timestep Consumption Time: 2.50502
PPO Batch Consumption Time: 0.29036
Total Iteration Time: 4.76477

Cumulative Model Updates: 237,440
Cumulative Timesteps: 1,980,892,130

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1980892130...
Checkpoint 1980892130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46,556.52312
Policy Entropy: 2.27929
Value Function Loss: 0.02045

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.07751
Policy Update Magnitude: 0.30645
Value Function Update Magnitude: 0.19542

Collected Steps per Second: 21,953.39180
Overall Steps per Second: 10,586.33001

Timestep Collection Time: 2.27792
Timestep Consumption Time: 2.44591
PPO Batch Consumption Time: 0.27964
Total Iteration Time: 4.72383

Cumulative Model Updates: 237,446
Cumulative Timesteps: 1,980,942,138

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,988.83769
Policy Entropy: 2.29082
Value Function Loss: 0.01996

Mean KL Divergence: 0.00718
SB3 Clip Fraction: 0.06879
Policy Update Magnitude: 0.30041
Value Function Update Magnitude: 0.17446

Collected Steps per Second: 22,048.63423
Overall Steps per Second: 10,519.81297

Timestep Collection Time: 2.26817
Timestep Consumption Time: 2.48572
PPO Batch Consumption Time: 0.28821
Total Iteration Time: 4.75389

Cumulative Model Updates: 237,452
Cumulative Timesteps: 1,980,992,148

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1980992148...
Checkpoint 1980992148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,988.83769
Policy Entropy: 2.30955
Value Function Loss: 0.01806

Mean KL Divergence: 0.00720
SB3 Clip Fraction: 0.06794
Policy Update Magnitude: 0.29691
Value Function Update Magnitude: 0.19868

Collected Steps per Second: 21,719.80891
Overall Steps per Second: 10,572.62620

Timestep Collection Time: 2.30223
Timestep Consumption Time: 2.42734
PPO Batch Consumption Time: 0.27915
Total Iteration Time: 4.72957

Cumulative Model Updates: 237,458
Cumulative Timesteps: 1,981,042,152

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70,843.28878
Policy Entropy: 2.29756
Value Function Loss: 0.01903

Mean KL Divergence: 0.00745
SB3 Clip Fraction: 0.07303
Policy Update Magnitude: 0.29844
Value Function Update Magnitude: 0.23880

Collected Steps per Second: 21,857.84230
Overall Steps per Second: 10,586.61457

Timestep Collection Time: 2.28824
Timestep Consumption Time: 2.43622
PPO Batch Consumption Time: 0.27735
Total Iteration Time: 4.72446

Cumulative Model Updates: 237,464
Cumulative Timesteps: 1,981,092,168

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1981092168...
Checkpoint 1981092168 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 63,896.32533
Policy Entropy: 2.27884
Value Function Loss: 0.01992

Mean KL Divergence: 0.00728
SB3 Clip Fraction: 0.06981
Policy Update Magnitude: 0.31080
Value Function Update Magnitude: 0.28429

Collected Steps per Second: 21,206.23813
Overall Steps per Second: 10,314.91804

Timestep Collection Time: 2.35874
Timestep Consumption Time: 2.49055
PPO Batch Consumption Time: 0.28984
Total Iteration Time: 4.84929

Cumulative Model Updates: 237,470
Cumulative Timesteps: 1,981,142,188

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66,123.25985
Policy Entropy: 2.27008
Value Function Loss: 0.01936

Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.07397
Policy Update Magnitude: 0.30902
Value Function Update Magnitude: 0.32807

Collected Steps per Second: 21,107.81295
Overall Steps per Second: 10,486.56355

Timestep Collection Time: 2.37021
Timestep Consumption Time: 2.40065
PPO Batch Consumption Time: 0.28813
Total Iteration Time: 4.77087

Cumulative Model Updates: 237,476
Cumulative Timesteps: 1,981,192,218

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1981192218...
Checkpoint 1981192218 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 64,806.26219
Policy Entropy: 2.28743
Value Function Loss: 0.01843

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.07044
Policy Update Magnitude: 0.30181
Value Function Update Magnitude: 0.30361

Collected Steps per Second: 21,046.94438
Overall Steps per Second: 10,391.21916

Timestep Collection Time: 2.37764
Timestep Consumption Time: 2.43816
PPO Batch Consumption Time: 0.29335
Total Iteration Time: 4.81580

Cumulative Model Updates: 237,482
Cumulative Timesteps: 1,981,242,260

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,285.78181
Policy Entropy: 2.30531
Value Function Loss: 0.01727

Mean KL Divergence: 0.00699
SB3 Clip Fraction: 0.06783
Policy Update Magnitude: 0.29125
Value Function Update Magnitude: 0.27681

Collected Steps per Second: 19,847.48611
Overall Steps per Second: 10,021.39663

Timestep Collection Time: 2.51931
Timestep Consumption Time: 2.47021
PPO Batch Consumption Time: 0.29244
Total Iteration Time: 4.98952

Cumulative Model Updates: 237,488
Cumulative Timesteps: 1,981,292,262

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1981292262...
Checkpoint 1981292262 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 62,511.06232
Policy Entropy: 2.29580
Value Function Loss: 0.01995

Mean KL Divergence: 0.00711
SB3 Clip Fraction: 0.06849
Policy Update Magnitude: 0.30393
Value Function Update Magnitude: 0.28456

Collected Steps per Second: 21,107.86453
Overall Steps per Second: 10,265.53561

Timestep Collection Time: 2.36964
Timestep Consumption Time: 2.50278
PPO Batch Consumption Time: 0.29341
Total Iteration Time: 4.87242

Cumulative Model Updates: 237,494
Cumulative Timesteps: 1,981,342,280

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51,666.63777
Policy Entropy: 2.27261
Value Function Loss: 0.01932

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.07333
Policy Update Magnitude: 0.31148
Value Function Update Magnitude: 0.27769

Collected Steps per Second: 22,205.25889
Overall Steps per Second: 10,556.48836

Timestep Collection Time: 2.25244
Timestep Consumption Time: 2.48550
PPO Batch Consumption Time: 0.29076
Total Iteration Time: 4.73794

Cumulative Model Updates: 237,500
Cumulative Timesteps: 1,981,392,296

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1981392296...
Checkpoint 1981392296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,512.75029
Policy Entropy: 2.29174
Value Function Loss: 0.01884

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.08723
Policy Update Magnitude: 0.30467
Value Function Update Magnitude: 0.29214

Collected Steps per Second: 21,874.88320
Overall Steps per Second: 10,473.64255

Timestep Collection Time: 2.28765
Timestep Consumption Time: 2.49025
PPO Batch Consumption Time: 0.29319
Total Iteration Time: 4.77790

Cumulative Model Updates: 237,506
Cumulative Timesteps: 1,981,442,338

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46,003.71796
Policy Entropy: 2.29112
Value Function Loss: 0.01809

Mean KL Divergence: 0.00756
SB3 Clip Fraction: 0.07143
Policy Update Magnitude: 0.29595
Value Function Update Magnitude: 0.28438

Collected Steps per Second: 22,048.77752
Overall Steps per Second: 10,444.09712

Timestep Collection Time: 2.26861
Timestep Consumption Time: 2.52070
PPO Batch Consumption Time: 0.29243
Total Iteration Time: 4.78931

Cumulative Model Updates: 237,512
Cumulative Timesteps: 1,981,492,358

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1981492358...
Checkpoint 1981492358 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 63,299.17252
Policy Entropy: 2.29256
Value Function Loss: 0.02102

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.07928
Policy Update Magnitude: 0.30901
Value Function Update Magnitude: 0.27764

Collected Steps per Second: 22,023.55925
Overall Steps per Second: 10,629.15472

Timestep Collection Time: 2.27129
Timestep Consumption Time: 2.43482
PPO Batch Consumption Time: 0.28023
Total Iteration Time: 4.70611

Cumulative Model Updates: 237,518
Cumulative Timesteps: 1,981,542,380

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68,430.87421
Policy Entropy: 2.28507
Value Function Loss: 0.02016

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.07549
Policy Update Magnitude: 0.31034
Value Function Update Magnitude: 0.28323

Collected Steps per Second: 21,921.06568
Overall Steps per Second: 10,491.76935

Timestep Collection Time: 2.28264
Timestep Consumption Time: 2.48662
PPO Batch Consumption Time: 0.28855
Total Iteration Time: 4.76926

Cumulative Model Updates: 237,524
Cumulative Timesteps: 1,981,592,418

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1981592418...
Checkpoint 1981592418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,319.38650
Policy Entropy: 2.29261
Value Function Loss: 0.02376

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.06904
Policy Update Magnitude: 0.32184
Value Function Update Magnitude: 0.32828

Collected Steps per Second: 21,913.69150
Overall Steps per Second: 10,622.70807

Timestep Collection Time: 2.28350
Timestep Consumption Time: 2.42716
PPO Batch Consumption Time: 0.27893
Total Iteration Time: 4.71066

Cumulative Model Updates: 237,530
Cumulative Timesteps: 1,981,642,458

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53,277.50751
Policy Entropy: 2.31002
Value Function Loss: 0.02063

Mean KL Divergence: 0.00716
SB3 Clip Fraction: 0.06867
Policy Update Magnitude: 0.31799
Value Function Update Magnitude: 0.39757

Collected Steps per Second: 21,754.49483
Overall Steps per Second: 10,502.44759

Timestep Collection Time: 2.29865
Timestep Consumption Time: 2.46271
PPO Batch Consumption Time: 0.28422
Total Iteration Time: 4.76137

Cumulative Model Updates: 237,536
Cumulative Timesteps: 1,981,692,464

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1981692464...
Checkpoint 1981692464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,512.81690
Policy Entropy: 2.31689
Value Function Loss: 0.01962

Mean KL Divergence: 0.00714
SB3 Clip Fraction: 0.06956
Policy Update Magnitude: 0.30544
Value Function Update Magnitude: 0.38815

Collected Steps per Second: 21,213.99756
Overall Steps per Second: 10,298.92324

Timestep Collection Time: 2.35807
Timestep Consumption Time: 2.49914
PPO Batch Consumption Time: 0.29176
Total Iteration Time: 4.85721

Cumulative Model Updates: 237,542
Cumulative Timesteps: 1,981,742,488

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55,705.59974
Policy Entropy: 2.30332
Value Function Loss: 0.01950

Mean KL Divergence: 0.00679
SB3 Clip Fraction: 0.06844
Policy Update Magnitude: 0.30141
Value Function Update Magnitude: 0.32674

Collected Steps per Second: 21,497.50878
Overall Steps per Second: 10,347.23263

Timestep Collection Time: 2.32669
Timestep Consumption Time: 2.50726
PPO Batch Consumption Time: 0.29016
Total Iteration Time: 4.83395

Cumulative Model Updates: 237,548
Cumulative Timesteps: 1,981,792,506

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1981792506...
Checkpoint 1981792506 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55,705.59974
Policy Entropy: 2.29287
Value Function Loss: 0.01830

Mean KL Divergence: 0.00694
SB3 Clip Fraction: 0.06693
Policy Update Magnitude: 0.29840
Value Function Update Magnitude: 0.29147

Collected Steps per Second: 21,302.48429
Overall Steps per Second: 10,318.00902

Timestep Collection Time: 2.34836
Timestep Consumption Time: 2.50005
PPO Batch Consumption Time: 0.29220
Total Iteration Time: 4.84842

Cumulative Model Updates: 237,554
Cumulative Timesteps: 1,981,842,532

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55,495.15923
Policy Entropy: 2.28067
Value Function Loss: 0.01777

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.07318
Policy Update Magnitude: 0.29600
Value Function Update Magnitude: 0.28671

Collected Steps per Second: 22,080.91103
Overall Steps per Second: 10,460.64757

Timestep Collection Time: 2.26449
Timestep Consumption Time: 2.51552
PPO Batch Consumption Time: 0.29167
Total Iteration Time: 4.78001

Cumulative Model Updates: 237,560
Cumulative Timesteps: 1,981,892,534

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1981892534...
Checkpoint 1981892534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46,760.70769
Policy Entropy: 2.29202
Value Function Loss: 0.01688

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.08845
Policy Update Magnitude: 0.29563
Value Function Update Magnitude: 0.28644

Collected Steps per Second: 21,992.16357
Overall Steps per Second: 10,459.41409

Timestep Collection Time: 2.27417
Timestep Consumption Time: 2.50755
PPO Batch Consumption Time: 0.29002
Total Iteration Time: 4.78172

Cumulative Model Updates: 237,566
Cumulative Timesteps: 1,981,942,548

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60,706.24505
Policy Entropy: 2.29749
Value Function Loss: 0.01613

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.08559
Policy Update Magnitude: 0.29418
Value Function Update Magnitude: 0.26428

Collected Steps per Second: 22,019.34826
Overall Steps per Second: 10,510.98072

Timestep Collection Time: 2.27091
Timestep Consumption Time: 2.48640
PPO Batch Consumption Time: 0.28951
Total Iteration Time: 4.75731

Cumulative Model Updates: 237,572
Cumulative Timesteps: 1,981,992,552

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1981992552...
Checkpoint 1981992552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,216.38831
Policy Entropy: 2.32310
Value Function Loss: 0.01803

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.08946
Policy Update Magnitude: 0.29910
Value Function Update Magnitude: 0.24943

Collected Steps per Second: 21,979.00536
Overall Steps per Second: 10,661.96823

Timestep Collection Time: 2.27517
Timestep Consumption Time: 2.41496
PPO Batch Consumption Time: 0.27779
Total Iteration Time: 4.69013

Cumulative Model Updates: 237,578
Cumulative Timesteps: 1,982,042,558

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50,736.12396
Policy Entropy: 2.32749
Value Function Loss: 0.01838

Mean KL Divergence: 0.01150
SB3 Clip Fraction: 0.09521
Policy Update Magnitude: 0.30205
Value Function Update Magnitude: 0.26591

Collected Steps per Second: 22,147.96556
Overall Steps per Second: 10,484.99288

Timestep Collection Time: 2.25781
Timestep Consumption Time: 2.51148
PPO Batch Consumption Time: 0.29386
Total Iteration Time: 4.76929

Cumulative Model Updates: 237,584
Cumulative Timesteps: 1,982,092,564

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1982092564...
Checkpoint 1982092564 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 66,342.38147
Policy Entropy: 2.31863
Value Function Loss: 0.01998

Mean KL Divergence: 0.01127
SB3 Clip Fraction: 0.09431
Policy Update Magnitude: 0.30564
Value Function Update Magnitude: 0.29919

Collected Steps per Second: 21,620.75039
Overall Steps per Second: 10,526.41173

Timestep Collection Time: 2.31296
Timestep Consumption Time: 2.43775
PPO Batch Consumption Time: 0.27921
Total Iteration Time: 4.75072

Cumulative Model Updates: 237,590
Cumulative Timesteps: 1,982,142,572

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67,343.58616
Policy Entropy: 2.32242
Value Function Loss: 0.01847

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.08802
Policy Update Magnitude: 0.30494
Value Function Update Magnitude: 0.29361

Collected Steps per Second: 21,933.30008
Overall Steps per Second: 10,500.88675

Timestep Collection Time: 2.27973
Timestep Consumption Time: 2.48196
PPO Batch Consumption Time: 0.28601
Total Iteration Time: 4.76169

Cumulative Model Updates: 237,596
Cumulative Timesteps: 1,982,192,574

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1982192574...
Checkpoint 1982192574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 77,551.23847
Policy Entropy: 2.31791
Value Function Loss: 0.01856

Mean KL Divergence: 0.00760
SB3 Clip Fraction: 0.07288
Policy Update Magnitude: 0.31000
Value Function Update Magnitude: 0.29470

Collected Steps per Second: 20,474.19201
Overall Steps per Second: 10,263.98159

Timestep Collection Time: 2.44278
Timestep Consumption Time: 2.42999
PPO Batch Consumption Time: 0.29428
Total Iteration Time: 4.87277

Cumulative Model Updates: 237,602
Cumulative Timesteps: 1,982,242,588

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46,381.32825
Policy Entropy: 2.30290
Value Function Loss: 0.01940

Mean KL Divergence: 0.00750
SB3 Clip Fraction: 0.07278
Policy Update Magnitude: 0.30897
Value Function Update Magnitude: 0.29208

Collected Steps per Second: 21,055.76406
Overall Steps per Second: 10,391.27802

Timestep Collection Time: 2.37579
Timestep Consumption Time: 2.43825
PPO Batch Consumption Time: 0.29351
Total Iteration Time: 4.81404

Cumulative Model Updates: 237,608
Cumulative Timesteps: 1,982,292,612

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1982292612...
Checkpoint 1982292612 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,216.01531
Policy Entropy: 2.30152
Value Function Loss: 0.02031

Mean KL Divergence: 0.00772
SB3 Clip Fraction: 0.07181
Policy Update Magnitude: 0.31145
Value Function Update Magnitude: 0.29960

Collected Steps per Second: 20,810.95202
Overall Steps per Second: 10,388.63596

Timestep Collection Time: 2.40258
Timestep Consumption Time: 2.41037
PPO Batch Consumption Time: 0.28990
Total Iteration Time: 4.81295

Cumulative Model Updates: 237,614
Cumulative Timesteps: 1,982,342,612

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45,419.40790
Policy Entropy: 2.30717
Value Function Loss: 0.01955

Mean KL Divergence: 0.00782
SB3 Clip Fraction: 0.07607
Policy Update Magnitude: 0.31393
Value Function Update Magnitude: 0.30348

Collected Steps per Second: 20,966.39927
Overall Steps per Second: 10,251.05451

Timestep Collection Time: 2.38572
Timestep Consumption Time: 2.49378
PPO Batch Consumption Time: 0.29186
Total Iteration Time: 4.87950

Cumulative Model Updates: 237,620
Cumulative Timesteps: 1,982,392,632

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1982392632...
Checkpoint 1982392632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,807.30846
Policy Entropy: 2.31990
Value Function Loss: 0.01860

Mean KL Divergence: 0.00743
SB3 Clip Fraction: 0.07186
Policy Update Magnitude: 0.30647
Value Function Update Magnitude: 0.30068

Collected Steps per Second: 21,673.72466
Overall Steps per Second: 10,607.49943

Timestep Collection Time: 2.30823
Timestep Consumption Time: 2.40805
PPO Batch Consumption Time: 0.27879
Total Iteration Time: 4.71629

Cumulative Model Updates: 237,626
Cumulative Timesteps: 1,982,442,660

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42,873.17732
Policy Entropy: 2.29806
Value Function Loss: 0.01738

Mean KL Divergence: 0.00661
SB3 Clip Fraction: 0.06485
Policy Update Magnitude: 0.30108
Value Function Update Magnitude: 0.29517

Collected Steps per Second: 22,016.62909
Overall Steps per Second: 10,494.87718

Timestep Collection Time: 2.27328
Timestep Consumption Time: 2.49571
PPO Batch Consumption Time: 0.28951
Total Iteration Time: 4.76899

Cumulative Model Updates: 237,632
Cumulative Timesteps: 1,982,492,710

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 1982492710...
Checkpoint 1982492710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,346.06257
Policy Entropy: 2.28554
Value Function Loss: 0.01766

Mean KL Divergence: 0.00670
SB3 Clip Fraction: 0.06552
Policy Update Magnitude: 0.30898
Value Function Update Magnitude: 0.30946

Collected Steps per Second: 21,712.09553
Overall Steps per Second: 10,536.91546

Timestep Collection Time: 2.30379
Timestep Consumption Time: 2.44333
PPO Batch Consumption Time: 0.27894
Total Iteration Time: 4.74712

Cumulative Model Updates: 237,638
Cumulative Timesteps: 1,982,542,730

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58,579.25388
Policy Entropy: 2.30099
Value Function Loss: 0.01812

Mean KL Divergence: 0.00756
SB3 Clip Fraction: 0.07357
Policy Update Magnitude: 0.30927
Value Function Update Magnitude: 0.31132

Collected Steps per Second: 22,406.31886
Overall Steps per Second: 10,563.79524

Timestep Collection Time: 2.23392
Timestep Consumption Time: 2.50434
PPO Batch Consumption Time: 0.29135
Total Iteration Time: 4.73826

Cumulative Model Updates: 237,644
Cumulative Timesteps: 1,982,592,784

Timesteps Collected: 50,054
--------END ITERATION REPORT--------


Saving checkpoint 1982592784...
Checkpoint 1982592784 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86,455.58865
Policy Entropy: 2.31061
Value Function Loss: 0.01832

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.07438
Policy Update Magnitude: 0.30392
Value Function Update Magnitude: 0.30327

Collected Steps per Second: 21,851.86783
Overall Steps per Second: 10,614.07663

Timestep Collection Time: 2.28951
Timestep Consumption Time: 2.42404
PPO Batch Consumption Time: 0.27932
Total Iteration Time: 4.71355

Cumulative Model Updates: 237,650
Cumulative Timesteps: 1,982,642,814

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 121,175.15425
Policy Entropy: 2.30260
Value Function Loss: 0.02137

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.08807
Policy Update Magnitude: 0.30975
Value Function Update Magnitude: 0.30732

Collected Steps per Second: 22,098.64665
Overall Steps per Second: 10,454.20122

Timestep Collection Time: 2.26276
Timestep Consumption Time: 2.52039
PPO Batch Consumption Time: 0.29226
Total Iteration Time: 4.78315

Cumulative Model Updates: 237,656
Cumulative Timesteps: 1,982,692,818

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1982692818...
Checkpoint 1982692818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 92,732.71298
Policy Entropy: 2.29175
Value Function Loss: 0.02084

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.09148
Policy Update Magnitude: 0.31897
Value Function Update Magnitude: 0.32141

Collected Steps per Second: 21,657.60837
Overall Steps per Second: 10,557.28063

Timestep Collection Time: 2.30866
Timestep Consumption Time: 2.42741
PPO Batch Consumption Time: 0.27915
Total Iteration Time: 4.73607

Cumulative Model Updates: 237,662
Cumulative Timesteps: 1,982,742,818

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83,728.86255
Policy Entropy: 2.30330
Value Function Loss: 0.02256

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.08673
Policy Update Magnitude: 0.31800
Value Function Update Magnitude: 0.32700

Collected Steps per Second: 21,900.52565
Overall Steps per Second: 10,637.75167

Timestep Collection Time: 2.28378
Timestep Consumption Time: 2.41796
PPO Batch Consumption Time: 0.27659
Total Iteration Time: 4.70175

Cumulative Model Updates: 237,668
Cumulative Timesteps: 1,982,792,834

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1982792834...
Checkpoint 1982792834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55,210.81938
Policy Entropy: 2.30740
Value Function Loss: 0.02150

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.07927
Policy Update Magnitude: 0.31879
Value Function Update Magnitude: 0.33229

Collected Steps per Second: 21,153.12850
Overall Steps per Second: 10,292.61650

Timestep Collection Time: 2.36400
Timestep Consumption Time: 2.49443
PPO Batch Consumption Time: 0.29126
Total Iteration Time: 4.85843

Cumulative Model Updates: 237,674
Cumulative Timesteps: 1,982,842,840

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42,812.05365
Policy Entropy: 2.30824
Value Function Loss: 0.02013

Mean KL Divergence: 0.00733
SB3 Clip Fraction: 0.06871
Policy Update Magnitude: 0.31775
Value Function Update Magnitude: 0.33128

Collected Steps per Second: 21,540.24409
Overall Steps per Second: 10,367.47720

Timestep Collection Time: 2.32337
Timestep Consumption Time: 2.50384
PPO Batch Consumption Time: 0.29332
Total Iteration Time: 4.82721

Cumulative Model Updates: 237,680
Cumulative Timesteps: 1,982,892,886

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1982892886...
Checkpoint 1982892886 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,456.66237
Policy Entropy: 2.29886
Value Function Loss: 0.02020

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.06806
Policy Update Magnitude: 0.31177
Value Function Update Magnitude: 0.30234

Collected Steps per Second: 21,233.49224
Overall Steps per Second: 10,465.91544

Timestep Collection Time: 2.35628
Timestep Consumption Time: 2.42419
PPO Batch Consumption Time: 0.27861
Total Iteration Time: 4.78047

Cumulative Model Updates: 237,686
Cumulative Timesteps: 1,982,942,918

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42,153.31072
Policy Entropy: 2.30642
Value Function Loss: 0.01866

Mean KL Divergence: 0.00760
SB3 Clip Fraction: 0.07096
Policy Update Magnitude: 0.30737
Value Function Update Magnitude: 0.29561

Collected Steps per Second: 21,807.18046
Overall Steps per Second: 10,622.91035

Timestep Collection Time: 2.29301
Timestep Consumption Time: 2.41418
PPO Batch Consumption Time: 0.27677
Total Iteration Time: 4.70718

Cumulative Model Updates: 237,692
Cumulative Timesteps: 1,982,992,922

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1982992922...
Checkpoint 1982992922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 64,984.24431
Policy Entropy: 2.31684
Value Function Loss: 0.02109

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.07849
Policy Update Magnitude: 0.31773
Value Function Update Magnitude: 0.25924

Collected Steps per Second: 21,446.06727
Overall Steps per Second: 10,501.37341

Timestep Collection Time: 2.33292
Timestep Consumption Time: 2.43141
PPO Batch Consumption Time: 0.27810
Total Iteration Time: 4.76433

Cumulative Model Updates: 237,698
Cumulative Timesteps: 1,983,042,954

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59,345.04373
Policy Entropy: 2.32989
Value Function Loss: 0.02069

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.07892
Policy Update Magnitude: 0.31641
Value Function Update Magnitude: 0.29155

Collected Steps per Second: 22,342.37135
Overall Steps per Second: 10,457.09573

Timestep Collection Time: 2.23835
Timestep Consumption Time: 2.54405
PPO Batch Consumption Time: 0.28938
Total Iteration Time: 4.78240

Cumulative Model Updates: 237,704
Cumulative Timesteps: 1,983,092,964

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1983092964...
Checkpoint 1983092964 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,620.59173
Policy Entropy: 2.32204
Value Function Loss: 0.01947

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.09084
Policy Update Magnitude: 0.30781
Value Function Update Magnitude: 0.30132

Collected Steps per Second: 21,228.06288
Overall Steps per Second: 10,229.33514

Timestep Collection Time: 2.35594
Timestep Consumption Time: 2.53314
PPO Batch Consumption Time: 0.29442
Total Iteration Time: 4.88908

Cumulative Model Updates: 237,710
Cumulative Timesteps: 1,983,142,976

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,576.12526
Policy Entropy: 2.32376
Value Function Loss: 0.01839

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.07540
Policy Update Magnitude: 0.30475
Value Function Update Magnitude: 0.26920

Collected Steps per Second: 21,888.52399
Overall Steps per Second: 10,489.09270

Timestep Collection Time: 2.28476
Timestep Consumption Time: 2.48305
PPO Batch Consumption Time: 0.28682
Total Iteration Time: 4.76781

Cumulative Model Updates: 237,716
Cumulative Timesteps: 1,983,192,986

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1983192986...
Checkpoint 1983192986 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 50,581.87485
Policy Entropy: 2.29260
Value Function Loss: 0.01941

Mean KL Divergence: 0.00709
SB3 Clip Fraction: 0.07022
Policy Update Magnitude: 0.31099
Value Function Update Magnitude: 0.23733

Collected Steps per Second: 22,085.03639
Overall Steps per Second: 10,696.65994

Timestep Collection Time: 2.26651
Timestep Consumption Time: 2.41308
PPO Batch Consumption Time: 0.27730
Total Iteration Time: 4.67959

Cumulative Model Updates: 237,722
Cumulative Timesteps: 1,983,243,042

Timesteps Collected: 50,056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53,432.85570
Policy Entropy: 2.30544
Value Function Loss: 0.02401

Mean KL Divergence: 0.00680
SB3 Clip Fraction: 0.06389
Policy Update Magnitude: 0.32081
Value Function Update Magnitude: 0.19440

Collected Steps per Second: 21,479.59181
Overall Steps per Second: 10,549.98095

Timestep Collection Time: 2.32798
Timestep Consumption Time: 2.41175
PPO Batch Consumption Time: 0.28980
Total Iteration Time: 4.73972

Cumulative Model Updates: 237,728
Cumulative Timesteps: 1,983,293,046

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1983293046...
Checkpoint 1983293046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 50,263.79980
Policy Entropy: 2.30649
Value Function Loss: 0.02581

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.07895
Policy Update Magnitude: 0.32608
Value Function Update Magnitude: 0.21414

Collected Steps per Second: 21,199.07434
Overall Steps per Second: 10,475.85947

Timestep Collection Time: 2.35935
Timestep Consumption Time: 2.41506
PPO Batch Consumption Time: 0.28915
Total Iteration Time: 4.77441

Cumulative Model Updates: 237,734
Cumulative Timesteps: 1,983,343,062

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,153.97299
Policy Entropy: 2.33736
Value Function Loss: 0.02403

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.08078
Policy Update Magnitude: 0.32205
Value Function Update Magnitude: 0.27347

Collected Steps per Second: 21,420.18114
Overall Steps per Second: 10,491.78214

Timestep Collection Time: 2.33425
Timestep Consumption Time: 2.43139
PPO Batch Consumption Time: 0.29267
Total Iteration Time: 4.76563

Cumulative Model Updates: 237,740
Cumulative Timesteps: 1,983,393,062

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1983393062...
Checkpoint 1983393062 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,764.30038
Policy Entropy: 2.31205
Value Function Loss: 0.01946

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.07553
Policy Update Magnitude: 0.31403
Value Function Update Magnitude: 0.29091

Collected Steps per Second: 20,808.55926
Overall Steps per Second: 10,243.25059

Timestep Collection Time: 2.40440
Timestep Consumption Time: 2.47999
PPO Batch Consumption Time: 0.29391
Total Iteration Time: 4.88439

Cumulative Model Updates: 237,746
Cumulative Timesteps: 1,983,443,094

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,860.66274
Policy Entropy: 2.31935
Value Function Loss: 0.01768

Mean KL Divergence: 0.00737
SB3 Clip Fraction: 0.07017
Policy Update Magnitude: 0.30901
Value Function Update Magnitude: 0.27023

Collected Steps per Second: 21,486.88542
Overall Steps per Second: 10,370.84879

Timestep Collection Time: 2.32709
Timestep Consumption Time: 2.49431
PPO Batch Consumption Time: 0.29329
Total Iteration Time: 4.82140

Cumulative Model Updates: 237,752
Cumulative Timesteps: 1,983,493,096

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1983493096...
Checkpoint 1983493096 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,538.54785
Policy Entropy: 2.31157
Value Function Loss: 0.01802

Mean KL Divergence: 0.00674
SB3 Clip Fraction: 0.06620
Policy Update Magnitude: 0.30455
Value Function Update Magnitude: 0.26500

Collected Steps per Second: 20,998.73767
Overall Steps per Second: 10,284.28771

Timestep Collection Time: 2.38281
Timestep Consumption Time: 2.48248
PPO Batch Consumption Time: 0.29295
Total Iteration Time: 4.86529

Cumulative Model Updates: 237,758
Cumulative Timesteps: 1,983,543,132

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,805.27445
Policy Entropy: 2.31188
Value Function Loss: 0.01903

Mean KL Divergence: 0.00654
SB3 Clip Fraction: 0.06589
Policy Update Magnitude: 0.30895
Value Function Update Magnitude: 0.27665

Collected Steps per Second: 21,611.53781
Overall Steps per Second: 10,368.02960

Timestep Collection Time: 2.31423
Timestep Consumption Time: 2.50964
PPO Batch Consumption Time: 0.29293
Total Iteration Time: 4.82387

Cumulative Model Updates: 237,764
Cumulative Timesteps: 1,983,593,146

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1983593146...
Checkpoint 1983593146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,393.12842
Policy Entropy: 2.29788
Value Function Loss: 0.02063

Mean KL Divergence: 0.00716
SB3 Clip Fraction: 0.06526
Policy Update Magnitude: 0.31263
Value Function Update Magnitude: 0.26919

Collected Steps per Second: 21,682.15108
Overall Steps per Second: 10,573.51116

Timestep Collection Time: 2.30614
Timestep Consumption Time: 2.42285
PPO Batch Consumption Time: 0.27862
Total Iteration Time: 4.72899

Cumulative Model Updates: 237,770
Cumulative Timesteps: 1,983,643,148

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48,642.88708
Policy Entropy: 2.29167
Value Function Loss: 0.02100

Mean KL Divergence: 0.00736
SB3 Clip Fraction: 0.06707
Policy Update Magnitude: 0.31694
Value Function Update Magnitude: 0.23357

Collected Steps per Second: 22,343.17106
Overall Steps per Second: 10,500.53120

Timestep Collection Time: 2.23907
Timestep Consumption Time: 2.52526
PPO Batch Consumption Time: 0.28821
Total Iteration Time: 4.76433

Cumulative Model Updates: 237,776
Cumulative Timesteps: 1,983,693,176

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1983693176...
Checkpoint 1983693176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55,232.38238
Policy Entropy: 2.30498
Value Function Loss: 0.02297

Mean KL Divergence: 0.00696
SB3 Clip Fraction: 0.06660
Policy Update Magnitude: 0.32149
Value Function Update Magnitude: 0.21522

Collected Steps per Second: 21,502.71971
Overall Steps per Second: 10,334.85394

Timestep Collection Time: 2.32650
Timestep Consumption Time: 2.51402
PPO Batch Consumption Time: 0.29317
Total Iteration Time: 4.84051

Cumulative Model Updates: 237,782
Cumulative Timesteps: 1,983,743,202

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56,797.07026
Policy Entropy: 2.31161
Value Function Loss: 0.02250

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.07880
Policy Update Magnitude: 0.32853
Value Function Update Magnitude: 0.21167

Collected Steps per Second: 21,935.29067
Overall Steps per Second: 10,471.53206

Timestep Collection Time: 2.28080
Timestep Consumption Time: 2.49692
PPO Batch Consumption Time: 0.29310
Total Iteration Time: 4.77772

Cumulative Model Updates: 237,788
Cumulative Timesteps: 1,983,793,232

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1983793232...
Checkpoint 1983793232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,572.27132
Policy Entropy: 2.32161
Value Function Loss: 0.02276

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.08987
Policy Update Magnitude: 0.32565
Value Function Update Magnitude: 0.21048

Collected Steps per Second: 21,989.72035
Overall Steps per Second: 10,536.61572

Timestep Collection Time: 2.27570
Timestep Consumption Time: 2.47364
PPO Batch Consumption Time: 0.28827
Total Iteration Time: 4.74934

Cumulative Model Updates: 237,794
Cumulative Timesteps: 1,983,843,274

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,688.96090
Policy Entropy: 2.31462
Value Function Loss: 0.02305

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.07987
Policy Update Magnitude: 0.32047
Value Function Update Magnitude: 0.19542

Collected Steps per Second: 22,410.86530
Overall Steps per Second: 10,601.44365

Timestep Collection Time: 2.23240
Timestep Consumption Time: 2.48677
PPO Batch Consumption Time: 0.29096
Total Iteration Time: 4.71917

Cumulative Model Updates: 237,800
Cumulative Timesteps: 1,983,893,304

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1983893304...
Checkpoint 1983893304 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,503.58102
Policy Entropy: 2.30616
Value Function Loss: 0.02485

Mean KL Divergence: 0.01114
SB3 Clip Fraction: 0.09706
Policy Update Magnitude: 0.32564
Value Function Update Magnitude: 0.23706

Collected Steps per Second: 21,663.70686
Overall Steps per Second: 10,463.83556

Timestep Collection Time: 2.30893
Timestep Consumption Time: 2.47134
PPO Batch Consumption Time: 0.28783
Total Iteration Time: 4.78027

Cumulative Model Updates: 237,806
Cumulative Timesteps: 1,983,943,324

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,267.06371
Policy Entropy: 2.30164
Value Function Loss: 0.02426

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.09041
Policy Update Magnitude: 0.33375
Value Function Update Magnitude: 0.28437

Collected Steps per Second: 21,355.38705
Overall Steps per Second: 10,491.65657

Timestep Collection Time: 2.34255
Timestep Consumption Time: 2.42562
PPO Batch Consumption Time: 0.29308
Total Iteration Time: 4.76817

Cumulative Model Updates: 237,812
Cumulative Timesteps: 1,983,993,350

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1983993350...
Checkpoint 1983993350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,107.55024
Policy Entropy: 2.29027
Value Function Loss: 0.02418

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.08581
Policy Update Magnitude: 0.33881
Value Function Update Magnitude: 0.31542

Collected Steps per Second: 21,037.49004
Overall Steps per Second: 10,570.12822

Timestep Collection Time: 2.37756
Timestep Consumption Time: 2.35445
PPO Batch Consumption Time: 0.27864
Total Iteration Time: 4.73201

Cumulative Model Updates: 237,818
Cumulative Timesteps: 1,984,043,368

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55,101.84462
Policy Entropy: 2.29275
Value Function Loss: 0.02172

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.08868
Policy Update Magnitude: 0.32699
Value Function Update Magnitude: 0.33771

Collected Steps per Second: 21,107.11131
Overall Steps per Second: 10,474.37725

Timestep Collection Time: 2.37048
Timestep Consumption Time: 2.40632
PPO Batch Consumption Time: 0.28588
Total Iteration Time: 4.77680

Cumulative Model Updates: 237,824
Cumulative Timesteps: 1,984,093,402

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1984093402...
Checkpoint 1984093402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 50,080.22753
Policy Entropy: 2.31472
Value Function Loss: 0.01985

Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.07516
Policy Update Magnitude: 0.31339
Value Function Update Magnitude: 0.33811

Collected Steps per Second: 20,607.36607
Overall Steps per Second: 10,209.85039

Timestep Collection Time: 2.42729
Timestep Consumption Time: 2.47190
PPO Batch Consumption Time: 0.28862
Total Iteration Time: 4.89919

Cumulative Model Updates: 237,830
Cumulative Timesteps: 1,984,143,422

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45,341.89473
Policy Entropy: 2.33128
Value Function Loss: 0.02009

Mean KL Divergence: 0.00740
SB3 Clip Fraction: 0.07270
Policy Update Magnitude: 0.31275
Value Function Update Magnitude: 0.31784

Collected Steps per Second: 21,398.28232
Overall Steps per Second: 10,469.53081

Timestep Collection Time: 2.33785
Timestep Consumption Time: 2.44040
PPO Batch Consumption Time: 0.27931
Total Iteration Time: 4.77825

Cumulative Model Updates: 237,836
Cumulative Timesteps: 1,984,193,448

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1984193448...
Checkpoint 1984193448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 73,409.63427
Policy Entropy: 2.33138
Value Function Loss: 0.01932

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.07682
Policy Update Magnitude: 0.31940
Value Function Update Magnitude: 0.31489

Collected Steps per Second: 21,699.50472
Overall Steps per Second: 10,302.50742

Timestep Collection Time: 2.30494
Timestep Consumption Time: 2.54980
PPO Batch Consumption Time: 0.29290
Total Iteration Time: 4.85474

Cumulative Model Updates: 237,842
Cumulative Timesteps: 1,984,243,464

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60,844.03357
Policy Entropy: 2.32123
Value Function Loss: 0.01916

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.08575
Policy Update Magnitude: 0.31056
Value Function Update Magnitude: 0.28174

Collected Steps per Second: 21,749.76465
Overall Steps per Second: 10,450.87612

Timestep Collection Time: 2.29979
Timestep Consumption Time: 2.48641
PPO Batch Consumption Time: 0.29256
Total Iteration Time: 4.78620

Cumulative Model Updates: 237,848
Cumulative Timesteps: 1,984,293,484

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1984293484...
Checkpoint 1984293484 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 70,971.74522
Policy Entropy: 2.32142
Value Function Loss: 0.01861

Mean KL Divergence: 0.00722
SB3 Clip Fraction: 0.06934
Policy Update Magnitude: 0.30732
Value Function Update Magnitude: 0.24359

Collected Steps per Second: 21,973.95464
Overall Steps per Second: 10,516.41695

Timestep Collection Time: 2.27651
Timestep Consumption Time: 2.48024
PPO Batch Consumption Time: 0.28611
Total Iteration Time: 4.75675

Cumulative Model Updates: 237,854
Cumulative Timesteps: 1,984,343,508

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 69,710.04431
Policy Entropy: 2.32141
Value Function Loss: 0.01986

Mean KL Divergence: 0.00674
SB3 Clip Fraction: 0.06643
Policy Update Magnitude: 0.31185
Value Function Update Magnitude: 0.22199

Collected Steps per Second: 21,977.97661
Overall Steps per Second: 10,472.22493

Timestep Collection Time: 2.27682
Timestep Consumption Time: 2.50153
PPO Batch Consumption Time: 0.29108
Total Iteration Time: 4.77835

Cumulative Model Updates: 237,860
Cumulative Timesteps: 1,984,393,548

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1984393548...
Checkpoint 1984393548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 69,710.04431
Policy Entropy: 2.30146
Value Function Loss: 0.01791

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.07545
Policy Update Magnitude: 0.30631
Value Function Update Magnitude: 0.19742

Collected Steps per Second: 21,912.55887
Overall Steps per Second: 10,570.92548

Timestep Collection Time: 2.28307
Timestep Consumption Time: 2.44953
PPO Batch Consumption Time: 0.28094
Total Iteration Time: 4.73260

Cumulative Model Updates: 237,866
Cumulative Timesteps: 1,984,443,576

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49,126.86495
Policy Entropy: 2.30351
Value Function Loss: 0.01909

Mean KL Divergence: 0.00727
SB3 Clip Fraction: 0.06814
Policy Update Magnitude: 0.30155
Value Function Update Magnitude: 0.15317

Collected Steps per Second: 21,884.06076
Overall Steps per Second: 10,605.66991

Timestep Collection Time: 2.28596
Timestep Consumption Time: 2.43095
PPO Batch Consumption Time: 0.27798
Total Iteration Time: 4.71691

Cumulative Model Updates: 237,872
Cumulative Timesteps: 1,984,493,602

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1984493602...
Checkpoint 1984493602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,520.40119
Policy Entropy: 2.30183
Value Function Loss: 0.02161

Mean KL Divergence: 0.00677
SB3 Clip Fraction: 0.06506
Policy Update Magnitude: 0.30975
Value Function Update Magnitude: 0.14258

Collected Steps per Second: 22,106.88159
Overall Steps per Second: 10,564.62856

Timestep Collection Time: 2.26373
Timestep Consumption Time: 2.47321
PPO Batch Consumption Time: 0.28637
Total Iteration Time: 4.73694

Cumulative Model Updates: 237,878
Cumulative Timesteps: 1,984,543,646

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45,450.32400
Policy Entropy: 2.31436
Value Function Loss: 0.02840

Mean KL Divergence: 0.00752
SB3 Clip Fraction: 0.07185
Policy Update Magnitude: 0.32982
Value Function Update Magnitude: 0.20300

Collected Steps per Second: 21,177.66404
Overall Steps per Second: 10,407.32525

Timestep Collection Time: 2.36230
Timestep Consumption Time: 2.44470
PPO Batch Consumption Time: 0.27886
Total Iteration Time: 4.80700

Cumulative Model Updates: 237,884
Cumulative Timesteps: 1,984,593,674

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1984593674...
Checkpoint 1984593674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,824.11728
Policy Entropy: 2.30869
Value Function Loss: 0.02826

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.08535
Policy Update Magnitude: 0.33631
Value Function Update Magnitude: 0.30773

Collected Steps per Second: 21,432.09357
Overall Steps per Second: 10,321.18524

Timestep Collection Time: 2.33360
Timestep Consumption Time: 2.51216
PPO Batch Consumption Time: 0.29340
Total Iteration Time: 4.84576

Cumulative Model Updates: 237,890
Cumulative Timesteps: 1,984,643,688

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,627.09676
Policy Entropy: 2.29897
Value Function Loss: 0.02544

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.08260
Policy Update Magnitude: 0.33387
Value Function Update Magnitude: 0.33818

Collected Steps per Second: 21,463.42870
Overall Steps per Second: 10,373.43925

Timestep Collection Time: 2.33122
Timestep Consumption Time: 2.49225
PPO Batch Consumption Time: 0.28835
Total Iteration Time: 4.82347

Cumulative Model Updates: 237,896
Cumulative Timesteps: 1,984,693,724

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1984693724...
Checkpoint 1984693724 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55,638.59847
Policy Entropy: 2.28483
Value Function Loss: 0.02205

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.07976
Policy Update Magnitude: 0.32926
Value Function Update Magnitude: 0.33103

Collected Steps per Second: 21,437.91462
Overall Steps per Second: 10,467.85636

Timestep Collection Time: 2.33241
Timestep Consumption Time: 2.44431
PPO Batch Consumption Time: 0.27756
Total Iteration Time: 4.77672

Cumulative Model Updates: 237,902
Cumulative Timesteps: 1,984,743,726

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55,529.18072
Policy Entropy: 2.26092
Value Function Loss: 0.02009

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.08101
Policy Update Magnitude: 0.32122
Value Function Update Magnitude: 0.33612

Collected Steps per Second: 22,037.46307
Overall Steps per Second: 10,372.19329

Timestep Collection Time: 2.26886
Timestep Consumption Time: 2.55172
PPO Batch Consumption Time: 0.29187
Total Iteration Time: 4.82058

Cumulative Model Updates: 237,908
Cumulative Timesteps: 1,984,793,726

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1984793726...
Checkpoint 1984793726 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 107,227.80725
Policy Entropy: 2.28229
Value Function Loss: 0.02094

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.08069
Policy Update Magnitude: 0.31702
Value Function Update Magnitude: 0.31252

Collected Steps per Second: 21,907.56296
Overall Steps per Second: 10,593.93329

Timestep Collection Time: 2.28414
Timestep Consumption Time: 2.43932
PPO Batch Consumption Time: 0.27885
Total Iteration Time: 4.72346

Cumulative Model Updates: 237,914
Cumulative Timesteps: 1,984,843,766

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79,018.52003
Policy Entropy: 2.29134
Value Function Loss: 0.02090

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.09372
Policy Update Magnitude: 0.31291
Value Function Update Magnitude: 0.30978

Collected Steps per Second: 21,961.86838
Overall Steps per Second: 10,472.50743

Timestep Collection Time: 2.27813
Timestep Consumption Time: 2.49933
PPO Batch Consumption Time: 0.28817
Total Iteration Time: 4.77746

Cumulative Model Updates: 237,920
Cumulative Timesteps: 1,984,893,798

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1984893798...
Checkpoint 1984893798 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 56,939.15379
Policy Entropy: 2.29068
Value Function Loss: 0.02097

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.08135
Policy Update Magnitude: 0.31691
Value Function Update Magnitude: 0.32111

Collected Steps per Second: 21,657.37053
Overall Steps per Second: 10,571.11081

Timestep Collection Time: 2.31053
Timestep Consumption Time: 2.42313
PPO Batch Consumption Time: 0.27904
Total Iteration Time: 4.73366

Cumulative Model Updates: 237,926
Cumulative Timesteps: 1,984,943,838

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,889.76071
Policy Entropy: 2.27466
Value Function Loss: 0.02314

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.07905
Policy Update Magnitude: 0.32551
Value Function Update Magnitude: 0.33967

Collected Steps per Second: 21,837.42096
Overall Steps per Second: 10,608.91805

Timestep Collection Time: 2.29075
Timestep Consumption Time: 2.42453
PPO Batch Consumption Time: 0.27775
Total Iteration Time: 4.71528

Cumulative Model Updates: 237,932
Cumulative Timesteps: 1,984,993,862

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1984993862...
Checkpoint 1984993862 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,608.07650
Policy Entropy: 2.24851
Value Function Loss: 0.02224

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.08540
Policy Update Magnitude: 0.32980
Value Function Update Magnitude: 0.34931

Collected Steps per Second: 20,934.03481
Overall Steps per Second: 10,219.89718

Timestep Collection Time: 2.38922
Timestep Consumption Time: 2.50476
PPO Batch Consumption Time: 0.29347
Total Iteration Time: 4.89398

Cumulative Model Updates: 237,938
Cumulative Timesteps: 1,985,043,878

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56,871.08446
Policy Entropy: 2.24353
Value Function Loss: 0.02414

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.08598
Policy Update Magnitude: 0.32699
Value Function Update Magnitude: 0.33082

Collected Steps per Second: 21,937.12075
Overall Steps per Second: 10,417.91239

Timestep Collection Time: 2.27979
Timestep Consumption Time: 2.52079
PPO Batch Consumption Time: 0.29405
Total Iteration Time: 4.80058

Cumulative Model Updates: 237,944
Cumulative Timesteps: 1,985,093,890

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1985093890...
Checkpoint 1985093890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46,480.46223
Policy Entropy: 2.24514
Value Function Loss: 0.02109

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.09098
Policy Update Magnitude: 0.31936
Value Function Update Magnitude: 0.30600

Collected Steps per Second: 21,609.14474
Overall Steps per Second: 10,545.93458

Timestep Collection Time: 2.31485
Timestep Consumption Time: 2.42840
PPO Batch Consumption Time: 0.27843
Total Iteration Time: 4.74325

Cumulative Model Updates: 237,950
Cumulative Timesteps: 1,985,143,912

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,243.63950
Policy Entropy: 2.26202
Value Function Loss: 0.02017

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.08671
Policy Update Magnitude: 0.31039
Value Function Update Magnitude: 0.30630

Collected Steps per Second: 21,448.84454
Overall Steps per Second: 10,473.04356

Timestep Collection Time: 2.33215
Timestep Consumption Time: 2.44411
PPO Batch Consumption Time: 0.27851
Total Iteration Time: 4.77626

Cumulative Model Updates: 237,956
Cumulative Timesteps: 1,985,193,934

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1985193934...
Checkpoint 1985193934 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,721.60887
Policy Entropy: 2.27216
Value Function Loss: 0.01954

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.07490
Policy Update Magnitude: 0.30254
Value Function Update Magnitude: 0.28923

Collected Steps per Second: 21,552.11020
Overall Steps per Second: 10,396.29730

Timestep Collection Time: 2.32228
Timestep Consumption Time: 2.49194
PPO Batch Consumption Time: 0.29189
Total Iteration Time: 4.81421

Cumulative Model Updates: 237,962
Cumulative Timesteps: 1,985,243,984

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57,367.30456
Policy Entropy: 2.26551
Value Function Loss: 0.02066

Mean KL Divergence: 0.00706
SB3 Clip Fraction: 0.06698
Policy Update Magnitude: 0.30493
Value Function Update Magnitude: 0.30519

Collected Steps per Second: 21,776.43982
Overall Steps per Second: 10,367.22701

Timestep Collection Time: 2.29643
Timestep Consumption Time: 2.52724
PPO Batch Consumption Time: 0.29299
Total Iteration Time: 4.82366

Cumulative Model Updates: 237,968
Cumulative Timesteps: 1,985,293,992

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1985293992...
Checkpoint 1985293992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 65,946.97225
Policy Entropy: 2.26287
Value Function Loss: 0.02091

Mean KL Divergence: 0.00681
SB3 Clip Fraction: 0.06480
Policy Update Magnitude: 0.31656
Value Function Update Magnitude: 0.30870

Collected Steps per Second: 21,773.27127
Overall Steps per Second: 10,475.46728

Timestep Collection Time: 2.29777
Timestep Consumption Time: 2.47815
PPO Batch Consumption Time: 0.27843
Total Iteration Time: 4.77592

Cumulative Model Updates: 237,974
Cumulative Timesteps: 1,985,344,022

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51,710.80035
Policy Entropy: 2.27164
Value Function Loss: 0.02134

Mean KL Divergence: 0.00703
SB3 Clip Fraction: 0.06723
Policy Update Magnitude: 0.32075
Value Function Update Magnitude: 0.27984

Collected Steps per Second: 21,925.41387
Overall Steps per Second: 10,591.45516

Timestep Collection Time: 2.28064
Timestep Consumption Time: 2.44052
PPO Batch Consumption Time: 0.27776
Total Iteration Time: 4.72116

Cumulative Model Updates: 237,980
Cumulative Timesteps: 1,985,394,026

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1985394026...
Checkpoint 1985394026 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47,491.92572
Policy Entropy: 2.26029
Value Function Loss: 0.02152

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.07563
Policy Update Magnitude: 0.32323
Value Function Update Magnitude: 0.28805

Collected Steps per Second: 21,874.52428
Overall Steps per Second: 10,608.80388

Timestep Collection Time: 2.28668
Timestep Consumption Time: 2.42827
PPO Batch Consumption Time: 0.27836
Total Iteration Time: 4.71495

Cumulative Model Updates: 237,986
Cumulative Timesteps: 1,985,444,046

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65,989.00829
Policy Entropy: 2.27128
Value Function Loss: 0.02067

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.07753
Policy Update Magnitude: 0.31588
Value Function Update Magnitude: 0.26957

Collected Steps per Second: 22,261.44307
Overall Steps per Second: 10,482.57395

Timestep Collection Time: 2.24693
Timestep Consumption Time: 2.52479
PPO Batch Consumption Time: 0.29323
Total Iteration Time: 4.77173

Cumulative Model Updates: 237,992
Cumulative Timesteps: 1,985,494,066

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1985494066...
Checkpoint 1985494066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48,204.20655
Policy Entropy: 2.25380
Value Function Loss: 0.02371

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.09014
Policy Update Magnitude: 0.31993
Value Function Update Magnitude: 0.32803

Collected Steps per Second: 21,993.60705
Overall Steps per Second: 10,581.42123

Timestep Collection Time: 2.27366
Timestep Consumption Time: 2.45217
PPO Batch Consumption Time: 0.28415
Total Iteration Time: 4.72583

Cumulative Model Updates: 237,998
Cumulative Timesteps: 1,985,544,072

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,807.26274
Policy Entropy: 2.26304
Value Function Loss: 0.02208

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.08828
Policy Update Magnitude: 0.31719
Value Function Update Magnitude: 0.34990

Collected Steps per Second: 22,060.37944
Overall Steps per Second: 10,461.79230

Timestep Collection Time: 2.26651
Timestep Consumption Time: 2.51279
PPO Batch Consumption Time: 0.29473
Total Iteration Time: 4.77930

Cumulative Model Updates: 238,004
Cumulative Timesteps: 1,985,594,072

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1985594072...
Checkpoint 1985594072 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,641.03251
Policy Entropy: 2.24976
Value Function Loss: 0.02054

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.08838
Policy Update Magnitude: 0.31092
Value Function Update Magnitude: 0.30953

Collected Steps per Second: 21,971.52472
Overall Steps per Second: 10,637.02017

Timestep Collection Time: 2.27585
Timestep Consumption Time: 2.42509
PPO Batch Consumption Time: 0.27949
Total Iteration Time: 4.70094

Cumulative Model Updates: 238,010
Cumulative Timesteps: 1,985,644,076

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,449.09190
Policy Entropy: 2.26533
Value Function Loss: 0.01732

Mean KL Divergence: 0.00744
SB3 Clip Fraction: 0.07301
Policy Update Magnitude: 0.30767
Value Function Update Magnitude: 0.29351

Collected Steps per Second: 20,778.91999
Overall Steps per Second: 10,517.20377

Timestep Collection Time: 2.40754
Timestep Consumption Time: 2.34905
PPO Batch Consumption Time: 0.27737
Total Iteration Time: 4.75659

Cumulative Model Updates: 238,016
Cumulative Timesteps: 1,985,694,102

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1985694102...
Checkpoint 1985694102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40,571.93941
Policy Entropy: 2.27580
Value Function Loss: 0.01753

Mean KL Divergence: 0.00750
SB3 Clip Fraction: 0.06901
Policy Update Magnitude: 0.30320
Value Function Update Magnitude: 0.30020

Collected Steps per Second: 20,889.43269
Overall Steps per Second: 10,527.17654

Timestep Collection Time: 2.39490
Timestep Consumption Time: 2.35738
PPO Batch Consumption Time: 0.27910
Total Iteration Time: 4.75227

Cumulative Model Updates: 238,022
Cumulative Timesteps: 1,985,744,130

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50,690.43303
Policy Entropy: 2.29361
Value Function Loss: 0.01997

Mean KL Divergence: 0.00682
SB3 Clip Fraction: 0.06393
Policy Update Magnitude: 0.31145
Value Function Update Magnitude: 0.29854

Collected Steps per Second: 20,826.68507
Overall Steps per Second: 10,494.10826

Timestep Collection Time: 2.40163
Timestep Consumption Time: 2.36466
PPO Batch Consumption Time: 0.27848
Total Iteration Time: 4.76629

Cumulative Model Updates: 238,028
Cumulative Timesteps: 1,985,794,148

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1985794148...
Checkpoint 1985794148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,457.97531
Policy Entropy: 2.27874
Value Function Loss: 0.02092

Mean KL Divergence: 0.00667
SB3 Clip Fraction: 0.06400
Policy Update Magnitude: 0.31744
Value Function Update Magnitude: 0.30109

Collected Steps per Second: 20,269.15276
Overall Steps per Second: 10,279.12490

Timestep Collection Time: 2.46809
Timestep Consumption Time: 2.39867
PPO Batch Consumption Time: 0.27748
Total Iteration Time: 4.86676

Cumulative Model Updates: 238,034
Cumulative Timesteps: 1,985,844,174

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49,333.07743
Policy Entropy: 2.25233
Value Function Loss: 0.02111

Mean KL Divergence: 0.00782
SB3 Clip Fraction: 0.07017
Policy Update Magnitude: 0.31491
Value Function Update Magnitude: 0.30520

Collected Steps per Second: 21,618.97146
Overall Steps per Second: 10,388.59870

Timestep Collection Time: 2.31297
Timestep Consumption Time: 2.50039
PPO Batch Consumption Time: 0.29143
Total Iteration Time: 4.81335

Cumulative Model Updates: 238,040
Cumulative Timesteps: 1,985,894,178

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1985894178...
Checkpoint 1985894178 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47,897.08802
Policy Entropy: 2.24301
Value Function Loss: 0.02023

Mean KL Divergence: 0.00752
SB3 Clip Fraction: 0.06889
Policy Update Magnitude: 0.31902
Value Function Update Magnitude: 0.35193

Collected Steps per Second: 21,629.46557
Overall Steps per Second: 10,371.57383

Timestep Collection Time: 2.31268
Timestep Consumption Time: 2.51031
PPO Batch Consumption Time: 0.29009
Total Iteration Time: 4.82299

Cumulative Model Updates: 238,046
Cumulative Timesteps: 1,985,944,200

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47,585.20625
Policy Entropy: 2.26001
Value Function Loss: 0.01842

Mean KL Divergence: 0.00770
SB3 Clip Fraction: 0.07291
Policy Update Magnitude: 0.31648
Value Function Update Magnitude: 0.37549

Collected Steps per Second: 22,126.11131
Overall Steps per Second: 10,649.71164

Timestep Collection Time: 2.25977
Timestep Consumption Time: 2.43519
PPO Batch Consumption Time: 0.27888
Total Iteration Time: 4.69496

Cumulative Model Updates: 238,052
Cumulative Timesteps: 1,985,994,200

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1985994200...
Checkpoint 1985994200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 58,746.81164
Policy Entropy: 2.28093
Value Function Loss: 0.01776

Mean KL Divergence: 0.00707
SB3 Clip Fraction: 0.06683
Policy Update Magnitude: 0.30674
Value Function Update Magnitude: 0.34572

Collected Steps per Second: 21,798.49379
Overall Steps per Second: 10,463.90115

Timestep Collection Time: 2.29566
Timestep Consumption Time: 2.48668
PPO Batch Consumption Time: 0.29018
Total Iteration Time: 4.78235

Cumulative Model Updates: 238,058
Cumulative Timesteps: 1,986,044,242

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55,593.46298
Policy Entropy: 2.28285
Value Function Loss: 0.01779

Mean KL Divergence: 0.00692
SB3 Clip Fraction: 0.06472
Policy Update Magnitude: 0.30437
Value Function Update Magnitude: 0.30432

Collected Steps per Second: 22,170.23723
Overall Steps per Second: 10,655.00705

Timestep Collection Time: 2.25591
Timestep Consumption Time: 2.43804
PPO Batch Consumption Time: 0.27983
Total Iteration Time: 4.69394

Cumulative Model Updates: 238,064
Cumulative Timesteps: 1,986,094,256

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1986094256...
Checkpoint 1986094256 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,334.33417
Policy Entropy: 2.27211
Value Function Loss: 0.01747

Mean KL Divergence: 0.00763
SB3 Clip Fraction: 0.07182
Policy Update Magnitude: 0.30085
Value Function Update Magnitude: 0.29702

Collected Steps per Second: 21,929.58243
Overall Steps per Second: 10,622.73322

Timestep Collection Time: 2.28240
Timestep Consumption Time: 2.42939
PPO Batch Consumption Time: 0.27913
Total Iteration Time: 4.71178

Cumulative Model Updates: 238,070
Cumulative Timesteps: 1,986,144,308

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49,334.33417
Policy Entropy: 2.25645
Value Function Loss: 0.01647

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.08110
Policy Update Magnitude: 0.29482
Value Function Update Magnitude: 0.28792

Collected Steps per Second: 22,070.81820
Overall Steps per Second: 10,547.38958

Timestep Collection Time: 2.26743
Timestep Consumption Time: 2.47725
PPO Batch Consumption Time: 0.28710
Total Iteration Time: 4.74468

Cumulative Model Updates: 238,076
Cumulative Timesteps: 1,986,194,352

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1986194352...
Checkpoint 1986194352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48,217.74004
Policy Entropy: 2.25277
Value Function Loss: 0.01636

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.08893
Policy Update Magnitude: 0.29328
Value Function Update Magnitude: 0.23625

Collected Steps per Second: 21,614.59364
Overall Steps per Second: 10,555.66283

Timestep Collection Time: 2.31445
Timestep Consumption Time: 2.42480
PPO Batch Consumption Time: 0.27880
Total Iteration Time: 4.73926

Cumulative Model Updates: 238,082
Cumulative Timesteps: 1,986,244,378

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 71,105.27149
Policy Entropy: 2.26006
Value Function Loss: 0.02120

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.08161
Policy Update Magnitude: 0.30787
Value Function Update Magnitude: 0.23011

Collected Steps per Second: 21,478.40934
Overall Steps per Second: 10,527.55673

Timestep Collection Time: 2.32997
Timestep Consumption Time: 2.42365
PPO Batch Consumption Time: 0.27892
Total Iteration Time: 4.75362

Cumulative Model Updates: 238,088
Cumulative Timesteps: 1,986,294,422

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1986294422...
Checkpoint 1986294422 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40,434.16000
Policy Entropy: 2.26434
Value Function Loss: 0.02328

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.07786
Policy Update Magnitude: 0.32463
Value Function Update Magnitude: 0.25051

Collected Steps per Second: 21,328.56299
Overall Steps per Second: 10,314.20418

Timestep Collection Time: 2.34493
Timestep Consumption Time: 2.50411
PPO Batch Consumption Time: 0.29213
Total Iteration Time: 4.84904

Cumulative Model Updates: 238,094
Cumulative Timesteps: 1,986,344,436

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,541.67539
Policy Entropy: 2.27250
Value Function Loss: 0.02181

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.07434
Policy Update Magnitude: 0.32342
Value Function Update Magnitude: 0.28576

Collected Steps per Second: 21,827.30881
Overall Steps per Second: 10,435.17801

Timestep Collection Time: 2.29162
Timestep Consumption Time: 2.50178
PPO Batch Consumption Time: 0.29347
Total Iteration Time: 4.79340

Cumulative Model Updates: 238,100
Cumulative Timesteps: 1,986,394,456

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1986394456...
Checkpoint 1986394456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43,188.85609
Policy Entropy: 2.27103
Value Function Loss: 0.02240

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.07937
Policy Update Magnitude: 0.32162
Value Function Update Magnitude: 0.35930

Collected Steps per Second: 21,437.87555
Overall Steps per Second: 10,494.16026

Timestep Collection Time: 2.33307
Timestep Consumption Time: 2.43301
PPO Batch Consumption Time: 0.27882
Total Iteration Time: 4.76608

Cumulative Model Updates: 238,106
Cumulative Timesteps: 1,986,444,472

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53,275.99989
Policy Entropy: 2.27966
Value Function Loss: 0.02257

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.07715
Policy Update Magnitude: 0.32678
Value Function Update Magnitude: 0.40071

Collected Steps per Second: 21,909.69185
Overall Steps per Second: 10,560.73758

Timestep Collection Time: 2.28255
Timestep Consumption Time: 2.45291
PPO Batch Consumption Time: 0.27803
Total Iteration Time: 4.73546

Cumulative Model Updates: 238,112
Cumulative Timesteps: 1,986,494,482

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1986494482...
Checkpoint 1986494482 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,252.60375
Policy Entropy: 2.26709
Value Function Loss: 0.02219

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.07558
Policy Update Magnitude: 0.32679
Value Function Update Magnitude: 0.39144

Collected Steps per Second: 21,629.78665
Overall Steps per Second: 10,308.48108

Timestep Collection Time: 2.31283
Timestep Consumption Time: 2.54007
PPO Batch Consumption Time: 0.29127
Total Iteration Time: 4.85290

Cumulative Model Updates: 238,118
Cumulative Timesteps: 1,986,544,508

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67,878.29626
Policy Entropy: 2.25699
Value Function Loss: 0.02132

Mean KL Divergence: 0.00750
SB3 Clip Fraction: 0.06766
Policy Update Magnitude: 0.32258
Value Function Update Magnitude: 0.36038

Collected Steps per Second: 22,451.24818
Overall Steps per Second: 10,700.72182

Timestep Collection Time: 2.22740
Timestep Consumption Time: 2.44593
PPO Batch Consumption Time: 0.27873
Total Iteration Time: 4.67333

Cumulative Model Updates: 238,124
Cumulative Timesteps: 1,986,594,516

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1986594516...
Checkpoint 1986594516 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 59,300.85826
Policy Entropy: 2.24752
Value Function Loss: 0.01941

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.06980
Policy Update Magnitude: 0.32082
Value Function Update Magnitude: 0.34543

Collected Steps per Second: 21,627.50196
Overall Steps per Second: 10,419.54720

Timestep Collection Time: 2.31243
Timestep Consumption Time: 2.48740
PPO Batch Consumption Time: 0.29129
Total Iteration Time: 4.79982

Cumulative Model Updates: 238,130
Cumulative Timesteps: 1,986,644,528

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53,911.97393
Policy Entropy: 2.23432
Value Function Loss: 0.02415

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.07481
Policy Update Magnitude: 0.32888
Value Function Update Magnitude: 0.35075

Collected Steps per Second: 22,302.53699
Overall Steps per Second: 10,678.87399

Timestep Collection Time: 2.24306
Timestep Consumption Time: 2.44151
PPO Batch Consumption Time: 0.27995
Total Iteration Time: 4.68458

Cumulative Model Updates: 238,136
Cumulative Timesteps: 1,986,694,554

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1986694554...
Checkpoint 1986694554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,605.94193
Policy Entropy: 2.23400
Value Function Loss: 0.02339

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.07476
Policy Update Magnitude: 0.34066
Value Function Update Magnitude: 0.36759

Collected Steps per Second: 21,835.39435
Overall Steps per Second: 10,601.23079

Timestep Collection Time: 2.29114
Timestep Consumption Time: 2.42793
PPO Batch Consumption Time: 0.27834
Total Iteration Time: 4.71907

Cumulative Model Updates: 238,142
Cumulative Timesteps: 1,986,744,582

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54,759.13381
Policy Entropy: 2.25649
Value Function Loss: 0.02415

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.07126
Policy Update Magnitude: 0.33242
Value Function Update Magnitude: 0.34417

Collected Steps per Second: 21,633.44629
Overall Steps per Second: 10,475.99403

Timestep Collection Time: 2.31216
Timestep Consumption Time: 2.46257
PPO Batch Consumption Time: 0.27893
Total Iteration Time: 4.77473

Cumulative Model Updates: 238,148
Cumulative Timesteps: 1,986,794,602

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1986794602...
Checkpoint 1986794602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48,462.08093
Policy Entropy: 2.27632
Value Function Loss: 0.01978

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.07029
Policy Update Magnitude: 0.31734
Value Function Update Magnitude: 0.31774

Collected Steps per Second: 21,389.33155
Overall Steps per Second: 10,331.03215

Timestep Collection Time: 2.33846
Timestep Consumption Time: 2.50307
PPO Batch Consumption Time: 0.29275
Total Iteration Time: 4.84153

Cumulative Model Updates: 238,154
Cumulative Timesteps: 1,986,844,620

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,178.26057
Policy Entropy: 2.28173
Value Function Loss: 0.01966

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.07600
Policy Update Magnitude: 0.30582
Value Function Update Magnitude: 0.30481

Collected Steps per Second: 21,022.07743
Overall Steps per Second: 10,386.71182

Timestep Collection Time: 2.37845
Timestep Consumption Time: 2.43539
PPO Batch Consumption Time: 0.29426
Total Iteration Time: 4.81384

Cumulative Model Updates: 238,160
Cumulative Timesteps: 1,986,894,620

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1986894620...
Checkpoint 1986894620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,936.38499
Policy Entropy: 2.27014
Value Function Loss: 0.01872

Mean KL Divergence: 0.00741
SB3 Clip Fraction: 0.07271
Policy Update Magnitude: 0.30510
Value Function Update Magnitude: 0.31152

Collected Steps per Second: 20,380.72398
Overall Steps per Second: 10,200.17918

Timestep Collection Time: 2.45477
Timestep Consumption Time: 2.45005
PPO Batch Consumption Time: 0.29400
Total Iteration Time: 4.90482

Cumulative Model Updates: 238,166
Cumulative Timesteps: 1,986,944,650

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46,521.55337
Policy Entropy: 2.24251
Value Function Loss: 0.01824

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.07541
Policy Update Magnitude: 0.30598
Value Function Update Magnitude: 0.33108

Collected Steps per Second: 20,669.72744
Overall Steps per Second: 10,458.47850

Timestep Collection Time: 2.41919
Timestep Consumption Time: 2.36200
PPO Batch Consumption Time: 0.27887
Total Iteration Time: 4.78119

Cumulative Model Updates: 238,172
Cumulative Timesteps: 1,986,994,654

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1986994654...
Checkpoint 1986994654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 60,830.31218
Policy Entropy: 2.22621
Value Function Loss: 0.01825

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.08229
Policy Update Magnitude: 0.30843
Value Function Update Magnitude: 0.32328

Collected Steps per Second: 21,034.84682
Overall Steps per Second: 10,371.33395

Timestep Collection Time: 2.37720
Timestep Consumption Time: 2.44417
PPO Batch Consumption Time: 0.29035
Total Iteration Time: 4.82137

Cumulative Model Updates: 238,178
Cumulative Timesteps: 1,987,044,658

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46,460.80868
Policy Entropy: 2.24257
Value Function Loss: 0.02002

Mean KL Divergence: 0.01117
SB3 Clip Fraction: 0.09641
Policy Update Magnitude: 0.31412
Value Function Update Magnitude: 0.32159

Collected Steps per Second: 21,603.90794
Overall Steps per Second: 10,414.72318

Timestep Collection Time: 2.31588
Timestep Consumption Time: 2.48809
PPO Batch Consumption Time: 0.29184
Total Iteration Time: 4.80397

Cumulative Model Updates: 238,184
Cumulative Timesteps: 1,987,094,690

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1987094690...
Checkpoint 1987094690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 61,770.54363
Policy Entropy: 2.24777
Value Function Loss: 0.02264

Mean KL Divergence: 0.01176
SB3 Clip Fraction: 0.09550
Policy Update Magnitude: 0.31556
Value Function Update Magnitude: 0.33758

Collected Steps per Second: 21,717.94783
Overall Steps per Second: 10,474.98050

Timestep Collection Time: 2.30409
Timestep Consumption Time: 2.47301
PPO Batch Consumption Time: 0.28855
Total Iteration Time: 4.77710

Cumulative Model Updates: 238,190
Cumulative Timesteps: 1,987,144,730

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,391.33007
Policy Entropy: 2.26669
Value Function Loss: 0.02106

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.09158
Policy Update Magnitude: 0.32175
Value Function Update Magnitude: 0.34567

Collected Steps per Second: 22,072.35496
Overall Steps per Second: 10,506.25797

Timestep Collection Time: 2.26618
Timestep Consumption Time: 2.49479
PPO Batch Consumption Time: 0.29467
Total Iteration Time: 4.76097

Cumulative Model Updates: 238,196
Cumulative Timesteps: 1,987,194,750

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1987194750...
Checkpoint 1987194750 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,703.01192
Policy Entropy: 2.25166
Value Function Loss: 0.02116

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.08521
Policy Update Magnitude: 0.32167
Value Function Update Magnitude: 0.36013

Collected Steps per Second: 21,580.38387
Overall Steps per Second: 10,548.62526

Timestep Collection Time: 2.31905
Timestep Consumption Time: 2.42526
PPO Batch Consumption Time: 0.27863
Total Iteration Time: 4.74431

Cumulative Model Updates: 238,202
Cumulative Timesteps: 1,987,244,796

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,510.51832
Policy Entropy: 2.24863
Value Function Loss: 0.01782

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.08278
Policy Update Magnitude: 0.31399
Value Function Update Magnitude: 0.34941

Collected Steps per Second: 22,159.68782
Overall Steps per Second: 10,517.72454

Timestep Collection Time: 2.25689
Timestep Consumption Time: 2.49813
PPO Batch Consumption Time: 0.28919
Total Iteration Time: 4.75502

Cumulative Model Updates: 238,208
Cumulative Timesteps: 1,987,294,808

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1987294808...
Checkpoint 1987294808 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,510.51832
Policy Entropy: 2.23063
Value Function Loss: 0.01710

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.08988
Policy Update Magnitude: 0.30392
Value Function Update Magnitude: 0.32759

Collected Steps per Second: 21,872.72601
Overall Steps per Second: 10,575.86650

Timestep Collection Time: 2.28687
Timestep Consumption Time: 2.44277
PPO Batch Consumption Time: 0.27855
Total Iteration Time: 4.72964

Cumulative Model Updates: 238,214
Cumulative Timesteps: 1,987,344,828

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,528.27905
Policy Entropy: 2.23728
Value Function Loss: 0.01796

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.08516
Policy Update Magnitude: 0.31263
Value Function Update Magnitude: 0.31739

Collected Steps per Second: 21,398.22769
Overall Steps per Second: 10,484.78959

Timestep Collection Time: 2.33804
Timestep Consumption Time: 2.43363
PPO Batch Consumption Time: 0.27880
Total Iteration Time: 4.77167

Cumulative Model Updates: 238,220
Cumulative Timesteps: 1,987,394,858

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1987394858...
Checkpoint 1987394858 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,895.37115
Policy Entropy: 2.23718
Value Function Loss: 0.01776

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.07958
Policy Update Magnitude: 0.31700
Value Function Update Magnitude: 0.34005

Collected Steps per Second: 21,478.25547
Overall Steps per Second: 10,374.11973

Timestep Collection Time: 2.32896
Timestep Consumption Time: 2.49285
PPO Batch Consumption Time: 0.29178
Total Iteration Time: 4.82181

Cumulative Model Updates: 238,226
Cumulative Timesteps: 1,987,444,880

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,371.88413
Policy Entropy: 2.24666
Value Function Loss: 0.01908

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.08114
Policy Update Magnitude: 0.32249
Value Function Update Magnitude: 0.31223

Collected Steps per Second: 21,654.06730
Overall Steps per Second: 10,376.38675

Timestep Collection Time: 2.31079
Timestep Consumption Time: 2.51151
PPO Batch Consumption Time: 0.29396
Total Iteration Time: 4.82230

Cumulative Model Updates: 238,232
Cumulative Timesteps: 1,987,494,918

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1987494918...
Checkpoint 1987494918 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 66,588.61368
Policy Entropy: 2.24814
Value Function Loss: 0.02058

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.08140
Policy Update Magnitude: 0.32271
Value Function Update Magnitude: 0.33676

Collected Steps per Second: 21,424.66940
Overall Steps per Second: 10,503.93758

Timestep Collection Time: 2.33413
Timestep Consumption Time: 2.42675
PPO Batch Consumption Time: 0.27882
Total Iteration Time: 4.76088

Cumulative Model Updates: 238,238
Cumulative Timesteps: 1,987,544,926

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46,233.44969
Policy Entropy: 2.28069
Value Function Loss: 0.02035

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.08337
Policy Update Magnitude: 0.31278
Value Function Update Magnitude: 0.34952

Collected Steps per Second: 21,632.27571
Overall Steps per Second: 10,553.72045

Timestep Collection Time: 2.31192
Timestep Consumption Time: 2.42689
PPO Batch Consumption Time: 0.28626
Total Iteration Time: 4.73880

Cumulative Model Updates: 238,244
Cumulative Timesteps: 1,987,594,938

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1987594938...
Checkpoint 1987594938 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55,762.13008
Policy Entropy: 2.28808
Value Function Loss: 0.02044

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.09090
Policy Update Magnitude: 0.30264
Value Function Update Magnitude: 0.33009

Collected Steps per Second: 21,069.39631
Overall Steps per Second: 10,555.23333

Timestep Collection Time: 2.37453
Timestep Consumption Time: 2.36529
PPO Batch Consumption Time: 0.27938
Total Iteration Time: 4.73983

Cumulative Model Updates: 238,250
Cumulative Timesteps: 1,987,644,968

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61,011.53104
Policy Entropy: 2.27981
Value Function Loss: 0.02035

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.09500
Policy Update Magnitude: 0.30211
Value Function Update Magnitude: 0.31822

Collected Steps per Second: 21,528.69306
Overall Steps per Second: 10,588.50521

Timestep Collection Time: 2.32276
Timestep Consumption Time: 2.39991
PPO Batch Consumption Time: 0.27789
Total Iteration Time: 4.72267

Cumulative Model Updates: 238,256
Cumulative Timesteps: 1,987,694,974

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1987694974...
Checkpoint 1987694974 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 71,833.57443
Policy Entropy: 2.25850
Value Function Loss: 0.02030

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.09260
Policy Update Magnitude: 0.30782
Value Function Update Magnitude: 0.33141

Collected Steps per Second: 21,693.11919
Overall Steps per Second: 10,571.22319

Timestep Collection Time: 2.30515
Timestep Consumption Time: 2.42523
PPO Batch Consumption Time: 0.28091
Total Iteration Time: 4.73039

Cumulative Model Updates: 238,262
Cumulative Timesteps: 1,987,744,980

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86,575.02277
Policy Entropy: 2.24759
Value Function Loss: 0.01961

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.08549
Policy Update Magnitude: 0.31225
Value Function Update Magnitude: 0.35750

Collected Steps per Second: 22,024.94490
Overall Steps per Second: 10,537.24398

Timestep Collection Time: 2.27106
Timestep Consumption Time: 2.47591
PPO Batch Consumption Time: 0.29379
Total Iteration Time: 4.74697

Cumulative Model Updates: 238,268
Cumulative Timesteps: 1,987,795,000

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1987795000...
Checkpoint 1987795000 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,050.46475
Policy Entropy: 2.24930
Value Function Loss: 0.01900

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.08150
Policy Update Magnitude: 0.31913
Value Function Update Magnitude: 0.36772

Collected Steps per Second: 21,888.57932
Overall Steps per Second: 10,574.69826

Timestep Collection Time: 2.28548
Timestep Consumption Time: 2.44524
PPO Batch Consumption Time: 0.28716
Total Iteration Time: 4.73073

Cumulative Model Updates: 238,274
Cumulative Timesteps: 1,987,845,026

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42,574.45661
Policy Entropy: 2.25212
Value Function Loss: 0.01738

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.07527
Policy Update Magnitude: 0.31511
Value Function Update Magnitude: 0.34661

Collected Steps per Second: 21,435.35764
Overall Steps per Second: 10,515.66762

Timestep Collection Time: 2.33446
Timestep Consumption Time: 2.42415
PPO Batch Consumption Time: 0.27748
Total Iteration Time: 4.75861

Cumulative Model Updates: 238,280
Cumulative Timesteps: 1,987,895,066

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1987895066...
Checkpoint 1987895066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,906.97191
Policy Entropy: 2.25258
Value Function Loss: 0.01837

Mean KL Divergence: 0.00737
SB3 Clip Fraction: 0.06854
Policy Update Magnitude: 0.30492
Value Function Update Magnitude: 0.31732

Collected Steps per Second: 21,652.37336
Overall Steps per Second: 10,529.58837

Timestep Collection Time: 2.31032
Timestep Consumption Time: 2.44048
PPO Batch Consumption Time: 0.27991
Total Iteration Time: 4.75080

Cumulative Model Updates: 238,286
Cumulative Timesteps: 1,987,945,090

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,570.47266
Policy Entropy: 2.24789
Value Function Loss: 0.02016

Mean KL Divergence: 0.00641
SB3 Clip Fraction: 0.06176
Policy Update Magnitude: 0.30865
Value Function Update Magnitude: 0.30501

Collected Steps per Second: 21,706.76137
Overall Steps per Second: 10,562.57917

Timestep Collection Time: 2.30454
Timestep Consumption Time: 2.43143
PPO Batch Consumption Time: 0.27712
Total Iteration Time: 4.73596

Cumulative Model Updates: 238,292
Cumulative Timesteps: 1,987,995,114

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1987995114...
Checkpoint 1987995114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,767.14756
Policy Entropy: 2.22444
Value Function Loss: 0.02140

Mean KL Divergence: 0.00662
SB3 Clip Fraction: 0.06278
Policy Update Magnitude: 0.32042
Value Function Update Magnitude: 0.30450

Collected Steps per Second: 21,286.84845
Overall Steps per Second: 10,278.81100

Timestep Collection Time: 2.35018
Timestep Consumption Time: 2.51692
PPO Batch Consumption Time: 0.29174
Total Iteration Time: 4.86710

Cumulative Model Updates: 238,298
Cumulative Timesteps: 1,988,045,142

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53,499.20426
Policy Entropy: 2.23367
Value Function Loss: 0.02193

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.07373
Policy Update Magnitude: 0.33012
Value Function Update Magnitude: 0.32991

Collected Steps per Second: 22,113.35418
Overall Steps per Second: 10,471.28138

Timestep Collection Time: 2.26117
Timestep Consumption Time: 2.51399
PPO Batch Consumption Time: 0.29062
Total Iteration Time: 4.77516

Cumulative Model Updates: 238,304
Cumulative Timesteps: 1,988,095,144

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1988095144...
Checkpoint 1988095144 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 83,482.35233
Policy Entropy: 2.22883
Value Function Loss: 0.01982

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.07987
Policy Update Magnitude: 0.32272
Value Function Update Magnitude: 0.32103

Collected Steps per Second: 21,875.26393
Overall Steps per Second: 10,448.50654

Timestep Collection Time: 2.28633
Timestep Consumption Time: 2.50039
PPO Batch Consumption Time: 0.28827
Total Iteration Time: 4.78671

Cumulative Model Updates: 238,310
Cumulative Timesteps: 1,988,145,158

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,094.08476
Policy Entropy: 2.24250
Value Function Loss: 0.02169

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.08452
Policy Update Magnitude: 0.32211
Value Function Update Magnitude: 0.30479

Collected Steps per Second: 21,883.70171
Overall Steps per Second: 10,484.80974

Timestep Collection Time: 2.28490
Timestep Consumption Time: 2.48410
PPO Batch Consumption Time: 0.28630
Total Iteration Time: 4.76899

Cumulative Model Updates: 238,316
Cumulative Timesteps: 1,988,195,160

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1988195160...
Checkpoint 1988195160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,327.13054
Policy Entropy: 2.23671
Value Function Loss: 0.02123

Mean KL Divergence: 0.01123
SB3 Clip Fraction: 0.09675
Policy Update Magnitude: 0.32354
Value Function Update Magnitude: 0.30226

Collected Steps per Second: 22,039.12246
Overall Steps per Second: 10,604.84486

Timestep Collection Time: 2.26951
Timestep Consumption Time: 2.44701
PPO Batch Consumption Time: 0.28104
Total Iteration Time: 4.71652

Cumulative Model Updates: 238,322
Cumulative Timesteps: 1,988,245,178

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,311.54318
Policy Entropy: 2.24824
Value Function Loss: 0.02083

Mean KL Divergence: 0.01061
SB3 Clip Fraction: 0.09130
Policy Update Magnitude: 0.31980
Value Function Update Magnitude: 0.31069

Collected Steps per Second: 21,778.56922
Overall Steps per Second: 10,458.83814

Timestep Collection Time: 2.29712
Timestep Consumption Time: 2.48620
PPO Batch Consumption Time: 0.28870
Total Iteration Time: 4.78332

Cumulative Model Updates: 238,328
Cumulative Timesteps: 1,988,295,206

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1988295206...
Checkpoint 1988295206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,722.98748
Policy Entropy: 2.25028
Value Function Loss: 0.01956

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.08474
Policy Update Magnitude: 0.32806
Value Function Update Magnitude: 0.32486

Collected Steps per Second: 21,334.97289
Overall Steps per Second: 10,631.81625

Timestep Collection Time: 2.34469
Timestep Consumption Time: 2.36043
PPO Batch Consumption Time: 0.27873
Total Iteration Time: 4.70512

Cumulative Model Updates: 238,334
Cumulative Timesteps: 1,988,345,230

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,722.98748
Policy Entropy: 2.23794
Value Function Loss: 0.01850

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.08155
Policy Update Magnitude: 0.32778
Value Function Update Magnitude: 0.34151

Collected Steps per Second: 21,471.14314
Overall Steps per Second: 10,488.80242

Timestep Collection Time: 2.33076
Timestep Consumption Time: 2.44043
PPO Batch Consumption Time: 0.29217
Total Iteration Time: 4.77118

Cumulative Model Updates: 238,340
Cumulative Timesteps: 1,988,395,274

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1988395274...
Checkpoint 1988395274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 61,122.07920
Policy Entropy: 2.23003
Value Function Loss: 0.01841

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.08346
Policy Update Magnitude: 0.31759
Value Function Update Magnitude: 0.33534

Collected Steps per Second: 20,719.04067
Overall Steps per Second: 10,325.53060

Timestep Collection Time: 2.41440
Timestep Consumption Time: 2.43029
PPO Batch Consumption Time: 0.29263
Total Iteration Time: 4.84469

Cumulative Model Updates: 238,346
Cumulative Timesteps: 1,988,445,298

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54,111.06876
Policy Entropy: 2.22154
Value Function Loss: 0.01886

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.07806
Policy Update Magnitude: 0.31502
Value Function Update Magnitude: 0.31556

Collected Steps per Second: 21,106.67377
Overall Steps per Second: 10,306.92919

Timestep Collection Time: 2.36996
Timestep Consumption Time: 2.48328
PPO Batch Consumption Time: 0.29059
Total Iteration Time: 4.85324

Cumulative Model Updates: 238,352
Cumulative Timesteps: 1,988,495,320

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1988495320...
Checkpoint 1988495320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55,141.48768
Policy Entropy: 2.23665
Value Function Loss: 0.02118

Mean KL Divergence: 0.00762
SB3 Clip Fraction: 0.07109
Policy Update Magnitude: 0.32815
Value Function Update Magnitude: 0.35243

Collected Steps per Second: 21,282.28761
Overall Steps per Second: 10,292.17356

Timestep Collection Time: 2.35012
Timestep Consumption Time: 2.50949
PPO Batch Consumption Time: 0.29334
Total Iteration Time: 4.85961

Cumulative Model Updates: 238,358
Cumulative Timesteps: 1,988,545,336

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48,175.30757
Policy Entropy: 2.23156
Value Function Loss: 0.02031

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.07081
Policy Update Magnitude: 0.32490
Value Function Update Magnitude: 0.35700

Collected Steps per Second: 22,017.38542
Overall Steps per Second: 10,461.69170

Timestep Collection Time: 2.27148
Timestep Consumption Time: 2.50901
PPO Batch Consumption Time: 0.29334
Total Iteration Time: 4.78049

Cumulative Model Updates: 238,364
Cumulative Timesteps: 1,988,595,348

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1988595348...
Checkpoint 1988595348 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,663.35063
Policy Entropy: 2.23195
Value Function Loss: 0.02054

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.06993
Policy Update Magnitude: 0.31660
Value Function Update Magnitude: 0.33495

Collected Steps per Second: 22,148.09113
Overall Steps per Second: 10,548.28201

Timestep Collection Time: 2.25789
Timestep Consumption Time: 2.48297
PPO Batch Consumption Time: 0.29108
Total Iteration Time: 4.74087

Cumulative Model Updates: 238,370
Cumulative Timesteps: 1,988,645,356

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,765.04330
Policy Entropy: 2.23544
Value Function Loss: 0.02105

Mean KL Divergence: 0.00717
SB3 Clip Fraction: 0.06994
Policy Update Magnitude: 0.31533
Value Function Update Magnitude: 0.30516

Collected Steps per Second: 22,206.88736
Overall Steps per Second: 10,487.86150

Timestep Collection Time: 2.25209
Timestep Consumption Time: 2.51647
PPO Batch Consumption Time: 0.29386
Total Iteration Time: 4.76856

Cumulative Model Updates: 238,376
Cumulative Timesteps: 1,988,695,368

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1988695368...
Checkpoint 1988695368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,620.06753
Policy Entropy: 2.23938
Value Function Loss: 0.02240

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.07481
Policy Update Magnitude: 0.32353
Value Function Update Magnitude: 0.29895

Collected Steps per Second: 22,221.85985
Overall Steps per Second: 10,601.30481

Timestep Collection Time: 2.25058
Timestep Consumption Time: 2.46696
PPO Batch Consumption Time: 0.28562
Total Iteration Time: 4.71753

Cumulative Model Updates: 238,382
Cumulative Timesteps: 1,988,745,380

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,413.27925
Policy Entropy: 2.23461
Value Function Loss: 0.02130

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.07586
Policy Update Magnitude: 0.32323
Value Function Update Magnitude: 0.28805

Collected Steps per Second: 21,138.03787
Overall Steps per Second: 10,373.93456

Timestep Collection Time: 2.36815
Timestep Consumption Time: 2.45722
PPO Batch Consumption Time: 0.27910
Total Iteration Time: 4.82536

Cumulative Model Updates: 238,388
Cumulative Timesteps: 1,988,795,438

Timesteps Collected: 50,058
--------END ITERATION REPORT--------


Saving checkpoint 1988795438...
Checkpoint 1988795438 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 56,441.39484
Policy Entropy: 2.22957
Value Function Loss: 0.02066

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.07530
Policy Update Magnitude: 0.31922
Value Function Update Magnitude: 0.28642

Collected Steps per Second: 21,784.68300
Overall Steps per Second: 10,400.91859

Timestep Collection Time: 2.29620
Timestep Consumption Time: 2.51318
PPO Batch Consumption Time: 0.29266
Total Iteration Time: 4.80938

Cumulative Model Updates: 238,394
Cumulative Timesteps: 1,988,845,460

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56,966.88418
Policy Entropy: 2.22205
Value Function Loss: 0.02054

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.08477
Policy Update Magnitude: 0.32543
Value Function Update Magnitude: 0.30212

Collected Steps per Second: 21,866.40870
Overall Steps per Second: 10,436.86464

Timestep Collection Time: 2.28698
Timestep Consumption Time: 2.50450
PPO Batch Consumption Time: 0.29360
Total Iteration Time: 4.79148

Cumulative Model Updates: 238,400
Cumulative Timesteps: 1,988,895,468

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1988895468...
Checkpoint 1988895468 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,650.02120
Policy Entropy: 2.22546
Value Function Loss: 0.02108

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.08784
Policy Update Magnitude: 0.32261
Value Function Update Magnitude: 0.32453

Collected Steps per Second: 21,516.80997
Overall Steps per Second: 10,501.66556

Timestep Collection Time: 2.32553
Timestep Consumption Time: 2.43924
PPO Batch Consumption Time: 0.27908
Total Iteration Time: 4.76477

Cumulative Model Updates: 238,406
Cumulative Timesteps: 1,988,945,506

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51,656.53585
Policy Entropy: 2.22074
Value Function Loss: 0.02120

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.08764
Policy Update Magnitude: 0.31904
Value Function Update Magnitude: 0.33367

Collected Steps per Second: 21,455.35876
Overall Steps per Second: 10,516.69113

Timestep Collection Time: 2.33079
Timestep Consumption Time: 2.42431
PPO Batch Consumption Time: 0.27875
Total Iteration Time: 4.75511

Cumulative Model Updates: 238,412
Cumulative Timesteps: 1,988,995,514

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1988995514...
Checkpoint 1988995514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 61,031.20038
Policy Entropy: 2.23103
Value Function Loss: 0.02199

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.07833
Policy Update Magnitude: 0.32496
Value Function Update Magnitude: 0.33073

Collected Steps per Second: 21,465.26248
Overall Steps per Second: 10,558.04315

Timestep Collection Time: 2.33046
Timestep Consumption Time: 2.40754
PPO Batch Consumption Time: 0.27832
Total Iteration Time: 4.73800

Cumulative Model Updates: 238,418
Cumulative Timesteps: 1,989,045,538

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85,683.51339
Policy Entropy: 2.24133
Value Function Loss: 0.02036

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.08066
Policy Update Magnitude: 0.32378
Value Function Update Magnitude: 0.31334

Collected Steps per Second: 21,410.68712
Overall Steps per Second: 10,470.24239

Timestep Collection Time: 2.33724
Timestep Consumption Time: 2.44221
PPO Batch Consumption Time: 0.27865
Total Iteration Time: 4.77945

Cumulative Model Updates: 238,424
Cumulative Timesteps: 1,989,095,580

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1989095580...
Checkpoint 1989095580 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 65,381.61848
Policy Entropy: 2.24607
Value Function Loss: 0.01949

Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.07737
Policy Update Magnitude: 0.31773
Value Function Update Magnitude: 0.32783

Collected Steps per Second: 20,858.32769
Overall Steps per Second: 10,362.00085

Timestep Collection Time: 2.39712
Timestep Consumption Time: 2.42820
PPO Batch Consumption Time: 0.29290
Total Iteration Time: 4.82532

Cumulative Model Updates: 238,430
Cumulative Timesteps: 1,989,145,580

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82,461.10854
Policy Entropy: 2.24485
Value Function Loss: 0.01771

Mean KL Divergence: 0.00729
SB3 Clip Fraction: 0.06891
Policy Update Magnitude: 0.30930
Value Function Update Magnitude: 0.31770

Collected Steps per Second: 21,494.15910
Overall Steps per Second: 10,471.59468

Timestep Collection Time: 2.32668
Timestep Consumption Time: 2.44910
PPO Batch Consumption Time: 0.29243
Total Iteration Time: 4.77578

Cumulative Model Updates: 238,436
Cumulative Timesteps: 1,989,195,590

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1989195590...
Checkpoint 1989195590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 119,806.22904
Policy Entropy: 2.24244
Value Function Loss: 0.01973

Mean KL Divergence: 0.00756
SB3 Clip Fraction: 0.07067
Policy Update Magnitude: 0.31928
Value Function Update Magnitude: 0.32556

Collected Steps per Second: 21,436.08117
Overall Steps per Second: 10,504.35564

Timestep Collection Time: 2.33364
Timestep Consumption Time: 2.42858
PPO Batch Consumption Time: 0.28978
Total Iteration Time: 4.76222

Cumulative Model Updates: 238,442
Cumulative Timesteps: 1,989,245,614

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75,452.68747
Policy Entropy: 2.22622
Value Function Loss: 0.02191

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.07227
Policy Update Magnitude: 0.32615
Value Function Update Magnitude: 0.37146

Collected Steps per Second: 21,240.96918
Overall Steps per Second: 10,441.01580

Timestep Collection Time: 2.35451
Timestep Consumption Time: 2.43545
PPO Batch Consumption Time: 0.29231
Total Iteration Time: 4.78996

Cumulative Model Updates: 238,448
Cumulative Timesteps: 1,989,295,626

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1989295626...
Checkpoint 1989295626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 52,687.54810
Policy Entropy: 2.22590
Value Function Loss: 0.02177

Mean KL Divergence: 0.01278
SB3 Clip Fraction: 0.07748
Policy Update Magnitude: 0.33613
Value Function Update Magnitude: 0.38303

Collected Steps per Second: 21,325.81798
Overall Steps per Second: 10,383.46193

Timestep Collection Time: 2.34542
Timestep Consumption Time: 2.47166
PPO Batch Consumption Time: 0.29148
Total Iteration Time: 4.81708

Cumulative Model Updates: 238,454
Cumulative Timesteps: 1,989,345,644

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59,184.05850
Policy Entropy: 2.23900
Value Function Loss: 0.02147

Mean KL Divergence: 0.01607
SB3 Clip Fraction: 0.07707
Policy Update Magnitude: 0.33219
Value Function Update Magnitude: 0.34818

Collected Steps per Second: 21,973.23325
Overall Steps per Second: 10,684.10693

Timestep Collection Time: 2.27595
Timestep Consumption Time: 2.40483
PPO Batch Consumption Time: 0.27925
Total Iteration Time: 4.68078

Cumulative Model Updates: 238,460
Cumulative Timesteps: 1,989,395,654

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1989395654...
Checkpoint 1989395654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55,977.12567
Policy Entropy: 2.24833
Value Function Loss: 0.02111

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.07720
Policy Update Magnitude: 0.32720
Value Function Update Magnitude: 0.34698

Collected Steps per Second: 21,784.34897
Overall Steps per Second: 10,615.62384

Timestep Collection Time: 2.29614
Timestep Consumption Time: 2.41578
PPO Batch Consumption Time: 0.27925
Total Iteration Time: 4.71192

Cumulative Model Updates: 238,466
Cumulative Timesteps: 1,989,445,674

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47,680.97732
Policy Entropy: 2.24639
Value Function Loss: 0.02031

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.07832
Policy Update Magnitude: 0.32157
Value Function Update Magnitude: 0.35875

Collected Steps per Second: 21,909.76561
Overall Steps per Second: 10,539.27221

Timestep Collection Time: 2.28318
Timestep Consumption Time: 2.46325
PPO Batch Consumption Time: 0.28378
Total Iteration Time: 4.74644

Cumulative Model Updates: 238,472
Cumulative Timesteps: 1,989,495,698

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1989495698...
Checkpoint 1989495698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,250.12349
Policy Entropy: 2.22701
Value Function Loss: 0.02285

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.07421
Policy Update Magnitude: 0.32282
Value Function Update Magnitude: 0.38506

Collected Steps per Second: 21,548.44224
Overall Steps per Second: 10,533.08493

Timestep Collection Time: 2.32072
Timestep Consumption Time: 2.42698
PPO Batch Consumption Time: 0.27863
Total Iteration Time: 4.74771

Cumulative Model Updates: 238,478
Cumulative Timesteps: 1,989,545,706

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,923.89896
Policy Entropy: 2.23976
Value Function Loss: 0.02034

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.07666
Policy Update Magnitude: 0.32419
Value Function Update Magnitude: 0.41177

Collected Steps per Second: 21,432.71323
Overall Steps per Second: 10,510.00759

Timestep Collection Time: 2.33456
Timestep Consumption Time: 2.42623
PPO Batch Consumption Time: 0.27938
Total Iteration Time: 4.76080

Cumulative Model Updates: 238,484
Cumulative Timesteps: 1,989,595,742

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1989595742...
Checkpoint 1989595742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,923.89896
Policy Entropy: 2.25906
Value Function Loss: 0.01844

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.07411
Policy Update Magnitude: 0.30993
Value Function Update Magnitude: 0.39318

Collected Steps per Second: 21,532.18012
Overall Steps per Second: 10,351.11518

Timestep Collection Time: 2.32378
Timestep Consumption Time: 2.51010
PPO Batch Consumption Time: 0.29273
Total Iteration Time: 4.83388

Cumulative Model Updates: 238,490
Cumulative Timesteps: 1,989,645,778

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50,236.68535
Policy Entropy: 2.26698
Value Function Loss: 0.01774

Mean KL Divergence: 0.00720
SB3 Clip Fraction: 0.06708
Policy Update Magnitude: 0.30430
Value Function Update Magnitude: 0.34736

Collected Steps per Second: 21,450.08051
Overall Steps per Second: 10,321.47890

Timestep Collection Time: 2.33174
Timestep Consumption Time: 2.51408
PPO Batch Consumption Time: 0.29110
Total Iteration Time: 4.84582

Cumulative Model Updates: 238,496
Cumulative Timesteps: 1,989,695,794

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1989695794...
Checkpoint 1989695794 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,986.38461
Policy Entropy: 2.24295
Value Function Loss: 0.01985

Mean KL Divergence: 0.00770
SB3 Clip Fraction: 0.06993
Policy Update Magnitude: 0.30570
Value Function Update Magnitude: 0.32299

Collected Steps per Second: 21,575.70441
Overall Steps per Second: 10,367.41573

Timestep Collection Time: 2.31863
Timestep Consumption Time: 2.50668
PPO Batch Consumption Time: 0.29024
Total Iteration Time: 4.82531

Cumulative Model Updates: 238,502
Cumulative Timesteps: 1,989,745,820

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45,314.99834
Policy Entropy: 2.23297
Value Function Loss: 0.02231

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.08060
Policy Update Magnitude: 0.31273
Value Function Update Magnitude: 0.31961

Collected Steps per Second: 22,236.67194
Overall Steps per Second: 10,450.61670

Timestep Collection Time: 2.24872
Timestep Consumption Time: 2.53607
PPO Batch Consumption Time: 0.29095
Total Iteration Time: 4.78479

Cumulative Model Updates: 238,508
Cumulative Timesteps: 1,989,795,824

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1989795824...
Checkpoint 1989795824 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,002.33944
Policy Entropy: 2.22904
Value Function Loss: 0.02198

Mean KL Divergence: 0.00777
SB3 Clip Fraction: 0.07171
Policy Update Magnitude: 0.31691
Value Function Update Magnitude: 0.33269

Collected Steps per Second: 22,118.38112
Overall Steps per Second: 10,408.78518

Timestep Collection Time: 2.26228
Timestep Consumption Time: 2.54500
PPO Batch Consumption Time: 0.29447
Total Iteration Time: 4.80729

Cumulative Model Updates: 238,514
Cumulative Timesteps: 1,989,845,862

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59,793.42887
Policy Entropy: 2.24877
Value Function Loss: 0.02207

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.07476
Policy Update Magnitude: 0.32477
Value Function Update Magnitude: 0.36315

Collected Steps per Second: 21,929.41400
Overall Steps per Second: 10,585.33970

Timestep Collection Time: 2.28077
Timestep Consumption Time: 2.44425
PPO Batch Consumption Time: 0.27807
Total Iteration Time: 4.72503

Cumulative Model Updates: 238,520
Cumulative Timesteps: 1,989,895,878

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1989895878...
Checkpoint 1989895878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,819.06747
Policy Entropy: 2.25275
Value Function Loss: 0.02179

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.07772
Policy Update Magnitude: 0.32500
Value Function Update Magnitude: 0.35154

Collected Steps per Second: 22,162.06266
Overall Steps per Second: 10,514.78773

Timestep Collection Time: 2.25674
Timestep Consumption Time: 2.49980
PPO Batch Consumption Time: 0.28878
Total Iteration Time: 4.75654

Cumulative Model Updates: 238,526
Cumulative Timesteps: 1,989,945,892

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79,496.46876
Policy Entropy: 2.26794
Value Function Loss: 0.02301

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.07410
Policy Update Magnitude: 0.32440
Value Function Update Magnitude: 0.35264

Collected Steps per Second: 22,080.14873
Overall Steps per Second: 10,504.09730

Timestep Collection Time: 2.26448
Timestep Consumption Time: 2.49557
PPO Batch Consumption Time: 0.28773
Total Iteration Time: 4.76005

Cumulative Model Updates: 238,532
Cumulative Timesteps: 1,989,995,892

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1989995892...
Checkpoint 1989995892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87,957.93493
Policy Entropy: 2.26880
Value Function Loss: 0.02027

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.07807
Policy Update Magnitude: 0.31659
Value Function Update Magnitude: 0.32863

Collected Steps per Second: 21,879.02931
Overall Steps per Second: 10,580.26278

Timestep Collection Time: 2.28575
Timestep Consumption Time: 2.44098
PPO Batch Consumption Time: 0.27904
Total Iteration Time: 4.72673

Cumulative Model Updates: 238,538
Cumulative Timesteps: 1,990,045,902

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67,456.42304
Policy Entropy: 2.25207
Value Function Loss: 0.02005

Mean KL Divergence: 0.00708
SB3 Clip Fraction: 0.06854
Policy Update Magnitude: 0.31428
Value Function Update Magnitude: 0.30100

Collected Steps per Second: 21,959.06589
Overall Steps per Second: 10,509.03926

Timestep Collection Time: 2.27733
Timestep Consumption Time: 2.48124
PPO Batch Consumption Time: 0.28550
Total Iteration Time: 4.75857

Cumulative Model Updates: 238,544
Cumulative Timesteps: 1,990,095,910

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1990095910...
Checkpoint 1990095910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 64,553.98823
Policy Entropy: 2.24791
Value Function Loss: 0.01744

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.07308
Policy Update Magnitude: 0.31049
Value Function Update Magnitude: 0.30662

Collected Steps per Second: 21,213.03517
Overall Steps per Second: 10,270.83198

Timestep Collection Time: 2.35704
Timestep Consumption Time: 2.51111
PPO Batch Consumption Time: 0.29371
Total Iteration Time: 4.86815

Cumulative Model Updates: 238,550
Cumulative Timesteps: 1,990,145,910

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61,522.91954
Policy Entropy: 2.23967
Value Function Loss: 0.01769

Mean KL Divergence: 0.00763
SB3 Clip Fraction: 0.07111
Policy Update Magnitude: 0.30646
Value Function Update Magnitude: 0.33805

Collected Steps per Second: 21,635.93553
Overall Steps per Second: 10,401.60128

Timestep Collection Time: 2.31217
Timestep Consumption Time: 2.49728
PPO Batch Consumption Time: 0.28990
Total Iteration Time: 4.80945

Cumulative Model Updates: 238,556
Cumulative Timesteps: 1,990,195,936

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1990195936...
Checkpoint 1990195936 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 53,311.70404
Policy Entropy: 2.26551
Value Function Loss: 0.01705

Mean KL Divergence: 0.00729
SB3 Clip Fraction: 0.06880
Policy Update Magnitude: 0.30182
Value Function Update Magnitude: 0.34162

Collected Steps per Second: 21,146.40077
Overall Steps per Second: 10,262.94382

Timestep Collection Time: 2.36523
Timestep Consumption Time: 2.50823
PPO Batch Consumption Time: 0.29242
Total Iteration Time: 4.87346

Cumulative Model Updates: 238,562
Cumulative Timesteps: 1,990,245,952

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55,619.58019
Policy Entropy: 2.27488
Value Function Loss: 0.01942

Mean KL Divergence: 0.00728
SB3 Clip Fraction: 0.06451
Policy Update Magnitude: 0.30716
Value Function Update Magnitude: 0.32825

Collected Steps per Second: 21,585.51868
Overall Steps per Second: 10,378.54157

Timestep Collection Time: 2.31674
Timestep Consumption Time: 2.50166
PPO Batch Consumption Time: 0.28993
Total Iteration Time: 4.81840

Cumulative Model Updates: 238,568
Cumulative Timesteps: 1,990,295,960

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1990295960...
Checkpoint 1990295960 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,552.98999
Policy Entropy: 2.28913
Value Function Loss: 0.01841

Mean KL Divergence: 0.00721
SB3 Clip Fraction: 0.06829
Policy Update Magnitude: 0.30694
Value Function Update Magnitude: 0.32110

Collected Steps per Second: 21,634.32497
Overall Steps per Second: 10,379.54615

Timestep Collection Time: 2.31188
Timestep Consumption Time: 2.50683
PPO Batch Consumption Time: 0.28982
Total Iteration Time: 4.81871

Cumulative Model Updates: 238,574
Cumulative Timesteps: 1,990,345,976

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,639.10903
Policy Entropy: 2.28854
Value Function Loss: 0.01712

Mean KL Divergence: 0.00720
SB3 Clip Fraction: 0.06747
Policy Update Magnitude: 0.30227
Value Function Update Magnitude: 0.30477

Collected Steps per Second: 22,232.66516
Overall Steps per Second: 10,479.26936

Timestep Collection Time: 2.25011
Timestep Consumption Time: 2.52369
PPO Batch Consumption Time: 0.28964
Total Iteration Time: 4.77381

Cumulative Model Updates: 238,580
Cumulative Timesteps: 1,990,396,002

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1990396002...
Checkpoint 1990396002 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 50,544.46140
Policy Entropy: 2.28234
Value Function Loss: 0.01932

Mean KL Divergence: 0.00705
SB3 Clip Fraction: 0.06495
Policy Update Magnitude: 0.31327
Value Function Update Magnitude: 0.32588

Collected Steps per Second: 21,496.34301
Overall Steps per Second: 10,482.34924

Timestep Collection Time: 2.32663
Timestep Consumption Time: 2.44463
PPO Batch Consumption Time: 0.29301
Total Iteration Time: 4.77126

Cumulative Model Updates: 238,586
Cumulative Timesteps: 1,990,446,016

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63,964.69641
Policy Entropy: 2.28769
Value Function Loss: 0.01871

Mean KL Divergence: 0.00743
SB3 Clip Fraction: 0.06581
Policy Update Magnitude: 0.31563
Value Function Update Magnitude: 0.36191

Collected Steps per Second: 21,419.85223
Overall Steps per Second: 10,476.10751

Timestep Collection Time: 2.33540
Timestep Consumption Time: 2.43965
PPO Batch Consumption Time: 0.29378
Total Iteration Time: 4.77506

Cumulative Model Updates: 238,592
Cumulative Timesteps: 1,990,496,040

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1990496040...
Checkpoint 1990496040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 61,054.46732
Policy Entropy: 2.28685
Value Function Loss: 0.02033

Mean KL Divergence: 0.00731
SB3 Clip Fraction: 0.06463
Policy Update Magnitude: 0.31509
Value Function Update Magnitude: 0.35816

Collected Steps per Second: 21,004.53621
Overall Steps per Second: 10,504.65363

Timestep Collection Time: 2.38053
Timestep Consumption Time: 2.37945
PPO Batch Consumption Time: 0.27891
Total Iteration Time: 4.75999

Cumulative Model Updates: 238,598
Cumulative Timesteps: 1,990,546,042

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90,827.33244
Policy Entropy: 2.27416
Value Function Loss: 0.01940

Mean KL Divergence: 0.00717
SB3 Clip Fraction: 0.06879
Policy Update Magnitude: 0.31180
Value Function Update Magnitude: 0.34275

Collected Steps per Second: 21,766.61773
Overall Steps per Second: 10,478.89528

Timestep Collection Time: 2.29719
Timestep Consumption Time: 2.47450
PPO Batch Consumption Time: 0.28839
Total Iteration Time: 4.77169

Cumulative Model Updates: 238,604
Cumulative Timesteps: 1,990,596,044

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1990596044...
Checkpoint 1990596044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86,907.32049
Policy Entropy: 2.24750
Value Function Loss: 0.01948

Mean KL Divergence: 0.00732
SB3 Clip Fraction: 0.06876
Policy Update Magnitude: 0.30694
Value Function Update Magnitude: 0.29911

Collected Steps per Second: 21,942.13944
Overall Steps per Second: 10,710.71570

Timestep Collection Time: 2.27991
Timestep Consumption Time: 2.39074
PPO Batch Consumption Time: 0.27731
Total Iteration Time: 4.67065

Cumulative Model Updates: 238,610
Cumulative Timesteps: 1,990,646,070

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86,907.32049
Policy Entropy: 2.25938
Value Function Loss: 0.01641

Mean KL Divergence: 0.00678
SB3 Clip Fraction: 0.06521
Policy Update Magnitude: 0.30111
Value Function Update Magnitude: 0.28962

Collected Steps per Second: 21,500.60985
Overall Steps per Second: 10,405.53615

Timestep Collection Time: 2.32672
Timestep Consumption Time: 2.48091
PPO Batch Consumption Time: 0.28650
Total Iteration Time: 4.80763

Cumulative Model Updates: 238,616
Cumulative Timesteps: 1,990,696,096

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1990696096...
Checkpoint 1990696096 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 60,339.14819
Policy Entropy: 2.27278
Value Function Loss: 0.01717

Mean KL Divergence: 0.00721
SB3 Clip Fraction: 0.06812
Policy Update Magnitude: 0.30117
Value Function Update Magnitude: 0.29581

Collected Steps per Second: 21,129.84124
Overall Steps per Second: 10,213.00378

Timestep Collection Time: 2.36755
Timestep Consumption Time: 2.53071
PPO Batch Consumption Time: 0.29300
Total Iteration Time: 4.89827

Cumulative Model Updates: 238,622
Cumulative Timesteps: 1,990,746,122

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54,195.50193
Policy Entropy: 2.29148
Value Function Loss: 0.01655

Mean KL Divergence: 0.00689
SB3 Clip Fraction: 0.06514
Policy Update Magnitude: 0.29903
Value Function Update Magnitude: 0.28635

Collected Steps per Second: 21,846.85480
Overall Steps per Second: 10,439.15752

Timestep Collection Time: 2.28893
Timestep Consumption Time: 2.50130
PPO Batch Consumption Time: 0.28826
Total Iteration Time: 4.79023

Cumulative Model Updates: 238,628
Cumulative Timesteps: 1,990,796,128

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1990796128...
Checkpoint 1990796128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,991.91507
Policy Entropy: 2.29779
Value Function Loss: 0.01769

Mean KL Divergence: 0.00720
SB3 Clip Fraction: 0.06775
Policy Update Magnitude: 0.30292
Value Function Update Magnitude: 0.28452

Collected Steps per Second: 21,504.96770
Overall Steps per Second: 10,357.71234

Timestep Collection Time: 2.32607
Timestep Consumption Time: 2.50338
PPO Batch Consumption Time: 0.29131
Total Iteration Time: 4.82944

Cumulative Model Updates: 238,634
Cumulative Timesteps: 1,990,846,150

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60,936.69477
Policy Entropy: 2.29134
Value Function Loss: 0.01770

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.08314
Policy Update Magnitude: 0.29787
Value Function Update Magnitude: 0.29537

Collected Steps per Second: 22,253.23524
Overall Steps per Second: 10,390.80559

Timestep Collection Time: 2.24866
Timestep Consumption Time: 2.56713
PPO Batch Consumption Time: 0.29388
Total Iteration Time: 4.81580

Cumulative Model Updates: 238,640
Cumulative Timesteps: 1,990,896,190

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1990896190...
Checkpoint 1990896190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 57,250.19835
Policy Entropy: 2.27329
Value Function Loss: 0.02092

Mean KL Divergence: 0.01123
SB3 Clip Fraction: 0.09558
Policy Update Magnitude: 0.31652
Value Function Update Magnitude: 0.33117

Collected Steps per Second: 21,850.39775
Overall Steps per Second: 10,513.80667

Timestep Collection Time: 2.28984
Timestep Consumption Time: 2.46904
PPO Batch Consumption Time: 0.27939
Total Iteration Time: 4.75889

Cumulative Model Updates: 238,646
Cumulative Timesteps: 1,990,946,224

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53,352.69902
Policy Entropy: 2.24371
Value Function Loss: 0.02298

Mean KL Divergence: 0.01131
SB3 Clip Fraction: 0.09693
Policy Update Magnitude: 0.33565
Value Function Update Magnitude: 0.33342

Collected Steps per Second: 22,243.92957
Overall Steps per Second: 10,463.02812

Timestep Collection Time: 2.24798
Timestep Consumption Time: 2.53113
PPO Batch Consumption Time: 0.29255
Total Iteration Time: 4.77911

Cumulative Model Updates: 238,652
Cumulative Timesteps: 1,990,996,228

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1990996228...
Checkpoint 1990996228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 59,090.20176
Policy Entropy: 2.24334
Value Function Loss: 0.02529

Mean KL Divergence: 0.01175
SB3 Clip Fraction: 0.09724
Policy Update Magnitude: 0.33651
Value Function Update Magnitude: 0.33555

Collected Steps per Second: 22,031.97684
Overall Steps per Second: 10,621.26682

Timestep Collection Time: 2.27052
Timestep Consumption Time: 2.43928
PPO Batch Consumption Time: 0.27927
Total Iteration Time: 4.70980

Cumulative Model Updates: 238,658
Cumulative Timesteps: 1,991,046,252

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,004.90184
Policy Entropy: 2.23182
Value Function Loss: 0.02222

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.08878
Policy Update Magnitude: 0.33407
Value Function Update Magnitude: 0.33427

Collected Steps per Second: 22,177.46199
Overall Steps per Second: 10,495.10573

Timestep Collection Time: 2.25562
Timestep Consumption Time: 2.51079
PPO Batch Consumption Time: 0.28954
Total Iteration Time: 4.76641

Cumulative Model Updates: 238,664
Cumulative Timesteps: 1,991,096,276

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1991096276...
Checkpoint 1991096276 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40,389.58535
Policy Entropy: 2.24521
Value Function Loss: 0.02025

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.07934
Policy Update Magnitude: 0.32715
Value Function Update Magnitude: 0.31631

Collected Steps per Second: 21,617.00654
Overall Steps per Second: 10,556.92663

Timestep Collection Time: 2.31392
Timestep Consumption Time: 2.42420
PPO Batch Consumption Time: 0.27933
Total Iteration Time: 4.73812

Cumulative Model Updates: 238,670
Cumulative Timesteps: 1,991,146,296

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51,672.83706
Policy Entropy: 2.23278
Value Function Loss: 0.02059

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.08631
Policy Update Magnitude: 0.32477
Value Function Update Magnitude: 0.31858

Collected Steps per Second: 22,010.94183
Overall Steps per Second: 10,566.92515

Timestep Collection Time: 2.27205
Timestep Consumption Time: 2.46064
PPO Batch Consumption Time: 0.28461
Total Iteration Time: 4.73269

Cumulative Model Updates: 238,676
Cumulative Timesteps: 1,991,196,306

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1991196306...
Checkpoint 1991196306 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40,972.29483
Policy Entropy: 2.22767
Value Function Loss: 0.01920

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.08312
Policy Update Magnitude: 0.32047
Value Function Update Magnitude: 0.31388

Collected Steps per Second: 21,072.31970
Overall Steps per Second: 10,248.25273

Timestep Collection Time: 2.37439
Timestep Consumption Time: 2.50780
PPO Batch Consumption Time: 0.29300
Total Iteration Time: 4.88220

Cumulative Model Updates: 238,682
Cumulative Timesteps: 1,991,246,340

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57,910.83149
Policy Entropy: 2.22362
Value Function Loss: 0.01965

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.08312
Policy Update Magnitude: 0.31491
Value Function Update Magnitude: 0.29944

Collected Steps per Second: 21,527.22826
Overall Steps per Second: 10,374.12250

Timestep Collection Time: 2.32375
Timestep Consumption Time: 2.49824
PPO Batch Consumption Time: 0.28933
Total Iteration Time: 4.82200

Cumulative Model Updates: 238,688
Cumulative Timesteps: 1,991,296,364

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1991296364...
Checkpoint 1991296364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,239.70068
Policy Entropy: 2.23749
Value Function Loss: 0.02125

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.08793
Policy Update Magnitude: 0.31402
Value Function Update Magnitude: 0.30128

Collected Steps per Second: 21,243.89123
Overall Steps per Second: 10,317.60733

Timestep Collection Time: 2.35494
Timestep Consumption Time: 2.49386
PPO Batch Consumption Time: 0.29315
Total Iteration Time: 4.84880

Cumulative Model Updates: 238,694
Cumulative Timesteps: 1,991,346,392

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,003.83738
Policy Entropy: 2.25831
Value Function Loss: 0.02106

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.08291
Policy Update Magnitude: 0.31743
Value Function Update Magnitude: 0.32179

Collected Steps per Second: 21,703.42519
Overall Steps per Second: 10,380.76880

Timestep Collection Time: 2.30517
Timestep Consumption Time: 2.51432
PPO Batch Consumption Time: 0.29440
Total Iteration Time: 4.81949

Cumulative Model Updates: 238,700
Cumulative Timesteps: 1,991,396,422

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1991396422...
Checkpoint 1991396422 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,003.83738
Policy Entropy: 2.26298
Value Function Loss: 0.01855

Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.07495
Policy Update Magnitude: 0.30570
Value Function Update Magnitude: 0.33078

Collected Steps per Second: 21,335.00163
Overall Steps per Second: 10,329.25812

Timestep Collection Time: 2.34394
Timestep Consumption Time: 2.49745
PPO Batch Consumption Time: 0.29192
Total Iteration Time: 4.84139

Cumulative Model Updates: 238,706
Cumulative Timesteps: 1,991,446,430

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,666.50328
Policy Entropy: 2.26678
Value Function Loss: 0.01740

Mean KL Divergence: 0.00734
SB3 Clip Fraction: 0.06807
Policy Update Magnitude: 0.29752
Value Function Update Magnitude: 0.30307

Collected Steps per Second: 21,732.14793
Overall Steps per Second: 10,672.33332

Timestep Collection Time: 2.30203
Timestep Consumption Time: 2.38561
PPO Batch Consumption Time: 0.27908
Total Iteration Time: 4.68763

Cumulative Model Updates: 238,712
Cumulative Timesteps: 1,991,496,458

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1991496458...
Checkpoint 1991496458 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 71,978.19634
Policy Entropy: 2.26364
Value Function Loss: 0.01901

Mean KL Divergence: 0.00612
SB3 Clip Fraction: 0.05859
Policy Update Magnitude: 0.30623
Value Function Update Magnitude: 0.29553

Collected Steps per Second: 21,128.33021
Overall Steps per Second: 10,416.18318

Timestep Collection Time: 2.36753
Timestep Consumption Time: 2.43480
PPO Batch Consumption Time: 0.29000
Total Iteration Time: 4.80233

Cumulative Model Updates: 238,718
Cumulative Timesteps: 1,991,546,480

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59,585.70507
Policy Entropy: 2.27663
Value Function Loss: 0.02015

Mean KL Divergence: 0.00643
SB3 Clip Fraction: 0.05966
Policy Update Magnitude: 0.30789
Value Function Update Magnitude: 0.31141

Collected Steps per Second: 21,910.10163
Overall Steps per Second: 10,769.08196

Timestep Collection Time: 2.28205
Timestep Consumption Time: 2.36087
PPO Batch Consumption Time: 0.27922
Total Iteration Time: 4.64292

Cumulative Model Updates: 238,724
Cumulative Timesteps: 1,991,596,480

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1991596480...
Checkpoint 1991596480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40,245.65178
Policy Entropy: 2.26757
Value Function Loss: 0.01941

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.07025
Policy Update Magnitude: 0.30192
Value Function Update Magnitude: 0.31668

Collected Steps per Second: 21,265.69515
Overall Steps per Second: 10,355.02943

Timestep Collection Time: 2.35318
Timestep Consumption Time: 2.47945
PPO Batch Consumption Time: 0.29184
Total Iteration Time: 4.83263

Cumulative Model Updates: 238,730
Cumulative Timesteps: 1,991,646,522

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89,870.07868
Policy Entropy: 2.26788
Value Function Loss: 0.02016

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.08002
Policy Update Magnitude: 0.30092
Value Function Update Magnitude: 0.31713

Collected Steps per Second: 22,456.88402
Overall Steps per Second: 10,757.02857

Timestep Collection Time: 2.22774
Timestep Consumption Time: 2.42299
PPO Batch Consumption Time: 0.27845
Total Iteration Time: 4.65073

Cumulative Model Updates: 238,736
Cumulative Timesteps: 1,991,696,550

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1991696550...
Checkpoint 1991696550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 113,406.31626
Policy Entropy: 2.26134
Value Function Loss: 0.01899

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.07373
Policy Update Magnitude: 0.30295
Value Function Update Magnitude: 0.31473

Collected Steps per Second: 21,859.10819
Overall Steps per Second: 10,675.56563

Timestep Collection Time: 2.28783
Timestep Consumption Time: 2.39670
PPO Batch Consumption Time: 0.27801
Total Iteration Time: 4.68453

Cumulative Model Updates: 238,742
Cumulative Timesteps: 1,991,746,560

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 96,116.50973
Policy Entropy: 2.23763
Value Function Loss: 0.01783

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.07476
Policy Update Magnitude: 0.30397
Value Function Update Magnitude: 0.29578

Collected Steps per Second: 22,074.47774
Overall Steps per Second: 10,488.66199

Timestep Collection Time: 2.26696
Timestep Consumption Time: 2.50409
PPO Batch Consumption Time: 0.29336
Total Iteration Time: 4.77106

Cumulative Model Updates: 238,748
Cumulative Timesteps: 1,991,796,602

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1991796602...
Checkpoint 1991796602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 70,247.20937
Policy Entropy: 2.23259
Value Function Loss: 0.01894

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.06942
Policy Update Magnitude: 0.30058
Value Function Update Magnitude: 0.29065

Collected Steps per Second: 21,339.99162
Overall Steps per Second: 10,509.54975

Timestep Collection Time: 2.34471
Timestep Consumption Time: 2.41630
PPO Batch Consumption Time: 0.27817
Total Iteration Time: 4.76100

Cumulative Model Updates: 238,754
Cumulative Timesteps: 1,991,846,638

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76,360.09293
Policy Entropy: 2.22854
Value Function Loss: 0.02083

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.08083
Policy Update Magnitude: 0.30423
Value Function Update Magnitude: 0.31375

Collected Steps per Second: 21,655.32373
Overall Steps per Second: 10,473.54817

Timestep Collection Time: 2.30946
Timestep Consumption Time: 2.46562
PPO Batch Consumption Time: 0.28760
Total Iteration Time: 4.77508

Cumulative Model Updates: 238,760
Cumulative Timesteps: 1,991,896,650

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1991896650...
Checkpoint 1991896650 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,826.18710
Policy Entropy: 2.25205
Value Function Loss: 0.02027

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.08107
Policy Update Magnitude: 0.30693
Value Function Update Magnitude: 0.31913

Collected Steps per Second: 20,954.90145
Overall Steps per Second: 10,297.56927

Timestep Collection Time: 2.38608
Timestep Consumption Time: 2.46944
PPO Batch Consumption Time: 0.27793
Total Iteration Time: 4.85551

Cumulative Model Updates: 238,766
Cumulative Timesteps: 1,991,946,650

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 72,576.95959
Policy Entropy: 2.26727
Value Function Loss: 0.01849

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.08077
Policy Update Magnitude: 0.29937
Value Function Update Magnitude: 0.27985

Collected Steps per Second: 21,927.15900
Overall Steps per Second: 10,389.84754

Timestep Collection Time: 2.28137
Timestep Consumption Time: 2.53333
PPO Batch Consumption Time: 0.29264
Total Iteration Time: 4.81470

Cumulative Model Updates: 238,772
Cumulative Timesteps: 1,991,996,674

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1991996674...
Checkpoint 1991996674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 61,029.58396
Policy Entropy: 2.27028
Value Function Loss: 0.01960

Mean KL Divergence: 0.00741
SB3 Clip Fraction: 0.07018
Policy Update Magnitude: 0.30263
Value Function Update Magnitude: 0.29095

Collected Steps per Second: 21,780.12146
Overall Steps per Second: 10,553.50422

Timestep Collection Time: 2.29631
Timestep Consumption Time: 2.44278
PPO Batch Consumption Time: 0.27867
Total Iteration Time: 4.73909

Cumulative Model Updates: 238,778
Cumulative Timesteps: 1,992,046,688

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75,266.58121
Policy Entropy: 2.23945
Value Function Loss: 0.01817

Mean KL Divergence: 0.00716
SB3 Clip Fraction: 0.06870
Policy Update Magnitude: 0.30604
Value Function Update Magnitude: 0.29835

Collected Steps per Second: 21,896.41020
Overall Steps per Second: 10,472.23358

Timestep Collection Time: 2.28412
Timestep Consumption Time: 2.49175
PPO Batch Consumption Time: 0.28743
Total Iteration Time: 4.77587

Cumulative Model Updates: 238,784
Cumulative Timesteps: 1,992,096,702

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1992096702...
Checkpoint 1992096702 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46,555.63675
Policy Entropy: 2.21211
Value Function Loss: 0.02110

Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.07390
Policy Update Magnitude: 0.31580
Value Function Update Magnitude: 0.28767

Collected Steps per Second: 21,699.10351
Overall Steps per Second: 10,419.79670

Timestep Collection Time: 2.30443
Timestep Consumption Time: 2.49452
PPO Batch Consumption Time: 0.29047
Total Iteration Time: 4.79894

Cumulative Model Updates: 238,790
Cumulative Timesteps: 1,992,146,706

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65,140.86958
Policy Entropy: 2.22928
Value Function Loss: 0.02024

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.08030
Policy Update Magnitude: 0.31657
Value Function Update Magnitude: 0.34691

Collected Steps per Second: 22,248.68771
Overall Steps per Second: 10,662.23055

Timestep Collection Time: 2.24804
Timestep Consumption Time: 2.44291
PPO Batch Consumption Time: 0.27894
Total Iteration Time: 4.69095

Cumulative Model Updates: 238,796
Cumulative Timesteps: 1,992,196,722

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1992196722...
Checkpoint 1992196722 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40,727.48290
Policy Entropy: 2.23695
Value Function Loss: 0.02007

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.07401
Policy Update Magnitude: 0.31571
Value Function Update Magnitude: 0.36901

Collected Steps per Second: 21,773.42449
Overall Steps per Second: 10,608.45484

Timestep Collection Time: 2.29720
Timestep Consumption Time: 2.41771
PPO Batch Consumption Time: 0.27917
Total Iteration Time: 4.71492

Cumulative Model Updates: 238,802
Cumulative Timesteps: 1,992,246,740

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 64,944.28585
Policy Entropy: 2.24824
Value Function Loss: 0.01799

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.07457
Policy Update Magnitude: 0.30869
Value Function Update Magnitude: 0.35314

Collected Steps per Second: 21,841.88582
Overall Steps per Second: 10,603.95065

Timestep Collection Time: 2.29064
Timestep Consumption Time: 2.42760
PPO Batch Consumption Time: 0.27774
Total Iteration Time: 4.71824

Cumulative Model Updates: 238,808
Cumulative Timesteps: 1,992,296,772

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1992296772...
Checkpoint 1992296772 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55,885.15421
Policy Entropy: 2.24786
Value Function Loss: 0.01744

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.07341
Policy Update Magnitude: 0.30655
Value Function Update Magnitude: 0.31901

Collected Steps per Second: 21,097.60492
Overall Steps per Second: 10,238.81010

Timestep Collection Time: 2.37221
Timestep Consumption Time: 2.51586
PPO Batch Consumption Time: 0.29385
Total Iteration Time: 4.88807

Cumulative Model Updates: 238,814
Cumulative Timesteps: 1,992,346,820

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61,365.08117
Policy Entropy: 2.24626
Value Function Loss: 0.01804

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.07209
Policy Update Magnitude: 0.30362
Value Function Update Magnitude: 0.30908

Collected Steps per Second: 21,203.08549
Overall Steps per Second: 10,459.25104

Timestep Collection Time: 2.36013
Timestep Consumption Time: 2.42434
PPO Batch Consumption Time: 0.27732
Total Iteration Time: 4.78447

Cumulative Model Updates: 238,820
Cumulative Timesteps: 1,992,396,862

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1992396862...
Checkpoint 1992396862 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43,430.87341
Policy Entropy: 2.22972
Value Function Loss: 0.01835

Mean KL Divergence: 0.00777
SB3 Clip Fraction: 0.07262
Policy Update Magnitude: 0.30643
Value Function Update Magnitude: 0.31463

Collected Steps per Second: 20,811.78706
Overall Steps per Second: 10,512.58955

Timestep Collection Time: 2.40258
Timestep Consumption Time: 2.35381
PPO Batch Consumption Time: 0.27847
Total Iteration Time: 4.75639

Cumulative Model Updates: 238,826
Cumulative Timesteps: 1,992,446,864

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54,111.39350
Policy Entropy: 2.21173
Value Function Loss: 0.01915

Mean KL Divergence: 0.00753
SB3 Clip Fraction: 0.07035
Policy Update Magnitude: 0.31436
Value Function Update Magnitude: 0.32395

Collected Steps per Second: 21,068.07963
Overall Steps per Second: 10,566.79793

Timestep Collection Time: 2.37468
Timestep Consumption Time: 2.35996
PPO Batch Consumption Time: 0.27761
Total Iteration Time: 4.73464

Cumulative Model Updates: 238,832
Cumulative Timesteps: 1,992,496,894

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1992496894...
Checkpoint 1992496894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,324.44194
Policy Entropy: 2.23249
Value Function Loss: 0.01972

Mean KL Divergence: 0.00744
SB3 Clip Fraction: 0.06912
Policy Update Magnitude: 0.32379
Value Function Update Magnitude: 0.32601

Collected Steps per Second: 20,908.93224
Overall Steps per Second: 10,219.50199

Timestep Collection Time: 2.39314
Timestep Consumption Time: 2.50318
PPO Batch Consumption Time: 0.29401
Total Iteration Time: 4.89632

Cumulative Model Updates: 238,838
Cumulative Timesteps: 1,992,546,932

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,720.36789
Policy Entropy: 2.22967
Value Function Loss: 0.01999

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.06749
Policy Update Magnitude: 0.31679
Value Function Update Magnitude: 0.34232

Collected Steps per Second: 21,171.45591
Overall Steps per Second: 10,289.86916

Timestep Collection Time: 2.36271
Timestep Consumption Time: 2.49858
PPO Batch Consumption Time: 0.28912
Total Iteration Time: 4.86129

Cumulative Model Updates: 238,844
Cumulative Timesteps: 1,992,596,954

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1992596954...
Checkpoint 1992596954 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,719.79888
Policy Entropy: 2.22922
Value Function Loss: 0.01813

Mean KL Divergence: 0.00744
SB3 Clip Fraction: 0.06641
Policy Update Magnitude: 0.31946
Value Function Update Magnitude: 0.32652

Collected Steps per Second: 21,846.39769
Overall Steps per Second: 10,656.26031

Timestep Collection Time: 2.29127
Timestep Consumption Time: 2.40606
PPO Batch Consumption Time: 0.27959
Total Iteration Time: 4.69733

Cumulative Model Updates: 238,850
Cumulative Timesteps: 1,992,647,010

Timesteps Collected: 50,056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,406.25690
Policy Entropy: 2.21065
Value Function Loss: 0.01928

Mean KL Divergence: 0.00709
SB3 Clip Fraction: 0.06589
Policy Update Magnitude: 0.31615
Value Function Update Magnitude: 0.29297

Collected Steps per Second: 21,805.35285
Overall Steps per Second: 10,508.65025

Timestep Collection Time: 2.29503
Timestep Consumption Time: 2.46714
PPO Batch Consumption Time: 0.28867
Total Iteration Time: 4.76217

Cumulative Model Updates: 238,856
Cumulative Timesteps: 1,992,697,054

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1992697054...
Checkpoint 1992697054 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 51,373.21565
Policy Entropy: 2.21722
Value Function Loss: 0.02014

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.06908
Policy Update Magnitude: 0.31523
Value Function Update Magnitude: 0.32625

Collected Steps per Second: 21,934.64979
Overall Steps per Second: 10,642.39793

Timestep Collection Time: 2.28150
Timestep Consumption Time: 2.42082
PPO Batch Consumption Time: 0.28029
Total Iteration Time: 4.70232

Cumulative Model Updates: 238,862
Cumulative Timesteps: 1,992,747,098

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49,325.71380
Policy Entropy: 2.22158
Value Function Loss: 0.01814

Mean KL Divergence: 0.00726
SB3 Clip Fraction: 0.06785
Policy Update Magnitude: 0.30755
Value Function Update Magnitude: 0.31125

Collected Steps per Second: 21,780.03523
Overall Steps per Second: 10,493.77290

Timestep Collection Time: 2.29669
Timestep Consumption Time: 2.47014
PPO Batch Consumption Time: 0.28543
Total Iteration Time: 4.76683

Cumulative Model Updates: 238,868
Cumulative Timesteps: 1,992,797,120

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1992797120...
Checkpoint 1992797120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 63,882.09423
Policy Entropy: 2.21965
Value Function Loss: 0.01953

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.07427
Policy Update Magnitude: 0.30481
Value Function Update Magnitude: 0.28666

Collected Steps per Second: 21,739.13988
Overall Steps per Second: 10,574.99037

Timestep Collection Time: 2.30110
Timestep Consumption Time: 2.42930
PPO Batch Consumption Time: 0.27897
Total Iteration Time: 4.73041

Cumulative Model Updates: 238,874
Cumulative Timesteps: 1,992,847,144

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60,352.71960
Policy Entropy: 2.21516
Value Function Loss: 0.01950

Mean KL Divergence: 0.00728
SB3 Clip Fraction: 0.07116
Policy Update Magnitude: 0.31478
Value Function Update Magnitude: 0.27618

Collected Steps per Second: 21,700.48422
Overall Steps per Second: 10,546.19426

Timestep Collection Time: 2.30576
Timestep Consumption Time: 2.43871
PPO Batch Consumption Time: 0.27840
Total Iteration Time: 4.74446

Cumulative Model Updates: 238,880
Cumulative Timesteps: 1,992,897,180

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1992897180...
Checkpoint 1992897180 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 52,631.52385
Policy Entropy: 2.21629
Value Function Loss: 0.01900

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.07451
Policy Update Magnitude: 0.31461
Value Function Update Magnitude: 0.29695

Collected Steps per Second: 21,341.26514
Overall Steps per Second: 10,331.21232

Timestep Collection Time: 2.34344
Timestep Consumption Time: 2.49742
PPO Batch Consumption Time: 0.29050
Total Iteration Time: 4.84086

Cumulative Model Updates: 238,886
Cumulative Timesteps: 1,992,947,192

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,222.60575
Policy Entropy: 2.23274
Value Function Loss: 0.01892

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.08030
Policy Update Magnitude: 0.30365
Value Function Update Magnitude: 0.30151

Collected Steps per Second: 21,535.55964
Overall Steps per Second: 10,368.57579

Timestep Collection Time: 2.32230
Timestep Consumption Time: 2.50112
PPO Batch Consumption Time: 0.29396
Total Iteration Time: 4.82342

Cumulative Model Updates: 238,892
Cumulative Timesteps: 1,992,997,204

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1992997204...
Checkpoint 1992997204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 67,012.44142
Policy Entropy: 2.22023
Value Function Loss: 0.01869

Mean KL Divergence: 0.01577
SB3 Clip Fraction: 0.11578
Policy Update Magnitude: 0.29145
Value Function Update Magnitude: 0.27825

Collected Steps per Second: 21,587.15092
Overall Steps per Second: 10,531.91651

Timestep Collection Time: 2.31768
Timestep Consumption Time: 2.43284
PPO Batch Consumption Time: 0.27900
Total Iteration Time: 4.75051

Cumulative Model Updates: 238,898
Cumulative Timesteps: 1,993,047,236

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46,644.07473
Policy Entropy: 2.23295
Value Function Loss: 0.02069

Mean KL Divergence: 0.01673
SB3 Clip Fraction: 0.11776
Policy Update Magnitude: 0.30813
Value Function Update Magnitude: 0.30041

Collected Steps per Second: 21,766.14480
Overall Steps per Second: 10,480.69661

Timestep Collection Time: 2.29797
Timestep Consumption Time: 2.47442
PPO Batch Consumption Time: 0.27925
Total Iteration Time: 4.77239

Cumulative Model Updates: 238,904
Cumulative Timesteps: 1,993,097,254

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1993097254...
Checkpoint 1993097254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48,314.42625
Policy Entropy: 2.21753
Value Function Loss: 0.02133

Mean KL Divergence: 0.01735
SB3 Clip Fraction: 0.11848
Policy Update Magnitude: 0.30872
Value Function Update Magnitude: 0.28888

Collected Steps per Second: 21,733.01355
Overall Steps per Second: 10,530.80643

Timestep Collection Time: 2.30083
Timestep Consumption Time: 2.44752
PPO Batch Consumption Time: 0.27922
Total Iteration Time: 4.74835

Cumulative Model Updates: 238,910
Cumulative Timesteps: 1,993,147,258

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 64,452.08470
Policy Entropy: 2.22038
Value Function Loss: 0.02396

Mean KL Divergence: 0.01327
SB3 Clip Fraction: 0.10622
Policy Update Magnitude: 0.32160
Value Function Update Magnitude: 0.25225

Collected Steps per Second: 21,997.05420
Overall Steps per Second: 10,535.71469

Timestep Collection Time: 2.27503
Timestep Consumption Time: 2.47491
PPO Batch Consumption Time: 0.28543
Total Iteration Time: 4.74994

Cumulative Model Updates: 238,916
Cumulative Timesteps: 1,993,197,302

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1993197302...
Checkpoint 1993197302 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 72,522.89767
Policy Entropy: 2.21431
Value Function Loss: 0.02374

Mean KL Divergence: 0.01095
SB3 Clip Fraction: 0.09335
Policy Update Magnitude: 0.32845
Value Function Update Magnitude: 0.25160

Collected Steps per Second: 20,901.16058
Overall Steps per Second: 10,387.24527

Timestep Collection Time: 2.39269
Timestep Consumption Time: 2.42187
PPO Batch Consumption Time: 0.29055
Total Iteration Time: 4.81456

Cumulative Model Updates: 238,922
Cumulative Timesteps: 1,993,247,312

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50,012.94127
Policy Entropy: 2.21467
Value Function Loss: 0.02252

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.08420
Policy Update Magnitude: 0.32775
Value Function Update Magnitude: 0.30388

Collected Steps per Second: 21,567.09390
Overall Steps per Second: 10,685.48528

Timestep Collection Time: 2.32039
Timestep Consumption Time: 2.36298
PPO Batch Consumption Time: 0.27971
Total Iteration Time: 4.68336

Cumulative Model Updates: 238,928
Cumulative Timesteps: 1,993,297,356

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1993297356...
Checkpoint 1993297356 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,022.83662
Policy Entropy: 2.23765
Value Function Loss: 0.02085

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.07611
Policy Update Magnitude: 0.32208
Value Function Update Magnitude: 0.30042

Collected Steps per Second: 21,236.84629
Overall Steps per Second: 10,626.29914

Timestep Collection Time: 2.35496
Timestep Consumption Time: 2.35147
PPO Batch Consumption Time: 0.27946
Total Iteration Time: 4.70644

Cumulative Model Updates: 238,934
Cumulative Timesteps: 1,993,347,368

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,835.50529
Policy Entropy: 2.25742
Value Function Loss: 0.02205

Mean KL Divergence: 0.00745
SB3 Clip Fraction: 0.07035
Policy Update Magnitude: 0.31900
Value Function Update Magnitude: 0.33028

Collected Steps per Second: 21,195.76517
Overall Steps per Second: 10,499.65609

Timestep Collection Time: 2.35915
Timestep Consumption Time: 2.40329
PPO Batch Consumption Time: 0.28692
Total Iteration Time: 4.76244

Cumulative Model Updates: 238,940
Cumulative Timesteps: 1,993,397,372

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1993397372...
Checkpoint 1993397372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,883.86129
Policy Entropy: 2.24629
Value Function Loss: 0.02046

Mean KL Divergence: 0.00738
SB3 Clip Fraction: 0.07105
Policy Update Magnitude: 0.31721
Value Function Update Magnitude: 0.34961

Collected Steps per Second: 21,066.72762
Overall Steps per Second: 10,305.29498

Timestep Collection Time: 2.37379
Timestep Consumption Time: 2.47886
PPO Batch Consumption Time: 0.29325
Total Iteration Time: 4.85265

Cumulative Model Updates: 238,946
Cumulative Timesteps: 1,993,447,380

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,477.42139
Policy Entropy: 2.23530
Value Function Loss: 0.01890

Mean KL Divergence: 0.00783
SB3 Clip Fraction: 0.07369
Policy Update Magnitude: 0.31603
Value Function Update Magnitude: 0.33618

Collected Steps per Second: 21,435.86808
Overall Steps per Second: 10,370.68965

Timestep Collection Time: 2.33375
Timestep Consumption Time: 2.49004
PPO Batch Consumption Time: 0.29213
Total Iteration Time: 4.82379

Cumulative Model Updates: 238,952
Cumulative Timesteps: 1,993,497,406

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1993497406...
Checkpoint 1993497406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 62,947.02790
Policy Entropy: 2.23810
Value Function Loss: 0.01761

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.06813
Policy Update Magnitude: 0.30702
Value Function Update Magnitude: 0.31564

Collected Steps per Second: 21,204.62578
Overall Steps per Second: 10,339.44241

Timestep Collection Time: 2.36015
Timestep Consumption Time: 2.48015
PPO Batch Consumption Time: 0.29140
Total Iteration Time: 4.84030

Cumulative Model Updates: 238,958
Cumulative Timesteps: 1,993,547,452

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49,660.80250
Policy Entropy: 2.23722
Value Function Loss: 0.01899

Mean KL Divergence: 0.00760
SB3 Clip Fraction: 0.06499
Policy Update Magnitude: 0.30585
Value Function Update Magnitude: 0.31760

Collected Steps per Second: 21,798.36560
Overall Steps per Second: 10,406.78358

Timestep Collection Time: 2.29403
Timestep Consumption Time: 2.51111
PPO Batch Consumption Time: 0.29249
Total Iteration Time: 4.80514

Cumulative Model Updates: 238,964
Cumulative Timesteps: 1,993,597,458

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1993597458...
Checkpoint 1993597458 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 92,516.61503
Policy Entropy: 2.21989
Value Function Loss: 0.02032

Mean KL Divergence: 0.00658
SB3 Clip Fraction: 0.06214
Policy Update Magnitude: 0.30548
Value Function Update Magnitude: 0.33666

Collected Steps per Second: 21,826.28461
Overall Steps per Second: 10,511.63178

Timestep Collection Time: 2.29192
Timestep Consumption Time: 2.46700
PPO Batch Consumption Time: 0.27873
Total Iteration Time: 4.75892

Cumulative Model Updates: 238,970
Cumulative Timesteps: 1,993,647,482

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76,106.25160
Policy Entropy: 2.22488
Value Function Loss: 0.01941

Mean KL Divergence: 0.00681
SB3 Clip Fraction: 0.06385
Policy Update Magnitude: 0.30992
Value Function Update Magnitude: 0.33627

Collected Steps per Second: 22,098.55622
Overall Steps per Second: 10,460.98468

Timestep Collection Time: 2.26377
Timestep Consumption Time: 2.51838
PPO Batch Consumption Time: 0.29156
Total Iteration Time: 4.78215

Cumulative Model Updates: 238,976
Cumulative Timesteps: 1,993,697,508

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1993697508...
Checkpoint 1993697508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 82,584.21251
Policy Entropy: 2.22909
Value Function Loss: 0.01898

Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.07309
Policy Update Magnitude: 0.30356
Value Function Update Magnitude: 0.33957

Collected Steps per Second: 21,874.53231
Overall Steps per Second: 10,592.19107

Timestep Collection Time: 2.28649
Timestep Consumption Time: 2.43547
PPO Batch Consumption Time: 0.27877
Total Iteration Time: 4.72197

Cumulative Model Updates: 238,982
Cumulative Timesteps: 1,993,747,524

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 64,725.19282
Policy Entropy: 2.22013
Value Function Loss: 0.01816

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.07433
Policy Update Magnitude: 0.30709
Value Function Update Magnitude: 0.33880

Collected Steps per Second: 22,028.61465
Overall Steps per Second: 10,516.08775

Timestep Collection Time: 2.27032
Timestep Consumption Time: 2.48544
PPO Batch Consumption Time: 0.28705
Total Iteration Time: 4.75576

Cumulative Model Updates: 238,988
Cumulative Timesteps: 1,993,797,536

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1993797536...
Checkpoint 1993797536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,769.07313
Policy Entropy: 2.20435
Value Function Loss: 0.01803

Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.07524
Policy Update Magnitude: 0.31701
Value Function Update Magnitude: 0.32488

Collected Steps per Second: 21,959.29054
Overall Steps per Second: 10,620.26201

Timestep Collection Time: 2.27894
Timestep Consumption Time: 2.43318
PPO Batch Consumption Time: 0.27976
Total Iteration Time: 4.71212

Cumulative Model Updates: 238,994
Cumulative Timesteps: 1,993,847,580

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46,683.41057
Policy Entropy: 2.20030
Value Function Loss: 0.01832

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.08576
Policy Update Magnitude: 0.31756
Value Function Update Magnitude: 0.32012

Collected Steps per Second: 22,138.90193
Overall Steps per Second: 10,499.99734

Timestep Collection Time: 2.25910
Timestep Consumption Time: 2.50414
PPO Batch Consumption Time: 0.29164
Total Iteration Time: 4.76324

Cumulative Model Updates: 239,000
Cumulative Timesteps: 1,993,897,594

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1993897594...
Checkpoint 1993897594 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47,858.09189
Policy Entropy: 2.19876
Value Function Loss: 0.01791

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.09400
Policy Update Magnitude: 0.30953
Value Function Update Magnitude: 0.32206

Collected Steps per Second: 21,317.74955
Overall Steps per Second: 10,634.04421

Timestep Collection Time: 2.34781
Timestep Consumption Time: 2.35877
PPO Batch Consumption Time: 0.27933
Total Iteration Time: 4.70658

Cumulative Model Updates: 239,006
Cumulative Timesteps: 1,993,947,644

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50,041.47210
Policy Entropy: 2.22541
Value Function Loss: 0.01625

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.08553
Policy Update Magnitude: 0.30369
Value Function Update Magnitude: 0.30224

Collected Steps per Second: 21,013.73814
Overall Steps per Second: 10,483.94319

Timestep Collection Time: 2.38092
Timestep Consumption Time: 2.39133
PPO Batch Consumption Time: 0.28509
Total Iteration Time: 4.77225

Cumulative Model Updates: 239,012
Cumulative Timesteps: 1,993,997,676

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1993997676...
Checkpoint 1993997676 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 57,716.31964
Policy Entropy: 2.22990
Value Function Loss: 0.01664

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.07878
Policy Update Magnitude: 0.30290
Value Function Update Magnitude: 0.29908

Collected Steps per Second: 20,723.82347
Overall Steps per Second: 10,356.47698

Timestep Collection Time: 2.41268
Timestep Consumption Time: 2.41521
PPO Batch Consumption Time: 0.29190
Total Iteration Time: 4.82790

Cumulative Model Updates: 239,018
Cumulative Timesteps: 1,994,047,676

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 71,209.48861
Policy Entropy: 2.23387
Value Function Loss: 0.01886

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.08258
Policy Update Magnitude: 0.31598
Value Function Update Magnitude: 0.30643

Collected Steps per Second: 21,299.76140
Overall Steps per Second: 10,605.70731

Timestep Collection Time: 2.34895
Timestep Consumption Time: 2.36851
PPO Batch Consumption Time: 0.28252
Total Iteration Time: 4.71746

Cumulative Model Updates: 239,024
Cumulative Timesteps: 1,994,097,708

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1994097708...
Checkpoint 1994097708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 56,933.62722
Policy Entropy: 2.21139
Value Function Loss: 0.01922

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.07571
Policy Update Magnitude: 0.31567
Value Function Update Magnitude: 0.33283

Collected Steps per Second: 20,970.99471
Overall Steps per Second: 10,305.06147

Timestep Collection Time: 2.38491
Timestep Consumption Time: 2.46843
PPO Batch Consumption Time: 0.28701
Total Iteration Time: 4.85334

Cumulative Model Updates: 239,030
Cumulative Timesteps: 1,994,147,722

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51,623.13755
Policy Entropy: 2.19847
Value Function Loss: 0.02228

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.07834
Policy Update Magnitude: 0.31863
Value Function Update Magnitude: 0.34435

Collected Steps per Second: 21,732.84598
Overall Steps per Second: 10,493.12902

Timestep Collection Time: 2.30140
Timestep Consumption Time: 2.46515
PPO Batch Consumption Time: 0.28778
Total Iteration Time: 4.76655

Cumulative Model Updates: 239,036
Cumulative Timesteps: 1,994,197,738

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1994197738...
Checkpoint 1994197738 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 53,259.61401
Policy Entropy: 2.21841
Value Function Loss: 0.02032

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.07266
Policy Update Magnitude: 0.32111
Value Function Update Magnitude: 0.30085

Collected Steps per Second: 21,837.76466
Overall Steps per Second: 10,564.58377

Timestep Collection Time: 2.29099
Timestep Consumption Time: 2.44465
PPO Batch Consumption Time: 0.27833
Total Iteration Time: 4.73563

Cumulative Model Updates: 239,042
Cumulative Timesteps: 1,994,247,768

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,258.46434
Policy Entropy: 2.22444
Value Function Loss: 0.02100

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.07737
Policy Update Magnitude: 0.31596
Value Function Update Magnitude: 0.31228

Collected Steps per Second: 22,173.47480
Overall Steps per Second: 10,464.26938

Timestep Collection Time: 2.25612
Timestep Consumption Time: 2.52453
PPO Batch Consumption Time: 0.29236
Total Iteration Time: 4.78065

Cumulative Model Updates: 239,048
Cumulative Timesteps: 1,994,297,794

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1994297794...
Checkpoint 1994297794 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 53,674.79004
Policy Entropy: 2.23347
Value Function Loss: 0.02203

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.07295
Policy Update Magnitude: 0.31257
Value Function Update Magnitude: 0.31060

Collected Steps per Second: 22,067.57514
Overall Steps per Second: 10,636.12876

Timestep Collection Time: 2.26622
Timestep Consumption Time: 2.43568
PPO Batch Consumption Time: 0.27884
Total Iteration Time: 4.70190

Cumulative Model Updates: 239,054
Cumulative Timesteps: 1,994,347,804

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,716.80072
Policy Entropy: 2.23737
Value Function Loss: 0.02371

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.07253
Policy Update Magnitude: 0.32178
Value Function Update Magnitude: 0.26654

Collected Steps per Second: 22,150.83000
Overall Steps per Second: 10,505.28263

Timestep Collection Time: 2.25779
Timestep Consumption Time: 2.50286
PPO Batch Consumption Time: 0.29084
Total Iteration Time: 4.76065

Cumulative Model Updates: 239,060
Cumulative Timesteps: 1,994,397,816

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1994397816...
Checkpoint 1994397816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 64,968.73221
Policy Entropy: 2.23945
Value Function Loss: 0.02303

Mean KL Divergence: 0.00753
SB3 Clip Fraction: 0.07044
Policy Update Magnitude: 0.32248
Value Function Update Magnitude: 0.28989

Collected Steps per Second: 21,031.20101
Overall Steps per Second: 10,256.48936

Timestep Collection Time: 2.37742
Timestep Consumption Time: 2.49754
PPO Batch Consumption Time: 0.29322
Total Iteration Time: 4.87496

Cumulative Model Updates: 239,066
Cumulative Timesteps: 1,994,447,816

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57,977.77087
Policy Entropy: 2.24510
Value Function Loss: 0.02115

Mean KL Divergence: 0.00753
SB3 Clip Fraction: 0.06942
Policy Update Magnitude: 0.32138
Value Function Update Magnitude: 0.32985

Collected Steps per Second: 21,537.95142
Overall Steps per Second: 10,391.11840

Timestep Collection Time: 2.32343
Timestep Consumption Time: 2.49241
PPO Batch Consumption Time: 0.28821
Total Iteration Time: 4.81584

Cumulative Model Updates: 239,072
Cumulative Timesteps: 1,994,497,858

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1994497858...
Checkpoint 1994497858 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,558.03697
Policy Entropy: 2.22991
Value Function Loss: 0.02281

Mean KL Divergence: 0.00745
SB3 Clip Fraction: 0.07145
Policy Update Magnitude: 0.32822
Value Function Update Magnitude: 0.33433

Collected Steps per Second: 21,483.02068
Overall Steps per Second: 10,350.91518

Timestep Collection Time: 2.32863
Timestep Consumption Time: 2.50437
PPO Batch Consumption Time: 0.29140
Total Iteration Time: 4.83300

Cumulative Model Updates: 239,078
Cumulative Timesteps: 1,994,547,884

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,973.82733
Policy Entropy: 2.22413
Value Function Loss: 0.02304

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.07286
Policy Update Magnitude: 0.33133
Value Function Update Magnitude: 0.29642

Collected Steps per Second: 21,745.08383
Overall Steps per Second: 10,401.60981

Timestep Collection Time: 2.30121
Timestep Consumption Time: 2.50958
PPO Batch Consumption Time: 0.29295
Total Iteration Time: 4.81079

Cumulative Model Updates: 239,084
Cumulative Timesteps: 1,994,597,924

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1994597924...
Checkpoint 1994597924 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,787.35715
Policy Entropy: 2.23558
Value Function Loss: 0.02045

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.07414
Policy Update Magnitude: 0.32021
Value Function Update Magnitude: 0.28942

Collected Steps per Second: 21,952.36341
Overall Steps per Second: 10,524.28532

Timestep Collection Time: 2.27784
Timestep Consumption Time: 2.47346
PPO Batch Consumption Time: 0.27856
Total Iteration Time: 4.75130

Cumulative Model Updates: 239,090
Cumulative Timesteps: 1,994,647,928

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,090.51885
Policy Entropy: 2.25474
Value Function Loss: 0.01900

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.07280
Policy Update Magnitude: 0.31437
Value Function Update Magnitude: 0.28358

Collected Steps per Second: 22,253.04005
Overall Steps per Second: 10,474.58010

Timestep Collection Time: 2.24913
Timestep Consumption Time: 2.52910
PPO Batch Consumption Time: 0.29332
Total Iteration Time: 4.77823

Cumulative Model Updates: 239,096
Cumulative Timesteps: 1,994,697,978

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 1994697978...
Checkpoint 1994697978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,090.51885
Policy Entropy: 2.25668
Value Function Loss: 0.01638

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.07038
Policy Update Magnitude: 0.30057
Value Function Update Magnitude: 0.26091

Collected Steps per Second: 21,950.91993
Overall Steps per Second: 10,589.08972

Timestep Collection Time: 2.27881
Timestep Consumption Time: 2.44511
PPO Batch Consumption Time: 0.27934
Total Iteration Time: 4.72392

Cumulative Model Updates: 239,102
Cumulative Timesteps: 1,994,748,000

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,771.06531
Policy Entropy: 2.23223
Value Function Loss: 0.01967

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.07196
Policy Update Magnitude: 0.31111
Value Function Update Magnitude: 0.27284

Collected Steps per Second: 21,870.88724
Overall Steps per Second: 10,491.06598

Timestep Collection Time: 2.28633
Timestep Consumption Time: 2.48001
PPO Batch Consumption Time: 0.28647
Total Iteration Time: 4.76634

Cumulative Model Updates: 239,108
Cumulative Timesteps: 1,994,798,004

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1994798004...
Checkpoint 1994798004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,560.66269
Policy Entropy: 2.23998
Value Function Loss: 0.01941

Mean KL Divergence: 0.00762
SB3 Clip Fraction: 0.06831
Policy Update Magnitude: 0.32104
Value Function Update Magnitude: 0.28080

Collected Steps per Second: 22,025.28023
Overall Steps per Second: 10,632.25770

Timestep Collection Time: 2.27057
Timestep Consumption Time: 2.43304
PPO Batch Consumption Time: 0.27934
Total Iteration Time: 4.70361

Cumulative Model Updates: 239,114
Cumulative Timesteps: 1,994,848,014

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42,635.29099
Policy Entropy: 2.23913
Value Function Loss: 0.02204

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.07566
Policy Update Magnitude: 0.32981
Value Function Update Magnitude: 0.33866

Collected Steps per Second: 22,320.87783
Overall Steps per Second: 10,508.64815

Timestep Collection Time: 2.24131
Timestep Consumption Time: 2.51934
PPO Batch Consumption Time: 0.29337
Total Iteration Time: 4.76065

Cumulative Model Updates: 239,120
Cumulative Timesteps: 1,994,898,042

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1994898042...
Checkpoint 1994898042 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 62,486.74015
Policy Entropy: 2.25380
Value Function Loss: 0.01880

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.07772
Policy Update Magnitude: 0.33301
Value Function Update Magnitude: 0.35546

Collected Steps per Second: 20,974.08141
Overall Steps per Second: 10,173.41400

Timestep Collection Time: 2.38590
Timestep Consumption Time: 2.53300
PPO Batch Consumption Time: 0.29166
Total Iteration Time: 4.91890

Cumulative Model Updates: 239,126
Cumulative Timesteps: 1,994,948,084

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60,253.84550
Policy Entropy: 2.25258
Value Function Loss: 0.01728

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.07591
Policy Update Magnitude: 0.31469
Value Function Update Magnitude: 0.33915

Collected Steps per Second: 21,624.75940
Overall Steps per Second: 10,461.42460

Timestep Collection Time: 2.31253
Timestep Consumption Time: 2.46769
PPO Batch Consumption Time: 0.28443
Total Iteration Time: 4.78023

Cumulative Model Updates: 239,132
Cumulative Timesteps: 1,994,998,092

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1994998092...
Checkpoint 1994998092 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 72,069.83256
Policy Entropy: 2.25250
Value Function Loss: 0.01839

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.07606
Policy Update Magnitude: 0.31626
Value Function Update Magnitude: 0.32294

Collected Steps per Second: 21,205.48088
Overall Steps per Second: 10,290.63641

Timestep Collection Time: 2.35864
Timestep Consumption Time: 2.50171
PPO Batch Consumption Time: 0.29386
Total Iteration Time: 4.86034

Cumulative Model Updates: 239,138
Cumulative Timesteps: 1,995,048,108

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,816.31494
Policy Entropy: 2.25480
Value Function Loss: 0.01885

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.08228
Policy Update Magnitude: 0.31958
Value Function Update Magnitude: 0.33720

Collected Steps per Second: 21,556.99120
Overall Steps per Second: 10,361.85434

Timestep Collection Time: 2.32045
Timestep Consumption Time: 2.50706
PPO Batch Consumption Time: 0.29138
Total Iteration Time: 4.82751

Cumulative Model Updates: 239,144
Cumulative Timesteps: 1,995,098,130

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1995098130...
Checkpoint 1995098130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,547.81120
Policy Entropy: 2.24463
Value Function Loss: 0.02010

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.08304
Policy Update Magnitude: 0.32101
Value Function Update Magnitude: 0.34776

Collected Steps per Second: 21,401.88875
Overall Steps per Second: 10,354.08610

Timestep Collection Time: 2.33699
Timestep Consumption Time: 2.49357
PPO Batch Consumption Time: 0.29093
Total Iteration Time: 4.83056

Cumulative Model Updates: 239,150
Cumulative Timesteps: 1,995,148,146

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,333.19806
Policy Entropy: 2.24658
Value Function Loss: 0.02078

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.08186
Policy Update Magnitude: 0.31570
Value Function Update Magnitude: 0.34545

Collected Steps per Second: 22,409.16536
Overall Steps per Second: 10,670.33391

Timestep Collection Time: 2.23230
Timestep Consumption Time: 2.45584
PPO Batch Consumption Time: 0.27880
Total Iteration Time: 4.68814

Cumulative Model Updates: 239,156
Cumulative Timesteps: 1,995,198,170

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1995198170...
Checkpoint 1995198170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 54,140.90942
Policy Entropy: 2.25113
Value Function Loss: 0.02053

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.08048
Policy Update Magnitude: 0.31326
Value Function Update Magnitude: 0.33720

Collected Steps per Second: 21,147.25016
Overall Steps per Second: 10,458.44992

Timestep Collection Time: 2.36437
Timestep Consumption Time: 2.41645
PPO Batch Consumption Time: 0.28913
Total Iteration Time: 4.78082

Cumulative Model Updates: 239,162
Cumulative Timesteps: 1,995,248,170

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45,083.90750
Policy Entropy: 2.26106
Value Function Loss: 0.01960

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.08160
Policy Update Magnitude: 0.30992
Value Function Update Magnitude: 0.31222

Collected Steps per Second: 21,731.37544
Overall Steps per Second: 10,702.63185

Timestep Collection Time: 2.30174
Timestep Consumption Time: 2.37188
PPO Batch Consumption Time: 0.28018
Total Iteration Time: 4.67362

Cumulative Model Updates: 239,168
Cumulative Timesteps: 1,995,298,190

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1995298190...
Checkpoint 1995298190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,727.37153
Policy Entropy: 2.26340
Value Function Loss: 0.02065

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.08749
Policy Update Magnitude: 0.32211
Value Function Update Magnitude: 0.30110

Collected Steps per Second: 21,238.92964
Overall Steps per Second: 10,615.23081

Timestep Collection Time: 2.35558
Timestep Consumption Time: 2.35746
PPO Batch Consumption Time: 0.27964
Total Iteration Time: 4.71304

Cumulative Model Updates: 239,174
Cumulative Timesteps: 1,995,348,220

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,348.03793
Policy Entropy: 2.26399
Value Function Loss: 0.01970

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.09270
Policy Update Magnitude: 0.32180
Value Function Update Magnitude: 0.32690

Collected Steps per Second: 21,560.02050
Overall Steps per Second: 10,481.80292

Timestep Collection Time: 2.32003
Timestep Consumption Time: 2.45204
PPO Batch Consumption Time: 0.28674
Total Iteration Time: 4.77208

Cumulative Model Updates: 239,180
Cumulative Timesteps: 1,995,398,240

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1995398240...
Checkpoint 1995398240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,348.03793
Policy Entropy: 2.25155
Value Function Loss: 0.01893

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.08735
Policy Update Magnitude: 0.31740
Value Function Update Magnitude: 0.33665

Collected Steps per Second: 21,685.43473
Overall Steps per Second: 10,611.60578

Timestep Collection Time: 2.30579
Timestep Consumption Time: 2.40622
PPO Batch Consumption Time: 0.27941
Total Iteration Time: 4.71201

Cumulative Model Updates: 239,186
Cumulative Timesteps: 1,995,448,242

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49,282.98600
Policy Entropy: 2.23774
Value Function Loss: 0.01733

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.07818
Policy Update Magnitude: 0.31674
Value Function Update Magnitude: 0.32415

Collected Steps per Second: 21,766.38670
Overall Steps per Second: 10,469.06325

Timestep Collection Time: 2.29831
Timestep Consumption Time: 2.48015
PPO Batch Consumption Time: 0.29101
Total Iteration Time: 4.77846

Cumulative Model Updates: 239,192
Cumulative Timesteps: 1,995,498,268

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1995498268...
Checkpoint 1995498268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 52,130.09561
Policy Entropy: 2.23801
Value Function Loss: 0.01835

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.07326
Policy Update Magnitude: 0.31568
Value Function Update Magnitude: 0.31914

Collected Steps per Second: 21,054.57723
Overall Steps per Second: 10,219.51855

Timestep Collection Time: 2.37507
Timestep Consumption Time: 2.51812
PPO Batch Consumption Time: 0.29447
Total Iteration Time: 4.89319

Cumulative Model Updates: 239,198
Cumulative Timesteps: 1,995,548,274

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65,594.51705
Policy Entropy: 2.27040
Value Function Loss: 0.01885

Mean KL Divergence: 0.00694
SB3 Clip Fraction: 0.06589
Policy Update Magnitude: 0.30919
Value Function Update Magnitude: 0.30512

Collected Steps per Second: 21,724.19023
Overall Steps per Second: 10,439.43456

Timestep Collection Time: 2.30324
Timestep Consumption Time: 2.48974
PPO Batch Consumption Time: 0.28802
Total Iteration Time: 4.79298

Cumulative Model Updates: 239,204
Cumulative Timesteps: 1,995,598,310

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1995598310...
Checkpoint 1995598310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 58,943.19135
Policy Entropy: 2.29012
Value Function Loss: 0.02135

Mean KL Divergence: 0.00719
SB3 Clip Fraction: 0.06962
Policy Update Magnitude: 0.31631
Value Function Update Magnitude: 0.32387

Collected Steps per Second: 21,122.37791
Overall Steps per Second: 10,240.24992

Timestep Collection Time: 2.36801
Timestep Consumption Time: 2.51644
PPO Batch Consumption Time: 0.29347
Total Iteration Time: 4.88445

Cumulative Model Updates: 239,210
Cumulative Timesteps: 1,995,648,328

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70,241.46285
Policy Entropy: 2.29036
Value Function Loss: 0.02027

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.07835
Policy Update Magnitude: 0.31450
Value Function Update Magnitude: 0.34074

Collected Steps per Second: 22,153.20725
Overall Steps per Second: 10,417.91557

Timestep Collection Time: 2.25809
Timestep Consumption Time: 2.54364
PPO Batch Consumption Time: 0.28993
Total Iteration Time: 4.80173

Cumulative Model Updates: 239,216
Cumulative Timesteps: 1,995,698,352

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1995698352...
Checkpoint 1995698352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87,066.91188
Policy Entropy: 2.27121
Value Function Loss: 0.02063

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.08353
Policy Update Magnitude: 0.31712
Value Function Update Magnitude: 0.36506

Collected Steps per Second: 21,783.08112
Overall Steps per Second: 10,546.68488

Timestep Collection Time: 2.29536
Timestep Consumption Time: 2.44547
PPO Batch Consumption Time: 0.27961
Total Iteration Time: 4.74083

Cumulative Model Updates: 239,222
Cumulative Timesteps: 1,995,748,352

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57,611.45593
Policy Entropy: 2.25788
Value Function Loss: 0.01943

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.08718
Policy Update Magnitude: 0.32191
Value Function Update Magnitude: 0.37299

Collected Steps per Second: 21,981.57458
Overall Steps per Second: 10,495.13456

Timestep Collection Time: 2.27600
Timestep Consumption Time: 2.49097
PPO Batch Consumption Time: 0.28770
Total Iteration Time: 4.76697

Cumulative Model Updates: 239,228
Cumulative Timesteps: 1,995,798,382

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1995798382...
Checkpoint 1995798382 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 50,730.62149
Policy Entropy: 2.25030
Value Function Loss: 0.01830

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.08390
Policy Update Magnitude: 0.31692
Value Function Update Magnitude: 0.35259

Collected Steps per Second: 21,670.45018
Overall Steps per Second: 10,433.43450

Timestep Collection Time: 2.30729
Timestep Consumption Time: 2.48500
PPO Batch Consumption Time: 0.28913
Total Iteration Time: 4.79229

Cumulative Model Updates: 239,234
Cumulative Timesteps: 1,995,848,382

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51,651.65201
Policy Entropy: 2.26201
Value Function Loss: 0.01918

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.08242
Policy Update Magnitude: 0.31575
Value Function Update Magnitude: 0.29769

Collected Steps per Second: 22,302.81344
Overall Steps per Second: 10,675.91511

Timestep Collection Time: 2.24196
Timestep Consumption Time: 2.44167
PPO Batch Consumption Time: 0.27962
Total Iteration Time: 4.68363

Cumulative Model Updates: 239,240
Cumulative Timesteps: 1,995,898,384

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1995898384...
Checkpoint 1995898384 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 65,559.22666
Policy Entropy: 2.24218
Value Function Loss: 0.01964

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.07394
Policy Update Magnitude: 0.31527
Value Function Update Magnitude: 0.26875

Collected Steps per Second: 21,564.85963
Overall Steps per Second: 10,571.45459

Timestep Collection Time: 2.31933
Timestep Consumption Time: 2.41190
PPO Batch Consumption Time: 0.27876
Total Iteration Time: 4.73123

Cumulative Model Updates: 239,246
Cumulative Timesteps: 1,995,948,400

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,884.75340
Policy Entropy: 2.24952
Value Function Loss: 0.02158

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.07017
Policy Update Magnitude: 0.32130
Value Function Update Magnitude: 0.31247

Collected Steps per Second: 22,087.60953
Overall Steps per Second: 10,554.01597

Timestep Collection Time: 2.26371
Timestep Consumption Time: 2.47382
PPO Batch Consumption Time: 0.28633
Total Iteration Time: 4.73753

Cumulative Model Updates: 239,252
Cumulative Timesteps: 1,995,998,400

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1995998400...
Checkpoint 1995998400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,913.83723
Policy Entropy: 2.26017
Value Function Loss: 0.02135

Mean KL Divergence: 0.00752
SB3 Clip Fraction: 0.07143
Policy Update Magnitude: 0.32007
Value Function Update Magnitude: 0.33328

Collected Steps per Second: 21,092.97194
Overall Steps per Second: 10,277.66161

Timestep Collection Time: 2.37197
Timestep Consumption Time: 2.49606
PPO Batch Consumption Time: 0.29281
Total Iteration Time: 4.86803

Cumulative Model Updates: 239,258
Cumulative Timesteps: 1,996,048,432

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,418.39445
Policy Entropy: 2.27280
Value Function Loss: 0.02008

Mean KL Divergence: 0.00741
SB3 Clip Fraction: 0.06985
Policy Update Magnitude: 0.31568
Value Function Update Magnitude: 0.29293

Collected Steps per Second: 21,119.09761
Overall Steps per Second: 10,404.26398

Timestep Collection Time: 2.36762
Timestep Consumption Time: 2.43829
PPO Batch Consumption Time: 0.29280
Total Iteration Time: 4.80591

Cumulative Model Updates: 239,264
Cumulative Timesteps: 1,996,098,434

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1996098434...
Checkpoint 1996098434 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,375.55379
Policy Entropy: 2.27426
Value Function Loss: 0.01815

Mean KL Divergence: 0.00685
SB3 Clip Fraction: 0.06650
Policy Update Magnitude: 0.30333
Value Function Update Magnitude: 0.23449

Collected Steps per Second: 20,846.42174
Overall Steps per Second: 10,525.40661

Timestep Collection Time: 2.39907
Timestep Consumption Time: 2.35248
PPO Batch Consumption Time: 0.27858
Total Iteration Time: 4.75155

Cumulative Model Updates: 239,270
Cumulative Timesteps: 1,996,148,446

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46,847.30877
Policy Entropy: 2.26347
Value Function Loss: 0.02241

Mean KL Divergence: 0.00646
SB3 Clip Fraction: 0.06182
Policy Update Magnitude: 0.31109
Value Function Update Magnitude: 0.23343

Collected Steps per Second: 21,336.78083
Overall Steps per Second: 10,523.42614

Timestep Collection Time: 2.34496
Timestep Consumption Time: 2.40957
PPO Batch Consumption Time: 0.28680
Total Iteration Time: 4.75454

Cumulative Model Updates: 239,276
Cumulative Timesteps: 1,996,198,480

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1996198480...
Checkpoint 1996198480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 60,978.03426
Policy Entropy: 2.24574
Value Function Loss: 0.02384

Mean KL Divergence: 0.00750
SB3 Clip Fraction: 0.07299
Policy Update Magnitude: 0.32191
Value Function Update Magnitude: 0.24026

Collected Steps per Second: 20,631.33025
Overall Steps per Second: 10,185.68616

Timestep Collection Time: 2.42447
Timestep Consumption Time: 2.48634
PPO Batch Consumption Time: 0.29134
Total Iteration Time: 4.91081

Cumulative Model Updates: 239,282
Cumulative Timesteps: 1,996,248,500

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50,995.01826
Policy Entropy: 2.23690
Value Function Loss: 0.02439

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.08101
Policy Update Magnitude: 0.32662
Value Function Update Magnitude: 0.31844

Collected Steps per Second: 21,761.12173
Overall Steps per Second: 10,366.41229

Timestep Collection Time: 2.29804
Timestep Consumption Time: 2.52600
PPO Batch Consumption Time: 0.29245
Total Iteration Time: 4.82404

Cumulative Model Updates: 239,288
Cumulative Timesteps: 1,996,298,508

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1996298508...
Checkpoint 1996298508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55,446.06473
Policy Entropy: 2.24972
Value Function Loss: 0.02127

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.08005
Policy Update Magnitude: 0.32028
Value Function Update Magnitude: 0.35660

Collected Steps per Second: 21,721.41190
Overall Steps per Second: 10,435.10303

Timestep Collection Time: 2.30243
Timestep Consumption Time: 2.49024
PPO Batch Consumption Time: 0.29199
Total Iteration Time: 4.79267

Cumulative Model Updates: 239,294
Cumulative Timesteps: 1,996,348,520

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 71,339.07391
Policy Entropy: 2.26727
Value Function Loss: 0.01814

Mean KL Divergence: 0.00737
SB3 Clip Fraction: 0.06801
Policy Update Magnitude: 0.31130
Value Function Update Magnitude: 0.30595

Collected Steps per Second: 22,154.56292
Overall Steps per Second: 10,721.47839

Timestep Collection Time: 2.25696
Timestep Consumption Time: 2.40676
PPO Batch Consumption Time: 0.27871
Total Iteration Time: 4.66372

Cumulative Model Updates: 239,300
Cumulative Timesteps: 1,996,398,522

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1996398522...
Checkpoint 1996398522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 66,410.07957
Policy Entropy: 2.27994
Value Function Loss: 0.01794

Mean KL Divergence: 0.00676
SB3 Clip Fraction: 0.06533
Policy Update Magnitude: 0.30088
Value Function Update Magnitude: 0.21909

Collected Steps per Second: 22,104.65495
Overall Steps per Second: 10,659.14024

Timestep Collection Time: 2.26323
Timestep Consumption Time: 2.43020
PPO Batch Consumption Time: 0.27862
Total Iteration Time: 4.69344

Cumulative Model Updates: 239,306
Cumulative Timesteps: 1,996,448,550

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47,199.12301
Policy Entropy: 2.28662
Value Function Loss: 0.01689

Mean KL Divergence: 0.00625
SB3 Clip Fraction: 0.05982
Policy Update Magnitude: 0.29555
Value Function Update Magnitude: 0.20712

Collected Steps per Second: 21,989.04645
Overall Steps per Second: 10,450.21473

Timestep Collection Time: 2.27486
Timestep Consumption Time: 2.51184
PPO Batch Consumption Time: 0.29117
Total Iteration Time: 4.78670

Cumulative Model Updates: 239,312
Cumulative Timesteps: 1,996,498,572

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1996498572...
Checkpoint 1996498572 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48,568.26832
Policy Entropy: 2.28333
Value Function Loss: 0.01900

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.07349
Policy Update Magnitude: 0.29793
Value Function Update Magnitude: 0.25051

Collected Steps per Second: 21,418.98323
Overall Steps per Second: 10,357.69204

Timestep Collection Time: 2.33494
Timestep Consumption Time: 2.49355
PPO Batch Consumption Time: 0.29208
Total Iteration Time: 4.82849

Cumulative Model Updates: 239,318
Cumulative Timesteps: 1,996,548,584

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53,422.66932
Policy Entropy: 2.27277
Value Function Loss: 0.01881

Mean KL Divergence: 0.00764
SB3 Clip Fraction: 0.07330
Policy Update Magnitude: 0.30301
Value Function Update Magnitude: 0.31525

Collected Steps per Second: 21,724.24067
Overall Steps per Second: 10,426.88776

Timestep Collection Time: 2.30287
Timestep Consumption Time: 2.49511
PPO Batch Consumption Time: 0.29137
Total Iteration Time: 4.79798

Cumulative Model Updates: 239,324
Cumulative Timesteps: 1,996,598,612

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1996598612...
Checkpoint 1996598612 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 61,375.71999
Policy Entropy: 2.28236
Value Function Loss: 0.01931

Mean KL Divergence: 0.00718
SB3 Clip Fraction: 0.06804
Policy Update Magnitude: 0.30633
Value Function Update Magnitude: 0.33933

Collected Steps per Second: 21,639.99306
Overall Steps per Second: 10,524.94034

Timestep Collection Time: 2.31146
Timestep Consumption Time: 2.44106
PPO Batch Consumption Time: 0.28007
Total Iteration Time: 4.75252

Cumulative Model Updates: 239,330
Cumulative Timesteps: 1,996,648,632

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,382.59235
Policy Entropy: 2.29018
Value Function Loss: 0.01926

Mean KL Divergence: 0.00677
SB3 Clip Fraction: 0.06443
Policy Update Magnitude: 0.31392
Value Function Update Magnitude: 0.34276

Collected Steps per Second: 21,576.95049
Overall Steps per Second: 10,536.09134

Timestep Collection Time: 2.31738
Timestep Consumption Time: 2.42840
PPO Batch Consumption Time: 0.27739
Total Iteration Time: 4.74578

Cumulative Model Updates: 239,336
Cumulative Timesteps: 1,996,698,634

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1996698634...
Checkpoint 1996698634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 51,240.91425
Policy Entropy: 2.26706
Value Function Loss: 0.02076

Mean KL Divergence: 0.00693
SB3 Clip Fraction: 0.06526
Policy Update Magnitude: 0.32621
Value Function Update Magnitude: 0.38547

Collected Steps per Second: 21,241.30095
Overall Steps per Second: 10,469.61184

Timestep Collection Time: 2.35409
Timestep Consumption Time: 2.42202
PPO Batch Consumption Time: 0.27879
Total Iteration Time: 4.77611

Cumulative Model Updates: 239,342
Cumulative Timesteps: 1,996,748,638

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,527.18810
Policy Entropy: 2.24968
Value Function Loss: 0.02294

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.08674
Policy Update Magnitude: 0.33320
Value Function Update Magnitude: 0.38018

Collected Steps per Second: 21,585.20458
Overall Steps per Second: 10,505.36115

Timestep Collection Time: 2.31659
Timestep Consumption Time: 2.44327
PPO Batch Consumption Time: 0.27893
Total Iteration Time: 4.75986

Cumulative Model Updates: 239,348
Cumulative Timesteps: 1,996,798,642

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1996798642...
Checkpoint 1996798642 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 64,823.59714
Policy Entropy: 2.24349
Value Function Loss: 0.02279

Mean KL Divergence: 0.01579
SB3 Clip Fraction: 0.12167
Policy Update Magnitude: 0.30982
Value Function Update Magnitude: 0.33696

Collected Steps per Second: 21,935.91198
Overall Steps per Second: 10,587.45742

Timestep Collection Time: 2.28037
Timestep Consumption Time: 2.44428
PPO Batch Consumption Time: 0.27916
Total Iteration Time: 4.72465

Cumulative Model Updates: 239,354
Cumulative Timesteps: 1,996,848,664

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50,329.78841
Policy Entropy: 2.26316
Value Function Loss: 0.02066

Mean KL Divergence: 0.01280
SB3 Clip Fraction: 0.10702
Policy Update Magnitude: 0.30108
Value Function Update Magnitude: 0.31815

Collected Steps per Second: 21,891.68869
Overall Steps per Second: 10,607.34638

Timestep Collection Time: 2.28534
Timestep Consumption Time: 2.43120
PPO Batch Consumption Time: 0.27796
Total Iteration Time: 4.71654

Cumulative Model Updates: 239,360
Cumulative Timesteps: 1,996,898,694

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1996898694...
Checkpoint 1996898694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,722.96985
Policy Entropy: 2.27776
Value Function Loss: 0.01910

Mean KL Divergence: 0.01665
SB3 Clip Fraction: 0.11784
Policy Update Magnitude: 0.29387
Value Function Update Magnitude: 0.32093

Collected Steps per Second: 22,038.80593
Overall Steps per Second: 10,627.93025

Timestep Collection Time: 2.26918
Timestep Consumption Time: 2.43635
PPO Batch Consumption Time: 0.27772
Total Iteration Time: 4.70553

Cumulative Model Updates: 239,366
Cumulative Timesteps: 1,996,948,704

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,714.17121
Policy Entropy: 2.28160
Value Function Loss: 0.01795

Mean KL Divergence: 0.02310
SB3 Clip Fraction: 0.14581
Policy Update Magnitude: 0.28357
Value Function Update Magnitude: 0.31165

Collected Steps per Second: 21,767.37737
Overall Steps per Second: 10,402.95360

Timestep Collection Time: 2.29821
Timestep Consumption Time: 2.51062
PPO Batch Consumption Time: 0.29470
Total Iteration Time: 4.80883

Cumulative Model Updates: 239,372
Cumulative Timesteps: 1,996,998,730

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1996998730...
Checkpoint 1996998730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 63,298.53639
Policy Entropy: 2.27717
Value Function Loss: 0.01990

Mean KL Divergence: 0.01457
SB3 Clip Fraction: 0.11519
Policy Update Magnitude: 0.30002
Value Function Update Magnitude: 0.31277

Collected Steps per Second: 21,872.25220
Overall Steps per Second: 10,593.44241

Timestep Collection Time: 2.28728
Timestep Consumption Time: 2.43526
PPO Batch Consumption Time: 0.27943
Total Iteration Time: 4.72254

Cumulative Model Updates: 239,378
Cumulative Timesteps: 1,997,048,758

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,237.29332
Policy Entropy: 2.28089
Value Function Loss: 0.02144

Mean KL Divergence: 0.01167
SB3 Clip Fraction: 0.10358
Policy Update Magnitude: 0.32118
Value Function Update Magnitude: 0.36738

Collected Steps per Second: 21,779.12373
Overall Steps per Second: 10,490.94169

Timestep Collection Time: 2.29761
Timestep Consumption Time: 2.47222
PPO Batch Consumption Time: 0.28492
Total Iteration Time: 4.76983

Cumulative Model Updates: 239,384
Cumulative Timesteps: 1,997,098,798

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1997098798...
Checkpoint 1997098798 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,273.33226
Policy Entropy: 2.25658
Value Function Loss: 0.02369

Mean KL Divergence: 0.01110
SB3 Clip Fraction: 0.09878
Policy Update Magnitude: 0.33080
Value Function Update Magnitude: 0.37884

Collected Steps per Second: 21,637.42880
Overall Steps per Second: 10,565.77956

Timestep Collection Time: 2.31164
Timestep Consumption Time: 2.42232
PPO Batch Consumption Time: 0.27883
Total Iteration Time: 4.73396

Cumulative Model Updates: 239,390
Cumulative Timesteps: 1,997,148,816

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,572.12590
Policy Entropy: 2.27439
Value Function Loss: 0.02471

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.07881
Policy Update Magnitude: 0.33841
Value Function Update Magnitude: 0.37393

Collected Steps per Second: 21,464.74802
Overall Steps per Second: 10,504.31839

Timestep Collection Time: 2.32996
Timestep Consumption Time: 2.43113
PPO Batch Consumption Time: 0.27856
Total Iteration Time: 4.76109

Cumulative Model Updates: 239,396
Cumulative Timesteps: 1,997,198,828

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1997198828...
Checkpoint 1997198828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,023.27848
Policy Entropy: 2.24061
Value Function Loss: 0.02251

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.08543
Policy Update Magnitude: 0.33582
Value Function Update Magnitude: 0.32503

Collected Steps per Second: 21,098.36996
Overall Steps per Second: 10,245.73529

Timestep Collection Time: 2.37184
Timestep Consumption Time: 2.51234
PPO Batch Consumption Time: 0.29440
Total Iteration Time: 4.88418

Cumulative Model Updates: 239,402
Cumulative Timesteps: 1,997,248,870

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,018.91488
Policy Entropy: 2.26358
Value Function Loss: 0.02198

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.08038
Policy Update Magnitude: 0.32240
Value Function Update Magnitude: 0.29822

Collected Steps per Second: 21,610.17063
Overall Steps per Second: 10,425.90286

Timestep Collection Time: 2.31548
Timestep Consumption Time: 2.48391
PPO Batch Consumption Time: 0.28594
Total Iteration Time: 4.79939

Cumulative Model Updates: 239,408
Cumulative Timesteps: 1,997,298,908

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1997298908...
Checkpoint 1997298908 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,203.56280
Policy Entropy: 2.25139
Value Function Loss: 0.01951

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.07843
Policy Update Magnitude: 0.31774
Value Function Update Magnitude: 0.30594

Collected Steps per Second: 21,064.88574
Overall Steps per Second: 10,377.85942

Timestep Collection Time: 2.37599
Timestep Consumption Time: 2.44678
PPO Batch Consumption Time: 0.29103
Total Iteration Time: 4.82277

Cumulative Model Updates: 239,414
Cumulative Timesteps: 1,997,348,958

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,376.28686
Policy Entropy: 2.24794
Value Function Loss: 0.02259

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.08723
Policy Update Magnitude: 0.32696
Value Function Update Magnitude: 0.32265

Collected Steps per Second: 21,565.23373
Overall Steps per Second: 10,704.01605

Timestep Collection Time: 2.32003
Timestep Consumption Time: 2.35410
PPO Batch Consumption Time: 0.27908
Total Iteration Time: 4.67413

Cumulative Model Updates: 239,420
Cumulative Timesteps: 1,997,398,990

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1997398990...
Checkpoint 1997398990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,875.65271
Policy Entropy: 2.24806
Value Function Loss: 0.01942

Mean KL Divergence: 0.01244
SB3 Clip Fraction: 0.10201
Policy Update Magnitude: 0.32753
Value Function Update Magnitude: 0.37057

Collected Steps per Second: 21,366.91977
Overall Steps per Second: 10,658.61058

Timestep Collection Time: 2.34063
Timestep Consumption Time: 2.35154
PPO Batch Consumption Time: 0.27937
Total Iteration Time: 4.69217

Cumulative Model Updates: 239,426
Cumulative Timesteps: 1,997,449,002

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,962.32681
Policy Entropy: 2.23340
Value Function Loss: 0.02125

Mean KL Divergence: 0.01249
SB3 Clip Fraction: 0.10026
Policy Update Magnitude: 0.32307
Value Function Update Magnitude: 0.39704

Collected Steps per Second: 21,527.96762
Overall Steps per Second: 10,556.97797

Timestep Collection Time: 2.32395
Timestep Consumption Time: 2.41509
PPO Batch Consumption Time: 0.27798
Total Iteration Time: 4.73905

Cumulative Model Updates: 239,432
Cumulative Timesteps: 1,997,499,032

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1997499032...
Checkpoint 1997499032 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43,676.60988
Policy Entropy: 2.23874
Value Function Loss: 0.01910

Mean KL Divergence: 0.01113
SB3 Clip Fraction: 0.09009
Policy Update Magnitude: 0.32224
Value Function Update Magnitude: 0.38997

Collected Steps per Second: 21,929.38140
Overall Steps per Second: 10,556.67099

Timestep Collection Time: 2.28123
Timestep Consumption Time: 2.45757
PPO Batch Consumption Time: 0.28784
Total Iteration Time: 4.73880

Cumulative Model Updates: 239,438
Cumulative Timesteps: 1,997,549,058

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,890.03035
Policy Entropy: 2.23588
Value Function Loss: 0.02102

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.08298
Policy Update Magnitude: 0.32233
Value Function Update Magnitude: 0.38067

Collected Steps per Second: 22,005.29488
Overall Steps per Second: 10,533.76142

Timestep Collection Time: 2.27227
Timestep Consumption Time: 2.47456
PPO Batch Consumption Time: 0.29306
Total Iteration Time: 4.74683

Cumulative Model Updates: 239,444
Cumulative Timesteps: 1,997,599,060

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1997599060...
Checkpoint 1997599060 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,941.74629
Policy Entropy: 2.25294
Value Function Loss: 0.01977

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.07651
Policy Update Magnitude: 0.31673
Value Function Update Magnitude: 0.33159

Collected Steps per Second: 21,867.56317
Overall Steps per Second: 10,638.88848

Timestep Collection Time: 2.28722
Timestep Consumption Time: 2.41402
PPO Batch Consumption Time: 0.27679
Total Iteration Time: 4.70124

Cumulative Model Updates: 239,450
Cumulative Timesteps: 1,997,649,076

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,565.17080
Policy Entropy: 2.25286
Value Function Loss: 0.02271

Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.07422
Policy Update Magnitude: 0.32672
Value Function Update Magnitude: 0.28725

Collected Steps per Second: 21,533.72686
Overall Steps per Second: 10,397.61025

Timestep Collection Time: 2.32231
Timestep Consumption Time: 2.48726
PPO Batch Consumption Time: 0.29465
Total Iteration Time: 4.80957

Cumulative Model Updates: 239,456
Cumulative Timesteps: 1,997,699,084

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1997699084...
Checkpoint 1997699084 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 66,190.14788
Policy Entropy: 2.26999
Value Function Loss: 0.02200

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.07377
Policy Update Magnitude: 0.32989
Value Function Update Magnitude: 0.32858

Collected Steps per Second: 21,152.49022
Overall Steps per Second: 10,274.70268

Timestep Collection Time: 2.36511
Timestep Consumption Time: 2.50393
PPO Batch Consumption Time: 0.29394
Total Iteration Time: 4.86905

Cumulative Model Updates: 239,462
Cumulative Timesteps: 1,997,749,112

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 64,460.57465
Policy Entropy: 2.26176
Value Function Loss: 0.02041

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.07307
Policy Update Magnitude: 0.31658
Value Function Update Magnitude: 0.33749

Collected Steps per Second: 21,806.56370
Overall Steps per Second: 10,421.81857

Timestep Collection Time: 2.29335
Timestep Consumption Time: 2.50524
PPO Batch Consumption Time: 0.29274
Total Iteration Time: 4.79859

Cumulative Model Updates: 239,468
Cumulative Timesteps: 1,997,799,122

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1997799122...
Checkpoint 1997799122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55,848.01204
Policy Entropy: 2.26918
Value Function Loss: 0.01936

Mean KL Divergence: 0.00723
SB3 Clip Fraction: 0.06905
Policy Update Magnitude: 0.30764
Value Function Update Magnitude: 0.32122

Collected Steps per Second: 21,595.82023
Overall Steps per Second: 10,519.02420

Timestep Collection Time: 2.31582
Timestep Consumption Time: 2.43861
PPO Batch Consumption Time: 0.27935
Total Iteration Time: 4.75443

Cumulative Model Updates: 239,474
Cumulative Timesteps: 1,997,849,134

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,099.70905
Policy Entropy: 2.24580
Value Function Loss: 0.01998

Mean KL Divergence: 0.00692
SB3 Clip Fraction: 0.06890
Policy Update Magnitude: 0.31351
Value Function Update Magnitude: 0.32421

Collected Steps per Second: 21,746.43411
Overall Steps per Second: 10,536.71989

Timestep Collection Time: 2.29932
Timestep Consumption Time: 2.44618
PPO Batch Consumption Time: 0.27799
Total Iteration Time: 4.74550

Cumulative Model Updates: 239,480
Cumulative Timesteps: 1,997,899,136

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1997899136...
Checkpoint 1997899136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,972.53110
Policy Entropy: 2.25740
Value Function Loss: 0.02360

Mean KL Divergence: 0.00762
SB3 Clip Fraction: 0.07374
Policy Update Magnitude: 0.32205
Value Function Update Magnitude: 0.33601

Collected Steps per Second: 22,189.77962
Overall Steps per Second: 10,592.30529

Timestep Collection Time: 2.25410
Timestep Consumption Time: 2.46801
PPO Batch Consumption Time: 0.27920
Total Iteration Time: 4.72211

Cumulative Model Updates: 239,486
Cumulative Timesteps: 1,997,949,154

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47,866.20341
Policy Entropy: 2.28504
Value Function Loss: 0.02193

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.07133
Policy Update Magnitude: 0.32083
Value Function Update Magnitude: 0.36951

Collected Steps per Second: 22,106.50915
Overall Steps per Second: 10,458.60213

Timestep Collection Time: 2.26232
Timestep Consumption Time: 2.51958
PPO Batch Consumption Time: 0.29429
Total Iteration Time: 4.78190

Cumulative Model Updates: 239,492
Cumulative Timesteps: 1,997,999,166

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1997999166...
Checkpoint 1997999166 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,960.21949
Policy Entropy: 2.30331
Value Function Loss: 0.02034

Mean KL Divergence: 0.00692
SB3 Clip Fraction: 0.06590
Policy Update Magnitude: 0.30856
Value Function Update Magnitude: 0.35855

Collected Steps per Second: 21,956.36826
Overall Steps per Second: 10,609.97175

Timestep Collection Time: 2.27761
Timestep Consumption Time: 2.43569
PPO Batch Consumption Time: 0.27892
Total Iteration Time: 4.71330

Cumulative Model Updates: 239,498
Cumulative Timesteps: 1,998,049,174

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,030.79064
Policy Entropy: 2.29603
Value Function Loss: 0.01696

Mean KL Divergence: 0.00650
SB3 Clip Fraction: 0.06407
Policy Update Magnitude: 0.30189
Value Function Update Magnitude: 0.31047

Collected Steps per Second: 21,922.09239
Overall Steps per Second: 10,463.82046

Timestep Collection Time: 2.28199
Timestep Consumption Time: 2.49886
PPO Batch Consumption Time: 0.29053
Total Iteration Time: 4.78085

Cumulative Model Updates: 239,504
Cumulative Timesteps: 1,998,099,200

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1998099200...
Checkpoint 1998099200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 111,846.18900
Policy Entropy: 2.28405
Value Function Loss: 0.02100

Mean KL Divergence: 0.00658
SB3 Clip Fraction: 0.06442
Policy Update Magnitude: 0.31398
Value Function Update Magnitude: 0.29341

Collected Steps per Second: 21,908.03427
Overall Steps per Second: 10,618.99888

Timestep Collection Time: 2.28272
Timestep Consumption Time: 2.42676
PPO Batch Consumption Time: 0.27913
Total Iteration Time: 4.70948

Cumulative Model Updates: 239,510
Cumulative Timesteps: 1,998,149,210

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92,028.84294
Policy Entropy: 2.30348
Value Function Loss: 0.01958

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.07342
Policy Update Magnitude: 0.31495
Value Function Update Magnitude: 0.31662

Collected Steps per Second: 20,587.93380
Overall Steps per Second: 10,082.09870

Timestep Collection Time: 2.43104
Timestep Consumption Time: 2.53321
PPO Batch Consumption Time: 0.29444
Total Iteration Time: 4.96424

Cumulative Model Updates: 239,516
Cumulative Timesteps: 1,998,199,260

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 1998199260...
Checkpoint 1998199260 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 81,275.96382
Policy Entropy: 2.29692
Value Function Loss: 0.01988

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.07950
Policy Update Magnitude: 0.30909
Value Function Update Magnitude: 0.30358

Collected Steps per Second: 21,153.68336
Overall Steps per Second: 10,280.88580

Timestep Collection Time: 2.36375
Timestep Consumption Time: 2.49984
PPO Batch Consumption Time: 0.29332
Total Iteration Time: 4.86359

Cumulative Model Updates: 239,522
Cumulative Timesteps: 1,998,249,262

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50,330.94987
Policy Entropy: 2.29495
Value Function Loss: 0.02038

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.07465
Policy Update Magnitude: 0.31634
Value Function Update Magnitude: 0.28489

Collected Steps per Second: 21,018.10416
Overall Steps per Second: 10,370.27811

Timestep Collection Time: 2.38090
Timestep Consumption Time: 2.44462
PPO Batch Consumption Time: 0.29395
Total Iteration Time: 4.82552

Cumulative Model Updates: 239,528
Cumulative Timesteps: 1,998,299,304

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1998299304...
Checkpoint 1998299304 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,185.45357
Policy Entropy: 2.28772
Value Function Loss: 0.01965

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.07183
Policy Update Magnitude: 0.31789
Value Function Update Magnitude: 0.34222

Collected Steps per Second: 20,755.71525
Overall Steps per Second: 10,325.21218

Timestep Collection Time: 2.40907
Timestep Consumption Time: 2.43364
PPO Batch Consumption Time: 0.29257
Total Iteration Time: 4.84271

Cumulative Model Updates: 239,534
Cumulative Timesteps: 1,998,349,306

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63,363.28135
Policy Entropy: 2.28546
Value Function Loss: 0.01822

Mean KL Divergence: 0.00752
SB3 Clip Fraction: 0.06431
Policy Update Magnitude: 0.31000
Value Function Update Magnitude: 0.37131

Collected Steps per Second: 21,594.51121
Overall Steps per Second: 10,480.44021

Timestep Collection Time: 2.31550
Timestep Consumption Time: 2.45549
PPO Batch Consumption Time: 0.29156
Total Iteration Time: 4.77098

Cumulative Model Updates: 239,540
Cumulative Timesteps: 1,998,399,308

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1998399308...
Checkpoint 1998399308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 67,824.26366
Policy Entropy: 2.27664
Value Function Loss: 0.01830

Mean KL Divergence: 0.00686
SB3 Clip Fraction: 0.06372
Policy Update Magnitude: 0.30930
Value Function Update Magnitude: 0.35074

Collected Steps per Second: 21,361.76625
Overall Steps per Second: 10,472.59145

Timestep Collection Time: 2.34091
Timestep Consumption Time: 2.43403
PPO Batch Consumption Time: 0.28472
Total Iteration Time: 4.77494

Cumulative Model Updates: 239,546
Cumulative Timesteps: 1,998,449,314

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51,485.77777
Policy Entropy: 2.27437
Value Function Loss: 0.01879

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.08053
Policy Update Magnitude: 0.30964
Value Function Update Magnitude: 0.33462

Collected Steps per Second: 21,834.13736
Overall Steps per Second: 10,456.61966

Timestep Collection Time: 2.29164
Timestep Consumption Time: 2.49346
PPO Batch Consumption Time: 0.29331
Total Iteration Time: 4.78510

Cumulative Model Updates: 239,552
Cumulative Timesteps: 1,998,499,350

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1998499350...
Checkpoint 1998499350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,882.14880
Policy Entropy: 2.29146
Value Function Loss: 0.02104

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.08098
Policy Update Magnitude: 0.30739
Value Function Update Magnitude: 0.34328

Collected Steps per Second: 21,485.36092
Overall Steps per Second: 10,575.36855

Timestep Collection Time: 2.32810
Timestep Consumption Time: 2.40176
PPO Batch Consumption Time: 0.27930
Total Iteration Time: 4.72986

Cumulative Model Updates: 239,558
Cumulative Timesteps: 1,998,549,370

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66,087.77537
Policy Entropy: 2.29514
Value Function Loss: 0.02022

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.07609
Policy Update Magnitude: 0.30606
Value Function Update Magnitude: 0.34320

Collected Steps per Second: 22,182.25616
Overall Steps per Second: 10,527.88203

Timestep Collection Time: 2.25514
Timestep Consumption Time: 2.49644
PPO Batch Consumption Time: 0.28922
Total Iteration Time: 4.75157

Cumulative Model Updates: 239,564
Cumulative Timesteps: 1,998,599,394

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1998599394...
Checkpoint 1998599394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 67,072.14385
Policy Entropy: 2.29609
Value Function Loss: 0.02309

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.07693
Policy Update Magnitude: 0.31327
Value Function Update Magnitude: 0.34004

Collected Steps per Second: 21,575.44861
Overall Steps per Second: 10,555.24880

Timestep Collection Time: 2.31819
Timestep Consumption Time: 2.42031
PPO Batch Consumption Time: 0.27832
Total Iteration Time: 4.73850

Cumulative Model Updates: 239,570
Cumulative Timesteps: 1,998,649,410

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45,849.38293
Policy Entropy: 2.29491
Value Function Loss: 0.02146

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.08054
Policy Update Magnitude: 0.31974
Value Function Update Magnitude: 0.34912

Collected Steps per Second: 22,104.97814
Overall Steps per Second: 10,523.21678

Timestep Collection Time: 2.26284
Timestep Consumption Time: 2.49046
PPO Batch Consumption Time: 0.28898
Total Iteration Time: 4.75330

Cumulative Model Updates: 239,576
Cumulative Timesteps: 1,998,699,430

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1998699430...
Checkpoint 1998699430 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,516.92511
Policy Entropy: 2.30356
Value Function Loss: 0.02005

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.08091
Policy Update Magnitude: 0.30862
Value Function Update Magnitude: 0.33897

Collected Steps per Second: 21,054.66556
Overall Steps per Second: 10,220.14341

Timestep Collection Time: 2.37544
Timestep Consumption Time: 2.51823
PPO Batch Consumption Time: 0.29452
Total Iteration Time: 4.89367

Cumulative Model Updates: 239,582
Cumulative Timesteps: 1,998,749,444

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,930.64259
Policy Entropy: 2.31306
Value Function Loss: 0.01962

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.07970
Policy Update Magnitude: 0.31010
Value Function Update Magnitude: 0.32973

Collected Steps per Second: 21,830.55440
Overall Steps per Second: 10,457.34450

Timestep Collection Time: 2.29128
Timestep Consumption Time: 2.49196
PPO Batch Consumption Time: 0.28958
Total Iteration Time: 4.78324

Cumulative Model Updates: 239,588
Cumulative Timesteps: 1,998,799,464

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1998799464...
Checkpoint 1998799464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 59,561.62895
Policy Entropy: 2.31275
Value Function Loss: 0.02018

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.07756
Policy Update Magnitude: 0.30566
Value Function Update Magnitude: 0.31874

Collected Steps per Second: 21,558.66055
Overall Steps per Second: 10,549.36587

Timestep Collection Time: 2.31972
Timestep Consumption Time: 2.42085
PPO Batch Consumption Time: 0.27780
Total Iteration Time: 4.74057

Cumulative Model Updates: 239,594
Cumulative Timesteps: 1,998,849,474

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47,812.50160
Policy Entropy: 2.31926
Value Function Loss: 0.02122

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.07287
Policy Update Magnitude: 0.31091
Value Function Update Magnitude: 0.30068

Collected Steps per Second: 21,664.24618
Overall Steps per Second: 10,494.26609

Timestep Collection Time: 2.30980
Timestep Consumption Time: 2.45852
PPO Batch Consumption Time: 0.27915
Total Iteration Time: 4.76832

Cumulative Model Updates: 239,600
Cumulative Timesteps: 1,998,899,514

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1998899514...
Checkpoint 1998899514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55,731.22240
Policy Entropy: 2.30724
Value Function Loss: 0.02121

Mean KL Divergence: 0.00739
SB3 Clip Fraction: 0.07120
Policy Update Magnitude: 0.31058
Value Function Update Magnitude: 0.28464

Collected Steps per Second: 21,526.11504
Overall Steps per Second: 10,343.38807

Timestep Collection Time: 2.32322
Timestep Consumption Time: 2.51175
PPO Batch Consumption Time: 0.29308
Total Iteration Time: 4.83497

Cumulative Model Updates: 239,606
Cumulative Timesteps: 1,998,949,524

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55,191.83747
Policy Entropy: 2.30012
Value Function Loss: 0.02356

Mean KL Divergence: 0.00726
SB3 Clip Fraction: 0.06827
Policy Update Magnitude: 0.32049
Value Function Update Magnitude: 0.31688

Collected Steps per Second: 22,247.01030
Overall Steps per Second: 10,474.73861

Timestep Collection Time: 2.24875
Timestep Consumption Time: 2.52731
PPO Batch Consumption Time: 0.29262
Total Iteration Time: 4.77606

Cumulative Model Updates: 239,612
Cumulative Timesteps: 1,998,999,552

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1998999552...
Checkpoint 1998999552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,876.04802
Policy Entropy: 2.32046
Value Function Loss: 0.02345

Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.07380
Policy Update Magnitude: 0.32010
Value Function Update Magnitude: 0.32470

Collected Steps per Second: 22,088.43149
Overall Steps per Second: 10,495.54068

Timestep Collection Time: 2.26571
Timestep Consumption Time: 2.50260
PPO Batch Consumption Time: 0.28987
Total Iteration Time: 4.76831

Cumulative Model Updates: 239,618
Cumulative Timesteps: 1,999,049,598

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,450.13460
Policy Entropy: 2.33275
Value Function Loss: 0.02235

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.07042
Policy Update Magnitude: 0.31628
Value Function Update Magnitude: 0.34943

Collected Steps per Second: 21,608.57408
Overall Steps per Second: 10,525.21558

Timestep Collection Time: 2.31519
Timestep Consumption Time: 2.43796
PPO Batch Consumption Time: 0.29366
Total Iteration Time: 4.75316

Cumulative Model Updates: 239,624
Cumulative Timesteps: 1,999,099,626

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1999099626...
Checkpoint 1999099626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 54,862.69912
Policy Entropy: 2.33570
Value Function Loss: 0.02170

Mean KL Divergence: 0.00752
SB3 Clip Fraction: 0.06917
Policy Update Magnitude: 0.32288
Value Function Update Magnitude: 0.38736

Collected Steps per Second: 21,121.18316
Overall Steps per Second: 10,612.28036

Timestep Collection Time: 2.36758
Timestep Consumption Time: 2.34451
PPO Batch Consumption Time: 0.27771
Total Iteration Time: 4.71209

Cumulative Model Updates: 239,630
Cumulative Timesteps: 1,999,149,632

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58,123.79810
Policy Entropy: 2.30288
Value Function Loss: 0.02111

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.07600
Policy Update Magnitude: 0.32412
Value Function Update Magnitude: 0.38741

Collected Steps per Second: 21,542.65942
Overall Steps per Second: 10,550.51054

Timestep Collection Time: 2.32190
Timestep Consumption Time: 2.41910
PPO Batch Consumption Time: 0.29159
Total Iteration Time: 4.74100

Cumulative Model Updates: 239,636
Cumulative Timesteps: 1,999,199,652

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1999199652...
Checkpoint 1999199652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 81,288.47655
Policy Entropy: 2.28069
Value Function Loss: 0.02182

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.07495
Policy Update Magnitude: 0.31794
Value Function Update Magnitude: 0.38950

Collected Steps per Second: 21,363.31081
Overall Steps per Second: 10,552.12381

Timestep Collection Time: 2.34149
Timestep Consumption Time: 2.39898
PPO Batch Consumption Time: 0.27686
Total Iteration Time: 4.74047

Cumulative Model Updates: 239,642
Cumulative Timesteps: 1,999,249,674

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52,240.68907
Policy Entropy: 2.26185
Value Function Loss: 0.02162

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.07271
Policy Update Magnitude: 0.31850
Value Function Update Magnitude: 0.39110

Collected Steps per Second: 22,109.71600
Overall Steps per Second: 10,584.16463

Timestep Collection Time: 2.26235
Timestep Consumption Time: 2.46357
PPO Batch Consumption Time: 0.28860
Total Iteration Time: 4.72593

Cumulative Model Updates: 239,648
Cumulative Timesteps: 1,999,299,694

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1999299694...
Checkpoint 1999299694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,783.58068
Policy Entropy: 2.27228
Value Function Loss: 0.01940

Mean KL Divergence: 0.00695
SB3 Clip Fraction: 0.06742
Policy Update Magnitude: 0.31294
Value Function Update Magnitude: 0.37193

Collected Steps per Second: 21,559.60574
Overall Steps per Second: 10,472.57385

Timestep Collection Time: 2.31989
Timestep Consumption Time: 2.45601
PPO Batch Consumption Time: 0.28921
Total Iteration Time: 4.77590

Cumulative Model Updates: 239,654
Cumulative Timesteps: 1,999,349,710

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49,038.45266
Policy Entropy: 2.29689
Value Function Loss: 0.01769

Mean KL Divergence: 0.00681
SB3 Clip Fraction: 0.06551
Policy Update Magnitude: 0.29889
Value Function Update Magnitude: 0.31766

Collected Steps per Second: 21,700.22800
Overall Steps per Second: 10,439.91907

Timestep Collection Time: 2.30532
Timestep Consumption Time: 2.48648
PPO Batch Consumption Time: 0.28746
Total Iteration Time: 4.79180

Cumulative Model Updates: 239,660
Cumulative Timesteps: 1,999,399,736

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1999399736...
Checkpoint 1999399736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,040.07654
Policy Entropy: 2.29401
Value Function Loss: 0.01799

Mean KL Divergence: 0.00630
SB3 Clip Fraction: 0.06252
Policy Update Magnitude: 0.29167
Value Function Update Magnitude: 0.23058

Collected Steps per Second: 21,026.19929
Overall Steps per Second: 10,208.53056

Timestep Collection Time: 2.37827
Timestep Consumption Time: 2.52018
PPO Batch Consumption Time: 0.29339
Total Iteration Time: 4.89845

Cumulative Model Updates: 239,666
Cumulative Timesteps: 1,999,449,742

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45,803.25665
Policy Entropy: 2.29061
Value Function Loss: 0.01805

Mean KL Divergence: 0.00677
SB3 Clip Fraction: 0.06540
Policy Update Magnitude: 0.29176
Value Function Update Magnitude: 0.20390

Collected Steps per Second: 21,392.78660
Overall Steps per Second: 10,487.98493

Timestep Collection Time: 2.33920
Timestep Consumption Time: 2.43216
PPO Batch Consumption Time: 0.27789
Total Iteration Time: 4.77136

Cumulative Model Updates: 239,672
Cumulative Timesteps: 1,999,499,784

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1999499784...
Checkpoint 1999499784 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43,960.59253
Policy Entropy: 2.29554
Value Function Loss: 0.01893

Mean KL Divergence: 0.00699
SB3 Clip Fraction: 0.06731
Policy Update Magnitude: 0.29451
Value Function Update Magnitude: 0.19770

Collected Steps per Second: 21,256.15529
Overall Steps per Second: 10,299.60705

Timestep Collection Time: 2.35245
Timestep Consumption Time: 2.50249
PPO Batch Consumption Time: 0.29180
Total Iteration Time: 4.85494

Cumulative Model Updates: 239,678
Cumulative Timesteps: 1,999,549,788

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,960.59253
Policy Entropy: 2.30806
Value Function Loss: 0.01752

Mean KL Divergence: 0.00743
SB3 Clip Fraction: 0.06968
Policy Update Magnitude: 0.28877
Value Function Update Magnitude: 0.18270

Collected Steps per Second: 22,126.12866
Overall Steps per Second: 10,374.60628

Timestep Collection Time: 2.26104
Timestep Consumption Time: 2.56112
PPO Batch Consumption Time: 0.29271
Total Iteration Time: 4.82216

Cumulative Model Updates: 239,684
Cumulative Timesteps: 1,999,599,816

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1999599816...
Checkpoint 1999599816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 61,156.61843
Policy Entropy: 2.30033
Value Function Loss: 0.01916

Mean KL Divergence: 0.00763
SB3 Clip Fraction: 0.07005
Policy Update Magnitude: 0.29037
Value Function Update Magnitude: 0.21522

Collected Steps per Second: 21,844.18542
Overall Steps per Second: 10,549.64093

Timestep Collection Time: 2.29031
Timestep Consumption Time: 2.45203
PPO Batch Consumption Time: 0.27858
Total Iteration Time: 4.74234

Cumulative Model Updates: 239,690
Cumulative Timesteps: 1,999,649,846

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52,125.83607
Policy Entropy: 2.28635
Value Function Loss: 0.01762

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.07220
Policy Update Magnitude: 0.29590
Value Function Update Magnitude: 0.21055

Collected Steps per Second: 22,124.99120
Overall Steps per Second: 10,510.06324

Timestep Collection Time: 2.25998
Timestep Consumption Time: 2.49756
PPO Batch Consumption Time: 0.29280
Total Iteration Time: 4.75754

Cumulative Model Updates: 239,696
Cumulative Timesteps: 1,999,699,848

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1999699848...
Checkpoint 1999699848 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 60,157.05795
Policy Entropy: 2.27861
Value Function Loss: 0.01842

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.07031
Policy Update Magnitude: 0.30254
Value Function Update Magnitude: 0.29093

Collected Steps per Second: 21,713.55344
Overall Steps per Second: 10,550.44838

Timestep Collection Time: 2.30345
Timestep Consumption Time: 2.43721
PPO Batch Consumption Time: 0.27966
Total Iteration Time: 4.74065

Cumulative Model Updates: 239,702
Cumulative Timesteps: 1,999,749,864

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62,860.92832
Policy Entropy: 2.27706
Value Function Loss: 0.01883

Mean KL Divergence: 0.00763
SB3 Clip Fraction: 0.07115
Policy Update Magnitude: 0.30732
Value Function Update Magnitude: 0.33598

Collected Steps per Second: 22,156.43926
Overall Steps per Second: 10,509.69653

Timestep Collection Time: 2.25668
Timestep Consumption Time: 2.50083
PPO Batch Consumption Time: 0.28997
Total Iteration Time: 4.75751

Cumulative Model Updates: 239,708
Cumulative Timesteps: 1,999,799,864

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1999799864...
Checkpoint 1999799864 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 53,312.02390
Policy Entropy: 2.28520
Value Function Loss: 0.01923

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.07700
Policy Update Magnitude: 0.31250
Value Function Update Magnitude: 0.33715

Collected Steps per Second: 21,704.76308
Overall Steps per Second: 10,567.49523

Timestep Collection Time: 2.30521
Timestep Consumption Time: 2.42950
PPO Batch Consumption Time: 0.27874
Total Iteration Time: 4.73471

Cumulative Model Updates: 239,714
Cumulative Timesteps: 1,999,849,898

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,019.65196
Policy Entropy: 2.29628
Value Function Loss: 0.01805

Mean KL Divergence: 0.00735
SB3 Clip Fraction: 0.06920
Policy Update Magnitude: 0.30915
Value Function Update Magnitude: 0.32018

Collected Steps per Second: 22,271.16657
Overall Steps per Second: 10,508.83523

Timestep Collection Time: 2.24604
Timestep Consumption Time: 2.51395
PPO Batch Consumption Time: 0.29292
Total Iteration Time: 4.75999

Cumulative Model Updates: 239,720
Cumulative Timesteps: 1,999,899,920

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1999899920...
Checkpoint 1999899920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,656.87007
Policy Entropy: 2.29718
Value Function Loss: 0.01675

Mean KL Divergence: 0.00680
SB3 Clip Fraction: 0.06321
Policy Update Magnitude: 0.29477
Value Function Update Magnitude: 0.29765

Collected Steps per Second: 21,250.99188
Overall Steps per Second: 10,308.68878

Timestep Collection Time: 2.35387
Timestep Consumption Time: 2.49854
PPO Batch Consumption Time: 0.29148
Total Iteration Time: 4.85241

Cumulative Model Updates: 239,726
Cumulative Timesteps: 1,999,949,942

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,566.24312
Policy Entropy: 2.28011
Value Function Loss: 0.01826

Mean KL Divergence: 0.00702
SB3 Clip Fraction: 0.06731
Policy Update Magnitude: 0.30566
Value Function Update Magnitude: 0.28285

Collected Steps per Second: 21,870.80165
Overall Steps per Second: 10,382.65440

Timestep Collection Time: 2.28743
Timestep Consumption Time: 2.53099
PPO Batch Consumption Time: 0.29341
Total Iteration Time: 4.81842

Cumulative Model Updates: 239,732
Cumulative Timesteps: 1,999,999,970

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1999999970...
Checkpoint 1999999970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,566.48888
Policy Entropy: 2.27224
Value Function Loss: 0.01915

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.07621
Policy Update Magnitude: 0.31206
Value Function Update Magnitude: 0.29681

Collected Steps per Second: 21,641.00437
Overall Steps per Second: 10,505.52621

Timestep Collection Time: 2.31145
Timestep Consumption Time: 2.45005
PPO Batch Consumption Time: 0.27967
Total Iteration Time: 4.76149

Cumulative Model Updates: 239,738
Cumulative Timesteps: 2,000,049,992

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51,094.29072
Policy Entropy: 2.26822
Value Function Loss: 0.01767

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.07415
Policy Update Magnitude: 0.30989
Value Function Update Magnitude: 0.32167

Collected Steps per Second: 21,116.75809
Overall Steps per Second: 10,186.68488

Timestep Collection Time: 2.36864
Timestep Consumption Time: 2.54150
PPO Batch Consumption Time: 0.29320
Total Iteration Time: 4.91014

Cumulative Model Updates: 239,744
Cumulative Timesteps: 2,000,100,010

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2000100010...
Checkpoint 2000100010 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 93,213.52091
Policy Entropy: 2.27074
Value Function Loss: 0.01763

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.07453
Policy Update Magnitude: 0.30389
Value Function Update Magnitude: 0.31683

Collected Steps per Second: 21,389.68176
Overall Steps per Second: 10,492.61143

Timestep Collection Time: 2.33804
Timestep Consumption Time: 2.42817
PPO Batch Consumption Time: 0.27859
Total Iteration Time: 4.76621

Cumulative Model Updates: 239,750
Cumulative Timesteps: 2,000,150,020

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79,730.47407
Policy Entropy: 2.26488
Value Function Loss: 0.01725

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.08381
Policy Update Magnitude: 0.30162
Value Function Update Magnitude: 0.30573

Collected Steps per Second: 22,109.29691
Overall Steps per Second: 10,607.21854

Timestep Collection Time: 2.26348
Timestep Consumption Time: 2.45444
PPO Batch Consumption Time: 0.27705
Total Iteration Time: 4.71792

Cumulative Model Updates: 239,756
Cumulative Timesteps: 2,000,200,064

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 2000200064...
Checkpoint 2000200064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55,525.01157
Policy Entropy: 2.26421
Value Function Loss: 0.01824

Mean KL Divergence: 0.01112
SB3 Clip Fraction: 0.09783
Policy Update Magnitude: 0.29235
Value Function Update Magnitude: 0.28799

Collected Steps per Second: 21,961.98664
Overall Steps per Second: 10,626.14340

Timestep Collection Time: 2.27794
Timestep Consumption Time: 2.43008
PPO Batch Consumption Time: 0.27713
Total Iteration Time: 4.70801

Cumulative Model Updates: 239,762
Cumulative Timesteps: 2,000,250,092

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47,784.31815
Policy Entropy: 2.27228
Value Function Loss: 0.01978

Mean KL Divergence: 0.01114
SB3 Clip Fraction: 0.09949
Policy Update Magnitude: 0.28916
Value Function Update Magnitude: 0.29357

Collected Steps per Second: 22,244.17387
Overall Steps per Second: 10,540.36853

Timestep Collection Time: 2.24787
Timestep Consumption Time: 2.49599
PPO Batch Consumption Time: 0.29088
Total Iteration Time: 4.74386

Cumulative Model Updates: 239,768
Cumulative Timesteps: 2,000,300,094

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2000300094...
Checkpoint 2000300094 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,977.65426
Policy Entropy: 2.27512
Value Function Loss: 0.01994

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.08680
Policy Update Magnitude: 0.30025
Value Function Update Magnitude: 0.31582

Collected Steps per Second: 21,727.35845
Overall Steps per Second: 10,473.35375

Timestep Collection Time: 2.30189
Timestep Consumption Time: 2.47347
PPO Batch Consumption Time: 0.28789
Total Iteration Time: 4.77536

Cumulative Model Updates: 239,774
Cumulative Timesteps: 2,000,350,108

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,044.78990
Policy Entropy: 2.30036
Value Function Loss: 0.02002

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.07552
Policy Update Magnitude: 0.30205
Value Function Update Magnitude: 0.30053

Collected Steps per Second: 21,503.93090
Overall Steps per Second: 10,516.20622

Timestep Collection Time: 2.32692
Timestep Consumption Time: 2.43126
PPO Batch Consumption Time: 0.29317
Total Iteration Time: 4.75818

Cumulative Model Updates: 239,780
Cumulative Timesteps: 2,000,400,146

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 2000400146...
Checkpoint 2000400146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,012.06085
Policy Entropy: 2.28978
Value Function Loss: 0.02004

Mean KL Divergence: 0.00756
SB3 Clip Fraction: 0.07136
Policy Update Magnitude: 0.30118
Value Function Update Magnitude: 0.24665

Collected Steps per Second: 21,045.68330
Overall Steps per Second: 10,543.23462

Timestep Collection Time: 2.37635
Timestep Consumption Time: 2.36716
PPO Batch Consumption Time: 0.27942
Total Iteration Time: 4.74352

Cumulative Model Updates: 239,786
Cumulative Timesteps: 2,000,450,158

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,586.29160
Policy Entropy: 2.27604
Value Function Loss: 0.02002

Mean KL Divergence: 0.00753
SB3 Clip Fraction: 0.06973
Policy Update Magnitude: 0.30700
Value Function Update Magnitude: 0.21902

Collected Steps per Second: 21,627.75715
Overall Steps per Second: 10,548.96288

Timestep Collection Time: 2.31351
Timestep Consumption Time: 2.42971
PPO Batch Consumption Time: 0.29260
Total Iteration Time: 4.74322

Cumulative Model Updates: 239,792
Cumulative Timesteps: 2,000,500,194

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 2000500194...
Checkpoint 2000500194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,783.39446
Policy Entropy: 2.26825
Value Function Loss: 0.01901

Mean KL Divergence: 0.00710
SB3 Clip Fraction: 0.06568
Policy Update Magnitude: 0.30797
Value Function Update Magnitude: 0.27556

Collected Steps per Second: 20,714.17475
Overall Steps per Second: 10,199.58883

Timestep Collection Time: 2.41448
Timestep Consumption Time: 2.48905
PPO Batch Consumption Time: 0.29297
Total Iteration Time: 4.90353

Cumulative Model Updates: 239,798
Cumulative Timesteps: 2,000,550,208

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56,263.35961
Policy Entropy: 2.27973
Value Function Loss: 0.01659

Mean KL Divergence: 0.00628
SB3 Clip Fraction: 0.05874
Policy Update Magnitude: 0.30337
Value Function Update Magnitude: 0.28180

Collected Steps per Second: 21,762.70703
Overall Steps per Second: 10,486.03313

Timestep Collection Time: 2.29788
Timestep Consumption Time: 2.47113
PPO Batch Consumption Time: 0.29276
Total Iteration Time: 4.76901

Cumulative Model Updates: 239,804
Cumulative Timesteps: 2,000,600,216

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2000600216...
Checkpoint 2000600216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 74,267.56348
Policy Entropy: 2.28396
Value Function Loss: 0.01860

Mean KL Divergence: 0.00646
SB3 Clip Fraction: 0.06138
Policy Update Magnitude: 0.30056
Value Function Update Magnitude: 0.26742

Collected Steps per Second: 21,316.59085
Overall Steps per Second: 10,546.19976

Timestep Collection Time: 2.34587
Timestep Consumption Time: 2.39574
PPO Batch Consumption Time: 0.27819
Total Iteration Time: 4.74161

Cumulative Model Updates: 239,810
Cumulative Timesteps: 2,000,650,222

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61,412.74444
Policy Entropy: 2.28181
Value Function Loss: 0.01884

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.09044
Policy Update Magnitude: 0.30359
Value Function Update Magnitude: 0.23189

Collected Steps per Second: 21,529.78687
Overall Steps per Second: 10,468.82731

Timestep Collection Time: 2.32422
Timestep Consumption Time: 2.45568
PPO Batch Consumption Time: 0.28776
Total Iteration Time: 4.77990

Cumulative Model Updates: 239,816
Cumulative Timesteps: 2,000,700,262

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 2000700262...
Checkpoint 2000700262 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 65,607.59782
Policy Entropy: 2.27874
Value Function Loss: 0.02106

Mean KL Divergence: 0.01161
SB3 Clip Fraction: 0.10265
Policy Update Magnitude: 0.30021
Value Function Update Magnitude: 0.21376

Collected Steps per Second: 21,142.19493
Overall Steps per Second: 10,248.00038

Timestep Collection Time: 2.36636
Timestep Consumption Time: 2.51557
PPO Batch Consumption Time: 0.29337
Total Iteration Time: 4.88193

Cumulative Model Updates: 239,822
Cumulative Timesteps: 2,000,750,292

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48,618.67522
Policy Entropy: 2.26225
Value Function Loss: 0.01971

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.09072
Policy Update Magnitude: 0.30438
Value Function Update Magnitude: 0.21260

Collected Steps per Second: 21,887.71236
Overall Steps per Second: 10,413.52846

Timestep Collection Time: 2.28530
Timestep Consumption Time: 2.51807
PPO Batch Consumption Time: 0.28675
Total Iteration Time: 4.80337

Cumulative Model Updates: 239,828
Cumulative Timesteps: 2,000,800,312

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2000800312...
Checkpoint 2000800312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,383.60022
Policy Entropy: 2.27267
Value Function Loss: 0.02138

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.07982
Policy Update Magnitude: 0.32522
Value Function Update Magnitude: 0.23697

Collected Steps per Second: 22,044.27662
Overall Steps per Second: 10,586.99051

Timestep Collection Time: 2.26943
Timestep Consumption Time: 2.45599
PPO Batch Consumption Time: 0.27918
Total Iteration Time: 4.72542

Cumulative Model Updates: 239,834
Cumulative Timesteps: 2,000,850,340

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,975.94312
Policy Entropy: 2.28135
Value Function Loss: 0.02247

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.07925
Policy Update Magnitude: 0.32816
Value Function Update Magnitude: 0.32799

Collected Steps per Second: 22,141.93154
Overall Steps per Second: 10,476.17572

Timestep Collection Time: 2.25915
Timestep Consumption Time: 2.51568
PPO Batch Consumption Time: 0.29032
Total Iteration Time: 4.77483

Cumulative Model Updates: 239,840
Cumulative Timesteps: 2,000,900,362

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2000900362...
Checkpoint 2000900362 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,963.25246
Policy Entropy: 2.29463
Value Function Loss: 0.02099

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.07393
Policy Update Magnitude: 0.33157
Value Function Update Magnitude: 0.35865

Collected Steps per Second: 21,941.22665
Overall Steps per Second: 10,599.82896

Timestep Collection Time: 2.28009
Timestep Consumption Time: 2.43961
PPO Batch Consumption Time: 0.27985
Total Iteration Time: 4.71970

Cumulative Model Updates: 239,846
Cumulative Timesteps: 2,000,950,390

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59,053.60161
Policy Entropy: 2.28555
Value Function Loss: 0.01864

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.07287
Policy Update Magnitude: 0.31823
Value Function Update Magnitude: 0.36508

Collected Steps per Second: 22,055.31998
Overall Steps per Second: 10,509.84627

Timestep Collection Time: 2.26766
Timestep Consumption Time: 2.49111
PPO Batch Consumption Time: 0.28774
Total Iteration Time: 4.75878

Cumulative Model Updates: 239,852
Cumulative Timesteps: 2,001,000,404

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2001000404...
Checkpoint 2001000404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 60,002.62443
Policy Entropy: 2.28994
Value Function Loss: 0.01814

Mean KL Divergence: 0.00697
SB3 Clip Fraction: 0.06479
Policy Update Magnitude: 0.31565
Value Function Update Magnitude: 0.33693

Collected Steps per Second: 21,712.13915
Overall Steps per Second: 10,571.27209

Timestep Collection Time: 2.30332
Timestep Consumption Time: 2.42743
PPO Batch Consumption Time: 0.27934
Total Iteration Time: 4.73075

Cumulative Model Updates: 239,858
Cumulative Timesteps: 2,001,050,414

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52,303.88537
Policy Entropy: 2.27735
Value Function Loss: 0.01735

Mean KL Divergence: 0.00685
SB3 Clip Fraction: 0.06592
Policy Update Magnitude: 0.30706
Value Function Update Magnitude: 0.30500

Collected Steps per Second: 22,070.47271
Overall Steps per Second: 10,531.29803

Timestep Collection Time: 2.26701
Timestep Consumption Time: 2.48397
PPO Batch Consumption Time: 0.28888
Total Iteration Time: 4.75098

Cumulative Model Updates: 239,864
Cumulative Timesteps: 2,001,100,448

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 2001100448...
Checkpoint 2001100448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 100,658.74769
Policy Entropy: 2.27920
Value Function Loss: 0.01736

Mean KL Divergence: 0.00730
SB3 Clip Fraction: 0.06956
Policy Update Magnitude: 0.29473
Value Function Update Magnitude: 0.28562

Collected Steps per Second: 21,357.48681
Overall Steps per Second: 10,338.15263

Timestep Collection Time: 2.34297
Timestep Consumption Time: 2.49735
PPO Batch Consumption Time: 0.29260
Total Iteration Time: 4.84032

Cumulative Model Updates: 239,870
Cumulative Timesteps: 2,001,150,488

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,074.72889
Policy Entropy: 2.27221
Value Function Loss: 0.01927

Mean KL Divergence: 0.00699
SB3 Clip Fraction: 0.06903
Policy Update Magnitude: 0.30559
Value Function Update Magnitude: 0.29404

Collected Steps per Second: 21,740.94431
Overall Steps per Second: 10,406.45509

Timestep Collection Time: 2.29990
Timestep Consumption Time: 2.50500
PPO Batch Consumption Time: 0.29357
Total Iteration Time: 4.80490

Cumulative Model Updates: 239,876
Cumulative Timesteps: 2,001,200,490

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2001200490...
Checkpoint 2001200490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,518.29379
Policy Entropy: 2.28793
Value Function Loss: 0.01919

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.07546
Policy Update Magnitude: 0.30668
Value Function Update Magnitude: 0.32703

Collected Steps per Second: 21,226.12560
Overall Steps per Second: 10,471.12526

Timestep Collection Time: 2.35606
Timestep Consumption Time: 2.41993
PPO Batch Consumption Time: 0.27858
Total Iteration Time: 4.77599

Cumulative Model Updates: 239,882
Cumulative Timesteps: 2,001,250,500

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75,925.61836
Policy Entropy: 2.30749
Value Function Loss: 0.02043

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.08274
Policy Update Magnitude: 0.31824
Value Function Update Magnitude: 0.34243

Collected Steps per Second: 21,764.40708
Overall Steps per Second: 10,502.82616

Timestep Collection Time: 2.29917
Timestep Consumption Time: 2.46527
PPO Batch Consumption Time: 0.27926
Total Iteration Time: 4.76443

Cumulative Model Updates: 239,888
Cumulative Timesteps: 2,001,300,540

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 2001300540...
Checkpoint 2001300540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 76,700.80643
Policy Entropy: 2.31283
Value Function Loss: 0.01820

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.07750
Policy Update Magnitude: 0.31320
Value Function Update Magnitude: 0.33748

Collected Steps per Second: 21,886.75791
Overall Steps per Second: 10,408.85775

Timestep Collection Time: 2.28522
Timestep Consumption Time: 2.51992
PPO Batch Consumption Time: 0.28966
Total Iteration Time: 4.80514

Cumulative Model Updates: 239,894
Cumulative Timesteps: 2,001,350,556

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63,694.31316
Policy Entropy: 2.30714
Value Function Loss: 0.01879

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.08101
Policy Update Magnitude: 0.31280
Value Function Update Magnitude: 0.34242

Collected Steps per Second: 22,060.13325
Overall Steps per Second: 10,659.08142

Timestep Collection Time: 2.26699
Timestep Consumption Time: 2.42479
PPO Batch Consumption Time: 0.27923
Total Iteration Time: 4.69177

Cumulative Model Updates: 239,900
Cumulative Timesteps: 2,001,400,566

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2001400566...
Checkpoint 2001400566 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 53,602.32810
Policy Entropy: 2.29806
Value Function Loss: 0.01535

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.07369
Policy Update Magnitude: 0.29853
Value Function Update Magnitude: 0.33255

Collected Steps per Second: 21,812.00417
Overall Steps per Second: 10,612.01338

Timestep Collection Time: 2.29378
Timestep Consumption Time: 2.42087
PPO Batch Consumption Time: 0.27901
Total Iteration Time: 4.71466

Cumulative Model Updates: 239,906
Cumulative Timesteps: 2,001,450,598

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66,839.96183
Policy Entropy: 2.29549
Value Function Loss: 0.01665

Mean KL Divergence: 0.00723
SB3 Clip Fraction: 0.06703
Policy Update Magnitude: 0.29117
Value Function Update Magnitude: 0.31337

Collected Steps per Second: 22,062.14822
Overall Steps per Second: 10,538.26005

Timestep Collection Time: 2.26669
Timestep Consumption Time: 2.47869
PPO Batch Consumption Time: 0.28828
Total Iteration Time: 4.74538

Cumulative Model Updates: 239,912
Cumulative Timesteps: 2,001,500,606

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2001500606...
Checkpoint 2001500606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 63,184.65750
Policy Entropy: 2.28281
Value Function Loss: 0.01874

Mean KL Divergence: 0.00614
SB3 Clip Fraction: 0.06228
Policy Update Magnitude: 0.29966
Value Function Update Magnitude: 0.30982

Collected Steps per Second: 21,275.20250
Overall Steps per Second: 10,610.70302

Timestep Collection Time: 2.35025
Timestep Consumption Time: 2.36216
PPO Batch Consumption Time: 0.27942
Total Iteration Time: 4.71241

Cumulative Model Updates: 239,918
Cumulative Timesteps: 2,001,550,608

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70,056.66944
Policy Entropy: 2.26994
Value Function Loss: 0.01972

Mean KL Divergence: 0.00692
SB3 Clip Fraction: 0.06942
Policy Update Magnitude: 0.30934
Value Function Update Magnitude: 0.32794

Collected Steps per Second: 21,453.47554
Overall Steps per Second: 10,472.46417

Timestep Collection Time: 2.33062
Timestep Consumption Time: 2.44380
PPO Batch Consumption Time: 0.29503
Total Iteration Time: 4.77443

Cumulative Model Updates: 239,924
Cumulative Timesteps: 2,001,600,608

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2001600608...
Checkpoint 2001600608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48,112.36806
Policy Entropy: 2.28004
Value Function Loss: 0.02100

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.07278
Policy Update Magnitude: 0.31025
Value Function Update Magnitude: 0.33917

Collected Steps per Second: 21,126.85547
Overall Steps per Second: 10,578.97462

Timestep Collection Time: 2.36703
Timestep Consumption Time: 2.36008
PPO Batch Consumption Time: 0.27892
Total Iteration Time: 4.72711

Cumulative Model Updates: 239,930
Cumulative Timesteps: 2,001,650,616

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 69,945.46533
Policy Entropy: 2.29854
Value Function Loss: 0.01976

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.07156
Policy Update Magnitude: 0.31147
Value Function Update Magnitude: 0.33538

Collected Steps per Second: 20,900.88051
Overall Steps per Second: 10,514.98253

Timestep Collection Time: 2.39330
Timestep Consumption Time: 2.36392
PPO Batch Consumption Time: 0.27874
Total Iteration Time: 4.75721

Cumulative Model Updates: 239,936
Cumulative Timesteps: 2,001,700,638

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2001700638...
Checkpoint 2001700638 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 88,182.21603
Policy Entropy: 2.29460
Value Function Loss: 0.01911

Mean KL Divergence: 0.00728
SB3 Clip Fraction: 0.06861
Policy Update Magnitude: 0.30828
Value Function Update Magnitude: 0.33274

Collected Steps per Second: 21,070.76720
Overall Steps per Second: 10,286.75274

Timestep Collection Time: 2.37381
Timestep Consumption Time: 2.48856
PPO Batch Consumption Time: 0.29310
Total Iteration Time: 4.86237

Cumulative Model Updates: 239,942
Cumulative Timesteps: 2,001,750,656

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75,394.37754
Policy Entropy: 2.28744
Value Function Loss: 0.01902

Mean KL Divergence: 0.00712
SB3 Clip Fraction: 0.06616
Policy Update Magnitude: 0.30843
Value Function Update Magnitude: 0.33816

Collected Steps per Second: 21,722.30130
Overall Steps per Second: 10,460.21299

Timestep Collection Time: 2.30307
Timestep Consumption Time: 2.47962
PPO Batch Consumption Time: 0.29316
Total Iteration Time: 4.78269

Cumulative Model Updates: 239,948
Cumulative Timesteps: 2,001,800,684

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2001800684...
Checkpoint 2001800684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47,661.88391
Policy Entropy: 2.28382
Value Function Loss: 0.01861

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.06992
Policy Update Magnitude: 0.30792
Value Function Update Magnitude: 0.30914

Collected Steps per Second: 21,743.40651
Overall Steps per Second: 10,547.08565

Timestep Collection Time: 2.30148
Timestep Consumption Time: 2.44315
PPO Batch Consumption Time: 0.27937
Total Iteration Time: 4.74463

Cumulative Model Updates: 239,954
Cumulative Timesteps: 2,001,850,726

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,118.62875
Policy Entropy: 2.30041
Value Function Loss: 0.01764

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.07431
Policy Update Magnitude: 0.29623
Value Function Update Magnitude: 0.24106

Collected Steps per Second: 21,853.13349
Overall Steps per Second: 10,381.18452

Timestep Collection Time: 2.28937
Timestep Consumption Time: 2.52992
PPO Batch Consumption Time: 0.29155
Total Iteration Time: 4.81930

Cumulative Model Updates: 239,960
Cumulative Timesteps: 2,001,900,756

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2001900756...
Checkpoint 2001900756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 50,350.13484
Policy Entropy: 2.29595
Value Function Loss: 0.01731

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.07470
Policy Update Magnitude: 0.29085
Value Function Update Magnitude: 0.21917

Collected Steps per Second: 20,817.16984
Overall Steps per Second: 10,243.46905

Timestep Collection Time: 2.40292
Timestep Consumption Time: 2.48039
PPO Batch Consumption Time: 0.28006
Total Iteration Time: 4.88331

Cumulative Model Updates: 239,966
Cumulative Timesteps: 2,001,950,778

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61,087.91211
Policy Entropy: 2.30495
Value Function Loss: 0.01882

Mean KL Divergence: 0.00716
SB3 Clip Fraction: 0.06895
Policy Update Magnitude: 0.29634
Value Function Update Magnitude: 0.19576

Collected Steps per Second: 21,652.50521
Overall Steps per Second: 10,539.11405

Timestep Collection Time: 2.31040
Timestep Consumption Time: 2.43630
PPO Batch Consumption Time: 0.27787
Total Iteration Time: 4.74670

Cumulative Model Updates: 239,972
Cumulative Timesteps: 2,002,000,804

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2002000804...
Checkpoint 2002000804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55,995.61850
Policy Entropy: 2.30515
Value Function Loss: 0.02164

Mean KL Divergence: 0.00700
SB3 Clip Fraction: 0.06244
Policy Update Magnitude: 0.30808
Value Function Update Magnitude: 0.22052

Collected Steps per Second: 22,076.27426
Overall Steps per Second: 10,686.32261

Timestep Collection Time: 2.26714
Timestep Consumption Time: 2.41642
PPO Batch Consumption Time: 0.27768
Total Iteration Time: 4.68356

Cumulative Model Updates: 239,978
Cumulative Timesteps: 2,002,050,854

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56,547.15519
Policy Entropy: 2.30386
Value Function Loss: 0.02113

Mean KL Divergence: 0.00730
SB3 Clip Fraction: 0.06125
Policy Update Magnitude: 0.31617
Value Function Update Magnitude: 0.27484

Collected Steps per Second: 21,974.42512
Overall Steps per Second: 10,463.73317

Timestep Collection Time: 2.27610
Timestep Consumption Time: 2.50384
PPO Batch Consumption Time: 0.29271
Total Iteration Time: 4.77994

Cumulative Model Updates: 239,984
Cumulative Timesteps: 2,002,100,870

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2002100870...
Checkpoint 2002100870 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43,978.55534
Policy Entropy: 2.29250
Value Function Loss: 0.01881

Mean KL Divergence: 0.00681
SB3 Clip Fraction: 0.06266
Policy Update Magnitude: 0.31061
Value Function Update Magnitude: 0.29655

Collected Steps per Second: 22,020.24450
Overall Steps per Second: 10,524.07889

Timestep Collection Time: 2.27127
Timestep Consumption Time: 2.48107
PPO Batch Consumption Time: 0.28512
Total Iteration Time: 4.75234

Cumulative Model Updates: 239,990
Cumulative Timesteps: 2,002,150,884

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42,210.82568
Policy Entropy: 2.29399
Value Function Loss: 0.01657

Mean KL Divergence: 0.00745
SB3 Clip Fraction: 0.07027
Policy Update Magnitude: 0.29908
Value Function Update Magnitude: 0.28772

Collected Steps per Second: 21,199.00494
Overall Steps per Second: 10,414.61619

Timestep Collection Time: 2.35973
Timestep Consumption Time: 2.44352
PPO Batch Consumption Time: 0.27870
Total Iteration Time: 4.80325

Cumulative Model Updates: 239,996
Cumulative Timesteps: 2,002,200,908

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2002200908...
Checkpoint 2002200908 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 57,992.37682
Policy Entropy: 2.29599
Value Function Loss: 0.02011

Mean KL Divergence: 0.00694
SB3 Clip Fraction: 0.06400
Policy Update Magnitude: 0.30153
Value Function Update Magnitude: 0.31195

Collected Steps per Second: 21,444.73272
Overall Steps per Second: 10,329.70931

Timestep Collection Time: 2.33176
Timestep Consumption Time: 2.50903
PPO Batch Consumption Time: 0.29328
Total Iteration Time: 4.84079

Cumulative Model Updates: 240,002
Cumulative Timesteps: 2,002,250,912

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61,332.69478
Policy Entropy: 2.29352
Value Function Loss: 0.01969

Mean KL Divergence: 0.00725
SB3 Clip Fraction: 0.06997
Policy Update Magnitude: 0.30543
Value Function Update Magnitude: 0.32666

Collected Steps per Second: 21,697.11301
Overall Steps per Second: 10,385.35127

Timestep Collection Time: 2.30510
Timestep Consumption Time: 2.51072
PPO Batch Consumption Time: 0.29237
Total Iteration Time: 4.81582

Cumulative Model Updates: 240,008
Cumulative Timesteps: 2,002,300,926

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2002300926...
Checkpoint 2002300926 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 72,769.24719
Policy Entropy: 2.29074
Value Function Loss: 0.02140

Mean KL Divergence: 0.00716
SB3 Clip Fraction: 0.06876
Policy Update Magnitude: 0.30784
Value Function Update Magnitude: 0.35551

Collected Steps per Second: 21,509.80442
Overall Steps per Second: 10,380.00426

Timestep Collection Time: 2.32582
Timestep Consumption Time: 2.49383
PPO Batch Consumption Time: 0.29046
Total Iteration Time: 4.81965

Cumulative Model Updates: 240,014
Cumulative Timesteps: 2,002,350,954

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60,097.32062
Policy Entropy: 2.30797
Value Function Loss: 0.01653

Mean KL Divergence: 0.00668
SB3 Clip Fraction: 0.06455
Policy Update Magnitude: 0.30331
Value Function Update Magnitude: 0.34714

Collected Steps per Second: 21,643.70721
Overall Steps per Second: 10,405.49771

Timestep Collection Time: 2.31199
Timestep Consumption Time: 2.49701
PPO Batch Consumption Time: 0.29238
Total Iteration Time: 4.80900

Cumulative Model Updates: 240,020
Cumulative Timesteps: 2,002,400,994

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 2002400994...
Checkpoint 2002400994 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 52,852.82475
Policy Entropy: 2.30022
Value Function Loss: 0.01626

Mean KL Divergence: 0.00714
SB3 Clip Fraction: 0.06850
Policy Update Magnitude: 0.29387
Value Function Update Magnitude: 0.29130

Collected Steps per Second: 22,050.75165
Overall Steps per Second: 10,589.79429

Timestep Collection Time: 2.26804
Timestep Consumption Time: 2.45462
PPO Batch Consumption Time: 0.27740
Total Iteration Time: 4.72266

Cumulative Model Updates: 240,026
Cumulative Timesteps: 2,002,451,006

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45,754.45335
Policy Entropy: 2.30655
Value Function Loss: 0.01685

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.07366
Policy Update Magnitude: 0.28848
Value Function Update Magnitude: 0.25630

Collected Steps per Second: 22,149.42310
Overall Steps per Second: 10,495.27267

Timestep Collection Time: 2.25821
Timestep Consumption Time: 2.50756
PPO Batch Consumption Time: 0.28926
Total Iteration Time: 4.76576

Cumulative Model Updates: 240,032
Cumulative Timesteps: 2,002,501,024

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2002501024...
Checkpoint 2002501024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,519.98133
Policy Entropy: 2.29607
Value Function Loss: 0.01501

Mean KL Divergence: 0.00642
SB3 Clip Fraction: 0.06242
Policy Update Magnitude: 0.28335
Value Function Update Magnitude: 0.24171

Collected Steps per Second: 21,402.25104
Overall Steps per Second: 10,508.05211

Timestep Collection Time: 2.33648
Timestep Consumption Time: 2.42234
PPO Batch Consumption Time: 0.29031
Total Iteration Time: 4.75883

Cumulative Model Updates: 240,038
Cumulative Timesteps: 2,002,551,030

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50,767.81999
Policy Entropy: 2.28207
Value Function Loss: 0.01799

Mean KL Divergence: 0.00641
SB3 Clip Fraction: 0.06255
Policy Update Magnitude: 0.28923
Value Function Update Magnitude: 0.27459

Collected Steps per Second: 21,541.04967
Overall Steps per Second: 10,534.19150

Timestep Collection Time: 2.32124
Timestep Consumption Time: 2.42540
PPO Batch Consumption Time: 0.29315
Total Iteration Time: 4.74664

Cumulative Model Updates: 240,044
Cumulative Timesteps: 2,002,601,032

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2002601032...
Checkpoint 2002601032 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 75,975.06396
Policy Entropy: 2.27584
Value Function Loss: 0.01797

Mean KL Divergence: 0.00666
SB3 Clip Fraction: 0.06379
Policy Update Magnitude: 0.30137
Value Function Update Magnitude: 0.32008

Collected Steps per Second: 21,364.22819
Overall Steps per Second: 10,564.86039

Timestep Collection Time: 2.34167
Timestep Consumption Time: 2.39365
PPO Batch Consumption Time: 0.28611
Total Iteration Time: 4.73532

Cumulative Model Updates: 240,050
Cumulative Timesteps: 2,002,651,060

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82,298.56269
Policy Entropy: 2.27090
Value Function Loss: 0.01736

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.08386
Policy Update Magnitude: 0.29842
Value Function Update Magnitude: 0.33862

Collected Steps per Second: 21,462.82085
Overall Steps per Second: 10,414.77910

Timestep Collection Time: 2.33082
Timestep Consumption Time: 2.47255
PPO Batch Consumption Time: 0.28738
Total Iteration Time: 4.80337

Cumulative Model Updates: 240,056
Cumulative Timesteps: 2,002,701,086

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2002701086...
Checkpoint 2002701086 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 107,582.12675
Policy Entropy: 2.28683
Value Function Loss: 0.01658

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.07737
Policy Update Magnitude: 0.29865
Value Function Update Magnitude: 0.32014

Collected Steps per Second: 21,500.50144
Overall Steps per Second: 10,594.52929

Timestep Collection Time: 2.32571
Timestep Consumption Time: 2.39408
PPO Batch Consumption Time: 0.27852
Total Iteration Time: 4.71979

Cumulative Model Updates: 240,062
Cumulative Timesteps: 2,002,751,090

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76,148.73479
Policy Entropy: 2.29354
Value Function Loss: 0.01818

Mean KL Divergence: 0.01231
SB3 Clip Fraction: 0.10241
Policy Update Magnitude: 0.29512
Value Function Update Magnitude: 0.29593

Collected Steps per Second: 21,391.90918
Overall Steps per Second: 10,584.91236

Timestep Collection Time: 2.33855
Timestep Consumption Time: 2.38761
PPO Batch Consumption Time: 0.27680
Total Iteration Time: 4.72616

Cumulative Model Updates: 240,068
Cumulative Timesteps: 2,002,801,116

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2002801116...
Checkpoint 2002801116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 52,929.08856
Policy Entropy: 2.30206
Value Function Loss: 0.02007

Mean KL Divergence: 0.01411
SB3 Clip Fraction: 0.11396
Policy Update Magnitude: 0.27675
Value Function Update Magnitude: 0.29550

Collected Steps per Second: 21,209.24060
Overall Steps per Second: 10,320.31660

Timestep Collection Time: 2.35756
Timestep Consumption Time: 2.48745
PPO Batch Consumption Time: 0.29113
Total Iteration Time: 4.84501

Cumulative Model Updates: 240,074
Cumulative Timesteps: 2,002,851,118

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,480.89951
Policy Entropy: 2.29987
Value Function Loss: 0.02181

Mean KL Divergence: 0.01701
SB3 Clip Fraction: 0.12718
Policy Update Magnitude: 0.28432
Value Function Update Magnitude: 0.33424

Collected Steps per Second: 21,967.59358
Overall Steps per Second: 10,678.61415

Timestep Collection Time: 2.27717
Timestep Consumption Time: 2.40733
PPO Batch Consumption Time: 0.27854
Total Iteration Time: 4.68450

Cumulative Model Updates: 240,080
Cumulative Timesteps: 2,002,901,142

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2002901142...
Checkpoint 2002901142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,938.75029
Policy Entropy: 2.29496
Value Function Loss: 0.02100

Mean KL Divergence: 0.01458
SB3 Clip Fraction: 0.11890
Policy Update Magnitude: 0.30306
Value Function Update Magnitude: 0.36684

Collected Steps per Second: 21,178.82025
Overall Steps per Second: 10,238.55380

Timestep Collection Time: 2.36179
Timestep Consumption Time: 2.52366
PPO Batch Consumption Time: 0.29371
Total Iteration Time: 4.88546

Cumulative Model Updates: 240,086
Cumulative Timesteps: 2,002,951,162

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46,694.40867
Policy Entropy: 2.29842
Value Function Loss: 0.01953

Mean KL Divergence: 0.01248
SB3 Clip Fraction: 0.11117
Policy Update Magnitude: 0.30561
Value Function Update Magnitude: 0.37395

Collected Steps per Second: 22,405.46290
Overall Steps per Second: 10,492.56632

Timestep Collection Time: 2.23213
Timestep Consumption Time: 2.53429
PPO Batch Consumption Time: 0.29299
Total Iteration Time: 4.76642

Cumulative Model Updates: 240,092
Cumulative Timesteps: 2,003,001,174

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2003001174...
Checkpoint 2003001174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48,677.70623
Policy Entropy: 2.29434
Value Function Loss: 0.01841

Mean KL Divergence: 0.01159
SB3 Clip Fraction: 0.10320
Policy Update Magnitude: 0.30076
Value Function Update Magnitude: 0.35015

Collected Steps per Second: 21,700.69933
Overall Steps per Second: 10,535.73116

Timestep Collection Time: 2.30435
Timestep Consumption Time: 2.44197
PPO Batch Consumption Time: 0.27909
Total Iteration Time: 4.74632

Cumulative Model Updates: 240,098
Cumulative Timesteps: 2,003,051,180

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50,628.81479
Policy Entropy: 2.28166
Value Function Loss: 0.01987

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.08049
Policy Update Magnitude: 0.31905
Value Function Update Magnitude: 0.34287

Collected Steps per Second: 22,539.99074
Overall Steps per Second: 10,557.69412

Timestep Collection Time: 2.22076
Timestep Consumption Time: 2.52042
PPO Batch Consumption Time: 0.29319
Total Iteration Time: 4.74119

Cumulative Model Updates: 240,104
Cumulative Timesteps: 2,003,101,236

Timesteps Collected: 50,056
--------END ITERATION REPORT--------


Saving checkpoint 2003101236...
Checkpoint 2003101236 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 50,069.27282
Policy Entropy: 2.29220
Value Function Loss: 0.01906

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.08034
Policy Update Magnitude: 0.31735
Value Function Update Magnitude: 0.33258

Collected Steps per Second: 21,811.74820
Overall Steps per Second: 10,554.66741

Timestep Collection Time: 2.29408
Timestep Consumption Time: 2.44676
PPO Batch Consumption Time: 0.27882
Total Iteration Time: 4.74084

Cumulative Model Updates: 240,110
Cumulative Timesteps: 2,003,151,274

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51,390.63128
Policy Entropy: 2.28476
Value Function Loss: 0.01913

Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.07472
Policy Update Magnitude: 0.31233
Value Function Update Magnitude: 0.27144

Collected Steps per Second: 22,187.27498
Overall Steps per Second: 10,484.48441

Timestep Collection Time: 2.25553
Timestep Consumption Time: 2.51762
PPO Batch Consumption Time: 0.29279
Total Iteration Time: 4.77315

Cumulative Model Updates: 240,116
Cumulative Timesteps: 2,003,201,318

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 2003201318...
Checkpoint 2003201318 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 53,587.27328
Policy Entropy: 2.29239
Value Function Loss: 0.01821

Mean KL Divergence: 0.00723
SB3 Clip Fraction: 0.07137
Policy Update Magnitude: 0.31116
Value Function Update Magnitude: 0.22388

Collected Steps per Second: 21,669.18866
Overall Steps per Second: 10,570.11903

Timestep Collection Time: 2.30816
Timestep Consumption Time: 2.42367
PPO Batch Consumption Time: 0.27847
Total Iteration Time: 4.73183

Cumulative Model Updates: 240,122
Cumulative Timesteps: 2,003,251,334

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,718.23177
Policy Entropy: 2.27697
Value Function Loss: 0.01928

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.07416
Policy Update Magnitude: 0.31009
Value Function Update Magnitude: 0.22776

Collected Steps per Second: 21,869.85608
Overall Steps per Second: 10,527.68805

Timestep Collection Time: 2.28717
Timestep Consumption Time: 2.46411
PPO Batch Consumption Time: 0.28540
Total Iteration Time: 4.75128

Cumulative Model Updates: 240,128
Cumulative Timesteps: 2,003,301,354

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2003301354...
Checkpoint 2003301354 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 52,092.88397
Policy Entropy: 2.26587
Value Function Loss: 0.01886

Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.07281
Policy Update Magnitude: 0.31174
Value Function Update Magnitude: 0.28778

Collected Steps per Second: 21,376.30821
Overall Steps per Second: 10,324.68938

Timestep Collection Time: 2.34082
Timestep Consumption Time: 2.50563
PPO Batch Consumption Time: 0.29314
Total Iteration Time: 4.84644

Cumulative Model Updates: 240,134
Cumulative Timesteps: 2,003,351,392

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46,706.70085
Policy Entropy: 2.28156
Value Function Loss: 0.01703

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.07396
Policy Update Magnitude: 0.31104
Value Function Update Magnitude: 0.32057

Collected Steps per Second: 21,774.49178
Overall Steps per Second: 10,422.25534

Timestep Collection Time: 2.29691
Timestep Consumption Time: 2.50186
PPO Batch Consumption Time: 0.29374
Total Iteration Time: 4.79877

Cumulative Model Updates: 240,140
Cumulative Timesteps: 2,003,401,406

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2003401406...
Checkpoint 2003401406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,229.51157
Policy Entropy: 2.28003
Value Function Loss: 0.01752

Mean KL Divergence: 0.00751
SB3 Clip Fraction: 0.06664
Policy Update Magnitude: 0.31113
Value Function Update Magnitude: 0.32707

Collected Steps per Second: 21,270.44047
Overall Steps per Second: 10,494.80490

Timestep Collection Time: 2.35190
Timestep Consumption Time: 2.41484
PPO Batch Consumption Time: 0.27827
Total Iteration Time: 4.76674

Cumulative Model Updates: 240,146
Cumulative Timesteps: 2,003,451,432

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50,433.92790
Policy Entropy: 2.29353
Value Function Loss: 0.01927

Mean KL Divergence: 0.00714
SB3 Clip Fraction: 0.06526
Policy Update Magnitude: 0.31675
Value Function Update Magnitude: 0.33400

Collected Steps per Second: 21,290.91783
Overall Steps per Second: 10,496.45486

Timestep Collection Time: 2.34870
Timestep Consumption Time: 2.41538
PPO Batch Consumption Time: 0.28827
Total Iteration Time: 4.76408

Cumulative Model Updates: 240,152
Cumulative Timesteps: 2,003,501,438

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2003501438...
Checkpoint 2003501438 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46,423.49600
Policy Entropy: 2.27728
Value Function Loss: 0.01887

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.07029
Policy Update Magnitude: 0.31570
Value Function Update Magnitude: 0.34709

Collected Steps per Second: 20,839.04744
Overall Steps per Second: 10,281.75342

Timestep Collection Time: 2.40049
Timestep Consumption Time: 2.46482
PPO Batch Consumption Time: 0.29280
Total Iteration Time: 4.86532

Cumulative Model Updates: 240,158
Cumulative Timesteps: 2,003,551,462

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52,116.21130
Policy Entropy: 2.29416
Value Function Loss: 0.01776

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.07167
Policy Update Magnitude: 0.30673
Value Function Update Magnitude: 0.32886

Collected Steps per Second: 21,598.04078
Overall Steps per Second: 10,493.76166

Timestep Collection Time: 2.31521
Timestep Consumption Time: 2.44991
PPO Batch Consumption Time: 0.29357
Total Iteration Time: 4.76512

Cumulative Model Updates: 240,164
Cumulative Timesteps: 2,003,601,466

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2003601466...
Checkpoint 2003601466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,018.63929
Policy Entropy: 2.31198
Value Function Loss: 0.01793

Mean KL Divergence: 0.00683
SB3 Clip Fraction: 0.06510
Policy Update Magnitude: 0.30126
Value Function Update Magnitude: 0.30188

Collected Steps per Second: 21,306.43238
Overall Steps per Second: 10,497.69728

Timestep Collection Time: 2.34718
Timestep Consumption Time: 2.41672
PPO Batch Consumption Time: 0.27923
Total Iteration Time: 4.76390

Cumulative Model Updates: 240,170
Cumulative Timesteps: 2,003,651,476

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82,576.70062
Policy Entropy: 2.31965
Value Function Loss: 0.01782

Mean KL Divergence: 0.00656
SB3 Clip Fraction: 0.06284
Policy Update Magnitude: 0.30031
Value Function Update Magnitude: 0.30326

Collected Steps per Second: 22,243.33393
Overall Steps per Second: 10,604.58944

Timestep Collection Time: 2.24867
Timestep Consumption Time: 2.46796
PPO Batch Consumption Time: 0.29156
Total Iteration Time: 4.71664

Cumulative Model Updates: 240,176
Cumulative Timesteps: 2,003,701,494

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2003701494...
Checkpoint 2003701494 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55,913.12016
Policy Entropy: 2.29974
Value Function Loss: 0.02022

Mean KL Divergence: 0.00714
SB3 Clip Fraction: 0.06781
Policy Update Magnitude: 0.30513
Value Function Update Magnitude: 0.30978

Collected Steps per Second: 21,822.20995
Overall Steps per Second: 10,512.71574

Timestep Collection Time: 2.29152
Timestep Consumption Time: 2.46520
PPO Batch Consumption Time: 0.28838
Total Iteration Time: 4.75672

Cumulative Model Updates: 240,182
Cumulative Timesteps: 2,003,751,500

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56,049.32804
Policy Entropy: 2.30545
Value Function Loss: 0.01915

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.07970
Policy Update Magnitude: 0.30673
Value Function Update Magnitude: 0.31330

Collected Steps per Second: 22,097.43391
Overall Steps per Second: 10,566.24666

Timestep Collection Time: 2.26415
Timestep Consumption Time: 2.47092
PPO Batch Consumption Time: 0.29285
Total Iteration Time: 4.73508

Cumulative Model Updates: 240,188
Cumulative Timesteps: 2,003,801,532

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2003801532...
Checkpoint 2003801532 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43,107.00223
Policy Entropy: 2.29437
Value Function Loss: 0.01866

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.08383
Policy Update Magnitude: 0.30089
Value Function Update Magnitude: 0.31768

Collected Steps per Second: 21,241.81105
Overall Steps per Second: 10,473.74977

Timestep Collection Time: 2.35479
Timestep Consumption Time: 2.42096
PPO Batch Consumption Time: 0.27796
Total Iteration Time: 4.77575

Cumulative Model Updates: 240,194
Cumulative Timesteps: 2,003,851,552

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,593.86722
Policy Entropy: 2.28400
Value Function Loss: 0.01798

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.08672
Policy Update Magnitude: 0.30595
Value Function Update Magnitude: 0.27860

Collected Steps per Second: 21,385.43797
Overall Steps per Second: 10,473.85433

Timestep Collection Time: 2.34038
Timestep Consumption Time: 2.43819
PPO Batch Consumption Time: 0.27912
Total Iteration Time: 4.77857

Cumulative Model Updates: 240,200
Cumulative Timesteps: 2,003,901,602

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 2003901602...
Checkpoint 2003901602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55,579.00854
Policy Entropy: 2.26110
Value Function Loss: 0.01952

Mean KL Divergence: 0.01212
SB3 Clip Fraction: 0.10385
Policy Update Magnitude: 0.30652
Value Function Update Magnitude: 0.28076

Collected Steps per Second: 21,275.98844
Overall Steps per Second: 10,252.17068

Timestep Collection Time: 2.35082
Timestep Consumption Time: 2.52776
PPO Batch Consumption Time: 0.29489
Total Iteration Time: 4.87858

Cumulative Model Updates: 240,206
Cumulative Timesteps: 2,003,951,618

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,435.54940
Policy Entropy: 2.27270
Value Function Loss: 0.02057

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.09091
Policy Update Magnitude: 0.31248
Value Function Update Magnitude: 0.31953

Collected Steps per Second: 21,623.80630
Overall Steps per Second: 10,540.00064

Timestep Collection Time: 2.31291
Timestep Consumption Time: 2.43225
PPO Batch Consumption Time: 0.27766
Total Iteration Time: 4.74516

Cumulative Model Updates: 240,212
Cumulative Timesteps: 2,004,001,632

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2004001632...
Checkpoint 2004001632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 90,511.69341
Policy Entropy: 2.28763
Value Function Loss: 0.02166

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.08955
Policy Update Magnitude: 0.32657
Value Function Update Magnitude: 0.35404

Collected Steps per Second: 21,836.23115
Overall Steps per Second: 10,516.69190

Timestep Collection Time: 2.29206
Timestep Consumption Time: 2.46704
PPO Batch Consumption Time: 0.27876
Total Iteration Time: 4.75910

Cumulative Model Updates: 240,218
Cumulative Timesteps: 2,004,051,682

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90,511.69341
Policy Entropy: 2.30451
Value Function Loss: 0.01823

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.07807
Policy Update Magnitude: 0.31608
Value Function Update Magnitude: 0.32708

Collected Steps per Second: 22,169.59581
Overall Steps per Second: 10,451.87557

Timestep Collection Time: 2.25552
Timestep Consumption Time: 2.52869
PPO Batch Consumption Time: 0.29127
Total Iteration Time: 4.78421

Cumulative Model Updates: 240,224
Cumulative Timesteps: 2,004,101,686

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2004101686...
Checkpoint 2004101686 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 109,033.72499
Policy Entropy: 2.26962
Value Function Loss: 0.01753

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.07487
Policy Update Magnitude: 0.30403
Value Function Update Magnitude: 0.27792

Collected Steps per Second: 22,041.58968
Overall Steps per Second: 10,619.71621

Timestep Collection Time: 2.26862
Timestep Consumption Time: 2.43998
PPO Batch Consumption Time: 0.27942
Total Iteration Time: 4.70860

Cumulative Model Updates: 240,230
Cumulative Timesteps: 2,004,151,690

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82,340.63507
Policy Entropy: 2.26203
Value Function Loss: 0.01728

Mean KL Divergence: 0.00712
SB3 Clip Fraction: 0.06723
Policy Update Magnitude: 0.30720
Value Function Update Magnitude: 0.25769

Collected Steps per Second: 22,050.10550
Overall Steps per Second: 10,503.34051

Timestep Collection Time: 2.26947
Timestep Consumption Time: 2.49492
PPO Batch Consumption Time: 0.28954
Total Iteration Time: 4.76439

Cumulative Model Updates: 240,236
Cumulative Timesteps: 2,004,201,732

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 2004201732...
Checkpoint 2004201732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 73,009.25834
Policy Entropy: 2.25722
Value Function Loss: 0.01771

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.07790
Policy Update Magnitude: 0.30552
Value Function Update Magnitude: 0.27942

Collected Steps per Second: 21,748.21224
Overall Steps per Second: 10,611.12444

Timestep Collection Time: 2.29987
Timestep Consumption Time: 2.41387
PPO Batch Consumption Time: 0.27870
Total Iteration Time: 4.71373

Cumulative Model Updates: 240,242
Cumulative Timesteps: 2,004,251,750

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70,598.11235
Policy Entropy: 2.27451
Value Function Loss: 0.01774

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.07289
Policy Update Magnitude: 0.30881
Value Function Update Magnitude: 0.30383

Collected Steps per Second: 22,508.02658
Overall Steps per Second: 10,605.74959

Timestep Collection Time: 2.22321
Timestep Consumption Time: 2.49499
PPO Batch Consumption Time: 0.29190
Total Iteration Time: 4.71820

Cumulative Model Updates: 240,248
Cumulative Timesteps: 2,004,301,790

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 2004301790...
Checkpoint 2004301790 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 51,052.61235
Policy Entropy: 2.29753
Value Function Loss: 0.01691

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.07694
Policy Update Magnitude: 0.30852
Value Function Update Magnitude: 0.30371

Collected Steps per Second: 21,243.99791
Overall Steps per Second: 10,538.72370

Timestep Collection Time: 2.35370
Timestep Consumption Time: 2.39090
PPO Batch Consumption Time: 0.28652
Total Iteration Time: 4.74460

Cumulative Model Updates: 240,254
Cumulative Timesteps: 2,004,351,792

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49,703.68644
Policy Entropy: 2.29920
Value Function Loss: 0.01783

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.08157
Policy Update Magnitude: 0.30747
Value Function Update Magnitude: 0.31159

Collected Steps per Second: 20,955.23415
Overall Steps per Second: 10,450.95918

Timestep Collection Time: 2.38623
Timestep Consumption Time: 2.39840
PPO Batch Consumption Time: 0.28572
Total Iteration Time: 4.78463

Cumulative Model Updates: 240,260
Cumulative Timesteps: 2,004,401,796

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2004401796...
Checkpoint 2004401796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,998.65967
Policy Entropy: 2.31188
Value Function Loss: 0.01611

Mean KL Divergence: 0.00736
SB3 Clip Fraction: 0.06992
Policy Update Magnitude: 0.30283
Value Function Update Magnitude: 0.32051

Collected Steps per Second: 20,597.46396
Overall Steps per Second: 10,328.34965

Timestep Collection Time: 2.42894
Timestep Consumption Time: 2.41501
PPO Batch Consumption Time: 0.29134
Total Iteration Time: 4.84395

Cumulative Model Updates: 240,266
Cumulative Timesteps: 2,004,451,826

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50,943.85028
Policy Entropy: 2.29761
Value Function Loss: 0.01979

Mean KL Divergence: 0.00717
SB3 Clip Fraction: 0.07188
Policy Update Magnitude: 0.30683
Value Function Update Magnitude: 0.31661

Collected Steps per Second: 20,659.20876
Overall Steps per Second: 10,303.20887

Timestep Collection Time: 2.42110
Timestep Consumption Time: 2.43350
PPO Batch Consumption Time: 0.29216
Total Iteration Time: 4.85460

Cumulative Model Updates: 240,272
Cumulative Timesteps: 2,004,501,844

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2004501844...
Checkpoint 2004501844 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47,770.68716
Policy Entropy: 2.31077
Value Function Loss: 0.02001

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.07352
Policy Update Magnitude: 0.31001
Value Function Update Magnitude: 0.29973

Collected Steps per Second: 21,060.22231
Overall Steps per Second: 10,307.10424

Timestep Collection Time: 2.37547
Timestep Consumption Time: 2.47827
PPO Batch Consumption Time: 0.29348
Total Iteration Time: 4.85374

Cumulative Model Updates: 240,278
Cumulative Timesteps: 2,004,551,872

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48,597.41944
Policy Entropy: 2.29498
Value Function Loss: 0.02013

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.07406
Policy Update Magnitude: 0.30449
Value Function Update Magnitude: 0.25248

Collected Steps per Second: 21,658.51721
Overall Steps per Second: 10,430.54326

Timestep Collection Time: 2.31068
Timestep Consumption Time: 2.48734
PPO Batch Consumption Time: 0.29293
Total Iteration Time: 4.79802

Cumulative Model Updates: 240,284
Cumulative Timesteps: 2,004,601,918

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 2004601918...
Checkpoint 2004601918 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,050.42883
Policy Entropy: 2.27991
Value Function Loss: 0.01742

Mean KL Divergence: 0.00693
SB3 Clip Fraction: 0.06794
Policy Update Magnitude: 0.30243
Value Function Update Magnitude: 0.27292

Collected Steps per Second: 21,808.01707
Overall Steps per Second: 10,521.94378

Timestep Collection Time: 2.29356
Timestep Consumption Time: 2.46012
PPO Batch Consumption Time: 0.27886
Total Iteration Time: 4.75368

Cumulative Model Updates: 240,290
Cumulative Timesteps: 2,004,651,936

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,786.39989
Policy Entropy: 2.26556
Value Function Loss: 0.01689

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.07183
Policy Update Magnitude: 0.29966
Value Function Update Magnitude: 0.27959

Collected Steps per Second: 22,104.16674
Overall Steps per Second: 10,452.60188

Timestep Collection Time: 2.26229
Timestep Consumption Time: 2.52178
PPO Batch Consumption Time: 0.29136
Total Iteration Time: 4.78407

Cumulative Model Updates: 240,296
Cumulative Timesteps: 2,004,701,942

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2004701942...
Checkpoint 2004701942 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43,183.57407
Policy Entropy: 2.27491
Value Function Loss: 0.01742

Mean KL Divergence: 0.00760
SB3 Clip Fraction: 0.07220
Policy Update Magnitude: 0.30866
Value Function Update Magnitude: 0.25695

Collected Steps per Second: 21,931.02255
Overall Steps per Second: 10,605.71318

Timestep Collection Time: 2.28088
Timestep Consumption Time: 2.43564
PPO Batch Consumption Time: 0.27909
Total Iteration Time: 4.71651

Cumulative Model Updates: 240,302
Cumulative Timesteps: 2,004,751,964

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66,202.10774
Policy Entropy: 2.28206
Value Function Loss: 0.01849

Mean KL Divergence: 0.00746
SB3 Clip Fraction: 0.06973
Policy Update Magnitude: 0.31090
Value Function Update Magnitude: 0.30355

Collected Steps per Second: 21,867.92108
Overall Steps per Second: 10,621.59598

Timestep Collection Time: 2.28645
Timestep Consumption Time: 2.42094
PPO Batch Consumption Time: 0.27747
Total Iteration Time: 4.70739

Cumulative Model Updates: 240,308
Cumulative Timesteps: 2,004,801,964

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2004801964...
Checkpoint 2004801964 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 66,202.10774
Policy Entropy: 2.28038
Value Function Loss: 0.01682

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.06613
Policy Update Magnitude: 0.30670
Value Function Update Magnitude: 0.31557

Collected Steps per Second: 22,072.87554
Overall Steps per Second: 10,571.41424

Timestep Collection Time: 2.26559
Timestep Consumption Time: 2.46491
PPO Batch Consumption Time: 0.28618
Total Iteration Time: 4.73049

Cumulative Model Updates: 240,314
Cumulative Timesteps: 2,004,851,972

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78,762.84792
Policy Entropy: 2.27316
Value Function Loss: 0.01750

Mean KL Divergence: 0.00751
SB3 Clip Fraction: 0.06582
Policy Update Magnitude: 0.30383
Value Function Update Magnitude: 0.28138

Collected Steps per Second: 22,034.09691
Overall Steps per Second: 10,478.43592

Timestep Collection Time: 2.27012
Timestep Consumption Time: 2.50350
PPO Batch Consumption Time: 0.29330
Total Iteration Time: 4.77361

Cumulative Model Updates: 240,320
Cumulative Timesteps: 2,004,901,992

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2004901992...
Checkpoint 2004901992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 58,115.98590
Policy Entropy: 2.26170
Value Function Loss: 0.01783

Mean KL Divergence: 0.00721
SB3 Clip Fraction: 0.06954
Policy Update Magnitude: 0.31318
Value Function Update Magnitude: 0.28624

Collected Steps per Second: 21,655.45240
Overall Steps per Second: 10,548.13170

Timestep Collection Time: 2.30981
Timestep Consumption Time: 2.43226
PPO Batch Consumption Time: 0.27853
Total Iteration Time: 4.74207

Cumulative Model Updates: 240,326
Cumulative Timesteps: 2,004,952,012

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57,802.84333
Policy Entropy: 2.26239
Value Function Loss: 0.01847

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.08006
Policy Update Magnitude: 0.30968
Value Function Update Magnitude: 0.27865

Collected Steps per Second: 21,502.54633
Overall Steps per Second: 10,500.99535

Timestep Collection Time: 2.32531
Timestep Consumption Time: 2.43615
PPO Batch Consumption Time: 0.27778
Total Iteration Time: 4.76145

Cumulative Model Updates: 240,332
Cumulative Timesteps: 2,005,002,012

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2005002012...
Checkpoint 2005002012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 53,489.52220
Policy Entropy: 2.25815
Value Function Loss: 0.01868

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.07258
Policy Update Magnitude: 0.31565
Value Function Update Magnitude: 0.31167

Collected Steps per Second: 21,494.97310
Overall Steps per Second: 10,368.19233

Timestep Collection Time: 2.32640
Timestep Consumption Time: 2.49662
PPO Batch Consumption Time: 0.29160
Total Iteration Time: 4.82302

Cumulative Model Updates: 240,338
Cumulative Timesteps: 2,005,052,018

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68,302.01384
Policy Entropy: 2.26446
Value Function Loss: 0.01697

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.08405
Policy Update Magnitude: 0.30814
Value Function Update Magnitude: 0.29381

Collected Steps per Second: 21,464.82934
Overall Steps per Second: 10,303.68769

Timestep Collection Time: 2.33023
Timestep Consumption Time: 2.52415
PPO Batch Consumption Time: 0.29418
Total Iteration Time: 4.85438

Cumulative Model Updates: 240,344
Cumulative Timesteps: 2,005,102,036

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2005102036...
Checkpoint 2005102036 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 76,578.31179
Policy Entropy: 2.24767
Value Function Loss: 0.01733

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.08058
Policy Update Magnitude: 0.30179
Value Function Update Magnitude: 0.28349

Collected Steps per Second: 21,202.12298
Overall Steps per Second: 10,275.53690

Timestep Collection Time: 2.35854
Timestep Consumption Time: 2.50797
PPO Batch Consumption Time: 0.29390
Total Iteration Time: 4.86651

Cumulative Model Updates: 240,350
Cumulative Timesteps: 2,005,152,042

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52,422.49599
Policy Entropy: 2.25406
Value Function Loss: 0.01816

Mean KL Divergence: 0.00716
SB3 Clip Fraction: 0.06919
Policy Update Magnitude: 0.30784
Value Function Update Magnitude: 0.28188

Collected Steps per Second: 21,741.85246
Overall Steps per Second: 10,375.03615

Timestep Collection Time: 2.30008
Timestep Consumption Time: 2.51995
PPO Batch Consumption Time: 0.29365
Total Iteration Time: 4.82003

Cumulative Model Updates: 240,356
Cumulative Timesteps: 2,005,202,050

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2005202050...
Checkpoint 2005202050 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,627.26791
Policy Entropy: 2.26407
Value Function Loss: 0.01925

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.07557
Policy Update Magnitude: 0.31115
Value Function Update Magnitude: 0.30643

Collected Steps per Second: 21,309.81869
Overall Steps per Second: 10,563.44983

Timestep Collection Time: 2.34643
Timestep Consumption Time: 2.38706
PPO Batch Consumption Time: 0.27862
Total Iteration Time: 4.73349

Cumulative Model Updates: 240,362
Cumulative Timesteps: 2,005,252,052

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 106,394.08954
Policy Entropy: 2.28327
Value Function Loss: 0.01813

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.07564
Policy Update Magnitude: 0.31455
Value Function Update Magnitude: 0.33721

Collected Steps per Second: 21,498.24442
Overall Steps per Second: 10,487.86143

Timestep Collection Time: 2.32726
Timestep Consumption Time: 2.44321
PPO Batch Consumption Time: 0.29271
Total Iteration Time: 4.77047

Cumulative Model Updates: 240,368
Cumulative Timesteps: 2,005,302,084

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2005302084...
Checkpoint 2005302084 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 106,394.08954
Policy Entropy: 2.27712
Value Function Loss: 0.01604

Mean KL Divergence: 0.00701
SB3 Clip Fraction: 0.06658
Policy Update Magnitude: 0.30268
Value Function Update Magnitude: 0.33585

Collected Steps per Second: 21,170.87107
Overall Steps per Second: 10,582.59558

Timestep Collection Time: 2.36268
Timestep Consumption Time: 2.36395
PPO Batch Consumption Time: 0.27967
Total Iteration Time: 4.72663

Cumulative Model Updates: 240,374
Cumulative Timesteps: 2,005,352,104

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78,421.14736
Policy Entropy: 2.27396
Value Function Loss: 0.01554

Mean KL Divergence: 0.00683
SB3 Clip Fraction: 0.06442
Policy Update Magnitude: 0.29678
Value Function Update Magnitude: 0.31815

Collected Steps per Second: 21,459.41525
Overall Steps per Second: 10,531.71055

Timestep Collection Time: 2.33128
Timestep Consumption Time: 2.41894
PPO Batch Consumption Time: 0.27894
Total Iteration Time: 4.75023

Cumulative Model Updates: 240,380
Cumulative Timesteps: 2,005,402,132

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2005402132...
Checkpoint 2005402132 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 92,829.61017
Policy Entropy: 2.26899
Value Function Loss: 0.01571

Mean KL Divergence: 0.00688
SB3 Clip Fraction: 0.06730
Policy Update Magnitude: 0.29648
Value Function Update Magnitude: 0.30142

Collected Steps per Second: 21,537.11297
Overall Steps per Second: 10,596.74540

Timestep Collection Time: 2.32315
Timestep Consumption Time: 2.39849
PPO Batch Consumption Time: 0.27896
Total Iteration Time: 4.72164

Cumulative Model Updates: 240,386
Cumulative Timesteps: 2,005,452,166

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56,709.39440
Policy Entropy: 2.28339
Value Function Loss: 0.01919

Mean KL Divergence: 0.00680
SB3 Clip Fraction: 0.06363
Policy Update Magnitude: 0.30487
Value Function Update Magnitude: 0.28100

Collected Steps per Second: 21,834.26421
Overall Steps per Second: 10,506.09712

Timestep Collection Time: 2.29007
Timestep Consumption Time: 2.46926
PPO Batch Consumption Time: 0.29103
Total Iteration Time: 4.75933

Cumulative Model Updates: 240,392
Cumulative Timesteps: 2,005,502,168

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2005502168...
Checkpoint 2005502168 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 60,304.07892
Policy Entropy: 2.26960
Value Function Loss: 0.01870

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.07083
Policy Update Magnitude: 0.30997
Value Function Update Magnitude: 0.28036

Collected Steps per Second: 22,056.52362
Overall Steps per Second: 10,637.50950

Timestep Collection Time: 2.26736
Timestep Consumption Time: 2.43393
PPO Batch Consumption Time: 0.27883
Total Iteration Time: 4.70129

Cumulative Model Updates: 240,398
Cumulative Timesteps: 2,005,552,178

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50,416.92039
Policy Entropy: 2.27612
Value Function Loss: 0.01765

Mean KL Divergence: 0.00741
SB3 Clip Fraction: 0.06878
Policy Update Magnitude: 0.30222
Value Function Update Magnitude: 0.29326

Collected Steps per Second: 21,542.32670
Overall Steps per Second: 10,541.87230

Timestep Collection Time: 2.32157
Timestep Consumption Time: 2.42256
PPO Batch Consumption Time: 0.27714
Total Iteration Time: 4.74413

Cumulative Model Updates: 240,404
Cumulative Timesteps: 2,005,602,190

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2005602190...
Checkpoint 2005602190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 54,431.44401
Policy Entropy: 2.26402
Value Function Loss: 0.01853

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.07449
Policy Update Magnitude: 0.31509
Value Function Update Magnitude: 0.31166

Collected Steps per Second: 21,511.72413
Overall Steps per Second: 10,564.28029

Timestep Collection Time: 2.32441
Timestep Consumption Time: 2.40871
PPO Batch Consumption Time: 0.27887
Total Iteration Time: 4.73312

Cumulative Model Updates: 240,410
Cumulative Timesteps: 2,005,652,192

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 126,277.75555
Policy Entropy: 2.28332
Value Function Loss: 0.01766

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.08088
Policy Update Magnitude: 0.31219
Value Function Update Magnitude: 0.33333

Collected Steps per Second: 21,146.16383
Overall Steps per Second: 10,359.08786

Timestep Collection Time: 2.36620
Timestep Consumption Time: 2.46396
PPO Batch Consumption Time: 0.27885
Total Iteration Time: 4.83015

Cumulative Model Updates: 240,416
Cumulative Timesteps: 2,005,702,228

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 2005702228...
Checkpoint 2005702228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 71,038.55986
Policy Entropy: 2.28974
Value Function Loss: 0.02064

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.07838
Policy Update Magnitude: 0.31490
Value Function Update Magnitude: 0.32755

Collected Steps per Second: 21,121.41477
Overall Steps per Second: 10,277.87372

Timestep Collection Time: 2.36793
Timestep Consumption Time: 2.49825
PPO Batch Consumption Time: 0.28780
Total Iteration Time: 4.86618

Cumulative Model Updates: 240,422
Cumulative Timesteps: 2,005,752,242

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68,962.11277
Policy Entropy: 2.27900
Value Function Loss: 0.02031

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.07892
Policy Update Magnitude: 0.31499
Value Function Update Magnitude: 0.34098

Collected Steps per Second: 21,655.69130
Overall Steps per Second: 10,541.98362

Timestep Collection Time: 2.31043
Timestep Consumption Time: 2.43573
PPO Batch Consumption Time: 0.27721
Total Iteration Time: 4.74617

Cumulative Model Updates: 240,428
Cumulative Timesteps: 2,005,802,276

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 2005802276...
Checkpoint 2005802276 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 64,180.63408
Policy Entropy: 2.27146
Value Function Loss: 0.02037

Mean KL Divergence: 0.01251
SB3 Clip Fraction: 0.10394
Policy Update Magnitude: 0.31395
Value Function Update Magnitude: 0.34778

Collected Steps per Second: 22,064.28280
Overall Steps per Second: 10,601.60303

Timestep Collection Time: 2.26665
Timestep Consumption Time: 2.45075
PPO Batch Consumption Time: 0.27755
Total Iteration Time: 4.71740

Cumulative Model Updates: 240,434
Cumulative Timesteps: 2,005,852,288

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49,116.75852
Policy Entropy: 2.26763
Value Function Loss: 0.01843

Mean KL Divergence: 0.01625
SB3 Clip Fraction: 0.12403
Policy Update Magnitude: 0.29905
Value Function Update Magnitude: 0.33781

Collected Steps per Second: 22,146.77331
Overall Steps per Second: 10,481.56969

Timestep Collection Time: 2.25866
Timestep Consumption Time: 2.51372
PPO Batch Consumption Time: 0.29362
Total Iteration Time: 4.77238

Cumulative Model Updates: 240,440
Cumulative Timesteps: 2,005,902,310

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2005902310...
Checkpoint 2005902310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 56,692.86094
Policy Entropy: 2.26932
Value Function Loss: 0.02020

Mean KL Divergence: 0.01394
SB3 Clip Fraction: 0.11159
Policy Update Magnitude: 0.30747
Value Function Update Magnitude: 0.33167

Collected Steps per Second: 21,767.98185
Overall Steps per Second: 10,552.99923

Timestep Collection Time: 2.29723
Timestep Consumption Time: 2.44133
PPO Batch Consumption Time: 0.27942
Total Iteration Time: 4.73856

Cumulative Model Updates: 240,446
Cumulative Timesteps: 2,005,952,316

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49,922.40882
Policy Entropy: 2.26682
Value Function Loss: 0.01892

Mean KL Divergence: 0.01092
SB3 Clip Fraction: 0.09339
Policy Update Magnitude: 0.31534
Value Function Update Magnitude: 0.32292

Collected Steps per Second: 22,068.91561
Overall Steps per Second: 10,471.56944

Timestep Collection Time: 2.26626
Timestep Consumption Time: 2.50991
PPO Batch Consumption Time: 0.29369
Total Iteration Time: 4.77617

Cumulative Model Updates: 240,452
Cumulative Timesteps: 2,006,002,330

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2006002330...
Checkpoint 2006002330 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 68,408.97354
Policy Entropy: 2.26157
Value Function Loss: 0.01939

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.07562
Policy Update Magnitude: 0.31036
Value Function Update Magnitude: 0.32416

Collected Steps per Second: 21,915.92788
Overall Steps per Second: 10,600.31856

Timestep Collection Time: 2.28172
Timestep Consumption Time: 2.43569
PPO Batch Consumption Time: 0.27871
Total Iteration Time: 4.71741

Cumulative Model Updates: 240,458
Cumulative Timesteps: 2,006,052,336

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56,989.37973
Policy Entropy: 2.26565
Value Function Loss: 0.01845

Mean KL Divergence: 0.00751
SB3 Clip Fraction: 0.07019
Policy Update Magnitude: 0.31593
Value Function Update Magnitude: 0.32865

Collected Steps per Second: 21,281.68058
Overall Steps per Second: 10,485.42149

Timestep Collection Time: 2.35075
Timestep Consumption Time: 2.42044
PPO Batch Consumption Time: 0.28746
Total Iteration Time: 4.77120

Cumulative Model Updates: 240,464
Cumulative Timesteps: 2,006,102,364

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2006102364...
Checkpoint 2006102364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 63,379.07356
Policy Entropy: 2.27077
Value Function Loss: 0.01959

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.07524
Policy Update Magnitude: 0.31234
Value Function Update Magnitude: 0.30636

Collected Steps per Second: 21,208.66049
Overall Steps per Second: 10,620.67113

Timestep Collection Time: 2.35894
Timestep Consumption Time: 2.35168
PPO Batch Consumption Time: 0.27853
Total Iteration Time: 4.71063

Cumulative Model Updates: 240,470
Cumulative Timesteps: 2,006,152,394

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42,678.76599
Policy Entropy: 2.28834
Value Function Loss: 0.01934

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.07255
Policy Update Magnitude: 0.30362
Value Function Update Magnitude: 0.29522

Collected Steps per Second: 21,049.79498
Overall Steps per Second: 10,438.68346

Timestep Collection Time: 2.37646
Timestep Consumption Time: 2.41571
PPO Batch Consumption Time: 0.27850
Total Iteration Time: 4.79218

Cumulative Model Updates: 240,476
Cumulative Timesteps: 2,006,202,418

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2006202418...
Checkpoint 2006202418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 68,257.38825
Policy Entropy: 2.27019
Value Function Loss: 0.01896

Mean KL Divergence: 0.00690
SB3 Clip Fraction: 0.06644
Policy Update Magnitude: 0.30511
Value Function Update Magnitude: 0.30790

Collected Steps per Second: 21,264.07004
Overall Steps per Second: 10,349.08309

Timestep Collection Time: 2.35176
Timestep Consumption Time: 2.48036
PPO Batch Consumption Time: 0.29358
Total Iteration Time: 4.83212

Cumulative Model Updates: 240,482
Cumulative Timesteps: 2,006,252,426

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63,727.87539
Policy Entropy: 2.25872
Value Function Loss: 0.01878

Mean KL Divergence: 0.00702
SB3 Clip Fraction: 0.06703
Policy Update Magnitude: 0.30779
Value Function Update Magnitude: 0.32553

Collected Steps per Second: 21,548.75806
Overall Steps per Second: 10,421.57381

Timestep Collection Time: 2.32078
Timestep Consumption Time: 2.47792
PPO Batch Consumption Time: 0.29389
Total Iteration Time: 4.79870

Cumulative Model Updates: 240,488
Cumulative Timesteps: 2,006,302,436

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2006302436...
Checkpoint 2006302436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 67,587.23391
Policy Entropy: 2.25080
Value Function Loss: 0.01696

Mean KL Divergence: 0.00722
SB3 Clip Fraction: 0.06711
Policy Update Magnitude: 0.30758
Value Function Update Magnitude: 0.29436

Collected Steps per Second: 21,496.53128
Overall Steps per Second: 10,502.45991

Timestep Collection Time: 2.32679
Timestep Consumption Time: 2.43571
PPO Batch Consumption Time: 0.27893
Total Iteration Time: 4.76250

Cumulative Model Updates: 240,494
Cumulative Timesteps: 2,006,352,454

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63,620.00145
Policy Entropy: 2.28247
Value Function Loss: 0.01916

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.08135
Policy Update Magnitude: 0.30611
Value Function Update Magnitude: 0.24268

Collected Steps per Second: 21,918.93760
Overall Steps per Second: 10,550.05779

Timestep Collection Time: 2.28323
Timestep Consumption Time: 2.46044
PPO Batch Consumption Time: 0.27929
Total Iteration Time: 4.74367

Cumulative Model Updates: 240,500
Cumulative Timesteps: 2,006,402,500

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 2006402500...
Checkpoint 2006402500 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 63,620.00145
Policy Entropy: 2.29132
Value Function Loss: 0.01770

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.07833
Policy Update Magnitude: 0.30111
Value Function Update Magnitude: 0.19973

Collected Steps per Second: 21,898.31434
Overall Steps per Second: 10,519.42307

Timestep Collection Time: 2.28337
Timestep Consumption Time: 2.46993
PPO Batch Consumption Time: 0.27907
Total Iteration Time: 4.75330

Cumulative Model Updates: 240,506
Cumulative Timesteps: 2,006,452,502

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56,512.05117
Policy Entropy: 2.27967
Value Function Loss: 0.01965

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.08092
Policy Update Magnitude: 0.29895
Value Function Update Magnitude: 0.18874

Collected Steps per Second: 22,168.56788
Overall Steps per Second: 10,553.26151

Timestep Collection Time: 2.25671
Timestep Consumption Time: 2.48382
PPO Batch Consumption Time: 0.28778
Total Iteration Time: 4.74053

Cumulative Model Updates: 240,512
Cumulative Timesteps: 2,006,502,530

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2006502530...
Checkpoint 2006502530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 54,605.76235
Policy Entropy: 2.24898
Value Function Loss: 0.02017

Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.07922
Policy Update Magnitude: 0.30835
Value Function Update Magnitude: 0.16903

Collected Steps per Second: 22,041.33709
Overall Steps per Second: 10,601.32774

Timestep Collection Time: 2.26983
Timestep Consumption Time: 2.44939
PPO Batch Consumption Time: 0.28032
Total Iteration Time: 4.71922

Cumulative Model Updates: 240,518
Cumulative Timesteps: 2,006,552,560

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54,824.22213
Policy Entropy: 2.26342
Value Function Loss: 0.02113

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.07968
Policy Update Magnitude: 0.30871
Value Function Update Magnitude: 0.15666

Collected Steps per Second: 22,078.87210
Overall Steps per Second: 10,535.05375

Timestep Collection Time: 2.26597
Timestep Consumption Time: 2.48294
PPO Batch Consumption Time: 0.29024
Total Iteration Time: 4.74891

Cumulative Model Updates: 240,524
Cumulative Timesteps: 2,006,602,590

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2006602590...
Checkpoint 2006602590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 76,486.31619
Policy Entropy: 2.27710
Value Function Loss: 0.02072

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.06836
Policy Update Magnitude: 0.30094
Value Function Update Magnitude: 0.12186

Collected Steps per Second: 21,930.10446
Overall Steps per Second: 10,608.27307

Timestep Collection Time: 2.27997
Timestep Consumption Time: 2.43333
PPO Batch Consumption Time: 0.27900
Total Iteration Time: 4.71330

Cumulative Model Updates: 240,530
Cumulative Timesteps: 2,006,652,590

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78,197.68133
Policy Entropy: 2.26148
Value Function Loss: 0.01858

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.07260
Policy Update Magnitude: 0.29699
Value Function Update Magnitude: 0.12261

Collected Steps per Second: 22,066.41316
Overall Steps per Second: 10,446.64985

Timestep Collection Time: 2.26625
Timestep Consumption Time: 2.52074
PPO Batch Consumption Time: 0.29401
Total Iteration Time: 4.78699

Cumulative Model Updates: 240,536
Cumulative Timesteps: 2,006,702,598

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2006702598...
Checkpoint 2006702598 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55,724.12574
Policy Entropy: 2.24208
Value Function Loss: 0.01919

Mean KL Divergence: 0.00699
SB3 Clip Fraction: 0.06428
Policy Update Magnitude: 0.30604
Value Function Update Magnitude: 0.20878

Collected Steps per Second: 21,090.05646
Overall Steps per Second: 10,238.28843

Timestep Collection Time: 2.37230
Timestep Consumption Time: 2.51445
PPO Batch Consumption Time: 0.29396
Total Iteration Time: 4.88675

Cumulative Model Updates: 240,542
Cumulative Timesteps: 2,006,752,630

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,888.33789
Policy Entropy: 2.24546
Value Function Loss: 0.01737

Mean KL Divergence: 0.00760
SB3 Clip Fraction: 0.07334
Policy Update Magnitude: 0.30391
Value Function Update Magnitude: 0.25666

Collected Steps per Second: 21,101.00499
Overall Steps per Second: 10,449.18942

Timestep Collection Time: 2.37107
Timestep Consumption Time: 2.41705
PPO Batch Consumption Time: 0.28943
Total Iteration Time: 4.78812

Cumulative Model Updates: 240,548
Cumulative Timesteps: 2,006,802,662

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2006802662...
Checkpoint 2006802662 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46,207.76766
Policy Entropy: 2.25934
Value Function Loss: 0.01657

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.07722
Policy Update Magnitude: 0.29401
Value Function Update Magnitude: 0.23148

Collected Steps per Second: 20,896.52307
Overall Steps per Second: 10,550.49768

Timestep Collection Time: 2.39418
Timestep Consumption Time: 2.34778
PPO Batch Consumption Time: 0.27887
Total Iteration Time: 4.74196

Cumulative Model Updates: 240,554
Cumulative Timesteps: 2,006,852,692

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47,290.49584
Policy Entropy: 2.27488
Value Function Loss: 0.01638

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.07464
Policy Update Magnitude: 0.29215
Value Function Update Magnitude: 0.25486

Collected Steps per Second: 21,006.24050
Overall Steps per Second: 10,562.92334

Timestep Collection Time: 2.38072
Timestep Consumption Time: 2.35376
PPO Batch Consumption Time: 0.27746
Total Iteration Time: 4.73448

Cumulative Model Updates: 240,560
Cumulative Timesteps: 2,006,902,702

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2006902702...
Checkpoint 2006902702 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,422.12266
Policy Entropy: 2.27772
Value Function Loss: 0.01529

Mean KL Divergence: 0.00732
SB3 Clip Fraction: 0.07023
Policy Update Magnitude: 0.28436
Value Function Update Magnitude: 0.25905

Collected Steps per Second: 20,876.66553
Overall Steps per Second: 10,232.56324

Timestep Collection Time: 2.39607
Timestep Consumption Time: 2.49244
PPO Batch Consumption Time: 0.29364
Total Iteration Time: 4.88851

Cumulative Model Updates: 240,566
Cumulative Timesteps: 2,006,952,724

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47,661.77279
Policy Entropy: 2.28063
Value Function Loss: 0.01592

Mean KL Divergence: 0.00658
SB3 Clip Fraction: 0.06154
Policy Update Magnitude: 0.28510
Value Function Update Magnitude: 0.26248

Collected Steps per Second: 22,177.97743
Overall Steps per Second: 10,417.17525

Timestep Collection Time: 2.25503
Timestep Consumption Time: 2.54589
PPO Batch Consumption Time: 0.29332
Total Iteration Time: 4.80092

Cumulative Model Updates: 240,572
Cumulative Timesteps: 2,007,002,736

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2007002736...
Checkpoint 2007002736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 81,298.83612
Policy Entropy: 2.26107
Value Function Loss: 0.01737

Mean KL Divergence: 0.00668
SB3 Clip Fraction: 0.06503
Policy Update Magnitude: 0.29701
Value Function Update Magnitude: 0.26272

Collected Steps per Second: 21,744.66132
Overall Steps per Second: 10,591.84720

Timestep Collection Time: 2.30052
Timestep Consumption Time: 2.42236
PPO Batch Consumption Time: 0.27969
Total Iteration Time: 4.72288

Cumulative Model Updates: 240,578
Cumulative Timesteps: 2,007,052,760

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81,298.83612
Policy Entropy: 2.25546
Value Function Loss: 0.01753

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.08113
Policy Update Magnitude: 0.30023
Value Function Update Magnitude: 0.23469

Collected Steps per Second: 22,046.12871
Overall Steps per Second: 10,452.87266

Timestep Collection Time: 2.26806
Timestep Consumption Time: 2.51550
PPO Batch Consumption Time: 0.29136
Total Iteration Time: 4.78357

Cumulative Model Updates: 240,584
Cumulative Timesteps: 2,007,102,762

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2007102762...
Checkpoint 2007102762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 76,976.94456
Policy Entropy: 2.26019
Value Function Loss: 0.01952

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.08069
Policy Update Magnitude: 0.30864
Value Function Update Magnitude: 0.22332

Collected Steps per Second: 21,910.47229
Overall Steps per Second: 10,593.48103

Timestep Collection Time: 2.28293
Timestep Consumption Time: 2.43885
PPO Batch Consumption Time: 0.27981
Total Iteration Time: 4.72177

Cumulative Model Updates: 240,590
Cumulative Timesteps: 2,007,152,782

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75,702.52061
Policy Entropy: 2.26427
Value Function Loss: 0.01838

Mean KL Divergence: 0.00749
SB3 Clip Fraction: 0.07149
Policy Update Magnitude: 0.31132
Value Function Update Magnitude: 0.26258

Collected Steps per Second: 22,198.61821
Overall Steps per Second: 10,503.35759

Timestep Collection Time: 2.25338
Timestep Consumption Time: 2.50909
PPO Batch Consumption Time: 0.29051
Total Iteration Time: 4.76248

Cumulative Model Updates: 240,596
Cumulative Timesteps: 2,007,202,804

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2007202804...
Checkpoint 2007202804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 61,967.20765
Policy Entropy: 2.24623
Value Function Loss: 0.01882

Mean KL Divergence: 0.00770
SB3 Clip Fraction: 0.07250
Policy Update Magnitude: 0.31739
Value Function Update Magnitude: 0.31739

Collected Steps per Second: 21,982.82942
Overall Steps per Second: 10,637.23407

Timestep Collection Time: 2.27578
Timestep Consumption Time: 2.42733
PPO Batch Consumption Time: 0.27898
Total Iteration Time: 4.70310

Cumulative Model Updates: 240,602
Cumulative Timesteps: 2,007,252,832

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42,126.91008
Policy Entropy: 2.24841
Value Function Loss: 0.01865

Mean KL Divergence: 0.00729
SB3 Clip Fraction: 0.06843
Policy Update Magnitude: 0.32589
Value Function Update Magnitude: 0.33171

Collected Steps per Second: 22,019.47128
Overall Steps per Second: 10,475.03435

Timestep Collection Time: 2.27181
Timestep Consumption Time: 2.50374
PPO Batch Consumption Time: 0.29051
Total Iteration Time: 4.77555

Cumulative Model Updates: 240,608
Cumulative Timesteps: 2,007,302,856

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2007302856...
Checkpoint 2007302856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,756.92614
Policy Entropy: 2.25050
Value Function Loss: 0.01767

Mean KL Divergence: 0.00772
SB3 Clip Fraction: 0.06979
Policy Update Magnitude: 0.32301
Value Function Update Magnitude: 0.33286

Collected Steps per Second: 21,402.17501
Overall Steps per Second: 10,350.89355

Timestep Collection Time: 2.33649
Timestep Consumption Time: 2.49459
PPO Batch Consumption Time: 0.29137
Total Iteration Time: 4.83108

Cumulative Model Updates: 240,614
Cumulative Timesteps: 2,007,352,862

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,575.61336
Policy Entropy: 2.27055
Value Function Loss: 0.01690

Mean KL Divergence: 0.00752
SB3 Clip Fraction: 0.06944
Policy Update Magnitude: 0.30786
Value Function Update Magnitude: 0.31891

Collected Steps per Second: 22,084.68885
Overall Steps per Second: 10,687.93588

Timestep Collection Time: 2.26510
Timestep Consumption Time: 2.41532
PPO Batch Consumption Time: 0.27839
Total Iteration Time: 4.68042

Cumulative Model Updates: 240,620
Cumulative Timesteps: 2,007,402,886

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2007402886...
Checkpoint 2007402886 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,700.09752
Policy Entropy: 2.27025
Value Function Loss: 0.01774

Mean KL Divergence: 0.00729
SB3 Clip Fraction: 0.06933
Policy Update Magnitude: 0.30305
Value Function Update Magnitude: 0.32065

Collected Steps per Second: 21,526.78496
Overall Steps per Second: 10,377.74601

Timestep Collection Time: 2.32315
Timestep Consumption Time: 2.49581
PPO Batch Consumption Time: 0.29263
Total Iteration Time: 4.81897

Cumulative Model Updates: 240,626
Cumulative Timesteps: 2,007,452,896

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,651.00020
Policy Entropy: 2.25547
Value Function Loss: 0.01829

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.07448
Policy Update Magnitude: 0.31333
Value Function Update Magnitude: 0.33235

Collected Steps per Second: 21,110.48780
Overall Steps per Second: 10,410.61960

Timestep Collection Time: 2.36925
Timestep Consumption Time: 2.43508
PPO Batch Consumption Time: 0.29274
Total Iteration Time: 4.80433

Cumulative Model Updates: 240,632
Cumulative Timesteps: 2,007,502,912

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2007502912...
Checkpoint 2007502912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43,651.00020
Policy Entropy: 2.24411
Value Function Loss: 0.01913

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.07084
Policy Update Magnitude: 0.31777
Value Function Update Magnitude: 0.35352

Collected Steps per Second: 20,920.10032
Overall Steps per Second: 10,512.16288

Timestep Collection Time: 2.39005
Timestep Consumption Time: 2.36635
PPO Batch Consumption Time: 0.27932
Total Iteration Time: 4.75640

Cumulative Model Updates: 240,638
Cumulative Timesteps: 2,007,552,912

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57,921.28421
Policy Entropy: 2.24696
Value Function Loss: 0.01812

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.07240
Policy Update Magnitude: 0.31838
Value Function Update Magnitude: 0.35751

Collected Steps per Second: 20,319.84484
Overall Steps per Second: 10,236.14686

Timestep Collection Time: 2.46213
Timestep Consumption Time: 2.42546
PPO Batch Consumption Time: 0.29126
Total Iteration Time: 4.88758

Cumulative Model Updates: 240,644
Cumulative Timesteps: 2,007,602,942

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2007602942...
Checkpoint 2007602942 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 68,714.06773
Policy Entropy: 2.24388
Value Function Loss: 0.01733

Mean KL Divergence: 0.00770
SB3 Clip Fraction: 0.07218
Policy Update Magnitude: 0.32005
Value Function Update Magnitude: 0.32807

Collected Steps per Second: 20,655.54386
Overall Steps per Second: 10,387.64351

Timestep Collection Time: 2.42163
Timestep Consumption Time: 2.39371
PPO Batch Consumption Time: 0.27808
Total Iteration Time: 4.81534

Cumulative Model Updates: 240,650
Cumulative Timesteps: 2,007,652,962

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84,841.58274
Policy Entropy: 2.24074
Value Function Loss: 0.01927

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.07318
Policy Update Magnitude: 0.32165
Value Function Update Magnitude: 0.32126

Collected Steps per Second: 21,695.86935
Overall Steps per Second: 10,609.23792

Timestep Collection Time: 2.30486
Timestep Consumption Time: 2.40858
PPO Batch Consumption Time: 0.27754
Total Iteration Time: 4.71344

Cumulative Model Updates: 240,656
Cumulative Timesteps: 2,007,702,968

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2007702968...
Checkpoint 2007702968 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 69,473.12220
Policy Entropy: 2.23684
Value Function Loss: 0.01963

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.07505
Policy Update Magnitude: 0.32270
Value Function Update Magnitude: 0.32648

Collected Steps per Second: 21,430.13583
Overall Steps per Second: 10,527.64604

Timestep Collection Time: 2.33316
Timestep Consumption Time: 2.41624
PPO Batch Consumption Time: 0.27871
Total Iteration Time: 4.74940

Cumulative Model Updates: 240,662
Cumulative Timesteps: 2,007,752,968

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 69,006.70223
Policy Entropy: 2.25187
Value Function Loss: 0.01938

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.07604
Policy Update Magnitude: 0.32395
Value Function Update Magnitude: 0.32106

Collected Steps per Second: 22,037.51525
Overall Steps per Second: 10,469.12372

Timestep Collection Time: 2.26931
Timestep Consumption Time: 2.50759
PPO Batch Consumption Time: 0.28854
Total Iteration Time: 4.77690

Cumulative Model Updates: 240,668
Cumulative Timesteps: 2,007,802,978

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2007802978...
Checkpoint 2007802978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,926.08059
Policy Entropy: 2.25430
Value Function Loss: 0.02014

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.07601
Policy Update Magnitude: 0.32754
Value Function Update Magnitude: 0.29646

Collected Steps per Second: 22,052.40045
Overall Steps per Second: 10,621.04169

Timestep Collection Time: 2.26950
Timestep Consumption Time: 2.44265
PPO Batch Consumption Time: 0.27950
Total Iteration Time: 4.71216

Cumulative Model Updates: 240,674
Cumulative Timesteps: 2,007,853,026

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79,912.35056
Policy Entropy: 2.25111
Value Function Loss: 0.01982

Mean KL Divergence: 0.00711
SB3 Clip Fraction: 0.06723
Policy Update Magnitude: 0.32077
Value Function Update Magnitude: 0.27049

Collected Steps per Second: 22,316.00962
Overall Steps per Second: 10,493.24329

Timestep Collection Time: 2.24081
Timestep Consumption Time: 2.52473
PPO Batch Consumption Time: 0.29437
Total Iteration Time: 4.76554

Cumulative Model Updates: 240,680
Cumulative Timesteps: 2,007,903,032

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2007903032...
Checkpoint 2007903032 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 58,840.75212
Policy Entropy: 2.26506
Value Function Loss: 0.01881

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.07805
Policy Update Magnitude: 0.30886
Value Function Update Magnitude: 0.26811

Collected Steps per Second: 21,773.81019
Overall Steps per Second: 10,560.67907

Timestep Collection Time: 2.29698
Timestep Consumption Time: 2.43889
PPO Batch Consumption Time: 0.27940
Total Iteration Time: 4.73587

Cumulative Model Updates: 240,686
Cumulative Timesteps: 2,007,953,046

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65,907.80028
Policy Entropy: 2.26887
Value Function Loss: 0.01652

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.07937
Policy Update Magnitude: 0.29582
Value Function Update Magnitude: 0.28367

Collected Steps per Second: 22,203.49840
Overall Steps per Second: 10,527.97416

Timestep Collection Time: 2.25334
Timestep Consumption Time: 2.49895
PPO Batch Consumption Time: 0.28992
Total Iteration Time: 4.75229

Cumulative Model Updates: 240,692
Cumulative Timesteps: 2,008,003,078

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2008003078...
Checkpoint 2008003078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 58,700.29567
Policy Entropy: 2.26036
Value Function Loss: 0.01674

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.07183
Policy Update Magnitude: 0.29857
Value Function Update Magnitude: 0.28085

Collected Steps per Second: 21,739.81924
Overall Steps per Second: 10,609.69405

Timestep Collection Time: 2.30076
Timestep Consumption Time: 2.41361
PPO Batch Consumption Time: 0.27795
Total Iteration Time: 4.71437

Cumulative Model Updates: 240,698
Cumulative Timesteps: 2,008,053,096

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45,495.95283
Policy Entropy: 2.24024
Value Function Loss: 0.02104

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.08085
Policy Update Magnitude: 0.31529
Value Function Update Magnitude: 0.29689

Collected Steps per Second: 21,593.45467
Overall Steps per Second: 10,475.03143

Timestep Collection Time: 2.31654
Timestep Consumption Time: 2.45882
PPO Batch Consumption Time: 0.28025
Total Iteration Time: 4.77536

Cumulative Model Updates: 240,704
Cumulative Timesteps: 2,008,103,118

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2008103118...
Checkpoint 2008103118 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 78,911.07734
Policy Entropy: 2.25378
Value Function Loss: 0.02309

Mean KL Divergence: 0.01145
SB3 Clip Fraction: 0.09694
Policy Update Magnitude: 0.32192
Value Function Update Magnitude: 0.31843

Collected Steps per Second: 20,990.14428
Overall Steps per Second: 10,228.59113

Timestep Collection Time: 2.38226
Timestep Consumption Time: 2.50639
PPO Batch Consumption Time: 0.29375
Total Iteration Time: 4.88865

Cumulative Model Updates: 240,710
Cumulative Timesteps: 2,008,153,122

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 73,600.83813
Policy Entropy: 2.27328
Value Function Loss: 0.02219

Mean KL Divergence: 0.01050
SB3 Clip Fraction: 0.09233
Policy Update Magnitude: 0.32118
Value Function Update Magnitude: 0.33145

Collected Steps per Second: 21,051.10581
Overall Steps per Second: 10,435.40212

Timestep Collection Time: 2.37603
Timestep Consumption Time: 2.41708
PPO Batch Consumption Time: 0.29029
Total Iteration Time: 4.79311

Cumulative Model Updates: 240,716
Cumulative Timesteps: 2,008,203,140

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2008203140...
Checkpoint 2008203140 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 64,311.15549
Policy Entropy: 2.27527
Value Function Loss: 0.02083

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.08554
Policy Update Magnitude: 0.32317
Value Function Update Magnitude: 0.29956

Collected Steps per Second: 20,918.52059
Overall Steps per Second: 10,399.68033

Timestep Collection Time: 2.39243
Timestep Consumption Time: 2.41984
PPO Batch Consumption Time: 0.28859
Total Iteration Time: 4.81226

Cumulative Model Updates: 240,722
Cumulative Timesteps: 2,008,253,186

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49,452.42037
Policy Entropy: 2.27742
Value Function Loss: 0.02144

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.08498
Policy Update Magnitude: 0.32638
Value Function Update Magnitude: 0.26023

Collected Steps per Second: 21,552.34648
Overall Steps per Second: 10,613.05898

Timestep Collection Time: 2.32021
Timestep Consumption Time: 2.39153
PPO Batch Consumption Time: 0.27900
Total Iteration Time: 4.71174

Cumulative Model Updates: 240,728
Cumulative Timesteps: 2,008,303,192

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2008303192...
Checkpoint 2008303192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40,153.16089
Policy Entropy: 2.26684
Value Function Loss: 0.02186

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.07531
Policy Update Magnitude: 0.32048
Value Function Update Magnitude: 0.32824

Collected Steps per Second: 21,109.99278
Overall Steps per Second: 10,291.21179

Timestep Collection Time: 2.36940
Timestep Consumption Time: 2.49086
PPO Batch Consumption Time: 0.29429
Total Iteration Time: 4.86026

Cumulative Model Updates: 240,734
Cumulative Timesteps: 2,008,353,210

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46,169.29267
Policy Entropy: 2.26137
Value Function Loss: 0.02087

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.07445
Policy Update Magnitude: 0.31947
Value Function Update Magnitude: 0.36741

Collected Steps per Second: 22,137.58108
Overall Steps per Second: 10,564.74996

Timestep Collection Time: 2.25987
Timestep Consumption Time: 2.47550
PPO Batch Consumption Time: 0.29290
Total Iteration Time: 4.73537

Cumulative Model Updates: 240,740
Cumulative Timesteps: 2,008,403,238

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2008403238...
Checkpoint 2008403238 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,707.21439
Policy Entropy: 2.24383
Value Function Loss: 0.02028

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.07996
Policy Update Magnitude: 0.32130
Value Function Update Magnitude: 0.37983

Collected Steps per Second: 21,806.71697
Overall Steps per Second: 10,504.85833

Timestep Collection Time: 2.29406
Timestep Consumption Time: 2.46811
PPO Batch Consumption Time: 0.28943
Total Iteration Time: 4.76218

Cumulative Model Updates: 240,746
Cumulative Timesteps: 2,008,453,264

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,765.05400
Policy Entropy: 2.26763
Value Function Loss: 0.01892

Mean KL Divergence: 0.00708
SB3 Clip Fraction: 0.06808
Policy Update Magnitude: 0.31593
Value Function Update Magnitude: 0.36358

Collected Steps per Second: 22,324.28485
Overall Steps per Second: 10,531.89347

Timestep Collection Time: 2.24052
Timestep Consumption Time: 2.50867
PPO Batch Consumption Time: 0.29355
Total Iteration Time: 4.74919

Cumulative Model Updates: 240,752
Cumulative Timesteps: 2,008,503,282

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2008503282...
Checkpoint 2008503282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 54,955.38843
Policy Entropy: 2.26336
Value Function Loss: 0.02023

Mean KL Divergence: 0.00699
SB3 Clip Fraction: 0.06736
Policy Update Magnitude: 0.31524
Value Function Update Magnitude: 0.35353

Collected Steps per Second: 21,708.03474
Overall Steps per Second: 10,540.86819

Timestep Collection Time: 2.30551
Timestep Consumption Time: 2.44249
PPO Batch Consumption Time: 0.27942
Total Iteration Time: 4.74800

Cumulative Model Updates: 240,758
Cumulative Timesteps: 2,008,553,330

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,034.65057
Policy Entropy: 2.26435
Value Function Loss: 0.01895

Mean KL Divergence: 0.00744
SB3 Clip Fraction: 0.07096
Policy Update Magnitude: 0.31709
Value Function Update Magnitude: 0.37593

Collected Steps per Second: 21,855.24441
Overall Steps per Second: 10,504.39354

Timestep Collection Time: 2.28934
Timestep Consumption Time: 2.47381
PPO Batch Consumption Time: 0.28665
Total Iteration Time: 4.76315

Cumulative Model Updates: 240,764
Cumulative Timesteps: 2,008,603,364

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 2008603364...
Checkpoint 2008603364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 54,773.39446
Policy Entropy: 2.25620
Value Function Loss: 0.02007

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.07191
Policy Update Magnitude: 0.32334
Value Function Update Magnitude: 0.39223

Collected Steps per Second: 21,307.01149
Overall Steps per Second: 10,364.14486

Timestep Collection Time: 2.34768
Timestep Consumption Time: 2.47877
PPO Batch Consumption Time: 0.28981
Total Iteration Time: 4.82645

Cumulative Model Updates: 240,770
Cumulative Timesteps: 2,008,653,386

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42,616.33647
Policy Entropy: 2.26215
Value Function Loss: 0.01983

Mean KL Divergence: 0.00743
SB3 Clip Fraction: 0.06778
Policy Update Magnitude: 0.33141
Value Function Update Magnitude: 0.38266

Collected Steps per Second: 21,812.87587
Overall Steps per Second: 10,480.38859

Timestep Collection Time: 2.29232
Timestep Consumption Time: 2.47869
PPO Batch Consumption Time: 0.28892
Total Iteration Time: 4.77101

Cumulative Model Updates: 240,776
Cumulative Timesteps: 2,008,703,388

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2008703388...
Checkpoint 2008703388 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 53,647.97546
Policy Entropy: 2.27700
Value Function Loss: 0.02052

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.06884
Policy Update Magnitude: 0.32452
Value Function Update Magnitude: 0.33493

Collected Steps per Second: 21,809.56069
Overall Steps per Second: 10,435.57929

Timestep Collection Time: 2.29441
Timestep Consumption Time: 2.50073
PPO Batch Consumption Time: 0.28967
Total Iteration Time: 4.79513

Cumulative Model Updates: 240,782
Cumulative Timesteps: 2,008,753,428

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,327.80286
Policy Entropy: 2.27600
Value Function Loss: 0.02076

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.07720
Policy Update Magnitude: 0.31789
Value Function Update Magnitude: 0.32684

Collected Steps per Second: 21,586.92683
Overall Steps per Second: 10,455.79787

Timestep Collection Time: 2.31835
Timestep Consumption Time: 2.46809
PPO Batch Consumption Time: 0.28499
Total Iteration Time: 4.78644

Cumulative Model Updates: 240,788
Cumulative Timesteps: 2,008,803,474

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 2008803474...
Checkpoint 2008803474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,786.42731
Policy Entropy: 2.26810
Value Function Loss: 0.02077

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.07795
Policy Update Magnitude: 0.32335
Value Function Update Magnitude: 0.34098

Collected Steps per Second: 21,703.49803
Overall Steps per Second: 10,560.76938

Timestep Collection Time: 2.30396
Timestep Consumption Time: 2.43092
PPO Batch Consumption Time: 0.27896
Total Iteration Time: 4.73488

Cumulative Model Updates: 240,794
Cumulative Timesteps: 2,008,853,478

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,724.32503
Policy Entropy: 2.25081
Value Function Loss: 0.01932

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.08304
Policy Update Magnitude: 0.31996
Value Function Update Magnitude: 0.31425

Collected Steps per Second: 22,144.08629
Overall Steps per Second: 10,601.97721

Timestep Collection Time: 2.26011
Timestep Consumption Time: 2.46052
PPO Batch Consumption Time: 0.27810
Total Iteration Time: 4.72063

Cumulative Model Updates: 240,800
Cumulative Timesteps: 2,008,903,526

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 2008903526...
Checkpoint 2008903526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,100.47889
Policy Entropy: 2.24974
Value Function Loss: 0.01914

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.07640
Policy Update Magnitude: 0.31829
Value Function Update Magnitude: 0.31591

Collected Steps per Second: 21,699.46416
Overall Steps per Second: 10,526.95689

Timestep Collection Time: 2.30439
Timestep Consumption Time: 2.44570
PPO Batch Consumption Time: 0.27916
Total Iteration Time: 4.75009

Cumulative Model Updates: 240,806
Cumulative Timesteps: 2,008,953,530

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,147.30196
Policy Entropy: 2.24703
Value Function Loss: 0.01992

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.07234
Policy Update Magnitude: 0.31819
Value Function Update Magnitude: 0.30456

Collected Steps per Second: 21,741.30868
Overall Steps per Second: 10,483.12329

Timestep Collection Time: 2.30041
Timestep Consumption Time: 2.47049
PPO Batch Consumption Time: 0.28623
Total Iteration Time: 4.77091

Cumulative Model Updates: 240,812
Cumulative Timesteps: 2,009,003,544

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2009003544...
Checkpoint 2009003544 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,147.30196
Policy Entropy: 2.25846
Value Function Loss: 0.01867

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.07469
Policy Update Magnitude: 0.30805
Value Function Update Magnitude: 0.31278

Collected Steps per Second: 21,928.28390
Overall Steps per Second: 10,603.37672

Timestep Collection Time: 2.28171
Timestep Consumption Time: 2.43697
PPO Batch Consumption Time: 0.27936
Total Iteration Time: 4.71869

Cumulative Model Updates: 240,818
Cumulative Timesteps: 2,009,053,578

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,630.06601
Policy Entropy: 2.25205
Value Function Loss: 0.01812

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.07727
Policy Update Magnitude: 0.29938
Value Function Update Magnitude: 0.30837

Collected Steps per Second: 21,464.53883
Overall Steps per Second: 10,488.22334

Timestep Collection Time: 2.33082
Timestep Consumption Time: 2.43929
PPO Batch Consumption Time: 0.29469
Total Iteration Time: 4.77011

Cumulative Model Updates: 240,824
Cumulative Timesteps: 2,009,103,608

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2009103608...
Checkpoint 2009103608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,021.14720
Policy Entropy: 2.26658
Value Function Loss: 0.01617

Mean KL Divergence: 0.00731
SB3 Clip Fraction: 0.06886
Policy Update Magnitude: 0.29611
Value Function Update Magnitude: 0.30217

Collected Steps per Second: 21,592.20478
Overall Steps per Second: 10,612.00693

Timestep Collection Time: 2.31704
Timestep Consumption Time: 2.39743
PPO Batch Consumption Time: 0.28600
Total Iteration Time: 4.71447

Cumulative Model Updates: 240,830
Cumulative Timesteps: 2,009,153,638

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,486.92560
Policy Entropy: 2.29121
Value Function Loss: 0.01811

Mean KL Divergence: 0.00668
SB3 Clip Fraction: 0.06396
Policy Update Magnitude: 0.29710
Value Function Update Magnitude: 0.30981

Collected Steps per Second: 21,139.03459
Overall Steps per Second: 10,495.66498

Timestep Collection Time: 2.36690
Timestep Consumption Time: 2.40021
PPO Batch Consumption Time: 0.28677
Total Iteration Time: 4.76711

Cumulative Model Updates: 240,836
Cumulative Timesteps: 2,009,203,672

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 2009203672...
Checkpoint 2009203672 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 54,490.47423
Policy Entropy: 2.29640
Value Function Loss: 0.01611

Mean KL Divergence: 0.00614
SB3 Clip Fraction: 0.06029
Policy Update Magnitude: 0.29462
Value Function Update Magnitude: 0.28351

Collected Steps per Second: 20,798.22787
Overall Steps per Second: 10,196.94725

Timestep Collection Time: 2.40424
Timestep Consumption Time: 2.49958
PPO Batch Consumption Time: 0.29393
Total Iteration Time: 4.90382

Cumulative Model Updates: 240,842
Cumulative Timesteps: 2,009,253,676

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58,412.49424
Policy Entropy: 2.29104
Value Function Loss: 0.01690

Mean KL Divergence: 0.00610
SB3 Clip Fraction: 0.06028
Policy Update Magnitude: 0.29195
Value Function Update Magnitude: 0.24048

Collected Steps per Second: 21,656.21037
Overall Steps per Second: 10,426.22245

Timestep Collection Time: 2.30945
Timestep Consumption Time: 2.48749
PPO Batch Consumption Time: 0.29145
Total Iteration Time: 4.79694

Cumulative Model Updates: 240,848
Cumulative Timesteps: 2,009,303,690

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2009303690...
Checkpoint 2009303690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,744.26446
Policy Entropy: 2.27496
Value Function Loss: 0.01764

Mean KL Divergence: 0.00693
SB3 Clip Fraction: 0.06704
Policy Update Magnitude: 0.30026
Value Function Update Magnitude: 0.24362

Collected Steps per Second: 21,575.72416
Overall Steps per Second: 10,568.03639

Timestep Collection Time: 2.31798
Timestep Consumption Time: 2.41441
PPO Batch Consumption Time: 0.27874
Total Iteration Time: 4.73238

Cumulative Model Updates: 240,854
Cumulative Timesteps: 2,009,353,702

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48,605.61278
Policy Entropy: 2.26904
Value Function Loss: 0.01937

Mean KL Divergence: 0.00747
SB3 Clip Fraction: 0.07100
Policy Update Magnitude: 0.30961
Value Function Update Magnitude: 0.27546

Collected Steps per Second: 21,767.32973
Overall Steps per Second: 10,516.75908

Timestep Collection Time: 2.29932
Timestep Consumption Time: 2.45975
PPO Batch Consumption Time: 0.27872
Total Iteration Time: 4.75907

Cumulative Model Updates: 240,860
Cumulative Timesteps: 2,009,403,752

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 2009403752...
Checkpoint 2009403752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 81,132.89823
Policy Entropy: 2.27086
Value Function Loss: 0.01828

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.08079
Policy Update Magnitude: 0.30898
Value Function Update Magnitude: 0.29210

Collected Steps per Second: 21,982.31471
Overall Steps per Second: 10,553.54910

Timestep Collection Time: 2.27474
Timestep Consumption Time: 2.46338
PPO Batch Consumption Time: 0.28011
Total Iteration Time: 4.73812

Cumulative Model Updates: 240,866
Cumulative Timesteps: 2,009,453,756

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59,339.31486
Policy Entropy: 2.28641
Value Function Loss: 0.01712

Mean KL Divergence: 0.01332
SB3 Clip Fraction: 0.10986
Policy Update Magnitude: 0.29308
Value Function Update Magnitude: 0.29351

Collected Steps per Second: 22,183.63051
Overall Steps per Second: 10,566.47527

Timestep Collection Time: 2.25518
Timestep Consumption Time: 2.47942
PPO Batch Consumption Time: 0.28574
Total Iteration Time: 4.73460

Cumulative Model Updates: 240,872
Cumulative Timesteps: 2,009,503,784

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2009503784...
Checkpoint 2009503784 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 70,094.13287
Policy Entropy: 2.29121
Value Function Loss: 0.01806

Mean KL Divergence: 0.01395
SB3 Clip Fraction: 0.11214
Policy Update Magnitude: 0.28388
Value Function Update Magnitude: 0.29799

Collected Steps per Second: 21,841.34378
Overall Steps per Second: 10,569.79258

Timestep Collection Time: 2.29024
Timestep Consumption Time: 2.44230
PPO Batch Consumption Time: 0.27981
Total Iteration Time: 4.73254

Cumulative Model Updates: 240,878
Cumulative Timesteps: 2,009,553,806

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 72,183.55671
Policy Entropy: 2.28301
Value Function Loss: 0.01660

Mean KL Divergence: 0.01344
SB3 Clip Fraction: 0.11356
Policy Update Magnitude: 0.28797
Value Function Update Magnitude: 0.31052

Collected Steps per Second: 21,812.03498
Overall Steps per Second: 10,617.98686

Timestep Collection Time: 2.29451
Timestep Consumption Time: 2.41900
PPO Batch Consumption Time: 0.27733
Total Iteration Time: 4.71351

Cumulative Model Updates: 240,884
Cumulative Timesteps: 2,009,603,854

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 2009603854...
Checkpoint 2009603854 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 62,230.94087
Policy Entropy: 2.27926
Value Function Loss: 0.01728

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.09643
Policy Update Magnitude: 0.29319
Value Function Update Magnitude: 0.31235

Collected Steps per Second: 21,524.60533
Overall Steps per Second: 10,525.06921

Timestep Collection Time: 2.32422
Timestep Consumption Time: 2.42900
PPO Batch Consumption Time: 0.27929
Total Iteration Time: 4.75322

Cumulative Model Updates: 240,890
Cumulative Timesteps: 2,009,653,882

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 69,493.55317
Policy Entropy: 2.27529
Value Function Loss: 0.01618

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.08656
Policy Update Magnitude: 0.29630
Value Function Update Magnitude: 0.30363

Collected Steps per Second: 21,641.56881
Overall Steps per Second: 10,440.47469

Timestep Collection Time: 2.31129
Timestep Consumption Time: 2.47968
PPO Batch Consumption Time: 0.28690
Total Iteration Time: 4.79097

Cumulative Model Updates: 240,896
Cumulative Timesteps: 2,009,703,902

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2009703902...
Checkpoint 2009703902 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 51,318.56285
Policy Entropy: 2.28433
Value Function Loss: 0.01672

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.07426
Policy Update Magnitude: 0.29497
Value Function Update Magnitude: 0.30383

Collected Steps per Second: 21,220.85755
Overall Steps per Second: 10,311.28972

Timestep Collection Time: 2.35627
Timestep Consumption Time: 2.49298
PPO Batch Consumption Time: 0.29350
Total Iteration Time: 4.84925

Cumulative Model Updates: 240,902
Cumulative Timesteps: 2,009,753,904

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49,277.14790
Policy Entropy: 2.27520
Value Function Loss: 0.01724

Mean KL Divergence: 0.00715
SB3 Clip Fraction: 0.06774
Policy Update Magnitude: 0.29510
Value Function Update Magnitude: 0.31669

Collected Steps per Second: 21,535.33113
Overall Steps per Second: 10,369.55516

Timestep Collection Time: 2.32214
Timestep Consumption Time: 2.50044
PPO Batch Consumption Time: 0.29186
Total Iteration Time: 4.82258

Cumulative Model Updates: 240,908
Cumulative Timesteps: 2,009,803,912

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2009803912...
Checkpoint 2009803912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 57,461.25830
Policy Entropy: 2.26609
Value Function Loss: 0.01946

Mean KL Divergence: 0.00679
SB3 Clip Fraction: 0.06522
Policy Update Magnitude: 0.31260
Value Function Update Magnitude: 0.33224

Collected Steps per Second: 20,867.13356
Overall Steps per Second: 10,420.92922

Timestep Collection Time: 2.39736
Timestep Consumption Time: 2.40317
PPO Batch Consumption Time: 0.28850
Total Iteration Time: 4.80053

Cumulative Model Updates: 240,914
Cumulative Timesteps: 2,009,853,938

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,119.34855
Policy Entropy: 2.25924
Value Function Loss: 0.02019

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.07457
Policy Update Magnitude: 0.31911
Value Function Update Magnitude: 0.31240

Collected Steps per Second: 21,195.89715
Overall Steps per Second: 10,422.00580

Timestep Collection Time: 2.35961
Timestep Consumption Time: 2.43928
PPO Batch Consumption Time: 0.29004
Total Iteration Time: 4.79888

Cumulative Model Updates: 240,920
Cumulative Timesteps: 2,009,903,952

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2009903952...
Checkpoint 2009903952 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,771.82488
Policy Entropy: 2.25318
Value Function Loss: 0.02029

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.07991
Policy Update Magnitude: 0.31900
Value Function Update Magnitude: 0.32615

Collected Steps per Second: 21,307.78489
Overall Steps per Second: 10,340.14628

Timestep Collection Time: 2.34731
Timestep Consumption Time: 2.48976
PPO Batch Consumption Time: 0.29792
Total Iteration Time: 4.83707

Cumulative Model Updates: 240,926
Cumulative Timesteps: 2,009,953,968

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 69,894.21725
Policy Entropy: 2.25343
Value Function Loss: 0.01921

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.07571
Policy Update Magnitude: 0.31689
Value Function Update Magnitude: 0.32160

Collected Steps per Second: 21,325.14215
Overall Steps per Second: 10,545.34076

Timestep Collection Time: 2.34503
Timestep Consumption Time: 2.39716
PPO Batch Consumption Time: 0.28551
Total Iteration Time: 4.74219

Cumulative Model Updates: 240,932
Cumulative Timesteps: 2,010,003,976

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2010003976...
Checkpoint 2010003976 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 72,832.04437
Policy Entropy: 2.25808
Value Function Loss: 0.01888

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.07781
Policy Update Magnitude: 0.31051
Value Function Update Magnitude: 0.29979

Collected Steps per Second: 21,312.50708
Overall Steps per Second: 10,567.76461

Timestep Collection Time: 2.34745
Timestep Consumption Time: 2.38676
PPO Batch Consumption Time: 0.27904
Total Iteration Time: 4.73421

Cumulative Model Updates: 240,938
Cumulative Timesteps: 2,010,054,006

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,095.04123
Policy Entropy: 2.25317
Value Function Loss: 0.01873

Mean KL Divergence: 0.00738
SB3 Clip Fraction: 0.07083
Policy Update Magnitude: 0.30914
Value Function Update Magnitude: 0.31687

Collected Steps per Second: 22,002.79364
Overall Steps per Second: 10,509.32482

Timestep Collection Time: 2.27280
Timestep Consumption Time: 2.48564
PPO Batch Consumption Time: 0.29174
Total Iteration Time: 4.75844

Cumulative Model Updates: 240,944
Cumulative Timesteps: 2,010,104,014

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2010104014...
Checkpoint 2010104014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 61,544.33704
Policy Entropy: 2.27130
Value Function Loss: 0.01753

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.08012
Policy Update Magnitude: 0.31045
Value Function Update Magnitude: 0.31698

Collected Steps per Second: 21,928.33021
Overall Steps per Second: 10,662.46877

Timestep Collection Time: 2.28052
Timestep Consumption Time: 2.40958
PPO Batch Consumption Time: 0.27885
Total Iteration Time: 4.69010

Cumulative Model Updates: 240,950
Cumulative Timesteps: 2,010,154,022

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85,959.84596
Policy Entropy: 2.27989
Value Function Loss: 0.01591

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.07733
Policy Update Magnitude: 0.30311
Value Function Update Magnitude: 0.28788

Collected Steps per Second: 22,009.93443
Overall Steps per Second: 10,461.71307

Timestep Collection Time: 2.27270
Timestep Consumption Time: 2.50873
PPO Batch Consumption Time: 0.29210
Total Iteration Time: 4.78143

Cumulative Model Updates: 240,956
Cumulative Timesteps: 2,010,204,044

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2010204044...
Checkpoint 2010204044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 56,878.51554
Policy Entropy: 2.27243
Value Function Loss: 0.01855

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.08091
Policy Update Magnitude: 0.30003
Value Function Update Magnitude: 0.28255

Collected Steps per Second: 21,741.88494
Overall Steps per Second: 10,567.21550

Timestep Collection Time: 2.30136
Timestep Consumption Time: 2.43366
PPO Batch Consumption Time: 0.27873
Total Iteration Time: 4.73502

Cumulative Model Updates: 240,962
Cumulative Timesteps: 2,010,254,080

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53,055.75823
Policy Entropy: 2.27336
Value Function Loss: 0.01819

Mean KL Divergence: 0.00732
SB3 Clip Fraction: 0.07003
Policy Update Magnitude: 0.30750
Value Function Update Magnitude: 0.31717

Collected Steps per Second: 21,339.73690
Overall Steps per Second: 10,452.65198

Timestep Collection Time: 2.34436
Timestep Consumption Time: 2.44179
PPO Batch Consumption Time: 0.27879
Total Iteration Time: 4.78615

Cumulative Model Updates: 240,968
Cumulative Timesteps: 2,010,304,108

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2010304108...
Checkpoint 2010304108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,246.90508
Policy Entropy: 2.27863
Value Function Loss: 0.01818

Mean KL Divergence: 0.00762
SB3 Clip Fraction: 0.06990
Policy Update Magnitude: 0.30131
Value Function Update Magnitude: 0.32161

Collected Steps per Second: 21,379.54719
Overall Steps per Second: 10,299.12880

Timestep Collection Time: 2.33934
Timestep Consumption Time: 2.51680
PPO Batch Consumption Time: 0.29321
Total Iteration Time: 4.85614

Cumulative Model Updates: 240,974
Cumulative Timesteps: 2,010,354,122

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,158.43770
Policy Entropy: 2.30154
Value Function Loss: 0.01649

Mean KL Divergence: 0.00699
SB3 Clip Fraction: 0.06535
Policy Update Magnitude: 0.29941
Value Function Update Magnitude: 0.30317

Collected Steps per Second: 21,852.33771
Overall Steps per Second: 10,418.19676

Timestep Collection Time: 2.28918
Timestep Consumption Time: 2.51242
PPO Batch Consumption Time: 0.29219
Total Iteration Time: 4.80160

Cumulative Model Updates: 240,980
Cumulative Timesteps: 2,010,404,146

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2010404146...
Checkpoint 2010404146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 93,798.18528
Policy Entropy: 2.31506
Value Function Loss: 0.01729

Mean KL Divergence: 0.00691
SB3 Clip Fraction: 0.06342
Policy Update Magnitude: 0.29967
Value Function Update Magnitude: 0.29713

Collected Steps per Second: 21,819.96020
Overall Steps per Second: 10,590.70715

Timestep Collection Time: 2.29258
Timestep Consumption Time: 2.43081
PPO Batch Consumption Time: 0.27866
Total Iteration Time: 4.72339

Cumulative Model Updates: 240,986
Cumulative Timesteps: 2,010,454,170

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92,672.29838
Policy Entropy: 2.30678
Value Function Loss: 0.01768

Mean KL Divergence: 0.00745
SB3 Clip Fraction: 0.07042
Policy Update Magnitude: 0.29770
Value Function Update Magnitude: 0.26995

Collected Steps per Second: 22,048.21493
Overall Steps per Second: 10,556.84454

Timestep Collection Time: 2.26966
Timestep Consumption Time: 2.47058
PPO Batch Consumption Time: 0.27824
Total Iteration Time: 4.74024

Cumulative Model Updates: 240,992
Cumulative Timesteps: 2,010,504,212

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 2010504212...
Checkpoint 2010504212 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87,254.98880
Policy Entropy: 2.30508
Value Function Loss: 0.01875

Mean KL Divergence: 0.00681
SB3 Clip Fraction: 0.06680
Policy Update Magnitude: 0.30483
Value Function Update Magnitude: 0.32346

Collected Steps per Second: 21,988.11740
Overall Steps per Second: 10,625.70659

Timestep Collection Time: 2.27587
Timestep Consumption Time: 2.43366
PPO Batch Consumption Time: 0.27843
Total Iteration Time: 4.70952

Cumulative Model Updates: 240,998
Cumulative Timesteps: 2,010,554,254

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65,438.37167
Policy Entropy: 2.31345
Value Function Loss: 0.01638

Mean KL Divergence: 0.00777
SB3 Clip Fraction: 0.06388
Policy Update Magnitude: 0.30438
Value Function Update Magnitude: 0.35386

Collected Steps per Second: 21,975.82984
Overall Steps per Second: 10,444.63588

Timestep Collection Time: 2.27586
Timestep Consumption Time: 2.51262
PPO Batch Consumption Time: 0.29443
Total Iteration Time: 4.78849

Cumulative Model Updates: 241,004
Cumulative Timesteps: 2,010,604,268

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2010604268...
Checkpoint 2010604268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55,798.46946
Policy Entropy: 2.31782
Value Function Loss: 0.01570

Mean KL Divergence: 0.01086
SB3 Clip Fraction: 0.06675
Policy Update Magnitude: 0.30890
Value Function Update Magnitude: 0.34037

Collected Steps per Second: 21,486.21294
Overall Steps per Second: 10,531.71581

Timestep Collection Time: 2.32735
Timestep Consumption Time: 2.42078
PPO Batch Consumption Time: 0.27868
Total Iteration Time: 4.74813

Cumulative Model Updates: 241,010
Cumulative Timesteps: 2,010,654,274

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75,955.94036
Policy Entropy: 2.30840
Value Function Loss: 0.01550

Mean KL Divergence: 0.00721
SB3 Clip Fraction: 0.06815
Policy Update Magnitude: 0.30113
Value Function Update Magnitude: 0.31073

Collected Steps per Second: 22,019.63000
Overall Steps per Second: 10,586.98018

Timestep Collection Time: 2.27106
Timestep Consumption Time: 2.45247
PPO Batch Consumption Time: 0.27795
Total Iteration Time: 4.72354

Cumulative Model Updates: 241,016
Cumulative Timesteps: 2,010,704,282

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2010704282...
Checkpoint 2010704282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 58,605.11791
Policy Entropy: 2.28695
Value Function Loss: 0.01927

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.07548
Policy Update Magnitude: 0.30757
Value Function Update Magnitude: 0.32167

Collected Steps per Second: 21,903.80483
Overall Steps per Second: 10,596.45571

Timestep Collection Time: 2.28344
Timestep Consumption Time: 2.43663
PPO Batch Consumption Time: 0.27911
Total Iteration Time: 4.72007

Cumulative Model Updates: 241,022
Cumulative Timesteps: 2,010,754,298

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56,018.33460
Policy Entropy: 2.28028
Value Function Loss: 0.01870

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.08500
Policy Update Magnitude: 0.30445
Value Function Update Magnitude: 0.33097

Collected Steps per Second: 21,695.56285
Overall Steps per Second: 10,487.14414

Timestep Collection Time: 2.30526
Timestep Consumption Time: 2.46381
PPO Batch Consumption Time: 0.28646
Total Iteration Time: 4.76908

Cumulative Model Updates: 241,028
Cumulative Timesteps: 2,010,804,312

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2010804312...
Checkpoint 2010804312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47,553.54136
Policy Entropy: 2.27948
Value Function Loss: 0.01856

Mean KL Divergence: 0.01639
SB3 Clip Fraction: 0.12203
Policy Update Magnitude: 0.29243
Value Function Update Magnitude: 0.33253

Collected Steps per Second: 20,931.79255
Overall Steps per Second: 10,186.07213

Timestep Collection Time: 2.38881
Timestep Consumption Time: 2.52005
PPO Batch Consumption Time: 0.29463
Total Iteration Time: 4.90886

Cumulative Model Updates: 241,034
Cumulative Timesteps: 2,010,854,314

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,814.02594
Policy Entropy: 2.27227
Value Function Loss: 0.01612

Mean KL Divergence: 0.01247
SB3 Clip Fraction: 0.10272
Policy Update Magnitude: 0.29003
Value Function Update Magnitude: 0.31426

Collected Steps per Second: 21,221.62240
Overall Steps per Second: 10,445.36627

Timestep Collection Time: 2.35731
Timestep Consumption Time: 2.43199
PPO Batch Consumption Time: 0.29123
Total Iteration Time: 4.78930

Cumulative Model Updates: 241,040
Cumulative Timesteps: 2,010,904,340

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2010904340...
Checkpoint 2010904340 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 72,207.94346
Policy Entropy: 2.28068
Value Function Loss: 0.01495

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.09334
Policy Update Magnitude: 0.28382
Value Function Update Magnitude: 0.27585

Collected Steps per Second: 20,785.60474
Overall Steps per Second: 10,397.17093

Timestep Collection Time: 2.40570
Timestep Consumption Time: 2.40368
PPO Batch Consumption Time: 0.28881
Total Iteration Time: 4.80939

Cumulative Model Updates: 241,046
Cumulative Timesteps: 2,010,954,344

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70,450.58348
Policy Entropy: 2.28606
Value Function Loss: 0.01839

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.07811
Policy Update Magnitude: 0.29501
Value Function Update Magnitude: 0.23716

Collected Steps per Second: 21,642.56625
Overall Steps per Second: 10,675.31869

Timestep Collection Time: 2.31137
Timestep Consumption Time: 2.37458
PPO Batch Consumption Time: 0.27831
Total Iteration Time: 4.68595

Cumulative Model Updates: 241,052
Cumulative Timesteps: 2,011,004,368

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2011004368...
Checkpoint 2011004368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 60,211.75653
Policy Entropy: 2.27475
Value Function Loss: 0.01908

Mean KL Divergence: 0.00706
SB3 Clip Fraction: 0.06840
Policy Update Magnitude: 0.30565
Value Function Update Magnitude: 0.26149

Collected Steps per Second: 20,918.77771
Overall Steps per Second: 10,226.82422

Timestep Collection Time: 2.39125
Timestep Consumption Time: 2.50001
PPO Batch Consumption Time: 0.29422
Total Iteration Time: 4.89125

Cumulative Model Updates: 241,058
Cumulative Timesteps: 2,011,054,390

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50,171.46904
Policy Entropy: 2.26424
Value Function Loss: 0.01968

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.08238
Policy Update Magnitude: 0.31509
Value Function Update Magnitude: 0.32024

Collected Steps per Second: 21,938.92440
Overall Steps per Second: 10,481.48373

Timestep Collection Time: 2.27905
Timestep Consumption Time: 2.49126
PPO Batch Consumption Time: 0.29238
Total Iteration Time: 4.77032

Cumulative Model Updates: 241,064
Cumulative Timesteps: 2,011,104,390

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2011104390...
Checkpoint 2011104390 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 74,495.22478
Policy Entropy: 2.26273
Value Function Loss: 0.01757

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.08711
Policy Update Magnitude: 0.31449
Value Function Update Magnitude: 0.34479

Collected Steps per Second: 21,857.39626
Overall Steps per Second: 10,662.95005

Timestep Collection Time: 2.28847
Timestep Consumption Time: 2.40254
PPO Batch Consumption Time: 0.27788
Total Iteration Time: 4.69101

Cumulative Model Updates: 241,070
Cumulative Timesteps: 2,011,154,410

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78,216.69513
Policy Entropy: 2.28308
Value Function Loss: 0.01719

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.08670
Policy Update Magnitude: 0.30707
Value Function Update Magnitude: 0.31291

Collected Steps per Second: 22,165.17710
Overall Steps per Second: 10,513.62373

Timestep Collection Time: 2.25669
Timestep Consumption Time: 2.50094
PPO Batch Consumption Time: 0.29208
Total Iteration Time: 4.75764

Cumulative Model Updates: 241,076
Cumulative Timesteps: 2,011,204,430

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2011204430...
Checkpoint 2011204430 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 83,112.25121
Policy Entropy: 2.31145
Value Function Loss: 0.01785

Mean KL Divergence: 0.01105
SB3 Clip Fraction: 0.09653
Policy Update Magnitude: 0.30199
Value Function Update Magnitude: 0.31526

Collected Steps per Second: 21,813.35059
Overall Steps per Second: 10,601.98717

Timestep Collection Time: 2.29236
Timestep Consumption Time: 2.42412
PPO Batch Consumption Time: 0.27781
Total Iteration Time: 4.71647

Cumulative Model Updates: 241,082
Cumulative Timesteps: 2,011,254,434

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66,213.90916
Policy Entropy: 2.31382
Value Function Loss: 0.01780

Mean KL Divergence: 0.01246
SB3 Clip Fraction: 0.10957
Policy Update Magnitude: 0.30016
Value Function Update Magnitude: 0.32649

Collected Steps per Second: 22,081.76636
Overall Steps per Second: 10,457.07033

Timestep Collection Time: 2.26567
Timestep Consumption Time: 2.51865
PPO Batch Consumption Time: 0.29276
Total Iteration Time: 4.78432

Cumulative Model Updates: 241,088
Cumulative Timesteps: 2,011,304,464

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2011304464...
Checkpoint 2011304464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 77,395.83455
Policy Entropy: 2.29804
Value Function Loss: 0.01991

Mean KL Divergence: 0.01266
SB3 Clip Fraction: 0.10728
Policy Update Magnitude: 0.30195
Value Function Update Magnitude: 0.33310

Collected Steps per Second: 20,168.80456
Overall Steps per Second: 10,111.65660

Timestep Collection Time: 2.47997
Timestep Consumption Time: 2.46660
PPO Batch Consumption Time: 0.27914
Total Iteration Time: 4.94657

Cumulative Model Updates: 241,094
Cumulative Timesteps: 2,011,354,482

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79,905.56736
Policy Entropy: 2.28962
Value Function Loss: 0.02096

Mean KL Divergence: 0.01172
SB3 Clip Fraction: 0.10241
Policy Update Magnitude: 0.31352
Value Function Update Magnitude: 0.36202

Collected Steps per Second: 21,576.64702
Overall Steps per Second: 10,537.38272

Timestep Collection Time: 2.31862
Timestep Consumption Time: 2.42905
PPO Batch Consumption Time: 0.27742
Total Iteration Time: 4.74767

Cumulative Model Updates: 241,100
Cumulative Timesteps: 2,011,404,510

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2011404510...
Checkpoint 2011404510 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 71,753.57157
Policy Entropy: 2.27993
Value Function Loss: 0.02141

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.09232
Policy Update Magnitude: 0.32023
Value Function Update Magnitude: 0.36779

Collected Steps per Second: 21,307.02843
Overall Steps per Second: 10,309.65229

Timestep Collection Time: 2.34777
Timestep Consumption Time: 2.50438
PPO Batch Consumption Time: 0.29147
Total Iteration Time: 4.85215

Cumulative Model Updates: 241,106
Cumulative Timesteps: 2,011,454,534

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76,141.80954
Policy Entropy: 2.27466
Value Function Loss: 0.02031

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.08303
Policy Update Magnitude: 0.32688
Value Function Update Magnitude: 0.34585

Collected Steps per Second: 21,568.51406
Overall Steps per Second: 10,348.78300

Timestep Collection Time: 2.31884
Timestep Consumption Time: 2.51400
PPO Batch Consumption Time: 0.29376
Total Iteration Time: 4.83284

Cumulative Model Updates: 241,112
Cumulative Timesteps: 2,011,504,548

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2011504548...
Checkpoint 2011504548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 74,237.24937
Policy Entropy: 2.27632
Value Function Loss: 0.02250

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.08950
Policy Update Magnitude: 0.32614
Value Function Update Magnitude: 0.35470

Collected Steps per Second: 21,463.66266
Overall Steps per Second: 10,516.20314

Timestep Collection Time: 2.33017
Timestep Consumption Time: 2.42573
PPO Batch Consumption Time: 0.27834
Total Iteration Time: 4.75590

Cumulative Model Updates: 241,118
Cumulative Timesteps: 2,011,554,562

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59,825.46134
Policy Entropy: 2.27794
Value Function Loss: 0.02079

Mean KL Divergence: 0.01179
SB3 Clip Fraction: 0.09578
Policy Update Magnitude: 0.32072
Value Function Update Magnitude: 0.36227

Collected Steps per Second: 22,400.95534
Overall Steps per Second: 10,502.33636

Timestep Collection Time: 2.23383
Timestep Consumption Time: 2.53082
PPO Batch Consumption Time: 0.28553
Total Iteration Time: 4.76465

Cumulative Model Updates: 241,124
Cumulative Timesteps: 2,011,604,602

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 2011604602...
Checkpoint 2011604602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 59,825.46134
Policy Entropy: 2.29463
Value Function Loss: 0.01831

Mean KL Divergence: 0.01226
SB3 Clip Fraction: 0.09342
Policy Update Magnitude: 0.30665
Value Function Update Magnitude: 0.33274

Collected Steps per Second: 21,719.26943
Overall Steps per Second: 10,553.60989

Timestep Collection Time: 2.30220
Timestep Consumption Time: 2.43571
PPO Batch Consumption Time: 0.27920
Total Iteration Time: 4.73790

Cumulative Model Updates: 241,130
Cumulative Timesteps: 2,011,654,604

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,559.27193
Policy Entropy: 2.29281
Value Function Loss: 0.01850

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.08491
Policy Update Magnitude: 0.31033
Value Function Update Magnitude: 0.33667

Collected Steps per Second: 22,317.12356
Overall Steps per Second: 10,527.87724

Timestep Collection Time: 2.24043
Timestep Consumption Time: 2.50886
PPO Batch Consumption Time: 0.29009
Total Iteration Time: 4.74930

Cumulative Model Updates: 241,136
Cumulative Timesteps: 2,011,704,604

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2011704604...
Checkpoint 2011704604 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,770.34601
Policy Entropy: 2.29755
Value Function Loss: 0.02157

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.08446
Policy Update Magnitude: 0.32740
Value Function Update Magnitude: 0.35617

Collected Steps per Second: 21,732.82817
Overall Steps per Second: 10,583.74095

Timestep Collection Time: 2.30214
Timestep Consumption Time: 2.42511
PPO Batch Consumption Time: 0.27875
Total Iteration Time: 4.72725

Cumulative Model Updates: 241,142
Cumulative Timesteps: 2,011,754,636

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,647.65961
Policy Entropy: 2.29472
Value Function Loss: 0.02033

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.08777
Policy Update Magnitude: 0.32048
Value Function Update Magnitude: 0.35384

Collected Steps per Second: 22,103.92103
Overall Steps per Second: 10,534.94175

Timestep Collection Time: 2.26403
Timestep Consumption Time: 2.48625
PPO Batch Consumption Time: 0.28771
Total Iteration Time: 4.75029

Cumulative Model Updates: 241,148
Cumulative Timesteps: 2,011,804,680

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 2011804680...
Checkpoint 2011804680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,761.82392
Policy Entropy: 2.29541
Value Function Loss: 0.01890

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.07790
Policy Update Magnitude: 0.31679
Value Function Update Magnitude: 0.34124

Collected Steps per Second: 21,723.00604
Overall Steps per Second: 10,565.56135

Timestep Collection Time: 2.30208
Timestep Consumption Time: 2.43104
PPO Batch Consumption Time: 0.27969
Total Iteration Time: 4.73311

Cumulative Model Updates: 241,154
Cumulative Timesteps: 2,011,854,688

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57,931.85775
Policy Entropy: 2.29267
Value Function Loss: 0.01842

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.07767
Policy Update Magnitude: 0.30665
Value Function Update Magnitude: 0.28793

Collected Steps per Second: 21,699.57151
Overall Steps per Second: 10,538.49199

Timestep Collection Time: 2.30438
Timestep Consumption Time: 2.44051
PPO Batch Consumption Time: 0.28040
Total Iteration Time: 4.74489

Cumulative Model Updates: 241,160
Cumulative Timesteps: 2,011,904,692

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2011904692...
Checkpoint 2011904692 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,426.28906
Policy Entropy: 2.28710
Value Function Loss: 0.01917

Mean KL Divergence: 0.01158
SB3 Clip Fraction: 0.09611
Policy Update Magnitude: 0.30443
Value Function Update Magnitude: 0.26990

Collected Steps per Second: 21,338.75703
Overall Steps per Second: 10,334.99225

Timestep Collection Time: 2.34428
Timestep Consumption Time: 2.49598
PPO Batch Consumption Time: 0.29235
Total Iteration Time: 4.84026

Cumulative Model Updates: 241,166
Cumulative Timesteps: 2,011,954,716

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91,710.63361
Policy Entropy: 2.31362
Value Function Loss: 0.01957

Mean KL Divergence: 0.01364
SB3 Clip Fraction: 0.10785
Policy Update Magnitude: 0.29150
Value Function Update Magnitude: 0.27473

Collected Steps per Second: 21,628.69365
Overall Steps per Second: 10,378.62153

Timestep Collection Time: 2.31258
Timestep Consumption Time: 2.50675
PPO Batch Consumption Time: 0.29365
Total Iteration Time: 4.81933

Cumulative Model Updates: 241,172
Cumulative Timesteps: 2,012,004,734

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2012004734...
Checkpoint 2012004734 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 71,959.85248
Policy Entropy: 2.32818
Value Function Loss: 0.02072

Mean KL Divergence: 0.01369
SB3 Clip Fraction: 0.11314
Policy Update Magnitude: 0.30575
Value Function Update Magnitude: 0.27173

Collected Steps per Second: 20,534.04350
Overall Steps per Second: 10,294.40628

Timestep Collection Time: 2.43732
Timestep Consumption Time: 2.42435
PPO Batch Consumption Time: 0.29295
Total Iteration Time: 4.86167

Cumulative Model Updates: 241,178
Cumulative Timesteps: 2,012,054,782

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56,243.82380
Policy Entropy: 2.32128
Value Function Loss: 0.01870

Mean KL Divergence: 0.01308
SB3 Clip Fraction: 0.10965
Policy Update Magnitude: 0.30055
Value Function Update Magnitude: 0.27458

Collected Steps per Second: 20,909.47698
Overall Steps per Second: 10,327.72439

Timestep Collection Time: 2.39241
Timestep Consumption Time: 2.45125
PPO Batch Consumption Time: 0.29422
Total Iteration Time: 4.84366

Cumulative Model Updates: 241,184
Cumulative Timesteps: 2,012,104,806

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2012104806...
Checkpoint 2012104806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 57,582.21490
Policy Entropy: 2.31406
Value Function Loss: 0.01821

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.09110
Policy Update Magnitude: 0.30519
Value Function Update Magnitude: 0.27718

Collected Steps per Second: 20,548.14813
Overall Steps per Second: 10,259.75443

Timestep Collection Time: 2.43360
Timestep Consumption Time: 2.44039
PPO Batch Consumption Time: 0.29354
Total Iteration Time: 4.87400

Cumulative Model Updates: 241,190
Cumulative Timesteps: 2,012,154,812

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,624.21902
Policy Entropy: 2.32339
Value Function Loss: 0.01557

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.08698
Policy Update Magnitude: 0.29696
Value Function Update Magnitude: 0.27493

Collected Steps per Second: 21,276.08090
Overall Steps per Second: 10,493.15456

Timestep Collection Time: 2.35147
Timestep Consumption Time: 2.41640
PPO Batch Consumption Time: 0.27716
Total Iteration Time: 4.76787

Cumulative Model Updates: 241,196
Cumulative Timesteps: 2,012,204,842

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2012204842...
Checkpoint 2012204842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 70,409.08304
Policy Entropy: 2.33157
Value Function Loss: 0.01779

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.07947
Policy Update Magnitude: 0.29105
Value Function Update Magnitude: 0.29819

Collected Steps per Second: 21,776.62489
Overall Steps per Second: 10,600.69570

Timestep Collection Time: 2.29622
Timestep Consumption Time: 2.42083
PPO Batch Consumption Time: 0.27771
Total Iteration Time: 4.71705

Cumulative Model Updates: 241,202
Cumulative Timesteps: 2,012,254,846

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65,945.25564
Policy Entropy: 2.32413
Value Function Loss: 0.01705

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.07808
Policy Update Magnitude: 0.29264
Value Function Update Magnitude: 0.26637

Collected Steps per Second: 21,793.40238
Overall Steps per Second: 10,465.16935

Timestep Collection Time: 2.29657
Timestep Consumption Time: 2.48596
PPO Batch Consumption Time: 0.29344
Total Iteration Time: 4.78253

Cumulative Model Updates: 241,208
Cumulative Timesteps: 2,012,304,896

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 2012304896...
Checkpoint 2012304896 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 64,052.94239
Policy Entropy: 2.31350
Value Function Loss: 0.01721

Mean KL Divergence: 0.01085
SB3 Clip Fraction: 0.09492
Policy Update Magnitude: 0.28985
Value Function Update Magnitude: 0.19851

Collected Steps per Second: 21,740.27406
Overall Steps per Second: 10,637.02192

Timestep Collection Time: 2.30199
Timestep Consumption Time: 2.40289
PPO Batch Consumption Time: 0.27801
Total Iteration Time: 4.70489

Cumulative Model Updates: 241,214
Cumulative Timesteps: 2,012,354,942

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60,746.46802
Policy Entropy: 2.30661
Value Function Loss: 0.01879

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.08968
Policy Update Magnitude: 0.30016
Value Function Update Magnitude: 0.21757

Collected Steps per Second: 22,340.91831
Overall Steps per Second: 10,557.90142

Timestep Collection Time: 2.23939
Timestep Consumption Time: 2.49924
PPO Batch Consumption Time: 0.29102
Total Iteration Time: 4.73863

Cumulative Model Updates: 241,220
Cumulative Timesteps: 2,012,404,972

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2012404972...
Checkpoint 2012404972 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 71,887.25489
Policy Entropy: 2.30390
Value Function Loss: 0.01875

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.08405
Policy Update Magnitude: 0.30708
Value Function Update Magnitude: 0.25447

Collected Steps per Second: 21,692.25440
Overall Steps per Second: 10,455.50142

Timestep Collection Time: 2.30506
Timestep Consumption Time: 2.47730
PPO Batch Consumption Time: 0.28670
Total Iteration Time: 4.78236

Cumulative Model Updates: 241,226
Cumulative Timesteps: 2,012,454,974

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49,543.41501
Policy Entropy: 2.29757
Value Function Loss: 0.01868

Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.07669
Policy Update Magnitude: 0.31149
Value Function Update Magnitude: 0.30988

Collected Steps per Second: 22,051.11221
Overall Steps per Second: 10,446.37509

Timestep Collection Time: 2.26882
Timestep Consumption Time: 2.52040
PPO Batch Consumption Time: 0.29150
Total Iteration Time: 4.78922

Cumulative Model Updates: 241,232
Cumulative Timesteps: 2,012,505,004

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2012505004...
Checkpoint 2012505004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47,494.25344
Policy Entropy: 2.30558
Value Function Loss: 0.01799

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.07876
Policy Update Magnitude: 0.31038
Value Function Update Magnitude: 0.33638

Collected Steps per Second: 21,502.64811
Overall Steps per Second: 10,372.60802

Timestep Collection Time: 2.32613
Timestep Consumption Time: 2.49599
PPO Batch Consumption Time: 0.29137
Total Iteration Time: 4.82212

Cumulative Model Updates: 241,238
Cumulative Timesteps: 2,012,555,022

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53,494.90563
Policy Entropy: 2.30435
Value Function Loss: 0.01659

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.07187
Policy Update Magnitude: 0.30298
Value Function Update Magnitude: 0.31315

Collected Steps per Second: 21,777.85715
Overall Steps per Second: 10,453.90386

Timestep Collection Time: 2.29692
Timestep Consumption Time: 2.48809
PPO Batch Consumption Time: 0.29087
Total Iteration Time: 4.78501

Cumulative Model Updates: 241,244
Cumulative Timesteps: 2,012,605,044

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2012605044...
Checkpoint 2012605044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,426.25664
Policy Entropy: 2.32918
Value Function Loss: 0.01779

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.08260
Policy Update Magnitude: 0.30049
Value Function Update Magnitude: 0.30517

Collected Steps per Second: 21,194.23808
Overall Steps per Second: 10,427.13528

Timestep Collection Time: 2.36036
Timestep Consumption Time: 2.43732
PPO Batch Consumption Time: 0.27897
Total Iteration Time: 4.79767

Cumulative Model Updates: 241,250
Cumulative Timesteps: 2,012,655,070

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,420.25410
Policy Entropy: 2.31653
Value Function Loss: 0.02067

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.08299
Policy Update Magnitude: 0.31835
Value Function Update Magnitude: 0.30504

Collected Steps per Second: 22,060.89083
Overall Steps per Second: 10,507.00842

Timestep Collection Time: 2.26745
Timestep Consumption Time: 2.49337
PPO Batch Consumption Time: 0.28827
Total Iteration Time: 4.76082

Cumulative Model Updates: 241,256
Cumulative Timesteps: 2,012,705,092

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2012705092...
Checkpoint 2012705092 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,731.27253
Policy Entropy: 2.32968
Value Function Loss: 0.01921

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.07744
Policy Update Magnitude: 0.31532
Value Function Update Magnitude: 0.31536

Collected Steps per Second: 21,213.10436
Overall Steps per Second: 10,569.84085

Timestep Collection Time: 2.35760
Timestep Consumption Time: 2.37398
PPO Batch Consumption Time: 0.27890
Total Iteration Time: 4.73158

Cumulative Model Updates: 241,262
Cumulative Timesteps: 2,012,755,104

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,818.58229
Policy Entropy: 2.31949
Value Function Loss: 0.01742

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.07486
Policy Update Magnitude: 0.30517
Value Function Update Magnitude: 0.29157

Collected Steps per Second: 21,626.30150
Overall Steps per Second: 10,540.31778

Timestep Collection Time: 2.31376
Timestep Consumption Time: 2.43354
PPO Batch Consumption Time: 0.29235
Total Iteration Time: 4.74730

Cumulative Model Updates: 241,268
Cumulative Timesteps: 2,012,805,142

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 2012805142...
Checkpoint 2012805142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 52,205.99456
Policy Entropy: 2.32434
Value Function Loss: 0.01453

Mean KL Divergence: 0.00782
SB3 Clip Fraction: 0.07086
Policy Update Magnitude: 0.29385
Value Function Update Magnitude: 0.23753

Collected Steps per Second: 21,324.93549
Overall Steps per Second: 10,552.87289

Timestep Collection Time: 2.34524
Timestep Consumption Time: 2.39395
PPO Batch Consumption Time: 0.27905
Total Iteration Time: 4.73918

Cumulative Model Updates: 241,274
Cumulative Timesteps: 2,012,855,154

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48,683.23936
Policy Entropy: 2.30591
Value Function Loss: 0.01676

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.06944
Policy Update Magnitude: 0.29416
Value Function Update Magnitude: 0.23551

Collected Steps per Second: 22,065.26291
Overall Steps per Second: 10,513.61265

Timestep Collection Time: 2.26718
Timestep Consumption Time: 2.49103
PPO Batch Consumption Time: 0.29178
Total Iteration Time: 4.75821

Cumulative Model Updates: 241,280
Cumulative Timesteps: 2,012,905,180

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2012905180...
Checkpoint 2012905180 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 98,907.69742
Policy Entropy: 2.28965
Value Function Loss: 0.01636

Mean KL Divergence: 0.00688
SB3 Clip Fraction: 0.06512
Policy Update Magnitude: 0.29880
Value Function Update Magnitude: 0.25848

Collected Steps per Second: 21,980.07893
Overall Steps per Second: 10,704.84809

Timestep Collection Time: 2.27479
Timestep Consumption Time: 2.39599
PPO Batch Consumption Time: 0.27757
Total Iteration Time: 4.67078

Cumulative Model Updates: 241,286
Cumulative Timesteps: 2,012,955,180

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68,339.99176
Policy Entropy: 2.28571
Value Function Loss: 0.01928

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.07056
Policy Update Magnitude: 0.30123
Value Function Update Magnitude: 0.28099

Collected Steps per Second: 22,006.33372
Overall Steps per Second: 10,457.11451

Timestep Collection Time: 2.27235
Timestep Consumption Time: 2.50966
PPO Batch Consumption Time: 0.29358
Total Iteration Time: 4.78201

Cumulative Model Updates: 241,292
Cumulative Timesteps: 2,013,005,186

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2013005186...
Checkpoint 2013005186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89,013.10726
Policy Entropy: 2.30538
Value Function Loss: 0.01891

Mean KL Divergence: 0.00748
SB3 Clip Fraction: 0.07043
Policy Update Magnitude: 0.30565
Value Function Update Magnitude: 0.35248

Collected Steps per Second: 21,902.84009
Overall Steps per Second: 10,633.06858

Timestep Collection Time: 2.28445
Timestep Consumption Time: 2.42124
PPO Batch Consumption Time: 0.27772
Total Iteration Time: 4.70570

Cumulative Model Updates: 241,298
Cumulative Timesteps: 2,013,055,222

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87,182.68859
Policy Entropy: 2.31329
Value Function Loss: 0.01822

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.07968
Policy Update Magnitude: 0.30072
Value Function Update Magnitude: 0.39173

Collected Steps per Second: 21,618.96804
Overall Steps per Second: 10,430.40076

Timestep Collection Time: 2.31325
Timestep Consumption Time: 2.48139
PPO Batch Consumption Time: 0.28721
Total Iteration Time: 4.79464

Cumulative Model Updates: 241,304
Cumulative Timesteps: 2,013,105,232

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2013105232...
Checkpoint 2013105232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87,182.68859
Policy Entropy: 2.30602
Value Function Loss: 0.01559

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.08063
Policy Update Magnitude: 0.29317
Value Function Update Magnitude: 0.35922

Collected Steps per Second: 21,492.13944
Overall Steps per Second: 10,535.32188

Timestep Collection Time: 2.32699
Timestep Consumption Time: 2.42009
PPO Batch Consumption Time: 0.27882
Total Iteration Time: 4.74708

Cumulative Model Updates: 241,310
Cumulative Timesteps: 2,013,155,244

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88,317.51295
Policy Entropy: 2.30280
Value Function Loss: 0.01940

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.07275
Policy Update Magnitude: 0.30724
Value Function Update Magnitude: 0.33394

Collected Steps per Second: 21,456.41992
Overall Steps per Second: 10,475.19457

Timestep Collection Time: 2.33124
Timestep Consumption Time: 2.44385
PPO Batch Consumption Time: 0.27927
Total Iteration Time: 4.77509

Cumulative Model Updates: 241,316
Cumulative Timesteps: 2,013,205,264

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2013205264...
Checkpoint 2013205264 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 125,764.06714
Policy Entropy: 2.31480
Value Function Loss: 0.01962

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.08098
Policy Update Magnitude: 0.31521
Value Function Update Magnitude: 0.35294

Collected Steps per Second: 20,989.63080
Overall Steps per Second: 10,249.28873

Timestep Collection Time: 2.38346
Timestep Consumption Time: 2.49766
PPO Batch Consumption Time: 0.29004
Total Iteration Time: 4.88112

Cumulative Model Updates: 241,322
Cumulative Timesteps: 2,013,255,292

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 103,047.65847
Policy Entropy: 2.32443
Value Function Loss: 0.01848

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.08119
Policy Update Magnitude: 0.30795
Value Function Update Magnitude: 0.35202

Collected Steps per Second: 20,834.94653
Overall Steps per Second: 10,466.08016

Timestep Collection Time: 2.40077
Timestep Consumption Time: 2.37847
PPO Batch Consumption Time: 0.27941
Total Iteration Time: 4.77925

Cumulative Model Updates: 241,328
Cumulative Timesteps: 2,013,305,312

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2013305312...
Checkpoint 2013305312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 66,708.65341
Policy Entropy: 2.32395
Value Function Loss: 0.01681

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.08083
Policy Update Magnitude: 0.29777
Value Function Update Magnitude: 0.33132

Collected Steps per Second: 21,064.52549
Overall Steps per Second: 10,372.75919

Timestep Collection Time: 2.37432
Timestep Consumption Time: 2.44734
PPO Batch Consumption Time: 0.29040
Total Iteration Time: 4.82167

Cumulative Model Updates: 241,334
Cumulative Timesteps: 2,013,355,326

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53,921.18277
Policy Entropy: 2.31763
Value Function Loss: 0.01678

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.09157
Policy Update Magnitude: 0.30071
Value Function Update Magnitude: 0.33259

Collected Steps per Second: 21,521.05158
Overall Steps per Second: 10,670.48064

Timestep Collection Time: 2.32433
Timestep Consumption Time: 2.36356
PPO Batch Consumption Time: 0.27896
Total Iteration Time: 4.68789

Cumulative Model Updates: 241,340
Cumulative Timesteps: 2,013,405,348

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2013405348...
Checkpoint 2013405348 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 60,551.02656
Policy Entropy: 2.31023
Value Function Loss: 0.01594

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.07978
Policy Update Magnitude: 0.29762
Value Function Update Magnitude: 0.33800

Collected Steps per Second: 21,209.39319
Overall Steps per Second: 10,312.46429

Timestep Collection Time: 2.35924
Timestep Consumption Time: 2.49295
PPO Batch Consumption Time: 0.29407
Total Iteration Time: 4.85219

Cumulative Model Updates: 241,346
Cumulative Timesteps: 2,013,455,386

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49,900.48767
Policy Entropy: 2.30134
Value Function Loss: 0.01809

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.08062
Policy Update Magnitude: 0.31002
Value Function Update Magnitude: 0.30482

Collected Steps per Second: 22,032.95552
Overall Steps per Second: 10,567.69412

Timestep Collection Time: 2.27024
Timestep Consumption Time: 2.46306
PPO Batch Consumption Time: 0.28969
Total Iteration Time: 4.73329

Cumulative Model Updates: 241,352
Cumulative Timesteps: 2,013,505,406

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2013505406...
Checkpoint 2013505406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 50,927.91303
Policy Entropy: 2.30448
Value Function Loss: 0.01766

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.07626
Policy Update Magnitude: 0.31515
Value Function Update Magnitude: 0.29913

Collected Steps per Second: 21,876.82979
Overall Steps per Second: 10,471.36572

Timestep Collection Time: 2.28680
Timestep Consumption Time: 2.49080
PPO Batch Consumption Time: 0.29448
Total Iteration Time: 4.77760

Cumulative Model Updates: 241,358
Cumulative Timesteps: 2,013,555,434

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,800.78428
Policy Entropy: 2.31814
Value Function Loss: 0.01924

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.07272
Policy Update Magnitude: 0.30795
Value Function Update Magnitude: 0.31237

Collected Steps per Second: 22,282.91706
Overall Steps per Second: 10,657.15418

Timestep Collection Time: 2.24504
Timestep Consumption Time: 2.44909
PPO Batch Consumption Time: 0.28960
Total Iteration Time: 4.69412

Cumulative Model Updates: 241,364
Cumulative Timesteps: 2,013,605,460

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2013605460...
Checkpoint 2013605460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 63,252.12400
Policy Entropy: 2.35101
Value Function Loss: 0.01806

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.07481
Policy Update Magnitude: 0.30196
Value Function Update Magnitude: 0.31248

Collected Steps per Second: 21,690.78202
Overall Steps per Second: 10,448.91540

Timestep Collection Time: 2.30577
Timestep Consumption Time: 2.48075
PPO Batch Consumption Time: 0.28636
Total Iteration Time: 4.78653

Cumulative Model Updates: 241,370
Cumulative Timesteps: 2,013,655,474

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 107,689.08995
Policy Entropy: 2.36121
Value Function Loss: 0.02079

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.08334
Policy Update Magnitude: 0.30316
Value Function Update Magnitude: 0.30430

Collected Steps per Second: 21,644.41122
Overall Steps per Second: 10,425.68288

Timestep Collection Time: 2.31191
Timestep Consumption Time: 2.48777
PPO Batch Consumption Time: 0.28742
Total Iteration Time: 4.79969

Cumulative Model Updates: 241,376
Cumulative Timesteps: 2,013,705,514

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 2013705514...
Checkpoint 2013705514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 80,627.55681
Policy Entropy: 2.34911
Value Function Loss: 0.02072

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.08444
Policy Update Magnitude: 0.31008
Value Function Update Magnitude: 0.32951

Collected Steps per Second: 21,370.20795
Overall Steps per Second: 10,316.55588

Timestep Collection Time: 2.34148
Timestep Consumption Time: 2.50878
PPO Batch Consumption Time: 0.29352
Total Iteration Time: 4.85026

Cumulative Model Updates: 241,382
Cumulative Timesteps: 2,013,755,552

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82,462.53349
Policy Entropy: 2.32054
Value Function Loss: 0.01995

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.08264
Policy Update Magnitude: 0.31971
Value Function Update Magnitude: 0.36100

Collected Steps per Second: 21,906.50744
Overall Steps per Second: 10,455.39507

Timestep Collection Time: 2.28288
Timestep Consumption Time: 2.50029
PPO Batch Consumption Time: 0.29230
Total Iteration Time: 4.78318

Cumulative Model Updates: 241,388
Cumulative Timesteps: 2,013,805,562

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2013805562...
Checkpoint 2013805562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 85,411.79779
Policy Entropy: 2.30845
Value Function Loss: 0.01896

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.08171
Policy Update Magnitude: 0.32126
Value Function Update Magnitude: 0.36282

Collected Steps per Second: 21,948.79241
Overall Steps per Second: 10,544.08796

Timestep Collection Time: 2.27994
Timestep Consumption Time: 2.46603
PPO Batch Consumption Time: 0.27831
Total Iteration Time: 4.74598

Cumulative Model Updates: 241,394
Cumulative Timesteps: 2,013,855,604

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 71,086.57188
Policy Entropy: 2.30263
Value Function Loss: 0.01792

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.07577
Policy Update Magnitude: 0.31795
Value Function Update Magnitude: 0.35263

Collected Steps per Second: 21,996.86406
Overall Steps per Second: 10,425.89271

Timestep Collection Time: 2.27396
Timestep Consumption Time: 2.52371
PPO Batch Consumption Time: 0.29358
Total Iteration Time: 4.79767

Cumulative Model Updates: 241,400
Cumulative Timesteps: 2,013,905,624

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2013905624...
Checkpoint 2013905624 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 66,613.76998
Policy Entropy: 2.28888
Value Function Loss: 0.01896

Mean KL Divergence: 0.00718
SB3 Clip Fraction: 0.06705
Policy Update Magnitude: 0.31683
Value Function Update Magnitude: 0.33594

Collected Steps per Second: 21,525.50365
Overall Steps per Second: 10,396.27321

Timestep Collection Time: 2.32338
Timestep Consumption Time: 2.48719
PPO Batch Consumption Time: 0.29109
Total Iteration Time: 4.81057

Cumulative Model Updates: 241,406
Cumulative Timesteps: 2,013,955,636

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61,950.01415
Policy Entropy: 2.29849
Value Function Loss: 0.01791

Mean KL Divergence: 0.00746
SB3 Clip Fraction: 0.06993
Policy Update Magnitude: 0.31232
Value Function Update Magnitude: 0.33524

Collected Steps per Second: 22,148.80907
Overall Steps per Second: 10,689.56590

Timestep Collection Time: 2.25845
Timestep Consumption Time: 2.42107
PPO Batch Consumption Time: 0.27916
Total Iteration Time: 4.67952

Cumulative Model Updates: 241,412
Cumulative Timesteps: 2,014,005,658

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2014005658...
Checkpoint 2014005658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,710.39318
Policy Entropy: 2.28955
Value Function Loss: 0.01885

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.07590
Policy Update Magnitude: 0.31264
Value Function Update Magnitude: 0.35266

Collected Steps per Second: 21,333.25509
Overall Steps per Second: 10,655.99562

Timestep Collection Time: 2.34470
Timestep Consumption Time: 2.34937
PPO Batch Consumption Time: 0.27901
Total Iteration Time: 4.69407

Cumulative Model Updates: 241,418
Cumulative Timesteps: 2,014,055,678

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50,726.37409
Policy Entropy: 2.30855
Value Function Loss: 0.01683

Mean KL Divergence: 0.00691
SB3 Clip Fraction: 0.06829
Policy Update Magnitude: 0.31225
Value Function Update Magnitude: 0.36135

Collected Steps per Second: 21,394.57044
Overall Steps per Second: 10,484.94506

Timestep Collection Time: 2.33779
Timestep Consumption Time: 2.43248
PPO Batch Consumption Time: 0.29270
Total Iteration Time: 4.77027

Cumulative Model Updates: 241,424
Cumulative Timesteps: 2,014,105,694

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2014105694...
Checkpoint 2014105694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 57,655.58113
Policy Entropy: 2.30412
Value Function Loss: 0.01716

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.06770
Policy Update Magnitude: 0.30637
Value Function Update Magnitude: 0.32145

Collected Steps per Second: 21,452.09396
Overall Steps per Second: 10,559.10035

Timestep Collection Time: 2.33077
Timestep Consumption Time: 2.40448
PPO Batch Consumption Time: 0.27883
Total Iteration Time: 4.73525

Cumulative Model Updates: 241,430
Cumulative Timesteps: 2,014,155,694

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70,038.72571
Policy Entropy: 2.33450
Value Function Loss: 0.01771

Mean KL Divergence: 0.00736
SB3 Clip Fraction: 0.06911
Policy Update Magnitude: 0.30525
Value Function Update Magnitude: 0.31057

Collected Steps per Second: 21,500.14418
Overall Steps per Second: 10,584.29500

Timestep Collection Time: 2.32557
Timestep Consumption Time: 2.39841
PPO Batch Consumption Time: 0.27728
Total Iteration Time: 4.72398

Cumulative Model Updates: 241,436
Cumulative Timesteps: 2,014,205,694

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2014205694...
Checkpoint 2014205694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 83,953.00067
Policy Entropy: 2.33881
Value Function Loss: 0.01898

Mean KL Divergence: 0.00725
SB3 Clip Fraction: 0.06661
Policy Update Magnitude: 0.30933
Value Function Update Magnitude: 0.32709

Collected Steps per Second: 21,001.40571
Overall Steps per Second: 10,317.37511

Timestep Collection Time: 2.38165
Timestep Consumption Time: 2.46629
PPO Batch Consumption Time: 0.29049
Total Iteration Time: 4.84794

Cumulative Model Updates: 241,442
Cumulative Timesteps: 2,014,255,712

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62,162.07679
Policy Entropy: 2.33756
Value Function Loss: 0.01808

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.07498
Policy Update Magnitude: 0.30469
Value Function Update Magnitude: 0.32861

Collected Steps per Second: 21,609.19254
Overall Steps per Second: 10,410.69834

Timestep Collection Time: 2.31402
Timestep Consumption Time: 2.48912
PPO Batch Consumption Time: 0.29077
Total Iteration Time: 4.80314

Cumulative Model Updates: 241,448
Cumulative Timesteps: 2,014,305,716

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2014305716...
Checkpoint 2014305716 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 91,387.18317
Policy Entropy: 2.32323
Value Function Loss: 0.01757

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.07077
Policy Update Magnitude: 0.30765
Value Function Update Magnitude: 0.32229

Collected Steps per Second: 21,649.11153
Overall Steps per Second: 10,560.45267

Timestep Collection Time: 2.31169
Timestep Consumption Time: 2.42731
PPO Batch Consumption Time: 0.27815
Total Iteration Time: 4.73900

Cumulative Model Updates: 241,454
Cumulative Timesteps: 2,014,355,762

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83,247.62192
Policy Entropy: 2.32089
Value Function Loss: 0.01587

Mean KL Divergence: 0.00737
SB3 Clip Fraction: 0.06916
Policy Update Magnitude: 0.30218
Value Function Update Magnitude: 0.30496

Collected Steps per Second: 21,852.26665
Overall Steps per Second: 10,422.98399

Timestep Collection Time: 2.29056
Timestep Consumption Time: 2.51171
PPO Batch Consumption Time: 0.29041
Total Iteration Time: 4.80227

Cumulative Model Updates: 241,460
Cumulative Timesteps: 2,014,405,816

Timesteps Collected: 50,054
--------END ITERATION REPORT--------


Saving checkpoint 2014405816...
Checkpoint 2014405816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 110,764.86272
Policy Entropy: 2.32756
Value Function Loss: 0.01705

Mean KL Divergence: 0.00681
SB3 Clip Fraction: 0.06400
Policy Update Magnitude: 0.30075
Value Function Update Magnitude: 0.30091

Collected Steps per Second: 22,034.18686
Overall Steps per Second: 10,568.52772

Timestep Collection Time: 2.27020
Timestep Consumption Time: 2.46291
PPO Batch Consumption Time: 0.27628
Total Iteration Time: 4.73311

Cumulative Model Updates: 241,466
Cumulative Timesteps: 2,014,455,838

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75,902.70635
Policy Entropy: 2.32537
Value Function Loss: 0.01711

Mean KL Divergence: 0.00704
SB3 Clip Fraction: 0.06753
Policy Update Magnitude: 0.29765
Value Function Update Magnitude: 0.28048

Collected Steps per Second: 22,041.10623
Overall Steps per Second: 10,460.14711

Timestep Collection Time: 2.26876
Timestep Consumption Time: 2.51186
PPO Batch Consumption Time: 0.29247
Total Iteration Time: 4.78062

Cumulative Model Updates: 241,472
Cumulative Timesteps: 2,014,505,844

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2014505844...
Checkpoint 2014505844 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 63,926.32734
Policy Entropy: 2.31586
Value Function Loss: 0.01828

Mean KL Divergence: 0.00644
SB3 Clip Fraction: 0.06330
Policy Update Magnitude: 0.29523
Value Function Update Magnitude: 0.25622

Collected Steps per Second: 21,961.83724
Overall Steps per Second: 10,518.81116

Timestep Collection Time: 2.27877
Timestep Consumption Time: 2.47899
PPO Batch Consumption Time: 0.28713
Total Iteration Time: 4.75776

Cumulative Model Updates: 241,478
Cumulative Timesteps: 2,014,555,890

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50,071.45619
Policy Entropy: 2.31859
Value Function Loss: 0.01799

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.07662
Policy Update Magnitude: 0.29692
Value Function Update Magnitude: 0.25755

Collected Steps per Second: 22,060.45866
Overall Steps per Second: 10,510.32483

Timestep Collection Time: 2.26731
Timestep Consumption Time: 2.49162
PPO Batch Consumption Time: 0.28967
Total Iteration Time: 4.75894

Cumulative Model Updates: 241,484
Cumulative Timesteps: 2,014,605,908

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2014605908...
Checkpoint 2014605908 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 77,703.23111
Policy Entropy: 2.34572
Value Function Loss: 0.01766

Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.08083
Policy Update Magnitude: 0.30014
Value Function Update Magnitude: 0.24994

Collected Steps per Second: 21,652.51016
Overall Steps per Second: 10,576.00177

Timestep Collection Time: 2.31003
Timestep Consumption Time: 2.41935
PPO Batch Consumption Time: 0.27938
Total Iteration Time: 4.72939

Cumulative Model Updates: 241,490
Cumulative Timesteps: 2,014,655,926

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95,447.05173
Policy Entropy: 2.34411
Value Function Loss: 0.01957

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.08729
Policy Update Magnitude: 0.30253
Value Function Update Magnitude: 0.23210

Collected Steps per Second: 22,072.50654
Overall Steps per Second: 10,508.74778

Timestep Collection Time: 2.26671
Timestep Consumption Time: 2.49427
PPO Batch Consumption Time: 0.29042
Total Iteration Time: 4.76099

Cumulative Model Updates: 241,496
Cumulative Timesteps: 2,014,705,958

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2014705958...
Checkpoint 2014705958 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 78,426.77228
Policy Entropy: 2.31888
Value Function Loss: 0.01904

Mean KL Divergence: 0.01187
SB3 Clip Fraction: 0.09505
Policy Update Magnitude: 0.30695
Value Function Update Magnitude: 0.24484

Collected Steps per Second: 22,044.18199
Overall Steps per Second: 10,674.88360

Timestep Collection Time: 2.26863
Timestep Consumption Time: 2.41620
PPO Batch Consumption Time: 0.27796
Total Iteration Time: 4.68483

Cumulative Model Updates: 241,502
Cumulative Timesteps: 2,014,755,968

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53,214.83815
Policy Entropy: 2.31462
Value Function Loss: 0.01891

Mean KL Divergence: 0.01548
SB3 Clip Fraction: 0.11659
Policy Update Magnitude: 0.30483
Value Function Update Magnitude: 0.27613

Collected Steps per Second: 20,990.84140
Overall Steps per Second: 10,439.78061

Timestep Collection Time: 2.38304
Timestep Consumption Time: 2.40844
PPO Batch Consumption Time: 0.28812
Total Iteration Time: 4.79148

Cumulative Model Updates: 241,508
Cumulative Timesteps: 2,014,805,990

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2014805990...
Checkpoint 2014805990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 57,154.98133
Policy Entropy: 2.32909
Value Function Loss: 0.01548

Mean KL Divergence: 0.01132
SB3 Clip Fraction: 0.09593
Policy Update Magnitude: 0.29490
Value Function Update Magnitude: 0.28551

Collected Steps per Second: 20,825.75444
Overall Steps per Second: 10,380.93535

Timestep Collection Time: 2.40251
Timestep Consumption Time: 2.41729
PPO Batch Consumption Time: 0.29053
Total Iteration Time: 4.81980

Cumulative Model Updates: 241,514
Cumulative Timesteps: 2,014,856,024

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 72,669.52990
Policy Entropy: 2.33987
Value Function Loss: 0.01769

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.08418
Policy Update Magnitude: 0.29389
Value Function Update Magnitude: 0.28674

Collected Steps per Second: 21,069.83463
Overall Steps per Second: 10,467.02452

Timestep Collection Time: 2.37363
Timestep Consumption Time: 2.40442
PPO Batch Consumption Time: 0.28975
Total Iteration Time: 4.77805

Cumulative Model Updates: 241,520
Cumulative Timesteps: 2,014,906,036

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2014906036...
Checkpoint 2014906036 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,007.53580
Policy Entropy: 2.33164
Value Function Loss: 0.02073

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.09738
Policy Update Magnitude: 0.30902
Value Function Update Magnitude: 0.30812

Collected Steps per Second: 20,984.54724
Overall Steps per Second: 10,430.09746

Timestep Collection Time: 2.38404
Timestep Consumption Time: 2.41246
PPO Batch Consumption Time: 0.27910
Total Iteration Time: 4.79650

Cumulative Model Updates: 241,526
Cumulative Timesteps: 2,014,956,064

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,567.37706
Policy Entropy: 2.32507
Value Function Loss: 0.02128

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.09277
Policy Update Magnitude: 0.31218
Value Function Update Magnitude: 0.34510

Collected Steps per Second: 21,660.02370
Overall Steps per Second: 10,471.05976

Timestep Collection Time: 2.30979
Timestep Consumption Time: 2.46815
PPO Batch Consumption Time: 0.28521
Total Iteration Time: 4.77793

Cumulative Model Updates: 241,532
Cumulative Timesteps: 2,015,006,094

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2015006094...
Checkpoint 2015006094 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,567.37706
Policy Entropy: 2.32500
Value Function Loss: 0.01883

Mean KL Divergence: 0.01218
SB3 Clip Fraction: 0.10586
Policy Update Magnitude: 0.30453
Value Function Update Magnitude: 0.32576

Collected Steps per Second: 21,885.09059
Overall Steps per Second: 10,589.06030

Timestep Collection Time: 2.28539
Timestep Consumption Time: 2.43797
PPO Batch Consumption Time: 0.27857
Total Iteration Time: 4.72337

Cumulative Model Updates: 241,538
Cumulative Timesteps: 2,015,056,110

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,573.94760
Policy Entropy: 2.33572
Value Function Loss: 0.01604

Mean KL Divergence: 0.01384
SB3 Clip Fraction: 0.11023
Policy Update Magnitude: 0.29078
Value Function Update Magnitude: 0.29411

Collected Steps per Second: 21,014.83592
Overall Steps per Second: 10,160.38850

Timestep Collection Time: 2.38022
Timestep Consumption Time: 2.54282
PPO Batch Consumption Time: 0.29153
Total Iteration Time: 4.92304

Cumulative Model Updates: 241,544
Cumulative Timesteps: 2,015,106,130

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2015106130...
Checkpoint 2015106130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 66,276.83184
Policy Entropy: 2.34431
Value Function Loss: 0.01976

Mean KL Divergence: 0.01403
SB3 Clip Fraction: 0.11350
Policy Update Magnitude: 0.29793
Value Function Update Magnitude: 0.28085

Collected Steps per Second: 21,712.59304
Overall Steps per Second: 10,555.40490

Timestep Collection Time: 2.30364
Timestep Consumption Time: 2.43497
PPO Batch Consumption Time: 0.27854
Total Iteration Time: 4.73862

Cumulative Model Updates: 241,550
Cumulative Timesteps: 2,015,156,148

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66,490.12753
Policy Entropy: 2.36451
Value Function Loss: 0.02230

Mean KL Divergence: 0.01345
SB3 Clip Fraction: 0.11258
Policy Update Magnitude: 0.30356
Value Function Update Magnitude: 0.27443

Collected Steps per Second: 21,883.78722
Overall Steps per Second: 10,437.04794

Timestep Collection Time: 2.28681
Timestep Consumption Time: 2.50804
PPO Batch Consumption Time: 0.29189
Total Iteration Time: 4.79484

Cumulative Model Updates: 241,556
Cumulative Timesteps: 2,015,206,192

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 2015206192...
Checkpoint 2015206192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 54,667.25649
Policy Entropy: 2.34687
Value Function Loss: 0.02199

Mean KL Divergence: 0.01244
SB3 Clip Fraction: 0.10489
Policy Update Magnitude: 0.29105
Value Function Update Magnitude: 0.27729

Collected Steps per Second: 21,804.93606
Overall Steps per Second: 10,589.89572

Timestep Collection Time: 2.29398
Timestep Consumption Time: 2.42939
PPO Batch Consumption Time: 0.27872
Total Iteration Time: 4.72337

Cumulative Model Updates: 241,562
Cumulative Timesteps: 2,015,256,212

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81,855.05379
Policy Entropy: 2.35525
Value Function Loss: 0.01896

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.08485
Policy Update Magnitude: 0.28473
Value Function Update Magnitude: 0.28317

Collected Steps per Second: 22,172.13625
Overall Steps per Second: 10,493.76848

Timestep Collection Time: 2.25617
Timestep Consumption Time: 2.51085
PPO Batch Consumption Time: 0.29169
Total Iteration Time: 4.76702

Cumulative Model Updates: 241,568
Cumulative Timesteps: 2,015,306,236

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2015306236...
Checkpoint 2015306236 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 73,320.34635
Policy Entropy: 2.33790
Value Function Loss: 0.01767

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.07406
Policy Update Magnitude: 0.29017
Value Function Update Magnitude: 0.24793

Collected Steps per Second: 21,702.55277
Overall Steps per Second: 10,591.80885

Timestep Collection Time: 2.30498
Timestep Consumption Time: 2.41791
PPO Batch Consumption Time: 0.27863
Total Iteration Time: 4.72289

Cumulative Model Updates: 241,574
Cumulative Timesteps: 2,015,356,260

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59,877.41545
Policy Entropy: 2.35357
Value Function Loss: 0.01813

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.08010
Policy Update Magnitude: 0.29652
Value Function Update Magnitude: 0.24388

Collected Steps per Second: 21,179.86678
Overall Steps per Second: 10,445.19915

Timestep Collection Time: 2.36168
Timestep Consumption Time: 2.42713
PPO Batch Consumption Time: 0.27826
Total Iteration Time: 4.78880

Cumulative Model Updates: 241,580
Cumulative Timesteps: 2,015,406,280

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2015406280...
Checkpoint 2015406280 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,759.84812
Policy Entropy: 2.35908
Value Function Loss: 0.01812

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.07388
Policy Update Magnitude: 0.29937
Value Function Update Magnitude: 0.22731

Collected Steps per Second: 21,141.32925
Overall Steps per Second: 10,276.53419

Timestep Collection Time: 2.36674
Timestep Consumption Time: 2.50222
PPO Batch Consumption Time: 0.29050
Total Iteration Time: 4.86896

Cumulative Model Updates: 241,586
Cumulative Timesteps: 2,015,456,316

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 72,328.62292
Policy Entropy: 2.37169
Value Function Loss: 0.01919

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.07081
Policy Update Magnitude: 0.30055
Value Function Update Magnitude: 0.19400

Collected Steps per Second: 21,142.30735
Overall Steps per Second: 10,435.61008

Timestep Collection Time: 2.36691
Timestep Consumption Time: 2.42840
PPO Batch Consumption Time: 0.28880
Total Iteration Time: 4.79531

Cumulative Model Updates: 241,592
Cumulative Timesteps: 2,015,506,358

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 2015506358...
Checkpoint 2015506358 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 69,473.90311
Policy Entropy: 2.36449
Value Function Loss: 0.01820

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.07213
Policy Update Magnitude: 0.29417
Value Function Update Magnitude: 0.17611

Collected Steps per Second: 20,709.66070
Overall Steps per Second: 10,337.34463

Timestep Collection Time: 2.41530
Timestep Consumption Time: 2.42347
PPO Batch Consumption Time: 0.29223
Total Iteration Time: 4.83877

Cumulative Model Updates: 241,598
Cumulative Timesteps: 2,015,556,378

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 69,473.90311
Policy Entropy: 2.35592
Value Function Loss: 0.01765

Mean KL Divergence: 0.00645
SB3 Clip Fraction: 0.06113
Policy Update Magnitude: 0.28898
Value Function Update Magnitude: 0.18876

Collected Steps per Second: 21,157.56906
Overall Steps per Second: 10,452.11205

Timestep Collection Time: 2.36369
Timestep Consumption Time: 2.42099
PPO Batch Consumption Time: 0.29236
Total Iteration Time: 4.78468

Cumulative Model Updates: 241,604
Cumulative Timesteps: 2,015,606,388

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2015606388...
Checkpoint 2015606388 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 68,103.85911
Policy Entropy: 2.33002
Value Function Loss: 0.01741

Mean KL Divergence: 0.00736
SB3 Clip Fraction: 0.07153
Policy Update Magnitude: 0.29535
Value Function Update Magnitude: 0.19565

Collected Steps per Second: 21,252.55470
Overall Steps per Second: 10,448.02846

Timestep Collection Time: 2.35360
Timestep Consumption Time: 2.43391
PPO Batch Consumption Time: 0.27842
Total Iteration Time: 4.78751

Cumulative Model Updates: 241,610
Cumulative Timesteps: 2,015,656,408

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59,848.53971
Policy Entropy: 2.33113
Value Function Loss: 0.01680

Mean KL Divergence: 0.00721
SB3 Clip Fraction: 0.06855
Policy Update Magnitude: 0.29489
Value Function Update Magnitude: 0.18848

Collected Steps per Second: 22,090.44608
Overall Steps per Second: 10,433.89442

Timestep Collection Time: 2.26532
Timestep Consumption Time: 2.53078
PPO Batch Consumption Time: 0.29554
Total Iteration Time: 4.79610

Cumulative Model Updates: 241,616
Cumulative Timesteps: 2,015,706,450

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 2015706450...
Checkpoint 2015706450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 58,380.30437
Policy Entropy: 2.33500
Value Function Loss: 0.01931

Mean KL Divergence: 0.00717
SB3 Clip Fraction: 0.06537
Policy Update Magnitude: 0.30036
Value Function Update Magnitude: 0.25147

Collected Steps per Second: 21,556.66339
Overall Steps per Second: 10,454.30327

Timestep Collection Time: 2.31956
Timestep Consumption Time: 2.46335
PPO Batch Consumption Time: 0.29214
Total Iteration Time: 4.78291

Cumulative Model Updates: 241,622
Cumulative Timesteps: 2,015,756,452

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 69,014.19885
Policy Entropy: 2.35434
Value Function Loss: 0.01764

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.07248
Policy Update Magnitude: 0.30222
Value Function Update Magnitude: 0.27811

Collected Steps per Second: 22,514.35817
Overall Steps per Second: 10,756.15161

Timestep Collection Time: 2.22098
Timestep Consumption Time: 2.42789
PPO Batch Consumption Time: 0.27939
Total Iteration Time: 4.64887

Cumulative Model Updates: 241,628
Cumulative Timesteps: 2,015,806,456

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2015806456...
Checkpoint 2015806456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 67,868.07106
Policy Entropy: 2.35707
Value Function Loss: 0.01918

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.07066
Policy Update Magnitude: 0.29416
Value Function Update Magnitude: 0.25684

Collected Steps per Second: 21,439.59071
Overall Steps per Second: 10,321.99293

Timestep Collection Time: 2.33260
Timestep Consumption Time: 2.51239
PPO Batch Consumption Time: 0.29257
Total Iteration Time: 4.84499

Cumulative Model Updates: 241,634
Cumulative Timesteps: 2,015,856,466

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57,989.70912
Policy Entropy: 2.35841
Value Function Loss: 0.01717

Mean KL Divergence: 0.00648
SB3 Clip Fraction: 0.06108
Policy Update Magnitude: 0.29316
Value Function Update Magnitude: 0.23894

Collected Steps per Second: 22,434.56298
Overall Steps per Second: 10,727.31643

Timestep Collection Time: 2.23058
Timestep Consumption Time: 2.43434
PPO Batch Consumption Time: 0.27887
Total Iteration Time: 4.66491

Cumulative Model Updates: 241,640
Cumulative Timesteps: 2,015,906,508

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 2015906508...
Checkpoint 2015906508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 99,091.06909
Policy Entropy: 2.36135
Value Function Loss: 0.01892

Mean KL Divergence: 0.00671
SB3 Clip Fraction: 0.06406
Policy Update Magnitude: 0.30148
Value Function Update Magnitude: 0.26677

Collected Steps per Second: 21,687.98548
Overall Steps per Second: 10,579.00803

Timestep Collection Time: 2.30653
Timestep Consumption Time: 2.42208
PPO Batch Consumption Time: 0.27938
Total Iteration Time: 4.72861

Cumulative Model Updates: 241,646
Cumulative Timesteps: 2,015,956,532

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95,696.68647
Policy Entropy: 2.35968
Value Function Loss: 0.02180

Mean KL Divergence: 0.00739
SB3 Clip Fraction: 0.06919
Policy Update Magnitude: 0.31125
Value Function Update Magnitude: 0.27157

Collected Steps per Second: 21,792.84935
Overall Steps per Second: 10,623.31684

Timestep Collection Time: 2.29552
Timestep Consumption Time: 2.41355
PPO Batch Consumption Time: 0.27720
Total Iteration Time: 4.70908

Cumulative Model Updates: 241,652
Cumulative Timesteps: 2,016,006,558

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2016006558...
Checkpoint 2016006558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 83,451.85027
Policy Entropy: 2.34684
Value Function Loss: 0.02222

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.07332
Policy Update Magnitude: 0.31049
Value Function Update Magnitude: 0.24685

Collected Steps per Second: 21,356.30063
Overall Steps per Second: 10,508.07141

Timestep Collection Time: 2.34132
Timestep Consumption Time: 2.41711
PPO Batch Consumption Time: 0.27854
Total Iteration Time: 4.75844

Cumulative Model Updates: 241,658
Cumulative Timesteps: 2,016,056,560

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56,541.85342
Policy Entropy: 2.34707
Value Function Loss: 0.02302

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.07868
Policy Update Magnitude: 0.30071
Value Function Update Magnitude: 0.29900

Collected Steps per Second: 21,077.72076
Overall Steps per Second: 10,572.55175

Timestep Collection Time: 2.37360
Timestep Consumption Time: 2.35847
PPO Batch Consumption Time: 0.27810
Total Iteration Time: 4.73206

Cumulative Model Updates: 241,664
Cumulative Timesteps: 2,016,106,590

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2016106590...
Checkpoint 2016106590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 53,085.65624
Policy Entropy: 2.38186
Value Function Loss: 0.01991

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.07452
Policy Update Magnitude: 0.30018
Value Function Update Magnitude: 0.32723

Collected Steps per Second: 20,504.42274
Overall Steps per Second: 10,267.55921

Timestep Collection Time: 2.43947
Timestep Consumption Time: 2.43218
PPO Batch Consumption Time: 0.29283
Total Iteration Time: 4.87165

Cumulative Model Updates: 241,670
Cumulative Timesteps: 2,016,156,610

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50,197.24771
Policy Entropy: 2.37112
Value Function Loss: 0.02025

Mean KL Divergence: 0.00748
SB3 Clip Fraction: 0.06701
Policy Update Magnitude: 0.30508
Value Function Update Magnitude: 0.30698

Collected Steps per Second: 21,242.92467
Overall Steps per Second: 10,447.26227

Timestep Collection Time: 2.35514
Timestep Consumption Time: 2.43368
PPO Batch Consumption Time: 0.29350
Total Iteration Time: 4.78881

Cumulative Model Updates: 241,676
Cumulative Timesteps: 2,016,206,640

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2016206640...
Checkpoint 2016206640 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,646.77731
Policy Entropy: 2.37047
Value Function Loss: 0.02010

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.06748
Policy Update Magnitude: 0.30981
Value Function Update Magnitude: 0.29947

Collected Steps per Second: 21,299.95211
Overall Steps per Second: 10,464.48749

Timestep Collection Time: 2.34799
Timestep Consumption Time: 2.43123
PPO Batch Consumption Time: 0.27824
Total Iteration Time: 4.77921

Cumulative Model Updates: 241,682
Cumulative Timesteps: 2,016,256,652

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54,559.70536
Policy Entropy: 2.36856
Value Function Loss: 0.01787

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.07418
Policy Update Magnitude: 0.30265
Value Function Update Magnitude: 0.32932

Collected Steps per Second: 22,098.39027
Overall Steps per Second: 10,474.96379

Timestep Collection Time: 2.26378
Timestep Consumption Time: 2.51198
PPO Batch Consumption Time: 0.29280
Total Iteration Time: 4.77577

Cumulative Model Updates: 241,688
Cumulative Timesteps: 2,016,306,678

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2016306678...
Checkpoint 2016306678 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 64,009.85004
Policy Entropy: 2.38099
Value Function Loss: 0.01637

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.07057
Policy Update Magnitude: 0.28861
Value Function Update Magnitude: 0.32083

Collected Steps per Second: 21,713.14755
Overall Steps per Second: 10,614.44691

Timestep Collection Time: 2.30386
Timestep Consumption Time: 2.40896
PPO Batch Consumption Time: 0.27972
Total Iteration Time: 4.71282

Cumulative Model Updates: 241,694
Cumulative Timesteps: 2,016,356,702

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50,065.74609
Policy Entropy: 2.37770
Value Function Loss: 0.01654

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.08177
Policy Update Magnitude: 0.28796
Value Function Update Magnitude: 0.32144

Collected Steps per Second: 22,031.53994
Overall Steps per Second: 10,561.38502

Timestep Collection Time: 2.27111
Timestep Consumption Time: 2.46653
PPO Batch Consumption Time: 0.28472
Total Iteration Time: 4.73764

Cumulative Model Updates: 241,700
Cumulative Timesteps: 2,016,406,738

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 2016406738...
Checkpoint 2016406738 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47,040.45742
Policy Entropy: 2.36342
Value Function Loss: 0.01516

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.07214
Policy Update Magnitude: 0.28551
Value Function Update Magnitude: 0.33786

Collected Steps per Second: 21,593.36588
Overall Steps per Second: 10,531.25429

Timestep Collection Time: 2.31599
Timestep Consumption Time: 2.43273
PPO Batch Consumption Time: 0.27948
Total Iteration Time: 4.74872

Cumulative Model Updates: 241,706
Cumulative Timesteps: 2,016,456,748

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,645.95082
Policy Entropy: 2.37052
Value Function Loss: 0.01409

Mean KL Divergence: 0.00630
SB3 Clip Fraction: 0.05985
Policy Update Magnitude: 0.28180
Value Function Update Magnitude: 0.33332

Collected Steps per Second: 22,171.01317
Overall Steps per Second: 10,549.56032

Timestep Collection Time: 2.25529
Timestep Consumption Time: 2.48444
PPO Batch Consumption Time: 0.28856
Total Iteration Time: 4.73972

Cumulative Model Updates: 241,712
Cumulative Timesteps: 2,016,506,750

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2016506750...
Checkpoint 2016506750 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 58,422.78939
Policy Entropy: 2.36475
Value Function Loss: 0.01773

Mean KL Divergence: 0.00695
SB3 Clip Fraction: 0.06770
Policy Update Magnitude: 0.29445
Value Function Update Magnitude: 0.29109

Collected Steps per Second: 21,649.17632
Overall Steps per Second: 10,569.42402

Timestep Collection Time: 2.31159
Timestep Consumption Time: 2.42320
PPO Batch Consumption Time: 0.27821
Total Iteration Time: 4.73479

Cumulative Model Updates: 241,718
Cumulative Timesteps: 2,016,556,794

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,347.18758
Policy Entropy: 2.35846
Value Function Loss: 0.01970

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.06999
Policy Update Magnitude: 0.30532
Value Function Update Magnitude: 0.29923

Collected Steps per Second: 21,441.66606
Overall Steps per Second: 10,498.10824

Timestep Collection Time: 2.33405
Timestep Consumption Time: 2.43309
PPO Batch Consumption Time: 0.27869
Total Iteration Time: 4.76714

Cumulative Model Updates: 241,724
Cumulative Timesteps: 2,016,606,840

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 2016606840...
Checkpoint 2016606840 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 98,293.49749
Policy Entropy: 2.35863
Value Function Loss: 0.02119

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.07043
Policy Update Magnitude: 0.31436
Value Function Update Magnitude: 0.37278

Collected Steps per Second: 21,357.67000
Overall Steps per Second: 10,345.13580

Timestep Collection Time: 2.34164
Timestep Consumption Time: 2.49271
PPO Batch Consumption Time: 0.29332
Total Iteration Time: 4.83435

Cumulative Model Updates: 241,730
Cumulative Timesteps: 2,016,656,852

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91,948.95158
Policy Entropy: 2.36344
Value Function Loss: 0.01833

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.07559
Policy Update Magnitude: 0.31229
Value Function Update Magnitude: 0.35082

Collected Steps per Second: 21,768.33024
Overall Steps per Second: 10,410.80366

Timestep Collection Time: 2.29811
Timestep Consumption Time: 2.50709
PPO Batch Consumption Time: 0.29301
Total Iteration Time: 4.80520

Cumulative Model Updates: 241,736
Cumulative Timesteps: 2,016,706,878

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2016706878...
Checkpoint 2016706878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86,747.83363
Policy Entropy: 2.37272
Value Function Loss: 0.01942

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.08475
Policy Update Magnitude: 0.30943
Value Function Update Magnitude: 0.34530

Collected Steps per Second: 20,254.08627
Overall Steps per Second: 10,104.96026

Timestep Collection Time: 2.47091
Timestep Consumption Time: 2.48171
PPO Batch Consumption Time: 0.28013
Total Iteration Time: 4.95262

Cumulative Model Updates: 241,742
Cumulative Timesteps: 2,016,756,924

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58,357.59247
Policy Entropy: 2.36731
Value Function Loss: 0.01893

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.07372
Policy Update Magnitude: 0.30758
Value Function Update Magnitude: 0.35584

Collected Steps per Second: 20,008.26789
Overall Steps per Second: 10,102.13149

Timestep Collection Time: 2.49907
Timestep Consumption Time: 2.45058
PPO Batch Consumption Time: 0.29334
Total Iteration Time: 4.94965

Cumulative Model Updates: 241,748
Cumulative Timesteps: 2,016,806,926

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2016806926...
Checkpoint 2016806926 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47,296.65822
Policy Entropy: 2.36884
Value Function Loss: 0.01949

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.07214
Policy Update Magnitude: 0.31282
Value Function Update Magnitude: 0.34603

Collected Steps per Second: 21,282.98598
Overall Steps per Second: 10,561.15628

Timestep Collection Time: 2.35033
Timestep Consumption Time: 2.38609
PPO Batch Consumption Time: 0.27912
Total Iteration Time: 4.73641

Cumulative Model Updates: 241,754
Cumulative Timesteps: 2,016,856,948

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49,138.72040
Policy Entropy: 2.37422
Value Function Loss: 0.01875

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.07299
Policy Update Magnitude: 0.31527
Value Function Update Magnitude: 0.34703

Collected Steps per Second: 21,354.28380
Overall Steps per Second: 10,458.57197

Timestep Collection Time: 2.34295
Timestep Consumption Time: 2.44088
PPO Batch Consumption Time: 0.29013
Total Iteration Time: 4.78383

Cumulative Model Updates: 241,760
Cumulative Timesteps: 2,016,906,980

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2016906980...
Checkpoint 2016906980 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,136.64291
Policy Entropy: 2.38742
Value Function Loss: 0.01861

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.07790
Policy Update Magnitude: 0.30651
Value Function Update Magnitude: 0.34921

Collected Steps per Second: 21,039.04106
Overall Steps per Second: 10,268.47123

Timestep Collection Time: 2.37720
Timestep Consumption Time: 2.49344
PPO Batch Consumption Time: 0.29403
Total Iteration Time: 4.87064

Cumulative Model Updates: 241,766
Cumulative Timesteps: 2,016,956,994

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49,131.19775
Policy Entropy: 2.39124
Value Function Loss: 0.01724

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.08004
Policy Update Magnitude: 0.29021
Value Function Update Magnitude: 0.35375

Collected Steps per Second: 21,698.40527
Overall Steps per Second: 10,436.64116

Timestep Collection Time: 2.30469
Timestep Consumption Time: 2.48689
PPO Batch Consumption Time: 0.29373
Total Iteration Time: 4.79158

Cumulative Model Updates: 241,772
Cumulative Timesteps: 2,017,007,002

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2017007002...
Checkpoint 2017007002 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 50,205.22313
Policy Entropy: 2.37945
Value Function Loss: 0.01852

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.08210
Policy Update Magnitude: 0.30198
Value Function Update Magnitude: 0.37018

Collected Steps per Second: 21,694.21232
Overall Steps per Second: 10,597.93356

Timestep Collection Time: 2.30550
Timestep Consumption Time: 2.41391
PPO Batch Consumption Time: 0.27898
Total Iteration Time: 4.71941

Cumulative Model Updates: 241,778
Cumulative Timesteps: 2,017,057,018

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,965.45268
Policy Entropy: 2.36571
Value Function Loss: 0.02015

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.08554
Policy Update Magnitude: 0.31400
Value Function Update Magnitude: 0.36760

Collected Steps per Second: 21,962.94887
Overall Steps per Second: 10,485.25578

Timestep Collection Time: 2.27784
Timestep Consumption Time: 2.49344
PPO Batch Consumption Time: 0.29409
Total Iteration Time: 4.77127

Cumulative Model Updates: 241,784
Cumulative Timesteps: 2,017,107,046

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2017107046...
Checkpoint 2017107046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,888.56677
Policy Entropy: 2.33808
Value Function Loss: 0.02037

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.07781
Policy Update Magnitude: 0.31502
Value Function Update Magnitude: 0.38736

Collected Steps per Second: 21,990.76984
Overall Steps per Second: 10,622.68016

Timestep Collection Time: 2.27541
Timestep Consumption Time: 2.43508
PPO Batch Consumption Time: 0.27909
Total Iteration Time: 4.71049

Cumulative Model Updates: 241,790
Cumulative Timesteps: 2,017,157,084

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56,145.83080
Policy Entropy: 2.34204
Value Function Loss: 0.01995

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.07539
Policy Update Magnitude: 0.30849
Value Function Update Magnitude: 0.38193

Collected Steps per Second: 21,578.88360
Overall Steps per Second: 10,581.20373

Timestep Collection Time: 2.31773
Timestep Consumption Time: 2.40895
PPO Batch Consumption Time: 0.27686
Total Iteration Time: 4.72668

Cumulative Model Updates: 241,796
Cumulative Timesteps: 2,017,207,098

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2017207098...
Checkpoint 2017207098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 75,711.95448
Policy Entropy: 2.36761
Value Function Loss: 0.01923

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.07375
Policy Update Magnitude: 0.30879
Value Function Update Magnitude: 0.37910

Collected Steps per Second: 21,505.28205
Overall Steps per Second: 10,520.36812

Timestep Collection Time: 2.32622
Timestep Consumption Time: 2.42894
PPO Batch Consumption Time: 0.27886
Total Iteration Time: 4.75516

Cumulative Model Updates: 241,802
Cumulative Timesteps: 2,017,257,124

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62,822.81565
Policy Entropy: 2.38311
Value Function Loss: 0.01850

Mean KL Divergence: 0.00729
SB3 Clip Fraction: 0.06903
Policy Update Magnitude: 0.30732
Value Function Update Magnitude: 0.35920

Collected Steps per Second: 21,670.39174
Overall Steps per Second: 10,537.51300

Timestep Collection Time: 2.30868
Timestep Consumption Time: 2.43912
PPO Batch Consumption Time: 0.27790
Total Iteration Time: 4.74780

Cumulative Model Updates: 241,808
Cumulative Timesteps: 2,017,307,154

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2017307154...
Checkpoint 2017307154 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 57,050.31296
Policy Entropy: 2.38341
Value Function Loss: 0.01759

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.07602
Policy Update Magnitude: 0.30128
Value Function Update Magnitude: 0.32092

Collected Steps per Second: 21,633.84484
Overall Steps per Second: 10,504.12625

Timestep Collection Time: 2.31230
Timestep Consumption Time: 2.45002
PPO Batch Consumption Time: 0.27919
Total Iteration Time: 4.76232

Cumulative Model Updates: 241,814
Cumulative Timesteps: 2,017,357,178

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,251.11017
Policy Entropy: 2.36377
Value Function Loss: 0.01881

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.07119
Policy Update Magnitude: 0.29587
Value Function Update Magnitude: 0.28300

Collected Steps per Second: 21,879.07022
Overall Steps per Second: 10,532.10315

Timestep Collection Time: 2.28712
Timestep Consumption Time: 2.46407
PPO Batch Consumption Time: 0.27898
Total Iteration Time: 4.75119

Cumulative Model Updates: 241,820
Cumulative Timesteps: 2,017,407,218

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 2017407218...
Checkpoint 2017407218 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,953.14233
Policy Entropy: 2.34633
Value Function Loss: 0.01758

Mean KL Divergence: 0.00716
SB3 Clip Fraction: 0.06513
Policy Update Magnitude: 0.29297
Value Function Update Magnitude: 0.29236

Collected Steps per Second: 21,910.30229
Overall Steps per Second: 10,578.64324

Timestep Collection Time: 2.28349
Timestep Consumption Time: 2.44604
PPO Batch Consumption Time: 0.27911
Total Iteration Time: 4.72953

Cumulative Model Updates: 241,826
Cumulative Timesteps: 2,017,457,250

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45,277.33187
Policy Entropy: 2.35262
Value Function Loss: 0.01720

Mean KL Divergence: 0.00663
SB3 Clip Fraction: 0.06505
Policy Update Magnitude: 0.29130
Value Function Update Magnitude: 0.29590

Collected Steps per Second: 22,048.48338
Overall Steps per Second: 10,475.67956

Timestep Collection Time: 2.26800
Timestep Consumption Time: 2.50553
PPO Batch Consumption Time: 0.29005
Total Iteration Time: 4.77353

Cumulative Model Updates: 241,832
Cumulative Timesteps: 2,017,507,256

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2017507256...
Checkpoint 2017507256 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,753.15405
Policy Entropy: 2.36706
Value Function Loss: 0.01631

Mean KL Divergence: 0.00636
SB3 Clip Fraction: 0.06145
Policy Update Magnitude: 0.28671
Value Function Update Magnitude: 0.29333

Collected Steps per Second: 21,963.04752
Overall Steps per Second: 10,596.67638

Timestep Collection Time: 2.27655
Timestep Consumption Time: 2.44191
PPO Batch Consumption Time: 0.28001
Total Iteration Time: 4.71846

Cumulative Model Updates: 241,838
Cumulative Timesteps: 2,017,557,256

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,753.15405
Policy Entropy: 2.37438
Value Function Loss: 0.01542

Mean KL Divergence: 0.00701
SB3 Clip Fraction: 0.06670
Policy Update Magnitude: 0.28073
Value Function Update Magnitude: 0.26602

Collected Steps per Second: 21,955.51881
Overall Steps per Second: 10,489.28309

Timestep Collection Time: 2.27797
Timestep Consumption Time: 2.49014
PPO Batch Consumption Time: 0.28709
Total Iteration Time: 4.76810

Cumulative Model Updates: 241,844
Cumulative Timesteps: 2,017,607,270

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2017607270...
Checkpoint 2017607270 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 58,545.58621
Policy Entropy: 2.33972
Value Function Loss: 0.01614

Mean KL Divergence: 0.00655
SB3 Clip Fraction: 0.06078
Policy Update Magnitude: 0.28498
Value Function Update Magnitude: 0.27297

Collected Steps per Second: 22,036.28604
Overall Steps per Second: 10,659.22549

Timestep Collection Time: 2.27007
Timestep Consumption Time: 2.42295
PPO Batch Consumption Time: 0.27879
Total Iteration Time: 4.69302

Cumulative Model Updates: 241,850
Cumulative Timesteps: 2,017,657,294

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46,029.33076
Policy Entropy: 2.31677
Value Function Loss: 0.01944

Mean KL Divergence: 0.00706
SB3 Clip Fraction: 0.06859
Policy Update Magnitude: 0.30506
Value Function Update Magnitude: 0.33978

Collected Steps per Second: 21,505.35230
Overall Steps per Second: 10,478.04098

Timestep Collection Time: 2.32528
Timestep Consumption Time: 2.44718
PPO Batch Consumption Time: 0.27886
Total Iteration Time: 4.77246

Cumulative Model Updates: 241,856
Cumulative Timesteps: 2,017,707,300

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2017707300...
Checkpoint 2017707300 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 60,437.14212
Policy Entropy: 2.32894
Value Function Loss: 0.01921

Mean KL Divergence: 0.00703
SB3 Clip Fraction: 0.06985
Policy Update Magnitude: 0.31326
Value Function Update Magnitude: 0.35541

Collected Steps per Second: 21,416.84416
Overall Steps per Second: 10,341.35569

Timestep Collection Time: 2.33583
Timestep Consumption Time: 2.50165
PPO Batch Consumption Time: 0.29082
Total Iteration Time: 4.83747

Cumulative Model Updates: 241,862
Cumulative Timesteps: 2,017,757,326

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88,115.22447
Policy Entropy: 2.36875
Value Function Loss: 0.02030

Mean KL Divergence: 0.00748
SB3 Clip Fraction: 0.07240
Policy Update Magnitude: 0.30866
Value Function Update Magnitude: 0.33359

Collected Steps per Second: 21,584.38517
Overall Steps per Second: 10,353.21354

Timestep Collection Time: 2.31769
Timestep Consumption Time: 2.51424
PPO Batch Consumption Time: 0.29413
Total Iteration Time: 4.83193

Cumulative Model Updates: 241,868
Cumulative Timesteps: 2,017,807,352

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2017807352...
Checkpoint 2017807352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 57,026.71324
Policy Entropy: 2.40156
Value Function Loss: 0.02092

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.08681
Policy Update Magnitude: 0.30669
Value Function Update Magnitude: 0.30572

Collected Steps per Second: 21,391.03557
Overall Steps per Second: 10,493.84896

Timestep Collection Time: 2.33883
Timestep Consumption Time: 2.42872
PPO Batch Consumption Time: 0.27838
Total Iteration Time: 4.76755

Cumulative Model Updates: 241,874
Cumulative Timesteps: 2,017,857,382

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57,026.71324
Policy Entropy: 2.36213
Value Function Loss: 0.02118

Mean KL Divergence: 0.01613
SB3 Clip Fraction: 0.12344
Policy Update Magnitude: 0.28788
Value Function Update Magnitude: 0.27108

Collected Steps per Second: 22,023.07554
Overall Steps per Second: 10,575.62060

Timestep Collection Time: 2.27144
Timestep Consumption Time: 2.45869
PPO Batch Consumption Time: 0.27805
Total Iteration Time: 4.73012

Cumulative Model Updates: 241,880
Cumulative Timesteps: 2,017,907,406

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2017907406...
Checkpoint 2017907406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 82,113.00214
Policy Entropy: 2.33768
Value Function Loss: 0.02028

Mean KL Divergence: 0.01538
SB3 Clip Fraction: 0.12428
Policy Update Magnitude: 0.27352
Value Function Update Magnitude: 0.23875

Collected Steps per Second: 22,033.87180
Overall Steps per Second: 10,640.50565

Timestep Collection Time: 2.27041
Timestep Consumption Time: 2.43105
PPO Batch Consumption Time: 0.27801
Total Iteration Time: 4.70147

Cumulative Model Updates: 241,886
Cumulative Timesteps: 2,017,957,432

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 107,636.81866
Policy Entropy: 2.31030
Value Function Loss: 0.01903

Mean KL Divergence: 0.01282
SB3 Clip Fraction: 0.11026
Policy Update Magnitude: 0.28831
Value Function Update Magnitude: 0.28331

Collected Steps per Second: 22,119.28070
Overall Steps per Second: 10,530.58416

Timestep Collection Time: 2.26174
Timestep Consumption Time: 2.48900
PPO Batch Consumption Time: 0.29276
Total Iteration Time: 4.75073

Cumulative Model Updates: 241,892
Cumulative Timesteps: 2,018,007,460

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2018007460...
Checkpoint 2018007460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 99,968.54106
Policy Entropy: 2.35490
Value Function Loss: 0.01716

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.09549
Policy Update Magnitude: 0.29690
Value Function Update Magnitude: 0.28954

Collected Steps per Second: 22,002.31244
Overall Steps per Second: 10,534.10967

Timestep Collection Time: 2.27431
Timestep Consumption Time: 2.47598
PPO Batch Consumption Time: 0.28765
Total Iteration Time: 4.75028

Cumulative Model Updates: 241,898
Cumulative Timesteps: 2,018,057,500

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 74,502.92136
Policy Entropy: 2.37270
Value Function Loss: 0.01625

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.08744
Policy Update Magnitude: 0.29534
Value Function Update Magnitude: 0.30169

Collected Steps per Second: 22,193.33085
Overall Steps per Second: 10,522.39169

Timestep Collection Time: 2.25419
Timestep Consumption Time: 2.50024
PPO Batch Consumption Time: 0.29366
Total Iteration Time: 4.75443

Cumulative Model Updates: 241,904
Cumulative Timesteps: 2,018,107,528

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2018107528...
Checkpoint 2018107528 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 66,317.56302
Policy Entropy: 2.36917
Value Function Loss: 0.01616

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.08444
Policy Update Magnitude: 0.28926
Value Function Update Magnitude: 0.29500

Collected Steps per Second: 21,149.51839
Overall Steps per Second: 10,565.82116

Timestep Collection Time: 2.36554
Timestep Consumption Time: 2.36954
PPO Batch Consumption Time: 0.27922
Total Iteration Time: 4.73508

Cumulative Model Updates: 241,910
Cumulative Timesteps: 2,018,157,558

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48,811.16892
Policy Entropy: 2.34278
Value Function Loss: 0.01628

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.08983
Policy Update Magnitude: 0.29542
Value Function Update Magnitude: 0.27710

Collected Steps per Second: 20,902.95607
Overall Steps per Second: 10,545.92541

Timestep Collection Time: 2.39382
Timestep Consumption Time: 2.35095
PPO Batch Consumption Time: 0.27730
Total Iteration Time: 4.74477

Cumulative Model Updates: 241,916
Cumulative Timesteps: 2,018,207,596

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 2018207596...
Checkpoint 2018207596 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46,602.29499
Policy Entropy: 2.31495
Value Function Loss: 0.01643

Mean KL Divergence: 0.01203
SB3 Clip Fraction: 0.10979
Policy Update Magnitude: 0.29581
Value Function Update Magnitude: 0.27356

Collected Steps per Second: 20,746.10670
Overall Steps per Second: 10,501.73033

Timestep Collection Time: 2.41125
Timestep Consumption Time: 2.35216
PPO Batch Consumption Time: 0.27834
Total Iteration Time: 4.76341

Cumulative Model Updates: 241,922
Cumulative Timesteps: 2,018,257,620

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67,636.90355
Policy Entropy: 2.32413
Value Function Loss: 0.01817

Mean KL Divergence: 0.01118
SB3 Clip Fraction: 0.09883
Policy Update Magnitude: 0.30279
Value Function Update Magnitude: 0.27913

Collected Steps per Second: 21,021.66149
Overall Steps per Second: 10,441.34502

Timestep Collection Time: 2.37955
Timestep Consumption Time: 2.41122
PPO Batch Consumption Time: 0.27898
Total Iteration Time: 4.79076

Cumulative Model Updates: 241,928
Cumulative Timesteps: 2,018,307,642

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2018307642...
Checkpoint 2018307642 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 61,112.18115
Policy Entropy: 2.32937
Value Function Loss: 0.01736

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.08362
Policy Update Magnitude: 0.30501
Value Function Update Magnitude: 0.27613

Collected Steps per Second: 21,335.99030
Overall Steps per Second: 10,334.24402

Timestep Collection Time: 2.34533
Timestep Consumption Time: 2.49682
PPO Batch Consumption Time: 0.29374
Total Iteration Time: 4.84215

Cumulative Model Updates: 241,934
Cumulative Timesteps: 2,018,357,682

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62,170.84320
Policy Entropy: 2.35165
Value Function Loss: 0.01700

Mean KL Divergence: 0.00736
SB3 Clip Fraction: 0.06323
Policy Update Magnitude: 0.29979
Value Function Update Magnitude: 0.27637

Collected Steps per Second: 22,111.74506
Overall Steps per Second: 10,475.82342

Timestep Collection Time: 2.26124
Timestep Consumption Time: 2.51165
PPO Batch Consumption Time: 0.29350
Total Iteration Time: 4.77289

Cumulative Model Updates: 241,940
Cumulative Timesteps: 2,018,407,682

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2018407682...
Checkpoint 2018407682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 63,450.96733
Policy Entropy: 2.35131
Value Function Loss: 0.01497

Mean KL Divergence: 0.00687
SB3 Clip Fraction: 0.06026
Policy Update Magnitude: 0.29249
Value Function Update Magnitude: 0.27860

Collected Steps per Second: 21,815.34968
Overall Steps per Second: 10,597.17224

Timestep Collection Time: 2.29316
Timestep Consumption Time: 2.42754
PPO Batch Consumption Time: 0.27748
Total Iteration Time: 4.72069

Cumulative Model Updates: 241,946
Cumulative Timesteps: 2,018,457,708

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45,964.31586
Policy Entropy: 2.35066
Value Function Loss: 0.01905

Mean KL Divergence: 0.00663
SB3 Clip Fraction: 0.06443
Policy Update Magnitude: 0.29725
Value Function Update Magnitude: 0.30853

Collected Steps per Second: 22,026.00478
Overall Steps per Second: 10,450.61920

Timestep Collection Time: 2.27004
Timestep Consumption Time: 2.51436
PPO Batch Consumption Time: 0.29282
Total Iteration Time: 4.78441

Cumulative Model Updates: 241,952
Cumulative Timesteps: 2,018,507,708

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2018507708...
Checkpoint 2018507708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,722.70749
Policy Entropy: 2.33863
Value Function Loss: 0.01960

Mean KL Divergence: 0.00724
SB3 Clip Fraction: 0.06929
Policy Update Magnitude: 0.30357
Value Function Update Magnitude: 0.32698

Collected Steps per Second: 21,747.90243
Overall Steps per Second: 10,555.18732

Timestep Collection Time: 2.29981
Timestep Consumption Time: 2.43872
PPO Batch Consumption Time: 0.27918
Total Iteration Time: 4.73852

Cumulative Model Updates: 241,958
Cumulative Timesteps: 2,018,557,724

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,649.43379
Policy Entropy: 2.34532
Value Function Loss: 0.02418

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.07474
Policy Update Magnitude: 0.31543
Value Function Update Magnitude: 0.31514

Collected Steps per Second: 22,093.68814
Overall Steps per Second: 10,503.55427

Timestep Collection Time: 2.26390
Timestep Consumption Time: 2.49810
PPO Batch Consumption Time: 0.29016
Total Iteration Time: 4.76201

Cumulative Model Updates: 241,964
Cumulative Timesteps: 2,018,607,742

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2018607742...
Checkpoint 2018607742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,433.77681
Policy Entropy: 2.35095
Value Function Loss: 0.02299

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.08068
Policy Update Magnitude: 0.31842
Value Function Update Magnitude: 0.28256

Collected Steps per Second: 21,692.96230
Overall Steps per Second: 10,569.37145

Timestep Collection Time: 2.30674
Timestep Consumption Time: 2.42770
PPO Batch Consumption Time: 0.27851
Total Iteration Time: 4.73443

Cumulative Model Updates: 241,970
Cumulative Timesteps: 2,018,657,782

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 69,188.35302
Policy Entropy: 2.34772
Value Function Loss: 0.02042

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.07222
Policy Update Magnitude: 0.31571
Value Function Update Magnitude: 0.26122

Collected Steps per Second: 21,843.49585
Overall Steps per Second: 10,529.37518

Timestep Collection Time: 2.28993
Timestep Consumption Time: 2.46059
PPO Batch Consumption Time: 0.28504
Total Iteration Time: 4.75052

Cumulative Model Updates: 241,976
Cumulative Timesteps: 2,018,707,802

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2018707802...
Checkpoint 2018707802 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 78,125.95501
Policy Entropy: 2.32591
Value Function Loss: 0.01742

Mean KL Divergence: 0.00676
SB3 Clip Fraction: 0.06500
Policy Update Magnitude: 0.30392
Value Function Update Magnitude: 0.29315

Collected Steps per Second: 21,628.51722
Overall Steps per Second: 10,559.42036

Timestep Collection Time: 2.31186
Timestep Consumption Time: 2.42344
PPO Batch Consumption Time: 0.27926
Total Iteration Time: 4.73530

Cumulative Model Updates: 241,982
Cumulative Timesteps: 2,018,757,804

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80,593.42526
Policy Entropy: 2.31996
Value Function Loss: 0.01691

Mean KL Divergence: 0.00693
SB3 Clip Fraction: 0.06647
Policy Update Magnitude: 0.29872
Value Function Update Magnitude: 0.28623

Collected Steps per Second: 21,598.47078
Overall Steps per Second: 10,522.90455

Timestep Collection Time: 2.31600
Timestep Consumption Time: 2.43763
PPO Batch Consumption Time: 0.27849
Total Iteration Time: 4.75363

Cumulative Model Updates: 241,988
Cumulative Timesteps: 2,018,807,826

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2018807826...
Checkpoint 2018807826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 59,737.95666
Policy Entropy: 2.31137
Value Function Loss: 0.01909

Mean KL Divergence: 0.00652
SB3 Clip Fraction: 0.06174
Policy Update Magnitude: 0.30926
Value Function Update Magnitude: 0.29582

Collected Steps per Second: 20,912.86146
Overall Steps per Second: 10,178.60044

Timestep Collection Time: 2.39087
Timestep Consumption Time: 2.52139
PPO Batch Consumption Time: 0.28939
Total Iteration Time: 4.91227

Cumulative Model Updates: 241,994
Cumulative Timesteps: 2,018,857,826

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42,857.85046
Policy Entropy: 2.32251
Value Function Loss: 0.02006

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.07540
Policy Update Magnitude: 0.31182
Value Function Update Magnitude: 0.32663

Collected Steps per Second: 21,526.35603
Overall Steps per Second: 10,481.06214

Timestep Collection Time: 2.32329
Timestep Consumption Time: 2.44836
PPO Batch Consumption Time: 0.27904
Total Iteration Time: 4.77165

Cumulative Model Updates: 242,000
Cumulative Timesteps: 2,018,907,838

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2018907838...
Checkpoint 2018907838 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 65,555.66444
Policy Entropy: 2.29918
Value Function Loss: 0.01974

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.07845
Policy Update Magnitude: 0.31272
Value Function Update Magnitude: 0.30550

Collected Steps per Second: 21,476.49209
Overall Steps per Second: 10,306.01085

Timestep Collection Time: 2.32906
Timestep Consumption Time: 2.52442
PPO Batch Consumption Time: 0.29186
Total Iteration Time: 4.85348

Cumulative Model Updates: 242,006
Cumulative Timesteps: 2,018,957,858

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 112,172.63978
Policy Entropy: 2.32045
Value Function Loss: 0.02032

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.08261
Policy Update Magnitude: 0.31413
Value Function Update Magnitude: 0.31060

Collected Steps per Second: 22,475.17733
Overall Steps per Second: 10,724.63218

Timestep Collection Time: 2.22503
Timestep Consumption Time: 2.43788
PPO Batch Consumption Time: 0.27850
Total Iteration Time: 4.66291

Cumulative Model Updates: 242,012
Cumulative Timesteps: 2,019,007,866

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2019007866...
Checkpoint 2019007866 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 93,217.70576
Policy Entropy: 2.33824
Value Function Loss: 0.01828

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.08005
Policy Update Magnitude: 0.30853
Value Function Update Magnitude: 0.28469

Collected Steps per Second: 21,814.86522
Overall Steps per Second: 10,603.95400

Timestep Collection Time: 2.29238
Timestep Consumption Time: 2.42359
PPO Batch Consumption Time: 0.27936
Total Iteration Time: 4.71598

Cumulative Model Updates: 242,018
Cumulative Timesteps: 2,019,057,874

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87,776.89656
Policy Entropy: 2.36414
Value Function Loss: 0.01759

Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.07722
Policy Update Magnitude: 0.29893
Value Function Update Magnitude: 0.27363

Collected Steps per Second: 21,408.10844
Overall Steps per Second: 10,531.24246

Timestep Collection Time: 2.33575
Timestep Consumption Time: 2.41241
PPO Batch Consumption Time: 0.28841
Total Iteration Time: 4.74816

Cumulative Model Updates: 242,024
Cumulative Timesteps: 2,019,107,878

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2019107878...
Checkpoint 2019107878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87,776.89656
Policy Entropy: 2.34135
Value Function Loss: 0.01576

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.07878
Policy Update Magnitude: 0.29383
Value Function Update Magnitude: 0.27769

Collected Steps per Second: 21,269.12349
Overall Steps per Second: 10,635.01929

Timestep Collection Time: 2.35111
Timestep Consumption Time: 2.35091
PPO Batch Consumption Time: 0.27929
Total Iteration Time: 4.70201

Cumulative Model Updates: 242,030
Cumulative Timesteps: 2,019,157,884

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75,019.87427
Policy Entropy: 2.34198
Value Function Loss: 0.01473

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.07927
Policy Update Magnitude: 0.28730
Value Function Update Magnitude: 0.27454

Collected Steps per Second: 21,572.88297
Overall Steps per Second: 10,542.74545

Timestep Collection Time: 2.31847
Timestep Consumption Time: 2.42565
PPO Batch Consumption Time: 0.29311
Total Iteration Time: 4.74412

Cumulative Model Updates: 242,036
Cumulative Timesteps: 2,019,207,900

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2019207900...
Checkpoint 2019207900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 61,513.05934
Policy Entropy: 2.34908
Value Function Loss: 0.01577

Mean KL Divergence: 0.00782
SB3 Clip Fraction: 0.07445
Policy Update Magnitude: 0.29093
Value Function Update Magnitude: 0.26006

Collected Steps per Second: 21,467.52145
Overall Steps per Second: 10,553.42536

Timestep Collection Time: 2.33040
Timestep Consumption Time: 2.41005
PPO Batch Consumption Time: 0.27980
Total Iteration Time: 4.74045

Cumulative Model Updates: 242,042
Cumulative Timesteps: 2,019,257,928

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53,606.75806
Policy Entropy: 2.35083
Value Function Loss: 0.01603

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.07658
Policy Update Magnitude: 0.29434
Value Function Update Magnitude: 0.26281

Collected Steps per Second: 21,289.63041
Overall Steps per Second: 10,518.15267

Timestep Collection Time: 2.34922
Timestep Consumption Time: 2.40580
PPO Batch Consumption Time: 0.27802
Total Iteration Time: 4.75502

Cumulative Model Updates: 242,048
Cumulative Timesteps: 2,019,307,942

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2019307942...
Checkpoint 2019307942 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47,576.03939
Policy Entropy: 2.34167
Value Function Loss: 0.01623

Mean KL Divergence: 0.00744
SB3 Clip Fraction: 0.07414
Policy Update Magnitude: 0.29642
Value Function Update Magnitude: 0.29144

Collected Steps per Second: 21,016.23962
Overall Steps per Second: 10,319.59588

Timestep Collection Time: 2.37959
Timestep Consumption Time: 2.46653
PPO Batch Consumption Time: 0.28950
Total Iteration Time: 4.84612

Cumulative Model Updates: 242,054
Cumulative Timesteps: 2,019,357,952

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85,616.51947
Policy Entropy: 2.32439
Value Function Loss: 0.01485

Mean KL Divergence: 0.00719
SB3 Clip Fraction: 0.07012
Policy Update Magnitude: 0.29904
Value Function Update Magnitude: 0.29805

Collected Steps per Second: 21,870.19272
Overall Steps per Second: 10,475.30645

Timestep Collection Time: 2.28677
Timestep Consumption Time: 2.48751
PPO Batch Consumption Time: 0.29024
Total Iteration Time: 4.77428

Cumulative Model Updates: 242,060
Cumulative Timesteps: 2,019,407,964

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2019407964...
Checkpoint 2019407964 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 105,133.90996
Policy Entropy: 2.31300
Value Function Loss: 0.01635

Mean KL Divergence: 0.00715
SB3 Clip Fraction: 0.07001
Policy Update Magnitude: 0.30086
Value Function Update Magnitude: 0.30274

Collected Steps per Second: 21,476.02628
Overall Steps per Second: 10,505.13162

Timestep Collection Time: 2.32836
Timestep Consumption Time: 2.43160
PPO Batch Consumption Time: 0.27697
Total Iteration Time: 4.75996

Cumulative Model Updates: 242,066
Cumulative Timesteps: 2,019,457,968

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90,631.04385
Policy Entropy: 2.30620
Value Function Loss: 0.01807

Mean KL Divergence: 0.00727
SB3 Clip Fraction: 0.06709
Policy Update Magnitude: 0.31084
Value Function Update Magnitude: 0.32176

Collected Steps per Second: 22,263.63717
Overall Steps per Second: 10,481.00125

Timestep Collection Time: 2.24626
Timestep Consumption Time: 2.52523
PPO Batch Consumption Time: 0.29227
Total Iteration Time: 4.77149

Cumulative Model Updates: 242,072
Cumulative Timesteps: 2,019,507,978

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2019507978...
Checkpoint 2019507978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 92,804.27020
Policy Entropy: 2.32636
Value Function Loss: 0.01958

Mean KL Divergence: 0.00737
SB3 Clip Fraction: 0.06591
Policy Update Magnitude: 0.31287
Value Function Update Magnitude: 0.34198

Collected Steps per Second: 22,052.97167
Overall Steps per Second: 10,474.91073

Timestep Collection Time: 2.26763
Timestep Consumption Time: 2.50644
PPO Batch Consumption Time: 0.28874
Total Iteration Time: 4.77407

Cumulative Model Updates: 242,078
Cumulative Timesteps: 2,019,557,986

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78,933.29990
Policy Entropy: 2.34729
Value Function Loss: 0.01746

Mean KL Divergence: 0.00723
SB3 Clip Fraction: 0.06576
Policy Update Magnitude: 0.30580
Value Function Update Magnitude: 0.34650

Collected Steps per Second: 22,139.22914
Overall Steps per Second: 10,517.93998

Timestep Collection Time: 2.25880
Timestep Consumption Time: 2.49575
PPO Batch Consumption Time: 0.29017
Total Iteration Time: 4.75454

Cumulative Model Updates: 242,084
Cumulative Timesteps: 2,019,607,994

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2019607994...
Checkpoint 2019607994 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 64,457.87943
Policy Entropy: 2.35043
Value Function Loss: 0.01667

Mean KL Divergence: 0.00630
SB3 Clip Fraction: 0.06087
Policy Update Magnitude: 0.30055
Value Function Update Magnitude: 0.30583

Collected Steps per Second: 21,998.33331
Overall Steps per Second: 10,661.85167

Timestep Collection Time: 2.27481
Timestep Consumption Time: 2.41875
PPO Batch Consumption Time: 0.27825
Total Iteration Time: 4.69356

Cumulative Model Updates: 242,090
Cumulative Timesteps: 2,019,658,036

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 130,691.76889
Policy Entropy: 2.37341
Value Function Loss: 0.01695

Mean KL Divergence: 0.00717
SB3 Clip Fraction: 0.06703
Policy Update Magnitude: 0.29652
Value Function Update Magnitude: 0.29731

Collected Steps per Second: 22,363.44832
Overall Steps per Second: 10,579.80607

Timestep Collection Time: 2.23704
Timestep Consumption Time: 2.49159
PPO Batch Consumption Time: 0.29094
Total Iteration Time: 4.72863

Cumulative Model Updates: 242,096
Cumulative Timesteps: 2,019,708,064

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2019708064...
Checkpoint 2019708064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 77,452.46055
Policy Entropy: 2.37637
Value Function Loss: 0.01900

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.07296
Policy Update Magnitude: 0.28991
Value Function Update Magnitude: 0.28781

Collected Steps per Second: 21,874.85771
Overall Steps per Second: 10,470.49036

Timestep Collection Time: 2.28619
Timestep Consumption Time: 2.49009
PPO Batch Consumption Time: 0.28845
Total Iteration Time: 4.77628

Cumulative Model Updates: 242,102
Cumulative Timesteps: 2,019,758,074

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56,335.76196
Policy Entropy: 2.36629
Value Function Loss: 0.01810

Mean KL Divergence: 0.00631
SB3 Clip Fraction: 0.05851
Policy Update Magnitude: 0.29205
Value Function Update Magnitude: 0.28091

Collected Steps per Second: 21,733.59907
Overall Steps per Second: 10,568.36495

Timestep Collection Time: 2.30307
Timestep Consumption Time: 2.43314
PPO Batch Consumption Time: 0.27764
Total Iteration Time: 4.73621

Cumulative Model Updates: 242,108
Cumulative Timesteps: 2,019,808,128

Timesteps Collected: 50,054
--------END ITERATION REPORT--------


Saving checkpoint 2019808128...
Checkpoint 2019808128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 67,676.51573
Policy Entropy: 2.35427
Value Function Loss: 0.02125

Mean KL Divergence: 0.00654
SB3 Clip Fraction: 0.06383
Policy Update Magnitude: 0.30146
Value Function Update Magnitude: 0.27596

Collected Steps per Second: 20,973.77737
Overall Steps per Second: 10,237.95548

Timestep Collection Time: 2.38412
Timestep Consumption Time: 2.50006
PPO Batch Consumption Time: 0.29272
Total Iteration Time: 4.88418

Cumulative Model Updates: 242,114
Cumulative Timesteps: 2,019,858,132

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59,251.06063
Policy Entropy: 2.33778
Value Function Loss: 0.01883

Mean KL Divergence: 0.00704
SB3 Clip Fraction: 0.06757
Policy Update Magnitude: 0.30242
Value Function Update Magnitude: 0.29601

Collected Steps per Second: 21,810.68846
Overall Steps per Second: 10,390.02146

Timestep Collection Time: 2.29245
Timestep Consumption Time: 2.51986
PPO Batch Consumption Time: 0.29372
Total Iteration Time: 4.81231

Cumulative Model Updates: 242,120
Cumulative Timesteps: 2,019,908,132

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2019908132...
Checkpoint 2019908132 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 52,143.83361
Policy Entropy: 2.35772
Value Function Loss: 0.01718

Mean KL Divergence: 0.00680
SB3 Clip Fraction: 0.06275
Policy Update Magnitude: 0.29281
Value Function Update Magnitude: 0.30757

Collected Steps per Second: 21,545.67790
Overall Steps per Second: 10,514.61606

Timestep Collection Time: 2.32084
Timestep Consumption Time: 2.43483
PPO Batch Consumption Time: 0.27865
Total Iteration Time: 4.75567

Cumulative Model Updates: 242,126
Cumulative Timesteps: 2,019,958,136

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42,032.53142
Policy Entropy: 2.36277
Value Function Loss: 0.01651

Mean KL Divergence: 0.00759
SB3 Clip Fraction: 0.07211
Policy Update Magnitude: 0.29048
Value Function Update Magnitude: 0.26828

Collected Steps per Second: 22,319.52206
Overall Steps per Second: 10,516.18519

Timestep Collection Time: 2.24091
Timestep Consumption Time: 2.51519
PPO Batch Consumption Time: 0.28857
Total Iteration Time: 4.75610

Cumulative Model Updates: 242,132
Cumulative Timesteps: 2,020,008,152

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2020008152...
Checkpoint 2020008152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 60,152.38474
Policy Entropy: 2.34942
Value Function Loss: 0.01722

Mean KL Divergence: 0.00751
SB3 Clip Fraction: 0.07170
Policy Update Magnitude: 0.29554
Value Function Update Magnitude: 0.25432

Collected Steps per Second: 21,709.76183
Overall Steps per Second: 10,576.72508

Timestep Collection Time: 2.30348
Timestep Consumption Time: 2.42464
PPO Batch Consumption Time: 0.27935
Total Iteration Time: 4.72812

Cumulative Model Updates: 242,138
Cumulative Timesteps: 2,020,058,160

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53,920.49346
Policy Entropy: 2.35281
Value Function Loss: 0.01964

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.07623
Policy Update Magnitude: 0.30326
Value Function Update Magnitude: 0.23514

Collected Steps per Second: 21,522.79241
Overall Steps per Second: 10,496.22360

Timestep Collection Time: 2.32451
Timestep Consumption Time: 2.44196
PPO Batch Consumption Time: 0.29377
Total Iteration Time: 4.76648

Cumulative Model Updates: 242,144
Cumulative Timesteps: 2,020,108,190

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2020108190...
Checkpoint 2020108190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 50,312.41030
Policy Entropy: 2.34702
Value Function Loss: 0.01698

Mean KL Divergence: 0.00744
SB3 Clip Fraction: 0.07157
Policy Update Magnitude: 0.30100
Value Function Update Magnitude: 0.28479

Collected Steps per Second: 21,135.82823
Overall Steps per Second: 10,576.12224

Timestep Collection Time: 2.36594
Timestep Consumption Time: 2.36226
PPO Batch Consumption Time: 0.27925
Total Iteration Time: 4.72820

Cumulative Model Updates: 242,150
Cumulative Timesteps: 2,020,158,196

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51,576.89359
Policy Entropy: 2.35911
Value Function Loss: 0.01602

Mean KL Divergence: 0.00683
SB3 Clip Fraction: 0.06761
Policy Update Magnitude: 0.29544
Value Function Update Magnitude: 0.31135

Collected Steps per Second: 21,609.88737
Overall Steps per Second: 10,603.16061

Timestep Collection Time: 2.31542
Timestep Consumption Time: 2.40355
PPO Batch Consumption Time: 0.27757
Total Iteration Time: 4.71897

Cumulative Model Updates: 242,156
Cumulative Timesteps: 2,020,208,232

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 2020208232...
Checkpoint 2020208232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 70,651.99572
Policy Entropy: 2.32989
Value Function Loss: 0.01700

Mean KL Divergence: 0.00679
SB3 Clip Fraction: 0.06603
Policy Update Magnitude: 0.30204
Value Function Update Magnitude: 0.30793

Collected Steps per Second: 21,810.50946
Overall Steps per Second: 10,568.35666

Timestep Collection Time: 2.29366
Timestep Consumption Time: 2.43990
PPO Batch Consumption Time: 0.28419
Total Iteration Time: 4.73356

Cumulative Model Updates: 242,162
Cumulative Timesteps: 2,020,258,258

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62,883.99613
Policy Entropy: 2.31890
Value Function Loss: 0.01798

Mean KL Divergence: 0.00699
SB3 Clip Fraction: 0.06779
Policy Update Magnitude: 0.31792
Value Function Update Magnitude: 0.32458

Collected Steps per Second: 21,745.24408
Overall Steps per Second: 10,458.19196

Timestep Collection Time: 2.30027
Timestep Consumption Time: 2.48258
PPO Batch Consumption Time: 0.29255
Total Iteration Time: 4.78285

Cumulative Model Updates: 242,168
Cumulative Timesteps: 2,020,308,278

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2020308278...
Checkpoint 2020308278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 57,636.51285
Policy Entropy: 2.29614
Value Function Loss: 0.01811

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.06995
Policy Update Magnitude: 0.31835
Value Function Update Magnitude: 0.33464

Collected Steps per Second: 21,181.97038
Overall Steps per Second: 10,247.72655

Timestep Collection Time: 2.36069
Timestep Consumption Time: 2.51883
PPO Batch Consumption Time: 0.29319
Total Iteration Time: 4.87952

Cumulative Model Updates: 242,174
Cumulative Timesteps: 2,020,358,282

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60,615.12990
Policy Entropy: 2.32338
Value Function Loss: 0.01688

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.06945
Policy Update Magnitude: 0.31212
Value Function Update Magnitude: 0.29662

Collected Steps per Second: 21,756.00743
Overall Steps per Second: 10,487.08911

Timestep Collection Time: 2.29950
Timestep Consumption Time: 2.47093
PPO Batch Consumption Time: 0.29380
Total Iteration Time: 4.77044

Cumulative Model Updates: 242,180
Cumulative Timesteps: 2,020,408,310

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2020408310...
Checkpoint 2020408310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 52,669.30223
Policy Entropy: 2.32702
Value Function Loss: 0.01822

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.07483
Policy Update Magnitude: 0.30574
Value Function Update Magnitude: 0.22538

Collected Steps per Second: 21,557.43531
Overall Steps per Second: 10,521.67582

Timestep Collection Time: 2.32115
Timestep Consumption Time: 2.43456
PPO Batch Consumption Time: 0.27900
Total Iteration Time: 4.75571

Cumulative Model Updates: 242,186
Cumulative Timesteps: 2,020,458,348

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70,171.49974
Policy Entropy: 2.35611
Value Function Loss: 0.01898

Mean KL Divergence: 0.00756
SB3 Clip Fraction: 0.07291
Policy Update Magnitude: 0.30051
Value Function Update Magnitude: 0.18618

Collected Steps per Second: 21,832.03232
Overall Steps per Second: 10,503.15205

Timestep Collection Time: 2.29122
Timestep Consumption Time: 2.47135
PPO Batch Consumption Time: 0.27961
Total Iteration Time: 4.76257

Cumulative Model Updates: 242,192
Cumulative Timesteps: 2,020,508,370

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2020508370...
Checkpoint 2020508370 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 71,177.04740
Policy Entropy: 2.33972
Value Function Loss: 0.01961

Mean KL Divergence: 0.00746
SB3 Clip Fraction: 0.06966
Policy Update Magnitude: 0.30032
Value Function Update Magnitude: 0.17409

Collected Steps per Second: 21,883.23247
Overall Steps per Second: 10,558.76120

Timestep Collection Time: 2.28485
Timestep Consumption Time: 2.45055
PPO Batch Consumption Time: 0.28019
Total Iteration Time: 4.73540

Cumulative Model Updates: 242,198
Cumulative Timesteps: 2,020,558,370

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 127,541.92313
Policy Entropy: 2.36513
Value Function Loss: 0.01775

Mean KL Divergence: 0.00657
SB3 Clip Fraction: 0.06211
Policy Update Magnitude: 0.29880
Value Function Update Magnitude: 0.16895

Collected Steps per Second: 22,037.82704
Overall Steps per Second: 10,535.46533

Timestep Collection Time: 2.26946
Timestep Consumption Time: 2.47774
PPO Batch Consumption Time: 0.28522
Total Iteration Time: 4.74720

Cumulative Model Updates: 242,204
Cumulative Timesteps: 2,020,608,384

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2020608384...
Checkpoint 2020608384 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 105,839.38175
Policy Entropy: 2.33720
Value Function Loss: 0.01902

Mean KL Divergence: 0.00681
SB3 Clip Fraction: 0.06182
Policy Update Magnitude: 0.30719
Value Function Update Magnitude: 0.20663

Collected Steps per Second: 21,491.80000
Overall Steps per Second: 10,530.35701

Timestep Collection Time: 2.32647
Timestep Consumption Time: 2.42171
PPO Batch Consumption Time: 0.27906
Total Iteration Time: 4.74818

Cumulative Model Updates: 242,210
Cumulative Timesteps: 2,020,658,384

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 98,042.35670
Policy Entropy: 2.33287
Value Function Loss: 0.01714

Mean KL Divergence: 0.00672
SB3 Clip Fraction: 0.06081
Policy Update Magnitude: 0.30535
Value Function Update Magnitude: 0.22527

Collected Steps per Second: 22,034.29583
Overall Steps per Second: 10,514.65148

Timestep Collection Time: 2.26955
Timestep Consumption Time: 2.48648
PPO Batch Consumption Time: 0.28746
Total Iteration Time: 4.75603

Cumulative Model Updates: 242,216
Cumulative Timesteps: 2,020,708,392

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2020708392...
Checkpoint 2020708392 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 77,233.50656
Policy Entropy: 2.31049
Value Function Loss: 0.01788

Mean KL Divergence: 0.00737
SB3 Clip Fraction: 0.06750
Policy Update Magnitude: 0.30937
Value Function Update Magnitude: 0.25079

Collected Steps per Second: 20,553.68936
Overall Steps per Second: 10,244.46123

Timestep Collection Time: 2.43285
Timestep Consumption Time: 2.44823
PPO Batch Consumption Time: 0.27855
Total Iteration Time: 4.88108

Cumulative Model Updates: 242,222
Cumulative Timesteps: 2,020,758,396

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55,636.51333
Policy Entropy: 2.31534
Value Function Loss: 0.01589

Mean KL Divergence: 0.00686
SB3 Clip Fraction: 0.06701
Policy Update Magnitude: 0.30768
Value Function Update Magnitude: 0.28801

Collected Steps per Second: 21,703.05147
Overall Steps per Second: 10,469.92784

Timestep Collection Time: 2.30382
Timestep Consumption Time: 2.47176
PPO Batch Consumption Time: 0.28594
Total Iteration Time: 4.77558

Cumulative Model Updates: 242,228
Cumulative Timesteps: 2,020,808,396

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2020808396...
Checkpoint 2020808396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86,998.24572
Policy Entropy: 2.31926
Value Function Loss: 0.01604

Mean KL Divergence: 0.00721
SB3 Clip Fraction: 0.06544
Policy Update Magnitude: 0.29981
Value Function Update Magnitude: 0.23747

Collected Steps per Second: 21,006.53183
Overall Steps per Second: 10,214.89660

Timestep Collection Time: 2.38088
Timestep Consumption Time: 2.51530
PPO Batch Consumption Time: 0.29384
Total Iteration Time: 4.89618

Cumulative Model Updates: 242,234
Cumulative Timesteps: 2,020,858,410

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90,989.19265
Policy Entropy: 2.32343
Value Function Loss: 0.01651

Mean KL Divergence: 0.00722
SB3 Clip Fraction: 0.06887
Policy Update Magnitude: 0.29633
Value Function Update Magnitude: 0.21805

Collected Steps per Second: 21,617.06952
Overall Steps per Second: 10,387.67370

Timestep Collection Time: 2.31363
Timestep Consumption Time: 2.50111
PPO Batch Consumption Time: 0.28845
Total Iteration Time: 4.81474

Cumulative Model Updates: 242,240
Cumulative Timesteps: 2,020,908,424

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2020908424...
Checkpoint 2020908424 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 75,443.56620
Policy Entropy: 2.35669
Value Function Loss: 0.01652

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.07466
Policy Update Magnitude: 0.29674
Value Function Update Magnitude: 0.27301

Collected Steps per Second: 21,984.32536
Overall Steps per Second: 10,544.83236

Timestep Collection Time: 2.27508
Timestep Consumption Time: 2.46810
PPO Batch Consumption Time: 0.27918
Total Iteration Time: 4.74318

Cumulative Model Updates: 242,246
Cumulative Timesteps: 2,020,958,440

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58,605.18649
Policy Entropy: 2.35768
Value Function Loss: 0.01948

Mean KL Divergence: 0.00702
SB3 Clip Fraction: 0.06560
Policy Update Magnitude: 0.30477
Value Function Update Magnitude: 0.28614

Collected Steps per Second: 22,288.74006
Overall Steps per Second: 10,526.72820

Timestep Collection Time: 2.24337
Timestep Consumption Time: 2.50663
PPO Batch Consumption Time: 0.28952
Total Iteration Time: 4.75000

Cumulative Model Updates: 242,252
Cumulative Timesteps: 2,021,008,442

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2021008442...
Checkpoint 2021008442 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 57,632.53797
Policy Entropy: 2.34476
Value Function Loss: 0.02054

Mean KL Divergence: 0.00758
SB3 Clip Fraction: 0.06686
Policy Update Magnitude: 0.31580
Value Function Update Magnitude: 0.25116

Collected Steps per Second: 21,718.56147
Overall Steps per Second: 10,581.89489

Timestep Collection Time: 2.30402
Timestep Consumption Time: 2.42481
PPO Batch Consumption Time: 0.27904
Total Iteration Time: 4.72883

Cumulative Model Updates: 242,258
Cumulative Timesteps: 2,021,058,482

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67,507.63281
Policy Entropy: 2.31738
Value Function Loss: 0.01972

Mean KL Divergence: 0.00753
SB3 Clip Fraction: 0.06885
Policy Update Magnitude: 0.31842
Value Function Update Magnitude: 0.27424

Collected Steps per Second: 21,415.37241
Overall Steps per Second: 10,467.26337

Timestep Collection Time: 2.33524
Timestep Consumption Time: 2.44251
PPO Batch Consumption Time: 0.27992
Total Iteration Time: 4.77775

Cumulative Model Updates: 242,264
Cumulative Timesteps: 2,021,108,492

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2021108492...
Checkpoint 2021108492 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 58,434.28057
Policy Entropy: 2.31513
Value Function Loss: 0.01771

Mean KL Divergence: 0.00759
SB3 Clip Fraction: 0.07313
Policy Update Magnitude: 0.30836
Value Function Update Magnitude: 0.30233

Collected Steps per Second: 21,918.28132
Overall Steps per Second: 10,601.01884

Timestep Collection Time: 2.28166
Timestep Consumption Time: 2.43581
PPO Batch Consumption Time: 0.27928
Total Iteration Time: 4.71747

Cumulative Model Updates: 242,270
Cumulative Timesteps: 2,021,158,502

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80,398.26087
Policy Entropy: 2.34131
Value Function Loss: 0.01485

Mean KL Divergence: 0.00660
SB3 Clip Fraction: 0.06308
Policy Update Magnitude: 0.29423
Value Function Update Magnitude: 0.27022

Collected Steps per Second: 22,200.67670
Overall Steps per Second: 10,582.06163

Timestep Collection Time: 2.25290
Timestep Consumption Time: 2.47358
PPO Batch Consumption Time: 0.28717
Total Iteration Time: 4.72649

Cumulative Model Updates: 242,276
Cumulative Timesteps: 2,021,208,518

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2021208518...
Checkpoint 2021208518 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 85,799.86848
Policy Entropy: 2.33786
Value Function Loss: 0.01536

Mean KL Divergence: 0.00723
SB3 Clip Fraction: 0.06521
Policy Update Magnitude: 0.28971
Value Function Update Magnitude: 0.25777

Collected Steps per Second: 21,332.76407
Overall Steps per Second: 10,663.04701

Timestep Collection Time: 2.34409
Timestep Consumption Time: 2.34556
PPO Batch Consumption Time: 0.27733
Total Iteration Time: 4.68965

Cumulative Model Updates: 242,282
Cumulative Timesteps: 2,021,258,524

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63,074.89358
Policy Entropy: 2.34288
Value Function Loss: 0.01676

Mean KL Divergence: 0.00738
SB3 Clip Fraction: 0.06988
Policy Update Magnitude: 0.29464
Value Function Update Magnitude: 0.27319

Collected Steps per Second: 21,220.99612
Overall Steps per Second: 10,455.03813

Timestep Collection Time: 2.35663
Timestep Consumption Time: 2.42671
PPO Batch Consumption Time: 0.29365
Total Iteration Time: 4.78334

Cumulative Model Updates: 242,288
Cumulative Timesteps: 2,021,308,534

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2021308534...
Checkpoint 2021308534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 60,277.98225
Policy Entropy: 2.31234
Value Function Loss: 0.01721

Mean KL Divergence: 0.00733
SB3 Clip Fraction: 0.06672
Policy Update Magnitude: 0.29814
Value Function Update Magnitude: 0.30316

Collected Steps per Second: 20,748.11281
Overall Steps per Second: 10,516.52233

Timestep Collection Time: 2.41034
Timestep Consumption Time: 2.34503
PPO Batch Consumption Time: 0.27890
Total Iteration Time: 4.75537

Cumulative Model Updates: 242,294
Cumulative Timesteps: 2,021,358,544

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55,992.95572
Policy Entropy: 2.31229
Value Function Loss: 0.01592

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.08387
Policy Update Magnitude: 0.29963
Value Function Update Magnitude: 0.31174

Collected Steps per Second: 21,012.43319
Overall Steps per Second: 10,464.95076

Timestep Collection Time: 2.38192
Timestep Consumption Time: 2.40071
PPO Batch Consumption Time: 0.27894
Total Iteration Time: 4.78263

Cumulative Model Updates: 242,300
Cumulative Timesteps: 2,021,408,594

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 2021408594...
Checkpoint 2021408594 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 69,043.27211
Policy Entropy: 2.32714
Value Function Loss: 0.01752

Mean KL Divergence: 0.01329
SB3 Clip Fraction: 0.10637
Policy Update Magnitude: 0.28941
Value Function Update Magnitude: 0.30996

Collected Steps per Second: 21,310.90658
Overall Steps per Second: 10,364.45338

Timestep Collection Time: 2.34762
Timestep Consumption Time: 2.47945
PPO Batch Consumption Time: 0.29415
Total Iteration Time: 4.82708

Cumulative Model Updates: 242,306
Cumulative Timesteps: 2,021,458,624

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57,437.80003
Policy Entropy: 2.35068
Value Function Loss: 0.01871

Mean KL Divergence: 0.01699
SB3 Clip Fraction: 0.12565
Policy Update Magnitude: 0.28459
Value Function Update Magnitude: 0.32042

Collected Steps per Second: 21,823.52643
Overall Steps per Second: 10,435.91087

Timestep Collection Time: 2.29166
Timestep Consumption Time: 2.50064
PPO Batch Consumption Time: 0.29357
Total Iteration Time: 4.79230

Cumulative Model Updates: 242,312
Cumulative Timesteps: 2,021,508,636

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2021508636...
Checkpoint 2021508636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48,953.80089
Policy Entropy: 2.37792
Value Function Loss: 0.01786

Mean KL Divergence: 0.01522
SB3 Clip Fraction: 0.11675
Policy Update Magnitude: 0.29355
Value Function Update Magnitude: 0.31365

Collected Steps per Second: 21,812.76689
Overall Steps per Second: 10,521.77967

Timestep Collection Time: 2.29279
Timestep Consumption Time: 2.46040
PPO Batch Consumption Time: 0.27970
Total Iteration Time: 4.75319

Cumulative Model Updates: 242,318
Cumulative Timesteps: 2,021,558,648

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45,057.50622
Policy Entropy: 2.36143
Value Function Loss: 0.01729

Mean KL Divergence: 0.01296
SB3 Clip Fraction: 0.10396
Policy Update Magnitude: 0.28735
Value Function Update Magnitude: 0.30830

Collected Steps per Second: 22,055.18946
Overall Steps per Second: 10,463.37936

Timestep Collection Time: 2.26876
Timestep Consumption Time: 2.51344
PPO Batch Consumption Time: 0.28963
Total Iteration Time: 4.78220

Cumulative Model Updates: 242,324
Cumulative Timesteps: 2,021,608,686

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 2021608686...
Checkpoint 2021608686 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 51,759.20389
Policy Entropy: 2.36176
Value Function Loss: 0.01572

Mean KL Divergence: 0.02011
SB3 Clip Fraction: 0.12630
Policy Update Magnitude: 0.27812
Value Function Update Magnitude: 0.29887

Collected Steps per Second: 21,977.44836
Overall Steps per Second: 10,603.47753

Timestep Collection Time: 2.27588
Timestep Consumption Time: 2.44125
PPO Batch Consumption Time: 0.27940
Total Iteration Time: 4.71713

Cumulative Model Updates: 242,330
Cumulative Timesteps: 2,021,658,704

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57,755.22439
Policy Entropy: 2.34412
Value Function Loss: 0.01842

Mean KL Divergence: 0.02098
SB3 Clip Fraction: 0.14657
Policy Update Magnitude: 0.25616
Value Function Update Magnitude: 0.27747

Collected Steps per Second: 22,000.26648
Overall Steps per Second: 10,502.89536

Timestep Collection Time: 2.27334
Timestep Consumption Time: 2.48859
PPO Batch Consumption Time: 0.28784
Total Iteration Time: 4.76193

Cumulative Model Updates: 242,336
Cumulative Timesteps: 2,021,708,718

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2021708718...
Checkpoint 2021708718 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 57,755.22439
Policy Entropy: 2.33413
Value Function Loss: 0.01668

Mean KL Divergence: 0.01825
SB3 Clip Fraction: 0.12636
Policy Update Magnitude: 0.26447
Value Function Update Magnitude: 0.23661

Collected Steps per Second: 21,895.13678
Overall Steps per Second: 10,606.80053

Timestep Collection Time: 2.28416
Timestep Consumption Time: 2.43093
PPO Batch Consumption Time: 0.27919
Total Iteration Time: 4.71509

Cumulative Model Updates: 242,342
Cumulative Timesteps: 2,021,758,730

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 73,235.47205
Policy Entropy: 2.33248
Value Function Loss: 0.01732

Mean KL Divergence: 0.01568
SB3 Clip Fraction: 0.11749
Policy Update Magnitude: 0.28062
Value Function Update Magnitude: 0.21833

Collected Steps per Second: 21,771.98041
Overall Steps per Second: 10,491.53049

Timestep Collection Time: 2.29681
Timestep Consumption Time: 2.46952
PPO Batch Consumption Time: 0.28539
Total Iteration Time: 4.76632

Cumulative Model Updates: 242,348
Cumulative Timesteps: 2,021,808,736

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2021808736...
Checkpoint 2021808736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84,183.00063
Policy Entropy: 2.33115
Value Function Loss: 0.01452

Mean KL Divergence: 0.01338
SB3 Clip Fraction: 0.10901
Policy Update Magnitude: 0.29197
Value Function Update Magnitude: 0.26217

Collected Steps per Second: 21,623.54873
Overall Steps per Second: 10,575.33283

Timestep Collection Time: 2.31239
Timestep Consumption Time: 2.41579
PPO Batch Consumption Time: 0.27929
Total Iteration Time: 4.72817

Cumulative Model Updates: 242,354
Cumulative Timesteps: 2,021,858,738

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78,473.66511
Policy Entropy: 2.33134
Value Function Loss: 0.01585

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.09045
Policy Update Magnitude: 0.29770
Value Function Update Magnitude: 0.31474

Collected Steps per Second: 21,431.30508
Overall Steps per Second: 10,479.08777

Timestep Collection Time: 2.33388
Timestep Consumption Time: 2.43925
PPO Batch Consumption Time: 0.27936
Total Iteration Time: 4.77313

Cumulative Model Updates: 242,360
Cumulative Timesteps: 2,021,908,756

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2021908756...
Checkpoint 2021908756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 56,314.28470
Policy Entropy: 2.31519
Value Function Loss: 0.01837

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.08056
Policy Update Magnitude: 0.31408
Value Function Update Magnitude: 0.33247

Collected Steps per Second: 21,416.81065
Overall Steps per Second: 10,330.68135

Timestep Collection Time: 2.33555
Timestep Consumption Time: 2.50634
PPO Batch Consumption Time: 0.29362
Total Iteration Time: 4.84189

Cumulative Model Updates: 242,366
Cumulative Timesteps: 2,021,958,776

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42,726.97792
Policy Entropy: 2.31309
Value Function Loss: 0.01985

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.08617
Policy Update Magnitude: 0.32218
Value Function Update Magnitude: 0.34859

Collected Steps per Second: 21,308.64391
Overall Steps per Second: 10,374.03632

Timestep Collection Time: 2.34806
Timestep Consumption Time: 2.47494
PPO Batch Consumption Time: 0.28602
Total Iteration Time: 4.82300

Cumulative Model Updates: 242,372
Cumulative Timesteps: 2,022,008,810

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 2022008810...
Checkpoint 2022008810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 81,233.68236
Policy Entropy: 2.32430
Value Function Loss: 0.01921

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.07980
Policy Update Magnitude: 0.32684
Value Function Update Magnitude: 0.36412

Collected Steps per Second: 21,324.22172
Overall Steps per Second: 10,323.15978

Timestep Collection Time: 2.34531
Timestep Consumption Time: 2.49933
PPO Batch Consumption Time: 0.29193
Total Iteration Time: 4.84464

Cumulative Model Updates: 242,378
Cumulative Timesteps: 2,022,058,822

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65,944.76112
Policy Entropy: 2.33164
Value Function Loss: 0.01787

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.07995
Policy Update Magnitude: 0.31898
Value Function Update Magnitude: 0.36118

Collected Steps per Second: 21,520.61612
Overall Steps per Second: 10,341.64131

Timestep Collection Time: 2.32456
Timestep Consumption Time: 2.51277
PPO Batch Consumption Time: 0.28860
Total Iteration Time: 4.83734

Cumulative Model Updates: 242,384
Cumulative Timesteps: 2,022,108,848

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2022108848...
Checkpoint 2022108848 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 51,189.09043
Policy Entropy: 2.33336
Value Function Loss: 0.01731

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.07770
Policy Update Magnitude: 0.30926
Value Function Update Magnitude: 0.33202

Collected Steps per Second: 22,165.55249
Overall Steps per Second: 10,569.91293

Timestep Collection Time: 2.25611
Timestep Consumption Time: 2.47505
PPO Batch Consumption Time: 0.27932
Total Iteration Time: 4.73116

Cumulative Model Updates: 242,390
Cumulative Timesteps: 2,022,158,856

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70,884.94732
Policy Entropy: 2.33711
Value Function Loss: 0.01651

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.07812
Policy Update Magnitude: 0.29731
Value Function Update Magnitude: 0.31964

Collected Steps per Second: 21,312.15677
Overall Steps per Second: 10,473.93630

Timestep Collection Time: 2.34730
Timestep Consumption Time: 2.42894
PPO Batch Consumption Time: 0.28771
Total Iteration Time: 4.77624

Cumulative Model Updates: 242,396
Cumulative Timesteps: 2,022,208,882

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2022208882...
Checkpoint 2022208882 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 59,892.09952
Policy Entropy: 2.33799
Value Function Loss: 0.01465

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.07532
Policy Update Magnitude: 0.28496
Value Function Update Magnitude: 0.31117

Collected Steps per Second: 21,220.67379
Overall Steps per Second: 10,607.51405

Timestep Collection Time: 2.35648
Timestep Consumption Time: 2.35773
PPO Batch Consumption Time: 0.27932
Total Iteration Time: 4.71421

Cumulative Model Updates: 242,402
Cumulative Timesteps: 2,022,258,888

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 71,056.55876
Policy Entropy: 2.34332
Value Function Loss: 0.01380

Mean KL Divergence: 0.00599
SB3 Clip Fraction: 0.05926
Policy Update Magnitude: 0.27448
Value Function Update Magnitude: 0.28738

Collected Steps per Second: 21,561.50185
Overall Steps per Second: 10,515.92332

Timestep Collection Time: 2.31923
Timestep Consumption Time: 2.43604
PPO Batch Consumption Time: 0.29147
Total Iteration Time: 4.75526

Cumulative Model Updates: 242,408
Cumulative Timesteps: 2,022,308,894

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2022308894...
Checkpoint 2022308894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 101,917.60593
Policy Entropy: 2.33003
Value Function Loss: 0.01431

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.08079
Policy Update Magnitude: 0.28285
Value Function Update Magnitude: 0.27919

Collected Steps per Second: 21,531.58321
Overall Steps per Second: 10,569.98938

Timestep Collection Time: 2.32328
Timestep Consumption Time: 2.40936
PPO Batch Consumption Time: 0.27880
Total Iteration Time: 4.73264

Cumulative Model Updates: 242,414
Cumulative Timesteps: 2,022,358,918

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 100,777.96985
Policy Entropy: 2.31810
Value Function Loss: 0.01541

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.08231
Policy Update Magnitude: 0.29582
Value Function Update Magnitude: 0.30681

Collected Steps per Second: 22,062.88358
Overall Steps per Second: 10,506.71777

Timestep Collection Time: 2.26725
Timestep Consumption Time: 2.49371
PPO Batch Consumption Time: 0.29203
Total Iteration Time: 4.76095

Cumulative Model Updates: 242,420
Cumulative Timesteps: 2,022,408,940

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2022408940...
Checkpoint 2022408940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 66,715.77296
Policy Entropy: 2.32245
Value Function Loss: 0.01570

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.07886
Policy Update Magnitude: 0.30087
Value Function Update Magnitude: 0.33507

Collected Steps per Second: 21,768.79533
Overall Steps per Second: 10,651.05868

Timestep Collection Time: 2.29843
Timestep Consumption Time: 2.39913
PPO Batch Consumption Time: 0.27851
Total Iteration Time: 4.69756

Cumulative Model Updates: 242,426
Cumulative Timesteps: 2,022,458,974

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68,402.78578
Policy Entropy: 2.33794
Value Function Loss: 0.01551

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.07622
Policy Update Magnitude: 0.30509
Value Function Update Magnitude: 0.32447

Collected Steps per Second: 21,620.32596
Overall Steps per Second: 10,533.67429

Timestep Collection Time: 2.31292
Timestep Consumption Time: 2.43434
PPO Batch Consumption Time: 0.27784
Total Iteration Time: 4.74725

Cumulative Model Updates: 242,432
Cumulative Timesteps: 2,022,508,980

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2022508980...
Checkpoint 2022508980 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 70,736.64369
Policy Entropy: 2.35641
Value Function Loss: 0.01398

Mean KL Divergence: 0.00699
SB3 Clip Fraction: 0.06565
Policy Update Magnitude: 0.29299
Value Function Update Magnitude: 0.31873

Collected Steps per Second: 21,424.62212
Overall Steps per Second: 10,504.00751

Timestep Collection Time: 2.33404
Timestep Consumption Time: 2.42662
PPO Batch Consumption Time: 0.27841
Total Iteration Time: 4.76066

Cumulative Model Updates: 242,438
Cumulative Timesteps: 2,022,558,986

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70,736.64369
Policy Entropy: 2.35223
Value Function Loss: 0.01340

Mean KL Divergence: 0.00703
SB3 Clip Fraction: 0.06684
Policy Update Magnitude: 0.28205
Value Function Update Magnitude: 0.29528

Collected Steps per Second: 21,654.59007
Overall Steps per Second: 10,505.15816

Timestep Collection Time: 2.31009
Timestep Consumption Time: 2.45176
PPO Batch Consumption Time: 0.27892
Total Iteration Time: 4.76185

Cumulative Model Updates: 242,444
Cumulative Timesteps: 2,022,609,010

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2022609010...
Checkpoint 2022609010 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 83,477.87740
Policy Entropy: 2.32896
Value Function Loss: 0.01376

Mean KL Divergence: 0.00650
SB3 Clip Fraction: 0.06278
Policy Update Magnitude: 0.27671
Value Function Update Magnitude: 0.26434

Collected Steps per Second: 21,247.63409
Overall Steps per Second: 10,278.06527

Timestep Collection Time: 2.35396
Timestep Consumption Time: 2.51233
PPO Batch Consumption Time: 0.29330
Total Iteration Time: 4.86629

Cumulative Model Updates: 242,450
Cumulative Timesteps: 2,022,659,026

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65,078.77963
Policy Entropy: 2.30297
Value Function Loss: 0.01691

Mean KL Divergence: 0.00643
SB3 Clip Fraction: 0.06305
Policy Update Magnitude: 0.29261
Value Function Update Magnitude: 0.28616

Collected Steps per Second: 22,167.26673
Overall Steps per Second: 10,446.66791

Timestep Collection Time: 2.25738
Timestep Consumption Time: 2.53266
PPO Batch Consumption Time: 0.29336
Total Iteration Time: 4.79004

Cumulative Model Updates: 242,456
Cumulative Timesteps: 2,022,709,066

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 2022709066...
Checkpoint 2022709066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 75,683.93521
Policy Entropy: 2.31645
Value Function Loss: 0.01935

Mean KL Divergence: 0.00691
SB3 Clip Fraction: 0.06913
Policy Update Magnitude: 0.31011
Value Function Update Magnitude: 0.31129

Collected Steps per Second: 21,548.58308
Overall Steps per Second: 10,319.02387

Timestep Collection Time: 2.32117
Timestep Consumption Time: 2.52599
PPO Batch Consumption Time: 0.29068
Total Iteration Time: 4.84716

Cumulative Model Updates: 242,462
Cumulative Timesteps: 2,022,759,084

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75,683.93521
Policy Entropy: 2.31343
Value Function Loss: 0.01735

Mean KL Divergence: 0.00757
SB3 Clip Fraction: 0.07202
Policy Update Magnitude: 0.31008
Value Function Update Magnitude: 0.33314

Collected Steps per Second: 22,560.75120
Overall Steps per Second: 10,730.39500

Timestep Collection Time: 2.21828
Timestep Consumption Time: 2.44567
PPO Batch Consumption Time: 0.27982
Total Iteration Time: 4.66395

Cumulative Model Updates: 242,468
Cumulative Timesteps: 2,022,809,130

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 2022809130...
Checkpoint 2022809130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 62,333.60573
Policy Entropy: 2.30182
Value Function Loss: 0.02136

Mean KL Divergence: 0.00720
SB3 Clip Fraction: 0.06874
Policy Update Magnitude: 0.31522
Value Function Update Magnitude: 0.32358

Collected Steps per Second: 21,716.99627
Overall Steps per Second: 10,573.18583

Timestep Collection Time: 2.30354
Timestep Consumption Time: 2.42786
PPO Batch Consumption Time: 0.27847
Total Iteration Time: 4.73140

Cumulative Model Updates: 242,474
Cumulative Timesteps: 2,022,859,156

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,932.50509
Policy Entropy: 2.29037
Value Function Loss: 0.01968

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.07409
Policy Update Magnitude: 0.32550
Value Function Update Magnitude: 0.32954

Collected Steps per Second: 21,974.66520
Overall Steps per Second: 10,511.08204

Timestep Collection Time: 2.27717
Timestep Consumption Time: 2.48352
PPO Batch Consumption Time: 0.28790
Total Iteration Time: 4.76069

Cumulative Model Updates: 242,480
Cumulative Timesteps: 2,022,909,196

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 2022909196...
Checkpoint 2022909196 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,469.50617
Policy Entropy: 2.29596
Value Function Loss: 0.01916

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.07891
Policy Update Magnitude: 0.31995
Value Function Update Magnitude: 0.33416

Collected Steps per Second: 21,597.46608
Overall Steps per Second: 10,565.31359

Timestep Collection Time: 2.31509
Timestep Consumption Time: 2.41738
PPO Batch Consumption Time: 0.27903
Total Iteration Time: 4.73247

Cumulative Model Updates: 242,486
Cumulative Timesteps: 2,022,959,196

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,721.30281
Policy Entropy: 2.32080
Value Function Loss: 0.01449

Mean KL Divergence: 0.00733
SB3 Clip Fraction: 0.06759
Policy Update Magnitude: 0.30376
Value Function Update Magnitude: 0.31363

Collected Steps per Second: 22,433.75078
Overall Steps per Second: 10,585.29631

Timestep Collection Time: 2.23021
Timestep Consumption Time: 2.49635
PPO Batch Consumption Time: 0.29313
Total Iteration Time: 4.72656

Cumulative Model Updates: 242,492
Cumulative Timesteps: 2,023,009,228

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2023009228...
Checkpoint 2023009228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,186.12975
Policy Entropy: 2.32651
Value Function Loss: 0.01365

Mean KL Divergence: 0.00669
SB3 Clip Fraction: 0.06408
Policy Update Magnitude: 0.28612
Value Function Update Magnitude: 0.29514

Collected Steps per Second: 20,295.64871
Overall Steps per Second: 10,218.58530

Timestep Collection Time: 2.46437
Timestep Consumption Time: 2.43024
PPO Batch Consumption Time: 0.29419
Total Iteration Time: 4.89461

Cumulative Model Updates: 242,498
Cumulative Timesteps: 2,023,059,244

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,186.12975
Policy Entropy: 2.33972
Value Function Loss: 0.01372

Mean KL Divergence: 0.00612
SB3 Clip Fraction: 0.06014
Policy Update Magnitude: 0.28821
Value Function Update Magnitude: 0.26824

Collected Steps per Second: 21,131.69271
Overall Steps per Second: 10,437.10970

Timestep Collection Time: 2.36848
Timestep Consumption Time: 2.42691
PPO Batch Consumption Time: 0.29327
Total Iteration Time: 4.79539

Cumulative Model Updates: 242,504
Cumulative Timesteps: 2,023,109,294

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 2023109294...
Checkpoint 2023109294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,186.12975
Policy Entropy: 2.34289
Value Function Loss: 0.01323

Mean KL Divergence: 0.00636
SB3 Clip Fraction: 0.06224
Policy Update Magnitude: 0.28829
Value Function Update Magnitude: 0.26147

Collected Steps per Second: 20,653.66517
Overall Steps per Second: 10,492.96499

Timestep Collection Time: 2.42136
Timestep Consumption Time: 2.34469
PPO Batch Consumption Time: 0.27864
Total Iteration Time: 4.76605

Cumulative Model Updates: 242,510
Cumulative Timesteps: 2,023,159,304

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,186.12975
Policy Entropy: 2.34912
Value Function Loss: 0.01225

Mean KL Divergence: 0.00646
SB3 Clip Fraction: 0.05887
Policy Update Magnitude: 0.27725
Value Function Update Magnitude: 0.24571

Collected Steps per Second: 20,947.00230
Overall Steps per Second: 10,304.44137

Timestep Collection Time: 2.38831
Timestep Consumption Time: 2.46668
PPO Batch Consumption Time: 0.29015
Total Iteration Time: 4.85499

Cumulative Model Updates: 242,516
Cumulative Timesteps: 2,023,209,332

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2023209332...
Checkpoint 2023209332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 50,282.83105
Policy Entropy: 2.34797
Value Function Loss: 0.01151

Mean KL Divergence: 0.00596
SB3 Clip Fraction: 0.05536
Policy Update Magnitude: 0.26735
Value Function Update Magnitude: 0.22729

Collected Steps per Second: 21,791.43735
Overall Steps per Second: 10,454.58207

Timestep Collection Time: 2.29586
Timestep Consumption Time: 2.48961
PPO Batch Consumption Time: 0.28991
Total Iteration Time: 4.78546

Cumulative Model Updates: 242,522
Cumulative Timesteps: 2,023,259,362

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89,315.86207
Policy Entropy: 2.34145
Value Function Loss: 0.01455

Mean KL Divergence: 0.00617
SB3 Clip Fraction: 0.06119
Policy Update Magnitude: 0.27464
Value Function Update Magnitude: 0.22640

Collected Steps per Second: 22,158.56725
Overall Steps per Second: 10,514.04049

Timestep Collection Time: 2.25773
Timestep Consumption Time: 2.50048
PPO Batch Consumption Time: 0.29253
Total Iteration Time: 4.75821

Cumulative Model Updates: 242,528
Cumulative Timesteps: 2,023,309,390

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2023309390...
Checkpoint 2023309390 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 100,164.56686
Policy Entropy: 2.33862
Value Function Loss: 0.01490

Mean KL Divergence: 0.00710
SB3 Clip Fraction: 0.06847
Policy Update Magnitude: 0.28094
Value Function Update Magnitude: 0.25455

Collected Steps per Second: 21,735.96179
Overall Steps per Second: 10,539.96103

Timestep Collection Time: 2.30245
Timestep Consumption Time: 2.44576
PPO Batch Consumption Time: 0.27957
Total Iteration Time: 4.74821

Cumulative Model Updates: 242,534
Cumulative Timesteps: 2,023,359,436

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83,237.90457
Policy Entropy: 2.34044
Value Function Loss: 0.01466

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.07985
Policy Update Magnitude: 0.28341
Value Function Update Magnitude: 0.27632

Collected Steps per Second: 22,180.67423
Overall Steps per Second: 10,481.11349

Timestep Collection Time: 2.25512
Timestep Consumption Time: 2.51728
PPO Batch Consumption Time: 0.29401
Total Iteration Time: 4.77239

Cumulative Model Updates: 242,540
Cumulative Timesteps: 2,023,409,456

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2023409456...
Checkpoint 2023409456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 151,288.60034
Policy Entropy: 2.33439
Value Function Loss: 0.01501

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.07933
Policy Update Magnitude: 0.27958
Value Function Update Magnitude: 0.26102

Collected Steps per Second: 21,832.93249
Overall Steps per Second: 10,603.09739

Timestep Collection Time: 2.29048
Timestep Consumption Time: 2.42587
PPO Batch Consumption Time: 0.27850
Total Iteration Time: 4.71636

Cumulative Model Updates: 242,546
Cumulative Timesteps: 2,023,459,464

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67,879.65275
Policy Entropy: 2.33346
Value Function Loss: 0.01784

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.07736
Policy Update Magnitude: 0.29398
Value Function Update Magnitude: 0.27083

Collected Steps per Second: 22,374.35035
Overall Steps per Second: 10,512.30144

Timestep Collection Time: 2.23586
Timestep Consumption Time: 2.52294
PPO Batch Consumption Time: 0.29406
Total Iteration Time: 4.75881

Cumulative Model Updates: 242,552
Cumulative Timesteps: 2,023,509,490

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2023509490...
Checkpoint 2023509490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 70,699.27544
Policy Entropy: 2.34070
Value Function Loss: 0.02004

Mean KL Divergence: 0.01101
SB3 Clip Fraction: 0.09712
Policy Update Magnitude: 0.31116
Value Function Update Magnitude: 0.28124

Collected Steps per Second: 21,786.55498
Overall Steps per Second: 10,577.94027

Timestep Collection Time: 2.29683
Timestep Consumption Time: 2.43377
PPO Batch Consumption Time: 0.27899
Total Iteration Time: 4.73060

Cumulative Model Updates: 242,558
Cumulative Timesteps: 2,023,559,530

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 116,579.50978
Policy Entropy: 2.36357
Value Function Loss: 0.02011

Mean KL Divergence: 0.01453
SB3 Clip Fraction: 0.11685
Policy Update Magnitude: 0.30782
Value Function Update Magnitude: 0.31086

Collected Steps per Second: 21,509.69275
Overall Steps per Second: 10,517.98888

Timestep Collection Time: 2.32621
Timestep Consumption Time: 2.43098
PPO Batch Consumption Time: 0.27853
Total Iteration Time: 4.75718

Cumulative Model Updates: 242,564
Cumulative Timesteps: 2,023,609,566

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 2023609566...
Checkpoint 2023609566 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 133,379.32877
Policy Entropy: 2.37452
Value Function Loss: 0.01933

Mean KL Divergence: 0.01303
SB3 Clip Fraction: 0.11248
Policy Update Magnitude: 0.29917
Value Function Update Magnitude: 0.31253

Collected Steps per Second: 21,086.94320
Overall Steps per Second: 10,240.30415

Timestep Collection Time: 2.37151
Timestep Consumption Time: 2.51193
PPO Batch Consumption Time: 0.29364
Total Iteration Time: 4.88345

Cumulative Model Updates: 242,570
Cumulative Timesteps: 2,023,659,574

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 117,455.19399
Policy Entropy: 2.38181
Value Function Loss: 0.01833

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.09075
Policy Update Magnitude: 0.30927
Value Function Update Magnitude: 0.30765

Collected Steps per Second: 21,901.10146
Overall Steps per Second: 10,447.59547

Timestep Collection Time: 2.28299
Timestep Consumption Time: 2.50280
PPO Batch Consumption Time: 0.29232
Total Iteration Time: 4.78579

Cumulative Model Updates: 242,576
Cumulative Timesteps: 2,023,709,574

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2023709574...
Checkpoint 2023709574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 99,202.37248
Policy Entropy: 2.37911
Value Function Loss: 0.01913

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.07622
Policy Update Magnitude: 0.32166
Value Function Update Magnitude: 0.29994

Collected Steps per Second: 21,498.82284
Overall Steps per Second: 10,514.16397

Timestep Collection Time: 2.32692
Timestep Consumption Time: 2.43104
PPO Batch Consumption Time: 0.27868
Total Iteration Time: 4.75796

Cumulative Model Updates: 242,582
Cumulative Timesteps: 2,023,759,600

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99,202.37248
Policy Entropy: 2.38081
Value Function Loss: 0.01681

Mean KL Divergence: 0.00711
SB3 Clip Fraction: 0.06499
Policy Update Magnitude: 0.31516
Value Function Update Magnitude: 0.26704

Collected Steps per Second: 21,363.07268
Overall Steps per Second: 10,511.43284

Timestep Collection Time: 2.34152
Timestep Consumption Time: 2.41730
PPO Batch Consumption Time: 0.28823
Total Iteration Time: 4.75882

Cumulative Model Updates: 242,588
Cumulative Timesteps: 2,023,809,622

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2023809622...
Checkpoint 2023809622 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 90,863.33712
Policy Entropy: 2.37996
Value Function Loss: 0.01974

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.07511
Policy Update Magnitude: 0.31328
Value Function Update Magnitude: 0.24757

Collected Steps per Second: 21,042.74462
Overall Steps per Second: 10,383.02695

Timestep Collection Time: 2.37783
Timestep Consumption Time: 2.44119
PPO Batch Consumption Time: 0.29064
Total Iteration Time: 4.81902

Cumulative Model Updates: 242,594
Cumulative Timesteps: 2,023,859,658

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88,713.54936
Policy Entropy: 2.36623
Value Function Loss: 0.01789

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.07234
Policy Update Magnitude: 0.30838
Value Function Update Magnitude: 0.26190

Collected Steps per Second: 21,800.18623
Overall Steps per Second: 10,714.47234

Timestep Collection Time: 2.29402
Timestep Consumption Time: 2.37350
PPO Batch Consumption Time: 0.27973
Total Iteration Time: 4.66752

Cumulative Model Updates: 242,600
Cumulative Timesteps: 2,023,909,668

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2023909668...
Checkpoint 2023909668 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 82,440.77986
Policy Entropy: 2.38200
Value Function Loss: 0.01752

Mean KL Divergence: 0.00722
SB3 Clip Fraction: 0.06740
Policy Update Magnitude: 0.29504
Value Function Update Magnitude: 0.27004

Collected Steps per Second: 21,091.46654
Overall Steps per Second: 10,322.30260

Timestep Collection Time: 2.37290
Timestep Consumption Time: 2.47563
PPO Batch Consumption Time: 0.29277
Total Iteration Time: 4.84853

Cumulative Model Updates: 242,606
Cumulative Timesteps: 2,023,959,716

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 102,728.57384
Policy Entropy: 2.37751
Value Function Loss: 0.01437

Mean KL Divergence: 0.00685
SB3 Clip Fraction: 0.06600
Policy Update Magnitude: 0.28586
Value Function Update Magnitude: 0.23705

Collected Steps per Second: 22,083.88459
Overall Steps per Second: 10,709.18287

Timestep Collection Time: 2.26491
Timestep Consumption Time: 2.40566
PPO Batch Consumption Time: 0.27915
Total Iteration Time: 4.67057

Cumulative Model Updates: 242,612
Cumulative Timesteps: 2,024,009,734

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2024009734...
Checkpoint 2024009734 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 80,093.64590
Policy Entropy: 2.36616
Value Function Loss: 0.01622

Mean KL Divergence: 0.00646
SB3 Clip Fraction: 0.06297
Policy Update Magnitude: 0.29264
Value Function Update Magnitude: 0.23455

Collected Steps per Second: 21,777.95887
Overall Steps per Second: 10,659.47721

Timestep Collection Time: 2.29673
Timestep Consumption Time: 2.39562
PPO Batch Consumption Time: 0.27868
Total Iteration Time: 4.69235

Cumulative Model Updates: 242,618
Cumulative Timesteps: 2,024,059,752

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 114,644.39793
Policy Entropy: 2.35788
Value Function Loss: 0.01669

Mean KL Divergence: 0.00689
SB3 Clip Fraction: 0.06370
Policy Update Magnitude: 0.30409
Value Function Update Magnitude: 0.23500

Collected Steps per Second: 22,146.87498
Overall Steps per Second: 10,487.98907

Timestep Collection Time: 2.25820
Timestep Consumption Time: 2.51031
PPO Batch Consumption Time: 0.29136
Total Iteration Time: 4.76850

Cumulative Model Updates: 242,624
Cumulative Timesteps: 2,024,109,764

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2024109764...
Checkpoint 2024109764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89,199.84126
Policy Entropy: 2.35147
Value Function Loss: 0.01582

Mean KL Divergence: 0.00626
SB3 Clip Fraction: 0.05612
Policy Update Magnitude: 0.29972
Value Function Update Magnitude: 0.28195

Collected Steps per Second: 21,564.72131
Overall Steps per Second: 10,417.05507

Timestep Collection Time: 2.31897
Timestep Consumption Time: 2.48162
PPO Batch Consumption Time: 0.28881
Total Iteration Time: 4.80059

Cumulative Model Updates: 242,630
Cumulative Timesteps: 2,024,159,772

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61,086.08541
Policy Entropy: 2.38626
Value Function Loss: 0.01408

Mean KL Divergence: 0.00665
SB3 Clip Fraction: 0.06219
Policy Update Magnitude: 0.28928
Value Function Update Magnitude: 0.29388

Collected Steps per Second: 21,904.75794
Overall Steps per Second: 10,609.56062

Timestep Collection Time: 2.28453
Timestep Consumption Time: 2.43216
PPO Batch Consumption Time: 0.27944
Total Iteration Time: 4.71669

Cumulative Model Updates: 242,636
Cumulative Timesteps: 2,024,209,814

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 2024209814...
Checkpoint 2024209814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 74,585.25943
Policy Entropy: 2.38764
Value Function Loss: 0.01608

Mean KL Divergence: 0.00667
SB3 Clip Fraction: 0.06287
Policy Update Magnitude: 0.28749
Value Function Update Magnitude: 0.29699

Collected Steps per Second: 20,898.77949
Overall Steps per Second: 10,370.39813

Timestep Collection Time: 2.39440
Timestep Consumption Time: 2.43087
PPO Batch Consumption Time: 0.27832
Total Iteration Time: 4.82527

Cumulative Model Updates: 242,642
Cumulative Timesteps: 2,024,259,854

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60,946.76790
Policy Entropy: 2.38479
Value Function Loss: 0.01655

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.07421
Policy Update Magnitude: 0.28414
Value Function Update Magnitude: 0.31459

Collected Steps per Second: 21,331.36411
Overall Steps per Second: 10,335.93077

Timestep Collection Time: 2.34434
Timestep Consumption Time: 2.49393
PPO Batch Consumption Time: 0.28885
Total Iteration Time: 4.83827

Cumulative Model Updates: 242,648
Cumulative Timesteps: 2,024,309,862

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2024309862...
Checkpoint 2024309862 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 78,700.01399
Policy Entropy: 2.38013
Value Function Loss: 0.01652

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.08002
Policy Update Magnitude: 0.28612
Value Function Update Magnitude: 0.28883

Collected Steps per Second: 21,401.72714
Overall Steps per Second: 10,350.82695

Timestep Collection Time: 2.33747
Timestep Consumption Time: 2.49557
PPO Batch Consumption Time: 0.29295
Total Iteration Time: 4.83304

Cumulative Model Updates: 242,654
Cumulative Timesteps: 2,024,359,888

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85,607.54718
Policy Entropy: 2.37061
Value Function Loss: 0.01690

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.08922
Policy Update Magnitude: 0.29102
Value Function Update Magnitude: 0.26695

Collected Steps per Second: 21,067.78288
Overall Steps per Second: 10,388.59533

Timestep Collection Time: 2.37367
Timestep Consumption Time: 2.44007
PPO Batch Consumption Time: 0.29326
Total Iteration Time: 4.81374

Cumulative Model Updates: 242,660
Cumulative Timesteps: 2,024,409,896

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2024409896...
Checkpoint 2024409896 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 71,567.83017
Policy Entropy: 2.37369
Value Function Loss: 0.01761

Mean KL Divergence: 0.00718
SB3 Clip Fraction: 0.06888
Policy Update Magnitude: 0.29993
Value Function Update Magnitude: 0.29281

Collected Steps per Second: 21,340.16382
Overall Steps per Second: 10,559.42259

Timestep Collection Time: 2.34525
Timestep Consumption Time: 2.39440
PPO Batch Consumption Time: 0.27861
Total Iteration Time: 4.73965

Cumulative Model Updates: 242,666
Cumulative Timesteps: 2,024,459,944

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 74,278.42043
Policy Entropy: 2.36970
Value Function Loss: 0.01659

Mean KL Divergence: 0.00712
SB3 Clip Fraction: 0.06993
Policy Update Magnitude: 0.29568
Value Function Update Magnitude: 0.31836

Collected Steps per Second: 19,283.53154
Overall Steps per Second: 10,002.53154

Timestep Collection Time: 2.59320
Timestep Consumption Time: 2.40614
PPO Batch Consumption Time: 0.27874
Total Iteration Time: 4.99933

Cumulative Model Updates: 242,672
Cumulative Timesteps: 2,024,509,950

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2024509950...
Checkpoint 2024509950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 62,875.70070
Policy Entropy: 2.37826
Value Function Loss: 0.01532

Mean KL Divergence: 0.00714
SB3 Clip Fraction: 0.07009
Policy Update Magnitude: 0.29175
Value Function Update Magnitude: 0.29105

Collected Steps per Second: 21,106.92126
Overall Steps per Second: 10,265.01109

Timestep Collection Time: 2.37060
Timestep Consumption Time: 2.50383
PPO Batch Consumption Time: 0.29336
Total Iteration Time: 4.87442

Cumulative Model Updates: 242,678
Cumulative Timesteps: 2,024,559,986

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 72,490.69404
Policy Entropy: 2.36534
Value Function Loss: 0.01845

Mean KL Divergence: 0.00657
SB3 Clip Fraction: 0.06281
Policy Update Magnitude: 0.30195
Value Function Update Magnitude: 0.27181

Collected Steps per Second: 21,883.75159
Overall Steps per Second: 10,487.92403

Timestep Collection Time: 2.28480
Timestep Consumption Time: 2.48259
PPO Batch Consumption Time: 0.29361
Total Iteration Time: 4.76739

Cumulative Model Updates: 242,684
Cumulative Timesteps: 2,024,609,986

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2024609986...
Checkpoint 2024609986 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 81,904.65669
Policy Entropy: 2.34425
Value Function Loss: 0.01841

Mean KL Divergence: 0.00693
SB3 Clip Fraction: 0.06435
Policy Update Magnitude: 0.30671
Value Function Update Magnitude: 0.26719

Collected Steps per Second: 22,029.80010
Overall Steps per Second: 10,583.33272

Timestep Collection Time: 2.26974
Timestep Consumption Time: 2.45485
PPO Batch Consumption Time: 0.28757
Total Iteration Time: 4.72460

Cumulative Model Updates: 242,690
Cumulative Timesteps: 2,024,659,988

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60,710.39318
Policy Entropy: 2.34199
Value Function Loss: 0.02032

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.07559
Policy Update Magnitude: 0.31105
Value Function Update Magnitude: 0.24789

Collected Steps per Second: 22,011.00577
Overall Steps per Second: 10,496.40921

Timestep Collection Time: 2.27205
Timestep Consumption Time: 2.49244
PPO Batch Consumption Time: 0.29344
Total Iteration Time: 4.76449

Cumulative Model Updates: 242,696
Cumulative Timesteps: 2,024,709,998

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2024709998...
Checkpoint 2024709998 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47,296.36275
Policy Entropy: 2.34725
Value Function Loss: 0.01644

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.07725
Policy Update Magnitude: 0.30968
Value Function Update Magnitude: 0.29450

Collected Steps per Second: 22,110.57187
Overall Steps per Second: 10,641.65965

Timestep Collection Time: 2.26172
Timestep Consumption Time: 2.43754
PPO Batch Consumption Time: 0.27816
Total Iteration Time: 4.69927

Cumulative Model Updates: 242,702
Cumulative Timesteps: 2,024,760,006

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48,666.67051
Policy Entropy: 2.36780
Value Function Loss: 0.01572

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.08052
Policy Update Magnitude: 0.30960
Value Function Update Magnitude: 0.31870

Collected Steps per Second: 21,841.73245
Overall Steps per Second: 10,426.20534

Timestep Collection Time: 2.28920
Timestep Consumption Time: 2.50641
PPO Batch Consumption Time: 0.29048
Total Iteration Time: 4.79561

Cumulative Model Updates: 242,708
Cumulative Timesteps: 2,024,810,006

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2024810006...
Checkpoint 2024810006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 51,015.13875
Policy Entropy: 2.38012
Value Function Loss: 0.01435

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.07499
Policy Update Magnitude: 0.29545
Value Function Update Magnitude: 0.31120

Collected Steps per Second: 21,611.90669
Overall Steps per Second: 10,560.79413

Timestep Collection Time: 2.31419
Timestep Consumption Time: 2.42163
PPO Batch Consumption Time: 0.27859
Total Iteration Time: 4.73582

Cumulative Model Updates: 242,714
Cumulative Timesteps: 2,024,860,020

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54,327.89139
Policy Entropy: 2.40219
Value Function Loss: 0.01515

Mean KL Divergence: 0.00783
SB3 Clip Fraction: 0.06572
Policy Update Magnitude: 0.28801
Value Function Update Magnitude: 0.29698

Collected Steps per Second: 21,514.63235
Overall Steps per Second: 10,470.11928

Timestep Collection Time: 2.32502
Timestep Consumption Time: 2.45257
PPO Batch Consumption Time: 0.27940
Total Iteration Time: 4.77760

Cumulative Model Updates: 242,720
Cumulative Timesteps: 2,024,910,042

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2024910042...
Checkpoint 2024910042 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 52,811.40153
Policy Entropy: 2.41140
Value Function Loss: 0.01561

Mean KL Divergence: 0.00653
SB3 Clip Fraction: 0.06499
Policy Update Magnitude: 0.28614
Value Function Update Magnitude: 0.28746

Collected Steps per Second: 21,450.45497
Overall Steps per Second: 10,318.38100

Timestep Collection Time: 2.33244
Timestep Consumption Time: 2.51638
PPO Batch Consumption Time: 0.29433
Total Iteration Time: 4.84882

Cumulative Model Updates: 242,726
Cumulative Timesteps: 2,024,960,074

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,703.14946
Policy Entropy: 2.40516
Value Function Loss: 0.01584

Mean KL Divergence: 0.00656
SB3 Clip Fraction: 0.06189
Policy Update Magnitude: 0.28760
Value Function Update Magnitude: 0.27770

Collected Steps per Second: 21,708.48313
Overall Steps per Second: 10,413.37819

Timestep Collection Time: 2.30491
Timestep Consumption Time: 2.50007
PPO Batch Consumption Time: 0.29100
Total Iteration Time: 4.80497

Cumulative Model Updates: 242,732
Cumulative Timesteps: 2,025,010,110

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 2025010110...
Checkpoint 2025010110 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 79,515.68827
Policy Entropy: 2.38351
Value Function Loss: 0.01739

Mean KL Divergence: 0.00756
SB3 Clip Fraction: 0.06896
Policy Update Magnitude: 0.29473
Value Function Update Magnitude: 0.30411

Collected Steps per Second: 21,682.70222
Overall Steps per Second: 10,536.87471

Timestep Collection Time: 2.30635
Timestep Consumption Time: 2.43964
PPO Batch Consumption Time: 0.27848
Total Iteration Time: 4.74600

Cumulative Model Updates: 242,738
Cumulative Timesteps: 2,025,060,118

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91,846.62876
Policy Entropy: 2.38018
Value Function Loss: 0.01634

Mean KL Divergence: 0.00739
SB3 Clip Fraction: 0.06470
Policy Update Magnitude: 0.30094
Value Function Update Magnitude: 0.31174

Collected Steps per Second: 22,005.10185
Overall Steps per Second: 10,598.18945

Timestep Collection Time: 2.27329
Timestep Consumption Time: 2.44676
PPO Batch Consumption Time: 0.27757
Total Iteration Time: 4.72005

Cumulative Model Updates: 242,744
Cumulative Timesteps: 2,025,110,142

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2025110142...
Checkpoint 2025110142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 76,749.61072
Policy Entropy: 2.38002
Value Function Loss: 0.01575

Mean KL Divergence: 0.00743
SB3 Clip Fraction: 0.06741
Policy Update Magnitude: 0.29463
Value Function Update Magnitude: 0.30758

Collected Steps per Second: 22,193.25494
Overall Steps per Second: 10,543.80223

Timestep Collection Time: 2.25312
Timestep Consumption Time: 2.48938
PPO Batch Consumption Time: 0.28922
Total Iteration Time: 4.74250

Cumulative Model Updates: 242,750
Cumulative Timesteps: 2,025,160,146

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86,888.55407
Policy Entropy: 2.39615
Value Function Loss: 0.01688

Mean KL Divergence: 0.00659
SB3 Clip Fraction: 0.06582
Policy Update Magnitude: 0.30679
Value Function Update Magnitude: 0.30856

Collected Steps per Second: 21,598.10708
Overall Steps per Second: 10,556.95437

Timestep Collection Time: 2.31604
Timestep Consumption Time: 2.42226
PPO Batch Consumption Time: 0.29398
Total Iteration Time: 4.73830

Cumulative Model Updates: 242,756
Cumulative Timesteps: 2,025,210,168

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2025210168...
Checkpoint 2025210168 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 64,503.22618
Policy Entropy: 2.41765
Value Function Loss: 0.01825

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.07620
Policy Update Magnitude: 0.30724
Value Function Update Magnitude: 0.33737

Collected Steps per Second: 21,335.94669
Overall Steps per Second: 10,575.84933

Timestep Collection Time: 2.34365
Timestep Consumption Time: 2.38448
PPO Batch Consumption Time: 0.28342
Total Iteration Time: 4.72813

Cumulative Model Updates: 242,762
Cumulative Timesteps: 2,025,260,172

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54,826.32121
Policy Entropy: 2.42382
Value Function Loss: 0.01974

Mean KL Divergence: 0.00762
SB3 Clip Fraction: 0.07113
Policy Update Magnitude: 0.30627
Value Function Update Magnitude: 0.27826

Collected Steps per Second: 21,621.90763
Overall Steps per Second: 10,557.57140

Timestep Collection Time: 2.31330
Timestep Consumption Time: 2.42434
PPO Batch Consumption Time: 0.29286
Total Iteration Time: 4.73764

Cumulative Model Updates: 242,768
Cumulative Timesteps: 2,025,310,190

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2025310190...
Checkpoint 2025310190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40,201.04713
Policy Entropy: 2.44370
Value Function Loss: 0.01833

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.07714
Policy Update Magnitude: 0.29947
Value Function Update Magnitude: 0.22297

Collected Steps per Second: 21,283.01846
Overall Steps per Second: 10,504.02745

Timestep Collection Time: 2.35070
Timestep Consumption Time: 2.41223
PPO Batch Consumption Time: 0.27918
Total Iteration Time: 4.76293

Cumulative Model Updates: 242,774
Cumulative Timesteps: 2,025,360,220

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 69,370.65981
Policy Entropy: 2.42382
Value Function Loss: 0.01936

Mean KL Divergence: 0.00757
SB3 Clip Fraction: 0.07330
Policy Update Magnitude: 0.29578
Value Function Update Magnitude: 0.20914

Collected Steps per Second: 21,436.79123
Overall Steps per Second: 10,452.49378

Timestep Collection Time: 2.33365
Timestep Consumption Time: 2.45238
PPO Batch Consumption Time: 0.28451
Total Iteration Time: 4.78603

Cumulative Model Updates: 242,780
Cumulative Timesteps: 2,025,410,246

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2025410246...
Checkpoint 2025410246 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 56,104.38568
Policy Entropy: 2.43360
Value Function Loss: 0.01929

Mean KL Divergence: 0.00741
SB3 Clip Fraction: 0.07117
Policy Update Magnitude: 0.30076
Value Function Update Magnitude: 0.24298

Collected Steps per Second: 21,431.04776
Overall Steps per Second: 10,575.53550

Timestep Collection Time: 2.33381
Timestep Consumption Time: 2.39560
PPO Batch Consumption Time: 0.27768
Total Iteration Time: 4.72941

Cumulative Model Updates: 242,786
Cumulative Timesteps: 2,025,460,262

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65,885.19460
Policy Entropy: 2.38924
Value Function Loss: 0.01900

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.06682
Policy Update Magnitude: 0.30521
Value Function Update Magnitude: 0.31955

Collected Steps per Second: 21,601.04764
Overall Steps per Second: 10,503.46126

Timestep Collection Time: 2.31507
Timestep Consumption Time: 2.44602
PPO Batch Consumption Time: 0.27933
Total Iteration Time: 4.76110

Cumulative Model Updates: 242,792
Cumulative Timesteps: 2,025,510,270

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2025510270...
Checkpoint 2025510270 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 149,485.11197
Policy Entropy: 2.38909
Value Function Loss: 0.01765

Mean KL Divergence: 0.01274
SB3 Clip Fraction: 0.06604
Policy Update Magnitude: 0.31282
Value Function Update Magnitude: 0.34764

Collected Steps per Second: 21,429.61967
Overall Steps per Second: 10,273.49916

Timestep Collection Time: 2.33453
Timestep Consumption Time: 2.53509
PPO Batch Consumption Time: 0.29411
Total Iteration Time: 4.86962

Cumulative Model Updates: 242,798
Cumulative Timesteps: 2,025,560,298

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 140,225.67755
Policy Entropy: 2.38429
Value Function Loss: 0.01622

Mean KL Divergence: 0.01556
SB3 Clip Fraction: 0.07574
Policy Update Magnitude: 0.30856
Value Function Update Magnitude: 0.33860

Collected Steps per Second: 22,056.06916
Overall Steps per Second: 10,405.22713

Timestep Collection Time: 2.26913
Timestep Consumption Time: 2.54076
PPO Batch Consumption Time: 0.29221
Total Iteration Time: 4.80989

Cumulative Model Updates: 242,804
Cumulative Timesteps: 2,025,610,346

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 2025610346...
Checkpoint 2025610346 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 79,007.12850
Policy Entropy: 2.40075
Value Function Loss: 0.01853

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.07697
Policy Update Magnitude: 0.30916
Value Function Update Magnitude: 0.32961

Collected Steps per Second: 21,586.96712
Overall Steps per Second: 10,535.82075

Timestep Collection Time: 2.31668
Timestep Consumption Time: 2.42999
PPO Batch Consumption Time: 0.27823
Total Iteration Time: 4.74666

Cumulative Model Updates: 242,810
Cumulative Timesteps: 2,025,660,356

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78,776.20233
Policy Entropy: 2.41800
Value Function Loss: 0.01612

Mean KL Divergence: 0.00738
SB3 Clip Fraction: 0.06822
Policy Update Magnitude: 0.30976
Value Function Update Magnitude: 0.30267

Collected Steps per Second: 22,089.00239
Overall Steps per Second: 10,517.76349

Timestep Collection Time: 2.26429
Timestep Consumption Time: 2.49109
PPO Batch Consumption Time: 0.28791
Total Iteration Time: 4.75538

Cumulative Model Updates: 242,816
Cumulative Timesteps: 2,025,710,372

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2025710372...
Checkpoint 2025710372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 73,027.14093
Policy Entropy: 2.40134
Value Function Loss: 0.01487

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.07884
Policy Update Magnitude: 0.30081
Value Function Update Magnitude: 0.28611

Collected Steps per Second: 22,028.33490
Overall Steps per Second: 10,614.11684

Timestep Collection Time: 2.27071
Timestep Consumption Time: 2.44188
PPO Batch Consumption Time: 0.27964
Total Iteration Time: 4.71259

Cumulative Model Updates: 242,822
Cumulative Timesteps: 2,025,760,392

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 111,078.64110
Policy Entropy: 2.39904
Value Function Loss: 0.01328

Mean KL Divergence: 0.00734
SB3 Clip Fraction: 0.06988
Policy Update Magnitude: 0.28687
Value Function Update Magnitude: 0.27687

Collected Steps per Second: 21,980.61835
Overall Steps per Second: 10,498.64844

Timestep Collection Time: 2.27537
Timestep Consumption Time: 2.48848
PPO Batch Consumption Time: 0.28696
Total Iteration Time: 4.76385

Cumulative Model Updates: 242,828
Cumulative Timesteps: 2,025,810,406

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2025810406...
Checkpoint 2025810406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84,728.30157
Policy Entropy: 2.38216
Value Function Loss: 0.01517

Mean KL Divergence: 0.00749
SB3 Clip Fraction: 0.07071
Policy Update Magnitude: 0.28979
Value Function Update Magnitude: 0.26941

Collected Steps per Second: 21,739.63031
Overall Steps per Second: 10,568.32458

Timestep Collection Time: 2.30059
Timestep Consumption Time: 2.43185
PPO Batch Consumption Time: 0.27904
Total Iteration Time: 4.73244

Cumulative Model Updates: 242,834
Cumulative Timesteps: 2,025,860,420

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66,454.67620
Policy Entropy: 2.37765
Value Function Loss: 0.01786

Mean KL Divergence: 0.00706
SB3 Clip Fraction: 0.06815
Policy Update Magnitude: 0.30032
Value Function Update Magnitude: 0.28887

Collected Steps per Second: 21,959.26463
Overall Steps per Second: 10,528.18677

Timestep Collection Time: 2.27767
Timestep Consumption Time: 2.47300
PPO Batch Consumption Time: 0.28694
Total Iteration Time: 4.75068

Cumulative Model Updates: 242,840
Cumulative Timesteps: 2,025,910,436

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2025910436...
Checkpoint 2025910436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 63,812.80739
Policy Entropy: 2.37162
Value Function Loss: 0.01776

Mean KL Divergence: 0.00664
SB3 Clip Fraction: 0.06512
Policy Update Magnitude: 0.30783
Value Function Update Magnitude: 0.32103

Collected Steps per Second: 21,287.69449
Overall Steps per Second: 10,313.88034

Timestep Collection Time: 2.35047
Timestep Consumption Time: 2.50086
PPO Batch Consumption Time: 0.29236
Total Iteration Time: 4.85133

Cumulative Model Updates: 242,846
Cumulative Timesteps: 2,025,960,472

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59,415.96831
Policy Entropy: 2.38532
Value Function Loss: 0.01718

Mean KL Divergence: 0.00670
SB3 Clip Fraction: 0.06513
Policy Update Magnitude: 0.30598
Value Function Update Magnitude: 0.31166

Collected Steps per Second: 21,624.32408
Overall Steps per Second: 10,348.49509

Timestep Collection Time: 2.31221
Timestep Consumption Time: 2.51941
PPO Batch Consumption Time: 0.29304
Total Iteration Time: 4.83162

Cumulative Model Updates: 242,852
Cumulative Timesteps: 2,026,010,472

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2026010472...
Checkpoint 2026010472 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 59,415.96831
Policy Entropy: 2.42147
Value Function Loss: 0.01499

Mean KL Divergence: 0.00759
SB3 Clip Fraction: 0.07165
Policy Update Magnitude: 0.29302
Value Function Update Magnitude: 0.28260

Collected Steps per Second: 21,530.06452
Overall Steps per Second: 10,553.23418

Timestep Collection Time: 2.32317
Timestep Consumption Time: 2.41642
PPO Batch Consumption Time: 0.27842
Total Iteration Time: 4.73959

Cumulative Model Updates: 242,858
Cumulative Timesteps: 2,026,060,490

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59,415.96831
Policy Entropy: 2.43626
Value Function Loss: 0.01388

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.07862
Policy Update Magnitude: 0.27485
Value Function Update Magnitude: 0.26459

Collected Steps per Second: 21,776.93065
Overall Steps per Second: 10,586.24861

Timestep Collection Time: 2.29628
Timestep Consumption Time: 2.42739
PPO Batch Consumption Time: 0.27735
Total Iteration Time: 4.72368

Cumulative Model Updates: 242,864
Cumulative Timesteps: 2,026,110,496

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2026110496...
Checkpoint 2026110496 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 83,517.62386
Policy Entropy: 2.43260
Value Function Loss: 0.01528

Mean KL Divergence: 0.00680
SB3 Clip Fraction: 0.06669
Policy Update Magnitude: 0.28149
Value Function Update Magnitude: 0.26132

Collected Steps per Second: 21,772.04693
Overall Steps per Second: 10,495.75128

Timestep Collection Time: 2.29652
Timestep Consumption Time: 2.46731
PPO Batch Consumption Time: 0.27912
Total Iteration Time: 4.76383

Cumulative Model Updates: 242,870
Cumulative Timesteps: 2,026,160,496

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82,937.79009
Policy Entropy: 2.42156
Value Function Loss: 0.01889

Mean KL Divergence: 0.00675
SB3 Clip Fraction: 0.06521
Policy Update Magnitude: 0.30116
Value Function Update Magnitude: 0.29240

Collected Steps per Second: 21,853.28532
Overall Steps per Second: 10,511.97744

Timestep Collection Time: 2.28844
Timestep Consumption Time: 2.46899
PPO Batch Consumption Time: 0.27949
Total Iteration Time: 4.75743

Cumulative Model Updates: 242,876
Cumulative Timesteps: 2,026,210,506

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2026210506...
Checkpoint 2026210506 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 82,937.79009
Policy Entropy: 2.43078
Value Function Loss: 0.01756

Mean KL Divergence: 0.00684
SB3 Clip Fraction: 0.06405
Policy Update Magnitude: 0.29923
Value Function Update Magnitude: 0.31905

Collected Steps per Second: 21,723.01076
Overall Steps per Second: 10,564.93925

Timestep Collection Time: 2.30207
Timestep Consumption Time: 2.43132
PPO Batch Consumption Time: 0.27837
Total Iteration Time: 4.73339

Cumulative Model Updates: 242,882
Cumulative Timesteps: 2,026,260,514

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 69,833.18396
Policy Entropy: 2.39285
Value Function Loss: 0.01643

Mean KL Divergence: 0.00676
SB3 Clip Fraction: 0.06469
Policy Update Magnitude: 0.30270
Value Function Update Magnitude: 0.30399

Collected Steps per Second: 22,254.39791
Overall Steps per Second: 10,526.56186

Timestep Collection Time: 2.24801
Timestep Consumption Time: 2.50454
PPO Batch Consumption Time: 0.28983
Total Iteration Time: 4.75255

Cumulative Model Updates: 242,888
Cumulative Timesteps: 2,026,310,542

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2026310542...
Checkpoint 2026310542 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 61,481.67911
Policy Entropy: 2.36455
Value Function Loss: 0.01494

Mean KL Divergence: 0.00745
SB3 Clip Fraction: 0.06642
Policy Update Magnitude: 0.30054
Value Function Update Magnitude: 0.28102

Collected Steps per Second: 21,922.06633
Overall Steps per Second: 10,603.18298

Timestep Collection Time: 2.28309
Timestep Consumption Time: 2.43719
PPO Batch Consumption Time: 0.27865
Total Iteration Time: 4.72028

Cumulative Model Updates: 242,894
Cumulative Timesteps: 2,026,360,592

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62,032.78463
Policy Entropy: 2.34233
Value Function Loss: 0.01816

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.06583
Policy Update Magnitude: 0.31840
Value Function Update Magnitude: 0.28596

Collected Steps per Second: 21,021.80590
Overall Steps per Second: 10,257.13440

Timestep Collection Time: 2.37867
Timestep Consumption Time: 2.49637
PPO Batch Consumption Time: 0.29047
Total Iteration Time: 4.87505

Cumulative Model Updates: 242,900
Cumulative Timesteps: 2,026,410,596

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2026410596...
Checkpoint 2026410596 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 56,785.70214
Policy Entropy: 2.37178
Value Function Loss: 0.01752

Mean KL Divergence: 0.00707
SB3 Clip Fraction: 0.06471
Policy Update Magnitude: 0.31765
Value Function Update Magnitude: 0.31543

Collected Steps per Second: 21,274.45136
Overall Steps per Second: 10,512.79773

Timestep Collection Time: 2.35052
Timestep Consumption Time: 2.40616
PPO Batch Consumption Time: 0.27720
Total Iteration Time: 4.75668

Cumulative Model Updates: 242,906
Cumulative Timesteps: 2,026,460,602

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59,473.12602
Policy Entropy: 2.35985
Value Function Loss: 0.01813

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.06646
Policy Update Magnitude: 0.31175
Value Function Update Magnitude: 0.32009

Collected Steps per Second: 21,716.52883
Overall Steps per Second: 10,394.53579

Timestep Collection Time: 2.30322
Timestep Consumption Time: 2.50873
PPO Batch Consumption Time: 0.29227
Total Iteration Time: 4.81195

Cumulative Model Updates: 242,912
Cumulative Timesteps: 2,026,510,620

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2026510620...
Checkpoint 2026510620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 72,940.40421
Policy Entropy: 2.38069
Value Function Loss: 0.01653

Mean KL Divergence: 0.00687
SB3 Clip Fraction: 0.06559
Policy Update Magnitude: 0.30637
Value Function Update Magnitude: 0.31155

Collected Steps per Second: 20,978.60643
Overall Steps per Second: 10,550.08133

Timestep Collection Time: 2.38357
Timestep Consumption Time: 2.35611
PPO Batch Consumption Time: 0.27864
Total Iteration Time: 4.73968

Cumulative Model Updates: 242,918
Cumulative Timesteps: 2,026,560,624

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66,215.81343
Policy Entropy: 2.38081
Value Function Loss: 0.01730

Mean KL Divergence: 0.00706
SB3 Clip Fraction: 0.06859
Policy Update Magnitude: 0.30765
Value Function Update Magnitude: 0.30760

Collected Steps per Second: 21,486.21936
Overall Steps per Second: 10,563.09242

Timestep Collection Time: 2.32847
Timestep Consumption Time: 2.40783
PPO Batch Consumption Time: 0.28477
Total Iteration Time: 4.73630

Cumulative Model Updates: 242,924
Cumulative Timesteps: 2,026,610,654

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2026610654...
Checkpoint 2026610654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86,274.98486
Policy Entropy: 2.39590
Value Function Loss: 0.01625

Mean KL Divergence: 0.00711
SB3 Clip Fraction: 0.06849
Policy Update Magnitude: 0.30338
Value Function Update Magnitude: 0.30367

Collected Steps per Second: 21,274.02687
Overall Steps per Second: 10,603.42559

Timestep Collection Time: 2.35057
Timestep Consumption Time: 2.36546
PPO Batch Consumption Time: 0.27913
Total Iteration Time: 4.71602

Cumulative Model Updates: 242,930
Cumulative Timesteps: 2,026,660,660

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87,899.04727
Policy Entropy: 2.38687
Value Function Loss: 0.01552

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.08878
Policy Update Magnitude: 0.29691
Value Function Update Magnitude: 0.28324

Collected Steps per Second: 21,649.27184
Overall Steps per Second: 10,446.23452

Timestep Collection Time: 2.30955
Timestep Consumption Time: 2.47687
PPO Batch Consumption Time: 0.28821
Total Iteration Time: 4.78641

Cumulative Model Updates: 242,936
Cumulative Timesteps: 2,026,710,660

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2026710660...
Checkpoint 2026710660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 58,700.07038
Policy Entropy: 2.38380
Value Function Loss: 0.01630

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.09038
Policy Update Magnitude: 0.28141
Value Function Update Magnitude: 0.26622

Collected Steps per Second: 21,889.41504
Overall Steps per Second: 10,644.77416

Timestep Collection Time: 2.28494
Timestep Consumption Time: 2.41370
PPO Batch Consumption Time: 0.27891
Total Iteration Time: 4.69864

Cumulative Model Updates: 242,942
Cumulative Timesteps: 2,026,760,676

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65,603.99750
Policy Entropy: 2.38235
Value Function Loss: 0.01696

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.07602
Policy Update Magnitude: 0.28927
Value Function Update Magnitude: 0.26035

Collected Steps per Second: 21,804.70442
Overall Steps per Second: 10,505.98477

Timestep Collection Time: 2.29373
Timestep Consumption Time: 2.46680
PPO Batch Consumption Time: 0.29301
Total Iteration Time: 4.76052

Cumulative Model Updates: 242,948
Cumulative Timesteps: 2,026,810,690

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2026810690...
Checkpoint 2026810690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 103,081.14295
Policy Entropy: 2.37692
Value Function Loss: 0.01712

Mean KL Divergence: 0.00706
SB3 Clip Fraction: 0.06780
Policy Update Magnitude: 0.30561
Value Function Update Magnitude: 0.28780

Collected Steps per Second: 21,955.86323
Overall Steps per Second: 10,639.48946

Timestep Collection Time: 2.27866
Timestep Consumption Time: 2.42363
PPO Batch Consumption Time: 0.27712
Total Iteration Time: 4.70229

Cumulative Model Updates: 242,954
Cumulative Timesteps: 2,026,860,720

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91,283.59051
Policy Entropy: 2.38215
Value Function Loss: 0.01663

Mean KL Divergence: 0.00688
SB3 Clip Fraction: 0.06261
Policy Update Magnitude: 0.30865
Value Function Update Magnitude: 0.29717

Collected Steps per Second: 21,501.04094
Overall Steps per Second: 10,392.17729

Timestep Collection Time: 2.32742
Timestep Consumption Time: 2.48793
PPO Batch Consumption Time: 0.29209
Total Iteration Time: 4.81535

Cumulative Model Updates: 242,960
Cumulative Timesteps: 2,026,910,762

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 2026910762...
Checkpoint 2026910762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 106,650.76131
Policy Entropy: 2.40155
Value Function Loss: 0.01679

Mean KL Divergence: 0.00756
SB3 Clip Fraction: 0.07052
Policy Update Magnitude: 0.30384
Value Function Update Magnitude: 0.33411

Collected Steps per Second: 21,609.45357
Overall Steps per Second: 10,559.48727

Timestep Collection Time: 2.31408
Timestep Consumption Time: 2.42157
PPO Batch Consumption Time: 0.27914
Total Iteration Time: 4.73565

Cumulative Model Updates: 242,966
Cumulative Timesteps: 2,026,960,768

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80,504.37726
Policy Entropy: 2.38404
Value Function Loss: 0.01598

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.07530
Policy Update Magnitude: 0.30019
Value Function Update Magnitude: 0.32290

Collected Steps per Second: 21,919.67503
Overall Steps per Second: 10,615.67970

Timestep Collection Time: 2.28124
Timestep Consumption Time: 2.42915
PPO Batch Consumption Time: 0.27724
Total Iteration Time: 4.71039

Cumulative Model Updates: 242,972
Cumulative Timesteps: 2,027,010,772

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2027010772...
Checkpoint 2027010772 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 69,176.30713
Policy Entropy: 2.37098
Value Function Loss: 0.01656

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.06986
Policy Update Magnitude: 0.30498
Value Function Update Magnitude: 0.30796

Collected Steps per Second: 21,662.60329
Overall Steps per Second: 10,510.85694

Timestep Collection Time: 2.30933
Timestep Consumption Time: 2.45013
PPO Batch Consumption Time: 0.27887
Total Iteration Time: 4.75946

Cumulative Model Updates: 242,978
Cumulative Timesteps: 2,027,060,798

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80,244.22429
Policy Entropy: 2.34989
Value Function Loss: 0.01835

Mean KL Divergence: 0.00762
SB3 Clip Fraction: 0.06584
Policy Update Magnitude: 0.30867
Value Function Update Magnitude: 0.32372

Collected Steps per Second: 22,193.34725
Overall Steps per Second: 10,470.80024

Timestep Collection Time: 2.25401
Timestep Consumption Time: 2.52347
PPO Batch Consumption Time: 0.28917
Total Iteration Time: 4.77748

Cumulative Model Updates: 242,984
Cumulative Timesteps: 2,027,110,822

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2027110822...
Checkpoint 2027110822 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 66,308.46871
Policy Entropy: 2.37345
Value Function Loss: 0.01802

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.07395
Policy Update Magnitude: 0.31669
Value Function Update Magnitude: 0.35058

Collected Steps per Second: 21,918.57047
Overall Steps per Second: 10,607.90891

Timestep Collection Time: 2.28163
Timestep Consumption Time: 2.43278
PPO Batch Consumption Time: 0.27975
Total Iteration Time: 4.71441

Cumulative Model Updates: 242,990
Cumulative Timesteps: 2,027,160,832

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70,553.59353
Policy Entropy: 2.38852
Value Function Loss: 0.01928

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.07202
Policy Update Magnitude: 0.31023
Value Function Update Magnitude: 0.34201

Collected Steps per Second: 22,216.60721
Overall Steps per Second: 10,514.02596

Timestep Collection Time: 2.25111
Timestep Consumption Time: 2.50558
PPO Batch Consumption Time: 0.29174
Total Iteration Time: 4.75669

Cumulative Model Updates: 242,996
Cumulative Timesteps: 2,027,210,844

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2027210844...
Checkpoint 2027210844 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 59,582.65124
Policy Entropy: 2.37700
Value Function Loss: 0.01826

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.07260
Policy Update Magnitude: 0.30614
Value Function Update Magnitude: 0.35624

Collected Steps per Second: 21,750.87594
Overall Steps per Second: 10,578.54019

Timestep Collection Time: 2.29968
Timestep Consumption Time: 2.42876
PPO Batch Consumption Time: 0.27898
Total Iteration Time: 4.72844

Cumulative Model Updates: 243,002
Cumulative Timesteps: 2,027,260,864

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59,582.65124
Policy Entropy: 2.36506
Value Function Loss: 0.01607

Mean KL Divergence: 0.00747
SB3 Clip Fraction: 0.07207
Policy Update Magnitude: 0.29946
Value Function Update Magnitude: 0.34901

Collected Steps per Second: 22,028.31700
Overall Steps per Second: 10,480.38522

Timestep Collection Time: 2.27008
Timestep Consumption Time: 2.50131
PPO Batch Consumption Time: 0.29005
Total Iteration Time: 4.77139

Cumulative Model Updates: 243,008
Cumulative Timesteps: 2,027,310,870

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2027310870...
Checkpoint 2027310870 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 63,554.03416
Policy Entropy: 2.35234
Value Function Loss: 0.01549

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.07613
Policy Update Magnitude: 0.30273
Value Function Update Magnitude: 0.32259

Collected Steps per Second: 21,707.81233
Overall Steps per Second: 10,586.26911

Timestep Collection Time: 2.30378
Timestep Consumption Time: 2.42026
PPO Batch Consumption Time: 0.27927
Total Iteration Time: 4.72404

Cumulative Model Updates: 243,014
Cumulative Timesteps: 2,027,360,880

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54,242.60841
Policy Entropy: 2.34886
Value Function Loss: 0.01683

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.07102
Policy Update Magnitude: 0.31351
Value Function Update Magnitude: 0.30138

Collected Steps per Second: 21,614.39179
Overall Steps per Second: 10,520.19437

Timestep Collection Time: 2.31503
Timestep Consumption Time: 2.44134
PPO Batch Consumption Time: 0.27998
Total Iteration Time: 4.75638

Cumulative Model Updates: 243,020
Cumulative Timesteps: 2,027,410,918

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 2027410918...
Checkpoint 2027410918 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 60,295.49970
Policy Entropy: 2.34534
Value Function Loss: 0.01619

Mean KL Divergence: 0.00744
SB3 Clip Fraction: 0.06818
Policy Update Magnitude: 0.31206
Value Function Update Magnitude: 0.31499

Collected Steps per Second: 21,154.41888
Overall Steps per Second: 10,233.81547

Timestep Collection Time: 2.36452
Timestep Consumption Time: 2.52320
PPO Batch Consumption Time: 0.29465
Total Iteration Time: 4.88772

Cumulative Model Updates: 243,026
Cumulative Timesteps: 2,027,460,938

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 74,792.66398
Policy Entropy: 2.36231
Value Function Loss: 0.01509

Mean KL Divergence: 0.00657
SB3 Clip Fraction: 0.06134
Policy Update Magnitude: 0.29758
Value Function Update Magnitude: 0.28682

Collected Steps per Second: 21,676.63730
Overall Steps per Second: 10,428.91472

Timestep Collection Time: 2.30672
Timestep Consumption Time: 2.48783
PPO Batch Consumption Time: 0.28903
Total Iteration Time: 4.79455

Cumulative Model Updates: 243,032
Cumulative Timesteps: 2,027,510,940

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2027510940...
Checkpoint 2027510940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 93,896.28511
Policy Entropy: 2.37717
Value Function Loss: 0.01607

Mean KL Divergence: 0.00654
SB3 Clip Fraction: 0.06387
Policy Update Magnitude: 0.29278
Value Function Update Magnitude: 0.25452

Collected Steps per Second: 21,596.30261
Overall Steps per Second: 10,564.91358

Timestep Collection Time: 2.31716
Timestep Consumption Time: 2.41947
PPO Batch Consumption Time: 0.27838
Total Iteration Time: 4.73662

Cumulative Model Updates: 243,038
Cumulative Timesteps: 2,027,560,982

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 115,252.08628
Policy Entropy: 2.37688
Value Function Loss: 0.01662

Mean KL Divergence: 0.00699
SB3 Clip Fraction: 0.06790
Policy Update Magnitude: 0.29559
Value Function Update Magnitude: 0.28702

Collected Steps per Second: 22,193.77511
Overall Steps per Second: 10,516.23932

Timestep Collection Time: 2.25369
Timestep Consumption Time: 2.50257
PPO Batch Consumption Time: 0.28609
Total Iteration Time: 4.75626

Cumulative Model Updates: 243,044
Cumulative Timesteps: 2,027,611,000

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2027611000...
Checkpoint 2027611000 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 79,666.59688
Policy Entropy: 2.37707
Value Function Loss: 0.01743

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.07366
Policy Update Magnitude: 0.29330
Value Function Update Magnitude: 0.29875

Collected Steps per Second: 21,564.51552
Overall Steps per Second: 10,554.48745

Timestep Collection Time: 2.31955
Timestep Consumption Time: 2.41967
PPO Batch Consumption Time: 0.27836
Total Iteration Time: 4.73922

Cumulative Model Updates: 243,050
Cumulative Timesteps: 2,027,661,020

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80,758.69146
Policy Entropy: 2.38340
Value Function Loss: 0.01794

Mean KL Divergence: 0.00691
SB3 Clip Fraction: 0.06935
Policy Update Magnitude: 0.29458
Value Function Update Magnitude: 0.29790

Collected Steps per Second: 21,531.55545
Overall Steps per Second: 10,535.89726

Timestep Collection Time: 2.32254
Timestep Consumption Time: 2.42389
PPO Batch Consumption Time: 0.28924
Total Iteration Time: 4.74644

Cumulative Model Updates: 243,056
Cumulative Timesteps: 2,027,711,028

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2027711028...
Checkpoint 2027711028 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 74,127.46918
Policy Entropy: 2.37380
Value Function Loss: 0.01737

Mean KL Divergence: 0.00663
SB3 Clip Fraction: 0.06431
Policy Update Magnitude: 0.30143
Value Function Update Magnitude: 0.27352

Collected Steps per Second: 21,337.67416
Overall Steps per Second: 10,624.17540

Timestep Collection Time: 2.34327
Timestep Consumption Time: 2.36297
PPO Batch Consumption Time: 0.27972
Total Iteration Time: 4.70625

Cumulative Model Updates: 243,062
Cumulative Timesteps: 2,027,761,028

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56,494.39288
Policy Entropy: 2.34599
Value Function Loss: 0.01810

Mean KL Divergence: 0.00716
SB3 Clip Fraction: 0.06610
Policy Update Magnitude: 0.31890
Value Function Update Magnitude: 0.24308

Collected Steps per Second: 21,725.47207
Overall Steps per Second: 10,545.27429

Timestep Collection Time: 2.30246
Timestep Consumption Time: 2.44109
PPO Batch Consumption Time: 0.29290
Total Iteration Time: 4.74355

Cumulative Model Updates: 243,068
Cumulative Timesteps: 2,027,811,050

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2027811050...
Checkpoint 2027811050 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,033.67744
Policy Entropy: 2.33914
Value Function Loss: 0.01870

Mean KL Divergence: 0.00721
SB3 Clip Fraction: 0.06592
Policy Update Magnitude: 0.32320
Value Function Update Magnitude: 0.24711

Collected Steps per Second: 21,043.69808
Overall Steps per Second: 10,358.97962

Timestep Collection Time: 2.37639
Timestep Consumption Time: 2.45111
PPO Batch Consumption Time: 0.28879
Total Iteration Time: 4.82750

Cumulative Model Updates: 243,074
Cumulative Timesteps: 2,027,861,058

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62,852.27469
Policy Entropy: 2.33174
Value Function Loss: 0.02037

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.07095
Policy Update Magnitude: 0.33256
Value Function Update Magnitude: 0.26936

Collected Steps per Second: 21,871.36309
Overall Steps per Second: 10,646.62480

Timestep Collection Time: 2.28637
Timestep Consumption Time: 2.41052
PPO Batch Consumption Time: 0.27837
Total Iteration Time: 4.69689

Cumulative Model Updates: 243,080
Cumulative Timesteps: 2,027,911,064

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2027911064...
Checkpoint 2027911064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 69,150.87986
Policy Entropy: 2.35613
Value Function Loss: 0.01887

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.07520
Policy Update Magnitude: 0.32703
Value Function Update Magnitude: 0.30589

Collected Steps per Second: 21,419.04469
Overall Steps per Second: 10,565.79087

Timestep Collection Time: 2.33456
Timestep Consumption Time: 2.39807
PPO Batch Consumption Time: 0.27882
Total Iteration Time: 4.73263

Cumulative Model Updates: 243,086
Cumulative Timesteps: 2,027,961,068

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68,416.72227
Policy Entropy: 2.36629
Value Function Loss: 0.01713

Mean KL Divergence: 0.00707
SB3 Clip Fraction: 0.06817
Policy Update Magnitude: 0.31209
Value Function Update Magnitude: 0.32002

Collected Steps per Second: 21,783.90980
Overall Steps per Second: 10,554.76134

Timestep Collection Time: 2.29711
Timestep Consumption Time: 2.44388
PPO Batch Consumption Time: 0.27907
Total Iteration Time: 4.74099

Cumulative Model Updates: 243,092
Cumulative Timesteps: 2,028,011,108

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 2028011108...
Checkpoint 2028011108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 70,069.74500
Policy Entropy: 2.39133
Value Function Loss: 0.01665

Mean KL Divergence: 0.00680
SB3 Clip Fraction: 0.06863
Policy Update Magnitude: 0.30395
Value Function Update Magnitude: 0.29462

Collected Steps per Second: 21,349.00309
Overall Steps per Second: 10,353.11688

Timestep Collection Time: 2.34418
Timestep Consumption Time: 2.48972
PPO Batch Consumption Time: 0.29205
Total Iteration Time: 4.83391

Cumulative Model Updates: 243,098
Cumulative Timesteps: 2,028,061,154

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84,883.86064
Policy Entropy: 2.39680
Value Function Loss: 0.01987

Mean KL Divergence: 0.00647
SB3 Clip Fraction: 0.06180
Policy Update Magnitude: 0.30899
Value Function Update Magnitude: 0.29854

Collected Steps per Second: 21,970.57480
Overall Steps per Second: 10,503.91586

Timestep Collection Time: 2.27714
Timestep Consumption Time: 2.48585
PPO Batch Consumption Time: 0.28994
Total Iteration Time: 4.76299

Cumulative Model Updates: 243,104
Cumulative Timesteps: 2,028,111,184

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2028111184...
Checkpoint 2028111184 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 85,877.23425
Policy Entropy: 2.40567
Value Function Loss: 0.01974

Mean KL Divergence: 0.00758
SB3 Clip Fraction: 0.07132
Policy Update Magnitude: 0.31154
Value Function Update Magnitude: 0.31596

Collected Steps per Second: 21,837.15558
Overall Steps per Second: 10,511.27135

Timestep Collection Time: 2.29105
Timestep Consumption Time: 2.46860
PPO Batch Consumption Time: 0.27722
Total Iteration Time: 4.75965

Cumulative Model Updates: 243,110
Cumulative Timesteps: 2,028,161,214

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76,569.78295
Policy Entropy: 2.37557
Value Function Loss: 0.01933

Mean KL Divergence: 0.00733
SB3 Clip Fraction: 0.06945
Policy Update Magnitude: 0.31745
Value Function Update Magnitude: 0.29483

Collected Steps per Second: 22,120.81770
Overall Steps per Second: 10,495.06779

Timestep Collection Time: 2.26122
Timestep Consumption Time: 2.50483
PPO Batch Consumption Time: 0.29227
Total Iteration Time: 4.76605

Cumulative Model Updates: 243,116
Cumulative Timesteps: 2,028,211,234

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2028211234...
Checkpoint 2028211234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 63,010.89766
Policy Entropy: 2.35334
Value Function Loss: 0.01547

Mean KL Divergence: 0.00735
SB3 Clip Fraction: 0.07025
Policy Update Magnitude: 0.31205
Value Function Update Magnitude: 0.28674

Collected Steps per Second: 21,895.28236
Overall Steps per Second: 10,505.31255

Timestep Collection Time: 2.28433
Timestep Consumption Time: 2.47669
PPO Batch Consumption Time: 0.27902
Total Iteration Time: 4.76102

Cumulative Model Updates: 243,122
Cumulative Timesteps: 2,028,261,250

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56,618.91235
Policy Entropy: 2.35255
Value Function Loss: 0.01615

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.06930
Policy Update Magnitude: 0.30968
Value Function Update Magnitude: 0.29848

Collected Steps per Second: 22,173.74317
Overall Steps per Second: 10,481.01910

Timestep Collection Time: 2.25591
Timestep Consumption Time: 2.51672
PPO Batch Consumption Time: 0.29444
Total Iteration Time: 4.77263

Cumulative Model Updates: 243,128
Cumulative Timesteps: 2,028,311,272

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2028311272...
Checkpoint 2028311272 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 113,234.16599
Policy Entropy: 2.36420
Value Function Loss: 0.01547

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.07208
Policy Update Magnitude: 0.30827
Value Function Update Magnitude: 0.30099

Collected Steps per Second: 21,577.88639
Overall Steps per Second: 10,547.06511

Timestep Collection Time: 2.31793
Timestep Consumption Time: 2.42424
PPO Batch Consumption Time: 0.27866
Total Iteration Time: 4.74217

Cumulative Model Updates: 243,134
Cumulative Timesteps: 2,028,361,288

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 104,153.00270
Policy Entropy: 2.37101
Value Function Loss: 0.01621

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.06891
Policy Update Magnitude: 0.30536
Value Function Update Magnitude: 0.29994

Collected Steps per Second: 21,896.75159
Overall Steps per Second: 10,610.47087

Timestep Collection Time: 2.28363
Timestep Consumption Time: 2.42908
PPO Batch Consumption Time: 0.27736
Total Iteration Time: 4.71270

Cumulative Model Updates: 243,140
Cumulative Timesteps: 2,028,411,292

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2028411292...
Checkpoint 2028411292 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 78,989.01516
Policy Entropy: 2.38101
Value Function Loss: 0.01588

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.07423
Policy Update Magnitude: 0.30249
Value Function Update Magnitude: 0.29392

Collected Steps per Second: 21,947.22966
Overall Steps per Second: 10,645.08717

Timestep Collection Time: 2.27865
Timestep Consumption Time: 2.41929
PPO Batch Consumption Time: 0.27744
Total Iteration Time: 4.69794

Cumulative Model Updates: 243,146
Cumulative Timesteps: 2,028,461,302

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67,243.10469
Policy Entropy: 2.37623
Value Function Loss: 0.01504

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.07938
Policy Update Magnitude: 0.30056
Value Function Update Magnitude: 0.28626

Collected Steps per Second: 21,620.42804
Overall Steps per Second: 10,366.58933

Timestep Collection Time: 2.31328
Timestep Consumption Time: 2.51126
PPO Batch Consumption Time: 0.29301
Total Iteration Time: 4.82454

Cumulative Model Updates: 243,152
Cumulative Timesteps: 2,028,511,316

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2028511316...
Checkpoint 2028511316 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 90,739.61308
Policy Entropy: 2.39682
Value Function Loss: 0.01525

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.07610
Policy Update Magnitude: 0.30127
Value Function Update Magnitude: 0.29419

Collected Steps per Second: 21,467.30456
Overall Steps per Second: 10,372.92902

Timestep Collection Time: 2.32922
Timestep Consumption Time: 2.49122
PPO Batch Consumption Time: 0.29037
Total Iteration Time: 4.82043

Cumulative Model Updates: 243,158
Cumulative Timesteps: 2,028,561,318

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67,452.79904
Policy Entropy: 2.38415
Value Function Loss: 0.01466

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.07501
Policy Update Magnitude: 0.29760
Value Function Update Magnitude: 0.28447

Collected Steps per Second: 21,696.57300
Overall Steps per Second: 10,426.07337

Timestep Collection Time: 2.30691
Timestep Consumption Time: 2.49375
PPO Batch Consumption Time: 0.29077
Total Iteration Time: 4.80066

Cumulative Model Updates: 243,164
Cumulative Timesteps: 2,028,611,370

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


Saving checkpoint 2028611370...
Checkpoint 2028611370 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 64,121.47753
Policy Entropy: 2.35859
Value Function Loss: 0.01760

Mean KL Divergence: 0.01120
SB3 Clip Fraction: 0.09088
Policy Update Magnitude: 0.30784
Value Function Update Magnitude: 0.24791

Collected Steps per Second: 21,400.96357
Overall Steps per Second: 10,474.70812

Timestep Collection Time: 2.33634
Timestep Consumption Time: 2.43706
PPO Batch Consumption Time: 0.27916
Total Iteration Time: 4.77340

Cumulative Model Updates: 243,170
Cumulative Timesteps: 2,028,661,370

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70,562.89025
Policy Entropy: 2.34650
Value Function Loss: 0.01835

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.08011
Policy Update Magnitude: 0.32183
Value Function Update Magnitude: 0.25312

Collected Steps per Second: 21,662.73297
Overall Steps per Second: 10,506.21903

Timestep Collection Time: 2.30940
Timestep Consumption Time: 2.45235
PPO Batch Consumption Time: 0.27816
Total Iteration Time: 4.76175

Cumulative Model Updates: 243,176
Cumulative Timesteps: 2,028,711,398

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2028711398...
Checkpoint 2028711398 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 70,866.14160
Policy Entropy: 2.36444
Value Function Loss: 0.01766

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.07226
Policy Update Magnitude: 0.31382
Value Function Update Magnitude: 0.27660

Collected Steps per Second: 22,107.29001
Overall Steps per Second: 10,578.69147

Timestep Collection Time: 2.26278
Timestep Consumption Time: 2.46597
PPO Batch Consumption Time: 0.27856
Total Iteration Time: 4.72875

Cumulative Model Updates: 243,182
Cumulative Timesteps: 2,028,761,422

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70,866.14160
Policy Entropy: 2.38518
Value Function Loss: 0.01417

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.07009
Policy Update Magnitude: 0.29657
Value Function Update Magnitude: 0.27443

Collected Steps per Second: 22,244.70195
Overall Steps per Second: 10,468.41577

Timestep Collection Time: 2.24845
Timestep Consumption Time: 2.52935
PPO Batch Consumption Time: 0.29179
Total Iteration Time: 4.77780

Cumulative Model Updates: 243,188
Cumulative Timesteps: 2,028,811,438

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2028811438...
Checkpoint 2028811438 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 71,384.24206
Policy Entropy: 2.38466
Value Function Loss: 0.01393

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.07880
Policy Update Magnitude: 0.28810
Value Function Update Magnitude: 0.25448

Collected Steps per Second: 21,966.95317
Overall Steps per Second: 10,649.37343

Timestep Collection Time: 2.27806
Timestep Consumption Time: 2.42100
PPO Batch Consumption Time: 0.27682
Total Iteration Time: 4.69906

Cumulative Model Updates: 243,194
Cumulative Timesteps: 2,028,861,480

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63,784.09076
Policy Entropy: 2.37568
Value Function Loss: 0.01374

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.08133
Policy Update Magnitude: 0.29644
Value Function Update Magnitude: 0.25742

Collected Steps per Second: 22,285.91437
Overall Steps per Second: 10,540.38160

Timestep Collection Time: 2.24420
Timestep Consumption Time: 2.50079
PPO Batch Consumption Time: 0.29298
Total Iteration Time: 4.74499

Cumulative Model Updates: 243,200
Cumulative Timesteps: 2,028,911,494

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2028911494...
Checkpoint 2028911494 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 66,541.95200
Policy Entropy: 2.36777
Value Function Loss: 0.01944

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.08480
Policy Update Magnitude: 0.31379
Value Function Update Magnitude: 0.31065

Collected Steps per Second: 22,054.67517
Overall Steps per Second: 10,546.03290

Timestep Collection Time: 2.26773
Timestep Consumption Time: 2.47472
PPO Batch Consumption Time: 0.28695
Total Iteration Time: 4.74245

Cumulative Model Updates: 243,206
Cumulative Timesteps: 2,028,961,508

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66,541.95200
Policy Entropy: 2.37186
Value Function Loss: 0.01707

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.08203
Policy Update Magnitude: 0.31798
Value Function Update Magnitude: 0.36597

Collected Steps per Second: 21,856.52316
Overall Steps per Second: 10,488.38363

Timestep Collection Time: 2.28829
Timestep Consumption Time: 2.48023
PPO Batch Consumption Time: 0.28904
Total Iteration Time: 4.76851

Cumulative Model Updates: 243,212
Cumulative Timesteps: 2,029,011,522

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2029011522...
Checkpoint 2029011522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,635.63780
Policy Entropy: 2.39126
Value Function Loss: 0.01660

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.08081
Policy Update Magnitude: 0.30647
Value Function Update Magnitude: 0.35859

Collected Steps per Second: 21,645.27823
Overall Steps per Second: 10,555.05537

Timestep Collection Time: 2.31145
Timestep Consumption Time: 2.42865
PPO Batch Consumption Time: 0.27807
Total Iteration Time: 4.74010

Cumulative Model Updates: 243,218
Cumulative Timesteps: 2,029,061,554

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65,968.40636
Policy Entropy: 2.38530
Value Function Loss: 0.01520

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.07115
Policy Update Magnitude: 0.30542
Value Function Update Magnitude: 0.33731

Collected Steps per Second: 21,364.14615
Overall Steps per Second: 10,476.74644

Timestep Collection Time: 2.34046
Timestep Consumption Time: 2.43220
PPO Batch Consumption Time: 0.27875
Total Iteration Time: 4.77266

Cumulative Model Updates: 243,224
Cumulative Timesteps: 2,029,111,556

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2029111556...
Checkpoint 2029111556 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 104,769.73431
Policy Entropy: 2.39089
Value Function Loss: 0.01519

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.07008
Policy Update Magnitude: 0.30952
Value Function Update Magnitude: 0.33326

Collected Steps per Second: 21,653.08492
Overall Steps per Second: 10,427.64122

Timestep Collection Time: 2.31126
Timestep Consumption Time: 2.48810
PPO Batch Consumption Time: 0.29016
Total Iteration Time: 4.79936

Cumulative Model Updates: 243,230
Cumulative Timesteps: 2,029,161,602

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 109,341.95979
Policy Entropy: 2.38376
Value Function Loss: 0.01653

Mean KL Divergence: 0.00759
SB3 Clip Fraction: 0.07119
Policy Update Magnitude: 0.31040
Value Function Update Magnitude: 0.33828

Collected Steps per Second: 21,336.66168
Overall Steps per Second: 10,330.80773

Timestep Collection Time: 2.34367
Timestep Consumption Time: 2.49681
PPO Batch Consumption Time: 0.29352
Total Iteration Time: 4.84047

Cumulative Model Updates: 243,236
Cumulative Timesteps: 2,029,211,608

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2029211608...
Checkpoint 2029211608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 72,832.36036
Policy Entropy: 2.38297
Value Function Loss: 0.01882

Mean KL Divergence: 0.00703
SB3 Clip Fraction: 0.06749
Policy Update Magnitude: 0.31206
Value Function Update Magnitude: 0.32424

Collected Steps per Second: 20,744.79067
Overall Steps per Second: 10,510.25601

Timestep Collection Time: 2.41073
Timestep Consumption Time: 2.34748
PPO Batch Consumption Time: 0.27872
Total Iteration Time: 4.75821

Cumulative Model Updates: 243,242
Cumulative Timesteps: 2,029,261,618

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52,250.81631
Policy Entropy: 2.36080
Value Function Loss: 0.02108

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.07532
Policy Update Magnitude: 0.32558
Value Function Update Magnitude: 0.32756

Collected Steps per Second: 20,870.75311
Overall Steps per Second: 10,496.88236

Timestep Collection Time: 2.39752
Timestep Consumption Time: 2.36942
PPO Batch Consumption Time: 0.27890
Total Iteration Time: 4.76694

Cumulative Model Updates: 243,248
Cumulative Timesteps: 2,029,311,656

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 2029311656...
Checkpoint 2029311656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84,454.43409
Policy Entropy: 2.37142
Value Function Loss: 0.02123

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.08353
Policy Update Magnitude: 0.32851
Value Function Update Magnitude: 0.33940

Collected Steps per Second: 21,363.68368
Overall Steps per Second: 10,535.81368

Timestep Collection Time: 2.34126
Timestep Consumption Time: 2.40616
PPO Batch Consumption Time: 0.27938
Total Iteration Time: 4.74743

Cumulative Model Updates: 243,254
Cumulative Timesteps: 2,029,361,674

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87,706.45190
Policy Entropy: 2.36416
Value Function Loss: 0.01923

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.08163
Policy Update Magnitude: 0.32475
Value Function Update Magnitude: 0.30814

Collected Steps per Second: 21,609.14032
Overall Steps per Second: 10,578.85969

Timestep Collection Time: 2.31559
Timestep Consumption Time: 2.41441
PPO Batch Consumption Time: 0.27919
Total Iteration Time: 4.73000

Cumulative Model Updates: 243,260
Cumulative Timesteps: 2,029,411,712

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 2029411712...
Checkpoint 2029411712 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 65,706.36879
Policy Entropy: 2.37431
Value Function Loss: 0.01761

Mean KL Divergence: 0.00746
SB3 Clip Fraction: 0.07069
Policy Update Magnitude: 0.32029
Value Function Update Magnitude: 0.27364

Collected Steps per Second: 21,812.63475
Overall Steps per Second: 10,621.68932

Timestep Collection Time: 2.29271
Timestep Consumption Time: 2.41558
PPO Batch Consumption Time: 0.27900
Total Iteration Time: 4.70829

Cumulative Model Updates: 243,266
Cumulative Timesteps: 2,029,461,722

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81,711.41936
Policy Entropy: 2.35514
Value Function Loss: 0.01832

Mean KL Divergence: 0.00760
SB3 Clip Fraction: 0.07089
Policy Update Magnitude: 0.32103
Value Function Update Magnitude: 0.29163

Collected Steps per Second: 21,927.96771
Overall Steps per Second: 10,472.68044

Timestep Collection Time: 2.28056
Timestep Consumption Time: 2.49453
PPO Batch Consumption Time: 0.29368
Total Iteration Time: 4.77509

Cumulative Model Updates: 243,272
Cumulative Timesteps: 2,029,511,730

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2029511730...
Checkpoint 2029511730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 63,028.08709
Policy Entropy: 2.36605
Value Function Loss: 0.01700

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.07443
Policy Update Magnitude: 0.32434
Value Function Update Magnitude: 0.28781

Collected Steps per Second: 21,999.21566
Overall Steps per Second: 10,615.53264

Timestep Collection Time: 2.27426
Timestep Consumption Time: 2.43883
PPO Batch Consumption Time: 0.27887
Total Iteration Time: 4.71309

Cumulative Model Updates: 243,278
Cumulative Timesteps: 2,029,561,762

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93,071.87158
Policy Entropy: 2.39375
Value Function Loss: 0.01700

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.07336
Policy Update Magnitude: 0.31953
Value Function Update Magnitude: 0.30720

Collected Steps per Second: 22,039.37132
Overall Steps per Second: 10,494.89533

Timestep Collection Time: 2.26876
Timestep Consumption Time: 2.49565
PPO Batch Consumption Time: 0.28808
Total Iteration Time: 4.76441

Cumulative Model Updates: 243,284
Cumulative Timesteps: 2,029,611,764

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2029611764...
Checkpoint 2029611764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 53,801.63415
Policy Entropy: 2.40899
Value Function Loss: 0.01581

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.08030
Policy Update Magnitude: 0.30588
Value Function Update Magnitude: 0.31542

Collected Steps per Second: 20,955.82478
Overall Steps per Second: 10,217.44368

Timestep Collection Time: 2.38654
Timestep Consumption Time: 2.50822
PPO Batch Consumption Time: 0.29236
Total Iteration Time: 4.89477

Cumulative Model Updates: 243,290
Cumulative Timesteps: 2,029,661,776

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47,374.21592
Policy Entropy: 2.38998
Value Function Loss: 0.01644

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.08158
Policy Update Magnitude: 0.29970
Value Function Update Magnitude: 0.33175

Collected Steps per Second: 21,424.74237
Overall Steps per Second: 10,446.15141

Timestep Collection Time: 2.33459
Timestep Consumption Time: 2.45358
PPO Batch Consumption Time: 0.27919
Total Iteration Time: 4.78817

Cumulative Model Updates: 243,296
Cumulative Timesteps: 2,029,711,794

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2029711794...
Checkpoint 2029711794 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,243.97365
Policy Entropy: 2.36698
Value Function Loss: 0.01637

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.07416
Policy Update Magnitude: 0.30608
Value Function Update Magnitude: 0.34089

Collected Steps per Second: 21,287.99566
Overall Steps per Second: 10,314.88633

Timestep Collection Time: 2.34977
Timestep Consumption Time: 2.49972
PPO Batch Consumption Time: 0.29292
Total Iteration Time: 4.84950

Cumulative Model Updates: 243,302
Cumulative Timesteps: 2,029,761,816

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,118.80147
Policy Entropy: 2.36414
Value Function Loss: 0.01796

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.08549
Policy Update Magnitude: 0.31415
Value Function Update Magnitude: 0.34422

Collected Steps per Second: 21,745.98497
Overall Steps per Second: 10,421.95739

Timestep Collection Time: 2.30029
Timestep Consumption Time: 2.49939
PPO Batch Consumption Time: 0.29371
Total Iteration Time: 4.79967

Cumulative Model Updates: 243,308
Cumulative Timesteps: 2,029,811,838

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2029811838...
Checkpoint 2029811838 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 52,905.55359
Policy Entropy: 2.37964
Value Function Loss: 0.01869

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.08082
Policy Update Magnitude: 0.31096
Value Function Update Magnitude: 0.35140

Collected Steps per Second: 21,024.14511
Overall Steps per Second: 10,564.94603

Timestep Collection Time: 2.37926
Timestep Consumption Time: 2.35545
PPO Batch Consumption Time: 0.27868
Total Iteration Time: 4.73471

Cumulative Model Updates: 243,314
Cumulative Timesteps: 2,029,861,860

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45,538.09889
Policy Entropy: 2.39194
Value Function Loss: 0.02060

Mean KL Divergence: 0.01136
SB3 Clip Fraction: 0.08693
Policy Update Magnitude: 0.31915
Value Function Update Magnitude: 0.34106

Collected Steps per Second: 20,786.34209
Overall Steps per Second: 10,428.87226

Timestep Collection Time: 2.40639
Timestep Consumption Time: 2.38991
PPO Batch Consumption Time: 0.27949
Total Iteration Time: 4.79630

Cumulative Model Updates: 243,320
Cumulative Timesteps: 2,029,911,880

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2029911880...
Checkpoint 2029911880 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 66,785.88975
Policy Entropy: 2.37772
Value Function Loss: 0.02160

Mean KL Divergence: 0.01397
SB3 Clip Fraction: 0.09099
Policy Update Magnitude: 0.32233
Value Function Update Magnitude: 0.32759

Collected Steps per Second: 21,448.72456
Overall Steps per Second: 10,603.65964

Timestep Collection Time: 2.33207
Timestep Consumption Time: 2.38517
PPO Batch Consumption Time: 0.27944
Total Iteration Time: 4.71724

Cumulative Model Updates: 243,326
Cumulative Timesteps: 2,029,961,900

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 64,906.15047
Policy Entropy: 2.39067
Value Function Loss: 0.01786

Mean KL Divergence: 0.01501
SB3 Clip Fraction: 0.09553
Policy Update Magnitude: 0.30577
Value Function Update Magnitude: 0.34787

Collected Steps per Second: 21,500.69798
Overall Steps per Second: 10,584.43100

Timestep Collection Time: 2.32551
Timestep Consumption Time: 2.39841
PPO Batch Consumption Time: 0.27792
Total Iteration Time: 4.72392

Cumulative Model Updates: 243,332
Cumulative Timesteps: 2,030,011,900

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2030011900...
Checkpoint 2030011900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,831.90958
Policy Entropy: 2.37571
Value Function Loss: 0.01738

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.08281
Policy Update Magnitude: 0.30082
Value Function Update Magnitude: 0.34098

Collected Steps per Second: 22,078.16181
Overall Steps per Second: 10,546.87030

Timestep Collection Time: 2.26604
Timestep Consumption Time: 2.47755
PPO Batch Consumption Time: 0.29115
Total Iteration Time: 4.74359

Cumulative Model Updates: 243,338
Cumulative Timesteps: 2,030,061,930

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,077.17957
Policy Entropy: 2.38486
Value Function Loss: 0.01584

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.09415
Policy Update Magnitude: 0.30243
Value Function Update Magnitude: 0.32666

Collected Steps per Second: 21,705.79694
Overall Steps per Second: 10,424.58196

Timestep Collection Time: 2.30353
Timestep Consumption Time: 2.49282
PPO Batch Consumption Time: 0.29181
Total Iteration Time: 4.79636

Cumulative Model Updates: 243,344
Cumulative Timesteps: 2,030,111,930

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2030111930...
Checkpoint 2030111930 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 62,939.50569
Policy Entropy: 2.38842
Value Function Loss: 0.01719

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.08099
Policy Update Magnitude: 0.29618
Value Function Update Magnitude: 0.33056

Collected Steps per Second: 19,956.13513
Overall Steps per Second: 10,150.40743

Timestep Collection Time: 2.50620
Timestep Consumption Time: 2.42109
PPO Batch Consumption Time: 0.27914
Total Iteration Time: 4.92729

Cumulative Model Updates: 243,350
Cumulative Timesteps: 2,030,161,944

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82,099.56878
Policy Entropy: 2.41079
Value Function Loss: 0.01644

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.08068
Policy Update Magnitude: 0.29320
Value Function Update Magnitude: 0.31413

Collected Steps per Second: 21,676.50785
Overall Steps per Second: 10,530.03299

Timestep Collection Time: 2.30775
Timestep Consumption Time: 2.44285
PPO Batch Consumption Time: 0.27902
Total Iteration Time: 4.75060

Cumulative Model Updates: 243,356
Cumulative Timesteps: 2,030,211,968

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2030211968...
Checkpoint 2030211968 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 108,515.18358
Policy Entropy: 2.42531
Value Function Loss: 0.01547

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.07951
Policy Update Magnitude: 0.28381
Value Function Update Magnitude: 0.29568

Collected Steps per Second: 21,456.53411
Overall Steps per Second: 10,348.08226

Timestep Collection Time: 2.33048
Timestep Consumption Time: 2.50172
PPO Batch Consumption Time: 0.29197
Total Iteration Time: 4.83220

Cumulative Model Updates: 243,362
Cumulative Timesteps: 2,030,261,972

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79,324.28688
Policy Entropy: 2.40381
Value Function Loss: 0.01521

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.07449
Policy Update Magnitude: 0.28368
Value Function Update Magnitude: 0.28405

Collected Steps per Second: 21,935.89323
Overall Steps per Second: 10,446.05629

Timestep Collection Time: 2.28019
Timestep Consumption Time: 2.50803
PPO Batch Consumption Time: 0.29217
Total Iteration Time: 4.78822

Cumulative Model Updates: 243,368
Cumulative Timesteps: 2,030,311,990

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2030311990...
Checkpoint 2030311990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 53,945.60975
Policy Entropy: 2.39582
Value Function Loss: 0.01533

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.07654
Policy Update Magnitude: 0.29862
Value Function Update Magnitude: 0.28910

Collected Steps per Second: 21,845.24824
Overall Steps per Second: 10,493.26023

Timestep Collection Time: 2.28956
Timestep Consumption Time: 2.47693
PPO Batch Consumption Time: 0.27924
Total Iteration Time: 4.76649

Cumulative Model Updates: 243,374
Cumulative Timesteps: 2,030,362,006

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,030.37614
Policy Entropy: 2.38168
Value Function Loss: 0.01651

Mean KL Divergence: 0.00756
SB3 Clip Fraction: 0.07147
Policy Update Magnitude: 0.31029
Value Function Update Magnitude: 0.27297

Collected Steps per Second: 22,357.43625
Overall Steps per Second: 10,521.72130

Timestep Collection Time: 2.23675
Timestep Consumption Time: 2.51608
PPO Batch Consumption Time: 0.29129
Total Iteration Time: 4.75283

Cumulative Model Updates: 243,380
Cumulative Timesteps: 2,030,412,014

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2030412014...
Checkpoint 2030412014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 51,881.50088
Policy Entropy: 2.39518
Value Function Loss: 0.01629

Mean KL Divergence: 0.00759
SB3 Clip Fraction: 0.06897
Policy Update Magnitude: 0.31461
Value Function Update Magnitude: 0.25747

Collected Steps per Second: 21,818.24589
Overall Steps per Second: 10,575.52271

Timestep Collection Time: 2.29285
Timestep Consumption Time: 2.43751
PPO Batch Consumption Time: 0.27915
Total Iteration Time: 4.73036

Cumulative Model Updates: 243,386
Cumulative Timesteps: 2,030,462,040

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 96,336.46019
Policy Entropy: 2.38986
Value Function Loss: 0.01593

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.07360
Policy Update Magnitude: 0.30521
Value Function Update Magnitude: 0.24555

Collected Steps per Second: 22,202.29667
Overall Steps per Second: 10,473.27309

Timestep Collection Time: 2.25283
Timestep Consumption Time: 2.52295
PPO Batch Consumption Time: 0.29467
Total Iteration Time: 4.77578

Cumulative Model Updates: 243,392
Cumulative Timesteps: 2,030,512,058

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2030512058...
Checkpoint 2030512058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 67,522.50439
Policy Entropy: 2.39901
Value Function Loss: 0.01531

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.07168
Policy Update Magnitude: 0.29758
Value Function Update Magnitude: 0.28080

Collected Steps per Second: 21,471.76019
Overall Steps per Second: 10,355.70512

Timestep Collection Time: 2.33004
Timestep Consumption Time: 2.50112
PPO Batch Consumption Time: 0.29103
Total Iteration Time: 4.83115

Cumulative Model Updates: 243,398
Cumulative Timesteps: 2,030,562,088

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 72,965.74756
Policy Entropy: 2.37195
Value Function Loss: 0.01557

Mean KL Divergence: 0.00670
SB3 Clip Fraction: 0.06275
Policy Update Magnitude: 0.30151
Value Function Update Magnitude: 0.32919

Collected Steps per Second: 22,178.70071
Overall Steps per Second: 10,676.11107

Timestep Collection Time: 2.25442
Timestep Consumption Time: 2.42894
PPO Batch Consumption Time: 0.27899
Total Iteration Time: 4.68335

Cumulative Model Updates: 243,404
Cumulative Timesteps: 2,030,612,088

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2030612088...
Checkpoint 2030612088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 93,687.22711
Policy Entropy: 2.36108
Value Function Loss: 0.01740

Mean KL Divergence: 0.00677
SB3 Clip Fraction: 0.06495
Policy Update Magnitude: 0.30954
Value Function Update Magnitude: 0.30719

Collected Steps per Second: 21,868.25780
Overall Steps per Second: 10,637.09879

Timestep Collection Time: 2.28852
Timestep Consumption Time: 2.41633
PPO Batch Consumption Time: 0.27814
Total Iteration Time: 4.70485

Cumulative Model Updates: 243,410
Cumulative Timesteps: 2,030,662,134

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63,766.06887
Policy Entropy: 2.37678
Value Function Loss: 0.01730

Mean KL Divergence: 0.00734
SB3 Clip Fraction: 0.07060
Policy Update Magnitude: 0.30961
Value Function Update Magnitude: 0.27594

Collected Steps per Second: 21,614.06227
Overall Steps per Second: 10,521.83825

Timestep Collection Time: 2.31451
Timestep Consumption Time: 2.43998
PPO Batch Consumption Time: 0.27954
Total Iteration Time: 4.75449

Cumulative Model Updates: 243,416
Cumulative Timesteps: 2,030,712,160

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2030712160...
Checkpoint 2030712160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,517.45373
Policy Entropy: 2.40241
Value Function Loss: 0.01761

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.08017
Policy Update Magnitude: 0.30850
Value Function Update Magnitude: 0.28880

Collected Steps per Second: 21,111.03436
Overall Steps per Second: 10,237.83107

Timestep Collection Time: 2.36852
Timestep Consumption Time: 2.51552
PPO Batch Consumption Time: 0.29340
Total Iteration Time: 4.88404

Cumulative Model Updates: 243,422
Cumulative Timesteps: 2,030,762,162

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76,855.32176
Policy Entropy: 2.39785
Value Function Loss: 0.01648

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.08547
Policy Update Magnitude: 0.30445
Value Function Update Magnitude: 0.31141

Collected Steps per Second: 21,718.46426
Overall Steps per Second: 10,448.25917

Timestep Collection Time: 2.30412
Timestep Consumption Time: 2.48538
PPO Batch Consumption Time: 0.28886
Total Iteration Time: 4.78951

Cumulative Model Updates: 243,428
Cumulative Timesteps: 2,030,812,204

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 2030812204...
Checkpoint 2030812204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 94,587.64085
Policy Entropy: 2.35499
Value Function Loss: 0.01677

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.08377
Policy Update Magnitude: 0.30717
Value Function Update Magnitude: 0.31640

Collected Steps per Second: 21,334.34514
Overall Steps per Second: 10,315.47303

Timestep Collection Time: 2.34458
Timestep Consumption Time: 2.50445
PPO Batch Consumption Time: 0.29271
Total Iteration Time: 4.84903

Cumulative Model Updates: 243,434
Cumulative Timesteps: 2,030,862,224

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83,181.69710
Policy Entropy: 2.34580
Value Function Loss: 0.01547

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.07705
Policy Update Magnitude: 0.31134
Value Function Update Magnitude: 0.31573

Collected Steps per Second: 21,612.62122
Overall Steps per Second: 10,353.37799

Timestep Collection Time: 2.31485
Timestep Consumption Time: 2.51739
PPO Batch Consumption Time: 0.29424
Total Iteration Time: 4.83224

Cumulative Model Updates: 243,440
Cumulative Timesteps: 2,030,912,254

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2030912254...
Checkpoint 2030912254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 100,989.92751
Policy Entropy: 2.36317
Value Function Loss: 0.01499

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.07342
Policy Update Magnitude: 0.30378
Value Function Update Magnitude: 0.31884

Collected Steps per Second: 21,589.52966
Overall Steps per Second: 10,332.96702

Timestep Collection Time: 2.31659
Timestep Consumption Time: 2.52365
PPO Batch Consumption Time: 0.29112
Total Iteration Time: 4.84024

Cumulative Model Updates: 243,446
Cumulative Timesteps: 2,030,962,268

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84,138.07724
Policy Entropy: 2.37724
Value Function Loss: 0.01457

Mean KL Divergence: 0.00733
SB3 Clip Fraction: 0.07011
Policy Update Magnitude: 0.29971
Value Function Update Magnitude: 0.30717

Collected Steps per Second: 22,398.99915
Overall Steps per Second: 10,680.74475

Timestep Collection Time: 2.23394
Timestep Consumption Time: 2.45094
PPO Batch Consumption Time: 0.27825
Total Iteration Time: 4.68488

Cumulative Model Updates: 243,452
Cumulative Timesteps: 2,031,012,306

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 2031012306...
Checkpoint 2031012306 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 65,733.87850
Policy Entropy: 2.38963
Value Function Loss: 0.01530

Mean KL Divergence: 0.00678
SB3 Clip Fraction: 0.06818
Policy Update Magnitude: 0.30195
Value Function Update Magnitude: 0.28685

Collected Steps per Second: 21,208.23055
Overall Steps per Second: 10,614.45843

Timestep Collection Time: 2.35833
Timestep Consumption Time: 2.35373
PPO Batch Consumption Time: 0.27922
Total Iteration Time: 4.71206

Cumulative Model Updates: 243,458
Cumulative Timesteps: 2,031,062,322

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 106,756.76474
Policy Entropy: 2.37034
Value Function Loss: 0.01677

Mean KL Divergence: 0.00673
SB3 Clip Fraction: 0.06549
Policy Update Magnitude: 0.30826
Value Function Update Magnitude: 0.28865

Collected Steps per Second: 21,297.98542
Overall Steps per Second: 10,500.72781

Timestep Collection Time: 2.34792
Timestep Consumption Time: 2.41422
PPO Batch Consumption Time: 0.28828
Total Iteration Time: 4.76215

Cumulative Model Updates: 243,464
Cumulative Timesteps: 2,031,112,328

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2031112328...
Checkpoint 2031112328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 88,052.54018
Policy Entropy: 2.39223
Value Function Loss: 0.01765

Mean KL Divergence: 0.00698
SB3 Clip Fraction: 0.06799
Policy Update Magnitude: 0.31521
Value Function Update Magnitude: 0.27590

Collected Steps per Second: 21,377.92013
Overall Steps per Second: 10,648.04362

Timestep Collection Time: 2.34064
Timestep Consumption Time: 2.35863
PPO Batch Consumption Time: 0.27928
Total Iteration Time: 4.69927

Cumulative Model Updates: 243,470
Cumulative Timesteps: 2,031,162,366

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53,751.43491
Policy Entropy: 2.37882
Value Function Loss: 0.01800

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.08003
Policy Update Magnitude: 0.31284
Value Function Update Magnitude: 0.26755

Collected Steps per Second: 21,528.48730
Overall Steps per Second: 10,451.12192

Timestep Collection Time: 2.32325
Timestep Consumption Time: 2.46246
PPO Batch Consumption Time: 0.28614
Total Iteration Time: 4.78571

Cumulative Model Updates: 243,476
Cumulative Timesteps: 2,031,212,382

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2031212382...
Checkpoint 2031212382 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 65,347.72613
Policy Entropy: 2.38176
Value Function Loss: 0.01999

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.07929
Policy Update Magnitude: 0.31487
Value Function Update Magnitude: 0.30896

Collected Steps per Second: 21,812.26697
Overall Steps per Second: 10,656.59229

Timestep Collection Time: 2.29229
Timestep Consumption Time: 2.39964
PPO Batch Consumption Time: 0.27785
Total Iteration Time: 4.69193

Cumulative Model Updates: 243,482
Cumulative Timesteps: 2,031,262,382

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 69,413.39166
Policy Entropy: 2.40166
Value Function Loss: 0.01881

Mean KL Divergence: 0.01058
SB3 Clip Fraction: 0.09233
Policy Update Magnitude: 0.31058
Value Function Update Magnitude: 0.34374

Collected Steps per Second: 21,706.34526
Overall Steps per Second: 10,499.13170

Timestep Collection Time: 2.30440
Timestep Consumption Time: 2.45981
PPO Batch Consumption Time: 0.28854
Total Iteration Time: 4.76420

Cumulative Model Updates: 243,488
Cumulative Timesteps: 2,031,312,402

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2031312402...
Checkpoint 2031312402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 74,934.48025
Policy Entropy: 2.39660
Value Function Loss: 0.01894

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.08046
Policy Update Magnitude: 0.30812
Value Function Update Magnitude: 0.33753

Collected Steps per Second: 21,216.99607
Overall Steps per Second: 10,401.16261

Timestep Collection Time: 2.35811
Timestep Consumption Time: 2.45212
PPO Batch Consumption Time: 0.28910
Total Iteration Time: 4.81023

Cumulative Model Updates: 243,494
Cumulative Timesteps: 2,031,362,434

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46,909.02410
Policy Entropy: 2.37141
Value Function Loss: 0.01877

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.07287
Policy Update Magnitude: 0.31313
Value Function Update Magnitude: 0.31714

Collected Steps per Second: 21,712.47592
Overall Steps per Second: 10,455.47655

Timestep Collection Time: 2.30347
Timestep Consumption Time: 2.48005
PPO Batch Consumption Time: 0.28978
Total Iteration Time: 4.78352

Cumulative Model Updates: 243,500
Cumulative Timesteps: 2,031,412,448

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2031412448...
Checkpoint 2031412448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,358.16914
Policy Entropy: 2.35856
Value Function Loss: 0.01931

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.07163
Policy Update Magnitude: 0.32350
Value Function Update Magnitude: 0.30586

Collected Steps per Second: 21,318.46248
Overall Steps per Second: 10,482.50949

Timestep Collection Time: 2.34538
Timestep Consumption Time: 2.42447
PPO Batch Consumption Time: 0.27724
Total Iteration Time: 4.76985

Cumulative Model Updates: 243,506
Cumulative Timesteps: 2,031,462,448

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88,340.53788
Policy Entropy: 2.37516
Value Function Loss: 0.01843

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.07952
Policy Update Magnitude: 0.32137
Value Function Update Magnitude: 0.32078

Collected Steps per Second: 22,009.52130
Overall Steps per Second: 10,412.69759

Timestep Collection Time: 2.27293
Timestep Consumption Time: 2.53140
PPO Batch Consumption Time: 0.29340
Total Iteration Time: 4.80433

Cumulative Model Updates: 243,512
Cumulative Timesteps: 2,031,512,474

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2031512474...
Checkpoint 2031512474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 60,035.70095
Policy Entropy: 2.40067
Value Function Loss: 0.01847

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.07311
Policy Update Magnitude: 0.31994
Value Function Update Magnitude: 0.32241

Collected Steps per Second: 21,792.17619
Overall Steps per Second: 10,515.89253

Timestep Collection Time: 2.29486
Timestep Consumption Time: 2.46080
PPO Batch Consumption Time: 0.27820
Total Iteration Time: 4.75566

Cumulative Model Updates: 243,518
Cumulative Timesteps: 2,031,562,484

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51,210.83312
Policy Entropy: 2.39212
Value Function Loss: 0.01926

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.07757
Policy Update Magnitude: 0.32196
Value Function Update Magnitude: 0.30510

Collected Steps per Second: 22,015.40727
Overall Steps per Second: 10,606.88387

Timestep Collection Time: 2.27368
Timestep Consumption Time: 2.44552
PPO Batch Consumption Time: 0.27813
Total Iteration Time: 4.71920

Cumulative Model Updates: 243,524
Cumulative Timesteps: 2,031,612,540

Timesteps Collected: 50,056
--------END ITERATION REPORT--------


Saving checkpoint 2031612540...
Checkpoint 2031612540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46,648.06287
Policy Entropy: 2.37371
Value Function Loss: 0.01809

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.07940
Policy Update Magnitude: 0.31690
Value Function Update Magnitude: 0.32064

Collected Steps per Second: 21,952.11994
Overall Steps per Second: 10,637.47698

Timestep Collection Time: 2.27832
Timestep Consumption Time: 2.42336
PPO Batch Consumption Time: 0.27764
Total Iteration Time: 4.70168

Cumulative Model Updates: 243,530
Cumulative Timesteps: 2,031,662,554

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,539.71331
Policy Entropy: 2.38644
Value Function Loss: 0.01760

Mean KL Divergence: 0.00720
SB3 Clip Fraction: 0.06606
Policy Update Magnitude: 0.30723
Value Function Update Magnitude: 0.30484

Collected Steps per Second: 22,232.02729
Overall Steps per Second: 10,521.35397

Timestep Collection Time: 2.25054
Timestep Consumption Time: 2.50493
PPO Batch Consumption Time: 0.29236
Total Iteration Time: 4.75547

Cumulative Model Updates: 243,536
Cumulative Timesteps: 2,031,712,588

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 2031712588...
Checkpoint 2031712588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,559.61605
Policy Entropy: 2.38651
Value Function Loss: 0.01563

Mean KL Divergence: 0.00682
SB3 Clip Fraction: 0.06398
Policy Update Magnitude: 0.30439
Value Function Update Magnitude: 0.30179

Collected Steps per Second: 21,901.20727
Overall Steps per Second: 10,532.60417

Timestep Collection Time: 2.28407
Timestep Consumption Time: 2.46537
PPO Batch Consumption Time: 0.28556
Total Iteration Time: 4.74944

Cumulative Model Updates: 243,542
Cumulative Timesteps: 2,031,762,612

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,895.43873
Policy Entropy: 2.41171
Value Function Loss: 0.01570

Mean KL Divergence: 0.00654
SB3 Clip Fraction: 0.06432
Policy Update Magnitude: 0.29490
Value Function Update Magnitude: 0.29760

Collected Steps per Second: 22,357.85169
Overall Steps per Second: 10,557.59864

Timestep Collection Time: 2.23698
Timestep Consumption Time: 2.50027
PPO Batch Consumption Time: 0.29184
Total Iteration Time: 4.73725

Cumulative Model Updates: 243,548
Cumulative Timesteps: 2,031,812,626

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2031812626...
Checkpoint 2031812626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 59,659.22397
Policy Entropy: 2.38530
Value Function Loss: 0.01687

Mean KL Divergence: 0.00650
SB3 Clip Fraction: 0.06339
Policy Update Magnitude: 0.30365
Value Function Update Magnitude: 0.28931

Collected Steps per Second: 21,460.65350
Overall Steps per Second: 10,512.12614

Timestep Collection Time: 2.33096
Timestep Consumption Time: 2.42773
PPO Batch Consumption Time: 0.27834
Total Iteration Time: 4.75869

Cumulative Model Updates: 243,554
Cumulative Timesteps: 2,031,862,650

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61,786.05638
Policy Entropy: 2.37165
Value Function Loss: 0.01616

Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.07686
Policy Update Magnitude: 0.31075
Value Function Update Magnitude: 0.28095

Collected Steps per Second: 21,056.47953
Overall Steps per Second: 10,471.71252

Timestep Collection Time: 2.37666
Timestep Consumption Time: 2.40231
PPO Batch Consumption Time: 0.28629
Total Iteration Time: 4.77897

Cumulative Model Updates: 243,560
Cumulative Timesteps: 2,031,912,694

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 2031912694...
Checkpoint 2031912694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 79,973.90761
Policy Entropy: 2.37062
Value Function Loss: 0.01867

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.07936
Policy Update Magnitude: 0.31278
Value Function Update Magnitude: 0.29385

Collected Steps per Second: 20,436.51220
Overall Steps per Second: 10,209.67010

Timestep Collection Time: 2.44778
Timestep Consumption Time: 2.45189
PPO Batch Consumption Time: 0.29567
Total Iteration Time: 4.89967

Cumulative Model Updates: 243,566
Cumulative Timesteps: 2,031,962,718

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63,087.65912
Policy Entropy: 2.41337
Value Function Loss: 0.01688

Mean KL Divergence: 0.00698
SB3 Clip Fraction: 0.06595
Policy Update Magnitude: 0.31395
Value Function Update Magnitude: 0.26364

Collected Steps per Second: 21,285.04636
Overall Steps per Second: 10,442.56684

Timestep Collection Time: 2.34907
Timestep Consumption Time: 2.43903
PPO Batch Consumption Time: 0.29045
Total Iteration Time: 4.78809

Cumulative Model Updates: 243,572
Cumulative Timesteps: 2,032,012,718

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2032012718...
Checkpoint 2032012718 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84,696.08283
Policy Entropy: 2.42455
Value Function Loss: 0.01861

Mean KL Divergence: 0.00770
SB3 Clip Fraction: 0.07240
Policy Update Magnitude: 0.30547
Value Function Update Magnitude: 0.28948

Collected Steps per Second: 20,789.07268
Overall Steps per Second: 10,234.67382

Timestep Collection Time: 2.40549
Timestep Consumption Time: 2.48064
PPO Batch Consumption Time: 0.28972
Total Iteration Time: 4.88614

Cumulative Model Updates: 243,578
Cumulative Timesteps: 2,032,062,726

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63,127.84681
Policy Entropy: 2.43320
Value Function Loss: 0.01522

Mean KL Divergence: 0.00782
SB3 Clip Fraction: 0.07328
Policy Update Magnitude: 0.29935
Value Function Update Magnitude: 0.30795

Collected Steps per Second: 22,424.72755
Overall Steps per Second: 10,636.40859

Timestep Collection Time: 2.23173
Timestep Consumption Time: 2.47343
PPO Batch Consumption Time: 0.28876
Total Iteration Time: 4.70516

Cumulative Model Updates: 243,584
Cumulative Timesteps: 2,032,112,772

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 2032112772...
Checkpoint 2032112772 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 53,153.41582
Policy Entropy: 2.40894
Value Function Loss: 0.01489

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.07276
Policy Update Magnitude: 0.29092
Value Function Update Magnitude: 0.30167

Collected Steps per Second: 21,706.47402
Overall Steps per Second: 10,420.94508

Timestep Collection Time: 2.30383
Timestep Consumption Time: 2.49497
PPO Batch Consumption Time: 0.29305
Total Iteration Time: 4.79880

Cumulative Model Updates: 243,590
Cumulative Timesteps: 2,032,162,780

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47,680.46230
Policy Entropy: 2.39821
Value Function Loss: 0.01453

Mean KL Divergence: 0.00690
SB3 Clip Fraction: 0.06718
Policy Update Magnitude: 0.29436
Value Function Update Magnitude: 0.27106

Collected Steps per Second: 22,331.27694
Overall Steps per Second: 10,544.18974

Timestep Collection Time: 2.24045
Timestep Consumption Time: 2.50454
PPO Batch Consumption Time: 0.29285
Total Iteration Time: 4.74498

Cumulative Model Updates: 243,596
Cumulative Timesteps: 2,032,212,812

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2032212812...
Checkpoint 2032212812 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 77,861.48091
Policy Entropy: 2.37729
Value Function Loss: 0.01593

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.07437
Policy Update Magnitude: 0.29894
Value Function Update Magnitude: 0.25861

Collected Steps per Second: 21,969.54576
Overall Steps per Second: 10,648.05993

Timestep Collection Time: 2.27761
Timestep Consumption Time: 2.42165
PPO Batch Consumption Time: 0.27721
Total Iteration Time: 4.69926

Cumulative Model Updates: 243,602
Cumulative Timesteps: 2,032,262,850

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66,762.03487
Policy Entropy: 2.38938
Value Function Loss: 0.01796

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.08017
Policy Update Magnitude: 0.30795
Value Function Update Magnitude: 0.30837

Collected Steps per Second: 22,325.89524
Overall Steps per Second: 10,742.00251

Timestep Collection Time: 2.24081
Timestep Consumption Time: 2.41643
PPO Batch Consumption Time: 0.27895
Total Iteration Time: 4.65723

Cumulative Model Updates: 243,608
Cumulative Timesteps: 2,032,312,878

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2032312878...
Checkpoint 2032312878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 64,964.16701
Policy Entropy: 2.41526
Value Function Loss: 0.01708

Mean KL Divergence: 0.00737
SB3 Clip Fraction: 0.06998
Policy Update Magnitude: 0.30539
Value Function Update Magnitude: 0.31250

Collected Steps per Second: 21,395.77858
Overall Steps per Second: 10,326.91997

Timestep Collection Time: 2.33803
Timestep Consumption Time: 2.50601
PPO Batch Consumption Time: 0.29237
Total Iteration Time: 4.84404

Cumulative Model Updates: 243,614
Cumulative Timesteps: 2,032,362,902

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52,359.34143
Policy Entropy: 2.41839
Value Function Loss: 0.01578

Mean KL Divergence: 0.00735
SB3 Clip Fraction: 0.07000
Policy Update Magnitude: 0.29082
Value Function Update Magnitude: 0.28177

Collected Steps per Second: 21,516.96959
Overall Steps per Second: 10,438.38635

Timestep Collection Time: 2.32449
Timestep Consumption Time: 2.46705
PPO Batch Consumption Time: 0.28635
Total Iteration Time: 4.79155

Cumulative Model Updates: 243,620
Cumulative Timesteps: 2,032,412,918

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2032412918...
Checkpoint 2032412918 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 52,359.34143
Policy Entropy: 2.40723
Value Function Loss: 0.01338

Mean KL Divergence: 0.00619
SB3 Clip Fraction: 0.05998
Policy Update Magnitude: 0.27540
Value Function Update Magnitude: 0.25455

Collected Steps per Second: 21,334.60034
Overall Steps per Second: 10,383.16633

Timestep Collection Time: 2.34380
Timestep Consumption Time: 2.47207
PPO Batch Consumption Time: 0.28927
Total Iteration Time: 4.81587

Cumulative Model Updates: 243,626
Cumulative Timesteps: 2,032,462,922

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57,020.60480
Policy Entropy: 2.39844
Value Function Loss: 0.01336

Mean KL Divergence: 0.00632
SB3 Clip Fraction: 0.05965
Policy Update Magnitude: 0.28540
Value Function Update Magnitude: 0.25709

Collected Steps per Second: 21,391.70051
Overall Steps per Second: 10,655.60489

Timestep Collection Time: 2.33876
Timestep Consumption Time: 2.35642
PPO Batch Consumption Time: 0.27877
Total Iteration Time: 4.69518

Cumulative Model Updates: 243,632
Cumulative Timesteps: 2,032,512,952

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2032512952...
Checkpoint 2032512952 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 85,805.05230
Policy Entropy: 2.37390
Value Function Loss: 0.01427

Mean KL Divergence: 0.00757
SB3 Clip Fraction: 0.07273
Policy Update Magnitude: 0.29611
Value Function Update Magnitude: 0.25590

Collected Steps per Second: 20,863.49867
Overall Steps per Second: 10,369.06050

Timestep Collection Time: 2.39672
Timestep Consumption Time: 2.42570
PPO Batch Consumption Time: 0.29187
Total Iteration Time: 4.82242

Cumulative Model Updates: 243,638
Cumulative Timesteps: 2,032,562,956

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89,716.02188
Policy Entropy: 2.36523
Value Function Loss: 0.01721

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.07550
Policy Update Magnitude: 0.31357
Value Function Update Magnitude: 0.28244

Collected Steps per Second: 21,652.36774
Overall Steps per Second: 10,692.29283

Timestep Collection Time: 2.31032
Timestep Consumption Time: 2.36819
PPO Batch Consumption Time: 0.27793
Total Iteration Time: 4.67851

Cumulative Model Updates: 243,644
Cumulative Timesteps: 2,032,612,980

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2032612980...
Checkpoint 2032612980 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 70,023.92726
Policy Entropy: 2.36436
Value Function Loss: 0.01755

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.08917
Policy Update Magnitude: 0.31847
Value Function Update Magnitude: 0.30651

Collected Steps per Second: 20,971.67708
Overall Steps per Second: 10,256.55726

Timestep Collection Time: 2.38512
Timestep Consumption Time: 2.49176
PPO Batch Consumption Time: 0.29249
Total Iteration Time: 4.87688

Cumulative Model Updates: 243,650
Cumulative Timesteps: 2,032,663,000

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70,023.92726
Policy Entropy: 2.36867
Value Function Loss: 0.01613

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.08519
Policy Update Magnitude: 0.30652
Value Function Update Magnitude: 0.29097

Collected Steps per Second: 22,195.93677
Overall Steps per Second: 10,569.53576

Timestep Collection Time: 2.25330
Timestep Consumption Time: 2.47861
PPO Batch Consumption Time: 0.29304
Total Iteration Time: 4.73190

Cumulative Model Updates: 243,656
Cumulative Timesteps: 2,032,713,014

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2032713014...
Checkpoint 2032713014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 59,114.07718
Policy Entropy: 2.38767
Value Function Loss: 0.01432

Mean KL Divergence: 0.00758
SB3 Clip Fraction: 0.07450
Policy Update Magnitude: 0.29153
Value Function Update Magnitude: 0.26631

Collected Steps per Second: 21,818.80958
Overall Steps per Second: 10,509.18320

Timestep Collection Time: 2.29270
Timestep Consumption Time: 2.46733
PPO Batch Consumption Time: 0.28776
Total Iteration Time: 4.76003

Cumulative Model Updates: 243,662
Cumulative Timesteps: 2,032,763,038

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52,444.94817
Policy Entropy: 2.41251
Value Function Loss: 0.01233

Mean KL Divergence: 0.00718
SB3 Clip Fraction: 0.07015
Policy Update Magnitude: 0.28252
Value Function Update Magnitude: 0.26531

Collected Steps per Second: 22,006.44390
Overall Steps per Second: 10,493.15016

Timestep Collection Time: 2.27297
Timestep Consumption Time: 2.49395
PPO Batch Consumption Time: 0.28908
Total Iteration Time: 4.76692

Cumulative Model Updates: 243,668
Cumulative Timesteps: 2,032,813,058

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2032813058...
Checkpoint 2032813058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 81,353.80967
Policy Entropy: 2.42304
Value Function Loss: 0.01559

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.07594
Policy Update Magnitude: 0.29038
Value Function Update Magnitude: 0.26407

Collected Steps per Second: 21,901.58231
Overall Steps per Second: 10,606.49519

Timestep Collection Time: 2.28358
Timestep Consumption Time: 2.43183
PPO Batch Consumption Time: 0.27902
Total Iteration Time: 4.71541

Cumulative Model Updates: 243,674
Cumulative Timesteps: 2,032,863,072

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55,994.12750
Policy Entropy: 2.42700
Value Function Loss: 0.01826

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.08746
Policy Update Magnitude: 0.31601
Value Function Update Magnitude: 0.28444

Collected Steps per Second: 21,857.00655
Overall Steps per Second: 10,469.48825

Timestep Collection Time: 2.28842
Timestep Consumption Time: 2.48908
PPO Batch Consumption Time: 0.28897
Total Iteration Time: 4.77750

Cumulative Model Updates: 243,680
Cumulative Timesteps: 2,032,913,090

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2032913090...
Checkpoint 2032913090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 58,824.76604
Policy Entropy: 2.41422
Value Function Loss: 0.01939

Mean KL Divergence: 0.01124
SB3 Clip Fraction: 0.09704
Policy Update Magnitude: 0.32000
Value Function Update Magnitude: 0.28323

Collected Steps per Second: 20,729.43239
Overall Steps per Second: 10,168.92096

Timestep Collection Time: 2.41348
Timestep Consumption Time: 2.50642
PPO Batch Consumption Time: 0.28944
Total Iteration Time: 4.91989

Cumulative Model Updates: 243,686
Cumulative Timesteps: 2,032,963,120

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66,772.41304
Policy Entropy: 2.39987
Value Function Loss: 0.01936

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.07733
Policy Update Magnitude: 0.31792
Value Function Update Magnitude: 0.32981

Collected Steps per Second: 21,534.45521
Overall Steps per Second: 10,489.86605

Timestep Collection Time: 2.32279
Timestep Consumption Time: 2.44562
PPO Batch Consumption Time: 0.27977
Total Iteration Time: 4.76841

Cumulative Model Updates: 243,692
Cumulative Timesteps: 2,033,013,140

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2033013140...
Checkpoint 2033013140 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 74,249.83906
Policy Entropy: 2.41229
Value Function Loss: 0.02058

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.07205
Policy Update Magnitude: 0.32516
Value Function Update Magnitude: 0.37010

Collected Steps per Second: 21,634.82119
Overall Steps per Second: 10,580.34777

Timestep Collection Time: 2.31146
Timestep Consumption Time: 2.41504
PPO Batch Consumption Time: 0.27821
Total Iteration Time: 4.72650

Cumulative Model Updates: 243,698
Cumulative Timesteps: 2,033,063,148

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83,653.59012
Policy Entropy: 2.40002
Value Function Loss: 0.02049

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.07822
Policy Update Magnitude: 0.32578
Value Function Update Magnitude: 0.38030

Collected Steps per Second: 21,870.57072
Overall Steps per Second: 10,509.11373

Timestep Collection Time: 2.28755
Timestep Consumption Time: 2.47308
PPO Batch Consumption Time: 0.27992
Total Iteration Time: 4.76063

Cumulative Model Updates: 243,704
Cumulative Timesteps: 2,033,113,178

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2033113178...
Checkpoint 2033113178 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 53,751.54717
Policy Entropy: 2.40383
Value Function Loss: 0.02033

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.07473
Policy Update Magnitude: 0.31999
Value Function Update Magnitude: 0.38591

Collected Steps per Second: 22,044.22863
Overall Steps per Second: 10,576.08133

Timestep Collection Time: 2.26862
Timestep Consumption Time: 2.45997
PPO Batch Consumption Time: 0.27943
Total Iteration Time: 4.72859

Cumulative Model Updates: 243,710
Cumulative Timesteps: 2,033,163,188

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 138,675.66397
Policy Entropy: 2.37896
Value Function Loss: 0.01738

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.07514
Policy Update Magnitude: 0.30878
Value Function Update Magnitude: 0.38095

Collected Steps per Second: 22,115.86028
Overall Steps per Second: 10,516.40595

Timestep Collection Time: 2.26182
Timestep Consumption Time: 2.49475
PPO Batch Consumption Time: 0.29040
Total Iteration Time: 4.75657

Cumulative Model Updates: 243,716
Cumulative Timesteps: 2,033,213,210

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2033213210...
Checkpoint 2033213210 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 75,369.05717
Policy Entropy: 2.38702
Value Function Loss: 0.01697

Mean KL Divergence: 0.00717
SB3 Clip Fraction: 0.06858
Policy Update Magnitude: 0.30615
Value Function Update Magnitude: 0.33371

Collected Steps per Second: 22,186.44161
Overall Steps per Second: 10,719.17976

Timestep Collection Time: 2.25417
Timestep Consumption Time: 2.41149
PPO Batch Consumption Time: 0.27783
Total Iteration Time: 4.66566

Cumulative Model Updates: 243,722
Cumulative Timesteps: 2,033,263,222

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65,610.52744
Policy Entropy: 2.38711
Value Function Loss: 0.01557

Mean KL Divergence: 0.00667
SB3 Clip Fraction: 0.06557
Policy Update Magnitude: 0.30295
Value Function Update Magnitude: 0.31639

Collected Steps per Second: 22,154.84558
Overall Steps per Second: 10,534.74678

Timestep Collection Time: 2.25729
Timestep Consumption Time: 2.48985
PPO Batch Consumption Time: 0.29077
Total Iteration Time: 4.74715

Cumulative Model Updates: 243,728
Cumulative Timesteps: 2,033,313,232

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2033313232...
Checkpoint 2033313232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 65,610.52744
Policy Entropy: 2.37264
Value Function Loss: 0.01365

Mean KL Divergence: 0.00676
SB3 Clip Fraction: 0.06434
Policy Update Magnitude: 0.29592
Value Function Update Magnitude: 0.30711

Collected Steps per Second: 21,985.60405
Overall Steps per Second: 10,460.94433

Timestep Collection Time: 2.27431
Timestep Consumption Time: 2.50557
PPO Batch Consumption Time: 0.29201
Total Iteration Time: 4.77987

Cumulative Model Updates: 243,734
Cumulative Timesteps: 2,033,363,234

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58,711.41474
Policy Entropy: 2.38205
Value Function Loss: 0.01288

Mean KL Divergence: 0.00649
SB3 Clip Fraction: 0.05927
Policy Update Magnitude: 0.29346
Value Function Update Magnitude: 0.26411

Collected Steps per Second: 21,678.72909
Overall Steps per Second: 10,485.20558

Timestep Collection Time: 2.30761
Timestep Consumption Time: 2.46350
PPO Batch Consumption Time: 0.28406
Total Iteration Time: 4.77110

Cumulative Model Updates: 243,740
Cumulative Timesteps: 2,033,413,260

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2033413260...
Checkpoint 2033413260 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 65,220.82574
Policy Entropy: 2.38707
Value Function Loss: 0.01366

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.06744
Policy Update Magnitude: 0.29156
Value Function Update Magnitude: 0.24185

Collected Steps per Second: 20,828.83975
Overall Steps per Second: 10,192.37097

Timestep Collection Time: 2.40157
Timestep Consumption Time: 2.50621
PPO Batch Consumption Time: 0.29183
Total Iteration Time: 4.90779

Cumulative Model Updates: 243,746
Cumulative Timesteps: 2,033,463,282

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66,265.98565
Policy Entropy: 2.37944
Value Function Loss: 0.01506

Mean KL Divergence: 0.00721
SB3 Clip Fraction: 0.07023
Policy Update Magnitude: 0.30254
Value Function Update Magnitude: 0.26870

Collected Steps per Second: 20,574.68573
Overall Steps per Second: 10,407.17154

Timestep Collection Time: 2.43192
Timestep Consumption Time: 2.37592
PPO Batch Consumption Time: 0.27928
Total Iteration Time: 4.80784

Cumulative Model Updates: 243,752
Cumulative Timesteps: 2,033,513,318

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 2033513318...
Checkpoint 2033513318 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 72,042.90206
Policy Entropy: 2.40905
Value Function Loss: 0.01454

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.08090
Policy Update Magnitude: 0.29631
Value Function Update Magnitude: 0.28722

Collected Steps per Second: 20,494.56350
Overall Steps per Second: 10,227.60574

Timestep Collection Time: 2.44026
Timestep Consumption Time: 2.44965
PPO Batch Consumption Time: 0.29199
Total Iteration Time: 4.88990

Cumulative Model Updates: 243,758
Cumulative Timesteps: 2,033,563,330

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 69,017.16946
Policy Entropy: 2.42735
Value Function Loss: 0.01337

Mean KL Divergence: 0.01181
SB3 Clip Fraction: 0.09831
Policy Update Magnitude: 0.28132
Value Function Update Magnitude: 0.27322

Collected Steps per Second: 21,032.36234
Overall Steps per Second: 10,496.11724

Timestep Collection Time: 2.37872
Timestep Consumption Time: 2.38781
PPO Batch Consumption Time: 0.27862
Total Iteration Time: 4.76652

Cumulative Model Updates: 243,764
Cumulative Timesteps: 2,033,613,360

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2033613360...
Checkpoint 2033613360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 65,178.79691
Policy Entropy: 2.40728
Value Function Loss: 0.01427

Mean KL Divergence: 0.01493
SB3 Clip Fraction: 0.11600
Policy Update Magnitude: 0.26769
Value Function Update Magnitude: 0.26438

Collected Steps per Second: 20,654.23836
Overall Steps per Second: 10,256.33391

Timestep Collection Time: 2.42159
Timestep Consumption Time: 2.45501
PPO Batch Consumption Time: 0.27751
Total Iteration Time: 4.87660

Cumulative Model Updates: 243,770
Cumulative Timesteps: 2,033,663,376

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83,498.64294
Policy Entropy: 2.37751
Value Function Loss: 0.01633

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.08519
Policy Update Magnitude: 0.29571
Value Function Update Magnitude: 0.28111

Collected Steps per Second: 21,327.74101
Overall Steps per Second: 10,424.23197

Timestep Collection Time: 2.34493
Timestep Consumption Time: 2.45274
PPO Batch Consumption Time: 0.27961
Total Iteration Time: 4.79767

Cumulative Model Updates: 243,776
Cumulative Timesteps: 2,033,713,388

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2033713388...
Checkpoint 2033713388 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 85,474.77833
Policy Entropy: 2.35634
Value Function Loss: 0.01706

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.08490
Policy Update Magnitude: 0.31492
Value Function Update Magnitude: 0.31818

Collected Steps per Second: 20,938.08916
Overall Steps per Second: 10,215.62252

Timestep Collection Time: 2.38990
Timestep Consumption Time: 2.50848
PPO Batch Consumption Time: 0.29435
Total Iteration Time: 4.89838

Cumulative Model Updates: 243,782
Cumulative Timesteps: 2,033,763,428

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85,425.27344
Policy Entropy: 2.36607
Value Function Loss: 0.01568

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.07500
Policy Update Magnitude: 0.30784
Value Function Update Magnitude: 0.32120

Collected Steps per Second: 20,866.21227
Overall Steps per Second: 10,365.29909

Timestep Collection Time: 2.39737
Timestep Consumption Time: 2.42873
PPO Batch Consumption Time: 0.27933
Total Iteration Time: 4.82610

Cumulative Model Updates: 243,788
Cumulative Timesteps: 2,033,813,452

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2033813452...
Checkpoint 2033813452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 71,393.75619
Policy Entropy: 2.38112
Value Function Loss: 0.01336

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.07650
Policy Update Magnitude: 0.29289
Value Function Update Magnitude: 0.29997

Collected Steps per Second: 21,033.94823
Overall Steps per Second: 10,322.55743

Timestep Collection Time: 2.37825
Timestep Consumption Time: 2.46784
PPO Batch Consumption Time: 0.27868
Total Iteration Time: 4.84609

Cumulative Model Updates: 243,794
Cumulative Timesteps: 2,033,863,476

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68,573.82408
Policy Entropy: 2.38171
Value Function Loss: 0.01392

Mean KL Divergence: 0.00649
SB3 Clip Fraction: 0.06190
Policy Update Magnitude: 0.29279
Value Function Update Magnitude: 0.28602

Collected Steps per Second: 19,830.77427
Overall Steps per Second: 9,933.94741

Timestep Collection Time: 2.52204
Timestep Consumption Time: 2.51262
PPO Batch Consumption Time: 0.27973
Total Iteration Time: 5.03466

Cumulative Model Updates: 243,800
Cumulative Timesteps: 2,033,913,490

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2033913490...
Checkpoint 2033913490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89,806.72217
Policy Entropy: 2.37814
Value Function Loss: 0.01355

Mean KL Divergence: 0.00638
SB3 Clip Fraction: 0.06251
Policy Update Magnitude: 0.29641
Value Function Update Magnitude: 0.28194

Collected Steps per Second: 20,591.69278
Overall Steps per Second: 10,207.10095

Timestep Collection Time: 2.42943
Timestep Consumption Time: 2.47167
PPO Batch Consumption Time: 0.27970
Total Iteration Time: 4.90110

Cumulative Model Updates: 243,806
Cumulative Timesteps: 2,033,963,516

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83,346.78699
Policy Entropy: 2.36492
Value Function Loss: 0.01513

Mean KL Divergence: 0.00677
SB3 Clip Fraction: 0.06447
Policy Update Magnitude: 0.30204
Value Function Update Magnitude: 0.27722

Collected Steps per Second: 21,001.33957
Overall Steps per Second: 10,148.77354

Timestep Collection Time: 2.38166
Timestep Consumption Time: 2.54682
PPO Batch Consumption Time: 0.29384
Total Iteration Time: 4.92848

Cumulative Model Updates: 243,812
Cumulative Timesteps: 2,034,013,534

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2034013534...
Checkpoint 2034013534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 78,653.98192
Policy Entropy: 2.38243
Value Function Loss: 0.01644

Mean KL Divergence: 0.00679
SB3 Clip Fraction: 0.06455
Policy Update Magnitude: 0.30327
Value Function Update Magnitude: 0.30374

Collected Steps per Second: 20,719.54145
Overall Steps per Second: 10,257.27218

Timestep Collection Time: 2.41347
Timestep Consumption Time: 2.46170
PPO Batch Consumption Time: 0.27712
Total Iteration Time: 4.87518

Cumulative Model Updates: 243,818
Cumulative Timesteps: 2,034,063,540

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62,799.91732
Policy Entropy: 2.39031
Value Function Loss: 0.01640

Mean KL Divergence: 0.00719
SB3 Clip Fraction: 0.06788
Policy Update Magnitude: 0.30449
Value Function Update Magnitude: 0.30741

Collected Steps per Second: 20,463.51824
Overall Steps per Second: 10,024.67314

Timestep Collection Time: 2.44474
Timestep Consumption Time: 2.54575
PPO Batch Consumption Time: 0.29395
Total Iteration Time: 4.99049

Cumulative Model Updates: 243,824
Cumulative Timesteps: 2,034,113,568

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2034113568...
Checkpoint 2034113568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 81,740.98022
Policy Entropy: 2.39509
Value Function Loss: 0.01907

Mean KL Divergence: 0.00703
SB3 Clip Fraction: 0.06621
Policy Update Magnitude: 0.31364
Value Function Update Magnitude: 0.32374

Collected Steps per Second: 20,610.30993
Overall Steps per Second: 10,219.58522

Timestep Collection Time: 2.42694
Timestep Consumption Time: 2.46758
PPO Batch Consumption Time: 0.27787
Total Iteration Time: 4.89452

Cumulative Model Updates: 243,830
Cumulative Timesteps: 2,034,163,588

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54,444.60731
Policy Entropy: 2.41221
Value Function Loss: 0.01926

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.08405
Policy Update Magnitude: 0.32380
Value Function Update Magnitude: 0.34014

Collected Steps per Second: 20,380.63517
Overall Steps per Second: 10,021.20973

Timestep Collection Time: 2.45449
Timestep Consumption Time: 2.53733
PPO Batch Consumption Time: 0.29382
Total Iteration Time: 4.99181

Cumulative Model Updates: 243,836
Cumulative Timesteps: 2,034,213,612

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2034213612...
Checkpoint 2034213612 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 59,592.79572
Policy Entropy: 2.40855
Value Function Loss: 0.01812

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.09150
Policy Update Magnitude: 0.32042
Value Function Update Magnitude: 0.32898

Collected Steps per Second: 20,778.84392
Overall Steps per Second: 10,151.08801

Timestep Collection Time: 2.40677
Timestep Consumption Time: 2.51979
PPO Batch Consumption Time: 0.29085
Total Iteration Time: 4.92657

Cumulative Model Updates: 243,842
Cumulative Timesteps: 2,034,263,622

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47,518.93027
Policy Entropy: 2.41983
Value Function Loss: 0.01575

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.07446
Policy Update Magnitude: 0.31132
Value Function Update Magnitude: 0.28022

Collected Steps per Second: 20,976.53001
Overall Steps per Second: 10,141.24321

Timestep Collection Time: 2.38371
Timestep Consumption Time: 2.54685
PPO Batch Consumption Time: 0.29295
Total Iteration Time: 4.93056

Cumulative Model Updates: 243,848
Cumulative Timesteps: 2,034,313,624

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2034313624...
Checkpoint 2034313624 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,889.09265
Policy Entropy: 2.39472
Value Function Loss: 0.01630

Mean KL Divergence: 0.00782
SB3 Clip Fraction: 0.07545
Policy Update Magnitude: 0.31712
Value Function Update Magnitude: 0.29667

Collected Steps per Second: 20,516.38381
Overall Steps per Second: 10,158.16711

Timestep Collection Time: 2.43854
Timestep Consumption Time: 2.48656
PPO Batch Consumption Time: 0.29376
Total Iteration Time: 4.92510

Cumulative Model Updates: 243,854
Cumulative Timesteps: 2,034,363,654

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,182.12168
Policy Entropy: 2.40167
Value Function Loss: 0.01605

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.07310
Policy Update Magnitude: 0.31658
Value Function Update Magnitude: 0.31102

Collected Steps per Second: 20,551.50313
Overall Steps per Second: 10,359.72417

Timestep Collection Time: 2.43427
Timestep Consumption Time: 2.39481
PPO Batch Consumption Time: 0.27896
Total Iteration Time: 4.82909

Cumulative Model Updates: 243,860
Cumulative Timesteps: 2,034,413,682

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2034413682...
Checkpoint 2034413682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,007.53987
Policy Entropy: 2.41324
Value Function Loss: 0.01594

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.08866
Policy Update Magnitude: 0.30490
Value Function Update Magnitude: 0.30657

Collected Steps per Second: 20,469.00252
Overall Steps per Second: 10,251.10261

Timestep Collection Time: 2.44321
Timestep Consumption Time: 2.43529
PPO Batch Consumption Time: 0.29005
Total Iteration Time: 4.87850

Cumulative Model Updates: 243,866
Cumulative Timesteps: 2,034,463,692

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,755.11548
Policy Entropy: 2.42134
Value Function Loss: 0.01883

Mean KL Divergence: 0.01297
SB3 Clip Fraction: 0.10476
Policy Update Magnitude: 0.30347
Value Function Update Magnitude: 0.28938

Collected Steps per Second: 17,472.46590
Overall Steps per Second: 9,227.29912

Timestep Collection Time: 2.86233
Timestep Consumption Time: 2.55767
PPO Batch Consumption Time: 0.27994
Total Iteration Time: 5.42000

Cumulative Model Updates: 243,872
Cumulative Timesteps: 2,034,513,704

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2034513704...
Checkpoint 2034513704 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 74,644.81895
Policy Entropy: 2.38182
Value Function Loss: 0.02057

Mean KL Divergence: 0.01473
SB3 Clip Fraction: 0.11094
Policy Update Magnitude: 0.32036
Value Function Update Magnitude: 0.31368

Collected Steps per Second: 20,057.68299
Overall Steps per Second: 9,953.87232

Timestep Collection Time: 2.49311
Timestep Consumption Time: 2.53066
PPO Batch Consumption Time: 0.29327
Total Iteration Time: 5.02377

Cumulative Model Updates: 243,878
Cumulative Timesteps: 2,034,563,710

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82,401.18183
Policy Entropy: 2.35851
Value Function Loss: 0.02038

Mean KL Divergence: 0.01115
SB3 Clip Fraction: 0.09670
Policy Update Magnitude: 0.32315
Value Function Update Magnitude: 0.33964

Collected Steps per Second: 21,145.59384
Overall Steps per Second: 10,410.36531

Timestep Collection Time: 2.36617
Timestep Consumption Time: 2.44000
PPO Batch Consumption Time: 0.27976
Total Iteration Time: 4.80617

Cumulative Model Updates: 243,884
Cumulative Timesteps: 2,034,613,744

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 2034613744...
Checkpoint 2034613744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 60,653.41257
Policy Entropy: 2.35127
Value Function Loss: 0.01932

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.08848
Policy Update Magnitude: 0.32742
Value Function Update Magnitude: 0.33988

Collected Steps per Second: 20,879.19992
Overall Steps per Second: 10,170.74711

Timestep Collection Time: 2.39540
Timestep Consumption Time: 2.52204
PPO Batch Consumption Time: 0.29368
Total Iteration Time: 4.91744

Cumulative Model Updates: 243,890
Cumulative Timesteps: 2,034,663,758

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76,691.17058
Policy Entropy: 2.37844
Value Function Loss: 0.01786

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.08273
Policy Update Magnitude: 0.33057
Value Function Update Magnitude: 0.36136

Collected Steps per Second: 21,439.36460
Overall Steps per Second: 10,417.01882

Timestep Collection Time: 2.33263
Timestep Consumption Time: 2.46817
PPO Batch Consumption Time: 0.27999
Total Iteration Time: 4.80080

Cumulative Model Updates: 243,896
Cumulative Timesteps: 2,034,713,768

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2034713768...
Checkpoint 2034713768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84,381.33813
Policy Entropy: 2.40050
Value Function Loss: 0.01620

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.07721
Policy Update Magnitude: 0.31714
Value Function Update Magnitude: 0.35615

Collected Steps per Second: 21,142.58858
Overall Steps per Second: 10,358.42122

Timestep Collection Time: 2.36499
Timestep Consumption Time: 2.46219
PPO Batch Consumption Time: 0.27799
Total Iteration Time: 4.82718

Cumulative Model Updates: 243,902
Cumulative Timesteps: 2,034,763,770

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 73,000.10863
Policy Entropy: 2.40470
Value Function Loss: 0.01439

Mean KL Divergence: 0.00766
SB3 Clip Fraction: 0.06984
Policy Update Magnitude: 0.29703
Value Function Update Magnitude: 0.30811

Collected Steps per Second: 21,131.77371
Overall Steps per Second: 10,347.94938

Timestep Collection Time: 2.36800
Timestep Consumption Time: 2.46774
PPO Batch Consumption Time: 0.27939
Total Iteration Time: 4.83574

Cumulative Model Updates: 243,908
Cumulative Timesteps: 2,034,813,810

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 2034813810...
Checkpoint 2034813810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 75,481.45642
Policy Entropy: 2.41262
Value Function Loss: 0.01377

Mean KL Divergence: 0.00682
SB3 Clip Fraction: 0.06630
Policy Update Magnitude: 0.28614
Value Function Update Magnitude: 0.29683

Collected Steps per Second: 20,737.40363
Overall Steps per Second: 10,263.48114

Timestep Collection Time: 2.41149
Timestep Consumption Time: 2.46093
PPO Batch Consumption Time: 0.27956
Total Iteration Time: 4.87242

Cumulative Model Updates: 243,914
Cumulative Timesteps: 2,034,863,818

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53,925.55741
Policy Entropy: 2.42266
Value Function Loss: 0.01380

Mean KL Divergence: 0.00609
SB3 Clip Fraction: 0.06080
Policy Update Magnitude: 0.28952
Value Function Update Magnitude: 0.29828

Collected Steps per Second: 20,806.44139
Overall Steps per Second: 10,118.00816

Timestep Collection Time: 2.40368
Timestep Consumption Time: 2.53919
PPO Batch Consumption Time: 0.29515
Total Iteration Time: 4.94287

Cumulative Model Updates: 243,920
Cumulative Timesteps: 2,034,913,830

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2034913830...
Checkpoint 2034913830 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 51,334.62647
Policy Entropy: 2.41418
Value Function Loss: 0.01481

Mean KL Divergence: 0.00673
SB3 Clip Fraction: 0.06637
Policy Update Magnitude: 0.29123
Value Function Update Magnitude: 0.31667

Collected Steps per Second: 9,633.95369
Overall Steps per Second: 6,152.24199

Timestep Collection Time: 5.19060
Timestep Consumption Time: 2.93749
PPO Batch Consumption Time: 0.28950
Total Iteration Time: 8.12809

Cumulative Model Updates: 243,926
Cumulative Timesteps: 2,034,963,836

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46,915.77926
Policy Entropy: 2.43095
Value Function Loss: 0.01575

Mean KL Divergence: 0.00715
SB3 Clip Fraction: 0.06951
Policy Update Magnitude: 0.30027
Value Function Update Magnitude: 0.33070

Collected Steps per Second: 17,291.23859
Overall Steps per Second: 9,281.54253

Timestep Collection Time: 2.89349
Timestep Consumption Time: 2.49699
PPO Batch Consumption Time: 0.27884
Total Iteration Time: 5.39048

Cumulative Model Updates: 243,932
Cumulative Timesteps: 2,035,013,868

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2035013868...
Checkpoint 2035013868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,456.67242
Policy Entropy: 2.41339
Value Function Loss: 0.01532

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.09040
Policy Update Magnitude: 0.30500
Value Function Update Magnitude: 0.32707

Collected Steps per Second: 19,972.44236
Overall Steps per Second: 9,837.54054

Timestep Collection Time: 2.50435
Timestep Consumption Time: 2.58005
PPO Batch Consumption Time: 0.29500
Total Iteration Time: 5.08440

Cumulative Model Updates: 243,938
Cumulative Timesteps: 2,035,063,886

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45,126.81694
Policy Entropy: 2.42475
Value Function Loss: 0.01673

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.07837
Policy Update Magnitude: 0.29539
Value Function Update Magnitude: 0.29920

Collected Steps per Second: 19,790.22864
Overall Steps per Second: 10,041.04270

Timestep Collection Time: 2.52842
Timestep Consumption Time: 2.45493
PPO Batch Consumption Time: 0.29450
Total Iteration Time: 4.98335

Cumulative Model Updates: 243,944
Cumulative Timesteps: 2,035,113,924

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 2035113924...
Checkpoint 2035113924 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 75,253.50321
Policy Entropy: 2.41940
Value Function Loss: 0.01800

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.07467
Policy Update Magnitude: 0.30444
Value Function Update Magnitude: 0.31472

Collected Steps per Second: 20,743.57873
Overall Steps per Second: 10,356.34664

Timestep Collection Time: 2.41058
Timestep Consumption Time: 2.41777
PPO Batch Consumption Time: 0.29024
Total Iteration Time: 4.82834

Cumulative Model Updates: 243,950
Cumulative Timesteps: 2,035,163,928

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 71,724.95621
Policy Entropy: 2.41194
Value Function Loss: 0.01853

Mean KL Divergence: 0.00726
SB3 Clip Fraction: 0.06836
Policy Update Magnitude: 0.30980
Value Function Update Magnitude: 0.33012

Collected Steps per Second: 20,951.30795
Overall Steps per Second: 10,333.33012

Timestep Collection Time: 2.38849
Timestep Consumption Time: 2.45429
PPO Batch Consumption Time: 0.29290
Total Iteration Time: 4.84278

Cumulative Model Updates: 243,956
Cumulative Timesteps: 2,035,213,970

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 2035213970...
Checkpoint 2035213970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,817.36046
Policy Entropy: 2.41926
Value Function Loss: 0.01576

Mean KL Divergence: 0.00730
SB3 Clip Fraction: 0.06909
Policy Update Magnitude: 0.30252
Value Function Update Magnitude: 0.30113

Collected Steps per Second: 21,357.50516
Overall Steps per Second: 10,349.04767

Timestep Collection Time: 2.34278
Timestep Consumption Time: 2.49206
PPO Batch Consumption Time: 0.29060
Total Iteration Time: 4.83484

Cumulative Model Updates: 243,962
Cumulative Timesteps: 2,035,264,006

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54,563.51315
Policy Entropy: 2.42154
Value Function Loss: 0.01573

Mean KL Divergence: 0.00714
SB3 Clip Fraction: 0.06874
Policy Update Magnitude: 0.29961
Value Function Update Magnitude: 0.30880

Collected Steps per Second: 22,111.52616
Overall Steps per Second: 10,686.62323

Timestep Collection Time: 2.26343
Timestep Consumption Time: 2.41980
PPO Batch Consumption Time: 0.27916
Total Iteration Time: 4.68324

Cumulative Model Updates: 243,968
Cumulative Timesteps: 2,035,314,054

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 2035314054...
Checkpoint 2035314054 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 68,270.65616
Policy Entropy: 2.42677
Value Function Loss: 0.01465

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.07499
Policy Update Magnitude: 0.29819
Value Function Update Magnitude: 0.28752

Collected Steps per Second: 21,869.52803
Overall Steps per Second: 10,630.66311

Timestep Collection Time: 2.28665
Timestep Consumption Time: 2.41748
PPO Batch Consumption Time: 0.27931
Total Iteration Time: 4.70413

Cumulative Model Updates: 243,974
Cumulative Timesteps: 2,035,364,062

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81,886.69861
Policy Entropy: 2.41544
Value Function Loss: 0.01640

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.08081
Policy Update Magnitude: 0.29827
Value Function Update Magnitude: 0.24921

Collected Steps per Second: 21,953.11965
Overall Steps per Second: 10,495.05250

Timestep Collection Time: 2.27968
Timestep Consumption Time: 2.48886
PPO Batch Consumption Time: 0.28715
Total Iteration Time: 4.76853

Cumulative Model Updates: 243,980
Cumulative Timesteps: 2,035,414,108

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 2035414108...
Checkpoint 2035414108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 62,866.12226
Policy Entropy: 2.38662
Value Function Loss: 0.01795

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.07580
Policy Update Magnitude: 0.30780
Value Function Update Magnitude: 0.28732

Collected Steps per Second: 21,927.50616
Overall Steps per Second: 10,609.17282

Timestep Collection Time: 2.28152
Timestep Consumption Time: 2.43402
PPO Batch Consumption Time: 0.27927
Total Iteration Time: 4.71554

Cumulative Model Updates: 243,986
Cumulative Timesteps: 2,035,464,136

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60,352.25546
Policy Entropy: 2.38669
Value Function Loss: 0.01881

Mean KL Divergence: 0.00721
SB3 Clip Fraction: 0.06827
Policy Update Magnitude: 0.32088
Value Function Update Magnitude: 0.33224

Collected Steps per Second: 21,867.95607
Overall Steps per Second: 10,484.61562

Timestep Collection Time: 2.28654
Timestep Consumption Time: 2.48254
PPO Batch Consumption Time: 0.28882
Total Iteration Time: 4.76908

Cumulative Model Updates: 243,992
Cumulative Timesteps: 2,035,514,138

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2035514138...
Checkpoint 2035514138 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55,287.58067
Policy Entropy: 2.40919
Value Function Loss: 0.01655

Mean KL Divergence: 0.00760
SB3 Clip Fraction: 0.07071
Policy Update Magnitude: 0.31175
Value Function Update Magnitude: 0.31655

Collected Steps per Second: 21,459.39868
Overall Steps per Second: 10,369.32201

Timestep Collection Time: 2.33129
Timestep Consumption Time: 2.49333
PPO Batch Consumption Time: 0.29134
Total Iteration Time: 4.82462

Cumulative Model Updates: 243,998
Cumulative Timesteps: 2,035,564,166

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59,879.57993
Policy Entropy: 2.42781
Value Function Loss: 0.01629

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.07967
Policy Update Magnitude: 0.30316
Value Function Update Magnitude: 0.28803

Collected Steps per Second: 21,579.09375
Overall Steps per Second: 10,357.02148

Timestep Collection Time: 2.31734
Timestep Consumption Time: 2.51089
PPO Batch Consumption Time: 0.29322
Total Iteration Time: 4.82822

Cumulative Model Updates: 244,004
Cumulative Timesteps: 2,035,614,172

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2035614172...
Checkpoint 2035614172 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 54,748.38113
Policy Entropy: 2.41597
Value Function Loss: 0.01751

Mean KL Divergence: 0.01199
SB3 Clip Fraction: 0.10179
Policy Update Magnitude: 0.29310
Value Function Update Magnitude: 0.28222

Collected Steps per Second: 21,229.26442
Overall Steps per Second: 10,309.73942

Timestep Collection Time: 2.35524
Timestep Consumption Time: 2.49454
PPO Batch Consumption Time: 0.29031
Total Iteration Time: 4.84978

Cumulative Model Updates: 244,010
Cumulative Timesteps: 2,035,664,172

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57,700.00771
Policy Entropy: 2.39480
Value Function Loss: 0.01779

Mean KL Divergence: 0.01552
SB3 Clip Fraction: 0.12067
Policy Update Magnitude: 0.27874
Value Function Update Magnitude: 0.28721

Collected Steps per Second: 20,458.72835
Overall Steps per Second: 10,225.46578

Timestep Collection Time: 2.44502
Timestep Consumption Time: 2.44688
PPO Batch Consumption Time: 0.27954
Total Iteration Time: 4.89190

Cumulative Model Updates: 244,016
Cumulative Timesteps: 2,035,714,194

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2035714194...
Checkpoint 2035714194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 53,640.36003
Policy Entropy: 2.39525
Value Function Loss: 0.01749

Mean KL Divergence: 0.01483
SB3 Clip Fraction: 0.11543
Policy Update Magnitude: 0.29796
Value Function Update Magnitude: 0.32487

Collected Steps per Second: 21,182.91204
Overall Steps per Second: 10,243.25677

Timestep Collection Time: 2.36143
Timestep Consumption Time: 2.52198
PPO Batch Consumption Time: 0.29240
Total Iteration Time: 4.88341

Cumulative Model Updates: 244,022
Cumulative Timesteps: 2,035,764,216

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 124,271.46611
Policy Entropy: 2.41124
Value Function Loss: 0.01628

Mean KL Divergence: 0.01238
SB3 Clip Fraction: 0.10135
Policy Update Magnitude: 0.29370
Value Function Update Magnitude: 0.32244

Collected Steps per Second: 21,663.32479
Overall Steps per Second: 10,451.70166

Timestep Collection Time: 2.30888
Timestep Consumption Time: 2.47675
PPO Batch Consumption Time: 0.28492
Total Iteration Time: 4.78563

Cumulative Model Updates: 244,028
Cumulative Timesteps: 2,035,814,234

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2035814234...
Checkpoint 2035814234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 97,656.72702
Policy Entropy: 2.41961
Value Function Loss: 0.01595

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.08148
Policy Update Magnitude: 0.30164
Value Function Update Magnitude: 0.29648

Collected Steps per Second: 21,868.77336
Overall Steps per Second: 10,554.70300

Timestep Collection Time: 2.28655
Timestep Consumption Time: 2.45106
PPO Batch Consumption Time: 0.27851
Total Iteration Time: 4.73760

Cumulative Model Updates: 244,034
Cumulative Timesteps: 2,035,864,238

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88,101.74406
Policy Entropy: 2.41500
Value Function Loss: 0.01515

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.08185
Policy Update Magnitude: 0.29647
Value Function Update Magnitude: 0.26270

Collected Steps per Second: 21,969.13593
Overall Steps per Second: 10,488.60440

Timestep Collection Time: 2.27619
Timestep Consumption Time: 2.49146
PPO Batch Consumption Time: 0.28744
Total Iteration Time: 4.76765

Cumulative Model Updates: 244,040
Cumulative Timesteps: 2,035,914,244

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2035914244...
Checkpoint 2035914244 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 96,541.42406
Policy Entropy: 2.38131
Value Function Loss: 0.01596

Mean KL Divergence: 0.00777
SB3 Clip Fraction: 0.07368
Policy Update Magnitude: 0.30002
Value Function Update Magnitude: 0.23994

Collected Steps per Second: 21,777.90111
Overall Steps per Second: 10,584.62692

Timestep Collection Time: 2.29701
Timestep Consumption Time: 2.42909
PPO Batch Consumption Time: 0.27968
Total Iteration Time: 4.72610

Cumulative Model Updates: 244,046
Cumulative Timesteps: 2,035,964,268

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 146,187.26104
Policy Entropy: 2.36320
Value Function Loss: 0.01580

Mean KL Divergence: 0.00692
SB3 Clip Fraction: 0.06947
Policy Update Magnitude: 0.30899
Value Function Update Magnitude: 0.24108

Collected Steps per Second: 21,452.72048
Overall Steps per Second: 10,550.05037

Timestep Collection Time: 2.33127
Timestep Consumption Time: 2.40919
PPO Batch Consumption Time: 0.28602
Total Iteration Time: 4.74045

Cumulative Model Updates: 244,052
Cumulative Timesteps: 2,036,014,280

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2036014280...
Checkpoint 2036014280 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 137,924.33794
Policy Entropy: 2.38447
Value Function Loss: 0.01586

Mean KL Divergence: 0.00646
SB3 Clip Fraction: 0.06368
Policy Update Magnitude: 0.30869
Value Function Update Magnitude: 0.24447

Collected Steps per Second: 21,375.83236
Overall Steps per Second: 10,656.15071

Timestep Collection Time: 2.34115
Timestep Consumption Time: 2.35511
PPO Batch Consumption Time: 0.27898
Total Iteration Time: 4.69625

Cumulative Model Updates: 244,058
Cumulative Timesteps: 2,036,064,324

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 101,938.73594
Policy Entropy: 2.41004
Value Function Loss: 0.01542

Mean KL Divergence: 0.00653
SB3 Clip Fraction: 0.06244
Policy Update Magnitude: 0.30162
Value Function Update Magnitude: 0.22208

Collected Steps per Second: 21,571.60164
Overall Steps per Second: 10,538.52130

Timestep Collection Time: 2.31851
Timestep Consumption Time: 2.42732
PPO Batch Consumption Time: 0.29195
Total Iteration Time: 4.74583

Cumulative Model Updates: 244,064
Cumulative Timesteps: 2,036,114,338

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2036114338...
Checkpoint 2036114338 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 98,627.81516
Policy Entropy: 2.43205
Value Function Loss: 0.01628

Mean KL Divergence: 0.00664
SB3 Clip Fraction: 0.06254
Policy Update Magnitude: 0.29615
Value Function Update Magnitude: 0.20235

Collected Steps per Second: 20,918.31145
Overall Steps per Second: 10,292.46538

Timestep Collection Time: 2.39035
Timestep Consumption Time: 2.46777
PPO Batch Consumption Time: 0.29077
Total Iteration Time: 4.85812

Cumulative Model Updates: 244,070
Cumulative Timesteps: 2,036,164,340

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80,956.58300
Policy Entropy: 2.43458
Value Function Loss: 0.01576

Mean KL Divergence: 0.00631
SB3 Clip Fraction: 0.06014
Policy Update Magnitude: 0.29208
Value Function Update Magnitude: 0.18272

Collected Steps per Second: 21,755.28231
Overall Steps per Second: 10,649.75905

Timestep Collection Time: 2.29829
Timestep Consumption Time: 2.39665
PPO Batch Consumption Time: 0.27855
Total Iteration Time: 4.69494

Cumulative Model Updates: 244,076
Cumulative Timesteps: 2,036,214,340

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2036214340...
Checkpoint 2036214340 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 52,152.22148
Policy Entropy: 2.42345
Value Function Loss: 0.02074

Mean KL Divergence: 0.00676
SB3 Clip Fraction: 0.06720
Policy Update Magnitude: 0.30540
Value Function Update Magnitude: 0.16915

Collected Steps per Second: 21,017.53381
Overall Steps per Second: 10,289.67022

Timestep Collection Time: 2.38030
Timestep Consumption Time: 2.48167
PPO Batch Consumption Time: 0.29283
Total Iteration Time: 4.86196

Cumulative Model Updates: 244,082
Cumulative Timesteps: 2,036,264,368

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 124,719.74160
Policy Entropy: 2.42193
Value Function Loss: 0.01791

Mean KL Divergence: 0.00635
SB3 Clip Fraction: 0.05898
Policy Update Magnitude: 0.31472
Value Function Update Magnitude: 0.21999

Collected Steps per Second: 21,803.85225
Overall Steps per Second: 10,438.51183

Timestep Collection Time: 2.29400
Timestep Consumption Time: 2.49768
PPO Batch Consumption Time: 0.28723
Total Iteration Time: 4.79168

Cumulative Model Updates: 244,088
Cumulative Timesteps: 2,036,314,386

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2036314386...
Checkpoint 2036314386 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 75,733.17580
Policy Entropy: 2.41335
Value Function Loss: 0.01719

Mean KL Divergence: 0.00702
SB3 Clip Fraction: 0.06419
Policy Update Magnitude: 0.30623
Value Function Update Magnitude: 0.27881

Collected Steps per Second: 22,043.43526
Overall Steps per Second: 10,552.28029

Timestep Collection Time: 2.27006
Timestep Consumption Time: 2.47204
PPO Batch Consumption Time: 0.27896
Total Iteration Time: 4.74210

Cumulative Model Updates: 244,094
Cumulative Timesteps: 2,036,364,426

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91,124.23013
Policy Entropy: 2.42477
Value Function Loss: 0.01483

Mean KL Divergence: 0.00706
SB3 Clip Fraction: 0.06649
Policy Update Magnitude: 0.29373
Value Function Update Magnitude: 0.26057

Collected Steps per Second: 21,938.62423
Overall Steps per Second: 10,591.01125

Timestep Collection Time: 2.27954
Timestep Consumption Time: 2.44239
PPO Batch Consumption Time: 0.27818
Total Iteration Time: 4.72193

Cumulative Model Updates: 244,100
Cumulative Timesteps: 2,036,414,436

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2036414436...
Checkpoint 2036414436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 102,839.24304
Policy Entropy: 2.41494
Value Function Loss: 0.01682

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.07535
Policy Update Magnitude: 0.29772
Value Function Update Magnitude: 0.25725

Collected Steps per Second: 21,645.99517
Overall Steps per Second: 10,548.40950

Timestep Collection Time: 2.31008
Timestep Consumption Time: 2.43035
PPO Batch Consumption Time: 0.27889
Total Iteration Time: 4.74043

Cumulative Model Updates: 244,106
Cumulative Timesteps: 2,036,464,440

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 107,740.90544
Policy Entropy: 2.40886
Value Function Loss: 0.01680

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.09025
Policy Update Magnitude: 0.30534
Value Function Update Magnitude: 0.28488

Collected Steps per Second: 21,972.85611
Overall Steps per Second: 10,475.75137

Timestep Collection Time: 2.27699
Timestep Consumption Time: 2.49899
PPO Batch Consumption Time: 0.28894
Total Iteration Time: 4.77598

Cumulative Model Updates: 244,112
Cumulative Timesteps: 2,036,514,472

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2036514472...
Checkpoint 2036514472 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 75,191.89507
Policy Entropy: 2.41322
Value Function Loss: 0.01515

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.08323
Policy Update Magnitude: 0.29995
Value Function Update Magnitude: 0.27033

Collected Steps per Second: 21,950.49045
Overall Steps per Second: 10,616.98207

Timestep Collection Time: 2.27958
Timestep Consumption Time: 2.43343
PPO Batch Consumption Time: 0.27927
Total Iteration Time: 4.71302

Cumulative Model Updates: 244,118
Cumulative Timesteps: 2,036,564,510

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 64,833.64835
Policy Entropy: 2.41205
Value Function Loss: 0.01390

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.07507
Policy Update Magnitude: 0.29175
Value Function Update Magnitude: 0.28935

Collected Steps per Second: 21,500.59885
Overall Steps per Second: 10,473.10871

Timestep Collection Time: 2.32812
Timestep Consumption Time: 2.45136
PPO Batch Consumption Time: 0.29177
Total Iteration Time: 4.77948

Cumulative Model Updates: 244,124
Cumulative Timesteps: 2,036,614,566

Timesteps Collected: 50,056
--------END ITERATION REPORT--------


Saving checkpoint 2036614566...
Checkpoint 2036614566 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 61,910.76517
Policy Entropy: 2.41821
Value Function Loss: 0.01557

Mean KL Divergence: 0.00684
SB3 Clip Fraction: 0.06526
Policy Update Magnitude: 0.29351
Value Function Update Magnitude: 0.28457

Collected Steps per Second: 21,063.55719
Overall Steps per Second: 10,606.11118

Timestep Collection Time: 2.37453
Timestep Consumption Time: 2.34124
PPO Batch Consumption Time: 0.27879
Total Iteration Time: 4.71577

Cumulative Model Updates: 244,130
Cumulative Timesteps: 2,036,664,582

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57,475.93453
Policy Entropy: 2.38863
Value Function Loss: 0.01775

Mean KL Divergence: 0.00691
SB3 Clip Fraction: 0.06440
Policy Update Magnitude: 0.30534
Value Function Update Magnitude: 0.30846

Collected Steps per Second: 21,015.63585
Overall Steps per Second: 10,576.45664

Timestep Collection Time: 2.38013
Timestep Consumption Time: 2.34924
PPO Batch Consumption Time: 0.27799
Total Iteration Time: 4.72937

Cumulative Model Updates: 244,136
Cumulative Timesteps: 2,036,714,602

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2036714602...
Checkpoint 2036714602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 60,341.09324
Policy Entropy: 2.40443
Value Function Loss: 0.01905

Mean KL Divergence: 0.00689
SB3 Clip Fraction: 0.06455
Policy Update Magnitude: 0.31571
Value Function Update Magnitude: 0.33890

Collected Steps per Second: 20,803.54547
Overall Steps per Second: 10,226.59539

Timestep Collection Time: 2.40555
Timestep Consumption Time: 2.48796
PPO Batch Consumption Time: 0.29234
Total Iteration Time: 4.89352

Cumulative Model Updates: 244,142
Cumulative Timesteps: 2,036,764,646

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 72,171.87264
Policy Entropy: 2.42372
Value Function Loss: 0.01691

Mean KL Divergence: 0.00763
SB3 Clip Fraction: 0.06732
Policy Update Magnitude: 0.30926
Value Function Update Magnitude: 0.34089

Collected Steps per Second: 21,794.91006
Overall Steps per Second: 10,498.23219

Timestep Collection Time: 2.29494
Timestep Consumption Time: 2.46948
PPO Batch Consumption Time: 0.29222
Total Iteration Time: 4.76442

Cumulative Model Updates: 244,148
Cumulative Timesteps: 2,036,814,664

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2036814664...
Checkpoint 2036814664 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 82,030.01082
Policy Entropy: 2.42604
Value Function Loss: 0.01434

Mean KL Divergence: 0.00690
SB3 Clip Fraction: 0.06662
Policy Update Magnitude: 0.29599
Value Function Update Magnitude: 0.29417

Collected Steps per Second: 21,094.15692
Overall Steps per Second: 10,467.50518

Timestep Collection Time: 2.37146
Timestep Consumption Time: 2.40752
PPO Batch Consumption Time: 0.27890
Total Iteration Time: 4.77898

Cumulative Model Updates: 244,154
Cumulative Timesteps: 2,036,864,688

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70,927.48689
Policy Entropy: 2.40251
Value Function Loss: 0.01389

Mean KL Divergence: 0.00670
SB3 Clip Fraction: 0.06390
Policy Update Magnitude: 0.28884
Value Function Update Magnitude: 0.24539

Collected Steps per Second: 21,888.78118
Overall Steps per Second: 10,512.05038

Timestep Collection Time: 2.28428
Timestep Consumption Time: 2.47217
PPO Batch Consumption Time: 0.27911
Total Iteration Time: 4.75645

Cumulative Model Updates: 244,160
Cumulative Timesteps: 2,036,914,688

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2036914688...
Checkpoint 2036914688 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 57,626.38090
Policy Entropy: 2.39444
Value Function Loss: 0.01403

Mean KL Divergence: 0.00642
SB3 Clip Fraction: 0.06137
Policy Update Magnitude: 0.28849
Value Function Update Magnitude: 0.20767

Collected Steps per Second: 21,911.54119
Overall Steps per Second: 10,524.15206

Timestep Collection Time: 2.28218
Timestep Consumption Time: 2.46937
PPO Batch Consumption Time: 0.27955
Total Iteration Time: 4.75155

Cumulative Model Updates: 244,166
Cumulative Timesteps: 2,036,964,694

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52,715.34277
Policy Entropy: 2.40002
Value Function Loss: 0.01613

Mean KL Divergence: 0.00770
SB3 Clip Fraction: 0.07228
Policy Update Magnitude: 0.29259
Value Function Update Magnitude: 0.20854

Collected Steps per Second: 22,111.32930
Overall Steps per Second: 10,536.48313

Timestep Collection Time: 2.26336
Timestep Consumption Time: 2.48642
PPO Batch Consumption Time: 0.28685
Total Iteration Time: 4.74978

Cumulative Model Updates: 244,172
Cumulative Timesteps: 2,037,014,740

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 2037014740...
Checkpoint 2037014740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46,533.95828
Policy Entropy: 2.41527
Value Function Loss: 0.01647

Mean KL Divergence: 0.00661
SB3 Clip Fraction: 0.06372
Policy Update Magnitude: 0.29814
Value Function Update Magnitude: 0.24122

Collected Steps per Second: 21,727.86093
Overall Steps per Second: 10,588.85264

Timestep Collection Time: 2.30248
Timestep Consumption Time: 2.42211
PPO Batch Consumption Time: 0.27913
Total Iteration Time: 4.72459

Cumulative Model Updates: 244,178
Cumulative Timesteps: 2,037,064,768

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77,507.71480
Policy Entropy: 2.40868
Value Function Loss: 0.01658

Mean KL Divergence: 0.00628
SB3 Clip Fraction: 0.06035
Policy Update Magnitude: 0.30224
Value Function Update Magnitude: 0.27371

Collected Steps per Second: 21,924.94555
Overall Steps per Second: 10,519.17849

Timestep Collection Time: 2.28242
Timestep Consumption Time: 2.47479
PPO Batch Consumption Time: 0.28583
Total Iteration Time: 4.75722

Cumulative Model Updates: 244,184
Cumulative Timesteps: 2,037,114,810

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 2037114810...
Checkpoint 2037114810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 69,288.81586
Policy Entropy: 2.41975
Value Function Loss: 0.01621

Mean KL Divergence: 0.00684
SB3 Clip Fraction: 0.06583
Policy Update Magnitude: 0.30788
Value Function Update Magnitude: 0.27414

Collected Steps per Second: 21,922.76391
Overall Steps per Second: 10,618.30564

Timestep Collection Time: 2.28192
Timestep Consumption Time: 2.42938
PPO Batch Consumption Time: 0.27928
Total Iteration Time: 4.71130

Cumulative Model Updates: 244,190
Cumulative Timesteps: 2,037,164,836

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50,230.27153
Policy Entropy: 2.43921
Value Function Loss: 0.01641

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.07744
Policy Update Magnitude: 0.30777
Value Function Update Magnitude: 0.25377

Collected Steps per Second: 22,264.61180
Overall Steps per Second: 10,512.32965

Timestep Collection Time: 2.24751
Timestep Consumption Time: 2.51261
PPO Batch Consumption Time: 0.29401
Total Iteration Time: 4.76012

Cumulative Model Updates: 244,196
Cumulative Timesteps: 2,037,214,876

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 2037214876...
Checkpoint 2037214876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,654.43394
Policy Entropy: 2.43505
Value Function Loss: 0.01711

Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.07427
Policy Update Magnitude: 0.30048
Value Function Update Magnitude: 0.28998

Collected Steps per Second: 21,397.31895
Overall Steps per Second: 10,389.77033

Timestep Collection Time: 2.33721
Timestep Consumption Time: 2.47618
PPO Batch Consumption Time: 0.28973
Total Iteration Time: 4.81339

Cumulative Model Updates: 244,202
Cumulative Timesteps: 2,037,264,886

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88,621.03635
Policy Entropy: 2.41583
Value Function Loss: 0.01748

Mean KL Divergence: 0.00695
SB3 Clip Fraction: 0.06356
Policy Update Magnitude: 0.31037
Value Function Update Magnitude: 0.32680

Collected Steps per Second: 21,150.47685
Overall Steps per Second: 10,629.72402

Timestep Collection Time: 2.36496
Timestep Consumption Time: 2.34071
PPO Batch Consumption Time: 0.27797
Total Iteration Time: 4.70567

Cumulative Model Updates: 244,208
Cumulative Timesteps: 2,037,314,906

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2037314906...
Checkpoint 2037314906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 73,333.70195
Policy Entropy: 2.41569
Value Function Loss: 0.01581

Mean KL Divergence: 0.00712
SB3 Clip Fraction: 0.06952
Policy Update Magnitude: 0.30969
Value Function Update Magnitude: 0.31993

Collected Steps per Second: 20,720.81209
Overall Steps per Second: 10,314.95814

Timestep Collection Time: 2.41467
Timestep Consumption Time: 2.43595
PPO Batch Consumption Time: 0.29348
Total Iteration Time: 4.85063

Cumulative Model Updates: 244,214
Cumulative Timesteps: 2,037,364,940

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58,152.58851
Policy Entropy: 2.43294
Value Function Loss: 0.01554

Mean KL Divergence: 0.00703
SB3 Clip Fraction: 0.06806
Policy Update Magnitude: 0.29745
Value Function Update Magnitude: 0.27431

Collected Steps per Second: 21,011.79235
Overall Steps per Second: 10,424.26883

Timestep Collection Time: 2.37981
Timestep Consumption Time: 2.41708
PPO Batch Consumption Time: 0.28650
Total Iteration Time: 4.79688

Cumulative Model Updates: 244,220
Cumulative Timesteps: 2,037,414,944

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2037414944...
Checkpoint 2037414944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 60,628.45393
Policy Entropy: 2.43499
Value Function Loss: 0.01475

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.08100
Policy Update Magnitude: 0.29509
Value Function Update Magnitude: 0.24831

Collected Steps per Second: 21,147.68056
Overall Steps per Second: 10,251.67991

Timestep Collection Time: 2.36461
Timestep Consumption Time: 2.51323
PPO Batch Consumption Time: 0.29285
Total Iteration Time: 4.87783

Cumulative Model Updates: 244,226
Cumulative Timesteps: 2,037,464,950

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66,072.91311
Policy Entropy: 2.41157
Value Function Loss: 0.01812

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.08332
Policy Update Magnitude: 0.30728
Value Function Update Magnitude: 0.29362

Collected Steps per Second: 22,156.77107
Overall Steps per Second: 10,743.02870

Timestep Collection Time: 2.25719
Timestep Consumption Time: 2.39811
PPO Batch Consumption Time: 0.27982
Total Iteration Time: 4.65530

Cumulative Model Updates: 244,232
Cumulative Timesteps: 2,037,514,962

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2037514962...
Checkpoint 2037514962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,488.51788
Policy Entropy: 2.40548
Value Function Loss: 0.01801

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.07361
Policy Update Magnitude: 0.31761
Value Function Update Magnitude: 0.31967

Collected Steps per Second: 21,634.23392
Overall Steps per Second: 10,487.52697

Timestep Collection Time: 2.31143
Timestep Consumption Time: 2.45671
PPO Batch Consumption Time: 0.28927
Total Iteration Time: 4.76814

Cumulative Model Updates: 244,238
Cumulative Timesteps: 2,037,564,968

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65,829.19461
Policy Entropy: 2.41052
Value Function Loss: 0.01642

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.07513
Policy Update Magnitude: 0.30737
Value Function Update Magnitude: 0.28702

Collected Steps per Second: 22,130.68006
Overall Steps per Second: 10,676.83298

Timestep Collection Time: 2.25958
Timestep Consumption Time: 2.42402
PPO Batch Consumption Time: 0.27859
Total Iteration Time: 4.68360

Cumulative Model Updates: 244,244
Cumulative Timesteps: 2,037,614,974

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2037614974...
Checkpoint 2037614974 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 125,599.91986
Policy Entropy: 2.42998
Value Function Loss: 0.01792

Mean KL Divergence: 0.00670
SB3 Clip Fraction: 0.06324
Policy Update Magnitude: 0.30645
Value Function Update Magnitude: 0.23083

Collected Steps per Second: 21,476.56171
Overall Steps per Second: 10,366.57993

Timestep Collection Time: 2.32886
Timestep Consumption Time: 2.49587
PPO Batch Consumption Time: 0.29156
Total Iteration Time: 4.82473

Cumulative Model Updates: 244,250
Cumulative Timesteps: 2,037,664,990

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 114,318.16772
Policy Entropy: 2.41330
Value Function Loss: 0.01624

Mean KL Divergence: 0.00652
SB3 Clip Fraction: 0.06240
Policy Update Magnitude: 0.30122
Value Function Update Magnitude: 0.21281

Collected Steps per Second: 21,983.89000
Overall Steps per Second: 10,507.79744

Timestep Collection Time: 2.27457
Timestep Consumption Time: 2.48418
PPO Batch Consumption Time: 0.28924
Total Iteration Time: 4.75875

Cumulative Model Updates: 244,256
Cumulative Timesteps: 2,037,714,994

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2037714994...
Checkpoint 2037714994 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 80,356.48379
Policy Entropy: 2.40507
Value Function Loss: 0.01657

Mean KL Divergence: 0.00642
SB3 Clip Fraction: 0.06217
Policy Update Magnitude: 0.29937
Value Function Update Magnitude: 0.24401

Collected Steps per Second: 21,476.72675
Overall Steps per Second: 10,517.27284

Timestep Collection Time: 2.32922
Timestep Consumption Time: 2.42715
PPO Batch Consumption Time: 0.27739
Total Iteration Time: 4.75637

Cumulative Model Updates: 244,262
Cumulative Timesteps: 2,037,765,018

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46,617.42033
Policy Entropy: 2.40238
Value Function Loss: 0.01485

Mean KL Divergence: 0.00584
SB3 Clip Fraction: 0.05609
Policy Update Magnitude: 0.28778
Value Function Update Magnitude: 0.24840

Collected Steps per Second: 21,688.55933
Overall Steps per Second: 10,371.45503

Timestep Collection Time: 2.30601
Timestep Consumption Time: 2.51627
PPO Batch Consumption Time: 0.29222
Total Iteration Time: 4.82227

Cumulative Model Updates: 244,268
Cumulative Timesteps: 2,037,815,032

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2037815032...
Checkpoint 2037815032 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 63,291.51012
Policy Entropy: 2.41214
Value Function Loss: 0.01713

Mean KL Divergence: 0.00704
SB3 Clip Fraction: 0.06679
Policy Update Magnitude: 0.29193
Value Function Update Magnitude: 0.25785

Collected Steps per Second: 21,167.71519
Overall Steps per Second: 10,253.77845

Timestep Collection Time: 2.36332
Timestep Consumption Time: 2.51547
PPO Batch Consumption Time: 0.29455
Total Iteration Time: 4.87879

Cumulative Model Updates: 244,274
Cumulative Timesteps: 2,037,865,058

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92,372.17611
Policy Entropy: 2.40637
Value Function Loss: 0.01849

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.07797
Policy Update Magnitude: 0.30553
Value Function Update Magnitude: 0.24960

Collected Steps per Second: 21,823.21078
Overall Steps per Second: 10,366.42848

Timestep Collection Time: 2.29160
Timestep Consumption Time: 2.53263
PPO Batch Consumption Time: 0.29253
Total Iteration Time: 4.82423

Cumulative Model Updates: 244,280
Cumulative Timesteps: 2,037,915,068

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2037915068...
Checkpoint 2037915068 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 65,135.47209
Policy Entropy: 2.39877
Value Function Loss: 0.01815

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.08094
Policy Update Magnitude: 0.31430
Value Function Update Magnitude: 0.25728

Collected Steps per Second: 22,001.85676
Overall Steps per Second: 10,580.31873

Timestep Collection Time: 2.27417
Timestep Consumption Time: 2.45499
PPO Batch Consumption Time: 0.27808
Total Iteration Time: 4.72916

Cumulative Model Updates: 244,286
Cumulative Timesteps: 2,037,965,104

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55,759.41600
Policy Entropy: 2.38683
Value Function Loss: 0.01686

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.08266
Policy Update Magnitude: 0.31605
Value Function Update Magnitude: 0.31818

Collected Steps per Second: 22,229.27928
Overall Steps per Second: 10,552.13061

Timestep Collection Time: 2.25118
Timestep Consumption Time: 2.49118
PPO Batch Consumption Time: 0.28846
Total Iteration Time: 4.74236

Cumulative Model Updates: 244,292
Cumulative Timesteps: 2,038,015,146

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 2038015146...
Checkpoint 2038015146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 50,540.32495
Policy Entropy: 2.38875
Value Function Loss: 0.01504

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.07588
Policy Update Magnitude: 0.31538
Value Function Update Magnitude: 0.29741

Collected Steps per Second: 21,563.18200
Overall Steps per Second: 10,560.42239

Timestep Collection Time: 2.32016
Timestep Consumption Time: 2.41734
PPO Batch Consumption Time: 0.27865
Total Iteration Time: 4.73750

Cumulative Model Updates: 244,298
Cumulative Timesteps: 2,038,065,176

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45,698.42577
Policy Entropy: 2.40462
Value Function Loss: 0.01514

Mean KL Divergence: 0.00705
SB3 Clip Fraction: 0.06459
Policy Update Magnitude: 0.30008
Value Function Update Magnitude: 0.27014

Collected Steps per Second: 22,165.89060
Overall Steps per Second: 10,499.40303

Timestep Collection Time: 2.25581
Timestep Consumption Time: 2.50656
PPO Batch Consumption Time: 0.29110
Total Iteration Time: 4.76237

Cumulative Model Updates: 244,304
Cumulative Timesteps: 2,038,115,178

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2038115178...
Checkpoint 2038115178 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,886.00109
Policy Entropy: 2.41898
Value Function Loss: 0.01594

Mean KL Divergence: 0.00635
SB3 Clip Fraction: 0.05834
Policy Update Magnitude: 0.28895
Value Function Update Magnitude: 0.26872

Collected Steps per Second: 22,071.30228
Overall Steps per Second: 10,646.97043

Timestep Collection Time: 2.26638
Timestep Consumption Time: 2.43186
PPO Batch Consumption Time: 0.27881
Total Iteration Time: 4.69824

Cumulative Model Updates: 244,310
Cumulative Timesteps: 2,038,165,200

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58,032.25701
Policy Entropy: 2.42703
Value Function Loss: 0.01515

Mean KL Divergence: 0.00623
SB3 Clip Fraction: 0.05978
Policy Update Magnitude: 0.28294
Value Function Update Magnitude: 0.26457

Collected Steps per Second: 22,275.11544
Overall Steps per Second: 10,542.24849

Timestep Collection Time: 2.24582
Timestep Consumption Time: 2.49946
PPO Batch Consumption Time: 0.29315
Total Iteration Time: 4.74529

Cumulative Model Updates: 244,316
Cumulative Timesteps: 2,038,215,226

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2038215226...
Checkpoint 2038215226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 76,307.11587
Policy Entropy: 2.41503
Value Function Loss: 0.01552

Mean KL Divergence: 0.00662
SB3 Clip Fraction: 0.06357
Policy Update Magnitude: 0.28817
Value Function Update Magnitude: 0.26640

Collected Steps per Second: 21,995.18655
Overall Steps per Second: 10,658.97269

Timestep Collection Time: 2.27404
Timestep Consumption Time: 2.41853
PPO Batch Consumption Time: 0.27671
Total Iteration Time: 4.69257

Cumulative Model Updates: 244,322
Cumulative Timesteps: 2,038,265,244

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76,688.29305
Policy Entropy: 2.39942
Value Function Loss: 0.01754

Mean KL Divergence: 0.00712
SB3 Clip Fraction: 0.06758
Policy Update Magnitude: 0.30204
Value Function Update Magnitude: 0.29001

Collected Steps per Second: 21,667.64142
Overall Steps per Second: 10,394.55251

Timestep Collection Time: 2.30777
Timestep Consumption Time: 2.50282
PPO Batch Consumption Time: 0.29124
Total Iteration Time: 4.81060

Cumulative Model Updates: 244,328
Cumulative Timesteps: 2,038,315,248

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2038315248...
Checkpoint 2038315248 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 69,500.91775
Policy Entropy: 2.40805
Value Function Loss: 0.01665

Mean KL Divergence: 0.00756
SB3 Clip Fraction: 0.07051
Policy Update Magnitude: 0.29923
Value Function Update Magnitude: 0.31311

Collected Steps per Second: 21,518.71621
Overall Steps per Second: 10,561.20548

Timestep Collection Time: 2.32402
Timestep Consumption Time: 2.41123
PPO Batch Consumption Time: 0.27841
Total Iteration Time: 4.73525

Cumulative Model Updates: 244,334
Cumulative Timesteps: 2,038,365,258

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59,321.39178
Policy Entropy: 2.43607
Value Function Loss: 0.01454

Mean KL Divergence: 0.00622
SB3 Clip Fraction: 0.05704
Policy Update Magnitude: 0.28342
Value Function Update Magnitude: 0.30707

Collected Steps per Second: 21,396.96202
Overall Steps per Second: 10,495.23188

Timestep Collection Time: 2.33818
Timestep Consumption Time: 2.42874
PPO Batch Consumption Time: 0.27822
Total Iteration Time: 4.76693

Cumulative Model Updates: 244,340
Cumulative Timesteps: 2,038,415,288

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2038415288...
Checkpoint 2038415288 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 79,084.35646
Policy Entropy: 2.43079
Value Function Loss: 0.01219

Mean KL Divergence: 0.00537
SB3 Clip Fraction: 0.05410
Policy Update Magnitude: 0.27776
Value Function Update Magnitude: 0.25963

Collected Steps per Second: 21,537.34289
Overall Steps per Second: 10,356.77768

Timestep Collection Time: 2.32313
Timestep Consumption Time: 2.50791
PPO Batch Consumption Time: 0.29289
Total Iteration Time: 4.83104

Cumulative Model Updates: 244,346
Cumulative Timesteps: 2,038,465,322

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56,009.46248
Policy Entropy: 2.42743
Value Function Loss: 0.01317

Mean KL Divergence: 0.00575
SB3 Clip Fraction: 0.05655
Policy Update Magnitude: 0.28230
Value Function Update Magnitude: 0.25130

Collected Steps per Second: 21,747.84002
Overall Steps per Second: 10,349.31097

Timestep Collection Time: 2.29981
Timestep Consumption Time: 2.53297
PPO Batch Consumption Time: 0.29390
Total Iteration Time: 4.83279

Cumulative Model Updates: 244,352
Cumulative Timesteps: 2,038,515,338

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2038515338...
Checkpoint 2038515338 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 133,292.52473
Policy Entropy: 2.39849
Value Function Loss: 0.01466

Mean KL Divergence: 0.00697
SB3 Clip Fraction: 0.06775
Policy Update Magnitude: 0.29089
Value Function Update Magnitude: 0.24779

Collected Steps per Second: 22,050.23933
Overall Steps per Second: 10,547.95505

Timestep Collection Time: 2.26827
Timestep Consumption Time: 2.47350
PPO Batch Consumption Time: 0.27890
Total Iteration Time: 4.74177

Cumulative Model Updates: 244,358
Cumulative Timesteps: 2,038,565,354

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68,169.30430
Policy Entropy: 2.43504
Value Function Loss: 0.01690

Mean KL Divergence: 0.00653
SB3 Clip Fraction: 0.06353
Policy Update Magnitude: 0.29610
Value Function Update Magnitude: 0.28553

Collected Steps per Second: 21,817.95731
Overall Steps per Second: 10,417.37448

Timestep Collection Time: 2.29352
Timestep Consumption Time: 2.50999
PPO Batch Consumption Time: 0.28956
Total Iteration Time: 4.80351

Cumulative Model Updates: 244,364
Cumulative Timesteps: 2,038,615,394

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 2038615394...
Checkpoint 2038615394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84,882.62150
Policy Entropy: 2.41837
Value Function Loss: 0.01559

Mean KL Divergence: 0.00739
SB3 Clip Fraction: 0.06954
Policy Update Magnitude: 0.29544
Value Function Update Magnitude: 0.32167

Collected Steps per Second: 21,721.75948
Overall Steps per Second: 10,421.64973

Timestep Collection Time: 2.30294
Timestep Consumption Time: 2.49706
PPO Batch Consumption Time: 0.29317
Total Iteration Time: 4.80001

Cumulative Model Updates: 244,370
Cumulative Timesteps: 2,038,665,418

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 94,171.98445
Policy Entropy: 2.44345
Value Function Loss: 0.01609

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.07152
Policy Update Magnitude: 0.29789
Value Function Update Magnitude: 0.31353

Collected Steps per Second: 22,446.11620
Overall Steps per Second: 10,723.88242

Timestep Collection Time: 2.22934
Timestep Consumption Time: 2.43688
PPO Batch Consumption Time: 0.27929
Total Iteration Time: 4.66622

Cumulative Model Updates: 244,376
Cumulative Timesteps: 2,038,715,458

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 2038715458...
Checkpoint 2038715458 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 81,977.03023
Policy Entropy: 2.42245
Value Function Loss: 0.01719

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.07952
Policy Update Magnitude: 0.30245
Value Function Update Magnitude: 0.30207

Collected Steps per Second: 22,054.88493
Overall Steps per Second: 10,645.79388

Timestep Collection Time: 2.26734
Timestep Consumption Time: 2.42991
PPO Batch Consumption Time: 0.27922
Total Iteration Time: 4.69725

Cumulative Model Updates: 244,382
Cumulative Timesteps: 2,038,765,464

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65,494.22959
Policy Entropy: 2.44187
Value Function Loss: 0.01851

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.07713
Policy Update Magnitude: 0.30468
Value Function Update Magnitude: 0.33529

Collected Steps per Second: 22,038.09365
Overall Steps per Second: 10,518.03067

Timestep Collection Time: 2.26971
Timestep Consumption Time: 2.48594
PPO Batch Consumption Time: 0.28784
Total Iteration Time: 4.75564

Cumulative Model Updates: 244,388
Cumulative Timesteps: 2,038,815,484

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2038815484...
Checkpoint 2038815484 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 64,754.80633
Policy Entropy: 2.41620
Value Function Loss: 0.01922

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.07062
Policy Update Magnitude: 0.31311
Value Function Update Magnitude: 0.35047

Collected Steps per Second: 21,903.03993
Overall Steps per Second: 10,621.50654

Timestep Collection Time: 2.28398
Timestep Consumption Time: 2.42590
PPO Batch Consumption Time: 0.27889
Total Iteration Time: 4.70988

Cumulative Model Updates: 244,394
Cumulative Timesteps: 2,038,865,510

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56,557.30429
Policy Entropy: 2.42706
Value Function Loss: 0.01658

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.07280
Policy Update Magnitude: 0.31180
Value Function Update Magnitude: 0.34313

Collected Steps per Second: 21,629.54533
Overall Steps per Second: 10,544.86931

Timestep Collection Time: 2.31369
Timestep Consumption Time: 2.43213
PPO Batch Consumption Time: 0.27754
Total Iteration Time: 4.74582

Cumulative Model Updates: 244,400
Cumulative Timesteps: 2,038,915,554

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 2038915554...
Checkpoint 2038915554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46,792.30855
Policy Entropy: 2.42879
Value Function Loss: 0.01660

Mean KL Divergence: 0.00763
SB3 Clip Fraction: 0.07294
Policy Update Magnitude: 0.30295
Value Function Update Magnitude: 0.33529

Collected Steps per Second: 21,380.13589
Overall Steps per Second: 10,491.51515

Timestep Collection Time: 2.33993
Timestep Consumption Time: 2.42850
PPO Batch Consumption Time: 0.27944
Total Iteration Time: 4.76842

Cumulative Model Updates: 244,406
Cumulative Timesteps: 2,038,965,582

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52,652.18894
Policy Entropy: 2.46125
Value Function Loss: 0.01520

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.07745
Policy Update Magnitude: 0.30435
Value Function Update Magnitude: 0.32422

Collected Steps per Second: 21,660.14573
Overall Steps per Second: 10,482.18490

Timestep Collection Time: 2.31033
Timestep Consumption Time: 2.46368
PPO Batch Consumption Time: 0.27903
Total Iteration Time: 4.77400

Cumulative Model Updates: 244,412
Cumulative Timesteps: 2,039,015,624

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 2039015624...
Checkpoint 2039015624 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55,807.39457
Policy Entropy: 2.45274
Value Function Loss: 0.01567

Mean KL Divergence: 0.00730
SB3 Clip Fraction: 0.07316
Policy Update Magnitude: 0.29910
Value Function Update Magnitude: 0.29659

Collected Steps per Second: 21,986.18826
Overall Steps per Second: 10,444.87991

Timestep Collection Time: 2.27443
Timestep Consumption Time: 2.51318
PPO Batch Consumption Time: 0.28881
Total Iteration Time: 4.78761

Cumulative Model Updates: 244,418
Cumulative Timesteps: 2,039,065,630

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62,324.69507
Policy Entropy: 2.45380
Value Function Loss: 0.01434

Mean KL Divergence: 0.00691
SB3 Clip Fraction: 0.06889
Policy Update Magnitude: 0.28538
Value Function Update Magnitude: 0.25553

Collected Steps per Second: 22,239.14514
Overall Steps per Second: 10,630.89364

Timestep Collection Time: 2.24955
Timestep Consumption Time: 2.45636
PPO Batch Consumption Time: 0.27992
Total Iteration Time: 4.70591

Cumulative Model Updates: 244,424
Cumulative Timesteps: 2,039,115,658

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2039115658...
Checkpoint 2039115658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47,031.82432
Policy Entropy: 2.45531
Value Function Loss: 0.01430

Mean KL Divergence: 0.00667
SB3 Clip Fraction: 0.06418
Policy Update Magnitude: 0.28189
Value Function Update Magnitude: 0.24803

Collected Steps per Second: 21,136.79770
Overall Steps per Second: 10,443.76502

Timestep Collection Time: 2.36677
Timestep Consumption Time: 2.42326
PPO Batch Consumption Time: 0.29090
Total Iteration Time: 4.79003

Cumulative Model Updates: 244,430
Cumulative Timesteps: 2,039,165,684

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65,687.22334
Policy Entropy: 2.43798
Value Function Loss: 0.01477

Mean KL Divergence: 0.00679
SB3 Clip Fraction: 0.06336
Policy Update Magnitude: 0.28723
Value Function Update Magnitude: 0.27266

Collected Steps per Second: 21,582.52892
Overall Steps per Second: 10,713.78929

Timestep Collection Time: 2.31743
Timestep Consumption Time: 2.35095
PPO Batch Consumption Time: 0.27938
Total Iteration Time: 4.66838

Cumulative Model Updates: 244,436
Cumulative Timesteps: 2,039,215,700

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2039215700...
Checkpoint 2039215700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 75,631.59639
Policy Entropy: 2.43275
Value Function Loss: 0.01690

Mean KL Divergence: 0.00675
SB3 Clip Fraction: 0.06308
Policy Update Magnitude: 0.29333
Value Function Update Magnitude: 0.30756

Collected Steps per Second: 21,241.00567
Overall Steps per Second: 10,623.56464

Timestep Collection Time: 2.35507
Timestep Consumption Time: 2.35371
PPO Batch Consumption Time: 0.27887
Total Iteration Time: 4.70878

Cumulative Model Updates: 244,442
Cumulative Timesteps: 2,039,265,724

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77,593.97963
Policy Entropy: 2.41553
Value Function Loss: 0.01601

Mean KL Divergence: 0.00691
SB3 Clip Fraction: 0.06788
Policy Update Magnitude: 0.29635
Value Function Update Magnitude: 0.27823

Collected Steps per Second: 21,144.47873
Overall Steps per Second: 10,435.70247

Timestep Collection Time: 2.36544
Timestep Consumption Time: 2.42734
PPO Batch Consumption Time: 0.28881
Total Iteration Time: 4.79278

Cumulative Model Updates: 244,448
Cumulative Timesteps: 2,039,315,740

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2039315740...
Checkpoint 2039315740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,127.99702
Policy Entropy: 2.43961
Value Function Loss: 0.01595

Mean KL Divergence: 0.00743
SB3 Clip Fraction: 0.07375
Policy Update Magnitude: 0.29171
Value Function Update Magnitude: 0.26176

Collected Steps per Second: 20,940.98395
Overall Steps per Second: 10,257.87876

Timestep Collection Time: 2.38766
Timestep Consumption Time: 2.48664
PPO Batch Consumption Time: 0.29301
Total Iteration Time: 4.87430

Cumulative Model Updates: 244,454
Cumulative Timesteps: 2,039,365,740

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77,901.06825
Policy Entropy: 2.45174
Value Function Loss: 0.01604

Mean KL Divergence: 0.00783
SB3 Clip Fraction: 0.07464
Policy Update Magnitude: 0.28921
Value Function Update Magnitude: 0.28992

Collected Steps per Second: 21,664.74264
Overall Steps per Second: 10,470.54884

Timestep Collection Time: 2.30817
Timestep Consumption Time: 2.46770
PPO Batch Consumption Time: 0.28873
Total Iteration Time: 4.77587

Cumulative Model Updates: 244,460
Cumulative Timesteps: 2,039,415,746

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2039415746...
Checkpoint 2039415746 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 68,112.78107
Policy Entropy: 2.47060
Value Function Loss: 0.01703

Mean KL Divergence: 0.00777
SB3 Clip Fraction: 0.07638
Policy Update Magnitude: 0.29111
Value Function Update Magnitude: 0.30899

Collected Steps per Second: 20,332.15114
Overall Steps per Second: 10,259.14471

Timestep Collection Time: 2.46054
Timestep Consumption Time: 2.41589
PPO Batch Consumption Time: 0.27710
Total Iteration Time: 4.87643

Cumulative Model Updates: 244,466
Cumulative Timesteps: 2,039,465,774

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61,873.28476
Policy Entropy: 2.44716
Value Function Loss: 0.01647

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.07861
Policy Update Magnitude: 0.29216
Value Function Update Magnitude: 0.30636

Collected Steps per Second: 21,548.37263
Overall Steps per Second: 10,383.10612

Timestep Collection Time: 2.32268
Timestep Consumption Time: 2.49765
PPO Batch Consumption Time: 0.28711
Total Iteration Time: 4.82033

Cumulative Model Updates: 244,472
Cumulative Timesteps: 2,039,515,824

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 2039515824...
Checkpoint 2039515824 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46,010.33274
Policy Entropy: 2.44165
Value Function Loss: 0.01469

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.07818
Policy Update Magnitude: 0.28627
Value Function Update Magnitude: 0.31226

Collected Steps per Second: 21,512.19858
Overall Steps per Second: 10,557.41296

Timestep Collection Time: 2.32510
Timestep Consumption Time: 2.41261
PPO Batch Consumption Time: 0.27849
Total Iteration Time: 4.73771

Cumulative Model Updates: 244,478
Cumulative Timesteps: 2,039,565,842

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79,426.16561
Policy Entropy: 2.43082
Value Function Loss: 0.01732

Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.07858
Policy Update Magnitude: 0.29945
Value Function Update Magnitude: 0.33119

Collected Steps per Second: 21,897.56065
Overall Steps per Second: 10,591.17562

Timestep Collection Time: 2.28427
Timestep Consumption Time: 2.43853
PPO Batch Consumption Time: 0.27661
Total Iteration Time: 4.72280

Cumulative Model Updates: 244,484
Cumulative Timesteps: 2,039,615,862

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2039615862...
Checkpoint 2039615862 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 56,887.70443
Policy Entropy: 2.44312
Value Function Loss: 0.01660

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.07665
Policy Update Magnitude: 0.30556
Value Function Update Magnitude: 0.34161

Collected Steps per Second: 21,924.38761
Overall Steps per Second: 10,565.15174

Timestep Collection Time: 2.28093
Timestep Consumption Time: 2.45237
PPO Batch Consumption Time: 0.27867
Total Iteration Time: 4.73330

Cumulative Model Updates: 244,490
Cumulative Timesteps: 2,039,665,870

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 74,513.35556
Policy Entropy: 2.44012
Value Function Loss: 0.01599

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.07225
Policy Update Magnitude: 0.30211
Value Function Update Magnitude: 0.33915

Collected Steps per Second: 22,181.95705
Overall Steps per Second: 10,453.07881

Timestep Collection Time: 2.25544
Timestep Consumption Time: 2.53071
PPO Batch Consumption Time: 0.29448
Total Iteration Time: 4.78615

Cumulative Model Updates: 244,496
Cumulative Timesteps: 2,039,715,900

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2039715900...
Checkpoint 2039715900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 81,210.65005
Policy Entropy: 2.45313
Value Function Loss: 0.01660

Mean KL Divergence: 0.00736
SB3 Clip Fraction: 0.07063
Policy Update Magnitude: 0.30057
Value Function Update Magnitude: 0.32529

Collected Steps per Second: 21,734.77374
Overall Steps per Second: 10,562.71224

Timestep Collection Time: 2.30230
Timestep Consumption Time: 2.43512
PPO Batch Consumption Time: 0.27938
Total Iteration Time: 4.73742

Cumulative Model Updates: 244,502
Cumulative Timesteps: 2,039,765,940

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67,262.48714
Policy Entropy: 2.43800
Value Function Loss: 0.01649

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.09278
Policy Update Magnitude: 0.29427
Value Function Update Magnitude: 0.29309

Collected Steps per Second: 21,909.27856
Overall Steps per Second: 10,520.86307

Timestep Collection Time: 2.28296
Timestep Consumption Time: 2.47121
PPO Batch Consumption Time: 0.28553
Total Iteration Time: 4.75417

Cumulative Model Updates: 244,508
Cumulative Timesteps: 2,039,815,958

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2039815958...
Checkpoint 2039815958 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,589.52466
Policy Entropy: 2.44652
Value Function Loss: 0.01845

Mean KL Divergence: 0.01661
SB3 Clip Fraction: 0.12334
Policy Update Magnitude: 0.27795
Value Function Update Magnitude: 0.32029

Collected Steps per Second: 21,867.09021
Overall Steps per Second: 10,605.36701

Timestep Collection Time: 2.28672
Timestep Consumption Time: 2.42825
PPO Batch Consumption Time: 0.27855
Total Iteration Time: 4.71497

Cumulative Model Updates: 244,514
Cumulative Timesteps: 2,039,865,962

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45,190.17943
Policy Entropy: 2.42317
Value Function Loss: 0.01732

Mean KL Divergence: 0.01060
SB3 Clip Fraction: 0.09973
Policy Update Magnitude: 0.29504
Value Function Update Magnitude: 0.34575

Collected Steps per Second: 22,183.01645
Overall Steps per Second: 10,494.33568

Timestep Collection Time: 2.25398
Timestep Consumption Time: 2.51050
PPO Batch Consumption Time: 0.29220
Total Iteration Time: 4.76447

Cumulative Model Updates: 244,520
Cumulative Timesteps: 2,039,915,962

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2039915962...
Checkpoint 2039915962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 51,573.92703
Policy Entropy: 2.41240
Value Function Loss: 0.01637

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.09221
Policy Update Magnitude: 0.31266
Value Function Update Magnitude: 0.36132

Collected Steps per Second: 21,568.15081
Overall Steps per Second: 10,412.21346

Timestep Collection Time: 2.31935
Timestep Consumption Time: 2.48501
PPO Batch Consumption Time: 0.29013
Total Iteration Time: 4.80436

Cumulative Model Updates: 244,526
Cumulative Timesteps: 2,039,965,986

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,563.17613
Policy Entropy: 2.42418
Value Function Loss: 0.01432

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.08648
Policy Update Magnitude: 0.30489
Value Function Update Magnitude: 0.34131

Collected Steps per Second: 21,641.79237
Overall Steps per Second: 10,415.72104

Timestep Collection Time: 2.31044
Timestep Consumption Time: 2.49019
PPO Batch Consumption Time: 0.29107
Total Iteration Time: 4.80063

Cumulative Model Updates: 244,532
Cumulative Timesteps: 2,040,015,988

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2040015988...
Checkpoint 2040015988 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,579.34620
Policy Entropy: 2.42903
Value Function Loss: 0.01293

Mean KL Divergence: 0.00734
SB3 Clip Fraction: 0.06882
Policy Update Magnitude: 0.28850
Value Function Update Magnitude: 0.28679

Collected Steps per Second: 20,837.06225
Overall Steps per Second: 10,565.03128

Timestep Collection Time: 2.40072
Timestep Consumption Time: 2.33414
PPO Batch Consumption Time: 0.27719
Total Iteration Time: 4.73487

Cumulative Model Updates: 244,538
Cumulative Timesteps: 2,040,066,012

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57,262.46473
Policy Entropy: 2.43120
Value Function Loss: 0.01368

Mean KL Divergence: 0.00657
SB3 Clip Fraction: 0.06438
Policy Update Magnitude: 0.29003
Value Function Update Magnitude: 0.27468

Collected Steps per Second: 21,292.11476
Overall Steps per Second: 10,459.19917

Timestep Collection Time: 2.34866
Timestep Consumption Time: 2.43258
PPO Batch Consumption Time: 0.29307
Total Iteration Time: 4.78125

Cumulative Model Updates: 244,544
Cumulative Timesteps: 2,040,116,020

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2040116020...
Checkpoint 2040116020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 57,262.46473
Policy Entropy: 2.42142
Value Function Loss: 0.01356

Mean KL Divergence: 0.00630
SB3 Clip Fraction: 0.06075
Policy Update Magnitude: 0.29825
Value Function Update Magnitude: 0.26216

Collected Steps per Second: 21,100.44757
Overall Steps per Second: 10,615.06755

Timestep Collection Time: 2.37199
Timestep Consumption Time: 2.34301
PPO Batch Consumption Time: 0.27716
Total Iteration Time: 4.71500

Cumulative Model Updates: 244,550
Cumulative Timesteps: 2,040,166,070

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99,965.85272
Policy Entropy: 2.43646
Value Function Loss: 0.01351

Mean KL Divergence: 0.00727
SB3 Clip Fraction: 0.06767
Policy Update Magnitude: 0.29012
Value Function Update Magnitude: 0.25676

Collected Steps per Second: 21,381.00681
Overall Steps per Second: 10,468.46277

Timestep Collection Time: 2.33918
Timestep Consumption Time: 2.43841
PPO Batch Consumption Time: 0.27747
Total Iteration Time: 4.77759

Cumulative Model Updates: 244,556
Cumulative Timesteps: 2,040,216,084

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2040216084...
Checkpoint 2040216084 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 67,116.89981
Policy Entropy: 2.44840
Value Function Loss: 0.01328

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.07512
Policy Update Magnitude: 0.27952
Value Function Update Magnitude: 0.24393

Collected Steps per Second: 21,405.81295
Overall Steps per Second: 10,540.46489

Timestep Collection Time: 2.33750
Timestep Consumption Time: 2.40954
PPO Batch Consumption Time: 0.27845
Total Iteration Time: 4.74704

Cumulative Model Updates: 244,562
Cumulative Timesteps: 2,040,266,120

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 71,361.84453
Policy Entropy: 2.44172
Value Function Loss: 0.01373

Mean KL Divergence: 0.00657
SB3 Clip Fraction: 0.06566
Policy Update Magnitude: 0.27710
Value Function Update Magnitude: 0.26050

Collected Steps per Second: 22,100.40485
Overall Steps per Second: 10,555.31484

Timestep Collection Time: 2.26457
Timestep Consumption Time: 2.47692
PPO Batch Consumption Time: 0.29307
Total Iteration Time: 4.74150

Cumulative Model Updates: 244,568
Cumulative Timesteps: 2,040,316,168

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 2040316168...
Checkpoint 2040316168 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 73,535.81533
Policy Entropy: 2.44868
Value Function Loss: 0.01339

Mean KL Divergence: 0.00624
SB3 Clip Fraction: 0.06285
Policy Update Magnitude: 0.27739
Value Function Update Magnitude: 0.26516

Collected Steps per Second: 21,878.57452
Overall Steps per Second: 10,640.10210

Timestep Collection Time: 2.28571
Timestep Consumption Time: 2.41425
PPO Batch Consumption Time: 0.27745
Total Iteration Time: 4.69995

Cumulative Model Updates: 244,574
Cumulative Timesteps: 2,040,366,176

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51,827.46617
Policy Entropy: 2.44838
Value Function Loss: 0.01522

Mean KL Divergence: 0.00643
SB3 Clip Fraction: 0.06405
Policy Update Magnitude: 0.28902
Value Function Update Magnitude: 0.27692

Collected Steps per Second: 22,119.39235
Overall Steps per Second: 10,518.71231

Timestep Collection Time: 2.26082
Timestep Consumption Time: 2.49337
PPO Batch Consumption Time: 0.29190
Total Iteration Time: 4.75419

Cumulative Model Updates: 244,580
Cumulative Timesteps: 2,040,416,184

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2040416184...
Checkpoint 2040416184 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 77,289.55977
Policy Entropy: 2.44932
Value Function Loss: 0.01515

Mean KL Divergence: 0.00729
SB3 Clip Fraction: 0.07048
Policy Update Magnitude: 0.28914
Value Function Update Magnitude: 0.30789

Collected Steps per Second: 21,903.82250
Overall Steps per Second: 10,494.59026

Timestep Collection Time: 2.28280
Timestep Consumption Time: 2.48175
PPO Batch Consumption Time: 0.28793
Total Iteration Time: 4.76455

Cumulative Model Updates: 244,586
Cumulative Timesteps: 2,040,466,186

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66,174.61767
Policy Entropy: 2.44525
Value Function Loss: 0.01764

Mean KL Divergence: 0.00770
SB3 Clip Fraction: 0.07266
Policy Update Magnitude: 0.28966
Value Function Update Magnitude: 0.33543

Collected Steps per Second: 22,101.69368
Overall Steps per Second: 10,442.63948

Timestep Collection Time: 2.26390
Timestep Consumption Time: 2.52761
PPO Batch Consumption Time: 0.29409
Total Iteration Time: 4.79151

Cumulative Model Updates: 244,592
Cumulative Timesteps: 2,040,516,222

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 2040516222...
Checkpoint 2040516222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 75,305.24773
Policy Entropy: 2.45149
Value Function Loss: 0.01662

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.07765
Policy Update Magnitude: 0.30577
Value Function Update Magnitude: 0.32390

Collected Steps per Second: 21,047.63343
Overall Steps per Second: 10,240.67511

Timestep Collection Time: 2.37604
Timestep Consumption Time: 2.50743
PPO Batch Consumption Time: 0.29407
Total Iteration Time: 4.88347

Cumulative Model Updates: 244,598
Cumulative Timesteps: 2,040,566,232

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78,775.95975
Policy Entropy: 2.46623
Value Function Loss: 0.01575

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.07878
Policy Update Magnitude: 0.30258
Value Function Update Magnitude: 0.29782

Collected Steps per Second: 21,649.71991
Overall Steps per Second: 10,463.98156

Timestep Collection Time: 2.31042
Timestep Consumption Time: 2.46978
PPO Batch Consumption Time: 0.28837
Total Iteration Time: 4.78021

Cumulative Model Updates: 244,604
Cumulative Timesteps: 2,040,616,252

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2040616252...
Checkpoint 2040616252 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84,584.24059
Policy Entropy: 2.46480
Value Function Loss: 0.01471

Mean KL Divergence: 0.00713
SB3 Clip Fraction: 0.06478
Policy Update Magnitude: 0.29395
Value Function Update Magnitude: 0.25195

Collected Steps per Second: 21,224.74365
Overall Steps per Second: 10,310.77793

Timestep Collection Time: 2.35715
Timestep Consumption Time: 2.49505
PPO Batch Consumption Time: 0.29212
Total Iteration Time: 4.85220

Cumulative Model Updates: 244,610
Cumulative Timesteps: 2,040,666,282

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 96,573.20624
Policy Entropy: 2.45207
Value Function Loss: 0.01386

Mean KL Divergence: 0.00667
SB3 Clip Fraction: 0.06398
Policy Update Magnitude: 0.28585
Value Function Update Magnitude: 0.21688

Collected Steps per Second: 21,389.89706
Overall Steps per Second: 10,519.01353

Timestep Collection Time: 2.33952
Timestep Consumption Time: 2.41777
PPO Batch Consumption Time: 0.28953
Total Iteration Time: 4.75729

Cumulative Model Updates: 244,616
Cumulative Timesteps: 2,040,716,324

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 2040716324...
Checkpoint 2040716324 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86,916.98024
Policy Entropy: 2.46399
Value Function Loss: 0.01369

Mean KL Divergence: 0.00710
SB3 Clip Fraction: 0.06868
Policy Update Magnitude: 0.27810
Value Function Update Magnitude: 0.21977

Collected Steps per Second: 21,077.26966
Overall Steps per Second: 10,450.81272

Timestep Collection Time: 2.37365
Timestep Consumption Time: 2.41354
PPO Batch Consumption Time: 0.28850
Total Iteration Time: 4.78719

Cumulative Model Updates: 244,622
Cumulative Timesteps: 2,040,766,354

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 106,916.87008
Policy Entropy: 2.47707
Value Function Loss: 0.01343

Mean KL Divergence: 0.00611
SB3 Clip Fraction: 0.05856
Policy Update Magnitude: 0.27680
Value Function Update Magnitude: 0.25981

Collected Steps per Second: 21,669.96003
Overall Steps per Second: 10,497.55049

Timestep Collection Time: 2.30863
Timestep Consumption Time: 2.45705
PPO Batch Consumption Time: 0.29293
Total Iteration Time: 4.76568

Cumulative Model Updates: 244,628
Cumulative Timesteps: 2,040,816,382

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2040816382...
Checkpoint 2040816382 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 92,478.91750
Policy Entropy: 2.46551
Value Function Loss: 0.01549

Mean KL Divergence: 0.00590
SB3 Clip Fraction: 0.05671
Policy Update Magnitude: 0.27964
Value Function Update Magnitude: 0.26702

Collected Steps per Second: 21,025.94238
Overall Steps per Second: 10,225.22777

Timestep Collection Time: 2.37849
Timestep Consumption Time: 2.51235
PPO Batch Consumption Time: 0.29416
Total Iteration Time: 4.89084

Cumulative Model Updates: 244,634
Cumulative Timesteps: 2,040,866,392

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89,796.10564
Policy Entropy: 2.45639
Value Function Loss: 0.01737

Mean KL Divergence: 0.00623
SB3 Clip Fraction: 0.06011
Policy Update Magnitude: 0.28977
Value Function Update Magnitude: 0.26050

Collected Steps per Second: 22,097.93032
Overall Steps per Second: 10,585.71735

Timestep Collection Time: 2.26356
Timestep Consumption Time: 2.46167
PPO Batch Consumption Time: 0.28867
Total Iteration Time: 4.72523

Cumulative Model Updates: 244,640
Cumulative Timesteps: 2,040,916,412

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2040916412...
Checkpoint 2040916412 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 72,356.53104
Policy Entropy: 2.45564
Value Function Loss: 0.01779

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.07470
Policy Update Magnitude: 0.29134
Value Function Update Magnitude: 0.29296

Collected Steps per Second: 21,937.08589
Overall Steps per Second: 10,514.54825

Timestep Collection Time: 2.28107
Timestep Consumption Time: 2.47805
PPO Batch Consumption Time: 0.29381
Total Iteration Time: 4.75912

Cumulative Model Updates: 244,646
Cumulative Timesteps: 2,040,966,452

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50,356.18497
Policy Entropy: 2.45206
Value Function Loss: 0.01802

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.08105
Policy Update Magnitude: 0.30591
Value Function Update Magnitude: 0.32019

Collected Steps per Second: 22,205.38418
Overall Steps per Second: 10,755.78919

Timestep Collection Time: 2.25297
Timestep Consumption Time: 2.39830
PPO Batch Consumption Time: 0.27887
Total Iteration Time: 4.65126

Cumulative Model Updates: 244,652
Cumulative Timesteps: 2,041,016,480

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2041016480...
Checkpoint 2041016480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 52,168.12574
Policy Entropy: 2.45903
Value Function Loss: 0.01662

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.07284
Policy Update Magnitude: 0.30493
Value Function Update Magnitude: 0.33717

Collected Steps per Second: 21,928.23027
Overall Steps per Second: 10,632.17858

Timestep Collection Time: 2.28062
Timestep Consumption Time: 2.42302
PPO Batch Consumption Time: 0.27825
Total Iteration Time: 4.70365

Cumulative Model Updates: 244,658
Cumulative Timesteps: 2,041,066,490

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82,098.27385
Policy Entropy: 2.45364
Value Function Loss: 0.01736

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.07153
Policy Update Magnitude: 0.29553
Value Function Update Magnitude: 0.33291

Collected Steps per Second: 21,861.16629
Overall Steps per Second: 10,509.29217

Timestep Collection Time: 2.28771
Timestep Consumption Time: 2.47113
PPO Batch Consumption Time: 0.28591
Total Iteration Time: 4.75884

Cumulative Model Updates: 244,664
Cumulative Timesteps: 2,041,116,502

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2041116502...
Checkpoint 2041116502 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 82,098.27385
Policy Entropy: 2.47031
Value Function Loss: 0.01354

Mean KL Divergence: 0.00676
SB3 Clip Fraction: 0.06531
Policy Update Magnitude: 0.28143
Value Function Update Magnitude: 0.30750

Collected Steps per Second: 21,622.94835
Overall Steps per Second: 10,566.27536

Timestep Collection Time: 2.31254
Timestep Consumption Time: 2.41987
PPO Batch Consumption Time: 0.27858
Total Iteration Time: 4.73242

Cumulative Model Updates: 244,670
Cumulative Timesteps: 2,041,166,506

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 96,775.29963
Policy Entropy: 2.48042
Value Function Loss: 0.01267

Mean KL Divergence: 0.00663
SB3 Clip Fraction: 0.06522
Policy Update Magnitude: 0.26893
Value Function Update Magnitude: 0.27019

Collected Steps per Second: 21,437.29146
Overall Steps per Second: 10,479.03627

Timestep Collection Time: 2.33248
Timestep Consumption Time: 2.43914
PPO Batch Consumption Time: 0.27866
Total Iteration Time: 4.77162

Cumulative Model Updates: 244,676
Cumulative Timesteps: 2,041,216,508

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2041216508...
Checkpoint 2041216508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86,865.58700
Policy Entropy: 2.45079
Value Function Loss: 0.01243

Mean KL Divergence: 0.00621
SB3 Clip Fraction: 0.06091
Policy Update Magnitude: 0.27753
Value Function Update Magnitude: 0.26944

Collected Steps per Second: 21,592.07203
Overall Steps per Second: 10,381.36830

Timestep Collection Time: 2.31585
Timestep Consumption Time: 2.50086
PPO Batch Consumption Time: 0.29276
Total Iteration Time: 4.81671

Cumulative Model Updates: 244,682
Cumulative Timesteps: 2,041,266,512

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 118,459.89427
Policy Entropy: 2.43466
Value Function Loss: 0.01492

Mean KL Divergence: 0.00641
SB3 Clip Fraction: 0.05878
Policy Update Magnitude: 0.30591
Value Function Update Magnitude: 0.32028

Collected Steps per Second: 21,539.95570
Overall Steps per Second: 10,321.40065

Timestep Collection Time: 2.32247
Timestep Consumption Time: 2.52435
PPO Batch Consumption Time: 0.29302
Total Iteration Time: 4.84682

Cumulative Model Updates: 244,688
Cumulative Timesteps: 2,041,316,538

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2041316538...
Checkpoint 2041316538 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 97,897.02990
Policy Entropy: 2.41625
Value Function Loss: 0.01629

Mean KL Divergence: 0.00725
SB3 Clip Fraction: 0.06377
Policy Update Magnitude: 0.31990
Value Function Update Magnitude: 0.34022

Collected Steps per Second: 20,788.71165
Overall Steps per Second: 10,175.67153

Timestep Collection Time: 2.40592
Timestep Consumption Time: 2.50933
PPO Batch Consumption Time: 0.28982
Total Iteration Time: 4.91525

Cumulative Model Updates: 244,694
Cumulative Timesteps: 2,041,366,554

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91,668.73610
Policy Entropy: 2.43825
Value Function Loss: 0.01621

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.07843
Policy Update Magnitude: 0.31223
Value Function Update Magnitude: 0.32689

Collected Steps per Second: 21,596.69647
Overall Steps per Second: 10,545.80177

Timestep Collection Time: 2.31517
Timestep Consumption Time: 2.42605
PPO Batch Consumption Time: 0.27680
Total Iteration Time: 4.74122

Cumulative Model Updates: 244,700
Cumulative Timesteps: 2,041,416,554

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2041416554...
Checkpoint 2041416554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89,524.66564
Policy Entropy: 2.45472
Value Function Loss: 0.01468

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.07037
Policy Update Magnitude: 0.29734
Value Function Update Magnitude: 0.29909

Collected Steps per Second: 21,435.73472
Overall Steps per Second: 10,505.14368

Timestep Collection Time: 2.33293
Timestep Consumption Time: 2.42741
PPO Batch Consumption Time: 0.27917
Total Iteration Time: 4.76033

Cumulative Model Updates: 244,706
Cumulative Timesteps: 2,041,466,562

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75,806.75151
Policy Entropy: 2.47644
Value Function Loss: 0.01407

Mean KL Divergence: 0.00720
SB3 Clip Fraction: 0.06817
Policy Update Magnitude: 0.29062
Value Function Update Magnitude: 0.24769

Collected Steps per Second: 21,542.20017
Overall Steps per Second: 10,499.60465

Timestep Collection Time: 2.32195
Timestep Consumption Time: 2.44203
PPO Batch Consumption Time: 0.27772
Total Iteration Time: 4.76399

Cumulative Model Updates: 244,712
Cumulative Timesteps: 2,041,516,582

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2041516582...
Checkpoint 2041516582 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 63,938.70738
Policy Entropy: 2.45592
Value Function Loss: 0.01491

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.07717
Policy Update Magnitude: 0.28111
Value Function Update Magnitude: 0.20158

Collected Steps per Second: 21,617.70147
Overall Steps per Second: 10,329.16358

Timestep Collection Time: 2.31431
Timestep Consumption Time: 2.52926
PPO Batch Consumption Time: 0.29214
Total Iteration Time: 4.84357

Cumulative Model Updates: 244,718
Cumulative Timesteps: 2,041,566,612

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54,803.88968
Policy Entropy: 2.44505
Value Function Loss: 0.01585

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.08385
Policy Update Magnitude: 0.28906
Value Function Update Magnitude: 0.18321

Collected Steps per Second: 22,102.05378
Overall Steps per Second: 10,496.40725

Timestep Collection Time: 2.26314
Timestep Consumption Time: 2.50230
PPO Batch Consumption Time: 0.28952
Total Iteration Time: 4.76544

Cumulative Model Updates: 244,724
Cumulative Timesteps: 2,041,616,632

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2041616632...
Checkpoint 2041616632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 60,130.25456
Policy Entropy: 2.44686
Value Function Loss: 0.01521

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.07646
Policy Update Magnitude: 0.29657
Value Function Update Magnitude: 0.24659

Collected Steps per Second: 22,036.20447
Overall Steps per Second: 10,497.88051

Timestep Collection Time: 2.27099
Timestep Consumption Time: 2.49607
PPO Batch Consumption Time: 0.29106
Total Iteration Time: 4.76706

Cumulative Model Updates: 244,730
Cumulative Timesteps: 2,041,666,676

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80,578.69604
Policy Entropy: 2.43798
Value Function Loss: 0.01533

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.07591
Policy Update Magnitude: 0.29477
Value Function Update Magnitude: 0.28352

Collected Steps per Second: 22,101.28958
Overall Steps per Second: 10,449.89106

Timestep Collection Time: 2.26385
Timestep Consumption Time: 2.52414
PPO Batch Consumption Time: 0.29311
Total Iteration Time: 4.78799

Cumulative Model Updates: 244,736
Cumulative Timesteps: 2,041,716,710

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 2041716710...
Checkpoint 2041716710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 80,645.65803
Policy Entropy: 2.43649
Value Function Loss: 0.01497

Mean KL Divergence: 0.00684
SB3 Clip Fraction: 0.06465
Policy Update Magnitude: 0.29762
Value Function Update Magnitude: 0.28296

Collected Steps per Second: 21,572.38910
Overall Steps per Second: 10,545.23977

Timestep Collection Time: 2.31954
Timestep Consumption Time: 2.42554
PPO Batch Consumption Time: 0.27935
Total Iteration Time: 4.74508

Cumulative Model Updates: 244,742
Cumulative Timesteps: 2,041,766,748

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60,944.06505
Policy Entropy: 2.43482
Value Function Loss: 0.01520

Mean KL Divergence: 0.00727
SB3 Clip Fraction: 0.06873
Policy Update Magnitude: 0.29684
Value Function Update Magnitude: 0.30718

Collected Steps per Second: 22,095.79548
Overall Steps per Second: 10,638.75697

Timestep Collection Time: 2.26378
Timestep Consumption Time: 2.43790
PPO Batch Consumption Time: 0.27751
Total Iteration Time: 4.70168

Cumulative Model Updates: 244,748
Cumulative Timesteps: 2,041,816,768

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2041816768...
Checkpoint 2041816768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55,248.21231
Policy Entropy: 2.44111
Value Function Loss: 0.01662

Mean KL Divergence: 0.00766
SB3 Clip Fraction: 0.06990
Policy Update Magnitude: 0.30139
Value Function Update Magnitude: 0.29140

Collected Steps per Second: 21,865.10557
Overall Steps per Second: 10,614.92033

Timestep Collection Time: 2.28711
Timestep Consumption Time: 2.42399
PPO Batch Consumption Time: 0.27725
Total Iteration Time: 4.71110

Cumulative Model Updates: 244,754
Cumulative Timesteps: 2,041,866,776

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49,080.86436
Policy Entropy: 2.45283
Value Function Loss: 0.01575

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.07396
Policy Update Magnitude: 0.30124
Value Function Update Magnitude: 0.27981

Collected Steps per Second: 21,658.96579
Overall Steps per Second: 10,384.64726

Timestep Collection Time: 2.31008
Timestep Consumption Time: 2.50799
PPO Batch Consumption Time: 0.29129
Total Iteration Time: 4.81807

Cumulative Model Updates: 244,760
Cumulative Timesteps: 2,041,916,810

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 2041916810...
Checkpoint 2041916810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,758.97567
Policy Entropy: 2.43262
Value Function Loss: 0.01617

Mean KL Divergence: 0.00748
SB3 Clip Fraction: 0.06744
Policy Update Magnitude: 0.30533
Value Function Update Magnitude: 0.33146

Collected Steps per Second: 21,460.19525
Overall Steps per Second: 10,386.94895

Timestep Collection Time: 2.33045
Timestep Consumption Time: 2.48443
PPO Batch Consumption Time: 0.28970
Total Iteration Time: 4.81489

Cumulative Model Updates: 244,766
Cumulative Timesteps: 2,041,966,822

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49,758.97567
Policy Entropy: 2.43967
Value Function Loss: 0.01406

Mean KL Divergence: 0.00679
SB3 Clip Fraction: 0.06078
Policy Update Magnitude: 0.29651
Value Function Update Magnitude: 0.32246

Collected Steps per Second: 21,332.06608
Overall Steps per Second: 10,319.11381

Timestep Collection Time: 2.34501
Timestep Consumption Time: 2.50269
PPO Batch Consumption Time: 0.29322
Total Iteration Time: 4.84770

Cumulative Model Updates: 244,772
Cumulative Timesteps: 2,042,016,846

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2042016846...
Checkpoint 2042016846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 79,433.01737
Policy Entropy: 2.45494
Value Function Loss: 0.01659

Mean KL Divergence: 0.00633
SB3 Clip Fraction: 0.05743
Policy Update Magnitude: 0.29850
Value Function Update Magnitude: 0.29446

Collected Steps per Second: 21,490.81306
Overall Steps per Second: 10,523.81312

Timestep Collection Time: 2.32844
Timestep Consumption Time: 2.42649
PPO Batch Consumption Time: 0.27866
Total Iteration Time: 4.75493

Cumulative Model Updates: 244,778
Cumulative Timesteps: 2,042,066,886

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89,442.52693
Policy Entropy: 2.47001
Value Function Loss: 0.01672

Mean KL Divergence: 0.00599
SB3 Clip Fraction: 0.05829
Policy Update Magnitude: 0.30518
Value Function Update Magnitude: 0.28630

Collected Steps per Second: 21,539.40043
Overall Steps per Second: 10,495.69692

Timestep Collection Time: 2.32188
Timestep Consumption Time: 2.44312
PPO Batch Consumption Time: 0.27812
Total Iteration Time: 4.76500

Cumulative Model Updates: 244,784
Cumulative Timesteps: 2,042,116,898

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2042116898...
Checkpoint 2042116898 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 91,239.60255
Policy Entropy: 2.45160
Value Function Loss: 0.01661

Mean KL Divergence: 0.00713
SB3 Clip Fraction: 0.06650
Policy Update Magnitude: 0.30744
Value Function Update Magnitude: 0.29666

Collected Steps per Second: 21,854.46938
Overall Steps per Second: 10,372.80511

Timestep Collection Time: 2.28887
Timestep Consumption Time: 2.53355
PPO Batch Consumption Time: 0.29146
Total Iteration Time: 4.82242

Cumulative Model Updates: 244,790
Cumulative Timesteps: 2,042,166,920

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76,061.10171
Policy Entropy: 2.44719
Value Function Loss: 0.01553

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.07252
Policy Update Magnitude: 0.30476
Value Function Update Magnitude: 0.30844

Collected Steps per Second: 21,980.17162
Overall Steps per Second: 10,449.54998

Timestep Collection Time: 2.27587
Timestep Consumption Time: 2.51132
PPO Batch Consumption Time: 0.28962
Total Iteration Time: 4.78719

Cumulative Model Updates: 244,796
Cumulative Timesteps: 2,042,216,944

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2042216944...
Checkpoint 2042216944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 76,061.10171
Policy Entropy: 2.44163
Value Function Loss: 0.01336

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.07158
Policy Update Magnitude: 0.29521
Value Function Update Magnitude: 0.32980

Collected Steps per Second: 21,964.64086
Overall Steps per Second: 10,460.91263

Timestep Collection Time: 2.27711
Timestep Consumption Time: 2.50411
PPO Batch Consumption Time: 0.29178
Total Iteration Time: 4.78123

Cumulative Model Updates: 244,802
Cumulative Timesteps: 2,042,266,960

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 96,755.53944
Policy Entropy: 2.45949
Value Function Loss: 0.01391

Mean KL Divergence: 0.00782
SB3 Clip Fraction: 0.07144
Policy Update Magnitude: 0.28959
Value Function Update Magnitude: 0.30618

Collected Steps per Second: 21,970.58697
Overall Steps per Second: 10,453.68224

Timestep Collection Time: 2.27613
Timestep Consumption Time: 2.50763
PPO Batch Consumption Time: 0.29262
Total Iteration Time: 4.78377

Cumulative Model Updates: 244,808
Cumulative Timesteps: 2,042,316,968

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2042316968...
Checkpoint 2042316968 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 109,607.02081
Policy Entropy: 2.47079
Value Function Loss: 0.01455

Mean KL Divergence: 0.00655
SB3 Clip Fraction: 0.06335
Policy Update Magnitude: 0.29726
Value Function Update Magnitude: 0.30057

Collected Steps per Second: 21,605.72692
Overall Steps per Second: 10,561.37418

Timestep Collection Time: 2.31605
Timestep Consumption Time: 2.42197
PPO Batch Consumption Time: 0.27850
Total Iteration Time: 4.73802

Cumulative Model Updates: 244,814
Cumulative Timesteps: 2,042,367,008

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 98,596.61096
Policy Entropy: 2.48388
Value Function Loss: 0.01388

Mean KL Divergence: 0.00619
SB3 Clip Fraction: 0.05925
Policy Update Magnitude: 0.29371
Value Function Update Magnitude: 0.30808

Collected Steps per Second: 21,934.94134
Overall Steps per Second: 10,615.74776

Timestep Collection Time: 2.27965
Timestep Consumption Time: 2.43071
PPO Batch Consumption Time: 0.27719
Total Iteration Time: 4.71036

Cumulative Model Updates: 244,820
Cumulative Timesteps: 2,042,417,012

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2042417012...
Checkpoint 2042417012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 66,219.60505
Policy Entropy: 2.47689
Value Function Loss: 0.01447

Mean KL Divergence: 0.00614
SB3 Clip Fraction: 0.06053
Policy Update Magnitude: 0.29032
Value Function Update Magnitude: 0.29761

Collected Steps per Second: 21,723.10991
Overall Steps per Second: 10,612.18361

Timestep Collection Time: 2.30262
Timestep Consumption Time: 2.41083
PPO Batch Consumption Time: 0.27759
Total Iteration Time: 4.71345

Cumulative Model Updates: 244,826
Cumulative Timesteps: 2,042,467,032

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62,898.59531
Policy Entropy: 2.47923
Value Function Loss: 0.01541

Mean KL Divergence: 0.00706
SB3 Clip Fraction: 0.07012
Policy Update Magnitude: 0.30144
Value Function Update Magnitude: 0.29478

Collected Steps per Second: 21,487.11840
Overall Steps per Second: 10,375.82849

Timestep Collection Time: 2.32781
Timestep Consumption Time: 2.49281
PPO Batch Consumption Time: 0.28742
Total Iteration Time: 4.82063

Cumulative Model Updates: 244,832
Cumulative Timesteps: 2,042,517,050

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2042517050...
Checkpoint 2042517050 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 51,734.92579
Policy Entropy: 2.46711
Value Function Loss: 0.01473

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.07864
Policy Update Magnitude: 0.29795
Value Function Update Magnitude: 0.31492

Collected Steps per Second: 21,493.71203
Overall Steps per Second: 10,358.39393

Timestep Collection Time: 2.32784
Timestep Consumption Time: 2.50244
PPO Batch Consumption Time: 0.29213
Total Iteration Time: 4.83029

Cumulative Model Updates: 244,838
Cumulative Timesteps: 2,042,567,084

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99,919.89946
Policy Entropy: 2.48479
Value Function Loss: 0.01342

Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.07282
Policy Update Magnitude: 0.28536
Value Function Update Magnitude: 0.30116

Collected Steps per Second: 21,606.26149
Overall Steps per Second: 10,371.26062

Timestep Collection Time: 2.31572
Timestep Consumption Time: 2.50858
PPO Batch Consumption Time: 0.29284
Total Iteration Time: 4.82429

Cumulative Model Updates: 244,844
Cumulative Timesteps: 2,042,617,118

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 2042617118...
Checkpoint 2042617118 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 110,084.34704
Policy Entropy: 2.48079
Value Function Loss: 0.01127

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.08001
Policy Update Magnitude: 0.27862
Value Function Update Magnitude: 0.27726

Collected Steps per Second: 21,074.33886
Overall Steps per Second: 10,234.26270

Timestep Collection Time: 2.37388
Timestep Consumption Time: 2.51440
PPO Batch Consumption Time: 0.29360
Total Iteration Time: 4.88829

Cumulative Model Updates: 244,850
Cumulative Timesteps: 2,042,667,146

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80,388.17550
Policy Entropy: 2.45958
Value Function Loss: 0.01334

Mean KL Divergence: 0.00783
SB3 Clip Fraction: 0.07308
Policy Update Magnitude: 0.27980
Value Function Update Magnitude: 0.27302

Collected Steps per Second: 21,718.46744
Overall Steps per Second: 10,379.90192

Timestep Collection Time: 2.30311
Timestep Consumption Time: 2.51582
PPO Batch Consumption Time: 0.29282
Total Iteration Time: 4.81893

Cumulative Model Updates: 244,856
Cumulative Timesteps: 2,042,717,166

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2042717166...
Checkpoint 2042717166 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 94,829.42768
Policy Entropy: 2.43386
Value Function Loss: 0.01484

Mean KL Divergence: 0.00668
SB3 Clip Fraction: 0.06574
Policy Update Magnitude: 0.29659
Value Function Update Magnitude: 0.29359

Collected Steps per Second: 21,835.42517
Overall Steps per Second: 10,553.72159

Timestep Collection Time: 2.29059
Timestep Consumption Time: 2.44859
PPO Batch Consumption Time: 0.27843
Total Iteration Time: 4.73918

Cumulative Model Updates: 244,862
Cumulative Timesteps: 2,042,767,182

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79,514.98809
Policy Entropy: 2.42142
Value Function Loss: 0.01567

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.07554
Policy Update Magnitude: 0.30166
Value Function Update Magnitude: 0.32243

Collected Steps per Second: 22,097.54102
Overall Steps per Second: 10,530.98112

Timestep Collection Time: 2.26270
Timestep Consumption Time: 2.48520
PPO Batch Consumption Time: 0.28585
Total Iteration Time: 4.74790

Cumulative Model Updates: 244,868
Cumulative Timesteps: 2,042,817,182

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2042817182...
Checkpoint 2042817182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 57,108.69679
Policy Entropy: 2.43348
Value Function Loss: 0.01561

Mean KL Divergence: 0.00737
SB3 Clip Fraction: 0.06761
Policy Update Magnitude: 0.30470
Value Function Update Magnitude: 0.33575

Collected Steps per Second: 22,026.85278
Overall Steps per Second: 10,623.88041

Timestep Collection Time: 2.27032
Timestep Consumption Time: 2.43681
PPO Batch Consumption Time: 0.27946
Total Iteration Time: 4.70713

Cumulative Model Updates: 244,874
Cumulative Timesteps: 2,042,867,190

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67,337.95222
Policy Entropy: 2.47013
Value Function Loss: 0.01525

Mean KL Divergence: 0.00746
SB3 Clip Fraction: 0.07266
Policy Update Magnitude: 0.29606
Value Function Update Magnitude: 0.30188

Collected Steps per Second: 22,069.72733
Overall Steps per Second: 10,457.54935

Timestep Collection Time: 2.26682
Timestep Consumption Time: 2.51710
PPO Batch Consumption Time: 0.29280
Total Iteration Time: 4.78391

Cumulative Model Updates: 244,880
Cumulative Timesteps: 2,042,917,218

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2042917218...
Checkpoint 2042917218 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 56,948.85956
Policy Entropy: 2.47548
Value Function Loss: 0.01460

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.08850
Policy Update Magnitude: 0.28407
Value Function Update Magnitude: 0.29209

Collected Steps per Second: 21,990.72792
Overall Steps per Second: 10,623.20758

Timestep Collection Time: 2.27496
Timestep Consumption Time: 2.43435
PPO Batch Consumption Time: 0.27923
Total Iteration Time: 4.70931

Cumulative Model Updates: 244,886
Cumulative Timesteps: 2,042,967,246

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84,793.00363
Policy Entropy: 2.47002
Value Function Loss: 0.01335

Mean KL Divergence: 0.01361
SB3 Clip Fraction: 0.10882
Policy Update Magnitude: 0.27205
Value Function Update Magnitude: 0.28453

Collected Steps per Second: 22,025.96694
Overall Steps per Second: 10,473.64987

Timestep Collection Time: 2.27005
Timestep Consumption Time: 2.50384
PPO Batch Consumption Time: 0.29263
Total Iteration Time: 4.77388

Cumulative Model Updates: 244,892
Cumulative Timesteps: 2,043,017,246

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2043017246...
Checkpoint 2043017246 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 77,661.31020
Policy Entropy: 2.45654
Value Function Loss: 0.01437

Mean KL Divergence: 0.01632
SB3 Clip Fraction: 0.12011
Policy Update Magnitude: 0.29134
Value Function Update Magnitude: 0.31376

Collected Steps per Second: 22,335.32796
Overall Steps per Second: 10,663.36374

Timestep Collection Time: 2.23995
Timestep Consumption Time: 2.45182
PPO Batch Consumption Time: 0.28321
Total Iteration Time: 4.69177

Cumulative Model Updates: 244,898
Cumulative Timesteps: 2,043,067,276

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68,921.48791
Policy Entropy: 2.43218
Value Function Loss: 0.01644

Mean KL Divergence: 0.01556
SB3 Clip Fraction: 0.11550
Policy Update Magnitude: 0.30419
Value Function Update Magnitude: 0.32350

Collected Steps per Second: 21,042.51563
Overall Steps per Second: 10,441.64077

Timestep Collection Time: 2.37624
Timestep Consumption Time: 2.41247
PPO Batch Consumption Time: 0.28853
Total Iteration Time: 4.78871

Cumulative Model Updates: 244,904
Cumulative Timesteps: 2,043,117,278

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2043117278...
Checkpoint 2043117278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 68,921.48791
Policy Entropy: 2.43524
Value Function Loss: 0.01527

Mean KL Divergence: 0.01303
SB3 Clip Fraction: 0.10413
Policy Update Magnitude: 0.30540
Value Function Update Magnitude: 0.33834

Collected Steps per Second: 20,678.16135
Overall Steps per Second: 10,351.20130

Timestep Collection Time: 2.41917
Timestep Consumption Time: 2.41351
PPO Batch Consumption Time: 0.29008
Total Iteration Time: 4.83268

Cumulative Model Updates: 244,910
Cumulative Timesteps: 2,043,167,302

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 119,431.18799
Policy Entropy: 2.42426
Value Function Loss: 0.01655

Mean KL Divergence: 0.01119
SB3 Clip Fraction: 0.09755
Policy Update Magnitude: 0.31096
Value Function Update Magnitude: 0.35282

Collected Steps per Second: 20,731.03830
Overall Steps per Second: 10,282.64888

Timestep Collection Time: 2.41271
Timestep Consumption Time: 2.45160
PPO Batch Consumption Time: 0.28853
Total Iteration Time: 4.86431

Cumulative Model Updates: 244,916
Cumulative Timesteps: 2,043,217,320

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2043217320...
Checkpoint 2043217320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 110,646.32457
Policy Entropy: 2.42618
Value Function Loss: 0.01409

Mean KL Divergence: 0.01058
SB3 Clip Fraction: 0.09291
Policy Update Magnitude: 0.30510
Value Function Update Magnitude: 0.34982

Collected Steps per Second: 20,826.96390
Overall Steps per Second: 10,207.91128

Timestep Collection Time: 2.40112
Timestep Consumption Time: 2.49783
PPO Batch Consumption Time: 0.29188
Total Iteration Time: 4.89895

Cumulative Model Updates: 244,922
Cumulative Timesteps: 2,043,267,328

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91,963.77432
Policy Entropy: 2.43058
Value Function Loss: 0.01377

Mean KL Divergence: 0.01082
SB3 Clip Fraction: 0.09215
Policy Update Magnitude: 0.29532
Value Function Update Magnitude: 0.32806

Collected Steps per Second: 21,711.14503
Overall Steps per Second: 10,454.77979

Timestep Collection Time: 2.30508
Timestep Consumption Time: 2.48182
PPO Batch Consumption Time: 0.28983
Total Iteration Time: 4.78690

Cumulative Model Updates: 244,928
Cumulative Timesteps: 2,043,317,374

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 2043317374...
Checkpoint 2043317374 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 70,820.99206
Policy Entropy: 2.42834
Value Function Loss: 0.01265

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.07319
Policy Update Magnitude: 0.29382
Value Function Update Magnitude: 0.31097

Collected Steps per Second: 22,060.41799
Overall Steps per Second: 10,620.43700

Timestep Collection Time: 2.26705
Timestep Consumption Time: 2.44199
PPO Batch Consumption Time: 0.27931
Total Iteration Time: 4.70903

Cumulative Model Updates: 244,934
Cumulative Timesteps: 2,043,367,386

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67,362.98418
Policy Entropy: 2.45380
Value Function Loss: 0.01339

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.07048
Policy Update Magnitude: 0.29962
Value Function Update Magnitude: 0.29544

Collected Steps per Second: 21,822.81889
Overall Steps per Second: 10,475.60837

Timestep Collection Time: 2.29173
Timestep Consumption Time: 2.48241
PPO Batch Consumption Time: 0.28654
Total Iteration Time: 4.77414

Cumulative Model Updates: 244,940
Cumulative Timesteps: 2,043,417,398

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2043417398...
Checkpoint 2043417398 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 59,817.59209
Policy Entropy: 2.44248
Value Function Loss: 0.01417

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.07348
Policy Update Magnitude: 0.30283
Value Function Update Magnitude: 0.29513

Collected Steps per Second: 22,000.95666
Overall Steps per Second: 10,632.88541

Timestep Collection Time: 2.27354
Timestep Consumption Time: 2.43074
PPO Batch Consumption Time: 0.27969
Total Iteration Time: 4.70427

Cumulative Model Updates: 244,946
Cumulative Timesteps: 2,043,467,418

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 74,120.41668
Policy Entropy: 2.43807
Value Function Loss: 0.01559

Mean KL Divergence: 0.00745
SB3 Clip Fraction: 0.07092
Policy Update Magnitude: 0.30438
Value Function Update Magnitude: 0.30366

Collected Steps per Second: 21,943.46050
Overall Steps per Second: 10,449.47948

Timestep Collection Time: 2.27968
Timestep Consumption Time: 2.50755
PPO Batch Consumption Time: 0.28995
Total Iteration Time: 4.78722

Cumulative Model Updates: 244,952
Cumulative Timesteps: 2,043,517,442

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2043517442...
Checkpoint 2043517442 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 74,908.87665
Policy Entropy: 2.44747
Value Function Loss: 0.01600

Mean KL Divergence: 0.00764
SB3 Clip Fraction: 0.07276
Policy Update Magnitude: 0.31215
Value Function Update Magnitude: 0.31979

Collected Steps per Second: 22,022.63954
Overall Steps per Second: 10,620.60729

Timestep Collection Time: 2.27166
Timestep Consumption Time: 2.43880
PPO Batch Consumption Time: 0.27892
Total Iteration Time: 4.71047

Cumulative Model Updates: 244,958
Cumulative Timesteps: 2,043,567,470

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 100,330.10405
Policy Entropy: 2.47539
Value Function Loss: 0.01486

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.08050
Policy Update Magnitude: 0.30924
Value Function Update Magnitude: 0.32787

Collected Steps per Second: 22,051.98518
Overall Steps per Second: 10,499.52612

Timestep Collection Time: 2.26846
Timestep Consumption Time: 2.49595
PPO Batch Consumption Time: 0.29062
Total Iteration Time: 4.76441

Cumulative Model Updates: 244,964
Cumulative Timesteps: 2,043,617,494

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2043617494...
Checkpoint 2043617494 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 78,699.63423
Policy Entropy: 2.49688
Value Function Loss: 0.01283

Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.07609
Policy Update Magnitude: 0.29991
Value Function Update Magnitude: 0.28857

Collected Steps per Second: 21,806.53850
Overall Steps per Second: 10,596.11343

Timestep Collection Time: 2.29482
Timestep Consumption Time: 2.42786
PPO Batch Consumption Time: 0.27893
Total Iteration Time: 4.72267

Cumulative Model Updates: 244,970
Cumulative Timesteps: 2,043,667,536

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68,245.37567
Policy Entropy: 2.48200
Value Function Loss: 0.01337

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.07664
Policy Update Magnitude: 0.29189
Value Function Update Magnitude: 0.28631

Collected Steps per Second: 21,342.94597
Overall Steps per Second: 10,450.04105

Timestep Collection Time: 2.34269
Timestep Consumption Time: 2.44198
PPO Batch Consumption Time: 0.27893
Total Iteration Time: 4.78467

Cumulative Model Updates: 244,976
Cumulative Timesteps: 2,043,717,536

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2043717536...
Checkpoint 2043717536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84,571.73417
Policy Entropy: 2.45806
Value Function Loss: 0.01386

Mean KL Divergence: 0.00692
SB3 Clip Fraction: 0.06589
Policy Update Magnitude: 0.29505
Value Function Update Magnitude: 0.30928

Collected Steps per Second: 21,364.27134
Overall Steps per Second: 10,330.20546

Timestep Collection Time: 2.34054
Timestep Consumption Time: 2.50002
PPO Batch Consumption Time: 0.29252
Total Iteration Time: 4.84056

Cumulative Model Updates: 244,982
Cumulative Timesteps: 2,043,767,540

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78,747.77781
Policy Entropy: 2.44267
Value Function Loss: 0.01404

Mean KL Divergence: 0.00651
SB3 Clip Fraction: 0.06032
Policy Update Magnitude: 0.30164
Value Function Update Magnitude: 0.31273

Collected Steps per Second: 21,652.48608
Overall Steps per Second: 10,373.66731

Timestep Collection Time: 2.30994
Timestep Consumption Time: 2.51150
PPO Batch Consumption Time: 0.29082
Total Iteration Time: 4.82144

Cumulative Model Updates: 244,988
Cumulative Timesteps: 2,043,817,556

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2043817556...
Checkpoint 2043817556 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 60,763.28557
Policy Entropy: 2.41558
Value Function Loss: 0.01367

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.07265
Policy Update Magnitude: 0.30859
Value Function Update Magnitude: 0.29517

Collected Steps per Second: 20,983.99678
Overall Steps per Second: 10,198.17172

Timestep Collection Time: 2.38286
Timestep Consumption Time: 2.52017
PPO Batch Consumption Time: 0.29203
Total Iteration Time: 4.90304

Cumulative Model Updates: 244,994
Cumulative Timesteps: 2,043,867,558

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53,022.71980
Policy Entropy: 2.42387
Value Function Loss: 0.01458

Mean KL Divergence: 0.00686
SB3 Clip Fraction: 0.06499
Policy Update Magnitude: 0.30594
Value Function Update Magnitude: 0.26128

Collected Steps per Second: 21,698.77030
Overall Steps per Second: 10,419.70101

Timestep Collection Time: 2.30474
Timestep Consumption Time: 2.49482
PPO Batch Consumption Time: 0.28784
Total Iteration Time: 4.79956

Cumulative Model Updates: 245,000
Cumulative Timesteps: 2,043,917,568

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2043917568...
Checkpoint 2043917568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 83,713.37245
Policy Entropy: 2.42977
Value Function Loss: 0.01722

Mean KL Divergence: 0.00725
SB3 Clip Fraction: 0.06790
Policy Update Magnitude: 0.31320
Value Function Update Magnitude: 0.28851

Collected Steps per Second: 22,095.54104
Overall Steps per Second: 10,601.76413

Timestep Collection Time: 2.26399
Timestep Consumption Time: 2.45447
PPO Batch Consumption Time: 0.27826
Total Iteration Time: 4.71846

Cumulative Model Updates: 245,006
Cumulative Timesteps: 2,043,967,592

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 140,292.99764
Policy Entropy: 2.42958
Value Function Loss: 0.01764

Mean KL Divergence: 0.00685
SB3 Clip Fraction: 0.06456
Policy Update Magnitude: 0.32101
Value Function Update Magnitude: 0.28502

Collected Steps per Second: 22,156.04900
Overall Steps per Second: 10,511.88195

Timestep Collection Time: 2.25744
Timestep Consumption Time: 2.50060
PPO Batch Consumption Time: 0.28765
Total Iteration Time: 4.75804

Cumulative Model Updates: 245,012
Cumulative Timesteps: 2,044,017,608

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2044017608...
Checkpoint 2044017608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 144,961.14460
Policy Entropy: 2.43732
Value Function Loss: 0.01643

Mean KL Divergence: 0.00740
SB3 Clip Fraction: 0.06886
Policy Update Magnitude: 0.31748
Value Function Update Magnitude: 0.29371

Collected Steps per Second: 21,888.37149
Overall Steps per Second: 10,600.15390

Timestep Collection Time: 2.28450
Timestep Consumption Time: 2.43279
PPO Batch Consumption Time: 0.27863
Total Iteration Time: 4.71729

Cumulative Model Updates: 245,018
Cumulative Timesteps: 2,044,067,612

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 129,802.40789
Policy Entropy: 2.44564
Value Function Loss: 0.01452

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.06753
Policy Update Magnitude: 0.29656
Value Function Update Magnitude: 0.30401

Collected Steps per Second: 22,291.85160
Overall Steps per Second: 10,500.61352

Timestep Collection Time: 2.24513
Timestep Consumption Time: 2.52107
PPO Batch Consumption Time: 0.29313
Total Iteration Time: 4.76620

Cumulative Model Updates: 245,024
Cumulative Timesteps: 2,044,117,660

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 2044117660...
Checkpoint 2044117660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 106,222.64838
Policy Entropy: 2.44812
Value Function Loss: 0.01417

Mean KL Divergence: 0.00669
SB3 Clip Fraction: 0.06332
Policy Update Magnitude: 0.29237
Value Function Update Magnitude: 0.27413

Collected Steps per Second: 21,946.49456
Overall Steps per Second: 10,597.21473

Timestep Collection Time: 2.27954
Timestep Consumption Time: 2.44132
PPO Batch Consumption Time: 0.27892
Total Iteration Time: 4.72086

Cumulative Model Updates: 245,030
Cumulative Timesteps: 2,044,167,688

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85,342.33179
Policy Entropy: 2.45219
Value Function Loss: 0.01389

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.07079
Policy Update Magnitude: 0.29588
Value Function Update Magnitude: 0.24083

Collected Steps per Second: 22,134.66634
Overall Steps per Second: 10,500.57687

Timestep Collection Time: 2.26116
Timestep Consumption Time: 2.50525
PPO Batch Consumption Time: 0.29285
Total Iteration Time: 4.76640

Cumulative Model Updates: 245,036
Cumulative Timesteps: 2,044,217,738

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 2044217738...
Checkpoint 2044217738 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 95,177.80002
Policy Entropy: 2.45496
Value Function Loss: 0.01392

Mean KL Divergence: 0.00661
SB3 Clip Fraction: 0.06228
Policy Update Magnitude: 0.30217
Value Function Update Magnitude: 0.27212

Collected Steps per Second: 21,877.18203
Overall Steps per Second: 10,617.95095

Timestep Collection Time: 2.28686
Timestep Consumption Time: 2.42497
PPO Batch Consumption Time: 0.27886
Total Iteration Time: 4.71183

Cumulative Model Updates: 245,042
Cumulative Timesteps: 2,044,267,768

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66,398.42976
Policy Entropy: 2.42192
Value Function Loss: 0.01531

Mean KL Divergence: 0.00752
SB3 Clip Fraction: 0.06849
Policy Update Magnitude: 0.30456
Value Function Update Magnitude: 0.29306

Collected Steps per Second: 21,626.43040
Overall Steps per Second: 10,537.49507

Timestep Collection Time: 2.31199
Timestep Consumption Time: 2.43297
PPO Batch Consumption Time: 0.27782
Total Iteration Time: 4.74496

Cumulative Model Updates: 245,048
Cumulative Timesteps: 2,044,317,768

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2044317768...
Checkpoint 2044317768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48,590.72268
Policy Entropy: 2.42104
Value Function Loss: 0.01563

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.07113
Policy Update Magnitude: 0.31643
Value Function Update Magnitude: 0.34332

Collected Steps per Second: 20,459.90609
Overall Steps per Second: 10,119.55771

Timestep Collection Time: 2.44459
Timestep Consumption Time: 2.49792
PPO Batch Consumption Time: 0.28947
Total Iteration Time: 4.94251

Cumulative Model Updates: 245,054
Cumulative Timesteps: 2,044,367,784

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59,937.87373
Policy Entropy: 2.40862
Value Function Loss: 0.01390

Mean KL Divergence: 0.00757
SB3 Clip Fraction: 0.07156
Policy Update Magnitude: 0.30772
Value Function Update Magnitude: 0.33422

Collected Steps per Second: 21,718.03064
Overall Steps per Second: 10,456.68480

Timestep Collection Time: 2.30334
Timestep Consumption Time: 2.48059
PPO Batch Consumption Time: 0.28614
Total Iteration Time: 4.78393

Cumulative Model Updates: 245,060
Cumulative Timesteps: 2,044,417,808

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2044417808...
Checkpoint 2044417808 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 82,647.43133
Policy Entropy: 2.44729
Value Function Loss: 0.01340

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.07189
Policy Update Magnitude: 0.29469
Value Function Update Magnitude: 0.29742

Collected Steps per Second: 21,530.37466
Overall Steps per Second: 10,382.82369

Timestep Collection Time: 2.32239
Timestep Consumption Time: 2.49344
PPO Batch Consumption Time: 0.29074
Total Iteration Time: 4.81584

Cumulative Model Updates: 245,066
Cumulative Timesteps: 2,044,467,810

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 109,193.18299
Policy Entropy: 2.43200
Value Function Loss: 0.01469

Mean KL Divergence: 0.00764
SB3 Clip Fraction: 0.07146
Policy Update Magnitude: 0.29445
Value Function Update Magnitude: 0.27482

Collected Steps per Second: 21,889.02467
Overall Steps per Second: 10,424.31434

Timestep Collection Time: 2.28635
Timestep Consumption Time: 2.51454
PPO Batch Consumption Time: 0.29233
Total Iteration Time: 4.80089

Cumulative Model Updates: 245,072
Cumulative Timesteps: 2,044,517,856

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 2044517856...
Checkpoint 2044517856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 121,166.10387
Policy Entropy: 2.42764
Value Function Loss: 0.01653

Mean KL Divergence: 0.00727
SB3 Clip Fraction: 0.06721
Policy Update Magnitude: 0.30982
Value Function Update Magnitude: 0.31531

Collected Steps per Second: 21,932.97819
Overall Steps per Second: 10,560.39547

Timestep Collection Time: 2.28086
Timestep Consumption Time: 2.45628
PPO Batch Consumption Time: 0.27689
Total Iteration Time: 4.73713

Cumulative Model Updates: 245,078
Cumulative Timesteps: 2,044,567,882

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83,701.21259
Policy Entropy: 2.43711
Value Function Loss: 0.01631

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.07110
Policy Update Magnitude: 0.31091
Value Function Update Magnitude: 0.33049

Collected Steps per Second: 22,379.49542
Overall Steps per Second: 10,566.90320

Timestep Collection Time: 2.23472
Timestep Consumption Time: 2.49817
PPO Batch Consumption Time: 0.28966
Total Iteration Time: 4.73289

Cumulative Model Updates: 245,084
Cumulative Timesteps: 2,044,617,894

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2044617894...
Checkpoint 2044617894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 77,399.37385
Policy Entropy: 2.44956
Value Function Loss: 0.01417

Mean KL Divergence: 0.00748
SB3 Clip Fraction: 0.06824
Policy Update Magnitude: 0.29914
Value Function Update Magnitude: 0.30593

Collected Steps per Second: 20,287.74625
Overall Steps per Second: 10,114.26165

Timestep Collection Time: 2.46651
Timestep Consumption Time: 2.48096
PPO Batch Consumption Time: 0.27735
Total Iteration Time: 4.94747

Cumulative Model Updates: 245,090
Cumulative Timesteps: 2,044,667,934

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61,317.90444
Policy Entropy: 2.45250
Value Function Loss: 0.01539

Mean KL Divergence: 0.00667
SB3 Clip Fraction: 0.06385
Policy Update Magnitude: 0.30805
Value Function Update Magnitude: 0.28192

Collected Steps per Second: 22,236.68453
Overall Steps per Second: 10,548.17620

Timestep Collection Time: 2.24953
Timestep Consumption Time: 2.49272
PPO Batch Consumption Time: 0.29116
Total Iteration Time: 4.74224

Cumulative Model Updates: 245,096
Cumulative Timesteps: 2,044,717,956

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2044717956...
Checkpoint 2044717956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,810.33657
Policy Entropy: 2.42922
Value Function Loss: 0.01735

Mean KL Divergence: 0.00721
SB3 Clip Fraction: 0.06625
Policy Update Magnitude: 0.30987
Value Function Update Magnitude: 0.30699

Collected Steps per Second: 21,919.60227
Overall Steps per Second: 10,470.39018

Timestep Collection Time: 2.28152
Timestep Consumption Time: 2.49481
PPO Batch Consumption Time: 0.28991
Total Iteration Time: 4.77633

Cumulative Model Updates: 245,102
Cumulative Timesteps: 2,044,767,966

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63,648.50453
Policy Entropy: 2.41792
Value Function Loss: 0.02236

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.07070
Policy Update Magnitude: 0.32875
Value Function Update Magnitude: 0.34192

Collected Steps per Second: 21,747.43985
Overall Steps per Second: 10,454.81323

Timestep Collection Time: 2.29912
Timestep Consumption Time: 2.48337
PPO Batch Consumption Time: 0.28704
Total Iteration Time: 4.78249

Cumulative Model Updates: 245,108
Cumulative Timesteps: 2,044,817,966

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2044817966...
Checkpoint 2044817966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,915.99882
Policy Entropy: 2.41801
Value Function Loss: 0.02140

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.09076
Policy Update Magnitude: 0.33547
Value Function Update Magnitude: 0.35198

Collected Steps per Second: 21,993.78340
Overall Steps per Second: 10,641.75381

Timestep Collection Time: 2.27346
Timestep Consumption Time: 2.42520
PPO Batch Consumption Time: 0.27928
Total Iteration Time: 4.69866

Cumulative Model Updates: 245,114
Cumulative Timesteps: 2,044,867,968

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,960.80677
Policy Entropy: 2.42807
Value Function Loss: 0.02031

Mean KL Divergence: 0.01793
SB3 Clip Fraction: 0.12799
Policy Update Magnitude: 0.31237
Value Function Update Magnitude: 0.37894

Collected Steps per Second: 22,007.09956
Overall Steps per Second: 10,453.29890

Timestep Collection Time: 2.27327
Timestep Consumption Time: 2.51259
PPO Batch Consumption Time: 0.29102
Total Iteration Time: 4.78586

Cumulative Model Updates: 245,120
Cumulative Timesteps: 2,044,917,996

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2044917996...
Checkpoint 2044917996 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,960.80677
Policy Entropy: 2.45043
Value Function Loss: 0.01518

Mean KL Divergence: 0.01380
SB3 Clip Fraction: 0.10931
Policy Update Magnitude: 0.28847
Value Function Update Magnitude: 0.34953

Collected Steps per Second: 21,028.95095
Overall Steps per Second: 10,204.24301

Timestep Collection Time: 2.37796
Timestep Consumption Time: 2.52255
PPO Batch Consumption Time: 0.29435
Total Iteration Time: 4.90051

Cumulative Model Updates: 245,126
Cumulative Timesteps: 2,044,968,002

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46,985.58991
Policy Entropy: 2.45262
Value Function Loss: 0.01351

Mean KL Divergence: 0.01243
SB3 Clip Fraction: 0.10379
Policy Update Magnitude: 0.27829
Value Function Update Magnitude: 0.31093

Collected Steps per Second: 21,600.28580
Overall Steps per Second: 10,541.56700

Timestep Collection Time: 2.31571
Timestep Consumption Time: 2.42931
PPO Batch Consumption Time: 0.27714
Total Iteration Time: 4.74503

Cumulative Model Updates: 245,132
Cumulative Timesteps: 2,045,018,022

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2045018022...
Checkpoint 2045018022 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 73,174.20387
Policy Entropy: 2.46738
Value Function Loss: 0.01322

Mean KL Divergence: 0.01059
SB3 Clip Fraction: 0.09330
Policy Update Magnitude: 0.28032
Value Function Update Magnitude: 0.30601

Collected Steps per Second: 21,329.97034
Overall Steps per Second: 10,479.31130

Timestep Collection Time: 2.34553
Timestep Consumption Time: 2.42864
PPO Batch Consumption Time: 0.27893
Total Iteration Time: 4.77417

Cumulative Model Updates: 245,138
Cumulative Timesteps: 2,045,068,052

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 121,162.20889
Policy Entropy: 2.46541
Value Function Loss: 0.01471

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.08324
Policy Update Magnitude: 0.29450
Value Function Update Magnitude: 0.30755

Collected Steps per Second: 20,561.16057
Overall Steps per Second: 10,449.24110

Timestep Collection Time: 2.43226
Timestep Consumption Time: 2.35374
PPO Batch Consumption Time: 0.27910
Total Iteration Time: 4.78599

Cumulative Model Updates: 245,144
Cumulative Timesteps: 2,045,118,062

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2045118062...
Checkpoint 2045118062 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 61,099.60070
Policy Entropy: 2.45878
Value Function Loss: 0.01603

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.08285
Policy Update Magnitude: 0.30512
Value Function Update Magnitude: 0.30757

Collected Steps per Second: 20,654.08399
Overall Steps per Second: 10,284.43908

Timestep Collection Time: 2.42131
Timestep Consumption Time: 2.44137
PPO Batch Consumption Time: 0.29443
Total Iteration Time: 4.86269

Cumulative Model Updates: 245,150
Cumulative Timesteps: 2,045,168,072

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52,177.17827
Policy Entropy: 2.44501
Value Function Loss: 0.01507

Mean KL Divergence: 0.01174
SB3 Clip Fraction: 0.09820
Policy Update Magnitude: 0.30018
Value Function Update Magnitude: 0.31584

Collected Steps per Second: 21,237.07084
Overall Steps per Second: 10,447.57596

Timestep Collection Time: 2.35456
Timestep Consumption Time: 2.43162
PPO Batch Consumption Time: 0.29115
Total Iteration Time: 4.78618

Cumulative Model Updates: 245,156
Cumulative Timesteps: 2,045,218,076

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2045218076...
Checkpoint 2045218076 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 78,731.56297
Policy Entropy: 2.44145
Value Function Loss: 0.01610

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.08181
Policy Update Magnitude: 0.30738
Value Function Update Magnitude: 0.31447

Collected Steps per Second: 20,603.05221
Overall Steps per Second: 10,284.89872

Timestep Collection Time: 2.42896
Timestep Consumption Time: 2.43681
PPO Batch Consumption Time: 0.29339
Total Iteration Time: 4.86577

Cumulative Model Updates: 245,162
Cumulative Timesteps: 2,045,268,120

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63,470.35348
Policy Entropy: 2.44354
Value Function Loss: 0.01695

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.07906
Policy Update Magnitude: 0.31428
Value Function Update Magnitude: 0.29228

Collected Steps per Second: 21,786.87671
Overall Steps per Second: 10,395.53366

Timestep Collection Time: 2.29579
Timestep Consumption Time: 2.51570
PPO Batch Consumption Time: 0.29367
Total Iteration Time: 4.81149

Cumulative Model Updates: 245,168
Cumulative Timesteps: 2,045,318,138

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2045318138...
Checkpoint 2045318138 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 67,458.15758
Policy Entropy: 2.44721
Value Function Loss: 0.01542

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.07499
Policy Update Magnitude: 0.31539
Value Function Update Magnitude: 0.27867

Collected Steps per Second: 21,965.09392
Overall Steps per Second: 10,659.47381

Timestep Collection Time: 2.27752
Timestep Consumption Time: 2.41558
PPO Batch Consumption Time: 0.27725
Total Iteration Time: 4.69310

Cumulative Model Updates: 245,174
Cumulative Timesteps: 2,045,368,164

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49,797.72195
Policy Entropy: 2.45382
Value Function Loss: 0.01510

Mean KL Divergence: 0.00723
SB3 Clip Fraction: 0.07074
Policy Update Magnitude: 0.30853
Value Function Update Magnitude: 0.22595

Collected Steps per Second: 22,263.93259
Overall Steps per Second: 10,789.54835

Timestep Collection Time: 2.24596
Timestep Consumption Time: 2.38852
PPO Batch Consumption Time: 0.27891
Total Iteration Time: 4.63449

Cumulative Model Updates: 245,180
Cumulative Timesteps: 2,045,418,168

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2045418168...
Checkpoint 2045418168 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 77,273.46120
Policy Entropy: 2.47009
Value Function Loss: 0.01479

Mean KL Divergence: 0.00631
SB3 Clip Fraction: 0.06185
Policy Update Magnitude: 0.30110
Value Function Update Magnitude: 0.20610

Collected Steps per Second: 21,876.46766
Overall Steps per Second: 10,621.59762

Timestep Collection Time: 2.28702
Timestep Consumption Time: 2.42338
PPO Batch Consumption Time: 0.27972
Total Iteration Time: 4.71040

Cumulative Model Updates: 245,186
Cumulative Timesteps: 2,045,468,200

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 116,518.02388
Policy Entropy: 2.45769
Value Function Loss: 0.01652

Mean KL Divergence: 0.00636
SB3 Clip Fraction: 0.06102
Policy Update Magnitude: 0.30715
Value Function Update Magnitude: 0.24769

Collected Steps per Second: 21,757.43781
Overall Steps per Second: 10,594.48317

Timestep Collection Time: 2.29843
Timestep Consumption Time: 2.42176
PPO Batch Consumption Time: 0.27739
Total Iteration Time: 4.72019

Cumulative Model Updates: 245,192
Cumulative Timesteps: 2,045,518,208

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2045518208...
Checkpoint 2045518208 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89,813.72698
Policy Entropy: 2.44036
Value Function Loss: 0.01496

Mean KL Divergence: 0.00637
SB3 Clip Fraction: 0.05981
Policy Update Magnitude: 0.30257
Value Function Update Magnitude: 0.33405

Collected Steps per Second: 22,045.42778
Overall Steps per Second: 10,554.22758

Timestep Collection Time: 2.26850
Timestep Consumption Time: 2.46989
PPO Batch Consumption Time: 0.28657
Total Iteration Time: 4.73839

Cumulative Model Updates: 245,198
Cumulative Timesteps: 2,045,568,218

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85,258.72791
Policy Entropy: 2.43613
Value Function Loss: 0.01380

Mean KL Divergence: 0.00684
SB3 Clip Fraction: 0.05971
Policy Update Magnitude: 0.29646
Value Function Update Magnitude: 0.36034

Collected Steps per Second: 21,810.57992
Overall Steps per Second: 10,471.37805

Timestep Collection Time: 2.29302
Timestep Consumption Time: 2.48305
PPO Batch Consumption Time: 0.28756
Total Iteration Time: 4.77607

Cumulative Model Updates: 245,204
Cumulative Timesteps: 2,045,618,230

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2045618230...
Checkpoint 2045618230 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 68,160.04519
Policy Entropy: 2.43927
Value Function Loss: 0.01290

Mean KL Divergence: 0.00685
SB3 Clip Fraction: 0.06302
Policy Update Magnitude: 0.28972
Value Function Update Magnitude: 0.30970

Collected Steps per Second: 21,146.84053
Overall Steps per Second: 10,225.07664

Timestep Collection Time: 2.36442
Timestep Consumption Time: 2.52552
PPO Batch Consumption Time: 0.29501
Total Iteration Time: 4.88994

Cumulative Model Updates: 245,210
Cumulative Timesteps: 2,045,668,230

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70,859.05098
Policy Entropy: 2.44747
Value Function Loss: 0.01366

Mean KL Divergence: 0.00641
SB3 Clip Fraction: 0.06396
Policy Update Magnitude: 0.28843
Value Function Update Magnitude: 0.25292

Collected Steps per Second: 21,390.50974
Overall Steps per Second: 10,437.83730

Timestep Collection Time: 2.33786
Timestep Consumption Time: 2.45317
PPO Batch Consumption Time: 0.28607
Total Iteration Time: 4.79103

Cumulative Model Updates: 245,216
Cumulative Timesteps: 2,045,718,238

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2045718238...
Checkpoint 2045718238 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 93,519.26954
Policy Entropy: 2.43901
Value Function Loss: 0.01402

Mean KL Divergence: 0.00692
SB3 Clip Fraction: 0.06623
Policy Update Magnitude: 0.29479
Value Function Update Magnitude: 0.25948

Collected Steps per Second: 21,704.67329
Overall Steps per Second: 10,541.90098

Timestep Collection Time: 2.30374
Timestep Consumption Time: 2.43942
PPO Batch Consumption Time: 0.27890
Total Iteration Time: 4.74317

Cumulative Model Updates: 245,222
Cumulative Timesteps: 2,045,768,240

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88,613.18303
Policy Entropy: 2.43688
Value Function Loss: 0.01365

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.07375
Policy Update Magnitude: 0.29327
Value Function Update Magnitude: 0.28039

Collected Steps per Second: 22,147.91657
Overall Steps per Second: 10,636.31954

Timestep Collection Time: 2.25809
Timestep Consumption Time: 2.44391
PPO Batch Consumption Time: 0.27734
Total Iteration Time: 4.70200

Cumulative Model Updates: 245,228
Cumulative Timesteps: 2,045,818,252

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2045818252...
Checkpoint 2045818252 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 71,049.04176
Policy Entropy: 2.43725
Value Function Loss: 0.01468

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.07358
Policy Update Magnitude: 0.28756
Value Function Update Magnitude: 0.29402

Collected Steps per Second: 21,909.26800
Overall Steps per Second: 10,600.01133

Timestep Collection Time: 2.28296
Timestep Consumption Time: 2.43571
PPO Batch Consumption Time: 0.27770
Total Iteration Time: 4.71867

Cumulative Model Updates: 245,234
Cumulative Timesteps: 2,045,868,270

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65,469.68759
Policy Entropy: 2.42777
Value Function Loss: 0.01450

Mean KL Divergence: 0.00723
SB3 Clip Fraction: 0.06868
Policy Update Magnitude: 0.29471
Value Function Update Magnitude: 0.29647

Collected Steps per Second: 21,899.55160
Overall Steps per Second: 10,405.80453

Timestep Collection Time: 2.28361
Timestep Consumption Time: 2.52236
PPO Batch Consumption Time: 0.29480
Total Iteration Time: 4.80597

Cumulative Model Updates: 245,240
Cumulative Timesteps: 2,045,918,280

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2045918280...
Checkpoint 2045918280 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 68,864.09065
Policy Entropy: 2.43351
Value Function Loss: 0.01659

Mean KL Divergence: 0.00738
SB3 Clip Fraction: 0.07054
Policy Update Magnitude: 0.30498
Value Function Update Magnitude: 0.32358

Collected Steps per Second: 22,108.66839
Overall Steps per Second: 10,671.98334

Timestep Collection Time: 2.26246
Timestep Consumption Time: 2.42458
PPO Batch Consumption Time: 0.27757
Total Iteration Time: 4.68704

Cumulative Model Updates: 245,246
Cumulative Timesteps: 2,045,968,300

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49,905.02475
Policy Entropy: 2.44188
Value Function Loss: 0.01749

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.07174
Policy Update Magnitude: 0.31605
Value Function Update Magnitude: 0.33288

Collected Steps per Second: 22,171.38674
Overall Steps per Second: 10,483.07319

Timestep Collection Time: 2.25525
Timestep Consumption Time: 2.51454
PPO Batch Consumption Time: 0.29321
Total Iteration Time: 4.76978

Cumulative Model Updates: 245,252
Cumulative Timesteps: 2,046,018,302

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2046018302...
Checkpoint 2046018302 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 60,760.32146
Policy Entropy: 2.42819
Value Function Loss: 0.01783

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.07909
Policy Update Magnitude: 0.31087
Value Function Update Magnitude: 0.33641

Collected Steps per Second: 22,092.19715
Overall Steps per Second: 10,550.47881

Timestep Collection Time: 2.26379
Timestep Consumption Time: 2.47647
PPO Batch Consumption Time: 0.28589
Total Iteration Time: 4.74026

Cumulative Model Updates: 245,258
Cumulative Timesteps: 2,046,068,314

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67,720.12604
Policy Entropy: 2.41977
Value Function Loss: 0.01733

Mean KL Divergence: 0.01249
SB3 Clip Fraction: 0.09575
Policy Update Magnitude: 0.31308
Value Function Update Magnitude: 0.34932

Collected Steps per Second: 21,575.02794
Overall Steps per Second: 10,466.62138

Timestep Collection Time: 2.31824
Timestep Consumption Time: 2.46038
PPO Batch Consumption Time: 0.28436
Total Iteration Time: 4.77862

Cumulative Model Updates: 245,264
Cumulative Timesteps: 2,046,118,330

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2046118330...
Checkpoint 2046118330 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,469.80375
Policy Entropy: 2.42094
Value Function Loss: 0.01684

Mean KL Divergence: 0.01154
SB3 Clip Fraction: 0.09634
Policy Update Magnitude: 0.31920
Value Function Update Magnitude: 0.33373

Collected Steps per Second: 21,308.32865
Overall Steps per Second: 10,311.09046

Timestep Collection Time: 2.34772
Timestep Consumption Time: 2.50395
PPO Batch Consumption Time: 0.29339
Total Iteration Time: 4.85167

Cumulative Model Updates: 245,270
Cumulative Timesteps: 2,046,168,356

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56,911.78273
Policy Entropy: 2.43961
Value Function Loss: 0.01747

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.08866
Policy Update Magnitude: 0.33034
Value Function Update Magnitude: 0.35608

Collected Steps per Second: 21,670.47769
Overall Steps per Second: 10,376.08777

Timestep Collection Time: 2.30913
Timestep Consumption Time: 2.51349
PPO Batch Consumption Time: 0.29327
Total Iteration Time: 4.82263

Cumulative Model Updates: 245,276
Cumulative Timesteps: 2,046,218,396

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 2046218396...
Checkpoint 2046218396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 114,844.24078
Policy Entropy: 2.44887
Value Function Loss: 0.01596

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.08274
Policy Update Magnitude: 0.31627
Value Function Update Magnitude: 0.32455

Collected Steps per Second: 21,313.25223
Overall Steps per Second: 10,345.64738

Timestep Collection Time: 2.34680
Timestep Consumption Time: 2.48789
PPO Batch Consumption Time: 0.29186
Total Iteration Time: 4.83469

Cumulative Model Updates: 245,282
Cumulative Timesteps: 2,046,268,414

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80,126.31428
Policy Entropy: 2.45257
Value Function Loss: 0.01537

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.07629
Policy Update Magnitude: 0.30928
Value Function Update Magnitude: 0.32067

Collected Steps per Second: 21,394.05602
Overall Steps per Second: 10,464.11760

Timestep Collection Time: 2.33850
Timestep Consumption Time: 2.44260
PPO Batch Consumption Time: 0.29030
Total Iteration Time: 4.78110

Cumulative Model Updates: 245,288
Cumulative Timesteps: 2,046,318,444

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2046318444...
Checkpoint 2046318444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 80,126.31428
Policy Entropy: 2.47012
Value Function Loss: 0.01415

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.08281
Policy Update Magnitude: 0.30518
Value Function Update Magnitude: 0.30399

Collected Steps per Second: 20,958.88491
Overall Steps per Second: 10,500.79168

Timestep Collection Time: 2.38600
Timestep Consumption Time: 2.37630
PPO Batch Consumption Time: 0.27888
Total Iteration Time: 4.76231

Cumulative Model Updates: 245,294
Cumulative Timesteps: 2,046,368,452

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61,070.94104
Policy Entropy: 2.45855
Value Function Loss: 0.01491

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.08531
Policy Update Magnitude: 0.30717
Value Function Update Magnitude: 0.31799

Collected Steps per Second: 21,426.46741
Overall Steps per Second: 10,493.69041

Timestep Collection Time: 2.33431
Timestep Consumption Time: 2.43198
PPO Batch Consumption Time: 0.29312
Total Iteration Time: 4.76629

Cumulative Model Updates: 245,300
Cumulative Timesteps: 2,046,418,468

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2046418468...
Checkpoint 2046418468 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 50,638.47451
Policy Entropy: 2.44288
Value Function Loss: 0.01400

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.07945
Policy Update Magnitude: 0.30517
Value Function Update Magnitude: 0.33143

Collected Steps per Second: 21,560.47236
Overall Steps per Second: 10,597.29434

Timestep Collection Time: 2.32091
Timestep Consumption Time: 2.40105
PPO Batch Consumption Time: 0.27788
Total Iteration Time: 4.72196

Cumulative Model Updates: 245,306
Cumulative Timesteps: 2,046,468,508

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76,586.24779
Policy Entropy: 2.42955
Value Function Loss: 0.01642

Mean KL Divergence: 0.00736
SB3 Clip Fraction: 0.06664
Policy Update Magnitude: 0.30978
Value Function Update Magnitude: 0.32857

Collected Steps per Second: 21,761.77929
Overall Steps per Second: 10,410.61019

Timestep Collection Time: 2.29880
Timestep Consumption Time: 2.50649
PPO Batch Consumption Time: 0.29653
Total Iteration Time: 4.80529

Cumulative Model Updates: 245,312
Cumulative Timesteps: 2,046,518,534

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2046518534...
Checkpoint 2046518534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 56,797.15740
Policy Entropy: 2.41622
Value Function Loss: 0.01715

Mean KL Divergence: 0.00675
SB3 Clip Fraction: 0.06182
Policy Update Magnitude: 0.31708
Value Function Update Magnitude: 0.32060

Collected Steps per Second: 21,955.33030
Overall Steps per Second: 10,687.47298

Timestep Collection Time: 2.27735
Timestep Consumption Time: 2.40102
PPO Batch Consumption Time: 0.27759
Total Iteration Time: 4.67837

Cumulative Model Updates: 245,318
Cumulative Timesteps: 2,046,568,534

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86,515.82724
Policy Entropy: 2.42574
Value Function Loss: 0.01920

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.07188
Policy Update Magnitude: 0.32325
Value Function Update Magnitude: 0.32918

Collected Steps per Second: 22,256.11662
Overall Steps per Second: 10,577.15766

Timestep Collection Time: 2.24783
Timestep Consumption Time: 2.48198
PPO Batch Consumption Time: 0.29125
Total Iteration Time: 4.72982

Cumulative Model Updates: 245,324
Cumulative Timesteps: 2,046,618,562

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2046618562...
Checkpoint 2046618562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 91,317.98310
Policy Entropy: 2.43040
Value Function Loss: 0.01763

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.06981
Policy Update Magnitude: 0.31853
Value Function Update Magnitude: 0.35080

Collected Steps per Second: 21,693.21087
Overall Steps per Second: 10,468.73539

Timestep Collection Time: 2.30616
Timestep Consumption Time: 2.47264
PPO Batch Consumption Time: 0.28566
Total Iteration Time: 4.77880

Cumulative Model Updates: 245,330
Cumulative Timesteps: 2,046,668,590

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82,874.86415
Policy Entropy: 2.43274
Value Function Loss: 0.01721

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.06850
Policy Update Magnitude: 0.32050
Value Function Update Magnitude: 0.33256

Collected Steps per Second: 21,311.85392
Overall Steps per Second: 10,460.62055

Timestep Collection Time: 2.34827
Timestep Consumption Time: 2.43596
PPO Batch Consumption Time: 0.27924
Total Iteration Time: 4.78423

Cumulative Model Updates: 245,336
Cumulative Timesteps: 2,046,718,636

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 2046718636...
Checkpoint 2046718636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 68,464.87071
Policy Entropy: 2.42246
Value Function Loss: 0.01692

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.07501
Policy Update Magnitude: 0.33289
Value Function Update Magnitude: 0.33226

Collected Steps per Second: 21,103.53234
Overall Steps per Second: 10,246.74421

Timestep Collection Time: 2.37060
Timestep Consumption Time: 2.51173
PPO Batch Consumption Time: 0.29334
Total Iteration Time: 4.88233

Cumulative Model Updates: 245,342
Cumulative Timesteps: 2,046,768,664

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80,329.13114
Policy Entropy: 2.41820
Value Function Loss: 0.01844

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.07598
Policy Update Magnitude: 0.33528
Value Function Update Magnitude: 0.35346

Collected Steps per Second: 21,555.79593
Overall Steps per Second: 10,429.83665

Timestep Collection Time: 2.32095
Timestep Consumption Time: 2.47586
PPO Batch Consumption Time: 0.28756
Total Iteration Time: 4.79682

Cumulative Model Updates: 245,348
Cumulative Timesteps: 2,046,818,694

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2046818694...
Checkpoint 2046818694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 71,793.17637
Policy Entropy: 2.43989
Value Function Loss: 0.01855

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.08287
Policy Update Magnitude: 0.33016
Value Function Update Magnitude: 0.36711

Collected Steps per Second: 21,757.43695
Overall Steps per Second: 10,559.21073

Timestep Collection Time: 2.29806
Timestep Consumption Time: 2.43714
PPO Batch Consumption Time: 0.27886
Total Iteration Time: 4.73520

Cumulative Model Updates: 245,354
Cumulative Timesteps: 2,046,868,694

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62,950.96316
Policy Entropy: 2.47166
Value Function Loss: 0.01834

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.07860
Policy Update Magnitude: 0.32406
Value Function Update Magnitude: 0.36152

Collected Steps per Second: 21,282.84472
Overall Steps per Second: 10,563.79945

Timestep Collection Time: 2.35034
Timestep Consumption Time: 2.38488
PPO Batch Consumption Time: 0.27794
Total Iteration Time: 4.73523

Cumulative Model Updates: 245,360
Cumulative Timesteps: 2,046,918,716

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2046918716...
Checkpoint 2046918716 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 62,950.96316
Policy Entropy: 2.46860
Value Function Loss: 0.01627

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.08133
Policy Update Magnitude: 0.31263
Value Function Update Magnitude: 0.36439

Collected Steps per Second: 21,363.13367
Overall Steps per Second: 10,527.10461

Timestep Collection Time: 2.34095
Timestep Consumption Time: 2.40965
PPO Batch Consumption Time: 0.27996
Total Iteration Time: 4.75059

Cumulative Model Updates: 245,366
Cumulative Timesteps: 2,046,968,726

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,137.77918
Policy Entropy: 2.43565
Value Function Loss: 0.01694

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.07589
Policy Update Magnitude: 0.31607
Value Function Update Magnitude: 0.35060

Collected Steps per Second: 21,413.24965
Overall Steps per Second: 10,525.14094

Timestep Collection Time: 2.33584
Timestep Consumption Time: 2.41640
PPO Batch Consumption Time: 0.28820
Total Iteration Time: 4.75224

Cumulative Model Updates: 245,372
Cumulative Timesteps: 2,047,018,744

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2047018744...
Checkpoint 2047018744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,559.33999
Policy Entropy: 2.41343
Value Function Loss: 0.01495

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.07553
Policy Update Magnitude: 0.31902
Value Function Update Magnitude: 0.33616

Collected Steps per Second: 21,389.63995
Overall Steps per Second: 10,550.16780

Timestep Collection Time: 2.33889
Timestep Consumption Time: 2.40303
PPO Batch Consumption Time: 0.27873
Total Iteration Time: 4.74192

Cumulative Model Updates: 245,378
Cumulative Timesteps: 2,047,068,772

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 115,302.39154
Policy Entropy: 2.39892
Value Function Loss: 0.01486

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.07254
Policy Update Magnitude: 0.31376
Value Function Update Magnitude: 0.31000

Collected Steps per Second: 21,986.67872
Overall Steps per Second: 10,533.64107

Timestep Collection Time: 2.27429
Timestep Consumption Time: 2.47279
PPO Batch Consumption Time: 0.28957
Total Iteration Time: 4.74708

Cumulative Model Updates: 245,384
Cumulative Timesteps: 2,047,118,776

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2047118776...
Checkpoint 2047118776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 79,718.76736
Policy Entropy: 2.42748
Value Function Loss: 0.01649

Mean KL Divergence: 0.00703
SB3 Clip Fraction: 0.06706
Policy Update Magnitude: 0.31691
Value Function Update Magnitude: 0.30096

Collected Steps per Second: 21,690.52209
Overall Steps per Second: 10,589.72354

Timestep Collection Time: 2.30534
Timestep Consumption Time: 2.41660
PPO Batch Consumption Time: 0.28053
Total Iteration Time: 4.72194

Cumulative Model Updates: 245,390
Cumulative Timesteps: 2,047,168,780

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60,456.54442
Policy Entropy: 2.44012
Value Function Loss: 0.01682

Mean KL Divergence: 0.00740
SB3 Clip Fraction: 0.07167
Policy Update Magnitude: 0.31480
Value Function Update Magnitude: 0.32728

Collected Steps per Second: 21,530.33392
Overall Steps per Second: 10,535.60203

Timestep Collection Time: 2.32351
Timestep Consumption Time: 2.42477
PPO Batch Consumption Time: 0.27829
Total Iteration Time: 4.74828

Cumulative Model Updates: 245,396
Cumulative Timesteps: 2,047,218,806

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2047218806...
Checkpoint 2047218806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55,500.44427
Policy Entropy: 2.43513
Value Function Loss: 0.01760

Mean KL Divergence: 0.00702
SB3 Clip Fraction: 0.06622
Policy Update Magnitude: 0.31342
Value Function Update Magnitude: 0.33908

Collected Steps per Second: 21,357.11316
Overall Steps per Second: 10,368.34501

Timestep Collection Time: 2.34283
Timestep Consumption Time: 2.48302
PPO Batch Consumption Time: 0.28994
Total Iteration Time: 4.82584

Cumulative Model Updates: 245,402
Cumulative Timesteps: 2,047,268,842

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53,515.53772
Policy Entropy: 2.43490
Value Function Loss: 0.01528

Mean KL Divergence: 0.00728
SB3 Clip Fraction: 0.06806
Policy Update Magnitude: 0.30877
Value Function Update Magnitude: 0.31891

Collected Steps per Second: 21,667.43323
Overall Steps per Second: 10,442.35294

Timestep Collection Time: 2.30835
Timestep Consumption Time: 2.48138
PPO Batch Consumption Time: 0.28979
Total Iteration Time: 4.78973

Cumulative Model Updates: 245,408
Cumulative Timesteps: 2,047,318,858

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2047318858...
Checkpoint 2047318858 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 50,524.08202
Policy Entropy: 2.43781
Value Function Loss: 0.01534

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.07817
Policy Update Magnitude: 0.30274
Value Function Update Magnitude: 0.28601

Collected Steps per Second: 21,454.58114
Overall Steps per Second: 10,503.43475

Timestep Collection Time: 2.33144
Timestep Consumption Time: 2.43081
PPO Batch Consumption Time: 0.27728
Total Iteration Time: 4.76225

Cumulative Model Updates: 245,414
Cumulative Timesteps: 2,047,368,878

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83,376.30141
Policy Entropy: 2.46188
Value Function Loss: 0.01592

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.07727
Policy Update Magnitude: 0.29494
Value Function Update Magnitude: 0.28008

Collected Steps per Second: 21,874.23126
Overall Steps per Second: 10,435.01721

Timestep Collection Time: 2.28662
Timestep Consumption Time: 2.50667
PPO Batch Consumption Time: 0.29235
Total Iteration Time: 4.79328

Cumulative Model Updates: 245,420
Cumulative Timesteps: 2,047,418,896

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2047418896...
Checkpoint 2047418896 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 83,082.59612
Policy Entropy: 2.45574
Value Function Loss: 0.01559

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.08988
Policy Update Magnitude: 0.30859
Value Function Update Magnitude: 0.30794

Collected Steps per Second: 22,120.77255
Overall Steps per Second: 10,594.78862

Timestep Collection Time: 2.26041
Timestep Consumption Time: 2.45908
PPO Batch Consumption Time: 0.27963
Total Iteration Time: 4.71949

Cumulative Model Updates: 245,426
Cumulative Timesteps: 2,047,468,898

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82,093.97637
Policy Entropy: 2.42703
Value Function Loss: 0.01638

Mean KL Divergence: 0.01397
SB3 Clip Fraction: 0.11097
Policy Update Magnitude: 0.29876
Value Function Update Magnitude: 0.26370

Collected Steps per Second: 21,885.35050
Overall Steps per Second: 10,366.32947

Timestep Collection Time: 2.28573
Timestep Consumption Time: 2.53989
PPO Batch Consumption Time: 0.29371
Total Iteration Time: 4.82562

Cumulative Model Updates: 245,432
Cumulative Timesteps: 2,047,518,922

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2047518922...
Checkpoint 2047518922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 69,353.17469
Policy Entropy: 2.42177
Value Function Loss: 0.01787

Mean KL Divergence: 0.01449
SB3 Clip Fraction: 0.11269
Policy Update Magnitude: 0.30819
Value Function Update Magnitude: 0.25726

Collected Steps per Second: 21,598.31132
Overall Steps per Second: 10,392.03391

Timestep Collection Time: 2.31537
Timestep Consumption Time: 2.49678
PPO Batch Consumption Time: 0.29296
Total Iteration Time: 4.81215

Cumulative Model Updates: 245,438
Cumulative Timesteps: 2,047,568,930

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57,456.45363
Policy Entropy: 2.39413
Value Function Loss: 0.01784

Mean KL Divergence: 0.01324
SB3 Clip Fraction: 0.10965
Policy Update Magnitude: 0.32642
Value Function Update Magnitude: 0.31618

Collected Steps per Second: 21,531.76631
Overall Steps per Second: 10,570.18784

Timestep Collection Time: 2.32289
Timestep Consumption Time: 2.40891
PPO Batch Consumption Time: 0.28786
Total Iteration Time: 4.73180

Cumulative Model Updates: 245,444
Cumulative Timesteps: 2,047,618,946

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2047618946...
Checkpoint 2047618946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 67,367.55945
Policy Entropy: 2.41141
Value Function Loss: 0.01779

Mean KL Divergence: 0.01172
SB3 Clip Fraction: 0.09562
Policy Update Magnitude: 0.32785
Value Function Update Magnitude: 0.31075

Collected Steps per Second: 21,274.66752
Overall Steps per Second: 10,478.76703

Timestep Collection Time: 2.35031
Timestep Consumption Time: 2.42144
PPO Batch Consumption Time: 0.29373
Total Iteration Time: 4.77174

Cumulative Model Updates: 245,450
Cumulative Timesteps: 2,047,668,948

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55,047.84711
Policy Entropy: 2.42058
Value Function Loss: 0.01727

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.08701
Policy Update Magnitude: 0.32279
Value Function Update Magnitude: 0.29878

Collected Steps per Second: 21,528.18452
Overall Steps per Second: 10,382.57669

Timestep Collection Time: 2.32486
Timestep Consumption Time: 2.49572
PPO Batch Consumption Time: 0.29321
Total Iteration Time: 4.82058

Cumulative Model Updates: 245,456
Cumulative Timesteps: 2,047,718,998

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 2047718998...
Checkpoint 2047718998 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55,047.84711
Policy Entropy: 2.43977
Value Function Loss: 0.01539

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.07399
Policy Update Magnitude: 0.30368
Value Function Update Magnitude: 0.27981

Collected Steps per Second: 21,352.86233
Overall Steps per Second: 10,383.70303

Timestep Collection Time: 2.34198
Timestep Consumption Time: 2.47403
PPO Batch Consumption Time: 0.29003
Total Iteration Time: 4.81601

Cumulative Model Updates: 245,462
Cumulative Timesteps: 2,047,769,006

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62,972.24931
Policy Entropy: 2.42842
Value Function Loss: 0.01641

Mean KL Divergence: 0.00737
SB3 Clip Fraction: 0.06953
Policy Update Magnitude: 0.30686
Value Function Update Magnitude: 0.27825

Collected Steps per Second: 21,557.94918
Overall Steps per Second: 10,415.55711

Timestep Collection Time: 2.31961
Timestep Consumption Time: 2.48148
PPO Batch Consumption Time: 0.29196
Total Iteration Time: 4.80109

Cumulative Model Updates: 245,468
Cumulative Timesteps: 2,047,819,012

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2047819012...
Checkpoint 2047819012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 71,547.32343
Policy Entropy: 2.42618
Value Function Loss: 0.01549

Mean KL Divergence: 0.00731
SB3 Clip Fraction: 0.07102
Policy Update Magnitude: 0.31663
Value Function Update Magnitude: 0.30591

Collected Steps per Second: 21,370.47325
Overall Steps per Second: 10,561.86494

Timestep Collection Time: 2.34024
Timestep Consumption Time: 2.39491
PPO Batch Consumption Time: 0.27725
Total Iteration Time: 4.73515

Cumulative Model Updates: 245,474
Cumulative Timesteps: 2,047,869,024

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59,549.98552
Policy Entropy: 2.44577
Value Function Loss: 0.01504

Mean KL Divergence: 0.00739
SB3 Clip Fraction: 0.06596
Policy Update Magnitude: 0.30514
Value Function Update Magnitude: 0.30786

Collected Steps per Second: 21,742.54455
Overall Steps per Second: 10,393.69567

Timestep Collection Time: 2.29991
Timestep Consumption Time: 2.51127
PPO Batch Consumption Time: 0.29171
Total Iteration Time: 4.81119

Cumulative Model Updates: 245,480
Cumulative Timesteps: 2,047,919,030

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2047919030...
Checkpoint 2047919030 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 83,087.75628
Policy Entropy: 2.45360
Value Function Loss: 0.01502

Mean KL Divergence: 0.00705
SB3 Clip Fraction: 0.06788
Policy Update Magnitude: 0.30536
Value Function Update Magnitude: 0.31207

Collected Steps per Second: 21,110.85257
Overall Steps per Second: 10,204.19176

Timestep Collection Time: 2.36930
Timestep Consumption Time: 2.53241
PPO Batch Consumption Time: 0.29426
Total Iteration Time: 4.90171

Cumulative Model Updates: 245,486
Cumulative Timesteps: 2,047,969,048

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67,556.37263
Policy Entropy: 2.44366
Value Function Loss: 0.01498

Mean KL Divergence: 0.00709
SB3 Clip Fraction: 0.06639
Policy Update Magnitude: 0.30968
Value Function Update Magnitude: 0.32926

Collected Steps per Second: 22,251.00501
Overall Steps per Second: 10,472.08537

Timestep Collection Time: 2.24880
Timestep Consumption Time: 2.52943
PPO Batch Consumption Time: 0.29098
Total Iteration Time: 4.77823

Cumulative Model Updates: 245,492
Cumulative Timesteps: 2,048,019,086

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 2048019086...
Checkpoint 2048019086 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 68,685.13932
Policy Entropy: 2.43069
Value Function Loss: 0.01558

Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.07492
Policy Update Magnitude: 0.32314
Value Function Update Magnitude: 0.31858

Collected Steps per Second: 22,016.94617
Overall Steps per Second: 10,589.39336

Timestep Collection Time: 2.27125
Timestep Consumption Time: 2.45102
PPO Batch Consumption Time: 0.27897
Total Iteration Time: 4.72227

Cumulative Model Updates: 245,498
Cumulative Timesteps: 2,048,069,092

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68,685.13932
Policy Entropy: 2.43203
Value Function Loss: 0.01416

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.07267
Policy Update Magnitude: 0.31721
Value Function Update Magnitude: 0.30450

Collected Steps per Second: 22,053.51345
Overall Steps per Second: 10,474.29805

Timestep Collection Time: 2.26830
Timestep Consumption Time: 2.50758
PPO Batch Consumption Time: 0.29050
Total Iteration Time: 4.77588

Cumulative Model Updates: 245,504
Cumulative Timesteps: 2,048,119,116

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2048119116...
Checkpoint 2048119116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 65,971.01879
Policy Entropy: 2.44652
Value Function Loss: 0.01682

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.07306
Policy Update Magnitude: 0.32588
Value Function Update Magnitude: 0.33886

Collected Steps per Second: 21,757.45338
Overall Steps per Second: 10,564.78595

Timestep Collection Time: 2.29861
Timestep Consumption Time: 2.43522
PPO Batch Consumption Time: 0.27948
Total Iteration Time: 4.73384

Cumulative Model Updates: 245,510
Cumulative Timesteps: 2,048,169,128

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62,501.85897
Policy Entropy: 2.44393
Value Function Loss: 0.01678

Mean KL Divergence: 0.00777
SB3 Clip Fraction: 0.07117
Policy Update Magnitude: 0.31785
Value Function Update Magnitude: 0.32522

Collected Steps per Second: 22,095.58830
Overall Steps per Second: 10,521.49799

Timestep Collection Time: 2.26308
Timestep Consumption Time: 2.48948
PPO Batch Consumption Time: 0.28719
Total Iteration Time: 4.75256

Cumulative Model Updates: 245,516
Cumulative Timesteps: 2,048,219,132

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2048219132...
Checkpoint 2048219132 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 101,850.69098
Policy Entropy: 2.43968
Value Function Loss: 0.01909

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.07088
Policy Update Magnitude: 0.32084
Value Function Update Magnitude: 0.32729

Collected Steps per Second: 21,742.27311
Overall Steps per Second: 10,589.32141

Timestep Collection Time: 2.30142
Timestep Consumption Time: 2.42391
PPO Batch Consumption Time: 0.27935
Total Iteration Time: 4.72533

Cumulative Model Updates: 245,522
Cumulative Timesteps: 2,048,269,170

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68,656.79008
Policy Entropy: 2.42866
Value Function Loss: 0.01649

Mean KL Divergence: 0.00673
SB3 Clip Fraction: 0.06373
Policy Update Magnitude: 0.32046
Value Function Update Magnitude: 0.34361

Collected Steps per Second: 22,147.65564
Overall Steps per Second: 10,515.46246

Timestep Collection Time: 2.25803
Timestep Consumption Time: 2.49783
PPO Batch Consumption Time: 0.28970
Total Iteration Time: 4.75585

Cumulative Model Updates: 245,528
Cumulative Timesteps: 2,048,319,180

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2048319180...
Checkpoint 2048319180 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 60,356.68191
Policy Entropy: 2.43951
Value Function Loss: 0.01674

Mean KL Divergence: 0.00752
SB3 Clip Fraction: 0.06786
Policy Update Magnitude: 0.32020
Value Function Update Magnitude: 0.34477

Collected Steps per Second: 21,447.87608
Overall Steps per Second: 10,386.68492

Timestep Collection Time: 2.33300
Timestep Consumption Time: 2.48451
PPO Batch Consumption Time: 0.28986
Total Iteration Time: 4.81751

Cumulative Model Updates: 245,534
Cumulative Timesteps: 2,048,369,218

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53,997.71724
Policy Entropy: 2.44366
Value Function Loss: 0.01510

Mean KL Divergence: 0.00762
SB3 Clip Fraction: 0.07026
Policy Update Magnitude: 0.31163
Value Function Update Magnitude: 0.33668

Collected Steps per Second: 21,709.45388
Overall Steps per Second: 10,428.59285

Timestep Collection Time: 2.30360
Timestep Consumption Time: 2.49186
PPO Batch Consumption Time: 0.28993
Total Iteration Time: 4.79547

Cumulative Model Updates: 245,540
Cumulative Timesteps: 2,048,419,228

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2048419228...
Checkpoint 2048419228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,252.82169
Policy Entropy: 2.47882
Value Function Loss: 0.01461

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.08149
Policy Update Magnitude: 0.30194
Value Function Update Magnitude: 0.29443

Collected Steps per Second: 21,591.51635
Overall Steps per Second: 10,466.86172

Timestep Collection Time: 2.31591
Timestep Consumption Time: 2.46145
PPO Batch Consumption Time: 0.28434
Total Iteration Time: 4.77736

Cumulative Model Updates: 245,546
Cumulative Timesteps: 2,048,469,232

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50,008.32075
Policy Entropy: 2.47935
Value Function Loss: 0.01494

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.07740
Policy Update Magnitude: 0.29567
Value Function Update Magnitude: 0.27984

Collected Steps per Second: 21,786.36524
Overall Steps per Second: 10,455.82231

Timestep Collection Time: 2.29621
Timestep Consumption Time: 2.48830
PPO Batch Consumption Time: 0.28914
Total Iteration Time: 4.78451

Cumulative Model Updates: 245,552
Cumulative Timesteps: 2,048,519,258

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2048519258...
Checkpoint 2048519258 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 50,008.32075
Policy Entropy: 2.47913
Value Function Loss: 0.01433

Mean KL Divergence: 0.00730
SB3 Clip Fraction: 0.06789
Policy Update Magnitude: 0.28813
Value Function Update Magnitude: 0.28240

Collected Steps per Second: 21,292.26169
Overall Steps per Second: 10,276.67526

Timestep Collection Time: 2.34836
Timestep Consumption Time: 2.51722
PPO Batch Consumption Time: 0.29280
Total Iteration Time: 4.86558

Cumulative Model Updates: 245,558
Cumulative Timesteps: 2,048,569,260

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 72,380.87292
Policy Entropy: 2.45979
Value Function Loss: 0.01554

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.06856
Policy Update Magnitude: 0.30321
Value Function Update Magnitude: 0.29354

Collected Steps per Second: 21,658.12282
Overall Steps per Second: 10,482.63771

Timestep Collection Time: 2.31036
Timestep Consumption Time: 2.46306
PPO Batch Consumption Time: 0.29221
Total Iteration Time: 4.77342

Cumulative Model Updates: 245,564
Cumulative Timesteps: 2,048,619,298

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 2048619298...
Checkpoint 2048619298 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 65,713.67444
Policy Entropy: 2.43198
Value Function Loss: 0.01783

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.07501
Policy Update Magnitude: 0.31567
Value Function Update Magnitude: 0.28239

Collected Steps per Second: 21,382.23241
Overall Steps per Second: 10,532.95058

Timestep Collection Time: 2.33951
Timestep Consumption Time: 2.40977
PPO Batch Consumption Time: 0.28893
Total Iteration Time: 4.74929

Cumulative Model Updates: 245,570
Cumulative Timesteps: 2,048,669,322

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88,336.89920
Policy Entropy: 2.41778
Value Function Loss: 0.01752

Mean KL Divergence: 0.01194
SB3 Clip Fraction: 0.08570
Policy Update Magnitude: 0.32198
Value Function Update Magnitude: 0.30466

Collected Steps per Second: 21,369.77132
Overall Steps per Second: 10,510.71821

Timestep Collection Time: 2.34003
Timestep Consumption Time: 2.41759
PPO Batch Consumption Time: 0.27825
Total Iteration Time: 4.75762

Cumulative Model Updates: 245,576
Cumulative Timesteps: 2,048,719,328

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2048719328...
Checkpoint 2048719328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 73,788.32027
Policy Entropy: 2.40180
Value Function Loss: 0.01988

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.09321
Policy Update Magnitude: 0.31609
Value Function Update Magnitude: 0.29918

Collected Steps per Second: 21,729.09778
Overall Steps per Second: 10,643.68364

Timestep Collection Time: 2.30161
Timestep Consumption Time: 2.39713
PPO Batch Consumption Time: 0.27781
Total Iteration Time: 4.69875

Cumulative Model Updates: 245,582
Cumulative Timesteps: 2,048,769,340

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 64,788.42222
Policy Entropy: 2.42445
Value Function Loss: 0.01804

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.08169
Policy Update Magnitude: 0.33013
Value Function Update Magnitude: 0.32281

Collected Steps per Second: 22,431.80525
Overall Steps per Second: 10,795.90945

Timestep Collection Time: 2.22916
Timestep Consumption Time: 2.40260
PPO Batch Consumption Time: 0.27872
Total Iteration Time: 4.63175

Cumulative Model Updates: 245,588
Cumulative Timesteps: 2,048,819,344

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2048819344...
Checkpoint 2048819344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 69,757.96584
Policy Entropy: 2.46736
Value Function Loss: 0.01715

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.07928
Policy Update Magnitude: 0.32251
Value Function Update Magnitude: 0.32356

Collected Steps per Second: 20,015.00025
Overall Steps per Second: 10,151.01589

Timestep Collection Time: 2.49943
Timestep Consumption Time: 2.42875
PPO Batch Consumption Time: 0.27829
Total Iteration Time: 4.92818

Cumulative Model Updates: 245,594
Cumulative Timesteps: 2,048,869,370

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,243.44117
Policy Entropy: 2.46588
Value Function Loss: 0.01785

Mean KL Divergence: 0.00681
SB3 Clip Fraction: 0.06050
Policy Update Magnitude: 0.32360
Value Function Update Magnitude: 0.31456

Collected Steps per Second: 21,259.92330
Overall Steps per Second: 10,448.38580

Timestep Collection Time: 2.35297
Timestep Consumption Time: 2.43475
PPO Batch Consumption Time: 0.27916
Total Iteration Time: 4.78773

Cumulative Model Updates: 245,600
Cumulative Timesteps: 2,048,919,394

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2048919394...
Checkpoint 2048919394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 77,474.99967
Policy Entropy: 2.47344
Value Function Loss: 0.01929

Mean KL Divergence: 0.00782
SB3 Clip Fraction: 0.07027
Policy Update Magnitude: 0.32654
Value Function Update Magnitude: 0.31443

Collected Steps per Second: 21,498.57888
Overall Steps per Second: 10,361.51262

Timestep Collection Time: 2.32629
Timestep Consumption Time: 2.50042
PPO Batch Consumption Time: 0.29291
Total Iteration Time: 4.82671

Cumulative Model Updates: 245,606
Cumulative Timesteps: 2,048,969,406

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88,345.70504
Policy Entropy: 2.46777
Value Function Loss: 0.01770

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.07094
Policy Update Magnitude: 0.31182
Value Function Update Magnitude: 0.29207

Collected Steps per Second: 22,106.33061
Overall Steps per Second: 10,439.96357

Timestep Collection Time: 2.26225
Timestep Consumption Time: 2.52800
PPO Batch Consumption Time: 0.29259
Total Iteration Time: 4.79025

Cumulative Model Updates: 245,612
Cumulative Timesteps: 2,049,019,416

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2049019416...
Checkpoint 2049019416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 58,503.38061
Policy Entropy: 2.49025
Value Function Loss: 0.01573

Mean KL Divergence: 0.00705
SB3 Clip Fraction: 0.06620
Policy Update Magnitude: 0.31253
Value Function Update Magnitude: 0.29877

Collected Steps per Second: 21,841.81686
Overall Steps per Second: 10,537.00990

Timestep Collection Time: 2.29074
Timestep Consumption Time: 2.45766
PPO Batch Consumption Time: 0.27828
Total Iteration Time: 4.74841

Cumulative Model Updates: 245,618
Cumulative Timesteps: 2,049,069,450

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,658.09309
Policy Entropy: 2.48937
Value Function Loss: 0.01600

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.06782
Policy Update Magnitude: 0.31318
Value Function Update Magnitude: 0.29904

Collected Steps per Second: 22,224.69519
Overall Steps per Second: 10,424.65921

Timestep Collection Time: 2.25101
Timestep Consumption Time: 2.54800
PPO Batch Consumption Time: 0.29191
Total Iteration Time: 4.79901

Cumulative Model Updates: 245,624
Cumulative Timesteps: 2,049,119,478

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2049119478...
Checkpoint 2049119478 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 51,456.37412
Policy Entropy: 2.47556
Value Function Loss: 0.01676

Mean KL Divergence: 0.00749
SB3 Clip Fraction: 0.07031
Policy Update Magnitude: 0.31712
Value Function Update Magnitude: 0.32551

Collected Steps per Second: 21,509.24492
Overall Steps per Second: 10,335.20165

Timestep Collection Time: 2.32477
Timestep Consumption Time: 2.51345
PPO Batch Consumption Time: 0.29349
Total Iteration Time: 4.83822

Cumulative Model Updates: 245,630
Cumulative Timesteps: 2,049,169,482

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,621.81230
Policy Entropy: 2.44191
Value Function Loss: 0.01905

Mean KL Divergence: 0.00737
SB3 Clip Fraction: 0.06970
Policy Update Magnitude: 0.33033
Value Function Update Magnitude: 0.36564

Collected Steps per Second: 22,167.33256
Overall Steps per Second: 10,508.50698

Timestep Collection Time: 2.25620
Timestep Consumption Time: 2.50318
PPO Batch Consumption Time: 0.29307
Total Iteration Time: 4.75938

Cumulative Model Updates: 245,636
Cumulative Timesteps: 2,049,219,496

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2049219496...
Checkpoint 2049219496 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 79,111.59631
Policy Entropy: 2.41356
Value Function Loss: 0.01929

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.08596
Policy Update Magnitude: 0.33957
Value Function Update Magnitude: 0.40309

Collected Steps per Second: 22,207.31770
Overall Steps per Second: 10,559.73298

Timestep Collection Time: 2.25241
Timestep Consumption Time: 2.48445
PPO Batch Consumption Time: 0.28836
Total Iteration Time: 4.73686

Cumulative Model Updates: 245,642
Cumulative Timesteps: 2,049,269,516

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61,215.18232
Policy Entropy: 2.42133
Value Function Loss: 0.01884

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.07955
Policy Update Magnitude: 0.34670
Value Function Update Magnitude: 0.39030

Collected Steps per Second: 22,176.83146
Overall Steps per Second: 10,487.87200

Timestep Collection Time: 2.25587
Timestep Consumption Time: 2.51421
PPO Batch Consumption Time: 0.29276
Total Iteration Time: 4.77008

Cumulative Model Updates: 245,648
Cumulative Timesteps: 2,049,319,544

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2049319544...
Checkpoint 2049319544 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 66,051.55570
Policy Entropy: 2.41291
Value Function Loss: 0.01760

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.08019
Policy Update Magnitude: 0.33583
Value Function Update Magnitude: 0.34273

Collected Steps per Second: 21,698.64670
Overall Steps per Second: 10,566.81769

Timestep Collection Time: 2.30484
Timestep Consumption Time: 2.42809
PPO Batch Consumption Time: 0.27836
Total Iteration Time: 4.73293

Cumulative Model Updates: 245,654
Cumulative Timesteps: 2,049,369,556

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49,747.88084
Policy Entropy: 2.42894
Value Function Loss: 0.01579

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.07688
Policy Update Magnitude: 0.32109
Value Function Update Magnitude: 0.30568

Collected Steps per Second: 21,491.04868
Overall Steps per Second: 10,551.03869

Timestep Collection Time: 2.32785
Timestep Consumption Time: 2.41367
PPO Batch Consumption Time: 0.27675
Total Iteration Time: 4.74152

Cumulative Model Updates: 245,660
Cumulative Timesteps: 2,049,419,584

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2049419584...
Checkpoint 2049419584 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 76,517.12610
Policy Entropy: 2.42807
Value Function Loss: 0.01490

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.06628
Policy Update Magnitude: 0.31736
Value Function Update Magnitude: 0.29875

Collected Steps per Second: 21,642.26767
Overall Steps per Second: 10,542.12697

Timestep Collection Time: 2.31150
Timestep Consumption Time: 2.43385
PPO Batch Consumption Time: 0.27893
Total Iteration Time: 4.74534

Cumulative Model Updates: 245,666
Cumulative Timesteps: 2,049,469,610

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83,560.95137
Policy Entropy: 2.44076
Value Function Loss: 0.01546

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.07247
Policy Update Magnitude: 0.31776
Value Function Update Magnitude: 0.32102

Collected Steps per Second: 21,230.39246
Overall Steps per Second: 10,461.70641

Timestep Collection Time: 2.35596
Timestep Consumption Time: 2.42509
PPO Batch Consumption Time: 0.28954
Total Iteration Time: 4.78106

Cumulative Model Updates: 245,672
Cumulative Timesteps: 2,049,519,628

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2049519628...
Checkpoint 2049519628 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 78,029.58815
Policy Entropy: 2.45169
Value Function Loss: 0.01654

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.07501
Policy Update Magnitude: 0.31657
Value Function Update Magnitude: 0.32082

Collected Steps per Second: 21,057.74703
Overall Steps per Second: 10,588.76784

Timestep Collection Time: 2.37547
Timestep Consumption Time: 2.34859
PPO Batch Consumption Time: 0.27809
Total Iteration Time: 4.72406

Cumulative Model Updates: 245,678
Cumulative Timesteps: 2,049,569,650

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45,077.49678
Policy Entropy: 2.45220
Value Function Loss: 0.01833

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.07503
Policy Update Magnitude: 0.33013
Value Function Update Magnitude: 0.32037

Collected Steps per Second: 20,766.32479
Overall Steps per Second: 10,465.65994

Timestep Collection Time: 2.40880
Timestep Consumption Time: 2.37083
PPO Batch Consumption Time: 0.27850
Total Iteration Time: 4.77963

Cumulative Model Updates: 245,684
Cumulative Timesteps: 2,049,619,672

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2049619672...
Checkpoint 2049619672 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48,036.62277
Policy Entropy: 2.42987
Value Function Loss: 0.01716

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.08028
Policy Update Magnitude: 0.32899
Value Function Update Magnitude: 0.32465

Collected Steps per Second: 21,132.35751
Overall Steps per Second: 10,236.98732

Timestep Collection Time: 2.36661
Timestep Consumption Time: 2.51881
PPO Batch Consumption Time: 0.29036
Total Iteration Time: 4.88542

Cumulative Model Updates: 245,690
Cumulative Timesteps: 2,049,669,684

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,350.11885
Policy Entropy: 2.43357
Value Function Loss: 0.01813

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.07650
Policy Update Magnitude: 0.32870
Value Function Update Magnitude: 0.32605

Collected Steps per Second: 22,127.64256
Overall Steps per Second: 10,525.31211

Timestep Collection Time: 2.26034
Timestep Consumption Time: 2.49163
PPO Batch Consumption Time: 0.29258
Total Iteration Time: 4.75197

Cumulative Model Updates: 245,696
Cumulative Timesteps: 2,049,719,700

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2049719700...
Checkpoint 2049719700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,207.75895
Policy Entropy: 2.45454
Value Function Loss: 0.01801

Mean KL Divergence: 0.00772
SB3 Clip Fraction: 0.07140
Policy Update Magnitude: 0.32904
Value Function Update Magnitude: 0.31316

Collected Steps per Second: 21,996.39244
Overall Steps per Second: 10,585.93260

Timestep Collection Time: 2.27455
Timestep Consumption Time: 2.45172
PPO Batch Consumption Time: 0.28598
Total Iteration Time: 4.72627

Cumulative Model Updates: 245,702
Cumulative Timesteps: 2,049,769,732

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92,593.87760
Policy Entropy: 2.47774
Value Function Loss: 0.01711

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.08393
Policy Update Magnitude: 0.31739
Value Function Update Magnitude: 0.32871

Collected Steps per Second: 21,893.45442
Overall Steps per Second: 10,484.69323

Timestep Collection Time: 2.28607
Timestep Consumption Time: 2.48755
PPO Batch Consumption Time: 0.29383
Total Iteration Time: 4.77363

Cumulative Model Updates: 245,708
Cumulative Timesteps: 2,049,819,782

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 2049819782...
Checkpoint 2049819782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 73,510.81213
Policy Entropy: 2.48423
Value Function Loss: 0.01765

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.09255
Policy Update Magnitude: 0.31445
Value Function Update Magnitude: 0.32773

Collected Steps per Second: 21,867.01103
Overall Steps per Second: 10,589.69019

Timestep Collection Time: 2.28765
Timestep Consumption Time: 2.43619
PPO Batch Consumption Time: 0.27909
Total Iteration Time: 4.72384

Cumulative Model Updates: 245,714
Cumulative Timesteps: 2,049,869,806

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53,629.56496
Policy Entropy: 2.49386
Value Function Loss: 0.01684

Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.07616
Policy Update Magnitude: 0.31410
Value Function Update Magnitude: 0.33918

Collected Steps per Second: 21,906.85394
Overall Steps per Second: 10,479.56334

Timestep Collection Time: 2.28476
Timestep Consumption Time: 2.49139
PPO Batch Consumption Time: 0.28857
Total Iteration Time: 4.77615

Cumulative Model Updates: 245,720
Cumulative Timesteps: 2,049,919,858

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


Saving checkpoint 2049919858...
Checkpoint 2049919858 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,457.99441
Policy Entropy: 2.49234
Value Function Loss: 0.01730

Mean KL Divergence: 0.00740
SB3 Clip Fraction: 0.06958
Policy Update Magnitude: 0.31968
Value Function Update Magnitude: 0.34750

Collected Steps per Second: 21,841.33176
Overall Steps per Second: 10,583.37015

Timestep Collection Time: 2.29043
Timestep Consumption Time: 2.43642
PPO Batch Consumption Time: 0.27910
Total Iteration Time: 4.72685

Cumulative Model Updates: 245,726
Cumulative Timesteps: 2,049,969,884

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97,262.88229
Policy Entropy: 2.52474
Value Function Loss: 0.01513

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.06909
Policy Update Magnitude: 0.31048
Value Function Update Magnitude: 0.31494

Collected Steps per Second: 21,871.89402
Overall Steps per Second: 10,519.05740

Timestep Collection Time: 2.28631
Timestep Consumption Time: 2.46753
PPO Batch Consumption Time: 0.28469
Total Iteration Time: 4.75385

Cumulative Model Updates: 245,732
Cumulative Timesteps: 2,050,019,890

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2050019890...
Checkpoint 2050019890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 61,116.91001
Policy Entropy: 2.53670
Value Function Loss: 0.01649

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.07005
Policy Update Magnitude: 0.30090
Value Function Update Magnitude: 0.26789

Collected Steps per Second: 21,270.91756
Overall Steps per Second: 10,305.97339

Timestep Collection Time: 2.35241
Timestep Consumption Time: 2.50283
PPO Batch Consumption Time: 0.29149
Total Iteration Time: 4.85524

Cumulative Model Updates: 245,738
Cumulative Timesteps: 2,050,069,928

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59,606.82100
Policy Entropy: 2.53073
Value Function Loss: 0.01835

Mean KL Divergence: 0.00752
SB3 Clip Fraction: 0.07251
Policy Update Magnitude: 0.30568
Value Function Update Magnitude: 0.23938

Collected Steps per Second: 21,760.26847
Overall Steps per Second: 10,344.52849

Timestep Collection Time: 2.29804
Timestep Consumption Time: 2.53601
PPO Batch Consumption Time: 0.29232
Total Iteration Time: 4.83405

Cumulative Model Updates: 245,744
Cumulative Timesteps: 2,050,119,934

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2050119934...
Checkpoint 2050119934 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 58,502.14895
Policy Entropy: 2.48241
Value Function Loss: 0.01887

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.07383
Policy Update Magnitude: 0.30858
Value Function Update Magnitude: 0.21609

Collected Steps per Second: 21,474.36288
Overall Steps per Second: 10,340.57424

Timestep Collection Time: 2.32975
Timestep Consumption Time: 2.50847
PPO Batch Consumption Time: 0.29185
Total Iteration Time: 4.83822

Cumulative Model Updates: 245,750
Cumulative Timesteps: 2,050,169,964

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55,845.76239
Policy Entropy: 2.50062
Value Function Loss: 0.01705

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.08067
Policy Update Magnitude: 0.30414
Value Function Update Magnitude: 0.22957

Collected Steps per Second: 21,793.14404
Overall Steps per Second: 10,402.23710

Timestep Collection Time: 2.29503
Timestep Consumption Time: 2.51316
PPO Batch Consumption Time: 0.29314
Total Iteration Time: 4.80820

Cumulative Model Updates: 245,756
Cumulative Timesteps: 2,050,219,980

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2050219980...
Checkpoint 2050219980 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55,208.62763
Policy Entropy: 2.49033
Value Function Loss: 0.01640

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.07807
Policy Update Magnitude: 0.30841
Value Function Update Magnitude: 0.23449

Collected Steps per Second: 21,963.19349
Overall Steps per Second: 10,499.95017

Timestep Collection Time: 2.27717
Timestep Consumption Time: 2.48609
PPO Batch Consumption Time: 0.27901
Total Iteration Time: 4.76326

Cumulative Model Updates: 245,762
Cumulative Timesteps: 2,050,269,994

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60,240.66395
Policy Entropy: 2.52023
Value Function Loss: 0.01797

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.07919
Policy Update Magnitude: 0.31790
Value Function Update Magnitude: 0.24390

Collected Steps per Second: 21,919.85045
Overall Steps per Second: 10,426.56763

Timestep Collection Time: 2.28222
Timestep Consumption Time: 2.51571
PPO Batch Consumption Time: 0.29136
Total Iteration Time: 4.79794

Cumulative Model Updates: 245,768
Cumulative Timesteps: 2,050,320,020

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2050320020...
Checkpoint 2050320020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 53,260.86978
Policy Entropy: 2.52427
Value Function Loss: 0.01589

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.07654
Policy Update Magnitude: 0.30985
Value Function Update Magnitude: 0.30196

Collected Steps per Second: 22,117.06635
Overall Steps per Second: 10,659.33592

Timestep Collection Time: 2.26214
Timestep Consumption Time: 2.43158
PPO Batch Consumption Time: 0.27832
Total Iteration Time: 4.69373

Cumulative Model Updates: 245,774
Cumulative Timesteps: 2,050,370,052

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53,260.86978
Policy Entropy: 2.55045
Value Function Loss: 0.01232

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.07698
Policy Update Magnitude: 0.28301
Value Function Update Magnitude: 0.28885

Collected Steps per Second: 21,474.69722
Overall Steps per Second: 10,515.45229

Timestep Collection Time: 2.32879
Timestep Consumption Time: 2.42707
PPO Batch Consumption Time: 0.29116
Total Iteration Time: 4.75586

Cumulative Model Updates: 245,780
Cumulative Timesteps: 2,050,420,062

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2050420062...
Checkpoint 2050420062 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 76,314.05811
Policy Entropy: 2.54203
Value Function Loss: 0.01078

Mean KL Divergence: 0.00564
SB3 Clip Fraction: 0.05476
Policy Update Magnitude: 0.26383
Value Function Update Magnitude: 0.25256

Collected Steps per Second: 21,477.51396
Overall Steps per Second: 10,704.08070

Timestep Collection Time: 2.32811
Timestep Consumption Time: 2.34319
PPO Batch Consumption Time: 0.27722
Total Iteration Time: 4.67130

Cumulative Model Updates: 245,786
Cumulative Timesteps: 2,050,470,064

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76,488.63095
Policy Entropy: 2.51116
Value Function Loss: 0.01232

Mean KL Divergence: 0.00553
SB3 Clip Fraction: 0.05470
Policy Update Magnitude: 0.26956
Value Function Update Magnitude: 0.25590

Collected Steps per Second: 21,925.17576
Overall Steps per Second: 10,796.53889

Timestep Collection Time: 2.28176
Timestep Consumption Time: 2.35195
PPO Batch Consumption Time: 0.27922
Total Iteration Time: 4.63371

Cumulative Model Updates: 245,792
Cumulative Timesteps: 2,050,520,092

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2050520092...
Checkpoint 2050520092 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 72,231.67995
Policy Entropy: 2.47409
Value Function Loss: 0.01393

Mean KL Divergence: 0.00669
SB3 Clip Fraction: 0.06496
Policy Update Magnitude: 0.29188
Value Function Update Magnitude: 0.29025

Collected Steps per Second: 21,190.95920
Overall Steps per Second: 10,351.25012

Timestep Collection Time: 2.35987
Timestep Consumption Time: 2.47123
PPO Batch Consumption Time: 0.29318
Total Iteration Time: 4.83111

Cumulative Model Updates: 245,798
Cumulative Timesteps: 2,050,570,100

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91,421.39337
Policy Entropy: 2.48831
Value Function Loss: 0.01437

Mean KL Divergence: 0.00666
SB3 Clip Fraction: 0.06391
Policy Update Magnitude: 0.30050
Value Function Update Magnitude: 0.31339

Collected Steps per Second: 21,218.34011
Overall Steps per Second: 10,384.03829

Timestep Collection Time: 2.35645
Timestep Consumption Time: 2.45863
PPO Batch Consumption Time: 0.28908
Total Iteration Time: 4.81508

Cumulative Model Updates: 245,804
Cumulative Timesteps: 2,050,620,100

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2050620100...
Checkpoint 2050620100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 103,114.02763
Policy Entropy: 2.47775
Value Function Loss: 0.01448

Mean KL Divergence: 0.00629
SB3 Clip Fraction: 0.05896
Policy Update Magnitude: 0.30651
Value Function Update Magnitude: 0.30700

Collected Steps per Second: 21,348.34118
Overall Steps per Second: 10,551.41203

Timestep Collection Time: 2.34238
Timestep Consumption Time: 2.39689
PPO Batch Consumption Time: 0.27821
Total Iteration Time: 4.73927

Cumulative Model Updates: 245,810
Cumulative Timesteps: 2,050,670,106

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 102,783.15385
Policy Entropy: 2.49698
Value Function Loss: 0.01696

Mean KL Divergence: 0.00628
SB3 Clip Fraction: 0.06085
Policy Update Magnitude: 0.31312
Value Function Update Magnitude: 0.30616

Collected Steps per Second: 21,426.43960
Overall Steps per Second: 10,455.40277

Timestep Collection Time: 2.33469
Timestep Consumption Time: 2.44983
PPO Batch Consumption Time: 0.28028
Total Iteration Time: 4.78451

Cumulative Model Updates: 245,816
Cumulative Timesteps: 2,050,720,130

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2050720130...
Checkpoint 2050720130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 88,932.60991
Policy Entropy: 2.47176
Value Function Loss: 0.01886

Mean KL Divergence: 0.00730
SB3 Clip Fraction: 0.06846
Policy Update Magnitude: 0.31087
Value Function Update Magnitude: 0.32373

Collected Steps per Second: 21,429.48220
Overall Steps per Second: 10,328.96609

Timestep Collection Time: 2.33398
Timestep Consumption Time: 2.50832
PPO Batch Consumption Time: 0.29384
Total Iteration Time: 4.84230

Cumulative Model Updates: 245,822
Cumulative Timesteps: 2,050,770,146

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82,615.94646
Policy Entropy: 2.49551
Value Function Loss: 0.01880

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.07866
Policy Update Magnitude: 0.31308
Value Function Update Magnitude: 0.37909

Collected Steps per Second: 21,708.35865
Overall Steps per Second: 10,357.29327

Timestep Collection Time: 2.30335
Timestep Consumption Time: 2.52436
PPO Batch Consumption Time: 0.29123
Total Iteration Time: 4.82771

Cumulative Model Updates: 245,828
Cumulative Timesteps: 2,050,820,148

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2050820148...
Checkpoint 2050820148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 63,588.36000
Policy Entropy: 2.48621
Value Function Loss: 0.01759

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.07734
Policy Update Magnitude: 0.31592
Value Function Update Magnitude: 0.39232

Collected Steps per Second: 21,690.12158
Overall Steps per Second: 10,305.24752

Timestep Collection Time: 2.30575
Timestep Consumption Time: 2.54731
PPO Batch Consumption Time: 0.29329
Total Iteration Time: 4.85306

Cumulative Model Updates: 245,834
Cumulative Timesteps: 2,050,870,160

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55,925.72801
Policy Entropy: 2.49720
Value Function Loss: 0.01758

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.07293
Policy Update Magnitude: 0.31888
Value Function Update Magnitude: 0.38449

Collected Steps per Second: 22,079.15354
Overall Steps per Second: 10,489.37770

Timestep Collection Time: 2.26549
Timestep Consumption Time: 2.50315
PPO Batch Consumption Time: 0.29045
Total Iteration Time: 4.76863

Cumulative Model Updates: 245,840
Cumulative Timesteps: 2,050,920,180

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2050920180...
Checkpoint 2050920180 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 74,528.93730
Policy Entropy: 2.46607
Value Function Loss: 0.01855

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.07533
Policy Update Magnitude: 0.32640
Value Function Update Magnitude: 0.39941

Collected Steps per Second: 22,130.25935
Overall Steps per Second: 10,483.01731

Timestep Collection Time: 2.26016
Timestep Consumption Time: 2.51117
PPO Batch Consumption Time: 0.29209
Total Iteration Time: 4.77134

Cumulative Model Updates: 245,846
Cumulative Timesteps: 2,050,970,198

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97,676.37993
Policy Entropy: 2.46861
Value Function Loss: 0.01885

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.07810
Policy Update Magnitude: 0.32679
Value Function Update Magnitude: 0.37743

Collected Steps per Second: 21,910.04453
Overall Steps per Second: 10,448.99364

Timestep Collection Time: 2.28334
Timestep Consumption Time: 2.50449
PPO Batch Consumption Time: 0.29109
Total Iteration Time: 4.78783

Cumulative Model Updates: 245,852
Cumulative Timesteps: 2,051,020,226

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2051020226...
Checkpoint 2051020226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 78,676.82091
Policy Entropy: 2.48470
Value Function Loss: 0.01845

Mean KL Divergence: 0.01082
SB3 Clip Fraction: 0.09139
Policy Update Magnitude: 0.32496
Value Function Update Magnitude: 0.32439

Collected Steps per Second: 21,798.37320
Overall Steps per Second: 10,624.81183

Timestep Collection Time: 2.29494
Timestep Consumption Time: 2.41347
PPO Batch Consumption Time: 0.27904
Total Iteration Time: 4.70841

Cumulative Model Updates: 245,858
Cumulative Timesteps: 2,051,070,252

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61,414.18384
Policy Entropy: 2.50318
Value Function Loss: 0.01722

Mean KL Divergence: 0.01406
SB3 Clip Fraction: 0.10758
Policy Update Magnitude: 0.31119
Value Function Update Magnitude: 0.28205

Collected Steps per Second: 22,142.84633
Overall Steps per Second: 10,491.96306

Timestep Collection Time: 2.25879
Timestep Consumption Time: 2.50829
PPO Batch Consumption Time: 0.29109
Total Iteration Time: 4.76708

Cumulative Model Updates: 245,864
Cumulative Timesteps: 2,051,120,268

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2051120268...
Checkpoint 2051120268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 54,359.23441
Policy Entropy: 2.50542
Value Function Loss: 0.01506

Mean KL Divergence: 0.01360
SB3 Clip Fraction: 0.10677
Policy Update Magnitude: 0.30744
Value Function Update Magnitude: 0.25195

Collected Steps per Second: 22,245.05325
Overall Steps per Second: 10,694.39092

Timestep Collection Time: 2.24850
Timestep Consumption Time: 2.42853
PPO Batch Consumption Time: 0.27754
Total Iteration Time: 4.67703

Cumulative Model Updates: 245,870
Cumulative Timesteps: 2,051,170,286

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 94,739.74527
Policy Entropy: 2.47680
Value Function Loss: 0.01588

Mean KL Divergence: 0.01070
SB3 Clip Fraction: 0.09200
Policy Update Magnitude: 0.30970
Value Function Update Magnitude: 0.24105

Collected Steps per Second: 21,050.55644
Overall Steps per Second: 10,407.53113

Timestep Collection Time: 2.37599
Timestep Consumption Time: 2.42976
PPO Batch Consumption Time: 0.28829
Total Iteration Time: 4.80575

Cumulative Model Updates: 245,876
Cumulative Timesteps: 2,051,220,302

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2051220302...
Checkpoint 2051220302 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 71,860.23011
Policy Entropy: 2.47584
Value Function Loss: 0.01594

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.08363
Policy Update Magnitude: 0.31401
Value Function Update Magnitude: 0.27793

Collected Steps per Second: 20,691.31948
Overall Steps per Second: 10,356.51566

Timestep Collection Time: 2.41667
Timestep Consumption Time: 2.41160
PPO Batch Consumption Time: 0.28997
Total Iteration Time: 4.82826

Cumulative Model Updates: 245,882
Cumulative Timesteps: 2,051,270,306

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 116,957.48522
Policy Entropy: 2.48294
Value Function Loss: 0.01697

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.07781
Policy Update Magnitude: 0.31528
Value Function Update Magnitude: 0.31323

Collected Steps per Second: 20,868.18455
Overall Steps per Second: 10,370.38256

Timestep Collection Time: 2.39733
Timestep Consumption Time: 2.42679
PPO Batch Consumption Time: 0.29225
Total Iteration Time: 4.82412

Cumulative Model Updates: 245,888
Cumulative Timesteps: 2,051,320,334

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2051320334...
Checkpoint 2051320334 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 80,215.05770
Policy Entropy: 2.51164
Value Function Loss: 0.01752

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.07226
Policy Update Magnitude: 0.31982
Value Function Update Magnitude: 0.34174

Collected Steps per Second: 21,099.02434
Overall Steps per Second: 10,590.63157

Timestep Collection Time: 2.37110
Timestep Consumption Time: 2.35269
PPO Batch Consumption Time: 0.27786
Total Iteration Time: 4.72380

Cumulative Model Updates: 245,894
Cumulative Timesteps: 2,051,370,362

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67,783.00035
Policy Entropy: 2.50871
Value Function Loss: 0.01683

Mean KL Divergence: 0.00743
SB3 Clip Fraction: 0.06981
Policy Update Magnitude: 0.31655
Value Function Update Magnitude: 0.36175

Collected Steps per Second: 21,241.33094
Overall Steps per Second: 10,507.20854

Timestep Collection Time: 2.35447
Timestep Consumption Time: 2.40531
PPO Batch Consumption Time: 0.27753
Total Iteration Time: 4.75978

Cumulative Model Updates: 245,900
Cumulative Timesteps: 2,051,420,374

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2051420374...
Checkpoint 2051420374 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 51,483.15389
Policy Entropy: 2.48697
Value Function Loss: 0.01769

Mean KL Divergence: 0.00743
SB3 Clip Fraction: 0.06809
Policy Update Magnitude: 0.32789
Value Function Update Magnitude: 0.36612

Collected Steps per Second: 21,997.31174
Overall Steps per Second: 10,645.65239

Timestep Collection Time: 2.27337
Timestep Consumption Time: 2.42414
PPO Batch Consumption Time: 0.27744
Total Iteration Time: 4.69750

Cumulative Model Updates: 245,906
Cumulative Timesteps: 2,051,470,382

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75,406.98024
Policy Entropy: 2.46087
Value Function Loss: 0.01814

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.07547
Policy Update Magnitude: 0.32929
Value Function Update Magnitude: 0.35438

Collected Steps per Second: 21,928.47825
Overall Steps per Second: 10,538.02246

Timestep Collection Time: 2.28206
Timestep Consumption Time: 2.46665
PPO Batch Consumption Time: 0.28897
Total Iteration Time: 4.74871

Cumulative Model Updates: 245,912
Cumulative Timesteps: 2,051,520,424

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 2051520424...
Checkpoint 2051520424 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43,811.98861
Policy Entropy: 2.43578
Value Function Loss: 0.01942

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.08020
Policy Update Magnitude: 0.33503
Value Function Update Magnitude: 0.35313

Collected Steps per Second: 21,762.50339
Overall Steps per Second: 10,445.71562

Timestep Collection Time: 2.29771
Timestep Consumption Time: 2.48932
PPO Batch Consumption Time: 0.28735
Total Iteration Time: 4.78703

Cumulative Model Updates: 245,918
Cumulative Timesteps: 2,051,570,428

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49,782.02243
Policy Entropy: 2.45853
Value Function Loss: 0.01884

Mean KL Divergence: 0.00750
SB3 Clip Fraction: 0.06930
Policy Update Magnitude: 0.33004
Value Function Update Magnitude: 0.37609

Collected Steps per Second: 22,546.79447
Overall Steps per Second: 10,628.27921

Timestep Collection Time: 2.21885
Timestep Consumption Time: 2.48821
PPO Batch Consumption Time: 0.29035
Total Iteration Time: 4.70706

Cumulative Model Updates: 245,924
Cumulative Timesteps: 2,051,620,456

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2051620456...
Checkpoint 2051620456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 60,205.63260
Policy Entropy: 2.47500
Value Function Loss: 0.01592

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.07954
Policy Update Magnitude: 0.31524
Value Function Update Magnitude: 0.38010

Collected Steps per Second: 21,861.82983
Overall Steps per Second: 10,471.05579

Timestep Collection Time: 2.28801
Timestep Consumption Time: 2.48897
PPO Batch Consumption Time: 0.28800
Total Iteration Time: 4.77698

Cumulative Model Updates: 245,930
Cumulative Timesteps: 2,051,670,476

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 73,807.89811
Policy Entropy: 2.50246
Value Function Loss: 0.01440

Mean KL Divergence: 0.00720
SB3 Clip Fraction: 0.06783
Policy Update Magnitude: 0.30554
Value Function Update Magnitude: 0.33938

Collected Steps per Second: 22,586.71832
Overall Steps per Second: 10,643.19938

Timestep Collection Time: 2.21493
Timestep Consumption Time: 2.48554
PPO Batch Consumption Time: 0.29025
Total Iteration Time: 4.70047

Cumulative Model Updates: 245,936
Cumulative Timesteps: 2,051,720,504

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2051720504...
Checkpoint 2051720504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 95,759.78534
Policy Entropy: 2.50866
Value Function Loss: 0.01319

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.07544
Policy Update Magnitude: 0.30221
Value Function Update Magnitude: 0.31297

Collected Steps per Second: 21,558.24331
Overall Steps per Second: 10,533.50528

Timestep Collection Time: 2.32041
Timestep Consumption Time: 2.42862
PPO Batch Consumption Time: 0.27709
Total Iteration Time: 4.74904

Cumulative Model Updates: 245,942
Cumulative Timesteps: 2,051,770,528

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95,759.78534
Policy Entropy: 2.50205
Value Function Loss: 0.01264

Mean KL Divergence: 0.00746
SB3 Clip Fraction: 0.06701
Policy Update Magnitude: 0.28889
Value Function Update Magnitude: 0.28748

Collected Steps per Second: 21,600.97299
Overall Steps per Second: 10,413.67018

Timestep Collection Time: 2.31508
Timestep Consumption Time: 2.48707
PPO Batch Consumption Time: 0.28861
Total Iteration Time: 4.80215

Cumulative Model Updates: 245,948
Cumulative Timesteps: 2,051,820,536

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2051820536...
Checkpoint 2051820536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86,874.16782
Policy Entropy: 2.48397
Value Function Loss: 0.01497

Mean KL Divergence: 0.00739
SB3 Clip Fraction: 0.06926
Policy Update Magnitude: 0.28973
Value Function Update Magnitude: 0.28251

Collected Steps per Second: 21,245.66358
Overall Steps per Second: 10,297.79528

Timestep Collection Time: 2.35436
Timestep Consumption Time: 2.50299
PPO Batch Consumption Time: 0.29216
Total Iteration Time: 4.85735

Cumulative Model Updates: 245,954
Cumulative Timesteps: 2,051,870,556

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76,923.67155
Policy Entropy: 2.48751
Value Function Loss: 0.01510

Mean KL Divergence: 0.00704
SB3 Clip Fraction: 0.06391
Policy Update Magnitude: 0.29797
Value Function Update Magnitude: 0.29833

Collected Steps per Second: 21,832.43085
Overall Steps per Second: 10,465.11010

Timestep Collection Time: 2.29017
Timestep Consumption Time: 2.48761
PPO Batch Consumption Time: 0.29134
Total Iteration Time: 4.77778

Cumulative Model Updates: 245,960
Cumulative Timesteps: 2,051,920,556

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2051920556...
Checkpoint 2051920556 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 76,923.67155
Policy Entropy: 2.49303
Value Function Loss: 0.01487

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.07166
Policy Update Magnitude: 0.29648
Value Function Update Magnitude: 0.31199

Collected Steps per Second: 21,831.89069
Overall Steps per Second: 10,581.64695

Timestep Collection Time: 2.29059
Timestep Consumption Time: 2.43532
PPO Batch Consumption Time: 0.27736
Total Iteration Time: 4.72592

Cumulative Model Updates: 245,966
Cumulative Timesteps: 2,051,970,564

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83,585.26680
Policy Entropy: 2.51628
Value Function Loss: 0.01383

Mean KL Divergence: 0.00729
SB3 Clip Fraction: 0.06625
Policy Update Magnitude: 0.28824
Value Function Update Magnitude: 0.28727

Collected Steps per Second: 22,351.68974
Overall Steps per Second: 10,466.99449

Timestep Collection Time: 2.23715
Timestep Consumption Time: 2.54016
PPO Batch Consumption Time: 0.29332
Total Iteration Time: 4.77730

Cumulative Model Updates: 245,972
Cumulative Timesteps: 2,052,020,568

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2052020568...
Checkpoint 2052020568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 99,584.23636
Policy Entropy: 2.52081
Value Function Loss: 0.01362

Mean KL Divergence: 0.00627
SB3 Clip Fraction: 0.05792
Policy Update Magnitude: 0.28059
Value Function Update Magnitude: 0.26367

Collected Steps per Second: 21,644.16913
Overall Steps per Second: 10,489.35457

Timestep Collection Time: 2.31046
Timestep Consumption Time: 2.45704
PPO Batch Consumption Time: 0.27881
Total Iteration Time: 4.76750

Cumulative Model Updates: 245,978
Cumulative Timesteps: 2,052,070,576

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79,323.50035
Policy Entropy: 2.51176
Value Function Loss: 0.01438

Mean KL Divergence: 0.00627
SB3 Clip Fraction: 0.05966
Policy Update Magnitude: 0.28261
Value Function Update Magnitude: 0.28851

Collected Steps per Second: 22,211.18215
Overall Steps per Second: 10,518.23989

Timestep Collection Time: 2.25220
Timestep Consumption Time: 2.50373
PPO Batch Consumption Time: 0.29122
Total Iteration Time: 4.75593

Cumulative Model Updates: 245,984
Cumulative Timesteps: 2,052,120,600

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2052120600...
Checkpoint 2052120600 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 75,999.08629
Policy Entropy: 2.50610
Value Function Loss: 0.01359

Mean KL Divergence: 0.00709
SB3 Clip Fraction: 0.06591
Policy Update Magnitude: 0.28657
Value Function Update Magnitude: 0.29538

Collected Steps per Second: 21,936.64872
Overall Steps per Second: 10,604.36596

Timestep Collection Time: 2.28002
Timestep Consumption Time: 2.43653
PPO Batch Consumption Time: 0.27935
Total Iteration Time: 4.71655

Cumulative Model Updates: 245,990
Cumulative Timesteps: 2,052,170,616

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 69,948.11750
Policy Entropy: 2.50539
Value Function Loss: 0.01529

Mean KL Divergence: 0.00708
SB3 Clip Fraction: 0.06473
Policy Update Magnitude: 0.28504
Value Function Update Magnitude: 0.27816

Collected Steps per Second: 22,645.44863
Overall Steps per Second: 10,610.93815

Timestep Collection Time: 2.20848
Timestep Consumption Time: 2.50477
PPO Batch Consumption Time: 0.29206
Total Iteration Time: 4.71325

Cumulative Model Updates: 245,996
Cumulative Timesteps: 2,052,220,628

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2052220628...
Checkpoint 2052220628 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 62,330.55003
Policy Entropy: 2.51333
Value Function Loss: 0.01474

Mean KL Divergence: 0.00577
SB3 Clip Fraction: 0.05583
Policy Update Magnitude: 0.29110
Value Function Update Magnitude: 0.27672

Collected Steps per Second: 21,864.72604
Overall Steps per Second: 10,522.33787

Timestep Collection Time: 2.28715
Timestep Consumption Time: 2.46540
PPO Batch Consumption Time: 0.28527
Total Iteration Time: 4.75256

Cumulative Model Updates: 246,002
Cumulative Timesteps: 2,052,270,636

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79,953.31905
Policy Entropy: 2.52822
Value Function Loss: 0.01510

Mean KL Divergence: 0.00685
SB3 Clip Fraction: 0.06540
Policy Update Magnitude: 0.29308
Value Function Update Magnitude: 0.28266

Collected Steps per Second: 22,398.41681
Overall Steps per Second: 10,546.99013

Timestep Collection Time: 2.23266
Timestep Consumption Time: 2.50879
PPO Batch Consumption Time: 0.29184
Total Iteration Time: 4.74145

Cumulative Model Updates: 246,008
Cumulative Timesteps: 2,052,320,644

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2052320644...
Checkpoint 2052320644 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 122,372.68578
Policy Entropy: 2.53890
Value Function Loss: 0.01521

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.07212
Policy Update Magnitude: 0.29007
Value Function Update Magnitude: 0.27532

Collected Steps per Second: 21,312.99031
Overall Steps per Second: 10,476.55331

Timestep Collection Time: 2.34674
Timestep Consumption Time: 2.42735
PPO Batch Consumption Time: 0.27832
Total Iteration Time: 4.77409

Cumulative Model Updates: 246,014
Cumulative Timesteps: 2,052,370,660

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92,795.14153
Policy Entropy: 2.54059
Value Function Loss: 0.01829

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.07247
Policy Update Magnitude: 0.30568
Value Function Update Magnitude: 0.26153

Collected Steps per Second: 21,799.47862
Overall Steps per Second: 10,533.57476

Timestep Collection Time: 2.29437
Timestep Consumption Time: 2.45388
PPO Batch Consumption Time: 0.28361
Total Iteration Time: 4.74825

Cumulative Model Updates: 246,020
Cumulative Timesteps: 2,052,420,676

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2052420676...
Checkpoint 2052420676 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 79,464.76946
Policy Entropy: 2.52244
Value Function Loss: 0.01647

Mean KL Divergence: 0.01133
SB3 Clip Fraction: 0.09304
Policy Update Magnitude: 0.29935
Value Function Update Magnitude: 0.27494

Collected Steps per Second: 21,539.01000
Overall Steps per Second: 10,403.59451

Timestep Collection Time: 2.32313
Timestep Consumption Time: 2.48655
PPO Batch Consumption Time: 0.28928
Total Iteration Time: 4.80968

Cumulative Model Updates: 246,026
Cumulative Timesteps: 2,052,470,714

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80,224.37522
Policy Entropy: 2.50929
Value Function Loss: 0.01885

Mean KL Divergence: 0.01133
SB3 Clip Fraction: 0.09212
Policy Update Magnitude: 0.30420
Value Function Update Magnitude: 0.30849

Collected Steps per Second: 22,103.80980
Overall Steps per Second: 10,632.56064

Timestep Collection Time: 2.26350
Timestep Consumption Time: 2.44204
PPO Batch Consumption Time: 0.27898
Total Iteration Time: 4.70555

Cumulative Model Updates: 246,032
Cumulative Timesteps: 2,052,520,746

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2052520746...
Checkpoint 2052520746 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 79,186.29676
Policy Entropy: 2.50015
Value Function Loss: 0.01651

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.08874
Policy Update Magnitude: 0.30715
Value Function Update Magnitude: 0.32904

Collected Steps per Second: 22,002.48762
Overall Steps per Second: 10,601.37906

Timestep Collection Time: 2.27374
Timestep Consumption Time: 2.44527
PPO Batch Consumption Time: 0.27881
Total Iteration Time: 4.71901

Cumulative Model Updates: 246,038
Cumulative Timesteps: 2,052,570,774

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79,958.61615
Policy Entropy: 2.51291
Value Function Loss: 0.01586

Mean KL Divergence: 0.01193
SB3 Clip Fraction: 0.09894
Policy Update Magnitude: 0.30783
Value Function Update Magnitude: 0.33556

Collected Steps per Second: 20,943.97330
Overall Steps per Second: 10,176.38380

Timestep Collection Time: 2.38875
Timestep Consumption Time: 2.52753
PPO Batch Consumption Time: 0.29267
Total Iteration Time: 4.91628

Cumulative Model Updates: 246,044
Cumulative Timesteps: 2,052,620,804

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2052620804...
Checkpoint 2052620804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 72,730.85685
Policy Entropy: 2.49440
Value Function Loss: 0.01597

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.08573
Policy Update Magnitude: 0.29672
Value Function Update Magnitude: 0.28359

Collected Steps per Second: 21,672.45370
Overall Steps per Second: 10,525.65405

Timestep Collection Time: 2.30763
Timestep Consumption Time: 2.44381
PPO Batch Consumption Time: 0.27884
Total Iteration Time: 4.75144

Cumulative Model Updates: 246,050
Cumulative Timesteps: 2,052,670,816

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 73,703.02583
Policy Entropy: 2.48926
Value Function Loss: 0.01765

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.08253
Policy Update Magnitude: 0.30181
Value Function Update Magnitude: 0.25879

Collected Steps per Second: 22,164.52421
Overall Steps per Second: 10,468.31012

Timestep Collection Time: 2.25604
Timestep Consumption Time: 2.52066
PPO Batch Consumption Time: 0.29313
Total Iteration Time: 4.77670

Cumulative Model Updates: 246,056
Cumulative Timesteps: 2,052,720,820

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2052720820...
Checkpoint 2052720820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 83,372.85468
Policy Entropy: 2.47379
Value Function Loss: 0.02177

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.08054
Policy Update Magnitude: 0.31548
Value Function Update Magnitude: 0.27539

Collected Steps per Second: 21,946.68712
Overall Steps per Second: 10,590.21436

Timestep Collection Time: 2.27952
Timestep Consumption Time: 2.44446
PPO Batch Consumption Time: 0.27932
Total Iteration Time: 4.72398

Cumulative Model Updates: 246,062
Cumulative Timesteps: 2,052,770,848

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70,167.33943
Policy Entropy: 2.46774
Value Function Loss: 0.02015

Mean KL Divergence: 0.00753
SB3 Clip Fraction: 0.07224
Policy Update Magnitude: 0.31409
Value Function Update Magnitude: 0.23893

Collected Steps per Second: 21,788.50318
Overall Steps per Second: 10,579.75670

Timestep Collection Time: 2.29479
Timestep Consumption Time: 2.43122
PPO Batch Consumption Time: 0.27729
Total Iteration Time: 4.72601

Cumulative Model Updates: 246,068
Cumulative Timesteps: 2,052,820,848

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2052820848...
Checkpoint 2052820848 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 59,328.51840
Policy Entropy: 2.46679
Value Function Loss: 0.02143

Mean KL Divergence: 0.00708
SB3 Clip Fraction: 0.06907
Policy Update Magnitude: 0.31486
Value Function Update Magnitude: 0.23624

Collected Steps per Second: 21,769.10870
Overall Steps per Second: 10,577.85766

Timestep Collection Time: 2.29775
Timestep Consumption Time: 2.43099
PPO Batch Consumption Time: 0.27888
Total Iteration Time: 4.72875

Cumulative Model Updates: 246,074
Cumulative Timesteps: 2,052,870,868

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70,638.07674
Policy Entropy: 2.47800
Value Function Loss: 0.01731

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.08117
Policy Update Magnitude: 0.30961
Value Function Update Magnitude: 0.26518

Collected Steps per Second: 21,851.29455
Overall Steps per Second: 10,448.41232

Timestep Collection Time: 2.28902
Timestep Consumption Time: 2.49812
PPO Batch Consumption Time: 0.28851
Total Iteration Time: 4.78714

Cumulative Model Updates: 246,080
Cumulative Timesteps: 2,052,920,886

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2052920886...
Checkpoint 2052920886 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 57,798.25897
Policy Entropy: 2.48411
Value Function Loss: 0.01620

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.09274
Policy Update Magnitude: 0.29493
Value Function Update Magnitude: 0.26701

Collected Steps per Second: 21,534.95874
Overall Steps per Second: 10,403.82558

Timestep Collection Time: 2.32236
Timestep Consumption Time: 2.48471
PPO Batch Consumption Time: 0.28925
Total Iteration Time: 4.80708

Cumulative Model Updates: 246,086
Cumulative Timesteps: 2,052,970,898

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,838.49530
Policy Entropy: 2.48208
Value Function Loss: 0.01716

Mean KL Divergence: 0.01073
SB3 Clip Fraction: 0.09379
Policy Update Magnitude: 0.30590
Value Function Update Magnitude: 0.26654

Collected Steps per Second: 21,799.50678
Overall Steps per Second: 10,619.09471

Timestep Collection Time: 2.29409
Timestep Consumption Time: 2.41535
PPO Batch Consumption Time: 0.27878
Total Iteration Time: 4.70944

Cumulative Model Updates: 246,092
Cumulative Timesteps: 2,053,020,908

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2053020908...
Checkpoint 2053020908 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 54,525.14170
Policy Entropy: 2.48300
Value Function Loss: 0.01713

Mean KL Divergence: 0.01102
SB3 Clip Fraction: 0.09373
Policy Update Magnitude: 0.31504
Value Function Update Magnitude: 0.31205

Collected Steps per Second: 20,963.48270
Overall Steps per Second: 10,261.87710

Timestep Collection Time: 2.38567
Timestep Consumption Time: 2.48790
PPO Batch Consumption Time: 0.28871
Total Iteration Time: 4.87357

Cumulative Model Updates: 246,098
Cumulative Timesteps: 2,053,070,920

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51,281.59636
Policy Entropy: 2.48524
Value Function Loss: 0.01642

Mean KL Divergence: 0.01073
SB3 Clip Fraction: 0.08951
Policy Update Magnitude: 0.31022
Value Function Update Magnitude: 0.33108

Collected Steps per Second: 21,898.96636
Overall Steps per Second: 10,439.35275

Timestep Collection Time: 2.28358
Timestep Consumption Time: 2.50676
PPO Batch Consumption Time: 0.28716
Total Iteration Time: 4.79034

Cumulative Model Updates: 246,104
Cumulative Timesteps: 2,053,120,928

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2053120928...
Checkpoint 2053120928 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 60,804.20562
Policy Entropy: 2.50305
Value Function Loss: 0.01585

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.07654
Policy Update Magnitude: 0.31098
Value Function Update Magnitude: 0.31777

Collected Steps per Second: 21,835.61334
Overall Steps per Second: 10,307.35539

Timestep Collection Time: 2.29002
Timestep Consumption Time: 2.56127
PPO Batch Consumption Time: 0.29265
Total Iteration Time: 4.85129

Cumulative Model Updates: 246,110
Cumulative Timesteps: 2,053,170,932

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78,900.85411
Policy Entropy: 2.50587
Value Function Loss: 0.01539

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.07620
Policy Update Magnitude: 0.30522
Value Function Update Magnitude: 0.29136

Collected Steps per Second: 22,365.25573
Overall Steps per Second: 10,709.45686

Timestep Collection Time: 2.23570
Timestep Consumption Time: 2.43326
PPO Batch Consumption Time: 0.27859
Total Iteration Time: 4.66896

Cumulative Model Updates: 246,116
Cumulative Timesteps: 2,053,220,934

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2053220934...
Checkpoint 2053220934 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 72,917.26761
Policy Entropy: 2.52575
Value Function Loss: 0.01430

Mean KL Divergence: 0.00743
SB3 Clip Fraction: 0.06348
Policy Update Magnitude: 0.28685
Value Function Update Magnitude: 0.26678

Collected Steps per Second: 22,021.56680
Overall Steps per Second: 10,462.05689

Timestep Collection Time: 2.27195
Timestep Consumption Time: 2.51028
PPO Batch Consumption Time: 0.29003
Total Iteration Time: 4.78223

Cumulative Model Updates: 246,122
Cumulative Timesteps: 2,053,270,966

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45,656.98666
Policy Entropy: 2.52142
Value Function Loss: 0.01348

Mean KL Divergence: 0.00601
SB3 Clip Fraction: 0.05725
Policy Update Magnitude: 0.28300
Value Function Update Magnitude: 0.23442

Collected Steps per Second: 21,311.75097
Overall Steps per Second: 10,285.59602

Timestep Collection Time: 2.34631
Timestep Consumption Time: 2.51524
PPO Batch Consumption Time: 0.28743
Total Iteration Time: 4.86156

Cumulative Model Updates: 246,128
Cumulative Timesteps: 2,053,320,970

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2053320970...
Checkpoint 2053320970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 60,074.59866
Policy Entropy: 2.49502
Value Function Loss: 0.01612

Mean KL Divergence: 0.00601
SB3 Clip Fraction: 0.05773
Policy Update Magnitude: 0.29925
Value Function Update Magnitude: 0.23026

Collected Steps per Second: 21,931.83787
Overall Steps per Second: 10,592.70417

Timestep Collection Time: 2.27979
Timestep Consumption Time: 2.44044
PPO Batch Consumption Time: 0.28005
Total Iteration Time: 4.72023

Cumulative Model Updates: 246,134
Cumulative Timesteps: 2,053,370,970

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 72,039.39688
Policy Entropy: 2.48603
Value Function Loss: 0.01556

Mean KL Divergence: 0.00712
SB3 Clip Fraction: 0.06337
Policy Update Magnitude: 0.30374
Value Function Update Magnitude: 0.28313

Collected Steps per Second: 21,840.68651
Overall Steps per Second: 10,491.02165

Timestep Collection Time: 2.28940
Timestep Consumption Time: 2.47677
PPO Batch Consumption Time: 0.28672
Total Iteration Time: 4.76617

Cumulative Model Updates: 246,140
Cumulative Timesteps: 2,053,420,972

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2053420972...
Checkpoint 2053420972 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 72,039.39688
Policy Entropy: 2.49703
Value Function Loss: 0.01391

Mean KL Divergence: 0.00762
SB3 Clip Fraction: 0.06565
Policy Update Magnitude: 0.28802
Value Function Update Magnitude: 0.27798

Collected Steps per Second: 21,960.23315
Overall Steps per Second: 10,634.32498

Timestep Collection Time: 2.27739
Timestep Consumption Time: 2.42549
PPO Batch Consumption Time: 0.27840
Total Iteration Time: 4.70288

Cumulative Model Updates: 246,146
Cumulative Timesteps: 2,053,470,984

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83,569.24183
Policy Entropy: 2.52263
Value Function Loss: 0.01143

Mean KL Divergence: 0.00640
SB3 Clip Fraction: 0.05717
Policy Update Magnitude: 0.27320
Value Function Update Magnitude: 0.23957

Collected Steps per Second: 21,741.65260
Overall Steps per Second: 10,446.86389

Timestep Collection Time: 2.30047
Timestep Consumption Time: 2.48719
PPO Batch Consumption Time: 0.28701
Total Iteration Time: 4.78766

Cumulative Model Updates: 246,152
Cumulative Timesteps: 2,053,521,000

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2053521000...
Checkpoint 2053521000 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 70,514.22015
Policy Entropy: 2.50175
Value Function Loss: 0.01231

Mean KL Divergence: 0.00612
SB3 Clip Fraction: 0.05934
Policy Update Magnitude: 0.26966
Value Function Update Magnitude: 0.25225

Collected Steps per Second: 21,495.64105
Overall Steps per Second: 10,390.03369

Timestep Collection Time: 2.32763
Timestep Consumption Time: 2.48794
PPO Batch Consumption Time: 0.29094
Total Iteration Time: 4.81558

Cumulative Model Updates: 246,158
Cumulative Timesteps: 2,053,571,034

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 72,512.09561
Policy Entropy: 2.49466
Value Function Loss: 0.01288

Mean KL Divergence: 0.00668
SB3 Clip Fraction: 0.06265
Policy Update Magnitude: 0.27774
Value Function Update Magnitude: 0.27441

Collected Steps per Second: 21,168.26029
Overall Steps per Second: 10,531.68702

Timestep Collection Time: 2.36297
Timestep Consumption Time: 2.38650
PPO Batch Consumption Time: 0.28812
Total Iteration Time: 4.74948

Cumulative Model Updates: 246,164
Cumulative Timesteps: 2,053,621,054

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2053621054...
Checkpoint 2053621054 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 72,512.09561
Policy Entropy: 2.49331
Value Function Loss: 0.01329

Mean KL Divergence: 0.00724
SB3 Clip Fraction: 0.06557
Policy Update Magnitude: 0.28296
Value Function Update Magnitude: 0.29084

Collected Steps per Second: 20,826.93794
Overall Steps per Second: 10,408.09720

Timestep Collection Time: 2.40179
Timestep Consumption Time: 2.40427
PPO Batch Consumption Time: 0.28762
Total Iteration Time: 4.80607

Cumulative Model Updates: 246,170
Cumulative Timesteps: 2,053,671,076

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 74,045.14489
Policy Entropy: 2.50305
Value Function Loss: 0.01238

Mean KL Divergence: 0.00680
SB3 Clip Fraction: 0.06258
Policy Update Magnitude: 0.28002
Value Function Update Magnitude: 0.28588

Collected Steps per Second: 20,996.34948
Overall Steps per Second: 10,437.53672

Timestep Collection Time: 2.38251
Timestep Consumption Time: 2.41019
PPO Batch Consumption Time: 0.28692
Total Iteration Time: 4.79270

Cumulative Model Updates: 246,176
Cumulative Timesteps: 2,053,721,100

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2053721100...
Checkpoint 2053721100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 74,045.14489
Policy Entropy: 2.51501
Value Function Loss: 0.01127

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.06866
Policy Update Magnitude: 0.27191
Value Function Update Magnitude: 0.25399

Collected Steps per Second: 20,957.61136
Overall Steps per Second: 10,170.67742

Timestep Collection Time: 2.38710
Timestep Consumption Time: 2.53174
PPO Batch Consumption Time: 0.29208
Total Iteration Time: 4.91885

Cumulative Model Updates: 246,182
Cumulative Timesteps: 2,053,771,128

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84,153.45617
Policy Entropy: 2.52701
Value Function Loss: 0.01199

Mean KL Divergence: 0.00748
SB3 Clip Fraction: 0.06707
Policy Update Magnitude: 0.26709
Value Function Update Magnitude: 0.20932

Collected Steps per Second: 21,989.82943
Overall Steps per Second: 10,462.47783

Timestep Collection Time: 2.27478
Timestep Consumption Time: 2.50631
PPO Batch Consumption Time: 0.29211
Total Iteration Time: 4.78109

Cumulative Model Updates: 246,188
Cumulative Timesteps: 2,053,821,150

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2053821150...
Checkpoint 2053821150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 92,623.77229
Policy Entropy: 2.52750
Value Function Loss: 0.01316

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.07154
Policy Update Magnitude: 0.27159
Value Function Update Magnitude: 0.21408

Collected Steps per Second: 21,873.94238
Overall Steps per Second: 10,652.65035

Timestep Collection Time: 2.28637
Timestep Consumption Time: 2.40842
PPO Batch Consumption Time: 0.27893
Total Iteration Time: 4.69479

Cumulative Model Updates: 246,194
Cumulative Timesteps: 2,053,871,162

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 125,992.93893
Policy Entropy: 2.51378
Value Function Loss: 0.01675

Mean KL Divergence: 0.00730
SB3 Clip Fraction: 0.06647
Policy Update Magnitude: 0.28969
Value Function Update Magnitude: 0.23352

Collected Steps per Second: 22,097.39853
Overall Steps per Second: 10,463.83250

Timestep Collection Time: 2.26389
Timestep Consumption Time: 2.51696
PPO Batch Consumption Time: 0.29195
Total Iteration Time: 4.78085

Cumulative Model Updates: 246,200
Cumulative Timesteps: 2,053,921,188

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2053921188...
Checkpoint 2053921188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 100,443.33895
Policy Entropy: 2.51899
Value Function Loss: 0.01657

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.07453
Policy Update Magnitude: 0.29399
Value Function Update Magnitude: 0.27220

Collected Steps per Second: 21,947.01185
Overall Steps per Second: 10,611.46892

Timestep Collection Time: 2.27894
Timestep Consumption Time: 2.43445
PPO Batch Consumption Time: 0.27852
Total Iteration Time: 4.71339

Cumulative Model Updates: 246,206
Cumulative Timesteps: 2,053,971,204

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 72,574.35901
Policy Entropy: 2.51414
Value Function Loss: 0.01786

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.08521
Policy Update Magnitude: 0.29846
Value Function Update Magnitude: 0.29790

Collected Steps per Second: 22,111.01103
Overall Steps per Second: 10,474.67704

Timestep Collection Time: 2.26240
Timestep Consumption Time: 2.51331
PPO Batch Consumption Time: 0.29017
Total Iteration Time: 4.77571

Cumulative Model Updates: 246,212
Cumulative Timesteps: 2,054,021,228

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2054021228...
Checkpoint 2054021228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 113,379.48628
Policy Entropy: 2.54228
Value Function Loss: 0.01529

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.09404
Policy Update Magnitude: 0.29701
Value Function Update Magnitude: 0.27750

Collected Steps per Second: 21,985.52075
Overall Steps per Second: 10,626.01248

Timestep Collection Time: 2.27495
Timestep Consumption Time: 2.43199
PPO Batch Consumption Time: 0.27920
Total Iteration Time: 4.70694

Cumulative Model Updates: 246,218
Cumulative Timesteps: 2,054,071,244

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 135,181.85803
Policy Entropy: 2.54340
Value Function Loss: 0.01436

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.08754
Policy Update Magnitude: 0.28164
Value Function Update Magnitude: 0.25697

Collected Steps per Second: 21,209.59138
Overall Steps per Second: 10,412.56412

Timestep Collection Time: 2.35780
Timestep Consumption Time: 2.44486
PPO Batch Consumption Time: 0.27896
Total Iteration Time: 4.80266

Cumulative Model Updates: 246,224
Cumulative Timesteps: 2,054,121,252

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2054121252...
Checkpoint 2054121252 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 107,593.19375
Policy Entropy: 2.52668
Value Function Loss: 0.01408

Mean KL Divergence: 0.00722
SB3 Clip Fraction: 0.06627
Policy Update Magnitude: 0.27722
Value Function Update Magnitude: 0.27652

Collected Steps per Second: 21,439.59068
Overall Steps per Second: 10,329.28093

Timestep Collection Time: 2.33325
Timestep Consumption Time: 2.50968
PPO Batch Consumption Time: 0.29313
Total Iteration Time: 4.84293

Cumulative Model Updates: 246,230
Cumulative Timesteps: 2,054,171,276

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 118,709.56375
Policy Entropy: 2.50089
Value Function Loss: 0.01404

Mean KL Divergence: 0.00615
SB3 Clip Fraction: 0.05867
Policy Update Magnitude: 0.28028
Value Function Update Magnitude: 0.26847

Collected Steps per Second: 21,698.83401
Overall Steps per Second: 10,401.45270

Timestep Collection Time: 2.30547
Timestep Consumption Time: 2.50405
PPO Batch Consumption Time: 0.29288
Total Iteration Time: 4.80952

Cumulative Model Updates: 246,236
Cumulative Timesteps: 2,054,221,302

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2054221302...
Checkpoint 2054221302 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 101,784.09008
Policy Entropy: 2.49423
Value Function Loss: 0.01431

Mean KL Divergence: 0.00677
SB3 Clip Fraction: 0.06238
Policy Update Magnitude: 0.28738
Value Function Update Magnitude: 0.29254

Collected Steps per Second: 21,600.78275
Overall Steps per Second: 10,568.67731

Timestep Collection Time: 2.31501
Timestep Consumption Time: 2.41652
PPO Batch Consumption Time: 0.27857
Total Iteration Time: 4.73153

Cumulative Model Updates: 246,242
Cumulative Timesteps: 2,054,271,308

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 101,784.09008
Policy Entropy: 2.48652
Value Function Loss: 0.01247

Mean KL Divergence: 0.00594
SB3 Clip Fraction: 0.05832
Policy Update Magnitude: 0.28339
Value Function Update Magnitude: 0.28769

Collected Steps per Second: 20,890.37615
Overall Steps per Second: 10,502.72850

Timestep Collection Time: 2.39393
Timestep Consumption Time: 2.36769
PPO Batch Consumption Time: 0.27888
Total Iteration Time: 4.76162

Cumulative Model Updates: 246,248
Cumulative Timesteps: 2,054,321,318

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2054321318...
Checkpoint 2054321318 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 116,866.22809
Policy Entropy: 2.50225
Value Function Loss: 0.01233

Mean KL Divergence: 0.00665
SB3 Clip Fraction: 0.06141
Policy Update Magnitude: 0.29071
Value Function Update Magnitude: 0.27003

Collected Steps per Second: 21,313.95037
Overall Steps per Second: 10,569.50403

Timestep Collection Time: 2.34691
Timestep Consumption Time: 2.38576
PPO Batch Consumption Time: 0.27885
Total Iteration Time: 4.73267

Cumulative Model Updates: 246,254
Cumulative Timesteps: 2,054,371,340

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 109,396.77697
Policy Entropy: 2.49396
Value Function Loss: 0.01170

Mean KL Divergence: 0.00624
SB3 Clip Fraction: 0.05557
Policy Update Magnitude: 0.28065
Value Function Update Magnitude: 0.25146

Collected Steps per Second: 21,720.62533
Overall Steps per Second: 10,538.84763

Timestep Collection Time: 2.30242
Timestep Consumption Time: 2.44288
PPO Batch Consumption Time: 0.29330
Total Iteration Time: 4.74530

Cumulative Model Updates: 246,260
Cumulative Timesteps: 2,054,421,350

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2054421350...
Checkpoint 2054421350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 109,396.77697
Policy Entropy: 2.51469
Value Function Loss: 0.01103

Mean KL Divergence: 0.00670
SB3 Clip Fraction: 0.05981
Policy Update Magnitude: 0.27313
Value Function Update Magnitude: 0.23615

Collected Steps per Second: 21,525.94538
Overall Steps per Second: 10,576.08847

Timestep Collection Time: 2.32315
Timestep Consumption Time: 2.40525
PPO Batch Consumption Time: 0.27904
Total Iteration Time: 4.72840

Cumulative Model Updates: 246,266
Cumulative Timesteps: 2,054,471,358

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 109,396.77697
Policy Entropy: 2.50891
Value Function Loss: 0.01035

Mean KL Divergence: 0.00624
SB3 Clip Fraction: 0.05882
Policy Update Magnitude: 0.26251
Value Function Update Magnitude: 0.20624

Collected Steps per Second: 21,702.26702
Overall Steps per Second: 10,498.23063

Timestep Collection Time: 2.30575
Timestep Consumption Time: 2.46077
PPO Batch Consumption Time: 0.28919
Total Iteration Time: 4.76652

Cumulative Model Updates: 246,272
Cumulative Timesteps: 2,054,521,398

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 2054521398...
Checkpoint 2054521398 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 126,751.60309
Policy Entropy: 2.51380
Value Function Loss: 0.01317

Mean KL Divergence: 0.00633
SB3 Clip Fraction: 0.06007
Policy Update Magnitude: 0.27512
Value Function Update Magnitude: 0.21928

Collected Steps per Second: 21,934.94247
Overall Steps per Second: 10,689.46516

Timestep Collection Time: 2.28129
Timestep Consumption Time: 2.39995
PPO Batch Consumption Time: 0.27747
Total Iteration Time: 4.68124

Cumulative Model Updates: 246,278
Cumulative Timesteps: 2,054,571,438

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 69,243.21565
Policy Entropy: 2.52128
Value Function Loss: 0.01519

Mean KL Divergence: 0.00625
SB3 Clip Fraction: 0.05731
Policy Update Magnitude: 0.28966
Value Function Update Magnitude: 0.24982

Collected Steps per Second: 22,124.19132
Overall Steps per Second: 10,495.74659

Timestep Collection Time: 2.26060
Timestep Consumption Time: 2.50457
PPO Batch Consumption Time: 0.29365
Total Iteration Time: 4.76517

Cumulative Model Updates: 246,284
Cumulative Timesteps: 2,054,621,452

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2054621452...
Checkpoint 2054621452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 67,838.27859
Policy Entropy: 2.51817
Value Function Loss: 0.01621

Mean KL Divergence: 0.00658
SB3 Clip Fraction: 0.06047
Policy Update Magnitude: 0.29147
Value Function Update Magnitude: 0.27794

Collected Steps per Second: 21,697.20650
Overall Steps per Second: 10,558.56921

Timestep Collection Time: 2.30537
Timestep Consumption Time: 2.43202
PPO Batch Consumption Time: 0.27953
Total Iteration Time: 4.73738

Cumulative Model Updates: 246,290
Cumulative Timesteps: 2,054,671,472

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59,999.77935
Policy Entropy: 2.50553
Value Function Loss: 0.01410

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.06891
Policy Update Magnitude: 0.28821
Value Function Update Magnitude: 0.29651

Collected Steps per Second: 21,357.25528
Overall Steps per Second: 10,451.93782

Timestep Collection Time: 2.34112
Timestep Consumption Time: 2.44268
PPO Batch Consumption Time: 0.27903
Total Iteration Time: 4.78380

Cumulative Model Updates: 246,296
Cumulative Timesteps: 2,054,721,472

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2054721472...
Checkpoint 2054721472 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 76,636.15774
Policy Entropy: 2.49002
Value Function Loss: 0.01361

Mean KL Divergence: 0.00747
SB3 Clip Fraction: 0.07076
Policy Update Magnitude: 0.27959
Value Function Update Magnitude: 0.27848

Collected Steps per Second: 21,612.93191
Overall Steps per Second: 10,552.19289

Timestep Collection Time: 2.31426
Timestep Consumption Time: 2.42579
PPO Batch Consumption Time: 0.27821
Total Iteration Time: 4.74006

Cumulative Model Updates: 246,302
Cumulative Timesteps: 2,054,771,490

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68,155.76454
Policy Entropy: 2.50904
Value Function Loss: 0.01261

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.08544
Policy Update Magnitude: 0.27769
Value Function Update Magnitude: 0.27601

Collected Steps per Second: 21,702.05685
Overall Steps per Second: 10,588.45208

Timestep Collection Time: 2.30540
Timestep Consumption Time: 2.41974
PPO Batch Consumption Time: 0.27744
Total Iteration Time: 4.72515

Cumulative Model Updates: 246,308
Cumulative Timesteps: 2,054,821,522

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2054821522...
Checkpoint 2054821522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 88,426.39884
Policy Entropy: 2.52450
Value Function Loss: 0.01352

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.08465
Policy Update Magnitude: 0.28035
Value Function Update Magnitude: 0.27094

Collected Steps per Second: 21,402.20758
Overall Steps per Second: 10,329.55153

Timestep Collection Time: 2.33621
Timestep Consumption Time: 2.50427
PPO Batch Consumption Time: 0.29133
Total Iteration Time: 4.84048

Cumulative Model Updates: 246,314
Cumulative Timesteps: 2,054,871,522

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 114,920.07602
Policy Entropy: 2.52520
Value Function Loss: 0.01523

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.08578
Policy Update Magnitude: 0.29116
Value Function Update Magnitude: 0.28798

Collected Steps per Second: 22,127.91260
Overall Steps per Second: 10,443.82717

Timestep Collection Time: 2.26095
Timestep Consumption Time: 2.52944
PPO Batch Consumption Time: 0.29027
Total Iteration Time: 4.79039

Cumulative Model Updates: 246,320
Cumulative Timesteps: 2,054,921,552

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2054921552...
Checkpoint 2054921552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 102,627.70489
Policy Entropy: 2.51121
Value Function Loss: 0.01595

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.08880
Policy Update Magnitude: 0.29660
Value Function Update Magnitude: 0.30968

Collected Steps per Second: 22,007.63698
Overall Steps per Second: 10,472.52029

Timestep Collection Time: 2.27276
Timestep Consumption Time: 2.50336
PPO Batch Consumption Time: 0.28781
Total Iteration Time: 4.77612

Cumulative Model Updates: 246,326
Cumulative Timesteps: 2,054,971,570

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 110,183.12438
Policy Entropy: 2.52371
Value Function Loss: 0.01521

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.08636
Policy Update Magnitude: 0.28989
Value Function Update Magnitude: 0.30873

Collected Steps per Second: 22,182.11772
Overall Steps per Second: 10,511.44920

Timestep Collection Time: 2.25533
Timestep Consumption Time: 2.50405
PPO Batch Consumption Time: 0.29396
Total Iteration Time: 4.75938

Cumulative Model Updates: 246,332
Cumulative Timesteps: 2,055,021,598

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2055021598...
Checkpoint 2055021598 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 92,310.28087
Policy Entropy: 2.55140
Value Function Loss: 0.01362

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.08830
Policy Update Magnitude: 0.28102
Value Function Update Magnitude: 0.28173

Collected Steps per Second: 21,614.86111
Overall Steps per Second: 10,547.32425

Timestep Collection Time: 2.31359
Timestep Consumption Time: 2.42770
PPO Batch Consumption Time: 0.27867
Total Iteration Time: 4.74130

Cumulative Model Updates: 246,338
Cumulative Timesteps: 2,055,071,606

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 100,412.39610
Policy Entropy: 2.53996
Value Function Loss: 0.01315

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.07334
Policy Update Magnitude: 0.27831
Value Function Update Magnitude: 0.23969

Collected Steps per Second: 22,059.81761
Overall Steps per Second: 10,494.99109

Timestep Collection Time: 2.26783
Timestep Consumption Time: 2.49901
PPO Batch Consumption Time: 0.29100
Total Iteration Time: 4.76685

Cumulative Model Updates: 246,344
Cumulative Timesteps: 2,055,121,634

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2055121634...
Checkpoint 2055121634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 106,052.81664
Policy Entropy: 2.54363
Value Function Loss: 0.01300

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.08471
Policy Update Magnitude: 0.27401
Value Function Update Magnitude: 0.25806

Collected Steps per Second: 22,265.81029
Overall Steps per Second: 10,721.22902

Timestep Collection Time: 2.24730
Timestep Consumption Time: 2.41989
PPO Batch Consumption Time: 0.27769
Total Iteration Time: 4.66719

Cumulative Model Updates: 246,350
Cumulative Timesteps: 2,055,171,672

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 100,201.58325
Policy Entropy: 2.51982
Value Function Loss: 0.01234

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.07377
Policy Update Magnitude: 0.27391
Value Function Update Magnitude: 0.26847

Collected Steps per Second: 22,130.99597
Overall Steps per Second: 10,519.61882

Timestep Collection Time: 2.26000
Timestep Consumption Time: 2.49455
PPO Batch Consumption Time: 0.29217
Total Iteration Time: 4.75454

Cumulative Model Updates: 246,356
Cumulative Timesteps: 2,055,221,688

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2055221688...
Checkpoint 2055221688 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 117,953.38647
Policy Entropy: 2.53292
Value Function Loss: 0.01323

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.07113
Policy Update Magnitude: 0.29934
Value Function Update Magnitude: 0.27278

Collected Steps per Second: 21,644.56544
Overall Steps per Second: 10,583.41106

Timestep Collection Time: 2.31060
Timestep Consumption Time: 2.41491
PPO Batch Consumption Time: 0.27702
Total Iteration Time: 4.72551

Cumulative Model Updates: 246,362
Cumulative Timesteps: 2,055,271,700

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 112,330.23419
Policy Entropy: 2.52981
Value Function Loss: 0.01301

Mean KL Divergence: 0.00758
SB3 Clip Fraction: 0.06952
Policy Update Magnitude: 0.29282
Value Function Update Magnitude: 0.27762

Collected Steps per Second: 21,728.54036
Overall Steps per Second: 10,367.38716

Timestep Collection Time: 2.30158
Timestep Consumption Time: 2.52220
PPO Batch Consumption Time: 0.29166
Total Iteration Time: 4.82378

Cumulative Model Updates: 246,368
Cumulative Timesteps: 2,055,321,710

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2055321710...
Checkpoint 2055321710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 103,640.57906
Policy Entropy: 2.55421
Value Function Loss: 0.01256

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.07042
Policy Update Magnitude: 0.28538
Value Function Update Magnitude: 0.27327

Collected Steps per Second: 21,358.38528
Overall Steps per Second: 10,373.39107

Timestep Collection Time: 2.34231
Timestep Consumption Time: 2.48041
PPO Batch Consumption Time: 0.29000
Total Iteration Time: 4.82272

Cumulative Model Updates: 246,374
Cumulative Timesteps: 2,055,371,738

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87,069.15460
Policy Entropy: 2.56268
Value Function Loss: 0.01209

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.07413
Policy Update Magnitude: 0.27965
Value Function Update Magnitude: 0.25695

Collected Steps per Second: 21,902.06879
Overall Steps per Second: 10,485.86896

Timestep Collection Time: 2.28307
Timestep Consumption Time: 2.48563
PPO Batch Consumption Time: 0.28857
Total Iteration Time: 4.76870

Cumulative Model Updates: 246,380
Cumulative Timesteps: 2,055,421,742

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2055421742...
Checkpoint 2055421742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 63,622.94501
Policy Entropy: 2.55691
Value Function Loss: 0.01450

Mean KL Divergence: 0.00690
SB3 Clip Fraction: 0.06563
Policy Update Magnitude: 0.28734
Value Function Update Magnitude: 0.23249

Collected Steps per Second: 21,878.50460
Overall Steps per Second: 10,448.84772

Timestep Collection Time: 2.28699
Timestep Consumption Time: 2.50167
PPO Batch Consumption Time: 0.28998
Total Iteration Time: 4.78866

Cumulative Model Updates: 246,386
Cumulative Timesteps: 2,055,471,778

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79,503.96449
Policy Entropy: 2.54433
Value Function Loss: 0.01796

Mean KL Divergence: 0.01186
SB3 Clip Fraction: 0.09992
Policy Update Magnitude: 0.30693
Value Function Update Magnitude: 0.24201

Collected Steps per Second: 22,362.02199
Overall Steps per Second: 10,442.64035

Timestep Collection Time: 2.23674
Timestep Consumption Time: 2.55305
PPO Batch Consumption Time: 0.29363
Total Iteration Time: 4.78978

Cumulative Model Updates: 246,392
Cumulative Timesteps: 2,055,521,796

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2055521796...
Checkpoint 2055521796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 77,740.19748
Policy Entropy: 2.51768
Value Function Loss: 0.01673

Mean KL Divergence: 0.02092
SB3 Clip Fraction: 0.13788
Policy Update Magnitude: 0.29465
Value Function Update Magnitude: 0.28910

Collected Steps per Second: 22,054.89738
Overall Steps per Second: 10,611.77205

Timestep Collection Time: 2.26798
Timestep Consumption Time: 2.44566
PPO Batch Consumption Time: 0.27932
Total Iteration Time: 4.71363

Cumulative Model Updates: 246,398
Cumulative Timesteps: 2,055,571,816

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 64,118.65663
Policy Entropy: 2.51606
Value Function Loss: 0.01788

Mean KL Divergence: 0.01464
SB3 Clip Fraction: 0.10971
Policy Update Magnitude: 0.29170
Value Function Update Magnitude: 0.31454

Collected Steps per Second: 22,437.38860
Overall Steps per Second: 10,535.81083

Timestep Collection Time: 2.22958
Timestep Consumption Time: 2.51860
PPO Batch Consumption Time: 0.29295
Total Iteration Time: 4.74819

Cumulative Model Updates: 246,404
Cumulative Timesteps: 2,055,621,842

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2055621842...
Checkpoint 2055621842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 57,647.64661
Policy Entropy: 2.50482
Value Function Loss: 0.01568

Mean KL Divergence: 0.01422
SB3 Clip Fraction: 0.11160
Policy Update Magnitude: 0.31127
Value Function Update Magnitude: 0.37340

Collected Steps per Second: 21,829.49619
Overall Steps per Second: 10,626.50135

Timestep Collection Time: 2.29057
Timestep Consumption Time: 2.41484
PPO Batch Consumption Time: 0.27692
Total Iteration Time: 4.70541

Cumulative Model Updates: 246,410
Cumulative Timesteps: 2,055,671,844

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81,804.44619
Policy Entropy: 2.52394
Value Function Loss: 0.01615

Mean KL Divergence: 0.01433
SB3 Clip Fraction: 0.10865
Policy Update Magnitude: 0.31292
Value Function Update Magnitude: 0.38785

Collected Steps per Second: 22,256.72493
Overall Steps per Second: 10,518.98718

Timestep Collection Time: 2.24723
Timestep Consumption Time: 2.50760
PPO Batch Consumption Time: 0.29199
Total Iteration Time: 4.75483

Cumulative Model Updates: 246,416
Cumulative Timesteps: 2,055,721,860

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2055721860...
Checkpoint 2055721860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 70,618.47217
Policy Entropy: 2.53532
Value Function Loss: 0.01443

Mean KL Divergence: 0.01259
SB3 Clip Fraction: 0.09656
Policy Update Magnitude: 0.31407
Value Function Update Magnitude: 0.35562

Collected Steps per Second: 21,939.38804
Overall Steps per Second: 10,501.69165

Timestep Collection Time: 2.28001
Timestep Consumption Time: 2.48322
PPO Batch Consumption Time: 0.28489
Total Iteration Time: 4.76323

Cumulative Model Updates: 246,422
Cumulative Timesteps: 2,055,771,882

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55,285.18177
Policy Entropy: 2.53004
Value Function Loss: 0.01549

Mean KL Divergence: 0.01065
SB3 Clip Fraction: 0.08990
Policy Update Magnitude: 0.30876
Value Function Update Magnitude: 0.33380

Collected Steps per Second: 21,890.13060
Overall Steps per Second: 10,483.14192

Timestep Collection Time: 2.28541
Timestep Consumption Time: 2.48682
PPO Batch Consumption Time: 0.28844
Total Iteration Time: 4.77223

Cumulative Model Updates: 246,428
Cumulative Timesteps: 2,055,821,910

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2055821910...
Checkpoint 2055821910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,383.49109
Policy Entropy: 2.51507
Value Function Loss: 0.01762

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.07887
Policy Update Magnitude: 0.32422
Value Function Update Magnitude: 0.35584

Collected Steps per Second: 21,342.08101
Overall Steps per Second: 10,333.00250

Timestep Collection Time: 2.34485
Timestep Consumption Time: 2.49827
PPO Batch Consumption Time: 0.29216
Total Iteration Time: 4.84312

Cumulative Model Updates: 246,434
Cumulative Timesteps: 2,055,871,954

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59,198.25048
Policy Entropy: 2.49173
Value Function Loss: 0.01701

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.06977
Policy Update Magnitude: 0.33014
Value Function Update Magnitude: 0.36496

Collected Steps per Second: 21,355.38474
Overall Steps per Second: 10,322.50481

Timestep Collection Time: 2.34245
Timestep Consumption Time: 2.50366
PPO Batch Consumption Time: 0.29105
Total Iteration Time: 4.84611

Cumulative Model Updates: 246,440
Cumulative Timesteps: 2,055,921,978

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2055921978...
Checkpoint 2055921978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 80,595.18181
Policy Entropy: 2.51211
Value Function Loss: 0.01631

Mean KL Divergence: 0.00753
SB3 Clip Fraction: 0.06786
Policy Update Magnitude: 0.32358
Value Function Update Magnitude: 0.34131

Collected Steps per Second: 21,119.61564
Overall Steps per Second: 10,289.11949

Timestep Collection Time: 2.36946
Timestep Consumption Time: 2.49413
PPO Batch Consumption Time: 0.29299
Total Iteration Time: 4.86358

Cumulative Model Updates: 246,446
Cumulative Timesteps: 2,055,972,020

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66,998.43224
Policy Entropy: 2.54241
Value Function Loss: 0.01490

Mean KL Divergence: 0.00668
SB3 Clip Fraction: 0.06496
Policy Update Magnitude: 0.31004
Value Function Update Magnitude: 0.31893

Collected Steps per Second: 21,154.55023
Overall Steps per Second: 10,456.64209

Timestep Collection Time: 2.36535
Timestep Consumption Time: 2.41993
PPO Batch Consumption Time: 0.29253
Total Iteration Time: 4.78528

Cumulative Model Updates: 246,452
Cumulative Timesteps: 2,056,022,058

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 2056022058...
Checkpoint 2056022058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 50,568.59243
Policy Entropy: 2.55012
Value Function Loss: 0.01446

Mean KL Divergence: 0.00643
SB3 Clip Fraction: 0.06091
Policy Update Magnitude: 0.30411
Value Function Update Magnitude: 0.31525

Collected Steps per Second: 20,811.44419
Overall Steps per Second: 10,507.96204

Timestep Collection Time: 2.40435
Timestep Consumption Time: 2.35756
PPO Batch Consumption Time: 0.27866
Total Iteration Time: 4.76191

Cumulative Model Updates: 246,458
Cumulative Timesteps: 2,056,072,096

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,596.10717
Policy Entropy: 2.53729
Value Function Loss: 0.01594

Mean KL Divergence: 0.00672
SB3 Clip Fraction: 0.06033
Policy Update Magnitude: 0.31125
Value Function Update Magnitude: 0.28220

Collected Steps per Second: 21,404.41742
Overall Steps per Second: 10,578.73141

Timestep Collection Time: 2.33765
Timestep Consumption Time: 2.39222
PPO Batch Consumption Time: 0.27739
Total Iteration Time: 4.72987

Cumulative Model Updates: 246,464
Cumulative Timesteps: 2,056,122,132

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 2056122132...
Checkpoint 2056122132 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,557.95838
Policy Entropy: 2.54146
Value Function Loss: 0.01534

Mean KL Divergence: 0.00699
SB3 Clip Fraction: 0.06041
Policy Update Magnitude: 0.30686
Value Function Update Magnitude: 0.21705

Collected Steps per Second: 21,554.97229
Overall Steps per Second: 10,558.44950

Timestep Collection Time: 2.32095
Timestep Consumption Time: 2.41725
PPO Batch Consumption Time: 0.27893
Total Iteration Time: 4.73820

Cumulative Model Updates: 246,470
Cumulative Timesteps: 2,056,172,160

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,557.95838
Policy Entropy: 2.54079
Value Function Loss: 0.01402

Mean KL Divergence: 0.00723
SB3 Clip Fraction: 0.06056
Policy Update Magnitude: 0.29787
Value Function Update Magnitude: 0.18850

Collected Steps per Second: 22,078.51326
Overall Steps per Second: 10,480.97799

Timestep Collection Time: 2.26555
Timestep Consumption Time: 2.50690
PPO Batch Consumption Time: 0.29493
Total Iteration Time: 4.77246

Cumulative Model Updates: 246,476
Cumulative Timesteps: 2,056,222,180

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2056222180...
Checkpoint 2056222180 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,878.19400
Policy Entropy: 2.55588
Value Function Loss: 0.01239

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.07369
Policy Update Magnitude: 0.29060
Value Function Update Magnitude: 0.18562

Collected Steps per Second: 21,811.94440
Overall Steps per Second: 10,640.27311

Timestep Collection Time: 2.29232
Timestep Consumption Time: 2.40681
PPO Batch Consumption Time: 0.27847
Total Iteration Time: 4.69913

Cumulative Model Updates: 246,482
Cumulative Timesteps: 2,056,272,180

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90,906.55164
Policy Entropy: 2.53726
Value Function Loss: 0.01464

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.09244
Policy Update Magnitude: 0.28261
Value Function Update Magnitude: 0.19288

Collected Steps per Second: 22,585.76023
Overall Steps per Second: 10,589.21493

Timestep Collection Time: 2.21458
Timestep Consumption Time: 2.50890
PPO Batch Consumption Time: 0.29040
Total Iteration Time: 4.72349

Cumulative Model Updates: 246,488
Cumulative Timesteps: 2,056,322,198

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2056322198...
Checkpoint 2056322198 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84,856.41016
Policy Entropy: 2.55116
Value Function Loss: 0.01593

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.08008
Policy Update Magnitude: 0.28545
Value Function Update Magnitude: 0.24035

Collected Steps per Second: 21,780.55041
Overall Steps per Second: 10,542.03630

Timestep Collection Time: 2.29563
Timestep Consumption Time: 2.44729
PPO Batch Consumption Time: 0.27729
Total Iteration Time: 4.74292

Cumulative Model Updates: 246,494
Cumulative Timesteps: 2,056,372,198

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70,705.43842
Policy Entropy: 2.53665
Value Function Loss: 0.01921

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.08791
Policy Update Magnitude: 0.30035
Value Function Update Magnitude: 0.28613

Collected Steps per Second: 21,987.04649
Overall Steps per Second: 10,486.77163

Timestep Collection Time: 2.27634
Timestep Consumption Time: 2.49634
PPO Batch Consumption Time: 0.29329
Total Iteration Time: 4.77268

Cumulative Model Updates: 246,500
Cumulative Timesteps: 2,056,422,248

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 2056422248...
Checkpoint 2056422248 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 68,563.35921
Policy Entropy: 2.51415
Value Function Loss: 0.01853

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.08339
Policy Update Magnitude: 0.31188
Value Function Update Magnitude: 0.26807

Collected Steps per Second: 21,313.61569
Overall Steps per Second: 10,506.11106

Timestep Collection Time: 2.34733
Timestep Consumption Time: 2.41466
PPO Batch Consumption Time: 0.27864
Total Iteration Time: 4.76199

Cumulative Model Updates: 246,506
Cumulative Timesteps: 2,056,472,278

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62,169.01223
Policy Entropy: 2.50654
Value Function Loss: 0.01650

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.07891
Policy Update Magnitude: 0.30988
Value Function Update Magnitude: 0.27570

Collected Steps per Second: 21,742.29214
Overall Steps per Second: 10,580.68821

Timestep Collection Time: 2.29994
Timestep Consumption Time: 2.42622
PPO Batch Consumption Time: 0.27738
Total Iteration Time: 4.72616

Cumulative Model Updates: 246,512
Cumulative Timesteps: 2,056,522,284

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2056522284...
Checkpoint 2056522284 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 77,252.14730
Policy Entropy: 2.51265
Value Function Loss: 0.01373

Mean KL Divergence: 0.00648
SB3 Clip Fraction: 0.06232
Policy Update Magnitude: 0.29751
Value Function Update Magnitude: 0.27110

Collected Steps per Second: 21,353.91194
Overall Steps per Second: 10,502.60414

Timestep Collection Time: 2.34299
Timestep Consumption Time: 2.42078
PPO Batch Consumption Time: 0.27832
Total Iteration Time: 4.76377

Cumulative Model Updates: 246,518
Cumulative Timesteps: 2,056,572,316

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 141,147.51049
Policy Entropy: 2.54895
Value Function Loss: 0.01295

Mean KL Divergence: 0.00645
SB3 Clip Fraction: 0.06036
Policy Update Magnitude: 0.29436
Value Function Update Magnitude: 0.29176

Collected Steps per Second: 21,915.32645
Overall Steps per Second: 10,509.52365

Timestep Collection Time: 2.28251
Timestep Consumption Time: 2.47717
PPO Batch Consumption Time: 0.28684
Total Iteration Time: 4.75968

Cumulative Model Updates: 246,524
Cumulative Timesteps: 2,056,622,338

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2056622338...
Checkpoint 2056622338 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 108,433.52166
Policy Entropy: 2.54888
Value Function Loss: 0.01713

Mean KL Divergence: 0.00721
SB3 Clip Fraction: 0.06801
Policy Update Magnitude: 0.30755
Value Function Update Magnitude: 0.31158

Collected Steps per Second: 21,218.24363
Overall Steps per Second: 10,579.26488

Timestep Collection Time: 2.35741
Timestep Consumption Time: 2.37071
PPO Batch Consumption Time: 0.27868
Total Iteration Time: 4.72812

Cumulative Model Updates: 246,530
Cumulative Timesteps: 2,056,672,358

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82,979.03832
Policy Entropy: 2.53423
Value Function Loss: 0.01608

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.06873
Policy Update Magnitude: 0.31831
Value Function Update Magnitude: 0.34975

Collected Steps per Second: 21,598.34675
Overall Steps per Second: 10,432.47248

Timestep Collection Time: 2.31583
Timestep Consumption Time: 2.47863
PPO Batch Consumption Time: 0.29618
Total Iteration Time: 4.79445

Cumulative Model Updates: 246,536
Cumulative Timesteps: 2,056,722,376

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2056722376...
Checkpoint 2056722376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 57,140.81912
Policy Entropy: 2.49169
Value Function Loss: 0.01662

Mean KL Divergence: 0.00772
SB3 Clip Fraction: 0.07052
Policy Update Magnitude: 0.31513
Value Function Update Magnitude: 0.33887

Collected Steps per Second: 20,725.87138
Overall Steps per Second: 10,319.65526

Timestep Collection Time: 2.41264
Timestep Consumption Time: 2.43287
PPO Batch Consumption Time: 0.29386
Total Iteration Time: 4.84551

Cumulative Model Updates: 246,542
Cumulative Timesteps: 2,056,772,380

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,806.37177
Policy Entropy: 2.50051
Value Function Loss: 0.01542

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.08051
Policy Update Magnitude: 0.31060
Value Function Update Magnitude: 0.30770

Collected Steps per Second: 21,788.08124
Overall Steps per Second: 10,470.74123

Timestep Collection Time: 2.29676
Timestep Consumption Time: 2.48246
PPO Batch Consumption Time: 0.29294
Total Iteration Time: 4.77922

Cumulative Model Updates: 246,548
Cumulative Timesteps: 2,056,822,422

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 2056822422...
Checkpoint 2056822422 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,779.18668
Policy Entropy: 2.49689
Value Function Loss: 0.01610

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.07155
Policy Update Magnitude: 0.30761
Value Function Update Magnitude: 0.23899

Collected Steps per Second: 21,852.98178
Overall Steps per Second: 10,580.52855

Timestep Collection Time: 2.29031
Timestep Consumption Time: 2.44008
PPO Batch Consumption Time: 0.28502
Total Iteration Time: 4.73039

Cumulative Model Updates: 246,554
Cumulative Timesteps: 2,056,872,472

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49,779.18668
Policy Entropy: 2.51491
Value Function Loss: 0.01470

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.08067
Policy Update Magnitude: 0.30182
Value Function Update Magnitude: 0.23344

Collected Steps per Second: 22,096.47241
Overall Steps per Second: 10,545.62719

Timestep Collection Time: 2.26335
Timestep Consumption Time: 2.47909
PPO Batch Consumption Time: 0.29195
Total Iteration Time: 4.74244

Cumulative Model Updates: 246,560
Cumulative Timesteps: 2,056,922,484

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2056922484...
Checkpoint 2056922484 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 50,577.44728
Policy Entropy: 2.50248
Value Function Loss: 0.01406

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.07144
Policy Update Magnitude: 0.29833
Value Function Update Magnitude: 0.24672

Collected Steps per Second: 21,771.42553
Overall Steps per Second: 10,580.52639

Timestep Collection Time: 2.29797
Timestep Consumption Time: 2.43053
PPO Batch Consumption Time: 0.27728
Total Iteration Time: 4.72850

Cumulative Model Updates: 246,566
Cumulative Timesteps: 2,056,972,514

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60,116.23632
Policy Entropy: 2.50928
Value Function Loss: 0.01333

Mean KL Divergence: 0.00747
SB3 Clip Fraction: 0.07302
Policy Update Magnitude: 0.30017
Value Function Update Magnitude: 0.28323

Collected Steps per Second: 21,648.23871
Overall Steps per Second: 10,428.83280

Timestep Collection Time: 2.31113
Timestep Consumption Time: 2.48633
PPO Batch Consumption Time: 0.28844
Total Iteration Time: 4.79747

Cumulative Model Updates: 246,572
Cumulative Timesteps: 2,057,022,546

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2057022546...
Checkpoint 2057022546 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 108,387.13934
Policy Entropy: 2.50525
Value Function Loss: 0.01520

Mean KL Divergence: 0.00724
SB3 Clip Fraction: 0.06856
Policy Update Magnitude: 0.30756
Value Function Update Magnitude: 0.31017

Collected Steps per Second: 21,082.25266
Overall Steps per Second: 10,251.89789

Timestep Collection Time: 2.37185
Timestep Consumption Time: 2.50568
PPO Batch Consumption Time: 0.29319
Total Iteration Time: 4.87754

Cumulative Model Updates: 246,578
Cumulative Timesteps: 2,057,072,550

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 129,633.53881
Policy Entropy: 2.49622
Value Function Loss: 0.01666

Mean KL Divergence: 0.00737
SB3 Clip Fraction: 0.07006
Policy Update Magnitude: 0.31123
Value Function Update Magnitude: 0.32614

Collected Steps per Second: 21,782.28577
Overall Steps per Second: 10,400.47009

Timestep Collection Time: 2.29590
Timestep Consumption Time: 2.51253
PPO Batch Consumption Time: 0.29323
Total Iteration Time: 4.80844

Cumulative Model Updates: 246,584
Cumulative Timesteps: 2,057,122,560

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2057122560...
Checkpoint 2057122560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 129,633.53881
Policy Entropy: 2.51273
Value Function Loss: 0.01536

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.07004
Policy Update Magnitude: 0.30485
Value Function Update Magnitude: 0.32801

Collected Steps per Second: 21,375.35709
Overall Steps per Second: 10,294.65480

Timestep Collection Time: 2.33998
Timestep Consumption Time: 2.51865
PPO Batch Consumption Time: 0.29229
Total Iteration Time: 4.85864

Cumulative Model Updates: 246,590
Cumulative Timesteps: 2,057,172,578

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84,391.43315
Policy Entropy: 2.51929
Value Function Loss: 0.01351

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.07779
Policy Update Magnitude: 0.29085
Value Function Update Magnitude: 0.29578

Collected Steps per Second: 22,042.25135
Overall Steps per Second: 10,402.35158

Timestep Collection Time: 2.26855
Timestep Consumption Time: 2.53844
PPO Batch Consumption Time: 0.29312
Total Iteration Time: 4.80699

Cumulative Model Updates: 246,596
Cumulative Timesteps: 2,057,222,582

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2057222582...
Checkpoint 2057222582 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86,652.42731
Policy Entropy: 2.54961
Value Function Loss: 0.01200

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.07696
Policy Update Magnitude: 0.27726
Value Function Update Magnitude: 0.25193

Collected Steps per Second: 21,457.90629
Overall Steps per Second: 10,312.19684

Timestep Collection Time: 2.33080
Timestep Consumption Time: 2.51919
PPO Batch Consumption Time: 0.29145
Total Iteration Time: 4.84999

Cumulative Model Updates: 246,602
Cumulative Timesteps: 2,057,272,596

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 104,204.08547
Policy Entropy: 2.53581
Value Function Loss: 0.01527

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.07349
Policy Update Magnitude: 0.29225
Value Function Update Magnitude: 0.24788

Collected Steps per Second: 22,387.12490
Overall Steps per Second: 10,682.31372

Timestep Collection Time: 2.23369
Timestep Consumption Time: 2.44750
PPO Batch Consumption Time: 0.27962
Total Iteration Time: 4.68120

Cumulative Model Updates: 246,608
Cumulative Timesteps: 2,057,322,602

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2057322602...
Checkpoint 2057322602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 128,892.96670
Policy Entropy: 2.53742
Value Function Loss: 0.01552

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.08648
Policy Update Magnitude: 0.30736
Value Function Update Magnitude: 0.29237

Collected Steps per Second: 21,762.67957
Overall Steps per Second: 10,592.87277

Timestep Collection Time: 2.29797
Timestep Consumption Time: 2.42313
PPO Batch Consumption Time: 0.27892
Total Iteration Time: 4.72110

Cumulative Model Updates: 246,614
Cumulative Timesteps: 2,057,372,612

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 120,107.95511
Policy Entropy: 2.52659
Value Function Loss: 0.01518

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.08736
Policy Update Magnitude: 0.30528
Value Function Update Magnitude: 0.31052

Collected Steps per Second: 22,057.02332
Overall Steps per Second: 10,520.53627

Timestep Collection Time: 2.26812
Timestep Consumption Time: 2.48715
PPO Batch Consumption Time: 0.28720
Total Iteration Time: 4.75527

Cumulative Model Updates: 246,620
Cumulative Timesteps: 2,057,422,640

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2057422640...
Checkpoint 2057422640 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 99,637.41924
Policy Entropy: 2.51364
Value Function Loss: 0.01438

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.08871
Policy Update Magnitude: 0.30306
Value Function Update Magnitude: 0.31862

Collected Steps per Second: 21,825.25990
Overall Steps per Second: 10,585.55643

Timestep Collection Time: 2.29102
Timestep Consumption Time: 2.43259
PPO Batch Consumption Time: 0.27970
Total Iteration Time: 4.72361

Cumulative Model Updates: 246,626
Cumulative Timesteps: 2,057,472,642

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 96,213.05488
Policy Entropy: 2.48646
Value Function Loss: 0.01348

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.08010
Policy Update Magnitude: 0.30226
Value Function Update Magnitude: 0.34120

Collected Steps per Second: 21,862.09085
Overall Steps per Second: 10,583.39970

Timestep Collection Time: 2.28789
Timestep Consumption Time: 2.43819
PPO Batch Consumption Time: 0.27782
Total Iteration Time: 4.72608

Cumulative Model Updates: 246,632
Cumulative Timesteps: 2,057,522,660

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2057522660...
Checkpoint 2057522660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 111,822.27342
Policy Entropy: 2.50200
Value Function Loss: 0.01388

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.07716
Policy Update Magnitude: 0.30412
Value Function Update Magnitude: 0.33529

Collected Steps per Second: 21,701.24949
Overall Steps per Second: 10,570.44171

Timestep Collection Time: 2.30401
Timestep Consumption Time: 2.42616
PPO Batch Consumption Time: 0.27898
Total Iteration Time: 4.73017

Cumulative Model Updates: 246,638
Cumulative Timesteps: 2,057,572,660

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 126,180.16819
Policy Entropy: 2.52826
Value Function Loss: 0.01405

Mean KL Divergence: 0.00734
SB3 Clip Fraction: 0.06831
Policy Update Magnitude: 0.29740
Value Function Update Magnitude: 0.31298

Collected Steps per Second: 21,827.28432
Overall Steps per Second: 10,465.43915

Timestep Collection Time: 2.29108
Timestep Consumption Time: 2.48732
PPO Batch Consumption Time: 0.28825
Total Iteration Time: 4.77839

Cumulative Model Updates: 246,644
Cumulative Timesteps: 2,057,622,668

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2057622668...
Checkpoint 2057622668 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 80,094.14937
Policy Entropy: 2.52904
Value Function Loss: 0.01497

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.07496
Policy Update Magnitude: 0.30005
Value Function Update Magnitude: 0.28909

Collected Steps per Second: 21,076.26831
Overall Steps per Second: 10,577.82584

Timestep Collection Time: 2.37338
Timestep Consumption Time: 2.35557
PPO Batch Consumption Time: 0.27842
Total Iteration Time: 4.72895

Cumulative Model Updates: 246,650
Cumulative Timesteps: 2,057,672,690

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48,663.63293
Policy Entropy: 2.51817
Value Function Loss: 0.01592

Mean KL Divergence: 0.00741
SB3 Clip Fraction: 0.06694
Policy Update Magnitude: 0.30155
Value Function Update Magnitude: 0.24770

Collected Steps per Second: 21,044.04713
Overall Steps per Second: 10,565.43230

Timestep Collection Time: 2.37663
Timestep Consumption Time: 2.35710
PPO Batch Consumption Time: 0.27740
Total Iteration Time: 4.73374

Cumulative Model Updates: 246,656
Cumulative Timesteps: 2,057,722,704

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2057722704...
Checkpoint 2057722704 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40,517.05341
Policy Entropy: 2.51700
Value Function Loss: 0.01460

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.07258
Policy Update Magnitude: 0.30076
Value Function Update Magnitude: 0.22641

Collected Steps per Second: 20,879.12184
Overall Steps per Second: 10,484.94329

Timestep Collection Time: 2.39684
Timestep Consumption Time: 2.37610
PPO Batch Consumption Time: 0.27953
Total Iteration Time: 4.77294

Cumulative Model Updates: 246,662
Cumulative Timesteps: 2,057,772,748

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53,543.36497
Policy Entropy: 2.52052
Value Function Loss: 0.01349

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.07474
Policy Update Magnitude: 0.29424
Value Function Update Magnitude: 0.18829

Collected Steps per Second: 21,364.18631
Overall Steps per Second: 10,473.93081

Timestep Collection Time: 2.34046
Timestep Consumption Time: 2.43349
PPO Batch Consumption Time: 0.27911
Total Iteration Time: 4.77395

Cumulative Model Updates: 246,668
Cumulative Timesteps: 2,057,822,750

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2057822750...
Checkpoint 2057822750 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46,524.46238
Policy Entropy: 2.50528
Value Function Loss: 0.01490

Mean KL Divergence: 0.00730
SB3 Clip Fraction: 0.06696
Policy Update Magnitude: 0.30288
Value Function Update Magnitude: 0.21805

Collected Steps per Second: 21,859.29227
Overall Steps per Second: 10,637.80535

Timestep Collection Time: 2.28836
Timestep Consumption Time: 2.41392
PPO Batch Consumption Time: 0.27904
Total Iteration Time: 4.70229

Cumulative Model Updates: 246,674
Cumulative Timesteps: 2,057,872,772

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,790.01057
Policy Entropy: 2.49405
Value Function Loss: 0.01686

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.07324
Policy Update Magnitude: 0.31493
Value Function Update Magnitude: 0.25130

Collected Steps per Second: 22,200.03304
Overall Steps per Second: 10,529.08993

Timestep Collection Time: 2.25225
Timestep Consumption Time: 2.49650
PPO Batch Consumption Time: 0.29272
Total Iteration Time: 4.74875

Cumulative Model Updates: 246,680
Cumulative Timesteps: 2,057,922,772

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2057922772...
Checkpoint 2057922772 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,494.89397
Policy Entropy: 2.48463
Value Function Loss: 0.01552

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.07575
Policy Update Magnitude: 0.30730
Value Function Update Magnitude: 0.25863

Collected Steps per Second: 22,167.93246
Overall Steps per Second: 10,685.27603

Timestep Collection Time: 2.25551
Timestep Consumption Time: 2.42383
PPO Batch Consumption Time: 0.27785
Total Iteration Time: 4.67934

Cumulative Model Updates: 246,686
Cumulative Timesteps: 2,057,972,772

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77,909.57874
Policy Entropy: 2.50652
Value Function Loss: 0.01522

Mean KL Divergence: 0.00764
SB3 Clip Fraction: 0.07099
Policy Update Magnitude: 0.30092
Value Function Update Magnitude: 0.29468

Collected Steps per Second: 22,181.37070
Overall Steps per Second: 10,528.56349

Timestep Collection Time: 2.25423
Timestep Consumption Time: 2.49494
PPO Batch Consumption Time: 0.29238
Total Iteration Time: 4.74918

Cumulative Model Updates: 246,692
Cumulative Timesteps: 2,058,022,774

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2058022774...
Checkpoint 2058022774 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 82,908.27268
Policy Entropy: 2.50541
Value Function Loss: 0.01414

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.07553
Policy Update Magnitude: 0.29803
Value Function Update Magnitude: 0.28979

Collected Steps per Second: 21,660.46356
Overall Steps per Second: 10,562.14696

Timestep Collection Time: 2.31029
Timestep Consumption Time: 2.42757
PPO Batch Consumption Time: 0.27717
Total Iteration Time: 4.73786

Cumulative Model Updates: 246,698
Cumulative Timesteps: 2,058,072,816

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88,562.94298
Policy Entropy: 2.48453
Value Function Loss: 0.01501

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.07683
Policy Update Magnitude: 0.30790
Value Function Update Magnitude: 0.31517

Collected Steps per Second: 21,675.35915
Overall Steps per Second: 10,403.56144

Timestep Collection Time: 2.30787
Timestep Consumption Time: 2.50048
PPO Batch Consumption Time: 0.29106
Total Iteration Time: 4.80835

Cumulative Model Updates: 246,704
Cumulative Timesteps: 2,058,122,840

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2058122840...
Checkpoint 2058122840 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 81,009.59818
Policy Entropy: 2.48753
Value Function Loss: 0.01550

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.07521
Policy Update Magnitude: 0.30997
Value Function Update Magnitude: 0.29106

Collected Steps per Second: 21,528.92546
Overall Steps per Second: 10,553.87578

Timestep Collection Time: 2.32413
Timestep Consumption Time: 2.41688
PPO Batch Consumption Time: 0.27926
Total Iteration Time: 4.74101

Cumulative Model Updates: 246,710
Cumulative Timesteps: 2,058,172,876

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56,750.64596
Policy Entropy: 2.49529
Value Function Loss: 0.01527

Mean KL Divergence: 0.00763
SB3 Clip Fraction: 0.06609
Policy Update Magnitude: 0.31191
Value Function Update Magnitude: 0.30029

Collected Steps per Second: 21,349.18974
Overall Steps per Second: 10,481.13910

Timestep Collection Time: 2.34276
Timestep Consumption Time: 2.42924
PPO Batch Consumption Time: 0.27836
Total Iteration Time: 4.77200

Cumulative Model Updates: 246,716
Cumulative Timesteps: 2,058,222,892

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2058222892...
Checkpoint 2058222892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46,847.00679
Policy Entropy: 2.50422
Value Function Loss: 0.01461

Mean KL Divergence: 0.00614
SB3 Clip Fraction: 0.06013
Policy Update Magnitude: 0.30823
Value Function Update Magnitude: 0.29618

Collected Steps per Second: 19,657.53121
Overall Steps per Second: 9,856.12618

Timestep Collection Time: 2.54355
Timestep Consumption Time: 2.52943
PPO Batch Consumption Time: 0.29418
Total Iteration Time: 5.07299

Cumulative Model Updates: 246,722
Cumulative Timesteps: 2,058,272,892

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59,270.62896
Policy Entropy: 2.48531
Value Function Loss: 0.01473

Mean KL Divergence: 0.00644
SB3 Clip Fraction: 0.06243
Policy Update Magnitude: 0.30857
Value Function Update Magnitude: 0.26283

Collected Steps per Second: 20,877.08299
Overall Steps per Second: 10,437.32152

Timestep Collection Time: 2.39507
Timestep Consumption Time: 2.39563
PPO Batch Consumption Time: 0.27884
Total Iteration Time: 4.79069

Cumulative Model Updates: 246,728
Cumulative Timesteps: 2,058,322,894

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2058322894...
Checkpoint 2058322894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43,831.68499
Policy Entropy: 2.47241
Value Function Loss: 0.01690

Mean KL Divergence: 0.00689
SB3 Clip Fraction: 0.06484
Policy Update Magnitude: 0.32302
Value Function Update Magnitude: 0.25343

Collected Steps per Second: 21,483.68931
Overall Steps per Second: 10,639.02469

Timestep Collection Time: 2.32744
Timestep Consumption Time: 2.37243
PPO Batch Consumption Time: 0.27912
Total Iteration Time: 4.69987

Cumulative Model Updates: 246,734
Cumulative Timesteps: 2,058,372,896

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46,379.03204
Policy Entropy: 2.49484
Value Function Loss: 0.01805

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.07340
Policy Update Magnitude: 0.32906
Value Function Update Magnitude: 0.30348

Collected Steps per Second: 21,411.65185
Overall Steps per Second: 10,510.42005

Timestep Collection Time: 2.33592
Timestep Consumption Time: 2.42278
PPO Batch Consumption Time: 0.29243
Total Iteration Time: 4.75871

Cumulative Model Updates: 246,740
Cumulative Timesteps: 2,058,422,912

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2058422912...
Checkpoint 2058422912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 110,408.89859
Policy Entropy: 2.55724
Value Function Loss: 0.01593

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.08297
Policy Update Magnitude: 0.31580
Value Function Update Magnitude: 0.31232

Collected Steps per Second: 21,371.03838
Overall Steps per Second: 10,533.34733

Timestep Collection Time: 2.34149
Timestep Consumption Time: 2.40914
PPO Batch Consumption Time: 0.27874
Total Iteration Time: 4.75063

Cumulative Model Updates: 246,746
Cumulative Timesteps: 2,058,472,952

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 107,693.86191
Policy Entropy: 2.56842
Value Function Loss: 0.01473

Mean KL Divergence: 0.00740
SB3 Clip Fraction: 0.06904
Policy Update Magnitude: 0.30070
Value Function Update Magnitude: 0.28228

Collected Steps per Second: 22,119.65234
Overall Steps per Second: 10,558.64493

Timestep Collection Time: 2.26170
Timestep Consumption Time: 2.47641
PPO Batch Consumption Time: 0.29361
Total Iteration Time: 4.73811

Cumulative Model Updates: 246,752
Cumulative Timesteps: 2,058,522,980

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2058522980...
Checkpoint 2058522980 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 71,918.28873
Policy Entropy: 2.54613
Value Function Loss: 0.01699

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.07232
Policy Update Magnitude: 0.30593
Value Function Update Magnitude: 0.29801

Collected Steps per Second: 21,881.34807
Overall Steps per Second: 10,587.18612

Timestep Collection Time: 2.28642
Timestep Consumption Time: 2.43910
PPO Batch Consumption Time: 0.28455
Total Iteration Time: 4.72552

Cumulative Model Updates: 246,758
Cumulative Timesteps: 2,058,573,010

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77,665.07812
Policy Entropy: 2.49694
Value Function Loss: 0.01744

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.07273
Policy Update Magnitude: 0.31829
Value Function Update Magnitude: 0.31268

Collected Steps per Second: 21,992.87422
Overall Steps per Second: 10,462.57520

Timestep Collection Time: 2.27383
Timestep Consumption Time: 2.50588
PPO Batch Consumption Time: 0.29240
Total Iteration Time: 4.77970

Cumulative Model Updates: 246,764
Cumulative Timesteps: 2,058,623,018

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2058623018...
Checkpoint 2058623018 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55,288.39464
Policy Entropy: 2.50832
Value Function Loss: 0.01608

Mean KL Divergence: 0.00750
SB3 Clip Fraction: 0.07021
Policy Update Magnitude: 0.31054
Value Function Update Magnitude: 0.35585

Collected Steps per Second: 21,523.86634
Overall Steps per Second: 10,540.55095

Timestep Collection Time: 2.32523
Timestep Consumption Time: 2.42291
PPO Batch Consumption Time: 0.27965
Total Iteration Time: 4.74814

Cumulative Model Updates: 246,770
Cumulative Timesteps: 2,058,673,066

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84,534.59263
Policy Entropy: 2.50544
Value Function Loss: 0.01678

Mean KL Divergence: 0.00714
SB3 Clip Fraction: 0.06740
Policy Update Magnitude: 0.30830
Value Function Update Magnitude: 0.35419

Collected Steps per Second: 21,132.17792
Overall Steps per Second: 10,272.67900

Timestep Collection Time: 2.36615
Timestep Consumption Time: 2.50132
PPO Batch Consumption Time: 0.29150
Total Iteration Time: 4.86747

Cumulative Model Updates: 246,776
Cumulative Timesteps: 2,058,723,068

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2058723068...
Checkpoint 2058723068 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 66,496.37894
Policy Entropy: 2.52374
Value Function Loss: 0.01661

Mean KL Divergence: 0.00708
SB3 Clip Fraction: 0.06733
Policy Update Magnitude: 0.32164
Value Function Update Magnitude: 0.33694

Collected Steps per Second: 21,707.95017
Overall Steps per Second: 10,488.22831

Timestep Collection Time: 2.30413
Timestep Consumption Time: 2.46483
PPO Batch Consumption Time: 0.28533
Total Iteration Time: 4.76897

Cumulative Model Updates: 246,782
Cumulative Timesteps: 2,058,773,086

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53,392.51439
Policy Entropy: 2.51816
Value Function Loss: 0.01757

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.08073
Policy Update Magnitude: 0.31691
Value Function Update Magnitude: 0.33789

Collected Steps per Second: 21,583.54763
Overall Steps per Second: 10,469.28703

Timestep Collection Time: 2.31788
Timestep Consumption Time: 2.46067
PPO Batch Consumption Time: 0.28337
Total Iteration Time: 4.77855

Cumulative Model Updates: 246,788
Cumulative Timesteps: 2,058,823,114

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2058823114...
Checkpoint 2058823114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 61,118.56146
Policy Entropy: 2.51290
Value Function Loss: 0.01777

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.06704
Policy Update Magnitude: 0.31762
Value Function Update Magnitude: 0.34392

Collected Steps per Second: 21,751.47125
Overall Steps per Second: 10,563.21397

Timestep Collection Time: 2.30007
Timestep Consumption Time: 2.43617
PPO Batch Consumption Time: 0.27879
Total Iteration Time: 4.73625

Cumulative Model Updates: 246,794
Cumulative Timesteps: 2,058,873,144

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51,073.39434
Policy Entropy: 2.50725
Value Function Loss: 0.01588

Mean KL Divergence: 0.00689
SB3 Clip Fraction: 0.06579
Policy Update Magnitude: 0.31227
Value Function Update Magnitude: 0.34097

Collected Steps per Second: 22,195.68763
Overall Steps per Second: 10,454.86939

Timestep Collection Time: 2.25341
Timestep Consumption Time: 2.53058
PPO Batch Consumption Time: 0.28857
Total Iteration Time: 4.78399

Cumulative Model Updates: 246,800
Cumulative Timesteps: 2,058,923,160

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2058923160...
Checkpoint 2058923160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 57,421.08382
Policy Entropy: 2.50522
Value Function Loss: 0.01555

Mean KL Divergence: 0.00728
SB3 Clip Fraction: 0.07063
Policy Update Magnitude: 0.30553
Value Function Update Magnitude: 0.31682

Collected Steps per Second: 21,951.57354
Overall Steps per Second: 10,597.42305

Timestep Collection Time: 2.27829
Timestep Consumption Time: 2.44097
PPO Batch Consumption Time: 0.27965
Total Iteration Time: 4.71926

Cumulative Model Updates: 246,806
Cumulative Timesteps: 2,058,973,172

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92,774.55599
Policy Entropy: 2.51472
Value Function Loss: 0.01532

Mean KL Divergence: 0.00650
SB3 Clip Fraction: 0.06103
Policy Update Magnitude: 0.30308
Value Function Update Magnitude: 0.32798

Collected Steps per Second: 21,908.06654
Overall Steps per Second: 10,528.86308

Timestep Collection Time: 2.28309
Timestep Consumption Time: 2.46747
PPO Batch Consumption Time: 0.28550
Total Iteration Time: 4.75056

Cumulative Model Updates: 246,812
Cumulative Timesteps: 2,059,023,190

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2059023190...
Checkpoint 2059023190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 77,367.20000
Policy Entropy: 2.52327
Value Function Loss: 0.01533

Mean KL Divergence: 0.00643
SB3 Clip Fraction: 0.05892
Policy Update Magnitude: 0.30380
Value Function Update Magnitude: 0.35161

Collected Steps per Second: 20,888.78852
Overall Steps per Second: 10,525.10469

Timestep Collection Time: 2.39506
Timestep Consumption Time: 2.35833
PPO Batch Consumption Time: 0.27945
Total Iteration Time: 4.75340

Cumulative Model Updates: 246,818
Cumulative Timesteps: 2,059,073,220

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 104,841.55722
Policy Entropy: 2.54238
Value Function Loss: 0.01507

Mean KL Divergence: 0.00665
SB3 Clip Fraction: 0.06292
Policy Update Magnitude: 0.29997
Value Function Update Magnitude: 0.34740

Collected Steps per Second: 21,604.75289
Overall Steps per Second: 10,566.93126

Timestep Collection Time: 2.31588
Timestep Consumption Time: 2.41908
PPO Batch Consumption Time: 0.28887
Total Iteration Time: 4.73496

Cumulative Model Updates: 246,824
Cumulative Timesteps: 2,059,123,254

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 2059123254...
Checkpoint 2059123254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 99,661.27829
Policy Entropy: 2.54297
Value Function Loss: 0.01331

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.07900
Policy Update Magnitude: 0.29328
Value Function Update Magnitude: 0.34171

Collected Steps per Second: 21,221.28625
Overall Steps per Second: 10,600.95703

Timestep Collection Time: 2.35810
Timestep Consumption Time: 2.36241
PPO Batch Consumption Time: 0.27990
Total Iteration Time: 4.72052

Cumulative Model Updates: 246,830
Cumulative Timesteps: 2,059,173,296

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77,346.80502
Policy Entropy: 2.52964
Value Function Loss: 0.01372

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.07493
Policy Update Magnitude: 0.28576
Value Function Update Magnitude: 0.30791

Collected Steps per Second: 21,265.00252
Overall Steps per Second: 10,525.20539

Timestep Collection Time: 2.35354
Timestep Consumption Time: 2.40152
PPO Batch Consumption Time: 0.27876
Total Iteration Time: 4.75506

Cumulative Model Updates: 246,836
Cumulative Timesteps: 2,059,223,344

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 2059223344...
Checkpoint 2059223344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 62,475.63900
Policy Entropy: 2.51295
Value Function Loss: 0.01453

Mean KL Divergence: 0.01139
SB3 Clip Fraction: 0.09350
Policy Update Magnitude: 0.29363
Value Function Update Magnitude: 0.31138

Collected Steps per Second: 21,239.22705
Overall Steps per Second: 10,357.29931

Timestep Collection Time: 2.35668
Timestep Consumption Time: 2.47605
PPO Batch Consumption Time: 0.29198
Total Iteration Time: 4.83273

Cumulative Model Updates: 246,842
Cumulative Timesteps: 2,059,273,398

Timesteps Collected: 50,054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65,838.50828
Policy Entropy: 2.50734
Value Function Loss: 0.01566

Mean KL Divergence: 0.01612
SB3 Clip Fraction: 0.12296
Policy Update Magnitude: 0.29988
Value Function Update Magnitude: 0.36872

Collected Steps per Second: 21,734.81646
Overall Steps per Second: 10,478.77768

Timestep Collection Time: 2.30092
Timestep Consumption Time: 2.47159
PPO Batch Consumption Time: 0.28960
Total Iteration Time: 4.77250

Cumulative Model Updates: 246,848
Cumulative Timesteps: 2,059,323,408

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2059323408...
Checkpoint 2059323408 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47,647.06702
Policy Entropy: 2.49796
Value Function Loss: 0.01654

Mean KL Divergence: 0.01240
SB3 Clip Fraction: 0.10297
Policy Update Magnitude: 0.31354
Value Function Update Magnitude: 0.40299

Collected Steps per Second: 21,255.84514
Overall Steps per Second: 10,429.86933

Timestep Collection Time: 2.35276
Timestep Consumption Time: 2.44212
PPO Batch Consumption Time: 0.27925
Total Iteration Time: 4.79488

Cumulative Model Updates: 246,854
Cumulative Timesteps: 2,059,373,418

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54,962.68642
Policy Entropy: 2.48222
Value Function Loss: 0.01721

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.08955
Policy Update Magnitude: 0.32445
Value Function Update Magnitude: 0.42712

Collected Steps per Second: 22,091.04236
Overall Steps per Second: 10,472.48184

Timestep Collection Time: 2.26354
Timestep Consumption Time: 2.51126
PPO Batch Consumption Time: 0.28595
Total Iteration Time: 4.77480

Cumulative Model Updates: 246,860
Cumulative Timesteps: 2,059,423,422

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2059423422...
Checkpoint 2059423422 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 53,830.89658
Policy Entropy: 2.48000
Value Function Loss: 0.01479

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.07370
Policy Update Magnitude: 0.32648
Value Function Update Magnitude: 0.41084

Collected Steps per Second: 21,745.71743
Overall Steps per Second: 10,557.11501

Timestep Collection Time: 2.30032
Timestep Consumption Time: 2.43791
PPO Batch Consumption Time: 0.27864
Total Iteration Time: 4.73823

Cumulative Model Updates: 246,866
Cumulative Timesteps: 2,059,473,444

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52,560.02129
Policy Entropy: 2.47412
Value Function Loss: 0.01418

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.07510
Policy Update Magnitude: 0.31681
Value Function Update Magnitude: 0.37042

Collected Steps per Second: 22,059.45841
Overall Steps per Second: 10,494.08944

Timestep Collection Time: 2.26769
Timestep Consumption Time: 2.49918
PPO Batch Consumption Time: 0.28889
Total Iteration Time: 4.76687

Cumulative Model Updates: 246,872
Cumulative Timesteps: 2,059,523,468

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2059523468...
Checkpoint 2059523468 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,449.94646
Policy Entropy: 2.49634
Value Function Loss: 0.01298

Mean KL Divergence: 0.00729
SB3 Clip Fraction: 0.06739
Policy Update Magnitude: 0.30593
Value Function Update Magnitude: 0.32537

Collected Steps per Second: 21,850.60137
Overall Steps per Second: 10,600.17253

Timestep Collection Time: 2.28964
Timestep Consumption Time: 2.43010
PPO Batch Consumption Time: 0.27881
Total Iteration Time: 4.71973

Cumulative Model Updates: 246,878
Cumulative Timesteps: 2,059,573,498

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58,206.98307
Policy Entropy: 2.48272
Value Function Loss: 0.01397

Mean KL Divergence: 0.00731
SB3 Clip Fraction: 0.06814
Policy Update Magnitude: 0.30492
Value Function Update Magnitude: 0.31983

Collected Steps per Second: 22,344.82536
Overall Steps per Second: 10,534.00839

Timestep Collection Time: 2.23846
Timestep Consumption Time: 2.50978
PPO Batch Consumption Time: 0.29265
Total Iteration Time: 4.74824

Cumulative Model Updates: 246,884
Cumulative Timesteps: 2,059,623,516

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2059623516...
Checkpoint 2059623516 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89,935.74547
Policy Entropy: 2.48211
Value Function Loss: 0.01714

Mean KL Divergence: 0.00689
SB3 Clip Fraction: 0.06689
Policy Update Magnitude: 0.32463
Value Function Update Magnitude: 0.31965

Collected Steps per Second: 21,671.00124
Overall Steps per Second: 10,580.81513

Timestep Collection Time: 2.30834
Timestep Consumption Time: 2.41946
PPO Batch Consumption Time: 0.27850
Total Iteration Time: 4.72780

Cumulative Model Updates: 246,890
Cumulative Timesteps: 2,059,673,540

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75,616.79289
Policy Entropy: 2.49729
Value Function Loss: 0.01799

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.07307
Policy Update Magnitude: 0.33020
Value Function Update Magnitude: 0.33066

Collected Steps per Second: 21,890.05967
Overall Steps per Second: 10,566.89022

Timestep Collection Time: 2.28597
Timestep Consumption Time: 2.44958
PPO Batch Consumption Time: 0.27762
Total Iteration Time: 4.73555

Cumulative Model Updates: 246,896
Cumulative Timesteps: 2,059,723,580

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 2059723580...
Checkpoint 2059723580 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 52,232.11614
Policy Entropy: 2.51864
Value Function Loss: 0.01781

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.07299
Policy Update Magnitude: 0.31824
Value Function Update Magnitude: 0.31537

Collected Steps per Second: 21,339.16557
Overall Steps per Second: 10,503.31298

Timestep Collection Time: 2.34339
Timestep Consumption Time: 2.41758
PPO Batch Consumption Time: 0.27859
Total Iteration Time: 4.76097

Cumulative Model Updates: 246,902
Cumulative Timesteps: 2,059,773,586

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46,226.26129
Policy Entropy: 2.53451
Value Function Loss: 0.01452

Mean KL Divergence: 0.00635
SB3 Clip Fraction: 0.06017
Policy Update Magnitude: 0.30327
Value Function Update Magnitude: 0.28055

Collected Steps per Second: 21,697.68574
Overall Steps per Second: 10,592.91827

Timestep Collection Time: 2.30449
Timestep Consumption Time: 2.41584
PPO Batch Consumption Time: 0.27716
Total Iteration Time: 4.72032

Cumulative Model Updates: 246,908
Cumulative Timesteps: 2,059,823,588

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2059823588...
Checkpoint 2059823588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48,707.43548
Policy Entropy: 2.53081
Value Function Loss: 0.01487

Mean KL Divergence: 0.00728
SB3 Clip Fraction: 0.07262
Policy Update Magnitude: 0.29218
Value Function Update Magnitude: 0.25129

Collected Steps per Second: 21,542.86089
Overall Steps per Second: 10,511.51685

Timestep Collection Time: 2.32216
Timestep Consumption Time: 2.43700
PPO Batch Consumption Time: 0.27832
Total Iteration Time: 4.75916

Cumulative Model Updates: 246,914
Cumulative Timesteps: 2,059,873,614

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49,541.89412
Policy Entropy: 2.54209
Value Function Loss: 0.01459

Mean KL Divergence: 0.00708
SB3 Clip Fraction: 0.07036
Policy Update Magnitude: 0.29258
Value Function Update Magnitude: 0.27272

Collected Steps per Second: 22,195.09853
Overall Steps per Second: 10,482.00520

Timestep Collection Time: 2.25338
Timestep Consumption Time: 2.51803
PPO Batch Consumption Time: 0.28979
Total Iteration Time: 4.77142

Cumulative Model Updates: 246,920
Cumulative Timesteps: 2,059,923,628

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2059923628...
Checkpoint 2059923628 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,212.84775
Policy Entropy: 2.54808
Value Function Loss: 0.01573

Mean KL Divergence: 0.00721
SB3 Clip Fraction: 0.06794
Policy Update Magnitude: 0.29655
Value Function Update Magnitude: 0.30575

Collected Steps per Second: 22,082.45870
Overall Steps per Second: 10,630.67667

Timestep Collection Time: 2.26460
Timestep Consumption Time: 2.43952
PPO Batch Consumption Time: 0.27954
Total Iteration Time: 4.70412

Cumulative Model Updates: 246,926
Cumulative Timesteps: 2,059,973,636

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61,109.91115
Policy Entropy: 2.53467
Value Function Loss: 0.01708

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.07888
Policy Update Magnitude: 0.30607
Value Function Update Magnitude: 0.33953

Collected Steps per Second: 21,616.10841
Overall Steps per Second: 10,536.92600

Timestep Collection Time: 2.31346
Timestep Consumption Time: 2.43252
PPO Batch Consumption Time: 0.29422
Total Iteration Time: 4.74598

Cumulative Model Updates: 246,932
Cumulative Timesteps: 2,060,023,644

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2060023644...
Checkpoint 2060023644 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48,884.06480
Policy Entropy: 2.53069
Value Function Loss: 0.01739

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.07911
Policy Update Magnitude: 0.30600
Value Function Update Magnitude: 0.34630

Collected Steps per Second: 21,095.96797
Overall Steps per Second: 10,565.15913

Timestep Collection Time: 2.37097
Timestep Consumption Time: 2.36327
PPO Batch Consumption Time: 0.27898
Total Iteration Time: 4.73424

Cumulative Model Updates: 246,938
Cumulative Timesteps: 2,060,073,662

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,375.81989
Policy Entropy: 2.52532
Value Function Loss: 0.01739

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.07494
Policy Update Magnitude: 0.31040
Value Function Update Magnitude: 0.35914

Collected Steps per Second: 21,692.40487
Overall Steps per Second: 10,531.25589

Timestep Collection Time: 2.30560
Timestep Consumption Time: 2.44350
PPO Batch Consumption Time: 0.29415
Total Iteration Time: 4.74910

Cumulative Model Updates: 246,944
Cumulative Timesteps: 2,060,123,676

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2060123676...
Checkpoint 2060123676 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 53,406.89127
Policy Entropy: 2.52016
Value Function Loss: 0.01597

Mean KL Divergence: 0.00732
SB3 Clip Fraction: 0.06811
Policy Update Magnitude: 0.31578
Value Function Update Magnitude: 0.35804

Collected Steps per Second: 20,590.82593
Overall Steps per Second: 10,158.02443

Timestep Collection Time: 2.42865
Timestep Consumption Time: 2.49435
PPO Batch Consumption Time: 0.29261
Total Iteration Time: 4.92300

Cumulative Model Updates: 246,950
Cumulative Timesteps: 2,060,173,684

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,569.68316
Policy Entropy: 2.50215
Value Function Loss: 0.01428

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.07306
Policy Update Magnitude: 0.30657
Value Function Update Magnitude: 0.35571

Collected Steps per Second: 21,634.69814
Overall Steps per Second: 10,460.51309

Timestep Collection Time: 2.31221
Timestep Consumption Time: 2.46996
PPO Batch Consumption Time: 0.28839
Total Iteration Time: 4.78217

Cumulative Model Updates: 246,956
Cumulative Timesteps: 2,060,223,708

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2060223708...
Checkpoint 2060223708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,248.79612
Policy Entropy: 2.47611
Value Function Loss: 0.01414

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.07573
Policy Update Magnitude: 0.30423
Value Function Update Magnitude: 0.34664

Collected Steps per Second: 21,220.80718
Overall Steps per Second: 10,371.85651

Timestep Collection Time: 2.35769
Timestep Consumption Time: 2.46614
PPO Batch Consumption Time: 0.29060
Total Iteration Time: 4.82382

Cumulative Model Updates: 246,962
Cumulative Timesteps: 2,060,273,740

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79,347.18771
Policy Entropy: 2.45661
Value Function Loss: 0.01670

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.07330
Policy Update Magnitude: 0.31845
Value Function Update Magnitude: 0.34714

Collected Steps per Second: 21,797.29432
Overall Steps per Second: 10,632.81267

Timestep Collection Time: 2.29423
Timestep Consumption Time: 2.40895
PPO Batch Consumption Time: 0.27870
Total Iteration Time: 4.70318

Cumulative Model Updates: 246,968
Cumulative Timesteps: 2,060,323,748

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2060323748...
Checkpoint 2060323748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 82,345.59977
Policy Entropy: 2.46367
Value Function Loss: 0.01874

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.07731
Policy Update Magnitude: 0.33291
Value Function Update Magnitude: 0.36688

Collected Steps per Second: 21,484.21308
Overall Steps per Second: 10,295.09370

Timestep Collection Time: 2.32804
Timestep Consumption Time: 2.53020
PPO Batch Consumption Time: 0.29302
Total Iteration Time: 4.85824

Cumulative Model Updates: 246,974
Cumulative Timesteps: 2,060,373,764

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55,421.10962
Policy Entropy: 2.49297
Value Function Loss: 0.01954

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.07368
Policy Update Magnitude: 0.33251
Value Function Update Magnitude: 0.38711

Collected Steps per Second: 22,370.65028
Overall Steps per Second: 10,464.90957

Timestep Collection Time: 2.23597
Timestep Consumption Time: 2.54382
PPO Batch Consumption Time: 0.29345
Total Iteration Time: 4.77978

Cumulative Model Updates: 246,980
Cumulative Timesteps: 2,060,423,784

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2060423784...
Checkpoint 2060423784 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 77,936.95073
Policy Entropy: 2.50438
Value Function Loss: 0.01615

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.08683
Policy Update Magnitude: 0.31470
Value Function Update Magnitude: 0.37342

Collected Steps per Second: 21,833.90297
Overall Steps per Second: 10,556.87327

Timestep Collection Time: 2.29157
Timestep Consumption Time: 2.44790
PPO Batch Consumption Time: 0.27949
Total Iteration Time: 4.73947

Cumulative Model Updates: 246,986
Cumulative Timesteps: 2,060,473,818

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77,936.95073
Policy Entropy: 2.50989
Value Function Loss: 0.01324

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.07616
Policy Update Magnitude: 0.29986
Value Function Update Magnitude: 0.32193

Collected Steps per Second: 22,024.21448
Overall Steps per Second: 10,471.86497

Timestep Collection Time: 2.27095
Timestep Consumption Time: 2.50527
PPO Batch Consumption Time: 0.28883
Total Iteration Time: 4.77623

Cumulative Model Updates: 246,992
Cumulative Timesteps: 2,060,523,834

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2060523834...
Checkpoint 2060523834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 53,031.81889
Policy Entropy: 2.50679
Value Function Loss: 0.01414

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.06778
Policy Update Magnitude: 0.28830
Value Function Update Magnitude: 0.27574

Collected Steps per Second: 21,747.41587
Overall Steps per Second: 10,564.28543

Timestep Collection Time: 2.29922
Timestep Consumption Time: 2.43390
PPO Batch Consumption Time: 0.27927
Total Iteration Time: 4.73312

Cumulative Model Updates: 246,998
Cumulative Timesteps: 2,060,573,836

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57,257.39086
Policy Entropy: 2.50054
Value Function Loss: 0.01786

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.07260
Policy Update Magnitude: 0.30862
Value Function Update Magnitude: 0.28275

Collected Steps per Second: 21,970.81804
Overall Steps per Second: 10,627.88777

Timestep Collection Time: 2.27684
Timestep Consumption Time: 2.43002
PPO Batch Consumption Time: 0.27774
Total Iteration Time: 4.70686

Cumulative Model Updates: 247,004
Cumulative Timesteps: 2,060,623,860

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2060623860...
Checkpoint 2060623860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 64,913.30788
Policy Entropy: 2.48779
Value Function Loss: 0.01834

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.09001
Policy Update Magnitude: 0.32065
Value Function Update Magnitude: 0.33386

Collected Steps per Second: 21,733.00012
Overall Steps per Second: 10,602.22819

Timestep Collection Time: 2.30111
Timestep Consumption Time: 2.41582
PPO Batch Consumption Time: 0.27751
Total Iteration Time: 4.71693

Cumulative Model Updates: 247,010
Cumulative Timesteps: 2,060,673,870

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54,002.11952
Policy Entropy: 2.49067
Value Function Loss: 0.01620

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.08206
Policy Update Magnitude: 0.31630
Value Function Update Magnitude: 0.31651

Collected Steps per Second: 21,678.39826
Overall Steps per Second: 10,423.39114

Timestep Collection Time: 2.30746
Timestep Consumption Time: 2.49156
PPO Batch Consumption Time: 0.28898
Total Iteration Time: 4.79901

Cumulative Model Updates: 247,016
Cumulative Timesteps: 2,060,723,892

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2060723892...
Checkpoint 2060723892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 97,428.98660
Policy Entropy: 2.49775
Value Function Loss: 0.01327

Mean KL Divergence: 0.00736
SB3 Clip Fraction: 0.07230
Policy Update Magnitude: 0.29958
Value Function Update Magnitude: 0.31495

Collected Steps per Second: 21,479.54058
Overall Steps per Second: 10,361.92072

Timestep Collection Time: 2.32836
Timestep Consumption Time: 2.49816
PPO Batch Consumption Time: 0.29014
Total Iteration Time: 4.82652

Cumulative Model Updates: 247,022
Cumulative Timesteps: 2,060,773,904

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97,428.98660
Policy Entropy: 2.52457
Value Function Loss: 0.01144

Mean KL Divergence: 0.00689
SB3 Clip Fraction: 0.06853
Policy Update Magnitude: 0.29118
Value Function Update Magnitude: 0.27662

Collected Steps per Second: 21,787.35319
Overall Steps per Second: 10,438.62665

Timestep Collection Time: 2.29555
Timestep Consumption Time: 2.49569
PPO Batch Consumption Time: 0.29081
Total Iteration Time: 4.79124

Cumulative Model Updates: 247,028
Cumulative Timesteps: 2,060,823,918

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2060823918...
Checkpoint 2060823918 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89,548.83236
Policy Entropy: 2.52550
Value Function Loss: 0.01286

Mean KL Divergence: 0.00701
SB3 Clip Fraction: 0.06811
Policy Update Magnitude: 0.28752
Value Function Update Magnitude: 0.23100

Collected Steps per Second: 21,546.07397
Overall Steps per Second: 10,507.21093

Timestep Collection Time: 2.32256
Timestep Consumption Time: 2.44008
PPO Batch Consumption Time: 0.27844
Total Iteration Time: 4.76263

Cumulative Model Updates: 247,034
Cumulative Timesteps: 2,060,873,960

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83,116.80492
Policy Entropy: 2.51677
Value Function Loss: 0.01397

Mean KL Divergence: 0.00712
SB3 Clip Fraction: 0.06807
Policy Update Magnitude: 0.28847
Value Function Update Magnitude: 0.25428

Collected Steps per Second: 21,887.22284
Overall Steps per Second: 10,450.16787

Timestep Collection Time: 2.28581
Timestep Consumption Time: 2.50167
PPO Batch Consumption Time: 0.28844
Total Iteration Time: 4.78748

Cumulative Model Updates: 247,040
Cumulative Timesteps: 2,060,923,990

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2060923990...
Checkpoint 2060923990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 67,578.21536
Policy Entropy: 2.52194
Value Function Loss: 0.01514

Mean KL Divergence: 0.00706
SB3 Clip Fraction: 0.06892
Policy Update Magnitude: 0.29698
Value Function Update Magnitude: 0.26010

Collected Steps per Second: 22,165.67432
Overall Steps per Second: 10,622.55077

Timestep Collection Time: 2.25610
Timestep Consumption Time: 2.45162
PPO Batch Consumption Time: 0.27902
Total Iteration Time: 4.70772

Cumulative Model Updates: 247,046
Cumulative Timesteps: 2,060,973,998

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84,079.63931
Policy Entropy: 2.51024
Value Function Loss: 0.01645

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.07972
Policy Update Magnitude: 0.30511
Value Function Update Magnitude: 0.30004

Collected Steps per Second: 22,207.33463
Overall Steps per Second: 10,511.87363

Timestep Collection Time: 2.25169
Timestep Consumption Time: 2.50522
PPO Batch Consumption Time: 0.29410
Total Iteration Time: 4.75691

Cumulative Model Updates: 247,052
Cumulative Timesteps: 2,061,024,002

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2061024002...
Checkpoint 2061024002 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 69,483.84971
Policy Entropy: 2.52977
Value Function Loss: 0.01705

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.08297
Policy Update Magnitude: 0.30998
Value Function Update Magnitude: 0.32438

Collected Steps per Second: 21,846.29623
Overall Steps per Second: 10,604.09680

Timestep Collection Time: 2.29064
Timestep Consumption Time: 2.42848
PPO Batch Consumption Time: 0.27802
Total Iteration Time: 4.71912

Cumulative Model Updates: 247,058
Cumulative Timesteps: 2,061,074,044

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91,998.01924
Policy Entropy: 2.53117
Value Function Loss: 0.01794

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.09135
Policy Update Magnitude: 0.31119
Value Function Update Magnitude: 0.33991

Collected Steps per Second: 22,207.72426
Overall Steps per Second: 10,509.98666

Timestep Collection Time: 2.25273
Timestep Consumption Time: 2.50731
PPO Batch Consumption Time: 0.29255
Total Iteration Time: 4.76004

Cumulative Model Updates: 247,064
Cumulative Timesteps: 2,061,124,072

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2061124072...
Checkpoint 2061124072 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86,581.18586
Policy Entropy: 2.52474
Value Function Loss: 0.01724

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.08707
Policy Update Magnitude: 0.31765
Value Function Update Magnitude: 0.33392

Collected Steps per Second: 21,888.69096
Overall Steps per Second: 10,613.55487

Timestep Collection Time: 2.28657
Timestep Consumption Time: 2.42910
PPO Batch Consumption Time: 0.27729
Total Iteration Time: 4.71567

Cumulative Model Updates: 247,070
Cumulative Timesteps: 2,061,174,122

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 74,816.15036
Policy Entropy: 2.51723
Value Function Loss: 0.01786

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.08222
Policy Update Magnitude: 0.32476
Value Function Update Magnitude: 0.35233

Collected Steps per Second: 21,920.07686
Overall Steps per Second: 10,443.47180

Timestep Collection Time: 2.28101
Timestep Consumption Time: 2.50667
PPO Batch Consumption Time: 0.29333
Total Iteration Time: 4.78768

Cumulative Model Updates: 247,076
Cumulative Timesteps: 2,061,224,122

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2061224122...
Checkpoint 2061224122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 108,439.96664
Policy Entropy: 2.50924
Value Function Loss: 0.01639

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.08403
Policy Update Magnitude: 0.32912
Value Function Update Magnitude: 0.35969

Collected Steps per Second: 21,114.79373
Overall Steps per Second: 10,265.88208

Timestep Collection Time: 2.36858
Timestep Consumption Time: 2.50309
PPO Batch Consumption Time: 0.29291
Total Iteration Time: 4.87167

Cumulative Model Updates: 247,082
Cumulative Timesteps: 2,061,274,134

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50,877.17188
Policy Entropy: 2.49427
Value Function Loss: 0.01743

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.08796
Policy Update Magnitude: 0.32455
Value Function Update Magnitude: 0.33294

Collected Steps per Second: 21,847.15459
Overall Steps per Second: 10,416.90863

Timestep Collection Time: 2.28872
Timestep Consumption Time: 2.51136
PPO Batch Consumption Time: 0.29249
Total Iteration Time: 4.80008

Cumulative Model Updates: 247,088
Cumulative Timesteps: 2,061,324,136

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2061324136...
Checkpoint 2061324136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 50,877.17188
Policy Entropy: 2.50091
Value Function Loss: 0.01582

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.08462
Policy Update Magnitude: 0.32031
Value Function Update Magnitude: 0.28055

Collected Steps per Second: 21,531.49902
Overall Steps per Second: 10,501.28947

Timestep Collection Time: 2.32246
Timestep Consumption Time: 2.43943
PPO Batch Consumption Time: 0.27880
Total Iteration Time: 4.76189

Cumulative Model Updates: 247,094
Cumulative Timesteps: 2,061,374,142

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52,581.55372
Policy Entropy: 2.47800
Value Function Loss: 0.01686

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.07929
Policy Update Magnitude: 0.31420
Value Function Update Magnitude: 0.24490

Collected Steps per Second: 22,026.00580
Overall Steps per Second: 10,503.88771

Timestep Collection Time: 2.27032
Timestep Consumption Time: 2.49040
PPO Batch Consumption Time: 0.28627
Total Iteration Time: 4.76071

Cumulative Model Updates: 247,100
Cumulative Timesteps: 2,061,424,148

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2061424148...
Checkpoint 2061424148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 103,099.05428
Policy Entropy: 2.47455
Value Function Loss: 0.01609

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.07909
Policy Update Magnitude: 0.31781
Value Function Update Magnitude: 0.23937

Collected Steps per Second: 20,444.00624
Overall Steps per Second: 10,216.81719

Timestep Collection Time: 2.44815
Timestep Consumption Time: 2.45064
PPO Batch Consumption Time: 0.29277
Total Iteration Time: 4.89879

Cumulative Model Updates: 247,106
Cumulative Timesteps: 2,061,474,198

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 74,406.25903
Policy Entropy: 2.47418
Value Function Loss: 0.01637

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.07578
Policy Update Magnitude: 0.31861
Value Function Update Magnitude: 0.28632

Collected Steps per Second: 21,499.54330
Overall Steps per Second: 10,464.52279

Timestep Collection Time: 2.32712
Timestep Consumption Time: 2.45399
PPO Batch Consumption Time: 0.29117
Total Iteration Time: 4.78111

Cumulative Model Updates: 247,112
Cumulative Timesteps: 2,061,524,230

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2061524230...
Checkpoint 2061524230 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 74,406.25903
Policy Entropy: 2.49434
Value Function Loss: 0.01507

Mean KL Divergence: 0.00772
SB3 Clip Fraction: 0.07061
Policy Update Magnitude: 0.30812
Value Function Update Magnitude: 0.33274

Collected Steps per Second: 21,420.44033
Overall Steps per Second: 10,540.28364

Timestep Collection Time: 2.33469
Timestep Consumption Time: 2.40997
PPO Batch Consumption Time: 0.27778
Total Iteration Time: 4.74465

Cumulative Model Updates: 247,118
Cumulative Timesteps: 2,061,574,240

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70,207.79658
Policy Entropy: 2.49703
Value Function Loss: 0.01412

Mean KL Divergence: 0.00682
SB3 Clip Fraction: 0.06436
Policy Update Magnitude: 0.30740
Value Function Update Magnitude: 0.32261

Collected Steps per Second: 21,978.31445
Overall Steps per Second: 10,517.00201

Timestep Collection Time: 2.27688
Timestep Consumption Time: 2.48132
PPO Batch Consumption Time: 0.29385
Total Iteration Time: 4.75820

Cumulative Model Updates: 247,124
Cumulative Timesteps: 2,061,624,282

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 2061624282...
Checkpoint 2061624282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 58,653.47102
Policy Entropy: 2.49891
Value Function Loss: 0.01381

Mean KL Divergence: 0.00737
SB3 Clip Fraction: 0.06949
Policy Update Magnitude: 0.30899
Value Function Update Magnitude: 0.31952

Collected Steps per Second: 21,867.65726
Overall Steps per Second: 10,550.17071

Timestep Collection Time: 2.28712
Timestep Consumption Time: 2.45346
PPO Batch Consumption Time: 0.28829
Total Iteration Time: 4.74059

Cumulative Model Updates: 247,130
Cumulative Timesteps: 2,061,674,296

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62,059.06595
Policy Entropy: 2.48515
Value Function Loss: 0.01434

Mean KL Divergence: 0.00701
SB3 Clip Fraction: 0.06126
Policy Update Magnitude: 0.31057
Value Function Update Magnitude: 0.30819

Collected Steps per Second: 22,171.94544
Overall Steps per Second: 10,497.90760

Timestep Collection Time: 2.25582
Timestep Consumption Time: 2.50855
PPO Batch Consumption Time: 0.29364
Total Iteration Time: 4.76438

Cumulative Model Updates: 247,136
Cumulative Timesteps: 2,061,724,312

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2061724312...
Checkpoint 2061724312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 68,168.06603
Policy Entropy: 2.46322
Value Function Loss: 0.01519

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.07006
Policy Update Magnitude: 0.30734
Value Function Update Magnitude: 0.28738

Collected Steps per Second: 22,186.50926
Overall Steps per Second: 10,574.21303

Timestep Collection Time: 2.25551
Timestep Consumption Time: 2.47694
PPO Batch Consumption Time: 0.28681
Total Iteration Time: 4.73246

Cumulative Model Updates: 247,142
Cumulative Timesteps: 2,061,774,354

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62,289.31971
Policy Entropy: 2.46159
Value Function Loss: 0.01543

Mean KL Divergence: 0.00701
SB3 Clip Fraction: 0.06367
Policy Update Magnitude: 0.31106
Value Function Update Magnitude: 0.27641

Collected Steps per Second: 21,633.84818
Overall Steps per Second: 10,557.64048

Timestep Collection Time: 2.31203
Timestep Consumption Time: 2.42559
PPO Batch Consumption Time: 0.27705
Total Iteration Time: 4.73761

Cumulative Model Updates: 247,148
Cumulative Timesteps: 2,061,824,372

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2061824372...
Checkpoint 2061824372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 64,093.55524
Policy Entropy: 2.46661
Value Function Loss: 0.01865

Mean KL Divergence: 0.00699
SB3 Clip Fraction: 0.06601
Policy Update Magnitude: 0.31736
Value Function Update Magnitude: 0.29930

Collected Steps per Second: 21,543.72232
Overall Steps per Second: 10,500.56178

Timestep Collection Time: 2.32086
Timestep Consumption Time: 2.44079
PPO Batch Consumption Time: 0.27863
Total Iteration Time: 4.76165

Cumulative Model Updates: 247,154
Cumulative Timesteps: 2,061,874,372

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51,645.04586
Policy Entropy: 2.48159
Value Function Loss: 0.01760

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.07324
Policy Update Magnitude: 0.32568
Value Function Update Magnitude: 0.32478

Collected Steps per Second: 21,596.95331
Overall Steps per Second: 10,551.66502

Timestep Collection Time: 2.31570
Timestep Consumption Time: 2.42403
PPO Batch Consumption Time: 0.27754
Total Iteration Time: 4.73973

Cumulative Model Updates: 247,160
Cumulative Timesteps: 2,061,924,384

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2061924384...
Checkpoint 2061924384 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 95,017.01126
Policy Entropy: 2.48191
Value Function Loss: 0.01689

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.07398
Policy Update Magnitude: 0.32414
Value Function Update Magnitude: 0.34103

Collected Steps per Second: 21,407.58532
Overall Steps per Second: 10,253.54855

Timestep Collection Time: 2.33702
Timestep Consumption Time: 2.54226
PPO Batch Consumption Time: 0.29285
Total Iteration Time: 4.87929

Cumulative Model Updates: 247,166
Cumulative Timesteps: 2,061,974,414

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 135,531.53366
Policy Entropy: 2.49766
Value Function Loss: 0.01380

Mean KL Divergence: 0.00734
SB3 Clip Fraction: 0.06760
Policy Update Magnitude: 0.31179
Value Function Update Magnitude: 0.31907

Collected Steps per Second: 20,652.00967
Overall Steps per Second: 10,090.67809

Timestep Collection Time: 2.42156
Timestep Consumption Time: 2.53450
PPO Batch Consumption Time: 0.29011
Total Iteration Time: 4.95606

Cumulative Model Updates: 247,172
Cumulative Timesteps: 2,062,024,424

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2062024424...
Checkpoint 2062024424 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 150,201.02977
Policy Entropy: 2.51396
Value Function Loss: 0.01391

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.06877
Policy Update Magnitude: 0.29818
Value Function Update Magnitude: 0.29168

Collected Steps per Second: 21,640.63274
Overall Steps per Second: 10,510.03865

Timestep Collection Time: 2.31102
Timestep Consumption Time: 2.44748
PPO Batch Consumption Time: 0.27740
Total Iteration Time: 4.75850

Cumulative Model Updates: 247,178
Cumulative Timesteps: 2,062,074,436

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 138,466.41249
Policy Entropy: 2.52424
Value Function Loss: 0.01299

Mean KL Divergence: 0.00716
SB3 Clip Fraction: 0.06590
Policy Update Magnitude: 0.28766
Value Function Update Magnitude: 0.27314

Collected Steps per Second: 21,960.59765
Overall Steps per Second: 10,467.79726

Timestep Collection Time: 2.27899
Timestep Consumption Time: 2.50215
PPO Batch Consumption Time: 0.29294
Total Iteration Time: 4.78114

Cumulative Model Updates: 247,184
Cumulative Timesteps: 2,062,124,484

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 2062124484...
Checkpoint 2062124484 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 107,334.48130
Policy Entropy: 2.52252
Value Function Loss: 0.01257

Mean KL Divergence: 0.00596
SB3 Clip Fraction: 0.05858
Policy Update Magnitude: 0.28037
Value Function Update Magnitude: 0.23629

Collected Steps per Second: 21,805.15903
Overall Steps per Second: 10,573.14991

Timestep Collection Time: 2.29505
Timestep Consumption Time: 2.43807
PPO Batch Consumption Time: 0.27957
Total Iteration Time: 4.73312

Cumulative Model Updates: 247,190
Cumulative Timesteps: 2,062,174,528

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60,942.08279
Policy Entropy: 2.51951
Value Function Loss: 0.01441

Mean KL Divergence: 0.00576
SB3 Clip Fraction: 0.05561
Policy Update Magnitude: 0.29707
Value Function Update Magnitude: 0.25067

Collected Steps per Second: 22,292.83249
Overall Steps per Second: 10,508.00773

Timestep Collection Time: 2.24314
Timestep Consumption Time: 2.51570
PPO Batch Consumption Time: 0.29338
Total Iteration Time: 4.75885

Cumulative Model Updates: 247,196
Cumulative Timesteps: 2,062,224,534

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2062224534...
Checkpoint 2062224534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55,558.35081
Policy Entropy: 2.52799
Value Function Loss: 0.01537

Mean KL Divergence: 0.00668
SB3 Clip Fraction: 0.06296
Policy Update Magnitude: 0.30171
Value Function Update Magnitude: 0.31030

Collected Steps per Second: 21,993.91319
Overall Steps per Second: 10,657.89645

Timestep Collection Time: 2.27508
Timestep Consumption Time: 2.41984
PPO Batch Consumption Time: 0.27783
Total Iteration Time: 4.69492

Cumulative Model Updates: 247,202
Cumulative Timesteps: 2,062,274,572

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 104,632.96807
Policy Entropy: 2.51424
Value Function Loss: 0.01485

Mean KL Divergence: 0.00753
SB3 Clip Fraction: 0.06991
Policy Update Magnitude: 0.30040
Value Function Update Magnitude: 0.34357

Collected Steps per Second: 22,148.28537
Overall Steps per Second: 10,566.12332

Timestep Collection Time: 2.25823
Timestep Consumption Time: 2.47539
PPO Batch Consumption Time: 0.29030
Total Iteration Time: 4.73362

Cumulative Model Updates: 247,208
Cumulative Timesteps: 2,062,324,588

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2062324588...
Checkpoint 2062324588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 101,142.05165
Policy Entropy: 2.49048
Value Function Loss: 0.01509

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.08160
Policy Update Magnitude: 0.30522
Value Function Update Magnitude: 0.33581

Collected Steps per Second: 21,045.10882
Overall Steps per Second: 10,478.57883

Timestep Collection Time: 2.37623
Timestep Consumption Time: 2.39617
PPO Batch Consumption Time: 0.28648
Total Iteration Time: 4.77240

Cumulative Model Updates: 247,214
Cumulative Timesteps: 2,062,374,596

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 102,803.24553
Policy Entropy: 2.44632
Value Function Loss: 0.01754

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.08768
Policy Update Magnitude: 0.31804
Value Function Update Magnitude: 0.30901

Collected Steps per Second: 21,025.01265
Overall Steps per Second: 10,438.56844

Timestep Collection Time: 2.37945
Timestep Consumption Time: 2.41316
PPO Batch Consumption Time: 0.28622
Total Iteration Time: 4.79261

Cumulative Model Updates: 247,220
Cumulative Timesteps: 2,062,424,624

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2062424624...
Checkpoint 2062424624 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 70,065.24315
Policy Entropy: 2.45330
Value Function Loss: 0.01757

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.09090
Policy Update Magnitude: 0.32427
Value Function Update Magnitude: 0.32410

Collected Steps per Second: 20,927.06654
Overall Steps per Second: 10,568.89442

Timestep Collection Time: 2.38925
Timestep Consumption Time: 2.34161
PPO Batch Consumption Time: 0.27874
Total Iteration Time: 4.73086

Cumulative Model Updates: 247,226
Cumulative Timesteps: 2,062,474,624

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 98,433.69659
Policy Entropy: 2.46576
Value Function Loss: 0.01900

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.08332
Policy Update Magnitude: 0.33431
Value Function Update Magnitude: 0.32494

Collected Steps per Second: 20,791.28754
Overall Steps per Second: 10,244.08670

Timestep Collection Time: 2.40601
Timestep Consumption Time: 2.47720
PPO Batch Consumption Time: 0.29136
Total Iteration Time: 4.88321

Cumulative Model Updates: 247,232
Cumulative Timesteps: 2,062,524,648

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2062524648...
Checkpoint 2062524648 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 98,399.39694
Policy Entropy: 2.49576
Value Function Loss: 0.01809

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.07813
Policy Update Magnitude: 0.33054
Value Function Update Magnitude: 0.33913

Collected Steps per Second: 21,718.44728
Overall Steps per Second: 10,473.12910

Timestep Collection Time: 2.30265
Timestep Consumption Time: 2.47243
PPO Batch Consumption Time: 0.28815
Total Iteration Time: 4.77508

Cumulative Model Updates: 247,238
Cumulative Timesteps: 2,062,574,658

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 69,880.41137
Policy Entropy: 2.47404
Value Function Loss: 0.01839

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.08296
Policy Update Magnitude: 0.32272
Value Function Update Magnitude: 0.33500

Collected Steps per Second: 21,877.79575
Overall Steps per Second: 10,477.26633

Timestep Collection Time: 2.28707
Timestep Consumption Time: 2.48861
PPO Batch Consumption Time: 0.28799
Total Iteration Time: 4.77567

Cumulative Model Updates: 247,244
Cumulative Timesteps: 2,062,624,694

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 2062624694...
Checkpoint 2062624694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 80,735.23004
Policy Entropy: 2.46462
Value Function Loss: 0.01757

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.08035
Policy Update Magnitude: 0.32586
Value Function Update Magnitude: 0.32893

Collected Steps per Second: 22,138.44885
Overall Steps per Second: 10,702.73331

Timestep Collection Time: 2.25996
Timestep Consumption Time: 2.41473
PPO Batch Consumption Time: 0.27791
Total Iteration Time: 4.67469

Cumulative Model Updates: 247,250
Cumulative Timesteps: 2,062,674,726

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 94,445.98611
Policy Entropy: 2.48546
Value Function Loss: 0.01573

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.07569
Policy Update Magnitude: 0.31824
Value Function Update Magnitude: 0.32357

Collected Steps per Second: 22,289.14801
Overall Steps per Second: 10,563.81729

Timestep Collection Time: 2.24351
Timestep Consumption Time: 2.49019
PPO Batch Consumption Time: 0.28944
Total Iteration Time: 4.73371

Cumulative Model Updates: 247,256
Cumulative Timesteps: 2,062,724,732

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2062724732...
Checkpoint 2062724732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 78,998.75741
Policy Entropy: 2.50651
Value Function Loss: 0.01391

Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.07513
Policy Update Magnitude: 0.29182
Value Function Update Magnitude: 0.32676

Collected Steps per Second: 22,237.63292
Overall Steps per Second: 10,533.21517

Timestep Collection Time: 2.24952
Timestep Consumption Time: 2.49965
PPO Batch Consumption Time: 0.29385
Total Iteration Time: 4.74917

Cumulative Model Updates: 247,262
Cumulative Timesteps: 2,062,774,756

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56,183.98596
Policy Entropy: 2.51292
Value Function Loss: 0.01295

Mean KL Divergence: 0.00708
SB3 Clip Fraction: 0.06661
Policy Update Magnitude: 0.29038
Value Function Update Magnitude: 0.28325

Collected Steps per Second: 21,984.29010
Overall Steps per Second: 10,466.92704

Timestep Collection Time: 2.27490
Timestep Consumption Time: 2.50320
PPO Batch Consumption Time: 0.29323
Total Iteration Time: 4.77810

Cumulative Model Updates: 247,268
Cumulative Timesteps: 2,062,824,768

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2062824768...
Checkpoint 2062824768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 56,183.98596
Policy Entropy: 2.48091
Value Function Loss: 0.01289

Mean KL Divergence: 0.00726
SB3 Clip Fraction: 0.06609
Policy Update Magnitude: 0.29409
Value Function Update Magnitude: 0.28511

Collected Steps per Second: 21,988.41776
Overall Steps per Second: 10,562.52489

Timestep Collection Time: 2.27438
Timestep Consumption Time: 2.46028
PPO Batch Consumption Time: 0.28558
Total Iteration Time: 4.73466

Cumulative Model Updates: 247,274
Cumulative Timesteps: 2,062,874,778

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84,214.35840
Policy Entropy: 2.46470
Value Function Loss: 0.01527

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.06983
Policy Update Magnitude: 0.30592
Value Function Update Magnitude: 0.25891

Collected Steps per Second: 22,134.22399
Overall Steps per Second: 10,488.68335

Timestep Collection Time: 2.26075
Timestep Consumption Time: 2.51010
PPO Batch Consumption Time: 0.29331
Total Iteration Time: 4.77086

Cumulative Model Updates: 247,280
Cumulative Timesteps: 2,062,924,818

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 2062924818...
Checkpoint 2062924818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84,214.35840
Policy Entropy: 2.44921
Value Function Loss: 0.01437

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.07918
Policy Update Magnitude: 0.30801
Value Function Update Magnitude: 0.23012

Collected Steps per Second: 20,918.90443
Overall Steps per Second: 10,525.73121

Timestep Collection Time: 2.39104
Timestep Consumption Time: 2.36093
PPO Batch Consumption Time: 0.27925
Total Iteration Time: 4.75197

Cumulative Model Updates: 247,286
Cumulative Timesteps: 2,062,974,836

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81,635.80690
Policy Entropy: 2.45491
Value Function Loss: 0.01546

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.07968
Policy Update Magnitude: 0.30921
Value Function Update Magnitude: 0.24748

Collected Steps per Second: 20,868.04357
Overall Steps per Second: 10,490.72852

Timestep Collection Time: 2.39831
Timestep Consumption Time: 2.37238
PPO Batch Consumption Time: 0.27877
Total Iteration Time: 4.77069

Cumulative Model Updates: 247,292
Cumulative Timesteps: 2,063,024,884

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 2063024884...
Checkpoint 2063024884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 81,635.80690
Policy Entropy: 2.46924
Value Function Loss: 0.01371

Mean KL Divergence: 0.01138
SB3 Clip Fraction: 0.09495
Policy Update Magnitude: 0.30323
Value Function Update Magnitude: 0.25401

Collected Steps per Second: 20,634.76840
Overall Steps per Second: 10,309.01414

Timestep Collection Time: 2.42309
Timestep Consumption Time: 2.42703
PPO Batch Consumption Time: 0.29285
Total Iteration Time: 4.85012

Cumulative Model Updates: 247,298
Cumulative Timesteps: 2,063,074,884

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 69,796.70875
Policy Entropy: 2.45589
Value Function Loss: 0.01725

Mean KL Divergence: 0.01340
SB3 Clip Fraction: 0.10686
Policy Update Magnitude: 0.31529
Value Function Update Magnitude: 0.28287

Collected Steps per Second: 20,951.22306
Overall Steps per Second: 10,372.07195

Timestep Collection Time: 2.38726
Timestep Consumption Time: 2.43492
PPO Batch Consumption Time: 0.29253
Total Iteration Time: 4.82218

Cumulative Model Updates: 247,304
Cumulative Timesteps: 2,063,124,900

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2063124900...
Checkpoint 2063124900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 74,432.45013
Policy Entropy: 2.46153
Value Function Loss: 0.01612

Mean KL Divergence: 0.01211
SB3 Clip Fraction: 0.09685
Policy Update Magnitude: 0.32398
Value Function Update Magnitude: 0.29111

Collected Steps per Second: 20,932.16485
Overall Steps per Second: 10,220.17575

Timestep Collection Time: 2.39058
Timestep Consumption Time: 2.50562
PPO Batch Consumption Time: 0.29371
Total Iteration Time: 4.89620

Cumulative Model Updates: 247,310
Cumulative Timesteps: 2,063,174,940

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66,935.78292
Policy Entropy: 2.45568
Value Function Loss: 0.01557

Mean KL Divergence: 0.01125
SB3 Clip Fraction: 0.09095
Policy Update Magnitude: 0.32131
Value Function Update Magnitude: 0.30316

Collected Steps per Second: 22,281.25826
Overall Steps per Second: 10,498.72293

Timestep Collection Time: 2.24413
Timestep Consumption Time: 2.51855
PPO Batch Consumption Time: 0.29241
Total Iteration Time: 4.76267

Cumulative Model Updates: 247,316
Cumulative Timesteps: 2,063,224,942

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2063224942...
Checkpoint 2063224942 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 65,193.08766
Policy Entropy: 2.48878
Value Function Loss: 0.01499

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.07487
Policy Update Magnitude: 0.31763
Value Function Update Magnitude: 0.28365

Collected Steps per Second: 21,982.92139
Overall Steps per Second: 10,549.51441

Timestep Collection Time: 2.27522
Timestep Consumption Time: 2.46585
PPO Batch Consumption Time: 0.28799
Total Iteration Time: 4.74107

Cumulative Model Updates: 247,322
Cumulative Timesteps: 2,063,274,958

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63,159.58210
Policy Entropy: 2.48697
Value Function Loss: 0.01514

Mean KL Divergence: 0.00756
SB3 Clip Fraction: 0.06713
Policy Update Magnitude: 0.31002
Value Function Update Magnitude: 0.25933

Collected Steps per Second: 22,066.46288
Overall Steps per Second: 10,456.75426

Timestep Collection Time: 2.26652
Timestep Consumption Time: 2.51642
PPO Batch Consumption Time: 0.29189
Total Iteration Time: 4.78294

Cumulative Model Updates: 247,328
Cumulative Timesteps: 2,063,324,972

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2063324972...
Checkpoint 2063324972 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 64,759.82619
Policy Entropy: 2.47656
Value Function Loss: 0.01657

Mean KL Divergence: 0.00700
SB3 Clip Fraction: 0.06266
Policy Update Magnitude: 0.31944
Value Function Update Magnitude: 0.30817

Collected Steps per Second: 21,783.92238
Overall Steps per Second: 10,576.90650

Timestep Collection Time: 2.29564
Timestep Consumption Time: 2.43240
PPO Batch Consumption Time: 0.27926
Total Iteration Time: 4.72804

Cumulative Model Updates: 247,334
Cumulative Timesteps: 2,063,374,980

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80,794.87202
Policy Entropy: 2.46574
Value Function Loss: 0.01555

Mean KL Divergence: 0.00738
SB3 Clip Fraction: 0.06837
Policy Update Magnitude: 0.31644
Value Function Update Magnitude: 0.28679

Collected Steps per Second: 22,163.95799
Overall Steps per Second: 10,529.94056

Timestep Collection Time: 2.25700
Timestep Consumption Time: 2.49365
PPO Batch Consumption Time: 0.29012
Total Iteration Time: 4.75064

Cumulative Model Updates: 247,340
Cumulative Timesteps: 2,063,425,004

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2063425004...
Checkpoint 2063425004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 96,111.19265
Policy Entropy: 2.49596
Value Function Loss: 0.01720

Mean KL Divergence: 0.00729
SB3 Clip Fraction: 0.06787
Policy Update Magnitude: 0.30879
Value Function Update Magnitude: 0.23480

Collected Steps per Second: 21,902.78736
Overall Steps per Second: 10,575.62772

Timestep Collection Time: 2.28446
Timestep Consumption Time: 2.44680
PPO Batch Consumption Time: 0.27851
Total Iteration Time: 4.73126

Cumulative Model Updates: 247,346
Cumulative Timesteps: 2,063,475,040

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97,165.63323
Policy Entropy: 2.51174
Value Function Loss: 0.01635

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.07442
Policy Update Magnitude: 0.30015
Value Function Update Magnitude: 0.19660

Collected Steps per Second: 21,896.12661
Overall Steps per Second: 10,559.72097

Timestep Collection Time: 2.28351
Timestep Consumption Time: 2.45146
PPO Batch Consumption Time: 0.27778
Total Iteration Time: 4.73497

Cumulative Model Updates: 247,352
Cumulative Timesteps: 2,063,525,040

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2063525040...
Checkpoint 2063525040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 97,511.08619
Policy Entropy: 2.50199
Value Function Loss: 0.01709

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.08723
Policy Update Magnitude: 0.29875
Value Function Update Magnitude: 0.21894

Collected Steps per Second: 21,453.81088
Overall Steps per Second: 10,524.97577

Timestep Collection Time: 2.33189
Timestep Consumption Time: 2.42137
PPO Batch Consumption Time: 0.27841
Total Iteration Time: 4.75327

Cumulative Model Updates: 247,358
Cumulative Timesteps: 2,063,575,068

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61,818.00384
Policy Entropy: 2.47671
Value Function Loss: 0.01692

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.08566
Policy Update Magnitude: 0.31488
Value Function Update Magnitude: 0.22340

Collected Steps per Second: 21,217.64986
Overall Steps per Second: 10,442.14645

Timestep Collection Time: 2.35813
Timestep Consumption Time: 2.43341
PPO Batch Consumption Time: 0.27842
Total Iteration Time: 4.79154

Cumulative Model Updates: 247,364
Cumulative Timesteps: 2,063,625,102

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 2063625102...
Checkpoint 2063625102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 51,618.20319
Policy Entropy: 2.47839
Value Function Loss: 0.01626

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.07717
Policy Update Magnitude: 0.32312
Value Function Update Magnitude: 0.24779

Collected Steps per Second: 21,406.63923
Overall Steps per Second: 10,338.34713

Timestep Collection Time: 2.33685
Timestep Consumption Time: 2.50184
PPO Batch Consumption Time: 0.29378
Total Iteration Time: 4.83868

Cumulative Model Updates: 247,370
Cumulative Timesteps: 2,063,675,126

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83,943.21664
Policy Entropy: 2.48092
Value Function Loss: 0.01768

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.07322
Policy Update Magnitude: 0.32756
Value Function Update Magnitude: 0.26740

Collected Steps per Second: 21,916.65048
Overall Steps per Second: 10,431.65047

Timestep Collection Time: 2.28219
Timestep Consumption Time: 2.51264
PPO Batch Consumption Time: 0.29383
Total Iteration Time: 4.79483

Cumulative Model Updates: 247,376
Cumulative Timesteps: 2,063,725,144

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2063725144...
Checkpoint 2063725144 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 91,863.94727
Policy Entropy: 2.49356
Value Function Loss: 0.01644

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.07314
Policy Update Magnitude: 0.31351
Value Function Update Magnitude: 0.26736

Collected Steps per Second: 21,433.18274
Overall Steps per Second: 10,493.52598

Timestep Collection Time: 2.33339
Timestep Consumption Time: 2.43260
PPO Batch Consumption Time: 0.27934
Total Iteration Time: 4.76599

Cumulative Model Updates: 247,382
Cumulative Timesteps: 2,063,775,156

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77,445.58878
Policy Entropy: 2.49240
Value Function Loss: 0.01540

Mean KL Divergence: 0.00737
SB3 Clip Fraction: 0.06792
Policy Update Magnitude: 0.30329
Value Function Update Magnitude: 0.26198

Collected Steps per Second: 22,046.98495
Overall Steps per Second: 10,537.32075

Timestep Collection Time: 2.26788
Timestep Consumption Time: 2.47716
PPO Batch Consumption Time: 0.28386
Total Iteration Time: 4.74504

Cumulative Model Updates: 247,388
Cumulative Timesteps: 2,063,825,156

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2063825156...
Checkpoint 2063825156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 88,335.40194
Policy Entropy: 2.47042
Value Function Loss: 0.01527

Mean KL Divergence: 0.00669
SB3 Clip Fraction: 0.06562
Policy Update Magnitude: 0.31381
Value Function Update Magnitude: 0.22390

Collected Steps per Second: 21,243.93202
Overall Steps per Second: 10,557.27470

Timestep Collection Time: 2.35371
Timestep Consumption Time: 2.38255
PPO Batch Consumption Time: 0.28093
Total Iteration Time: 4.73626

Cumulative Model Updates: 247,394
Cumulative Timesteps: 2,063,875,158

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 74,392.42640
Policy Entropy: 2.45451
Value Function Loss: 0.01517

Mean KL Divergence: 0.00701
SB3 Clip Fraction: 0.06614
Policy Update Magnitude: 0.31810
Value Function Update Magnitude: 0.21007

Collected Steps per Second: 21,489.55352
Overall Steps per Second: 10,520.68673

Timestep Collection Time: 2.32820
Timestep Consumption Time: 2.42738
PPO Batch Consumption Time: 0.28960
Total Iteration Time: 4.75558

Cumulative Model Updates: 247,400
Cumulative Timesteps: 2,063,925,190

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2063925190...
Checkpoint 2063925190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 74,392.42640
Policy Entropy: 2.47487
Value Function Loss: 0.01462

Mean KL Divergence: 0.00759
SB3 Clip Fraction: 0.06536
Policy Update Magnitude: 0.31238
Value Function Update Magnitude: 0.20647

Collected Steps per Second: 21,238.51185
Overall Steps per Second: 10,629.55836

Timestep Collection Time: 2.35544
Timestep Consumption Time: 2.35087
PPO Batch Consumption Time: 0.27872
Total Iteration Time: 4.70631

Cumulative Model Updates: 247,406
Cumulative Timesteps: 2,063,975,216

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63,567.57974
Policy Entropy: 2.48986
Value Function Loss: 0.01238

Mean KL Divergence: 0.00675
SB3 Clip Fraction: 0.06027
Policy Update Magnitude: 0.30167
Value Function Update Magnitude: 0.19958

Collected Steps per Second: 21,564.82517
Overall Steps per Second: 10,491.96008

Timestep Collection Time: 2.31868
Timestep Consumption Time: 2.44706
PPO Batch Consumption Time: 0.28573
Total Iteration Time: 4.76574

Cumulative Model Updates: 247,412
Cumulative Timesteps: 2,064,025,218

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2064025218...
Checkpoint 2064025218 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 54,761.08243
Policy Entropy: 2.47995
Value Function Loss: 0.01313

Mean KL Divergence: 0.00615
SB3 Clip Fraction: 0.05645
Policy Update Magnitude: 0.29484
Value Function Update Magnitude: 0.17288

Collected Steps per Second: 21,833.26926
Overall Steps per Second: 10,709.31543

Timestep Collection Time: 2.29127
Timestep Consumption Time: 2.37999
PPO Batch Consumption Time: 0.27662
Total Iteration Time: 4.67126

Cumulative Model Updates: 247,418
Cumulative Timesteps: 2,064,075,244

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68,610.39803
Policy Entropy: 2.45732
Value Function Loss: 0.01453

Mean KL Divergence: 0.00640
SB3 Clip Fraction: 0.05988
Policy Update Magnitude: 0.30612
Value Function Update Magnitude: 0.18098

Collected Steps per Second: 21,786.44206
Overall Steps per Second: 10,444.65156

Timestep Collection Time: 2.29510
Timestep Consumption Time: 2.49223
PPO Batch Consumption Time: 0.29349
Total Iteration Time: 4.78733

Cumulative Model Updates: 247,424
Cumulative Timesteps: 2,064,125,246

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2064125246...
Checkpoint 2064125246 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 66,369.10041
Policy Entropy: 2.46515
Value Function Loss: 0.01449

Mean KL Divergence: 0.00726
SB3 Clip Fraction: 0.06732
Policy Update Magnitude: 0.30612
Value Function Update Magnitude: 0.19841

Collected Steps per Second: 20,968.19816
Overall Steps per Second: 10,189.88525

Timestep Collection Time: 2.38456
Timestep Consumption Time: 2.52226
PPO Batch Consumption Time: 0.29428
Total Iteration Time: 4.90683

Cumulative Model Updates: 247,430
Cumulative Timesteps: 2,064,175,246

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 96,093.49748
Policy Entropy: 2.45696
Value Function Loss: 0.01871

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.07473
Policy Update Magnitude: 0.31800
Value Function Update Magnitude: 0.19629

Collected Steps per Second: 21,641.95207
Overall Steps per Second: 10,385.12307

Timestep Collection Time: 2.31218
Timestep Consumption Time: 2.50626
PPO Batch Consumption Time: 0.28877
Total Iteration Time: 4.81843

Cumulative Model Updates: 247,436
Cumulative Timesteps: 2,064,225,286

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 2064225286...
Checkpoint 2064225286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 56,880.84327
Policy Entropy: 2.48630
Value Function Loss: 0.01962

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.07884
Policy Update Magnitude: 0.32641
Value Function Update Magnitude: 0.23347

Collected Steps per Second: 21,333.42431
Overall Steps per Second: 10,314.26851

Timestep Collection Time: 2.34505
Timestep Consumption Time: 2.50532
PPO Batch Consumption Time: 0.29385
Total Iteration Time: 4.85037

Cumulative Model Updates: 247,442
Cumulative Timesteps: 2,064,275,314

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53,611.41038
Policy Entropy: 2.51173
Value Function Loss: 0.01779

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.07958
Policy Update Magnitude: 0.30991
Value Function Update Magnitude: 0.25203

Collected Steps per Second: 22,457.49190
Overall Steps per Second: 10,454.33713

Timestep Collection Time: 2.22643
Timestep Consumption Time: 2.55628
PPO Batch Consumption Time: 0.29327
Total Iteration Time: 4.78270

Cumulative Model Updates: 247,448
Cumulative Timesteps: 2,064,325,314

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2064325314...
Checkpoint 2064325314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 73,556.42782
Policy Entropy: 2.53403
Value Function Loss: 0.01414

Mean KL Divergence: 0.00756
SB3 Clip Fraction: 0.06367
Policy Update Magnitude: 0.29283
Value Function Update Magnitude: 0.23785

Collected Steps per Second: 21,715.20406
Overall Steps per Second: 10,495.53647

Timestep Collection Time: 2.30253
Timestep Consumption Time: 2.46140
PPO Batch Consumption Time: 0.27902
Total Iteration Time: 4.76393

Cumulative Model Updates: 247,454
Cumulative Timesteps: 2,064,375,314

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90,923.99901
Policy Entropy: 2.50899
Value Function Loss: 0.01297

Mean KL Divergence: 0.00720
SB3 Clip Fraction: 0.07097
Policy Update Magnitude: 0.28920
Value Function Update Magnitude: 0.22230

Collected Steps per Second: 22,062.17982
Overall Steps per Second: 10,486.88608

Timestep Collection Time: 2.26659
Timestep Consumption Time: 2.50184
PPO Batch Consumption Time: 0.28848
Total Iteration Time: 4.76843

Cumulative Model Updates: 247,460
Cumulative Timesteps: 2,064,425,320

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2064425320...
Checkpoint 2064425320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 88,619.08527
Policy Entropy: 2.50158
Value Function Loss: 0.01349

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.07250
Policy Update Magnitude: 0.29270
Value Function Update Magnitude: 0.26487

Collected Steps per Second: 21,845.20727
Overall Steps per Second: 10,594.58474

Timestep Collection Time: 2.28975
Timestep Consumption Time: 2.43153
PPO Batch Consumption Time: 0.27931
Total Iteration Time: 4.72128

Cumulative Model Updates: 247,466
Cumulative Timesteps: 2,064,475,340

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54,018.00650
Policy Entropy: 2.47414
Value Function Loss: 0.01564

Mean KL Divergence: 0.00736
SB3 Clip Fraction: 0.06873
Policy Update Magnitude: 0.30473
Value Function Update Magnitude: 0.26474

Collected Steps per Second: 22,204.74121
Overall Steps per Second: 10,497.57828

Timestep Collection Time: 2.25222
Timestep Consumption Time: 2.51173
PPO Batch Consumption Time: 0.29008
Total Iteration Time: 4.76396

Cumulative Model Updates: 247,472
Cumulative Timesteps: 2,064,525,350

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2064525350...
Checkpoint 2064525350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87,232.07361
Policy Entropy: 2.47910
Value Function Loss: 0.01712

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.08033
Policy Update Magnitude: 0.33214
Value Function Update Magnitude: 0.23368

Collected Steps per Second: 21,439.23001
Overall Steps per Second: 10,305.77175

Timestep Collection Time: 2.33367
Timestep Consumption Time: 2.52109
PPO Batch Consumption Time: 0.29336
Total Iteration Time: 4.85476

Cumulative Model Updates: 247,478
Cumulative Timesteps: 2,064,575,382

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67,955.38234
Policy Entropy: 2.47124
Value Function Loss: 0.01989

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.07559
Policy Update Magnitude: 0.33441
Value Function Update Magnitude: 0.25137

Collected Steps per Second: 22,213.34682
Overall Steps per Second: 10,532.37321

Timestep Collection Time: 2.25342
Timestep Consumption Time: 2.49917
PPO Batch Consumption Time: 0.29074
Total Iteration Time: 4.75259

Cumulative Model Updates: 247,484
Cumulative Timesteps: 2,064,625,438

Timesteps Collected: 50,056
--------END ITERATION REPORT--------


Saving checkpoint 2064625438...
Checkpoint 2064625438 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 67,955.38234
Policy Entropy: 2.47716
Value Function Loss: 0.01761

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.06935
Policy Update Magnitude: 0.32786
Value Function Update Magnitude: 0.25900

Collected Steps per Second: 21,467.23267
Overall Steps per Second: 10,478.99498

Timestep Collection Time: 2.32922
Timestep Consumption Time: 2.44242
PPO Batch Consumption Time: 0.27876
Total Iteration Time: 4.77164

Cumulative Model Updates: 247,490
Cumulative Timesteps: 2,064,675,440

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56,783.26632
Policy Entropy: 2.48576
Value Function Loss: 0.01756

Mean KL Divergence: 0.00710
SB3 Clip Fraction: 0.06715
Policy Update Magnitude: 0.31759
Value Function Update Magnitude: 0.27358

Collected Steps per Second: 21,904.91214
Overall Steps per Second: 10,460.81749

Timestep Collection Time: 2.28405
Timestep Consumption Time: 2.49875
PPO Batch Consumption Time: 0.29025
Total Iteration Time: 4.78280

Cumulative Model Updates: 247,496
Cumulative Timesteps: 2,064,725,472

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2064725472...
Checkpoint 2064725472 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 66,365.23774
Policy Entropy: 2.48785
Value Function Loss: 0.01440

Mean KL Divergence: 0.00730
SB3 Clip Fraction: 0.07001
Policy Update Magnitude: 0.31081
Value Function Update Magnitude: 0.30651

Collected Steps per Second: 21,415.11039
Overall Steps per Second: 10,360.05413

Timestep Collection Time: 2.33611
Timestep Consumption Time: 2.49282
PPO Batch Consumption Time: 0.29131
Total Iteration Time: 4.82893

Cumulative Model Updates: 247,502
Cumulative Timesteps: 2,064,775,500

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 102,490.68401
Policy Entropy: 2.52485
Value Function Loss: 0.01450

Mean KL Divergence: 0.00689
SB3 Clip Fraction: 0.06640
Policy Update Magnitude: 0.30033
Value Function Update Magnitude: 0.28026

Collected Steps per Second: 22,033.80682
Overall Steps per Second: 10,472.54276

Timestep Collection Time: 2.26951
Timestep Consumption Time: 2.50545
PPO Batch Consumption Time: 0.29013
Total Iteration Time: 4.77496

Cumulative Model Updates: 247,508
Cumulative Timesteps: 2,064,825,506

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2064825506...
Checkpoint 2064825506 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 122,994.22566
Policy Entropy: 2.53646
Value Function Loss: 0.01476

Mean KL Divergence: 0.00747
SB3 Clip Fraction: 0.06992
Policy Update Magnitude: 0.29828
Value Function Update Magnitude: 0.24368

Collected Steps per Second: 21,437.77387
Overall Steps per Second: 10,411.58599

Timestep Collection Time: 2.33261
Timestep Consumption Time: 2.47031
PPO Batch Consumption Time: 0.27812
Total Iteration Time: 4.80292

Cumulative Model Updates: 247,514
Cumulative Timesteps: 2,064,875,512

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68,461.58311
Policy Entropy: 2.52468
Value Function Loss: 0.01565

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.07298
Policy Update Magnitude: 0.30154
Value Function Update Magnitude: 0.24580

Collected Steps per Second: 22,172.78874
Overall Steps per Second: 10,399.40132

Timestep Collection Time: 2.25511
Timestep Consumption Time: 2.55305
PPO Batch Consumption Time: 0.29540
Total Iteration Time: 4.80816

Cumulative Model Updates: 247,520
Cumulative Timesteps: 2,064,925,514

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2064925514...
Checkpoint 2064925514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48,762.08434
Policy Entropy: 2.50082
Value Function Loss: 0.01520

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.07706
Policy Update Magnitude: 0.30042
Value Function Update Magnitude: 0.28739

Collected Steps per Second: 21,718.84194
Overall Steps per Second: 10,390.68036

Timestep Collection Time: 2.30233
Timestep Consumption Time: 2.51006
PPO Batch Consumption Time: 0.29280
Total Iteration Time: 4.81239

Cumulative Model Updates: 247,526
Cumulative Timesteps: 2,064,975,518

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,230.13899
Policy Entropy: 2.46372
Value Function Loss: 0.01557

Mean KL Divergence: 0.00731
SB3 Clip Fraction: 0.06226
Policy Update Magnitude: 0.31524
Value Function Update Magnitude: 0.33200

Collected Steps per Second: 22,364.05586
Overall Steps per Second: 10,723.73071

Timestep Collection Time: 2.23689
Timestep Consumption Time: 2.42809
PPO Batch Consumption Time: 0.27914
Total Iteration Time: 4.66498

Cumulative Model Updates: 247,532
Cumulative Timesteps: 2,065,025,544

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2065025544...
Checkpoint 2065025544 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,742.93742
Policy Entropy: 2.47298
Value Function Loss: 0.01496

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.06834
Policy Update Magnitude: 0.31963
Value Function Update Magnitude: 0.34156

Collected Steps per Second: 21,765.06072
Overall Steps per Second: 10,623.60949

Timestep Collection Time: 2.29864
Timestep Consumption Time: 2.41068
PPO Batch Consumption Time: 0.27916
Total Iteration Time: 4.70932

Cumulative Model Updates: 247,538
Cumulative Timesteps: 2,065,075,574

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67,073.07302
Policy Entropy: 2.49201
Value Function Loss: 0.01650

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.07101
Policy Update Magnitude: 0.31425
Value Function Update Magnitude: 0.32212

Collected Steps per Second: 21,204.73335
Overall Steps per Second: 10,514.06104

Timestep Collection Time: 2.35796
Timestep Consumption Time: 2.39757
PPO Batch Consumption Time: 0.28560
Total Iteration Time: 4.75554

Cumulative Model Updates: 247,544
Cumulative Timesteps: 2,065,125,574

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2065125574...
Checkpoint 2065125574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,234.43470
Policy Entropy: 2.52264
Value Function Loss: 0.01970

Mean KL Divergence: 0.00645
SB3 Clip Fraction: 0.06066
Policy Update Magnitude: 0.31455
Value Function Update Magnitude: 0.30017

Collected Steps per Second: 21,283.97963
Overall Steps per Second: 10,650.67187

Timestep Collection Time: 2.34928
Timestep Consumption Time: 2.34545
PPO Batch Consumption Time: 0.27844
Total Iteration Time: 4.69473

Cumulative Model Updates: 247,550
Cumulative Timesteps: 2,065,175,576

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,545.47479
Policy Entropy: 2.52160
Value Function Loss: 0.02054

Mean KL Divergence: 0.00766
SB3 Clip Fraction: 0.07120
Policy Update Magnitude: 0.31772
Value Function Update Magnitude: 0.33619

Collected Steps per Second: 20,845.41836
Overall Steps per Second: 10,424.70861

Timestep Collection Time: 2.39966
Timestep Consumption Time: 2.39874
PPO Batch Consumption Time: 0.28543
Total Iteration Time: 4.79841

Cumulative Model Updates: 247,556
Cumulative Timesteps: 2,065,225,598

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2065225598...
Checkpoint 2065225598 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 69,781.77135
Policy Entropy: 2.50438
Value Function Loss: 0.02146

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.08170
Policy Update Magnitude: 0.32211
Value Function Update Magnitude: 0.33129

Collected Steps per Second: 20,953.18135
Overall Steps per Second: 10,582.87654

Timestep Collection Time: 2.38856
Timestep Consumption Time: 2.34059
PPO Batch Consumption Time: 0.27876
Total Iteration Time: 4.72915

Cumulative Model Updates: 247,562
Cumulative Timesteps: 2,065,275,646

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57,248.85697
Policy Entropy: 2.50397
Value Function Loss: 0.01772

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.08074
Policy Update Magnitude: 0.32246
Value Function Update Magnitude: 0.31541

Collected Steps per Second: 21,095.37036
Overall Steps per Second: 10,453.77889

Timestep Collection Time: 2.37019
Timestep Consumption Time: 2.41277
PPO Batch Consumption Time: 0.27884
Total Iteration Time: 4.78296

Cumulative Model Updates: 247,568
Cumulative Timesteps: 2,065,325,646

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2065325646...
Checkpoint 2065325646 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 50,364.15071
Policy Entropy: 2.49095
Value Function Loss: 0.01670

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.06864
Policy Update Magnitude: 0.31132
Value Function Update Magnitude: 0.31444

Collected Steps per Second: 21,457.58197
Overall Steps per Second: 10,428.11536

Timestep Collection Time: 2.33046
Timestep Consumption Time: 2.46485
PPO Batch Consumption Time: 0.28932
Total Iteration Time: 4.79531

Cumulative Model Updates: 247,574
Cumulative Timesteps: 2,065,375,652

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48,156.22455
Policy Entropy: 2.49113
Value Function Loss: 0.01412

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.07416
Policy Update Magnitude: 0.31438
Value Function Update Magnitude: 0.32065

Collected Steps per Second: 21,815.46922
Overall Steps per Second: 10,487.43246

Timestep Collection Time: 2.29287
Timestep Consumption Time: 2.47665
PPO Batch Consumption Time: 0.28999
Total Iteration Time: 4.76952

Cumulative Model Updates: 247,580
Cumulative Timesteps: 2,065,425,672

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2065425672...
Checkpoint 2065425672 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 61,915.31679
Policy Entropy: 2.50029
Value Function Loss: 0.01356

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.07266
Policy Update Magnitude: 0.30573
Value Function Update Magnitude: 0.31548

Collected Steps per Second: 22,138.48307
Overall Steps per Second: 10,444.89744

Timestep Collection Time: 2.25860
Timestep Consumption Time: 2.52862
PPO Batch Consumption Time: 0.29188
Total Iteration Time: 4.78722

Cumulative Model Updates: 247,586
Cumulative Timesteps: 2,065,475,674

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46,388.98798
Policy Entropy: 2.51427
Value Function Loss: 0.01294

Mean KL Divergence: 0.00710
SB3 Clip Fraction: 0.06382
Policy Update Magnitude: 0.29823
Value Function Update Magnitude: 0.31209

Collected Steps per Second: 22,227.67936
Overall Steps per Second: 10,501.57386

Timestep Collection Time: 2.24945
Timestep Consumption Time: 2.51174
PPO Batch Consumption Time: 0.29344
Total Iteration Time: 4.76119

Cumulative Model Updates: 247,592
Cumulative Timesteps: 2,065,525,674

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2065525674...
Checkpoint 2065525674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 107,366.37112
Policy Entropy: 2.50102
Value Function Loss: 0.01472

Mean KL Divergence: 0.00634
SB3 Clip Fraction: 0.06087
Policy Update Magnitude: 0.30147
Value Function Update Magnitude: 0.30818

Collected Steps per Second: 21,647.05133
Overall Steps per Second: 10,533.14536

Timestep Collection Time: 2.31200
Timestep Consumption Time: 2.43948
PPO Batch Consumption Time: 0.27793
Total Iteration Time: 4.75148

Cumulative Model Updates: 247,598
Cumulative Timesteps: 2,065,575,722

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83,625.11509
Policy Entropy: 2.49869
Value Function Loss: 0.01398

Mean KL Divergence: 0.00621
SB3 Clip Fraction: 0.05960
Policy Update Magnitude: 0.30292
Value Function Update Magnitude: 0.31156

Collected Steps per Second: 21,940.19130
Overall Steps per Second: 10,495.02184

Timestep Collection Time: 2.27892
Timestep Consumption Time: 2.48524
PPO Batch Consumption Time: 0.28744
Total Iteration Time: 4.76416

Cumulative Model Updates: 247,604
Cumulative Timesteps: 2,065,625,722

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2065625722...
Checkpoint 2065625722 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 83,216.13291
Policy Entropy: 2.48015
Value Function Loss: 0.01576

Mean KL Divergence: 0.00681
SB3 Clip Fraction: 0.06528
Policy Update Magnitude: 0.30593
Value Function Update Magnitude: 0.27338

Collected Steps per Second: 21,904.46806
Overall Steps per Second: 10,606.65779

Timestep Collection Time: 2.28401
Timestep Consumption Time: 2.43284
PPO Batch Consumption Time: 0.27930
Total Iteration Time: 4.71685

Cumulative Model Updates: 247,610
Cumulative Timesteps: 2,065,675,752

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 132,184.46210
Policy Entropy: 2.49173
Value Function Loss: 0.01464

Mean KL Divergence: 0.00672
SB3 Clip Fraction: 0.06730
Policy Update Magnitude: 0.30458
Value Function Update Magnitude: 0.25820

Collected Steps per Second: 22,081.76884
Overall Steps per Second: 10,468.72696

Timestep Collection Time: 2.26549
Timestep Consumption Time: 2.51312
PPO Batch Consumption Time: 0.29132
Total Iteration Time: 4.77861

Cumulative Model Updates: 247,616
Cumulative Timesteps: 2,065,725,778

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2065725778...
Checkpoint 2065725778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 119,565.17957
Policy Entropy: 2.49010
Value Function Loss: 0.01430

Mean KL Divergence: 0.00727
SB3 Clip Fraction: 0.07166
Policy Update Magnitude: 0.30032
Value Function Update Magnitude: 0.27108

Collected Steps per Second: 21,253.30604
Overall Steps per Second: 10,181.12644

Timestep Collection Time: 2.35361
Timestep Consumption Time: 2.55960
PPO Batch Consumption Time: 0.29071
Total Iteration Time: 4.91321

Cumulative Model Updates: 247,622
Cumulative Timesteps: 2,065,775,800

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75,358.87330
Policy Entropy: 2.51857
Value Function Loss: 0.01511

Mean KL Divergence: 0.00684
SB3 Clip Fraction: 0.06527
Policy Update Magnitude: 0.29769
Value Function Update Magnitude: 0.25910

Collected Steps per Second: 21,529.27693
Overall Steps per Second: 10,502.33568

Timestep Collection Time: 2.32288
Timestep Consumption Time: 2.43891
PPO Batch Consumption Time: 0.27852
Total Iteration Time: 4.76180

Cumulative Model Updates: 247,628
Cumulative Timesteps: 2,065,825,810

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2065825810...
Checkpoint 2065825810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 123,400.49447
Policy Entropy: 2.53339
Value Function Loss: 0.01534

Mean KL Divergence: 0.00756
SB3 Clip Fraction: 0.07235
Policy Update Magnitude: 0.29456
Value Function Update Magnitude: 0.28717

Collected Steps per Second: 21,564.84754
Overall Steps per Second: 10,419.40088

Timestep Collection Time: 2.31933
Timestep Consumption Time: 2.48095
PPO Batch Consumption Time: 0.28969
Total Iteration Time: 4.80028

Cumulative Model Updates: 247,634
Cumulative Timesteps: 2,065,875,826

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92,359.87440
Policy Entropy: 2.53326
Value Function Loss: 0.01466

Mean KL Divergence: 0.00685
SB3 Clip Fraction: 0.06318
Policy Update Magnitude: 0.29893
Value Function Update Magnitude: 0.31023

Collected Steps per Second: 21,720.04306
Overall Steps per Second: 10,602.49131

Timestep Collection Time: 2.30211
Timestep Consumption Time: 2.41395
PPO Batch Consumption Time: 0.27880
Total Iteration Time: 4.71606

Cumulative Model Updates: 247,640
Cumulative Timesteps: 2,065,925,828

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2065925828...
Checkpoint 2065925828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 72,223.20431
Policy Entropy: 2.52631
Value Function Loss: 0.01529

Mean KL Divergence: 0.00649
SB3 Clip Fraction: 0.05888
Policy Update Magnitude: 0.29649
Value Function Update Magnitude: 0.30244

Collected Steps per Second: 21,502.02784
Overall Steps per Second: 10,328.59852

Timestep Collection Time: 2.32555
Timestep Consumption Time: 2.51577
PPO Batch Consumption Time: 0.29372
Total Iteration Time: 4.84132

Cumulative Model Updates: 247,646
Cumulative Timesteps: 2,065,975,832

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 72,223.20431
Policy Entropy: 2.52771
Value Function Loss: 0.01422

Mean KL Divergence: 0.00665
SB3 Clip Fraction: 0.06012
Policy Update Magnitude: 0.29762
Value Function Update Magnitude: 0.31426

Collected Steps per Second: 21,503.53989
Overall Steps per Second: 10,404.57766

Timestep Collection Time: 2.32566
Timestep Consumption Time: 2.48087
PPO Batch Consumption Time: 0.28502
Total Iteration Time: 4.80654

Cumulative Model Updates: 247,652
Cumulative Timesteps: 2,066,025,842

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2066025842...
Checkpoint 2066025842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 91,986.97300
Policy Entropy: 2.51774
Value Function Loss: 0.01530

Mean KL Divergence: 0.00626
SB3 Clip Fraction: 0.05805
Policy Update Magnitude: 0.30225
Value Function Update Magnitude: 0.32497

Collected Steps per Second: 21,975.45157
Overall Steps per Second: 10,513.25611

Timestep Collection Time: 2.27527
Timestep Consumption Time: 2.48063
PPO Batch Consumption Time: 0.27831
Total Iteration Time: 4.75590

Cumulative Model Updates: 247,658
Cumulative Timesteps: 2,066,075,842

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97,386.60794
Policy Entropy: 2.51914
Value Function Loss: 0.01537

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.07009
Policy Update Magnitude: 0.30388
Value Function Update Magnitude: 0.34682

Collected Steps per Second: 22,051.32679
Overall Steps per Second: 10,577.12003

Timestep Collection Time: 2.26961
Timestep Consumption Time: 2.46211
PPO Batch Consumption Time: 0.28024
Total Iteration Time: 4.73172

Cumulative Model Updates: 247,664
Cumulative Timesteps: 2,066,125,890

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 2066125890...
Checkpoint 2066125890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 102,876.92458
Policy Entropy: 2.52250
Value Function Loss: 0.01780

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.07503
Policy Update Magnitude: 0.30271
Value Function Update Magnitude: 0.33184

Collected Steps per Second: 21,967.62847
Overall Steps per Second: 10,597.60112

Timestep Collection Time: 2.27826
Timestep Consumption Time: 2.44432
PPO Batch Consumption Time: 0.27991
Total Iteration Time: 4.72258

Cumulative Model Updates: 247,670
Cumulative Timesteps: 2,066,175,938

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 105,294.35741
Policy Entropy: 2.53803
Value Function Loss: 0.01806

Mean KL Divergence: 0.00710
SB3 Clip Fraction: 0.06827
Policy Update Magnitude: 0.31120
Value Function Update Magnitude: 0.30858

Collected Steps per Second: 21,865.78244
Overall Steps per Second: 10,520.99504

Timestep Collection Time: 2.28677
Timestep Consumption Time: 2.46582
PPO Batch Consumption Time: 0.28612
Total Iteration Time: 4.75259

Cumulative Model Updates: 247,676
Cumulative Timesteps: 2,066,225,940

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2066225940...
Checkpoint 2066225940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 66,468.88333
Policy Entropy: 2.55092
Value Function Loss: 0.01829

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.07324
Policy Update Magnitude: 0.31713
Value Function Update Magnitude: 0.32279

Collected Steps per Second: 22,012.29471
Overall Steps per Second: 10,594.67393

Timestep Collection Time: 2.27291
Timestep Consumption Time: 2.44946
PPO Batch Consumption Time: 0.27891
Total Iteration Time: 4.72237

Cumulative Model Updates: 247,682
Cumulative Timesteps: 2,066,275,972

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78,668.28796
Policy Entropy: 2.54769
Value Function Loss: 0.01706

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.07840
Policy Update Magnitude: 0.30797
Value Function Update Magnitude: 0.34647

Collected Steps per Second: 21,902.65021
Overall Steps per Second: 10,446.76460

Timestep Collection Time: 2.28374
Timestep Consumption Time: 2.50434
PPO Batch Consumption Time: 0.28848
Total Iteration Time: 4.78809

Cumulative Model Updates: 247,688
Cumulative Timesteps: 2,066,325,992

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2066325992...
Checkpoint 2066325992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 67,015.52746
Policy Entropy: 2.55535
Value Function Loss: 0.01502

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.07701
Policy Update Magnitude: 0.29739
Value Function Update Magnitude: 0.33678

Collected Steps per Second: 21,808.81537
Overall Steps per Second: 10,602.22485

Timestep Collection Time: 2.29430
Timestep Consumption Time: 2.42509
PPO Batch Consumption Time: 0.27894
Total Iteration Time: 4.71939

Cumulative Model Updates: 247,694
Cumulative Timesteps: 2,066,376,028

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63,970.86428
Policy Entropy: 2.55627
Value Function Loss: 0.01444

Mean KL Divergence: 0.00707
SB3 Clip Fraction: 0.06476
Policy Update Magnitude: 0.29648
Value Function Update Magnitude: 0.28208

Collected Steps per Second: 21,177.43848
Overall Steps per Second: 10,295.79159

Timestep Collection Time: 2.36195
Timestep Consumption Time: 2.49635
PPO Batch Consumption Time: 0.28939
Total Iteration Time: 4.85830

Cumulative Model Updates: 247,700
Cumulative Timesteps: 2,066,426,048

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2066426048...
Checkpoint 2066426048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 83,141.25015
Policy Entropy: 2.55316
Value Function Loss: 0.01324

Mean KL Divergence: 0.00702
SB3 Clip Fraction: 0.06488
Policy Update Magnitude: 0.28621
Value Function Update Magnitude: 0.26885

Collected Steps per Second: 20,622.82940
Overall Steps per Second: 10,480.57427

Timestep Collection Time: 2.42634
Timestep Consumption Time: 2.34802
PPO Batch Consumption Time: 0.27737
Total Iteration Time: 4.77436

Cumulative Model Updates: 247,706
Cumulative Timesteps: 2,066,476,086

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70,913.23400
Policy Entropy: 2.53047
Value Function Loss: 0.01328

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.06539
Policy Update Magnitude: 0.28653
Value Function Update Magnitude: 0.26154

Collected Steps per Second: 21,152.84261
Overall Steps per Second: 10,410.33191

Timestep Collection Time: 2.36413
Timestep Consumption Time: 2.43956
PPO Batch Consumption Time: 0.29234
Total Iteration Time: 4.80369

Cumulative Model Updates: 247,712
Cumulative Timesteps: 2,066,526,094

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2066526094...
Checkpoint 2066526094 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55,313.20669
Policy Entropy: 2.50836
Value Function Loss: 0.01433

Mean KL Divergence: 0.00738
SB3 Clip Fraction: 0.07098
Policy Update Magnitude: 0.29164
Value Function Update Magnitude: 0.21180

Collected Steps per Second: 20,950.12613
Overall Steps per Second: 10,543.42846

Timestep Collection Time: 2.38710
Timestep Consumption Time: 2.35614
PPO Batch Consumption Time: 0.27845
Total Iteration Time: 4.74324

Cumulative Model Updates: 247,718
Cumulative Timesteps: 2,066,576,104

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42,863.71581
Policy Entropy: 2.50913
Value Function Loss: 0.01560

Mean KL Divergence: 0.00662
SB3 Clip Fraction: 0.05889
Policy Update Magnitude: 0.29474
Value Function Update Magnitude: 0.21462

Collected Steps per Second: 20,271.26301
Overall Steps per Second: 10,169.97610

Timestep Collection Time: 2.46724
Timestep Consumption Time: 2.45057
PPO Batch Consumption Time: 0.29338
Total Iteration Time: 4.91781

Cumulative Model Updates: 247,724
Cumulative Timesteps: 2,066,626,118

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2066626118...
Checkpoint 2066626118 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,477.40090
Policy Entropy: 2.51508
Value Function Loss: 0.01519

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.07405
Policy Update Magnitude: 0.30401
Value Function Update Magnitude: 0.28906

Collected Steps per Second: 21,507.41165
Overall Steps per Second: 10,512.47507

Timestep Collection Time: 2.32562
Timestep Consumption Time: 2.43235
PPO Batch Consumption Time: 0.27830
Total Iteration Time: 4.75797

Cumulative Model Updates: 247,730
Cumulative Timesteps: 2,066,676,136

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,563.75153
Policy Entropy: 2.53529
Value Function Loss: 0.01409

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.07077
Policy Update Magnitude: 0.29302
Value Function Update Magnitude: 0.32362

Collected Steps per Second: 22,028.28946
Overall Steps per Second: 10,446.96034

Timestep Collection Time: 2.27053
Timestep Consumption Time: 2.51708
PPO Batch Consumption Time: 0.29476
Total Iteration Time: 4.78761

Cumulative Model Updates: 247,736
Cumulative Timesteps: 2,066,726,152

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2066726152...
Checkpoint 2066726152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 50,027.61878
Policy Entropy: 2.52846
Value Function Loss: 0.01359

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.08598
Policy Update Magnitude: 0.28865
Value Function Update Magnitude: 0.29435

Collected Steps per Second: 21,862.94490
Overall Steps per Second: 10,663.50625

Timestep Collection Time: 2.28835
Timestep Consumption Time: 2.40336
PPO Batch Consumption Time: 0.27861
Total Iteration Time: 4.69170

Cumulative Model Updates: 247,742
Cumulative Timesteps: 2,066,776,182

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,346.73457
Policy Entropy: 2.50141
Value Function Loss: 0.01677

Mean KL Divergence: 0.01948
SB3 Clip Fraction: 0.13701
Policy Update Magnitude: 0.29172
Value Function Update Magnitude: 0.31697

Collected Steps per Second: 21,986.74473
Overall Steps per Second: 10,510.61102

Timestep Collection Time: 2.27446
Timestep Consumption Time: 2.48340
PPO Batch Consumption Time: 0.28822
Total Iteration Time: 4.75786

Cumulative Model Updates: 247,748
Cumulative Timesteps: 2,066,826,190

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2066826190...
Checkpoint 2066826190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 57,422.84506
Policy Entropy: 2.48276
Value Function Loss: 0.01580

Mean KL Divergence: 0.01453
SB3 Clip Fraction: 0.11717
Policy Update Magnitude: 0.30740
Value Function Update Magnitude: 0.33841

Collected Steps per Second: 21,659.79110
Overall Steps per Second: 10,554.25397

Timestep Collection Time: 2.31055
Timestep Consumption Time: 2.43124
PPO Batch Consumption Time: 0.27878
Total Iteration Time: 4.74178

Cumulative Model Updates: 247,754
Cumulative Timesteps: 2,066,876,236

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 103,721.76438
Policy Entropy: 2.45634
Value Function Loss: 0.01901

Mean KL Divergence: 0.01251
SB3 Clip Fraction: 0.10675
Policy Update Magnitude: 0.32658
Value Function Update Magnitude: 0.34773

Collected Steps per Second: 22,118.36444
Overall Steps per Second: 10,518.30006

Timestep Collection Time: 2.26066
Timestep Consumption Time: 2.49315
PPO Batch Consumption Time: 0.28858
Total Iteration Time: 4.75381

Cumulative Model Updates: 247,760
Cumulative Timesteps: 2,066,926,238

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2066926238...
Checkpoint 2066926238 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 148,650.57164
Policy Entropy: 2.46721
Value Function Loss: 0.01591

Mean KL Divergence: 0.01246
SB3 Clip Fraction: 0.10430
Policy Update Magnitude: 0.32953
Value Function Update Magnitude: 0.33894

Collected Steps per Second: 21,740.88357
Overall Steps per Second: 10,578.77279

Timestep Collection Time: 2.30147
Timestep Consumption Time: 2.42838
PPO Batch Consumption Time: 0.27862
Total Iteration Time: 4.72985

Cumulative Model Updates: 247,766
Cumulative Timesteps: 2,066,976,274

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 119,738.10913
Policy Entropy: 2.48750
Value Function Loss: 0.01560

Mean KL Divergence: 0.01565
SB3 Clip Fraction: 0.12340
Policy Update Magnitude: 0.32528
Value Function Update Magnitude: 0.29131

Collected Steps per Second: 21,360.10877
Overall Steps per Second: 10,471.99416

Timestep Collection Time: 2.34268
Timestep Consumption Time: 2.43577
PPO Batch Consumption Time: 0.27861
Total Iteration Time: 4.77846

Cumulative Model Updates: 247,772
Cumulative Timesteps: 2,067,026,314

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 2067026314...
Checkpoint 2067026314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 69,226.95071
Policy Entropy: 2.51706
Value Function Loss: 0.01653

Mean KL Divergence: 0.01466
SB3 Clip Fraction: 0.11282
Policy Update Magnitude: 0.31782
Value Function Update Magnitude: 0.24679

Collected Steps per Second: 21,293.25157
Overall Steps per Second: 10,282.42215

Timestep Collection Time: 2.34957
Timestep Consumption Time: 2.51601
PPO Batch Consumption Time: 0.29434
Total Iteration Time: 4.86559

Cumulative Model Updates: 247,778
Cumulative Timesteps: 2,067,076,344

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89,281.20953
Policy Entropy: 2.53042
Value Function Loss: 0.01890

Mean KL Divergence: 0.01337
SB3 Clip Fraction: 0.10749
Policy Update Magnitude: 0.31874
Value Function Update Magnitude: 0.22645

Collected Steps per Second: 21,598.97155
Overall Steps per Second: 10,413.18339

Timestep Collection Time: 2.31604
Timestep Consumption Time: 2.48787
PPO Batch Consumption Time: 0.28700
Total Iteration Time: 4.80391

Cumulative Model Updates: 247,784
Cumulative Timesteps: 2,067,126,368

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2067126368...
Checkpoint 2067126368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 153,974.86192
Policy Entropy: 2.54058
Value Function Loss: 0.01933

Mean KL Divergence: 0.01539
SB3 Clip Fraction: 0.12100
Policy Update Magnitude: 0.30097
Value Function Update Magnitude: 0.23970

Collected Steps per Second: 21,078.47735
Overall Steps per Second: 10,217.61794

Timestep Collection Time: 2.37237
Timestep Consumption Time: 2.52172
PPO Batch Consumption Time: 0.29420
Total Iteration Time: 4.89410

Cumulative Model Updates: 247,790
Cumulative Timesteps: 2,067,176,374

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 134,167.21602
Policy Entropy: 2.54696
Value Function Loss: 0.01660

Mean KL Divergence: 0.01091
SB3 Clip Fraction: 0.10083
Policy Update Magnitude: 0.29223
Value Function Update Magnitude: 0.22843

Collected Steps per Second: 21,773.00325
Overall Steps per Second: 10,471.07069

Timestep Collection Time: 2.29734
Timestep Consumption Time: 2.47963
PPO Batch Consumption Time: 0.28691
Total Iteration Time: 4.77697

Cumulative Model Updates: 247,796
Cumulative Timesteps: 2,067,226,394

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2067226394...
Checkpoint 2067226394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 107,880.11139
Policy Entropy: 2.53489
Value Function Loss: 0.01680

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.09038
Policy Update Magnitude: 0.30611
Value Function Update Magnitude: 0.28599

Collected Steps per Second: 20,965.75429
Overall Steps per Second: 10,361.01223

Timestep Collection Time: 2.38570
Timestep Consumption Time: 2.44182
PPO Batch Consumption Time: 0.29066
Total Iteration Time: 4.82752

Cumulative Model Updates: 247,802
Cumulative Timesteps: 2,067,276,412

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88,414.91675
Policy Entropy: 2.52006
Value Function Loss: 0.01547

Mean KL Divergence: 0.01083
SB3 Clip Fraction: 0.09784
Policy Update Magnitude: 0.31168
Value Function Update Magnitude: 0.29505

Collected Steps per Second: 21,805.46420
Overall Steps per Second: 10,717.11909

Timestep Collection Time: 2.29511
Timestep Consumption Time: 2.37461
PPO Batch Consumption Time: 0.27957
Total Iteration Time: 4.66973

Cumulative Model Updates: 247,808
Cumulative Timesteps: 2,067,326,458

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 2067326458...
Checkpoint 2067326458 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 91,769.65538
Policy Entropy: 2.51407
Value Function Loss: 0.01685

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.08712
Policy Update Magnitude: 0.31891
Value Function Update Magnitude: 0.26422

Collected Steps per Second: 21,115.06253
Overall Steps per Second: 10,582.97024

Timestep Collection Time: 2.36930
Timestep Consumption Time: 2.35791
PPO Batch Consumption Time: 0.27945
Total Iteration Time: 4.72722

Cumulative Model Updates: 247,814
Cumulative Timesteps: 2,067,376,486

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84,862.27284
Policy Entropy: 2.53054
Value Function Loss: 0.01522

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.08487
Policy Update Magnitude: 0.31562
Value Function Update Magnitude: 0.27231

Collected Steps per Second: 21,648.04530
Overall Steps per Second: 10,599.22735

Timestep Collection Time: 2.31079
Timestep Consumption Time: 2.40880
PPO Batch Consumption Time: 0.27708
Total Iteration Time: 4.71959

Cumulative Model Updates: 247,820
Cumulative Timesteps: 2,067,426,510

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2067426510...
Checkpoint 2067426510 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 61,540.34736
Policy Entropy: 2.52696
Value Function Loss: 0.01925

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.08023
Policy Update Magnitude: 0.32755
Value Function Update Magnitude: 0.32694

Collected Steps per Second: 21,597.09125
Overall Steps per Second: 10,544.25258

Timestep Collection Time: 2.31550
Timestep Consumption Time: 2.42718
PPO Batch Consumption Time: 0.27984
Total Iteration Time: 4.74268

Cumulative Model Updates: 247,826
Cumulative Timesteps: 2,067,476,518

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 121,808.85334
Policy Entropy: 2.53722
Value Function Loss: 0.01885

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.07122
Policy Update Magnitude: 0.33181
Value Function Update Magnitude: 0.35610

Collected Steps per Second: 21,965.22746
Overall Steps per Second: 10,464.12901

Timestep Collection Time: 2.27742
Timestep Consumption Time: 2.50310
PPO Batch Consumption Time: 0.29429
Total Iteration Time: 4.78052

Cumulative Model Updates: 247,832
Cumulative Timesteps: 2,067,526,542

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2067526542...
Checkpoint 2067526542 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 81,742.67050
Policy Entropy: 2.52432
Value Function Loss: 0.01974

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.07097
Policy Update Magnitude: 0.32609
Value Function Update Magnitude: 0.38104

Collected Steps per Second: 21,732.66167
Overall Steps per Second: 10,559.28471

Timestep Collection Time: 2.30170
Timestep Consumption Time: 2.43556
PPO Batch Consumption Time: 0.27873
Total Iteration Time: 4.73725

Cumulative Model Updates: 247,838
Cumulative Timesteps: 2,067,576,564

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66,126.81868
Policy Entropy: 2.52865
Value Function Loss: 0.01680

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.07735
Policy Update Magnitude: 0.32722
Value Function Update Magnitude: 0.37701

Collected Steps per Second: 21,363.76184
Overall Steps per Second: 10,523.78054

Timestep Collection Time: 2.34163
Timestep Consumption Time: 2.41199
PPO Batch Consumption Time: 0.27876
Total Iteration Time: 4.75361

Cumulative Model Updates: 247,844
Cumulative Timesteps: 2,067,626,590

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2067626590...
Checkpoint 2067626590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 62,226.62805
Policy Entropy: 2.52044
Value Function Loss: 0.01636

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.07385
Policy Update Magnitude: 0.32841
Value Function Update Magnitude: 0.37782

Collected Steps per Second: 20,442.17620
Overall Steps per Second: 10,203.52413

Timestep Collection Time: 2.44661
Timestep Consumption Time: 2.45503
PPO Batch Consumption Time: 0.27930
Total Iteration Time: 4.90164

Cumulative Model Updates: 247,850
Cumulative Timesteps: 2,067,676,604

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49,748.19163
Policy Entropy: 2.51310
Value Function Loss: 0.01518

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.06961
Policy Update Magnitude: 0.31974
Value Function Update Magnitude: 0.37007

Collected Steps per Second: 21,555.79728
Overall Steps per Second: 10,494.76603

Timestep Collection Time: 2.31965
Timestep Consumption Time: 2.44482
PPO Batch Consumption Time: 0.27818
Total Iteration Time: 4.76447

Cumulative Model Updates: 247,856
Cumulative Timesteps: 2,067,726,606

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2067726606...
Checkpoint 2067726606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47,979.65347
Policy Entropy: 2.50130
Value Function Loss: 0.01627

Mean KL Divergence: 0.00696
SB3 Clip Fraction: 0.06215
Policy Update Magnitude: 0.32214
Value Function Update Magnitude: 0.34934

Collected Steps per Second: 21,242.83267
Overall Steps per Second: 10,279.18856

Timestep Collection Time: 2.35515
Timestep Consumption Time: 2.51197
PPO Batch Consumption Time: 0.29262
Total Iteration Time: 4.86712

Cumulative Model Updates: 247,862
Cumulative Timesteps: 2,067,776,636

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57,014.71937
Policy Entropy: 2.49503
Value Function Loss: 0.01757

Mean KL Divergence: 0.00691
SB3 Clip Fraction: 0.06217
Policy Update Magnitude: 0.32780
Value Function Update Magnitude: 0.34412

Collected Steps per Second: 21,999.45426
Overall Steps per Second: 10,497.66169

Timestep Collection Time: 2.27397
Timestep Consumption Time: 2.49148
PPO Batch Consumption Time: 0.29185
Total Iteration Time: 4.76544

Cumulative Model Updates: 247,868
Cumulative Timesteps: 2,067,826,662

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2067826662...
Checkpoint 2067826662 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,195.08743
Policy Entropy: 2.49661
Value Function Loss: 0.01655

Mean KL Divergence: 0.00720
SB3 Clip Fraction: 0.06699
Policy Update Magnitude: 0.32711
Value Function Update Magnitude: 0.36783

Collected Steps per Second: 21,587.52428
Overall Steps per Second: 10,462.69662

Timestep Collection Time: 2.31680
Timestep Consumption Time: 2.46342
PPO Batch Consumption Time: 0.27836
Total Iteration Time: 4.78022

Cumulative Model Updates: 247,874
Cumulative Timesteps: 2,067,876,676

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,429.77332
Policy Entropy: 2.50108
Value Function Loss: 0.01781

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.07074
Policy Update Magnitude: 0.33867
Value Function Update Magnitude: 0.38435

Collected Steps per Second: 22,424.10943
Overall Steps per Second: 10,567.83069

Timestep Collection Time: 2.23108
Timestep Consumption Time: 2.50310
PPO Batch Consumption Time: 0.29110
Total Iteration Time: 4.73418

Cumulative Model Updates: 247,880
Cumulative Timesteps: 2,067,926,706

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2067926706...
Checkpoint 2067926706 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,577.61280
Policy Entropy: 2.53218
Value Function Loss: 0.01507

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.08028
Policy Update Magnitude: 0.32928
Value Function Update Magnitude: 0.39541

Collected Steps per Second: 21,946.69906
Overall Steps per Second: 10,520.67167

Timestep Collection Time: 2.27934
Timestep Consumption Time: 2.47549
PPO Batch Consumption Time: 0.28549
Total Iteration Time: 4.75483

Cumulative Model Updates: 247,886
Cumulative Timesteps: 2,067,976,730

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52,332.70882
Policy Entropy: 2.54725
Value Function Loss: 0.01391

Mean KL Divergence: 0.01155
SB3 Clip Fraction: 0.08007
Policy Update Magnitude: 0.30940
Value Function Update Magnitude: 0.37160

Collected Steps per Second: 22,200.95670
Overall Steps per Second: 10,518.77295

Timestep Collection Time: 2.25279
Timestep Consumption Time: 2.50195
PPO Batch Consumption Time: 0.29255
Total Iteration Time: 4.75474

Cumulative Model Updates: 247,892
Cumulative Timesteps: 2,068,026,744

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2068026744...
Checkpoint 2068026744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 60,293.27163
Policy Entropy: 2.55761
Value Function Loss: 0.01395

Mean KL Divergence: 0.00728
SB3 Clip Fraction: 0.07044
Policy Update Magnitude: 0.29952
Value Function Update Magnitude: 0.32417

Collected Steps per Second: 21,766.59393
Overall Steps per Second: 10,546.53758

Timestep Collection Time: 2.29783
Timestep Consumption Time: 2.44458
PPO Batch Consumption Time: 0.28144
Total Iteration Time: 4.74241

Cumulative Model Updates: 247,898
Cumulative Timesteps: 2,068,076,760

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58,310.27065
Policy Entropy: 2.53819
Value Function Loss: 0.01349

Mean KL Divergence: 0.00638
SB3 Clip Fraction: 0.06000
Policy Update Magnitude: 0.29881
Value Function Update Magnitude: 0.32017

Collected Steps per Second: 22,279.34967
Overall Steps per Second: 10,483.95643

Timestep Collection Time: 2.24504
Timestep Consumption Time: 2.52587
PPO Batch Consumption Time: 0.29317
Total Iteration Time: 4.77091

Cumulative Model Updates: 247,904
Cumulative Timesteps: 2,068,126,778

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2068126778...
Checkpoint 2068126778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 58,310.27065
Policy Entropy: 2.53342
Value Function Loss: 0.01299

Mean KL Divergence: 0.00712
SB3 Clip Fraction: 0.06505
Policy Update Magnitude: 0.29587
Value Function Update Magnitude: 0.32830

Collected Steps per Second: 21,832.83951
Overall Steps per Second: 10,617.23587

Timestep Collection Time: 2.29132
Timestep Consumption Time: 2.42045
PPO Batch Consumption Time: 0.27895
Total Iteration Time: 4.71177

Cumulative Model Updates: 247,910
Cumulative Timesteps: 2,068,176,804

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 108,709.78386
Policy Entropy: 2.53800
Value Function Loss: 0.01342

Mean KL Divergence: 0.00619
SB3 Clip Fraction: 0.05721
Policy Update Magnitude: 0.30221
Value Function Update Magnitude: 0.31976

Collected Steps per Second: 20,927.61435
Overall Steps per Second: 10,565.87459

Timestep Collection Time: 2.39024
Timestep Consumption Time: 2.34406
PPO Batch Consumption Time: 0.27683
Total Iteration Time: 4.73430

Cumulative Model Updates: 247,916
Cumulative Timesteps: 2,068,226,826

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2068226826...
Checkpoint 2068226826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 108,711.94017
Policy Entropy: 2.52787
Value Function Loss: 0.01556

Mean KL Divergence: 0.00716
SB3 Clip Fraction: 0.06349
Policy Update Magnitude: 0.31070
Value Function Update Magnitude: 0.34733

Collected Steps per Second: 20,675.04826
Overall Steps per Second: 10,488.05270

Timestep Collection Time: 2.41992
Timestep Consumption Time: 2.35046
PPO Batch Consumption Time: 0.27907
Total Iteration Time: 4.77038

Cumulative Model Updates: 247,922
Cumulative Timesteps: 2,068,276,858

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68,233.40031
Policy Entropy: 2.52518
Value Function Loss: 0.01831

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.07392
Policy Update Magnitude: 0.32257
Value Function Update Magnitude: 0.37974

Collected Steps per Second: 20,976.20028
Overall Steps per Second: 10,535.32186

Timestep Collection Time: 2.38547
Timestep Consumption Time: 2.36408
PPO Batch Consumption Time: 0.27890
Total Iteration Time: 4.74955

Cumulative Model Updates: 247,928
Cumulative Timesteps: 2,068,326,896

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 2068326896...
Checkpoint 2068326896 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 75,926.31166
Policy Entropy: 2.53275
Value Function Loss: 0.01732

Mean KL Divergence: 0.00759
SB3 Clip Fraction: 0.07342
Policy Update Magnitude: 0.32881
Value Function Update Magnitude: 0.40131

Collected Steps per Second: 20,519.62112
Overall Steps per Second: 10,172.88783

Timestep Collection Time: 2.43689
Timestep Consumption Time: 2.47853
PPO Batch Consumption Time: 0.28833
Total Iteration Time: 4.91542

Cumulative Model Updates: 247,934
Cumulative Timesteps: 2,068,376,900

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46,488.04218
Policy Entropy: 2.53645
Value Function Loss: 0.01664

Mean KL Divergence: 0.00729
SB3 Clip Fraction: 0.06788
Policy Update Magnitude: 0.31952
Value Function Update Magnitude: 0.36857

Collected Steps per Second: 21,613.34669
Overall Steps per Second: 10,484.17549

Timestep Collection Time: 2.31477
Timestep Consumption Time: 2.45718
PPO Batch Consumption Time: 0.28589
Total Iteration Time: 4.77195

Cumulative Model Updates: 247,940
Cumulative Timesteps: 2,068,426,930

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2068426930...
Checkpoint 2068426930 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 96,189.03559
Policy Entropy: 2.52657
Value Function Loss: 0.01544

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.07114
Policy Update Magnitude: 0.32135
Value Function Update Magnitude: 0.31396

Collected Steps per Second: 22,030.58096
Overall Steps per Second: 10,625.82515

Timestep Collection Time: 2.26994
Timestep Consumption Time: 2.43633
PPO Batch Consumption Time: 0.27848
Total Iteration Time: 4.70627

Cumulative Model Updates: 247,946
Cumulative Timesteps: 2,068,476,938

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95,350.30241
Policy Entropy: 2.51986
Value Function Loss: 0.01552

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.08949
Policy Update Magnitude: 0.32208
Value Function Update Magnitude: 0.32096

Collected Steps per Second: 21,954.16276
Overall Steps per Second: 10,375.09473

Timestep Collection Time: 2.27838
Timestep Consumption Time: 2.54278
PPO Batch Consumption Time: 0.29296
Total Iteration Time: 4.82116

Cumulative Model Updates: 247,952
Cumulative Timesteps: 2,068,526,958

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2068526958...
Checkpoint 2068526958 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 52,026.54850
Policy Entropy: 2.52097
Value Function Loss: 0.01610

Mean KL Divergence: 0.01374
SB3 Clip Fraction: 0.11146
Policy Update Magnitude: 0.31154
Value Function Update Magnitude: 0.36825

Collected Steps per Second: 21,805.87825
Overall Steps per Second: 10,446.45905

Timestep Collection Time: 2.29397
Timestep Consumption Time: 2.49445
PPO Batch Consumption Time: 0.29135
Total Iteration Time: 4.78842

Cumulative Model Updates: 247,958
Cumulative Timesteps: 2,068,576,980

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57,581.23322
Policy Entropy: 2.51843
Value Function Loss: 0.01470

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.09237
Policy Update Magnitude: 0.30569
Value Function Update Magnitude: 0.39843

Collected Steps per Second: 22,205.39780
Overall Steps per Second: 10,683.04557

Timestep Collection Time: 2.25188
Timestep Consumption Time: 2.42880
PPO Batch Consumption Time: 0.27834
Total Iteration Time: 4.68069

Cumulative Model Updates: 247,964
Cumulative Timesteps: 2,068,626,984

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2068626984...
Checkpoint 2068626984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 65,970.11603
Policy Entropy: 2.51476
Value Function Loss: 0.01393

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.08443
Policy Update Magnitude: 0.30673
Value Function Update Magnitude: 0.35769

Collected Steps per Second: 22,039.06314
Overall Steps per Second: 10,645.46398

Timestep Collection Time: 2.26988
Timestep Consumption Time: 2.42940
PPO Batch Consumption Time: 0.27851
Total Iteration Time: 4.69928

Cumulative Model Updates: 247,970
Cumulative Timesteps: 2,068,677,010

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87,446.98578
Policy Entropy: 2.51759
Value Function Loss: 0.01446

Mean KL Divergence: 0.00731
SB3 Clip Fraction: 0.06740
Policy Update Magnitude: 0.31071
Value Function Update Magnitude: 0.29245

Collected Steps per Second: 22,172.04606
Overall Steps per Second: 10,491.24484

Timestep Collection Time: 2.25672
Timestep Consumption Time: 2.51259
PPO Batch Consumption Time: 0.28987
Total Iteration Time: 4.76931

Cumulative Model Updates: 247,976
Cumulative Timesteps: 2,068,727,046

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 2068727046...
Checkpoint 2068727046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89,827.85835
Policy Entropy: 2.52104
Value Function Loss: 0.01423

Mean KL Divergence: 0.00685
SB3 Clip Fraction: 0.06223
Policy Update Magnitude: 0.30963
Value Function Update Magnitude: 0.26915

Collected Steps per Second: 21,778.55594
Overall Steps per Second: 10,570.80978

Timestep Collection Time: 2.29657
Timestep Consumption Time: 2.43495
PPO Batch Consumption Time: 0.27869
Total Iteration Time: 4.73152

Cumulative Model Updates: 247,982
Cumulative Timesteps: 2,068,777,062

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 104,519.00774
Policy Entropy: 2.51902
Value Function Loss: 0.01594

Mean KL Divergence: 0.00701
SB3 Clip Fraction: 0.06515
Policy Update Magnitude: 0.31675
Value Function Update Magnitude: 0.34621

Collected Steps per Second: 21,603.62405
Overall Steps per Second: 10,493.31971

Timestep Collection Time: 2.31443
Timestep Consumption Time: 2.45051
PPO Batch Consumption Time: 0.27883
Total Iteration Time: 4.76494

Cumulative Model Updates: 247,988
Cumulative Timesteps: 2,068,827,062

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2068827062...
Checkpoint 2068827062 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 54,027.57866
Policy Entropy: 2.50269
Value Function Loss: 0.01582

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.07296
Policy Update Magnitude: 0.32349
Value Function Update Magnitude: 0.35306

Collected Steps per Second: 21,529.41660
Overall Steps per Second: 10,406.78168

Timestep Collection Time: 2.32361
Timestep Consumption Time: 2.48345
PPO Batch Consumption Time: 0.29089
Total Iteration Time: 4.80706

Cumulative Model Updates: 247,994
Cumulative Timesteps: 2,068,877,088

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76,658.45866
Policy Entropy: 2.49891
Value Function Loss: 0.01639

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.07427
Policy Update Magnitude: 0.33387
Value Function Update Magnitude: 0.37223

Collected Steps per Second: 21,322.90694
Overall Steps per Second: 10,285.91652

Timestep Collection Time: 2.34574
Timestep Consumption Time: 2.51703
PPO Batch Consumption Time: 0.29134
Total Iteration Time: 4.86277

Cumulative Model Updates: 248,000
Cumulative Timesteps: 2,068,927,106

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2068927106...
Checkpoint 2068927106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 91,237.25766
Policy Entropy: 2.50709
Value Function Loss: 0.01624

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.07581
Policy Update Magnitude: 0.33641
Value Function Update Magnitude: 0.39423

Collected Steps per Second: 21,671.71687
Overall Steps per Second: 10,571.05782

Timestep Collection Time: 2.30743
Timestep Consumption Time: 2.42303
PPO Batch Consumption Time: 0.27920
Total Iteration Time: 4.73046

Cumulative Model Updates: 248,006
Cumulative Timesteps: 2,068,977,112

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 72,139.05991
Policy Entropy: 2.52148
Value Function Loss: 0.01691

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.08050
Policy Update Magnitude: 0.32761
Value Function Update Magnitude: 0.36499

Collected Steps per Second: 21,922.85444
Overall Steps per Second: 10,618.66757

Timestep Collection Time: 2.28072
Timestep Consumption Time: 2.42796
PPO Batch Consumption Time: 0.27689
Total Iteration Time: 4.70869

Cumulative Model Updates: 248,012
Cumulative Timesteps: 2,069,027,112

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2069027112...
Checkpoint 2069027112 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 64,452.90480
Policy Entropy: 2.51693
Value Function Loss: 0.01896

Mean KL Divergence: 0.01198
SB3 Clip Fraction: 0.09082
Policy Update Magnitude: 0.33579
Value Function Update Magnitude: 0.38370

Collected Steps per Second: 21,990.66296
Overall Steps per Second: 10,622.92215

Timestep Collection Time: 2.27378
Timestep Consumption Time: 2.43321
PPO Batch Consumption Time: 0.27748
Total Iteration Time: 4.70699

Cumulative Model Updates: 248,018
Cumulative Timesteps: 2,069,077,114

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46,845.45242
Policy Entropy: 2.51872
Value Function Loss: 0.01837

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.08916
Policy Update Magnitude: 0.33727
Value Function Update Magnitude: 0.41931

Collected Steps per Second: 22,348.41397
Overall Steps per Second: 10,607.53180

Timestep Collection Time: 2.23873
Timestep Consumption Time: 2.47792
PPO Batch Consumption Time: 0.28723
Total Iteration Time: 4.71665

Cumulative Model Updates: 248,024
Cumulative Timesteps: 2,069,127,146

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2069127146...
Checkpoint 2069127146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,909.98928
Policy Entropy: 2.51529
Value Function Loss: 0.01741

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.09013
Policy Update Magnitude: 0.33248
Value Function Update Magnitude: 0.39301

Collected Steps per Second: 21,564.75735
Overall Steps per Second: 10,389.84305

Timestep Collection Time: 2.31934
Timestep Consumption Time: 2.49459
PPO Batch Consumption Time: 0.28917
Total Iteration Time: 4.81393

Cumulative Model Updates: 248,030
Cumulative Timesteps: 2,069,177,162

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54,447.26769
Policy Entropy: 2.53393
Value Function Loss: 0.01639

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.09166
Policy Update Magnitude: 0.32448
Value Function Update Magnitude: 0.38065

Collected Steps per Second: 22,068.78710
Overall Steps per Second: 10,472.82627

Timestep Collection Time: 2.26664
Timestep Consumption Time: 2.50972
PPO Batch Consumption Time: 0.29338
Total Iteration Time: 4.77636

Cumulative Model Updates: 248,036
Cumulative Timesteps: 2,069,227,184

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2069227184...
Checkpoint 2069227184 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 62,047.57414
Policy Entropy: 2.55778
Value Function Loss: 0.01563

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.08622
Policy Update Magnitude: 0.31779
Value Function Update Magnitude: 0.36661

Collected Steps per Second: 21,752.11205
Overall Steps per Second: 10,573.51274

Timestep Collection Time: 2.29890
Timestep Consumption Time: 2.43046
PPO Batch Consumption Time: 0.27911
Total Iteration Time: 4.72936

Cumulative Model Updates: 248,042
Cumulative Timesteps: 2,069,277,190

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59,356.30453
Policy Entropy: 2.54853
Value Function Loss: 0.01669

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.07584
Policy Update Magnitude: 0.31580
Value Function Update Magnitude: 0.35392

Collected Steps per Second: 21,942.02926
Overall Steps per Second: 10,496.31738

Timestep Collection Time: 2.27964
Timestep Consumption Time: 2.48584
PPO Batch Consumption Time: 0.28860
Total Iteration Time: 4.76548

Cumulative Model Updates: 248,048
Cumulative Timesteps: 2,069,327,210

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2069327210...
Checkpoint 2069327210 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 69,197.26710
Policy Entropy: 2.54006
Value Function Loss: 0.01548

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.09107
Policy Update Magnitude: 0.31229
Value Function Update Magnitude: 0.37427

Collected Steps per Second: 21,434.12104
Overall Steps per Second: 10,350.59104

Timestep Collection Time: 2.33376
Timestep Consumption Time: 2.49901
PPO Batch Consumption Time: 0.29251
Total Iteration Time: 4.83277

Cumulative Model Updates: 248,054
Cumulative Timesteps: 2,069,377,232

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58,248.82591
Policy Entropy: 2.49501
Value Function Loss: 0.01688

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.08632
Policy Update Magnitude: 0.31797
Value Function Update Magnitude: 0.35072

Collected Steps per Second: 21,640.97376
Overall Steps per Second: 10,393.04901

Timestep Collection Time: 2.31108
Timestep Consumption Time: 2.50118
PPO Batch Consumption Time: 0.29224
Total Iteration Time: 4.81225

Cumulative Model Updates: 248,060
Cumulative Timesteps: 2,069,427,246

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2069427246...
Checkpoint 2069427246 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,365.39212
Policy Entropy: 2.50492
Value Function Loss: 0.01497

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.08479
Policy Update Magnitude: 0.31839
Value Function Update Magnitude: 0.33352

Collected Steps per Second: 20,190.96732
Overall Steps per Second: 10,048.36009

Timestep Collection Time: 2.47735
Timestep Consumption Time: 2.50058
PPO Batch Consumption Time: 0.29225
Total Iteration Time: 4.97793

Cumulative Model Updates: 248,066
Cumulative Timesteps: 2,069,477,266

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46,868.39343
Policy Entropy: 2.50209
Value Function Loss: 0.01718

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.07647
Policy Update Magnitude: 0.31693
Value Function Update Magnitude: 0.33838

Collected Steps per Second: 21,893.35829
Overall Steps per Second: 10,442.86061

Timestep Collection Time: 2.28425
Timestep Consumption Time: 2.50466
PPO Batch Consumption Time: 0.28928
Total Iteration Time: 4.78892

Cumulative Model Updates: 248,072
Cumulative Timesteps: 2,069,527,276

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2069527276...
Checkpoint 2069527276 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,287.36593
Policy Entropy: 2.55191
Value Function Loss: 0.01633

Mean KL Divergence: 0.01067
SB3 Clip Fraction: 0.08809
Policy Update Magnitude: 0.31318
Value Function Update Magnitude: 0.32575

Collected Steps per Second: 21,118.26741
Overall Steps per Second: 10,466.48324

Timestep Collection Time: 2.36819
Timestep Consumption Time: 2.41011
PPO Batch Consumption Time: 0.28853
Total Iteration Time: 4.77830

Cumulative Model Updates: 248,078
Cumulative Timesteps: 2,069,577,288

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,627.69120
Policy Entropy: 2.57250
Value Function Loss: 0.02042

Mean KL Divergence: 0.01183
SB3 Clip Fraction: 0.09732
Policy Update Magnitude: 0.31604
Value Function Update Magnitude: 0.33136

Collected Steps per Second: 21,486.39030
Overall Steps per Second: 10,544.42398

Timestep Collection Time: 2.32780
Timestep Consumption Time: 2.41556
PPO Batch Consumption Time: 0.29318
Total Iteration Time: 4.74336

Cumulative Model Updates: 248,084
Cumulative Timesteps: 2,069,627,304

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2069627304...
Checkpoint 2069627304 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43,262.03221
Policy Entropy: 2.56547
Value Function Loss: 0.01899

Mean KL Divergence: 0.01133
SB3 Clip Fraction: 0.09150
Policy Update Magnitude: 0.32252
Value Function Update Magnitude: 0.33492

Collected Steps per Second: 21,055.38896
Overall Steps per Second: 10,489.49223

Timestep Collection Time: 2.37602
Timestep Consumption Time: 2.39333
PPO Batch Consumption Time: 0.27881
Total Iteration Time: 4.76934

Cumulative Model Updates: 248,090
Cumulative Timesteps: 2,069,677,332

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,613.92168
Policy Entropy: 2.56424
Value Function Loss: 0.01938

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.09084
Policy Update Magnitude: 0.32427
Value Function Update Magnitude: 0.33411

Collected Steps per Second: 21,912.58311
Overall Steps per Second: 10,492.06686

Timestep Collection Time: 2.28234
Timestep Consumption Time: 2.48431
PPO Batch Consumption Time: 0.29060
Total Iteration Time: 4.76665

Cumulative Model Updates: 248,096
Cumulative Timesteps: 2,069,727,344

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2069727344...
Checkpoint 2069727344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,613.92168
Policy Entropy: 2.54247
Value Function Loss: 0.01502

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.07702
Policy Update Magnitude: 0.31537
Value Function Update Magnitude: 0.34749

Collected Steps per Second: 21,581.94947
Overall Steps per Second: 10,591.54759

Timestep Collection Time: 2.31694
Timestep Consumption Time: 2.40419
PPO Batch Consumption Time: 0.27882
Total Iteration Time: 4.72112

Cumulative Model Updates: 248,102
Cumulative Timesteps: 2,069,777,348

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,613.92168
Policy Entropy: 2.53974
Value Function Loss: 0.01321

Mean KL Divergence: 0.01139
SB3 Clip Fraction: 0.06947
Policy Update Magnitude: 0.29907
Value Function Update Magnitude: 0.31980

Collected Steps per Second: 21,250.97900
Overall Steps per Second: 10,484.62231

Timestep Collection Time: 2.35368
Timestep Consumption Time: 2.41693
PPO Batch Consumption Time: 0.27862
Total Iteration Time: 4.77061

Cumulative Model Updates: 248,108
Cumulative Timesteps: 2,069,827,366

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2069827366...
Checkpoint 2069827366 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,055.89979
Policy Entropy: 2.52366
Value Function Loss: 0.01406

Mean KL Divergence: 0.01104
SB3 Clip Fraction: 0.06598
Policy Update Magnitude: 0.30491
Value Function Update Magnitude: 0.29889

Collected Steps per Second: 21,528.22593
Overall Steps per Second: 10,368.21512

Timestep Collection Time: 2.32281
Timestep Consumption Time: 2.50020
PPO Batch Consumption Time: 0.29255
Total Iteration Time: 4.82301

Cumulative Model Updates: 248,114
Cumulative Timesteps: 2,069,877,372

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,661.95164
Policy Entropy: 2.49269
Value Function Loss: 0.01481

Mean KL Divergence: 0.00688
SB3 Clip Fraction: 0.06591
Policy Update Magnitude: 0.31529
Value Function Update Magnitude: 0.32796

Collected Steps per Second: 21,658.46422
Overall Steps per Second: 10,379.29035

Timestep Collection Time: 2.30884
Timestep Consumption Time: 2.50902
PPO Batch Consumption Time: 0.29363
Total Iteration Time: 4.81786

Cumulative Model Updates: 248,120
Cumulative Timesteps: 2,069,927,378

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2069927378...
Checkpoint 2069927378 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 77,604.31232
Policy Entropy: 2.48929
Value Function Loss: 0.01550

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.06948
Policy Update Magnitude: 0.32476
Value Function Update Magnitude: 0.34690

Collected Steps per Second: 21,519.78558
Overall Steps per Second: 10,526.98858

Timestep Collection Time: 2.32363
Timestep Consumption Time: 2.42645
PPO Batch Consumption Time: 0.27843
Total Iteration Time: 4.75008

Cumulative Model Updates: 248,126
Cumulative Timesteps: 2,069,977,382

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77,604.31232
Policy Entropy: 2.52852
Value Function Loss: 0.01311

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.07134
Policy Update Magnitude: 0.31055
Value Function Update Magnitude: 0.34971

Collected Steps per Second: 21,739.53946
Overall Steps per Second: 10,528.99475

Timestep Collection Time: 2.30134
Timestep Consumption Time: 2.45030
PPO Batch Consumption Time: 0.27835
Total Iteration Time: 4.75164

Cumulative Model Updates: 248,132
Cumulative Timesteps: 2,070,027,412

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2070027412...
Checkpoint 2070027412 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 58,490.96649
Policy Entropy: 2.57243
Value Function Loss: 0.01430

Mean KL Divergence: 0.00701
SB3 Clip Fraction: 0.06400
Policy Update Magnitude: 0.29942
Value Function Update Magnitude: 0.33006

Collected Steps per Second: 21,962.50507
Overall Steps per Second: 10,541.35697

Timestep Collection Time: 2.27770
Timestep Consumption Time: 2.46780
PPO Batch Consumption Time: 0.27900
Total Iteration Time: 4.74550

Cumulative Model Updates: 248,138
Cumulative Timesteps: 2,070,077,436

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68,946.21578
Policy Entropy: 2.55558
Value Function Loss: 0.01365

Mean KL Divergence: 0.00651
SB3 Clip Fraction: 0.06065
Policy Update Magnitude: 0.29447
Value Function Update Magnitude: 0.29859

Collected Steps per Second: 22,085.68722
Overall Steps per Second: 10,528.72780

Timestep Collection Time: 2.26418
Timestep Consumption Time: 2.48530
PPO Batch Consumption Time: 0.28719
Total Iteration Time: 4.74948

Cumulative Model Updates: 248,144
Cumulative Timesteps: 2,070,127,442

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2070127442...
Checkpoint 2070127442 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 54,343.35796
Policy Entropy: 2.51836
Value Function Loss: 0.01751

Mean KL Divergence: 0.00783
SB3 Clip Fraction: 0.06898
Policy Update Magnitude: 0.31698
Value Function Update Magnitude: 0.32022

Collected Steps per Second: 21,850.92945
Overall Steps per Second: 10,581.35296

Timestep Collection Time: 2.28860
Timestep Consumption Time: 2.43745
PPO Batch Consumption Time: 0.27890
Total Iteration Time: 4.72605

Cumulative Model Updates: 248,150
Cumulative Timesteps: 2,070,177,450

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 103,341.85399
Policy Entropy: 2.49306
Value Function Loss: 0.01653

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.07018
Policy Update Magnitude: 0.32831
Value Function Update Magnitude: 0.36786

Collected Steps per Second: 22,375.23286
Overall Steps per Second: 10,512.29649

Timestep Collection Time: 2.23470
Timestep Consumption Time: 2.52182
PPO Batch Consumption Time: 0.29288
Total Iteration Time: 4.75652

Cumulative Model Updates: 248,156
Cumulative Timesteps: 2,070,227,452

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2070227452...
Checkpoint 2070227452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 109,489.02396
Policy Entropy: 2.50232
Value Function Loss: 0.01549

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.07725
Policy Update Magnitude: 0.31806
Value Function Update Magnitude: 0.35754

Collected Steps per Second: 22,309.91140
Overall Steps per Second: 10,719.24263

Timestep Collection Time: 2.24277
Timestep Consumption Time: 2.42510
PPO Batch Consumption Time: 0.27737
Total Iteration Time: 4.66787

Cumulative Model Updates: 248,162
Cumulative Timesteps: 2,070,277,488

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97,175.79233
Policy Entropy: 2.53648
Value Function Loss: 0.01405

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.07161
Policy Update Magnitude: 0.31265
Value Function Update Magnitude: 0.33727

Collected Steps per Second: 22,130.20088
Overall Steps per Second: 10,474.02657

Timestep Collection Time: 2.25972
Timestep Consumption Time: 2.51476
PPO Batch Consumption Time: 0.29268
Total Iteration Time: 4.77448

Cumulative Model Updates: 248,168
Cumulative Timesteps: 2,070,327,496

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2070327496...
Checkpoint 2070327496 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 56,659.45661
Policy Entropy: 2.54706
Value Function Loss: 0.01582

Mean KL Divergence: 0.00741
SB3 Clip Fraction: 0.06848
Policy Update Magnitude: 0.31386
Value Function Update Magnitude: 0.33266

Collected Steps per Second: 21,278.53909
Overall Steps per Second: 10,476.23514

Timestep Collection Time: 2.35063
Timestep Consumption Time: 2.42379
PPO Batch Consumption Time: 0.27851
Total Iteration Time: 4.77443

Cumulative Model Updates: 248,174
Cumulative Timesteps: 2,070,377,514

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63,570.46789
Policy Entropy: 2.55896
Value Function Loss: 0.01493

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.08489
Policy Update Magnitude: 0.30923
Value Function Update Magnitude: 0.35902

Collected Steps per Second: 21,664.89916
Overall Steps per Second: 10,598.19137

Timestep Collection Time: 2.30862
Timestep Consumption Time: 2.41068
PPO Batch Consumption Time: 0.27702
Total Iteration Time: 4.71930

Cumulative Model Updates: 248,180
Cumulative Timesteps: 2,070,427,530

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2070427530...
Checkpoint 2070427530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 73,968.92659
Policy Entropy: 2.56137
Value Function Loss: 0.01421

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.08195
Policy Update Magnitude: 0.29624
Value Function Update Magnitude: 0.34602

Collected Steps per Second: 21,520.06385
Overall Steps per Second: 10,530.59129

Timestep Collection Time: 2.32397
Timestep Consumption Time: 2.42524
PPO Batch Consumption Time: 0.27898
Total Iteration Time: 4.74921

Cumulative Model Updates: 248,186
Cumulative Timesteps: 2,070,477,542

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68,991.39733
Policy Entropy: 2.55300
Value Function Loss: 0.01253

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.08070
Policy Update Magnitude: 0.29046
Value Function Update Magnitude: 0.30450

Collected Steps per Second: 21,712.92911
Overall Steps per Second: 10,559.61326

Timestep Collection Time: 2.30324
Timestep Consumption Time: 2.43273
PPO Batch Consumption Time: 0.27782
Total Iteration Time: 4.73597

Cumulative Model Updates: 248,192
Cumulative Timesteps: 2,070,527,552

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2070527552...
Checkpoint 2070527552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 68,991.39733
Policy Entropy: 2.55305
Value Function Loss: 0.01248

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.08391
Policy Update Magnitude: 0.28988
Value Function Update Magnitude: 0.29048

Collected Steps per Second: 21,961.61076
Overall Steps per Second: 10,556.58556

Timestep Collection Time: 2.27879
Timestep Consumption Time: 2.46194
PPO Batch Consumption Time: 0.27896
Total Iteration Time: 4.74074

Cumulative Model Updates: 248,198
Cumulative Timesteps: 2,070,577,598

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 148,939.75732
Policy Entropy: 2.52714
Value Function Loss: 0.01625

Mean KL Divergence: 0.01277
SB3 Clip Fraction: 0.09802
Policy Update Magnitude: 0.28795
Value Function Update Magnitude: 0.29957

Collected Steps per Second: 22,064.94270
Overall Steps per Second: 10,451.75492

Timestep Collection Time: 2.26830
Timestep Consumption Time: 2.52037
PPO Batch Consumption Time: 0.29367
Total Iteration Time: 4.78867

Cumulative Model Updates: 248,204
Cumulative Timesteps: 2,070,627,648

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 2070627648...
Checkpoint 2070627648 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 101,404.57534
Policy Entropy: 2.53592
Value Function Loss: 0.01685

Mean KL Divergence: 0.01303
SB3 Clip Fraction: 0.10353
Policy Update Magnitude: 0.31396
Value Function Update Magnitude: 0.32780

Collected Steps per Second: 22,079.05625
Overall Steps per Second: 10,665.90741

Timestep Collection Time: 2.26540
Timestep Consumption Time: 2.42412
PPO Batch Consumption Time: 0.27906
Total Iteration Time: 4.68952

Cumulative Model Updates: 248,210
Cumulative Timesteps: 2,070,677,666

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88,259.04451
Policy Entropy: 2.49210
Value Function Loss: 0.01822

Mean KL Divergence: 0.01396
SB3 Clip Fraction: 0.11042
Policy Update Magnitude: 0.32327
Value Function Update Magnitude: 0.34500

Collected Steps per Second: 22,042.14418
Overall Steps per Second: 10,455.70073

Timestep Collection Time: 2.27029
Timestep Consumption Time: 2.51581
PPO Batch Consumption Time: 0.29319
Total Iteration Time: 4.78610

Cumulative Model Updates: 248,216
Cumulative Timesteps: 2,070,727,708

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 2070727708...
Checkpoint 2070727708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 90,255.37259
Policy Entropy: 2.49309
Value Function Loss: 0.01721

Mean KL Divergence: 0.01166
SB3 Clip Fraction: 0.10486
Policy Update Magnitude: 0.33037
Value Function Update Magnitude: 0.33808

Collected Steps per Second: 21,783.71662
Overall Steps per Second: 10,579.69442

Timestep Collection Time: 2.29658
Timestep Consumption Time: 2.43210
PPO Batch Consumption Time: 0.27871
Total Iteration Time: 4.72868

Cumulative Model Updates: 248,222
Cumulative Timesteps: 2,070,777,736

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90,498.29379
Policy Entropy: 2.49227
Value Function Loss: 0.01803

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.08833
Policy Update Magnitude: 0.33906
Value Function Update Magnitude: 0.36402

Collected Steps per Second: 22,183.10287
Overall Steps per Second: 10,515.89912

Timestep Collection Time: 2.25532
Timestep Consumption Time: 2.50224
PPO Batch Consumption Time: 0.29206
Total Iteration Time: 4.75756

Cumulative Model Updates: 248,228
Cumulative Timesteps: 2,070,827,766

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2070827766...
Checkpoint 2070827766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 79,047.36021
Policy Entropy: 2.50455
Value Function Loss: 0.01580

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.07376
Policy Update Magnitude: 0.33144
Value Function Update Magnitude: 0.35240

Collected Steps per Second: 21,547.41349
Overall Steps per Second: 10,567.26306

Timestep Collection Time: 2.32084
Timestep Consumption Time: 2.41152
PPO Batch Consumption Time: 0.27839
Total Iteration Time: 4.73235

Cumulative Model Updates: 248,234
Cumulative Timesteps: 2,070,877,774

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 74,220.12511
Policy Entropy: 2.51166
Value Function Loss: 0.01624

Mean KL Divergence: 0.00758
SB3 Clip Fraction: 0.06958
Policy Update Magnitude: 0.32928
Value Function Update Magnitude: 0.34062

Collected Steps per Second: 21,311.63248
Overall Steps per Second: 10,466.34383

Timestep Collection Time: 2.34623
Timestep Consumption Time: 2.43118
PPO Batch Consumption Time: 0.27838
Total Iteration Time: 4.77741

Cumulative Model Updates: 248,240
Cumulative Timesteps: 2,070,927,776

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2070927776...
Checkpoint 2070927776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 67,623.15756
Policy Entropy: 2.52183
Value Function Loss: 0.01490

Mean KL Divergence: 0.00687
SB3 Clip Fraction: 0.06388
Policy Update Magnitude: 0.31888
Value Function Update Magnitude: 0.34047

Collected Steps per Second: 20,802.15557
Overall Steps per Second: 10,342.60660

Timestep Collection Time: 2.40456
Timestep Consumption Time: 2.43175
PPO Batch Consumption Time: 0.29397
Total Iteration Time: 4.83631

Cumulative Model Updates: 248,246
Cumulative Timesteps: 2,070,977,796

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 69,969.07148
Policy Entropy: 2.55051
Value Function Loss: 0.01396

Mean KL Divergence: 0.00701
SB3 Clip Fraction: 0.06361
Policy Update Magnitude: 0.30364
Value Function Update Magnitude: 0.32929

Collected Steps per Second: 21,102.44050
Overall Steps per Second: 10,382.01416

Timestep Collection Time: 2.37015
Timestep Consumption Time: 2.44741
PPO Batch Consumption Time: 0.29049
Total Iteration Time: 4.81756

Cumulative Model Updates: 248,252
Cumulative Timesteps: 2,071,027,812

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2071027812...
Checkpoint 2071027812 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48,282.24011
Policy Entropy: 2.56543
Value Function Loss: 0.01422

Mean KL Divergence: 0.00707
SB3 Clip Fraction: 0.06429
Policy Update Magnitude: 0.29427
Value Function Update Magnitude: 0.30683

Collected Steps per Second: 21,344.49762
Overall Steps per Second: 10,594.51459

Timestep Collection Time: 2.34290
Timestep Consumption Time: 2.37728
PPO Batch Consumption Time: 0.27793
Total Iteration Time: 4.72018

Cumulative Model Updates: 248,258
Cumulative Timesteps: 2,071,077,820

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67,649.68440
Policy Entropy: 2.55235
Value Function Loss: 0.01500

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.07561
Policy Update Magnitude: 0.30187
Value Function Update Magnitude: 0.29849

Collected Steps per Second: 21,484.11492
Overall Steps per Second: 10,500.85927

Timestep Collection Time: 2.32730
Timestep Consumption Time: 2.43421
PPO Batch Consumption Time: 0.27883
Total Iteration Time: 4.76152

Cumulative Model Updates: 248,264
Cumulative Timesteps: 2,071,127,820

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2071127820...
Checkpoint 2071127820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 72,925.62324
Policy Entropy: 2.52344
Value Function Loss: 0.01578

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.07872
Policy Update Magnitude: 0.30452
Value Function Update Magnitude: 0.31101

Collected Steps per Second: 21,434.46595
Overall Steps per Second: 10,551.13821

Timestep Collection Time: 2.33316
Timestep Consumption Time: 2.40661
PPO Batch Consumption Time: 0.27915
Total Iteration Time: 4.73977

Cumulative Model Updates: 248,270
Cumulative Timesteps: 2,071,177,830

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62,697.11163
Policy Entropy: 2.52710
Value Function Loss: 0.01520

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.08722
Policy Update Magnitude: 0.30767
Value Function Update Magnitude: 0.30550

Collected Steps per Second: 21,992.22911
Overall Steps per Second: 10,537.25137

Timestep Collection Time: 2.27544
Timestep Consumption Time: 2.47362
PPO Batch Consumption Time: 0.29003
Total Iteration Time: 4.74906

Cumulative Model Updates: 248,276
Cumulative Timesteps: 2,071,227,872

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 2071227872...
Checkpoint 2071227872 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 71,217.21857
Policy Entropy: 2.50625
Value Function Loss: 0.01623

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.07947
Policy Update Magnitude: 0.31139
Value Function Update Magnitude: 0.29721

Collected Steps per Second: 21,865.44965
Overall Steps per Second: 10,594.84101

Timestep Collection Time: 2.28827
Timestep Consumption Time: 2.43422
PPO Batch Consumption Time: 0.27944
Total Iteration Time: 4.72249

Cumulative Model Updates: 248,282
Cumulative Timesteps: 2,071,277,906

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76,732.78113
Policy Entropy: 2.52230
Value Function Loss: 0.01734

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.07938
Policy Update Magnitude: 0.31789
Value Function Update Magnitude: 0.28861

Collected Steps per Second: 22,158.35790
Overall Steps per Second: 10,487.40597

Timestep Collection Time: 2.25648
Timestep Consumption Time: 2.51114
PPO Batch Consumption Time: 0.29183
Total Iteration Time: 4.76762

Cumulative Model Updates: 248,288
Cumulative Timesteps: 2,071,327,906

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2071327906...
Checkpoint 2071327906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 103,587.30930
Policy Entropy: 2.51144
Value Function Loss: 0.01917

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.08654
Policy Update Magnitude: 0.32730
Value Function Update Magnitude: 0.27810

Collected Steps per Second: 21,588.66517
Overall Steps per Second: 10,422.18145

Timestep Collection Time: 2.31788
Timestep Consumption Time: 2.48342
PPO Batch Consumption Time: 0.28887
Total Iteration Time: 4.80130

Cumulative Model Updates: 248,294
Cumulative Timesteps: 2,071,377,946

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89,752.60342
Policy Entropy: 2.50258
Value Function Loss: 0.02013

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.08123
Policy Update Magnitude: 0.33106
Value Function Update Magnitude: 0.31048

Collected Steps per Second: 20,450.28563
Overall Steps per Second: 10,196.06078

Timestep Collection Time: 2.44632
Timestep Consumption Time: 2.46028
PPO Batch Consumption Time: 0.27885
Total Iteration Time: 4.90660

Cumulative Model Updates: 248,300
Cumulative Timesteps: 2,071,427,974

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2071427974...
Checkpoint 2071427974 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 77,426.83725
Policy Entropy: 2.50595
Value Function Loss: 0.01692

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.08233
Policy Update Magnitude: 0.32634
Value Function Update Magnitude: 0.34882

Collected Steps per Second: 21,294.61326
Overall Steps per Second: 10,278.39025

Timestep Collection Time: 2.35008
Timestep Consumption Time: 2.51878
PPO Batch Consumption Time: 0.29349
Total Iteration Time: 4.86886

Cumulative Model Updates: 248,306
Cumulative Timesteps: 2,071,478,018

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77,426.83725
Policy Entropy: 2.50169
Value Function Loss: 0.01469

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.07922
Policy Update Magnitude: 0.30951
Value Function Update Magnitude: 0.31948

Collected Steps per Second: 22,080.26672
Overall Steps per Second: 10,435.51778

Timestep Collection Time: 2.26447
Timestep Consumption Time: 2.52686
PPO Batch Consumption Time: 0.28923
Total Iteration Time: 4.79133

Cumulative Model Updates: 248,312
Cumulative Timesteps: 2,071,528,018

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2071528018...
Checkpoint 2071528018 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 77,426.83725
Policy Entropy: 2.52658
Value Function Loss: 0.01298

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.07803
Policy Update Magnitude: 0.30433
Value Function Update Magnitude: 0.27541

Collected Steps per Second: 21,186.29617
Overall Steps per Second: 10,555.50136

Timestep Collection Time: 2.36049
Timestep Consumption Time: 2.37733
PPO Batch Consumption Time: 0.27877
Total Iteration Time: 4.73781

Cumulative Model Updates: 248,318
Cumulative Timesteps: 2,071,578,028

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63,234.00110
Policy Entropy: 2.51661
Value Function Loss: 0.01746

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.09250
Policy Update Magnitude: 0.31063
Value Function Update Magnitude: 0.23419

Collected Steps per Second: 21,456.36918
Overall Steps per Second: 10,565.36333

Timestep Collection Time: 2.33115
Timestep Consumption Time: 2.40300
PPO Batch Consumption Time: 0.28749
Total Iteration Time: 4.73415

Cumulative Model Updates: 248,324
Cumulative Timesteps: 2,071,628,046

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2071628046...
Checkpoint 2071628046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40,092.68481
Policy Entropy: 2.52844
Value Function Loss: 0.01844

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.08435
Policy Update Magnitude: 0.31894
Value Function Update Magnitude: 0.23131

Collected Steps per Second: 21,120.54221
Overall Steps per Second: 10,575.40038

Timestep Collection Time: 2.36850
Timestep Consumption Time: 2.36172
PPO Batch Consumption Time: 0.27923
Total Iteration Time: 4.73022

Cumulative Model Updates: 248,330
Cumulative Timesteps: 2,071,678,070

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62,916.44789
Policy Entropy: 2.51553
Value Function Loss: 0.01845

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.07910
Policy Update Magnitude: 0.31516
Value Function Update Magnitude: 0.29168

Collected Steps per Second: 21,760.14979
Overall Steps per Second: 10,579.60940

Timestep Collection Time: 2.29778
Timestep Consumption Time: 2.42829
PPO Batch Consumption Time: 0.29239
Total Iteration Time: 4.72607

Cumulative Model Updates: 248,336
Cumulative Timesteps: 2,071,728,070

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2071728070...
Checkpoint 2071728070 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46,113.97025
Policy Entropy: 2.53515
Value Function Loss: 0.01626

Mean KL Divergence: 0.00704
SB3 Clip Fraction: 0.06790
Policy Update Magnitude: 0.31253
Value Function Update Magnitude: 0.30294

Collected Steps per Second: 20,978.76407
Overall Steps per Second: 10,277.99213

Timestep Collection Time: 2.38441
Timestep Consumption Time: 2.48249
PPO Batch Consumption Time: 0.29024
Total Iteration Time: 4.86690

Cumulative Model Updates: 248,342
Cumulative Timesteps: 2,071,778,092

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75,790.75781
Policy Entropy: 2.53885
Value Function Loss: 0.01622

Mean KL Divergence: 0.00658
SB3 Clip Fraction: 0.06435
Policy Update Magnitude: 0.31194
Value Function Update Magnitude: 0.30475

Collected Steps per Second: 22,231.40877
Overall Steps per Second: 10,793.93766

Timestep Collection Time: 2.25015
Timestep Consumption Time: 2.38430
PPO Batch Consumption Time: 0.27707
Total Iteration Time: 4.63445

Cumulative Model Updates: 248,348
Cumulative Timesteps: 2,071,828,116

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2071828116...
Checkpoint 2071828116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 59,926.55930
Policy Entropy: 2.54260
Value Function Loss: 0.01556

Mean KL Divergence: 0.00646
SB3 Clip Fraction: 0.06202
Policy Update Magnitude: 0.30834
Value Function Update Magnitude: 0.29569

Collected Steps per Second: 21,443.20098
Overall Steps per Second: 10,525.05969

Timestep Collection Time: 2.33305
Timestep Consumption Time: 2.42018
PPO Batch Consumption Time: 0.27818
Total Iteration Time: 4.75323

Cumulative Model Updates: 248,354
Cumulative Timesteps: 2,071,878,144

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55,505.25294
Policy Entropy: 2.51908
Value Function Loss: 0.01432

Mean KL Divergence: 0.00687
SB3 Clip Fraction: 0.06541
Policy Update Magnitude: 0.30905
Value Function Update Magnitude: 0.30199

Collected Steps per Second: 21,772.13036
Overall Steps per Second: 10,579.08650

Timestep Collection Time: 2.29651
Timestep Consumption Time: 2.42979
PPO Batch Consumption Time: 0.27755
Total Iteration Time: 4.72631

Cumulative Model Updates: 248,360
Cumulative Timesteps: 2,071,928,144

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2071928144...
Checkpoint 2071928144 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 66,139.15186
Policy Entropy: 2.51636
Value Function Loss: 0.01528

Mean KL Divergence: 0.00647
SB3 Clip Fraction: 0.05960
Policy Update Magnitude: 0.31252
Value Function Update Magnitude: 0.30065

Collected Steps per Second: 20,914.77951
Overall Steps per Second: 10,276.71905

Timestep Collection Time: 2.39161
Timestep Consumption Time: 2.47570
PPO Batch Consumption Time: 0.29198
Total Iteration Time: 4.86731

Cumulative Model Updates: 248,366
Cumulative Timesteps: 2,071,978,164

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65,978.94484
Policy Entropy: 2.50972
Value Function Loss: 0.01632

Mean KL Divergence: 0.00680
SB3 Clip Fraction: 0.06133
Policy Update Magnitude: 0.31908
Value Function Update Magnitude: 0.31967

Collected Steps per Second: 21,815.46636
Overall Steps per Second: 10,469.27532

Timestep Collection Time: 2.29287
Timestep Consumption Time: 2.48492
PPO Batch Consumption Time: 0.29066
Total Iteration Time: 4.77779

Cumulative Model Updates: 248,372
Cumulative Timesteps: 2,072,028,184

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2072028184...
Checkpoint 2072028184 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 61,512.07396
Policy Entropy: 2.52965
Value Function Loss: 0.01797

Mean KL Divergence: 0.00747
SB3 Clip Fraction: 0.06614
Policy Update Magnitude: 0.32993
Value Function Update Magnitude: 0.33182

Collected Steps per Second: 21,664.21480
Overall Steps per Second: 10,562.10998

Timestep Collection Time: 2.31008
Timestep Consumption Time: 2.42818
PPO Batch Consumption Time: 0.27729
Total Iteration Time: 4.73826

Cumulative Model Updates: 248,378
Cumulative Timesteps: 2,072,078,230

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53,622.81412
Policy Entropy: 2.55940
Value Function Loss: 0.01577

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.06920
Policy Update Magnitude: 0.31760
Value Function Update Magnitude: 0.32410

Collected Steps per Second: 22,470.36356
Overall Steps per Second: 10,525.52237

Timestep Collection Time: 2.22604
Timestep Consumption Time: 2.52621
PPO Batch Consumption Time: 0.29040
Total Iteration Time: 4.75226

Cumulative Model Updates: 248,384
Cumulative Timesteps: 2,072,128,250

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2072128250...
Checkpoint 2072128250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 64,796.46936
Policy Entropy: 2.56089
Value Function Loss: 0.01690

Mean KL Divergence: 0.00750
SB3 Clip Fraction: 0.06973
Policy Update Magnitude: 0.31014
Value Function Update Magnitude: 0.33664

Collected Steps per Second: 21,730.12095
Overall Steps per Second: 10,538.58993

Timestep Collection Time: 2.30289
Timestep Consumption Time: 2.44557
PPO Batch Consumption Time: 0.27858
Total Iteration Time: 4.74845

Cumulative Model Updates: 248,390
Cumulative Timesteps: 2,072,178,292

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 64,796.46936
Policy Entropy: 2.57313
Value Function Loss: 0.01308

Mean KL Divergence: 0.00604
SB3 Clip Fraction: 0.05861
Policy Update Magnitude: 0.29661
Value Function Update Magnitude: 0.29098

Collected Steps per Second: 22,141.31046
Overall Steps per Second: 10,486.63684

Timestep Collection Time: 2.25931
Timestep Consumption Time: 2.51096
PPO Batch Consumption Time: 0.29387
Total Iteration Time: 4.77026

Cumulative Model Updates: 248,396
Cumulative Timesteps: 2,072,228,316

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2072228316...
Checkpoint 2072228316 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 107,124.12070
Policy Entropy: 2.55153
Value Function Loss: 0.01665

Mean KL Divergence: 0.00648
SB3 Clip Fraction: 0.06204
Policy Update Magnitude: 0.30054
Value Function Update Magnitude: 0.22565

Collected Steps per Second: 21,400.15530
Overall Steps per Second: 10,506.06665

Timestep Collection Time: 2.33653
Timestep Consumption Time: 2.42282
PPO Batch Consumption Time: 0.27919
Total Iteration Time: 4.75935

Cumulative Model Updates: 248,402
Cumulative Timesteps: 2,072,278,318

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79,676.81322
Policy Entropy: 2.54923
Value Function Loss: 0.01648

Mean KL Divergence: 0.00650
SB3 Clip Fraction: 0.06329
Policy Update Magnitude: 0.30979
Value Function Update Magnitude: 0.21772

Collected Steps per Second: 22,086.96462
Overall Steps per Second: 10,508.50033

Timestep Collection Time: 2.26396
Timestep Consumption Time: 2.49447
PPO Batch Consumption Time: 0.28812
Total Iteration Time: 4.75843

Cumulative Model Updates: 248,408
Cumulative Timesteps: 2,072,328,322

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2072328322...
Checkpoint 2072328322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 63,541.65300
Policy Entropy: 2.55697
Value Function Loss: 0.01979

Mean KL Divergence: 0.01268
SB3 Clip Fraction: 0.06229
Policy Update Magnitude: 0.31521
Value Function Update Magnitude: 0.22059

Collected Steps per Second: 21,746.30923
Overall Steps per Second: 10,574.51705

Timestep Collection Time: 2.30025
Timestep Consumption Time: 2.43018
PPO Batch Consumption Time: 0.27846
Total Iteration Time: 4.73043

Cumulative Model Updates: 248,414
Cumulative Timesteps: 2,072,378,344

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90,267.36576
Policy Entropy: 2.55757
Value Function Loss: 0.02136

Mean KL Divergence: 0.02173
SB3 Clip Fraction: 0.06266
Policy Update Magnitude: 0.33506
Value Function Update Magnitude: 0.26384

Collected Steps per Second: 21,477.01217
Overall Steps per Second: 10,519.64081

Timestep Collection Time: 2.32900
Timestep Consumption Time: 2.42591
PPO Batch Consumption Time: 0.27816
Total Iteration Time: 4.75492

Cumulative Model Updates: 248,420
Cumulative Timesteps: 2,072,428,364

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2072428364...
Checkpoint 2072428364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 69,217.31369
Policy Entropy: 2.54077
Value Function Loss: 0.02254

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.08282
Policy Update Magnitude: 0.34708
Value Function Update Magnitude: 0.31968

Collected Steps per Second: 21,424.90293
Overall Steps per Second: 10,368.97252

Timestep Collection Time: 2.33513
Timestep Consumption Time: 2.48984
PPO Batch Consumption Time: 0.29197
Total Iteration Time: 4.82497

Cumulative Model Updates: 248,426
Cumulative Timesteps: 2,072,478,394

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 69,217.31369
Policy Entropy: 2.52035
Value Function Loss: 0.01887

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.07511
Policy Update Magnitude: 0.33680
Value Function Update Magnitude: 0.31999

Collected Steps per Second: 21,887.23794
Overall Steps per Second: 10,481.92182

Timestep Collection Time: 2.28590
Timestep Consumption Time: 2.48727
PPO Batch Consumption Time: 0.28957
Total Iteration Time: 4.77317

Cumulative Model Updates: 248,432
Cumulative Timesteps: 2,072,528,426

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2072528426...
Checkpoint 2072528426 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 56,021.17268
Policy Entropy: 2.51589
Value Function Loss: 0.01770

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.06745
Policy Update Magnitude: 0.31569
Value Function Update Magnitude: 0.32709

Collected Steps per Second: 21,191.61929
Overall Steps per Second: 10,399.29717

Timestep Collection Time: 2.36018
Timestep Consumption Time: 2.44938
PPO Batch Consumption Time: 0.27879
Total Iteration Time: 4.80956

Cumulative Model Updates: 248,438
Cumulative Timesteps: 2,072,578,442

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48,224.32110
Policy Entropy: 2.49243
Value Function Loss: 0.01523

Mean KL Divergence: 0.00698
SB3 Clip Fraction: 0.06615
Policy Update Magnitude: 0.31621
Value Function Update Magnitude: 0.32917

Collected Steps per Second: 21,371.76558
Overall Steps per Second: 10,526.50394

Timestep Collection Time: 2.33954
Timestep Consumption Time: 2.41038
PPO Batch Consumption Time: 0.28335
Total Iteration Time: 4.74992

Cumulative Model Updates: 248,444
Cumulative Timesteps: 2,072,628,442

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2072628442...
Checkpoint 2072628442 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,574.37296
Policy Entropy: 2.47769
Value Function Loss: 0.01680

Mean KL Divergence: 0.00724
SB3 Clip Fraction: 0.06838
Policy Update Magnitude: 0.32098
Value Function Update Magnitude: 0.29721

Collected Steps per Second: 21,220.73399
Overall Steps per Second: 10,582.10192

Timestep Collection Time: 2.35703
Timestep Consumption Time: 2.36963
PPO Batch Consumption Time: 0.27878
Total Iteration Time: 4.72666

Cumulative Model Updates: 248,450
Cumulative Timesteps: 2,072,678,460

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65,378.85989
Policy Entropy: 2.48200
Value Function Loss: 0.01742

Mean KL Divergence: 0.00757
SB3 Clip Fraction: 0.07224
Policy Update Magnitude: 0.32478
Value Function Update Magnitude: 0.27608

Collected Steps per Second: 21,441.26437
Overall Steps per Second: 10,470.24883

Timestep Collection Time: 2.33251
Timestep Consumption Time: 2.44407
PPO Batch Consumption Time: 0.29152
Total Iteration Time: 4.77658

Cumulative Model Updates: 248,456
Cumulative Timesteps: 2,072,728,472

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2072728472...
Checkpoint 2072728472 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 69,728.75934
Policy Entropy: 2.51333
Value Function Loss: 0.01594

Mean KL Divergence: 0.00727
SB3 Clip Fraction: 0.06847
Policy Update Magnitude: 0.31327
Value Function Update Magnitude: 0.27663

Collected Steps per Second: 21,431.58866
Overall Steps per Second: 10,380.23966

Timestep Collection Time: 2.33468
Timestep Consumption Time: 2.48563
PPO Batch Consumption Time: 0.29129
Total Iteration Time: 4.82031

Cumulative Model Updates: 248,462
Cumulative Timesteps: 2,072,778,508

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54,053.61877
Policy Entropy: 2.53417
Value Function Loss: 0.01504

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.07399
Policy Update Magnitude: 0.30195
Value Function Update Magnitude: 0.27158

Collected Steps per Second: 21,767.80684
Overall Steps per Second: 10,501.51681

Timestep Collection Time: 2.29798
Timestep Consumption Time: 2.46533
PPO Batch Consumption Time: 0.28856
Total Iteration Time: 4.76331

Cumulative Model Updates: 248,468
Cumulative Timesteps: 2,072,828,530

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2072828530...
Checkpoint 2072828530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 54,977.81833
Policy Entropy: 2.54535
Value Function Loss: 0.01564

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.08640
Policy Update Magnitude: 0.29326
Value Function Update Magnitude: 0.23539

Collected Steps per Second: 22,018.43776
Overall Steps per Second: 10,540.16469

Timestep Collection Time: 2.27264
Timestep Consumption Time: 2.47491
PPO Batch Consumption Time: 0.29284
Total Iteration Time: 4.74755

Cumulative Model Updates: 248,474
Cumulative Timesteps: 2,072,878,570

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78,690.40864
Policy Entropy: 2.53277
Value Function Loss: 0.01565

Mean KL Divergence: 0.01203
SB3 Clip Fraction: 0.09810
Policy Update Magnitude: 0.29091
Value Function Update Magnitude: 0.21437

Collected Steps per Second: 21,969.94254
Overall Steps per Second: 10,484.59817

Timestep Collection Time: 2.27766
Timestep Consumption Time: 2.49506
PPO Batch Consumption Time: 0.29077
Total Iteration Time: 4.77272

Cumulative Model Updates: 248,480
Cumulative Timesteps: 2,072,928,610

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 2072928610...
Checkpoint 2072928610 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 94,365.41095
Policy Entropy: 2.51386
Value Function Loss: 0.01512

Mean KL Divergence: 0.01126
SB3 Clip Fraction: 0.09539
Policy Update Magnitude: 0.29581
Value Function Update Magnitude: 0.23923

Collected Steps per Second: 21,329.11328
Overall Steps per Second: 10,461.44021

Timestep Collection Time: 2.34487
Timestep Consumption Time: 2.43592
PPO Batch Consumption Time: 0.27881
Total Iteration Time: 4.78079

Cumulative Model Updates: 248,486
Cumulative Timesteps: 2,072,978,624

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81,309.97861
Policy Entropy: 2.50750
Value Function Loss: 0.01446

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.08101
Policy Update Magnitude: 0.30055
Value Function Update Magnitude: 0.27317

Collected Steps per Second: 21,546.99292
Overall Steps per Second: 10,535.07447

Timestep Collection Time: 2.32088
Timestep Consumption Time: 2.42593
PPO Batch Consumption Time: 0.27725
Total Iteration Time: 4.74681

Cumulative Model Updates: 248,492
Cumulative Timesteps: 2,073,028,632

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2073028632...
Checkpoint 2073028632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,272.57886
Policy Entropy: 2.51769
Value Function Loss: 0.01583

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.08007
Policy Update Magnitude: 0.30464
Value Function Update Magnitude: 0.28307

Collected Steps per Second: 21,587.79376
Overall Steps per Second: 10,531.58050

Timestep Collection Time: 2.31640
Timestep Consumption Time: 2.43179
PPO Batch Consumption Time: 0.27871
Total Iteration Time: 4.74820

Cumulative Model Updates: 248,498
Cumulative Timesteps: 2,073,078,638

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59,657.84897
Policy Entropy: 2.52768
Value Function Loss: 0.01642

Mean KL Divergence: 0.00680
SB3 Clip Fraction: 0.06428
Policy Update Magnitude: 0.29459
Value Function Update Magnitude: 0.29793

Collected Steps per Second: 21,608.92715
Overall Steps per Second: 10,513.12712

Timestep Collection Time: 2.31469
Timestep Consumption Time: 2.44298
PPO Batch Consumption Time: 0.27908
Total Iteration Time: 4.75767

Cumulative Model Updates: 248,504
Cumulative Timesteps: 2,073,128,656

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2073128656...
Checkpoint 2073128656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,266.44353
Policy Entropy: 2.52429
Value Function Loss: 0.01812

Mean KL Divergence: 0.00660
SB3 Clip Fraction: 0.06137
Policy Update Magnitude: 0.30076
Value Function Update Magnitude: 0.31468

Collected Steps per Second: 21,690.20565
Overall Steps per Second: 10,398.35866

Timestep Collection Time: 2.30620
Timestep Consumption Time: 2.50436
PPO Batch Consumption Time: 0.29013
Total Iteration Time: 4.81057

Cumulative Model Updates: 248,510
Cumulative Timesteps: 2,073,178,678

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,466.88767
Policy Entropy: 2.52858
Value Function Loss: 0.01697

Mean KL Divergence: 0.00726
SB3 Clip Fraction: 0.06780
Policy Update Magnitude: 0.30202
Value Function Update Magnitude: 0.32029

Collected Steps per Second: 21,955.99641
Overall Steps per Second: 10,411.91859

Timestep Collection Time: 2.27737
Timestep Consumption Time: 2.52501
PPO Batch Consumption Time: 0.29213
Total Iteration Time: 4.80238

Cumulative Model Updates: 248,516
Cumulative Timesteps: 2,073,228,680

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2073228680...
Checkpoint 2073228680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,049.87414
Policy Entropy: 2.52830
Value Function Loss: 0.01695

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.07075
Policy Update Magnitude: 0.29843
Value Function Update Magnitude: 0.28418

Collected Steps per Second: 21,878.38732
Overall Steps per Second: 10,465.90680

Timestep Collection Time: 2.28536
Timestep Consumption Time: 2.49206
PPO Batch Consumption Time: 0.28856
Total Iteration Time: 4.77742

Cumulative Model Updates: 248,522
Cumulative Timesteps: 2,073,278,680

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 64,703.32799
Policy Entropy: 2.52054
Value Function Loss: 0.01587

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.07263
Policy Update Magnitude: 0.29232
Value Function Update Magnitude: 0.27397

Collected Steps per Second: 21,698.13354
Overall Steps per Second: 10,470.08852

Timestep Collection Time: 2.30564
Timestep Consumption Time: 2.47255
PPO Batch Consumption Time: 0.28600
Total Iteration Time: 4.77818

Cumulative Model Updates: 248,528
Cumulative Timesteps: 2,073,328,708

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2073328708...
Checkpoint 2073328708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 67,580.19811
Policy Entropy: 2.52695
Value Function Loss: 0.01439

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.07707
Policy Update Magnitude: 0.29621
Value Function Update Magnitude: 0.29691

Collected Steps per Second: 21,362.68137
Overall Steps per Second: 10,635.89186

Timestep Collection Time: 2.34072
Timestep Consumption Time: 2.36072
PPO Batch Consumption Time: 0.27896
Total Iteration Time: 4.70144

Cumulative Model Updates: 248,534
Cumulative Timesteps: 2,073,378,712

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59,124.41760
Policy Entropy: 2.53002
Value Function Loss: 0.01395

Mean KL Divergence: 0.00759
SB3 Clip Fraction: 0.07233
Policy Update Magnitude: 0.29395
Value Function Update Magnitude: 0.29130

Collected Steps per Second: 21,347.34469
Overall Steps per Second: 10,482.31905

Timestep Collection Time: 2.34446
Timestep Consumption Time: 2.43006
PPO Batch Consumption Time: 0.29340
Total Iteration Time: 4.77452

Cumulative Model Updates: 248,540
Cumulative Timesteps: 2,073,428,760

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 2073428760...
Checkpoint 2073428760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 54,971.29408
Policy Entropy: 2.52050
Value Function Loss: 0.01474

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.07546
Policy Update Magnitude: 0.29411
Value Function Update Magnitude: 0.27677

Collected Steps per Second: 21,401.34523
Overall Steps per Second: 10,700.86058

Timestep Collection Time: 2.33696
Timestep Consumption Time: 2.33687
PPO Batch Consumption Time: 0.27746
Total Iteration Time: 4.67383

Cumulative Model Updates: 248,546
Cumulative Timesteps: 2,073,478,774

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79,930.68877
Policy Entropy: 2.50816
Value Function Loss: 0.01588

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.08177
Policy Update Magnitude: 0.29916
Value Function Update Magnitude: 0.27331

Collected Steps per Second: 21,323.91820
Overall Steps per Second: 10,380.40140

Timestep Collection Time: 2.34516
Timestep Consumption Time: 2.47238
PPO Batch Consumption Time: 0.28759
Total Iteration Time: 4.81754

Cumulative Model Updates: 248,552
Cumulative Timesteps: 2,073,528,782

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2073528782...
Checkpoint 2073528782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87,477.24951
Policy Entropy: 2.47141
Value Function Loss: 0.02050

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.09073
Policy Update Magnitude: 0.31896
Value Function Update Magnitude: 0.30599

Collected Steps per Second: 21,197.70823
Overall Steps per Second: 10,348.23745

Timestep Collection Time: 2.35997
Timestep Consumption Time: 2.47428
PPO Batch Consumption Time: 0.29236
Total Iteration Time: 4.83425

Cumulative Model Updates: 248,558
Cumulative Timesteps: 2,073,578,808

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60,932.64250
Policy Entropy: 2.47473
Value Function Loss: 0.01914

Mean KL Divergence: 0.01645
SB3 Clip Fraction: 0.12411
Policy Update Magnitude: 0.32934
Value Function Update Magnitude: 0.33486

Collected Steps per Second: 21,326.20579
Overall Steps per Second: 10,321.17174

Timestep Collection Time: 2.34613
Timestep Consumption Time: 2.50158
PPO Batch Consumption Time: 0.29258
Total Iteration Time: 4.84771

Cumulative Model Updates: 248,564
Cumulative Timesteps: 2,073,628,842

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 2073628842...
Checkpoint 2073628842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 60,932.64250
Policy Entropy: 2.46945
Value Function Loss: 0.01687

Mean KL Divergence: 0.01704
SB3 Clip Fraction: 0.13096
Policy Update Magnitude: 0.31411
Value Function Update Magnitude: 0.32590

Collected Steps per Second: 21,439.76273
Overall Steps per Second: 10,556.11861

Timestep Collection Time: 2.33249
Timestep Consumption Time: 2.40486
PPO Batch Consumption Time: 0.27838
Total Iteration Time: 4.73735

Cumulative Model Updates: 248,570
Cumulative Timesteps: 2,073,678,850

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49,410.95183
Policy Entropy: 2.49766
Value Function Loss: 0.01559

Mean KL Divergence: 0.01321
SB3 Clip Fraction: 0.11334
Policy Update Magnitude: 0.30958
Value Function Update Magnitude: 0.30061

Collected Steps per Second: 22,050.89653
Overall Steps per Second: 10,512.50755

Timestep Collection Time: 2.26775
Timestep Consumption Time: 2.48906
PPO Batch Consumption Time: 0.27883
Total Iteration Time: 4.75681

Cumulative Model Updates: 248,576
Cumulative Timesteps: 2,073,728,856

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2073728856...
Checkpoint 2073728856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 54,595.53923
Policy Entropy: 2.49069
Value Function Loss: 0.01581

Mean KL Divergence: 0.01053
SB3 Clip Fraction: 0.09563
Policy Update Magnitude: 0.31541
Value Function Update Magnitude: 0.26772

Collected Steps per Second: 21,585.32405
Overall Steps per Second: 10,345.68612

Timestep Collection Time: 2.31778
Timestep Consumption Time: 2.51805
PPO Batch Consumption Time: 0.28992
Total Iteration Time: 4.83583

Cumulative Model Updates: 248,582
Cumulative Timesteps: 2,073,778,886

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67,416.36761
Policy Entropy: 2.50356
Value Function Loss: 0.01802

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.08307
Policy Update Magnitude: 0.31711
Value Function Update Magnitude: 0.29948

Collected Steps per Second: 22,102.65161
Overall Steps per Second: 10,491.25669

Timestep Collection Time: 2.26299
Timestep Consumption Time: 2.50460
PPO Batch Consumption Time: 0.28999
Total Iteration Time: 4.76759

Cumulative Model Updates: 248,588
Cumulative Timesteps: 2,073,828,904

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2073828904...
Checkpoint 2073828904 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 56,056.82506
Policy Entropy: 2.51184
Value Function Loss: 0.01805

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.07842
Policy Update Magnitude: 0.32738
Value Function Update Magnitude: 0.32666

Collected Steps per Second: 21,820.49023
Overall Steps per Second: 10,463.39363

Timestep Collection Time: 2.29170
Timestep Consumption Time: 2.48744
PPO Batch Consumption Time: 0.28981
Total Iteration Time: 4.77914

Cumulative Model Updates: 248,594
Cumulative Timesteps: 2,073,878,910

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56,056.82506
Policy Entropy: 2.51042
Value Function Loss: 0.01655

Mean KL Divergence: 0.00718
SB3 Clip Fraction: 0.06812
Policy Update Magnitude: 0.32037
Value Function Update Magnitude: 0.34088

Collected Steps per Second: 21,999.92762
Overall Steps per Second: 10,443.31989

Timestep Collection Time: 2.27419
Timestep Consumption Time: 2.51662
PPO Batch Consumption Time: 0.29168
Total Iteration Time: 4.79081

Cumulative Model Updates: 248,600
Cumulative Timesteps: 2,073,928,942

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2073928942...
Checkpoint 2073928942 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 71,485.52369
Policy Entropy: 2.51474
Value Function Loss: 0.01660

Mean KL Divergence: 0.00740
SB3 Clip Fraction: 0.06517
Policy Update Magnitude: 0.32569
Value Function Update Magnitude: 0.35694

Collected Steps per Second: 22,020.73240
Overall Steps per Second: 10,614.53344

Timestep Collection Time: 2.27131
Timestep Consumption Time: 2.44072
PPO Batch Consumption Time: 0.27942
Total Iteration Time: 4.71203

Cumulative Model Updates: 248,606
Cumulative Timesteps: 2,073,978,958

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 112,809.90102
Policy Entropy: 2.51563
Value Function Loss: 0.01549

Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.07270
Policy Update Magnitude: 0.32574
Value Function Update Magnitude: 0.35621

Collected Steps per Second: 21,889.38389
Overall Steps per Second: 10,473.95088

Timestep Collection Time: 2.28567
Timestep Consumption Time: 2.49113
PPO Batch Consumption Time: 0.28910
Total Iteration Time: 4.77680

Cumulative Model Updates: 248,612
Cumulative Timesteps: 2,074,028,990

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2074028990...
Checkpoint 2074028990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 76,741.67629
Policy Entropy: 2.52442
Value Function Loss: 0.01636

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.07776
Policy Update Magnitude: 0.31754
Value Function Update Magnitude: 0.35550

Collected Steps per Second: 21,582.16986
Overall Steps per Second: 10,559.54173

Timestep Collection Time: 2.31793
Timestep Consumption Time: 2.41958
PPO Batch Consumption Time: 0.27882
Total Iteration Time: 4.73752

Cumulative Model Updates: 248,618
Cumulative Timesteps: 2,074,079,016

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 64,343.70616
Policy Entropy: 2.52884
Value Function Loss: 0.01667

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.08207
Policy Update Magnitude: 0.31649
Value Function Update Magnitude: 0.35211

Collected Steps per Second: 21,652.34548
Overall Steps per Second: 10,532.74691

Timestep Collection Time: 2.30996
Timestep Consumption Time: 2.43866
PPO Batch Consumption Time: 0.27867
Total Iteration Time: 4.74862

Cumulative Model Updates: 248,624
Cumulative Timesteps: 2,074,129,032

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2074129032...
Checkpoint 2074129032 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 52,598.03408
Policy Entropy: 2.52526
Value Function Loss: 0.01527

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.07840
Policy Update Magnitude: 0.30843
Value Function Update Magnitude: 0.36494

Collected Steps per Second: 21,511.65817
Overall Steps per Second: 10,378.59303

Timestep Collection Time: 2.32451
Timestep Consumption Time: 2.49349
PPO Batch Consumption Time: 0.28941
Total Iteration Time: 4.81799

Cumulative Model Updates: 248,630
Cumulative Timesteps: 2,074,179,036

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,719.81462
Policy Entropy: 2.53701
Value Function Loss: 0.01536

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.07060
Policy Update Magnitude: 0.30530
Value Function Update Magnitude: 0.33989

Collected Steps per Second: 21,987.72362
Overall Steps per Second: 10,633.36596

Timestep Collection Time: 2.27491
Timestep Consumption Time: 2.42915
PPO Batch Consumption Time: 0.27799
Total Iteration Time: 4.70406

Cumulative Model Updates: 248,636
Cumulative Timesteps: 2,074,229,056

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2074229056...
Checkpoint 2074229056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 85,831.04219
Policy Entropy: 2.51359
Value Function Loss: 0.01572

Mean KL Divergence: 0.00777
SB3 Clip Fraction: 0.06952
Policy Update Magnitude: 0.31276
Value Function Update Magnitude: 0.31929

Collected Steps per Second: 21,435.55495
Overall Steps per Second: 10,285.65597

Timestep Collection Time: 2.33407
Timestep Consumption Time: 2.53018
PPO Batch Consumption Time: 0.28793
Total Iteration Time: 4.86425

Cumulative Model Updates: 248,642
Cumulative Timesteps: 2,074,279,088

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79,090.99301
Policy Entropy: 2.50396
Value Function Loss: 0.01762

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.07909
Policy Update Magnitude: 0.31664
Value Function Update Magnitude: 0.30396

Collected Steps per Second: 21,981.11333
Overall Steps per Second: 10,423.29308

Timestep Collection Time: 2.27504
Timestep Consumption Time: 2.52267
PPO Batch Consumption Time: 0.28706
Total Iteration Time: 4.79772

Cumulative Model Updates: 248,648
Cumulative Timesteps: 2,074,329,096

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2074329096...
Checkpoint 2074329096 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 61,389.96356
Policy Entropy: 2.49258
Value Function Loss: 0.01637

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.07238
Policy Update Magnitude: 0.31966
Value Function Update Magnitude: 0.30233

Collected Steps per Second: 21,769.08988
Overall Steps per Second: 10,572.10492

Timestep Collection Time: 2.29702
Timestep Consumption Time: 2.43279
PPO Batch Consumption Time: 0.27850
Total Iteration Time: 4.72981

Cumulative Model Updates: 248,654
Cumulative Timesteps: 2,074,379,100

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60,312.99322
Policy Entropy: 2.50806
Value Function Loss: 0.01842

Mean KL Divergence: 0.00751
SB3 Clip Fraction: 0.07122
Policy Update Magnitude: 0.32458
Value Function Update Magnitude: 0.34049

Collected Steps per Second: 22,010.17037
Overall Steps per Second: 10,625.58312

Timestep Collection Time: 2.27168
Timestep Consumption Time: 2.43395
PPO Batch Consumption Time: 0.27776
Total Iteration Time: 4.70562

Cumulative Model Updates: 248,660
Cumulative Timesteps: 2,074,429,100

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2074429100...
Checkpoint 2074429100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,516.00534
Policy Entropy: 2.51519
Value Function Loss: 0.01727

Mean KL Divergence: 0.00721
SB3 Clip Fraction: 0.06992
Policy Update Magnitude: 0.32449
Value Function Update Magnitude: 0.35460

Collected Steps per Second: 21,810.66628
Overall Steps per Second: 10,587.88761

Timestep Collection Time: 2.29411
Timestep Consumption Time: 2.43167
PPO Batch Consumption Time: 0.27803
Total Iteration Time: 4.72578

Cumulative Model Updates: 248,666
Cumulative Timesteps: 2,074,479,136

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90,353.50069
Policy Entropy: 2.51799
Value Function Loss: 0.01882

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.06966
Policy Update Magnitude: 0.31999
Value Function Update Magnitude: 0.35516

Collected Steps per Second: 22,078.03149
Overall Steps per Second: 10,473.61263

Timestep Collection Time: 2.26587
Timestep Consumption Time: 2.51051
PPO Batch Consumption Time: 0.29391
Total Iteration Time: 4.77638

Cumulative Model Updates: 248,672
Cumulative Timesteps: 2,074,529,162

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2074529162...
Checkpoint 2074529162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 66,493.86520
Policy Entropy: 2.53044
Value Function Loss: 0.01711

Mean KL Divergence: 0.00758
SB3 Clip Fraction: 0.07155
Policy Update Magnitude: 0.31952
Value Function Update Magnitude: 0.35014

Collected Steps per Second: 21,653.11297
Overall Steps per Second: 10,544.07290

Timestep Collection Time: 2.30914
Timestep Consumption Time: 2.43286
PPO Batch Consumption Time: 0.27916
Total Iteration Time: 4.74200

Cumulative Model Updates: 248,678
Cumulative Timesteps: 2,074,579,162

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61,250.43791
Policy Entropy: 2.52216
Value Function Loss: 0.01593

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.07463
Policy Update Magnitude: 0.31141
Value Function Update Magnitude: 0.33482

Collected Steps per Second: 21,300.52292
Overall Steps per Second: 10,502.24246

Timestep Collection Time: 2.34924
Timestep Consumption Time: 2.41546
PPO Batch Consumption Time: 0.29032
Total Iteration Time: 4.76470

Cumulative Model Updates: 248,684
Cumulative Timesteps: 2,074,629,202

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 2074629202...
Checkpoint 2074629202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 80,881.51140
Policy Entropy: 2.53183
Value Function Loss: 0.01294

Mean KL Divergence: 0.00739
SB3 Clip Fraction: 0.07068
Policy Update Magnitude: 0.29856
Value Function Update Magnitude: 0.31988

Collected Steps per Second: 20,784.09927
Overall Steps per Second: 10,363.19023

Timestep Collection Time: 2.40569
Timestep Consumption Time: 2.41908
PPO Batch Consumption Time: 0.29112
Total Iteration Time: 4.82477

Cumulative Model Updates: 248,690
Cumulative Timesteps: 2,074,679,202

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 96,986.93550
Policy Entropy: 2.52290
Value Function Loss: 0.01275

Mean KL Divergence: 0.00631
SB3 Clip Fraction: 0.06121
Policy Update Magnitude: 0.29203
Value Function Update Magnitude: 0.29825

Collected Steps per Second: 21,043.72519
Overall Steps per Second: 10,282.13026

Timestep Collection Time: 2.37724
Timestep Consumption Time: 2.48809
PPO Batch Consumption Time: 0.29219
Total Iteration Time: 4.86533

Cumulative Model Updates: 248,696
Cumulative Timesteps: 2,074,729,228

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2074729228...
Checkpoint 2074729228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47,624.65438
Policy Entropy: 2.51882
Value Function Loss: 0.01566

Mean KL Divergence: 0.00691
SB3 Clip Fraction: 0.06555
Policy Update Magnitude: 0.29945
Value Function Update Magnitude: 0.29559

Collected Steps per Second: 21,317.08279
Overall Steps per Second: 10,365.63349

Timestep Collection Time: 2.34685
Timestep Consumption Time: 2.47948
PPO Batch Consumption Time: 0.29108
Total Iteration Time: 4.82633

Cumulative Model Updates: 248,702
Cumulative Timesteps: 2,074,779,256

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49,849.81842
Policy Entropy: 2.52229
Value Function Loss: 0.01622

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.07460
Policy Update Magnitude: 0.30546
Value Function Update Magnitude: 0.30745

Collected Steps per Second: 22,376.23236
Overall Steps per Second: 10,700.37942

Timestep Collection Time: 2.23451
Timestep Consumption Time: 2.43822
PPO Batch Consumption Time: 0.27939
Total Iteration Time: 4.67273

Cumulative Model Updates: 248,708
Cumulative Timesteps: 2,074,829,256

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2074829256...
Checkpoint 2074829256 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 68,189.27292
Policy Entropy: 2.53220
Value Function Loss: 0.01637

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.07324
Policy Update Magnitude: 0.30237
Value Function Update Magnitude: 0.30823

Collected Steps per Second: 21,410.71398
Overall Steps per Second: 10,399.21491

Timestep Collection Time: 2.33668
Timestep Consumption Time: 2.47426
PPO Batch Consumption Time: 0.28917
Total Iteration Time: 4.81094

Cumulative Model Updates: 248,714
Cumulative Timesteps: 2,074,879,286

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52,123.80824
Policy Entropy: 2.54229
Value Function Loss: 0.01643

Mean KL Divergence: 0.00671
SB3 Clip Fraction: 0.06714
Policy Update Magnitude: 0.30435
Value Function Update Magnitude: 0.30245

Collected Steps per Second: 22,382.90470
Overall Steps per Second: 10,709.05078

Timestep Collection Time: 2.23403
Timestep Consumption Time: 2.43530
PPO Batch Consumption Time: 0.27921
Total Iteration Time: 4.66932

Cumulative Model Updates: 248,720
Cumulative Timesteps: 2,074,929,290

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2074929290...
Checkpoint 2074929290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43,094.83306
Policy Entropy: 2.51578
Value Function Loss: 0.01536

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.07914
Policy Update Magnitude: 0.30405
Value Function Update Magnitude: 0.31617

Collected Steps per Second: 21,905.99502
Overall Steps per Second: 10,596.28287

Timestep Collection Time: 2.28303
Timestep Consumption Time: 2.43674
PPO Batch Consumption Time: 0.27931
Total Iteration Time: 4.71977

Cumulative Model Updates: 248,726
Cumulative Timesteps: 2,074,979,302

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,094.83306
Policy Entropy: 2.50268
Value Function Loss: 0.01539

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.07482
Policy Update Magnitude: 0.30159
Value Function Update Magnitude: 0.31141

Collected Steps per Second: 22,191.30656
Overall Steps per Second: 10,522.43297

Timestep Collection Time: 2.25395
Timestep Consumption Time: 2.49952
PPO Batch Consumption Time: 0.29282
Total Iteration Time: 4.75346

Cumulative Model Updates: 248,732
Cumulative Timesteps: 2,075,029,320

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2075029320...
Checkpoint 2075029320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,767.20155
Policy Entropy: 2.49478
Value Function Loss: 0.01545

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.07544
Policy Update Magnitude: 0.30407
Value Function Update Magnitude: 0.26694

Collected Steps per Second: 22,011.19504
Overall Steps per Second: 10,636.99041

Timestep Collection Time: 2.27193
Timestep Consumption Time: 2.42940
PPO Batch Consumption Time: 0.27850
Total Iteration Time: 4.70133

Cumulative Model Updates: 248,738
Cumulative Timesteps: 2,075,079,328

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67,207.56638
Policy Entropy: 2.49740
Value Function Loss: 0.01710

Mean KL Divergence: 0.00777
SB3 Clip Fraction: 0.07232
Policy Update Magnitude: 0.30960
Value Function Update Magnitude: 0.27845

Collected Steps per Second: 21,639.22985
Overall Steps per Second: 10,429.16478

Timestep Collection Time: 2.31145
Timestep Consumption Time: 2.48452
PPO Batch Consumption Time: 0.28603
Total Iteration Time: 4.79597

Cumulative Model Updates: 248,744
Cumulative Timesteps: 2,075,129,346

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2075129346...
Checkpoint 2075129346 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 65,181.38262
Policy Entropy: 2.50395
Value Function Loss: 0.01615

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.07941
Policy Update Magnitude: 0.30744
Value Function Update Magnitude: 0.28320

Collected Steps per Second: 20,886.07682
Overall Steps per Second: 10,232.15861

Timestep Collection Time: 2.39528
Timestep Consumption Time: 2.49401
PPO Batch Consumption Time: 0.27836
Total Iteration Time: 4.88929

Cumulative Model Updates: 248,750
Cumulative Timesteps: 2,075,179,374

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 73,808.63014
Policy Entropy: 2.52156
Value Function Loss: 0.01509

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.07538
Policy Update Magnitude: 0.30389
Value Function Update Magnitude: 0.25915

Collected Steps per Second: 22,301.72278
Overall Steps per Second: 10,473.88979

Timestep Collection Time: 2.24225
Timestep Consumption Time: 2.53210
PPO Batch Consumption Time: 0.29175
Total Iteration Time: 4.77435

Cumulative Model Updates: 248,756
Cumulative Timesteps: 2,075,229,380

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2075229380...
Checkpoint 2075229380 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 77,950.70812
Policy Entropy: 2.52096
Value Function Loss: 0.01391

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.06854
Policy Update Magnitude: 0.29863
Value Function Update Magnitude: 0.24862

Collected Steps per Second: 21,840.11124
Overall Steps per Second: 10,620.65405

Timestep Collection Time: 2.29019
Timestep Consumption Time: 2.41931
PPO Batch Consumption Time: 0.27785
Total Iteration Time: 4.70950

Cumulative Model Updates: 248,762
Cumulative Timesteps: 2,075,279,398

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86,484.52177
Policy Entropy: 2.50417
Value Function Loss: 0.01879

Mean KL Divergence: 0.00738
SB3 Clip Fraction: 0.06736
Policy Update Magnitude: 0.30908
Value Function Update Magnitude: 0.25825

Collected Steps per Second: 22,248.90300
Overall Steps per Second: 10,512.94108

Timestep Collection Time: 2.24856
Timestep Consumption Time: 2.51015
PPO Batch Consumption Time: 0.29321
Total Iteration Time: 4.75871

Cumulative Model Updates: 248,768
Cumulative Timesteps: 2,075,329,426

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2075329426...
Checkpoint 2075329426 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 161,800.15601
Policy Entropy: 2.50119
Value Function Loss: 0.01889

Mean KL Divergence: 0.00734
SB3 Clip Fraction: 0.06675
Policy Update Magnitude: 0.32368
Value Function Update Magnitude: 0.30100

Collected Steps per Second: 21,527.45678
Overall Steps per Second: 10,515.86622

Timestep Collection Time: 2.32308
Timestep Consumption Time: 2.43259
PPO Batch Consumption Time: 0.27948
Total Iteration Time: 4.75567

Cumulative Model Updates: 248,774
Cumulative Timesteps: 2,075,379,436

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 96,710.21036
Policy Entropy: 2.51231
Value Function Loss: 0.01843

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.07962
Policy Update Magnitude: 0.31812
Value Function Update Magnitude: 0.33815

Collected Steps per Second: 22,101.37534
Overall Steps per Second: 10,486.13718

Timestep Collection Time: 2.26402
Timestep Consumption Time: 2.50780
PPO Batch Consumption Time: 0.28986
Total Iteration Time: 4.77182

Cumulative Model Updates: 248,780
Cumulative Timesteps: 2,075,429,474

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 2075429474...
Checkpoint 2075429474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86,069.23530
Policy Entropy: 2.54740
Value Function Loss: 0.01517

Mean KL Divergence: 0.00750
SB3 Clip Fraction: 0.06897
Policy Update Magnitude: 0.32124
Value Function Update Magnitude: 0.33247

Collected Steps per Second: 21,776.69196
Overall Steps per Second: 10,594.73750

Timestep Collection Time: 2.29704
Timestep Consumption Time: 2.42436
PPO Batch Consumption Time: 0.27849
Total Iteration Time: 4.72140

Cumulative Model Updates: 248,786
Cumulative Timesteps: 2,075,479,496

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 74,364.61354
Policy Entropy: 2.55847
Value Function Loss: 0.01548

Mean KL Divergence: 0.00751
SB3 Clip Fraction: 0.07137
Policy Update Magnitude: 0.31598
Value Function Update Magnitude: 0.30648

Collected Steps per Second: 21,461.66130
Overall Steps per Second: 10,494.43774

Timestep Collection Time: 2.33123
Timestep Consumption Time: 2.43625
PPO Batch Consumption Time: 0.27875
Total Iteration Time: 4.76748

Cumulative Model Updates: 248,792
Cumulative Timesteps: 2,075,529,528

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2075529528...
Checkpoint 2075529528 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 74,217.72470
Policy Entropy: 2.54988
Value Function Loss: 0.01493

Mean KL Divergence: 0.00710
SB3 Clip Fraction: 0.06175
Policy Update Magnitude: 0.29951
Value Function Update Magnitude: 0.30359

Collected Steps per Second: 21,411.64124
Overall Steps per Second: 10,379.39060

Timestep Collection Time: 2.33518
Timestep Consumption Time: 2.48206
PPO Batch Consumption Time: 0.29083
Total Iteration Time: 4.81724

Cumulative Model Updates: 248,798
Cumulative Timesteps: 2,075,579,528

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 73,338.66558
Policy Entropy: 2.52055
Value Function Loss: 0.01357

Mean KL Divergence: 0.00772
SB3 Clip Fraction: 0.06836
Policy Update Magnitude: 0.29693
Value Function Update Magnitude: 0.30215

Collected Steps per Second: 21,741.91807
Overall Steps per Second: 10,421.83013

Timestep Collection Time: 2.30053
Timestep Consumption Time: 2.49882
PPO Batch Consumption Time: 0.29212
Total Iteration Time: 4.79935

Cumulative Model Updates: 248,804
Cumulative Timesteps: 2,075,629,546

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2075629546...
Checkpoint 2075629546 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 74,986.34345
Policy Entropy: 2.52157
Value Function Loss: 0.01365

Mean KL Divergence: 0.00762
SB3 Clip Fraction: 0.07100
Policy Update Magnitude: 0.29495
Value Function Update Magnitude: 0.28097

Collected Steps per Second: 21,422.02735
Overall Steps per Second: 10,493.14487

Timestep Collection Time: 2.33461
Timestep Consumption Time: 2.43155
PPO Batch Consumption Time: 0.27840
Total Iteration Time: 4.76616

Cumulative Model Updates: 248,810
Cumulative Timesteps: 2,075,679,558

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65,017.21956
Policy Entropy: 2.52172
Value Function Loss: 0.01383

Mean KL Divergence: 0.00727
SB3 Clip Fraction: 0.06612
Policy Update Magnitude: 0.29519
Value Function Update Magnitude: 0.27628

Collected Steps per Second: 20,935.30555
Overall Steps per Second: 10,519.91929

Timestep Collection Time: 2.39032
Timestep Consumption Time: 2.36656
PPO Batch Consumption Time: 0.27756
Total Iteration Time: 4.75688

Cumulative Model Updates: 248,816
Cumulative Timesteps: 2,075,729,600

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 2075729600...
Checkpoint 2075729600 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 117,311.83890
Policy Entropy: 2.53852
Value Function Loss: 0.01458

Mean KL Divergence: 0.00748
SB3 Clip Fraction: 0.07053
Policy Update Magnitude: 0.29343
Value Function Update Magnitude: 0.28931

Collected Steps per Second: 21,236.11211
Overall Steps per Second: 10,529.35221

Timestep Collection Time: 2.35467
Timestep Consumption Time: 2.39434
PPO Batch Consumption Time: 0.27796
Total Iteration Time: 4.74901

Cumulative Model Updates: 248,822
Cumulative Timesteps: 2,075,779,604

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 134,341.49999
Policy Entropy: 2.52216
Value Function Loss: 0.01528

Mean KL Divergence: 0.00782
SB3 Clip Fraction: 0.07162
Policy Update Magnitude: 0.30581
Value Function Update Magnitude: 0.29969

Collected Steps per Second: 21,402.98996
Overall Steps per Second: 10,479.13409

Timestep Collection Time: 2.33612
Timestep Consumption Time: 2.43526
PPO Batch Consumption Time: 0.28920
Total Iteration Time: 4.77139

Cumulative Model Updates: 248,828
Cumulative Timesteps: 2,075,829,604

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2075829604...
Checkpoint 2075829604 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 100,244.02930
Policy Entropy: 2.52580
Value Function Loss: 0.01497

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.07837
Policy Update Magnitude: 0.30981
Value Function Update Magnitude: 0.33322

Collected Steps per Second: 21,274.44502
Overall Steps per Second: 10,366.73480

Timestep Collection Time: 2.35052
Timestep Consumption Time: 2.47318
PPO Batch Consumption Time: 0.29262
Total Iteration Time: 4.82370

Cumulative Model Updates: 248,834
Cumulative Timesteps: 2,075,879,610

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 64,239.97680
Policy Entropy: 2.49242
Value Function Loss: 0.01553

Mean KL Divergence: 0.01084
SB3 Clip Fraction: 0.09341
Policy Update Magnitude: 0.31035
Value Function Update Magnitude: 0.35322

Collected Steps per Second: 21,542.39723
Overall Steps per Second: 10,386.56946

Timestep Collection Time: 2.32203
Timestep Consumption Time: 2.49400
PPO Batch Consumption Time: 0.29284
Total Iteration Time: 4.81603

Cumulative Model Updates: 248,840
Cumulative Timesteps: 2,075,929,632

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2075929632...
Checkpoint 2075929632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 60,224.75222
Policy Entropy: 2.51690
Value Function Loss: 0.01930

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.08254
Policy Update Magnitude: 0.33193
Value Function Update Magnitude: 0.35520

Collected Steps per Second: 22,043.82733
Overall Steps per Second: 10,540.67353

Timestep Collection Time: 2.26866
Timestep Consumption Time: 2.47582
PPO Batch Consumption Time: 0.29196
Total Iteration Time: 4.74448

Cumulative Model Updates: 248,846
Cumulative Timesteps: 2,075,979,642

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50,601.85222
Policy Entropy: 2.49595
Value Function Loss: 0.02084

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.08089
Policy Update Magnitude: 0.33454
Value Function Update Magnitude: 0.35405

Collected Steps per Second: 22,256.65974
Overall Steps per Second: 10,556.97422

Timestep Collection Time: 2.24697
Timestep Consumption Time: 2.49018
PPO Batch Consumption Time: 0.29243
Total Iteration Time: 4.73715

Cumulative Model Updates: 248,852
Cumulative Timesteps: 2,076,029,652

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2076029652...
Checkpoint 2076029652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55,052.93797
Policy Entropy: 2.52046
Value Function Loss: 0.01790

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.08314
Policy Update Magnitude: 0.32339
Value Function Update Magnitude: 0.31901

Collected Steps per Second: 21,858.96222
Overall Steps per Second: 10,552.65009

Timestep Collection Time: 2.28739
Timestep Consumption Time: 2.45076
PPO Batch Consumption Time: 0.28411
Total Iteration Time: 4.73815

Cumulative Model Updates: 248,858
Cumulative Timesteps: 2,076,079,652

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67,696.82173
Policy Entropy: 2.50826
Value Function Loss: 0.01639

Mean KL Divergence: 0.00749
SB3 Clip Fraction: 0.07008
Policy Update Magnitude: 0.32191
Value Function Update Magnitude: 0.33450

Collected Steps per Second: 21,741.79617
Overall Steps per Second: 10,413.15526

Timestep Collection Time: 2.29972
Timestep Consumption Time: 2.50190
PPO Batch Consumption Time: 0.28784
Total Iteration Time: 4.80162

Cumulative Model Updates: 248,864
Cumulative Timesteps: 2,076,129,652

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2076129652...
Checkpoint 2076129652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 81,070.84495
Policy Entropy: 2.53000
Value Function Loss: 0.01776

Mean KL Divergence: 0.00748
SB3 Clip Fraction: 0.07112
Policy Update Magnitude: 0.33375
Value Function Update Magnitude: 0.33228

Collected Steps per Second: 21,315.87927
Overall Steps per Second: 10,314.56518

Timestep Collection Time: 2.34801
Timestep Consumption Time: 2.50435
PPO Batch Consumption Time: 0.29317
Total Iteration Time: 4.85236

Cumulative Model Updates: 248,870
Cumulative Timesteps: 2,076,179,702

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90,200.02057
Policy Entropy: 2.50471
Value Function Loss: 0.02011

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.07220
Policy Update Magnitude: 0.34225
Value Function Update Magnitude: 0.32997

Collected Steps per Second: 21,524.67742
Overall Steps per Second: 10,381.50268

Timestep Collection Time: 2.32357
Timestep Consumption Time: 2.49404
PPO Batch Consumption Time: 0.28841
Total Iteration Time: 4.81761

Cumulative Model Updates: 248,876
Cumulative Timesteps: 2,076,229,716

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2076229716...
Checkpoint 2076229716 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 61,107.52316
Policy Entropy: 2.53197
Value Function Loss: 0.02005

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.07442
Policy Update Magnitude: 0.32984
Value Function Update Magnitude: 0.26726

Collected Steps per Second: 21,440.52791
Overall Steps per Second: 10,364.46038

Timestep Collection Time: 2.33269
Timestep Consumption Time: 2.49284
PPO Batch Consumption Time: 0.29128
Total Iteration Time: 4.82553

Cumulative Model Updates: 248,882
Cumulative Timesteps: 2,076,279,730

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50,881.51493
Policy Entropy: 2.52507
Value Function Loss: 0.01945

Mean KL Divergence: 0.00756
SB3 Clip Fraction: 0.06926
Policy Update Magnitude: 0.31485
Value Function Update Magnitude: 0.22727

Collected Steps per Second: 22,035.85807
Overall Steps per Second: 10,640.43019

Timestep Collection Time: 2.27103
Timestep Consumption Time: 2.43217
PPO Batch Consumption Time: 0.27876
Total Iteration Time: 4.70319

Cumulative Model Updates: 248,888
Cumulative Timesteps: 2,076,329,774

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 2076329774...
Checkpoint 2076329774 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,273.34549
Policy Entropy: 2.51167
Value Function Loss: 0.01755

Mean KL Divergence: 0.00709
SB3 Clip Fraction: 0.06683
Policy Update Magnitude: 0.31627
Value Function Update Magnitude: 0.28053

Collected Steps per Second: 21,753.96377
Overall Steps per Second: 10,371.81996

Timestep Collection Time: 2.29990
Timestep Consumption Time: 2.52394
PPO Batch Consumption Time: 0.29219
Total Iteration Time: 4.82384

Cumulative Model Updates: 248,894
Cumulative Timesteps: 2,076,379,806

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47,879.86583
Policy Entropy: 2.48015
Value Function Loss: 0.01614

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.07408
Policy Update Magnitude: 0.32104
Value Function Update Magnitude: 0.31915

Collected Steps per Second: 21,416.17050
Overall Steps per Second: 10,525.64045

Timestep Collection Time: 2.33571
Timestep Consumption Time: 2.41668
PPO Batch Consumption Time: 0.28975
Total Iteration Time: 4.75239

Cumulative Model Updates: 248,900
Cumulative Timesteps: 2,076,429,828

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2076429828...
Checkpoint 2076429828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 51,001.68643
Policy Entropy: 2.47682
Value Function Loss: 0.01592

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.07735
Policy Update Magnitude: 0.31508
Value Function Update Magnitude: 0.31639

Collected Steps per Second: 21,535.80335
Overall Steps per Second: 10,495.97588

Timestep Collection Time: 2.32292
Timestep Consumption Time: 2.44329
PPO Batch Consumption Time: 0.29514
Total Iteration Time: 4.76621

Cumulative Model Updates: 248,906
Cumulative Timesteps: 2,076,479,854

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51,433.13520
Policy Entropy: 2.50278
Value Function Loss: 0.01493

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.08509
Policy Update Magnitude: 0.31555
Value Function Update Magnitude: 0.30694

Collected Steps per Second: 21,389.10751
Overall Steps per Second: 10,384.24251

Timestep Collection Time: 2.33857
Timestep Consumption Time: 2.47834
PPO Batch Consumption Time: 0.28779
Total Iteration Time: 4.81691

Cumulative Model Updates: 248,912
Cumulative Timesteps: 2,076,529,874

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2076529874...
Checkpoint 2076529874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89,772.27113
Policy Entropy: 2.49998
Value Function Loss: 0.01682

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.08804
Policy Update Magnitude: 0.31293
Value Function Update Magnitude: 0.30504

Collected Steps per Second: 21,830.69416
Overall Steps per Second: 10,629.74348

Timestep Collection Time: 2.29237
Timestep Consumption Time: 2.41555
PPO Batch Consumption Time: 0.28005
Total Iteration Time: 4.70792

Cumulative Model Updates: 248,918
Cumulative Timesteps: 2,076,579,918

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89,772.27113
Policy Entropy: 2.51269
Value Function Loss: 0.01531

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.08327
Policy Update Magnitude: 0.31416
Value Function Update Magnitude: 0.30672

Collected Steps per Second: 21,777.26716
Overall Steps per Second: 10,492.53821

Timestep Collection Time: 2.29597
Timestep Consumption Time: 2.46932
PPO Batch Consumption Time: 0.28849
Total Iteration Time: 4.76529

Cumulative Model Updates: 248,924
Cumulative Timesteps: 2,076,629,918

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2076629918...
Checkpoint 2076629918 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 70,243.77693
Policy Entropy: 2.49838
Value Function Loss: 0.01675

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.07633
Policy Update Magnitude: 0.31181
Value Function Update Magnitude: 0.31566

Collected Steps per Second: 21,899.09728
Overall Steps per Second: 10,612.80472

Timestep Collection Time: 2.28439
Timestep Consumption Time: 2.42935
PPO Batch Consumption Time: 0.27908
Total Iteration Time: 4.71374

Cumulative Model Updates: 248,930
Cumulative Timesteps: 2,076,679,944

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48,659.72048
Policy Entropy: 2.49505
Value Function Loss: 0.01684

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.07731
Policy Update Magnitude: 0.32406
Value Function Update Magnitude: 0.33335

Collected Steps per Second: 21,514.10630
Overall Steps per Second: 10,602.28749

Timestep Collection Time: 2.32545
Timestep Consumption Time: 2.39334
PPO Batch Consumption Time: 0.27726
Total Iteration Time: 4.71879

Cumulative Model Updates: 248,936
Cumulative Timesteps: 2,076,729,974

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2076729974...
Checkpoint 2076729974 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,710.96272
Policy Entropy: 2.50020
Value Function Loss: 0.01980

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.08727
Policy Update Magnitude: 0.32833
Value Function Update Magnitude: 0.32009

Collected Steps per Second: 21,066.01017
Overall Steps per Second: 10,279.41241

Timestep Collection Time: 2.37520
Timestep Consumption Time: 2.49239
PPO Batch Consumption Time: 0.29136
Total Iteration Time: 4.86759

Cumulative Model Updates: 248,942
Cumulative Timesteps: 2,076,780,010

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56,606.50037
Policy Entropy: 2.51079
Value Function Loss: 0.01962

Mean KL Divergence: 0.01278
SB3 Clip Fraction: 0.10373
Policy Update Magnitude: 0.32959
Value Function Update Magnitude: 0.31693

Collected Steps per Second: 21,787.18899
Overall Steps per Second: 10,452.10943

Timestep Collection Time: 2.29557
Timestep Consumption Time: 2.48949
PPO Batch Consumption Time: 0.29065
Total Iteration Time: 4.78506

Cumulative Model Updates: 248,948
Cumulative Timesteps: 2,076,830,024

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2076830024...
Checkpoint 2076830024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 51,552.85454
Policy Entropy: 2.51680
Value Function Loss: 0.01960

Mean KL Divergence: 0.01171
SB3 Clip Fraction: 0.09516
Policy Update Magnitude: 0.32884
Value Function Update Magnitude: 0.33133

Collected Steps per Second: 21,429.01408
Overall Steps per Second: 10,497.59472

Timestep Collection Time: 2.33497
Timestep Consumption Time: 2.43146
PPO Batch Consumption Time: 0.27849
Total Iteration Time: 4.76643

Cumulative Model Updates: 248,954
Cumulative Timesteps: 2,076,880,060

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47,371.78233
Policy Entropy: 2.52227
Value Function Loss: 0.01775

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.09021
Policy Update Magnitude: 0.32257
Value Function Update Magnitude: 0.35614

Collected Steps per Second: 21,759.08446
Overall Steps per Second: 10,417.35269

Timestep Collection Time: 2.29789
Timestep Consumption Time: 2.50179
PPO Batch Consumption Time: 0.28700
Total Iteration Time: 4.79968

Cumulative Model Updates: 248,960
Cumulative Timesteps: 2,076,930,060

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2076930060...
Checkpoint 2076930060 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 50,282.53400
Policy Entropy: 2.51820
Value Function Loss: 0.01755

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.08114
Policy Update Magnitude: 0.31984
Value Function Update Magnitude: 0.36308

Collected Steps per Second: 21,933.21158
Overall Steps per Second: 10,530.11207

Timestep Collection Time: 2.28038
Timestep Consumption Time: 2.46943
PPO Batch Consumption Time: 0.27884
Total Iteration Time: 4.74981

Cumulative Model Updates: 248,966
Cumulative Timesteps: 2,076,980,076

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 64,953.01977
Policy Entropy: 2.52377
Value Function Loss: 0.01706

Mean KL Divergence: 0.00728
SB3 Clip Fraction: 0.07028
Policy Update Magnitude: 0.32868
Value Function Update Magnitude: 0.36342

Collected Steps per Second: 22,158.99770
Overall Steps per Second: 10,633.61804

Timestep Collection Time: 2.25777
Timestep Consumption Time: 2.44712
PPO Batch Consumption Time: 0.27779
Total Iteration Time: 4.70489

Cumulative Model Updates: 248,972
Cumulative Timesteps: 2,077,030,106

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2077030106...
Checkpoint 2077030106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 60,943.44905
Policy Entropy: 2.52057
Value Function Loss: 0.01658

Mean KL Divergence: 0.00757
SB3 Clip Fraction: 0.06538
Policy Update Magnitude: 0.32205
Value Function Update Magnitude: 0.34747

Collected Steps per Second: 20,959.53935
Overall Steps per Second: 10,211.15016

Timestep Collection Time: 2.38593
Timestep Consumption Time: 2.51146
PPO Batch Consumption Time: 0.29399
Total Iteration Time: 4.89739

Cumulative Model Updates: 248,978
Cumulative Timesteps: 2,077,080,114

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,829.76019
Policy Entropy: 2.51580
Value Function Loss: 0.01718

Mean KL Divergence: 0.00724
SB3 Clip Fraction: 0.06121
Policy Update Magnitude: 0.31288
Value Function Update Magnitude: 0.34466

Collected Steps per Second: 21,280.77061
Overall Steps per Second: 10,464.73790

Timestep Collection Time: 2.35095
Timestep Consumption Time: 2.42987
PPO Batch Consumption Time: 0.27741
Total Iteration Time: 4.78082

Cumulative Model Updates: 248,984
Cumulative Timesteps: 2,077,130,144

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2077130144...
Checkpoint 2077130144 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48,482.06191
Policy Entropy: 2.50824
Value Function Loss: 0.01613

Mean KL Divergence: 0.00694
SB3 Clip Fraction: 0.06409
Policy Update Magnitude: 0.30803
Value Function Update Magnitude: 0.33102

Collected Steps per Second: 21,694.10488
Overall Steps per Second: 10,580.15101

Timestep Collection Time: 2.30570
Timestep Consumption Time: 2.42203
PPO Batch Consumption Time: 0.27791
Total Iteration Time: 4.72772

Cumulative Model Updates: 248,990
Cumulative Timesteps: 2,077,180,164

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80,505.83561
Policy Entropy: 2.50667
Value Function Loss: 0.01592

Mean KL Divergence: 0.00666
SB3 Clip Fraction: 0.06338
Policy Update Magnitude: 0.30095
Value Function Update Magnitude: 0.30798

Collected Steps per Second: 21,925.29154
Overall Steps per Second: 10,443.50220

Timestep Collection Time: 2.28102
Timestep Consumption Time: 2.50780
PPO Batch Consumption Time: 0.29065
Total Iteration Time: 4.78881

Cumulative Model Updates: 248,996
Cumulative Timesteps: 2,077,230,176

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2077230176...
Checkpoint 2077230176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 110,711.64435
Policy Entropy: 2.52069
Value Function Loss: 0.01501

Mean KL Divergence: 0.00654
SB3 Clip Fraction: 0.06191
Policy Update Magnitude: 0.29890
Value Function Update Magnitude: 0.27479

Collected Steps per Second: 20,999.92947
Overall Steps per Second: 10,340.02672

Timestep Collection Time: 2.38201
Timestep Consumption Time: 2.45570
PPO Batch Consumption Time: 0.29148
Total Iteration Time: 4.83771

Cumulative Model Updates: 249,002
Cumulative Timesteps: 2,077,280,198

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90,115.00668
Policy Entropy: 2.52920
Value Function Loss: 0.01467

Mean KL Divergence: 0.00636
SB3 Clip Fraction: 0.06128
Policy Update Magnitude: 0.29198
Value Function Update Magnitude: 0.26013

Collected Steps per Second: 21,349.54155
Overall Steps per Second: 10,637.41439

Timestep Collection Time: 2.34225
Timestep Consumption Time: 2.35870
PPO Batch Consumption Time: 0.27842
Total Iteration Time: 4.70095

Cumulative Model Updates: 249,008
Cumulative Timesteps: 2,077,330,204

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2077330204...
Checkpoint 2077330204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 72,221.92230
Policy Entropy: 2.53967
Value Function Loss: 0.01399

Mean KL Divergence: 0.00680
SB3 Clip Fraction: 0.06505
Policy Update Magnitude: 0.28940
Value Function Update Magnitude: 0.25548

Collected Steps per Second: 21,111.51947
Overall Steps per Second: 10,443.32556

Timestep Collection Time: 2.36989
Timestep Consumption Time: 2.42092
PPO Batch Consumption Time: 0.29166
Total Iteration Time: 4.79081

Cumulative Model Updates: 249,014
Cumulative Timesteps: 2,077,380,236

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62,875.88059
Policy Entropy: 2.54306
Value Function Loss: 0.01606

Mean KL Divergence: 0.00732
SB3 Clip Fraction: 0.06687
Policy Update Magnitude: 0.29657
Value Function Update Magnitude: 0.27955

Collected Steps per Second: 21,593.09301
Overall Steps per Second: 10,442.78973

Timestep Collection Time: 2.31741
Timestep Consumption Time: 2.47442
PPO Batch Consumption Time: 0.29258
Total Iteration Time: 4.79182

Cumulative Model Updates: 249,020
Cumulative Timesteps: 2,077,430,276

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 2077430276...
Checkpoint 2077430276 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 59,434.97386
Policy Entropy: 2.52894
Value Function Loss: 0.01505

Mean KL Divergence: 0.00735
SB3 Clip Fraction: 0.06857
Policy Update Magnitude: 0.29329
Value Function Update Magnitude: 0.30288

Collected Steps per Second: 21,915.62794
Overall Steps per Second: 10,499.59976

Timestep Collection Time: 2.28248
Timestep Consumption Time: 2.48170
PPO Batch Consumption Time: 0.29144
Total Iteration Time: 4.76418

Cumulative Model Updates: 249,026
Cumulative Timesteps: 2,077,480,298

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47,043.66028
Policy Entropy: 2.51964
Value Function Loss: 0.01692

Mean KL Divergence: 0.00734
SB3 Clip Fraction: 0.06844
Policy Update Magnitude: 0.29994
Value Function Update Magnitude: 0.28824

Collected Steps per Second: 21,893.24907
Overall Steps per Second: 10,467.10918

Timestep Collection Time: 2.28637
Timestep Consumption Time: 2.49585
PPO Batch Consumption Time: 0.29325
Total Iteration Time: 4.78222

Cumulative Model Updates: 249,032
Cumulative Timesteps: 2,077,530,354

Timesteps Collected: 50,056
--------END ITERATION REPORT--------


Saving checkpoint 2077530354...
Checkpoint 2077530354 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 54,031.52041
Policy Entropy: 2.50747
Value Function Loss: 0.01586

Mean KL Divergence: 0.00658
SB3 Clip Fraction: 0.06196
Policy Update Magnitude: 0.29868
Value Function Update Magnitude: 0.28591

Collected Steps per Second: 21,623.99150
Overall Steps per Second: 10,562.80304

Timestep Collection Time: 2.31373
Timestep Consumption Time: 2.42290
PPO Batch Consumption Time: 0.27914
Total Iteration Time: 4.73662

Cumulative Model Updates: 249,038
Cumulative Timesteps: 2,077,580,386

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65,439.14411
Policy Entropy: 2.50882
Value Function Loss: 0.01540

Mean KL Divergence: 0.00723
SB3 Clip Fraction: 0.06909
Policy Update Magnitude: 0.29686
Value Function Update Magnitude: 0.27351

Collected Steps per Second: 21,661.54091
Overall Steps per Second: 10,546.54115

Timestep Collection Time: 2.30925
Timestep Consumption Time: 2.43372
PPO Batch Consumption Time: 0.27861
Total Iteration Time: 4.74298

Cumulative Model Updates: 249,044
Cumulative Timesteps: 2,077,630,408

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2077630408...
Checkpoint 2077630408 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 90,927.50471
Policy Entropy: 2.51840
Value Function Loss: 0.01390

Mean KL Divergence: 0.00665
SB3 Clip Fraction: 0.06287
Policy Update Magnitude: 0.29583
Value Function Update Magnitude: 0.29172

Collected Steps per Second: 21,606.59258
Overall Steps per Second: 10,567.84046

Timestep Collection Time: 2.31494
Timestep Consumption Time: 2.41810
PPO Batch Consumption Time: 0.27859
Total Iteration Time: 4.73304

Cumulative Model Updates: 249,050
Cumulative Timesteps: 2,077,680,426

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 114,528.89907
Policy Entropy: 2.52048
Value Function Loss: 0.01270

Mean KL Divergence: 0.00633
SB3 Clip Fraction: 0.06157
Policy Update Magnitude: 0.28385
Value Function Update Magnitude: 0.29061

Collected Steps per Second: 21,368.28292
Overall Steps per Second: 10,469.66614

Timestep Collection Time: 2.34001
Timestep Consumption Time: 2.43588
PPO Batch Consumption Time: 0.27898
Total Iteration Time: 4.77589

Cumulative Model Updates: 249,056
Cumulative Timesteps: 2,077,730,428

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2077730428...
Checkpoint 2077730428 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 98,489.86108
Policy Entropy: 2.52204
Value Function Loss: 0.01315

Mean KL Divergence: 0.00610
SB3 Clip Fraction: 0.05868
Policy Update Magnitude: 0.27344
Value Function Update Magnitude: 0.28003

Collected Steps per Second: 21,196.44612
Overall Steps per Second: 10,287.80187

Timestep Collection Time: 2.35889
Timestep Consumption Time: 2.50124
PPO Batch Consumption Time: 0.29326
Total Iteration Time: 4.86012

Cumulative Model Updates: 249,062
Cumulative Timesteps: 2,077,780,428

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 107,882.38572
Policy Entropy: 2.52053
Value Function Loss: 0.01413

Mean KL Divergence: 0.00594
SB3 Clip Fraction: 0.05986
Policy Update Magnitude: 0.27323
Value Function Update Magnitude: 0.25451

Collected Steps per Second: 21,911.06051
Overall Steps per Second: 10,427.69065

Timestep Collection Time: 2.28250
Timestep Consumption Time: 2.51358
PPO Batch Consumption Time: 0.29375
Total Iteration Time: 4.79608

Cumulative Model Updates: 249,068
Cumulative Timesteps: 2,077,830,440

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2077830440...
Checkpoint 2077830440 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 107,882.38572
Policy Entropy: 2.52581
Value Function Loss: 0.01374

Mean KL Divergence: 0.00650
SB3 Clip Fraction: 0.06545
Policy Update Magnitude: 0.27595
Value Function Update Magnitude: 0.25110

Collected Steps per Second: 21,348.30108
Overall Steps per Second: 10,603.77185

Timestep Collection Time: 2.34239
Timestep Consumption Time: 2.37348
PPO Batch Consumption Time: 0.27824
Total Iteration Time: 4.71587

Cumulative Model Updates: 249,074
Cumulative Timesteps: 2,077,880,446

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77,621.89912
Policy Entropy: 2.53717
Value Function Loss: 0.01439

Mean KL Divergence: 0.00660
SB3 Clip Fraction: 0.06527
Policy Update Magnitude: 0.28453
Value Function Update Magnitude: 0.27431

Collected Steps per Second: 21,533.89142
Overall Steps per Second: 10,391.51299

Timestep Collection Time: 2.32211
Timestep Consumption Time: 2.48990
PPO Batch Consumption Time: 0.29717
Total Iteration Time: 4.81200

Cumulative Model Updates: 249,080
Cumulative Timesteps: 2,077,930,450

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2077930450...
Checkpoint 2077930450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 58,849.03382
Policy Entropy: 2.52226
Value Function Loss: 0.01495

Mean KL Divergence: 0.00717
SB3 Clip Fraction: 0.06780
Policy Update Magnitude: 0.28971
Value Function Update Magnitude: 0.30418

Collected Steps per Second: 21,166.62794
Overall Steps per Second: 10,430.39609

Timestep Collection Time: 2.36259
Timestep Consumption Time: 2.43186
PPO Batch Consumption Time: 0.29174
Total Iteration Time: 4.79445

Cumulative Model Updates: 249,086
Cumulative Timesteps: 2,077,980,458

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50,874.92308
Policy Entropy: 2.51053
Value Function Loss: 0.01544

Mean KL Divergence: 0.00711
SB3 Clip Fraction: 0.06423
Policy Update Magnitude: 0.29211
Value Function Update Magnitude: 0.32826

Collected Steps per Second: 21,497.52793
Overall Steps per Second: 10,414.54358

Timestep Collection Time: 2.32771
Timestep Consumption Time: 2.47711
PPO Batch Consumption Time: 0.29335
Total Iteration Time: 4.80482

Cumulative Model Updates: 249,092
Cumulative Timesteps: 2,078,030,498

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 2078030498...
Checkpoint 2078030498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 82,209.01623
Policy Entropy: 2.48223
Value Function Loss: 0.01651

Mean KL Divergence: 0.00613
SB3 Clip Fraction: 0.05797
Policy Update Magnitude: 0.30582
Value Function Update Magnitude: 0.32281

Collected Steps per Second: 21,847.72554
Overall Steps per Second: 10,566.62715

Timestep Collection Time: 2.29040
Timestep Consumption Time: 2.44527
PPO Batch Consumption Time: 0.28641
Total Iteration Time: 4.73566

Cumulative Model Updates: 249,098
Cumulative Timesteps: 2,078,080,538

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82,441.83262
Policy Entropy: 2.49027
Value Function Loss: 0.01424

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.07822
Policy Update Magnitude: 0.31411
Value Function Update Magnitude: 0.30692

Collected Steps per Second: 22,057.58346
Overall Steps per Second: 10,542.19255

Timestep Collection Time: 2.26743
Timestep Consumption Time: 2.47675
PPO Batch Consumption Time: 0.29146
Total Iteration Time: 4.74417

Cumulative Model Updates: 249,104
Cumulative Timesteps: 2,078,130,552

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2078130552...
Checkpoint 2078130552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 98,141.69839
Policy Entropy: 2.48566
Value Function Loss: 0.01355

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.08085
Policy Update Magnitude: 0.30033
Value Function Update Magnitude: 0.29541

Collected Steps per Second: 22,169.53809
Overall Steps per Second: 10,508.57926

Timestep Collection Time: 2.25571
Timestep Consumption Time: 2.50307
PPO Batch Consumption Time: 0.29220
Total Iteration Time: 4.75878

Cumulative Model Updates: 249,110
Cumulative Timesteps: 2,078,180,560

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83,471.09734
Policy Entropy: 2.52100
Value Function Loss: 0.01256

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.08153
Policy Update Magnitude: 0.29678
Value Function Update Magnitude: 0.28594

Collected Steps per Second: 21,719.09219
Overall Steps per Second: 10,471.99614

Timestep Collection Time: 2.30396
Timestep Consumption Time: 2.47449
PPO Batch Consumption Time: 0.28455
Total Iteration Time: 4.77846

Cumulative Model Updates: 249,116
Cumulative Timesteps: 2,078,230,600

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 2078230600...
Checkpoint 2078230600 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 101,679.15442
Policy Entropy: 2.49843
Value Function Loss: 0.01374

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.08600
Policy Update Magnitude: 0.30349
Value Function Update Magnitude: 0.29758

Collected Steps per Second: 21,374.40420
Overall Steps per Second: 10,334.68520

Timestep Collection Time: 2.33953
Timestep Consumption Time: 2.49913
PPO Batch Consumption Time: 0.29127
Total Iteration Time: 4.83866

Cumulative Model Updates: 249,122
Cumulative Timesteps: 2,078,280,606

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75,809.83340
Policy Entropy: 2.48078
Value Function Loss: 0.01389

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.07345
Policy Update Magnitude: 0.30448
Value Function Update Magnitude: 0.32977

Collected Steps per Second: 20,926.89158
Overall Steps per Second: 10,349.26129

Timestep Collection Time: 2.38984
Timestep Consumption Time: 2.44258
PPO Batch Consumption Time: 0.27770
Total Iteration Time: 4.83242

Cumulative Model Updates: 249,128
Cumulative Timesteps: 2,078,330,618

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2078330618...
Checkpoint 2078330618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 71,667.40704
Policy Entropy: 2.46733
Value Function Loss: 0.01357

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.07602
Policy Update Magnitude: 0.30829
Value Function Update Magnitude: 0.33472

Collected Steps per Second: 21,398.13741
Overall Steps per Second: 10,328.90571

Timestep Collection Time: 2.33768
Timestep Consumption Time: 2.50523
PPO Batch Consumption Time: 0.29179
Total Iteration Time: 4.84291

Cumulative Model Updates: 249,134
Cumulative Timesteps: 2,078,380,640

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83,607.31793
Policy Entropy: 2.48007
Value Function Loss: 0.01214

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.07900
Policy Update Magnitude: 0.29806
Value Function Update Magnitude: 0.33139

Collected Steps per Second: 22,179.81430
Overall Steps per Second: 10,435.60426

Timestep Collection Time: 2.25466
Timestep Consumption Time: 2.53739
PPO Batch Consumption Time: 0.29146
Total Iteration Time: 4.79206

Cumulative Model Updates: 249,140
Cumulative Timesteps: 2,078,430,648

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2078430648...
Checkpoint 2078430648 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 100,744.23434
Policy Entropy: 2.47523
Value Function Loss: 0.01347

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.07719
Policy Update Magnitude: 0.29967
Value Function Update Magnitude: 0.32449

Collected Steps per Second: 22,132.35741
Overall Steps per Second: 10,496.25989

Timestep Collection Time: 2.26085
Timestep Consumption Time: 2.50637
PPO Batch Consumption Time: 0.29088
Total Iteration Time: 4.76722

Cumulative Model Updates: 249,146
Cumulative Timesteps: 2,078,480,686

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 106,313.18841
Policy Entropy: 2.48066
Value Function Loss: 0.01495

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.07702
Policy Update Magnitude: 0.31366
Value Function Update Magnitude: 0.31844

Collected Steps per Second: 21,848.97819
Overall Steps per Second: 10,426.43255

Timestep Collection Time: 2.28981
Timestep Consumption Time: 2.50857
PPO Batch Consumption Time: 0.28832
Total Iteration Time: 4.79838

Cumulative Model Updates: 249,152
Cumulative Timesteps: 2,078,530,716

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2078530716...
Checkpoint 2078530716 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 128,255.68365
Policy Entropy: 2.47239
Value Function Loss: 0.01500

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.08579
Policy Update Magnitude: 0.32065
Value Function Update Magnitude: 0.33403

Collected Steps per Second: 21,921.89451
Overall Steps per Second: 10,619.65947

Timestep Collection Time: 2.28174
Timestep Consumption Time: 2.42840
PPO Batch Consumption Time: 0.27809
Total Iteration Time: 4.71013

Cumulative Model Updates: 249,158
Cumulative Timesteps: 2,078,580,736

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85,144.74303
Policy Entropy: 2.48442
Value Function Loss: 0.01550

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.07931
Policy Update Magnitude: 0.31326
Value Function Update Magnitude: 0.33585

Collected Steps per Second: 22,292.13175
Overall Steps per Second: 10,515.47216

Timestep Collection Time: 2.24366
Timestep Consumption Time: 2.51276
PPO Batch Consumption Time: 0.29394
Total Iteration Time: 4.75642

Cumulative Model Updates: 249,164
Cumulative Timesteps: 2,078,630,752

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2078630752...
Checkpoint 2078630752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 74,088.00143
Policy Entropy: 2.48054
Value Function Loss: 0.01685

Mean KL Divergence: 0.00756
SB3 Clip Fraction: 0.07020
Policy Update Magnitude: 0.32327
Value Function Update Magnitude: 0.32819

Collected Steps per Second: 21,509.12440
Overall Steps per Second: 10,563.06686

Timestep Collection Time: 2.32608
Timestep Consumption Time: 2.41042
PPO Batch Consumption Time: 0.27893
Total Iteration Time: 4.73650

Cumulative Model Updates: 249,170
Cumulative Timesteps: 2,078,680,784

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79,204.61295
Policy Entropy: 2.48753
Value Function Loss: 0.01672

Mean KL Divergence: 0.00715
SB3 Clip Fraction: 0.06818
Policy Update Magnitude: 0.31841
Value Function Update Magnitude: 0.32064

Collected Steps per Second: 21,911.83931
Overall Steps per Second: 10,504.50202

Timestep Collection Time: 2.28196
Timestep Consumption Time: 2.47809
PPO Batch Consumption Time: 0.28649
Total Iteration Time: 4.76005

Cumulative Model Updates: 249,176
Cumulative Timesteps: 2,078,730,786

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2078730786...
Checkpoint 2078730786 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 79,204.61295
Policy Entropy: 2.46863
Value Function Loss: 0.01402

Mean KL Divergence: 0.00688
SB3 Clip Fraction: 0.06618
Policy Update Magnitude: 0.30040
Value Function Update Magnitude: 0.30651

Collected Steps per Second: 21,258.08025
Overall Steps per Second: 10,263.57026

Timestep Collection Time: 2.35214
Timestep Consumption Time: 2.51965
PPO Batch Consumption Time: 0.29442
Total Iteration Time: 4.87179

Cumulative Model Updates: 249,182
Cumulative Timesteps: 2,078,780,788

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 101,629.68665
Policy Entropy: 2.47462
Value Function Loss: 0.01425

Mean KL Divergence: 0.00690
SB3 Clip Fraction: 0.06708
Policy Update Magnitude: 0.29583
Value Function Update Magnitude: 0.28415

Collected Steps per Second: 21,094.55068
Overall Steps per Second: 10,403.00377

Timestep Collection Time: 2.37113
Timestep Consumption Time: 2.43690
PPO Batch Consumption Time: 0.29189
Total Iteration Time: 4.80803

Cumulative Model Updates: 249,188
Cumulative Timesteps: 2,078,830,806

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2078830806...
Checkpoint 2078830806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84,599.45632
Policy Entropy: 2.46898
Value Function Loss: 0.01471

Mean KL Divergence: 0.00658
SB3 Clip Fraction: 0.06336
Policy Update Magnitude: 0.29827
Value Function Update Magnitude: 0.28257

Collected Steps per Second: 20,291.37374
Overall Steps per Second: 10,198.60108

Timestep Collection Time: 2.46459
Timestep Consumption Time: 2.43902
PPO Batch Consumption Time: 0.29184
Total Iteration Time: 4.90361

Cumulative Model Updates: 249,194
Cumulative Timesteps: 2,078,880,816

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65,638.20827
Policy Entropy: 2.48168
Value Function Loss: 0.01566

Mean KL Divergence: 0.00616
SB3 Clip Fraction: 0.05903
Policy Update Magnitude: 0.30097
Value Function Update Magnitude: 0.28840

Collected Steps per Second: 20,749.29255
Overall Steps per Second: 10,383.90686

Timestep Collection Time: 2.41068
Timestep Consumption Time: 2.40638
PPO Batch Consumption Time: 0.27868
Total Iteration Time: 4.81707

Cumulative Model Updates: 249,200
Cumulative Timesteps: 2,078,930,836

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2078930836...
Checkpoint 2078930836 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 69,502.56450
Policy Entropy: 2.49635
Value Function Loss: 0.01501

Mean KL Divergence: 0.00645
SB3 Clip Fraction: 0.05990
Policy Update Magnitude: 0.30034
Value Function Update Magnitude: 0.27720

Collected Steps per Second: 20,657.01571
Overall Steps per Second: 10,351.56785

Timestep Collection Time: 2.42068
Timestep Consumption Time: 2.40989
PPO Batch Consumption Time: 0.27755
Total Iteration Time: 4.83057

Cumulative Model Updates: 249,206
Cumulative Timesteps: 2,078,980,840

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83,396.81203
Policy Entropy: 2.48963
Value Function Loss: 0.01430

Mean KL Divergence: 0.00657
SB3 Clip Fraction: 0.05873
Policy Update Magnitude: 0.29629
Value Function Update Magnitude: 0.27807

Collected Steps per Second: 21,995.33852
Overall Steps per Second: 10,471.28986

Timestep Collection Time: 2.27503
Timestep Consumption Time: 2.50375
PPO Batch Consumption Time: 0.29272
Total Iteration Time: 4.77878

Cumulative Model Updates: 249,212
Cumulative Timesteps: 2,079,030,880

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 2079030880...
Checkpoint 2079030880 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 73,179.79963
Policy Entropy: 2.48450
Value Function Loss: 0.01338

Mean KL Divergence: 0.00707
SB3 Clip Fraction: 0.06577
Policy Update Magnitude: 0.29985
Value Function Update Magnitude: 0.26305

Collected Steps per Second: 21,836.54848
Overall Steps per Second: 10,547.10097

Timestep Collection Time: 2.29020
Timestep Consumption Time: 2.45139
PPO Batch Consumption Time: 0.27922
Total Iteration Time: 4.74159

Cumulative Model Updates: 249,218
Cumulative Timesteps: 2,079,080,890

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76,473.76959
Policy Entropy: 2.46210
Value Function Loss: 0.01439

Mean KL Divergence: 0.00717
SB3 Clip Fraction: 0.06955
Policy Update Magnitude: 0.30662
Value Function Update Magnitude: 0.29251

Collected Steps per Second: 22,478.88301
Overall Steps per Second: 10,578.19498

Timestep Collection Time: 2.22467
Timestep Consumption Time: 2.50279
PPO Batch Consumption Time: 0.29246
Total Iteration Time: 4.72746

Cumulative Model Updates: 249,224
Cumulative Timesteps: 2,079,130,898

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2079130898...
Checkpoint 2079130898 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 81,349.39003
Policy Entropy: 2.49722
Value Function Loss: 0.01518

Mean KL Divergence: 0.00753
SB3 Clip Fraction: 0.07145
Policy Update Magnitude: 0.31487
Value Function Update Magnitude: 0.31283

Collected Steps per Second: 21,995.33413
Overall Steps per Second: 10,533.30502

Timestep Collection Time: 2.27357
Timestep Consumption Time: 2.47403
PPO Batch Consumption Time: 0.28784
Total Iteration Time: 4.74761

Cumulative Model Updates: 249,230
Cumulative Timesteps: 2,079,180,906

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 112,875.26025
Policy Entropy: 2.52428
Value Function Loss: 0.01459

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.07284
Policy Update Magnitude: 0.31201
Value Function Update Magnitude: 0.30898

Collected Steps per Second: 22,187.93874
Overall Steps per Second: 10,501.48474

Timestep Collection Time: 2.25402
Timestep Consumption Time: 2.50836
PPO Batch Consumption Time: 0.29392
Total Iteration Time: 4.76237

Cumulative Model Updates: 249,236
Cumulative Timesteps: 2,079,230,918

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2079230918...
Checkpoint 2079230918 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 110,901.35014
Policy Entropy: 2.55461
Value Function Loss: 0.01394

Mean KL Divergence: 0.00655
SB3 Clip Fraction: 0.06322
Policy Update Magnitude: 0.30575
Value Function Update Magnitude: 0.29680

Collected Steps per Second: 21,782.49247
Overall Steps per Second: 10,568.35620

Timestep Collection Time: 2.29744
Timestep Consumption Time: 2.43783
PPO Batch Consumption Time: 0.27927
Total Iteration Time: 4.73527

Cumulative Model Updates: 249,242
Cumulative Timesteps: 2,079,280,962

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83,875.72425
Policy Entropy: 2.54515
Value Function Loss: 0.01472

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.07149
Policy Update Magnitude: 0.31415
Value Function Update Magnitude: 0.30883

Collected Steps per Second: 22,140.82763
Overall Steps per Second: 10,491.32345

Timestep Collection Time: 2.25945
Timestep Consumption Time: 2.50888
PPO Batch Consumption Time: 0.29355
Total Iteration Time: 4.76832

Cumulative Model Updates: 249,248
Cumulative Timesteps: 2,079,330,988

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2079330988...
Checkpoint 2079330988 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 73,102.20708
Policy Entropy: 2.54194
Value Function Loss: 0.01584

Mean KL Divergence: 0.00738
SB3 Clip Fraction: 0.06681
Policy Update Magnitude: 0.31948
Value Function Update Magnitude: 0.32947

Collected Steps per Second: 21,522.16532
Overall Steps per Second: 10,545.36932

Timestep Collection Time: 2.32347
Timestep Consumption Time: 2.41852
PPO Batch Consumption Time: 0.27873
Total Iteration Time: 4.74199

Cumulative Model Updates: 249,254
Cumulative Timesteps: 2,079,380,994

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59,219.06362
Policy Entropy: 2.52783
Value Function Loss: 0.01615

Mean KL Divergence: 0.00770
SB3 Clip Fraction: 0.07040
Policy Update Magnitude: 0.32064
Value Function Update Magnitude: 0.32747

Collected Steps per Second: 21,662.55311
Overall Steps per Second: 10,524.96408

Timestep Collection Time: 2.30988
Timestep Consumption Time: 2.44434
PPO Batch Consumption Time: 0.27993
Total Iteration Time: 4.75422

Cumulative Model Updates: 249,260
Cumulative Timesteps: 2,079,431,032

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 2079431032...
Checkpoint 2079431032 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 59,219.06362
Policy Entropy: 2.51281
Value Function Loss: 0.01403

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.07407
Policy Update Magnitude: 0.30623
Value Function Update Magnitude: 0.32114

Collected Steps per Second: 20,767.20661
Overall Steps per Second: 10,371.84504

Timestep Collection Time: 2.40841
Timestep Consumption Time: 2.41387
PPO Batch Consumption Time: 0.29114
Total Iteration Time: 4.82229

Cumulative Model Updates: 249,266
Cumulative Timesteps: 2,079,481,048

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84,350.46755
Policy Entropy: 2.50536
Value Function Loss: 0.01652

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.07387
Policy Update Magnitude: 0.31524
Value Function Update Magnitude: 0.31305

Collected Steps per Second: 21,135.13603
Overall Steps per Second: 10,449.15804

Timestep Collection Time: 2.36800
Timestep Consumption Time: 2.42167
PPO Batch Consumption Time: 0.29050
Total Iteration Time: 4.78967

Cumulative Model Updates: 249,272
Cumulative Timesteps: 2,079,531,096

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 2079531096...
Checkpoint 2079531096 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 57,879.08493
Policy Entropy: 2.50894
Value Function Loss: 0.01708

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.07847
Policy Update Magnitude: 0.32228
Value Function Update Magnitude: 0.35617

Collected Steps per Second: 21,238.39075
Overall Steps per Second: 10,464.73064

Timestep Collection Time: 2.35555
Timestep Consumption Time: 2.42508
PPO Batch Consumption Time: 0.28474
Total Iteration Time: 4.78063

Cumulative Model Updates: 249,278
Cumulative Timesteps: 2,079,581,124

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48,323.71186
Policy Entropy: 2.52018
Value Function Loss: 0.01584

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.08072
Policy Update Magnitude: 0.30964
Value Function Update Magnitude: 0.37606

Collected Steps per Second: 21,723.57414
Overall Steps per Second: 10,457.39222

Timestep Collection Time: 2.30174
Timestep Consumption Time: 2.47976
PPO Batch Consumption Time: 0.28993
Total Iteration Time: 4.78150

Cumulative Model Updates: 249,284
Cumulative Timesteps: 2,079,631,126

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2079631126...
Checkpoint 2079631126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 62,411.96985
Policy Entropy: 2.51942
Value Function Loss: 0.01338

Mean KL Divergence: 0.00739
SB3 Clip Fraction: 0.06998
Policy Update Magnitude: 0.29318
Value Function Update Magnitude: 0.34528

Collected Steps per Second: 21,818.42405
Overall Steps per Second: 10,629.92772

Timestep Collection Time: 2.29384
Timestep Consumption Time: 2.41438
PPO Batch Consumption Time: 0.27898
Total Iteration Time: 4.70822

Cumulative Model Updates: 249,290
Cumulative Timesteps: 2,079,681,174

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67,926.11571
Policy Entropy: 2.50609
Value Function Loss: 0.01325

Mean KL Divergence: 0.00677
SB3 Clip Fraction: 0.06476
Policy Update Magnitude: 0.29048
Value Function Update Magnitude: 0.31085

Collected Steps per Second: 22,218.76804
Overall Steps per Second: 10,607.98490

Timestep Collection Time: 2.25170
Timestep Consumption Time: 2.46456
PPO Batch Consumption Time: 0.29260
Total Iteration Time: 4.71626

Cumulative Model Updates: 249,296
Cumulative Timesteps: 2,079,731,204

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2079731204...
Checkpoint 2079731204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 61,448.80488
Policy Entropy: 2.50524
Value Function Loss: 0.01309

Mean KL Divergence: 0.00650
SB3 Clip Fraction: 0.06371
Policy Update Magnitude: 0.29381
Value Function Update Magnitude: 0.31302

Collected Steps per Second: 21,925.59591
Overall Steps per Second: 10,525.38992

Timestep Collection Time: 2.28080
Timestep Consumption Time: 2.47037
PPO Batch Consumption Time: 0.28581
Total Iteration Time: 4.75118

Cumulative Model Updates: 249,302
Cumulative Timesteps: 2,079,781,212

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 104,471.64340
Policy Entropy: 2.49767
Value Function Loss: 0.01425

Mean KL Divergence: 0.00651
SB3 Clip Fraction: 0.05991
Policy Update Magnitude: 0.30311
Value Function Update Magnitude: 0.33224

Collected Steps per Second: 22,162.68808
Overall Steps per Second: 10,497.97175

Timestep Collection Time: 2.25686
Timestep Consumption Time: 2.50768
PPO Batch Consumption Time: 0.29316
Total Iteration Time: 4.76454

Cumulative Model Updates: 249,308
Cumulative Timesteps: 2,079,831,230

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2079831230...
Checkpoint 2079831230 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 93,788.64137
Policy Entropy: 2.50360
Value Function Loss: 0.01373

Mean KL Divergence: 0.00646
SB3 Clip Fraction: 0.05582
Policy Update Magnitude: 0.30573
Value Function Update Magnitude: 0.32810

Collected Steps per Second: 21,772.47098
Overall Steps per Second: 10,566.15837

Timestep Collection Time: 2.29776
Timestep Consumption Time: 2.43697
PPO Batch Consumption Time: 0.27824
Total Iteration Time: 4.73474

Cumulative Model Updates: 249,314
Cumulative Timesteps: 2,079,881,258

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53,560.88068
Policy Entropy: 2.48817
Value Function Loss: 0.01607

Mean KL Divergence: 0.00717
SB3 Clip Fraction: 0.06219
Policy Update Magnitude: 0.30828
Value Function Update Magnitude: 0.31474

Collected Steps per Second: 21,390.97530
Overall Steps per Second: 10,496.43002

Timestep Collection Time: 2.33846
Timestep Consumption Time: 2.42716
PPO Batch Consumption Time: 0.27838
Total Iteration Time: 4.76562

Cumulative Model Updates: 249,320
Cumulative Timesteps: 2,079,931,280

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2079931280...
Checkpoint 2079931280 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 79,293.65478
Policy Entropy: 2.48361
Value Function Loss: 0.01713

Mean KL Divergence: 0.00735
SB3 Clip Fraction: 0.07033
Policy Update Magnitude: 0.31273
Value Function Update Magnitude: 0.33414

Collected Steps per Second: 21,215.76322
Overall Steps per Second: 10,304.85686

Timestep Collection Time: 2.35834
Timestep Consumption Time: 2.49704
PPO Batch Consumption Time: 0.29182
Total Iteration Time: 4.85538

Cumulative Model Updates: 249,326
Cumulative Timesteps: 2,079,981,314

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 71,519.68838
Policy Entropy: 2.52045
Value Function Loss: 0.01446

Mean KL Divergence: 0.00721
SB3 Clip Fraction: 0.06847
Policy Update Magnitude: 0.30361
Value Function Update Magnitude: 0.31735

Collected Steps per Second: 21,928.77563
Overall Steps per Second: 10,465.95929

Timestep Collection Time: 2.28093
Timestep Consumption Time: 2.49818
PPO Batch Consumption Time: 0.29174
Total Iteration Time: 4.77911

Cumulative Model Updates: 249,332
Cumulative Timesteps: 2,080,031,332

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2080031332...
Checkpoint 2080031332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 71,519.68838
Policy Entropy: 2.53757
Value Function Loss: 0.01367

Mean KL Divergence: 0.00736
SB3 Clip Fraction: 0.07092
Policy Update Magnitude: 0.29937
Value Function Update Magnitude: 0.29574

Collected Steps per Second: 20,847.27999
Overall Steps per Second: 10,497.06931

Timestep Collection Time: 2.40022
Timestep Consumption Time: 2.36664
PPO Batch Consumption Time: 0.27898
Total Iteration Time: 4.76685

Cumulative Model Updates: 249,338
Cumulative Timesteps: 2,080,081,370

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86,618.38075
Policy Entropy: 2.53932
Value Function Loss: 0.01243

Mean KL Divergence: 0.00605
SB3 Clip Fraction: 0.05985
Policy Update Magnitude: 0.29574
Value Function Update Magnitude: 0.30113

Collected Steps per Second: 21,365.67530
Overall Steps per Second: 10,447.01827

Timestep Collection Time: 2.34039
Timestep Consumption Time: 2.44605
PPO Batch Consumption Time: 0.29081
Total Iteration Time: 4.78644

Cumulative Model Updates: 249,344
Cumulative Timesteps: 2,080,131,374

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2080131374...
Checkpoint 2080131374 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 105,859.30912
Policy Entropy: 2.50657
Value Function Loss: 0.01488

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.07541
Policy Update Magnitude: 0.30261
Value Function Update Magnitude: 0.28558

Collected Steps per Second: 21,206.62410
Overall Steps per Second: 10,370.22422

Timestep Collection Time: 2.35898
Timestep Consumption Time: 2.46502
PPO Batch Consumption Time: 0.29178
Total Iteration Time: 4.82400

Cumulative Model Updates: 249,350
Cumulative Timesteps: 2,080,181,400

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78,617.22562
Policy Entropy: 2.47981
Value Function Loss: 0.01635

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.08196
Policy Update Magnitude: 0.30771
Value Function Update Magnitude: 0.28637

Collected Steps per Second: 21,512.77663
Overall Steps per Second: 10,386.99767

Timestep Collection Time: 2.32569
Timestep Consumption Time: 2.49110
PPO Batch Consumption Time: 0.29230
Total Iteration Time: 4.81679

Cumulative Model Updates: 249,356
Cumulative Timesteps: 2,080,231,432

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2080231432...
Checkpoint 2080231432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 67,563.01329
Policy Entropy: 2.47191
Value Function Loss: 0.01793

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.08370
Policy Update Magnitude: 0.31853
Value Function Update Magnitude: 0.26164

Collected Steps per Second: 21,955.31981
Overall Steps per Second: 10,554.37426

Timestep Collection Time: 2.27872
Timestep Consumption Time: 2.46150
PPO Batch Consumption Time: 0.28871
Total Iteration Time: 4.74021

Cumulative Model Updates: 249,362
Cumulative Timesteps: 2,080,281,462

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61,351.72523
Policy Entropy: 2.50380
Value Function Loss: 0.01644

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.08626
Policy Update Magnitude: 0.32049
Value Function Update Magnitude: 0.26492

Collected Steps per Second: 22,204.67064
Overall Steps per Second: 10,565.82826

Timestep Collection Time: 2.25241
Timestep Consumption Time: 2.48115
PPO Batch Consumption Time: 0.29310
Total Iteration Time: 4.73356

Cumulative Model Updates: 249,368
Cumulative Timesteps: 2,080,331,476

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2080331476...
Checkpoint 2080331476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 75,578.09258
Policy Entropy: 2.52679
Value Function Loss: 0.01619

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.09227
Policy Update Magnitude: 0.31301
Value Function Update Magnitude: 0.31104

Collected Steps per Second: 21,836.15022
Overall Steps per Second: 10,512.38980

Timestep Collection Time: 2.29097
Timestep Consumption Time: 2.46779
PPO Batch Consumption Time: 0.28965
Total Iteration Time: 4.75877

Cumulative Model Updates: 249,374
Cumulative Timesteps: 2,080,381,502

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 74,021.94683
Policy Entropy: 2.55822
Value Function Loss: 0.01659

Mean KL Divergence: 0.01058
SB3 Clip Fraction: 0.08861
Policy Update Magnitude: 0.31413
Value Function Update Magnitude: 0.34039

Collected Steps per Second: 22,408.95054
Overall Steps per Second: 10,554.00242

Timestep Collection Time: 2.23232
Timestep Consumption Time: 2.50749
PPO Batch Consumption Time: 0.29336
Total Iteration Time: 4.73981

Cumulative Model Updates: 249,380
Cumulative Timesteps: 2,080,431,526

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2080431526...
Checkpoint 2080431526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47,286.62214
Policy Entropy: 2.55528
Value Function Loss: 0.01526

Mean KL Divergence: 0.01163
SB3 Clip Fraction: 0.09386
Policy Update Magnitude: 0.30616
Value Function Update Magnitude: 0.30766

Collected Steps per Second: 21,646.00297
Overall Steps per Second: 10,530.20384

Timestep Collection Time: 2.31156
Timestep Consumption Time: 2.44011
PPO Batch Consumption Time: 0.27905
Total Iteration Time: 4.75166

Cumulative Model Updates: 249,386
Cumulative Timesteps: 2,080,481,562

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56,737.26962
Policy Entropy: 2.53375
Value Function Loss: 0.01645

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.07807
Policy Update Magnitude: 0.29807
Value Function Update Magnitude: 0.31613

Collected Steps per Second: 21,646.53210
Overall Steps per Second: 10,562.68900

Timestep Collection Time: 2.31002
Timestep Consumption Time: 2.42400
PPO Batch Consumption Time: 0.27681
Total Iteration Time: 4.73402

Cumulative Model Updates: 249,392
Cumulative Timesteps: 2,080,531,566

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2080531566...
Checkpoint 2080531566 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40,351.92023
Policy Entropy: 2.52837
Value Function Loss: 0.01707

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.07162
Policy Update Magnitude: 0.30636
Value Function Update Magnitude: 0.32292

Collected Steps per Second: 21,545.18707
Overall Steps per Second: 10,537.60831

Timestep Collection Time: 2.32098
Timestep Consumption Time: 2.42450
PPO Batch Consumption Time: 0.27935
Total Iteration Time: 4.74548

Cumulative Model Updates: 249,398
Cumulative Timesteps: 2,080,581,572

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,196.97768
Policy Entropy: 2.51763
Value Function Loss: 0.01983

Mean KL Divergence: 0.00735
SB3 Clip Fraction: 0.06820
Policy Update Magnitude: 0.31732
Value Function Update Magnitude: 0.28964

Collected Steps per Second: 21,311.81730
Overall Steps per Second: 10,456.56225

Timestep Collection Time: 2.34715
Timestep Consumption Time: 2.43664
PPO Batch Consumption Time: 0.27907
Total Iteration Time: 4.78379

Cumulative Model Updates: 249,404
Cumulative Timesteps: 2,080,631,594

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2080631594...
Checkpoint 2080631594 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,949.51079
Policy Entropy: 2.54312
Value Function Loss: 0.01847

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.07661
Policy Update Magnitude: 0.31195
Value Function Update Magnitude: 0.27051

Collected Steps per Second: 21,321.08444
Overall Steps per Second: 10,320.03478

Timestep Collection Time: 2.34566
Timestep Consumption Time: 2.50045
PPO Batch Consumption Time: 0.29296
Total Iteration Time: 4.84611

Cumulative Model Updates: 249,410
Cumulative Timesteps: 2,080,681,606

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,608.11684
Policy Entropy: 2.53045
Value Function Loss: 0.01743

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.07818
Policy Update Magnitude: 0.30647
Value Function Update Magnitude: 0.27083

Collected Steps per Second: 21,818.88225
Overall Steps per Second: 10,385.16868

Timestep Collection Time: 2.29260
Timestep Consumption Time: 2.52408
PPO Batch Consumption Time: 0.29317
Total Iteration Time: 4.81668

Cumulative Model Updates: 249,416
Cumulative Timesteps: 2,080,731,628

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2080731628...
Checkpoint 2080731628 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,365.36090
Policy Entropy: 2.53651
Value Function Loss: 0.01525

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.08168
Policy Update Magnitude: 0.30185
Value Function Update Magnitude: 0.23089

Collected Steps per Second: 21,694.36034
Overall Steps per Second: 10,320.24690

Timestep Collection Time: 2.30521
Timestep Consumption Time: 2.54061
PPO Batch Consumption Time: 0.29156
Total Iteration Time: 4.84581

Cumulative Model Updates: 249,422
Cumulative Timesteps: 2,080,781,638

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65,155.47913
Policy Entropy: 2.51767
Value Function Loss: 0.01649

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.07580
Policy Update Magnitude: 0.30739
Value Function Update Magnitude: 0.26985

Collected Steps per Second: 20,888.00005
Overall Steps per Second: 10,360.12886

Timestep Collection Time: 2.39573
Timestep Consumption Time: 2.43452
PPO Batch Consumption Time: 0.27719
Total Iteration Time: 4.83025

Cumulative Model Updates: 249,428
Cumulative Timesteps: 2,080,831,680

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 2080831680...
Checkpoint 2080831680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 97,924.92666
Policy Entropy: 2.52274
Value Function Loss: 0.01701

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.08162
Policy Update Magnitude: 0.30945
Value Function Update Magnitude: 0.33174

Collected Steps per Second: 21,515.54612
Overall Steps per Second: 10,521.68411

Timestep Collection Time: 2.32483
Timestep Consumption Time: 2.42916
PPO Batch Consumption Time: 0.27902
Total Iteration Time: 4.75399

Cumulative Model Updates: 249,434
Cumulative Timesteps: 2,080,881,700

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 127,646.08967
Policy Entropy: 2.51442
Value Function Loss: 0.01622

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.08202
Policy Update Magnitude: 0.31005
Value Function Update Magnitude: 0.35630

Collected Steps per Second: 21,479.88074
Overall Steps per Second: 10,509.89416

Timestep Collection Time: 2.32897
Timestep Consumption Time: 2.43093
PPO Batch Consumption Time: 0.27927
Total Iteration Time: 4.75990

Cumulative Model Updates: 249,440
Cumulative Timesteps: 2,080,931,726

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2080931726...
Checkpoint 2080931726 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 134,181.49673
Policy Entropy: 2.53408
Value Function Loss: 0.01395

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.07538
Policy Update Magnitude: 0.30447
Value Function Update Magnitude: 0.33428

Collected Steps per Second: 21,059.07298
Overall Steps per Second: 10,592.02426

Timestep Collection Time: 2.37608
Timestep Consumption Time: 2.34804
PPO Batch Consumption Time: 0.27848
Total Iteration Time: 4.72412

Cumulative Model Updates: 249,446
Cumulative Timesteps: 2,080,981,764

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 124,095.87897
Policy Entropy: 2.52306
Value Function Loss: 0.01343

Mean KL Divergence: 0.00691
SB3 Clip Fraction: 0.06563
Policy Update Magnitude: 0.30517
Value Function Update Magnitude: 0.30799

Collected Steps per Second: 21,350.42779
Overall Steps per Second: 10,459.99770

Timestep Collection Time: 2.34244
Timestep Consumption Time: 2.43883
PPO Batch Consumption Time: 0.28749
Total Iteration Time: 4.78126

Cumulative Model Updates: 249,452
Cumulative Timesteps: 2,081,031,776

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2081031776...
Checkpoint 2081031776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87,098.77990
Policy Entropy: 2.53059
Value Function Loss: 0.01329

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.06948
Policy Update Magnitude: 0.33506
Value Function Update Magnitude: 0.29888

Collected Steps per Second: 21,190.74223
Overall Steps per Second: 10,597.54500

Timestep Collection Time: 2.35971
Timestep Consumption Time: 2.35874
PPO Batch Consumption Time: 0.27874
Total Iteration Time: 4.71845

Cumulative Model Updates: 249,458
Cumulative Timesteps: 2,081,081,780

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87,848.93802
Policy Entropy: 2.52479
Value Function Loss: 0.01488

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.08061
Policy Update Magnitude: 0.31404
Value Function Update Magnitude: 0.32263

Collected Steps per Second: 21,433.13455
Overall Steps per Second: 10,533.38918

Timestep Collection Time: 2.33377
Timestep Consumption Time: 2.41494
PPO Batch Consumption Time: 0.27840
Total Iteration Time: 4.74871

Cumulative Model Updates: 249,464
Cumulative Timesteps: 2,081,131,800

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2081131800...
Checkpoint 2081131800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 109,749.79834
Policy Entropy: 2.53188
Value Function Loss: 0.01493

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.07768
Policy Update Magnitude: 0.31344
Value Function Update Magnitude: 0.33215

Collected Steps per Second: 21,912.97598
Overall Steps per Second: 10,676.83977

Timestep Collection Time: 2.28194
Timestep Consumption Time: 2.40147
PPO Batch Consumption Time: 0.27825
Total Iteration Time: 4.68341

Cumulative Model Updates: 249,470
Cumulative Timesteps: 2,081,181,804

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65,440.35478
Policy Entropy: 2.52781
Value Function Loss: 0.01594

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.07960
Policy Update Magnitude: 0.32099
Value Function Update Magnitude: 0.34338

Collected Steps per Second: 22,264.19721
Overall Steps per Second: 10,596.47321

Timestep Collection Time: 2.24711
Timestep Consumption Time: 2.47428
PPO Batch Consumption Time: 0.28957
Total Iteration Time: 4.72138

Cumulative Model Updates: 249,476
Cumulative Timesteps: 2,081,231,834

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2081231834...
Checkpoint 2081231834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 63,742.88340
Policy Entropy: 2.53551
Value Function Loss: 0.01512

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.07746
Policy Update Magnitude: 0.31992
Value Function Update Magnitude: 0.30902

Collected Steps per Second: 21,907.34917
Overall Steps per Second: 10,443.46225

Timestep Collection Time: 2.28261
Timestep Consumption Time: 2.50565
PPO Batch Consumption Time: 0.29140
Total Iteration Time: 4.78826

Cumulative Model Updates: 249,482
Cumulative Timesteps: 2,081,281,840

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63,115.64332
Policy Entropy: 2.54337
Value Function Loss: 0.01480

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.08269
Policy Update Magnitude: 0.31207
Value Function Update Magnitude: 0.29070

Collected Steps per Second: 21,703.70340
Overall Steps per Second: 10,472.64259

Timestep Collection Time: 2.30468
Timestep Consumption Time: 2.47158
PPO Batch Consumption Time: 0.28562
Total Iteration Time: 4.77625

Cumulative Model Updates: 249,488
Cumulative Timesteps: 2,081,331,860

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2081331860...
Checkpoint 2081331860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 57,262.95785
Policy Entropy: 2.53721
Value Function Loss: 0.01557

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.08819
Policy Update Magnitude: 0.30997
Value Function Update Magnitude: 0.31740

Collected Steps per Second: 21,477.70844
Overall Steps per Second: 10,554.88419

Timestep Collection Time: 2.32800
Timestep Consumption Time: 2.40915
PPO Batch Consumption Time: 0.27859
Total Iteration Time: 4.73714

Cumulative Model Updates: 249,494
Cumulative Timesteps: 2,081,381,860

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51,830.88408
Policy Entropy: 2.55599
Value Function Loss: 0.01440

Mean KL Divergence: 0.01055
SB3 Clip Fraction: 0.09511
Policy Update Magnitude: 0.29819
Value Function Update Magnitude: 0.31561

Collected Steps per Second: 21,612.87132
Overall Steps per Second: 10,529.24900

Timestep Collection Time: 2.31529
Timestep Consumption Time: 2.43719
PPO Batch Consumption Time: 0.27912
Total Iteration Time: 4.75248

Cumulative Model Updates: 249,500
Cumulative Timesteps: 2,081,431,900

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 2081431900...
Checkpoint 2081431900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 51,830.88408
Policy Entropy: 2.53911
Value Function Loss: 0.01387

Mean KL Divergence: 0.01065
SB3 Clip Fraction: 0.09484
Policy Update Magnitude: 0.28827
Value Function Update Magnitude: 0.28827

Collected Steps per Second: 21,792.80239
Overall Steps per Second: 10,550.93907

Timestep Collection Time: 2.29535
Timestep Consumption Time: 2.44565
PPO Batch Consumption Time: 0.27828
Total Iteration Time: 4.74100

Cumulative Model Updates: 249,506
Cumulative Timesteps: 2,081,481,922

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50,794.35612
Policy Entropy: 2.56039
Value Function Loss: 0.01276

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.07763
Policy Update Magnitude: 0.28070
Value Function Update Magnitude: 0.26731

Collected Steps per Second: 22,217.61940
Overall Steps per Second: 10,540.92558

Timestep Collection Time: 2.25128
Timestep Consumption Time: 2.49385
PPO Batch Consumption Time: 0.28991
Total Iteration Time: 4.74512

Cumulative Model Updates: 249,512
Cumulative Timesteps: 2,081,531,940

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2081531940...
Checkpoint 2081531940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 60,726.03895
Policy Entropy: 2.55786
Value Function Loss: 0.01355

Mean KL Divergence: 0.00653
SB3 Clip Fraction: 0.06473
Policy Update Magnitude: 0.28731
Value Function Update Magnitude: 0.27867

Collected Steps per Second: 21,230.01895
Overall Steps per Second: 10,599.11114

Timestep Collection Time: 2.35525
Timestep Consumption Time: 2.36232
PPO Batch Consumption Time: 0.27870
Total Iteration Time: 4.71757

Cumulative Model Updates: 249,518
Cumulative Timesteps: 2,081,581,942

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75,826.97065
Policy Entropy: 2.54739
Value Function Loss: 0.01541

Mean KL Divergence: 0.00622
SB3 Clip Fraction: 0.05896
Policy Update Magnitude: 0.29393
Value Function Update Magnitude: 0.31007

Collected Steps per Second: 21,456.28672
Overall Steps per Second: 10,489.40583

Timestep Collection Time: 2.33218
Timestep Consumption Time: 2.43834
PPO Batch Consumption Time: 0.29350
Total Iteration Time: 4.77053

Cumulative Model Updates: 249,524
Cumulative Timesteps: 2,081,631,982

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 2081631982...
Checkpoint 2081631982 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 96,623.54027
Policy Entropy: 2.55507
Value Function Loss: 0.01452

Mean KL Divergence: 0.00704
SB3 Clip Fraction: 0.06659
Policy Update Magnitude: 0.29661
Value Function Update Magnitude: 0.30544

Collected Steps per Second: 21,477.36930
Overall Steps per Second: 10,668.95854

Timestep Collection Time: 2.32952
Timestep Consumption Time: 2.35997
PPO Batch Consumption Time: 0.27809
Total Iteration Time: 4.68949

Cumulative Model Updates: 249,530
Cumulative Timesteps: 2,081,682,014

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97,375.62229
Policy Entropy: 2.56740
Value Function Loss: 0.01426

Mean KL Divergence: 0.00631
SB3 Clip Fraction: 0.05951
Policy Update Magnitude: 0.28711
Value Function Update Magnitude: 0.29286

Collected Steps per Second: 21,521.63519
Overall Steps per Second: 10,438.90761

Timestep Collection Time: 2.32436
Timestep Consumption Time: 2.46771
PPO Batch Consumption Time: 0.28929
Total Iteration Time: 4.79207

Cumulative Model Updates: 249,536
Cumulative Timesteps: 2,081,732,038

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2081732038...
Checkpoint 2081732038 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 93,055.77473
Policy Entropy: 2.59359
Value Function Loss: 0.01207

Mean KL Divergence: 0.00617
SB3 Clip Fraction: 0.05972
Policy Update Magnitude: 0.27815
Value Function Update Magnitude: 0.26020

Collected Steps per Second: 21,931.64325
Overall Steps per Second: 10,692.35089

Timestep Collection Time: 2.28018
Timestep Consumption Time: 2.39681
PPO Batch Consumption Time: 0.27710
Total Iteration Time: 4.67699

Cumulative Model Updates: 249,542
Cumulative Timesteps: 2,081,782,046

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89,750.77748
Policy Entropy: 2.57612
Value Function Loss: 0.01235

Mean KL Divergence: 0.00603
SB3 Clip Fraction: 0.05673
Policy Update Magnitude: 0.27275
Value Function Update Magnitude: 0.24941

Collected Steps per Second: 21,203.96599
Overall Steps per Second: 10,393.61618

Timestep Collection Time: 2.35833
Timestep Consumption Time: 2.45289
PPO Batch Consumption Time: 0.28606
Total Iteration Time: 4.81122

Cumulative Model Updates: 249,548
Cumulative Timesteps: 2,081,832,052

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2081832052...
Checkpoint 2081832052 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89,750.77748
Policy Entropy: 2.57540
Value Function Loss: 0.01061

Mean KL Divergence: 0.00613
SB3 Clip Fraction: 0.05964
Policy Update Magnitude: 0.26957
Value Function Update Magnitude: 0.24739

Collected Steps per Second: 21,559.42236
Overall Steps per Second: 10,561.72660

Timestep Collection Time: 2.32028
Timestep Consumption Time: 2.41606
PPO Batch Consumption Time: 0.27884
Total Iteration Time: 4.73635

Cumulative Model Updates: 249,554
Cumulative Timesteps: 2,081,882,076

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89,750.77748
Policy Entropy: 2.58768
Value Function Loss: 0.00959

Mean KL Divergence: 0.00561
SB3 Clip Fraction: 0.05382
Policy Update Magnitude: 0.26371
Value Function Update Magnitude: 0.22183

Collected Steps per Second: 21,491.89984
Overall Steps per Second: 10,509.59384

Timestep Collection Time: 2.32711
Timestep Consumption Time: 2.43178
PPO Batch Consumption Time: 0.27819
Total Iteration Time: 4.75889

Cumulative Model Updates: 249,560
Cumulative Timesteps: 2,081,932,090

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2081932090...
Checkpoint 2081932090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 133,899.21684
Policy Entropy: 2.58987
Value Function Loss: 0.01052

Mean KL Divergence: 0.00571
SB3 Clip Fraction: 0.05592
Policy Update Magnitude: 0.25885
Value Function Update Magnitude: 0.19066

Collected Steps per Second: 20,373.06579
Overall Steps per Second: 10,217.68662

Timestep Collection Time: 2.45677
Timestep Consumption Time: 2.44179
PPO Batch Consumption Time: 0.27855
Total Iteration Time: 4.89856

Cumulative Model Updates: 249,566
Cumulative Timesteps: 2,081,982,142

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 113,481.88710
Policy Entropy: 2.58939
Value Function Loss: 0.01076

Mean KL Divergence: 0.00542
SB3 Clip Fraction: 0.05450
Policy Update Magnitude: 0.25831
Value Function Update Magnitude: 0.19306

Collected Steps per Second: 21,648.05893
Overall Steps per Second: 10,528.43611

Timestep Collection Time: 2.30968
Timestep Consumption Time: 2.43937
PPO Batch Consumption Time: 0.27752
Total Iteration Time: 4.74904

Cumulative Model Updates: 249,572
Cumulative Timesteps: 2,082,032,142

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2082032142...
Checkpoint 2082032142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 157,446.67928
Policy Entropy: 2.55383
Value Function Loss: 0.01373

Mean KL Divergence: 0.00589
SB3 Clip Fraction: 0.05840
Policy Update Magnitude: 0.27801
Value Function Update Magnitude: 0.24165

Collected Steps per Second: 21,795.83643
Overall Steps per Second: 10,494.41546

Timestep Collection Time: 2.29475
Timestep Consumption Time: 2.47121
PPO Batch Consumption Time: 0.27802
Total Iteration Time: 4.76596

Cumulative Model Updates: 249,578
Cumulative Timesteps: 2,082,082,158

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 110,773.84180
Policy Entropy: 2.55505
Value Function Loss: 0.01317

Mean KL Divergence: 0.00704
SB3 Clip Fraction: 0.06650
Policy Update Magnitude: 0.28864
Value Function Update Magnitude: 0.26259

Collected Steps per Second: 21,992.78159
Overall Steps per Second: 10,536.36499

Timestep Collection Time: 2.27529
Timestep Consumption Time: 2.47397
PPO Batch Consumption Time: 0.27938
Total Iteration Time: 4.74927

Cumulative Model Updates: 249,584
Cumulative Timesteps: 2,082,132,198

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 2082132198...
Checkpoint 2082132198 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 109,788.80237
Policy Entropy: 2.53717
Value Function Loss: 0.01637

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.07670
Policy Update Magnitude: 0.29873
Value Function Update Magnitude: 0.24286

Collected Steps per Second: 21,936.62701
Overall Steps per Second: 10,617.26828

Timestep Collection Time: 2.28020
Timestep Consumption Time: 2.43099
PPO Batch Consumption Time: 0.27900
Total Iteration Time: 4.71119

Cumulative Model Updates: 249,590
Cumulative Timesteps: 2,082,182,218

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90,864.14332
Policy Entropy: 2.53040
Value Function Loss: 0.01530

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.07670
Policy Update Magnitude: 0.31114
Value Function Update Magnitude: 0.21745

Collected Steps per Second: 22,258.32295
Overall Steps per Second: 10,456.23101

Timestep Collection Time: 2.24680
Timestep Consumption Time: 2.53599
PPO Batch Consumption Time: 0.29291
Total Iteration Time: 4.78279

Cumulative Model Updates: 249,596
Cumulative Timesteps: 2,082,232,228

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2082232228...
Checkpoint 2082232228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 66,441.44764
Policy Entropy: 2.51071
Value Function Loss: 0.01645

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.08527
Policy Update Magnitude: 0.30980
Value Function Update Magnitude: 0.20231

Collected Steps per Second: 21,823.17158
Overall Steps per Second: 10,586.08963

Timestep Collection Time: 2.29197
Timestep Consumption Time: 2.43291
PPO Batch Consumption Time: 0.27858
Total Iteration Time: 4.72488

Cumulative Model Updates: 249,602
Cumulative Timesteps: 2,082,282,246

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58,170.29980
Policy Entropy: 2.54112
Value Function Loss: 0.01450

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.07475
Policy Update Magnitude: 0.30497
Value Function Update Magnitude: 0.21479

Collected Steps per Second: 22,164.48308
Overall Steps per Second: 10,518.73282

Timestep Collection Time: 2.25712
Timestep Consumption Time: 2.49896
PPO Batch Consumption Time: 0.28854
Total Iteration Time: 4.75609

Cumulative Model Updates: 249,608
Cumulative Timesteps: 2,082,332,274

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2082332274...
Checkpoint 2082332274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 50,703.99333
Policy Entropy: 2.56765
Value Function Loss: 0.01336

Mean KL Divergence: 0.00723
SB3 Clip Fraction: 0.06783
Policy Update Magnitude: 0.28712
Value Function Update Magnitude: 0.24189

Collected Steps per Second: 21,663.99329
Overall Steps per Second: 10,565.31202

Timestep Collection Time: 2.30807
Timestep Consumption Time: 2.42459
PPO Batch Consumption Time: 0.27867
Total Iteration Time: 4.73266

Cumulative Model Updates: 249,614
Cumulative Timesteps: 2,082,382,276

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 113,077.79445
Policy Entropy: 2.57276
Value Function Loss: 0.01397

Mean KL Divergence: 0.00720
SB3 Clip Fraction: 0.06870
Policy Update Magnitude: 0.29245
Value Function Update Magnitude: 0.25283

Collected Steps per Second: 21,824.87827
Overall Steps per Second: 10,514.80886

Timestep Collection Time: 2.29115
Timestep Consumption Time: 2.46443
PPO Batch Consumption Time: 0.28482
Total Iteration Time: 4.75558

Cumulative Model Updates: 249,620
Cumulative Timesteps: 2,082,432,280

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2082432280...
Checkpoint 2082432280 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 129,813.10108
Policy Entropy: 2.58533
Value Function Loss: 0.01456

Mean KL Divergence: 0.00653
SB3 Clip Fraction: 0.06397
Policy Update Magnitude: 0.29832
Value Function Update Magnitude: 0.26169

Collected Steps per Second: 21,413.98878
Overall Steps per Second: 10,343.18494

Timestep Collection Time: 2.33502
Timestep Consumption Time: 2.49928
PPO Batch Consumption Time: 0.29092
Total Iteration Time: 4.83429

Cumulative Model Updates: 249,626
Cumulative Timesteps: 2,082,482,282

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 112,515.93952
Policy Entropy: 2.57644
Value Function Loss: 0.01535

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.07160
Policy Update Magnitude: 0.29631
Value Function Update Magnitude: 0.30352

Collected Steps per Second: 21,822.52373
Overall Steps per Second: 10,432.79623

Timestep Collection Time: 2.29158
Timestep Consumption Time: 2.50177
PPO Batch Consumption Time: 0.29265
Total Iteration Time: 4.79335

Cumulative Model Updates: 249,632
Cumulative Timesteps: 2,082,532,290

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2082532290...
Checkpoint 2082532290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 98,585.24007
Policy Entropy: 2.56300
Value Function Loss: 0.01509

Mean KL Divergence: 0.00691
SB3 Clip Fraction: 0.06446
Policy Update Magnitude: 0.29526
Value Function Update Magnitude: 0.33459

Collected Steps per Second: 21,442.60531
Overall Steps per Second: 10,491.82045

Timestep Collection Time: 2.33181
Timestep Consumption Time: 2.43381
PPO Batch Consumption Time: 0.27880
Total Iteration Time: 4.76562

Cumulative Model Updates: 249,638
Cumulative Timesteps: 2,082,582,290

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 108,027.87607
Policy Entropy: 2.55349
Value Function Loss: 0.01418

Mean KL Divergence: 0.00659
SB3 Clip Fraction: 0.06323
Policy Update Magnitude: 0.29686
Value Function Update Magnitude: 0.32680

Collected Steps per Second: 21,908.47362
Overall Steps per Second: 10,483.61536

Timestep Collection Time: 2.28450
Timestep Consumption Time: 2.48961
PPO Batch Consumption Time: 0.28526
Total Iteration Time: 4.77412

Cumulative Model Updates: 249,644
Cumulative Timesteps: 2,082,632,340

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 2082632340...
Checkpoint 2082632340 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 80,504.98184
Policy Entropy: 2.55810
Value Function Loss: 0.01422

Mean KL Divergence: 0.00726
SB3 Clip Fraction: 0.06723
Policy Update Magnitude: 0.29736
Value Function Update Magnitude: 0.29821

Collected Steps per Second: 21,961.37860
Overall Steps per Second: 10,551.26912

Timestep Collection Time: 2.27791
Timestep Consumption Time: 2.46332
PPO Batch Consumption Time: 0.27858
Total Iteration Time: 4.74123

Cumulative Model Updates: 249,650
Cumulative Timesteps: 2,082,682,366

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63,308.90320
Policy Entropy: 2.58422
Value Function Loss: 0.01301

Mean KL Divergence: 0.00642
SB3 Clip Fraction: 0.06468
Policy Update Magnitude: 0.28412
Value Function Update Magnitude: 0.27979

Collected Steps per Second: 22,136.94109
Overall Steps per Second: 10,502.24777

Timestep Collection Time: 2.25948
Timestep Consumption Time: 2.50312
PPO Batch Consumption Time: 0.28980
Total Iteration Time: 4.76260

Cumulative Model Updates: 249,656
Cumulative Timesteps: 2,082,732,384

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2082732384...
Checkpoint 2082732384 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87,380.48635
Policy Entropy: 2.60143
Value Function Loss: 0.01197

Mean KL Divergence: 0.00662
SB3 Clip Fraction: 0.06502
Policy Update Magnitude: 0.27470
Value Function Update Magnitude: 0.26087

Collected Steps per Second: 21,886.65026
Overall Steps per Second: 10,602.57959

Timestep Collection Time: 2.28450
Timestep Consumption Time: 2.43134
PPO Batch Consumption Time: 0.27979
Total Iteration Time: 4.71583

Cumulative Model Updates: 249,662
Cumulative Timesteps: 2,082,782,384

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78,966.22612
Policy Entropy: 2.57642
Value Function Loss: 0.01511

Mean KL Divergence: 0.00597
SB3 Clip Fraction: 0.05767
Policy Update Magnitude: 0.27729
Value Function Update Magnitude: 0.23516

Collected Steps per Second: 22,289.82087
Overall Steps per Second: 10,511.32656

Timestep Collection Time: 2.24452
Timestep Consumption Time: 2.51511
PPO Batch Consumption Time: 0.29466
Total Iteration Time: 4.75963

Cumulative Model Updates: 249,668
Cumulative Timesteps: 2,082,832,414

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2082832414...
Checkpoint 2082832414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 107,134.52400
Policy Entropy: 2.55262
Value Function Loss: 0.01600

Mean KL Divergence: 0.00605
SB3 Clip Fraction: 0.05537
Policy Update Magnitude: 0.29037
Value Function Update Magnitude: 0.23491

Collected Steps per Second: 21,838.97697
Overall Steps per Second: 10,585.61786

Timestep Collection Time: 2.29141
Timestep Consumption Time: 2.43595
PPO Batch Consumption Time: 0.27878
Total Iteration Time: 4.72736

Cumulative Model Updates: 249,674
Cumulative Timesteps: 2,082,882,456

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81,248.13711
Policy Entropy: 2.52273
Value Function Loss: 0.01632

Mean KL Divergence: 0.00666
SB3 Clip Fraction: 0.06028
Policy Update Magnitude: 0.29988
Value Function Update Magnitude: 0.30238

Collected Steps per Second: 22,018.81146
Overall Steps per Second: 10,539.84318

Timestep Collection Time: 2.27079
Timestep Consumption Time: 2.47312
PPO Batch Consumption Time: 0.28908
Total Iteration Time: 4.74390

Cumulative Model Updates: 249,680
Cumulative Timesteps: 2,082,932,456

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2082932456...
Checkpoint 2082932456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 99,212.91727
Policy Entropy: 2.54123
Value Function Loss: 0.01351

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.07075
Policy Update Magnitude: 0.29905
Value Function Update Magnitude: 0.32417

Collected Steps per Second: 20,861.58470
Overall Steps per Second: 10,564.19829

Timestep Collection Time: 2.39819
Timestep Consumption Time: 2.33762
PPO Batch Consumption Time: 0.27792
Total Iteration Time: 4.73581

Cumulative Model Updates: 249,686
Cumulative Timesteps: 2,082,982,486

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80,774.57774
Policy Entropy: 2.53550
Value Function Loss: 0.01421

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.07439
Policy Update Magnitude: 0.29583
Value Function Update Magnitude: 0.29449

Collected Steps per Second: 20,842.93296
Overall Steps per Second: 10,482.77930

Timestep Collection Time: 2.39918
Timestep Consumption Time: 2.37112
PPO Batch Consumption Time: 0.27927
Total Iteration Time: 4.77030

Cumulative Model Updates: 249,692
Cumulative Timesteps: 2,083,032,492

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2083032492...
Checkpoint 2083032492 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 70,362.29701
Policy Entropy: 2.53324
Value Function Loss: 0.01449

Mean KL Divergence: 0.00710
SB3 Clip Fraction: 0.06961
Policy Update Magnitude: 0.29459
Value Function Update Magnitude: 0.29327

Collected Steps per Second: 20,429.93246
Overall Steps per Second: 10,229.20266

Timestep Collection Time: 2.44945
Timestep Consumption Time: 2.44263
PPO Batch Consumption Time: 0.29209
Total Iteration Time: 4.89207

Cumulative Model Updates: 249,698
Cumulative Timesteps: 2,083,082,534

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 101,519.38155
Policy Entropy: 2.53178
Value Function Loss: 0.01477

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.07636
Policy Update Magnitude: 0.29803
Value Function Update Magnitude: 0.31498

Collected Steps per Second: 21,050.49036
Overall Steps per Second: 10,456.35932

Timestep Collection Time: 2.37543
Timestep Consumption Time: 2.40673
PPO Batch Consumption Time: 0.28648
Total Iteration Time: 4.78216

Cumulative Model Updates: 249,704
Cumulative Timesteps: 2,083,132,538

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2083132538...
Checkpoint 2083132538 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 125,332.36539
Policy Entropy: 2.54688
Value Function Loss: 0.01458

Mean KL Divergence: 0.00685
SB3 Clip Fraction: 0.06504
Policy Update Magnitude: 0.29662
Value Function Update Magnitude: 0.35505

Collected Steps per Second: 21,457.75029
Overall Steps per Second: 10,341.10229

Timestep Collection Time: 2.33016
Timestep Consumption Time: 2.50491
PPO Batch Consumption Time: 0.29128
Total Iteration Time: 4.83507

Cumulative Model Updates: 249,710
Cumulative Timesteps: 2,083,182,538

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 138,579.84276
Policy Entropy: 2.54799
Value Function Loss: 0.01300

Mean KL Divergence: 0.00708
SB3 Clip Fraction: 0.06893
Policy Update Magnitude: 0.28856
Value Function Update Magnitude: 0.33961

Collected Steps per Second: 22,156.91721
Overall Steps per Second: 10,680.00896

Timestep Collection Time: 2.25799
Timestep Consumption Time: 2.42647
PPO Batch Consumption Time: 0.27929
Total Iteration Time: 4.68445

Cumulative Model Updates: 249,716
Cumulative Timesteps: 2,083,232,568

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2083232568...
Checkpoint 2083232568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 109,034.39087
Policy Entropy: 2.54427
Value Function Loss: 0.01225

Mean KL Divergence: 0.00719
SB3 Clip Fraction: 0.07023
Policy Update Magnitude: 0.28195
Value Function Update Magnitude: 0.31681

Collected Steps per Second: 21,566.22324
Overall Steps per Second: 10,431.03964

Timestep Collection Time: 2.31881
Timestep Consumption Time: 2.47534
PPO Batch Consumption Time: 0.29122
Total Iteration Time: 4.79415

Cumulative Model Updates: 249,722
Cumulative Timesteps: 2,083,282,576

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 104,668.95955
Policy Entropy: 2.55069
Value Function Loss: 0.01265

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.07603
Policy Update Magnitude: 0.28657
Value Function Update Magnitude: 0.29957

Collected Steps per Second: 22,232.87141
Overall Steps per Second: 10,671.31523

Timestep Collection Time: 2.24910
Timestep Consumption Time: 2.43673
PPO Batch Consumption Time: 0.27909
Total Iteration Time: 4.68583

Cumulative Model Updates: 249,728
Cumulative Timesteps: 2,083,332,580

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2083332580...
Checkpoint 2083332580 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 81,188.88433
Policy Entropy: 2.56077
Value Function Loss: 0.01316

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.07252
Policy Update Magnitude: 0.28477
Value Function Update Magnitude: 0.30751

Collected Steps per Second: 21,561.45318
Overall Steps per Second: 10,379.18274

Timestep Collection Time: 2.31997
Timestep Consumption Time: 2.49948
PPO Batch Consumption Time: 0.29284
Total Iteration Time: 4.81945

Cumulative Model Updates: 249,734
Cumulative Timesteps: 2,083,382,602

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67,971.06454
Policy Entropy: 2.56409
Value Function Loss: 0.01392

Mean KL Divergence: 0.00715
SB3 Clip Fraction: 0.06843
Policy Update Magnitude: 0.30067
Value Function Update Magnitude: 0.32937

Collected Steps per Second: 22,499.20876
Overall Steps per Second: 10,731.92142

Timestep Collection Time: 2.22310
Timestep Consumption Time: 2.43757
PPO Batch Consumption Time: 0.27941
Total Iteration Time: 4.66068

Cumulative Model Updates: 249,740
Cumulative Timesteps: 2,083,432,620

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2083432620...
Checkpoint 2083432620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 72,546.77409
Policy Entropy: 2.56068
Value Function Loss: 0.01368

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.07479
Policy Update Magnitude: 0.29248
Value Function Update Magnitude: 0.32530

Collected Steps per Second: 21,830.85676
Overall Steps per Second: 10,614.59975

Timestep Collection Time: 2.29217
Timestep Consumption Time: 2.42209
PPO Batch Consumption Time: 0.27881
Total Iteration Time: 4.71426

Cumulative Model Updates: 249,746
Cumulative Timesteps: 2,083,482,660

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55,275.18206
Policy Entropy: 2.57088
Value Function Loss: 0.01333

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.08330
Policy Update Magnitude: 0.27428
Value Function Update Magnitude: 0.28198

Collected Steps per Second: 21,761.11220
Overall Steps per Second: 10,581.03299

Timestep Collection Time: 2.29795
Timestep Consumption Time: 2.42805
PPO Batch Consumption Time: 0.27767
Total Iteration Time: 4.72600

Cumulative Model Updates: 249,752
Cumulative Timesteps: 2,083,532,666

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2083532666...
Checkpoint 2083532666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,228.65904
Policy Entropy: 2.58521
Value Function Loss: 0.01267

Mean KL Divergence: 0.01122
SB3 Clip Fraction: 0.09626
Policy Update Magnitude: 0.26417
Value Function Update Magnitude: 0.25444

Collected Steps per Second: 21,392.54098
Overall Steps per Second: 10,529.13736

Timestep Collection Time: 2.33782
Timestep Consumption Time: 2.41204
PPO Batch Consumption Time: 0.27828
Total Iteration Time: 4.74987

Cumulative Model Updates: 249,758
Cumulative Timesteps: 2,083,582,678

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,084.07788
Policy Entropy: 2.57191
Value Function Loss: 0.01211

Mean KL Divergence: 0.01318
SB3 Clip Fraction: 0.11023
Policy Update Magnitude: 0.26296
Value Function Update Magnitude: 0.25771

Collected Steps per Second: 21,784.97390
Overall Steps per Second: 10,583.61024

Timestep Collection Time: 2.29562
Timestep Consumption Time: 2.42961
PPO Batch Consumption Time: 0.27698
Total Iteration Time: 4.72523

Cumulative Model Updates: 249,764
Cumulative Timesteps: 2,083,632,688

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2083632688...
Checkpoint 2083632688 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 52,914.20732
Policy Entropy: 2.53408
Value Function Loss: 0.01373

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.09270
Policy Update Magnitude: 0.27958
Value Function Update Magnitude: 0.28437

Collected Steps per Second: 21,499.71103
Overall Steps per Second: 10,498.57306

Timestep Collection Time: 2.32617
Timestep Consumption Time: 2.43752
PPO Batch Consumption Time: 0.27891
Total Iteration Time: 4.76370

Cumulative Model Updates: 249,770
Cumulative Timesteps: 2,083,682,700

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48,313.31954
Policy Entropy: 2.51916
Value Function Loss: 0.01337

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.07443
Policy Update Magnitude: 0.28830
Value Function Update Magnitude: 0.32920

Collected Steps per Second: 22,142.28438
Overall Steps per Second: 10,604.60245

Timestep Collection Time: 2.25948
Timestep Consumption Time: 2.45829
PPO Batch Consumption Time: 0.27720
Total Iteration Time: 4.71776

Cumulative Model Updates: 249,776
Cumulative Timesteps: 2,083,732,730

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2083732730...
Checkpoint 2083732730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 60,179.37545
Policy Entropy: 2.50396
Value Function Loss: 0.01288

Mean KL Divergence: 0.00674
SB3 Clip Fraction: 0.06378
Policy Update Magnitude: 0.29227
Value Function Update Magnitude: 0.31901

Collected Steps per Second: 21,705.39946
Overall Steps per Second: 10,481.26865

Timestep Collection Time: 2.30533
Timestep Consumption Time: 2.46872
PPO Batch Consumption Time: 0.27907
Total Iteration Time: 4.77404

Cumulative Model Updates: 249,782
Cumulative Timesteps: 2,083,782,768

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60,179.37545
Policy Entropy: 2.54666
Value Function Loss: 0.01121

Mean KL Divergence: 0.00584
SB3 Clip Fraction: 0.05516
Policy Update Magnitude: 0.28639
Value Function Update Magnitude: 0.27304

Collected Steps per Second: 22,192.09106
Overall Steps per Second: 10,540.98659

Timestep Collection Time: 2.25378
Timestep Consumption Time: 2.49113
PPO Batch Consumption Time: 0.28955
Total Iteration Time: 4.74491

Cumulative Model Updates: 249,788
Cumulative Timesteps: 2,083,832,784

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2083832784...
Checkpoint 2083832784 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 120,514.31940
Policy Entropy: 2.57854
Value Function Loss: 0.01075

Mean KL Divergence: 0.00741
SB3 Clip Fraction: 0.06852
Policy Update Magnitude: 0.27271
Value Function Update Magnitude: 0.23514

Collected Steps per Second: 21,645.45731
Overall Steps per Second: 10,540.89132

Timestep Collection Time: 2.31023
Timestep Consumption Time: 2.43377
PPO Batch Consumption Time: 0.27904
Total Iteration Time: 4.74400

Cumulative Model Updates: 249,794
Cumulative Timesteps: 2,083,882,790

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 111,532.51012
Policy Entropy: 2.59494
Value Function Loss: 0.01126

Mean KL Divergence: 0.00658
SB3 Clip Fraction: 0.06471
Policy Update Magnitude: 0.26951
Value Function Update Magnitude: 0.24317

Collected Steps per Second: 21,973.58951
Overall Steps per Second: 10,544.16871

Timestep Collection Time: 2.27591
Timestep Consumption Time: 2.46699
PPO Batch Consumption Time: 0.28589
Total Iteration Time: 4.74291

Cumulative Model Updates: 249,800
Cumulative Timesteps: 2,083,932,800

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2083932800...
Checkpoint 2083932800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 101,052.57496
Policy Entropy: 2.58467
Value Function Loss: 0.01346

Mean KL Divergence: 0.00728
SB3 Clip Fraction: 0.06903
Policy Update Magnitude: 0.29001
Value Function Update Magnitude: 0.28816

Collected Steps per Second: 22,180.11209
Overall Steps per Second: 10,693.01469

Timestep Collection Time: 2.25472
Timestep Consumption Time: 2.42216
PPO Batch Consumption Time: 0.27695
Total Iteration Time: 4.67689

Cumulative Model Updates: 249,806
Cumulative Timesteps: 2,083,982,810

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 122,620.40868
Policy Entropy: 2.57137
Value Function Loss: 0.01414

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.06961
Policy Update Magnitude: 0.29346
Value Function Update Magnitude: 0.33825

Collected Steps per Second: 22,251.53568
Overall Steps per Second: 10,579.17784

Timestep Collection Time: 2.24811
Timestep Consumption Time: 2.48042
PPO Batch Consumption Time: 0.28913
Total Iteration Time: 4.72853

Cumulative Model Updates: 249,812
Cumulative Timesteps: 2,084,032,834

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2084032834...
Checkpoint 2084032834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 122,620.40868
Policy Entropy: 2.57792
Value Function Loss: 0.01207

Mean KL Divergence: 0.00646
SB3 Clip Fraction: 0.05962
Policy Update Magnitude: 0.28120
Value Function Update Magnitude: 0.31466

Collected Steps per Second: 21,658.09241
Overall Steps per Second: 10,428.05764

Timestep Collection Time: 2.31027
Timestep Consumption Time: 2.48794
PPO Batch Consumption Time: 0.28799
Total Iteration Time: 4.79821

Cumulative Model Updates: 249,818
Cumulative Timesteps: 2,084,082,870

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91,963.62039
Policy Entropy: 2.58417
Value Function Loss: 0.01270

Mean KL Divergence: 0.00569
SB3 Clip Fraction: 0.05615
Policy Update Magnitude: 0.27808
Value Function Update Magnitude: 0.23480

Collected Steps per Second: 21,336.92544
Overall Steps per Second: 10,466.15991

Timestep Collection Time: 2.34411
Timestep Consumption Time: 2.43472
PPO Batch Consumption Time: 0.27864
Total Iteration Time: 4.77883

Cumulative Model Updates: 249,824
Cumulative Timesteps: 2,084,132,886

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2084132886...
Checkpoint 2084132886 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 88,755.75110
Policy Entropy: 2.56214
Value Function Loss: 0.01530

Mean KL Divergence: 0.00699
SB3 Clip Fraction: 0.06644
Policy Update Magnitude: 0.30507
Value Function Update Magnitude: 0.25974

Collected Steps per Second: 21,284.60327
Overall Steps per Second: 10,306.72508

Timestep Collection Time: 2.35071
Timestep Consumption Time: 2.50379
PPO Batch Consumption Time: 0.29367
Total Iteration Time: 4.85450

Cumulative Model Updates: 249,830
Cumulative Timesteps: 2,084,182,920

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 117,588.32639
Policy Entropy: 2.56165
Value Function Loss: 0.01500

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.07184
Policy Update Magnitude: 0.30315
Value Function Update Magnitude: 0.33834

Collected Steps per Second: 21,874.69733
Overall Steps per Second: 10,454.03020

Timestep Collection Time: 2.28693
Timestep Consumption Time: 2.49840
PPO Batch Consumption Time: 0.29223
Total Iteration Time: 4.78533

Cumulative Model Updates: 249,836
Cumulative Timesteps: 2,084,232,946

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2084232946...
Checkpoint 2084232946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 74,936.20579
Policy Entropy: 2.54635
Value Function Loss: 0.01409

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.06666
Policy Update Magnitude: 0.29863
Value Function Update Magnitude: 0.34117

Collected Steps per Second: 21,519.66467
Overall Steps per Second: 10,479.56331

Timestep Collection Time: 2.32448
Timestep Consumption Time: 2.44881
PPO Batch Consumption Time: 0.27899
Total Iteration Time: 4.77329

Cumulative Model Updates: 249,842
Cumulative Timesteps: 2,084,282,968

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59,032.87067
Policy Entropy: 2.58327
Value Function Loss: 0.01458

Mean KL Divergence: 0.00677
SB3 Clip Fraction: 0.06467
Policy Update Magnitude: 0.30342
Value Function Update Magnitude: 0.30084

Collected Steps per Second: 22,155.77183
Overall Steps per Second: 10,439.48866

Timestep Collection Time: 2.25819
Timestep Consumption Time: 2.53438
PPO Batch Consumption Time: 0.28759
Total Iteration Time: 4.79257

Cumulative Model Updates: 249,848
Cumulative Timesteps: 2,084,333,000

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2084333000...
Checkpoint 2084333000 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 56,392.53753
Policy Entropy: 2.60048
Value Function Loss: 0.01418

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.07438
Policy Update Magnitude: 0.29946
Value Function Update Magnitude: 0.29832

Collected Steps per Second: 21,920.96171
Overall Steps per Second: 10,614.29045

Timestep Collection Time: 2.28284
Timestep Consumption Time: 2.43175
PPO Batch Consumption Time: 0.27908
Total Iteration Time: 4.71459

Cumulative Model Updates: 249,854
Cumulative Timesteps: 2,084,383,042

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49,051.80009
Policy Entropy: 2.62372
Value Function Loss: 0.01333

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.07768
Policy Update Magnitude: 0.28596
Value Function Update Magnitude: 0.28161

Collected Steps per Second: 21,992.79566
Overall Steps per Second: 10,521.05453

Timestep Collection Time: 2.27402
Timestep Consumption Time: 2.47950
PPO Batch Consumption Time: 0.28678
Total Iteration Time: 4.75352

Cumulative Model Updates: 249,860
Cumulative Timesteps: 2,084,433,054

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2084433054...
Checkpoint 2084433054 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 68,641.67111
Policy Entropy: 2.61200
Value Function Loss: 0.01243

Mean KL Divergence: 0.01121
SB3 Clip Fraction: 0.10131
Policy Update Magnitude: 0.27741
Value Function Update Magnitude: 0.26146

Collected Steps per Second: 21,932.69871
Overall Steps per Second: 10,627.26418

Timestep Collection Time: 2.28061
Timestep Consumption Time: 2.42615
PPO Batch Consumption Time: 0.27934
Total Iteration Time: 4.70676

Cumulative Model Updates: 249,866
Cumulative Timesteps: 2,084,483,074

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68,641.67111
Policy Entropy: 2.57664
Value Function Loss: 0.01440

Mean KL Divergence: 0.01154
SB3 Clip Fraction: 0.09952
Policy Update Magnitude: 0.28326
Value Function Update Magnitude: 0.27502

Collected Steps per Second: 22,205.54625
Overall Steps per Second: 10,518.49895

Timestep Collection Time: 2.25394
Timestep Consumption Time: 2.50434
PPO Batch Consumption Time: 0.29273
Total Iteration Time: 4.75828

Cumulative Model Updates: 249,872
Cumulative Timesteps: 2,084,533,124

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 2084533124...
Checkpoint 2084533124 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 116,616.42879
Policy Entropy: 2.55462
Value Function Loss: 0.01445

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.08466
Policy Update Magnitude: 0.30200
Value Function Update Magnitude: 0.31054

Collected Steps per Second: 20,717.77615
Overall Steps per Second: 10,260.79686

Timestep Collection Time: 2.41464
Timestep Consumption Time: 2.46081
PPO Batch Consumption Time: 0.29336
Total Iteration Time: 4.87545

Cumulative Model Updates: 249,878
Cumulative Timesteps: 2,084,583,150

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 98,918.52060
Policy Entropy: 2.54735
Value Function Loss: 0.01477

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.08388
Policy Update Magnitude: 0.30565
Value Function Update Magnitude: 0.32741

Collected Steps per Second: 21,391.07135
Overall Steps per Second: 10,493.63598

Timestep Collection Time: 2.33845
Timestep Consumption Time: 2.42844
PPO Batch Consumption Time: 0.29168
Total Iteration Time: 4.76689

Cumulative Model Updates: 249,884
Cumulative Timesteps: 2,084,633,172

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2084633172...
Checkpoint 2084633172 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86,957.71504
Policy Entropy: 2.54233
Value Function Loss: 0.01380

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.07891
Policy Update Magnitude: 0.30304
Value Function Update Magnitude: 0.31672

Collected Steps per Second: 20,650.29348
Overall Steps per Second: 10,455.55592

Timestep Collection Time: 2.42185
Timestep Consumption Time: 2.36144
PPO Batch Consumption Time: 0.27847
Total Iteration Time: 4.78329

Cumulative Model Updates: 249,890
Cumulative Timesteps: 2,084,683,184

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 119,074.77275
Policy Entropy: 2.54074
Value Function Loss: 0.01398

Mean KL Divergence: 0.00770
SB3 Clip Fraction: 0.07415
Policy Update Magnitude: 0.31186
Value Function Update Magnitude: 0.31306

Collected Steps per Second: 20,976.52562
Overall Steps per Second: 10,444.65258

Timestep Collection Time: 2.38457
Timestep Consumption Time: 2.40448
PPO Batch Consumption Time: 0.27831
Total Iteration Time: 4.78905

Cumulative Model Updates: 249,896
Cumulative Timesteps: 2,084,733,204

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2084733204...
Checkpoint 2084733204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 119,074.77275
Policy Entropy: 2.52221
Value Function Loss: 0.01337

Mean KL Divergence: 0.00644
SB3 Clip Fraction: 0.06171
Policy Update Magnitude: 0.30894
Value Function Update Magnitude: 0.32593

Collected Steps per Second: 21,539.21191
Overall Steps per Second: 10,418.04113

Timestep Collection Time: 2.32255
Timestep Consumption Time: 2.47931
PPO Batch Consumption Time: 0.28996
Total Iteration Time: 4.80186

Cumulative Model Updates: 249,902
Cumulative Timesteps: 2,084,783,230

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 111,830.01801
Policy Entropy: 2.53864
Value Function Loss: 0.01209

Mean KL Divergence: 0.00672
SB3 Clip Fraction: 0.06026
Policy Update Magnitude: 0.29851
Value Function Update Magnitude: 0.28461

Collected Steps per Second: 21,507.61687
Overall Steps per Second: 10,456.69938

Timestep Collection Time: 2.32569
Timestep Consumption Time: 2.45785
PPO Batch Consumption Time: 0.28653
Total Iteration Time: 4.78354

Cumulative Model Updates: 249,908
Cumulative Timesteps: 2,084,833,250

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2084833250...
Checkpoint 2084833250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86,540.47689
Policy Entropy: 2.55202
Value Function Loss: 0.01441

Mean KL Divergence: 0.00654
SB3 Clip Fraction: 0.05932
Policy Update Magnitude: 0.29437
Value Function Update Magnitude: 0.24638

Collected Steps per Second: 21,243.48616
Overall Steps per Second: 10,260.87161

Timestep Collection Time: 2.35376
Timestep Consumption Time: 2.51932
PPO Batch Consumption Time: 0.29360
Total Iteration Time: 4.87308

Cumulative Model Updates: 249,914
Cumulative Timesteps: 2,084,883,252

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 139,127.33548
Policy Entropy: 2.58347
Value Function Loss: 0.01473

Mean KL Divergence: 0.00587
SB3 Clip Fraction: 0.05709
Policy Update Magnitude: 0.29760
Value Function Update Magnitude: 0.25348

Collected Steps per Second: 22,084.18771
Overall Steps per Second: 10,435.62845

Timestep Collection Time: 2.26515
Timestep Consumption Time: 2.52843
PPO Batch Consumption Time: 0.28966
Total Iteration Time: 4.79358

Cumulative Model Updates: 249,920
Cumulative Timesteps: 2,084,933,276

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2084933276...
Checkpoint 2084933276 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 144,149.94832
Policy Entropy: 2.59430
Value Function Loss: 0.01588

Mean KL Divergence: 0.00718
SB3 Clip Fraction: 0.07016
Policy Update Magnitude: 0.29853
Value Function Update Magnitude: 0.26388

Collected Steps per Second: 21,518.20039
Overall Steps per Second: 10,350.06715

Timestep Collection Time: 2.32510
Timestep Consumption Time: 2.50888
PPO Batch Consumption Time: 0.28975
Total Iteration Time: 4.83398

Cumulative Model Updates: 249,926
Cumulative Timesteps: 2,084,983,308

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 135,452.27398
Policy Entropy: 2.59030
Value Function Loss: 0.01693

Mean KL Divergence: 0.00679
SB3 Clip Fraction: 0.06506
Policy Update Magnitude: 0.31032
Value Function Update Magnitude: 0.30333

Collected Steps per Second: 22,352.86324
Overall Steps per Second: 10,696.88810

Timestep Collection Time: 2.23721
Timestep Consumption Time: 2.43780
PPO Batch Consumption Time: 0.27947
Total Iteration Time: 4.67500

Cumulative Model Updates: 249,932
Cumulative Timesteps: 2,085,033,316

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2085033316...
Checkpoint 2085033316 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 82,205.67082
Policy Entropy: 2.58610
Value Function Loss: 0.01707

Mean KL Divergence: 0.00688
SB3 Clip Fraction: 0.06639
Policy Update Magnitude: 0.31472
Value Function Update Magnitude: 0.32405

Collected Steps per Second: 21,920.76243
Overall Steps per Second: 10,602.83715

Timestep Collection Time: 2.28176
Timestep Consumption Time: 2.43565
PPO Batch Consumption Time: 0.27904
Total Iteration Time: 4.71742

Cumulative Model Updates: 249,938
Cumulative Timesteps: 2,085,083,334

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 114,035.93948
Policy Entropy: 2.57948
Value Function Loss: 0.01627

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.07637
Policy Update Magnitude: 0.31043
Value Function Update Magnitude: 0.29504

Collected Steps per Second: 22,011.17548
Overall Steps per Second: 10,496.11953

Timestep Collection Time: 2.27321
Timestep Consumption Time: 2.49389
PPO Batch Consumption Time: 0.29041
Total Iteration Time: 4.76710

Cumulative Model Updates: 249,944
Cumulative Timesteps: 2,085,133,370

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 2085133370...
Checkpoint 2085133370 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 162,222.60220
Policy Entropy: 2.57843
Value Function Loss: 0.01535

Mean KL Divergence: 0.00703
SB3 Clip Fraction: 0.06541
Policy Update Magnitude: 0.30236
Value Function Update Magnitude: 0.23112

Collected Steps per Second: 21,068.85725
Overall Steps per Second: 10,587.12873

Timestep Collection Time: 2.37440
Timestep Consumption Time: 2.35077
PPO Batch Consumption Time: 0.27854
Total Iteration Time: 4.72517

Cumulative Model Updates: 249,950
Cumulative Timesteps: 2,085,183,396

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83,381.25446
Policy Entropy: 2.58032
Value Function Loss: 0.01623

Mean KL Divergence: 0.00739
SB3 Clip Fraction: 0.06901
Policy Update Magnitude: 0.30557
Value Function Update Magnitude: 0.23315

Collected Steps per Second: 21,075.72599
Overall Steps per Second: 10,575.51344

Timestep Collection Time: 2.37278
Timestep Consumption Time: 2.35588
PPO Batch Consumption Time: 0.27776
Total Iteration Time: 4.72866

Cumulative Model Updates: 249,956
Cumulative Timesteps: 2,085,233,404

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2085233404...
Checkpoint 2085233404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 92,274.06854
Policy Entropy: 2.59401
Value Function Loss: 0.01742

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.07188
Policy Update Magnitude: 0.30876
Value Function Update Magnitude: 0.28651

Collected Steps per Second: 20,980.45629
Overall Steps per Second: 10,542.56745

Timestep Collection Time: 2.38393
Timestep Consumption Time: 2.36026
PPO Batch Consumption Time: 0.27851
Total Iteration Time: 4.74420

Cumulative Model Updates: 249,962
Cumulative Timesteps: 2,085,283,420

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84,527.99227
Policy Entropy: 2.57586
Value Function Loss: 0.01733

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.08454
Policy Update Magnitude: 0.31366
Value Function Update Magnitude: 0.31598

Collected Steps per Second: 20,981.73586
Overall Steps per Second: 10,434.87221

Timestep Collection Time: 2.38417
Timestep Consumption Time: 2.40976
PPO Batch Consumption Time: 0.27839
Total Iteration Time: 4.79393

Cumulative Model Updates: 249,968
Cumulative Timesteps: 2,085,333,444

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2085333444...
Checkpoint 2085333444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 85,301.30881
Policy Entropy: 2.55929
Value Function Loss: 0.01587

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.09234
Policy Update Magnitude: 0.31005
Value Function Update Magnitude: 0.32957

Collected Steps per Second: 21,486.19058
Overall Steps per Second: 10,441.02895

Timestep Collection Time: 2.32912
Timestep Consumption Time: 2.46389
PPO Batch Consumption Time: 0.28996
Total Iteration Time: 4.79301

Cumulative Model Updates: 249,974
Cumulative Timesteps: 2,085,383,488

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52,245.45302
Policy Entropy: 2.57010
Value Function Loss: 0.01528

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.08364
Policy Update Magnitude: 0.30535
Value Function Update Magnitude: 0.30621

Collected Steps per Second: 21,655.51981
Overall Steps per Second: 10,619.45572

Timestep Collection Time: 2.30962
Timestep Consumption Time: 2.40023
PPO Batch Consumption Time: 0.27828
Total Iteration Time: 4.70985

Cumulative Model Updates: 249,980
Cumulative Timesteps: 2,085,433,504

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2085433504...
Checkpoint 2085433504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 52,702.36380
Policy Entropy: 2.58647
Value Function Loss: 0.01444

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.07416
Policy Update Magnitude: 0.29977
Value Function Update Magnitude: 0.29557

Collected Steps per Second: 21,312.26350
Overall Steps per Second: 10,275.70401

Timestep Collection Time: 2.34785
Timestep Consumption Time: 2.52169
PPO Batch Consumption Time: 0.29104
Total Iteration Time: 4.86954

Cumulative Model Updates: 249,986
Cumulative Timesteps: 2,085,483,542

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63,366.09633
Policy Entropy: 2.57540
Value Function Loss: 0.01399

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.08196
Policy Update Magnitude: 0.28870
Value Function Update Magnitude: 0.29419

Collected Steps per Second: 21,917.47156
Overall Steps per Second: 10,454.10540

Timestep Collection Time: 2.28192
Timestep Consumption Time: 2.50223
PPO Batch Consumption Time: 0.28549
Total Iteration Time: 4.78415

Cumulative Model Updates: 249,992
Cumulative Timesteps: 2,085,533,556

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2085533556...
Checkpoint 2085533556 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 63,485.59859
Policy Entropy: 2.56717
Value Function Loss: 0.01440

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.08691
Policy Update Magnitude: 0.29260
Value Function Update Magnitude: 0.27572

Collected Steps per Second: 22,003.89462
Overall Steps per Second: 10,623.16702

Timestep Collection Time: 2.27242
Timestep Consumption Time: 2.43447
PPO Batch Consumption Time: 0.27852
Total Iteration Time: 4.70688

Cumulative Model Updates: 249,998
Cumulative Timesteps: 2,085,583,558

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60,742.20342
Policy Entropy: 2.57205
Value Function Loss: 0.01456

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.08403
Policy Update Magnitude: 0.29930
Value Function Update Magnitude: 0.28608

Collected Steps per Second: 21,913.73816
Overall Steps per Second: 10,459.66161

Timestep Collection Time: 2.28195
Timestep Consumption Time: 2.49890
PPO Batch Consumption Time: 0.29117
Total Iteration Time: 4.78084

Cumulative Model Updates: 250,004
Cumulative Timesteps: 2,085,633,564

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2085633564...
Checkpoint 2085633564 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 53,435.62658
Policy Entropy: 2.57860
Value Function Loss: 0.01523

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.09275
Policy Update Magnitude: 0.30480
Value Function Update Magnitude: 0.31742

Collected Steps per Second: 22,034.53046
Overall Steps per Second: 10,695.92418

Timestep Collection Time: 2.26962
Timestep Consumption Time: 2.40599
PPO Batch Consumption Time: 0.27747
Total Iteration Time: 4.67561

Cumulative Model Updates: 250,010
Cumulative Timesteps: 2,085,683,574

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62,870.53147
Policy Entropy: 2.59071
Value Function Loss: 0.01399

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.08360
Policy Update Magnitude: 0.29952
Value Function Update Magnitude: 0.30229

Collected Steps per Second: 21,918.39792
Overall Steps per Second: 10,475.24854

Timestep Collection Time: 2.28210
Timestep Consumption Time: 2.49296
PPO Batch Consumption Time: 0.29285
Total Iteration Time: 4.77507

Cumulative Model Updates: 250,016
Cumulative Timesteps: 2,085,733,594

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2085733594...
Checkpoint 2085733594 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40,346.97967
Policy Entropy: 2.59767
Value Function Loss: 0.01376

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.08692
Policy Update Magnitude: 0.29391
Value Function Update Magnitude: 0.30316

Collected Steps per Second: 21,189.98027
Overall Steps per Second: 10,649.42463

Timestep Collection Time: 2.36130
Timestep Consumption Time: 2.33717
PPO Batch Consumption Time: 0.27674
Total Iteration Time: 4.69847

Cumulative Model Updates: 250,022
Cumulative Timesteps: 2,085,783,630

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,492.27159
Policy Entropy: 2.59155
Value Function Loss: 0.01194

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.07057
Policy Update Magnitude: 0.29285
Value Function Update Magnitude: 0.28944

Collected Steps per Second: 21,475.70161
Overall Steps per Second: 10,507.08141

Timestep Collection Time: 2.32840
Timestep Consumption Time: 2.43068
PPO Batch Consumption Time: 0.29073
Total Iteration Time: 4.75908

Cumulative Model Updates: 250,028
Cumulative Timesteps: 2,085,833,634

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2085833634...
Checkpoint 2085833634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 85,807.66229
Policy Entropy: 2.56995
Value Function Loss: 0.01658

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.07563
Policy Update Magnitude: 0.30521
Value Function Update Magnitude: 0.30615

Collected Steps per Second: 21,062.56825
Overall Steps per Second: 10,488.93801

Timestep Collection Time: 2.37483
Timestep Consumption Time: 2.39400
PPO Batch Consumption Time: 0.28515
Total Iteration Time: 4.76883

Cumulative Model Updates: 250,034
Cumulative Timesteps: 2,085,883,654

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63,272.57628
Policy Entropy: 2.57466
Value Function Loss: 0.01540

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.09462
Policy Update Magnitude: 0.30996
Value Function Update Magnitude: 0.35040

Collected Steps per Second: 21,354.03361
Overall Steps per Second: 10,547.77255

Timestep Collection Time: 2.34195
Timestep Consumption Time: 2.39934
PPO Batch Consumption Time: 0.27698
Total Iteration Time: 4.74129

Cumulative Model Updates: 250,040
Cumulative Timesteps: 2,085,933,664

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2085933664...
Checkpoint 2085933664 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 63,272.57628
Policy Entropy: 2.56812
Value Function Loss: 0.01439

Mean KL Divergence: 0.00748
SB3 Clip Fraction: 0.07422
Policy Update Magnitude: 0.29505
Value Function Update Magnitude: 0.34698

Collected Steps per Second: 21,427.70525
Overall Steps per Second: 10,549.38099

Timestep Collection Time: 2.33455
Timestep Consumption Time: 2.40734
PPO Batch Consumption Time: 0.27820
Total Iteration Time: 4.74189

Cumulative Model Updates: 250,046
Cumulative Timesteps: 2,085,983,688

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48,555.57455
Policy Entropy: 2.56053
Value Function Loss: 0.01237

Mean KL Divergence: 0.00684
SB3 Clip Fraction: 0.06816
Policy Update Magnitude: 0.28524
Value Function Update Magnitude: 0.30076

Collected Steps per Second: 22,141.87894
Overall Steps per Second: 10,460.41310

Timestep Collection Time: 2.25961
Timestep Consumption Time: 2.52338
PPO Batch Consumption Time: 0.29261
Total Iteration Time: 4.78299

Cumulative Model Updates: 250,052
Cumulative Timesteps: 2,086,033,720

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2086033720...
Checkpoint 2086033720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,131.46939
Policy Entropy: 2.55292
Value Function Loss: 0.01195

Mean KL Divergence: 0.00661
SB3 Clip Fraction: 0.06548
Policy Update Magnitude: 0.28254
Value Function Update Magnitude: 0.27631

Collected Steps per Second: 21,758.70407
Overall Steps per Second: 10,559.27347

Timestep Collection Time: 2.29968
Timestep Consumption Time: 2.43910
PPO Batch Consumption Time: 0.27870
Total Iteration Time: 4.73877

Cumulative Model Updates: 250,058
Cumulative Timesteps: 2,086,083,758

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51,547.39558
Policy Entropy: 2.54357
Value Function Loss: 0.01377

Mean KL Divergence: 0.00623
SB3 Clip Fraction: 0.06018
Policy Update Magnitude: 0.28800
Value Function Update Magnitude: 0.28662

Collected Steps per Second: 22,132.88984
Overall Steps per Second: 10,560.49947

Timestep Collection Time: 2.25935
Timestep Consumption Time: 2.47584
PPO Batch Consumption Time: 0.28634
Total Iteration Time: 4.73519

Cumulative Model Updates: 250,064
Cumulative Timesteps: 2,086,133,764

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2086133764...
Checkpoint 2086133764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 57,478.75474
Policy Entropy: 2.53877
Value Function Loss: 0.01388

Mean KL Divergence: 0.00638
SB3 Clip Fraction: 0.06428
Policy Update Magnitude: 0.29348
Value Function Update Magnitude: 0.31522

Collected Steps per Second: 21,734.46583
Overall Steps per Second: 10,568.57264

Timestep Collection Time: 2.30086
Timestep Consumption Time: 2.43090
PPO Batch Consumption Time: 0.27872
Total Iteration Time: 4.73176

Cumulative Model Updates: 250,070
Cumulative Timesteps: 2,086,183,772

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47,900.95842
Policy Entropy: 2.55960
Value Function Loss: 0.01268

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.07223
Policy Update Magnitude: 0.29028
Value Function Update Magnitude: 0.31867

Collected Steps per Second: 22,337.19087
Overall Steps per Second: 10,508.99461

Timestep Collection Time: 2.24003
Timestep Consumption Time: 2.52122
PPO Batch Consumption Time: 0.29306
Total Iteration Time: 4.76125

Cumulative Model Updates: 250,076
Cumulative Timesteps: 2,086,233,808

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 2086233808...
Checkpoint 2086233808 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 85,616.05283
Policy Entropy: 2.58234
Value Function Loss: 0.01168

Mean KL Divergence: 0.00653
SB3 Clip Fraction: 0.06326
Policy Update Magnitude: 0.28488
Value Function Update Magnitude: 0.29366

Collected Steps per Second: 21,826.71001
Overall Steps per Second: 10,589.66808

Timestep Collection Time: 2.29178
Timestep Consumption Time: 2.43188
PPO Batch Consumption Time: 0.27861
Total Iteration Time: 4.72366

Cumulative Model Updates: 250,082
Cumulative Timesteps: 2,086,283,830

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79,959.76146
Policy Entropy: 2.59063
Value Function Loss: 0.01178

Mean KL Divergence: 0.00664
SB3 Clip Fraction: 0.06341
Policy Update Magnitude: 0.28099
Value Function Update Magnitude: 0.28627

Collected Steps per Second: 21,682.00706
Overall Steps per Second: 10,566.04536

Timestep Collection Time: 2.30698
Timestep Consumption Time: 2.42705
PPO Batch Consumption Time: 0.27764
Total Iteration Time: 4.73403

Cumulative Model Updates: 250,088
Cumulative Timesteps: 2,086,333,850

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2086333850...
Checkpoint 2086333850 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 93,537.78010
Policy Entropy: 2.56261
Value Function Loss: 0.01314

Mean KL Divergence: 0.00628
SB3 Clip Fraction: 0.05815
Policy Update Magnitude: 0.28914
Value Function Update Magnitude: 0.30520

Collected Steps per Second: 21,416.38109
Overall Steps per Second: 10,503.68501

Timestep Collection Time: 2.33522
Timestep Consumption Time: 2.42615
PPO Batch Consumption Time: 0.27844
Total Iteration Time: 4.76138

Cumulative Model Updates: 250,094
Cumulative Timesteps: 2,086,383,862

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81,424.35638
Policy Entropy: 2.55669
Value Function Loss: 0.01307

Mean KL Divergence: 0.00747
SB3 Clip Fraction: 0.06974
Policy Update Magnitude: 0.29517
Value Function Update Magnitude: 0.31557

Collected Steps per Second: 21,542.83091
Overall Steps per Second: 10,476.96750

Timestep Collection Time: 2.32281
Timestep Consumption Time: 2.45338
PPO Batch Consumption Time: 0.27900
Total Iteration Time: 4.77619

Cumulative Model Updates: 250,100
Cumulative Timesteps: 2,086,433,902

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 2086433902...
Checkpoint 2086433902 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 93,520.62075
Policy Entropy: 2.54894
Value Function Loss: 0.01295

Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.07189
Policy Update Magnitude: 0.29769
Value Function Update Magnitude: 0.31261

Collected Steps per Second: 20,513.95835
Overall Steps per Second: 10,253.59246

Timestep Collection Time: 2.43736
Timestep Consumption Time: 2.43897
PPO Batch Consumption Time: 0.27874
Total Iteration Time: 4.87634

Cumulative Model Updates: 250,106
Cumulative Timesteps: 2,086,483,902

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 225,640.06440
Policy Entropy: 2.55250
Value Function Loss: 0.01498

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.07099
Policy Update Magnitude: 0.30386
Value Function Update Magnitude: 0.31472

Collected Steps per Second: 21,986.84482
Overall Steps per Second: 10,467.53920

Timestep Collection Time: 2.27481
Timestep Consumption Time: 2.50339
PPO Batch Consumption Time: 0.29004
Total Iteration Time: 4.77820

Cumulative Model Updates: 250,112
Cumulative Timesteps: 2,086,533,918

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2086533918...
Checkpoint 2086533918 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 142,470.19193
Policy Entropy: 2.56335
Value Function Loss: 0.01504

Mean KL Divergence: 0.00724
SB3 Clip Fraction: 0.06348
Policy Update Magnitude: 0.29963
Value Function Update Magnitude: 0.30377

Collected Steps per Second: 21,239.42104
Overall Steps per Second: 10,301.34110

Timestep Collection Time: 2.35553
Timestep Consumption Time: 2.50112
PPO Batch Consumption Time: 0.29375
Total Iteration Time: 4.85665

Cumulative Model Updates: 250,118
Cumulative Timesteps: 2,086,583,948

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 107,361.12510
Policy Entropy: 2.58618
Value Function Loss: 0.01485

Mean KL Divergence: 0.00681
SB3 Clip Fraction: 0.06491
Policy Update Magnitude: 0.28844
Value Function Update Magnitude: 0.27979

Collected Steps per Second: 21,752.26996
Overall Steps per Second: 10,366.11938

Timestep Collection Time: 2.30073
Timestep Consumption Time: 2.52712
PPO Batch Consumption Time: 0.29238
Total Iteration Time: 4.82784

Cumulative Model Updates: 250,124
Cumulative Timesteps: 2,086,633,994

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 2086633994...
Checkpoint 2086633994 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 107,361.12510
Policy Entropy: 2.55740
Value Function Loss: 0.01256

Mean KL Divergence: 0.00606
SB3 Clip Fraction: 0.06111
Policy Update Magnitude: 0.28016
Value Function Update Magnitude: 0.27081

Collected Steps per Second: 21,877.21968
Overall Steps per Second: 10,550.05384

Timestep Collection Time: 2.28749
Timestep Consumption Time: 2.45599
PPO Batch Consumption Time: 0.27894
Total Iteration Time: 4.74348

Cumulative Model Updates: 250,130
Cumulative Timesteps: 2,086,684,038

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91,344.37256
Policy Entropy: 2.53796
Value Function Loss: 0.01381

Mean KL Divergence: 0.00589
SB3 Clip Fraction: 0.06065
Policy Update Magnitude: 0.29001
Value Function Update Magnitude: 0.30013

Collected Steps per Second: 22,228.56791
Overall Steps per Second: 10,524.61598

Timestep Collection Time: 2.25035
Timestep Consumption Time: 2.50251
PPO Batch Consumption Time: 0.28816
Total Iteration Time: 4.75286

Cumulative Model Updates: 250,136
Cumulative Timesteps: 2,086,734,060

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2086734060...
Checkpoint 2086734060 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 113,299.04957
Policy Entropy: 2.55795
Value Function Loss: 0.01234

Mean KL Divergence: 0.00667
SB3 Clip Fraction: 0.06369
Policy Update Magnitude: 0.29436
Value Function Update Magnitude: 0.31744

Collected Steps per Second: 21,666.53349
Overall Steps per Second: 10,578.54285

Timestep Collection Time: 2.30891
Timestep Consumption Time: 2.42010
PPO Batch Consumption Time: 0.27935
Total Iteration Time: 4.72901

Cumulative Model Updates: 250,142
Cumulative Timesteps: 2,086,784,086

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 154,338.08973
Policy Entropy: 2.58335
Value Function Loss: 0.01297

Mean KL Divergence: 0.00679
SB3 Clip Fraction: 0.06548
Policy Update Magnitude: 0.28870
Value Function Update Magnitude: 0.31656

Collected Steps per Second: 22,314.13083
Overall Steps per Second: 10,528.08112

Timestep Collection Time: 2.24109
Timestep Consumption Time: 2.50887
PPO Batch Consumption Time: 0.29336
Total Iteration Time: 4.74996

Cumulative Model Updates: 250,148
Cumulative Timesteps: 2,086,834,094

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2086834094...
Checkpoint 2086834094 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 123,397.90259
Policy Entropy: 2.60176
Value Function Loss: 0.01179

Mean KL Divergence: 0.00650
SB3 Clip Fraction: 0.06380
Policy Update Magnitude: 0.28383
Value Function Update Magnitude: 0.27543

Collected Steps per Second: 21,975.83440
Overall Steps per Second: 10,634.28916

Timestep Collection Time: 2.27559
Timestep Consumption Time: 2.42693
PPO Batch Consumption Time: 0.27908
Total Iteration Time: 4.70252

Cumulative Model Updates: 250,154
Cumulative Timesteps: 2,086,884,102

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 123,397.90259
Policy Entropy: 2.56461
Value Function Loss: 0.01203

Mean KL Divergence: 0.00682
SB3 Clip Fraction: 0.06463
Policy Update Magnitude: 0.27800
Value Function Update Magnitude: 0.20464

Collected Steps per Second: 21,801.07489
Overall Steps per Second: 10,580.68762

Timestep Collection Time: 2.29466
Timestep Consumption Time: 2.43339
PPO Batch Consumption Time: 0.29229
Total Iteration Time: 4.72805

Cumulative Model Updates: 250,160
Cumulative Timesteps: 2,086,934,128

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2086934128...
Checkpoint 2086934128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 102,101.53356
Policy Entropy: 2.54336
Value Function Loss: 0.01361

Mean KL Divergence: 0.00690
SB3 Clip Fraction: 0.06575
Policy Update Magnitude: 0.28375
Value Function Update Magnitude: 0.17210

Collected Steps per Second: 21,146.57006
Overall Steps per Second: 10,624.48376

Timestep Collection Time: 2.36549
Timestep Consumption Time: 2.34269
PPO Batch Consumption Time: 0.27721
Total Iteration Time: 4.70818

Cumulative Model Updates: 250,166
Cumulative Timesteps: 2,086,984,150

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 114,045.76915
Policy Entropy: 2.53445
Value Function Loss: 0.01259

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.07686
Policy Update Magnitude: 0.28318
Value Function Update Magnitude: 0.22330

Collected Steps per Second: 21,244.44171
Overall Steps per Second: 10,464.13908

Timestep Collection Time: 2.35403
Timestep Consumption Time: 2.42515
PPO Batch Consumption Time: 0.29297
Total Iteration Time: 4.77918

Cumulative Model Updates: 250,172
Cumulative Timesteps: 2,087,034,160

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2087034160...
Checkpoint 2087034160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 94,311.36756
Policy Entropy: 2.52866
Value Function Loss: 0.01385

Mean KL Divergence: 0.01248
SB3 Clip Fraction: 0.10148
Policy Update Magnitude: 0.27637
Value Function Update Magnitude: 0.25068

Collected Steps per Second: 20,577.73518
Overall Steps per Second: 10,149.20995

Timestep Collection Time: 2.43039
Timestep Consumption Time: 2.49728
PPO Batch Consumption Time: 0.29348
Total Iteration Time: 4.92767

Cumulative Model Updates: 250,178
Cumulative Timesteps: 2,087,084,172

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 111,493.40603
Policy Entropy: 2.52626
Value Function Loss: 0.01466

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.08927
Policy Update Magnitude: 0.29072
Value Function Update Magnitude: 0.27419

Collected Steps per Second: 21,833.29665
Overall Steps per Second: 10,475.84005

Timestep Collection Time: 2.29054
Timestep Consumption Time: 2.48330
PPO Batch Consumption Time: 0.29355
Total Iteration Time: 4.77384

Cumulative Model Updates: 250,184
Cumulative Timesteps: 2,087,134,182

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2087134182...
Checkpoint 2087134182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 82,335.34757
Policy Entropy: 2.51364
Value Function Loss: 0.01651

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.08378
Policy Update Magnitude: 0.31522
Value Function Update Magnitude: 0.28001

Collected Steps per Second: 21,209.84131
Overall Steps per Second: 10,506.43226

Timestep Collection Time: 2.35815
Timestep Consumption Time: 2.40236
PPO Batch Consumption Time: 0.27812
Total Iteration Time: 4.76051

Cumulative Model Updates: 250,190
Cumulative Timesteps: 2,087,184,198

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70,370.32588
Policy Entropy: 2.51574
Value Function Loss: 0.01623

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.07559
Policy Update Magnitude: 0.32103
Value Function Update Magnitude: 0.26472

Collected Steps per Second: 21,819.36887
Overall Steps per Second: 10,534.34579

Timestep Collection Time: 2.29200
Timestep Consumption Time: 2.45533
PPO Batch Consumption Time: 0.27921
Total Iteration Time: 4.74733

Cumulative Model Updates: 250,196
Cumulative Timesteps: 2,087,234,208

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2087234208...
Checkpoint 2087234208 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 76,597.13171
Policy Entropy: 2.52867
Value Function Loss: 0.01462

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.07229
Policy Update Magnitude: 0.30964
Value Function Update Magnitude: 0.22804

Collected Steps per Second: 22,090.90797
Overall Steps per Second: 10,548.08059

Timestep Collection Time: 2.26337
Timestep Consumption Time: 2.47682
PPO Batch Consumption Time: 0.27877
Total Iteration Time: 4.74020

Cumulative Model Updates: 250,202
Cumulative Timesteps: 2,087,284,208

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 130,050.72206
Policy Entropy: 2.53651
Value Function Loss: 0.01440

Mean KL Divergence: 0.00728
SB3 Clip Fraction: 0.06914
Policy Update Magnitude: 0.30157
Value Function Update Magnitude: 0.25175

Collected Steps per Second: 22,116.19016
Overall Steps per Second: 10,442.61418

Timestep Collection Time: 2.26160
Timestep Consumption Time: 2.52820
PPO Batch Consumption Time: 0.29223
Total Iteration Time: 4.78980

Cumulative Model Updates: 250,208
Cumulative Timesteps: 2,087,334,226

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2087334226...
Checkpoint 2087334226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 114,169.27858
Policy Entropy: 2.54357
Value Function Loss: 0.01476

Mean KL Divergence: 0.00649
SB3 Clip Fraction: 0.06294
Policy Update Magnitude: 0.30249
Value Function Update Magnitude: 0.29506

Collected Steps per Second: 21,512.03613
Overall Steps per Second: 10,356.50995

Timestep Collection Time: 2.32530
Timestep Consumption Time: 2.50470
PPO Batch Consumption Time: 0.29427
Total Iteration Time: 4.83001

Cumulative Model Updates: 250,214
Cumulative Timesteps: 2,087,384,248

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82,263.80784
Policy Entropy: 2.55283
Value Function Loss: 0.01468

Mean KL Divergence: 0.00718
SB3 Clip Fraction: 0.06754
Policy Update Magnitude: 0.30534
Value Function Update Magnitude: 0.31641

Collected Steps per Second: 22,301.31821
Overall Steps per Second: 10,734.72351

Timestep Collection Time: 2.24265
Timestep Consumption Time: 2.41644
PPO Batch Consumption Time: 0.27958
Total Iteration Time: 4.65909

Cumulative Model Updates: 250,220
Cumulative Timesteps: 2,087,434,262

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2087434262...
Checkpoint 2087434262 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 120,454.18522
Policy Entropy: 2.56290
Value Function Loss: 0.01467

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.07994
Policy Update Magnitude: 0.30248
Value Function Update Magnitude: 0.30864

Collected Steps per Second: 22,021.69593
Overall Steps per Second: 10,639.05628

Timestep Collection Time: 2.27158
Timestep Consumption Time: 2.43034
PPO Batch Consumption Time: 0.27928
Total Iteration Time: 4.70192

Cumulative Model Updates: 250,226
Cumulative Timesteps: 2,087,484,286

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99,185.30010
Policy Entropy: 2.53456
Value Function Loss: 0.01436

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.07174
Policy Update Magnitude: 0.29942
Value Function Update Magnitude: 0.29477

Collected Steps per Second: 21,493.59381
Overall Steps per Second: 10,526.31601

Timestep Collection Time: 2.32748
Timestep Consumption Time: 2.42499
PPO Batch Consumption Time: 0.28996
Total Iteration Time: 4.75247

Cumulative Model Updates: 250,232
Cumulative Timesteps: 2,087,534,312

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2087534312...
Checkpoint 2087534312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 91,362.59328
Policy Entropy: 2.53851
Value Function Loss: 0.01379

Mean KL Divergence: 0.00664
SB3 Clip Fraction: 0.06174
Policy Update Magnitude: 0.30566
Value Function Update Magnitude: 0.26431

Collected Steps per Second: 21,072.46954
Overall Steps per Second: 10,599.80142

Timestep Collection Time: 2.37333
Timestep Consumption Time: 2.34487
PPO Batch Consumption Time: 0.27814
Total Iteration Time: 4.71820

Cumulative Model Updates: 250,238
Cumulative Timesteps: 2,087,584,324

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58,799.22788
Policy Entropy: 2.51600
Value Function Loss: 0.01569

Mean KL Divergence: 0.00639
SB3 Clip Fraction: 0.05868
Policy Update Magnitude: 0.31627
Value Function Update Magnitude: 0.25198

Collected Steps per Second: 20,879.16334
Overall Steps per Second: 10,517.33906

Timestep Collection Time: 2.39626
Timestep Consumption Time: 2.36083
PPO Batch Consumption Time: 0.27884
Total Iteration Time: 4.75710

Cumulative Model Updates: 250,244
Cumulative Timesteps: 2,087,634,356

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2087634356...
Checkpoint 2087634356 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 78,938.11886
Policy Entropy: 2.54103
Value Function Loss: 0.01511

Mean KL Divergence: 0.00661
SB3 Clip Fraction: 0.06173
Policy Update Magnitude: 0.31677
Value Function Update Magnitude: 0.26350

Collected Steps per Second: 20,669.23698
Overall Steps per Second: 10,192.74776

Timestep Collection Time: 2.42080
Timestep Consumption Time: 2.48818
PPO Batch Consumption Time: 0.29165
Total Iteration Time: 4.90898

Cumulative Model Updates: 250,250
Cumulative Timesteps: 2,087,684,392

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 72,878.55664
Policy Entropy: 2.55913
Value Function Loss: 0.01389

Mean KL Divergence: 0.00726
SB3 Clip Fraction: 0.06576
Policy Update Magnitude: 0.30625
Value Function Update Magnitude: 0.29695

Collected Steps per Second: 21,560.84930
Overall Steps per Second: 10,454.52066

Timestep Collection Time: 2.32022
Timestep Consumption Time: 2.46488
PPO Batch Consumption Time: 0.28635
Total Iteration Time: 4.78511

Cumulative Model Updates: 250,256
Cumulative Timesteps: 2,087,734,418

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2087734418...
Checkpoint 2087734418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 72,878.55664
Policy Entropy: 2.58402
Value Function Loss: 0.01089

Mean KL Divergence: 0.00608
SB3 Clip Fraction: 0.05752
Policy Update Magnitude: 0.28907
Value Function Update Magnitude: 0.27446

Collected Steps per Second: 21,402.13748
Overall Steps per Second: 10,573.01906

Timestep Collection Time: 2.33631
Timestep Consumption Time: 2.39290
PPO Batch Consumption Time: 0.27863
Total Iteration Time: 4.72921

Cumulative Model Updates: 250,262
Cumulative Timesteps: 2,087,784,420

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70,729.28204
Policy Entropy: 2.57515
Value Function Loss: 0.01065

Mean KL Divergence: 0.00606
SB3 Clip Fraction: 0.05811
Policy Update Magnitude: 0.27619
Value Function Update Magnitude: 0.23512

Collected Steps per Second: 21,671.31364
Overall Steps per Second: 10,479.47428

Timestep Collection Time: 2.30849
Timestep Consumption Time: 2.46541
PPO Batch Consumption Time: 0.27908
Total Iteration Time: 4.77390

Cumulative Model Updates: 250,268
Cumulative Timesteps: 2,087,834,448

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2087834448...
Checkpoint 2087834448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 61,378.63134
Policy Entropy: 2.56121
Value Function Loss: 0.01305

Mean KL Divergence: 0.00667
SB3 Clip Fraction: 0.06564
Policy Update Magnitude: 0.29076
Value Function Update Magnitude: 0.24197

Collected Steps per Second: 22,002.72765
Overall Steps per Second: 10,414.10451

Timestep Collection Time: 2.27354
Timestep Consumption Time: 2.52995
PPO Batch Consumption Time: 0.29066
Total Iteration Time: 4.80349

Cumulative Model Updates: 250,274
Cumulative Timesteps: 2,087,884,472

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61,378.63134
Policy Entropy: 2.54489
Value Function Loss: 0.01287

Mean KL Divergence: 0.00783
SB3 Clip Fraction: 0.07606
Policy Update Magnitude: 0.30084
Value Function Update Magnitude: 0.29580

Collected Steps per Second: 21,958.46596
Overall Steps per Second: 10,456.25572

Timestep Collection Time: 2.27748
Timestep Consumption Time: 2.50530
PPO Batch Consumption Time: 0.28988
Total Iteration Time: 4.78278

Cumulative Model Updates: 250,280
Cumulative Timesteps: 2,087,934,482

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2087934482...
Checkpoint 2087934482 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 92,808.50109
Policy Entropy: 2.56576
Value Function Loss: 0.01374

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.07363
Policy Update Magnitude: 0.29518
Value Function Update Magnitude: 0.27917

Collected Steps per Second: 22,284.16972
Overall Steps per Second: 10,525.12269

Timestep Collection Time: 2.24437
Timestep Consumption Time: 2.50750
PPO Batch Consumption Time: 0.29345
Total Iteration Time: 4.75187

Cumulative Model Updates: 250,286
Cumulative Timesteps: 2,087,984,496

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76,455.68292
Policy Entropy: 2.57044
Value Function Loss: 0.01225

Mean KL Divergence: 0.00622
SB3 Clip Fraction: 0.06018
Policy Update Magnitude: 0.28515
Value Function Update Magnitude: 0.26478

Collected Steps per Second: 22,141.08517
Overall Steps per Second: 10,464.39043

Timestep Collection Time: 2.25906
Timestep Consumption Time: 2.52077
PPO Batch Consumption Time: 0.29333
Total Iteration Time: 4.77983

Cumulative Model Updates: 250,292
Cumulative Timesteps: 2,088,034,514

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2088034514...
Checkpoint 2088034514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 67,570.38355
Policy Entropy: 2.58293
Value Function Loss: 0.01217

Mean KL Divergence: 0.00544
SB3 Clip Fraction: 0.05406
Policy Update Magnitude: 0.27855
Value Function Update Magnitude: 0.27427

Collected Steps per Second: 22,058.47618
Overall Steps per Second: 10,557.67493

Timestep Collection Time: 2.26716
Timestep Consumption Time: 2.46968
PPO Batch Consumption Time: 0.28432
Total Iteration Time: 4.73684

Cumulative Model Updates: 250,298
Cumulative Timesteps: 2,088,084,524

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 114,151.82083
Policy Entropy: 2.55410
Value Function Loss: 0.01569

Mean KL Divergence: 0.00558
SB3 Clip Fraction: 0.05480
Policy Update Magnitude: 0.28944
Value Function Update Magnitude: 0.25557

Collected Steps per Second: 22,062.16190
Overall Steps per Second: 10,471.83936

Timestep Collection Time: 2.26687
Timestep Consumption Time: 2.50899
PPO Batch Consumption Time: 0.29147
Total Iteration Time: 4.77586

Cumulative Model Updates: 250,304
Cumulative Timesteps: 2,088,134,536

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2088134536...
Checkpoint 2088134536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 124,539.16480
Policy Entropy: 2.53035
Value Function Loss: 0.01688

Mean KL Divergence: 0.00684
SB3 Clip Fraction: 0.06765
Policy Update Magnitude: 0.30156
Value Function Update Magnitude: 0.25510

Collected Steps per Second: 22,040.26426
Overall Steps per Second: 10,644.75837

Timestep Collection Time: 2.26975
Timestep Consumption Time: 2.42984
PPO Batch Consumption Time: 0.27933
Total Iteration Time: 4.69959

Cumulative Model Updates: 250,310
Cumulative Timesteps: 2,088,184,562

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 100,823.09114
Policy Entropy: 2.51875
Value Function Loss: 0.01720

Mean KL Divergence: 0.00757
SB3 Clip Fraction: 0.07299
Policy Update Magnitude: 0.30004
Value Function Update Magnitude: 0.29893

Collected Steps per Second: 21,411.90264
Overall Steps per Second: 10,468.98811

Timestep Collection Time: 2.33683
Timestep Consumption Time: 2.44262
PPO Batch Consumption Time: 0.27934
Total Iteration Time: 4.77945

Cumulative Model Updates: 250,316
Cumulative Timesteps: 2,088,234,598

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 2088234598...
Checkpoint 2088234598 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 83,105.58160
Policy Entropy: 2.52642
Value Function Loss: 0.01555

Mean KL Divergence: 0.00707
SB3 Clip Fraction: 0.06625
Policy Update Magnitude: 0.30110
Value Function Update Magnitude: 0.31098

Collected Steps per Second: 21,575.30046
Overall Steps per Second: 10,554.44475

Timestep Collection Time: 2.31941
Timestep Consumption Time: 2.42191
PPO Batch Consumption Time: 0.27807
Total Iteration Time: 4.74132

Cumulative Model Updates: 250,322
Cumulative Timesteps: 2,088,284,640

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 71,121.79206
Policy Entropy: 2.53624
Value Function Loss: 0.01669

Mean KL Divergence: 0.00732
SB3 Clip Fraction: 0.06839
Policy Update Magnitude: 0.30790
Value Function Update Magnitude: 0.29468

Collected Steps per Second: 21,492.04022
Overall Steps per Second: 10,469.52778

Timestep Collection Time: 2.32709
Timestep Consumption Time: 2.45001
PPO Batch Consumption Time: 0.27832
Total Iteration Time: 4.77710

Cumulative Model Updates: 250,328
Cumulative Timesteps: 2,088,334,654

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2088334654...
Checkpoint 2088334654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 97,150.91005
Policy Entropy: 2.53281
Value Function Loss: 0.01670

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.07188
Policy Update Magnitude: 0.31533
Value Function Update Magnitude: 0.29485

Collected Steps per Second: 21,092.87884
Overall Steps per Second: 10,267.59090

Timestep Collection Time: 2.37113
Timestep Consumption Time: 2.49992
PPO Batch Consumption Time: 0.28903
Total Iteration Time: 4.87105

Cumulative Model Updates: 250,334
Cumulative Timesteps: 2,088,384,668

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 74,067.20257
Policy Entropy: 2.54939
Value Function Loss: 0.01835

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.08304
Policy Update Magnitude: 0.31246
Value Function Update Magnitude: 0.29500

Collected Steps per Second: 21,834.05161
Overall Steps per Second: 10,558.52535

Timestep Collection Time: 2.29147
Timestep Consumption Time: 2.44707
PPO Batch Consumption Time: 0.27720
Total Iteration Time: 4.73854

Cumulative Model Updates: 250,340
Cumulative Timesteps: 2,088,434,700

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2088434700...
Checkpoint 2088434700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 56,456.98513
Policy Entropy: 2.54729
Value Function Loss: 0.01583

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.07210
Policy Update Magnitude: 0.31199
Value Function Update Magnitude: 0.30930

Collected Steps per Second: 22,119.62002
Overall Steps per Second: 10,611.52476

Timestep Collection Time: 2.26116
Timestep Consumption Time: 2.45221
PPO Batch Consumption Time: 0.27758
Total Iteration Time: 4.71337

Cumulative Model Updates: 250,346
Cumulative Timesteps: 2,088,484,716

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 116,428.18623
Policy Entropy: 2.56900
Value Function Loss: 0.01612

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.07481
Policy Update Magnitude: 0.29398
Value Function Update Magnitude: 0.25411

Collected Steps per Second: 22,119.07026
Overall Steps per Second: 10,524.99272

Timestep Collection Time: 2.26122
Timestep Consumption Time: 2.49090
PPO Batch Consumption Time: 0.29252
Total Iteration Time: 4.75212

Cumulative Model Updates: 250,352
Cumulative Timesteps: 2,088,534,732

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2088534732...
Checkpoint 2088534732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 80,205.70572
Policy Entropy: 2.54411
Value Function Loss: 0.01433

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.07274
Policy Update Magnitude: 0.28890
Value Function Update Magnitude: 0.24085

Collected Steps per Second: 21,948.37477
Overall Steps per Second: 10,512.54377

Timestep Collection Time: 2.27926
Timestep Consumption Time: 2.47944
PPO Batch Consumption Time: 0.28809
Total Iteration Time: 4.75870

Cumulative Model Updates: 250,358
Cumulative Timesteps: 2,088,584,758

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75,336.09963
Policy Entropy: 2.53889
Value Function Loss: 0.01546

Mean KL Divergence: 0.00744
SB3 Clip Fraction: 0.07329
Policy Update Magnitude: 0.29981
Value Function Update Magnitude: 0.27686

Collected Steps per Second: 22,024.48402
Overall Steps per Second: 10,469.08531

Timestep Collection Time: 2.27084
Timestep Consumption Time: 2.50647
PPO Batch Consumption Time: 0.29315
Total Iteration Time: 4.77730

Cumulative Model Updates: 250,364
Cumulative Timesteps: 2,088,634,772

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2088634772...
Checkpoint 2088634772 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 71,716.76833
Policy Entropy: 2.51747
Value Function Loss: 0.01594

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.08404
Policy Update Magnitude: 0.31045
Value Function Update Magnitude: 0.28056

Collected Steps per Second: 21,440.22113
Overall Steps per Second: 10,663.79364

Timestep Collection Time: 2.33207
Timestep Consumption Time: 2.35670
PPO Batch Consumption Time: 0.27743
Total Iteration Time: 4.68876

Cumulative Model Updates: 250,370
Cumulative Timesteps: 2,088,684,772

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80,007.69428
Policy Entropy: 2.52289
Value Function Loss: 0.01788

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.09385
Policy Update Magnitude: 0.32735
Value Function Update Magnitude: 0.30587

Collected Steps per Second: 21,384.01757
Overall Steps per Second: 10,504.71821

Timestep Collection Time: 2.33866
Timestep Consumption Time: 2.42206
PPO Batch Consumption Time: 0.29311
Total Iteration Time: 4.76072

Cumulative Model Updates: 250,376
Cumulative Timesteps: 2,088,734,782

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2088734782...
Checkpoint 2088734782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 81,116.72423
Policy Entropy: 2.53472
Value Function Loss: 0.01799

Mean KL Divergence: 0.01534
SB3 Clip Fraction: 0.11939
Policy Update Magnitude: 0.31643
Value Function Update Magnitude: 0.34125

Collected Steps per Second: 21,248.70847
Overall Steps per Second: 10,645.64637

Timestep Collection Time: 2.35553
Timestep Consumption Time: 2.34611
PPO Batch Consumption Time: 0.27714
Total Iteration Time: 4.70164

Cumulative Model Updates: 250,382
Cumulative Timesteps: 2,088,784,834

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42,900.86567
Policy Entropy: 2.55738
Value Function Loss: 0.01881

Mean KL Divergence: 0.01271
SB3 Clip Fraction: 0.10585
Policy Update Magnitude: 0.30905
Value Function Update Magnitude: 0.36297

Collected Steps per Second: 20,896.20567
Overall Steps per Second: 10,384.78668

Timestep Collection Time: 2.39364
Timestep Consumption Time: 2.42283
PPO Batch Consumption Time: 0.29073
Total Iteration Time: 4.81647

Cumulative Model Updates: 250,388
Cumulative Timesteps: 2,088,834,852

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2088834852...
Checkpoint 2088834852 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 58,763.76879
Policy Entropy: 2.56416
Value Function Loss: 0.01919

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.08928
Policy Update Magnitude: 0.32282
Value Function Update Magnitude: 0.37035

Collected Steps per Second: 21,047.81087
Overall Steps per Second: 10,324.97285

Timestep Collection Time: 2.37659
Timestep Consumption Time: 2.46817
PPO Batch Consumption Time: 0.29022
Total Iteration Time: 4.84476

Cumulative Model Updates: 250,394
Cumulative Timesteps: 2,088,884,874

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52,779.40293
Policy Entropy: 2.54499
Value Function Loss: 0.01730

Mean KL Divergence: 0.00783
SB3 Clip Fraction: 0.07288
Policy Update Magnitude: 0.31987
Value Function Update Magnitude: 0.36226

Collected Steps per Second: 21,590.91620
Overall Steps per Second: 10,435.03205

Timestep Collection Time: 2.31634
Timestep Consumption Time: 2.47636
PPO Batch Consumption Time: 0.29237
Total Iteration Time: 4.79270

Cumulative Model Updates: 250,400
Cumulative Timesteps: 2,088,934,886

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2088934886...
Checkpoint 2088934886 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 92,455.99150
Policy Entropy: 2.51981
Value Function Loss: 0.01588

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.07456
Policy Update Magnitude: 0.31403
Value Function Update Magnitude: 0.35010

Collected Steps per Second: 21,819.02737
Overall Steps per Second: 10,596.44956

Timestep Collection Time: 2.29222
Timestep Consumption Time: 2.42766
PPO Batch Consumption Time: 0.27682
Total Iteration Time: 4.71988

Cumulative Model Updates: 250,406
Cumulative Timesteps: 2,088,984,900

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92,455.99150
Policy Entropy: 2.51454
Value Function Loss: 0.01395

Mean KL Divergence: 0.00664
SB3 Clip Fraction: 0.06545
Policy Update Magnitude: 0.31221
Value Function Update Magnitude: 0.36716

Collected Steps per Second: 22,127.42832
Overall Steps per Second: 10,493.95266

Timestep Collection Time: 2.25964
Timestep Consumption Time: 2.50501
PPO Batch Consumption Time: 0.29059
Total Iteration Time: 4.76465

Cumulative Model Updates: 250,412
Cumulative Timesteps: 2,089,034,900

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2089034900...
Checkpoint 2089034900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 62,081.03067
Policy Entropy: 2.50554
Value Function Loss: 0.01477

Mean KL Divergence: 0.00666
SB3 Clip Fraction: 0.06508
Policy Update Magnitude: 0.31670
Value Function Update Magnitude: 0.33220

Collected Steps per Second: 21,942.24642
Overall Steps per Second: 10,478.44102

Timestep Collection Time: 2.27898
Timestep Consumption Time: 2.49329
PPO Batch Consumption Time: 0.28704
Total Iteration Time: 4.77227

Cumulative Model Updates: 250,418
Cumulative Timesteps: 2,089,084,906

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62,191.92439
Policy Entropy: 2.50077
Value Function Loss: 0.01468

Mean KL Divergence: 0.00730
SB3 Clip Fraction: 0.06715
Policy Update Magnitude: 0.31937
Value Function Update Magnitude: 0.31348

Collected Steps per Second: 22,213.34644
Overall Steps per Second: 10,536.53424

Timestep Collection Time: 2.25207
Timestep Consumption Time: 2.49579
PPO Batch Consumption Time: 0.29362
Total Iteration Time: 4.74786

Cumulative Model Updates: 250,424
Cumulative Timesteps: 2,089,134,932

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2089134932...
Checkpoint 2089134932 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 72,911.20650
Policy Entropy: 2.49406
Value Function Loss: 0.01544

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.07113
Policy Update Magnitude: 0.31991
Value Function Update Magnitude: 0.32011

Collected Steps per Second: 21,827.58850
Overall Steps per Second: 10,634.37028

Timestep Collection Time: 2.29114
Timestep Consumption Time: 2.41154
PPO Batch Consumption Time: 0.27785
Total Iteration Time: 4.70268

Cumulative Model Updates: 250,430
Cumulative Timesteps: 2,089,184,942

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85,565.67737
Policy Entropy: 2.50429
Value Function Loss: 0.01406

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.07374
Policy Update Magnitude: 0.31172
Value Function Update Magnitude: 0.30145

Collected Steps per Second: 22,041.27473
Overall Steps per Second: 10,478.64785

Timestep Collection Time: 2.27001
Timestep Consumption Time: 2.50484
PPO Batch Consumption Time: 0.29351
Total Iteration Time: 4.77485

Cumulative Model Updates: 250,436
Cumulative Timesteps: 2,089,234,976

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 2089234976...
Checkpoint 2089234976 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 80,536.55346
Policy Entropy: 2.51284
Value Function Loss: 0.01417

Mean KL Divergence: 0.00741
SB3 Clip Fraction: 0.07259
Policy Update Magnitude: 0.30783
Value Function Update Magnitude: 0.29255

Collected Steps per Second: 21,846.75198
Overall Steps per Second: 10,580.20181

Timestep Collection Time: 2.28959
Timestep Consumption Time: 2.43811
PPO Batch Consumption Time: 0.27810
Total Iteration Time: 4.72770

Cumulative Model Updates: 250,442
Cumulative Timesteps: 2,089,284,996

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68,242.53784
Policy Entropy: 2.49210
Value Function Loss: 0.01410

Mean KL Divergence: 0.00663
SB3 Clip Fraction: 0.06650
Policy Update Magnitude: 0.31338
Value Function Update Magnitude: 0.31664

Collected Steps per Second: 21,579.90215
Overall Steps per Second: 10,542.95791

Timestep Collection Time: 2.31808
Timestep Consumption Time: 2.42670
PPO Batch Consumption Time: 0.27717
Total Iteration Time: 4.74478

Cumulative Model Updates: 250,448
Cumulative Timesteps: 2,089,335,020

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2089335020...
Checkpoint 2089335020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 95,149.58014
Policy Entropy: 2.49374
Value Function Loss: 0.01526

Mean KL Divergence: 0.00677
SB3 Clip Fraction: 0.06650
Policy Update Magnitude: 0.31343
Value Function Update Magnitude: 0.32117

Collected Steps per Second: 21,634.58596
Overall Steps per Second: 10,551.36270

Timestep Collection Time: 2.31204
Timestep Consumption Time: 2.42858
PPO Batch Consumption Time: 0.27869
Total Iteration Time: 4.74062

Cumulative Model Updates: 250,454
Cumulative Timesteps: 2,089,385,040

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 94,034.23526
Policy Entropy: 2.50320
Value Function Loss: 0.01501

Mean KL Divergence: 0.00705
SB3 Clip Fraction: 0.06656
Policy Update Magnitude: 0.31424
Value Function Update Magnitude: 0.27985

Collected Steps per Second: 21,590.47594
Overall Steps per Second: 10,408.93973

Timestep Collection Time: 2.31602
Timestep Consumption Time: 2.48793
PPO Batch Consumption Time: 0.28750
Total Iteration Time: 4.80395

Cumulative Model Updates: 250,460
Cumulative Timesteps: 2,089,435,044

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2089435044...
Checkpoint 2089435044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 152,632.13599
Policy Entropy: 2.51195
Value Function Loss: 0.01490

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.07649
Policy Update Magnitude: 0.31154
Value Function Update Magnitude: 0.23630

Collected Steps per Second: 21,252.68420
Overall Steps per Second: 10,306.92721

Timestep Collection Time: 2.35424
Timestep Consumption Time: 2.50016
PPO Batch Consumption Time: 0.29376
Total Iteration Time: 4.85441

Cumulative Model Updates: 250,466
Cumulative Timesteps: 2,089,485,078

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 135,517.54936
Policy Entropy: 2.51820
Value Function Loss: 0.01397

Mean KL Divergence: 0.00665
SB3 Clip Fraction: 0.06499
Policy Update Magnitude: 0.31632
Value Function Update Magnitude: 0.24330

Collected Steps per Second: 21,958.12500
Overall Steps per Second: 10,416.62457

Timestep Collection Time: 2.27733
Timestep Consumption Time: 2.52326
PPO Batch Consumption Time: 0.29281
Total Iteration Time: 4.80060

Cumulative Model Updates: 250,472
Cumulative Timesteps: 2,089,535,084

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2089535084...
Checkpoint 2089535084 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 135,517.54936
Policy Entropy: 2.50352
Value Function Loss: 0.01341

Mean KL Divergence: 0.00690
SB3 Clip Fraction: 0.06447
Policy Update Magnitude: 0.30773
Value Function Update Magnitude: 0.26238

Collected Steps per Second: 22,002.34828
Overall Steps per Second: 10,591.63713

Timestep Collection Time: 2.27367
Timestep Consumption Time: 2.44949
PPO Batch Consumption Time: 0.27865
Total Iteration Time: 4.72316

Cumulative Model Updates: 250,478
Cumulative Timesteps: 2,089,585,110

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86,171.94381
Policy Entropy: 2.49818
Value Function Loss: 0.01383

Mean KL Divergence: 0.00657
SB3 Clip Fraction: 0.06360
Policy Update Magnitude: 0.30728
Value Function Update Magnitude: 0.27886

Collected Steps per Second: 22,417.46481
Overall Steps per Second: 10,562.29473

Timestep Collection Time: 2.23174
Timestep Consumption Time: 2.50492
PPO Batch Consumption Time: 0.29271
Total Iteration Time: 4.73666

Cumulative Model Updates: 250,484
Cumulative Timesteps: 2,089,635,140

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2089635140...
Checkpoint 2089635140 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,141.65695
Policy Entropy: 2.50200
Value Function Loss: 0.01641

Mean KL Divergence: 0.00646
SB3 Clip Fraction: 0.06444
Policy Update Magnitude: 0.31449
Value Function Update Magnitude: 0.32254

Collected Steps per Second: 21,543.05107
Overall Steps per Second: 10,535.88117

Timestep Collection Time: 2.32214
Timestep Consumption Time: 2.42601
PPO Batch Consumption Time: 0.29155
Total Iteration Time: 4.74816

Cumulative Model Updates: 250,490
Cumulative Timesteps: 2,089,685,166

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59,571.19977
Policy Entropy: 2.50154
Value Function Loss: 0.01649

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.07596
Policy Update Magnitude: 0.31937
Value Function Update Magnitude: 0.33614

Collected Steps per Second: 21,652.05069
Overall Steps per Second: 10,565.27920

Timestep Collection Time: 2.30953
Timestep Consumption Time: 2.42352
PPO Batch Consumption Time: 0.29252
Total Iteration Time: 4.73305

Cumulative Model Updates: 250,496
Cumulative Timesteps: 2,089,735,172

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2089735172...
Checkpoint 2089735172 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89,909.53142
Policy Entropy: 2.52558
Value Function Loss: 0.01607

Mean KL Divergence: 0.00708
SB3 Clip Fraction: 0.06803
Policy Update Magnitude: 0.30660
Value Function Update Magnitude: 0.32729

Collected Steps per Second: 21,135.97634
Overall Steps per Second: 10,509.48857

Timestep Collection Time: 2.36696
Timestep Consumption Time: 2.39331
PPO Batch Consumption Time: 0.28499
Total Iteration Time: 4.76027

Cumulative Model Updates: 250,502
Cumulative Timesteps: 2,089,785,200

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82,070.00112
Policy Entropy: 2.50967
Value Function Loss: 0.01349

Mean KL Divergence: 0.00676
SB3 Clip Fraction: 0.06690
Policy Update Magnitude: 0.29718
Value Function Update Magnitude: 0.32223

Collected Steps per Second: 21,423.78922
Overall Steps per Second: 10,546.44804

Timestep Collection Time: 2.33544
Timestep Consumption Time: 2.40872
PPO Batch Consumption Time: 0.27817
Total Iteration Time: 4.74416

Cumulative Model Updates: 250,508
Cumulative Timesteps: 2,089,835,234

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 2089835234...
Checkpoint 2089835234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 61,554.16308
Policy Entropy: 2.49050
Value Function Loss: 0.01494

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.07612
Policy Update Magnitude: 0.30645
Value Function Update Magnitude: 0.33319

Collected Steps per Second: 21,801.73256
Overall Steps per Second: 10,495.13929

Timestep Collection Time: 2.29413
Timestep Consumption Time: 2.47151
PPO Batch Consumption Time: 0.28801
Total Iteration Time: 4.76563

Cumulative Model Updates: 250,514
Cumulative Timesteps: 2,089,885,250

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86,022.86826
Policy Entropy: 2.48316
Value Function Loss: 0.01577

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.07061
Policy Update Magnitude: 0.31627
Value Function Update Magnitude: 0.34288

Collected Steps per Second: 21,594.61162
Overall Steps per Second: 10,532.62905

Timestep Collection Time: 2.31706
Timestep Consumption Time: 2.43351
PPO Batch Consumption Time: 0.28445
Total Iteration Time: 4.75057

Cumulative Model Updates: 250,520
Cumulative Timesteps: 2,089,935,286

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 2089935286...
Checkpoint 2089935286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 103,050.61316
Policy Entropy: 2.48811
Value Function Loss: 0.01651

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.08933
Policy Update Magnitude: 0.31663
Value Function Update Magnitude: 0.34172

Collected Steps per Second: 21,302.35804
Overall Steps per Second: 10,297.57827

Timestep Collection Time: 2.34782
Timestep Consumption Time: 2.50905
PPO Batch Consumption Time: 0.29318
Total Iteration Time: 4.85687

Cumulative Model Updates: 250,526
Cumulative Timesteps: 2,089,985,300

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61,109.67075
Policy Entropy: 2.50699
Value Function Loss: 0.01769

Mean KL Divergence: 0.01422
SB3 Clip Fraction: 0.11566
Policy Update Magnitude: 0.31495
Value Function Update Magnitude: 0.33196

Collected Steps per Second: 21,625.45031
Overall Steps per Second: 10,356.92005

Timestep Collection Time: 2.31255
Timestep Consumption Time: 2.51610
PPO Batch Consumption Time: 0.29163
Total Iteration Time: 4.82866

Cumulative Model Updates: 250,532
Cumulative Timesteps: 2,090,035,310

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2090035310...
Checkpoint 2090035310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 59,646.86714
Policy Entropy: 2.49984
Value Function Loss: 0.01590

Mean KL Divergence: 0.01873
SB3 Clip Fraction: 0.13656
Policy Update Magnitude: 0.30435
Value Function Update Magnitude: 0.34021

Collected Steps per Second: 21,470.14009
Overall Steps per Second: 10,354.89329

Timestep Collection Time: 2.32947
Timestep Consumption Time: 2.50052
PPO Batch Consumption Time: 0.29096
Total Iteration Time: 4.82999

Cumulative Model Updates: 250,538
Cumulative Timesteps: 2,090,085,324

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50,261.41867
Policy Entropy: 2.49689
Value Function Loss: 0.01508

Mean KL Divergence: 0.01384
SB3 Clip Fraction: 0.11381
Policy Update Magnitude: 0.30346
Value Function Update Magnitude: 0.33804

Collected Steps per Second: 21,975.33525
Overall Steps per Second: 10,463.28348

Timestep Collection Time: 2.27573
Timestep Consumption Time: 2.50384
PPO Batch Consumption Time: 0.29119
Total Iteration Time: 4.77957

Cumulative Model Updates: 250,544
Cumulative Timesteps: 2,090,135,334

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2090135334...
Checkpoint 2090135334 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 53,974.33268
Policy Entropy: 2.47117
Value Function Loss: 0.01356

Mean KL Divergence: 0.01237
SB3 Clip Fraction: 0.10471
Policy Update Magnitude: 0.29989
Value Function Update Magnitude: 0.32208

Collected Steps per Second: 21,968.57799
Overall Steps per Second: 10,477.27544

Timestep Collection Time: 2.27716
Timestep Consumption Time: 2.49755
PPO Batch Consumption Time: 0.28595
Total Iteration Time: 4.77471

Cumulative Model Updates: 250,550
Cumulative Timesteps: 2,090,185,360

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81,080.63068
Policy Entropy: 2.50068
Value Function Loss: 0.01313

Mean KL Divergence: 0.01560
SB3 Clip Fraction: 0.12341
Policy Update Magnitude: 0.28616
Value Function Update Magnitude: 0.30094

Collected Steps per Second: 21,146.85085
Overall Steps per Second: 10,381.02260

Timestep Collection Time: 2.36461
Timestep Consumption Time: 2.45226
PPO Batch Consumption Time: 0.27886
Total Iteration Time: 4.81687

Cumulative Model Updates: 250,556
Cumulative Timesteps: 2,090,235,364

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2090235364...
Checkpoint 2090235364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 93,750.06611
Policy Entropy: 2.50281
Value Function Loss: 0.01258

Mean KL Divergence: 0.01184
SB3 Clip Fraction: 0.10436
Policy Update Magnitude: 0.28581
Value Function Update Magnitude: 0.30174

Collected Steps per Second: 21,622.73111
Overall Steps per Second: 10,387.27649

Timestep Collection Time: 2.31321
Timestep Consumption Time: 2.50210
PPO Batch Consumption Time: 0.29171
Total Iteration Time: 4.81531

Cumulative Model Updates: 250,562
Cumulative Timesteps: 2,090,285,382

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93,750.06611
Policy Entropy: 2.52517
Value Function Loss: 0.01087

Mean KL Divergence: 0.01159
SB3 Clip Fraction: 0.10028
Policy Update Magnitude: 0.29312
Value Function Update Magnitude: 0.28262

Collected Steps per Second: 21,662.00693
Overall Steps per Second: 10,726.27403

Timestep Collection Time: 2.30847
Timestep Consumption Time: 2.35354
PPO Batch Consumption Time: 0.27769
Total Iteration Time: 4.66201

Cumulative Model Updates: 250,568
Cumulative Timesteps: 2,090,335,388

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2090335388...
Checkpoint 2090335388 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86,050.92108
Policy Entropy: 2.50914
Value Function Loss: 0.01292

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.07752
Policy Update Magnitude: 0.29747
Value Function Update Magnitude: 0.26136

Collected Steps per Second: 21,101.99485
Overall Steps per Second: 10,604.15167

Timestep Collection Time: 2.37001
Timestep Consumption Time: 2.34625
PPO Batch Consumption Time: 0.27875
Total Iteration Time: 4.71627

Cumulative Model Updates: 250,574
Cumulative Timesteps: 2,090,385,400

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92,915.72983
Policy Entropy: 2.50596
Value Function Loss: 0.01358

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.08549
Policy Update Magnitude: 0.30578
Value Function Update Magnitude: 0.27285

Collected Steps per Second: 21,482.24761
Overall Steps per Second: 10,504.69645

Timestep Collection Time: 2.32964
Timestep Consumption Time: 2.43451
PPO Batch Consumption Time: 0.29064
Total Iteration Time: 4.76415

Cumulative Model Updates: 250,580
Cumulative Timesteps: 2,090,435,446

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 2090435446...
Checkpoint 2090435446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 92,915.72983
Policy Entropy: 2.46940
Value Function Loss: 0.01395

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.08220
Policy Update Magnitude: 0.30553
Value Function Update Magnitude: 0.29646

Collected Steps per Second: 21,179.05757
Overall Steps per Second: 10,337.33388

Timestep Collection Time: 2.36224
Timestep Consumption Time: 2.47750
PPO Batch Consumption Time: 0.29295
Total Iteration Time: 4.83974

Cumulative Model Updates: 250,586
Cumulative Timesteps: 2,090,485,476

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 98,990.30419
Policy Entropy: 2.46959
Value Function Loss: 0.01327

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.08220
Policy Update Magnitude: 0.30958
Value Function Update Magnitude: 0.28543

Collected Steps per Second: 21,551.87368
Overall Steps per Second: 10,394.91467

Timestep Collection Time: 2.32036
Timestep Consumption Time: 2.49046
PPO Batch Consumption Time: 0.29351
Total Iteration Time: 4.81081

Cumulative Model Updates: 250,592
Cumulative Timesteps: 2,090,535,484

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2090535484...
Checkpoint 2090535484 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 127,045.96489
Policy Entropy: 2.44298
Value Function Loss: 0.01471

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.08803
Policy Update Magnitude: 0.31993
Value Function Update Magnitude: 0.28532

Collected Steps per Second: 21,370.57401
Overall Steps per Second: 10,551.50414

Timestep Collection Time: 2.34070
Timestep Consumption Time: 2.40005
PPO Batch Consumption Time: 0.27878
Total Iteration Time: 4.74075

Cumulative Model Updates: 250,598
Cumulative Timesteps: 2,090,585,506

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 105,185.98529
Policy Entropy: 2.46902
Value Function Loss: 0.01461

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.07679
Policy Update Magnitude: 0.32649
Value Function Update Magnitude: 0.28710

Collected Steps per Second: 21,653.90589
Overall Steps per Second: 10,546.07436

Timestep Collection Time: 2.31062
Timestep Consumption Time: 2.43370
PPO Batch Consumption Time: 0.27816
Total Iteration Time: 4.74432

Cumulative Model Updates: 250,604
Cumulative Timesteps: 2,090,635,540

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 2090635540...
Checkpoint 2090635540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 118,705.45010
Policy Entropy: 2.46514
Value Function Loss: 0.01428

Mean KL Divergence: 0.00732
SB3 Clip Fraction: 0.07032
Policy Update Magnitude: 0.32248
Value Function Update Magnitude: 0.28432

Collected Steps per Second: 21,518.89745
Overall Steps per Second: 10,507.33954

Timestep Collection Time: 2.32484
Timestep Consumption Time: 2.43640
PPO Batch Consumption Time: 0.27879
Total Iteration Time: 4.76124

Cumulative Model Updates: 250,610
Cumulative Timesteps: 2,090,685,568

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99,039.45903
Policy Entropy: 2.45849
Value Function Loss: 0.01353

Mean KL Divergence: 0.00684
SB3 Clip Fraction: 0.06317
Policy Update Magnitude: 0.31935
Value Function Update Magnitude: 0.27118

Collected Steps per Second: 21,951.62088
Overall Steps per Second: 10,529.01880

Timestep Collection Time: 2.27938
Timestep Consumption Time: 2.47282
PPO Batch Consumption Time: 0.27909
Total Iteration Time: 4.75220

Cumulative Model Updates: 250,616
Cumulative Timesteps: 2,090,735,604

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 2090735604...
Checkpoint 2090735604 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 98,037.95515
Policy Entropy: 2.45122
Value Function Loss: 0.01255

Mean KL Divergence: 0.00687
SB3 Clip Fraction: 0.06420
Policy Update Magnitude: 0.31116
Value Function Update Magnitude: 0.25606

Collected Steps per Second: 21,951.77991
Overall Steps per Second: 10,564.72016

Timestep Collection Time: 2.27845
Timestep Consumption Time: 2.45580
PPO Batch Consumption Time: 0.27883
Total Iteration Time: 4.73425

Cumulative Model Updates: 250,622
Cumulative Timesteps: 2,090,785,620

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81,909.94284
Policy Entropy: 2.44662
Value Function Loss: 0.01447

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.07075
Policy Update Magnitude: 0.31299
Value Function Update Magnitude: 0.26501

Collected Steps per Second: 22,183.59622
Overall Steps per Second: 10,492.12055

Timestep Collection Time: 2.25536
Timestep Consumption Time: 2.51317
PPO Batch Consumption Time: 0.29043
Total Iteration Time: 4.76853

Cumulative Model Updates: 250,628
Cumulative Timesteps: 2,090,835,652

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2090835652...
Checkpoint 2090835652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 76,365.66084
Policy Entropy: 2.47627
Value Function Loss: 0.01528

Mean KL Divergence: 0.00705
SB3 Clip Fraction: 0.06634
Policy Update Magnitude: 0.31937
Value Function Update Magnitude: 0.28180

Collected Steps per Second: 21,499.58163
Overall Steps per Second: 10,355.83622

Timestep Collection Time: 2.32656
Timestep Consumption Time: 2.50357
PPO Batch Consumption Time: 0.29246
Total Iteration Time: 4.83013

Cumulative Model Updates: 250,634
Cumulative Timesteps: 2,090,885,672

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60,094.91662
Policy Entropy: 2.49849
Value Function Loss: 0.01628

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.07305
Policy Update Magnitude: 0.31669
Value Function Update Magnitude: 0.30361

Collected Steps per Second: 22,264.01764
Overall Steps per Second: 10,709.30578

Timestep Collection Time: 2.24676
Timestep Consumption Time: 2.42413
PPO Batch Consumption Time: 0.27851
Total Iteration Time: 4.67089

Cumulative Model Updates: 250,640
Cumulative Timesteps: 2,090,935,694

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2090935694...
Checkpoint 2090935694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 58,361.61074
Policy Entropy: 2.52139
Value Function Loss: 0.01484

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.07812
Policy Update Magnitude: 0.30589
Value Function Update Magnitude: 0.29890

Collected Steps per Second: 21,953.97198
Overall Steps per Second: 10,655.33030

Timestep Collection Time: 2.27822
Timestep Consumption Time: 2.41577
PPO Batch Consumption Time: 0.27891
Total Iteration Time: 4.69399

Cumulative Model Updates: 250,646
Cumulative Timesteps: 2,090,985,710

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58,361.61074
Policy Entropy: 2.52965
Value Function Loss: 0.01276

Mean KL Divergence: 0.00743
SB3 Clip Fraction: 0.06914
Policy Update Magnitude: 0.29152
Value Function Update Magnitude: 0.27528

Collected Steps per Second: 22,289.14642
Overall Steps per Second: 10,504.64105

Timestep Collection Time: 2.24333
Timestep Consumption Time: 2.51666
PPO Batch Consumption Time: 0.29308
Total Iteration Time: 4.75999

Cumulative Model Updates: 250,652
Cumulative Timesteps: 2,091,035,712

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2091035712...
Checkpoint 2091035712 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 66,138.09437
Policy Entropy: 2.52752
Value Function Loss: 0.01135

Mean KL Divergence: 0.00568
SB3 Clip Fraction: 0.05668
Policy Update Magnitude: 0.28593
Value Function Update Magnitude: 0.24838

Collected Steps per Second: 21,532.64683
Overall Steps per Second: 10,363.87768

Timestep Collection Time: 2.32233
Timestep Consumption Time: 2.50269
PPO Batch Consumption Time: 0.29145
Total Iteration Time: 4.82503

Cumulative Model Updates: 250,658
Cumulative Timesteps: 2,091,085,718

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,448.78587
Policy Entropy: 2.52120
Value Function Loss: 0.01304

Mean KL Divergence: 0.00594
SB3 Clip Fraction: 0.05738
Policy Update Magnitude: 0.29260
Value Function Update Magnitude: 0.22802

Collected Steps per Second: 21,629.42224
Overall Steps per Second: 10,441.46978

Timestep Collection Time: 2.31278
Timestep Consumption Time: 2.47812
PPO Batch Consumption Time: 0.29209
Total Iteration Time: 4.79090

Cumulative Model Updates: 250,664
Cumulative Timesteps: 2,091,135,742

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2091135742...
Checkpoint 2091135742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 77,374.51090
Policy Entropy: 2.53570
Value Function Loss: 0.01502

Mean KL Divergence: 0.00670
SB3 Clip Fraction: 0.06341
Policy Update Magnitude: 0.30663
Value Function Update Magnitude: 0.26841

Collected Steps per Second: 21,332.70128
Overall Steps per Second: 10,461.17340

Timestep Collection Time: 2.34410
Timestep Consumption Time: 2.43605
PPO Batch Consumption Time: 0.27850
Total Iteration Time: 4.78015

Cumulative Model Updates: 250,670
Cumulative Timesteps: 2,091,185,748

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66,343.52127
Policy Entropy: 2.52172
Value Function Loss: 0.01638

Mean KL Divergence: 0.00741
SB3 Clip Fraction: 0.06610
Policy Update Magnitude: 0.30915
Value Function Update Magnitude: 0.33430

Collected Steps per Second: 21,850.83978
Overall Steps per Second: 10,478.33005

Timestep Collection Time: 2.28925
Timestep Consumption Time: 2.48460
PPO Batch Consumption Time: 0.28576
Total Iteration Time: 4.77385

Cumulative Model Updates: 250,676
Cumulative Timesteps: 2,091,235,770

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2091235770...
Checkpoint 2091235770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43,922.96227
Policy Entropy: 2.50644
Value Function Loss: 0.01775

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.07040
Policy Update Magnitude: 0.31474
Value Function Update Magnitude: 0.35965

Collected Steps per Second: 21,892.44471
Overall Steps per Second: 10,362.74305

Timestep Collection Time: 2.28398
Timestep Consumption Time: 2.54119
PPO Batch Consumption Time: 0.29103
Total Iteration Time: 4.82517

Cumulative Model Updates: 250,682
Cumulative Timesteps: 2,091,285,772

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57,257.06932
Policy Entropy: 2.49067
Value Function Loss: 0.01646

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.08003
Policy Update Magnitude: 0.31981
Value Function Update Magnitude: 0.36174

Collected Steps per Second: 21,152.20252
Overall Steps per Second: 10,257.00426

Timestep Collection Time: 2.36448
Timestep Consumption Time: 2.51160
PPO Batch Consumption Time: 0.27992
Total Iteration Time: 4.87608

Cumulative Model Updates: 250,688
Cumulative Timesteps: 2,091,335,786

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2091335786...
Checkpoint 2091335786 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 108,811.43838
Policy Entropy: 2.50468
Value Function Loss: 0.01617

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.07268
Policy Update Magnitude: 0.31786
Value Function Update Magnitude: 0.34578

Collected Steps per Second: 21,737.59536
Overall Steps per Second: 10,446.97054

Timestep Collection Time: 2.30127
Timestep Consumption Time: 2.48711
PPO Batch Consumption Time: 0.29002
Total Iteration Time: 4.78837

Cumulative Model Updates: 250,694
Cumulative Timesteps: 2,091,385,810

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89,626.46900
Policy Entropy: 2.51226
Value Function Loss: 0.01421

Mean KL Divergence: 0.00727
SB3 Clip Fraction: 0.07073
Policy Update Magnitude: 0.31235
Value Function Update Magnitude: 0.33705

Collected Steps per Second: 22,515.87174
Overall Steps per Second: 10,753.19827

Timestep Collection Time: 2.22083
Timestep Consumption Time: 2.42932
PPO Batch Consumption Time: 0.27787
Total Iteration Time: 4.65015

Cumulative Model Updates: 250,700
Cumulative Timesteps: 2,091,435,814

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2091435814...
Checkpoint 2091435814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 66,712.65154
Policy Entropy: 2.52367
Value Function Loss: 0.01645

Mean KL Divergence: 0.00679
SB3 Clip Fraction: 0.06405
Policy Update Magnitude: 0.31766
Value Function Update Magnitude: 0.33852

Collected Steps per Second: 21,186.84197
Overall Steps per Second: 10,292.22064

Timestep Collection Time: 2.35996
Timestep Consumption Time: 2.49808
PPO Batch Consumption Time: 0.29138
Total Iteration Time: 4.85804

Cumulative Model Updates: 250,706
Cumulative Timesteps: 2,091,485,814

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 105,242.19552
Policy Entropy: 2.50236
Value Function Loss: 0.01580

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.07885
Policy Update Magnitude: 0.32006
Value Function Update Magnitude: 0.35786

Collected Steps per Second: 22,081.14067
Overall Steps per Second: 10,529.32286

Timestep Collection Time: 2.26646
Timestep Consumption Time: 2.48655
PPO Batch Consumption Time: 0.28872
Total Iteration Time: 4.75301

Cumulative Model Updates: 250,712
Cumulative Timesteps: 2,091,535,860

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 2091535860...
Checkpoint 2091535860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 70,342.29681
Policy Entropy: 2.49521
Value Function Loss: 0.01567

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.08488
Policy Update Magnitude: 0.31864
Value Function Update Magnitude: 0.34674

Collected Steps per Second: 22,068.17787
Overall Steps per Second: 10,499.38797

Timestep Collection Time: 2.26743
Timestep Consumption Time: 2.49837
PPO Batch Consumption Time: 0.29362
Total Iteration Time: 4.76580

Cumulative Model Updates: 250,718
Cumulative Timesteps: 2,091,585,898

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 64,878.68664
Policy Entropy: 2.48206
Value Function Loss: 0.01450

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.08895
Policy Update Magnitude: 0.32192
Value Function Update Magnitude: 0.32997

Collected Steps per Second: 21,669.04974
Overall Steps per Second: 10,391.38220

Timestep Collection Time: 2.30808
Timestep Consumption Time: 2.50494
PPO Batch Consumption Time: 0.29148
Total Iteration Time: 4.81303

Cumulative Model Updates: 250,724
Cumulative Timesteps: 2,091,635,912

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2091635912...
Checkpoint 2091635912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 68,527.78051
Policy Entropy: 2.49598
Value Function Loss: 0.01575

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.07974
Policy Update Magnitude: 0.32331
Value Function Update Magnitude: 0.32466

Collected Steps per Second: 21,287.44347
Overall Steps per Second: 10,318.44682

Timestep Collection Time: 2.34974
Timestep Consumption Time: 2.49789
PPO Batch Consumption Time: 0.29256
Total Iteration Time: 4.84763

Cumulative Model Updates: 250,730
Cumulative Timesteps: 2,091,685,932

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79,683.58289
Policy Entropy: 2.50810
Value Function Loss: 0.01333

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.07518
Policy Update Magnitude: 0.31274
Value Function Update Magnitude: 0.33020

Collected Steps per Second: 21,556.12042
Overall Steps per Second: 10,367.34999

Timestep Collection Time: 2.32073
Timestep Consumption Time: 2.50461
PPO Batch Consumption Time: 0.29241
Total Iteration Time: 4.82534

Cumulative Model Updates: 250,736
Cumulative Timesteps: 2,091,735,958

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2091735958...
Checkpoint 2091735958 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 74,165.97854
Policy Entropy: 2.53882
Value Function Loss: 0.01313

Mean KL Divergence: 0.00690
SB3 Clip Fraction: 0.06585
Policy Update Magnitude: 0.29608
Value Function Update Magnitude: 0.30308

Collected Steps per Second: 21,188.08812
Overall Steps per Second: 10,262.05786

Timestep Collection Time: 2.36114
Timestep Consumption Time: 2.51391
PPO Batch Consumption Time: 0.29374
Total Iteration Time: 4.87505

Cumulative Model Updates: 250,742
Cumulative Timesteps: 2,091,785,986

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 96,154.25702
Policy Entropy: 2.53847
Value Function Loss: 0.01361

Mean KL Divergence: 0.00643
SB3 Clip Fraction: 0.06350
Policy Update Magnitude: 0.29522
Value Function Update Magnitude: 0.29414

Collected Steps per Second: 22,096.47629
Overall Steps per Second: 10,354.49899

Timestep Collection Time: 2.26407
Timestep Consumption Time: 2.56745
PPO Batch Consumption Time: 0.29172
Total Iteration Time: 4.83152

Cumulative Model Updates: 250,748
Cumulative Timesteps: 2,091,836,014

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2091836014...
Checkpoint 2091836014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 120,500.02486
Policy Entropy: 2.51109
Value Function Loss: 0.01432

Mean KL Divergence: 0.00733
SB3 Clip Fraction: 0.06938
Policy Update Magnitude: 0.29847
Value Function Update Magnitude: 0.30464

Collected Steps per Second: 21,830.09502
Overall Steps per Second: 10,560.98055

Timestep Collection Time: 2.29069
Timestep Consumption Time: 2.44429
PPO Batch Consumption Time: 0.27956
Total Iteration Time: 4.73498

Cumulative Model Updates: 250,754
Cumulative Timesteps: 2,091,886,020

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 106,871.97179
Policy Entropy: 2.49379
Value Function Loss: 0.01483

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.07175
Policy Update Magnitude: 0.30558
Value Function Update Magnitude: 0.31410

Collected Steps per Second: 21,871.71211
Overall Steps per Second: 10,594.03897

Timestep Collection Time: 2.28652
Timestep Consumption Time: 2.43406
PPO Batch Consumption Time: 0.28209
Total Iteration Time: 4.72058

Cumulative Model Updates: 250,760
Cumulative Timesteps: 2,091,936,030

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2091936030...
Checkpoint 2091936030 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 122,999.69931
Policy Entropy: 2.50004
Value Function Loss: 0.01508

Mean KL Divergence: 0.00666
SB3 Clip Fraction: 0.06393
Policy Update Magnitude: 0.31025
Value Function Update Magnitude: 0.29252

Collected Steps per Second: 21,964.59928
Overall Steps per Second: 10,630.47898

Timestep Collection Time: 2.27776
Timestep Consumption Time: 2.42852
PPO Batch Consumption Time: 0.27804
Total Iteration Time: 4.70628

Cumulative Model Updates: 250,766
Cumulative Timesteps: 2,091,986,060

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87,888.18858
Policy Entropy: 2.49674
Value Function Loss: 0.01501

Mean KL Divergence: 0.00713
SB3 Clip Fraction: 0.06830
Policy Update Magnitude: 0.31483
Value Function Update Magnitude: 0.31267

Collected Steps per Second: 22,193.63559
Overall Steps per Second: 10,563.93643

Timestep Collection Time: 2.25389
Timestep Consumption Time: 2.48128
PPO Batch Consumption Time: 0.29095
Total Iteration Time: 4.73517

Cumulative Model Updates: 250,772
Cumulative Timesteps: 2,092,036,082

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2092036082...
Checkpoint 2092036082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 71,865.89534
Policy Entropy: 2.52456
Value Function Loss: 0.01574

Mean KL Divergence: 0.00746
SB3 Clip Fraction: 0.07131
Policy Update Magnitude: 0.31632
Value Function Update Magnitude: 0.33049

Collected Steps per Second: 21,611.83372
Overall Steps per Second: 10,534.89020

Timestep Collection Time: 2.31549
Timestep Consumption Time: 2.43463
PPO Batch Consumption Time: 0.29415
Total Iteration Time: 4.75012

Cumulative Model Updates: 250,778
Cumulative Timesteps: 2,092,086,124

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57,682.74488
Policy Entropy: 2.54545
Value Function Loss: 0.01368

Mean KL Divergence: 0.00734
SB3 Clip Fraction: 0.06770
Policy Update Magnitude: 0.30204
Value Function Update Magnitude: 0.32623

Collected Steps per Second: 21,259.16963
Overall Steps per Second: 10,436.44426

Timestep Collection Time: 2.35230
Timestep Consumption Time: 2.43937
PPO Batch Consumption Time: 0.29271
Total Iteration Time: 4.79167

Cumulative Model Updates: 250,784
Cumulative Timesteps: 2,092,136,132

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2092136132...
Checkpoint 2092136132 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55,341.32055
Policy Entropy: 2.54313
Value Function Loss: 0.01274

Mean KL Divergence: 0.00717
SB3 Clip Fraction: 0.06635
Policy Update Magnitude: 0.29047
Value Function Update Magnitude: 0.29919

Collected Steps per Second: 20,733.25303
Overall Steps per Second: 10,204.70280

Timestep Collection Time: 2.41265
Timestep Consumption Time: 2.48921
PPO Batch Consumption Time: 0.29259
Total Iteration Time: 4.90186

Cumulative Model Updates: 250,790
Cumulative Timesteps: 2,092,186,154

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59,836.87501
Policy Entropy: 2.54375
Value Function Loss: 0.01460

Mean KL Divergence: 0.01058
SB3 Clip Fraction: 0.09202
Policy Update Magnitude: 0.29190
Value Function Update Magnitude: 0.28414

Collected Steps per Second: 21,664.92806
Overall Steps per Second: 10,419.42239

Timestep Collection Time: 2.30788
Timestep Consumption Time: 2.49085
PPO Batch Consumption Time: 0.28963
Total Iteration Time: 4.79873

Cumulative Model Updates: 250,796
Cumulative Timesteps: 2,092,236,154

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2092236154...
Checkpoint 2092236154 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 79,241.31336
Policy Entropy: 2.52768
Value Function Loss: 0.01659

Mean KL Divergence: 0.01813
SB3 Clip Fraction: 0.12659
Policy Update Magnitude: 0.29009
Value Function Update Magnitude: 0.29574

Collected Steps per Second: 21,454.53126
Overall Steps per Second: 10,551.32698

Timestep Collection Time: 2.33135
Timestep Consumption Time: 2.40910
PPO Batch Consumption Time: 0.27875
Total Iteration Time: 4.74045

Cumulative Model Updates: 250,802
Cumulative Timesteps: 2,092,286,172

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79,241.31336
Policy Entropy: 2.52323
Value Function Loss: 0.01531

Mean KL Divergence: 0.01241
SB3 Clip Fraction: 0.10473
Policy Update Magnitude: 0.30110
Value Function Update Magnitude: 0.30376

Collected Steps per Second: 21,359.02418
Overall Steps per Second: 10,534.11923

Timestep Collection Time: 2.34140
Timestep Consumption Time: 2.40603
PPO Batch Consumption Time: 0.27832
Total Iteration Time: 4.74743

Cumulative Model Updates: 250,808
Cumulative Timesteps: 2,092,336,182

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2092336182...
Checkpoint 2092336182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 92,888.17705
Policy Entropy: 2.52432
Value Function Loss: 0.01419

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.07758
Policy Update Magnitude: 0.30465
Value Function Update Magnitude: 0.30480

Collected Steps per Second: 21,552.46158
Overall Steps per Second: 10,386.33460

Timestep Collection Time: 2.32048
Timestep Consumption Time: 2.49470
PPO Batch Consumption Time: 0.29166
Total Iteration Time: 4.81517

Cumulative Model Updates: 250,814
Cumulative Timesteps: 2,092,386,194

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95,095.48074
Policy Entropy: 2.54117
Value Function Loss: 0.01416

Mean KL Divergence: 0.00783
SB3 Clip Fraction: 0.07439
Policy Update Magnitude: 0.31151
Value Function Update Magnitude: 0.31213

Collected Steps per Second: 22,429.86530
Overall Steps per Second: 10,642.68488

Timestep Collection Time: 2.22988
Timestep Consumption Time: 2.46968
PPO Batch Consumption Time: 0.27885
Total Iteration Time: 4.69957

Cumulative Model Updates: 250,820
Cumulative Timesteps: 2,092,436,210

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2092436210...
Checkpoint 2092436210 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 69,480.27386
Policy Entropy: 2.54939
Value Function Loss: 0.01537

Mean KL Divergence: 0.00736
SB3 Clip Fraction: 0.06663
Policy Update Magnitude: 0.30824
Value Function Update Magnitude: 0.33485

Collected Steps per Second: 21,658.40552
Overall Steps per Second: 10,378.77593

Timestep Collection Time: 2.30894
Timestep Consumption Time: 2.50935
PPO Batch Consumption Time: 0.29174
Total Iteration Time: 4.81829

Cumulative Model Updates: 250,826
Cumulative Timesteps: 2,092,486,218

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63,952.10089
Policy Entropy: 2.54651
Value Function Loss: 0.01697

Mean KL Divergence: 0.00732
SB3 Clip Fraction: 0.06739
Policy Update Magnitude: 0.31366
Value Function Update Magnitude: 0.35334

Collected Steps per Second: 22,233.45034
Overall Steps per Second: 10,564.33044

Timestep Collection Time: 2.24931
Timestep Consumption Time: 2.48454
PPO Batch Consumption Time: 0.28927
Total Iteration Time: 4.73385

Cumulative Model Updates: 250,832
Cumulative Timesteps: 2,092,536,228

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2092536228...
Checkpoint 2092536228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 52,529.88210
Policy Entropy: 2.53015
Value Function Loss: 0.01654

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.07471
Policy Update Magnitude: 0.32118
Value Function Update Magnitude: 0.33600

Collected Steps per Second: 22,075.12827
Overall Steps per Second: 10,496.59155

Timestep Collection Time: 2.26535
Timestep Consumption Time: 2.49886
PPO Batch Consumption Time: 0.29385
Total Iteration Time: 4.76421

Cumulative Model Updates: 250,838
Cumulative Timesteps: 2,092,586,236

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54,460.95508
Policy Entropy: 2.51535
Value Function Loss: 0.01493

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.07104
Policy Update Magnitude: 0.32401
Value Function Update Magnitude: 0.31278

Collected Steps per Second: 21,971.53883
Overall Steps per Second: 10,473.48043

Timestep Collection Time: 2.27640
Timestep Consumption Time: 2.49909
PPO Batch Consumption Time: 0.29264
Total Iteration Time: 4.77549

Cumulative Model Updates: 250,844
Cumulative Timesteps: 2,092,636,252

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2092636252...
Checkpoint 2092636252 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,850.50382
Policy Entropy: 2.48779
Value Function Loss: 0.01444

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.06871
Policy Update Magnitude: 0.32434
Value Function Update Magnitude: 0.32384

Collected Steps per Second: 22,154.24792
Overall Steps per Second: 10,524.81139

Timestep Collection Time: 2.25772
Timestep Consumption Time: 2.49467
PPO Batch Consumption Time: 0.29147
Total Iteration Time: 4.75239

Cumulative Model Updates: 250,850
Cumulative Timesteps: 2,092,686,270

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42,531.91597
Policy Entropy: 2.46228
Value Function Loss: 0.01398

Mean KL Divergence: 0.00714
SB3 Clip Fraction: 0.06302
Policy Update Magnitude: 0.32441
Value Function Update Magnitude: 0.32956

Collected Steps per Second: 21,531.02531
Overall Steps per Second: 10,549.06353

Timestep Collection Time: 2.32335
Timestep Consumption Time: 2.41869
PPO Batch Consumption Time: 0.27702
Total Iteration Time: 4.74203

Cumulative Model Updates: 250,856
Cumulative Timesteps: 2,092,736,294

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2092736294...
Checkpoint 2092736294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,956.83265
Policy Entropy: 2.48811
Value Function Loss: 0.01682

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.07320
Policy Update Magnitude: 0.33132
Value Function Update Magnitude: 0.32443

Collected Steps per Second: 21,713.18176
Overall Steps per Second: 10,617.13695

Timestep Collection Time: 2.30321
Timestep Consumption Time: 2.40710
PPO Batch Consumption Time: 0.27636
Total Iteration Time: 4.71031

Cumulative Model Updates: 250,862
Cumulative Timesteps: 2,092,786,304

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,919.18250
Policy Entropy: 2.51016
Value Function Loss: 0.01620

Mean KL Divergence: 0.00763
SB3 Clip Fraction: 0.07025
Policy Update Magnitude: 0.32761
Value Function Update Magnitude: 0.32574

Collected Steps per Second: 20,940.23900
Overall Steps per Second: 10,377.03425

Timestep Collection Time: 2.38928
Timestep Consumption Time: 2.43214
PPO Batch Consumption Time: 0.28931
Total Iteration Time: 4.82142

Cumulative Model Updates: 250,868
Cumulative Timesteps: 2,092,836,336

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2092836336...
Checkpoint 2092836336 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,746.02344
Policy Entropy: 2.53007
Value Function Loss: 0.01620

Mean KL Divergence: 0.00745
SB3 Clip Fraction: 0.06863
Policy Update Magnitude: 0.31430
Value Function Update Magnitude: 0.31913

Collected Steps per Second: 20,917.38960
Overall Steps per Second: 10,396.30193

Timestep Collection Time: 2.39217
Timestep Consumption Time: 2.42089
PPO Batch Consumption Time: 0.29049
Total Iteration Time: 4.81306

Cumulative Model Updates: 250,874
Cumulative Timesteps: 2,092,886,374

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,862.94744
Policy Entropy: 2.52669
Value Function Loss: 0.01542

Mean KL Divergence: 0.00640
SB3 Clip Fraction: 0.06003
Policy Update Magnitude: 0.30771
Value Function Update Magnitude: 0.34440

Collected Steps per Second: 20,935.85692
Overall Steps per Second: 10,370.55104

Timestep Collection Time: 2.38882
Timestep Consumption Time: 2.43368
PPO Batch Consumption Time: 0.29322
Total Iteration Time: 4.82250

Cumulative Model Updates: 250,880
Cumulative Timesteps: 2,092,936,386

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2092936386...
Checkpoint 2092936386 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55,115.58941
Policy Entropy: 2.51358
Value Function Loss: 0.01574

Mean KL Divergence: 0.00644
SB3 Clip Fraction: 0.06225
Policy Update Magnitude: 0.31917
Value Function Update Magnitude: 0.35470

Collected Steps per Second: 21,032.46804
Overall Steps per Second: 10,464.11831

Timestep Collection Time: 2.37813
Timestep Consumption Time: 2.40182
PPO Batch Consumption Time: 0.27854
Total Iteration Time: 4.77995

Cumulative Model Updates: 250,886
Cumulative Timesteps: 2,092,986,404

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46,014.82109
Policy Entropy: 2.50716
Value Function Loss: 0.01482

Mean KL Divergence: 0.00720
SB3 Clip Fraction: 0.06724
Policy Update Magnitude: 0.31915
Value Function Update Magnitude: 0.30742

Collected Steps per Second: 21,724.99236
Overall Steps per Second: 10,506.56979

Timestep Collection Time: 2.30306
Timestep Consumption Time: 2.45910
PPO Batch Consumption Time: 0.27916
Total Iteration Time: 4.76216

Cumulative Model Updates: 250,892
Cumulative Timesteps: 2,093,036,438

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 2093036438...
Checkpoint 2093036438 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 108,505.31735
Policy Entropy: 2.52463
Value Function Loss: 0.01385

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.07167
Policy Update Magnitude: 0.30767
Value Function Update Magnitude: 0.23387

Collected Steps per Second: 21,895.76898
Overall Steps per Second: 10,625.21931

Timestep Collection Time: 2.28464
Timestep Consumption Time: 2.42340
PPO Batch Consumption Time: 0.27952
Total Iteration Time: 4.70804

Cumulative Model Updates: 250,898
Cumulative Timesteps: 2,093,086,462

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90,906.22432
Policy Entropy: 2.53356
Value Function Loss: 0.01380

Mean KL Divergence: 0.01188
SB3 Clip Fraction: 0.09770
Policy Update Magnitude: 0.29298
Value Function Update Magnitude: 0.17730

Collected Steps per Second: 21,358.80581
Overall Steps per Second: 10,447.16948

Timestep Collection Time: 2.34133
Timestep Consumption Time: 2.44542
PPO Batch Consumption Time: 0.27873
Total Iteration Time: 4.78675

Cumulative Model Updates: 250,904
Cumulative Timesteps: 2,093,136,470

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2093136470...
Checkpoint 2093136470 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 112,045.95173
Policy Entropy: 2.53415
Value Function Loss: 0.01567

Mean KL Divergence: 0.01522
SB3 Clip Fraction: 0.11458
Policy Update Magnitude: 0.29386
Value Function Update Magnitude: 0.20741

Collected Steps per Second: 21,883.03274
Overall Steps per Second: 10,617.93012

Timestep Collection Time: 2.28588
Timestep Consumption Time: 2.42521
PPO Batch Consumption Time: 0.27913
Total Iteration Time: 4.71109

Cumulative Model Updates: 250,910
Cumulative Timesteps: 2,093,186,492

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70,325.25635
Policy Entropy: 2.52091
Value Function Loss: 0.01696

Mean KL Divergence: 0.01423
SB3 Clip Fraction: 0.11255
Policy Update Magnitude: 0.31517
Value Function Update Magnitude: 0.27848

Collected Steps per Second: 22,187.52513
Overall Steps per Second: 10,510.99235

Timestep Collection Time: 2.25424
Timestep Consumption Time: 2.50421
PPO Batch Consumption Time: 0.29040
Total Iteration Time: 4.75845

Cumulative Model Updates: 250,916
Cumulative Timesteps: 2,093,236,508

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2093236508...
Checkpoint 2093236508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 68,073.66421
Policy Entropy: 2.50855
Value Function Loss: 0.01684

Mean KL Divergence: 0.01223
SB3 Clip Fraction: 0.10707
Policy Update Magnitude: 0.32134
Value Function Update Magnitude: 0.37237

Collected Steps per Second: 21,915.27784
Overall Steps per Second: 10,616.89037

Timestep Collection Time: 2.28197
Timestep Consumption Time: 2.42845
PPO Batch Consumption Time: 0.27905
Total Iteration Time: 4.71042

Cumulative Model Updates: 250,922
Cumulative Timesteps: 2,093,286,518

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68,073.66421
Policy Entropy: 2.51291
Value Function Loss: 0.01454

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.07475
Policy Update Magnitude: 0.31806
Value Function Update Magnitude: 0.39129

Collected Steps per Second: 21,842.75592
Overall Steps per Second: 10,460.24164

Timestep Collection Time: 2.28918
Timestep Consumption Time: 2.49102
PPO Batch Consumption Time: 0.28727
Total Iteration Time: 4.78020

Cumulative Model Updates: 250,928
Cumulative Timesteps: 2,093,336,520

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2093336520...
Checkpoint 2093336520 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 68,073.66421
Policy Entropy: 2.50643
Value Function Loss: 0.01236

Mean KL Divergence: 0.00698
SB3 Clip Fraction: 0.06598
Policy Update Magnitude: 0.30290
Value Function Update Magnitude: 0.32956

Collected Steps per Second: 21,613.51773
Overall Steps per Second: 10,588.09715

Timestep Collection Time: 2.31374
Timestep Consumption Time: 2.40930
PPO Batch Consumption Time: 0.27808
Total Iteration Time: 4.72304

Cumulative Model Updates: 250,934
Cumulative Timesteps: 2,093,386,528

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62,424.15248
Policy Entropy: 2.48980
Value Function Loss: 0.01277

Mean KL Divergence: 0.00660
SB3 Clip Fraction: 0.06226
Policy Update Magnitude: 0.30268
Value Function Update Magnitude: 0.26776

Collected Steps per Second: 21,655.12919
Overall Steps per Second: 10,587.00973

Timestep Collection Time: 2.31086
Timestep Consumption Time: 2.41587
PPO Batch Consumption Time: 0.27714
Total Iteration Time: 4.72674

Cumulative Model Updates: 250,940
Cumulative Timesteps: 2,093,436,570

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 2093436570...
Checkpoint 2093436570 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 112,775.70612
Policy Entropy: 2.50003
Value Function Loss: 0.01257

Mean KL Divergence: 0.00729
SB3 Clip Fraction: 0.06919
Policy Update Magnitude: 0.29958
Value Function Update Magnitude: 0.22504

Collected Steps per Second: 20,908.17262
Overall Steps per Second: 10,522.88942

Timestep Collection Time: 2.39179
Timestep Consumption Time: 2.36051
PPO Batch Consumption Time: 0.27786
Total Iteration Time: 4.75231

Cumulative Model Updates: 250,946
Cumulative Timesteps: 2,093,486,578

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 74,523.22228
Policy Entropy: 2.49937
Value Function Loss: 0.01372

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.07319
Policy Update Magnitude: 0.29901
Value Function Update Magnitude: 0.22200

Collected Steps per Second: 21,169.29671
Overall Steps per Second: 10,482.42821

Timestep Collection Time: 2.36371
Timestep Consumption Time: 2.40981
PPO Batch Consumption Time: 0.28757
Total Iteration Time: 4.77351

Cumulative Model Updates: 250,952
Cumulative Timesteps: 2,093,536,616

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 2093536616...
Checkpoint 2093536616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 67,527.84674
Policy Entropy: 2.52586
Value Function Loss: 0.01324

Mean KL Divergence: 0.00685
SB3 Clip Fraction: 0.06566
Policy Update Magnitude: 0.29881
Value Function Update Magnitude: 0.25733

Collected Steps per Second: 20,825.15078
Overall Steps per Second: 10,359.91849

Timestep Collection Time: 2.40094
Timestep Consumption Time: 2.42535
PPO Batch Consumption Time: 0.29092
Total Iteration Time: 4.82629

Cumulative Model Updates: 250,958
Cumulative Timesteps: 2,093,586,616

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80,731.57247
Policy Entropy: 2.51679
Value Function Loss: 0.01360

Mean KL Divergence: 0.00654
SB3 Clip Fraction: 0.06205
Policy Update Magnitude: 0.30326
Value Function Update Magnitude: 0.27180

Collected Steps per Second: 21,700.65141
Overall Steps per Second: 10,367.57877

Timestep Collection Time: 2.30408
Timestep Consumption Time: 2.51865
PPO Batch Consumption Time: 0.29313
Total Iteration Time: 4.82273

Cumulative Model Updates: 250,964
Cumulative Timesteps: 2,093,636,616

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2093636616...
Checkpoint 2093636616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 111,300.77466
Policy Entropy: 2.51024
Value Function Loss: 0.01513

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.07302
Policy Update Magnitude: 0.30279
Value Function Update Magnitude: 0.29785

Collected Steps per Second: 21,767.50732
Overall Steps per Second: 10,404.47977

Timestep Collection Time: 2.29810
Timestep Consumption Time: 2.50982
PPO Batch Consumption Time: 0.29136
Total Iteration Time: 4.80793

Cumulative Model Updates: 250,970
Cumulative Timesteps: 2,093,686,640

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 115,274.31251
Policy Entropy: 2.50086
Value Function Loss: 0.01604

Mean KL Divergence: 0.01331
SB3 Clip Fraction: 0.10546
Policy Update Magnitude: 0.30854
Value Function Update Magnitude: 0.31171

Collected Steps per Second: 21,961.87191
Overall Steps per Second: 10,709.09227

Timestep Collection Time: 2.27795
Timestep Consumption Time: 2.39360
PPO Batch Consumption Time: 0.27727
Total Iteration Time: 4.67154

Cumulative Model Updates: 250,976
Cumulative Timesteps: 2,093,736,668

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2093736668...
Checkpoint 2093736668 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 113,098.25397
Policy Entropy: 2.48663
Value Function Loss: 0.01863

Mean KL Divergence: 0.01365
SB3 Clip Fraction: 0.10386
Policy Update Magnitude: 0.32128
Value Function Update Magnitude: 0.31903

Collected Steps per Second: 21,451.85278
Overall Steps per Second: 10,582.80582

Timestep Collection Time: 2.33108
Timestep Consumption Time: 2.39413
PPO Batch Consumption Time: 0.27749
Total Iteration Time: 4.72521

Cumulative Model Updates: 250,982
Cumulative Timesteps: 2,093,786,674

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65,415.92559
Policy Entropy: 2.46822
Value Function Loss: 0.01691

Mean KL Divergence: 0.01250
SB3 Clip Fraction: 0.09805
Policy Update Magnitude: 0.32980
Value Function Update Magnitude: 0.33014

Collected Steps per Second: 22,381.51254
Overall Steps per Second: 10,562.67841

Timestep Collection Time: 2.23408
Timestep Consumption Time: 2.49976
PPO Batch Consumption Time: 0.29114
Total Iteration Time: 4.73384

Cumulative Model Updates: 250,988
Cumulative Timesteps: 2,093,836,676

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2093836676...
Checkpoint 2093836676 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,327.03827
Policy Entropy: 2.44849
Value Function Loss: 0.01800

Mean KL Divergence: 0.01194
SB3 Clip Fraction: 0.09094
Policy Update Magnitude: 0.33061
Value Function Update Magnitude: 0.33819

Collected Steps per Second: 21,792.79884
Overall Steps per Second: 10,457.69737

Timestep Collection Time: 2.29525
Timestep Consumption Time: 2.48783
PPO Batch Consumption Time: 0.28753
Total Iteration Time: 4.78308

Cumulative Model Updates: 250,994
Cumulative Timesteps: 2,093,886,696

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55,936.77461
Policy Entropy: 2.48885
Value Function Loss: 0.01602

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.08121
Policy Update Magnitude: 0.32432
Value Function Update Magnitude: 0.30706

Collected Steps per Second: 21,900.08687
Overall Steps per Second: 10,502.63775

Timestep Collection Time: 2.28437
Timestep Consumption Time: 2.47900
PPO Batch Consumption Time: 0.28790
Total Iteration Time: 4.76337

Cumulative Model Updates: 251,000
Cumulative Timesteps: 2,093,936,724

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2093936724...
Checkpoint 2093936724 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 63,791.08418
Policy Entropy: 2.52239
Value Function Loss: 0.01519

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.08003
Policy Update Magnitude: 0.31224
Value Function Update Magnitude: 0.30899

Collected Steps per Second: 20,493.71574
Overall Steps per Second: 10,131.29118

Timestep Collection Time: 2.44085
Timestep Consumption Time: 2.49653
PPO Batch Consumption Time: 0.27869
Total Iteration Time: 4.93738

Cumulative Model Updates: 251,006
Cumulative Timesteps: 2,093,986,746

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50,331.17018
Policy Entropy: 2.53442
Value Function Loss: 0.01393

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.08265
Policy Update Magnitude: 0.30474
Value Function Update Magnitude: 0.29476

Collected Steps per Second: 21,530.96756
Overall Steps per Second: 10,485.48267

Timestep Collection Time: 2.32363
Timestep Consumption Time: 2.44773
PPO Batch Consumption Time: 0.27849
Total Iteration Time: 4.77136

Cumulative Model Updates: 251,012
Cumulative Timesteps: 2,094,036,776

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2094036776...
Checkpoint 2094036776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 52,244.09433
Policy Entropy: 2.52169
Value Function Loss: 0.01647

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.08569
Policy Update Magnitude: 0.31887
Value Function Update Magnitude: 0.30542

Collected Steps per Second: 21,163.17378
Overall Steps per Second: 10,242.18459

Timestep Collection Time: 2.36269
Timestep Consumption Time: 2.51928
PPO Batch Consumption Time: 0.29387
Total Iteration Time: 4.88197

Cumulative Model Updates: 251,018
Cumulative Timesteps: 2,094,086,778

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 115,063.67479
Policy Entropy: 2.52158
Value Function Loss: 0.01680

Mean KL Divergence: 0.01084
SB3 Clip Fraction: 0.09848
Policy Update Magnitude: 0.31930
Value Function Update Magnitude: 0.32800

Collected Steps per Second: 22,212.59120
Overall Steps per Second: 10,461.86474

Timestep Collection Time: 2.25314
Timestep Consumption Time: 2.53071
PPO Batch Consumption Time: 0.28811
Total Iteration Time: 4.78385

Cumulative Model Updates: 251,024
Cumulative Timesteps: 2,094,136,826

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 2094136826...
Checkpoint 2094136826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 85,570.18888
Policy Entropy: 2.53798
Value Function Loss: 0.01701

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.09437
Policy Update Magnitude: 0.31481
Value Function Update Magnitude: 0.34201

Collected Steps per Second: 21,600.99825
Overall Steps per Second: 10,354.17792

Timestep Collection Time: 2.31582
Timestep Consumption Time: 2.51547
PPO Batch Consumption Time: 0.29110
Total Iteration Time: 4.83129

Cumulative Model Updates: 251,030
Cumulative Timesteps: 2,094,186,850

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 73,192.12859
Policy Entropy: 2.54219
Value Function Loss: 0.01338

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.08682
Policy Update Magnitude: 0.30641
Value Function Update Magnitude: 0.32865

Collected Steps per Second: 22,272.34459
Overall Steps per Second: 10,666.58797

Timestep Collection Time: 2.24601
Timestep Consumption Time: 2.44377
PPO Batch Consumption Time: 0.28045
Total Iteration Time: 4.68978

Cumulative Model Updates: 251,036
Cumulative Timesteps: 2,094,236,874

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2094236874...
Checkpoint 2094236874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 72,511.37548
Policy Entropy: 2.53786
Value Function Loss: 0.01339

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.07788
Policy Update Magnitude: 0.29980
Value Function Update Magnitude: 0.30732

Collected Steps per Second: 21,653.49064
Overall Steps per Second: 10,416.73413

Timestep Collection Time: 2.30993
Timestep Consumption Time: 2.49177
PPO Batch Consumption Time: 0.29091
Total Iteration Time: 4.80170

Cumulative Model Updates: 251,042
Cumulative Timesteps: 2,094,286,892

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 72,410.82390
Policy Entropy: 2.52281
Value Function Loss: 0.01355

Mean KL Divergence: 0.00683
SB3 Clip Fraction: 0.06428
Policy Update Magnitude: 0.29923
Value Function Update Magnitude: 0.29672

Collected Steps per Second: 22,421.68954
Overall Steps per Second: 10,713.48130

Timestep Collection Time: 2.23025
Timestep Consumption Time: 2.43733
PPO Batch Consumption Time: 0.28002
Total Iteration Time: 4.66758

Cumulative Model Updates: 251,048
Cumulative Timesteps: 2,094,336,898

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2094336898...
Checkpoint 2094336898 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 119,285.14857
Policy Entropy: 2.49475
Value Function Loss: 0.01550

Mean KL Divergence: 0.00703
SB3 Clip Fraction: 0.06536
Policy Update Magnitude: 0.32484
Value Function Update Magnitude: 0.30415

Collected Steps per Second: 21,223.19679
Overall Steps per Second: 10,616.77344

Timestep Collection Time: 2.35629
Timestep Consumption Time: 2.35399
PPO Batch Consumption Time: 0.27814
Total Iteration Time: 4.71028

Cumulative Model Updates: 251,054
Cumulative Timesteps: 2,094,386,906

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 107,992.77099
Policy Entropy: 2.47947
Value Function Loss: 0.01768

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.07252
Policy Update Magnitude: 0.33378
Value Function Update Magnitude: 0.35524

Collected Steps per Second: 21,419.92797
Overall Steps per Second: 10,490.85608

Timestep Collection Time: 2.33521
Timestep Consumption Time: 2.43275
PPO Batch Consumption Time: 0.29343
Total Iteration Time: 4.76796

Cumulative Model Updates: 251,060
Cumulative Timesteps: 2,094,436,926

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2094436926...
Checkpoint 2094436926 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 90,311.12109
Policy Entropy: 2.50103
Value Function Loss: 0.01663

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.07710
Policy Update Magnitude: 0.32696
Value Function Update Magnitude: 0.36165

Collected Steps per Second: 20,621.58307
Overall Steps per Second: 10,313.88599

Timestep Collection Time: 2.42678
Timestep Consumption Time: 2.42532
PPO Batch Consumption Time: 0.29222
Total Iteration Time: 4.85210

Cumulative Model Updates: 251,066
Cumulative Timesteps: 2,094,486,970

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 64,397.55361
Policy Entropy: 2.51108
Value Function Loss: 0.01761

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.07311
Policy Update Magnitude: 0.33139
Value Function Update Magnitude: 0.38266

Collected Steps per Second: 21,034.70790
Overall Steps per Second: 10,371.65641

Timestep Collection Time: 2.37721
Timestep Consumption Time: 2.44400
PPO Batch Consumption Time: 0.28526
Total Iteration Time: 4.82122

Cumulative Model Updates: 251,072
Cumulative Timesteps: 2,094,536,974

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2094536974...
Checkpoint 2094536974 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 72,150.79472
Policy Entropy: 2.52702
Value Function Loss: 0.01531

Mean KL Divergence: 0.00718
SB3 Clip Fraction: 0.06697
Policy Update Magnitude: 0.32372
Value Function Update Magnitude: 0.37643

Collected Steps per Second: 21,200.61649
Overall Steps per Second: 10,530.33502

Timestep Collection Time: 2.35974
Timestep Consumption Time: 2.39110
PPO Batch Consumption Time: 0.27848
Total Iteration Time: 4.75085

Cumulative Model Updates: 251,078
Cumulative Timesteps: 2,094,587,002

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 71,557.70394
Policy Entropy: 2.52372
Value Function Loss: 0.01463

Mean KL Divergence: 0.00703
SB3 Clip Fraction: 0.06464
Policy Update Magnitude: 0.30970
Value Function Update Magnitude: 0.33284

Collected Steps per Second: 21,603.07425
Overall Steps per Second: 10,596.74283

Timestep Collection Time: 2.31495
Timestep Consumption Time: 2.40443
PPO Batch Consumption Time: 0.27730
Total Iteration Time: 4.71937

Cumulative Model Updates: 251,084
Cumulative Timesteps: 2,094,637,012

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2094637012...
Checkpoint 2094637012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86,423.23127
Policy Entropy: 2.51891
Value Function Loss: 0.01434

Mean KL Divergence: 0.00687
SB3 Clip Fraction: 0.06297
Policy Update Magnitude: 0.30493
Value Function Update Magnitude: 0.29462

Collected Steps per Second: 21,506.70745
Overall Steps per Second: 10,487.96428

Timestep Collection Time: 2.32486
Timestep Consumption Time: 2.44251
PPO Batch Consumption Time: 0.27910
Total Iteration Time: 4.76737

Cumulative Model Updates: 251,090
Cumulative Timesteps: 2,094,687,012

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86,423.23127
Policy Entropy: 2.51521
Value Function Loss: 0.01334

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.07808
Policy Update Magnitude: 0.30543
Value Function Update Magnitude: 0.29888

Collected Steps per Second: 22,086.67385
Overall Steps per Second: 10,580.16280

Timestep Collection Time: 2.26381
Timestep Consumption Time: 2.46202
PPO Batch Consumption Time: 0.27696
Total Iteration Time: 4.72583

Cumulative Model Updates: 251,096
Cumulative Timesteps: 2,094,737,012

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2094737012...
Checkpoint 2094737012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 73,056.03808
Policy Entropy: 2.49701
Value Function Loss: 0.01341

Mean KL Divergence: 0.01114
SB3 Clip Fraction: 0.09114
Policy Update Magnitude: 0.29836
Value Function Update Magnitude: 0.31862

Collected Steps per Second: 21,925.63131
Overall Steps per Second: 10,574.13318

Timestep Collection Time: 2.28071
Timestep Consumption Time: 2.44838
PPO Batch Consumption Time: 0.27950
Total Iteration Time: 4.72909

Cumulative Model Updates: 251,102
Cumulative Timesteps: 2,094,787,018

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77,314.79222
Policy Entropy: 2.49562
Value Function Loss: 0.01403

Mean KL Divergence: 0.01143
SB3 Clip Fraction: 0.09912
Policy Update Magnitude: 0.30910
Value Function Update Magnitude: 0.32375

Collected Steps per Second: 22,224.15903
Overall Steps per Second: 10,524.28200

Timestep Collection Time: 2.24998
Timestep Consumption Time: 2.50131
PPO Batch Consumption Time: 0.29365
Total Iteration Time: 4.75130

Cumulative Model Updates: 251,108
Cumulative Timesteps: 2,094,837,022

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2094837022...
Checkpoint 2094837022 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 51,936.92846
Policy Entropy: 2.48715
Value Function Loss: 0.01669

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.09496
Policy Update Magnitude: 0.31302
Value Function Update Magnitude: 0.32831

Collected Steps per Second: 21,828.82113
Overall Steps per Second: 10,626.43138

Timestep Collection Time: 2.29174
Timestep Consumption Time: 2.41595
PPO Batch Consumption Time: 0.27785
Total Iteration Time: 4.70770

Cumulative Model Updates: 251,114
Cumulative Timesteps: 2,094,887,048

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 69,190.77840
Policy Entropy: 2.49496
Value Function Loss: 0.01703

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.08480
Policy Update Magnitude: 0.32279
Value Function Update Magnitude: 0.36744

Collected Steps per Second: 22,234.78678
Overall Steps per Second: 10,574.50796

Timestep Collection Time: 2.24954
Timestep Consumption Time: 2.48052
PPO Batch Consumption Time: 0.28968
Total Iteration Time: 4.73005

Cumulative Model Updates: 251,120
Cumulative Timesteps: 2,094,937,066

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2094937066...
Checkpoint 2094937066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 59,467.33235
Policy Entropy: 2.48389
Value Function Loss: 0.01855

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.07773
Policy Update Magnitude: 0.33625
Value Function Update Magnitude: 0.40743

Collected Steps per Second: 20,853.34127
Overall Steps per Second: 10,549.68841

Timestep Collection Time: 2.39894
Timestep Consumption Time: 2.34300
PPO Batch Consumption Time: 0.27767
Total Iteration Time: 4.74194

Cumulative Model Updates: 251,126
Cumulative Timesteps: 2,094,987,092

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 71,492.64507
Policy Entropy: 2.48614
Value Function Loss: 0.01517

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.07251
Policy Update Magnitude: 0.32612
Value Function Update Magnitude: 0.41178

Collected Steps per Second: 21,386.48623
Overall Steps per Second: 10,519.77283

Timestep Collection Time: 2.33923
Timestep Consumption Time: 2.41638
PPO Batch Consumption Time: 0.29165
Total Iteration Time: 4.75562

Cumulative Model Updates: 251,132
Cumulative Timesteps: 2,095,037,120

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2095037120...
Checkpoint 2095037120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84,349.81952
Policy Entropy: 2.48405
Value Function Loss: 0.01569

Mean KL Divergence: 0.00752
SB3 Clip Fraction: 0.06609
Policy Update Magnitude: 0.31734
Value Function Update Magnitude: 0.38197

Collected Steps per Second: 21,007.12786
Overall Steps per Second: 10,500.33800

Timestep Collection Time: 2.38167
Timestep Consumption Time: 2.38313
PPO Batch Consumption Time: 0.28443
Total Iteration Time: 4.76480

Cumulative Model Updates: 251,138
Cumulative Timesteps: 2,095,087,152

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81,170.54539
Policy Entropy: 2.49549
Value Function Loss: 0.01441

Mean KL Divergence: 0.00732
SB3 Clip Fraction: 0.06930
Policy Update Magnitude: 0.31356
Value Function Update Magnitude: 0.34437

Collected Steps per Second: 20,940.69650
Overall Steps per Second: 10,428.33263

Timestep Collection Time: 2.38922
Timestep Consumption Time: 2.40848
PPO Batch Consumption Time: 0.27774
Total Iteration Time: 4.79770

Cumulative Model Updates: 251,144
Cumulative Timesteps: 2,095,137,184

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2095137184...
Checkpoint 2095137184 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 75,407.04292
Policy Entropy: 2.49851
Value Function Loss: 0.01376

Mean KL Divergence: 0.00704
SB3 Clip Fraction: 0.06711
Policy Update Magnitude: 0.30733
Value Function Update Magnitude: 0.35492

Collected Steps per Second: 21,442.06276
Overall Steps per Second: 10,582.46024

Timestep Collection Time: 2.33224
Timestep Consumption Time: 2.39332
PPO Batch Consumption Time: 0.27796
Total Iteration Time: 4.72556

Cumulative Model Updates: 251,150
Cumulative Timesteps: 2,095,187,192

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59,593.17990
Policy Entropy: 2.48861
Value Function Loss: 0.01176

Mean KL Divergence: 0.00649
SB3 Clip Fraction: 0.06292
Policy Update Magnitude: 0.29725
Value Function Update Magnitude: 0.34297

Collected Steps per Second: 22,091.00340
Overall Steps per Second: 10,524.82152

Timestep Collection Time: 2.26409
Timestep Consumption Time: 2.48811
PPO Batch Consumption Time: 0.28878
Total Iteration Time: 4.75219

Cumulative Model Updates: 251,156
Cumulative Timesteps: 2,095,237,208

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2095237208...
Checkpoint 2095237208 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 77,866.29838
Policy Entropy: 2.49511
Value Function Loss: 0.01228

Mean KL Divergence: 0.00646
SB3 Clip Fraction: 0.06190
Policy Update Magnitude: 0.29561
Value Function Update Magnitude: 0.32926

Collected Steps per Second: 21,806.76807
Overall Steps per Second: 10,563.74229

Timestep Collection Time: 2.29516
Timestep Consumption Time: 2.44275
PPO Batch Consumption Time: 0.27872
Total Iteration Time: 4.73790

Cumulative Model Updates: 251,162
Cumulative Timesteps: 2,095,287,258

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82,100.76860
Policy Entropy: 2.49132
Value Function Loss: 0.01286

Mean KL Divergence: 0.00628
SB3 Clip Fraction: 0.05943
Policy Update Magnitude: 0.29366
Value Function Update Magnitude: 0.30658

Collected Steps per Second: 22,137.40965
Overall Steps per Second: 10,558.50030

Timestep Collection Time: 2.25988
Timestep Consumption Time: 2.47829
PPO Batch Consumption Time: 0.28871
Total Iteration Time: 4.73817

Cumulative Model Updates: 251,168
Cumulative Timesteps: 2,095,337,286

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2095337286...
Checkpoint 2095337286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 68,748.20174
Policy Entropy: 2.50793
Value Function Loss: 0.01528

Mean KL Divergence: 0.00648
SB3 Clip Fraction: 0.05908
Policy Update Magnitude: 0.30816
Value Function Update Magnitude: 0.30359

Collected Steps per Second: 21,971.17787
Overall Steps per Second: 10,655.28353

Timestep Collection Time: 2.27580
Timestep Consumption Time: 2.41690
PPO Batch Consumption Time: 0.27759
Total Iteration Time: 4.69270

Cumulative Model Updates: 251,174
Cumulative Timesteps: 2,095,387,288

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57,234.55073
Policy Entropy: 2.53028
Value Function Loss: 0.01410

Mean KL Divergence: 0.00719
SB3 Clip Fraction: 0.06775
Policy Update Magnitude: 0.30534
Value Function Update Magnitude: 0.29919

Collected Steps per Second: 21,931.36714
Overall Steps per Second: 10,428.36843

Timestep Collection Time: 2.28030
Timestep Consumption Time: 2.51528
PPO Batch Consumption Time: 0.29413
Total Iteration Time: 4.79557

Cumulative Model Updates: 251,180
Cumulative Timesteps: 2,095,437,298

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2095437298...
Checkpoint 2095437298 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 57,234.55073
Policy Entropy: 2.54303
Value Function Loss: 0.01324

Mean KL Divergence: 0.00745
SB3 Clip Fraction: 0.06833
Policy Update Magnitude: 0.29168
Value Function Update Magnitude: 0.28118

Collected Steps per Second: 21,792.59994
Overall Steps per Second: 10,568.20498

Timestep Collection Time: 2.29509
Timestep Consumption Time: 2.43760
PPO Batch Consumption Time: 0.27943
Total Iteration Time: 4.73269

Cumulative Model Updates: 251,186
Cumulative Timesteps: 2,095,487,314

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54,790.37194
Policy Entropy: 2.54349
Value Function Loss: 0.01193

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.07625
Policy Update Magnitude: 0.29303
Value Function Update Magnitude: 0.27849

Collected Steps per Second: 21,256.05835
Overall Steps per Second: 10,457.56508

Timestep Collection Time: 2.35378
Timestep Consumption Time: 2.43051
PPO Batch Consumption Time: 0.27860
Total Iteration Time: 4.78429

Cumulative Model Updates: 251,192
Cumulative Timesteps: 2,095,537,346

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2095537346...
Checkpoint 2095537346 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 57,479.97411
Policy Entropy: 2.54422
Value Function Loss: 0.01230

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.07468
Policy Update Magnitude: 0.28886
Value Function Update Magnitude: 0.27361

Collected Steps per Second: 21,491.29731
Overall Steps per Second: 10,355.28746

Timestep Collection Time: 2.32680
Timestep Consumption Time: 2.50223
PPO Batch Consumption Time: 0.29229
Total Iteration Time: 4.82903

Cumulative Model Updates: 251,198
Cumulative Timesteps: 2,095,587,352

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 72,703.73372
Policy Entropy: 2.53737
Value Function Loss: 0.01460

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.07311
Policy Update Magnitude: 0.29589
Value Function Update Magnitude: 0.29711

Collected Steps per Second: 21,694.41697
Overall Steps per Second: 10,341.12568

Timestep Collection Time: 2.30594
Timestep Consumption Time: 2.53164
PPO Batch Consumption Time: 0.29388
Total Iteration Time: 4.83758

Cumulative Model Updates: 251,204
Cumulative Timesteps: 2,095,637,378

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2095637378...
Checkpoint 2095637378 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 92,147.44502
Policy Entropy: 2.53922
Value Function Loss: 0.01370

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.09154
Policy Update Magnitude: 0.30412
Value Function Update Magnitude: 0.32375

Collected Steps per Second: 21,938.94651
Overall Steps per Second: 10,606.69439

Timestep Collection Time: 2.27978
Timestep Consumption Time: 2.43573
PPO Batch Consumption Time: 0.27867
Total Iteration Time: 4.71551

Cumulative Model Updates: 251,210
Cumulative Timesteps: 2,095,687,394

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80,024.00715
Policy Entropy: 2.54290
Value Function Loss: 0.01383

Mean KL Divergence: 0.01211
SB3 Clip Fraction: 0.10112
Policy Update Magnitude: 0.30087
Value Function Update Magnitude: 0.33252

Collected Steps per Second: 22,387.99589
Overall Steps per Second: 10,484.51226

Timestep Collection Time: 2.23388
Timestep Consumption Time: 2.53621
PPO Batch Consumption Time: 0.29104
Total Iteration Time: 4.77008

Cumulative Model Updates: 251,216
Cumulative Timesteps: 2,095,737,406

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2095737406...
Checkpoint 2095737406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 64,889.49207
Policy Entropy: 2.55047
Value Function Loss: 0.01478

Mean KL Divergence: 0.01257
SB3 Clip Fraction: 0.09893
Policy Update Magnitude: 0.30645
Value Function Update Magnitude: 0.30352

Collected Steps per Second: 21,953.56066
Overall Steps per Second: 10,597.89670

Timestep Collection Time: 2.27927
Timestep Consumption Time: 2.44224
PPO Batch Consumption Time: 0.27880
Total Iteration Time: 4.72150

Cumulative Model Updates: 251,222
Cumulative Timesteps: 2,095,787,444

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70,098.47074
Policy Entropy: 2.54353
Value Function Loss: 0.01473

Mean KL Divergence: 0.01081
SB3 Clip Fraction: 0.08876
Policy Update Magnitude: 0.30808
Value Function Update Magnitude: 0.23644

Collected Steps per Second: 22,279.50577
Overall Steps per Second: 10,504.80094

Timestep Collection Time: 2.24637
Timestep Consumption Time: 2.51793
PPO Batch Consumption Time: 0.29412
Total Iteration Time: 4.76430

Cumulative Model Updates: 251,228
Cumulative Timesteps: 2,095,837,492

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 2095837492...
Checkpoint 2095837492 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 62,987.50549
Policy Entropy: 2.55825
Value Function Loss: 0.01396

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.07248
Policy Update Magnitude: 0.29647
Value Function Update Magnitude: 0.19159

Collected Steps per Second: 20,853.41624
Overall Steps per Second: 10,193.69571

Timestep Collection Time: 2.39798
Timestep Consumption Time: 2.50760
PPO Batch Consumption Time: 0.29189
Total Iteration Time: 4.90558

Cumulative Model Updates: 251,234
Cumulative Timesteps: 2,095,887,498

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66,187.32894
Policy Entropy: 2.56795
Value Function Loss: 0.01328

Mean KL Divergence: 0.00634
SB3 Clip Fraction: 0.05782
Policy Update Magnitude: 0.29291
Value Function Update Magnitude: 0.18133

Collected Steps per Second: 21,220.26936
Overall Steps per Second: 10,438.06309

Timestep Collection Time: 2.35859
Timestep Consumption Time: 2.43636
PPO Batch Consumption Time: 0.27849
Total Iteration Time: 4.79495

Cumulative Model Updates: 251,240
Cumulative Timesteps: 2,095,937,548

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 2095937548...
Checkpoint 2095937548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84,578.96123
Policy Entropy: 2.57038
Value Function Loss: 0.01368

Mean KL Divergence: 0.00760
SB3 Clip Fraction: 0.07155
Policy Update Magnitude: 0.29526
Value Function Update Magnitude: 0.18145

Collected Steps per Second: 21,663.68305
Overall Steps per Second: 10,610.71722

Timestep Collection Time: 2.30967
Timestep Consumption Time: 2.40594
PPO Batch Consumption Time: 0.27801
Total Iteration Time: 4.71561

Cumulative Model Updates: 251,246
Cumulative Timesteps: 2,095,987,584

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 119,600.04183
Policy Entropy: 2.57691
Value Function Loss: 0.01512

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.08201
Policy Update Magnitude: 0.29466
Value Function Update Magnitude: 0.18430

Collected Steps per Second: 21,669.88161
Overall Steps per Second: 10,522.14311

Timestep Collection Time: 2.30947
Timestep Consumption Time: 2.44678
PPO Batch Consumption Time: 0.27886
Total Iteration Time: 4.75626

Cumulative Model Updates: 251,252
Cumulative Timesteps: 2,096,037,630

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 2096037630...
Checkpoint 2096037630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 91,304.72603
Policy Entropy: 2.57280
Value Function Loss: 0.01463

Mean KL Divergence: 0.00724
SB3 Clip Fraction: 0.07050
Policy Update Magnitude: 0.29270
Value Function Update Magnitude: 0.17339

Collected Steps per Second: 21,411.87145
Overall Steps per Second: 10,575.51893

Timestep Collection Time: 2.33525
Timestep Consumption Time: 2.39284
PPO Batch Consumption Time: 0.27858
Total Iteration Time: 4.72809

Cumulative Model Updates: 251,258
Cumulative Timesteps: 2,096,087,632

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80,391.31050
Policy Entropy: 2.56542
Value Function Loss: 0.01389

Mean KL Divergence: 0.00752
SB3 Clip Fraction: 0.07148
Policy Update Magnitude: 0.28667
Value Function Update Magnitude: 0.17951

Collected Steps per Second: 21,506.83962
Overall Steps per Second: 10,512.29020

Timestep Collection Time: 2.32503
Timestep Consumption Time: 2.43169
PPO Batch Consumption Time: 0.29178
Total Iteration Time: 4.75672

Cumulative Model Updates: 251,264
Cumulative Timesteps: 2,096,137,636

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2096137636...
Checkpoint 2096137636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 80,391.31050
Policy Entropy: 2.52883
Value Function Loss: 0.01212

Mean KL Divergence: 0.00635
SB3 Clip Fraction: 0.06181
Policy Update Magnitude: 0.28126
Value Function Update Magnitude: 0.19382

Collected Steps per Second: 21,108.05386
Overall Steps per Second: 10,599.05213

Timestep Collection Time: 2.37047
Timestep Consumption Time: 2.35033
PPO Batch Consumption Time: 0.27848
Total Iteration Time: 4.72080

Cumulative Model Updates: 251,270
Cumulative Timesteps: 2,096,187,672

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60,677.75366
Policy Entropy: 2.54004
Value Function Loss: 0.01266

Mean KL Divergence: 0.00609
SB3 Clip Fraction: 0.05960
Policy Update Magnitude: 0.28891
Value Function Update Magnitude: 0.22205

Collected Steps per Second: 21,667.15784
Overall Steps per Second: 10,486.11628

Timestep Collection Time: 2.30773
Timestep Consumption Time: 2.46067
PPO Batch Consumption Time: 0.28855
Total Iteration Time: 4.76840

Cumulative Model Updates: 251,276
Cumulative Timesteps: 2,096,237,674

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2096237674...
Checkpoint 2096237674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 95,411.18969
Policy Entropy: 2.53850
Value Function Loss: 0.01309

Mean KL Divergence: 0.00653
SB3 Clip Fraction: 0.06313
Policy Update Magnitude: 0.29446
Value Function Update Magnitude: 0.23411

Collected Steps per Second: 21,926.43749
Overall Steps per Second: 10,693.46503

Timestep Collection Time: 2.28099
Timestep Consumption Time: 2.39607
PPO Batch Consumption Time: 0.27726
Total Iteration Time: 4.67706

Cumulative Model Updates: 251,282
Cumulative Timesteps: 2,096,287,688

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 113,215.78739
Policy Entropy: 2.53172
Value Function Loss: 0.01476

Mean KL Divergence: 0.00616
SB3 Clip Fraction: 0.05662
Policy Update Magnitude: 0.29719
Value Function Update Magnitude: 0.20601

Collected Steps per Second: 22,053.26261
Overall Steps per Second: 10,548.11038

Timestep Collection Time: 2.26833
Timestep Consumption Time: 2.47413
PPO Batch Consumption Time: 0.29148
Total Iteration Time: 4.74246

Cumulative Model Updates: 251,288
Cumulative Timesteps: 2,096,337,712

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2096337712...
Checkpoint 2096337712 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 104,303.92088
Policy Entropy: 2.52877
Value Function Loss: 0.01690

Mean KL Divergence: 0.00672
SB3 Clip Fraction: 0.06184
Policy Update Magnitude: 0.31318
Value Function Update Magnitude: 0.21131

Collected Steps per Second: 21,611.81177
Overall Steps per Second: 10,580.02295

Timestep Collection Time: 2.31494
Timestep Consumption Time: 2.41379
PPO Batch Consumption Time: 0.27705
Total Iteration Time: 4.72872

Cumulative Model Updates: 251,294
Cumulative Timesteps: 2,096,387,742

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62,055.54252
Policy Entropy: 2.53034
Value Function Loss: 0.01816

Mean KL Divergence: 0.00710
SB3 Clip Fraction: 0.06538
Policy Update Magnitude: 0.32269
Value Function Update Magnitude: 0.23770

Collected Steps per Second: 21,296.30706
Overall Steps per Second: 10,326.55734

Timestep Collection Time: 2.34782
Timestep Consumption Time: 2.49406
PPO Batch Consumption Time: 0.28823
Total Iteration Time: 4.84188

Cumulative Model Updates: 251,300
Cumulative Timesteps: 2,096,437,742

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2096437742...
Checkpoint 2096437742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 73,665.00809
Policy Entropy: 2.53672
Value Function Loss: 0.01862

Mean KL Divergence: 0.00721
SB3 Clip Fraction: 0.06718
Policy Update Magnitude: 0.32527
Value Function Update Magnitude: 0.23753

Collected Steps per Second: 21,245.86283
Overall Steps per Second: 10,251.49648

Timestep Collection Time: 2.35481
Timestep Consumption Time: 2.52545
PPO Batch Consumption Time: 0.29111
Total Iteration Time: 4.88026

Cumulative Model Updates: 251,306
Cumulative Timesteps: 2,096,487,772

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 101,392.76861
Policy Entropy: 2.54028
Value Function Loss: 0.01666

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.06876
Policy Update Magnitude: 0.31921
Value Function Update Magnitude: 0.25707

Collected Steps per Second: 21,977.72840
Overall Steps per Second: 10,450.82858

Timestep Collection Time: 2.27585
Timestep Consumption Time: 2.51018
PPO Batch Consumption Time: 0.29140
Total Iteration Time: 4.78603

Cumulative Model Updates: 251,312
Cumulative Timesteps: 2,096,537,790

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2096537790...
Checkpoint 2096537790 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 97,520.89677
Policy Entropy: 2.52389
Value Function Loss: 0.01631

Mean KL Divergence: 0.00766
SB3 Clip Fraction: 0.07432
Policy Update Magnitude: 0.31456
Value Function Update Magnitude: 0.32688

Collected Steps per Second: 21,954.87814
Overall Steps per Second: 10,593.69479

Timestep Collection Time: 2.27968
Timestep Consumption Time: 2.44483
PPO Batch Consumption Time: 0.28033
Total Iteration Time: 4.72451

Cumulative Model Updates: 251,318
Cumulative Timesteps: 2,096,587,840

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 73,173.65361
Policy Entropy: 2.54597
Value Function Loss: 0.01468

Mean KL Divergence: 0.00723
SB3 Clip Fraction: 0.06914
Policy Update Magnitude: 0.31521
Value Function Update Magnitude: 0.33974

Collected Steps per Second: 22,099.57449
Overall Steps per Second: 10,496.63338

Timestep Collection Time: 2.26258
Timestep Consumption Time: 2.50105
PPO Batch Consumption Time: 0.29189
Total Iteration Time: 4.76362

Cumulative Model Updates: 251,324
Cumulative Timesteps: 2,096,637,842

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2096637842...
Checkpoint 2096637842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 63,375.16132
Policy Entropy: 2.52506
Value Function Loss: 0.01637

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.08156
Policy Update Magnitude: 0.31751
Value Function Update Magnitude: 0.32038

Collected Steps per Second: 21,916.63400
Overall Steps per Second: 10,587.65865

Timestep Collection Time: 2.28283
Timestep Consumption Time: 2.44267
PPO Batch Consumption Time: 0.28151
Total Iteration Time: 4.72550

Cumulative Model Updates: 251,330
Cumulative Timesteps: 2,096,687,874

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 74,000.53065
Policy Entropy: 2.55378
Value Function Loss: 0.01527

Mean KL Divergence: 0.01238
SB3 Clip Fraction: 0.10318
Policy Update Magnitude: 0.31420
Value Function Update Magnitude: 0.34427

Collected Steps per Second: 21,271.10846
Overall Steps per Second: 10,516.64850

Timestep Collection Time: 2.35089
Timestep Consumption Time: 2.40405
PPO Batch Consumption Time: 0.28830
Total Iteration Time: 4.75494

Cumulative Model Updates: 251,336
Cumulative Timesteps: 2,096,737,880

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2096737880...
Checkpoint 2096737880 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 77,167.60784
Policy Entropy: 2.52316
Value Function Loss: 0.01495

Mean KL Divergence: 0.01132
SB3 Clip Fraction: 0.09873
Policy Update Magnitude: 0.31121
Value Function Update Magnitude: 0.34096

Collected Steps per Second: 20,907.45321
Overall Steps per Second: 10,564.58639

Timestep Collection Time: 2.39187
Timestep Consumption Time: 2.34168
PPO Batch Consumption Time: 0.27824
Total Iteration Time: 4.73355

Cumulative Model Updates: 251,342
Cumulative Timesteps: 2,096,787,888

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92,303.82260
Policy Entropy: 2.54891
Value Function Loss: 0.01342

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.08087
Policy Update Magnitude: 0.30899
Value Function Update Magnitude: 0.31737

Collected Steps per Second: 21,032.20108
Overall Steps per Second: 10,571.34713

Timestep Collection Time: 2.37797
Timestep Consumption Time: 2.35312
PPO Batch Consumption Time: 0.27739
Total Iteration Time: 4.73109

Cumulative Model Updates: 251,348
Cumulative Timesteps: 2,096,837,902

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2096837902...
Checkpoint 2096837902 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 67,202.03305
Policy Entropy: 2.54280
Value Function Loss: 0.01364

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.07240
Policy Update Magnitude: 0.30654
Value Function Update Magnitude: 0.31155

Collected Steps per Second: 21,179.50516
Overall Steps per Second: 10,340.98965

Timestep Collection Time: 2.36134
Timestep Consumption Time: 2.47495
PPO Batch Consumption Time: 0.28893
Total Iteration Time: 4.83629

Cumulative Model Updates: 251,354
Cumulative Timesteps: 2,096,887,914

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 71,169.46322
Policy Entropy: 2.55853
Value Function Loss: 0.01343

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.07426
Policy Update Magnitude: 0.30757
Value Function Update Magnitude: 0.34033

Collected Steps per Second: 22,300.52939
Overall Steps per Second: 10,708.96449

Timestep Collection Time: 2.24344
Timestep Consumption Time: 2.42834
PPO Batch Consumption Time: 0.27897
Total Iteration Time: 4.67179

Cumulative Model Updates: 251,360
Cumulative Timesteps: 2,096,937,944

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2096937944...
Checkpoint 2096937944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 58,074.88327
Policy Entropy: 2.55081
Value Function Loss: 0.01354

Mean KL Divergence: 0.00714
SB3 Clip Fraction: 0.06579
Policy Update Magnitude: 0.30558
Value Function Update Magnitude: 0.34329

Collected Steps per Second: 21,799.25652
Overall Steps per Second: 10,610.83342

Timestep Collection Time: 2.29503
Timestep Consumption Time: 2.41996
PPO Batch Consumption Time: 0.27922
Total Iteration Time: 4.71499

Cumulative Model Updates: 251,366
Cumulative Timesteps: 2,096,987,974

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56,143.35124
Policy Entropy: 2.54580
Value Function Loss: 0.01331

Mean KL Divergence: 0.00710
SB3 Clip Fraction: 0.06357
Policy Update Magnitude: 0.30531
Value Function Update Magnitude: 0.36085

Collected Steps per Second: 22,086.71343
Overall Steps per Second: 10,438.39637

Timestep Collection Time: 2.26408
Timestep Consumption Time: 2.52651
PPO Batch Consumption Time: 0.29127
Total Iteration Time: 4.79058

Cumulative Model Updates: 251,372
Cumulative Timesteps: 2,097,037,980

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2097037980...
Checkpoint 2097037980 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 59,643.89036
Policy Entropy: 2.55266
Value Function Loss: 0.01236

Mean KL Divergence: 0.00730
SB3 Clip Fraction: 0.06480
Policy Update Magnitude: 0.30023
Value Function Update Magnitude: 0.34867

Collected Steps per Second: 21,952.69999
Overall Steps per Second: 10,605.82044

Timestep Collection Time: 2.27826
Timestep Consumption Time: 2.43745
PPO Batch Consumption Time: 0.27937
Total Iteration Time: 4.71571

Cumulative Model Updates: 251,378
Cumulative Timesteps: 2,097,087,994

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65,339.88030
Policy Entropy: 2.56289
Value Function Loss: 0.01291

Mean KL Divergence: 0.00757
SB3 Clip Fraction: 0.06352
Policy Update Magnitude: 0.29985
Value Function Update Magnitude: 0.30018

Collected Steps per Second: 22,003.06762
Overall Steps per Second: 10,510.81007

Timestep Collection Time: 2.27277
Timestep Consumption Time: 2.48499
PPO Batch Consumption Time: 0.28642
Total Iteration Time: 4.75777

Cumulative Model Updates: 251,384
Cumulative Timesteps: 2,097,138,002

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2097138002...
Checkpoint 2097138002 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 94,801.64653
Policy Entropy: 2.59655
Value Function Loss: 0.01674

Mean KL Divergence: 0.00725
SB3 Clip Fraction: 0.06659
Policy Update Magnitude: 0.31148
Value Function Update Magnitude: 0.30366

Collected Steps per Second: 22,241.68701
Overall Steps per Second: 10,702.86018

Timestep Collection Time: 2.24839
Timestep Consumption Time: 2.42401
PPO Batch Consumption Time: 0.27657
Total Iteration Time: 4.67240

Cumulative Model Updates: 251,390
Cumulative Timesteps: 2,097,188,010

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67,276.65290
Policy Entropy: 2.60855
Value Function Loss: 0.01543

Mean KL Divergence: 0.00756
SB3 Clip Fraction: 0.07030
Policy Update Magnitude: 0.31062
Value Function Update Magnitude: 0.30087

Collected Steps per Second: 21,915.66980
Overall Steps per Second: 10,423.58395

Timestep Collection Time: 2.28257
Timestep Consumption Time: 2.51655
PPO Batch Consumption Time: 0.29390
Total Iteration Time: 4.79912

Cumulative Model Updates: 251,396
Cumulative Timesteps: 2,097,238,034

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2097238034...
Checkpoint 2097238034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 72,585.91736
Policy Entropy: 2.63589
Value Function Loss: 0.01395

Mean KL Divergence: 0.00649
SB3 Clip Fraction: 0.06223
Policy Update Magnitude: 0.29354
Value Function Update Magnitude: 0.30829

Collected Steps per Second: 21,509.94979
Overall Steps per Second: 10,536.81153

Timestep Collection Time: 2.32525
Timestep Consumption Time: 2.42154
PPO Batch Consumption Time: 0.27833
Total Iteration Time: 4.74679

Cumulative Model Updates: 251,402
Cumulative Timesteps: 2,097,288,050

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84,744.99511
Policy Entropy: 2.64434
Value Function Loss: 0.01279

Mean KL Divergence: 0.00585
SB3 Clip Fraction: 0.05541
Policy Update Magnitude: 0.28752
Value Function Update Magnitude: 0.27475

Collected Steps per Second: 21,725.25499
Overall Steps per Second: 10,600.53766

Timestep Collection Time: 2.30294
Timestep Consumption Time: 2.41682
PPO Batch Consumption Time: 0.27707
Total Iteration Time: 4.71976

Cumulative Model Updates: 251,408
Cumulative Timesteps: 2,097,338,082

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2097338082...
Checkpoint 2097338082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 73,908.58697
Policy Entropy: 2.62915
Value Function Loss: 0.01260

Mean KL Divergence: 0.00580
SB3 Clip Fraction: 0.05451
Policy Update Magnitude: 0.28651
Value Function Update Magnitude: 0.28508

Collected Steps per Second: 21,788.55202
Overall Steps per Second: 10,577.12892

Timestep Collection Time: 2.29644
Timestep Consumption Time: 2.43415
PPO Batch Consumption Time: 0.27926
Total Iteration Time: 4.73058

Cumulative Model Updates: 251,414
Cumulative Timesteps: 2,097,388,118

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56,129.28135
Policy Entropy: 2.60411
Value Function Loss: 0.01457

Mean KL Divergence: 0.00673
SB3 Clip Fraction: 0.06344
Policy Update Magnitude: 0.29315
Value Function Update Magnitude: 0.30213

Collected Steps per Second: 22,038.82248
Overall Steps per Second: 10,442.28405

Timestep Collection Time: 2.26881
Timestep Consumption Time: 2.51960
PPO Batch Consumption Time: 0.28731
Total Iteration Time: 4.78842

Cumulative Model Updates: 251,420
Cumulative Timesteps: 2,097,438,120

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2097438120...
Checkpoint 2097438120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 52,711.05139
Policy Entropy: 2.59106
Value Function Loss: 0.01355

Mean KL Divergence: 0.00718
SB3 Clip Fraction: 0.06636
Policy Update Magnitude: 0.30126
Value Function Update Magnitude: 0.31083

Collected Steps per Second: 21,841.66986
Overall Steps per Second: 10,560.99873

Timestep Collection Time: 2.28966
Timestep Consumption Time: 2.44569
PPO Batch Consumption Time: 0.27871
Total Iteration Time: 4.73535

Cumulative Model Updates: 251,426
Cumulative Timesteps: 2,097,488,130

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52,278.32034
Policy Entropy: 2.59493
Value Function Loss: 0.01235

Mean KL Divergence: 0.00642
SB3 Clip Fraction: 0.05905
Policy Update Magnitude: 0.29358
Value Function Update Magnitude: 0.31928

Collected Steps per Second: 22,229.06658
Overall Steps per Second: 10,546.25182

Timestep Collection Time: 2.25003
Timestep Consumption Time: 2.49251
PPO Batch Consumption Time: 0.28973
Total Iteration Time: 4.74254

Cumulative Model Updates: 251,432
Cumulative Timesteps: 2,097,538,146

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2097538146...
Checkpoint 2097538146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,328.79780
Policy Entropy: 2.58972
Value Function Loss: 0.01194

Mean KL Divergence: 0.00643
SB3 Clip Fraction: 0.05899
Policy Update Magnitude: 0.28794
Value Function Update Magnitude: 0.28762

Collected Steps per Second: 22,040.50447
Overall Steps per Second: 10,653.36052

Timestep Collection Time: 2.26873
Timestep Consumption Time: 2.42500
PPO Batch Consumption Time: 0.27782
Total Iteration Time: 4.69373

Cumulative Model Updates: 251,438
Cumulative Timesteps: 2,097,588,150

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68,052.19654
Policy Entropy: 2.59266
Value Function Loss: 0.01275

Mean KL Divergence: 0.00704
SB3 Clip Fraction: 0.06541
Policy Update Magnitude: 0.28252
Value Function Update Magnitude: 0.23768

Collected Steps per Second: 22,307.12504
Overall Steps per Second: 10,551.80735

Timestep Collection Time: 2.24314
Timestep Consumption Time: 2.49899
PPO Batch Consumption Time: 0.29292
Total Iteration Time: 4.74213

Cumulative Model Updates: 251,444
Cumulative Timesteps: 2,097,638,188

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 2097638188...
Checkpoint 2097638188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 81,668.16126
Policy Entropy: 2.59342
Value Function Loss: 0.01410

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.08453
Policy Update Magnitude: 0.28034
Value Function Update Magnitude: 0.23232

Collected Steps per Second: 21,931.58908
Overall Steps per Second: 10,505.53930

Timestep Collection Time: 2.28182
Timestep Consumption Time: 2.48176
PPO Batch Consumption Time: 0.28715
Total Iteration Time: 4.76358

Cumulative Model Updates: 251,450
Cumulative Timesteps: 2,097,688,232

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81,649.65612
Policy Entropy: 2.60070
Value Function Loss: 0.01439

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.08063
Policy Update Magnitude: 0.29062
Value Function Update Magnitude: 0.25412

Collected Steps per Second: 22,038.58448
Overall Steps per Second: 10,485.05197

Timestep Collection Time: 2.26993
Timestep Consumption Time: 2.50125
PPO Batch Consumption Time: 0.29255
Total Iteration Time: 4.77117

Cumulative Model Updates: 251,456
Cumulative Timesteps: 2,097,738,258

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2097738258...
Checkpoint 2097738258 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 76,246.97207
Policy Entropy: 2.58259
Value Function Loss: 0.01440

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.07330
Policy Update Magnitude: 0.29383
Value Function Update Magnitude: 0.26434

Collected Steps per Second: 21,302.68639
Overall Steps per Second: 10,318.43002

Timestep Collection Time: 2.34909
Timestep Consumption Time: 2.50068
PPO Batch Consumption Time: 0.29177
Total Iteration Time: 4.84977

Cumulative Model Updates: 251,462
Cumulative Timesteps: 2,097,788,300

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 145,967.12183
Policy Entropy: 2.56600
Value Function Loss: 0.01480

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.07036
Policy Update Magnitude: 0.30460
Value Function Update Magnitude: 0.27131

Collected Steps per Second: 21,892.61092
Overall Steps per Second: 10,413.35836

Timestep Collection Time: 2.28470
Timestep Consumption Time: 2.51856
PPO Batch Consumption Time: 0.29223
Total Iteration Time: 4.80325

Cumulative Model Updates: 251,468
Cumulative Timesteps: 2,097,838,318

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2097838318...
Checkpoint 2097838318 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86,232.72105
Policy Entropy: 2.56519
Value Function Loss: 0.01619

Mean KL Divergence: 0.00639
SB3 Clip Fraction: 0.05979
Policy Update Magnitude: 0.31154
Value Function Update Magnitude: 0.28295

Collected Steps per Second: 21,429.20971
Overall Steps per Second: 10,489.41694

Timestep Collection Time: 2.33438
Timestep Consumption Time: 2.43461
PPO Batch Consumption Time: 0.27866
Total Iteration Time: 4.76900

Cumulative Model Updates: 251,474
Cumulative Timesteps: 2,097,888,342

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76,611.27030
Policy Entropy: 2.55986
Value Function Loss: 0.01669

Mean KL Divergence: 0.00677
SB3 Clip Fraction: 0.06453
Policy Update Magnitude: 0.31355
Value Function Update Magnitude: 0.34349

Collected Steps per Second: 21,626.03863
Overall Steps per Second: 10,528.82857

Timestep Collection Time: 2.31341
Timestep Consumption Time: 2.43830
PPO Batch Consumption Time: 0.27876
Total Iteration Time: 4.75172

Cumulative Model Updates: 251,480
Cumulative Timesteps: 2,097,938,372

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2097938372...
Checkpoint 2097938372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 76,611.27030
Policy Entropy: 2.58986
Value Function Loss: 0.01320

Mean KL Divergence: 0.00739
SB3 Clip Fraction: 0.06922
Policy Update Magnitude: 0.29787
Value Function Update Magnitude: 0.35605

Collected Steps per Second: 22,112.73410
Overall Steps per Second: 10,594.55917

Timestep Collection Time: 2.26241
Timestep Consumption Time: 2.45964
PPO Batch Consumption Time: 0.27826
Total Iteration Time: 4.72205

Cumulative Model Updates: 251,486
Cumulative Timesteps: 2,097,988,400

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 94,018.60194
Policy Entropy: 2.57771
Value Function Loss: 0.01226

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.07219
Policy Update Magnitude: 0.28420
Value Function Update Magnitude: 0.31720

Collected Steps per Second: 22,152.10450
Overall Steps per Second: 10,370.41212

Timestep Collection Time: 2.25766
Timestep Consumption Time: 2.56490
PPO Batch Consumption Time: 0.29695
Total Iteration Time: 4.82257

Cumulative Model Updates: 251,492
Cumulative Timesteps: 2,098,038,412

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2098038412...
Checkpoint 2098038412 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 99,301.64867
Policy Entropy: 2.57291
Value Function Loss: 0.01108

Mean KL Divergence: 0.00643
SB3 Clip Fraction: 0.06307
Policy Update Magnitude: 0.28624
Value Function Update Magnitude: 0.28103

Collected Steps per Second: 21,790.13407
Overall Steps per Second: 10,417.72285

Timestep Collection Time: 2.29489
Timestep Consumption Time: 2.50520
PPO Batch Consumption Time: 0.29317
Total Iteration Time: 4.80009

Cumulative Model Updates: 251,498
Cumulative Timesteps: 2,098,088,418

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99,301.64867
Policy Entropy: 2.56932
Value Function Loss: 0.01171

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.06523
Policy Update Magnitude: 0.28536
Value Function Update Magnitude: 0.28002

Collected Steps per Second: 22,341.05549
Overall Steps per Second: 10,711.46797

Timestep Collection Time: 2.23875
Timestep Consumption Time: 2.43064
PPO Batch Consumption Time: 0.27890
Total Iteration Time: 4.66939

Cumulative Model Updates: 251,504
Cumulative Timesteps: 2,098,138,434

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2098138434...
Checkpoint 2098138434 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 81,229.69756
Policy Entropy: 2.57929
Value Function Loss: 0.01152

Mean KL Divergence: 0.00732
SB3 Clip Fraction: 0.06687
Policy Update Magnitude: 0.28247
Value Function Update Magnitude: 0.26949

Collected Steps per Second: 21,936.95496
Overall Steps per Second: 10,615.13964

Timestep Collection Time: 2.27990
Timestep Consumption Time: 2.43168
PPO Batch Consumption Time: 0.27943
Total Iteration Time: 4.71157

Cumulative Model Updates: 251,510
Cumulative Timesteps: 2,098,188,448

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 111,082.71816
Policy Entropy: 2.57994
Value Function Loss: 0.01235

Mean KL Divergence: 0.00594
SB3 Clip Fraction: 0.05726
Policy Update Magnitude: 0.28502
Value Function Update Magnitude: 0.23755

Collected Steps per Second: 22,167.04590
Overall Steps per Second: 10,532.34856

Timestep Collection Time: 2.25632
Timestep Consumption Time: 2.49248
PPO Batch Consumption Time: 0.28787
Total Iteration Time: 4.74880

Cumulative Model Updates: 251,516
Cumulative Timesteps: 2,098,238,464

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2098238464...
Checkpoint 2098238464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 93,406.79924
Policy Entropy: 2.56703
Value Function Loss: 0.01184

Mean KL Divergence: 0.00643
SB3 Clip Fraction: 0.06092
Policy Update Magnitude: 0.29089
Value Function Update Magnitude: 0.21804

Collected Steps per Second: 21,770.46581
Overall Steps per Second: 10,590.19730

Timestep Collection Time: 2.29779
Timestep Consumption Time: 2.42582
PPO Batch Consumption Time: 0.27896
Total Iteration Time: 4.72361

Cumulative Model Updates: 251,522
Cumulative Timesteps: 2,098,288,488

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89,602.11253
Policy Entropy: 2.58131
Value Function Loss: 0.01227

Mean KL Divergence: 0.00705
SB3 Clip Fraction: 0.06517
Policy Update Magnitude: 0.30179
Value Function Update Magnitude: 0.19956

Collected Steps per Second: 21,844.74585
Overall Steps per Second: 10,607.10277

Timestep Collection Time: 2.28952
Timestep Consumption Time: 2.42562
PPO Batch Consumption Time: 0.27698
Total Iteration Time: 4.71514

Cumulative Model Updates: 251,528
Cumulative Timesteps: 2,098,338,502

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2098338502...
Checkpoint 2098338502 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 93,011.51419
Policy Entropy: 2.58744
Value Function Loss: 0.01527

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.07651
Policy Update Magnitude: 0.30085
Value Function Update Magnitude: 0.17965

Collected Steps per Second: 21,369.38095
Overall Steps per Second: 10,492.33833

Timestep Collection Time: 2.34176
Timestep Consumption Time: 2.42762
PPO Batch Consumption Time: 0.27902
Total Iteration Time: 4.76938

Cumulative Model Updates: 251,534
Cumulative Timesteps: 2,098,388,544

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 74,333.03686
Policy Entropy: 2.57530
Value Function Loss: 0.01602

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.08162
Policy Update Magnitude: 0.30633
Value Function Update Magnitude: 0.23595

Collected Steps per Second: 21,834.93415
Overall Steps per Second: 10,603.35152

Timestep Collection Time: 2.29092
Timestep Consumption Time: 2.42665
PPO Batch Consumption Time: 0.27731
Total Iteration Time: 4.71756

Cumulative Model Updates: 251,540
Cumulative Timesteps: 2,098,438,566

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2098438566...
Checkpoint 2098438566 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 57,958.04041
Policy Entropy: 2.56297
Value Function Loss: 0.01520

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.07639
Policy Update Magnitude: 0.30717
Value Function Update Magnitude: 0.29233

Collected Steps per Second: 21,120.67819
Overall Steps per Second: 10,266.63967

Timestep Collection Time: 2.36773
Timestep Consumption Time: 2.50319
PPO Batch Consumption Time: 0.29137
Total Iteration Time: 4.87092

Cumulative Model Updates: 251,546
Cumulative Timesteps: 2,098,488,574

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95,031.95595
Policy Entropy: 2.56212
Value Function Loss: 0.01467

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.08453
Policy Update Magnitude: 0.30814
Value Function Update Magnitude: 0.30585

Collected Steps per Second: 22,150.85100
Overall Steps per Second: 10,471.76995

Timestep Collection Time: 2.25743
Timestep Consumption Time: 2.51769
PPO Batch Consumption Time: 0.29025
Total Iteration Time: 4.77512

Cumulative Model Updates: 251,552
Cumulative Timesteps: 2,098,538,578

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2098538578...
Checkpoint 2098538578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 80,757.13295
Policy Entropy: 2.57793
Value Function Loss: 0.01600

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.07264
Policy Update Magnitude: 0.30790
Value Function Update Magnitude: 0.28925

Collected Steps per Second: 21,784.77287
Overall Steps per Second: 10,550.03322

Timestep Collection Time: 2.29711
Timestep Consumption Time: 2.44619
PPO Batch Consumption Time: 0.27718
Total Iteration Time: 4.74330

Cumulative Model Updates: 251,558
Cumulative Timesteps: 2,098,588,620

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86,043.42554
Policy Entropy: 2.58607
Value Function Loss: 0.01624

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.07218
Policy Update Magnitude: 0.30781
Value Function Update Magnitude: 0.31969

Collected Steps per Second: 22,504.44424
Overall Steps per Second: 10,761.93381

Timestep Collection Time: 2.22232
Timestep Consumption Time: 2.42480
PPO Batch Consumption Time: 0.27937
Total Iteration Time: 4.64712

Cumulative Model Updates: 251,564
Cumulative Timesteps: 2,098,638,632

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2098638632...
Checkpoint 2098638632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86,043.42554
Policy Entropy: 2.58901
Value Function Loss: 0.01383

Mean KL Divergence: 0.00673
SB3 Clip Fraction: 0.06102
Policy Update Magnitude: 0.30522
Value Function Update Magnitude: 0.31170

Collected Steps per Second: 21,695.18914
Overall Steps per Second: 10,596.07777

Timestep Collection Time: 2.30604
Timestep Consumption Time: 2.41552
PPO Batch Consumption Time: 0.27944
Total Iteration Time: 4.72156

Cumulative Model Updates: 251,570
Cumulative Timesteps: 2,098,688,662

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 128,007.89576
Policy Entropy: 2.57563
Value Function Loss: 0.01551

Mean KL Divergence: 0.00681
SB3 Clip Fraction: 0.06500
Policy Update Magnitude: 0.31290
Value Function Update Magnitude: 0.31894

Collected Steps per Second: 21,457.65588
Overall Steps per Second: 10,543.20305

Timestep Collection Time: 2.33082
Timestep Consumption Time: 2.41290
PPO Batch Consumption Time: 0.28812
Total Iteration Time: 4.74372

Cumulative Model Updates: 251,576
Cumulative Timesteps: 2,098,738,676

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2098738676...
Checkpoint 2098738676 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 111,807.83003
Policy Entropy: 2.56569
Value Function Loss: 0.01483

Mean KL Divergence: 0.00731
SB3 Clip Fraction: 0.06956
Policy Update Magnitude: 0.32413
Value Function Update Magnitude: 0.35120

Collected Steps per Second: 21,154.79302
Overall Steps per Second: 10,606.45057

Timestep Collection Time: 2.36429
Timestep Consumption Time: 2.35133
PPO Batch Consumption Time: 0.27950
Total Iteration Time: 4.71562

Cumulative Model Updates: 251,582
Cumulative Timesteps: 2,098,788,692

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 118,924.08358
Policy Entropy: 2.56533
Value Function Loss: 0.01465

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.07438
Policy Update Magnitude: 0.31355
Value Function Update Magnitude: 0.34171

Collected Steps per Second: 21,467.13277
Overall Steps per Second: 10,486.70462

Timestep Collection Time: 2.32989
Timestep Consumption Time: 2.43958
PPO Batch Consumption Time: 0.29253
Total Iteration Time: 4.76947

Cumulative Model Updates: 251,588
Cumulative Timesteps: 2,098,838,708

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2098838708...
Checkpoint 2098838708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 62,904.56239
Policy Entropy: 2.57491
Value Function Loss: 0.01437

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.07150
Policy Update Magnitude: 0.31266
Value Function Update Magnitude: 0.33264

Collected Steps per Second: 20,780.08071
Overall Steps per Second: 10,214.44889

Timestep Collection Time: 2.40673
Timestep Consumption Time: 2.48947
PPO Batch Consumption Time: 0.29341
Total Iteration Time: 4.89620

Cumulative Model Updates: 251,594
Cumulative Timesteps: 2,098,888,720

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62,904.56239
Policy Entropy: 2.57323
Value Function Loss: 0.01348

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.07526
Policy Update Magnitude: 0.31427
Value Function Update Magnitude: 0.33494

Collected Steps per Second: 21,845.85177
Overall Steps per Second: 10,459.04482

Timestep Collection Time: 2.29014
Timestep Consumption Time: 2.49328
PPO Batch Consumption Time: 0.29328
Total Iteration Time: 4.78342

Cumulative Model Updates: 251,600
Cumulative Timesteps: 2,098,938,750

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2098938750...
Checkpoint 2098938750 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 59,501.12169
Policy Entropy: 2.57218
Value Function Loss: 0.01658

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.07740
Policy Update Magnitude: 0.33005
Value Function Update Magnitude: 0.31211

Collected Steps per Second: 21,007.91975
Overall Steps per Second: 10,280.41439

Timestep Collection Time: 2.38053
Timestep Consumption Time: 2.48406
PPO Batch Consumption Time: 0.29300
Total Iteration Time: 4.86459

Cumulative Model Updates: 251,606
Cumulative Timesteps: 2,098,988,760

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59,501.12169
Policy Entropy: 2.56066
Value Function Loss: 0.01454

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.08309
Policy Update Magnitude: 0.31542
Value Function Update Magnitude: 0.25459

Collected Steps per Second: 21,693.32357
Overall Steps per Second: 10,374.06062

Timestep Collection Time: 2.30486
Timestep Consumption Time: 2.51486
PPO Batch Consumption Time: 0.29313
Total Iteration Time: 4.81971

Cumulative Model Updates: 251,612
Cumulative Timesteps: 2,099,038,760

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2099038760...
Checkpoint 2099038760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87,744.30232
Policy Entropy: 2.53701
Value Function Loss: 0.01701

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.07296
Policy Update Magnitude: 0.31337
Value Function Update Magnitude: 0.21104

Collected Steps per Second: 21,659.30618
Overall Steps per Second: 10,557.49455

Timestep Collection Time: 2.30958
Timestep Consumption Time: 2.42866
PPO Batch Consumption Time: 0.27841
Total Iteration Time: 4.73825

Cumulative Model Updates: 251,618
Cumulative Timesteps: 2,099,088,784

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 100,919.10451
Policy Entropy: 2.54927
Value Function Loss: 0.01502

Mean KL Divergence: 0.00698
SB3 Clip Fraction: 0.06736
Policy Update Magnitude: 0.31570
Value Function Update Magnitude: 0.17301

Collected Steps per Second: 22,139.78131
Overall Steps per Second: 10,581.17657

Timestep Collection Time: 2.25883
Timestep Consumption Time: 2.46749
PPO Batch Consumption Time: 0.27701
Total Iteration Time: 4.72632

Cumulative Model Updates: 251,624
Cumulative Timesteps: 2,099,138,794

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2099138794...
Checkpoint 2099138794 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 82,714.02437
Policy Entropy: 2.57085
Value Function Loss: 0.01621

Mean KL Divergence: 0.00707
SB3 Clip Fraction: 0.06299
Policy Update Magnitude: 0.30853
Value Function Update Magnitude: 0.16071

Collected Steps per Second: 22,003.96349
Overall Steps per Second: 10,625.55429

Timestep Collection Time: 2.27350
Timestep Consumption Time: 2.43458
PPO Batch Consumption Time: 0.27735
Total Iteration Time: 4.70808

Cumulative Model Updates: 251,630
Cumulative Timesteps: 2,099,188,820

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67,322.45358
Policy Entropy: 2.59251
Value Function Loss: 0.01517

Mean KL Divergence: 0.00629
SB3 Clip Fraction: 0.05932
Policy Update Magnitude: 0.30180
Value Function Update Magnitude: 0.16788

Collected Steps per Second: 22,358.22260
Overall Steps per Second: 10,601.78897

Timestep Collection Time: 2.23730
Timestep Consumption Time: 2.48096
PPO Batch Consumption Time: 0.28889
Total Iteration Time: 4.71826

Cumulative Model Updates: 251,636
Cumulative Timesteps: 2,099,238,842

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2099238842...
Checkpoint 2099238842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 60,074.50678
Policy Entropy: 2.57871
Value Function Loss: 0.01450

Mean KL Divergence: 0.00618
SB3 Clip Fraction: 0.05871
Policy Update Magnitude: 0.29892
Value Function Update Magnitude: 0.17118

Collected Steps per Second: 22,041.43420
Overall Steps per Second: 10,486.90492

Timestep Collection Time: 2.26982
Timestep Consumption Time: 2.50090
PPO Batch Consumption Time: 0.29458
Total Iteration Time: 4.77071

Cumulative Model Updates: 251,642
Cumulative Timesteps: 2,099,288,872

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76,298.88768
Policy Entropy: 2.56173
Value Function Loss: 0.01553

Mean KL Divergence: 0.00661
SB3 Clip Fraction: 0.06485
Policy Update Magnitude: 0.29881
Value Function Update Magnitude: 0.17097

Collected Steps per Second: 21,441.07292
Overall Steps per Second: 10,530.94297

Timestep Collection Time: 2.33309
Timestep Consumption Time: 2.41710
PPO Batch Consumption Time: 0.29298
Total Iteration Time: 4.75019

Cumulative Model Updates: 251,648
Cumulative Timesteps: 2,099,338,896

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2099338896...
Checkpoint 2099338896 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 76,298.88768
Policy Entropy: 2.55288
Value Function Loss: 0.01354

Mean KL Divergence: 0.00688
SB3 Clip Fraction: 0.06633
Policy Update Magnitude: 0.29650
Value Function Update Magnitude: 0.21199

Collected Steps per Second: 21,515.75675
Overall Steps per Second: 10,535.68626

Timestep Collection Time: 2.32406
Timestep Consumption Time: 2.42209
PPO Batch Consumption Time: 0.29162
Total Iteration Time: 4.74616

Cumulative Model Updates: 251,654
Cumulative Timesteps: 2,099,388,900

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 73,834.78668
Policy Entropy: 2.54465
Value Function Loss: 0.01535

Mean KL Divergence: 0.00653
SB3 Clip Fraction: 0.06124
Policy Update Magnitude: 0.30838
Value Function Update Magnitude: 0.26724

Collected Steps per Second: 21,650.30455
Overall Steps per Second: 10,552.09915

Timestep Collection Time: 2.30999
Timestep Consumption Time: 2.42954
PPO Batch Consumption Time: 0.29150
Total Iteration Time: 4.73953

Cumulative Model Updates: 251,660
Cumulative Timesteps: 2,099,438,912

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2099438912...
Checkpoint 2099438912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 79,952.17118
Policy Entropy: 2.56099
Value Function Loss: 0.01327

Mean KL Divergence: 0.00727
SB3 Clip Fraction: 0.06652
Policy Update Magnitude: 0.31179
Value Function Update Magnitude: 0.30848

Collected Steps per Second: 21,130.23388
Overall Steps per Second: 10,470.85979

Timestep Collection Time: 2.36694
Timestep Consumption Time: 2.40955
PPO Batch Consumption Time: 0.27847
Total Iteration Time: 4.77649

Cumulative Model Updates: 251,666
Cumulative Timesteps: 2,099,488,926

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89,065.33751
Policy Entropy: 2.58082
Value Function Loss: 0.01293

Mean KL Divergence: 0.00706
SB3 Clip Fraction: 0.06492
Policy Update Magnitude: 0.30507
Value Function Update Magnitude: 0.31920

Collected Steps per Second: 21,859.18639
Overall Steps per Second: 10,550.12035

Timestep Collection Time: 2.28810
Timestep Consumption Time: 2.45270
PPO Batch Consumption Time: 0.28643
Total Iteration Time: 4.74080

Cumulative Model Updates: 251,672
Cumulative Timesteps: 2,099,538,942

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2099538942...
Checkpoint 2099538942 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 146,619.79369
Policy Entropy: 2.59996
Value Function Loss: 0.01302

Mean KL Divergence: 0.00639
SB3 Clip Fraction: 0.06344
Policy Update Magnitude: 0.29899
Value Function Update Magnitude: 0.30300

Collected Steps per Second: 21,224.75669
Overall Steps per Second: 10,281.99966

Timestep Collection Time: 2.35762
Timestep Consumption Time: 2.50913
PPO Batch Consumption Time: 0.29286
Total Iteration Time: 4.86676

Cumulative Model Updates: 251,678
Cumulative Timesteps: 2,099,588,982

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 114,447.76907
Policy Entropy: 2.60332
Value Function Loss: 0.01342

Mean KL Divergence: 0.00736
SB3 Clip Fraction: 0.07106
Policy Update Magnitude: 0.30075
Value Function Update Magnitude: 0.30263

Collected Steps per Second: 21,696.81776
Overall Steps per Second: 10,193.31321

Timestep Collection Time: 2.30633
Timestep Consumption Time: 2.60277
PPO Batch Consumption Time: 0.29552
Total Iteration Time: 4.90910

Cumulative Model Updates: 251,684
Cumulative Timesteps: 2,099,639,022

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 2099639022...
Checkpoint 2099639022 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 151,049.39781
Policy Entropy: 2.60576
Value Function Loss: 0.01439

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.07463
Policy Update Magnitude: 0.30321
Value Function Update Magnitude: 0.28151

Collected Steps per Second: 22,060.80106
Overall Steps per Second: 10,495.70525

Timestep Collection Time: 2.26664
Timestep Consumption Time: 2.49759
PPO Batch Consumption Time: 0.29160
Total Iteration Time: 4.76423

Cumulative Model Updates: 251,690
Cumulative Timesteps: 2,099,689,026

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91,301.27570
Policy Entropy: 2.60045
Value Function Loss: 0.01450

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.07090
Policy Update Magnitude: 0.30449
Value Function Update Magnitude: 0.23008

Collected Steps per Second: 21,912.44592
Overall Steps per Second: 10,468.53432

Timestep Collection Time: 2.28199
Timestep Consumption Time: 2.49461
PPO Batch Consumption Time: 0.29100
Total Iteration Time: 4.77660

Cumulative Model Updates: 251,696
Cumulative Timesteps: 2,099,739,030

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2099739030...
Checkpoint 2099739030 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 90,742.66692
Policy Entropy: 2.60089
Value Function Loss: 0.01461

Mean KL Divergence: 0.00702
SB3 Clip Fraction: 0.06426
Policy Update Magnitude: 0.29886
Value Function Update Magnitude: 0.18695

Collected Steps per Second: 21,796.48497
Overall Steps per Second: 10,482.47412

Timestep Collection Time: 2.29560
Timestep Consumption Time: 2.47770
PPO Batch Consumption Time: 0.28626
Total Iteration Time: 4.77330

Cumulative Model Updates: 251,702
Cumulative Timesteps: 2,099,789,066

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95,341.95941
Policy Entropy: 2.61274
Value Function Loss: 0.01565

Mean KL Divergence: 0.00585
SB3 Clip Fraction: 0.05723
Policy Update Magnitude: 0.30044
Value Function Update Magnitude: 0.17564

Collected Steps per Second: 22,064.16463
Overall Steps per Second: 10,466.38160

Timestep Collection Time: 2.26820
Timestep Consumption Time: 2.51339
PPO Batch Consumption Time: 0.29130
Total Iteration Time: 4.78160

Cumulative Model Updates: 251,708
Cumulative Timesteps: 2,099,839,112

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 2099839112...
Checkpoint 2099839112 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 95,341.95941
Policy Entropy: 2.62286
Value Function Loss: 0.01235

Mean KL Divergence: 0.00602
SB3 Clip Fraction: 0.05636
Policy Update Magnitude: 0.29348
Value Function Update Magnitude: 0.21553

Collected Steps per Second: 22,104.08202
Overall Steps per Second: 10,634.73491

Timestep Collection Time: 2.26311
Timestep Consumption Time: 2.44072
PPO Batch Consumption Time: 0.27946
Total Iteration Time: 4.70383

Cumulative Model Updates: 251,714
Cumulative Timesteps: 2,099,889,136

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 96,199.75769
Policy Entropy: 2.61435
Value Function Loss: 0.01204

Mean KL Divergence: 0.00539
SB3 Clip Fraction: 0.05065
Policy Update Magnitude: 0.28556
Value Function Update Magnitude: 0.24013

Collected Steps per Second: 21,430.33679
Overall Steps per Second: 10,530.24968

Timestep Collection Time: 2.33379
Timestep Consumption Time: 2.41576
PPO Batch Consumption Time: 0.27693
Total Iteration Time: 4.74955

Cumulative Model Updates: 251,720
Cumulative Timesteps: 2,099,939,150

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2099939150...
Checkpoint 2099939150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 106,632.05824
Policy Entropy: 2.59696
Value Function Loss: 0.01276

Mean KL Divergence: 0.00580
SB3 Clip Fraction: 0.05676
Policy Update Magnitude: 0.29519
Value Function Update Magnitude: 0.22441

Collected Steps per Second: 21,392.33311
Overall Steps per Second: 10,524.05395

Timestep Collection Time: 2.33803
Timestep Consumption Time: 2.41451
PPO Batch Consumption Time: 0.27813
Total Iteration Time: 4.75254

Cumulative Model Updates: 251,726
Cumulative Timesteps: 2,099,989,166

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 101,056.58692
Policy Entropy: 2.59673
Value Function Loss: 0.01535

Mean KL Divergence: 0.00736
SB3 Clip Fraction: 0.06925
Policy Update Magnitude: 0.29992
Value Function Update Magnitude: 0.19909

Collected Steps per Second: 21,482.76975
Overall Steps per Second: 10,478.67912

Timestep Collection Time: 2.32866
Timestep Consumption Time: 2.44542
PPO Batch Consumption Time: 0.27842
Total Iteration Time: 4.77408

Cumulative Model Updates: 251,732
Cumulative Timesteps: 2,100,039,192

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2100039192...
Checkpoint 2100039192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 137,405.61473
Policy Entropy: 2.61965
Value Function Loss: 0.01611

Mean KL Divergence: 0.00708
SB3 Clip Fraction: 0.06670
Policy Update Magnitude: 0.30379
Value Function Update Magnitude: 0.22150

Collected Steps per Second: 21,697.40466
Overall Steps per Second: 10,391.06606

Timestep Collection Time: 2.30553
Timestep Consumption Time: 2.50861
PPO Batch Consumption Time: 0.29062
Total Iteration Time: 4.81414

Cumulative Model Updates: 251,738
Cumulative Timesteps: 2,100,089,216

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 137,405.61473
Policy Entropy: 2.61853
Value Function Loss: 0.01455

Mean KL Divergence: 0.00696
SB3 Clip Fraction: 0.06930
Policy Update Magnitude: 0.29555
Value Function Update Magnitude: 0.23056

Collected Steps per Second: 22,304.49253
Overall Steps per Second: 10,497.38167

Timestep Collection Time: 2.24242
Timestep Consumption Time: 2.52220
PPO Batch Consumption Time: 0.28848
Total Iteration Time: 4.76462

Cumulative Model Updates: 251,744
Cumulative Timesteps: 2,100,139,232

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2100139232...
Checkpoint 2100139232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 131,923.51955
Policy Entropy: 2.57831
Value Function Loss: 0.01472

Mean KL Divergence: 0.00783
SB3 Clip Fraction: 0.07311
Policy Update Magnitude: 0.30575
Value Function Update Magnitude: 0.29593

Collected Steps per Second: 22,387.88604
Overall Steps per Second: 10,588.54385

Timestep Collection Time: 2.23451
Timestep Consumption Time: 2.49003
PPO Batch Consumption Time: 0.29124
Total Iteration Time: 4.72454

Cumulative Model Updates: 251,750
Cumulative Timesteps: 2,100,189,258

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 114,749.75829
Policy Entropy: 2.57327
Value Function Loss: 0.01388

Mean KL Divergence: 0.00734
SB3 Clip Fraction: 0.07066
Policy Update Magnitude: 0.31209
Value Function Update Magnitude: 0.33292

Collected Steps per Second: 22,477.27704
Overall Steps per Second: 10,706.04484

Timestep Collection Time: 2.22545
Timestep Consumption Time: 2.44687
PPO Batch Consumption Time: 0.27955
Total Iteration Time: 4.67231

Cumulative Model Updates: 251,756
Cumulative Timesteps: 2,100,239,280

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2100239280...
Checkpoint 2100239280 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 85,097.71386
Policy Entropy: 2.59562
Value Function Loss: 0.01369

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.07246
Policy Update Magnitude: 0.30411
Value Function Update Magnitude: 0.33731

Collected Steps per Second: 21,919.66638
Overall Steps per Second: 10,600.31951

Timestep Collection Time: 2.28124
Timestep Consumption Time: 2.43598
PPO Batch Consumption Time: 0.27953
Total Iteration Time: 4.71722

Cumulative Model Updates: 251,762
Cumulative Timesteps: 2,100,289,284

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85,097.71386
Policy Entropy: 2.61820
Value Function Loss: 0.01145

Mean KL Divergence: 0.00727
SB3 Clip Fraction: 0.06805
Policy Update Magnitude: 0.28781
Value Function Update Magnitude: 0.31854

Collected Steps per Second: 22,149.58685
Overall Steps per Second: 10,555.47813

Timestep Collection Time: 2.25828
Timestep Consumption Time: 2.48049
PPO Batch Consumption Time: 0.28711
Total Iteration Time: 4.73877

Cumulative Model Updates: 251,768
Cumulative Timesteps: 2,100,339,304

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2100339304...
Checkpoint 2100339304 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 79,078.41367
Policy Entropy: 2.59939
Value Function Loss: 0.01106

Mean KL Divergence: 0.00695
SB3 Clip Fraction: 0.06561
Policy Update Magnitude: 0.27876
Value Function Update Magnitude: 0.28869

Collected Steps per Second: 21,739.32324
Overall Steps per Second: 10,562.85322

Timestep Collection Time: 2.30016
Timestep Consumption Time: 2.43378
PPO Batch Consumption Time: 0.27815
Total Iteration Time: 4.73395

Cumulative Model Updates: 251,774
Cumulative Timesteps: 2,100,389,308

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75,523.15467
Policy Entropy: 2.58667
Value Function Loss: 0.01170

Mean KL Divergence: 0.00606
SB3 Clip Fraction: 0.05808
Policy Update Magnitude: 0.28406
Value Function Update Magnitude: 0.27288

Collected Steps per Second: 21,776.59692
Overall Steps per Second: 10,584.06057

Timestep Collection Time: 2.29788
Timestep Consumption Time: 2.42998
PPO Batch Consumption Time: 0.27729
Total Iteration Time: 4.72786

Cumulative Model Updates: 251,780
Cumulative Timesteps: 2,100,439,348

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 2100439348...
Checkpoint 2100439348 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 82,023.00372
Policy Entropy: 2.58752
Value Function Loss: 0.01274

Mean KL Divergence: 0.00682
SB3 Clip Fraction: 0.06481
Policy Update Magnitude: 0.29911
Value Function Update Magnitude: 0.30529

Collected Steps per Second: 21,458.96327
Overall Steps per Second: 10,518.76274

Timestep Collection Time: 2.33115
Timestep Consumption Time: 2.42455
PPO Batch Consumption Time: 0.27873
Total Iteration Time: 4.75569

Cumulative Model Updates: 251,786
Cumulative Timesteps: 2,100,489,372

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70,822.70239
Policy Entropy: 2.59084
Value Function Loss: 0.01313

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.07718
Policy Update Magnitude: 0.30373
Value Function Update Magnitude: 0.30842

Collected Steps per Second: 21,530.94127
Overall Steps per Second: 10,491.68757

Timestep Collection Time: 2.32308
Timestep Consumption Time: 2.44432
PPO Batch Consumption Time: 0.28031
Total Iteration Time: 4.76739

Cumulative Model Updates: 251,792
Cumulative Timesteps: 2,100,539,390

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2100539390...
Checkpoint 2100539390 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 53,930.29515
Policy Entropy: 2.60873
Value Function Loss: 0.01346

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.07500
Policy Update Magnitude: 0.30025
Value Function Update Magnitude: 0.32011

Collected Steps per Second: 21,628.68590
Overall Steps per Second: 10,383.77045

Timestep Collection Time: 2.31174
Timestep Consumption Time: 2.50346
PPO Batch Consumption Time: 0.28974
Total Iteration Time: 4.81521

Cumulative Model Updates: 251,798
Cumulative Timesteps: 2,100,589,390

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,716.83859
Policy Entropy: 2.61071
Value Function Loss: 0.01346

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.07016
Policy Update Magnitude: 0.30100
Value Function Update Magnitude: 0.32272

Collected Steps per Second: 22,360.19745
Overall Steps per Second: 10,660.22761

Timestep Collection Time: 2.23630
Timestep Consumption Time: 2.45441
PPO Batch Consumption Time: 0.27892
Total Iteration Time: 4.69071

Cumulative Model Updates: 251,804
Cumulative Timesteps: 2,100,639,394

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2100639394...
Checkpoint 2100639394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,315.86609
Policy Entropy: 2.62272
Value Function Loss: 0.01419

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.07563
Policy Update Magnitude: 0.29527
Value Function Update Magnitude: 0.32844

Collected Steps per Second: 21,906.07075
Overall Steps per Second: 10,632.66074

Timestep Collection Time: 2.28366
Timestep Consumption Time: 2.42128
PPO Batch Consumption Time: 0.27928
Total Iteration Time: 4.70494

Cumulative Model Updates: 251,810
Cumulative Timesteps: 2,100,689,420

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,742.76564
Policy Entropy: 2.59058
Value Function Loss: 0.01375

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.07993
Policy Update Magnitude: 0.29437
Value Function Update Magnitude: 0.33573

Collected Steps per Second: 21,615.98733
Overall Steps per Second: 10,543.71361

Timestep Collection Time: 2.31440
Timestep Consumption Time: 2.43042
PPO Batch Consumption Time: 0.27699
Total Iteration Time: 4.74482

Cumulative Model Updates: 251,816
Cumulative Timesteps: 2,100,739,448

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2100739448...
Checkpoint 2100739448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 52,063.38157
Policy Entropy: 2.57643
Value Function Loss: 0.01292

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.08019
Policy Update Magnitude: 0.30175
Value Function Update Magnitude: 0.32978

Collected Steps per Second: 21,922.50757
Overall Steps per Second: 10,659.76198

Timestep Collection Time: 2.28140
Timestep Consumption Time: 2.41045
PPO Batch Consumption Time: 0.27685
Total Iteration Time: 4.69185

Cumulative Model Updates: 251,822
Cumulative Timesteps: 2,100,789,462

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56,233.73543
Policy Entropy: 2.53941
Value Function Loss: 0.01290

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.07743
Policy Update Magnitude: 0.30732
Value Function Update Magnitude: 0.29549

Collected Steps per Second: 22,074.91095
Overall Steps per Second: 10,587.45690

Timestep Collection Time: 2.26501
Timestep Consumption Time: 2.45755
PPO Batch Consumption Time: 0.28914
Total Iteration Time: 4.72257

Cumulative Model Updates: 251,828
Cumulative Timesteps: 2,100,839,462

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2100839462...
Checkpoint 2100839462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 50,234.01425
Policy Entropy: 2.53130
Value Function Loss: 0.01345

Mean KL Divergence: 0.00717
SB3 Clip Fraction: 0.06267
Policy Update Magnitude: 0.30704
Value Function Update Magnitude: 0.26543

Collected Steps per Second: 21,513.75262
Overall Steps per Second: 10,559.17554

Timestep Collection Time: 2.32428
Timestep Consumption Time: 2.41132
PPO Batch Consumption Time: 0.29165
Total Iteration Time: 4.73560

Cumulative Model Updates: 251,834
Cumulative Timesteps: 2,100,889,466

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45,558.73970
Policy Entropy: 2.55256
Value Function Loss: 0.01332

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.07412
Policy Update Magnitude: 0.30935
Value Function Update Magnitude: 0.27010

Collected Steps per Second: 21,104.65169
Overall Steps per Second: 10,458.48955

Timestep Collection Time: 2.37066
Timestep Consumption Time: 2.41320
PPO Batch Consumption Time: 0.29175
Total Iteration Time: 4.78386

Cumulative Model Updates: 251,840
Cumulative Timesteps: 2,100,939,498

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2100939498...
Checkpoint 2100939498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 60,398.22137
Policy Entropy: 2.56015
Value Function Loss: 0.01379

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.07643
Policy Update Magnitude: 0.30957
Value Function Update Magnitude: 0.29559

Collected Steps per Second: 20,632.07100
Overall Steps per Second: 10,467.39605

Timestep Collection Time: 2.42370
Timestep Consumption Time: 2.35361
PPO Batch Consumption Time: 0.27850
Total Iteration Time: 4.77731

Cumulative Model Updates: 251,846
Cumulative Timesteps: 2,100,989,504

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 104,405.13569
Policy Entropy: 2.57065
Value Function Loss: 0.01494

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.08684
Policy Update Magnitude: 0.31611
Value Function Update Magnitude: 0.33296

Collected Steps per Second: 20,852.69077
Overall Steps per Second: 10,207.36612

Timestep Collection Time: 2.39959
Timestep Consumption Time: 2.50255
PPO Batch Consumption Time: 0.29323
Total Iteration Time: 4.90215

Cumulative Model Updates: 251,852
Cumulative Timesteps: 2,101,039,542

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 2101039542...
Checkpoint 2101039542 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89,543.15456
Policy Entropy: 2.56455
Value Function Loss: 0.01367

Mean KL Divergence: 0.01380
SB3 Clip Fraction: 0.11138
Policy Update Magnitude: 0.31578
Value Function Update Magnitude: 0.33802

Collected Steps per Second: 21,388.97746
Overall Steps per Second: 10,496.01377

Timestep Collection Time: 2.33831
Timestep Consumption Time: 2.42674
PPO Batch Consumption Time: 0.27931
Total Iteration Time: 4.76505

Cumulative Model Updates: 251,858
Cumulative Timesteps: 2,101,089,556

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76,552.30245
Policy Entropy: 2.57093
Value Function Loss: 0.01416

Mean KL Divergence: 0.01436
SB3 Clip Fraction: 0.11069
Policy Update Magnitude: 0.31514
Value Function Update Magnitude: 0.29324

Collected Steps per Second: 21,811.91180
Overall Steps per Second: 10,461.23868

Timestep Collection Time: 2.29398
Timestep Consumption Time: 2.48901
PPO Batch Consumption Time: 0.29083
Total Iteration Time: 4.78299

Cumulative Model Updates: 251,864
Cumulative Timesteps: 2,101,139,592

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 2101139592...
Checkpoint 2101139592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 71,572.09946
Policy Entropy: 2.57160
Value Function Loss: 0.01384

Mean KL Divergence: 0.01184
SB3 Clip Fraction: 0.09991
Policy Update Magnitude: 0.31372
Value Function Update Magnitude: 0.28302

Collected Steps per Second: 21,715.55205
Overall Steps per Second: 10,377.36056

Timestep Collection Time: 2.30434
Timestep Consumption Time: 2.51770
PPO Batch Consumption Time: 0.29091
Total Iteration Time: 4.82204

Cumulative Model Updates: 251,870
Cumulative Timesteps: 2,101,189,632

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 72,396.83255
Policy Entropy: 2.56955
Value Function Loss: 0.01375

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.08973
Policy Update Magnitude: 0.30835
Value Function Update Magnitude: 0.29858

Collected Steps per Second: 22,269.29473
Overall Steps per Second: 10,662.11286

Timestep Collection Time: 2.24632
Timestep Consumption Time: 2.44543
PPO Batch Consumption Time: 0.27863
Total Iteration Time: 4.69175

Cumulative Model Updates: 251,876
Cumulative Timesteps: 2,101,239,656

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2101239656...
Checkpoint 2101239656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 92,444.76844
Policy Entropy: 2.56345
Value Function Loss: 0.01532

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.07856
Policy Update Magnitude: 0.31381
Value Function Update Magnitude: 0.33200

Collected Steps per Second: 21,470.64613
Overall Steps per Second: 10,356.88484

Timestep Collection Time: 2.33016
Timestep Consumption Time: 2.50045
PPO Batch Consumption Time: 0.29286
Total Iteration Time: 4.83060

Cumulative Model Updates: 251,882
Cumulative Timesteps: 2,101,289,686

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 69,016.64788
Policy Entropy: 2.56555
Value Function Loss: 0.01502

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.07348
Policy Update Magnitude: 0.33446
Value Function Update Magnitude: 0.36354

Collected Steps per Second: 22,369.11799
Overall Steps per Second: 10,770.88564

Timestep Collection Time: 2.23648
Timestep Consumption Time: 2.40827
PPO Batch Consumption Time: 0.27806
Total Iteration Time: 4.64474

Cumulative Model Updates: 251,888
Cumulative Timesteps: 2,101,339,714

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2101339714...
Checkpoint 2101339714 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 69,375.98687
Policy Entropy: 2.58008
Value Function Loss: 0.01592

Mean KL Divergence: 0.01222
SB3 Clip Fraction: 0.07316
Policy Update Magnitude: 0.33045
Value Function Update Magnitude: 0.33430

Collected Steps per Second: 22,040.09063
Overall Steps per Second: 10,652.77225

Timestep Collection Time: 2.26877
Timestep Consumption Time: 2.42521
PPO Batch Consumption Time: 0.27912
Total Iteration Time: 4.69399

Cumulative Model Updates: 251,894
Cumulative Timesteps: 2,101,389,718

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 69,375.98687
Policy Entropy: 2.60040
Value Function Loss: 0.01443

Mean KL Divergence: 0.01326
SB3 Clip Fraction: 0.06927
Policy Update Magnitude: 0.31235
Value Function Update Magnitude: 0.25492

Collected Steps per Second: 22,240.30773
Overall Steps per Second: 10,528.82464

Timestep Collection Time: 2.24907
Timestep Consumption Time: 2.50170
PPO Batch Consumption Time: 0.29392
Total Iteration Time: 4.75077

Cumulative Model Updates: 251,900
Cumulative Timesteps: 2,101,439,738

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2101439738...
Checkpoint 2101439738 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 52,007.86686
Policy Entropy: 2.59261
Value Function Loss: 0.01468

Mean KL Divergence: 0.00693
SB3 Clip Fraction: 0.05994
Policy Update Magnitude: 0.30386
Value Function Update Magnitude: 0.20301

Collected Steps per Second: 21,733.38279
Overall Steps per Second: 10,574.85169

Timestep Collection Time: 2.30226
Timestep Consumption Time: 2.42934
PPO Batch Consumption Time: 0.27860
Total Iteration Time: 4.73160

Cumulative Model Updates: 251,906
Cumulative Timesteps: 2,101,489,774

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,575.26131
Policy Entropy: 2.60219
Value Function Loss: 0.01308

Mean KL Divergence: 0.00707
SB3 Clip Fraction: 0.06147
Policy Update Magnitude: 0.30723
Value Function Update Magnitude: 0.23676

Collected Steps per Second: 20,502.56446
Overall Steps per Second: 10,072.84551

Timestep Collection Time: 2.44009
Timestep Consumption Time: 2.52654
PPO Batch Consumption Time: 0.29385
Total Iteration Time: 4.96662

Cumulative Model Updates: 251,912
Cumulative Timesteps: 2,101,539,802

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2101539802...
Checkpoint 2101539802 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,088.19425
Policy Entropy: 2.59264
Value Function Loss: 0.01558

Mean KL Divergence: 0.00730
SB3 Clip Fraction: 0.06219
Policy Update Magnitude: 0.31169
Value Function Update Magnitude: 0.26390

Collected Steps per Second: 20,589.86287
Overall Steps per Second: 10,290.68428

Timestep Collection Time: 2.43071
Timestep Consumption Time: 2.43272
PPO Batch Consumption Time: 0.29334
Total Iteration Time: 4.86343

Cumulative Model Updates: 251,918
Cumulative Timesteps: 2,101,589,850

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48,597.63611
Policy Entropy: 2.62202
Value Function Loss: 0.01782

Mean KL Divergence: 0.00684
SB3 Clip Fraction: 0.05976
Policy Update Magnitude: 0.32069
Value Function Update Magnitude: 0.23860

Collected Steps per Second: 21,861.38743
Overall Steps per Second: 10,746.03478

Timestep Collection Time: 2.28869
Timestep Consumption Time: 2.36735
PPO Batch Consumption Time: 0.27849
Total Iteration Time: 4.65604

Cumulative Model Updates: 251,924
Cumulative Timesteps: 2,101,639,884

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 2101639884...
Checkpoint 2101639884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84,706.81431
Policy Entropy: 2.61247
Value Function Loss: 0.01971

Mean KL Divergence: 0.00741
SB3 Clip Fraction: 0.06775
Policy Update Magnitude: 0.31462
Value Function Update Magnitude: 0.23073

Collected Steps per Second: 21,220.08892
Overall Steps per Second: 10,594.56768

Timestep Collection Time: 2.35682
Timestep Consumption Time: 2.36371
PPO Batch Consumption Time: 0.27893
Total Iteration Time: 4.72053

Cumulative Model Updates: 251,930
Cumulative Timesteps: 2,101,689,896

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 147,304.93480
Policy Entropy: 2.64195
Value Function Loss: 0.01603

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.07435
Policy Update Magnitude: 0.31341
Value Function Update Magnitude: 0.29687

Collected Steps per Second: 21,689.86271
Overall Steps per Second: 10,638.69964

Timestep Collection Time: 2.30661
Timestep Consumption Time: 2.39603
PPO Batch Consumption Time: 0.27723
Total Iteration Time: 4.70264

Cumulative Model Updates: 251,936
Cumulative Timesteps: 2,101,739,926

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2101739926...
Checkpoint 2101739926 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 147,304.93480
Policy Entropy: 2.62427
Value Function Loss: 0.01395

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.07700
Policy Update Magnitude: 0.29230
Value Function Update Magnitude: 0.29200

Collected Steps per Second: 22,075.31053
Overall Steps per Second: 10,553.61122

Timestep Collection Time: 2.26506
Timestep Consumption Time: 2.47284
PPO Batch Consumption Time: 0.29153
Total Iteration Time: 4.73790

Cumulative Model Updates: 251,942
Cumulative Timesteps: 2,101,789,928

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 122,043.92652
Policy Entropy: 2.61364
Value Function Loss: 0.01162

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.07722
Policy Update Magnitude: 0.27711
Value Function Update Magnitude: 0.23614

Collected Steps per Second: 22,187.01909
Overall Steps per Second: 10,546.92712

Timestep Collection Time: 2.25447
Timestep Consumption Time: 2.48814
PPO Batch Consumption Time: 0.29246
Total Iteration Time: 4.74261

Cumulative Model Updates: 251,948
Cumulative Timesteps: 2,101,839,948

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2101839948...
Checkpoint 2101839948 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 103,352.32700
Policy Entropy: 2.57020
Value Function Loss: 0.01221

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.09292
Policy Update Magnitude: 0.28359
Value Function Update Magnitude: 0.24184

Collected Steps per Second: 22,001.93699
Overall Steps per Second: 10,561.62321

Timestep Collection Time: 2.27353
Timestep Consumption Time: 2.46268
PPO Batch Consumption Time: 0.28397
Total Iteration Time: 4.73620

Cumulative Model Updates: 251,954
Cumulative Timesteps: 2,101,889,970

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84,019.05843
Policy Entropy: 2.57130
Value Function Loss: 0.01209

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.08825
Policy Update Magnitude: 0.29086
Value Function Update Magnitude: 0.26245

Collected Steps per Second: 22,135.07455
Overall Steps per Second: 10,503.99490

Timestep Collection Time: 2.26112
Timestep Consumption Time: 2.50374
PPO Batch Consumption Time: 0.29393
Total Iteration Time: 4.76485

Cumulative Model Updates: 251,960
Cumulative Timesteps: 2,101,940,020

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 2101940020...
Checkpoint 2101940020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 77,477.63109
Policy Entropy: 2.57638
Value Function Loss: 0.01260

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.08819
Policy Update Magnitude: 0.28965
Value Function Update Magnitude: 0.27680

Collected Steps per Second: 21,372.79585
Overall Steps per Second: 10,351.70383

Timestep Collection Time: 2.34073
Timestep Consumption Time: 2.49210
PPO Batch Consumption Time: 0.29059
Total Iteration Time: 4.83283

Cumulative Model Updates: 251,966
Cumulative Timesteps: 2,101,990,048

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 103,088.04730
Policy Entropy: 2.60578
Value Function Loss: 0.01369

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.08147
Policy Update Magnitude: 0.29528
Value Function Update Magnitude: 0.27898

Collected Steps per Second: 21,585.36784
Overall Steps per Second: 10,382.66317

Timestep Collection Time: 2.31694
Timestep Consumption Time: 2.49994
PPO Batch Consumption Time: 0.29264
Total Iteration Time: 4.81688

Cumulative Model Updates: 251,972
Cumulative Timesteps: 2,102,040,060

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2102040060...
Checkpoint 2102040060 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 126,548.36964
Policy Entropy: 2.60428
Value Function Loss: 0.01545

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.07759
Policy Update Magnitude: 0.30186
Value Function Update Magnitude: 0.31398

Collected Steps per Second: 21,414.23517
Overall Steps per Second: 10,201.67241

Timestep Collection Time: 2.33574
Timestep Consumption Time: 2.56719
PPO Batch Consumption Time: 0.29267
Total Iteration Time: 4.90292

Cumulative Model Updates: 251,978
Cumulative Timesteps: 2,102,090,078

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 98,135.33860
Policy Entropy: 2.59660
Value Function Loss: 0.01627

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.07774
Policy Update Magnitude: 0.31531
Value Function Update Magnitude: 0.35242

Collected Steps per Second: 22,013.84088
Overall Steps per Second: 10,384.06078

Timestep Collection Time: 2.27230
Timestep Consumption Time: 2.54489
PPO Batch Consumption Time: 0.29236
Total Iteration Time: 4.81719

Cumulative Model Updates: 251,984
Cumulative Timesteps: 2,102,140,100

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2102140100...
Checkpoint 2102140100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 98,135.33860
Policy Entropy: 2.57965
Value Function Loss: 0.01440

Mean KL Divergence: 0.00728
SB3 Clip Fraction: 0.06678
Policy Update Magnitude: 0.31169
Value Function Update Magnitude: 0.35703

Collected Steps per Second: 22,033.37729
Overall Steps per Second: 10,624.60872

Timestep Collection Time: 2.26938
Timestep Consumption Time: 2.43687
PPO Batch Consumption Time: 0.27819
Total Iteration Time: 4.70624

Cumulative Model Updates: 251,990
Cumulative Timesteps: 2,102,190,102

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 72,782.86217
Policy Entropy: 2.58174
Value Function Loss: 0.01431

Mean KL Divergence: 0.00687
SB3 Clip Fraction: 0.06193
Policy Update Magnitude: 0.30597
Value Function Update Magnitude: 0.34267

Collected Steps per Second: 22,185.94319
Overall Steps per Second: 10,512.88857

Timestep Collection Time: 2.25395
Timestep Consumption Time: 2.50269
PPO Batch Consumption Time: 0.29276
Total Iteration Time: 4.75664

Cumulative Model Updates: 251,996
Cumulative Timesteps: 2,102,240,108

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2102240108...
Checkpoint 2102240108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 72,782.86217
Policy Entropy: 2.59584
Value Function Loss: 0.01240

Mean KL Divergence: 0.00684
SB3 Clip Fraction: 0.06416
Policy Update Magnitude: 0.30501
Value Function Update Magnitude: 0.31273

Collected Steps per Second: 22,114.28538
Overall Steps per Second: 10,542.77102

Timestep Collection Time: 2.26180
Timestep Consumption Time: 2.48250
PPO Batch Consumption Time: 0.28973
Total Iteration Time: 4.74429

Cumulative Model Updates: 252,002
Cumulative Timesteps: 2,102,290,126

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81,910.60036
Policy Entropy: 2.61664
Value Function Loss: 0.01268

Mean KL Divergence: 0.00635
SB3 Clip Fraction: 0.06070
Policy Update Magnitude: 0.30040
Value Function Update Magnitude: 0.29057

Collected Steps per Second: 21,631.00680
Overall Steps per Second: 10,540.39564

Timestep Collection Time: 2.31279
Timestep Consumption Time: 2.43352
PPO Batch Consumption Time: 0.29348
Total Iteration Time: 4.74631

Cumulative Model Updates: 252,008
Cumulative Timesteps: 2,102,340,154

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2102340154...
Checkpoint 2102340154 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 62,957.60830
Policy Entropy: 2.61974
Value Function Loss: 0.01340

Mean KL Divergence: 0.00603
SB3 Clip Fraction: 0.05590
Policy Update Magnitude: 0.29902
Value Function Update Magnitude: 0.26349

Collected Steps per Second: 21,079.08315
Overall Steps per Second: 10,613.28523

Timestep Collection Time: 2.37240
Timestep Consumption Time: 2.33943
PPO Batch Consumption Time: 0.27711
Total Iteration Time: 4.71183

Cumulative Model Updates: 252,014
Cumulative Timesteps: 2,102,390,162

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61,779.70706
Policy Entropy: 2.62031
Value Function Loss: 0.01261

Mean KL Divergence: 0.00626
SB3 Clip Fraction: 0.05918
Policy Update Magnitude: 0.29840
Value Function Update Magnitude: 0.28601

Collected Steps per Second: 21,497.17672
Overall Steps per Second: 10,546.07640

Timestep Collection Time: 2.32793
Timestep Consumption Time: 2.41734
PPO Batch Consumption Time: 0.29034
Total Iteration Time: 4.74527

Cumulative Model Updates: 252,020
Cumulative Timesteps: 2,102,440,206

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 2102440206...
Checkpoint 2102440206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 61,779.70706
Policy Entropy: 2.59485
Value Function Loss: 0.01182

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.07261
Policy Update Magnitude: 0.28925
Value Function Update Magnitude: 0.27400

Collected Steps per Second: 20,714.66978
Overall Steps per Second: 10,414.32085

Timestep Collection Time: 2.41442
Timestep Consumption Time: 2.38800
PPO Batch Consumption Time: 0.27838
Total Iteration Time: 4.80243

Cumulative Model Updates: 252,026
Cumulative Timesteps: 2,102,490,220

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70,310.18332
Policy Entropy: 2.59679
Value Function Loss: 0.01118

Mean KL Divergence: 0.00729
SB3 Clip Fraction: 0.07126
Policy Update Magnitude: 0.28458
Value Function Update Magnitude: 0.26898

Collected Steps per Second: 21,589.68770
Overall Steps per Second: 10,607.47222

Timestep Collection Time: 2.31722
Timestep Consumption Time: 2.39908
PPO Batch Consumption Time: 0.27663
Total Iteration Time: 4.71630

Cumulative Model Updates: 252,032
Cumulative Timesteps: 2,102,540,248

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2102540248...
Checkpoint 2102540248 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 67,655.98017
Policy Entropy: 2.60125
Value Function Loss: 0.01308

Mean KL Divergence: 0.00731
SB3 Clip Fraction: 0.07016
Policy Update Magnitude: 0.28822
Value Function Update Magnitude: 0.26073

Collected Steps per Second: 21,354.87524
Overall Steps per Second: 10,519.62443

Timestep Collection Time: 2.34185
Timestep Consumption Time: 2.41212
PPO Batch Consumption Time: 0.27845
Total Iteration Time: 4.75397

Cumulative Model Updates: 252,038
Cumulative Timesteps: 2,102,590,258

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79,280.07005
Policy Entropy: 2.61575
Value Function Loss: 0.01317

Mean KL Divergence: 0.00733
SB3 Clip Fraction: 0.07080
Policy Update Magnitude: 0.28702
Value Function Update Magnitude: 0.25296

Collected Steps per Second: 21,977.61548
Overall Steps per Second: 10,494.25341

Timestep Collection Time: 2.27623
Timestep Consumption Time: 2.49076
PPO Batch Consumption Time: 0.28827
Total Iteration Time: 4.76699

Cumulative Model Updates: 252,044
Cumulative Timesteps: 2,102,640,284

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2102640284...
Checkpoint 2102640284 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 59,405.33383
Policy Entropy: 2.62980
Value Function Loss: 0.01511

Mean KL Divergence: 0.00653
SB3 Clip Fraction: 0.06443
Policy Update Magnitude: 0.28918
Value Function Update Magnitude: 0.27403

Collected Steps per Second: 21,653.73073
Overall Steps per Second: 10,350.24203

Timestep Collection Time: 2.30963
Timestep Consumption Time: 2.52234
PPO Batch Consumption Time: 0.29095
Total Iteration Time: 4.83196

Cumulative Model Updates: 252,050
Cumulative Timesteps: 2,102,690,296

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 64,266.84867
Policy Entropy: 2.63123
Value Function Loss: 0.01329

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.07551
Policy Update Magnitude: 0.28775
Value Function Update Magnitude: 0.26308

Collected Steps per Second: 22,363.60335
Overall Steps per Second: 10,675.01330

Timestep Collection Time: 2.23676
Timestep Consumption Time: 2.44914
PPO Batch Consumption Time: 0.27929
Total Iteration Time: 4.68590

Cumulative Model Updates: 252,056
Cumulative Timesteps: 2,102,740,318

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2102740318...
Checkpoint 2102740318 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 81,404.75864
Policy Entropy: 2.64599
Value Function Loss: 0.01421

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.07747
Policy Update Magnitude: 0.29164
Value Function Update Magnitude: 0.26730

Collected Steps per Second: 21,606.50095
Overall Steps per Second: 10,354.53590

Timestep Collection Time: 2.31421
Timestep Consumption Time: 2.51478
PPO Batch Consumption Time: 0.29247
Total Iteration Time: 4.82899

Cumulative Model Updates: 252,062
Cumulative Timesteps: 2,102,790,320

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95,709.16915
Policy Entropy: 2.62059
Value Function Loss: 0.01727

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.07287
Policy Update Magnitude: 0.32308
Value Function Update Magnitude: 0.29506

Collected Steps per Second: 22,244.20542
Overall Steps per Second: 10,562.97873

Timestep Collection Time: 2.24939
Timestep Consumption Time: 2.48753
PPO Batch Consumption Time: 0.28952
Total Iteration Time: 4.73692

Cumulative Model Updates: 252,068
Cumulative Timesteps: 2,102,840,356

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 2102840356...
Checkpoint 2102840356 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,888.85289
Policy Entropy: 2.61256
Value Function Loss: 0.01941

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.08149
Policy Update Magnitude: 0.33649
Value Function Update Magnitude: 0.36894

Collected Steps per Second: 22,091.91618
Overall Steps per Second: 10,484.69040

Timestep Collection Time: 2.26472
Timestep Consumption Time: 2.50719
PPO Batch Consumption Time: 0.29330
Total Iteration Time: 4.77191

Cumulative Model Updates: 252,074
Cumulative Timesteps: 2,102,890,388

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53,605.18147
Policy Entropy: 2.59230
Value Function Loss: 0.01825

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.08132
Policy Update Magnitude: 0.33084
Value Function Update Magnitude: 0.40660

Collected Steps per Second: 22,068.64013
Overall Steps per Second: 10,463.97534

Timestep Collection Time: 2.26702
Timestep Consumption Time: 2.51415
PPO Batch Consumption Time: 0.29321
Total Iteration Time: 4.78117

Cumulative Model Updates: 252,080
Cumulative Timesteps: 2,102,940,418

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2102940418...
Checkpoint 2102940418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 70,939.88038
Policy Entropy: 2.60430
Value Function Loss: 0.01538

Mean KL Divergence: 0.00698
SB3 Clip Fraction: 0.06476
Policy Update Magnitude: 0.31994
Value Function Update Magnitude: 0.37549

Collected Steps per Second: 21,791.44241
Overall Steps per Second: 10,587.51125

Timestep Collection Time: 2.29659
Timestep Consumption Time: 2.43030
PPO Batch Consumption Time: 0.27938
Total Iteration Time: 4.72689

Cumulative Model Updates: 252,086
Cumulative Timesteps: 2,102,990,464

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95,845.22932
Policy Entropy: 2.60506
Value Function Loss: 0.01403

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.07470
Policy Update Magnitude: 0.30813
Value Function Update Magnitude: 0.34084

Collected Steps per Second: 21,994.37351
Overall Steps per Second: 10,474.51690

Timestep Collection Time: 2.27367
Timestep Consumption Time: 2.50058
PPO Batch Consumption Time: 0.29052
Total Iteration Time: 4.77425

Cumulative Model Updates: 252,092
Cumulative Timesteps: 2,103,040,472

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2103040472...
Checkpoint 2103040472 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 121,994.97243
Policy Entropy: 2.58679
Value Function Loss: 0.01484

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.07962
Policy Update Magnitude: 0.31161
Value Function Update Magnitude: 0.30968

Collected Steps per Second: 21,494.47140
Overall Steps per Second: 10,553.89347

Timestep Collection Time: 2.32646
Timestep Consumption Time: 2.41170
PPO Batch Consumption Time: 0.27829
Total Iteration Time: 4.73816

Cumulative Model Updates: 252,098
Cumulative Timesteps: 2,103,090,478

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76,323.70358
Policy Entropy: 2.58824
Value Function Loss: 0.01706

Mean KL Divergence: 0.01074
SB3 Clip Fraction: 0.09422
Policy Update Magnitude: 0.31458
Value Function Update Magnitude: 0.33729

Collected Steps per Second: 21,683.65136
Overall Steps per Second: 10,540.86558

Timestep Collection Time: 2.30718
Timestep Consumption Time: 2.43892
PPO Batch Consumption Time: 0.27873
Total Iteration Time: 4.74610

Cumulative Model Updates: 252,104
Cumulative Timesteps: 2,103,140,506

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2103140506...
Checkpoint 2103140506 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 63,109.68679
Policy Entropy: 2.59383
Value Function Loss: 0.01627

Mean KL Divergence: 0.01496
SB3 Clip Fraction: 0.11757
Policy Update Magnitude: 0.30194
Value Function Update Magnitude: 0.33174

Collected Steps per Second: 21,732.26024
Overall Steps per Second: 10,331.25668

Timestep Collection Time: 2.30137
Timestep Consumption Time: 2.53967
PPO Batch Consumption Time: 0.29230
Total Iteration Time: 4.84104

Cumulative Model Updates: 252,110
Cumulative Timesteps: 2,103,190,520

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63,109.68679
Policy Entropy: 2.61051
Value Function Loss: 0.01494

Mean KL Divergence: 0.01283
SB3 Clip Fraction: 0.10875
Policy Update Magnitude: 0.29829
Value Function Update Magnitude: 0.28229

Collected Steps per Second: 21,601.43088
Overall Steps per Second: 10,671.46181

Timestep Collection Time: 2.31522
Timestep Consumption Time: 2.37130
PPO Batch Consumption Time: 0.27918
Total Iteration Time: 4.68652

Cumulative Model Updates: 252,116
Cumulative Timesteps: 2,103,240,532

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2103240532...
Checkpoint 2103240532 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 59,862.50832
Policy Entropy: 2.63456
Value Function Loss: 0.01213

Mean KL Divergence: 0.01157
SB3 Clip Fraction: 0.10546
Policy Update Magnitude: 0.29173
Value Function Update Magnitude: 0.25723

Collected Steps per Second: 21,343.87025
Overall Steps per Second: 10,656.09949

Timestep Collection Time: 2.34381
Timestep Consumption Time: 2.35078
PPO Batch Consumption Time: 0.27941
Total Iteration Time: 4.69459

Cumulative Model Updates: 252,122
Cumulative Timesteps: 2,103,290,558

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59,959.48502
Policy Entropy: 2.64024
Value Function Loss: 0.01245

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.08649
Policy Update Magnitude: 0.29141
Value Function Update Magnitude: 0.27390

Collected Steps per Second: 21,501.79536
Overall Steps per Second: 10,575.65638

Timestep Collection Time: 2.32650
Timestep Consumption Time: 2.40360
PPO Batch Consumption Time: 0.27762
Total Iteration Time: 4.73011

Cumulative Model Updates: 252,128
Cumulative Timesteps: 2,103,340,582

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2103340582...
Checkpoint 2103340582 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 57,267.44770
Policy Entropy: 2.63104
Value Function Loss: 0.01292

Mean KL Divergence: 0.00661
SB3 Clip Fraction: 0.06353
Policy Update Magnitude: 0.28344
Value Function Update Magnitude: 0.30668

Collected Steps per Second: 22,000.48181
Overall Steps per Second: 10,603.51294

Timestep Collection Time: 2.27268
Timestep Consumption Time: 2.44274
PPO Batch Consumption Time: 0.28608
Total Iteration Time: 4.71542

Cumulative Model Updates: 252,134
Cumulative Timesteps: 2,103,390,582

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 157,650.26124
Policy Entropy: 2.61400
Value Function Loss: 0.01356

Mean KL Divergence: 0.00621
SB3 Clip Fraction: 0.05664
Policy Update Magnitude: 0.29270
Value Function Update Magnitude: 0.33063

Collected Steps per Second: 21,301.54901
Overall Steps per Second: 10,432.18967

Timestep Collection Time: 2.34762
Timestep Consumption Time: 2.44600
PPO Batch Consumption Time: 0.28546
Total Iteration Time: 4.79362

Cumulative Model Updates: 252,140
Cumulative Timesteps: 2,103,440,590

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2103440590...
Checkpoint 2103440590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 96,078.19353
Policy Entropy: 2.59670
Value Function Loss: 0.01549

Mean KL Divergence: 0.00637
SB3 Clip Fraction: 0.06077
Policy Update Magnitude: 0.31507
Value Function Update Magnitude: 0.35699

Collected Steps per Second: 21,439.03180
Overall Steps per Second: 10,353.90495

Timestep Collection Time: 2.33350
Timestep Consumption Time: 2.49830
PPO Batch Consumption Time: 0.29119
Total Iteration Time: 4.83180

Cumulative Model Updates: 252,146
Cumulative Timesteps: 2,103,490,618

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67,150.41686
Policy Entropy: 2.61409
Value Function Loss: 0.01720

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.07724
Policy Update Magnitude: 0.33080
Value Function Update Magnitude: 0.38681

Collected Steps per Second: 21,662.64153
Overall Steps per Second: 10,388.76474

Timestep Collection Time: 2.30849
Timestep Consumption Time: 2.50517
PPO Batch Consumption Time: 0.29269
Total Iteration Time: 4.81366

Cumulative Model Updates: 252,152
Cumulative Timesteps: 2,103,540,626

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2103540626...
Checkpoint 2103540626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 65,650.77541
Policy Entropy: 2.63215
Value Function Loss: 0.01645

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.07518
Policy Update Magnitude: 0.32397
Value Function Update Magnitude: 0.40178

Collected Steps per Second: 21,519.41233
Overall Steps per Second: 10,520.12040

Timestep Collection Time: 2.32413
Timestep Consumption Time: 2.42999
PPO Batch Consumption Time: 0.27925
Total Iteration Time: 4.75413

Cumulative Model Updates: 252,158
Cumulative Timesteps: 2,103,590,640

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54,153.15530
Policy Entropy: 2.64090
Value Function Loss: 0.01660

Mean KL Divergence: 0.00678
SB3 Clip Fraction: 0.06361
Policy Update Magnitude: 0.31896
Value Function Update Magnitude: 0.35659

Collected Steps per Second: 21,384.49220
Overall Steps per Second: 10,478.87249

Timestep Collection Time: 2.33936
Timestep Consumption Time: 2.43463
PPO Batch Consumption Time: 0.27821
Total Iteration Time: 4.77399

Cumulative Model Updates: 252,164
Cumulative Timesteps: 2,103,640,666

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2103640666...
Checkpoint 2103640666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,862.46108
Policy Entropy: 2.60580
Value Function Loss: 0.01676

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.07927
Policy Update Magnitude: 0.32403
Value Function Update Magnitude: 0.35300

Collected Steps per Second: 21,370.51137
Overall Steps per Second: 10,321.16325

Timestep Collection Time: 2.34042
Timestep Consumption Time: 2.50554
PPO Batch Consumption Time: 0.29224
Total Iteration Time: 4.84597

Cumulative Model Updates: 252,170
Cumulative Timesteps: 2,103,690,682

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49,984.67008
Policy Entropy: 2.56849
Value Function Loss: 0.01726

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.08093
Policy Update Magnitude: 0.32513
Value Function Update Magnitude: 0.36734

Collected Steps per Second: 22,188.53887
Overall Steps per Second: 10,432.34683

Timestep Collection Time: 2.25387
Timestep Consumption Time: 2.53988
PPO Batch Consumption Time: 0.29242
Total Iteration Time: 4.79374

Cumulative Model Updates: 252,176
Cumulative Timesteps: 2,103,740,692

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2103740692...
Checkpoint 2103740692 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 82,713.27602
Policy Entropy: 2.55233
Value Function Loss: 0.01849

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.08249
Policy Update Magnitude: 0.33732
Value Function Update Magnitude: 0.38697

Collected Steps per Second: 21,850.70326
Overall Steps per Second: 10,590.42880

Timestep Collection Time: 2.28835
Timestep Consumption Time: 2.43309
PPO Batch Consumption Time: 0.27750
Total Iteration Time: 4.72143

Cumulative Model Updates: 252,182
Cumulative Timesteps: 2,103,790,694

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 119,682.69868
Policy Entropy: 2.57420
Value Function Loss: 0.01871

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.07747
Policy Update Magnitude: 0.34341
Value Function Update Magnitude: 0.41122

Collected Steps per Second: 21,851.03095
Overall Steps per Second: 10,438.46782

Timestep Collection Time: 2.28932
Timestep Consumption Time: 2.50295
PPO Batch Consumption Time: 0.29326
Total Iteration Time: 4.79227

Cumulative Model Updates: 252,188
Cumulative Timesteps: 2,103,840,718

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2103840718...
Checkpoint 2103840718 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 109,761.09002
Policy Entropy: 2.59911
Value Function Loss: 0.01709

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.08203
Policy Update Magnitude: 0.33381
Value Function Update Magnitude: 0.42426

Collected Steps per Second: 21,314.96631
Overall Steps per Second: 10,645.73741

Timestep Collection Time: 2.34699
Timestep Consumption Time: 2.35217
PPO Batch Consumption Time: 0.27798
Total Iteration Time: 4.69916

Cumulative Model Updates: 252,194
Cumulative Timesteps: 2,103,890,744

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90,130.35506
Policy Entropy: 2.59908
Value Function Loss: 0.01394

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.07169
Policy Update Magnitude: 0.31809
Value Function Update Magnitude: 0.38975

Collected Steps per Second: 21,603.03223
Overall Steps per Second: 10,585.64096

Timestep Collection Time: 2.31542
Timestep Consumption Time: 2.40985
PPO Batch Consumption Time: 0.29090
Total Iteration Time: 4.72527

Cumulative Model Updates: 252,200
Cumulative Timesteps: 2,103,940,764

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2103940764...
Checkpoint 2103940764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 69,357.37104
Policy Entropy: 2.59779
Value Function Loss: 0.01286

Mean KL Divergence: 0.00668
SB3 Clip Fraction: 0.06271
Policy Update Magnitude: 0.30876
Value Function Update Magnitude: 0.35711

Collected Steps per Second: 21,481.39128
Overall Steps per Second: 10,434.39442

Timestep Collection Time: 2.32806
Timestep Consumption Time: 2.46474
PPO Batch Consumption Time: 0.28691
Total Iteration Time: 4.79280

Cumulative Model Updates: 252,206
Cumulative Timesteps: 2,103,990,774

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 151,030.49004
Policy Entropy: 2.61513
Value Function Loss: 0.01484

Mean KL Divergence: 0.00635
SB3 Clip Fraction: 0.06141
Policy Update Magnitude: 0.31282
Value Function Update Magnitude: 0.35571

Collected Steps per Second: 21,543.39923
Overall Steps per Second: 10,433.38468

Timestep Collection Time: 2.32192
Timestep Consumption Time: 2.47250
PPO Batch Consumption Time: 0.28859
Total Iteration Time: 4.79442

Cumulative Model Updates: 252,212
Cumulative Timesteps: 2,104,040,796

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2104040796...
Checkpoint 2104040796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 109,948.78798
Policy Entropy: 2.63284
Value Function Loss: 0.01490

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.08426
Policy Update Magnitude: 0.30884
Value Function Update Magnitude: 0.34017

Collected Steps per Second: 21,246.83044
Overall Steps per Second: 10,360.23545

Timestep Collection Time: 2.35423
Timestep Consumption Time: 2.47384
PPO Batch Consumption Time: 0.29240
Total Iteration Time: 4.82808

Cumulative Model Updates: 252,218
Cumulative Timesteps: 2,104,090,816

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82,143.55317
Policy Entropy: 2.61792
Value Function Loss: 0.01670

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.07472
Policy Update Magnitude: 0.31840
Value Function Update Magnitude: 0.34485

Collected Steps per Second: 21,635.43594
Overall Steps per Second: 10,362.52779

Timestep Collection Time: 2.31315
Timestep Consumption Time: 2.51637
PPO Batch Consumption Time: 0.29396
Total Iteration Time: 4.82952

Cumulative Model Updates: 252,224
Cumulative Timesteps: 2,104,140,862

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 2104140862...
Checkpoint 2104140862 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 69,147.09418
Policy Entropy: 2.60060
Value Function Loss: 0.01525

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.07907
Policy Update Magnitude: 0.32139
Value Function Update Magnitude: 0.34082

Collected Steps per Second: 21,521.34686
Overall Steps per Second: 10,526.20366

Timestep Collection Time: 2.32337
Timestep Consumption Time: 2.42687
PPO Batch Consumption Time: 0.27835
Total Iteration Time: 4.75024

Cumulative Model Updates: 252,230
Cumulative Timesteps: 2,104,190,864

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78,133.17281
Policy Entropy: 2.57231
Value Function Loss: 0.01631

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.07662
Policy Update Magnitude: 0.32012
Value Function Update Magnitude: 0.32406

Collected Steps per Second: 21,606.63138
Overall Steps per Second: 10,601.98915

Timestep Collection Time: 2.31531
Timestep Consumption Time: 2.40324
PPO Batch Consumption Time: 0.27753
Total Iteration Time: 4.71855

Cumulative Model Updates: 252,236
Cumulative Timesteps: 2,104,240,890

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2104240890...
Checkpoint 2104240890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 59,054.92144
Policy Entropy: 2.58275
Value Function Loss: 0.01777

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.07564
Policy Update Magnitude: 0.32540
Value Function Update Magnitude: 0.35368

Collected Steps per Second: 21,608.41971
Overall Steps per Second: 10,309.18910

Timestep Collection Time: 2.31465
Timestep Consumption Time: 2.53694
PPO Batch Consumption Time: 0.29076
Total Iteration Time: 4.85159

Cumulative Model Updates: 252,242
Cumulative Timesteps: 2,104,290,906

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49,347.36807
Policy Entropy: 2.60718
Value Function Loss: 0.01550

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.07540
Policy Update Magnitude: 0.31614
Value Function Update Magnitude: 0.37019

Collected Steps per Second: 22,318.91372
Overall Steps per Second: 10,672.85069

Timestep Collection Time: 2.24115
Timestep Consumption Time: 2.44551
PPO Batch Consumption Time: 0.27835
Total Iteration Time: 4.68666

Cumulative Model Updates: 252,248
Cumulative Timesteps: 2,104,340,926

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2104340926...
Checkpoint 2104340926 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 51,566.77529
Policy Entropy: 2.61391
Value Function Loss: 0.01632

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.08030
Policy Update Magnitude: 0.31595
Value Function Update Magnitude: 0.38146

Collected Steps per Second: 22,092.96931
Overall Steps per Second: 10,596.46332

Timestep Collection Time: 2.26344
Timestep Consumption Time: 2.45569
PPO Batch Consumption Time: 0.27962
Total Iteration Time: 4.71912

Cumulative Model Updates: 252,254
Cumulative Timesteps: 2,104,390,932

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 73,736.98759
Policy Entropy: 2.60329
Value Function Loss: 0.01473

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.08025
Policy Update Magnitude: 0.31414
Value Function Update Magnitude: 0.36900

Collected Steps per Second: 22,028.50847
Overall Steps per Second: 10,533.79060

Timestep Collection Time: 2.27078
Timestep Consumption Time: 2.47793
PPO Batch Consumption Time: 0.28669
Total Iteration Time: 4.74872

Cumulative Model Updates: 252,260
Cumulative Timesteps: 2,104,440,954

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2104440954...
Checkpoint 2104440954 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 76,150.17326
Policy Entropy: 2.56945
Value Function Loss: 0.01653

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.06689
Policy Update Magnitude: 0.31992
Value Function Update Magnitude: 0.38636

Collected Steps per Second: 21,905.82423
Overall Steps per Second: 10,606.48944

Timestep Collection Time: 2.28277
Timestep Consumption Time: 2.43189
PPO Batch Consumption Time: 0.27890
Total Iteration Time: 4.71466

Cumulative Model Updates: 252,266
Cumulative Timesteps: 2,104,490,960

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54,665.48182
Policy Entropy: 2.56632
Value Function Loss: 0.01648

Mean KL Divergence: 0.00770
SB3 Clip Fraction: 0.06937
Policy Update Magnitude: 0.32570
Value Function Update Magnitude: 0.38583

Collected Steps per Second: 22,019.24063
Overall Steps per Second: 10,516.31104

Timestep Collection Time: 2.27092
Timestep Consumption Time: 2.48398
PPO Batch Consumption Time: 0.28955
Total Iteration Time: 4.75490

Cumulative Model Updates: 252,272
Cumulative Timesteps: 2,104,540,964

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2104540964...
Checkpoint 2104540964 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 79,050.25661
Policy Entropy: 2.57678
Value Function Loss: 0.01824

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.08067
Policy Update Magnitude: 0.32507
Value Function Update Magnitude: 0.38673

Collected Steps per Second: 21,686.79076
Overall Steps per Second: 10,578.89983

Timestep Collection Time: 2.30638
Timestep Consumption Time: 2.42171
PPO Batch Consumption Time: 0.27809
Total Iteration Time: 4.72809

Cumulative Model Updates: 252,278
Cumulative Timesteps: 2,104,590,982

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79,050.25661
Policy Entropy: 2.61963
Value Function Loss: 0.01555

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.08440
Policy Update Magnitude: 0.31956
Value Function Update Magnitude: 0.39336

Collected Steps per Second: 21,491.08474
Overall Steps per Second: 10,543.66406

Timestep Collection Time: 2.32710
Timestep Consumption Time: 2.41622
PPO Batch Consumption Time: 0.27699
Total Iteration Time: 4.74332

Cumulative Model Updates: 252,284
Cumulative Timesteps: 2,104,640,994

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2104640994...
Checkpoint 2104640994 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 70,671.00799
Policy Entropy: 2.62450
Value Function Loss: 0.01428

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.08980
Policy Update Magnitude: 0.30670
Value Function Update Magnitude: 0.37223

Collected Steps per Second: 21,208.75488
Overall Steps per Second: 10,488.47362

Timestep Collection Time: 2.35874
Timestep Consumption Time: 2.41087
PPO Batch Consumption Time: 0.27835
Total Iteration Time: 4.76962

Cumulative Model Updates: 252,290
Cumulative Timesteps: 2,104,691,020

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 64,116.39551
Policy Entropy: 2.63633
Value Function Loss: 0.01273

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.07656
Policy Update Magnitude: 0.30225
Value Function Update Magnitude: 0.37460

Collected Steps per Second: 21,511.70057
Overall Steps per Second: 10,496.25549

Timestep Collection Time: 2.32525
Timestep Consumption Time: 2.44026
PPO Batch Consumption Time: 0.27843
Total Iteration Time: 4.76551

Cumulative Model Updates: 252,296
Cumulative Timesteps: 2,104,741,040

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2104741040...
Checkpoint 2104741040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 66,183.28075
Policy Entropy: 2.59952
Value Function Loss: 0.01345

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.07140
Policy Update Magnitude: 0.30380
Value Function Update Magnitude: 0.35991

Collected Steps per Second: 21,583.90492
Overall Steps per Second: 10,374.82569

Timestep Collection Time: 2.31719
Timestep Consumption Time: 2.50352
PPO Batch Consumption Time: 0.29201
Total Iteration Time: 4.82071

Cumulative Model Updates: 252,302
Cumulative Timesteps: 2,104,791,054

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 69,298.96373
Policy Entropy: 2.58259
Value Function Loss: 0.01481

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.06462
Policy Update Magnitude: 0.31622
Value Function Update Magnitude: 0.36748

Collected Steps per Second: 22,410.93916
Overall Steps per Second: 10,716.20942

Timestep Collection Time: 2.23230
Timestep Consumption Time: 2.43614
PPO Batch Consumption Time: 0.27815
Total Iteration Time: 4.66844

Cumulative Model Updates: 252,308
Cumulative Timesteps: 2,104,841,082

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2104841082...
Checkpoint 2104841082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 74,647.25601
Policy Entropy: 2.59034
Value Function Loss: 0.01318

Mean KL Divergence: 0.00683
SB3 Clip Fraction: 0.06038
Policy Update Magnitude: 0.30977
Value Function Update Magnitude: 0.36052

Collected Steps per Second: 20,773.68021
Overall Steps per Second: 10,334.53270

Timestep Collection Time: 2.40718
Timestep Consumption Time: 2.43155
PPO Batch Consumption Time: 0.29272
Total Iteration Time: 4.83873

Cumulative Model Updates: 252,314
Cumulative Timesteps: 2,104,891,088

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 64,138.86054
Policy Entropy: 2.59885
Value Function Loss: 0.01239

Mean KL Divergence: 0.00598
SB3 Clip Fraction: 0.05724
Policy Update Magnitude: 0.30088
Value Function Update Magnitude: 0.33108

Collected Steps per Second: 21,553.44246
Overall Steps per Second: 10,561.46520

Timestep Collection Time: 2.32158
Timestep Consumption Time: 2.41621
PPO Batch Consumption Time: 0.29007
Total Iteration Time: 4.73779

Cumulative Model Updates: 252,320
Cumulative Timesteps: 2,104,941,126

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 2104941126...
Checkpoint 2104941126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,692.66368
Policy Entropy: 2.59464
Value Function Loss: 0.01304

Mean KL Divergence: 0.00651
SB3 Clip Fraction: 0.06133
Policy Update Magnitude: 0.30405
Value Function Update Magnitude: 0.32608

Collected Steps per Second: 21,451.73619
Overall Steps per Second: 10,504.11961

Timestep Collection Time: 2.33147
Timestep Consumption Time: 2.42990
PPO Batch Consumption Time: 0.29415
Total Iteration Time: 4.76137

Cumulative Model Updates: 252,326
Cumulative Timesteps: 2,104,991,140

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54,076.96515
Policy Entropy: 2.57634
Value Function Loss: 0.01431

Mean KL Divergence: 0.00777
SB3 Clip Fraction: 0.07082
Policy Update Magnitude: 0.31677
Value Function Update Magnitude: 0.34233

Collected Steps per Second: 21,775.05241
Overall Steps per Second: 10,453.94241

Timestep Collection Time: 2.29749
Timestep Consumption Time: 2.48807
PPO Batch Consumption Time: 0.29366
Total Iteration Time: 4.78556

Cumulative Model Updates: 252,332
Cumulative Timesteps: 2,105,041,168

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2105041168...
Checkpoint 2105041168 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 60,274.30250
Policy Entropy: 2.57332
Value Function Loss: 0.01314

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.07572
Policy Update Magnitude: 0.31307
Value Function Update Magnitude: 0.34495

Collected Steps per Second: 21,936.97631
Overall Steps per Second: 10,567.63808

Timestep Collection Time: 2.27953
Timestep Consumption Time: 2.45246
PPO Batch Consumption Time: 0.28784
Total Iteration Time: 4.73199

Cumulative Model Updates: 252,338
Cumulative Timesteps: 2,105,091,174

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51,890.08977
Policy Entropy: 2.56592
Value Function Loss: 0.01380

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.07787
Policy Update Magnitude: 0.31350
Value Function Update Magnitude: 0.33473

Collected Steps per Second: 21,685.56007
Overall Steps per Second: 10,471.74626

Timestep Collection Time: 2.30587
Timestep Consumption Time: 2.46927
PPO Batch Consumption Time: 0.28968
Total Iteration Time: 4.77513

Cumulative Model Updates: 252,344
Cumulative Timesteps: 2,105,141,178

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2105141178...
Checkpoint 2105141178 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 78,414.18108
Policy Entropy: 2.57235
Value Function Loss: 0.01326

Mean KL Divergence: 0.00783
SB3 Clip Fraction: 0.06973
Policy Update Magnitude: 0.31001
Value Function Update Magnitude: 0.32969

Collected Steps per Second: 21,234.61575
Overall Steps per Second: 10,299.14964

Timestep Collection Time: 2.35502
Timestep Consumption Time: 2.50052
PPO Batch Consumption Time: 0.29182
Total Iteration Time: 4.85555

Cumulative Model Updates: 252,350
Cumulative Timesteps: 2,105,191,186

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80,728.92832
Policy Entropy: 2.58913
Value Function Loss: 0.01329

Mean KL Divergence: 0.00702
SB3 Clip Fraction: 0.06314
Policy Update Magnitude: 0.30400
Value Function Update Magnitude: 0.31884

Collected Steps per Second: 21,966.23451
Overall Steps per Second: 10,455.41521

Timestep Collection Time: 2.27658
Timestep Consumption Time: 2.50639
PPO Batch Consumption Time: 0.29120
Total Iteration Time: 4.78298

Cumulative Model Updates: 252,356
Cumulative Timesteps: 2,105,241,194

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2105241194...
Checkpoint 2105241194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 69,445.06541
Policy Entropy: 2.61188
Value Function Loss: 0.01307

Mean KL Divergence: 0.00595
SB3 Clip Fraction: 0.05441
Policy Update Magnitude: 0.29638
Value Function Update Magnitude: 0.30622

Collected Steps per Second: 21,550.82934
Overall Steps per Second: 10,422.42698

Timestep Collection Time: 2.32186
Timestep Consumption Time: 2.47913
PPO Batch Consumption Time: 0.27815
Total Iteration Time: 4.80099

Cumulative Model Updates: 252,362
Cumulative Timesteps: 2,105,291,232

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79,657.30374
Policy Entropy: 2.60712
Value Function Loss: 0.01406

Mean KL Divergence: 0.00681
SB3 Clip Fraction: 0.06648
Policy Update Magnitude: 0.30123
Value Function Update Magnitude: 0.31074

Collected Steps per Second: 22,364.48975
Overall Steps per Second: 10,537.10648

Timestep Collection Time: 2.23587
Timestep Consumption Time: 2.50965
PPO Batch Consumption Time: 0.29080
Total Iteration Time: 4.74552

Cumulative Model Updates: 252,368
Cumulative Timesteps: 2,105,341,236

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2105341236...
Checkpoint 2105341236 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 79,657.30374
Policy Entropy: 2.59179
Value Function Loss: 0.01308

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.07921
Policy Update Magnitude: 0.29581
Value Function Update Magnitude: 0.32415

Collected Steps per Second: 21,613.80141
Overall Steps per Second: 10,568.66688

Timestep Collection Time: 2.31417
Timestep Consumption Time: 2.41850
PPO Batch Consumption Time: 0.27877
Total Iteration Time: 4.73267

Cumulative Model Updates: 252,374
Cumulative Timesteps: 2,105,391,254

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76,425.91047
Policy Entropy: 2.58881
Value Function Loss: 0.01213

Mean KL Divergence: 0.00699
SB3 Clip Fraction: 0.06582
Policy Update Magnitude: 0.29162
Value Function Update Magnitude: 0.31188

Collected Steps per Second: 22,205.22031
Overall Steps per Second: 10,498.56886

Timestep Collection Time: 2.25190
Timestep Consumption Time: 2.51103
PPO Batch Consumption Time: 0.29093
Total Iteration Time: 4.76293

Cumulative Model Updates: 252,380
Cumulative Timesteps: 2,105,441,258

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2105441258...
Checkpoint 2105441258 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 93,733.29336
Policy Entropy: 2.58041
Value Function Loss: 0.01370

Mean KL Divergence: 0.00721
SB3 Clip Fraction: 0.06926
Policy Update Magnitude: 0.30668
Value Function Update Magnitude: 0.31792

Collected Steps per Second: 21,908.30028
Overall Steps per Second: 10,600.67040

Timestep Collection Time: 2.28343
Timestep Consumption Time: 2.43571
PPO Batch Consumption Time: 0.27903
Total Iteration Time: 4.71914

Cumulative Model Updates: 252,386
Cumulative Timesteps: 2,105,491,284

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 118,483.26850
Policy Entropy: 2.57722
Value Function Loss: 0.01421

Mean KL Divergence: 0.00725
SB3 Clip Fraction: 0.06770
Policy Update Magnitude: 0.32445
Value Function Update Magnitude: 0.34248

Collected Steps per Second: 22,350.42930
Overall Steps per Second: 10,541.59910

Timestep Collection Time: 2.23817
Timestep Consumption Time: 2.50722
PPO Batch Consumption Time: 0.29365
Total Iteration Time: 4.74539

Cumulative Model Updates: 252,392
Cumulative Timesteps: 2,105,541,308

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2105541308...
Checkpoint 2105541308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 118,483.26850
Policy Entropy: 2.59508
Value Function Loss: 0.01313

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.07085
Policy Update Magnitude: 0.31716
Value Function Update Magnitude: 0.33455

Collected Steps per Second: 21,582.05753
Overall Steps per Second: 10,564.41938

Timestep Collection Time: 2.31692
Timestep Consumption Time: 2.41632
PPO Batch Consumption Time: 0.27850
Total Iteration Time: 4.73325

Cumulative Model Updates: 252,398
Cumulative Timesteps: 2,105,591,312

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99,852.35026
Policy Entropy: 2.61825
Value Function Loss: 0.01367

Mean KL Divergence: 0.00739
SB3 Clip Fraction: 0.06835
Policy Update Magnitude: 0.31371
Value Function Update Magnitude: 0.33050

Collected Steps per Second: 21,654.30548
Overall Steps per Second: 10,561.43189

Timestep Collection Time: 2.31003
Timestep Consumption Time: 2.42626
PPO Batch Consumption Time: 0.27770
Total Iteration Time: 4.73629

Cumulative Model Updates: 252,404
Cumulative Timesteps: 2,105,641,334

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2105641334...
Checkpoint 2105641334 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 108,497.46375
Policy Entropy: 2.62732
Value Function Loss: 0.01242

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.08445
Policy Update Magnitude: 0.30283
Value Function Update Magnitude: 0.33302

Collected Steps per Second: 21,083.09278
Overall Steps per Second: 10,293.08751

Timestep Collection Time: 2.37223
Timestep Consumption Time: 2.48676
PPO Batch Consumption Time: 0.29129
Total Iteration Time: 4.85899

Cumulative Model Updates: 252,410
Cumulative Timesteps: 2,105,691,348

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 74,316.30331
Policy Entropy: 2.60027
Value Function Loss: 0.01438

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.07584
Policy Update Magnitude: 0.30559
Value Function Update Magnitude: 0.34200

Collected Steps per Second: 21,863.32811
Overall Steps per Second: 10,429.62888

Timestep Collection Time: 2.28867
Timestep Consumption Time: 2.50901
PPO Batch Consumption Time: 0.29201
Total Iteration Time: 4.79768

Cumulative Model Updates: 252,416
Cumulative Timesteps: 2,105,741,386

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 2105741386...
Checkpoint 2105741386 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 74,316.30331
Policy Entropy: 2.59465
Value Function Loss: 0.01465

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.08548
Policy Update Magnitude: 0.31194
Value Function Update Magnitude: 0.32417

Collected Steps per Second: 21,947.38190
Overall Steps per Second: 10,591.37797

Timestep Collection Time: 2.28000
Timestep Consumption Time: 2.44460
PPO Batch Consumption Time: 0.27725
Total Iteration Time: 4.72460

Cumulative Model Updates: 252,422
Cumulative Timesteps: 2,105,791,426

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62,701.79034
Policy Entropy: 2.58932
Value Function Loss: 0.01581

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.07945
Policy Update Magnitude: 0.31912
Value Function Update Magnitude: 0.28937

Collected Steps per Second: 21,734.72925
Overall Steps per Second: 10,611.60139

Timestep Collection Time: 2.30175
Timestep Consumption Time: 2.41271
PPO Batch Consumption Time: 0.28714
Total Iteration Time: 4.71446

Cumulative Model Updates: 252,428
Cumulative Timesteps: 2,105,841,454

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2105841454...
Checkpoint 2105841454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 115,453.67773
Policy Entropy: 2.60469
Value Function Loss: 0.01478

Mean KL Divergence: 0.00725
SB3 Clip Fraction: 0.06733
Policy Update Magnitude: 0.30983
Value Function Update Magnitude: 0.27958

Collected Steps per Second: 21,259.01850
Overall Steps per Second: 10,425.87885

Timestep Collection Time: 2.35326
Timestep Consumption Time: 2.44518
PPO Batch Consumption Time: 0.29463
Total Iteration Time: 4.79844

Cumulative Model Updates: 252,434
Cumulative Timesteps: 2,105,891,482

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93,821.35321
Policy Entropy: 2.59414
Value Function Loss: 0.01316

Mean KL Divergence: 0.00666
SB3 Clip Fraction: 0.06262
Policy Update Magnitude: 0.30145
Value Function Update Magnitude: 0.28782

Collected Steps per Second: 21,374.72743
Overall Steps per Second: 10,475.72724

Timestep Collection Time: 2.34015
Timestep Consumption Time: 2.43470
PPO Batch Consumption Time: 0.29259
Total Iteration Time: 4.77485

Cumulative Model Updates: 252,440
Cumulative Timesteps: 2,105,941,502

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2105941502...
Checkpoint 2105941502 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 110,614.57422
Policy Entropy: 2.63356
Value Function Loss: 0.01120

Mean KL Divergence: 0.00578
SB3 Clip Fraction: 0.05552
Policy Update Magnitude: 0.29183
Value Function Update Magnitude: 0.29224

Collected Steps per Second: 20,957.37164
Overall Steps per Second: 10,261.16778

Timestep Collection Time: 2.38742
Timestep Consumption Time: 2.48864
PPO Batch Consumption Time: 0.29346
Total Iteration Time: 4.87605

Cumulative Model Updates: 252,446
Cumulative Timesteps: 2,105,991,536

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99,864.34493
Policy Entropy: 2.62596
Value Function Loss: 0.01110

Mean KL Divergence: 0.00682
SB3 Clip Fraction: 0.06462
Policy Update Magnitude: 0.27934
Value Function Update Magnitude: 0.28685

Collected Steps per Second: 22,071.72468
Overall Steps per Second: 10,580.20689

Timestep Collection Time: 2.26616
Timestep Consumption Time: 2.46135
PPO Batch Consumption Time: 0.29007
Total Iteration Time: 4.72751

Cumulative Model Updates: 252,452
Cumulative Timesteps: 2,106,041,554

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2106041554...
Checkpoint 2106041554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 105,141.71815
Policy Entropy: 2.60606
Value Function Loss: 0.01231

Mean KL Divergence: 0.00653
SB3 Clip Fraction: 0.06154
Policy Update Magnitude: 0.28298
Value Function Update Magnitude: 0.29602

Collected Steps per Second: 22,042.28932
Overall Steps per Second: 10,530.36037

Timestep Collection Time: 2.26909
Timestep Consumption Time: 2.48060
PPO Batch Consumption Time: 0.29342
Total Iteration Time: 4.74969

Cumulative Model Updates: 252,458
Cumulative Timesteps: 2,106,091,570

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 119,692.02701
Policy Entropy: 2.58052
Value Function Loss: 0.01430

Mean KL Divergence: 0.00689
SB3 Clip Fraction: 0.06464
Policy Update Magnitude: 0.29709
Value Function Update Magnitude: 0.29238

Collected Steps per Second: 21,746.79080
Overall Steps per Second: 10,391.23934

Timestep Collection Time: 2.30066
Timestep Consumption Time: 2.51416
PPO Batch Consumption Time: 0.29376
Total Iteration Time: 4.81483

Cumulative Model Updates: 252,464
Cumulative Timesteps: 2,106,141,602

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2106141602...
Checkpoint 2106141602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 93,622.72751
Policy Entropy: 2.59166
Value Function Loss: 0.01469

Mean KL Divergence: 0.00733
SB3 Clip Fraction: 0.06825
Policy Update Magnitude: 0.30640
Value Function Update Magnitude: 0.27908

Collected Steps per Second: 21,499.78847
Overall Steps per Second: 10,535.32235

Timestep Collection Time: 2.32570
Timestep Consumption Time: 2.42043
PPO Batch Consumption Time: 0.27839
Total Iteration Time: 4.74613

Cumulative Model Updates: 252,470
Cumulative Timesteps: 2,106,191,604

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84,157.49924
Policy Entropy: 2.61266
Value Function Loss: 0.01465

Mean KL Divergence: 0.00744
SB3 Clip Fraction: 0.06962
Policy Update Magnitude: 0.29517
Value Function Update Magnitude: 0.28862

Collected Steps per Second: 21,648.29127
Overall Steps per Second: 10,518.28350

Timestep Collection Time: 2.31039
Timestep Consumption Time: 2.44476
PPO Batch Consumption Time: 0.27927
Total Iteration Time: 4.75515

Cumulative Model Updates: 252,476
Cumulative Timesteps: 2,106,241,620

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2106241620...
Checkpoint 2106241620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 99,349.21229
Policy Entropy: 2.62729
Value Function Loss: 0.01282

Mean KL Divergence: 0.00714
SB3 Clip Fraction: 0.06912
Policy Update Magnitude: 0.28689
Value Function Update Magnitude: 0.27409

Collected Steps per Second: 21,178.78768
Overall Steps per Second: 10,283.40627

Timestep Collection Time: 2.36199
Timestep Consumption Time: 2.50255
PPO Batch Consumption Time: 0.29324
Total Iteration Time: 4.86454

Cumulative Model Updates: 252,482
Cumulative Timesteps: 2,106,291,644

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 100,396.17324
Policy Entropy: 2.62975
Value Function Loss: 0.01303

Mean KL Divergence: 0.00660
SB3 Clip Fraction: 0.06266
Policy Update Magnitude: 0.28597
Value Function Update Magnitude: 0.26924

Collected Steps per Second: 21,939.92484
Overall Steps per Second: 10,470.36292

Timestep Collection Time: 2.27977
Timestep Consumption Time: 2.49733
PPO Batch Consumption Time: 0.29265
Total Iteration Time: 4.77710

Cumulative Model Updates: 252,488
Cumulative Timesteps: 2,106,341,662

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2106341662...
Checkpoint 2106341662 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87,854.99110
Policy Entropy: 2.62021
Value Function Loss: 0.01375

Mean KL Divergence: 0.00637
SB3 Clip Fraction: 0.06273
Policy Update Magnitude: 0.28679
Value Function Update Magnitude: 0.26410

Collected Steps per Second: 22,016.46519
Overall Steps per Second: 10,630.04807

Timestep Collection Time: 2.27303
Timestep Consumption Time: 2.43476
PPO Batch Consumption Time: 0.27693
Total Iteration Time: 4.70779

Cumulative Model Updates: 252,494
Cumulative Timesteps: 2,106,391,706

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 111,187.33788
Policy Entropy: 2.60608
Value Function Loss: 0.01375

Mean KL Divergence: 0.00718
SB3 Clip Fraction: 0.06875
Policy Update Magnitude: 0.29431
Value Function Update Magnitude: 0.27824

Collected Steps per Second: 21,559.95566
Overall Steps per Second: 10,707.61635

Timestep Collection Time: 2.32051
Timestep Consumption Time: 2.35187
PPO Batch Consumption Time: 0.27880
Total Iteration Time: 4.67238

Cumulative Model Updates: 252,500
Cumulative Timesteps: 2,106,441,736

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2106441736...
Checkpoint 2106441736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 98,683.70705
Policy Entropy: 2.60915
Value Function Loss: 0.01387

Mean KL Divergence: 0.01122
SB3 Clip Fraction: 0.10117
Policy Update Magnitude: 0.29418
Value Function Update Magnitude: 0.29919

Collected Steps per Second: 21,078.10366
Overall Steps per Second: 10,426.22419

Timestep Collection Time: 2.37279
Timestep Consumption Time: 2.42415
PPO Batch Consumption Time: 0.29167
Total Iteration Time: 4.79694

Cumulative Model Updates: 252,506
Cumulative Timesteps: 2,106,491,750

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48,819.75817
Policy Entropy: 2.60710
Value Function Loss: 0.01516

Mean KL Divergence: 0.01778
SB3 Clip Fraction: 0.13194
Policy Update Magnitude: 0.29161
Value Function Update Magnitude: 0.29762

Collected Steps per Second: 21,535.99924
Overall Steps per Second: 10,700.22670

Timestep Collection Time: 2.32253
Timestep Consumption Time: 2.35195
PPO Batch Consumption Time: 0.27873
Total Iteration Time: 4.67448

Cumulative Model Updates: 252,512
Cumulative Timesteps: 2,106,541,768

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2106541768...
Checkpoint 2106541768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,880.49017
Policy Entropy: 2.63278
Value Function Loss: 0.01481

Mean KL Divergence: 0.01449
SB3 Clip Fraction: 0.11095
Policy Update Magnitude: 0.30459
Value Function Update Magnitude: 0.28741

Collected Steps per Second: 21,098.94954
Overall Steps per Second: 10,290.74323

Timestep Collection Time: 2.37007
Timestep Consumption Time: 2.48925
PPO Batch Consumption Time: 0.29402
Total Iteration Time: 4.85932

Cumulative Model Updates: 252,518
Cumulative Timesteps: 2,106,591,774

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92,109.85797
Policy Entropy: 2.60548
Value Function Loss: 0.01622

Mean KL Divergence: 0.01427
SB3 Clip Fraction: 0.11031
Policy Update Magnitude: 0.30749
Value Function Update Magnitude: 0.30380

Collected Steps per Second: 22,027.41851
Overall Steps per Second: 10,536.91286

Timestep Collection Time: 2.27008
Timestep Consumption Time: 2.47552
PPO Batch Consumption Time: 0.29225
Total Iteration Time: 4.74560

Cumulative Model Updates: 252,524
Cumulative Timesteps: 2,106,641,778

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2106641778...
Checkpoint 2106641778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 65,104.06986
Policy Entropy: 2.61652
Value Function Loss: 0.01385

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.08671
Policy Update Magnitude: 0.30605
Value Function Update Magnitude: 0.30074

Collected Steps per Second: 21,893.39848
Overall Steps per Second: 10,527.80536

Timestep Collection Time: 2.28388
Timestep Consumption Time: 2.46563
PPO Batch Consumption Time: 0.28956
Total Iteration Time: 4.74952

Cumulative Model Updates: 252,530
Cumulative Timesteps: 2,106,691,780

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59,884.45687
Policy Entropy: 2.59788
Value Function Loss: 0.01324

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.08186
Policy Update Magnitude: 0.29637
Value Function Update Magnitude: 0.30069

Collected Steps per Second: 21,621.76184
Overall Steps per Second: 10,543.81076

Timestep Collection Time: 2.31304
Timestep Consumption Time: 2.43022
PPO Batch Consumption Time: 0.27744
Total Iteration Time: 4.74326

Cumulative Model Updates: 252,536
Cumulative Timesteps: 2,106,741,792

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2106741792...
Checkpoint 2106741792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 70,591.34094
Policy Entropy: 2.60961
Value Function Loss: 0.01489

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.07379
Policy Update Magnitude: 0.29389
Value Function Update Magnitude: 0.31098

Collected Steps per Second: 21,152.48258
Overall Steps per Second: 10,469.01072

Timestep Collection Time: 2.36483
Timestep Consumption Time: 2.41327
PPO Batch Consumption Time: 0.27837
Total Iteration Time: 4.77810

Cumulative Model Updates: 252,542
Cumulative Timesteps: 2,106,791,814

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62,224.17053
Policy Entropy: 2.60785
Value Function Loss: 0.01405

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.07249
Policy Update Magnitude: 0.29393
Value Function Update Magnitude: 0.32355

Collected Steps per Second: 21,355.86293
Overall Steps per Second: 10,475.97963

Timestep Collection Time: 2.34249
Timestep Consumption Time: 2.43281
PPO Batch Consumption Time: 0.27895
Total Iteration Time: 4.77531

Cumulative Model Updates: 252,548
Cumulative Timesteps: 2,106,841,840

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2106841840...
Checkpoint 2106841840 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 71,512.20479
Policy Entropy: 2.62240
Value Function Loss: 0.01490

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.07916
Policy Update Magnitude: 0.29685
Value Function Update Magnitude: 0.30141

Collected Steps per Second: 21,410.12919
Overall Steps per Second: 10,341.00975

Timestep Collection Time: 2.33590
Timestep Consumption Time: 2.50037
PPO Batch Consumption Time: 0.29360
Total Iteration Time: 4.83628

Cumulative Model Updates: 252,554
Cumulative Timesteps: 2,106,891,852

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49,486.06587
Policy Entropy: 2.62139
Value Function Loss: 0.01494

Mean KL Divergence: 0.00729
SB3 Clip Fraction: 0.07057
Policy Update Magnitude: 0.30543
Value Function Update Magnitude: 0.26647

Collected Steps per Second: 21,682.53601
Overall Steps per Second: 10,373.57071

Timestep Collection Time: 2.30665
Timestep Consumption Time: 2.51464
PPO Batch Consumption Time: 0.29088
Total Iteration Time: 4.82129

Cumulative Model Updates: 252,560
Cumulative Timesteps: 2,106,941,866

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2106941866...
Checkpoint 2106941866 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 53,979.67233
Policy Entropy: 2.61676
Value Function Loss: 0.01468

Mean KL Divergence: 0.00716
SB3 Clip Fraction: 0.06765
Policy Update Magnitude: 0.29909
Value Function Update Magnitude: 0.26719

Collected Steps per Second: 22,042.25613
Overall Steps per Second: 10,590.61528

Timestep Collection Time: 2.27009
Timestep Consumption Time: 2.45465
PPO Batch Consumption Time: 0.27916
Total Iteration Time: 4.72475

Cumulative Model Updates: 252,566
Cumulative Timesteps: 2,106,991,904

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 72,686.66210
Policy Entropy: 2.60314
Value Function Loss: 0.01406

Mean KL Divergence: 0.00758
SB3 Clip Fraction: 0.07380
Policy Update Magnitude: 0.29949
Value Function Update Magnitude: 0.26756

Collected Steps per Second: 21,231.52343
Overall Steps per Second: 10,483.23075

Timestep Collection Time: 2.35612
Timestep Consumption Time: 2.41569
PPO Batch Consumption Time: 0.28890
Total Iteration Time: 4.77181

Cumulative Model Updates: 252,572
Cumulative Timesteps: 2,107,041,928

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2107041928...
Checkpoint 2107041928 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 96,850.56266
Policy Entropy: 2.60941
Value Function Loss: 0.01454

Mean KL Divergence: 0.00652
SB3 Clip Fraction: 0.06370
Policy Update Magnitude: 0.30276
Value Function Update Magnitude: 0.26477

Collected Steps per Second: 21,445.01321
Overall Steps per Second: 10,711.68723

Timestep Collection Time: 2.33369
Timestep Consumption Time: 2.33840
PPO Batch Consumption Time: 0.27743
Total Iteration Time: 4.67209

Cumulative Model Updates: 252,578
Cumulative Timesteps: 2,107,091,974

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 125,396.12971
Policy Entropy: 2.60052
Value Function Loss: 0.01434

Mean KL Divergence: 0.00685
SB3 Clip Fraction: 0.06675
Policy Update Magnitude: 0.30887
Value Function Update Magnitude: 0.26563

Collected Steps per Second: 21,335.43474
Overall Steps per Second: 10,488.47187

Timestep Collection Time: 2.34408
Timestep Consumption Time: 2.42420
PPO Batch Consumption Time: 0.29065
Total Iteration Time: 4.76828

Cumulative Model Updates: 252,584
Cumulative Timesteps: 2,107,141,986

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2107141986...
Checkpoint 2107141986 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 88,095.25816
Policy Entropy: 2.60048
Value Function Loss: 0.01480

Mean KL Divergence: 0.00666
SB3 Clip Fraction: 0.06305
Policy Update Magnitude: 0.31431
Value Function Update Magnitude: 0.29012

Collected Steps per Second: 20,304.13167
Overall Steps per Second: 10,100.96930

Timestep Collection Time: 2.46334
Timestep Consumption Time: 2.48826
PPO Batch Consumption Time: 0.29055
Total Iteration Time: 4.95160

Cumulative Model Updates: 252,590
Cumulative Timesteps: 2,107,192,002

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56,106.56113
Policy Entropy: 2.60623
Value Function Loss: 0.01558

Mean KL Divergence: 0.00659
SB3 Clip Fraction: 0.06437
Policy Update Magnitude: 0.31583
Value Function Update Magnitude: 0.34926

Collected Steps per Second: 21,501.46358
Overall Steps per Second: 10,427.22206

Timestep Collection Time: 2.32710
Timestep Consumption Time: 2.47150
PPO Batch Consumption Time: 0.28702
Total Iteration Time: 4.79859

Cumulative Model Updates: 252,596
Cumulative Timesteps: 2,107,242,038

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 2107242038...
Checkpoint 2107242038 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,873.70122
Policy Entropy: 2.61060
Value Function Loss: 0.01587

Mean KL Divergence: 0.00715
SB3 Clip Fraction: 0.06859
Policy Update Magnitude: 0.30939
Value Function Update Magnitude: 0.37859

Collected Steps per Second: 21,384.22971
Overall Steps per Second: 10,400.39158

Timestep Collection Time: 2.33864
Timestep Consumption Time: 2.46983
PPO Batch Consumption Time: 0.29100
Total Iteration Time: 4.80847

Cumulative Model Updates: 252,602
Cumulative Timesteps: 2,107,292,048

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53,500.89131
Policy Entropy: 2.61450
Value Function Loss: 0.01470

Mean KL Divergence: 0.00727
SB3 Clip Fraction: 0.07128
Policy Update Magnitude: 0.30932
Value Function Update Magnitude: 0.34999

Collected Steps per Second: 21,671.83293
Overall Steps per Second: 10,374.85221

Timestep Collection Time: 2.30770
Timestep Consumption Time: 2.51281
PPO Batch Consumption Time: 0.29253
Total Iteration Time: 4.82050

Cumulative Model Updates: 252,608
Cumulative Timesteps: 2,107,342,060

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2107342060...
Checkpoint 2107342060 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 65,133.25739
Policy Entropy: 2.60168
Value Function Loss: 0.01737

Mean KL Divergence: 0.00741
SB3 Clip Fraction: 0.07158
Policy Update Magnitude: 0.31834
Value Function Update Magnitude: 0.31186

Collected Steps per Second: 21,852.71440
Overall Steps per Second: 10,592.19213

Timestep Collection Time: 2.28814
Timestep Consumption Time: 2.43251
PPO Batch Consumption Time: 0.27680
Total Iteration Time: 4.72065

Cumulative Model Updates: 252,614
Cumulative Timesteps: 2,107,392,062

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65,133.25739
Policy Entropy: 2.62038
Value Function Loss: 0.01530

Mean KL Divergence: 0.00674
SB3 Clip Fraction: 0.06367
Policy Update Magnitude: 0.31536
Value Function Update Magnitude: 0.30074

Collected Steps per Second: 22,379.12227
Overall Steps per Second: 10,550.73326

Timestep Collection Time: 2.23494
Timestep Consumption Time: 2.50558
PPO Batch Consumption Time: 0.28974
Total Iteration Time: 4.74052

Cumulative Model Updates: 252,620
Cumulative Timesteps: 2,107,442,078

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2107442078...
Checkpoint 2107442078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55,897.45469
Policy Entropy: 2.63276
Value Function Loss: 0.01572

Mean KL Divergence: 0.00701
SB3 Clip Fraction: 0.06620
Policy Update Magnitude: 0.31148
Value Function Update Magnitude: 0.33829

Collected Steps per Second: 22,157.40595
Overall Steps per Second: 10,502.51753

Timestep Collection Time: 2.25866
Timestep Consumption Time: 2.50649
PPO Batch Consumption Time: 0.29394
Total Iteration Time: 4.76514

Cumulative Model Updates: 252,626
Cumulative Timesteps: 2,107,492,124

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65,145.63380
Policy Entropy: 2.62758
Value Function Loss: 0.01408

Mean KL Divergence: 0.00661
SB3 Clip Fraction: 0.06361
Policy Update Magnitude: 0.31722
Value Function Update Magnitude: 0.34861

Collected Steps per Second: 22,019.02724
Overall Steps per Second: 10,481.56185

Timestep Collection Time: 2.27122
Timestep Consumption Time: 2.50002
PPO Batch Consumption Time: 0.29224
Total Iteration Time: 4.77124

Cumulative Model Updates: 252,632
Cumulative Timesteps: 2,107,542,134

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2107542134...
Checkpoint 2107542134 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 142,250.01199
Policy Entropy: 2.61209
Value Function Loss: 0.01549

Mean KL Divergence: 0.00659
SB3 Clip Fraction: 0.05987
Policy Update Magnitude: 0.32351
Value Function Update Magnitude: 0.36534

Collected Steps per Second: 21,892.41493
Overall Steps per Second: 10,632.16118

Timestep Collection Time: 2.28545
Timestep Consumption Time: 2.42046
PPO Batch Consumption Time: 0.27791
Total Iteration Time: 4.70591

Cumulative Model Updates: 252,638
Cumulative Timesteps: 2,107,592,168

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 150,674.20479
Policy Entropy: 2.62296
Value Function Loss: 0.01465

Mean KL Divergence: 0.00762
SB3 Clip Fraction: 0.06743
Policy Update Magnitude: 0.31586
Value Function Update Magnitude: 0.37108

Collected Steps per Second: 22,264.84659
Overall Steps per Second: 10,520.86442

Timestep Collection Time: 2.24587
Timestep Consumption Time: 2.50697
PPO Batch Consumption Time: 0.29257
Total Iteration Time: 4.75284

Cumulative Model Updates: 252,644
Cumulative Timesteps: 2,107,642,172

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2107642172...
Checkpoint 2107642172 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 122,348.91966
Policy Entropy: 2.62918
Value Function Loss: 0.01341

Mean KL Divergence: 0.00675
SB3 Clip Fraction: 0.06243
Policy Update Magnitude: 0.30163
Value Function Update Magnitude: 0.32818

Collected Steps per Second: 22,153.32655
Overall Steps per Second: 10,565.99003

Timestep Collection Time: 2.25781
Timestep Consumption Time: 2.47606
PPO Batch Consumption Time: 0.28785
Total Iteration Time: 4.73387

Cumulative Model Updates: 252,650
Cumulative Timesteps: 2,107,692,190

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 122,967.64947
Policy Entropy: 2.63169
Value Function Loss: 0.01373

Mean KL Divergence: 0.00637
SB3 Clip Fraction: 0.06201
Policy Update Magnitude: 0.29564
Value Function Update Magnitude: 0.30168

Collected Steps per Second: 21,579.68527
Overall Steps per Second: 10,425.95741

Timestep Collection Time: 2.31718
Timestep Consumption Time: 2.47893
PPO Batch Consumption Time: 0.28596
Total Iteration Time: 4.79611

Cumulative Model Updates: 252,656
Cumulative Timesteps: 2,107,742,194

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2107742194...
Checkpoint 2107742194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 69,081.23789
Policy Entropy: 2.63282
Value Function Loss: 0.01326

Mean KL Divergence: 0.00668
SB3 Clip Fraction: 0.06477
Policy Update Magnitude: 0.31075
Value Function Update Magnitude: 0.30900

Collected Steps per Second: 21,515.28858
Overall Steps per Second: 10,403.95760

Timestep Collection Time: 2.32449
Timestep Consumption Time: 2.48253
PPO Batch Consumption Time: 0.28956
Total Iteration Time: 4.80702

Cumulative Model Updates: 252,662
Cumulative Timesteps: 2,107,792,206

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57,450.90661
Policy Entropy: 2.63936
Value Function Loss: 0.01314

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.07302
Policy Update Magnitude: 0.30824
Value Function Update Magnitude: 0.32002

Collected Steps per Second: 21,494.98603
Overall Steps per Second: 10,341.84076

Timestep Collection Time: 2.32826
Timestep Consumption Time: 2.51091
PPO Batch Consumption Time: 0.29334
Total Iteration Time: 4.83918

Cumulative Model Updates: 252,668
Cumulative Timesteps: 2,107,842,252

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 2107842252...
Checkpoint 2107842252 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 57,581.49823
Policy Entropy: 2.64477
Value Function Loss: 0.01189

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.07295
Policy Update Magnitude: 0.29453
Value Function Update Magnitude: 0.31852

Collected Steps per Second: 21,402.21787
Overall Steps per Second: 10,480.99711

Timestep Collection Time: 2.33761
Timestep Consumption Time: 2.43579
PPO Batch Consumption Time: 0.27898
Total Iteration Time: 4.77340

Cumulative Model Updates: 252,674
Cumulative Timesteps: 2,107,892,282

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57,581.49823
Policy Entropy: 2.63694
Value Function Loss: 0.01151

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.06957
Policy Update Magnitude: 0.28604
Value Function Update Magnitude: 0.29371

Collected Steps per Second: 21,442.94217
Overall Steps per Second: 10,475.69040

Timestep Collection Time: 2.33326
Timestep Consumption Time: 2.44275
PPO Batch Consumption Time: 0.27801
Total Iteration Time: 4.77601

Cumulative Model Updates: 252,680
Cumulative Timesteps: 2,107,942,314

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2107942314...
Checkpoint 2107942314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 114,110.52130
Policy Entropy: 2.62059
Value Function Loss: 0.01246

Mean KL Divergence: 0.00758
SB3 Clip Fraction: 0.07132
Policy Update Magnitude: 0.28988
Value Function Update Magnitude: 0.27713

Collected Steps per Second: 22,009.77773
Overall Steps per Second: 10,408.59674

Timestep Collection Time: 2.27208
Timestep Consumption Time: 2.53241
PPO Batch Consumption Time: 0.29036
Total Iteration Time: 4.80449

Cumulative Model Updates: 252,686
Cumulative Timesteps: 2,107,992,322

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90,360.23664
Policy Entropy: 2.60793
Value Function Loss: 0.01484

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.07475
Policy Update Magnitude: 0.30163
Value Function Update Magnitude: 0.29941

Collected Steps per Second: 22,159.75044
Overall Steps per Second: 10,617.73651

Timestep Collection Time: 2.25634
Timestep Consumption Time: 2.45276
PPO Batch Consumption Time: 0.27868
Total Iteration Time: 4.70910

Cumulative Model Updates: 252,692
Cumulative Timesteps: 2,108,042,322

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2108042322...
Checkpoint 2108042322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 68,678.61745
Policy Entropy: 2.62650
Value Function Loss: 0.01527

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.08620
Policy Update Magnitude: 0.30636
Value Function Update Magnitude: 0.31969

Collected Steps per Second: 21,865.31868
Overall Steps per Second: 10,461.44381

Timestep Collection Time: 2.28801
Timestep Consumption Time: 2.49412
PPO Batch Consumption Time: 0.29122
Total Iteration Time: 4.78213

Cumulative Model Updates: 252,698
Cumulative Timesteps: 2,108,092,350

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80,347.87828
Policy Entropy: 2.65708
Value Function Loss: 0.01509

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.07854
Policy Update Magnitude: 0.30576
Value Function Update Magnitude: 0.33899

Collected Steps per Second: 21,252.20117
Overall Steps per Second: 10,512.64637

Timestep Collection Time: 2.35420
Timestep Consumption Time: 2.40502
PPO Batch Consumption Time: 0.28972
Total Iteration Time: 4.75922

Cumulative Model Updates: 252,704
Cumulative Timesteps: 2,108,142,382

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2108142382...
Checkpoint 2108142382 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87,852.33653
Policy Entropy: 2.64679
Value Function Loss: 0.01209

Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.07835
Policy Update Magnitude: 0.29783
Value Function Update Magnitude: 0.31833

Collected Steps per Second: 21,035.40911
Overall Steps per Second: 10,419.64451

Timestep Collection Time: 2.37694
Timestep Consumption Time: 2.42168
PPO Batch Consumption Time: 0.28993
Total Iteration Time: 4.79863

Cumulative Model Updates: 252,710
Cumulative Timesteps: 2,108,192,382

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 73,588.22156
Policy Entropy: 2.62399
Value Function Loss: 0.01274

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.07611
Policy Update Magnitude: 0.30271
Value Function Update Magnitude: 0.30840

Collected Steps per Second: 21,464.70766
Overall Steps per Second: 10,451.29421

Timestep Collection Time: 2.33146
Timestep Consumption Time: 2.45685
PPO Batch Consumption Time: 0.29449
Total Iteration Time: 4.78831

Cumulative Model Updates: 252,716
Cumulative Timesteps: 2,108,242,426

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 2108242426...
Checkpoint 2108242426 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 74,636.35601
Policy Entropy: 2.62624
Value Function Loss: 0.01337

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.07135
Policy Update Magnitude: 0.30502
Value Function Update Magnitude: 0.30470

Collected Steps per Second: 21,397.14392
Overall Steps per Second: 10,628.40119

Timestep Collection Time: 2.33760
Timestep Consumption Time: 2.36847
PPO Batch Consumption Time: 0.27929
Total Iteration Time: 4.70607

Cumulative Model Updates: 252,722
Cumulative Timesteps: 2,108,292,444

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66,184.75739
Policy Entropy: 2.64173
Value Function Loss: 0.01298

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.08945
Policy Update Magnitude: 0.30300
Value Function Update Magnitude: 0.31582

Collected Steps per Second: 21,007.35245
Overall Steps per Second: 10,443.50354

Timestep Collection Time: 2.38088
Timestep Consumption Time: 2.40832
PPO Batch Consumption Time: 0.27944
Total Iteration Time: 4.78920

Cumulative Model Updates: 252,728
Cumulative Timesteps: 2,108,342,460

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2108342460...
Checkpoint 2108342460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 66,184.75739
Policy Entropy: 2.65745
Value Function Loss: 0.01218

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.08116
Policy Update Magnitude: 0.28792
Value Function Update Magnitude: 0.30292

Collected Steps per Second: 21,276.86193
Overall Steps per Second: 10,369.17477

Timestep Collection Time: 2.34997
Timestep Consumption Time: 2.47201
PPO Batch Consumption Time: 0.29211
Total Iteration Time: 4.82198

Cumulative Model Updates: 252,734
Cumulative Timesteps: 2,108,392,460

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63,062.28965
Policy Entropy: 2.69116
Value Function Loss: 0.01210

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.07247
Policy Update Magnitude: 0.28474
Value Function Update Magnitude: 0.24797

Collected Steps per Second: 21,503.40992
Overall Steps per Second: 10,428.48023

Timestep Collection Time: 2.32614
Timestep Consumption Time: 2.47034
PPO Batch Consumption Time: 0.29106
Total Iteration Time: 4.79648

Cumulative Model Updates: 252,740
Cumulative Timesteps: 2,108,442,480

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2108442480...
Checkpoint 2108442480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 116,869.64801
Policy Entropy: 2.67592
Value Function Loss: 0.01230

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.07527
Policy Update Magnitude: 0.27318
Value Function Update Magnitude: 0.23130

Collected Steps per Second: 21,511.63318
Overall Steps per Second: 10,500.18722

Timestep Collection Time: 2.32451
Timestep Consumption Time: 2.43769
PPO Batch Consumption Time: 0.27884
Total Iteration Time: 4.76220

Cumulative Model Updates: 252,746
Cumulative Timesteps: 2,108,492,484

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 96,560.27459
Policy Entropy: 2.68501
Value Function Loss: 0.01203

Mean KL Divergence: 0.00744
SB3 Clip Fraction: 0.07137
Policy Update Magnitude: 0.26853
Value Function Update Magnitude: 0.24033

Collected Steps per Second: 21,654.84925
Overall Steps per Second: 10,552.33444

Timestep Collection Time: 2.31061
Timestep Consumption Time: 2.43109
PPO Batch Consumption Time: 0.27714
Total Iteration Time: 4.74170

Cumulative Model Updates: 252,752
Cumulative Timesteps: 2,108,542,520

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 2108542520...
Checkpoint 2108542520 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86,620.39506
Policy Entropy: 2.63502
Value Function Loss: 0.01201

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.08323
Policy Update Magnitude: 0.27360
Value Function Update Magnitude: 0.22596

Collected Steps per Second: 21,790.78528
Overall Steps per Second: 10,505.62567

Timestep Collection Time: 2.29491
Timestep Consumption Time: 2.46520
PPO Batch Consumption Time: 0.27933
Total Iteration Time: 4.76012

Cumulative Model Updates: 252,758
Cumulative Timesteps: 2,108,592,528

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 72,523.14946
Policy Entropy: 2.65321
Value Function Loss: 0.01271

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.07963
Policy Update Magnitude: 0.28123
Value Function Update Magnitude: 0.24117

Collected Steps per Second: 22,069.34523
Overall Steps per Second: 10,463.40016

Timestep Collection Time: 2.26667
Timestep Consumption Time: 2.51418
PPO Batch Consumption Time: 0.29142
Total Iteration Time: 4.78086

Cumulative Model Updates: 252,764
Cumulative Timesteps: 2,108,642,552

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2108642552...
Checkpoint 2108642552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 59,822.42689
Policy Entropy: 2.65214
Value Function Loss: 0.01215

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.07198
Policy Update Magnitude: 0.28409
Value Function Update Magnitude: 0.28264

Collected Steps per Second: 21,748.61036
Overall Steps per Second: 10,416.42153

Timestep Collection Time: 2.29983
Timestep Consumption Time: 2.50202
PPO Batch Consumption Time: 0.29075
Total Iteration Time: 4.80184

Cumulative Model Updates: 252,770
Cumulative Timesteps: 2,108,692,570

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92,040.23075
Policy Entropy: 2.66506
Value Function Loss: 0.01223

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.07703
Policy Update Magnitude: 0.28323
Value Function Update Magnitude: 0.29113

Collected Steps per Second: 22,332.24528
Overall Steps per Second: 10,703.67069

Timestep Collection Time: 2.23963
Timestep Consumption Time: 2.43316
PPO Batch Consumption Time: 0.27900
Total Iteration Time: 4.67279

Cumulative Model Updates: 252,776
Cumulative Timesteps: 2,108,742,586

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2108742586...
Checkpoint 2108742586 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 64,786.61173
Policy Entropy: 2.65146
Value Function Loss: 0.01164

Mean KL Divergence: 0.01279
SB3 Clip Fraction: 0.10805
Policy Update Magnitude: 0.28528
Value Function Update Magnitude: 0.30455

Collected Steps per Second: 21,861.91009
Overall Steps per Second: 10,602.64034

Timestep Collection Time: 2.28800
Timestep Consumption Time: 2.42970
PPO Batch Consumption Time: 0.27869
Total Iteration Time: 4.71769

Cumulative Model Updates: 252,782
Cumulative Timesteps: 2,108,792,606

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 64,786.61173
Policy Entropy: 2.64576
Value Function Loss: 0.01171

Mean KL Divergence: 0.01103
SB3 Clip Fraction: 0.09462
Policy Update Magnitude: 0.28852
Value Function Update Magnitude: 0.30852

Collected Steps per Second: 22,121.97129
Overall Steps per Second: 10,483.32961

Timestep Collection Time: 2.26128
Timestep Consumption Time: 2.51049
PPO Batch Consumption Time: 0.29105
Total Iteration Time: 4.77177

Cumulative Model Updates: 252,788
Cumulative Timesteps: 2,108,842,630

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2108842630...
Checkpoint 2108842630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 74,556.27120
Policy Entropy: 2.62806
Value Function Loss: 0.01129

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.08686
Policy Update Magnitude: 0.28617
Value Function Update Magnitude: 0.28916

Collected Steps per Second: 21,550.00726
Overall Steps per Second: 10,384.84878

Timestep Collection Time: 2.32102
Timestep Consumption Time: 2.49542
PPO Batch Consumption Time: 0.29141
Total Iteration Time: 4.81644

Cumulative Model Updates: 252,794
Cumulative Timesteps: 2,108,892,648

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63,296.99549
Policy Entropy: 2.62305
Value Function Loss: 0.01185

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.07514
Policy Update Magnitude: 0.29043
Value Function Update Magnitude: 0.26821

Collected Steps per Second: 21,455.04026
Overall Steps per Second: 10,337.53701

Timestep Collection Time: 2.33185
Timestep Consumption Time: 2.50779
PPO Batch Consumption Time: 0.29296
Total Iteration Time: 4.83964

Cumulative Model Updates: 252,800
Cumulative Timesteps: 2,108,942,678

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2108942678...
Checkpoint 2108942678 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 71,903.70805
Policy Entropy: 2.60181
Value Function Loss: 0.01173

Mean KL Divergence: 0.00682
SB3 Clip Fraction: 0.06527
Policy Update Magnitude: 0.29487
Value Function Update Magnitude: 0.27184

Collected Steps per Second: 21,115.89055
Overall Steps per Second: 10,294.88180

Timestep Collection Time: 2.36864
Timestep Consumption Time: 2.48969
PPO Batch Consumption Time: 0.29281
Total Iteration Time: 4.85834

Cumulative Model Updates: 252,806
Cumulative Timesteps: 2,108,992,694

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 114,601.33626
Policy Entropy: 2.62506
Value Function Loss: 0.01284

Mean KL Divergence: 0.00674
SB3 Clip Fraction: 0.06446
Policy Update Magnitude: 0.29332
Value Function Update Magnitude: 0.28793

Collected Steps per Second: 21,089.97904
Overall Steps per Second: 10,342.09041

Timestep Collection Time: 2.37288
Timestep Consumption Time: 2.46599
PPO Batch Consumption Time: 0.29220
Total Iteration Time: 4.83887

Cumulative Model Updates: 252,812
Cumulative Timesteps: 2,109,042,738

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 2109042738...
Checkpoint 2109042738 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89,981.91340
Policy Entropy: 2.61442
Value Function Loss: 0.01352

Mean KL Divergence: 0.00653
SB3 Clip Fraction: 0.06250
Policy Update Magnitude: 0.29967
Value Function Update Magnitude: 0.28617

Collected Steps per Second: 20,778.72256
Overall Steps per Second: 10,343.92560

Timestep Collection Time: 2.40650
Timestep Consumption Time: 2.42764
PPO Batch Consumption Time: 0.29114
Total Iteration Time: 4.83414

Cumulative Model Updates: 252,818
Cumulative Timesteps: 2,109,092,742

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 109,848.43774
Policy Entropy: 2.60552
Value Function Loss: 0.01534

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.07414
Policy Update Magnitude: 0.30860
Value Function Update Magnitude: 0.26405

Collected Steps per Second: 21,217.75365
Overall Steps per Second: 10,488.50448

Timestep Collection Time: 2.35755
Timestep Consumption Time: 2.41167
PPO Batch Consumption Time: 0.28996
Total Iteration Time: 4.76922

Cumulative Model Updates: 252,824
Cumulative Timesteps: 2,109,142,764

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2109142764...
Checkpoint 2109142764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 100,030.71418
Policy Entropy: 2.59802
Value Function Loss: 0.01644

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.07251
Policy Update Magnitude: 0.31426
Value Function Update Magnitude: 0.26080

Collected Steps per Second: 21,080.34935
Overall Steps per Second: 10,409.31639

Timestep Collection Time: 2.37188
Timestep Consumption Time: 2.43151
PPO Batch Consumption Time: 0.27881
Total Iteration Time: 4.80339

Cumulative Model Updates: 252,830
Cumulative Timesteps: 2,109,192,764

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 100,030.71418
Policy Entropy: 2.60078
Value Function Loss: 0.01396

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.07693
Policy Update Magnitude: 0.31101
Value Function Update Magnitude: 0.24267

Collected Steps per Second: 22,202.92142
Overall Steps per Second: 10,516.12462

Timestep Collection Time: 2.25322
Timestep Consumption Time: 2.50405
PPO Batch Consumption Time: 0.29323
Total Iteration Time: 4.75727

Cumulative Model Updates: 252,836
Cumulative Timesteps: 2,109,242,792

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2109242792...
Checkpoint 2109242792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 111,488.08923
Policy Entropy: 2.59130
Value Function Loss: 0.01442

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.07975
Policy Update Magnitude: 0.30710
Value Function Update Magnitude: 0.25427

Collected Steps per Second: 22,014.97039
Overall Steps per Second: 10,634.82513

Timestep Collection Time: 2.27273
Timestep Consumption Time: 2.43201
PPO Batch Consumption Time: 0.28392
Total Iteration Time: 4.70473

Cumulative Model Updates: 252,842
Cumulative Timesteps: 2,109,292,826

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 121,604.84902
Policy Entropy: 2.59064
Value Function Loss: 0.01352

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.07742
Policy Update Magnitude: 0.30317
Value Function Update Magnitude: 0.27751

Collected Steps per Second: 22,332.57663
Overall Steps per Second: 10,563.51161

Timestep Collection Time: 2.24094
Timestep Consumption Time: 2.49669
PPO Batch Consumption Time: 0.29196
Total Iteration Time: 4.73763

Cumulative Model Updates: 252,848
Cumulative Timesteps: 2,109,342,872

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 2109342872...
Checkpoint 2109342872 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 124,453.00686
Policy Entropy: 2.58808
Value Function Loss: 0.01455

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.07553
Policy Update Magnitude: 0.30210
Value Function Update Magnitude: 0.25098

Collected Steps per Second: 21,510.06303
Overall Steps per Second: 10,496.26413

Timestep Collection Time: 2.32505
Timestep Consumption Time: 2.43969
PPO Batch Consumption Time: 0.27914
Total Iteration Time: 4.76474

Cumulative Model Updates: 252,854
Cumulative Timesteps: 2,109,392,884

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 101,430.40015
Policy Entropy: 2.57969
Value Function Loss: 0.01683

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.06938
Policy Update Magnitude: 0.31888
Value Function Update Magnitude: 0.23340

Collected Steps per Second: 22,338.56052
Overall Steps per Second: 10,561.01413

Timestep Collection Time: 2.23945
Timestep Consumption Time: 2.49741
PPO Batch Consumption Time: 0.29262
Total Iteration Time: 4.73686

Cumulative Model Updates: 252,860
Cumulative Timesteps: 2,109,442,910

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2109442910...
Checkpoint 2109442910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86,199.70701
Policy Entropy: 2.59500
Value Function Loss: 0.01695

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.07854
Policy Update Magnitude: 0.31122
Value Function Update Magnitude: 0.23253

Collected Steps per Second: 21,708.37180
Overall Steps per Second: 10,549.53241

Timestep Collection Time: 2.30455
Timestep Consumption Time: 2.43765
PPO Batch Consumption Time: 0.27952
Total Iteration Time: 4.74220

Cumulative Model Updates: 252,866
Cumulative Timesteps: 2,109,492,938

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 128,271.06077
Policy Entropy: 2.59855
Value Function Loss: 0.01638

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.07038
Policy Update Magnitude: 0.30395
Value Function Update Magnitude: 0.18498

Collected Steps per Second: 21,611.35082
Overall Steps per Second: 10,477.23357

Timestep Collection Time: 2.31462
Timestep Consumption Time: 2.45973
PPO Batch Consumption Time: 0.28469
Total Iteration Time: 4.77435

Cumulative Model Updates: 252,872
Cumulative Timesteps: 2,109,542,960

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2109542960...
Checkpoint 2109542960 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 98,418.51564
Policy Entropy: 2.61688
Value Function Loss: 0.01590

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.07674
Policy Update Magnitude: 0.30284
Value Function Update Magnitude: 0.16239

Collected Steps per Second: 21,459.11326
Overall Steps per Second: 10,557.35107

Timestep Collection Time: 2.33001
Timestep Consumption Time: 2.40602
PPO Batch Consumption Time: 0.27852
Total Iteration Time: 4.73604

Cumulative Model Updates: 252,878
Cumulative Timesteps: 2,109,592,960

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85,660.58230
Policy Entropy: 2.61910
Value Function Loss: 0.01711

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.07110
Policy Update Magnitude: 0.30862
Value Function Update Magnitude: 0.16299

Collected Steps per Second: 21,071.88638
Overall Steps per Second: 10,598.60870

Timestep Collection Time: 2.37425
Timestep Consumption Time: 2.34618
PPO Batch Consumption Time: 0.27702
Total Iteration Time: 4.72043

Cumulative Model Updates: 252,884
Cumulative Timesteps: 2,109,642,990

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2109642990...
Checkpoint 2109642990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89,909.26158
Policy Entropy: 2.61335
Value Function Loss: 0.01945

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.07849
Policy Update Magnitude: 0.31835
Value Function Update Magnitude: 0.15960

Collected Steps per Second: 21,368.47328
Overall Steps per Second: 10,537.85038

Timestep Collection Time: 2.34121
Timestep Consumption Time: 2.40625
PPO Batch Consumption Time: 0.28720
Total Iteration Time: 4.74746

Cumulative Model Updates: 252,890
Cumulative Timesteps: 2,109,693,018

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85,578.71830
Policy Entropy: 2.59495
Value Function Loss: 0.01911

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.07632
Policy Update Magnitude: 0.32695
Value Function Update Magnitude: 0.26651

Collected Steps per Second: 21,130.66689
Overall Steps per Second: 10,459.65724

Timestep Collection Time: 2.36651
Timestep Consumption Time: 2.41433
PPO Batch Consumption Time: 0.28411
Total Iteration Time: 4.78085

Cumulative Model Updates: 252,896
Cumulative Timesteps: 2,109,743,024

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2109743024...
Checkpoint 2109743024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 85,578.71830
Policy Entropy: 2.58710
Value Function Loss: 0.01762

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.08578
Policy Update Magnitude: 0.32124
Value Function Update Magnitude: 0.26411

Collected Steps per Second: 21,093.76518
Overall Steps per Second: 10,259.90901

Timestep Collection Time: 2.37189
Timestep Consumption Time: 2.50457
PPO Batch Consumption Time: 0.29363
Total Iteration Time: 4.87646

Cumulative Model Updates: 252,902
Cumulative Timesteps: 2,109,793,056

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95,215.75147
Policy Entropy: 2.59523
Value Function Loss: 0.01525

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.07699
Policy Update Magnitude: 0.31784
Value Function Update Magnitude: 0.20584

Collected Steps per Second: 22,121.28826
Overall Steps per Second: 10,557.89148

Timestep Collection Time: 2.26117
Timestep Consumption Time: 2.47652
PPO Batch Consumption Time: 0.29045
Total Iteration Time: 4.73769

Cumulative Model Updates: 252,908
Cumulative Timesteps: 2,109,843,076

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2109843076...
Checkpoint 2109843076 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 88,092.36363
Policy Entropy: 2.59453
Value Function Loss: 0.01397

Mean KL Divergence: 0.00763
SB3 Clip Fraction: 0.07430
Policy Update Magnitude: 0.31384
Value Function Update Magnitude: 0.19201

Collected Steps per Second: 21,789.03585
Overall Steps per Second: 10,447.20515

Timestep Collection Time: 2.29473
Timestep Consumption Time: 2.49124
PPO Batch Consumption Time: 0.29005
Total Iteration Time: 4.78597

Cumulative Model Updates: 252,914
Cumulative Timesteps: 2,109,893,076

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93,061.34118
Policy Entropy: 2.62777
Value Function Loss: 0.01351

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.06787
Policy Update Magnitude: 0.31193
Value Function Update Magnitude: 0.24022

Collected Steps per Second: 22,182.63702
Overall Steps per Second: 10,563.23200

Timestep Collection Time: 2.25483
Timestep Consumption Time: 2.48028
PPO Batch Consumption Time: 0.29310
Total Iteration Time: 4.73510

Cumulative Model Updates: 252,920
Cumulative Timesteps: 2,109,943,094

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2109943094...
Checkpoint 2109943094 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 100,871.76100
Policy Entropy: 2.62484
Value Function Loss: 0.01328

Mean KL Divergence: 0.00727
SB3 Clip Fraction: 0.06739
Policy Update Magnitude: 0.30270
Value Function Update Magnitude: 0.26414

Collected Steps per Second: 21,641.51647
Overall Steps per Second: 10,549.28201

Timestep Collection Time: 2.31074
Timestep Consumption Time: 2.42967
PPO Batch Consumption Time: 0.27840
Total Iteration Time: 4.74042

Cumulative Model Updates: 252,926
Cumulative Timesteps: 2,109,993,102

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 203,485.96860
Policy Entropy: 2.66167
Value Function Loss: 0.01227

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.07039
Policy Update Magnitude: 0.29393
Value Function Update Magnitude: 0.25936

Collected Steps per Second: 22,071.40566
Overall Steps per Second: 10,450.44261

Timestep Collection Time: 2.26646
Timestep Consumption Time: 2.52032
PPO Batch Consumption Time: 0.29192
Total Iteration Time: 4.78678

Cumulative Model Updates: 252,932
Cumulative Timesteps: 2,110,043,126

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2110043126...
Checkpoint 2110043126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 162,378.11235
Policy Entropy: 2.65825
Value Function Loss: 0.01250

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.07884
Policy Update Magnitude: 0.28820
Value Function Update Magnitude: 0.24398

Collected Steps per Second: 21,755.82761
Overall Steps per Second: 10,605.71473

Timestep Collection Time: 2.29888
Timestep Consumption Time: 2.41688
PPO Batch Consumption Time: 0.27726
Total Iteration Time: 4.71576

Cumulative Model Updates: 252,938
Cumulative Timesteps: 2,110,093,140

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 108,065.03831
Policy Entropy: 2.65773
Value Function Loss: 0.01333

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.08740
Policy Update Magnitude: 0.29754
Value Function Update Magnitude: 0.27940

Collected Steps per Second: 21,577.78306
Overall Steps per Second: 10,515.55264

Timestep Collection Time: 2.31794
Timestep Consumption Time: 2.43844
PPO Batch Consumption Time: 0.27892
Total Iteration Time: 4.75638

Cumulative Model Updates: 252,944
Cumulative Timesteps: 2,110,143,156

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2110143156...
Checkpoint 2110143156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 93,721.09471
Policy Entropy: 2.65213
Value Function Loss: 0.01474

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.09106
Policy Update Magnitude: 0.30550
Value Function Update Magnitude: 0.30889

Collected Steps per Second: 21,129.21841
Overall Steps per Second: 10,261.92334

Timestep Collection Time: 2.36781
Timestep Consumption Time: 2.50749
PPO Batch Consumption Time: 0.29341
Total Iteration Time: 4.87530

Cumulative Model Updates: 252,950
Cumulative Timesteps: 2,110,193,186

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80,375.43666
Policy Entropy: 2.60248
Value Function Loss: 0.01626

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.08044
Policy Update Magnitude: 0.31555
Value Function Update Magnitude: 0.30165

Collected Steps per Second: 21,764.83780
Overall Steps per Second: 10,404.47327

Timestep Collection Time: 2.29912
Timestep Consumption Time: 2.51035
PPO Batch Consumption Time: 0.29157
Total Iteration Time: 4.80947

Cumulative Model Updates: 252,956
Cumulative Timesteps: 2,110,243,226

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 2110243226...
Checkpoint 2110243226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 56,909.94502
Policy Entropy: 2.59295
Value Function Loss: 0.01568

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.07864
Policy Update Magnitude: 0.32314
Value Function Update Magnitude: 0.30363

Collected Steps per Second: 21,643.03053
Overall Steps per Second: 10,550.51254

Timestep Collection Time: 2.31114
Timestep Consumption Time: 2.42987
PPO Batch Consumption Time: 0.27880
Total Iteration Time: 4.74100

Cumulative Model Updates: 252,962
Cumulative Timesteps: 2,110,293,246

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48,554.96339
Policy Entropy: 2.56846
Value Function Loss: 0.01497

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.08203
Policy Update Magnitude: 0.31836
Value Function Update Magnitude: 0.33508

Collected Steps per Second: 21,371.82741
Overall Steps per Second: 10,468.64025

Timestep Collection Time: 2.34018
Timestep Consumption Time: 2.43732
PPO Batch Consumption Time: 0.27816
Total Iteration Time: 4.77751

Cumulative Model Updates: 252,968
Cumulative Timesteps: 2,110,343,260

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2110343260...
Checkpoint 2110343260 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 113,092.40325
Policy Entropy: 2.60266
Value Function Loss: 0.01406

Mean KL Divergence: 0.00703
SB3 Clip Fraction: 0.06435
Policy Update Magnitude: 0.32252
Value Function Update Magnitude: 0.33650

Collected Steps per Second: 21,813.98842
Overall Steps per Second: 10,368.65946

Timestep Collection Time: 2.29330
Timestep Consumption Time: 2.53143
PPO Batch Consumption Time: 0.29314
Total Iteration Time: 4.82473

Cumulative Model Updates: 252,974
Cumulative Timesteps: 2,110,393,286

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77,527.78949
Policy Entropy: 2.60480
Value Function Loss: 0.01440

Mean KL Divergence: 0.00671
SB3 Clip Fraction: 0.06603
Policy Update Magnitude: 0.32182
Value Function Update Magnitude: 0.29002

Collected Steps per Second: 22,069.12866
Overall Steps per Second: 10,544.91086

Timestep Collection Time: 2.26579
Timestep Consumption Time: 2.47621
PPO Batch Consumption Time: 0.28814
Total Iteration Time: 4.74200

Cumulative Model Updates: 252,980
Cumulative Timesteps: 2,110,443,290

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2110443290...
Checkpoint 2110443290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 68,452.19642
Policy Entropy: 2.62631
Value Function Loss: 0.01415

Mean KL Divergence: 0.00674
SB3 Clip Fraction: 0.06463
Policy Update Magnitude: 0.31506
Value Function Update Magnitude: 0.26481

Collected Steps per Second: 22,098.23462
Overall Steps per Second: 10,508.36948

Timestep Collection Time: 2.26299
Timestep Consumption Time: 2.49589
PPO Batch Consumption Time: 0.29424
Total Iteration Time: 4.75887

Cumulative Model Updates: 252,986
Cumulative Timesteps: 2,110,493,298

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89,906.45088
Policy Entropy: 2.60780
Value Function Loss: 0.01581

Mean KL Divergence: 0.00725
SB3 Clip Fraction: 0.06909
Policy Update Magnitude: 0.30747
Value Function Update Magnitude: 0.28521

Collected Steps per Second: 21,492.58451
Overall Steps per Second: 10,565.11496

Timestep Collection Time: 2.32759
Timestep Consumption Time: 2.40742
PPO Batch Consumption Time: 0.29050
Total Iteration Time: 4.73502

Cumulative Model Updates: 252,992
Cumulative Timesteps: 2,110,543,324

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2110543324...
Checkpoint 2110543324 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 67,983.99980
Policy Entropy: 2.60387
Value Function Loss: 0.01529

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.07577
Policy Update Magnitude: 0.31150
Value Function Update Magnitude: 0.28809

Collected Steps per Second: 21,232.62987
Overall Steps per Second: 10,477.55007

Timestep Collection Time: 2.35637
Timestep Consumption Time: 2.41879
PPO Batch Consumption Time: 0.29087
Total Iteration Time: 4.77516

Cumulative Model Updates: 252,998
Cumulative Timesteps: 2,110,593,356

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52,909.35690
Policy Entropy: 2.60830
Value Function Loss: 0.01619

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.08644
Policy Update Magnitude: 0.31327
Value Function Update Magnitude: 0.30559

Collected Steps per Second: 21,441.62628
Overall Steps per Second: 10,453.59522

Timestep Collection Time: 2.33219
Timestep Consumption Time: 2.45142
PPO Batch Consumption Time: 0.28483
Total Iteration Time: 4.78362

Cumulative Model Updates: 253,004
Cumulative Timesteps: 2,110,643,362

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2110643362...
Checkpoint 2110643362 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 74,371.65412
Policy Entropy: 2.64029
Value Function Loss: 0.01543

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.07990
Policy Update Magnitude: 0.30809
Value Function Update Magnitude: 0.34980

Collected Steps per Second: 21,725.00690
Overall Steps per Second: 10,614.13191

Timestep Collection Time: 2.30205
Timestep Consumption Time: 2.40978
PPO Batch Consumption Time: 0.27837
Total Iteration Time: 4.71183

Cumulative Model Updates: 253,010
Cumulative Timesteps: 2,110,693,374

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76,914.04543
Policy Entropy: 2.66400
Value Function Loss: 0.01360

Mean KL Divergence: 0.00740
SB3 Clip Fraction: 0.06686
Policy Update Magnitude: 0.29946
Value Function Update Magnitude: 0.32172

Collected Steps per Second: 21,191.07253
Overall Steps per Second: 10,531.90213

Timestep Collection Time: 2.35977
Timestep Consumption Time: 2.38828
PPO Batch Consumption Time: 0.27624
Total Iteration Time: 4.74805

Cumulative Model Updates: 253,016
Cumulative Timesteps: 2,110,743,380

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2110743380...
Checkpoint 2110743380 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 76,914.04543
Policy Entropy: 2.66101
Value Function Loss: 0.01223

Mean KL Divergence: 0.00641
SB3 Clip Fraction: 0.06198
Policy Update Magnitude: 0.28418
Value Function Update Magnitude: 0.28068

Collected Steps per Second: 21,590.66045
Overall Steps per Second: 10,554.56621

Timestep Collection Time: 2.31711
Timestep Consumption Time: 2.42283
PPO Batch Consumption Time: 0.27877
Total Iteration Time: 4.73994

Cumulative Model Updates: 253,022
Cumulative Timesteps: 2,110,793,408

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 103,573.11482
Policy Entropy: 2.63049
Value Function Loss: 0.01163

Mean KL Divergence: 0.00577
SB3 Clip Fraction: 0.05699
Policy Update Magnitude: 0.29027
Value Function Update Magnitude: 0.26997

Collected Steps per Second: 21,467.62664
Overall Steps per Second: 10,478.32607

Timestep Collection Time: 2.32983
Timestep Consumption Time: 2.44345
PPO Batch Consumption Time: 0.27869
Total Iteration Time: 4.77328

Cumulative Model Updates: 253,028
Cumulative Timesteps: 2,110,843,424

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2110843424...
Checkpoint 2110843424 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 82,778.86690
Policy Entropy: 2.61514
Value Function Loss: 0.01283

Mean KL Divergence: 0.00741
SB3 Clip Fraction: 0.06618
Policy Update Magnitude: 0.31044
Value Function Update Magnitude: 0.29554

Collected Steps per Second: 21,515.43756
Overall Steps per Second: 10,378.03140

Timestep Collection Time: 2.32512
Timestep Consumption Time: 2.49525
PPO Batch Consumption Time: 0.29094
Total Iteration Time: 4.82037

Cumulative Model Updates: 253,034
Cumulative Timesteps: 2,110,893,450

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91,939.47910
Policy Entropy: 2.62150
Value Function Loss: 0.01302

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.07088
Policy Update Magnitude: 0.30890
Value Function Update Magnitude: 0.32749

Collected Steps per Second: 20,441.40370
Overall Steps per Second: 10,267.41446

Timestep Collection Time: 2.44680
Timestep Consumption Time: 2.42453
PPO Batch Consumption Time: 0.27838
Total Iteration Time: 4.87133

Cumulative Model Updates: 253,040
Cumulative Timesteps: 2,110,943,466

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2110943466...
Checkpoint 2110943466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86,637.20875
Policy Entropy: 2.64889
Value Function Loss: 0.01223

Mean KL Divergence: 0.00749
SB3 Clip Fraction: 0.06597
Policy Update Magnitude: 0.29856
Value Function Update Magnitude: 0.28796

Collected Steps per Second: 21,333.46520
Overall Steps per Second: 10,332.26627

Timestep Collection Time: 2.34580
Timestep Consumption Time: 2.49767
PPO Batch Consumption Time: 0.29310
Total Iteration Time: 4.84347

Cumulative Model Updates: 253,046
Cumulative Timesteps: 2,110,993,510

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 102,018.47505
Policy Entropy: 2.65961
Value Function Loss: 0.01205

Mean KL Divergence: 0.00678
SB3 Clip Fraction: 0.06733
Policy Update Magnitude: 0.28674
Value Function Update Magnitude: 0.26323

Collected Steps per Second: 21,557.08089
Overall Steps per Second: 10,361.36938

Timestep Collection Time: 2.32063
Timestep Consumption Time: 2.50750
PPO Batch Consumption Time: 0.29331
Total Iteration Time: 4.82813

Cumulative Model Updates: 253,052
Cumulative Timesteps: 2,111,043,536

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2111043536...
Checkpoint 2111043536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 109,095.83937
Policy Entropy: 2.66306
Value Function Loss: 0.01121

Mean KL Divergence: 0.00680
SB3 Clip Fraction: 0.06875
Policy Update Magnitude: 0.27920
Value Function Update Magnitude: 0.24042

Collected Steps per Second: 20,919.50521
Overall Steps per Second: 10,551.98282

Timestep Collection Time: 2.39031
Timestep Consumption Time: 2.34852
PPO Batch Consumption Time: 0.27879
Total Iteration Time: 4.73883

Cumulative Model Updates: 253,058
Cumulative Timesteps: 2,111,093,540

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83,525.07414
Policy Entropy: 2.64419
Value Function Loss: 0.01294

Mean KL Divergence: 0.00716
SB3 Clip Fraction: 0.07009
Policy Update Magnitude: 0.27278
Value Function Update Magnitude: 0.24545

Collected Steps per Second: 21,452.27651
Overall Steps per Second: 10,549.51901

Timestep Collection Time: 2.33271
Timestep Consumption Time: 2.41082
PPO Batch Consumption Time: 0.28423
Total Iteration Time: 4.74353

Cumulative Model Updates: 253,064
Cumulative Timesteps: 2,111,143,582

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 2111143582...
Checkpoint 2111143582 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 68,287.82603
Policy Entropy: 2.62451
Value Function Loss: 0.01443

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.07665
Policy Update Magnitude: 0.28211
Value Function Update Magnitude: 0.24271

Collected Steps per Second: 21,388.81057
Overall Steps per Second: 10,629.91793

Timestep Collection Time: 2.33907
Timestep Consumption Time: 2.36745
PPO Batch Consumption Time: 0.27869
Total Iteration Time: 4.70653

Cumulative Model Updates: 253,070
Cumulative Timesteps: 2,111,193,612

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88,296.86457
Policy Entropy: 2.61926
Value Function Loss: 0.01351

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.08477
Policy Update Magnitude: 0.28968
Value Function Update Magnitude: 0.25669

Collected Steps per Second: 21,537.52861
Overall Steps per Second: 10,445.10902

Timestep Collection Time: 2.32255
Timestep Consumption Time: 2.46649
PPO Batch Consumption Time: 0.28882
Total Iteration Time: 4.78904

Cumulative Model Updates: 253,076
Cumulative Timesteps: 2,111,243,634

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2111243634...
Checkpoint 2111243634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 62,217.06874
Policy Entropy: 2.61151
Value Function Loss: 0.01503

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.08189
Policy Update Magnitude: 0.29757
Value Function Update Magnitude: 0.29322

Collected Steps per Second: 21,989.87147
Overall Steps per Second: 10,698.48716

Timestep Collection Time: 2.27468
Timestep Consumption Time: 2.40074
PPO Batch Consumption Time: 0.27747
Total Iteration Time: 4.67543

Cumulative Model Updates: 253,082
Cumulative Timesteps: 2,111,293,654

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45,527.15862
Policy Entropy: 2.62770
Value Function Loss: 0.01373

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.08179
Policy Update Magnitude: 0.30473
Value Function Update Magnitude: 0.29606

Collected Steps per Second: 22,193.21323
Overall Steps per Second: 10,599.78527

Timestep Collection Time: 2.25447
Timestep Consumption Time: 2.46581
PPO Batch Consumption Time: 0.28935
Total Iteration Time: 4.72028

Cumulative Model Updates: 253,088
Cumulative Timesteps: 2,111,343,688

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 2111343688...
Checkpoint 2111343688 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,718.77268
Policy Entropy: 2.62849
Value Function Loss: 0.01369

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.08054
Policy Update Magnitude: 0.29748
Value Function Update Magnitude: 0.28118

Collected Steps per Second: 22,247.28439
Overall Steps per Second: 10,527.52985

Timestep Collection Time: 2.24836
Timestep Consumption Time: 2.50299
PPO Batch Consumption Time: 0.29328
Total Iteration Time: 4.75135

Cumulative Model Updates: 253,094
Cumulative Timesteps: 2,111,393,708

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,969.49282
Policy Entropy: 2.61208
Value Function Loss: 0.01430

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.07517
Policy Update Magnitude: 0.32094
Value Function Update Magnitude: 0.29055

Collected Steps per Second: 21,555.05256
Overall Steps per Second: 10,374.48915

Timestep Collection Time: 2.32066
Timestep Consumption Time: 2.50097
PPO Batch Consumption Time: 0.29084
Total Iteration Time: 4.82164

Cumulative Model Updates: 253,100
Cumulative Timesteps: 2,111,443,730

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2111443730...
Checkpoint 2111443730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 137,976.97494
Policy Entropy: 2.58906
Value Function Loss: 0.01392

Mean KL Divergence: 0.01083
SB3 Clip Fraction: 0.09619
Policy Update Magnitude: 0.31764
Value Function Update Magnitude: 0.29685

Collected Steps per Second: 21,539.34001
Overall Steps per Second: 10,532.14348

Timestep Collection Time: 2.32152
Timestep Consumption Time: 2.42623
PPO Batch Consumption Time: 0.27869
Total Iteration Time: 4.74775

Cumulative Model Updates: 253,106
Cumulative Timesteps: 2,111,493,734

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 123,661.84545
Policy Entropy: 2.55958
Value Function Loss: 0.01537

Mean KL Divergence: 0.01135
SB3 Clip Fraction: 0.09378
Policy Update Magnitude: 0.32922
Value Function Update Magnitude: 0.28753

Collected Steps per Second: 21,772.97401
Overall Steps per Second: 10,609.89004

Timestep Collection Time: 2.29688
Timestep Consumption Time: 2.41664
PPO Batch Consumption Time: 0.27657
Total Iteration Time: 4.71353

Cumulative Model Updates: 253,112
Cumulative Timesteps: 2,111,543,744

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2111543744...
Checkpoint 2111543744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 50,119.89406
Policy Entropy: 2.59175
Value Function Loss: 0.01646

Mean KL Divergence: 0.01156
SB3 Clip Fraction: 0.10344
Policy Update Magnitude: 0.33149
Value Function Update Magnitude: 0.31162

Collected Steps per Second: 21,654.60762
Overall Steps per Second: 10,516.83630

Timestep Collection Time: 2.31082
Timestep Consumption Time: 2.44726
PPO Batch Consumption Time: 0.27828
Total Iteration Time: 4.75808

Cumulative Model Updates: 253,118
Cumulative Timesteps: 2,111,593,784

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50,119.89406
Policy Entropy: 2.59143
Value Function Loss: 0.01517

Mean KL Divergence: 0.01060
SB3 Clip Fraction: 0.09227
Policy Update Magnitude: 0.32485
Value Function Update Magnitude: 0.30477

Collected Steps per Second: 22,017.69719
Overall Steps per Second: 10,504.56022

Timestep Collection Time: 2.27135
Timestep Consumption Time: 2.48943
PPO Batch Consumption Time: 0.28646
Total Iteration Time: 4.76079

Cumulative Model Updates: 253,124
Cumulative Timesteps: 2,111,643,794

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2111643794...
Checkpoint 2111643794 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86,851.28584
Policy Entropy: 2.62277
Value Function Loss: 0.01491

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.08408
Policy Update Magnitude: 0.31274
Value Function Update Magnitude: 0.29644

Collected Steps per Second: 22,082.50122
Overall Steps per Second: 10,663.41001

Timestep Collection Time: 2.26442
Timestep Consumption Time: 2.42489
PPO Batch Consumption Time: 0.27828
Total Iteration Time: 4.68931

Cumulative Model Updates: 253,130
Cumulative Timesteps: 2,111,693,798

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 72,997.83476
Policy Entropy: 2.60832
Value Function Loss: 0.01306

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.07265
Policy Update Magnitude: 0.29785
Value Function Update Magnitude: 0.26106

Collected Steps per Second: 21,406.88840
Overall Steps per Second: 10,490.47478

Timestep Collection Time: 2.33682
Timestep Consumption Time: 2.43170
PPO Batch Consumption Time: 0.29358
Total Iteration Time: 4.76852

Cumulative Model Updates: 253,136
Cumulative Timesteps: 2,111,743,822

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2111743822...
Checkpoint 2111743822 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 67,900.48099
Policy Entropy: 2.63692
Value Function Loss: 0.01239

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.08034
Policy Update Magnitude: 0.28960
Value Function Update Magnitude: 0.22945

Collected Steps per Second: 21,485.19319
Overall Steps per Second: 10,621.29094

Timestep Collection Time: 2.32793
Timestep Consumption Time: 2.38110
PPO Batch Consumption Time: 0.28557
Total Iteration Time: 4.70903

Cumulative Model Updates: 253,142
Cumulative Timesteps: 2,111,793,838

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81,264.42997
Policy Entropy: 2.62157
Value Function Loss: 0.01285

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.07898
Policy Update Magnitude: 0.29321
Value Function Update Magnitude: 0.23627

Collected Steps per Second: 21,358.86785
Overall Steps per Second: 10,476.34895

Timestep Collection Time: 2.34132
Timestep Consumption Time: 2.43210
PPO Batch Consumption Time: 0.29252
Total Iteration Time: 4.77342

Cumulative Model Updates: 253,148
Cumulative Timesteps: 2,111,843,846

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2111843846...
Checkpoint 2111843846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 78,477.12409
Policy Entropy: 2.63143
Value Function Loss: 0.01211

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.08149
Policy Update Magnitude: 0.28681
Value Function Update Magnitude: 0.26006

Collected Steps per Second: 21,329.16513
Overall Steps per Second: 10,531.71960

Timestep Collection Time: 2.34486
Timestep Consumption Time: 2.40403
PPO Batch Consumption Time: 0.27854
Total Iteration Time: 4.74889

Cumulative Model Updates: 253,154
Cumulative Timesteps: 2,111,893,860

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80,585.74164
Policy Entropy: 2.63426
Value Function Loss: 0.01397

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.08892
Policy Update Magnitude: 0.29360
Value Function Update Magnitude: 0.29368

Collected Steps per Second: 21,445.17474
Overall Steps per Second: 10,587.05793

Timestep Collection Time: 2.33181
Timestep Consumption Time: 2.39151
PPO Batch Consumption Time: 0.27620
Total Iteration Time: 4.72331

Cumulative Model Updates: 253,160
Cumulative Timesteps: 2,111,943,866

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2111943866...
Checkpoint 2111943866 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 90,918.67105
Policy Entropy: 2.64089
Value Function Loss: 0.01342

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.09160
Policy Update Magnitude: 0.30262
Value Function Update Magnitude: 0.32893

Collected Steps per Second: 21,093.64048
Overall Steps per Second: 10,486.68197

Timestep Collection Time: 2.37114
Timestep Consumption Time: 2.39834
PPO Batch Consumption Time: 0.27832
Total Iteration Time: 4.76948

Cumulative Model Updates: 253,166
Cumulative Timesteps: 2,111,993,882

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 111,451.03714
Policy Entropy: 2.64201
Value Function Loss: 0.01457

Mean KL Divergence: 0.01074
SB3 Clip Fraction: 0.09422
Policy Update Magnitude: 0.30801
Value Function Update Magnitude: 0.33224

Collected Steps per Second: 21,766.29835
Overall Steps per Second: 10,588.85976

Timestep Collection Time: 2.29851
Timestep Consumption Time: 2.42627
PPO Batch Consumption Time: 0.27693
Total Iteration Time: 4.72478

Cumulative Model Updates: 253,172
Cumulative Timesteps: 2,112,043,912

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2112043912...
Checkpoint 2112043912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 112,301.39605
Policy Entropy: 2.61832
Value Function Loss: 0.01549

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.08468
Policy Update Magnitude: 0.32142
Value Function Update Magnitude: 0.33702

Collected Steps per Second: 21,472.30311
Overall Steps per Second: 10,497.78307

Timestep Collection Time: 2.32979
Timestep Consumption Time: 2.43560
PPO Batch Consumption Time: 0.27822
Total Iteration Time: 4.76539

Cumulative Model Updates: 253,178
Cumulative Timesteps: 2,112,093,938

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 123,955.60574
Policy Entropy: 2.63288
Value Function Loss: 0.01547

Mean KL Divergence: 0.01241
SB3 Clip Fraction: 0.10225
Policy Update Magnitude: 0.31437
Value Function Update Magnitude: 0.29137

Collected Steps per Second: 22,192.14401
Overall Steps per Second: 10,490.82236

Timestep Collection Time: 2.25368
Timestep Consumption Time: 2.51372
PPO Batch Consumption Time: 0.28731
Total Iteration Time: 4.76741

Cumulative Model Updates: 253,184
Cumulative Timesteps: 2,112,143,952

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2112143952...
Checkpoint 2112143952 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 119,972.98844
Policy Entropy: 2.63575
Value Function Loss: 0.01516

Mean KL Divergence: 0.01208
SB3 Clip Fraction: 0.09708
Policy Update Magnitude: 0.30678
Value Function Update Magnitude: 0.24391

Collected Steps per Second: 22,083.97641
Overall Steps per Second: 10,631.60236

Timestep Collection Time: 2.26535
Timestep Consumption Time: 2.44024
PPO Batch Consumption Time: 0.27882
Total Iteration Time: 4.70559

Cumulative Model Updates: 253,190
Cumulative Timesteps: 2,112,193,980

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80,856.72746
Policy Entropy: 2.64582
Value Function Loss: 0.01490

Mean KL Divergence: 0.01201
SB3 Clip Fraction: 0.09884
Policy Update Magnitude: 0.30739
Value Function Update Magnitude: 0.27225

Collected Steps per Second: 22,088.12023
Overall Steps per Second: 10,459.65439

Timestep Collection Time: 2.26393
Timestep Consumption Time: 2.51691
PPO Batch Consumption Time: 0.28822
Total Iteration Time: 4.78085

Cumulative Model Updates: 253,196
Cumulative Timesteps: 2,112,243,986

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2112243986...
Checkpoint 2112243986 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 62,069.49729
Policy Entropy: 2.61153
Value Function Loss: 0.01637

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.08830
Policy Update Magnitude: 0.30932
Value Function Update Magnitude: 0.30286

Collected Steps per Second: 21,756.35312
Overall Steps per Second: 10,576.88473

Timestep Collection Time: 2.29891
Timestep Consumption Time: 2.42989
PPO Batch Consumption Time: 0.27911
Total Iteration Time: 4.72880

Cumulative Model Updates: 253,202
Cumulative Timesteps: 2,112,294,002

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58,296.62373
Policy Entropy: 2.61008
Value Function Loss: 0.01514

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.08538
Policy Update Magnitude: 0.31535
Value Function Update Magnitude: 0.33178

Collected Steps per Second: 22,124.48885
Overall Steps per Second: 10,539.91824

Timestep Collection Time: 2.26057
Timestep Consumption Time: 2.48463
PPO Batch Consumption Time: 0.28971
Total Iteration Time: 4.74520

Cumulative Model Updates: 253,208
Cumulative Timesteps: 2,112,344,016

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2112344016...
Checkpoint 2112344016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 58,296.62373
Policy Entropy: 2.63797
Value Function Loss: 0.01268

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.07802
Policy Update Magnitude: 0.31014
Value Function Update Magnitude: 0.31491

Collected Steps per Second: 21,996.70089
Overall Steps per Second: 10,685.92169

Timestep Collection Time: 2.27370
Timestep Consumption Time: 2.40666
PPO Batch Consumption Time: 0.27768
Total Iteration Time: 4.68036

Cumulative Model Updates: 253,214
Cumulative Timesteps: 2,112,394,030

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 94,490.91960
Policy Entropy: 2.66586
Value Function Loss: 0.01161

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.07162
Policy Update Magnitude: 0.29091
Value Function Update Magnitude: 0.28523

Collected Steps per Second: 21,908.54445
Overall Steps per Second: 10,458.43942

Timestep Collection Time: 2.28221
Timestep Consumption Time: 2.49861
PPO Batch Consumption Time: 0.29274
Total Iteration Time: 4.78083

Cumulative Model Updates: 253,220
Cumulative Timesteps: 2,112,444,030

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2112444030...
Checkpoint 2112444030 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 71,814.13483
Policy Entropy: 2.67178
Value Function Loss: 0.01133

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.06978
Policy Update Magnitude: 0.27489
Value Function Update Magnitude: 0.25075

Collected Steps per Second: 20,672.69733
Overall Steps per Second: 10,506.84904

Timestep Collection Time: 2.41894
Timestep Consumption Time: 2.34043
PPO Batch Consumption Time: 0.27810
Total Iteration Time: 4.75937

Cumulative Model Updates: 253,226
Cumulative Timesteps: 2,112,494,036

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62,806.33109
Policy Entropy: 2.68283
Value Function Loss: 0.01280

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.07022
Policy Update Magnitude: 0.27688
Value Function Update Magnitude: 0.24719

Collected Steps per Second: 21,317.43414
Overall Steps per Second: 10,525.26028

Timestep Collection Time: 2.34625
Timestep Consumption Time: 2.40575
PPO Batch Consumption Time: 0.28766
Total Iteration Time: 4.75200

Cumulative Model Updates: 253,232
Cumulative Timesteps: 2,112,544,052

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2112544052...
Checkpoint 2112544052 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55,781.29392
Policy Entropy: 2.67932
Value Function Loss: 0.01295

Mean KL Divergence: 0.00613
SB3 Clip Fraction: 0.06017
Policy Update Magnitude: 0.28474
Value Function Update Magnitude: 0.27434

Collected Steps per Second: 20,873.03873
Overall Steps per Second: 10,563.81083

Timestep Collection Time: 2.39687
Timestep Consumption Time: 2.33911
PPO Batch Consumption Time: 0.27856
Total Iteration Time: 4.73598

Cumulative Model Updates: 253,238
Cumulative Timesteps: 2,112,594,082

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95,868.55191
Policy Entropy: 2.66358
Value Function Loss: 0.01388

Mean KL Divergence: 0.00638
SB3 Clip Fraction: 0.06054
Policy Update Magnitude: 0.29182
Value Function Update Magnitude: 0.33303

Collected Steps per Second: 21,309.13848
Overall Steps per Second: 10,471.46251

Timestep Collection Time: 2.34651
Timestep Consumption Time: 2.42857
PPO Batch Consumption Time: 0.27919
Total Iteration Time: 4.77507

Cumulative Model Updates: 253,244
Cumulative Timesteps: 2,112,644,084

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2112644084...
Checkpoint 2112644084 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 88,872.84287
Policy Entropy: 2.63431
Value Function Loss: 0.01304

Mean KL Divergence: 0.00633
SB3 Clip Fraction: 0.05947
Policy Update Magnitude: 0.30353
Value Function Update Magnitude: 0.36968

Collected Steps per Second: 21,849.66768
Overall Steps per Second: 10,427.31520

Timestep Collection Time: 2.28910
Timestep Consumption Time: 2.50754
PPO Batch Consumption Time: 0.29044
Total Iteration Time: 4.79663

Cumulative Model Updates: 253,250
Cumulative Timesteps: 2,112,694,100

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 100,946.37384
Policy Entropy: 2.62432
Value Function Loss: 0.01562

Mean KL Divergence: 0.00706
SB3 Clip Fraction: 0.06568
Policy Update Magnitude: 0.31959
Value Function Update Magnitude: 0.38450

Collected Steps per Second: 22,253.97237
Overall Steps per Second: 10,722.26295

Timestep Collection Time: 2.24769
Timestep Consumption Time: 2.41737
PPO Batch Consumption Time: 0.27951
Total Iteration Time: 4.66506

Cumulative Model Updates: 253,256
Cumulative Timesteps: 2,112,744,120

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2112744120...
Checkpoint 2112744120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 107,545.73699
Policy Entropy: 2.64312
Value Function Loss: 0.01520

Mean KL Divergence: 0.00619
SB3 Clip Fraction: 0.05603
Policy Update Magnitude: 0.32115
Value Function Update Magnitude: 0.39705

Collected Steps per Second: 21,764.33236
Overall Steps per Second: 10,581.07725

Timestep Collection Time: 2.29908
Timestep Consumption Time: 2.42993
PPO Batch Consumption Time: 0.27958
Total Iteration Time: 4.72901

Cumulative Model Updates: 253,262
Cumulative Timesteps: 2,112,794,158

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53,915.10019
Policy Entropy: 2.64900
Value Function Loss: 0.01522

Mean KL Divergence: 0.00701
SB3 Clip Fraction: 0.06404
Policy Update Magnitude: 0.31377
Value Function Update Magnitude: 0.38468

Collected Steps per Second: 21,760.84197
Overall Steps per Second: 10,570.95760

Timestep Collection Time: 2.29982
Timestep Consumption Time: 2.43447
PPO Batch Consumption Time: 0.27795
Total Iteration Time: 4.73429

Cumulative Model Updates: 253,268
Cumulative Timesteps: 2,112,844,204

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 2112844204...
Checkpoint 2112844204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,851.39704
Policy Entropy: 2.65739
Value Function Loss: 0.01380

Mean KL Divergence: 0.00623
SB3 Clip Fraction: 0.05999
Policy Update Magnitude: 0.30914
Value Function Update Magnitude: 0.34954

Collected Steps per Second: 21,577.62760
Overall Steps per Second: 10,525.34134

Timestep Collection Time: 2.31796
Timestep Consumption Time: 2.43400
PPO Batch Consumption Time: 0.27769
Total Iteration Time: 4.75196

Cumulative Model Updates: 253,274
Cumulative Timesteps: 2,112,894,220

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53,387.10163
Policy Entropy: 2.66869
Value Function Loss: 0.01486

Mean KL Divergence: 0.00700
SB3 Clip Fraction: 0.06518
Policy Update Magnitude: 0.30635
Value Function Update Magnitude: 0.33253

Collected Steps per Second: 22,364.50395
Overall Steps per Second: 10,532.34254

Timestep Collection Time: 2.23658
Timestep Consumption Time: 2.51260
PPO Batch Consumption Time: 0.29327
Total Iteration Time: 4.74918

Cumulative Model Updates: 253,280
Cumulative Timesteps: 2,112,944,240

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2112944240...
Checkpoint 2112944240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 53,387.10163
Policy Entropy: 2.64668
Value Function Loss: 0.01423

Mean KL Divergence: 0.00701
SB3 Clip Fraction: 0.06619
Policy Update Magnitude: 0.30632
Value Function Update Magnitude: 0.32447

Collected Steps per Second: 21,674.63249
Overall Steps per Second: 10,575.73975

Timestep Collection Time: 2.30786
Timestep Consumption Time: 2.42202
PPO Batch Consumption Time: 0.27873
Total Iteration Time: 4.72988

Cumulative Model Updates: 253,286
Cumulative Timesteps: 2,112,994,262

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,518.92379
Policy Entropy: 2.66741
Value Function Loss: 0.01465

Mean KL Divergence: 0.00667
SB3 Clip Fraction: 0.06199
Policy Update Magnitude: 0.30189
Value Function Update Magnitude: 0.32308

Collected Steps per Second: 21,465.18057
Overall Steps per Second: 10,499.92872

Timestep Collection Time: 2.32973
Timestep Consumption Time: 2.43297
PPO Batch Consumption Time: 0.27842
Total Iteration Time: 4.76270

Cumulative Model Updates: 253,292
Cumulative Timesteps: 2,113,044,270

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2113044270...
Checkpoint 2113044270 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 54,800.24122
Policy Entropy: 2.64692
Value Function Loss: 0.01594

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.07156
Policy Update Magnitude: 0.30916
Value Function Update Magnitude: 0.34015

Collected Steps per Second: 21,327.97216
Overall Steps per Second: 10,292.64263

Timestep Collection Time: 2.34556
Timestep Consumption Time: 2.51481
PPO Batch Consumption Time: 0.29389
Total Iteration Time: 4.86037

Cumulative Model Updates: 253,298
Cumulative Timesteps: 2,113,094,296

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 147,482.92495
Policy Entropy: 2.63967
Value Function Loss: 0.01793

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.07203
Policy Update Magnitude: 0.32068
Value Function Update Magnitude: 0.35851

Collected Steps per Second: 21,805.01535
Overall Steps per Second: 10,406.92897

Timestep Collection Time: 2.29498
Timestep Consumption Time: 2.51355
PPO Batch Consumption Time: 0.29250
Total Iteration Time: 4.80853

Cumulative Model Updates: 253,304
Cumulative Timesteps: 2,113,144,338

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 2113144338...
Checkpoint 2113144338 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 128,821.13564
Policy Entropy: 2.64176
Value Function Loss: 0.01596

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.07699
Policy Update Magnitude: 0.31580
Value Function Update Magnitude: 0.36015

Collected Steps per Second: 22,028.69800
Overall Steps per Second: 10,557.69982

Timestep Collection Time: 2.27040
Timestep Consumption Time: 2.46680
PPO Batch Consumption Time: 0.27888
Total Iteration Time: 4.73721

Cumulative Model Updates: 253,310
Cumulative Timesteps: 2,113,194,352

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78,787.11207
Policy Entropy: 2.66020
Value Function Loss: 0.01406

Mean KL Divergence: 0.00733
SB3 Clip Fraction: 0.07062
Policy Update Magnitude: 0.30183
Value Function Update Magnitude: 0.35428

Collected Steps per Second: 22,325.65632
Overall Steps per Second: 10,427.29339

Timestep Collection Time: 2.23967
Timestep Consumption Time: 2.55563
PPO Batch Consumption Time: 0.29553
Total Iteration Time: 4.79530

Cumulative Model Updates: 253,316
Cumulative Timesteps: 2,113,244,354

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2113244354...
Checkpoint 2113244354 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 83,830.59832
Policy Entropy: 2.68140
Value Function Loss: 0.01193

Mean KL Divergence: 0.00680
SB3 Clip Fraction: 0.06601
Policy Update Magnitude: 0.29226
Value Function Update Magnitude: 0.32752

Collected Steps per Second: 21,380.22930
Overall Steps per Second: 10,283.66140

Timestep Collection Time: 2.33870
Timestep Consumption Time: 2.52357
PPO Batch Consumption Time: 0.29397
Total Iteration Time: 4.86228

Cumulative Model Updates: 253,322
Cumulative Timesteps: 2,113,294,356

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76,885.04788
Policy Entropy: 2.67032
Value Function Loss: 0.01143

Mean KL Divergence: 0.00664
SB3 Clip Fraction: 0.06380
Policy Update Magnitude: 0.28511
Value Function Update Magnitude: 0.30901

Collected Steps per Second: 21,999.31688
Overall Steps per Second: 10,451.63926

Timestep Collection Time: 2.27398
Timestep Consumption Time: 2.51245
PPO Batch Consumption Time: 0.29151
Total Iteration Time: 4.78643

Cumulative Model Updates: 253,328
Cumulative Timesteps: 2,113,344,382

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2113344382...
Checkpoint 2113344382 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 76,885.04788
Policy Entropy: 2.66283
Value Function Loss: 0.01027

Mean KL Divergence: 0.00662
SB3 Clip Fraction: 0.06499
Policy Update Magnitude: 0.28504
Value Function Update Magnitude: 0.29309

Collected Steps per Second: 21,677.30534
Overall Steps per Second: 10,569.39599

Timestep Collection Time: 2.30693
Timestep Consumption Time: 2.42447
PPO Batch Consumption Time: 0.27930
Total Iteration Time: 4.73140

Cumulative Model Updates: 253,334
Cumulative Timesteps: 2,113,394,390

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 104,674.74576
Policy Entropy: 2.64244
Value Function Loss: 0.01022

Mean KL Divergence: 0.00680
SB3 Clip Fraction: 0.06626
Policy Update Magnitude: 0.28076
Value Function Update Magnitude: 0.27695

Collected Steps per Second: 22,317.18869
Overall Steps per Second: 10,535.37003

Timestep Collection Time: 2.24168
Timestep Consumption Time: 2.50690
PPO Batch Consumption Time: 0.29309
Total Iteration Time: 4.74858

Cumulative Model Updates: 253,340
Cumulative Timesteps: 2,113,444,418

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2113444418...
Checkpoint 2113444418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 117,761.99769
Policy Entropy: 2.63205
Value Function Loss: 0.01144

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.07299
Policy Update Magnitude: 0.28650
Value Function Update Magnitude: 0.28027

Collected Steps per Second: 21,473.83732
Overall Steps per Second: 10,388.46629

Timestep Collection Time: 2.32925
Timestep Consumption Time: 2.48551
PPO Batch Consumption Time: 0.28982
Total Iteration Time: 4.81476

Cumulative Model Updates: 253,346
Cumulative Timesteps: 2,113,494,436

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81,188.41837
Policy Entropy: 2.62639
Value Function Loss: 0.01208

Mean KL Divergence: 0.00661
SB3 Clip Fraction: 0.06201
Policy Update Magnitude: 0.29740
Value Function Update Magnitude: 0.29394

Collected Steps per Second: 21,699.39091
Overall Steps per Second: 10,471.08913

Timestep Collection Time: 2.30550
Timestep Consumption Time: 2.47222
PPO Batch Consumption Time: 0.28927
Total Iteration Time: 4.77773

Cumulative Model Updates: 253,352
Cumulative Timesteps: 2,113,544,464

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2113544464...
Checkpoint 2113544464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 95,290.70370
Policy Entropy: 2.62843
Value Function Loss: 0.01230

Mean KL Divergence: 0.00690
SB3 Clip Fraction: 0.06354
Policy Update Magnitude: 0.29572
Value Function Update Magnitude: 0.27492

Collected Steps per Second: 21,189.48301
Overall Steps per Second: 10,468.17018

Timestep Collection Time: 2.36145
Timestep Consumption Time: 2.41856
PPO Batch Consumption Time: 0.29318
Total Iteration Time: 4.78001

Cumulative Model Updates: 253,358
Cumulative Timesteps: 2,113,594,502

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86,081.29535
Policy Entropy: 2.63891
Value Function Loss: 0.01329

Mean KL Divergence: 0.00610
SB3 Clip Fraction: 0.05737
Policy Update Magnitude: 0.29645
Value Function Update Magnitude: 0.24610

Collected Steps per Second: 21,252.32114
Overall Steps per Second: 10,428.78117

Timestep Collection Time: 2.35278
Timestep Consumption Time: 2.44184
PPO Batch Consumption Time: 0.29325
Total Iteration Time: 4.79462

Cumulative Model Updates: 253,364
Cumulative Timesteps: 2,113,644,504

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2113644504...
Checkpoint 2113644504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 81,323.70060
Policy Entropy: 2.64183
Value Function Loss: 0.01266

Mean KL Divergence: 0.00599
SB3 Clip Fraction: 0.05956
Policy Update Magnitude: 0.29269
Value Function Update Magnitude: 0.27145

Collected Steps per Second: 21,088.18582
Overall Steps per Second: 10,286.13857

Timestep Collection Time: 2.37100
Timestep Consumption Time: 2.48991
PPO Batch Consumption Time: 0.29103
Total Iteration Time: 4.86091

Cumulative Model Updates: 253,370
Cumulative Timesteps: 2,113,694,504

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68,839.45920
Policy Entropy: 2.63754
Value Function Loss: 0.01203

Mean KL Divergence: 0.00628
SB3 Clip Fraction: 0.05895
Policy Update Magnitude: 0.28541
Value Function Update Magnitude: 0.30300

Collected Steps per Second: 21,924.99684
Overall Steps per Second: 10,352.49965

Timestep Collection Time: 2.28169
Timestep Consumption Time: 2.55057
PPO Batch Consumption Time: 0.29359
Total Iteration Time: 4.83226

Cumulative Model Updates: 253,376
Cumulative Timesteps: 2,113,744,530

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2113744530...
Checkpoint 2113744530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89,539.55020
Policy Entropy: 2.64972
Value Function Loss: 0.01088

Mean KL Divergence: 0.00583
SB3 Clip Fraction: 0.05596
Policy Update Magnitude: 0.27496
Value Function Update Magnitude: 0.29049

Collected Steps per Second: 21,949.18425
Overall Steps per Second: 10,713.93016

Timestep Collection Time: 2.27945
Timestep Consumption Time: 2.39036
PPO Batch Consumption Time: 0.27668
Total Iteration Time: 4.66981

Cumulative Model Updates: 253,382
Cumulative Timesteps: 2,113,794,562

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83,526.76229
Policy Entropy: 2.64828
Value Function Loss: 0.01073

Mean KL Divergence: 0.00489
SB3 Clip Fraction: 0.04952
Policy Update Magnitude: 0.27683
Value Function Update Magnitude: 0.26915

Collected Steps per Second: 22,384.81691
Overall Steps per Second: 10,578.34203

Timestep Collection Time: 2.23527
Timestep Consumption Time: 2.49478
PPO Batch Consumption Time: 0.28983
Total Iteration Time: 4.73004

Cumulative Model Updates: 253,388
Cumulative Timesteps: 2,113,844,598

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 2113844598...
Checkpoint 2113844598 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 98,905.31854
Policy Entropy: 2.64216
Value Function Loss: 0.01188

Mean KL Divergence: 0.00517
SB3 Clip Fraction: 0.04954
Policy Update Magnitude: 0.28431
Value Function Update Magnitude: 0.27527

Collected Steps per Second: 22,042.15304
Overall Steps per Second: 10,481.70650

Timestep Collection Time: 2.26929
Timestep Consumption Time: 2.50284
PPO Batch Consumption Time: 0.29352
Total Iteration Time: 4.77212

Cumulative Model Updates: 253,394
Cumulative Timesteps: 2,113,894,618

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82,431.48053
Policy Entropy: 2.64971
Value Function Loss: 0.01257

Mean KL Divergence: 0.00678
SB3 Clip Fraction: 0.06275
Policy Update Magnitude: 0.29855
Value Function Update Magnitude: 0.29501

Collected Steps per Second: 22,273.96694
Overall Steps per Second: 10,553.09851

Timestep Collection Time: 2.24594
Timestep Consumption Time: 2.49447
PPO Batch Consumption Time: 0.29126
Total Iteration Time: 4.74041

Cumulative Model Updates: 253,400
Cumulative Timesteps: 2,113,944,644

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2113944644...
Checkpoint 2113944644 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48,178.42741
Policy Entropy: 2.64662
Value Function Loss: 0.01427

Mean KL Divergence: 0.00746
SB3 Clip Fraction: 0.06903
Policy Update Magnitude: 0.29994
Value Function Update Magnitude: 0.29394

Collected Steps per Second: 21,865.95455
Overall Steps per Second: 10,490.67308

Timestep Collection Time: 2.28703
Timestep Consumption Time: 2.47988
PPO Batch Consumption Time: 0.28725
Total Iteration Time: 4.76690

Cumulative Model Updates: 253,406
Cumulative Timesteps: 2,113,994,652

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52,999.40962
Policy Entropy: 2.64226
Value Function Loss: 0.01553

Mean KL Divergence: 0.00758
SB3 Clip Fraction: 0.07141
Policy Update Magnitude: 0.29981
Value Function Update Magnitude: 0.29833

Collected Steps per Second: 21,955.90209
Overall Steps per Second: 10,458.67069

Timestep Collection Time: 2.27829
Timestep Consumption Time: 2.50453
PPO Batch Consumption Time: 0.29037
Total Iteration Time: 4.78283

Cumulative Model Updates: 253,412
Cumulative Timesteps: 2,114,044,674

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2114044674...
Checkpoint 2114044674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 60,070.84321
Policy Entropy: 2.64439
Value Function Loss: 0.01361

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.07555
Policy Update Magnitude: 0.29852
Value Function Update Magnitude: 0.30930

Collected Steps per Second: 21,667.85265
Overall Steps per Second: 10,566.88321

Timestep Collection Time: 2.30766
Timestep Consumption Time: 2.42430
PPO Batch Consumption Time: 0.27855
Total Iteration Time: 4.73195

Cumulative Model Updates: 253,418
Cumulative Timesteps: 2,114,094,676

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60,070.84321
Policy Entropy: 2.65866
Value Function Loss: 0.01122

Mean KL Divergence: 0.00758
SB3 Clip Fraction: 0.07014
Policy Update Magnitude: 0.28529
Value Function Update Magnitude: 0.27924

Collected Steps per Second: 21,223.19196
Overall Steps per Second: 10,464.23989

Timestep Collection Time: 2.35620
Timestep Consumption Time: 2.42256
PPO Batch Consumption Time: 0.27808
Total Iteration Time: 4.77875

Cumulative Model Updates: 253,424
Cumulative Timesteps: 2,114,144,682

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2114144682...
Checkpoint 2114144682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 104,919.72077
Policy Entropy: 2.66814
Value Function Loss: 0.01176

Mean KL Divergence: 0.00528
SB3 Clip Fraction: 0.05185
Policy Update Magnitude: 0.28173
Value Function Update Magnitude: 0.26733

Collected Steps per Second: 21,530.63769
Overall Steps per Second: 10,372.28436

Timestep Collection Time: 2.32367
Timestep Consumption Time: 2.49977
PPO Batch Consumption Time: 0.29191
Total Iteration Time: 4.82343

Cumulative Model Updates: 253,430
Cumulative Timesteps: 2,114,194,712

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 111,941.45398
Policy Entropy: 2.64978
Value Function Loss: 0.01208

Mean KL Divergence: 0.00541
SB3 Clip Fraction: 0.05405
Policy Update Magnitude: 0.28856
Value Function Update Magnitude: 0.28240

Collected Steps per Second: 21,576.37310
Overall Steps per Second: 10,355.21856

Timestep Collection Time: 2.31920
Timestep Consumption Time: 2.51314
PPO Batch Consumption Time: 0.29297
Total Iteration Time: 4.83235

Cumulative Model Updates: 253,436
Cumulative Timesteps: 2,114,244,752

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 2114244752...
Checkpoint 2114244752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 130,274.80002
Policy Entropy: 2.61472
Value Function Loss: 0.01377

Mean KL Divergence: 0.00593
SB3 Clip Fraction: 0.05603
Policy Update Magnitude: 0.30340
Value Function Update Magnitude: 0.30847

Collected Steps per Second: 21,495.68493
Overall Steps per Second: 10,386.00639

Timestep Collection Time: 2.32819
Timestep Consumption Time: 2.49041
PPO Batch Consumption Time: 0.28954
Total Iteration Time: 4.81860

Cumulative Model Updates: 253,442
Cumulative Timesteps: 2,114,294,798

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 131,896.88563
Policy Entropy: 2.63447
Value Function Loss: 0.01389

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.07170
Policy Update Magnitude: 0.31025
Value Function Update Magnitude: 0.28659

Collected Steps per Second: 22,051.14545
Overall Steps per Second: 10,456.64189

Timestep Collection Time: 2.26782
Timestep Consumption Time: 2.51460
PPO Batch Consumption Time: 0.28884
Total Iteration Time: 4.78241

Cumulative Model Updates: 253,448
Cumulative Timesteps: 2,114,344,806

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2114344806...
Checkpoint 2114344806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 137,427.28030
Policy Entropy: 2.64740
Value Function Loss: 0.01296

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.07242
Policy Update Magnitude: 0.30157
Value Function Update Magnitude: 0.27753

Collected Steps per Second: 22,333.52079
Overall Steps per Second: 10,550.26792

Timestep Collection Time: 2.24004
Timestep Consumption Time: 2.50183
PPO Batch Consumption Time: 0.29108
Total Iteration Time: 4.74187

Cumulative Model Updates: 253,454
Cumulative Timesteps: 2,114,394,834

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 137,427.28030
Policy Entropy: 2.67321
Value Function Loss: 0.01216

Mean KL Divergence: 0.00736
SB3 Clip Fraction: 0.06852
Policy Update Magnitude: 0.29850
Value Function Update Magnitude: 0.24911

Collected Steps per Second: 21,553.92391
Overall Steps per Second: 10,341.82346

Timestep Collection Time: 2.32097
Timestep Consumption Time: 2.51628
PPO Batch Consumption Time: 0.29230
Total Iteration Time: 4.83725

Cumulative Model Updates: 253,460
Cumulative Timesteps: 2,114,444,860

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2114444860...
Checkpoint 2114444860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 103,390.19214
Policy Entropy: 2.67399
Value Function Loss: 0.01184

Mean KL Divergence: 0.00640
SB3 Clip Fraction: 0.06163
Policy Update Magnitude: 0.29718
Value Function Update Magnitude: 0.25739

Collected Steps per Second: 22,016.12691
Overall Steps per Second: 10,621.56293

Timestep Collection Time: 2.27215
Timestep Consumption Time: 2.43751
PPO Batch Consumption Time: 0.27902
Total Iteration Time: 4.70966

Cumulative Model Updates: 253,466
Cumulative Timesteps: 2,114,494,884

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97,728.96163
Policy Entropy: 2.66375
Value Function Loss: 0.01462

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.07288
Policy Update Magnitude: 0.31316
Value Function Update Magnitude: 0.23799

Collected Steps per Second: 21,838.70398
Overall Steps per Second: 10,474.66221

Timestep Collection Time: 2.29070
Timestep Consumption Time: 2.48520
PPO Batch Consumption Time: 0.28843
Total Iteration Time: 4.77591

Cumulative Model Updates: 253,472
Cumulative Timesteps: 2,114,544,910

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2114544910...
Checkpoint 2114544910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89,185.47402
Policy Entropy: 2.63727
Value Function Loss: 0.01538

Mean KL Divergence: 0.00777
SB3 Clip Fraction: 0.07242
Policy Update Magnitude: 0.32231
Value Function Update Magnitude: 0.19745

Collected Steps per Second: 21,978.50585
Overall Steps per Second: 10,616.21262

Timestep Collection Time: 2.27559
Timestep Consumption Time: 2.43551
PPO Batch Consumption Time: 0.27849
Total Iteration Time: 4.71110

Cumulative Model Updates: 253,478
Cumulative Timesteps: 2,114,594,924

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58,502.58404
Policy Entropy: 2.63631
Value Function Loss: 0.01575

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.07338
Policy Update Magnitude: 0.31983
Value Function Update Magnitude: 0.21499

Collected Steps per Second: 22,116.43550
Overall Steps per Second: 10,484.40353

Timestep Collection Time: 2.26302
Timestep Consumption Time: 2.51073
PPO Batch Consumption Time: 0.29136
Total Iteration Time: 4.77376

Cumulative Model Updates: 253,484
Cumulative Timesteps: 2,114,644,974

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 2114644974...
Checkpoint 2114644974 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 73,241.11565
Policy Entropy: 2.63095
Value Function Loss: 0.01750

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.08100
Policy Update Magnitude: 0.32992
Value Function Update Magnitude: 0.25015

Collected Steps per Second: 21,192.01303
Overall Steps per Second: 10,199.03698

Timestep Collection Time: 2.36070
Timestep Consumption Time: 2.54447
PPO Batch Consumption Time: 0.29156
Total Iteration Time: 4.90517

Cumulative Model Updates: 253,490
Cumulative Timesteps: 2,114,695,002

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67,860.47855
Policy Entropy: 2.64474
Value Function Loss: 0.01762

Mean KL Divergence: 0.01216
SB3 Clip Fraction: 0.10074
Policy Update Magnitude: 0.32613
Value Function Update Magnitude: 0.30931

Collected Steps per Second: 21,025.51000
Overall Steps per Second: 10,385.99876

Timestep Collection Time: 2.37806
Timestep Consumption Time: 2.43611
PPO Batch Consumption Time: 0.27813
Total Iteration Time: 4.81417

Cumulative Model Updates: 253,496
Cumulative Timesteps: 2,114,745,002

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2114745002...
Checkpoint 2114745002 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 167,447.11874
Policy Entropy: 2.61417
Value Function Loss: 0.01780

Mean KL Divergence: 0.01711
SB3 Clip Fraction: 0.12989
Policy Update Magnitude: 0.30353
Value Function Update Magnitude: 0.33944

Collected Steps per Second: 21,543.43555
Overall Steps per Second: 10,380.06425

Timestep Collection Time: 2.32117
Timestep Consumption Time: 2.49633
PPO Batch Consumption Time: 0.29333
Total Iteration Time: 4.81750

Cumulative Model Updates: 253,502
Cumulative Timesteps: 2,114,795,008

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 110,891.32437
Policy Entropy: 2.63593
Value Function Loss: 0.01648

Mean KL Divergence: 0.01233
SB3 Clip Fraction: 0.09991
Policy Update Magnitude: 0.30671
Value Function Update Magnitude: 0.35138

Collected Steps per Second: 21,190.37564
Overall Steps per Second: 10,437.68408

Timestep Collection Time: 2.36041
Timestep Consumption Time: 2.43165
PPO Batch Consumption Time: 0.29331
Total Iteration Time: 4.79206

Cumulative Model Updates: 253,508
Cumulative Timesteps: 2,114,845,026

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2114845026...
Checkpoint 2114845026 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 117,241.64264
Policy Entropy: 2.64776
Value Function Loss: 0.01510

Mean KL Divergence: 0.01119
SB3 Clip Fraction: 0.09009
Policy Update Magnitude: 0.31786
Value Function Update Magnitude: 0.34219

Collected Steps per Second: 21,229.40338
Overall Steps per Second: 10,632.63340

Timestep Collection Time: 2.35645
Timestep Consumption Time: 2.34850
PPO Batch Consumption Time: 0.27715
Total Iteration Time: 4.70495

Cumulative Model Updates: 253,514
Cumulative Timesteps: 2,114,895,052

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 117,241.64264
Policy Entropy: 2.66157
Value Function Loss: 0.01367

Mean KL Divergence: 0.01061
SB3 Clip Fraction: 0.08868
Policy Update Magnitude: 0.30771
Value Function Update Magnitude: 0.32239

Collected Steps per Second: 21,102.98392
Overall Steps per Second: 10,378.24884

Timestep Collection Time: 2.36962
Timestep Consumption Time: 2.44873
PPO Batch Consumption Time: 0.27852
Total Iteration Time: 4.81835

Cumulative Model Updates: 253,520
Cumulative Timesteps: 2,114,945,058

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2114945058...
Checkpoint 2114945058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84,063.22275
Policy Entropy: 2.64775
Value Function Loss: 0.01414

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.07795
Policy Update Magnitude: 0.30286
Value Function Update Magnitude: 0.29610

Collected Steps per Second: 21,771.06826
Overall Steps per Second: 10,613.13131

Timestep Collection Time: 2.29672
Timestep Consumption Time: 2.41462
PPO Batch Consumption Time: 0.27825
Total Iteration Time: 4.71133

Cumulative Model Updates: 253,526
Cumulative Timesteps: 2,114,995,060

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54,275.08423
Policy Entropy: 2.61516
Value Function Loss: 0.01484

Mean KL Divergence: 0.00679
SB3 Clip Fraction: 0.06506
Policy Update Magnitude: 0.31881
Value Function Update Magnitude: 0.25184

Collected Steps per Second: 21,993.25934
Overall Steps per Second: 10,506.60124

Timestep Collection Time: 2.27506
Timestep Consumption Time: 2.48728
PPO Batch Consumption Time: 0.29377
Total Iteration Time: 4.76234

Cumulative Model Updates: 253,532
Cumulative Timesteps: 2,115,045,096

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 2115045096...
Checkpoint 2115045096 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 57,004.67156
Policy Entropy: 2.59596
Value Function Loss: 0.01740

Mean KL Divergence: 0.00724
SB3 Clip Fraction: 0.06540
Policy Update Magnitude: 0.33775
Value Function Update Magnitude: 0.21174

Collected Steps per Second: 21,872.34823
Overall Steps per Second: 10,671.20378

Timestep Collection Time: 2.28645
Timestep Consumption Time: 2.40000
PPO Batch Consumption Time: 0.27738
Total Iteration Time: 4.68644

Cumulative Model Updates: 253,538
Cumulative Timesteps: 2,115,095,106

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56,389.42575
Policy Entropy: 2.61017
Value Function Loss: 0.01627

Mean KL Divergence: 0.00733
SB3 Clip Fraction: 0.06447
Policy Update Magnitude: 0.33829
Value Function Update Magnitude: 0.24805

Collected Steps per Second: 22,210.59213
Overall Steps per Second: 10,549.53231

Timestep Collection Time: 2.25316
Timestep Consumption Time: 2.49056
PPO Batch Consumption Time: 0.29122
Total Iteration Time: 4.74372

Cumulative Model Updates: 253,544
Cumulative Timesteps: 2,115,145,150

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 2115145150...
Checkpoint 2115145150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 70,612.27864
Policy Entropy: 2.62329
Value Function Loss: 0.01612

Mean KL Divergence: 0.00720
SB3 Clip Fraction: 0.06345
Policy Update Magnitude: 0.33273
Value Function Update Magnitude: 0.27272

Collected Steps per Second: 21,912.71421
Overall Steps per Second: 10,494.37029

Timestep Collection Time: 2.28342
Timestep Consumption Time: 2.48447
PPO Batch Consumption Time: 0.29007
Total Iteration Time: 4.76789

Cumulative Model Updates: 253,550
Cumulative Timesteps: 2,115,195,186

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 103,595.60570
Policy Entropy: 2.63621
Value Function Loss: 0.01469

Mean KL Divergence: 0.00712
SB3 Clip Fraction: 0.06483
Policy Update Magnitude: 0.33449
Value Function Update Magnitude: 0.31483

Collected Steps per Second: 22,028.31506
Overall Steps per Second: 10,468.61092

Timestep Collection Time: 2.27008
Timestep Consumption Time: 2.50668
PPO Batch Consumption Time: 0.29366
Total Iteration Time: 4.77676

Cumulative Model Updates: 253,556
Cumulative Timesteps: 2,115,245,192

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2115245192...
Checkpoint 2115245192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 77,350.27330
Policy Entropy: 2.63192
Value Function Loss: 0.01534

Mean KL Divergence: 0.00704
SB3 Clip Fraction: 0.06317
Policy Update Magnitude: 0.33011
Value Function Update Magnitude: 0.33278

Collected Steps per Second: 21,663.20532
Overall Steps per Second: 10,553.74681

Timestep Collection Time: 2.30917
Timestep Consumption Time: 2.43076
PPO Batch Consumption Time: 0.27842
Total Iteration Time: 4.73993

Cumulative Model Updates: 253,562
Cumulative Timesteps: 2,115,295,216

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 94,623.47528
Policy Entropy: 2.62643
Value Function Loss: 0.01715

Mean KL Divergence: 0.00752
SB3 Clip Fraction: 0.06680
Policy Update Magnitude: 0.33362
Value Function Update Magnitude: 0.35559

Collected Steps per Second: 21,554.78464
Overall Steps per Second: 10,476.40797

Timestep Collection Time: 2.32171
Timestep Consumption Time: 2.45512
PPO Batch Consumption Time: 0.27835
Total Iteration Time: 4.77683

Cumulative Model Updates: 253,568
Cumulative Timesteps: 2,115,345,260

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 2115345260...
Checkpoint 2115345260 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 126,720.50627
Policy Entropy: 2.61890
Value Function Loss: 0.01720

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.07158
Policy Update Magnitude: 0.34158
Value Function Update Magnitude: 0.37967

Collected Steps per Second: 21,429.22528
Overall Steps per Second: 10,340.04941

Timestep Collection Time: 2.33560
Timestep Consumption Time: 2.50481
PPO Batch Consumption Time: 0.29343
Total Iteration Time: 4.84040

Cumulative Model Updates: 253,574
Cumulative Timesteps: 2,115,395,310

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93,077.05668
Policy Entropy: 2.64003
Value Function Loss: 0.01446

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.07516
Policy Update Magnitude: 0.32890
Value Function Update Magnitude: 0.39164

Collected Steps per Second: 21,511.87724
Overall Steps per Second: 10,339.25561

Timestep Collection Time: 2.32458
Timestep Consumption Time: 2.51194
PPO Batch Consumption Time: 0.29219
Total Iteration Time: 4.83652

Cumulative Model Updates: 253,580
Cumulative Timesteps: 2,115,445,316

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2115445316...
Checkpoint 2115445316 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 69,815.31886
Policy Entropy: 2.65475
Value Function Loss: 0.01465

Mean KL Divergence: 0.00721
SB3 Clip Fraction: 0.06418
Policy Update Magnitude: 0.31594
Value Function Update Magnitude: 0.36257

Collected Steps per Second: 21,680.95804
Overall Steps per Second: 10,563.21038

Timestep Collection Time: 2.30626
Timestep Consumption Time: 2.42734
PPO Batch Consumption Time: 0.27839
Total Iteration Time: 4.73360

Cumulative Model Updates: 253,586
Cumulative Timesteps: 2,115,495,318

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62,701.13919
Policy Entropy: 2.66947
Value Function Loss: 0.01393

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.07631
Policy Update Magnitude: 0.30547
Value Function Update Magnitude: 0.34406

Collected Steps per Second: 22,080.51839
Overall Steps per Second: 10,614.11984

Timestep Collection Time: 2.26480
Timestep Consumption Time: 2.44666
PPO Batch Consumption Time: 0.27709
Total Iteration Time: 4.71146

Cumulative Model Updates: 253,592
Cumulative Timesteps: 2,115,545,326

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2115545326...
Checkpoint 2115545326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 90,502.80432
Policy Entropy: 2.66993
Value Function Loss: 0.01295

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.08114
Policy Update Magnitude: 0.29840
Value Function Update Magnitude: 0.32424

Collected Steps per Second: 21,908.38067
Overall Steps per Second: 10,511.61123

Timestep Collection Time: 2.28360
Timestep Consumption Time: 2.47590
PPO Batch Consumption Time: 0.28589
Total Iteration Time: 4.75950

Cumulative Model Updates: 253,598
Cumulative Timesteps: 2,115,595,356

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79,521.15442
Policy Entropy: 2.66867
Value Function Loss: 0.01079

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.07054
Policy Update Magnitude: 0.29014
Value Function Update Magnitude: 0.29913

Collected Steps per Second: 21,553.19499
Overall Steps per Second: 10,525.80216

Timestep Collection Time: 2.32096
Timestep Consumption Time: 2.43156
PPO Batch Consumption Time: 0.29341
Total Iteration Time: 4.75251

Cumulative Model Updates: 253,604
Cumulative Timesteps: 2,115,645,380

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2115645380...
Checkpoint 2115645380 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 72,107.96268
Policy Entropy: 2.65581
Value Function Loss: 0.01125

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.07324
Policy Update Magnitude: 0.28845
Value Function Update Magnitude: 0.27931

Collected Steps per Second: 20,773.73803
Overall Steps per Second: 10,524.43225

Timestep Collection Time: 2.40717
Timestep Consumption Time: 2.34425
PPO Batch Consumption Time: 0.27888
Total Iteration Time: 4.75142

Cumulative Model Updates: 253,610
Cumulative Timesteps: 2,115,695,386

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80,128.98374
Policy Entropy: 2.63860
Value Function Loss: 0.01316

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.07170
Policy Update Magnitude: 0.30962
Value Function Update Magnitude: 0.28535

Collected Steps per Second: 21,535.17069
Overall Steps per Second: 10,538.86305

Timestep Collection Time: 2.32280
Timestep Consumption Time: 2.42363
PPO Batch Consumption Time: 0.29024
Total Iteration Time: 4.74643

Cumulative Model Updates: 253,616
Cumulative Timesteps: 2,115,745,408

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2115745408...
Checkpoint 2115745408 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 60,027.42682
Policy Entropy: 2.65646
Value Function Loss: 0.01549

Mean KL Divergence: 0.00763
SB3 Clip Fraction: 0.06791
Policy Update Magnitude: 0.31907
Value Function Update Magnitude: 0.31042

Collected Steps per Second: 21,488.02050
Overall Steps per Second: 10,728.19535

Timestep Collection Time: 2.32725
Timestep Consumption Time: 2.33411
PPO Batch Consumption Time: 0.27669
Total Iteration Time: 4.66136

Cumulative Model Updates: 253,622
Cumulative Timesteps: 2,115,795,416

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54,643.03481
Policy Entropy: 2.67506
Value Function Loss: 0.01560

Mean KL Divergence: 0.00759
SB3 Clip Fraction: 0.06487
Policy Update Magnitude: 0.31297
Value Function Update Magnitude: 0.32035

Collected Steps per Second: 21,594.25757
Overall Steps per Second: 10,436.39288

Timestep Collection Time: 2.31608
Timestep Consumption Time: 2.47619
PPO Batch Consumption Time: 0.29302
Total Iteration Time: 4.79227

Cumulative Model Updates: 253,628
Cumulative Timesteps: 2,115,845,430

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2115845430...
Checkpoint 2115845430 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46,165.85799
Policy Entropy: 2.68966
Value Function Loss: 0.01585

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.08076
Policy Update Magnitude: 0.30490
Value Function Update Magnitude: 0.31013

Collected Steps per Second: 21,370.51745
Overall Steps per Second: 10,536.92864

Timestep Collection Time: 2.33995
Timestep Consumption Time: 2.40583
PPO Batch Consumption Time: 0.27878
Total Iteration Time: 4.74579

Cumulative Model Updates: 253,634
Cumulative Timesteps: 2,115,895,436

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,791.81288
Policy Entropy: 2.68942
Value Function Loss: 0.01282

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.06859
Policy Update Magnitude: 0.29381
Value Function Update Magnitude: 0.29594

Collected Steps per Second: 21,778.27711
Overall Steps per Second: 10,480.14355

Timestep Collection Time: 2.29632
Timestep Consumption Time: 2.47556
PPO Batch Consumption Time: 0.28888
Total Iteration Time: 4.77188

Cumulative Model Updates: 253,640
Cumulative Timesteps: 2,115,945,446

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2115945446...
Checkpoint 2115945446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 79,594.90497
Policy Entropy: 2.66984
Value Function Loss: 0.01467

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.07424
Policy Update Magnitude: 0.29876
Value Function Update Magnitude: 0.29752

Collected Steps per Second: 21,123.15384
Overall Steps per Second: 10,245.58613

Timestep Collection Time: 2.36745
Timestep Consumption Time: 2.51348
PPO Batch Consumption Time: 0.29328
Total Iteration Time: 4.88093

Cumulative Model Updates: 253,646
Cumulative Timesteps: 2,115,995,454

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67,898.70926
Policy Entropy: 2.65452
Value Function Loss: 0.01433

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.08387
Policy Update Magnitude: 0.30565
Value Function Update Magnitude: 0.32085

Collected Steps per Second: 22,325.40310
Overall Steps per Second: 10,458.06076

Timestep Collection Time: 2.24139
Timestep Consumption Time: 2.54343
PPO Batch Consumption Time: 0.29333
Total Iteration Time: 4.78483

Cumulative Model Updates: 253,652
Cumulative Timesteps: 2,116,045,494

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 2116045494...
Checkpoint 2116045494 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 52,403.59803
Policy Entropy: 2.65269
Value Function Loss: 0.01471

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.08561
Policy Update Magnitude: 0.30466
Value Function Update Magnitude: 0.34644

Collected Steps per Second: 21,988.99382
Overall Steps per Second: 10,587.02344

Timestep Collection Time: 2.27596
Timestep Consumption Time: 2.45115
PPO Batch Consumption Time: 0.27927
Total Iteration Time: 4.72711

Cumulative Model Updates: 253,658
Cumulative Timesteps: 2,116,095,540

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 73,764.01276
Policy Entropy: 2.64491
Value Function Loss: 0.01373

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.07644
Policy Update Magnitude: 0.30876
Value Function Update Magnitude: 0.35134

Collected Steps per Second: 22,169.28325
Overall Steps per Second: 10,479.64605

Timestep Collection Time: 2.25555
Timestep Consumption Time: 2.51598
PPO Batch Consumption Time: 0.29480
Total Iteration Time: 4.77154

Cumulative Model Updates: 253,664
Cumulative Timesteps: 2,116,145,544

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2116145544...
Checkpoint 2116145544 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 51,307.35987
Policy Entropy: 2.64761
Value Function Loss: 0.01249

Mean KL Divergence: 0.00695
SB3 Clip Fraction: 0.06622
Policy Update Magnitude: 0.30704
Value Function Update Magnitude: 0.32699

Collected Steps per Second: 21,928.40340
Overall Steps per Second: 10,620.32130

Timestep Collection Time: 2.28069
Timestep Consumption Time: 2.42839
PPO Batch Consumption Time: 0.27888
Total Iteration Time: 4.70909

Cumulative Model Updates: 253,670
Cumulative Timesteps: 2,116,195,556

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58,429.81823
Policy Entropy: 2.65894
Value Function Loss: 0.01186

Mean KL Divergence: 0.00670
SB3 Clip Fraction: 0.06214
Policy Update Magnitude: 0.29694
Value Function Update Magnitude: 0.31820

Collected Steps per Second: 22,388.93048
Overall Steps per Second: 10,556.85144

Timestep Collection Time: 2.23423
Timestep Consumption Time: 2.50412
PPO Batch Consumption Time: 0.29249
Total Iteration Time: 4.73834

Cumulative Model Updates: 253,676
Cumulative Timesteps: 2,116,245,578

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2116245578...
Checkpoint 2116245578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 51,905.74324
Policy Entropy: 2.66692
Value Function Loss: 0.01117

Mean KL Divergence: 0.00630
SB3 Clip Fraction: 0.06130
Policy Update Magnitude: 0.29799
Value Function Update Magnitude: 0.30860

Collected Steps per Second: 22,092.48979
Overall Steps per Second: 10,531.43555

Timestep Collection Time: 2.26403
Timestep Consumption Time: 2.48537
PPO Batch Consumption Time: 0.28763
Total Iteration Time: 4.74940

Cumulative Model Updates: 253,682
Cumulative Timesteps: 2,116,295,596

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58,076.86046
Policy Entropy: 2.65747
Value Function Loss: 0.01245

Mean KL Divergence: 0.00596
SB3 Clip Fraction: 0.05434
Policy Update Magnitude: 0.29570
Value Function Update Magnitude: 0.32423

Collected Steps per Second: 22,285.85010
Overall Steps per Second: 10,510.43013

Timestep Collection Time: 2.24385
Timestep Consumption Time: 2.51390
PPO Batch Consumption Time: 0.29275
Total Iteration Time: 4.75775

Cumulative Model Updates: 253,688
Cumulative Timesteps: 2,116,345,602

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2116345602...
Checkpoint 2116345602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 70,760.67026
Policy Entropy: 2.65005
Value Function Loss: 0.01248

Mean KL Divergence: 0.00678
SB3 Clip Fraction: 0.06072
Policy Update Magnitude: 0.30214
Value Function Update Magnitude: 0.35244

Collected Steps per Second: 21,198.56067
Overall Steps per Second: 10,291.53076

Timestep Collection Time: 2.35988
Timestep Consumption Time: 2.50101
PPO Batch Consumption Time: 0.29150
Total Iteration Time: 4.86089

Cumulative Model Updates: 253,694
Cumulative Timesteps: 2,116,395,628

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61,015.39600
Policy Entropy: 2.65156
Value Function Loss: 0.01222

Mean KL Divergence: 0.00694
SB3 Clip Fraction: 0.06694
Policy Update Magnitude: 0.29732
Value Function Update Magnitude: 0.34798

Collected Steps per Second: 21,536.85062
Overall Steps per Second: 10,329.98089

Timestep Collection Time: 2.32318
Timestep Consumption Time: 2.52039
PPO Batch Consumption Time: 0.29164
Total Iteration Time: 4.84357

Cumulative Model Updates: 253,700
Cumulative Timesteps: 2,116,445,662

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 2116445662...
Checkpoint 2116445662 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 61,015.39600
Policy Entropy: 2.64368
Value Function Loss: 0.01251

Mean KL Divergence: 0.00712
SB3 Clip Fraction: 0.06655
Policy Update Magnitude: 0.29685
Value Function Update Magnitude: 0.35004

Collected Steps per Second: 21,533.10972
Overall Steps per Second: 10,380.99156

Timestep Collection Time: 2.32312
Timestep Consumption Time: 2.49569
PPO Batch Consumption Time: 0.29067
Total Iteration Time: 4.81881

Cumulative Model Updates: 253,706
Cumulative Timesteps: 2,116,495,686

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46,710.81876
Policy Entropy: 2.63661
Value Function Loss: 0.01165

Mean KL Divergence: 0.00664
SB3 Clip Fraction: 0.06146
Policy Update Magnitude: 0.29875
Value Function Update Magnitude: 0.35378

Collected Steps per Second: 21,976.98749
Overall Steps per Second: 10,648.93783

Timestep Collection Time: 2.27538
Timestep Consumption Time: 2.42049
PPO Batch Consumption Time: 0.27910
Total Iteration Time: 4.69587

Cumulative Model Updates: 253,712
Cumulative Timesteps: 2,116,545,692

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2116545692...
Checkpoint 2116545692 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43,576.58682
Policy Entropy: 2.65034
Value Function Loss: 0.01115

Mean KL Divergence: 0.00738
SB3 Clip Fraction: 0.06841
Policy Update Magnitude: 0.28998
Value Function Update Magnitude: 0.31351

Collected Steps per Second: 20,518.70104
Overall Steps per Second: 10,256.84155

Timestep Collection Time: 2.43690
Timestep Consumption Time: 2.43809
PPO Batch Consumption Time: 0.27898
Total Iteration Time: 4.87499

Cumulative Model Updates: 253,718
Cumulative Timesteps: 2,116,595,694

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52,905.46594
Policy Entropy: 2.67698
Value Function Loss: 0.01043

Mean KL Divergence: 0.00685
SB3 Clip Fraction: 0.06629
Policy Update Magnitude: 0.28252
Value Function Update Magnitude: 0.27732

Collected Steps per Second: 21,690.21920
Overall Steps per Second: 10,477.38192

Timestep Collection Time: 2.30546
Timestep Consumption Time: 2.46729
PPO Batch Consumption Time: 0.28560
Total Iteration Time: 4.77276

Cumulative Model Updates: 253,724
Cumulative Timesteps: 2,116,645,700

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2116645700...
Checkpoint 2116645700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 59,178.32261
Policy Entropy: 2.67889
Value Function Loss: 0.01106

Mean KL Divergence: 0.00571
SB3 Clip Fraction: 0.05681
Policy Update Magnitude: 0.27177
Value Function Update Magnitude: 0.25498

Collected Steps per Second: 21,537.30222
Overall Steps per Second: 10,386.02083

Timestep Collection Time: 2.32285
Timestep Consumption Time: 2.49401
PPO Batch Consumption Time: 0.28984
Total Iteration Time: 4.81686

Cumulative Model Updates: 253,730
Cumulative Timesteps: 2,116,695,728

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84,219.35198
Policy Entropy: 2.69603
Value Function Loss: 0.01027

Mean KL Divergence: 0.00623
SB3 Clip Fraction: 0.06175
Policy Update Magnitude: 0.26234
Value Function Update Magnitude: 0.24407

Collected Steps per Second: 21,948.75734
Overall Steps per Second: 10,500.22388

Timestep Collection Time: 2.27976
Timestep Consumption Time: 2.48566
PPO Batch Consumption Time: 0.28873
Total Iteration Time: 4.76542

Cumulative Model Updates: 253,736
Cumulative Timesteps: 2,116,745,766

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 2116745766...
Checkpoint 2116745766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84,219.35198
Policy Entropy: 2.69212
Value Function Loss: 0.01031

Mean KL Divergence: 0.00564
SB3 Clip Fraction: 0.05489
Policy Update Magnitude: 0.25473
Value Function Update Magnitude: 0.23782

Collected Steps per Second: 21,969.13973
Overall Steps per Second: 10,438.60592

Timestep Collection Time: 2.27692
Timestep Consumption Time: 2.51510
PPO Batch Consumption Time: 0.29040
Total Iteration Time: 4.79202

Cumulative Model Updates: 253,742
Cumulative Timesteps: 2,116,795,788

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 112,408.03229
Policy Entropy: 2.67294
Value Function Loss: 0.01063

Mean KL Divergence: 0.00556
SB3 Clip Fraction: 0.05538
Policy Update Magnitude: 0.26586
Value Function Update Magnitude: 0.22853

Collected Steps per Second: 22,097.88895
Overall Steps per Second: 10,489.59351

Timestep Collection Time: 2.26302
Timestep Consumption Time: 2.50437
PPO Batch Consumption Time: 0.29102
Total Iteration Time: 4.76739

Cumulative Model Updates: 253,748
Cumulative Timesteps: 2,116,845,796

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2116845796...
Checkpoint 2116845796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 104,033.35734
Policy Entropy: 2.66195
Value Function Loss: 0.01197

Mean KL Divergence: 0.00585
SB3 Clip Fraction: 0.05752
Policy Update Magnitude: 0.28150
Value Function Update Magnitude: 0.23280

Collected Steps per Second: 21,777.97450
Overall Steps per Second: 10,584.44559

Timestep Collection Time: 2.29608
Timestep Consumption Time: 2.42821
PPO Batch Consumption Time: 0.27856
Total Iteration Time: 4.72429

Cumulative Model Updates: 253,754
Cumulative Timesteps: 2,116,895,800

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 123,610.99997
Policy Entropy: 2.66147
Value Function Loss: 0.01271

Mean KL Divergence: 0.00663
SB3 Clip Fraction: 0.06057
Policy Update Magnitude: 0.28424
Value Function Update Magnitude: 0.25770

Collected Steps per Second: 22,188.40420
Overall Steps per Second: 10,499.59947

Timestep Collection Time: 2.25514
Timestep Consumption Time: 2.51056
PPO Batch Consumption Time: 0.29286
Total Iteration Time: 4.76571

Cumulative Model Updates: 253,760
Cumulative Timesteps: 2,116,945,838

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 2116945838...
Checkpoint 2116945838 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 123,610.99997
Policy Entropy: 2.66285
Value Function Loss: 0.01127

Mean KL Divergence: 0.00636
SB3 Clip Fraction: 0.06114
Policy Update Magnitude: 0.27422
Value Function Update Magnitude: 0.26209

Collected Steps per Second: 21,909.88464
Overall Steps per Second: 10,651.35666

Timestep Collection Time: 2.28207
Timestep Consumption Time: 2.41216
PPO Batch Consumption Time: 0.27694
Total Iteration Time: 4.69424

Cumulative Model Updates: 253,766
Cumulative Timesteps: 2,116,995,838

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 174,147.41781
Policy Entropy: 2.64986
Value Function Loss: 0.01180

Mean KL Divergence: 0.00633
SB3 Clip Fraction: 0.06214
Policy Update Magnitude: 0.28582
Value Function Update Magnitude: 0.25793

Collected Steps per Second: 22,509.22350
Overall Steps per Second: 10,777.39881

Timestep Collection Time: 2.22193
Timestep Consumption Time: 2.41870
PPO Batch Consumption Time: 0.27887
Total Iteration Time: 4.64064

Cumulative Model Updates: 253,772
Cumulative Timesteps: 2,117,045,852

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2117045852...
Checkpoint 2117045852 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 131,673.28665
Policy Entropy: 2.63291
Value Function Loss: 0.01342

Mean KL Divergence: 0.00658
SB3 Clip Fraction: 0.06326
Policy Update Magnitude: 0.30107
Value Function Update Magnitude: 0.26308

Collected Steps per Second: 21,654.21887
Overall Steps per Second: 10,413.45869

Timestep Collection Time: 2.31013
Timestep Consumption Time: 2.49366
PPO Batch Consumption Time: 0.28989
Total Iteration Time: 4.80378

Cumulative Model Updates: 253,778
Cumulative Timesteps: 2,117,095,876

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 111,321.75638
Policy Entropy: 2.64437
Value Function Loss: 0.01416

Mean KL Divergence: 0.00736
SB3 Clip Fraction: 0.06604
Policy Update Magnitude: 0.31413
Value Function Update Magnitude: 0.30599

Collected Steps per Second: 21,925.90141
Overall Steps per Second: 10,518.27800

Timestep Collection Time: 2.28178
Timestep Consumption Time: 2.47471
PPO Batch Consumption Time: 0.28840
Total Iteration Time: 4.75648

Cumulative Model Updates: 253,784
Cumulative Timesteps: 2,117,145,906

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2117145906...
Checkpoint 2117145906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 99,429.53541
Policy Entropy: 2.65144
Value Function Loss: 0.01235

Mean KL Divergence: 0.00648
SB3 Clip Fraction: 0.06084
Policy Update Magnitude: 0.30714
Value Function Update Magnitude: 0.33564

Collected Steps per Second: 21,071.85799
Overall Steps per Second: 10,417.62921

Timestep Collection Time: 2.37283
Timestep Consumption Time: 2.42672
PPO Batch Consumption Time: 0.27815
Total Iteration Time: 4.79956

Cumulative Model Updates: 253,790
Cumulative Timesteps: 2,117,195,906

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77,639.85229
Policy Entropy: 2.66798
Value Function Loss: 0.01063

Mean KL Divergence: 0.00625
SB3 Clip Fraction: 0.05969
Policy Update Magnitude: 0.28901
Value Function Update Magnitude: 0.31943

Collected Steps per Second: 21,683.71201
Overall Steps per Second: 10,508.60170

Timestep Collection Time: 2.30652
Timestep Consumption Time: 2.45282
PPO Batch Consumption Time: 0.27706
Total Iteration Time: 4.75934

Cumulative Model Updates: 253,796
Cumulative Timesteps: 2,117,245,920

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2117245920...
Checkpoint 2117245920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 106,641.62220
Policy Entropy: 2.67240
Value Function Loss: 0.01049

Mean KL Divergence: 0.00542
SB3 Clip Fraction: 0.05219
Policy Update Magnitude: 0.28179
Value Function Update Magnitude: 0.29036

Collected Steps per Second: 21,938.19174
Overall Steps per Second: 10,521.20875

Timestep Collection Time: 2.27995
Timestep Consumption Time: 2.47407
PPO Batch Consumption Time: 0.27864
Total Iteration Time: 4.75402

Cumulative Model Updates: 253,802
Cumulative Timesteps: 2,117,295,938

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97,081.94882
Policy Entropy: 2.64124
Value Function Loss: 0.01272

Mean KL Divergence: 0.00766
SB3 Clip Fraction: 0.07042
Policy Update Magnitude: 0.29547
Value Function Update Magnitude: 0.30395

Collected Steps per Second: 22,416.84976
Overall Steps per Second: 10,544.25421

Timestep Collection Time: 2.23261
Timestep Consumption Time: 2.51387
PPO Batch Consumption Time: 0.29229
Total Iteration Time: 4.74647

Cumulative Model Updates: 253,808
Cumulative Timesteps: 2,117,345,986

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 2117345986...
Checkpoint 2117345986 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 97,081.94882
Policy Entropy: 2.65061
Value Function Loss: 0.01163

Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.07439
Policy Update Magnitude: 0.29858
Value Function Update Magnitude: 0.30957

Collected Steps per Second: 21,907.61871
Overall Steps per Second: 10,589.80289

Timestep Collection Time: 2.28277
Timestep Consumption Time: 2.43970
PPO Batch Consumption Time: 0.27884
Total Iteration Time: 4.72247

Cumulative Model Updates: 253,814
Cumulative Timesteps: 2,117,395,996

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81,484.53672
Policy Entropy: 2.64852
Value Function Loss: 0.01227

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.07218
Policy Update Magnitude: 0.28539
Value Function Update Magnitude: 0.29325

Collected Steps per Second: 22,163.09228
Overall Steps per Second: 10,462.66303

Timestep Collection Time: 2.25672
Timestep Consumption Time: 2.52370
PPO Batch Consumption Time: 0.29397
Total Iteration Time: 4.78043

Cumulative Model Updates: 253,820
Cumulative Timesteps: 2,117,446,012

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2117446012...
Checkpoint 2117446012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 69,475.28147
Policy Entropy: 2.66104
Value Function Loss: 0.01210

Mean KL Divergence: 0.00740
SB3 Clip Fraction: 0.07057
Policy Update Magnitude: 0.28490
Value Function Update Magnitude: 0.29080

Collected Steps per Second: 21,853.45059
Overall Steps per Second: 10,611.87588

Timestep Collection Time: 2.28797
Timestep Consumption Time: 2.42373
PPO Batch Consumption Time: 0.27910
Total Iteration Time: 4.71170

Cumulative Model Updates: 253,826
Cumulative Timesteps: 2,117,496,012

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 108,297.64764
Policy Entropy: 2.63991
Value Function Loss: 0.01256

Mean KL Divergence: 0.00558
SB3 Clip Fraction: 0.05134
Policy Update Magnitude: 0.29144
Value Function Update Magnitude: 0.30955

Collected Steps per Second: 22,220.89625
Overall Steps per Second: 10,512.78177

Timestep Collection Time: 2.25076
Timestep Consumption Time: 2.50668
PPO Batch Consumption Time: 0.29338
Total Iteration Time: 4.75745

Cumulative Model Updates: 253,832
Cumulative Timesteps: 2,117,546,026

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2117546026...
Checkpoint 2117546026 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 117,724.61424
Policy Entropy: 2.62291
Value Function Loss: 0.01478

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.07774
Policy Update Magnitude: 0.30045
Value Function Update Magnitude: 0.31491

Collected Steps per Second: 21,760.30505
Overall Steps per Second: 10,582.64151

Timestep Collection Time: 2.29859
Timestep Consumption Time: 2.42783
PPO Batch Consumption Time: 0.27793
Total Iteration Time: 4.72642

Cumulative Model Updates: 253,838
Cumulative Timesteps: 2,117,596,044

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 126,046.38260
Policy Entropy: 2.62353
Value Function Loss: 0.01481

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.07605
Policy Update Magnitude: 0.30371
Value Function Update Magnitude: 0.32492

Collected Steps per Second: 21,604.18831
Overall Steps per Second: 10,437.33894

Timestep Collection Time: 2.31492
Timestep Consumption Time: 2.47672
PPO Batch Consumption Time: 0.28597
Total Iteration Time: 4.79164

Cumulative Model Updates: 253,844
Cumulative Timesteps: 2,117,646,056

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2117646056...
Checkpoint 2117646056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 108,101.60328
Policy Entropy: 2.63561
Value Function Loss: 0.01716

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.07411
Policy Update Magnitude: 0.30723
Value Function Update Magnitude: 0.31092

Collected Steps per Second: 21,450.60303
Overall Steps per Second: 10,350.73739

Timestep Collection Time: 2.33168
Timestep Consumption Time: 2.50044
PPO Batch Consumption Time: 0.29154
Total Iteration Time: 4.83212

Cumulative Model Updates: 253,850
Cumulative Timesteps: 2,117,696,072

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 128,607.55256
Policy Entropy: 2.66257
Value Function Loss: 0.01499

Mean KL Divergence: 0.00718
SB3 Clip Fraction: 0.06922
Policy Update Magnitude: 0.30605
Value Function Update Magnitude: 0.30725

Collected Steps per Second: 21,975.07293
Overall Steps per Second: 10,491.37625

Timestep Collection Time: 2.27676
Timestep Consumption Time: 2.49211
PPO Batch Consumption Time: 0.29124
Total Iteration Time: 4.76887

Cumulative Model Updates: 253,856
Cumulative Timesteps: 2,117,746,104

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2117746104...
Checkpoint 2117746104 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 106,127.33605
Policy Entropy: 2.67283
Value Function Loss: 0.01457

Mean KL Divergence: 0.00647
SB3 Clip Fraction: 0.06184
Policy Update Magnitude: 0.30216
Value Function Update Magnitude: 0.32888

Collected Steps per Second: 21,822.88183
Overall Steps per Second: 10,483.65018

Timestep Collection Time: 2.29291
Timestep Consumption Time: 2.48004
PPO Batch Consumption Time: 0.27825
Total Iteration Time: 4.77296

Cumulative Model Updates: 253,862
Cumulative Timesteps: 2,117,796,142

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 120,685.84789
Policy Entropy: 2.66767
Value Function Loss: 0.01277

Mean KL Divergence: 0.00758
SB3 Clip Fraction: 0.06999
Policy Update Magnitude: 0.29896
Value Function Update Magnitude: 0.34481

Collected Steps per Second: 22,149.44839
Overall Steps per Second: 10,507.33182

Timestep Collection Time: 2.25866
Timestep Consumption Time: 2.50259
PPO Batch Consumption Time: 0.29154
Total Iteration Time: 4.76125

Cumulative Model Updates: 253,868
Cumulative Timesteps: 2,117,846,170

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2117846170...
Checkpoint 2117846170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 103,895.08398
Policy Entropy: 2.65602
Value Function Loss: 0.01315

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.07897
Policy Update Magnitude: 0.29251
Value Function Update Magnitude: 0.33226

Collected Steps per Second: 21,959.04068
Overall Steps per Second: 10,630.18636

Timestep Collection Time: 2.27697
Timestep Consumption Time: 2.42662
PPO Batch Consumption Time: 0.27810
Total Iteration Time: 4.70359

Cumulative Model Updates: 253,874
Cumulative Timesteps: 2,117,896,170

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 146,901.07590
Policy Entropy: 2.66072
Value Function Loss: 0.01261

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.08476
Policy Update Magnitude: 0.29019
Value Function Update Magnitude: 0.28931

Collected Steps per Second: 22,119.00022
Overall Steps per Second: 10,521.04729

Timestep Collection Time: 2.26050
Timestep Consumption Time: 2.49188
PPO Batch Consumption Time: 0.29116
Total Iteration Time: 4.75238

Cumulative Model Updates: 253,880
Cumulative Timesteps: 2,117,946,170

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2117946170...
Checkpoint 2117946170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 95,084.37047
Policy Entropy: 2.66732
Value Function Loss: 0.01282

Mean KL Divergence: 0.01106
SB3 Clip Fraction: 0.09570
Policy Update Magnitude: 0.29093
Value Function Update Magnitude: 0.24678

Collected Steps per Second: 22,072.96965
Overall Steps per Second: 10,512.69931

Timestep Collection Time: 2.26621
Timestep Consumption Time: 2.49203
PPO Batch Consumption Time: 0.29076
Total Iteration Time: 4.75825

Cumulative Model Updates: 253,886
Cumulative Timesteps: 2,117,996,192

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79,344.73736
Policy Entropy: 2.66562
Value Function Loss: 0.01316

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.08920
Policy Update Magnitude: 0.29288
Value Function Update Magnitude: 0.24204

Collected Steps per Second: 22,132.04056
Overall Steps per Second: 10,499.96145

Timestep Collection Time: 2.26052
Timestep Consumption Time: 2.50426
PPO Batch Consumption Time: 0.29274
Total Iteration Time: 4.76478

Cumulative Model Updates: 253,892
Cumulative Timesteps: 2,118,046,222

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2118046222...
Checkpoint 2118046222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 61,969.69316
Policy Entropy: 2.64718
Value Function Loss: 0.01437

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.07999
Policy Update Magnitude: 0.30308
Value Function Update Magnitude: 0.25461

Collected Steps per Second: 21,840.25997
Overall Steps per Second: 10,615.33101

Timestep Collection Time: 2.29054
Timestep Consumption Time: 2.42208
PPO Batch Consumption Time: 0.27819
Total Iteration Time: 4.71262

Cumulative Model Updates: 253,898
Cumulative Timesteps: 2,118,096,248

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80,421.48240
Policy Entropy: 2.64015
Value Function Loss: 0.01342

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.07635
Policy Update Magnitude: 0.30380
Value Function Update Magnitude: 0.31568

Collected Steps per Second: 21,154.13449
Overall Steps per Second: 10,465.01920

Timestep Collection Time: 2.36436
Timestep Consumption Time: 2.41499
PPO Batch Consumption Time: 0.28935
Total Iteration Time: 4.77935

Cumulative Model Updates: 253,904
Cumulative Timesteps: 2,118,146,264

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2118146264...
Checkpoint 2118146264 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 167,912.51598
Policy Entropy: 2.63385
Value Function Loss: 0.01324

Mean KL Divergence: 0.00730
SB3 Clip Fraction: 0.06705
Policy Update Magnitude: 0.30313
Value Function Update Magnitude: 0.32673

Collected Steps per Second: 20,884.61968
Overall Steps per Second: 10,554.31263

Timestep Collection Time: 2.39497
Timestep Consumption Time: 2.34414
PPO Batch Consumption Time: 0.27849
Total Iteration Time: 4.73911

Cumulative Model Updates: 253,910
Cumulative Timesteps: 2,118,196,282

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 109,067.33273
Policy Entropy: 2.62727
Value Function Loss: 0.01389

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.07289
Policy Update Magnitude: 0.30866
Value Function Update Magnitude: 0.31334

Collected Steps per Second: 21,153.14412
Overall Steps per Second: 10,510.91071

Timestep Collection Time: 2.36428
Timestep Consumption Time: 2.39382
PPO Batch Consumption Time: 0.28546
Total Iteration Time: 4.75810

Cumulative Model Updates: 253,916
Cumulative Timesteps: 2,118,246,294

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2118246294...
Checkpoint 2118246294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 118,606.44971
Policy Entropy: 2.64568
Value Function Loss: 0.01371

Mean KL Divergence: 0.00739
SB3 Clip Fraction: 0.06747
Policy Update Magnitude: 0.31041
Value Function Update Magnitude: 0.32674

Collected Steps per Second: 20,936.35627
Overall Steps per Second: 10,554.57552

Timestep Collection Time: 2.38972
Timestep Consumption Time: 2.35060
PPO Batch Consumption Time: 0.27858
Total Iteration Time: 4.74031

Cumulative Model Updates: 253,922
Cumulative Timesteps: 2,118,296,326

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 111,068.73425
Policy Entropy: 2.64207
Value Function Loss: 0.01329

Mean KL Divergence: 0.00680
SB3 Clip Fraction: 0.06276
Policy Update Magnitude: 0.30712
Value Function Update Magnitude: 0.31788

Collected Steps per Second: 21,347.60400
Overall Steps per Second: 10,513.01778

Timestep Collection Time: 2.34237
Timestep Consumption Time: 2.41402
PPO Batch Consumption Time: 0.27826
Total Iteration Time: 4.75639

Cumulative Model Updates: 253,928
Cumulative Timesteps: 2,118,346,330

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2118346330...
Checkpoint 2118346330 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 71,518.30460
Policy Entropy: 2.66027
Value Function Loss: 0.01410

Mean KL Divergence: 0.00746
SB3 Clip Fraction: 0.06562
Policy Update Magnitude: 0.30995
Value Function Update Magnitude: 0.34115

Collected Steps per Second: 21,851.17400
Overall Steps per Second: 10,587.39218

Timestep Collection Time: 2.28894
Timestep Consumption Time: 2.43517
PPO Batch Consumption Time: 0.27871
Total Iteration Time: 4.72411

Cumulative Model Updates: 253,934
Cumulative Timesteps: 2,118,396,346

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 111,994.20040
Policy Entropy: 2.63180
Value Function Loss: 0.01413

Mean KL Divergence: 0.00698
SB3 Clip Fraction: 0.06451
Policy Update Magnitude: 0.31441
Value Function Update Magnitude: 0.33563

Collected Steps per Second: 22,033.45714
Overall Steps per Second: 10,419.50635

Timestep Collection Time: 2.27055
Timestep Consumption Time: 2.53083
PPO Batch Consumption Time: 0.29588
Total Iteration Time: 4.80138

Cumulative Model Updates: 253,940
Cumulative Timesteps: 2,118,446,374

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2118446374...
Checkpoint 2118446374 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 95,677.70212
Policy Entropy: 2.63178
Value Function Loss: 0.01411

Mean KL Divergence: 0.00671
SB3 Clip Fraction: 0.06455
Policy Update Magnitude: 0.31318
Value Function Update Magnitude: 0.33571

Collected Steps per Second: 21,776.72369
Overall Steps per Second: 10,414.72757

Timestep Collection Time: 2.29603
Timestep Consumption Time: 2.50486
PPO Batch Consumption Time: 0.29237
Total Iteration Time: 4.80089

Cumulative Model Updates: 253,946
Cumulative Timesteps: 2,118,496,374

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79,775.73909
Policy Entropy: 2.60340
Value Function Loss: 0.01347

Mean KL Divergence: 0.00668
SB3 Clip Fraction: 0.06353
Policy Update Magnitude: 0.31117
Value Function Update Magnitude: 0.31336

Collected Steps per Second: 22,367.84196
Overall Steps per Second: 10,729.57738

Timestep Collection Time: 2.23669
Timestep Consumption Time: 2.42612
PPO Batch Consumption Time: 0.27782
Total Iteration Time: 4.66281

Cumulative Model Updates: 253,952
Cumulative Timesteps: 2,118,546,404

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2118546404...
Checkpoint 2118546404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 132,663.44120
Policy Entropy: 2.60358
Value Function Loss: 0.01287

Mean KL Divergence: 0.00678
SB3 Clip Fraction: 0.06312
Policy Update Magnitude: 0.31067
Value Function Update Magnitude: 0.28623

Collected Steps per Second: 21,582.64842
Overall Steps per Second: 10,379.72260

Timestep Collection Time: 2.31677
Timestep Consumption Time: 2.50051
PPO Batch Consumption Time: 0.29239
Total Iteration Time: 4.81728

Cumulative Model Updates: 253,958
Cumulative Timesteps: 2,118,596,406

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 94,184.30931
Policy Entropy: 2.59848
Value Function Loss: 0.01259

Mean KL Divergence: 0.00711
SB3 Clip Fraction: 0.06593
Policy Update Magnitude: 0.31105
Value Function Update Magnitude: 0.28717

Collected Steps per Second: 21,584.68086
Overall Steps per Second: 10,342.08984

Timestep Collection Time: 2.31711
Timestep Consumption Time: 2.51886
PPO Batch Consumption Time: 0.29544
Total Iteration Time: 4.83597

Cumulative Model Updates: 253,964
Cumulative Timesteps: 2,118,646,420

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2118646420...
Checkpoint 2118646420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 80,728.01535
Policy Entropy: 2.60148
Value Function Loss: 0.01285

Mean KL Divergence: 0.00696
SB3 Clip Fraction: 0.06596
Policy Update Magnitude: 0.30809
Value Function Update Magnitude: 0.28042

Collected Steps per Second: 21,549.29377
Overall Steps per Second: 10,538.21553

Timestep Collection Time: 2.32156
Timestep Consumption Time: 2.42573
PPO Batch Consumption Time: 0.27840
Total Iteration Time: 4.74729

Cumulative Model Updates: 253,970
Cumulative Timesteps: 2,118,696,448

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 74,349.23148
Policy Entropy: 2.63858
Value Function Loss: 0.01197

Mean KL Divergence: 0.00741
SB3 Clip Fraction: 0.07047
Policy Update Magnitude: 0.29873
Value Function Update Magnitude: 0.25813

Collected Steps per Second: 21,648.65462
Overall Steps per Second: 10,541.83195

Timestep Collection Time: 2.30989
Timestep Consumption Time: 2.43369
PPO Batch Consumption Time: 0.27854
Total Iteration Time: 4.74358

Cumulative Model Updates: 253,976
Cumulative Timesteps: 2,118,746,454

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2118746454...
Checkpoint 2118746454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 77,069.20428
Policy Entropy: 2.64459
Value Function Loss: 0.01202

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.07638
Policy Update Magnitude: 0.29382
Value Function Update Magnitude: 0.24921

Collected Steps per Second: 22,032.43290
Overall Steps per Second: 10,579.34837

Timestep Collection Time: 2.26974
Timestep Consumption Time: 2.45720
PPO Batch Consumption Time: 0.27854
Total Iteration Time: 4.72695

Cumulative Model Updates: 253,982
Cumulative Timesteps: 2,118,796,462

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97,311.83285
Policy Entropy: 2.64430
Value Function Loss: 0.01284

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.07349
Policy Update Magnitude: 0.31510
Value Function Update Magnitude: 0.26459

Collected Steps per Second: 21,911.65427
Overall Steps per Second: 10,417.62695

Timestep Collection Time: 2.28262
Timestep Consumption Time: 2.51847
PPO Batch Consumption Time: 0.29070
Total Iteration Time: 4.80109

Cumulative Model Updates: 253,988
Cumulative Timesteps: 2,118,846,478

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2118846478...
Checkpoint 2118846478 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 92,681.09324
Policy Entropy: 2.64690
Value Function Loss: 0.01177

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.06985
Policy Update Magnitude: 0.30159
Value Function Update Magnitude: 0.28016

Collected Steps per Second: 22,190.85556
Overall Steps per Second: 10,674.83051

Timestep Collection Time: 2.25363
Timestep Consumption Time: 2.43122
PPO Batch Consumption Time: 0.27943
Total Iteration Time: 4.68485

Cumulative Model Updates: 253,994
Cumulative Timesteps: 2,118,896,488

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 106,931.96373
Policy Entropy: 2.64792
Value Function Loss: 0.01242

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.07966
Policy Update Magnitude: 0.29167
Value Function Update Magnitude: 0.26844

Collected Steps per Second: 22,278.43409
Overall Steps per Second: 10,500.53612

Timestep Collection Time: 2.24468
Timestep Consumption Time: 2.51774
PPO Batch Consumption Time: 0.29329
Total Iteration Time: 4.76242

Cumulative Model Updates: 254,000
Cumulative Timesteps: 2,118,946,496

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2118946496...
Checkpoint 2118946496 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 60,030.54506
Policy Entropy: 2.64244
Value Function Loss: 0.01388

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.07574
Policy Update Magnitude: 0.29333
Value Function Update Magnitude: 0.26210

Collected Steps per Second: 22,036.73477
Overall Steps per Second: 10,624.01153

Timestep Collection Time: 2.26912
Timestep Consumption Time: 2.43758
PPO Batch Consumption Time: 0.27941
Total Iteration Time: 4.70670

Cumulative Model Updates: 254,006
Cumulative Timesteps: 2,118,996,500

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79,171.79496
Policy Entropy: 2.62917
Value Function Loss: 0.01405

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.07472
Policy Update Magnitude: 0.30619
Value Function Update Magnitude: 0.30670

Collected Steps per Second: 22,021.83170
Overall Steps per Second: 10,447.12784

Timestep Collection Time: 2.27111
Timestep Consumption Time: 2.51623
PPO Batch Consumption Time: 0.29185
Total Iteration Time: 4.78734

Cumulative Model Updates: 254,012
Cumulative Timesteps: 2,119,046,514

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2119046514...
Checkpoint 2119046514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 72,570.83989
Policy Entropy: 2.64218
Value Function Loss: 0.01359

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.07692
Policy Update Magnitude: 0.30871
Value Function Update Magnitude: 0.29545

Collected Steps per Second: 21,693.95599
Overall Steps per Second: 10,573.21737

Timestep Collection Time: 2.30488
Timestep Consumption Time: 2.42424
PPO Batch Consumption Time: 0.27830
Total Iteration Time: 4.72912

Cumulative Model Updates: 254,018
Cumulative Timesteps: 2,119,096,516

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63,667.19812
Policy Entropy: 2.66558
Value Function Loss: 0.01096

Mean KL Divergence: 0.00682
SB3 Clip Fraction: 0.06157
Policy Update Magnitude: 0.29325
Value Function Update Magnitude: 0.25446

Collected Steps per Second: 21,407.78858
Overall Steps per Second: 10,482.66395

Timestep Collection Time: 2.33579
Timestep Consumption Time: 2.43438
PPO Batch Consumption Time: 0.27824
Total Iteration Time: 4.77016

Cumulative Model Updates: 254,024
Cumulative Timesteps: 2,119,146,520

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2119146520...
Checkpoint 2119146520 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48,189.74358
Policy Entropy: 2.66650
Value Function Loss: 0.01190

Mean KL Divergence: 0.00621
SB3 Clip Fraction: 0.05973
Policy Update Magnitude: 0.28146
Value Function Update Magnitude: 0.22821

Collected Steps per Second: 21,513.88519
Overall Steps per Second: 10,382.92639

Timestep Collection Time: 2.32547
Timestep Consumption Time: 2.49301
PPO Batch Consumption Time: 0.29235
Total Iteration Time: 4.81849

Cumulative Model Updates: 254,030
Cumulative Timesteps: 2,119,196,550

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68,301.84520
Policy Entropy: 2.66480
Value Function Loss: 0.01311

Mean KL Divergence: 0.00582
SB3 Clip Fraction: 0.05837
Policy Update Magnitude: 0.28732
Value Function Update Magnitude: 0.23026

Collected Steps per Second: 21,532.24657
Overall Steps per Second: 10,345.94849

Timestep Collection Time: 2.32451
Timestep Consumption Time: 2.51332
PPO Batch Consumption Time: 0.29380
Total Iteration Time: 4.83784

Cumulative Model Updates: 254,036
Cumulative Timesteps: 2,119,246,602

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


Saving checkpoint 2119246602...
Checkpoint 2119246602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 51,689.88208
Policy Entropy: 2.67284
Value Function Loss: 0.01345

Mean KL Divergence: 0.00625
SB3 Clip Fraction: 0.05794
Policy Update Magnitude: 0.29287
Value Function Update Magnitude: 0.28620

Collected Steps per Second: 21,557.00020
Overall Steps per Second: 10,549.93564

Timestep Collection Time: 2.32017
Timestep Consumption Time: 2.42071
PPO Batch Consumption Time: 0.27798
Total Iteration Time: 4.74088

Cumulative Model Updates: 254,042
Cumulative Timesteps: 2,119,296,618

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61,760.75172
Policy Entropy: 2.68035
Value Function Loss: 0.01229

Mean KL Divergence: 0.00653
SB3 Clip Fraction: 0.05932
Policy Update Magnitude: 0.28820
Value Function Update Magnitude: 0.27685

Collected Steps per Second: 22,275.17154
Overall Steps per Second: 10,634.57892

Timestep Collection Time: 2.24546
Timestep Consumption Time: 2.45788
PPO Batch Consumption Time: 0.27699
Total Iteration Time: 4.70334

Cumulative Model Updates: 254,048
Cumulative Timesteps: 2,119,346,636

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2119346636...
Checkpoint 2119346636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 63,800.95300
Policy Entropy: 2.67592
Value Function Loss: 0.01065

Mean KL Divergence: 0.00641
SB3 Clip Fraction: 0.06115
Policy Update Magnitude: 0.27576
Value Function Update Magnitude: 0.27043

Collected Steps per Second: 21,865.70025
Overall Steps per Second: 10,598.15608

Timestep Collection Time: 2.28733
Timestep Consumption Time: 2.43180
PPO Batch Consumption Time: 0.27729
Total Iteration Time: 4.71912

Cumulative Model Updates: 254,054
Cumulative Timesteps: 2,119,396,650

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66,735.82819
Policy Entropy: 2.65056
Value Function Loss: 0.01145

Mean KL Divergence: 0.00698
SB3 Clip Fraction: 0.06461
Policy Update Magnitude: 0.27653
Value Function Update Magnitude: 0.26486

Collected Steps per Second: 22,136.67056
Overall Steps per Second: 10,505.32790

Timestep Collection Time: 2.26005
Timestep Consumption Time: 2.50229
PPO Batch Consumption Time: 0.29352
Total Iteration Time: 4.76235

Cumulative Model Updates: 254,060
Cumulative Timesteps: 2,119,446,680

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2119446680...
Checkpoint 2119446680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 97,967.70304
Policy Entropy: 2.64993
Value Function Loss: 0.01220

Mean KL Divergence: 0.00691
SB3 Clip Fraction: 0.06515
Policy Update Magnitude: 0.28694
Value Function Update Magnitude: 0.27331

Collected Steps per Second: 21,913.79962
Overall Steps per Second: 10,522.08614

Timestep Collection Time: 2.28358
Timestep Consumption Time: 2.47232
PPO Batch Consumption Time: 0.28656
Total Iteration Time: 4.75590

Cumulative Model Updates: 254,066
Cumulative Timesteps: 2,119,496,722

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89,184.29240
Policy Entropy: 2.65402
Value Function Loss: 0.01175

Mean KL Divergence: 0.00628
SB3 Clip Fraction: 0.05957
Policy Update Magnitude: 0.28722
Value Function Update Magnitude: 0.27262

Collected Steps per Second: 22,017.30389
Overall Steps per Second: 10,479.51150

Timestep Collection Time: 2.27194
Timestep Consumption Time: 2.50137
PPO Batch Consumption Time: 0.29038
Total Iteration Time: 4.77331

Cumulative Model Updates: 254,072
Cumulative Timesteps: 2,119,546,744

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2119546744...
Checkpoint 2119546744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 126,131.84953
Policy Entropy: 2.66418
Value Function Loss: 0.01348

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.06821
Policy Update Magnitude: 0.29040
Value Function Update Magnitude: 0.30470

Collected Steps per Second: 22,185.50275
Overall Steps per Second: 10,619.28168

Timestep Collection Time: 2.25372
Timestep Consumption Time: 2.45469
PPO Batch Consumption Time: 0.28403
Total Iteration Time: 4.70842

Cumulative Model Updates: 254,078
Cumulative Timesteps: 2,119,596,744

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83,379.26933
Policy Entropy: 2.65551
Value Function Loss: 0.01579

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.07424
Policy Update Magnitude: 0.30626
Value Function Update Magnitude: 0.35034

Collected Steps per Second: 22,025.69750
Overall Steps per Second: 10,483.07111

Timestep Collection Time: 2.27098
Timestep Consumption Time: 2.50052
PPO Batch Consumption Time: 0.29288
Total Iteration Time: 4.77150

Cumulative Model Updates: 254,084
Cumulative Timesteps: 2,119,646,764

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2119646764...
Checkpoint 2119646764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 70,737.21659
Policy Entropy: 2.64938
Value Function Loss: 0.01588

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.08066
Policy Update Magnitude: 0.31936
Value Function Update Magnitude: 0.37571

Collected Steps per Second: 21,489.37922
Overall Steps per Second: 10,537.52035

Timestep Collection Time: 2.32757
Timestep Consumption Time: 2.41909
PPO Batch Consumption Time: 0.27838
Total Iteration Time: 4.74666

Cumulative Model Updates: 254,090
Cumulative Timesteps: 2,119,696,782

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 71,331.33800
Policy Entropy: 2.64547
Value Function Loss: 0.01503

Mean KL Divergence: 0.01250
SB3 Clip Fraction: 0.10083
Policy Update Magnitude: 0.31530
Value Function Update Magnitude: 0.38353

Collected Steps per Second: 21,561.60572
Overall Steps per Second: 10,495.69273

Timestep Collection Time: 2.31949
Timestep Consumption Time: 2.44551
PPO Batch Consumption Time: 0.27862
Total Iteration Time: 4.76500

Cumulative Model Updates: 254,096
Cumulative Timesteps: 2,119,746,794

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2119746794...
Checkpoint 2119746794 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 95,053.96184
Policy Entropy: 2.65545
Value Function Loss: 0.01537

Mean KL Divergence: 0.01241
SB3 Clip Fraction: 0.10239
Policy Update Magnitude: 0.31395
Value Function Update Magnitude: 0.35247

Collected Steps per Second: 21,141.34519
Overall Steps per Second: 10,250.92360

Timestep Collection Time: 2.36560
Timestep Consumption Time: 2.51318
PPO Batch Consumption Time: 0.29389
Total Iteration Time: 4.87878

Cumulative Model Updates: 254,102
Cumulative Timesteps: 2,119,796,806

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 139,176.12077
Policy Entropy: 2.64006
Value Function Loss: 0.01539

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.08875
Policy Update Magnitude: 0.31206
Value Function Update Magnitude: 0.35007

Collected Steps per Second: 21,848.68144
Overall Steps per Second: 10,429.71075

Timestep Collection Time: 2.28984
Timestep Consumption Time: 2.50703
PPO Batch Consumption Time: 0.29179
Total Iteration Time: 4.79687

Cumulative Model Updates: 254,108
Cumulative Timesteps: 2,119,846,836

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2119846836...
Checkpoint 2119846836 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 116,073.29529
Policy Entropy: 2.67096
Value Function Loss: 0.01247

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.07471
Policy Update Magnitude: 0.30124
Value Function Update Magnitude: 0.33915

Collected Steps per Second: 20,753.47186
Overall Steps per Second: 10,337.56460

Timestep Collection Time: 2.41001
Timestep Consumption Time: 2.42827
PPO Batch Consumption Time: 0.29121
Total Iteration Time: 4.83828

Cumulative Model Updates: 254,114
Cumulative Timesteps: 2,119,896,852

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84,300.22958
Policy Entropy: 2.67440
Value Function Loss: 0.01347

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.07970
Policy Update Magnitude: 0.29614
Value Function Update Magnitude: 0.31277

Collected Steps per Second: 21,757.20005
Overall Steps per Second: 10,695.20431

Timestep Collection Time: 2.29956
Timestep Consumption Time: 2.37842
PPO Batch Consumption Time: 0.27836
Total Iteration Time: 4.67798

Cumulative Model Updates: 254,120
Cumulative Timesteps: 2,119,946,884

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2119946884...
Checkpoint 2119946884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 82,049.49785
Policy Entropy: 2.70534
Value Function Loss: 0.01225

Mean KL Divergence: 0.00711
SB3 Clip Fraction: 0.06362
Policy Update Magnitude: 0.29142
Value Function Update Magnitude: 0.30638

Collected Steps per Second: 21,320.98536
Overall Steps per Second: 10,643.34274

Timestep Collection Time: 2.34567
Timestep Consumption Time: 2.35323
PPO Batch Consumption Time: 0.27804
Total Iteration Time: 4.69890

Cumulative Model Updates: 254,126
Cumulative Timesteps: 2,119,996,896

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82,049.49785
Policy Entropy: 2.66910
Value Function Loss: 0.01277

Mean KL Divergence: 0.00644
SB3 Clip Fraction: 0.05951
Policy Update Magnitude: 0.28495
Value Function Update Magnitude: 0.27035

Collected Steps per Second: 21,547.96050
Overall Steps per Second: 10,567.81475

Timestep Collection Time: 2.32087
Timestep Consumption Time: 2.41142
PPO Batch Consumption Time: 0.27803
Total Iteration Time: 4.73229

Cumulative Model Updates: 254,132
Cumulative Timesteps: 2,120,046,906

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2120046906...
Checkpoint 2120046906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 80,881.34674
Policy Entropy: 2.67703
Value Function Loss: 0.01173

Mean KL Divergence: 0.00703
SB3 Clip Fraction: 0.06469
Policy Update Magnitude: 0.28493
Value Function Update Magnitude: 0.24814

Collected Steps per Second: 21,399.84169
Overall Steps per Second: 10,541.07633

Timestep Collection Time: 2.33665
Timestep Consumption Time: 2.40708
PPO Batch Consumption Time: 0.27845
Total Iteration Time: 4.74373

Cumulative Model Updates: 254,138
Cumulative Timesteps: 2,120,096,910

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 69,623.89052
Policy Entropy: 2.65446
Value Function Loss: 0.01217

Mean KL Divergence: 0.00683
SB3 Clip Fraction: 0.06476
Policy Update Magnitude: 0.28836
Value Function Update Magnitude: 0.22972

Collected Steps per Second: 22,248.41601
Overall Steps per Second: 10,601.20489

Timestep Collection Time: 2.24888
Timestep Consumption Time: 2.47077
PPO Batch Consumption Time: 0.29263
Total Iteration Time: 4.71965

Cumulative Model Updates: 254,144
Cumulative Timesteps: 2,120,146,944

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 2120146944...
Checkpoint 2120146944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 62,158.65877
Policy Entropy: 2.65442
Value Function Loss: 0.01297

Mean KL Divergence: 0.00627
SB3 Clip Fraction: 0.06170
Policy Update Magnitude: 0.29163
Value Function Update Magnitude: 0.24519

Collected Steps per Second: 21,941.31050
Overall Steps per Second: 10,515.96949

Timestep Collection Time: 2.28063
Timestep Consumption Time: 2.47785
PPO Batch Consumption Time: 0.28597
Total Iteration Time: 4.75848

Cumulative Model Updates: 254,150
Cumulative Timesteps: 2,120,196,984

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 132,052.07339
Policy Entropy: 2.65493
Value Function Loss: 0.01468

Mean KL Divergence: 0.00619
SB3 Clip Fraction: 0.06143
Policy Update Magnitude: 0.30847
Value Function Update Magnitude: 0.28117

Collected Steps per Second: 21,939.26893
Overall Steps per Second: 10,459.89345

Timestep Collection Time: 2.28020
Timestep Consumption Time: 2.50245
PPO Batch Consumption Time: 0.28875
Total Iteration Time: 4.78265

Cumulative Model Updates: 254,156
Cumulative Timesteps: 2,120,247,010

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2120247010...
Checkpoint 2120247010 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 99,940.75413
Policy Entropy: 2.64890
Value Function Loss: 0.01536

Mean KL Divergence: 0.00682
SB3 Clip Fraction: 0.06306
Policy Update Magnitude: 0.30977
Value Function Update Magnitude: 0.32327

Collected Steps per Second: 21,244.79401
Overall Steps per Second: 10,282.49744

Timestep Collection Time: 2.35361
Timestep Consumption Time: 2.50921
PPO Batch Consumption Time: 0.29336
Total Iteration Time: 4.86283

Cumulative Model Updates: 254,162
Cumulative Timesteps: 2,120,297,012

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 94,733.88128
Policy Entropy: 2.66004
Value Function Loss: 0.01440

Mean KL Divergence: 0.00693
SB3 Clip Fraction: 0.06636
Policy Update Magnitude: 0.30062
Value Function Update Magnitude: 0.33602

Collected Steps per Second: 20,800.76372
Overall Steps per Second: 10,078.27725

Timestep Collection Time: 2.40549
Timestep Consumption Time: 2.55925
PPO Batch Consumption Time: 0.29209
Total Iteration Time: 4.96474

Cumulative Model Updates: 254,168
Cumulative Timesteps: 2,120,347,048

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 2120347048...
Checkpoint 2120347048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86,614.38767
Policy Entropy: 2.65841
Value Function Loss: 0.01374

Mean KL Divergence: 0.00617
SB3 Clip Fraction: 0.05834
Policy Update Magnitude: 0.29745
Value Function Update Magnitude: 0.33042

Collected Steps per Second: 21,696.73365
Overall Steps per Second: 10,470.69634

Timestep Collection Time: 2.30652
Timestep Consumption Time: 2.47291
PPO Batch Consumption Time: 0.27828
Total Iteration Time: 4.77943

Cumulative Model Updates: 254,174
Cumulative Timesteps: 2,120,397,092

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 64,094.25744
Policy Entropy: 2.66433
Value Function Loss: 0.01222

Mean KL Divergence: 0.00614
SB3 Clip Fraction: 0.05847
Policy Update Magnitude: 0.29799
Value Function Update Magnitude: 0.28990

Collected Steps per Second: 22,258.67245
Overall Steps per Second: 10,449.73481

Timestep Collection Time: 2.24775
Timestep Consumption Time: 2.54012
PPO Batch Consumption Time: 0.29446
Total Iteration Time: 4.78787

Cumulative Model Updates: 254,180
Cumulative Timesteps: 2,120,447,124

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2120447124...
Checkpoint 2120447124 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 53,319.87338
Policy Entropy: 2.65632
Value Function Loss: 0.01564

Mean KL Divergence: 0.00657
SB3 Clip Fraction: 0.06331
Policy Update Magnitude: 0.31264
Value Function Update Magnitude: 0.27864

Collected Steps per Second: 21,627.01915
Overall Steps per Second: 10,406.50951

Timestep Collection Time: 2.31257
Timestep Consumption Time: 2.49346
PPO Batch Consumption Time: 0.29043
Total Iteration Time: 4.80603

Cumulative Model Updates: 254,186
Cumulative Timesteps: 2,120,497,138

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67,520.72915
Policy Entropy: 2.66022
Value Function Loss: 0.01527

Mean KL Divergence: 0.00656
SB3 Clip Fraction: 0.06223
Policy Update Magnitude: 0.32083
Value Function Update Magnitude: 0.27924

Collected Steps per Second: 22,387.08544
Overall Steps per Second: 10,709.82512

Timestep Collection Time: 2.23361
Timestep Consumption Time: 2.43537
PPO Batch Consumption Time: 0.27986
Total Iteration Time: 4.66898

Cumulative Model Updates: 254,192
Cumulative Timesteps: 2,120,547,142

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2120547142...
Checkpoint 2120547142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 93,821.16970
Policy Entropy: 2.64024
Value Function Loss: 0.01619

Mean KL Divergence: 0.00699
SB3 Clip Fraction: 0.06294
Policy Update Magnitude: 0.32526
Value Function Update Magnitude: 0.30211

Collected Steps per Second: 21,820.23726
Overall Steps per Second: 10,604.41137

Timestep Collection Time: 2.29209
Timestep Consumption Time: 2.42425
PPO Batch Consumption Time: 0.27812
Total Iteration Time: 4.71634

Cumulative Model Updates: 254,198
Cumulative Timesteps: 2,120,597,156

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77,283.85530
Policy Entropy: 2.66125
Value Function Loss: 0.01620

Mean KL Divergence: 0.00744
SB3 Clip Fraction: 0.06605
Policy Update Magnitude: 0.32193
Value Function Update Magnitude: 0.33981

Collected Steps per Second: 22,204.17270
Overall Steps per Second: 10,496.14082

Timestep Collection Time: 2.25183
Timestep Consumption Time: 2.51183
PPO Batch Consumption Time: 0.29213
Total Iteration Time: 4.76366

Cumulative Model Updates: 254,204
Cumulative Timesteps: 2,120,647,156

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2120647156...
Checkpoint 2120647156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 77,283.85530
Policy Entropy: 2.68534
Value Function Loss: 0.01519

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.07182
Policy Update Magnitude: 0.30930
Value Function Update Magnitude: 0.31834

Collected Steps per Second: 21,690.18670
Overall Steps per Second: 10,586.09165

Timestep Collection Time: 2.30602
Timestep Consumption Time: 2.41886
PPO Batch Consumption Time: 0.27835
Total Iteration Time: 4.72488

Cumulative Model Updates: 254,210
Cumulative Timesteps: 2,120,697,174

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 116,050.47484
Policy Entropy: 2.69583
Value Function Loss: 0.01346

Mean KL Divergence: 0.00655
SB3 Clip Fraction: 0.05825
Policy Update Magnitude: 0.29490
Value Function Update Magnitude: 0.30835

Collected Steps per Second: 22,043.63644
Overall Steps per Second: 10,559.88065

Timestep Collection Time: 2.26823
Timestep Consumption Time: 2.46667
PPO Batch Consumption Time: 0.28564
Total Iteration Time: 4.73490

Cumulative Model Updates: 254,216
Cumulative Timesteps: 2,120,747,174

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2120747174...
Checkpoint 2120747174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 158,322.96661
Policy Entropy: 2.68929
Value Function Loss: 0.01306

Mean KL Divergence: 0.00639
SB3 Clip Fraction: 0.05779
Policy Update Magnitude: 0.30319
Value Function Update Magnitude: 0.32797

Collected Steps per Second: 20,725.86781
Overall Steps per Second: 10,373.56145

Timestep Collection Time: 2.41331
Timestep Consumption Time: 2.40837
PPO Batch Consumption Time: 0.28916
Total Iteration Time: 4.82168

Cumulative Model Updates: 254,222
Cumulative Timesteps: 2,120,797,192

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 142,963.68173
Policy Entropy: 2.67910
Value Function Loss: 0.01146

Mean KL Divergence: 0.00738
SB3 Clip Fraction: 0.06570
Policy Update Magnitude: 0.30377
Value Function Update Magnitude: 0.33618

Collected Steps per Second: 21,265.37576
Overall Steps per Second: 10,636.08959

Timestep Collection Time: 2.35143
Timestep Consumption Time: 2.34992
PPO Batch Consumption Time: 0.27834
Total Iteration Time: 4.70135

Cumulative Model Updates: 254,228
Cumulative Timesteps: 2,120,847,196

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2120847196...
Checkpoint 2120847196 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 102,023.64396
Policy Entropy: 2.67500
Value Function Loss: 0.01307

Mean KL Divergence: 0.00716
SB3 Clip Fraction: 0.06348
Policy Update Magnitude: 0.30194
Value Function Update Magnitude: 0.30111

Collected Steps per Second: 20,872.18795
Overall Steps per Second: 10,377.37663

Timestep Collection Time: 2.39697
Timestep Consumption Time: 2.42409
PPO Batch Consumption Time: 0.29199
Total Iteration Time: 4.82106

Cumulative Model Updates: 254,234
Cumulative Timesteps: 2,120,897,226

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82,540.61549
Policy Entropy: 2.67137
Value Function Loss: 0.01357

Mean KL Divergence: 0.00703
SB3 Clip Fraction: 0.06411
Policy Update Magnitude: 0.30478
Value Function Update Magnitude: 0.29796

Collected Steps per Second: 21,666.94451
Overall Steps per Second: 10,387.13021

Timestep Collection Time: 2.30886
Timestep Consumption Time: 2.50729
PPO Batch Consumption Time: 0.29265
Total Iteration Time: 4.81615

Cumulative Model Updates: 254,240
Cumulative Timesteps: 2,120,947,252

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2120947252...
Checkpoint 2120947252 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 63,561.73026
Policy Entropy: 2.67574
Value Function Loss: 0.01373

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.07692
Policy Update Magnitude: 0.29976
Value Function Update Magnitude: 0.32241

Collected Steps per Second: 22,052.67751
Overall Steps per Second: 10,571.80867

Timestep Collection Time: 2.26821
Timestep Consumption Time: 2.46325
PPO Batch Consumption Time: 0.28860
Total Iteration Time: 4.73145

Cumulative Model Updates: 254,246
Cumulative Timesteps: 2,120,997,272

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79,887.58395
Policy Entropy: 2.68670
Value Function Loss: 0.01193

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.06706
Policy Update Magnitude: 0.29142
Value Function Update Magnitude: 0.31437

Collected Steps per Second: 22,202.08219
Overall Steps per Second: 10,594.03823

Timestep Collection Time: 2.25267
Timestep Consumption Time: 2.46829
PPO Batch Consumption Time: 0.29125
Total Iteration Time: 4.72096

Cumulative Model Updates: 254,252
Cumulative Timesteps: 2,121,047,286

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2121047286...
Checkpoint 2121047286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 75,352.57120
Policy Entropy: 2.68886
Value Function Loss: 0.01121

Mean KL Divergence: 0.00645
SB3 Clip Fraction: 0.06018
Policy Update Magnitude: 0.28472
Value Function Update Magnitude: 0.29132

Collected Steps per Second: 22,048.49540
Overall Steps per Second: 10,492.64801

Timestep Collection Time: 2.26836
Timestep Consumption Time: 2.49821
PPO Batch Consumption Time: 0.29124
Total Iteration Time: 4.76658

Cumulative Model Updates: 254,258
Cumulative Timesteps: 2,121,097,300

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75,352.57120
Policy Entropy: 2.68600
Value Function Loss: 0.00968

Mean KL Divergence: 0.00578
SB3 Clip Fraction: 0.05503
Policy Update Magnitude: 0.26963
Value Function Update Magnitude: 0.27229

Collected Steps per Second: 22,313.40522
Overall Steps per Second: 10,545.87220

Timestep Collection Time: 2.24206
Timestep Consumption Time: 2.50179
PPO Batch Consumption Time: 0.29326
Total Iteration Time: 4.74385

Cumulative Model Updates: 254,264
Cumulative Timesteps: 2,121,147,328

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2121147328...
Checkpoint 2121147328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86,611.36629
Policy Entropy: 2.65786
Value Function Loss: 0.01001

Mean KL Divergence: 0.00541
SB3 Clip Fraction: 0.04969
Policy Update Magnitude: 0.26967
Value Function Update Magnitude: 0.26066

Collected Steps per Second: 21,479.87085
Overall Steps per Second: 10,497.34389

Timestep Collection Time: 2.32832
Timestep Consumption Time: 2.43593
PPO Batch Consumption Time: 0.27937
Total Iteration Time: 4.76425

Cumulative Model Updates: 254,270
Cumulative Timesteps: 2,121,197,340

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95,263.64294
Policy Entropy: 2.65595
Value Function Loss: 0.01096

Mean KL Divergence: 0.00596
SB3 Clip Fraction: 0.05652
Policy Update Magnitude: 0.26956
Value Function Update Magnitude: 0.24585

Collected Steps per Second: 22,083.63722
Overall Steps per Second: 10,500.61452

Timestep Collection Time: 2.26512
Timestep Consumption Time: 2.49861
PPO Batch Consumption Time: 0.28902
Total Iteration Time: 4.76372

Cumulative Model Updates: 254,276
Cumulative Timesteps: 2,121,247,362

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2121247362...
Checkpoint 2121247362 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 95,263.64294
Policy Entropy: 2.66887
Value Function Loss: 0.01128

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.07644
Policy Update Magnitude: 0.27126
Value Function Update Magnitude: 0.25031

Collected Steps per Second: 21,371.76155
Overall Steps per Second: 10,363.59788

Timestep Collection Time: 2.34075
Timestep Consumption Time: 2.48634
PPO Batch Consumption Time: 0.29153
Total Iteration Time: 4.82709

Cumulative Model Updates: 254,282
Cumulative Timesteps: 2,121,297,388

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 116,599.91987
Policy Entropy: 2.67875
Value Function Loss: 0.01424

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.07491
Policy Update Magnitude: 0.29338
Value Function Update Magnitude: 0.26571

Collected Steps per Second: 21,661.23079
Overall Steps per Second: 10,393.70549

Timestep Collection Time: 2.30910
Timestep Consumption Time: 2.50323
PPO Batch Consumption Time: 0.29328
Total Iteration Time: 4.81234

Cumulative Model Updates: 254,288
Cumulative Timesteps: 2,121,347,406

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2121347406...
Checkpoint 2121347406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 81,450.69980
Policy Entropy: 2.67765
Value Function Loss: 0.01380

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.07417
Policy Update Magnitude: 0.31318
Value Function Update Magnitude: 0.33185

Collected Steps per Second: 21,617.49641
Overall Steps per Second: 10,537.60535

Timestep Collection Time: 2.31405
Timestep Consumption Time: 2.43314
PPO Batch Consumption Time: 0.27824
Total Iteration Time: 4.74719

Cumulative Model Updates: 254,294
Cumulative Timesteps: 2,121,397,430

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 71,757.47512
Policy Entropy: 2.65039
Value Function Loss: 0.01428

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.08162
Policy Update Magnitude: 0.31467
Value Function Update Magnitude: 0.35238

Collected Steps per Second: 20,935.13770
Overall Steps per Second: 10,556.64198

Timestep Collection Time: 2.38900
Timestep Consumption Time: 2.34868
PPO Batch Consumption Time: 0.27704
Total Iteration Time: 4.73768

Cumulative Model Updates: 254,300
Cumulative Timesteps: 2,121,447,444

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2121447444...
Checkpoint 2121447444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 92,677.40215
Policy Entropy: 2.64060
Value Function Loss: 0.01293

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.08322
Policy Update Magnitude: 0.31174
Value Function Update Magnitude: 0.32662

Collected Steps per Second: 20,971.30178
Overall Steps per Second: 10,524.61435

Timestep Collection Time: 2.38421
Timestep Consumption Time: 2.36656
PPO Batch Consumption Time: 0.27895
Total Iteration Time: 4.75077

Cumulative Model Updates: 254,306
Cumulative Timesteps: 2,121,497,444

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92,677.40215
Policy Entropy: 2.65660
Value Function Loss: 0.01179

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.07268
Policy Update Magnitude: 0.30048
Value Function Update Magnitude: 0.30853

Collected Steps per Second: 21,407.32714
Overall Steps per Second: 10,470.45767

Timestep Collection Time: 2.33602
Timestep Consumption Time: 2.44008
PPO Batch Consumption Time: 0.27850
Total Iteration Time: 4.77610

Cumulative Model Updates: 254,312
Cumulative Timesteps: 2,121,547,452

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2121547452...
Checkpoint 2121547452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 92,350.20803
Policy Entropy: 2.67412
Value Function Loss: 0.01136

Mean KL Divergence: 0.01059
SB3 Clip Fraction: 0.08881
Policy Update Magnitude: 0.28449
Value Function Update Magnitude: 0.27030

Collected Steps per Second: 21,967.80281
Overall Steps per Second: 10,706.98353

Timestep Collection Time: 2.27670
Timestep Consumption Time: 2.39446
PPO Batch Consumption Time: 0.27683
Total Iteration Time: 4.67116

Cumulative Model Updates: 254,318
Cumulative Timesteps: 2,121,597,466

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85,135.57557
Policy Entropy: 2.68799
Value Function Loss: 0.01063

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.07172
Policy Update Magnitude: 0.27505
Value Function Update Magnitude: 0.26238

Collected Steps per Second: 22,058.62120
Overall Steps per Second: 10,571.96928

Timestep Collection Time: 2.26768
Timestep Consumption Time: 2.46388
PPO Batch Consumption Time: 0.28983
Total Iteration Time: 4.73157

Cumulative Model Updates: 254,324
Cumulative Timesteps: 2,121,647,488

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2121647488...
Checkpoint 2121647488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 81,121.30643
Policy Entropy: 2.68695
Value Function Loss: 0.01084

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.07533
Policy Update Magnitude: 0.27303
Value Function Update Magnitude: 0.25557

Collected Steps per Second: 22,267.33707
Overall Steps per Second: 10,526.66606

Timestep Collection Time: 2.24607
Timestep Consumption Time: 2.50510
PPO Batch Consumption Time: 0.29330
Total Iteration Time: 4.75117

Cumulative Model Updates: 254,330
Cumulative Timesteps: 2,121,697,502

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 74,049.04877
Policy Entropy: 2.68868
Value Function Loss: 0.00975

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.07209
Policy Update Magnitude: 0.26773
Value Function Update Magnitude: 0.23572

Collected Steps per Second: 22,153.61790
Overall Steps per Second: 10,557.00371

Timestep Collection Time: 2.25823
Timestep Consumption Time: 2.48061
PPO Batch Consumption Time: 0.29054
Total Iteration Time: 4.73884

Cumulative Model Updates: 254,336
Cumulative Timesteps: 2,121,747,530

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2121747530...
Checkpoint 2121747530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 74,049.04877
Policy Entropy: 2.67748
Value Function Loss: 0.00970

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.08223
Policy Update Magnitude: 0.26356
Value Function Update Magnitude: 0.23388

Collected Steps per Second: 21,863.69083
Overall Steps per Second: 10,449.70344

Timestep Collection Time: 2.28799
Timestep Consumption Time: 2.49913
PPO Batch Consumption Time: 0.29094
Total Iteration Time: 4.78712

Cumulative Model Updates: 254,342
Cumulative Timesteps: 2,121,797,554

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 74,049.04877
Policy Entropy: 2.65286
Value Function Loss: 0.01036

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.08105
Policy Update Magnitude: 0.27302
Value Function Update Magnitude: 0.24192

Collected Steps per Second: 22,017.25410
Overall Steps per Second: 10,471.70356

Timestep Collection Time: 2.27185
Timestep Consumption Time: 2.50483
PPO Batch Consumption Time: 0.28948
Total Iteration Time: 4.77668

Cumulative Model Updates: 254,348
Cumulative Timesteps: 2,121,847,574

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2121847574...
Checkpoint 2121847574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 73,045.04323
Policy Entropy: 2.65328
Value Function Loss: 0.01103

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.08456
Policy Update Magnitude: 0.28657
Value Function Update Magnitude: 0.22927

Collected Steps per Second: 21,489.18045
Overall Steps per Second: 10,417.53497

Timestep Collection Time: 2.32861
Timestep Consumption Time: 2.47483
PPO Batch Consumption Time: 0.28854
Total Iteration Time: 4.80344

Cumulative Model Updates: 254,354
Cumulative Timesteps: 2,121,897,614

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 72,629.07637
Policy Entropy: 2.65657
Value Function Loss: 0.01148

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.07840
Policy Update Magnitude: 0.29800
Value Function Update Magnitude: 0.26331

Collected Steps per Second: 21,755.02390
Overall Steps per Second: 10,628.00702

Timestep Collection Time: 2.29832
Timestep Consumption Time: 2.40623
PPO Batch Consumption Time: 0.27777
Total Iteration Time: 4.70455

Cumulative Model Updates: 254,360
Cumulative Timesteps: 2,121,947,614

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2121947614...
Checkpoint 2121947614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 128,949.95488
Policy Entropy: 2.66693
Value Function Loss: 0.01189

Mean KL Divergence: 0.00698
SB3 Clip Fraction: 0.06571
Policy Update Magnitude: 0.29752
Value Function Update Magnitude: 0.28614

Collected Steps per Second: 21,145.49350
Overall Steps per Second: 10,609.44623

Timestep Collection Time: 2.36523
Timestep Consumption Time: 2.34887
PPO Batch Consumption Time: 0.27857
Total Iteration Time: 4.71410

Cumulative Model Updates: 254,366
Cumulative Timesteps: 2,121,997,628

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 138,733.72761
Policy Entropy: 2.66372
Value Function Loss: 0.01352

Mean KL Divergence: 0.00725
SB3 Clip Fraction: 0.06620
Policy Update Magnitude: 0.30060
Value Function Update Magnitude: 0.28221

Collected Steps per Second: 21,487.64755
Overall Steps per Second: 10,505.36198

Timestep Collection Time: 2.32766
Timestep Consumption Time: 2.43333
PPO Batch Consumption Time: 0.28600
Total Iteration Time: 4.76100

Cumulative Model Updates: 254,372
Cumulative Timesteps: 2,122,047,644

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2122047644...
Checkpoint 2122047644 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 139,606.08911
Policy Entropy: 2.67433
Value Function Loss: 0.01439

Mean KL Divergence: 0.00746
SB3 Clip Fraction: 0.06846
Policy Update Magnitude: 0.30324
Value Function Update Magnitude: 0.26115

Collected Steps per Second: 21,516.29750
Overall Steps per Second: 10,674.10927

Timestep Collection Time: 2.32596
Timestep Consumption Time: 2.36258
PPO Batch Consumption Time: 0.27952
Total Iteration Time: 4.68854

Cumulative Model Updates: 254,378
Cumulative Timesteps: 2,122,097,690

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 139,606.08911
Policy Entropy: 2.66717
Value Function Loss: 0.01314

Mean KL Divergence: 0.00677
SB3 Clip Fraction: 0.06258
Policy Update Magnitude: 0.30095
Value Function Update Magnitude: 0.20813

Collected Steps per Second: 21,817.35696
Overall Steps per Second: 10,467.72484

Timestep Collection Time: 2.29240
Timestep Consumption Time: 2.48553
PPO Batch Consumption Time: 0.29251
Total Iteration Time: 4.77792

Cumulative Model Updates: 254,384
Cumulative Timesteps: 2,122,147,704

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2122147704...
Checkpoint 2122147704 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 157,624.95163
Policy Entropy: 2.63932
Value Function Loss: 0.01392

Mean KL Divergence: 0.00604
SB3 Clip Fraction: 0.05717
Policy Update Magnitude: 0.30474
Value Function Update Magnitude: 0.20659

Collected Steps per Second: 21,972.42292
Overall Steps per Second: 10,701.99942

Timestep Collection Time: 2.27786
Timestep Consumption Time: 2.39884
PPO Batch Consumption Time: 0.27829
Total Iteration Time: 4.67670

Cumulative Model Updates: 254,390
Cumulative Timesteps: 2,122,197,754

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 117,950.62495
Policy Entropy: 2.63051
Value Function Loss: 0.01476

Mean KL Divergence: 0.00663
SB3 Clip Fraction: 0.06276
Policy Update Magnitude: 0.31234
Value Function Update Magnitude: 0.21759

Collected Steps per Second: 20,916.98276
Overall Steps per Second: 10,406.16496

Timestep Collection Time: 2.39145
Timestep Consumption Time: 2.41550
PPO Batch Consumption Time: 0.27906
Total Iteration Time: 4.80696

Cumulative Model Updates: 254,396
Cumulative Timesteps: 2,122,247,776

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2122247776...
Checkpoint 2122247776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 81,770.52530
Policy Entropy: 2.61816
Value Function Loss: 0.01581

Mean KL Divergence: 0.00644
SB3 Clip Fraction: 0.06189
Policy Update Magnitude: 0.32427
Value Function Update Magnitude: 0.21553

Collected Steps per Second: 21,078.46048
Overall Steps per Second: 10,227.07885

Timestep Collection Time: 2.37294
Timestep Consumption Time: 2.51780
PPO Batch Consumption Time: 0.29406
Total Iteration Time: 4.89074

Cumulative Model Updates: 254,402
Cumulative Timesteps: 2,122,297,794

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92,340.69948
Policy Entropy: 2.64523
Value Function Loss: 0.01401

Mean KL Divergence: 0.00684
SB3 Clip Fraction: 0.06490
Policy Update Magnitude: 0.31561
Value Function Update Magnitude: 0.26947

Collected Steps per Second: 21,626.99779
Overall Steps per Second: 10,424.21687

Timestep Collection Time: 2.31331
Timestep Consumption Time: 2.48609
PPO Batch Consumption Time: 0.28633
Total Iteration Time: 4.79940

Cumulative Model Updates: 254,408
Cumulative Timesteps: 2,122,347,824

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2122347824...
Checkpoint 2122347824 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 118,338.59339
Policy Entropy: 2.65424
Value Function Loss: 0.01464

Mean KL Divergence: 0.00671
SB3 Clip Fraction: 0.06430
Policy Update Magnitude: 0.31623
Value Function Update Magnitude: 0.29690

Collected Steps per Second: 21,665.75044
Overall Steps per Second: 10,573.57861

Timestep Collection Time: 2.31019
Timestep Consumption Time: 2.42350
PPO Batch Consumption Time: 0.27836
Total Iteration Time: 4.73369

Cumulative Model Updates: 254,414
Cumulative Timesteps: 2,122,397,876

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 132,360.02678
Policy Entropy: 2.66669
Value Function Loss: 0.01253

Mean KL Divergence: 0.00690
SB3 Clip Fraction: 0.06389
Policy Update Magnitude: 0.30428
Value Function Update Magnitude: 0.29850

Collected Steps per Second: 22,321.80116
Overall Steps per Second: 10,519.95953

Timestep Collection Time: 2.24059
Timestep Consumption Time: 2.51361
PPO Batch Consumption Time: 0.28616
Total Iteration Time: 4.75420

Cumulative Model Updates: 254,420
Cumulative Timesteps: 2,122,447,890

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2122447890...
Checkpoint 2122447890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 92,167.30883
Policy Entropy: 2.67102
Value Function Loss: 0.01429

Mean KL Divergence: 0.00743
SB3 Clip Fraction: 0.06373
Policy Update Magnitude: 0.30518
Value Function Update Magnitude: 0.29826

Collected Steps per Second: 22,012.76056
Overall Steps per Second: 10,600.00337

Timestep Collection Time: 2.27286
Timestep Consumption Time: 2.44714
PPO Batch Consumption Time: 0.27929
Total Iteration Time: 4.72000

Cumulative Model Updates: 254,426
Cumulative Timesteps: 2,122,497,922

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82,002.15042
Policy Entropy: 2.68076
Value Function Loss: 0.01253

Mean KL Divergence: 0.00650
SB3 Clip Fraction: 0.05855
Policy Update Magnitude: 0.30307
Value Function Update Magnitude: 0.30386

Collected Steps per Second: 22,209.10047
Overall Steps per Second: 10,516.12889

Timestep Collection Time: 2.25241
Timestep Consumption Time: 2.50447
PPO Batch Consumption Time: 0.29392
Total Iteration Time: 4.75688

Cumulative Model Updates: 254,432
Cumulative Timesteps: 2,122,547,946

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2122547946...
Checkpoint 2122547946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 106,411.13324
Policy Entropy: 2.70001
Value Function Loss: 0.01213

Mean KL Divergence: 0.00668
SB3 Clip Fraction: 0.05929
Policy Update Magnitude: 0.29006
Value Function Update Magnitude: 0.32019

Collected Steps per Second: 21,851.56802
Overall Steps per Second: 10,555.63332

Timestep Collection Time: 2.29018
Timestep Consumption Time: 2.45080
PPO Batch Consumption Time: 0.28014
Total Iteration Time: 4.74098

Cumulative Model Updates: 254,438
Cumulative Timesteps: 2,122,597,990

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 123,509.44399
Policy Entropy: 2.70386
Value Function Loss: 0.01094

Mean KL Divergence: 0.00641
SB3 Clip Fraction: 0.05939
Policy Update Magnitude: 0.28859
Value Function Update Magnitude: 0.30905

Collected Steps per Second: 22,156.82801
Overall Steps per Second: 10,505.73745

Timestep Collection Time: 2.25718
Timestep Consumption Time: 2.50326
PPO Batch Consumption Time: 0.29051
Total Iteration Time: 4.76045

Cumulative Model Updates: 254,444
Cumulative Timesteps: 2,122,648,002

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2122648002...
Checkpoint 2122648002 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 90,605.57755
Policy Entropy: 2.72095
Value Function Loss: 0.01065

Mean KL Divergence: 0.00669
SB3 Clip Fraction: 0.06344
Policy Update Magnitude: 0.27772
Value Function Update Magnitude: 0.29455

Collected Steps per Second: 21,918.48804
Overall Steps per Second: 10,627.92329

Timestep Collection Time: 2.28264
Timestep Consumption Time: 2.42496
PPO Batch Consumption Time: 0.27846
Total Iteration Time: 4.70760

Cumulative Model Updates: 254,450
Cumulative Timesteps: 2,122,698,034

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 114,399.79968
Policy Entropy: 2.69863
Value Function Loss: 0.01177

Mean KL Divergence: 0.00736
SB3 Clip Fraction: 0.06558
Policy Update Magnitude: 0.28321
Value Function Update Magnitude: 0.29006

Collected Steps per Second: 21,604.69277
Overall Steps per Second: 10,551.17432

Timestep Collection Time: 2.31570
Timestep Consumption Time: 2.42595
PPO Batch Consumption Time: 0.27770
Total Iteration Time: 4.74165

Cumulative Model Updates: 254,456
Cumulative Timesteps: 2,122,748,064

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2122748064...
Checkpoint 2122748064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 99,574.12576
Policy Entropy: 2.70108
Value Function Loss: 0.01147

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.07627
Policy Update Magnitude: 0.28553
Value Function Update Magnitude: 0.29236

Collected Steps per Second: 21,247.34233
Overall Steps per Second: 10,476.93773

Timestep Collection Time: 2.35455
Timestep Consumption Time: 2.42051
PPO Batch Consumption Time: 0.27859
Total Iteration Time: 4.77506

Cumulative Model Updates: 254,462
Cumulative Timesteps: 2,122,798,092

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79,530.86384
Policy Entropy: 2.67334
Value Function Loss: 0.01177

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.08091
Policy Update Magnitude: 0.28565
Value Function Update Magnitude: 0.28552

Collected Steps per Second: 21,702.91783
Overall Steps per Second: 10,584.03522

Timestep Collection Time: 2.30421
Timestep Consumption Time: 2.42065
PPO Batch Consumption Time: 0.27722
Total Iteration Time: 4.72485

Cumulative Model Updates: 254,468
Cumulative Timesteps: 2,122,848,100

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2122848100...
Checkpoint 2122848100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 142,447.56035
Policy Entropy: 2.66149
Value Function Loss: 0.01223

Mean KL Divergence: 0.00757
SB3 Clip Fraction: 0.06949
Policy Update Magnitude: 0.29574
Value Function Update Magnitude: 0.28801

Collected Steps per Second: 21,597.90364
Overall Steps per Second: 10,502.03142

Timestep Collection Time: 2.31513
Timestep Consumption Time: 2.44604
PPO Batch Consumption Time: 0.27841
Total Iteration Time: 4.76117

Cumulative Model Updates: 254,474
Cumulative Timesteps: 2,122,898,102

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 126,129.72564
Policy Entropy: 2.64571
Value Function Loss: 0.01379

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.07337
Policy Update Magnitude: 0.31136
Value Function Update Magnitude: 0.32573

Collected Steps per Second: 22,020.91093
Overall Steps per Second: 10,626.35012

Timestep Collection Time: 2.27175
Timestep Consumption Time: 2.43598
PPO Batch Consumption Time: 0.27724
Total Iteration Time: 4.70773

Cumulative Model Updates: 254,480
Cumulative Timesteps: 2,122,948,128

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2122948128...
Checkpoint 2122948128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 98,163.99254
Policy Entropy: 2.69398
Value Function Loss: 0.01210

Mean KL Divergence: 0.00736
SB3 Clip Fraction: 0.07080
Policy Update Magnitude: 0.30954
Value Function Update Magnitude: 0.32388

Collected Steps per Second: 21,983.18972
Overall Steps per Second: 10,490.85339

Timestep Collection Time: 2.27447
Timestep Consumption Time: 2.49159
PPO Batch Consumption Time: 0.28741
Total Iteration Time: 4.76606

Cumulative Model Updates: 254,486
Cumulative Timesteps: 2,122,998,128

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57,725.24864
Policy Entropy: 2.70535
Value Function Loss: 0.01238

Mean KL Divergence: 0.00724
SB3 Clip Fraction: 0.06579
Policy Update Magnitude: 0.30486
Value Function Update Magnitude: 0.31230

Collected Steps per Second: 22,217.46328
Overall Steps per Second: 10,497.74146

Timestep Collection Time: 2.25120
Timestep Consumption Time: 2.51325
PPO Batch Consumption Time: 0.29324
Total Iteration Time: 4.76445

Cumulative Model Updates: 254,492
Cumulative Timesteps: 2,123,048,144

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2123048144...
Checkpoint 2123048144 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 75,283.66600
Policy Entropy: 2.70984
Value Function Loss: 0.01426

Mean KL Divergence: 0.00763
SB3 Clip Fraction: 0.07121
Policy Update Magnitude: 0.30453
Value Function Update Magnitude: 0.31883

Collected Steps per Second: 22,236.06566
Overall Steps per Second: 10,662.30668

Timestep Collection Time: 2.24896
Timestep Consumption Time: 2.44121
PPO Batch Consumption Time: 0.27801
Total Iteration Time: 4.69017

Cumulative Model Updates: 254,498
Cumulative Timesteps: 2,123,098,152

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 71,554.19059
Policy Entropy: 2.67159
Value Function Loss: 0.01427

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.07401
Policy Update Magnitude: 0.30354
Value Function Update Magnitude: 0.31214

Collected Steps per Second: 22,167.19264
Overall Steps per Second: 10,475.82214

Timestep Collection Time: 2.25568
Timestep Consumption Time: 2.51741
PPO Batch Consumption Time: 0.29350
Total Iteration Time: 4.77309

Cumulative Model Updates: 254,504
Cumulative Timesteps: 2,123,148,154

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2123148154...
Checkpoint 2123148154 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 67,414.11987
Policy Entropy: 2.66281
Value Function Loss: 0.01592

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.07107
Policy Update Magnitude: 0.31351
Value Function Update Magnitude: 0.31661

Collected Steps per Second: 22,245.06162
Overall Steps per Second: 10,592.90123

Timestep Collection Time: 2.24787
Timestep Consumption Time: 2.47265
PPO Batch Consumption Time: 0.28614
Total Iteration Time: 4.72052

Cumulative Model Updates: 254,510
Cumulative Timesteps: 2,123,198,158

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56,985.38175
Policy Entropy: 2.67663
Value Function Loss: 0.01674

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.07584
Policy Update Magnitude: 0.32784
Value Function Update Magnitude: 0.32771

Collected Steps per Second: 21,681.29297
Overall Steps per Second: 10,523.92666

Timestep Collection Time: 2.30669
Timestep Consumption Time: 2.44553
PPO Batch Consumption Time: 0.27747
Total Iteration Time: 4.75222

Cumulative Model Updates: 254,516
Cumulative Timesteps: 2,123,248,170

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2123248170...
Checkpoint 2123248170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 56,985.38175
Policy Entropy: 2.68624
Value Function Loss: 0.01518

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.08074
Policy Update Magnitude: 0.30646
Value Function Update Magnitude: 0.31685

Collected Steps per Second: 21,675.89703
Overall Steps per Second: 10,541.29639

Timestep Collection Time: 2.30791
Timestep Consumption Time: 2.43781
PPO Batch Consumption Time: 0.27863
Total Iteration Time: 4.74572

Cumulative Model Updates: 254,522
Cumulative Timesteps: 2,123,298,196

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52,182.85650
Policy Entropy: 2.68464
Value Function Loss: 0.01304

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.08150
Policy Update Magnitude: 0.28733
Value Function Update Magnitude: 0.29781

Collected Steps per Second: 21,585.89370
Overall Steps per Second: 10,493.23488

Timestep Collection Time: 2.31818
Timestep Consumption Time: 2.45061
PPO Batch Consumption Time: 0.27884
Total Iteration Time: 4.76879

Cumulative Model Updates: 254,528
Cumulative Timesteps: 2,123,348,236

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 2123348236...
Checkpoint 2123348236 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 52,182.85650
Policy Entropy: 2.67656
Value Function Loss: 0.01007

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.07656
Policy Update Magnitude: 0.28023
Value Function Update Magnitude: 0.27264

Collected Steps per Second: 21,666.32517
Overall Steps per Second: 10,364.49861

Timestep Collection Time: 2.30893
Timestep Consumption Time: 2.51774
PPO Batch Consumption Time: 0.29065
Total Iteration Time: 4.82667

Cumulative Model Updates: 254,534
Cumulative Timesteps: 2,123,398,262

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76,672.69252
Policy Entropy: 2.66451
Value Function Loss: 0.01177

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.07638
Policy Update Magnitude: 0.28926
Value Function Update Magnitude: 0.26430

Collected Steps per Second: 22,356.37717
Overall Steps per Second: 10,643.03695

Timestep Collection Time: 2.23811
Timestep Consumption Time: 2.46318
PPO Batch Consumption Time: 0.27939
Total Iteration Time: 4.70129

Cumulative Model Updates: 254,540
Cumulative Timesteps: 2,123,448,298

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 2123448298...
Checkpoint 2123448298 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 63,314.70814
Policy Entropy: 2.65017
Value Function Loss: 0.01236

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.07315
Policy Update Magnitude: 0.30297
Value Function Update Magnitude: 0.28002

Collected Steps per Second: 21,890.95641
Overall Steps per Second: 10,597.91010

Timestep Collection Time: 2.28505
Timestep Consumption Time: 2.43493
PPO Batch Consumption Time: 0.27983
Total Iteration Time: 4.71999

Cumulative Model Updates: 254,546
Cumulative Timesteps: 2,123,498,320

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 137,316.66339
Policy Entropy: 2.61569
Value Function Loss: 0.01343

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.07367
Policy Update Magnitude: 0.31628
Value Function Update Magnitude: 0.27395

Collected Steps per Second: 21,958.61639
Overall Steps per Second: 10,641.48474

Timestep Collection Time: 2.27792
Timestep Consumption Time: 2.42255
PPO Batch Consumption Time: 0.27757
Total Iteration Time: 4.70047

Cumulative Model Updates: 254,552
Cumulative Timesteps: 2,123,548,340

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2123548340...
Checkpoint 2123548340 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 171,434.94081
Policy Entropy: 2.61970
Value Function Loss: 0.01382

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.06818
Policy Update Magnitude: 0.31869
Value Function Update Magnitude: 0.28719

Collected Steps per Second: 21,957.25756
Overall Steps per Second: 10,657.80787

Timestep Collection Time: 2.27852
Timestep Consumption Time: 2.41569
PPO Batch Consumption Time: 0.27703
Total Iteration Time: 4.69421

Cumulative Model Updates: 254,558
Cumulative Timesteps: 2,123,598,370

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 125,372.62804
Policy Entropy: 2.64616
Value Function Loss: 0.01239

Mean KL Divergence: 0.00702
SB3 Clip Fraction: 0.06705
Policy Update Magnitude: 0.31375
Value Function Update Magnitude: 0.30226

Collected Steps per Second: 22,362.91419
Overall Steps per Second: 10,773.17848

Timestep Collection Time: 2.23754
Timestep Consumption Time: 2.40714
PPO Batch Consumption Time: 0.27829
Total Iteration Time: 4.64468

Cumulative Model Updates: 254,564
Cumulative Timesteps: 2,123,648,408

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 2123648408...
Checkpoint 2123648408 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 123,877.27650
Policy Entropy: 2.66241
Value Function Loss: 0.01203

Mean KL Divergence: 0.00748
SB3 Clip Fraction: 0.07025
Policy Update Magnitude: 0.30224
Value Function Update Magnitude: 0.29159

Collected Steps per Second: 21,159.88054
Overall Steps per Second: 10,624.30002

Timestep Collection Time: 2.36296
Timestep Consumption Time: 2.34323
PPO Batch Consumption Time: 0.27804
Total Iteration Time: 4.70619

Cumulative Model Updates: 254,570
Cumulative Timesteps: 2,123,698,408

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 120,953.09740
Policy Entropy: 2.64761
Value Function Loss: 0.01110

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.07334
Policy Update Magnitude: 0.29361
Value Function Update Magnitude: 0.28169

Collected Steps per Second: 21,071.95401
Overall Steps per Second: 10,628.65513

Timestep Collection Time: 2.37292
Timestep Consumption Time: 2.33154
PPO Batch Consumption Time: 0.27694
Total Iteration Time: 4.70445

Cumulative Model Updates: 254,576
Cumulative Timesteps: 2,123,748,410

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2123748410...
Checkpoint 2123748410 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 124,288.48077
Policy Entropy: 2.64395
Value Function Loss: 0.01177

Mean KL Divergence: 0.00731
SB3 Clip Fraction: 0.07064
Policy Update Magnitude: 0.29182
Value Function Update Magnitude: 0.29963

Collected Steps per Second: 20,976.84799
Overall Steps per Second: 10,475.95455

Timestep Collection Time: 2.38530
Timestep Consumption Time: 2.39097
PPO Batch Consumption Time: 0.27773
Total Iteration Time: 4.77627

Cumulative Model Updates: 254,582
Cumulative Timesteps: 2,123,798,446

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60,734.24281
Policy Entropy: 2.64811
Value Function Loss: 0.01253

Mean KL Divergence: 0.00721
SB3 Clip Fraction: 0.06691
Policy Update Magnitude: 0.29724
Value Function Update Magnitude: 0.31209

Collected Steps per Second: 21,460.90873
Overall Steps per Second: 10,531.73380

Timestep Collection Time: 2.33066
Timestep Consumption Time: 2.41861
PPO Batch Consumption Time: 0.27915
Total Iteration Time: 4.74927

Cumulative Model Updates: 254,588
Cumulative Timesteps: 2,123,848,464

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2123848464...
Checkpoint 2123848464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 56,208.00783
Policy Entropy: 2.64774
Value Function Loss: 0.01495

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.07585
Policy Update Magnitude: 0.30632
Value Function Update Magnitude: 0.30080

Collected Steps per Second: 21,550.23644
Overall Steps per Second: 10,576.59118

Timestep Collection Time: 2.32220
Timestep Consumption Time: 2.40938
PPO Batch Consumption Time: 0.27905
Total Iteration Time: 4.73158

Cumulative Model Updates: 254,594
Cumulative Timesteps: 2,123,898,508

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58,117.03230
Policy Entropy: 2.64006
Value Function Loss: 0.01469

Mean KL Divergence: 0.00749
SB3 Clip Fraction: 0.06775
Policy Update Magnitude: 0.31091
Value Function Update Magnitude: 0.29091

Collected Steps per Second: 22,036.77073
Overall Steps per Second: 10,591.86603

Timestep Collection Time: 2.27039
Timestep Consumption Time: 2.45324
PPO Batch Consumption Time: 0.27680
Total Iteration Time: 4.72362

Cumulative Model Updates: 254,600
Cumulative Timesteps: 2,123,948,540

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2123948540...
Checkpoint 2123948540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 59,161.14361
Policy Entropy: 2.62583
Value Function Loss: 0.01531

Mean KL Divergence: 0.00759
SB3 Clip Fraction: 0.07207
Policy Update Magnitude: 0.31026
Value Function Update Magnitude: 0.27422

Collected Steps per Second: 21,784.23020
Overall Steps per Second: 10,633.68478

Timestep Collection Time: 2.29597
Timestep Consumption Time: 2.40757
PPO Batch Consumption Time: 0.27695
Total Iteration Time: 4.70354

Cumulative Model Updates: 254,606
Cumulative Timesteps: 2,123,998,556

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60,929.32352
Policy Entropy: 2.62491
Value Function Loss: 0.01357

Mean KL Divergence: 0.00777
SB3 Clip Fraction: 0.07559
Policy Update Magnitude: 0.31258
Value Function Update Magnitude: 0.27560

Collected Steps per Second: 22,370.73417
Overall Steps per Second: 10,609.87158

Timestep Collection Time: 2.23542
Timestep Consumption Time: 2.47793
PPO Batch Consumption Time: 0.28800
Total Iteration Time: 4.71335

Cumulative Model Updates: 254,612
Cumulative Timesteps: 2,124,048,564

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2124048564...
Checkpoint 2124048564 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 62,336.56023
Policy Entropy: 2.62327
Value Function Loss: 0.01304

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.07614
Policy Update Magnitude: 0.30822
Value Function Update Magnitude: 0.28941

Collected Steps per Second: 21,770.05061
Overall Steps per Second: 10,380.80227

Timestep Collection Time: 2.29701
Timestep Consumption Time: 2.52015
PPO Batch Consumption Time: 0.29392
Total Iteration Time: 4.81716

Cumulative Model Updates: 254,618
Cumulative Timesteps: 2,124,098,570

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84,425.25737
Policy Entropy: 2.62611
Value Function Loss: 0.01314

Mean KL Divergence: 0.00750
SB3 Clip Fraction: 0.06673
Policy Update Magnitude: 0.30906
Value Function Update Magnitude: 0.28699

Collected Steps per Second: 21,979.78705
Overall Steps per Second: 10,471.80045

Timestep Collection Time: 2.27491
Timestep Consumption Time: 2.50001
PPO Batch Consumption Time: 0.28880
Total Iteration Time: 4.77492

Cumulative Model Updates: 254,624
Cumulative Timesteps: 2,124,148,572

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2124148572...
Checkpoint 2124148572 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 79,797.60996
Policy Entropy: 2.62633
Value Function Loss: 0.01533

Mean KL Divergence: 0.00734
SB3 Clip Fraction: 0.06845
Policy Update Magnitude: 0.32272
Value Function Update Magnitude: 0.30919

Collected Steps per Second: 21,181.08695
Overall Steps per Second: 10,309.80507

Timestep Collection Time: 2.36173
Timestep Consumption Time: 2.49035
PPO Batch Consumption Time: 0.29203
Total Iteration Time: 4.85208

Cumulative Model Updates: 254,630
Cumulative Timesteps: 2,124,198,596

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91,907.28977
Policy Entropy: 2.62232
Value Function Loss: 0.01589

Mean KL Divergence: 0.01115
SB3 Clip Fraction: 0.09611
Policy Update Magnitude: 0.32795
Value Function Update Magnitude: 0.33155

Collected Steps per Second: 21,896.70910
Overall Steps per Second: 10,425.88296

Timestep Collection Time: 2.28500
Timestep Consumption Time: 2.51402
PPO Batch Consumption Time: 0.29344
Total Iteration Time: 4.79902

Cumulative Model Updates: 254,636
Cumulative Timesteps: 2,124,248,630

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 2124248630...
Checkpoint 2124248630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 93,002.06138
Policy Entropy: 2.58699
Value Function Loss: 0.01610

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.08135
Policy Update Magnitude: 0.32922
Value Function Update Magnitude: 0.35246

Collected Steps per Second: 21,312.57656
Overall Steps per Second: 10,289.10983

Timestep Collection Time: 2.34688
Timestep Consumption Time: 2.51438
PPO Batch Consumption Time: 0.29010
Total Iteration Time: 4.86126

Cumulative Model Updates: 254,642
Cumulative Timesteps: 2,124,298,648

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77,188.26739
Policy Entropy: 2.58294
Value Function Loss: 0.01354

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.08897
Policy Update Magnitude: 0.33109
Value Function Update Magnitude: 0.37694

Collected Steps per Second: 21,956.12437
Overall Steps per Second: 10,641.96899

Timestep Collection Time: 2.27763
Timestep Consumption Time: 2.42150
PPO Batch Consumption Time: 0.27814
Total Iteration Time: 4.69913

Cumulative Model Updates: 254,648
Cumulative Timesteps: 2,124,348,656

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2124348656...
Checkpoint 2124348656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 132,022.88311
Policy Entropy: 2.59186
Value Function Loss: 0.01297

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.07926
Policy Update Magnitude: 0.32423
Value Function Update Magnitude: 0.35787

Collected Steps per Second: 21,386.50223
Overall Steps per Second: 10,286.53153

Timestep Collection Time: 2.33951
Timestep Consumption Time: 2.52452
PPO Batch Consumption Time: 0.29259
Total Iteration Time: 4.86403

Cumulative Model Updates: 254,654
Cumulative Timesteps: 2,124,398,690

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 121,910.71293
Policy Entropy: 2.64235
Value Function Loss: 0.01334

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.07090
Policy Update Magnitude: 0.31864
Value Function Update Magnitude: 0.33865

Collected Steps per Second: 22,156.60550
Overall Steps per Second: 10,415.28021

Timestep Collection Time: 2.25820
Timestep Consumption Time: 2.54571
PPO Batch Consumption Time: 0.28954
Total Iteration Time: 4.80390

Cumulative Model Updates: 254,660
Cumulative Timesteps: 2,124,448,724

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 2124448724...
Checkpoint 2124448724 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 104,901.04330
Policy Entropy: 2.66620
Value Function Loss: 0.01442

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.06759
Policy Update Magnitude: 0.30414
Value Function Update Magnitude: 0.33030

Collected Steps per Second: 22,004.22490
Overall Steps per Second: 10,590.15660

Timestep Collection Time: 2.27229
Timestep Consumption Time: 2.44907
PPO Batch Consumption Time: 0.27823
Total Iteration Time: 4.72137

Cumulative Model Updates: 254,666
Cumulative Timesteps: 2,124,498,724

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75,980.92844
Policy Entropy: 2.66181
Value Function Loss: 0.01537

Mean KL Divergence: 0.00721
SB3 Clip Fraction: 0.06736
Policy Update Magnitude: 0.30758
Value Function Update Magnitude: 0.32662

Collected Steps per Second: 22,219.57012
Overall Steps per Second: 10,531.03005

Timestep Collection Time: 2.25063
Timestep Consumption Time: 2.49800
PPO Batch Consumption Time: 0.29092
Total Iteration Time: 4.74863

Cumulative Model Updates: 254,672
Cumulative Timesteps: 2,124,548,732

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2124548732...
Checkpoint 2124548732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 85,857.73611
Policy Entropy: 2.63465
Value Function Loss: 0.01503

Mean KL Divergence: 0.00748
SB3 Clip Fraction: 0.06806
Policy Update Magnitude: 0.31134
Value Function Update Magnitude: 0.32988

Collected Steps per Second: 21,958.88348
Overall Steps per Second: 10,639.16576

Timestep Collection Time: 2.27698
Timestep Consumption Time: 2.42263
PPO Batch Consumption Time: 0.27856
Total Iteration Time: 4.69962

Cumulative Model Updates: 254,678
Cumulative Timesteps: 2,124,598,732

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62,816.97869
Policy Entropy: 2.62406
Value Function Loss: 0.01511

Mean KL Divergence: 0.00757
SB3 Clip Fraction: 0.07236
Policy Update Magnitude: 0.32846
Value Function Update Magnitude: 0.39275

Collected Steps per Second: 22,290.60037
Overall Steps per Second: 10,542.49151

Timestep Collection Time: 2.24516
Timestep Consumption Time: 2.50191
PPO Batch Consumption Time: 0.29246
Total Iteration Time: 4.74708

Cumulative Model Updates: 254,684
Cumulative Timesteps: 2,124,648,778

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 2124648778...
Checkpoint 2124648778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 56,271.09246
Policy Entropy: 2.63228
Value Function Loss: 0.01243

Mean KL Divergence: 0.01162
SB3 Clip Fraction: 0.09538
Policy Update Magnitude: 0.31920
Value Function Update Magnitude: 0.40261

Collected Steps per Second: 21,786.29116
Overall Steps per Second: 10,607.16856

Timestep Collection Time: 2.29539
Timestep Consumption Time: 2.41916
PPO Batch Consumption Time: 0.27670
Total Iteration Time: 4.71455

Cumulative Model Updates: 254,690
Cumulative Timesteps: 2,124,698,786

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54,605.41458
Policy Entropy: 2.64477
Value Function Loss: 0.01199

Mean KL Divergence: 0.01769
SB3 Clip Fraction: 0.12290
Policy Update Magnitude: 0.28668
Value Function Update Magnitude: 0.36606

Collected Steps per Second: 22,144.13439
Overall Steps per Second: 10,539.94473

Timestep Collection Time: 2.25911
Timestep Consumption Time: 2.48722
PPO Batch Consumption Time: 0.29085
Total Iteration Time: 4.74632

Cumulative Model Updates: 254,696
Cumulative Timesteps: 2,124,748,812

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2124748812...
Checkpoint 2124748812 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 62,309.91491
Policy Entropy: 2.64842
Value Function Loss: 0.01305

Mean KL Divergence: 0.01142
SB3 Clip Fraction: 0.10127
Policy Update Magnitude: 0.28819
Value Function Update Magnitude: 0.29309

Collected Steps per Second: 21,330.40191
Overall Steps per Second: 10,509.42858

Timestep Collection Time: 2.34407
Timestep Consumption Time: 2.41356
PPO Batch Consumption Time: 0.27641
Total Iteration Time: 4.75763

Cumulative Model Updates: 254,702
Cumulative Timesteps: 2,124,798,812

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87,244.66667
Policy Entropy: 2.65389
Value Function Loss: 0.01543

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.09305
Policy Update Magnitude: 0.30050
Value Function Update Magnitude: 0.26802

Collected Steps per Second: 21,749.29546
Overall Steps per Second: 10,406.55970

Timestep Collection Time: 2.29902
Timestep Consumption Time: 2.50584
PPO Batch Consumption Time: 0.29097
Total Iteration Time: 4.80485

Cumulative Model Updates: 254,708
Cumulative Timesteps: 2,124,848,814

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2124848814...
Checkpoint 2124848814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87,244.66667
Policy Entropy: 2.64008
Value Function Loss: 0.01564

Mean KL Divergence: 0.01060
SB3 Clip Fraction: 0.09287
Policy Update Magnitude: 0.30600
Value Function Update Magnitude: 0.24439

Collected Steps per Second: 21,520.45737
Overall Steps per Second: 10,415.36403

Timestep Collection Time: 2.32365
Timestep Consumption Time: 2.47753
PPO Batch Consumption Time: 0.28794
Total Iteration Time: 4.80118

Cumulative Model Updates: 254,714
Cumulative Timesteps: 2,124,898,820

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 69,049.35323
Policy Entropy: 2.62034
Value Function Loss: 0.01578

Mean KL Divergence: 0.01076
SB3 Clip Fraction: 0.09283
Policy Update Magnitude: 0.31050
Value Function Update Magnitude: 0.24588

Collected Steps per Second: 21,739.39878
Overall Steps per Second: 10,422.94448

Timestep Collection Time: 2.30071
Timestep Consumption Time: 2.49794
PPO Batch Consumption Time: 0.28989
Total Iteration Time: 4.79864

Cumulative Model Updates: 254,720
Cumulative Timesteps: 2,124,948,836

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2124948836...
Checkpoint 2124948836 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 69,049.35323
Policy Entropy: 2.62587
Value Function Loss: 0.01271

Mean KL Divergence: 0.01292
SB3 Clip Fraction: 0.09973
Policy Update Magnitude: 0.30631
Value Function Update Magnitude: 0.26594

Collected Steps per Second: 21,579.94703
Overall Steps per Second: 10,464.91332

Timestep Collection Time: 2.31799
Timestep Consumption Time: 2.46199
PPO Batch Consumption Time: 0.28398
Total Iteration Time: 4.77997

Cumulative Model Updates: 254,726
Cumulative Timesteps: 2,124,998,858

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97,075.45365
Policy Entropy: 2.62914
Value Function Loss: 0.01401

Mean KL Divergence: 0.01702
SB3 Clip Fraction: 0.12821
Policy Update Magnitude: 0.29530
Value Function Update Magnitude: 0.28250

Collected Steps per Second: 22,307.00402
Overall Steps per Second: 10,490.87577

Timestep Collection Time: 2.24181
Timestep Consumption Time: 2.52500
PPO Batch Consumption Time: 0.29300
Total Iteration Time: 4.76681

Cumulative Model Updates: 254,732
Cumulative Timesteps: 2,125,048,866

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2125048866...
Checkpoint 2125048866 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 74,551.52624
Policy Entropy: 2.63570
Value Function Loss: 0.01471

Mean KL Divergence: 0.01174
SB3 Clip Fraction: 0.10104
Policy Update Magnitude: 0.30509
Value Function Update Magnitude: 0.31838

Collected Steps per Second: 21,265.84039
Overall Steps per Second: 10,606.18625

Timestep Collection Time: 2.35232
Timestep Consumption Time: 2.36418
PPO Batch Consumption Time: 0.27865
Total Iteration Time: 4.71649

Cumulative Model Updates: 254,738
Cumulative Timesteps: 2,125,098,890

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 105,282.33254
Policy Entropy: 2.61404
Value Function Loss: 0.01510

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.08572
Policy Update Magnitude: 0.31711
Value Function Update Magnitude: 0.36579

Collected Steps per Second: 21,390.62403
Overall Steps per Second: 10,452.49771

Timestep Collection Time: 2.33869
Timestep Consumption Time: 2.44734
PPO Batch Consumption Time: 0.29359
Total Iteration Time: 4.78603

Cumulative Model Updates: 254,744
Cumulative Timesteps: 2,125,148,916

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2125148916...
Checkpoint 2125148916 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 105,282.33254
Policy Entropy: 2.58921
Value Function Loss: 0.01394

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.07593
Policy Update Magnitude: 0.31826
Value Function Update Magnitude: 0.37041

Collected Steps per Second: 21,074.51186
Overall Steps per Second: 10,277.32734

Timestep Collection Time: 2.37301
Timestep Consumption Time: 2.49304
PPO Batch Consumption Time: 0.29359
Total Iteration Time: 4.86605

Cumulative Model Updates: 254,750
Cumulative Timesteps: 2,125,198,926

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89,606.66002
Policy Entropy: 2.59829
Value Function Loss: 0.01340

Mean KL Divergence: 0.00745
SB3 Clip Fraction: 0.06922
Policy Update Magnitude: 0.32101
Value Function Update Magnitude: 0.31013

Collected Steps per Second: 21,985.66286
Overall Steps per Second: 10,511.21594

Timestep Collection Time: 2.27521
Timestep Consumption Time: 2.48371
PPO Batch Consumption Time: 0.29210
Total Iteration Time: 4.75892

Cumulative Model Updates: 254,756
Cumulative Timesteps: 2,125,248,948

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2125248948...
Checkpoint 2125248948 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 129,534.11082
Policy Entropy: 2.59104
Value Function Loss: 0.01426

Mean KL Divergence: 0.00714
SB3 Clip Fraction: 0.06541
Policy Update Magnitude: 0.32567
Value Function Update Magnitude: 0.27584

Collected Steps per Second: 21,829.16799
Overall Steps per Second: 10,464.28397

Timestep Collection Time: 2.29088
Timestep Consumption Time: 2.48804
PPO Batch Consumption Time: 0.29114
Total Iteration Time: 4.77892

Cumulative Model Updates: 254,762
Cumulative Timesteps: 2,125,298,956

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 108,058.75314
Policy Entropy: 2.59619
Value Function Loss: 0.01563

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.07156
Policy Update Magnitude: 0.33121
Value Function Update Magnitude: 0.25621

Collected Steps per Second: 21,971.41029
Overall Steps per Second: 10,506.22677

Timestep Collection Time: 2.27669
Timestep Consumption Time: 2.48449
PPO Batch Consumption Time: 0.28946
Total Iteration Time: 4.76118

Cumulative Model Updates: 254,768
Cumulative Timesteps: 2,125,348,978

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2125348978...
Checkpoint 2125348978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 108,058.75314
Policy Entropy: 2.62729
Value Function Loss: 0.01404

Mean KL Divergence: 0.00701
SB3 Clip Fraction: 0.06431
Policy Update Magnitude: 0.32390
Value Function Update Magnitude: 0.23715

Collected Steps per Second: 21,822.46749
Overall Steps per Second: 10,594.27875

Timestep Collection Time: 2.29195
Timestep Consumption Time: 2.42909
PPO Batch Consumption Time: 0.27854
Total Iteration Time: 4.72104

Cumulative Model Updates: 254,774
Cumulative Timesteps: 2,125,398,994

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99,992.62419
Policy Entropy: 2.66255
Value Function Loss: 0.01260

Mean KL Divergence: 0.00664
SB3 Clip Fraction: 0.06313
Policy Update Magnitude: 0.30112
Value Function Update Magnitude: 0.24694

Collected Steps per Second: 21,104.42732
Overall Steps per Second: 10,416.75347

Timestep Collection Time: 2.36927
Timestep Consumption Time: 2.43089
PPO Batch Consumption Time: 0.27853
Total Iteration Time: 4.80015

Cumulative Model Updates: 254,780
Cumulative Timesteps: 2,125,448,996

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2125448996...
Checkpoint 2125448996 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 67,793.41440
Policy Entropy: 2.66244
Value Function Loss: 0.01182

Mean KL Divergence: 0.00649
SB3 Clip Fraction: 0.06180
Policy Update Magnitude: 0.29147
Value Function Update Magnitude: 0.26538

Collected Steps per Second: 21,523.55929
Overall Steps per Second: 10,401.65996

Timestep Collection Time: 2.32452
Timestep Consumption Time: 2.48548
PPO Batch Consumption Time: 0.29136
Total Iteration Time: 4.81000

Cumulative Model Updates: 254,786
Cumulative Timesteps: 2,125,499,028

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 71,138.41689
Policy Entropy: 2.63964
Value Function Loss: 0.01114

Mean KL Divergence: 0.00764
SB3 Clip Fraction: 0.06694
Policy Update Magnitude: 0.29287
Value Function Update Magnitude: 0.28134

Collected Steps per Second: 21,711.95511
Overall Steps per Second: 10,404.19334

Timestep Collection Time: 2.30380
Timestep Consumption Time: 2.50388
PPO Batch Consumption Time: 0.29257
Total Iteration Time: 4.80768

Cumulative Model Updates: 254,792
Cumulative Timesteps: 2,125,549,048

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2125549048...
Checkpoint 2125549048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 105,639.71990
Policy Entropy: 2.59707
Value Function Loss: 0.01348

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.07240
Policy Update Magnitude: 0.30499
Value Function Update Magnitude: 0.29140

Collected Steps per Second: 21,760.09521
Overall Steps per Second: 10,582.47845

Timestep Collection Time: 2.29889
Timestep Consumption Time: 2.42817
PPO Batch Consumption Time: 0.27725
Total Iteration Time: 4.72706

Cumulative Model Updates: 254,798
Cumulative Timesteps: 2,125,599,072

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91,458.50489
Policy Entropy: 2.59750
Value Function Loss: 0.01317

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.07430
Policy Update Magnitude: 0.31292
Value Function Update Magnitude: 0.30068

Collected Steps per Second: 22,020.06591
Overall Steps per Second: 10,408.75657

Timestep Collection Time: 2.27156
Timestep Consumption Time: 2.53400
PPO Batch Consumption Time: 0.29246
Total Iteration Time: 4.80557

Cumulative Model Updates: 254,804
Cumulative Timesteps: 2,125,649,092

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2125649092...
Checkpoint 2125649092 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86,024.68062
Policy Entropy: 2.58755
Value Function Loss: 0.01425

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.07041
Policy Update Magnitude: 0.31624
Value Function Update Magnitude: 0.30139

Collected Steps per Second: 21,446.56489
Overall Steps per Second: 10,623.15783

Timestep Collection Time: 2.33343
Timestep Consumption Time: 2.37741
PPO Batch Consumption Time: 0.27966
Total Iteration Time: 4.71084

Cumulative Model Updates: 254,810
Cumulative Timesteps: 2,125,699,136

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87,643.82863
Policy Entropy: 2.61387
Value Function Loss: 0.01328

Mean KL Divergence: 0.00610
SB3 Clip Fraction: 0.05993
Policy Update Magnitude: 0.31368
Value Function Update Magnitude: 0.30738

Collected Steps per Second: 21,670.23348
Overall Steps per Second: 10,562.53687

Timestep Collection Time: 2.30944
Timestep Consumption Time: 2.42863
PPO Batch Consumption Time: 0.29201
Total Iteration Time: 4.73807

Cumulative Model Updates: 254,816
Cumulative Timesteps: 2,125,749,182

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 2125749182...
Checkpoint 2125749182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 110,233.70847
Policy Entropy: 2.61430
Value Function Loss: 0.01356

Mean KL Divergence: 0.00692
SB3 Clip Fraction: 0.06405
Policy Update Magnitude: 0.30367
Value Function Update Magnitude: 0.28977

Collected Steps per Second: 21,213.48156
Overall Steps per Second: 10,629.67983

Timestep Collection Time: 2.35746
Timestep Consumption Time: 2.34729
PPO Batch Consumption Time: 0.27813
Total Iteration Time: 4.70475

Cumulative Model Updates: 254,822
Cumulative Timesteps: 2,125,799,192

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91,587.80199
Policy Entropy: 2.63443
Value Function Loss: 0.01280

Mean KL Divergence: 0.00667
SB3 Clip Fraction: 0.06442
Policy Update Magnitude: 0.30398
Value Function Update Magnitude: 0.26919

Collected Steps per Second: 21,540.31842
Overall Steps per Second: 10,376.36774

Timestep Collection Time: 2.32151
Timestep Consumption Time: 2.49771
PPO Batch Consumption Time: 0.29361
Total Iteration Time: 4.81922

Cumulative Model Updates: 254,828
Cumulative Timesteps: 2,125,849,198

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2125849198...
Checkpoint 2125849198 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84,936.38268
Policy Entropy: 2.64192
Value Function Loss: 0.01162

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.07159
Policy Update Magnitude: 0.29657
Value Function Update Magnitude: 0.27013

Collected Steps per Second: 21,970.59061
Overall Steps per Second: 10,703.38456

Timestep Collection Time: 2.27695
Timestep Consumption Time: 2.39690
PPO Batch Consumption Time: 0.27741
Total Iteration Time: 4.67385

Cumulative Model Updates: 254,834
Cumulative Timesteps: 2,125,899,224

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 64,238.05978
Policy Entropy: 2.63988
Value Function Loss: 0.01211

Mean KL Divergence: 0.00743
SB3 Clip Fraction: 0.06569
Policy Update Magnitude: 0.29464
Value Function Update Magnitude: 0.27928

Collected Steps per Second: 21,809.97018
Overall Steps per Second: 10,488.05007

Timestep Collection Time: 2.29262
Timestep Consumption Time: 2.47490
PPO Batch Consumption Time: 0.29287
Total Iteration Time: 4.76752

Cumulative Model Updates: 254,840
Cumulative Timesteps: 2,125,949,226

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2125949226...
Checkpoint 2125949226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 81,536.36974
Policy Entropy: 2.63702
Value Function Loss: 0.01207

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.07426
Policy Update Magnitude: 0.29775
Value Function Update Magnitude: 0.30069

Collected Steps per Second: 21,031.99619
Overall Steps per Second: 10,100.86421

Timestep Collection Time: 2.37752
Timestep Consumption Time: 2.57295
PPO Batch Consumption Time: 0.29152
Total Iteration Time: 4.95047

Cumulative Model Updates: 254,846
Cumulative Timesteps: 2,125,999,230

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81,536.36974
Policy Entropy: 2.64788
Value Function Loss: 0.01093

Mean KL Divergence: 0.00712
SB3 Clip Fraction: 0.06723
Policy Update Magnitude: 0.28736
Value Function Update Magnitude: 0.29091

Collected Steps per Second: 21,391.03902
Overall Steps per Second: 10,413.85361

Timestep Collection Time: 2.33958
Timestep Consumption Time: 2.46614
PPO Batch Consumption Time: 0.27925
Total Iteration Time: 4.80571

Cumulative Model Updates: 254,852
Cumulative Timesteps: 2,126,049,276

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 2126049276...
Checkpoint 2126049276 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 85,369.00094
Policy Entropy: 2.65949
Value Function Loss: 0.01076

Mean KL Divergence: 0.00623
SB3 Clip Fraction: 0.05978
Policy Update Magnitude: 0.28596
Value Function Update Magnitude: 0.27315

Collected Steps per Second: 22,032.25402
Overall Steps per Second: 10,629.79393

Timestep Collection Time: 2.26949
Timestep Consumption Time: 2.43446
PPO Batch Consumption Time: 0.27904
Total Iteration Time: 4.70395

Cumulative Model Updates: 254,858
Cumulative Timesteps: 2,126,099,278

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91,266.21814
Policy Entropy: 2.65935
Value Function Loss: 0.01210

Mean KL Divergence: 0.00658
SB3 Clip Fraction: 0.06366
Policy Update Magnitude: 0.29950
Value Function Update Magnitude: 0.28824

Collected Steps per Second: 22,116.50535
Overall Steps per Second: 10,520.85466

Timestep Collection Time: 2.26166
Timestep Consumption Time: 2.49271
PPO Batch Consumption Time: 0.28861
Total Iteration Time: 4.75437

Cumulative Model Updates: 254,864
Cumulative Timesteps: 2,126,149,298

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2126149298...
Checkpoint 2126149298 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84,343.04493
Policy Entropy: 2.63958
Value Function Loss: 0.01254

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.07900
Policy Update Magnitude: 0.30590
Value Function Update Magnitude: 0.26780

Collected Steps per Second: 21,789.47157
Overall Steps per Second: 10,592.12885

Timestep Collection Time: 2.29478
Timestep Consumption Time: 2.42590
PPO Batch Consumption Time: 0.27904
Total Iteration Time: 4.72068

Cumulative Model Updates: 254,870
Cumulative Timesteps: 2,126,199,300

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 64,514.86067
Policy Entropy: 2.66454
Value Function Loss: 0.01296

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.08451
Policy Update Magnitude: 0.31321
Value Function Update Magnitude: 0.26855

Collected Steps per Second: 22,098.29991
Overall Steps per Second: 10,464.62237

Timestep Collection Time: 2.26271
Timestep Consumption Time: 2.51549
PPO Batch Consumption Time: 0.28988
Total Iteration Time: 4.77819

Cumulative Model Updates: 254,876
Cumulative Timesteps: 2,126,249,302

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2126249302...
Checkpoint 2126249302 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 81,169.84752
Policy Entropy: 2.66217
Value Function Loss: 0.01327

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.08129
Policy Update Magnitude: 0.31041
Value Function Update Magnitude: 0.28715

Collected Steps per Second: 21,947.91233
Overall Steps per Second: 10,612.62935

Timestep Collection Time: 2.27849
Timestep Consumption Time: 2.43364
PPO Batch Consumption Time: 0.27890
Total Iteration Time: 4.71212

Cumulative Model Updates: 254,882
Cumulative Timesteps: 2,126,299,310

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81,169.84752
Policy Entropy: 2.67876
Value Function Loss: 0.01237

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.07263
Policy Update Magnitude: 0.30714
Value Function Update Magnitude: 0.28608

Collected Steps per Second: 21,444.75115
Overall Steps per Second: 10,506.40913

Timestep Collection Time: 2.33251
Timestep Consumption Time: 2.42840
PPO Batch Consumption Time: 0.27891
Total Iteration Time: 4.76090

Cumulative Model Updates: 254,888
Cumulative Timesteps: 2,126,349,330

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2126349330...
Checkpoint 2126349330 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 71,234.19695
Policy Entropy: 2.67745
Value Function Loss: 0.01219

Mean KL Divergence: 0.00697
SB3 Clip Fraction: 0.06538
Policy Update Magnitude: 0.29257
Value Function Update Magnitude: 0.27820

Collected Steps per Second: 21,144.79555
Overall Steps per Second: 10,270.80990

Timestep Collection Time: 2.36512
Timestep Consumption Time: 2.50402
PPO Batch Consumption Time: 0.29309
Total Iteration Time: 4.86914

Cumulative Model Updates: 254,894
Cumulative Timesteps: 2,126,399,340

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56,764.87070
Policy Entropy: 2.67486
Value Function Loss: 0.01350

Mean KL Divergence: 0.00697
SB3 Clip Fraction: 0.06601
Policy Update Magnitude: 0.29810
Value Function Update Magnitude: 0.29340

Collected Steps per Second: 21,471.06170
Overall Steps per Second: 10,379.16244

Timestep Collection Time: 2.33011
Timestep Consumption Time: 2.49012
PPO Batch Consumption Time: 0.28892
Total Iteration Time: 4.82023

Cumulative Model Updates: 254,900
Cumulative Timesteps: 2,126,449,370

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2126449370...
Checkpoint 2126449370 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 80,903.57344
Policy Entropy: 2.68226
Value Function Loss: 0.01407

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.07033
Policy Update Magnitude: 0.31212
Value Function Update Magnitude: 0.32628

Collected Steps per Second: 21,434.08528
Overall Steps per Second: 10,349.81835

Timestep Collection Time: 2.33283
Timestep Consumption Time: 2.49837
PPO Batch Consumption Time: 0.29153
Total Iteration Time: 4.83120

Cumulative Model Updates: 254,906
Cumulative Timesteps: 2,126,499,372

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60,050.36117
Policy Entropy: 2.66007
Value Function Loss: 0.01384

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.07130
Policy Update Magnitude: 0.32083
Value Function Update Magnitude: 0.35592

Collected Steps per Second: 21,308.35315
Overall Steps per Second: 10,499.46467

Timestep Collection Time: 2.34819
Timestep Consumption Time: 2.41739
PPO Batch Consumption Time: 0.28982
Total Iteration Time: 4.76558

Cumulative Model Updates: 254,912
Cumulative Timesteps: 2,126,549,408

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 2126549408...
Checkpoint 2126549408 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 52,432.29924
Policy Entropy: 2.66912
Value Function Loss: 0.01206

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.07000
Policy Update Magnitude: 0.31226
Value Function Update Magnitude: 0.36334

Collected Steps per Second: 20,752.65898
Overall Steps per Second: 10,418.62973

Timestep Collection Time: 2.41010
Timestep Consumption Time: 2.39053
PPO Batch Consumption Time: 0.27849
Total Iteration Time: 4.80063

Cumulative Model Updates: 254,918
Cumulative Timesteps: 2,126,599,424

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 107,758.37550
Policy Entropy: 2.64962
Value Function Loss: 0.01199

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.07878
Policy Update Magnitude: 0.30993
Value Function Update Magnitude: 0.34238

Collected Steps per Second: 21,587.89451
Overall Steps per Second: 10,511.31884

Timestep Collection Time: 2.31621
Timestep Consumption Time: 2.44076
PPO Batch Consumption Time: 0.29264
Total Iteration Time: 4.75697

Cumulative Model Updates: 254,924
Cumulative Timesteps: 2,126,649,426

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2126649426...
Checkpoint 2126649426 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 67,025.91797
Policy Entropy: 2.64568
Value Function Loss: 0.01212

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.07178
Policy Update Magnitude: 0.31005
Value Function Update Magnitude: 0.32929

Collected Steps per Second: 20,972.84116
Overall Steps per Second: 10,243.12547

Timestep Collection Time: 2.38528
Timestep Consumption Time: 2.49859
PPO Batch Consumption Time: 0.29304
Total Iteration Time: 4.88386

Cumulative Model Updates: 254,930
Cumulative Timesteps: 2,126,699,452

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54,470.21582
Policy Entropy: 2.65934
Value Function Loss: 0.01393

Mean KL Divergence: 0.00667
SB3 Clip Fraction: 0.06358
Policy Update Magnitude: 0.30949
Value Function Update Magnitude: 0.31553

Collected Steps per Second: 22,224.39252
Overall Steps per Second: 10,745.55523

Timestep Collection Time: 2.25059
Timestep Consumption Time: 2.40417
PPO Batch Consumption Time: 0.27888
Total Iteration Time: 4.65476

Cumulative Model Updates: 254,936
Cumulative Timesteps: 2,126,749,470

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2126749470...
Checkpoint 2126749470 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 107,288.29636
Policy Entropy: 2.68083
Value Function Loss: 0.01290

Mean KL Divergence: 0.00597
SB3 Clip Fraction: 0.05747
Policy Update Magnitude: 0.30347
Value Function Update Magnitude: 0.26600

Collected Steps per Second: 21,852.45063
Overall Steps per Second: 10,657.64011

Timestep Collection Time: 2.29009
Timestep Consumption Time: 2.40551
PPO Batch Consumption Time: 0.27931
Total Iteration Time: 4.69560

Cumulative Model Updates: 254,942
Cumulative Timesteps: 2,126,799,514

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 116,085.10289
Policy Entropy: 2.68655
Value Function Loss: 0.01212

Mean KL Divergence: 0.00573
SB3 Clip Fraction: 0.05667
Policy Update Magnitude: 0.29681
Value Function Update Magnitude: 0.18603

Collected Steps per Second: 22,161.18420
Overall Steps per Second: 10,496.05814

Timestep Collection Time: 2.25710
Timestep Consumption Time: 2.50850
PPO Batch Consumption Time: 0.29102
Total Iteration Time: 4.76560

Cumulative Model Updates: 254,948
Cumulative Timesteps: 2,126,849,534

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2126849534...
Checkpoint 2126849534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 111,151.26089
Policy Entropy: 2.67132
Value Function Loss: 0.01216

Mean KL Divergence: 0.00594
SB3 Clip Fraction: 0.05634
Policy Update Magnitude: 0.29820
Value Function Update Magnitude: 0.17271

Collected Steps per Second: 21,641.04260
Overall Steps per Second: 10,567.34115

Timestep Collection Time: 2.31135
Timestep Consumption Time: 2.42210
PPO Batch Consumption Time: 0.27807
Total Iteration Time: 4.73345

Cumulative Model Updates: 254,954
Cumulative Timesteps: 2,126,899,554

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 168,952.30061
Policy Entropy: 2.63656
Value Function Loss: 0.01294

Mean KL Divergence: 0.00659
SB3 Clip Fraction: 0.05756
Policy Update Magnitude: 0.30056
Value Function Update Magnitude: 0.23599

Collected Steps per Second: 21,554.43650
Overall Steps per Second: 10,542.12727

Timestep Collection Time: 2.32175
Timestep Consumption Time: 2.42530
PPO Batch Consumption Time: 0.27814
Total Iteration Time: 4.74705

Cumulative Model Updates: 254,960
Cumulative Timesteps: 2,126,949,598

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 2126949598...
Checkpoint 2126949598 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 136,358.31824
Policy Entropy: 2.63120
Value Function Loss: 0.01448

Mean KL Divergence: 0.00670
SB3 Clip Fraction: 0.06056
Policy Update Magnitude: 0.31468
Value Function Update Magnitude: 0.29915

Collected Steps per Second: 21,327.32311
Overall Steps per Second: 10,329.63122

Timestep Collection Time: 2.34516
Timestep Consumption Time: 2.49683
PPO Batch Consumption Time: 0.29203
Total Iteration Time: 4.84199

Cumulative Model Updates: 254,966
Cumulative Timesteps: 2,126,999,614

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 114,963.21127
Policy Entropy: 2.63909
Value Function Loss: 0.01345

Mean KL Divergence: 0.00690
SB3 Clip Fraction: 0.06399
Policy Update Magnitude: 0.31708
Value Function Update Magnitude: 0.33272

Collected Steps per Second: 21,861.14209
Overall Steps per Second: 10,432.80688

Timestep Collection Time: 2.28725
Timestep Consumption Time: 2.50551
PPO Batch Consumption Time: 0.29226
Total Iteration Time: 4.79277

Cumulative Model Updates: 254,972
Cumulative Timesteps: 2,127,049,616

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2127049616...
Checkpoint 2127049616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 95,837.95185
Policy Entropy: 2.64412
Value Function Loss: 0.01255

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.07285
Policy Update Magnitude: 0.30871
Value Function Update Magnitude: 0.31667

Collected Steps per Second: 21,500.84235
Overall Steps per Second: 10,492.12540

Timestep Collection Time: 2.32651
Timestep Consumption Time: 2.44106
PPO Batch Consumption Time: 0.27842
Total Iteration Time: 4.76758

Cumulative Model Updates: 254,978
Cumulative Timesteps: 2,127,099,638

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91,074.94976
Policy Entropy: 2.64352
Value Function Loss: 0.01299

Mean KL Divergence: 0.00712
SB3 Clip Fraction: 0.06480
Policy Update Magnitude: 0.31479
Value Function Update Magnitude: 0.29946

Collected Steps per Second: 21,756.46921
Overall Steps per Second: 10,576.30461

Timestep Collection Time: 2.29982
Timestep Consumption Time: 2.43113
PPO Batch Consumption Time: 0.27653
Total Iteration Time: 4.73095

Cumulative Model Updates: 254,984
Cumulative Timesteps: 2,127,149,674

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 2127149674...
Checkpoint 2127149674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 115,714.67824
Policy Entropy: 2.63327
Value Function Loss: 0.01454

Mean KL Divergence: 0.00748
SB3 Clip Fraction: 0.06914
Policy Update Magnitude: 0.31989
Value Function Update Magnitude: 0.30431

Collected Steps per Second: 21,827.94797
Overall Steps per Second: 10,499.65518

Timestep Collection Time: 2.29192
Timestep Consumption Time: 2.47280
PPO Batch Consumption Time: 0.27853
Total Iteration Time: 4.76473

Cumulative Model Updates: 254,990
Cumulative Timesteps: 2,127,199,702

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92,506.74792
Policy Entropy: 2.64383
Value Function Loss: 0.01495

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.07519
Policy Update Magnitude: 0.31620
Value Function Update Magnitude: 0.32465

Collected Steps per Second: 22,277.22023
Overall Steps per Second: 10,476.47059

Timestep Collection Time: 2.24525
Timestep Consumption Time: 2.52906
PPO Batch Consumption Time: 0.29334
Total Iteration Time: 4.77432

Cumulative Model Updates: 254,996
Cumulative Timesteps: 2,127,249,720

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2127249720...
Checkpoint 2127249720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 57,738.63634
Policy Entropy: 2.63758
Value Function Loss: 0.01543

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.07338
Policy Update Magnitude: 0.32557
Value Function Update Magnitude: 0.32814

Collected Steps per Second: 21,764.06387
Overall Steps per Second: 10,575.48020

Timestep Collection Time: 2.29847
Timestep Consumption Time: 2.43172
PPO Batch Consumption Time: 0.27931
Total Iteration Time: 4.73019

Cumulative Model Updates: 255,002
Cumulative Timesteps: 2,127,299,744

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68,243.87415
Policy Entropy: 2.66932
Value Function Loss: 0.01357

Mean KL Divergence: 0.00715
SB3 Clip Fraction: 0.06563
Policy Update Magnitude: 0.31167
Value Function Update Magnitude: 0.31813

Collected Steps per Second: 22,001.42476
Overall Steps per Second: 10,595.21113

Timestep Collection Time: 2.27267
Timestep Consumption Time: 2.44663
PPO Batch Consumption Time: 0.27748
Total Iteration Time: 4.71930

Cumulative Model Updates: 255,008
Cumulative Timesteps: 2,127,349,746

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2127349746...
Checkpoint 2127349746 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 57,929.78018
Policy Entropy: 2.65514
Value Function Loss: 0.01411

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.07913
Policy Update Magnitude: 0.30551
Value Function Update Magnitude: 0.32220

Collected Steps per Second: 21,920.86150
Overall Steps per Second: 10,634.98632

Timestep Collection Time: 2.28203
Timestep Consumption Time: 2.42169
PPO Batch Consumption Time: 0.27793
Total Iteration Time: 4.70372

Cumulative Model Updates: 255,014
Cumulative Timesteps: 2,127,399,770

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57,368.90773
Policy Entropy: 2.67315
Value Function Loss: 0.01357

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.06986
Policy Update Magnitude: 0.30353
Value Function Update Magnitude: 0.31760

Collected Steps per Second: 22,233.31779
Overall Steps per Second: 10,560.30790

Timestep Collection Time: 2.24915
Timestep Consumption Time: 2.48613
PPO Batch Consumption Time: 0.29012
Total Iteration Time: 4.73528

Cumulative Model Updates: 255,020
Cumulative Timesteps: 2,127,449,776

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2127449776...
Checkpoint 2127449776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 50,696.48521
Policy Entropy: 2.63268
Value Function Loss: 0.01421

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.07346
Policy Update Magnitude: 0.30988
Value Function Update Magnitude: 0.32676

Collected Steps per Second: 21,470.02569
Overall Steps per Second: 10,535.79065

Timestep Collection Time: 2.32911
Timestep Consumption Time: 2.41719
PPO Batch Consumption Time: 0.27735
Total Iteration Time: 4.74630

Cumulative Model Updates: 255,026
Cumulative Timesteps: 2,127,499,782

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 115,254.16112
Policy Entropy: 2.65188
Value Function Loss: 0.01560

Mean KL Divergence: 0.00720
SB3 Clip Fraction: 0.06991
Policy Update Magnitude: 0.32042
Value Function Update Magnitude: 0.31329

Collected Steps per Second: 21,873.51823
Overall Steps per Second: 10,447.46158

Timestep Collection Time: 2.28633
Timestep Consumption Time: 2.50048
PPO Batch Consumption Time: 0.29350
Total Iteration Time: 4.78681

Cumulative Model Updates: 255,032
Cumulative Timesteps: 2,127,549,792

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2127549792...
Checkpoint 2127549792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 157,619.49567
Policy Entropy: 2.65086
Value Function Loss: 0.01452

Mean KL Divergence: 0.00782
SB3 Clip Fraction: 0.07530
Policy Update Magnitude: 0.32544
Value Function Update Magnitude: 0.28630

Collected Steps per Second: 21,498.77955
Overall Steps per Second: 10,517.39589

Timestep Collection Time: 2.32599
Timestep Consumption Time: 2.42861
PPO Batch Consumption Time: 0.27852
Total Iteration Time: 4.75460

Cumulative Model Updates: 255,038
Cumulative Timesteps: 2,127,599,798

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 196,700.61093
Policy Entropy: 2.65959
Value Function Loss: 0.01401

Mean KL Divergence: 0.00684
SB3 Clip Fraction: 0.06480
Policy Update Magnitude: 0.31587
Value Function Update Magnitude: 0.29816

Collected Steps per Second: 21,611.26752
Overall Steps per Second: 10,495.85903

Timestep Collection Time: 2.31416
Timestep Consumption Time: 2.45076
PPO Batch Consumption Time: 0.27898
Total Iteration Time: 4.76493

Cumulative Model Updates: 255,044
Cumulative Timesteps: 2,127,649,810

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2127649810...
Checkpoint 2127649810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 153,110.70141
Policy Entropy: 2.66352
Value Function Loss: 0.01281

Mean KL Divergence: 0.00643
SB3 Clip Fraction: 0.06136
Policy Update Magnitude: 0.30702
Value Function Update Magnitude: 0.30202

Collected Steps per Second: 21,983.65324
Overall Steps per Second: 10,544.69910

Timestep Collection Time: 2.27615
Timestep Consumption Time: 2.46918
PPO Batch Consumption Time: 0.27850
Total Iteration Time: 4.74532

Cumulative Model Updates: 255,050
Cumulative Timesteps: 2,127,699,848

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 116,786.83259
Policy Entropy: 2.67961
Value Function Loss: 0.01186

Mean KL Divergence: 0.00698
SB3 Clip Fraction: 0.06492
Policy Update Magnitude: 0.29983
Value Function Update Magnitude: 0.30799

Collected Steps per Second: 22,411.12860
Overall Steps per Second: 10,557.89187

Timestep Collection Time: 2.23157
Timestep Consumption Time: 2.50536
PPO Batch Consumption Time: 0.29199
Total Iteration Time: 4.73693

Cumulative Model Updates: 255,056
Cumulative Timesteps: 2,127,749,860

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2127749860...
Checkpoint 2127749860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 60,408.46075
Policy Entropy: 2.68201
Value Function Loss: 0.01412

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.07429
Policy Update Magnitude: 0.31114
Value Function Update Magnitude: 0.35118

Collected Steps per Second: 21,708.66468
Overall Steps per Second: 10,561.63389

Timestep Collection Time: 2.30323
Timestep Consumption Time: 2.43089
PPO Batch Consumption Time: 0.27889
Total Iteration Time: 4.73412

Cumulative Model Updates: 255,062
Cumulative Timesteps: 2,127,799,860

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95,925.26737
Policy Entropy: 2.69994
Value Function Loss: 0.01409

Mean KL Divergence: 0.01646
SB3 Clip Fraction: 0.08227
Policy Update Magnitude: 0.30586
Value Function Update Magnitude: 0.37326

Collected Steps per Second: 22,317.77351
Overall Steps per Second: 10,514.47171

Timestep Collection Time: 2.24126
Timestep Consumption Time: 2.51599
PPO Batch Consumption Time: 0.29170
Total Iteration Time: 4.75725

Cumulative Model Updates: 255,068
Cumulative Timesteps: 2,127,849,880

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2127849880...
Checkpoint 2127849880 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 81,855.90402
Policy Entropy: 2.68756
Value Function Loss: 0.01428

Mean KL Divergence: 0.02241
SB3 Clip Fraction: 0.08306
Policy Update Magnitude: 0.30688
Value Function Update Magnitude: 0.39065

Collected Steps per Second: 20,591.79154
Overall Steps per Second: 10,301.96388

Timestep Collection Time: 2.42961
Timestep Consumption Time: 2.42675
PPO Batch Consumption Time: 0.27724
Total Iteration Time: 4.85636

Cumulative Model Updates: 255,074
Cumulative Timesteps: 2,127,899,910

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79,187.73712
Policy Entropy: 2.68947
Value Function Loss: 0.01272

Mean KL Divergence: 0.00692
SB3 Clip Fraction: 0.06465
Policy Update Magnitude: 0.30057
Value Function Update Magnitude: 0.33557

Collected Steps per Second: 21,897.26123
Overall Steps per Second: 10,442.04933

Timestep Collection Time: 2.28421
Timestep Consumption Time: 2.50584
PPO Batch Consumption Time: 0.29153
Total Iteration Time: 4.79006

Cumulative Model Updates: 255,080
Cumulative Timesteps: 2,127,949,928

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2127949928...
Checkpoint 2127949928 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 82,932.42339
Policy Entropy: 2.67656
Value Function Loss: 0.01495

Mean KL Divergence: 0.00704
SB3 Clip Fraction: 0.06617
Policy Update Magnitude: 0.31871
Value Function Update Magnitude: 0.33674

Collected Steps per Second: 21,305.79593
Overall Steps per Second: 10,502.56533

Timestep Collection Time: 2.34762
Timestep Consumption Time: 2.41483
PPO Batch Consumption Time: 0.27780
Total Iteration Time: 4.76246

Cumulative Model Updates: 255,086
Cumulative Timesteps: 2,127,999,946

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99,040.25559
Policy Entropy: 2.69343
Value Function Loss: 0.01452

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.06898
Policy Update Magnitude: 0.32022
Value Function Update Magnitude: 0.36828

Collected Steps per Second: 21,941.31958
Overall Steps per Second: 10,471.85618

Timestep Collection Time: 2.28036
Timestep Consumption Time: 2.49759
PPO Batch Consumption Time: 0.28656
Total Iteration Time: 4.77795

Cumulative Model Updates: 255,092
Cumulative Timesteps: 2,128,049,980

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 2128049980...
Checkpoint 2128049980 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 83,703.07459
Policy Entropy: 2.68048
Value Function Loss: 0.01382

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.07013
Policy Update Magnitude: 0.30913
Value Function Update Magnitude: 0.35950

Collected Steps per Second: 21,849.45578
Overall Steps per Second: 10,411.42294

Timestep Collection Time: 2.28912
Timestep Consumption Time: 2.51484
PPO Batch Consumption Time: 0.28981
Total Iteration Time: 4.80395

Cumulative Model Updates: 255,098
Cumulative Timesteps: 2,128,099,996

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83,703.07459
Policy Entropy: 2.69855
Value Function Loss: 0.01177

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.07212
Policy Update Magnitude: 0.29472
Value Function Update Magnitude: 0.29961

Collected Steps per Second: 21,989.89567
Overall Steps per Second: 10,624.37147

Timestep Collection Time: 2.27504
Timestep Consumption Time: 2.43375
PPO Batch Consumption Time: 0.27865
Total Iteration Time: 4.70880

Cumulative Model Updates: 255,104
Cumulative Timesteps: 2,128,150,024

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2128150024...
Checkpoint 2128150024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 74,117.07585
Policy Entropy: 2.70144
Value Function Loss: 0.01058

Mean KL Divergence: 0.00686
SB3 Clip Fraction: 0.06213
Policy Update Magnitude: 0.28441
Value Function Update Magnitude: 0.21181

Collected Steps per Second: 21,946.41174
Overall Steps per Second: 10,656.26522

Timestep Collection Time: 2.28101
Timestep Consumption Time: 2.41670
PPO Batch Consumption Time: 0.27859
Total Iteration Time: 4.69771

Cumulative Model Updates: 255,110
Cumulative Timesteps: 2,128,200,084

Timesteps Collected: 50,060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77,430.43816
Policy Entropy: 2.71741
Value Function Loss: 0.01047

Mean KL Divergence: 0.00634
SB3 Clip Fraction: 0.05730
Policy Update Magnitude: 0.27896
Value Function Update Magnitude: 0.17001

Collected Steps per Second: 22,327.02414
Overall Steps per Second: 10,536.35475

Timestep Collection Time: 2.24069
Timestep Consumption Time: 2.50744
PPO Batch Consumption Time: 0.29291
Total Iteration Time: 4.74813

Cumulative Model Updates: 255,116
Cumulative Timesteps: 2,128,250,112

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2128250112...
Checkpoint 2128250112 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 68,203.55452
Policy Entropy: 2.70724
Value Function Loss: 0.01115

Mean KL Divergence: 0.00731
SB3 Clip Fraction: 0.06978
Policy Update Magnitude: 0.27919
Value Function Update Magnitude: 0.17243

Collected Steps per Second: 21,348.76681
Overall Steps per Second: 10,624.28296

Timestep Collection Time: 2.34234
Timestep Consumption Time: 2.36443
PPO Batch Consumption Time: 0.27925
Total Iteration Time: 4.70676

Cumulative Model Updates: 255,122
Cumulative Timesteps: 2,128,300,118

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65,216.59629
Policy Entropy: 2.68335
Value Function Loss: 0.01334

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.07406
Policy Update Magnitude: 0.29853
Value Function Update Magnitude: 0.18007

Collected Steps per Second: 21,431.28054
Overall Steps per Second: 10,463.66802

Timestep Collection Time: 2.33313
Timestep Consumption Time: 2.44550
PPO Batch Consumption Time: 0.29449
Total Iteration Time: 4.77863

Cumulative Model Updates: 255,128
Cumulative Timesteps: 2,128,350,120

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2128350120...
Checkpoint 2128350120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 63,335.49846
Policy Entropy: 2.68930
Value Function Loss: 0.01215

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.07549
Policy Update Magnitude: 0.29947
Value Function Update Magnitude: 0.17501

Collected Steps per Second: 21,182.01577
Overall Steps per Second: 10,609.07816

Timestep Collection Time: 2.36144
Timestep Consumption Time: 2.35339
PPO Batch Consumption Time: 0.27874
Total Iteration Time: 4.71483

Cumulative Model Updates: 255,134
Cumulative Timesteps: 2,128,400,140

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63,335.49846
Policy Entropy: 2.69755
Value Function Loss: 0.01044

Mean KL Divergence: 0.00715
SB3 Clip Fraction: 0.06172
Policy Update Magnitude: 0.28182
Value Function Update Magnitude: 0.16480

Collected Steps per Second: 21,146.56151
Overall Steps per Second: 10,463.54938

Timestep Collection Time: 2.36530
Timestep Consumption Time: 2.41491
PPO Batch Consumption Time: 0.27838
Total Iteration Time: 4.78021

Cumulative Model Updates: 255,140
Cumulative Timesteps: 2,128,450,158

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2128450158...
Checkpoint 2128450158 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 63,335.49846
Policy Entropy: 2.71803
Value Function Loss: 0.00885

Mean KL Divergence: 0.00508
SB3 Clip Fraction: 0.04855
Policy Update Magnitude: 0.26291
Value Function Update Magnitude: 0.14814

Collected Steps per Second: 21,227.01572
Overall Steps per Second: 10,395.78642

Timestep Collection Time: 2.35643
Timestep Consumption Time: 2.45513
PPO Batch Consumption Time: 0.29080
Total Iteration Time: 4.81156

Cumulative Model Updates: 255,146
Cumulative Timesteps: 2,128,500,178

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99,785.14805
Policy Entropy: 2.70778
Value Function Loss: 0.00955

Mean KL Divergence: 0.00463
SB3 Clip Fraction: 0.04496
Policy Update Magnitude: 0.27158
Value Function Update Magnitude: 0.17792

Collected Steps per Second: 21,689.52944
Overall Steps per Second: 10,663.75285

Timestep Collection Time: 2.30627
Timestep Consumption Time: 2.38457
PPO Batch Consumption Time: 0.27826
Total Iteration Time: 4.69084

Cumulative Model Updates: 255,152
Cumulative Timesteps: 2,128,550,200

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2128550200...
Checkpoint 2128550200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 113,556.35729
Policy Entropy: 2.70135
Value Function Loss: 0.01010

Mean KL Divergence: 0.00538
SB3 Clip Fraction: 0.05037
Policy Update Magnitude: 0.28062
Value Function Update Magnitude: 0.23121

Collected Steps per Second: 21,293.49262
Overall Steps per Second: 10,273.74112

Timestep Collection Time: 2.34917
Timestep Consumption Time: 2.51975
PPO Batch Consumption Time: 0.29475
Total Iteration Time: 4.86892

Cumulative Model Updates: 255,158
Cumulative Timesteps: 2,128,600,222

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 124,236.67674
Policy Entropy: 2.69552
Value Function Loss: 0.01075

Mean KL Divergence: 0.00634
SB3 Clip Fraction: 0.05617
Policy Update Magnitude: 0.28242
Value Function Update Magnitude: 0.25908

Collected Steps per Second: 21,832.80135
Overall Steps per Second: 10,512.68594

Timestep Collection Time: 2.29123
Timestep Consumption Time: 2.46721
PPO Batch Consumption Time: 0.27798
Total Iteration Time: 4.75844

Cumulative Model Updates: 255,164
Cumulative Timesteps: 2,128,650,246

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2128650246...
Checkpoint 2128650246 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 97,866.63345
Policy Entropy: 2.67700
Value Function Loss: 0.01216

Mean KL Divergence: 0.00609
SB3 Clip Fraction: 0.05436
Policy Update Magnitude: 0.29068
Value Function Update Magnitude: 0.26304

Collected Steps per Second: 20,923.36494
Overall Steps per Second: 10,054.35710

Timestep Collection Time: 2.39178
Timestep Consumption Time: 2.58557
PPO Batch Consumption Time: 0.29170
Total Iteration Time: 4.97734

Cumulative Model Updates: 255,170
Cumulative Timesteps: 2,128,700,290

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92,822.79262
Policy Entropy: 2.66236
Value Function Loss: 0.01243

Mean KL Divergence: 0.00613
SB3 Clip Fraction: 0.05788
Policy Update Magnitude: 0.29547
Value Function Update Magnitude: 0.29872

Collected Steps per Second: 22,006.42340
Overall Steps per Second: 10,612.19726

Timestep Collection Time: 2.27306
Timestep Consumption Time: 2.44057
PPO Batch Consumption Time: 0.27677
Total Iteration Time: 4.71363

Cumulative Model Updates: 255,176
Cumulative Timesteps: 2,128,750,312

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2128750312...
Checkpoint 2128750312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 67,524.93815
Policy Entropy: 2.64549
Value Function Loss: 0.01330

Mean KL Divergence: 0.00663
SB3 Clip Fraction: 0.06464
Policy Update Magnitude: 0.30468
Value Function Update Magnitude: 0.34665

Collected Steps per Second: 21,617.60307
Overall Steps per Second: 10,534.29908

Timestep Collection Time: 2.31413
Timestep Consumption Time: 2.43474
PPO Batch Consumption Time: 0.27888
Total Iteration Time: 4.74887

Cumulative Model Updates: 255,182
Cumulative Timesteps: 2,128,800,338

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97,079.19525
Policy Entropy: 2.64868
Value Function Loss: 0.01131

Mean KL Divergence: 0.00740
SB3 Clip Fraction: 0.07050
Policy Update Magnitude: 0.30181
Value Function Update Magnitude: 0.35637

Collected Steps per Second: 21,993.66537
Overall Steps per Second: 10,479.27719

Timestep Collection Time: 2.27502
Timestep Consumption Time: 2.49974
PPO Batch Consumption Time: 0.28833
Total Iteration Time: 4.77476

Cumulative Model Updates: 255,188
Cumulative Timesteps: 2,128,850,374

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 2128850374...
Checkpoint 2128850374 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 111,098.06912
Policy Entropy: 2.66351
Value Function Loss: 0.01244

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.07591
Policy Update Magnitude: 0.31267
Value Function Update Magnitude: 0.31646

Collected Steps per Second: 22,064.02546
Overall Steps per Second: 10,644.23335

Timestep Collection Time: 2.26740
Timestep Consumption Time: 2.43261
PPO Batch Consumption Time: 0.27968
Total Iteration Time: 4.70001

Cumulative Model Updates: 255,194
Cumulative Timesteps: 2,128,900,402

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 108,493.63478
Policy Entropy: 2.67938
Value Function Loss: 0.01240

Mean KL Divergence: 0.00733
SB3 Clip Fraction: 0.07087
Policy Update Magnitude: 0.33279
Value Function Update Magnitude: 0.30179

Collected Steps per Second: 21,870.15720
Overall Steps per Second: 10,466.91661

Timestep Collection Time: 2.28787
Timestep Consumption Time: 2.49253
PPO Batch Consumption Time: 0.28664
Total Iteration Time: 4.78040

Cumulative Model Updates: 255,200
Cumulative Timesteps: 2,128,950,438

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 2128950438...
Checkpoint 2128950438 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 174,419.81674
Policy Entropy: 2.68548
Value Function Loss: 0.01123

Mean KL Divergence: 0.00726
SB3 Clip Fraction: 0.06440
Policy Update Magnitude: 0.30487
Value Function Update Magnitude: 0.30517

Collected Steps per Second: 21,755.25189
Overall Steps per Second: 10,438.26893

Timestep Collection Time: 2.29912
Timestep Consumption Time: 2.49267
PPO Batch Consumption Time: 0.29023
Total Iteration Time: 4.79179

Cumulative Model Updates: 255,206
Cumulative Timesteps: 2,129,000,456

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 174,419.81674
Policy Entropy: 2.69733
Value Function Loss: 0.01008

Mean KL Divergence: 0.00654
SB3 Clip Fraction: 0.05632
Policy Update Magnitude: 0.28496
Value Function Update Magnitude: 0.29604

Collected Steps per Second: 21,711.61646
Overall Steps per Second: 10,420.33539

Timestep Collection Time: 2.30420
Timestep Consumption Time: 2.49679
PPO Batch Consumption Time: 0.28963
Total Iteration Time: 4.80100

Cumulative Model Updates: 255,212
Cumulative Timesteps: 2,129,050,484

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2129050484...
Checkpoint 2129050484 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 222,102.90810
Policy Entropy: 2.68706
Value Function Loss: 0.00987

Mean KL Divergence: 0.00672
SB3 Clip Fraction: 0.06079
Policy Update Magnitude: 0.28376
Value Function Update Magnitude: 0.28195

Collected Steps per Second: 20,914.97823
Overall Steps per Second: 10,233.92648

Timestep Collection Time: 2.39130
Timestep Consumption Time: 2.49578
PPO Batch Consumption Time: 0.28956
Total Iteration Time: 4.88708

Cumulative Model Updates: 255,218
Cumulative Timesteps: 2,129,100,498

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 222,102.90810
Policy Entropy: 2.68845
Value Function Loss: 0.01001

Mean KL Divergence: 0.00750
SB3 Clip Fraction: 0.06677
Policy Update Magnitude: 0.28979
Value Function Update Magnitude: 0.28707

Collected Steps per Second: 21,822.65237
Overall Steps per Second: 10,462.93814

Timestep Collection Time: 2.29120
Timestep Consumption Time: 2.48758
PPO Batch Consumption Time: 0.28961
Total Iteration Time: 4.77877

Cumulative Model Updates: 255,224
Cumulative Timesteps: 2,129,150,498

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2129150498...
Checkpoint 2129150498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 204,934.15085
Policy Entropy: 2.66691
Value Function Loss: 0.01103

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.06295
Policy Update Magnitude: 0.29150
Value Function Update Magnitude: 0.28249

Collected Steps per Second: 21,430.70800
Overall Steps per Second: 10,494.55859

Timestep Collection Time: 2.33385
Timestep Consumption Time: 2.43205
PPO Batch Consumption Time: 0.27687
Total Iteration Time: 4.76590

Cumulative Model Updates: 255,230
Cumulative Timesteps: 2,129,200,514

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 204,934.15085
Policy Entropy: 2.68836
Value Function Loss: 0.00990

Mean KL Divergence: 0.00711
SB3 Clip Fraction: 0.05709
Policy Update Magnitude: 0.28861
Value Function Update Magnitude: 0.27619

Collected Steps per Second: 21,781.93817
Overall Steps per Second: 10,396.70068

Timestep Collection Time: 2.29576
Timestep Consumption Time: 2.51404
PPO Batch Consumption Time: 0.29115
Total Iteration Time: 4.80980

Cumulative Model Updates: 255,236
Cumulative Timesteps: 2,129,250,520

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2129250520...
Checkpoint 2129250520 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 193,994.08273
Policy Entropy: 2.69032
Value Function Loss: 0.01022

Mean KL Divergence: 0.00625
SB3 Clip Fraction: 0.05641
Policy Update Magnitude: 0.27742
Value Function Update Magnitude: 0.25969

Collected Steps per Second: 21,771.40633
Overall Steps per Second: 10,325.40620

Timestep Collection Time: 2.29677
Timestep Consumption Time: 2.54604
PPO Batch Consumption Time: 0.29283
Total Iteration Time: 4.84281

Cumulative Model Updates: 255,242
Cumulative Timesteps: 2,129,300,524

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 172,056.27540
Policy Entropy: 2.70149
Value Function Loss: 0.00981

Mean KL Divergence: 0.00621
SB3 Clip Fraction: 0.05460
Policy Update Magnitude: 0.27359
Value Function Update Magnitude: 0.23329

Collected Steps per Second: 22,337.89584
Overall Steps per Second: 10,684.55329

Timestep Collection Time: 2.23915
Timestep Consumption Time: 2.44218
PPO Batch Consumption Time: 0.27886
Total Iteration Time: 4.68134

Cumulative Model Updates: 255,248
Cumulative Timesteps: 2,129,350,542

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2129350542...
Checkpoint 2129350542 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 145,685.30084
Policy Entropy: 2.69639
Value Function Loss: 0.01037

Mean KL Divergence: 0.00570
SB3 Clip Fraction: 0.05099
Policy Update Magnitude: 0.27892
Value Function Update Magnitude: 0.21228

Collected Steps per Second: 22,017.96846
Overall Steps per Second: 10,665.32057

Timestep Collection Time: 2.27233
Timestep Consumption Time: 2.41877
PPO Batch Consumption Time: 0.27801
Total Iteration Time: 4.69109

Cumulative Model Updates: 255,254
Cumulative Timesteps: 2,129,400,574

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 140,513.81714
Policy Entropy: 2.70336
Value Function Loss: 0.01032

Mean KL Divergence: 0.00573
SB3 Clip Fraction: 0.05496
Policy Update Magnitude: 0.28036
Value Function Update Magnitude: 0.22493

Collected Steps per Second: 22,184.31132
Overall Steps per Second: 10,505.63566

Timestep Collection Time: 2.25412
Timestep Consumption Time: 2.50581
PPO Batch Consumption Time: 0.29210
Total Iteration Time: 4.75992

Cumulative Model Updates: 255,260
Cumulative Timesteps: 2,129,450,580

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2129450580...
Checkpoint 2129450580 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 141,500.55845
Policy Entropy: 2.72424
Value Function Loss: 0.00892

Mean KL Divergence: 0.00508
SB3 Clip Fraction: 0.04685
Policy Update Magnitude: 0.26890
Value Function Update Magnitude: 0.22938

Collected Steps per Second: 22,137.27287
Overall Steps per Second: 10,681.24480

Timestep Collection Time: 2.25918
Timestep Consumption Time: 2.42305
PPO Batch Consumption Time: 0.27779
Total Iteration Time: 4.68223

Cumulative Model Updates: 255,266
Cumulative Timesteps: 2,129,500,592

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 113,256.25102
Policy Entropy: 2.71367
Value Function Loss: 0.01018

Mean KL Divergence: 0.00579
SB3 Clip Fraction: 0.05502
Policy Update Magnitude: 0.27004
Value Function Update Magnitude: 0.23495

Collected Steps per Second: 21,827.17684
Overall Steps per Second: 10,449.61936

Timestep Collection Time: 2.29210
Timestep Consumption Time: 2.49564
PPO Batch Consumption Time: 0.29234
Total Iteration Time: 4.78773

Cumulative Model Updates: 255,272
Cumulative Timesteps: 2,129,550,622

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2129550622...
Checkpoint 2129550622 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 133,394.52107
Policy Entropy: 2.70460
Value Function Loss: 0.01272

Mean KL Divergence: 0.00671
SB3 Clip Fraction: 0.06328
Policy Update Magnitude: 0.28459
Value Function Update Magnitude: 0.27099

Collected Steps per Second: 21,886.26592
Overall Steps per Second: 10,603.10329

Timestep Collection Time: 2.28463
Timestep Consumption Time: 2.43116
PPO Batch Consumption Time: 0.27855
Total Iteration Time: 4.71579

Cumulative Model Updates: 255,278
Cumulative Timesteps: 2,129,600,624

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 129,946.92290
Policy Entropy: 2.70297
Value Function Loss: 0.01284

Mean KL Divergence: 0.00623
SB3 Clip Fraction: 0.05771
Policy Update Magnitude: 0.29436
Value Function Update Magnitude: 0.27982

Collected Steps per Second: 21,861.99446
Overall Steps per Second: 10,478.48305

Timestep Collection Time: 2.28890
Timestep Consumption Time: 2.48660
PPO Batch Consumption Time: 0.28837
Total Iteration Time: 4.77550

Cumulative Model Updates: 255,284
Cumulative Timesteps: 2,129,650,664

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 2129650664...
Checkpoint 2129650664 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 146,606.67894
Policy Entropy: 2.69011
Value Function Loss: 0.01284

Mean KL Divergence: 0.00597
SB3 Clip Fraction: 0.05752
Policy Update Magnitude: 0.29325
Value Function Update Magnitude: 0.27621

Collected Steps per Second: 21,438.79426
Overall Steps per Second: 10,379.35031

Timestep Collection Time: 2.33315
Timestep Consumption Time: 2.48603
PPO Batch Consumption Time: 0.28980
Total Iteration Time: 4.81918

Cumulative Model Updates: 255,290
Cumulative Timesteps: 2,129,700,684

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91,306.62403
Policy Entropy: 2.68655
Value Function Loss: 0.01213

Mean KL Divergence: 0.00696
SB3 Clip Fraction: 0.06524
Policy Update Magnitude: 0.29199
Value Function Update Magnitude: 0.28349

Collected Steps per Second: 21,017.37388
Overall Steps per Second: 10,349.20002

Timestep Collection Time: 2.37917
Timestep Consumption Time: 2.45250
PPO Batch Consumption Time: 0.29329
Total Iteration Time: 4.83168

Cumulative Model Updates: 255,296
Cumulative Timesteps: 2,129,750,688

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2129750688...
Checkpoint 2129750688 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 125,194.96369
Policy Entropy: 2.66841
Value Function Loss: 0.01335

Mean KL Divergence: 0.00733
SB3 Clip Fraction: 0.06799
Policy Update Magnitude: 0.30178
Value Function Update Magnitude: 0.29615

Collected Steps per Second: 20,790.43984
Overall Steps per Second: 10,522.73837

Timestep Collection Time: 2.40620
Timestep Consumption Time: 2.34788
PPO Batch Consumption Time: 0.27785
Total Iteration Time: 4.75409

Cumulative Model Updates: 255,302
Cumulative Timesteps: 2,129,800,714

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85,053.55393
Policy Entropy: 2.68271
Value Function Loss: 0.01320

Mean KL Divergence: 0.00672
SB3 Clip Fraction: 0.06279
Policy Update Magnitude: 0.30243
Value Function Update Magnitude: 0.30784

Collected Steps per Second: 20,861.02679
Overall Steps per Second: 10,492.87953

Timestep Collection Time: 2.39873
Timestep Consumption Time: 2.37022
PPO Batch Consumption Time: 0.27887
Total Iteration Time: 4.76895

Cumulative Model Updates: 255,308
Cumulative Timesteps: 2,129,850,754

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 2129850754...
Checkpoint 2129850754 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 93,937.02651
Policy Entropy: 2.68885
Value Function Loss: 0.01325

Mean KL Divergence: 0.00687
SB3 Clip Fraction: 0.06412
Policy Update Magnitude: 0.31936
Value Function Update Magnitude: 0.33958

Collected Steps per Second: 21,361.57763
Overall Steps per Second: 10,349.39706

Timestep Collection Time: 2.34140
Timestep Consumption Time: 2.49135
PPO Batch Consumption Time: 0.29111
Total Iteration Time: 4.83275

Cumulative Model Updates: 255,314
Cumulative Timesteps: 2,129,900,770

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 122,005.58752
Policy Entropy: 2.66595
Value Function Loss: 0.01347

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.07146
Policy Update Magnitude: 0.31742
Value Function Update Magnitude: 0.34338

Collected Steps per Second: 22,074.68012
Overall Steps per Second: 10,680.62074

Timestep Collection Time: 2.26594
Timestep Consumption Time: 2.41730
PPO Batch Consumption Time: 0.27886
Total Iteration Time: 4.68325

Cumulative Model Updates: 255,320
Cumulative Timesteps: 2,129,950,790

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2129950790...
Checkpoint 2129950790 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 125,418.16082
Policy Entropy: 2.66432
Value Function Loss: 0.01600

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.06899
Policy Update Magnitude: 0.33601
Value Function Update Magnitude: 0.39235

Collected Steps per Second: 21,803.38573
Overall Steps per Second: 10,656.15510

Timestep Collection Time: 2.29441
Timestep Consumption Time: 2.40015
PPO Batch Consumption Time: 0.27867
Total Iteration Time: 4.69456

Cumulative Model Updates: 255,326
Cumulative Timesteps: 2,130,000,816

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 113,926.98644
Policy Entropy: 2.64296
Value Function Loss: 0.01372

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.07669
Policy Update Magnitude: 0.33519
Value Function Update Magnitude: 0.41343

Collected Steps per Second: 22,017.44358
Overall Steps per Second: 10,468.68661

Timestep Collection Time: 2.27147
Timestep Consumption Time: 2.50582
PPO Batch Consumption Time: 0.29088
Total Iteration Time: 4.77729

Cumulative Model Updates: 255,332
Cumulative Timesteps: 2,130,050,828

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2130050828...
Checkpoint 2130050828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 78,984.23554
Policy Entropy: 2.66369
Value Function Loss: 0.01339

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.07304
Policy Update Magnitude: 0.32363
Value Function Update Magnitude: 0.35564

Collected Steps per Second: 22,113.68344
Overall Steps per Second: 10,643.83117

Timestep Collection Time: 2.26258
Timestep Consumption Time: 2.43817
PPO Batch Consumption Time: 0.27950
Total Iteration Time: 4.70075

Cumulative Model Updates: 255,338
Cumulative Timesteps: 2,130,100,862

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 146,538.04979
Policy Entropy: 2.66769
Value Function Loss: 0.01393

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.08465
Policy Update Magnitude: 0.31250
Value Function Update Magnitude: 0.29673

Collected Steps per Second: 21,990.62230
Overall Steps per Second: 10,468.26093

Timestep Collection Time: 2.27397
Timestep Consumption Time: 2.50295
PPO Batch Consumption Time: 0.28866
Total Iteration Time: 4.77692

Cumulative Model Updates: 255,344
Cumulative Timesteps: 2,130,150,868

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2130150868...
Checkpoint 2130150868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 104,078.46734
Policy Entropy: 2.66998
Value Function Loss: 0.01524

Mean KL Divergence: 0.01419
SB3 Clip Fraction: 0.11240
Policy Update Magnitude: 0.30617
Value Function Update Magnitude: 0.30115

Collected Steps per Second: 21,641.08287
Overall Steps per Second: 10,605.54293

Timestep Collection Time: 2.31245
Timestep Consumption Time: 2.40621
PPO Batch Consumption Time: 0.27807
Total Iteration Time: 4.71866

Cumulative Model Updates: 255,350
Cumulative Timesteps: 2,130,200,912

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68,450.64282
Policy Entropy: 2.64932
Value Function Loss: 0.01474

Mean KL Divergence: 0.01719
SB3 Clip Fraction: 0.11981
Policy Update Magnitude: 0.30166
Value Function Update Magnitude: 0.34326

Collected Steps per Second: 21,609.88876
Overall Steps per Second: 10,517.04148

Timestep Collection Time: 2.31496
Timestep Consumption Time: 2.44170
PPO Batch Consumption Time: 0.27915
Total Iteration Time: 4.75666

Cumulative Model Updates: 255,356
Cumulative Timesteps: 2,130,250,938

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2130250938...
Checkpoint 2130250938 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 56,461.93059
Policy Entropy: 2.65429
Value Function Loss: 0.01347

Mean KL Divergence: 0.01613
SB3 Clip Fraction: 0.11418
Policy Update Magnitude: 0.31283
Value Function Update Magnitude: 0.33239

Collected Steps per Second: 21,389.48353
Overall Steps per Second: 10,342.60537

Timestep Collection Time: 2.33881
Timestep Consumption Time: 2.49807
PPO Batch Consumption Time: 0.29153
Total Iteration Time: 4.83689

Cumulative Model Updates: 255,362
Cumulative Timesteps: 2,130,300,964

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56,461.93059
Policy Entropy: 2.65274
Value Function Loss: 0.01187

Mean KL Divergence: 0.01250
SB3 Clip Fraction: 0.09891
Policy Update Magnitude: 0.30994
Value Function Update Magnitude: 0.30960

Collected Steps per Second: 21,047.22000
Overall Steps per Second: 10,416.95029

Timestep Collection Time: 2.37580
Timestep Consumption Time: 2.42445
PPO Batch Consumption Time: 0.29203
Total Iteration Time: 4.80025

Cumulative Model Updates: 255,368
Cumulative Timesteps: 2,130,350,968

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2130350968...
Checkpoint 2130350968 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 64,199.50056
Policy Entropy: 2.65747
Value Function Loss: 0.01055

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.07337
Policy Update Magnitude: 0.29427
Value Function Update Magnitude: 0.27740

Collected Steps per Second: 21,180.37921
Overall Steps per Second: 10,611.68689

Timestep Collection Time: 2.36105
Timestep Consumption Time: 2.35149
PPO Batch Consumption Time: 0.27682
Total Iteration Time: 4.71254

Cumulative Model Updates: 255,374
Cumulative Timesteps: 2,130,400,976

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60,805.12214
Policy Entropy: 2.64704
Value Function Loss: 0.01047

Mean KL Divergence: 0.01139
SB3 Clip Fraction: 0.08911
Policy Update Magnitude: 0.29384
Value Function Update Magnitude: 0.25575

Collected Steps per Second: 21,636.58207
Overall Steps per Second: 10,476.66764

Timestep Collection Time: 2.31183
Timestep Consumption Time: 2.46259
PPO Batch Consumption Time: 0.29169
Total Iteration Time: 4.77442

Cumulative Model Updates: 255,380
Cumulative Timesteps: 2,130,450,996

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2130450996...
Checkpoint 2130450996 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47,527.28910
Policy Entropy: 2.64864
Value Function Loss: 0.01269

Mean KL Divergence: 0.01576
SB3 Clip Fraction: 0.11116
Policy Update Magnitude: 0.30361
Value Function Update Magnitude: 0.27268

Collected Steps per Second: 21,448.13081
Overall Steps per Second: 10,570.15183

Timestep Collection Time: 2.33260
Timestep Consumption Time: 2.40054
PPO Batch Consumption Time: 0.27713
Total Iteration Time: 4.73314

Cumulative Model Updates: 255,386
Cumulative Timesteps: 2,130,501,026

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54,466.27942
Policy Entropy: 2.61405
Value Function Loss: 0.01482

Mean KL Divergence: 0.01808
SB3 Clip Fraction: 0.12088
Policy Update Magnitude: 0.32187
Value Function Update Magnitude: 0.30125

Collected Steps per Second: 21,968.13115
Overall Steps per Second: 10,506.30146

Timestep Collection Time: 2.27739
Timestep Consumption Time: 2.48451
PPO Batch Consumption Time: 0.29359
Total Iteration Time: 4.76190

Cumulative Model Updates: 255,392
Cumulative Timesteps: 2,130,551,056

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2130551056...
Checkpoint 2130551056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 80,748.12896
Policy Entropy: 2.62503
Value Function Loss: 0.01419

Mean KL Divergence: 0.01717
SB3 Clip Fraction: 0.12255
Policy Update Magnitude: 0.31530
Value Function Update Magnitude: 0.29598

Collected Steps per Second: 21,906.02554
Overall Steps per Second: 10,549.83429

Timestep Collection Time: 2.28494
Timestep Consumption Time: 2.45959
PPO Batch Consumption Time: 0.28901
Total Iteration Time: 4.74453

Cumulative Model Updates: 255,398
Cumulative Timesteps: 2,130,601,110

Timesteps Collected: 50,054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 137,857.88483
Policy Entropy: 2.62934
Value Function Loss: 0.01328

Mean KL Divergence: 0.01446
SB3 Clip Fraction: 0.11346
Policy Update Magnitude: 0.30504
Value Function Update Magnitude: 0.30799

Collected Steps per Second: 22,126.42616
Overall Steps per Second: 10,446.15248

Timestep Collection Time: 2.26101
Timestep Consumption Time: 2.52812
PPO Batch Consumption Time: 0.29373
Total Iteration Time: 4.78913

Cumulative Model Updates: 255,404
Cumulative Timesteps: 2,130,651,138

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2130651138...
Checkpoint 2130651138 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 172,460.05269
Policy Entropy: 2.64940
Value Function Loss: 0.01227

Mean KL Divergence: 0.01194
SB3 Clip Fraction: 0.10074
Policy Update Magnitude: 0.31543
Value Function Update Magnitude: 0.31522

Collected Steps per Second: 21,955.13257
Overall Steps per Second: 10,593.78993

Timestep Collection Time: 2.27755
Timestep Consumption Time: 2.44257
PPO Batch Consumption Time: 0.27849
Total Iteration Time: 4.72012

Cumulative Model Updates: 255,410
Cumulative Timesteps: 2,130,701,142

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62,702.30460
Policy Entropy: 2.63967
Value Function Loss: 0.01462

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.08573
Policy Update Magnitude: 0.34472
Value Function Update Magnitude: 0.36417

Collected Steps per Second: 21,751.78714
Overall Steps per Second: 10,602.82488

Timestep Collection Time: 2.29866
Timestep Consumption Time: 2.41706
PPO Batch Consumption Time: 0.27670
Total Iteration Time: 4.71572

Cumulative Model Updates: 255,416
Cumulative Timesteps: 2,130,751,142

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2130751142...
Checkpoint 2130751142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 77,807.76053
Policy Entropy: 2.65697
Value Function Loss: 0.01430

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.08012
Policy Update Magnitude: 0.34413
Value Function Update Magnitude: 0.39091

Collected Steps per Second: 21,321.63723
Overall Steps per Second: 10,483.37094

Timestep Collection Time: 2.34654
Timestep Consumption Time: 2.42597
PPO Batch Consumption Time: 0.27900
Total Iteration Time: 4.77251

Cumulative Model Updates: 255,422
Cumulative Timesteps: 2,130,801,174

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48,753.81943
Policy Entropy: 2.65698
Value Function Loss: 0.01399

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.07041
Policy Update Magnitude: 0.32669
Value Function Update Magnitude: 0.40011

Collected Steps per Second: 21,673.62062
Overall Steps per Second: 10,575.34862

Timestep Collection Time: 2.30732
Timestep Consumption Time: 2.42141
PPO Batch Consumption Time: 0.27695
Total Iteration Time: 4.72873

Cumulative Model Updates: 255,428
Cumulative Timesteps: 2,130,851,182

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2130851182...
Checkpoint 2130851182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 58,582.64987
Policy Entropy: 2.66301
Value Function Loss: 0.01211

Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.06760
Policy Update Magnitude: 0.31314
Value Function Update Magnitude: 0.38019

Collected Steps per Second: 21,192.46172
Overall Steps per Second: 10,493.60428

Timestep Collection Time: 2.36037
Timestep Consumption Time: 2.40654
PPO Batch Consumption Time: 0.27804
Total Iteration Time: 4.76690

Cumulative Model Updates: 255,434
Cumulative Timesteps: 2,130,901,204

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87,999.69741
Policy Entropy: 2.64622
Value Function Loss: 0.01341

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.08213
Policy Update Magnitude: 0.31375
Value Function Update Magnitude: 0.34721

Collected Steps per Second: 20,966.24879
Overall Steps per Second: 10,532.59918

Timestep Collection Time: 2.38488
Timestep Consumption Time: 2.36248
PPO Batch Consumption Time: 0.27852
Total Iteration Time: 4.74736

Cumulative Model Updates: 255,440
Cumulative Timesteps: 2,130,951,206

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2130951206...
Checkpoint 2130951206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 110,488.98309
Policy Entropy: 2.65293
Value Function Loss: 0.01347

Mean KL Divergence: 0.00757
SB3 Clip Fraction: 0.07092
Policy Update Magnitude: 0.31579
Value Function Update Magnitude: 0.32554

Collected Steps per Second: 20,765.78209
Overall Steps per Second: 10,329.64906

Timestep Collection Time: 2.41002
Timestep Consumption Time: 2.43487
PPO Batch Consumption Time: 0.29274
Total Iteration Time: 4.84489

Cumulative Model Updates: 255,446
Cumulative Timesteps: 2,131,001,252

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 108,584.91379
Policy Entropy: 2.66049
Value Function Loss: 0.01330

Mean KL Divergence: 0.00752
SB3 Clip Fraction: 0.06991
Policy Update Magnitude: 0.32024
Value Function Update Magnitude: 0.31899

Collected Steps per Second: 21,624.08082
Overall Steps per Second: 10,530.15815

Timestep Collection Time: 2.31233
Timestep Consumption Time: 2.43613
PPO Batch Consumption Time: 0.28886
Total Iteration Time: 4.74846

Cumulative Model Updates: 255,452
Cumulative Timesteps: 2,131,051,254

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2131051254...
Checkpoint 2131051254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86,631.09330
Policy Entropy: 2.66410
Value Function Loss: 0.01222

Mean KL Divergence: 0.00756
SB3 Clip Fraction: 0.06402
Policy Update Magnitude: 0.31232
Value Function Update Magnitude: 0.30833

Collected Steps per Second: 21,554.11436
Overall Steps per Second: 10,380.31263

Timestep Collection Time: 2.32178
Timestep Consumption Time: 2.49927
PPO Batch Consumption Time: 0.29097
Total Iteration Time: 4.82105

Cumulative Model Updates: 255,458
Cumulative Timesteps: 2,131,101,298

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80,593.71414
Policy Entropy: 2.68300
Value Function Loss: 0.01313

Mean KL Divergence: 0.00683
SB3 Clip Fraction: 0.05806
Policy Update Magnitude: 0.31196
Value Function Update Magnitude: 0.31941

Collected Steps per Second: 21,995.24693
Overall Steps per Second: 10,527.94683

Timestep Collection Time: 2.27385
Timestep Consumption Time: 2.47674
PPO Batch Consumption Time: 0.29086
Total Iteration Time: 4.75059

Cumulative Model Updates: 255,464
Cumulative Timesteps: 2,131,151,312

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2131151312...
Checkpoint 2131151312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 108,123.80524
Policy Entropy: 2.66262
Value Function Loss: 0.01317

Mean KL Divergence: 0.00660
SB3 Clip Fraction: 0.05898
Policy Update Magnitude: 0.30521
Value Function Update Magnitude: 0.30463

Collected Steps per Second: 21,847.94406
Overall Steps per Second: 10,640.71025

Timestep Collection Time: 2.28973
Timestep Consumption Time: 2.41164
PPO Batch Consumption Time: 0.27969
Total Iteration Time: 4.70138

Cumulative Model Updates: 255,470
Cumulative Timesteps: 2,131,201,338

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79,848.37277
Policy Entropy: 2.65324
Value Function Loss: 0.01424

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.07356
Policy Update Magnitude: 0.31086
Value Function Update Magnitude: 0.31173

Collected Steps per Second: 22,225.25572
Overall Steps per Second: 10,444.18470

Timestep Collection Time: 2.24969
Timestep Consumption Time: 2.53766
PPO Batch Consumption Time: 0.29518
Total Iteration Time: 4.78735

Cumulative Model Updates: 255,476
Cumulative Timesteps: 2,131,251,338

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2131251338...
Checkpoint 2131251338 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 69,849.60303
Policy Entropy: 2.63889
Value Function Loss: 0.01372

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.07001
Policy Update Magnitude: 0.31737
Value Function Update Magnitude: 0.32475

Collected Steps per Second: 21,784.03210
Overall Steps per Second: 10,581.23247

Timestep Collection Time: 2.29618
Timestep Consumption Time: 2.43106
PPO Batch Consumption Time: 0.27885
Total Iteration Time: 4.72724

Cumulative Model Updates: 255,482
Cumulative Timesteps: 2,131,301,358

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 69,849.60303
Policy Entropy: 2.66418
Value Function Loss: 0.01230

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.07280
Policy Update Magnitude: 0.30630
Value Function Update Magnitude: 0.32411

Collected Steps per Second: 22,110.83661
Overall Steps per Second: 10,549.31511

Timestep Collection Time: 2.26251
Timestep Consumption Time: 2.47960
PPO Batch Consumption Time: 0.28719
Total Iteration Time: 4.74211

Cumulative Model Updates: 255,488
Cumulative Timesteps: 2,131,351,384

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2131351384...
Checkpoint 2131351384 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 59,700.69857
Policy Entropy: 2.66592
Value Function Loss: 0.01161

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.07131
Policy Update Magnitude: 0.29540
Value Function Update Magnitude: 0.30299

Collected Steps per Second: 21,362.84238
Overall Steps per Second: 10,348.24403

Timestep Collection Time: 2.34089
Timestep Consumption Time: 2.49162
PPO Batch Consumption Time: 0.29092
Total Iteration Time: 4.83251

Cumulative Model Updates: 255,494
Cumulative Timesteps: 2,131,401,392

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59,980.84795
Policy Entropy: 2.65916
Value Function Loss: 0.01228

Mean KL Divergence: 0.00635
SB3 Clip Fraction: 0.05847
Policy Update Magnitude: 0.30416
Value Function Update Magnitude: 0.28636

Collected Steps per Second: 21,879.99199
Overall Steps per Second: 10,496.40687

Timestep Collection Time: 2.28528
Timestep Consumption Time: 2.47844
PPO Batch Consumption Time: 0.28810
Total Iteration Time: 4.76373

Cumulative Model Updates: 255,500
Cumulative Timesteps: 2,131,451,394

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2131451394...
Checkpoint 2131451394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 70,217.67245
Policy Entropy: 2.64952
Value Function Loss: 0.01270

Mean KL Divergence: 0.00681
SB3 Clip Fraction: 0.06155
Policy Update Magnitude: 0.30760
Value Function Update Magnitude: 0.29364

Collected Steps per Second: 21,608.51366
Overall Steps per Second: 10,402.02807

Timestep Collection Time: 2.31409
Timestep Consumption Time: 2.49305
PPO Batch Consumption Time: 0.28931
Total Iteration Time: 4.80714

Cumulative Model Updates: 255,506
Cumulative Timesteps: 2,131,501,398

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 120,125.53076
Policy Entropy: 2.63082
Value Function Loss: 0.01392

Mean KL Divergence: 0.00733
SB3 Clip Fraction: 0.06283
Policy Update Magnitude: 0.31903
Value Function Update Magnitude: 0.33676

Collected Steps per Second: 21,251.50348
Overall Steps per Second: 10,465.51175

Timestep Collection Time: 2.35437
Timestep Consumption Time: 2.42647
PPO Batch Consumption Time: 0.29058
Total Iteration Time: 4.78085

Cumulative Model Updates: 255,512
Cumulative Timesteps: 2,131,551,432

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 2131551432...
Checkpoint 2131551432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 109,005.31799
Policy Entropy: 2.62546
Value Function Loss: 0.01439

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.07051
Policy Update Magnitude: 0.32501
Value Function Update Magnitude: 0.34694

Collected Steps per Second: 21,043.81869
Overall Steps per Second: 10,579.78598

Timestep Collection Time: 2.37618
Timestep Consumption Time: 2.35019
PPO Batch Consumption Time: 0.27849
Total Iteration Time: 4.72637

Cumulative Model Updates: 255,518
Cumulative Timesteps: 2,131,601,436

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 109,005.31799
Policy Entropy: 2.63516
Value Function Loss: 0.01355

Mean KL Divergence: 0.01127
SB3 Clip Fraction: 0.07188
Policy Update Magnitude: 0.31602
Value Function Update Magnitude: 0.33286

Collected Steps per Second: 20,168.57889
Overall Steps per Second: 10,078.93960

Timestep Collection Time: 2.47930
Timestep Consumption Time: 2.48193
PPO Batch Consumption Time: 0.29324
Total Iteration Time: 4.96124

Cumulative Model Updates: 255,524
Cumulative Timesteps: 2,131,651,440

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2131651440...
Checkpoint 2131651440 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 69,077.82129
Policy Entropy: 2.65039
Value Function Loss: 0.01447

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.07046
Policy Update Magnitude: 0.30756
Value Function Update Magnitude: 0.28977

Collected Steps per Second: 21,359.11152
Overall Steps per Second: 10,515.78193

Timestep Collection Time: 2.34158
Timestep Consumption Time: 2.41451
PPO Batch Consumption Time: 0.27858
Total Iteration Time: 4.75609

Cumulative Model Updates: 255,530
Cumulative Timesteps: 2,131,701,454

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 98,384.51784
Policy Entropy: 2.66325
Value Function Loss: 0.01407

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.08465
Policy Update Magnitude: 0.31395
Value Function Update Magnitude: 0.28554

Collected Steps per Second: 21,750.07493
Overall Steps per Second: 10,572.69832

Timestep Collection Time: 2.29995
Timestep Consumption Time: 2.43149
PPO Batch Consumption Time: 0.28057
Total Iteration Time: 4.73143

Cumulative Model Updates: 255,536
Cumulative Timesteps: 2,131,751,478

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2131751478...
Checkpoint 2131751478 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 75,491.42755
Policy Entropy: 2.66657
Value Function Loss: 0.01613

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.08914
Policy Update Magnitude: 0.31793
Value Function Update Magnitude: 0.27683

Collected Steps per Second: 21,815.43566
Overall Steps per Second: 10,614.47751

Timestep Collection Time: 2.29425
Timestep Consumption Time: 2.42101
PPO Batch Consumption Time: 0.28197
Total Iteration Time: 4.71526

Cumulative Model Updates: 255,542
Cumulative Timesteps: 2,131,801,528

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70,185.01486
Policy Entropy: 2.67433
Value Function Loss: 0.01716

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.08926
Policy Update Magnitude: 0.31633
Value Function Update Magnitude: 0.31107

Collected Steps per Second: 22,097.39747
Overall Steps per Second: 10,459.81864

Timestep Collection Time: 2.26380
Timestep Consumption Time: 2.51870
PPO Batch Consumption Time: 0.29167
Total Iteration Time: 4.78249

Cumulative Model Updates: 255,548
Cumulative Timesteps: 2,131,851,552

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2131851552...
Checkpoint 2131851552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 136,442.15232
Policy Entropy: 2.67686
Value Function Loss: 0.01659

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.07617
Policy Update Magnitude: 0.32004
Value Function Update Magnitude: 0.35289

Collected Steps per Second: 21,981.24229
Overall Steps per Second: 10,602.10350

Timestep Collection Time: 2.27539
Timestep Consumption Time: 2.44216
PPO Batch Consumption Time: 0.27872
Total Iteration Time: 4.71755

Cumulative Model Updates: 255,554
Cumulative Timesteps: 2,131,901,568

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 136,442.15232
Policy Entropy: 2.65283
Value Function Loss: 0.01391

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.06901
Policy Update Magnitude: 0.31597
Value Function Update Magnitude: 0.35570

Collected Steps per Second: 21,994.58536
Overall Steps per Second: 10,511.68631

Timestep Collection Time: 2.27365
Timestep Consumption Time: 2.48372
PPO Batch Consumption Time: 0.28723
Total Iteration Time: 4.75737

Cumulative Model Updates: 255,560
Cumulative Timesteps: 2,131,951,576

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2131951576...
Checkpoint 2131951576 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 146,941.55785
Policy Entropy: 2.67344
Value Function Loss: 0.01310

Mean KL Divergence: 0.00696
SB3 Clip Fraction: 0.06233
Policy Update Magnitude: 0.31497
Value Function Update Magnitude: 0.32319

Collected Steps per Second: 21,142.23982
Overall Steps per Second: 10,272.57362

Timestep Collection Time: 2.36550
Timestep Consumption Time: 2.50300
PPO Batch Consumption Time: 0.29413
Total Iteration Time: 4.86850

Cumulative Model Updates: 255,566
Cumulative Timesteps: 2,132,001,588

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84,432.93603
Policy Entropy: 2.66882
Value Function Loss: 0.01410

Mean KL Divergence: 0.00665
SB3 Clip Fraction: 0.05695
Policy Update Magnitude: 0.31825
Value Function Update Magnitude: 0.31037

Collected Steps per Second: 21,585.24733
Overall Steps per Second: 10,358.62492

Timestep Collection Time: 2.31640
Timestep Consumption Time: 2.51050
PPO Batch Consumption Time: 0.29059
Total Iteration Time: 4.82690

Cumulative Model Updates: 255,572
Cumulative Timesteps: 2,132,051,588

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2132051588...
Checkpoint 2132051588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 121,723.69635
Policy Entropy: 2.66605
Value Function Loss: 0.01466

Mean KL Divergence: 0.00644
SB3 Clip Fraction: 0.05752
Policy Update Magnitude: 0.31814
Value Function Update Magnitude: 0.34328

Collected Steps per Second: 21,470.83872
Overall Steps per Second: 10,341.94169

Timestep Collection Time: 2.32995
Timestep Consumption Time: 2.50725
PPO Batch Consumption Time: 0.29214
Total Iteration Time: 4.83720

Cumulative Model Updates: 255,578
Cumulative Timesteps: 2,132,101,614

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 121,723.69635
Policy Entropy: 2.67448
Value Function Loss: 0.01242

Mean KL Divergence: 0.00638
SB3 Clip Fraction: 0.05687
Policy Update Magnitude: 0.30881
Value Function Update Magnitude: 0.33392

Collected Steps per Second: 22,308.00242
Overall Steps per Second: 10,526.28723

Timestep Collection Time: 2.24359
Timestep Consumption Time: 2.51117
PPO Batch Consumption Time: 0.28914
Total Iteration Time: 4.75476

Cumulative Model Updates: 255,584
Cumulative Timesteps: 2,132,151,664

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 2132151664...
Checkpoint 2132151664 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 153,749.23060
Policy Entropy: 2.69477
Value Function Loss: 0.01133

Mean KL Divergence: 0.00667
SB3 Clip Fraction: 0.06324
Policy Update Magnitude: 0.29875
Value Function Update Magnitude: 0.31271

Collected Steps per Second: 21,190.23543
Overall Steps per Second: 10,444.20303

Timestep Collection Time: 2.36109
Timestep Consumption Time: 2.42932
PPO Batch Consumption Time: 0.29130
Total Iteration Time: 4.79041

Cumulative Model Updates: 255,590
Cumulative Timesteps: 2,132,201,696

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 131,070.00442
Policy Entropy: 2.68460
Value Function Loss: 0.01069

Mean KL Divergence: 0.00650
SB3 Clip Fraction: 0.05923
Policy Update Magnitude: 0.29579
Value Function Update Magnitude: 0.31359

Collected Steps per Second: 21,535.44281
Overall Steps per Second: 10,499.84593

Timestep Collection Time: 2.32324
Timestep Consumption Time: 2.44178
PPO Batch Consumption Time: 0.29347
Total Iteration Time: 4.76502

Cumulative Model Updates: 255,596
Cumulative Timesteps: 2,132,251,728

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2132251728...
Checkpoint 2132251728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 117,473.17314
Policy Entropy: 2.66749
Value Function Loss: 0.01181

Mean KL Divergence: 0.00718
SB3 Clip Fraction: 0.06689
Policy Update Magnitude: 0.30012
Value Function Update Magnitude: 0.29616

Collected Steps per Second: 21,105.65223
Overall Steps per Second: 10,575.93242

Timestep Collection Time: 2.37083
Timestep Consumption Time: 2.36047
PPO Batch Consumption Time: 0.27835
Total Iteration Time: 4.73131

Cumulative Model Updates: 255,602
Cumulative Timesteps: 2,132,301,766

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 71,734.16119
Policy Entropy: 2.66670
Value Function Loss: 0.01448

Mean KL Divergence: 0.00762
SB3 Clip Fraction: 0.06714
Policy Update Magnitude: 0.32127
Value Function Update Magnitude: 0.26891

Collected Steps per Second: 21,612.49270
Overall Steps per Second: 10,494.75310

Timestep Collection Time: 2.31542
Timestep Consumption Time: 2.45287
PPO Batch Consumption Time: 0.28516
Total Iteration Time: 4.76829

Cumulative Model Updates: 255,608
Cumulative Timesteps: 2,132,351,808

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 2132351808...
Checkpoint 2132351808 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 73,230.58239
Policy Entropy: 2.69839
Value Function Loss: 0.01431

Mean KL Divergence: 0.00737
SB3 Clip Fraction: 0.06548
Policy Update Magnitude: 0.32063
Value Function Update Magnitude: 0.25970

Collected Steps per Second: 21,988.83563
Overall Steps per Second: 10,612.54395

Timestep Collection Time: 2.27470
Timestep Consumption Time: 2.43840
PPO Batch Consumption Time: 0.28503
Total Iteration Time: 4.71310

Cumulative Model Updates: 255,614
Cumulative Timesteps: 2,132,401,826

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 100,590.77198
Policy Entropy: 2.67960
Value Function Loss: 0.01406

Mean KL Divergence: 0.00783
SB3 Clip Fraction: 0.06709
Policy Update Magnitude: 0.30820
Value Function Update Magnitude: 0.23549

Collected Steps per Second: 22,017.40393
Overall Steps per Second: 10,529.34662

Timestep Collection Time: 2.27248
Timestep Consumption Time: 2.47939
PPO Batch Consumption Time: 0.29158
Total Iteration Time: 4.75186

Cumulative Model Updates: 255,620
Cumulative Timesteps: 2,132,451,860

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 2132451860...
Checkpoint 2132451860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 75,246.54183
Policy Entropy: 2.67399
Value Function Loss: 0.01276

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.07236
Policy Update Magnitude: 0.30202
Value Function Update Magnitude: 0.22337

Collected Steps per Second: 21,584.35947
Overall Steps per Second: 10,534.64126

Timestep Collection Time: 2.31760
Timestep Consumption Time: 2.43092
PPO Batch Consumption Time: 0.27795
Total Iteration Time: 4.74852

Cumulative Model Updates: 255,626
Cumulative Timesteps: 2,132,501,884

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66,659.38831
Policy Entropy: 2.65742
Value Function Loss: 0.01187

Mean KL Divergence: 0.00718
SB3 Clip Fraction: 0.06584
Policy Update Magnitude: 0.29254
Value Function Update Magnitude: 0.21420

Collected Steps per Second: 21,377.32074
Overall Steps per Second: 10,478.25583

Timestep Collection Time: 2.33968
Timestep Consumption Time: 2.43364
PPO Batch Consumption Time: 0.27843
Total Iteration Time: 4.77331

Cumulative Model Updates: 255,632
Cumulative Timesteps: 2,132,551,900

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2132551900...
Checkpoint 2132551900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 93,623.90747
Policy Entropy: 2.67880
Value Function Loss: 0.01182

Mean KL Divergence: 0.00594
SB3 Clip Fraction: 0.05655
Policy Update Magnitude: 0.28726
Value Function Update Magnitude: 0.18570

Collected Steps per Second: 21,641.38499
Overall Steps per Second: 10,433.76431

Timestep Collection Time: 2.31113
Timestep Consumption Time: 2.48254
PPO Batch Consumption Time: 0.28940
Total Iteration Time: 4.79367

Cumulative Model Updates: 255,638
Cumulative Timesteps: 2,132,601,916

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 71,341.21146
Policy Entropy: 2.67123
Value Function Loss: 0.01237

Mean KL Divergence: 0.00662
SB3 Clip Fraction: 0.06212
Policy Update Magnitude: 0.29419
Value Function Update Magnitude: 0.20855

Collected Steps per Second: 21,720.04695
Overall Steps per Second: 10,421.25104

Timestep Collection Time: 2.30349
Timestep Consumption Time: 2.49747
PPO Batch Consumption Time: 0.29115
Total Iteration Time: 4.80096

Cumulative Model Updates: 255,644
Cumulative Timesteps: 2,132,651,948

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2132651948...
Checkpoint 2132651948 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 82,290.38165
Policy Entropy: 2.67679
Value Function Loss: 0.01228

Mean KL Divergence: 0.00749
SB3 Clip Fraction: 0.06620
Policy Update Magnitude: 0.30011
Value Function Update Magnitude: 0.24983

Collected Steps per Second: 21,837.06027
Overall Steps per Second: 10,450.80773

Timestep Collection Time: 2.29033
Timestep Consumption Time: 2.49533
PPO Batch Consumption Time: 0.28622
Total Iteration Time: 4.78566

Cumulative Model Updates: 255,650
Cumulative Timesteps: 2,132,701,962

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82,290.38165
Policy Entropy: 2.68935
Value Function Loss: 0.00991

Mean KL Divergence: 0.00718
SB3 Clip Fraction: 0.06030
Policy Update Magnitude: 0.28498
Value Function Update Magnitude: 0.25607

Collected Steps per Second: 22,179.37133
Overall Steps per Second: 10,470.61059

Timestep Collection Time: 2.25516
Timestep Consumption Time: 2.52183
PPO Batch Consumption Time: 0.28780
Total Iteration Time: 4.77699

Cumulative Model Updates: 255,656
Cumulative Timesteps: 2,132,751,980

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2132751980...
Checkpoint 2132751980 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86,530.60073
Policy Entropy: 2.68878
Value Function Loss: 0.01106

Mean KL Divergence: 0.00623
SB3 Clip Fraction: 0.05749
Policy Update Magnitude: 0.28940
Value Function Update Magnitude: 0.25956

Collected Steps per Second: 22,195.98485
Overall Steps per Second: 10,655.34733

Timestep Collection Time: 2.25302
Timestep Consumption Time: 2.44021
PPO Batch Consumption Time: 0.27790
Total Iteration Time: 4.69323

Cumulative Model Updates: 255,662
Cumulative Timesteps: 2,132,801,988

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 69,379.08014
Policy Entropy: 2.68345
Value Function Loss: 0.01222

Mean KL Divergence: 0.00553
SB3 Clip Fraction: 0.05244
Policy Update Magnitude: 0.29047
Value Function Update Magnitude: 0.26891

Collected Steps per Second: 22,033.89435
Overall Steps per Second: 10,437.06052

Timestep Collection Time: 2.27005
Timestep Consumption Time: 2.52230
PPO Batch Consumption Time: 0.29383
Total Iteration Time: 4.79235

Cumulative Model Updates: 255,668
Cumulative Timesteps: 2,132,852,006

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2132852006...
Checkpoint 2132852006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 58,012.60110
Policy Entropy: 2.66495
Value Function Loss: 0.01415

Mean KL Divergence: 0.00713
SB3 Clip Fraction: 0.06491
Policy Update Magnitude: 0.29944
Value Function Update Magnitude: 0.28524

Collected Steps per Second: 22,051.86473
Overall Steps per Second: 10,637.92547

Timestep Collection Time: 2.26829
Timestep Consumption Time: 2.43376
PPO Batch Consumption Time: 0.27888
Total Iteration Time: 4.70204

Cumulative Model Updates: 255,674
Cumulative Timesteps: 2,132,902,026

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 172,329.13060
Policy Entropy: 2.66518
Value Function Loss: 0.01495

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.07087
Policy Update Magnitude: 0.31251
Value Function Update Magnitude: 0.29780

Collected Steps per Second: 22,348.32906
Overall Steps per Second: 10,554.89833

Timestep Collection Time: 2.23766
Timestep Consumption Time: 2.50023
PPO Batch Consumption Time: 0.29280
Total Iteration Time: 4.73789

Cumulative Model Updates: 255,680
Cumulative Timesteps: 2,132,952,034

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2132952034...
Checkpoint 2132952034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 140,451.56887
Policy Entropy: 2.68270
Value Function Loss: 0.01276

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.07473
Policy Update Magnitude: 0.30709
Value Function Update Magnitude: 0.31400

Collected Steps per Second: 21,946.82768
Overall Steps per Second: 10,614.50467

Timestep Collection Time: 2.27951
Timestep Consumption Time: 2.43366
PPO Batch Consumption Time: 0.27793
Total Iteration Time: 4.71317

Cumulative Model Updates: 255,686
Cumulative Timesteps: 2,133,002,062

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 173,266.96141
Policy Entropy: 2.69543
Value Function Loss: 0.01137

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.07497
Policy Update Magnitude: 0.29007
Value Function Update Magnitude: 0.30359

Collected Steps per Second: 21,493.12480
Overall Steps per Second: 10,362.88030

Timestep Collection Time: 2.32633
Timestep Consumption Time: 2.49859
PPO Batch Consumption Time: 0.28876
Total Iteration Time: 4.82491

Cumulative Model Updates: 255,692
Cumulative Timesteps: 2,133,052,062

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2133052062...
Checkpoint 2133052062 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 125,676.24047
Policy Entropy: 2.69619
Value Function Loss: 0.01101

Mean KL Divergence: 0.00735
SB3 Clip Fraction: 0.07079
Policy Update Magnitude: 0.28643
Value Function Update Magnitude: 0.28215

Collected Steps per Second: 21,511.46632
Overall Steps per Second: 10,564.29079

Timestep Collection Time: 2.32499
Timestep Consumption Time: 2.40926
PPO Batch Consumption Time: 0.27780
Total Iteration Time: 4.73425

Cumulative Model Updates: 255,698
Cumulative Timesteps: 2,133,102,076

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 105,763.90321
Policy Entropy: 2.66868
Value Function Loss: 0.01129

Mean KL Divergence: 0.00652
SB3 Clip Fraction: 0.06105
Policy Update Magnitude: 0.28505
Value Function Update Magnitude: 0.27989

Collected Steps per Second: 21,874.79349
Overall Steps per Second: 10,618.64070

Timestep Collection Time: 2.28647
Timestep Consumption Time: 2.42374
PPO Batch Consumption Time: 0.27660
Total Iteration Time: 4.71021

Cumulative Model Updates: 255,704
Cumulative Timesteps: 2,133,152,092

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2133152092...
Checkpoint 2133152092 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 109,192.95539
Policy Entropy: 2.65308
Value Function Loss: 0.01257

Mean KL Divergence: 0.00652
SB3 Clip Fraction: 0.05984
Policy Update Magnitude: 0.28988
Value Function Update Magnitude: 0.28396

Collected Steps per Second: 21,840.40027
Overall Steps per Second: 10,557.49346

Timestep Collection Time: 2.29117
Timestep Consumption Time: 2.44859
PPO Batch Consumption Time: 0.27803
Total Iteration Time: 4.73976

Cumulative Model Updates: 255,710
Cumulative Timesteps: 2,133,202,132

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 120,605.40948
Policy Entropy: 2.66299
Value Function Loss: 0.01158

Mean KL Divergence: 0.00736
SB3 Clip Fraction: 0.06907
Policy Update Magnitude: 0.28796
Value Function Update Magnitude: 0.27519

Collected Steps per Second: 21,867.52475
Overall Steps per Second: 10,404.62466

Timestep Collection Time: 2.28659
Timestep Consumption Time: 2.51916
PPO Batch Consumption Time: 0.28847
Total Iteration Time: 4.80575

Cumulative Model Updates: 255,716
Cumulative Timesteps: 2,133,252,134

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2133252134...
Checkpoint 2133252134 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 109,622.83537
Policy Entropy: 2.66234
Value Function Loss: 0.01374

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.07602
Policy Update Magnitude: 0.29124
Value Function Update Magnitude: 0.27719

Collected Steps per Second: 22,100.47691
Overall Steps per Second: 10,592.62123

Timestep Collection Time: 2.26276
Timestep Consumption Time: 2.45827
PPO Batch Consumption Time: 0.27943
Total Iteration Time: 4.72102

Cumulative Model Updates: 255,722
Cumulative Timesteps: 2,133,302,142

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 109,622.83537
Policy Entropy: 2.63853
Value Function Loss: 0.01233

Mean KL Divergence: 0.01177
SB3 Clip Fraction: 0.09394
Policy Update Magnitude: 0.29792
Value Function Update Magnitude: 0.29039

Collected Steps per Second: 21,887.68993
Overall Steps per Second: 10,619.38145

Timestep Collection Time: 2.28658
Timestep Consumption Time: 2.42631
PPO Batch Consumption Time: 0.27707
Total Iteration Time: 4.71289

Cumulative Model Updates: 255,728
Cumulative Timesteps: 2,133,352,190

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 2133352190...
Checkpoint 2133352190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 77,087.49115
Policy Entropy: 2.64625
Value Function Loss: 0.01298

Mean KL Divergence: 0.01742
SB3 Clip Fraction: 0.12929
Policy Update Magnitude: 0.29417
Value Function Update Magnitude: 0.29316

Collected Steps per Second: 22,011.85271
Overall Steps per Second: 10,545.33958

Timestep Collection Time: 2.27214
Timestep Consumption Time: 2.47062
PPO Batch Consumption Time: 0.28632
Total Iteration Time: 4.74276

Cumulative Model Updates: 255,734
Cumulative Timesteps: 2,133,402,204

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90,252.36386
Policy Entropy: 2.62733
Value Function Loss: 0.01260

Mean KL Divergence: 0.01573
SB3 Clip Fraction: 0.12188
Policy Update Magnitude: 0.30759
Value Function Update Magnitude: 0.28864

Collected Steps per Second: 21,779.19286
Overall Steps per Second: 10,457.95297

Timestep Collection Time: 2.29669
Timestep Consumption Time: 2.48628
PPO Batch Consumption Time: 0.28808
Total Iteration Time: 4.78296

Cumulative Model Updates: 255,740
Cumulative Timesteps: 2,133,452,224

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2133452224...
Checkpoint 2133452224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 79,332.29505
Policy Entropy: 2.64436
Value Function Loss: 0.01300

Mean KL Divergence: 0.01232
SB3 Clip Fraction: 0.10125
Policy Update Magnitude: 0.31485
Value Function Update Magnitude: 0.29353

Collected Steps per Second: 22,098.67516
Overall Steps per Second: 10,631.96641

Timestep Collection Time: 2.26330
Timestep Consumption Time: 2.44100
PPO Batch Consumption Time: 0.28010
Total Iteration Time: 4.70430

Cumulative Model Updates: 255,746
Cumulative Timesteps: 2,133,502,240

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95,581.42165
Policy Entropy: 2.62960
Value Function Loss: 0.01456

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.07605
Policy Update Magnitude: 0.31680
Value Function Update Magnitude: 0.32726

Collected Steps per Second: 20,927.42777
Overall Steps per Second: 10,405.50488

Timestep Collection Time: 2.38969
Timestep Consumption Time: 2.41642
PPO Batch Consumption Time: 0.27856
Total Iteration Time: 4.80611

Cumulative Model Updates: 255,752
Cumulative Timesteps: 2,133,552,250

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2133552250...
Checkpoint 2133552250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 105,822.69668
Policy Entropy: 2.65660
Value Function Loss: 0.01257

Mean KL Divergence: 0.00640
SB3 Clip Fraction: 0.05765
Policy Update Magnitude: 0.30540
Value Function Update Magnitude: 0.31882

Collected Steps per Second: 21,654.49394
Overall Steps per Second: 10,449.37058

Timestep Collection Time: 2.30908
Timestep Consumption Time: 2.47609
PPO Batch Consumption Time: 0.29027
Total Iteration Time: 4.78517

Cumulative Model Updates: 255,758
Cumulative Timesteps: 2,133,602,252

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 111,073.87047
Policy Entropy: 2.64767
Value Function Loss: 0.01235

Mean KL Divergence: 0.00727
SB3 Clip Fraction: 0.06802
Policy Update Magnitude: 0.29515
Value Function Update Magnitude: 0.27994

Collected Steps per Second: 21,562.87761
Overall Steps per Second: 10,381.56678

Timestep Collection Time: 2.32010
Timestep Consumption Time: 2.49883
PPO Batch Consumption Time: 0.29256
Total Iteration Time: 4.81893

Cumulative Model Updates: 255,764
Cumulative Timesteps: 2,133,652,280

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2133652280...
Checkpoint 2133652280 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 93,350.04572
Policy Entropy: 2.61506
Value Function Loss: 0.01229

Mean KL Divergence: 0.00708
SB3 Clip Fraction: 0.06727
Policy Update Magnitude: 0.31303
Value Function Update Magnitude: 0.28176

Collected Steps per Second: 21,692.57893
Overall Steps per Second: 10,552.89186

Timestep Collection Time: 2.30558
Timestep Consumption Time: 2.43378
PPO Batch Consumption Time: 0.27802
Total Iteration Time: 4.73936

Cumulative Model Updates: 255,770
Cumulative Timesteps: 2,133,702,294

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 69,284.78284
Policy Entropy: 2.58576
Value Function Loss: 0.01341

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.06956
Policy Update Magnitude: 0.32882
Value Function Update Magnitude: 0.33655

Collected Steps per Second: 21,787.47989
Overall Steps per Second: 10,546.06677

Timestep Collection Time: 2.29664
Timestep Consumption Time: 2.44807
PPO Batch Consumption Time: 0.29226
Total Iteration Time: 4.74471

Cumulative Model Updates: 255,776
Cumulative Timesteps: 2,133,752,332

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 2133752332...
Checkpoint 2133752332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 64,209.41652
Policy Entropy: 2.59459
Value Function Loss: 0.01274

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.08257
Policy Update Magnitude: 0.32519
Value Function Update Magnitude: 0.36742

Collected Steps per Second: 21,480.25648
Overall Steps per Second: 10,507.65381

Timestep Collection Time: 2.32828
Timestep Consumption Time: 2.43130
PPO Batch Consumption Time: 0.29122
Total Iteration Time: 4.75958

Cumulative Model Updates: 255,782
Cumulative Timesteps: 2,133,802,344

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 64,209.41652
Policy Entropy: 2.63418
Value Function Loss: 0.01028

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.07788
Policy Update Magnitude: 0.30232
Value Function Update Magnitude: 0.32203

Collected Steps per Second: 21,481.05042
Overall Steps per Second: 10,433.71009

Timestep Collection Time: 2.32912
Timestep Consumption Time: 2.46610
PPO Batch Consumption Time: 0.28735
Total Iteration Time: 4.79523

Cumulative Model Updates: 255,788
Cumulative Timesteps: 2,133,852,376

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2133852376...
Checkpoint 2133852376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 54,109.70469
Policy Entropy: 2.65374
Value Function Loss: 0.00974

Mean KL Divergence: 0.00730
SB3 Clip Fraction: 0.06606
Policy Update Magnitude: 0.28784
Value Function Update Magnitude: 0.26028

Collected Steps per Second: 21,571.44798
Overall Steps per Second: 10,610.13270

Timestep Collection Time: 2.31844
Timestep Consumption Time: 2.39517
PPO Batch Consumption Time: 0.27813
Total Iteration Time: 4.71361

Cumulative Model Updates: 255,794
Cumulative Timesteps: 2,133,902,388

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60,965.29619
Policy Entropy: 2.63552
Value Function Loss: 0.00989

Mean KL Divergence: 0.00639
SB3 Clip Fraction: 0.05866
Policy Update Magnitude: 0.29228
Value Function Update Magnitude: 0.22208

Collected Steps per Second: 21,751.20787
Overall Steps per Second: 10,520.79734

Timestep Collection Time: 2.30019
Timestep Consumption Time: 2.45534
PPO Batch Consumption Time: 0.28664
Total Iteration Time: 4.75553

Cumulative Model Updates: 255,800
Cumulative Timesteps: 2,133,952,420

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2133952420...
Checkpoint 2133952420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 92,649.00247
Policy Entropy: 2.60358
Value Function Loss: 0.01268

Mean KL Divergence: 0.00717
SB3 Clip Fraction: 0.06378
Policy Update Magnitude: 0.31598
Value Function Update Magnitude: 0.25872

Collected Steps per Second: 21,994.53083
Overall Steps per Second: 10,731.06116

Timestep Collection Time: 2.27384
Timestep Consumption Time: 2.38665
PPO Batch Consumption Time: 0.27660
Total Iteration Time: 4.66049

Cumulative Model Updates: 255,806
Cumulative Timesteps: 2,134,002,432

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 73,212.91586
Policy Entropy: 2.60253
Value Function Loss: 0.01270

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.07366
Policy Update Magnitude: 0.32629
Value Function Update Magnitude: 0.29006

Collected Steps per Second: 21,719.04301
Overall Steps per Second: 10,382.23601

Timestep Collection Time: 2.30222
Timestep Consumption Time: 2.51389
PPO Batch Consumption Time: 0.29315
Total Iteration Time: 4.81611

Cumulative Model Updates: 255,812
Cumulative Timesteps: 2,134,052,434

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2134052434...
Checkpoint 2134052434 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 73,212.91586
Policy Entropy: 2.61287
Value Function Loss: 0.01216

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.07687
Policy Update Magnitude: 0.31131
Value Function Update Magnitude: 0.29514

Collected Steps per Second: 21,232.41542
Overall Steps per Second: 10,305.59428

Timestep Collection Time: 2.35640
Timestep Consumption Time: 2.49844
PPO Batch Consumption Time: 0.29245
Total Iteration Time: 4.85484

Cumulative Model Updates: 255,818
Cumulative Timesteps: 2,134,102,466

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 120,863.64783
Policy Entropy: 2.62433
Value Function Loss: 0.01339

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.07483
Policy Update Magnitude: 0.32075
Value Function Update Magnitude: 0.30548

Collected Steps per Second: 21,770.94997
Overall Steps per Second: 10,423.11852

Timestep Collection Time: 2.29774
Timestep Consumption Time: 2.50159
PPO Batch Consumption Time: 0.29301
Total Iteration Time: 4.79933

Cumulative Model Updates: 255,824
Cumulative Timesteps: 2,134,152,490

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2134152490...
Checkpoint 2134152490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 99,362.65663
Policy Entropy: 2.62504
Value Function Loss: 0.01322

Mean KL Divergence: 0.00734
SB3 Clip Fraction: 0.06585
Policy Update Magnitude: 0.32029
Value Function Update Magnitude: 0.30285

Collected Steps per Second: 21,688.94753
Overall Steps per Second: 10,533.34844

Timestep Collection Time: 2.30578
Timestep Consumption Time: 2.44200
PPO Batch Consumption Time: 0.27818
Total Iteration Time: 4.74778

Cumulative Model Updates: 255,830
Cumulative Timesteps: 2,134,202,500

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 113,633.31344
Policy Entropy: 2.62721
Value Function Loss: 0.01269

Mean KL Divergence: 0.00669
SB3 Clip Fraction: 0.06009
Policy Update Magnitude: 0.31442
Value Function Update Magnitude: 0.26012

Collected Steps per Second: 22,294.07791
Overall Steps per Second: 10,434.96043

Timestep Collection Time: 2.24400
Timestep Consumption Time: 2.55026
PPO Batch Consumption Time: 0.28881
Total Iteration Time: 4.79427

Cumulative Model Updates: 255,836
Cumulative Timesteps: 2,134,252,528

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2134252528...
Checkpoint 2134252528 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 68,623.41813
Policy Entropy: 2.61412
Value Function Loss: 0.01435

Mean KL Divergence: 0.00658
SB3 Clip Fraction: 0.06092
Policy Update Magnitude: 0.31464
Value Function Update Magnitude: 0.22492

Collected Steps per Second: 21,841.90456
Overall Steps per Second: 10,550.03649

Timestep Collection Time: 2.29018
Timestep Consumption Time: 2.45122
PPO Batch Consumption Time: 0.27897
Total Iteration Time: 4.74141

Cumulative Model Updates: 255,842
Cumulative Timesteps: 2,134,302,550

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92,026.68683
Policy Entropy: 2.63273
Value Function Loss: 0.01481

Mean KL Divergence: 0.00694
SB3 Clip Fraction: 0.06404
Policy Update Magnitude: 0.32423
Value Function Update Magnitude: 0.29054

Collected Steps per Second: 22,192.01524
Overall Steps per Second: 10,573.80480

Timestep Collection Time: 2.25378
Timestep Consumption Time: 2.47640
PPO Batch Consumption Time: 0.28529
Total Iteration Time: 4.73018

Cumulative Model Updates: 255,848
Cumulative Timesteps: 2,134,352,566

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2134352566...
Checkpoint 2134352566 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 94,691.24416
Policy Entropy: 2.63939
Value Function Loss: 0.01331

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.08371
Policy Update Magnitude: 0.30897
Value Function Update Magnitude: 0.33043

Collected Steps per Second: 21,895.04159
Overall Steps per Second: 10,612.57292

Timestep Collection Time: 2.28472
Timestep Consumption Time: 2.42894
PPO Batch Consumption Time: 0.27895
Total Iteration Time: 4.71365

Cumulative Model Updates: 255,854
Cumulative Timesteps: 2,134,402,590

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 100,031.18067
Policy Entropy: 2.66329
Value Function Loss: 0.01140

Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.06803
Policy Update Magnitude: 0.29596
Value Function Update Magnitude: 0.29787

Collected Steps per Second: 22,447.52621
Overall Steps per Second: 10,538.59022

Timestep Collection Time: 2.22831
Timestep Consumption Time: 2.51806
PPO Batch Consumption Time: 0.29379
Total Iteration Time: 4.74637

Cumulative Model Updates: 255,860
Cumulative Timesteps: 2,134,452,610

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2134452610...
Checkpoint 2134452610 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 173,229.01084
Policy Entropy: 2.64212
Value Function Loss: 0.01268

Mean KL Divergence: 0.00706
SB3 Clip Fraction: 0.06072
Policy Update Magnitude: 0.30030
Value Function Update Magnitude: 0.27186

Collected Steps per Second: 21,727.16171
Overall Steps per Second: 10,546.94596

Timestep Collection Time: 2.30274
Timestep Consumption Time: 2.44100
PPO Batch Consumption Time: 0.27888
Total Iteration Time: 4.74374

Cumulative Model Updates: 255,866
Cumulative Timesteps: 2,134,502,642

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 173,229.01084
Policy Entropy: 2.62950
Value Function Loss: 0.01322

Mean KL Divergence: 0.00753
SB3 Clip Fraction: 0.06333
Policy Update Magnitude: 0.30575
Value Function Update Magnitude: 0.30633

Collected Steps per Second: 21,980.62124
Overall Steps per Second: 10,514.00103

Timestep Collection Time: 2.27537
Timestep Consumption Time: 2.48153
PPO Batch Consumption Time: 0.28642
Total Iteration Time: 4.75690

Cumulative Model Updates: 255,872
Cumulative Timesteps: 2,134,552,656

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2134552656...
Checkpoint 2134552656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 181,774.17290
Policy Entropy: 2.64000
Value Function Loss: 0.01313

Mean KL Divergence: 0.00670
SB3 Clip Fraction: 0.06192
Policy Update Magnitude: 0.30476
Value Function Update Magnitude: 0.31552

Collected Steps per Second: 21,651.10412
Overall Steps per Second: 10,577.67460

Timestep Collection Time: 2.31166
Timestep Consumption Time: 2.42000
PPO Batch Consumption Time: 0.27849
Total Iteration Time: 4.73166

Cumulative Model Updates: 255,878
Cumulative Timesteps: 2,134,602,706

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 173,284.42047
Policy Entropy: 2.64727
Value Function Loss: 0.01070

Mean KL Divergence: 0.00631
SB3 Clip Fraction: 0.05902
Policy Update Magnitude: 0.30066
Value Function Update Magnitude: 0.31213

Collected Steps per Second: 21,880.38838
Overall Steps per Second: 10,464.71019

Timestep Collection Time: 2.28524
Timestep Consumption Time: 2.49291
PPO Batch Consumption Time: 0.28730
Total Iteration Time: 4.77815

Cumulative Model Updates: 255,884
Cumulative Timesteps: 2,134,652,708

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2134652708...
Checkpoint 2134652708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 106,794.03344
Policy Entropy: 2.64689
Value Function Loss: 0.01239

Mean KL Divergence: 0.00620
SB3 Clip Fraction: 0.05785
Policy Update Magnitude: 0.31104
Value Function Update Magnitude: 0.35894

Collected Steps per Second: 21,378.67117
Overall Steps per Second: 10,232.43152

Timestep Collection Time: 2.33878
Timestep Consumption Time: 2.54764
PPO Batch Consumption Time: 0.29393
Total Iteration Time: 4.88642

Cumulative Model Updates: 255,890
Cumulative Timesteps: 2,134,702,708

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 100,761.01082
Policy Entropy: 2.60470
Value Function Loss: 0.01804

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.06573
Policy Update Magnitude: 0.35377
Value Function Update Magnitude: 0.37224

Collected Steps per Second: 22,346.14312
Overall Steps per Second: 10,467.80036

Timestep Collection Time: 2.23869
Timestep Consumption Time: 2.54035
PPO Batch Consumption Time: 0.29136
Total Iteration Time: 4.77904

Cumulative Model Updates: 255,896
Cumulative Timesteps: 2,134,752,734

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2134752734...
Checkpoint 2134752734 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,475.11758
Policy Entropy: 2.60622
Value Function Loss: 0.01921

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.08134
Policy Update Magnitude: 0.36994
Value Function Update Magnitude: 0.38496

Collected Steps per Second: 21,917.64731
Overall Steps per Second: 10,590.05896

Timestep Collection Time: 2.28154
Timestep Consumption Time: 2.44044
PPO Batch Consumption Time: 0.27911
Total Iteration Time: 4.72198

Cumulative Model Updates: 255,902
Cumulative Timesteps: 2,134,802,740

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49,475.11758
Policy Entropy: 2.62002
Value Function Loss: 0.01597

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.08043
Policy Update Magnitude: 0.34699
Value Function Update Magnitude: 0.38169

Collected Steps per Second: 22,118.95934
Overall Steps per Second: 10,484.27403

Timestep Collection Time: 2.26150
Timestep Consumption Time: 2.50965
PPO Batch Consumption Time: 0.29195
Total Iteration Time: 4.77115

Cumulative Model Updates: 255,908
Cumulative Timesteps: 2,134,852,762

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2134852762...
Checkpoint 2134852762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 79,861.69902
Policy Entropy: 2.63573
Value Function Loss: 0.01337

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.07369
Policy Update Magnitude: 0.32702
Value Function Update Magnitude: 0.33564

Collected Steps per Second: 21,799.73757
Overall Steps per Second: 10,586.53872

Timestep Collection Time: 2.29507
Timestep Consumption Time: 2.43093
PPO Batch Consumption Time: 0.27879
Total Iteration Time: 4.72600

Cumulative Model Updates: 255,914
Cumulative Timesteps: 2,134,902,794

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68,595.33402
Policy Entropy: 2.64203
Value Function Loss: 0.01182

Mean KL Divergence: 0.00727
SB3 Clip Fraction: 0.06764
Policy Update Magnitude: 0.31460
Value Function Update Magnitude: 0.31558

Collected Steps per Second: 22,392.72833
Overall Steps per Second: 10,564.22141

Timestep Collection Time: 2.23403
Timestep Consumption Time: 2.50139
PPO Batch Consumption Time: 0.29405
Total Iteration Time: 4.73542

Cumulative Model Updates: 255,920
Cumulative Timesteps: 2,134,952,820

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2134952820...
Checkpoint 2134952820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 119,613.26641
Policy Entropy: 2.62867
Value Function Loss: 0.01244

Mean KL Divergence: 0.00726
SB3 Clip Fraction: 0.06683
Policy Update Magnitude: 0.32046
Value Function Update Magnitude: 0.32992

Collected Steps per Second: 22,129.34214
Overall Steps per Second: 10,607.99279

Timestep Collection Time: 2.26179
Timestep Consumption Time: 2.45654
PPO Batch Consumption Time: 0.28446
Total Iteration Time: 4.71833

Cumulative Model Updates: 255,926
Cumulative Timesteps: 2,135,002,872

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 101,003.66550
Policy Entropy: 2.64162
Value Function Loss: 0.01342

Mean KL Divergence: 0.00649
SB3 Clip Fraction: 0.06072
Policy Update Magnitude: 0.32803
Value Function Update Magnitude: 0.32362

Collected Steps per Second: 21,440.90623
Overall Steps per Second: 10,492.78189

Timestep Collection Time: 2.33283
Timestep Consumption Time: 2.43407
PPO Batch Consumption Time: 0.29276
Total Iteration Time: 4.76690

Cumulative Model Updates: 255,932
Cumulative Timesteps: 2,135,052,890

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2135052890...
Checkpoint 2135052890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 90,586.77679
Policy Entropy: 2.63090
Value Function Loss: 0.01306

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.07428
Policy Update Magnitude: 0.31661
Value Function Update Magnitude: 0.29501

Collected Steps per Second: 20,468.56045
Overall Steps per Second: 10,270.62383

Timestep Collection Time: 2.44355
Timestep Consumption Time: 2.42626
PPO Batch Consumption Time: 0.29175
Total Iteration Time: 4.86981

Cumulative Model Updates: 255,938
Cumulative Timesteps: 2,135,102,906

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 113,949.59682
Policy Entropy: 2.65687
Value Function Loss: 0.01266

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.06941
Policy Update Magnitude: 0.30522
Value Function Update Magnitude: 0.27848

Collected Steps per Second: 21,302.27390
Overall Steps per Second: 10,498.94664

Timestep Collection Time: 2.34764
Timestep Consumption Time: 2.41570
PPO Batch Consumption Time: 0.29045
Total Iteration Time: 4.76333

Cumulative Model Updates: 255,944
Cumulative Timesteps: 2,135,152,916

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2135152916...
Checkpoint 2135152916 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 64,090.20082
Policy Entropy: 2.65074
Value Function Loss: 0.01320

Mean KL Divergence: 0.00721
SB3 Clip Fraction: 0.06632
Policy Update Magnitude: 0.30831
Value Function Update Magnitude: 0.26484

Collected Steps per Second: 20,798.88104
Overall Steps per Second: 10,415.25105

Timestep Collection Time: 2.40580
Timestep Consumption Time: 2.39850
PPO Batch Consumption Time: 0.27804
Total Iteration Time: 4.80430

Cumulative Model Updates: 255,950
Cumulative Timesteps: 2,135,202,954

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60,382.41270
Policy Entropy: 2.65371
Value Function Loss: 0.01423

Mean KL Divergence: 0.00759
SB3 Clip Fraction: 0.07159
Policy Update Magnitude: 0.31815
Value Function Update Magnitude: 0.26326

Collected Steps per Second: 22,211.32341
Overall Steps per Second: 10,496.96858

Timestep Collection Time: 2.25182
Timestep Consumption Time: 2.51298
PPO Batch Consumption Time: 0.29106
Total Iteration Time: 4.76480

Cumulative Model Updates: 255,956
Cumulative Timesteps: 2,135,252,970

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2135252970...
Checkpoint 2135252970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 110,562.24134
Policy Entropy: 2.63074
Value Function Loss: 0.01475

Mean KL Divergence: 0.01081
SB3 Clip Fraction: 0.09368
Policy Update Magnitude: 0.33967
Value Function Update Magnitude: 0.30960

Collected Steps per Second: 21,564.75345
Overall Steps per Second: 10,535.22841

Timestep Collection Time: 2.31888
Timestep Consumption Time: 2.42767
PPO Batch Consumption Time: 0.27883
Total Iteration Time: 4.74655

Cumulative Model Updates: 255,962
Cumulative Timesteps: 2,135,302,976

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80,779.96209
Policy Entropy: 2.62614
Value Function Loss: 0.01645

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.08394
Policy Update Magnitude: 0.34770
Value Function Update Magnitude: 0.34179

Collected Steps per Second: 22,332.16709
Overall Steps per Second: 10,569.00895

Timestep Collection Time: 2.23910
Timestep Consumption Time: 2.49209
PPO Batch Consumption Time: 0.29061
Total Iteration Time: 4.73119

Cumulative Model Updates: 255,968
Cumulative Timesteps: 2,135,352,980

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2135352980...
Checkpoint 2135352980 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 80,779.96209
Policy Entropy: 2.62309
Value Function Loss: 0.01522

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.07561
Policy Update Magnitude: 0.34588
Value Function Update Magnitude: 0.34471

Collected Steps per Second: 21,287.69766
Overall Steps per Second: 10,213.18706

Timestep Collection Time: 2.35037
Timestep Consumption Time: 2.54859
PPO Batch Consumption Time: 0.29433
Total Iteration Time: 4.89896

Cumulative Model Updates: 255,974
Cumulative Timesteps: 2,135,403,014

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 102,458.42621
Policy Entropy: 2.63033
Value Function Loss: 0.01544

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.07146
Policy Update Magnitude: 0.33640
Value Function Update Magnitude: 0.32188

Collected Steps per Second: 22,124.30084
Overall Steps per Second: 10,493.09822

Timestep Collection Time: 2.26113
Timestep Consumption Time: 2.50638
PPO Batch Consumption Time: 0.29302
Total Iteration Time: 4.76751

Cumulative Model Updates: 255,980
Cumulative Timesteps: 2,135,453,040

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2135453040...
Checkpoint 2135453040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 77,419.95723
Policy Entropy: 2.65905
Value Function Loss: 0.01302

Mean KL Divergence: 0.00762
SB3 Clip Fraction: 0.06828
Policy Update Magnitude: 0.31122
Value Function Update Magnitude: 0.27035

Collected Steps per Second: 21,948.10406
Overall Steps per Second: 10,651.20487

Timestep Collection Time: 2.27810
Timestep Consumption Time: 2.41620
PPO Batch Consumption Time: 0.27730
Total Iteration Time: 4.69430

Cumulative Model Updates: 255,986
Cumulative Timesteps: 2,135,503,040

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59,321.50407
Policy Entropy: 2.66683
Value Function Loss: 0.01527

Mean KL Divergence: 0.00705
SB3 Clip Fraction: 0.06055
Policy Update Magnitude: 0.30601
Value Function Update Magnitude: 0.22320

Collected Steps per Second: 21,985.05491
Overall Steps per Second: 10,494.20864

Timestep Collection Time: 2.27564
Timestep Consumption Time: 2.49175
PPO Batch Consumption Time: 0.29249
Total Iteration Time: 4.76739

Cumulative Model Updates: 255,992
Cumulative Timesteps: 2,135,553,070

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2135553070...
Checkpoint 2135553070 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 65,238.57367
Policy Entropy: 2.67864
Value Function Loss: 0.01337

Mean KL Divergence: 0.00639
SB3 Clip Fraction: 0.05863
Policy Update Magnitude: 0.30682
Value Function Update Magnitude: 0.21626

Collected Steps per Second: 21,797.57979
Overall Steps per Second: 10,631.53816

Timestep Collection Time: 2.29411
Timestep Consumption Time: 2.40944
PPO Batch Consumption Time: 0.27714
Total Iteration Time: 4.70355

Cumulative Model Updates: 255,998
Cumulative Timesteps: 2,135,603,076

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65,238.57367
Policy Entropy: 2.67343
Value Function Loss: 0.01172

Mean KL Divergence: 0.00602
SB3 Clip Fraction: 0.05594
Policy Update Magnitude: 0.28741
Value Function Update Magnitude: 0.19794

Collected Steps per Second: 20,922.09593
Overall Steps per Second: 10,360.63268

Timestep Collection Time: 2.39154
Timestep Consumption Time: 2.43790
PPO Batch Consumption Time: 0.29158
Total Iteration Time: 4.82943

Cumulative Model Updates: 256,004
Cumulative Timesteps: 2,135,653,112

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 2135653112...
Checkpoint 2135653112 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 113,028.42477
Policy Entropy: 2.66534
Value Function Loss: 0.00985

Mean KL Divergence: 0.00565
SB3 Clip Fraction: 0.05339
Policy Update Magnitude: 0.28519
Value Function Update Magnitude: 0.17533

Collected Steps per Second: 21,028.55249
Overall Steps per Second: 10,593.12974

Timestep Collection Time: 2.37953
Timestep Consumption Time: 2.34410
PPO Batch Consumption Time: 0.27879
Total Iteration Time: 4.72363

Cumulative Model Updates: 256,010
Cumulative Timesteps: 2,135,703,150

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91,286.96433
Policy Entropy: 2.66970
Value Function Loss: 0.01097

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.07223
Policy Update Magnitude: 0.29316
Value Function Update Magnitude: 0.17133

Collected Steps per Second: 21,167.27401
Overall Steps per Second: 10,503.56528

Timestep Collection Time: 2.36374
Timestep Consumption Time: 2.39978
PPO Batch Consumption Time: 0.28552
Total Iteration Time: 4.76353

Cumulative Model Updates: 256,016
Cumulative Timesteps: 2,135,753,184

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 2135753184...
Checkpoint 2135753184 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 94,936.80664
Policy Entropy: 2.63890
Value Function Loss: 0.01324

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.07108
Policy Update Magnitude: 0.30053
Value Function Update Magnitude: 0.21355

Collected Steps per Second: 21,158.21319
Overall Steps per Second: 10,343.13318

Timestep Collection Time: 2.36457
Timestep Consumption Time: 2.47246
PPO Batch Consumption Time: 0.29186
Total Iteration Time: 4.83703

Cumulative Model Updates: 256,022
Cumulative Timesteps: 2,135,803,214

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 150,961.86501
Policy Entropy: 2.61640
Value Function Loss: 0.01403

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.07165
Policy Update Magnitude: 0.30880
Value Function Update Magnitude: 0.23679

Collected Steps per Second: 22,175.95407
Overall Steps per Second: 10,665.90197

Timestep Collection Time: 2.25487
Timestep Consumption Time: 2.43334
PPO Batch Consumption Time: 0.27847
Total Iteration Time: 4.68821

Cumulative Model Updates: 256,028
Cumulative Timesteps: 2,135,853,218

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2135853218...
Checkpoint 2135853218 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 138,510.47490
Policy Entropy: 2.62415
Value Function Loss: 0.01353

Mean KL Divergence: 0.00753
SB3 Clip Fraction: 0.06554
Policy Update Magnitude: 0.30856
Value Function Update Magnitude: 0.24663

Collected Steps per Second: 21,809.72969
Overall Steps per Second: 10,645.06429

Timestep Collection Time: 2.29347
Timestep Consumption Time: 2.40542
PPO Batch Consumption Time: 0.27831
Total Iteration Time: 4.69889

Cumulative Model Updates: 256,034
Cumulative Timesteps: 2,135,903,238

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 108,086.88330
Policy Entropy: 2.63746
Value Function Loss: 0.01276

Mean KL Divergence: 0.00672
SB3 Clip Fraction: 0.06033
Policy Update Magnitude: 0.30269
Value Function Update Magnitude: 0.24907

Collected Steps per Second: 21,905.09498
Overall Steps per Second: 10,532.05717

Timestep Collection Time: 2.28294
Timestep Consumption Time: 2.46523
PPO Batch Consumption Time: 0.28492
Total Iteration Time: 4.74817

Cumulative Model Updates: 256,040
Cumulative Timesteps: 2,135,953,246

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2135953246...
Checkpoint 2135953246 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 94,238.20977
Policy Entropy: 2.67016
Value Function Loss: 0.01165

Mean KL Divergence: 0.00691
SB3 Clip Fraction: 0.06198
Policy Update Magnitude: 0.29552
Value Function Update Magnitude: 0.26043

Collected Steps per Second: 21,997.03611
Overall Steps per Second: 10,658.52255

Timestep Collection Time: 2.27431
Timestep Consumption Time: 2.41940
PPO Batch Consumption Time: 0.27755
Total Iteration Time: 4.69371

Cumulative Model Updates: 256,046
Cumulative Timesteps: 2,136,003,274

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 101,180.98378
Policy Entropy: 2.63238
Value Function Loss: 0.01438

Mean KL Divergence: 0.00659
SB3 Clip Fraction: 0.05924
Policy Update Magnitude: 0.31728
Value Function Update Magnitude: 0.31436

Collected Steps per Second: 21,930.42279
Overall Steps per Second: 10,388.78561

Timestep Collection Time: 2.28012
Timestep Consumption Time: 2.53315
PPO Batch Consumption Time: 0.29266
Total Iteration Time: 4.81327

Cumulative Model Updates: 256,052
Cumulative Timesteps: 2,136,053,278

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2136053278...
Checkpoint 2136053278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 126,052.21385
Policy Entropy: 2.63394
Value Function Loss: 0.01701

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.06284
Policy Update Magnitude: 0.33789
Value Function Update Magnitude: 0.35145

Collected Steps per Second: 22,070.53242
Overall Steps per Second: 10,650.47223

Timestep Collection Time: 2.26619
Timestep Consumption Time: 2.42994
PPO Batch Consumption Time: 0.27847
Total Iteration Time: 4.69613

Cumulative Model Updates: 256,058
Cumulative Timesteps: 2,136,103,294

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87,694.76987
Policy Entropy: 2.63780
Value Function Loss: 0.01668

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.07251
Policy Update Magnitude: 0.32831
Value Function Update Magnitude: 0.35014

Collected Steps per Second: 21,390.07882
Overall Steps per Second: 10,465.55348

Timestep Collection Time: 2.33800
Timestep Consumption Time: 2.44053
PPO Batch Consumption Time: 0.27787
Total Iteration Time: 4.77853

Cumulative Model Updates: 256,064
Cumulative Timesteps: 2,136,153,304

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2136153304...
Checkpoint 2136153304 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 75,790.71752
Policy Entropy: 2.67728
Value Function Loss: 0.01456

Mean KL Divergence: 0.00730
SB3 Clip Fraction: 0.06620
Policy Update Magnitude: 0.30744
Value Function Update Magnitude: 0.33542

Collected Steps per Second: 21,506.08951
Overall Steps per Second: 10,376.61359

Timestep Collection Time: 2.32492
Timestep Consumption Time: 2.49360
PPO Batch Consumption Time: 0.29218
Total Iteration Time: 4.81853

Cumulative Model Updates: 256,070
Cumulative Timesteps: 2,136,203,304

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87,158.74607
Policy Entropy: 2.67194
Value Function Loss: 0.01120

Mean KL Divergence: 0.00602
SB3 Clip Fraction: 0.05658
Policy Update Magnitude: 0.29414
Value Function Update Magnitude: 0.27459

Collected Steps per Second: 21,682.54841
Overall Steps per Second: 10,398.00446

Timestep Collection Time: 2.30646
Timestep Consumption Time: 2.50311
PPO Batch Consumption Time: 0.29270
Total Iteration Time: 4.80958

Cumulative Model Updates: 256,076
Cumulative Timesteps: 2,136,253,314

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2136253314...
Checkpoint 2136253314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,297.19691
Policy Entropy: 2.66210
Value Function Loss: 0.01243

Mean KL Divergence: 0.00686
SB3 Clip Fraction: 0.06166
Policy Update Magnitude: 0.29731
Value Function Update Magnitude: 0.23847

Collected Steps per Second: 21,280.79938
Overall Steps per Second: 10,475.30371

Timestep Collection Time: 2.34954
Timestep Consumption Time: 2.42360
PPO Batch Consumption Time: 0.27798
Total Iteration Time: 4.77313

Cumulative Model Updates: 256,082
Cumulative Timesteps: 2,136,303,314

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,297.19691
Policy Entropy: 2.62697
Value Function Loss: 0.01266

Mean KL Divergence: 0.00630
SB3 Clip Fraction: 0.05903
Policy Update Magnitude: 0.30041
Value Function Update Magnitude: 0.24169

Collected Steps per Second: 21,752.99851
Overall Steps per Second: 10,587.36593

Timestep Collection Time: 2.29899
Timestep Consumption Time: 2.42456
PPO Batch Consumption Time: 0.27661
Total Iteration Time: 4.72355

Cumulative Model Updates: 256,088
Cumulative Timesteps: 2,136,353,324

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2136353324...
Checkpoint 2136353324 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 57,538.53612
Policy Entropy: 2.64045
Value Function Loss: 0.01203

Mean KL Divergence: 0.00653
SB3 Clip Fraction: 0.06014
Policy Update Magnitude: 0.30239
Value Function Update Magnitude: 0.25346

Collected Steps per Second: 21,623.09806
Overall Steps per Second: 10,609.86875

Timestep Collection Time: 2.31382
Timestep Consumption Time: 2.40179
PPO Batch Consumption Time: 0.28353
Total Iteration Time: 4.71561

Cumulative Model Updates: 256,094
Cumulative Timesteps: 2,136,403,356

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48,555.05769
Policy Entropy: 2.63618
Value Function Loss: 0.01019

Mean KL Divergence: 0.00626
SB3 Clip Fraction: 0.05916
Policy Update Magnitude: 0.29226
Value Function Update Magnitude: 0.28100

Collected Steps per Second: 21,362.07330
Overall Steps per Second: 10,492.37169

Timestep Collection Time: 2.34106
Timestep Consumption Time: 2.42525
PPO Batch Consumption Time: 0.29141
Total Iteration Time: 4.76632

Cumulative Model Updates: 256,100
Cumulative Timesteps: 2,136,453,366

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2136453366...
Checkpoint 2136453366 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 59,056.57761
Policy Entropy: 2.65101
Value Function Loss: 0.01075

Mean KL Divergence: 0.00583
SB3 Clip Fraction: 0.05651
Policy Update Magnitude: 0.29316
Value Function Update Magnitude: 0.28685

Collected Steps per Second: 21,468.88270
Overall Steps per Second: 10,564.61069

Timestep Collection Time: 2.32923
Timestep Consumption Time: 2.40412
PPO Batch Consumption Time: 0.28844
Total Iteration Time: 4.73335

Cumulative Model Updates: 256,106
Cumulative Timesteps: 2,136,503,372

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49,842.53974
Policy Entropy: 2.66552
Value Function Loss: 0.01189

Mean KL Divergence: 0.00764
SB3 Clip Fraction: 0.06914
Policy Update Magnitude: 0.29605
Value Function Update Magnitude: 0.25658

Collected Steps per Second: 21,257.64993
Overall Steps per Second: 10,524.54092

Timestep Collection Time: 2.35285
Timestep Consumption Time: 2.39947
PPO Batch Consumption Time: 0.27683
Total Iteration Time: 4.75232

Cumulative Model Updates: 256,112
Cumulative Timesteps: 2,136,553,388

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2136553388...
Checkpoint 2136553388 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 65,291.82219
Policy Entropy: 2.67971
Value Function Loss: 0.01231

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.07220
Policy Update Magnitude: 0.29228
Value Function Update Magnitude: 0.26080

Collected Steps per Second: 22,104.19472
Overall Steps per Second: 10,560.53892

Timestep Collection Time: 2.26292
Timestep Consumption Time: 2.47358
PPO Batch Consumption Time: 0.29128
Total Iteration Time: 4.73650

Cumulative Model Updates: 256,118
Cumulative Timesteps: 2,136,603,408

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51,569.79970
Policy Entropy: 2.67624
Value Function Loss: 0.01355

Mean KL Divergence: 0.01777
SB3 Clip Fraction: 0.12238
Policy Update Magnitude: 0.29574
Value Function Update Magnitude: 0.30531

Collected Steps per Second: 21,738.55590
Overall Steps per Second: 10,445.02577

Timestep Collection Time: 2.30052
Timestep Consumption Time: 2.48740
PPO Batch Consumption Time: 0.29229
Total Iteration Time: 4.78793

Cumulative Model Updates: 256,124
Cumulative Timesteps: 2,136,653,418

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2136653418...
Checkpoint 2136653418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 60,980.73535
Policy Entropy: 2.65881
Value Function Loss: 0.01363

Mean KL Divergence: 0.01614
SB3 Clip Fraction: 0.11753
Policy Update Magnitude: 0.28148
Value Function Update Magnitude: 0.31403

Collected Steps per Second: 21,924.16455
Overall Steps per Second: 10,600.21514

Timestep Collection Time: 2.28132
Timestep Consumption Time: 2.43708
PPO Batch Consumption Time: 0.27849
Total Iteration Time: 4.71839

Cumulative Model Updates: 256,130
Cumulative Timesteps: 2,136,703,434

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89,772.99814
Policy Entropy: 2.66777
Value Function Loss: 0.01282

Mean KL Divergence: 0.01954
SB3 Clip Fraction: 0.12621
Policy Update Magnitude: 0.29172
Value Function Update Magnitude: 0.30795

Collected Steps per Second: 21,589.87647
Overall Steps per Second: 10,520.40744

Timestep Collection Time: 2.31812
Timestep Consumption Time: 2.43911
PPO Batch Consumption Time: 0.27873
Total Iteration Time: 4.75723

Cumulative Model Updates: 256,136
Cumulative Timesteps: 2,136,753,482

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 2136753482...
Checkpoint 2136753482 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 108,606.75606
Policy Entropy: 2.66321
Value Function Loss: 0.01292

Mean KL Divergence: 0.01604
SB3 Clip Fraction: 0.11289
Policy Update Magnitude: 0.30151
Value Function Update Magnitude: 0.32784

Collected Steps per Second: 21,295.08328
Overall Steps per Second: 10,304.90829

Timestep Collection Time: 2.34937
Timestep Consumption Time: 2.50560
PPO Batch Consumption Time: 0.29309
Total Iteration Time: 4.85497

Cumulative Model Updates: 256,142
Cumulative Timesteps: 2,136,803,512

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 102,884.59109
Policy Entropy: 2.63487
Value Function Loss: 0.01417

Mean KL Divergence: 0.01151
SB3 Clip Fraction: 0.09797
Policy Update Magnitude: 0.32168
Value Function Update Magnitude: 0.35338

Collected Steps per Second: 21,560.88300
Overall Steps per Second: 10,329.13644

Timestep Collection Time: 2.32133
Timestep Consumption Time: 2.52418
PPO Batch Consumption Time: 0.29263
Total Iteration Time: 4.84552

Cumulative Model Updates: 256,148
Cumulative Timesteps: 2,136,853,562

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 2136853562...
Checkpoint 2136853562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 126,349.81225
Policy Entropy: 2.59281
Value Function Loss: 0.01567

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.08747
Policy Update Magnitude: 0.34112
Value Function Update Magnitude: 0.38216

Collected Steps per Second: 21,120.20096
Overall Steps per Second: 10,240.56460

Timestep Collection Time: 2.36778
Timestep Consumption Time: 2.51554
PPO Batch Consumption Time: 0.29402
Total Iteration Time: 4.88332

Cumulative Model Updates: 256,154
Cumulative Timesteps: 2,136,903,570

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 110,315.48396
Policy Entropy: 2.60968
Value Function Loss: 0.01396

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.07443
Policy Update Magnitude: 0.33926
Value Function Update Magnitude: 0.38158

Collected Steps per Second: 21,907.14138
Overall Steps per Second: 10,452.96568

Timestep Collection Time: 2.28346
Timestep Consumption Time: 2.50217
PPO Batch Consumption Time: 0.28773
Total Iteration Time: 4.78563

Cumulative Model Updates: 256,160
Cumulative Timesteps: 2,136,953,594

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2136953594...
Checkpoint 2136953594 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 110,866.18629
Policy Entropy: 2.63510
Value Function Loss: 0.01444

Mean KL Divergence: 0.00707
SB3 Clip Fraction: 0.06373
Policy Update Magnitude: 0.33327
Value Function Update Magnitude: 0.39066

Collected Steps per Second: 21,853.56860
Overall Steps per Second: 10,374.45525

Timestep Collection Time: 2.28924
Timestep Consumption Time: 2.53299
PPO Batch Consumption Time: 0.29066
Total Iteration Time: 4.82223

Cumulative Model Updates: 256,166
Cumulative Timesteps: 2,137,003,622

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93,672.82301
Policy Entropy: 2.67867
Value Function Loss: 0.01322

Mean KL Divergence: 0.00672
SB3 Clip Fraction: 0.06121
Policy Update Magnitude: 0.32167
Value Function Update Magnitude: 0.38914

Collected Steps per Second: 22,269.97843
Overall Steps per Second: 10,648.19102

Timestep Collection Time: 2.24706
Timestep Consumption Time: 2.45252
PPO Batch Consumption Time: 0.27881
Total Iteration Time: 4.69958

Cumulative Model Updates: 256,172
Cumulative Timesteps: 2,137,053,664

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 2137053664...
Checkpoint 2137053664 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 93,672.82301
Policy Entropy: 2.69879
Value Function Loss: 0.01162

Mean KL Divergence: 0.00643
SB3 Clip Fraction: 0.05896
Policy Update Magnitude: 0.30080
Value Function Update Magnitude: 0.33857

Collected Steps per Second: 21,885.36858
Overall Steps per Second: 10,508.46586

Timestep Collection Time: 2.28518
Timestep Consumption Time: 2.47403
PPO Batch Consumption Time: 0.28639
Total Iteration Time: 4.75921

Cumulative Model Updates: 256,178
Cumulative Timesteps: 2,137,103,676

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90,328.31729
Policy Entropy: 2.68514
Value Function Loss: 0.01090

Mean KL Divergence: 0.00621
SB3 Clip Fraction: 0.05881
Policy Update Magnitude: 0.28518
Value Function Update Magnitude: 0.28524

Collected Steps per Second: 21,897.95488
Overall Steps per Second: 10,627.62775

Timestep Collection Time: 2.28569
Timestep Consumption Time: 2.42392
PPO Batch Consumption Time: 0.27845
Total Iteration Time: 4.70961

Cumulative Model Updates: 256,184
Cumulative Timesteps: 2,137,153,728

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


Saving checkpoint 2137153728...
Checkpoint 2137153728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 70,467.30686
Policy Entropy: 2.67543
Value Function Loss: 0.01158

Mean KL Divergence: 0.00568
SB3 Clip Fraction: 0.05387
Policy Update Magnitude: 0.29231
Value Function Update Magnitude: 0.27876

Collected Steps per Second: 21,765.15323
Overall Steps per Second: 10,597.06664

Timestep Collection Time: 2.29890
Timestep Consumption Time: 2.42278
PPO Batch Consumption Time: 0.27913
Total Iteration Time: 4.72168

Cumulative Model Updates: 256,190
Cumulative Timesteps: 2,137,203,764

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 72,743.15025
Policy Entropy: 2.64731
Value Function Loss: 0.01253

Mean KL Divergence: 0.00638
SB3 Clip Fraction: 0.06014
Policy Update Magnitude: 0.30514
Value Function Update Magnitude: 0.31193

Collected Steps per Second: 22,079.31991
Overall Steps per Second: 10,526.06101

Timestep Collection Time: 2.26511
Timestep Consumption Time: 2.48615
PPO Batch Consumption Time: 0.28639
Total Iteration Time: 4.75125

Cumulative Model Updates: 256,196
Cumulative Timesteps: 2,137,253,776

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2137253776...
Checkpoint 2137253776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 53,806.83096
Policy Entropy: 2.63669
Value Function Loss: 0.01226

Mean KL Divergence: 0.00622
SB3 Clip Fraction: 0.05807
Policy Update Magnitude: 0.30970
Value Function Update Magnitude: 0.34077

Collected Steps per Second: 20,207.96774
Overall Steps per Second: 10,160.12926

Timestep Collection Time: 2.47586
Timestep Consumption Time: 2.44849
PPO Batch Consumption Time: 0.27870
Total Iteration Time: 4.92435

Cumulative Model Updates: 256,202
Cumulative Timesteps: 2,137,303,808

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 73,534.32221
Policy Entropy: 2.65817
Value Function Loss: 0.01217

Mean KL Divergence: 0.00619
SB3 Clip Fraction: 0.05892
Policy Update Magnitude: 0.31283
Value Function Update Magnitude: 0.34090

Collected Steps per Second: 21,239.26106
Overall Steps per Second: 10,502.12294

Timestep Collection Time: 2.35620
Timestep Consumption Time: 2.40893
PPO Batch Consumption Time: 0.28562
Total Iteration Time: 4.76513

Cumulative Model Updates: 256,208
Cumulative Timesteps: 2,137,353,852

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 2137353852...
Checkpoint 2137353852 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 66,159.36139
Policy Entropy: 2.68616
Value Function Loss: 0.01322

Mean KL Divergence: 0.00691
SB3 Clip Fraction: 0.06201
Policy Update Magnitude: 0.31724
Value Function Update Magnitude: 0.33898

Collected Steps per Second: 21,004.89886
Overall Steps per Second: 10,387.54591

Timestep Collection Time: 2.38049
Timestep Consumption Time: 2.43316
PPO Batch Consumption Time: 0.29001
Total Iteration Time: 4.81365

Cumulative Model Updates: 256,214
Cumulative Timesteps: 2,137,403,854

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 121,966.38835
Policy Entropy: 2.70445
Value Function Loss: 0.01278

Mean KL Divergence: 0.00620
SB3 Clip Fraction: 0.05598
Policy Update Magnitude: 0.30549
Value Function Update Magnitude: 0.33765

Collected Steps per Second: 21,681.98572
Overall Steps per Second: 10,669.83123

Timestep Collection Time: 2.30662
Timestep Consumption Time: 2.38062
PPO Batch Consumption Time: 0.27873
Total Iteration Time: 4.68723

Cumulative Model Updates: 256,220
Cumulative Timesteps: 2,137,453,866

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2137453866...
Checkpoint 2137453866 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 121,966.38835
Policy Entropy: 2.69742
Value Function Loss: 0.01184

Mean KL Divergence: 0.00587
SB3 Clip Fraction: 0.05271
Policy Update Magnitude: 0.29278
Value Function Update Magnitude: 0.32382

Collected Steps per Second: 21,427.33859
Overall Steps per Second: 10,422.04228

Timestep Collection Time: 2.33375
Timestep Consumption Time: 2.46435
PPO Batch Consumption Time: 0.28960
Total Iteration Time: 4.79810

Cumulative Model Updates: 256,226
Cumulative Timesteps: 2,137,503,872

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 107,200.59839
Policy Entropy: 2.67144
Value Function Loss: 0.01191

Mean KL Divergence: 0.00644
SB3 Clip Fraction: 0.06012
Policy Update Magnitude: 0.29644
Value Function Update Magnitude: 0.32500

Collected Steps per Second: 22,320.37717
Overall Steps per Second: 10,799.82153

Timestep Collection Time: 2.24190
Timestep Consumption Time: 2.39151
PPO Batch Consumption Time: 0.27683
Total Iteration Time: 4.63341

Cumulative Model Updates: 256,232
Cumulative Timesteps: 2,137,553,912

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 2137553912...
Checkpoint 2137553912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 85,456.60971
Policy Entropy: 2.66105
Value Function Loss: 0.01298

Mean KL Divergence: 0.00749
SB3 Clip Fraction: 0.06617
Policy Update Magnitude: 0.30422
Value Function Update Magnitude: 0.32637

Collected Steps per Second: 21,992.72312
Overall Steps per Second: 10,579.49629

Timestep Collection Time: 2.27402
Timestep Consumption Time: 2.45323
PPO Batch Consumption Time: 0.28849
Total Iteration Time: 4.72726

Cumulative Model Updates: 256,238
Cumulative Timesteps: 2,137,603,924

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 107,371.94135
Policy Entropy: 2.65828
Value Function Loss: 0.01293

Mean KL Divergence: 0.01089
SB3 Clip Fraction: 0.06539
Policy Update Magnitude: 0.30338
Value Function Update Magnitude: 0.34831

Collected Steps per Second: 22,276.92926
Overall Steps per Second: 10,524.49803

Timestep Collection Time: 2.24582
Timestep Consumption Time: 2.50785
PPO Batch Consumption Time: 0.29346
Total Iteration Time: 4.75367

Cumulative Model Updates: 256,244
Cumulative Timesteps: 2,137,653,954

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2137653954...
Checkpoint 2137653954 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 97,570.09886
Policy Entropy: 2.68225
Value Function Loss: 0.01117

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.05992
Policy Update Magnitude: 0.29476
Value Function Update Magnitude: 0.33221

Collected Steps per Second: 22,072.73301
Overall Steps per Second: 10,662.16201

Timestep Collection Time: 2.26533
Timestep Consumption Time: 2.42434
PPO Batch Consumption Time: 0.27659
Total Iteration Time: 4.68967

Cumulative Model Updates: 256,250
Cumulative Timesteps: 2,137,703,956

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 71,564.72804
Policy Entropy: 2.68000
Value Function Loss: 0.01213

Mean KL Divergence: 0.00607
SB3 Clip Fraction: 0.05663
Policy Update Magnitude: 0.29402
Value Function Update Magnitude: 0.28358

Collected Steps per Second: 21,933.08267
Overall Steps per Second: 10,443.34467

Timestep Collection Time: 2.28176
Timestep Consumption Time: 2.51038
PPO Batch Consumption Time: 0.29335
Total Iteration Time: 4.79214

Cumulative Model Updates: 256,256
Cumulative Timesteps: 2,137,754,002

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 2137754002...
Checkpoint 2137754002 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 71,564.72804
Policy Entropy: 2.67746
Value Function Loss: 0.01085

Mean KL Divergence: 0.00584
SB3 Clip Fraction: 0.05262
Policy Update Magnitude: 0.28596
Value Function Update Magnitude: 0.25472

Collected Steps per Second: 21,421.73913
Overall Steps per Second: 10,519.56267

Timestep Collection Time: 2.33492
Timestep Consumption Time: 2.41984
PPO Batch Consumption Time: 0.27837
Total Iteration Time: 4.75476

Cumulative Model Updates: 256,262
Cumulative Timesteps: 2,137,804,020

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 135,889.39733
Policy Entropy: 2.67630
Value Function Loss: 0.01190

Mean KL Divergence: 0.00583
SB3 Clip Fraction: 0.05392
Policy Update Magnitude: 0.28287
Value Function Update Magnitude: 0.24344

Collected Steps per Second: 21,691.25515
Overall Steps per Second: 10,560.72330

Timestep Collection Time: 2.30554
Timestep Consumption Time: 2.42993
PPO Batch Consumption Time: 0.27721
Total Iteration Time: 4.73547

Cumulative Model Updates: 256,268
Cumulative Timesteps: 2,137,854,030

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2137854030...
Checkpoint 2137854030 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 114,436.08025
Policy Entropy: 2.70057
Value Function Loss: 0.00977

Mean KL Divergence: 0.00504
SB3 Clip Fraction: 0.04784
Policy Update Magnitude: 0.27433
Value Function Update Magnitude: 0.23693

Collected Steps per Second: 21,518.70801
Overall Steps per Second: 10,539.79024

Timestep Collection Time: 2.32384
Timestep Consumption Time: 2.42066
PPO Batch Consumption Time: 0.27697
Total Iteration Time: 4.74450

Cumulative Model Updates: 256,274
Cumulative Timesteps: 2,137,904,036

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 107,413.34543
Policy Entropy: 2.69461
Value Function Loss: 0.01273

Mean KL Divergence: 0.00610
SB3 Clip Fraction: 0.05378
Policy Update Magnitude: 0.28210
Value Function Update Magnitude: 0.29364

Collected Steps per Second: 21,989.32379
Overall Steps per Second: 10,496.48095

Timestep Collection Time: 2.27601
Timestep Consumption Time: 2.49206
PPO Batch Consumption Time: 0.27924
Total Iteration Time: 4.76807

Cumulative Model Updates: 256,280
Cumulative Timesteps: 2,137,954,084

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 2137954084...
Checkpoint 2137954084 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 91,425.00116
Policy Entropy: 2.68675
Value Function Loss: 0.01187

Mean KL Divergence: 0.00751
SB3 Clip Fraction: 0.06932
Policy Update Magnitude: 0.29388
Value Function Update Magnitude: 0.30859

Collected Steps per Second: 21,911.30236
Overall Steps per Second: 10,563.63395

Timestep Collection Time: 2.28330
Timestep Consumption Time: 2.45276
PPO Batch Consumption Time: 0.27866
Total Iteration Time: 4.73606

Cumulative Model Updates: 256,286
Cumulative Timesteps: 2,138,004,114

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92,043.25187
Policy Entropy: 2.68222
Value Function Loss: 0.01282

Mean KL Divergence: 0.01116
SB3 Clip Fraction: 0.09451
Policy Update Magnitude: 0.29088
Value Function Update Magnitude: 0.29844

Collected Steps per Second: 22,095.52426
Overall Steps per Second: 10,487.10391

Timestep Collection Time: 2.26444
Timestep Consumption Time: 2.50656
PPO Batch Consumption Time: 0.28967
Total Iteration Time: 4.77100

Cumulative Model Updates: 256,292
Cumulative Timesteps: 2,138,054,148

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 2138054148...
Checkpoint 2138054148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 100,390.32212
Policy Entropy: 2.68634
Value Function Loss: 0.01150

Mean KL Divergence: 0.01397
SB3 Clip Fraction: 0.10886
Policy Update Magnitude: 0.27251
Value Function Update Magnitude: 0.28535

Collected Steps per Second: 22,008.41291
Overall Steps per Second: 10,652.44160

Timestep Collection Time: 2.27222
Timestep Consumption Time: 2.42229
PPO Batch Consumption Time: 0.27876
Total Iteration Time: 4.69451

Cumulative Model Updates: 256,298
Cumulative Timesteps: 2,138,104,156

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86,338.58504
Policy Entropy: 2.69822
Value Function Loss: 0.01094

Mean KL Divergence: 0.01261
SB3 Clip Fraction: 0.10516
Policy Update Magnitude: 0.26218
Value Function Update Magnitude: 0.26178

Collected Steps per Second: 21,996.51207
Overall Steps per Second: 10,468.27024

Timestep Collection Time: 2.27327
Timestep Consumption Time: 2.50345
PPO Batch Consumption Time: 0.29121
Total Iteration Time: 4.77672

Cumulative Model Updates: 256,304
Cumulative Timesteps: 2,138,154,160

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2138154160...
Checkpoint 2138154160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 75,374.61237
Policy Entropy: 2.71944
Value Function Loss: 0.01025

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.08412
Policy Update Magnitude: 0.26998
Value Function Update Magnitude: 0.23694

Collected Steps per Second: 21,487.82664
Overall Steps per Second: 10,395.18194

Timestep Collection Time: 2.32764
Timestep Consumption Time: 2.48382
PPO Batch Consumption Time: 0.28976
Total Iteration Time: 4.81146

Cumulative Model Updates: 256,310
Cumulative Timesteps: 2,138,204,176

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 166,122.18012
Policy Entropy: 2.71072
Value Function Loss: 0.01095

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.07148
Policy Update Magnitude: 0.26850
Value Function Update Magnitude: 0.23018

Collected Steps per Second: 22,179.78856
Overall Steps per Second: 10,684.63574

Timestep Collection Time: 2.25439
Timestep Consumption Time: 2.42541
PPO Batch Consumption Time: 0.27832
Total Iteration Time: 4.67980

Cumulative Model Updates: 256,316
Cumulative Timesteps: 2,138,254,178

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2138254178...
Checkpoint 2138254178 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 135,252.74976
Policy Entropy: 2.71243
Value Function Loss: 0.01024

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.08559
Policy Update Magnitude: 0.26873
Value Function Update Magnitude: 0.22053

Collected Steps per Second: 21,678.02456
Overall Steps per Second: 10,594.17396

Timestep Collection Time: 2.30722
Timestep Consumption Time: 2.41386
PPO Batch Consumption Time: 0.27763
Total Iteration Time: 4.72109

Cumulative Model Updates: 256,322
Cumulative Timesteps: 2,138,304,194

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 101,145.62621
Policy Entropy: 2.70057
Value Function Loss: 0.01264

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.08384
Policy Update Magnitude: 0.27799
Value Function Update Magnitude: 0.21504

Collected Steps per Second: 21,543.91144
Overall Steps per Second: 10,530.34664

Timestep Collection Time: 2.32298
Timestep Consumption Time: 2.42957
PPO Batch Consumption Time: 0.27811
Total Iteration Time: 4.75255

Cumulative Model Updates: 256,328
Cumulative Timesteps: 2,138,354,240

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 2138354240...
Checkpoint 2138354240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 101,145.62621
Policy Entropy: 2.70842
Value Function Loss: 0.01168

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.07566
Policy Update Magnitude: 0.28475
Value Function Update Magnitude: 0.23096

Collected Steps per Second: 21,534.85834
Overall Steps per Second: 10,568.56018

Timestep Collection Time: 2.32247
Timestep Consumption Time: 2.40987
PPO Batch Consumption Time: 0.27785
Total Iteration Time: 4.73234

Cumulative Model Updates: 256,334
Cumulative Timesteps: 2,138,404,254

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 101,145.62621
Policy Entropy: 2.69377
Value Function Loss: 0.01181

Mean KL Divergence: 0.00741
SB3 Clip Fraction: 0.06710
Policy Update Magnitude: 0.28477
Value Function Update Magnitude: 0.27525

Collected Steps per Second: 20,962.27340
Overall Steps per Second: 10,476.79077

Timestep Collection Time: 2.38552
Timestep Consumption Time: 2.38750
PPO Batch Consumption Time: 0.27929
Total Iteration Time: 4.77303

Cumulative Model Updates: 256,340
Cumulative Timesteps: 2,138,454,260

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2138454260...
Checkpoint 2138454260 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 158,760.09530
Policy Entropy: 2.69894
Value Function Loss: 0.01074

Mean KL Divergence: 0.00722
SB3 Clip Fraction: 0.06800
Policy Update Magnitude: 0.28540
Value Function Update Magnitude: 0.26693

Collected Steps per Second: 21,312.84448
Overall Steps per Second: 10,572.26928

Timestep Collection Time: 2.34826
Timestep Consumption Time: 2.38564
PPO Batch Consumption Time: 0.27881
Total Iteration Time: 4.73389

Cumulative Model Updates: 256,346
Cumulative Timesteps: 2,138,504,308

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 159,727.97756
Policy Entropy: 2.70142
Value Function Loss: 0.01133

Mean KL Divergence: 0.00684
SB3 Clip Fraction: 0.06168
Policy Update Magnitude: 0.28443
Value Function Update Magnitude: 0.26222

Collected Steps per Second: 21,677.08039
Overall Steps per Second: 10,558.12830

Timestep Collection Time: 2.30806
Timestep Consumption Time: 2.43066
PPO Batch Consumption Time: 0.27878
Total Iteration Time: 4.73872

Cumulative Model Updates: 256,352
Cumulative Timesteps: 2,138,554,340

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2138554340...
Checkpoint 2138554340 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 191,905.87194
Policy Entropy: 2.69438
Value Function Loss: 0.01173

Mean KL Divergence: 0.00635
SB3 Clip Fraction: 0.05744
Policy Update Magnitude: 0.29411
Value Function Update Magnitude: 0.29369

Collected Steps per Second: 21,782.92145
Overall Steps per Second: 10,637.26581

Timestep Collection Time: 2.29584
Timestep Consumption Time: 2.40556
PPO Batch Consumption Time: 0.27890
Total Iteration Time: 4.70140

Cumulative Model Updates: 256,358
Cumulative Timesteps: 2,138,604,350

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 164,920.63852
Policy Entropy: 2.68713
Value Function Loss: 0.01046

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.07566
Policy Update Magnitude: 0.29484
Value Function Update Magnitude: 0.27649

Collected Steps per Second: 22,002.90873
Overall Steps per Second: 10,454.45527

Timestep Collection Time: 2.27315
Timestep Consumption Time: 2.51103
PPO Batch Consumption Time: 0.29326
Total Iteration Time: 4.78418

Cumulative Model Updates: 256,364
Cumulative Timesteps: 2,138,654,366

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2138654366...
Checkpoint 2138654366 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 175,253.77771
Policy Entropy: 2.68880
Value Function Loss: 0.01094

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.07890
Policy Update Magnitude: 0.30143
Value Function Update Magnitude: 0.26587

Collected Steps per Second: 22,024.86700
Overall Steps per Second: 10,598.18051

Timestep Collection Time: 2.27062
Timestep Consumption Time: 2.44812
PPO Batch Consumption Time: 0.27950
Total Iteration Time: 4.71873

Cumulative Model Updates: 256,370
Cumulative Timesteps: 2,138,704,376

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 110,789.61017
Policy Entropy: 2.69758
Value Function Loss: 0.01364

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.07098
Policy Update Magnitude: 0.30450
Value Function Update Magnitude: 0.26328

Collected Steps per Second: 22,182.26539
Overall Steps per Second: 10,499.06117

Timestep Collection Time: 2.25504
Timestep Consumption Time: 2.50938
PPO Batch Consumption Time: 0.29275
Total Iteration Time: 4.76443

Cumulative Model Updates: 256,376
Cumulative Timesteps: 2,138,754,398

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2138754398...
Checkpoint 2138754398 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 96,262.96669
Policy Entropy: 2.68744
Value Function Loss: 0.01435

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.06508
Policy Update Magnitude: 0.31099
Value Function Update Magnitude: 0.29985

Collected Steps per Second: 21,605.65936
Overall Steps per Second: 10,436.32038

Timestep Collection Time: 2.31560
Timestep Consumption Time: 2.47824
PPO Batch Consumption Time: 0.28854
Total Iteration Time: 4.79384

Cumulative Model Updates: 256,382
Cumulative Timesteps: 2,138,804,428

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 102,617.76285
Policy Entropy: 2.66666
Value Function Loss: 0.01323

Mean KL Divergence: 0.00760
SB3 Clip Fraction: 0.06345
Policy Update Magnitude: 0.31432
Value Function Update Magnitude: 0.36338

Collected Steps per Second: 22,022.62597
Overall Steps per Second: 10,652.77119

Timestep Collection Time: 2.27166
Timestep Consumption Time: 2.42458
PPO Batch Consumption Time: 0.27800
Total Iteration Time: 4.69624

Cumulative Model Updates: 256,388
Cumulative Timesteps: 2,138,854,456

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2138854456...
Checkpoint 2138854456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 128,646.38803
Policy Entropy: 2.67755
Value Function Loss: 0.01082

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.07592
Policy Update Magnitude: 0.30110
Value Function Update Magnitude: 0.36598

Collected Steps per Second: 21,402.24768
Overall Steps per Second: 10,324.67580

Timestep Collection Time: 2.33732
Timestep Consumption Time: 2.50777
PPO Batch Consumption Time: 0.29341
Total Iteration Time: 4.84509

Cumulative Model Updates: 256,394
Cumulative Timesteps: 2,138,904,480

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 110,653.69787
Policy Entropy: 2.68496
Value Function Loss: 0.01251

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.07306
Policy Update Magnitude: 0.30398
Value Function Update Magnitude: 0.32472

Collected Steps per Second: 21,889.80782
Overall Steps per Second: 10,480.81740

Timestep Collection Time: 2.28462
Timestep Consumption Time: 2.48695
PPO Batch Consumption Time: 0.29256
Total Iteration Time: 4.77157

Cumulative Model Updates: 256,400
Cumulative Timesteps: 2,138,954,490

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2138954490...
Checkpoint 2138954490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 90,645.06717
Policy Entropy: 2.70867
Value Function Loss: 0.01150

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.07463
Policy Update Magnitude: 0.30197
Value Function Update Magnitude: 0.31643

Collected Steps per Second: 20,991.76410
Overall Steps per Second: 10,601.78338

Timestep Collection Time: 2.38236
Timestep Consumption Time: 2.33477
PPO Batch Consumption Time: 0.27674
Total Iteration Time: 4.71713

Cumulative Model Updates: 256,406
Cumulative Timesteps: 2,139,004,500

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90,645.06717
Policy Entropy: 2.70996
Value Function Loss: 0.01091

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.07508
Policy Update Magnitude: 0.28442
Value Function Update Magnitude: 0.31044

Collected Steps per Second: 21,598.05951
Overall Steps per Second: 10,489.30093

Timestep Collection Time: 2.31595
Timestep Consumption Time: 2.45272
PPO Batch Consumption Time: 0.29232
Total Iteration Time: 4.76867

Cumulative Model Updates: 256,412
Cumulative Timesteps: 2,139,054,520

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2139054520...
Checkpoint 2139054520 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 104,087.94268
Policy Entropy: 2.69474
Value Function Loss: 0.00977

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.06657
Policy Update Magnitude: 0.28499
Value Function Update Magnitude: 0.29234

Collected Steps per Second: 21,301.85617
Overall Steps per Second: 10,439.44527

Timestep Collection Time: 2.34881
Timestep Consumption Time: 2.44397
PPO Batch Consumption Time: 0.29129
Total Iteration Time: 4.79278

Cumulative Model Updates: 256,418
Cumulative Timesteps: 2,139,104,554

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86,688.18812
Policy Entropy: 2.68199
Value Function Loss: 0.01177

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.06548
Policy Update Magnitude: 0.29713
Value Function Update Magnitude: 0.28109

Collected Steps per Second: 21,692.35032
Overall Steps per Second: 10,530.02967

Timestep Collection Time: 2.30551
Timestep Consumption Time: 2.44395
PPO Batch Consumption Time: 0.28492
Total Iteration Time: 4.74946

Cumulative Model Updates: 256,424
Cumulative Timesteps: 2,139,154,566

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2139154566...
Checkpoint 2139154566 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 81,445.38164
Policy Entropy: 2.66916
Value Function Loss: 0.01268

Mean KL Divergence: 0.00670
SB3 Clip Fraction: 0.06132
Policy Update Magnitude: 0.31181
Value Function Update Magnitude: 0.29922

Collected Steps per Second: 21,489.43013
Overall Steps per Second: 10,579.28869

Timestep Collection Time: 2.32812
Timestep Consumption Time: 2.40093
PPO Batch Consumption Time: 0.27897
Total Iteration Time: 4.72905

Cumulative Model Updates: 256,430
Cumulative Timesteps: 2,139,204,596

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75,990.39671
Policy Entropy: 2.69022
Value Function Loss: 0.01127

Mean KL Divergence: 0.00650
SB3 Clip Fraction: 0.05653
Policy Update Magnitude: 0.29618
Value Function Update Magnitude: 0.30895

Collected Steps per Second: 22,035.03731
Overall Steps per Second: 10,515.86673

Timestep Collection Time: 2.26929
Timestep Consumption Time: 2.48581
PPO Batch Consumption Time: 0.29216
Total Iteration Time: 4.75510

Cumulative Model Updates: 256,436
Cumulative Timesteps: 2,139,254,600

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2139254600...
Checkpoint 2139254600 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 98,363.81646
Policy Entropy: 2.67932
Value Function Loss: 0.00970

Mean KL Divergence: 0.00566
SB3 Clip Fraction: 0.05246
Policy Update Magnitude: 0.28633
Value Function Update Magnitude: 0.29755

Collected Steps per Second: 21,429.96198
Overall Steps per Second: 10,367.29554

Timestep Collection Time: 2.33412
Timestep Consumption Time: 2.49067
PPO Batch Consumption Time: 0.29050
Total Iteration Time: 4.82479

Cumulative Model Updates: 256,442
Cumulative Timesteps: 2,139,304,620

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56,301.69957
Policy Entropy: 2.65308
Value Function Loss: 0.01132

Mean KL Divergence: 0.00551
SB3 Clip Fraction: 0.05093
Policy Update Magnitude: 0.29468
Value Function Update Magnitude: 0.25263

Collected Steps per Second: 22,237.44608
Overall Steps per Second: 10,710.21480

Timestep Collection Time: 2.24954
Timestep Consumption Time: 2.42114
PPO Batch Consumption Time: 0.27812
Total Iteration Time: 4.67068

Cumulative Model Updates: 256,448
Cumulative Timesteps: 2,139,354,644

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2139354644...
Checkpoint 2139354644 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89,390.68014
Policy Entropy: 2.65641
Value Function Loss: 0.01177

Mean KL Divergence: 0.00757
SB3 Clip Fraction: 0.06239
Policy Update Magnitude: 0.30137
Value Function Update Magnitude: 0.24082

Collected Steps per Second: 21,349.52361
Overall Steps per Second: 10,335.30740

Timestep Collection Time: 2.34300
Timestep Consumption Time: 2.49691
PPO Batch Consumption Time: 0.29243
Total Iteration Time: 4.83991

Cumulative Model Updates: 256,454
Cumulative Timesteps: 2,139,404,666

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 152,712.05923
Policy Entropy: 2.67142
Value Function Loss: 0.01238

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.06560
Policy Update Magnitude: 0.30251
Value Function Update Magnitude: 0.26836

Collected Steps per Second: 21,847.75676
Overall Steps per Second: 10,465.68097

Timestep Collection Time: 2.29012
Timestep Consumption Time: 2.49065
PPO Batch Consumption Time: 0.29076
Total Iteration Time: 4.78077

Cumulative Model Updates: 256,460
Cumulative Timesteps: 2,139,454,700

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 2139454700...
Checkpoint 2139454700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 107,729.08967
Policy Entropy: 2.68661
Value Function Loss: 0.01145

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.06373
Policy Update Magnitude: 0.29068
Value Function Update Magnitude: 0.30698

Collected Steps per Second: 21,560.35771
Overall Steps per Second: 10,518.64779

Timestep Collection Time: 2.31953
Timestep Consumption Time: 2.43488
PPO Batch Consumption Time: 0.27904
Total Iteration Time: 4.75441

Cumulative Model Updates: 256,466
Cumulative Timesteps: 2,139,504,710

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 136,381.74495
Policy Entropy: 2.65888
Value Function Loss: 0.01206

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.07246
Policy Update Magnitude: 0.29661
Value Function Update Magnitude: 0.31415

Collected Steps per Second: 22,058.10186
Overall Steps per Second: 10,473.16678

Timestep Collection Time: 2.26801
Timestep Consumption Time: 2.50877
PPO Batch Consumption Time: 0.29341
Total Iteration Time: 4.77678

Cumulative Model Updates: 256,472
Cumulative Timesteps: 2,139,554,738

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2139554738...
Checkpoint 2139554738 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 117,837.62019
Policy Entropy: 2.65890
Value Function Loss: 0.01151

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.06792
Policy Update Magnitude: 0.29222
Value Function Update Magnitude: 0.30524

Collected Steps per Second: 21,465.28706
Overall Steps per Second: 10,341.11694

Timestep Collection Time: 2.33093
Timestep Consumption Time: 2.50743
PPO Batch Consumption Time: 0.29156
Total Iteration Time: 4.83836

Cumulative Model Updates: 256,478
Cumulative Timesteps: 2,139,604,772

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 138,700.98465
Policy Entropy: 2.66705
Value Function Loss: 0.01168

Mean KL Divergence: 0.00684
SB3 Clip Fraction: 0.06202
Policy Update Magnitude: 0.28782
Value Function Update Magnitude: 0.29584

Collected Steps per Second: 22,204.15854
Overall Steps per Second: 10,457.51197

Timestep Collection Time: 2.25363
Timestep Consumption Time: 2.53145
PPO Batch Consumption Time: 0.29068
Total Iteration Time: 4.78508

Cumulative Model Updates: 256,484
Cumulative Timesteps: 2,139,654,812

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 2139654812...
Checkpoint 2139654812 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 138,700.98465
Policy Entropy: 2.68077
Value Function Loss: 0.01101

Mean KL Divergence: 0.00540
SB3 Clip Fraction: 0.05033
Policy Update Magnitude: 0.29610
Value Function Update Magnitude: 0.29135

Collected Steps per Second: 22,204.48599
Overall Steps per Second: 10,476.79825

Timestep Collection Time: 2.25189
Timestep Consumption Time: 2.52075
PPO Batch Consumption Time: 0.29209
Total Iteration Time: 4.77264

Cumulative Model Updates: 256,490
Cumulative Timesteps: 2,139,704,814

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 145,636.65632
Policy Entropy: 2.69704
Value Function Loss: 0.01263

Mean KL Divergence: 0.00634
SB3 Clip Fraction: 0.05557
Policy Update Magnitude: 0.29981
Value Function Update Magnitude: 0.29456

Collected Steps per Second: 22,370.82556
Overall Steps per Second: 10,585.24083

Timestep Collection Time: 2.23675
Timestep Consumption Time: 2.49040
PPO Batch Consumption Time: 0.29217
Total Iteration Time: 4.72715

Cumulative Model Updates: 256,496
Cumulative Timesteps: 2,139,754,852

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 2139754852...
Checkpoint 2139754852 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 116,344.75155
Policy Entropy: 2.68737
Value Function Loss: 0.01439

Mean KL Divergence: 0.00705
SB3 Clip Fraction: 0.06313
Policy Update Magnitude: 0.30355
Value Function Update Magnitude: 0.31133

Collected Steps per Second: 22,071.62326
Overall Steps per Second: 10,517.89207

Timestep Collection Time: 2.26544
Timestep Consumption Time: 2.48855
PPO Batch Consumption Time: 0.28895
Total Iteration Time: 4.75399

Cumulative Model Updates: 256,502
Cumulative Timesteps: 2,139,804,854

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 116,344.75155
Policy Entropy: 2.68943
Value Function Loss: 0.01390

Mean KL Divergence: 0.00736
SB3 Clip Fraction: 0.06952
Policy Update Magnitude: 0.30567
Value Function Update Magnitude: 0.30544

Collected Steps per Second: 22,114.64614
Overall Steps per Second: 10,467.62408

Timestep Collection Time: 2.26104
Timestep Consumption Time: 2.51579
PPO Batch Consumption Time: 0.29312
Total Iteration Time: 4.77682

Cumulative Model Updates: 256,508
Cumulative Timesteps: 2,139,854,856

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2139854856...
Checkpoint 2139854856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 107,375.08668
Policy Entropy: 2.64835
Value Function Loss: 0.01314

Mean KL Divergence: 0.00639
SB3 Clip Fraction: 0.05971
Policy Update Magnitude: 0.30284
Value Function Update Magnitude: 0.29711

Collected Steps per Second: 21,469.70490
Overall Steps per Second: 10,510.56385

Timestep Collection Time: 2.33017
Timestep Consumption Time: 2.42962
PPO Batch Consumption Time: 0.27927
Total Iteration Time: 4.75978

Cumulative Model Updates: 256,514
Cumulative Timesteps: 2,139,904,884

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 101,912.77957
Policy Entropy: 2.64879
Value Function Loss: 0.01234

Mean KL Divergence: 0.00574
SB3 Clip Fraction: 0.05347
Policy Update Magnitude: 0.31708
Value Function Update Magnitude: 0.31925

Collected Steps per Second: 22,103.70769
Overall Steps per Second: 10,553.66737

Timestep Collection Time: 2.26224
Timestep Consumption Time: 2.47582
PPO Batch Consumption Time: 0.28651
Total Iteration Time: 4.73807

Cumulative Model Updates: 256,520
Cumulative Timesteps: 2,139,954,888

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2139954888...
Checkpoint 2139954888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 64,734.44747
Policy Entropy: 2.65854
Value Function Loss: 0.01197

Mean KL Divergence: 0.00618
SB3 Clip Fraction: 0.05389
Policy Update Magnitude: 0.31637
Value Function Update Magnitude: 0.35726

Collected Steps per Second: 21,645.55150
Overall Steps per Second: 10,572.49150

Timestep Collection Time: 2.31216
Timestep Consumption Time: 2.42163
PPO Batch Consumption Time: 0.27849
Total Iteration Time: 4.73379

Cumulative Model Updates: 256,526
Cumulative Timesteps: 2,140,004,936

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66,447.62725
Policy Entropy: 2.70780
Value Function Loss: 0.01062

Mean KL Divergence: 0.00665
SB3 Clip Fraction: 0.05295
Policy Update Magnitude: 0.30273
Value Function Update Magnitude: 0.33625

Collected Steps per Second: 21,655.22153
Overall Steps per Second: 10,560.55891

Timestep Collection Time: 2.30947
Timestep Consumption Time: 2.42627
PPO Batch Consumption Time: 0.27784
Total Iteration Time: 4.73573

Cumulative Model Updates: 256,532
Cumulative Timesteps: 2,140,054,948

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2140054948...
Checkpoint 2140054948 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 94,827.75257
Policy Entropy: 2.71656
Value Function Loss: 0.01078

Mean KL Divergence: 0.00573
SB3 Clip Fraction: 0.05209
Policy Update Magnitude: 0.28740
Value Function Update Magnitude: 0.29313

Collected Steps per Second: 21,643.33428
Overall Steps per Second: 10,542.32506

Timestep Collection Time: 2.31027
Timestep Consumption Time: 2.43270
PPO Batch Consumption Time: 0.27842
Total Iteration Time: 4.74298

Cumulative Model Updates: 256,538
Cumulative Timesteps: 2,140,104,950

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 110,911.74155
Policy Entropy: 2.72054
Value Function Loss: 0.01037

Mean KL Divergence: 0.00546
SB3 Clip Fraction: 0.04986
Policy Update Magnitude: 0.27659
Value Function Update Magnitude: 0.27286

Collected Steps per Second: 21,650.50233
Overall Steps per Second: 10,581.68280

Timestep Collection Time: 2.31154
Timestep Consumption Time: 2.41795
PPO Batch Consumption Time: 0.27657
Total Iteration Time: 4.72949

Cumulative Model Updates: 256,544
Cumulative Timesteps: 2,140,154,996

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 2140154996...
Checkpoint 2140154996 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 150,891.67006
Policy Entropy: 2.71554
Value Function Loss: 0.01087

Mean KL Divergence: 0.00648
SB3 Clip Fraction: 0.05974
Policy Update Magnitude: 0.27951
Value Function Update Magnitude: 0.31257

Collected Steps per Second: 21,761.06438
Overall Steps per Second: 10,516.20059

Timestep Collection Time: 2.29860
Timestep Consumption Time: 2.45787
PPO Batch Consumption Time: 0.27775
Total Iteration Time: 4.75647

Cumulative Model Updates: 256,550
Cumulative Timesteps: 2,140,205,016

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 105,938.27419
Policy Entropy: 2.71096
Value Function Loss: 0.01338

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.07647
Policy Update Magnitude: 0.30140
Value Function Update Magnitude: 0.34308

Collected Steps per Second: 22,025.77836
Overall Steps per Second: 10,488.80695

Timestep Collection Time: 2.27225
Timestep Consumption Time: 2.49932
PPO Batch Consumption Time: 0.28627
Total Iteration Time: 4.77156

Cumulative Model Updates: 256,556
Cumulative Timesteps: 2,140,255,064

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 2140255064...
Checkpoint 2140255064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 80,706.80816
Policy Entropy: 2.71256
Value Function Loss: 0.01294

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.07912
Policy Update Magnitude: 0.30395
Value Function Update Magnitude: 0.32264

Collected Steps per Second: 21,406.42800
Overall Steps per Second: 10,637.05542

Timestep Collection Time: 2.33668
Timestep Consumption Time: 2.36575
PPO Batch Consumption Time: 0.27908
Total Iteration Time: 4.70243

Cumulative Model Updates: 256,562
Cumulative Timesteps: 2,140,305,084

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97,033.35998
Policy Entropy: 2.68851
Value Function Loss: 0.01386

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.08107
Policy Update Magnitude: 0.30768
Value Function Update Magnitude: 0.29201

Collected Steps per Second: 21,458.59870
Overall Steps per Second: 10,522.98366

Timestep Collection Time: 2.33100
Timestep Consumption Time: 2.42240
PPO Batch Consumption Time: 0.29214
Total Iteration Time: 4.75340

Cumulative Model Updates: 256,568
Cumulative Timesteps: 2,140,355,104

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2140355104...
Checkpoint 2140355104 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87,351.24241
Policy Entropy: 2.69769
Value Function Loss: 0.01191

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.07555
Policy Update Magnitude: 0.30178
Value Function Update Magnitude: 0.25518

Collected Steps per Second: 21,544.47864
Overall Steps per Second: 10,592.64430

Timestep Collection Time: 2.32189
Timestep Consumption Time: 2.40063
PPO Batch Consumption Time: 0.28804
Total Iteration Time: 4.72252

Cumulative Model Updates: 256,574
Cumulative Timesteps: 2,140,405,128

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78,698.82320
Policy Entropy: 2.67343
Value Function Loss: 0.01311

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.07201
Policy Update Magnitude: 0.30054
Value Function Update Magnitude: 0.26461

Collected Steps per Second: 21,515.62395
Overall Steps per Second: 10,437.25647

Timestep Collection Time: 2.32417
Timestep Consumption Time: 2.46693
PPO Batch Consumption Time: 0.28926
Total Iteration Time: 4.79111

Cumulative Model Updates: 256,580
Cumulative Timesteps: 2,140,455,134

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2140455134...
Checkpoint 2140455134 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 75,452.00974
Policy Entropy: 2.69684
Value Function Loss: 0.01357

Mean KL Divergence: 0.00753
SB3 Clip Fraction: 0.06773
Policy Update Magnitude: 0.31568
Value Function Update Magnitude: 0.29148

Collected Steps per Second: 22,053.94689
Overall Steps per Second: 10,632.28009

Timestep Collection Time: 2.26771
Timestep Consumption Time: 2.43608
PPO Batch Consumption Time: 0.28477
Total Iteration Time: 4.70379

Cumulative Model Updates: 256,586
Cumulative Timesteps: 2,140,505,146

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88,155.19846
Policy Entropy: 2.71330
Value Function Loss: 0.01371

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.07338
Policy Update Magnitude: 0.31499
Value Function Update Magnitude: 0.31458

Collected Steps per Second: 21,458.46159
Overall Steps per Second: 10,455.24543

Timestep Collection Time: 2.33120
Timestep Consumption Time: 2.45338
PPO Batch Consumption Time: 0.28591
Total Iteration Time: 4.78458

Cumulative Model Updates: 256,592
Cumulative Timesteps: 2,140,555,170

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2140555170...
Checkpoint 2140555170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 103,968.12429
Policy Entropy: 2.72178
Value Function Loss: 0.01301

Mean KL Divergence: 0.00739
SB3 Clip Fraction: 0.06456
Policy Update Magnitude: 0.31023
Value Function Update Magnitude: 0.32880

Collected Steps per Second: 21,545.20657
Overall Steps per Second: 10,564.14691

Timestep Collection Time: 2.32098
Timestep Consumption Time: 2.41258
PPO Batch Consumption Time: 0.27769
Total Iteration Time: 4.73356

Cumulative Model Updates: 256,598
Cumulative Timesteps: 2,140,605,176

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88,474.55760
Policy Entropy: 2.70644
Value Function Loss: 0.01167

Mean KL Divergence: 0.00757
SB3 Clip Fraction: 0.06698
Policy Update Magnitude: 0.30692
Value Function Update Magnitude: 0.32694

Collected Steps per Second: 21,632.69367
Overall Steps per Second: 10,546.77166

Timestep Collection Time: 2.31252
Timestep Consumption Time: 2.43073
PPO Batch Consumption Time: 0.27819
Total Iteration Time: 4.74325

Cumulative Model Updates: 256,604
Cumulative Timesteps: 2,140,655,202

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2140655202...
Checkpoint 2140655202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 90,712.89667
Policy Entropy: 2.69237
Value Function Loss: 0.01193

Mean KL Divergence: 0.00736
SB3 Clip Fraction: 0.06611
Policy Update Magnitude: 0.30078
Value Function Update Magnitude: 0.28507

Collected Steps per Second: 21,759.19692
Overall Steps per Second: 10,532.52164

Timestep Collection Time: 2.29834
Timestep Consumption Time: 2.44981
PPO Batch Consumption Time: 0.27813
Total Iteration Time: 4.74815

Cumulative Model Updates: 256,610
Cumulative Timesteps: 2,140,705,212

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56,849.19545
Policy Entropy: 2.70339
Value Function Loss: 0.01186

Mean KL Divergence: 0.00732
SB3 Clip Fraction: 0.06423
Policy Update Magnitude: 0.30614
Value Function Update Magnitude: 0.23547

Collected Steps per Second: 21,444.94758
Overall Steps per Second: 10,443.86881

Timestep Collection Time: 2.33183
Timestep Consumption Time: 2.45624
PPO Batch Consumption Time: 0.27805
Total Iteration Time: 4.78807

Cumulative Model Updates: 256,616
Cumulative Timesteps: 2,140,755,218

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2140755218...
Checkpoint 2140755218 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 80,510.11502
Policy Entropy: 2.71460
Value Function Loss: 0.01536

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.06534
Policy Update Magnitude: 0.32900
Value Function Update Magnitude: 0.28574

Collected Steps per Second: 22,064.46314
Overall Steps per Second: 10,657.57975

Timestep Collection Time: 2.26627
Timestep Consumption Time: 2.42560
PPO Batch Consumption Time: 0.27865
Total Iteration Time: 4.69187

Cumulative Model Updates: 256,622
Cumulative Timesteps: 2,140,805,222

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99,576.79374
Policy Entropy: 2.72239
Value Function Loss: 0.01653

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.08005
Policy Update Magnitude: 0.32943
Value Function Update Magnitude: 0.28447

Collected Steps per Second: 22,024.98899
Overall Steps per Second: 10,430.37424

Timestep Collection Time: 2.27024
Timestep Consumption Time: 2.52364
PPO Batch Consumption Time: 0.28864
Total Iteration Time: 4.79388

Cumulative Model Updates: 256,628
Cumulative Timesteps: 2,140,855,224

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2140855224...
Checkpoint 2140855224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 73,747.19773
Policy Entropy: 2.72376
Value Function Loss: 0.01557

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.08458
Policy Update Magnitude: 0.31455
Value Function Update Magnitude: 0.32541

Collected Steps per Second: 21,859.17317
Overall Steps per Second: 10,439.57607

Timestep Collection Time: 2.28957
Timestep Consumption Time: 2.50450
PPO Batch Consumption Time: 0.29158
Total Iteration Time: 4.79406

Cumulative Model Updates: 256,634
Cumulative Timesteps: 2,140,905,272

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79,658.58913
Policy Entropy: 2.72944
Value Function Loss: 0.01339

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.08384
Policy Update Magnitude: 0.29670
Value Function Update Magnitude: 0.32373

Collected Steps per Second: 21,794.04035
Overall Steps per Second: 10,463.95760

Timestep Collection Time: 2.29613
Timestep Consumption Time: 2.48619
PPO Batch Consumption Time: 0.29020
Total Iteration Time: 4.78232

Cumulative Model Updates: 256,640
Cumulative Timesteps: 2,140,955,314

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 2140955314...
Checkpoint 2140955314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 74,756.03546
Policy Entropy: 2.73112
Value Function Loss: 0.01312

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.07485
Policy Update Magnitude: 0.30899
Value Function Update Magnitude: 0.29446

Collected Steps per Second: 21,905.17507
Overall Steps per Second: 10,450.30359

Timestep Collection Time: 2.28457
Timestep Consumption Time: 2.50419
PPO Batch Consumption Time: 0.29188
Total Iteration Time: 4.78876

Cumulative Model Updates: 256,646
Cumulative Timesteps: 2,141,005,358

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59,638.53936
Policy Entropy: 2.72792
Value Function Loss: 0.01193

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.07901
Policy Update Magnitude: 0.30257
Value Function Update Magnitude: 0.25480

Collected Steps per Second: 21,624.73932
Overall Steps per Second: 10,450.07314

Timestep Collection Time: 2.31355
Timestep Consumption Time: 2.47397
PPO Batch Consumption Time: 0.27879
Total Iteration Time: 4.78753

Cumulative Model Updates: 256,652
Cumulative Timesteps: 2,141,055,388

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2141055388...
Checkpoint 2141055388 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 83,335.11264
Policy Entropy: 2.71271
Value Function Loss: 0.01406

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.06341
Policy Update Magnitude: 0.30593
Value Function Update Magnitude: 0.25190

Collected Steps per Second: 21,353.81915
Overall Steps per Second: 10,345.79527

Timestep Collection Time: 2.34178
Timestep Consumption Time: 2.49168
PPO Batch Consumption Time: 0.29225
Total Iteration Time: 4.83346

Cumulative Model Updates: 256,658
Cumulative Timesteps: 2,141,105,394

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87,807.26089
Policy Entropy: 2.70514
Value Function Loss: 0.01551

Mean KL Divergence: 0.00745
SB3 Clip Fraction: 0.06998
Policy Update Magnitude: 0.33603
Value Function Update Magnitude: 0.28980

Collected Steps per Second: 20,933.58131
Overall Steps per Second: 10,382.54094

Timestep Collection Time: 2.38937
Timestep Consumption Time: 2.42814
PPO Batch Consumption Time: 0.29333
Total Iteration Time: 4.81751

Cumulative Model Updates: 256,664
Cumulative Timesteps: 2,141,155,412

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2141155412...
Checkpoint 2141155412 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47,756.95817
Policy Entropy: 2.68905
Value Function Loss: 0.01624

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.07657
Policy Update Magnitude: 0.32937
Value Function Update Magnitude: 0.34828

Collected Steps per Second: 20,700.60900
Overall Steps per Second: 10,318.60679

Timestep Collection Time: 2.41616
Timestep Consumption Time: 2.43101
PPO Batch Consumption Time: 0.29023
Total Iteration Time: 4.84717

Cumulative Model Updates: 256,670
Cumulative Timesteps: 2,141,205,428

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,377.92706
Policy Entropy: 2.69182
Value Function Loss: 0.01483

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.06835
Policy Update Magnitude: 0.31766
Value Function Update Magnitude: 0.37251

Collected Steps per Second: 21,572.75873
Overall Steps per Second: 10,647.93899

Timestep Collection Time: 2.31894
Timestep Consumption Time: 2.37924
PPO Batch Consumption Time: 0.27873
Total Iteration Time: 4.69819

Cumulative Model Updates: 256,676
Cumulative Timesteps: 2,141,255,454

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2141255454...
Checkpoint 2141255454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 63,184.37748
Policy Entropy: 2.70952
Value Function Loss: 0.01346

Mean KL Divergence: 0.00692
SB3 Clip Fraction: 0.06557
Policy Update Magnitude: 0.31108
Value Function Update Magnitude: 0.35566

Collected Steps per Second: 21,126.11573
Overall Steps per Second: 10,269.71955

Timestep Collection Time: 2.36769
Timestep Consumption Time: 2.50294
PPO Batch Consumption Time: 0.29240
Total Iteration Time: 4.87063

Cumulative Model Updates: 256,682
Cumulative Timesteps: 2,141,305,474

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61,262.99536
Policy Entropy: 2.71752
Value Function Loss: 0.01227

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.07375
Policy Update Magnitude: 0.30027
Value Function Update Magnitude: 0.32777

Collected Steps per Second: 22,290.05869
Overall Steps per Second: 10,630.12733

Timestep Collection Time: 2.24432
Timestep Consumption Time: 2.46174
PPO Batch Consumption Time: 0.29063
Total Iteration Time: 4.70606

Cumulative Model Updates: 256,688
Cumulative Timesteps: 2,141,355,500

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2141355500...
Checkpoint 2141355500 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 52,614.61998
Policy Entropy: 2.72238
Value Function Loss: 0.01174

Mean KL Divergence: 0.01141
SB3 Clip Fraction: 0.09690
Policy Update Magnitude: 0.30724
Value Function Update Magnitude: 0.28626

Collected Steps per Second: 22,013.75166
Overall Steps per Second: 10,524.40996

Timestep Collection Time: 2.27194
Timestep Consumption Time: 2.48025
PPO Batch Consumption Time: 0.29410
Total Iteration Time: 4.75219

Cumulative Model Updates: 256,694
Cumulative Timesteps: 2,141,405,514

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 104,682.15041
Policy Entropy: 2.73369
Value Function Loss: 0.01248

Mean KL Divergence: 0.01522
SB3 Clip Fraction: 0.10646
Policy Update Magnitude: 0.29700
Value Function Update Magnitude: 0.25581

Collected Steps per Second: 22,151.28102
Overall Steps per Second: 10,466.46129

Timestep Collection Time: 2.25721
Timestep Consumption Time: 2.51996
PPO Batch Consumption Time: 0.29380
Total Iteration Time: 4.77716

Cumulative Model Updates: 256,700
Cumulative Timesteps: 2,141,455,514

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2141455514...
Checkpoint 2141455514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 79,216.72154
Policy Entropy: 2.72260
Value Function Loss: 0.01612

Mean KL Divergence: 0.01651
SB3 Clip Fraction: 0.11609
Policy Update Magnitude: 0.30293
Value Function Update Magnitude: 0.30761

Collected Steps per Second: 21,662.24339
Overall Steps per Second: 10,542.69511

Timestep Collection Time: 2.30983
Timestep Consumption Time: 2.43621
PPO Batch Consumption Time: 0.27902
Total Iteration Time: 4.74604

Cumulative Model Updates: 256,706
Cumulative Timesteps: 2,141,505,550

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67,783.03816
Policy Entropy: 2.71965
Value Function Loss: 0.01655

Mean KL Divergence: 0.01414
SB3 Clip Fraction: 0.11133
Policy Update Magnitude: 0.31212
Value Function Update Magnitude: 0.37407

Collected Steps per Second: 21,998.59655
Overall Steps per Second: 10,513.95914

Timestep Collection Time: 2.27369
Timestep Consumption Time: 2.48360
PPO Batch Consumption Time: 0.29033
Total Iteration Time: 4.75729

Cumulative Model Updates: 256,712
Cumulative Timesteps: 2,141,555,568

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2141555568...
Checkpoint 2141555568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55,137.40417
Policy Entropy: 2.71266
Value Function Loss: 0.01657

Mean KL Divergence: 0.01347
SB3 Clip Fraction: 0.10688
Policy Update Magnitude: 0.33525
Value Function Update Magnitude: 0.41458

Collected Steps per Second: 21,340.90544
Overall Steps per Second: 10,361.71100

Timestep Collection Time: 2.34404
Timestep Consumption Time: 2.48373
PPO Batch Consumption Time: 0.29100
Total Iteration Time: 4.82777

Cumulative Model Updates: 256,718
Cumulative Timesteps: 2,141,605,592

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55,137.40417
Policy Entropy: 2.71706
Value Function Loss: 0.01233

Mean KL Divergence: 0.01331
SB3 Clip Fraction: 0.09531
Policy Update Magnitude: 0.32021
Value Function Update Magnitude: 0.41250

Collected Steps per Second: 21,801.11582
Overall Steps per Second: 10,448.73009

Timestep Collection Time: 2.29419
Timestep Consumption Time: 2.49261
PPO Batch Consumption Time: 0.29011
Total Iteration Time: 4.78680

Cumulative Model Updates: 256,724
Cumulative Timesteps: 2,141,655,608

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2141655608...
Checkpoint 2141655608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 63,713.09432
Policy Entropy: 2.75034
Value Function Loss: 0.01127

Mean KL Divergence: 0.01602
SB3 Clip Fraction: 0.08680
Policy Update Magnitude: 0.29834
Value Function Update Magnitude: 0.35764

Collected Steps per Second: 21,349.83190
Overall Steps per Second: 10,462.11348

Timestep Collection Time: 2.34325
Timestep Consumption Time: 2.43858
PPO Batch Consumption Time: 0.27926
Total Iteration Time: 4.78183

Cumulative Model Updates: 256,730
Cumulative Timesteps: 2,141,705,636

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63,713.09432
Policy Entropy: 2.73718
Value Function Loss: 0.01034

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.08193
Policy Update Magnitude: 0.28788
Value Function Update Magnitude: 0.29581

Collected Steps per Second: 21,831.71132
Overall Steps per Second: 10,447.52335

Timestep Collection Time: 2.29043
Timestep Consumption Time: 2.49578
PPO Batch Consumption Time: 0.28729
Total Iteration Time: 4.78621

Cumulative Model Updates: 256,736
Cumulative Timesteps: 2,141,755,640

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2141755640...
Checkpoint 2141755640 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 51,995.23260
Policy Entropy: 2.72611
Value Function Loss: 0.01144

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.07819
Policy Update Magnitude: 0.28866
Value Function Update Magnitude: 0.24961

Collected Steps per Second: 21,096.29108
Overall Steps per Second: 10,254.56455

Timestep Collection Time: 2.37132
Timestep Consumption Time: 2.50710
PPO Batch Consumption Time: 0.29346
Total Iteration Time: 4.87841

Cumulative Model Updates: 256,742
Cumulative Timesteps: 2,141,805,666

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51,872.46630
Policy Entropy: 2.71732
Value Function Loss: 0.01091

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.08179
Policy Update Magnitude: 0.28849
Value Function Update Magnitude: 0.28867

Collected Steps per Second: 22,410.38825
Overall Steps per Second: 10,489.73370

Timestep Collection Time: 2.23120
Timestep Consumption Time: 2.53556
PPO Batch Consumption Time: 0.29286
Total Iteration Time: 4.76676

Cumulative Model Updates: 256,748
Cumulative Timesteps: 2,141,855,668

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2141855668...
Checkpoint 2141855668 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 65,693.44731
Policy Entropy: 2.71837
Value Function Loss: 0.01092

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.08281
Policy Update Magnitude: 0.28872
Value Function Update Magnitude: 0.33047

Collected Steps per Second: 21,159.73327
Overall Steps per Second: 10,605.35509

Timestep Collection Time: 2.36373
Timestep Consumption Time: 2.35237
PPO Batch Consumption Time: 0.27743
Total Iteration Time: 4.71611

Cumulative Model Updates: 256,754
Cumulative Timesteps: 2,141,905,684

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70,305.31989
Policy Entropy: 2.72781
Value Function Loss: 0.01153

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.07610
Policy Update Magnitude: 0.29750
Value Function Update Magnitude: 0.33492

Collected Steps per Second: 21,716.50852
Overall Steps per Second: 10,596.08415

Timestep Collection Time: 2.30442
Timestep Consumption Time: 2.41845
PPO Batch Consumption Time: 0.28907
Total Iteration Time: 4.72288

Cumulative Model Updates: 256,760
Cumulative Timesteps: 2,141,955,728

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 2141955728...
Checkpoint 2141955728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 97,301.37355
Policy Entropy: 2.70694
Value Function Loss: 0.01401

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.07532
Policy Update Magnitude: 0.30156
Value Function Update Magnitude: 0.35139

Collected Steps per Second: 21,363.51738
Overall Steps per Second: 10,483.73695

Timestep Collection Time: 2.34222
Timestep Consumption Time: 2.43070
PPO Batch Consumption Time: 0.29316
Total Iteration Time: 4.77292

Cumulative Model Updates: 256,766
Cumulative Timesteps: 2,142,005,766

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 132,601.73713
Policy Entropy: 2.72542
Value Function Loss: 0.01299

Mean KL Divergence: 0.00748
SB3 Clip Fraction: 0.06915
Policy Update Magnitude: 0.29915
Value Function Update Magnitude: 0.34765

Collected Steps per Second: 21,667.17610
Overall Steps per Second: 10,415.32119

Timestep Collection Time: 2.30847
Timestep Consumption Time: 2.49388
PPO Batch Consumption Time: 0.29280
Total Iteration Time: 4.80235

Cumulative Model Updates: 256,772
Cumulative Timesteps: 2,142,055,784

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2142055784...
Checkpoint 2142055784 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 130,674.19658
Policy Entropy: 2.70809
Value Function Loss: 0.01383

Mean KL Divergence: 0.00721
SB3 Clip Fraction: 0.06661
Policy Update Magnitude: 0.30554
Value Function Update Magnitude: 0.34175

Collected Steps per Second: 21,419.93492
Overall Steps per Second: 10,382.34647

Timestep Collection Time: 2.33502
Timestep Consumption Time: 2.48239
PPO Batch Consumption Time: 0.29000
Total Iteration Time: 4.81741

Cumulative Model Updates: 256,778
Cumulative Timesteps: 2,142,105,800

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 152,964.24307
Policy Entropy: 2.71889
Value Function Loss: 0.01250

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.06760
Policy Update Magnitude: 0.30668
Value Function Update Magnitude: 0.34148

Collected Steps per Second: 22,312.72441
Overall Steps per Second: 10,805.83564

Timestep Collection Time: 2.24159
Timestep Consumption Time: 2.38702
PPO Batch Consumption Time: 0.27629
Total Iteration Time: 4.62861

Cumulative Model Updates: 256,784
Cumulative Timesteps: 2,142,155,816

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2142155816...
Checkpoint 2142155816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 123,539.40113
Policy Entropy: 2.70572
Value Function Loss: 0.01293

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.07375
Policy Update Magnitude: 0.31195
Value Function Update Magnitude: 0.34692

Collected Steps per Second: 21,563.67957
Overall Steps per Second: 10,613.72922

Timestep Collection Time: 2.32094
Timestep Consumption Time: 2.39446
PPO Batch Consumption Time: 0.27696
Total Iteration Time: 4.71540

Cumulative Model Updates: 256,790
Cumulative Timesteps: 2,142,205,864

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 112,559.87861
Policy Entropy: 2.72875
Value Function Loss: 0.01359

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.07110
Policy Update Magnitude: 0.31087
Value Function Update Magnitude: 0.32634

Collected Steps per Second: 21,946.88389
Overall Steps per Second: 10,452.25995

Timestep Collection Time: 2.27868
Timestep Consumption Time: 2.50593
PPO Batch Consumption Time: 0.29293
Total Iteration Time: 4.78461

Cumulative Model Updates: 256,796
Cumulative Timesteps: 2,142,255,874

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2142255874...
Checkpoint 2142255874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 81,938.21574
Policy Entropy: 2.71186
Value Function Loss: 0.01398

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.08148
Policy Update Magnitude: 0.31133
Value Function Update Magnitude: 0.36076

Collected Steps per Second: 21,489.75406
Overall Steps per Second: 10,514.13308

Timestep Collection Time: 2.32753
Timestep Consumption Time: 2.42969
PPO Batch Consumption Time: 0.27869
Total Iteration Time: 4.75722

Cumulative Model Updates: 256,802
Cumulative Timesteps: 2,142,305,892

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88,929.97394
Policy Entropy: 2.70693
Value Function Loss: 0.01501

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.07239
Policy Update Magnitude: 0.31881
Value Function Update Magnitude: 0.36908

Collected Steps per Second: 21,586.05088
Overall Steps per Second: 10,527.57827

Timestep Collection Time: 2.31742
Timestep Consumption Time: 2.43429
PPO Batch Consumption Time: 0.27877
Total Iteration Time: 4.75171

Cumulative Model Updates: 256,808
Cumulative Timesteps: 2,142,355,916

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2142355916...
Checkpoint 2142355916 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 116,387.45601
Policy Entropy: 2.71966
Value Function Loss: 0.01354

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.06952
Policy Update Magnitude: 0.31324
Value Function Update Magnitude: 0.36101

Collected Steps per Second: 21,516.68490
Overall Steps per Second: 10,338.52177

Timestep Collection Time: 2.32406
Timestep Consumption Time: 2.51280
PPO Batch Consumption Time: 0.29276
Total Iteration Time: 4.83686

Cumulative Model Updates: 256,814
Cumulative Timesteps: 2,142,405,922

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95,950.95525
Policy Entropy: 2.71945
Value Function Loss: 0.01294

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.06198
Policy Update Magnitude: 0.30167
Value Function Update Magnitude: 0.33223

Collected Steps per Second: 22,641.21662
Overall Steps per Second: 10,689.68381

Timestep Collection Time: 2.20889
Timestep Consumption Time: 2.46964
PPO Batch Consumption Time: 0.27968
Total Iteration Time: 4.67853

Cumulative Model Updates: 256,820
Cumulative Timesteps: 2,142,455,934

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2142455934...
Checkpoint 2142455934 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 80,229.19425
Policy Entropy: 2.72257
Value Function Loss: 0.01357

Mean KL Divergence: 0.00659
SB3 Clip Fraction: 0.06198
Policy Update Magnitude: 0.30928
Value Function Update Magnitude: 0.31237

Collected Steps per Second: 21,526.21807
Overall Steps per Second: 10,327.80214

Timestep Collection Time: 2.32433
Timestep Consumption Time: 2.52026
PPO Batch Consumption Time: 0.29293
Total Iteration Time: 4.84459

Cumulative Model Updates: 256,826
Cumulative Timesteps: 2,142,505,968

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70,639.99632
Policy Entropy: 2.71267
Value Function Loss: 0.01388

Mean KL Divergence: 0.00758
SB3 Clip Fraction: 0.06166
Policy Update Magnitude: 0.31785
Value Function Update Magnitude: 0.33609

Collected Steps per Second: 22,368.62090
Overall Steps per Second: 10,577.27081

Timestep Collection Time: 2.23653
Timestep Consumption Time: 2.49324
PPO Batch Consumption Time: 0.29083
Total Iteration Time: 4.72976

Cumulative Model Updates: 256,832
Cumulative Timesteps: 2,142,555,996

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2142555996...
Checkpoint 2142555996 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 61,187.79692
Policy Entropy: 2.72357
Value Function Loss: 0.01319

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.05962
Policy Update Magnitude: 0.31787
Value Function Update Magnitude: 0.32738

Collected Steps per Second: 22,122.65015
Overall Steps per Second: 10,455.39844

Timestep Collection Time: 2.26103
Timestep Consumption Time: 2.52310
PPO Batch Consumption Time: 0.29477
Total Iteration Time: 4.78413

Cumulative Model Updates: 256,838
Cumulative Timesteps: 2,142,606,016

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83,770.05420
Policy Entropy: 2.72311
Value Function Loss: 0.01199

Mean KL Divergence: 0.00741
SB3 Clip Fraction: 0.06314
Policy Update Magnitude: 0.30932
Value Function Update Magnitude: 0.31316

Collected Steps per Second: 22,321.37379
Overall Steps per Second: 10,518.72115

Timestep Collection Time: 2.24108
Timestep Consumption Time: 2.51463
PPO Batch Consumption Time: 0.29338
Total Iteration Time: 4.75571

Cumulative Model Updates: 256,844
Cumulative Timesteps: 2,142,656,040

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2142656040...
Checkpoint 2142656040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 83,770.05420
Policy Entropy: 2.73061
Value Function Loss: 0.01009

Mean KL Divergence: 0.00766
SB3 Clip Fraction: 0.06773
Policy Update Magnitude: 0.28626
Value Function Update Magnitude: 0.26648

Collected Steps per Second: 21,988.46396
Overall Steps per Second: 10,630.25465

Timestep Collection Time: 2.27610
Timestep Consumption Time: 2.43197
PPO Batch Consumption Time: 0.27789
Total Iteration Time: 4.70807

Cumulative Model Updates: 256,850
Cumulative Timesteps: 2,142,706,088

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 100,313.32446
Policy Entropy: 2.72644
Value Function Loss: 0.01092

Mean KL Divergence: 0.00598
SB3 Clip Fraction: 0.05617
Policy Update Magnitude: 0.28943
Value Function Update Magnitude: 0.24061

Collected Steps per Second: 21,965.74873
Overall Steps per Second: 10,472.66008

Timestep Collection Time: 2.27691
Timestep Consumption Time: 2.49876
PPO Batch Consumption Time: 0.29332
Total Iteration Time: 4.77567

Cumulative Model Updates: 256,856
Cumulative Timesteps: 2,142,756,102

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2142756102...
Checkpoint 2142756102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 78,413.70762
Policy Entropy: 2.70820
Value Function Loss: 0.01236

Mean KL Divergence: 0.00638
SB3 Clip Fraction: 0.05801
Policy Update Magnitude: 0.30100
Value Function Update Magnitude: 0.24384

Collected Steps per Second: 21,377.19659
Overall Steps per Second: 10,506.92388

Timestep Collection Time: 2.33922
Timestep Consumption Time: 2.42012
PPO Batch Consumption Time: 0.27823
Total Iteration Time: 4.75934

Cumulative Model Updates: 256,862
Cumulative Timesteps: 2,142,806,108

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 74,640.27090
Policy Entropy: 2.69814
Value Function Loss: 0.01401

Mean KL Divergence: 0.00690
SB3 Clip Fraction: 0.06112
Policy Update Magnitude: 0.30752
Value Function Update Magnitude: 0.22081

Collected Steps per Second: 21,762.51202
Overall Steps per Second: 10,604.99207

Timestep Collection Time: 2.29863
Timestep Consumption Time: 2.41839
PPO Batch Consumption Time: 0.27728
Total Iteration Time: 4.71702

Cumulative Model Updates: 256,868
Cumulative Timesteps: 2,142,856,132

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2142856132...
Checkpoint 2142856132 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 105,260.23223
Policy Entropy: 2.70978
Value Function Loss: 0.01439

Mean KL Divergence: 0.00686
SB3 Clip Fraction: 0.06132
Policy Update Magnitude: 0.30904
Value Function Update Magnitude: 0.21564

Collected Steps per Second: 21,506.58174
Overall Steps per Second: 10,453.45349

Timestep Collection Time: 2.32645
Timestep Consumption Time: 2.45991
PPO Batch Consumption Time: 0.27892
Total Iteration Time: 4.78636

Cumulative Model Updates: 256,874
Cumulative Timesteps: 2,142,906,166

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 105,938.82775
Policy Entropy: 2.73577
Value Function Loss: 0.01372

Mean KL Divergence: 0.00669
SB3 Clip Fraction: 0.06270
Policy Update Magnitude: 0.30513
Value Function Update Magnitude: 0.20630

Collected Steps per Second: 20,763.87183
Overall Steps per Second: 10,148.47159

Timestep Collection Time: 2.41015
Timestep Consumption Time: 2.52104
PPO Batch Consumption Time: 0.29299
Total Iteration Time: 4.93119

Cumulative Model Updates: 256,880
Cumulative Timesteps: 2,142,956,210

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 2142956210...
Checkpoint 2142956210 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 90,497.86853
Policy Entropy: 2.73430
Value Function Loss: 0.01313

Mean KL Divergence: 0.00687
SB3 Clip Fraction: 0.06422
Policy Update Magnitude: 0.30350
Value Function Update Magnitude: 0.21776

Collected Steps per Second: 21,206.75925
Overall Steps per Second: 10,282.39390

Timestep Collection Time: 2.35830
Timestep Consumption Time: 2.50554
PPO Batch Consumption Time: 0.29404
Total Iteration Time: 4.86385

Cumulative Model Updates: 256,886
Cumulative Timesteps: 2,143,006,222

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 106,783.46443
Policy Entropy: 2.72524
Value Function Loss: 0.01211

Mean KL Divergence: 0.00653
SB3 Clip Fraction: 0.06254
Policy Update Magnitude: 0.29862
Value Function Update Magnitude: 0.24040

Collected Steps per Second: 21,591.43179
Overall Steps per Second: 10,326.92420

Timestep Collection Time: 2.31601
Timestep Consumption Time: 2.52628
PPO Batch Consumption Time: 0.29210
Total Iteration Time: 4.84229

Cumulative Model Updates: 256,892
Cumulative Timesteps: 2,143,056,228

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2143056228...
Checkpoint 2143056228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 78,269.10613
Policy Entropy: 2.70913
Value Function Loss: 0.01251

Mean KL Divergence: 0.00612
SB3 Clip Fraction: 0.05675
Policy Update Magnitude: 0.30438
Value Function Update Magnitude: 0.24430

Collected Steps per Second: 21,857.49737
Overall Steps per Second: 10,603.76170

Timestep Collection Time: 2.28773
Timestep Consumption Time: 2.42796
PPO Batch Consumption Time: 0.27831
Total Iteration Time: 4.71568

Cumulative Model Updates: 256,898
Cumulative Timesteps: 2,143,106,232

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68,816.44905
Policy Entropy: 2.70467
Value Function Loss: 0.01455

Mean KL Divergence: 0.00708
SB3 Clip Fraction: 0.06492
Policy Update Magnitude: 0.29643
Value Function Update Magnitude: 0.21819

Collected Steps per Second: 22,112.65245
Overall Steps per Second: 10,585.69667

Timestep Collection Time: 2.26251
Timestep Consumption Time: 2.46368
PPO Batch Consumption Time: 0.27687
Total Iteration Time: 4.72619

Cumulative Model Updates: 256,904
Cumulative Timesteps: 2,143,156,262

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2143156262...
Checkpoint 2143156262 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 58,802.84324
Policy Entropy: 2.71819
Value Function Loss: 0.01445

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.06221
Policy Update Magnitude: 0.29399
Value Function Update Magnitude: 0.24586

Collected Steps per Second: 22,014.79006
Overall Steps per Second: 10,637.16264

Timestep Collection Time: 2.27120
Timestep Consumption Time: 2.42930
PPO Batch Consumption Time: 0.27708
Total Iteration Time: 4.70050

Cumulative Model Updates: 256,910
Cumulative Timesteps: 2,143,206,262

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55,339.89175
Policy Entropy: 2.73554
Value Function Loss: 0.01370

Mean KL Divergence: 0.00726
SB3 Clip Fraction: 0.06871
Policy Update Magnitude: 0.29672
Value Function Update Magnitude: 0.28926

Collected Steps per Second: 22,172.90968
Overall Steps per Second: 10,544.02413

Timestep Collection Time: 2.25564
Timestep Consumption Time: 2.48771
PPO Batch Consumption Time: 0.29057
Total Iteration Time: 4.74335

Cumulative Model Updates: 256,916
Cumulative Timesteps: 2,143,256,276

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2143256276...
Checkpoint 2143256276 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55,706.78428
Policy Entropy: 2.73080
Value Function Loss: 0.01306

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.07990
Policy Update Magnitude: 0.29384
Value Function Update Magnitude: 0.32004

Collected Steps per Second: 22,193.88147
Overall Steps per Second: 10,528.13019

Timestep Collection Time: 2.25368
Timestep Consumption Time: 2.49721
PPO Batch Consumption Time: 0.29259
Total Iteration Time: 4.75089

Cumulative Model Updates: 256,922
Cumulative Timesteps: 2,143,306,294

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66,132.16498
Policy Entropy: 2.71255
Value Function Loss: 0.01278

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.08794
Policy Update Magnitude: 0.29528
Value Function Update Magnitude: 0.31117

Collected Steps per Second: 21,983.16514
Overall Steps per Second: 10,467.67484

Timestep Collection Time: 2.27465
Timestep Consumption Time: 2.50234
PPO Batch Consumption Time: 0.29254
Total Iteration Time: 4.77699

Cumulative Model Updates: 256,928
Cumulative Timesteps: 2,143,356,298

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2143356298...
Checkpoint 2143356298 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 57,548.26602
Policy Entropy: 2.69483
Value Function Loss: 0.01226

Mean KL Divergence: 0.01085
SB3 Clip Fraction: 0.09354
Policy Update Magnitude: 0.29371
Value Function Update Magnitude: 0.29571

Collected Steps per Second: 22,224.27073
Overall Steps per Second: 10,608.55184

Timestep Collection Time: 2.25096
Timestep Consumption Time: 2.46467
PPO Batch Consumption Time: 0.28752
Total Iteration Time: 4.71563

Cumulative Model Updates: 256,934
Cumulative Timesteps: 2,143,406,324

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67,997.41476
Policy Entropy: 2.68647
Value Function Loss: 0.01507

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.07986
Policy Update Magnitude: 0.31062
Value Function Update Magnitude: 0.30439

Collected Steps per Second: 20,867.33208
Overall Steps per Second: 10,394.73447

Timestep Collection Time: 2.39647
Timestep Consumption Time: 2.41442
PPO Batch Consumption Time: 0.28678
Total Iteration Time: 4.81090

Cumulative Model Updates: 256,940
Cumulative Timesteps: 2,143,456,332

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2143456332...
Checkpoint 2143456332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 62,038.99714
Policy Entropy: 2.66573
Value Function Loss: 0.01492

Mean KL Divergence: 0.01098
SB3 Clip Fraction: 0.09541
Policy Update Magnitude: 0.32313
Value Function Update Magnitude: 0.33700

Collected Steps per Second: 20,848.90458
Overall Steps per Second: 10,406.26473

Timestep Collection Time: 2.39945
Timestep Consumption Time: 2.40784
PPO Batch Consumption Time: 0.29035
Total Iteration Time: 4.80730

Cumulative Model Updates: 256,946
Cumulative Timesteps: 2,143,506,358

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52,459.23574
Policy Entropy: 2.68556
Value Function Loss: 0.01427

Mean KL Divergence: 0.01329
SB3 Clip Fraction: 0.10995
Policy Update Magnitude: 0.31807
Value Function Update Magnitude: 0.34475

Collected Steps per Second: 21,128.09649
Overall Steps per Second: 10,441.37833

Timestep Collection Time: 2.36898
Timestep Consumption Time: 2.42464
PPO Batch Consumption Time: 0.29140
Total Iteration Time: 4.79362

Cumulative Model Updates: 256,952
Cumulative Timesteps: 2,143,556,410

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


Saving checkpoint 2143556410...
Checkpoint 2143556410 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 82,424.10302
Policy Entropy: 2.70275
Value Function Loss: 0.01220

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.09002
Policy Update Magnitude: 0.30955
Value Function Update Magnitude: 0.35593

Collected Steps per Second: 21,202.07458
Overall Steps per Second: 10,491.42141

Timestep Collection Time: 2.36015
Timestep Consumption Time: 2.40946
PPO Batch Consumption Time: 0.27878
Total Iteration Time: 4.76961

Cumulative Model Updates: 256,958
Cumulative Timesteps: 2,143,606,450

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 73,870.78847
Policy Entropy: 2.71827
Value Function Loss: 0.01034

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.08006
Policy Update Magnitude: 0.29971
Value Function Update Magnitude: 0.36624

Collected Steps per Second: 22,167.66022
Overall Steps per Second: 10,457.41967

Timestep Collection Time: 2.25554
Timestep Consumption Time: 2.52576
PPO Batch Consumption Time: 0.29157
Total Iteration Time: 4.78129

Cumulative Model Updates: 256,964
Cumulative Timesteps: 2,143,656,450

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2143656450...
Checkpoint 2143656450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 56,414.99373
Policy Entropy: 2.72277
Value Function Loss: 0.01066

Mean KL Divergence: 0.01209
SB3 Clip Fraction: 0.10716
Policy Update Magnitude: 0.28027
Value Function Update Magnitude: 0.33173

Collected Steps per Second: 21,913.71542
Overall Steps per Second: 10,627.40904

Timestep Collection Time: 2.28186
Timestep Consumption Time: 2.42333
PPO Batch Consumption Time: 0.27921
Total Iteration Time: 4.70519

Cumulative Model Updates: 256,970
Cumulative Timesteps: 2,143,706,454

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62,987.53552
Policy Entropy: 2.75178
Value Function Loss: 0.01080

Mean KL Divergence: 0.01178
SB3 Clip Fraction: 0.10291
Policy Update Magnitude: 0.27116
Value Function Update Magnitude: 0.29360

Collected Steps per Second: 22,111.59210
Overall Steps per Second: 10,487.60710

Timestep Collection Time: 2.26352
Timestep Consumption Time: 2.50878
PPO Batch Consumption Time: 0.29249
Total Iteration Time: 4.77230

Cumulative Model Updates: 256,976
Cumulative Timesteps: 2,143,756,504

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 2143756504...
Checkpoint 2143756504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 53,345.91502
Policy Entropy: 2.75327
Value Function Loss: 0.01248

Mean KL Divergence: 0.01182
SB3 Clip Fraction: 0.10330
Policy Update Magnitude: 0.27813
Value Function Update Magnitude: 0.34296

Collected Steps per Second: 22,049.29997
Overall Steps per Second: 10,673.67168

Timestep Collection Time: 2.26783
Timestep Consumption Time: 2.41697
PPO Batch Consumption Time: 0.27682
Total Iteration Time: 4.68480

Cumulative Model Updates: 256,982
Cumulative Timesteps: 2,143,806,508

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53,483.81416
Policy Entropy: 2.74036
Value Function Loss: 0.01282

Mean KL Divergence: 0.01109
SB3 Clip Fraction: 0.09039
Policy Update Magnitude: 0.29872
Value Function Update Magnitude: 0.36808

Collected Steps per Second: 22,027.71630
Overall Steps per Second: 10,470.70189

Timestep Collection Time: 2.27023
Timestep Consumption Time: 2.50576
PPO Batch Consumption Time: 0.29276
Total Iteration Time: 4.77599

Cumulative Model Updates: 256,988
Cumulative Timesteps: 2,143,856,516

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2143856516...
Checkpoint 2143856516 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 58,015.29799
Policy Entropy: 2.70071
Value Function Loss: 0.01266

Mean KL Divergence: 0.01078
SB3 Clip Fraction: 0.08743
Policy Update Magnitude: 0.30741
Value Function Update Magnitude: 0.35293

Collected Steps per Second: 21,788.36673
Overall Steps per Second: 10,566.24449

Timestep Collection Time: 2.29563
Timestep Consumption Time: 2.43813
PPO Batch Consumption Time: 0.27881
Total Iteration Time: 4.73375

Cumulative Model Updates: 256,994
Cumulative Timesteps: 2,143,906,534

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 113,815.46519
Policy Entropy: 2.70267
Value Function Loss: 0.01168

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.07980
Policy Update Magnitude: 0.30457
Value Function Update Magnitude: 0.34426

Collected Steps per Second: 21,835.75337
Overall Steps per Second: 10,476.21486

Timestep Collection Time: 2.29019
Timestep Consumption Time: 2.48329
PPO Batch Consumption Time: 0.28674
Total Iteration Time: 4.77348

Cumulative Model Updates: 257,000
Cumulative Timesteps: 2,143,956,542

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2143956542...
Checkpoint 2143956542 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 114,914.51656
Policy Entropy: 2.71646
Value Function Loss: 0.01101

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.07291
Policy Update Magnitude: 0.29508
Value Function Update Magnitude: 0.31460

Collected Steps per Second: 20,979.11422
Overall Steps per Second: 10,255.87143

Timestep Collection Time: 2.38494
Timestep Consumption Time: 2.49363
PPO Batch Consumption Time: 0.29297
Total Iteration Time: 4.87857

Cumulative Model Updates: 257,006
Cumulative Timesteps: 2,144,006,576

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91,426.56962
Policy Entropy: 2.71986
Value Function Loss: 0.01084

Mean KL Divergence: 0.00745
SB3 Clip Fraction: 0.06532
Policy Update Magnitude: 0.29027
Value Function Update Magnitude: 0.31324

Collected Steps per Second: 20,976.02625
Overall Steps per Second: 10,378.62253

Timestep Collection Time: 2.38367
Timestep Consumption Time: 2.43392
PPO Batch Consumption Time: 0.29165
Total Iteration Time: 4.81760

Cumulative Model Updates: 257,012
Cumulative Timesteps: 2,144,056,576

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2144056576...
Checkpoint 2144056576 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 112,126.85584
Policy Entropy: 2.69968
Value Function Loss: 0.01219

Mean KL Divergence: 0.00652
SB3 Clip Fraction: 0.05909
Policy Update Magnitude: 0.30412
Value Function Update Magnitude: 0.30030

Collected Steps per Second: 20,952.71214
Overall Steps per Second: 10,571.56153

Timestep Collection Time: 2.38738
Timestep Consumption Time: 2.34438
PPO Batch Consumption Time: 0.27827
Total Iteration Time: 4.73175

Cumulative Model Updates: 257,018
Cumulative Timesteps: 2,144,106,598

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 136,259.71724
Policy Entropy: 2.69028
Value Function Loss: 0.01227

Mean KL Divergence: 0.00653
SB3 Clip Fraction: 0.05992
Policy Update Magnitude: 0.30591
Value Function Update Magnitude: 0.30414

Collected Steps per Second: 21,428.76328
Overall Steps per Second: 10,534.50315

Timestep Collection Time: 2.33434
Timestep Consumption Time: 2.41406
PPO Batch Consumption Time: 0.28385
Total Iteration Time: 4.74840

Cumulative Model Updates: 257,024
Cumulative Timesteps: 2,144,156,620

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2144156620...
Checkpoint 2144156620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 128,251.85694
Policy Entropy: 2.68396
Value Function Loss: 0.01214

Mean KL Divergence: 0.00613
SB3 Clip Fraction: 0.05543
Policy Update Magnitude: 0.30658
Value Function Update Magnitude: 0.31458

Collected Steps per Second: 21,224.08790
Overall Steps per Second: 10,353.08735

Timestep Collection Time: 2.35657
Timestep Consumption Time: 2.47445
PPO Batch Consumption Time: 0.29025
Total Iteration Time: 4.83102

Cumulative Model Updates: 257,030
Cumulative Timesteps: 2,144,206,636

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 110,724.53401
Policy Entropy: 2.68697
Value Function Loss: 0.01113

Mean KL Divergence: 0.00599
SB3 Clip Fraction: 0.05435
Policy Update Magnitude: 0.30414
Value Function Update Magnitude: 0.32260

Collected Steps per Second: 22,182.11425
Overall Steps per Second: 10,711.82181

Timestep Collection Time: 2.25425
Timestep Consumption Time: 2.41386
PPO Batch Consumption Time: 0.27914
Total Iteration Time: 4.66811

Cumulative Model Updates: 257,036
Cumulative Timesteps: 2,144,256,640

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2144256640...
Checkpoint 2144256640 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 136,966.37291
Policy Entropy: 2.69241
Value Function Loss: 0.00991

Mean KL Divergence: 0.00592
SB3 Clip Fraction: 0.05410
Policy Update Magnitude: 0.29486
Value Function Update Magnitude: 0.31364

Collected Steps per Second: 21,458.78821
Overall Steps per Second: 10,566.67632

Timestep Collection Time: 2.33033
Timestep Consumption Time: 2.40210
PPO Batch Consumption Time: 0.27867
Total Iteration Time: 4.73242

Cumulative Model Updates: 257,042
Cumulative Timesteps: 2,144,306,646

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 109,173.70017
Policy Entropy: 2.70262
Value Function Loss: 0.01201

Mean KL Divergence: 0.00547
SB3 Clip Fraction: 0.05139
Policy Update Magnitude: 0.29775
Value Function Update Magnitude: 0.32418

Collected Steps per Second: 22,181.06142
Overall Steps per Second: 10,548.28136

Timestep Collection Time: 2.25463
Timestep Consumption Time: 2.48643
PPO Batch Consumption Time: 0.28810
Total Iteration Time: 4.74106

Cumulative Model Updates: 257,048
Cumulative Timesteps: 2,144,356,656

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2144356656...
Checkpoint 2144356656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 121,988.15715
Policy Entropy: 2.70292
Value Function Loss: 0.01137

Mean KL Divergence: 0.00617
SB3 Clip Fraction: 0.05914
Policy Update Magnitude: 0.30304
Value Function Update Magnitude: 0.34551

Collected Steps per Second: 21,908.95423
Overall Steps per Second: 10,604.17905

Timestep Collection Time: 2.28226
Timestep Consumption Time: 2.43305
PPO Batch Consumption Time: 0.27840
Total Iteration Time: 4.71531

Cumulative Model Updates: 257,054
Cumulative Timesteps: 2,144,406,658

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 141,870.11752
Policy Entropy: 2.70678
Value Function Loss: 0.01147

Mean KL Divergence: 0.00662
SB3 Clip Fraction: 0.06196
Policy Update Magnitude: 0.29452
Value Function Update Magnitude: 0.32684

Collected Steps per Second: 21,983.86856
Overall Steps per Second: 10,481.83545

Timestep Collection Time: 2.27540
Timestep Consumption Time: 2.49686
PPO Batch Consumption Time: 0.29136
Total Iteration Time: 4.77226

Cumulative Model Updates: 257,060
Cumulative Timesteps: 2,144,456,680

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2144456680...
Checkpoint 2144456680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 114,317.99988
Policy Entropy: 2.72447
Value Function Loss: 0.00959

Mean KL Divergence: 0.00563
SB3 Clip Fraction: 0.05297
Policy Update Magnitude: 0.28255
Value Function Update Magnitude: 0.29000

Collected Steps per Second: 21,791.91454
Overall Steps per Second: 10,575.86076

Timestep Collection Time: 2.29470
Timestep Consumption Time: 2.43361
PPO Batch Consumption Time: 0.27839
Total Iteration Time: 4.72831

Cumulative Model Updates: 257,066
Cumulative Timesteps: 2,144,506,686

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 123,759.97207
Policy Entropy: 2.71149
Value Function Loss: 0.01182

Mean KL Divergence: 0.00661
SB3 Clip Fraction: 0.06043
Policy Update Magnitude: 0.29195
Value Function Update Magnitude: 0.27223

Collected Steps per Second: 21,663.87988
Overall Steps per Second: 10,527.17457

Timestep Collection Time: 2.30864
Timestep Consumption Time: 2.44231
PPO Batch Consumption Time: 0.27830
Total Iteration Time: 4.75094

Cumulative Model Updates: 257,072
Cumulative Timesteps: 2,144,556,700

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2144556700...
Checkpoint 2144556700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 106,919.88623
Policy Entropy: 2.70780
Value Function Loss: 0.01226

Mean KL Divergence: 0.00632
SB3 Clip Fraction: 0.05682
Policy Update Magnitude: 0.30608
Value Function Update Magnitude: 0.27287

Collected Steps per Second: 21,321.01907
Overall Steps per Second: 10,313.41536

Timestep Collection Time: 2.34585
Timestep Consumption Time: 2.50375
PPO Batch Consumption Time: 0.29194
Total Iteration Time: 4.84961

Cumulative Model Updates: 257,078
Cumulative Timesteps: 2,144,606,716

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 106,568.43964
Policy Entropy: 2.69371
Value Function Loss: 0.01320

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.06899
Policy Update Magnitude: 0.31000
Value Function Update Magnitude: 0.32096

Collected Steps per Second: 21,679.28764
Overall Steps per Second: 10,710.97466

Timestep Collection Time: 2.30764
Timestep Consumption Time: 2.36308
PPO Batch Consumption Time: 0.27858
Total Iteration Time: 4.67072

Cumulative Model Updates: 257,084
Cumulative Timesteps: 2,144,656,744

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2144656744...
Checkpoint 2144656744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 95,422.48234
Policy Entropy: 2.69747
Value Function Loss: 0.01228

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.07722
Policy Update Magnitude: 0.30465
Value Function Update Magnitude: 0.33351

Collected Steps per Second: 21,113.69640
Overall Steps per Second: 10,594.04006

Timestep Collection Time: 2.36870
Timestep Consumption Time: 2.35207
PPO Batch Consumption Time: 0.27919
Total Iteration Time: 4.72077

Cumulative Model Updates: 257,090
Cumulative Timesteps: 2,144,706,756

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85,326.92129
Policy Entropy: 2.69829
Value Function Loss: 0.01281

Mean KL Divergence: 0.01193
SB3 Clip Fraction: 0.10151
Policy Update Magnitude: 0.30435
Value Function Update Magnitude: 0.33086

Collected Steps per Second: 21,724.39538
Overall Steps per Second: 10,576.33455

Timestep Collection Time: 2.30285
Timestep Consumption Time: 2.42733
PPO Batch Consumption Time: 0.29096
Total Iteration Time: 4.73018

Cumulative Model Updates: 257,096
Cumulative Timesteps: 2,144,756,784

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2144756784...
Checkpoint 2144756784 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 90,056.28304
Policy Entropy: 2.69555
Value Function Loss: 0.01387

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.08493
Policy Update Magnitude: 0.30874
Value Function Update Magnitude: 0.32967

Collected Steps per Second: 21,476.73438
Overall Steps per Second: 10,558.73076

Timestep Collection Time: 2.32894
Timestep Consumption Time: 2.40818
PPO Batch Consumption Time: 0.27892
Total Iteration Time: 4.73712

Cumulative Model Updates: 257,102
Cumulative Timesteps: 2,144,806,802

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 110,159.33883
Policy Entropy: 2.68653
Value Function Loss: 0.01415

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.07121
Policy Update Magnitude: 0.32567
Value Function Update Magnitude: 0.37488

Collected Steps per Second: 21,999.04558
Overall Steps per Second: 10,512.98440

Timestep Collection Time: 2.27301
Timestep Consumption Time: 2.48340
PPO Batch Consumption Time: 0.29157
Total Iteration Time: 4.75640

Cumulative Model Updates: 257,108
Cumulative Timesteps: 2,144,856,806

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2144856806...
Checkpoint 2144856806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 91,288.51649
Policy Entropy: 2.67028
Value Function Loss: 0.01293

Mean KL Divergence: 0.01058
SB3 Clip Fraction: 0.07360
Policy Update Magnitude: 0.32466
Value Function Update Magnitude: 0.37025

Collected Steps per Second: 22,033.94820
Overall Steps per Second: 10,715.46735

Timestep Collection Time: 2.26932
Timestep Consumption Time: 2.39702
PPO Batch Consumption Time: 0.27661
Total Iteration Time: 4.66634

Cumulative Model Updates: 257,114
Cumulative Timesteps: 2,144,906,808

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 140,828.25704
Policy Entropy: 2.66205
Value Function Loss: 0.01149

Mean KL Divergence: 0.01138
SB3 Clip Fraction: 0.07218
Policy Update Magnitude: 0.31079
Value Function Update Magnitude: 0.33273

Collected Steps per Second: 21,661.53870
Overall Steps per Second: 10,386.68434

Timestep Collection Time: 2.30852
Timestep Consumption Time: 2.50592
PPO Batch Consumption Time: 0.29175
Total Iteration Time: 4.81443

Cumulative Model Updates: 257,120
Cumulative Timesteps: 2,144,956,814

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2144956814...
Checkpoint 2144956814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 121,304.64436
Policy Entropy: 2.68365
Value Function Loss: 0.01247

Mean KL Divergence: 0.00734
SB3 Clip Fraction: 0.06601
Policy Update Magnitude: 0.30196
Value Function Update Magnitude: 0.31011

Collected Steps per Second: 21,586.11787
Overall Steps per Second: 10,565.51934

Timestep Collection Time: 2.31704
Timestep Consumption Time: 2.41684
PPO Batch Consumption Time: 0.27870
Total Iteration Time: 4.73389

Cumulative Model Updates: 257,126
Cumulative Timesteps: 2,145,006,830

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 102,394.18658
Policy Entropy: 2.70351
Value Function Loss: 0.01277

Mean KL Divergence: 0.00660
SB3 Clip Fraction: 0.06707
Policy Update Magnitude: 0.30253
Value Function Update Magnitude: 0.29901

Collected Steps per Second: 21,534.21624
Overall Steps per Second: 10,506.55525

Timestep Collection Time: 2.32235
Timestep Consumption Time: 2.43753
PPO Batch Consumption Time: 0.27867
Total Iteration Time: 4.75989

Cumulative Model Updates: 257,132
Cumulative Timesteps: 2,145,056,840

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2145056840...
Checkpoint 2145056840 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 91,124.32451
Policy Entropy: 2.72373
Value Function Loss: 0.01377

Mean KL Divergence: 0.00683
SB3 Clip Fraction: 0.06474
Policy Update Magnitude: 0.30565
Value Function Update Magnitude: 0.30757

Collected Steps per Second: 21,025.50808
Overall Steps per Second: 10,202.91242

Timestep Collection Time: 2.37968
Timestep Consumption Time: 2.52421
PPO Batch Consumption Time: 0.29280
Total Iteration Time: 4.90389

Cumulative Model Updates: 257,138
Cumulative Timesteps: 2,145,106,874

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 114,578.05618
Policy Entropy: 2.72527
Value Function Loss: 0.01148

Mean KL Divergence: 0.00689
SB3 Clip Fraction: 0.06397
Policy Update Magnitude: 0.29091
Value Function Update Magnitude: 0.31626

Collected Steps per Second: 21,701.95567
Overall Steps per Second: 10,555.01978

Timestep Collection Time: 2.30422
Timestep Consumption Time: 2.43343
PPO Batch Consumption Time: 0.27584
Total Iteration Time: 4.73765

Cumulative Model Updates: 257,144
Cumulative Timesteps: 2,145,156,880

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2145156880...
Checkpoint 2145156880 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 114,578.05618
Policy Entropy: 2.70018
Value Function Loss: 0.01119

Mean KL Divergence: 0.00583
SB3 Clip Fraction: 0.05476
Policy Update Magnitude: 0.28576
Value Function Update Magnitude: 0.28822

Collected Steps per Second: 21,918.80027
Overall Steps per Second: 10,528.95629

Timestep Collection Time: 2.28224
Timestep Consumption Time: 2.46885
PPO Batch Consumption Time: 0.27812
Total Iteration Time: 4.75109

Cumulative Model Updates: 257,150
Cumulative Timesteps: 2,145,206,904

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 114,666.44748
Policy Entropy: 2.66888
Value Function Loss: 0.01205

Mean KL Divergence: 0.00623
SB3 Clip Fraction: 0.05957
Policy Update Magnitude: 0.30098
Value Function Update Magnitude: 0.28462

Collected Steps per Second: 22,424.20771
Overall Steps per Second: 10,539.43434

Timestep Collection Time: 2.23125
Timestep Consumption Time: 2.51606
PPO Batch Consumption Time: 0.29160
Total Iteration Time: 4.74731

Cumulative Model Updates: 257,156
Cumulative Timesteps: 2,145,256,938

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 2145256938...
Checkpoint 2145256938 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 85,869.86564
Policy Entropy: 2.68390
Value Function Loss: 0.01439

Mean KL Divergence: 0.00684
SB3 Clip Fraction: 0.06389
Policy Update Magnitude: 0.31161
Value Function Update Magnitude: 0.34045

Collected Steps per Second: 22,159.05275
Overall Steps per Second: 10,588.67001

Timestep Collection Time: 2.25858
Timestep Consumption Time: 2.46798
PPO Batch Consumption Time: 0.28456
Total Iteration Time: 4.72656

Cumulative Model Updates: 257,162
Cumulative Timesteps: 2,145,306,986

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 69,959.99172
Policy Entropy: 2.71834
Value Function Loss: 0.01518

Mean KL Divergence: 0.00747
SB3 Clip Fraction: 0.07087
Policy Update Magnitude: 0.31447
Value Function Update Magnitude: 0.36211

Collected Steps per Second: 22,420.19930
Overall Steps per Second: 10,563.53240

Timestep Collection Time: 2.23138
Timestep Consumption Time: 2.50454
PPO Batch Consumption Time: 0.29191
Total Iteration Time: 4.73592

Cumulative Model Updates: 257,168
Cumulative Timesteps: 2,145,357,014

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2145357014...
Checkpoint 2145357014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87,900.29615
Policy Entropy: 2.73794
Value Function Loss: 0.01339

Mean KL Divergence: 0.00739
SB3 Clip Fraction: 0.06791
Policy Update Magnitude: 0.30241
Value Function Update Magnitude: 0.35010

Collected Steps per Second: 22,052.89389
Overall Steps per Second: 10,533.02075

Timestep Collection Time: 2.26864
Timestep Consumption Time: 2.48119
PPO Batch Consumption Time: 0.28879
Total Iteration Time: 4.74982

Cumulative Model Updates: 257,174
Cumulative Timesteps: 2,145,407,044

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87,900.29615
Policy Entropy: 2.74608
Value Function Loss: 0.00938

Mean KL Divergence: 0.00689
SB3 Clip Fraction: 0.06527
Policy Update Magnitude: 0.27945
Value Function Update Magnitude: 0.31163

Collected Steps per Second: 22,254.09428
Overall Steps per Second: 10,529.51377

Timestep Collection Time: 2.24795
Timestep Consumption Time: 2.50308
PPO Batch Consumption Time: 0.29289
Total Iteration Time: 4.75103

Cumulative Model Updates: 257,180
Cumulative Timesteps: 2,145,457,070

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2145457070...
Checkpoint 2145457070 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87,900.29615
Policy Entropy: 2.75940
Value Function Loss: 0.00753

Mean KL Divergence: 0.00608
SB3 Clip Fraction: 0.05618
Policy Update Magnitude: 0.25544
Value Function Update Magnitude: 0.24970

Collected Steps per Second: 22,055.48746
Overall Steps per Second: 10,562.71083

Timestep Collection Time: 2.26755
Timestep Consumption Time: 2.46722
PPO Batch Consumption Time: 0.28539
Total Iteration Time: 4.73477

Cumulative Model Updates: 257,186
Cumulative Timesteps: 2,145,507,082

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80,702.69388
Policy Entropy: 2.75368
Value Function Loss: 0.00819

Mean KL Divergence: 0.00526
SB3 Clip Fraction: 0.05237
Policy Update Magnitude: 0.25040
Value Function Update Magnitude: 0.22757

Collected Steps per Second: 21,973.89751
Overall Steps per Second: 10,437.10866

Timestep Collection Time: 2.27588
Timestep Consumption Time: 2.51567
PPO Batch Consumption Time: 0.29366
Total Iteration Time: 4.79156

Cumulative Model Updates: 257,192
Cumulative Timesteps: 2,145,557,092

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2145557092...
Checkpoint 2145557092 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 80,222.22924
Policy Entropy: 2.74205
Value Function Loss: 0.00930

Mean KL Divergence: 0.00577
SB3 Clip Fraction: 0.05615
Policy Update Magnitude: 0.26533
Value Function Update Magnitude: 0.25677

Collected Steps per Second: 21,253.75405
Overall Steps per Second: 10,341.91299

Timestep Collection Time: 2.35469
Timestep Consumption Time: 2.48445
PPO Batch Consumption Time: 0.29205
Total Iteration Time: 4.83914

Cumulative Model Updates: 257,198
Cumulative Timesteps: 2,145,607,138

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80,222.22924
Policy Entropy: 2.73181
Value Function Loss: 0.00926

Mean KL Divergence: 0.00670
SB3 Clip Fraction: 0.05988
Policy Update Magnitude: 0.26999
Value Function Update Magnitude: 0.26960

Collected Steps per Second: 21,427.24494
Overall Steps per Second: 10,664.68344

Timestep Collection Time: 2.33376
Timestep Consumption Time: 2.35518
PPO Batch Consumption Time: 0.27842
Total Iteration Time: 4.68893

Cumulative Model Updates: 257,204
Cumulative Timesteps: 2,145,657,144

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2145657144...
Checkpoint 2145657144 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 85,919.75110
Policy Entropy: 2.72773
Value Function Loss: 0.01192

Mean KL Divergence: 0.00692
SB3 Clip Fraction: 0.06163
Policy Update Magnitude: 0.29418
Value Function Update Magnitude: 0.30774

Collected Steps per Second: 20,918.98866
Overall Steps per Second: 10,377.73258

Timestep Collection Time: 2.39142
Timestep Consumption Time: 2.42910
PPO Batch Consumption Time: 0.29302
Total Iteration Time: 4.82051

Cumulative Model Updates: 257,210
Cumulative Timesteps: 2,145,707,170

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80,302.90677
Policy Entropy: 2.72601
Value Function Loss: 0.01350

Mean KL Divergence: 0.00783
SB3 Clip Fraction: 0.06213
Policy Update Magnitude: 0.30581
Value Function Update Magnitude: 0.35910

Collected Steps per Second: 21,527.57644
Overall Steps per Second: 10,504.63320

Timestep Collection Time: 2.32335
Timestep Consumption Time: 2.43798
PPO Batch Consumption Time: 0.29208
Total Iteration Time: 4.76133

Cumulative Model Updates: 257,216
Cumulative Timesteps: 2,145,757,186

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2145757186...
Checkpoint 2145757186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 69,984.86155
Policy Entropy: 2.71812
Value Function Loss: 0.01490

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.06398
Policy Update Magnitude: 0.31196
Value Function Update Magnitude: 0.36961

Collected Steps per Second: 21,279.68492
Overall Steps per Second: 10,497.47082

Timestep Collection Time: 2.35069
Timestep Consumption Time: 2.41446
PPO Batch Consumption Time: 0.28472
Total Iteration Time: 4.76515

Cumulative Model Updates: 257,222
Cumulative Timesteps: 2,145,807,208

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59,361.11312
Policy Entropy: 2.73304
Value Function Loss: 0.01338

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.06941
Policy Update Magnitude: 0.30694
Value Function Update Magnitude: 0.34699

Collected Steps per Second: 21,946.00910
Overall Steps per Second: 10,482.18469

Timestep Collection Time: 2.27841
Timestep Consumption Time: 2.49178
PPO Batch Consumption Time: 0.29296
Total Iteration Time: 4.77019

Cumulative Model Updates: 257,228
Cumulative Timesteps: 2,145,857,210

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2145857210...
Checkpoint 2145857210 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 61,937.44630
Policy Entropy: 2.72930
Value Function Loss: 0.01220

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.06421
Policy Update Magnitude: 0.30115
Value Function Update Magnitude: 0.33004

Collected Steps per Second: 21,449.81177
Overall Steps per Second: 10,560.31985

Timestep Collection Time: 2.33242
Timestep Consumption Time: 2.40512
PPO Batch Consumption Time: 0.27875
Total Iteration Time: 4.73755

Cumulative Model Updates: 257,234
Cumulative Timesteps: 2,145,907,240

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55,615.89418
Policy Entropy: 2.74074
Value Function Loss: 0.01051

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.06759
Policy Update Magnitude: 0.29093
Value Function Update Magnitude: 0.28607

Collected Steps per Second: 22,322.81362
Overall Steps per Second: 10,596.38002

Timestep Collection Time: 2.24013
Timestep Consumption Time: 2.47903
PPO Batch Consumption Time: 0.29322
Total Iteration Time: 4.71916

Cumulative Model Updates: 257,240
Cumulative Timesteps: 2,145,957,246

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2145957246...
Checkpoint 2145957246 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55,615.89418
Policy Entropy: 2.73628
Value Function Loss: 0.00956

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.06517
Policy Update Magnitude: 0.27877
Value Function Update Magnitude: 0.27113

Collected Steps per Second: 21,941.58745
Overall Steps per Second: 10,547.98975

Timestep Collection Time: 2.27951
Timestep Consumption Time: 2.46225
PPO Batch Consumption Time: 0.28441
Total Iteration Time: 4.74176

Cumulative Model Updates: 257,246
Cumulative Timesteps: 2,146,007,262

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99,430.66525
Policy Entropy: 2.75038
Value Function Loss: 0.01222

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.07527
Policy Update Magnitude: 0.27946
Value Function Update Magnitude: 0.28890

Collected Steps per Second: 22,289.73599
Overall Steps per Second: 10,539.02924

Timestep Collection Time: 2.24372
Timestep Consumption Time: 2.50169
PPO Batch Consumption Time: 0.29308
Total Iteration Time: 4.74541

Cumulative Model Updates: 257,252
Cumulative Timesteps: 2,146,057,274

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2146057274...
Checkpoint 2146057274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 106,737.62544
Policy Entropy: 2.73433
Value Function Loss: 0.01189

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.08478
Policy Update Magnitude: 0.29071
Value Function Update Magnitude: 0.33002

Collected Steps per Second: 21,618.70695
Overall Steps per Second: 10,531.78567

Timestep Collection Time: 2.31300
Timestep Consumption Time: 2.43492
PPO Batch Consumption Time: 0.27907
Total Iteration Time: 4.74791

Cumulative Model Updates: 257,258
Cumulative Timesteps: 2,146,107,278

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 106,737.62544
Policy Entropy: 2.71763
Value Function Loss: 0.01261

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.08863
Policy Update Magnitude: 0.29566
Value Function Update Magnitude: 0.37057

Collected Steps per Second: 21,315.09357
Overall Steps per Second: 10,466.67634

Timestep Collection Time: 2.34763
Timestep Consumption Time: 2.43326
PPO Batch Consumption Time: 0.27835
Total Iteration Time: 4.78089

Cumulative Model Updates: 257,264
Cumulative Timesteps: 2,146,157,318

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 2146157318...
Checkpoint 2146157318 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 91,812.74330
Policy Entropy: 2.72230
Value Function Loss: 0.01154

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.07916
Policy Update Magnitude: 0.29993
Value Function Update Magnitude: 0.34516

Collected Steps per Second: 21,446.67869
Overall Steps per Second: 10,384.19466

Timestep Collection Time: 2.33304
Timestep Consumption Time: 2.48543
PPO Batch Consumption Time: 0.29105
Total Iteration Time: 4.81848

Cumulative Model Updates: 257,270
Cumulative Timesteps: 2,146,207,354

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 128,756.37567
Policy Entropy: 2.71894
Value Function Loss: 0.01176

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.07436
Policy Update Magnitude: 0.30045
Value Function Update Magnitude: 0.32959

Collected Steps per Second: 21,933.45883
Overall Steps per Second: 10,425.85387

Timestep Collection Time: 2.27971
Timestep Consumption Time: 2.51625
PPO Batch Consumption Time: 0.29115
Total Iteration Time: 4.79596

Cumulative Model Updates: 257,276
Cumulative Timesteps: 2,146,257,356

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2146257356...
Checkpoint 2146257356 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 109,372.51061
Policy Entropy: 2.72964
Value Function Loss: 0.01184

Mean KL Divergence: 0.00675
SB3 Clip Fraction: 0.06136
Policy Update Magnitude: 0.29875
Value Function Update Magnitude: 0.30310

Collected Steps per Second: 22,024.24860
Overall Steps per Second: 10,551.08204

Timestep Collection Time: 2.27113
Timestep Consumption Time: 2.46961
PPO Batch Consumption Time: 0.27734
Total Iteration Time: 4.74075

Cumulative Model Updates: 257,282
Cumulative Timesteps: 2,146,307,376

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 101,415.45074
Policy Entropy: 2.71728
Value Function Loss: 0.01059

Mean KL Divergence: 0.00764
SB3 Clip Fraction: 0.07080
Policy Update Magnitude: 0.28972
Value Function Update Magnitude: 0.29373

Collected Steps per Second: 22,359.83819
Overall Steps per Second: 10,555.32644

Timestep Collection Time: 2.23705
Timestep Consumption Time: 2.50179
PPO Batch Consumption Time: 0.28930
Total Iteration Time: 4.73884

Cumulative Model Updates: 257,288
Cumulative Timesteps: 2,146,357,396

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2146357396...
Checkpoint 2146357396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 78,935.99188
Policy Entropy: 2.72306
Value Function Loss: 0.01008

Mean KL Divergence: 0.00620
SB3 Clip Fraction: 0.05712
Policy Update Magnitude: 0.28239
Value Function Update Magnitude: 0.26736

Collected Steps per Second: 21,845.00692
Overall Steps per Second: 10,480.07589

Timestep Collection Time: 2.28977
Timestep Consumption Time: 2.48310
PPO Batch Consumption Time: 0.28807
Total Iteration Time: 4.77287

Cumulative Model Updates: 257,294
Cumulative Timesteps: 2,146,407,416

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99,025.51160
Policy Entropy: 2.72164
Value Function Loss: 0.01003

Mean KL Divergence: 0.00617
SB3 Clip Fraction: 0.05776
Policy Update Magnitude: 0.28024
Value Function Update Magnitude: 0.25189

Collected Steps per Second: 22,329.48487
Overall Steps per Second: 10,543.30129

Timestep Collection Time: 2.23982
Timestep Consumption Time: 2.50386
PPO Batch Consumption Time: 0.29258
Total Iteration Time: 4.74368

Cumulative Model Updates: 257,300
Cumulative Timesteps: 2,146,457,430

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2146457430...
Checkpoint 2146457430 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86,474.82696
Policy Entropy: 2.73266
Value Function Loss: 0.00964

Mean KL Divergence: 0.00614
SB3 Clip Fraction: 0.05716
Policy Update Magnitude: 0.27653
Value Function Update Magnitude: 0.26125

Collected Steps per Second: 22,191.72754
Overall Steps per Second: 10,535.02022

Timestep Collection Time: 2.25336
Timestep Consumption Time: 2.49328
PPO Batch Consumption Time: 0.28936
Total Iteration Time: 4.74664

Cumulative Model Updates: 257,306
Cumulative Timesteps: 2,146,507,436

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 74,240.77901
Policy Entropy: 2.73344
Value Function Loss: 0.00898

Mean KL Divergence: 0.00523
SB3 Clip Fraction: 0.04990
Policy Update Magnitude: 0.27036
Value Function Update Magnitude: 0.25637

Collected Steps per Second: 22,343.99429
Overall Steps per Second: 10,546.87556

Timestep Collection Time: 2.23989
Timestep Consumption Time: 2.50541
PPO Batch Consumption Time: 0.29237
Total Iteration Time: 4.74529

Cumulative Model Updates: 257,312
Cumulative Timesteps: 2,146,557,484

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 2146557484...
Checkpoint 2146557484 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 96,140.25675
Policy Entropy: 2.72198
Value Function Loss: 0.01000

Mean KL Divergence: 0.00529
SB3 Clip Fraction: 0.05078
Policy Update Magnitude: 0.27619
Value Function Update Magnitude: 0.24451

Collected Steps per Second: 21,918.64250
Overall Steps per Second: 10,646.18333

Timestep Collection Time: 2.28299
Timestep Consumption Time: 2.41729
PPO Batch Consumption Time: 0.27694
Total Iteration Time: 4.70028

Cumulative Model Updates: 257,318
Cumulative Timesteps: 2,146,607,524

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 129,364.94449
Policy Entropy: 2.71309
Value Function Loss: 0.00984

Mean KL Divergence: 0.00545
SB3 Clip Fraction: 0.05265
Policy Update Magnitude: 0.27628
Value Function Update Magnitude: 0.25428

Collected Steps per Second: 21,851.90909
Overall Steps per Second: 10,437.49897

Timestep Collection Time: 2.28850
Timestep Consumption Time: 2.50269
PPO Batch Consumption Time: 0.29164
Total Iteration Time: 4.79119

Cumulative Model Updates: 257,324
Cumulative Timesteps: 2,146,657,532

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2146657532...
Checkpoint 2146657532 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 107,710.81892
Policy Entropy: 2.72077
Value Function Loss: 0.01247

Mean KL Divergence: 0.00551
SB3 Clip Fraction: 0.05307
Policy Update Magnitude: 0.28192
Value Function Update Magnitude: 0.26553

Collected Steps per Second: 20,294.19853
Overall Steps per Second: 10,126.64542

Timestep Collection Time: 2.46474
Timestep Consumption Time: 2.47470
PPO Batch Consumption Time: 0.28007
Total Iteration Time: 4.93944

Cumulative Model Updates: 257,330
Cumulative Timesteps: 2,146,707,552

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 112,792.30754
Policy Entropy: 2.72995
Value Function Loss: 0.01087

Mean KL Divergence: 0.00627
SB3 Clip Fraction: 0.05833
Policy Update Magnitude: 0.29131
Value Function Update Magnitude: 0.26064

Collected Steps per Second: 21,839.28468
Overall Steps per Second: 10,475.16637

Timestep Collection Time: 2.29018
Timestep Consumption Time: 2.48454
PPO Batch Consumption Time: 0.28512
Total Iteration Time: 4.77472

Cumulative Model Updates: 257,336
Cumulative Timesteps: 2,146,757,568

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2146757568...
Checkpoint 2146757568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 113,421.75108
Policy Entropy: 2.72895
Value Function Loss: 0.01031

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.07222
Policy Update Magnitude: 0.27858
Value Function Update Magnitude: 0.23846

Collected Steps per Second: 21,458.45481
Overall Steps per Second: 10,342.15614

Timestep Collection Time: 2.33018
Timestep Consumption Time: 2.50460
PPO Batch Consumption Time: 0.29118
Total Iteration Time: 4.83478

Cumulative Model Updates: 257,342
Cumulative Timesteps: 2,146,807,570

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 111,052.03002
Policy Entropy: 2.73468
Value Function Loss: 0.00870

Mean KL Divergence: 0.00709
SB3 Clip Fraction: 0.06702
Policy Update Magnitude: 0.27583
Value Function Update Magnitude: 0.23539

Collected Steps per Second: 21,570.18880
Overall Steps per Second: 10,331.43904

Timestep Collection Time: 2.31838
Timestep Consumption Time: 2.52199
PPO Batch Consumption Time: 0.29297
Total Iteration Time: 4.84037

Cumulative Model Updates: 257,348
Cumulative Timesteps: 2,146,857,578

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2146857578...
Checkpoint 2146857578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 94,257.28500
Policy Entropy: 2.71628
Value Function Loss: 0.00999

Mean KL Divergence: 0.00687
SB3 Clip Fraction: 0.06427
Policy Update Magnitude: 0.27431
Value Function Update Magnitude: 0.21701

Collected Steps per Second: 21,895.28393
Overall Steps per Second: 10,534.53123

Timestep Collection Time: 2.28488
Timestep Consumption Time: 2.46408
PPO Batch Consumption Time: 0.27886
Total Iteration Time: 4.74895

Cumulative Model Updates: 257,354
Cumulative Timesteps: 2,146,907,606

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76,858.51192
Policy Entropy: 2.70195
Value Function Loss: 0.01087

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.06758
Policy Update Magnitude: 0.28086
Value Function Update Magnitude: 0.21339

Collected Steps per Second: 22,036.36728
Overall Steps per Second: 10,552.01697

Timestep Collection Time: 2.26925
Timestep Consumption Time: 2.46975
PPO Batch Consumption Time: 0.28541
Total Iteration Time: 4.73900

Cumulative Model Updates: 257,360
Cumulative Timesteps: 2,146,957,612

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2146957612...
Checkpoint 2146957612 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 163,633.06131
Policy Entropy: 2.69446
Value Function Loss: 0.01051

Mean KL Divergence: 0.00676
SB3 Clip Fraction: 0.06454
Policy Update Magnitude: 0.27710
Value Function Update Magnitude: 0.20907

Collected Steps per Second: 21,930.31212
Overall Steps per Second: 10,630.43360

Timestep Collection Time: 2.28041
Timestep Consumption Time: 2.42401
PPO Batch Consumption Time: 0.27829
Total Iteration Time: 4.70442

Cumulative Model Updates: 257,366
Cumulative Timesteps: 2,147,007,622

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 166,339.67499
Policy Entropy: 2.69497
Value Function Loss: 0.01096

Mean KL Divergence: 0.00584
SB3 Clip Fraction: 0.05513
Policy Update Magnitude: 0.28130
Value Function Update Magnitude: 0.24669

Collected Steps per Second: 21,587.35327
Overall Steps per Second: 10,526.56812

Timestep Collection Time: 2.31691
Timestep Consumption Time: 2.43449
PPO Batch Consumption Time: 0.29320
Total Iteration Time: 4.75141

Cumulative Model Updates: 257,372
Cumulative Timesteps: 2,147,057,638

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2147057638...
Checkpoint 2147057638 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 101,639.07000
Policy Entropy: 2.70985
Value Function Loss: 0.01152

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.07185
Policy Update Magnitude: 0.29478
Value Function Update Magnitude: 0.28068

Collected Steps per Second: 21,339.89714
Overall Steps per Second: 10,527.33240

Timestep Collection Time: 2.34303
Timestep Consumption Time: 2.40651
PPO Batch Consumption Time: 0.28785
Total Iteration Time: 4.74954

Cumulative Model Updates: 257,378
Cumulative Timesteps: 2,147,107,638

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80,976.93447
Policy Entropy: 2.69449
Value Function Loss: 0.01171

Mean KL Divergence: 0.00693
SB3 Clip Fraction: 0.06519
Policy Update Magnitude: 0.29287
Value Function Update Magnitude: 0.27395

Collected Steps per Second: 21,555.81434
Overall Steps per Second: 10,547.79979

Timestep Collection Time: 2.32104
Timestep Consumption Time: 2.42231
PPO Batch Consumption Time: 0.29290
Total Iteration Time: 4.74336

Cumulative Model Updates: 257,384
Cumulative Timesteps: 2,147,157,670

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2147157670...
Checkpoint 2147157670 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 121,945.55353
Policy Entropy: 2.67874
Value Function Loss: 0.01400

Mean KL Divergence: 0.00711
SB3 Clip Fraction: 0.06600
Policy Update Magnitude: 0.30504
Value Function Update Magnitude: 0.23734

Collected Steps per Second: 21,304.64224
Overall Steps per Second: 10,574.99450

Timestep Collection Time: 2.34747
Timestep Consumption Time: 2.38180
PPO Batch Consumption Time: 0.28440
Total Iteration Time: 4.72927

Cumulative Model Updates: 257,390
Cumulative Timesteps: 2,147,207,682

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 150,806.90683
Policy Entropy: 2.67831
Value Function Loss: 0.01291

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.07747
Policy Update Magnitude: 0.31520
Value Function Update Magnitude: 0.21427

Collected Steps per Second: 21,029.52232
Overall Steps per Second: 10,431.77124

Timestep Collection Time: 2.37809
Timestep Consumption Time: 2.41592
PPO Batch Consumption Time: 0.27916
Total Iteration Time: 4.79401

Cumulative Model Updates: 257,396
Cumulative Timesteps: 2,147,257,692

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2147257692...
Checkpoint 2147257692 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 137,336.58623
Policy Entropy: 2.70976
Value Function Loss: 0.01290

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.07868
Policy Update Magnitude: 0.30721
Value Function Update Magnitude: 0.19583

Collected Steps per Second: 21,610.24436
Overall Steps per Second: 10,599.17673

Timestep Collection Time: 2.31548
Timestep Consumption Time: 2.40546
PPO Batch Consumption Time: 0.27899
Total Iteration Time: 4.72093

Cumulative Model Updates: 257,402
Cumulative Timesteps: 2,147,307,730

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81,845.78599
Policy Entropy: 2.71336
Value Function Loss: 0.01527

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.08585
Policy Update Magnitude: 0.31545
Value Function Update Magnitude: 0.20107

Collected Steps per Second: 21,409.65158
Overall Steps per Second: 10,582.50005

Timestep Collection Time: 2.33708
Timestep Consumption Time: 2.39111
PPO Batch Consumption Time: 0.27680
Total Iteration Time: 4.72818

Cumulative Model Updates: 257,408
Cumulative Timesteps: 2,147,357,766

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 2147357766...
Checkpoint 2147357766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 81,845.78599
Policy Entropy: 2.68808
Value Function Loss: 0.01374

Mean KL Divergence: 0.01348
SB3 Clip Fraction: 0.11196
Policy Update Magnitude: 0.33250
Value Function Update Magnitude: 0.28328

Collected Steps per Second: 21,731.01853
Overall Steps per Second: 10,565.99478

Timestep Collection Time: 2.30150
Timestep Consumption Time: 2.43198
PPO Batch Consumption Time: 0.27851
Total Iteration Time: 4.73349

Cumulative Model Updates: 257,414
Cumulative Timesteps: 2,147,407,780

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75,207.03946
Policy Entropy: 2.65947
Value Function Loss: 0.01427

Mean KL Divergence: 0.01774
SB3 Clip Fraction: 0.12405
Policy Update Magnitude: 0.32946
Value Function Update Magnitude: 0.33821

Collected Steps per Second: 22,043.46868
Overall Steps per Second: 10,434.48959

Timestep Collection Time: 2.26897
Timestep Consumption Time: 2.52436
PPO Batch Consumption Time: 0.28769
Total Iteration Time: 4.79333

Cumulative Model Updates: 257,420
Cumulative Timesteps: 2,147,457,796

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2147457796...
Checkpoint 2147457796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 140,850.65600
Policy Entropy: 2.63899
Value Function Loss: 0.01218

Mean KL Divergence: 0.01590
SB3 Clip Fraction: 0.11476
Policy Update Magnitude: 0.32563
Value Function Update Magnitude: 0.32184

Collected Steps per Second: 21,922.46025
Overall Steps per Second: 10,556.05973

Timestep Collection Time: 2.28223
Timestep Consumption Time: 2.45742
PPO Batch Consumption Time: 0.27837
Total Iteration Time: 4.73965

Cumulative Model Updates: 257,426
Cumulative Timesteps: 2,147,507,828

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 100,850.14003
Policy Entropy: 2.61323
Value Function Loss: 0.01382

Mean KL Divergence: 0.01397
SB3 Clip Fraction: 0.10857
Policy Update Magnitude: 0.32567
Value Function Update Magnitude: 0.31163

Collected Steps per Second: 21,985.20327
Overall Steps per Second: 10,649.14193

Timestep Collection Time: 2.27453
Timestep Consumption Time: 2.42125
PPO Batch Consumption Time: 0.27709
Total Iteration Time: 4.69578

Cumulative Model Updates: 257,432
Cumulative Timesteps: 2,147,557,834

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2147557834...
Checkpoint 2147557834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 101,010.23845
Policy Entropy: 2.60351
Value Function Loss: 0.01371

Mean KL Divergence: 0.01643
SB3 Clip Fraction: 0.12555
Policy Update Magnitude: 0.32535
Value Function Update Magnitude: 0.32830

Collected Steps per Second: 21,700.11403
Overall Steps per Second: 10,520.82433

Timestep Collection Time: 2.30589
Timestep Consumption Time: 2.45020
PPO Batch Consumption Time: 0.27879
Total Iteration Time: 4.75609

Cumulative Model Updates: 257,438
Cumulative Timesteps: 2,147,607,872

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90,836.90129
Policy Entropy: 2.61381
Value Function Loss: 0.01331

Mean KL Divergence: 0.01537
SB3 Clip Fraction: 0.11849
Policy Update Magnitude: 0.31959
Value Function Update Magnitude: 0.33575

Collected Steps per Second: 21,903.21208
Overall Steps per Second: 10,451.73988

Timestep Collection Time: 2.28524
Timestep Consumption Time: 2.50382
PPO Batch Consumption Time: 0.28884
Total Iteration Time: 4.78906

Cumulative Model Updates: 257,444
Cumulative Timesteps: 2,147,657,926

Timesteps Collected: 50,054
--------END ITERATION REPORT--------


Saving checkpoint 2147657926...
Checkpoint 2147657926 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 99,929.37474
Policy Entropy: 2.63671
Value Function Loss: 0.01227

Mean KL Divergence: 0.02536
SB3 Clip Fraction: 0.11412
Policy Update Magnitude: 0.32188
Value Function Update Magnitude: 0.31740

Collected Steps per Second: 22,135.88259
Overall Steps per Second: 10,642.05468

Timestep Collection Time: 2.26004
Timestep Consumption Time: 2.44093
PPO Batch Consumption Time: 0.28041
Total Iteration Time: 4.70097

Cumulative Model Updates: 257,450
Cumulative Timesteps: 2,147,707,954

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 126,918.71729
Policy Entropy: 2.65819
Value Function Loss: 0.01319

Mean KL Divergence: 0.01119
SB3 Clip Fraction: 0.09629
Policy Update Magnitude: 0.32609
Value Function Update Magnitude: 0.31752

Collected Steps per Second: 21,816.54035
Overall Steps per Second: 10,478.03769

Timestep Collection Time: 2.29285
Timestep Consumption Time: 2.48114
PPO Batch Consumption Time: 0.28747
Total Iteration Time: 4.77399

Cumulative Model Updates: 257,456
Cumulative Timesteps: 2,147,757,976

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2147757976...
Checkpoint 2147757976 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 112,389.12648
Policy Entropy: 2.69021
Value Function Loss: 0.01330

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.07364
Policy Update Magnitude: 0.32462
Value Function Update Magnitude: 0.34016

Collected Steps per Second: 21,541.17774
Overall Steps per Second: 10,577.94120

Timestep Collection Time: 2.32225
Timestep Consumption Time: 2.40684
PPO Batch Consumption Time: 0.27809
Total Iteration Time: 4.72909

Cumulative Model Updates: 257,462
Cumulative Timesteps: 2,147,808,000

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90,665.55386
Policy Entropy: 2.67423
Value Function Loss: 0.01478

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.07177
Policy Update Magnitude: 0.33260
Value Function Update Magnitude: 0.37267

Collected Steps per Second: 21,350.55061
Overall Steps per Second: 10,465.72847

Timestep Collection Time: 2.34252
Timestep Consumption Time: 2.43632
PPO Batch Consumption Time: 0.27893
Total Iteration Time: 4.77884

Cumulative Model Updates: 257,468
Cumulative Timesteps: 2,147,858,014

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2147858014...
Checkpoint 2147858014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 67,182.58779
Policy Entropy: 2.68920
Value Function Loss: 0.01231

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.07651
Policy Update Magnitude: 0.32812
Value Function Update Magnitude: 0.37714

Collected Steps per Second: 20,629.60689
Overall Steps per Second: 10,316.31728

Timestep Collection Time: 2.42399
Timestep Consumption Time: 2.42328
PPO Batch Consumption Time: 0.29223
Total Iteration Time: 4.84727

Cumulative Model Updates: 257,474
Cumulative Timesteps: 2,147,908,020

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79,237.25346
Policy Entropy: 2.66433
Value Function Loss: 0.01143

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.08132
Policy Update Magnitude: 0.31166
Value Function Update Magnitude: 0.32944

Collected Steps per Second: 21,228.29855
Overall Steps per Second: 10,460.96924

Timestep Collection Time: 2.35629
Timestep Consumption Time: 2.42530
PPO Batch Consumption Time: 0.29317
Total Iteration Time: 4.78158

Cumulative Model Updates: 257,480
Cumulative Timesteps: 2,147,958,040

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2147958040...
Checkpoint 2147958040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 68,219.78734
Policy Entropy: 2.68199
Value Function Loss: 0.01060

Mean KL Divergence: 0.00738
SB3 Clip Fraction: 0.07010
Policy Update Magnitude: 0.30192
Value Function Update Magnitude: 0.28952

Collected Steps per Second: 20,913.79748
Overall Steps per Second: 10,540.48363

Timestep Collection Time: 2.39172
Timestep Consumption Time: 2.35379
PPO Batch Consumption Time: 0.27834
Total Iteration Time: 4.74551

Cumulative Model Updates: 257,486
Cumulative Timesteps: 2,148,008,060

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68,219.78734
Policy Entropy: 2.67479
Value Function Loss: 0.00974

Mean KL Divergence: 0.00725
SB3 Clip Fraction: 0.06907
Policy Update Magnitude: 0.29565
Value Function Update Magnitude: 0.26371

Collected Steps per Second: 21,516.93904
Overall Steps per Second: 10,480.02978

Timestep Collection Time: 2.32468
Timestep Consumption Time: 2.44821
PPO Batch Consumption Time: 0.27917
Total Iteration Time: 4.77289

Cumulative Model Updates: 257,492
Cumulative Timesteps: 2,148,058,080

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2148058080...
Checkpoint 2148058080 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 68,924.74115
Policy Entropy: 2.66537
Value Function Loss: 0.01121

Mean KL Divergence: 0.00702
SB3 Clip Fraction: 0.06607
Policy Update Magnitude: 0.30175
Value Function Update Magnitude: 0.27646

Collected Steps per Second: 21,938.77884
Overall Steps per Second: 10,635.92467

Timestep Collection Time: 2.28035
Timestep Consumption Time: 2.42334
PPO Batch Consumption Time: 0.27845
Total Iteration Time: 4.70368

Cumulative Model Updates: 257,498
Cumulative Timesteps: 2,148,108,108

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55,768.19208
Policy Entropy: 2.65787
Value Function Loss: 0.01164

Mean KL Divergence: 0.00697
SB3 Clip Fraction: 0.06352
Policy Update Magnitude: 0.30843
Value Function Update Magnitude: 0.32262

Collected Steps per Second: 22,083.99282
Overall Steps per Second: 10,551.82091

Timestep Collection Time: 2.26490
Timestep Consumption Time: 2.47533
PPO Batch Consumption Time: 0.29304
Total Iteration Time: 4.74022

Cumulative Model Updates: 257,504
Cumulative Timesteps: 2,148,158,126

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2148158126...
Checkpoint 2148158126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55,768.19208
Policy Entropy: 2.65021
Value Function Loss: 0.01172

Mean KL Divergence: 0.00699
SB3 Clip Fraction: 0.06252
Policy Update Magnitude: 0.31035
Value Function Update Magnitude: 0.32192

Collected Steps per Second: 21,749.64738
Overall Steps per Second: 10,590.84912

Timestep Collection Time: 2.29981
Timestep Consumption Time: 2.42314
PPO Batch Consumption Time: 0.27706
Total Iteration Time: 4.72295

Cumulative Model Updates: 257,510
Cumulative Timesteps: 2,148,208,146

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 71,451.39696
Policy Entropy: 2.66477
Value Function Loss: 0.01101

Mean KL Divergence: 0.00648
SB3 Clip Fraction: 0.06109
Policy Update Magnitude: 0.30356
Value Function Update Magnitude: 0.29178

Collected Steps per Second: 22,140.32756
Overall Steps per Second: 10,536.13941

Timestep Collection Time: 2.25941
Timestep Consumption Time: 2.48844
PPO Batch Consumption Time: 0.29131
Total Iteration Time: 4.74785

Cumulative Model Updates: 257,516
Cumulative Timesteps: 2,148,258,170

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2148258170...
Checkpoint 2148258170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 72,374.66704
Policy Entropy: 2.68910
Value Function Loss: 0.01085

Mean KL Divergence: 0.00565
SB3 Clip Fraction: 0.05223
Policy Update Magnitude: 0.30135
Value Function Update Magnitude: 0.28217

Collected Steps per Second: 22,027.70742
Overall Steps per Second: 10,518.61841

Timestep Collection Time: 2.27223
Timestep Consumption Time: 2.48619
PPO Batch Consumption Time: 0.28874
Total Iteration Time: 4.75842

Cumulative Model Updates: 257,522
Cumulative Timesteps: 2,148,308,222

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 104,699.95094
Policy Entropy: 2.71125
Value Function Loss: 0.01124

Mean KL Divergence: 0.00556
SB3 Clip Fraction: 0.05243
Policy Update Magnitude: 0.29996
Value Function Update Magnitude: 0.28512

Collected Steps per Second: 22,000.31829
Overall Steps per Second: 10,462.94504

Timestep Collection Time: 2.27279
Timestep Consumption Time: 2.50618
PPO Batch Consumption Time: 0.29217
Total Iteration Time: 4.77896

Cumulative Model Updates: 257,528
Cumulative Timesteps: 2,148,358,224

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2148358224...
Checkpoint 2148358224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 152,639.32998
Policy Entropy: 2.67792
Value Function Loss: 0.01248

Mean KL Divergence: 0.00716
SB3 Clip Fraction: 0.06689
Policy Update Magnitude: 0.30521
Value Function Update Magnitude: 0.29968

Collected Steps per Second: 21,466.17475
Overall Steps per Second: 10,542.41025

Timestep Collection Time: 2.33055
Timestep Consumption Time: 2.41485
PPO Batch Consumption Time: 0.27824
Total Iteration Time: 4.74540

Cumulative Model Updates: 257,534
Cumulative Timesteps: 2,148,408,252

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 130,178.58866
Policy Entropy: 2.67805
Value Function Loss: 0.01236

Mean KL Divergence: 0.00655
SB3 Clip Fraction: 0.05993
Policy Update Magnitude: 0.30956
Value Function Update Magnitude: 0.30668

Collected Steps per Second: 21,543.04389
Overall Steps per Second: 10,492.61182

Timestep Collection Time: 2.32121
Timestep Consumption Time: 2.44462
PPO Batch Consumption Time: 0.27857
Total Iteration Time: 4.76583

Cumulative Model Updates: 257,540
Cumulative Timesteps: 2,148,458,258

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2148458258...
Checkpoint 2148458258 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 115,015.09326
Policy Entropy: 2.67793
Value Function Loss: 0.01177

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.07028
Policy Update Magnitude: 0.30876
Value Function Update Magnitude: 0.30737

Collected Steps per Second: 21,638.26428
Overall Steps per Second: 10,280.22451

Timestep Collection Time: 2.31109
Timestep Consumption Time: 2.55339
PPO Batch Consumption Time: 0.29346
Total Iteration Time: 4.86449

Cumulative Model Updates: 257,546
Cumulative Timesteps: 2,148,508,266

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99,990.33826
Policy Entropy: 2.67554
Value Function Loss: 0.01329

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.06732
Policy Update Magnitude: 0.32374
Value Function Update Magnitude: 0.32424

Collected Steps per Second: 22,308.56418
Overall Steps per Second: 10,438.56076

Timestep Collection Time: 2.24335
Timestep Consumption Time: 2.55099
PPO Batch Consumption Time: 0.29366
Total Iteration Time: 4.79434

Cumulative Model Updates: 257,552
Cumulative Timesteps: 2,148,558,312

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 2148558312...
Checkpoint 2148558312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 105,390.00709
Policy Entropy: 2.67752
Value Function Loss: 0.01283

Mean KL Divergence: 0.00704
SB3 Clip Fraction: 0.06428
Policy Update Magnitude: 0.32465
Value Function Update Magnitude: 0.35171

Collected Steps per Second: 20,787.49502
Overall Steps per Second: 10,187.30949

Timestep Collection Time: 2.40597
Timestep Consumption Time: 2.50348
PPO Batch Consumption Time: 0.28975
Total Iteration Time: 4.90944

Cumulative Model Updates: 257,558
Cumulative Timesteps: 2,148,608,326

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79,331.11657
Policy Entropy: 2.69065
Value Function Loss: 0.01343

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.07159
Policy Update Magnitude: 0.30825
Value Function Update Magnitude: 0.34772

Collected Steps per Second: 21,782.37520
Overall Steps per Second: 10,447.76730

Timestep Collection Time: 2.29709
Timestep Consumption Time: 2.49207
PPO Batch Consumption Time: 0.28745
Total Iteration Time: 4.78916

Cumulative Model Updates: 257,564
Cumulative Timesteps: 2,148,658,362

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 2148658362...
Checkpoint 2148658362 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 79,331.11657
Policy Entropy: 2.71804
Value Function Loss: 0.01052

Mean KL Divergence: 0.00645
SB3 Clip Fraction: 0.06313
Policy Update Magnitude: 0.28850
Value Function Update Magnitude: 0.29302

Collected Steps per Second: 21,504.31387
Overall Steps per Second: 10,379.78662

Timestep Collection Time: 2.32567
Timestep Consumption Time: 2.49254
PPO Batch Consumption Time: 0.29098
Total Iteration Time: 4.81821

Cumulative Model Updates: 257,570
Cumulative Timesteps: 2,148,708,374

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86,587.11140
Policy Entropy: 2.74040
Value Function Loss: 0.01148

Mean KL Divergence: 0.00676
SB3 Clip Fraction: 0.06249
Policy Update Magnitude: 0.28216
Value Function Update Magnitude: 0.25313

Collected Steps per Second: 22,057.58416
Overall Steps per Second: 10,507.33412

Timestep Collection Time: 2.26752
Timestep Consumption Time: 2.49258
PPO Batch Consumption Time: 0.28853
Total Iteration Time: 4.76010

Cumulative Model Updates: 257,576
Cumulative Timesteps: 2,148,758,390

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2148758390...
Checkpoint 2148758390 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 95,608.28208
Policy Entropy: 2.72032
Value Function Loss: 0.01078

Mean KL Divergence: 0.00662
SB3 Clip Fraction: 0.06198
Policy Update Magnitude: 0.28489
Value Function Update Magnitude: 0.25014

Collected Steps per Second: 21,342.48306
Overall Steps per Second: 10,409.20314

Timestep Collection Time: 2.34359
Timestep Consumption Time: 2.46158
PPO Batch Consumption Time: 0.27795
Total Iteration Time: 4.80517

Cumulative Model Updates: 257,582
Cumulative Timesteps: 2,148,808,408

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86,920.64343
Policy Entropy: 2.70194
Value Function Loss: 0.01151

Mean KL Divergence: 0.00664
SB3 Clip Fraction: 0.06148
Policy Update Magnitude: 0.28531
Value Function Update Magnitude: 0.24983

Collected Steps per Second: 22,177.08789
Overall Steps per Second: 10,462.72028

Timestep Collection Time: 2.25539
Timestep Consumption Time: 2.52520
PPO Batch Consumption Time: 0.29303
Total Iteration Time: 4.78059

Cumulative Model Updates: 257,588
Cumulative Timesteps: 2,148,858,426

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2148858426...
Checkpoint 2148858426 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 103,034.79737
Policy Entropy: 2.67576
Value Function Loss: 0.01094

Mean KL Divergence: 0.00633
SB3 Clip Fraction: 0.05776
Policy Update Magnitude: 0.29036
Value Function Update Magnitude: 0.25246

Collected Steps per Second: 21,809.18217
Overall Steps per Second: 10,581.38973

Timestep Collection Time: 2.29399
Timestep Consumption Time: 2.43412
PPO Batch Consumption Time: 0.27790
Total Iteration Time: 4.72811

Cumulative Model Updates: 257,594
Cumulative Timesteps: 2,148,908,456

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 127,665.97866
Policy Entropy: 2.65771
Value Function Loss: 0.01307

Mean KL Divergence: 0.00670
SB3 Clip Fraction: 0.06116
Policy Update Magnitude: 0.29937
Value Function Update Magnitude: 0.27227

Collected Steps per Second: 22,302.70999
Overall Steps per Second: 10,510.84541

Timestep Collection Time: 2.24269
Timestep Consumption Time: 2.51602
PPO Batch Consumption Time: 0.29374
Total Iteration Time: 4.75870

Cumulative Model Updates: 257,600
Cumulative Timesteps: 2,148,958,474

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2148958474...
Checkpoint 2148958474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 105,757.19065
Policy Entropy: 2.65026
Value Function Loss: 0.01305

Mean KL Divergence: 0.00688
SB3 Clip Fraction: 0.06420
Policy Update Magnitude: 0.31718
Value Function Update Magnitude: 0.29416

Collected Steps per Second: 21,843.57979
Overall Steps per Second: 10,602.25247

Timestep Collection Time: 2.28900
Timestep Consumption Time: 2.42698
PPO Batch Consumption Time: 0.27893
Total Iteration Time: 4.71598

Cumulative Model Updates: 257,606
Cumulative Timesteps: 2,149,008,474

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 103,392.29588
Policy Entropy: 2.66655
Value Function Loss: 0.01275

Mean KL Divergence: 0.00734
SB3 Clip Fraction: 0.06790
Policy Update Magnitude: 0.30885
Value Function Update Magnitude: 0.31032

Collected Steps per Second: 22,185.19318
Overall Steps per Second: 10,473.85909

Timestep Collection Time: 2.25439
Timestep Consumption Time: 2.52074
PPO Batch Consumption Time: 0.29317
Total Iteration Time: 4.77513

Cumulative Model Updates: 257,612
Cumulative Timesteps: 2,149,058,488

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2149058488...
Checkpoint 2149058488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 140,931.75023
Policy Entropy: 2.67277
Value Function Loss: 0.01058

Mean KL Divergence: 0.00732
SB3 Clip Fraction: 0.06428
Policy Update Magnitude: 0.30915
Value Function Update Magnitude: 0.30115

Collected Steps per Second: 21,712.58467
Overall Steps per Second: 10,586.35071

Timestep Collection Time: 2.30373
Timestep Consumption Time: 2.42122
PPO Batch Consumption Time: 0.27768
Total Iteration Time: 4.72495

Cumulative Model Updates: 257,618
Cumulative Timesteps: 2,149,108,508

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 103,446.81768
Policy Entropy: 2.69937
Value Function Loss: 0.01096

Mean KL Divergence: 0.00694
SB3 Clip Fraction: 0.06136
Policy Update Magnitude: 0.29832
Value Function Update Magnitude: 0.30526

Collected Steps per Second: 21,843.58094
Overall Steps per Second: 10,534.98310

Timestep Collection Time: 2.28964
Timestep Consumption Time: 2.45778
PPO Batch Consumption Time: 0.28322
Total Iteration Time: 4.74742

Cumulative Model Updates: 257,624
Cumulative Timesteps: 2,149,158,522

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2149158522...
Checkpoint 2149158522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 115,751.36950
Policy Entropy: 2.70065
Value Function Loss: 0.01055

Mean KL Divergence: 0.00724
SB3 Clip Fraction: 0.06416
Policy Update Magnitude: 0.29378
Value Function Update Magnitude: 0.30151

Collected Steps per Second: 21,682.84715
Overall Steps per Second: 10,567.53432

Timestep Collection Time: 2.30662
Timestep Consumption Time: 2.42618
PPO Batch Consumption Time: 0.27778
Total Iteration Time: 4.73280

Cumulative Model Updates: 257,630
Cumulative Timesteps: 2,149,208,536

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 120,771.80172
Policy Entropy: 2.69750
Value Function Loss: 0.01086

Mean KL Divergence: 0.00629
SB3 Clip Fraction: 0.05911
Policy Update Magnitude: 0.29918
Value Function Update Magnitude: 0.29047

Collected Steps per Second: 21,602.74616
Overall Steps per Second: 10,501.28167

Timestep Collection Time: 2.31526
Timestep Consumption Time: 2.44759
PPO Batch Consumption Time: 0.27894
Total Iteration Time: 4.76285

Cumulative Model Updates: 257,636
Cumulative Timesteps: 2,149,258,552

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2149258552...
Checkpoint 2149258552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 107,378.95133
Policy Entropy: 2.67794
Value Function Loss: 0.01106

Mean KL Divergence: 0.00731
SB3 Clip Fraction: 0.06630
Policy Update Magnitude: 0.29996
Value Function Update Magnitude: 0.28386

Collected Steps per Second: 21,312.27103
Overall Steps per Second: 10,268.77424

Timestep Collection Time: 2.34747
Timestep Consumption Time: 2.52458
PPO Batch Consumption Time: 0.29321
Total Iteration Time: 4.87205

Cumulative Model Updates: 257,642
Cumulative Timesteps: 2,149,308,582

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88,106.45473
Policy Entropy: 2.68693
Value Function Loss: 0.01110

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.06739
Policy Update Magnitude: 0.29797
Value Function Update Magnitude: 0.28683

Collected Steps per Second: 21,895.12166
Overall Steps per Second: 10,425.85454

Timestep Collection Time: 2.28462
Timestep Consumption Time: 2.51326
PPO Batch Consumption Time: 0.29315
Total Iteration Time: 4.79788

Cumulative Model Updates: 257,648
Cumulative Timesteps: 2,149,358,604

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2149358604...
Checkpoint 2149358604 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 67,518.75738
Policy Entropy: 2.68701
Value Function Loss: 0.01368

Mean KL Divergence: 0.00682
SB3 Clip Fraction: 0.06276
Policy Update Magnitude: 0.30345
Value Function Update Magnitude: 0.28858

Collected Steps per Second: 21,958.49713
Overall Steps per Second: 10,548.52966

Timestep Collection Time: 2.27875
Timestep Consumption Time: 2.46485
PPO Batch Consumption Time: 0.27890
Total Iteration Time: 4.74360

Cumulative Model Updates: 257,654
Cumulative Timesteps: 2,149,408,642

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49,523.73484
Policy Entropy: 2.69462
Value Function Loss: 0.01367

Mean KL Divergence: 0.00680
SB3 Clip Fraction: 0.06376
Policy Update Magnitude: 0.30726
Value Function Update Magnitude: 0.26249

Collected Steps per Second: 22,249.22630
Overall Steps per Second: 10,422.54487

Timestep Collection Time: 2.24781
Timestep Consumption Time: 2.55064
PPO Batch Consumption Time: 0.29525
Total Iteration Time: 4.79844

Cumulative Model Updates: 257,660
Cumulative Timesteps: 2,149,458,654

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2149458654...
Checkpoint 2149458654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 72,800.48553
Policy Entropy: 2.67424
Value Function Loss: 0.01265

Mean KL Divergence: 0.00695
SB3 Clip Fraction: 0.06676
Policy Update Magnitude: 0.29481
Value Function Update Magnitude: 0.26298

Collected Steps per Second: 21,981.23423
Overall Steps per Second: 10,640.99221

Timestep Collection Time: 2.27494
Timestep Consumption Time: 2.42443
PPO Batch Consumption Time: 0.27903
Total Iteration Time: 4.69937

Cumulative Model Updates: 257,666
Cumulative Timesteps: 2,149,508,660

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 118,863.88598
Policy Entropy: 2.67412
Value Function Loss: 0.01171

Mean KL Divergence: 0.00613
SB3 Clip Fraction: 0.05706
Policy Update Magnitude: 0.29533
Value Function Update Magnitude: 0.24705

Collected Steps per Second: 22,402.09016
Overall Steps per Second: 10,532.34425

Timestep Collection Time: 2.23310
Timestep Consumption Time: 2.51665
PPO Batch Consumption Time: 0.29342
Total Iteration Time: 4.74975

Cumulative Model Updates: 257,672
Cumulative Timesteps: 2,149,558,686

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2149558686...
Checkpoint 2149558686 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 165,393.78254
Policy Entropy: 2.67096
Value Function Loss: 0.01087

Mean KL Divergence: 0.00591
SB3 Clip Fraction: 0.05396
Policy Update Magnitude: 0.29404
Value Function Update Magnitude: 0.25801

Collected Steps per Second: 21,991.79612
Overall Steps per Second: 10,633.17450

Timestep Collection Time: 2.27548
Timestep Consumption Time: 2.43073
PPO Batch Consumption Time: 0.27871
Total Iteration Time: 4.70621

Cumulative Model Updates: 257,678
Cumulative Timesteps: 2,149,608,728

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 183,003.23273
Policy Entropy: 2.67798
Value Function Loss: 0.01084

Mean KL Divergence: 0.00591
SB3 Clip Fraction: 0.05261
Policy Update Magnitude: 0.28077
Value Function Update Magnitude: 0.25759

Collected Steps per Second: 22,216.81456
Overall Steps per Second: 10,528.30443

Timestep Collection Time: 2.25154
Timestep Consumption Time: 2.49965
PPO Batch Consumption Time: 0.29287
Total Iteration Time: 4.75119

Cumulative Model Updates: 257,684
Cumulative Timesteps: 2,149,658,750

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2149658750...
Checkpoint 2149658750 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 171,374.78416
Policy Entropy: 2.69758
Value Function Loss: 0.01071

Mean KL Divergence: 0.00542
SB3 Clip Fraction: 0.05262
Policy Update Magnitude: 0.27946
Value Function Update Magnitude: 0.23813

Collected Steps per Second: 21,739.00945
Overall Steps per Second: 10,578.76173

Timestep Collection Time: 2.30001
Timestep Consumption Time: 2.42644
PPO Batch Consumption Time: 0.27853
Total Iteration Time: 4.72645

Cumulative Model Updates: 257,690
Cumulative Timesteps: 2,149,708,750

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 152,989.71371
Policy Entropy: 2.66667
Value Function Loss: 0.01077

Mean KL Divergence: 0.00657
SB3 Clip Fraction: 0.06358
Policy Update Magnitude: 0.29101
Value Function Update Magnitude: 0.21232

Collected Steps per Second: 21,838.50990
Overall Steps per Second: 10,477.01471

Timestep Collection Time: 2.28953
Timestep Consumption Time: 2.48282
PPO Batch Consumption Time: 0.28633
Total Iteration Time: 4.77235

Cumulative Model Updates: 257,696
Cumulative Timesteps: 2,149,758,750

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2149758750...
Checkpoint 2149758750 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 120,473.79953
Policy Entropy: 2.66121
Value Function Loss: 0.01229

Mean KL Divergence: 0.00640
SB3 Clip Fraction: 0.05967
Policy Update Magnitude: 0.29464
Value Function Update Magnitude: 0.22810

Collected Steps per Second: 21,770.86099
Overall Steps per Second: 10,591.68477

Timestep Collection Time: 2.29665
Timestep Consumption Time: 2.42404
PPO Batch Consumption Time: 0.27742
Total Iteration Time: 4.72068

Cumulative Model Updates: 257,702
Cumulative Timesteps: 2,149,808,750

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92,965.55043
Policy Entropy: 2.65052
Value Function Loss: 0.01369

Mean KL Divergence: 0.00657
SB3 Clip Fraction: 0.05675
Policy Update Magnitude: 0.31002
Value Function Update Magnitude: 0.28768

Collected Steps per Second: 21,929.65929
Overall Steps per Second: 10,488.25084

Timestep Collection Time: 2.28221
Timestep Consumption Time: 2.48961
PPO Batch Consumption Time: 0.28557
Total Iteration Time: 4.77182

Cumulative Model Updates: 257,708
Cumulative Timesteps: 2,149,858,798

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 2149858798...
Checkpoint 2149858798 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 91,065.95400
Policy Entropy: 2.66703
Value Function Loss: 0.01285

Mean KL Divergence: 0.00743
SB3 Clip Fraction: 0.06428
Policy Update Magnitude: 0.31183
Value Function Update Magnitude: 0.32357

Collected Steps per Second: 21,823.73238
Overall Steps per Second: 10,388.37166

Timestep Collection Time: 2.29127
Timestep Consumption Time: 2.52219
PPO Batch Consumption Time: 0.28909
Total Iteration Time: 4.81346

Cumulative Model Updates: 257,714
Cumulative Timesteps: 2,149,908,802

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88,446.13538
Policy Entropy: 2.69526
Value Function Loss: 0.01172

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.06959
Policy Update Magnitude: 0.29116
Value Function Update Magnitude: 0.28188

Collected Steps per Second: 22,296.64342
Overall Steps per Second: 10,656.09323

Timestep Collection Time: 2.24339
Timestep Consumption Time: 2.45064
PPO Batch Consumption Time: 0.27774
Total Iteration Time: 4.69403

Cumulative Model Updates: 257,720
Cumulative Timesteps: 2,149,958,822

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2149958822...
Checkpoint 2149958822 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 93,424.44341
Policy Entropy: 2.71072
Value Function Loss: 0.00994

Mean KL Divergence: 0.00619
SB3 Clip Fraction: 0.05596
Policy Update Magnitude: 0.27241
Value Function Update Magnitude: 0.23467

Collected Steps per Second: 22,286.42712
Overall Steps per Second: 10,735.79008

Timestep Collection Time: 2.24576
Timestep Consumption Time: 2.41621
PPO Batch Consumption Time: 0.27701
Total Iteration Time: 4.66198

Cumulative Model Updates: 257,726
Cumulative Timesteps: 2,150,008,872

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85,142.94401
Policy Entropy: 2.71982
Value Function Loss: 0.00965

Mean KL Divergence: 0.00544
SB3 Clip Fraction: 0.05231
Policy Update Magnitude: 0.26476
Value Function Update Magnitude: 0.22385

Collected Steps per Second: 22,308.18322
Overall Steps per Second: 10,543.45204

Timestep Collection Time: 2.24169
Timestep Consumption Time: 2.50135
PPO Batch Consumption Time: 0.29132
Total Iteration Time: 4.74304

Cumulative Model Updates: 257,732
Cumulative Timesteps: 2,150,058,880

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2150058880...
Checkpoint 2150058880 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86,461.12045
Policy Entropy: 2.70365
Value Function Loss: 0.00893

Mean KL Divergence: 0.00579
SB3 Clip Fraction: 0.05495
Policy Update Magnitude: 0.27419
Value Function Update Magnitude: 0.21608

Collected Steps per Second: 21,877.40320
Overall Steps per Second: 10,532.80583

Timestep Collection Time: 2.28693
Timestep Consumption Time: 2.46319
PPO Batch Consumption Time: 0.28508
Total Iteration Time: 4.75011

Cumulative Model Updates: 257,738
Cumulative Timesteps: 2,150,108,912

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76,846.06462
Policy Entropy: 2.70700
Value Function Loss: 0.00902

Mean KL Divergence: 0.00635
SB3 Clip Fraction: 0.05466
Policy Update Magnitude: 0.27782
Value Function Update Magnitude: 0.21028

Collected Steps per Second: 22,435.07787
Overall Steps per Second: 10,638.84787

Timestep Collection Time: 2.23070
Timestep Consumption Time: 2.47338
PPO Batch Consumption Time: 0.28846
Total Iteration Time: 4.70408

Cumulative Model Updates: 257,744
Cumulative Timesteps: 2,150,158,958

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 2150158958...
Checkpoint 2150158958 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 98,899.48082
Policy Entropy: 2.69431
Value Function Loss: 0.01010

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.06593
Policy Update Magnitude: 0.27486
Value Function Update Magnitude: 0.20705

Collected Steps per Second: 21,887.14273
Overall Steps per Second: 10,457.67529

Timestep Collection Time: 2.28691
Timestep Consumption Time: 2.49943
PPO Batch Consumption Time: 0.28967
Total Iteration Time: 4.78634

Cumulative Model Updates: 257,750
Cumulative Timesteps: 2,150,209,012

Timesteps Collected: 50,054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 98,899.48082
Policy Entropy: 2.70856
Value Function Loss: 0.00948

Mean KL Divergence: 0.00618
SB3 Clip Fraction: 0.05538
Policy Update Magnitude: 0.27261
Value Function Update Magnitude: 0.19262

Collected Steps per Second: 21,331.20326
Overall Steps per Second: 10,425.17175

Timestep Collection Time: 2.34408
Timestep Consumption Time: 2.45220
PPO Batch Consumption Time: 0.27930
Total Iteration Time: 4.79628

Cumulative Model Updates: 257,756
Cumulative Timesteps: 2,150,259,014

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2150259014...
Checkpoint 2150259014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 129,139.98495
Policy Entropy: 2.67884
Value Function Loss: 0.01056

Mean KL Divergence: 0.00575
SB3 Clip Fraction: 0.05603
Policy Update Magnitude: 0.27649
Value Function Update Magnitude: 0.17200

Collected Steps per Second: 21,296.93170
Overall Steps per Second: 10,334.92924

Timestep Collection Time: 2.34832
Timestep Consumption Time: 2.49080
PPO Batch Consumption Time: 0.29242
Total Iteration Time: 4.83912

Cumulative Model Updates: 257,762
Cumulative Timesteps: 2,150,309,026

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 115,609.95959
Policy Entropy: 2.67693
Value Function Loss: 0.00987

Mean KL Divergence: 0.00631
SB3 Clip Fraction: 0.05990
Policy Update Magnitude: 0.28135
Value Function Update Magnitude: 0.18307

Collected Steps per Second: 21,829.84758
Overall Steps per Second: 10,414.85174

Timestep Collection Time: 2.29246
Timestep Consumption Time: 2.51260
PPO Batch Consumption Time: 0.29295
Total Iteration Time: 4.80506

Cumulative Model Updates: 257,768
Cumulative Timesteps: 2,150,359,070

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 2150359070...
Checkpoint 2150359070 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 113,359.94650
Policy Entropy: 2.68528
Value Function Loss: 0.01042

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.07369
Policy Update Magnitude: 0.28122
Value Function Update Magnitude: 0.20885

Collected Steps per Second: 22,106.23425
Overall Steps per Second: 10,560.12107

Timestep Collection Time: 2.26181
Timestep Consumption Time: 2.47299
PPO Batch Consumption Time: 0.27948
Total Iteration Time: 4.73479

Cumulative Model Updates: 257,774
Cumulative Timesteps: 2,150,409,070

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83,869.43588
Policy Entropy: 2.71423
Value Function Loss: 0.01101

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.07466
Policy Update Magnitude: 0.28572
Value Function Update Magnitude: 0.24003

Collected Steps per Second: 21,698.31619
Overall Steps per Second: 10,529.55760

Timestep Collection Time: 2.30525
Timestep Consumption Time: 2.44519
PPO Batch Consumption Time: 0.29268
Total Iteration Time: 4.75044

Cumulative Model Updates: 257,780
Cumulative Timesteps: 2,150,459,090

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2150459090...
Checkpoint 2150459090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 134,881.23998
Policy Entropy: 2.73203
Value Function Loss: 0.01094

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.07324
Policy Update Magnitude: 0.28708
Value Function Update Magnitude: 0.29362

Collected Steps per Second: 21,035.54222
Overall Steps per Second: 10,563.56807

Timestep Collection Time: 2.37759
Timestep Consumption Time: 2.35698
PPO Batch Consumption Time: 0.27829
Total Iteration Time: 4.73457

Cumulative Model Updates: 257,786
Cumulative Timesteps: 2,150,509,104

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93,476.87843
Policy Entropy: 2.73776
Value Function Loss: 0.01041

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.08428
Policy Update Magnitude: 0.27996
Value Function Update Magnitude: 0.29322

Collected Steps per Second: 21,189.26677
Overall Steps per Second: 10,456.87308

Timestep Collection Time: 2.36072
Timestep Consumption Time: 2.42292
PPO Batch Consumption Time: 0.29071
Total Iteration Time: 4.78365

Cumulative Model Updates: 257,792
Cumulative Timesteps: 2,150,559,126

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2150559126...
Checkpoint 2150559126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 147,830.11116
Policy Entropy: 2.73884
Value Function Loss: 0.00975

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.09008
Policy Update Magnitude: 0.27958
Value Function Update Magnitude: 0.26480

Collected Steps per Second: 21,344.59874
Overall Steps per Second: 10,609.86932

Timestep Collection Time: 2.34279
Timestep Consumption Time: 2.37036
PPO Batch Consumption Time: 0.27883
Total Iteration Time: 4.71316

Cumulative Model Updates: 257,798
Cumulative Timesteps: 2,150,609,132

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 140,887.74325
Policy Entropy: 2.72818
Value Function Loss: 0.00981

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.07801
Policy Update Magnitude: 0.27884
Value Function Update Magnitude: 0.23347

Collected Steps per Second: 21,036.91477
Overall Steps per Second: 10,439.73562

Timestep Collection Time: 2.37801
Timestep Consumption Time: 2.41387
PPO Batch Consumption Time: 0.27847
Total Iteration Time: 4.79188

Cumulative Model Updates: 257,804
Cumulative Timesteps: 2,150,659,158

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2150659158...
Checkpoint 2150659158 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 140,887.74325
Policy Entropy: 2.73523
Value Function Loss: 0.00856

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.07239
Policy Update Magnitude: 0.26873
Value Function Update Magnitude: 0.21982

Collected Steps per Second: 21,174.56197
Overall Steps per Second: 10,320.76296

Timestep Collection Time: 2.36180
Timestep Consumption Time: 2.48378
PPO Batch Consumption Time: 0.29324
Total Iteration Time: 4.84557

Cumulative Model Updates: 257,810
Cumulative Timesteps: 2,150,709,168

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 140,887.74325
Policy Entropy: 2.72293
Value Function Loss: 0.00882

Mean KL Divergence: 0.00692
SB3 Clip Fraction: 0.06428
Policy Update Magnitude: 0.26663
Value Function Update Magnitude: 0.20306

Collected Steps per Second: 21,630.71816
Overall Steps per Second: 10,390.12180

Timestep Collection Time: 2.31273
Timestep Consumption Time: 2.50204
PPO Batch Consumption Time: 0.28989
Total Iteration Time: 4.81477

Cumulative Model Updates: 257,816
Cumulative Timesteps: 2,150,759,194

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2150759194...
Checkpoint 2150759194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 133,175.20380
Policy Entropy: 2.72381
Value Function Loss: 0.00955

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.07463
Policy Update Magnitude: 0.27879
Value Function Update Magnitude: 0.21213

Collected Steps per Second: 21,517.72582
Overall Steps per Second: 10,377.62630

Timestep Collection Time: 2.32460
Timestep Consumption Time: 2.49539
PPO Batch Consumption Time: 0.29089
Total Iteration Time: 4.81998

Cumulative Model Updates: 257,822
Cumulative Timesteps: 2,150,809,214

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 161,450.62025
Policy Entropy: 2.70079
Value Function Loss: 0.01168

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.08369
Policy Update Magnitude: 0.29916
Value Function Update Magnitude: 0.29201

Collected Steps per Second: 21,764.01140
Overall Steps per Second: 10,383.61179

Timestep Collection Time: 2.29921
Timestep Consumption Time: 2.51992
PPO Batch Consumption Time: 0.29231
Total Iteration Time: 4.81913

Cumulative Model Updates: 257,828
Cumulative Timesteps: 2,150,859,254

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 2150859254...
Checkpoint 2150859254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 153,923.95138
Policy Entropy: 2.69193
Value Function Loss: 0.01302

Mean KL Divergence: 0.01303
SB3 Clip Fraction: 0.09987
Policy Update Magnitude: 0.31233
Value Function Update Magnitude: 0.32592

Collected Steps per Second: 21,669.12965
Overall Steps per Second: 10,465.76505

Timestep Collection Time: 2.30771
Timestep Consumption Time: 2.47035
PPO Batch Consumption Time: 0.27788
Total Iteration Time: 4.77805

Cumulative Model Updates: 257,834
Cumulative Timesteps: 2,150,909,260

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 127,305.72959
Policy Entropy: 2.69270
Value Function Loss: 0.01194

Mean KL Divergence: 0.01911
SB3 Clip Fraction: 0.13871
Policy Update Magnitude: 0.30963
Value Function Update Magnitude: 0.35981

Collected Steps per Second: 22,221.91905
Overall Steps per Second: 10,517.09506

Timestep Collection Time: 2.25030
Timestep Consumption Time: 2.50443
PPO Batch Consumption Time: 0.28813
Total Iteration Time: 4.75474

Cumulative Model Updates: 257,840
Cumulative Timesteps: 2,150,959,266

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2150959266...
Checkpoint 2150959266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 106,667.05794
Policy Entropy: 2.68518
Value Function Loss: 0.01062

Mean KL Divergence: 0.01479
SB3 Clip Fraction: 0.11692
Policy Update Magnitude: 0.30393
Value Function Update Magnitude: 0.34447

Collected Steps per Second: 22,084.22159
Overall Steps per Second: 10,635.29585

Timestep Collection Time: 2.26497
Timestep Consumption Time: 2.43824
PPO Batch Consumption Time: 0.27873
Total Iteration Time: 4.70321

Cumulative Model Updates: 257,846
Cumulative Timesteps: 2,151,009,286

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 144,986.52322
Policy Entropy: 2.69353
Value Function Loss: 0.01012

Mean KL Divergence: 0.01265
SB3 Clip Fraction: 0.10413
Policy Update Magnitude: 0.29367
Value Function Update Magnitude: 0.31596

Collected Steps per Second: 22,006.83460
Overall Steps per Second: 10,471.32676

Timestep Collection Time: 2.27220
Timestep Consumption Time: 2.50312
PPO Batch Consumption Time: 0.29249
Total Iteration Time: 4.77533

Cumulative Model Updates: 257,852
Cumulative Timesteps: 2,151,059,290

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2151059290...
Checkpoint 2151059290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 132,762.55266
Policy Entropy: 2.69523
Value Function Loss: 0.01055

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.08709
Policy Update Magnitude: 0.30314
Value Function Update Magnitude: 0.33979

Collected Steps per Second: 21,721.90902
Overall Steps per Second: 10,561.91410

Timestep Collection Time: 2.30274
Timestep Consumption Time: 2.43314
PPO Batch Consumption Time: 0.27954
Total Iteration Time: 4.73588

Cumulative Model Updates: 257,858
Cumulative Timesteps: 2,151,109,310

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 108,253.91324
Policy Entropy: 2.72301
Value Function Loss: 0.01140

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.08211
Policy Update Magnitude: 0.29806
Value Function Update Magnitude: 0.32837

Collected Steps per Second: 21,860.27534
Overall Steps per Second: 10,531.20741

Timestep Collection Time: 2.28817
Timestep Consumption Time: 2.46152
PPO Batch Consumption Time: 0.28452
Total Iteration Time: 4.74969

Cumulative Model Updates: 257,864
Cumulative Timesteps: 2,151,159,330

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2151159330...
Checkpoint 2151159330 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 78,410.78008
Policy Entropy: 2.73377
Value Function Loss: 0.01439

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.06946
Policy Update Magnitude: 0.30143
Value Function Update Magnitude: 0.30970

Collected Steps per Second: 21,767.04413
Overall Steps per Second: 10,583.39634

Timestep Collection Time: 2.29714
Timestep Consumption Time: 2.42743
PPO Batch Consumption Time: 0.27789
Total Iteration Time: 4.72457

Cumulative Model Updates: 257,870
Cumulative Timesteps: 2,151,209,332

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 135,634.98006
Policy Entropy: 2.73505
Value Function Loss: 0.01423

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.08477
Policy Update Magnitude: 0.30691
Value Function Update Magnitude: 0.32348

Collected Steps per Second: 21,193.67976
Overall Steps per Second: 10,429.60111

Timestep Collection Time: 2.35919
Timestep Consumption Time: 2.43485
PPO Batch Consumption Time: 0.27892
Total Iteration Time: 4.79405

Cumulative Model Updates: 257,876
Cumulative Timesteps: 2,151,259,332

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2151259332...
Checkpoint 2151259332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 93,324.25513
Policy Entropy: 2.72440
Value Function Loss: 0.01298

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.08813
Policy Update Magnitude: 0.30406
Value Function Update Magnitude: 0.34725

Collected Steps per Second: 21,358.69231
Overall Steps per Second: 10,296.43685

Timestep Collection Time: 2.34293
Timestep Consumption Time: 2.51719
PPO Batch Consumption Time: 0.29378
Total Iteration Time: 4.86013

Cumulative Model Updates: 257,882
Cumulative Timesteps: 2,151,309,374

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88,963.96662
Policy Entropy: 2.71273
Value Function Loss: 0.01246

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.07615
Policy Update Magnitude: 0.30225
Value Function Update Magnitude: 0.35781

Collected Steps per Second: 21,686.09732
Overall Steps per Second: 10,456.11329

Timestep Collection Time: 2.30627
Timestep Consumption Time: 2.47696
PPO Batch Consumption Time: 0.28751
Total Iteration Time: 4.78323

Cumulative Model Updates: 257,888
Cumulative Timesteps: 2,151,359,388

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2151359388...
Checkpoint 2151359388 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 73,109.14375
Policy Entropy: 2.71896
Value Function Loss: 0.01132

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.07375
Policy Update Magnitude: 0.30337
Value Function Update Magnitude: 0.34060

Collected Steps per Second: 21,419.45502
Overall Steps per Second: 10,533.36752

Timestep Collection Time: 2.33582
Timestep Consumption Time: 2.41404
PPO Batch Consumption Time: 0.27825
Total Iteration Time: 4.74986

Cumulative Model Updates: 257,894
Cumulative Timesteps: 2,151,409,420

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 73,109.14375
Policy Entropy: 2.72526
Value Function Loss: 0.01034

Mean KL Divergence: 0.00658
SB3 Clip Fraction: 0.06204
Policy Update Magnitude: 0.29526
Value Function Update Magnitude: 0.31498

Collected Steps per Second: 21,761.16549
Overall Steps per Second: 10,538.18245

Timestep Collection Time: 2.29831
Timestep Consumption Time: 2.44767
PPO Batch Consumption Time: 0.27921
Total Iteration Time: 4.74598

Cumulative Model Updates: 257,900
Cumulative Timesteps: 2,151,459,434

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2151459434...
Checkpoint 2151459434 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 113,136.89885
Policy Entropy: 2.72278
Value Function Loss: 0.01129

Mean KL Divergence: 0.00562
SB3 Clip Fraction: 0.05425
Policy Update Magnitude: 0.30073
Value Function Update Magnitude: 0.28027

Collected Steps per Second: 21,449.69958
Overall Steps per Second: 10,581.11603

Timestep Collection Time: 2.33243
Timestep Consumption Time: 2.39580
PPO Batch Consumption Time: 0.27887
Total Iteration Time: 4.72823

Cumulative Model Updates: 257,906
Cumulative Timesteps: 2,151,509,464

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92,996.54382
Policy Entropy: 2.70260
Value Function Loss: 0.01193

Mean KL Divergence: 0.00676
SB3 Clip Fraction: 0.06313
Policy Update Magnitude: 0.30628
Value Function Update Magnitude: 0.34133

Collected Steps per Second: 21,268.25626
Overall Steps per Second: 10,491.14471

Timestep Collection Time: 2.35205
Timestep Consumption Time: 2.41616
PPO Batch Consumption Time: 0.28754
Total Iteration Time: 4.76821

Cumulative Model Updates: 257,912
Cumulative Timesteps: 2,151,559,488

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2151559488...
Checkpoint 2151559488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 77,875.41055
Policy Entropy: 2.69829
Value Function Loss: 0.01228

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.07175
Policy Update Magnitude: 0.31081
Value Function Update Magnitude: 0.38664

Collected Steps per Second: 21,051.97236
Overall Steps per Second: 10,293.07568

Timestep Collection Time: 2.37602
Timestep Consumption Time: 2.48355
PPO Batch Consumption Time: 0.29362
Total Iteration Time: 4.85958

Cumulative Model Updates: 257,918
Cumulative Timesteps: 2,151,609,508

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77,875.41055
Policy Entropy: 2.72655
Value Function Loss: 0.01016

Mean KL Divergence: 0.00712
SB3 Clip Fraction: 0.06777
Policy Update Magnitude: 0.30085
Value Function Update Magnitude: 0.35764

Collected Steps per Second: 22,217.13203
Overall Steps per Second: 10,734.30043

Timestep Collection Time: 2.25052
Timestep Consumption Time: 2.40745
PPO Batch Consumption Time: 0.27939
Total Iteration Time: 4.65797

Cumulative Model Updates: 257,924
Cumulative Timesteps: 2,151,659,508

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2151659508...
Checkpoint 2151659508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 73,682.92977
Policy Entropy: 2.71252
Value Function Loss: 0.01055

Mean KL Divergence: 0.00740
SB3 Clip Fraction: 0.07046
Policy Update Magnitude: 0.29809
Value Function Update Magnitude: 0.34500

Collected Steps per Second: 21,916.15868
Overall Steps per Second: 10,662.06566

Timestep Collection Time: 2.28142
Timestep Consumption Time: 2.40810
PPO Batch Consumption Time: 0.27846
Total Iteration Time: 4.68952

Cumulative Model Updates: 257,930
Cumulative Timesteps: 2,151,709,508

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90,794.99207
Policy Entropy: 2.70987
Value Function Loss: 0.00979

Mean KL Divergence: 0.00643
SB3 Clip Fraction: 0.05920
Policy Update Magnitude: 0.29639
Value Function Update Magnitude: 0.31405

Collected Steps per Second: 22,158.73379
Overall Steps per Second: 10,527.64928

Timestep Collection Time: 2.25735
Timestep Consumption Time: 2.49395
PPO Batch Consumption Time: 0.28972
Total Iteration Time: 4.75130

Cumulative Model Updates: 257,936
Cumulative Timesteps: 2,151,759,528

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2151759528...
Checkpoint 2151759528 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 90,794.99207
Policy Entropy: 2.70004
Value Function Loss: 0.00978

Mean KL Divergence: 0.00605
SB3 Clip Fraction: 0.05414
Policy Update Magnitude: 0.29294
Value Function Update Magnitude: 0.31762

Collected Steps per Second: 21,899.27376
Overall Steps per Second: 10,631.29195

Timestep Collection Time: 2.28373
Timestep Consumption Time: 2.42050
PPO Batch Consumption Time: 0.27824
Total Iteration Time: 4.70423

Cumulative Model Updates: 257,942
Cumulative Timesteps: 2,151,809,540

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90,794.99207
Policy Entropy: 2.72369
Value Function Loss: 0.00849

Mean KL Divergence: 0.00551
SB3 Clip Fraction: 0.05193
Policy Update Magnitude: 0.27977
Value Function Update Magnitude: 0.27401

Collected Steps per Second: 21,247.16041
Overall Steps per Second: 10,421.04531

Timestep Collection Time: 2.35439
Timestep Consumption Time: 2.44590
PPO Batch Consumption Time: 0.27898
Total Iteration Time: 4.80029

Cumulative Model Updates: 257,948
Cumulative Timesteps: 2,151,859,564

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2151859564...
Checkpoint 2151859564 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 90,794.99207
Policy Entropy: 2.74065
Value Function Loss: 0.00808

Mean KL Divergence: 0.00539
SB3 Clip Fraction: 0.05304
Policy Update Magnitude: 0.26339
Value Function Update Magnitude: 0.22403

Collected Steps per Second: 21,350.62626
Overall Steps per Second: 10,311.67148

Timestep Collection Time: 2.34251
Timestep Consumption Time: 2.50772
PPO Batch Consumption Time: 0.29379
Total Iteration Time: 4.85023

Cumulative Model Updates: 257,954
Cumulative Timesteps: 2,151,909,578

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90,794.99207
Policy Entropy: 2.73578
Value Function Loss: 0.00861

Mean KL Divergence: 0.00526
SB3 Clip Fraction: 0.05065
Policy Update Magnitude: 0.26496
Value Function Update Magnitude: 0.21097

Collected Steps per Second: 21,356.22438
Overall Steps per Second: 10,418.09280

Timestep Collection Time: 2.34311
Timestep Consumption Time: 2.46007
PPO Batch Consumption Time: 0.28509
Total Iteration Time: 4.80318

Cumulative Model Updates: 257,960
Cumulative Timesteps: 2,151,959,618

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 2151959618...
Checkpoint 2151959618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 135,376.57720
Policy Entropy: 2.69467
Value Function Loss: 0.00991

Mean KL Divergence: 0.00598
SB3 Clip Fraction: 0.05673
Policy Update Magnitude: 0.28726
Value Function Update Magnitude: 0.23432

Collected Steps per Second: 21,738.24831
Overall Steps per Second: 10,604.81303

Timestep Collection Time: 2.30175
Timestep Consumption Time: 2.41649
PPO Batch Consumption Time: 0.27839
Total Iteration Time: 4.71823

Cumulative Model Updates: 257,966
Cumulative Timesteps: 2,152,009,654

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 142,716.11134
Policy Entropy: 2.68781
Value Function Loss: 0.01042

Mean KL Divergence: 0.00708
SB3 Clip Fraction: 0.06536
Policy Update Magnitude: 0.29911
Value Function Update Magnitude: 0.26499

Collected Steps per Second: 21,404.44953
Overall Steps per Second: 10,459.07232

Timestep Collection Time: 2.33596
Timestep Consumption Time: 2.44458
PPO Batch Consumption Time: 0.28894
Total Iteration Time: 4.78054

Cumulative Model Updates: 257,972
Cumulative Timesteps: 2,152,059,654

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2152059654...
Checkpoint 2152059654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 136,908.03200
Policy Entropy: 2.68345
Value Function Loss: 0.01048

Mean KL Divergence: 0.00717
SB3 Clip Fraction: 0.06510
Policy Update Magnitude: 0.29688
Value Function Update Magnitude: 0.24945

Collected Steps per Second: 21,350.94999
Overall Steps per Second: 10,584.38367

Timestep Collection Time: 2.34275
Timestep Consumption Time: 2.38308
PPO Batch Consumption Time: 0.27894
Total Iteration Time: 4.72583

Cumulative Model Updates: 257,978
Cumulative Timesteps: 2,152,109,674

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 136,908.03200
Policy Entropy: 2.69136
Value Function Loss: 0.00989

Mean KL Divergence: 0.00640
SB3 Clip Fraction: 0.05875
Policy Update Magnitude: 0.29171
Value Function Update Magnitude: 0.25599

Collected Steps per Second: 21,602.19381
Overall Steps per Second: 10,500.72062

Timestep Collection Time: 2.31476
Timestep Consumption Time: 2.44719
PPO Batch Consumption Time: 0.28578
Total Iteration Time: 4.76196

Cumulative Model Updates: 257,984
Cumulative Timesteps: 2,152,159,678

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2152159678...
Checkpoint 2152159678 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 166,878.99160
Policy Entropy: 2.69011
Value Function Loss: 0.01051

Mean KL Divergence: 0.00613
SB3 Clip Fraction: 0.05753
Policy Update Magnitude: 0.29240
Value Function Update Magnitude: 0.27087

Collected Steps per Second: 22,023.27459
Overall Steps per Second: 10,728.46293

Timestep Collection Time: 2.27232
Timestep Consumption Time: 2.39228
PPO Batch Consumption Time: 0.27712
Total Iteration Time: 4.66460

Cumulative Model Updates: 257,990
Cumulative Timesteps: 2,152,209,722

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 152,069.40016
Policy Entropy: 2.70541
Value Function Loss: 0.01008

Mean KL Divergence: 0.00601
SB3 Clip Fraction: 0.05602
Policy Update Magnitude: 0.28464
Value Function Update Magnitude: 0.28502

Collected Steps per Second: 22,145.73779
Overall Steps per Second: 10,725.73861

Timestep Collection Time: 2.25949
Timestep Consumption Time: 2.40574
PPO Batch Consumption Time: 0.27932
Total Iteration Time: 4.66523

Cumulative Model Updates: 257,996
Cumulative Timesteps: 2,152,259,760

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 2152259760...
Checkpoint 2152259760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 142,037.48685
Policy Entropy: 2.71985
Value Function Loss: 0.01023

Mean KL Divergence: 0.00720
SB3 Clip Fraction: 0.06595
Policy Update Magnitude: 0.29438
Value Function Update Magnitude: 0.29622

Collected Steps per Second: 21,681.95512
Overall Steps per Second: 10,640.39199

Timestep Collection Time: 2.30607
Timestep Consumption Time: 2.39301
PPO Batch Consumption Time: 0.27866
Total Iteration Time: 4.69908

Cumulative Model Updates: 258,002
Cumulative Timesteps: 2,152,309,760

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 110,812.26763
Policy Entropy: 2.70986
Value Function Loss: 0.01015

Mean KL Divergence: 0.00686
SB3 Clip Fraction: 0.06141
Policy Update Magnitude: 0.30157
Value Function Update Magnitude: 0.31312

Collected Steps per Second: 20,508.29776
Overall Steps per Second: 10,076.07840

Timestep Collection Time: 2.44009
Timestep Consumption Time: 2.52633
PPO Batch Consumption Time: 0.29032
Total Iteration Time: 4.96642

Cumulative Model Updates: 258,008
Cumulative Timesteps: 2,152,359,802

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 2152359802...
Checkpoint 2152359802 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 98,405.97841
Policy Entropy: 2.68950
Value Function Loss: 0.00967

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.07004
Policy Update Magnitude: 0.29129
Value Function Update Magnitude: 0.30823

Collected Steps per Second: 21,267.86660
Overall Steps per Second: 10,309.93609

Timestep Collection Time: 2.35162
Timestep Consumption Time: 2.49943
PPO Batch Consumption Time: 0.29324
Total Iteration Time: 4.85105

Cumulative Model Updates: 258,014
Cumulative Timesteps: 2,152,409,816

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 123,465.23257
Policy Entropy: 2.67117
Value Function Loss: 0.01061

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.08691
Policy Update Magnitude: 0.29485
Value Function Update Magnitude: 0.29651

Collected Steps per Second: 21,620.95342
Overall Steps per Second: 10,375.13749

Timestep Collection Time: 2.31359
Timestep Consumption Time: 2.50774
PPO Batch Consumption Time: 0.28964
Total Iteration Time: 4.82133

Cumulative Model Updates: 258,020
Cumulative Timesteps: 2,152,459,838

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2152459838...
Checkpoint 2152459838 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 112,731.29766
Policy Entropy: 2.68402
Value Function Loss: 0.01018

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.08896
Policy Update Magnitude: 0.28873
Value Function Update Magnitude: 0.30779

Collected Steps per Second: 21,473.31066
Overall Steps per Second: 10,372.60933

Timestep Collection Time: 2.32996
Timestep Consumption Time: 2.49351
PPO Batch Consumption Time: 0.29085
Total Iteration Time: 4.82347

Cumulative Model Updates: 258,026
Cumulative Timesteps: 2,152,509,870

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99,470.69763
Policy Entropy: 2.67922
Value Function Loss: 0.01253

Mean KL Divergence: 0.00738
SB3 Clip Fraction: 0.06934
Policy Update Magnitude: 0.30758
Value Function Update Magnitude: 0.34471

Collected Steps per Second: 21,992.45158
Overall Steps per Second: 10,505.68665

Timestep Collection Time: 2.27478
Timestep Consumption Time: 2.48721
PPO Batch Consumption Time: 0.28914
Total Iteration Time: 4.76199

Cumulative Model Updates: 258,032
Cumulative Timesteps: 2,152,559,898

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2152559898...
Checkpoint 2152559898 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 100,115.04120
Policy Entropy: 2.68797
Value Function Loss: 0.01166

Mean KL Divergence: 0.00749
SB3 Clip Fraction: 0.06822
Policy Update Magnitude: 0.32196
Value Function Update Magnitude: 0.36418

Collected Steps per Second: 22,008.17128
Overall Steps per Second: 10,472.22408

Timestep Collection Time: 2.27316
Timestep Consumption Time: 2.50405
PPO Batch Consumption Time: 0.28474
Total Iteration Time: 4.77721

Cumulative Model Updates: 258,038
Cumulative Timesteps: 2,152,609,926

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68,793.56994
Policy Entropy: 2.66698
Value Function Loss: 0.01294

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.06866
Policy Update Magnitude: 0.32227
Value Function Update Magnitude: 0.36213

Collected Steps per Second: 22,288.23271
Overall Steps per Second: 10,543.61510

Timestep Collection Time: 2.24405
Timestep Consumption Time: 2.49967
PPO Batch Consumption Time: 0.29004
Total Iteration Time: 4.74372

Cumulative Model Updates: 258,044
Cumulative Timesteps: 2,152,659,942

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2152659942...
Checkpoint 2152659942 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 57,893.59171
Policy Entropy: 2.67560
Value Function Loss: 0.01277

Mean KL Divergence: 0.00750
SB3 Clip Fraction: 0.06670
Policy Update Magnitude: 0.31967
Value Function Update Magnitude: 0.34143

Collected Steps per Second: 22,010.24240
Overall Steps per Second: 10,489.44602

Timestep Collection Time: 2.27185
Timestep Consumption Time: 2.49523
PPO Batch Consumption Time: 0.29194
Total Iteration Time: 4.76708

Cumulative Model Updates: 258,050
Cumulative Timesteps: 2,152,709,946

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50,199.17022
Policy Entropy: 2.68170
Value Function Loss: 0.01184

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.07329
Policy Update Magnitude: 0.31368
Value Function Update Magnitude: 0.32033

Collected Steps per Second: 21,522.37867
Overall Steps per Second: 10,530.83662

Timestep Collection Time: 2.32391
Timestep Consumption Time: 2.42557
PPO Batch Consumption Time: 0.29288
Total Iteration Time: 4.74948

Cumulative Model Updates: 258,056
Cumulative Timesteps: 2,152,759,962

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2152759962...
Checkpoint 2152759962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47,251.36783
Policy Entropy: 2.70376
Value Function Loss: 0.01154

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.07718
Policy Update Magnitude: 0.30489
Value Function Update Magnitude: 0.31291

Collected Steps per Second: 21,203.96000
Overall Steps per Second: 10,588.42347

Timestep Collection Time: 2.35805
Timestep Consumption Time: 2.36409
PPO Batch Consumption Time: 0.27822
Total Iteration Time: 4.72214

Cumulative Model Updates: 258,062
Cumulative Timesteps: 2,152,809,962

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,867.53481
Policy Entropy: 2.71520
Value Function Loss: 0.01160

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.08424
Policy Update Magnitude: 0.31076
Value Function Update Magnitude: 0.31228

Collected Steps per Second: 21,663.27870
Overall Steps per Second: 10,604.88106

Timestep Collection Time: 2.31008
Timestep Consumption Time: 2.40887
PPO Batch Consumption Time: 0.29032
Total Iteration Time: 4.71896

Cumulative Model Updates: 258,068
Cumulative Timesteps: 2,152,860,006

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 2152860006...
Checkpoint 2152860006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,495.87616
Policy Entropy: 2.70904
Value Function Loss: 0.01093

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.07804
Policy Update Magnitude: 0.30205
Value Function Update Magnitude: 0.31433

Collected Steps per Second: 21,205.53608
Overall Steps per Second: 10,486.32953

Timestep Collection Time: 2.35825
Timestep Consumption Time: 2.41062
PPO Batch Consumption Time: 0.27884
Total Iteration Time: 4.76888

Cumulative Model Updates: 258,074
Cumulative Timesteps: 2,152,910,014

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,116.37409
Policy Entropy: 2.72746
Value Function Loss: 0.01068

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.06899
Policy Update Magnitude: 0.29282
Value Function Update Magnitude: 0.28830

Collected Steps per Second: 21,827.16543
Overall Steps per Second: 10,464.98962

Timestep Collection Time: 2.29274
Timestep Consumption Time: 2.48930
PPO Batch Consumption Time: 0.29257
Total Iteration Time: 4.78204

Cumulative Model Updates: 258,080
Cumulative Timesteps: 2,152,960,058

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 2152960058...
Checkpoint 2152960058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43,424.59981
Policy Entropy: 2.74678
Value Function Loss: 0.01092

Mean KL Divergence: 0.00645
SB3 Clip Fraction: 0.06213
Policy Update Magnitude: 0.28693
Value Function Update Magnitude: 0.27743

Collected Steps per Second: 20,934.43357
Overall Steps per Second: 10,263.15655

Timestep Collection Time: 2.38946
Timestep Consumption Time: 2.48448
PPO Batch Consumption Time: 0.29323
Total Iteration Time: 4.87394

Cumulative Model Updates: 258,086
Cumulative Timesteps: 2,153,010,080

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 71,508.81791
Policy Entropy: 2.76385
Value Function Loss: 0.01128

Mean KL Divergence: 0.00639
SB3 Clip Fraction: 0.06235
Policy Update Magnitude: 0.28269
Value Function Update Magnitude: 0.24030

Collected Steps per Second: 22,055.26710
Overall Steps per Second: 10,489.09687

Timestep Collection Time: 2.26785
Timestep Consumption Time: 2.50072
PPO Batch Consumption Time: 0.29234
Total Iteration Time: 4.76857

Cumulative Model Updates: 258,092
Cumulative Timesteps: 2,153,060,098

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2153060098...
Checkpoint 2153060098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 90,605.53622
Policy Entropy: 2.75667
Value Function Loss: 0.01110

Mean KL Divergence: 0.00569
SB3 Clip Fraction: 0.05520
Policy Update Magnitude: 0.28584
Value Function Update Magnitude: 0.18165

Collected Steps per Second: 21,416.96805
Overall Steps per Second: 10,470.96215

Timestep Collection Time: 2.33516
Timestep Consumption Time: 2.44110
PPO Batch Consumption Time: 0.27902
Total Iteration Time: 4.77626

Cumulative Model Updates: 258,098
Cumulative Timesteps: 2,153,110,110

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99,014.51832
Policy Entropy: 2.74538
Value Function Loss: 0.01095

Mean KL Divergence: 0.00539
SB3 Clip Fraction: 0.05049
Policy Update Magnitude: 0.28731
Value Function Update Magnitude: 0.17840

Collected Steps per Second: 21,716.90266
Overall Steps per Second: 10,582.68650

Timestep Collection Time: 2.30245
Timestep Consumption Time: 2.42244
PPO Batch Consumption Time: 0.27689
Total Iteration Time: 4.72489

Cumulative Model Updates: 258,104
Cumulative Timesteps: 2,153,160,112

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2153160112...
Checkpoint 2153160112 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 176,339.90036
Policy Entropy: 2.69340
Value Function Loss: 0.01152

Mean KL Divergence: 0.00592
SB3 Clip Fraction: 0.05529
Policy Update Magnitude: 0.29921
Value Function Update Magnitude: 0.24695

Collected Steps per Second: 21,858.18988
Overall Steps per Second: 10,539.20502

Timestep Collection Time: 2.28930
Timestep Consumption Time: 2.45868
PPO Batch Consumption Time: 0.27687
Total Iteration Time: 4.74799

Cumulative Model Updates: 258,110
Cumulative Timesteps: 2,153,210,152

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 115,892.18227
Policy Entropy: 2.69253
Value Function Loss: 0.01182

Mean KL Divergence: 0.00706
SB3 Clip Fraction: 0.06662
Policy Update Magnitude: 0.31181
Value Function Update Magnitude: 0.29775

Collected Steps per Second: 22,071.89334
Overall Steps per Second: 10,407.24037

Timestep Collection Time: 2.26696
Timestep Consumption Time: 2.54085
PPO Batch Consumption Time: 0.29440
Total Iteration Time: 4.80781

Cumulative Model Updates: 258,116
Cumulative Timesteps: 2,153,260,188

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 2153260188...
Checkpoint 2153260188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 131,746.50011
Policy Entropy: 2.69418
Value Function Loss: 0.01294

Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.07304
Policy Update Magnitude: 0.32433
Value Function Update Magnitude: 0.33411

Collected Steps per Second: 22,028.34169
Overall Steps per Second: 10,670.00985

Timestep Collection Time: 2.27071
Timestep Consumption Time: 2.41719
PPO Batch Consumption Time: 0.27769
Total Iteration Time: 4.68791

Cumulative Model Updates: 258,122
Cumulative Timesteps: 2,153,310,208

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91,717.86469
Policy Entropy: 2.73490
Value Function Loss: 0.01153

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.07299
Policy Update Magnitude: 0.30941
Value Function Update Magnitude: 0.33230

Collected Steps per Second: 22,222.52828
Overall Steps per Second: 10,513.22244

Timestep Collection Time: 2.25087
Timestep Consumption Time: 2.50695
PPO Batch Consumption Time: 0.29204
Total Iteration Time: 4.75782

Cumulative Model Updates: 258,128
Cumulative Timesteps: 2,153,360,228

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2153360228...
Checkpoint 2153360228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 91,717.86469
Policy Entropy: 2.71576
Value Function Loss: 0.01065

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.06999
Policy Update Magnitude: 0.29611
Value Function Update Magnitude: 0.30917

Collected Steps per Second: 21,818.47394
Overall Steps per Second: 10,627.62422

Timestep Collection Time: 2.29292
Timestep Consumption Time: 2.41444
PPO Batch Consumption Time: 0.27855
Total Iteration Time: 4.70735

Cumulative Model Updates: 258,134
Cumulative Timesteps: 2,153,410,256

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89,334.62827
Policy Entropy: 2.73523
Value Function Loss: 0.01081

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.06851
Policy Update Magnitude: 0.29872
Value Function Update Magnitude: 0.27968

Collected Steps per Second: 21,272.61932
Overall Steps per Second: 10,467.32984

Timestep Collection Time: 2.35270
Timestep Consumption Time: 2.42866
PPO Batch Consumption Time: 0.29209
Total Iteration Time: 4.78135

Cumulative Model Updates: 258,140
Cumulative Timesteps: 2,153,460,304

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 2153460304...
Checkpoint 2153460304 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 125,189.26487
Policy Entropy: 2.72824
Value Function Loss: 0.01388

Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.07768
Policy Update Magnitude: 0.30559
Value Function Update Magnitude: 0.28463

Collected Steps per Second: 20,881.19563
Overall Steps per Second: 10,384.46958

Timestep Collection Time: 2.39689
Timestep Consumption Time: 2.42280
PPO Batch Consumption Time: 0.29041
Total Iteration Time: 4.81970

Cumulative Model Updates: 258,146
Cumulative Timesteps: 2,153,510,354

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99,353.99550
Policy Entropy: 2.75361
Value Function Loss: 0.01277

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.07236
Policy Update Magnitude: 0.29591
Value Function Update Magnitude: 0.29953

Collected Steps per Second: 21,405.59223
Overall Steps per Second: 10,681.29134

Timestep Collection Time: 2.33640
Timestep Consumption Time: 2.34581
PPO Batch Consumption Time: 0.27847
Total Iteration Time: 4.68221

Cumulative Model Updates: 258,152
Cumulative Timesteps: 2,153,560,366

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2153560366...
Checkpoint 2153560366 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 78,826.28076
Policy Entropy: 2.74798
Value Function Loss: 0.01294

Mean KL Divergence: 0.00595
SB3 Clip Fraction: 0.05713
Policy Update Magnitude: 0.29166
Value Function Update Magnitude: 0.30561

Collected Steps per Second: 20,677.31177
Overall Steps per Second: 10,219.70590

Timestep Collection Time: 2.41888
Timestep Consumption Time: 2.47519
PPO Batch Consumption Time: 0.28812
Total Iteration Time: 4.89407

Cumulative Model Updates: 258,158
Cumulative Timesteps: 2,153,610,382

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 218,962.10453
Policy Entropy: 2.73079
Value Function Loss: 0.01157

Mean KL Divergence: 0.00569
SB3 Clip Fraction: 0.05595
Policy Update Magnitude: 0.29775
Value Function Update Magnitude: 0.29262

Collected Steps per Second: 21,302.65165
Overall Steps per Second: 10,475.05613

Timestep Collection Time: 2.34741
Timestep Consumption Time: 2.42641
PPO Batch Consumption Time: 0.27856
Total Iteration Time: 4.77382

Cumulative Model Updates: 258,164
Cumulative Timesteps: 2,153,660,388

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2153660388...
Checkpoint 2153660388 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 189,265.28541
Policy Entropy: 2.71575
Value Function Loss: 0.01131

Mean KL Divergence: 0.00653
SB3 Clip Fraction: 0.06168
Policy Update Magnitude: 0.29500
Value Function Update Magnitude: 0.28241

Collected Steps per Second: 21,261.96953
Overall Steps per Second: 10,534.53618

Timestep Collection Time: 2.35209
Timestep Consumption Time: 2.39516
PPO Batch Consumption Time: 0.27851
Total Iteration Time: 4.74724

Cumulative Model Updates: 258,170
Cumulative Timesteps: 2,153,710,398

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 161,100.62985
Policy Entropy: 2.69631
Value Function Loss: 0.01057

Mean KL Divergence: 0.00667
SB3 Clip Fraction: 0.06352
Policy Update Magnitude: 0.29070
Value Function Update Magnitude: 0.28861

Collected Steps per Second: 21,670.48204
Overall Steps per Second: 10,505.45213

Timestep Collection Time: 2.30738
Timestep Consumption Time: 2.45225
PPO Batch Consumption Time: 0.27842
Total Iteration Time: 4.75962

Cumulative Model Updates: 258,176
Cumulative Timesteps: 2,153,760,400

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2153760400...
Checkpoint 2153760400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 159,823.67038
Policy Entropy: 2.71284
Value Function Loss: 0.00924

Mean KL Divergence: 0.00548
SB3 Clip Fraction: 0.05370
Policy Update Magnitude: 0.28742
Value Function Update Magnitude: 0.28556

Collected Steps per Second: 21,666.28916
Overall Steps per Second: 10,337.23231

Timestep Collection Time: 2.30856
Timestep Consumption Time: 2.53006
PPO Batch Consumption Time: 0.29348
Total Iteration Time: 4.83863

Cumulative Model Updates: 258,182
Cumulative Timesteps: 2,153,810,418

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 130,824.47130
Policy Entropy: 2.73323
Value Function Loss: 0.00886

Mean KL Divergence: 0.00620
SB3 Clip Fraction: 0.06117
Policy Update Magnitude: 0.28128
Value Function Update Magnitude: 0.25730

Collected Steps per Second: 22,212.61206
Overall Steps per Second: 10,466.59463

Timestep Collection Time: 2.25178
Timestep Consumption Time: 2.52704
PPO Batch Consumption Time: 0.29065
Total Iteration Time: 4.77882

Cumulative Model Updates: 258,188
Cumulative Timesteps: 2,153,860,436

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2153860436...
Checkpoint 2153860436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 103,617.21421
Policy Entropy: 2.73566
Value Function Loss: 0.01030

Mean KL Divergence: 0.00605
SB3 Clip Fraction: 0.05736
Policy Update Magnitude: 0.29002
Value Function Update Magnitude: 0.25424

Collected Steps per Second: 20,889.02613
Overall Steps per Second: 10,065.91614

Timestep Collection Time: 2.39513
Timestep Consumption Time: 2.57530
PPO Batch Consumption Time: 0.29397
Total Iteration Time: 4.97044

Cumulative Model Updates: 258,194
Cumulative Timesteps: 2,153,910,468

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 94,952.43306
Policy Entropy: 2.72780
Value Function Loss: 0.01152

Mean KL Divergence: 0.00662
SB3 Clip Fraction: 0.05940
Policy Update Magnitude: 0.29343
Value Function Update Magnitude: 0.28174

Collected Steps per Second: 20,530.58037
Overall Steps per Second: 10,018.33024

Timestep Collection Time: 2.43753
Timestep Consumption Time: 2.55771
PPO Batch Consumption Time: 0.29151
Total Iteration Time: 4.99524

Cumulative Model Updates: 258,200
Cumulative Timesteps: 2,153,960,512

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 2153960512...
Checkpoint 2153960512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 112,903.96607
Policy Entropy: 2.70838
Value Function Loss: 0.01181

Mean KL Divergence: 0.00728
SB3 Clip Fraction: 0.06093
Policy Update Magnitude: 0.29853
Value Function Update Magnitude: 0.29545

Collected Steps per Second: 20,448.42197
Overall Steps per Second: 10,173.96313

Timestep Collection Time: 2.44576
Timestep Consumption Time: 2.46992
PPO Batch Consumption Time: 0.27833
Total Iteration Time: 4.91569

Cumulative Model Updates: 258,206
Cumulative Timesteps: 2,154,010,524

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99,782.45898
Policy Entropy: 2.69900
Value Function Loss: 0.01227

Mean KL Divergence: 0.00675
SB3 Clip Fraction: 0.06192
Policy Update Magnitude: 0.30517
Value Function Update Magnitude: 0.30614

Collected Steps per Second: 22,067.32648
Overall Steps per Second: 10,632.67476

Timestep Collection Time: 2.26643
Timestep Consumption Time: 2.43737
PPO Batch Consumption Time: 0.27740
Total Iteration Time: 4.70380

Cumulative Model Updates: 258,212
Cumulative Timesteps: 2,154,060,538

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2154060538...
Checkpoint 2154060538 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 182,557.15537
Policy Entropy: 2.68502
Value Function Loss: 0.01234

Mean KL Divergence: 0.00624
SB3 Clip Fraction: 0.05961
Policy Update Magnitude: 0.32349
Value Function Update Magnitude: 0.33186

Collected Steps per Second: 21,849.39647
Overall Steps per Second: 10,578.79355

Timestep Collection Time: 2.28986
Timestep Consumption Time: 2.43960
PPO Batch Consumption Time: 0.27856
Total Iteration Time: 4.72946

Cumulative Model Updates: 258,218
Cumulative Timesteps: 2,154,110,570

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 110,733.12550
Policy Entropy: 2.67769
Value Function Loss: 0.01318

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.06830
Policy Update Magnitude: 0.32422
Value Function Update Magnitude: 0.33775

Collected Steps per Second: 22,028.41388
Overall Steps per Second: 10,483.64903

Timestep Collection Time: 2.27025
Timestep Consumption Time: 2.50004
PPO Batch Consumption Time: 0.28996
Total Iteration Time: 4.77029

Cumulative Model Updates: 258,224
Cumulative Timesteps: 2,154,160,580

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2154160580...
Checkpoint 2154160580 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 98,440.15734
Policy Entropy: 2.68924
Value Function Loss: 0.01326

Mean KL Divergence: 0.00772
SB3 Clip Fraction: 0.06752
Policy Update Magnitude: 0.31798
Value Function Update Magnitude: 0.32394

Collected Steps per Second: 21,349.97165
Overall Steps per Second: 10,324.96579

Timestep Collection Time: 2.34267
Timestep Consumption Time: 2.50151
PPO Batch Consumption Time: 0.29026
Total Iteration Time: 4.84418

Cumulative Model Updates: 258,230
Cumulative Timesteps: 2,154,210,596

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 98,440.15734
Policy Entropy: 2.72447
Value Function Loss: 0.01103

Mean KL Divergence: 0.00691
SB3 Clip Fraction: 0.06660
Policy Update Magnitude: 0.29976
Value Function Update Magnitude: 0.30938

Collected Steps per Second: 21,295.43239
Overall Steps per Second: 10,302.64663

Timestep Collection Time: 2.34830
Timestep Consumption Time: 2.50560
PPO Batch Consumption Time: 0.29194
Total Iteration Time: 4.85390

Cumulative Model Updates: 258,236
Cumulative Timesteps: 2,154,260,604

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2154260604...
Checkpoint 2154260604 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 105,653.19746
Policy Entropy: 2.73168
Value Function Loss: 0.01033

Mean KL Divergence: 0.00606
SB3 Clip Fraction: 0.05920
Policy Update Magnitude: 0.28685
Value Function Update Magnitude: 0.25919

Collected Steps per Second: 20,959.44955
Overall Steps per Second: 10,559.74816

Timestep Collection Time: 2.38585
Timestep Consumption Time: 2.34968
PPO Batch Consumption Time: 0.27828
Total Iteration Time: 4.73553

Cumulative Model Updates: 258,242
Cumulative Timesteps: 2,154,310,610

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 101,227.61826
Policy Entropy: 2.73873
Value Function Loss: 0.01008

Mean KL Divergence: 0.00577
SB3 Clip Fraction: 0.05606
Policy Update Magnitude: 0.29038
Value Function Update Magnitude: 0.26038

Collected Steps per Second: 21,475.21893
Overall Steps per Second: 10,532.37217

Timestep Collection Time: 2.32957
Timestep Consumption Time: 2.42036
PPO Batch Consumption Time: 0.28422
Total Iteration Time: 4.74993

Cumulative Model Updates: 258,248
Cumulative Timesteps: 2,154,360,638

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2154360638...
Checkpoint 2154360638 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87,736.83499
Policy Entropy: 2.71035
Value Function Loss: 0.01021

Mean KL Divergence: 0.00736
SB3 Clip Fraction: 0.06735
Policy Update Magnitude: 0.28623
Value Function Update Magnitude: 0.27988

Collected Steps per Second: 21,547.43817
Overall Steps per Second: 10,659.74208

Timestep Collection Time: 2.32213
Timestep Consumption Time: 2.37179
PPO Batch Consumption Time: 0.27832
Total Iteration Time: 4.69392

Cumulative Model Updates: 258,254
Cumulative Timesteps: 2,154,410,674

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 71,803.75312
Policy Entropy: 2.72332
Value Function Loss: 0.01023

Mean KL Divergence: 0.00695
SB3 Clip Fraction: 0.06382
Policy Update Magnitude: 0.30092
Value Function Update Magnitude: 0.30964

Collected Steps per Second: 21,335.52793
Overall Steps per Second: 10,424.92624

Timestep Collection Time: 2.34370
Timestep Consumption Time: 2.45288
PPO Batch Consumption Time: 0.28606
Total Iteration Time: 4.79658

Cumulative Model Updates: 258,260
Cumulative Timesteps: 2,154,460,678

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2154460678...
Checkpoint 2154460678 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 67,846.79543
Policy Entropy: 2.72128
Value Function Loss: 0.00955

Mean KL Divergence: 0.00597
SB3 Clip Fraction: 0.05718
Policy Update Magnitude: 0.29964
Value Function Update Magnitude: 0.31001

Collected Steps per Second: 21,825.28963
Overall Steps per Second: 10,635.83603

Timestep Collection Time: 2.29156
Timestep Consumption Time: 2.41084
PPO Batch Consumption Time: 0.27859
Total Iteration Time: 4.70240

Cumulative Model Updates: 258,266
Cumulative Timesteps: 2,154,510,692

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56,796.64845
Policy Entropy: 2.70601
Value Function Loss: 0.01015

Mean KL Divergence: 0.00598
SB3 Clip Fraction: 0.05623
Policy Update Magnitude: 0.30016
Value Function Update Magnitude: 0.31064

Collected Steps per Second: 22,031.12419
Overall Steps per Second: 10,536.45865

Timestep Collection Time: 2.27142
Timestep Consumption Time: 2.47799
PPO Batch Consumption Time: 0.29376
Total Iteration Time: 4.74941

Cumulative Model Updates: 258,272
Cumulative Timesteps: 2,154,560,734

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 2154560734...
Checkpoint 2154560734 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 224,646.44582
Policy Entropy: 2.69375
Value Function Loss: 0.01154

Mean KL Divergence: 0.00642
SB3 Clip Fraction: 0.06129
Policy Update Magnitude: 0.30733
Value Function Update Magnitude: 0.31839

Collected Steps per Second: 22,045.97122
Overall Steps per Second: 10,543.49579

Timestep Collection Time: 2.26853
Timestep Consumption Time: 2.47487
PPO Batch Consumption Time: 0.28564
Total Iteration Time: 4.74340

Cumulative Model Updates: 258,278
Cumulative Timesteps: 2,154,610,746

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 210,548.59086
Policy Entropy: 2.68257
Value Function Loss: 0.01110

Mean KL Divergence: 0.00746
SB3 Clip Fraction: 0.06760
Policy Update Magnitude: 0.30470
Value Function Update Magnitude: 0.32292

Collected Steps per Second: 21,771.05655
Overall Steps per Second: 10,459.33516

Timestep Collection Time: 2.29681
Timestep Consumption Time: 2.48399
PPO Batch Consumption Time: 0.28717
Total Iteration Time: 4.78080

Cumulative Model Updates: 258,284
Cumulative Timesteps: 2,154,660,750

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2154660750...
Checkpoint 2154660750 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 219,388.71253
Policy Entropy: 2.70437
Value Function Loss: 0.01170

Mean KL Divergence: 0.00656
SB3 Clip Fraction: 0.06053
Policy Update Magnitude: 0.30721
Value Function Update Magnitude: 0.32193

Collected Steps per Second: 21,234.76416
Overall Steps per Second: 10,317.43976

Timestep Collection Time: 2.35463
Timestep Consumption Time: 2.49153
PPO Batch Consumption Time: 0.29186
Total Iteration Time: 4.84616

Cumulative Model Updates: 258,290
Cumulative Timesteps: 2,154,710,750

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 219,388.71253
Policy Entropy: 2.71411
Value Function Loss: 0.00979

Mean KL Divergence: 0.00630
SB3 Clip Fraction: 0.05785
Policy Update Magnitude: 0.29836
Value Function Update Magnitude: 0.32483

Collected Steps per Second: 21,676.57807
Overall Steps per Second: 10,373.20212

Timestep Collection Time: 2.30701
Timestep Consumption Time: 2.51388
PPO Batch Consumption Time: 0.29360
Total Iteration Time: 4.82088

Cumulative Model Updates: 258,296
Cumulative Timesteps: 2,154,760,758

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2154760758...
Checkpoint 2154760758 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 132,666.59618
Policy Entropy: 2.72784
Value Function Loss: 0.01091

Mean KL Divergence: 0.00740
SB3 Clip Fraction: 0.06784
Policy Update Magnitude: 0.29069
Value Function Update Magnitude: 0.30509

Collected Steps per Second: 21,739.78063
Overall Steps per Second: 10,580.72722

Timestep Collection Time: 2.30030
Timestep Consumption Time: 2.42603
PPO Batch Consumption Time: 0.27850
Total Iteration Time: 4.72633

Cumulative Model Updates: 258,302
Cumulative Timesteps: 2,154,810,766

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 117,170.41133
Policy Entropy: 2.72636
Value Function Loss: 0.01235

Mean KL Divergence: 0.00621
SB3 Clip Fraction: 0.06051
Policy Update Magnitude: 0.29863
Value Function Update Magnitude: 0.28453

Collected Steps per Second: 21,798.45541
Overall Steps per Second: 10,491.77906

Timestep Collection Time: 2.29374
Timestep Consumption Time: 2.47190
PPO Batch Consumption Time: 0.27893
Total Iteration Time: 4.76564

Cumulative Model Updates: 258,308
Cumulative Timesteps: 2,154,860,766

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2154860766...
Checkpoint 2154860766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 90,370.10368
Policy Entropy: 2.71574
Value Function Loss: 0.01297

Mean KL Divergence: 0.00631
SB3 Clip Fraction: 0.06058
Policy Update Magnitude: 0.30683
Value Function Update Magnitude: 0.29545

Collected Steps per Second: 21,401.37681
Overall Steps per Second: 10,610.37311

Timestep Collection Time: 2.33686
Timestep Consumption Time: 2.37664
PPO Batch Consumption Time: 0.27912
Total Iteration Time: 4.71350

Cumulative Model Updates: 258,314
Cumulative Timesteps: 2,154,910,778

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 106,734.60595
Policy Entropy: 2.71724
Value Function Loss: 0.01193

Mean KL Divergence: 0.00629
SB3 Clip Fraction: 0.05697
Policy Update Magnitude: 0.30157
Value Function Update Magnitude: 0.29879

Collected Steps per Second: 21,515.96425
Overall Steps per Second: 10,537.91026

Timestep Collection Time: 2.32544
Timestep Consumption Time: 2.42256
PPO Batch Consumption Time: 0.29353
Total Iteration Time: 4.74800

Cumulative Model Updates: 258,320
Cumulative Timesteps: 2,154,960,812

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 2154960812...
Checkpoint 2154960812 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 102,618.79364
Policy Entropy: 2.70451
Value Function Loss: 0.01147

Mean KL Divergence: 0.00711
SB3 Clip Fraction: 0.06271
Policy Update Magnitude: 0.30140
Value Function Update Magnitude: 0.28976

Collected Steps per Second: 21,524.08584
Overall Steps per Second: 10,569.01749

Timestep Collection Time: 2.32382
Timestep Consumption Time: 2.40870
PPO Batch Consumption Time: 0.28980
Total Iteration Time: 4.73251

Cumulative Model Updates: 258,326
Cumulative Timesteps: 2,155,010,830

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80,301.58423
Policy Entropy: 2.70951
Value Function Loss: 0.01134

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.07428
Policy Update Magnitude: 0.31142
Value Function Update Magnitude: 0.31111

Collected Steps per Second: 21,235.50132
Overall Steps per Second: 10,524.98680

Timestep Collection Time: 2.35540
Timestep Consumption Time: 2.39691
PPO Batch Consumption Time: 0.27683
Total Iteration Time: 4.75231

Cumulative Model Updates: 258,332
Cumulative Timesteps: 2,155,060,848

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2155060848...
Checkpoint 2155060848 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 71,108.03181
Policy Entropy: 2.70679
Value Function Loss: 0.01127

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.06944
Policy Update Magnitude: 0.30796
Value Function Update Magnitude: 0.31607

Collected Steps per Second: 21,751.10487
Overall Steps per Second: 10,533.59323

Timestep Collection Time: 2.29910
Timestep Consumption Time: 2.44838
PPO Batch Consumption Time: 0.28525
Total Iteration Time: 4.74748

Cumulative Model Updates: 258,338
Cumulative Timesteps: 2,155,110,856

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76,520.71623
Policy Entropy: 2.73398
Value Function Loss: 0.01041

Mean KL Divergence: 0.00756
SB3 Clip Fraction: 0.06677
Policy Update Magnitude: 0.29434
Value Function Update Magnitude: 0.29202

Collected Steps per Second: 21,582.51312
Overall Steps per Second: 10,481.67182

Timestep Collection Time: 2.31771
Timestep Consumption Time: 2.45462
PPO Batch Consumption Time: 0.28708
Total Iteration Time: 4.77233

Cumulative Model Updates: 258,344
Cumulative Timesteps: 2,155,160,878

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2155160878...
Checkpoint 2155160878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 93,626.92092
Policy Entropy: 2.75202
Value Function Loss: 0.01099

Mean KL Divergence: 0.00698
SB3 Clip Fraction: 0.06713
Policy Update Magnitude: 0.28852
Value Function Update Magnitude: 0.27273

Collected Steps per Second: 21,514.23090
Overall Steps per Second: 10,373.64967

Timestep Collection Time: 2.32479
Timestep Consumption Time: 2.49666
PPO Batch Consumption Time: 0.29025
Total Iteration Time: 4.82145

Cumulative Model Updates: 258,350
Cumulative Timesteps: 2,155,210,894

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 120,407.89297
Policy Entropy: 2.75439
Value Function Loss: 0.01198

Mean KL Divergence: 0.00688
SB3 Clip Fraction: 0.06439
Policy Update Magnitude: 0.28705
Value Function Update Magnitude: 0.26319

Collected Steps per Second: 21,471.90165
Overall Steps per Second: 10,314.46474

Timestep Collection Time: 2.32909
Timestep Consumption Time: 2.51944
PPO Batch Consumption Time: 0.29314
Total Iteration Time: 4.84853

Cumulative Model Updates: 258,356
Cumulative Timesteps: 2,155,260,904

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2155260904...
Checkpoint 2155260904 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 120,312.97011
Policy Entropy: 2.74030
Value Function Loss: 0.01287

Mean KL Divergence: 0.00726
SB3 Clip Fraction: 0.06877
Policy Update Magnitude: 0.28997
Value Function Update Magnitude: 0.26126

Collected Steps per Second: 21,461.09902
Overall Steps per Second: 10,541.35004

Timestep Collection Time: 2.32989
Timestep Consumption Time: 2.41353
PPO Batch Consumption Time: 0.27800
Total Iteration Time: 4.74342

Cumulative Model Updates: 258,362
Cumulative Timesteps: 2,155,310,906

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 94,276.39220
Policy Entropy: 2.75252
Value Function Loss: 0.01233

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.06985
Policy Update Magnitude: 0.29076
Value Function Update Magnitude: 0.25793

Collected Steps per Second: 21,979.58714
Overall Steps per Second: 10,526.22321

Timestep Collection Time: 2.27620
Timestep Consumption Time: 2.47669
PPO Batch Consumption Time: 0.27834
Total Iteration Time: 4.75289

Cumulative Model Updates: 258,368
Cumulative Timesteps: 2,155,360,936

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2155360936...
Checkpoint 2155360936 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 127,429.95778
Policy Entropy: 2.73578
Value Function Loss: 0.01058

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.07780
Policy Update Magnitude: 0.28479
Value Function Update Magnitude: 0.23786

Collected Steps per Second: 21,854.57100
Overall Steps per Second: 10,563.90781

Timestep Collection Time: 2.28913
Timestep Consumption Time: 2.44662
PPO Batch Consumption Time: 0.27840
Total Iteration Time: 4.73575

Cumulative Model Updates: 258,374
Cumulative Timesteps: 2,155,410,964

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 104,322.50922
Policy Entropy: 2.71283
Value Function Loss: 0.00941

Mean KL Divergence: 0.00748
SB3 Clip Fraction: 0.07257
Policy Update Magnitude: 0.27542
Value Function Update Magnitude: 0.21815

Collected Steps per Second: 22,035.54018
Overall Steps per Second: 10,499.06192

Timestep Collection Time: 2.26952
Timestep Consumption Time: 2.49377
PPO Batch Consumption Time: 0.28780
Total Iteration Time: 4.76328

Cumulative Model Updates: 258,380
Cumulative Timesteps: 2,155,460,974

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2155460974...
Checkpoint 2155460974 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 94,749.13973
Policy Entropy: 2.68893
Value Function Loss: 0.01011

Mean KL Divergence: 0.00717
SB3 Clip Fraction: 0.06777
Policy Update Magnitude: 0.29051
Value Function Update Magnitude: 0.23885

Collected Steps per Second: 22,197.19765
Overall Steps per Second: 10,666.26943

Timestep Collection Time: 2.25290
Timestep Consumption Time: 2.43553
PPO Batch Consumption Time: 0.27856
Total Iteration Time: 4.68842

Cumulative Model Updates: 258,386
Cumulative Timesteps: 2,155,510,982

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95,913.12771
Policy Entropy: 2.68856
Value Function Loss: 0.01042

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.06908
Policy Update Magnitude: 0.29854
Value Function Update Magnitude: 0.24726

Collected Steps per Second: 22,420.85953
Overall Steps per Second: 10,601.12515

Timestep Collection Time: 2.23158
Timestep Consumption Time: 2.48811
PPO Batch Consumption Time: 0.29127
Total Iteration Time: 4.71969

Cumulative Model Updates: 258,392
Cumulative Timesteps: 2,155,561,016

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 2155561016...
Checkpoint 2155561016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87,957.35315
Policy Entropy: 2.70726
Value Function Loss: 0.01119

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.08904
Policy Update Magnitude: 0.30755
Value Function Update Magnitude: 0.23552

Collected Steps per Second: 21,985.36112
Overall Steps per Second: 10,473.06177

Timestep Collection Time: 2.27442
Timestep Consumption Time: 2.50011
PPO Batch Consumption Time: 0.29121
Total Iteration Time: 4.77454

Cumulative Model Updates: 258,398
Cumulative Timesteps: 2,155,611,020

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99,654.15484
Policy Entropy: 2.69231
Value Function Loss: 0.01192

Mean KL Divergence: 0.01096
SB3 Clip Fraction: 0.09660
Policy Update Magnitude: 0.30454
Value Function Update Magnitude: 0.22095

Collected Steps per Second: 21,876.60726
Overall Steps per Second: 10,459.06498

Timestep Collection Time: 2.28573
Timestep Consumption Time: 2.49520
PPO Batch Consumption Time: 0.28892
Total Iteration Time: 4.78092

Cumulative Model Updates: 258,404
Cumulative Timesteps: 2,155,661,024

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2155661024...
Checkpoint 2155661024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 85,313.14667
Policy Entropy: 2.69254
Value Function Loss: 0.01254

Mean KL Divergence: 0.01170
SB3 Clip Fraction: 0.10311
Policy Update Magnitude: 0.30057
Value Function Update Magnitude: 0.22309

Collected Steps per Second: 21,279.56331
Overall Steps per Second: 10,315.65487

Timestep Collection Time: 2.35024
Timestep Consumption Time: 2.49793
PPO Batch Consumption Time: 0.29219
Total Iteration Time: 4.84817

Cumulative Model Updates: 258,410
Cumulative Timesteps: 2,155,711,036

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70,005.28471
Policy Entropy: 2.68656
Value Function Loss: 0.01082

Mean KL Divergence: 0.01070
SB3 Clip Fraction: 0.09444
Policy Update Magnitude: 0.29830
Value Function Update Magnitude: 0.25274

Collected Steps per Second: 21,940.31833
Overall Steps per Second: 10,491.11657

Timestep Collection Time: 2.27955
Timestep Consumption Time: 2.48772
PPO Batch Consumption Time: 0.29043
Total Iteration Time: 4.76727

Cumulative Model Updates: 258,416
Cumulative Timesteps: 2,155,761,050

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2155761050...
Checkpoint 2155761050 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 62,852.76251
Policy Entropy: 2.69236
Value Function Loss: 0.01014

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.08062
Policy Update Magnitude: 0.29112
Value Function Update Magnitude: 0.29359

Collected Steps per Second: 21,586.46537
Overall Steps per Second: 10,558.00857

Timestep Collection Time: 2.31701
Timestep Consumption Time: 2.42025
PPO Batch Consumption Time: 0.27640
Total Iteration Time: 4.73726

Cumulative Model Updates: 258,422
Cumulative Timesteps: 2,155,811,066

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67,906.70112
Policy Entropy: 2.69291
Value Function Loss: 0.01169

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.07033
Policy Update Magnitude: 0.29809
Value Function Update Magnitude: 0.29346

Collected Steps per Second: 22,060.53006
Overall Steps per Second: 10,435.20016

Timestep Collection Time: 2.26767
Timestep Consumption Time: 2.52630
PPO Batch Consumption Time: 0.29332
Total Iteration Time: 4.79397

Cumulative Model Updates: 258,428
Cumulative Timesteps: 2,155,861,092

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2155861092...
Checkpoint 2155861092 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 70,457.20284
Policy Entropy: 2.71115
Value Function Loss: 0.01272

Mean KL Divergence: 0.00684
SB3 Clip Fraction: 0.06623
Policy Update Magnitude: 0.30789
Value Function Update Magnitude: 0.33430

Collected Steps per Second: 21,846.97959
Overall Steps per Second: 10,576.39894

Timestep Collection Time: 2.28947
Timestep Consumption Time: 2.43974
PPO Batch Consumption Time: 0.27891
Total Iteration Time: 4.72921

Cumulative Model Updates: 258,434
Cumulative Timesteps: 2,155,911,110

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80,328.46406
Policy Entropy: 2.73011
Value Function Loss: 0.01158

Mean KL Divergence: 0.00631
SB3 Clip Fraction: 0.06051
Policy Update Magnitude: 0.30695
Value Function Update Magnitude: 0.37676

Collected Steps per Second: 22,221.85416
Overall Steps per Second: 10,512.27313

Timestep Collection Time: 2.25202
Timestep Consumption Time: 2.50851
PPO Batch Consumption Time: 0.29349
Total Iteration Time: 4.76053

Cumulative Model Updates: 258,440
Cumulative Timesteps: 2,155,961,154

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 2155961154...
Checkpoint 2155961154 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 76,506.27588
Policy Entropy: 2.74125
Value Function Loss: 0.00972

Mean KL Divergence: 0.00684
SB3 Clip Fraction: 0.06430
Policy Update Magnitude: 0.31486
Value Function Update Magnitude: 0.34253

Collected Steps per Second: 21,370.26334
Overall Steps per Second: 10,513.28347

Timestep Collection Time: 2.34017
Timestep Consumption Time: 2.41667
PPO Batch Consumption Time: 0.27883
Total Iteration Time: 4.75684

Cumulative Model Updates: 258,446
Cumulative Timesteps: 2,156,011,164

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76,506.27588
Policy Entropy: 2.74150
Value Function Loss: 0.00842

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.07058
Policy Update Magnitude: 0.28930
Value Function Update Magnitude: 0.30234

Collected Steps per Second: 22,118.72805
Overall Steps per Second: 10,511.32042

Timestep Collection Time: 2.26089
Timestep Consumption Time: 2.49665
PPO Batch Consumption Time: 0.28820
Total Iteration Time: 4.75754

Cumulative Model Updates: 258,452
Cumulative Timesteps: 2,156,061,172

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2156061172...
Checkpoint 2156061172 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 75,561.85493
Policy Entropy: 2.74519
Value Function Loss: 0.00843

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.08772
Policy Update Magnitude: 0.27017
Value Function Update Magnitude: 0.25173

Collected Steps per Second: 20,822.52037
Overall Steps per Second: 10,276.12967

Timestep Collection Time: 2.40125
Timestep Consumption Time: 2.46440
PPO Batch Consumption Time: 0.27696
Total Iteration Time: 4.86565

Cumulative Model Updates: 258,458
Cumulative Timesteps: 2,156,111,172

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 244,291.54684
Policy Entropy: 2.73975
Value Function Loss: 0.00968

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.07435
Policy Update Magnitude: 0.28308
Value Function Update Magnitude: 0.24110

Collected Steps per Second: 22,239.45742
Overall Steps per Second: 10,569.30704

Timestep Collection Time: 2.24889
Timestep Consumption Time: 2.48312
PPO Batch Consumption Time: 0.29090
Total Iteration Time: 4.73200

Cumulative Model Updates: 258,464
Cumulative Timesteps: 2,156,161,186

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2156161186...
Checkpoint 2156161186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 123,128.93441
Policy Entropy: 2.72018
Value Function Loss: 0.01220

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.07416
Policy Update Magnitude: 0.30474
Value Function Update Magnitude: 0.28879

Collected Steps per Second: 21,587.21709
Overall Steps per Second: 10,490.12173

Timestep Collection Time: 2.31748
Timestep Consumption Time: 2.45158
PPO Batch Consumption Time: 0.28410
Total Iteration Time: 4.76906

Cumulative Model Updates: 258,470
Cumulative Timesteps: 2,156,211,214

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 150,205.53960
Policy Entropy: 2.69641
Value Function Loss: 0.01132

Mean KL Divergence: 0.00736
SB3 Clip Fraction: 0.06042
Policy Update Magnitude: 0.31993
Value Function Update Magnitude: 0.33482

Collected Steps per Second: 21,409.97797
Overall Steps per Second: 10,506.03325

Timestep Collection Time: 2.33723
Timestep Consumption Time: 2.42575
PPO Batch Consumption Time: 0.27686
Total Iteration Time: 4.76298

Cumulative Model Updates: 258,476
Cumulative Timesteps: 2,156,261,254

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 2156261254...
Checkpoint 2156261254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 105,218.89159
Policy Entropy: 2.67649
Value Function Loss: 0.01251

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.06917
Policy Update Magnitude: 0.32416
Value Function Update Magnitude: 0.34179

Collected Steps per Second: 20,611.85636
Overall Steps per Second: 10,496.12165

Timestep Collection Time: 2.42579
Timestep Consumption Time: 2.33788
PPO Batch Consumption Time: 0.27874
Total Iteration Time: 4.76366

Cumulative Model Updates: 258,482
Cumulative Timesteps: 2,156,311,254

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 159,524.37458
Policy Entropy: 2.65751
Value Function Loss: 0.01451

Mean KL Divergence: 0.00760
SB3 Clip Fraction: 0.07220
Policy Update Magnitude: 0.34483
Value Function Update Magnitude: 0.34085

Collected Steps per Second: 21,129.08316
Overall Steps per Second: 10,607.15038

Timestep Collection Time: 2.36773
Timestep Consumption Time: 2.34871
PPO Batch Consumption Time: 0.27677
Total Iteration Time: 4.71644

Cumulative Model Updates: 258,488
Cumulative Timesteps: 2,156,361,282

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2156361282...
Checkpoint 2156361282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 90,340.27022
Policy Entropy: 2.66257
Value Function Loss: 0.01433

Mean KL Divergence: 0.00745
SB3 Clip Fraction: 0.06649
Policy Update Magnitude: 0.35192
Value Function Update Magnitude: 0.34949

Collected Steps per Second: 20,799.95596
Overall Steps per Second: 10,491.88260

Timestep Collection Time: 2.40520
Timestep Consumption Time: 2.36306
PPO Batch Consumption Time: 0.27837
Total Iteration Time: 4.76826

Cumulative Model Updates: 258,494
Cumulative Timesteps: 2,156,411,310

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97,796.75226
Policy Entropy: 2.67109
Value Function Loss: 0.01344

Mean KL Divergence: 0.00772
SB3 Clip Fraction: 0.06854
Policy Update Magnitude: 0.33872
Value Function Update Magnitude: 0.35701

Collected Steps per Second: 21,637.82121
Overall Steps per Second: 10,489.46591

Timestep Collection Time: 2.31197
Timestep Consumption Time: 2.45720
PPO Batch Consumption Time: 0.27910
Total Iteration Time: 4.76917

Cumulative Model Updates: 258,500
Cumulative Timesteps: 2,156,461,336

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2156461336...
Checkpoint 2156461336 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 65,700.41953
Policy Entropy: 2.68101
Value Function Loss: 0.01248

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.07315
Policy Update Magnitude: 0.32688
Value Function Update Magnitude: 0.35197

Collected Steps per Second: 21,603.29227
Overall Steps per Second: 10,596.71547

Timestep Collection Time: 2.31594
Timestep Consumption Time: 2.40552
PPO Batch Consumption Time: 0.27883
Total Iteration Time: 4.72146

Cumulative Model Updates: 258,506
Cumulative Timesteps: 2,156,511,368

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 104,120.59637
Policy Entropy: 2.69432
Value Function Loss: 0.01171

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.07724
Policy Update Magnitude: 0.31460
Value Function Update Magnitude: 0.32978

Collected Steps per Second: 22,234.04588
Overall Steps per Second: 10,568.29144

Timestep Collection Time: 2.24916
Timestep Consumption Time: 2.48273
PPO Batch Consumption Time: 0.29318
Total Iteration Time: 4.73189

Cumulative Model Updates: 258,512
Cumulative Timesteps: 2,156,561,376

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2156561376...
Checkpoint 2156561376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 77,651.46644
Policy Entropy: 2.71146
Value Function Loss: 0.01114

Mean KL Divergence: 0.01164
SB3 Clip Fraction: 0.10170
Policy Update Magnitude: 0.29902
Value Function Update Magnitude: 0.30292

Collected Steps per Second: 21,609.05246
Overall Steps per Second: 10,537.80220

Timestep Collection Time: 2.31523
Timestep Consumption Time: 2.43244
PPO Batch Consumption Time: 0.27872
Total Iteration Time: 4.74767

Cumulative Model Updates: 258,518
Cumulative Timesteps: 2,156,611,406

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77,651.46644
Policy Entropy: 2.72826
Value Function Loss: 0.01067

Mean KL Divergence: 0.01547
SB3 Clip Fraction: 0.12206
Policy Update Magnitude: 0.27834
Value Function Update Magnitude: 0.27447

Collected Steps per Second: 22,210.04666
Overall Steps per Second: 10,514.64682

Timestep Collection Time: 2.25150
Timestep Consumption Time: 2.50434
PPO Batch Consumption Time: 0.29121
Total Iteration Time: 4.75584

Cumulative Model Updates: 258,524
Cumulative Timesteps: 2,156,661,412

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2156661412...
Checkpoint 2156661412 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 77,651.46644
Policy Entropy: 2.72922
Value Function Loss: 0.00997

Mean KL Divergence: 0.01186
SB3 Clip Fraction: 0.10172
Policy Update Magnitude: 0.27066
Value Function Update Magnitude: 0.24384

Collected Steps per Second: 20,814.43638
Overall Steps per Second: 10,167.03963

Timestep Collection Time: 2.40372
Timestep Consumption Time: 2.51728
PPO Batch Consumption Time: 0.29143
Total Iteration Time: 4.92100

Cumulative Model Updates: 258,530
Cumulative Timesteps: 2,156,711,444

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79,331.16610
Policy Entropy: 2.70220
Value Function Loss: 0.01237

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.07528
Policy Update Magnitude: 0.29473
Value Function Update Magnitude: 0.23264

Collected Steps per Second: 21,991.82718
Overall Steps per Second: 10,525.08671

Timestep Collection Time: 2.27403
Timestep Consumption Time: 2.47748
PPO Batch Consumption Time: 0.28813
Total Iteration Time: 4.75150

Cumulative Model Updates: 258,536
Cumulative Timesteps: 2,156,761,454

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2156761454...
Checkpoint 2156761454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 74,164.83959
Policy Entropy: 2.69779
Value Function Loss: 0.01144

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.07894
Policy Update Magnitude: 0.30918
Value Function Update Magnitude: 0.25754

Collected Steps per Second: 21,358.17319
Overall Steps per Second: 10,509.42301

Timestep Collection Time: 2.34243
Timestep Consumption Time: 2.41806
PPO Batch Consumption Time: 0.27891
Total Iteration Time: 4.76049

Cumulative Model Updates: 258,542
Cumulative Timesteps: 2,156,811,484

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 94,719.18956
Policy Entropy: 2.69843
Value Function Loss: 0.01175

Mean KL Divergence: 0.00741
SB3 Clip Fraction: 0.06805
Policy Update Magnitude: 0.30204
Value Function Update Magnitude: 0.27322

Collected Steps per Second: 21,464.09176
Overall Steps per Second: 10,511.89995

Timestep Collection Time: 2.33152
Timestep Consumption Time: 2.42918
PPO Batch Consumption Time: 0.27781
Total Iteration Time: 4.76070

Cumulative Model Updates: 258,548
Cumulative Timesteps: 2,156,861,528

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 2156861528...
Checkpoint 2156861528 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 148,031.28258
Policy Entropy: 2.69979
Value Function Loss: 0.01121

Mean KL Divergence: 0.00623
SB3 Clip Fraction: 0.06004
Policy Update Magnitude: 0.30147
Value Function Update Magnitude: 0.28376

Collected Steps per Second: 20,826.84436
Overall Steps per Second: 10,339.88894

Timestep Collection Time: 2.40344
Timestep Consumption Time: 2.43762
PPO Batch Consumption Time: 0.29305
Total Iteration Time: 4.84106

Cumulative Model Updates: 258,554
Cumulative Timesteps: 2,156,911,584

Timesteps Collected: 50,056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 121,513.48932
Policy Entropy: 2.68248
Value Function Loss: 0.01074

Mean KL Divergence: 0.00605
SB3 Clip Fraction: 0.05919
Policy Update Magnitude: 0.30277
Value Function Update Magnitude: 0.28435

Collected Steps per Second: 21,588.70317
Overall Steps per Second: 10,549.14191

Timestep Collection Time: 2.31603
Timestep Consumption Time: 2.42370
PPO Batch Consumption Time: 0.28948
Total Iteration Time: 4.73972

Cumulative Model Updates: 258,560
Cumulative Timesteps: 2,156,961,584

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2156961584...
Checkpoint 2156961584 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 121,883.02623
Policy Entropy: 2.67551
Value Function Loss: 0.01041

Mean KL Divergence: 0.00637
SB3 Clip Fraction: 0.06138
Policy Update Magnitude: 0.29590
Value Function Update Magnitude: 0.27049

Collected Steps per Second: 21,441.20482
Overall Steps per Second: 10,524.38744

Timestep Collection Time: 2.33242
Timestep Consumption Time: 2.41940
PPO Batch Consumption Time: 0.29316
Total Iteration Time: 4.75182

Cumulative Model Updates: 258,566
Cumulative Timesteps: 2,157,011,594

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 107,594.83504
Policy Entropy: 2.70191
Value Function Loss: 0.00870

Mean KL Divergence: 0.00558
SB3 Clip Fraction: 0.05130
Policy Update Magnitude: 0.28252
Value Function Update Magnitude: 0.24462

Collected Steps per Second: 21,880.37335
Overall Steps per Second: 10,491.87492

Timestep Collection Time: 2.28570
Timestep Consumption Time: 2.48103
PPO Batch Consumption Time: 0.29210
Total Iteration Time: 4.76674

Cumulative Model Updates: 258,572
Cumulative Timesteps: 2,157,061,606

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2157061606...
Checkpoint 2157061606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 107,594.83504
Policy Entropy: 2.72068
Value Function Loss: 0.00807

Mean KL Divergence: 0.00606
SB3 Clip Fraction: 0.05535
Policy Update Magnitude: 0.27108
Value Function Update Magnitude: 0.22462

Collected Steps per Second: 21,686.10930
Overall Steps per Second: 10,538.74722

Timestep Collection Time: 2.30728
Timestep Consumption Time: 2.44053
PPO Batch Consumption Time: 0.28489
Total Iteration Time: 4.74781

Cumulative Model Updates: 258,578
Cumulative Timesteps: 2,157,111,642

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 96,786.65805
Policy Entropy: 2.72519
Value Function Loss: 0.00913

Mean KL Divergence: 0.00635
SB3 Clip Fraction: 0.06254
Policy Update Magnitude: 0.27435
Value Function Update Magnitude: 0.21708

Collected Steps per Second: 22,123.43096
Overall Steps per Second: 10,593.20082

Timestep Collection Time: 2.26095
Timestep Consumption Time: 2.46095
PPO Batch Consumption Time: 0.29144
Total Iteration Time: 4.72190

Cumulative Model Updates: 258,584
Cumulative Timesteps: 2,157,161,662

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2157161662...
Checkpoint 2157161662 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 111,395.81368
Policy Entropy: 2.70745
Value Function Loss: 0.01028

Mean KL Divergence: 0.00678
SB3 Clip Fraction: 0.06811
Policy Update Magnitude: 0.28459
Value Function Update Magnitude: 0.24233

Collected Steps per Second: 21,975.03240
Overall Steps per Second: 10,500.13176

Timestep Collection Time: 2.27604
Timestep Consumption Time: 2.48733
PPO Batch Consumption Time: 0.28967
Total Iteration Time: 4.76337

Cumulative Model Updates: 258,590
Cumulative Timesteps: 2,157,211,678

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 135,411.85228
Policy Entropy: 2.70897
Value Function Loss: 0.01054

Mean KL Divergence: 0.00743
SB3 Clip Fraction: 0.07060
Policy Update Magnitude: 0.28605
Value Function Update Magnitude: 0.23109

Collected Steps per Second: 21,703.33844
Overall Steps per Second: 10,435.30129

Timestep Collection Time: 2.30444
Timestep Consumption Time: 2.48833
PPO Batch Consumption Time: 0.28718
Total Iteration Time: 4.79277

Cumulative Model Updates: 258,596
Cumulative Timesteps: 2,157,261,692

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2157261692...
Checkpoint 2157261692 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 135,411.85228
Policy Entropy: 2.74469
Value Function Loss: 0.00952

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.08322
Policy Update Magnitude: 0.27679
Value Function Update Magnitude: 0.20097

Collected Steps per Second: 21,537.57385
Overall Steps per Second: 10,389.51651

Timestep Collection Time: 2.32236
Timestep Consumption Time: 2.49192
PPO Batch Consumption Time: 0.28984
Total Iteration Time: 4.81428

Cumulative Model Updates: 258,602
Cumulative Timesteps: 2,157,311,710

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 144,061.73762
Policy Entropy: 2.74926
Value Function Loss: 0.00854

Mean KL Divergence: 0.00750
SB3 Clip Fraction: 0.06912
Policy Update Magnitude: 0.26116
Value Function Update Magnitude: 0.18148

Collected Steps per Second: 21,468.40767
Overall Steps per Second: 10,320.24791

Timestep Collection Time: 2.32984
Timestep Consumption Time: 2.51675
PPO Batch Consumption Time: 0.29299
Total Iteration Time: 4.84659

Cumulative Model Updates: 258,608
Cumulative Timesteps: 2,157,361,728

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2157361728...
Checkpoint 2157361728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 144,061.73762
Policy Entropy: 2.73254
Value Function Loss: 0.00832

Mean KL Divergence: 0.00663
SB3 Clip Fraction: 0.06070
Policy Update Magnitude: 0.25560
Value Function Update Magnitude: 0.16479

Collected Steps per Second: 21,500.74679
Overall Steps per Second: 10,515.18476

Timestep Collection Time: 2.32587
Timestep Consumption Time: 2.42992
PPO Batch Consumption Time: 0.27812
Total Iteration Time: 4.75579

Cumulative Model Updates: 258,614
Cumulative Timesteps: 2,157,411,736

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83,745.95570
Policy Entropy: 2.72375
Value Function Loss: 0.01064

Mean KL Divergence: 0.00609
SB3 Clip Fraction: 0.06129
Policy Update Magnitude: 0.27802
Value Function Update Magnitude: 0.19040

Collected Steps per Second: 22,077.46316
Overall Steps per Second: 10,612.96851

Timestep Collection Time: 2.26620
Timestep Consumption Time: 2.44803
PPO Batch Consumption Time: 0.27700
Total Iteration Time: 4.71423

Cumulative Model Updates: 258,620
Cumulative Timesteps: 2,157,461,768

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2157461768...
Checkpoint 2157461768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 117,354.72271
Policy Entropy: 2.71182
Value Function Loss: 0.01252

Mean KL Divergence: 0.00665
SB3 Clip Fraction: 0.06220
Policy Update Magnitude: 0.31380
Value Function Update Magnitude: 0.28572

Collected Steps per Second: 22,163.62845
Overall Steps per Second: 10,465.14257

Timestep Collection Time: 2.25784
Timestep Consumption Time: 2.52394
PPO Batch Consumption Time: 0.29096
Total Iteration Time: 4.78178

Cumulative Model Updates: 258,626
Cumulative Timesteps: 2,157,511,810

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 104,722.18459
Policy Entropy: 2.71336
Value Function Loss: 0.01213

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.06888
Policy Update Magnitude: 0.31980
Value Function Update Magnitude: 0.33512

Collected Steps per Second: 21,656.35753
Overall Steps per Second: 10,524.63050

Timestep Collection Time: 2.30907
Timestep Consumption Time: 2.44226
PPO Batch Consumption Time: 0.27872
Total Iteration Time: 4.75133

Cumulative Model Updates: 258,632
Cumulative Timesteps: 2,157,561,816

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2157561816...
Checkpoint 2157561816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 104,722.18459
Policy Entropy: 2.69019
Value Function Loss: 0.01113

Mean KL Divergence: 0.00733
SB3 Clip Fraction: 0.06530
Policy Update Magnitude: 0.31497
Value Function Update Magnitude: 0.33729

Collected Steps per Second: 22,118.19181
Overall Steps per Second: 10,664.00189

Timestep Collection Time: 2.26167
Timestep Consumption Time: 2.42925
PPO Batch Consumption Time: 0.27873
Total Iteration Time: 4.69092

Cumulative Model Updates: 258,638
Cumulative Timesteps: 2,157,611,840

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 105,078.10256
Policy Entropy: 2.69037
Value Function Loss: 0.01054

Mean KL Divergence: 0.00659
SB3 Clip Fraction: 0.06302
Policy Update Magnitude: 0.30786
Value Function Update Magnitude: 0.28826

Collected Steps per Second: 22,152.04098
Overall Steps per Second: 10,505.39912

Timestep Collection Time: 2.25812
Timestep Consumption Time: 2.50343
PPO Batch Consumption Time: 0.29351
Total Iteration Time: 4.76155

Cumulative Model Updates: 258,644
Cumulative Timesteps: 2,157,661,862

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2157661862...
Checkpoint 2157661862 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 92,025.41013
Policy Entropy: 2.67493
Value Function Loss: 0.01119

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.07415
Policy Update Magnitude: 0.30353
Value Function Update Magnitude: 0.26801

Collected Steps per Second: 22,067.66866
Overall Steps per Second: 10,596.19851

Timestep Collection Time: 2.26712
Timestep Consumption Time: 2.45439
PPO Batch Consumption Time: 0.28484
Total Iteration Time: 4.72150

Cumulative Model Updates: 258,650
Cumulative Timesteps: 2,157,711,892

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 159,714.50075
Policy Entropy: 2.68416
Value Function Loss: 0.01130

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.08352
Policy Update Magnitude: 0.31061
Value Function Update Magnitude: 0.27048

Collected Steps per Second: 21,139.11248
Overall Steps per Second: 10,456.54811

Timestep Collection Time: 2.36623
Timestep Consumption Time: 2.41738
PPO Batch Consumption Time: 0.28954
Total Iteration Time: 4.78361

Cumulative Model Updates: 258,656
Cumulative Timesteps: 2,157,761,912

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2157761912...
Checkpoint 2157761912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 159,403.38788
Policy Entropy: 2.68385
Value Function Loss: 0.01180

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.07448
Policy Update Magnitude: 0.31533
Value Function Update Magnitude: 0.24651

Collected Steps per Second: 21,039.20662
Overall Steps per Second: 10,582.99721

Timestep Collection Time: 2.37813
Timestep Consumption Time: 2.34964
PPO Batch Consumption Time: 0.27833
Total Iteration Time: 4.72777

Cumulative Model Updates: 258,662
Cumulative Timesteps: 2,157,811,946

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 124,269.44183
Policy Entropy: 2.69919
Value Function Loss: 0.01317

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.07366
Policy Update Magnitude: 0.32436
Value Function Update Magnitude: 0.27667

Collected Steps per Second: 20,939.57336
Overall Steps per Second: 10,549.69691

Timestep Collection Time: 2.38897
Timestep Consumption Time: 2.35278
PPO Batch Consumption Time: 0.27717
Total Iteration Time: 4.74175

Cumulative Model Updates: 258,668
Cumulative Timesteps: 2,157,861,970

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2157861970...
Checkpoint 2157861970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 124,269.44183
Policy Entropy: 2.69245
Value Function Loss: 0.01136

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.07653
Policy Update Magnitude: 0.31238
Value Function Update Magnitude: 0.32340

Collected Steps per Second: 21,078.38348
Overall Steps per Second: 10,513.29822

Timestep Collection Time: 2.37276
Timestep Consumption Time: 2.38445
PPO Batch Consumption Time: 0.27820
Total Iteration Time: 4.75721

Cumulative Model Updates: 258,674
Cumulative Timesteps: 2,157,911,984

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 101,454.71582
Policy Entropy: 2.70348
Value Function Loss: 0.01134

Mean KL Divergence: 0.00772
SB3 Clip Fraction: 0.06798
Policy Update Magnitude: 0.30450
Value Function Update Magnitude: 0.31091

Collected Steps per Second: 21,463.79937
Overall Steps per Second: 10,473.83522

Timestep Collection Time: 2.33090
Timestep Consumption Time: 2.44576
PPO Batch Consumption Time: 0.27884
Total Iteration Time: 4.77666

Cumulative Model Updates: 258,680
Cumulative Timesteps: 2,157,962,014

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2157962014...
Checkpoint 2157962014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 101,454.71582
Policy Entropy: 2.70851
Value Function Loss: 0.00957

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.07252
Policy Update Magnitude: 0.29658
Value Function Update Magnitude: 0.28502

Collected Steps per Second: 20,907.12470
Overall Steps per Second: 10,261.76020

Timestep Collection Time: 2.39335
Timestep Consumption Time: 2.48281
PPO Batch Consumption Time: 0.29164
Total Iteration Time: 4.87616

Cumulative Model Updates: 258,686
Cumulative Timesteps: 2,158,012,052

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 139,138.94574
Policy Entropy: 2.71768
Value Function Loss: 0.00957

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.07231
Policy Update Magnitude: 0.28871
Value Function Update Magnitude: 0.27920

Collected Steps per Second: 21,465.06910
Overall Steps per Second: 10,416.72830

Timestep Collection Time: 2.32937
Timestep Consumption Time: 2.47061
PPO Batch Consumption Time: 0.28669
Total Iteration Time: 4.79997

Cumulative Model Updates: 258,692
Cumulative Timesteps: 2,158,062,052

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2158062052...
Checkpoint 2158062052 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 126,900.53383
Policy Entropy: 2.71133
Value Function Loss: 0.01273

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.08012
Policy Update Magnitude: 0.30196
Value Function Update Magnitude: 0.26234

Collected Steps per Second: 21,565.32353
Overall Steps per Second: 10,372.04199

Timestep Collection Time: 2.31882
Timestep Consumption Time: 2.50241
PPO Batch Consumption Time: 0.29180
Total Iteration Time: 4.82123

Cumulative Model Updates: 258,698
Cumulative Timesteps: 2,158,112,058

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 113,584.84168
Policy Entropy: 2.71375
Value Function Loss: 0.01318

Mean KL Divergence: 0.01070
SB3 Clip Fraction: 0.09371
Policy Update Magnitude: 0.31128
Value Function Update Magnitude: 0.30153

Collected Steps per Second: 21,694.99218
Overall Steps per Second: 10,393.30666

Timestep Collection Time: 2.30560
Timestep Consumption Time: 2.50711
PPO Batch Consumption Time: 0.29318
Total Iteration Time: 4.81271

Cumulative Model Updates: 258,704
Cumulative Timesteps: 2,158,162,078

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2158162078...
Checkpoint 2158162078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89,177.45087
Policy Entropy: 2.70581
Value Function Loss: 0.01401

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.09322
Policy Update Magnitude: 0.31512
Value Function Update Magnitude: 0.31478

Collected Steps per Second: 21,648.83221
Overall Steps per Second: 10,495.25976

Timestep Collection Time: 2.30959
Timestep Consumption Time: 2.45446
PPO Batch Consumption Time: 0.27824
Total Iteration Time: 4.76406

Cumulative Model Updates: 258,710
Cumulative Timesteps: 2,158,212,078

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90,017.93517
Policy Entropy: 2.70870
Value Function Loss: 0.01279

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.09368
Policy Update Magnitude: 0.32182
Value Function Update Magnitude: 0.31039

Collected Steps per Second: 21,970.51359
Overall Steps per Second: 10,483.44762

Timestep Collection Time: 2.27760
Timestep Consumption Time: 2.49564
PPO Batch Consumption Time: 0.28770
Total Iteration Time: 4.77324

Cumulative Model Updates: 258,716
Cumulative Timesteps: 2,158,262,118

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 2158262118...
Checkpoint 2158262118 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 77,352.24589
Policy Entropy: 2.70974
Value Function Loss: 0.01164

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.08552
Policy Update Magnitude: 0.31562
Value Function Update Magnitude: 0.30085

Collected Steps per Second: 21,897.02482
Overall Steps per Second: 10,609.94055

Timestep Collection Time: 2.28533
Timestep Consumption Time: 2.43119
PPO Batch Consumption Time: 0.27855
Total Iteration Time: 4.71652

Cumulative Model Updates: 258,722
Cumulative Timesteps: 2,158,312,160

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 98,099.75242
Policy Entropy: 2.71352
Value Function Loss: 0.01157

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.09006
Policy Update Magnitude: 0.30618
Value Function Update Magnitude: 0.31174

Collected Steps per Second: 22,084.33181
Overall Steps per Second: 10,507.65944

Timestep Collection Time: 2.26423
Timestep Consumption Time: 2.49458
PPO Batch Consumption Time: 0.29014
Total Iteration Time: 4.75881

Cumulative Model Updates: 258,728
Cumulative Timesteps: 2,158,362,164

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2158362164...
Checkpoint 2158362164 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 98,099.75242
Policy Entropy: 2.72852
Value Function Loss: 0.00958

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.08718
Policy Update Magnitude: 0.28993
Value Function Update Magnitude: 0.29185

Collected Steps per Second: 21,314.93055
Overall Steps per Second: 10,636.19927

Timestep Collection Time: 2.34718
Timestep Consumption Time: 2.35657
PPO Batch Consumption Time: 0.27946
Total Iteration Time: 4.70375

Cumulative Model Updates: 258,734
Cumulative Timesteps: 2,158,412,194

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 120,193.56426
Policy Entropy: 2.71030
Value Function Loss: 0.01050

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.07291
Policy Update Magnitude: 0.28554
Value Function Update Magnitude: 0.24690

Collected Steps per Second: 21,721.13589
Overall Steps per Second: 10,582.10666

Timestep Collection Time: 2.30191
Timestep Consumption Time: 2.42305
PPO Batch Consumption Time: 0.29114
Total Iteration Time: 4.72496

Cumulative Model Updates: 258,740
Cumulative Timesteps: 2,158,462,194

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2158462194...
Checkpoint 2158462194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 145,495.29423
Policy Entropy: 2.72335
Value Function Loss: 0.00952

Mean KL Divergence: 0.00762
SB3 Clip Fraction: 0.07244
Policy Update Magnitude: 0.28497
Value Function Update Magnitude: 0.21196

Collected Steps per Second: 21,349.91772
Overall Steps per Second: 10,510.36791

Timestep Collection Time: 2.34193
Timestep Consumption Time: 2.41528
PPO Batch Consumption Time: 0.28798
Total Iteration Time: 4.75721

Cumulative Model Updates: 258,746
Cumulative Timesteps: 2,158,512,194

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 132,029.31579
Policy Entropy: 2.71901
Value Function Loss: 0.00981

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.07393
Policy Update Magnitude: 0.28131
Value Function Update Magnitude: 0.25048

Collected Steps per Second: 21,113.80270
Overall Steps per Second: 10,470.65803

Timestep Collection Time: 2.36840
Timestep Consumption Time: 2.40742
PPO Batch Consumption Time: 0.27803
Total Iteration Time: 4.77582

Cumulative Model Updates: 258,752
Cumulative Timesteps: 2,158,562,200

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2158562200...
Checkpoint 2158562200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 133,904.09010
Policy Entropy: 2.72041
Value Function Loss: 0.00948

Mean KL Divergence: 0.00681
SB3 Clip Fraction: 0.06594
Policy Update Magnitude: 0.28722
Value Function Update Magnitude: 0.25684

Collected Steps per Second: 21,364.41879
Overall Steps per Second: 10,569.91591

Timestep Collection Time: 2.34090
Timestep Consumption Time: 2.39064
PPO Batch Consumption Time: 0.27825
Total Iteration Time: 4.73154

Cumulative Model Updates: 258,758
Cumulative Timesteps: 2,158,612,212

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 109,462.03202
Policy Entropy: 2.70215
Value Function Loss: 0.00989

Mean KL Divergence: 0.00702
SB3 Clip Fraction: 0.06446
Policy Update Magnitude: 0.28811
Value Function Update Magnitude: 0.25529

Collected Steps per Second: 21,690.98780
Overall Steps per Second: 10,586.55870

Timestep Collection Time: 2.30520
Timestep Consumption Time: 2.41796
PPO Batch Consumption Time: 0.27679
Total Iteration Time: 4.72316

Cumulative Model Updates: 258,764
Cumulative Timesteps: 2,158,662,214

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2158662214...
Checkpoint 2158662214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 99,292.47188
Policy Entropy: 2.71026
Value Function Loss: 0.00998

Mean KL Divergence: 0.00712
SB3 Clip Fraction: 0.06736
Policy Update Magnitude: 0.28914
Value Function Update Magnitude: 0.25849

Collected Steps per Second: 21,617.98895
Overall Steps per Second: 10,510.75560

Timestep Collection Time: 2.31354
Timestep Consumption Time: 2.44483
PPO Batch Consumption Time: 0.27916
Total Iteration Time: 4.75836

Cumulative Model Updates: 258,770
Cumulative Timesteps: 2,158,712,228

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90,828.67368
Policy Entropy: 2.70857
Value Function Loss: 0.00939

Mean KL Divergence: 0.00701
SB3 Clip Fraction: 0.06633
Policy Update Magnitude: 0.28047
Value Function Update Magnitude: 0.27663

Collected Steps per Second: 21,969.60720
Overall Steps per Second: 10,549.18631

Timestep Collection Time: 2.27778
Timestep Consumption Time: 2.46590
PPO Batch Consumption Time: 0.27716
Total Iteration Time: 4.74368

Cumulative Model Updates: 258,776
Cumulative Timesteps: 2,158,762,270

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 2158762270...
Checkpoint 2158762270 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 160,123.22174
Policy Entropy: 2.70383
Value Function Loss: 0.01098

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.07531
Policy Update Magnitude: 0.29024
Value Function Update Magnitude: 0.25067

Collected Steps per Second: 21,665.40617
Overall Steps per Second: 10,521.49157

Timestep Collection Time: 2.30875
Timestep Consumption Time: 2.44533
PPO Batch Consumption Time: 0.27778
Total Iteration Time: 4.75408

Cumulative Model Updates: 258,782
Cumulative Timesteps: 2,158,812,290

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 148,400.89653
Policy Entropy: 2.70992
Value Function Loss: 0.01146

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.07262
Policy Update Magnitude: 0.29121
Value Function Update Magnitude: 0.25385

Collected Steps per Second: 22,200.71647
Overall Steps per Second: 10,504.85150

Timestep Collection Time: 2.25335
Timestep Consumption Time: 2.50883
PPO Batch Consumption Time: 0.28995
Total Iteration Time: 4.76218

Cumulative Model Updates: 258,788
Cumulative Timesteps: 2,158,862,316

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2158862316...
Checkpoint 2158862316 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 124,795.63270
Policy Entropy: 2.72361
Value Function Loss: 0.01377

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.08548
Policy Update Magnitude: 0.29651
Value Function Update Magnitude: 0.27501

Collected Steps per Second: 22,028.13471
Overall Steps per Second: 10,629.12621

Timestep Collection Time: 2.26992
Timestep Consumption Time: 2.43433
PPO Batch Consumption Time: 0.27842
Total Iteration Time: 4.70424

Cumulative Model Updates: 258,794
Cumulative Timesteps: 2,158,912,318

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 114,866.24764
Policy Entropy: 2.72534
Value Function Loss: 0.01214

Mean KL Divergence: 0.01228
SB3 Clip Fraction: 0.10870
Policy Update Magnitude: 0.30902
Value Function Update Magnitude: 0.30090

Collected Steps per Second: 22,102.43381
Overall Steps per Second: 10,485.28168

Timestep Collection Time: 2.26301
Timestep Consumption Time: 2.50730
PPO Batch Consumption Time: 0.29327
Total Iteration Time: 4.77031

Cumulative Model Updates: 258,800
Cumulative Timesteps: 2,158,962,336

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2158962336...
Checkpoint 2158962336 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 98,311.05095
Policy Entropy: 2.67909
Value Function Loss: 0.01280

Mean KL Divergence: 0.01118
SB3 Clip Fraction: 0.09814
Policy Update Magnitude: 0.32021
Value Function Update Magnitude: 0.29937

Collected Steps per Second: 21,774.74437
Overall Steps per Second: 10,573.45415

Timestep Collection Time: 2.29789
Timestep Consumption Time: 2.43434
PPO Batch Consumption Time: 0.27881
Total Iteration Time: 4.73223

Cumulative Model Updates: 258,806
Cumulative Timesteps: 2,159,012,372

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 108,782.20805
Policy Entropy: 2.68833
Value Function Loss: 0.01166

Mean KL Divergence: 0.01295
SB3 Clip Fraction: 0.10434
Policy Update Magnitude: 0.31135
Value Function Update Magnitude: 0.29948

Collected Steps per Second: 22,255.21301
Overall Steps per Second: 10,515.80788

Timestep Collection Time: 2.24783
Timestep Consumption Time: 2.50939
PPO Batch Consumption Time: 0.29334
Total Iteration Time: 4.75722

Cumulative Model Updates: 258,812
Cumulative Timesteps: 2,159,062,398

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2159062398...
Checkpoint 2159062398 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 108,782.20805
Policy Entropy: 2.70108
Value Function Loss: 0.00975

Mean KL Divergence: 0.01244
SB3 Clip Fraction: 0.10647
Policy Update Magnitude: 0.28486
Value Function Update Magnitude: 0.27655

Collected Steps per Second: 20,972.41364
Overall Steps per Second: 10,217.24520

Timestep Collection Time: 2.38408
Timestep Consumption Time: 2.50960
PPO Batch Consumption Time: 0.29357
Total Iteration Time: 4.89369

Cumulative Model Updates: 258,818
Cumulative Timesteps: 2,159,112,398

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91,074.91171
Policy Entropy: 2.72772
Value Function Loss: 0.00873

Mean KL Divergence: 0.01146
SB3 Clip Fraction: 0.10010
Policy Update Magnitude: 0.27164
Value Function Update Magnitude: 0.25092

Collected Steps per Second: 21,848.95349
Overall Steps per Second: 10,457.66025

Timestep Collection Time: 2.28862
Timestep Consumption Time: 2.49294
PPO Batch Consumption Time: 0.29145
Total Iteration Time: 4.78157

Cumulative Model Updates: 258,824
Cumulative Timesteps: 2,159,162,402

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2159162402...
Checkpoint 2159162402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 123,880.32994
Policy Entropy: 2.70816
Value Function Loss: 0.01189

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.09369
Policy Update Magnitude: 0.30966
Value Function Update Magnitude: 0.24395

Collected Steps per Second: 21,372.69744
Overall Steps per Second: 10,377.09301

Timestep Collection Time: 2.34065
Timestep Consumption Time: 2.48016
PPO Batch Consumption Time: 0.28867
Total Iteration Time: 4.82081

Cumulative Model Updates: 258,830
Cumulative Timesteps: 2,159,212,428

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 110,353.73511
Policy Entropy: 2.68736
Value Function Loss: 0.01345

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.08370
Policy Update Magnitude: 0.32530
Value Function Update Magnitude: 0.32378

Collected Steps per Second: 21,968.06726
Overall Steps per Second: 10,623.22736

Timestep Collection Time: 2.27712
Timestep Consumption Time: 2.43180
PPO Batch Consumption Time: 0.27781
Total Iteration Time: 4.70893

Cumulative Model Updates: 258,836
Cumulative Timesteps: 2,159,262,452

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2159262452...
Checkpoint 2159262452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 105,132.00617
Policy Entropy: 2.67696
Value Function Loss: 0.01242

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.07162
Policy Update Magnitude: 0.32264
Value Function Update Magnitude: 0.36013

Collected Steps per Second: 21,455.02135
Overall Steps per Second: 10,324.51268

Timestep Collection Time: 2.33055
Timestep Consumption Time: 2.51249
PPO Batch Consumption Time: 0.29339
Total Iteration Time: 4.84304

Cumulative Model Updates: 258,842
Cumulative Timesteps: 2,159,312,454

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 170,383.22817
Policy Entropy: 2.68561
Value Function Loss: 0.01192

Mean KL Divergence: 0.00759
SB3 Clip Fraction: 0.06868
Policy Update Magnitude: 0.31270
Value Function Update Magnitude: 0.34268

Collected Steps per Second: 22,302.39493
Overall Steps per Second: 10,443.17176

Timestep Collection Time: 2.24227
Timestep Consumption Time: 2.54631
PPO Batch Consumption Time: 0.29272
Total Iteration Time: 4.78858

Cumulative Model Updates: 258,848
Cumulative Timesteps: 2,159,362,462

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2159362462...
Checkpoint 2159362462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 109,774.48299
Policy Entropy: 2.67512
Value Function Loss: 0.01329

Mean KL Divergence: 0.00743
SB3 Clip Fraction: 0.07014
Policy Update Magnitude: 0.31871
Value Function Update Magnitude: 0.31359

Collected Steps per Second: 21,516.15695
Overall Steps per Second: 10,480.73905

Timestep Collection Time: 2.32476
Timestep Consumption Time: 2.44780
PPO Batch Consumption Time: 0.27886
Total Iteration Time: 4.77256

Cumulative Model Updates: 258,854
Cumulative Timesteps: 2,159,412,482

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67,434.63949
Policy Entropy: 2.66186
Value Function Loss: 0.01519

Mean KL Divergence: 0.00727
SB3 Clip Fraction: 0.06810
Policy Update Magnitude: 0.34951
Value Function Update Magnitude: 0.36552

Collected Steps per Second: 22,206.37032
Overall Steps per Second: 10,575.22531

Timestep Collection Time: 2.25350
Timestep Consumption Time: 2.47851
PPO Batch Consumption Time: 0.28610
Total Iteration Time: 4.73200

Cumulative Model Updates: 258,860
Cumulative Timesteps: 2,159,462,524

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 2159462524...
Checkpoint 2159462524 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 65,036.93770
Policy Entropy: 2.65900
Value Function Loss: 0.01295

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.07494
Policy Update Magnitude: 0.33408
Value Function Update Magnitude: 0.36786

Collected Steps per Second: 22,119.29671
Overall Steps per Second: 10,660.96444

Timestep Collection Time: 2.26047
Timestep Consumption Time: 2.42954
PPO Batch Consumption Time: 0.27765
Total Iteration Time: 4.69001

Cumulative Model Updates: 258,866
Cumulative Timesteps: 2,159,512,524

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 73,538.60474
Policy Entropy: 2.68810
Value Function Loss: 0.01068

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.07955
Policy Update Magnitude: 0.30897
Value Function Update Magnitude: 0.31657

Collected Steps per Second: 22,421.02137
Overall Steps per Second: 10,637.73477

Timestep Collection Time: 2.23192
Timestep Consumption Time: 2.47227
PPO Batch Consumption Time: 0.28926
Total Iteration Time: 4.70420

Cumulative Model Updates: 258,872
Cumulative Timesteps: 2,159,562,566

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 2159562566...
Checkpoint 2159562566 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 94,634.95766
Policy Entropy: 2.70163
Value Function Loss: 0.01127

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.08500
Policy Update Magnitude: 0.30010
Value Function Update Magnitude: 0.27455

Collected Steps per Second: 21,908.30877
Overall Steps per Second: 10,432.94099

Timestep Collection Time: 2.28443
Timestep Consumption Time: 2.51268
PPO Batch Consumption Time: 0.29392
Total Iteration Time: 4.79711

Cumulative Model Updates: 258,878
Cumulative Timesteps: 2,159,612,614

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78,302.01832
Policy Entropy: 2.70567
Value Function Loss: 0.01133

Mean KL Divergence: 0.02229
SB3 Clip Fraction: 0.14319
Policy Update Magnitude: 0.30221
Value Function Update Magnitude: 0.28677

Collected Steps per Second: 21,749.17657
Overall Steps per Second: 10,488.39977

Timestep Collection Time: 2.30004
Timestep Consumption Time: 2.46942
PPO Batch Consumption Time: 0.28582
Total Iteration Time: 4.76946

Cumulative Model Updates: 258,884
Cumulative Timesteps: 2,159,662,638

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2159662638...
Checkpoint 2159662638 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 93,118.83854
Policy Entropy: 2.67370
Value Function Loss: 0.01700

Mean KL Divergence: 0.01815
SB3 Clip Fraction: 0.13361
Policy Update Magnitude: 0.32235
Value Function Update Magnitude: 0.29761

Collected Steps per Second: 21,490.94782
Overall Steps per Second: 10,536.34934

Timestep Collection Time: 2.32768
Timestep Consumption Time: 2.42008
PPO Batch Consumption Time: 0.27823
Total Iteration Time: 4.74775

Cumulative Model Updates: 258,890
Cumulative Timesteps: 2,159,712,662

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 74,263.53428
Policy Entropy: 2.66969
Value Function Loss: 0.01905

Mean KL Divergence: 0.01497
SB3 Clip Fraction: 0.11038
Policy Update Magnitude: 0.35146
Value Function Update Magnitude: 0.31720

Collected Steps per Second: 21,748.87493
Overall Steps per Second: 10,563.05001

Timestep Collection Time: 2.30007
Timestep Consumption Time: 2.43568
PPO Batch Consumption Time: 0.28127
Total Iteration Time: 4.73575

Cumulative Model Updates: 258,896
Cumulative Timesteps: 2,159,762,686

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2159762686...
Checkpoint 2159762686 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 61,718.51790
Policy Entropy: 2.63686
Value Function Loss: 0.01768

Mean KL Divergence: 0.01277
SB3 Clip Fraction: 0.10075
Policy Update Magnitude: 0.36386
Value Function Update Magnitude: 0.35062

Collected Steps per Second: 21,338.93160
Overall Steps per Second: 10,360.05036

Timestep Collection Time: 2.34492
Timestep Consumption Time: 2.48498
PPO Batch Consumption Time: 0.29030
Total Iteration Time: 4.82990

Cumulative Model Updates: 258,902
Cumulative Timesteps: 2,159,812,724

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59,524.16001
Policy Entropy: 2.66109
Value Function Loss: 0.01561

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.08701
Policy Update Magnitude: 0.35546
Value Function Update Magnitude: 0.35697

Collected Steps per Second: 21,256.45249
Overall Steps per Second: 10,596.09225

Timestep Collection Time: 2.35336
Timestep Consumption Time: 2.36763
PPO Batch Consumption Time: 0.27958
Total Iteration Time: 4.72099

Cumulative Model Updates: 258,908
Cumulative Timesteps: 2,159,862,748

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2159862748...
Checkpoint 2159862748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 59,524.16001
Policy Entropy: 2.66080
Value Function Loss: 0.01253

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.08006
Policy Update Magnitude: 0.33636
Value Function Update Magnitude: 0.34735

Collected Steps per Second: 20,606.74727
Overall Steps per Second: 10,313.82722

Timestep Collection Time: 2.42755
Timestep Consumption Time: 2.42263
PPO Batch Consumption Time: 0.28891
Total Iteration Time: 4.85019

Cumulative Model Updates: 258,914
Cumulative Timesteps: 2,159,912,772

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68,097.69559
Policy Entropy: 2.66177
Value Function Loss: 0.01272

Mean KL Divergence: 0.00747
SB3 Clip Fraction: 0.06860
Policy Update Magnitude: 0.32439
Value Function Update Magnitude: 0.30853

Collected Steps per Second: 21,421.78969
Overall Steps per Second: 10,435.57792

Timestep Collection Time: 2.33463
Timestep Consumption Time: 2.45782
PPO Batch Consumption Time: 0.27880
Total Iteration Time: 4.79245

Cumulative Model Updates: 258,920
Cumulative Timesteps: 2,159,962,784

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2159962784...
Checkpoint 2159962784 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 61,162.81835
Policy Entropy: 2.67456
Value Function Loss: 0.01257

Mean KL Divergence: 0.00692
SB3 Clip Fraction: 0.06199
Policy Update Magnitude: 0.34788
Value Function Update Magnitude: 0.32816

Collected Steps per Second: 21,558.92315
Overall Steps per Second: 10,591.08238

Timestep Collection Time: 2.31923
Timestep Consumption Time: 2.40173
PPO Batch Consumption Time: 0.27831
Total Iteration Time: 4.72095

Cumulative Model Updates: 258,926
Cumulative Timesteps: 2,160,012,784

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61,162.81835
Policy Entropy: 2.68008
Value Function Loss: 0.01186

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.06752
Policy Update Magnitude: 0.32175
Value Function Update Magnitude: 0.33559

Collected Steps per Second: 21,939.60865
Overall Steps per Second: 10,518.12636

Timestep Collection Time: 2.27926
Timestep Consumption Time: 2.47501
PPO Batch Consumption Time: 0.28850
Total Iteration Time: 4.75427

Cumulative Model Updates: 258,932
Cumulative Timesteps: 2,160,062,790

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2160062790...
Checkpoint 2160062790 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 59,774.11431
Policy Entropy: 2.68934
Value Function Loss: 0.01236

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.07180
Policy Update Magnitude: 0.30777
Value Function Update Magnitude: 0.32589

Collected Steps per Second: 21,945.04632
Overall Steps per Second: 10,638.39221

Timestep Collection Time: 2.27960
Timestep Consumption Time: 2.42280
PPO Batch Consumption Time: 0.27866
Total Iteration Time: 4.70240

Cumulative Model Updates: 258,938
Cumulative Timesteps: 2,160,112,816

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56,862.29361
Policy Entropy: 2.67735
Value Function Loss: 0.01582

Mean KL Divergence: 0.00756
SB3 Clip Fraction: 0.07386
Policy Update Magnitude: 0.33068
Value Function Update Magnitude: 0.32444

Collected Steps per Second: 22,342.70906
Overall Steps per Second: 10,523.99826

Timestep Collection Time: 2.23912
Timestep Consumption Time: 2.51459
PPO Batch Consumption Time: 0.29059
Total Iteration Time: 4.75371

Cumulative Model Updates: 258,944
Cumulative Timesteps: 2,160,162,844

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2160162844...
Checkpoint 2160162844 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40,040.00823
Policy Entropy: 2.68102
Value Function Loss: 0.01544

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.07873
Policy Update Magnitude: 0.33861
Value Function Update Magnitude: 0.34390

Collected Steps per Second: 21,923.84381
Overall Steps per Second: 10,632.45193

Timestep Collection Time: 2.28181
Timestep Consumption Time: 2.42322
PPO Batch Consumption Time: 0.27825
Total Iteration Time: 4.70503

Cumulative Model Updates: 258,950
Cumulative Timesteps: 2,160,212,870

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70,014.31672
Policy Entropy: 2.70930
Value Function Loss: 0.01476

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.07667
Policy Update Magnitude: 0.32724
Value Function Update Magnitude: 0.33917

Collected Steps per Second: 22,095.31024
Overall Steps per Second: 10,475.66075

Timestep Collection Time: 2.26428
Timestep Consumption Time: 2.51155
PPO Batch Consumption Time: 0.29425
Total Iteration Time: 4.77583

Cumulative Model Updates: 258,956
Cumulative Timesteps: 2,160,262,900

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2160262900...
Checkpoint 2160262900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 61,120.82356
Policy Entropy: 2.70503
Value Function Loss: 0.01251

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.07111
Policy Update Magnitude: 0.32069
Value Function Update Magnitude: 0.32208

Collected Steps per Second: 21,588.96155
Overall Steps per Second: 10,569.08499

Timestep Collection Time: 2.31720
Timestep Consumption Time: 2.41604
PPO Batch Consumption Time: 0.27852
Total Iteration Time: 4.73324

Cumulative Model Updates: 258,962
Cumulative Timesteps: 2,160,312,926

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47,971.39496
Policy Entropy: 2.69730
Value Function Loss: 0.01188

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.07056
Policy Update Magnitude: 0.31349
Value Function Update Magnitude: 0.29934

Collected Steps per Second: 21,792.56616
Overall Steps per Second: 10,589.74807

Timestep Collection Time: 2.29638
Timestep Consumption Time: 2.42932
PPO Batch Consumption Time: 0.27718
Total Iteration Time: 4.72570

Cumulative Model Updates: 258,968
Cumulative Timesteps: 2,160,362,970

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 2160362970...
Checkpoint 2160362970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 53,744.19941
Policy Entropy: 2.68187
Value Function Loss: 0.01139

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.07805
Policy Update Magnitude: 0.31391
Value Function Update Magnitude: 0.30673

Collected Steps per Second: 21,671.31259
Overall Steps per Second: 10,504.34879

Timestep Collection Time: 2.30858
Timestep Consumption Time: 2.45421
PPO Batch Consumption Time: 0.27855
Total Iteration Time: 4.76279

Cumulative Model Updates: 258,974
Cumulative Timesteps: 2,160,413,000

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66,298.59951
Policy Entropy: 2.69463
Value Function Loss: 0.01155

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.07437
Policy Update Magnitude: 0.31797
Value Function Update Magnitude: 0.30606

Collected Steps per Second: 22,017.60880
Overall Steps per Second: 10,569.24268

Timestep Collection Time: 2.27182
Timestep Consumption Time: 2.46078
PPO Batch Consumption Time: 0.27763
Total Iteration Time: 4.73260

Cumulative Model Updates: 258,980
Cumulative Timesteps: 2,160,463,020

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2160463020...
Checkpoint 2160463020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 108,062.02191
Policy Entropy: 2.68724
Value Function Loss: 0.01263

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.07353
Policy Update Magnitude: 0.31874
Value Function Update Magnitude: 0.29066

Collected Steps per Second: 21,849.90378
Overall Steps per Second: 10,570.49036

Timestep Collection Time: 2.28944
Timestep Consumption Time: 2.44298
PPO Batch Consumption Time: 0.27922
Total Iteration Time: 4.73242

Cumulative Model Updates: 258,986
Cumulative Timesteps: 2,160,513,044

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 105,321.57973
Policy Entropy: 2.70221
Value Function Loss: 0.01193

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.07919
Policy Update Magnitude: 0.31136
Value Function Update Magnitude: 0.28373

Collected Steps per Second: 22,090.53232
Overall Steps per Second: 10,479.33489

Timestep Collection Time: 2.26468
Timestep Consumption Time: 2.50929
PPO Batch Consumption Time: 0.29313
Total Iteration Time: 4.77397

Cumulative Model Updates: 258,992
Cumulative Timesteps: 2,160,563,072

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2160563072...
Checkpoint 2160563072 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 125,428.88080
Policy Entropy: 2.68397
Value Function Loss: 0.01309

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.08070
Policy Update Magnitude: 0.31485
Value Function Update Magnitude: 0.31223

Collected Steps per Second: 21,882.26327
Overall Steps per Second: 10,601.85883

Timestep Collection Time: 2.28496
Timestep Consumption Time: 2.43120
PPO Batch Consumption Time: 0.27841
Total Iteration Time: 4.71615

Cumulative Model Updates: 258,998
Cumulative Timesteps: 2,160,613,072

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 135,714.77043
Policy Entropy: 2.68890
Value Function Loss: 0.01314

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.08161
Policy Update Magnitude: 0.32908
Value Function Update Magnitude: 0.31644

Collected Steps per Second: 22,246.86883
Overall Steps per Second: 10,517.12867

Timestep Collection Time: 2.24886
Timestep Consumption Time: 2.50815
PPO Batch Consumption Time: 0.29246
Total Iteration Time: 4.75700

Cumulative Model Updates: 259,004
Cumulative Timesteps: 2,160,663,102

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2160663102...
Checkpoint 2160663102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 135,714.77043
Policy Entropy: 2.66479
Value Function Loss: 0.01337

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.07595
Policy Update Magnitude: 0.32156
Value Function Update Magnitude: 0.29645

Collected Steps per Second: 21,943.36087
Overall Steps per Second: 10,615.34643

Timestep Collection Time: 2.28042
Timestep Consumption Time: 2.43351
PPO Batch Consumption Time: 0.27923
Total Iteration Time: 4.71393

Cumulative Model Updates: 259,010
Cumulative Timesteps: 2,160,713,142

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 109,750.31246
Policy Entropy: 2.67616
Value Function Loss: 0.01495

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.07191
Policy Update Magnitude: 0.32551
Value Function Update Magnitude: 0.31276

Collected Steps per Second: 21,709.33841
Overall Steps per Second: 10,459.11687

Timestep Collection Time: 2.30343
Timestep Consumption Time: 2.47766
PPO Batch Consumption Time: 0.28709
Total Iteration Time: 4.78109

Cumulative Model Updates: 259,016
Cumulative Timesteps: 2,160,763,148

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2160763148...
Checkpoint 2160763148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 112,544.27442
Policy Entropy: 2.69002
Value Function Loss: 0.01406

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.07834
Policy Update Magnitude: 0.32529
Value Function Update Magnitude: 0.32946

Collected Steps per Second: 21,478.40271
Overall Steps per Second: 10,557.26709

Timestep Collection Time: 2.32820
Timestep Consumption Time: 2.40844
PPO Batch Consumption Time: 0.27891
Total Iteration Time: 4.73664

Cumulative Model Updates: 259,022
Cumulative Timesteps: 2,160,813,154

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 64,068.27944
Policy Entropy: 2.67792
Value Function Loss: 0.01418

Mean KL Divergence: 0.00758
SB3 Clip Fraction: 0.06092
Policy Update Magnitude: 0.32377
Value Function Update Magnitude: 0.33488

Collected Steps per Second: 21,529.50204
Overall Steps per Second: 10,534.12052

Timestep Collection Time: 2.32314
Timestep Consumption Time: 2.42486
PPO Batch Consumption Time: 0.27869
Total Iteration Time: 4.74800

Cumulative Model Updates: 259,028
Cumulative Timesteps: 2,160,863,170

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2160863170...
Checkpoint 2160863170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 67,898.23626
Policy Entropy: 2.68900
Value Function Loss: 0.01249

Mean KL Divergence: 0.00686
SB3 Clip Fraction: 0.06164
Policy Update Magnitude: 0.32524
Value Function Update Magnitude: 0.32180

Collected Steps per Second: 21,514.96788
Overall Steps per Second: 10,564.89361

Timestep Collection Time: 2.32508
Timestep Consumption Time: 2.40985
PPO Batch Consumption Time: 0.27796
Total Iteration Time: 4.73493

Cumulative Model Updates: 259,034
Cumulative Timesteps: 2,160,913,194

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 73,709.75398
Policy Entropy: 2.68709
Value Function Loss: 0.01213

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.07540
Policy Update Magnitude: 0.31322
Value Function Update Magnitude: 0.32642

Collected Steps per Second: 21,758.74709
Overall Steps per Second: 10,589.60539

Timestep Collection Time: 2.29885
Timestep Consumption Time: 2.42465
PPO Batch Consumption Time: 0.27678
Total Iteration Time: 4.72350

Cumulative Model Updates: 259,040
Cumulative Timesteps: 2,160,963,214

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2160963214...
Checkpoint 2160963214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 60,890.53888
Policy Entropy: 2.72955
Value Function Loss: 0.01363

Mean KL Divergence: 0.01743
SB3 Clip Fraction: 0.12624
Policy Update Magnitude: 0.29585
Value Function Update Magnitude: 0.30326

Collected Steps per Second: 21,618.08080
Overall Steps per Second: 10,495.17401

Timestep Collection Time: 2.31371
Timestep Consumption Time: 2.45210
PPO Batch Consumption Time: 0.27817
Total Iteration Time: 4.76581

Cumulative Model Updates: 259,046
Cumulative Timesteps: 2,161,013,232

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55,105.98658
Policy Entropy: 2.72339
Value Function Loss: 0.01292

Mean KL Divergence: 0.01887
SB3 Clip Fraction: 0.12682
Policy Update Magnitude: 0.29649
Value Function Update Magnitude: 0.26732

Collected Steps per Second: 21,307.27972
Overall Steps per Second: 10,491.06743

Timestep Collection Time: 2.34671
Timestep Consumption Time: 2.41944
PPO Batch Consumption Time: 0.28867
Total Iteration Time: 4.76615

Cumulative Model Updates: 259,052
Cumulative Timesteps: 2,161,063,234

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2161063234...
Checkpoint 2161063234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 50,923.52167
Policy Entropy: 2.73554
Value Function Loss: 0.01283

Mean KL Divergence: 0.01348
SB3 Clip Fraction: 0.10353
Policy Update Magnitude: 0.30116
Value Function Update Magnitude: 0.21703

Collected Steps per Second: 21,272.92171
Overall Steps per Second: 10,631.23568

Timestep Collection Time: 2.35059
Timestep Consumption Time: 2.35290
PPO Batch Consumption Time: 0.27883
Total Iteration Time: 4.70350

Cumulative Model Updates: 259,058
Cumulative Timesteps: 2,161,113,238

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97,233.45291
Policy Entropy: 2.71056
Value Function Loss: 0.01378

Mean KL Divergence: 0.01053
SB3 Clip Fraction: 0.09434
Policy Update Magnitude: 0.31763
Value Function Update Magnitude: 0.17856

Collected Steps per Second: 21,591.51545
Overall Steps per Second: 10,543.11125

Timestep Collection Time: 2.31656
Timestep Consumption Time: 2.42758
PPO Batch Consumption Time: 0.29335
Total Iteration Time: 4.74414

Cumulative Model Updates: 259,064
Cumulative Timesteps: 2,161,163,256

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2161163256...
Checkpoint 2161163256 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 93,026.51357
Policy Entropy: 2.68227
Value Function Loss: 0.01546

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.07441
Policy Update Magnitude: 0.32553
Value Function Update Magnitude: 0.21097

Collected Steps per Second: 21,394.53176
Overall Steps per Second: 10,547.11159

Timestep Collection Time: 2.33742
Timestep Consumption Time: 2.40397
PPO Batch Consumption Time: 0.27918
Total Iteration Time: 4.74139

Cumulative Model Updates: 259,070
Cumulative Timesteps: 2,161,213,264

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 71,230.49491
Policy Entropy: 2.69208
Value Function Loss: 0.01483

Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.07201
Policy Update Magnitude: 0.31887
Value Function Update Magnitude: 0.22714

Collected Steps per Second: 22,035.15500
Overall Steps per Second: 10,525.20663

Timestep Collection Time: 2.26974
Timestep Consumption Time: 2.48209
PPO Batch Consumption Time: 0.29198
Total Iteration Time: 4.75183

Cumulative Model Updates: 259,076
Cumulative Timesteps: 2,161,263,278

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2161263278...
Checkpoint 2161263278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 88,520.39128
Policy Entropy: 2.72030
Value Function Loss: 0.01249

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.06929
Policy Update Magnitude: 0.29891
Value Function Update Magnitude: 0.23831

Collected Steps per Second: 21,794.33486
Overall Steps per Second: 10,665.46745

Timestep Collection Time: 2.29436
Timestep Consumption Time: 2.39404
PPO Batch Consumption Time: 0.27678
Total Iteration Time: 4.68840

Cumulative Model Updates: 259,082
Cumulative Timesteps: 2,161,313,282

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63,475.22603
Policy Entropy: 2.72197
Value Function Loss: 0.01185

Mean KL Divergence: 0.00708
SB3 Clip Fraction: 0.06399
Policy Update Magnitude: 0.29520
Value Function Update Magnitude: 0.21648

Collected Steps per Second: 21,686.03550
Overall Steps per Second: 10,398.72594

Timestep Collection Time: 2.30637
Timestep Consumption Time: 2.50345
PPO Batch Consumption Time: 0.29038
Total Iteration Time: 4.80982

Cumulative Model Updates: 259,088
Cumulative Timesteps: 2,161,363,298

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2161363298...
Checkpoint 2161363298 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 99,230.89476
Policy Entropy: 2.71091
Value Function Loss: 0.01212

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.07226
Policy Update Magnitude: 0.30870
Value Function Update Magnitude: 0.26372

Collected Steps per Second: 21,641.03026
Overall Steps per Second: 10,564.81770

Timestep Collection Time: 2.31126
Timestep Consumption Time: 2.42314
PPO Batch Consumption Time: 0.27815
Total Iteration Time: 4.73439

Cumulative Model Updates: 259,094
Cumulative Timesteps: 2,161,413,316

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86,336.59975
Policy Entropy: 2.71371
Value Function Loss: 0.01208

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.07699
Policy Update Magnitude: 0.31035
Value Function Update Magnitude: 0.28575

Collected Steps per Second: 21,708.05017
Overall Steps per Second: 10,506.01441

Timestep Collection Time: 2.30329
Timestep Consumption Time: 2.45589
PPO Batch Consumption Time: 0.27958
Total Iteration Time: 4.75918

Cumulative Model Updates: 259,100
Cumulative Timesteps: 2,161,463,316

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2161463316...
Checkpoint 2161463316 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 65,759.44842
Policy Entropy: 2.70518
Value Function Loss: 0.01351

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.08115
Policy Update Magnitude: 0.31247
Value Function Update Magnitude: 0.29351

Collected Steps per Second: 22,181.32542
Overall Steps per Second: 10,623.51073

Timestep Collection Time: 2.25451
Timestep Consumption Time: 2.45279
PPO Batch Consumption Time: 0.27840
Total Iteration Time: 4.70730

Cumulative Model Updates: 259,106
Cumulative Timesteps: 2,161,513,324

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65,046.17504
Policy Entropy: 2.72217
Value Function Loss: 0.01499

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.07318
Policy Update Magnitude: 0.31465
Value Function Update Magnitude: 0.28991

Collected Steps per Second: 22,371.46771
Overall Steps per Second: 10,579.23120

Timestep Collection Time: 2.23597
Timestep Consumption Time: 2.49235
PPO Batch Consumption Time: 0.29219
Total Iteration Time: 4.72832

Cumulative Model Updates: 259,112
Cumulative Timesteps: 2,161,563,346

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2161563346...
Checkpoint 2161563346 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 54,807.11444
Policy Entropy: 2.72078
Value Function Loss: 0.01504

Mean KL Divergence: 0.01228
SB3 Clip Fraction: 0.10364
Policy Update Magnitude: 0.30610
Value Function Update Magnitude: 0.27779

Collected Steps per Second: 22,318.70182
Overall Steps per Second: 10,544.54377

Timestep Collection Time: 2.24135
Timestep Consumption Time: 2.50272
PPO Batch Consumption Time: 0.29383
Total Iteration Time: 4.74406

Cumulative Model Updates: 259,118
Cumulative Timesteps: 2,161,613,370

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,498.04171
Policy Entropy: 2.70047
Value Function Loss: 0.01417

Mean KL Divergence: 0.01053
SB3 Clip Fraction: 0.09419
Policy Update Magnitude: 0.30647
Value Function Update Magnitude: 0.25042

Collected Steps per Second: 21,911.93339
Overall Steps per Second: 10,413.17440

Timestep Collection Time: 2.28232
Timestep Consumption Time: 2.52025
PPO Batch Consumption Time: 0.29347
Total Iteration Time: 4.80257

Cumulative Model Updates: 259,124
Cumulative Timesteps: 2,161,663,380

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2161663380...
Checkpoint 2161663380 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,223.75261
Policy Entropy: 2.69566
Value Function Loss: 0.01358

Mean KL Divergence: 0.01112
SB3 Clip Fraction: 0.09274
Policy Update Magnitude: 0.32706
Value Function Update Magnitude: 0.27531

Collected Steps per Second: 21,734.02113
Overall Steps per Second: 10,560.66844

Timestep Collection Time: 2.30100
Timestep Consumption Time: 2.43449
PPO Batch Consumption Time: 0.27874
Total Iteration Time: 4.73550

Cumulative Model Updates: 259,130
Cumulative Timesteps: 2,161,713,390

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42,661.50040
Policy Entropy: 2.69352
Value Function Loss: 0.01290

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.08106
Policy Update Magnitude: 0.32171
Value Function Update Magnitude: 0.30794

Collected Steps per Second: 21,559.07690
Overall Steps per Second: 10,292.70264

Timestep Collection Time: 2.32144
Timestep Consumption Time: 2.54104
PPO Batch Consumption Time: 0.29070
Total Iteration Time: 4.86247

Cumulative Model Updates: 259,136
Cumulative Timesteps: 2,161,763,438

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 2161763438...
Checkpoint 2161763438 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 51,632.12431
Policy Entropy: 2.71246
Value Function Loss: 0.01409

Mean KL Divergence: 0.00714
SB3 Clip Fraction: 0.06696
Policy Update Magnitude: 0.32405
Value Function Update Magnitude: 0.32643

Collected Steps per Second: 21,822.05857
Overall Steps per Second: 10,443.40721

Timestep Collection Time: 2.29227
Timestep Consumption Time: 2.49755
PPO Batch Consumption Time: 0.28707
Total Iteration Time: 4.78982

Cumulative Model Updates: 259,142
Cumulative Timesteps: 2,161,813,460

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 64,307.71373
Policy Entropy: 2.69902
Value Function Loss: 0.01422

Mean KL Divergence: 0.00685
SB3 Clip Fraction: 0.06539
Policy Update Magnitude: 0.33522
Value Function Update Magnitude: 0.32329

Collected Steps per Second: 21,577.27006
Overall Steps per Second: 10,471.12440

Timestep Collection Time: 2.31809
Timestep Consumption Time: 2.45867
PPO Batch Consumption Time: 0.28397
Total Iteration Time: 4.77676

Cumulative Model Updates: 259,148
Cumulative Timesteps: 2,161,863,478

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2161863478...
Checkpoint 2161863478 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 99,274.45906
Policy Entropy: 2.68517
Value Function Loss: 0.01585

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.07437
Policy Update Magnitude: 0.34202
Value Function Update Magnitude: 0.31199

Collected Steps per Second: 21,432.25110
Overall Steps per Second: 10,351.70015

Timestep Collection Time: 2.33387
Timestep Consumption Time: 2.49819
PPO Batch Consumption Time: 0.29064
Total Iteration Time: 4.83206

Cumulative Model Updates: 259,154
Cumulative Timesteps: 2,161,913,498

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63,230.25519
Policy Entropy: 2.68245
Value Function Loss: 0.01536

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.07482
Policy Update Magnitude: 0.34623
Value Function Update Magnitude: 0.32876

Collected Steps per Second: 21,695.66340
Overall Steps per Second: 10,432.67157

Timestep Collection Time: 2.30535
Timestep Consumption Time: 2.48882
PPO Batch Consumption Time: 0.29122
Total Iteration Time: 4.79417

Cumulative Model Updates: 259,160
Cumulative Timesteps: 2,161,963,514

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2161963514...
Checkpoint 2161963514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 88,353.80091
Policy Entropy: 2.68626
Value Function Loss: 0.01465

Mean KL Divergence: 0.00763
SB3 Clip Fraction: 0.06977
Policy Update Magnitude: 0.34109
Value Function Update Magnitude: 0.34200

Collected Steps per Second: 21,623.01165
Overall Steps per Second: 10,580.34887

Timestep Collection Time: 2.31300
Timestep Consumption Time: 2.41407
PPO Batch Consumption Time: 0.27630
Total Iteration Time: 4.72707

Cumulative Model Updates: 259,166
Cumulative Timesteps: 2,162,013,528

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54,659.01425
Policy Entropy: 2.68025
Value Function Loss: 0.01433

Mean KL Divergence: 0.00751
SB3 Clip Fraction: 0.07131
Policy Update Magnitude: 0.35257
Value Function Update Magnitude: 0.34492

Collected Steps per Second: 21,555.94216
Overall Steps per Second: 10,356.09100

Timestep Collection Time: 2.32020
Timestep Consumption Time: 2.50923
PPO Batch Consumption Time: 0.28839
Total Iteration Time: 4.82943

Cumulative Model Updates: 259,172
Cumulative Timesteps: 2,162,063,542

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2162063542...
Checkpoint 2162063542 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,250.21536
Policy Entropy: 2.70744
Value Function Loss: 0.01327

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.07911
Policy Update Magnitude: 0.33598
Value Function Update Magnitude: 0.35627

Collected Steps per Second: 21,309.73835
Overall Steps per Second: 10,579.93145

Timestep Collection Time: 2.34775
Timestep Consumption Time: 2.38101
PPO Batch Consumption Time: 0.27789
Total Iteration Time: 4.72876

Cumulative Model Updates: 259,178
Cumulative Timesteps: 2,162,113,572

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,250.21536
Policy Entropy: 2.71827
Value Function Loss: 0.01177

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.06983
Policy Update Magnitude: 0.31327
Value Function Update Magnitude: 0.33164

Collected Steps per Second: 21,384.34262
Overall Steps per Second: 10,487.48994

Timestep Collection Time: 2.34022
Timestep Consumption Time: 2.43156
PPO Batch Consumption Time: 0.28913
Total Iteration Time: 4.77178

Cumulative Model Updates: 259,184
Cumulative Timesteps: 2,162,163,616

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 2162163616...
Checkpoint 2162163616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46,656.84655
Policy Entropy: 2.72473
Value Function Loss: 0.01130

Mean KL Divergence: 0.00735
SB3 Clip Fraction: 0.06974
Policy Update Magnitude: 0.30726
Value Function Update Magnitude: 0.29612

Collected Steps per Second: 21,330.80150
Overall Steps per Second: 10,391.12899

Timestep Collection Time: 2.34497
Timestep Consumption Time: 2.46876
PPO Batch Consumption Time: 0.29146
Total Iteration Time: 4.81372

Cumulative Model Updates: 259,190
Cumulative Timesteps: 2,162,213,636

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45,747.08421
Policy Entropy: 2.71570
Value Function Loss: 0.01085

Mean KL Divergence: 0.00710
SB3 Clip Fraction: 0.06422
Policy Update Magnitude: 0.30488
Value Function Update Magnitude: 0.27405

Collected Steps per Second: 21,796.76972
Overall Steps per Second: 10,640.71358

Timestep Collection Time: 2.29474
Timestep Consumption Time: 2.40588
PPO Batch Consumption Time: 0.27926
Total Iteration Time: 4.70062

Cumulative Model Updates: 259,196
Cumulative Timesteps: 2,162,263,654

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2162263654...
Checkpoint 2162263654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 77,186.12142
Policy Entropy: 2.70754
Value Function Loss: 0.01236

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.07436
Policy Update Magnitude: 0.30390
Value Function Update Magnitude: 0.29221

Collected Steps per Second: 21,719.72538
Overall Steps per Second: 10,635.79330

Timestep Collection Time: 2.30252
Timestep Consumption Time: 2.39953
PPO Batch Consumption Time: 0.27890
Total Iteration Time: 4.70205

Cumulative Model Updates: 259,202
Cumulative Timesteps: 2,162,313,664

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85,576.37752
Policy Entropy: 2.70775
Value Function Loss: 0.01289

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.08303
Policy Update Magnitude: 0.31066
Value Function Update Magnitude: 0.33995

Collected Steps per Second: 22,010.81014
Overall Steps per Second: 10,635.06439

Timestep Collection Time: 2.27179
Timestep Consumption Time: 2.43001
PPO Batch Consumption Time: 0.27719
Total Iteration Time: 4.70181

Cumulative Model Updates: 259,208
Cumulative Timesteps: 2,162,363,668

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2162363668...
Checkpoint 2162363668 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 83,572.45551
Policy Entropy: 2.69785
Value Function Loss: 0.01172

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.08272
Policy Update Magnitude: 0.30478
Value Function Update Magnitude: 0.31818

Collected Steps per Second: 21,799.22487
Overall Steps per Second: 10,590.46769

Timestep Collection Time: 2.29458
Timestep Consumption Time: 2.42854
PPO Batch Consumption Time: 0.27763
Total Iteration Time: 4.72312

Cumulative Model Updates: 259,214
Cumulative Timesteps: 2,162,413,688

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83,572.45551
Policy Entropy: 2.68779
Value Function Loss: 0.00979

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.08099
Policy Update Magnitude: 0.29244
Value Function Update Magnitude: 0.28646

Collected Steps per Second: 21,687.60819
Overall Steps per Second: 10,421.12840

Timestep Collection Time: 2.30694
Timestep Consumption Time: 2.49408
PPO Batch Consumption Time: 0.28625
Total Iteration Time: 4.80102

Cumulative Model Updates: 259,220
Cumulative Timesteps: 2,162,463,720

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2162463720...
Checkpoint 2162463720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 75,657.27040
Policy Entropy: 2.67333
Value Function Loss: 0.01053

Mean KL Divergence: 0.00627
SB3 Clip Fraction: 0.06251
Policy Update Magnitude: 0.29426
Value Function Update Magnitude: 0.25795

Collected Steps per Second: 21,455.07633
Overall Steps per Second: 10,390.29402

Timestep Collection Time: 2.33092
Timestep Consumption Time: 2.48223
PPO Batch Consumption Time: 0.28978
Total Iteration Time: 4.81315

Cumulative Model Updates: 259,226
Cumulative Timesteps: 2,162,513,730

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 111,224.12837
Policy Entropy: 2.67952
Value Function Loss: 0.01323

Mean KL Divergence: 0.00590
SB3 Clip Fraction: 0.05853
Policy Update Magnitude: 0.31121
Value Function Update Magnitude: 0.25581

Collected Steps per Second: 21,949.74787
Overall Steps per Second: 10,656.19123

Timestep Collection Time: 2.27902
Timestep Consumption Time: 2.41534
PPO Batch Consumption Time: 0.27811
Total Iteration Time: 4.69436

Cumulative Model Updates: 259,232
Cumulative Timesteps: 2,162,563,754

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2162563754...
Checkpoint 2162563754 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86,149.88545
Policy Entropy: 2.67771
Value Function Loss: 0.01311

Mean KL Divergence: 0.00669
SB3 Clip Fraction: 0.06187
Policy Update Magnitude: 0.31759
Value Function Update Magnitude: 0.27719

Collected Steps per Second: 21,589.60062
Overall Steps per Second: 10,363.42881

Timestep Collection Time: 2.31612
Timestep Consumption Time: 2.50893
PPO Batch Consumption Time: 0.29191
Total Iteration Time: 4.82504

Cumulative Model Updates: 259,238
Cumulative Timesteps: 2,162,613,758

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 72,977.29443
Policy Entropy: 2.69603
Value Function Loss: 0.01169

Mean KL Divergence: 0.00703
SB3 Clip Fraction: 0.06432
Policy Update Magnitude: 0.30676
Value Function Update Magnitude: 0.27071

Collected Steps per Second: 22,350.87167
Overall Steps per Second: 10,555.82937

Timestep Collection Time: 2.23714
Timestep Consumption Time: 2.49977
PPO Batch Consumption Time: 0.28744
Total Iteration Time: 4.73691

Cumulative Model Updates: 259,244
Cumulative Timesteps: 2,162,663,760

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2162663760...
Checkpoint 2162663760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87,912.80303
Policy Entropy: 2.69888
Value Function Loss: 0.01297

Mean KL Divergence: 0.00661
SB3 Clip Fraction: 0.05981
Policy Update Magnitude: 0.31962
Value Function Update Magnitude: 0.23833

Collected Steps per Second: 21,366.80791
Overall Steps per Second: 10,441.58023

Timestep Collection Time: 2.34204
Timestep Consumption Time: 2.45053
PPO Batch Consumption Time: 0.29321
Total Iteration Time: 4.79257

Cumulative Model Updates: 259,250
Cumulative Timesteps: 2,162,713,802

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83,274.24525
Policy Entropy: 2.71287
Value Function Loss: 0.01311

Mean KL Divergence: 0.00653
SB3 Clip Fraction: 0.05864
Policy Update Magnitude: 0.32435
Value Function Update Magnitude: 0.25811

Collected Steps per Second: 21,664.36680
Overall Steps per Second: 10,615.59884

Timestep Collection Time: 2.30905
Timestep Consumption Time: 2.40327
PPO Batch Consumption Time: 0.28954
Total Iteration Time: 4.71231

Cumulative Model Updates: 259,256
Cumulative Timesteps: 2,162,763,826

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2162763826...
Checkpoint 2162763826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 53,256.37018
Policy Entropy: 2.70294
Value Function Loss: 0.01391

Mean KL Divergence: 0.00747
SB3 Clip Fraction: 0.06475
Policy Update Magnitude: 0.32342
Value Function Update Magnitude: 0.27489

Collected Steps per Second: 21,488.71748
Overall Steps per Second: 10,541.44271

Timestep Collection Time: 2.32690
Timestep Consumption Time: 2.41648
PPO Batch Consumption Time: 0.29321
Total Iteration Time: 4.74337

Cumulative Model Updates: 259,262
Cumulative Timesteps: 2,162,813,828

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,632.67120
Policy Entropy: 2.71306
Value Function Loss: 0.01491

Mean KL Divergence: 0.00746
SB3 Clip Fraction: 0.06724
Policy Update Magnitude: 0.32688
Value Function Update Magnitude: 0.28309

Collected Steps per Second: 21,644.71157
Overall Steps per Second: 10,457.32895

Timestep Collection Time: 2.31059
Timestep Consumption Time: 2.47190
PPO Batch Consumption Time: 0.29229
Total Iteration Time: 4.78248

Cumulative Model Updates: 259,268
Cumulative Timesteps: 2,162,863,840

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2162863840...
Checkpoint 2162863840 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,063.27142
Policy Entropy: 2.70504
Value Function Loss: 0.01387

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.07762
Policy Update Magnitude: 0.32105
Value Function Update Magnitude: 0.34715

Collected Steps per Second: 21,597.66994
Overall Steps per Second: 10,600.76959

Timestep Collection Time: 2.31692
Timestep Consumption Time: 2.40350
PPO Batch Consumption Time: 0.27683
Total Iteration Time: 4.72041

Cumulative Model Updates: 259,274
Cumulative Timesteps: 2,162,913,880

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50,511.45894
Policy Entropy: 2.68630
Value Function Loss: 0.01333

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.07612
Policy Update Magnitude: 0.31301
Value Function Update Magnitude: 0.32519

Collected Steps per Second: 21,961.82087
Overall Steps per Second: 10,565.43238

Timestep Collection Time: 2.27905
Timestep Consumption Time: 2.45829
PPO Batch Consumption Time: 0.29090
Total Iteration Time: 4.73734

Cumulative Model Updates: 259,280
Cumulative Timesteps: 2,162,963,932

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


Saving checkpoint 2162963932...
Checkpoint 2162963932 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84,114.45896
Policy Entropy: 2.67374
Value Function Loss: 0.01388

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.08159
Policy Update Magnitude: 0.32284
Value Function Update Magnitude: 0.30909

Collected Steps per Second: 21,462.01734
Overall Steps per Second: 10,481.48225

Timestep Collection Time: 2.33063
Timestep Consumption Time: 2.44160
PPO Batch Consumption Time: 0.28528
Total Iteration Time: 4.77223

Cumulative Model Updates: 259,286
Cumulative Timesteps: 2,163,013,952

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 94,593.98662
Policy Entropy: 2.67171
Value Function Loss: 0.01370

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.08341
Policy Update Magnitude: 0.32525
Value Function Update Magnitude: 0.31049

Collected Steps per Second: 21,810.86603
Overall Steps per Second: 10,438.18468

Timestep Collection Time: 2.29372
Timestep Consumption Time: 2.49907
PPO Batch Consumption Time: 0.28932
Total Iteration Time: 4.79279

Cumulative Model Updates: 259,292
Cumulative Timesteps: 2,163,063,980

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2163063980...
Checkpoint 2163063980 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 69,184.75205
Policy Entropy: 2.65115
Value Function Loss: 0.01439

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.07574
Policy Update Magnitude: 0.32839
Value Function Update Magnitude: 0.28802

Collected Steps per Second: 21,397.65964
Overall Steps per Second: 10,342.90360

Timestep Collection Time: 2.33801
Timestep Consumption Time: 2.49893
PPO Batch Consumption Time: 0.29125
Total Iteration Time: 4.83694

Cumulative Model Updates: 259,298
Cumulative Timesteps: 2,163,114,008

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99,510.16791
Policy Entropy: 2.67356
Value Function Loss: 0.01208

Mean KL Divergence: 0.00757
SB3 Clip Fraction: 0.07141
Policy Update Magnitude: 0.31955
Value Function Update Magnitude: 0.30479

Collected Steps per Second: 21,679.41947
Overall Steps per Second: 10,371.29497

Timestep Collection Time: 2.30717
Timestep Consumption Time: 2.51557
PPO Batch Consumption Time: 0.29310
Total Iteration Time: 4.82273

Cumulative Model Updates: 259,304
Cumulative Timesteps: 2,163,164,026

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2163164026...
Checkpoint 2163164026 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 78,609.21844
Policy Entropy: 2.67132
Value Function Loss: 0.01299

Mean KL Divergence: 0.00664
SB3 Clip Fraction: 0.06320
Policy Update Magnitude: 0.31206
Value Function Update Magnitude: 0.31168

Collected Steps per Second: 21,628.63052
Overall Steps per Second: 10,510.15403

Timestep Collection Time: 2.31305
Timestep Consumption Time: 2.44692
PPO Batch Consumption Time: 0.27832
Total Iteration Time: 4.75997

Cumulative Model Updates: 259,310
Cumulative Timesteps: 2,163,214,054

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60,722.42784
Policy Entropy: 2.69177
Value Function Loss: 0.01478

Mean KL Divergence: 0.00639
SB3 Clip Fraction: 0.06084
Policy Update Magnitude: 0.33340
Value Function Update Magnitude: 0.29547

Collected Steps per Second: 22,348.25700
Overall Steps per Second: 10,466.02108

Timestep Collection Time: 2.23785
Timestep Consumption Time: 2.54066
PPO Batch Consumption Time: 0.29216
Total Iteration Time: 4.77851

Cumulative Model Updates: 259,316
Cumulative Timesteps: 2,163,264,066

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2163264066...
Checkpoint 2163264066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 120,868.84614
Policy Entropy: 2.68231
Value Function Loss: 0.01509

Mean KL Divergence: 0.00763
SB3 Clip Fraction: 0.06865
Policy Update Magnitude: 0.33328
Value Function Update Magnitude: 0.31132

Collected Steps per Second: 22,032.31259
Overall Steps per Second: 10,644.46259

Timestep Collection Time: 2.27048
Timestep Consumption Time: 2.42905
PPO Batch Consumption Time: 0.27892
Total Iteration Time: 4.69953

Cumulative Model Updates: 259,322
Cumulative Timesteps: 2,163,314,090

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83,504.80582
Policy Entropy: 2.69755
Value Function Loss: 0.01438

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.07875
Policy Update Magnitude: 0.32155
Value Function Update Magnitude: 0.33176

Collected Steps per Second: 22,148.65127
Overall Steps per Second: 10,532.73426

Timestep Collection Time: 2.25765
Timestep Consumption Time: 2.48983
PPO Batch Consumption Time: 0.28738
Total Iteration Time: 4.74749

Cumulative Model Updates: 259,328
Cumulative Timesteps: 2,163,364,094

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2163364094...
Checkpoint 2163364094 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 95,605.19128
Policy Entropy: 2.67508
Value Function Loss: 0.01264

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.08636
Policy Update Magnitude: 0.32929
Value Function Update Magnitude: 0.33867

Collected Steps per Second: 21,948.10010
Overall Steps per Second: 10,646.14303

Timestep Collection Time: 2.27919
Timestep Consumption Time: 2.41960
PPO Batch Consumption Time: 0.27782
Total Iteration Time: 4.69879

Cumulative Model Updates: 259,334
Cumulative Timesteps: 2,163,414,118

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81,268.67125
Policy Entropy: 2.68268
Value Function Loss: 0.01204

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.08067
Policy Update Magnitude: 0.33052
Value Function Update Magnitude: 0.34677

Collected Steps per Second: 22,461.17299
Overall Steps per Second: 10,578.73023

Timestep Collection Time: 2.22687
Timestep Consumption Time: 2.50130
PPO Batch Consumption Time: 0.29168
Total Iteration Time: 4.72817

Cumulative Model Updates: 259,340
Cumulative Timesteps: 2,163,464,136

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2163464136...
Checkpoint 2163464136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87,196.03121
Policy Entropy: 2.68990
Value Function Loss: 0.01105

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.08195
Policy Update Magnitude: 0.31471
Value Function Update Magnitude: 0.33969

Collected Steps per Second: 21,763.91196
Overall Steps per Second: 10,476.66039

Timestep Collection Time: 2.29738
Timestep Consumption Time: 2.47513
PPO Batch Consumption Time: 0.28584
Total Iteration Time: 4.77251

Cumulative Model Updates: 259,346
Cumulative Timesteps: 2,163,514,136

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67,143.04281
Policy Entropy: 2.71558
Value Function Loss: 0.01092

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.07930
Policy Update Magnitude: 0.31163
Value Function Update Magnitude: 0.32900

Collected Steps per Second: 20,951.34190
Overall Steps per Second: 10,481.20803

Timestep Collection Time: 2.38715
Timestep Consumption Time: 2.38463
PPO Batch Consumption Time: 0.28392
Total Iteration Time: 4.77178

Cumulative Model Updates: 259,352
Cumulative Timesteps: 2,163,564,150

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2163564150...
Checkpoint 2163564150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 68,267.23953
Policy Entropy: 2.70957
Value Function Loss: 0.01095

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.07646
Policy Update Magnitude: 0.30219
Value Function Update Magnitude: 0.32573

Collected Steps per Second: 20,847.28892
Overall Steps per Second: 10,555.15145

Timestep Collection Time: 2.39868
Timestep Consumption Time: 2.33891
PPO Batch Consumption Time: 0.27845
Total Iteration Time: 4.73759

Cumulative Model Updates: 259,358
Cumulative Timesteps: 2,163,614,156

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82,752.79888
Policy Entropy: 2.71370
Value Function Loss: 0.01063

Mean KL Divergence: 0.00728
SB3 Clip Fraction: 0.06397
Policy Update Magnitude: 0.29210
Value Function Update Magnitude: 0.30987

Collected Steps per Second: 19,869.96344
Overall Steps per Second: 10,085.39324

Timestep Collection Time: 2.51646
Timestep Consumption Time: 2.44140
PPO Batch Consumption Time: 0.29305
Total Iteration Time: 4.95786

Cumulative Model Updates: 259,364
Cumulative Timesteps: 2,163,664,158

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2163664158...
Checkpoint 2163664158 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 99,671.30222
Policy Entropy: 2.72148
Value Function Loss: 0.00924

Mean KL Divergence: 0.00648
SB3 Clip Fraction: 0.06295
Policy Update Magnitude: 0.28169
Value Function Update Magnitude: 0.28442

Collected Steps per Second: 20,845.98867
Overall Steps per Second: 10,214.13864

Timestep Collection Time: 2.40017
Timestep Consumption Time: 2.49833
PPO Batch Consumption Time: 0.29193
Total Iteration Time: 4.89850

Cumulative Model Updates: 259,370
Cumulative Timesteps: 2,163,714,192

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 98,520.22946
Policy Entropy: 2.72978
Value Function Loss: 0.00863

Mean KL Divergence: 0.00624
SB3 Clip Fraction: 0.05888
Policy Update Magnitude: 0.27333
Value Function Update Magnitude: 0.26684

Collected Steps per Second: 21,758.21403
Overall Steps per Second: 10,472.56787

Timestep Collection Time: 2.29881
Timestep Consumption Time: 2.47729
PPO Batch Consumption Time: 0.28915
Total Iteration Time: 4.77610

Cumulative Model Updates: 259,376
Cumulative Timesteps: 2,163,764,210

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2163764210...
Checkpoint 2163764210 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 75,502.91157
Policy Entropy: 2.73058
Value Function Loss: 0.01037

Mean KL Divergence: 0.00598
SB3 Clip Fraction: 0.05804
Policy Update Magnitude: 0.28548
Value Function Update Magnitude: 0.26718

Collected Steps per Second: 21,924.09934
Overall Steps per Second: 10,605.40535

Timestep Collection Time: 2.28215
Timestep Consumption Time: 2.43564
PPO Batch Consumption Time: 0.27777
Total Iteration Time: 4.71778

Cumulative Model Updates: 259,382
Cumulative Timesteps: 2,163,814,244

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78,311.99398
Policy Entropy: 2.71280
Value Function Loss: 0.01128

Mean KL Divergence: 0.00616
SB3 Clip Fraction: 0.05929
Policy Update Magnitude: 0.30014
Value Function Update Magnitude: 0.29963

Collected Steps per Second: 22,324.67202
Overall Steps per Second: 10,536.38518

Timestep Collection Time: 2.24147
Timestep Consumption Time: 2.50779
PPO Batch Consumption Time: 0.29209
Total Iteration Time: 4.74926

Cumulative Model Updates: 259,388
Cumulative Timesteps: 2,163,864,284

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 2163864284...
Checkpoint 2163864284 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84,544.67278
Policy Entropy: 2.69871
Value Function Loss: 0.01164

Mean KL Divergence: 0.00692
SB3 Clip Fraction: 0.06290
Policy Update Magnitude: 0.30436
Value Function Update Magnitude: 0.32182

Collected Steps per Second: 22,167.66816
Overall Steps per Second: 10,561.39640

Timestep Collection Time: 2.25599
Timestep Consumption Time: 2.47918
PPO Batch Consumption Time: 0.28598
Total Iteration Time: 4.73517

Cumulative Model Updates: 259,394
Cumulative Timesteps: 2,163,914,294

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84,544.67278
Policy Entropy: 2.67455
Value Function Loss: 0.01030

Mean KL Divergence: 0.00687
SB3 Clip Fraction: 0.06168
Policy Update Magnitude: 0.29814
Value Function Update Magnitude: 0.32123

Collected Steps per Second: 22,093.94544
Overall Steps per Second: 10,481.15559

Timestep Collection Time: 2.26333
Timestep Consumption Time: 2.50770
PPO Batch Consumption Time: 0.29307
Total Iteration Time: 4.77104

Cumulative Model Updates: 259,400
Cumulative Timesteps: 2,163,964,300

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2163964300...
Checkpoint 2163964300 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 79,246.84537
Policy Entropy: 2.66655
Value Function Loss: 0.01110

Mean KL Divergence: 0.00661
SB3 Clip Fraction: 0.06090
Policy Update Magnitude: 0.30367
Value Function Update Magnitude: 0.31317

Collected Steps per Second: 21,560.95186
Overall Steps per Second: 10,540.47840

Timestep Collection Time: 2.31919
Timestep Consumption Time: 2.42480
PPO Batch Consumption Time: 0.27865
Total Iteration Time: 4.74400

Cumulative Model Updates: 259,406
Cumulative Timesteps: 2,164,014,304

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65,378.84029
Policy Entropy: 2.67149
Value Function Loss: 0.01116

Mean KL Divergence: 0.00692
SB3 Clip Fraction: 0.06469
Policy Update Magnitude: 0.30806
Value Function Update Magnitude: 0.32009

Collected Steps per Second: 22,350.43095
Overall Steps per Second: 10,546.72661

Timestep Collection Time: 2.23781
Timestep Consumption Time: 2.50452
PPO Batch Consumption Time: 0.29283
Total Iteration Time: 4.74232

Cumulative Model Updates: 259,412
Cumulative Timesteps: 2,164,064,320

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2164064320...
Checkpoint 2164064320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 144,238.11394
Policy Entropy: 2.67690
Value Function Loss: 0.01192

Mean KL Divergence: 0.00655
SB3 Clip Fraction: 0.06181
Policy Update Magnitude: 0.31733
Value Function Update Magnitude: 0.32057

Collected Steps per Second: 22,101.73437
Overall Steps per Second: 10,684.97804

Timestep Collection Time: 2.26227
Timestep Consumption Time: 2.41720
PPO Batch Consumption Time: 0.27655
Total Iteration Time: 4.67947

Cumulative Model Updates: 259,418
Cumulative Timesteps: 2,164,114,320

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 132,636.73068
Policy Entropy: 2.71120
Value Function Loss: 0.01223

Mean KL Divergence: 0.00702
SB3 Clip Fraction: 0.06733
Policy Update Magnitude: 0.31404
Value Function Update Magnitude: 0.31275

Collected Steps per Second: 21,821.22634
Overall Steps per Second: 10,430.21824

Timestep Collection Time: 2.29181
Timestep Consumption Time: 2.50292
PPO Batch Consumption Time: 0.29247
Total Iteration Time: 4.79472

Cumulative Model Updates: 259,424
Cumulative Timesteps: 2,164,164,330

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2164164330...
Checkpoint 2164164330 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 109,098.92685
Policy Entropy: 2.70646
Value Function Loss: 0.01176

Mean KL Divergence: 0.00675
SB3 Clip Fraction: 0.06114
Policy Update Magnitude: 0.30691
Value Function Update Magnitude: 0.30618

Collected Steps per Second: 21,641.41885
Overall Steps per Second: 10,555.07145

Timestep Collection Time: 2.31122
Timestep Consumption Time: 2.42755
PPO Batch Consumption Time: 0.27787
Total Iteration Time: 4.73876

Cumulative Model Updates: 259,430
Cumulative Timesteps: 2,164,214,348

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82,046.47351
Policy Entropy: 2.69638
Value Function Loss: 0.01299

Mean KL Divergence: 0.00722
SB3 Clip Fraction: 0.07015
Policy Update Magnitude: 0.30772
Value Function Update Magnitude: 0.29629

Collected Steps per Second: 21,594.79659
Overall Steps per Second: 10,557.47042

Timestep Collection Time: 2.31547
Timestep Consumption Time: 2.42071
PPO Batch Consumption Time: 0.27688
Total Iteration Time: 4.73617

Cumulative Model Updates: 259,436
Cumulative Timesteps: 2,164,264,350

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2164264350...
Checkpoint 2164264350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 124,939.38652
Policy Entropy: 2.67982
Value Function Loss: 0.01344

Mean KL Divergence: 0.00735
SB3 Clip Fraction: 0.07100
Policy Update Magnitude: 0.31306
Value Function Update Magnitude: 0.31247

Collected Steps per Second: 20,954.08984
Overall Steps per Second: 10,533.38521

Timestep Collection Time: 2.38674
Timestep Consumption Time: 2.36121
PPO Batch Consumption Time: 0.27840
Total Iteration Time: 4.74795

Cumulative Model Updates: 259,442
Cumulative Timesteps: 2,164,314,362

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 106,573.14849
Policy Entropy: 2.67806
Value Function Loss: 0.01241

Mean KL Divergence: 0.00756
SB3 Clip Fraction: 0.06904
Policy Update Magnitude: 0.31001
Value Function Update Magnitude: 0.32251

Collected Steps per Second: 21,353.84067
Overall Steps per Second: 10,522.22018

Timestep Collection Time: 2.34281
Timestep Consumption Time: 2.41170
PPO Batch Consumption Time: 0.28441
Total Iteration Time: 4.75451

Cumulative Model Updates: 259,448
Cumulative Timesteps: 2,164,364,390

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2164364390...
Checkpoint 2164364390 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 94,785.15595
Policy Entropy: 2.68371
Value Function Loss: 0.01116

Mean KL Divergence: 0.00772
SB3 Clip Fraction: 0.07030
Policy Update Magnitude: 0.30467
Value Function Update Magnitude: 0.30285

Collected Steps per Second: 21,553.10908
Overall Steps per Second: 10,372.92004

Timestep Collection Time: 2.32022
Timestep Consumption Time: 2.50079
PPO Batch Consumption Time: 0.28839
Total Iteration Time: 4.82101

Cumulative Model Updates: 259,454
Cumulative Timesteps: 2,164,414,398

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 94,785.15595
Policy Entropy: 2.67785
Value Function Loss: 0.00935

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.08348
Policy Update Magnitude: 0.30357
Value Function Update Magnitude: 0.30250

Collected Steps per Second: 22,129.59098
Overall Steps per Second: 10,703.85254

Timestep Collection Time: 2.26086
Timestep Consumption Time: 2.41334
PPO Batch Consumption Time: 0.27962
Total Iteration Time: 4.67420

Cumulative Model Updates: 259,460
Cumulative Timesteps: 2,164,464,430

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2164464430...
Checkpoint 2164464430 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 94,210.33424
Policy Entropy: 2.68121
Value Function Loss: 0.01076

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.07761
Policy Update Magnitude: 0.30637
Value Function Update Magnitude: 0.30583

Collected Steps per Second: 21,989.73906
Overall Steps per Second: 10,706.20984

Timestep Collection Time: 2.27488
Timestep Consumption Time: 2.39755
PPO Batch Consumption Time: 0.27721
Total Iteration Time: 4.67243

Cumulative Model Updates: 259,466
Cumulative Timesteps: 2,164,514,454

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85,058.43544
Policy Entropy: 2.69747
Value Function Loss: 0.01133

Mean KL Divergence: 0.00729
SB3 Clip Fraction: 0.06727
Policy Update Magnitude: 0.30668
Value Function Update Magnitude: 0.29838

Collected Steps per Second: 22,017.63479
Overall Steps per Second: 10,460.33481

Timestep Collection Time: 2.27227
Timestep Consumption Time: 2.51056
PPO Batch Consumption Time: 0.29269
Total Iteration Time: 4.78283

Cumulative Model Updates: 259,472
Cumulative Timesteps: 2,164,564,484

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2164564484...
Checkpoint 2164564484 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 98,501.30624
Policy Entropy: 2.66804
Value Function Loss: 0.01261

Mean KL Divergence: 0.00674
SB3 Clip Fraction: 0.06021
Policy Update Magnitude: 0.31484
Value Function Update Magnitude: 0.33912

Collected Steps per Second: 21,791.70673
Overall Steps per Second: 10,555.84975

Timestep Collection Time: 2.29675
Timestep Consumption Time: 2.44470
PPO Batch Consumption Time: 0.27861
Total Iteration Time: 4.74145

Cumulative Model Updates: 259,478
Cumulative Timesteps: 2,164,614,534

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70,386.24128
Policy Entropy: 2.66658
Value Function Loss: 0.01214

Mean KL Divergence: 0.00592
SB3 Clip Fraction: 0.05370
Policy Update Magnitude: 0.32668
Value Function Update Magnitude: 0.33928

Collected Steps per Second: 22,114.52351
Overall Steps per Second: 10,466.32261

Timestep Collection Time: 2.26096
Timestep Consumption Time: 2.51627
PPO Batch Consumption Time: 0.29210
Total Iteration Time: 4.77723

Cumulative Model Updates: 259,484
Cumulative Timesteps: 2,164,664,534

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2164664534...
Checkpoint 2164664534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 92,402.13150
Policy Entropy: 2.65957
Value Function Loss: 0.01159

Mean KL Divergence: 0.00692
SB3 Clip Fraction: 0.06224
Policy Update Magnitude: 0.32637
Value Function Update Magnitude: 0.30831

Collected Steps per Second: 21,712.18696
Overall Steps per Second: 10,553.47028

Timestep Collection Time: 2.30313
Timestep Consumption Time: 2.43522
PPO Batch Consumption Time: 0.27840
Total Iteration Time: 4.73835

Cumulative Model Updates: 259,490
Cumulative Timesteps: 2,164,714,540

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92,469.08028
Policy Entropy: 2.70894
Value Function Loss: 0.01198

Mean KL Divergence: 0.00714
SB3 Clip Fraction: 0.06208
Policy Update Magnitude: 0.32427
Value Function Update Magnitude: 0.32895

Collected Steps per Second: 21,801.96057
Overall Steps per Second: 10,535.34165

Timestep Collection Time: 2.29567
Timestep Consumption Time: 2.45501
PPO Batch Consumption Time: 0.27872
Total Iteration Time: 4.75068

Cumulative Model Updates: 259,496
Cumulative Timesteps: 2,164,764,590

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 2164764590...
Checkpoint 2164764590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 83,873.58748
Policy Entropy: 2.70826
Value Function Loss: 0.01265

Mean KL Divergence: 0.00739
SB3 Clip Fraction: 0.06384
Policy Update Magnitude: 0.32755
Value Function Update Magnitude: 0.33553

Collected Steps per Second: 21,708.45516
Overall Steps per Second: 10,542.90346

Timestep Collection Time: 2.30408
Timestep Consumption Time: 2.44015
PPO Batch Consumption Time: 0.27860
Total Iteration Time: 4.74423

Cumulative Model Updates: 259,502
Cumulative Timesteps: 2,164,814,608

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90,895.17226
Policy Entropy: 2.69805
Value Function Loss: 0.01299

Mean KL Divergence: 0.00702
SB3 Clip Fraction: 0.06086
Policy Update Magnitude: 0.32191
Value Function Update Magnitude: 0.32065

Collected Steps per Second: 21,571.80362
Overall Steps per Second: 10,494.98639

Timestep Collection Time: 2.31923
Timestep Consumption Time: 2.44781
PPO Batch Consumption Time: 0.27767
Total Iteration Time: 4.76704

Cumulative Model Updates: 259,508
Cumulative Timesteps: 2,164,864,638

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2164864638...
Checkpoint 2164864638 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 116,725.44386
Policy Entropy: 2.68437
Value Function Loss: 0.01298

Mean KL Divergence: 0.00638
SB3 Clip Fraction: 0.05940
Policy Update Magnitude: 0.32416
Value Function Update Magnitude: 0.30732

Collected Steps per Second: 21,652.06250
Overall Steps per Second: 10,324.11191

Timestep Collection Time: 2.30934
Timestep Consumption Time: 2.53388
PPO Batch Consumption Time: 0.29344
Total Iteration Time: 4.84323

Cumulative Model Updates: 259,514
Cumulative Timesteps: 2,164,914,640

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79,491.56965
Policy Entropy: 2.68712
Value Function Loss: 0.01223

Mean KL Divergence: 0.00667
SB3 Clip Fraction: 0.06279
Policy Update Magnitude: 0.31708
Value Function Update Magnitude: 0.27338

Collected Steps per Second: 21,947.68848
Overall Steps per Second: 10,392.99655

Timestep Collection Time: 2.27978
Timestep Consumption Time: 2.53461
PPO Batch Consumption Time: 0.29303
Total Iteration Time: 4.81440

Cumulative Model Updates: 259,520
Cumulative Timesteps: 2,164,964,676

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 2164964676...
Checkpoint 2164964676 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 88,162.76497
Policy Entropy: 2.70216
Value Function Loss: 0.01233

Mean KL Divergence: 0.00715
SB3 Clip Fraction: 0.06442
Policy Update Magnitude: 0.31666
Value Function Update Magnitude: 0.25941

Collected Steps per Second: 22,161.61735
Overall Steps per Second: 10,668.88547

Timestep Collection Time: 2.25787
Timestep Consumption Time: 2.43222
PPO Batch Consumption Time: 0.27776
Total Iteration Time: 4.69009

Cumulative Model Updates: 259,526
Cumulative Timesteps: 2,165,014,714

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90,544.75040
Policy Entropy: 2.70112
Value Function Loss: 0.01112

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.07944
Policy Update Magnitude: 0.31150
Value Function Update Magnitude: 0.25609

Collected Steps per Second: 21,985.05482
Overall Steps per Second: 10,464.76970

Timestep Collection Time: 2.27473
Timestep Consumption Time: 2.50416
PPO Batch Consumption Time: 0.29297
Total Iteration Time: 4.77889

Cumulative Model Updates: 259,532
Cumulative Timesteps: 2,165,064,724

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2165064724...
Checkpoint 2165064724 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 124,047.46901
Policy Entropy: 2.66695
Value Function Loss: 0.01247

Mean KL Divergence: 0.00733
SB3 Clip Fraction: 0.06728
Policy Update Magnitude: 0.31386
Value Function Update Magnitude: 0.23423

Collected Steps per Second: 22,088.09089
Overall Steps per Second: 10,566.64204

Timestep Collection Time: 2.26412
Timestep Consumption Time: 2.46870
PPO Batch Consumption Time: 0.28589
Total Iteration Time: 4.73282

Cumulative Model Updates: 259,538
Cumulative Timesteps: 2,165,114,734

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 124,047.46901
Policy Entropy: 2.66912
Value Function Loss: 0.01093

Mean KL Divergence: 0.00732
SB3 Clip Fraction: 0.06997
Policy Update Magnitude: 0.31403
Value Function Update Magnitude: 0.20351

Collected Steps per Second: 22,084.05722
Overall Steps per Second: 10,506.61435

Timestep Collection Time: 2.26562
Timestep Consumption Time: 2.49653
PPO Batch Consumption Time: 0.29250
Total Iteration Time: 4.76214

Cumulative Model Updates: 259,544
Cumulative Timesteps: 2,165,164,768

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 2165164768...
Checkpoint 2165164768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 104,955.84101
Policy Entropy: 2.65597
Value Function Loss: 0.01288

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.06776
Policy Update Magnitude: 0.33908
Value Function Update Magnitude: 0.18784

Collected Steps per Second: 21,847.56249
Overall Steps per Second: 10,576.34816

Timestep Collection Time: 2.28895
Timestep Consumption Time: 2.43934
PPO Batch Consumption Time: 0.27824
Total Iteration Time: 4.72829

Cumulative Model Updates: 259,550
Cumulative Timesteps: 2,165,214,776

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93,699.09551
Policy Entropy: 2.69246
Value Function Loss: 0.01171

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.07847
Policy Update Magnitude: 0.33664
Value Function Update Magnitude: 0.24817

Collected Steps per Second: 22,288.88222
Overall Steps per Second: 10,571.89957

Timestep Collection Time: 2.24426
Timestep Consumption Time: 2.48734
PPO Batch Consumption Time: 0.29230
Total Iteration Time: 4.73160

Cumulative Model Updates: 259,556
Cumulative Timesteps: 2,165,264,798

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2165264798...
Checkpoint 2165264798 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 148,893.40727
Policy Entropy: 2.67380
Value Function Loss: 0.01164

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.07140
Policy Update Magnitude: 0.32137
Value Function Update Magnitude: 0.32476

Collected Steps per Second: 21,347.91534
Overall Steps per Second: 10,586.48958

Timestep Collection Time: 2.34393
Timestep Consumption Time: 2.38266
PPO Batch Consumption Time: 0.28439
Total Iteration Time: 4.72659

Cumulative Model Updates: 259,562
Cumulative Timesteps: 2,165,314,836

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 135,597.59170
Policy Entropy: 2.66970
Value Function Loss: 0.01120

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.07965
Policy Update Magnitude: 0.32396
Value Function Update Magnitude: 0.35083

Collected Steps per Second: 21,082.58981
Overall Steps per Second: 10,426.78968

Timestep Collection Time: 2.37200
Timestep Consumption Time: 2.42410
PPO Batch Consumption Time: 0.29113
Total Iteration Time: 4.79611

Cumulative Model Updates: 259,568
Cumulative Timesteps: 2,165,364,844

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2165364844...
Checkpoint 2165364844 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 100,969.30601
Policy Entropy: 2.66206
Value Function Loss: 0.01313

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.07683
Policy Update Magnitude: 0.33434
Value Function Update Magnitude: 0.36308

Collected Steps per Second: 20,670.87427
Overall Steps per Second: 10,341.22957

Timestep Collection Time: 2.42051
Timestep Consumption Time: 2.41780
PPO Batch Consumption Time: 0.29120
Total Iteration Time: 4.83830

Cumulative Model Updates: 259,574
Cumulative Timesteps: 2,165,414,878

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84,779.65083
Policy Entropy: 2.66273
Value Function Loss: 0.01299

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.07389
Policy Update Magnitude: 0.32355
Value Function Update Magnitude: 0.37778

Collected Steps per Second: 21,128.09226
Overall Steps per Second: 10,325.90655

Timestep Collection Time: 2.36699
Timestep Consumption Time: 2.47617
PPO Batch Consumption Time: 0.29129
Total Iteration Time: 4.84316

Cumulative Model Updates: 259,580
Cumulative Timesteps: 2,165,464,888

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2165464888...
Checkpoint 2165464888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 75,912.61277
Policy Entropy: 2.69785
Value Function Loss: 0.01257

Mean KL Divergence: 0.00701
SB3 Clip Fraction: 0.06723
Policy Update Magnitude: 0.31416
Value Function Update Magnitude: 0.35118

Collected Steps per Second: 21,418.38056
Overall Steps per Second: 10,523.50547

Timestep Collection Time: 2.33500
Timestep Consumption Time: 2.41741
PPO Batch Consumption Time: 0.27789
Total Iteration Time: 4.75241

Cumulative Model Updates: 259,586
Cumulative Timesteps: 2,165,514,900

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75,912.61277
Policy Entropy: 2.71278
Value Function Loss: 0.01050

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.07596
Policy Update Magnitude: 0.29785
Value Function Update Magnitude: 0.31012

Collected Steps per Second: 21,890.73276
Overall Steps per Second: 10,577.46299

Timestep Collection Time: 2.28617
Timestep Consumption Time: 2.44521
PPO Batch Consumption Time: 0.27837
Total Iteration Time: 4.73138

Cumulative Model Updates: 259,592
Cumulative Timesteps: 2,165,564,946

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 2165564946...
Checkpoint 2165564946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 75,912.61277
Policy Entropy: 2.73661
Value Function Loss: 0.00898

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.08722
Policy Update Magnitude: 0.28497
Value Function Update Magnitude: 0.28415

Collected Steps per Second: 21,988.23392
Overall Steps per Second: 10,591.95529

Timestep Collection Time: 2.27422
Timestep Consumption Time: 2.44691
PPO Batch Consumption Time: 0.27886
Total Iteration Time: 4.72113

Cumulative Model Updates: 259,598
Cumulative Timesteps: 2,165,614,952

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61,479.73725
Policy Entropy: 2.72801
Value Function Loss: 0.01146

Mean KL Divergence: 0.01060
SB3 Clip Fraction: 0.09414
Policy Update Magnitude: 0.28723
Value Function Update Magnitude: 0.28174

Collected Steps per Second: 22,193.18868
Overall Steps per Second: 10,510.38078

Timestep Collection Time: 2.25502
Timestep Consumption Time: 2.50656
PPO Batch Consumption Time: 0.29406
Total Iteration Time: 4.76158

Cumulative Model Updates: 259,604
Cumulative Timesteps: 2,165,664,998

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 2165664998...
Checkpoint 2165664998 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 66,808.52252
Policy Entropy: 2.72031
Value Function Loss: 0.01210

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.08878
Policy Update Magnitude: 0.29370
Value Function Update Magnitude: 0.28383

Collected Steps per Second: 21,622.10119
Overall Steps per Second: 10,549.55570

Timestep Collection Time: 2.31291
Timestep Consumption Time: 2.42757
PPO Batch Consumption Time: 0.27849
Total Iteration Time: 4.74048

Cumulative Model Updates: 259,610
Cumulative Timesteps: 2,165,715,008

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81,014.32469
Policy Entropy: 2.70046
Value Function Loss: 0.01446

Mean KL Divergence: 0.00750
SB3 Clip Fraction: 0.07260
Policy Update Magnitude: 0.31410
Value Function Update Magnitude: 0.31903

Collected Steps per Second: 22,412.55756
Overall Steps per Second: 10,528.85024

Timestep Collection Time: 2.23187
Timestep Consumption Time: 2.51907
PPO Batch Consumption Time: 0.29322
Total Iteration Time: 4.75095

Cumulative Model Updates: 259,616
Cumulative Timesteps: 2,165,765,030

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2165765030...
Checkpoint 2165765030 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 101,680.19963
Policy Entropy: 2.69543
Value Function Loss: 0.01327

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.07489
Policy Update Magnitude: 0.32949
Value Function Update Magnitude: 0.34056

Collected Steps per Second: 21,846.83663
Overall Steps per Second: 10,592.26391

Timestep Collection Time: 2.29031
Timestep Consumption Time: 2.43352
PPO Batch Consumption Time: 0.27871
Total Iteration Time: 4.72382

Cumulative Model Updates: 259,622
Cumulative Timesteps: 2,165,815,066

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70,357.95137
Policy Entropy: 2.69298
Value Function Loss: 0.01369

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.07746
Policy Update Magnitude: 0.33300
Value Function Update Magnitude: 0.32122

Collected Steps per Second: 21,936.23854
Overall Steps per Second: 10,510.40754

Timestep Collection Time: 2.28052
Timestep Consumption Time: 2.47914
PPO Batch Consumption Time: 0.28779
Total Iteration Time: 4.75966

Cumulative Model Updates: 259,628
Cumulative Timesteps: 2,165,865,092

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2165865092...
Checkpoint 2165865092 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 68,902.48501
Policy Entropy: 2.69400
Value Function Loss: 0.01466

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.08195
Policy Update Magnitude: 0.33822
Value Function Update Magnitude: 0.30379

Collected Steps per Second: 20,941.00172
Overall Steps per Second: 10,204.56950

Timestep Collection Time: 2.38804
Timestep Consumption Time: 2.51251
PPO Batch Consumption Time: 0.29391
Total Iteration Time: 4.90055

Cumulative Model Updates: 259,634
Cumulative Timesteps: 2,165,915,100

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84,941.98197
Policy Entropy: 2.66645
Value Function Loss: 0.01398

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.09647
Policy Update Magnitude: 0.33893
Value Function Update Magnitude: 0.33393

Collected Steps per Second: 21,707.57205
Overall Steps per Second: 10,421.35469

Timestep Collection Time: 2.30380
Timestep Consumption Time: 2.49500
PPO Batch Consumption Time: 0.28959
Total Iteration Time: 4.79880

Cumulative Model Updates: 259,640
Cumulative Timesteps: 2,165,965,110

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2165965110...
Checkpoint 2165965110 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84,941.98197
Policy Entropy: 2.66977
Value Function Loss: 0.01147

Mean KL Divergence: 0.01071
SB3 Clip Fraction: 0.09105
Policy Update Magnitude: 0.31992
Value Function Update Magnitude: 0.35853

Collected Steps per Second: 21,393.01506
Overall Steps per Second: 10,263.85396

Timestep Collection Time: 2.33852
Timestep Consumption Time: 2.53567
PPO Batch Consumption Time: 0.29407
Total Iteration Time: 4.87419

Cumulative Model Updates: 259,646
Cumulative Timesteps: 2,166,015,138

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86,556.11063
Policy Entropy: 2.66313
Value Function Loss: 0.01062

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.08104
Policy Update Magnitude: 0.30965
Value Function Update Magnitude: 0.31704

Collected Steps per Second: 21,062.29056
Overall Steps per Second: 10,099.77075

Timestep Collection Time: 2.37619
Timestep Consumption Time: 2.57917
PPO Batch Consumption Time: 0.29233
Total Iteration Time: 4.95536

Cumulative Model Updates: 259,652
Cumulative Timesteps: 2,166,065,186

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 2166065186...
Checkpoint 2166065186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 99,414.21523
Policy Entropy: 2.70885
Value Function Loss: 0.01086

Mean KL Divergence: 0.00782
SB3 Clip Fraction: 0.07373
Policy Update Magnitude: 0.30326
Value Function Update Magnitude: 0.26113

Collected Steps per Second: 21,107.15251
Overall Steps per Second: 10,188.47165

Timestep Collection Time: 2.37000
Timestep Consumption Time: 2.53986
PPO Batch Consumption Time: 0.29316
Total Iteration Time: 4.90986

Cumulative Model Updates: 259,658
Cumulative Timesteps: 2,166,115,210

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90,207.57006
Policy Entropy: 2.69792
Value Function Loss: 0.01506

Mean KL Divergence: 0.00691
SB3 Clip Fraction: 0.06547
Policy Update Magnitude: 0.30725
Value Function Update Magnitude: 0.24743

Collected Steps per Second: 21,944.81899
Overall Steps per Second: 10,426.14371

Timestep Collection Time: 2.27862
Timestep Consumption Time: 2.51740
PPO Batch Consumption Time: 0.29217
Total Iteration Time: 4.79602

Cumulative Model Updates: 259,664
Cumulative Timesteps: 2,166,165,214

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2166165214...
Checkpoint 2166165214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 121,593.54622
Policy Entropy: 2.69629
Value Function Loss: 0.01538

Mean KL Divergence: 0.00670
SB3 Clip Fraction: 0.06035
Policy Update Magnitude: 0.32306
Value Function Update Magnitude: 0.32178

Collected Steps per Second: 21,607.36397
Overall Steps per Second: 10,539.59965

Timestep Collection Time: 2.31523
Timestep Consumption Time: 2.43125
PPO Batch Consumption Time: 0.27896
Total Iteration Time: 4.74648

Cumulative Model Updates: 259,670
Cumulative Timesteps: 2,166,215,240

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92,835.21112
Policy Entropy: 2.70034
Value Function Loss: 0.01383

Mean KL Divergence: 0.00704
SB3 Clip Fraction: 0.06368
Policy Update Magnitude: 0.32128
Value Function Update Magnitude: 0.34913

Collected Steps per Second: 22,060.28474
Overall Steps per Second: 10,491.42245

Timestep Collection Time: 2.26797
Timestep Consumption Time: 2.50088
PPO Batch Consumption Time: 0.29095
Total Iteration Time: 4.76885

Cumulative Model Updates: 259,676
Cumulative Timesteps: 2,166,265,272

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2166265272...
Checkpoint 2166265272 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 71,077.57387
Policy Entropy: 2.71454
Value Function Loss: 0.01173

Mean KL Divergence: 0.00643
SB3 Clip Fraction: 0.05755
Policy Update Magnitude: 0.30718
Value Function Update Magnitude: 0.31633

Collected Steps per Second: 21,718.39234
Overall Steps per Second: 10,566.82477

Timestep Collection Time: 2.30284
Timestep Consumption Time: 2.43027
PPO Batch Consumption Time: 0.27933
Total Iteration Time: 4.73312

Cumulative Model Updates: 259,682
Cumulative Timesteps: 2,166,315,286

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75,316.40494
Policy Entropy: 2.73340
Value Function Loss: 0.00999

Mean KL Divergence: 0.00547
SB3 Clip Fraction: 0.05340
Policy Update Magnitude: 0.29822
Value Function Update Magnitude: 0.30615

Collected Steps per Second: 22,205.80045
Overall Steps per Second: 10,504.83268

Timestep Collection Time: 2.25229
Timestep Consumption Time: 2.50875
PPO Batch Consumption Time: 0.29115
Total Iteration Time: 4.76105

Cumulative Model Updates: 259,688
Cumulative Timesteps: 2,166,365,300

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2166365300...
Checkpoint 2166365300 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 75,316.40494
Policy Entropy: 2.71517
Value Function Loss: 0.01028

Mean KL Divergence: 0.00547
SB3 Clip Fraction: 0.05003
Policy Update Magnitude: 0.30377
Value Function Update Magnitude: 0.30210

Collected Steps per Second: 22,010.24241
Overall Steps per Second: 10,631.05426

Timestep Collection Time: 2.27294
Timestep Consumption Time: 2.43289
PPO Batch Consumption Time: 0.27849
Total Iteration Time: 4.70584

Cumulative Model Updates: 259,694
Cumulative Timesteps: 2,166,415,328

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65,750.00989
Policy Entropy: 2.71813
Value Function Loss: 0.00909

Mean KL Divergence: 0.00559
SB3 Clip Fraction: 0.04809
Policy Update Magnitude: 0.29567
Value Function Update Magnitude: 0.26695

Collected Steps per Second: 21,114.13648
Overall Steps per Second: 10,489.51636

Timestep Collection Time: 2.36893
Timestep Consumption Time: 2.39945
PPO Batch Consumption Time: 0.28447
Total Iteration Time: 4.76838

Cumulative Model Updates: 259,700
Cumulative Timesteps: 2,166,465,346

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2166465346...
Checkpoint 2166465346 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 148,835.28440
Policy Entropy: 2.71729
Value Function Loss: 0.00951

Mean KL Divergence: 0.00631
SB3 Clip Fraction: 0.04876
Policy Update Magnitude: 0.28915
Value Function Update Magnitude: 0.25448

Collected Steps per Second: 20,815.41326
Overall Steps per Second: 10,543.63877

Timestep Collection Time: 2.40245
Timestep Consumption Time: 2.34050
PPO Batch Consumption Time: 0.27813
Total Iteration Time: 4.74295

Cumulative Model Updates: 259,706
Cumulative Timesteps: 2,166,515,354

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 157,370.40695
Policy Entropy: 2.72830
Value Function Loss: 0.01023

Mean KL Divergence: 0.00525
SB3 Clip Fraction: 0.04938
Policy Update Magnitude: 0.28483
Value Function Update Magnitude: 0.26047

Collected Steps per Second: 21,230.85829
Overall Steps per Second: 10,500.72095

Timestep Collection Time: 2.35563
Timestep Consumption Time: 2.40709
PPO Batch Consumption Time: 0.28771
Total Iteration Time: 4.76272

Cumulative Model Updates: 259,712
Cumulative Timesteps: 2,166,565,366

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2166565366...
Checkpoint 2166565366 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 157,370.40695
Policy Entropy: 2.74406
Value Function Loss: 0.00891

Mean KL Divergence: 0.00560
SB3 Clip Fraction: 0.05242
Policy Update Magnitude: 0.27727
Value Function Update Magnitude: 0.24588

Collected Steps per Second: 20,481.86820
Overall Steps per Second: 10,290.03284

Timestep Collection Time: 2.44167
Timestep Consumption Time: 2.41837
PPO Batch Consumption Time: 0.27642
Total Iteration Time: 4.86004

Cumulative Model Updates: 259,718
Cumulative Timesteps: 2,166,615,376

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 150,485.27547
Policy Entropy: 2.74061
Value Function Loss: 0.00960

Mean KL Divergence: 0.00542
SB3 Clip Fraction: 0.05013
Policy Update Magnitude: 0.26755
Value Function Update Magnitude: 0.23457

Collected Steps per Second: 21,573.82629
Overall Steps per Second: 10,397.83347

Timestep Collection Time: 2.31790
Timestep Consumption Time: 2.49137
PPO Batch Consumption Time: 0.29246
Total Iteration Time: 4.80927

Cumulative Model Updates: 259,724
Cumulative Timesteps: 2,166,665,382

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2166665382...
Checkpoint 2166665382 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 103,701.74232
Policy Entropy: 2.74085
Value Function Loss: 0.00943

Mean KL Divergence: 0.00770
SB3 Clip Fraction: 0.06561
Policy Update Magnitude: 0.27606
Value Function Update Magnitude: 0.24546

Collected Steps per Second: 21,966.22626
Overall Steps per Second: 10,614.48123

Timestep Collection Time: 2.27704
Timestep Consumption Time: 2.43520
PPO Batch Consumption Time: 0.27931
Total Iteration Time: 4.71224

Cumulative Model Updates: 259,730
Cumulative Timesteps: 2,166,715,400

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 104,298.97232
Policy Entropy: 2.72220
Value Function Loss: 0.01017

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.07932
Policy Update Magnitude: 0.27945
Value Function Update Magnitude: 0.28377

Collected Steps per Second: 22,134.77804
Overall Steps per Second: 10,474.20303

Timestep Collection Time: 2.26052
Timestep Consumption Time: 2.51655
PPO Batch Consumption Time: 0.29264
Total Iteration Time: 4.77707

Cumulative Model Updates: 259,736
Cumulative Timesteps: 2,166,765,436

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 2166765436...
Checkpoint 2166765436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 104,318.08556
Policy Entropy: 2.73438
Value Function Loss: 0.00939

Mean KL Divergence: 0.00723
SB3 Clip Fraction: 0.06840
Policy Update Magnitude: 0.28332
Value Function Update Magnitude: 0.30103

Collected Steps per Second: 22,061.69971
Overall Steps per Second: 10,659.35833

Timestep Collection Time: 2.26710
Timestep Consumption Time: 2.42512
PPO Batch Consumption Time: 0.27739
Total Iteration Time: 4.69221

Cumulative Model Updates: 259,742
Cumulative Timesteps: 2,166,815,452

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 101,317.10431
Policy Entropy: 2.70456
Value Function Loss: 0.00874

Mean KL Divergence: 0.00609
SB3 Clip Fraction: 0.05680
Policy Update Magnitude: 0.28091
Value Function Update Magnitude: 0.28827

Collected Steps per Second: 22,303.59669
Overall Steps per Second: 10,553.51612

Timestep Collection Time: 2.24367
Timestep Consumption Time: 2.49806
PPO Batch Consumption Time: 0.29231
Total Iteration Time: 4.74174

Cumulative Model Updates: 259,748
Cumulative Timesteps: 2,166,865,494

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 2166865494...
Checkpoint 2166865494 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 91,595.83243
Policy Entropy: 2.70653
Value Function Loss: 0.00894

Mean KL Divergence: 0.00639
SB3 Clip Fraction: 0.05799
Policy Update Magnitude: 0.28733
Value Function Update Magnitude: 0.25931

Collected Steps per Second: 22,105.87032
Overall Steps per Second: 10,507.21524

Timestep Collection Time: 2.26266
Timestep Consumption Time: 2.49769
PPO Batch Consumption Time: 0.28989
Total Iteration Time: 4.76035

Cumulative Model Updates: 259,754
Cumulative Timesteps: 2,166,915,512

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 98,106.88566
Policy Entropy: 2.67439
Value Function Loss: 0.01077

Mean KL Divergence: 0.00715
SB3 Clip Fraction: 0.06751
Policy Update Magnitude: 0.29564
Value Function Update Magnitude: 0.22189

Collected Steps per Second: 22,026.48602
Overall Steps per Second: 10,447.77587

Timestep Collection Time: 2.27172
Timestep Consumption Time: 2.51763
PPO Batch Consumption Time: 0.29090
Total Iteration Time: 4.78934

Cumulative Model Updates: 259,760
Cumulative Timesteps: 2,166,965,550

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 2166965550...
Checkpoint 2166965550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 82,201.87624
Policy Entropy: 2.68301
Value Function Loss: 0.01179

Mean KL Divergence: 0.00716
SB3 Clip Fraction: 0.06824
Policy Update Magnitude: 0.30915
Value Function Update Magnitude: 0.23471

Collected Steps per Second: 21,509.51932
Overall Steps per Second: 10,377.88747

Timestep Collection Time: 2.32548
Timestep Consumption Time: 2.49438
PPO Batch Consumption Time: 0.29156
Total Iteration Time: 4.81986

Cumulative Model Updates: 259,766
Cumulative Timesteps: 2,167,015,570

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79,152.96868
Policy Entropy: 2.67974
Value Function Loss: 0.01301

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.08047
Policy Update Magnitude: 0.32815
Value Function Update Magnitude: 0.24695

Collected Steps per Second: 21,735.83463
Overall Steps per Second: 10,437.25411

Timestep Collection Time: 2.30201
Timestep Consumption Time: 2.49198
PPO Batch Consumption Time: 0.29161
Total Iteration Time: 4.79398

Cumulative Model Updates: 259,772
Cumulative Timesteps: 2,167,065,606

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 2167065606...
Checkpoint 2167065606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 79,152.96868
Policy Entropy: 2.71506
Value Function Loss: 0.01065

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.07699
Policy Update Magnitude: 0.30968
Value Function Update Magnitude: 0.26245

Collected Steps per Second: 21,583.01328
Overall Steps per Second: 10,555.76201

Timestep Collection Time: 2.31682
Timestep Consumption Time: 2.42031
PPO Batch Consumption Time: 0.27693
Total Iteration Time: 4.73713

Cumulative Model Updates: 259,778
Cumulative Timesteps: 2,167,115,610

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86,910.19161
Policy Entropy: 2.71192
Value Function Loss: 0.01114

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.07537
Policy Update Magnitude: 0.29534
Value Function Update Magnitude: 0.25664

Collected Steps per Second: 21,562.02807
Overall Steps per Second: 10,365.04609

Timestep Collection Time: 2.32000
Timestep Consumption Time: 2.50622
PPO Batch Consumption Time: 0.28913
Total Iteration Time: 4.82622

Cumulative Model Updates: 259,784
Cumulative Timesteps: 2,167,165,634

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2167165634...
Checkpoint 2167165634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 79,753.41579
Policy Entropy: 2.68282
Value Function Loss: 0.01103

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.08276
Policy Update Magnitude: 0.29729
Value Function Update Magnitude: 0.25421

Collected Steps per Second: 21,314.92131
Overall Steps per Second: 10,284.22974

Timestep Collection Time: 2.34653
Timestep Consumption Time: 2.51684
PPO Batch Consumption Time: 0.29350
Total Iteration Time: 4.86337

Cumulative Model Updates: 259,790
Cumulative Timesteps: 2,167,215,650

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 133,682.67840
Policy Entropy: 2.65496
Value Function Loss: 0.01334

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.06967
Policy Update Magnitude: 0.31124
Value Function Update Magnitude: 0.23511

Collected Steps per Second: 21,640.33984
Overall Steps per Second: 10,407.19828

Timestep Collection Time: 2.31161
Timestep Consumption Time: 2.49506
PPO Batch Consumption Time: 0.28842
Total Iteration Time: 4.80667

Cumulative Model Updates: 259,796
Cumulative Timesteps: 2,167,265,674

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2167265674...
Checkpoint 2167265674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 140,744.34112
Policy Entropy: 2.65342
Value Function Loss: 0.01261

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.08045
Policy Update Magnitude: 0.32917
Value Function Update Magnitude: 0.27688

Collected Steps per Second: 21,577.14777
Overall Steps per Second: 10,289.53377

Timestep Collection Time: 2.31847
Timestep Consumption Time: 2.54336
PPO Batch Consumption Time: 0.29322
Total Iteration Time: 4.86183

Cumulative Model Updates: 259,802
Cumulative Timesteps: 2,167,315,700

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 168,779.87202
Policy Entropy: 2.67770
Value Function Loss: 0.01096

Mean KL Divergence: 0.00777
SB3 Clip Fraction: 0.06764
Policy Update Magnitude: 0.31727
Value Function Update Magnitude: 0.32421

Collected Steps per Second: 22,360.43454
Overall Steps per Second: 10,571.66034

Timestep Collection Time: 2.23752
Timestep Consumption Time: 2.49513
PPO Batch Consumption Time: 0.28806
Total Iteration Time: 4.73265

Cumulative Model Updates: 259,808
Cumulative Timesteps: 2,167,365,732

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2167365732...
Checkpoint 2167365732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 142,819.44498
Policy Entropy: 2.72339
Value Function Loss: 0.00922

Mean KL Divergence: 0.00718
SB3 Clip Fraction: 0.06378
Policy Update Magnitude: 0.29575
Value Function Update Magnitude: 0.30857

Collected Steps per Second: 20,417.55000
Overall Steps per Second: 10,085.15448

Timestep Collection Time: 2.45005
Timestep Consumption Time: 2.51011
PPO Batch Consumption Time: 0.29242
Total Iteration Time: 4.96016

Cumulative Model Updates: 259,814
Cumulative Timesteps: 2,167,415,756

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 142,819.44498
Policy Entropy: 2.74071
Value Function Loss: 0.00827

Mean KL Divergence: 0.00686
SB3 Clip Fraction: 0.06323
Policy Update Magnitude: 0.27475
Value Function Update Magnitude: 0.27180

Collected Steps per Second: 21,754.52402
Overall Steps per Second: 10,395.91418

Timestep Collection Time: 2.29966
Timestep Consumption Time: 2.51262
PPO Batch Consumption Time: 0.29076
Total Iteration Time: 4.81228

Cumulative Model Updates: 259,820
Cumulative Timesteps: 2,167,465,784

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2167465784...
Checkpoint 2167465784 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 115,199.78912
Policy Entropy: 2.76313
Value Function Loss: 0.00865

Mean KL Divergence: 0.00642
SB3 Clip Fraction: 0.06050
Policy Update Magnitude: 0.26224
Value Function Update Magnitude: 0.24212

Collected Steps per Second: 21,121.49864
Overall Steps per Second: 10,261.74947

Timestep Collection Time: 2.36887
Timestep Consumption Time: 2.50691
PPO Batch Consumption Time: 0.29278
Total Iteration Time: 4.87578

Cumulative Model Updates: 259,826
Cumulative Timesteps: 2,167,515,818

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 98,311.65968
Policy Entropy: 2.73669
Value Function Loss: 0.01151

Mean KL Divergence: 0.00731
SB3 Clip Fraction: 0.06653
Policy Update Magnitude: 0.27425
Value Function Update Magnitude: 0.25002

Collected Steps per Second: 21,915.77773
Overall Steps per Second: 10,427.30740

Timestep Collection Time: 2.28247
Timestep Consumption Time: 2.51475
PPO Batch Consumption Time: 0.29241
Total Iteration Time: 4.79721

Cumulative Model Updates: 259,832
Cumulative Timesteps: 2,167,565,840

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2167565840...
Checkpoint 2167565840 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 88,136.39021
Policy Entropy: 2.72321
Value Function Loss: 0.01152

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.08576
Policy Update Magnitude: 0.29394
Value Function Update Magnitude: 0.26082

Collected Steps per Second: 21,780.82191
Overall Steps per Second: 10,519.04830

Timestep Collection Time: 2.29642
Timestep Consumption Time: 2.45857
PPO Batch Consumption Time: 0.27830
Total Iteration Time: 4.75499

Cumulative Model Updates: 259,838
Cumulative Timesteps: 2,167,615,858

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 111,045.32896
Policy Entropy: 2.70457
Value Function Loss: 0.01220

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.08494
Policy Update Magnitude: 0.30066
Value Function Update Magnitude: 0.27721

Collected Steps per Second: 22,140.28738
Overall Steps per Second: 10,544.15504

Timestep Collection Time: 2.25941
Timestep Consumption Time: 2.48483
PPO Batch Consumption Time: 0.28721
Total Iteration Time: 4.74424

Cumulative Model Updates: 259,844
Cumulative Timesteps: 2,167,665,882

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2167665882...
Checkpoint 2167665882 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 106,806.80854
Policy Entropy: 2.71212
Value Function Loss: 0.01180

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.07903
Policy Update Magnitude: 0.31084
Value Function Update Magnitude: 0.30630

Collected Steps per Second: 22,215.16358
Overall Steps per Second: 10,705.94380

Timestep Collection Time: 2.25098
Timestep Consumption Time: 2.41988
PPO Batch Consumption Time: 0.27696
Total Iteration Time: 4.67086

Cumulative Model Updates: 259,850
Cumulative Timesteps: 2,167,715,888

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92,203.29557
Policy Entropy: 2.71714
Value Function Loss: 0.01458

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.08637
Policy Update Magnitude: 0.32386
Value Function Update Magnitude: 0.32556

Collected Steps per Second: 22,268.14354
Overall Steps per Second: 10,550.65533

Timestep Collection Time: 2.24752
Timestep Consumption Time: 2.49608
PPO Batch Consumption Time: 0.29013
Total Iteration Time: 4.74359

Cumulative Model Updates: 259,856
Cumulative Timesteps: 2,167,765,936

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 2167765936...
Checkpoint 2167765936 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 125,523.48850
Policy Entropy: 2.72397
Value Function Loss: 0.01339

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.07365
Policy Update Magnitude: 0.32495
Value Function Update Magnitude: 0.30617

Collected Steps per Second: 22,023.03276
Overall Steps per Second: 10,459.13814

Timestep Collection Time: 2.27071
Timestep Consumption Time: 2.51056
PPO Batch Consumption Time: 0.29163
Total Iteration Time: 4.78127

Cumulative Model Updates: 259,862
Cumulative Timesteps: 2,167,815,944

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 104,955.55089
Policy Entropy: 2.73371
Value Function Loss: 0.01234

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.07462
Policy Update Magnitude: 0.31313
Value Function Update Magnitude: 0.33676

Collected Steps per Second: 22,033.12476
Overall Steps per Second: 10,485.37473

Timestep Collection Time: 2.26976
Timestep Consumption Time: 2.49974
PPO Batch Consumption Time: 0.29255
Total Iteration Time: 4.76950

Cumulative Model Updates: 259,868
Cumulative Timesteps: 2,167,865,954

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2167865954...
Checkpoint 2167865954 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 104,177.39968
Policy Entropy: 2.74063
Value Function Loss: 0.01069

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.06823
Policy Update Magnitude: 0.29418
Value Function Update Magnitude: 0.32881

Collected Steps per Second: 21,908.22918
Overall Steps per Second: 10,601.49565

Timestep Collection Time: 2.28353
Timestep Consumption Time: 2.43543
PPO Batch Consumption Time: 0.27913
Total Iteration Time: 4.71896

Cumulative Model Updates: 259,874
Cumulative Timesteps: 2,167,915,982

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 104,177.39968
Policy Entropy: 2.73800
Value Function Loss: 0.00879

Mean KL Divergence: 0.00718
SB3 Clip Fraction: 0.06697
Policy Update Magnitude: 0.28488
Value Function Update Magnitude: 0.28725

Collected Steps per Second: 21,841.26760
Overall Steps per Second: 10,468.19180

Timestep Collection Time: 2.28961
Timestep Consumption Time: 2.48753
PPO Batch Consumption Time: 0.28713
Total Iteration Time: 4.77714

Cumulative Model Updates: 259,880
Cumulative Timesteps: 2,167,965,990

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2167965990...
Checkpoint 2167965990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 80,064.40052
Policy Entropy: 2.72860
Value Function Loss: 0.00950

Mean KL Divergence: 0.00729
SB3 Clip Fraction: 0.06980
Policy Update Magnitude: 0.28246
Value Function Update Magnitude: 0.26580

Collected Steps per Second: 21,584.38723
Overall Steps per Second: 10,547.12972

Timestep Collection Time: 2.31742
Timestep Consumption Time: 2.42511
PPO Batch Consumption Time: 0.27853
Total Iteration Time: 4.74252

Cumulative Model Updates: 259,886
Cumulative Timesteps: 2,168,016,010

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86,923.67103
Policy Entropy: 2.69921
Value Function Loss: 0.01028

Mean KL Divergence: 0.00607
SB3 Clip Fraction: 0.05574
Policy Update Magnitude: 0.29860
Value Function Update Magnitude: 0.27111

Collected Steps per Second: 21,500.59462
Overall Steps per Second: 10,513.90236

Timestep Collection Time: 2.32561
Timestep Consumption Time: 2.43019
PPO Batch Consumption Time: 0.27838
Total Iteration Time: 4.75580

Cumulative Model Updates: 259,892
Cumulative Timesteps: 2,168,066,012

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2168066012...
Checkpoint 2168066012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86,923.67103
Policy Entropy: 2.69653
Value Function Loss: 0.00958

Mean KL Divergence: 0.00695
SB3 Clip Fraction: 0.06160
Policy Update Magnitude: 0.29322
Value Function Update Magnitude: 0.26187

Collected Steps per Second: 21,264.54384
Overall Steps per Second: 10,309.70364

Timestep Collection Time: 2.35171
Timestep Consumption Time: 2.49887
PPO Batch Consumption Time: 0.29289
Total Iteration Time: 4.85058

Cumulative Model Updates: 259,898
Cumulative Timesteps: 2,168,116,020

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88,663.66318
Policy Entropy: 2.66878
Value Function Loss: 0.00988

Mean KL Divergence: 0.00660
SB3 Clip Fraction: 0.05967
Policy Update Magnitude: 0.28939
Value Function Update Magnitude: 0.26260

Collected Steps per Second: 21,848.35129
Overall Steps per Second: 10,390.26522

Timestep Collection Time: 2.28850
Timestep Consumption Time: 2.52369
PPO Batch Consumption Time: 0.29356
Total Iteration Time: 4.81220

Cumulative Model Updates: 259,904
Cumulative Timesteps: 2,168,166,020

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2168166020...
Checkpoint 2168166020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 79,874.08745
Policy Entropy: 2.67994
Value Function Loss: 0.00929

Mean KL Divergence: 0.00581
SB3 Clip Fraction: 0.05477
Policy Update Magnitude: 0.29331
Value Function Update Magnitude: 0.28478

Collected Steps per Second: 21,687.34557
Overall Steps per Second: 10,294.34926

Timestep Collection Time: 2.30586
Timestep Consumption Time: 2.55195
PPO Batch Consumption Time: 0.29167
Total Iteration Time: 4.85781

Cumulative Model Updates: 259,910
Cumulative Timesteps: 2,168,216,028

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79,874.08745
Policy Entropy: 2.69344
Value Function Loss: 0.00887

Mean KL Divergence: 0.00696
SB3 Clip Fraction: 0.06218
Policy Update Magnitude: 0.28880
Value Function Update Magnitude: 0.26125

Collected Steps per Second: 22,402.31328
Overall Steps per Second: 10,706.43299

Timestep Collection Time: 2.23254
Timestep Consumption Time: 2.43886
PPO Batch Consumption Time: 0.27860
Total Iteration Time: 4.67140

Cumulative Model Updates: 259,916
Cumulative Timesteps: 2,168,266,042

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2168266042...
Checkpoint 2168266042 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 95,045.24696
Policy Entropy: 2.70183
Value Function Loss: 0.01010

Mean KL Divergence: 0.00741
SB3 Clip Fraction: 0.06581
Policy Update Magnitude: 0.29112
Value Function Update Magnitude: 0.23285

Collected Steps per Second: 21,855.00519
Overall Steps per Second: 10,444.50770

Timestep Collection Time: 2.28817
Timestep Consumption Time: 2.49980
PPO Batch Consumption Time: 0.29093
Total Iteration Time: 4.78797

Cumulative Model Updates: 259,922
Cumulative Timesteps: 2,168,316,050

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85,711.24548
Policy Entropy: 2.69954
Value Function Loss: 0.01115

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.07037
Policy Update Magnitude: 0.29193
Value Function Update Magnitude: 0.21149

Collected Steps per Second: 22,320.17466
Overall Steps per Second: 10,709.12318

Timestep Collection Time: 2.24120
Timestep Consumption Time: 2.42996
PPO Batch Consumption Time: 0.27879
Total Iteration Time: 4.67116

Cumulative Model Updates: 259,928
Cumulative Timesteps: 2,168,366,074

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2168366074...
Checkpoint 2168366074 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 267,613.31202
Policy Entropy: 2.67349
Value Function Loss: 0.01332

Mean KL Divergence: 0.00758
SB3 Clip Fraction: 0.06735
Policy Update Magnitude: 0.30081
Value Function Update Magnitude: 0.26456

Collected Steps per Second: 22,003.54023
Overall Steps per Second: 10,633.38884

Timestep Collection Time: 2.27245
Timestep Consumption Time: 2.42991
PPO Batch Consumption Time: 0.27914
Total Iteration Time: 4.70236

Cumulative Model Updates: 259,934
Cumulative Timesteps: 2,168,416,076

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 142,424.05546
Policy Entropy: 2.69110
Value Function Loss: 0.01350

Mean KL Divergence: 0.00722
SB3 Clip Fraction: 0.06889
Policy Update Magnitude: 0.31270
Value Function Update Magnitude: 0.28044

Collected Steps per Second: 22,117.16818
Overall Steps per Second: 10,500.84234

Timestep Collection Time: 2.26087
Timestep Consumption Time: 2.50104
PPO Batch Consumption Time: 0.29046
Total Iteration Time: 4.76190

Cumulative Model Updates: 259,940
Cumulative Timesteps: 2,168,466,080

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2168466080...
Checkpoint 2168466080 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 142,424.05546
Policy Entropy: 2.70988
Value Function Loss: 0.01104

Mean KL Divergence: 0.00688
SB3 Clip Fraction: 0.06373
Policy Update Magnitude: 0.30210
Value Function Update Magnitude: 0.25785

Collected Steps per Second: 21,880.81212
Overall Steps per Second: 10,621.95712

Timestep Collection Time: 2.28639
Timestep Consumption Time: 2.42348
PPO Batch Consumption Time: 0.27710
Total Iteration Time: 4.70987

Cumulative Model Updates: 259,946
Cumulative Timesteps: 2,168,516,108

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 110,073.54654
Policy Entropy: 2.70767
Value Function Loss: 0.01113

Mean KL Divergence: 0.00724
SB3 Clip Fraction: 0.06410
Policy Update Magnitude: 0.30479
Value Function Update Magnitude: 0.25595

Collected Steps per Second: 21,922.03322
Overall Steps per Second: 10,453.46093

Timestep Collection Time: 2.28127
Timestep Consumption Time: 2.50280
PPO Batch Consumption Time: 0.28868
Total Iteration Time: 4.78406

Cumulative Model Updates: 259,952
Cumulative Timesteps: 2,168,566,118

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2168566118...
Checkpoint 2168566118 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 97,931.01605
Policy Entropy: 2.72448
Value Function Loss: 0.01027

Mean KL Divergence: 0.01234
SB3 Clip Fraction: 0.10348
Policy Update Magnitude: 0.29566
Value Function Update Magnitude: 0.28645

Collected Steps per Second: 21,518.42205
Overall Steps per Second: 10,347.17593

Timestep Collection Time: 2.32433
Timestep Consumption Time: 2.50945
PPO Batch Consumption Time: 0.29113
Total Iteration Time: 4.83378

Cumulative Model Updates: 259,958
Cumulative Timesteps: 2,168,616,134

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 103,999.50961
Policy Entropy: 2.72647
Value Function Loss: 0.00977

Mean KL Divergence: 0.01308
SB3 Clip Fraction: 0.10537
Policy Update Magnitude: 0.28407
Value Function Update Magnitude: 0.26375

Collected Steps per Second: 21,590.39266
Overall Steps per Second: 10,392.41499

Timestep Collection Time: 2.31594
Timestep Consumption Time: 2.49546
PPO Batch Consumption Time: 0.29320
Total Iteration Time: 4.81139

Cumulative Model Updates: 259,964
Cumulative Timesteps: 2,168,666,136

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2168666136...
Checkpoint 2168666136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 182,959.41834
Policy Entropy: 2.74310
Value Function Loss: 0.00984

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.08542
Policy Update Magnitude: 0.28377
Value Function Update Magnitude: 0.25822

Collected Steps per Second: 21,442.60168
Overall Steps per Second: 10,502.93330

Timestep Collection Time: 2.33246
Timestep Consumption Time: 2.42945
PPO Batch Consumption Time: 0.27855
Total Iteration Time: 4.76191

Cumulative Model Updates: 259,970
Cumulative Timesteps: 2,168,716,150

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 162,239.36820
Policy Entropy: 2.71837
Value Function Loss: 0.01102

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.08258
Policy Update Magnitude: 0.30050
Value Function Update Magnitude: 0.28728

Collected Steps per Second: 22,006.11404
Overall Steps per Second: 10,481.57584

Timestep Collection Time: 2.27228
Timestep Consumption Time: 2.49838
PPO Batch Consumption Time: 0.28591
Total Iteration Time: 4.77066

Cumulative Model Updates: 259,976
Cumulative Timesteps: 2,168,766,154

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2168766154...
Checkpoint 2168766154 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 186,091.66284
Policy Entropy: 2.67824
Value Function Loss: 0.01278

Mean KL Divergence: 0.01110
SB3 Clip Fraction: 0.08794
Policy Update Magnitude: 0.31166
Value Function Update Magnitude: 0.32180

Collected Steps per Second: 21,968.01019
Overall Steps per Second: 10,581.15005

Timestep Collection Time: 2.27622
Timestep Consumption Time: 2.44954
PPO Batch Consumption Time: 0.27847
Total Iteration Time: 4.72576

Cumulative Model Updates: 259,982
Cumulative Timesteps: 2,168,816,158

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 214,873.03435
Policy Entropy: 2.68184
Value Function Loss: 0.01197

Mean KL Divergence: 0.01248
SB3 Clip Fraction: 0.09809
Policy Update Magnitude: 0.32218
Value Function Update Magnitude: 0.33622

Collected Steps per Second: 21,898.16957
Overall Steps per Second: 10,588.79296

Timestep Collection Time: 2.28512
Timestep Consumption Time: 2.44063
PPO Batch Consumption Time: 0.27712
Total Iteration Time: 4.72575

Cumulative Model Updates: 259,988
Cumulative Timesteps: 2,168,866,198

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 2168866198...
Checkpoint 2168866198 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 185,680.95191
Policy Entropy: 2.69761
Value Function Loss: 0.01077

Mean KL Divergence: 0.01102
SB3 Clip Fraction: 0.09546
Policy Update Magnitude: 0.31388
Value Function Update Magnitude: 0.31755

Collected Steps per Second: 22,144.13750
Overall Steps per Second: 10,621.94133

Timestep Collection Time: 2.25920
Timestep Consumption Time: 2.45068
PPO Batch Consumption Time: 0.28369
Total Iteration Time: 4.70987

Cumulative Model Updates: 259,994
Cumulative Timesteps: 2,168,916,226

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 173,088.43813
Policy Entropy: 2.72618
Value Function Loss: 0.00988

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.07628
Policy Update Magnitude: 0.30327
Value Function Update Magnitude: 0.29551

Collected Steps per Second: 22,248.67908
Overall Steps per Second: 10,510.21605

Timestep Collection Time: 2.24768
Timestep Consumption Time: 2.51035
PPO Batch Consumption Time: 0.29330
Total Iteration Time: 4.75804

Cumulative Model Updates: 260,000
Cumulative Timesteps: 2,168,966,234

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2168966234...
Checkpoint 2168966234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 143,606.42793
Policy Entropy: 2.70588
Value Function Loss: 0.00996

Mean KL Divergence: 0.00672
SB3 Clip Fraction: 0.06118
Policy Update Magnitude: 0.30154
Value Function Update Magnitude: 0.27386

Collected Steps per Second: 21,989.81889
Overall Steps per Second: 10,518.35203

Timestep Collection Time: 2.27551
Timestep Consumption Time: 2.48170
PPO Batch Consumption Time: 0.28651
Total Iteration Time: 4.75721

Cumulative Model Updates: 260,006
Cumulative Timesteps: 2,169,016,272

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 131,827.66925
Policy Entropy: 2.67554
Value Function Loss: 0.01077

Mean KL Divergence: 0.00636
SB3 Clip Fraction: 0.05412
Policy Update Magnitude: 0.31381
Value Function Update Magnitude: 0.28069

Collected Steps per Second: 22,031.01810
Overall Steps per Second: 10,498.66013

Timestep Collection Time: 2.27162
Timestep Consumption Time: 2.49528
PPO Batch Consumption Time: 0.28927
Total Iteration Time: 4.76689

Cumulative Model Updates: 260,012
Cumulative Timesteps: 2,169,066,318

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 2169066318...
Checkpoint 2169066318 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 122,714.30787
Policy Entropy: 2.64430
Value Function Loss: 0.01185

Mean KL Divergence: 0.00743
SB3 Clip Fraction: 0.06784
Policy Update Magnitude: 0.32358
Value Function Update Magnitude: 0.29875

Collected Steps per Second: 21,841.60248
Overall Steps per Second: 10,626.37683

Timestep Collection Time: 2.28985
Timestep Consumption Time: 2.41674
PPO Batch Consumption Time: 0.27850
Total Iteration Time: 4.70659

Cumulative Model Updates: 260,018
Cumulative Timesteps: 2,169,116,332

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 100,683.99990
Policy Entropy: 2.64879
Value Function Loss: 0.01262

Mean KL Divergence: 0.00708
SB3 Clip Fraction: 0.06535
Policy Update Magnitude: 0.32593
Value Function Update Magnitude: 0.32471

Collected Steps per Second: 21,624.78338
Overall Steps per Second: 10,536.07072

Timestep Collection Time: 2.31346
Timestep Consumption Time: 2.43480
PPO Batch Consumption Time: 0.27747
Total Iteration Time: 4.74826

Cumulative Model Updates: 260,024
Cumulative Timesteps: 2,169,166,360

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2169166360...
Checkpoint 2169166360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 101,715.81145
Policy Entropy: 2.67225
Value Function Loss: 0.01249

Mean KL Divergence: 0.00655
SB3 Clip Fraction: 0.06112
Policy Update Magnitude: 0.33001
Value Function Update Magnitude: 0.35302

Collected Steps per Second: 21,518.97150
Overall Steps per Second: 10,515.18191

Timestep Collection Time: 2.32483
Timestep Consumption Time: 2.43286
PPO Batch Consumption Time: 0.27820
Total Iteration Time: 4.75769

Cumulative Model Updates: 260,030
Cumulative Timesteps: 2,169,216,388

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 111,871.72350
Policy Entropy: 2.69770
Value Function Loss: 0.01071

Mean KL Divergence: 0.00625
SB3 Clip Fraction: 0.05550
Policy Update Magnitude: 0.31369
Value Function Update Magnitude: 0.35721

Collected Steps per Second: 21,563.52732
Overall Steps per Second: 10,483.17269

Timestep Collection Time: 2.31947
Timestep Consumption Time: 2.45160
PPO Batch Consumption Time: 0.27935
Total Iteration Time: 4.77107

Cumulative Model Updates: 260,036
Cumulative Timesteps: 2,169,266,404

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2169266404...
Checkpoint 2169266404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 111,871.72350
Policy Entropy: 2.69471
Value Function Loss: 0.00953

Mean KL Divergence: 0.00603
SB3 Clip Fraction: 0.05430
Policy Update Magnitude: 0.29554
Value Function Update Magnitude: 0.33581

Collected Steps per Second: 21,315.31888
Overall Steps per Second: 10,238.86976

Timestep Collection Time: 2.34573
Timestep Consumption Time: 2.53762
PPO Batch Consumption Time: 0.28820
Total Iteration Time: 4.88335

Cumulative Model Updates: 260,042
Cumulative Timesteps: 2,169,316,404

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 106,766.75206
Policy Entropy: 2.68468
Value Function Loss: 0.00931

Mean KL Divergence: 0.00609
SB3 Clip Fraction: 0.05698
Policy Update Magnitude: 0.29432
Value Function Update Magnitude: 0.28726

Collected Steps per Second: 21,963.09066
Overall Steps per Second: 10,422.31681

Timestep Collection Time: 2.27709
Timestep Consumption Time: 2.52146
PPO Batch Consumption Time: 0.29158
Total Iteration Time: 4.79855

Cumulative Model Updates: 260,048
Cumulative Timesteps: 2,169,366,416

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2169366416...
Checkpoint 2169366416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 96,538.27931
Policy Entropy: 2.65723
Value Function Loss: 0.00985

Mean KL Divergence: 0.00725
SB3 Clip Fraction: 0.06572
Policy Update Magnitude: 0.30066
Value Function Update Magnitude: 0.27547

Collected Steps per Second: 21,934.94081
Overall Steps per Second: 10,618.48877

Timestep Collection Time: 2.28074
Timestep Consumption Time: 2.43066
PPO Batch Consumption Time: 0.27870
Total Iteration Time: 4.71140

Cumulative Model Updates: 260,054
Cumulative Timesteps: 2,169,416,444

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 112,778.89869
Policy Entropy: 2.68293
Value Function Loss: 0.00942

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.06666
Policy Update Magnitude: 0.30191
Value Function Update Magnitude: 0.29531

Collected Steps per Second: 22,199.86148
Overall Steps per Second: 10,509.20637

Timestep Collection Time: 2.25425
Timestep Consumption Time: 2.50767
PPO Batch Consumption Time: 0.29299
Total Iteration Time: 4.76192

Cumulative Model Updates: 260,060
Cumulative Timesteps: 2,169,466,488

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 2169466488...
Checkpoint 2169466488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 142,808.55748
Policy Entropy: 2.69990
Value Function Loss: 0.00883

Mean KL Divergence: 0.00751
SB3 Clip Fraction: 0.06829
Policy Update Magnitude: 0.29880
Value Function Update Magnitude: 0.28951

Collected Steps per Second: 21,389.12671
Overall Steps per Second: 10,695.85908

Timestep Collection Time: 2.33857
Timestep Consumption Time: 2.33800
PPO Batch Consumption Time: 0.27707
Total Iteration Time: 4.67658

Cumulative Model Updates: 260,066
Cumulative Timesteps: 2,169,516,508

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 142,484.44253
Policy Entropy: 2.71992
Value Function Loss: 0.01088

Mean KL Divergence: 0.00739
SB3 Clip Fraction: 0.06471
Policy Update Magnitude: 0.30605
Value Function Update Magnitude: 0.27208

Collected Steps per Second: 21,556.79348
Overall Steps per Second: 10,523.58427

Timestep Collection Time: 2.32168
Timestep Consumption Time: 2.43411
PPO Batch Consumption Time: 0.29235
Total Iteration Time: 4.75579

Cumulative Model Updates: 260,072
Cumulative Timesteps: 2,169,566,556

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 2169566556...
Checkpoint 2169566556 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 169,456.79215
Policy Entropy: 2.68360
Value Function Loss: 0.01169

Mean KL Divergence: 0.00734
SB3 Clip Fraction: 0.06775
Policy Update Magnitude: 0.31330
Value Function Update Magnitude: 0.28932

Collected Steps per Second: 21,496.20529
Overall Steps per Second: 10,568.78804

Timestep Collection Time: 2.32850
Timestep Consumption Time: 2.40752
PPO Batch Consumption Time: 0.28855
Total Iteration Time: 4.73602

Cumulative Model Updates: 260,078
Cumulative Timesteps: 2,169,616,610

Timesteps Collected: 50,054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 113,656.54699
Policy Entropy: 2.69832
Value Function Loss: 0.01195

Mean KL Divergence: 0.00722
SB3 Clip Fraction: 0.06526
Policy Update Magnitude: 0.30984
Value Function Update Magnitude: 0.29788

Collected Steps per Second: 21,345.33578
Overall Steps per Second: 10,456.49971

Timestep Collection Time: 2.34290
Timestep Consumption Time: 2.43977
PPO Batch Consumption Time: 0.28488
Total Iteration Time: 4.78267

Cumulative Model Updates: 260,084
Cumulative Timesteps: 2,169,666,620

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2169666620...
Checkpoint 2169666620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 98,619.29639
Policy Entropy: 2.71914
Value Function Loss: 0.01070

Mean KL Divergence: 0.00699
SB3 Clip Fraction: 0.06541
Policy Update Magnitude: 0.30014
Value Function Update Magnitude: 0.29283

Collected Steps per Second: 21,507.26791
Overall Steps per Second: 10,576.87388

Timestep Collection Time: 2.32498
Timestep Consumption Time: 2.40269
PPO Batch Consumption Time: 0.27829
Total Iteration Time: 4.72767

Cumulative Model Updates: 260,090
Cumulative Timesteps: 2,169,716,624

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 110,003.74193
Policy Entropy: 2.76132
Value Function Loss: 0.01138

Mean KL Divergence: 0.00705
SB3 Clip Fraction: 0.06577
Policy Update Magnitude: 0.31108
Value Function Update Magnitude: 0.29288

Collected Steps per Second: 21,715.01456
Overall Steps per Second: 10,464.87715

Timestep Collection Time: 2.30283
Timestep Consumption Time: 2.47563
PPO Batch Consumption Time: 0.28847
Total Iteration Time: 4.77846

Cumulative Model Updates: 260,096
Cumulative Timesteps: 2,169,766,630

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2169766630...
Checkpoint 2169766630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 79,641.84976
Policy Entropy: 2.75639
Value Function Loss: 0.01127

Mean KL Divergence: 0.00731
SB3 Clip Fraction: 0.06454
Policy Update Magnitude: 0.30026
Value Function Update Magnitude: 0.29418

Collected Steps per Second: 21,442.20879
Overall Steps per Second: 10,356.18831

Timestep Collection Time: 2.33371
Timestep Consumption Time: 2.49818
PPO Batch Consumption Time: 0.29186
Total Iteration Time: 4.83189

Cumulative Model Updates: 260,102
Cumulative Timesteps: 2,169,816,670

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 71,563.86925
Policy Entropy: 2.72522
Value Function Loss: 0.01109

Mean KL Divergence: 0.00758
SB3 Clip Fraction: 0.06887
Policy Update Magnitude: 0.29784
Value Function Update Magnitude: 0.29457

Collected Steps per Second: 22,017.65023
Overall Steps per Second: 10,459.70598

Timestep Collection Time: 2.27100
Timestep Consumption Time: 2.50944
PPO Batch Consumption Time: 0.29116
Total Iteration Time: 4.78044

Cumulative Model Updates: 260,108
Cumulative Timesteps: 2,169,866,672

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2169866672...
Checkpoint 2169866672 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 58,764.09914
Policy Entropy: 2.70900
Value Function Loss: 0.01096

Mean KL Divergence: 0.00701
SB3 Clip Fraction: 0.06481
Policy Update Magnitude: 0.29433
Value Function Update Magnitude: 0.26821

Collected Steps per Second: 22,125.93703
Overall Steps per Second: 10,523.79815

Timestep Collection Time: 2.26088
Timestep Consumption Time: 2.49254
PPO Batch Consumption Time: 0.28564
Total Iteration Time: 4.75342

Cumulative Model Updates: 260,114
Cumulative Timesteps: 2,169,916,696

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70,257.82104
Policy Entropy: 2.69061
Value Function Loss: 0.01059

Mean KL Divergence: 0.00715
SB3 Clip Fraction: 0.06500
Policy Update Magnitude: 0.29579
Value Function Update Magnitude: 0.24940

Collected Steps per Second: 22,267.81138
Overall Steps per Second: 10,562.83806

Timestep Collection Time: 2.24683
Timestep Consumption Time: 2.48978
PPO Batch Consumption Time: 0.29001
Total Iteration Time: 4.73661

Cumulative Model Updates: 260,120
Cumulative Timesteps: 2,169,966,728

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2169966728...
Checkpoint 2169966728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 92,381.72806
Policy Entropy: 2.70447
Value Function Loss: 0.01098

Mean KL Divergence: 0.00782
SB3 Clip Fraction: 0.07044
Policy Update Magnitude: 0.31653
Value Function Update Magnitude: 0.27359

Collected Steps per Second: 21,941.62588
Overall Steps per Second: 10,508.98526

Timestep Collection Time: 2.27877
Timestep Consumption Time: 2.47906
PPO Batch Consumption Time: 0.28817
Total Iteration Time: 4.75783

Cumulative Model Updates: 260,126
Cumulative Timesteps: 2,170,016,728

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88,464.34539
Policy Entropy: 2.69584
Value Function Loss: 0.01120

Mean KL Divergence: 0.00720
SB3 Clip Fraction: 0.06589
Policy Update Magnitude: 0.31528
Value Function Update Magnitude: 0.30016

Collected Steps per Second: 22,220.20461
Overall Steps per Second: 10,568.75333

Timestep Collection Time: 2.25128
Timestep Consumption Time: 2.48191
PPO Batch Consumption Time: 0.29171
Total Iteration Time: 4.73320

Cumulative Model Updates: 260,132
Cumulative Timesteps: 2,170,066,752

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2170066752...
Checkpoint 2170066752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 135,853.91571
Policy Entropy: 2.70844
Value Function Loss: 0.01046

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.06828
Policy Update Magnitude: 0.30493
Value Function Update Magnitude: 0.32838

Collected Steps per Second: 21,166.60582
Overall Steps per Second: 10,528.99329

Timestep Collection Time: 2.36316
Timestep Consumption Time: 2.38754
PPO Batch Consumption Time: 0.28527
Total Iteration Time: 4.75069

Cumulative Model Updates: 260,138
Cumulative Timesteps: 2,170,116,772

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 120,937.22196
Policy Entropy: 2.71109
Value Function Loss: 0.00989

Mean KL Divergence: 0.00637
SB3 Clip Fraction: 0.05462
Policy Update Magnitude: 0.29570
Value Function Update Magnitude: 0.33259

Collected Steps per Second: 21,710.57962
Overall Steps per Second: 10,603.67994

Timestep Collection Time: 2.30413
Timestep Consumption Time: 2.41348
PPO Batch Consumption Time: 0.29114
Total Iteration Time: 4.71761

Cumulative Model Updates: 260,144
Cumulative Timesteps: 2,170,166,796

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2170166796...
Checkpoint 2170166796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 141,557.74731
Policy Entropy: 2.71575
Value Function Loss: 0.00877

Mean KL Divergence: 0.00623
SB3 Clip Fraction: 0.05198
Policy Update Magnitude: 0.28842
Value Function Update Magnitude: 0.32725

Collected Steps per Second: 21,061.64784
Overall Steps per Second: 10,487.79615

Timestep Collection Time: 2.37512
Timestep Consumption Time: 2.39461
PPO Batch Consumption Time: 0.28557
Total Iteration Time: 4.76973

Cumulative Model Updates: 260,150
Cumulative Timesteps: 2,170,216,820

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 141,557.74731
Policy Entropy: 2.71948
Value Function Loss: 0.00824

Mean KL Divergence: 0.00607
SB3 Clip Fraction: 0.05435
Policy Update Magnitude: 0.28131
Value Function Update Magnitude: 0.28043

Collected Steps per Second: 21,165.43375
Overall Steps per Second: 10,469.41803

Timestep Collection Time: 2.36423
Timestep Consumption Time: 2.41540
PPO Batch Consumption Time: 0.27889
Total Iteration Time: 4.77964

Cumulative Model Updates: 260,156
Cumulative Timesteps: 2,170,266,860

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 2170266860...
Checkpoint 2170266860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 115,844.32561
Policy Entropy: 2.72658
Value Function Loss: 0.00870

Mean KL Divergence: 0.00555
SB3 Clip Fraction: 0.05011
Policy Update Magnitude: 0.28349
Value Function Update Magnitude: 0.26230

Collected Steps per Second: 21,066.76610
Overall Steps per Second: 10,322.86734

Timestep Collection Time: 2.37388
Timestep Consumption Time: 2.47070
PPO Batch Consumption Time: 0.29245
Total Iteration Time: 4.84458

Cumulative Model Updates: 260,162
Cumulative Timesteps: 2,170,316,870

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 118,627.39894
Policy Entropy: 2.75330
Value Function Loss: 0.00973

Mean KL Divergence: 0.00620
SB3 Clip Fraction: 0.05945
Policy Update Magnitude: 0.29360
Value Function Update Magnitude: 0.26905

Collected Steps per Second: 21,592.23263
Overall Steps per Second: 10,463.93816

Timestep Collection Time: 2.31593
Timestep Consumption Time: 2.46296
PPO Batch Consumption Time: 0.29045
Total Iteration Time: 4.77889

Cumulative Model Updates: 260,168
Cumulative Timesteps: 2,170,366,876

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2170366876...
Checkpoint 2170366876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 74,640.54408
Policy Entropy: 2.74623
Value Function Loss: 0.01074

Mean KL Divergence: 0.00646
SB3 Clip Fraction: 0.05918
Policy Update Magnitude: 0.28930
Value Function Update Magnitude: 0.29035

Collected Steps per Second: 21,731.25459
Overall Steps per Second: 10,550.49632

Timestep Collection Time: 2.30120
Timestep Consumption Time: 2.43867
PPO Batch Consumption Time: 0.27716
Total Iteration Time: 4.73987

Cumulative Model Updates: 260,174
Cumulative Timesteps: 2,170,416,884

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 73,708.29218
Policy Entropy: 2.73631
Value Function Loss: 0.01208

Mean KL Divergence: 0.00587
SB3 Clip Fraction: 0.05105
Policy Update Magnitude: 0.31120
Value Function Update Magnitude: 0.32510

Collected Steps per Second: 22,123.73134
Overall Steps per Second: 10,448.18891

Timestep Collection Time: 2.26056
Timestep Consumption Time: 2.52611
PPO Batch Consumption Time: 0.29349
Total Iteration Time: 4.78667

Cumulative Model Updates: 260,180
Cumulative Timesteps: 2,170,466,896

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2170466896...
Checkpoint 2170466896 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 73,708.29218
Policy Entropy: 2.74455
Value Function Loss: 0.01087

Mean KL Divergence: 0.00648
SB3 Clip Fraction: 0.05823
Policy Update Magnitude: 0.31035
Value Function Update Magnitude: 0.31475

Collected Steps per Second: 21,865.48859
Overall Steps per Second: 10,528.05067

Timestep Collection Time: 2.28689
Timestep Consumption Time: 2.46271
PPO Batch Consumption Time: 0.27869
Total Iteration Time: 4.74960

Cumulative Model Updates: 260,186
Cumulative Timesteps: 2,170,516,900

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 71,515.37973
Policy Entropy: 2.74067
Value Function Loss: 0.01208

Mean KL Divergence: 0.00651
SB3 Clip Fraction: 0.05598
Policy Update Magnitude: 0.30080
Value Function Update Magnitude: 0.28181

Collected Steps per Second: 22,350.75420
Overall Steps per Second: 10,540.71930

Timestep Collection Time: 2.23796
Timestep Consumption Time: 2.50745
PPO Batch Consumption Time: 0.29308
Total Iteration Time: 4.74541

Cumulative Model Updates: 260,192
Cumulative Timesteps: 2,170,566,920

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2170566920...
Checkpoint 2170566920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 75,149.14610
Policy Entropy: 2.73147
Value Function Loss: 0.01114

Mean KL Divergence: 0.00613
SB3 Clip Fraction: 0.05677
Policy Update Magnitude: 0.29448
Value Function Update Magnitude: 0.24563

Collected Steps per Second: 21,599.62345
Overall Steps per Second: 10,533.56583

Timestep Collection Time: 2.31597
Timestep Consumption Time: 2.43304
PPO Batch Consumption Time: 0.27883
Total Iteration Time: 4.74901

Cumulative Model Updates: 260,198
Cumulative Timesteps: 2,170,616,944

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 96,436.42476
Policy Entropy: 2.73068
Value Function Loss: 0.01189

Mean KL Divergence: 0.00684
SB3 Clip Fraction: 0.06371
Policy Update Magnitude: 0.29172
Value Function Update Magnitude: 0.20068

Collected Steps per Second: 22,500.56407
Overall Steps per Second: 10,591.90583

Timestep Collection Time: 2.22226
Timestep Consumption Time: 2.49852
PPO Batch Consumption Time: 0.29403
Total Iteration Time: 4.72077

Cumulative Model Updates: 260,204
Cumulative Timesteps: 2,170,666,946

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2170666946...
Checkpoint 2170666946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 80,437.83383
Policy Entropy: 2.71680
Value Function Loss: 0.01176

Mean KL Divergence: 0.00669
SB3 Clip Fraction: 0.06323
Policy Update Magnitude: 0.29460
Value Function Update Magnitude: 0.17358

Collected Steps per Second: 21,733.84943
Overall Steps per Second: 10,548.68785

Timestep Collection Time: 2.30111
Timestep Consumption Time: 2.43995
PPO Batch Consumption Time: 0.27957
Total Iteration Time: 4.74106

Cumulative Model Updates: 260,210
Cumulative Timesteps: 2,170,716,958

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61,455.54332
Policy Entropy: 2.74519
Value Function Loss: 0.01259

Mean KL Divergence: 0.00740
SB3 Clip Fraction: 0.06985
Policy Update Magnitude: 0.30094
Value Function Update Magnitude: 0.18063

Collected Steps per Second: 22,409.32409
Overall Steps per Second: 10,643.90813

Timestep Collection Time: 2.23157
Timestep Consumption Time: 2.46670
PPO Batch Consumption Time: 0.28958
Total Iteration Time: 4.69827

Cumulative Model Updates: 260,216
Cumulative Timesteps: 2,170,766,966

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2170766966...
Checkpoint 2170766966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 78,048.28729
Policy Entropy: 2.73582
Value Function Loss: 0.01195

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.08021
Policy Update Magnitude: 0.29511
Value Function Update Magnitude: 0.19482

Collected Steps per Second: 21,200.26528
Overall Steps per Second: 10,441.58655

Timestep Collection Time: 2.35931
Timestep Consumption Time: 2.43096
PPO Batch Consumption Time: 0.27812
Total Iteration Time: 4.79027

Cumulative Model Updates: 260,222
Cumulative Timesteps: 2,170,816,984

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56,581.27590
Policy Entropy: 2.73981
Value Function Loss: 0.01213

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.07594
Policy Update Magnitude: 0.30061
Value Function Update Magnitude: 0.25770

Collected Steps per Second: 21,114.58029
Overall Steps per Second: 10,489.61948

Timestep Collection Time: 2.36841
Timestep Consumption Time: 2.39897
PPO Batch Consumption Time: 0.28593
Total Iteration Time: 4.76738

Cumulative Model Updates: 260,228
Cumulative Timesteps: 2,170,866,992

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2170866992...
Checkpoint 2170866992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 57,663.82175
Policy Entropy: 2.72909
Value Function Loss: 0.01063

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.06862
Policy Update Magnitude: 0.30896
Value Function Update Magnitude: 0.28350

Collected Steps per Second: 20,709.26329
Overall Steps per Second: 10,373.37322

Timestep Collection Time: 2.41592
Timestep Consumption Time: 2.40719
PPO Batch Consumption Time: 0.29006
Total Iteration Time: 4.82312

Cumulative Model Updates: 260,234
Cumulative Timesteps: 2,170,917,024

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57,663.82175
Policy Entropy: 2.71964
Value Function Loss: 0.00899

Mean KL Divergence: 0.00631
SB3 Clip Fraction: 0.05745
Policy Update Magnitude: 0.29530
Value Function Update Magnitude: 0.25488

Collected Steps per Second: 21,402.60737
Overall Steps per Second: 10,661.44449

Timestep Collection Time: 2.33644
Timestep Consumption Time: 2.35391
PPO Batch Consumption Time: 0.27809
Total Iteration Time: 4.69036

Cumulative Model Updates: 260,240
Cumulative Timesteps: 2,170,967,030

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2170967030...
Checkpoint 2170967030 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 59,882.32259
Policy Entropy: 2.73467
Value Function Loss: 0.00803

Mean KL Divergence: 0.00577
SB3 Clip Fraction: 0.05478
Policy Update Magnitude: 0.28054
Value Function Update Magnitude: 0.23521

Collected Steps per Second: 20,687.18623
Overall Steps per Second: 10,211.06447

Timestep Collection Time: 2.41734
Timestep Consumption Time: 2.48009
PPO Batch Consumption Time: 0.28766
Total Iteration Time: 4.89743

Cumulative Model Updates: 260,246
Cumulative Timesteps: 2,171,017,038

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55,236.82540
Policy Entropy: 2.72544
Value Function Loss: 0.00991

Mean KL Divergence: 0.00562
SB3 Clip Fraction: 0.05342
Policy Update Magnitude: 0.28287
Value Function Update Magnitude: 0.24020

Collected Steps per Second: 21,811.63606
Overall Steps per Second: 10,489.04579

Timestep Collection Time: 2.29400
Timestep Consumption Time: 2.47631
PPO Batch Consumption Time: 0.28559
Total Iteration Time: 4.77031

Cumulative Model Updates: 260,252
Cumulative Timesteps: 2,171,067,074

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 2171067074...
Checkpoint 2171067074 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 123,876.18995
Policy Entropy: 2.73324
Value Function Loss: 0.01084

Mean KL Divergence: 0.00601
SB3 Clip Fraction: 0.05645
Policy Update Magnitude: 0.28538
Value Function Update Magnitude: 0.25842

Collected Steps per Second: 21,586.53619
Overall Steps per Second: 10,558.70792

Timestep Collection Time: 2.31737
Timestep Consumption Time: 2.42033
PPO Batch Consumption Time: 0.27781
Total Iteration Time: 4.73770

Cumulative Model Updates: 260,258
Cumulative Timesteps: 2,171,117,098

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 117,840.63899
Policy Entropy: 2.74341
Value Function Loss: 0.01160

Mean KL Divergence: 0.00585
SB3 Clip Fraction: 0.05614
Policy Update Magnitude: 0.28307
Value Function Update Magnitude: 0.27690

Collected Steps per Second: 21,337.89752
Overall Steps per Second: 10,257.10196

Timestep Collection Time: 2.34428
Timestep Consumption Time: 2.53254
PPO Batch Consumption Time: 0.29042
Total Iteration Time: 4.87682

Cumulative Model Updates: 260,264
Cumulative Timesteps: 2,171,167,120

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2171167120...
Checkpoint 2171167120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 117,840.63899
Policy Entropy: 2.74551
Value Function Loss: 0.00950

Mean KL Divergence: 0.00560
SB3 Clip Fraction: 0.05550
Policy Update Magnitude: 0.27983
Value Function Update Magnitude: 0.25774

Collected Steps per Second: 22,137.61540
Overall Steps per Second: 10,465.90150

Timestep Collection Time: 2.25905
Timestep Consumption Time: 2.51932
PPO Batch Consumption Time: 0.29386
Total Iteration Time: 4.77837

Cumulative Model Updates: 260,270
Cumulative Timesteps: 2,171,217,130

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 125,332.49537
Policy Entropy: 2.75266
Value Function Loss: 0.00929

Mean KL Divergence: 0.00619
SB3 Clip Fraction: 0.05985
Policy Update Magnitude: 0.27780
Value Function Update Magnitude: 0.25641

Collected Steps per Second: 22,040.19308
Overall Steps per Second: 10,445.94648

Timestep Collection Time: 2.26949
Timestep Consumption Time: 2.51897
PPO Batch Consumption Time: 0.29182
Total Iteration Time: 4.78846

Cumulative Model Updates: 260,276
Cumulative Timesteps: 2,171,267,150

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2171267150...
Checkpoint 2171267150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 104,511.23259
Policy Entropy: 2.74007
Value Function Loss: 0.00948

Mean KL Divergence: 0.00554
SB3 Clip Fraction: 0.05239
Policy Update Magnitude: 0.28932
Value Function Update Magnitude: 0.27955

Collected Steps per Second: 21,985.14726
Overall Steps per Second: 10,629.47118

Timestep Collection Time: 2.27545
Timestep Consumption Time: 2.43090
PPO Batch Consumption Time: 0.27867
Total Iteration Time: 4.70635

Cumulative Model Updates: 260,282
Cumulative Timesteps: 2,171,317,176

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 112,914.30177
Policy Entropy: 2.77013
Value Function Loss: 0.00990

Mean KL Divergence: 0.00506
SB3 Clip Fraction: 0.04708
Policy Update Magnitude: 0.29122
Value Function Update Magnitude: 0.28118

Collected Steps per Second: 21,847.84527
Overall Steps per Second: 10,452.87203

Timestep Collection Time: 2.28920
Timestep Consumption Time: 2.49552
PPO Batch Consumption Time: 0.28849
Total Iteration Time: 4.78471

Cumulative Model Updates: 260,288
Cumulative Timesteps: 2,171,367,190

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2171367190...
Checkpoint 2171367190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 112,914.30177
Policy Entropy: 2.73542
Value Function Loss: 0.00963

Mean KL Divergence: 0.00549
SB3 Clip Fraction: 0.04996
Policy Update Magnitude: 0.28488
Value Function Update Magnitude: 0.25757

Collected Steps per Second: 21,333.50800
Overall Steps per Second: 10,326.75527

Timestep Collection Time: 2.34504
Timestep Consumption Time: 2.49946
PPO Batch Consumption Time: 0.29242
Total Iteration Time: 4.84450

Cumulative Model Updates: 260,294
Cumulative Timesteps: 2,171,417,218

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 123,149.58195
Policy Entropy: 2.71030
Value Function Loss: 0.01194

Mean KL Divergence: 0.00613
SB3 Clip Fraction: 0.05906
Policy Update Magnitude: 0.30685
Value Function Update Magnitude: 0.25135

Collected Steps per Second: 21,816.68375
Overall Steps per Second: 10,420.59616

Timestep Collection Time: 2.29192
Timestep Consumption Time: 2.50647
PPO Batch Consumption Time: 0.29289
Total Iteration Time: 4.79838

Cumulative Model Updates: 260,300
Cumulative Timesteps: 2,171,467,220

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2171467220...
Checkpoint 2171467220 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 110,699.63032
Policy Entropy: 2.70298
Value Function Loss: 0.01171

Mean KL Divergence: 0.00672
SB3 Clip Fraction: 0.06449
Policy Update Magnitude: 0.31830
Value Function Update Magnitude: 0.27622

Collected Steps per Second: 21,449.35354
Overall Steps per Second: 10,518.44645

Timestep Collection Time: 2.33219
Timestep Consumption Time: 2.42364
PPO Batch Consumption Time: 0.27873
Total Iteration Time: 4.75584

Cumulative Model Updates: 260,306
Cumulative Timesteps: 2,171,517,244

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 161,485.94312
Policy Entropy: 2.70742
Value Function Loss: 0.01138

Mean KL Divergence: 0.00728
SB3 Clip Fraction: 0.06454
Policy Update Magnitude: 0.31112
Value Function Update Magnitude: 0.29975

Collected Steps per Second: 21,313.75908
Overall Steps per Second: 10,517.19987

Timestep Collection Time: 2.34703
Timestep Consumption Time: 2.40937
PPO Batch Consumption Time: 0.28678
Total Iteration Time: 4.75640

Cumulative Model Updates: 260,312
Cumulative Timesteps: 2,171,567,268

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2171567268...
Checkpoint 2171567268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 166,160.21860
Policy Entropy: 2.71455
Value Function Loss: 0.01238

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.06985
Policy Update Magnitude: 0.32094
Value Function Update Magnitude: 0.30532

Collected Steps per Second: 21,289.26117
Overall Steps per Second: 10,572.06270

Timestep Collection Time: 2.34917
Timestep Consumption Time: 2.38142
PPO Batch Consumption Time: 0.27805
Total Iteration Time: 4.73058

Cumulative Model Updates: 260,318
Cumulative Timesteps: 2,171,617,280

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 157,983.44865
Policy Entropy: 2.73468
Value Function Loss: 0.01191

Mean KL Divergence: 0.00772
SB3 Clip Fraction: 0.07075
Policy Update Magnitude: 0.31476
Value Function Update Magnitude: 0.31205

Collected Steps per Second: 21,524.44468
Overall Steps per Second: 10,479.47241

Timestep Collection Time: 2.32452
Timestep Consumption Time: 2.44996
PPO Batch Consumption Time: 0.29242
Total Iteration Time: 4.77448

Cumulative Model Updates: 260,324
Cumulative Timesteps: 2,171,667,314

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 2171667314...
Checkpoint 2171667314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 130,770.78461
Policy Entropy: 2.75138
Value Function Loss: 0.01121

Mean KL Divergence: 0.00782
SB3 Clip Fraction: 0.07016
Policy Update Magnitude: 0.29914
Value Function Update Magnitude: 0.28985

Collected Steps per Second: 21,060.25955
Overall Steps per Second: 10,302.35437

Timestep Collection Time: 2.37547
Timestep Consumption Time: 2.48051
PPO Batch Consumption Time: 0.29372
Total Iteration Time: 4.85598

Cumulative Model Updates: 260,330
Cumulative Timesteps: 2,171,717,342

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 130,770.78461
Policy Entropy: 2.75919
Value Function Loss: 0.00997

Mean KL Divergence: 0.00567
SB3 Clip Fraction: 0.05575
Policy Update Magnitude: 0.29281
Value Function Update Magnitude: 0.28009

Collected Steps per Second: 21,827.19041
Overall Steps per Second: 10,485.89029

Timestep Collection Time: 2.29090
Timestep Consumption Time: 2.47779
PPO Batch Consumption Time: 0.29322
Total Iteration Time: 4.76869

Cumulative Model Updates: 260,336
Cumulative Timesteps: 2,171,767,346

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2171767346...
Checkpoint 2171767346 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 132,022.25754
Policy Entropy: 2.73419
Value Function Loss: 0.01215

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.07246
Policy Update Magnitude: 0.30882
Value Function Update Magnitude: 0.31425

Collected Steps per Second: 22,076.80504
Overall Steps per Second: 10,535.33420

Timestep Collection Time: 2.26573
Timestep Consumption Time: 2.48211
PPO Batch Consumption Time: 0.29211
Total Iteration Time: 4.74783

Cumulative Model Updates: 260,342
Cumulative Timesteps: 2,171,817,366

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 112,337.16645
Policy Entropy: 2.72895
Value Function Loss: 0.01182

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.08061
Policy Update Magnitude: 0.30986
Value Function Update Magnitude: 0.34758

Collected Steps per Second: 22,221.00480
Overall Steps per Second: 10,534.59998

Timestep Collection Time: 2.25066
Timestep Consumption Time: 2.49674
PPO Batch Consumption Time: 0.29263
Total Iteration Time: 4.74740

Cumulative Model Updates: 260,348
Cumulative Timesteps: 2,171,867,378

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2171867378...
Checkpoint 2171867378 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 96,130.33344
Policy Entropy: 2.75102
Value Function Loss: 0.01293

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.07537
Policy Update Magnitude: 0.31008
Value Function Update Magnitude: 0.35069

Collected Steps per Second: 22,169.03486
Overall Steps per Second: 10,550.52968

Timestep Collection Time: 2.25630
Timestep Consumption Time: 2.48469
PPO Batch Consumption Time: 0.28786
Total Iteration Time: 4.74099

Cumulative Model Updates: 260,354
Cumulative Timesteps: 2,171,917,398

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 162,686.54956
Policy Entropy: 2.74775
Value Function Loss: 0.01347

Mean KL Divergence: 0.00684
SB3 Clip Fraction: 0.06532
Policy Update Magnitude: 0.32738
Value Function Update Magnitude: 0.35525

Collected Steps per Second: 21,656.45466
Overall Steps per Second: 10,433.81872

Timestep Collection Time: 2.30952
Timestep Consumption Time: 2.48412
PPO Batch Consumption Time: 0.28734
Total Iteration Time: 4.79364

Cumulative Model Updates: 260,360
Cumulative Timesteps: 2,171,967,414

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2171967414...
Checkpoint 2171967414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 94,040.45334
Policy Entropy: 2.71795
Value Function Loss: 0.01513

Mean KL Divergence: 0.00728
SB3 Clip Fraction: 0.06873
Policy Update Magnitude: 0.34352
Value Function Update Magnitude: 0.35847

Collected Steps per Second: 21,332.31856
Overall Steps per Second: 10,319.29690

Timestep Collection Time: 2.34508
Timestep Consumption Time: 2.50273
PPO Batch Consumption Time: 0.29337
Total Iteration Time: 4.84781

Cumulative Model Updates: 260,366
Cumulative Timesteps: 2,172,017,440

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 152,114.25889
Policy Entropy: 2.69635
Value Function Loss: 0.01393

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.07858
Policy Update Magnitude: 0.35148
Value Function Update Magnitude: 0.35546

Collected Steps per Second: 21,559.64137
Overall Steps per Second: 10,367.43771

Timestep Collection Time: 2.31980
Timestep Consumption Time: 2.50435
PPO Batch Consumption Time: 0.29043
Total Iteration Time: 4.82414

Cumulative Model Updates: 260,372
Cumulative Timesteps: 2,172,067,454

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2172067454...
Checkpoint 2172067454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 88,712.67569
Policy Entropy: 2.68542
Value Function Loss: 0.01443

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.07157
Policy Update Magnitude: 0.34327
Value Function Update Magnitude: 0.35610

Collected Steps per Second: 21,719.77315
Overall Steps per Second: 10,572.62941

Timestep Collection Time: 2.30269
Timestep Consumption Time: 2.42782
PPO Batch Consumption Time: 0.27826
Total Iteration Time: 4.73052

Cumulative Model Updates: 260,378
Cumulative Timesteps: 2,172,117,468

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 116,793.91796
Policy Entropy: 2.71284
Value Function Loss: 0.01187

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.07281
Policy Update Magnitude: 0.33253
Value Function Update Magnitude: 0.36064

Collected Steps per Second: 22,076.58830
Overall Steps per Second: 10,513.40010

Timestep Collection Time: 2.26493
Timestep Consumption Time: 2.49109
PPO Batch Consumption Time: 0.28465
Total Iteration Time: 4.75603

Cumulative Model Updates: 260,384
Cumulative Timesteps: 2,172,167,470

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2172167470...
Checkpoint 2172167470 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 75,101.89631
Policy Entropy: 2.72574
Value Function Loss: 0.01138

Mean KL Divergence: 0.00712
SB3 Clip Fraction: 0.06683
Policy Update Magnitude: 0.31460
Value Function Update Magnitude: 0.32159

Collected Steps per Second: 22,265.29991
Overall Steps per Second: 10,686.24106

Timestep Collection Time: 2.24592
Timestep Consumption Time: 2.43356
PPO Batch Consumption Time: 0.27778
Total Iteration Time: 4.67948

Cumulative Model Updates: 260,390
Cumulative Timesteps: 2,172,217,476

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 121,426.07264
Policy Entropy: 2.74337
Value Function Loss: 0.01191

Mean KL Divergence: 0.00729
SB3 Clip Fraction: 0.06865
Policy Update Magnitude: 0.31249
Value Function Update Magnitude: 0.28751

Collected Steps per Second: 22,260.03454
Overall Steps per Second: 10,561.65314

Timestep Collection Time: 2.24636
Timestep Consumption Time: 2.48813
PPO Batch Consumption Time: 0.29085
Total Iteration Time: 4.73449

Cumulative Model Updates: 260,396
Cumulative Timesteps: 2,172,267,480

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2172267480...
Checkpoint 2172267480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 135,805.97594
Policy Entropy: 2.73605
Value Function Loss: 0.01209

Mean KL Divergence: 0.00756
SB3 Clip Fraction: 0.06975
Policy Update Magnitude: 0.30912
Value Function Update Magnitude: 0.29080

Collected Steps per Second: 22,144.90164
Overall Steps per Second: 10,476.97630

Timestep Collection Time: 2.25948
Timestep Consumption Time: 2.51632
PPO Batch Consumption Time: 0.29392
Total Iteration Time: 4.77581

Cumulative Model Updates: 260,402
Cumulative Timesteps: 2,172,317,516

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 117,020.79768
Policy Entropy: 2.74740
Value Function Loss: 0.01135

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.08335
Policy Update Magnitude: 0.29792
Value Function Update Magnitude: 0.27520

Collected Steps per Second: 22,068.46759
Overall Steps per Second: 10,458.80012

Timestep Collection Time: 2.26595
Timestep Consumption Time: 2.51529
PPO Batch Consumption Time: 0.29382
Total Iteration Time: 4.78124

Cumulative Model Updates: 260,408
Cumulative Timesteps: 2,172,367,522

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2172367522...
Checkpoint 2172367522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 106,244.65481
Policy Entropy: 2.73946
Value Function Loss: 0.01110

Mean KL Divergence: 0.00706
SB3 Clip Fraction: 0.06675
Policy Update Magnitude: 0.29844
Value Function Update Magnitude: 0.27211

Collected Steps per Second: 21,911.08177
Overall Steps per Second: 10,617.69577

Timestep Collection Time: 2.28368
Timestep Consumption Time: 2.42901
PPO Batch Consumption Time: 0.27874
Total Iteration Time: 4.71270

Cumulative Model Updates: 260,414
Cumulative Timesteps: 2,172,417,560

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93,078.71763
Policy Entropy: 2.71447
Value Function Loss: 0.01291

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.08324
Policy Update Magnitude: 0.32674
Value Function Update Magnitude: 0.31110

Collected Steps per Second: 21,573.48699
Overall Steps per Second: 10,569.16094

Timestep Collection Time: 2.31859
Timestep Consumption Time: 2.41405
PPO Batch Consumption Time: 0.27670
Total Iteration Time: 4.73264

Cumulative Model Updates: 260,420
Cumulative Timesteps: 2,172,467,580

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2172467580...
Checkpoint 2172467580 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 66,889.84369
Policy Entropy: 2.68991
Value Function Loss: 0.01357

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.07188
Policy Update Magnitude: 0.33135
Value Function Update Magnitude: 0.30268

Collected Steps per Second: 21,701.62205
Overall Steps per Second: 10,546.82255

Timestep Collection Time: 2.30453
Timestep Consumption Time: 2.43737
PPO Batch Consumption Time: 0.27863
Total Iteration Time: 4.74190

Cumulative Model Updates: 260,426
Cumulative Timesteps: 2,172,517,592

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76,142.48561
Policy Entropy: 2.68594
Value Function Loss: 0.01412

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.08429
Policy Update Magnitude: 0.34321
Value Function Update Magnitude: 0.33047

Collected Steps per Second: 21,958.20313
Overall Steps per Second: 10,410.01925

Timestep Collection Time: 2.27833
Timestep Consumption Time: 2.52743
PPO Batch Consumption Time: 0.29252
Total Iteration Time: 4.80575

Cumulative Model Updates: 260,432
Cumulative Timesteps: 2,172,567,620

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2172567620...
Checkpoint 2172567620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 59,043.18058
Policy Entropy: 2.70791
Value Function Loss: 0.01235

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.07990
Policy Update Magnitude: 0.33515
Value Function Update Magnitude: 0.37303

Collected Steps per Second: 21,573.06930
Overall Steps per Second: 10,330.04773

Timestep Collection Time: 2.31872
Timestep Consumption Time: 2.52365
PPO Batch Consumption Time: 0.29329
Total Iteration Time: 4.84238

Cumulative Model Updates: 260,438
Cumulative Timesteps: 2,172,617,642

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61,330.92776
Policy Entropy: 2.71969
Value Function Loss: 0.01066

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.07244
Policy Update Magnitude: 0.31747
Value Function Update Magnitude: 0.33662

Collected Steps per Second: 22,128.76097
Overall Steps per Second: 10,454.60214

Timestep Collection Time: 2.26050
Timestep Consumption Time: 2.52419
PPO Batch Consumption Time: 0.29262
Total Iteration Time: 4.78469

Cumulative Model Updates: 260,444
Cumulative Timesteps: 2,172,667,664

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2172667664...
Checkpoint 2172667664 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 65,578.19768
Policy Entropy: 2.72165
Value Function Loss: 0.01103

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.07018
Policy Update Magnitude: 0.30397
Value Function Update Magnitude: 0.28173

Collected Steps per Second: 21,985.84655
Overall Steps per Second: 10,616.50336

Timestep Collection Time: 2.27601
Timestep Consumption Time: 2.43741
PPO Batch Consumption Time: 0.27755
Total Iteration Time: 4.71342

Cumulative Model Updates: 260,450
Cumulative Timesteps: 2,172,717,704

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 104,518.42390
Policy Entropy: 2.71240
Value Function Loss: 0.01228

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.07931
Policy Update Magnitude: 0.30862
Value Function Update Magnitude: 0.26247

Collected Steps per Second: 22,273.36464
Overall Steps per Second: 10,559.70557

Timestep Collection Time: 2.24510
Timestep Consumption Time: 2.49045
PPO Batch Consumption Time: 0.29097
Total Iteration Time: 4.73555

Cumulative Model Updates: 260,456
Cumulative Timesteps: 2,172,767,710

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2172767710...
Checkpoint 2172767710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 99,204.53231
Policy Entropy: 2.70538
Value Function Loss: 0.01363

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.08010
Policy Update Magnitude: 0.31317
Value Function Update Magnitude: 0.28308

Collected Steps per Second: 21,969.84728
Overall Steps per Second: 10,470.84680

Timestep Collection Time: 2.27612
Timestep Consumption Time: 2.49962
PPO Batch Consumption Time: 0.29319
Total Iteration Time: 4.77574

Cumulative Model Updates: 260,462
Cumulative Timesteps: 2,172,817,716

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 72,096.71125
Policy Entropy: 2.69928
Value Function Loss: 0.01234

Mean KL Divergence: 0.00713
SB3 Clip Fraction: 0.06797
Policy Update Magnitude: 0.31457
Value Function Update Magnitude: 0.29182

Collected Steps per Second: 22,276.71125
Overall Steps per Second: 10,525.80930

Timestep Collection Time: 2.24486
Timestep Consumption Time: 2.50613
PPO Batch Consumption Time: 0.29395
Total Iteration Time: 4.75099

Cumulative Model Updates: 260,468
Cumulative Timesteps: 2,172,867,724

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2172867724...
Checkpoint 2172867724 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 72,096.71125
Policy Entropy: 2.72725
Value Function Loss: 0.01036

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.07226
Policy Update Magnitude: 0.30193
Value Function Update Magnitude: 0.29212

Collected Steps per Second: 22,009.81903
Overall Steps per Second: 10,574.75811

Timestep Collection Time: 2.27190
Timestep Consumption Time: 2.45672
PPO Batch Consumption Time: 0.28426
Total Iteration Time: 4.72862

Cumulative Model Updates: 260,474
Cumulative Timesteps: 2,172,917,728

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 131,790.96679
Policy Entropy: 2.71663
Value Function Loss: 0.01001

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.07536
Policy Update Magnitude: 0.29504
Value Function Update Magnitude: 0.26115

Collected Steps per Second: 21,178.85677
Overall Steps per Second: 10,442.92674

Timestep Collection Time: 2.36311
Timestep Consumption Time: 2.42941
PPO Batch Consumption Time: 0.29024
Total Iteration Time: 4.79253

Cumulative Model Updates: 260,480
Cumulative Timesteps: 2,172,967,776

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 2172967776...
Checkpoint 2172967776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 100,464.16158
Policy Entropy: 2.72591
Value Function Loss: 0.01119

Mean KL Divergence: 0.01396
SB3 Clip Fraction: 0.10806
Policy Update Magnitude: 0.30655
Value Function Update Magnitude: 0.28773

Collected Steps per Second: 20,886.39837
Overall Steps per Second: 10,564.69409

Timestep Collection Time: 2.39486
Timestep Consumption Time: 2.33978
PPO Batch Consumption Time: 0.27819
Total Iteration Time: 4.73464

Cumulative Model Updates: 260,486
Cumulative Timesteps: 2,173,017,796

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 94,860.04193
Policy Entropy: 2.70805
Value Function Loss: 0.01288

Mean KL Divergence: 0.01549
SB3 Clip Fraction: 0.11972
Policy Update Magnitude: 0.33197
Value Function Update Magnitude: 0.34067

Collected Steps per Second: 20,026.39253
Overall Steps per Second: 10,155.66113

Timestep Collection Time: 2.49790
Timestep Consumption Time: 2.42782
PPO Batch Consumption Time: 0.29284
Total Iteration Time: 4.92573

Cumulative Model Updates: 260,492
Cumulative Timesteps: 2,173,067,820

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2173067820...
Checkpoint 2173067820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 137,134.60007
Policy Entropy: 2.72209
Value Function Loss: 0.01315

Mean KL Divergence: 0.01211
SB3 Clip Fraction: 0.10271
Policy Update Magnitude: 0.33557
Value Function Update Magnitude: 0.33519

Collected Steps per Second: 20,922.92803
Overall Steps per Second: 10,296.62487

Timestep Collection Time: 2.39135
Timestep Consumption Time: 2.46791
PPO Batch Consumption Time: 0.29107
Total Iteration Time: 4.85926

Cumulative Model Updates: 260,498
Cumulative Timesteps: 2,173,117,854

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80,011.08197
Policy Entropy: 2.70422
Value Function Loss: 0.01425

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.08272
Policy Update Magnitude: 0.34326
Value Function Update Magnitude: 0.32815

Collected Steps per Second: 21,814.30738
Overall Steps per Second: 10,538.61964

Timestep Collection Time: 2.29363
Timestep Consumption Time: 2.45405
PPO Batch Consumption Time: 0.28846
Total Iteration Time: 4.74768

Cumulative Model Updates: 260,504
Cumulative Timesteps: 2,173,167,888

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 2173167888...
Checkpoint 2173167888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 83,040.27582
Policy Entropy: 2.70543
Value Function Loss: 0.01455

Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.07715
Policy Update Magnitude: 0.34999
Value Function Update Magnitude: 0.32275

Collected Steps per Second: 21,387.51961
Overall Steps per Second: 10,412.16520

Timestep Collection Time: 2.33931
Timestep Consumption Time: 2.46584
PPO Batch Consumption Time: 0.28748
Total Iteration Time: 4.80515

Cumulative Model Updates: 260,510
Cumulative Timesteps: 2,173,217,920

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 69,119.51798
Policy Entropy: 2.69776
Value Function Loss: 0.01464

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.07747
Policy Update Magnitude: 0.34672
Value Function Update Magnitude: 0.35294

Collected Steps per Second: 22,008.08624
Overall Steps per Second: 10,476.71681

Timestep Collection Time: 2.27198
Timestep Consumption Time: 2.50070
PPO Batch Consumption Time: 0.29096
Total Iteration Time: 4.77268

Cumulative Model Updates: 260,516
Cumulative Timesteps: 2,173,267,922

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2173267922...
Checkpoint 2173267922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 70,397.44721
Policy Entropy: 2.72256
Value Function Loss: 0.01270

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.07762
Policy Update Magnitude: 0.32447
Value Function Update Magnitude: 0.33649

Collected Steps per Second: 21,854.26572
Overall Steps per Second: 10,545.62042

Timestep Collection Time: 2.28871
Timestep Consumption Time: 2.45431
PPO Batch Consumption Time: 0.27826
Total Iteration Time: 4.74301

Cumulative Model Updates: 260,522
Cumulative Timesteps: 2,173,317,940

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77,655.69570
Policy Entropy: 2.74664
Value Function Loss: 0.01090

Mean KL Divergence: 0.00686
SB3 Clip Fraction: 0.06433
Policy Update Magnitude: 0.30427
Value Function Update Magnitude: 0.29872

Collected Steps per Second: 22,141.40929
Overall Steps per Second: 10,499.87539

Timestep Collection Time: 2.26020
Timestep Consumption Time: 2.50595
PPO Batch Consumption Time: 0.28897
Total Iteration Time: 4.76615

Cumulative Model Updates: 260,528
Cumulative Timesteps: 2,173,367,984

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 2173367984...
Checkpoint 2173367984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 73,507.09314
Policy Entropy: 2.75860
Value Function Loss: 0.01113

Mean KL Divergence: 0.00713
SB3 Clip Fraction: 0.06751
Policy Update Magnitude: 0.29851
Value Function Update Magnitude: 0.25183

Collected Steps per Second: 21,793.51065
Overall Steps per Second: 10,591.35100

Timestep Collection Time: 2.29435
Timestep Consumption Time: 2.42667
PPO Batch Consumption Time: 0.27878
Total Iteration Time: 4.72102

Cumulative Model Updates: 260,534
Cumulative Timesteps: 2,173,417,986

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65,425.61125
Policy Entropy: 2.75210
Value Function Loss: 0.01311

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.07397
Policy Update Magnitude: 0.30431
Value Function Update Magnitude: 0.24028

Collected Steps per Second: 22,193.74512
Overall Steps per Second: 10,564.43644

Timestep Collection Time: 2.25460
Timestep Consumption Time: 2.48186
PPO Batch Consumption Time: 0.28768
Total Iteration Time: 4.73646

Cumulative Model Updates: 260,540
Cumulative Timesteps: 2,173,468,024

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 2173468024...
Checkpoint 2173468024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 69,834.96142
Policy Entropy: 2.73462
Value Function Loss: 0.01470

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.08767
Policy Update Magnitude: 0.31996
Value Function Update Magnitude: 0.28585

Collected Steps per Second: 21,992.93231
Overall Steps per Second: 10,612.00469

Timestep Collection Time: 2.27455
Timestep Consumption Time: 2.43936
PPO Batch Consumption Time: 0.27875
Total Iteration Time: 4.71391

Cumulative Model Updates: 260,546
Cumulative Timesteps: 2,173,518,048

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81,273.66237
Policy Entropy: 2.73285
Value Function Loss: 0.01400

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.07473
Policy Update Magnitude: 0.32570
Value Function Update Magnitude: 0.29466

Collected Steps per Second: 21,719.06028
Overall Steps per Second: 10,470.57665

Timestep Collection Time: 2.30387
Timestep Consumption Time: 2.47504
PPO Batch Consumption Time: 0.28472
Total Iteration Time: 4.77892

Cumulative Model Updates: 260,552
Cumulative Timesteps: 2,173,568,086

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 2173568086...
Checkpoint 2173568086 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87,343.21130
Policy Entropy: 2.72089
Value Function Loss: 0.01393

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.07477
Policy Update Magnitude: 0.32246
Value Function Update Magnitude: 0.29320

Collected Steps per Second: 21,306.18180
Overall Steps per Second: 10,314.79505

Timestep Collection Time: 2.34814
Timestep Consumption Time: 2.50217
PPO Batch Consumption Time: 0.29133
Total Iteration Time: 4.85031

Cumulative Model Updates: 260,558
Cumulative Timesteps: 2,173,618,116

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 96,559.83869
Policy Entropy: 2.70374
Value Function Loss: 0.01179

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.07788
Policy Update Magnitude: 0.31852
Value Function Update Magnitude: 0.30147

Collected Steps per Second: 22,054.54874
Overall Steps per Second: 10,525.02301

Timestep Collection Time: 2.26774
Timestep Consumption Time: 2.48417
PPO Batch Consumption Time: 0.28923
Total Iteration Time: 4.75191

Cumulative Model Updates: 260,564
Cumulative Timesteps: 2,173,668,130

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2173668130...
Checkpoint 2173668130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 88,913.44297
Policy Entropy: 2.70658
Value Function Loss: 0.01171

Mean KL Divergence: 0.00737
SB3 Clip Fraction: 0.07026
Policy Update Magnitude: 0.31974
Value Function Update Magnitude: 0.28543

Collected Steps per Second: 21,733.39503
Overall Steps per Second: 10,456.76313

Timestep Collection Time: 2.30263
Timestep Consumption Time: 2.48317
PPO Batch Consumption Time: 0.28788
Total Iteration Time: 4.78580

Cumulative Model Updates: 260,570
Cumulative Timesteps: 2,173,718,174

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70,499.83102
Policy Entropy: 2.71063
Value Function Loss: 0.01393

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.07543
Policy Update Magnitude: 0.32243
Value Function Update Magnitude: 0.30846

Collected Steps per Second: 22,390.64835
Overall Steps per Second: 10,528.57018

Timestep Collection Time: 2.23334
Timestep Consumption Time: 2.51621
PPO Batch Consumption Time: 0.29160
Total Iteration Time: 4.74955

Cumulative Model Updates: 260,576
Cumulative Timesteps: 2,173,768,180

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2173768180...
Checkpoint 2173768180 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 64,194.39785
Policy Entropy: 2.72564
Value Function Loss: 0.01462

Mean KL Divergence: 0.00726
SB3 Clip Fraction: 0.06751
Policy Update Magnitude: 0.34195
Value Function Update Magnitude: 0.39472

Collected Steps per Second: 21,211.17532
Overall Steps per Second: 10,434.51407

Timestep Collection Time: 2.35885
Timestep Consumption Time: 2.43620
PPO Batch Consumption Time: 0.28910
Total Iteration Time: 4.79505

Cumulative Model Updates: 260,582
Cumulative Timesteps: 2,173,818,214

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 94,814.79862
Policy Entropy: 2.73627
Value Function Loss: 0.01379

Mean KL Divergence: 0.00766
SB3 Clip Fraction: 0.06745
Policy Update Magnitude: 0.33426
Value Function Update Magnitude: 0.41594

Collected Steps per Second: 21,592.29371
Overall Steps per Second: 10,559.89532

Timestep Collection Time: 2.31610
Timestep Consumption Time: 2.41974
PPO Batch Consumption Time: 0.28852
Total Iteration Time: 4.73584

Cumulative Model Updates: 260,588
Cumulative Timesteps: 2,173,868,224

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2173868224...
Checkpoint 2173868224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 94,814.79862
Policy Entropy: 2.75428
Value Function Loss: 0.01080

Mean KL Divergence: 0.00691
SB3 Clip Fraction: 0.06157
Policy Update Magnitude: 0.30810
Value Function Update Magnitude: 0.35628

Collected Steps per Second: 21,477.29390
Overall Steps per Second: 10,714.88894

Timestep Collection Time: 2.32962
Timestep Consumption Time: 2.33995
PPO Batch Consumption Time: 0.27725
Total Iteration Time: 4.66958

Cumulative Model Updates: 260,594
Cumulative Timesteps: 2,173,918,258

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86,224.31986
Policy Entropy: 2.76062
Value Function Loss: 0.01101

Mean KL Divergence: 0.00576
SB3 Clip Fraction: 0.05486
Policy Update Magnitude: 0.29590
Value Function Update Magnitude: 0.27920

Collected Steps per Second: 21,755.00781
Overall Steps per Second: 10,440.23484

Timestep Collection Time: 2.29832
Timestep Consumption Time: 2.49084
PPO Batch Consumption Time: 0.29329
Total Iteration Time: 4.78916

Cumulative Model Updates: 260,600
Cumulative Timesteps: 2,173,968,258

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2173968258...
Checkpoint 2173968258 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 69,264.96774
Policy Entropy: 2.74258
Value Function Loss: 0.01231

Mean KL Divergence: 0.00652
SB3 Clip Fraction: 0.06222
Policy Update Magnitude: 0.30827
Value Function Update Magnitude: 0.26755

Collected Steps per Second: 22,064.35192
Overall Steps per Second: 10,597.67950

Timestep Collection Time: 2.26664
Timestep Consumption Time: 2.45250
PPO Batch Consumption Time: 0.28714
Total Iteration Time: 4.71915

Cumulative Model Updates: 260,606
Cumulative Timesteps: 2,174,018,270

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 151,339.10935
Policy Entropy: 2.76145
Value Function Loss: 0.01192

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.07341
Policy Update Magnitude: 0.30546
Value Function Update Magnitude: 0.32070

Collected Steps per Second: 21,884.16770
Overall Steps per Second: 10,508.94864

Timestep Collection Time: 2.28622
Timestep Consumption Time: 2.47468
PPO Batch Consumption Time: 0.29236
Total Iteration Time: 4.76089

Cumulative Model Updates: 260,612
Cumulative Timesteps: 2,174,068,302

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2174068302...
Checkpoint 2174068302 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 125,860.61781
Policy Entropy: 2.79875
Value Function Loss: 0.01113

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.07444
Policy Update Magnitude: 0.29680
Value Function Update Magnitude: 0.30709

Collected Steps per Second: 21,023.72436
Overall Steps per Second: 10,230.60973

Timestep Collection Time: 2.37988
Timestep Consumption Time: 2.51073
PPO Batch Consumption Time: 0.29354
Total Iteration Time: 4.89062

Cumulative Model Updates: 260,618
Cumulative Timesteps: 2,174,118,336

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99,187.36433
Policy Entropy: 2.80828
Value Function Loss: 0.01181

Mean KL Divergence: 0.00710
SB3 Clip Fraction: 0.06763
Policy Update Magnitude: 0.29103
Value Function Update Magnitude: 0.29244

Collected Steps per Second: 21,449.39849
Overall Steps per Second: 10,356.35514

Timestep Collection Time: 2.33107
Timestep Consumption Time: 2.49689
PPO Batch Consumption Time: 0.28863
Total Iteration Time: 4.82795

Cumulative Model Updates: 260,624
Cumulative Timesteps: 2,174,168,336

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2174168336...
Checkpoint 2174168336 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 74,517.72569
Policy Entropy: 2.77831
Value Function Loss: 0.01145

Mean KL Divergence: 0.00662
SB3 Clip Fraction: 0.06188
Policy Update Magnitude: 0.29046
Value Function Update Magnitude: 0.30458

Collected Steps per Second: 21,343.57629
Overall Steps per Second: 10,315.97514

Timestep Collection Time: 2.34422
Timestep Consumption Time: 2.50593
PPO Batch Consumption Time: 0.29259
Total Iteration Time: 4.85015

Cumulative Model Updates: 260,630
Cumulative Timesteps: 2,174,218,370

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 104,781.45768
Policy Entropy: 2.74744
Value Function Loss: 0.01231

Mean KL Divergence: 0.00641
SB3 Clip Fraction: 0.05961
Policy Update Magnitude: 0.29706
Value Function Update Magnitude: 0.30621

Collected Steps per Second: 21,937.20492
Overall Steps per Second: 10,404.49638

Timestep Collection Time: 2.28024
Timestep Consumption Time: 2.52749
PPO Batch Consumption Time: 0.29265
Total Iteration Time: 4.80773

Cumulative Model Updates: 260,636
Cumulative Timesteps: 2,174,268,392

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2174268392...
Checkpoint 2174268392 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 104,781.45768
Policy Entropy: 2.78069
Value Function Loss: 0.01014

Mean KL Divergence: 0.00706
SB3 Clip Fraction: 0.06762
Policy Update Magnitude: 0.29213
Value Function Update Magnitude: 0.29517

Collected Steps per Second: 22,025.25768
Overall Steps per Second: 10,607.11926

Timestep Collection Time: 2.27012
Timestep Consumption Time: 2.44369
PPO Batch Consumption Time: 0.28284
Total Iteration Time: 4.71382

Cumulative Model Updates: 260,642
Cumulative Timesteps: 2,174,318,392

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68,370.53699
Policy Entropy: 2.78625
Value Function Loss: 0.01192

Mean KL Divergence: 0.00703
SB3 Clip Fraction: 0.06106
Policy Update Magnitude: 0.29089
Value Function Update Magnitude: 0.26496

Collected Steps per Second: 22,290.07778
Overall Steps per Second: 10,522.35233

Timestep Collection Time: 2.24405
Timestep Consumption Time: 2.50964
PPO Batch Consumption Time: 0.29283
Total Iteration Time: 4.75369

Cumulative Model Updates: 260,648
Cumulative Timesteps: 2,174,368,412

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2174368412...
Checkpoint 2174368412 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 68,294.57768
Policy Entropy: 2.79127
Value Function Loss: 0.01106

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.06466
Policy Update Magnitude: 0.29703
Value Function Update Magnitude: 0.27258

Collected Steps per Second: 20,492.27609
Overall Steps per Second: 10,428.40119

Timestep Collection Time: 2.44004
Timestep Consumption Time: 2.35475
PPO Batch Consumption Time: 0.27918
Total Iteration Time: 4.79479

Cumulative Model Updates: 260,654
Cumulative Timesteps: 2,174,418,414

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 69,675.93150
Policy Entropy: 2.75230
Value Function Loss: 0.01266

Mean KL Divergence: 0.01074
SB3 Clip Fraction: 0.09165
Policy Update Magnitude: 0.30045
Value Function Update Magnitude: 0.28240

Collected Steps per Second: 21,492.86295
Overall Steps per Second: 10,546.25503

Timestep Collection Time: 2.32766
Timestep Consumption Time: 2.41602
PPO Batch Consumption Time: 0.28879
Total Iteration Time: 4.74367

Cumulative Model Updates: 260,660
Cumulative Timesteps: 2,174,468,442

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2174468442...
Checkpoint 2174468442 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 106,089.02098
Policy Entropy: 2.73249
Value Function Loss: 0.01469

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.08716
Policy Update Magnitude: 0.31614
Value Function Update Magnitude: 0.31884

Collected Steps per Second: 21,266.02282
Overall Steps per Second: 10,640.59823

Timestep Collection Time: 2.35145
Timestep Consumption Time: 2.34810
PPO Batch Consumption Time: 0.27895
Total Iteration Time: 4.69955

Cumulative Model Updates: 260,666
Cumulative Timesteps: 2,174,518,448

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 74,254.52835
Policy Entropy: 2.74184
Value Function Loss: 0.01450

Mean KL Divergence: 0.01095
SB3 Clip Fraction: 0.08969
Policy Update Magnitude: 0.31919
Value Function Update Magnitude: 0.35685

Collected Steps per Second: 21,607.89134
Overall Steps per Second: 10,572.25188

Timestep Collection Time: 2.31471
Timestep Consumption Time: 2.41616
PPO Batch Consumption Time: 0.29173
Total Iteration Time: 4.73087

Cumulative Model Updates: 260,672
Cumulative Timesteps: 2,174,568,464

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2174568464...
Checkpoint 2174568464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 66,736.57381
Policy Entropy: 2.74622
Value Function Loss: 0.01339

Mean KL Divergence: 0.01236
SB3 Clip Fraction: 0.10144
Policy Update Magnitude: 0.30595
Value Function Update Magnitude: 0.38103

Collected Steps per Second: 20,946.28623
Overall Steps per Second: 10,456.06128

Timestep Collection Time: 2.38811
Timestep Consumption Time: 2.39591
PPO Batch Consumption Time: 0.27829
Total Iteration Time: 4.78402

Cumulative Model Updates: 260,678
Cumulative Timesteps: 2,174,618,486

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86,177.64723
Policy Entropy: 2.74019
Value Function Loss: 0.01100

Mean KL Divergence: 0.01095
SB3 Clip Fraction: 0.09250
Policy Update Magnitude: 0.29531
Value Function Update Magnitude: 0.38250

Collected Steps per Second: 21,410.38664
Overall Steps per Second: 10,586.24244

Timestep Collection Time: 2.33578
Timestep Consumption Time: 2.38827
PPO Batch Consumption Time: 0.27657
Total Iteration Time: 4.72406

Cumulative Model Updates: 260,684
Cumulative Timesteps: 2,174,668,496

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2174668496...
Checkpoint 2174668496 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 108,325.11858
Policy Entropy: 2.73198
Value Function Loss: 0.01071

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.07959
Policy Update Magnitude: 0.30280
Value Function Update Magnitude: 0.33698

Collected Steps per Second: 21,437.26836
Overall Steps per Second: 10,554.85800

Timestep Collection Time: 2.33276
Timestep Consumption Time: 2.40515
PPO Batch Consumption Time: 0.27829
Total Iteration Time: 4.73791

Cumulative Model Updates: 260,690
Cumulative Timesteps: 2,174,718,504

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 150,180.48760
Policy Entropy: 2.73768
Value Function Loss: 0.01090

Mean KL Divergence: 0.00653
SB3 Clip Fraction: 0.06312
Policy Update Magnitude: 0.30719
Value Function Update Magnitude: 0.30677

Collected Steps per Second: 21,858.23591
Overall Steps per Second: 10,465.43980

Timestep Collection Time: 2.28783
Timestep Consumption Time: 2.49056
PPO Batch Consumption Time: 0.28763
Total Iteration Time: 4.77839

Cumulative Model Updates: 260,696
Cumulative Timesteps: 2,174,768,512

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2174768512...
Checkpoint 2174768512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 116,927.79848
Policy Entropy: 2.74578
Value Function Loss: 0.01003

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.07574
Policy Update Magnitude: 0.30427
Value Function Update Magnitude: 0.27677

Collected Steps per Second: 21,758.35216
Overall Steps per Second: 10,564.18063

Timestep Collection Time: 2.29926
Timestep Consumption Time: 2.43637
PPO Batch Consumption Time: 0.27794
Total Iteration Time: 4.73563

Cumulative Model Updates: 260,702
Cumulative Timesteps: 2,174,818,540

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 105,216.05680
Policy Entropy: 2.75550
Value Function Loss: 0.00940

Mean KL Divergence: 0.00652
SB3 Clip Fraction: 0.06090
Policy Update Magnitude: 0.29353
Value Function Update Magnitude: 0.26521

Collected Steps per Second: 22,312.88940
Overall Steps per Second: 10,560.02672

Timestep Collection Time: 2.24229
Timestep Consumption Time: 2.49558
PPO Batch Consumption Time: 0.28633
Total Iteration Time: 4.73787

Cumulative Model Updates: 260,708
Cumulative Timesteps: 2,174,868,572

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2174868572...
Checkpoint 2174868572 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 170,157.12546
Policy Entropy: 2.76048
Value Function Loss: 0.00931

Mean KL Divergence: 0.00694
SB3 Clip Fraction: 0.06378
Policy Update Magnitude: 0.28444
Value Function Update Magnitude: 0.28266

Collected Steps per Second: 21,778.64570
Overall Steps per Second: 10,526.13574

Timestep Collection Time: 2.29730
Timestep Consumption Time: 2.45583
PPO Batch Consumption Time: 0.27896
Total Iteration Time: 4.75312

Cumulative Model Updates: 260,714
Cumulative Timesteps: 2,174,918,604

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 125,014.18479
Policy Entropy: 2.75859
Value Function Loss: 0.00984

Mean KL Divergence: 0.00682
SB3 Clip Fraction: 0.06236
Policy Update Magnitude: 0.28667
Value Function Update Magnitude: 0.29695

Collected Steps per Second: 22,306.78225
Overall Steps per Second: 10,547.63150

Timestep Collection Time: 2.24246
Timestep Consumption Time: 2.50003
PPO Batch Consumption Time: 0.28900
Total Iteration Time: 4.74249

Cumulative Model Updates: 260,720
Cumulative Timesteps: 2,174,968,626

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2174968626...
Checkpoint 2174968626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 85,711.93925
Policy Entropy: 2.74550
Value Function Loss: 0.01359

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.07920
Policy Update Magnitude: 0.32524
Value Function Update Magnitude: 0.33106

Collected Steps per Second: 22,090.16506
Overall Steps per Second: 10,636.09188

Timestep Collection Time: 2.26436
Timestep Consumption Time: 2.43850
PPO Batch Consumption Time: 0.27869
Total Iteration Time: 4.70286

Cumulative Model Updates: 260,726
Cumulative Timesteps: 2,175,018,646

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 69,817.72799
Policy Entropy: 2.72694
Value Function Loss: 0.01279

Mean KL Divergence: 0.01736
SB3 Clip Fraction: 0.08026
Policy Update Magnitude: 0.33391
Value Function Update Magnitude: 0.36886

Collected Steps per Second: 22,167.82800
Overall Steps per Second: 10,483.70722

Timestep Collection Time: 2.25669
Timestep Consumption Time: 2.51509
PPO Batch Consumption Time: 0.29378
Total Iteration Time: 4.77179

Cumulative Model Updates: 260,732
Cumulative Timesteps: 2,175,068,672

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2175068672...
Checkpoint 2175068672 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 62,446.93187
Policy Entropy: 2.72303
Value Function Loss: 0.01307

Mean KL Divergence: 0.02611
SB3 Clip Fraction: 0.08297
Policy Update Magnitude: 0.33002
Value Function Update Magnitude: 0.38804

Collected Steps per Second: 21,653.10411
Overall Steps per Second: 10,559.39370

Timestep Collection Time: 2.31006
Timestep Consumption Time: 2.42695
PPO Batch Consumption Time: 0.27869
Total Iteration Time: 4.73701

Cumulative Model Updates: 260,738
Cumulative Timesteps: 2,175,118,692

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59,821.32486
Policy Entropy: 2.73071
Value Function Loss: 0.01244

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.06939
Policy Update Magnitude: 0.32556
Value Function Update Magnitude: 0.40813

Collected Steps per Second: 21,683.01931
Overall Steps per Second: 10,557.58240

Timestep Collection Time: 2.30687
Timestep Consumption Time: 2.43095
PPO Batch Consumption Time: 0.27729
Total Iteration Time: 4.73783

Cumulative Model Updates: 260,744
Cumulative Timesteps: 2,175,168,712

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2175168712...
Checkpoint 2175168712 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46,145.81427
Policy Entropy: 2.72080
Value Function Loss: 0.01282

Mean KL Divergence: 0.00645
SB3 Clip Fraction: 0.05915
Policy Update Magnitude: 0.32956
Value Function Update Magnitude: 0.40857

Collected Steps per Second: 21,447.45498
Overall Steps per Second: 10,524.70402

Timestep Collection Time: 2.33249
Timestep Consumption Time: 2.42071
PPO Batch Consumption Time: 0.27807
Total Iteration Time: 4.75320

Cumulative Model Updates: 260,750
Cumulative Timesteps: 2,175,218,738

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68,690.09932
Policy Entropy: 2.71157
Value Function Loss: 0.01192

Mean KL Divergence: 0.00637
SB3 Clip Fraction: 0.06078
Policy Update Magnitude: 0.33090
Value Function Update Magnitude: 0.38475

Collected Steps per Second: 21,506.66751
Overall Steps per Second: 10,535.38334

Timestep Collection Time: 2.32514
Timestep Consumption Time: 2.42134
PPO Batch Consumption Time: 0.27820
Total Iteration Time: 4.74648

Cumulative Model Updates: 260,756
Cumulative Timesteps: 2,175,268,744

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2175268744...
Checkpoint 2175268744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 65,545.40870
Policy Entropy: 2.69492
Value Function Loss: 0.01192

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.07393
Policy Update Magnitude: 0.32314
Value Function Update Magnitude: 0.35071

Collected Steps per Second: 21,572.46443
Overall Steps per Second: 10,572.63056

Timestep Collection Time: 2.31953
Timestep Consumption Time: 2.41326
PPO Batch Consumption Time: 0.27795
Total Iteration Time: 4.73279

Cumulative Model Updates: 260,762
Cumulative Timesteps: 2,175,318,782

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59,341.82937
Policy Entropy: 2.72823
Value Function Loss: 0.01135

Mean KL Divergence: 0.00630
SB3 Clip Fraction: 0.05848
Policy Update Magnitude: 0.31395
Value Function Update Magnitude: 0.33272

Collected Steps per Second: 21,876.99163
Overall Steps per Second: 10,530.64000

Timestep Collection Time: 2.28551
Timestep Consumption Time: 2.46254
PPO Batch Consumption Time: 0.27826
Total Iteration Time: 4.74805

Cumulative Model Updates: 260,768
Cumulative Timesteps: 2,175,368,782

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2175368782...
Checkpoint 2175368782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 59,341.82937
Policy Entropy: 2.73439
Value Function Loss: 0.01031

Mean KL Divergence: 0.00647
SB3 Clip Fraction: 0.06236
Policy Update Magnitude: 0.30478
Value Function Update Magnitude: 0.27536

Collected Steps per Second: 21,588.21103
Overall Steps per Second: 10,325.41448

Timestep Collection Time: 2.31673
Timestep Consumption Time: 2.52705
PPO Batch Consumption Time: 0.29159
Total Iteration Time: 4.84378

Cumulative Model Updates: 260,774
Cumulative Timesteps: 2,175,418,796

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65,224.45264
Policy Entropy: 2.74703
Value Function Loss: 0.01066

Mean KL Divergence: 0.00687
SB3 Clip Fraction: 0.06586
Policy Update Magnitude: 0.29983
Value Function Update Magnitude: 0.25651

Collected Steps per Second: 22,065.81667
Overall Steps per Second: 10,509.63116

Timestep Collection Time: 2.26640
Timestep Consumption Time: 2.49209
PPO Batch Consumption Time: 0.28968
Total Iteration Time: 4.75849

Cumulative Model Updates: 260,780
Cumulative Timesteps: 2,175,468,806

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2175468806...
Checkpoint 2175468806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,446.64122
Policy Entropy: 2.73531
Value Function Loss: 0.01069

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.07282
Policy Update Magnitude: 0.29722
Value Function Update Magnitude: 0.26491

Collected Steps per Second: 22,120.98719
Overall Steps per Second: 10,495.65807

Timestep Collection Time: 2.26292
Timestep Consumption Time: 2.50648
PPO Batch Consumption Time: 0.29311
Total Iteration Time: 4.76940

Cumulative Model Updates: 260,786
Cumulative Timesteps: 2,175,518,864

Timesteps Collected: 50,058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49,446.64122
Policy Entropy: 2.71606
Value Function Loss: 0.01076

Mean KL Divergence: 0.00696
SB3 Clip Fraction: 0.06533
Policy Update Magnitude: 0.29427
Value Function Update Magnitude: 0.27155

Collected Steps per Second: 22,077.78898
Overall Steps per Second: 10,498.40992

Timestep Collection Time: 2.26662
Timestep Consumption Time: 2.50000
PPO Batch Consumption Time: 0.29356
Total Iteration Time: 4.76663

Cumulative Model Updates: 260,792
Cumulative Timesteps: 2,175,568,906

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 2175568906...
Checkpoint 2175568906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47,629.52970
Policy Entropy: 2.68697
Value Function Loss: 0.01156

Mean KL Divergence: 0.00703
SB3 Clip Fraction: 0.06492
Policy Update Magnitude: 0.31109
Value Function Update Magnitude: 0.29077

Collected Steps per Second: 21,960.50903
Overall Steps per Second: 10,545.21864

Timestep Collection Time: 2.27700
Timestep Consumption Time: 2.46487
PPO Batch Consumption Time: 0.28486
Total Iteration Time: 4.74186

Cumulative Model Updates: 260,798
Cumulative Timesteps: 2,175,618,910

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 94,729.00782
Policy Entropy: 2.68273
Value Function Loss: 0.01315

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.07498
Policy Update Magnitude: 0.33623
Value Function Update Magnitude: 0.32370

Collected Steps per Second: 21,909.31107
Overall Steps per Second: 10,466.28113

Timestep Collection Time: 2.28241
Timestep Consumption Time: 2.49541
PPO Batch Consumption Time: 0.29095
Total Iteration Time: 4.77782

Cumulative Model Updates: 260,804
Cumulative Timesteps: 2,175,668,916

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2175668916...
Checkpoint 2175668916 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 76,463.82212
Policy Entropy: 2.70406
Value Function Loss: 0.01408

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.07384
Policy Update Magnitude: 0.33637
Value Function Update Magnitude: 0.34568

Collected Steps per Second: 21,926.72677
Overall Steps per Second: 10,627.19702

Timestep Collection Time: 2.28233
Timestep Consumption Time: 2.42672
PPO Batch Consumption Time: 0.27842
Total Iteration Time: 4.70905

Cumulative Model Updates: 260,810
Cumulative Timesteps: 2,175,718,960

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97,072.91781
Policy Entropy: 2.73664
Value Function Loss: 0.01325

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.08028
Policy Update Magnitude: 0.32164
Value Function Update Magnitude: 0.33747

Collected Steps per Second: 21,620.81363
Overall Steps per Second: 10,442.68025

Timestep Collection Time: 2.31471
Timestep Consumption Time: 2.47773
PPO Batch Consumption Time: 0.28559
Total Iteration Time: 4.79245

Cumulative Model Updates: 260,816
Cumulative Timesteps: 2,175,769,006

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 2175769006...
Checkpoint 2175769006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 100,820.96977
Policy Entropy: 2.72830
Value Function Loss: 0.01095

Mean KL Divergence: 0.00756
SB3 Clip Fraction: 0.07039
Policy Update Magnitude: 0.30790
Value Function Update Magnitude: 0.28697

Collected Steps per Second: 21,199.56493
Overall Steps per Second: 10,272.42137

Timestep Collection Time: 2.36043
Timestep Consumption Time: 2.51087
PPO Batch Consumption Time: 0.29240
Total Iteration Time: 4.87130

Cumulative Model Updates: 260,822
Cumulative Timesteps: 2,175,819,046

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54,463.29241
Policy Entropy: 2.73785
Value Function Loss: 0.01221

Mean KL Divergence: 0.00689
SB3 Clip Fraction: 0.06445
Policy Update Magnitude: 0.30995
Value Function Update Magnitude: 0.24436

Collected Steps per Second: 21,715.76985
Overall Steps per Second: 10,417.01943

Timestep Collection Time: 2.30321
Timestep Consumption Time: 2.49816
PPO Batch Consumption Time: 0.28913
Total Iteration Time: 4.80137

Cumulative Model Updates: 260,828
Cumulative Timesteps: 2,175,869,062

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2175869062...
Checkpoint 2175869062 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 58,257.25670
Policy Entropy: 2.72789
Value Function Loss: 0.01231

Mean KL Divergence: 0.00703
SB3 Clip Fraction: 0.06226
Policy Update Magnitude: 0.31042
Value Function Update Magnitude: 0.21974

Collected Steps per Second: 21,478.99748
Overall Steps per Second: 10,355.59843

Timestep Collection Time: 2.32990
Timestep Consumption Time: 2.50265
PPO Batch Consumption Time: 0.29197
Total Iteration Time: 4.83256

Cumulative Model Updates: 260,834
Cumulative Timesteps: 2,175,919,106

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,985.52671
Policy Entropy: 2.71211
Value Function Loss: 0.01317

Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.06861
Policy Update Magnitude: 0.31861
Value Function Update Magnitude: 0.23614

Collected Steps per Second: 21,779.53598
Overall Steps per Second: 10,395.28955

Timestep Collection Time: 2.29628
Timestep Consumption Time: 2.51474
PPO Batch Consumption Time: 0.29282
Total Iteration Time: 4.81103

Cumulative Model Updates: 260,840
Cumulative Timesteps: 2,175,969,118

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2175969118...
Checkpoint 2175969118 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,114.60150
Policy Entropy: 2.72651
Value Function Loss: 0.01104

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.08217
Policy Update Magnitude: 0.30745
Value Function Update Magnitude: 0.25288

Collected Steps per Second: 21,840.55218
Overall Steps per Second: 10,509.63936

Timestep Collection Time: 2.29069
Timestep Consumption Time: 2.46970
PPO Batch Consumption Time: 0.27881
Total Iteration Time: 4.76039

Cumulative Model Updates: 260,846
Cumulative Timesteps: 2,176,019,148

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 123,974.50124
Policy Entropy: 2.71160
Value Function Loss: 0.01343

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.07326
Policy Update Magnitude: 0.30694
Value Function Update Magnitude: 0.23745

Collected Steps per Second: 22,236.23351
Overall Steps per Second: 10,482.86929

Timestep Collection Time: 2.24993
Timestep Consumption Time: 2.52262
PPO Batch Consumption Time: 0.29310
Total Iteration Time: 4.77255

Cumulative Model Updates: 260,852
Cumulative Timesteps: 2,176,069,178

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2176069178...
Checkpoint 2176069178 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 145,600.22475
Policy Entropy: 2.74895
Value Function Loss: 0.01336

Mean KL Divergence: 0.00718
SB3 Clip Fraction: 0.06701
Policy Update Magnitude: 0.31187
Value Function Update Magnitude: 0.23465

Collected Steps per Second: 22,128.20667
Overall Steps per Second: 10,713.35124

Timestep Collection Time: 2.25965
Timestep Consumption Time: 2.40761
PPO Batch Consumption Time: 0.27676
Total Iteration Time: 4.66726

Cumulative Model Updates: 260,858
Cumulative Timesteps: 2,176,119,180

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77,648.42951
Policy Entropy: 2.73287
Value Function Loss: 0.01502

Mean KL Divergence: 0.00694
SB3 Clip Fraction: 0.06302
Policy Update Magnitude: 0.31475
Value Function Update Magnitude: 0.26683

Collected Steps per Second: 22,173.32737
Overall Steps per Second: 10,545.54153

Timestep Collection Time: 2.25613
Timestep Consumption Time: 2.48767
PPO Batch Consumption Time: 0.29016
Total Iteration Time: 4.74381

Cumulative Model Updates: 260,864
Cumulative Timesteps: 2,176,169,206

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2176169206...
Checkpoint 2176169206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 99,087.00128
Policy Entropy: 2.73558
Value Function Loss: 0.01483

Mean KL Divergence: 0.00627
SB3 Clip Fraction: 0.06186
Policy Update Magnitude: 0.32771
Value Function Update Magnitude: 0.25491

Collected Steps per Second: 21,476.05200
Overall Steps per Second: 10,479.41907

Timestep Collection Time: 2.32901
Timestep Consumption Time: 2.44396
PPO Batch Consumption Time: 0.29257
Total Iteration Time: 4.77297

Cumulative Model Updates: 260,870
Cumulative Timesteps: 2,176,219,224

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 69,455.99523
Policy Entropy: 2.73772
Value Function Loss: 0.01462

Mean KL Divergence: 0.00753
SB3 Clip Fraction: 0.07107
Policy Update Magnitude: 0.32278
Value Function Update Magnitude: 0.22325

Collected Steps per Second: 21,644.65813
Overall Steps per Second: 10,560.07196

Timestep Collection Time: 2.31032
Timestep Consumption Time: 2.42507
PPO Batch Consumption Time: 0.29111
Total Iteration Time: 4.73538

Cumulative Model Updates: 260,876
Cumulative Timesteps: 2,176,269,230

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2176269230...
Checkpoint 2176269230 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 115,937.95545
Policy Entropy: 2.74930
Value Function Loss: 0.01299

Mean KL Divergence: 0.00756
SB3 Clip Fraction: 0.06798
Policy Update Magnitude: 0.30654
Value Function Update Magnitude: 0.22480

Collected Steps per Second: 21,420.31223
Overall Steps per Second: 10,539.69924

Timestep Collection Time: 2.33489
Timestep Consumption Time: 2.41041
PPO Batch Consumption Time: 0.27938
Total Iteration Time: 4.74530

Cumulative Model Updates: 260,882
Cumulative Timesteps: 2,176,319,244

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 96,253.33863
Policy Entropy: 2.77131
Value Function Loss: 0.01124

Mean KL Divergence: 0.00648
SB3 Clip Fraction: 0.06240
Policy Update Magnitude: 0.29644
Value Function Update Magnitude: 0.25752

Collected Steps per Second: 21,508.31035
Overall Steps per Second: 10,428.52423

Timestep Collection Time: 2.32645
Timestep Consumption Time: 2.47174
PPO Batch Consumption Time: 0.28835
Total Iteration Time: 4.79819

Cumulative Model Updates: 260,888
Cumulative Timesteps: 2,176,369,282

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 2176369282...
Checkpoint 2176369282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 83,974.41464
Policy Entropy: 2.76428
Value Function Loss: 0.01099

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.07821
Policy Update Magnitude: 0.29304
Value Function Update Magnitude: 0.25454

Collected Steps per Second: 21,451.44083
Overall Steps per Second: 10,579.70849

Timestep Collection Time: 2.33122
Timestep Consumption Time: 2.39557
PPO Batch Consumption Time: 0.27849
Total Iteration Time: 4.72678

Cumulative Model Updates: 260,894
Cumulative Timesteps: 2,176,419,290

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95,589.27687
Policy Entropy: 2.78470
Value Function Loss: 0.01134

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.08424
Policy Update Magnitude: 0.29127
Value Function Update Magnitude: 0.27202

Collected Steps per Second: 21,704.52920
Overall Steps per Second: 10,545.82018

Timestep Collection Time: 2.30496
Timestep Consumption Time: 2.43891
PPO Batch Consumption Time: 0.28416
Total Iteration Time: 4.74387

Cumulative Model Updates: 260,900
Cumulative Timesteps: 2,176,469,318

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2176469318...
Checkpoint 2176469318 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 71,089.33500
Policy Entropy: 2.78715
Value Function Loss: 0.01053

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.07825
Policy Update Magnitude: 0.29058
Value Function Update Magnitude: 0.27967

Collected Steps per Second: 21,801.96279
Overall Steps per Second: 10,584.58149

Timestep Collection Time: 2.29365
Timestep Consumption Time: 2.43077
PPO Batch Consumption Time: 0.27793
Total Iteration Time: 4.72442

Cumulative Model Updates: 260,906
Cumulative Timesteps: 2,176,519,324

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83,652.73874
Policy Entropy: 2.77912
Value Function Loss: 0.01104

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.07965
Policy Update Magnitude: 0.29077
Value Function Update Magnitude: 0.25984

Collected Steps per Second: 22,208.19405
Overall Steps per Second: 10,590.09184

Timestep Collection Time: 2.25340
Timestep Consumption Time: 2.47215
PPO Batch Consumption Time: 0.27706
Total Iteration Time: 4.72555

Cumulative Model Updates: 260,912
Cumulative Timesteps: 2,176,569,368

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 2176569368...
Checkpoint 2176569368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 114,632.48810
Policy Entropy: 2.77960
Value Function Loss: 0.01028

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.07744
Policy Update Magnitude: 0.28438
Value Function Update Magnitude: 0.26835

Collected Steps per Second: 22,040.78824
Overall Steps per Second: 10,615.90545

Timestep Collection Time: 2.26961
Timestep Consumption Time: 2.44256
PPO Batch Consumption Time: 0.27714
Total Iteration Time: 4.71217

Cumulative Model Updates: 260,918
Cumulative Timesteps: 2,176,619,392

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99,038.81322
Policy Entropy: 2.74932
Value Function Loss: 0.00990

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.08057
Policy Update Magnitude: 0.28052
Value Function Update Magnitude: 0.26014

Collected Steps per Second: 22,206.36455
Overall Steps per Second: 10,557.62579

Timestep Collection Time: 2.25170
Timestep Consumption Time: 2.48441
PPO Batch Consumption Time: 0.29163
Total Iteration Time: 4.73610

Cumulative Model Updates: 260,924
Cumulative Timesteps: 2,176,669,394

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2176669394...
Checkpoint 2176669394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 105,176.45955
Policy Entropy: 2.75013
Value Function Loss: 0.00912

Mean KL Divergence: 0.00716
SB3 Clip Fraction: 0.06883
Policy Update Magnitude: 0.27662
Value Function Update Magnitude: 0.24391

Collected Steps per Second: 21,908.78708
Overall Steps per Second: 10,463.82225

Timestep Collection Time: 2.28237
Timestep Consumption Time: 2.49638
PPO Batch Consumption Time: 0.28999
Total Iteration Time: 4.77875

Cumulative Model Updates: 260,930
Cumulative Timesteps: 2,176,719,398

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 105,176.45955
Policy Entropy: 2.74115
Value Function Loss: 0.00821

Mean KL Divergence: 0.00586
SB3 Clip Fraction: 0.05660
Policy Update Magnitude: 0.27436
Value Function Update Magnitude: 0.24323

Collected Steps per Second: 22,164.58257
Overall Steps per Second: 10,497.69139

Timestep Collection Time: 2.25693
Timestep Consumption Time: 2.50830
PPO Batch Consumption Time: 0.29279
Total Iteration Time: 4.76524

Cumulative Model Updates: 260,936
Cumulative Timesteps: 2,176,769,422

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2176769422...
Checkpoint 2176769422 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 105,176.45955
Policy Entropy: 2.74563
Value Function Loss: 0.00844

Mean KL Divergence: 0.00551
SB3 Clip Fraction: 0.05176
Policy Update Magnitude: 0.27326
Value Function Update Magnitude: 0.23814

Collected Steps per Second: 20,496.19918
Overall Steps per Second: 10,187.41644

Timestep Collection Time: 2.43987
Timestep Consumption Time: 2.46893
PPO Batch Consumption Time: 0.27825
Total Iteration Time: 4.90880

Cumulative Model Updates: 260,942
Cumulative Timesteps: 2,176,819,430

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 96,189.01229
Policy Entropy: 2.73031
Value Function Loss: 0.01057

Mean KL Divergence: 0.00687
SB3 Clip Fraction: 0.06350
Policy Update Magnitude: 0.29298
Value Function Update Magnitude: 0.23530

Collected Steps per Second: 22,366.61478
Overall Steps per Second: 10,564.19379

Timestep Collection Time: 2.23673
Timestep Consumption Time: 2.49889
PPO Batch Consumption Time: 0.29270
Total Iteration Time: 4.73562

Cumulative Model Updates: 260,948
Cumulative Timesteps: 2,176,869,458

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2176869458...
Checkpoint 2176869458 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 62,765.83478
Policy Entropy: 2.68974
Value Function Loss: 0.01408

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.07367
Policy Update Magnitude: 0.32651
Value Function Update Magnitude: 0.28290

Collected Steps per Second: 21,698.85355
Overall Steps per Second: 10,588.66131

Timestep Collection Time: 2.30491
Timestep Consumption Time: 2.41844
PPO Batch Consumption Time: 0.27680
Total Iteration Time: 4.72335

Cumulative Model Updates: 260,954
Cumulative Timesteps: 2,176,919,472

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70,970.99719
Policy Entropy: 2.70171
Value Function Loss: 0.01307

Mean KL Divergence: 0.01102
SB3 Clip Fraction: 0.09930
Policy Update Magnitude: 0.32900
Value Function Update Magnitude: 0.31305

Collected Steps per Second: 21,685.98616
Overall Steps per Second: 10,385.66680

Timestep Collection Time: 2.30693
Timestep Consumption Time: 2.51010
PPO Batch Consumption Time: 0.29055
Total Iteration Time: 4.81702

Cumulative Model Updates: 260,960
Cumulative Timesteps: 2,176,969,500

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2176969500...
Checkpoint 2176969500 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 70,970.99719
Policy Entropy: 2.72089
Value Function Loss: 0.01035

Mean KL Divergence: 0.01066
SB3 Clip Fraction: 0.09291
Policy Update Magnitude: 0.30043
Value Function Update Magnitude: 0.28078

Collected Steps per Second: 20,914.09827
Overall Steps per Second: 10,215.92849

Timestep Collection Time: 2.39331
Timestep Consumption Time: 2.50629
PPO Batch Consumption Time: 0.28962
Total Iteration Time: 4.89960

Cumulative Model Updates: 260,966
Cumulative Timesteps: 2,177,019,554

Timesteps Collected: 50,054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 110,370.35648
Policy Entropy: 2.75272
Value Function Loss: 0.00921

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.07757
Policy Update Magnitude: 0.27255
Value Function Update Magnitude: 0.22682

Collected Steps per Second: 21,596.92982
Overall Steps per Second: 10,546.92620

Timestep Collection Time: 2.31700
Timestep Consumption Time: 2.42751
PPO Batch Consumption Time: 0.27706
Total Iteration Time: 4.74451

Cumulative Model Updates: 260,972
Cumulative Timesteps: 2,177,069,594

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 2177069594...
Checkpoint 2177069594 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 98,326.69230
Policy Entropy: 2.74201
Value Function Loss: 0.01021

Mean KL Divergence: 0.00699
SB3 Clip Fraction: 0.06887
Policy Update Magnitude: 0.27751
Value Function Update Magnitude: 0.20348

Collected Steps per Second: 21,332.05607
Overall Steps per Second: 10,519.67873

Timestep Collection Time: 2.34502
Timestep Consumption Time: 2.41026
PPO Batch Consumption Time: 0.27762
Total Iteration Time: 4.75528

Cumulative Model Updates: 260,978
Cumulative Timesteps: 2,177,119,618

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85,809.15653
Policy Entropy: 2.72296
Value Function Loss: 0.01298

Mean KL Divergence: 0.00695
SB3 Clip Fraction: 0.06746
Policy Update Magnitude: 0.29902
Value Function Update Magnitude: 0.22712

Collected Steps per Second: 22,129.81162
Overall Steps per Second: 10,490.37665

Timestep Collection Time: 2.25994
Timestep Consumption Time: 2.50748
PPO Batch Consumption Time: 0.28506
Total Iteration Time: 4.76742

Cumulative Model Updates: 260,984
Cumulative Timesteps: 2,177,169,630

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2177169630...
Checkpoint 2177169630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84,456.50839
Policy Entropy: 2.71468
Value Function Loss: 0.01391

Mean KL Divergence: 0.00678
SB3 Clip Fraction: 0.06462
Policy Update Magnitude: 0.31623
Value Function Update Magnitude: 0.25050

Collected Steps per Second: 21,425.39796
Overall Steps per Second: 10,616.59390

Timestep Collection Time: 2.33499
Timestep Consumption Time: 2.37726
PPO Batch Consumption Time: 0.27801
Total Iteration Time: 4.71225

Cumulative Model Updates: 260,990
Cumulative Timesteps: 2,177,219,658

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 199,282.69439
Policy Entropy: 2.71079
Value Function Loss: 0.01384

Mean KL Divergence: 0.00663
SB3 Clip Fraction: 0.06241
Policy Update Magnitude: 0.32998
Value Function Update Magnitude: 0.30038

Collected Steps per Second: 21,451.97918
Overall Steps per Second: 10,496.42996

Timestep Collection Time: 2.33265
Timestep Consumption Time: 2.43468
PPO Batch Consumption Time: 0.29230
Total Iteration Time: 4.76734

Cumulative Model Updates: 260,996
Cumulative Timesteps: 2,177,269,698

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 2177269698...
Checkpoint 2177269698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 186,141.34805
Policy Entropy: 2.72403
Value Function Loss: 0.01133

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.07300
Policy Update Magnitude: 0.31527
Value Function Update Magnitude: 0.32054

Collected Steps per Second: 21,224.40132
Overall Steps per Second: 10,631.01479

Timestep Collection Time: 2.35653
Timestep Consumption Time: 2.34819
PPO Batch Consumption Time: 0.27812
Total Iteration Time: 4.70472

Cumulative Model Updates: 261,002
Cumulative Timesteps: 2,177,319,714

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 126,546.15129
Policy Entropy: 2.73005
Value Function Loss: 0.01123

Mean KL Divergence: 0.00749
SB3 Clip Fraction: 0.06818
Policy Update Magnitude: 0.30988
Value Function Update Magnitude: 0.33170

Collected Steps per Second: 21,598.57985
Overall Steps per Second: 10,460.17319

Timestep Collection Time: 2.31626
Timestep Consumption Time: 2.46645
PPO Batch Consumption Time: 0.28818
Total Iteration Time: 4.78271

Cumulative Model Updates: 261,008
Cumulative Timesteps: 2,177,369,742

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2177369742...
Checkpoint 2177369742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 121,648.70438
Policy Entropy: 2.74046
Value Function Loss: 0.01072

Mean KL Divergence: 0.00707
SB3 Clip Fraction: 0.06750
Policy Update Magnitude: 0.29769
Value Function Update Magnitude: 0.29866

Collected Steps per Second: 22,007.76077
Overall Steps per Second: 10,707.43965

Timestep Collection Time: 2.27202
Timestep Consumption Time: 2.39782
PPO Batch Consumption Time: 0.27768
Total Iteration Time: 4.66984

Cumulative Model Updates: 261,014
Cumulative Timesteps: 2,177,419,744

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 100,814.18329
Policy Entropy: 2.73276
Value Function Loss: 0.01052

Mean KL Divergence: 0.00646
SB3 Clip Fraction: 0.05822
Policy Update Magnitude: 0.29346
Value Function Update Magnitude: 0.28285

Collected Steps per Second: 22,139.02504
Overall Steps per Second: 10,778.04201

Timestep Collection Time: 2.25900
Timestep Consumption Time: 2.38118
PPO Batch Consumption Time: 0.27705
Total Iteration Time: 4.64017

Cumulative Model Updates: 261,020
Cumulative Timesteps: 2,177,469,756

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2177469756...
Checkpoint 2177469756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 100,814.18329
Policy Entropy: 2.74647
Value Function Loss: 0.00927

Mean KL Divergence: 0.00635
SB3 Clip Fraction: 0.05845
Policy Update Magnitude: 0.28899
Value Function Update Magnitude: 0.25936

Collected Steps per Second: 21,353.59321
Overall Steps per Second: 10,312.01357

Timestep Collection Time: 2.34199
Timestep Consumption Time: 2.50769
PPO Batch Consumption Time: 0.29355
Total Iteration Time: 4.84968

Cumulative Model Updates: 261,026
Cumulative Timesteps: 2,177,519,766

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88,831.05134
Policy Entropy: 2.72500
Value Function Loss: 0.01126

Mean KL Divergence: 0.00677
SB3 Clip Fraction: 0.05928
Policy Update Magnitude: 0.30110
Value Function Update Magnitude: 0.27937

Collected Steps per Second: 21,530.46272
Overall Steps per Second: 10,422.80108

Timestep Collection Time: 2.32461
Timestep Consumption Time: 2.47736
PPO Batch Consumption Time: 0.28680
Total Iteration Time: 4.80197

Cumulative Model Updates: 261,032
Cumulative Timesteps: 2,177,569,816

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 2177569816...
Checkpoint 2177569816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 66,446.78230
Policy Entropy: 2.74272
Value Function Loss: 0.01049

Mean KL Divergence: 0.00589
SB3 Clip Fraction: 0.05621
Policy Update Magnitude: 0.30645
Value Function Update Magnitude: 0.29271

Collected Steps per Second: 21,469.61350
Overall Steps per Second: 10,388.13365

Timestep Collection Time: 2.32980
Timestep Consumption Time: 2.48530
PPO Batch Consumption Time: 0.28856
Total Iteration Time: 4.81511

Cumulative Model Updates: 261,038
Cumulative Timesteps: 2,177,619,836

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 102,058.32453
Policy Entropy: 2.73523
Value Function Loss: 0.01187

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.06693
Policy Update Magnitude: 0.30350
Value Function Update Magnitude: 0.27393

Collected Steps per Second: 21,898.65250
Overall Steps per Second: 10,609.08036

Timestep Collection Time: 2.28352
Timestep Consumption Time: 2.42999
PPO Batch Consumption Time: 0.27826
Total Iteration Time: 4.71351

Cumulative Model Updates: 261,044
Cumulative Timesteps: 2,177,669,842

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2177669842...
Checkpoint 2177669842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 95,149.61888
Policy Entropy: 2.77512
Value Function Loss: 0.01079

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.08261
Policy Update Magnitude: 0.30093
Value Function Update Magnitude: 0.29185

Collected Steps per Second: 21,468.26596
Overall Steps per Second: 10,298.46314

Timestep Collection Time: 2.33004
Timestep Consumption Time: 2.52719
PPO Batch Consumption Time: 0.29258
Total Iteration Time: 4.85723

Cumulative Model Updates: 261,050
Cumulative Timesteps: 2,177,719,864

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 100,278.26324
Policy Entropy: 2.75746
Value Function Loss: 0.01151

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.09112
Policy Update Magnitude: 0.29982
Value Function Update Magnitude: 0.30066

Collected Steps per Second: 22,364.11866
Overall Steps per Second: 10,424.53917

Timestep Collection Time: 2.23590
Timestep Consumption Time: 2.56086
PPO Batch Consumption Time: 0.29372
Total Iteration Time: 4.79676

Cumulative Model Updates: 261,056
Cumulative Timesteps: 2,177,769,868

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2177769868...
Checkpoint 2177769868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 78,322.21942
Policy Entropy: 2.74729
Value Function Loss: 0.01153

Mean KL Divergence: 0.01180
SB3 Clip Fraction: 0.09459
Policy Update Magnitude: 0.30415
Value Function Update Magnitude: 0.29030

Collected Steps per Second: 21,765.29824
Overall Steps per Second: 10,547.70988

Timestep Collection Time: 2.29788
Timestep Consumption Time: 2.44381
PPO Batch Consumption Time: 0.27828
Total Iteration Time: 4.74169

Cumulative Model Updates: 261,062
Cumulative Timesteps: 2,177,819,882

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67,371.46858
Policy Entropy: 2.71367
Value Function Loss: 0.01344

Mean KL Divergence: 0.01125
SB3 Clip Fraction: 0.09175
Policy Update Magnitude: 0.31435
Value Function Update Magnitude: 0.30187

Collected Steps per Second: 22,445.87875
Overall Steps per Second: 10,572.82667

Timestep Collection Time: 2.22981
Timestep Consumption Time: 2.50403
PPO Batch Consumption Time: 0.29205
Total Iteration Time: 4.73383

Cumulative Model Updates: 261,068
Cumulative Timesteps: 2,177,869,932

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 2177869932...
Checkpoint 2177869932 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 75,785.42488
Policy Entropy: 2.73644
Value Function Loss: 0.01263

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.08586
Policy Update Magnitude: 0.31819
Value Function Update Magnitude: 0.30291

Collected Steps per Second: 21,459.82795
Overall Steps per Second: 10,541.67362

Timestep Collection Time: 2.33003
Timestep Consumption Time: 2.41324
PPO Batch Consumption Time: 0.27827
Total Iteration Time: 4.74327

Cumulative Model Updates: 261,074
Cumulative Timesteps: 2,177,919,934

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86,595.83859
Policy Entropy: 2.74677
Value Function Loss: 0.01232

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.07739
Policy Update Magnitude: 0.32496
Value Function Update Magnitude: 0.28132

Collected Steps per Second: 22,206.03430
Overall Steps per Second: 10,533.71422

Timestep Collection Time: 2.25353
Timestep Consumption Time: 2.49712
PPO Batch Consumption Time: 0.29055
Total Iteration Time: 4.75065

Cumulative Model Updates: 261,080
Cumulative Timesteps: 2,177,969,976

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 2177969976...
Checkpoint 2177969976 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 82,883.21225
Policy Entropy: 2.76994
Value Function Loss: 0.01046

Mean KL Divergence: 0.00691
SB3 Clip Fraction: 0.06379
Policy Update Magnitude: 0.31409
Value Function Update Magnitude: 0.26744

Collected Steps per Second: 21,696.62486
Overall Steps per Second: 10,569.95524

Timestep Collection Time: 2.30451
Timestep Consumption Time: 2.42588
PPO Batch Consumption Time: 0.27833
Total Iteration Time: 4.73039

Cumulative Model Updates: 261,086
Cumulative Timesteps: 2,178,019,976

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88,788.10757
Policy Entropy: 2.77688
Value Function Loss: 0.01190

Mean KL Divergence: 0.00608
SB3 Clip Fraction: 0.05516
Policy Update Magnitude: 0.30595
Value Function Update Magnitude: 0.24721

Collected Steps per Second: 22,202.88041
Overall Steps per Second: 10,520.54458

Timestep Collection Time: 2.25223
Timestep Consumption Time: 2.50095
PPO Batch Consumption Time: 0.29035
Total Iteration Time: 4.75318

Cumulative Model Updates: 261,092
Cumulative Timesteps: 2,178,069,982

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2178069982...
Checkpoint 2178069982 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 74,404.99977
Policy Entropy: 2.80125
Value Function Loss: 0.01126

Mean KL Divergence: 0.00548
SB3 Clip Fraction: 0.05278
Policy Update Magnitude: 0.29838
Value Function Update Magnitude: 0.28420

Collected Steps per Second: 21,548.83571
Overall Steps per Second: 10,558.30044

Timestep Collection Time: 2.32050
Timestep Consumption Time: 2.41549
PPO Batch Consumption Time: 0.27796
Total Iteration Time: 4.73599

Cumulative Model Updates: 261,098
Cumulative Timesteps: 2,178,119,986

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 105,931.72493
Policy Entropy: 2.80259
Value Function Loss: 0.01077

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.07367
Policy Update Magnitude: 0.29002
Value Function Update Magnitude: 0.31962

Collected Steps per Second: 21,623.86978
Overall Steps per Second: 10,502.00050

Timestep Collection Time: 2.31300
Timestep Consumption Time: 2.44952
PPO Batch Consumption Time: 0.28120
Total Iteration Time: 4.76252

Cumulative Model Updates: 261,104
Cumulative Timesteps: 2,178,170,002

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2178170002...
Checkpoint 2178170002 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 80,938.55240
Policy Entropy: 2.77941
Value Function Loss: 0.01056

Mean KL Divergence: 0.00749
SB3 Clip Fraction: 0.06953
Policy Update Magnitude: 0.28986
Value Function Update Magnitude: 0.32160

Collected Steps per Second: 21,302.23386
Overall Steps per Second: 10,272.42507

Timestep Collection Time: 2.34773
Timestep Consumption Time: 2.52083
PPO Batch Consumption Time: 0.29381
Total Iteration Time: 4.86857

Cumulative Model Updates: 261,110
Cumulative Timesteps: 2,178,220,014

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 107,594.08320
Policy Entropy: 2.75534
Value Function Loss: 0.01106

Mean KL Divergence: 0.00698
SB3 Clip Fraction: 0.05865
Policy Update Magnitude: 0.30186
Value Function Update Magnitude: 0.30882

Collected Steps per Second: 21,608.52786
Overall Steps per Second: 10,410.80382

Timestep Collection Time: 2.31594
Timestep Consumption Time: 2.49099
PPO Batch Consumption Time: 0.28699
Total Iteration Time: 4.80693

Cumulative Model Updates: 261,116
Cumulative Timesteps: 2,178,270,058

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 2178270058...
Checkpoint 2178270058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 114,065.04904
Policy Entropy: 2.73091
Value Function Loss: 0.01185

Mean KL Divergence: 0.00710
SB3 Clip Fraction: 0.06299
Policy Update Magnitude: 0.30382
Value Function Update Magnitude: 0.30999

Collected Steps per Second: 21,397.65844
Overall Steps per Second: 10,313.69103

Timestep Collection Time: 2.33811
Timestep Consumption Time: 2.51273
PPO Batch Consumption Time: 0.29312
Total Iteration Time: 4.85083

Cumulative Model Updates: 261,122
Cumulative Timesteps: 2,178,320,088

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88,082.13443
Policy Entropy: 2.74232
Value Function Loss: 0.01208

Mean KL Divergence: 0.00679
SB3 Clip Fraction: 0.05954
Policy Update Magnitude: 0.30397
Value Function Update Magnitude: 0.30920

Collected Steps per Second: 22,024.20725
Overall Steps per Second: 10,397.85076

Timestep Collection Time: 2.27050
Timestep Consumption Time: 2.53876
PPO Batch Consumption Time: 0.29310
Total Iteration Time: 4.80926

Cumulative Model Updates: 261,128
Cumulative Timesteps: 2,178,370,094

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2178370094...
Checkpoint 2178370094 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 88,263.63580
Policy Entropy: 2.75541
Value Function Loss: 0.01290

Mean KL Divergence: 0.00709
SB3 Clip Fraction: 0.06297
Policy Update Magnitude: 0.31299
Value Function Update Magnitude: 0.32229

Collected Steps per Second: 21,888.03421
Overall Steps per Second: 10,590.97299

Timestep Collection Time: 2.28490
Timestep Consumption Time: 2.43723
PPO Batch Consumption Time: 0.27870
Total Iteration Time: 4.72213

Cumulative Model Updates: 261,134
Cumulative Timesteps: 2,178,420,106

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 167,292.05316
Policy Entropy: 2.76844
Value Function Loss: 0.01363

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.08844
Policy Update Magnitude: 0.31385
Value Function Update Magnitude: 0.33546

Collected Steps per Second: 22,398.40221
Overall Steps per Second: 10,601.55304

Timestep Collection Time: 2.23328
Timestep Consumption Time: 2.48508
PPO Batch Consumption Time: 0.29073
Total Iteration Time: 4.71837

Cumulative Model Updates: 261,140
Cumulative Timesteps: 2,178,470,128

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2178470128...
Checkpoint 2178470128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 118,664.54801
Policy Entropy: 2.76431
Value Function Loss: 0.01321

Mean KL Divergence: 0.01178
SB3 Clip Fraction: 0.10045
Policy Update Magnitude: 0.30851
Value Function Update Magnitude: 0.30166

Collected Steps per Second: 21,617.94606
Overall Steps per Second: 10,553.70075

Timestep Collection Time: 2.31419
Timestep Consumption Time: 2.42614
PPO Batch Consumption Time: 0.27721
Total Iteration Time: 4.74033

Cumulative Model Updates: 261,146
Cumulative Timesteps: 2,178,520,156

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 129,303.67356
Policy Entropy: 2.75422
Value Function Loss: 0.01233

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.08111
Policy Update Magnitude: 0.30431
Value Function Update Magnitude: 0.26426

Collected Steps per Second: 22,069.15024
Overall Steps per Second: 10,479.09158

Timestep Collection Time: 2.26697
Timestep Consumption Time: 2.50730
PPO Batch Consumption Time: 0.29299
Total Iteration Time: 4.77427

Cumulative Model Updates: 261,152
Cumulative Timesteps: 2,178,570,186

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2178570186...
Checkpoint 2178570186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 112,318.57954
Policy Entropy: 2.74752
Value Function Loss: 0.01027

Mean KL Divergence: 0.00748
SB3 Clip Fraction: 0.06733
Policy Update Magnitude: 0.29414
Value Function Update Magnitude: 0.25251

Collected Steps per Second: 21,325.64276
Overall Steps per Second: 10,543.99748

Timestep Collection Time: 2.34469
Timestep Consumption Time: 2.39754
PPO Batch Consumption Time: 0.28556
Total Iteration Time: 4.74222

Cumulative Model Updates: 261,158
Cumulative Timesteps: 2,178,620,188

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 111,635.54323
Policy Entropy: 2.74973
Value Function Loss: 0.00861

Mean KL Divergence: 0.00664
SB3 Clip Fraction: 0.06205
Policy Update Magnitude: 0.27877
Value Function Update Magnitude: 0.23488

Collected Steps per Second: 21,446.67986
Overall Steps per Second: 10,455.80921

Timestep Collection Time: 2.33155
Timestep Consumption Time: 2.45086
PPO Batch Consumption Time: 0.29412
Total Iteration Time: 4.78241

Cumulative Model Updates: 261,164
Cumulative Timesteps: 2,178,670,192

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2178670192...
Checkpoint 2178670192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 123,776.06436
Policy Entropy: 2.79127
Value Function Loss: 0.00759

Mean KL Divergence: 0.00650
SB3 Clip Fraction: 0.05815
Policy Update Magnitude: 0.26463
Value Function Update Magnitude: 0.21742

Collected Steps per Second: 20,620.89213
Overall Steps per Second: 10,221.31591

Timestep Collection Time: 2.42521
Timestep Consumption Time: 2.46751
PPO Batch Consumption Time: 0.28849
Total Iteration Time: 4.89272

Cumulative Model Updates: 261,170
Cumulative Timesteps: 2,178,720,202

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 127,487.46991
Policy Entropy: 2.80101
Value Function Loss: 0.00700

Mean KL Divergence: 0.00599
SB3 Clip Fraction: 0.05830
Policy Update Magnitude: 0.24722
Value Function Update Magnitude: 0.22201

Collected Steps per Second: 21,343.60665
Overall Steps per Second: 10,449.52217

Timestep Collection Time: 2.34487
Timestep Consumption Time: 2.44463
PPO Batch Consumption Time: 0.28507
Total Iteration Time: 4.78950

Cumulative Model Updates: 261,176
Cumulative Timesteps: 2,178,770,250

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 2178770250...
Checkpoint 2178770250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 195,361.04394
Policy Entropy: 2.80005
Value Function Loss: 0.00910

Mean KL Divergence: 0.00514
SB3 Clip Fraction: 0.04910
Policy Update Magnitude: 0.25328
Value Function Update Magnitude: 0.23416

Collected Steps per Second: 21,407.77483
Overall Steps per Second: 10,545.83890

Timestep Collection Time: 2.33579
Timestep Consumption Time: 2.40580
PPO Batch Consumption Time: 0.27837
Total Iteration Time: 4.74159

Cumulative Model Updates: 261,182
Cumulative Timesteps: 2,178,820,254

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 114,469.25084
Policy Entropy: 2.75251
Value Function Loss: 0.01224

Mean KL Divergence: 0.00588
SB3 Clip Fraction: 0.05759
Policy Update Magnitude: 0.28731
Value Function Update Magnitude: 0.25103

Collected Steps per Second: 21,373.64280
Overall Steps per Second: 10,531.58615

Timestep Collection Time: 2.34045
Timestep Consumption Time: 2.40945
PPO Batch Consumption Time: 0.27818
Total Iteration Time: 4.74990

Cumulative Model Updates: 261,188
Cumulative Timesteps: 2,178,870,278

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2178870278...
Checkpoint 2178870278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 100,533.70757
Policy Entropy: 2.74209
Value Function Loss: 0.01490

Mean KL Divergence: 0.00618
SB3 Clip Fraction: 0.05876
Policy Update Magnitude: 0.31270
Value Function Update Magnitude: 0.33856

Collected Steps per Second: 21,572.02082
Overall Steps per Second: 10,422.98948

Timestep Collection Time: 2.31958
Timestep Consumption Time: 2.48116
PPO Batch Consumption Time: 0.28875
Total Iteration Time: 4.80073

Cumulative Model Updates: 261,194
Cumulative Timesteps: 2,178,920,316

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 71,892.26482
Policy Entropy: 2.74677
Value Function Loss: 0.01426

Mean KL Divergence: 0.00662
SB3 Clip Fraction: 0.06285
Policy Update Magnitude: 0.31551
Value Function Update Magnitude: 0.37401

Collected Steps per Second: 22,137.53592
Overall Steps per Second: 10,605.27192

Timestep Collection Time: 2.25924
Timestep Consumption Time: 2.45672
PPO Batch Consumption Time: 0.27889
Total Iteration Time: 4.71596

Cumulative Model Updates: 261,200
Cumulative Timesteps: 2,178,970,330

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2178970330...
Checkpoint 2178970330 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 75,327.41321
Policy Entropy: 2.74002
Value Function Loss: 0.01245

Mean KL Divergence: 0.00617
SB3 Clip Fraction: 0.05791
Policy Update Magnitude: 0.32065
Value Function Update Magnitude: 0.36686

Collected Steps per Second: 21,965.49355
Overall Steps per Second: 10,599.20701

Timestep Collection Time: 2.27684
Timestep Consumption Time: 2.44162
PPO Batch Consumption Time: 0.27851
Total Iteration Time: 4.71847

Cumulative Model Updates: 261,206
Cumulative Timesteps: 2,179,020,342

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 123,537.13371
Policy Entropy: 2.75087
Value Function Loss: 0.01074

Mean KL Divergence: 0.00654
SB3 Clip Fraction: 0.06022
Policy Update Magnitude: 0.31058
Value Function Update Magnitude: 0.30856

Collected Steps per Second: 22,008.57624
Overall Steps per Second: 10,564.19799

Timestep Collection Time: 2.27302
Timestep Consumption Time: 2.46241
PPO Batch Consumption Time: 0.28457
Total Iteration Time: 4.73543

Cumulative Model Updates: 261,212
Cumulative Timesteps: 2,179,070,368

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2179070368...
Checkpoint 2179070368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 133,308.34768
Policy Entropy: 2.73627
Value Function Loss: 0.01081

Mean KL Divergence: 0.00595
SB3 Clip Fraction: 0.05408
Policy Update Magnitude: 0.29609
Value Function Update Magnitude: 0.28871

Collected Steps per Second: 21,794.69645
Overall Steps per Second: 10,583.47126

Timestep Collection Time: 2.29441
Timestep Consumption Time: 2.43050
PPO Batch Consumption Time: 0.27830
Total Iteration Time: 4.72491

Cumulative Model Updates: 261,218
Cumulative Timesteps: 2,179,120,374

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 109,140.54289
Policy Entropy: 2.75272
Value Function Loss: 0.01031

Mean KL Divergence: 0.00528
SB3 Clip Fraction: 0.05072
Policy Update Magnitude: 0.29654
Value Function Update Magnitude: 0.26234

Collected Steps per Second: 21,971.74739
Overall Steps per Second: 10,490.10812

Timestep Collection Time: 2.27711
Timestep Consumption Time: 2.49234
PPO Batch Consumption Time: 0.28715
Total Iteration Time: 4.76945

Cumulative Model Updates: 261,224
Cumulative Timesteps: 2,179,170,406

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2179170406...
Checkpoint 2179170406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 90,425.68647
Policy Entropy: 2.72208
Value Function Loss: 0.01122

Mean KL Divergence: 0.00588
SB3 Clip Fraction: 0.05681
Policy Update Magnitude: 0.30601
Value Function Update Magnitude: 0.25551

Collected Steps per Second: 21,630.99895
Overall Steps per Second: 10,554.67854

Timestep Collection Time: 2.31150
Timestep Consumption Time: 2.42574
PPO Batch Consumption Time: 0.27853
Total Iteration Time: 4.73724

Cumulative Model Updates: 261,230
Cumulative Timesteps: 2,179,220,406

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87,566.54778
Policy Entropy: 2.71887
Value Function Loss: 0.01272

Mean KL Divergence: 0.00691
SB3 Clip Fraction: 0.06401
Policy Update Magnitude: 0.32392
Value Function Update Magnitude: 0.23399

Collected Steps per Second: 21,502.09269
Overall Steps per Second: 10,531.22000

Timestep Collection Time: 2.32694
Timestep Consumption Time: 2.42408
PPO Batch Consumption Time: 0.27748
Total Iteration Time: 4.75102

Cumulative Model Updates: 261,236
Cumulative Timesteps: 2,179,270,440

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 2179270440...
Checkpoint 2179270440 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87,566.54778
Policy Entropy: 2.72062
Value Function Loss: 0.01183

Mean KL Divergence: 0.00702
SB3 Clip Fraction: 0.06361
Policy Update Magnitude: 0.32401
Value Function Update Magnitude: 0.22339

Collected Steps per Second: 21,528.36685
Overall Steps per Second: 10,369.04084

Timestep Collection Time: 2.32345
Timestep Consumption Time: 2.50053
PPO Batch Consumption Time: 0.29218
Total Iteration Time: 4.82398

Cumulative Model Updates: 261,242
Cumulative Timesteps: 2,179,320,460

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76,264.80187
Policy Entropy: 2.71877
Value Function Loss: 0.01146

Mean KL Divergence: 0.00708
SB3 Clip Fraction: 0.06293
Policy Update Magnitude: 0.31795
Value Function Update Magnitude: 0.22646

Collected Steps per Second: 21,762.24017
Overall Steps per Second: 10,397.29163

Timestep Collection Time: 2.29811
Timestep Consumption Time: 2.51199
PPO Batch Consumption Time: 0.29302
Total Iteration Time: 4.81010

Cumulative Model Updates: 261,248
Cumulative Timesteps: 2,179,370,472

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2179370472...
Checkpoint 2179370472 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 88,990.53782
Policy Entropy: 2.74177
Value Function Loss: 0.01060

Mean KL Divergence: 0.00680
SB3 Clip Fraction: 0.05975
Policy Update Magnitude: 0.31065
Value Function Update Magnitude: 0.24367

Collected Steps per Second: 21,906.11385
Overall Steps per Second: 10,582.25542

Timestep Collection Time: 2.28411
Timestep Consumption Time: 2.44418
PPO Batch Consumption Time: 0.27724
Total Iteration Time: 4.72829

Cumulative Model Updates: 261,254
Cumulative Timesteps: 2,179,420,508

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82,641.10051
Policy Entropy: 2.74097
Value Function Loss: 0.01095

Mean KL Divergence: 0.00710
SB3 Clip Fraction: 0.06577
Policy Update Magnitude: 0.30088
Value Function Update Magnitude: 0.27629

Collected Steps per Second: 22,422.82674
Overall Steps per Second: 10,468.67405

Timestep Collection Time: 2.22996
Timestep Consumption Time: 2.54639
PPO Batch Consumption Time: 0.29331
Total Iteration Time: 4.77635

Cumulative Model Updates: 261,260
Cumulative Timesteps: 2,179,470,510

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2179470510...
Checkpoint 2179470510 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 71,785.18097
Policy Entropy: 2.75372
Value Function Loss: 0.01220

Mean KL Divergence: 0.00613
SB3 Clip Fraction: 0.05667
Policy Update Magnitude: 0.30029
Value Function Update Magnitude: 0.27901

Collected Steps per Second: 21,749.21722
Overall Steps per Second: 10,527.25131

Timestep Collection Time: 2.29939
Timestep Consumption Time: 2.45113
PPO Batch Consumption Time: 0.27875
Total Iteration Time: 4.75053

Cumulative Model Updates: 261,266
Cumulative Timesteps: 2,179,520,520

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59,990.37427
Policy Entropy: 2.73472
Value Function Loss: 0.01204

Mean KL Divergence: 0.00636
SB3 Clip Fraction: 0.06088
Policy Update Magnitude: 0.30115
Value Function Update Magnitude: 0.28054

Collected Steps per Second: 22,105.12585
Overall Steps per Second: 10,492.18196

Timestep Collection Time: 2.26391
Timestep Consumption Time: 2.50574
PPO Batch Consumption Time: 0.29044
Total Iteration Time: 4.76965

Cumulative Model Updates: 261,272
Cumulative Timesteps: 2,179,570,564

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 2179570564...
Checkpoint 2179570564 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 52,569.79156
Policy Entropy: 2.73928
Value Function Loss: 0.01166

Mean KL Divergence: 0.00748
SB3 Clip Fraction: 0.07010
Policy Update Magnitude: 0.29930
Value Function Update Magnitude: 0.28339

Collected Steps per Second: 22,077.22193
Overall Steps per Second: 10,645.89794

Timestep Collection Time: 2.26686
Timestep Consumption Time: 2.43410
PPO Batch Consumption Time: 0.27909
Total Iteration Time: 4.70097

Cumulative Model Updates: 261,278
Cumulative Timesteps: 2,179,620,610

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 64,384.63593
Policy Entropy: 2.71503
Value Function Loss: 0.01442

Mean KL Divergence: 0.01095
SB3 Clip Fraction: 0.08639
Policy Update Magnitude: 0.32894
Value Function Update Magnitude: 0.27398

Collected Steps per Second: 21,991.16967
Overall Steps per Second: 10,465.03461

Timestep Collection Time: 2.27391
Timestep Consumption Time: 2.50448
PPO Batch Consumption Time: 0.29049
Total Iteration Time: 4.77839

Cumulative Model Updates: 261,284
Cumulative Timesteps: 2,179,670,616

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2179670616...
Checkpoint 2179670616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 64,384.63593
Policy Entropy: 2.72810
Value Function Loss: 0.01371

Mean KL Divergence: 0.01070
SB3 Clip Fraction: 0.08869
Policy Update Magnitude: 0.32554
Value Function Update Magnitude: 0.30104

Collected Steps per Second: 22,062.56139
Overall Steps per Second: 10,676.98298

Timestep Collection Time: 2.26655
Timestep Consumption Time: 2.41698
PPO Batch Consumption Time: 0.27673
Total Iteration Time: 4.68353

Cumulative Model Updates: 261,290
Cumulative Timesteps: 2,179,720,622

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 64,384.63593
Policy Entropy: 2.71537
Value Function Loss: 0.01237

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.08494
Policy Update Magnitude: 0.31479
Value Function Update Magnitude: 0.28757

Collected Steps per Second: 21,366.18203
Overall Steps per Second: 10,387.07981

Timestep Collection Time: 2.34043
Timestep Consumption Time: 2.47382
PPO Batch Consumption Time: 0.28549
Total Iteration Time: 4.81425

Cumulative Model Updates: 261,296
Cumulative Timesteps: 2,179,770,628

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2179770628...
Checkpoint 2179770628 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 73,677.55785
Policy Entropy: 2.72125
Value Function Loss: 0.01078

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.07396
Policy Update Magnitude: 0.30784
Value Function Update Magnitude: 0.26490

Collected Steps per Second: 21,376.16751
Overall Steps per Second: 10,331.76275

Timestep Collection Time: 2.33961
Timestep Consumption Time: 2.50099
PPO Batch Consumption Time: 0.29255
Total Iteration Time: 4.84061

Cumulative Model Updates: 261,302
Cumulative Timesteps: 2,179,820,640

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 153,782.18101
Policy Entropy: 2.71152
Value Function Loss: 0.01205

Mean KL Divergence: 0.00709
SB3 Clip Fraction: 0.06593
Policy Update Magnitude: 0.31615
Value Function Update Magnitude: 0.27633

Collected Steps per Second: 18,524.45291
Overall Steps per Second: 9,577.99669

Timestep Collection Time: 2.69989
Timestep Consumption Time: 2.52187
PPO Batch Consumption Time: 0.29461
Total Iteration Time: 5.22176

Cumulative Model Updates: 261,308
Cumulative Timesteps: 2,179,870,654

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2179870654...
Checkpoint 2179870654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 120,701.76263
Policy Entropy: 2.73919
Value Function Loss: 0.01139

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.06873
Policy Update Magnitude: 0.32754
Value Function Update Magnitude: 0.30538

Collected Steps per Second: 21,610.20950
Overall Steps per Second: 10,559.09803

Timestep Collection Time: 2.31428
Timestep Consumption Time: 2.42211
PPO Batch Consumption Time: 0.27795
Total Iteration Time: 4.73639

Cumulative Model Updates: 261,314
Cumulative Timesteps: 2,179,920,666

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 107,155.62923
Policy Entropy: 2.75851
Value Function Loss: 0.01059

Mean KL Divergence: 0.01707
SB3 Clip Fraction: 0.06689
Policy Update Magnitude: 0.32267
Value Function Update Magnitude: 0.30582

Collected Steps per Second: 21,896.19374
Overall Steps per Second: 10,579.18164

Timestep Collection Time: 2.28442
Timestep Consumption Time: 2.44374
PPO Batch Consumption Time: 0.27652
Total Iteration Time: 4.72815

Cumulative Model Updates: 261,320
Cumulative Timesteps: 2,179,970,686

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2179970686...
Checkpoint 2179970686 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 119,558.85740
Policy Entropy: 2.76730
Value Function Loss: 0.01077

Mean KL Divergence: 0.02423
SB3 Clip Fraction: 0.06018
Policy Update Magnitude: 0.29821
Value Function Update Magnitude: 0.29208

Collected Steps per Second: 21,523.92948
Overall Steps per Second: 10,569.09843

Timestep Collection Time: 2.32485
Timestep Consumption Time: 2.40970
PPO Batch Consumption Time: 0.28550
Total Iteration Time: 4.73456

Cumulative Model Updates: 261,326
Cumulative Timesteps: 2,180,020,726

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 119,558.85740
Policy Entropy: 2.76262
Value Function Loss: 0.01002

Mean KL Divergence: 0.00644
SB3 Clip Fraction: 0.06004
Policy Update Magnitude: 0.29002
Value Function Update Magnitude: 0.25999

Collected Steps per Second: 21,580.77331
Overall Steps per Second: 10,565.73738

Timestep Collection Time: 2.31771
Timestep Consumption Time: 2.41627
PPO Batch Consumption Time: 0.29195
Total Iteration Time: 4.73398

Cumulative Model Updates: 261,332
Cumulative Timesteps: 2,180,070,744

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2180070744...
Checkpoint 2180070744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 94,170.00840
Policy Entropy: 2.75257
Value Function Loss: 0.01269

Mean KL Divergence: 0.00725
SB3 Clip Fraction: 0.06779
Policy Update Magnitude: 0.29118
Value Function Update Magnitude: 0.24201

Collected Steps per Second: 21,567.31454
Overall Steps per Second: 10,533.46409

Timestep Collection Time: 2.31934
Timestep Consumption Time: 2.42952
PPO Batch Consumption Time: 0.29359
Total Iteration Time: 4.74887

Cumulative Model Updates: 261,338
Cumulative Timesteps: 2,180,120,766

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 72,972.27292
Policy Entropy: 2.74285
Value Function Loss: 0.01189

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.07268
Policy Update Magnitude: 0.29935
Value Function Update Magnitude: 0.28816

Collected Steps per Second: 21,395.80293
Overall Steps per Second: 10,450.01045

Timestep Collection Time: 2.33700
Timestep Consumption Time: 2.44788
PPO Batch Consumption Time: 0.29356
Total Iteration Time: 4.78488

Cumulative Model Updates: 261,344
Cumulative Timesteps: 2,180,170,768

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2180170768...
Checkpoint 2180170768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 62,861.93480
Policy Entropy: 2.71815
Value Function Loss: 0.01212

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.07451
Policy Update Magnitude: 0.30639
Value Function Update Magnitude: 0.32724

Collected Steps per Second: 21,357.82685
Overall Steps per Second: 10,546.38412

Timestep Collection Time: 2.34228
Timestep Consumption Time: 2.40115
PPO Batch Consumption Time: 0.27911
Total Iteration Time: 4.74343

Cumulative Model Updates: 261,350
Cumulative Timesteps: 2,180,220,794

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62,861.93480
Policy Entropy: 2.71327
Value Function Loss: 0.01051

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.08835
Policy Update Magnitude: 0.31313
Value Function Update Magnitude: 0.33271

Collected Steps per Second: 22,016.67902
Overall Steps per Second: 10,530.54795

Timestep Collection Time: 2.27137
Timestep Consumption Time: 2.47748
PPO Batch Consumption Time: 0.29104
Total Iteration Time: 4.74885

Cumulative Model Updates: 261,356
Cumulative Timesteps: 2,180,270,802

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2180270802...
Checkpoint 2180270802 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 62,861.93480
Policy Entropy: 2.71614
Value Function Loss: 0.00957

Mean KL Divergence: 0.01238
SB3 Clip Fraction: 0.10076
Policy Update Magnitude: 0.30169
Value Function Update Magnitude: 0.29235

Collected Steps per Second: 21,141.13899
Overall Steps per Second: 10,341.95203

Timestep Collection Time: 2.36676
Timestep Consumption Time: 2.47140
PPO Batch Consumption Time: 0.29173
Total Iteration Time: 4.83816

Cumulative Model Updates: 261,362
Cumulative Timesteps: 2,180,320,838

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78,499.63996
Policy Entropy: 2.73450
Value Function Loss: 0.00874

Mean KL Divergence: 0.01606
SB3 Clip Fraction: 0.11437
Policy Update Magnitude: 0.28106
Value Function Update Magnitude: 0.26356

Collected Steps per Second: 21,760.41591
Overall Steps per Second: 10,374.40033

Timestep Collection Time: 2.29867
Timestep Consumption Time: 2.52281
PPO Batch Consumption Time: 0.29390
Total Iteration Time: 4.82148

Cumulative Model Updates: 261,368
Cumulative Timesteps: 2,180,370,858

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2180370858...
Checkpoint 2180370858 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 66,007.96133
Policy Entropy: 2.74419
Value Function Loss: 0.00912

Mean KL Divergence: 0.01550
SB3 Clip Fraction: 0.11834
Policy Update Magnitude: 0.27654
Value Function Update Magnitude: 0.24963

Collected Steps per Second: 21,298.11046
Overall Steps per Second: 10,325.18829

Timestep Collection Time: 2.34763
Timestep Consumption Time: 2.49490
PPO Batch Consumption Time: 0.29094
Total Iteration Time: 4.84253

Cumulative Model Updates: 261,374
Cumulative Timesteps: 2,180,420,858

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77,728.69321
Policy Entropy: 2.74532
Value Function Loss: 0.00948

Mean KL Divergence: 0.01395
SB3 Clip Fraction: 0.10916
Policy Update Magnitude: 0.27427
Value Function Update Magnitude: 0.28504

Collected Steps per Second: 21,975.41075
Overall Steps per Second: 10,459.95254

Timestep Collection Time: 2.27673
Timestep Consumption Time: 2.50647
PPO Batch Consumption Time: 0.29009
Total Iteration Time: 4.78320

Cumulative Model Updates: 261,380
Cumulative Timesteps: 2,180,470,890

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2180470890...
Checkpoint 2180470890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 138,108.83563
Policy Entropy: 2.73802
Value Function Loss: 0.01065

Mean KL Divergence: 0.01169
SB3 Clip Fraction: 0.09164
Policy Update Magnitude: 0.28702
Value Function Update Magnitude: 0.32500

Collected Steps per Second: 21,995.76025
Overall Steps per Second: 10,553.42788

Timestep Collection Time: 2.27471
Timestep Consumption Time: 2.46631
PPO Batch Consumption Time: 0.27666
Total Iteration Time: 4.74102

Cumulative Model Updates: 261,386
Cumulative Timesteps: 2,180,520,924

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 129,383.64806
Policy Entropy: 2.73338
Value Function Loss: 0.01106

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.08246
Policy Update Magnitude: 0.29788
Value Function Update Magnitude: 0.32351

Collected Steps per Second: 20,808.64893
Overall Steps per Second: 10,277.50771

Timestep Collection Time: 2.40342
Timestep Consumption Time: 2.46274
PPO Batch Consumption Time: 0.27856
Total Iteration Time: 4.86616

Cumulative Model Updates: 261,392
Cumulative Timesteps: 2,180,570,936

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2180570936...
Checkpoint 2180570936 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 130,157.35307
Policy Entropy: 2.71011
Value Function Loss: 0.01190

Mean KL Divergence: 0.00681
SB3 Clip Fraction: 0.06607
Policy Update Magnitude: 0.31149
Value Function Update Magnitude: 0.31487

Collected Steps per Second: 21,632.01486
Overall Steps per Second: 10,355.67569

Timestep Collection Time: 2.31148
Timestep Consumption Time: 2.51698
PPO Batch Consumption Time: 0.29314
Total Iteration Time: 4.82846

Cumulative Model Updates: 261,398
Cumulative Timesteps: 2,180,620,938

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 111,686.29362
Policy Entropy: 2.70551
Value Function Loss: 0.01260

Mean KL Divergence: 0.00693
SB3 Clip Fraction: 0.06452
Policy Update Magnitude: 0.31369
Value Function Update Magnitude: 0.31496

Collected Steps per Second: 22,473.16347
Overall Steps per Second: 10,759.81369

Timestep Collection Time: 2.22683
Timestep Consumption Time: 2.42418
PPO Batch Consumption Time: 0.27901
Total Iteration Time: 4.65101

Cumulative Model Updates: 261,404
Cumulative Timesteps: 2,180,670,982

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 2180670982...
Checkpoint 2180670982 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 102,995.42488
Policy Entropy: 2.73225
Value Function Loss: 0.01214

Mean KL Divergence: 0.00686
SB3 Clip Fraction: 0.06241
Policy Update Magnitude: 0.30723
Value Function Update Magnitude: 0.32050

Collected Steps per Second: 21,762.39267
Overall Steps per Second: 10,452.28995

Timestep Collection Time: 2.29828
Timestep Consumption Time: 2.48689
PPO Batch Consumption Time: 0.29076
Total Iteration Time: 4.78517

Cumulative Model Updates: 261,410
Cumulative Timesteps: 2,180,720,998

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86,242.98093
Policy Entropy: 2.75844
Value Function Loss: 0.01049

Mean KL Divergence: 0.00622
SB3 Clip Fraction: 0.05897
Policy Update Magnitude: 0.29357
Value Function Update Magnitude: 0.29619

Collected Steps per Second: 22,531.10227
Overall Steps per Second: 10,766.00994

Timestep Collection Time: 2.21924
Timestep Consumption Time: 2.42519
PPO Batch Consumption Time: 0.27794
Total Iteration Time: 4.64443

Cumulative Model Updates: 261,416
Cumulative Timesteps: 2,180,771,000

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2180771000...
Checkpoint 2180771000 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86,242.98093
Policy Entropy: 2.74616
Value Function Loss: 0.00906

Mean KL Divergence: 0.00595
SB3 Clip Fraction: 0.05557
Policy Update Magnitude: 0.28118
Value Function Update Magnitude: 0.27953

Collected Steps per Second: 21,907.48415
Overall Steps per Second: 10,593.16492

Timestep Collection Time: 2.28306
Timestep Consumption Time: 2.43848
PPO Batch Consumption Time: 0.27858
Total Iteration Time: 4.72154

Cumulative Model Updates: 261,422
Cumulative Timesteps: 2,180,821,016

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99,936.68917
Policy Entropy: 2.73858
Value Function Loss: 0.00928

Mean KL Divergence: 0.00585
SB3 Clip Fraction: 0.05550
Policy Update Magnitude: 0.27887
Value Function Update Magnitude: 0.26939

Collected Steps per Second: 21,653.86501
Overall Steps per Second: 10,439.93849

Timestep Collection Time: 2.31053
Timestep Consumption Time: 2.48183
PPO Batch Consumption Time: 0.28551
Total Iteration Time: 4.79237

Cumulative Model Updates: 261,428
Cumulative Timesteps: 2,180,871,048

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2180871048...
Checkpoint 2180871048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 99,936.68917
Policy Entropy: 2.72353
Value Function Loss: 0.00967

Mean KL Divergence: 0.00691
SB3 Clip Fraction: 0.06204
Policy Update Magnitude: 0.28449
Value Function Update Magnitude: 0.25851

Collected Steps per Second: 21,491.09959
Overall Steps per Second: 10,413.66321

Timestep Collection Time: 2.32757
Timestep Consumption Time: 2.47593
PPO Batch Consumption Time: 0.28901
Total Iteration Time: 4.80350

Cumulative Model Updates: 261,434
Cumulative Timesteps: 2,180,921,070

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 173,813.55736
Policy Entropy: 2.72749
Value Function Loss: 0.01035

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.07088
Policy Update Magnitude: 0.29274
Value Function Update Magnitude: 0.26211

Collected Steps per Second: 21,908.04139
Overall Steps per Second: 10,627.11578

Timestep Collection Time: 2.28428
Timestep Consumption Time: 2.42481
PPO Batch Consumption Time: 0.27843
Total Iteration Time: 4.70909

Cumulative Model Updates: 261,440
Cumulative Timesteps: 2,180,971,114

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 2180971114...
Checkpoint 2180971114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 144,365.18569
Policy Entropy: 2.71640
Value Function Loss: 0.01103

Mean KL Divergence: 0.00732
SB3 Clip Fraction: 0.06789
Policy Update Magnitude: 0.29866
Value Function Update Magnitude: 0.29523

Collected Steps per Second: 21,456.37482
Overall Steps per Second: 10,328.75720

Timestep Collection Time: 2.33124
Timestep Consumption Time: 2.51155
PPO Batch Consumption Time: 0.29305
Total Iteration Time: 4.84279

Cumulative Model Updates: 261,446
Cumulative Timesteps: 2,181,021,134

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 127,779.77420
Policy Entropy: 2.72251
Value Function Loss: 0.01129

Mean KL Divergence: 0.00704
SB3 Clip Fraction: 0.06599
Policy Update Magnitude: 0.30348
Value Function Update Magnitude: 0.32828

Collected Steps per Second: 22,052.55963
Overall Steps per Second: 10,498.37376

Timestep Collection Time: 2.26731
Timestep Consumption Time: 2.49533
PPO Batch Consumption Time: 0.29020
Total Iteration Time: 4.76264

Cumulative Model Updates: 261,452
Cumulative Timesteps: 2,181,071,134

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2181071134...
Checkpoint 2181071134 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 132,364.91800
Policy Entropy: 2.70560
Value Function Loss: 0.01261

Mean KL Divergence: 0.00652
SB3 Clip Fraction: 0.06141
Policy Update Magnitude: 0.31373
Value Function Update Magnitude: 0.35139

Collected Steps per Second: 21,912.02727
Overall Steps per Second: 10,527.97043

Timestep Collection Time: 2.28203
Timestep Consumption Time: 2.46760
PPO Batch Consumption Time: 0.27837
Total Iteration Time: 4.74963

Cumulative Model Updates: 261,458
Cumulative Timesteps: 2,181,121,138

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 123,221.79858
Policy Entropy: 2.71948
Value Function Loss: 0.01457

Mean KL Divergence: 0.00646
SB3 Clip Fraction: 0.06162
Policy Update Magnitude: 0.35076
Value Function Update Magnitude: 0.36993

Collected Steps per Second: 22,234.05031
Overall Steps per Second: 10,517.67860

Timestep Collection Time: 2.24907
Timestep Consumption Time: 2.50540
PPO Batch Consumption Time: 0.29242
Total Iteration Time: 4.75447

Cumulative Model Updates: 261,464
Cumulative Timesteps: 2,181,171,144

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2181171144...
Checkpoint 2181171144 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 137,063.64764
Policy Entropy: 2.72958
Value Function Loss: 0.01419

Mean KL Divergence: 0.00697
SB3 Clip Fraction: 0.06652
Policy Update Magnitude: 0.33512
Value Function Update Magnitude: 0.35807

Collected Steps per Second: 21,887.80334
Overall Steps per Second: 10,630.72112

Timestep Collection Time: 2.28493
Timestep Consumption Time: 2.41955
PPO Batch Consumption Time: 0.27685
Total Iteration Time: 4.70448

Cumulative Model Updates: 261,470
Cumulative Timesteps: 2,181,221,156

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 127,574.12625
Policy Entropy: 2.72340
Value Function Loss: 0.01462

Mean KL Divergence: 0.00704
SB3 Clip Fraction: 0.06488
Policy Update Magnitude: 0.32694
Value Function Update Magnitude: 0.34405

Collected Steps per Second: 22,296.29355
Overall Steps per Second: 10,544.86401

Timestep Collection Time: 2.24315
Timestep Consumption Time: 2.49982
PPO Batch Consumption Time: 0.29121
Total Iteration Time: 4.74297

Cumulative Model Updates: 261,476
Cumulative Timesteps: 2,181,271,170

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2181271170...
Checkpoint 2181271170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 152,696.51747
Policy Entropy: 2.69088
Value Function Loss: 0.01322

Mean KL Divergence: 0.00685
SB3 Clip Fraction: 0.06313
Policy Update Magnitude: 0.32889
Value Function Update Magnitude: 0.34921

Collected Steps per Second: 21,739.01898
Overall Steps per Second: 10,451.07455

Timestep Collection Time: 2.30158
Timestep Consumption Time: 2.48587
PPO Batch Consumption Time: 0.28773
Total Iteration Time: 4.78745

Cumulative Model Updates: 261,482
Cumulative Timesteps: 2,181,321,204

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 129,951.72948
Policy Entropy: 2.71633
Value Function Loss: 0.01279

Mean KL Divergence: 0.00673
SB3 Clip Fraction: 0.06460
Policy Update Magnitude: 0.33068
Value Function Update Magnitude: 0.37195

Collected Steps per Second: 22,196.75362
Overall Steps per Second: 10,486.49471

Timestep Collection Time: 2.25384
Timestep Consumption Time: 2.51686
PPO Batch Consumption Time: 0.29466
Total Iteration Time: 4.77071

Cumulative Model Updates: 261,488
Cumulative Timesteps: 2,181,371,232

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2181371232...
Checkpoint 2181371232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 77,137.54071
Policy Entropy: 2.72761
Value Function Loss: 0.01325

Mean KL Divergence: 0.00749
SB3 Clip Fraction: 0.06813
Policy Update Magnitude: 0.32674
Value Function Update Magnitude: 0.38723

Collected Steps per Second: 21,411.36999
Overall Steps per Second: 10,374.78205

Timestep Collection Time: 2.33539
Timestep Consumption Time: 2.48437
PPO Batch Consumption Time: 0.29057
Total Iteration Time: 4.81976

Cumulative Model Updates: 261,494
Cumulative Timesteps: 2,181,421,236

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77,137.54071
Policy Entropy: 2.72971
Value Function Loss: 0.01117

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.07300
Policy Update Magnitude: 0.31732
Value Function Update Magnitude: 0.38263

Collected Steps per Second: 21,804.39858
Overall Steps per Second: 10,483.18158

Timestep Collection Time: 2.29312
Timestep Consumption Time: 2.47643
PPO Batch Consumption Time: 0.28889
Total Iteration Time: 4.76954

Cumulative Model Updates: 261,500
Cumulative Timesteps: 2,181,471,236

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2181471236...
Checkpoint 2181471236 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 77,137.54071
Policy Entropy: 2.70368
Value Function Loss: 0.01013

Mean KL Divergence: 0.00693
SB3 Clip Fraction: 0.06402
Policy Update Magnitude: 0.30691
Value Function Update Magnitude: 0.35867

Collected Steps per Second: 20,709.81739
Overall Steps per Second: 10,497.48263

Timestep Collection Time: 2.41431
Timestep Consumption Time: 2.34873
PPO Batch Consumption Time: 0.27681
Total Iteration Time: 4.76305

Cumulative Model Updates: 261,506
Cumulative Timesteps: 2,181,521,236

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82,330.84548
Policy Entropy: 2.69809
Value Function Loss: 0.01049

Mean KL Divergence: 0.00645
SB3 Clip Fraction: 0.06100
Policy Update Magnitude: 0.30781
Value Function Update Magnitude: 0.32268

Collected Steps per Second: 20,975.69708
Overall Steps per Second: 10,361.86033

Timestep Collection Time: 2.38409
Timestep Consumption Time: 2.44207
PPO Batch Consumption Time: 0.29122
Total Iteration Time: 4.82616

Cumulative Model Updates: 261,512
Cumulative Timesteps: 2,181,571,244

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2181571244...
Checkpoint 2181571244 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 71,789.98851
Policy Entropy: 2.71277
Value Function Loss: 0.01094

Mean KL Divergence: 0.00701
SB3 Clip Fraction: 0.06525
Policy Update Magnitude: 0.31085
Value Function Update Magnitude: 0.31985

Collected Steps per Second: 20,962.93514
Overall Steps per Second: 10,574.65174

Timestep Collection Time: 2.38697
Timestep Consumption Time: 2.34491
PPO Batch Consumption Time: 0.27830
Total Iteration Time: 4.73188

Cumulative Model Updates: 261,518
Cumulative Timesteps: 2,181,621,282

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57,061.46245
Policy Entropy: 2.72397
Value Function Loss: 0.01195

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.08019
Policy Update Magnitude: 0.31779
Value Function Update Magnitude: 0.31770

Collected Steps per Second: 21,146.93086
Overall Steps per Second: 10,579.80461

Timestep Collection Time: 2.36441
Timestep Consumption Time: 2.36158
PPO Batch Consumption Time: 0.27699
Total Iteration Time: 4.72599

Cumulative Model Updates: 261,524
Cumulative Timesteps: 2,181,671,282

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2181671282...
Checkpoint 2181671282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 57,061.46245
Policy Entropy: 2.73171
Value Function Loss: 0.01148

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.08258
Policy Update Magnitude: 0.31886
Value Function Update Magnitude: 0.31664

Collected Steps per Second: 21,054.48821
Overall Steps per Second: 10,224.24511

Timestep Collection Time: 2.37555
Timestep Consumption Time: 2.51635
PPO Batch Consumption Time: 0.29283
Total Iteration Time: 4.89190

Cumulative Model Updates: 261,530
Cumulative Timesteps: 2,181,721,298

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48,166.18008
Policy Entropy: 2.73595
Value Function Loss: 0.01187

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.08432
Policy Update Magnitude: 0.31931
Value Function Update Magnitude: 0.29571

Collected Steps per Second: 21,945.66634
Overall Steps per Second: 10,522.99792

Timestep Collection Time: 2.28009
Timestep Consumption Time: 2.47502
PPO Batch Consumption Time: 0.29052
Total Iteration Time: 4.75511

Cumulative Model Updates: 261,536
Cumulative Timesteps: 2,181,771,336

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 2181771336...
Checkpoint 2181771336 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 120,108.64449
Policy Entropy: 2.75174
Value Function Loss: 0.01005

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.07468
Policy Update Magnitude: 0.29742
Value Function Update Magnitude: 0.25465

Collected Steps per Second: 21,574.81385
Overall Steps per Second: 10,483.88527

Timestep Collection Time: 2.31770
Timestep Consumption Time: 2.45190
PPO Batch Consumption Time: 0.28653
Total Iteration Time: 4.76961

Cumulative Model Updates: 261,542
Cumulative Timesteps: 2,181,821,340

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 103,261.46833
Policy Entropy: 2.77960
Value Function Loss: 0.00967

Mean KL Divergence: 0.00680
SB3 Clip Fraction: 0.06315
Policy Update Magnitude: 0.28853
Value Function Update Magnitude: 0.28095

Collected Steps per Second: 21,993.48261
Overall Steps per Second: 10,470.11437

Timestep Collection Time: 2.27376
Timestep Consumption Time: 2.50250
PPO Batch Consumption Time: 0.29156
Total Iteration Time: 4.77626

Cumulative Model Updates: 261,548
Cumulative Timesteps: 2,181,871,348

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2181871348...
Checkpoint 2181871348 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 79,215.95463
Policy Entropy: 2.79566
Value Function Loss: 0.00869

Mean KL Divergence: 0.00613
SB3 Clip Fraction: 0.05695
Policy Update Magnitude: 0.31076
Value Function Update Magnitude: 0.28571

Collected Steps per Second: 22,040.69267
Overall Steps per Second: 10,654.69435

Timestep Collection Time: 2.26953
Timestep Consumption Time: 2.42530
PPO Batch Consumption Time: 0.27797
Total Iteration Time: 4.69483

Cumulative Model Updates: 261,554
Cumulative Timesteps: 2,181,921,370

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 74,411.29929
Policy Entropy: 2.79113
Value Function Loss: 0.00896

Mean KL Divergence: 0.00701
SB3 Clip Fraction: 0.06270
Policy Update Magnitude: 0.27741
Value Function Update Magnitude: 0.27588

Collected Steps per Second: 22,088.14274
Overall Steps per Second: 10,509.64175

Timestep Collection Time: 2.26375
Timestep Consumption Time: 2.49398
PPO Batch Consumption Time: 0.29212
Total Iteration Time: 4.75773

Cumulative Model Updates: 261,560
Cumulative Timesteps: 2,181,971,372

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2181971372...
Checkpoint 2181971372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 116,828.70031
Policy Entropy: 2.74573
Value Function Loss: 0.01115

Mean KL Divergence: 0.00644
SB3 Clip Fraction: 0.06125
Policy Update Magnitude: 0.28986
Value Function Update Magnitude: 0.27919

Collected Steps per Second: 22,179.23270
Overall Steps per Second: 10,555.39507

Timestep Collection Time: 2.25445
Timestep Consumption Time: 2.48265
PPO Batch Consumption Time: 0.28778
Total Iteration Time: 4.73710

Cumulative Model Updates: 261,566
Cumulative Timesteps: 2,182,021,374

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99,579.60652
Policy Entropy: 2.74686
Value Function Loss: 0.01153

Mean KL Divergence: 0.00662
SB3 Clip Fraction: 0.06112
Policy Update Magnitude: 0.30563
Value Function Update Magnitude: 0.31922

Collected Steps per Second: 21,554.27134
Overall Steps per Second: 10,536.26679

Timestep Collection Time: 2.32084
Timestep Consumption Time: 2.42695
PPO Batch Consumption Time: 0.27680
Total Iteration Time: 4.74779

Cumulative Model Updates: 261,572
Cumulative Timesteps: 2,182,071,398

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2182071398...
Checkpoint 2182071398 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 103,024.45288
Policy Entropy: 2.73919
Value Function Loss: 0.01229

Mean KL Divergence: 0.00693
SB3 Clip Fraction: 0.06360
Policy Update Magnitude: 0.31163
Value Function Update Magnitude: 0.35359

Collected Steps per Second: 21,562.73747
Overall Steps per Second: 10,548.69153

Timestep Collection Time: 2.32086
Timestep Consumption Time: 2.42324
PPO Batch Consumption Time: 0.27914
Total Iteration Time: 4.74410

Cumulative Model Updates: 261,578
Cumulative Timesteps: 2,182,121,442

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88,853.53575
Policy Entropy: 2.77507
Value Function Loss: 0.01237

Mean KL Divergence: 0.00668
SB3 Clip Fraction: 0.06177
Policy Update Magnitude: 0.31400
Value Function Update Magnitude: 0.37412

Collected Steps per Second: 21,750.87122
Overall Steps per Second: 10,448.07777

Timestep Collection Time: 2.30005
Timestep Consumption Time: 2.48820
PPO Batch Consumption Time: 0.28839
Total Iteration Time: 4.78825

Cumulative Model Updates: 261,584
Cumulative Timesteps: 2,182,171,470

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2182171470...
Checkpoint 2182171470 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 73,695.83795
Policy Entropy: 2.77537
Value Function Loss: 0.01110

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.07850
Policy Update Magnitude: 0.30108
Value Function Update Magnitude: 0.38655

Collected Steps per Second: 20,571.24590
Overall Steps per Second: 10,285.74902

Timestep Collection Time: 2.43126
Timestep Consumption Time: 2.43120
PPO Batch Consumption Time: 0.29310
Total Iteration Time: 4.86246

Cumulative Model Updates: 261,590
Cumulative Timesteps: 2,182,221,484

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93,379.39160
Policy Entropy: 2.75309
Value Function Loss: 0.01202

Mean KL Divergence: 0.01082
SB3 Clip Fraction: 0.08435
Policy Update Magnitude: 0.31019
Value Function Update Magnitude: 0.38027

Collected Steps per Second: 21,142.86538
Overall Steps per Second: 10,446.87502

Timestep Collection Time: 2.36562
Timestep Consumption Time: 2.42203
PPO Batch Consumption Time: 0.29266
Total Iteration Time: 4.78765

Cumulative Model Updates: 261,596
Cumulative Timesteps: 2,182,271,500

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2182271500...
Checkpoint 2182271500 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 92,646.74636
Policy Entropy: 2.70759
Value Function Loss: 0.01263

Mean KL Divergence: 0.01109
SB3 Clip Fraction: 0.08395
Policy Update Magnitude: 0.33137
Value Function Update Magnitude: 0.41052

Collected Steps per Second: 21,449.00722
Overall Steps per Second: 10,658.77555

Timestep Collection Time: 2.33148
Timestep Consumption Time: 2.36024
PPO Batch Consumption Time: 0.27522
Total Iteration Time: 4.69172

Cumulative Model Updates: 261,602
Cumulative Timesteps: 2,182,321,508

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 105,564.50713
Policy Entropy: 2.68803
Value Function Loss: 0.01364

Mean KL Divergence: 0.01372
SB3 Clip Fraction: 0.09543
Policy Update Magnitude: 0.33476
Value Function Update Magnitude: 0.43891

Collected Steps per Second: 21,549.88140
Overall Steps per Second: 10,391.70044

Timestep Collection Time: 2.32038
Timestep Consumption Time: 2.49153
PPO Batch Consumption Time: 0.29224
Total Iteration Time: 4.81192

Cumulative Model Updates: 261,608
Cumulative Timesteps: 2,182,371,512

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2182371512...
Checkpoint 2182371512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 174,832.90679
Policy Entropy: 2.71694
Value Function Loss: 0.01253

Mean KL Divergence: 0.01103
SB3 Clip Fraction: 0.08670
Policy Update Magnitude: 0.32675
Value Function Update Magnitude: 0.39970

Collected Steps per Second: 21,784.45209
Overall Steps per Second: 10,653.91887

Timestep Collection Time: 2.29687
Timestep Consumption Time: 2.39962
PPO Batch Consumption Time: 0.27774
Total Iteration Time: 4.69649

Cumulative Model Updates: 261,614
Cumulative Timesteps: 2,182,421,548

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 128,584.75357
Policy Entropy: 2.74046
Value Function Loss: 0.01248

Mean KL Divergence: 0.00713
SB3 Clip Fraction: 0.06877
Policy Update Magnitude: 0.31006
Value Function Update Magnitude: 0.35099

Collected Steps per Second: 21,146.57581
Overall Steps per Second: 10,435.75396

Timestep Collection Time: 2.36530
Timestep Consumption Time: 2.42765
PPO Batch Consumption Time: 0.28341
Total Iteration Time: 4.79295

Cumulative Model Updates: 261,620
Cumulative Timesteps: 2,182,471,566

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2182471566...
Checkpoint 2182471566 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 99,846.86264
Policy Entropy: 2.72978
Value Function Loss: 0.01099

Mean KL Divergence: 0.00651
SB3 Clip Fraction: 0.06292
Policy Update Magnitude: 0.29631
Value Function Update Magnitude: 0.31447

Collected Steps per Second: 21,444.99780
Overall Steps per Second: 10,532.99435

Timestep Collection Time: 2.33388
Timestep Consumption Time: 2.41786
PPO Batch Consumption Time: 0.27746
Total Iteration Time: 4.75174

Cumulative Model Updates: 261,626
Cumulative Timesteps: 2,182,521,616

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88,171.98404
Policy Entropy: 2.74657
Value Function Loss: 0.01085

Mean KL Divergence: 0.00729
SB3 Clip Fraction: 0.06835
Policy Update Magnitude: 0.29536
Value Function Update Magnitude: 0.30582

Collected Steps per Second: 21,734.73415
Overall Steps per Second: 10,587.60174

Timestep Collection Time: 2.30185
Timestep Consumption Time: 2.42349
PPO Batch Consumption Time: 0.27673
Total Iteration Time: 4.72534

Cumulative Model Updates: 261,632
Cumulative Timesteps: 2,182,571,646

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2182571646...
Checkpoint 2182571646 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 88,171.98404
Policy Entropy: 2.75425
Value Function Loss: 0.00931

Mean KL Divergence: 0.00705
SB3 Clip Fraction: 0.06481
Policy Update Magnitude: 0.28109
Value Function Update Magnitude: 0.28287

Collected Steps per Second: 21,750.57892
Overall Steps per Second: 10,546.40682

Timestep Collection Time: 2.29953
Timestep Consumption Time: 2.44294
PPO Batch Consumption Time: 0.27846
Total Iteration Time: 4.74247

Cumulative Model Updates: 261,638
Cumulative Timesteps: 2,182,621,662

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88,171.98404
Policy Entropy: 2.74034
Value Function Loss: 0.00932

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.06738
Policy Update Magnitude: 0.28411
Value Function Update Magnitude: 0.27145

Collected Steps per Second: 22,097.80348
Overall Steps per Second: 10,470.17210

Timestep Collection Time: 2.26366
Timestep Consumption Time: 2.51391
PPO Batch Consumption Time: 0.28884
Total Iteration Time: 4.77757

Cumulative Model Updates: 261,644
Cumulative Timesteps: 2,182,671,684

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2182671684...
Checkpoint 2182671684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 88,171.98404
Policy Entropy: 2.73287
Value Function Loss: 0.00817

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.07447
Policy Update Magnitude: 0.28323
Value Function Update Magnitude: 0.26770

Collected Steps per Second: 21,894.94246
Overall Steps per Second: 10,615.17599

Timestep Collection Time: 2.28363
Timestep Consumption Time: 2.42661
PPO Batch Consumption Time: 0.27877
Total Iteration Time: 4.71024

Cumulative Model Updates: 261,650
Cumulative Timesteps: 2,182,721,684

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88,171.98404
Policy Entropy: 2.71979
Value Function Loss: 0.00809

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.07124
Policy Update Magnitude: 0.27383
Value Function Update Magnitude: 0.25507

Collected Steps per Second: 21,993.85082
Overall Steps per Second: 10,465.74578

Timestep Collection Time: 2.27364
Timestep Consumption Time: 2.50443
PPO Batch Consumption Time: 0.29010
Total Iteration Time: 4.77806

Cumulative Model Updates: 261,656
Cumulative Timesteps: 2,182,771,690

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2182771690...
Checkpoint 2182771690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89,749.19350
Policy Entropy: 2.73177
Value Function Loss: 0.00882

Mean KL Divergence: 0.00680
SB3 Clip Fraction: 0.06611
Policy Update Magnitude: 0.27210
Value Function Update Magnitude: 0.23145

Collected Steps per Second: 21,953.31120
Overall Steps per Second: 10,624.98810

Timestep Collection Time: 2.27929
Timestep Consumption Time: 2.43017
PPO Batch Consumption Time: 0.27831
Total Iteration Time: 4.70946

Cumulative Model Updates: 261,662
Cumulative Timesteps: 2,182,821,728

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89,749.19350
Policy Entropy: 2.74170
Value Function Loss: 0.00861

Mean KL Divergence: 0.00642
SB3 Clip Fraction: 0.06317
Policy Update Magnitude: 0.26531
Value Function Update Magnitude: 0.23472

Collected Steps per Second: 22,164.16765
Overall Steps per Second: 10,497.39055

Timestep Collection Time: 2.25634
Timestep Consumption Time: 2.50770
PPO Batch Consumption Time: 0.29338
Total Iteration Time: 4.76404

Cumulative Model Updates: 261,668
Cumulative Timesteps: 2,182,871,738

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2182871738...
Checkpoint 2182871738 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84,198.43778
Policy Entropy: 2.74334
Value Function Loss: 0.00891

Mean KL Divergence: 0.00662
SB3 Clip Fraction: 0.06148
Policy Update Magnitude: 0.26158
Value Function Update Magnitude: 0.22777

Collected Steps per Second: 22,068.76012
Overall Steps per Second: 10,691.37776

Timestep Collection Time: 2.26710
Timestep Consumption Time: 2.41256
PPO Batch Consumption Time: 0.27619
Total Iteration Time: 4.67966

Cumulative Model Updates: 261,674
Cumulative Timesteps: 2,182,921,770

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81,114.92701
Policy Entropy: 2.73434
Value Function Loss: 0.00939

Mean KL Divergence: 0.00666
SB3 Clip Fraction: 0.06179
Policy Update Magnitude: 0.26455
Value Function Update Magnitude: 0.22238

Collected Steps per Second: 20,871.19129
Overall Steps per Second: 10,386.22370

Timestep Collection Time: 2.39574
Timestep Consumption Time: 2.41852
PPO Batch Consumption Time: 0.28808
Total Iteration Time: 4.81426

Cumulative Model Updates: 261,680
Cumulative Timesteps: 2,182,971,772

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2182971772...
Checkpoint 2182971772 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 99,975.73871
Policy Entropy: 2.74065
Value Function Loss: 0.00958

Mean KL Divergence: 0.00641
SB3 Clip Fraction: 0.05900
Policy Update Magnitude: 0.27318
Value Function Update Magnitude: 0.23434

Collected Steps per Second: 21,144.88238
Overall Steps per Second: 10,590.67637

Timestep Collection Time: 2.36634
Timestep Consumption Time: 2.35819
PPO Batch Consumption Time: 0.27901
Total Iteration Time: 4.72453

Cumulative Model Updates: 261,686
Cumulative Timesteps: 2,183,021,808

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 110,874.93000
Policy Entropy: 2.75224
Value Function Loss: 0.00862

Mean KL Divergence: 0.00665
SB3 Clip Fraction: 0.06174
Policy Update Magnitude: 0.26847
Value Function Update Magnitude: 0.24648

Collected Steps per Second: 21,009.16952
Overall Steps per Second: 10,596.40552

Timestep Collection Time: 2.38010
Timestep Consumption Time: 2.33886
PPO Batch Consumption Time: 0.27686
Total Iteration Time: 4.71896

Cumulative Model Updates: 261,692
Cumulative Timesteps: 2,183,071,812

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2183071812...
Checkpoint 2183071812 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 134,469.55123
Policy Entropy: 2.75584
Value Function Loss: 0.00843

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.08214
Policy Update Magnitude: 0.26537
Value Function Update Magnitude: 0.24400

Collected Steps per Second: 21,019.94574
Overall Steps per Second: 10,466.77321

Timestep Collection Time: 2.37888
Timestep Consumption Time: 2.39852
PPO Batch Consumption Time: 0.27812
Total Iteration Time: 4.77740

Cumulative Model Updates: 261,698
Cumulative Timesteps: 2,183,121,816

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 110,605.69123
Policy Entropy: 2.73059
Value Function Loss: 0.00884

Mean KL Divergence: 0.01337
SB3 Clip Fraction: 0.10534
Policy Update Magnitude: 0.26361
Value Function Update Magnitude: 0.23663

Collected Steps per Second: 21,626.93677
Overall Steps per Second: 10,536.94836

Timestep Collection Time: 2.31424
Timestep Consumption Time: 2.43571
PPO Batch Consumption Time: 0.27904
Total Iteration Time: 4.74995

Cumulative Model Updates: 261,704
Cumulative Timesteps: 2,183,171,866

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 2183171866...
Checkpoint 2183171866 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 129,580.70327
Policy Entropy: 2.69465
Value Function Loss: 0.01137

Mean KL Divergence: 0.01779
SB3 Clip Fraction: 0.13130
Policy Update Magnitude: 0.28503
Value Function Update Magnitude: 0.26925

Collected Steps per Second: 21,814.25269
Overall Steps per Second: 10,551.61506

Timestep Collection Time: 2.29336
Timestep Consumption Time: 2.44790
PPO Batch Consumption Time: 0.27831
Total Iteration Time: 4.74126

Cumulative Model Updates: 261,710
Cumulative Timesteps: 2,183,221,894

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 177,096.17963
Policy Entropy: 2.70510
Value Function Loss: 0.01281

Mean KL Divergence: 0.01287
SB3 Clip Fraction: 0.10462
Policy Update Magnitude: 0.30166
Value Function Update Magnitude: 0.28880

Collected Steps per Second: 22,107.61698
Overall Steps per Second: 10,518.05622

Timestep Collection Time: 2.26230
Timestep Consumption Time: 2.49276
PPO Batch Consumption Time: 0.28667
Total Iteration Time: 4.75506

Cumulative Model Updates: 261,716
Cumulative Timesteps: 2,183,271,908

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2183271908...
Checkpoint 2183271908 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 101,216.42935
Policy Entropy: 2.70474
Value Function Loss: 0.01269

Mean KL Divergence: 0.01119
SB3 Clip Fraction: 0.09491
Policy Update Magnitude: 0.31557
Value Function Update Magnitude: 0.31705

Collected Steps per Second: 22,063.86939
Overall Steps per Second: 10,627.05532

Timestep Collection Time: 2.26715
Timestep Consumption Time: 2.43990
PPO Batch Consumption Time: 0.27957
Total Iteration Time: 4.70704

Cumulative Model Updates: 261,722
Cumulative Timesteps: 2,183,321,930

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97,408.46160
Policy Entropy: 2.70634
Value Function Loss: 0.01295

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.08580
Policy Update Magnitude: 0.31785
Value Function Update Magnitude: 0.32839

Collected Steps per Second: 21,912.31159
Overall Steps per Second: 10,472.92201

Timestep Collection Time: 2.28264
Timestep Consumption Time: 2.49329
PPO Batch Consumption Time: 0.29057
Total Iteration Time: 4.77594

Cumulative Model Updates: 261,728
Cumulative Timesteps: 2,183,371,948

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2183371948...
Checkpoint 2183371948 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 109,509.74768
Policy Entropy: 2.68643
Value Function Loss: 0.01155

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.06929
Policy Update Magnitude: 0.31288
Value Function Update Magnitude: 0.32912

Collected Steps per Second: 21,870.42945
Overall Steps per Second: 10,617.73881

Timestep Collection Time: 2.28665
Timestep Consumption Time: 2.42339
PPO Batch Consumption Time: 0.27843
Total Iteration Time: 4.71004

Cumulative Model Updates: 261,734
Cumulative Timesteps: 2,183,421,958

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89,630.06781
Policy Entropy: 2.70188
Value Function Loss: 0.01113

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.06854
Policy Update Magnitude: 0.30628
Value Function Update Magnitude: 0.32639

Collected Steps per Second: 21,952.80183
Overall Steps per Second: 10,491.17433

Timestep Collection Time: 2.27761
Timestep Consumption Time: 2.48830
PPO Batch Consumption Time: 0.28940
Total Iteration Time: 4.76591

Cumulative Model Updates: 261,740
Cumulative Timesteps: 2,183,471,958

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2183471958...
Checkpoint 2183471958 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89,630.06781
Policy Entropy: 2.72449
Value Function Loss: 0.00929

Mean KL Divergence: 0.00664
SB3 Clip Fraction: 0.06353
Policy Update Magnitude: 0.28672
Value Function Update Magnitude: 0.29235

Collected Steps per Second: 21,087.02737
Overall Steps per Second: 10,289.92409

Timestep Collection Time: 2.37312
Timestep Consumption Time: 2.49009
PPO Batch Consumption Time: 0.29241
Total Iteration Time: 4.86320

Cumulative Model Updates: 261,746
Cumulative Timesteps: 2,183,522,000

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 112,293.70200
Policy Entropy: 2.73349
Value Function Loss: 0.01069

Mean KL Divergence: 0.00611
SB3 Clip Fraction: 0.05684
Policy Update Magnitude: 0.28812
Value Function Update Magnitude: 0.27603

Collected Steps per Second: 20,973.91445
Overall Steps per Second: 10,362.86779

Timestep Collection Time: 2.38458
Timestep Consumption Time: 2.44169
PPO Batch Consumption Time: 0.29178
Total Iteration Time: 4.82627

Cumulative Model Updates: 261,752
Cumulative Timesteps: 2,183,572,014

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2183572014...
Checkpoint 2183572014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 129,188.12336
Policy Entropy: 2.71689
Value Function Loss: 0.01032

Mean KL Divergence: 0.00659
SB3 Clip Fraction: 0.06214
Policy Update Magnitude: 0.30172
Value Function Update Magnitude: 0.27260

Collected Steps per Second: 20,665.04558
Overall Steps per Second: 10,321.99574

Timestep Collection Time: 2.42022
Timestep Consumption Time: 2.42516
PPO Batch Consumption Time: 0.29308
Total Iteration Time: 4.84538

Cumulative Model Updates: 261,758
Cumulative Timesteps: 2,183,622,028

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 169,679.68655
Policy Entropy: 2.72319
Value Function Loss: 0.01133

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.07695
Policy Update Magnitude: 0.29941
Value Function Update Magnitude: 0.27658

Collected Steps per Second: 21,640.87280
Overall Steps per Second: 10,768.45115

Timestep Collection Time: 2.31118
Timestep Consumption Time: 2.33350
PPO Batch Consumption Time: 0.27614
Total Iteration Time: 4.64468

Cumulative Model Updates: 261,764
Cumulative Timesteps: 2,183,672,044

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2183672044...
Checkpoint 2183672044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 169,165.85368
Policy Entropy: 2.69984
Value Function Loss: 0.01084

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.07651
Policy Update Magnitude: 0.30549
Value Function Update Magnitude: 0.28640

Collected Steps per Second: 20,978.67529
Overall Steps per Second: 10,209.17463

Timestep Collection Time: 2.38499
Timestep Consumption Time: 2.51589
PPO Batch Consumption Time: 0.28806
Total Iteration Time: 4.90089

Cumulative Model Updates: 261,770
Cumulative Timesteps: 2,183,722,078

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 155,567.18372
Policy Entropy: 2.72897
Value Function Loss: 0.00982

Mean KL Divergence: 0.00730
SB3 Clip Fraction: 0.06475
Policy Update Magnitude: 0.29835
Value Function Update Magnitude: 0.32830

Collected Steps per Second: 22,408.15131
Overall Steps per Second: 10,611.16329

Timestep Collection Time: 2.23187
Timestep Consumption Time: 2.48128
PPO Batch Consumption Time: 0.28944
Total Iteration Time: 4.71315

Cumulative Model Updates: 261,776
Cumulative Timesteps: 2,183,772,090

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2183772090...
Checkpoint 2183772090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 116,614.68366
Policy Entropy: 2.73656
Value Function Loss: 0.01030

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.06650
Policy Update Magnitude: 0.30037
Value Function Update Magnitude: 0.32274

Collected Steps per Second: 22,073.26839
Overall Steps per Second: 10,536.53070

Timestep Collection Time: 2.26582
Timestep Consumption Time: 2.48091
PPO Batch Consumption Time: 0.29286
Total Iteration Time: 4.74672

Cumulative Model Updates: 261,782
Cumulative Timesteps: 2,183,822,104

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 101,727.69569
Policy Entropy: 2.76390
Value Function Loss: 0.01038

Mean KL Divergence: 0.00611
SB3 Clip Fraction: 0.05834
Policy Update Magnitude: 0.28875
Value Function Update Magnitude: 0.27705

Collected Steps per Second: 22,358.89168
Overall Steps per Second: 10,574.22811

Timestep Collection Time: 2.23732
Timestep Consumption Time: 2.49343
PPO Batch Consumption Time: 0.29086
Total Iteration Time: 4.73075

Cumulative Model Updates: 261,788
Cumulative Timesteps: 2,183,872,128

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2183872128...
Checkpoint 2183872128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 82,196.52891
Policy Entropy: 2.76851
Value Function Loss: 0.01183

Mean KL Divergence: 0.00605
SB3 Clip Fraction: 0.05685
Policy Update Magnitude: 0.28467
Value Function Update Magnitude: 0.26222

Collected Steps per Second: 22,069.94046
Overall Steps per Second: 10,496.18243

Timestep Collection Time: 2.26589
Timestep Consumption Time: 2.49851
PPO Batch Consumption Time: 0.29196
Total Iteration Time: 4.76440

Cumulative Model Updates: 261,794
Cumulative Timesteps: 2,183,922,136

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84,257.82290
Policy Entropy: 2.75553
Value Function Loss: 0.01215

Mean KL Divergence: 0.00644
SB3 Clip Fraction: 0.06199
Policy Update Magnitude: 0.29772
Value Function Update Magnitude: 0.30333

Collected Steps per Second: 22,178.50218
Overall Steps per Second: 10,532.89464

Timestep Collection Time: 2.25516
Timestep Consumption Time: 2.49340
PPO Batch Consumption Time: 0.29246
Total Iteration Time: 4.74855

Cumulative Model Updates: 261,800
Cumulative Timesteps: 2,183,972,152

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2183972152...
Checkpoint 2183972152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 59,057.30141
Policy Entropy: 2.73649
Value Function Loss: 0.01226

Mean KL Divergence: 0.00699
SB3 Clip Fraction: 0.06372
Policy Update Magnitude: 0.30851
Value Function Update Magnitude: 0.33771

Collected Steps per Second: 21,977.15642
Overall Steps per Second: 10,553.93265

Timestep Collection Time: 2.27509
Timestep Consumption Time: 2.46248
PPO Batch Consumption Time: 0.28477
Total Iteration Time: 4.73757

Cumulative Model Updates: 261,806
Cumulative Timesteps: 2,184,022,152

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89,970.57935
Policy Entropy: 2.71273
Value Function Loss: 0.01254

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.08307
Policy Update Magnitude: 0.31873
Value Function Update Magnitude: 0.32800

Collected Steps per Second: 21,678.86249
Overall Steps per Second: 10,497.35131

Timestep Collection Time: 2.30759
Timestep Consumption Time: 2.45799
PPO Batch Consumption Time: 0.28483
Total Iteration Time: 4.76558

Cumulative Model Updates: 261,812
Cumulative Timesteps: 2,184,072,178

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2184072178...
Checkpoint 2184072178 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 132,357.81079
Policy Entropy: 2.72140
Value Function Loss: 0.01147

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.08879
Policy Update Magnitude: 0.32027
Value Function Update Magnitude: 0.30435

Collected Steps per Second: 21,603.27642
Overall Steps per Second: 10,557.55476

Timestep Collection Time: 2.31465
Timestep Consumption Time: 2.42168
PPO Batch Consumption Time: 0.27833
Total Iteration Time: 4.73632

Cumulative Model Updates: 261,818
Cumulative Timesteps: 2,184,122,182

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 121,092.10216
Policy Entropy: 2.74172
Value Function Loss: 0.01025

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.08671
Policy Update Magnitude: 0.30611
Value Function Update Magnitude: 0.30119

Collected Steps per Second: 20,799.95589
Overall Steps per Second: 10,487.35773

Timestep Collection Time: 2.40501
Timestep Consumption Time: 2.36493
PPO Batch Consumption Time: 0.27887
Total Iteration Time: 4.76993

Cumulative Model Updates: 261,824
Cumulative Timesteps: 2,184,172,206

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2184172206...
Checkpoint 2184172206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 121,092.10216
Policy Entropy: 2.74654
Value Function Loss: 0.00941

Mean KL Divergence: 0.00783
SB3 Clip Fraction: 0.07267
Policy Update Magnitude: 0.29560
Value Function Update Magnitude: 0.28468

Collected Steps per Second: 20,632.37099
Overall Steps per Second: 10,290.51964

Timestep Collection Time: 2.42405
Timestep Consumption Time: 2.43615
PPO Batch Consumption Time: 0.29318
Total Iteration Time: 4.86020

Cumulative Model Updates: 261,830
Cumulative Timesteps: 2,184,222,220

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 128,329.12735
Policy Entropy: 2.73679
Value Function Loss: 0.00942

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.07291
Policy Update Magnitude: 0.28828
Value Function Update Magnitude: 0.26971

Collected Steps per Second: 21,008.72101
Overall Steps per Second: 10,386.50615

Timestep Collection Time: 2.38092
Timestep Consumption Time: 2.43495
PPO Batch Consumption Time: 0.29275
Total Iteration Time: 4.81586

Cumulative Model Updates: 261,836
Cumulative Timesteps: 2,184,272,240

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2184272240...
Checkpoint 2184272240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 112,597.31455
Policy Entropy: 2.71148
Value Function Loss: 0.01065

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.07814
Policy Update Magnitude: 0.28724
Value Function Update Magnitude: 0.26309

Collected Steps per Second: 20,946.74548
Overall Steps per Second: 10,144.34503

Timestep Collection Time: 2.38729
Timestep Consumption Time: 2.54215
PPO Batch Consumption Time: 0.29807
Total Iteration Time: 4.92945

Cumulative Model Updates: 261,842
Cumulative Timesteps: 2,184,322,246

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89,814.40170
Policy Entropy: 2.72232
Value Function Loss: 0.01160

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.08017
Policy Update Magnitude: 0.29952
Value Function Update Magnitude: 0.27043

Collected Steps per Second: 22,167.57324
Overall Steps per Second: 10,532.44751

Timestep Collection Time: 2.25699
Timestep Consumption Time: 2.49328
PPO Batch Consumption Time: 0.29212
Total Iteration Time: 4.75027

Cumulative Model Updates: 261,848
Cumulative Timesteps: 2,184,372,278

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2184372278...
Checkpoint 2184372278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84,343.88134
Policy Entropy: 2.73685
Value Function Loss: 0.01228

Mean KL Divergence: 0.00751
SB3 Clip Fraction: 0.06886
Policy Update Magnitude: 0.30566
Value Function Update Magnitude: 0.27897

Collected Steps per Second: 22,084.80877
Overall Steps per Second: 10,598.26366

Timestep Collection Time: 2.26463
Timestep Consumption Time: 2.45444
PPO Batch Consumption Time: 0.28885
Total Iteration Time: 4.71907

Cumulative Model Updates: 261,854
Cumulative Timesteps: 2,184,422,292

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 98,448.66441
Policy Entropy: 2.76472
Value Function Loss: 0.01080

Mean KL Divergence: 0.00671
SB3 Clip Fraction: 0.06292
Policy Update Magnitude: 0.29802
Value Function Update Magnitude: 0.30098

Collected Steps per Second: 22,252.07223
Overall Steps per Second: 10,482.01418

Timestep Collection Time: 2.24716
Timestep Consumption Time: 2.52330
PPO Batch Consumption Time: 0.29300
Total Iteration Time: 4.77046

Cumulative Model Updates: 261,860
Cumulative Timesteps: 2,184,472,296

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2184472296...
Checkpoint 2184472296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 80,711.08858
Policy Entropy: 2.76311
Value Function Loss: 0.01022

Mean KL Divergence: 0.00687
SB3 Clip Fraction: 0.06571
Policy Update Magnitude: 0.29605
Value Function Update Magnitude: 0.32460

Collected Steps per Second: 21,979.13951
Overall Steps per Second: 10,662.57208

Timestep Collection Time: 2.27543
Timestep Consumption Time: 2.41500
PPO Batch Consumption Time: 0.27650
Total Iteration Time: 4.69043

Cumulative Model Updates: 261,866
Cumulative Timesteps: 2,184,522,308

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 74,963.20225
Policy Entropy: 2.74081
Value Function Loss: 0.01029

Mean KL Divergence: 0.00615
SB3 Clip Fraction: 0.05797
Policy Update Magnitude: 0.29793
Value Function Update Magnitude: 0.32859

Collected Steps per Second: 21,245.74241
Overall Steps per Second: 10,448.96136

Timestep Collection Time: 2.35341
Timestep Consumption Time: 2.43175
PPO Batch Consumption Time: 0.27702
Total Iteration Time: 4.78516

Cumulative Model Updates: 261,872
Cumulative Timesteps: 2,184,572,308

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2184572308...
Checkpoint 2184572308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 75,050.75061
Policy Entropy: 2.73103
Value Function Loss: 0.01024

Mean KL Divergence: 0.00555
SB3 Clip Fraction: 0.05147
Policy Update Magnitude: 0.29560
Value Function Update Magnitude: 0.30615

Collected Steps per Second: 21,454.20161
Overall Steps per Second: 10,521.54319

Timestep Collection Time: 2.33129
Timestep Consumption Time: 2.42238
PPO Batch Consumption Time: 0.27792
Total Iteration Time: 4.75368

Cumulative Model Updates: 261,878
Cumulative Timesteps: 2,184,622,324

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93,215.67758
Policy Entropy: 2.72038
Value Function Loss: 0.01093

Mean KL Divergence: 0.00563
SB3 Clip Fraction: 0.05495
Policy Update Magnitude: 0.30095
Value Function Update Magnitude: 0.29113

Collected Steps per Second: 21,695.16532
Overall Steps per Second: 10,591.71992

Timestep Collection Time: 2.30558
Timestep Consumption Time: 2.41697
PPO Batch Consumption Time: 0.27629
Total Iteration Time: 4.72256

Cumulative Model Updates: 261,884
Cumulative Timesteps: 2,184,672,344

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2184672344...
Checkpoint 2184672344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 133,655.86043
Policy Entropy: 2.73921
Value Function Loss: 0.01083

Mean KL Divergence: 0.00600
SB3 Clip Fraction: 0.05922
Policy Update Magnitude: 0.30805
Value Function Update Magnitude: 0.30899

Collected Steps per Second: 21,592.47712
Overall Steps per Second: 10,544.53041

Timestep Collection Time: 2.31710
Timestep Consumption Time: 2.42773
PPO Batch Consumption Time: 0.27860
Total Iteration Time: 4.74483

Cumulative Model Updates: 261,890
Cumulative Timesteps: 2,184,722,376

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 184,509.47407
Policy Entropy: 2.71724
Value Function Loss: 0.01374

Mean KL Divergence: 0.00708
SB3 Clip Fraction: 0.06561
Policy Update Magnitude: 0.31615
Value Function Update Magnitude: 0.30304

Collected Steps per Second: 21,382.34285
Overall Steps per Second: 10,453.00195

Timestep Collection Time: 2.33866
Timestep Consumption Time: 2.44523
PPO Batch Consumption Time: 0.28696
Total Iteration Time: 4.78389

Cumulative Model Updates: 261,896
Cumulative Timesteps: 2,184,772,382

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2184772382...
Checkpoint 2184772382 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 113,374.99367
Policy Entropy: 2.70349
Value Function Loss: 0.01373

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.07662
Policy Update Magnitude: 0.32908
Value Function Update Magnitude: 0.32495

Collected Steps per Second: 21,532.03813
Overall Steps per Second: 10,703.99993

Timestep Collection Time: 2.32333
Timestep Consumption Time: 2.35025
PPO Batch Consumption Time: 0.27687
Total Iteration Time: 4.67358

Cumulative Model Updates: 261,902
Cumulative Timesteps: 2,184,822,408

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 94,623.22896
Policy Entropy: 2.71765
Value Function Loss: 0.01213

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.07749
Policy Update Magnitude: 0.32507
Value Function Update Magnitude: 0.34091

Collected Steps per Second: 21,709.92681
Overall Steps per Second: 10,601.92155

Timestep Collection Time: 2.30309
Timestep Consumption Time: 2.41303
PPO Batch Consumption Time: 0.28922
Total Iteration Time: 4.71613

Cumulative Model Updates: 261,908
Cumulative Timesteps: 2,184,872,408

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2184872408...
Checkpoint 2184872408 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 81,206.83556
Policy Entropy: 2.72773
Value Function Loss: 0.01002

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.07379
Policy Update Magnitude: 0.31002
Value Function Update Magnitude: 0.28275

Collected Steps per Second: 21,490.50308
Overall Steps per Second: 10,477.78406

Timestep Collection Time: 2.32791
Timestep Consumption Time: 2.44676
PPO Batch Consumption Time: 0.28873
Total Iteration Time: 4.77467

Cumulative Model Updates: 261,914
Cumulative Timesteps: 2,184,922,436

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88,257.32935
Policy Entropy: 2.73863
Value Function Loss: 0.00983

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.07437
Policy Update Magnitude: 0.29862
Value Function Update Magnitude: 0.26491

Collected Steps per Second: 22,684.56559
Overall Steps per Second: 10,845.97946

Timestep Collection Time: 2.20423
Timestep Consumption Time: 2.40596
PPO Batch Consumption Time: 0.27836
Total Iteration Time: 4.61019

Cumulative Model Updates: 261,920
Cumulative Timesteps: 2,184,972,438

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2184972438...
Checkpoint 2184972438 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 71,643.90288
Policy Entropy: 2.73789
Value Function Loss: 0.01138

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.06915
Policy Update Magnitude: 0.30075
Value Function Update Magnitude: 0.26627

Collected Steps per Second: 21,823.34463
Overall Steps per Second: 10,641.68071

Timestep Collection Time: 2.29149
Timestep Consumption Time: 2.40777
PPO Batch Consumption Time: 0.27836
Total Iteration Time: 4.69926

Cumulative Model Updates: 261,926
Cumulative Timesteps: 2,185,022,446

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62,715.36125
Policy Entropy: 2.75707
Value Function Loss: 0.01141

Mean KL Divergence: 0.00700
SB3 Clip Fraction: 0.06682
Policy Update Magnitude: 0.29721
Value Function Update Magnitude: 0.28725

Collected Steps per Second: 21,926.20506
Overall Steps per Second: 10,510.43774

Timestep Collection Time: 2.28174
Timestep Consumption Time: 2.47829
PPO Batch Consumption Time: 0.28599
Total Iteration Time: 4.76003

Cumulative Model Updates: 261,932
Cumulative Timesteps: 2,185,072,476

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2185072476...
Checkpoint 2185072476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 108,384.80122
Policy Entropy: 2.75207
Value Function Loss: 0.01161

Mean KL Divergence: 0.00672
SB3 Clip Fraction: 0.06330
Policy Update Magnitude: 0.29491
Value Function Update Magnitude: 0.31254

Collected Steps per Second: 21,475.12328
Overall Steps per Second: 10,548.42002

Timestep Collection Time: 2.32995
Timestep Consumption Time: 2.41351
PPO Batch Consumption Time: 0.27803
Total Iteration Time: 4.74346

Cumulative Model Updates: 261,938
Cumulative Timesteps: 2,185,122,512

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 110,533.02369
Policy Entropy: 2.74389
Value Function Loss: 0.01065

Mean KL Divergence: 0.00703
SB3 Clip Fraction: 0.06559
Policy Update Magnitude: 0.29681
Value Function Update Magnitude: 0.31270

Collected Steps per Second: 21,760.73222
Overall Steps per Second: 10,581.15715

Timestep Collection Time: 2.29772
Timestep Consumption Time: 2.42766
PPO Batch Consumption Time: 0.27708
Total Iteration Time: 4.72538

Cumulative Model Updates: 261,944
Cumulative Timesteps: 2,185,172,512

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2185172512...
Checkpoint 2185172512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 110,533.02369
Policy Entropy: 2.72347
Value Function Loss: 0.00965

Mean KL Divergence: 0.00723
SB3 Clip Fraction: 0.06680
Policy Update Magnitude: 0.29282
Value Function Update Magnitude: 0.29883

Collected Steps per Second: 21,257.28518
Overall Steps per Second: 10,284.40853

Timestep Collection Time: 2.35336
Timestep Consumption Time: 2.51090
PPO Batch Consumption Time: 0.29138
Total Iteration Time: 4.86426

Cumulative Model Updates: 261,950
Cumulative Timesteps: 2,185,222,538

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 98,469.51175
Policy Entropy: 2.69090
Value Function Loss: 0.00935

Mean KL Divergence: 0.00678
SB3 Clip Fraction: 0.06012
Policy Update Magnitude: 0.28946
Value Function Update Magnitude: 0.24151

Collected Steps per Second: 22,297.06382
Overall Steps per Second: 10,694.54852

Timestep Collection Time: 2.24343
Timestep Consumption Time: 2.43390
PPO Batch Consumption Time: 0.27738
Total Iteration Time: 4.67734

Cumulative Model Updates: 261,956
Cumulative Timesteps: 2,185,272,560

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2185272560...
Checkpoint 2185272560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 98,469.51175
Policy Entropy: 2.66740
Value Function Loss: 0.00944

Mean KL Divergence: 0.00680
SB3 Clip Fraction: 0.06417
Policy Update Magnitude: 0.29725
Value Function Update Magnitude: 0.23947

Collected Steps per Second: 21,771.40547
Overall Steps per Second: 10,584.45937

Timestep Collection Time: 2.29751
Timestep Consumption Time: 2.42829
PPO Batch Consumption Time: 0.27891
Total Iteration Time: 4.72580

Cumulative Model Updates: 261,962
Cumulative Timesteps: 2,185,322,580

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 187,249.85694
Policy Entropy: 2.65646
Value Function Loss: 0.01081

Mean KL Divergence: 0.00724
SB3 Clip Fraction: 0.06855
Policy Update Magnitude: 0.30996
Value Function Update Magnitude: 0.24770

Collected Steps per Second: 22,034.27804
Overall Steps per Second: 10,534.90612

Timestep Collection Time: 2.26965
Timestep Consumption Time: 2.47743
PPO Batch Consumption Time: 0.28673
Total Iteration Time: 4.74708

Cumulative Model Updates: 261,968
Cumulative Timesteps: 2,185,372,590

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2185372590...
Checkpoint 2185372590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 158,395.48514
Policy Entropy: 2.66265
Value Function Loss: 0.01163

Mean KL Divergence: 0.00733
SB3 Clip Fraction: 0.06629
Policy Update Magnitude: 0.32028
Value Function Update Magnitude: 0.29672

Collected Steps per Second: 22,075.49629
Overall Steps per Second: 10,648.53688

Timestep Collection Time: 2.26704
Timestep Consumption Time: 2.43276
PPO Batch Consumption Time: 0.27926
Total Iteration Time: 4.69980

Cumulative Model Updates: 261,974
Cumulative Timesteps: 2,185,422,636

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 112,905.31556
Policy Entropy: 2.69451
Value Function Loss: 0.01128

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.07619
Policy Update Magnitude: 0.31447
Value Function Update Magnitude: 0.31222

Collected Steps per Second: 22,289.96787
Overall Steps per Second: 10,511.85656

Timestep Collection Time: 2.24316
Timestep Consumption Time: 2.51337
PPO Batch Consumption Time: 0.29360
Total Iteration Time: 4.75653

Cumulative Model Updates: 261,980
Cumulative Timesteps: 2,185,472,636

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2185472636...
Checkpoint 2185472636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 92,771.45954
Policy Entropy: 2.71867
Value Function Loss: 0.01101

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.07344
Policy Update Magnitude: 0.29779
Value Function Update Magnitude: 0.29701

Collected Steps per Second: 22,051.95427
Overall Steps per Second: 10,610.59682

Timestep Collection Time: 2.26810
Timestep Consumption Time: 2.44568
PPO Batch Consumption Time: 0.27851
Total Iteration Time: 4.71378

Cumulative Model Updates: 261,986
Cumulative Timesteps: 2,185,522,652

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 103,117.74906
Policy Entropy: 2.74788
Value Function Loss: 0.01182

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.07847
Policy Update Magnitude: 0.29487
Value Function Update Magnitude: 0.29753

Collected Steps per Second: 21,519.69288
Overall Steps per Second: 10,518.07370

Timestep Collection Time: 2.32410
Timestep Consumption Time: 2.43095
PPO Batch Consumption Time: 0.27696
Total Iteration Time: 4.75505

Cumulative Model Updates: 261,992
Cumulative Timesteps: 2,185,572,666

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2185572666...
Checkpoint 2185572666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 100,703.51813
Policy Entropy: 2.74520
Value Function Loss: 0.01183

Mean KL Divergence: 0.00719
SB3 Clip Fraction: 0.06901
Policy Update Magnitude: 0.29994
Value Function Update Magnitude: 0.32466

Collected Steps per Second: 21,525.90546
Overall Steps per Second: 10,514.38700

Timestep Collection Time: 2.32473
Timestep Consumption Time: 2.43465
PPO Batch Consumption Time: 0.27828
Total Iteration Time: 4.75938

Cumulative Model Updates: 261,998
Cumulative Timesteps: 2,185,622,708

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 100,703.51813
Policy Entropy: 2.69333
Value Function Loss: 0.01173

Mean KL Divergence: 0.00732
SB3 Clip Fraction: 0.06828
Policy Update Magnitude: 0.30870
Value Function Update Magnitude: 0.34250

Collected Steps per Second: 21,810.71885
Overall Steps per Second: 10,511.93011

Timestep Collection Time: 2.29273
Timestep Consumption Time: 2.46435
PPO Batch Consumption Time: 0.28418
Total Iteration Time: 4.75707

Cumulative Model Updates: 262,004
Cumulative Timesteps: 2,185,672,714

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2185672714...
Checkpoint 2185672714 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 83,808.77291
Policy Entropy: 2.69642
Value Function Loss: 0.01185

Mean KL Divergence: 0.00604
SB3 Clip Fraction: 0.05842
Policy Update Magnitude: 0.30938
Value Function Update Magnitude: 0.33968

Collected Steps per Second: 21,640.14383
Overall Steps per Second: 10,568.33877

Timestep Collection Time: 2.31191
Timestep Consumption Time: 2.42204
PPO Batch Consumption Time: 0.27832
Total Iteration Time: 4.73395

Cumulative Model Updates: 262,010
Cumulative Timesteps: 2,185,722,744

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91,988.46715
Policy Entropy: 2.66585
Value Function Loss: 0.01167

Mean KL Divergence: 0.00584
SB3 Clip Fraction: 0.05462
Policy Update Magnitude: 0.32277
Value Function Update Magnitude: 0.34038

Collected Steps per Second: 21,491.75811
Overall Steps per Second: 10,434.70998

Timestep Collection Time: 2.32768
Timestep Consumption Time: 2.46651
PPO Batch Consumption Time: 0.27853
Total Iteration Time: 4.79419

Cumulative Model Updates: 262,016
Cumulative Timesteps: 2,185,772,770

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2185772770...
Checkpoint 2185772770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 80,077.20720
Policy Entropy: 2.66194
Value Function Loss: 0.01217

Mean KL Divergence: 0.00652
SB3 Clip Fraction: 0.06142
Policy Update Magnitude: 0.33210
Value Function Update Magnitude: 0.33068

Collected Steps per Second: 22,154.82782
Overall Steps per Second: 10,469.59917

Timestep Collection Time: 2.25802
Timestep Consumption Time: 2.52020
PPO Batch Consumption Time: 0.28896
Total Iteration Time: 4.77822

Cumulative Model Updates: 262,022
Cumulative Timesteps: 2,185,822,796

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56,438.91966
Policy Entropy: 2.62911
Value Function Loss: 0.01307

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.07074
Policy Update Magnitude: 0.33980
Value Function Update Magnitude: 0.33195

Collected Steps per Second: 22,418.67035
Overall Steps per Second: 10,697.47224

Timestep Collection Time: 2.23091
Timestep Consumption Time: 2.44440
PPO Batch Consumption Time: 0.27966
Total Iteration Time: 4.67531

Cumulative Model Updates: 262,028
Cumulative Timesteps: 2,185,872,810

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2185872810...
Checkpoint 2185872810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 88,043.30672
Policy Entropy: 2.63827
Value Function Loss: 0.01320

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.07092
Policy Update Magnitude: 0.33742
Value Function Update Magnitude: 0.33929

Collected Steps per Second: 22,094.08520
Overall Steps per Second: 10,635.55676

Timestep Collection Time: 2.26504
Timestep Consumption Time: 2.44031
PPO Batch Consumption Time: 0.27984
Total Iteration Time: 4.70535

Cumulative Model Updates: 262,034
Cumulative Timesteps: 2,185,922,854

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 117,577.16485
Policy Entropy: 2.65859
Value Function Loss: 0.01263

Mean KL Divergence: 0.00738
SB3 Clip Fraction: 0.06985
Policy Update Magnitude: 0.31829
Value Function Update Magnitude: 0.29716

Collected Steps per Second: 22,172.14326
Overall Steps per Second: 10,508.98484

Timestep Collection Time: 2.25653
Timestep Consumption Time: 2.50435
PPO Batch Consumption Time: 0.29300
Total Iteration Time: 4.76088

Cumulative Model Updates: 262,040
Cumulative Timesteps: 2,185,972,886

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2185972886...
Checkpoint 2185972886 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 133,476.27108
Policy Entropy: 2.68037
Value Function Loss: 0.01124

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.07534
Policy Update Magnitude: 0.30094
Value Function Update Magnitude: 0.26212

Collected Steps per Second: 22,074.77162
Overall Steps per Second: 10,672.15065

Timestep Collection Time: 2.26539
Timestep Consumption Time: 2.42045
PPO Batch Consumption Time: 0.27798
Total Iteration Time: 4.68584

Cumulative Model Updates: 262,046
Cumulative Timesteps: 2,186,022,894

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 123,718.63979
Policy Entropy: 2.71055
Value Function Loss: 0.01077

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.08416
Policy Update Magnitude: 0.30045
Value Function Update Magnitude: 0.24351

Collected Steps per Second: 22,108.69694
Overall Steps per Second: 10,523.57875

Timestep Collection Time: 2.26336
Timestep Consumption Time: 2.49167
PPO Batch Consumption Time: 0.29071
Total Iteration Time: 4.75504

Cumulative Model Updates: 262,052
Cumulative Timesteps: 2,186,072,934

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 2186072934...
Checkpoint 2186072934 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 81,850.00306
Policy Entropy: 2.71020
Value Function Loss: 0.01309

Mean KL Divergence: 0.01430
SB3 Clip Fraction: 0.10933
Policy Update Magnitude: 0.31012
Value Function Update Magnitude: 0.27834

Collected Steps per Second: 21,731.65292
Overall Steps per Second: 10,487.63961

Timestep Collection Time: 2.30226
Timestep Consumption Time: 2.46830
PPO Batch Consumption Time: 0.28509
Total Iteration Time: 4.77057

Cumulative Model Updates: 262,058
Cumulative Timesteps: 2,186,122,966

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 106,158.40697
Policy Entropy: 2.70325
Value Function Loss: 0.01235

Mean KL Divergence: 0.01288
SB3 Clip Fraction: 0.10169
Policy Update Magnitude: 0.31712
Value Function Update Magnitude: 0.31166

Collected Steps per Second: 21,124.23350
Overall Steps per Second: 10,408.55471

Timestep Collection Time: 2.36733
Timestep Consumption Time: 2.43718
PPO Batch Consumption Time: 0.27841
Total Iteration Time: 4.80451

Cumulative Model Updates: 262,064
Cumulative Timesteps: 2,186,172,974

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2186172974...
Checkpoint 2186172974 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 106,158.40697
Policy Entropy: 2.70285
Value Function Loss: 0.01215

Mean KL Divergence: 0.01162
SB3 Clip Fraction: 0.09470
Policy Update Magnitude: 0.31571
Value Function Update Magnitude: 0.29920

Collected Steps per Second: 20,966.20696
Overall Steps per Second: 10,215.51497

Timestep Collection Time: 2.38555
Timestep Consumption Time: 2.51053
PPO Batch Consumption Time: 0.27880
Total Iteration Time: 4.89608

Cumulative Model Updates: 262,070
Cumulative Timesteps: 2,186,222,990

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 130,600.14729
Policy Entropy: 2.70190
Value Function Loss: 0.01064

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.07905
Policy Update Magnitude: 0.30349
Value Function Update Magnitude: 0.27633

Collected Steps per Second: 21,327.91133
Overall Steps per Second: 10,443.63893

Timestep Collection Time: 2.34481
Timestep Consumption Time: 2.44375
PPO Batch Consumption Time: 0.27820
Total Iteration Time: 4.78856

Cumulative Model Updates: 262,076
Cumulative Timesteps: 2,186,273,000

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2186273000...
Checkpoint 2186273000 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 217,571.00539
Policy Entropy: 2.70064
Value Function Loss: 0.01125

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.07289
Policy Update Magnitude: 0.30762
Value Function Update Magnitude: 0.28155

Collected Steps per Second: 21,613.24056
Overall Steps per Second: 10,396.60585

Timestep Collection Time: 2.31358
Timestep Consumption Time: 2.49606
PPO Batch Consumption Time: 0.29144
Total Iteration Time: 4.80965

Cumulative Model Updates: 262,082
Cumulative Timesteps: 2,186,323,004

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 176,002.88772
Policy Entropy: 2.69183
Value Function Loss: 0.01080

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.07866
Policy Update Magnitude: 0.31441
Value Function Update Magnitude: 0.30626

Collected Steps per Second: 21,937.29648
Overall Steps per Second: 10,348.91325

Timestep Collection Time: 2.27959
Timestep Consumption Time: 2.55261
PPO Batch Consumption Time: 0.29336
Total Iteration Time: 4.83220

Cumulative Model Updates: 262,088
Cumulative Timesteps: 2,186,373,012

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2186373012...
Checkpoint 2186373012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 151,371.12086
Policy Entropy: 2.69637
Value Function Loss: 0.01008

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.07460
Policy Update Magnitude: 0.31506
Value Function Update Magnitude: 0.30975

Collected Steps per Second: 22,147.24794
Overall Steps per Second: 10,638.66326

Timestep Collection Time: 2.25870
Timestep Consumption Time: 2.44339
PPO Batch Consumption Time: 0.27689
Total Iteration Time: 4.70209

Cumulative Model Updates: 262,094
Cumulative Timesteps: 2,186,423,036

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 125,651.71776
Policy Entropy: 2.71762
Value Function Loss: 0.00948

Mean KL Divergence: 0.00739
SB3 Clip Fraction: 0.06511
Policy Update Magnitude: 0.30499
Value Function Update Magnitude: 0.29118

Collected Steps per Second: 21,845.45691
Overall Steps per Second: 10,423.46791

Timestep Collection Time: 2.29036
Timestep Consumption Time: 2.50977
PPO Batch Consumption Time: 0.29407
Total Iteration Time: 4.80013

Cumulative Model Updates: 262,100
Cumulative Timesteps: 2,186,473,070

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 2186473070...
Checkpoint 2186473070 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 79,884.63816
Policy Entropy: 2.70837
Value Function Loss: 0.01038

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.07147
Policy Update Magnitude: 0.30215
Value Function Update Magnitude: 0.29473

Collected Steps per Second: 22,225.60720
Overall Steps per Second: 10,650.29848

Timestep Collection Time: 2.25047
Timestep Consumption Time: 2.44593
PPO Batch Consumption Time: 0.28270
Total Iteration Time: 4.69639

Cumulative Model Updates: 262,106
Cumulative Timesteps: 2,186,523,088

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 125,560.99113
Policy Entropy: 2.70098
Value Function Loss: 0.01143

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.08385
Policy Update Magnitude: 0.30624
Value Function Update Magnitude: 0.30654

Collected Steps per Second: 22,224.26743
Overall Steps per Second: 10,536.50599

Timestep Collection Time: 2.25024
Timestep Consumption Time: 2.49611
PPO Batch Consumption Time: 0.29218
Total Iteration Time: 4.74636

Cumulative Model Updates: 262,112
Cumulative Timesteps: 2,186,573,098

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2186573098...
Checkpoint 2186573098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 119,617.38931
Policy Entropy: 2.69522
Value Function Loss: 0.01086

Mean KL Divergence: 0.01055
SB3 Clip Fraction: 0.09068
Policy Update Magnitude: 0.29954
Value Function Update Magnitude: 0.29602

Collected Steps per Second: 21,348.80180
Overall Steps per Second: 10,493.36741

Timestep Collection Time: 2.34318
Timestep Consumption Time: 2.42403
PPO Batch Consumption Time: 0.28740
Total Iteration Time: 4.76720

Cumulative Model Updates: 262,118
Cumulative Timesteps: 2,186,623,122

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 103,853.41631
Policy Entropy: 2.70196
Value Function Loss: 0.01102

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.07272
Policy Update Magnitude: 0.29740
Value Function Update Magnitude: 0.28129

Collected Steps per Second: 21,477.56478
Overall Steps per Second: 10,517.99342

Timestep Collection Time: 2.32997
Timestep Consumption Time: 2.42779
PPO Batch Consumption Time: 0.29316
Total Iteration Time: 4.75775

Cumulative Model Updates: 262,124
Cumulative Timesteps: 2,186,673,164

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 2186673164...
Checkpoint 2186673164 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 106,579.29150
Policy Entropy: 2.68770
Value Function Loss: 0.01171

Mean KL Divergence: 0.00728
SB3 Clip Fraction: 0.06810
Policy Update Magnitude: 0.33573
Value Function Update Magnitude: 0.34294

Collected Steps per Second: 20,805.09218
Overall Steps per Second: 10,557.53649

Timestep Collection Time: 2.40422
Timestep Consumption Time: 2.33363
PPO Batch Consumption Time: 0.27746
Total Iteration Time: 4.73785

Cumulative Model Updates: 262,130
Cumulative Timesteps: 2,186,723,184

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 137,180.92612
Policy Entropy: 2.69997
Value Function Loss: 0.01147

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.07102
Policy Update Magnitude: 0.33912
Value Function Update Magnitude: 0.38960

Collected Steps per Second: 21,121.72521
Overall Steps per Second: 10,447.77743

Timestep Collection Time: 2.36875
Timestep Consumption Time: 2.42002
PPO Batch Consumption Time: 0.27874
Total Iteration Time: 4.78877

Cumulative Model Updates: 262,136
Cumulative Timesteps: 2,186,773,216

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2186773216...
Checkpoint 2186773216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 81,341.41866
Policy Entropy: 2.70229
Value Function Loss: 0.01215

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.06729
Policy Update Magnitude: 0.33168
Value Function Update Magnitude: 0.38612

Collected Steps per Second: 21,220.36714
Overall Steps per Second: 10,349.60524

Timestep Collection Time: 2.35679
Timestep Consumption Time: 2.47547
PPO Batch Consumption Time: 0.29243
Total Iteration Time: 4.83226

Cumulative Model Updates: 262,142
Cumulative Timesteps: 2,186,823,228

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87,544.67370
Policy Entropy: 2.71755
Value Function Loss: 0.01375

Mean KL Divergence: 0.00660
SB3 Clip Fraction: 0.06459
Policy Update Magnitude: 0.33249
Value Function Update Magnitude: 0.35325

Collected Steps per Second: 21,976.61843
Overall Steps per Second: 10,560.64474

Timestep Collection Time: 2.27524
Timestep Consumption Time: 2.45951
PPO Batch Consumption Time: 0.28822
Total Iteration Time: 4.73475

Cumulative Model Updates: 262,148
Cumulative Timesteps: 2,186,873,230

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2186873230...
Checkpoint 2186873230 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 82,766.13777
Policy Entropy: 2.69622
Value Function Loss: 0.01314

Mean KL Divergence: 0.00691
SB3 Clip Fraction: 0.06623
Policy Update Magnitude: 0.32804
Value Function Update Magnitude: 0.35735

Collected Steps per Second: 22,139.68225
Overall Steps per Second: 10,437.99696

Timestep Collection Time: 2.25857
Timestep Consumption Time: 2.53201
PPO Batch Consumption Time: 0.28950
Total Iteration Time: 4.79057

Cumulative Model Updates: 262,154
Cumulative Timesteps: 2,186,923,234

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82,766.13777
Policy Entropy: 2.66336
Value Function Loss: 0.01172

Mean KL Divergence: 0.00741
SB3 Clip Fraction: 0.06983
Policy Update Magnitude: 0.32083
Value Function Update Magnitude: 0.35164

Collected Steps per Second: 22,188.29546
Overall Steps per Second: 10,523.26202

Timestep Collection Time: 2.25407
Timestep Consumption Time: 2.49864
PPO Batch Consumption Time: 0.29196
Total Iteration Time: 4.75271

Cumulative Model Updates: 262,160
Cumulative Timesteps: 2,186,973,248

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2186973248...
Checkpoint 2186973248 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 97,111.54745
Policy Entropy: 2.66550
Value Function Loss: 0.01019

Mean KL Divergence: 0.00685
SB3 Clip Fraction: 0.06448
Policy Update Magnitude: 0.31598
Value Function Update Magnitude: 0.32572

Collected Steps per Second: 22,216.30498
Overall Steps per Second: 10,527.35502

Timestep Collection Time: 2.25105
Timestep Consumption Time: 2.49943
PPO Batch Consumption Time: 0.28983
Total Iteration Time: 4.75048

Cumulative Model Updates: 262,166
Cumulative Timesteps: 2,187,023,258

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97,869.03975
Policy Entropy: 2.69212
Value Function Loss: 0.00956

Mean KL Divergence: 0.00690
SB3 Clip Fraction: 0.06351
Policy Update Magnitude: 0.30077
Value Function Update Magnitude: 0.30575

Collected Steps per Second: 21,613.51152
Overall Steps per Second: 10,531.95336

Timestep Collection Time: 2.31383
Timestep Consumption Time: 2.43458
PPO Batch Consumption Time: 0.27679
Total Iteration Time: 4.74841

Cumulative Model Updates: 262,172
Cumulative Timesteps: 2,187,073,268

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2187073268...
Checkpoint 2187073268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 62,888.70268
Policy Entropy: 2.73081
Value Function Loss: 0.00991

Mean KL Divergence: 0.00748
SB3 Clip Fraction: 0.07043
Policy Update Magnitude: 0.29133
Value Function Update Magnitude: 0.28757

Collected Steps per Second: 21,826.81287
Overall Steps per Second: 10,625.58983

Timestep Collection Time: 2.29177
Timestep Consumption Time: 2.41592
PPO Batch Consumption Time: 0.27702
Total Iteration Time: 4.70769

Cumulative Model Updates: 262,178
Cumulative Timesteps: 2,187,123,290

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59,687.74421
Policy Entropy: 2.74713
Value Function Loss: 0.00966

Mean KL Divergence: 0.00601
SB3 Clip Fraction: 0.05724
Policy Update Magnitude: 0.29541
Value Function Update Magnitude: 0.28241

Collected Steps per Second: 22,539.15290
Overall Steps per Second: 10,770.94114

Timestep Collection Time: 2.21943
Timestep Consumption Time: 2.42492
PPO Batch Consumption Time: 0.27869
Total Iteration Time: 4.64435

Cumulative Model Updates: 262,184
Cumulative Timesteps: 2,187,173,314

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2187173314...
Checkpoint 2187173314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 69,827.68752
Policy Entropy: 2.72148
Value Function Loss: 0.01173

Mean KL Divergence: 0.00683
SB3 Clip Fraction: 0.06375
Policy Update Magnitude: 0.30616
Value Function Update Magnitude: 0.29352

Collected Steps per Second: 21,266.93589
Overall Steps per Second: 10,673.00352

Timestep Collection Time: 2.35191
Timestep Consumption Time: 2.33449
PPO Batch Consumption Time: 0.27766
Total Iteration Time: 4.68640

Cumulative Model Updates: 262,190
Cumulative Timesteps: 2,187,223,332

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 126,660.09071
Policy Entropy: 2.71981
Value Function Loss: 0.01153

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.07217
Policy Update Magnitude: 0.31033
Value Function Update Magnitude: 0.30045

Collected Steps per Second: 21,060.12363
Overall Steps per Second: 10,580.32438

Timestep Collection Time: 2.37501
Timestep Consumption Time: 2.35244
PPO Batch Consumption Time: 0.27605
Total Iteration Time: 4.72745

Cumulative Model Updates: 262,196
Cumulative Timesteps: 2,187,273,350

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2187273350...
Checkpoint 2187273350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 117,328.77962
Policy Entropy: 2.72292
Value Function Loss: 0.01154

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.07487
Policy Update Magnitude: 0.30029
Value Function Update Magnitude: 0.28505

Collected Steps per Second: 20,848.47525
Overall Steps per Second: 10,536.95756

Timestep Collection Time: 2.39883
Timestep Consumption Time: 2.34751
PPO Batch Consumption Time: 0.27787
Total Iteration Time: 4.74634

Cumulative Model Updates: 262,202
Cumulative Timesteps: 2,187,323,362

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 117,328.77962
Policy Entropy: 2.73524
Value Function Loss: 0.00997

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.07798
Policy Update Magnitude: 0.29119
Value Function Update Magnitude: 0.23150

Collected Steps per Second: 20,866.36768
Overall Steps per Second: 10,416.31741

Timestep Collection Time: 2.39706
Timestep Consumption Time: 2.40483
PPO Batch Consumption Time: 0.27809
Total Iteration Time: 4.80189

Cumulative Model Updates: 262,208
Cumulative Timesteps: 2,187,373,380

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2187373380...
Checkpoint 2187373380 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 117,328.77962
Policy Entropy: 2.74274
Value Function Loss: 0.00859

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.07858
Policy Update Magnitude: 0.27927
Value Function Update Magnitude: 0.19417

Collected Steps per Second: 21,141.98680
Overall Steps per Second: 10,314.37142

Timestep Collection Time: 2.36610
Timestep Consumption Time: 2.48383
PPO Batch Consumption Time: 0.29329
Total Iteration Time: 4.84993

Cumulative Model Updates: 262,214
Cumulative Timesteps: 2,187,423,404

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91,442.11537
Policy Entropy: 2.73707
Value Function Loss: 0.00872

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.07983
Policy Update Magnitude: 0.27511
Value Function Update Magnitude: 0.17074

Collected Steps per Second: 22,184.04992
Overall Steps per Second: 10,503.66151

Timestep Collection Time: 2.25486
Timestep Consumption Time: 2.50748
PPO Batch Consumption Time: 0.29247
Total Iteration Time: 4.76234

Cumulative Model Updates: 262,220
Cumulative Timesteps: 2,187,473,426

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2187473426...
Checkpoint 2187473426 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 91,442.11537
Policy Entropy: 2.74189
Value Function Loss: 0.00797

Mean KL Divergence: 0.00716
SB3 Clip Fraction: 0.06722
Policy Update Magnitude: 0.26969
Value Function Update Magnitude: 0.18599

Collected Steps per Second: 21,971.92827
Overall Steps per Second: 10,588.94495

Timestep Collection Time: 2.27581
Timestep Consumption Time: 2.44647
PPO Batch Consumption Time: 0.27676
Total Iteration Time: 4.72228

Cumulative Model Updates: 262,226
Cumulative Timesteps: 2,187,523,430

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84,350.02036
Policy Entropy: 2.73715
Value Function Loss: 0.00843

Mean KL Divergence: 0.00661
SB3 Clip Fraction: 0.06088
Policy Update Magnitude: 0.26601
Value Function Update Magnitude: 0.21840

Collected Steps per Second: 22,238.95003
Overall Steps per Second: 10,554.24177

Timestep Collection Time: 2.24975
Timestep Consumption Time: 2.49072
PPO Batch Consumption Time: 0.29106
Total Iteration Time: 4.74046

Cumulative Model Updates: 262,232
Cumulative Timesteps: 2,187,573,462

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2187573462...
Checkpoint 2187573462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 112,134.66926
Policy Entropy: 2.72169
Value Function Loss: 0.00960

Mean KL Divergence: 0.00667
SB3 Clip Fraction: 0.06429
Policy Update Magnitude: 0.28416
Value Function Update Magnitude: 0.26193

Collected Steps per Second: 21,858.16794
Overall Steps per Second: 10,511.60328

Timestep Collection Time: 2.28912
Timestep Consumption Time: 2.47095
PPO Batch Consumption Time: 0.28651
Total Iteration Time: 4.76007

Cumulative Model Updates: 262,238
Cumulative Timesteps: 2,187,623,498

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 118,309.35441
Policy Entropy: 2.72187
Value Function Loss: 0.00949

Mean KL Divergence: 0.00626
SB3 Clip Fraction: 0.05979
Policy Update Magnitude: 0.29202
Value Function Update Magnitude: 0.27005

Collected Steps per Second: 22,304.91396
Overall Steps per Second: 10,581.06635

Timestep Collection Time: 2.24193
Timestep Consumption Time: 2.48406
PPO Batch Consumption Time: 0.29097
Total Iteration Time: 4.72599

Cumulative Model Updates: 262,244
Cumulative Timesteps: 2,187,673,504

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2187673504...
Checkpoint 2187673504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 109,346.04330
Policy Entropy: 2.74219
Value Function Loss: 0.00948

Mean KL Divergence: 0.00541
SB3 Clip Fraction: 0.05083
Policy Update Magnitude: 0.28306
Value Function Update Magnitude: 0.25423

Collected Steps per Second: 22,048.62840
Overall Steps per Second: 10,490.28588

Timestep Collection Time: 2.26817
Timestep Consumption Time: 2.49910
PPO Batch Consumption Time: 0.29019
Total Iteration Time: 4.76727

Cumulative Model Updates: 262,250
Cumulative Timesteps: 2,187,723,514

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97,155.39155
Policy Entropy: 2.72668
Value Function Loss: 0.00919

Mean KL Divergence: 0.00517
SB3 Clip Fraction: 0.05065
Policy Update Magnitude: 0.28601
Value Function Update Magnitude: 0.25045

Collected Steps per Second: 22,245.96857
Overall Steps per Second: 10,543.67941

Timestep Collection Time: 2.24877
Timestep Consumption Time: 2.49588
PPO Batch Consumption Time: 0.29220
Total Iteration Time: 4.74464

Cumulative Model Updates: 262,256
Cumulative Timesteps: 2,187,773,540

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2187773540...
Checkpoint 2187773540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 91,972.01576
Policy Entropy: 2.71422
Value Function Loss: 0.00873

Mean KL Divergence: 0.00540
SB3 Clip Fraction: 0.05151
Policy Update Magnitude: 0.28248
Value Function Update Magnitude: 0.25879

Collected Steps per Second: 21,604.59080
Overall Steps per Second: 10,536.32929

Timestep Collection Time: 2.31479
Timestep Consumption Time: 2.43165
PPO Batch Consumption Time: 0.27847
Total Iteration Time: 4.74643

Cumulative Model Updates: 262,262
Cumulative Timesteps: 2,187,823,550

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 104,434.69203
Policy Entropy: 2.69743
Value Function Loss: 0.00979

Mean KL Divergence: 0.00715
SB3 Clip Fraction: 0.06509
Policy Update Magnitude: 0.29187
Value Function Update Magnitude: 0.27865

Collected Steps per Second: 21,579.73583
Overall Steps per Second: 10,549.61580

Timestep Collection Time: 2.31931
Timestep Consumption Time: 2.42494
PPO Batch Consumption Time: 0.27686
Total Iteration Time: 4.74425

Cumulative Model Updates: 262,268
Cumulative Timesteps: 2,187,873,600

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 2187873600...
Checkpoint 2187873600 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 99,271.43008
Policy Entropy: 2.69629
Value Function Loss: 0.01081

Mean KL Divergence: 0.00695
SB3 Clip Fraction: 0.06514
Policy Update Magnitude: 0.30259
Value Function Update Magnitude: 0.28732

Collected Steps per Second: 21,280.63981
Overall Steps per Second: 10,481.56966

Timestep Collection Time: 2.34965
Timestep Consumption Time: 2.42082
PPO Batch Consumption Time: 0.27794
Total Iteration Time: 4.77047

Cumulative Model Updates: 262,274
Cumulative Timesteps: 2,187,923,602

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 94,464.88516
Policy Entropy: 2.71314
Value Function Loss: 0.01019

Mean KL Divergence: 0.00716
SB3 Clip Fraction: 0.06602
Policy Update Magnitude: 0.29971
Value Function Update Magnitude: 0.29971

Collected Steps per Second: 21,899.32772
Overall Steps per Second: 10,484.02756

Timestep Collection Time: 2.28381
Timestep Consumption Time: 2.48668
PPO Batch Consumption Time: 0.28567
Total Iteration Time: 4.77049

Cumulative Model Updates: 262,280
Cumulative Timesteps: 2,187,973,616

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2187973616...
Checkpoint 2187973616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 94,464.88516
Policy Entropy: 2.72881
Value Function Loss: 0.00901

Mean KL Divergence: 0.00676
SB3 Clip Fraction: 0.06176
Policy Update Magnitude: 0.28164
Value Function Update Magnitude: 0.29025

Collected Steps per Second: 21,259.57454
Overall Steps per Second: 10,249.81590

Timestep Collection Time: 2.35301
Timestep Consumption Time: 2.52747
PPO Batch Consumption Time: 0.29405
Total Iteration Time: 4.88048

Cumulative Model Updates: 262,286
Cumulative Timesteps: 2,188,023,640

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85,492.97376
Policy Entropy: 2.74070
Value Function Loss: 0.00796

Mean KL Divergence: 0.00580
SB3 Clip Fraction: 0.05633
Policy Update Magnitude: 0.26880
Value Function Update Magnitude: 0.24738

Collected Steps per Second: 22,284.14838
Overall Steps per Second: 10,439.55499

Timestep Collection Time: 2.24411
Timestep Consumption Time: 2.54614
PPO Batch Consumption Time: 0.29227
Total Iteration Time: 4.79024

Cumulative Model Updates: 262,292
Cumulative Timesteps: 2,188,073,648

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2188073648...
Checkpoint 2188073648 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 67,077.86754
Policy Entropy: 2.73478
Value Function Loss: 0.00967

Mean KL Divergence: 0.00522
SB3 Clip Fraction: 0.05126
Policy Update Magnitude: 0.27847
Value Function Update Magnitude: 0.23371

Collected Steps per Second: 20,508.65212
Overall Steps per Second: 10,265.22246

Timestep Collection Time: 2.43936
Timestep Consumption Time: 2.43418
PPO Batch Consumption Time: 0.27682
Total Iteration Time: 4.87354

Cumulative Model Updates: 262,298
Cumulative Timesteps: 2,188,123,676

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82,197.25400
Policy Entropy: 2.71786
Value Function Loss: 0.01265

Mean KL Divergence: 0.00541
SB3 Clip Fraction: 0.05317
Policy Update Magnitude: 0.30928
Value Function Update Magnitude: 0.27197

Collected Steps per Second: 21,655.27755
Overall Steps per Second: 10,372.34163

Timestep Collection Time: 2.30909
Timestep Consumption Time: 2.51181
PPO Batch Consumption Time: 0.29171
Total Iteration Time: 4.82090

Cumulative Model Updates: 262,304
Cumulative Timesteps: 2,188,173,680

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2188173680...
Checkpoint 2188173680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 81,338.16484
Policy Entropy: 2.72955
Value Function Loss: 0.01336

Mean KL Divergence: 0.00617
SB3 Clip Fraction: 0.05734
Policy Update Magnitude: 0.31196
Value Function Update Magnitude: 0.31192

Collected Steps per Second: 20,870.45496
Overall Steps per Second: 10,413.10573

Timestep Collection Time: 2.39640
Timestep Consumption Time: 2.40658
PPO Batch Consumption Time: 0.28813
Total Iteration Time: 4.80299

Cumulative Model Updates: 262,310
Cumulative Timesteps: 2,188,223,694

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87,155.42053
Policy Entropy: 2.71123
Value Function Loss: 0.01343

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.06919
Policy Update Magnitude: 0.31450
Value Function Update Magnitude: 0.33456

Collected Steps per Second: 21,353.37587
Overall Steps per Second: 10,649.22407

Timestep Collection Time: 2.34211
Timestep Consumption Time: 2.35419
PPO Batch Consumption Time: 0.27865
Total Iteration Time: 4.69630

Cumulative Model Updates: 262,316
Cumulative Timesteps: 2,188,273,706

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2188273706...
Checkpoint 2188273706 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 71,611.46958
Policy Entropy: 2.70330
Value Function Loss: 0.01085

Mean KL Divergence: 0.00722
SB3 Clip Fraction: 0.06617
Policy Update Magnitude: 0.31275
Value Function Update Magnitude: 0.33615

Collected Steps per Second: 21,268.56108
Overall Steps per Second: 10,596.88487

Timestep Collection Time: 2.35098
Timestep Consumption Time: 2.36757
PPO Batch Consumption Time: 0.27765
Total Iteration Time: 4.71856

Cumulative Model Updates: 262,322
Cumulative Timesteps: 2,188,323,708

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47,379.20469
Policy Entropy: 2.68031
Value Function Loss: 0.01056

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.06596
Policy Update Magnitude: 0.31199
Value Function Update Magnitude: 0.31356

Collected Steps per Second: 21,360.46435
Overall Steps per Second: 10,483.29117

Timestep Collection Time: 2.34143
Timestep Consumption Time: 2.42940
PPO Batch Consumption Time: 0.27946
Total Iteration Time: 4.77083

Cumulative Model Updates: 262,328
Cumulative Timesteps: 2,188,373,722

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2188373722...
Checkpoint 2188373722 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46,006.25619
Policy Entropy: 2.69377
Value Function Loss: 0.01003

Mean KL Divergence: 0.00706
SB3 Clip Fraction: 0.06501
Policy Update Magnitude: 0.32127
Value Function Update Magnitude: 0.31591

Collected Steps per Second: 21,832.85681
Overall Steps per Second: 10,623.48443

Timestep Collection Time: 2.29159
Timestep Consumption Time: 2.41797
PPO Batch Consumption Time: 0.27917
Total Iteration Time: 4.70957

Cumulative Model Updates: 262,334
Cumulative Timesteps: 2,188,423,754

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83,788.75756
Policy Entropy: 2.69539
Value Function Loss: 0.01155

Mean KL Divergence: 0.00666
SB3 Clip Fraction: 0.06134
Policy Update Magnitude: 0.32827
Value Function Update Magnitude: 0.33819

Collected Steps per Second: 21,866.01698
Overall Steps per Second: 10,536.38273

Timestep Collection Time: 2.28748
Timestep Consumption Time: 2.45969
PPO Batch Consumption Time: 0.28720
Total Iteration Time: 4.74717

Cumulative Model Updates: 262,340
Cumulative Timesteps: 2,188,473,772

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2188473772...
Checkpoint 2188473772 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 70,685.94299
Policy Entropy: 2.70330
Value Function Loss: 0.01153

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.07021
Policy Update Magnitude: 0.32607
Value Function Update Magnitude: 0.35745

Collected Steps per Second: 21,859.69606
Overall Steps per Second: 10,605.29527

Timestep Collection Time: 2.28869
Timestep Consumption Time: 2.42877
PPO Batch Consumption Time: 0.27799
Total Iteration Time: 4.71745

Cumulative Model Updates: 262,346
Cumulative Timesteps: 2,188,523,802

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 113,075.52516
Policy Entropy: 2.70157
Value Function Loss: 0.01142

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.07351
Policy Update Magnitude: 0.31573
Value Function Update Magnitude: 0.32131

Collected Steps per Second: 22,159.35650
Overall Steps per Second: 10,503.84231

Timestep Collection Time: 2.25701
Timestep Consumption Time: 2.50448
PPO Batch Consumption Time: 0.29273
Total Iteration Time: 4.76150

Cumulative Model Updates: 262,352
Cumulative Timesteps: 2,188,573,816

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2188573816...
Checkpoint 2188573816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 113,075.52516
Policy Entropy: 2.72523
Value Function Loss: 0.00984

Mean KL Divergence: 0.00686
SB3 Clip Fraction: 0.06314
Policy Update Magnitude: 0.30173
Value Function Update Magnitude: 0.29608

Collected Steps per Second: 21,752.37176
Overall Steps per Second: 10,570.82408

Timestep Collection Time: 2.30044
Timestep Consumption Time: 2.43335
PPO Batch Consumption Time: 0.27853
Total Iteration Time: 4.73378

Cumulative Model Updates: 262,358
Cumulative Timesteps: 2,188,623,856

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 100,169.85414
Policy Entropy: 2.72615
Value Function Loss: 0.00859

Mean KL Divergence: 0.00717
SB3 Clip Fraction: 0.06575
Policy Update Magnitude: 0.28498
Value Function Update Magnitude: 0.27088

Collected Steps per Second: 21,355.98281
Overall Steps per Second: 10,461.43669

Timestep Collection Time: 2.34239
Timestep Consumption Time: 2.43936
PPO Batch Consumption Time: 0.27850
Total Iteration Time: 4.78175

Cumulative Model Updates: 262,364
Cumulative Timesteps: 2,188,673,880

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2188673880...
Checkpoint 2188673880 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 100,169.85414
Policy Entropy: 2.74547
Value Function Loss: 0.00822

Mean KL Divergence: 0.00671
SB3 Clip Fraction: 0.06178
Policy Update Magnitude: 0.27824
Value Function Update Magnitude: 0.25378

Collected Steps per Second: 21,217.74954
Overall Steps per Second: 10,305.93040

Timestep Collection Time: 2.35793
Timestep Consumption Time: 2.49655
PPO Batch Consumption Time: 0.29338
Total Iteration Time: 4.85449

Cumulative Model Updates: 262,370
Cumulative Timesteps: 2,188,723,910

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 123,648.40839
Policy Entropy: 2.73077
Value Function Loss: 0.00976

Mean KL Divergence: 0.00675
SB3 Clip Fraction: 0.06219
Policy Update Magnitude: 0.29094
Value Function Update Magnitude: 0.24950

Collected Steps per Second: 21,609.11877
Overall Steps per Second: 10,369.52969

Timestep Collection Time: 2.31402
Timestep Consumption Time: 2.50818
PPO Batch Consumption Time: 0.29180
Total Iteration Time: 4.82221

Cumulative Model Updates: 262,376
Cumulative Timesteps: 2,188,773,914

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2188773914...
Checkpoint 2188773914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86,700.22695
Policy Entropy: 2.73324
Value Function Loss: 0.00976

Mean KL Divergence: 0.00649
SB3 Clip Fraction: 0.06124
Policy Update Magnitude: 0.29304
Value Function Update Magnitude: 0.25405

Collected Steps per Second: 20,828.98945
Overall Steps per Second: 10,370.67136

Timestep Collection Time: 2.40136
Timestep Consumption Time: 2.42166
PPO Batch Consumption Time: 0.29157
Total Iteration Time: 4.82302

Cumulative Model Updates: 262,382
Cumulative Timesteps: 2,188,823,932

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 113,631.39579
Policy Entropy: 2.72135
Value Function Loss: 0.00964

Mean KL Divergence: 0.00651
SB3 Clip Fraction: 0.06138
Policy Update Magnitude: 0.29423
Value Function Update Magnitude: 0.27570

Collected Steps per Second: 21,457.57842
Overall Steps per Second: 10,500.47013

Timestep Collection Time: 2.33065
Timestep Consumption Time: 2.43200
PPO Batch Consumption Time: 0.28886
Total Iteration Time: 4.76264

Cumulative Model Updates: 262,388
Cumulative Timesteps: 2,188,873,942

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2188873942...
Checkpoint 2188873942 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 113,631.39579
Policy Entropy: 2.72659
Value Function Loss: 0.00884

Mean KL Divergence: 0.00646
SB3 Clip Fraction: 0.05948
Policy Update Magnitude: 0.29314
Value Function Update Magnitude: 0.28436

Collected Steps per Second: 21,642.78527
Overall Steps per Second: 10,515.00352

Timestep Collection Time: 2.31126
Timestep Consumption Time: 2.44595
PPO Batch Consumption Time: 0.29282
Total Iteration Time: 4.75720

Cumulative Model Updates: 262,394
Cumulative Timesteps: 2,188,923,964

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 113,631.39579
Policy Entropy: 2.74437
Value Function Loss: 0.00836

Mean KL Divergence: 0.00648
SB3 Clip Fraction: 0.05972
Policy Update Magnitude: 0.28630
Value Function Update Magnitude: 0.26040

Collected Steps per Second: 21,688.12420
Overall Steps per Second: 10,433.11141

Timestep Collection Time: 2.30569
Timestep Consumption Time: 2.48732
PPO Batch Consumption Time: 0.29208
Total Iteration Time: 4.79301

Cumulative Model Updates: 262,400
Cumulative Timesteps: 2,188,973,970

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2188973970...
Checkpoint 2188973970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 113,631.39579
Policy Entropy: 2.76340
Value Function Loss: 0.00816

Mean KL Divergence: 0.00692
SB3 Clip Fraction: 0.06016
Policy Update Magnitude: 0.27482
Value Function Update Magnitude: 0.23578

Collected Steps per Second: 21,784.64293
Overall Steps per Second: 10,633.53964

Timestep Collection Time: 2.29593
Timestep Consumption Time: 2.40768
PPO Batch Consumption Time: 0.27763
Total Iteration Time: 4.70361

Cumulative Model Updates: 262,406
Cumulative Timesteps: 2,189,023,986

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 117,447.49302
Policy Entropy: 2.77475
Value Function Loss: 0.00840

Mean KL Divergence: 0.00668
SB3 Clip Fraction: 0.05960
Policy Update Magnitude: 0.27182
Value Function Update Magnitude: 0.22405

Collected Steps per Second: 22,187.26504
Overall Steps per Second: 10,616.98075

Timestep Collection Time: 2.25400
Timestep Consumption Time: 2.45638
PPO Batch Consumption Time: 0.28869
Total Iteration Time: 4.71038

Cumulative Model Updates: 262,412
Cumulative Timesteps: 2,189,073,996

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2189073996...
Checkpoint 2189073996 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 133,051.34606
Policy Entropy: 2.75937
Value Function Loss: 0.00928

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.07207
Policy Update Magnitude: 0.27982
Value Function Update Magnitude: 0.25377

Collected Steps per Second: 22,268.23119
Overall Steps per Second: 10,578.36770

Timestep Collection Time: 2.24652
Timestep Consumption Time: 2.48257
PPO Batch Consumption Time: 0.29039
Total Iteration Time: 4.72908

Cumulative Model Updates: 262,418
Cumulative Timesteps: 2,189,124,022

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 123,335.06981
Policy Entropy: 2.73964
Value Function Loss: 0.00927

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.06845
Policy Update Magnitude: 0.27948
Value Function Update Magnitude: 0.27932

Collected Steps per Second: 22,318.95753
Overall Steps per Second: 10,708.91727

Timestep Collection Time: 2.24204
Timestep Consumption Time: 2.43070
PPO Batch Consumption Time: 0.27804
Total Iteration Time: 4.67274

Cumulative Model Updates: 262,424
Cumulative Timesteps: 2,189,174,062

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 2189174062...
Checkpoint 2189174062 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 112,160.90928
Policy Entropy: 2.73396
Value Function Loss: 0.00926

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.07809
Policy Update Magnitude: 0.28118
Value Function Update Magnitude: 0.27542

Collected Steps per Second: 21,590.22797
Overall Steps per Second: 10,424.83670

Timestep Collection Time: 2.31605
Timestep Consumption Time: 2.48057
PPO Batch Consumption Time: 0.28944
Total Iteration Time: 4.79662

Cumulative Model Updates: 262,430
Cumulative Timesteps: 2,189,224,066

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 145,932.17937
Policy Entropy: 2.73210
Value Function Loss: 0.00937

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.07919
Policy Update Magnitude: 0.28940
Value Function Update Magnitude: 0.26317

Collected Steps per Second: 21,829.90475
Overall Steps per Second: 10,631.07584

Timestep Collection Time: 2.29089
Timestep Consumption Time: 2.41324
PPO Batch Consumption Time: 0.27761
Total Iteration Time: 4.70413

Cumulative Model Updates: 262,436
Cumulative Timesteps: 2,189,274,076

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2189274076...
Checkpoint 2189274076 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 145,932.17937
Policy Entropy: 2.73435
Value Function Loss: 0.00919

Mean KL Divergence: 0.01613
SB3 Clip Fraction: 0.11237
Policy Update Magnitude: 0.29355
Value Function Update Magnitude: 0.25385

Collected Steps per Second: 21,328.99062
Overall Steps per Second: 10,302.52404

Timestep Collection Time: 2.34545
Timestep Consumption Time: 2.51026
PPO Batch Consumption Time: 0.29353
Total Iteration Time: 4.85570

Cumulative Model Updates: 262,442
Cumulative Timesteps: 2,189,324,102

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 176,142.86630
Policy Entropy: 2.71665
Value Function Loss: 0.01058

Mean KL Divergence: 0.01369
SB3 Clip Fraction: 0.10103
Policy Update Magnitude: 0.30655
Value Function Update Magnitude: 0.28303

Collected Steps per Second: 21,574.58333
Overall Steps per Second: 10,414.25040

Timestep Collection Time: 2.31967
Timestep Consumption Time: 2.48586
PPO Batch Consumption Time: 0.28760
Total Iteration Time: 4.80553

Cumulative Model Updates: 262,448
Cumulative Timesteps: 2,189,374,148

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 2189374148...
Checkpoint 2189374148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 136,364.64646
Policy Entropy: 2.71420
Value Function Loss: 0.01075

Mean KL Divergence: 0.01265
SB3 Clip Fraction: 0.09322
Policy Update Magnitude: 0.31451
Value Function Update Magnitude: 0.31075

Collected Steps per Second: 21,674.34887
Overall Steps per Second: 10,566.67362

Timestep Collection Time: 2.30826
Timestep Consumption Time: 2.42644
PPO Batch Consumption Time: 0.27789
Total Iteration Time: 4.73470

Cumulative Model Updates: 262,454
Cumulative Timesteps: 2,189,424,178

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 126,268.41730
Policy Entropy: 2.70783
Value Function Loss: 0.01163

Mean KL Divergence: 0.01154
SB3 Clip Fraction: 0.09451
Policy Update Magnitude: 0.31779
Value Function Update Magnitude: 0.32938

Collected Steps per Second: 21,976.99156
Overall Steps per Second: 10,538.20440

Timestep Collection Time: 2.27583
Timestep Consumption Time: 2.47032
PPO Batch Consumption Time: 0.27831
Total Iteration Time: 4.74616

Cumulative Model Updates: 262,460
Cumulative Timesteps: 2,189,474,194

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2189474194...
Checkpoint 2189474194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 115,381.22227
Policy Entropy: 2.71601
Value Function Loss: 0.01172

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.08303
Policy Update Magnitude: 0.31952
Value Function Update Magnitude: 0.33593

Collected Steps per Second: 21,970.07765
Overall Steps per Second: 10,570.42297

Timestep Collection Time: 2.27600
Timestep Consumption Time: 2.45455
PPO Batch Consumption Time: 0.27911
Total Iteration Time: 4.73056

Cumulative Model Updates: 262,466
Cumulative Timesteps: 2,189,524,198

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 115,381.22227
Policy Entropy: 2.70708
Value Function Loss: 0.01143

Mean KL Divergence: 0.00715
SB3 Clip Fraction: 0.06849
Policy Update Magnitude: 0.31860
Value Function Update Magnitude: 0.29754

Collected Steps per Second: 22,186.16118
Overall Steps per Second: 10,485.80754

Timestep Collection Time: 2.25402
Timestep Consumption Time: 2.51510
PPO Batch Consumption Time: 0.29068
Total Iteration Time: 4.76911

Cumulative Model Updates: 262,472
Cumulative Timesteps: 2,189,574,206

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2189574206...
Checkpoint 2189574206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 115,381.22227
Policy Entropy: 2.71111
Value Function Loss: 0.00976

Mean KL Divergence: 0.00748
SB3 Clip Fraction: 0.06837
Policy Update Magnitude: 0.30752
Value Function Update Magnitude: 0.23334

Collected Steps per Second: 21,498.51336
Overall Steps per Second: 10,361.66835

Timestep Collection Time: 2.32602
Timestep Consumption Time: 2.50004
PPO Batch Consumption Time: 0.29137
Total Iteration Time: 4.82606

Cumulative Model Updates: 262,478
Cumulative Timesteps: 2,189,624,212

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97,528.80198
Policy Entropy: 2.71570
Value Function Loss: 0.01050

Mean KL Divergence: 0.00670
SB3 Clip Fraction: 0.05718
Policy Update Magnitude: 0.30031
Value Function Update Magnitude: 0.21121

Collected Steps per Second: 22,299.52518
Overall Steps per Second: 10,733.16200

Timestep Collection Time: 2.24301
Timestep Consumption Time: 2.41713
PPO Batch Consumption Time: 0.27842
Total Iteration Time: 4.66014

Cumulative Model Updates: 262,484
Cumulative Timesteps: 2,189,674,230

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2189674230...
Checkpoint 2189674230 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 101,951.37078
Policy Entropy: 2.70810
Value Function Loss: 0.01074

Mean KL Divergence: 0.00717
SB3 Clip Fraction: 0.06385
Policy Update Magnitude: 0.31118
Value Function Update Magnitude: 0.23440

Collected Steps per Second: 21,788.49477
Overall Steps per Second: 10,611.31874

Timestep Collection Time: 2.29681
Timestep Consumption Time: 2.41929
PPO Batch Consumption Time: 0.27863
Total Iteration Time: 4.71610

Cumulative Model Updates: 262,490
Cumulative Timesteps: 2,189,724,274

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82,502.15970
Policy Entropy: 2.70911
Value Function Loss: 0.01067

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.07558
Policy Update Magnitude: 0.30565
Value Function Update Magnitude: 0.28194

Collected Steps per Second: 21,787.10469
Overall Steps per Second: 10,601.11615

Timestep Collection Time: 2.29494
Timestep Consumption Time: 2.42155
PPO Batch Consumption Time: 0.27728
Total Iteration Time: 4.71648

Cumulative Model Updates: 262,496
Cumulative Timesteps: 2,189,774,274

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2189774274...
Checkpoint 2189774274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 166,313.47189
Policy Entropy: 2.70675
Value Function Loss: 0.01058

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.07047
Policy Update Magnitude: 0.31579
Value Function Update Magnitude: 0.27787

Collected Steps per Second: 21,530.46821
Overall Steps per Second: 10,532.97533

Timestep Collection Time: 2.32359
Timestep Consumption Time: 2.42606
PPO Batch Consumption Time: 0.27881
Total Iteration Time: 4.74966

Cumulative Model Updates: 262,502
Cumulative Timesteps: 2,189,824,302

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 224,441.08434
Policy Entropy: 2.71445
Value Function Loss: 0.01053

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.07263
Policy Update Magnitude: 0.31182
Value Function Update Magnitude: 0.27760

Collected Steps per Second: 20,966.53531
Overall Steps per Second: 10,473.26863

Timestep Collection Time: 2.38494
Timestep Consumption Time: 2.38950
PPO Batch Consumption Time: 0.28425
Total Iteration Time: 4.77444

Cumulative Model Updates: 262,508
Cumulative Timesteps: 2,189,874,306

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2189874306...
Checkpoint 2189874306 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 114,535.82337
Policy Entropy: 2.67095
Value Function Loss: 0.01307

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.07193
Policy Update Magnitude: 0.32189
Value Function Update Magnitude: 0.29050

Collected Steps per Second: 20,693.82854
Overall Steps per Second: 10,317.57636

Timestep Collection Time: 2.41763
Timestep Consumption Time: 2.43138
PPO Batch Consumption Time: 0.29167
Total Iteration Time: 4.84901

Cumulative Model Updates: 262,514
Cumulative Timesteps: 2,189,924,336

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84,583.70977
Policy Entropy: 2.67616
Value Function Loss: 0.01323

Mean KL Divergence: 0.00701
SB3 Clip Fraction: 0.06751
Policy Update Magnitude: 0.34326
Value Function Update Magnitude: 0.32581

Collected Steps per Second: 21,658.03293
Overall Steps per Second: 10,538.31809

Timestep Collection Time: 2.30935
Timestep Consumption Time: 2.43676
PPO Batch Consumption Time: 0.28817
Total Iteration Time: 4.74611

Cumulative Model Updates: 262,520
Cumulative Timesteps: 2,189,974,352

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2189974352...
Checkpoint 2189974352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 107,135.05065
Policy Entropy: 2.67864
Value Function Loss: 0.01245

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.07404
Policy Update Magnitude: 0.34481
Value Function Update Magnitude: 0.37628

Collected Steps per Second: 21,107.00824
Overall Steps per Second: 10,414.51558

Timestep Collection Time: 2.37002
Timestep Consumption Time: 2.43328
PPO Batch Consumption Time: 0.27946
Total Iteration Time: 4.80330

Cumulative Model Updates: 262,526
Cumulative Timesteps: 2,190,024,376

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 107,135.05065
Policy Entropy: 2.70723
Value Function Loss: 0.01066

Mean KL Divergence: 0.00683
SB3 Clip Fraction: 0.06311
Policy Update Magnitude: 0.33108
Value Function Update Magnitude: 0.35974

Collected Steps per Second: 21,867.82102
Overall Steps per Second: 10,476.01108

Timestep Collection Time: 2.28793
Timestep Consumption Time: 2.48794
PPO Batch Consumption Time: 0.29399
Total Iteration Time: 4.77586

Cumulative Model Updates: 262,532
Cumulative Timesteps: 2,190,074,408

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2190074408...
Checkpoint 2190074408 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 64,905.16251
Policy Entropy: 2.69638
Value Function Loss: 0.01269

Mean KL Divergence: 0.00712
SB3 Clip Fraction: 0.06441
Policy Update Magnitude: 0.33186
Value Function Update Magnitude: 0.34214

Collected Steps per Second: 21,857.45344
Overall Steps per Second: 10,703.19151

Timestep Collection Time: 2.28782
Timestep Consumption Time: 2.38424
PPO Batch Consumption Time: 0.27752
Total Iteration Time: 4.67206

Cumulative Model Updates: 262,538
Cumulative Timesteps: 2,190,124,414

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 94,055.82943
Policy Entropy: 2.70685
Value Function Loss: 0.01169

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.07114
Policy Update Magnitude: 0.33064
Value Function Update Magnitude: 0.35162

Collected Steps per Second: 22,160.81107
Overall Steps per Second: 10,550.57191

Timestep Collection Time: 2.25768
Timestep Consumption Time: 2.48443
PPO Batch Consumption Time: 0.28898
Total Iteration Time: 4.74211

Cumulative Model Updates: 262,544
Cumulative Timesteps: 2,190,174,446

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2190174446...
Checkpoint 2190174446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 75,273.59139
Policy Entropy: 2.70442
Value Function Loss: 0.01172

Mean KL Divergence: 0.00699
SB3 Clip Fraction: 0.06313
Policy Update Magnitude: 0.32142
Value Function Update Magnitude: 0.32398

Collected Steps per Second: 22,120.43183
Overall Steps per Second: 10,468.05458

Timestep Collection Time: 2.26225
Timestep Consumption Time: 2.51820
PPO Batch Consumption Time: 0.29293
Total Iteration Time: 4.78045

Cumulative Model Updates: 262,550
Cumulative Timesteps: 2,190,224,488

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 165,530.15294
Policy Entropy: 2.72442
Value Function Loss: 0.01170

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.06705
Policy Update Magnitude: 0.32102
Value Function Update Magnitude: 0.28595

Collected Steps per Second: 21,909.07650
Overall Steps per Second: 10,480.76755

Timestep Collection Time: 2.28335
Timestep Consumption Time: 2.48978
PPO Batch Consumption Time: 0.28990
Total Iteration Time: 4.77312

Cumulative Model Updates: 262,556
Cumulative Timesteps: 2,190,274,514

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2190274514...
Checkpoint 2190274514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 165,530.15294
Policy Entropy: 2.72785
Value Function Loss: 0.01080

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.07507
Policy Update Magnitude: 0.31336
Value Function Update Magnitude: 0.29757

Collected Steps per Second: 21,423.84517
Overall Steps per Second: 10,530.67124

Timestep Collection Time: 2.33422
Timestep Consumption Time: 2.41457
PPO Batch Consumption Time: 0.27823
Total Iteration Time: 4.74880

Cumulative Model Updates: 262,562
Cumulative Timesteps: 2,190,324,522

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 206,621.83145
Policy Entropy: 2.73142
Value Function Loss: 0.00987

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.06886
Policy Update Magnitude: 0.29608
Value Function Update Magnitude: 0.31471

Collected Steps per Second: 21,542.69437
Overall Steps per Second: 10,528.57852

Timestep Collection Time: 2.32134
Timestep Consumption Time: 2.42840
PPO Batch Consumption Time: 0.27880
Total Iteration Time: 4.74974

Cumulative Model Updates: 262,568
Cumulative Timesteps: 2,190,374,530

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2190374530...
Checkpoint 2190374530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 206,621.83145
Policy Entropy: 2.72290
Value Function Loss: 0.00898

Mean KL Divergence: 0.00752
SB3 Clip Fraction: 0.07019
Policy Update Magnitude: 0.29053
Value Function Update Magnitude: 0.29651

Collected Steps per Second: 21,747.37871
Overall Steps per Second: 10,554.68255

Timestep Collection Time: 2.30088
Timestep Consumption Time: 2.43996
PPO Batch Consumption Time: 0.27830
Total Iteration Time: 4.74083

Cumulative Model Updates: 262,574
Cumulative Timesteps: 2,190,424,568

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 164,920.34344
Policy Entropy: 2.72418
Value Function Loss: 0.01091

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.07352
Policy Update Magnitude: 0.30571
Value Function Update Magnitude: 0.27323

Collected Steps per Second: 21,629.18129
Overall Steps per Second: 10,547.81396

Timestep Collection Time: 2.31299
Timestep Consumption Time: 2.42999
PPO Batch Consumption Time: 0.28810
Total Iteration Time: 4.74297

Cumulative Model Updates: 262,580
Cumulative Timesteps: 2,190,474,596

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2190474596...
Checkpoint 2190474596 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 152,567.78105
Policy Entropy: 2.74434
Value Function Loss: 0.01053

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.07351
Policy Update Magnitude: 0.30787
Value Function Update Magnitude: 0.27335

Collected Steps per Second: 21,348.48124
Overall Steps per Second: 10,680.82840

Timestep Collection Time: 2.34312
Timestep Consumption Time: 2.34023
PPO Batch Consumption Time: 0.27729
Total Iteration Time: 4.68334

Cumulative Model Updates: 262,586
Cumulative Timesteps: 2,190,524,618

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 125,897.89144
Policy Entropy: 2.75138
Value Function Loss: 0.00975

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.07008
Policy Update Magnitude: 0.29197
Value Function Update Magnitude: 0.28377

Collected Steps per Second: 21,477.00732
Overall Steps per Second: 10,496.68156

Timestep Collection Time: 2.33012
Timestep Consumption Time: 2.43748
PPO Batch Consumption Time: 0.29308
Total Iteration Time: 4.76760

Cumulative Model Updates: 262,592
Cumulative Timesteps: 2,190,574,662

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 2190574662...
Checkpoint 2190574662 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 137,047.08983
Policy Entropy: 2.73840
Value Function Loss: 0.01055

Mean KL Divergence: 0.00712
SB3 Clip Fraction: 0.06955
Policy Update Magnitude: 0.29835
Value Function Update Magnitude: 0.27143

Collected Steps per Second: 21,182.11198
Overall Steps per Second: 10,480.98964

Timestep Collection Time: 2.36058
Timestep Consumption Time: 2.41016
PPO Batch Consumption Time: 0.27854
Total Iteration Time: 4.77073

Cumulative Model Updates: 262,598
Cumulative Timesteps: 2,190,624,664

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 128,571.35052
Policy Entropy: 2.71798
Value Function Loss: 0.01111

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.07449
Policy Update Magnitude: 0.31259
Value Function Update Magnitude: 0.29673

Collected Steps per Second: 22,147.31965
Overall Steps per Second: 10,540.96182

Timestep Collection Time: 2.25896
Timestep Consumption Time: 2.48728
PPO Batch Consumption Time: 0.29294
Total Iteration Time: 4.74625

Cumulative Model Updates: 262,604
Cumulative Timesteps: 2,190,674,694

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2190674694...
Checkpoint 2190674694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 156,570.84301
Policy Entropy: 2.71466
Value Function Loss: 0.01193

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.07491
Policy Update Magnitude: 0.31050
Value Function Update Magnitude: 0.32158

Collected Steps per Second: 21,934.61556
Overall Steps per Second: 10,733.24582

Timestep Collection Time: 2.28178
Timestep Consumption Time: 2.38130
PPO Batch Consumption Time: 0.27632
Total Iteration Time: 4.66308

Cumulative Model Updates: 262,610
Cumulative Timesteps: 2,190,724,744

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 213,826.58317
Policy Entropy: 2.71805
Value Function Loss: 0.01057

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.08386
Policy Update Magnitude: 0.31175
Value Function Update Magnitude: 0.30388

Collected Steps per Second: 21,946.64745
Overall Steps per Second: 10,474.02918

Timestep Collection Time: 2.27916
Timestep Consumption Time: 2.49646
PPO Batch Consumption Time: 0.29237
Total Iteration Time: 4.77562

Cumulative Model Updates: 262,616
Cumulative Timesteps: 2,190,774,764

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2190774764...
Checkpoint 2190774764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 174,168.16053
Policy Entropy: 2.72795
Value Function Loss: 0.01076

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.07064
Policy Update Magnitude: 0.30954
Value Function Update Magnitude: 0.29804

Collected Steps per Second: 21,521.73770
Overall Steps per Second: 10,517.58317

Timestep Collection Time: 2.32425
Timestep Consumption Time: 2.43178
PPO Batch Consumption Time: 0.27751
Total Iteration Time: 4.75604

Cumulative Model Updates: 262,622
Cumulative Timesteps: 2,190,824,786

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 125,067.45992
Policy Entropy: 2.72680
Value Function Loss: 0.01018

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.06911
Policy Update Magnitude: 0.30388
Value Function Update Magnitude: 0.30112

Collected Steps per Second: 21,284.25714
Overall Steps per Second: 10,459.14041

Timestep Collection Time: 2.34972
Timestep Consumption Time: 2.43194
PPO Batch Consumption Time: 0.27826
Total Iteration Time: 4.78165

Cumulative Model Updates: 262,628
Cumulative Timesteps: 2,190,874,798

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2190874798...
Checkpoint 2190874798 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 107,871.62748
Policy Entropy: 2.73648
Value Function Loss: 0.01116

Mean KL Divergence: 0.00762
SB3 Clip Fraction: 0.07178
Policy Update Magnitude: 0.30710
Value Function Update Magnitude: 0.29905

Collected Steps per Second: 21,353.72350
Overall Steps per Second: 10,330.94467

Timestep Collection Time: 2.34367
Timestep Consumption Time: 2.50061
PPO Batch Consumption Time: 0.29285
Total Iteration Time: 4.84428

Cumulative Model Updates: 262,634
Cumulative Timesteps: 2,190,924,844

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 74,256.87371
Policy Entropy: 2.71847
Value Function Loss: 0.01081

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.08105
Policy Update Magnitude: 0.31311
Value Function Update Magnitude: 0.29719

Collected Steps per Second: 21,812.69573
Overall Steps per Second: 10,402.17074

Timestep Collection Time: 2.29261
Timestep Consumption Time: 2.51485
PPO Batch Consumption Time: 0.29337
Total Iteration Time: 4.80746

Cumulative Model Updates: 262,640
Cumulative Timesteps: 2,190,974,852

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2190974852...
Checkpoint 2190974852 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 67,474.98932
Policy Entropy: 2.72632
Value Function Loss: 0.01153

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.08701
Policy Update Magnitude: 0.30971
Value Function Update Magnitude: 0.32913

Collected Steps per Second: 21,871.43401
Overall Steps per Second: 10,527.01874

Timestep Collection Time: 2.28618
Timestep Consumption Time: 2.46369
PPO Batch Consumption Time: 0.27846
Total Iteration Time: 4.74987

Cumulative Model Updates: 262,646
Cumulative Timesteps: 2,191,024,854

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67,474.98932
Policy Entropy: 2.73969
Value Function Loss: 0.00991

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.07505
Policy Update Magnitude: 0.30280
Value Function Update Magnitude: 0.31428

Collected Steps per Second: 21,477.79616
Overall Steps per Second: 10,510.88947

Timestep Collection Time: 2.32994
Timestep Consumption Time: 2.43103
PPO Batch Consumption Time: 0.29086
Total Iteration Time: 4.76097

Cumulative Model Updates: 262,652
Cumulative Timesteps: 2,191,074,896

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 2191074896...
Checkpoint 2191074896 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 82,320.15082
Policy Entropy: 2.75031
Value Function Loss: 0.01056

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.07460
Policy Update Magnitude: 0.30216
Value Function Update Magnitude: 0.31903

Collected Steps per Second: 21,378.61089
Overall Steps per Second: 10,637.76856

Timestep Collection Time: 2.33916
Timestep Consumption Time: 2.36183
PPO Batch Consumption Time: 0.27916
Total Iteration Time: 4.70099

Cumulative Model Updates: 262,658
Cumulative Timesteps: 2,191,124,904

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82,320.15082
Policy Entropy: 2.77092
Value Function Loss: 0.00944

Mean KL Divergence: 0.00711
SB3 Clip Fraction: 0.06493
Policy Update Magnitude: 0.29618
Value Function Update Magnitude: 0.30772

Collected Steps per Second: 21,570.96077
Overall Steps per Second: 10,540.35482

Timestep Collection Time: 2.31867
Timestep Consumption Time: 2.42652
PPO Batch Consumption Time: 0.29222
Total Iteration Time: 4.74519

Cumulative Model Updates: 262,664
Cumulative Timesteps: 2,191,174,920

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2191174920...
Checkpoint 2191174920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 85,181.51186
Policy Entropy: 2.78280
Value Function Loss: 0.00874

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.06993
Policy Update Magnitude: 0.27636
Value Function Update Magnitude: 0.28376

Collected Steps per Second: 21,406.17247
Overall Steps per Second: 10,533.62097

Timestep Collection Time: 2.33643
Timestep Consumption Time: 2.41161
PPO Batch Consumption Time: 0.27888
Total Iteration Time: 4.74803

Cumulative Model Updates: 262,670
Cumulative Timesteps: 2,191,224,934

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 71,526.66112
Policy Entropy: 2.78049
Value Function Loss: 0.00915

Mean KL Divergence: 0.00616
SB3 Clip Fraction: 0.05427
Policy Update Magnitude: 0.27302
Value Function Update Magnitude: 0.25092

Collected Steps per Second: 22,148.53543
Overall Steps per Second: 10,568.05905

Timestep Collection Time: 2.25902
Timestep Consumption Time: 2.47543
PPO Batch Consumption Time: 0.29244
Total Iteration Time: 4.73445

Cumulative Model Updates: 262,676
Cumulative Timesteps: 2,191,274,968

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 2191274968...
Checkpoint 2191274968 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 69,433.03282
Policy Entropy: 2.76867
Value Function Loss: 0.00927

Mean KL Divergence: 0.00586
SB3 Clip Fraction: 0.05331
Policy Update Magnitude: 0.28298
Value Function Update Magnitude: 0.27673

Collected Steps per Second: 21,614.19530
Overall Steps per Second: 10,640.56499

Timestep Collection Time: 2.31376
Timestep Consumption Time: 2.38618
PPO Batch Consumption Time: 0.27679
Total Iteration Time: 4.69994

Cumulative Model Updates: 262,682
Cumulative Timesteps: 2,191,324,978

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 69,433.03282
Policy Entropy: 2.75891
Value Function Loss: 0.00834

Mean KL Divergence: 0.00557
SB3 Clip Fraction: 0.05344
Policy Update Magnitude: 0.28300
Value Function Update Magnitude: 0.28136

Collected Steps per Second: 21,559.49639
Overall Steps per Second: 10,371.11501

Timestep Collection Time: 2.31981
Timestep Consumption Time: 2.50262
PPO Batch Consumption Time: 0.28942
Total Iteration Time: 4.82243

Cumulative Model Updates: 262,688
Cumulative Timesteps: 2,191,374,992

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2191374992...
Checkpoint 2191374992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 71,749.29501
Policy Entropy: 2.77558
Value Function Loss: 0.00805

Mean KL Divergence: 0.00603
SB3 Clip Fraction: 0.05691
Policy Update Magnitude: 0.27654
Value Function Update Magnitude: 0.26951

Collected Steps per Second: 21,418.89996
Overall Steps per Second: 10,326.09985

Timestep Collection Time: 2.33448
Timestep Consumption Time: 2.50781
PPO Batch Consumption Time: 0.29170
Total Iteration Time: 4.84229

Cumulative Model Updates: 262,694
Cumulative Timesteps: 2,191,424,994

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76,705.05254
Policy Entropy: 2.78644
Value Function Loss: 0.00765

Mean KL Divergence: 0.00708
SB3 Clip Fraction: 0.06442
Policy Update Magnitude: 0.26526
Value Function Update Magnitude: 0.25297

Collected Steps per Second: 21,981.50283
Overall Steps per Second: 10,499.49555

Timestep Collection Time: 2.27619
Timestep Consumption Time: 2.48919
PPO Batch Consumption Time: 0.29108
Total Iteration Time: 4.76537

Cumulative Model Updates: 262,700
Cumulative Timesteps: 2,191,475,028

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 2191475028...
Checkpoint 2191475028 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 99,010.03463
Policy Entropy: 2.79121
Value Function Loss: 0.00851

Mean KL Divergence: 0.00596
SB3 Clip Fraction: 0.05683
Policy Update Magnitude: 0.26962
Value Function Update Magnitude: 0.24628

Collected Steps per Second: 21,491.14044
Overall Steps per Second: 10,545.99926

Timestep Collection Time: 2.32775
Timestep Consumption Time: 2.41585
PPO Batch Consumption Time: 0.27651
Total Iteration Time: 4.74360

Cumulative Model Updates: 262,706
Cumulative Timesteps: 2,191,525,054

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99,010.03463
Policy Entropy: 2.78058
Value Function Loss: 0.00843

Mean KL Divergence: 0.00642
SB3 Clip Fraction: 0.05898
Policy Update Magnitude: 0.27380
Value Function Update Magnitude: 0.25993

Collected Steps per Second: 22,021.27993
Overall Steps per Second: 10,417.32920

Timestep Collection Time: 2.27071
Timestep Consumption Time: 2.52937
PPO Batch Consumption Time: 0.29300
Total Iteration Time: 4.80008

Cumulative Model Updates: 262,712
Cumulative Timesteps: 2,191,575,058

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2191575058...
Checkpoint 2191575058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 113,071.77403
Policy Entropy: 2.74662
Value Function Loss: 0.01232

Mean KL Divergence: 0.00644
SB3 Clip Fraction: 0.05715
Policy Update Magnitude: 0.30440
Value Function Update Magnitude: 0.29024

Collected Steps per Second: 21,940.33530
Overall Steps per Second: 10,569.33287

Timestep Collection Time: 2.28046
Timestep Consumption Time: 2.45343
PPO Batch Consumption Time: 0.27801
Total Iteration Time: 4.73388

Cumulative Model Updates: 262,718
Cumulative Timesteps: 2,191,625,092

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 113,071.77403
Policy Entropy: 2.74125
Value Function Loss: 0.01129

Mean KL Divergence: 0.00699
SB3 Clip Fraction: 0.06192
Policy Update Magnitude: 0.31606
Value Function Update Magnitude: 0.32862

Collected Steps per Second: 22,376.95771
Overall Steps per Second: 10,567.31844

Timestep Collection Time: 2.23551
Timestep Consumption Time: 2.49833
PPO Batch Consumption Time: 0.29196
Total Iteration Time: 4.73384

Cumulative Model Updates: 262,724
Cumulative Timesteps: 2,191,675,116

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2191675116...
Checkpoint 2191675116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 104,779.35752
Policy Entropy: 2.74722
Value Function Loss: 0.01088

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.07497
Policy Update Magnitude: 0.30779
Value Function Update Magnitude: 0.31100

Collected Steps per Second: 21,853.24617
Overall Steps per Second: 10,638.22319

Timestep Collection Time: 2.28845
Timestep Consumption Time: 2.41253
PPO Batch Consumption Time: 0.27686
Total Iteration Time: 4.70097

Cumulative Model Updates: 262,730
Cumulative Timesteps: 2,191,725,126

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87,983.97168
Policy Entropy: 2.74846
Value Function Loss: 0.01016

Mean KL Divergence: 0.00736
SB3 Clip Fraction: 0.06827
Policy Update Magnitude: 0.30636
Value Function Update Magnitude: 0.27924

Collected Steps per Second: 22,141.69027
Overall Steps per Second: 10,510.10170

Timestep Collection Time: 2.25945
Timestep Consumption Time: 2.50054
PPO Batch Consumption Time: 0.29117
Total Iteration Time: 4.75999

Cumulative Model Updates: 262,736
Cumulative Timesteps: 2,191,775,154

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2191775154...
Checkpoint 2191775154 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 81,282.83984
Policy Entropy: 2.74992
Value Function Loss: 0.00994

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.06983
Policy Update Magnitude: 0.30502
Value Function Update Magnitude: 0.28356

Collected Steps per Second: 21,934.80593
Overall Steps per Second: 10,506.74179

Timestep Collection Time: 2.28131
Timestep Consumption Time: 2.48135
PPO Batch Consumption Time: 0.28735
Total Iteration Time: 4.76266

Cumulative Model Updates: 262,742
Cumulative Timesteps: 2,191,825,194

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 154,064.79554
Policy Entropy: 2.74183
Value Function Loss: 0.01112

Mean KL Divergence: 0.00721
SB3 Clip Fraction: 0.06481
Policy Update Magnitude: 0.30549
Value Function Update Magnitude: 0.31144

Collected Steps per Second: 21,706.97083
Overall Steps per Second: 10,439.65512

Timestep Collection Time: 2.30359
Timestep Consumption Time: 2.48622
PPO Batch Consumption Time: 0.27905
Total Iteration Time: 4.78981

Cumulative Model Updates: 262,748
Cumulative Timesteps: 2,191,875,198

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2191875198...
Checkpoint 2191875198 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 135,701.99366
Policy Entropy: 2.77123
Value Function Loss: 0.01152

Mean KL Divergence: 0.00619
SB3 Clip Fraction: 0.05951
Policy Update Magnitude: 0.31400
Value Function Update Magnitude: 0.32210

Collected Steps per Second: 21,381.22801
Overall Steps per Second: 10,322.64987

Timestep Collection Time: 2.33962
Timestep Consumption Time: 2.50642
PPO Batch Consumption Time: 0.29368
Total Iteration Time: 4.84604

Cumulative Model Updates: 262,754
Cumulative Timesteps: 2,191,925,222

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 135,701.99366
Policy Entropy: 2.76250
Value Function Loss: 0.01175

Mean KL Divergence: 0.00709
SB3 Clip Fraction: 0.06610
Policy Update Magnitude: 0.32183
Value Function Update Magnitude: 0.31428

Collected Steps per Second: 21,799.23476
Overall Steps per Second: 10,444.11899

Timestep Collection Time: 2.29604
Timestep Consumption Time: 2.49632
PPO Batch Consumption Time: 0.29188
Total Iteration Time: 4.79236

Cumulative Model Updates: 262,760
Cumulative Timesteps: 2,191,975,274

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


Saving checkpoint 2191975274...
Checkpoint 2191975274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 94,248.52003
Policy Entropy: 2.73278
Value Function Loss: 0.01125

Mean KL Divergence: 0.00758
SB3 Clip Fraction: 0.06987
Policy Update Magnitude: 0.31647
Value Function Update Magnitude: 0.32054

Collected Steps per Second: 21,315.44909
Overall Steps per Second: 10,488.92632

Timestep Collection Time: 2.34712
Timestep Consumption Time: 2.42267
PPO Batch Consumption Time: 0.27765
Total Iteration Time: 4.76979

Cumulative Model Updates: 262,766
Cumulative Timesteps: 2,192,025,304

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 213,862.21419
Policy Entropy: 2.70027
Value Function Loss: 0.01215

Mean KL Divergence: 0.00695
SB3 Clip Fraction: 0.06496
Policy Update Magnitude: 0.32271
Value Function Update Magnitude: 0.30541

Collected Steps per Second: 21,713.51740
Overall Steps per Second: 10,596.18346

Timestep Collection Time: 2.30428
Timestep Consumption Time: 2.41761
PPO Batch Consumption Time: 0.27626
Total Iteration Time: 4.72189

Cumulative Model Updates: 262,772
Cumulative Timesteps: 2,192,075,338

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 2192075338...
Checkpoint 2192075338 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 276,784.60938
Policy Entropy: 2.70818
Value Function Loss: 0.01291

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.07265
Policy Update Magnitude: 0.33909
Value Function Update Magnitude: 0.31413

Collected Steps per Second: 21,542.81543
Overall Steps per Second: 10,523.26519

Timestep Collection Time: 2.32217
Timestep Consumption Time: 2.43168
PPO Batch Consumption Time: 0.27841
Total Iteration Time: 4.75385

Cumulative Model Updates: 262,778
Cumulative Timesteps: 2,192,125,364

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 211,062.38625
Policy Entropy: 2.72225
Value Function Loss: 0.01305

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.07025
Policy Update Magnitude: 0.33226
Value Function Update Magnitude: 0.33292

Collected Steps per Second: 22,043.88941
Overall Steps per Second: 10,588.67552

Timestep Collection Time: 2.27056
Timestep Consumption Time: 2.45638
PPO Batch Consumption Time: 0.27743
Total Iteration Time: 4.72694

Cumulative Model Updates: 262,784
Cumulative Timesteps: 2,192,175,416

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


Saving checkpoint 2192175416...
Checkpoint 2192175416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 211,062.38625
Policy Entropy: 2.75964
Value Function Loss: 0.01044

Mean KL Divergence: 0.00731
SB3 Clip Fraction: 0.06621
Policy Update Magnitude: 0.32026
Value Function Update Magnitude: 0.32208

Collected Steps per Second: 21,745.65550
Overall Steps per Second: 10,486.77762

Timestep Collection Time: 2.29949
Timestep Consumption Time: 2.46880
PPO Batch Consumption Time: 0.27915
Total Iteration Time: 4.76829

Cumulative Model Updates: 262,790
Cumulative Timesteps: 2,192,225,420

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 123,124.95462
Policy Entropy: 2.75732
Value Function Loss: 0.01138

Mean KL Divergence: 0.00709
SB3 Clip Fraction: 0.06678
Policy Update Magnitude: 0.31783
Value Function Update Magnitude: 0.30645

Collected Steps per Second: 22,044.47208
Overall Steps per Second: 10,491.87804

Timestep Collection Time: 2.26914
Timestep Consumption Time: 2.49855
PPO Batch Consumption Time: 0.28869
Total Iteration Time: 4.76769

Cumulative Model Updates: 262,796
Cumulative Timesteps: 2,192,275,442

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2192275442...
Checkpoint 2192275442 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 124,314.80748
Policy Entropy: 2.74286
Value Function Loss: 0.01208

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.06821
Policy Update Magnitude: 0.32697
Value Function Update Magnitude: 0.33272

Collected Steps per Second: 22,052.68852
Overall Steps per Second: 10,667.29097

Timestep Collection Time: 2.26784
Timestep Consumption Time: 2.42051
PPO Batch Consumption Time: 0.27858
Total Iteration Time: 4.68835

Cumulative Model Updates: 262,802
Cumulative Timesteps: 2,192,325,454

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78,103.21631
Policy Entropy: 2.74088
Value Function Loss: 0.01330

Mean KL Divergence: 0.00679
SB3 Clip Fraction: 0.06313
Policy Update Magnitude: 0.33371
Value Function Update Magnitude: 0.35028

Collected Steps per Second: 22,254.81325
Overall Steps per Second: 10,508.11082

Timestep Collection Time: 2.24724
Timestep Consumption Time: 2.51213
PPO Batch Consumption Time: 0.29201
Total Iteration Time: 4.75937

Cumulative Model Updates: 262,808
Cumulative Timesteps: 2,192,375,466

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2192375466...
Checkpoint 2192375466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 71,184.66130
Policy Entropy: 2.74621
Value Function Loss: 0.01267

Mean KL Divergence: 0.00620
SB3 Clip Fraction: 0.05915
Policy Update Magnitude: 0.33881
Value Function Update Magnitude: 0.35252

Collected Steps per Second: 22,051.84574
Overall Steps per Second: 10,572.90267

Timestep Collection Time: 2.26738
Timestep Consumption Time: 2.46169
PPO Batch Consumption Time: 0.28450
Total Iteration Time: 4.72907

Cumulative Model Updates: 262,814
Cumulative Timesteps: 2,192,425,466

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52,033.65914
Policy Entropy: 2.76496
Value Function Loss: 0.01182

Mean KL Divergence: 0.00606
SB3 Clip Fraction: 0.05541
Policy Update Magnitude: 0.32857
Value Function Update Magnitude: 0.35102

Collected Steps per Second: 22,030.60281
Overall Steps per Second: 10,468.21884

Timestep Collection Time: 2.26966
Timestep Consumption Time: 2.50689
PPO Batch Consumption Time: 0.29240
Total Iteration Time: 4.77655

Cumulative Model Updates: 262,820
Cumulative Timesteps: 2,192,475,468

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2192475468...
Checkpoint 2192475468 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 71,006.23143
Policy Entropy: 2.75130
Value Function Loss: 0.01191

Mean KL Divergence: 0.00731
SB3 Clip Fraction: 0.06451
Policy Update Magnitude: 0.31739
Value Function Update Magnitude: 0.31045

Collected Steps per Second: 21,356.80473
Overall Steps per Second: 10,358.51400

Timestep Collection Time: 2.34239
Timestep Consumption Time: 2.48707
PPO Batch Consumption Time: 0.29029
Total Iteration Time: 4.82946

Cumulative Model Updates: 262,826
Cumulative Timesteps: 2,192,525,494

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 64,311.64875
Policy Entropy: 2.77113
Value Function Loss: 0.01176

Mean KL Divergence: 0.00670
SB3 Clip Fraction: 0.06510
Policy Update Magnitude: 0.31254
Value Function Update Magnitude: 0.29723

Collected Steps per Second: 21,897.20557
Overall Steps per Second: 10,653.43903

Timestep Collection Time: 2.28522
Timestep Consumption Time: 2.41185
PPO Batch Consumption Time: 0.27756
Total Iteration Time: 4.69707

Cumulative Model Updates: 262,832
Cumulative Timesteps: 2,192,575,534

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 2192575534...
Checkpoint 2192575534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 101,503.53793
Policy Entropy: 2.77026
Value Function Loss: 0.01150

Mean KL Divergence: 0.00697
SB3 Clip Fraction: 0.06669
Policy Update Magnitude: 0.30417
Value Function Update Magnitude: 0.30188

Collected Steps per Second: 21,350.88287
Overall Steps per Second: 10,318.61770

Timestep Collection Time: 2.34229
Timestep Consumption Time: 2.50429
PPO Batch Consumption Time: 0.29231
Total Iteration Time: 4.84658

Cumulative Model Updates: 262,838
Cumulative Timesteps: 2,192,625,544

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 101,503.53793
Policy Entropy: 2.79900
Value Function Loss: 0.00962

Mean KL Divergence: 0.00624
SB3 Clip Fraction: 0.05989
Policy Update Magnitude: 0.29253
Value Function Update Magnitude: 0.26656

Collected Steps per Second: 21,697.45695
Overall Steps per Second: 10,404.83749

Timestep Collection Time: 2.30451
Timestep Consumption Time: 2.50114
PPO Batch Consumption Time: 0.28981
Total Iteration Time: 4.80565

Cumulative Model Updates: 262,844
Cumulative Timesteps: 2,192,675,546

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2192675546...
Checkpoint 2192675546 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 92,363.51861
Policy Entropy: 2.78127
Value Function Loss: 0.00955

Mean KL Divergence: 0.00573
SB3 Clip Fraction: 0.05498
Policy Update Magnitude: 0.28291
Value Function Update Magnitude: 0.22781

Collected Steps per Second: 21,191.50755
Overall Steps per Second: 10,604.55054

Timestep Collection Time: 2.36038
Timestep Consumption Time: 2.35646
PPO Batch Consumption Time: 0.27761
Total Iteration Time: 4.71684

Cumulative Model Updates: 262,850
Cumulative Timesteps: 2,192,725,566

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97,621.56682
Policy Entropy: 2.79307
Value Function Loss: 0.00981

Mean KL Divergence: 0.00594
SB3 Clip Fraction: 0.05634
Policy Update Magnitude: 0.28257
Value Function Update Magnitude: 0.19167

Collected Steps per Second: 21,136.62722
Overall Steps per Second: 10,482.43820

Timestep Collection Time: 2.36641
Timestep Consumption Time: 2.40519
PPO Batch Consumption Time: 0.27826
Total Iteration Time: 4.77160

Cumulative Model Updates: 262,856
Cumulative Timesteps: 2,192,775,584

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2192775584...
Checkpoint 2192775584 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 128,071.62436
Policy Entropy: 2.78231
Value Function Loss: 0.01201

Mean KL Divergence: 0.00611
SB3 Clip Fraction: 0.05703
Policy Update Magnitude: 0.29816
Value Function Update Magnitude: 0.22073

Collected Steps per Second: 21,451.16445
Overall Steps per Second: 10,680.19853

Timestep Collection Time: 2.33116
Timestep Consumption Time: 2.35097
PPO Batch Consumption Time: 0.27685
Total Iteration Time: 4.68212

Cumulative Model Updates: 262,862
Cumulative Timesteps: 2,192,825,590

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 174,318.99807
Policy Entropy: 2.79130
Value Function Loss: 0.01158

Mean KL Divergence: 0.00683
SB3 Clip Fraction: 0.06178
Policy Update Magnitude: 0.30981
Value Function Update Magnitude: 0.24541

Collected Steps per Second: 21,674.24766
Overall Steps per Second: 10,429.60496

Timestep Collection Time: 2.30744
Timestep Consumption Time: 2.48776
PPO Batch Consumption Time: 0.29409
Total Iteration Time: 4.79520

Cumulative Model Updates: 262,868
Cumulative Timesteps: 2,192,875,602

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2192875602...
Checkpoint 2192875602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 148,616.67938
Policy Entropy: 2.75446
Value Function Loss: 0.01275

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.07524
Policy Update Magnitude: 0.32518
Value Function Update Magnitude: 0.29223

Collected Steps per Second: 21,930.72858
Overall Steps per Second: 10,624.80133

Timestep Collection Time: 2.28027
Timestep Consumption Time: 2.42645
PPO Batch Consumption Time: 0.28423
Total Iteration Time: 4.70672

Cumulative Model Updates: 262,874
Cumulative Timesteps: 2,192,925,610

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82,735.70592
Policy Entropy: 2.75174
Value Function Loss: 0.01200

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.08334
Policy Update Magnitude: 0.33702
Value Function Update Magnitude: 0.32521

Collected Steps per Second: 21,927.57614
Overall Steps per Second: 10,505.69780

Timestep Collection Time: 2.28133
Timestep Consumption Time: 2.48028
PPO Batch Consumption Time: 0.29333
Total Iteration Time: 4.76161

Cumulative Model Updates: 262,880
Cumulative Timesteps: 2,192,975,634

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2192975634...
Checkpoint 2192975634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 78,777.19946
Policy Entropy: 2.75671
Value Function Loss: 0.01224

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.08768
Policy Update Magnitude: 0.33593
Value Function Update Magnitude: 0.34364

Collected Steps per Second: 22,067.84957
Overall Steps per Second: 10,572.89990

Timestep Collection Time: 2.26583
Timestep Consumption Time: 2.46343
PPO Batch Consumption Time: 0.28441
Total Iteration Time: 4.72926

Cumulative Model Updates: 262,886
Cumulative Timesteps: 2,193,025,636

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 98,371.15915
Policy Entropy: 2.76299
Value Function Loss: 0.01257

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.07914
Policy Update Magnitude: 0.33416
Value Function Update Magnitude: 0.33289

Collected Steps per Second: 21,945.77152
Overall Steps per Second: 10,466.47341

Timestep Collection Time: 2.27880
Timestep Consumption Time: 2.49931
PPO Batch Consumption Time: 0.28876
Total Iteration Time: 4.77811

Cumulative Model Updates: 262,892
Cumulative Timesteps: 2,193,075,646

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2193075646...
Checkpoint 2193075646 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 125,408.73977
Policy Entropy: 2.78016
Value Function Loss: 0.01085

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.07709
Policy Update Magnitude: 0.31806
Value Function Update Magnitude: 0.30953

Collected Steps per Second: 21,661.81523
Overall Steps per Second: 10,567.63527

Timestep Collection Time: 2.30904
Timestep Consumption Time: 2.42409
PPO Batch Consumption Time: 0.27799
Total Iteration Time: 4.73313

Cumulative Model Updates: 262,898
Cumulative Timesteps: 2,193,125,664

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 123,586.76787
Policy Entropy: 2.76370
Value Function Loss: 0.01206

Mean KL Divergence: 0.00766
SB3 Clip Fraction: 0.07240
Policy Update Magnitude: 0.31676
Value Function Update Magnitude: 0.31521

Collected Steps per Second: 21,340.60625
Overall Steps per Second: 10,448.98760

Timestep Collection Time: 2.34323
Timestep Consumption Time: 2.44249
PPO Batch Consumption Time: 0.27858
Total Iteration Time: 4.78573

Cumulative Model Updates: 262,904
Cumulative Timesteps: 2,193,175,670

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2193175670...
Checkpoint 2193175670 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 98,289.80095
Policy Entropy: 2.75648
Value Function Loss: 0.01148

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.07268
Policy Update Magnitude: 0.31883
Value Function Update Magnitude: 0.31995

Collected Steps per Second: 21,580.20190
Overall Steps per Second: 10,328.22229

Timestep Collection Time: 2.31888
Timestep Consumption Time: 2.52629
PPO Batch Consumption Time: 0.29276
Total Iteration Time: 4.84517

Cumulative Model Updates: 262,910
Cumulative Timesteps: 2,193,225,712

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 98,289.80095
Policy Entropy: 2.75635
Value Function Loss: 0.01043

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.08217
Policy Update Magnitude: 0.30594
Value Function Update Magnitude: 0.30614

Collected Steps per Second: 22,002.52638
Overall Steps per Second: 10,392.83417

Timestep Collection Time: 2.27338
Timestep Consumption Time: 2.53956
PPO Batch Consumption Time: 0.29144
Total Iteration Time: 4.81293

Cumulative Model Updates: 262,916
Cumulative Timesteps: 2,193,275,732

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2193275732...
Checkpoint 2193275732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 139,429.68012
Policy Entropy: 2.76674
Value Function Loss: 0.01161

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.07605
Policy Update Magnitude: 0.31273
Value Function Update Magnitude: 0.28996

Collected Steps per Second: 22,109.31340
Overall Steps per Second: 10,690.90349

Timestep Collection Time: 2.26149
Timestep Consumption Time: 2.41538
PPO Batch Consumption Time: 0.27663
Total Iteration Time: 4.67687

Cumulative Model Updates: 262,922
Cumulative Timesteps: 2,193,325,732

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 109,856.30110
Policy Entropy: 2.78690
Value Function Loss: 0.01038

Mean KL Divergence: 0.01139
SB3 Clip Fraction: 0.09629
Policy Update Magnitude: 0.31694
Value Function Update Magnitude: 0.30306

Collected Steps per Second: 22,225.11277
Overall Steps per Second: 10,516.60874

Timestep Collection Time: 2.25025
Timestep Consumption Time: 2.50528
PPO Batch Consumption Time: 0.29200
Total Iteration Time: 4.75553

Cumulative Model Updates: 262,928
Cumulative Timesteps: 2,193,375,744

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2193375744...
Checkpoint 2193375744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 113,192.51010
Policy Entropy: 2.78267
Value Function Loss: 0.01105

Mean KL Divergence: 0.01188
SB3 Clip Fraction: 0.09722
Policy Update Magnitude: 0.30826
Value Function Update Magnitude: 0.32002

Collected Steps per Second: 22,038.57332
Overall Steps per Second: 10,519.84509

Timestep Collection Time: 2.26929
Timestep Consumption Time: 2.48477
PPO Batch Consumption Time: 0.28849
Total Iteration Time: 4.75406

Cumulative Model Updates: 262,934
Cumulative Timesteps: 2,193,425,756

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97,492.94023
Policy Entropy: 2.79396
Value Function Loss: 0.01008

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.08100
Policy Update Magnitude: 0.30944
Value Function Update Magnitude: 0.32422

Collected Steps per Second: 22,164.80289
Overall Steps per Second: 10,536.55201

Timestep Collection Time: 2.25646
Timestep Consumption Time: 2.49025
PPO Batch Consumption Time: 0.29244
Total Iteration Time: 4.74671

Cumulative Model Updates: 262,940
Cumulative Timesteps: 2,193,475,770

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2193475770...
Checkpoint 2193475770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 80,680.93116
Policy Entropy: 2.79764
Value Function Loss: 0.01141

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.06983
Policy Update Magnitude: 0.30864
Value Function Update Magnitude: 0.31464

Collected Steps per Second: 21,968.28410
Overall Steps per Second: 10,561.40561

Timestep Collection Time: 2.27637
Timestep Consumption Time: 2.45860
PPO Batch Consumption Time: 0.28578
Total Iteration Time: 4.73498

Cumulative Model Updates: 262,946
Cumulative Timesteps: 2,193,525,778

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80,680.93116
Policy Entropy: 2.82055
Value Function Loss: 0.01022

Mean KL Divergence: 0.00706
SB3 Clip Fraction: 0.06831
Policy Update Magnitude: 0.29720
Value Function Update Magnitude: 0.28699

Collected Steps per Second: 21,458.99007
Overall Steps per Second: 10,509.83538

Timestep Collection Time: 2.33217
Timestep Consumption Time: 2.42966
PPO Batch Consumption Time: 0.29231
Total Iteration Time: 4.76183

Cumulative Model Updates: 262,952
Cumulative Timesteps: 2,193,575,824

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 2193575824...
Checkpoint 2193575824 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 88,652.62651
Policy Entropy: 2.81454
Value Function Loss: 0.00973

Mean KL Divergence: 0.00764
SB3 Clip Fraction: 0.07006
Policy Update Magnitude: 0.29531
Value Function Update Magnitude: 0.27029

Collected Steps per Second: 20,557.02621
Overall Steps per Second: 10,273.24630

Timestep Collection Time: 2.43343
Timestep Consumption Time: 2.43592
PPO Batch Consumption Time: 0.29197
Total Iteration Time: 4.86935

Cumulative Model Updates: 262,958
Cumulative Timesteps: 2,193,625,848

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62,004.60607
Policy Entropy: 2.81148
Value Function Loss: 0.01019

Mean KL Divergence: 0.00726
SB3 Clip Fraction: 0.06579
Policy Update Magnitude: 0.30638
Value Function Update Magnitude: 0.29279

Collected Steps per Second: 21,296.76876
Overall Steps per Second: 10,508.97536

Timestep Collection Time: 2.34862
Timestep Consumption Time: 2.41093
PPO Batch Consumption Time: 0.28929
Total Iteration Time: 4.75955

Cumulative Model Updates: 262,964
Cumulative Timesteps: 2,193,675,866

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2193675866...
Checkpoint 2193675866 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 58,351.15652
Policy Entropy: 2.78493
Value Function Loss: 0.01037

Mean KL Divergence: 0.00718
SB3 Clip Fraction: 0.06437
Policy Update Magnitude: 0.31543
Value Function Update Magnitude: 0.32632

Collected Steps per Second: 20,993.78353
Overall Steps per Second: 10,424.62292

Timestep Collection Time: 2.38280
Timestep Consumption Time: 2.41584
PPO Batch Consumption Time: 0.27873
Total Iteration Time: 4.79864

Cumulative Model Updates: 262,970
Cumulative Timesteps: 2,193,725,890

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50,309.74260
Policy Entropy: 2.78854
Value Function Loss: 0.00977

Mean KL Divergence: 0.00711
SB3 Clip Fraction: 0.06152
Policy Update Magnitude: 0.31391
Value Function Update Magnitude: 0.35352

Collected Steps per Second: 21,094.39908
Overall Steps per Second: 10,437.43205

Timestep Collection Time: 2.37162
Timestep Consumption Time: 2.42151
PPO Batch Consumption Time: 0.27920
Total Iteration Time: 4.79313

Cumulative Model Updates: 262,976
Cumulative Timesteps: 2,193,775,918

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2193775918...
Checkpoint 2193775918 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 94,866.79710
Policy Entropy: 2.78476
Value Function Loss: 0.01025

Mean KL Divergence: 0.00718
SB3 Clip Fraction: 0.05904
Policy Update Magnitude: 0.31397
Value Function Update Magnitude: 0.36709

Collected Steps per Second: 21,069.40501
Overall Steps per Second: 10,303.26651

Timestep Collection Time: 2.37368
Timestep Consumption Time: 2.48032
PPO Batch Consumption Time: 0.29303
Total Iteration Time: 4.85399

Cumulative Model Updates: 262,982
Cumulative Timesteps: 2,193,825,930

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86,246.62043
Policy Entropy: 2.80045
Value Function Loss: 0.01009

Mean KL Divergence: 0.00743
SB3 Clip Fraction: 0.05838
Policy Update Magnitude: 0.30699
Value Function Update Magnitude: 0.34772

Collected Steps per Second: 21,855.07655
Overall Steps per Second: 10,513.97709

Timestep Collection Time: 2.28871
Timestep Consumption Time: 2.46876
PPO Batch Consumption Time: 0.29244
Total Iteration Time: 4.75748

Cumulative Model Updates: 262,988
Cumulative Timesteps: 2,193,875,950

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2193875950...
Checkpoint 2193875950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 104,954.53414
Policy Entropy: 2.78848
Value Function Loss: 0.01002

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.06462
Policy Update Magnitude: 0.29617
Value Function Update Magnitude: 0.30979

Collected Steps per Second: 21,609.10616
Overall Steps per Second: 10,566.22390

Timestep Collection Time: 2.31532
Timestep Consumption Time: 2.41977
PPO Batch Consumption Time: 0.27671
Total Iteration Time: 4.73509

Cumulative Model Updates: 262,994
Cumulative Timesteps: 2,193,925,982

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 108,427.46850
Policy Entropy: 2.80028
Value Function Loss: 0.00993

Mean KL Divergence: 0.00678
SB3 Clip Fraction: 0.06379
Policy Update Magnitude: 0.29157
Value Function Update Magnitude: 0.26512

Collected Steps per Second: 22,215.07578
Overall Steps per Second: 10,429.61703

Timestep Collection Time: 2.25162
Timestep Consumption Time: 2.54433
PPO Batch Consumption Time: 0.29297
Total Iteration Time: 4.79596

Cumulative Model Updates: 263,000
Cumulative Timesteps: 2,193,976,002

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2193976002...
Checkpoint 2193976002 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 109,116.36052
Policy Entropy: 2.79608
Value Function Loss: 0.01188

Mean KL Divergence: 0.00716
SB3 Clip Fraction: 0.06393
Policy Update Magnitude: 0.30165
Value Function Update Magnitude: 0.28009

Collected Steps per Second: 21,562.76669
Overall Steps per Second: 10,512.23802

Timestep Collection Time: 2.31881
Timestep Consumption Time: 2.43755
PPO Batch Consumption Time: 0.27916
Total Iteration Time: 4.75636

Cumulative Model Updates: 263,006
Cumulative Timesteps: 2,194,026,002

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 133,748.45607
Policy Entropy: 2.80232
Value Function Loss: 0.01147

Mean KL Divergence: 0.00702
SB3 Clip Fraction: 0.06346
Policy Update Magnitude: 0.30497
Value Function Update Magnitude: 0.32193

Collected Steps per Second: 21,176.84725
Overall Steps per Second: 10,291.87352

Timestep Collection Time: 2.36258
Timestep Consumption Time: 2.49873
PPO Batch Consumption Time: 0.29112
Total Iteration Time: 4.86131

Cumulative Model Updates: 263,012
Cumulative Timesteps: 2,194,076,034

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2194076034...
Checkpoint 2194076034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 107,293.51643
Policy Entropy: 2.80224
Value Function Loss: 0.01262

Mean KL Divergence: 0.00711
SB3 Clip Fraction: 0.06784
Policy Update Magnitude: 0.30715
Value Function Update Magnitude: 0.30774

Collected Steps per Second: 21,719.85656
Overall Steps per Second: 10,460.88911

Timestep Collection Time: 2.30397
Timestep Consumption Time: 2.47975
PPO Batch Consumption Time: 0.28607
Total Iteration Time: 4.78372

Cumulative Model Updates: 263,018
Cumulative Timesteps: 2,194,126,076

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70,834.23518
Policy Entropy: 2.79383
Value Function Loss: 0.01254

Mean KL Divergence: 0.00722
SB3 Clip Fraction: 0.06930
Policy Update Magnitude: 0.30449
Value Function Update Magnitude: 0.31804

Collected Steps per Second: 22,172.92443
Overall Steps per Second: 10,464.70952

Timestep Collection Time: 2.25554
Timestep Consumption Time: 2.52357
PPO Batch Consumption Time: 0.29476
Total Iteration Time: 4.77911

Cumulative Model Updates: 263,024
Cumulative Timesteps: 2,194,176,088

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2194176088...
Checkpoint 2194176088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 74,434.35943
Policy Entropy: 2.75585
Value Function Loss: 0.01341

Mean KL Divergence: 0.00679
SB3 Clip Fraction: 0.06325
Policy Update Magnitude: 0.32334
Value Function Update Magnitude: 0.28940

Collected Steps per Second: 21,627.98899
Overall Steps per Second: 10,551.34902

Timestep Collection Time: 2.31247
Timestep Consumption Time: 2.42759
PPO Batch Consumption Time: 0.27848
Total Iteration Time: 4.74006

Cumulative Model Updates: 263,030
Cumulative Timesteps: 2,194,226,102

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 74,434.35943
Policy Entropy: 2.75540
Value Function Loss: 0.01131

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.07088
Policy Update Magnitude: 0.32267
Value Function Update Magnitude: 0.28693

Collected Steps per Second: 22,158.16111
Overall Steps per Second: 10,548.47403

Timestep Collection Time: 2.25660
Timestep Consumption Time: 2.48362
PPO Batch Consumption Time: 0.28868
Total Iteration Time: 4.74021

Cumulative Model Updates: 263,036
Cumulative Timesteps: 2,194,276,104

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2194276104...
Checkpoint 2194276104 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 102,109.06446
Policy Entropy: 2.76808
Value Function Loss: 0.01044

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.07144
Policy Update Magnitude: 0.30482
Value Function Update Magnitude: 0.28241

Collected Steps per Second: 21,245.87634
Overall Steps per Second: 10,334.72483

Timestep Collection Time: 2.35349
Timestep Consumption Time: 2.48476
PPO Batch Consumption Time: 0.29056
Total Iteration Time: 4.83825

Cumulative Model Updates: 263,042
Cumulative Timesteps: 2,194,326,106

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 69,471.73088
Policy Entropy: 2.78779
Value Function Loss: 0.01133

Mean KL Divergence: 0.00666
SB3 Clip Fraction: 0.06389
Policy Update Magnitude: 0.30722
Value Function Update Magnitude: 0.26724

Collected Steps per Second: 21,889.21983
Overall Steps per Second: 10,516.00361

Timestep Collection Time: 2.28578
Timestep Consumption Time: 2.47211
PPO Batch Consumption Time: 0.28806
Total Iteration Time: 4.75789

Cumulative Model Updates: 263,048
Cumulative Timesteps: 2,194,376,140

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 2194376140...
Checkpoint 2194376140 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 62,897.58634
Policy Entropy: 2.78974
Value Function Loss: 0.01123

Mean KL Divergence: 0.00659
SB3 Clip Fraction: 0.06049
Policy Update Magnitude: 0.29348
Value Function Update Magnitude: 0.26063

Collected Steps per Second: 21,397.79564
Overall Steps per Second: 10,424.28977

Timestep Collection Time: 2.33725
Timestep Consumption Time: 2.46039
PPO Batch Consumption Time: 0.28484
Total Iteration Time: 4.79764

Cumulative Model Updates: 263,054
Cumulative Timesteps: 2,194,426,152

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62,897.58634
Policy Entropy: 2.80188
Value Function Loss: 0.00953

Mean KL Divergence: 0.00621
SB3 Clip Fraction: 0.05720
Policy Update Magnitude: 0.27467
Value Function Update Magnitude: 0.26012

Collected Steps per Second: 21,189.27125
Overall Steps per Second: 10,445.45255

Timestep Collection Time: 2.36072
Timestep Consumption Time: 2.42816
PPO Batch Consumption Time: 0.28853
Total Iteration Time: 4.78888

Cumulative Model Updates: 263,060
Cumulative Timesteps: 2,194,476,174

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2194476174...
Checkpoint 2194476174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 71,235.57489
Policy Entropy: 2.81192
Value Function Loss: 0.01159

Mean KL Divergence: 0.00661
SB3 Clip Fraction: 0.06306
Policy Update Magnitude: 0.28728
Value Function Update Magnitude: 0.26202

Collected Steps per Second: 20,649.37370
Overall Steps per Second: 10,294.25422

Timestep Collection Time: 2.42148
Timestep Consumption Time: 2.43579
PPO Batch Consumption Time: 0.29289
Total Iteration Time: 4.85727

Cumulative Model Updates: 263,066
Cumulative Timesteps: 2,194,526,176

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 120,760.70684
Policy Entropy: 2.81326
Value Function Loss: 0.01152

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.07445
Policy Update Magnitude: 0.30094
Value Function Update Magnitude: 0.30265

Collected Steps per Second: 21,756.38090
Overall Steps per Second: 10,542.39579

Timestep Collection Time: 2.29937
Timestep Consumption Time: 2.44585
PPO Batch Consumption Time: 0.29032
Total Iteration Time: 4.74522

Cumulative Model Updates: 263,072
Cumulative Timesteps: 2,194,576,202

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2194576202...
Checkpoint 2194576202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 102,440.85608
Policy Entropy: 2.81337
Value Function Loss: 0.01280

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.08233
Policy Update Magnitude: 0.29819
Value Function Update Magnitude: 0.30291

Collected Steps per Second: 21,406.04884
Overall Steps per Second: 10,517.69841

Timestep Collection Time: 2.33616
Timestep Consumption Time: 2.41849
PPO Batch Consumption Time: 0.27742
Total Iteration Time: 4.75465

Cumulative Model Updates: 263,078
Cumulative Timesteps: 2,194,626,210

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 102,440.85608
Policy Entropy: 2.80285
Value Function Loss: 0.01049

Mean KL Divergence: 0.01095
SB3 Clip Fraction: 0.09213
Policy Update Magnitude: 0.29495
Value Function Update Magnitude: 0.31332

Collected Steps per Second: 22,462.99618
Overall Steps per Second: 10,802.04574

Timestep Collection Time: 2.22704
Timestep Consumption Time: 2.40412
PPO Batch Consumption Time: 0.27837
Total Iteration Time: 4.63116

Cumulative Model Updates: 263,084
Cumulative Timesteps: 2,194,676,236

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2194676236...
Checkpoint 2194676236 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 114,444.50180
Policy Entropy: 2.79747
Value Function Loss: 0.01230

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.07670
Policy Update Magnitude: 0.31267
Value Function Update Magnitude: 0.28910

Collected Steps per Second: 21,799.56460
Overall Steps per Second: 10,662.37478

Timestep Collection Time: 2.29528
Timestep Consumption Time: 2.39749
PPO Batch Consumption Time: 0.27802
Total Iteration Time: 4.69276

Cumulative Model Updates: 263,090
Cumulative Timesteps: 2,194,726,272

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 154,592.38585
Policy Entropy: 2.78765
Value Function Loss: 0.01250

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.07861
Policy Update Magnitude: 0.32051
Value Function Update Magnitude: 0.31373

Collected Steps per Second: 22,412.41422
Overall Steps per Second: 10,548.49563

Timestep Collection Time: 2.23269
Timestep Consumption Time: 2.51111
PPO Batch Consumption Time: 0.29355
Total Iteration Time: 4.74380

Cumulative Model Updates: 263,096
Cumulative Timesteps: 2,194,776,312

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 2194776312...
Checkpoint 2194776312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 122,375.55889
Policy Entropy: 2.79476
Value Function Loss: 0.01195

Mean KL Divergence: 0.00698
SB3 Clip Fraction: 0.06376
Policy Update Magnitude: 0.31119
Value Function Update Magnitude: 0.33217

Collected Steps per Second: 21,786.61577
Overall Steps per Second: 10,599.47465

Timestep Collection Time: 2.29517
Timestep Consumption Time: 2.42242
PPO Batch Consumption Time: 0.27707
Total Iteration Time: 4.71759

Cumulative Model Updates: 263,102
Cumulative Timesteps: 2,194,826,316

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90,086.27822
Policy Entropy: 2.77054
Value Function Loss: 0.01091

Mean KL Divergence: 0.00654
SB3 Clip Fraction: 0.06088
Policy Update Magnitude: 0.30879
Value Function Update Magnitude: 0.31275

Collected Steps per Second: 22,199.70331
Overall Steps per Second: 10,584.93132

Timestep Collection Time: 2.25282
Timestep Consumption Time: 2.47201
PPO Batch Consumption Time: 0.29038
Total Iteration Time: 4.72483

Cumulative Model Updates: 263,108
Cumulative Timesteps: 2,194,876,328

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2194876328...
Checkpoint 2194876328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 81,520.69196
Policy Entropy: 2.78777
Value Function Loss: 0.01127

Mean KL Divergence: 0.00650
SB3 Clip Fraction: 0.06227
Policy Update Magnitude: 0.31497
Value Function Update Magnitude: 0.33792

Collected Steps per Second: 21,446.79840
Overall Steps per Second: 10,466.36001

Timestep Collection Time: 2.33238
Timestep Consumption Time: 2.44694
PPO Batch Consumption Time: 0.27823
Total Iteration Time: 4.77931

Cumulative Model Updates: 263,114
Cumulative Timesteps: 2,194,926,350

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 98,219.07014
Policy Entropy: 2.77723
Value Function Loss: 0.01062

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.07047
Policy Update Magnitude: 0.30867
Value Function Update Magnitude: 0.32086

Collected Steps per Second: 21,696.22756
Overall Steps per Second: 10,421.89042

Timestep Collection Time: 2.30455
Timestep Consumption Time: 2.49305
PPO Batch Consumption Time: 0.28719
Total Iteration Time: 4.79759

Cumulative Model Updates: 263,120
Cumulative Timesteps: 2,194,976,350

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2194976350...
Checkpoint 2194976350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86,090.71491
Policy Entropy: 2.80414
Value Function Loss: 0.01023

Mean KL Divergence: 0.00743
SB3 Clip Fraction: 0.06886
Policy Update Magnitude: 0.30065
Value Function Update Magnitude: 0.30113

Collected Steps per Second: 21,482.22917
Overall Steps per Second: 10,336.89114

Timestep Collection Time: 2.32937
Timestep Consumption Time: 2.51155
PPO Batch Consumption Time: 0.29259
Total Iteration Time: 4.84091

Cumulative Model Updates: 263,126
Cumulative Timesteps: 2,195,026,390

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75,181.47634
Policy Entropy: 2.80451
Value Function Loss: 0.01053

Mean KL Divergence: 0.00702
SB3 Clip Fraction: 0.06857
Policy Update Magnitude: 0.30366
Value Function Update Magnitude: 0.31831

Collected Steps per Second: 22,173.32455
Overall Steps per Second: 10,478.68854

Timestep Collection Time: 2.25541
Timestep Consumption Time: 2.51713
PPO Batch Consumption Time: 0.29245
Total Iteration Time: 4.77254

Cumulative Model Updates: 263,132
Cumulative Timesteps: 2,195,076,400

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2195076400...
Checkpoint 2195076400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 102,762.02407
Policy Entropy: 2.80647
Value Function Loss: 0.01076

Mean KL Divergence: 0.00705
SB3 Clip Fraction: 0.06595
Policy Update Magnitude: 0.31001
Value Function Update Magnitude: 0.33454

Collected Steps per Second: 22,015.85332
Overall Steps per Second: 10,488.94677

Timestep Collection Time: 2.27127
Timestep Consumption Time: 2.49603
PPO Batch Consumption Time: 0.29025
Total Iteration Time: 4.76730

Cumulative Model Updates: 263,138
Cumulative Timesteps: 2,195,126,404

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88,836.52927
Policy Entropy: 2.80634
Value Function Loss: 0.00992

Mean KL Divergence: 0.00710
SB3 Clip Fraction: 0.06340
Policy Update Magnitude: 0.29843
Value Function Update Magnitude: 0.30760

Collected Steps per Second: 21,648.98999
Overall Steps per Second: 10,567.46157

Timestep Collection Time: 2.30995
Timestep Consumption Time: 2.42232
PPO Batch Consumption Time: 0.29302
Total Iteration Time: 4.73226

Cumulative Model Updates: 263,144
Cumulative Timesteps: 2,195,176,412

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2195176412...
Checkpoint 2195176412 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 88,197.19359
Policy Entropy: 2.80425
Value Function Loss: 0.01069

Mean KL Divergence: 0.00693
SB3 Clip Fraction: 0.06403
Policy Update Magnitude: 0.29185
Value Function Update Magnitude: 0.29113

Collected Steps per Second: 21,057.62509
Overall Steps per Second: 10,600.87761

Timestep Collection Time: 2.37529
Timestep Consumption Time: 2.34300
PPO Batch Consumption Time: 0.27686
Total Iteration Time: 4.71829

Cumulative Model Updates: 263,150
Cumulative Timesteps: 2,195,226,430

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88,197.19359
Policy Entropy: 2.81308
Value Function Loss: 0.00930

Mean KL Divergence: 0.00608
SB3 Clip Fraction: 0.05773
Policy Update Magnitude: 0.28899
Value Function Update Magnitude: 0.30527

Collected Steps per Second: 21,274.68986
Overall Steps per Second: 10,443.30229

Timestep Collection Time: 2.35106
Timestep Consumption Time: 2.43842
PPO Batch Consumption Time: 0.29331
Total Iteration Time: 4.78948

Cumulative Model Updates: 263,156
Cumulative Timesteps: 2,195,276,448

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2195276448...
Checkpoint 2195276448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 77,055.44737
Policy Entropy: 2.82196
Value Function Loss: 0.00902

Mean KL Divergence: 0.00720
SB3 Clip Fraction: 0.06717
Policy Update Magnitude: 0.27941
Value Function Update Magnitude: 0.29018

Collected Steps per Second: 21,553.12475
Overall Steps per Second: 10,578.71126

Timestep Collection Time: 2.32041
Timestep Consumption Time: 2.40720
PPO Batch Consumption Time: 0.27911
Total Iteration Time: 4.72761

Cumulative Model Updates: 263,162
Cumulative Timesteps: 2,195,326,460

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81,371.43129
Policy Entropy: 2.81013
Value Function Loss: 0.00914

Mean KL Divergence: 0.00636
SB3 Clip Fraction: 0.06161
Policy Update Magnitude: 0.28034
Value Function Update Magnitude: 0.27663

Collected Steps per Second: 21,959.32549
Overall Steps per Second: 10,456.90546

Timestep Collection Time: 2.27721
Timestep Consumption Time: 2.50489
PPO Batch Consumption Time: 0.29436
Total Iteration Time: 4.78210

Cumulative Model Updates: 263,168
Cumulative Timesteps: 2,195,376,466

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2195376466...
Checkpoint 2195376466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 124,181.24779
Policy Entropy: 2.79916
Value Function Loss: 0.00882

Mean KL Divergence: 0.00564
SB3 Clip Fraction: 0.05500
Policy Update Magnitude: 0.28251
Value Function Update Magnitude: 0.28502

Collected Steps per Second: 21,421.93789
Overall Steps per Second: 10,555.74485

Timestep Collection Time: 2.33424
Timestep Consumption Time: 2.40289
PPO Batch Consumption Time: 0.27840
Total Iteration Time: 4.73714

Cumulative Model Updates: 263,174
Cumulative Timesteps: 2,195,426,470

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 121,614.99405
Policy Entropy: 2.78198
Value Function Loss: 0.00919

Mean KL Divergence: 0.00526
SB3 Clip Fraction: 0.04932
Policy Update Magnitude: 0.29511
Value Function Update Magnitude: 0.28744

Collected Steps per Second: 21,698.39936
Overall Steps per Second: 10,591.01051

Timestep Collection Time: 2.30681
Timestep Consumption Time: 2.41928
PPO Batch Consumption Time: 0.27687
Total Iteration Time: 4.72608

Cumulative Model Updates: 263,180
Cumulative Timesteps: 2,195,476,524

Timesteps Collected: 50,054
--------END ITERATION REPORT--------


Saving checkpoint 2195476524...
Checkpoint 2195476524 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 111,160.19480
Policy Entropy: 2.78585
Value Function Loss: 0.00951

Mean KL Divergence: 0.00583
SB3 Clip Fraction: 0.05586
Policy Update Magnitude: 0.30612
Value Function Update Magnitude: 0.30078

Collected Steps per Second: 21,461.37418
Overall Steps per Second: 10,527.52682

Timestep Collection Time: 2.33014
Timestep Consumption Time: 2.42007
PPO Batch Consumption Time: 0.27788
Total Iteration Time: 4.75021

Cumulative Model Updates: 263,186
Cumulative Timesteps: 2,195,526,532

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 115,549.79358
Policy Entropy: 2.76203
Value Function Loss: 0.00947

Mean KL Divergence: 0.00659
SB3 Clip Fraction: 0.05949
Policy Update Magnitude: 0.31251
Value Function Update Magnitude: 0.31439

Collected Steps per Second: 21,685.38387
Overall Steps per Second: 10,566.50803

Timestep Collection Time: 2.30708
Timestep Consumption Time: 2.42769
PPO Batch Consumption Time: 0.27664
Total Iteration Time: 4.73477

Cumulative Model Updates: 263,192
Cumulative Timesteps: 2,195,576,562

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2195576562...
Checkpoint 2195576562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 98,173.74564
Policy Entropy: 2.75232
Value Function Loss: 0.01058

Mean KL Divergence: 0.00673
SB3 Clip Fraction: 0.06135
Policy Update Magnitude: 0.31168
Value Function Update Magnitude: 0.32717

Collected Steps per Second: 21,713.83584
Overall Steps per Second: 10,466.05399

Timestep Collection Time: 2.30286
Timestep Consumption Time: 2.47487
PPO Batch Consumption Time: 0.27878
Total Iteration Time: 4.77773

Cumulative Model Updates: 263,198
Cumulative Timesteps: 2,195,626,566

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 98,173.74564
Policy Entropy: 2.76601
Value Function Loss: 0.00925

Mean KL Divergence: 0.00731
SB3 Clip Fraction: 0.06670
Policy Update Magnitude: 0.30526
Value Function Update Magnitude: 0.33442

Collected Steps per Second: 21,693.63585
Overall Steps per Second: 10,550.98481

Timestep Collection Time: 2.30510
Timestep Consumption Time: 2.43436
PPO Batch Consumption Time: 0.27794
Total Iteration Time: 4.73946

Cumulative Model Updates: 263,204
Cumulative Timesteps: 2,195,676,572

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2195676572...
Checkpoint 2195676572 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87,975.37737
Policy Entropy: 2.77307
Value Function Loss: 0.00950

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.07255
Policy Update Magnitude: 0.30031
Value Function Update Magnitude: 0.31454

Collected Steps per Second: 22,154.04737
Overall Steps per Second: 10,702.76979

Timestep Collection Time: 2.25828
Timestep Consumption Time: 2.41621
PPO Batch Consumption Time: 0.27721
Total Iteration Time: 4.67449

Cumulative Model Updates: 263,210
Cumulative Timesteps: 2,195,726,602

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 121,961.03139
Policy Entropy: 2.76939
Value Function Loss: 0.01112

Mean KL Divergence: 0.00728
SB3 Clip Fraction: 0.06783
Policy Update Magnitude: 0.31388
Value Function Update Magnitude: 0.33500

Collected Steps per Second: 21,525.70725
Overall Steps per Second: 10,566.47822

Timestep Collection Time: 2.32318
Timestep Consumption Time: 2.40953
PPO Batch Consumption Time: 0.29031
Total Iteration Time: 4.73270

Cumulative Model Updates: 263,216
Cumulative Timesteps: 2,195,776,610

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2195776610...
Checkpoint 2195776610 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 127,904.23919
Policy Entropy: 2.73825
Value Function Loss: 0.01280

Mean KL Divergence: 0.00737
SB3 Clip Fraction: 0.06807
Policy Update Magnitude: 0.33052
Value Function Update Magnitude: 0.36580

Collected Steps per Second: 21,615.09127
Overall Steps per Second: 10,554.31836

Timestep Collection Time: 2.31468
Timestep Consumption Time: 2.42575
PPO Batch Consumption Time: 0.29343
Total Iteration Time: 4.74043

Cumulative Model Updates: 263,222
Cumulative Timesteps: 2,195,826,642

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 112,941.26297
Policy Entropy: 2.73193
Value Function Loss: 0.01230

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.08021
Policy Update Magnitude: 0.33998
Value Function Update Magnitude: 0.39097

Collected Steps per Second: 21,469.82488
Overall Steps per Second: 10,547.12710

Timestep Collection Time: 2.32950
Timestep Consumption Time: 2.41245
PPO Batch Consumption Time: 0.29038
Total Iteration Time: 4.74195

Cumulative Model Updates: 263,228
Cumulative Timesteps: 2,195,876,656

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2195876656...
Checkpoint 2195876656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 127,010.32521
Policy Entropy: 2.73251
Value Function Loss: 0.01230

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.09048
Policy Update Magnitude: 0.34493
Value Function Update Magnitude: 0.37401

Collected Steps per Second: 21,010.34373
Overall Steps per Second: 10,458.37970

Timestep Collection Time: 2.37978
Timestep Consumption Time: 2.40108
PPO Batch Consumption Time: 0.27866
Total Iteration Time: 4.78086

Cumulative Model Updates: 263,234
Cumulative Timesteps: 2,195,926,656

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 105,390.14569
Policy Entropy: 2.73320
Value Function Loss: 0.01102

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.07917
Policy Update Magnitude: 0.33362
Value Function Update Magnitude: 0.36628

Collected Steps per Second: 21,574.37012
Overall Steps per Second: 10,428.94552

Timestep Collection Time: 2.31886
Timestep Consumption Time: 2.47817
PPO Batch Consumption Time: 0.28924
Total Iteration Time: 4.79703

Cumulative Model Updates: 263,240
Cumulative Timesteps: 2,195,976,684

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2195976684...
Checkpoint 2195976684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 122,543.54670
Policy Entropy: 2.71767
Value Function Loss: 0.01068

Mean KL Divergence: 0.01219
SB3 Clip Fraction: 0.09819
Policy Update Magnitude: 0.32522
Value Function Update Magnitude: 0.35202

Collected Steps per Second: 21,242.49355
Overall Steps per Second: 10,354.83919

Timestep Collection Time: 2.35537
Timestep Consumption Time: 2.47657
PPO Batch Consumption Time: 0.29158
Total Iteration Time: 4.83194

Cumulative Model Updates: 263,246
Cumulative Timesteps: 2,196,026,718

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 117,575.05837
Policy Entropy: 2.71931
Value Function Loss: 0.00925

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.08944
Policy Update Magnitude: 0.31386
Value Function Update Magnitude: 0.33185

Collected Steps per Second: 21,693.32004
Overall Steps per Second: 10,385.29192

Timestep Collection Time: 2.30606
Timestep Consumption Time: 2.51095
PPO Batch Consumption Time: 0.29267
Total Iteration Time: 4.81700

Cumulative Model Updates: 263,252
Cumulative Timesteps: 2,196,076,744

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2196076744...
Checkpoint 2196076744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 117,575.05837
Policy Entropy: 2.72434
Value Function Loss: 0.00936

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.07928
Policy Update Magnitude: 0.30768
Value Function Update Magnitude: 0.30642

Collected Steps per Second: 21,453.14340
Overall Steps per Second: 10,523.58717

Timestep Collection Time: 2.33178
Timestep Consumption Time: 2.42173
PPO Batch Consumption Time: 0.27821
Total Iteration Time: 4.75351

Cumulative Model Updates: 263,258
Cumulative Timesteps: 2,196,126,768

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 106,409.21535
Policy Entropy: 2.73580
Value Function Loss: 0.01027

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.08176
Policy Update Magnitude: 0.31238
Value Function Update Magnitude: 0.30685

Collected Steps per Second: 21,819.81116
Overall Steps per Second: 10,589.57348

Timestep Collection Time: 2.29250
Timestep Consumption Time: 2.43120
PPO Batch Consumption Time: 0.27709
Total Iteration Time: 4.72370

Cumulative Model Updates: 263,264
Cumulative Timesteps: 2,196,176,790

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2196176790...
Checkpoint 2196176790 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89,708.08110
Policy Entropy: 2.72617
Value Function Loss: 0.01109

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.09297
Policy Update Magnitude: 0.31792
Value Function Update Magnitude: 0.31350

Collected Steps per Second: 21,697.85569
Overall Steps per Second: 10,470.12485

Timestep Collection Time: 2.30465
Timestep Consumption Time: 2.47141
PPO Batch Consumption Time: 0.27845
Total Iteration Time: 4.77607

Cumulative Model Updates: 263,270
Cumulative Timesteps: 2,196,226,796

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 74,814.18038
Policy Entropy: 2.73033
Value Function Loss: 0.01142

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.07398
Policy Update Magnitude: 0.32522
Value Function Update Magnitude: 0.33263

Collected Steps per Second: 21,923.49064
Overall Steps per Second: 10,607.95003

Timestep Collection Time: 2.28130
Timestep Consumption Time: 2.43347
PPO Batch Consumption Time: 0.27699
Total Iteration Time: 4.71477

Cumulative Model Updates: 263,276
Cumulative Timesteps: 2,196,276,810

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2196276810...
Checkpoint 2196276810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 66,499.92384
Policy Entropy: 2.72070
Value Function Loss: 0.01276

Mean KL Divergence: 0.01135
SB3 Clip Fraction: 0.08711
Policy Update Magnitude: 0.32928
Value Function Update Magnitude: 0.30423

Collected Steps per Second: 22,348.58947
Overall Steps per Second: 10,568.80741

Timestep Collection Time: 2.23790
Timestep Consumption Time: 2.49432
PPO Batch Consumption Time: 0.28999
Total Iteration Time: 4.73223

Cumulative Model Updates: 263,282
Cumulative Timesteps: 2,196,326,824

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 74,206.79840
Policy Entropy: 2.74779
Value Function Loss: 0.01162

Mean KL Divergence: 0.01050
SB3 Clip Fraction: 0.08043
Policy Update Magnitude: 0.32590
Value Function Update Magnitude: 0.27937

Collected Steps per Second: 22,306.71049
Overall Steps per Second: 10,517.96475

Timestep Collection Time: 2.24184
Timestep Consumption Time: 2.51270
PPO Batch Consumption Time: 0.29328
Total Iteration Time: 4.75453

Cumulative Model Updates: 263,288
Cumulative Timesteps: 2,196,376,832

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2196376832...
Checkpoint 2196376832 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 71,828.33404
Policy Entropy: 2.74342
Value Function Loss: 0.01257

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.07985
Policy Update Magnitude: 0.32400
Value Function Update Magnitude: 0.30616

Collected Steps per Second: 22,244.22455
Overall Steps per Second: 10,576.52998

Timestep Collection Time: 2.24885
Timestep Consumption Time: 2.48086
PPO Batch Consumption Time: 0.28767
Total Iteration Time: 4.72972

Cumulative Model Updates: 263,294
Cumulative Timesteps: 2,196,426,856

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 72,512.68535
Policy Entropy: 2.74165
Value Function Loss: 0.01136

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.07477
Policy Update Magnitude: 0.32641
Value Function Update Magnitude: 0.34515

Collected Steps per Second: 21,809.13350
Overall Steps per Second: 10,449.55065

Timestep Collection Time: 2.29363
Timestep Consumption Time: 2.49337
PPO Batch Consumption Time: 0.28962
Total Iteration Time: 4.78700

Cumulative Model Updates: 263,300
Cumulative Timesteps: 2,196,476,878

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2196476878...
Checkpoint 2196476878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 116,642.35099
Policy Entropy: 2.72827
Value Function Loss: 0.01172

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.08148
Policy Update Magnitude: 0.32745
Value Function Update Magnitude: 0.33503

Collected Steps per Second: 21,771.16071
Overall Steps per Second: 10,599.81639

Timestep Collection Time: 2.29735
Timestep Consumption Time: 2.42122
PPO Batch Consumption Time: 0.27812
Total Iteration Time: 4.71857

Cumulative Model Updates: 263,306
Cumulative Timesteps: 2,196,526,894

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95,692.07675
Policy Entropy: 2.75072
Value Function Loss: 0.01031

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.08306
Policy Update Magnitude: 0.31281
Value Function Update Magnitude: 0.31562

Collected Steps per Second: 21,722.69576
Overall Steps per Second: 10,588.77819

Timestep Collection Time: 2.30266
Timestep Consumption Time: 2.42121
PPO Batch Consumption Time: 0.27695
Total Iteration Time: 4.72387

Cumulative Model Updates: 263,312
Cumulative Timesteps: 2,196,576,914

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2196576914...
Checkpoint 2196576914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 102,795.44185
Policy Entropy: 2.72427
Value Function Loss: 0.01249

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.07914
Policy Update Magnitude: 0.32676
Value Function Update Magnitude: 0.30611

Collected Steps per Second: 21,401.09230
Overall Steps per Second: 10,491.88787

Timestep Collection Time: 2.33642
Timestep Consumption Time: 2.42935
PPO Batch Consumption Time: 0.27823
Total Iteration Time: 4.76578

Cumulative Model Updates: 263,318
Cumulative Timesteps: 2,196,626,916

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60,104.80546
Policy Entropy: 2.72857
Value Function Loss: 0.01278

Mean KL Divergence: 0.00782
SB3 Clip Fraction: 0.07123
Policy Update Magnitude: 0.34342
Value Function Update Magnitude: 0.34225

Collected Steps per Second: 21,367.10424
Overall Steps per Second: 10,462.54817

Timestep Collection Time: 2.34098
Timestep Consumption Time: 2.43988
PPO Batch Consumption Time: 0.27790
Total Iteration Time: 4.78086

Cumulative Model Updates: 263,324
Cumulative Timesteps: 2,196,676,936

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2196676936...
Checkpoint 2196676936 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,735.06712
Policy Entropy: 2.73476
Value Function Loss: 0.01306

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.08561
Policy Update Magnitude: 0.34041
Value Function Update Magnitude: 0.35854

Collected Steps per Second: 21,326.21209
Overall Steps per Second: 10,315.41552

Timestep Collection Time: 2.34566
Timestep Consumption Time: 2.50378
PPO Batch Consumption Time: 0.29286
Total Iteration Time: 4.84944

Cumulative Model Updates: 263,330
Cumulative Timesteps: 2,196,726,960

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 106,837.41918
Policy Entropy: 2.74852
Value Function Loss: 0.01240

Mean KL Divergence: 0.01344
SB3 Clip Fraction: 0.10823
Policy Update Magnitude: 0.32389
Value Function Update Magnitude: 0.36269

Collected Steps per Second: 22,150.98646
Overall Steps per Second: 10,407.90078

Timestep Collection Time: 2.25823
Timestep Consumption Time: 2.54793
PPO Batch Consumption Time: 0.29242
Total Iteration Time: 4.80616

Cumulative Model Updates: 263,336
Cumulative Timesteps: 2,196,776,982

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2196776982...
Checkpoint 2196776982 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 92,474.07898
Policy Entropy: 2.76348
Value Function Loss: 0.01132

Mean KL Divergence: 0.01210
SB3 Clip Fraction: 0.10384
Policy Update Magnitude: 0.31797
Value Function Update Magnitude: 0.34439

Collected Steps per Second: 21,833.46965
Overall Steps per Second: 10,551.96607

Timestep Collection Time: 2.29235
Timestep Consumption Time: 2.45084
PPO Batch Consumption Time: 0.27827
Total Iteration Time: 4.74319

Cumulative Model Updates: 263,342
Cumulative Timesteps: 2,196,827,032

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83,098.91366
Policy Entropy: 2.74076
Value Function Loss: 0.01182

Mean KL Divergence: 0.01093
SB3 Clip Fraction: 0.09876
Policy Update Magnitude: 0.31469
Value Function Update Magnitude: 0.32912

Collected Steps per Second: 22,263.20346
Overall Steps per Second: 10,539.58108

Timestep Collection Time: 2.24694
Timestep Consumption Time: 2.49936
PPO Batch Consumption Time: 0.29130
Total Iteration Time: 4.74630

Cumulative Model Updates: 263,348
Cumulative Timesteps: 2,196,877,056

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2196877056...
Checkpoint 2196877056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 59,412.56192
Policy Entropy: 2.75780
Value Function Loss: 0.00978

Mean KL Divergence: 0.00738
SB3 Clip Fraction: 0.06967
Policy Update Magnitude: 0.31197
Value Function Update Magnitude: 0.33177

Collected Steps per Second: 21,981.70801
Overall Steps per Second: 10,671.10291

Timestep Collection Time: 2.27589
Timestep Consumption Time: 2.41228
PPO Batch Consumption Time: 0.27693
Total Iteration Time: 4.68818

Cumulative Model Updates: 263,354
Cumulative Timesteps: 2,196,927,084

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56,723.34433
Policy Entropy: 2.75554
Value Function Loss: 0.00959

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.07153
Policy Update Magnitude: 0.31344
Value Function Update Magnitude: 0.33804

Collected Steps per Second: 21,607.55399
Overall Steps per Second: 10,566.16149

Timestep Collection Time: 2.31530
Timestep Consumption Time: 2.41944
PPO Batch Consumption Time: 0.29147
Total Iteration Time: 4.73474

Cumulative Model Updates: 263,360
Cumulative Timesteps: 2,196,977,112

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2196977112...
Checkpoint 2196977112 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46,215.28508
Policy Entropy: 2.76690
Value Function Loss: 0.00973

Mean KL Divergence: 0.00699
SB3 Clip Fraction: 0.05938
Policy Update Magnitude: 0.30771
Value Function Update Magnitude: 0.33436

Collected Steps per Second: 21,393.71061
Overall Steps per Second: 10,477.82234

Timestep Collection Time: 2.33826
Timestep Consumption Time: 2.43602
PPO Batch Consumption Time: 0.29219
Total Iteration Time: 4.77427

Cumulative Model Updates: 263,366
Cumulative Timesteps: 2,197,027,136

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95,059.69211
Policy Entropy: 2.76796
Value Function Loss: 0.00911

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.06094
Policy Update Magnitude: 0.30048
Value Function Update Magnitude: 0.31434

Collected Steps per Second: 21,395.58727
Overall Steps per Second: 10,509.16089

Timestep Collection Time: 2.33889
Timestep Consumption Time: 2.42286
PPO Batch Consumption Time: 0.29248
Total Iteration Time: 4.76175

Cumulative Model Updates: 263,372
Cumulative Timesteps: 2,197,077,178

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 2197077178...
Checkpoint 2197077178 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 103,609.69150
Policy Entropy: 2.74639
Value Function Loss: 0.01020

Mean KL Divergence: 0.00631
SB3 Clip Fraction: 0.06189
Policy Update Magnitude: 0.30954
Value Function Update Magnitude: 0.30119

Collected Steps per Second: 20,864.13451
Overall Steps per Second: 10,284.42840

Timestep Collection Time: 2.39770
Timestep Consumption Time: 2.46654
PPO Batch Consumption Time: 0.29216
Total Iteration Time: 4.86425

Cumulative Model Updates: 263,378
Cumulative Timesteps: 2,197,127,204

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99,712.43628
Policy Entropy: 2.76085
Value Function Loss: 0.00909

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.06235
Policy Update Magnitude: 0.30215
Value Function Update Magnitude: 0.27331

Collected Steps per Second: 21,547.22274
Overall Steps per Second: 10,436.03970

Timestep Collection Time: 2.32160
Timestep Consumption Time: 2.47179
PPO Batch Consumption Time: 0.29226
Total Iteration Time: 4.79339

Cumulative Model Updates: 263,384
Cumulative Timesteps: 2,197,177,228

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2197177228...
Checkpoint 2197177228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 77,618.17475
Policy Entropy: 2.74642
Value Function Loss: 0.01176

Mean KL Divergence: 0.01288
SB3 Clip Fraction: 0.05734
Policy Update Magnitude: 0.30522
Value Function Update Magnitude: 0.25309

Collected Steps per Second: 21,019.68277
Overall Steps per Second: 10,463.72525

Timestep Collection Time: 2.37996
Timestep Consumption Time: 2.40094
PPO Batch Consumption Time: 0.27803
Total Iteration Time: 4.78090

Cumulative Model Updates: 263,390
Cumulative Timesteps: 2,197,227,254

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 186,142.95722
Policy Entropy: 2.76142
Value Function Loss: 0.01061

Mean KL Divergence: 0.01400
SB3 Clip Fraction: 0.04859
Policy Update Magnitude: 0.30130
Value Function Update Magnitude: 0.28917

Collected Steps per Second: 21,682.27806
Overall Steps per Second: 10,582.92867

Timestep Collection Time: 2.30658
Timestep Consumption Time: 2.41914
PPO Batch Consumption Time: 0.27648
Total Iteration Time: 4.72572

Cumulative Model Updates: 263,396
Cumulative Timesteps: 2,197,277,266

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2197277266...
Checkpoint 2197277266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 153,874.80583
Policy Entropy: 2.76586
Value Function Loss: 0.01147

Mean KL Divergence: 0.00684
SB3 Clip Fraction: 0.05227
Policy Update Magnitude: 0.28939
Value Function Update Magnitude: 0.31363

Collected Steps per Second: 21,303.32474
Overall Steps per Second: 10,308.18213

Timestep Collection Time: 2.34855
Timestep Consumption Time: 2.50507
PPO Batch Consumption Time: 0.29108
Total Iteration Time: 4.85362

Cumulative Model Updates: 263,402
Cumulative Timesteps: 2,197,327,298

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 237,976.27229
Policy Entropy: 2.76787
Value Function Loss: 0.00993

Mean KL Divergence: 0.00537
SB3 Clip Fraction: 0.05037
Policy Update Magnitude: 0.29022
Value Function Update Magnitude: 0.30963

Collected Steps per Second: 22,436.04335
Overall Steps per Second: 10,660.10657

Timestep Collection Time: 2.22954
Timestep Consumption Time: 2.46291
PPO Batch Consumption Time: 0.27866
Total Iteration Time: 4.69245

Cumulative Model Updates: 263,408
Cumulative Timesteps: 2,197,377,320

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2197377320...
Checkpoint 2197377320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 194,934.00440
Policy Entropy: 2.75549
Value Function Loss: 0.01138

Mean KL Divergence: 0.00555
SB3 Clip Fraction: 0.05350
Policy Update Magnitude: 0.30234
Value Function Update Magnitude: 0.33175

Collected Steps per Second: 21,796.42698
Overall Steps per Second: 10,382.85377

Timestep Collection Time: 2.29496
Timestep Consumption Time: 2.52279
PPO Batch Consumption Time: 0.29165
Total Iteration Time: 4.81775

Cumulative Model Updates: 263,414
Cumulative Timesteps: 2,197,427,342

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81,731.84402
Policy Entropy: 2.71720
Value Function Loss: 0.01398

Mean KL Divergence: 0.00677
SB3 Clip Fraction: 0.06289
Policy Update Magnitude: 0.32266
Value Function Update Magnitude: 0.31974

Collected Steps per Second: 22,519.95657
Overall Steps per Second: 10,740.57915

Timestep Collection Time: 2.22070
Timestep Consumption Time: 2.43548
PPO Batch Consumption Time: 0.27880
Total Iteration Time: 4.65617

Cumulative Model Updates: 263,420
Cumulative Timesteps: 2,197,477,352

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2197477352...
Checkpoint 2197477352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 71,208.12673
Policy Entropy: 2.73400
Value Function Loss: 0.01322

Mean KL Divergence: 0.00707
SB3 Clip Fraction: 0.06457
Policy Update Magnitude: 0.32767
Value Function Update Magnitude: 0.32099

Collected Steps per Second: 20,764.80157
Overall Steps per Second: 10,303.38125

Timestep Collection Time: 2.40898
Timestep Consumption Time: 2.44593
PPO Batch Consumption Time: 0.27684
Total Iteration Time: 4.85491

Cumulative Model Updates: 263,426
Cumulative Timesteps: 2,197,527,374

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 74,108.77227
Policy Entropy: 2.74757
Value Function Loss: 0.01172

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.07543
Policy Update Magnitude: 0.31936
Value Function Update Magnitude: 0.32757

Collected Steps per Second: 22,327.79918
Overall Steps per Second: 10,528.77950

Timestep Collection Time: 2.23999
Timestep Consumption Time: 2.51023
PPO Batch Consumption Time: 0.29172
Total Iteration Time: 4.75022

Cumulative Model Updates: 263,432
Cumulative Timesteps: 2,197,577,388

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2197577388...
Checkpoint 2197577388 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 63,898.58627
Policy Entropy: 2.80182
Value Function Loss: 0.00896

Mean KL Divergence: 0.00730
SB3 Clip Fraction: 0.06576
Policy Update Magnitude: 0.29672
Value Function Update Magnitude: 0.29702

Collected Steps per Second: 21,965.55626
Overall Steps per Second: 10,500.20550

Timestep Collection Time: 2.27684
Timestep Consumption Time: 2.48612
PPO Batch Consumption Time: 0.28848
Total Iteration Time: 4.76295

Cumulative Model Updates: 263,438
Cumulative Timesteps: 2,197,627,400

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78,523.33381
Policy Entropy: 2.78755
Value Function Loss: 0.00890

Mean KL Divergence: 0.00737
SB3 Clip Fraction: 0.06992
Policy Update Magnitude: 0.28617
Value Function Update Magnitude: 0.27606

Collected Steps per Second: 22,374.20070
Overall Steps per Second: 10,577.74654

Timestep Collection Time: 2.23552
Timestep Consumption Time: 2.49309
PPO Batch Consumption Time: 0.29204
Total Iteration Time: 4.72861

Cumulative Model Updates: 263,444
Cumulative Timesteps: 2,197,677,418

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2197677418...
Checkpoint 2197677418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 74,355.93245
Policy Entropy: 2.75471
Value Function Loss: 0.00899

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.07349
Policy Update Magnitude: 0.29712
Value Function Update Magnitude: 0.28569

Collected Steps per Second: 21,165.53188
Overall Steps per Second: 10,473.58849

Timestep Collection Time: 2.36337
Timestep Consumption Time: 2.41264
PPO Batch Consumption Time: 0.27766
Total Iteration Time: 4.77601

Cumulative Model Updates: 263,450
Cumulative Timesteps: 2,197,727,440

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99,794.57467
Policy Entropy: 2.73700
Value Function Loss: 0.01018

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.08851
Policy Update Magnitude: 0.29702
Value Function Update Magnitude: 0.28120

Collected Steps per Second: 21,885.60256
Overall Steps per Second: 10,496.48998

Timestep Collection Time: 2.28497
Timestep Consumption Time: 2.47929
PPO Batch Consumption Time: 0.28630
Total Iteration Time: 4.76426

Cumulative Model Updates: 263,456
Cumulative Timesteps: 2,197,777,448

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2197777448...
Checkpoint 2197777448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 103,482.78586
Policy Entropy: 2.74541
Value Function Loss: 0.01105

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.08251
Policy Update Magnitude: 0.31247
Value Function Update Magnitude: 0.28500

Collected Steps per Second: 20,768.67170
Overall Steps per Second: 10,369.10872

Timestep Collection Time: 2.40853
Timestep Consumption Time: 2.41561
PPO Batch Consumption Time: 0.29105
Total Iteration Time: 4.82414

Cumulative Model Updates: 263,462
Cumulative Timesteps: 2,197,827,470

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 103,482.78586
Policy Entropy: 2.78056
Value Function Loss: 0.00900

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.07914
Policy Update Magnitude: 0.29798
Value Function Update Magnitude: 0.29128

Collected Steps per Second: 21,285.99865
Overall Steps per Second: 10,508.71511

Timestep Collection Time: 2.34943
Timestep Consumption Time: 2.40948
PPO Batch Consumption Time: 0.28927
Total Iteration Time: 4.75891

Cumulative Model Updates: 263,468
Cumulative Timesteps: 2,197,877,480

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2197877480...
Checkpoint 2197877480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 103,482.78586
Policy Entropy: 2.81273
Value Function Loss: 0.00777

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.07189
Policy Update Magnitude: 0.27517
Value Function Update Magnitude: 0.27601

Collected Steps per Second: 21,405.58825
Overall Steps per Second: 10,444.38254

Timestep Collection Time: 2.33603
Timestep Consumption Time: 2.45162
PPO Batch Consumption Time: 0.28716
Total Iteration Time: 4.78765

Cumulative Model Updates: 263,474
Cumulative Timesteps: 2,197,927,484

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 96,525.24355
Policy Entropy: 2.81518
Value Function Loss: 0.00824

Mean KL Divergence: 0.00731
SB3 Clip Fraction: 0.06342
Policy Update Magnitude: 0.26551
Value Function Update Magnitude: 0.26042

Collected Steps per Second: 21,740.62982
Overall Steps per Second: 10,432.30327

Timestep Collection Time: 2.30095
Timestep Consumption Time: 2.49416
PPO Batch Consumption Time: 0.29150
Total Iteration Time: 4.79511

Cumulative Model Updates: 263,480
Cumulative Timesteps: 2,197,977,508

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2197977508...
Checkpoint 2197977508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 118,636.64871
Policy Entropy: 2.79923
Value Function Loss: 0.00927

Mean KL Divergence: 0.00671
SB3 Clip Fraction: 0.06297
Policy Update Magnitude: 0.27564
Value Function Update Magnitude: 0.25614

Collected Steps per Second: 21,917.21562
Overall Steps per Second: 10,638.30624

Timestep Collection Time: 2.28204
Timestep Consumption Time: 2.41946
PPO Batch Consumption Time: 0.27932
Total Iteration Time: 4.70150

Cumulative Model Updates: 263,486
Cumulative Timesteps: 2,198,027,524

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 106,770.58044
Policy Entropy: 2.75778
Value Function Loss: 0.01069

Mean KL Divergence: 0.00678
SB3 Clip Fraction: 0.06301
Policy Update Magnitude: 0.29218
Value Function Update Magnitude: 0.27752

Collected Steps per Second: 22,165.45793
Overall Steps per Second: 10,599.73803

Timestep Collection Time: 2.25694
Timestep Consumption Time: 2.46262
PPO Batch Consumption Time: 0.29140
Total Iteration Time: 4.71955

Cumulative Model Updates: 263,492
Cumulative Timesteps: 2,198,077,550

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2198077550...
Checkpoint 2198077550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 126,720.23025
Policy Entropy: 2.74283
Value Function Loss: 0.01170

Mean KL Divergence: 0.00661
SB3 Clip Fraction: 0.05874
Policy Update Magnitude: 0.30257
Value Function Update Magnitude: 0.31889

Collected Steps per Second: 22,072.00543
Overall Steps per Second: 10,528.91014

Timestep Collection Time: 2.26703
Timestep Consumption Time: 2.48540
PPO Batch Consumption Time: 0.28918
Total Iteration Time: 4.75244

Cumulative Model Updates: 263,498
Cumulative Timesteps: 2,198,127,588

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87,978.33476
Policy Entropy: 2.73460
Value Function Loss: 0.01324

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.07194
Policy Update Magnitude: 0.31799
Value Function Update Magnitude: 0.32516

Collected Steps per Second: 22,311.35727
Overall Steps per Second: 10,552.86261

Timestep Collection Time: 2.24271
Timestep Consumption Time: 2.49894
PPO Batch Consumption Time: 0.29220
Total Iteration Time: 4.74165

Cumulative Model Updates: 263,504
Cumulative Timesteps: 2,198,177,626

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 2198177626...
Checkpoint 2198177626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 90,574.15965
Policy Entropy: 2.74967
Value Function Loss: 0.01328

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.07268
Policy Update Magnitude: 0.32377
Value Function Update Magnitude: 0.32333

Collected Steps per Second: 21,815.62163
Overall Steps per Second: 10,609.06319

Timestep Collection Time: 2.29359
Timestep Consumption Time: 2.42276
PPO Batch Consumption Time: 0.27698
Total Iteration Time: 4.71634

Cumulative Model Updates: 263,510
Cumulative Timesteps: 2,198,227,662

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86,877.45597
Policy Entropy: 2.73604
Value Function Loss: 0.01347

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.07809
Policy Update Magnitude: 0.32885
Value Function Update Magnitude: 0.27597

Collected Steps per Second: 21,772.51773
Overall Steps per Second: 10,428.32964

Timestep Collection Time: 2.29656
Timestep Consumption Time: 2.49826
PPO Batch Consumption Time: 0.29268
Total Iteration Time: 4.79482

Cumulative Model Updates: 263,516
Cumulative Timesteps: 2,198,277,664

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2198277664...
Checkpoint 2198277664 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 74,051.75314
Policy Entropy: 2.72939
Value Function Loss: 0.01348

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.08332
Policy Update Magnitude: 0.32731
Value Function Update Magnitude: 0.23922

Collected Steps per Second: 21,487.70636
Overall Steps per Second: 10,527.76855

Timestep Collection Time: 2.32738
Timestep Consumption Time: 2.42292
PPO Batch Consumption Time: 0.27820
Total Iteration Time: 4.75029

Cumulative Model Updates: 263,522
Cumulative Timesteps: 2,198,327,674

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56,499.99437
Policy Entropy: 2.72456
Value Function Loss: 0.01279

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.07127
Policy Update Magnitude: 0.32374
Value Function Update Magnitude: 0.21376

Collected Steps per Second: 21,550.29786
Overall Steps per Second: 10,499.40851

Timestep Collection Time: 2.32247
Timestep Consumption Time: 2.44446
PPO Batch Consumption Time: 0.27833
Total Iteration Time: 4.76694

Cumulative Model Updates: 263,528
Cumulative Timesteps: 2,198,377,724

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 2198377724...
Checkpoint 2198377724 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,074.35066
Policy Entropy: 2.73160
Value Function Loss: 0.01091

Mean KL Divergence: 0.00663
SB3 Clip Fraction: 0.06321
Policy Update Magnitude: 0.31407
Value Function Update Magnitude: 0.20048

Collected Steps per Second: 21,431.94101
Overall Steps per Second: 10,355.58904

Timestep Collection Time: 2.33306
Timestep Consumption Time: 2.49544
PPO Batch Consumption Time: 0.29052
Total Iteration Time: 4.82850

Cumulative Model Updates: 263,534
Cumulative Timesteps: 2,198,427,726

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56,504.71906
Policy Entropy: 2.73894
Value Function Loss: 0.00884

Mean KL Divergence: 0.00711
SB3 Clip Fraction: 0.06542
Policy Update Magnitude: 0.30143
Value Function Update Magnitude: 0.19556

Collected Steps per Second: 22,335.04325
Overall Steps per Second: 10,664.70521

Timestep Collection Time: 2.23908
Timestep Consumption Time: 2.45022
PPO Batch Consumption Time: 0.27738
Total Iteration Time: 4.68930

Cumulative Model Updates: 263,540
Cumulative Timesteps: 2,198,477,736

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2198477736...
Checkpoint 2198477736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 51,686.23061
Policy Entropy: 2.74124
Value Function Loss: 0.01025

Mean KL Divergence: 0.00737
SB3 Clip Fraction: 0.06740
Policy Update Magnitude: 0.29849
Value Function Update Magnitude: 0.19204

Collected Steps per Second: 21,591.84405
Overall Steps per Second: 10,367.87037

Timestep Collection Time: 2.31671
Timestep Consumption Time: 2.50801
PPO Batch Consumption Time: 0.29228
Total Iteration Time: 4.82471

Cumulative Model Updates: 263,546
Cumulative Timesteps: 2,198,527,758

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63,225.62861
Policy Entropy: 2.75675
Value Function Loss: 0.01035

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.07282
Policy Update Magnitude: 0.30374
Value Function Update Magnitude: 0.25496

Collected Steps per Second: 21,736.27064
Overall Steps per Second: 10,729.78424

Timestep Collection Time: 2.30177
Timestep Consumption Time: 2.36113
PPO Batch Consumption Time: 0.27848
Total Iteration Time: 4.66291

Cumulative Model Updates: 263,552
Cumulative Timesteps: 2,198,577,790

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2198577790...
Checkpoint 2198577790 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 73,022.25942
Policy Entropy: 2.76119
Value Function Loss: 0.01156

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.07137
Policy Update Magnitude: 0.30239
Value Function Update Magnitude: 0.28272

Collected Steps per Second: 21,493.16730
Overall Steps per Second: 10,697.90089

Timestep Collection Time: 2.32632
Timestep Consumption Time: 2.34749
PPO Batch Consumption Time: 0.27946
Total Iteration Time: 4.67381

Cumulative Model Updates: 263,558
Cumulative Timesteps: 2,198,627,790

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 142,963.93526
Policy Entropy: 2.76947
Value Function Loss: 0.01170

Mean KL Divergence: 0.00739
SB3 Clip Fraction: 0.06809
Policy Update Magnitude: 0.31662
Value Function Update Magnitude: 0.26012

Collected Steps per Second: 21,719.14041
Overall Steps per Second: 10,563.82221

Timestep Collection Time: 2.30387
Timestep Consumption Time: 2.43287
PPO Batch Consumption Time: 0.29322
Total Iteration Time: 4.73673

Cumulative Model Updates: 263,564
Cumulative Timesteps: 2,198,677,828

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 2198677828...
Checkpoint 2198677828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 110,215.95166
Policy Entropy: 2.74814
Value Function Loss: 0.01196

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.07460
Policy Update Magnitude: 0.31664
Value Function Update Magnitude: 0.27150

Collected Steps per Second: 21,464.81482
Overall Steps per Second: 10,565.34191

Timestep Collection Time: 2.33014
Timestep Consumption Time: 2.40383
PPO Batch Consumption Time: 0.27819
Total Iteration Time: 4.73397

Cumulative Model Updates: 263,570
Cumulative Timesteps: 2,198,727,844

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 127,634.70064
Policy Entropy: 2.74357
Value Function Loss: 0.01276

Mean KL Divergence: 0.00699
SB3 Clip Fraction: 0.06505
Policy Update Magnitude: 0.31393
Value Function Update Magnitude: 0.25049

Collected Steps per Second: 21,687.33443
Overall Steps per Second: 10,438.65136

Timestep Collection Time: 2.30734
Timestep Consumption Time: 2.48639
PPO Batch Consumption Time: 0.29247
Total Iteration Time: 4.79372

Cumulative Model Updates: 263,576
Cumulative Timesteps: 2,198,777,884

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 2198777884...
Checkpoint 2198777884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 104,179.06858
Policy Entropy: 2.73570
Value Function Loss: 0.01325

Mean KL Divergence: 0.01088
SB3 Clip Fraction: 0.09150
Policy Update Magnitude: 0.33300
Value Function Update Magnitude: 0.22075

Collected Steps per Second: 21,446.75870
Overall Steps per Second: 10,560.35217

Timestep Collection Time: 2.33201
Timestep Consumption Time: 2.40401
PPO Batch Consumption Time: 0.27836
Total Iteration Time: 4.73602

Cumulative Model Updates: 263,582
Cumulative Timesteps: 2,198,827,898

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 112,352.43055
Policy Entropy: 2.75879
Value Function Loss: 0.01285

Mean KL Divergence: 0.01175
SB3 Clip Fraction: 0.09520
Policy Update Magnitude: 0.32399
Value Function Update Magnitude: 0.22750

Collected Steps per Second: 21,741.42511
Overall Steps per Second: 10,603.14937

Timestep Collection Time: 2.30022
Timestep Consumption Time: 2.41631
PPO Batch Consumption Time: 0.27652
Total Iteration Time: 4.71652

Cumulative Model Updates: 263,588
Cumulative Timesteps: 2,198,877,908

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2198877908...
Checkpoint 2198877908 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 96,486.36768
Policy Entropy: 2.75548
Value Function Loss: 0.01324

Mean KL Divergence: 0.01185
SB3 Clip Fraction: 0.09358
Policy Update Magnitude: 0.32792
Value Function Update Magnitude: 0.26776

Collected Steps per Second: 21,533.59244
Overall Steps per Second: 10,526.51514

Timestep Collection Time: 2.32316
Timestep Consumption Time: 2.42922
PPO Batch Consumption Time: 0.27791
Total Iteration Time: 4.75238

Cumulative Model Updates: 263,594
Cumulative Timesteps: 2,198,927,934

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 106,101.27766
Policy Entropy: 2.74102
Value Function Loss: 0.01487

Mean KL Divergence: 0.01259
SB3 Clip Fraction: 0.10697
Policy Update Magnitude: 0.33809
Value Function Update Magnitude: 0.29434

Collected Steps per Second: 21,656.45601
Overall Steps per Second: 10,560.83937

Timestep Collection Time: 2.30906
Timestep Consumption Time: 2.42598
PPO Batch Consumption Time: 0.27751
Total Iteration Time: 4.73504

Cumulative Model Updates: 263,600
Cumulative Timesteps: 2,198,977,940

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2198977940...
Checkpoint 2198977940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 92,711.77421
Policy Entropy: 2.70631
Value Function Loss: 0.01494

Mean KL Divergence: 0.01171
SB3 Clip Fraction: 0.09507
Policy Update Magnitude: 0.34648
Value Function Update Magnitude: 0.30766

Collected Steps per Second: 21,953.79467
Overall Steps per Second: 10,533.39263

Timestep Collection Time: 2.27824
Timestep Consumption Time: 2.47009
PPO Batch Consumption Time: 0.27790
Total Iteration Time: 4.74833

Cumulative Model Updates: 263,606
Cumulative Timesteps: 2,199,027,956

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 94,649.79562
Policy Entropy: 2.71163
Value Function Loss: 0.01422

Mean KL Divergence: 0.01178
SB3 Clip Fraction: 0.09712
Policy Update Magnitude: 0.33579
Value Function Update Magnitude: 0.33973

Collected Steps per Second: 22,391.11958
Overall Steps per Second: 10,536.99401

Timestep Collection Time: 2.23499
Timestep Consumption Time: 2.51437
PPO Batch Consumption Time: 0.29050
Total Iteration Time: 4.74936

Cumulative Model Updates: 263,612
Cumulative Timesteps: 2,199,078,000

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 2199078000...
Checkpoint 2199078000 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 79,597.59263
Policy Entropy: 2.72551
Value Function Loss: 0.01183

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.08832
Policy Update Magnitude: 0.31497
Value Function Update Magnitude: 0.33300

Collected Steps per Second: 21,986.97165
Overall Steps per Second: 10,661.13265

Timestep Collection Time: 2.27426
Timestep Consumption Time: 2.41605
PPO Batch Consumption Time: 0.27735
Total Iteration Time: 4.69031

Cumulative Model Updates: 263,618
Cumulative Timesteps: 2,199,128,004

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 111,438.46213
Policy Entropy: 2.74305
Value Function Loss: 0.01062

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.07359
Policy Update Magnitude: 0.31084
Value Function Update Magnitude: 0.30094

Collected Steps per Second: 21,662.74052
Overall Steps per Second: 10,647.26026

Timestep Collection Time: 2.30866
Timestep Consumption Time: 2.38851
PPO Batch Consumption Time: 0.28749
Total Iteration Time: 4.69717

Cumulative Model Updates: 263,624
Cumulative Timesteps: 2,199,178,016

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2199178016...
Checkpoint 2199178016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 190,620.02664
Policy Entropy: 2.73047
Value Function Loss: 0.01249

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.07803
Policy Update Magnitude: 0.31193
Value Function Update Magnitude: 0.30647

Collected Steps per Second: 21,352.98343
Overall Steps per Second: 10,520.14482

Timestep Collection Time: 2.34253
Timestep Consumption Time: 2.41216
PPO Batch Consumption Time: 0.29174
Total Iteration Time: 4.75469

Cumulative Model Updates: 263,630
Cumulative Timesteps: 2,199,228,036

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 172,749.29321
Policy Entropy: 2.72716
Value Function Loss: 0.01127

Mean KL Divergence: 0.01086
SB3 Clip Fraction: 0.08866
Policy Update Magnitude: 0.31684
Value Function Update Magnitude: 0.32029

Collected Steps per Second: 21,759.61216
Overall Steps per Second: 10,752.91871

Timestep Collection Time: 2.29802
Timestep Consumption Time: 2.35225
PPO Batch Consumption Time: 0.27851
Total Iteration Time: 4.65027

Cumulative Model Updates: 263,636
Cumulative Timesteps: 2,199,278,040

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2199278040...
Checkpoint 2199278040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 107,838.68115
Policy Entropy: 2.72566
Value Function Loss: 0.01231

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.08724
Policy Update Magnitude: 0.30803
Value Function Update Magnitude: 0.30510

Collected Steps per Second: 20,961.76024
Overall Steps per Second: 10,232.21568

Timestep Collection Time: 2.38720
Timestep Consumption Time: 2.50323
PPO Batch Consumption Time: 0.29414
Total Iteration Time: 4.89044

Cumulative Model Updates: 263,642
Cumulative Timesteps: 2,199,328,080

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95,915.48611
Policy Entropy: 2.73032
Value Function Loss: 0.01073

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.07835
Policy Update Magnitude: 0.30857
Value Function Update Magnitude: 0.26277

Collected Steps per Second: 21,526.21538
Overall Steps per Second: 10,438.74908

Timestep Collection Time: 2.32349
Timestep Consumption Time: 2.46789
PPO Batch Consumption Time: 0.28768
Total Iteration Time: 4.79138

Cumulative Model Updates: 263,648
Cumulative Timesteps: 2,199,378,096

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2199378096...
Checkpoint 2199378096 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 98,008.31596
Policy Entropy: 2.71665
Value Function Loss: 0.01348

Mean KL Divergence: 0.00726
SB3 Clip Fraction: 0.06777
Policy Update Magnitude: 0.33056
Value Function Update Magnitude: 0.25172

Collected Steps per Second: 20,133.25882
Overall Steps per Second: 10,182.81016

Timestep Collection Time: 2.48345
Timestep Consumption Time: 2.42678
PPO Batch Consumption Time: 0.27912
Total Iteration Time: 4.91024

Cumulative Model Updates: 263,654
Cumulative Timesteps: 2,199,428,096

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88,440.41349
Policy Entropy: 2.70816
Value Function Loss: 0.01282

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.07292
Policy Update Magnitude: 0.33304
Value Function Update Magnitude: 0.22425

Collected Steps per Second: 21,854.18551
Overall Steps per Second: 10,498.25444

Timestep Collection Time: 2.28871
Timestep Consumption Time: 2.47570
PPO Batch Consumption Time: 0.28462
Total Iteration Time: 4.76441

Cumulative Model Updates: 263,660
Cumulative Timesteps: 2,199,478,114

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2199478114...
Checkpoint 2199478114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 70,659.81804
Policy Entropy: 2.71664
Value Function Loss: 0.01268

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.06944
Policy Update Magnitude: 0.32788
Value Function Update Magnitude: 0.27143

Collected Steps per Second: 21,457.31043
Overall Steps per Second: 10,361.64828

Timestep Collection Time: 2.33170
Timestep Consumption Time: 2.49688
PPO Batch Consumption Time: 0.29130
Total Iteration Time: 4.82858

Cumulative Model Updates: 263,666
Cumulative Timesteps: 2,199,528,146

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76,671.33531
Policy Entropy: 2.72438
Value Function Loss: 0.01301

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.07839
Policy Update Magnitude: 0.33343
Value Function Update Magnitude: 0.30941

Collected Steps per Second: 22,207.42142
Overall Steps per Second: 10,644.26656

Timestep Collection Time: 2.25168
Timestep Consumption Time: 2.44606
PPO Batch Consumption Time: 0.27825
Total Iteration Time: 4.69774

Cumulative Model Updates: 263,672
Cumulative Timesteps: 2,199,578,150

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2199578150...
Checkpoint 2199578150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 81,620.36058
Policy Entropy: 2.74378
Value Function Loss: 0.01269

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.08855
Policy Update Magnitude: 0.32302
Value Function Update Magnitude: 0.32953

Collected Steps per Second: 21,918.97498
Overall Steps per Second: 10,449.01896

Timestep Collection Time: 2.28241
Timestep Consumption Time: 2.50541
PPO Batch Consumption Time: 0.29035
Total Iteration Time: 4.78782

Cumulative Model Updates: 263,678
Cumulative Timesteps: 2,199,628,178

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70,789.95882
Policy Entropy: 2.73855
Value Function Loss: 0.01487

Mean KL Divergence: 0.01339
SB3 Clip Fraction: 0.09715
Policy Update Magnitude: 0.32102
Value Function Update Magnitude: 0.34989

Collected Steps per Second: 22,531.95682
Overall Steps per Second: 10,749.96912

Timestep Collection Time: 2.22067
Timestep Consumption Time: 2.43386
PPO Batch Consumption Time: 0.27829
Total Iteration Time: 4.65452

Cumulative Model Updates: 263,684
Cumulative Timesteps: 2,199,678,214

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 2199678214...
Checkpoint 2199678214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 100,802.59107
Policy Entropy: 2.73607
Value Function Loss: 0.01390

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.08748
Policy Update Magnitude: 0.32131
Value Function Update Magnitude: 0.35270

Collected Steps per Second: 22,156.76686
Overall Steps per Second: 10,703.03384

Timestep Collection Time: 2.25674
Timestep Consumption Time: 2.41502
PPO Batch Consumption Time: 0.27776
Total Iteration Time: 4.67176

Cumulative Model Updates: 263,690
Cumulative Timesteps: 2,199,728,216

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 111,297.67046
Policy Entropy: 2.74429
Value Function Loss: 0.01382

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.08061
Policy Update Magnitude: 0.32842
Value Function Update Magnitude: 0.35378

Collected Steps per Second: 21,480.00247
Overall Steps per Second: 10,535.08733

Timestep Collection Time: 2.32989
Timestep Consumption Time: 2.42052
PPO Batch Consumption Time: 0.29086
Total Iteration Time: 4.75041

Cumulative Model Updates: 263,696
Cumulative Timesteps: 2,199,778,262

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 2199778262...
Checkpoint 2199778262 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 126,958.85735
Policy Entropy: 2.73153
Value Function Loss: 0.01303

Mean KL Divergence: 0.00760
SB3 Clip Fraction: 0.06824
Policy Update Magnitude: 0.32346
Value Function Update Magnitude: 0.34490

Collected Steps per Second: 21,338.28031
Overall Steps per Second: 10,477.25575

Timestep Collection Time: 2.34508
Timestep Consumption Time: 2.43098
PPO Batch Consumption Time: 0.29062
Total Iteration Time: 4.77606

Cumulative Model Updates: 263,702
Cumulative Timesteps: 2,199,828,302

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 112,913.77513
Policy Entropy: 2.73254
Value Function Loss: 0.01294

Mean KL Divergence: 0.00743
SB3 Clip Fraction: 0.06789
Policy Update Magnitude: 0.33585
Value Function Update Magnitude: 0.35226

Collected Steps per Second: 21,331.13790
Overall Steps per Second: 10,500.92318

Timestep Collection Time: 2.34474
Timestep Consumption Time: 2.41827
PPO Batch Consumption Time: 0.29097
Total Iteration Time: 4.76301

Cumulative Model Updates: 263,708
Cumulative Timesteps: 2,199,878,318

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2199878318...
Checkpoint 2199878318 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 81,352.46460
Policy Entropy: 2.72770
Value Function Loss: 0.01459

Mean KL Divergence: 0.00663
SB3 Clip Fraction: 0.05929
Policy Update Magnitude: 0.34876
Value Function Update Magnitude: 0.34956

Collected Steps per Second: 21,043.72150
Overall Steps per Second: 10,325.42927

Timestep Collection Time: 2.37838
Timestep Consumption Time: 2.46887
PPO Batch Consumption Time: 0.29150
Total Iteration Time: 4.84726

Cumulative Model Updates: 263,714
Cumulative Timesteps: 2,199,928,368

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 125,006.01167
Policy Entropy: 2.75213
Value Function Loss: 0.01512

Mean KL Divergence: 0.00722
SB3 Clip Fraction: 0.06381
Policy Update Magnitude: 0.34777
Value Function Update Magnitude: 0.30042

Collected Steps per Second: 21,646.32657
Overall Steps per Second: 10,466.51297

Timestep Collection Time: 2.31060
Timestep Consumption Time: 2.46807
PPO Batch Consumption Time: 0.29074
Total Iteration Time: 4.77867

Cumulative Model Updates: 263,720
Cumulative Timesteps: 2,199,978,384

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2199978384...
Checkpoint 2199978384 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 105,913.03836
Policy Entropy: 2.74735
Value Function Loss: 0.01454

Mean KL Divergence: 0.00723
SB3 Clip Fraction: 0.06346
Policy Update Magnitude: 0.33732
Value Function Update Magnitude: 0.33987

Collected Steps per Second: 21,636.29589
Overall Steps per Second: 10,510.20837

Timestep Collection Time: 2.31315
Timestep Consumption Time: 2.44870
PPO Batch Consumption Time: 0.28506
Total Iteration Time: 4.76185

Cumulative Model Updates: 263,726
Cumulative Timesteps: 2,200,028,432

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79,107.30528
Policy Entropy: 2.71652
Value Function Loss: 0.01340

Mean KL Divergence: 0.00715
SB3 Clip Fraction: 0.06724
Policy Update Magnitude: 0.34278
Value Function Update Magnitude: 0.39390

Collected Steps per Second: 22,285.34810
Overall Steps per Second: 10,534.61773

Timestep Collection Time: 2.24381
Timestep Consumption Time: 2.50283
PPO Batch Consumption Time: 0.29264
Total Iteration Time: 4.74664

Cumulative Model Updates: 263,732
Cumulative Timesteps: 2,200,078,436

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2200078436...
Checkpoint 2200078436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 69,217.28550
Policy Entropy: 2.69220
Value Function Loss: 0.01230

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.07034
Policy Update Magnitude: 0.34821
Value Function Update Magnitude: 0.41105

Collected Steps per Second: 22,147.95409
Overall Steps per Second: 10,539.01147

Timestep Collection Time: 2.25935
Timestep Consumption Time: 2.48872
PPO Batch Consumption Time: 0.28964
Total Iteration Time: 4.74807

Cumulative Model Updates: 263,738
Cumulative Timesteps: 2,200,128,476

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61,616.44361
Policy Entropy: 2.67857
Value Function Loss: 0.01378

Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.06670
Policy Update Magnitude: 0.34648
Value Function Update Magnitude: 0.39557

Collected Steps per Second: 22,009.55830
Overall Steps per Second: 10,445.45966

Timestep Collection Time: 2.27256
Timestep Consumption Time: 2.51593
PPO Batch Consumption Time: 0.29083
Total Iteration Time: 4.78849

Cumulative Model Updates: 263,744
Cumulative Timesteps: 2,200,178,494

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2200178494...
Checkpoint 2200178494 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 105,485.55411
Policy Entropy: 2.71128
Value Function Loss: 0.01291

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.07310
Policy Update Magnitude: 0.33939
Value Function Update Magnitude: 0.38058

Collected Steps per Second: 22,201.30739
Overall Steps per Second: 10,707.72895

Timestep Collection Time: 2.25284
Timestep Consumption Time: 2.41818
PPO Batch Consumption Time: 0.27787
Total Iteration Time: 4.67102

Cumulative Model Updates: 263,750
Cumulative Timesteps: 2,200,228,510

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 73,622.37869
Policy Entropy: 2.71253
Value Function Loss: 0.01335

Mean KL Divergence: 0.00752
SB3 Clip Fraction: 0.07116
Policy Update Magnitude: 0.32354
Value Function Update Magnitude: 0.35341

Collected Steps per Second: 22,158.19627
Overall Steps per Second: 10,528.56277

Timestep Collection Time: 2.25731
Timestep Consumption Time: 2.49338
PPO Batch Consumption Time: 0.29185
Total Iteration Time: 4.75070

Cumulative Model Updates: 263,756
Cumulative Timesteps: 2,200,278,528

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2200278528...
Checkpoint 2200278528 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 146,841.71727
Policy Entropy: 2.71323
Value Function Loss: 0.01163

Mean KL Divergence: 0.00751
SB3 Clip Fraction: 0.07102
Policy Update Magnitude: 0.31783
Value Function Update Magnitude: 0.33638

Collected Steps per Second: 21,879.25805
Overall Steps per Second: 10,521.12370

Timestep Collection Time: 2.28655
Timestep Consumption Time: 2.46846
PPO Batch Consumption Time: 0.28655
Total Iteration Time: 4.75501

Cumulative Model Updates: 263,762
Cumulative Timesteps: 2,200,328,556

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 109,901.63471
Policy Entropy: 2.69105
Value Function Loss: 0.01268

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.07205
Policy Update Magnitude: 0.32546
Value Function Update Magnitude: 0.32186

Collected Steps per Second: 21,621.60666
Overall Steps per Second: 10,431.63840

Timestep Collection Time: 2.31278
Timestep Consumption Time: 2.48091
PPO Batch Consumption Time: 0.28678
Total Iteration Time: 4.79369

Cumulative Model Updates: 263,768
Cumulative Timesteps: 2,200,378,562

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2200378562...
Checkpoint 2200378562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 61,519.38058
Policy Entropy: 2.68053
Value Function Loss: 0.01351

Mean KL Divergence: 0.01105
SB3 Clip Fraction: 0.09116
Policy Update Magnitude: 0.33610
Value Function Update Magnitude: 0.33905

Collected Steps per Second: 21,459.87484
Overall Steps per Second: 10,349.28056

Timestep Collection Time: 2.33030
Timestep Consumption Time: 2.50172
PPO Batch Consumption Time: 0.29127
Total Iteration Time: 4.83203

Cumulative Model Updates: 263,774
Cumulative Timesteps: 2,200,428,570

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 96,472.04922
Policy Entropy: 2.71665
Value Function Loss: 0.01471

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.07270
Policy Update Magnitude: 0.33664
Value Function Update Magnitude: 0.35705

Collected Steps per Second: 21,826.34682
Overall Steps per Second: 10,445.83673

Timestep Collection Time: 2.29200
Timestep Consumption Time: 2.49708
PPO Batch Consumption Time: 0.29168
Total Iteration Time: 4.78909

Cumulative Model Updates: 263,780
Cumulative Timesteps: 2,200,478,596

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2200478596...
Checkpoint 2200478596 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86,850.23642
Policy Entropy: 2.74418
Value Function Loss: 0.01436

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.07225
Policy Update Magnitude: 0.32785
Value Function Update Magnitude: 0.36310

Collected Steps per Second: 21,253.36002
Overall Steps per Second: 10,454.48493

Timestep Collection Time: 2.35285
Timestep Consumption Time: 2.43036
PPO Batch Consumption Time: 0.27834
Total Iteration Time: 4.78321

Cumulative Model Updates: 263,786
Cumulative Timesteps: 2,200,528,602

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86,850.23642
Policy Entropy: 2.75948
Value Function Loss: 0.01223

Mean KL Divergence: 0.00728
SB3 Clip Fraction: 0.06787
Policy Update Magnitude: 0.30961
Value Function Update Magnitude: 0.34590

Collected Steps per Second: 22,265.94845
Overall Steps per Second: 10,495.67315

Timestep Collection Time: 2.24630
Timestep Consumption Time: 2.51909
PPO Batch Consumption Time: 0.28861
Total Iteration Time: 4.76539

Cumulative Model Updates: 263,792
Cumulative Timesteps: 2,200,578,618

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2200578618...
Checkpoint 2200578618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 65,530.06772
Policy Entropy: 2.75325
Value Function Loss: 0.01088

Mean KL Divergence: 0.00652
SB3 Clip Fraction: 0.06077
Policy Update Magnitude: 0.31490
Value Function Update Magnitude: 0.29795

Collected Steps per Second: 22,027.47951
Overall Steps per Second: 10,571.19969

Timestep Collection Time: 2.27035
Timestep Consumption Time: 2.46043
PPO Batch Consumption Time: 0.27949
Total Iteration Time: 4.73078

Cumulative Model Updates: 263,798
Cumulative Timesteps: 2,200,628,628

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68,967.16360
Policy Entropy: 2.73164
Value Function Loss: 0.01058

Mean KL Divergence: 0.00756
SB3 Clip Fraction: 0.06829
Policy Update Magnitude: 0.31794
Value Function Update Magnitude: 0.30282

Collected Steps per Second: 22,158.95815
Overall Steps per Second: 10,512.67087

Timestep Collection Time: 2.25805
Timestep Consumption Time: 2.50154
PPO Batch Consumption Time: 0.28968
Total Iteration Time: 4.75959

Cumulative Model Updates: 263,804
Cumulative Timesteps: 2,200,678,664

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 2200678664...
Checkpoint 2200678664 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 78,103.53094
Policy Entropy: 2.72977
Value Function Loss: 0.01202

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.06872
Policy Update Magnitude: 0.31221
Value Function Update Magnitude: 0.31405

Collected Steps per Second: 21,983.72466
Overall Steps per Second: 10,651.37105

Timestep Collection Time: 2.27577
Timestep Consumption Time: 2.42127
PPO Batch Consumption Time: 0.27838
Total Iteration Time: 4.69705

Cumulative Model Updates: 263,810
Cumulative Timesteps: 2,200,728,694

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90,284.81706
Policy Entropy: 2.72833
Value Function Loss: 0.01236

Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.07114
Policy Update Magnitude: 0.31414
Value Function Update Magnitude: 0.30455

Collected Steps per Second: 22,332.37253
Overall Steps per Second: 10,492.44252

Timestep Collection Time: 2.24051
Timestep Consumption Time: 2.52825
PPO Batch Consumption Time: 0.29354
Total Iteration Time: 4.76877

Cumulative Model Updates: 263,816
Cumulative Timesteps: 2,200,778,730

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 2200778730...
Checkpoint 2200778730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 58,369.28377
Policy Entropy: 2.74929
Value Function Loss: 0.01416

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.08478
Policy Update Magnitude: 0.31582
Value Function Update Magnitude: 0.31130

Collected Steps per Second: 21,999.13318
Overall Steps per Second: 10,641.95715

Timestep Collection Time: 2.27336
Timestep Consumption Time: 2.42615
PPO Batch Consumption Time: 0.27696
Total Iteration Time: 4.69951

Cumulative Model Updates: 263,822
Cumulative Timesteps: 2,200,828,742

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80,027.58292
Policy Entropy: 2.74674
Value Function Loss: 0.01285

Mean KL Divergence: 0.01282
SB3 Clip Fraction: 0.10299
Policy Update Magnitude: 0.31112
Value Function Update Magnitude: 0.32131

Collected Steps per Second: 22,103.66241
Overall Steps per Second: 10,515.31853

Timestep Collection Time: 2.26243
Timestep Consumption Time: 2.49330
PPO Batch Consumption Time: 0.29229
Total Iteration Time: 4.75573

Cumulative Model Updates: 263,828
Cumulative Timesteps: 2,200,878,750

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2200878750...
Checkpoint 2200878750 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 113,507.20735
Policy Entropy: 2.74588
Value Function Loss: 0.01345

Mean KL Divergence: 0.01533
SB3 Clip Fraction: 0.11256
Policy Update Magnitude: 0.31034
Value Function Update Magnitude: 0.34077

Collected Steps per Second: 21,426.09894
Overall Steps per Second: 10,514.46565

Timestep Collection Time: 2.33426
Timestep Consumption Time: 2.42243
PPO Batch Consumption Time: 0.27776
Total Iteration Time: 4.75668

Cumulative Model Updates: 263,834
Cumulative Timesteps: 2,200,928,764

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82,714.95058
Policy Entropy: 2.73911
Value Function Loss: 0.01429

Mean KL Divergence: 0.01297
SB3 Clip Fraction: 0.10589
Policy Update Magnitude: 0.32005
Value Function Update Magnitude: 0.33379

Collected Steps per Second: 21,947.39967
Overall Steps per Second: 10,466.11376

Timestep Collection Time: 2.27981
Timestep Consumption Time: 2.50095
PPO Batch Consumption Time: 0.29002
Total Iteration Time: 4.78076

Cumulative Model Updates: 263,840
Cumulative Timesteps: 2,200,978,800

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 2200978800...
Checkpoint 2200978800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 82,714.95058
Policy Entropy: 2.73901
Value Function Loss: 0.01403

Mean KL Divergence: 0.01175
SB3 Clip Fraction: 0.09766
Policy Update Magnitude: 0.32475
Value Function Update Magnitude: 0.32431

Collected Steps per Second: 21,305.15680
Overall Steps per Second: 10,275.86000

Timestep Collection Time: 2.34779
Timestep Consumption Time: 2.51993
PPO Batch Consumption Time: 0.29237
Total Iteration Time: 4.86772

Cumulative Model Updates: 263,846
Cumulative Timesteps: 2,201,028,820

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99,752.96438
Policy Entropy: 2.72832
Value Function Loss: 0.01431

Mean KL Divergence: 0.01157
SB3 Clip Fraction: 0.09801
Policy Update Magnitude: 0.34211
Value Function Update Magnitude: 0.35037

Collected Steps per Second: 22,443.76548
Overall Steps per Second: 10,509.41381

Timestep Collection Time: 2.22806
Timestep Consumption Time: 2.53015
PPO Batch Consumption Time: 0.29194
Total Iteration Time: 4.75821

Cumulative Model Updates: 263,852
Cumulative Timesteps: 2,201,078,826

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2201078826...
Checkpoint 2201078826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 113,128.71740
Policy Entropy: 2.72067
Value Function Loss: 0.01449

Mean KL Divergence: 0.01055
SB3 Clip Fraction: 0.09152
Policy Update Magnitude: 0.34272
Value Function Update Magnitude: 0.35499

Collected Steps per Second: 21,984.44803
Overall Steps per Second: 10,445.88271

Timestep Collection Time: 2.27679
Timestep Consumption Time: 2.51495
PPO Batch Consumption Time: 0.29088
Total Iteration Time: 4.79174

Cumulative Model Updates: 263,858
Cumulative Timesteps: 2,201,128,880

Timesteps Collected: 50,054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 109,055.54710
Policy Entropy: 2.73931
Value Function Loss: 0.01357

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.07960
Policy Update Magnitude: 0.33551
Value Function Update Magnitude: 0.37096

Collected Steps per Second: 21,584.67302
Overall Steps per Second: 10,522.34737

Timestep Collection Time: 2.31720
Timestep Consumption Time: 2.43611
PPO Batch Consumption Time: 0.29184
Total Iteration Time: 4.75331

Cumulative Model Updates: 263,864
Cumulative Timesteps: 2,201,178,896

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2201178896...
Checkpoint 2201178896 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 107,557.52612
Policy Entropy: 2.73836
Value Function Loss: 0.01223

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.07734
Policy Update Magnitude: 0.32421
Value Function Update Magnitude: 0.34115

Collected Steps per Second: 21,332.49372
Overall Steps per Second: 10,628.67162

Timestep Collection Time: 2.34394
Timestep Consumption Time: 2.36051
PPO Batch Consumption Time: 0.27880
Total Iteration Time: 4.70444

Cumulative Model Updates: 263,870
Cumulative Timesteps: 2,201,228,898

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87,784.31941
Policy Entropy: 2.71524
Value Function Loss: 0.01362

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.07528
Policy Update Magnitude: 0.32941
Value Function Update Magnitude: 0.34975

Collected Steps per Second: 21,549.00712
Overall Steps per Second: 10,474.42195

Timestep Collection Time: 2.32094
Timestep Consumption Time: 2.45393
PPO Batch Consumption Time: 0.28753
Total Iteration Time: 4.77487

Cumulative Model Updates: 263,876
Cumulative Timesteps: 2,201,278,912

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2201278912...
Checkpoint 2201278912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89,409.63759
Policy Entropy: 2.72367
Value Function Loss: 0.01266

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.07539
Policy Update Magnitude: 0.34053
Value Function Update Magnitude: 0.36718

Collected Steps per Second: 21,527.51408
Overall Steps per Second: 10,576.68373

Timestep Collection Time: 2.32270
Timestep Consumption Time: 2.40487
PPO Batch Consumption Time: 0.27856
Total Iteration Time: 4.72757

Cumulative Model Updates: 263,882
Cumulative Timesteps: 2,201,328,914

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 64,605.57254
Policy Entropy: 2.72237
Value Function Loss: 0.01333

Mean KL Divergence: 0.00747
SB3 Clip Fraction: 0.06586
Policy Update Magnitude: 0.33906
Value Function Update Magnitude: 0.38569

Collected Steps per Second: 22,027.80363
Overall Steps per Second: 10,494.78896

Timestep Collection Time: 2.27022
Timestep Consumption Time: 2.49481
PPO Batch Consumption Time: 0.29267
Total Iteration Time: 4.76503

Cumulative Model Updates: 263,888
Cumulative Timesteps: 2,201,378,922

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2201378922...
Checkpoint 2201378922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 59,339.36294
Policy Entropy: 2.75178
Value Function Loss: 0.01395

Mean KL Divergence: 0.00672
SB3 Clip Fraction: 0.06166
Policy Update Magnitude: 0.34378
Value Function Update Magnitude: 0.39067

Collected Steps per Second: 21,407.47723
Overall Steps per Second: 10,386.38321

Timestep Collection Time: 2.33703
Timestep Consumption Time: 2.47985
PPO Batch Consumption Time: 0.28991
Total Iteration Time: 4.81688

Cumulative Model Updates: 263,894
Cumulative Timesteps: 2,201,428,952

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58,540.85849
Policy Entropy: 2.74994
Value Function Loss: 0.01349

Mean KL Divergence: 0.00737
SB3 Clip Fraction: 0.06674
Policy Update Magnitude: 0.33398
Value Function Update Magnitude: 0.38420

Collected Steps per Second: 21,909.71589
Overall Steps per Second: 10,640.92462

Timestep Collection Time: 2.28364
Timestep Consumption Time: 2.41839
PPO Batch Consumption Time: 0.27803
Total Iteration Time: 4.70204

Cumulative Model Updates: 263,900
Cumulative Timesteps: 2,201,478,986

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 2201478986...
Checkpoint 2201478986 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 52,088.69979
Policy Entropy: 2.76086
Value Function Loss: 0.01421

Mean KL Divergence: 0.00658
SB3 Clip Fraction: 0.05948
Policy Update Magnitude: 0.32706
Value Function Update Magnitude: 0.36716

Collected Steps per Second: 21,190.99530
Overall Steps per Second: 10,268.32134

Timestep Collection Time: 2.35978
Timestep Consumption Time: 2.51015
PPO Batch Consumption Time: 0.29136
Total Iteration Time: 4.86993

Cumulative Model Updates: 263,906
Cumulative Timesteps: 2,201,528,992

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,430.86386
Policy Entropy: 2.76253
Value Function Loss: 0.01229

Mean KL Divergence: 0.00671
SB3 Clip Fraction: 0.06183
Policy Update Magnitude: 0.32261
Value Function Update Magnitude: 0.36068

Collected Steps per Second: 21,758.38416
Overall Steps per Second: 10,459.61636

Timestep Collection Time: 2.29916
Timestep Consumption Time: 2.48362
PPO Batch Consumption Time: 0.29138
Total Iteration Time: 4.78278

Cumulative Model Updates: 263,912
Cumulative Timesteps: 2,201,579,018

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2201579018...
Checkpoint 2201579018 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,355.92064
Policy Entropy: 2.76404
Value Function Loss: 0.01275

Mean KL Divergence: 0.00661
SB3 Clip Fraction: 0.05958
Policy Update Magnitude: 0.32430
Value Function Update Magnitude: 0.35738

Collected Steps per Second: 21,249.49405
Overall Steps per Second: 10,307.43088

Timestep Collection Time: 2.35300
Timestep Consumption Time: 2.49787
PPO Batch Consumption Time: 0.29176
Total Iteration Time: 4.85087

Cumulative Model Updates: 263,918
Cumulative Timesteps: 2,201,629,018

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,631.68518
Policy Entropy: 2.75952
Value Function Loss: 0.01259

Mean KL Divergence: 0.00694
SB3 Clip Fraction: 0.06607
Policy Update Magnitude: 0.32712
Value Function Update Magnitude: 0.36760

Collected Steps per Second: 22,411.87765
Overall Steps per Second: 10,546.05759

Timestep Collection Time: 2.23239
Timestep Consumption Time: 2.51175
PPO Batch Consumption Time: 0.28952
Total Iteration Time: 4.74414

Cumulative Model Updates: 263,924
Cumulative Timesteps: 2,201,679,050

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2201679050...
Checkpoint 2201679050 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,563.65052
Policy Entropy: 2.76774
Value Function Loss: 0.01195

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.07257
Policy Update Magnitude: 0.32489
Value Function Update Magnitude: 0.36933

Collected Steps per Second: 21,965.91612
Overall Steps per Second: 10,453.53776

Timestep Collection Time: 2.27735
Timestep Consumption Time: 2.50802
PPO Batch Consumption Time: 0.29258
Total Iteration Time: 4.78537

Cumulative Model Updates: 263,930
Cumulative Timesteps: 2,201,729,074

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45,563.65052
Policy Entropy: 2.78142
Value Function Loss: 0.01033

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.08277
Policy Update Magnitude: 0.30901
Value Function Update Magnitude: 0.34070

Collected Steps per Second: 22,311.33753
Overall Steps per Second: 10,558.27624

Timestep Collection Time: 2.24209
Timestep Consumption Time: 2.49581
PPO Batch Consumption Time: 0.29183
Total Iteration Time: 4.73789

Cumulative Model Updates: 263,936
Cumulative Timesteps: 2,201,779,098

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2201779098...
Checkpoint 2201779098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,140.38547
Policy Entropy: 2.80086
Value Function Loss: 0.00943

Mean KL Divergence: 0.00732
SB3 Clip Fraction: 0.06778
Policy Update Magnitude: 0.29387
Value Function Update Magnitude: 0.30623

Collected Steps per Second: 21,786.54833
Overall Steps per Second: 10,574.69723

Timestep Collection Time: 2.29720
Timestep Consumption Time: 2.43561
PPO Batch Consumption Time: 0.27755
Total Iteration Time: 4.73281

Cumulative Model Updates: 263,942
Cumulative Timesteps: 2,201,829,146

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61,628.88271
Policy Entropy: 2.79270
Value Function Loss: 0.01069

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.07074
Policy Update Magnitude: 0.28594
Value Function Update Magnitude: 0.28016

Collected Steps per Second: 22,281.72210
Overall Steps per Second: 10,566.22915

Timestep Collection Time: 2.24516
Timestep Consumption Time: 2.48936
PPO Batch Consumption Time: 0.28998
Total Iteration Time: 4.73452

Cumulative Model Updates: 263,948
Cumulative Timesteps: 2,201,879,172

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2201879172...
Checkpoint 2201879172 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 50,793.10603
Policy Entropy: 2.80365
Value Function Loss: 0.01083

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.07895
Policy Update Magnitude: 0.29238
Value Function Update Magnitude: 0.28392

Collected Steps per Second: 21,623.96542
Overall Steps per Second: 10,468.22238

Timestep Collection Time: 2.31271
Timestep Consumption Time: 2.46460
PPO Batch Consumption Time: 0.28462
Total Iteration Time: 4.77732

Cumulative Model Updates: 263,954
Cumulative Timesteps: 2,201,929,182

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83,590.54172
Policy Entropy: 2.79059
Value Function Loss: 0.00985

Mean KL Divergence: 0.00756
SB3 Clip Fraction: 0.07100
Policy Update Magnitude: 0.28607
Value Function Update Magnitude: 0.26094

Collected Steps per Second: 22,105.30684
Overall Steps per Second: 10,469.89056

Timestep Collection Time: 2.26262
Timestep Consumption Time: 2.51450
PPO Batch Consumption Time: 0.29321
Total Iteration Time: 4.77713

Cumulative Model Updates: 263,960
Cumulative Timesteps: 2,201,979,198

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2201979198...
Checkpoint 2201979198 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 64,886.46222
Policy Entropy: 2.77430
Value Function Loss: 0.01014

Mean KL Divergence: 0.00703
SB3 Clip Fraction: 0.06426
Policy Update Magnitude: 0.28513
Value Function Update Magnitude: 0.25083

Collected Steps per Second: 21,424.25903
Overall Steps per Second: 10,364.48730

Timestep Collection Time: 2.33380
Timestep Consumption Time: 2.49036
PPO Batch Consumption Time: 0.29055
Total Iteration Time: 4.82417

Cumulative Model Updates: 263,966
Cumulative Timesteps: 2,202,029,198

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57,902.21461
Policy Entropy: 2.76389
Value Function Loss: 0.00942

Mean KL Divergence: 0.00559
SB3 Clip Fraction: 0.05427
Policy Update Magnitude: 0.28959
Value Function Update Magnitude: 0.24759

Collected Steps per Second: 21,636.58091
Overall Steps per Second: 10,423.77953

Timestep Collection Time: 2.31099
Timestep Consumption Time: 2.48592
PPO Batch Consumption Time: 0.29093
Total Iteration Time: 4.79692

Cumulative Model Updates: 263,972
Cumulative Timesteps: 2,202,079,200

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2202079200...
Checkpoint 2202079200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89,196.99600
Policy Entropy: 2.75824
Value Function Loss: 0.01045

Mean KL Divergence: 0.00566
SB3 Clip Fraction: 0.05409
Policy Update Magnitude: 0.29435
Value Function Update Magnitude: 0.26827

Collected Steps per Second: 21,482.11934
Overall Steps per Second: 10,544.08232

Timestep Collection Time: 2.32826
Timestep Consumption Time: 2.41525
PPO Batch Consumption Time: 0.27753
Total Iteration Time: 4.74351

Cumulative Model Updates: 263,978
Cumulative Timesteps: 2,202,129,216

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89,196.99600
Policy Entropy: 2.78707
Value Function Loss: 0.00873

Mean KL Divergence: 0.00550
SB3 Clip Fraction: 0.05189
Policy Update Magnitude: 0.29330
Value Function Update Magnitude: 0.28104

Collected Steps per Second: 20,691.41318
Overall Steps per Second: 10,104.41974

Timestep Collection Time: 2.41888
Timestep Consumption Time: 2.53440
PPO Batch Consumption Time: 0.29165
Total Iteration Time: 4.95328

Cumulative Model Updates: 263,984
Cumulative Timesteps: 2,202,179,266

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 2202179266...
Checkpoint 2202179266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 88,479.10133
Policy Entropy: 2.77457
Value Function Loss: 0.01113

Mean KL Divergence: 0.00584
SB3 Clip Fraction: 0.05213
Policy Update Magnitude: 0.30766
Value Function Update Magnitude: 0.26628

Collected Steps per Second: 21,158.29033
Overall Steps per Second: 10,432.19480

Timestep Collection Time: 2.36390
Timestep Consumption Time: 2.43049
PPO Batch Consumption Time: 0.27837
Total Iteration Time: 4.79439

Cumulative Model Updates: 263,990
Cumulative Timesteps: 2,202,229,282

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77,662.55725
Policy Entropy: 2.78980
Value Function Loss: 0.01041

Mean KL Divergence: 0.00629
SB3 Clip Fraction: 0.05377
Policy Update Magnitude: 0.31531
Value Function Update Magnitude: 0.29347

Collected Steps per Second: 21,404.06581
Overall Steps per Second: 10,509.79349

Timestep Collection Time: 2.33675
Timestep Consumption Time: 2.42224
PPO Batch Consumption Time: 0.28540
Total Iteration Time: 4.75899

Cumulative Model Updates: 263,996
Cumulative Timesteps: 2,202,279,298

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2202279298...
Checkpoint 2202279298 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 102,511.67806
Policy Entropy: 2.75101
Value Function Loss: 0.01110

Mean KL Divergence: 0.00748
SB3 Clip Fraction: 0.06570
Policy Update Magnitude: 0.31553
Value Function Update Magnitude: 0.30380

Collected Steps per Second: 21,412.79229
Overall Steps per Second: 10,680.53105

Timestep Collection Time: 2.33627
Timestep Consumption Time: 2.34758
PPO Batch Consumption Time: 0.27736
Total Iteration Time: 4.68385

Cumulative Model Updates: 264,002
Cumulative Timesteps: 2,202,329,324

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 134,219.12838
Policy Entropy: 2.75384
Value Function Loss: 0.01118

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.08561
Policy Update Magnitude: 0.32209
Value Function Update Magnitude: 0.32759

Collected Steps per Second: 21,692.85628
Overall Steps per Second: 10,622.36402

Timestep Collection Time: 2.30610
Timestep Consumption Time: 2.40339
PPO Batch Consumption Time: 0.28918
Total Iteration Time: 4.70950

Cumulative Model Updates: 264,008
Cumulative Timesteps: 2,202,379,350

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2202379350...
Checkpoint 2202379350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 119,914.41502
Policy Entropy: 2.75883
Value Function Loss: 0.01091

Mean KL Divergence: 0.01113
SB3 Clip Fraction: 0.08967
Policy Update Magnitude: 0.31446
Value Function Update Magnitude: 0.35106

Collected Steps per Second: 21,446.97458
Overall Steps per Second: 10,432.29549

Timestep Collection Time: 2.33264
Timestep Consumption Time: 2.46286
PPO Batch Consumption Time: 0.28830
Total Iteration Time: 4.79549

Cumulative Model Updates: 264,014
Cumulative Timesteps: 2,202,429,378

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 107,127.30160
Policy Entropy: 2.78857
Value Function Loss: 0.01195

Mean KL Divergence: 0.01131
SB3 Clip Fraction: 0.08988
Policy Update Magnitude: 0.32443
Value Function Update Magnitude: 0.34806

Collected Steps per Second: 22,152.71107
Overall Steps per Second: 10,571.37801

Timestep Collection Time: 2.25751
Timestep Consumption Time: 2.47319
PPO Batch Consumption Time: 0.29198
Total Iteration Time: 4.73070

Cumulative Model Updates: 264,020
Cumulative Timesteps: 2,202,479,388

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2202479388...
Checkpoint 2202479388 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86,770.23547
Policy Entropy: 2.80514
Value Function Loss: 0.01156

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.08666
Policy Update Magnitude: 0.29620
Value Function Update Magnitude: 0.33019

Collected Steps per Second: 22,032.55567
Overall Steps per Second: 10,592.35929

Timestep Collection Time: 2.27064
Timestep Consumption Time: 2.45239
PPO Batch Consumption Time: 0.28765
Total Iteration Time: 4.72303

Cumulative Model Updates: 264,026
Cumulative Timesteps: 2,202,529,416

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67,030.28852
Policy Entropy: 2.81689
Value Function Loss: 0.01258

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.07686
Policy Update Magnitude: 0.28988
Value Function Update Magnitude: 0.32108

Collected Steps per Second: 22,189.96553
Overall Steps per Second: 10,520.83473

Timestep Collection Time: 2.25462
Timestep Consumption Time: 2.50070
PPO Batch Consumption Time: 0.29222
Total Iteration Time: 4.75533

Cumulative Model Updates: 264,032
Cumulative Timesteps: 2,202,579,446

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2202579446...
Checkpoint 2202579446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 64,593.65813
Policy Entropy: 2.82939
Value Function Loss: 0.01079

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.07456
Policy Update Magnitude: 0.28675
Value Function Update Magnitude: 0.28906

Collected Steps per Second: 21,882.44025
Overall Steps per Second: 10,647.55420

Timestep Collection Time: 2.28567
Timestep Consumption Time: 2.41175
PPO Batch Consumption Time: 0.27661
Total Iteration Time: 4.69742

Cumulative Model Updates: 264,038
Cumulative Timesteps: 2,202,629,462

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 71,444.03276
Policy Entropy: 2.83642
Value Function Loss: 0.01158

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.07145
Policy Update Magnitude: 0.28294
Value Function Update Magnitude: 0.24780

Collected Steps per Second: 21,833.35415
Overall Steps per Second: 10,463.32525

Timestep Collection Time: 2.29154
Timestep Consumption Time: 2.49011
PPO Batch Consumption Time: 0.29257
Total Iteration Time: 4.78165

Cumulative Model Updates: 264,044
Cumulative Timesteps: 2,202,679,494

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2202679494...
Checkpoint 2202679494 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 52,250.51375
Policy Entropy: 2.82448
Value Function Loss: 0.01119

Mean KL Divergence: 0.00694
SB3 Clip Fraction: 0.06481
Policy Update Magnitude: 0.28641
Value Function Update Magnitude: 0.26805

Collected Steps per Second: 21,735.24533
Overall Steps per Second: 10,556.26626

Timestep Collection Time: 2.30087
Timestep Consumption Time: 2.43660
PPO Batch Consumption Time: 0.27775
Total Iteration Time: 4.73747

Cumulative Model Updates: 264,050
Cumulative Timesteps: 2,202,729,504

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42,713.94713
Policy Entropy: 2.80466
Value Function Loss: 0.01227

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.07418
Policy Update Magnitude: 0.29381
Value Function Update Magnitude: 0.26950

Collected Steps per Second: 21,404.99248
Overall Steps per Second: 10,500.26320

Timestep Collection Time: 2.33656
Timestep Consumption Time: 2.42656
PPO Batch Consumption Time: 0.27644
Total Iteration Time: 4.76312

Cumulative Model Updates: 264,056
Cumulative Timesteps: 2,202,779,518

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2202779518...
Checkpoint 2202779518 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 93,678.73439
Policy Entropy: 2.80553
Value Function Loss: 0.01172

Mean KL Divergence: 0.00733
SB3 Clip Fraction: 0.06779
Policy Update Magnitude: 0.29489
Value Function Update Magnitude: 0.26132

Collected Steps per Second: 22,160.48315
Overall Steps per Second: 10,549.08084

Timestep Collection Time: 2.25663
Timestep Consumption Time: 2.48388
PPO Batch Consumption Time: 0.27806
Total Iteration Time: 4.74051

Cumulative Model Updates: 264,062
Cumulative Timesteps: 2,202,829,526

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82,355.41541
Policy Entropy: 2.80494
Value Function Loss: 0.01123

Mean KL Divergence: 0.00719
SB3 Clip Fraction: 0.06735
Policy Update Magnitude: 0.28503
Value Function Update Magnitude: 0.26887

Collected Steps per Second: 21,914.58167
Overall Steps per Second: 10,501.56486

Timestep Collection Time: 2.28277
Timestep Consumption Time: 2.48090
PPO Batch Consumption Time: 0.28644
Total Iteration Time: 4.76367

Cumulative Model Updates: 264,068
Cumulative Timesteps: 2,202,879,552

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2202879552...
Checkpoint 2202879552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 83,875.82629
Policy Entropy: 2.80460
Value Function Loss: 0.01149

Mean KL Divergence: 0.00677
SB3 Clip Fraction: 0.06518
Policy Update Magnitude: 0.29054
Value Function Update Magnitude: 0.28435

Collected Steps per Second: 22,031.39990
Overall Steps per Second: 10,668.27895

Timestep Collection Time: 2.27040
Timestep Consumption Time: 2.41827
PPO Batch Consumption Time: 0.27707
Total Iteration Time: 4.68867

Cumulative Model Updates: 264,074
Cumulative Timesteps: 2,202,929,572

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58,961.47204
Policy Entropy: 2.78072
Value Function Loss: 0.01315

Mean KL Divergence: 0.00651
SB3 Clip Fraction: 0.06446
Policy Update Magnitude: 0.30693
Value Function Update Magnitude: 0.33330

Collected Steps per Second: 21,812.70554
Overall Steps per Second: 10,397.06789

Timestep Collection Time: 2.29233
Timestep Consumption Time: 2.51691
PPO Batch Consumption Time: 0.29217
Total Iteration Time: 4.80924

Cumulative Model Updates: 264,080
Cumulative Timesteps: 2,202,979,574

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2202979574...
Checkpoint 2202979574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 58,961.47204
Policy Entropy: 2.78020
Value Function Loss: 0.01389

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.07163
Policy Update Magnitude: 0.32839
Value Function Update Magnitude: 0.34250

Collected Steps per Second: 22,058.23706
Overall Steps per Second: 10,633.74116

Timestep Collection Time: 2.26682
Timestep Consumption Time: 2.43538
PPO Batch Consumption Time: 0.27901
Total Iteration Time: 4.70220

Cumulative Model Updates: 264,086
Cumulative Timesteps: 2,203,029,576

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 94,764.61316
Policy Entropy: 2.76699
Value Function Loss: 0.01366

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.07359
Policy Update Magnitude: 0.33317
Value Function Update Magnitude: 0.34265

Collected Steps per Second: 21,732.59678
Overall Steps per Second: 10,468.91528

Timestep Collection Time: 2.30180
Timestep Consumption Time: 2.47654
PPO Batch Consumption Time: 0.28569
Total Iteration Time: 4.77834

Cumulative Model Updates: 264,092
Cumulative Timesteps: 2,203,079,600

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2203079600...
Checkpoint 2203079600 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 105,880.35397
Policy Entropy: 2.76018
Value Function Loss: 0.01269

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.07353
Policy Update Magnitude: 0.32935
Value Function Update Magnitude: 0.32138

Collected Steps per Second: 21,696.00538
Overall Steps per Second: 10,589.57165

Timestep Collection Time: 2.30457
Timestep Consumption Time: 2.41705
PPO Batch Consumption Time: 0.27814
Total Iteration Time: 4.72163

Cumulative Model Updates: 264,098
Cumulative Timesteps: 2,203,129,600

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 74,395.03821
Policy Entropy: 2.75393
Value Function Loss: 0.01220

Mean KL Divergence: 0.00696
SB3 Clip Fraction: 0.06219
Policy Update Magnitude: 0.32689
Value Function Update Magnitude: 0.30624

Collected Steps per Second: 20,682.42662
Overall Steps per Second: 10,083.13323

Timestep Collection Time: 2.41828
Timestep Consumption Time: 2.54208
PPO Batch Consumption Time: 0.29374
Total Iteration Time: 4.96036

Cumulative Model Updates: 264,104
Cumulative Timesteps: 2,203,179,616

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2203179616...
Checkpoint 2203179616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 75,598.90634
Policy Entropy: 2.76840
Value Function Loss: 0.01091

Mean KL Divergence: 0.00756
SB3 Clip Fraction: 0.06856
Policy Update Magnitude: 0.31032
Value Function Update Magnitude: 0.30623

Collected Steps per Second: 20,965.21096
Overall Steps per Second: 10,217.93058

Timestep Collection Time: 2.38643
Timestep Consumption Time: 2.51006
PPO Batch Consumption Time: 0.29322
Total Iteration Time: 4.89649

Cumulative Model Updates: 264,110
Cumulative Timesteps: 2,203,229,648

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 69,657.81669
Policy Entropy: 2.78178
Value Function Loss: 0.01071

Mean KL Divergence: 0.00654
SB3 Clip Fraction: 0.06180
Policy Update Magnitude: 0.30079
Value Function Update Magnitude: 0.29980

Collected Steps per Second: 20,559.81674
Overall Steps per Second: 10,420.64498

Timestep Collection Time: 2.43232
Timestep Consumption Time: 2.36662
PPO Batch Consumption Time: 0.27872
Total Iteration Time: 4.79894

Cumulative Model Updates: 264,116
Cumulative Timesteps: 2,203,279,656

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2203279656...
Checkpoint 2203279656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 101,055.68702
Policy Entropy: 2.77456
Value Function Loss: 0.01272

Mean KL Divergence: 0.00552
SB3 Clip Fraction: 0.05090
Policy Update Magnitude: 0.31670
Value Function Update Magnitude: 0.31471

Collected Steps per Second: 20,792.60686
Overall Steps per Second: 10,374.48533

Timestep Collection Time: 2.40614
Timestep Consumption Time: 2.41626
PPO Batch Consumption Time: 0.29278
Total Iteration Time: 4.82241

Cumulative Model Updates: 264,122
Cumulative Timesteps: 2,203,329,686

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63,122.63044
Policy Entropy: 2.74664
Value Function Loss: 0.01354

Mean KL Divergence: 0.00714
SB3 Clip Fraction: 0.05907
Policy Update Magnitude: 0.32549
Value Function Update Magnitude: 0.33600

Collected Steps per Second: 21,315.90959
Overall Steps per Second: 10,476.14583

Timestep Collection Time: 2.34745
Timestep Consumption Time: 2.42893
PPO Batch Consumption Time: 0.28931
Total Iteration Time: 4.77637

Cumulative Model Updates: 264,128
Cumulative Timesteps: 2,203,379,724

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 2203379724...
Checkpoint 2203379724 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47,632.91325
Policy Entropy: 2.73225
Value Function Loss: 0.01313

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.06352
Policy Update Magnitude: 0.32158
Value Function Update Magnitude: 0.31951

Collected Steps per Second: 21,129.64222
Overall Steps per Second: 10,429.15887

Timestep Collection Time: 2.36757
Timestep Consumption Time: 2.42917
PPO Batch Consumption Time: 0.27880
Total Iteration Time: 4.79674

Cumulative Model Updates: 264,134
Cumulative Timesteps: 2,203,429,750

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 108,336.27867
Policy Entropy: 2.73689
Value Function Loss: 0.01276

Mean KL Divergence: 0.00645
SB3 Clip Fraction: 0.06013
Policy Update Magnitude: 0.31697
Value Function Update Magnitude: 0.30965

Collected Steps per Second: 21,831.80536
Overall Steps per Second: 10,507.56223

Timestep Collection Time: 2.29106
Timestep Consumption Time: 2.46913
PPO Batch Consumption Time: 0.27884
Total Iteration Time: 4.76019

Cumulative Model Updates: 264,140
Cumulative Timesteps: 2,203,479,768

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2203479768...
Checkpoint 2203479768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89,108.70267
Policy Entropy: 2.74140
Value Function Loss: 0.01131

Mean KL Divergence: 0.00639
SB3 Clip Fraction: 0.05771
Policy Update Magnitude: 0.31797
Value Function Update Magnitude: 0.31773

Collected Steps per Second: 21,933.18210
Overall Steps per Second: 10,626.48922

Timestep Collection Time: 2.28211
Timestep Consumption Time: 2.42819
PPO Batch Consumption Time: 0.28103
Total Iteration Time: 4.71030

Cumulative Model Updates: 264,146
Cumulative Timesteps: 2,203,529,822

Timesteps Collected: 50,054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83,926.29065
Policy Entropy: 2.71563
Value Function Loss: 0.01190

Mean KL Divergence: 0.00682
SB3 Clip Fraction: 0.06443
Policy Update Magnitude: 0.31480
Value Function Update Magnitude: 0.29655

Collected Steps per Second: 22,065.82754
Overall Steps per Second: 10,542.61956

Timestep Collection Time: 2.26740
Timestep Consumption Time: 2.47829
PPO Batch Consumption Time: 0.29274
Total Iteration Time: 4.74569

Cumulative Model Updates: 264,152
Cumulative Timesteps: 2,203,579,854

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2203579854...
Checkpoint 2203579854 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 75,332.05448
Policy Entropy: 2.72162
Value Function Loss: 0.01203

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.07110
Policy Update Magnitude: 0.31664
Value Function Update Magnitude: 0.25687

Collected Steps per Second: 22,131.23452
Overall Steps per Second: 10,530.59373

Timestep Collection Time: 2.25979
Timestep Consumption Time: 2.48942
PPO Batch Consumption Time: 0.28617
Total Iteration Time: 4.74921

Cumulative Model Updates: 264,158
Cumulative Timesteps: 2,203,629,866

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 105,929.61277
Policy Entropy: 2.71408
Value Function Loss: 0.01481

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.07727
Policy Update Magnitude: 0.32415
Value Function Update Magnitude: 0.25315

Collected Steps per Second: 22,245.07342
Overall Steps per Second: 10,539.09132

Timestep Collection Time: 2.24778
Timestep Consumption Time: 2.49665
PPO Batch Consumption Time: 0.29185
Total Iteration Time: 4.74443

Cumulative Model Updates: 264,164
Cumulative Timesteps: 2,203,679,868

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2203679868...
Checkpoint 2203679868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 80,667.62080
Policy Entropy: 2.74030
Value Function Loss: 0.01399

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.07331
Policy Update Magnitude: 0.34768
Value Function Update Magnitude: 0.29282

Collected Steps per Second: 21,953.07028
Overall Steps per Second: 10,655.91241

Timestep Collection Time: 2.27895
Timestep Consumption Time: 2.41609
PPO Batch Consumption Time: 0.27608
Total Iteration Time: 4.69505

Cumulative Model Updates: 264,170
Cumulative Timesteps: 2,203,729,898

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81,310.37664
Policy Entropy: 2.75353
Value Function Loss: 0.01407

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.07341
Policy Update Magnitude: 0.33733
Value Function Update Magnitude: 0.33199

Collected Steps per Second: 21,850.55314
Overall Steps per Second: 10,433.50591

Timestep Collection Time: 2.28919
Timestep Consumption Time: 2.50498
PPO Batch Consumption Time: 0.29211
Total Iteration Time: 4.79417

Cumulative Model Updates: 264,176
Cumulative Timesteps: 2,203,779,918

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2203779918...
Checkpoint 2203779918 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 71,344.78498
Policy Entropy: 2.75945
Value Function Loss: 0.01201

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.07090
Policy Update Magnitude: 0.32019
Value Function Update Magnitude: 0.29638

Collected Steps per Second: 21,715.28725
Overall Steps per Second: 10,567.67742

Timestep Collection Time: 2.30446
Timestep Consumption Time: 2.43092
PPO Batch Consumption Time: 0.27873
Total Iteration Time: 4.73538

Cumulative Model Updates: 264,182
Cumulative Timesteps: 2,203,829,960

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 71,344.78498
Policy Entropy: 2.77634
Value Function Loss: 0.01022

Mean KL Divergence: 0.01070
SB3 Clip Fraction: 0.08541
Policy Update Magnitude: 0.29956
Value Function Update Magnitude: 0.25898

Collected Steps per Second: 21,635.94510
Overall Steps per Second: 10,409.39175

Timestep Collection Time: 2.31199
Timestep Consumption Time: 2.49348
PPO Batch Consumption Time: 0.28827
Total Iteration Time: 4.80547

Cumulative Model Updates: 264,188
Cumulative Timesteps: 2,203,879,982

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2203879982...
Checkpoint 2203879982 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 73,870.74882
Policy Entropy: 2.77379
Value Function Loss: 0.00932

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.07934
Policy Update Magnitude: 0.28488
Value Function Update Magnitude: 0.20467

Collected Steps per Second: 21,564.98635
Overall Steps per Second: 10,338.59220

Timestep Collection Time: 2.32024
Timestep Consumption Time: 2.51949
PPO Batch Consumption Time: 0.29267
Total Iteration Time: 4.83973

Cumulative Model Updates: 264,194
Cumulative Timesteps: 2,203,930,018

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82,183.60528
Policy Entropy: 2.76151
Value Function Loss: 0.01073

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.07388
Policy Update Magnitude: 0.29643
Value Function Update Magnitude: 0.25716

Collected Steps per Second: 22,387.77759
Overall Steps per Second: 10,467.84809

Timestep Collection Time: 2.23524
Timestep Consumption Time: 2.54531
PPO Batch Consumption Time: 0.29145
Total Iteration Time: 4.78054

Cumulative Model Updates: 264,200
Cumulative Timesteps: 2,203,980,060

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 2203980060...
Checkpoint 2203980060 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 107,370.20841
Policy Entropy: 2.74556
Value Function Loss: 0.01157

Mean KL Divergence: 0.00710
SB3 Clip Fraction: 0.06717
Policy Update Magnitude: 0.31577
Value Function Update Magnitude: 0.33478

Collected Steps per Second: 21,738.20060
Overall Steps per Second: 10,520.28013

Timestep Collection Time: 2.30056
Timestep Consumption Time: 2.45312
PPO Batch Consumption Time: 0.27886
Total Iteration Time: 4.75368

Cumulative Model Updates: 264,206
Cumulative Timesteps: 2,204,030,070

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 120,345.30707
Policy Entropy: 2.74803
Value Function Loss: 0.01392

Mean KL Divergence: 0.00747
SB3 Clip Fraction: 0.06691
Policy Update Magnitude: 0.32806
Value Function Update Magnitude: 0.35825

Collected Steps per Second: 22,078.08557
Overall Steps per Second: 10,489.98142

Timestep Collection Time: 2.26550
Timestep Consumption Time: 2.50266
PPO Batch Consumption Time: 0.29136
Total Iteration Time: 4.76817

Cumulative Model Updates: 264,212
Cumulative Timesteps: 2,204,080,088

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2204080088...
Checkpoint 2204080088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 78,459.98160
Policy Entropy: 2.75519
Value Function Loss: 0.01358

Mean KL Divergence: 0.00689
SB3 Clip Fraction: 0.06626
Policy Update Magnitude: 0.32206
Value Function Update Magnitude: 0.36284

Collected Steps per Second: 21,936.13724
Overall Steps per Second: 10,446.46617

Timestep Collection Time: 2.28099
Timestep Consumption Time: 2.50877
PPO Batch Consumption Time: 0.29174
Total Iteration Time: 4.78975

Cumulative Model Updates: 264,218
Cumulative Timesteps: 2,204,130,124

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78,459.98160
Policy Entropy: 2.73406
Value Function Loss: 0.01153

Mean KL Divergence: 0.00753
SB3 Clip Fraction: 0.07196
Policy Update Magnitude: 0.31485
Value Function Update Magnitude: 0.33470

Collected Steps per Second: 22,272.49591
Overall Steps per Second: 10,534.50988

Timestep Collection Time: 2.24717
Timestep Consumption Time: 2.50389
PPO Batch Consumption Time: 0.29312
Total Iteration Time: 4.75105

Cumulative Model Updates: 264,224
Cumulative Timesteps: 2,204,180,174

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 2204180174...
Checkpoint 2204180174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 78,459.98160
Policy Entropy: 2.72686
Value Function Loss: 0.00986

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.07341
Policy Update Magnitude: 0.30654
Value Function Update Magnitude: 0.28556

Collected Steps per Second: 21,585.38966
Overall Steps per Second: 10,521.63949

Timestep Collection Time: 2.31768
Timestep Consumption Time: 2.43709
PPO Batch Consumption Time: 0.27925
Total Iteration Time: 4.75477

Cumulative Model Updates: 264,230
Cumulative Timesteps: 2,204,230,202

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68,460.83104
Policy Entropy: 2.74376
Value Function Loss: 0.00914

Mean KL Divergence: 0.00718
SB3 Clip Fraction: 0.06866
Policy Update Magnitude: 0.30188
Value Function Update Magnitude: 0.25886

Collected Steps per Second: 22,367.09593
Overall Steps per Second: 10,577.27188

Timestep Collection Time: 2.23623
Timestep Consumption Time: 2.49259
PPO Batch Consumption Time: 0.29268
Total Iteration Time: 4.72882

Cumulative Model Updates: 264,236
Cumulative Timesteps: 2,204,280,220

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2204280220...
Checkpoint 2204280220 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 63,769.50949
Policy Entropy: 2.77147
Value Function Loss: 0.00921

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.07464
Policy Update Magnitude: 0.29508
Value Function Update Magnitude: 0.25663

Collected Steps per Second: 21,301.75963
Overall Steps per Second: 10,507.01515

Timestep Collection Time: 2.34835
Timestep Consumption Time: 2.41266
PPO Batch Consumption Time: 0.27784
Total Iteration Time: 4.76101

Cumulative Model Updates: 264,242
Cumulative Timesteps: 2,204,330,244

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70,524.21454
Policy Entropy: 2.78238
Value Function Loss: 0.00943

Mean KL Divergence: 0.00616
SB3 Clip Fraction: 0.05860
Policy Update Magnitude: 0.28464
Value Function Update Magnitude: 0.26447

Collected Steps per Second: 21,899.77603
Overall Steps per Second: 10,505.62317

Timestep Collection Time: 2.28468
Timestep Consumption Time: 2.47791
PPO Batch Consumption Time: 0.28781
Total Iteration Time: 4.76259

Cumulative Model Updates: 264,248
Cumulative Timesteps: 2,204,380,278

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 2204380278...
Checkpoint 2204380278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84,762.55912
Policy Entropy: 2.78432
Value Function Loss: 0.01001

Mean KL Divergence: 0.00600
SB3 Clip Fraction: 0.05703
Policy Update Magnitude: 0.28410
Value Function Update Magnitude: 0.26319

Collected Steps per Second: 20,911.06554
Overall Steps per Second: 10,507.73219

Timestep Collection Time: 2.39299
Timestep Consumption Time: 2.36922
PPO Batch Consumption Time: 0.28221
Total Iteration Time: 4.76221

Cumulative Model Updates: 264,254
Cumulative Timesteps: 2,204,430,318

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76,781.03274
Policy Entropy: 2.77697
Value Function Loss: 0.01046

Mean KL Divergence: 0.00643
SB3 Clip Fraction: 0.06158
Policy Update Magnitude: 0.29674
Value Function Update Magnitude: 0.28372

Collected Steps per Second: 21,274.37294
Overall Steps per Second: 10,655.15176

Timestep Collection Time: 2.35278
Timestep Consumption Time: 2.34485
PPO Batch Consumption Time: 0.27638
Total Iteration Time: 4.69763

Cumulative Model Updates: 264,260
Cumulative Timesteps: 2,204,480,372

Timesteps Collected: 50,054
--------END ITERATION REPORT--------


Saving checkpoint 2204480372...
Checkpoint 2204480372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 97,340.13443
Policy Entropy: 2.77422
Value Function Loss: 0.01122

Mean KL Divergence: 0.00686
SB3 Clip Fraction: 0.06221
Policy Update Magnitude: 0.30514
Value Function Update Magnitude: 0.31277

Collected Steps per Second: 21,013.38178
Overall Steps per Second: 10,535.07971

Timestep Collection Time: 2.38086
Timestep Consumption Time: 2.36803
PPO Batch Consumption Time: 0.27723
Total Iteration Time: 4.74890

Cumulative Model Updates: 264,266
Cumulative Timesteps: 2,204,530,402

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77,546.21612
Policy Entropy: 2.77934
Value Function Loss: 0.01109

Mean KL Divergence: 0.00736
SB3 Clip Fraction: 0.06616
Policy Update Magnitude: 0.30018
Value Function Update Magnitude: 0.31995

Collected Steps per Second: 21,802.33381
Overall Steps per Second: 10,467.45697

Timestep Collection Time: 2.29563
Timestep Consumption Time: 2.48586
PPO Batch Consumption Time: 0.28634
Total Iteration Time: 4.78149

Cumulative Model Updates: 264,272
Cumulative Timesteps: 2,204,580,452

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 2204580452...
Checkpoint 2204580452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 77,546.21612
Policy Entropy: 2.76578
Value Function Loss: 0.01029

Mean KL Divergence: 0.00674
SB3 Clip Fraction: 0.06380
Policy Update Magnitude: 0.29578
Value Function Update Magnitude: 0.30737

Collected Steps per Second: 21,611.96143
Overall Steps per Second: 10,580.39064

Timestep Collection Time: 2.31566
Timestep Consumption Time: 2.41441
PPO Batch Consumption Time: 0.27838
Total Iteration Time: 4.73007

Cumulative Model Updates: 264,278
Cumulative Timesteps: 2,204,630,498

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 118,481.73912
Policy Entropy: 2.75441
Value Function Loss: 0.01152

Mean KL Divergence: 0.00639
SB3 Clip Fraction: 0.06209
Policy Update Magnitude: 0.31665
Value Function Update Magnitude: 0.29480

Collected Steps per Second: 21,985.03521
Overall Steps per Second: 10,529.06089

Timestep Collection Time: 2.27482
Timestep Consumption Time: 2.47508
PPO Batch Consumption Time: 0.29016
Total Iteration Time: 4.74990

Cumulative Model Updates: 264,284
Cumulative Timesteps: 2,204,680,510

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2204680510...
Checkpoint 2204680510 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 112,194.99851
Policy Entropy: 2.75024
Value Function Loss: 0.01127

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.07124
Policy Update Magnitude: 0.32278
Value Function Update Magnitude: 0.33756

Collected Steps per Second: 21,834.50812
Overall Steps per Second: 10,601.43149

Timestep Collection Time: 2.29096
Timestep Consumption Time: 2.42746
PPO Batch Consumption Time: 0.27852
Total Iteration Time: 4.71842

Cumulative Model Updates: 264,290
Cumulative Timesteps: 2,204,730,532

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 137,884.52164
Policy Entropy: 2.77851
Value Function Loss: 0.01038

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.06594
Policy Update Magnitude: 0.30676
Value Function Update Magnitude: 0.33827

Collected Steps per Second: 22,393.60831
Overall Steps per Second: 10,542.41801

Timestep Collection Time: 2.23305
Timestep Consumption Time: 2.51027
PPO Batch Consumption Time: 0.29340
Total Iteration Time: 4.74331

Cumulative Model Updates: 264,296
Cumulative Timesteps: 2,204,780,538

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2204780538...
Checkpoint 2204780538 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 137,884.52164
Policy Entropy: 2.78131
Value Function Loss: 0.01004

Mean KL Divergence: 0.00694
SB3 Clip Fraction: 0.06014
Policy Update Magnitude: 0.30160
Value Function Update Magnitude: 0.32952

Collected Steps per Second: 21,944.16358
Overall Steps per Second: 10,658.81041

Timestep Collection Time: 2.27970
Timestep Consumption Time: 2.41370
PPO Batch Consumption Time: 0.27613
Total Iteration Time: 4.69339

Cumulative Model Updates: 264,302
Cumulative Timesteps: 2,204,830,564

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 94,844.95248
Policy Entropy: 2.78845
Value Function Loss: 0.01044

Mean KL Divergence: 0.00641
SB3 Clip Fraction: 0.05867
Policy Update Magnitude: 0.29622
Value Function Update Magnitude: 0.30328

Collected Steps per Second: 21,779.57684
Overall Steps per Second: 10,456.64442

Timestep Collection Time: 2.29757
Timestep Consumption Time: 2.48791
PPO Batch Consumption Time: 0.29149
Total Iteration Time: 4.78547

Cumulative Model Updates: 264,308
Cumulative Timesteps: 2,204,880,604

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 2204880604...
Checkpoint 2204880604 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 94,844.95248
Policy Entropy: 2.76045
Value Function Loss: 0.01113

Mean KL Divergence: 0.00634
SB3 Clip Fraction: 0.06186
Policy Update Magnitude: 0.29938
Value Function Update Magnitude: 0.28207

Collected Steps per Second: 20,852.68191
Overall Steps per Second: 10,207.76942

Timestep Collection Time: 2.39854
Timestep Consumption Time: 2.50126
PPO Batch Consumption Time: 0.29303
Total Iteration Time: 4.89980

Cumulative Model Updates: 264,314
Cumulative Timesteps: 2,204,930,620

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 103,738.99890
Policy Entropy: 2.75872
Value Function Loss: 0.01121

Mean KL Divergence: 0.00556
SB3 Clip Fraction: 0.05324
Policy Update Magnitude: 0.30168
Value Function Update Magnitude: 0.27457

Collected Steps per Second: 21,949.37262
Overall Steps per Second: 10,504.49635

Timestep Collection Time: 2.27925
Timestep Consumption Time: 2.48329
PPO Batch Consumption Time: 0.29230
Total Iteration Time: 4.76253

Cumulative Model Updates: 264,320
Cumulative Timesteps: 2,204,980,648

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2204980648...
Checkpoint 2204980648 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 95,390.34045
Policy Entropy: 2.75279
Value Function Loss: 0.00975

Mean KL Divergence: 0.00659
SB3 Clip Fraction: 0.06206
Policy Update Magnitude: 0.29275
Value Function Update Magnitude: 0.26419

Collected Steps per Second: 21,056.50994
Overall Steps per Second: 10,561.78200

Timestep Collection Time: 2.37485
Timestep Consumption Time: 2.35977
PPO Batch Consumption Time: 0.27727
Total Iteration Time: 4.73462

Cumulative Model Updates: 264,326
Cumulative Timesteps: 2,205,030,654

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95,390.34045
Policy Entropy: 2.80771
Value Function Loss: 0.00792

Mean KL Divergence: 0.00624
SB3 Clip Fraction: 0.06010
Policy Update Magnitude: 0.26783
Value Function Update Magnitude: 0.24649

Collected Steps per Second: 21,011.99733
Overall Steps per Second: 10,424.09419

Timestep Collection Time: 2.37969
Timestep Consumption Time: 2.41708
PPO Batch Consumption Time: 0.28408
Total Iteration Time: 4.79677

Cumulative Model Updates: 264,332
Cumulative Timesteps: 2,205,080,656

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2205080656...
Checkpoint 2205080656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 95,390.34045
Policy Entropy: 2.79287
Value Function Loss: 0.00728

Mean KL Divergence: 0.00579
SB3 Clip Fraction: 0.05588
Policy Update Magnitude: 0.25715
Value Function Update Magnitude: 0.21322

Collected Steps per Second: 20,907.82720
Overall Steps per Second: 10,554.37953

Timestep Collection Time: 2.39346
Timestep Consumption Time: 2.34789
PPO Batch Consumption Time: 0.27765
Total Iteration Time: 4.74135

Cumulative Model Updates: 264,338
Cumulative Timesteps: 2,205,130,698

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 115,345.74722
Policy Entropy: 2.79161
Value Function Loss: 0.00772

Mean KL Divergence: 0.00677
SB3 Clip Fraction: 0.06629
Policy Update Magnitude: 0.26163
Value Function Update Magnitude: 0.20823

Collected Steps per Second: 21,618.84413
Overall Steps per Second: 10,498.20425

Timestep Collection Time: 2.31280
Timestep Consumption Time: 2.44992
PPO Batch Consumption Time: 0.28534
Total Iteration Time: 4.76272

Cumulative Model Updates: 264,344
Cumulative Timesteps: 2,205,180,698

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2205180698...
Checkpoint 2205180698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 164,499.87062
Policy Entropy: 2.76724
Value Function Loss: 0.00979

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.07729
Policy Update Magnitude: 0.27936
Value Function Update Magnitude: 0.25399

Collected Steps per Second: 22,115.96842
Overall Steps per Second: 10,748.92498

Timestep Collection Time: 2.26253
Timestep Consumption Time: 2.39264
PPO Batch Consumption Time: 0.27692
Total Iteration Time: 4.65516

Cumulative Model Updates: 264,350
Cumulative Timesteps: 2,205,230,736

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 141,506.28110
Policy Entropy: 2.79383
Value Function Loss: 0.00976

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.07907
Policy Update Magnitude: 0.28462
Value Function Update Magnitude: 0.25895

Collected Steps per Second: 22,335.18634
Overall Steps per Second: 10,776.06036

Timestep Collection Time: 2.23916
Timestep Consumption Time: 2.40187
PPO Batch Consumption Time: 0.27773
Total Iteration Time: 4.64103

Cumulative Model Updates: 264,356
Cumulative Timesteps: 2,205,280,748

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2205280748...
Checkpoint 2205280748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 97,692.22908
Policy Entropy: 2.80800
Value Function Loss: 0.01006

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.07739
Policy Update Magnitude: 0.27703
Value Function Update Magnitude: 0.26380

Collected Steps per Second: 21,987.91236
Overall Steps per Second: 10,624.95513

Timestep Collection Time: 2.27416
Timestep Consumption Time: 2.43212
PPO Batch Consumption Time: 0.27829
Total Iteration Time: 4.70628

Cumulative Model Updates: 264,362
Cumulative Timesteps: 2,205,330,752

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 117,036.24881
Policy Entropy: 2.80307
Value Function Loss: 0.01121

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.07442
Policy Update Magnitude: 0.27847
Value Function Update Magnitude: 0.27025

Collected Steps per Second: 21,621.14767
Overall Steps per Second: 10,538.68378

Timestep Collection Time: 2.31292
Timestep Consumption Time: 2.43226
PPO Batch Consumption Time: 0.27801
Total Iteration Time: 4.74518

Cumulative Model Updates: 264,368
Cumulative Timesteps: 2,205,380,760

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2205380760...
Checkpoint 2205380760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 108,412.27788
Policy Entropy: 2.80885
Value Function Loss: 0.01067

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.07491
Policy Update Magnitude: 0.28293
Value Function Update Magnitude: 0.24124

Collected Steps per Second: 21,429.22711
Overall Steps per Second: 10,519.25804

Timestep Collection Time: 2.33345
Timestep Consumption Time: 2.42012
PPO Batch Consumption Time: 0.27834
Total Iteration Time: 4.75357

Cumulative Model Updates: 264,374
Cumulative Timesteps: 2,205,430,764

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95,954.43213
Policy Entropy: 2.80152
Value Function Loss: 0.01299

Mean KL Divergence: 0.00740
SB3 Clip Fraction: 0.07171
Policy Update Magnitude: 0.29226
Value Function Update Magnitude: 0.23155

Collected Steps per Second: 21,501.45462
Overall Steps per Second: 10,508.76447

Timestep Collection Time: 2.32617
Timestep Consumption Time: 2.43329
PPO Batch Consumption Time: 0.27852
Total Iteration Time: 4.75946

Cumulative Model Updates: 264,380
Cumulative Timesteps: 2,205,480,780

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2205480780...
Checkpoint 2205480780 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 135,184.01472
Policy Entropy: 2.78985
Value Function Loss: 0.01361

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.07711
Policy Update Magnitude: 0.29966
Value Function Update Magnitude: 0.25934

Collected Steps per Second: 21,099.51970
Overall Steps per Second: 10,219.76583

Timestep Collection Time: 2.37048
Timestep Consumption Time: 2.52357
PPO Batch Consumption Time: 0.29195
Total Iteration Time: 4.89405

Cumulative Model Updates: 264,386
Cumulative Timesteps: 2,205,530,796

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 108,071.01819
Policy Entropy: 2.76763
Value Function Loss: 0.01300

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.07442
Policy Update Magnitude: 0.30696
Value Function Update Magnitude: 0.29580

Collected Steps per Second: 22,155.93342
Overall Steps per Second: 10,453.85318

Timestep Collection Time: 2.25827
Timestep Consumption Time: 2.52791
PPO Batch Consumption Time: 0.28632
Total Iteration Time: 4.78618

Cumulative Model Updates: 264,392
Cumulative Timesteps: 2,205,580,830

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 2205580830...
Checkpoint 2205580830 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 80,707.42126
Policy Entropy: 2.77363
Value Function Loss: 0.01062

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.07902
Policy Update Magnitude: 0.29772
Value Function Update Magnitude: 0.30726

Collected Steps per Second: 22,077.86915
Overall Steps per Second: 10,619.09705

Timestep Collection Time: 2.26480
Timestep Consumption Time: 2.44388
PPO Batch Consumption Time: 0.27914
Total Iteration Time: 4.70869

Cumulative Model Updates: 264,398
Cumulative Timesteps: 2,205,630,832

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 96,656.02476
Policy Entropy: 2.78629
Value Function Loss: 0.00882

Mean KL Divergence: 0.00766
SB3 Clip Fraction: 0.07152
Policy Update Magnitude: 0.28286
Value Function Update Magnitude: 0.27722

Collected Steps per Second: 22,192.15199
Overall Steps per Second: 10,469.39445

Timestep Collection Time: 2.25413
Timestep Consumption Time: 2.52399
PPO Batch Consumption Time: 0.29233
Total Iteration Time: 4.77812

Cumulative Model Updates: 264,404
Cumulative Timesteps: 2,205,680,856

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2205680856...
Checkpoint 2205680856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 70,203.64976
Policy Entropy: 2.78578
Value Function Loss: 0.00950

Mean KL Divergence: 0.00622
SB3 Clip Fraction: 0.06056
Policy Update Magnitude: 0.27531
Value Function Update Magnitude: 0.24484

Collected Steps per Second: 21,640.37130
Overall Steps per Second: 10,580.67668

Timestep Collection Time: 2.31096
Timestep Consumption Time: 2.41558
PPO Batch Consumption Time: 0.27825
Total Iteration Time: 4.72654

Cumulative Model Updates: 264,410
Cumulative Timesteps: 2,205,730,866

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 64,619.64503
Policy Entropy: 2.79976
Value Function Loss: 0.01045

Mean KL Divergence: 0.00601
SB3 Clip Fraction: 0.05738
Policy Update Magnitude: 0.27934
Value Function Update Magnitude: 0.24429

Collected Steps per Second: 22,064.66606
Overall Steps per Second: 10,502.32349

Timestep Collection Time: 2.26697
Timestep Consumption Time: 2.49578
PPO Batch Consumption Time: 0.29003
Total Iteration Time: 4.76276

Cumulative Model Updates: 264,416
Cumulative Timesteps: 2,205,780,886

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2205780886...
Checkpoint 2205780886 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 69,925.33120
Policy Entropy: 2.78717
Value Function Loss: 0.01191

Mean KL Divergence: 0.00564
SB3 Clip Fraction: 0.05280
Policy Update Magnitude: 0.29023
Value Function Update Magnitude: 0.24736

Collected Steps per Second: 21,922.15618
Overall Steps per Second: 10,624.19120

Timestep Collection Time: 2.28153
Timestep Consumption Time: 2.42622
PPO Batch Consumption Time: 0.27862
Total Iteration Time: 4.70775

Cumulative Model Updates: 264,422
Cumulative Timesteps: 2,205,830,902

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 115,830.44400
Policy Entropy: 2.79616
Value Function Loss: 0.01187

Mean KL Divergence: 0.00575
SB3 Clip Fraction: 0.05256
Policy Update Magnitude: 0.30829
Value Function Update Magnitude: 0.26163

Collected Steps per Second: 21,945.97215
Overall Steps per Second: 10,493.08190

Timestep Collection Time: 2.27887
Timestep Consumption Time: 2.48732
PPO Batch Consumption Time: 0.28963
Total Iteration Time: 4.76619

Cumulative Model Updates: 264,428
Cumulative Timesteps: 2,205,880,914

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2205880914...
Checkpoint 2205880914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 159,624.25250
Policy Entropy: 2.77382
Value Function Loss: 0.01189

Mean KL Divergence: 0.00669
SB3 Clip Fraction: 0.06012
Policy Update Magnitude: 0.30316
Value Function Update Magnitude: 0.31562

Collected Steps per Second: 21,575.12289
Overall Steps per Second: 10,384.02236

Timestep Collection Time: 2.31785
Timestep Consumption Time: 2.49801
PPO Batch Consumption Time: 0.29016
Total Iteration Time: 4.81586

Cumulative Model Updates: 264,434
Cumulative Timesteps: 2,205,930,922

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 139,275.60647
Policy Entropy: 2.76592
Value Function Loss: 0.01151

Mean KL Divergence: 0.00715
SB3 Clip Fraction: 0.06226
Policy Update Magnitude: 0.29689
Value Function Update Magnitude: 0.31636

Collected Steps per Second: 21,583.12759
Overall Steps per Second: 10,353.63417

Timestep Collection Time: 2.31662
Timestep Consumption Time: 2.51260
PPO Batch Consumption Time: 0.29359
Total Iteration Time: 4.82922

Cumulative Model Updates: 264,440
Cumulative Timesteps: 2,205,980,922

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2205980922...
Checkpoint 2205980922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 85,112.21892
Policy Entropy: 2.75373
Value Function Loss: 0.01324

Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.07588
Policy Update Magnitude: 0.30225
Value Function Update Magnitude: 0.25828

Collected Steps per Second: 21,200.91405
Overall Steps per Second: 10,303.11341

Timestep Collection Time: 2.36056
Timestep Consumption Time: 2.49681
PPO Batch Consumption Time: 0.29016
Total Iteration Time: 4.85737

Cumulative Model Updates: 264,446
Cumulative Timesteps: 2,206,030,968

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 71,946.47628
Policy Entropy: 2.78949
Value Function Loss: 0.01396

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.07986
Policy Update Magnitude: 0.30367
Value Function Update Magnitude: 0.24135

Collected Steps per Second: 22,279.42558
Overall Steps per Second: 10,657.55144

Timestep Collection Time: 2.24431
Timestep Consumption Time: 2.44738
PPO Batch Consumption Time: 0.27801
Total Iteration Time: 4.69170

Cumulative Model Updates: 264,452
Cumulative Timesteps: 2,206,080,970

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2206080970...
Checkpoint 2206080970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 105,729.21910
Policy Entropy: 2.79986
Value Function Loss: 0.01357

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.08976
Policy Update Magnitude: 0.30261
Value Function Update Magnitude: 0.26098

Collected Steps per Second: 21,849.60402
Overall Steps per Second: 10,605.55465

Timestep Collection Time: 2.28892
Timestep Consumption Time: 2.42672
PPO Batch Consumption Time: 0.27866
Total Iteration Time: 4.71564

Cumulative Model Updates: 264,458
Cumulative Timesteps: 2,206,130,982

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 131,462.98114
Policy Entropy: 2.80560
Value Function Loss: 0.01270

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.08007
Policy Update Magnitude: 0.29472
Value Function Update Magnitude: 0.25236

Collected Steps per Second: 22,101.34727
Overall Steps per Second: 10,545.82923

Timestep Collection Time: 2.26258
Timestep Consumption Time: 2.47920
PPO Batch Consumption Time: 0.28603
Total Iteration Time: 4.74178

Cumulative Model Updates: 264,464
Cumulative Timesteps: 2,206,180,988

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2206180988...
Checkpoint 2206180988 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 112,485.05653
Policy Entropy: 2.78177
Value Function Loss: 0.01271

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.07180
Policy Update Magnitude: 0.29608
Value Function Update Magnitude: 0.24413

Collected Steps per Second: 21,878.51156
Overall Steps per Second: 10,578.74509

Timestep Collection Time: 2.28718
Timestep Consumption Time: 2.44306
PPO Batch Consumption Time: 0.27867
Total Iteration Time: 4.73024

Cumulative Model Updates: 264,470
Cumulative Timesteps: 2,206,231,028

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 103,644.31190
Policy Entropy: 2.75689
Value Function Loss: 0.01342

Mean KL Divergence: 0.00698
SB3 Clip Fraction: 0.06275
Policy Update Magnitude: 0.31016
Value Function Update Magnitude: 0.26087

Collected Steps per Second: 22,271.64155
Overall Steps per Second: 10,534.06554

Timestep Collection Time: 2.24635
Timestep Consumption Time: 2.50300
PPO Batch Consumption Time: 0.29342
Total Iteration Time: 4.74935

Cumulative Model Updates: 264,476
Cumulative Timesteps: 2,206,281,058

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2206281058...
Checkpoint 2206281058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 56,434.09313
Policy Entropy: 2.75804
Value Function Loss: 0.01435

Mean KL Divergence: 0.00735
SB3 Clip Fraction: 0.06824
Policy Update Magnitude: 0.32560
Value Function Update Magnitude: 0.27745

Collected Steps per Second: 21,599.77354
Overall Steps per Second: 10,557.78808

Timestep Collection Time: 2.31604
Timestep Consumption Time: 2.42226
PPO Batch Consumption Time: 0.27909
Total Iteration Time: 4.73830

Cumulative Model Updates: 264,482
Cumulative Timesteps: 2,206,331,084

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52,770.44300
Policy Entropy: 2.75284
Value Function Loss: 0.01316

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.07414
Policy Update Magnitude: 0.32031
Value Function Update Magnitude: 0.29501

Collected Steps per Second: 21,734.28747
Overall Steps per Second: 10,581.72056

Timestep Collection Time: 2.30051
Timestep Consumption Time: 2.42462
PPO Batch Consumption Time: 0.27706
Total Iteration Time: 4.72513

Cumulative Model Updates: 264,488
Cumulative Timesteps: 2,206,381,084

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2206381084...
Checkpoint 2206381084 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 62,694.95792
Policy Entropy: 2.75875
Value Function Loss: 0.01193

Mean KL Divergence: 0.00680
SB3 Clip Fraction: 0.06575
Policy Update Magnitude: 0.31332
Value Function Update Magnitude: 0.29253

Collected Steps per Second: 21,515.43068
Overall Steps per Second: 10,513.69182

Timestep Collection Time: 2.32521
Timestep Consumption Time: 2.43315
PPO Batch Consumption Time: 0.27793
Total Iteration Time: 4.75837

Cumulative Model Updates: 264,494
Cumulative Timesteps: 2,206,431,112

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89,222.20663
Policy Entropy: 2.74599
Value Function Loss: 0.01235

Mean KL Divergence: 0.00667
SB3 Clip Fraction: 0.06467
Policy Update Magnitude: 0.31595
Value Function Update Magnitude: 0.28332

Collected Steps per Second: 21,262.67026
Overall Steps per Second: 10,509.94857

Timestep Collection Time: 2.35173
Timestep Consumption Time: 2.40605
PPO Batch Consumption Time: 0.28631
Total Iteration Time: 4.75778

Cumulative Model Updates: 264,500
Cumulative Timesteps: 2,206,481,116

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2206481116...
Checkpoint 2206481116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 129,868.96623
Policy Entropy: 2.77657
Value Function Loss: 0.01253

Mean KL Divergence: 0.00699
SB3 Clip Fraction: 0.06586
Policy Update Magnitude: 0.31437
Value Function Update Magnitude: 0.30369

Collected Steps per Second: 20,781.15653
Overall Steps per Second: 10,295.01724

Timestep Collection Time: 2.40612
Timestep Consumption Time: 2.45079
PPO Batch Consumption Time: 0.29363
Total Iteration Time: 4.85691

Cumulative Model Updates: 264,506
Cumulative Timesteps: 2,206,531,118

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 142,722.21139
Policy Entropy: 2.77357
Value Function Loss: 0.01378

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.07027
Policy Update Magnitude: 0.31955
Value Function Update Magnitude: 0.31539

Collected Steps per Second: 21,500.42563
Overall Steps per Second: 10,526.53628

Timestep Collection Time: 2.32572
Timestep Consumption Time: 2.42456
PPO Batch Consumption Time: 0.28937
Total Iteration Time: 4.75028

Cumulative Model Updates: 264,512
Cumulative Timesteps: 2,206,581,122

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2206581122...
Checkpoint 2206581122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 108,620.61643
Policy Entropy: 2.76581
Value Function Loss: 0.01302

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.08067
Policy Update Magnitude: 0.32069
Value Function Update Magnitude: 0.33307

Collected Steps per Second: 21,297.93419
Overall Steps per Second: 10,506.70928

Timestep Collection Time: 2.34877
Timestep Consumption Time: 2.41238
PPO Batch Consumption Time: 0.27685
Total Iteration Time: 4.76115

Cumulative Model Updates: 264,518
Cumulative Timesteps: 2,206,631,146

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92,635.04010
Policy Entropy: 2.74419
Value Function Loss: 0.01244

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.08444
Policy Update Magnitude: 0.31650
Value Function Update Magnitude: 0.33185

Collected Steps per Second: 21,916.51516
Overall Steps per Second: 10,513.80574

Timestep Collection Time: 2.28321
Timestep Consumption Time: 2.47625
PPO Batch Consumption Time: 0.29332
Total Iteration Time: 4.75946

Cumulative Model Updates: 264,524
Cumulative Timesteps: 2,206,681,186

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 2206681186...
Checkpoint 2206681186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 71,285.95610
Policy Entropy: 2.76700
Value Function Loss: 0.01269

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.08084
Policy Update Magnitude: 0.31351
Value Function Update Magnitude: 0.31557

Collected Steps per Second: 21,975.56748
Overall Steps per Second: 10,545.54954

Timestep Collection Time: 2.27525
Timestep Consumption Time: 2.46608
PPO Batch Consumption Time: 0.28977
Total Iteration Time: 4.74134

Cumulative Model Updates: 264,530
Cumulative Timesteps: 2,206,731,186

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65,419.54560
Policy Entropy: 2.81100
Value Function Loss: 0.01240

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.08643
Policy Update Magnitude: 0.30068
Value Function Update Magnitude: 0.28686

Collected Steps per Second: 22,107.30079
Overall Steps per Second: 10,492.50647

Timestep Collection Time: 2.26305
Timestep Consumption Time: 2.50511
PPO Batch Consumption Time: 0.29283
Total Iteration Time: 4.76816

Cumulative Model Updates: 264,536
Cumulative Timesteps: 2,206,781,216

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2206781216...
Checkpoint 2206781216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 88,231.72994
Policy Entropy: 2.80901
Value Function Loss: 0.01369

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.07547
Policy Update Magnitude: 0.29056
Value Function Update Magnitude: 0.27672

Collected Steps per Second: 21,671.40963
Overall Steps per Second: 10,553.42954

Timestep Collection Time: 2.30756
Timestep Consumption Time: 2.43100
PPO Batch Consumption Time: 0.27796
Total Iteration Time: 4.73855

Cumulative Model Updates: 264,542
Cumulative Timesteps: 2,206,831,224

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 157,471.13562
Policy Entropy: 2.80058
Value Function Loss: 0.01440

Mean KL Divergence: 0.00702
SB3 Clip Fraction: 0.06719
Policy Update Magnitude: 0.30794
Value Function Update Magnitude: 0.28617

Collected Steps per Second: 22,068.31835
Overall Steps per Second: 10,494.67500

Timestep Collection Time: 2.26687
Timestep Consumption Time: 2.49993
PPO Batch Consumption Time: 0.29045
Total Iteration Time: 4.76680

Cumulative Model Updates: 264,548
Cumulative Timesteps: 2,206,881,250

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2206881250...
Checkpoint 2206881250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 129,632.10317
Policy Entropy: 2.80901
Value Function Loss: 0.01312

Mean KL Divergence: 0.00772
SB3 Clip Fraction: 0.07293
Policy Update Magnitude: 0.30814
Value Function Update Magnitude: 0.29049

Collected Steps per Second: 21,277.72885
Overall Steps per Second: 10,263.71586

Timestep Collection Time: 2.35091
Timestep Consumption Time: 2.52276
PPO Batch Consumption Time: 0.29240
Total Iteration Time: 4.87367

Cumulative Model Updates: 264,554
Cumulative Timesteps: 2,206,931,272

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80,496.50468
Policy Entropy: 2.81582
Value Function Loss: 0.01470

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.08331
Policy Update Magnitude: 0.30809
Value Function Update Magnitude: 0.30909

Collected Steps per Second: 21,323.56930
Overall Steps per Second: 10,366.85415

Timestep Collection Time: 2.34482
Timestep Consumption Time: 2.47824
PPO Batch Consumption Time: 0.28573
Total Iteration Time: 4.82306

Cumulative Model Updates: 264,560
Cumulative Timesteps: 2,206,981,272

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2206981272...
Checkpoint 2206981272 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 63,392.38555
Policy Entropy: 2.80951
Value Function Loss: 0.01460

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.08515
Policy Update Magnitude: 0.31640
Value Function Update Magnitude: 0.33687

Collected Steps per Second: 21,596.17628
Overall Steps per Second: 10,403.17404

Timestep Collection Time: 2.31661
Timestep Consumption Time: 2.49250
PPO Batch Consumption Time: 0.29008
Total Iteration Time: 4.80911

Cumulative Model Updates: 264,566
Cumulative Timesteps: 2,207,031,302

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81,547.83811
Policy Entropy: 2.78953
Value Function Loss: 0.01488

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.08182
Policy Update Magnitude: 0.32006
Value Function Update Magnitude: 0.34922

Collected Steps per Second: 22,421.05143
Overall Steps per Second: 10,628.30140

Timestep Collection Time: 2.23156
Timestep Consumption Time: 2.47606
PPO Batch Consumption Time: 0.28076
Total Iteration Time: 4.70762

Cumulative Model Updates: 264,572
Cumulative Timesteps: 2,207,081,336

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 2207081336...
Checkpoint 2207081336 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40,883.94578
Policy Entropy: 2.79121
Value Function Loss: 0.01423

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.06982
Policy Update Magnitude: 0.32348
Value Function Update Magnitude: 0.37318

Collected Steps per Second: 21,760.58587
Overall Steps per Second: 10,407.22270

Timestep Collection Time: 2.29819
Timestep Consumption Time: 2.50712
PPO Batch Consumption Time: 0.28922
Total Iteration Time: 4.80532

Cumulative Model Updates: 264,578
Cumulative Timesteps: 2,207,131,346

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49,651.68192
Policy Entropy: 2.78868
Value Function Loss: 0.01391

Mean KL Divergence: 0.00766
SB3 Clip Fraction: 0.07222
Policy Update Magnitude: 0.33019
Value Function Update Magnitude: 0.39421

Collected Steps per Second: 22,160.42478
Overall Steps per Second: 10,685.45226

Timestep Collection Time: 2.25727
Timestep Consumption Time: 2.42405
PPO Batch Consumption Time: 0.27929
Total Iteration Time: 4.68132

Cumulative Model Updates: 264,584
Cumulative Timesteps: 2,207,181,368

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2207181368...
Checkpoint 2207181368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 59,826.90975
Policy Entropy: 2.77974
Value Function Loss: 0.01253

Mean KL Divergence: 0.00782
SB3 Clip Fraction: 0.06773
Policy Update Magnitude: 0.32144
Value Function Update Magnitude: 0.40094

Collected Steps per Second: 22,083.45427
Overall Steps per Second: 10,667.11798

Timestep Collection Time: 2.26504
Timestep Consumption Time: 2.42413
PPO Batch Consumption Time: 0.27859
Total Iteration Time: 4.68918

Cumulative Model Updates: 264,590
Cumulative Timesteps: 2,207,231,388

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65,423.22275
Policy Entropy: 2.79632
Value Function Loss: 0.01140

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.06757
Policy Update Magnitude: 0.30887
Value Function Update Magnitude: 0.36321

Collected Steps per Second: 22,405.18983
Overall Steps per Second: 10,585.01475

Timestep Collection Time: 2.23243
Timestep Consumption Time: 2.49293
PPO Batch Consumption Time: 0.29276
Total Iteration Time: 4.72536

Cumulative Model Updates: 264,596
Cumulative Timesteps: 2,207,281,406

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2207281406...
Checkpoint 2207281406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,133.90249
Policy Entropy: 2.80106
Value Function Loss: 0.01172

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.07359
Policy Update Magnitude: 0.29603
Value Function Update Magnitude: 0.29156

Collected Steps per Second: 21,213.72812
Overall Steps per Second: 10,575.94601

Timestep Collection Time: 2.35744
Timestep Consumption Time: 2.37122
PPO Batch Consumption Time: 0.28262
Total Iteration Time: 4.72866

Cumulative Model Updates: 264,602
Cumulative Timesteps: 2,207,331,416

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 71,604.61342
Policy Entropy: 2.77840
Value Function Loss: 0.01320

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.07691
Policy Update Magnitude: 0.30502
Value Function Update Magnitude: 0.28115

Collected Steps per Second: 21,230.43117
Overall Steps per Second: 10,454.23282

Timestep Collection Time: 2.35586
Timestep Consumption Time: 2.42842
PPO Batch Consumption Time: 0.29337
Total Iteration Time: 4.78428

Cumulative Model Updates: 264,608
Cumulative Timesteps: 2,207,381,432

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2207381432...
Checkpoint 2207381432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 69,474.49648
Policy Entropy: 2.76992
Value Function Loss: 0.01395

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.07432
Policy Update Magnitude: 0.31921
Value Function Update Magnitude: 0.31876

Collected Steps per Second: 20,988.53833
Overall Steps per Second: 10,558.24526

Timestep Collection Time: 2.38225
Timestep Consumption Time: 2.35338
PPO Batch Consumption Time: 0.27755
Total Iteration Time: 4.73564

Cumulative Model Updates: 264,614
Cumulative Timesteps: 2,207,431,432

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62,274.06835
Policy Entropy: 2.76676
Value Function Loss: 0.01337

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.07885
Policy Update Magnitude: 0.31742
Value Function Update Magnitude: 0.29227

Collected Steps per Second: 21,187.08147
Overall Steps per Second: 10,478.07341

Timestep Collection Time: 2.36068
Timestep Consumption Time: 2.41271
PPO Batch Consumption Time: 0.27849
Total Iteration Time: 4.77340

Cumulative Model Updates: 264,620
Cumulative Timesteps: 2,207,481,448

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2207481448...
Checkpoint 2207481448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 106,213.04920
Policy Entropy: 2.77795
Value Function Loss: 0.01260

Mean KL Divergence: 0.00593
SB3 Clip Fraction: 0.05761
Policy Update Magnitude: 0.31410
Value Function Update Magnitude: 0.25552

Collected Steps per Second: 21,169.86282
Overall Steps per Second: 10,303.90356

Timestep Collection Time: 2.36289
Timestep Consumption Time: 2.49178
PPO Batch Consumption Time: 0.29333
Total Iteration Time: 4.85466

Cumulative Model Updates: 264,626
Cumulative Timesteps: 2,207,531,470

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 117,153.14588
Policy Entropy: 2.77137
Value Function Loss: 0.01191

Mean KL Divergence: 0.00569
SB3 Clip Fraction: 0.05624
Policy Update Magnitude: 0.30998
Value Function Update Magnitude: 0.23719

Collected Steps per Second: 22,277.50046
Overall Steps per Second: 10,569.25112

Timestep Collection Time: 2.24621
Timestep Consumption Time: 2.48828
PPO Batch Consumption Time: 0.29003
Total Iteration Time: 4.73449

Cumulative Model Updates: 264,632
Cumulative Timesteps: 2,207,581,510

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 2207581510...
Checkpoint 2207581510 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 81,984.56241
Policy Entropy: 2.78331
Value Function Loss: 0.01233

Mean KL Divergence: 0.00614
SB3 Clip Fraction: 0.05873
Policy Update Magnitude: 0.31082
Value Function Update Magnitude: 0.27156

Collected Steps per Second: 21,598.84757
Overall Steps per Second: 10,710.61597

Timestep Collection Time: 2.31586
Timestep Consumption Time: 2.35427
PPO Batch Consumption Time: 0.27798
Total Iteration Time: 4.67013

Cumulative Model Updates: 264,638
Cumulative Timesteps: 2,207,631,530

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68,698.15534
Policy Entropy: 2.78805
Value Function Loss: 0.01203

Mean KL Divergence: 0.00636
SB3 Clip Fraction: 0.05803
Policy Update Magnitude: 0.30983
Value Function Update Magnitude: 0.31484

Collected Steps per Second: 22,010.52015
Overall Steps per Second: 10,630.79886

Timestep Collection Time: 2.27164
Timestep Consumption Time: 2.43167
PPO Batch Consumption Time: 0.27902
Total Iteration Time: 4.70332

Cumulative Model Updates: 264,644
Cumulative Timesteps: 2,207,681,530

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2207681530...
Checkpoint 2207681530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 63,289.06563
Policy Entropy: 2.74606
Value Function Loss: 0.01281

Mean KL Divergence: 0.00728
SB3 Clip Fraction: 0.06610
Policy Update Magnitude: 0.32006
Value Function Update Magnitude: 0.33044

Collected Steps per Second: 21,980.63422
Overall Steps per Second: 10,602.41796

Timestep Collection Time: 2.27500
Timestep Consumption Time: 2.44147
PPO Batch Consumption Time: 0.27854
Total Iteration Time: 4.71647

Cumulative Model Updates: 264,650
Cumulative Timesteps: 2,207,731,536

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70,225.81053
Policy Entropy: 2.73865
Value Function Loss: 0.01261

Mean KL Divergence: 0.00743
SB3 Clip Fraction: 0.06974
Policy Update Magnitude: 0.31924
Value Function Update Magnitude: 0.32180

Collected Steps per Second: 22,207.63127
Overall Steps per Second: 10,503.92612

Timestep Collection Time: 2.25193
Timestep Consumption Time: 2.50915
PPO Batch Consumption Time: 0.29365
Total Iteration Time: 4.76108

Cumulative Model Updates: 264,656
Cumulative Timesteps: 2,207,781,546

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2207781546...
Checkpoint 2207781546 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 112,757.80376
Policy Entropy: 2.72959
Value Function Loss: 0.01230

Mean KL Divergence: 0.00711
SB3 Clip Fraction: 0.06470
Policy Update Magnitude: 0.31069
Value Function Update Magnitude: 0.30143

Collected Steps per Second: 21,951.10222
Overall Steps per Second: 10,618.65927

Timestep Collection Time: 2.27897
Timestep Consumption Time: 2.43217
PPO Batch Consumption Time: 0.27863
Total Iteration Time: 4.71114

Cumulative Model Updates: 264,662
Cumulative Timesteps: 2,207,831,572

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66,524.53906
Policy Entropy: 2.74357
Value Function Loss: 0.01222

Mean KL Divergence: 0.00640
SB3 Clip Fraction: 0.05750
Policy Update Magnitude: 0.30656
Value Function Update Magnitude: 0.29100

Collected Steps per Second: 21,406.20862
Overall Steps per Second: 10,474.53625

Timestep Collection Time: 2.33596
Timestep Consumption Time: 2.43791
PPO Batch Consumption Time: 0.27819
Total Iteration Time: 4.77386

Cumulative Model Updates: 264,668
Cumulative Timesteps: 2,207,881,576

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2207881576...
Checkpoint 2207881576 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 61,612.44458
Policy Entropy: 2.73857
Value Function Loss: 0.01221

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.07081
Policy Update Magnitude: 0.31347
Value Function Update Magnitude: 0.30290

Collected Steps per Second: 21,195.70000
Overall Steps per Second: 10,332.88556

Timestep Collection Time: 2.36020
Timestep Consumption Time: 2.48124
PPO Batch Consumption Time: 0.29218
Total Iteration Time: 4.84144

Cumulative Model Updates: 264,674
Cumulative Timesteps: 2,207,931,602

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49,257.22694
Policy Entropy: 2.73794
Value Function Loss: 0.01163

Mean KL Divergence: 0.00689
SB3 Clip Fraction: 0.06636
Policy Update Magnitude: 0.30826
Value Function Update Magnitude: 0.30485

Collected Steps per Second: 21,254.17122
Overall Steps per Second: 10,499.38492

Timestep Collection Time: 2.35267
Timestep Consumption Time: 2.40990
PPO Batch Consumption Time: 0.28939
Total Iteration Time: 4.76256

Cumulative Model Updates: 264,680
Cumulative Timesteps: 2,207,981,606

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2207981606...
Checkpoint 2207981606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 80,569.23962
Policy Entropy: 2.74143
Value Function Loss: 0.01288

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.07481
Policy Update Magnitude: 0.31358
Value Function Update Magnitude: 0.32267

Collected Steps per Second: 21,047.41088
Overall Steps per Second: 10,436.62569

Timestep Collection Time: 2.37597
Timestep Consumption Time: 2.41562
PPO Batch Consumption Time: 0.28793
Total Iteration Time: 4.79159

Cumulative Model Updates: 264,686
Cumulative Timesteps: 2,208,031,614

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93,176.07405
Policy Entropy: 2.75098
Value Function Loss: 0.01308

Mean KL Divergence: 0.00690
SB3 Clip Fraction: 0.06629
Policy Update Magnitude: 0.31441
Value Function Update Magnitude: 0.34009

Collected Steps per Second: 21,257.28934
Overall Steps per Second: 10,461.32029

Timestep Collection Time: 2.35232
Timestep Consumption Time: 2.42757
PPO Batch Consumption Time: 0.28892
Total Iteration Time: 4.77989

Cumulative Model Updates: 264,692
Cumulative Timesteps: 2,208,081,618

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2208081618...
Checkpoint 2208081618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 57,288.92633
Policy Entropy: 2.75034
Value Function Loss: 0.01415

Mean KL Divergence: 0.00639
SB3 Clip Fraction: 0.06134
Policy Update Magnitude: 0.31319
Value Function Update Magnitude: 0.35632

Collected Steps per Second: 21,261.19946
Overall Steps per Second: 10,292.31644

Timestep Collection Time: 2.35274
Timestep Consumption Time: 2.50739
PPO Batch Consumption Time: 0.29329
Total Iteration Time: 4.86013

Cumulative Model Updates: 264,698
Cumulative Timesteps: 2,208,131,640

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57,288.92633
Policy Entropy: 2.74122
Value Function Loss: 0.01259

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.08336
Policy Update Magnitude: 0.31887
Value Function Update Magnitude: 0.35440

Collected Steps per Second: 22,289.90839
Overall Steps per Second: 10,712.64606

Timestep Collection Time: 2.24389
Timestep Consumption Time: 2.42499
PPO Batch Consumption Time: 0.27868
Total Iteration Time: 4.66887

Cumulative Model Updates: 264,704
Cumulative Timesteps: 2,208,181,656

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2208181656...
Checkpoint 2208181656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 102,065.53595
Policy Entropy: 2.74498
Value Function Loss: 0.01325

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.07418
Policy Update Magnitude: 0.31846
Value Function Update Magnitude: 0.31233

Collected Steps per Second: 21,334.07847
Overall Steps per Second: 10,358.73369

Timestep Collection Time: 2.34479
Timestep Consumption Time: 2.48437
PPO Batch Consumption Time: 0.29254
Total Iteration Time: 4.82916

Cumulative Model Updates: 264,710
Cumulative Timesteps: 2,208,231,680

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75,222.52313
Policy Entropy: 2.75071
Value Function Loss: 0.01240

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.07483
Policy Update Magnitude: 0.31290
Value Function Update Magnitude: 0.27870

Collected Steps per Second: 22,230.78970
Overall Steps per Second: 10,771.27762

Timestep Collection Time: 2.24985
Timestep Consumption Time: 2.39361
PPO Batch Consumption Time: 0.27761
Total Iteration Time: 4.64346

Cumulative Model Updates: 264,716
Cumulative Timesteps: 2,208,281,696

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2208281696...
Checkpoint 2208281696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87,111.50501
Policy Entropy: 2.76880
Value Function Loss: 0.01321

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.07315
Policy Update Magnitude: 0.31525
Value Function Update Magnitude: 0.26477

Collected Steps per Second: 22,078.05401
Overall Steps per Second: 10,669.30449

Timestep Collection Time: 2.26505
Timestep Consumption Time: 2.42204
PPO Batch Consumption Time: 0.27866
Total Iteration Time: 4.68709

Cumulative Model Updates: 264,722
Cumulative Timesteps: 2,208,331,704

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84,642.51148
Policy Entropy: 2.75656
Value Function Loss: 0.01452

Mean KL Divergence: 0.00760
SB3 Clip Fraction: 0.07090
Policy Update Magnitude: 0.32207
Value Function Update Magnitude: 0.30124

Collected Steps per Second: 22,486.86715
Overall Steps per Second: 10,574.59686

Timestep Collection Time: 2.22450
Timestep Consumption Time: 2.50589
PPO Batch Consumption Time: 0.29294
Total Iteration Time: 4.73039

Cumulative Model Updates: 264,728
Cumulative Timesteps: 2,208,381,726

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2208381726...
Checkpoint 2208381726 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 107,159.10902
Policy Entropy: 2.75780
Value Function Loss: 0.01427

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.06654
Policy Update Magnitude: 0.32952
Value Function Update Magnitude: 0.27705

Collected Steps per Second: 21,760.61668
Overall Steps per Second: 10,567.67790

Timestep Collection Time: 2.29773
Timestep Consumption Time: 2.43368
PPO Batch Consumption Time: 0.27903
Total Iteration Time: 4.73141

Cumulative Model Updates: 264,734
Cumulative Timesteps: 2,208,431,726

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76,976.50722
Policy Entropy: 2.76221
Value Function Loss: 0.01359

Mean KL Divergence: 0.00698
SB3 Clip Fraction: 0.06176
Policy Update Magnitude: 0.31584
Value Function Update Magnitude: 0.26836

Collected Steps per Second: 21,390.70726
Overall Steps per Second: 10,525.94525

Timestep Collection Time: 2.33868
Timestep Consumption Time: 2.41396
PPO Batch Consumption Time: 0.27649
Total Iteration Time: 4.75264

Cumulative Model Updates: 264,740
Cumulative Timesteps: 2,208,481,752

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2208481752...
Checkpoint 2208481752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 61,183.41705
Policy Entropy: 2.76462
Value Function Loss: 0.01212

Mean KL Divergence: 0.00618
SB3 Clip Fraction: 0.05608
Policy Update Magnitude: 0.31136
Value Function Update Magnitude: 0.26689

Collected Steps per Second: 21,080.02821
Overall Steps per Second: 10,283.69808

Timestep Collection Time: 2.37286
Timestep Consumption Time: 2.49115
PPO Batch Consumption Time: 0.29231
Total Iteration Time: 4.86401

Cumulative Model Updates: 264,746
Cumulative Timesteps: 2,208,531,772

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60,483.60791
Policy Entropy: 2.76552
Value Function Loss: 0.01202

Mean KL Divergence: 0.00624
SB3 Clip Fraction: 0.06262
Policy Update Magnitude: 0.30462
Value Function Update Magnitude: 0.30367

Collected Steps per Second: 21,790.55927
Overall Steps per Second: 10,448.04789

Timestep Collection Time: 2.29549
Timestep Consumption Time: 2.49201
PPO Batch Consumption Time: 0.29084
Total Iteration Time: 4.78750

Cumulative Model Updates: 264,752
Cumulative Timesteps: 2,208,581,792

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2208581792...
Checkpoint 2208581792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 67,970.76606
Policy Entropy: 2.75874
Value Function Loss: 0.01301

Mean KL Divergence: 0.00650
SB3 Clip Fraction: 0.06260
Policy Update Magnitude: 0.31126
Value Function Update Magnitude: 0.31123

Collected Steps per Second: 21,368.94950
Overall Steps per Second: 10,477.55187

Timestep Collection Time: 2.34003
Timestep Consumption Time: 2.43246
PPO Batch Consumption Time: 0.27769
Total Iteration Time: 4.77249

Cumulative Model Updates: 264,758
Cumulative Timesteps: 2,208,631,796

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54,487.03693
Policy Entropy: 2.75378
Value Function Loss: 0.01270

Mean KL Divergence: 0.00719
SB3 Clip Fraction: 0.05754
Policy Update Magnitude: 0.30853
Value Function Update Magnitude: 0.31643

Collected Steps per Second: 21,876.99910
Overall Steps per Second: 10,495.34247

Timestep Collection Time: 2.28587
Timestep Consumption Time: 2.47891
PPO Batch Consumption Time: 0.28682
Total Iteration Time: 4.76478

Cumulative Model Updates: 264,764
Cumulative Timesteps: 2,208,681,804

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2208681804...
Checkpoint 2208681804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 59,638.65785
Policy Entropy: 2.73478
Value Function Loss: 0.01331

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.07688
Policy Update Magnitude: 0.30317
Value Function Update Magnitude: 0.33283

Collected Steps per Second: 21,947.03373
Overall Steps per Second: 10,580.52953

Timestep Collection Time: 2.27821
Timestep Consumption Time: 2.44745
PPO Batch Consumption Time: 0.27803
Total Iteration Time: 4.72566

Cumulative Model Updates: 264,770
Cumulative Timesteps: 2,208,731,804

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91,217.21676
Policy Entropy: 2.70086
Value Function Loss: 0.01235

Mean KL Divergence: 0.00730
SB3 Clip Fraction: 0.06854
Policy Update Magnitude: 0.31564
Value Function Update Magnitude: 0.35266

Collected Steps per Second: 22,100.77059
Overall Steps per Second: 10,469.46093

Timestep Collection Time: 2.26327
Timestep Consumption Time: 2.51444
PPO Batch Consumption Time: 0.29276
Total Iteration Time: 4.77771

Cumulative Model Updates: 264,776
Cumulative Timesteps: 2,208,781,824

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2208781824...
Checkpoint 2208781824 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 56,773.14503
Policy Entropy: 2.67804
Value Function Loss: 0.01386

Mean KL Divergence: 0.00686
SB3 Clip Fraction: 0.06413
Policy Update Magnitude: 0.33250
Value Function Update Magnitude: 0.34324

Collected Steps per Second: 20,215.35597
Overall Steps per Second: 10,148.66753

Timestep Collection Time: 2.47485
Timestep Consumption Time: 2.45486
PPO Batch Consumption Time: 0.27874
Total Iteration Time: 4.92971

Cumulative Model Updates: 264,782
Cumulative Timesteps: 2,208,831,854

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57,559.16078
Policy Entropy: 2.66848
Value Function Loss: 0.01348

Mean KL Divergence: 0.00647
SB3 Clip Fraction: 0.05923
Policy Update Magnitude: 0.33610
Value Function Update Magnitude: 0.36918

Collected Steps per Second: 21,715.51812
Overall Steps per Second: 10,515.73354

Timestep Collection Time: 2.30296
Timestep Consumption Time: 2.45277
PPO Batch Consumption Time: 0.29271
Total Iteration Time: 4.75573

Cumulative Model Updates: 264,788
Cumulative Timesteps: 2,208,881,864

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2208881864...
Checkpoint 2208881864 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 77,312.22728
Policy Entropy: 2.69274
Value Function Loss: 0.01291

Mean KL Divergence: 0.00730
SB3 Clip Fraction: 0.06750
Policy Update Magnitude: 0.33515
Value Function Update Magnitude: 0.37130

Collected Steps per Second: 21,472.94018
Overall Steps per Second: 10,693.54541

Timestep Collection Time: 2.33000
Timestep Consumption Time: 2.34871
PPO Batch Consumption Time: 0.27703
Total Iteration Time: 4.67871

Cumulative Model Updates: 264,794
Cumulative Timesteps: 2,208,931,896

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 100,632.90866
Policy Entropy: 2.71173
Value Function Loss: 0.01434

Mean KL Divergence: 0.00736
SB3 Clip Fraction: 0.07096
Policy Update Magnitude: 0.33402
Value Function Update Magnitude: 0.33032

Collected Steps per Second: 21,491.82265
Overall Steps per Second: 10,523.39276

Timestep Collection Time: 2.32702
Timestep Consumption Time: 2.42544
PPO Batch Consumption Time: 0.29196
Total Iteration Time: 4.75246

Cumulative Model Updates: 264,800
Cumulative Timesteps: 2,208,981,908

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2208981908...
Checkpoint 2208981908 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 78,408.64859
Policy Entropy: 2.73227
Value Function Loss: 0.01285

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.07148
Policy Update Magnitude: 0.32703
Value Function Update Magnitude: 0.32639

Collected Steps per Second: 21,134.62883
Overall Steps per Second: 10,463.08263

Timestep Collection Time: 2.36616
Timestep Consumption Time: 2.41331
PPO Batch Consumption Time: 0.27804
Total Iteration Time: 4.77947

Cumulative Model Updates: 264,806
Cumulative Timesteps: 2,209,031,916

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 71,582.14836
Policy Entropy: 2.73004
Value Function Loss: 0.01266

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.07220
Policy Update Magnitude: 0.31044
Value Function Update Magnitude: 0.35446

Collected Steps per Second: 20,936.16279
Overall Steps per Second: 10,429.55820

Timestep Collection Time: 2.38879
Timestep Consumption Time: 2.40643
PPO Batch Consumption Time: 0.27752
Total Iteration Time: 4.79522

Cumulative Model Updates: 264,812
Cumulative Timesteps: 2,209,081,928

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2209081928...
Checkpoint 2209081928 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 68,700.18802
Policy Entropy: 2.72030
Value Function Loss: 0.01133

Mean KL Divergence: 0.00695
SB3 Clip Fraction: 0.06430
Policy Update Magnitude: 0.30156
Value Function Update Magnitude: 0.32484

Collected Steps per Second: 21,183.50231
Overall Steps per Second: 10,331.90571

Timestep Collection Time: 2.36137
Timestep Consumption Time: 2.48014
PPO Batch Consumption Time: 0.29302
Total Iteration Time: 4.84151

Cumulative Model Updates: 264,818
Cumulative Timesteps: 2,209,131,950

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 71,428.32168
Policy Entropy: 2.73285
Value Function Loss: 0.01096

Mean KL Divergence: 0.00673
SB3 Clip Fraction: 0.06399
Policy Update Magnitude: 0.29817
Value Function Update Magnitude: 0.29697

Collected Steps per Second: 21,967.40312
Overall Steps per Second: 10,445.64755

Timestep Collection Time: 2.27710
Timestep Consumption Time: 2.51169
PPO Batch Consumption Time: 0.29246
Total Iteration Time: 4.78879

Cumulative Model Updates: 264,824
Cumulative Timesteps: 2,209,181,972

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2209181972...
Checkpoint 2209181972 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 98,919.59715
Policy Entropy: 2.72445
Value Function Loss: 0.01195

Mean KL Divergence: 0.00659
SB3 Clip Fraction: 0.06261
Policy Update Magnitude: 0.30303
Value Function Update Magnitude: 0.29415

Collected Steps per Second: 21,457.21600
Overall Steps per Second: 10,493.22324

Timestep Collection Time: 2.33106
Timestep Consumption Time: 2.43564
PPO Batch Consumption Time: 0.27799
Total Iteration Time: 4.76670

Cumulative Model Updates: 264,830
Cumulative Timesteps: 2,209,231,990

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46,695.54420
Policy Entropy: 2.72751
Value Function Loss: 0.01352

Mean KL Divergence: 0.00736
SB3 Clip Fraction: 0.06968
Policy Update Magnitude: 0.31557
Value Function Update Magnitude: 0.30483

Collected Steps per Second: 21,427.87989
Overall Steps per Second: 10,468.35881

Timestep Collection Time: 2.33434
Timestep Consumption Time: 2.44387
PPO Batch Consumption Time: 0.27773
Total Iteration Time: 4.77821

Cumulative Model Updates: 264,836
Cumulative Timesteps: 2,209,282,010

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2209282010...
Checkpoint 2209282010 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 63,835.53253
Policy Entropy: 2.68592
Value Function Loss: 0.01412

Mean KL Divergence: 0.00681
SB3 Clip Fraction: 0.06649
Policy Update Magnitude: 0.33455
Value Function Update Magnitude: 0.33418

Collected Steps per Second: 22,398.67748
Overall Steps per Second: 10,671.36730

Timestep Collection Time: 2.23379
Timestep Consumption Time: 2.45483
PPO Batch Consumption Time: 0.27819
Total Iteration Time: 4.68862

Cumulative Model Updates: 264,842
Cumulative Timesteps: 2,209,332,044

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83,166.79165
Policy Entropy: 2.70158
Value Function Loss: 0.01375

Mean KL Divergence: 0.00697
SB3 Clip Fraction: 0.06619
Policy Update Magnitude: 0.33870
Value Function Update Magnitude: 0.33560

Collected Steps per Second: 22,303.10741
Overall Steps per Second: 10,507.59324

Timestep Collection Time: 2.24345
Timestep Consumption Time: 2.51844
PPO Batch Consumption Time: 0.29400
Total Iteration Time: 4.76189

Cumulative Model Updates: 264,848
Cumulative Timesteps: 2,209,382,080

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 2209382080...
Checkpoint 2209382080 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 56,308.69311
Policy Entropy: 2.70381
Value Function Loss: 0.01432

Mean KL Divergence: 0.00720
SB3 Clip Fraction: 0.06487
Policy Update Magnitude: 0.33598
Value Function Update Magnitude: 0.35617

Collected Steps per Second: 22,032.18246
Overall Steps per Second: 10,679.67568

Timestep Collection Time: 2.26977
Timestep Consumption Time: 2.41277
PPO Batch Consumption Time: 0.27732
Total Iteration Time: 4.68254

Cumulative Model Updates: 264,854
Cumulative Timesteps: 2,209,432,088

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53,767.49775
Policy Entropy: 2.72590
Value Function Loss: 0.01173

Mean KL Divergence: 0.00652
SB3 Clip Fraction: 0.06154
Policy Update Magnitude: 0.32606
Value Function Update Magnitude: 0.35183

Collected Steps per Second: 22,212.02682
Overall Steps per Second: 10,545.02747

Timestep Collection Time: 2.25112
Timestep Consumption Time: 2.49064
PPO Batch Consumption Time: 0.29118
Total Iteration Time: 4.74176

Cumulative Model Updates: 264,860
Cumulative Timesteps: 2,209,482,090

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2209482090...
Checkpoint 2209482090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 75,574.73596
Policy Entropy: 2.71411
Value Function Loss: 0.01167

Mean KL Divergence: 0.00662
SB3 Clip Fraction: 0.06587
Policy Update Magnitude: 0.31423
Value Function Update Magnitude: 0.32292

Collected Steps per Second: 22,057.74078
Overall Steps per Second: 10,479.03759

Timestep Collection Time: 2.26750
Timestep Consumption Time: 2.50545
PPO Batch Consumption Time: 0.29147
Total Iteration Time: 4.77296

Cumulative Model Updates: 264,866
Cumulative Timesteps: 2,209,532,106

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62,544.07015
Policy Entropy: 2.71832
Value Function Loss: 0.01058

Mean KL Divergence: 0.00627
SB3 Clip Fraction: 0.05967
Policy Update Magnitude: 0.31499
Value Function Update Magnitude: 0.31308

Collected Steps per Second: 22,338.20940
Overall Steps per Second: 10,568.44976

Timestep Collection Time: 2.23948
Timestep Consumption Time: 2.49404
PPO Batch Consumption Time: 0.29236
Total Iteration Time: 4.73352

Cumulative Model Updates: 264,872
Cumulative Timesteps: 2,209,582,132

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2209582132...
Checkpoint 2209582132 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 101,198.75193
Policy Entropy: 2.71158
Value Function Loss: 0.01264

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.06931
Policy Update Magnitude: 0.32121
Value Function Update Magnitude: 0.31918

Collected Steps per Second: 21,470.78666
Overall Steps per Second: 10,513.71446

Timestep Collection Time: 2.32986
Timestep Consumption Time: 2.42811
PPO Batch Consumption Time: 0.27838
Total Iteration Time: 4.75798

Cumulative Model Updates: 264,878
Cumulative Timesteps: 2,209,632,156

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86,319.93266
Policy Entropy: 2.71779
Value Function Loss: 0.01246

Mean KL Divergence: 0.00698
SB3 Clip Fraction: 0.06301
Policy Update Magnitude: 0.32392
Value Function Update Magnitude: 0.28538

Collected Steps per Second: 21,430.06954
Overall Steps per Second: 10,524.55270

Timestep Collection Time: 2.33485
Timestep Consumption Time: 2.41937
PPO Batch Consumption Time: 0.27738
Total Iteration Time: 4.75422

Cumulative Model Updates: 264,884
Cumulative Timesteps: 2,209,682,192

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 2209682192...
Checkpoint 2209682192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 145,766.02632
Policy Entropy: 2.70738
Value Function Loss: 0.01369

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.07549
Policy Update Magnitude: 0.32675
Value Function Update Magnitude: 0.22679

Collected Steps per Second: 20,992.59365
Overall Steps per Second: 10,577.08625

Timestep Collection Time: 2.38179
Timestep Consumption Time: 2.34541
PPO Batch Consumption Time: 0.27844
Total Iteration Time: 4.72720

Cumulative Model Updates: 264,890
Cumulative Timesteps: 2,209,732,192

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 138,979.62060
Policy Entropy: 2.70906
Value Function Loss: 0.01204

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.07397
Policy Update Magnitude: 0.31967
Value Function Update Magnitude: 0.20517

Collected Steps per Second: 20,950.11126
Overall Steps per Second: 10,549.18326

Timestep Collection Time: 2.38681
Timestep Consumption Time: 2.35327
PPO Batch Consumption Time: 0.27729
Total Iteration Time: 4.74008

Cumulative Model Updates: 264,896
Cumulative Timesteps: 2,209,782,196

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2209782196...
Checkpoint 2209782196 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 63,100.02839
Policy Entropy: 2.69797
Value Function Loss: 0.01229

Mean KL Divergence: 0.00695
SB3 Clip Fraction: 0.06453
Policy Update Magnitude: 0.31733
Value Function Update Magnitude: 0.21032

Collected Steps per Second: 21,378.04546
Overall Steps per Second: 10,536.00093

Timestep Collection Time: 2.33997
Timestep Consumption Time: 2.40794
PPO Batch Consumption Time: 0.27879
Total Iteration Time: 4.74791

Cumulative Model Updates: 264,902
Cumulative Timesteps: 2,209,832,220

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75,337.25184
Policy Entropy: 2.70654
Value Function Loss: 0.01088

Mean KL Divergence: 0.00617
SB3 Clip Fraction: 0.05998
Policy Update Magnitude: 0.31486
Value Function Update Magnitude: 0.27790

Collected Steps per Second: 21,339.81453
Overall Steps per Second: 10,444.02911

Timestep Collection Time: 2.34360
Timestep Consumption Time: 2.44497
PPO Batch Consumption Time: 0.28487
Total Iteration Time: 4.78857

Cumulative Model Updates: 264,908
Cumulative Timesteps: 2,209,882,232

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2209882232...
Checkpoint 2209882232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 63,249.33830
Policy Entropy: 2.70695
Value Function Loss: 0.01205

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.07054
Policy Update Magnitude: 0.31352
Value Function Update Magnitude: 0.29041

Collected Steps per Second: 22,063.68968
Overall Steps per Second: 10,719.81837

Timestep Collection Time: 2.26626
Timestep Consumption Time: 2.39819
PPO Batch Consumption Time: 0.27776
Total Iteration Time: 4.66444

Cumulative Model Updates: 264,914
Cumulative Timesteps: 2,209,932,234

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 98,361.31911
Policy Entropy: 2.71416
Value Function Loss: 0.01274

Mean KL Divergence: 0.00645
SB3 Clip Fraction: 0.06218
Policy Update Magnitude: 0.31522
Value Function Update Magnitude: 0.30348

Collected Steps per Second: 22,119.37039
Overall Steps per Second: 10,593.73395

Timestep Collection Time: 2.26110
Timestep Consumption Time: 2.46000
PPO Batch Consumption Time: 0.28957
Total Iteration Time: 4.72109

Cumulative Model Updates: 264,920
Cumulative Timesteps: 2,209,982,248

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2209982248...
Checkpoint 2209982248 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 82,470.38404
Policy Entropy: 2.72843
Value Function Loss: 0.01203

Mean KL Divergence: 0.00640
SB3 Clip Fraction: 0.06091
Policy Update Magnitude: 0.31432
Value Function Update Magnitude: 0.33090

Collected Steps per Second: 22,238.88447
Overall Steps per Second: 10,513.63841

Timestep Collection Time: 2.24966
Timestep Consumption Time: 2.50892
PPO Batch Consumption Time: 0.29301
Total Iteration Time: 4.75858

Cumulative Model Updates: 264,926
Cumulative Timesteps: 2,210,032,278

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 125,957.12952
Policy Entropy: 2.71512
Value Function Loss: 0.01067

Mean KL Divergence: 0.00660
SB3 Clip Fraction: 0.06280
Policy Update Magnitude: 0.30180
Value Function Update Magnitude: 0.29959

Collected Steps per Second: 21,726.66814
Overall Steps per Second: 10,377.64125

Timestep Collection Time: 2.30242
Timestep Consumption Time: 2.51794
PPO Batch Consumption Time: 0.29372
Total Iteration Time: 4.82036

Cumulative Model Updates: 264,932
Cumulative Timesteps: 2,210,082,302

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2210082302...
Checkpoint 2210082302 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 90,569.31805
Policy Entropy: 2.71558
Value Function Loss: 0.01130

Mean KL Divergence: 0.00741
SB3 Clip Fraction: 0.06971
Policy Update Magnitude: 0.30239
Value Function Update Magnitude: 0.27166

Collected Steps per Second: 21,654.80419
Overall Steps per Second: 10,592.72391

Timestep Collection Time: 2.30997
Timestep Consumption Time: 2.41233
PPO Batch Consumption Time: 0.27892
Total Iteration Time: 4.72230

Cumulative Model Updates: 264,938
Cumulative Timesteps: 2,210,132,324

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88,859.57406
Policy Entropy: 2.68537
Value Function Loss: 0.01329

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.06984
Policy Update Magnitude: 0.32332
Value Function Update Magnitude: 0.30348

Collected Steps per Second: 21,394.80248
Overall Steps per Second: 10,477.07947

Timestep Collection Time: 2.33702
Timestep Consumption Time: 2.43531
PPO Batch Consumption Time: 0.27857
Total Iteration Time: 4.77232

Cumulative Model Updates: 264,944
Cumulative Timesteps: 2,210,182,324

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2210182324...
Checkpoint 2210182324 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87,200.74491
Policy Entropy: 2.71449
Value Function Loss: 0.01355

Mean KL Divergence: 0.00699
SB3 Clip Fraction: 0.06203
Policy Update Magnitude: 0.32840
Value Function Update Magnitude: 0.31652

Collected Steps per Second: 21,573.81344
Overall Steps per Second: 10,432.03341

Timestep Collection Time: 2.32013
Timestep Consumption Time: 2.47798
PPO Batch Consumption Time: 0.28914
Total Iteration Time: 4.79811

Cumulative Model Updates: 264,950
Cumulative Timesteps: 2,210,232,378

Timesteps Collected: 50,054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 123,241.30387
Policy Entropy: 2.72138
Value Function Loss: 0.01308

Mean KL Divergence: 0.00670
SB3 Clip Fraction: 0.06497
Policy Update Magnitude: 0.31448
Value Function Update Magnitude: 0.31793

Collected Steps per Second: 21,766.30375
Overall Steps per Second: 10,435.57895

Timestep Collection Time: 2.29869
Timestep Consumption Time: 2.49587
PPO Batch Consumption Time: 0.29007
Total Iteration Time: 4.79456

Cumulative Model Updates: 264,956
Cumulative Timesteps: 2,210,282,412

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 2210282412...
Checkpoint 2210282412 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 93,215.66013
Policy Entropy: 2.73379
Value Function Loss: 0.01138

Mean KL Divergence: 0.00752
SB3 Clip Fraction: 0.07120
Policy Update Magnitude: 0.31738
Value Function Update Magnitude: 0.33409

Collected Steps per Second: 21,278.66944
Overall Steps per Second: 10,488.92893

Timestep Collection Time: 2.35165
Timestep Consumption Time: 2.41909
PPO Batch Consumption Time: 0.29107
Total Iteration Time: 4.77074

Cumulative Model Updates: 264,962
Cumulative Timesteps: 2,210,332,452

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66,342.15539
Policy Entropy: 2.70116
Value Function Loss: 0.01255

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.07522
Policy Update Magnitude: 0.32003
Value Function Update Magnitude: 0.35313

Collected Steps per Second: 21,458.64357
Overall Steps per Second: 10,416.37783

Timestep Collection Time: 2.33006
Timestep Consumption Time: 2.47007
PPO Batch Consumption Time: 0.29207
Total Iteration Time: 4.80013

Cumulative Model Updates: 264,968
Cumulative Timesteps: 2,210,382,452

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2210382452...
Checkpoint 2210382452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 83,531.18391
Policy Entropy: 2.71170
Value Function Loss: 0.01386

Mean KL Divergence: 0.01281
SB3 Clip Fraction: 0.07777
Policy Update Magnitude: 0.32200
Value Function Update Magnitude: 0.39149

Collected Steps per Second: 21,514.62254
Overall Steps per Second: 10,639.54926

Timestep Collection Time: 2.32400
Timestep Consumption Time: 2.37545
PPO Batch Consumption Time: 0.27916
Total Iteration Time: 4.69945

Cumulative Model Updates: 264,974
Cumulative Timesteps: 2,210,432,452

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 69,553.20510
Policy Entropy: 2.72462
Value Function Loss: 0.01267

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.08692
Policy Update Magnitude: 0.31594
Value Function Update Magnitude: 0.38690

Collected Steps per Second: 21,470.53273
Overall Steps per Second: 10,523.91147

Timestep Collection Time: 2.32943
Timestep Consumption Time: 2.42299
PPO Batch Consumption Time: 0.29320
Total Iteration Time: 4.75242

Cumulative Model Updates: 264,980
Cumulative Timesteps: 2,210,482,466

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2210482466...
Checkpoint 2210482466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 82,551.18030
Policy Entropy: 2.74366
Value Function Loss: 0.01333

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.08121
Policy Update Magnitude: 0.30657
Value Function Update Magnitude: 0.35609

Collected Steps per Second: 21,635.60410
Overall Steps per Second: 10,582.38819

Timestep Collection Time: 2.31239
Timestep Consumption Time: 2.41527
PPO Batch Consumption Time: 0.28297
Total Iteration Time: 4.72767

Cumulative Model Updates: 264,986
Cumulative Timesteps: 2,210,532,496

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92,404.62782
Policy Entropy: 2.73587
Value Function Loss: 0.01448

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.08405
Policy Update Magnitude: 0.31565
Value Function Update Magnitude: 0.33382

Collected Steps per Second: 22,046.20453
Overall Steps per Second: 10,536.17992

Timestep Collection Time: 2.26805
Timestep Consumption Time: 2.47769
PPO Batch Consumption Time: 0.29264
Total Iteration Time: 4.74574

Cumulative Model Updates: 264,992
Cumulative Timesteps: 2,210,582,498

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2210582498...
Checkpoint 2210582498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 77,041.32191
Policy Entropy: 2.73545
Value Function Loss: 0.01571

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.08878
Policy Update Magnitude: 0.33873
Value Function Update Magnitude: 0.35472

Collected Steps per Second: 22,214.44565
Overall Steps per Second: 10,577.42412

Timestep Collection Time: 2.25178
Timestep Consumption Time: 2.47735
PPO Batch Consumption Time: 0.29258
Total Iteration Time: 4.72913

Cumulative Model Updates: 264,998
Cumulative Timesteps: 2,210,632,520

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51,946.41551
Policy Entropy: 2.71035
Value Function Loss: 0.01506

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.08515
Policy Update Magnitude: 0.33851
Value Function Update Magnitude: 0.38866

Collected Steps per Second: 22,061.70496
Overall Steps per Second: 10,481.97628

Timestep Collection Time: 2.26782
Timestep Consumption Time: 2.50532
PPO Batch Consumption Time: 0.29322
Total Iteration Time: 4.77315

Cumulative Model Updates: 265,004
Cumulative Timesteps: 2,210,682,552

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2210682552...
Checkpoint 2210682552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 61,692.37100
Policy Entropy: 2.72318
Value Function Loss: 0.01161

Mean KL Divergence: 0.01077
SB3 Clip Fraction: 0.09552
Policy Update Magnitude: 0.32863
Value Function Update Magnitude: 0.36670

Collected Steps per Second: 20,583.81254
Overall Steps per Second: 10,156.41690

Timestep Collection Time: 2.42948
Timestep Consumption Time: 2.49430
PPO Batch Consumption Time: 0.28928
Total Iteration Time: 4.92378

Cumulative Model Updates: 265,010
Cumulative Timesteps: 2,210,732,560

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61,692.37100
Policy Entropy: 2.74660
Value Function Loss: 0.00991

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.09197
Policy Update Magnitude: 0.30470
Value Function Update Magnitude: 0.32390

Collected Steps per Second: 21,754.05327
Overall Steps per Second: 10,472.74227

Timestep Collection Time: 2.29980
Timestep Consumption Time: 2.47736
PPO Batch Consumption Time: 0.28662
Total Iteration Time: 4.77716

Cumulative Model Updates: 265,016
Cumulative Timesteps: 2,210,782,590

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2210782590...
Checkpoint 2210782590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 81,064.36148
Policy Entropy: 2.72690
Value Function Loss: 0.01140

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.08651
Policy Update Magnitude: 0.29920
Value Function Update Magnitude: 0.29054

Collected Steps per Second: 21,475.83854
Overall Steps per Second: 10,363.59019

Timestep Collection Time: 2.32987
Timestep Consumption Time: 2.49818
PPO Batch Consumption Time: 0.29073
Total Iteration Time: 4.82806

Cumulative Model Updates: 265,022
Cumulative Timesteps: 2,210,832,626

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63,142.26808
Policy Entropy: 2.71551
Value Function Loss: 0.01186

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.07341
Policy Update Magnitude: 0.31333
Value Function Update Magnitude: 0.30830

Collected Steps per Second: 22,087.62694
Overall Steps per Second: 10,664.17424

Timestep Collection Time: 2.26462
Timestep Consumption Time: 2.42585
PPO Batch Consumption Time: 0.27789
Total Iteration Time: 4.69047

Cumulative Model Updates: 265,028
Cumulative Timesteps: 2,210,882,646

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2210882646...
Checkpoint 2210882646 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 66,791.38472
Policy Entropy: 2.69391
Value Function Loss: 0.01262

Mean KL Divergence: 0.01066
SB3 Clip Fraction: 0.08979
Policy Update Magnitude: 0.32046
Value Function Update Magnitude: 0.32609

Collected Steps per Second: 21,613.98781
Overall Steps per Second: 10,294.17318

Timestep Collection Time: 2.31545
Timestep Consumption Time: 2.54614
PPO Batch Consumption Time: 0.29381
Total Iteration Time: 4.86159

Cumulative Model Updates: 265,034
Cumulative Timesteps: 2,210,932,692

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 69,916.74126
Policy Entropy: 2.72709
Value Function Loss: 0.01218

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.07612
Policy Update Magnitude: 0.32589
Value Function Update Magnitude: 0.32756

Collected Steps per Second: 22,201.24437
Overall Steps per Second: 10,484.93242

Timestep Collection Time: 2.25402
Timestep Consumption Time: 2.51874
PPO Batch Consumption Time: 0.29212
Total Iteration Time: 4.77275

Cumulative Model Updates: 265,040
Cumulative Timesteps: 2,210,982,734

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 2210982734...
Checkpoint 2210982734 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 80,869.51144
Policy Entropy: 2.73609
Value Function Loss: 0.01328

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.07621
Policy Update Magnitude: 0.32283
Value Function Update Magnitude: 0.33347

Collected Steps per Second: 21,619.33634
Overall Steps per Second: 10,530.97060

Timestep Collection Time: 2.31422
Timestep Consumption Time: 2.43671
PPO Batch Consumption Time: 0.27941
Total Iteration Time: 4.75094

Cumulative Model Updates: 265,046
Cumulative Timesteps: 2,211,032,766

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 107,849.77552
Policy Entropy: 2.73560
Value Function Loss: 0.01304

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.08402
Policy Update Magnitude: 0.32188
Value Function Update Magnitude: 0.33352

Collected Steps per Second: 22,283.92152
Overall Steps per Second: 10,536.57783

Timestep Collection Time: 2.24458
Timestep Consumption Time: 2.50250
PPO Batch Consumption Time: 0.29277
Total Iteration Time: 4.74708

Cumulative Model Updates: 265,052
Cumulative Timesteps: 2,211,082,784

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2211082784...
Checkpoint 2211082784 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84,046.30536
Policy Entropy: 2.71619
Value Function Loss: 0.01410

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.07194
Policy Update Magnitude: 0.32816
Value Function Update Magnitude: 0.32694

Collected Steps per Second: 21,831.65918
Overall Steps per Second: 10,601.72945

Timestep Collection Time: 2.29071
Timestep Consumption Time: 2.42644
PPO Batch Consumption Time: 0.27803
Total Iteration Time: 4.71715

Cumulative Model Updates: 265,058
Cumulative Timesteps: 2,211,132,794

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75,650.51663
Policy Entropy: 2.68319
Value Function Loss: 0.01377

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.07699
Policy Update Magnitude: 0.33843
Value Function Update Magnitude: 0.33910

Collected Steps per Second: 22,436.39657
Overall Steps per Second: 10,578.71953

Timestep Collection Time: 2.22950
Timestep Consumption Time: 2.49905
PPO Batch Consumption Time: 0.29161
Total Iteration Time: 4.72855

Cumulative Model Updates: 265,064
Cumulative Timesteps: 2,211,182,816

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2211182816...
Checkpoint 2211182816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 58,125.34774
Policy Entropy: 2.66531
Value Function Loss: 0.01478

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.08042
Policy Update Magnitude: 0.33718
Value Function Update Magnitude: 0.36046

Collected Steps per Second: 21,556.02970
Overall Steps per Second: 10,523.86555

Timestep Collection Time: 2.32158
Timestep Consumption Time: 2.43371
PPO Batch Consumption Time: 0.27855
Total Iteration Time: 4.75529

Cumulative Model Updates: 265,070
Cumulative Timesteps: 2,211,232,860

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63,242.67744
Policy Entropy: 2.69098
Value Function Loss: 0.01539

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.08080
Policy Update Magnitude: 0.34278
Value Function Update Magnitude: 0.35641

Collected Steps per Second: 21,429.02984
Overall Steps per Second: 10,483.95270

Timestep Collection Time: 2.33412
Timestep Consumption Time: 2.43679
PPO Batch Consumption Time: 0.29343
Total Iteration Time: 4.77091

Cumulative Model Updates: 265,076
Cumulative Timesteps: 2,211,282,878

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2211282878...
Checkpoint 2211282878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,548.51510
Policy Entropy: 2.70154
Value Function Loss: 0.01623

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.07113
Policy Update Magnitude: 0.34503
Value Function Update Magnitude: 0.34742

Collected Steps per Second: 20,501.32051
Overall Steps per Second: 10,293.91617

Timestep Collection Time: 2.43906
Timestep Consumption Time: 2.41856
PPO Batch Consumption Time: 0.29236
Total Iteration Time: 4.85763

Cumulative Model Updates: 265,082
Cumulative Timesteps: 2,211,332,882

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,303.96805
Policy Entropy: 2.70378
Value Function Loss: 0.01385

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.07987
Policy Update Magnitude: 0.34391
Value Function Update Magnitude: 0.33979

Collected Steps per Second: 21,322.71963
Overall Steps per Second: 10,534.98659

Timestep Collection Time: 2.34595
Timestep Consumption Time: 2.40223
PPO Batch Consumption Time: 0.28866
Total Iteration Time: 4.74818

Cumulative Model Updates: 265,088
Cumulative Timesteps: 2,211,382,904

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2211382904...
Checkpoint 2211382904 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 72,384.07987
Policy Entropy: 2.69729
Value Function Loss: 0.01519

Mean KL Divergence: 0.01150
SB3 Clip Fraction: 0.10023
Policy Update Magnitude: 0.33477
Value Function Update Magnitude: 0.33316

Collected Steps per Second: 21,072.76207
Overall Steps per Second: 10,499.02349

Timestep Collection Time: 2.37378
Timestep Consumption Time: 2.39067
PPO Batch Consumption Time: 0.27641
Total Iteration Time: 4.76444

Cumulative Model Updates: 265,094
Cumulative Timesteps: 2,211,432,926

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53,882.79766
Policy Entropy: 2.73110
Value Function Loss: 0.01415

Mean KL Divergence: 0.01114
SB3 Clip Fraction: 0.09556
Policy Update Magnitude: 0.33742
Value Function Update Magnitude: 0.34121

Collected Steps per Second: 21,864.79064
Overall Steps per Second: 10,472.86919

Timestep Collection Time: 2.28696
Timestep Consumption Time: 2.48766
PPO Batch Consumption Time: 0.29249
Total Iteration Time: 4.77462

Cumulative Model Updates: 265,100
Cumulative Timesteps: 2,211,482,930

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2211482930...
Checkpoint 2211482930 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46,831.34692
Policy Entropy: 2.73732
Value Function Loss: 0.01478

Mean KL Divergence: 0.01111
SB3 Clip Fraction: 0.09578
Policy Update Magnitude: 0.33678
Value Function Update Magnitude: 0.31110

Collected Steps per Second: 21,745.52303
Overall Steps per Second: 10,510.01546

Timestep Collection Time: 2.29988
Timestep Consumption Time: 2.45863
PPO Batch Consumption Time: 0.27789
Total Iteration Time: 4.75851

Cumulative Model Updates: 265,106
Cumulative Timesteps: 2,211,532,942

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80,540.71905
Policy Entropy: 2.71671
Value Function Loss: 0.01614

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.08539
Policy Update Magnitude: 0.35377
Value Function Update Magnitude: 0.25866

Collected Steps per Second: 21,855.06643
Overall Steps per Second: 10,420.29003

Timestep Collection Time: 2.28826
Timestep Consumption Time: 2.51103
PPO Batch Consumption Time: 0.29055
Total Iteration Time: 4.79929

Cumulative Model Updates: 265,112
Cumulative Timesteps: 2,211,582,952

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2211582952...
Checkpoint 2211582952 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 77,243.56747
Policy Entropy: 2.67996
Value Function Loss: 0.01955

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.07324
Policy Update Magnitude: 0.36754
Value Function Update Magnitude: 0.26328

Collected Steps per Second: 22,089.09155
Overall Steps per Second: 10,645.19653

Timestep Collection Time: 2.26501
Timestep Consumption Time: 2.43495
PPO Batch Consumption Time: 0.27908
Total Iteration Time: 4.69996

Cumulative Model Updates: 265,118
Cumulative Timesteps: 2,211,632,984

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54,937.87484
Policy Entropy: 2.66952
Value Function Loss: 0.02048

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.07580
Policy Update Magnitude: 0.38688
Value Function Update Magnitude: 0.28763

Collected Steps per Second: 22,232.03120
Overall Steps per Second: 10,526.43235

Timestep Collection Time: 2.24919
Timestep Consumption Time: 2.50114
PPO Batch Consumption Time: 0.29031
Total Iteration Time: 4.75033

Cumulative Model Updates: 265,124
Cumulative Timesteps: 2,211,682,988

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2211682988...
Checkpoint 2211682988 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 73,342.58640
Policy Entropy: 2.69919
Value Function Loss: 0.01608

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.07602
Policy Update Magnitude: 0.37195
Value Function Update Magnitude: 0.34279

Collected Steps per Second: 21,770.64772
Overall Steps per Second: 10,601.55134

Timestep Collection Time: 2.29722
Timestep Consumption Time: 2.42020
PPO Batch Consumption Time: 0.27796
Total Iteration Time: 4.71742

Cumulative Model Updates: 265,130
Cumulative Timesteps: 2,211,733,000

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67,511.11995
Policy Entropy: 2.73759
Value Function Loss: 0.01276

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.07815
Policy Update Magnitude: 0.33758
Value Function Update Magnitude: 0.36908

Collected Steps per Second: 22,480.02930
Overall Steps per Second: 10,604.08089

Timestep Collection Time: 2.22500
Timestep Consumption Time: 2.49187
PPO Batch Consumption Time: 0.29266
Total Iteration Time: 4.71686

Cumulative Model Updates: 265,136
Cumulative Timesteps: 2,211,783,018

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2211783018...
Checkpoint 2211783018 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 67,511.11995
Policy Entropy: 2.72721
Value Function Loss: 0.01152

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.07028
Policy Update Magnitude: 0.32127
Value Function Update Magnitude: 0.33801

Collected Steps per Second: 21,750.65420
Overall Steps per Second: 9,298.31181

Timestep Collection Time: 2.30016
Timestep Consumption Time: 3.08039
PPO Batch Consumption Time: 0.33131
Total Iteration Time: 5.38055

Cumulative Model Updates: 265,142
Cumulative Timesteps: 2,211,833,048

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63,126.75081
Policy Entropy: 2.72579
Value Function Loss: 0.01143

Mean KL Divergence: 0.00659
SB3 Clip Fraction: 0.06208
Policy Update Magnitude: 0.32119
Value Function Update Magnitude: 0.30482

Collected Steps per Second: 10,896.05690
Overall Steps per Second: 6,667.70783

Timestep Collection Time: 4.59028
Timestep Consumption Time: 2.91094
PPO Batch Consumption Time: 0.32234
Total Iteration Time: 7.50123

Cumulative Model Updates: 265,148
Cumulative Timesteps: 2,211,883,064

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2211883064...
Checkpoint 2211883064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 59,282.81975
Policy Entropy: 2.69579
Value Function Loss: 0.01080

Mean KL Divergence: 0.00692
SB3 Clip Fraction: 0.06272
Policy Update Magnitude: 0.31207
Value Function Update Magnitude: 0.30084

Collected Steps per Second: 18,571.80206
Overall Steps per Second: 9,705.35128

Timestep Collection Time: 2.69279
Timestep Consumption Time: 2.46004
PPO Batch Consumption Time: 0.29560
Total Iteration Time: 5.15283

Cumulative Model Updates: 265,154
Cumulative Timesteps: 2,211,933,074

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50,518.15119
Policy Entropy: 2.71229
Value Function Loss: 0.01127

Mean KL Divergence: 0.00639
SB3 Clip Fraction: 0.05882
Policy Update Magnitude: 0.31216
Value Function Update Magnitude: 0.30990

Collected Steps per Second: 19,736.60384
Overall Steps per Second: 10,257.95324

Timestep Collection Time: 2.53478
Timestep Consumption Time: 2.34221
PPO Batch Consumption Time: 0.28760
Total Iteration Time: 4.87700

Cumulative Model Updates: 265,160
Cumulative Timesteps: 2,211,983,102

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2211983102...
Checkpoint 2211983102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 60,859.43221
Policy Entropy: 2.70845
Value Function Loss: 0.01212

Mean KL Divergence: 0.00634
SB3 Clip Fraction: 0.05999
Policy Update Magnitude: 0.31927
Value Function Update Magnitude: 0.32262

Collected Steps per Second: 19,425.52164
Overall Steps per Second: 9,983.99707

Timestep Collection Time: 2.57599
Timestep Consumption Time: 2.43603
PPO Batch Consumption Time: 0.28951
Total Iteration Time: 5.01202

Cumulative Model Updates: 265,166
Cumulative Timesteps: 2,212,033,142

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56,727.51926
Policy Entropy: 2.70876
Value Function Loss: 0.01229

Mean KL Divergence: 0.00738
SB3 Clip Fraction: 0.07032
Policy Update Magnitude: 0.32409
Value Function Update Magnitude: 0.31588

Collected Steps per Second: 19,985.60209
Overall Steps per Second: 10,195.62374

Timestep Collection Time: 2.50300
Timestep Consumption Time: 2.40342
PPO Batch Consumption Time: 0.28290
Total Iteration Time: 4.90642

Cumulative Model Updates: 265,172
Cumulative Timesteps: 2,212,083,166

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2212083166...
Checkpoint 2212083166 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,671.59651
Policy Entropy: 2.72593
Value Function Loss: 0.01257

Mean KL Divergence: 0.00729
SB3 Clip Fraction: 0.06720
Policy Update Magnitude: 0.32735
Value Function Update Magnitude: 0.31114

Collected Steps per Second: 18,916.93656
Overall Steps per Second: 9,692.82969

Timestep Collection Time: 2.64440
Timestep Consumption Time: 2.51653
PPO Batch Consumption Time: 0.29312
Total Iteration Time: 5.16093

Cumulative Model Updates: 265,178
Cumulative Timesteps: 2,212,133,190

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,388.57981
Policy Entropy: 2.71745
Value Function Loss: 0.01405

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.06428
Policy Update Magnitude: 0.33235
Value Function Update Magnitude: 0.30836

Collected Steps per Second: 16,128.50275
Overall Steps per Second: 8,924.45617

Timestep Collection Time: 3.10085
Timestep Consumption Time: 2.50308
PPO Batch Consumption Time: 0.28005
Total Iteration Time: 5.60393

Cumulative Model Updates: 265,184
Cumulative Timesteps: 2,212,183,202

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2212183202...
Checkpoint 2212183202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,777.74783
Policy Entropy: 2.71585
Value Function Loss: 0.01352

Mean KL Divergence: 0.01058
SB3 Clip Fraction: 0.06287
Policy Update Magnitude: 0.32812
Value Function Update Magnitude: 0.32796

Collected Steps per Second: 18,616.04466
Overall Steps per Second: 9,421.96911

Timestep Collection Time: 2.68811
Timestep Consumption Time: 2.62309
PPO Batch Consumption Time: 0.30779
Total Iteration Time: 5.31120

Cumulative Model Updates: 265,190
Cumulative Timesteps: 2,212,233,244

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,777.74783
Policy Entropy: 2.71388
Value Function Loss: 0.01238

Mean KL Divergence: 0.01192
SB3 Clip Fraction: 0.06946
Policy Update Magnitude: 0.31836
Value Function Update Magnitude: 0.31831

Collected Steps per Second: 17,494.78793
Overall Steps per Second: 9,121.36343

Timestep Collection Time: 2.85879
Timestep Consumption Time: 2.62438
PPO Batch Consumption Time: 0.29435
Total Iteration Time: 5.48317

Cumulative Model Updates: 265,196
Cumulative Timesteps: 2,212,283,258

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2212283258...
Checkpoint 2212283258 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 57,797.77735
Policy Entropy: 2.72444
Value Function Loss: 0.01287

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.07302
Policy Update Magnitude: 0.31696
Value Function Update Magnitude: 0.28786

Collected Steps per Second: 20,211.53353
Overall Steps per Second: 10,006.29170

Timestep Collection Time: 2.47393
Timestep Consumption Time: 2.52312
PPO Batch Consumption Time: 0.29232
Total Iteration Time: 4.99706

Cumulative Model Updates: 265,202
Cumulative Timesteps: 2,212,333,260

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90,164.16800
Policy Entropy: 2.73993
Value Function Loss: 0.01417

Mean KL Divergence: 0.00770
SB3 Clip Fraction: 0.07166
Policy Update Magnitude: 0.32986
Value Function Update Magnitude: 0.30144

Collected Steps per Second: 18,554.37791
Overall Steps per Second: 9,446.27109

Timestep Collection Time: 2.69608
Timestep Consumption Time: 2.59956
PPO Batch Consumption Time: 0.29787
Total Iteration Time: 5.29563

Cumulative Model Updates: 265,208
Cumulative Timesteps: 2,212,383,284

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2212383284...
Checkpoint 2212383284 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 59,214.18893
Policy Entropy: 2.74889
Value Function Loss: 0.01664

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.08113
Policy Update Magnitude: 0.32742
Value Function Update Magnitude: 0.34822

Collected Steps per Second: 16,553.29941
Overall Steps per Second: 7,363.30848

Timestep Collection Time: 3.02187
Timestep Consumption Time: 3.77154
PPO Batch Consumption Time: 0.48878
Total Iteration Time: 6.79341

Cumulative Model Updates: 265,214
Cumulative Timesteps: 2,212,433,306

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80,459.05256
Policy Entropy: 2.74070
Value Function Loss: 0.01505

Mean KL Divergence: 0.00764
SB3 Clip Fraction: 0.06683
Policy Update Magnitude: 0.33103
Value Function Update Magnitude: 0.37537

Collected Steps per Second: 14,303.67239
Overall Steps per Second: 7,206.35559

Timestep Collection Time: 3.49798
Timestep Consumption Time: 3.44506
PPO Batch Consumption Time: 0.44013
Total Iteration Time: 6.94304

Cumulative Model Updates: 265,220
Cumulative Timesteps: 2,212,483,340

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 2212483340...
Checkpoint 2212483340 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 57,776.98058
Policy Entropy: 2.73417
Value Function Loss: 0.01414

Mean KL Divergence: 0.00718
SB3 Clip Fraction: 0.06770
Policy Update Magnitude: 0.32867
Value Function Update Magnitude: 0.36416

Collected Steps per Second: 14,964.94269
Overall Steps per Second: 6,973.87354

Timestep Collection Time: 3.34261
Timestep Consumption Time: 3.83016
PPO Batch Consumption Time: 0.50696
Total Iteration Time: 7.17277

Cumulative Model Updates: 265,226
Cumulative Timesteps: 2,212,533,362

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59,205.25409
Policy Entropy: 2.71673
Value Function Loss: 0.01379

Mean KL Divergence: 0.00734
SB3 Clip Fraction: 0.06909
Policy Update Magnitude: 0.33019
Value Function Update Magnitude: 0.36106

Collected Steps per Second: 13,577.78929
Overall Steps per Second: 6,623.77658

Timestep Collection Time: 3.68322
Timestep Consumption Time: 3.86685
PPO Batch Consumption Time: 0.50834
Total Iteration Time: 7.55007

Cumulative Model Updates: 265,232
Cumulative Timesteps: 2,212,583,372

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2212583372...
Checkpoint 2212583372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,814.65972
Policy Entropy: 2.74041
Value Function Loss: 0.01222

Mean KL Divergence: 0.00760
SB3 Clip Fraction: 0.07245
Policy Update Magnitude: 0.32969
Value Function Update Magnitude: 0.36630

Collected Steps per Second: 14,668.79312
Overall Steps per Second: 7,190.94221

Timestep Collection Time: 3.40887
Timestep Consumption Time: 3.54488
PPO Batch Consumption Time: 0.46100
Total Iteration Time: 6.95375

Cumulative Model Updates: 265,238
Cumulative Timesteps: 2,212,633,376

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,011.45568
Policy Entropy: 2.76541
Value Function Loss: 0.01169

Mean KL Divergence: 0.00656
SB3 Clip Fraction: 0.06219
Policy Update Magnitude: 0.31610
Value Function Update Magnitude: 0.35202

Collected Steps per Second: 14,960.85865
Overall Steps per Second: 7,383.92541

Timestep Collection Time: 3.34406
Timestep Consumption Time: 3.43147
PPO Batch Consumption Time: 0.44191
Total Iteration Time: 6.77553

Cumulative Model Updates: 265,244
Cumulative Timesteps: 2,212,683,406

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2212683406...
Checkpoint 2212683406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 58,366.96745
Policy Entropy: 2.76934
Value Function Loss: 0.01100

Mean KL Divergence: 0.00611
SB3 Clip Fraction: 0.05660
Policy Update Magnitude: 0.30285
Value Function Update Magnitude: 0.32615

Collected Steps per Second: 14,976.39081
Overall Steps per Second: 7,397.31578

Timestep Collection Time: 3.34046
Timestep Consumption Time: 3.42254
PPO Batch Consumption Time: 0.44460
Total Iteration Time: 6.76299

Cumulative Model Updates: 265,250
Cumulative Timesteps: 2,212,733,434

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95,225.34810
Policy Entropy: 2.74378
Value Function Loss: 0.01368

Mean KL Divergence: 0.00609
SB3 Clip Fraction: 0.05882
Policy Update Magnitude: 0.31034
Value Function Update Magnitude: 0.31746

Collected Steps per Second: 15,077.97803
Overall Steps per Second: 7,121.10307

Timestep Collection Time: 3.31822
Timestep Consumption Time: 3.70766
PPO Batch Consumption Time: 0.49010
Total Iteration Time: 7.02588

Cumulative Model Updates: 265,256
Cumulative Timesteps: 2,212,783,466

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2212783466...
Checkpoint 2212783466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 91,780.87158
Policy Entropy: 2.72473
Value Function Loss: 0.01381

Mean KL Divergence: 0.00697
SB3 Clip Fraction: 0.06480
Policy Update Magnitude: 0.32513
Value Function Update Magnitude: 0.35491

Collected Steps per Second: 15,446.16416
Overall Steps per Second: 7,251.94212

Timestep Collection Time: 3.24016
Timestep Consumption Time: 3.66117
PPO Batch Consumption Time: 0.48268
Total Iteration Time: 6.90132

Cumulative Model Updates: 265,262
Cumulative Timesteps: 2,212,833,514

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70,054.47267
Policy Entropy: 2.71984
Value Function Loss: 0.01416

Mean KL Divergence: 0.00640
SB3 Clip Fraction: 0.05948
Policy Update Magnitude: 0.33657
Value Function Update Magnitude: 0.37081

Collected Steps per Second: 14,647.91743
Overall Steps per Second: 6,951.82834

Timestep Collection Time: 3.41373
Timestep Consumption Time: 3.77920
PPO Batch Consumption Time: 0.51142
Total Iteration Time: 7.19293

Cumulative Model Updates: 265,268
Cumulative Timesteps: 2,212,883,518

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2212883518...
Checkpoint 2212883518 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89,016.27327
Policy Entropy: 2.74705
Value Function Loss: 0.01354

Mean KL Divergence: 0.00665
SB3 Clip Fraction: 0.06314
Policy Update Magnitude: 0.33056
Value Function Update Magnitude: 0.32268

Collected Steps per Second: 14,512.93585
Overall Steps per Second: 7,183.31168

Timestep Collection Time: 3.44686
Timestep Consumption Time: 3.51706
PPO Batch Consumption Time: 0.47056
Total Iteration Time: 6.96392

Cumulative Model Updates: 265,274
Cumulative Timesteps: 2,212,933,542

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 73,349.47565
Policy Entropy: 2.73380
Value Function Loss: 0.01293

Mean KL Divergence: 0.00714
SB3 Clip Fraction: 0.06699
Policy Update Magnitude: 0.32198
Value Function Update Magnitude: 0.28306

Collected Steps per Second: 14,814.90170
Overall Steps per Second: 7,029.79359

Timestep Collection Time: 3.37606
Timestep Consumption Time: 3.73880
PPO Batch Consumption Time: 0.50559
Total Iteration Time: 7.11486

Cumulative Model Updates: 265,280
Cumulative Timesteps: 2,212,983,558

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2212983558...
Checkpoint 2212983558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 73,349.47565
Policy Entropy: 2.74695
Value Function Loss: 0.01111

Mean KL Divergence: 0.00705
SB3 Clip Fraction: 0.06593
Policy Update Magnitude: 0.30592
Value Function Update Magnitude: 0.28138

Collected Steps per Second: 14,743.45498
Overall Steps per Second: 6,938.02009

Timestep Collection Time: 3.39351
Timestep Consumption Time: 3.81777
PPO Batch Consumption Time: 0.51168
Total Iteration Time: 7.21128

Cumulative Model Updates: 265,286
Cumulative Timesteps: 2,213,033,590

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53,666.13981
Policy Entropy: 2.75029
Value Function Loss: 0.01129

Mean KL Divergence: 0.00713
SB3 Clip Fraction: 0.06489
Policy Update Magnitude: 0.30541
Value Function Update Magnitude: 0.28749

Collected Steps per Second: 15,301.70754
Overall Steps per Second: 7,248.54369

Timestep Collection Time: 3.26826
Timestep Consumption Time: 3.63105
PPO Batch Consumption Time: 0.47784
Total Iteration Time: 6.89932

Cumulative Model Updates: 265,292
Cumulative Timesteps: 2,213,083,600

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2213083600...
Checkpoint 2213083600 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 62,545.96483
Policy Entropy: 2.74459
Value Function Loss: 0.01244

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.07657
Policy Update Magnitude: 0.32109
Value Function Update Magnitude: 0.31817

Collected Steps per Second: 15,449.22828
Overall Steps per Second: 7,175.39090

Timestep Collection Time: 3.23822
Timestep Consumption Time: 3.73394
PPO Batch Consumption Time: 0.49726
Total Iteration Time: 6.97216

Cumulative Model Updates: 265,298
Cumulative Timesteps: 2,213,133,628

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 72,436.71201
Policy Entropy: 2.72793
Value Function Loss: 0.01288

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.08232
Policy Update Magnitude: 0.32610
Value Function Update Magnitude: 0.33792

Collected Steps per Second: 14,922.09324
Overall Steps per Second: 6,902.44096

Timestep Collection Time: 3.35194
Timestep Consumption Time: 3.89448
PPO Batch Consumption Time: 0.51366
Total Iteration Time: 7.24642

Cumulative Model Updates: 265,304
Cumulative Timesteps: 2,213,183,646

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2213183646...
Checkpoint 2213183646 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 72,436.71201
Policy Entropy: 2.71800
Value Function Loss: 0.01085

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.07052
Policy Update Magnitude: 0.31735
Value Function Update Magnitude: 0.32678

Collected Steps per Second: 15,390.52298
Overall Steps per Second: 7,023.23770

Timestep Collection Time: 3.24901
Timestep Consumption Time: 3.87078
PPO Batch Consumption Time: 0.51319
Total Iteration Time: 7.11979

Cumulative Model Updates: 265,310
Cumulative Timesteps: 2,213,233,650

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 72,436.71201
Policy Entropy: 2.73736
Value Function Loss: 0.00888

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.07634
Policy Update Magnitude: 0.29568
Value Function Update Magnitude: 0.28070

Collected Steps per Second: 15,370.46206
Overall Steps per Second: 7,382.11010

Timestep Collection Time: 3.25468
Timestep Consumption Time: 3.52197
PPO Batch Consumption Time: 0.45906
Total Iteration Time: 6.77665

Cumulative Model Updates: 265,316
Cumulative Timesteps: 2,213,283,676

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2213283676...
Checkpoint 2213283676 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 85,494.40381
Policy Entropy: 2.73959
Value Function Loss: 0.01046

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.07830
Policy Update Magnitude: 0.28910
Value Function Update Magnitude: 0.22379

Collected Steps per Second: 14,945.54806
Overall Steps per Second: 7,117.97375

Timestep Collection Time: 3.34722
Timestep Consumption Time: 3.68091
PPO Batch Consumption Time: 0.48131
Total Iteration Time: 7.02812

Cumulative Model Updates: 265,322
Cumulative Timesteps: 2,213,333,702

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92,720.93670
Policy Entropy: 2.70272
Value Function Loss: 0.01272

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.07278
Policy Update Magnitude: 0.31004
Value Function Update Magnitude: 0.26739

Collected Steps per Second: 14,997.96478
Overall Steps per Second: 7,377.14514

Timestep Collection Time: 3.33699
Timestep Consumption Time: 3.44721
PPO Batch Consumption Time: 0.44524
Total Iteration Time: 6.78420

Cumulative Model Updates: 265,328
Cumulative Timesteps: 2,213,383,750

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 2213383750...
Checkpoint 2213383750 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 105,585.14412
Policy Entropy: 2.69731
Value Function Loss: 0.01310

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.07105
Policy Update Magnitude: 0.32307
Value Function Update Magnitude: 0.31767

Collected Steps per Second: 15,820.95453
Overall Steps per Second: 7,576.83489

Timestep Collection Time: 3.16062
Timestep Consumption Time: 3.43897
PPO Batch Consumption Time: 0.44772
Total Iteration Time: 6.59959

Cumulative Model Updates: 265,334
Cumulative Timesteps: 2,213,433,754

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 105,585.14412
Policy Entropy: 2.69933
Value Function Loss: 0.01078

Mean KL Divergence: 0.00739
SB3 Clip Fraction: 0.06755
Policy Update Magnitude: 0.31480
Value Function Update Magnitude: 0.30547

Collected Steps per Second: 15,869.71732
Overall Steps per Second: 7,666.41126

Timestep Collection Time: 3.15242
Timestep Consumption Time: 3.37319
PPO Batch Consumption Time: 0.43398
Total Iteration Time: 6.52561

Cumulative Model Updates: 265,340
Cumulative Timesteps: 2,213,483,782

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2213483782...
Checkpoint 2213483782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 120,799.38477
Policy Entropy: 2.72052
Value Function Loss: 0.01044

Mean KL Divergence: 0.00694
SB3 Clip Fraction: 0.06804
Policy Update Magnitude: 0.30452
Value Function Update Magnitude: 0.28451

Collected Steps per Second: 15,495.47718
Overall Steps per Second: 7,557.37849

Timestep Collection Time: 3.22675
Timestep Consumption Time: 3.38930
PPO Batch Consumption Time: 0.43820
Total Iteration Time: 6.61605

Cumulative Model Updates: 265,346
Cumulative Timesteps: 2,213,533,782

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 74,842.94597
Policy Entropy: 2.73991
Value Function Loss: 0.01246

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.07186
Policy Update Magnitude: 0.30739
Value Function Update Magnitude: 0.29215

Collected Steps per Second: 16,150.75119
Overall Steps per Second: 7,560.32277

Timestep Collection Time: 3.09756
Timestep Consumption Time: 3.51961
PPO Batch Consumption Time: 0.46017
Total Iteration Time: 6.61718

Cumulative Model Updates: 265,352
Cumulative Timesteps: 2,213,583,810

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2213583810...
Checkpoint 2213583810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 67,845.07916
Policy Entropy: 2.74004
Value Function Loss: 0.01253

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.06800
Policy Update Magnitude: 0.30749
Value Function Update Magnitude: 0.32049

Collected Steps per Second: 14,973.74342
Overall Steps per Second: 8,585.49080

Timestep Collection Time: 3.34105
Timestep Consumption Time: 2.48599
PPO Batch Consumption Time: 0.30104
Total Iteration Time: 5.82704

Cumulative Model Updates: 265,358
Cumulative Timesteps: 2,213,633,838

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 73,602.81702
Policy Entropy: 2.74256
Value Function Loss: 0.01427

Mean KL Divergence: 0.00664
SB3 Clip Fraction: 0.06283
Policy Update Magnitude: 0.31696
Value Function Update Magnitude: 0.31267

Collected Steps per Second: 17,339.28790
Overall Steps per Second: 8,952.03782

Timestep Collection Time: 2.88397
Timestep Consumption Time: 2.70202
PPO Batch Consumption Time: 0.31358
Total Iteration Time: 5.58599

Cumulative Model Updates: 265,364
Cumulative Timesteps: 2,213,683,844

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2213683844...
Checkpoint 2213683844 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 94,583.54952
Policy Entropy: 2.72634
Value Function Loss: 0.01575

Mean KL Divergence: 0.00643
SB3 Clip Fraction: 0.06078
Policy Update Magnitude: 0.33431
Value Function Update Magnitude: 0.30633

Collected Steps per Second: 19,018.54959
Overall Steps per Second: 10,065.71012

Timestep Collection Time: 2.62943
Timestep Consumption Time: 2.33872
PPO Batch Consumption Time: 0.28841
Total Iteration Time: 4.96815

Cumulative Model Updates: 265,370
Cumulative Timesteps: 2,213,733,852

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 107,021.72442
Policy Entropy: 2.73266
Value Function Loss: 0.01462

Mean KL Divergence: 0.00743
SB3 Clip Fraction: 0.06626
Policy Update Magnitude: 0.32924
Value Function Update Magnitude: 0.30200

Collected Steps per Second: 20,167.09348
Overall Steps per Second: 9,996.76193

Timestep Collection Time: 2.48058
Timestep Consumption Time: 2.52364
PPO Batch Consumption Time: 0.29696
Total Iteration Time: 5.00422

Cumulative Model Updates: 265,376
Cumulative Timesteps: 2,213,783,878

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2213783878...
Checkpoint 2213783878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 71,714.18888
Policy Entropy: 2.72118
Value Function Loss: 0.01390

Mean KL Divergence: 0.00703
SB3 Clip Fraction: 0.06300
Policy Update Magnitude: 0.32214
Value Function Update Magnitude: 0.28947

Collected Steps per Second: 18,781.22078
Overall Steps per Second: 9,553.12385

Timestep Collection Time: 2.66383
Timestep Consumption Time: 2.57320
PPO Batch Consumption Time: 0.30906
Total Iteration Time: 5.23703

Cumulative Model Updates: 265,382
Cumulative Timesteps: 2,213,833,908

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2213833908...
Checkpoint 2213833908 saved!
