{"Mean KL Divergence":0.008523849925647179,"Policy Entropy":3.4686502615610757,"_timestamp":1.7387810549121103e+09,"Timestep Consumption Time":5.824629700000514,"Collected Steps per Second":14290.685256956895,"Overall Steps per Second":5364.317329386054,"Cumulative Timesteps":500708334,"Policy Reward":1430.961485744439,"Value Function Loss":0.003331785167877873,"SB3 Clip Fraction":0.09898999705910683,"_wandb":{"runtime":49127},"Timestep Collection Time":3.500321999999869,"y_vel":36.29866622473255,"Cumulative Model Updates":60026,"z_vel":3.718396974726664,"Timesteps Collected":50022,"Policy Update Magnitude":0.5578063130378723,"x_vel":12.410479771665962,"_runtime":49127.5173353,"_step":20021,"PPO Batch Consumption Time":0.8033364613850912,"Value Function Update Magnitude":0.6434407830238342,"Total Iteration Time":9.324951700000383}