Checkpoint loaded!
Learner successfully initialized!
Press (p) to pause (c) to checkpoint, (q) to checkpoint and quit (after next iteration)

--------BEGIN ITERATION REPORT--------
Policy Reward: 426.20492
Policy Entropy: 2.82126
Value Function Loss: 0.00389

Mean KL Divergence: 0.00023
SB3 Clip Fraction: 0.00032
Policy Update Magnitude: 0.13540
Value Function Update Magnitude: 0.11010

Collected Steps per Second: 7,533.99338
Overall Steps per Second: 4,375.49417

Timestep Collection Time: 6.63924
Timestep Consumption Time: 4.79261
PPO Batch Consumption Time: 1.92464
Total Iteration Time: 11.43185

Cumulative Model Updates: 48,698
Cumulative Timesteps: 406,226,996

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 780.03078
Policy Entropy: 2.84843
Value Function Loss: 0.00407

Mean KL Divergence: 0.00139
SB3 Clip Fraction: 0.01155
Policy Update Magnitude: 0.14747
Value Function Update Magnitude: 0.11563

Collected Steps per Second: 20,411.14460
Overall Steps per Second: 13,154.90097

Timestep Collection Time: 2.44994
Timestep Consumption Time: 1.35138
PPO Batch Consumption Time: 0.34276
Total Iteration Time: 3.80132

Cumulative Model Updates: 48,700
Cumulative Timesteps: 406,277,002

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 406277002...
Checkpoint 406277002 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,001.85615
Policy Entropy: 2.87355
Value Function Loss: 0.00393

Mean KL Divergence: 0.00354
SB3 Clip Fraction: 0.03599
Policy Update Magnitude: 0.28356
Value Function Update Magnitude: 0.22575

Collected Steps per Second: 21,405.44347
Overall Steps per Second: 11,716.61097

Timestep Collection Time: 2.33604
Timestep Consumption Time: 1.93175
PPO Batch Consumption Time: 0.30672
Total Iteration Time: 4.26779

Cumulative Model Updates: 48,704
Cumulative Timesteps: 406,327,006

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 937.57607
Policy Entropy: 2.91732
Value Function Loss: 0.00366

Mean KL Divergence: 0.00416
SB3 Clip Fraction: 0.04318
Policy Update Magnitude: 0.39560
Value Function Update Magnitude: 0.32641

Collected Steps per Second: 21,554.90631
Overall Steps per Second: 10,517.53312

Timestep Collection Time: 2.32031
Timestep Consumption Time: 2.43499
PPO Batch Consumption Time: 0.29149
Total Iteration Time: 4.75530

Cumulative Model Updates: 48,710
Cumulative Timesteps: 406,377,020

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 406377020...
Checkpoint 406377020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,394.46155
Policy Entropy: 2.93887
Value Function Loss: 0.00328

Mean KL Divergence: 0.00422
SB3 Clip Fraction: 0.04407
Policy Update Magnitude: 0.37398
Value Function Update Magnitude: 0.30254

Collected Steps per Second: 20,560.71885
Overall Steps per Second: 10,231.15508

Timestep Collection Time: 2.43250
Timestep Consumption Time: 2.45590
PPO Batch Consumption Time: 0.29558
Total Iteration Time: 4.88840

Cumulative Model Updates: 48,716
Cumulative Timesteps: 406,427,034

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,358.82880
Policy Entropy: 2.94923
Value Function Loss: 0.00325

Mean KL Divergence: 0.00413
SB3 Clip Fraction: 0.04363
Policy Update Magnitude: 0.35799
Value Function Update Magnitude: 0.28178

Collected Steps per Second: 21,491.89053
Overall Steps per Second: 10,470.85574

Timestep Collection Time: 2.32646
Timestep Consumption Time: 2.44870
PPO Batch Consumption Time: 0.29568
Total Iteration Time: 4.77516

Cumulative Model Updates: 48,722
Cumulative Timesteps: 406,477,034

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 406477034...
Checkpoint 406477034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,119.86641
Policy Entropy: 2.94515
Value Function Loss: 0.00327

Mean KL Divergence: 0.00412
SB3 Clip Fraction: 0.04407
Policy Update Magnitude: 0.35204
Value Function Update Magnitude: 0.29464

Collected Steps per Second: 21,684.44964
Overall Steps per Second: 10,548.70138

Timestep Collection Time: 2.30691
Timestep Consumption Time: 2.43529
PPO Batch Consumption Time: 0.29099
Total Iteration Time: 4.74220

Cumulative Model Updates: 48,728
Cumulative Timesteps: 406,527,058

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 757.08989
Policy Entropy: 2.94296
Value Function Loss: 0.00332

Mean KL Divergence: 0.00400
SB3 Clip Fraction: 0.04175
Policy Update Magnitude: 0.35526
Value Function Update Magnitude: 0.29764

Collected Steps per Second: 21,630.07315
Overall Steps per Second: 10,494.74664

Timestep Collection Time: 2.31169
Timestep Consumption Time: 2.45279
PPO Batch Consumption Time: 0.29508
Total Iteration Time: 4.76448

Cumulative Model Updates: 48,734
Cumulative Timesteps: 406,577,060

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 406577060...
Checkpoint 406577060 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,897.47305
Policy Entropy: 2.95554
Value Function Loss: 0.00335

Mean KL Divergence: 0.00429
SB3 Clip Fraction: 0.04555
Policy Update Magnitude: 0.36201
Value Function Update Magnitude: 0.30339

Collected Steps per Second: 21,113.47751
Overall Steps per Second: 10,327.69423

Timestep Collection Time: 2.36816
Timestep Consumption Time: 2.47320
PPO Batch Consumption Time: 0.29692
Total Iteration Time: 4.84135

Cumulative Model Updates: 48,740
Cumulative Timesteps: 406,627,060

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,326.92370
Policy Entropy: 2.95921
Value Function Loss: 0.00345

Mean KL Divergence: 0.00439
SB3 Clip Fraction: 0.04698
Policy Update Magnitude: 0.36932
Value Function Update Magnitude: 0.31156

Collected Steps per Second: 21,232.67783
Overall Steps per Second: 10,432.83632

Timestep Collection Time: 2.35599
Timestep Consumption Time: 2.43887
PPO Batch Consumption Time: 0.29393
Total Iteration Time: 4.79486

Cumulative Model Updates: 48,746
Cumulative Timesteps: 406,677,084

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 406677084...
Checkpoint 406677084 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 949.50851
Policy Entropy: 2.96088
Value Function Loss: 0.00354

Mean KL Divergence: 0.00423
SB3 Clip Fraction: 0.04483
Policy Update Magnitude: 0.37510
Value Function Update Magnitude: 0.30425

Collected Steps per Second: 21,068.41940
Overall Steps per Second: 10,536.47343

Timestep Collection Time: 2.37332
Timestep Consumption Time: 2.37230
PPO Batch Consumption Time: 0.28010
Total Iteration Time: 4.74561

Cumulative Model Updates: 48,752
Cumulative Timesteps: 406,727,086

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,142.38383
Policy Entropy: 2.96958
Value Function Loss: 0.00352

Mean KL Divergence: 0.00405
SB3 Clip Fraction: 0.04197
Policy Update Magnitude: 0.37899
Value Function Update Magnitude: 0.30127

Collected Steps per Second: 21,224.48183
Overall Steps per Second: 10,430.55749

Timestep Collection Time: 2.35634
Timestep Consumption Time: 2.43842
PPO Batch Consumption Time: 0.28983
Total Iteration Time: 4.79476

Cumulative Model Updates: 48,758
Cumulative Timesteps: 406,777,098

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 406777098...
Checkpoint 406777098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 712.71498
Policy Entropy: 2.98008
Value Function Loss: 0.00349

Mean KL Divergence: 0.00412
SB3 Clip Fraction: 0.04327
Policy Update Magnitude: 0.37799
Value Function Update Magnitude: 0.29652

Collected Steps per Second: 21,148.85128
Overall Steps per Second: 10,558.92397

Timestep Collection Time: 2.36419
Timestep Consumption Time: 2.37114
PPO Batch Consumption Time: 0.28079
Total Iteration Time: 4.73533

Cumulative Model Updates: 48,764
Cumulative Timesteps: 406,827,098

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 921.99553
Policy Entropy: 2.98205
Value Function Loss: 0.00352

Mean KL Divergence: 0.00421
SB3 Clip Fraction: 0.04436
Policy Update Magnitude: 0.38177
Value Function Update Magnitude: 0.29103

Collected Steps per Second: 21,452.99478
Overall Steps per Second: 10,443.68935

Timestep Collection Time: 2.33161
Timestep Consumption Time: 2.45789
PPO Batch Consumption Time: 0.29522
Total Iteration Time: 4.78950

Cumulative Model Updates: 48,770
Cumulative Timesteps: 406,877,118

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 406877118...
Checkpoint 406877118 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,185.00735
Policy Entropy: 2.98714
Value Function Loss: 0.00339

Mean KL Divergence: 0.00419
SB3 Clip Fraction: 0.04461
Policy Update Magnitude: 0.38174
Value Function Update Magnitude: 0.29334

Collected Steps per Second: 21,362.21650
Overall Steps per Second: 10,255.01250

Timestep Collection Time: 2.34142
Timestep Consumption Time: 2.53600
PPO Batch Consumption Time: 0.30447
Total Iteration Time: 4.87742

Cumulative Model Updates: 48,776
Cumulative Timesteps: 406,927,136

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,030.81627
Policy Entropy: 2.97896
Value Function Loss: 0.00328

Mean KL Divergence: 0.00374
SB3 Clip Fraction: 0.03859
Policy Update Magnitude: 0.38915
Value Function Update Magnitude: 0.29727

Collected Steps per Second: 21,980.50359
Overall Steps per Second: 10,530.53448

Timestep Collection Time: 2.27520
Timestep Consumption Time: 2.47385
PPO Batch Consumption Time: 0.29583
Total Iteration Time: 4.74905

Cumulative Model Updates: 48,782
Cumulative Timesteps: 406,977,146

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 406977146...
Checkpoint 406977146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 757.63310
Policy Entropy: 2.98923
Value Function Loss: 0.00319

Mean KL Divergence: 0.00366
SB3 Clip Fraction: 0.03776
Policy Update Magnitude: 0.38385
Value Function Update Magnitude: 0.28988

Collected Steps per Second: 21,629.05781
Overall Steps per Second: 10,590.71176

Timestep Collection Time: 2.31272
Timestep Consumption Time: 2.41047
PPO Batch Consumption Time: 0.28701
Total Iteration Time: 4.72320

Cumulative Model Updates: 48,788
Cumulative Timesteps: 407,027,168

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,087.50808
Policy Entropy: 2.97774
Value Function Loss: 0.00341

Mean KL Divergence: 0.00393
SB3 Clip Fraction: 0.04119
Policy Update Magnitude: 0.38253
Value Function Update Magnitude: 0.29120

Collected Steps per Second: 22,042.32680
Overall Steps per Second: 10,626.09124

Timestep Collection Time: 2.26845
Timestep Consumption Time: 2.43713
PPO Batch Consumption Time: 0.29264
Total Iteration Time: 4.70559

Cumulative Model Updates: 48,794
Cumulative Timesteps: 407,077,170

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 407077170...
Checkpoint 407077170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,066.41358
Policy Entropy: 2.98666
Value Function Loss: 0.00348

Mean KL Divergence: 0.00384
SB3 Clip Fraction: 0.04031
Policy Update Magnitude: 0.38145
Value Function Update Magnitude: 0.31355

Collected Steps per Second: 21,356.49977
Overall Steps per Second: 10,467.44232

Timestep Collection Time: 2.34233
Timestep Consumption Time: 2.43668
PPO Batch Consumption Time: 0.29085
Total Iteration Time: 4.77901

Cumulative Model Updates: 48,800
Cumulative Timesteps: 407,127,194

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,012.38215
Policy Entropy: 2.97633
Value Function Loss: 0.00361

Mean KL Divergence: 0.00376
SB3 Clip Fraction: 0.03819
Policy Update Magnitude: 0.38033
Value Function Update Magnitude: 0.31972

Collected Steps per Second: 21,808.32731
Overall Steps per Second: 10,554.09127

Timestep Collection Time: 2.29270
Timestep Consumption Time: 2.44480
PPO Batch Consumption Time: 0.29471
Total Iteration Time: 4.73750

Cumulative Model Updates: 48,806
Cumulative Timesteps: 407,177,194

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 407177194...
Checkpoint 407177194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,729.96429
Policy Entropy: 2.99064
Value Function Loss: 0.00337

Mean KL Divergence: 0.00383
SB3 Clip Fraction: 0.03955
Policy Update Magnitude: 0.38085
Value Function Update Magnitude: 0.31880

Collected Steps per Second: 21,358.24577
Overall Steps per Second: 10,454.57551

Timestep Collection Time: 2.34233
Timestep Consumption Time: 2.44295
PPO Batch Consumption Time: 0.29562
Total Iteration Time: 4.78527

Cumulative Model Updates: 48,812
Cumulative Timesteps: 407,227,222

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,156.35052
Policy Entropy: 2.98700
Value Function Loss: 0.00335

Mean KL Divergence: 0.00391
SB3 Clip Fraction: 0.04143
Policy Update Magnitude: 0.37071
Value Function Update Magnitude: 0.30064

Collected Steps per Second: 22,304.52344
Overall Steps per Second: 10,824.50989

Timestep Collection Time: 2.24295
Timestep Consumption Time: 2.37878
PPO Batch Consumption Time: 0.28103
Total Iteration Time: 4.62173

Cumulative Model Updates: 48,818
Cumulative Timesteps: 407,277,250

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 407277250...
Checkpoint 407277250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 950.70399
Policy Entropy: 3.01364
Value Function Loss: 0.00332

Mean KL Divergence: 0.00389
SB3 Clip Fraction: 0.03992
Policy Update Magnitude: 0.36846
Value Function Update Magnitude: 0.29560

Collected Steps per Second: 20,891.07238
Overall Steps per Second: 10,360.21330

Timestep Collection Time: 2.39490
Timestep Consumption Time: 2.43435
PPO Batch Consumption Time: 0.29327
Total Iteration Time: 4.82924

Cumulative Model Updates: 48,824
Cumulative Timesteps: 407,327,282

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,006.88783
Policy Entropy: 3.00414
Value Function Loss: 0.00345

Mean KL Divergence: 0.00387
SB3 Clip Fraction: 0.04005
Policy Update Magnitude: 0.37309
Value Function Update Magnitude: 0.29463

Collected Steps per Second: 21,527.72294
Overall Steps per Second: 10,637.58841

Timestep Collection Time: 2.32361
Timestep Consumption Time: 2.37877
PPO Batch Consumption Time: 0.28156
Total Iteration Time: 4.70238

Cumulative Model Updates: 48,830
Cumulative Timesteps: 407,377,304

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 407377304...
Checkpoint 407377304 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 986.46323
Policy Entropy: 3.01559
Value Function Loss: 0.00356

Mean KL Divergence: 0.00420
SB3 Clip Fraction: 0.04535
Policy Update Magnitude: 0.36753
Value Function Update Magnitude: 0.29683

Collected Steps per Second: 21,031.19368
Overall Steps per Second: 10,384.01722

Timestep Collection Time: 2.37828
Timestep Consumption Time: 2.43855
PPO Batch Consumption Time: 0.29538
Total Iteration Time: 4.81683

Cumulative Model Updates: 48,836
Cumulative Timesteps: 407,427,322

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,357.61538
Policy Entropy: 3.01358
Value Function Loss: 0.00342

Mean KL Divergence: 0.00396
SB3 Clip Fraction: 0.04031
Policy Update Magnitude: 0.36628
Value Function Update Magnitude: 0.29941

Collected Steps per Second: 21,479.69525
Overall Steps per Second: 10,445.97194

Timestep Collection Time: 2.32806
Timestep Consumption Time: 2.45905
PPO Batch Consumption Time: 0.29543
Total Iteration Time: 4.78711

Cumulative Model Updates: 48,842
Cumulative Timesteps: 407,477,328

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 407477328...
Checkpoint 407477328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,024.87462
Policy Entropy: 3.03690
Value Function Loss: 0.00338

Mean KL Divergence: 0.00409
SB3 Clip Fraction: 0.04331
Policy Update Magnitude: 0.36387
Value Function Update Magnitude: 0.30164

Collected Steps per Second: 21,119.78245
Overall Steps per Second: 10,450.48007

Timestep Collection Time: 2.36877
Timestep Consumption Time: 2.41837
PPO Batch Consumption Time: 0.28616
Total Iteration Time: 4.78715

Cumulative Model Updates: 48,848
Cumulative Timesteps: 407,527,356

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,219.28645
Policy Entropy: 3.02617
Value Function Loss: 0.00334

Mean KL Divergence: 0.00425
SB3 Clip Fraction: 0.04406
Policy Update Magnitude: 0.35613
Value Function Update Magnitude: 0.29703

Collected Steps per Second: 21,377.10228
Overall Steps per Second: 10,532.00322

Timestep Collection Time: 2.34017
Timestep Consumption Time: 2.40974
PPO Batch Consumption Time: 0.28741
Total Iteration Time: 4.74990

Cumulative Model Updates: 48,854
Cumulative Timesteps: 407,577,382

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 407577382...
Checkpoint 407577382 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 683.86274
Policy Entropy: 3.03716
Value Function Loss: 0.00342

Mean KL Divergence: 0.00414
SB3 Clip Fraction: 0.04312
Policy Update Magnitude: 0.36068
Value Function Update Magnitude: 0.28955

Collected Steps per Second: 21,241.30439
Overall Steps per Second: 10,366.13941

Timestep Collection Time: 2.35456
Timestep Consumption Time: 2.47018
PPO Batch Consumption Time: 0.29431
Total Iteration Time: 4.82475

Cumulative Model Updates: 48,860
Cumulative Timesteps: 407,627,396

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,356.96717
Policy Entropy: 3.02146
Value Function Loss: 0.00330

Mean KL Divergence: 0.00427
SB3 Clip Fraction: 0.04483
Policy Update Magnitude: 0.35781
Value Function Update Magnitude: 0.29166

Collected Steps per Second: 21,801.47327
Overall Steps per Second: 10,669.48193

Timestep Collection Time: 2.29370
Timestep Consumption Time: 2.39313
PPO Batch Consumption Time: 0.28158
Total Iteration Time: 4.68683

Cumulative Model Updates: 48,866
Cumulative Timesteps: 407,677,402

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 407677402...
Checkpoint 407677402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,602.79450
Policy Entropy: 3.03673
Value Function Loss: 0.00324

Mean KL Divergence: 0.00455
SB3 Clip Fraction: 0.04785
Policy Update Magnitude: 0.35084
Value Function Update Magnitude: 0.28778

Collected Steps per Second: 22,141.59456
Overall Steps per Second: 10,473.73528

Timestep Collection Time: 2.25892
Timestep Consumption Time: 2.51646
PPO Batch Consumption Time: 0.29173
Total Iteration Time: 4.77537

Cumulative Model Updates: 48,872
Cumulative Timesteps: 407,727,418

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 873.50033
Policy Entropy: 3.03085
Value Function Loss: 0.00333

Mean KL Divergence: 0.00417
SB3 Clip Fraction: 0.04481
Policy Update Magnitude: 0.34703
Value Function Update Magnitude: 0.28532

Collected Steps per Second: 23,130.52890
Overall Steps per Second: 10,739.47746

Timestep Collection Time: 2.16225
Timestep Consumption Time: 2.49477
PPO Batch Consumption Time: 0.29030
Total Iteration Time: 4.65702

Cumulative Model Updates: 48,878
Cumulative Timesteps: 407,777,432

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 407777432...
Checkpoint 407777432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 879.88150
Policy Entropy: 3.03487
Value Function Loss: 0.00351

Mean KL Divergence: 0.00446
SB3 Clip Fraction: 0.04711
Policy Update Magnitude: 0.35447
Value Function Update Magnitude: 0.29438

Collected Steps per Second: 21,751.94580
Overall Steps per Second: 10,621.22373

Timestep Collection Time: 2.29938
Timestep Consumption Time: 2.40968
PPO Batch Consumption Time: 0.28712
Total Iteration Time: 4.70906

Cumulative Model Updates: 48,884
Cumulative Timesteps: 407,827,448

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,560.50418
Policy Entropy: 3.03838
Value Function Loss: 0.00352

Mean KL Divergence: 0.00400
SB3 Clip Fraction: 0.04076
Policy Update Magnitude: 0.36458
Value Function Update Magnitude: 0.29932

Collected Steps per Second: 22,051.16785
Overall Steps per Second: 10,556.38174

Timestep Collection Time: 2.26764
Timestep Consumption Time: 2.46922
PPO Batch Consumption Time: 0.29824
Total Iteration Time: 4.73685

Cumulative Model Updates: 48,890
Cumulative Timesteps: 407,877,452

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 407877452...
Checkpoint 407877452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,204.85700
Policy Entropy: 3.05357
Value Function Loss: 0.00344

Mean KL Divergence: 0.00374
SB3 Clip Fraction: 0.03729
Policy Update Magnitude: 0.37460
Value Function Update Magnitude: 0.31423

Collected Steps per Second: 21,721.26106
Overall Steps per Second: 10,524.58109

Timestep Collection Time: 2.30392
Timestep Consumption Time: 2.45105
PPO Batch Consumption Time: 0.29414
Total Iteration Time: 4.75496

Cumulative Model Updates: 48,896
Cumulative Timesteps: 407,927,496

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,400.34086
Policy Entropy: 3.04681
Value Function Loss: 0.00344

Mean KL Divergence: 0.00424
SB3 Clip Fraction: 0.04470
Policy Update Magnitude: 0.37653
Value Function Update Magnitude: 0.33089

Collected Steps per Second: 21,277.92467
Overall Steps per Second: 10,489.25044

Timestep Collection Time: 2.35032
Timestep Consumption Time: 2.41741
PPO Batch Consumption Time: 0.28773
Total Iteration Time: 4.76774

Cumulative Model Updates: 48,902
Cumulative Timesteps: 407,977,506

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 407977506...
Checkpoint 407977506 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,387.32321
Policy Entropy: 3.04027
Value Function Loss: 0.00361

Mean KL Divergence: 0.00428
SB3 Clip Fraction: 0.04459
Policy Update Magnitude: 0.37668
Value Function Update Magnitude: 0.34145

Collected Steps per Second: 21,241.48069
Overall Steps per Second: 10,539.64077

Timestep Collection Time: 2.35530
Timestep Consumption Time: 2.39154
PPO Batch Consumption Time: 0.28135
Total Iteration Time: 4.74684

Cumulative Model Updates: 48,908
Cumulative Timesteps: 408,027,536

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,398.07123
Policy Entropy: 3.03512
Value Function Loss: 0.00360

Mean KL Divergence: 0.00425
SB3 Clip Fraction: 0.04495
Policy Update Magnitude: 0.38926
Value Function Update Magnitude: 0.34211

Collected Steps per Second: 21,774.99758
Overall Steps per Second: 10,541.57822

Timestep Collection Time: 2.29658
Timestep Consumption Time: 2.44730
PPO Batch Consumption Time: 0.29288
Total Iteration Time: 4.74388

Cumulative Model Updates: 48,914
Cumulative Timesteps: 408,077,544

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 408077544...
Checkpoint 408077544 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,718.21652
Policy Entropy: 3.04507
Value Function Loss: 0.00349

Mean KL Divergence: 0.00409
SB3 Clip Fraction: 0.04295
Policy Update Magnitude: 0.38777
Value Function Update Magnitude: 0.33241

Collected Steps per Second: 21,601.09237
Overall Steps per Second: 10,625.84851

Timestep Collection Time: 2.31664
Timestep Consumption Time: 2.39282
PPO Batch Consumption Time: 0.28226
Total Iteration Time: 4.70946

Cumulative Model Updates: 48,920
Cumulative Timesteps: 408,127,586

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 810.92414
Policy Entropy: 3.04546
Value Function Loss: 0.00328

Mean KL Divergence: 0.00391
SB3 Clip Fraction: 0.03969
Policy Update Magnitude: 0.38235
Value Function Update Magnitude: 0.31897

Collected Steps per Second: 22,081.05976
Overall Steps per Second: 10,550.87564

Timestep Collection Time: 2.26538
Timestep Consumption Time: 2.47565
PPO Batch Consumption Time: 0.29585
Total Iteration Time: 4.74103

Cumulative Model Updates: 48,926
Cumulative Timesteps: 408,177,608

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 408177608...
Checkpoint 408177608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,652.28086
Policy Entropy: 3.04157
Value Function Loss: 0.00326

Mean KL Divergence: 0.00401
SB3 Clip Fraction: 0.04158
Policy Update Magnitude: 0.37800
Value Function Update Magnitude: 0.30212

Collected Steps per Second: 21,637.36081
Overall Steps per Second: 10,525.95553

Timestep Collection Time: 2.31119
Timestep Consumption Time: 2.43974
PPO Batch Consumption Time: 0.29189
Total Iteration Time: 4.75092

Cumulative Model Updates: 48,932
Cumulative Timesteps: 408,227,616

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,283.77029
Policy Entropy: 3.03552
Value Function Loss: 0.00324

Mean KL Divergence: 0.00406
SB3 Clip Fraction: 0.04176
Policy Update Magnitude: 0.37868
Value Function Update Magnitude: 0.28829

Collected Steps per Second: 21,764.24278
Overall Steps per Second: 10,498.36731

Timestep Collection Time: 2.29854
Timestep Consumption Time: 2.46658
PPO Batch Consumption Time: 0.29678
Total Iteration Time: 4.76512

Cumulative Model Updates: 48,938
Cumulative Timesteps: 408,277,642

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 408277642...
Checkpoint 408277642 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,388.88777
Policy Entropy: 3.05693
Value Function Loss: 0.00321

Mean KL Divergence: 0.00417
SB3 Clip Fraction: 0.04554
Policy Update Magnitude: 0.37500
Value Function Update Magnitude: 0.27951

Collected Steps per Second: 21,827.81284
Overall Steps per Second: 10,637.46780

Timestep Collection Time: 2.29093
Timestep Consumption Time: 2.41000
PPO Batch Consumption Time: 0.28738
Total Iteration Time: 4.70093

Cumulative Model Updates: 48,944
Cumulative Timesteps: 408,327,648

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 596.74767
Policy Entropy: 3.04893
Value Function Loss: 0.00346

Mean KL Divergence: 0.00374
SB3 Clip Fraction: 0.03865
Policy Update Magnitude: 0.37415
Value Function Update Magnitude: 0.28579

Collected Steps per Second: 22,395.71154
Overall Steps per Second: 10,844.70104

Timestep Collection Time: 2.23320
Timestep Consumption Time: 2.37864
PPO Batch Consumption Time: 0.28192
Total Iteration Time: 4.61184

Cumulative Model Updates: 48,950
Cumulative Timesteps: 408,377,662

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 408377662...
Checkpoint 408377662 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,478.00467
Policy Entropy: 3.05717
Value Function Loss: 0.00332

Mean KL Divergence: 0.00369
SB3 Clip Fraction: 0.03797
Policy Update Magnitude: 0.37550
Value Function Update Magnitude: 0.29498

Collected Steps per Second: 21,615.25342
Overall Steps per Second: 10,675.16649

Timestep Collection Time: 2.31318
Timestep Consumption Time: 2.37059
PPO Batch Consumption Time: 0.28138
Total Iteration Time: 4.68377

Cumulative Model Updates: 48,956
Cumulative Timesteps: 408,427,662

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,121.66898
Policy Entropy: 3.05241
Value Function Loss: 0.00348

Mean KL Divergence: 0.00410
SB3 Clip Fraction: 0.04374
Policy Update Magnitude: 0.37676
Value Function Update Magnitude: 0.29121

Collected Steps per Second: 21,929.03598
Overall Steps per Second: 10,599.41576

Timestep Collection Time: 2.28036
Timestep Consumption Time: 2.43745
PPO Batch Consumption Time: 0.29425
Total Iteration Time: 4.71781

Cumulative Model Updates: 48,962
Cumulative Timesteps: 408,477,668

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 408477668...
Checkpoint 408477668 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,562.74295
Policy Entropy: 3.06816
Value Function Loss: 0.00322

Mean KL Divergence: 0.00384
SB3 Clip Fraction: 0.03974
Policy Update Magnitude: 0.36985
Value Function Update Magnitude: 0.27138

Collected Steps per Second: 21,519.47215
Overall Steps per Second: 10,557.13634

Timestep Collection Time: 2.32403
Timestep Consumption Time: 2.41323
PPO Batch Consumption Time: 0.28891
Total Iteration Time: 4.73727

Cumulative Model Updates: 48,968
Cumulative Timesteps: 408,527,680

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,044.52659
Policy Entropy: 3.07140
Value Function Loss: 0.00338

Mean KL Divergence: 0.00409
SB3 Clip Fraction: 0.04224
Policy Update Magnitude: 0.36145
Value Function Update Magnitude: 0.25823

Collected Steps per Second: 21,846.73835
Overall Steps per Second: 10,622.26064

Timestep Collection Time: 2.28895
Timestep Consumption Time: 2.41872
PPO Batch Consumption Time: 0.29178
Total Iteration Time: 4.70766

Cumulative Model Updates: 48,974
Cumulative Timesteps: 408,577,686

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 408577686...
Checkpoint 408577686 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,098.36052
Policy Entropy: 3.06628
Value Function Loss: 0.00353

Mean KL Divergence: 0.00413
SB3 Clip Fraction: 0.04331
Policy Update Magnitude: 0.36641
Value Function Update Magnitude: 0.27044

Collected Steps per Second: 22,024.77673
Overall Steps per Second: 10,459.67542

Timestep Collection Time: 2.27053
Timestep Consumption Time: 2.51049
PPO Batch Consumption Time: 0.29523
Total Iteration Time: 4.78103

Cumulative Model Updates: 48,980
Cumulative Timesteps: 408,627,694

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 835.28959
Policy Entropy: 3.05300
Value Function Loss: 0.00350

Mean KL Divergence: 0.00449
SB3 Clip Fraction: 0.04774
Policy Update Magnitude: 0.37805
Value Function Update Magnitude: 0.28400

Collected Steps per Second: 22,458.70568
Overall Steps per Second: 10,551.33911

Timestep Collection Time: 2.22738
Timestep Consumption Time: 2.51363
PPO Batch Consumption Time: 0.29441
Total Iteration Time: 4.74101

Cumulative Model Updates: 48,986
Cumulative Timesteps: 408,677,718

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 408677718...
Checkpoint 408677718 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,149.49202
Policy Entropy: 3.06136
Value Function Loss: 0.00341

Mean KL Divergence: 0.00411
SB3 Clip Fraction: 0.04286
Policy Update Magnitude: 0.37440
Value Function Update Magnitude: 0.28512

Collected Steps per Second: 22,407.58897
Overall Steps per Second: 10,506.68382

Timestep Collection Time: 2.23174
Timestep Consumption Time: 2.52789
PPO Batch Consumption Time: 0.29468
Total Iteration Time: 4.75964

Cumulative Model Updates: 48,992
Cumulative Timesteps: 408,727,726

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 900.69336
Policy Entropy: 3.06028
Value Function Loss: 0.00335

Mean KL Divergence: 0.00390
SB3 Clip Fraction: 0.03972
Policy Update Magnitude: 0.37212
Value Function Update Magnitude: 0.28543

Collected Steps per Second: 22,897.39598
Overall Steps per Second: 10,589.02006

Timestep Collection Time: 2.18418
Timestep Consumption Time: 2.53883
PPO Batch Consumption Time: 0.29364
Total Iteration Time: 4.72301

Cumulative Model Updates: 48,998
Cumulative Timesteps: 408,777,738

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 408777738...
Checkpoint 408777738 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,842.31090
Policy Entropy: 3.07757
Value Function Loss: 0.00334

Mean KL Divergence: 0.00426
SB3 Clip Fraction: 0.04465
Policy Update Magnitude: 0.37322
Value Function Update Magnitude: 0.29262

Collected Steps per Second: 21,913.83963
Overall Steps per Second: 10,564.85756

Timestep Collection Time: 2.28203
Timestep Consumption Time: 2.45140
PPO Batch Consumption Time: 0.29587
Total Iteration Time: 4.73343

Cumulative Model Updates: 49,004
Cumulative Timesteps: 408,827,746

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,093.63663
Policy Entropy: 3.08356
Value Function Loss: 0.00324

Mean KL Divergence: 0.00408
SB3 Clip Fraction: 0.04192
Policy Update Magnitude: 0.36151
Value Function Update Magnitude: 0.28989

Collected Steps per Second: 21,775.00425
Overall Steps per Second: 10,310.09013

Timestep Collection Time: 2.29639
Timestep Consumption Time: 2.55361
PPO Batch Consumption Time: 0.31109
Total Iteration Time: 4.85001

Cumulative Model Updates: 49,010
Cumulative Timesteps: 408,877,750

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 408877750...
Checkpoint 408877750 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,492.01251
Policy Entropy: 3.09569
Value Function Loss: 0.00316

Mean KL Divergence: 0.00384
SB3 Clip Fraction: 0.03961
Policy Update Magnitude: 0.35603
Value Function Update Magnitude: 0.27499

Collected Steps per Second: 21,274.56382
Overall Steps per Second: 10,407.57381

Timestep Collection Time: 2.35182
Timestep Consumption Time: 2.45564
PPO Batch Consumption Time: 0.29567
Total Iteration Time: 4.80746

Cumulative Model Updates: 49,016
Cumulative Timesteps: 408,927,784

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,029.37993
Policy Entropy: 3.08350
Value Function Loss: 0.00322

Mean KL Divergence: 0.00390
SB3 Clip Fraction: 0.03993
Policy Update Magnitude: 0.36237
Value Function Update Magnitude: 0.25767

Collected Steps per Second: 22,469.86014
Overall Steps per Second: 10,571.26792

Timestep Collection Time: 2.22529
Timestep Consumption Time: 2.50470
PPO Batch Consumption Time: 0.28983
Total Iteration Time: 4.72999

Cumulative Model Updates: 49,022
Cumulative Timesteps: 408,977,786

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 408977786...
Checkpoint 408977786 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 588.35428
Policy Entropy: 3.08610
Value Function Loss: 0.00331

Mean KL Divergence: 0.00440
SB3 Clip Fraction: 0.04663
Policy Update Magnitude: 0.37006
Value Function Update Magnitude: 0.25922

Collected Steps per Second: 22,537.85512
Overall Steps per Second: 10,633.03388

Timestep Collection Time: 2.21955
Timestep Consumption Time: 2.48503
PPO Batch Consumption Time: 0.29180
Total Iteration Time: 4.70458

Cumulative Model Updates: 49,028
Cumulative Timesteps: 409,027,810

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,272.70395
Policy Entropy: 3.08183
Value Function Loss: 0.00331

Mean KL Divergence: 0.00454
SB3 Clip Fraction: 0.04914
Policy Update Magnitude: 0.36373
Value Function Update Magnitude: 0.26323

Collected Steps per Second: 22,239.03311
Overall Steps per Second: 10,729.74537

Timestep Collection Time: 2.24947
Timestep Consumption Time: 2.41290
PPO Batch Consumption Time: 0.28632
Total Iteration Time: 4.66237

Cumulative Model Updates: 49,034
Cumulative Timesteps: 409,077,836

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 409077836...
Checkpoint 409077836 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,351.88628
Policy Entropy: 3.08782
Value Function Loss: 0.00336

Mean KL Divergence: 0.00420
SB3 Clip Fraction: 0.04539
Policy Update Magnitude: 0.36746
Value Function Update Magnitude: 0.27123

Collected Steps per Second: 22,544.87445
Overall Steps per Second: 10,609.72475

Timestep Collection Time: 2.21780
Timestep Consumption Time: 2.49486
PPO Batch Consumption Time: 0.28839
Total Iteration Time: 4.71266

Cumulative Model Updates: 49,040
Cumulative Timesteps: 409,127,836

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,313.38633
Policy Entropy: 3.08461
Value Function Loss: 0.00343

Mean KL Divergence: 0.00428
SB3 Clip Fraction: 0.04566
Policy Update Magnitude: 0.38140
Value Function Update Magnitude: 0.28304

Collected Steps per Second: 22,419.86720
Overall Steps per Second: 10,546.85169

Timestep Collection Time: 2.23070
Timestep Consumption Time: 2.51119
PPO Batch Consumption Time: 0.29507
Total Iteration Time: 4.74189

Cumulative Model Updates: 49,046
Cumulative Timesteps: 409,177,848

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 409177848...
Checkpoint 409177848 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 993.59862
Policy Entropy: 3.08436
Value Function Loss: 0.00332

Mean KL Divergence: 0.00417
SB3 Clip Fraction: 0.04426
Policy Update Magnitude: 0.38155
Value Function Update Magnitude: 0.29088

Collected Steps per Second: 21,499.74540
Overall Steps per Second: 10,554.34776

Timestep Collection Time: 2.32700
Timestep Consumption Time: 2.41322
PPO Batch Consumption Time: 0.28736
Total Iteration Time: 4.74023

Cumulative Model Updates: 49,052
Cumulative Timesteps: 409,227,878

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,409.11466
Policy Entropy: 3.09056
Value Function Loss: 0.00340

Mean KL Divergence: 0.00420
SB3 Clip Fraction: 0.04432
Policy Update Magnitude: 0.36700
Value Function Update Magnitude: 0.28690

Collected Steps per Second: 21,469.69166
Overall Steps per Second: 10,446.83118

Timestep Collection Time: 2.32942
Timestep Consumption Time: 2.45787
PPO Batch Consumption Time: 0.29329
Total Iteration Time: 4.78729

Cumulative Model Updates: 49,058
Cumulative Timesteps: 409,277,890

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 409277890...
Checkpoint 409277890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 713.58252
Policy Entropy: 3.09679
Value Function Loss: 0.00325

Mean KL Divergence: 0.00406
SB3 Clip Fraction: 0.04235
Policy Update Magnitude: 0.36168
Value Function Update Magnitude: 0.28720

Collected Steps per Second: 21,556.31788
Overall Steps per Second: 10,636.06949

Timestep Collection Time: 2.32043
Timestep Consumption Time: 2.38243
PPO Batch Consumption Time: 0.28200
Total Iteration Time: 4.70287

Cumulative Model Updates: 49,064
Cumulative Timesteps: 409,327,910

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,057.83142
Policy Entropy: 3.09543
Value Function Loss: 0.00318

Mean KL Divergence: 0.00421
SB3 Clip Fraction: 0.04426
Policy Update Magnitude: 0.36378
Value Function Update Magnitude: 0.28000

Collected Steps per Second: 21,545.43932
Overall Steps per Second: 10,463.27290

Timestep Collection Time: 2.32086
Timestep Consumption Time: 2.45814
PPO Batch Consumption Time: 0.29516
Total Iteration Time: 4.77900

Cumulative Model Updates: 49,070
Cumulative Timesteps: 409,377,914

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 409377914...
Checkpoint 409377914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,029.49968
Policy Entropy: 3.10047
Value Function Loss: 0.00313

Mean KL Divergence: 0.00421
SB3 Clip Fraction: 0.04479
Policy Update Magnitude: 0.36199
Value Function Update Magnitude: 0.27164

Collected Steps per Second: 21,560.89036
Overall Steps per Second: 10,571.83772

Timestep Collection Time: 2.31994
Timestep Consumption Time: 2.41150
PPO Batch Consumption Time: 0.28095
Total Iteration Time: 4.73144

Cumulative Model Updates: 49,076
Cumulative Timesteps: 409,427,934

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,018.70999
Policy Entropy: 3.11350
Value Function Loss: 0.00317

Mean KL Divergence: 0.00439
SB3 Clip Fraction: 0.04681
Policy Update Magnitude: 0.36844
Value Function Update Magnitude: 0.26903

Collected Steps per Second: 21,909.87037
Overall Steps per Second: 10,544.19910

Timestep Collection Time: 2.28308
Timestep Consumption Time: 2.46095
PPO Batch Consumption Time: 0.29609
Total Iteration Time: 4.74403

Cumulative Model Updates: 49,082
Cumulative Timesteps: 409,477,956

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 409477956...
Checkpoint 409477956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,101.04348
Policy Entropy: 3.10578
Value Function Loss: 0.00333

Mean KL Divergence: 0.00456
SB3 Clip Fraction: 0.04981
Policy Update Magnitude: 0.37452
Value Function Update Magnitude: 0.27122

Collected Steps per Second: 21,221.06516
Overall Steps per Second: 10,375.39600

Timestep Collection Time: 2.35737
Timestep Consumption Time: 2.46422
PPO Batch Consumption Time: 0.29614
Total Iteration Time: 4.82160

Cumulative Model Updates: 49,088
Cumulative Timesteps: 409,527,982

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,030.49730
Policy Entropy: 3.09444
Value Function Loss: 0.00347

Mean KL Divergence: 0.00469
SB3 Clip Fraction: 0.05171
Policy Update Magnitude: 0.38035
Value Function Update Magnitude: 0.27739

Collected Steps per Second: 21,768.64946
Overall Steps per Second: 10,699.79793

Timestep Collection Time: 2.29808
Timestep Consumption Time: 2.37734
PPO Batch Consumption Time: 0.28083
Total Iteration Time: 4.67542

Cumulative Model Updates: 49,094
Cumulative Timesteps: 409,578,008

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 409578008...
Checkpoint 409578008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 788.82612
Policy Entropy: 3.10328
Value Function Loss: 0.00341

Mean KL Divergence: 0.00457
SB3 Clip Fraction: 0.04964
Policy Update Magnitude: 0.38000
Value Function Update Magnitude: 0.29158

Collected Steps per Second: 22,206.11235
Overall Steps per Second: 10,653.79656

Timestep Collection Time: 2.25217
Timestep Consumption Time: 2.44212
PPO Batch Consumption Time: 0.28137
Total Iteration Time: 4.69429

Cumulative Model Updates: 49,100
Cumulative Timesteps: 409,628,020

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,348.68018
Policy Entropy: 3.11176
Value Function Loss: 0.00323

Mean KL Divergence: 0.00444
SB3 Clip Fraction: 0.04754
Policy Update Magnitude: 0.38396
Value Function Update Magnitude: 0.29186

Collected Steps per Second: 22,220.18618
Overall Steps per Second: 10,470.32020

Timestep Collection Time: 2.25165
Timestep Consumption Time: 2.52681
PPO Batch Consumption Time: 0.29635
Total Iteration Time: 4.77846

Cumulative Model Updates: 49,106
Cumulative Timesteps: 409,678,052

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 409678052...
Checkpoint 409678052 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 789.43684
Policy Entropy: 3.11555
Value Function Loss: 0.00317

Mean KL Divergence: 0.00423
SB3 Clip Fraction: 0.04385
Policy Update Magnitude: 0.39287
Value Function Update Magnitude: 0.28826

Collected Steps per Second: 21,901.51109
Overall Steps per Second: 10,573.92405

Timestep Collection Time: 2.28295
Timestep Consumption Time: 2.44567
PPO Batch Consumption Time: 0.28104
Total Iteration Time: 4.72861

Cumulative Model Updates: 49,112
Cumulative Timesteps: 409,728,052

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 763.82052
Policy Entropy: 3.11218
Value Function Loss: 0.00328

Mean KL Divergence: 0.00452
SB3 Clip Fraction: 0.04894
Policy Update Magnitude: 0.38624
Value Function Update Magnitude: 0.29306

Collected Steps per Second: 21,465.83198
Overall Steps per Second: 10,553.70449

Timestep Collection Time: 2.33031
Timestep Consumption Time: 2.40945
PPO Batch Consumption Time: 0.28644
Total Iteration Time: 4.73976

Cumulative Model Updates: 49,118
Cumulative Timesteps: 409,778,074

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 409778074...
Checkpoint 409778074 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,376.57800
Policy Entropy: 3.10798
Value Function Loss: 0.00338

Mean KL Divergence: 0.00419
SB3 Clip Fraction: 0.04422
Policy Update Magnitude: 0.39775
Value Function Update Magnitude: 0.29483

Collected Steps per Second: 21,956.16362
Overall Steps per Second: 10,624.11661

Timestep Collection Time: 2.27790
Timestep Consumption Time: 2.42969
PPO Batch Consumption Time: 0.28569
Total Iteration Time: 4.70759

Cumulative Model Updates: 49,124
Cumulative Timesteps: 409,828,088

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,625.95742
Policy Entropy: 3.11115
Value Function Loss: 0.00342

Mean KL Divergence: 0.00435
SB3 Clip Fraction: 0.04513
Policy Update Magnitude: 0.39862
Value Function Update Magnitude: 0.30189

Collected Steps per Second: 21,931.28233
Overall Steps per Second: 10,591.37283

Timestep Collection Time: 2.28058
Timestep Consumption Time: 2.44176
PPO Batch Consumption Time: 0.29038
Total Iteration Time: 4.72233

Cumulative Model Updates: 49,130
Cumulative Timesteps: 409,878,104

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 409878104...
Checkpoint 409878104 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,032.68498
Policy Entropy: 3.12537
Value Function Loss: 0.00342

Mean KL Divergence: 0.00455
SB3 Clip Fraction: 0.04847
Policy Update Magnitude: 0.40376
Value Function Update Magnitude: 0.29515

Collected Steps per Second: 22,102.08765
Overall Steps per Second: 10,680.54313

Timestep Collection Time: 2.26341
Timestep Consumption Time: 2.42044
PPO Batch Consumption Time: 0.29103
Total Iteration Time: 4.68384

Cumulative Model Updates: 49,136
Cumulative Timesteps: 409,928,130

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,601.36840
Policy Entropy: 3.11343
Value Function Loss: 0.00355

Mean KL Divergence: 0.00437
SB3 Clip Fraction: 0.04600
Policy Update Magnitude: 0.40009
Value Function Update Magnitude: 0.28806

Collected Steps per Second: 22,903.50161
Overall Steps per Second: 10,732.83836

Timestep Collection Time: 2.18421
Timestep Consumption Time: 2.47681
PPO Batch Consumption Time: 0.28647
Total Iteration Time: 4.66102

Cumulative Model Updates: 49,142
Cumulative Timesteps: 409,978,156

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 409978156...
Checkpoint 409978156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 827.41182
Policy Entropy: 3.10594
Value Function Loss: 0.00372

Mean KL Divergence: 0.00455
SB3 Clip Fraction: 0.04907
Policy Update Magnitude: 0.40607
Value Function Update Magnitude: 0.29570

Collected Steps per Second: 22,007.35858
Overall Steps per Second: 10,601.96783

Timestep Collection Time: 2.27215
Timestep Consumption Time: 2.44433
PPO Batch Consumption Time: 0.29398
Total Iteration Time: 4.71648

Cumulative Model Updates: 49,148
Cumulative Timesteps: 410,028,160

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 997.81193
Policy Entropy: 3.10770
Value Function Loss: 0.00364

Mean KL Divergence: 0.00465
SB3 Clip Fraction: 0.05030
Policy Update Magnitude: 0.40062
Value Function Update Magnitude: 0.29625

Collected Steps per Second: 22,127.34592
Overall Steps per Second: 10,667.85914

Timestep Collection Time: 2.25974
Timestep Consumption Time: 2.42743
PPO Batch Consumption Time: 0.29039
Total Iteration Time: 4.68716

Cumulative Model Updates: 49,154
Cumulative Timesteps: 410,078,162

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 410078162...
Checkpoint 410078162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,361.79048
Policy Entropy: 3.11530
Value Function Loss: 0.00356

Mean KL Divergence: 0.00417
SB3 Clip Fraction: 0.04329
Policy Update Magnitude: 0.39389
Value Function Update Magnitude: 0.30240

Collected Steps per Second: 21,947.41326
Overall Steps per Second: 10,616.74790

Timestep Collection Time: 2.27918
Timestep Consumption Time: 2.43244
PPO Batch Consumption Time: 0.29222
Total Iteration Time: 4.71161

Cumulative Model Updates: 49,160
Cumulative Timesteps: 410,128,184

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,042.10648
Policy Entropy: 3.14118
Value Function Loss: 0.00323

Mean KL Divergence: 0.00436
SB3 Clip Fraction: 0.04741
Policy Update Magnitude: 0.38695
Value Function Update Magnitude: 0.28843

Collected Steps per Second: 21,179.35617
Overall Steps per Second: 10,448.08378

Timestep Collection Time: 2.36192
Timestep Consumption Time: 2.42594
PPO Batch Consumption Time: 0.29389
Total Iteration Time: 4.78786

Cumulative Model Updates: 49,166
Cumulative Timesteps: 410,178,208

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 410178208...
Checkpoint 410178208 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,249.62694
Policy Entropy: 3.13377
Value Function Loss: 0.00341

Mean KL Divergence: 0.00466
SB3 Clip Fraction: 0.05052
Policy Update Magnitude: 0.38271
Value Function Update Magnitude: 0.27240

Collected Steps per Second: 21,156.92432
Overall Steps per Second: 10,513.19874

Timestep Collection Time: 2.36367
Timestep Consumption Time: 2.39302
PPO Batch Consumption Time: 0.28550
Total Iteration Time: 4.75669

Cumulative Model Updates: 49,172
Cumulative Timesteps: 410,228,216

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 830.64894
Policy Entropy: 3.12953
Value Function Loss: 0.00338

Mean KL Divergence: 0.00462
SB3 Clip Fraction: 0.05059
Policy Update Magnitude: 0.38003
Value Function Update Magnitude: 0.27636

Collected Steps per Second: 21,601.01372
Overall Steps per Second: 10,521.11670

Timestep Collection Time: 2.31693
Timestep Consumption Time: 2.43998
PPO Batch Consumption Time: 0.29499
Total Iteration Time: 4.75691

Cumulative Model Updates: 49,178
Cumulative Timesteps: 410,278,264

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 410278264...
Checkpoint 410278264 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,127.62021
Policy Entropy: 3.11957
Value Function Loss: 0.00361

Mean KL Divergence: 0.00447
SB3 Clip Fraction: 0.04809
Policy Update Magnitude: 0.38899
Value Function Update Magnitude: 0.28317

Collected Steps per Second: 21,738.44634
Overall Steps per Second: 10,550.60603

Timestep Collection Time: 2.30072
Timestep Consumption Time: 2.43967
PPO Batch Consumption Time: 0.29297
Total Iteration Time: 4.74039

Cumulative Model Updates: 49,184
Cumulative Timesteps: 410,328,278

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,372.21610
Policy Entropy: 3.13653
Value Function Loss: 0.00334

Mean KL Divergence: 0.00466
SB3 Clip Fraction: 0.05082
Policy Update Magnitude: 0.39798
Value Function Update Magnitude: 0.28349

Collected Steps per Second: 21,401.90845
Overall Steps per Second: 10,465.86491

Timestep Collection Time: 2.33689
Timestep Consumption Time: 2.44188
PPO Batch Consumption Time: 0.29067
Total Iteration Time: 4.77877

Cumulative Model Updates: 49,190
Cumulative Timesteps: 410,378,292

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 410378292...
Checkpoint 410378292 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,070.26801
Policy Entropy: 3.13381
Value Function Loss: 0.00337

Mean KL Divergence: 0.00446
SB3 Clip Fraction: 0.04766
Policy Update Magnitude: 0.39387
Value Function Update Magnitude: 0.28217

Collected Steps per Second: 21,345.07056
Overall Steps per Second: 10,586.30242

Timestep Collection Time: 2.34359
Timestep Consumption Time: 2.38177
PPO Batch Consumption Time: 0.28080
Total Iteration Time: 4.72535

Cumulative Model Updates: 49,196
Cumulative Timesteps: 410,428,316

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,236.53761
Policy Entropy: 3.13311
Value Function Loss: 0.00341

Mean KL Divergence: 0.00469
SB3 Clip Fraction: 0.05139
Policy Update Magnitude: 0.38901
Value Function Update Magnitude: 0.27601

Collected Steps per Second: 21,960.49298
Overall Steps per Second: 10,548.64601

Timestep Collection Time: 2.27754
Timestep Consumption Time: 2.46392
PPO Batch Consumption Time: 0.29539
Total Iteration Time: 4.74146

Cumulative Model Updates: 49,202
Cumulative Timesteps: 410,478,332

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 410478332...
Checkpoint 410478332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,323.01794
Policy Entropy: 3.12931
Value Function Loss: 0.00353

Mean KL Divergence: 0.00461
SB3 Clip Fraction: 0.04985
Policy Update Magnitude: 0.39831
Value Function Update Magnitude: 0.28841

Collected Steps per Second: 21,716.76232
Overall Steps per Second: 10,586.35750

Timestep Collection Time: 2.30384
Timestep Consumption Time: 2.42224
PPO Batch Consumption Time: 0.28896
Total Iteration Time: 4.72608

Cumulative Model Updates: 49,208
Cumulative Timesteps: 410,528,364

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 630.63034
Policy Entropy: 3.11963
Value Function Loss: 0.00356

Mean KL Divergence: 0.00522
SB3 Clip Fraction: 0.05823
Policy Update Magnitude: 0.40462
Value Function Update Magnitude: 0.29733

Collected Steps per Second: 21,768.48983
Overall Steps per Second: 10,540.32959

Timestep Collection Time: 2.29791
Timestep Consumption Time: 2.44786
PPO Batch Consumption Time: 0.29457
Total Iteration Time: 4.74577

Cumulative Model Updates: 49,214
Cumulative Timesteps: 410,578,386

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 410578386...
Checkpoint 410578386 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,022.06110
Policy Entropy: 3.12300
Value Function Loss: 0.00344

Mean KL Divergence: 0.00530
SB3 Clip Fraction: 0.05936
Policy Update Magnitude: 0.39847
Value Function Update Magnitude: 0.29884

Collected Steps per Second: 21,895.88223
Overall Steps per Second: 10,570.56941

Timestep Collection Time: 2.28445
Timestep Consumption Time: 2.44756
PPO Batch Consumption Time: 0.29616
Total Iteration Time: 4.73201

Cumulative Model Updates: 49,220
Cumulative Timesteps: 410,628,406

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 963.11296
Policy Entropy: 3.12433
Value Function Loss: 0.00356

Mean KL Divergence: 0.00490
SB3 Clip Fraction: 0.05309
Policy Update Magnitude: 0.39867
Value Function Update Magnitude: 0.30215

Collected Steps per Second: 21,981.99921
Overall Steps per Second: 10,621.42176

Timestep Collection Time: 2.27559
Timestep Consumption Time: 2.43395
PPO Batch Consumption Time: 0.29111
Total Iteration Time: 4.70954

Cumulative Model Updates: 49,226
Cumulative Timesteps: 410,678,428

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 410678428...
Checkpoint 410678428 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,980.51946
Policy Entropy: 3.12940
Value Function Loss: 0.00341

Mean KL Divergence: 0.00478
SB3 Clip Fraction: 0.05036
Policy Update Magnitude: 0.39063
Value Function Update Magnitude: 0.30832

Collected Steps per Second: 22,009.27430
Overall Steps per Second: 10,660.50944

Timestep Collection Time: 2.27204
Timestep Consumption Time: 2.41873
PPO Batch Consumption Time: 0.29135
Total Iteration Time: 4.69077

Cumulative Model Updates: 49,232
Cumulative Timesteps: 410,728,434

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 799.61755
Policy Entropy: 3.11405
Value Function Loss: 0.00343

Mean KL Divergence: 0.00494
SB3 Clip Fraction: 0.05485
Policy Update Magnitude: 0.37970
Value Function Update Magnitude: 0.30598

Collected Steps per Second: 21,604.52740
Overall Steps per Second: 10,652.65073

Timestep Collection Time: 2.31442
Timestep Consumption Time: 2.37943
PPO Batch Consumption Time: 0.28121
Total Iteration Time: 4.69386

Cumulative Model Updates: 49,238
Cumulative Timesteps: 410,778,436

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 410778436...
Checkpoint 410778436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,044.89064
Policy Entropy: 3.12121
Value Function Loss: 0.00342

Mean KL Divergence: 0.00446
SB3 Clip Fraction: 0.04814
Policy Update Magnitude: 0.38523
Value Function Update Magnitude: 0.30828

Collected Steps per Second: 21,109.74001
Overall Steps per Second: 10,501.04450

Timestep Collection Time: 2.36971
Timestep Consumption Time: 2.39400
PPO Batch Consumption Time: 0.28758
Total Iteration Time: 4.76372

Cumulative Model Updates: 49,244
Cumulative Timesteps: 410,828,460

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,343.49933
Policy Entropy: 3.11606
Value Function Loss: 0.00352

Mean KL Divergence: 0.00478
SB3 Clip Fraction: 0.05217
Policy Update Magnitude: 0.38975
Value Function Update Magnitude: 0.31423

Collected Steps per Second: 21,383.73569
Overall Steps per Second: 10,628.71976

Timestep Collection Time: 2.33860
Timestep Consumption Time: 2.36639
PPO Batch Consumption Time: 0.28144
Total Iteration Time: 4.70499

Cumulative Model Updates: 49,250
Cumulative Timesteps: 410,878,468

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 410878468...
Checkpoint 410878468 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,262.45861
Policy Entropy: 3.10654
Value Function Loss: 0.00352

Mean KL Divergence: 0.00488
SB3 Clip Fraction: 0.05322
Policy Update Magnitude: 0.39223
Value Function Update Magnitude: 0.31567

Collected Steps per Second: 21,386.28121
Overall Steps per Second: 10,615.98683

Timestep Collection Time: 2.33860
Timestep Consumption Time: 2.37259
PPO Batch Consumption Time: 0.28170
Total Iteration Time: 4.71120

Cumulative Model Updates: 49,256
Cumulative Timesteps: 410,928,482

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,278.79988
Policy Entropy: 3.11157
Value Function Loss: 0.00356

Mean KL Divergence: 0.00491
SB3 Clip Fraction: 0.05443
Policy Update Magnitude: 0.39434
Value Function Update Magnitude: 0.30706

Collected Steps per Second: 21,379.52603
Overall Steps per Second: 10,519.87190

Timestep Collection Time: 2.33990
Timestep Consumption Time: 2.41548
PPO Batch Consumption Time: 0.28718
Total Iteration Time: 4.75538

Cumulative Model Updates: 49,262
Cumulative Timesteps: 410,978,508

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 410978508...
Checkpoint 410978508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,233.99644
Policy Entropy: 3.11318
Value Function Loss: 0.00348

Mean KL Divergence: 0.00492
SB3 Clip Fraction: 0.05488
Policy Update Magnitude: 0.39335
Value Function Update Magnitude: 0.31027

Collected Steps per Second: 22,415.63197
Overall Steps per Second: 10,666.96223

Timestep Collection Time: 2.23085
Timestep Consumption Time: 2.45708
PPO Batch Consumption Time: 0.28002
Total Iteration Time: 4.68793

Cumulative Model Updates: 49,268
Cumulative Timesteps: 411,028,514

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 948.65545
Policy Entropy: 3.12339
Value Function Loss: 0.00346

Mean KL Divergence: 0.00473
SB3 Clip Fraction: 0.05101
Policy Update Magnitude: 0.39094
Value Function Update Magnitude: 0.31532

Collected Steps per Second: 22,105.46242
Overall Steps per Second: 10,766.73031

Timestep Collection Time: 2.26252
Timestep Consumption Time: 2.38272
PPO Batch Consumption Time: 0.28130
Total Iteration Time: 4.64524

Cumulative Model Updates: 49,274
Cumulative Timesteps: 411,078,528

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 411078528...
Checkpoint 411078528 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 821.30990
Policy Entropy: 3.11713
Value Function Loss: 0.00346

Mean KL Divergence: 0.00473
SB3 Clip Fraction: 0.05229
Policy Update Magnitude: 0.39049
Value Function Update Magnitude: 0.31479

Collected Steps per Second: 21,819.32635
Overall Steps per Second: 10,687.70502

Timestep Collection Time: 2.29265
Timestep Consumption Time: 2.38787
PPO Batch Consumption Time: 0.28208
Total Iteration Time: 4.68052

Cumulative Model Updates: 49,280
Cumulative Timesteps: 411,128,552

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,337.52025
Policy Entropy: 3.12346
Value Function Loss: 0.00345

Mean KL Divergence: 0.00487
SB3 Clip Fraction: 0.05272
Policy Update Magnitude: 0.38615
Value Function Update Magnitude: 0.32456

Collected Steps per Second: 21,915.68335
Overall Steps per Second: 10,560.99778

Timestep Collection Time: 2.28165
Timestep Consumption Time: 2.45313
PPO Batch Consumption Time: 0.29535
Total Iteration Time: 4.73478

Cumulative Model Updates: 49,286
Cumulative Timesteps: 411,178,556

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 411178556...
Checkpoint 411178556 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 857.45763
Policy Entropy: 3.11722
Value Function Loss: 0.00337

Mean KL Divergence: 0.00500
SB3 Clip Fraction: 0.05601
Policy Update Magnitude: 0.37437
Value Function Update Magnitude: 0.32428

Collected Steps per Second: 21,734.67324
Overall Steps per Second: 10,584.29481

Timestep Collection Time: 2.30112
Timestep Consumption Time: 2.42419
PPO Batch Consumption Time: 0.29123
Total Iteration Time: 4.72530

Cumulative Model Updates: 49,292
Cumulative Timesteps: 411,228,570

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,865.44603
Policy Entropy: 3.12737
Value Function Loss: 0.00330

Mean KL Divergence: 0.00461
SB3 Clip Fraction: 0.05019
Policy Update Magnitude: 0.36985
Value Function Update Magnitude: 0.31749

Collected Steps per Second: 22,042.86376
Overall Steps per Second: 10,651.45992

Timestep Collection Time: 2.26912
Timestep Consumption Time: 2.42676
PPO Batch Consumption Time: 0.29059
Total Iteration Time: 4.69588

Cumulative Model Updates: 49,298
Cumulative Timesteps: 411,278,588

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 411278588...
Checkpoint 411278588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,015.61811
Policy Entropy: 3.13717
Value Function Loss: 0.00333

Mean KL Divergence: 0.00456
SB3 Clip Fraction: 0.05117
Policy Update Magnitude: 0.37147
Value Function Update Magnitude: 0.32953

Collected Steps per Second: 21,843.42949
Overall Steps per Second: 10,613.39315

Timestep Collection Time: 2.29030
Timestep Consumption Time: 2.42337
PPO Batch Consumption Time: 0.29067
Total Iteration Time: 4.71367

Cumulative Model Updates: 49,304
Cumulative Timesteps: 411,328,616

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 727.97545
Policy Entropy: 3.14060
Value Function Loss: 0.00350

Mean KL Divergence: 0.00476
SB3 Clip Fraction: 0.05259
Policy Update Magnitude: 0.38001
Value Function Update Magnitude: 0.33232

Collected Steps per Second: 22,069.56474
Overall Steps per Second: 10,434.20479

Timestep Collection Time: 2.26683
Timestep Consumption Time: 2.52778
PPO Batch Consumption Time: 0.29198
Total Iteration Time: 4.79462

Cumulative Model Updates: 49,310
Cumulative Timesteps: 411,378,644

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 411378644...
Checkpoint 411378644 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,829.45040
Policy Entropy: 3.13993
Value Function Loss: 0.00352

Mean KL Divergence: 0.00516
SB3 Clip Fraction: 0.05703
Policy Update Magnitude: 0.37719
Value Function Update Magnitude: 0.33543

Collected Steps per Second: 22,089.19165
Overall Steps per Second: 10,504.56768

Timestep Collection Time: 2.26427
Timestep Consumption Time: 2.49708
PPO Batch Consumption Time: 0.29079
Total Iteration Time: 4.76136

Cumulative Model Updates: 49,316
Cumulative Timesteps: 411,428,660

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,128.58397
Policy Entropy: 3.13303
Value Function Loss: 0.00358

Mean KL Divergence: 0.00555
SB3 Clip Fraction: 0.06274
Policy Update Magnitude: 0.37439
Value Function Update Magnitude: 0.33206

Collected Steps per Second: 21,137.27820
Overall Steps per Second: 10,411.13297

Timestep Collection Time: 2.36625
Timestep Consumption Time: 2.43784
PPO Batch Consumption Time: 0.28624
Total Iteration Time: 4.80409

Cumulative Model Updates: 49,322
Cumulative Timesteps: 411,478,676

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 411478676...
Checkpoint 411478676 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,507.16084
Policy Entropy: 3.14411
Value Function Loss: 0.00341

Mean KL Divergence: 0.00507
SB3 Clip Fraction: 0.05626
Policy Update Magnitude: 0.37463
Value Function Update Magnitude: 0.33040

Collected Steps per Second: 21,022.58597
Overall Steps per Second: 10,453.14734

Timestep Collection Time: 2.37849
Timestep Consumption Time: 2.40495
PPO Batch Consumption Time: 0.28886
Total Iteration Time: 4.78344

Cumulative Model Updates: 49,328
Cumulative Timesteps: 411,528,678

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,308.85066
Policy Entropy: 3.16180
Value Function Loss: 0.00340

Mean KL Divergence: 0.00514
SB3 Clip Fraction: 0.05584
Policy Update Magnitude: 0.37885
Value Function Update Magnitude: 0.32826

Collected Steps per Second: 22,019.43652
Overall Steps per Second: 10,711.49094

Timestep Collection Time: 2.27154
Timestep Consumption Time: 2.39803
PPO Batch Consumption Time: 0.28013
Total Iteration Time: 4.66956

Cumulative Model Updates: 49,334
Cumulative Timesteps: 411,578,696

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 411578696...
Checkpoint 411578696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,064.42896
Policy Entropy: 3.17825
Value Function Loss: 0.00333

Mean KL Divergence: 0.00463
SB3 Clip Fraction: 0.04925
Policy Update Magnitude: 0.37551
Value Function Update Magnitude: 0.32736

Collected Steps per Second: 21,772.24470
Overall Steps per Second: 10,568.88455

Timestep Collection Time: 2.29751
Timestep Consumption Time: 2.43544
PPO Batch Consumption Time: 0.29044
Total Iteration Time: 4.73295

Cumulative Model Updates: 49,340
Cumulative Timesteps: 411,628,718

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,162.02497
Policy Entropy: 3.17215
Value Function Loss: 0.00336

Mean KL Divergence: 0.00451
SB3 Clip Fraction: 0.04844
Policy Update Magnitude: 0.37886
Value Function Update Magnitude: 0.33245

Collected Steps per Second: 21,911.65163
Overall Steps per Second: 10,594.16682

Timestep Collection Time: 2.28253
Timestep Consumption Time: 2.43837
PPO Batch Consumption Time: 0.29374
Total Iteration Time: 4.72090

Cumulative Model Updates: 49,346
Cumulative Timesteps: 411,678,732

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 411678732...
Checkpoint 411678732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,999.99033
Policy Entropy: 3.16366
Value Function Loss: 0.00355

Mean KL Divergence: 0.00447
SB3 Clip Fraction: 0.04816
Policy Update Magnitude: 0.38507
Value Function Update Magnitude: 0.33704

Collected Steps per Second: 21,837.37462
Overall Steps per Second: 10,543.94452

Timestep Collection Time: 2.28984
Timestep Consumption Time: 2.45260
PPO Batch Consumption Time: 0.29587
Total Iteration Time: 4.74244

Cumulative Model Updates: 49,352
Cumulative Timesteps: 411,728,736

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 814.40622
Policy Entropy: 3.15133
Value Function Loss: 0.00353

Mean KL Divergence: 0.00433
SB3 Clip Fraction: 0.04565
Policy Update Magnitude: 0.39292
Value Function Update Magnitude: 0.34146

Collected Steps per Second: 21,836.55058
Overall Steps per Second: 10,544.92724

Timestep Collection Time: 2.29001
Timestep Consumption Time: 2.45217
PPO Batch Consumption Time: 0.29351
Total Iteration Time: 4.74219

Cumulative Model Updates: 49,358
Cumulative Timesteps: 411,778,742

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 411778742...
Checkpoint 411778742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,574.82052
Policy Entropy: 3.16523
Value Function Loss: 0.00347

Mean KL Divergence: 0.00462
SB3 Clip Fraction: 0.04921
Policy Update Magnitude: 0.38942
Value Function Update Magnitude: 0.33430

Collected Steps per Second: 21,970.16323
Overall Steps per Second: 10,606.85538

Timestep Collection Time: 2.27618
Timestep Consumption Time: 2.43851
PPO Batch Consumption Time: 0.29526
Total Iteration Time: 4.71469

Cumulative Model Updates: 49,364
Cumulative Timesteps: 411,828,750

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,424.66382
Policy Entropy: 3.16622
Value Function Loss: 0.00335

Mean KL Divergence: 0.00507
SB3 Clip Fraction: 0.05498
Policy Update Magnitude: 0.38916
Value Function Update Magnitude: 0.31377

Collected Steps per Second: 21,982.02223
Overall Steps per Second: 10,743.57334

Timestep Collection Time: 2.27513
Timestep Consumption Time: 2.37993
PPO Batch Consumption Time: 0.28210
Total Iteration Time: 4.65506

Cumulative Model Updates: 49,370
Cumulative Timesteps: 411,878,762

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 411878762...
Checkpoint 411878762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,577.05338
Policy Entropy: 3.16481
Value Function Loss: 0.00331

Mean KL Divergence: 0.00468
SB3 Clip Fraction: 0.05054
Policy Update Magnitude: 0.39780
Value Function Update Magnitude: 0.30183

Collected Steps per Second: 22,406.09011
Overall Steps per Second: 10,677.89133

Timestep Collection Time: 2.23234
Timestep Consumption Time: 2.45192
PPO Batch Consumption Time: 0.28184
Total Iteration Time: 4.68426

Cumulative Model Updates: 49,376
Cumulative Timesteps: 411,928,780

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,284.30837
Policy Entropy: 3.16156
Value Function Loss: 0.00342

Mean KL Divergence: 0.00468
SB3 Clip Fraction: 0.05065
Policy Update Magnitude: 0.39940
Value Function Update Magnitude: 0.31206

Collected Steps per Second: 22,042.89717
Overall Steps per Second: 10,495.96829

Timestep Collection Time: 2.26867
Timestep Consumption Time: 2.49583
PPO Batch Consumption Time: 0.28892
Total Iteration Time: 4.76450

Cumulative Model Updates: 49,382
Cumulative Timesteps: 411,978,788

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 411978788...
Checkpoint 411978788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,254.15282
Policy Entropy: 3.17415
Value Function Loss: 0.00329

Mean KL Divergence: 0.00460
SB3 Clip Fraction: 0.04998
Policy Update Magnitude: 0.39856
Value Function Update Magnitude: 0.31131

Collected Steps per Second: 21,549.82412
Overall Steps per Second: 10,699.97365

Timestep Collection Time: 2.32076
Timestep Consumption Time: 2.35327
PPO Batch Consumption Time: 0.27969
Total Iteration Time: 4.67403

Cumulative Model Updates: 49,388
Cumulative Timesteps: 412,028,800

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,279.06006
Policy Entropy: 3.17451
Value Function Loss: 0.00344

Mean KL Divergence: 0.00501
SB3 Clip Fraction: 0.05673
Policy Update Magnitude: 0.39492
Value Function Update Magnitude: 0.30301

Collected Steps per Second: 21,619.02848
Overall Steps per Second: 10,513.51666

Timestep Collection Time: 2.31296
Timestep Consumption Time: 2.44320
PPO Batch Consumption Time: 0.29341
Total Iteration Time: 4.75616

Cumulative Model Updates: 49,394
Cumulative Timesteps: 412,078,804

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 412078804...
Checkpoint 412078804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 863.08806
Policy Entropy: 3.19051
Value Function Loss: 0.00336

Mean KL Divergence: 0.00516
SB3 Clip Fraction: 0.05769
Policy Update Magnitude: 0.40075
Value Function Update Magnitude: 0.30966

Collected Steps per Second: 21,755.68112
Overall Steps per Second: 10,352.79495

Timestep Collection Time: 2.29926
Timestep Consumption Time: 2.53248
PPO Batch Consumption Time: 0.30801
Total Iteration Time: 4.83174

Cumulative Model Updates: 49,400
Cumulative Timesteps: 412,128,826

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,023.38775
Policy Entropy: 3.18810
Value Function Loss: 0.00328

Mean KL Divergence: 0.00515
SB3 Clip Fraction: 0.05960
Policy Update Magnitude: 0.40303
Value Function Update Magnitude: 0.32281

Collected Steps per Second: 21,958.42240
Overall Steps per Second: 10,638.11073

Timestep Collection Time: 2.27758
Timestep Consumption Time: 2.42363
PPO Batch Consumption Time: 0.28119
Total Iteration Time: 4.70121

Cumulative Model Updates: 49,406
Cumulative Timesteps: 412,178,838

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 412178838...
Checkpoint 412178838 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,621.53230
Policy Entropy: 3.21331
Value Function Loss: 0.00317

Mean KL Divergence: 0.00458
SB3 Clip Fraction: 0.05070
Policy Update Magnitude: 0.39837
Value Function Update Magnitude: 0.31647

Collected Steps per Second: 21,684.36792
Overall Steps per Second: 10,578.36623

Timestep Collection Time: 2.30636
Timestep Consumption Time: 2.42140
PPO Batch Consumption Time: 0.28841
Total Iteration Time: 4.72776

Cumulative Model Updates: 49,412
Cumulative Timesteps: 412,228,850

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,873.31148
Policy Entropy: 3.20525
Value Function Loss: 0.00319

Mean KL Divergence: 0.00445
SB3 Clip Fraction: 0.04658
Policy Update Magnitude: 0.39670
Value Function Update Magnitude: 0.29798

Collected Steps per Second: 21,920.07610
Overall Steps per Second: 10,548.01834

Timestep Collection Time: 2.28129
Timestep Consumption Time: 2.45951
PPO Batch Consumption Time: 0.29555
Total Iteration Time: 4.74080

Cumulative Model Updates: 49,418
Cumulative Timesteps: 412,278,856

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 412278856...
Checkpoint 412278856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 662.08698
Policy Entropy: 3.19217
Value Function Loss: 0.00340

Mean KL Divergence: 0.00457
SB3 Clip Fraction: 0.04802
Policy Update Magnitude: 0.39591
Value Function Update Magnitude: 0.29607

Collected Steps per Second: 21,789.72760
Overall Steps per Second: 10,583.86446

Timestep Collection Time: 2.29567
Timestep Consumption Time: 2.43058
PPO Batch Consumption Time: 0.28996
Total Iteration Time: 4.72625

Cumulative Model Updates: 49,424
Cumulative Timesteps: 412,328,878

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,218.65295
Policy Entropy: 3.17640
Value Function Loss: 0.00346

Mean KL Divergence: 0.00495
SB3 Clip Fraction: 0.05390
Policy Update Magnitude: 0.40164
Value Function Update Magnitude: 0.30066

Collected Steps per Second: 22,098.18425
Overall Steps per Second: 10,628.72576

Timestep Collection Time: 2.26372
Timestep Consumption Time: 2.44278
PPO Batch Consumption Time: 0.29223
Total Iteration Time: 4.70649

Cumulative Model Updates: 49,430
Cumulative Timesteps: 412,378,902

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 412378902...
Checkpoint 412378902 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 916.61510
Policy Entropy: 3.16415
Value Function Loss: 0.00354

Mean KL Divergence: 0.00558
SB3 Clip Fraction: 0.06170
Policy Update Magnitude: 0.40095
Value Function Update Magnitude: 0.30758

Collected Steps per Second: 22,520.61864
Overall Steps per Second: 10,610.98486

Timestep Collection Time: 2.22045
Timestep Consumption Time: 2.49221
PPO Batch Consumption Time: 0.29412
Total Iteration Time: 4.71266

Cumulative Model Updates: 49,436
Cumulative Timesteps: 412,428,908

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 822.76201
Policy Entropy: 3.17791
Value Function Loss: 0.00354

Mean KL Divergence: 0.00559
SB3 Clip Fraction: 0.06159
Policy Update Magnitude: 0.40266
Value Function Update Magnitude: 0.31664

Collected Steps per Second: 22,955.63617
Overall Steps per Second: 10,741.42766

Timestep Collection Time: 2.17838
Timestep Consumption Time: 2.47706
PPO Batch Consumption Time: 0.28600
Total Iteration Time: 4.65543

Cumulative Model Updates: 49,442
Cumulative Timesteps: 412,478,914

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 412478914...
Checkpoint 412478914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 803.35582
Policy Entropy: 3.17582
Value Function Loss: 0.00364

Mean KL Divergence: 0.00579
SB3 Clip Fraction: 0.06557
Policy Update Magnitude: 0.40100
Value Function Update Magnitude: 0.33393

Collected Steps per Second: 21,940.34462
Overall Steps per Second: 10,577.72757

Timestep Collection Time: 2.27927
Timestep Consumption Time: 2.44840
PPO Batch Consumption Time: 0.28111
Total Iteration Time: 4.72767

Cumulative Model Updates: 49,448
Cumulative Timesteps: 412,528,922

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 909.26525
Policy Entropy: 3.18813
Value Function Loss: 0.00354

Mean KL Divergence: 0.00544
SB3 Clip Fraction: 0.06077
Policy Update Magnitude: 0.40573
Value Function Update Magnitude: 0.32530

Collected Steps per Second: 22,031.32654
Overall Steps per Second: 10,574.10122

Timestep Collection Time: 2.27022
Timestep Consumption Time: 2.45983
PPO Batch Consumption Time: 0.28338
Total Iteration Time: 4.73005

Cumulative Model Updates: 49,454
Cumulative Timesteps: 412,578,938

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 412578938...
Checkpoint 412578938 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,179.67953
Policy Entropy: 3.19903
Value Function Loss: 0.00343

Mean KL Divergence: 0.00531
SB3 Clip Fraction: 0.05771
Policy Update Magnitude: 0.40437
Value Function Update Magnitude: 0.30763

Collected Steps per Second: 22,094.20629
Overall Steps per Second: 10,676.07651

Timestep Collection Time: 2.26340
Timestep Consumption Time: 2.42072
PPO Batch Consumption Time: 0.27953
Total Iteration Time: 4.68412

Cumulative Model Updates: 49,460
Cumulative Timesteps: 412,628,946

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,119.83921
Policy Entropy: 3.20512
Value Function Loss: 0.00350

Mean KL Divergence: 0.00510
SB3 Clip Fraction: 0.05620
Policy Update Magnitude: 0.39810
Value Function Update Magnitude: 0.30375

Collected Steps per Second: 22,428.28317
Overall Steps per Second: 10,544.35974

Timestep Collection Time: 2.23004
Timestep Consumption Time: 2.51335
PPO Batch Consumption Time: 0.29181
Total Iteration Time: 4.74339

Cumulative Model Updates: 49,466
Cumulative Timesteps: 412,678,962

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 412678962...
Checkpoint 412678962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,271.48766
Policy Entropy: 3.20464
Value Function Loss: 0.00357

Mean KL Divergence: 0.00533
SB3 Clip Fraction: 0.05987
Policy Update Magnitude: 0.39180
Value Function Update Magnitude: 0.30554

Collected Steps per Second: 22,154.89439
Overall Steps per Second: 10,480.88642

Timestep Collection Time: 2.25738
Timestep Consumption Time: 2.51435
PPO Batch Consumption Time: 0.29086
Total Iteration Time: 4.77173

Cumulative Model Updates: 49,472
Cumulative Timesteps: 412,728,974

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 993.87633
Policy Entropy: 3.19240
Value Function Loss: 0.00357

Mean KL Divergence: 0.00595
SB3 Clip Fraction: 0.06744
Policy Update Magnitude: 0.39029
Value Function Update Magnitude: 0.30631

Collected Steps per Second: 22,867.35885
Overall Steps per Second: 10,437.45744

Timestep Collection Time: 2.18705
Timestep Consumption Time: 2.60454
PPO Batch Consumption Time: 0.30268
Total Iteration Time: 4.79159

Cumulative Model Updates: 49,478
Cumulative Timesteps: 412,778,986

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 412778986...
Checkpoint 412778986 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,331.74740
Policy Entropy: 3.20741
Value Function Loss: 0.00344

Mean KL Divergence: 0.00631
SB3 Clip Fraction: 0.07080
Policy Update Magnitude: 0.38843
Value Function Update Magnitude: 0.29950

Collected Steps per Second: 22,343.29320
Overall Steps per Second: 10,613.80670

Timestep Collection Time: 2.23790
Timestep Consumption Time: 2.47314
PPO Batch Consumption Time: 0.28323
Total Iteration Time: 4.71103

Cumulative Model Updates: 49,484
Cumulative Timesteps: 412,828,988

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 591.99179
Policy Entropy: 3.19924
Value Function Loss: 0.00355

Mean KL Divergence: 0.00578
SB3 Clip Fraction: 0.06513
Policy Update Magnitude: 0.38121
Value Function Update Magnitude: 0.29608

Collected Steps per Second: 22,941.39723
Overall Steps per Second: 10,687.85482

Timestep Collection Time: 2.17990
Timestep Consumption Time: 2.49924
PPO Batch Consumption Time: 0.29036
Total Iteration Time: 4.67914

Cumulative Model Updates: 49,490
Cumulative Timesteps: 412,878,998

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 412878998...
Checkpoint 412878998 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,354.53906
Policy Entropy: 3.19773
Value Function Loss: 0.00377

Mean KL Divergence: 0.00504
SB3 Clip Fraction: 0.05492
Policy Update Magnitude: 0.39339
Value Function Update Magnitude: 0.29696

Collected Steps per Second: 22,961.32628
Overall Steps per Second: 10,820.90375

Timestep Collection Time: 2.17871
Timestep Consumption Time: 2.44438
PPO Batch Consumption Time: 0.28189
Total Iteration Time: 4.62309

Cumulative Model Updates: 49,496
Cumulative Timesteps: 412,929,024

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,327.66330
Policy Entropy: 3.19100
Value Function Loss: 0.00391

Mean KL Divergence: 0.00502
SB3 Clip Fraction: 0.05506
Policy Update Magnitude: 0.40452
Value Function Update Magnitude: 0.30438

Collected Steps per Second: 22,731.59414
Overall Steps per Second: 10,623.81044

Timestep Collection Time: 2.19993
Timestep Consumption Time: 2.50723
PPO Batch Consumption Time: 0.29488
Total Iteration Time: 4.70716

Cumulative Model Updates: 49,502
Cumulative Timesteps: 412,979,032

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 412979032...
Checkpoint 412979032 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,357.72256
Policy Entropy: 3.20456
Value Function Loss: 0.00367

Mean KL Divergence: 0.00553
SB3 Clip Fraction: 0.06284
Policy Update Magnitude: 0.40236
Value Function Update Magnitude: 0.31348

Collected Steps per Second: 22,780.62561
Overall Steps per Second: 10,669.33296

Timestep Collection Time: 2.19537
Timestep Consumption Time: 2.49208
PPO Batch Consumption Time: 0.29348
Total Iteration Time: 4.68745

Cumulative Model Updates: 49,508
Cumulative Timesteps: 413,029,044

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 979.13212
Policy Entropy: 3.19957
Value Function Loss: 0.00349

Mean KL Divergence: 0.00494
SB3 Clip Fraction: 0.05469
Policy Update Magnitude: 0.39444
Value Function Update Magnitude: 0.30534

Collected Steps per Second: 22,930.84922
Overall Steps per Second: 10,841.82150

Timestep Collection Time: 2.18073
Timestep Consumption Time: 2.43159
PPO Batch Consumption Time: 0.27960
Total Iteration Time: 4.61232

Cumulative Model Updates: 49,514
Cumulative Timesteps: 413,079,050

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 413079050...
Checkpoint 413079050 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,576.15679
Policy Entropy: 3.21170
Value Function Loss: 0.00355

Mean KL Divergence: 0.00517
SB3 Clip Fraction: 0.05789
Policy Update Magnitude: 0.39225
Value Function Update Magnitude: 0.30315

Collected Steps per Second: 22,117.74856
Overall Steps per Second: 10,571.85444

Timestep Collection Time: 2.26162
Timestep Consumption Time: 2.47000
PPO Batch Consumption Time: 0.28608
Total Iteration Time: 4.73162

Cumulative Model Updates: 49,520
Cumulative Timesteps: 413,129,072

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 464.43680
Policy Entropy: 3.19342
Value Function Loss: 0.00374

Mean KL Divergence: 0.00523
SB3 Clip Fraction: 0.05813
Policy Update Magnitude: 0.39389
Value Function Update Magnitude: 0.30524

Collected Steps per Second: 22,601.40929
Overall Steps per Second: 10,622.08390

Timestep Collection Time: 2.21340
Timestep Consumption Time: 2.49622
PPO Batch Consumption Time: 0.29371
Total Iteration Time: 4.70962

Cumulative Model Updates: 49,526
Cumulative Timesteps: 413,179,098

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 413179098...
Checkpoint 413179098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,246.09968
Policy Entropy: 3.20441
Value Function Loss: 0.00368

Mean KL Divergence: 0.00498
SB3 Clip Fraction: 0.05291
Policy Update Magnitude: 0.39879
Value Function Update Magnitude: 0.32026

Collected Steps per Second: 22,326.46635
Overall Steps per Second: 10,510.75005

Timestep Collection Time: 2.24066
Timestep Consumption Time: 2.51885
PPO Batch Consumption Time: 0.29528
Total Iteration Time: 4.75951

Cumulative Model Updates: 49,532
Cumulative Timesteps: 413,229,124

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,036.83387
Policy Entropy: 3.21572
Value Function Loss: 0.00353

Mean KL Divergence: 0.00557
SB3 Clip Fraction: 0.06090
Policy Update Magnitude: 0.39624
Value Function Update Magnitude: 0.31810

Collected Steps per Second: 22,730.44803
Overall Steps per Second: 10,560.76251

Timestep Collection Time: 2.20022
Timestep Consumption Time: 2.53542
PPO Batch Consumption Time: 0.29321
Total Iteration Time: 4.73564

Cumulative Model Updates: 49,538
Cumulative Timesteps: 413,279,136

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 413279136...
Checkpoint 413279136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,040.54386
Policy Entropy: 3.22848
Value Function Loss: 0.00342

Mean KL Divergence: 0.00556
SB3 Clip Fraction: 0.06181
Policy Update Magnitude: 0.39813
Value Function Update Magnitude: 0.30362

Collected Steps per Second: 22,417.32269
Overall Steps per Second: 10,544.80428

Timestep Collection Time: 2.23256
Timestep Consumption Time: 2.51366
PPO Batch Consumption Time: 0.29263
Total Iteration Time: 4.74622

Cumulative Model Updates: 49,544
Cumulative Timesteps: 413,329,184

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 903.74632
Policy Entropy: 3.21545
Value Function Loss: 0.00343

Mean KL Divergence: 0.00651
SB3 Clip Fraction: 0.07367
Policy Update Magnitude: 0.39375
Value Function Update Magnitude: 0.30173

Collected Steps per Second: 22,714.26114
Overall Steps per Second: 10,585.02991

Timestep Collection Time: 2.20276
Timestep Consumption Time: 2.52411
PPO Batch Consumption Time: 0.29279
Total Iteration Time: 4.72686

Cumulative Model Updates: 49,550
Cumulative Timesteps: 413,379,218

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 413379218...
Checkpoint 413379218 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,226.93596
Policy Entropy: 3.22154
Value Function Loss: 0.00337

Mean KL Divergence: 0.00587
SB3 Clip Fraction: 0.06649
Policy Update Magnitude: 0.39163
Value Function Update Magnitude: 0.30675

Collected Steps per Second: 22,180.14611
Overall Steps per Second: 10,706.20350

Timestep Collection Time: 2.25454
Timestep Consumption Time: 2.41621
PPO Batch Consumption Time: 0.28950
Total Iteration Time: 4.67075

Cumulative Model Updates: 49,556
Cumulative Timesteps: 413,429,224

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,415.51042
Policy Entropy: 3.21904
Value Function Loss: 0.00337

Mean KL Divergence: 0.00543
SB3 Clip Fraction: 0.06066
Policy Update Magnitude: 0.39234
Value Function Update Magnitude: 0.30426

Collected Steps per Second: 22,582.39998
Overall Steps per Second: 10,642.07905

Timestep Collection Time: 2.21473
Timestep Consumption Time: 2.48491
PPO Batch Consumption Time: 0.29930
Total Iteration Time: 4.69965

Cumulative Model Updates: 49,562
Cumulative Timesteps: 413,479,238

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 413479238...
Checkpoint 413479238 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 782.57283
Policy Entropy: 3.23790
Value Function Loss: 0.00341

Mean KL Divergence: 0.00529
SB3 Clip Fraction: 0.05878
Policy Update Magnitude: 0.39306
Value Function Update Magnitude: 0.30080

Collected Steps per Second: 21,810.12242
Overall Steps per Second: 10,722.68459

Timestep Collection Time: 2.29316
Timestep Consumption Time: 2.37116
PPO Batch Consumption Time: 0.28113
Total Iteration Time: 4.66432

Cumulative Model Updates: 49,568
Cumulative Timesteps: 413,529,252

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,927.77967
Policy Entropy: 3.21414
Value Function Loss: 0.00347

Mean KL Divergence: 0.00500
SB3 Clip Fraction: 0.05502
Policy Update Magnitude: 0.39557
Value Function Update Magnitude: 0.30671

Collected Steps per Second: 22,382.83890
Overall Steps per Second: 10,870.13331

Timestep Collection Time: 2.23475
Timestep Consumption Time: 2.36685
PPO Batch Consumption Time: 0.28121
Total Iteration Time: 4.60160

Cumulative Model Updates: 49,574
Cumulative Timesteps: 413,579,272

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 413579272...
Checkpoint 413579272 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,273.40242
Policy Entropy: 3.21533
Value Function Loss: 0.00341

Mean KL Divergence: 0.00517
SB3 Clip Fraction: 0.05684
Policy Update Magnitude: 0.39881
Value Function Update Magnitude: 0.30622

Collected Steps per Second: 22,061.91703
Overall Steps per Second: 10,654.24319

Timestep Collection Time: 2.26780
Timestep Consumption Time: 2.42817
PPO Batch Consumption Time: 0.29088
Total Iteration Time: 4.69597

Cumulative Model Updates: 49,580
Cumulative Timesteps: 413,629,304

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 965.95632
Policy Entropy: 3.22123
Value Function Loss: 0.00333

Mean KL Divergence: 0.00561
SB3 Clip Fraction: 0.06394
Policy Update Magnitude: 0.39606
Value Function Update Magnitude: 0.30019

Collected Steps per Second: 22,098.39966
Overall Steps per Second: 10,690.40686

Timestep Collection Time: 2.26297
Timestep Consumption Time: 2.41487
PPO Batch Consumption Time: 0.28876
Total Iteration Time: 4.67784

Cumulative Model Updates: 49,586
Cumulative Timesteps: 413,679,312

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 413679312...
Checkpoint 413679312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,071.80916
Policy Entropy: 3.22078
Value Function Loss: 0.00327

Mean KL Divergence: 0.00473
SB3 Clip Fraction: 0.05230
Policy Update Magnitude: 0.39308
Value Function Update Magnitude: 0.29003

Collected Steps per Second: 21,532.78457
Overall Steps per Second: 10,525.47863

Timestep Collection Time: 2.32204
Timestep Consumption Time: 2.42834
PPO Batch Consumption Time: 0.29346
Total Iteration Time: 4.75038

Cumulative Model Updates: 49,592
Cumulative Timesteps: 413,729,312

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,795.75011
Policy Entropy: 3.21716
Value Function Loss: 0.00320

Mean KL Divergence: 0.00487
SB3 Clip Fraction: 0.05249
Policy Update Magnitude: 0.39443
Value Function Update Magnitude: 0.28617

Collected Steps per Second: 22,130.84530
Overall Steps per Second: 10,837.11819

Timestep Collection Time: 2.25965
Timestep Consumption Time: 2.35486
PPO Batch Consumption Time: 0.27904
Total Iteration Time: 4.61451

Cumulative Model Updates: 49,598
Cumulative Timesteps: 413,779,320

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 413779320...
Checkpoint 413779320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,045.25897
Policy Entropy: 3.22954
Value Function Loss: 0.00319

Mean KL Divergence: 0.00523
SB3 Clip Fraction: 0.05781
Policy Update Magnitude: 0.39377
Value Function Update Magnitude: 0.29019

Collected Steps per Second: 21,623.01236
Overall Steps per Second: 10,618.12057

Timestep Collection Time: 2.31337
Timestep Consumption Time: 2.39763
PPO Batch Consumption Time: 0.28660
Total Iteration Time: 4.71100

Cumulative Model Updates: 49,604
Cumulative Timesteps: 413,829,342

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,813.22510
Policy Entropy: 3.22429
Value Function Loss: 0.00330

Mean KL Divergence: 0.00520
SB3 Clip Fraction: 0.05660
Policy Update Magnitude: 0.39931
Value Function Update Magnitude: 0.29833

Collected Steps per Second: 22,686.55233
Overall Steps per Second: 10,616.73227

Timestep Collection Time: 2.20606
Timestep Consumption Time: 2.50800
PPO Batch Consumption Time: 0.29087
Total Iteration Time: 4.71407

Cumulative Model Updates: 49,610
Cumulative Timesteps: 413,879,390

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 413879390...
Checkpoint 413879390 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,123.77268
Policy Entropy: 3.21762
Value Function Loss: 0.00335

Mean KL Divergence: 0.00497
SB3 Clip Fraction: 0.05410
Policy Update Magnitude: 0.40445
Value Function Update Magnitude: 0.30473

Collected Steps per Second: 22,603.62226
Overall Steps per Second: 10,624.88516

Timestep Collection Time: 2.21319
Timestep Consumption Time: 2.49520
PPO Batch Consumption Time: 0.29241
Total Iteration Time: 4.70838

Cumulative Model Updates: 49,616
Cumulative Timesteps: 413,929,416

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 788.61187
Policy Entropy: 3.22387
Value Function Loss: 0.00335

Mean KL Divergence: 0.00462
SB3 Clip Fraction: 0.04833
Policy Update Magnitude: 0.40304
Value Function Update Magnitude: 0.31920

Collected Steps per Second: 23,239.03708
Overall Steps per Second: 10,751.22422

Timestep Collection Time: 2.15233
Timestep Consumption Time: 2.49998
PPO Batch Consumption Time: 0.29135
Total Iteration Time: 4.65231

Cumulative Model Updates: 49,622
Cumulative Timesteps: 413,979,434

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 413979434...
Checkpoint 413979434 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 839.44840
Policy Entropy: 3.21126
Value Function Loss: 0.00337

Mean KL Divergence: 0.00486
SB3 Clip Fraction: 0.05280
Policy Update Magnitude: 0.40355
Value Function Update Magnitude: 0.31339

Collected Steps per Second: 22,577.04519
Overall Steps per Second: 10,623.10501

Timestep Collection Time: 2.21579
Timestep Consumption Time: 2.49338
PPO Batch Consumption Time: 0.29120
Total Iteration Time: 4.70917

Cumulative Model Updates: 49,628
Cumulative Timesteps: 414,029,460

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,496.26738
Policy Entropy: 3.21846
Value Function Loss: 0.00331

Mean KL Divergence: 0.00499
SB3 Clip Fraction: 0.05426
Policy Update Magnitude: 0.40137
Value Function Update Magnitude: 0.30603

Collected Steps per Second: 23,021.71411
Overall Steps per Second: 10,842.76087

Timestep Collection Time: 2.17291
Timestep Consumption Time: 2.44068
PPO Batch Consumption Time: 0.28141
Total Iteration Time: 4.61359

Cumulative Model Updates: 49,634
Cumulative Timesteps: 414,079,484

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 414079484...
Checkpoint 414079484 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,326.59379
Policy Entropy: 3.22524
Value Function Loss: 0.00332

Mean KL Divergence: 0.00502
SB3 Clip Fraction: 0.05399
Policy Update Magnitude: 0.39733
Value Function Update Magnitude: 0.30291

Collected Steps per Second: 22,680.46446
Overall Steps per Second: 10,711.90677

Timestep Collection Time: 2.20498
Timestep Consumption Time: 2.46366
PPO Batch Consumption Time: 0.28631
Total Iteration Time: 4.66864

Cumulative Model Updates: 49,640
Cumulative Timesteps: 414,129,494

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 824.01868
Policy Entropy: 3.23459
Value Function Loss: 0.00332

Mean KL Divergence: 0.00463
SB3 Clip Fraction: 0.04904
Policy Update Magnitude: 0.39651
Value Function Update Magnitude: 0.29397

Collected Steps per Second: 21,192.51804
Overall Steps per Second: 10,518.42345

Timestep Collection Time: 2.36046
Timestep Consumption Time: 2.39539
PPO Batch Consumption Time: 0.28630
Total Iteration Time: 4.75585

Cumulative Model Updates: 49,646
Cumulative Timesteps: 414,179,518

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 414179518...
Checkpoint 414179518 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,643.93083
Policy Entropy: 3.24294
Value Function Loss: 0.00326

Mean KL Divergence: 0.00485
SB3 Clip Fraction: 0.05215
Policy Update Magnitude: 0.38724
Value Function Update Magnitude: 0.29284

Collected Steps per Second: 21,449.01786
Overall Steps per Second: 10,638.12384

Timestep Collection Time: 2.33139
Timestep Consumption Time: 2.36925
PPO Batch Consumption Time: 0.27935
Total Iteration Time: 4.70064

Cumulative Model Updates: 49,652
Cumulative Timesteps: 414,229,524

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,559.81382
Policy Entropy: 3.24956
Value Function Loss: 0.00333

Mean KL Divergence: 0.00539
SB3 Clip Fraction: 0.05976
Policy Update Magnitude: 0.38640
Value Function Update Magnitude: 0.28846

Collected Steps per Second: 21,601.10713
Overall Steps per Second: 10,497.78832

Timestep Collection Time: 2.31525
Timestep Consumption Time: 2.44880
PPO Batch Consumption Time: 0.29416
Total Iteration Time: 4.76405

Cumulative Model Updates: 49,658
Cumulative Timesteps: 414,279,536

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 414279536...
Checkpoint 414279536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,240.72487
Policy Entropy: 3.24541
Value Function Loss: 0.00319

Mean KL Divergence: 0.00690
SB3 Clip Fraction: 0.07873
Policy Update Magnitude: 0.38920
Value Function Update Magnitude: 0.28565

Collected Steps per Second: 22,027.25907
Overall Steps per Second: 10,544.70810

Timestep Collection Time: 2.27091
Timestep Consumption Time: 2.47289
PPO Batch Consumption Time: 0.28644
Total Iteration Time: 4.74380

Cumulative Model Updates: 49,664
Cumulative Timesteps: 414,329,558

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 802.95494
Policy Entropy: 3.24421
Value Function Loss: 0.00343

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.09162
Policy Update Magnitude: 0.39316
Value Function Update Magnitude: 0.28725

Collected Steps per Second: 21,532.24513
Overall Steps per Second: 10,476.61983

Timestep Collection Time: 2.32368
Timestep Consumption Time: 2.45210
PPO Batch Consumption Time: 0.29268
Total Iteration Time: 4.77578

Cumulative Model Updates: 49,670
Cumulative Timesteps: 414,379,592

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 414379592...
Checkpoint 414379592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 927.08286
Policy Entropy: 3.24899
Value Function Loss: 0.00347

Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.09095
Policy Update Magnitude: 0.39189
Value Function Update Magnitude: 0.29141

Collected Steps per Second: 21,379.26425
Overall Steps per Second: 10,577.36161

Timestep Collection Time: 2.34002
Timestep Consumption Time: 2.38970
PPO Batch Consumption Time: 0.28083
Total Iteration Time: 4.72972

Cumulative Model Updates: 49,676
Cumulative Timesteps: 414,429,620

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,638.88644
Policy Entropy: 3.25049
Value Function Loss: 0.00351

Mean KL Divergence: 0.00652
SB3 Clip Fraction: 0.07377
Policy Update Magnitude: 0.39797
Value Function Update Magnitude: 0.29782

Collected Steps per Second: 22,174.22532
Overall Steps per Second: 10,607.35835

Timestep Collection Time: 2.25496
Timestep Consumption Time: 2.45894
PPO Batch Consumption Time: 0.29274
Total Iteration Time: 4.71390

Cumulative Model Updates: 49,682
Cumulative Timesteps: 414,479,622

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 414479622...
Checkpoint 414479622 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,237.07358
Policy Entropy: 3.24175
Value Function Loss: 0.00343

Mean KL Divergence: 0.00595
SB3 Clip Fraction: 0.06506
Policy Update Magnitude: 0.39295
Value Function Update Magnitude: 0.29366

Collected Steps per Second: 21,563.42041
Overall Steps per Second: 10,530.35549

Timestep Collection Time: 2.31948
Timestep Consumption Time: 2.43021
PPO Batch Consumption Time: 0.29159
Total Iteration Time: 4.74970

Cumulative Model Updates: 49,688
Cumulative Timesteps: 414,529,638

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,298.20414
Policy Entropy: 3.23217
Value Function Loss: 0.00340

Mean KL Divergence: 0.00557
SB3 Clip Fraction: 0.06158
Policy Update Magnitude: 0.39014
Value Function Update Magnitude: 0.29994

Collected Steps per Second: 22,604.02387
Overall Steps per Second: 10,519.50811

Timestep Collection Time: 2.21217
Timestep Consumption Time: 2.54128
PPO Batch Consumption Time: 0.29549
Total Iteration Time: 4.75345

Cumulative Model Updates: 49,694
Cumulative Timesteps: 414,579,642

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 414579642...
Checkpoint 414579642 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 799.10713
Policy Entropy: 3.24478
Value Function Loss: 0.00340

Mean KL Divergence: 0.00539
SB3 Clip Fraction: 0.06155
Policy Update Magnitude: 0.38960
Value Function Update Magnitude: 0.30235

Collected Steps per Second: 22,670.04323
Overall Steps per Second: 10,570.29221

Timestep Collection Time: 2.20555
Timestep Consumption Time: 2.52468
PPO Batch Consumption Time: 0.29582
Total Iteration Time: 4.73024

Cumulative Model Updates: 49,700
Cumulative Timesteps: 414,629,642

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,135.74046
Policy Entropy: 3.24087
Value Function Loss: 0.00325

Mean KL Divergence: 0.00505
SB3 Clip Fraction: 0.05652
Policy Update Magnitude: 0.39192
Value Function Update Magnitude: 0.29997

Collected Steps per Second: 22,297.34843
Overall Steps per Second: 10,825.94958

Timestep Collection Time: 2.24242
Timestep Consumption Time: 2.37611
PPO Batch Consumption Time: 0.28177
Total Iteration Time: 4.61853

Cumulative Model Updates: 49,706
Cumulative Timesteps: 414,679,642

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 414679642...
Checkpoint 414679642 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 853.36720
Policy Entropy: 3.25245
Value Function Loss: 0.00324

Mean KL Divergence: 0.00486
SB3 Clip Fraction: 0.05338
Policy Update Magnitude: 0.39099
Value Function Update Magnitude: 0.29582

Collected Steps per Second: 21,475.52987
Overall Steps per Second: 10,661.65261

Timestep Collection Time: 2.32963
Timestep Consumption Time: 2.36289
PPO Batch Consumption Time: 0.28062
Total Iteration Time: 4.69252

Cumulative Model Updates: 49,712
Cumulative Timesteps: 414,729,672

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,265.15531
Policy Entropy: 3.24823
Value Function Loss: 0.00338

Mean KL Divergence: 0.00467
SB3 Clip Fraction: 0.05042
Policy Update Magnitude: 0.39288
Value Function Update Magnitude: 0.31531

Collected Steps per Second: 21,708.69839
Overall Steps per Second: 10,439.38575

Timestep Collection Time: 2.30442
Timestep Consumption Time: 2.48762
PPO Batch Consumption Time: 0.29684
Total Iteration Time: 4.79204

Cumulative Model Updates: 49,718
Cumulative Timesteps: 414,779,698

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 414779698...
Checkpoint 414779698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,689.51843
Policy Entropy: 3.25250
Value Function Loss: 0.00353

Mean KL Divergence: 0.00543
SB3 Clip Fraction: 0.06111
Policy Update Magnitude: 0.39653
Value Function Update Magnitude: 0.32679

Collected Steps per Second: 21,012.51764
Overall Steps per Second: 10,400.50881

Timestep Collection Time: 2.38001
Timestep Consumption Time: 2.42841
PPO Batch Consumption Time: 0.29319
Total Iteration Time: 4.80842

Cumulative Model Updates: 49,724
Cumulative Timesteps: 414,829,708

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 876.34999
Policy Entropy: 3.25359
Value Function Loss: 0.00377

Mean KL Divergence: 0.00594
SB3 Clip Fraction: 0.06565
Policy Update Magnitude: 0.40688
Value Function Update Magnitude: 0.34335

Collected Steps per Second: 21,911.96264
Overall Steps per Second: 10,733.04910

Timestep Collection Time: 2.28286
Timestep Consumption Time: 2.37770
PPO Batch Consumption Time: 0.28047
Total Iteration Time: 4.66056

Cumulative Model Updates: 49,730
Cumulative Timesteps: 414,879,730

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 414879730...
Checkpoint 414879730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,057.75409
Policy Entropy: 3.26176
Value Function Loss: 0.00365

Mean KL Divergence: 0.00653
SB3 Clip Fraction: 0.07305
Policy Update Magnitude: 0.41182
Value Function Update Magnitude: 0.33911

Collected Steps per Second: 21,454.62642
Overall Steps per Second: 10,635.25850

Timestep Collection Time: 2.33106
Timestep Consumption Time: 2.37141
PPO Batch Consumption Time: 0.28064
Total Iteration Time: 4.70247

Cumulative Model Updates: 49,736
Cumulative Timesteps: 414,929,742

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,311.99106
Policy Entropy: 3.25960
Value Function Loss: 0.00355

Mean KL Divergence: 0.00585
SB3 Clip Fraction: 0.06485
Policy Update Magnitude: 0.40816
Value Function Update Magnitude: 0.33708

Collected Steps per Second: 21,964.55414
Overall Steps per Second: 10,520.23578

Timestep Collection Time: 2.27649
Timestep Consumption Time: 2.47645
PPO Batch Consumption Time: 0.29506
Total Iteration Time: 4.75294

Cumulative Model Updates: 49,742
Cumulative Timesteps: 414,979,744

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 414979744...
Checkpoint 414979744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,585.14279
Policy Entropy: 3.26468
Value Function Loss: 0.00327

Mean KL Divergence: 0.00557
SB3 Clip Fraction: 0.06096
Policy Update Magnitude: 0.39705
Value Function Update Magnitude: 0.33223

Collected Steps per Second: 21,679.80461
Overall Steps per Second: 10,596.10385

Timestep Collection Time: 2.30639
Timestep Consumption Time: 2.41252
PPO Batch Consumption Time: 0.28702
Total Iteration Time: 4.71890

Cumulative Model Updates: 49,748
Cumulative Timesteps: 415,029,746

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,839.00836
Policy Entropy: 3.26079
Value Function Loss: 0.00337

Mean KL Divergence: 0.00548
SB3 Clip Fraction: 0.06211
Policy Update Magnitude: 0.39431
Value Function Update Magnitude: 0.31911

Collected Steps per Second: 22,075.60768
Overall Steps per Second: 10,591.17014

Timestep Collection Time: 2.26549
Timestep Consumption Time: 2.45656
PPO Batch Consumption Time: 0.29604
Total Iteration Time: 4.72205

Cumulative Model Updates: 49,754
Cumulative Timesteps: 415,079,758

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 415079758...
Checkpoint 415079758 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 909.61538
Policy Entropy: 3.25932
Value Function Loss: 0.00348

Mean KL Divergence: 0.00534
SB3 Clip Fraction: 0.05938
Policy Update Magnitude: 0.39834
Value Function Update Magnitude: 0.33149

Collected Steps per Second: 21,685.16836
Overall Steps per Second: 10,500.83117

Timestep Collection Time: 2.30701
Timestep Consumption Time: 2.45718
PPO Batch Consumption Time: 0.29315
Total Iteration Time: 4.76419

Cumulative Model Updates: 49,760
Cumulative Timesteps: 415,129,786

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,350.75086
Policy Entropy: 3.26151
Value Function Loss: 0.00356

Mean KL Divergence: 0.00544
SB3 Clip Fraction: 0.05939
Policy Update Magnitude: 0.40313
Value Function Update Magnitude: 0.34328

Collected Steps per Second: 22,102.69817
Overall Steps per Second: 10,538.94475

Timestep Collection Time: 2.26253
Timestep Consumption Time: 2.48254
PPO Batch Consumption Time: 0.29612
Total Iteration Time: 4.74507

Cumulative Model Updates: 49,766
Cumulative Timesteps: 415,179,794

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 415179794...
Checkpoint 415179794 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,568.64919
Policy Entropy: 3.27151
Value Function Loss: 0.00352

Mean KL Divergence: 0.00576
SB3 Clip Fraction: 0.06189
Policy Update Magnitude: 0.40831
Value Function Update Magnitude: 0.34064

Collected Steps per Second: 21,770.27757
Overall Steps per Second: 10,608.09434

Timestep Collection Time: 2.29772
Timestep Consumption Time: 2.41774
PPO Batch Consumption Time: 0.29052
Total Iteration Time: 4.71546

Cumulative Model Updates: 49,772
Cumulative Timesteps: 415,229,816

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,364.05034
Policy Entropy: 3.26706
Value Function Loss: 0.00343

Mean KL Divergence: 0.00602
SB3 Clip Fraction: 0.06783
Policy Update Magnitude: 0.41055
Value Function Update Magnitude: 0.33724

Collected Steps per Second: 22,007.77657
Overall Steps per Second: 10,597.40115

Timestep Collection Time: 2.27229
Timestep Consumption Time: 2.44661
PPO Batch Consumption Time: 0.29258
Total Iteration Time: 4.71889

Cumulative Model Updates: 49,778
Cumulative Timesteps: 415,279,824

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 415279824...
Checkpoint 415279824 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,956.16745
Policy Entropy: 3.25677
Value Function Loss: 0.00329

Mean KL Divergence: 0.00623
SB3 Clip Fraction: 0.06979
Policy Update Magnitude: 0.41217
Value Function Update Magnitude: 0.33617

Collected Steps per Second: 21,256.23842
Overall Steps per Second: 10,498.97830

Timestep Collection Time: 2.35338
Timestep Consumption Time: 2.41127
PPO Batch Consumption Time: 0.28703
Total Iteration Time: 4.76465

Cumulative Model Updates: 49,784
Cumulative Timesteps: 415,329,848

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 969.19705
Policy Entropy: 3.26301
Value Function Loss: 0.00341

Mean KL Divergence: 0.00733
SB3 Clip Fraction: 0.08006
Policy Update Magnitude: 0.40661
Value Function Update Magnitude: 0.33320

Collected Steps per Second: 21,700.92420
Overall Steps per Second: 10,565.72039

Timestep Collection Time: 2.30608
Timestep Consumption Time: 2.43037
PPO Batch Consumption Time: 0.29418
Total Iteration Time: 4.73645

Cumulative Model Updates: 49,790
Cumulative Timesteps: 415,379,892

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 415379892...
Checkpoint 415379892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,563.24036
Policy Entropy: 3.26387
Value Function Loss: 0.00365

Mean KL Divergence: 0.00588
SB3 Clip Fraction: 0.06622
Policy Update Magnitude: 0.40797
Value Function Update Magnitude: 0.33946

Collected Steps per Second: 21,479.03083
Overall Steps per Second: 10,373.49626

Timestep Collection Time: 2.32869
Timestep Consumption Time: 2.49302
PPO Batch Consumption Time: 0.30417
Total Iteration Time: 4.82171

Cumulative Model Updates: 49,796
Cumulative Timesteps: 415,429,910

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,093.22817
Policy Entropy: 3.25689
Value Function Loss: 0.00352

Mean KL Divergence: 0.00582
SB3 Clip Fraction: 0.06520
Policy Update Magnitude: 0.41916
Value Function Update Magnitude: 0.34038

Collected Steps per Second: 21,901.42685
Overall Steps per Second: 10,588.48135

Timestep Collection Time: 2.28405
Timestep Consumption Time: 2.44033
PPO Batch Consumption Time: 0.28820
Total Iteration Time: 4.72438

Cumulative Model Updates: 49,802
Cumulative Timesteps: 415,479,934

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 415479934...
Checkpoint 415479934 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,593.81570
Policy Entropy: 3.25440
Value Function Loss: 0.00335

Mean KL Divergence: 0.00536
SB3 Clip Fraction: 0.05950
Policy Update Magnitude: 0.41219
Value Function Update Magnitude: 0.33436

Collected Steps per Second: 21,486.35609
Overall Steps per Second: 10,637.98366

Timestep Collection Time: 2.32836
Timestep Consumption Time: 2.37441
PPO Batch Consumption Time: 0.28174
Total Iteration Time: 4.70277

Cumulative Model Updates: 49,808
Cumulative Timesteps: 415,529,962

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,482.14994
Policy Entropy: 3.24147
Value Function Loss: 0.00318

Mean KL Divergence: 0.00546
SB3 Clip Fraction: 0.06065
Policy Update Magnitude: 0.40097
Value Function Update Magnitude: 0.32661

Collected Steps per Second: 22,092.74491
Overall Steps per Second: 10,579.21845

Timestep Collection Time: 2.26382
Timestep Consumption Time: 2.46375
PPO Batch Consumption Time: 0.29342
Total Iteration Time: 4.72757

Cumulative Model Updates: 49,814
Cumulative Timesteps: 415,579,976

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 415579976...
Checkpoint 415579976 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 740.26029
Policy Entropy: 3.23030
Value Function Loss: 0.00324

Mean KL Divergence: 0.00612
SB3 Clip Fraction: 0.06949
Policy Update Magnitude: 0.40444
Value Function Update Magnitude: 0.32999

Collected Steps per Second: 22,080.98611
Overall Steps per Second: 10,629.98827

Timestep Collection Time: 2.26448
Timestep Consumption Time: 2.43938
PPO Batch Consumption Time: 0.29396
Total Iteration Time: 4.70386

Cumulative Model Updates: 49,820
Cumulative Timesteps: 415,629,978

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 636.88684
Policy Entropy: 3.23021
Value Function Loss: 0.00339

Mean KL Divergence: 0.00553
SB3 Clip Fraction: 0.06150
Policy Update Magnitude: 0.40828
Value Function Update Magnitude: 0.33787

Collected Steps per Second: 22,195.19441
Overall Steps per Second: 10,780.74926

Timestep Collection Time: 2.25463
Timestep Consumption Time: 2.38716
PPO Batch Consumption Time: 0.28176
Total Iteration Time: 4.64179

Cumulative Model Updates: 49,826
Cumulative Timesteps: 415,680,020

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 415680020...
Checkpoint 415680020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 894.52979
Policy Entropy: 3.25484
Value Function Loss: 0.00342

Mean KL Divergence: 0.00545
SB3 Clip Fraction: 0.05991
Policy Update Magnitude: 0.41745
Value Function Update Magnitude: 0.34067

Collected Steps per Second: 21,724.72006
Overall Steps per Second: 10,722.81970

Timestep Collection Time: 2.30254
Timestep Consumption Time: 2.36247
PPO Batch Consumption Time: 0.28005
Total Iteration Time: 4.66500

Cumulative Model Updates: 49,832
Cumulative Timesteps: 415,730,042

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,477.10711
Policy Entropy: 3.24558
Value Function Loss: 0.00347

Mean KL Divergence: 0.00573
SB3 Clip Fraction: 0.06531
Policy Update Magnitude: 0.41676
Value Function Update Magnitude: 0.33079

Collected Steps per Second: 22,310.56803
Overall Steps per Second: 10,840.14763

Timestep Collection Time: 2.24190
Timestep Consumption Time: 2.37225
PPO Batch Consumption Time: 0.28134
Total Iteration Time: 4.61414

Cumulative Model Updates: 49,838
Cumulative Timesteps: 415,780,060

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 415780060...
Checkpoint 415780060 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,164.21361
Policy Entropy: 3.25073
Value Function Loss: 0.00349

Mean KL Divergence: 0.00550
SB3 Clip Fraction: 0.06198
Policy Update Magnitude: 0.41645
Value Function Update Magnitude: 0.33413

Collected Steps per Second: 22,554.92605
Overall Steps per Second: 10,773.53369

Timestep Collection Time: 2.21725
Timestep Consumption Time: 2.42468
PPO Batch Consumption Time: 0.27930
Total Iteration Time: 4.64193

Cumulative Model Updates: 49,844
Cumulative Timesteps: 415,830,070

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 666.88979
Policy Entropy: 3.26333
Value Function Loss: 0.00369

Mean KL Divergence: 0.00527
SB3 Clip Fraction: 0.05793
Policy Update Magnitude: 0.41984
Value Function Update Magnitude: 0.34161

Collected Steps per Second: 23,138.11961
Overall Steps per Second: 10,838.62208

Timestep Collection Time: 2.16189
Timestep Consumption Time: 2.45328
PPO Batch Consumption Time: 0.28216
Total Iteration Time: 4.61516

Cumulative Model Updates: 49,850
Cumulative Timesteps: 415,880,092

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 415880092...
Checkpoint 415880092 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,147.52371
Policy Entropy: 3.27162
Value Function Loss: 0.00366

Mean KL Divergence: 0.00505
SB3 Clip Fraction: 0.05526
Policy Update Magnitude: 0.42215
Value Function Update Magnitude: 0.33194

Collected Steps per Second: 21,174.54095
Overall Steps per Second: 10,594.01169

Timestep Collection Time: 2.36350
Timestep Consumption Time: 2.36049
PPO Batch Consumption Time: 0.28034
Total Iteration Time: 4.72399

Cumulative Model Updates: 49,856
Cumulative Timesteps: 415,930,138

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,253.86285
Policy Entropy: 3.28183
Value Function Loss: 0.00346

Mean KL Divergence: 0.00555
SB3 Clip Fraction: 0.06189
Policy Update Magnitude: 0.41080
Value Function Update Magnitude: 0.32965

Collected Steps per Second: 21,593.07416
Overall Steps per Second: 10,521.12884

Timestep Collection Time: 2.31648
Timestep Consumption Time: 2.43776
PPO Batch Consumption Time: 0.29259
Total Iteration Time: 4.75424

Cumulative Model Updates: 49,862
Cumulative Timesteps: 415,980,158

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 415980158...
Checkpoint 415980158 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 724.74424
Policy Entropy: 3.27811
Value Function Loss: 0.00331

Mean KL Divergence: 0.00573
SB3 Clip Fraction: 0.06248
Policy Update Magnitude: 0.40436
Value Function Update Magnitude: 0.32918

Collected Steps per Second: 21,307.36131
Overall Steps per Second: 10,630.33753

Timestep Collection Time: 2.34726
Timestep Consumption Time: 2.35757
PPO Batch Consumption Time: 0.28063
Total Iteration Time: 4.70484

Cumulative Model Updates: 49,868
Cumulative Timesteps: 416,030,172

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,484.18150
Policy Entropy: 3.27680
Value Function Loss: 0.00313

Mean KL Divergence: 0.00686
SB3 Clip Fraction: 0.07958
Policy Update Magnitude: 0.40077
Value Function Update Magnitude: 0.32614

Collected Steps per Second: 21,552.77150
Overall Steps per Second: 10,449.37863

Timestep Collection Time: 2.32109
Timestep Consumption Time: 2.46637
PPO Batch Consumption Time: 0.29689
Total Iteration Time: 4.78746

Cumulative Model Updates: 49,874
Cumulative Timesteps: 416,080,198

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 416080198...
Checkpoint 416080198 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,757.88529
Policy Entropy: 3.26365
Value Function Loss: 0.00315

Mean KL Divergence: 0.00632
SB3 Clip Fraction: 0.07221
Policy Update Magnitude: 0.40010
Value Function Update Magnitude: 0.32029

Collected Steps per Second: 21,198.33172
Overall Steps per Second: 10,401.37738

Timestep Collection Time: 2.35953
Timestep Consumption Time: 2.44926
PPO Batch Consumption Time: 0.29397
Total Iteration Time: 4.80879

Cumulative Model Updates: 49,880
Cumulative Timesteps: 416,130,216

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 940.78729
Policy Entropy: 3.25951
Value Function Loss: 0.00326

Mean KL Divergence: 0.00567
SB3 Clip Fraction: 0.06251
Policy Update Magnitude: 0.39784
Value Function Update Magnitude: 0.32005

Collected Steps per Second: 22,310.54322
Overall Steps per Second: 10,731.90359

Timestep Collection Time: 2.24109
Timestep Consumption Time: 2.41791
PPO Batch Consumption Time: 0.28530
Total Iteration Time: 4.65901

Cumulative Model Updates: 49,886
Cumulative Timesteps: 416,180,216

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 416180216...
Checkpoint 416180216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,129.24694
Policy Entropy: 3.25758
Value Function Loss: 0.00334

Mean KL Divergence: 0.00618
SB3 Clip Fraction: 0.06779
Policy Update Magnitude: 0.40884
Value Function Update Magnitude: 0.32524

Collected Steps per Second: 22,629.02846
Overall Steps per Second: 10,577.46184

Timestep Collection Time: 2.21070
Timestep Consumption Time: 2.51879
PPO Batch Consumption Time: 0.29267
Total Iteration Time: 4.72949

Cumulative Model Updates: 49,892
Cumulative Timesteps: 416,230,242

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 908.01018
Policy Entropy: 3.25891
Value Function Loss: 0.00344

Mean KL Divergence: 0.00640
SB3 Clip Fraction: 0.07247
Policy Update Magnitude: 0.40870
Value Function Update Magnitude: 0.32944

Collected Steps per Second: 22,599.27539
Overall Steps per Second: 10,552.43680

Timestep Collection Time: 2.21343
Timestep Consumption Time: 2.52689
PPO Batch Consumption Time: 0.29538
Total Iteration Time: 4.74033

Cumulative Model Updates: 49,898
Cumulative Timesteps: 416,280,264

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 416280264...
Checkpoint 416280264 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,092.72059
Policy Entropy: 3.26012
Value Function Loss: 0.00355

Mean KL Divergence: 0.00556
SB3 Clip Fraction: 0.06324
Policy Update Magnitude: 0.41049
Value Function Update Magnitude: 0.33217

Collected Steps per Second: 22,309.28628
Overall Steps per Second: 10,588.65389

Timestep Collection Time: 2.24238
Timestep Consumption Time: 2.48211
PPO Batch Consumption Time: 0.28944
Total Iteration Time: 4.72449

Cumulative Model Updates: 49,904
Cumulative Timesteps: 416,330,290

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,111.19165
Policy Entropy: 3.23517
Value Function Loss: 0.00369

Mean KL Divergence: 0.00577
SB3 Clip Fraction: 0.06490
Policy Update Magnitude: 0.41247
Value Function Update Magnitude: 0.34320

Collected Steps per Second: 22,805.96333
Overall Steps per Second: 10,672.87963

Timestep Collection Time: 2.19320
Timestep Consumption Time: 2.49326
PPO Batch Consumption Time: 0.29023
Total Iteration Time: 4.68646

Cumulative Model Updates: 49,910
Cumulative Timesteps: 416,380,308

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 416380308...
Checkpoint 416380308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,177.31337
Policy Entropy: 3.25037
Value Function Loss: 0.00363

Mean KL Divergence: 0.00528
SB3 Clip Fraction: 0.05929
Policy Update Magnitude: 0.41933
Value Function Update Magnitude: 0.35241

Collected Steps per Second: 22,777.47136
Overall Steps per Second: 10,808.86148

Timestep Collection Time: 2.19541
Timestep Consumption Time: 2.43097
PPO Batch Consumption Time: 0.28093
Total Iteration Time: 4.62639

Cumulative Model Updates: 49,916
Cumulative Timesteps: 416,430,314

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,097.12243
Policy Entropy: 3.25664
Value Function Loss: 0.00341

Mean KL Divergence: 0.00523
SB3 Clip Fraction: 0.05878
Policy Update Magnitude: 0.41841
Value Function Update Magnitude: 0.35408

Collected Steps per Second: 22,456.37535
Overall Steps per Second: 10,518.43117

Timestep Collection Time: 2.22654
Timestep Consumption Time: 2.52702
PPO Batch Consumption Time: 0.29531
Total Iteration Time: 4.75356

Cumulative Model Updates: 49,922
Cumulative Timesteps: 416,480,314

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 416480314...
Checkpoint 416480314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,207.76097
Policy Entropy: 3.26629
Value Function Loss: 0.00327

Mean KL Divergence: 0.00446
SB3 Clip Fraction: 0.04747
Policy Update Magnitude: 0.41737
Value Function Update Magnitude: 0.34213

Collected Steps per Second: 21,367.36340
Overall Steps per Second: 10,632.07969

Timestep Collection Time: 2.34002
Timestep Consumption Time: 2.36273
PPO Batch Consumption Time: 0.28064
Total Iteration Time: 4.70275

Cumulative Model Updates: 49,928
Cumulative Timesteps: 416,530,314

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,001.08057
Policy Entropy: 3.25543
Value Function Loss: 0.00349

Mean KL Divergence: 0.00518
SB3 Clip Fraction: 0.05714
Policy Update Magnitude: 0.41378
Value Function Update Magnitude: 0.33551

Collected Steps per Second: 22,507.81640
Overall Steps per Second: 10,613.95037

Timestep Collection Time: 2.22145
Timestep Consumption Time: 2.48933
PPO Batch Consumption Time: 0.29251
Total Iteration Time: 4.71078

Cumulative Model Updates: 49,934
Cumulative Timesteps: 416,580,314

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 416580314...
Checkpoint 416580314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,107.28531
Policy Entropy: 3.25500
Value Function Loss: 0.00348

Mean KL Divergence: 0.00497
SB3 Clip Fraction: 0.05543
Policy Update Magnitude: 0.41321
Value Function Update Magnitude: 0.33596

Collected Steps per Second: 21,815.11282
Overall Steps per Second: 10,607.34629

Timestep Collection Time: 2.29272
Timestep Consumption Time: 2.42250
PPO Batch Consumption Time: 0.29359
Total Iteration Time: 4.71522

Cumulative Model Updates: 49,940
Cumulative Timesteps: 416,630,330

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,630.51771
Policy Entropy: 3.25402
Value Function Loss: 0.00344

Mean KL Divergence: 0.00550
SB3 Clip Fraction: 0.06171
Policy Update Magnitude: 0.41635
Value Function Update Magnitude: 0.32724

Collected Steps per Second: 21,865.87997
Overall Steps per Second: 10,727.23702

Timestep Collection Time: 2.28786
Timestep Consumption Time: 2.37560
PPO Batch Consumption Time: 0.28120
Total Iteration Time: 4.66346

Cumulative Model Updates: 49,946
Cumulative Timesteps: 416,680,356

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 416680356...
Checkpoint 416680356 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,912.93036
Policy Entropy: 3.25961
Value Function Loss: 0.00337

Mean KL Divergence: 0.00533
SB3 Clip Fraction: 0.05965
Policy Update Magnitude: 0.41151
Value Function Update Magnitude: 0.31979

Collected Steps per Second: 21,265.27086
Overall Steps per Second: 10,612.60573

Timestep Collection Time: 2.35182
Timestep Consumption Time: 2.36069
PPO Batch Consumption Time: 0.28002
Total Iteration Time: 4.71251

Cumulative Model Updates: 49,952
Cumulative Timesteps: 416,730,368

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,553.30772
Policy Entropy: 3.25759
Value Function Loss: 0.00353

Mean KL Divergence: 0.00608
SB3 Clip Fraction: 0.06833
Policy Update Magnitude: 0.41034
Value Function Update Magnitude: 0.32798

Collected Steps per Second: 21,821.31489
Overall Steps per Second: 10,508.50025

Timestep Collection Time: 2.29180
Timestep Consumption Time: 2.46721
PPO Batch Consumption Time: 0.29904
Total Iteration Time: 4.75900

Cumulative Model Updates: 49,958
Cumulative Timesteps: 416,780,378

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 416780378...
Checkpoint 416780378 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,009.97857
Policy Entropy: 3.25147
Value Function Loss: 0.00368

Mean KL Divergence: 0.00619
SB3 Clip Fraction: 0.06828
Policy Update Magnitude: 0.41638
Value Function Update Magnitude: 0.33807

Collected Steps per Second: 21,806.68684
Overall Steps per Second: 10,689.96810

Timestep Collection Time: 2.29425
Timestep Consumption Time: 2.38584
PPO Batch Consumption Time: 0.28504
Total Iteration Time: 4.68009

Cumulative Model Updates: 49,964
Cumulative Timesteps: 416,830,408

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,201.54746
Policy Entropy: 3.24484
Value Function Loss: 0.00357

Mean KL Divergence: 0.00710
SB3 Clip Fraction: 0.07895
Policy Update Magnitude: 0.42156
Value Function Update Magnitude: 0.33826

Collected Steps per Second: 21,862.70147
Overall Steps per Second: 10,614.49675

Timestep Collection Time: 2.28737
Timestep Consumption Time: 2.42393
PPO Batch Consumption Time: 0.29133
Total Iteration Time: 4.71129

Cumulative Model Updates: 49,970
Cumulative Timesteps: 416,880,416

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 416880416...
Checkpoint 416880416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,564.92471
Policy Entropy: 3.24793
Value Function Loss: 0.00345

Mean KL Divergence: 0.00722
SB3 Clip Fraction: 0.08147
Policy Update Magnitude: 0.40642
Value Function Update Magnitude: 0.33452

Collected Steps per Second: 21,991.30821
Overall Steps per Second: 10,668.41470

Timestep Collection Time: 2.27435
Timestep Consumption Time: 2.41388
PPO Batch Consumption Time: 0.28960
Total Iteration Time: 4.68823

Cumulative Model Updates: 49,976
Cumulative Timesteps: 416,930,432

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,203.77874
Policy Entropy: 3.25267
Value Function Loss: 0.00328

Mean KL Divergence: 0.00616
SB3 Clip Fraction: 0.06973
Policy Update Magnitude: 0.39649
Value Function Update Magnitude: 0.32410

Collected Steps per Second: 22,081.30297
Overall Steps per Second: 10,695.64640

Timestep Collection Time: 2.26517
Timestep Consumption Time: 2.41131
PPO Batch Consumption Time: 0.28793
Total Iteration Time: 4.67648

Cumulative Model Updates: 49,982
Cumulative Timesteps: 416,980,450

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 416980450...
Checkpoint 416980450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,582.56053
Policy Entropy: 3.25666
Value Function Loss: 0.00336

Mean KL Divergence: 0.00545
SB3 Clip Fraction: 0.06039
Policy Update Magnitude: 0.39346
Value Function Update Magnitude: 0.32073

Collected Steps per Second: 21,732.89092
Overall Steps per Second: 10,652.99962

Timestep Collection Time: 2.30195
Timestep Consumption Time: 2.39419
PPO Batch Consumption Time: 0.28576
Total Iteration Time: 4.69614

Cumulative Model Updates: 49,988
Cumulative Timesteps: 417,030,478

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,567.24890
Policy Entropy: 3.25004
Value Function Loss: 0.00334

Mean KL Divergence: 0.00559
SB3 Clip Fraction: 0.06202
Policy Update Magnitude: 0.39234
Value Function Update Magnitude: 0.31412

Collected Steps per Second: 21,307.68356
Overall Steps per Second: 10,391.45129

Timestep Collection Time: 2.34723
Timestep Consumption Time: 2.46577
PPO Batch Consumption Time: 0.29148
Total Iteration Time: 4.81299

Cumulative Model Updates: 49,994
Cumulative Timesteps: 417,080,492

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 417080492...
Checkpoint 417080492 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 607.01139
Policy Entropy: 3.25544
Value Function Loss: 0.00339

Mean KL Divergence: 0.00566
SB3 Clip Fraction: 0.06361
Policy Update Magnitude: 0.39483
Value Function Update Magnitude: 0.32342

Collected Steps per Second: 21,261.91715
Overall Steps per Second: 10,602.08203

Timestep Collection Time: 2.35181
Timestep Consumption Time: 2.36462
PPO Batch Consumption Time: 0.28071
Total Iteration Time: 4.71643

Cumulative Model Updates: 50,000
Cumulative Timesteps: 417,130,496

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,121.38072
Policy Entropy: 3.23777
Value Function Loss: 0.00365

Mean KL Divergence: 0.00546
SB3 Clip Fraction: 0.05970
Policy Update Magnitude: 0.39969
Value Function Update Magnitude: 0.32395

Collected Steps per Second: 21,742.31986
Overall Steps per Second: 10,528.70781

Timestep Collection Time: 2.30040
Timestep Consumption Time: 2.45004
PPO Batch Consumption Time: 0.29353
Total Iteration Time: 4.75044

Cumulative Model Updates: 50,006
Cumulative Timesteps: 417,180,512

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 417180512...
Checkpoint 417180512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,319.85183
Policy Entropy: 3.24819
Value Function Loss: 0.00372

Mean KL Divergence: 0.00535
SB3 Clip Fraction: 0.05998
Policy Update Magnitude: 0.41188
Value Function Update Magnitude: 0.33090

Collected Steps per Second: 21,348.82680
Overall Steps per Second: 10,645.32493

Timestep Collection Time: 2.34242
Timestep Consumption Time: 2.35523
PPO Batch Consumption Time: 0.27971
Total Iteration Time: 4.69765

Cumulative Model Updates: 50,012
Cumulative Timesteps: 417,230,520

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,319.13079
Policy Entropy: 3.25876
Value Function Loss: 0.00372

Mean KL Divergence: 0.00702
SB3 Clip Fraction: 0.07657
Policy Update Magnitude: 0.41544
Value Function Update Magnitude: 0.32562

Collected Steps per Second: 22,033.68003
Overall Steps per Second: 10,583.68034

Timestep Collection Time: 2.26971
Timestep Consumption Time: 2.45549
PPO Batch Consumption Time: 0.29328
Total Iteration Time: 4.72520

Cumulative Model Updates: 50,018
Cumulative Timesteps: 417,280,530

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 417280530...
Checkpoint 417280530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,277.90909
Policy Entropy: 3.26588
Value Function Loss: 0.00352

Mean KL Divergence: 0.00619
SB3 Clip Fraction: 0.06799
Policy Update Magnitude: 0.41332
Value Function Update Magnitude: 0.32600

Collected Steps per Second: 21,957.96990
Overall Steps per Second: 10,596.72405

Timestep Collection Time: 2.27835
Timestep Consumption Time: 2.44273
PPO Batch Consumption Time: 0.29328
Total Iteration Time: 4.72108

Cumulative Model Updates: 50,024
Cumulative Timesteps: 417,330,558

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 892.57092
Policy Entropy: 3.24951
Value Function Loss: 0.00352

Mean KL Divergence: 0.00730
SB3 Clip Fraction: 0.08203
Policy Update Magnitude: 0.41579
Value Function Update Magnitude: 0.33157

Collected Steps per Second: 22,160.17621
Overall Steps per Second: 10,801.84039

Timestep Collection Time: 2.25639
Timestep Consumption Time: 2.37264
PPO Batch Consumption Time: 0.28148
Total Iteration Time: 4.62903

Cumulative Model Updates: 50,030
Cumulative Timesteps: 417,380,560

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 417380560...
Checkpoint 417380560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,387.11067
Policy Entropy: 3.24934
Value Function Loss: 0.00355

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.09339
Policy Update Magnitude: 0.41781
Value Function Update Magnitude: 0.33411

Collected Steps per Second: 21,647.26852
Overall Steps per Second: 10,640.06472

Timestep Collection Time: 2.31105
Timestep Consumption Time: 2.39080
PPO Batch Consumption Time: 0.28177
Total Iteration Time: 4.70185

Cumulative Model Updates: 50,036
Cumulative Timesteps: 417,430,588

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 991.48559
Policy Entropy: 3.25359
Value Function Loss: 0.00352

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.08989
Policy Update Magnitude: 0.40900
Value Function Update Magnitude: 0.33327

Collected Steps per Second: 21,858.37160
Overall Steps per Second: 10,633.67188

Timestep Collection Time: 2.28773
Timestep Consumption Time: 2.41488
PPO Batch Consumption Time: 0.29181
Total Iteration Time: 4.70261

Cumulative Model Updates: 50,042
Cumulative Timesteps: 417,480,594

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 417480594...
Checkpoint 417480594 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,781.89179
Policy Entropy: 3.27442
Value Function Loss: 0.00342

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.09045
Policy Update Magnitude: 0.40062
Value Function Update Magnitude: 0.33045

Collected Steps per Second: 21,883.20043
Overall Steps per Second: 10,611.99734

Timestep Collection Time: 2.28559
Timestep Consumption Time: 2.42757
PPO Batch Consumption Time: 0.29341
Total Iteration Time: 4.71316

Cumulative Model Updates: 50,048
Cumulative Timesteps: 417,530,610

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,540.78254
Policy Entropy: 3.28312
Value Function Loss: 0.00333

Mean KL Divergence: 0.00589
SB3 Clip Fraction: 0.06603
Policy Update Magnitude: 0.40380
Value Function Update Magnitude: 0.32329

Collected Steps per Second: 21,842.40317
Overall Steps per Second: 10,751.07478

Timestep Collection Time: 2.28940
Timestep Consumption Time: 2.36186
PPO Batch Consumption Time: 0.28101
Total Iteration Time: 4.65126

Cumulative Model Updates: 50,054
Cumulative Timesteps: 417,580,616

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 417580616...
Checkpoint 417580616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,161.22422
Policy Entropy: 3.28525
Value Function Loss: 0.00323

Mean KL Divergence: 0.00610
SB3 Clip Fraction: 0.06922
Policy Update Magnitude: 0.40655
Value Function Update Magnitude: 0.32398

Collected Steps per Second: 21,814.39496
Overall Steps per Second: 10,677.41733

Timestep Collection Time: 2.29252
Timestep Consumption Time: 2.39119
PPO Batch Consumption Time: 0.28547
Total Iteration Time: 4.68372

Cumulative Model Updates: 50,060
Cumulative Timesteps: 417,630,626

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 869.99250
Policy Entropy: 3.28481
Value Function Loss: 0.00330

Mean KL Divergence: 0.00574
SB3 Clip Fraction: 0.06515
Policy Update Magnitude: 0.40359
Value Function Update Magnitude: 0.31693

Collected Steps per Second: 21,876.75723
Overall Steps per Second: 10,604.58427

Timestep Collection Time: 2.28644
Timestep Consumption Time: 2.43038
PPO Batch Consumption Time: 0.29223
Total Iteration Time: 4.71683

Cumulative Model Updates: 50,066
Cumulative Timesteps: 417,680,646

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 417680646...
Checkpoint 417680646 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,017.67576
Policy Entropy: 3.28409
Value Function Loss: 0.00326

Mean KL Divergence: 0.00524
SB3 Clip Fraction: 0.05925
Policy Update Magnitude: 0.39859
Value Function Update Magnitude: 0.32243

Collected Steps per Second: 21,573.12955
Overall Steps per Second: 10,523.92153

Timestep Collection Time: 2.31844
Timestep Consumption Time: 2.43416
PPO Batch Consumption Time: 0.29316
Total Iteration Time: 4.75260

Cumulative Model Updates: 50,072
Cumulative Timesteps: 417,730,662

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,447.05720
Policy Entropy: 3.27955
Value Function Loss: 0.00329

Mean KL Divergence: 0.00479
SB3 Clip Fraction: 0.05339
Policy Update Magnitude: 0.40339
Value Function Update Magnitude: 0.31557

Collected Steps per Second: 21,799.01087
Overall Steps per Second: 10,585.67655

Timestep Collection Time: 2.29377
Timestep Consumption Time: 2.42978
PPO Batch Consumption Time: 0.29278
Total Iteration Time: 4.72355

Cumulative Model Updates: 50,078
Cumulative Timesteps: 417,780,664

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 417780664...
Checkpoint 417780664 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,051.94814
Policy Entropy: 3.28606
Value Function Loss: 0.00323

Mean KL Divergence: 0.00564
SB3 Clip Fraction: 0.06472
Policy Update Magnitude: 0.40522
Value Function Update Magnitude: 0.31618

Collected Steps per Second: 21,761.68216
Overall Steps per Second: 10,543.55261

Timestep Collection Time: 2.29762
Timestep Consumption Time: 2.44462
PPO Batch Consumption Time: 0.29562
Total Iteration Time: 4.74223

Cumulative Model Updates: 50,084
Cumulative Timesteps: 417,830,664

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 592.26230
Policy Entropy: 3.27974
Value Function Loss: 0.00335

Mean KL Divergence: 0.00515
SB3 Clip Fraction: 0.05607
Policy Update Magnitude: 0.40025
Value Function Update Magnitude: 0.32692

Collected Steps per Second: 22,101.50600
Overall Steps per Second: 10,639.68574

Timestep Collection Time: 2.26310
Timestep Consumption Time: 2.43798
PPO Batch Consumption Time: 0.28907
Total Iteration Time: 4.70108

Cumulative Model Updates: 50,090
Cumulative Timesteps: 417,880,682

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 417880682...
Checkpoint 417880682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 786.56336
Policy Entropy: 3.27535
Value Function Loss: 0.00334

Mean KL Divergence: 0.00554
SB3 Clip Fraction: 0.06149
Policy Update Magnitude: 0.40786
Value Function Update Magnitude: 0.33021

Collected Steps per Second: 22,072.93382
Overall Steps per Second: 10,789.80678

Timestep Collection Time: 2.26540
Timestep Consumption Time: 2.36898
PPO Batch Consumption Time: 0.28197
Total Iteration Time: 4.63437

Cumulative Model Updates: 50,096
Cumulative Timesteps: 417,930,686

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 964.37819
Policy Entropy: 3.26789
Value Function Loss: 0.00354

Mean KL Divergence: 0.00620
SB3 Clip Fraction: 0.07051
Policy Update Magnitude: 0.41289
Value Function Update Magnitude: 0.33390

Collected Steps per Second: 21,604.94067
Overall Steps per Second: 10,532.63088

Timestep Collection Time: 2.31512
Timestep Consumption Time: 2.43374
PPO Batch Consumption Time: 0.29150
Total Iteration Time: 4.74886

Cumulative Model Updates: 50,102
Cumulative Timesteps: 417,980,704

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 417980704...
Checkpoint 417980704 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,805.52160
Policy Entropy: 3.26523
Value Function Loss: 0.00339

Mean KL Divergence: 0.00623
SB3 Clip Fraction: 0.06962
Policy Update Magnitude: 0.40708
Value Function Update Magnitude: 0.33412

Collected Steps per Second: 21,998.89940
Overall Steps per Second: 10,643.13740

Timestep Collection Time: 2.27366
Timestep Consumption Time: 2.42589
PPO Batch Consumption Time: 0.29270
Total Iteration Time: 4.69955

Cumulative Model Updates: 50,108
Cumulative Timesteps: 418,030,722

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,359.64011
Policy Entropy: 3.25164
Value Function Loss: 0.00349

Mean KL Divergence: 0.00551
SB3 Clip Fraction: 0.06059
Policy Update Magnitude: 0.40961
Value Function Update Magnitude: 0.33214

Collected Steps per Second: 22,529.38109
Overall Steps per Second: 10,408.57810

Timestep Collection Time: 2.22021
Timestep Consumption Time: 2.58544
PPO Batch Consumption Time: 0.30548
Total Iteration Time: 4.80565

Cumulative Model Updates: 50,114
Cumulative Timesteps: 418,080,742

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 418080742...
Checkpoint 418080742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 985.00484
Policy Entropy: 3.26635
Value Function Loss: 0.00331

Mean KL Divergence: 0.00530
SB3 Clip Fraction: 0.05858
Policy Update Magnitude: 0.41537
Value Function Update Magnitude: 0.32691

Collected Steps per Second: 21,854.83342
Overall Steps per Second: 10,707.82957

Timestep Collection Time: 2.28901
Timestep Consumption Time: 2.38290
PPO Batch Consumption Time: 0.28265
Total Iteration Time: 4.67191

Cumulative Model Updates: 50,120
Cumulative Timesteps: 418,130,768

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,555.80049
Policy Entropy: 3.25398
Value Function Loss: 0.00350

Mean KL Divergence: 0.00591
SB3 Clip Fraction: 0.06651
Policy Update Magnitude: 0.41355
Value Function Update Magnitude: 0.32403

Collected Steps per Second: 21,913.08880
Overall Steps per Second: 10,622.87958

Timestep Collection Time: 2.28238
Timestep Consumption Time: 2.42576
PPO Batch Consumption Time: 0.29126
Total Iteration Time: 4.70814

Cumulative Model Updates: 50,126
Cumulative Timesteps: 418,180,782

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 418180782...
Checkpoint 418180782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,271.21997
Policy Entropy: 3.26543
Value Function Loss: 0.00349

Mean KL Divergence: 0.00549
SB3 Clip Fraction: 0.06147
Policy Update Magnitude: 0.41045
Value Function Update Magnitude: 0.32489

Collected Steps per Second: 21,702.81488
Overall Steps per Second: 10,582.35290

Timestep Collection Time: 2.30468
Timestep Consumption Time: 2.42187
PPO Batch Consumption Time: 0.29285
Total Iteration Time: 4.72655

Cumulative Model Updates: 50,132
Cumulative Timesteps: 418,230,800

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 992.07849
Policy Entropy: 3.25154
Value Function Loss: 0.00343

Mean KL Divergence: 0.00508
SB3 Clip Fraction: 0.05547
Policy Update Magnitude: 0.41244
Value Function Update Magnitude: 0.31973

Collected Steps per Second: 21,672.44651
Overall Steps per Second: 10,666.28445

Timestep Collection Time: 2.30745
Timestep Consumption Time: 2.38097
PPO Batch Consumption Time: 0.28092
Total Iteration Time: 4.68842

Cumulative Model Updates: 50,138
Cumulative Timesteps: 418,280,808

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 418280808...
Checkpoint 418280808 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,190.95680
Policy Entropy: 3.25498
Value Function Loss: 0.00332

Mean KL Divergence: 0.00567
SB3 Clip Fraction: 0.06302
Policy Update Magnitude: 0.40481
Value Function Update Magnitude: 0.31546

Collected Steps per Second: 21,492.03649
Overall Steps per Second: 10,663.39201

Timestep Collection Time: 2.32644
Timestep Consumption Time: 2.36250
PPO Batch Consumption Time: 0.28045
Total Iteration Time: 4.68894

Cumulative Model Updates: 50,144
Cumulative Timesteps: 418,330,808

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,344.08541
Policy Entropy: 3.24258
Value Function Loss: 0.00337

Mean KL Divergence: 0.00558
SB3 Clip Fraction: 0.06192
Policy Update Magnitude: 0.40507
Value Function Update Magnitude: 0.32441

Collected Steps per Second: 21,625.70650
Overall Steps per Second: 10,531.34667

Timestep Collection Time: 2.31308
Timestep Consumption Time: 2.43674
PPO Batch Consumption Time: 0.29017
Total Iteration Time: 4.74982

Cumulative Model Updates: 50,150
Cumulative Timesteps: 418,380,830

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 418380830...
Checkpoint 418380830 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,253.23623
Policy Entropy: 3.25601
Value Function Loss: 0.00346

Mean KL Divergence: 0.00539
SB3 Clip Fraction: 0.06040
Policy Update Magnitude: 0.40804
Value Function Update Magnitude: 0.34137

Collected Steps per Second: 21,817.71713
Overall Steps per Second: 10,649.60323

Timestep Collection Time: 2.29282
Timestep Consumption Time: 2.40445
PPO Batch Consumption Time: 0.28082
Total Iteration Time: 4.69726

Cumulative Model Updates: 50,156
Cumulative Timesteps: 418,430,854

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,015.23329
Policy Entropy: 3.26472
Value Function Loss: 0.00354

Mean KL Divergence: 0.00509
SB3 Clip Fraction: 0.05515
Policy Update Magnitude: 0.41782
Value Function Update Magnitude: 0.35082

Collected Steps per Second: 21,886.56960
Overall Steps per Second: 10,549.62242

Timestep Collection Time: 2.28460
Timestep Consumption Time: 2.45510
PPO Batch Consumption Time: 0.29430
Total Iteration Time: 4.73970

Cumulative Model Updates: 50,162
Cumulative Timesteps: 418,480,856

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 418480856...
Checkpoint 418480856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,016.54270
Policy Entropy: 3.28115
Value Function Loss: 0.00363

Mean KL Divergence: 0.00614
SB3 Clip Fraction: 0.06921
Policy Update Magnitude: 0.42578
Value Function Update Magnitude: 0.36045

Collected Steps per Second: 21,987.29225
Overall Steps per Second: 10,587.51364

Timestep Collection Time: 2.27431
Timestep Consumption Time: 2.44880
PPO Batch Consumption Time: 0.29570
Total Iteration Time: 4.72311

Cumulative Model Updates: 50,168
Cumulative Timesteps: 418,530,862

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,037.01945
Policy Entropy: 3.27058
Value Function Loss: 0.00359

Mean KL Divergence: 0.00558
SB3 Clip Fraction: 0.06260
Policy Update Magnitude: 0.42688
Value Function Update Magnitude: 0.36603

Collected Steps per Second: 22,858.55189
Overall Steps per Second: 10,796.77185

Timestep Collection Time: 2.18833
Timestep Consumption Time: 2.44472
PPO Batch Consumption Time: 0.28143
Total Iteration Time: 4.63305

Cumulative Model Updates: 50,174
Cumulative Timesteps: 418,580,884

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 418580884...
Checkpoint 418580884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,153.10518
Policy Entropy: 3.26091
Value Function Loss: 0.00372

Mean KL Divergence: 0.00587
SB3 Clip Fraction: 0.06663
Policy Update Magnitude: 0.42532
Value Function Update Magnitude: 0.37566

Collected Steps per Second: 22,352.44194
Overall Steps per Second: 10,702.81604

Timestep Collection Time: 2.23823
Timestep Consumption Time: 2.43624
PPO Batch Consumption Time: 0.28172
Total Iteration Time: 4.67447

Cumulative Model Updates: 50,180
Cumulative Timesteps: 418,630,914

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,033.13723
Policy Entropy: 3.26207
Value Function Loss: 0.00358

Mean KL Divergence: 0.00583
SB3 Clip Fraction: 0.06540
Policy Update Magnitude: 0.42106
Value Function Update Magnitude: 0.36974

Collected Steps per Second: 22,177.61035
Overall Steps per Second: 10,661.24812

Timestep Collection Time: 2.25471
Timestep Consumption Time: 2.43555
PPO Batch Consumption Time: 0.29046
Total Iteration Time: 4.69026

Cumulative Model Updates: 50,186
Cumulative Timesteps: 418,680,918

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 418680918...
Checkpoint 418680918 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,598.21080
Policy Entropy: 3.27966
Value Function Loss: 0.00347

Mean KL Divergence: 0.00735
SB3 Clip Fraction: 0.08100
Policy Update Magnitude: 0.41533
Value Function Update Magnitude: 0.34995

Collected Steps per Second: 22,108.50571
Overall Steps per Second: 10,676.93948

Timestep Collection Time: 2.26284
Timestep Consumption Time: 2.42277
PPO Batch Consumption Time: 0.28978
Total Iteration Time: 4.68561

Cumulative Model Updates: 50,192
Cumulative Timesteps: 418,730,946

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 988.96697
Policy Entropy: 3.26801
Value Function Loss: 0.00343

Mean KL Divergence: 0.00744
SB3 Clip Fraction: 0.08392
Policy Update Magnitude: 0.40750
Value Function Update Magnitude: 0.34981

Collected Steps per Second: 22,428.71464
Overall Steps per Second: 10,528.25468

Timestep Collection Time: 2.22937
Timestep Consumption Time: 2.51994
PPO Batch Consumption Time: 0.29249
Total Iteration Time: 4.74932

Cumulative Model Updates: 50,198
Cumulative Timesteps: 418,780,948

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 418780948...
Checkpoint 418780948 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,064.24782
Policy Entropy: 3.25804
Value Function Loss: 0.00347

Mean KL Divergence: 0.00701
SB3 Clip Fraction: 0.07683
Policy Update Magnitude: 0.40629
Value Function Update Magnitude: 0.34674

Collected Steps per Second: 22,032.36348
Overall Steps per Second: 10,494.38515

Timestep Collection Time: 2.26957
Timestep Consumption Time: 2.49526
PPO Batch Consumption Time: 0.29263
Total Iteration Time: 4.76483

Cumulative Model Updates: 50,204
Cumulative Timesteps: 418,830,952

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 691.14120
Policy Entropy: 3.25621
Value Function Loss: 0.00351

Mean KL Divergence: 0.00668
SB3 Clip Fraction: 0.07277
Policy Update Magnitude: 0.41100
Value Function Update Magnitude: 0.34303

Collected Steps per Second: 22,309.02266
Overall Steps per Second: 10,659.95759

Timestep Collection Time: 2.24134
Timestep Consumption Time: 2.44930
PPO Batch Consumption Time: 0.28100
Total Iteration Time: 4.69064

Cumulative Model Updates: 50,210
Cumulative Timesteps: 418,880,954

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 418880954...
Checkpoint 418880954 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,380.27339
Policy Entropy: 3.26113
Value Function Loss: 0.00342

Mean KL Divergence: 0.00703
SB3 Clip Fraction: 0.07937
Policy Update Magnitude: 0.40790
Value Function Update Magnitude: 0.33950

Collected Steps per Second: 22,109.51824
Overall Steps per Second: 10,653.45070

Timestep Collection Time: 2.26201
Timestep Consumption Time: 2.43243
PPO Batch Consumption Time: 0.28055
Total Iteration Time: 4.69444

Cumulative Model Updates: 50,216
Cumulative Timesteps: 418,930,966

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,022.40831
Policy Entropy: 3.26725
Value Function Loss: 0.00351

Mean KL Divergence: 0.00617
SB3 Clip Fraction: 0.06981
Policy Update Magnitude: 0.40402
Value Function Update Magnitude: 0.34335

Collected Steps per Second: 22,515.51970
Overall Steps per Second: 10,527.70589

Timestep Collection Time: 2.22176
Timestep Consumption Time: 2.52990
PPO Batch Consumption Time: 0.28958
Total Iteration Time: 4.75165

Cumulative Model Updates: 50,222
Cumulative Timesteps: 418,980,990

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 418980990...
Checkpoint 418980990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,391.70683
Policy Entropy: 3.27053
Value Function Loss: 0.00360

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.08776
Policy Update Magnitude: 0.41045
Value Function Update Magnitude: 0.34705

Collected Steps per Second: 22,224.19838
Overall Steps per Second: 10,589.74019

Timestep Collection Time: 2.25016
Timestep Consumption Time: 2.47215
PPO Batch Consumption Time: 0.28067
Total Iteration Time: 4.72231

Cumulative Model Updates: 50,228
Cumulative Timesteps: 419,030,998

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,049.81933
Policy Entropy: 3.27304
Value Function Loss: 0.00373

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.08774
Policy Update Magnitude: 0.42337
Value Function Update Magnitude: 0.35956

Collected Steps per Second: 21,804.39190
Overall Steps per Second: 10,507.18953

Timestep Collection Time: 2.29385
Timestep Consumption Time: 2.46632
PPO Batch Consumption Time: 0.29453
Total Iteration Time: 4.76017

Cumulative Model Updates: 50,234
Cumulative Timesteps: 419,081,014

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 419081014...
Checkpoint 419081014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,259.32196
Policy Entropy: 3.27706
Value Function Loss: 0.00365

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.08588
Policy Update Magnitude: 0.42110
Value Function Update Magnitude: 0.36900

Collected Steps per Second: 21,578.06358
Overall Steps per Second: 10,651.69232

Timestep Collection Time: 2.31837
Timestep Consumption Time: 2.37816
PPO Batch Consumption Time: 0.28177
Total Iteration Time: 4.69653

Cumulative Model Updates: 50,240
Cumulative Timesteps: 419,131,040

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,478.80709
Policy Entropy: 3.28909
Value Function Loss: 0.00355

Mean KL Divergence: 0.00669
SB3 Clip Fraction: 0.07539
Policy Update Magnitude: 0.41553
Value Function Update Magnitude: 0.36620

Collected Steps per Second: 21,861.90069
Overall Steps per Second: 10,575.23206

Timestep Collection Time: 2.28736
Timestep Consumption Time: 2.44124
PPO Batch Consumption Time: 0.29368
Total Iteration Time: 4.72860

Cumulative Model Updates: 50,246
Cumulative Timesteps: 419,181,046

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 419181046...
Checkpoint 419181046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,299.56472
Policy Entropy: 3.29902
Value Function Loss: 0.00335

Mean KL Divergence: 0.00587
SB3 Clip Fraction: 0.06523
Policy Update Magnitude: 0.40587
Value Function Update Magnitude: 0.36144

Collected Steps per Second: 21,927.06755
Overall Steps per Second: 10,609.46793

Timestep Collection Time: 2.28047
Timestep Consumption Time: 2.43268
PPO Batch Consumption Time: 0.29535
Total Iteration Time: 4.71315

Cumulative Model Updates: 50,252
Cumulative Timesteps: 419,231,050

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,384.61044
Policy Entropy: 3.29480
Value Function Loss: 0.00335

Mean KL Divergence: 0.00511
SB3 Clip Fraction: 0.05657
Policy Update Magnitude: 0.40637
Value Function Update Magnitude: 0.34418

Collected Steps per Second: 22,067.82469
Overall Steps per Second: 10,784.03899

Timestep Collection Time: 2.26719
Timestep Consumption Time: 2.37226
PPO Batch Consumption Time: 0.28199
Total Iteration Time: 4.63945

Cumulative Model Updates: 50,258
Cumulative Timesteps: 419,281,082

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 419281082...
Checkpoint 419281082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 963.89656
Policy Entropy: 3.29558
Value Function Loss: 0.00330

Mean KL Divergence: 0.00663
SB3 Clip Fraction: 0.07452
Policy Update Magnitude: 0.40181
Value Function Update Magnitude: 0.33769

Collected Steps per Second: 21,851.32102
Overall Steps per Second: 10,686.19490

Timestep Collection Time: 2.28892
Timestep Consumption Time: 2.39151
PPO Batch Consumption Time: 0.28528
Total Iteration Time: 4.68043

Cumulative Model Updates: 50,264
Cumulative Timesteps: 419,331,098

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,286.56864
Policy Entropy: 3.29047
Value Function Loss: 0.00343

Mean KL Divergence: 0.00691
SB3 Clip Fraction: 0.07829
Policy Update Magnitude: 0.40103
Value Function Update Magnitude: 0.34806

Collected Steps per Second: 21,577.09955
Overall Steps per Second: 10,528.50631

Timestep Collection Time: 2.31829
Timestep Consumption Time: 2.43281
PPO Batch Consumption Time: 0.29419
Total Iteration Time: 4.75110

Cumulative Model Updates: 50,270
Cumulative Timesteps: 419,381,120

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 419381120...
Checkpoint 419381120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,070.88799
Policy Entropy: 3.30697
Value Function Loss: 0.00321

Mean KL Divergence: 0.00617
SB3 Clip Fraction: 0.06969
Policy Update Magnitude: 0.40109
Value Function Update Magnitude: 0.34602

Collected Steps per Second: 21,120.15957
Overall Steps per Second: 10,441.14996

Timestep Collection Time: 2.36883
Timestep Consumption Time: 2.42279
PPO Batch Consumption Time: 0.29229
Total Iteration Time: 4.79162

Cumulative Model Updates: 50,276
Cumulative Timesteps: 419,431,150

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,048.66968
Policy Entropy: 3.29138
Value Function Loss: 0.00329

Mean KL Divergence: 0.00620
SB3 Clip Fraction: 0.06914
Policy Update Magnitude: 0.39771
Value Function Update Magnitude: 0.33898

Collected Steps per Second: 21,597.94291
Overall Steps per Second: 10,588.73614

Timestep Collection Time: 2.31578
Timestep Consumption Time: 2.40773
PPO Batch Consumption Time: 0.28574
Total Iteration Time: 4.72351

Cumulative Model Updates: 50,282
Cumulative Timesteps: 419,481,166

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 419481166...
Checkpoint 419481166 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,699.02553
Policy Entropy: 3.29151
Value Function Loss: 0.00330

Mean KL Divergence: 0.00498
SB3 Clip Fraction: 0.05390
Policy Update Magnitude: 0.39641
Value Function Update Magnitude: 0.33905

Collected Steps per Second: 21,712.12717
Overall Steps per Second: 10,647.24744

Timestep Collection Time: 2.30351
Timestep Consumption Time: 2.39386
PPO Batch Consumption Time: 0.28593
Total Iteration Time: 4.69736

Cumulative Model Updates: 50,288
Cumulative Timesteps: 419,531,180

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 957.84935
Policy Entropy: 3.29019
Value Function Loss: 0.00341

Mean KL Divergence: 0.00521
SB3 Clip Fraction: 0.05768
Policy Update Magnitude: 0.39394
Value Function Update Magnitude: 0.34487

Collected Steps per Second: 22,033.98996
Overall Steps per Second: 10,621.18545

Timestep Collection Time: 2.27076
Timestep Consumption Time: 2.44001
PPO Batch Consumption Time: 0.29124
Total Iteration Time: 4.71077

Cumulative Model Updates: 50,294
Cumulative Timesteps: 419,581,214

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 419581214...
Checkpoint 419581214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,399.74870
Policy Entropy: 3.30023
Value Function Loss: 0.00330

Mean KL Divergence: 0.00466
SB3 Clip Fraction: 0.04916
Policy Update Magnitude: 0.39748
Value Function Update Magnitude: 0.34678

Collected Steps per Second: 22,086.60083
Overall Steps per Second: 10,796.49494

Timestep Collection Time: 2.26436
Timestep Consumption Time: 2.36788
PPO Batch Consumption Time: 0.28138
Total Iteration Time: 4.63224

Cumulative Model Updates: 50,300
Cumulative Timesteps: 419,631,226

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,110.81260
Policy Entropy: 3.31739
Value Function Loss: 0.00346

Mean KL Divergence: 0.00523
SB3 Clip Fraction: 0.05740
Policy Update Magnitude: 0.39922
Value Function Update Magnitude: 0.34972

Collected Steps per Second: 21,873.41715
Overall Steps per Second: 10,550.95958

Timestep Collection Time: 2.28643
Timestep Consumption Time: 2.45361
PPO Batch Consumption Time: 0.29304
Total Iteration Time: 4.74004

Cumulative Model Updates: 50,306
Cumulative Timesteps: 419,681,238

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 419681238...
Checkpoint 419681238 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,100.75783
Policy Entropy: 3.31659
Value Function Loss: 0.00343

Mean KL Divergence: 0.00551
SB3 Clip Fraction: 0.05923
Policy Update Magnitude: 0.41172
Value Function Update Magnitude: 0.35699

Collected Steps per Second: 21,982.30715
Overall Steps per Second: 10,626.70867

Timestep Collection Time: 2.27465
Timestep Consumption Time: 2.43067
PPO Batch Consumption Time: 0.29062
Total Iteration Time: 4.70531

Cumulative Model Updates: 50,312
Cumulative Timesteps: 419,731,240

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,023.55858
Policy Entropy: 3.29694
Value Function Loss: 0.00326

Mean KL Divergence: 0.00560
SB3 Clip Fraction: 0.06219
Policy Update Magnitude: 0.41378
Value Function Update Magnitude: 0.35736

Collected Steps per Second: 22,179.57125
Overall Steps per Second: 10,722.03917

Timestep Collection Time: 2.25505
Timestep Consumption Time: 2.40974
PPO Batch Consumption Time: 0.28883
Total Iteration Time: 4.66478

Cumulative Model Updates: 50,318
Cumulative Timesteps: 419,781,256

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 419781256...
Checkpoint 419781256 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,544.73768
Policy Entropy: 3.29136
Value Function Loss: 0.00326

Mean KL Divergence: 0.00626
SB3 Clip Fraction: 0.06912
Policy Update Magnitude: 0.40386
Value Function Update Magnitude: 0.34562

Collected Steps per Second: 22,013.32817
Overall Steps per Second: 10,810.82857

Timestep Collection Time: 2.27181
Timestep Consumption Time: 2.35411
PPO Batch Consumption Time: 0.28066
Total Iteration Time: 4.62592

Cumulative Model Updates: 50,324
Cumulative Timesteps: 419,831,266

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,791.85936
Policy Entropy: 3.29004
Value Function Loss: 0.00330

Mean KL Divergence: 0.00541
SB3 Clip Fraction: 0.05904
Policy Update Magnitude: 0.40283
Value Function Update Magnitude: 0.34502

Collected Steps per Second: 21,254.60821
Overall Steps per Second: 10,500.99635

Timestep Collection Time: 2.35365
Timestep Consumption Time: 2.41027
PPO Batch Consumption Time: 0.28720
Total Iteration Time: 4.76393

Cumulative Model Updates: 50,330
Cumulative Timesteps: 419,881,292

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 419881292...
Checkpoint 419881292 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,099.99714
Policy Entropy: 3.30537
Value Function Loss: 0.00335

Mean KL Divergence: 0.00588
SB3 Clip Fraction: 0.06587
Policy Update Magnitude: 0.41243
Value Function Update Magnitude: 0.35727

Collected Steps per Second: 21,452.15894
Overall Steps per Second: 10,669.96231

Timestep Collection Time: 2.33217
Timestep Consumption Time: 2.35670
PPO Batch Consumption Time: 0.28024
Total Iteration Time: 4.68886

Cumulative Model Updates: 50,336
Cumulative Timesteps: 419,931,322

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 995.77548
Policy Entropy: 3.30710
Value Function Loss: 0.00329

Mean KL Divergence: 0.00575
SB3 Clip Fraction: 0.06441
Policy Update Magnitude: 0.40462
Value Function Update Magnitude: 0.35439

Collected Steps per Second: 21,545.24676
Overall Steps per Second: 10,550.01225

Timestep Collection Time: 2.32274
Timestep Consumption Time: 2.42076
PPO Batch Consumption Time: 0.28943
Total Iteration Time: 4.74350

Cumulative Model Updates: 50,342
Cumulative Timesteps: 419,981,366

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 419981366...
Checkpoint 419981366 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,199.21704
Policy Entropy: 3.32147
Value Function Loss: 0.00343

Mean KL Divergence: 0.00513
SB3 Clip Fraction: 0.05471
Policy Update Magnitude: 0.40357
Value Function Update Magnitude: 0.35662

Collected Steps per Second: 21,804.67422
Overall Steps per Second: 10,639.77769

Timestep Collection Time: 2.29382
Timestep Consumption Time: 2.40703
PPO Batch Consumption Time: 0.28619
Total Iteration Time: 4.70085

Cumulative Model Updates: 50,348
Cumulative Timesteps: 420,031,382

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,574.25121
Policy Entropy: 3.30164
Value Function Loss: 0.00341

Mean KL Divergence: 0.00605
SB3 Clip Fraction: 0.06836
Policy Update Magnitude: 0.40764
Value Function Update Magnitude: 0.35921

Collected Steps per Second: 21,343.50302
Overall Steps per Second: 10,454.68407

Timestep Collection Time: 2.34338
Timestep Consumption Time: 2.44069
PPO Batch Consumption Time: 0.28859
Total Iteration Time: 4.78408

Cumulative Model Updates: 50,354
Cumulative Timesteps: 420,081,398

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 420081398...
Checkpoint 420081398 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,092.48875
Policy Entropy: 3.28844
Value Function Loss: 0.00347

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.08850
Policy Update Magnitude: 0.40441
Value Function Update Magnitude: 0.36617

Collected Steps per Second: 21,591.30816
Overall Steps per Second: 10,393.14456

Timestep Collection Time: 2.31677
Timestep Consumption Time: 2.49621
PPO Batch Consumption Time: 0.28942
Total Iteration Time: 4.81298

Cumulative Model Updates: 50,360
Cumulative Timesteps: 420,131,420

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,691.82680
Policy Entropy: 3.28186
Value Function Loss: 0.00347

Mean KL Divergence: 0.00733
SB3 Clip Fraction: 0.08079
Policy Update Magnitude: 0.40480
Value Function Update Magnitude: 0.36064

Collected Steps per Second: 21,766.38889
Overall Steps per Second: 10,736.06290

Timestep Collection Time: 2.29813
Timestep Consumption Time: 2.36112
PPO Batch Consumption Time: 0.27956
Total Iteration Time: 4.65925

Cumulative Model Updates: 50,366
Cumulative Timesteps: 420,181,442

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 420181442...
Checkpoint 420181442 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,484.23209
Policy Entropy: 3.27892
Value Function Loss: 0.00348

Mean KL Divergence: 0.00731
SB3 Clip Fraction: 0.08097
Policy Update Magnitude: 0.40362
Value Function Update Magnitude: 0.35262

Collected Steps per Second: 21,948.10834
Overall Steps per Second: 10,578.25950

Timestep Collection Time: 2.27865
Timestep Consumption Time: 2.44916
PPO Batch Consumption Time: 0.29611
Total Iteration Time: 4.72781

Cumulative Model Updates: 50,372
Cumulative Timesteps: 420,231,454

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 792.66487
Policy Entropy: 3.27139
Value Function Loss: 0.00355

Mean KL Divergence: 0.00603
SB3 Clip Fraction: 0.06621
Policy Update Magnitude: 0.40575
Value Function Update Magnitude: 0.35088

Collected Steps per Second: 22,176.53234
Overall Steps per Second: 10,455.46819

Timestep Collection Time: 2.25545
Timestep Consumption Time: 2.52846
PPO Batch Consumption Time: 0.29436
Total Iteration Time: 4.78391

Cumulative Model Updates: 50,378
Cumulative Timesteps: 420,281,472

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 420281472...
Checkpoint 420281472 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,154.11106
Policy Entropy: 3.27601
Value Function Loss: 0.00371

Mean KL Divergence: 0.00600
SB3 Clip Fraction: 0.06696
Policy Update Magnitude: 0.40922
Value Function Update Magnitude: 0.36427

Collected Steps per Second: 22,123.75093
Overall Steps per Second: 10,664.01976

Timestep Collection Time: 2.26083
Timestep Consumption Time: 2.42952
PPO Batch Consumption Time: 0.29291
Total Iteration Time: 4.69035

Cumulative Model Updates: 50,384
Cumulative Timesteps: 420,331,490

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,232.27406
Policy Entropy: 3.29450
Value Function Loss: 0.00360

Mean KL Divergence: 0.00575
SB3 Clip Fraction: 0.06432
Policy Update Magnitude: 0.41550
Value Function Update Magnitude: 0.36580

Collected Steps per Second: 21,745.10443
Overall Steps per Second: 10,563.43957

Timestep Collection Time: 2.29946
Timestep Consumption Time: 2.43404
PPO Batch Consumption Time: 0.29424
Total Iteration Time: 4.73350

Cumulative Model Updates: 50,390
Cumulative Timesteps: 420,381,492

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 420381492...
Checkpoint 420381492 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,490.29186
Policy Entropy: 3.28732
Value Function Loss: 0.00357

Mean KL Divergence: 0.00592
SB3 Clip Fraction: 0.06560
Policy Update Magnitude: 0.41072
Value Function Update Magnitude: 0.36261

Collected Steps per Second: 21,610.82129
Overall Steps per Second: 10,543.91023

Timestep Collection Time: 2.31504
Timestep Consumption Time: 2.42988
PPO Batch Consumption Time: 0.29270
Total Iteration Time: 4.74492

Cumulative Model Updates: 50,396
Cumulative Timesteps: 420,431,522

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,081.44847
Policy Entropy: 3.29014
Value Function Loss: 0.00319

Mean KL Divergence: 0.00580
SB3 Clip Fraction: 0.06455
Policy Update Magnitude: 0.40341
Value Function Update Magnitude: 0.35985

Collected Steps per Second: 21,593.94506
Overall Steps per Second: 10,509.06294

Timestep Collection Time: 2.31602
Timestep Consumption Time: 2.44292
PPO Batch Consumption Time: 0.29457
Total Iteration Time: 4.75894

Cumulative Model Updates: 50,402
Cumulative Timesteps: 420,481,534

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 420481534...
Checkpoint 420481534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,327.95704
Policy Entropy: 3.26630
Value Function Loss: 0.00317

Mean KL Divergence: 0.00594
SB3 Clip Fraction: 0.06760
Policy Update Magnitude: 0.39553
Value Function Update Magnitude: 0.34715

Collected Steps per Second: 21,625.64824
Overall Steps per Second: 10,583.71515

Timestep Collection Time: 2.31272
Timestep Consumption Time: 2.41284
PPO Batch Consumption Time: 0.28872
Total Iteration Time: 4.72556

Cumulative Model Updates: 50,408
Cumulative Timesteps: 420,531,548

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,270.64945
Policy Entropy: 3.27194
Value Function Loss: 0.00313

Mean KL Divergence: 0.00667
SB3 Clip Fraction: 0.07415
Policy Update Magnitude: 0.39250
Value Function Update Magnitude: 0.33789

Collected Steps per Second: 21,720.72974
Overall Steps per Second: 10,566.28101

Timestep Collection Time: 2.30296
Timestep Consumption Time: 2.43115
PPO Batch Consumption Time: 0.29323
Total Iteration Time: 4.73412

Cumulative Model Updates: 50,414
Cumulative Timesteps: 420,581,570

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 420581570...
Checkpoint 420581570 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,603.52098
Policy Entropy: 3.25531
Value Function Loss: 0.00331

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.08758
Policy Update Magnitude: 0.39601
Value Function Update Magnitude: 0.33966

Collected Steps per Second: 21,531.02726
Overall Steps per Second: 10,530.27210

Timestep Collection Time: 2.32325
Timestep Consumption Time: 2.42705
PPO Batch Consumption Time: 0.28977
Total Iteration Time: 4.75030

Cumulative Model Updates: 50,420
Cumulative Timesteps: 420,631,592

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,987.30483
Policy Entropy: 3.24882
Value Function Loss: 0.00339

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.09086
Policy Update Magnitude: 0.40275
Value Function Update Magnitude: 0.33562

Collected Steps per Second: 21,984.09127
Overall Steps per Second: 10,507.72195

Timestep Collection Time: 2.27483
Timestep Consumption Time: 2.48453
PPO Batch Consumption Time: 0.29468
Total Iteration Time: 4.75936

Cumulative Model Updates: 50,426
Cumulative Timesteps: 420,681,602

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 420681602...
Checkpoint 420681602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,574.48711
Policy Entropy: 3.24508
Value Function Loss: 0.00354

Mean KL Divergence: 0.00687
SB3 Clip Fraction: 0.07488
Policy Update Magnitude: 0.40959
Value Function Update Magnitude: 0.34842

Collected Steps per Second: 22,003.16404
Overall Steps per Second: 10,559.10223

Timestep Collection Time: 2.27367
Timestep Consumption Time: 2.46423
PPO Batch Consumption Time: 0.29651
Total Iteration Time: 4.73790

Cumulative Model Updates: 50,432
Cumulative Timesteps: 420,731,630

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,073.65765
Policy Entropy: 3.26186
Value Function Loss: 0.00334

Mean KL Divergence: 0.00670
SB3 Clip Fraction: 0.07596
Policy Update Magnitude: 0.41754
Value Function Update Magnitude: 0.35737

Collected Steps per Second: 22,286.61171
Overall Steps per Second: 10,735.15386

Timestep Collection Time: 2.24350
Timestep Consumption Time: 2.41410
PPO Batch Consumption Time: 0.28579
Total Iteration Time: 4.65760

Cumulative Model Updates: 50,438
Cumulative Timesteps: 420,781,630

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 420781630...
Checkpoint 420781630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,115.60046
Policy Entropy: 3.25906
Value Function Loss: 0.00347

Mean KL Divergence: 0.00705
SB3 Clip Fraction: 0.07936
Policy Update Magnitude: 0.41903
Value Function Update Magnitude: 0.35635

Collected Steps per Second: 21,784.36605
Overall Steps per Second: 10,780.03116

Timestep Collection Time: 2.29614
Timestep Consumption Time: 2.34392
PPO Batch Consumption Time: 0.28135
Total Iteration Time: 4.64006

Cumulative Model Updates: 50,444
Cumulative Timesteps: 420,831,650

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,263.70405
Policy Entropy: 3.25818
Value Function Loss: 0.00350

Mean KL Divergence: 0.00699
SB3 Clip Fraction: 0.07872
Policy Update Magnitude: 0.42706
Value Function Update Magnitude: 0.35945

Collected Steps per Second: 22,015.27866
Overall Steps per Second: 10,530.01784

Timestep Collection Time: 2.27215
Timestep Consumption Time: 2.47827
PPO Batch Consumption Time: 0.29581
Total Iteration Time: 4.75042

Cumulative Model Updates: 50,450
Cumulative Timesteps: 420,881,672

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 420881672...
Checkpoint 420881672 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,409.71606
Policy Entropy: 3.24892
Value Function Loss: 0.00378

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.10094
Policy Update Magnitude: 0.43508
Value Function Update Magnitude: 0.36641

Collected Steps per Second: 21,975.51049
Overall Steps per Second: 10,625.71477

Timestep Collection Time: 2.27526
Timestep Consumption Time: 2.43031
PPO Batch Consumption Time: 0.29263
Total Iteration Time: 4.70557

Cumulative Model Updates: 50,456
Cumulative Timesteps: 420,931,672

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 929.82959
Policy Entropy: 3.27719
Value Function Loss: 0.00363

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.08886
Policy Update Magnitude: 0.43821
Value Function Update Magnitude: 0.36653

Collected Steps per Second: 22,378.57712
Overall Steps per Second: 10,889.94059

Timestep Collection Time: 2.23544
Timestep Consumption Time: 2.35834
PPO Batch Consumption Time: 0.28072
Total Iteration Time: 4.59378

Cumulative Model Updates: 50,462
Cumulative Timesteps: 420,981,698

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 420981698...
Checkpoint 420981698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,569.36478
Policy Entropy: 3.28488
Value Function Loss: 0.00353

Mean KL Divergence: 0.00695
SB3 Clip Fraction: 0.07632
Policy Update Magnitude: 0.44072
Value Function Update Magnitude: 0.36115

Collected Steps per Second: 21,293.77846
Overall Steps per Second: 10,613.29160

Timestep Collection Time: 2.34810
Timestep Consumption Time: 2.36297
PPO Batch Consumption Time: 0.28083
Total Iteration Time: 4.71107

Cumulative Model Updates: 50,468
Cumulative Timesteps: 421,031,698

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 854.68171
Policy Entropy: 3.30032
Value Function Loss: 0.00358

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.08727
Policy Update Magnitude: 0.43249
Value Function Update Magnitude: 0.36027

Collected Steps per Second: 21,941.00289
Overall Steps per Second: 10,591.21309

Timestep Collection Time: 2.28002
Timestep Consumption Time: 2.44333
PPO Batch Consumption Time: 0.29271
Total Iteration Time: 4.72335

Cumulative Model Updates: 50,474
Cumulative Timesteps: 421,081,724

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 421081724...
Checkpoint 421081724 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 840.98114
Policy Entropy: 3.30872
Value Function Loss: 0.00358

Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.08830
Policy Update Magnitude: 0.42590
Value Function Update Magnitude: 0.35897

Collected Steps per Second: 21,638.93052
Overall Steps per Second: 10,498.37873

Timestep Collection Time: 2.31157
Timestep Consumption Time: 2.45297
PPO Batch Consumption Time: 0.29256
Total Iteration Time: 4.76455

Cumulative Model Updates: 50,480
Cumulative Timesteps: 421,131,744

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,952.91484
Policy Entropy: 3.31096
Value Function Loss: 0.00358

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.08663
Policy Update Magnitude: 0.42373
Value Function Update Magnitude: 0.35658

Collected Steps per Second: 21,919.77089
Overall Steps per Second: 10,599.30934

Timestep Collection Time: 2.28205
Timestep Consumption Time: 2.43731
PPO Batch Consumption Time: 0.29379
Total Iteration Time: 4.71936

Cumulative Model Updates: 50,486
Cumulative Timesteps: 421,181,766

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 421181766...
Checkpoint 421181766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,045.70176
Policy Entropy: 3.30639
Value Function Loss: 0.00351

Mean KL Divergence: 0.00695
SB3 Clip Fraction: 0.07603
Policy Update Magnitude: 0.42208
Value Function Update Magnitude: 0.34495

Collected Steps per Second: 21,556.90533
Overall Steps per Second: 10,543.42492

Timestep Collection Time: 2.31981
Timestep Consumption Time: 2.42324
PPO Batch Consumption Time: 0.29092
Total Iteration Time: 4.74305

Cumulative Model Updates: 50,492
Cumulative Timesteps: 421,231,774

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,260.24767
Policy Entropy: 3.29778
Value Function Loss: 0.00355

Mean KL Divergence: 0.00599
SB3 Clip Fraction: 0.06604
Policy Update Magnitude: 0.42304
Value Function Update Magnitude: 0.34534

Collected Steps per Second: 22,931.23463
Overall Steps per Second: 10,779.14822

Timestep Collection Time: 2.18096
Timestep Consumption Time: 2.45874
PPO Batch Consumption Time: 0.28077
Total Iteration Time: 4.63970

Cumulative Model Updates: 50,498
Cumulative Timesteps: 421,281,786

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 421281786...
Checkpoint 421281786 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,313.00826
Policy Entropy: 3.30369
Value Function Loss: 0.00352

Mean KL Divergence: 0.00534
SB3 Clip Fraction: 0.05768
Policy Update Magnitude: 0.42743
Value Function Update Magnitude: 0.35120

Collected Steps per Second: 22,085.72368
Overall Steps per Second: 10,680.21718

Timestep Collection Time: 2.26472
Timestep Consumption Time: 2.41852
PPO Batch Consumption Time: 0.28795
Total Iteration Time: 4.68324

Cumulative Model Updates: 50,504
Cumulative Timesteps: 421,331,804

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 846.33468
Policy Entropy: 3.29447
Value Function Loss: 0.00365

Mean KL Divergence: 0.00540
SB3 Clip Fraction: 0.05831
Policy Update Magnitude: 0.42893
Value Function Update Magnitude: 0.37045

Collected Steps per Second: 22,922.02484
Overall Steps per Second: 10,695.85714

Timestep Collection Time: 2.18253
Timestep Consumption Time: 2.49480
PPO Batch Consumption Time: 0.29222
Total Iteration Time: 4.67732

Cumulative Model Updates: 50,510
Cumulative Timesteps: 421,381,832

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 421381832...
Checkpoint 421381832 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,161.23361
Policy Entropy: 3.28947
Value Function Loss: 0.00368

Mean KL Divergence: 0.00520
SB3 Clip Fraction: 0.05720
Policy Update Magnitude: 0.43971
Value Function Update Magnitude: 0.38494

Collected Steps per Second: 22,791.23389
Overall Steps per Second: 10,812.49792

Timestep Collection Time: 2.19426
Timestep Consumption Time: 2.43094
PPO Batch Consumption Time: 0.28214
Total Iteration Time: 4.62520

Cumulative Model Updates: 50,516
Cumulative Timesteps: 421,431,842

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 799.03626
Policy Entropy: 3.27153
Value Function Loss: 0.00389

Mean KL Divergence: 0.00616
SB3 Clip Fraction: 0.07014
Policy Update Magnitude: 0.44225
Value Function Update Magnitude: 0.37067

Collected Steps per Second: 22,938.62928
Overall Steps per Second: 10,527.22745

Timestep Collection Time: 2.18051
Timestep Consumption Time: 2.57078
PPO Batch Consumption Time: 0.30087
Total Iteration Time: 4.75130

Cumulative Model Updates: 50,522
Cumulative Timesteps: 421,481,860

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 421481860...
Checkpoint 421481860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,455.06411
Policy Entropy: 3.27959
Value Function Loss: 0.00384

Mean KL Divergence: 0.00614
SB3 Clip Fraction: 0.06888
Policy Update Magnitude: 0.43868
Value Function Update Magnitude: 0.36669

Collected Steps per Second: 22,498.74979
Overall Steps per Second: 10,657.55894

Timestep Collection Time: 2.22243
Timestep Consumption Time: 2.46926
PPO Batch Consumption Time: 0.28672
Total Iteration Time: 4.69169

Cumulative Model Updates: 50,528
Cumulative Timesteps: 421,531,862

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 954.56996
Policy Entropy: 3.28324
Value Function Loss: 0.00360

Mean KL Divergence: 0.00746
SB3 Clip Fraction: 0.08426
Policy Update Magnitude: 0.42420
Value Function Update Magnitude: 0.36336

Collected Steps per Second: 22,200.83128
Overall Steps per Second: 10,477.13639

Timestep Collection Time: 2.25298
Timestep Consumption Time: 2.52104
PPO Batch Consumption Time: 0.29014
Total Iteration Time: 4.77401

Cumulative Model Updates: 50,534
Cumulative Timesteps: 421,581,880

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 421581880...
Checkpoint 421581880 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,081.76541
Policy Entropy: 3.29716
Value Function Loss: 0.00337

Mean KL Divergence: 0.00636
SB3 Clip Fraction: 0.07129
Policy Update Magnitude: 0.41379
Value Function Update Magnitude: 0.35480

Collected Steps per Second: 21,014.24806
Overall Steps per Second: 10,561.52331

Timestep Collection Time: 2.38096
Timestep Consumption Time: 2.35643
PPO Batch Consumption Time: 0.28062
Total Iteration Time: 4.73738

Cumulative Model Updates: 50,540
Cumulative Timesteps: 421,631,914

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 885.79143
Policy Entropy: 3.28500
Value Function Loss: 0.00353

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.08688
Policy Update Magnitude: 0.41922
Value Function Update Magnitude: 0.36167

Collected Steps per Second: 21,714.60459
Overall Steps per Second: 10,566.00008

Timestep Collection Time: 2.30343
Timestep Consumption Time: 2.43044
PPO Batch Consumption Time: 0.29020
Total Iteration Time: 4.73386

Cumulative Model Updates: 50,546
Cumulative Timesteps: 421,681,932

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 421681932...
Checkpoint 421681932 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 942.28067
Policy Entropy: 3.27793
Value Function Loss: 0.00361

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.09477
Policy Update Magnitude: 0.42210
Value Function Update Magnitude: 0.37510

Collected Steps per Second: 21,808.20336
Overall Steps per Second: 10,563.27810

Timestep Collection Time: 2.29345
Timestep Consumption Time: 2.44144
PPO Batch Consumption Time: 0.29120
Total Iteration Time: 4.73489

Cumulative Model Updates: 50,552
Cumulative Timesteps: 421,731,948

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,098.60919
Policy Entropy: 3.28166
Value Function Loss: 0.00361

Mean KL Divergence: 0.00705
SB3 Clip Fraction: 0.08156
Policy Update Magnitude: 0.41960
Value Function Update Magnitude: 0.36693

Collected Steps per Second: 22,995.02315
Overall Steps per Second: 10,643.99489

Timestep Collection Time: 2.17525
Timestep Consumption Time: 2.52411
PPO Batch Consumption Time: 0.29291
Total Iteration Time: 4.69936

Cumulative Model Updates: 50,558
Cumulative Timesteps: 421,781,968

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 421781968...
Checkpoint 421781968 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 918.24308
Policy Entropy: 3.28454
Value Function Loss: 0.00351

Mean KL Divergence: 0.00597
SB3 Clip Fraction: 0.06750
Policy Update Magnitude: 0.41233
Value Function Update Magnitude: 0.35818

Collected Steps per Second: 22,700.57323
Overall Steps per Second: 10,629.78569

Timestep Collection Time: 2.20382
Timestep Consumption Time: 2.50258
PPO Batch Consumption Time: 0.29272
Total Iteration Time: 4.70640

Cumulative Model Updates: 50,564
Cumulative Timesteps: 421,831,996

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,236.49513
Policy Entropy: 3.29073
Value Function Loss: 0.00343

Mean KL Divergence: 0.00604
SB3 Clip Fraction: 0.06710
Policy Update Magnitude: 0.41239
Value Function Update Magnitude: 0.35401

Collected Steps per Second: 22,905.24508
Overall Steps per Second: 10,806.71963

Timestep Collection Time: 2.18326
Timestep Consumption Time: 2.44424
PPO Batch Consumption Time: 0.28067
Total Iteration Time: 4.62749

Cumulative Model Updates: 50,570
Cumulative Timesteps: 421,882,004

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 421882004...
Checkpoint 421882004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,510.95219
Policy Entropy: 3.29833
Value Function Loss: 0.00353

Mean KL Divergence: 0.00728
SB3 Clip Fraction: 0.08006
Policy Update Magnitude: 0.42056
Value Function Update Magnitude: 0.35877

Collected Steps per Second: 22,463.08237
Overall Steps per Second: 10,627.39462

Timestep Collection Time: 2.22587
Timestep Consumption Time: 2.47895
PPO Batch Consumption Time: 0.28926
Total Iteration Time: 4.70482

Cumulative Model Updates: 50,576
Cumulative Timesteps: 421,932,004

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,289.83132
Policy Entropy: 3.30856
Value Function Loss: 0.00344

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.09411
Policy Update Magnitude: 0.42236
Value Function Update Magnitude: 0.36220

Collected Steps per Second: 22,453.78754
Overall Steps per Second: 10,609.12996

Timestep Collection Time: 2.22778
Timestep Consumption Time: 2.48722
PPO Batch Consumption Time: 0.29236
Total Iteration Time: 4.71500

Cumulative Model Updates: 50,582
Cumulative Timesteps: 421,982,026

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 421982026...
Checkpoint 421982026 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 981.09761
Policy Entropy: 3.30259
Value Function Loss: 0.00350

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.08752
Policy Update Magnitude: 0.42408
Value Function Update Magnitude: 0.36144

Collected Steps per Second: 21,840.31843
Overall Steps per Second: 10,617.24068

Timestep Collection Time: 2.29008
Timestep Consumption Time: 2.42075
PPO Batch Consumption Time: 0.29318
Total Iteration Time: 4.71083

Cumulative Model Updates: 50,588
Cumulative Timesteps: 422,032,042

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 978.71177
Policy Entropy: 3.30665
Value Function Loss: 0.00357

Mean KL Divergence: 0.00627
SB3 Clip Fraction: 0.06730
Policy Update Magnitude: 0.42389
Value Function Update Magnitude: 0.37162

Collected Steps per Second: 21,917.12105
Overall Steps per Second: 10,750.76529

Timestep Collection Time: 2.28214
Timestep Consumption Time: 2.37036
PPO Batch Consumption Time: 0.28144
Total Iteration Time: 4.65251

Cumulative Model Updates: 50,594
Cumulative Timesteps: 422,082,060

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 422082060...
Checkpoint 422082060 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,481.15089
Policy Entropy: 3.29487
Value Function Loss: 0.00351

Mean KL Divergence: 0.00605
SB3 Clip Fraction: 0.06790
Policy Update Magnitude: 0.42853
Value Function Update Magnitude: 0.37077

Collected Steps per Second: 21,269.28387
Overall Steps per Second: 10,441.37078

Timestep Collection Time: 2.35147
Timestep Consumption Time: 2.43852
PPO Batch Consumption Time: 0.29488
Total Iteration Time: 4.78998

Cumulative Model Updates: 50,600
Cumulative Timesteps: 422,132,074

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,495.88150
Policy Entropy: 3.30236
Value Function Loss: 0.00354

Mean KL Divergence: 0.00572
SB3 Clip Fraction: 0.06378
Policy Update Magnitude: 0.43201
Value Function Update Magnitude: 0.37094

Collected Steps per Second: 21,649.05139
Overall Steps per Second: 10,674.25983

Timestep Collection Time: 2.30966
Timestep Consumption Time: 2.37469
PPO Batch Consumption Time: 0.27983
Total Iteration Time: 4.68435

Cumulative Model Updates: 50,606
Cumulative Timesteps: 422,182,076

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 422182076...
Checkpoint 422182076 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,045.92347
Policy Entropy: 3.28700
Value Function Loss: 0.00360

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.08425
Policy Update Magnitude: 0.43309
Value Function Update Magnitude: 0.36661

Collected Steps per Second: 21,258.16855
Overall Steps per Second: 10,560.07232

Timestep Collection Time: 2.35279
Timestep Consumption Time: 2.38354
PPO Batch Consumption Time: 0.28096
Total Iteration Time: 4.73633

Cumulative Model Updates: 50,612
Cumulative Timesteps: 422,232,092

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 952.34392
Policy Entropy: 3.29884
Value Function Loss: 0.00385

Mean KL Divergence: 0.00704
SB3 Clip Fraction: 0.07876
Policy Update Magnitude: 0.43136
Value Function Update Magnitude: 0.37517

Collected Steps per Second: 22,125.88701
Overall Steps per Second: 10,546.42513

Timestep Collection Time: 2.25989
Timestep Consumption Time: 2.48125
PPO Batch Consumption Time: 0.29433
Total Iteration Time: 4.74113

Cumulative Model Updates: 50,618
Cumulative Timesteps: 422,282,094

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 422282094...
Checkpoint 422282094 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,092.13803
Policy Entropy: 3.29795
Value Function Loss: 0.00365

Mean KL Divergence: 0.00660
SB3 Clip Fraction: 0.07365
Policy Update Magnitude: 0.43997
Value Function Update Magnitude: 0.38548

Collected Steps per Second: 21,908.28324
Overall Steps per Second: 10,455.81997

Timestep Collection Time: 2.28233
Timestep Consumption Time: 2.49988
PPO Batch Consumption Time: 0.29766
Total Iteration Time: 4.78222

Cumulative Model Updates: 50,624
Cumulative Timesteps: 422,332,096

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,702.43260
Policy Entropy: 3.29970
Value Function Loss: 0.00353

Mean KL Divergence: 0.00647
SB3 Clip Fraction: 0.07306
Policy Update Magnitude: 0.44209
Value Function Update Magnitude: 0.38499

Collected Steps per Second: 22,057.68922
Overall Steps per Second: 10,632.96884

Timestep Collection Time: 2.26751
Timestep Consumption Time: 2.43635
PPO Batch Consumption Time: 0.29400
Total Iteration Time: 4.70386

Cumulative Model Updates: 50,630
Cumulative Timesteps: 422,382,112

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 422382112...
Checkpoint 422382112 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,394.16990
Policy Entropy: 3.29390
Value Function Loss: 0.00332

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.09986
Policy Update Magnitude: 0.42330
Value Function Update Magnitude: 0.36714

Collected Steps per Second: 21,717.25777
Overall Steps per Second: 10,627.16620

Timestep Collection Time: 2.30305
Timestep Consumption Time: 2.40338
PPO Batch Consumption Time: 0.28859
Total Iteration Time: 4.70643

Cumulative Model Updates: 50,636
Cumulative Timesteps: 422,432,128

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,573.62417
Policy Entropy: 3.28840
Value Function Loss: 0.00329

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.08642
Policy Update Magnitude: 0.41446
Value Function Update Magnitude: 0.36141

Collected Steps per Second: 22,073.78661
Overall Steps per Second: 10,785.93404

Timestep Collection Time: 2.26567
Timestep Consumption Time: 2.37111
PPO Batch Consumption Time: 0.28155
Total Iteration Time: 4.63678

Cumulative Model Updates: 50,642
Cumulative Timesteps: 422,482,140

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 422482140...
Checkpoint 422482140 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,945.60679
Policy Entropy: 3.29150
Value Function Loss: 0.00320

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.09984
Policy Update Magnitude: 0.41123
Value Function Update Magnitude: 0.35507

Collected Steps per Second: 22,078.39857
Overall Steps per Second: 10,745.34946

Timestep Collection Time: 2.26602
Timestep Consumption Time: 2.38995
PPO Batch Consumption Time: 0.28514
Total Iteration Time: 4.65597

Cumulative Model Updates: 50,648
Cumulative Timesteps: 422,532,170

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,466.35274
Policy Entropy: 3.28858
Value Function Loss: 0.00336

Mean KL Divergence: 0.01074
SB3 Clip Fraction: 0.10878
Policy Update Magnitude: 0.41056
Value Function Update Magnitude: 0.35606

Collected Steps per Second: 22,099.89272
Overall Steps per Second: 10,696.14787

Timestep Collection Time: 2.26354
Timestep Consumption Time: 2.41328
PPO Batch Consumption Time: 0.28839
Total Iteration Time: 4.67682

Cumulative Model Updates: 50,654
Cumulative Timesteps: 422,582,194

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 422582194...
Checkpoint 422582194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,814.61541
Policy Entropy: 3.30714
Value Function Loss: 0.00325

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.09855
Policy Update Magnitude: 0.41496
Value Function Update Magnitude: 0.34726

Collected Steps per Second: 21,507.23956
Overall Steps per Second: 10,527.69957

Timestep Collection Time: 2.32573
Timestep Consumption Time: 2.42555
PPO Batch Consumption Time: 0.29348
Total Iteration Time: 4.75128

Cumulative Model Updates: 50,660
Cumulative Timesteps: 422,632,214

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 800.08602
Policy Entropy: 3.30549
Value Function Loss: 0.00330

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.09080
Policy Update Magnitude: 0.41522
Value Function Update Magnitude: 0.36714

Collected Steps per Second: 21,816.75997
Overall Steps per Second: 10,719.83690

Timestep Collection Time: 2.29356
Timestep Consumption Time: 2.37424
PPO Batch Consumption Time: 0.28162
Total Iteration Time: 4.66779

Cumulative Model Updates: 50,666
Cumulative Timesteps: 422,682,252

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 422682252...
Checkpoint 422682252 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 812.23059
Policy Entropy: 3.29775
Value Function Loss: 0.00325

Mean KL Divergence: 0.00703
SB3 Clip Fraction: 0.07797
Policy Update Magnitude: 0.41354
Value Function Update Magnitude: 0.37700

Collected Steps per Second: 21,496.51251
Overall Steps per Second: 10,658.55521

Timestep Collection Time: 2.32745
Timestep Consumption Time: 2.36662
PPO Batch Consumption Time: 0.28101
Total Iteration Time: 4.69407

Cumulative Model Updates: 50,672
Cumulative Timesteps: 422,732,284

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 905.34302
Policy Entropy: 3.30133
Value Function Loss: 0.00350

Mean KL Divergence: 0.00625
SB3 Clip Fraction: 0.07060
Policy Update Magnitude: 0.41982
Value Function Update Magnitude: 0.38355

Collected Steps per Second: 21,152.73748
Overall Steps per Second: 10,446.61679

Timestep Collection Time: 2.36423
Timestep Consumption Time: 2.42296
PPO Batch Consumption Time: 0.28459
Total Iteration Time: 4.78720

Cumulative Model Updates: 50,678
Cumulative Timesteps: 422,782,294

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 422782294...
Checkpoint 422782294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,047.74058
Policy Entropy: 3.30509
Value Function Loss: 0.00361

Mean KL Divergence: 0.00720
SB3 Clip Fraction: 0.08077
Policy Update Magnitude: 0.43097
Value Function Update Magnitude: 0.40293

Collected Steps per Second: 21,211.00531
Overall Steps per Second: 10,494.20764

Timestep Collection Time: 2.35793
Timestep Consumption Time: 2.40794
PPO Batch Consumption Time: 0.28913
Total Iteration Time: 4.76587

Cumulative Model Updates: 50,684
Cumulative Timesteps: 422,832,308

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 710.13350
Policy Entropy: 3.30722
Value Function Loss: 0.00342

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.09910
Policy Update Magnitude: 0.42922
Value Function Update Magnitude: 0.41699

Collected Steps per Second: 22,347.62487
Overall Steps per Second: 10,677.61295

Timestep Collection Time: 2.23791
Timestep Consumption Time: 2.44591
PPO Batch Consumption Time: 0.28908
Total Iteration Time: 4.68382

Cumulative Model Updates: 50,690
Cumulative Timesteps: 422,882,320

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 422882320...
Checkpoint 422882320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,625.29755
Policy Entropy: 3.29702
Value Function Loss: 0.00349

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.08723
Policy Update Magnitude: 0.42131
Value Function Update Magnitude: 0.41248

Collected Steps per Second: 21,714.29564
Overall Steps per Second: 10,518.70584

Timestep Collection Time: 2.30392
Timestep Consumption Time: 2.45218
PPO Batch Consumption Time: 0.29061
Total Iteration Time: 4.75610

Cumulative Model Updates: 50,696
Cumulative Timesteps: 422,932,348

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 933.06856
Policy Entropy: 3.29088
Value Function Loss: 0.00345

Mean KL Divergence: 0.00712
SB3 Clip Fraction: 0.07898
Policy Update Magnitude: 0.42400
Value Function Update Magnitude: 0.41564

Collected Steps per Second: 21,803.86201
Overall Steps per Second: 10,537.03776

Timestep Collection Time: 2.29409
Timestep Consumption Time: 2.45298
PPO Batch Consumption Time: 0.29437
Total Iteration Time: 4.74706

Cumulative Model Updates: 50,702
Cumulative Timesteps: 422,982,368

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 422982368...
Checkpoint 422982368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,285.40426
Policy Entropy: 3.28320
Value Function Loss: 0.00360

Mean KL Divergence: 0.00690
SB3 Clip Fraction: 0.07627
Policy Update Magnitude: 0.43391
Value Function Update Magnitude: 0.42136

Collected Steps per Second: 21,593.44873
Overall Steps per Second: 10,671.82131

Timestep Collection Time: 2.31681
Timestep Consumption Time: 2.37105
PPO Batch Consumption Time: 0.28073
Total Iteration Time: 4.68786

Cumulative Model Updates: 50,708
Cumulative Timesteps: 423,032,396

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,370.70984
Policy Entropy: 3.29472
Value Function Loss: 0.00340

Mean KL Divergence: 0.00550
SB3 Clip Fraction: 0.06096
Policy Update Magnitude: 0.43460
Value Function Update Magnitude: 0.40500

Collected Steps per Second: 22,161.00219
Overall Steps per Second: 10,809.65931

Timestep Collection Time: 2.25631
Timestep Consumption Time: 2.36937
PPO Batch Consumption Time: 0.28094
Total Iteration Time: 4.62568

Cumulative Model Updates: 50,714
Cumulative Timesteps: 423,082,398

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 423082398...
Checkpoint 423082398 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,254.13247
Policy Entropy: 3.29529
Value Function Loss: 0.00362

Mean KL Divergence: 0.00555
SB3 Clip Fraction: 0.06235
Policy Update Magnitude: 0.42896
Value Function Update Magnitude: 0.39785

Collected Steps per Second: 21,884.90172
Overall Steps per Second: 10,727.44033

Timestep Collection Time: 2.28486
Timestep Consumption Time: 2.37645
PPO Batch Consumption Time: 0.28047
Total Iteration Time: 4.66132

Cumulative Model Updates: 50,720
Cumulative Timesteps: 423,132,402

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 844.15526
Policy Entropy: 3.29493
Value Function Loss: 0.00356

Mean KL Divergence: 0.00649
SB3 Clip Fraction: 0.07250
Policy Update Magnitude: 0.43005
Value Function Update Magnitude: 0.39930

Collected Steps per Second: 21,632.82326
Overall Steps per Second: 10,510.62127

Timestep Collection Time: 2.31260
Timestep Consumption Time: 2.44716
PPO Batch Consumption Time: 0.29499
Total Iteration Time: 4.75976

Cumulative Model Updates: 50,726
Cumulative Timesteps: 423,182,430

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 423182430...
Checkpoint 423182430 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 879.95524
Policy Entropy: 3.29235
Value Function Loss: 0.00355

Mean KL Divergence: 0.00743
SB3 Clip Fraction: 0.08214
Policy Update Magnitude: 0.43140
Value Function Update Magnitude: 0.37875

Collected Steps per Second: 21,632.69220
Overall Steps per Second: 10,587.63244

Timestep Collection Time: 2.31224
Timestep Consumption Time: 2.41214
PPO Batch Consumption Time: 0.29015
Total Iteration Time: 4.72438

Cumulative Model Updates: 50,732
Cumulative Timesteps: 423,232,450

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 942.05980
Policy Entropy: 3.29476
Value Function Loss: 0.00355

Mean KL Divergence: 0.00733
SB3 Clip Fraction: 0.08202
Policy Update Magnitude: 0.42334
Value Function Update Magnitude: 0.35771

Collected Steps per Second: 21,762.38976
Overall Steps per Second: 10,537.45731

Timestep Collection Time: 2.29791
Timestep Consumption Time: 2.44783
PPO Batch Consumption Time: 0.29415
Total Iteration Time: 4.74574

Cumulative Model Updates: 50,738
Cumulative Timesteps: 423,282,458

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 423282458...
Checkpoint 423282458 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 998.25234
Policy Entropy: 3.30476
Value Function Loss: 0.00354

Mean KL Divergence: 0.00724
SB3 Clip Fraction: 0.08043
Policy Update Magnitude: 0.42176
Value Function Update Magnitude: 0.37480

Collected Steps per Second: 21,495.70198
Overall Steps per Second: 10,558.29592

Timestep Collection Time: 2.32651
Timestep Consumption Time: 2.41005
PPO Batch Consumption Time: 0.28909
Total Iteration Time: 4.73656

Cumulative Model Updates: 50,744
Cumulative Timesteps: 423,332,468

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,452.28165
Policy Entropy: 3.30261
Value Function Loss: 0.00340

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.08558
Policy Update Magnitude: 0.42146
Value Function Update Magnitude: 0.39341

Collected Steps per Second: 21,815.80401
Overall Steps per Second: 10,571.92924

Timestep Collection Time: 2.29210
Timestep Consumption Time: 2.43778
PPO Batch Consumption Time: 0.29290
Total Iteration Time: 4.72988

Cumulative Model Updates: 50,750
Cumulative Timesteps: 423,382,472

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 423382472...
Checkpoint 423382472 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,370.38981
Policy Entropy: 3.31101
Value Function Loss: 0.00344

Mean KL Divergence: 0.00566
SB3 Clip Fraction: 0.06113
Policy Update Magnitude: 0.42903
Value Function Update Magnitude: 0.38668

Collected Steps per Second: 21,228.77722
Overall Steps per Second: 10,479.16620

Timestep Collection Time: 2.35567
Timestep Consumption Time: 2.41647
PPO Batch Consumption Time: 0.28074
Total Iteration Time: 4.77214

Cumulative Model Updates: 50,756
Cumulative Timesteps: 423,432,480

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 844.84638
Policy Entropy: 3.31701
Value Function Loss: 0.00345

Mean KL Divergence: 0.00554
SB3 Clip Fraction: 0.06126
Policy Update Magnitude: 0.44064
Value Function Update Magnitude: 0.38105

Collected Steps per Second: 21,864.50877
Overall Steps per Second: 10,543.15928

Timestep Collection Time: 2.28727
Timestep Consumption Time: 2.45609
PPO Batch Consumption Time: 0.29443
Total Iteration Time: 4.74336

Cumulative Model Updates: 50,762
Cumulative Timesteps: 423,482,490

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 423482490...
Checkpoint 423482490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 996.04615
Policy Entropy: 3.32199
Value Function Loss: 0.00361

Mean KL Divergence: 0.00672
SB3 Clip Fraction: 0.07520
Policy Update Magnitude: 0.44159
Value Function Update Magnitude: 0.39008

Collected Steps per Second: 21,869.93878
Overall Steps per Second: 10,551.19658

Timestep Collection Time: 2.28762
Timestep Consumption Time: 2.45403
PPO Batch Consumption Time: 0.29395
Total Iteration Time: 4.74164

Cumulative Model Updates: 50,768
Cumulative Timesteps: 423,532,520

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 973.91530
Policy Entropy: 3.31866
Value Function Loss: 0.00357

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.09811
Policy Update Magnitude: 0.44180
Value Function Update Magnitude: 0.39106

Collected Steps per Second: 22,007.83839
Overall Steps per Second: 10,636.34941

Timestep Collection Time: 2.27274
Timestep Consumption Time: 2.42982
PPO Batch Consumption Time: 0.29248
Total Iteration Time: 4.70255

Cumulative Model Updates: 50,774
Cumulative Timesteps: 423,582,538

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 423582538...
Checkpoint 423582538 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 675.47511
Policy Entropy: 3.31547
Value Function Loss: 0.00357

Mean KL Divergence: 0.00751
SB3 Clip Fraction: 0.08328
Policy Update Magnitude: 0.44053
Value Function Update Magnitude: 0.39693

Collected Steps per Second: 21,857.77544
Overall Steps per Second: 10,561.79443

Timestep Collection Time: 2.28834
Timestep Consumption Time: 2.44741
PPO Batch Consumption Time: 0.29560
Total Iteration Time: 4.73575

Cumulative Model Updates: 50,780
Cumulative Timesteps: 423,632,556

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,233.83577
Policy Entropy: 3.30323
Value Function Loss: 0.00342

Mean KL Divergence: 0.00595
SB3 Clip Fraction: 0.06522
Policy Update Magnitude: 0.44601
Value Function Update Magnitude: 0.38828

Collected Steps per Second: 22,346.56637
Overall Steps per Second: 10,836.22473

Timestep Collection Time: 2.23855
Timestep Consumption Time: 2.37781
PPO Batch Consumption Time: 0.28163
Total Iteration Time: 4.61637

Cumulative Model Updates: 50,786
Cumulative Timesteps: 423,682,580

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 423682580...
Checkpoint 423682580 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,963.58089
Policy Entropy: 3.30193
Value Function Loss: 0.00340

Mean KL Divergence: 0.00745
SB3 Clip Fraction: 0.08420
Policy Update Magnitude: 0.43877
Value Function Update Magnitude: 0.36678

Collected Steps per Second: 22,057.23936
Overall Steps per Second: 10,645.04181

Timestep Collection Time: 2.26737
Timestep Consumption Time: 2.43078
PPO Batch Consumption Time: 0.29346
Total Iteration Time: 4.69815

Cumulative Model Updates: 50,792
Cumulative Timesteps: 423,732,592

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,169.53125
Policy Entropy: 3.30608
Value Function Loss: 0.00336

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.09564
Policy Update Magnitude: 0.43277
Value Function Update Magnitude: 0.37499

Collected Steps per Second: 21,932.63739
Overall Steps per Second: 10,646.68364

Timestep Collection Time: 2.28044
Timestep Consumption Time: 2.41736
PPO Batch Consumption Time: 0.29091
Total Iteration Time: 4.69780

Cumulative Model Updates: 50,798
Cumulative Timesteps: 423,782,608

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 423782608...
Checkpoint 423782608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,937.53135
Policy Entropy: 3.31214
Value Function Loss: 0.00338

Mean KL Divergence: 0.00699
SB3 Clip Fraction: 0.07636
Policy Update Magnitude: 0.44452
Value Function Update Magnitude: 0.38681

Collected Steps per Second: 21,393.56328
Overall Steps per Second: 10,470.36322

Timestep Collection Time: 2.33762
Timestep Consumption Time: 2.43872
PPO Batch Consumption Time: 0.29522
Total Iteration Time: 4.77634

Cumulative Model Updates: 50,804
Cumulative Timesteps: 423,832,618

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,408.47963
Policy Entropy: 3.29632
Value Function Loss: 0.00353

Mean KL Divergence: 0.00695
SB3 Clip Fraction: 0.07618
Policy Update Magnitude: 0.44741
Value Function Update Magnitude: 0.37566

Collected Steps per Second: 21,545.90512
Overall Steps per Second: 10,477.53149

Timestep Collection Time: 2.32072
Timestep Consumption Time: 2.45159
PPO Batch Consumption Time: 0.29513
Total Iteration Time: 4.77231

Cumulative Model Updates: 50,810
Cumulative Timesteps: 423,882,620

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 423882620...
Checkpoint 423882620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,301.01269
Policy Entropy: 3.29174
Value Function Loss: 0.00361

Mean KL Divergence: 0.00696
SB3 Clip Fraction: 0.07940
Policy Update Magnitude: 0.44630
Value Function Update Magnitude: 0.38419

Collected Steps per Second: 21,214.22131
Overall Steps per Second: 10,566.55476

Timestep Collection Time: 2.35776
Timestep Consumption Time: 2.37586
PPO Batch Consumption Time: 0.28096
Total Iteration Time: 4.73361

Cumulative Model Updates: 50,816
Cumulative Timesteps: 423,932,638

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 866.29835
Policy Entropy: 3.28471
Value Function Loss: 0.00373

Mean KL Divergence: 0.00653
SB3 Clip Fraction: 0.07329
Policy Update Magnitude: 0.45524
Value Function Update Magnitude: 0.38609

Collected Steps per Second: 21,602.91113
Overall Steps per Second: 10,489.97480

Timestep Collection Time: 2.31580
Timestep Consumption Time: 2.45333
PPO Batch Consumption Time: 0.29574
Total Iteration Time: 4.76912

Cumulative Model Updates: 50,822
Cumulative Timesteps: 423,982,666

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 423982666...
Checkpoint 423982666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,037.58747
Policy Entropy: 3.29016
Value Function Loss: 0.00366

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.08515
Policy Update Magnitude: 0.45885
Value Function Update Magnitude: 0.39907

Collected Steps per Second: 21,668.86104
Overall Steps per Second: 10,651.03090

Timestep Collection Time: 2.30810
Timestep Consumption Time: 2.38759
PPO Batch Consumption Time: 0.28392
Total Iteration Time: 4.69570

Cumulative Model Updates: 50,828
Cumulative Timesteps: 424,032,680

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 845.72179
Policy Entropy: 3.29029
Value Function Loss: 0.00367

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.10130
Policy Update Magnitude: 0.45121
Value Function Update Magnitude: 0.39369

Collected Steps per Second: 22,181.13488
Overall Steps per Second: 10,475.51006

Timestep Collection Time: 2.25552
Timestep Consumption Time: 2.52038
PPO Batch Consumption Time: 0.30014
Total Iteration Time: 4.77590

Cumulative Model Updates: 50,834
Cumulative Timesteps: 424,082,710

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 424082710...
Checkpoint 424082710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,136.30117
Policy Entropy: 3.30489
Value Function Loss: 0.00365

Mean KL Divergence: 0.00732
SB3 Clip Fraction: 0.08178
Policy Update Magnitude: 0.45763
Value Function Update Magnitude: 0.40773

Collected Steps per Second: 21,909.86912
Overall Steps per Second: 10,554.86946

Timestep Collection Time: 2.28217
Timestep Consumption Time: 2.45517
PPO Batch Consumption Time: 0.29475
Total Iteration Time: 4.73734

Cumulative Model Updates: 50,840
Cumulative Timesteps: 424,132,712

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,395.87949
Policy Entropy: 3.32497
Value Function Loss: 0.00347

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.09230
Policy Update Magnitude: 0.45828
Value Function Update Magnitude: 0.40342

Collected Steps per Second: 22,234.90039
Overall Steps per Second: 10,698.30876

Timestep Collection Time: 2.24989
Timestep Consumption Time: 2.42618
PPO Batch Consumption Time: 0.29074
Total Iteration Time: 4.67607

Cumulative Model Updates: 50,846
Cumulative Timesteps: 424,182,738

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 424182738...
Checkpoint 424182738 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,792.62859
Policy Entropy: 3.32717
Value Function Loss: 0.00336

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.09331
Policy Update Magnitude: 0.44616
Value Function Update Magnitude: 0.39343

Collected Steps per Second: 21,981.53323
Overall Steps per Second: 10,801.85963

Timestep Collection Time: 2.27464
Timestep Consumption Time: 2.35420
PPO Batch Consumption Time: 0.28121
Total Iteration Time: 4.62883

Cumulative Model Updates: 50,852
Cumulative Timesteps: 424,232,738

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,453.51309
Policy Entropy: 3.32915
Value Function Loss: 0.00354

Mean KL Divergence: 0.00712
SB3 Clip Fraction: 0.07750
Policy Update Magnitude: 0.45060
Value Function Update Magnitude: 0.37512

Collected Steps per Second: 22,000.27763
Overall Steps per Second: 10,559.86882

Timestep Collection Time: 2.27279
Timestep Consumption Time: 2.46231
PPO Batch Consumption Time: 0.29560
Total Iteration Time: 4.73510

Cumulative Model Updates: 50,858
Cumulative Timesteps: 424,282,740

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 424282740...
Checkpoint 424282740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,481.13767
Policy Entropy: 3.32856
Value Function Loss: 0.00360

Mean KL Divergence: 0.00716
SB3 Clip Fraction: 0.08097
Policy Update Magnitude: 0.45838
Value Function Update Magnitude: 0.37811

Collected Steps per Second: 22,108.28524
Overall Steps per Second: 10,616.39213

Timestep Collection Time: 2.26178
Timestep Consumption Time: 2.44830
PPO Batch Consumption Time: 0.29668
Total Iteration Time: 4.71007

Cumulative Model Updates: 50,864
Cumulative Timesteps: 424,332,744

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,543.45319
Policy Entropy: 3.34312
Value Function Loss: 0.00355

Mean KL Divergence: 0.00636
SB3 Clip Fraction: 0.07110
Policy Update Magnitude: 0.45571
Value Function Update Magnitude: 0.37755

Collected Steps per Second: 20,508.81475
Overall Steps per Second: 10,142.75201

Timestep Collection Time: 2.43905
Timestep Consumption Time: 2.49275
PPO Batch Consumption Time: 0.29515
Total Iteration Time: 4.93180

Cumulative Model Updates: 50,870
Cumulative Timesteps: 424,382,766

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 424382766...
Checkpoint 424382766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,163.00135
Policy Entropy: 3.33648
Value Function Loss: 0.00338

Mean KL Divergence: 0.00679
SB3 Clip Fraction: 0.07749
Policy Update Magnitude: 0.44711
Value Function Update Magnitude: 0.37496

Collected Steps per Second: 21,150.71972
Overall Steps per Second: 10,605.27680

Timestep Collection Time: 2.36550
Timestep Consumption Time: 2.35215
PPO Batch Consumption Time: 0.27958
Total Iteration Time: 4.71765

Cumulative Model Updates: 50,876
Cumulative Timesteps: 424,432,798

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 652.03174
Policy Entropy: 3.32779
Value Function Loss: 0.00358

Mean KL Divergence: 0.00675
SB3 Clip Fraction: 0.07489
Policy Update Magnitude: 0.44871
Value Function Update Magnitude: 0.37571

Collected Steps per Second: 22,675.64133
Overall Steps per Second: 10,626.26767

Timestep Collection Time: 2.20527
Timestep Consumption Time: 2.50061
PPO Batch Consumption Time: 0.28978
Total Iteration Time: 4.70589

Cumulative Model Updates: 50,882
Cumulative Timesteps: 424,482,804

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 424482804...
Checkpoint 424482804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 590.47640
Policy Entropy: 3.33727
Value Function Loss: 0.00374

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.09509
Policy Update Magnitude: 0.44906
Value Function Update Magnitude: 0.37244

Collected Steps per Second: 22,586.83948
Overall Steps per Second: 10,795.66905

Timestep Collection Time: 2.21394
Timestep Consumption Time: 2.41810
PPO Batch Consumption Time: 0.28069
Total Iteration Time: 4.63204

Cumulative Model Updates: 50,888
Cumulative Timesteps: 424,532,810

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 984.24034
Policy Entropy: 3.33322
Value Function Loss: 0.00395

Mean KL Divergence: 0.01055
SB3 Clip Fraction: 0.11159
Policy Update Magnitude: 0.45400
Value Function Update Magnitude: 0.37476

Collected Steps per Second: 22,431.38489
Overall Steps per Second: 10,520.25078

Timestep Collection Time: 2.22982
Timestep Consumption Time: 2.52463
PPO Batch Consumption Time: 0.29546
Total Iteration Time: 4.75445

Cumulative Model Updates: 50,894
Cumulative Timesteps: 424,582,828

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 424582828...
Checkpoint 424582828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,212.88034
Policy Entropy: 3.33825
Value Function Loss: 0.00373

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.10607
Policy Update Magnitude: 0.45547
Value Function Update Magnitude: 0.38019

Collected Steps per Second: 20,937.34753
Overall Steps per Second: 10,154.50653

Timestep Collection Time: 2.38894
Timestep Consumption Time: 2.53676
PPO Batch Consumption Time: 0.31170
Total Iteration Time: 4.92569

Cumulative Model Updates: 50,900
Cumulative Timesteps: 424,632,846

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 933.07073
Policy Entropy: 3.33016
Value Function Loss: 0.00392

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.09880
Policy Update Magnitude: 0.46180
Value Function Update Magnitude: 0.37556

Collected Steps per Second: 21,646.51786
Overall Steps per Second: 10,432.41516

Timestep Collection Time: 2.31030
Timestep Consumption Time: 2.48341
PPO Batch Consumption Time: 0.29292
Total Iteration Time: 4.79371

Cumulative Model Updates: 50,906
Cumulative Timesteps: 424,682,856

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 424682856...
Checkpoint 424682856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 907.32900
Policy Entropy: 3.34586
Value Function Loss: 0.00379

Mean KL Divergence: 0.00694
SB3 Clip Fraction: 0.07751
Policy Update Magnitude: 0.47408
Value Function Update Magnitude: 0.38827

Collected Steps per Second: 22,525.81308
Overall Steps per Second: 10,678.19269

Timestep Collection Time: 2.22039
Timestep Consumption Time: 2.46355
PPO Batch Consumption Time: 0.28167
Total Iteration Time: 4.68394

Cumulative Model Updates: 50,912
Cumulative Timesteps: 424,732,872

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,119.18248
Policy Entropy: 3.35900
Value Function Loss: 0.00366

Mean KL Divergence: 0.00606
SB3 Clip Fraction: 0.06595
Policy Update Magnitude: 0.47233
Value Function Update Magnitude: 0.39460

Collected Steps per Second: 21,906.05061
Overall Steps per Second: 10,557.57900

Timestep Collection Time: 2.28357
Timestep Consumption Time: 2.45464
PPO Batch Consumption Time: 0.29502
Total Iteration Time: 4.73821

Cumulative Model Updates: 50,918
Cumulative Timesteps: 424,782,896

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 424782896...
Checkpoint 424782896 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,179.38461
Policy Entropy: 3.36222
Value Function Loss: 0.00329

Mean KL Divergence: 0.00545
SB3 Clip Fraction: 0.05952
Policy Update Magnitude: 0.46110
Value Function Update Magnitude: 0.38172

Collected Steps per Second: 21,883.53212
Overall Steps per Second: 10,584.18347

Timestep Collection Time: 2.28501
Timestep Consumption Time: 2.43940
PPO Batch Consumption Time: 0.29511
Total Iteration Time: 4.72441

Cumulative Model Updates: 50,924
Cumulative Timesteps: 424,832,900

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,013.83185
Policy Entropy: 3.35848
Value Function Loss: 0.00324

Mean KL Divergence: 0.00497
SB3 Clip Fraction: 0.05442
Policy Update Magnitude: 0.45356
Value Function Update Magnitude: 0.37044

Collected Steps per Second: 21,910.18812
Overall Steps per Second: 10,627.37241

Timestep Collection Time: 2.28250
Timestep Consumption Time: 2.42327
PPO Batch Consumption Time: 0.29209
Total Iteration Time: 4.70577

Cumulative Model Updates: 50,930
Cumulative Timesteps: 424,882,910

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 424882910...
Checkpoint 424882910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,565.04175
Policy Entropy: 3.35525
Value Function Loss: 0.00323

Mean KL Divergence: 0.00513
SB3 Clip Fraction: 0.05679
Policy Update Magnitude: 0.44163
Value Function Update Magnitude: 0.36424

Collected Steps per Second: 22,116.34256
Overall Steps per Second: 10,733.18626

Timestep Collection Time: 2.26095
Timestep Consumption Time: 2.39787
PPO Batch Consumption Time: 0.28818
Total Iteration Time: 4.65882

Cumulative Model Updates: 50,936
Cumulative Timesteps: 424,932,914

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,325.67168
Policy Entropy: 3.37912
Value Function Loss: 0.00325

Mean KL Divergence: 0.00569
SB3 Clip Fraction: 0.06392
Policy Update Magnitude: 0.44273
Value Function Update Magnitude: 0.37137

Collected Steps per Second: 21,473.17397
Overall Steps per Second: 10,689.43819

Timestep Collection Time: 2.32849
Timestep Consumption Time: 2.34903
PPO Batch Consumption Time: 0.27900
Total Iteration Time: 4.67751

Cumulative Model Updates: 50,942
Cumulative Timesteps: 424,982,914

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 424982914...
Checkpoint 424982914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,361.83859
Policy Entropy: 3.37497
Value Function Loss: 0.00324

Mean KL Divergence: 0.00509
SB3 Clip Fraction: 0.05542
Policy Update Magnitude: 0.44201
Value Function Update Magnitude: 0.36312

Collected Steps per Second: 21,469.89981
Overall Steps per Second: 10,615.94214

Timestep Collection Time: 2.33024
Timestep Consumption Time: 2.38248
PPO Batch Consumption Time: 0.28464
Total Iteration Time: 4.71272

Cumulative Model Updates: 50,948
Cumulative Timesteps: 425,032,944

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,792.15039
Policy Entropy: 3.39307
Value Function Loss: 0.00340

Mean KL Divergence: 0.00542
SB3 Clip Fraction: 0.05943
Policy Update Magnitude: 0.44813
Value Function Update Magnitude: 0.36238

Collected Steps per Second: 21,756.02595
Overall Steps per Second: 10,596.06656

Timestep Collection Time: 2.29904
Timestep Consumption Time: 2.42139
PPO Batch Consumption Time: 0.29102
Total Iteration Time: 4.72043

Cumulative Model Updates: 50,954
Cumulative Timesteps: 425,082,962

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 425082962...
Checkpoint 425082962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,105.31942
Policy Entropy: 3.36709
Value Function Loss: 0.00352

Mean KL Divergence: 0.00570
SB3 Clip Fraction: 0.06346
Policy Update Magnitude: 0.45941
Value Function Update Magnitude: 0.36096

Collected Steps per Second: 21,446.32743
Overall Steps per Second: 10,455.03540

Timestep Collection Time: 2.33289
Timestep Consumption Time: 2.45255
PPO Batch Consumption Time: 0.29424
Total Iteration Time: 4.78545

Cumulative Model Updates: 50,960
Cumulative Timesteps: 425,132,994

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 784.67481
Policy Entropy: 3.36321
Value Function Loss: 0.00351

Mean KL Divergence: 0.00608
SB3 Clip Fraction: 0.06834
Policy Update Magnitude: 0.46043
Value Function Update Magnitude: 0.35832

Collected Steps per Second: 21,782.63282
Overall Steps per Second: 10,560.63902

Timestep Collection Time: 2.29688
Timestep Consumption Time: 2.44072
PPO Batch Consumption Time: 0.29389
Total Iteration Time: 4.73759

Cumulative Model Updates: 50,966
Cumulative Timesteps: 425,183,026

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 425183026...
Checkpoint 425183026 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 839.26134
Policy Entropy: 3.35325
Value Function Loss: 0.00335

Mean KL Divergence: 0.00574
SB3 Clip Fraction: 0.06340
Policy Update Magnitude: 0.45312
Value Function Update Magnitude: 0.34206

Collected Steps per Second: 22,078.68594
Overall Steps per Second: 10,541.60255

Timestep Collection Time: 2.26481
Timestep Consumption Time: 2.47868
PPO Batch Consumption Time: 0.29319
Total Iteration Time: 4.74349

Cumulative Model Updates: 50,972
Cumulative Timesteps: 425,233,030

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,137.61883
Policy Entropy: 3.35838
Value Function Loss: 0.00321

Mean KL Divergence: 0.00566
SB3 Clip Fraction: 0.06263
Policy Update Magnitude: 0.43914
Value Function Update Magnitude: 0.32917

Collected Steps per Second: 21,750.03601
Overall Steps per Second: 10,574.17969

Timestep Collection Time: 2.29958
Timestep Consumption Time: 2.43043
PPO Batch Consumption Time: 0.29293
Total Iteration Time: 4.73001

Cumulative Model Updates: 50,978
Cumulative Timesteps: 425,283,046

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 425283046...
Checkpoint 425283046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,969.23584
Policy Entropy: 3.35930
Value Function Loss: 0.00317

Mean KL Divergence: 0.00526
SB3 Clip Fraction: 0.05778
Policy Update Magnitude: 0.43244
Value Function Update Magnitude: 0.32353

Collected Steps per Second: 22,367.38872
Overall Steps per Second: 10,870.85360

Timestep Collection Time: 2.23549
Timestep Consumption Time: 2.36415
PPO Batch Consumption Time: 0.28145
Total Iteration Time: 4.59964

Cumulative Model Updates: 50,984
Cumulative Timesteps: 425,333,048

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,215.67348
Policy Entropy: 3.36876
Value Function Loss: 0.00319

Mean KL Divergence: 0.00551
SB3 Clip Fraction: 0.05934
Policy Update Magnitude: 0.43320
Value Function Update Magnitude: 0.32306

Collected Steps per Second: 21,802.52234
Overall Steps per Second: 10,540.55912

Timestep Collection Time: 2.29377
Timestep Consumption Time: 2.45076
PPO Batch Consumption Time: 0.29542
Total Iteration Time: 4.74453

Cumulative Model Updates: 50,990
Cumulative Timesteps: 425,383,058

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 425383058...
Checkpoint 425383058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,623.67615
Policy Entropy: 3.35863
Value Function Loss: 0.00341

Mean KL Divergence: 0.00645
SB3 Clip Fraction: 0.07250
Policy Update Magnitude: 0.43031
Value Function Update Magnitude: 0.33004

Collected Steps per Second: 21,644.38672
Overall Steps per Second: 10,679.72838

Timestep Collection Time: 2.31136
Timestep Consumption Time: 2.37303
PPO Batch Consumption Time: 0.28481
Total Iteration Time: 4.68439

Cumulative Model Updates: 50,996
Cumulative Timesteps: 425,433,086

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,252.12391
Policy Entropy: 3.35841
Value Function Loss: 0.00327

Mean KL Divergence: 0.00691
SB3 Clip Fraction: 0.07764
Policy Update Magnitude: 0.42249
Value Function Update Magnitude: 0.33320

Collected Steps per Second: 22,071.44295
Overall Steps per Second: 10,790.77778

Timestep Collection Time: 2.26664
Timestep Consumption Time: 2.36954
PPO Batch Consumption Time: 0.28108
Total Iteration Time: 4.63618

Cumulative Model Updates: 51,002
Cumulative Timesteps: 425,483,114

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 425483114...
Checkpoint 425483114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,081.74829
Policy Entropy: 3.32939
Value Function Loss: 0.00334

Mean KL Divergence: 0.00589
SB3 Clip Fraction: 0.06546
Policy Update Magnitude: 0.42673
Value Function Update Magnitude: 0.33840

Collected Steps per Second: 21,712.15329
Overall Steps per Second: 10,719.82821

Timestep Collection Time: 2.30332
Timestep Consumption Time: 2.36187
PPO Batch Consumption Time: 0.28158
Total Iteration Time: 4.66519

Cumulative Model Updates: 51,008
Cumulative Timesteps: 425,533,124

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,144.64444
Policy Entropy: 3.32285
Value Function Loss: 0.00335

Mean KL Divergence: 0.00722
SB3 Clip Fraction: 0.08135
Policy Update Magnitude: 0.43094
Value Function Update Magnitude: 0.34312

Collected Steps per Second: 21,508.63853
Overall Steps per Second: 10,468.78468

Timestep Collection Time: 2.32511
Timestep Consumption Time: 2.45195
PPO Batch Consumption Time: 0.29548
Total Iteration Time: 4.77706

Cumulative Model Updates: 51,014
Cumulative Timesteps: 425,583,134

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 425583134...
Checkpoint 425583134 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 986.65398
Policy Entropy: 3.31167
Value Function Loss: 0.00364

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.08833
Policy Update Magnitude: 0.44132
Value Function Update Magnitude: 0.35319

Collected Steps per Second: 21,805.77285
Overall Steps per Second: 10,660.60327

Timestep Collection Time: 2.29306
Timestep Consumption Time: 2.39729
PPO Batch Consumption Time: 0.28852
Total Iteration Time: 4.69035

Cumulative Model Updates: 51,020
Cumulative Timesteps: 425,633,136

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,188.52375
Policy Entropy: 3.31456
Value Function Loss: 0.00348

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.08724
Policy Update Magnitude: 0.44927
Value Function Update Magnitude: 0.35957

Collected Steps per Second: 21,642.93347
Overall Steps per Second: 10,560.38363

Timestep Collection Time: 2.31152
Timestep Consumption Time: 2.42581
PPO Batch Consumption Time: 0.29304
Total Iteration Time: 4.73733

Cumulative Model Updates: 51,026
Cumulative Timesteps: 425,683,164

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 425683164...
Checkpoint 425683164 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,023.13093
Policy Entropy: 3.32850
Value Function Loss: 0.00355

Mean KL Divergence: 0.00762
SB3 Clip Fraction: 0.08339
Policy Update Magnitude: 0.45378
Value Function Update Magnitude: 0.36588

Collected Steps per Second: 22,428.54434
Overall Steps per Second: 10,554.62926

Timestep Collection Time: 2.22948
Timestep Consumption Time: 2.50816
PPO Batch Consumption Time: 0.29490
Total Iteration Time: 4.73764

Cumulative Model Updates: 51,032
Cumulative Timesteps: 425,733,168

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 695.81237
Policy Entropy: 3.34805
Value Function Loss: 0.00343

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.09715
Policy Update Magnitude: 0.44607
Value Function Update Magnitude: 0.35596

Collected Steps per Second: 21,797.51678
Overall Steps per Second: 10,598.70611

Timestep Collection Time: 2.29457
Timestep Consumption Time: 2.42449
PPO Batch Consumption Time: 0.29141
Total Iteration Time: 4.71907

Cumulative Model Updates: 51,038
Cumulative Timesteps: 425,783,184

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 425783184...
Checkpoint 425783184 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,411.25066
Policy Entropy: 3.34668
Value Function Loss: 0.00355

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.09148
Policy Update Magnitude: 0.43955
Value Function Update Magnitude: 0.35935

Collected Steps per Second: 22,316.00750
Overall Steps per Second: 10,799.09829

Timestep Collection Time: 2.24117
Timestep Consumption Time: 2.39014
PPO Batch Consumption Time: 0.28077
Total Iteration Time: 4.63131

Cumulative Model Updates: 51,044
Cumulative Timesteps: 425,833,198

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 982.09176
Policy Entropy: 3.33635
Value Function Loss: 0.00342

Mean KL Divergence: 0.01115
SB3 Clip Fraction: 0.11135
Policy Update Magnitude: 0.43673
Value Function Update Magnitude: 0.37003

Collected Steps per Second: 22,165.49269
Overall Steps per Second: 10,643.86330

Timestep Collection Time: 2.25675
Timestep Consumption Time: 2.44286
PPO Batch Consumption Time: 0.29443
Total Iteration Time: 4.69961

Cumulative Model Updates: 51,050
Cumulative Timesteps: 425,883,220

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 425883220...
Checkpoint 425883220 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,323.82613
Policy Entropy: 3.33748
Value Function Loss: 0.00343

Mean KL Divergence: 0.01156
SB3 Clip Fraction: 0.11787
Policy Update Magnitude: 0.43671
Value Function Update Magnitude: 0.37599

Collected Steps per Second: 22,963.44913
Overall Steps per Second: 10,729.56057

Timestep Collection Time: 2.17833
Timestep Consumption Time: 2.48374
PPO Batch Consumption Time: 0.29262
Total Iteration Time: 4.66207

Cumulative Model Updates: 51,056
Cumulative Timesteps: 425,933,242

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,007.62536
Policy Entropy: 3.35056
Value Function Loss: 0.00342

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.10063
Policy Update Magnitude: 0.43534
Value Function Update Magnitude: 0.37501

Collected Steps per Second: 21,924.03631
Overall Steps per Second: 10,765.24268

Timestep Collection Time: 2.28078
Timestep Consumption Time: 2.36416
PPO Batch Consumption Time: 0.28080
Total Iteration Time: 4.64495

Cumulative Model Updates: 51,062
Cumulative Timesteps: 425,983,246

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 425983246...
Checkpoint 425983246 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,171.06853
Policy Entropy: 3.35916
Value Function Loss: 0.00346

Mean KL Divergence: 0.00722
SB3 Clip Fraction: 0.08021
Policy Update Magnitude: 0.44272
Value Function Update Magnitude: 0.37971

Collected Steps per Second: 22,527.50905
Overall Steps per Second: 10,630.06355

Timestep Collection Time: 2.22040
Timestep Consumption Time: 2.48513
PPO Batch Consumption Time: 0.28993
Total Iteration Time: 4.70552

Cumulative Model Updates: 51,068
Cumulative Timesteps: 426,033,266

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,126.48529
Policy Entropy: 3.35710
Value Function Loss: 0.00332

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.08359
Policy Update Magnitude: 0.44358
Value Function Update Magnitude: 0.38435

Collected Steps per Second: 22,565.50685
Overall Steps per Second: 10,637.39066

Timestep Collection Time: 2.21666
Timestep Consumption Time: 2.48562
PPO Batch Consumption Time: 0.29076
Total Iteration Time: 4.70228

Cumulative Model Updates: 51,074
Cumulative Timesteps: 426,083,286

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 426083286...
Checkpoint 426083286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 732.85735
Policy Entropy: 3.36943
Value Function Loss: 0.00319

Mean KL Divergence: 0.00600
SB3 Clip Fraction: 0.06595
Policy Update Magnitude: 0.43654
Value Function Update Magnitude: 0.37557

Collected Steps per Second: 21,811.24168
Overall Steps per Second: 10,628.92668

Timestep Collection Time: 2.29359
Timestep Consumption Time: 2.41300
PPO Batch Consumption Time: 0.29157
Total Iteration Time: 4.70659

Cumulative Model Updates: 51,080
Cumulative Timesteps: 426,133,312

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,520.80189
Policy Entropy: 3.37530
Value Function Loss: 0.00320

Mean KL Divergence: 0.00538
SB3 Clip Fraction: 0.05838
Policy Update Magnitude: 0.43989
Value Function Update Magnitude: 0.37373

Collected Steps per Second: 21,764.39681
Overall Steps per Second: 10,751.72826

Timestep Collection Time: 2.29761
Timestep Consumption Time: 2.35337
PPO Batch Consumption Time: 0.27951
Total Iteration Time: 4.65097

Cumulative Model Updates: 51,086
Cumulative Timesteps: 426,183,318

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 426183318...
Checkpoint 426183318 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,980.31443
Policy Entropy: 3.37695
Value Function Loss: 0.00327

Mean KL Divergence: 0.00575
SB3 Clip Fraction: 0.06347
Policy Update Magnitude: 0.43542
Value Function Update Magnitude: 0.37202

Collected Steps per Second: 21,760.26732
Overall Steps per Second: 10,632.01053

Timestep Collection Time: 2.29786
Timestep Consumption Time: 2.40511
PPO Batch Consumption Time: 0.28796
Total Iteration Time: 4.70297

Cumulative Model Updates: 51,092
Cumulative Timesteps: 426,233,320

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,619.34977
Policy Entropy: 3.37245
Value Function Loss: 0.00331

Mean KL Divergence: 0.00565
SB3 Clip Fraction: 0.06335
Policy Update Magnitude: 0.43400
Value Function Update Magnitude: 0.37247

Collected Steps per Second: 21,674.98630
Overall Steps per Second: 10,527.14803

Timestep Collection Time: 2.30791
Timestep Consumption Time: 2.44399
PPO Batch Consumption Time: 0.29378
Total Iteration Time: 4.75190

Cumulative Model Updates: 51,098
Cumulative Timesteps: 426,283,344

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 426283344...
Checkpoint 426283344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,192.59954
Policy Entropy: 3.37376
Value Function Loss: 0.00334

Mean KL Divergence: 0.00660
SB3 Clip Fraction: 0.07428
Policy Update Magnitude: 0.43511
Value Function Update Magnitude: 0.37488

Collected Steps per Second: 21,796.33588
Overall Steps per Second: 10,546.61393

Timestep Collection Time: 2.29451
Timestep Consumption Time: 2.44748
PPO Batch Consumption Time: 0.28932
Total Iteration Time: 4.74200

Cumulative Model Updates: 51,104
Cumulative Timesteps: 426,333,356

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,032.76198
Policy Entropy: 3.36613
Value Function Loss: 0.00322

Mean KL Divergence: 0.00602
SB3 Clip Fraction: 0.06679
Policy Update Magnitude: 0.43395
Value Function Update Magnitude: 0.36646

Collected Steps per Second: 21,881.22241
Overall Steps per Second: 10,623.16078

Timestep Collection Time: 2.28534
Timestep Consumption Time: 2.42192
PPO Batch Consumption Time: 0.29141
Total Iteration Time: 4.70726

Cumulative Model Updates: 51,110
Cumulative Timesteps: 426,383,362

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 426383362...
Checkpoint 426383362 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,613.49535
Policy Entropy: 3.35874
Value Function Loss: 0.00315

Mean KL Divergence: 0.00577
SB3 Clip Fraction: 0.06554
Policy Update Magnitude: 0.43402
Value Function Update Magnitude: 0.36387

Collected Steps per Second: 21,953.30718
Overall Steps per Second: 10,667.15388

Timestep Collection Time: 2.27865
Timestep Consumption Time: 2.41088
PPO Batch Consumption Time: 0.29016
Total Iteration Time: 4.68954

Cumulative Model Updates: 51,116
Cumulative Timesteps: 426,433,386

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,007.50934
Policy Entropy: 3.34872
Value Function Loss: 0.00323

Mean KL Divergence: 0.00554
SB3 Clip Fraction: 0.06109
Policy Update Magnitude: 0.43645
Value Function Update Magnitude: 0.35875

Collected Steps per Second: 22,154.01076
Overall Steps per Second: 10,715.92094

Timestep Collection Time: 2.25801
Timestep Consumption Time: 2.41018
PPO Batch Consumption Time: 0.28769
Total Iteration Time: 4.66819

Cumulative Model Updates: 51,122
Cumulative Timesteps: 426,483,410

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 426483410...
Checkpoint 426483410 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,472.29654
Policy Entropy: 3.34983
Value Function Loss: 0.00330

Mean KL Divergence: 0.00580
SB3 Clip Fraction: 0.06405
Policy Update Magnitude: 0.43463
Value Function Update Magnitude: 0.35454

Collected Steps per Second: 21,750.24665
Overall Steps per Second: 10,635.80516

Timestep Collection Time: 2.30020
Timestep Consumption Time: 2.40372
PPO Batch Consumption Time: 0.28762
Total Iteration Time: 4.70392

Cumulative Model Updates: 51,128
Cumulative Timesteps: 426,533,440

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,724.46488
Policy Entropy: 3.33808
Value Function Loss: 0.00336

Mean KL Divergence: 0.00571
SB3 Clip Fraction: 0.06307
Policy Update Magnitude: 0.43948
Value Function Update Magnitude: 0.37244

Collected Steps per Second: 21,575.45807
Overall Steps per Second: 10,302.22759

Timestep Collection Time: 2.31745
Timestep Consumption Time: 2.53587
PPO Batch Consumption Time: 0.30802
Total Iteration Time: 4.85332

Cumulative Model Updates: 51,134
Cumulative Timesteps: 426,583,440

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 426583440...
Checkpoint 426583440 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,468.97974
Policy Entropy: 3.34561
Value Function Loss: 0.00326

Mean KL Divergence: 0.00622
SB3 Clip Fraction: 0.07012
Policy Update Magnitude: 0.44190
Value Function Update Magnitude: 0.38620

Collected Steps per Second: 21,708.63445
Overall Steps per Second: 10,695.60476

Timestep Collection Time: 2.30415
Timestep Consumption Time: 2.37254
PPO Batch Consumption Time: 0.27949
Total Iteration Time: 4.67669

Cumulative Model Updates: 51,140
Cumulative Timesteps: 426,633,460

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,422.91802
Policy Entropy: 3.33436
Value Function Loss: 0.00322

Mean KL Divergence: 0.00639
SB3 Clip Fraction: 0.07389
Policy Update Magnitude: 0.44027
Value Function Update Magnitude: 0.38478

Collected Steps per Second: 21,875.20217
Overall Steps per Second: 10,562.32433

Timestep Collection Time: 2.28615
Timestep Consumption Time: 2.44860
PPO Batch Consumption Time: 0.29516
Total Iteration Time: 4.73475

Cumulative Model Updates: 51,146
Cumulative Timesteps: 426,683,470

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 426683470...
Checkpoint 426683470 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,062.87640
Policy Entropy: 3.32115
Value Function Loss: 0.00330

Mean KL Divergence: 0.00587
SB3 Clip Fraction: 0.06659
Policy Update Magnitude: 0.44247
Value Function Update Magnitude: 0.37806

Collected Steps per Second: 21,619.80538
Overall Steps per Second: 10,592.80634

Timestep Collection Time: 2.31306
Timestep Consumption Time: 2.40788
PPO Batch Consumption Time: 0.28749
Total Iteration Time: 4.72094

Cumulative Model Updates: 51,152
Cumulative Timesteps: 426,733,478

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 989.93675
Policy Entropy: 3.31523
Value Function Loss: 0.00354

Mean KL Divergence: 0.00711
SB3 Clip Fraction: 0.07915
Policy Update Magnitude: 0.45109
Value Function Update Magnitude: 0.37908

Collected Steps per Second: 21,679.74554
Overall Steps per Second: 10,549.04646

Timestep Collection Time: 2.30713
Timestep Consumption Time: 2.43434
PPO Batch Consumption Time: 0.29511
Total Iteration Time: 4.74147

Cumulative Model Updates: 51,158
Cumulative Timesteps: 426,783,496

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 426783496...
Checkpoint 426783496 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,173.92974
Policy Entropy: 3.32573
Value Function Loss: 0.00356

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.08827
Policy Update Magnitude: 0.44783
Value Function Update Magnitude: 0.38016

Collected Steps per Second: 21,785.22274
Overall Steps per Second: 10,573.64464

Timestep Collection Time: 2.29596
Timestep Consumption Time: 2.43448
PPO Batch Consumption Time: 0.29296
Total Iteration Time: 4.73044

Cumulative Model Updates: 51,164
Cumulative Timesteps: 426,833,514

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,559.83442
Policy Entropy: 3.33571
Value Function Loss: 0.00337

Mean KL Divergence: 0.00735
SB3 Clip Fraction: 0.08044
Policy Update Magnitude: 0.44386
Value Function Update Magnitude: 0.36944

Collected Steps per Second: 21,732.29936
Overall Steps per Second: 10,540.89282

Timestep Collection Time: 2.30118
Timestep Consumption Time: 2.44320
PPO Batch Consumption Time: 0.29405
Total Iteration Time: 4.74438

Cumulative Model Updates: 51,170
Cumulative Timesteps: 426,883,524

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 426883524...
Checkpoint 426883524 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 992.41922
Policy Entropy: 3.34867
Value Function Loss: 0.00333

Mean KL Divergence: 0.00741
SB3 Clip Fraction: 0.07840
Policy Update Magnitude: 0.43664
Value Function Update Magnitude: 0.36461

Collected Steps per Second: 22,096.72407
Overall Steps per Second: 10,569.03388

Timestep Collection Time: 2.26314
Timestep Consumption Time: 2.46842
PPO Batch Consumption Time: 0.29440
Total Iteration Time: 4.73156

Cumulative Model Updates: 51,176
Cumulative Timesteps: 426,933,532

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 949.31374
Policy Entropy: 3.35052
Value Function Loss: 0.00325

Mean KL Divergence: 0.00738
SB3 Clip Fraction: 0.08260
Policy Update Magnitude: 0.43183
Value Function Update Magnitude: 0.36579

Collected Steps per Second: 21,687.39030
Overall Steps per Second: 10,517.11806

Timestep Collection Time: 2.30659
Timestep Consumption Time: 2.44984
PPO Batch Consumption Time: 0.29379
Total Iteration Time: 4.75644

Cumulative Model Updates: 51,182
Cumulative Timesteps: 426,983,556

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 426983556...
Checkpoint 426983556 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,020.69993
Policy Entropy: 3.34494
Value Function Loss: 0.00337

Mean KL Divergence: 0.00752
SB3 Clip Fraction: 0.08459
Policy Update Magnitude: 0.43445
Value Function Update Magnitude: 0.36985

Collected Steps per Second: 22,187.57530
Overall Steps per Second: 10,665.40221

Timestep Collection Time: 2.25378
Timestep Consumption Time: 2.43483
PPO Batch Consumption Time: 0.29469
Total Iteration Time: 4.68862

Cumulative Model Updates: 51,188
Cumulative Timesteps: 427,033,562

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,854.59884
Policy Entropy: 3.34265
Value Function Loss: 0.00317

Mean KL Divergence: 0.00648
SB3 Clip Fraction: 0.07322
Policy Update Magnitude: 0.43916
Value Function Update Magnitude: 0.37604

Collected Steps per Second: 22,189.42853
Overall Steps per Second: 10,836.68180

Timestep Collection Time: 2.25396
Timestep Consumption Time: 2.36129
PPO Batch Consumption Time: 0.27991
Total Iteration Time: 4.61525

Cumulative Model Updates: 51,194
Cumulative Timesteps: 427,083,576

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 427083576...
Checkpoint 427083576 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,574.51880
Policy Entropy: 3.33848
Value Function Loss: 0.00329

Mean KL Divergence: 0.00645
SB3 Clip Fraction: 0.07087
Policy Update Magnitude: 0.44190
Value Function Update Magnitude: 0.38349

Collected Steps per Second: 22,144.83036
Overall Steps per Second: 10,595.07553

Timestep Collection Time: 2.25904
Timestep Consumption Time: 2.46259
PPO Batch Consumption Time: 0.28700
Total Iteration Time: 4.72163

Cumulative Model Updates: 51,200
Cumulative Timesteps: 427,133,602

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,955.76722
Policy Entropy: 3.31642
Value Function Loss: 0.00338

Mean KL Divergence: 0.00772
SB3 Clip Fraction: 0.08645
Policy Update Magnitude: 0.44535
Value Function Update Magnitude: 0.39167

Collected Steps per Second: 22,660.75868
Overall Steps per Second: 10,679.30472

Timestep Collection Time: 2.20743
Timestep Consumption Time: 2.47658
PPO Batch Consumption Time: 0.28986
Total Iteration Time: 4.68401

Cumulative Model Updates: 51,206
Cumulative Timesteps: 427,183,624

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 427183624...
Checkpoint 427183624 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,732.73454
Policy Entropy: 3.30803
Value Function Loss: 0.00345

Mean KL Divergence: 0.00662
SB3 Clip Fraction: 0.07497
Policy Update Magnitude: 0.45650
Value Function Update Magnitude: 0.40035

Collected Steps per Second: 22,674.23061
Overall Steps per Second: 10,723.06996

Timestep Collection Time: 2.20532
Timestep Consumption Time: 2.45789
PPO Batch Consumption Time: 0.28778
Total Iteration Time: 4.66322

Cumulative Model Updates: 51,212
Cumulative Timesteps: 427,233,628

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 889.99714
Policy Entropy: 3.30239
Value Function Loss: 0.00345

Mean KL Divergence: 0.00560
SB3 Clip Fraction: 0.06281
Policy Update Magnitude: 0.45805
Value Function Update Magnitude: 0.39838

Collected Steps per Second: 22,272.43402
Overall Steps per Second: 10,446.02579

Timestep Collection Time: 2.24547
Timestep Consumption Time: 2.54219
PPO Batch Consumption Time: 0.30293
Total Iteration Time: 4.78766

Cumulative Model Updates: 51,218
Cumulative Timesteps: 427,283,640

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 427283640...
Checkpoint 427283640 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,005.16129
Policy Entropy: 3.30626
Value Function Loss: 0.00360

Mean KL Divergence: 0.00697
SB3 Clip Fraction: 0.07829
Policy Update Magnitude: 0.45927
Value Function Update Magnitude: 0.39384

Collected Steps per Second: 22,297.24993
Overall Steps per Second: 10,743.75632

Timestep Collection Time: 2.24261
Timestep Consumption Time: 2.41163
PPO Batch Consumption Time: 0.28067
Total Iteration Time: 4.65424

Cumulative Model Updates: 51,224
Cumulative Timesteps: 427,333,644

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 782.49855
Policy Entropy: 3.31481
Value Function Loss: 0.00356

Mean KL Divergence: 0.01126
SB3 Clip Fraction: 0.11554
Policy Update Magnitude: 0.46009
Value Function Update Magnitude: 0.38878

Collected Steps per Second: 21,907.82417
Overall Steps per Second: 10,501.92824

Timestep Collection Time: 2.28265
Timestep Consumption Time: 2.47914
PPO Batch Consumption Time: 0.28968
Total Iteration Time: 4.76179

Cumulative Model Updates: 51,230
Cumulative Timesteps: 427,383,652

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 427383652...
Checkpoint 427383652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,376.41715
Policy Entropy: 3.32859
Value Function Loss: 0.00344

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.10207
Policy Update Magnitude: 0.44961
Value Function Update Magnitude: 0.38416

Collected Steps per Second: 21,831.75876
Overall Steps per Second: 10,574.91379

Timestep Collection Time: 2.29116
Timestep Consumption Time: 2.43890
PPO Batch Consumption Time: 0.28051
Total Iteration Time: 4.73006

Cumulative Model Updates: 51,236
Cumulative Timesteps: 427,433,672

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,217.79001
Policy Entropy: 3.33684
Value Function Loss: 0.00344

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.09670
Policy Update Magnitude: 0.44912
Value Function Update Magnitude: 0.37368

Collected Steps per Second: 22,266.25728
Overall Steps per Second: 10,505.62159

Timestep Collection Time: 2.24609
Timestep Consumption Time: 2.51441
PPO Batch Consumption Time: 0.29493
Total Iteration Time: 4.76050

Cumulative Model Updates: 51,242
Cumulative Timesteps: 427,483,684

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 427483684...
Checkpoint 427483684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 845.42925
Policy Entropy: 3.32019
Value Function Loss: 0.00338

Mean KL Divergence: 0.00716
SB3 Clip Fraction: 0.08014
Policy Update Magnitude: 0.44840
Value Function Update Magnitude: 0.37220

Collected Steps per Second: 22,646.15048
Overall Steps per Second: 10,647.79455

Timestep Collection Time: 2.20868
Timestep Consumption Time: 2.48882
PPO Batch Consumption Time: 0.28706
Total Iteration Time: 4.69750

Cumulative Model Updates: 51,248
Cumulative Timesteps: 427,533,702

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 768.85533
Policy Entropy: 3.32227
Value Function Loss: 0.00330

Mean KL Divergence: 0.00550
SB3 Clip Fraction: 0.05986
Policy Update Magnitude: 0.44716
Value Function Update Magnitude: 0.35508

Collected Steps per Second: 22,614.12747
Overall Steps per Second: 10,793.46495

Timestep Collection Time: 2.21110
Timestep Consumption Time: 2.42152
PPO Batch Consumption Time: 0.28092
Total Iteration Time: 4.63262

Cumulative Model Updates: 51,254
Cumulative Timesteps: 427,583,704

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 427583704...
Checkpoint 427583704 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 927.14385
Policy Entropy: 3.32017
Value Function Loss: 0.00318

Mean KL Divergence: 0.00618
SB3 Clip Fraction: 0.06891
Policy Update Magnitude: 0.43831
Value Function Update Magnitude: 0.35452

Collected Steps per Second: 22,664.75229
Overall Steps per Second: 10,846.03849

Timestep Collection Time: 2.20695
Timestep Consumption Time: 2.40487
PPO Batch Consumption Time: 0.28169
Total Iteration Time: 4.61182

Cumulative Model Updates: 51,260
Cumulative Timesteps: 427,633,724

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,993.06491
Policy Entropy: 3.32384
Value Function Loss: 0.00327

Mean KL Divergence: 0.00630
SB3 Clip Fraction: 0.07024
Policy Update Magnitude: 0.43892
Value Function Update Magnitude: 0.36321

Collected Steps per Second: 22,696.83514
Overall Steps per Second: 10,802.15144

Timestep Collection Time: 2.20339
Timestep Consumption Time: 2.42624
PPO Batch Consumption Time: 0.28200
Total Iteration Time: 4.62963

Cumulative Model Updates: 51,266
Cumulative Timesteps: 427,683,734

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 427683734...
Checkpoint 427683734 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,434.21264
Policy Entropy: 3.33080
Value Function Loss: 0.00328

Mean KL Divergence: 0.00601
SB3 Clip Fraction: 0.06593
Policy Update Magnitude: 0.44144
Value Function Update Magnitude: 0.37738

Collected Steps per Second: 22,794.48877
Overall Steps per Second: 10,701.30765

Timestep Collection Time: 2.19465
Timestep Consumption Time: 2.48010
PPO Batch Consumption Time: 0.28714
Total Iteration Time: 4.67476

Cumulative Model Updates: 51,272
Cumulative Timesteps: 427,733,760

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,004.15020
Policy Entropy: 3.34892
Value Function Loss: 0.00335

Mean KL Divergence: 0.00545
SB3 Clip Fraction: 0.06130
Policy Update Magnitude: 0.44982
Value Function Update Magnitude: 0.37068

Collected Steps per Second: 22,464.75124
Overall Steps per Second: 10,566.98363

Timestep Collection Time: 2.22589
Timestep Consumption Time: 2.50621
PPO Batch Consumption Time: 0.29322
Total Iteration Time: 4.73210

Cumulative Model Updates: 51,278
Cumulative Timesteps: 427,783,764

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 427783764...
Checkpoint 427783764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,332.56362
Policy Entropy: 3.36433
Value Function Loss: 0.00336

Mean KL Divergence: 0.00566
SB3 Clip Fraction: 0.06230
Policy Update Magnitude: 0.45962
Value Function Update Magnitude: 0.35996

Collected Steps per Second: 22,011.99085
Overall Steps per Second: 10,562.49867

Timestep Collection Time: 2.27222
Timestep Consumption Time: 2.46303
PPO Batch Consumption Time: 0.28531
Total Iteration Time: 4.73524

Cumulative Model Updates: 51,284
Cumulative Timesteps: 427,833,780

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,265.28278
Policy Entropy: 3.36239
Value Function Loss: 0.00354

Mean KL Divergence: 0.00615
SB3 Clip Fraction: 0.06866
Policy Update Magnitude: 0.46162
Value Function Update Magnitude: 0.36911

Collected Steps per Second: 22,217.28130
Overall Steps per Second: 10,477.90447

Timestep Collection Time: 2.25149
Timestep Consumption Time: 2.52256
PPO Batch Consumption Time: 0.29497
Total Iteration Time: 4.77405

Cumulative Model Updates: 51,290
Cumulative Timesteps: 427,883,802

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 427883802...
Checkpoint 427883802 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 839.11361
Policy Entropy: 3.34766
Value Function Loss: 0.00357

Mean KL Divergence: 0.00710
SB3 Clip Fraction: 0.08189
Policy Update Magnitude: 0.46450
Value Function Update Magnitude: 0.39176

Collected Steps per Second: 21,976.56042
Overall Steps per Second: 10,510.35576

Timestep Collection Time: 2.27515
Timestep Consumption Time: 2.48206
PPO Batch Consumption Time: 0.28888
Total Iteration Time: 4.75721

Cumulative Model Updates: 51,296
Cumulative Timesteps: 427,933,802

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,702.14815
Policy Entropy: 3.36632
Value Function Loss: 0.00327

Mean KL Divergence: 0.00751
SB3 Clip Fraction: 0.08360
Policy Update Magnitude: 0.46265
Value Function Update Magnitude: 0.39728

Collected Steps per Second: 22,325.78920
Overall Steps per Second: 10,556.22192

Timestep Collection Time: 2.24001
Timestep Consumption Time: 2.49748
PPO Batch Consumption Time: 0.28857
Total Iteration Time: 4.73749

Cumulative Model Updates: 51,302
Cumulative Timesteps: 427,983,812

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 427983812...
Checkpoint 427983812 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,109.62687
Policy Entropy: 3.37044
Value Function Loss: 0.00311

Mean KL Divergence: 0.00689
SB3 Clip Fraction: 0.07546
Policy Update Magnitude: 0.44930
Value Function Update Magnitude: 0.39069

Collected Steps per Second: 22,698.90363
Overall Steps per Second: 10,641.19111

Timestep Collection Time: 2.20398
Timestep Consumption Time: 2.49737
PPO Batch Consumption Time: 0.28898
Total Iteration Time: 4.70135

Cumulative Model Updates: 51,308
Cumulative Timesteps: 428,033,840

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,618.16851
Policy Entropy: 3.35577
Value Function Loss: 0.00318

Mean KL Divergence: 0.00722
SB3 Clip Fraction: 0.08051
Policy Update Magnitude: 0.43662
Value Function Update Magnitude: 0.36847

Collected Steps per Second: 22,634.83387
Overall Steps per Second: 10,595.27139

Timestep Collection Time: 2.20969
Timestep Consumption Time: 2.51090
PPO Batch Consumption Time: 0.29009
Total Iteration Time: 4.72060

Cumulative Model Updates: 51,314
Cumulative Timesteps: 428,083,856

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 428083856...
Checkpoint 428083856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 748.67865
Policy Entropy: 3.35967
Value Function Loss: 0.00328

Mean KL Divergence: 0.00676
SB3 Clip Fraction: 0.07573
Policy Update Magnitude: 0.43588
Value Function Update Magnitude: 0.37725

Collected Steps per Second: 22,761.42608
Overall Steps per Second: 10,849.50595

Timestep Collection Time: 2.19784
Timestep Consumption Time: 2.41306
PPO Batch Consumption Time: 0.28067
Total Iteration Time: 4.61090

Cumulative Model Updates: 51,320
Cumulative Timesteps: 428,133,882

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,817.60458
Policy Entropy: 3.35426
Value Function Loss: 0.00340

Mean KL Divergence: 0.00550
SB3 Clip Fraction: 0.06060
Policy Update Magnitude: 0.44799
Value Function Update Magnitude: 0.38731

Collected Steps per Second: 22,810.97115
Overall Steps per Second: 10,742.71505

Timestep Collection Time: 2.19316
Timestep Consumption Time: 2.46377
PPO Batch Consumption Time: 0.29062
Total Iteration Time: 4.65692

Cumulative Model Updates: 51,326
Cumulative Timesteps: 428,183,910

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 428183910...
Checkpoint 428183910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,422.59580
Policy Entropy: 3.34723
Value Function Loss: 0.00330

Mean KL Divergence: 0.00622
SB3 Clip Fraction: 0.07060
Policy Update Magnitude: 0.44724
Value Function Update Magnitude: 0.38152

Collected Steps per Second: 22,909.02384
Overall Steps per Second: 10,904.02734

Timestep Collection Time: 2.18386
Timestep Consumption Time: 2.40436
PPO Batch Consumption Time: 0.28086
Total Iteration Time: 4.58821

Cumulative Model Updates: 51,332
Cumulative Timesteps: 428,233,940

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,415.13825
Policy Entropy: 3.33099
Value Function Loss: 0.00342

Mean KL Divergence: 0.00658
SB3 Clip Fraction: 0.07293
Policy Update Magnitude: 0.44931
Value Function Update Magnitude: 0.37331

Collected Steps per Second: 22,864.14205
Overall Steps per Second: 10,790.57744

Timestep Collection Time: 2.18736
Timestep Consumption Time: 2.44743
PPO Batch Consumption Time: 0.28099
Total Iteration Time: 4.63478

Cumulative Model Updates: 51,338
Cumulative Timesteps: 428,283,952

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 428283952...
Checkpoint 428283952 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 887.22530
Policy Entropy: 3.33586
Value Function Loss: 0.00343

Mean KL Divergence: 0.00626
SB3 Clip Fraction: 0.06772
Policy Update Magnitude: 0.46373
Value Function Update Magnitude: 0.38174

Collected Steps per Second: 22,143.36590
Overall Steps per Second: 10,491.47712

Timestep Collection Time: 2.25874
Timestep Consumption Time: 2.50856
PPO Batch Consumption Time: 0.29189
Total Iteration Time: 4.76730

Cumulative Model Updates: 51,344
Cumulative Timesteps: 428,333,968

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,249.43058
Policy Entropy: 3.33788
Value Function Loss: 0.00328

Mean KL Divergence: 0.00542
SB3 Clip Fraction: 0.05933
Policy Update Magnitude: 0.47488
Value Function Update Magnitude: 0.39341

Collected Steps per Second: 22,464.39567
Overall Steps per Second: 10,715.06076

Timestep Collection Time: 2.22672
Timestep Consumption Time: 2.44166
PPO Batch Consumption Time: 0.28124
Total Iteration Time: 4.66838

Cumulative Model Updates: 51,350
Cumulative Timesteps: 428,383,990

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 428383990...
Checkpoint 428383990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,574.81952
Policy Entropy: 3.35307
Value Function Loss: 0.00312

Mean KL Divergence: 0.00682
SB3 Clip Fraction: 0.07524
Policy Update Magnitude: 0.45842
Value Function Update Magnitude: 0.39007

Collected Steps per Second: 21,860.47703
Overall Steps per Second: 10,658.30947

Timestep Collection Time: 2.28806
Timestep Consumption Time: 2.40481
PPO Batch Consumption Time: 0.28047
Total Iteration Time: 4.69286

Cumulative Model Updates: 51,356
Cumulative Timesteps: 428,434,008

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 955.31061
Policy Entropy: 3.35120
Value Function Loss: 0.00309

Mean KL Divergence: 0.00565
SB3 Clip Fraction: 0.06151
Policy Update Magnitude: 0.44939
Value Function Update Magnitude: 0.37900

Collected Steps per Second: 22,327.17728
Overall Steps per Second: 10,533.49230

Timestep Collection Time: 2.24157
Timestep Consumption Time: 2.50975
PPO Batch Consumption Time: 0.29449
Total Iteration Time: 4.75132

Cumulative Model Updates: 51,362
Cumulative Timesteps: 428,484,056

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 428484056...
Checkpoint 428484056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,352.24425
Policy Entropy: 3.34507
Value Function Loss: 0.00314

Mean KL Divergence: 0.00529
SB3 Clip Fraction: 0.05753
Policy Update Magnitude: 0.45509
Value Function Update Magnitude: 0.38686

Collected Steps per Second: 22,051.19021
Overall Steps per Second: 10,613.91785

Timestep Collection Time: 2.26763
Timestep Consumption Time: 2.44354
PPO Batch Consumption Time: 0.27967
Total Iteration Time: 4.71117

Cumulative Model Updates: 51,368
Cumulative Timesteps: 428,534,060

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 871.63949
Policy Entropy: 3.32626
Value Function Loss: 0.00331

Mean KL Divergence: 0.00631
SB3 Clip Fraction: 0.06782
Policy Update Magnitude: 0.45926
Value Function Update Magnitude: 0.42372

Collected Steps per Second: 22,498.19691
Overall Steps per Second: 10,562.20120

Timestep Collection Time: 2.22284
Timestep Consumption Time: 2.51196
PPO Batch Consumption Time: 0.28991
Total Iteration Time: 4.73481

Cumulative Model Updates: 51,374
Cumulative Timesteps: 428,584,070

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 428584070...
Checkpoint 428584070 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 790.86496
Policy Entropy: 3.32210
Value Function Loss: 0.00343

Mean KL Divergence: 0.00618
SB3 Clip Fraction: 0.06811
Policy Update Magnitude: 0.46105
Value Function Update Magnitude: 0.41669

Collected Steps per Second: 22,495.04574
Overall Steps per Second: 10,679.81147

Timestep Collection Time: 2.22440
Timestep Consumption Time: 2.46089
PPO Batch Consumption Time: 0.28990
Total Iteration Time: 4.68529

Cumulative Model Updates: 51,380
Cumulative Timesteps: 428,634,108

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 842.85668
Policy Entropy: 3.31819
Value Function Loss: 0.00340

Mean KL Divergence: 0.00777
SB3 Clip Fraction: 0.08620
Policy Update Magnitude: 0.46614
Value Function Update Magnitude: 0.41837

Collected Steps per Second: 22,958.17493
Overall Steps per Second: 10,688.56630

Timestep Collection Time: 2.17866
Timestep Consumption Time: 2.50092
PPO Batch Consumption Time: 0.29625
Total Iteration Time: 4.67958

Cumulative Model Updates: 51,386
Cumulative Timesteps: 428,684,126

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 428684126...
Checkpoint 428684126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,201.16635
Policy Entropy: 3.34119
Value Function Loss: 0.00326

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.08590
Policy Update Magnitude: 0.46295
Value Function Update Magnitude: 0.40424

Collected Steps per Second: 22,623.11653
Overall Steps per Second: 10,658.18080

Timestep Collection Time: 2.21119
Timestep Consumption Time: 2.48229
PPO Batch Consumption Time: 0.29434
Total Iteration Time: 4.69348

Cumulative Model Updates: 51,392
Cumulative Timesteps: 428,734,150

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,036.52173
Policy Entropy: 3.33396
Value Function Loss: 0.00315

Mean KL Divergence: 0.00673
SB3 Clip Fraction: 0.07588
Policy Update Magnitude: 0.45188
Value Function Update Magnitude: 0.38948

Collected Steps per Second: 22,968.11098
Overall Steps per Second: 10,921.01952

Timestep Collection Time: 2.17737
Timestep Consumption Time: 2.40188
PPO Batch Consumption Time: 0.27964
Total Iteration Time: 4.57924

Cumulative Model Updates: 51,398
Cumulative Timesteps: 428,784,160

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 428784160...
Checkpoint 428784160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,217.87810
Policy Entropy: 3.35334
Value Function Loss: 0.00318

Mean KL Divergence: 0.00737
SB3 Clip Fraction: 0.08335
Policy Update Magnitude: 0.44854
Value Function Update Magnitude: 0.38022

Collected Steps per Second: 22,885.55170
Overall Steps per Second: 10,621.98278

Timestep Collection Time: 2.18540
Timestep Consumption Time: 2.52314
PPO Batch Consumption Time: 0.29570
Total Iteration Time: 4.70854

Cumulative Model Updates: 51,404
Cumulative Timesteps: 428,834,174

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,492.43162
Policy Entropy: 3.33590
Value Function Loss: 0.00335

Mean KL Divergence: 0.00668
SB3 Clip Fraction: 0.07630
Policy Update Magnitude: 0.45294
Value Function Update Magnitude: 0.38895

Collected Steps per Second: 22,793.02439
Overall Steps per Second: 10,839.84110

Timestep Collection Time: 2.19479
Timestep Consumption Time: 2.42022
PPO Batch Consumption Time: 0.28179
Total Iteration Time: 4.61501

Cumulative Model Updates: 51,410
Cumulative Timesteps: 428,884,200

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 428884200...
Checkpoint 428884200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,030.28748
Policy Entropy: 3.35350
Value Function Loss: 0.00358

Mean KL Divergence: 0.00621
SB3 Clip Fraction: 0.06972
Policy Update Magnitude: 0.46317
Value Function Update Magnitude: 0.38192

Collected Steps per Second: 22,088.89701
Overall Steps per Second: 10,549.35978

Timestep Collection Time: 2.26367
Timestep Consumption Time: 2.47614
PPO Batch Consumption Time: 0.29395
Total Iteration Time: 4.73981

Cumulative Model Updates: 51,416
Cumulative Timesteps: 428,934,202

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,545.48688
Policy Entropy: 3.34794
Value Function Loss: 0.00344

Mean KL Divergence: 0.00580
SB3 Clip Fraction: 0.06333
Policy Update Magnitude: 0.46849
Value Function Update Magnitude: 0.40389

Collected Steps per Second: 22,479.82016
Overall Steps per Second: 10,813.26273

Timestep Collection Time: 2.22502
Timestep Consumption Time: 2.40060
PPO Batch Consumption Time: 0.27965
Total Iteration Time: 4.62562

Cumulative Model Updates: 51,422
Cumulative Timesteps: 428,984,220

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 428984220...
Checkpoint 428984220 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 581.10158
Policy Entropy: 3.35233
Value Function Loss: 0.00334

Mean KL Divergence: 0.00534
SB3 Clip Fraction: 0.05675
Policy Update Magnitude: 0.46541
Value Function Update Magnitude: 0.39655

Collected Steps per Second: 22,369.04624
Overall Steps per Second: 10,637.79960

Timestep Collection Time: 2.23577
Timestep Consumption Time: 2.46558
PPO Batch Consumption Time: 0.29172
Total Iteration Time: 4.70135

Cumulative Model Updates: 51,428
Cumulative Timesteps: 429,034,232

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 898.48315
Policy Entropy: 3.34536
Value Function Loss: 0.00319

Mean KL Divergence: 0.00695
SB3 Clip Fraction: 0.07656
Policy Update Magnitude: 0.45412
Value Function Update Magnitude: 0.39771

Collected Steps per Second: 22,419.43888
Overall Steps per Second: 10,538.89589

Timestep Collection Time: 2.23056
Timestep Consumption Time: 2.51452
PPO Batch Consumption Time: 0.29338
Total Iteration Time: 4.74509

Cumulative Model Updates: 51,434
Cumulative Timesteps: 429,084,240

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 429084240...
Checkpoint 429084240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,241.06901
Policy Entropy: 3.33060
Value Function Loss: 0.00321

Mean KL Divergence: 0.00569
SB3 Clip Fraction: 0.06271
Policy Update Magnitude: 0.44461
Value Function Update Magnitude: 0.38064

Collected Steps per Second: 22,851.53478
Overall Steps per Second: 10,679.94603

Timestep Collection Time: 2.18909
Timestep Consumption Time: 2.49483
PPO Batch Consumption Time: 0.29302
Total Iteration Time: 4.68392

Cumulative Model Updates: 51,440
Cumulative Timesteps: 429,134,264

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,934.41139
Policy Entropy: 3.31909
Value Function Loss: 0.00312

Mean KL Divergence: 0.00611
SB3 Clip Fraction: 0.06953
Policy Update Magnitude: 0.44346
Value Function Update Magnitude: 0.37000

Collected Steps per Second: 22,944.54084
Overall Steps per Second: 10,747.78605

Timestep Collection Time: 2.17969
Timestep Consumption Time: 2.47355
PPO Batch Consumption Time: 0.28543
Total Iteration Time: 4.65324

Cumulative Model Updates: 51,446
Cumulative Timesteps: 429,184,276

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 429184276...
Checkpoint 429184276 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,271.94224
Policy Entropy: 3.32640
Value Function Loss: 0.00314

Mean KL Divergence: 0.00566
SB3 Clip Fraction: 0.06247
Policy Update Magnitude: 0.44493
Value Function Update Magnitude: 0.36104

Collected Steps per Second: 22,813.56648
Overall Steps per Second: 10,675.63572

Timestep Collection Time: 2.19264
Timestep Consumption Time: 2.49298
PPO Batch Consumption Time: 0.29154
Total Iteration Time: 4.68562

Cumulative Model Updates: 51,452
Cumulative Timesteps: 429,234,298

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,051.67292
Policy Entropy: 3.31555
Value Function Loss: 0.00334

Mean KL Divergence: 0.00617
SB3 Clip Fraction: 0.06952
Policy Update Magnitude: 0.44444
Value Function Update Magnitude: 0.36981

Collected Steps per Second: 22,730.20786
Overall Steps per Second: 10,819.91484

Timestep Collection Time: 2.20139
Timestep Consumption Time: 2.42323
PPO Batch Consumption Time: 0.28168
Total Iteration Time: 4.62462

Cumulative Model Updates: 51,458
Cumulative Timesteps: 429,284,336

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 429284336...
Checkpoint 429284336 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,055.84733
Policy Entropy: 3.31739
Value Function Loss: 0.00335

Mean KL Divergence: 0.00682
SB3 Clip Fraction: 0.07727
Policy Update Magnitude: 0.44922
Value Function Update Magnitude: 0.39283

Collected Steps per Second: 22,852.08371
Overall Steps per Second: 10,715.92248

Timestep Collection Time: 2.18851
Timestep Consumption Time: 2.47856
PPO Batch Consumption Time: 0.28834
Total Iteration Time: 4.66707

Cumulative Model Updates: 51,464
Cumulative Timesteps: 429,334,348

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,454.26299
Policy Entropy: 3.31761
Value Function Loss: 0.00309

Mean KL Divergence: 0.00740
SB3 Clip Fraction: 0.08367
Policy Update Magnitude: 0.44955
Value Function Update Magnitude: 0.38731

Collected Steps per Second: 22,759.08142
Overall Steps per Second: 10,859.45011

Timestep Collection Time: 2.19816
Timestep Consumption Time: 2.40871
PPO Batch Consumption Time: 0.28074
Total Iteration Time: 4.60686

Cumulative Model Updates: 51,470
Cumulative Timesteps: 429,384,376

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 429384376...
Checkpoint 429384376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,378.14108
Policy Entropy: 3.34331
Value Function Loss: 0.00317

Mean KL Divergence: 0.00648
SB3 Clip Fraction: 0.07200
Policy Update Magnitude: 0.44458
Value Function Update Magnitude: 0.36773

Collected Steps per Second: 22,604.27899
Overall Steps per Second: 10,732.87013

Timestep Collection Time: 2.21312
Timestep Consumption Time: 2.44789
PPO Batch Consumption Time: 0.28959
Total Iteration Time: 4.66101

Cumulative Model Updates: 51,476
Cumulative Timesteps: 429,434,402

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,010.84086
Policy Entropy: 3.35423
Value Function Loss: 0.00331

Mean KL Divergence: 0.00589
SB3 Clip Fraction: 0.06499
Policy Update Magnitude: 0.45838
Value Function Update Magnitude: 0.37658

Collected Steps per Second: 22,553.18466
Overall Steps per Second: 10,614.21970

Timestep Collection Time: 2.21743
Timestep Consumption Time: 2.49418
PPO Batch Consumption Time: 0.29142
Total Iteration Time: 4.71160

Cumulative Model Updates: 51,482
Cumulative Timesteps: 429,484,412

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 429484412...
Checkpoint 429484412 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,420.19443
Policy Entropy: 3.33580
Value Function Loss: 0.00372

Mean KL Divergence: 0.00694
SB3 Clip Fraction: 0.07934
Policy Update Magnitude: 0.47159
Value Function Update Magnitude: 0.39077

Collected Steps per Second: 22,611.73649
Overall Steps per Second: 10,829.39306

Timestep Collection Time: 2.21186
Timestep Consumption Time: 2.40650
PPO Batch Consumption Time: 0.28038
Total Iteration Time: 4.61836

Cumulative Model Updates: 51,488
Cumulative Timesteps: 429,534,426

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 836.17683
Policy Entropy: 3.32545
Value Function Loss: 0.00367

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.09033
Policy Update Magnitude: 0.47109
Value Function Update Magnitude: 0.40660

Collected Steps per Second: 22,190.22480
Overall Steps per Second: 10,527.19199

Timestep Collection Time: 2.25351
Timestep Consumption Time: 2.49666
PPO Batch Consumption Time: 0.29534
Total Iteration Time: 4.75017

Cumulative Model Updates: 51,494
Cumulative Timesteps: 429,584,432

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 429584432...
Checkpoint 429584432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,002.54908
Policy Entropy: 3.32989
Value Function Loss: 0.00358

Mean KL Divergence: 0.00770
SB3 Clip Fraction: 0.08564
Policy Update Magnitude: 0.46739
Value Function Update Magnitude: 0.41006

Collected Steps per Second: 22,215.03080
Overall Steps per Second: 10,668.55534

Timestep Collection Time: 2.25145
Timestep Consumption Time: 2.43672
PPO Batch Consumption Time: 0.28594
Total Iteration Time: 4.68817

Cumulative Model Updates: 51,500
Cumulative Timesteps: 429,634,448

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,021.52932
Policy Entropy: 3.34088
Value Function Loss: 0.00330

Mean KL Divergence: 0.00646
SB3 Clip Fraction: 0.07168
Policy Update Magnitude: 0.46919
Value Function Update Magnitude: 0.38713

Collected Steps per Second: 22,706.09086
Overall Steps per Second: 10,621.23633

Timestep Collection Time: 2.20214
Timestep Consumption Time: 2.50560
PPO Batch Consumption Time: 0.29023
Total Iteration Time: 4.70774

Cumulative Model Updates: 51,506
Cumulative Timesteps: 429,684,450

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 429684450...
Checkpoint 429684450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 676.81477
Policy Entropy: 3.33730
Value Function Loss: 0.00334

Mean KL Divergence: 0.00611
SB3 Clip Fraction: 0.06924
Policy Update Magnitude: 0.46956
Value Function Update Magnitude: 0.37833

Collected Steps per Second: 22,958.98271
Overall Steps per Second: 10,802.41837

Timestep Collection Time: 2.17823
Timestep Consumption Time: 2.45129
PPO Batch Consumption Time: 0.28138
Total Iteration Time: 4.62952

Cumulative Model Updates: 51,512
Cumulative Timesteps: 429,734,460

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 910.28265
Policy Entropy: 3.33231
Value Function Loss: 0.00320

Mean KL Divergence: 0.00695
SB3 Clip Fraction: 0.07641
Policy Update Magnitude: 0.46500
Value Function Update Magnitude: 0.38015

Collected Steps per Second: 22,902.61017
Overall Steps per Second: 10,648.71236

Timestep Collection Time: 2.18490
Timestep Consumption Time: 2.51426
PPO Batch Consumption Time: 0.29441
Total Iteration Time: 4.69916

Cumulative Model Updates: 51,518
Cumulative Timesteps: 429,784,500

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 429784500...
Checkpoint 429784500 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 937.85327
Policy Entropy: 3.32672
Value Function Loss: 0.00331

Mean KL Divergence: 0.00676
SB3 Clip Fraction: 0.07574
Policy Update Magnitude: 0.46051
Value Function Update Magnitude: 0.37363

Collected Steps per Second: 22,565.29923
Overall Steps per Second: 10,570.08371

Timestep Collection Time: 2.21641
Timestep Consumption Time: 2.51524
PPO Batch Consumption Time: 0.29554
Total Iteration Time: 4.73166

Cumulative Model Updates: 51,524
Cumulative Timesteps: 429,834,514

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 997.32387
Policy Entropy: 3.32425
Value Function Loss: 0.00335

Mean KL Divergence: 0.00626
SB3 Clip Fraction: 0.06895
Policy Update Magnitude: 0.45675
Value Function Update Magnitude: 0.37216

Collected Steps per Second: 22,874.61434
Overall Steps per Second: 10,795.74695

Timestep Collection Time: 2.18688
Timestep Consumption Time: 2.44680
PPO Batch Consumption Time: 0.28177
Total Iteration Time: 4.63368

Cumulative Model Updates: 51,530
Cumulative Timesteps: 429,884,538

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 429884538...
Checkpoint 429884538 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,070.98675
Policy Entropy: 3.33343
Value Function Loss: 0.00350

Mean KL Divergence: 0.00656
SB3 Clip Fraction: 0.07307
Policy Update Magnitude: 0.45784
Value Function Update Magnitude: 0.37520

Collected Steps per Second: 22,621.44314
Overall Steps per Second: 10,518.51049

Timestep Collection Time: 2.21082
Timestep Consumption Time: 2.54384
PPO Batch Consumption Time: 0.30190
Total Iteration Time: 4.75467

Cumulative Model Updates: 51,536
Cumulative Timesteps: 429,934,550

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 708.87650
Policy Entropy: 3.32462
Value Function Loss: 0.00361

Mean KL Divergence: 0.00644
SB3 Clip Fraction: 0.07132
Policy Update Magnitude: 0.46894
Value Function Update Magnitude: 0.38607

Collected Steps per Second: 22,401.15034
Overall Steps per Second: 10,672.18665

Timestep Collection Time: 2.23265
Timestep Consumption Time: 2.45373
PPO Batch Consumption Time: 0.28391
Total Iteration Time: 4.68639

Cumulative Model Updates: 51,542
Cumulative Timesteps: 429,984,564

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 429984564...
Checkpoint 429984564 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 733.59699
Policy Entropy: 3.32910
Value Function Loss: 0.00367

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.08737
Policy Update Magnitude: 0.48026
Value Function Update Magnitude: 0.39096

Collected Steps per Second: 22,029.70347
Overall Steps per Second: 10,646.93650

Timestep Collection Time: 2.27148
Timestep Consumption Time: 2.42846
PPO Batch Consumption Time: 0.28569
Total Iteration Time: 4.69994

Cumulative Model Updates: 51,548
Cumulative Timesteps: 430,034,604

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,236.78860
Policy Entropy: 3.33562
Value Function Loss: 0.00353

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.08487
Policy Update Magnitude: 0.48412
Value Function Update Magnitude: 0.40849

Collected Steps per Second: 22,681.80335
Overall Steps per Second: 10,768.21049

Timestep Collection Time: 2.20538
Timestep Consumption Time: 2.43996
PPO Batch Consumption Time: 0.28070
Total Iteration Time: 4.64534

Cumulative Model Updates: 51,554
Cumulative Timesteps: 430,084,626

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 430084626...
Checkpoint 430084626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 892.91141
Policy Entropy: 3.33093
Value Function Loss: 0.00347

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.09203
Policy Update Magnitude: 0.46604
Value Function Update Magnitude: 0.41686

Collected Steps per Second: 21,779.34022
Overall Steps per Second: 10,395.47621

Timestep Collection Time: 2.29649
Timestep Consumption Time: 2.51484
PPO Batch Consumption Time: 0.29499
Total Iteration Time: 4.81132

Cumulative Model Updates: 51,560
Cumulative Timesteps: 430,134,642

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,102.03367
Policy Entropy: 3.32863
Value Function Loss: 0.00334

Mean KL Divergence: 0.00694
SB3 Clip Fraction: 0.07906
Policy Update Magnitude: 0.45833
Value Function Update Magnitude: 0.42180

Collected Steps per Second: 22,602.77492
Overall Steps per Second: 10,790.00331

Timestep Collection Time: 2.21309
Timestep Consumption Time: 2.42287
PPO Batch Consumption Time: 0.28098
Total Iteration Time: 4.63596

Cumulative Model Updates: 51,566
Cumulative Timesteps: 430,184,664

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 430184664...
Checkpoint 430184664 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,294.50851
Policy Entropy: 3.32834
Value Function Loss: 0.00336

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.09248
Policy Update Magnitude: 0.46252
Value Function Update Magnitude: 0.41931

Collected Steps per Second: 21,941.21378
Overall Steps per Second: 10,621.34417

Timestep Collection Time: 2.27882
Timestep Consumption Time: 2.42869
PPO Batch Consumption Time: 0.28081
Total Iteration Time: 4.70750

Cumulative Model Updates: 51,572
Cumulative Timesteps: 430,234,664

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 749.14879
Policy Entropy: 3.33782
Value Function Loss: 0.00324

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.08837
Policy Update Magnitude: 0.45768
Value Function Update Magnitude: 0.41096

Collected Steps per Second: 22,867.07121
Overall Steps per Second: 10,851.90563

Timestep Collection Time: 2.18664
Timestep Consumption Time: 2.42103
PPO Batch Consumption Time: 0.28130
Total Iteration Time: 4.60767

Cumulative Model Updates: 51,578
Cumulative Timesteps: 430,284,666

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 430284666...
Checkpoint 430284666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,954.50757
Policy Entropy: 3.35248
Value Function Loss: 0.00316

Mean KL Divergence: 0.00632
SB3 Clip Fraction: 0.07068
Policy Update Magnitude: 0.46000
Value Function Update Magnitude: 0.40648

Collected Steps per Second: 22,339.27363
Overall Steps per Second: 10,756.38622

Timestep Collection Time: 2.23839
Timestep Consumption Time: 2.41038
PPO Batch Consumption Time: 0.28031
Total Iteration Time: 4.64877

Cumulative Model Updates: 51,584
Cumulative Timesteps: 430,334,670

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,121.10776
Policy Entropy: 3.33700
Value Function Loss: 0.00326

Mean KL Divergence: 0.00665
SB3 Clip Fraction: 0.07409
Policy Update Magnitude: 0.45866
Value Function Update Magnitude: 0.40252

Collected Steps per Second: 22,867.21383
Overall Steps per Second: 10,873.90212

Timestep Collection Time: 2.18767
Timestep Consumption Time: 2.41288
PPO Batch Consumption Time: 0.28129
Total Iteration Time: 4.60056

Cumulative Model Updates: 51,590
Cumulative Timesteps: 430,384,696

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 430384696...
Checkpoint 430384696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,094.95760
Policy Entropy: 3.34827
Value Function Loss: 0.00324

Mean KL Divergence: 0.00603
SB3 Clip Fraction: 0.06688
Policy Update Magnitude: 0.45648
Value Function Update Magnitude: 0.40598

Collected Steps per Second: 21,415.70661
Overall Steps per Second: 10,297.43083

Timestep Collection Time: 2.33483
Timestep Consumption Time: 2.52095
PPO Batch Consumption Time: 0.29460
Total Iteration Time: 4.85577

Cumulative Model Updates: 51,596
Cumulative Timesteps: 430,434,698

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,422.61009
Policy Entropy: 3.31228
Value Function Loss: 0.00323

Mean KL Divergence: 0.00556
SB3 Clip Fraction: 0.06053
Policy Update Magnitude: 0.45377
Value Function Update Magnitude: 0.39862

Collected Steps per Second: 22,486.80157
Overall Steps per Second: 10,786.34151

Timestep Collection Time: 2.22388
Timestep Consumption Time: 2.41235
PPO Batch Consumption Time: 0.28104
Total Iteration Time: 4.63623

Cumulative Model Updates: 51,602
Cumulative Timesteps: 430,484,706

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 430484706...
Checkpoint 430484706 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,161.28398
Policy Entropy: 3.30939
Value Function Loss: 0.00327

Mean KL Divergence: 0.00713
SB3 Clip Fraction: 0.07792
Policy Update Magnitude: 0.44661
Value Function Update Magnitude: 0.38011

Collected Steps per Second: 22,167.00586
Overall Steps per Second: 10,657.22350

Timestep Collection Time: 2.25642
Timestep Consumption Time: 2.43693
PPO Batch Consumption Time: 0.28182
Total Iteration Time: 4.69334

Cumulative Model Updates: 51,608
Cumulative Timesteps: 430,534,724

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 770.45731
Policy Entropy: 3.30934
Value Function Loss: 0.00322

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.08508
Policy Update Magnitude: 0.44839
Value Function Update Magnitude: 0.38750

Collected Steps per Second: 22,055.94781
Overall Steps per Second: 10,514.25461

Timestep Collection Time: 2.26823
Timestep Consumption Time: 2.48988
PPO Batch Consumption Time: 0.28582
Total Iteration Time: 4.75811

Cumulative Model Updates: 51,614
Cumulative Timesteps: 430,584,752

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 430584752...
Checkpoint 430584752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 963.97774
Policy Entropy: 3.30962
Value Function Loss: 0.00349

Mean KL Divergence: 0.00681
SB3 Clip Fraction: 0.07709
Policy Update Magnitude: 0.45885
Value Function Update Magnitude: 0.41013

Collected Steps per Second: 22,142.88532
Overall Steps per Second: 10,579.69400

Timestep Collection Time: 2.25869
Timestep Consumption Time: 2.46866
PPO Batch Consumption Time: 0.28079
Total Iteration Time: 4.72736

Cumulative Model Updates: 51,620
Cumulative Timesteps: 430,634,766

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,355.20594
Policy Entropy: 3.30611
Value Function Loss: 0.00353

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.10008
Policy Update Magnitude: 0.46485
Value Function Update Magnitude: 0.42424

Collected Steps per Second: 22,944.85980
Overall Steps per Second: 10,861.85539

Timestep Collection Time: 2.17966
Timestep Consumption Time: 2.42471
PPO Batch Consumption Time: 0.28094
Total Iteration Time: 4.60437

Cumulative Model Updates: 51,626
Cumulative Timesteps: 430,684,778

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 430684778...
Checkpoint 430684778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,468.83794
Policy Entropy: 3.29885
Value Function Loss: 0.00373

Mean KL Divergence: 0.00751
SB3 Clip Fraction: 0.08320
Policy Update Magnitude: 0.46976
Value Function Update Magnitude: 0.42120

Collected Steps per Second: 22,348.80359
Overall Steps per Second: 10,737.90342

Timestep Collection Time: 2.23842
Timestep Consumption Time: 2.42040
PPO Batch Consumption Time: 0.28100
Total Iteration Time: 4.65882

Cumulative Model Updates: 51,632
Cumulative Timesteps: 430,734,804

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,441.66056
Policy Entropy: 3.30359
Value Function Loss: 0.00355

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.09492
Policy Update Magnitude: 0.46946
Value Function Update Magnitude: 0.42838

Collected Steps per Second: 22,857.91684
Overall Steps per Second: 10,858.81858

Timestep Collection Time: 2.18830
Timestep Consumption Time: 2.41809
PPO Batch Consumption Time: 0.28143
Total Iteration Time: 4.60639

Cumulative Model Updates: 51,638
Cumulative Timesteps: 430,784,824

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 430784824...
Checkpoint 430784824 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,292.31964
Policy Entropy: 3.31244
Value Function Loss: 0.00342

Mean KL Divergence: 0.00718
SB3 Clip Fraction: 0.07918
Policy Update Magnitude: 0.46783
Value Function Update Magnitude: 0.43360

Collected Steps per Second: 22,544.07538
Overall Steps per Second: 10,661.20580

Timestep Collection Time: 2.21841
Timestep Consumption Time: 2.47262
PPO Batch Consumption Time: 0.29017
Total Iteration Time: 4.69103

Cumulative Model Updates: 51,644
Cumulative Timesteps: 430,834,836

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,158.51580
Policy Entropy: 3.31141
Value Function Loss: 0.00325

Mean KL Divergence: 0.00662
SB3 Clip Fraction: 0.07624
Policy Update Magnitude: 0.46759
Value Function Update Magnitude: 0.41090

Collected Steps per Second: 22,707.06416
Overall Steps per Second: 10,843.44162

Timestep Collection Time: 2.20249
Timestep Consumption Time: 2.40970
PPO Batch Consumption Time: 0.28002
Total Iteration Time: 4.61219

Cumulative Model Updates: 51,650
Cumulative Timesteps: 430,884,848

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 430884848...
Checkpoint 430884848 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 936.41814
Policy Entropy: 3.32187
Value Function Loss: 0.00323

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.08728
Policy Update Magnitude: 0.46392
Value Function Update Magnitude: 0.39809

Collected Steps per Second: 22,093.89100
Overall Steps per Second: 10,627.90477

Timestep Collection Time: 2.26343
Timestep Consumption Time: 2.44192
PPO Batch Consumption Time: 0.28038
Total Iteration Time: 4.70535

Cumulative Model Updates: 51,656
Cumulative Timesteps: 430,934,856

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,115.35722
Policy Entropy: 3.31742
Value Function Loss: 0.00321

Mean KL Divergence: 0.00623
SB3 Clip Fraction: 0.06880
Policy Update Magnitude: 0.46172
Value Function Update Magnitude: 0.39994

Collected Steps per Second: 22,292.16162
Overall Steps per Second: 10,547.97497

Timestep Collection Time: 2.24420
Timestep Consumption Time: 2.49870
PPO Batch Consumption Time: 0.29526
Total Iteration Time: 4.74290

Cumulative Model Updates: 51,662
Cumulative Timesteps: 430,984,884

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 430984884...
Checkpoint 430984884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,439.43071
Policy Entropy: 3.30942
Value Function Loss: 0.00324

Mean KL Divergence: 0.00645
SB3 Clip Fraction: 0.07192
Policy Update Magnitude: 0.46238
Value Function Update Magnitude: 0.41711

Collected Steps per Second: 22,120.22610
Overall Steps per Second: 10,698.02049

Timestep Collection Time: 2.26083
Timestep Consumption Time: 2.41387
PPO Batch Consumption Time: 0.28016
Total Iteration Time: 4.67470

Cumulative Model Updates: 51,668
Cumulative Timesteps: 431,034,894

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,373.27439
Policy Entropy: 3.31375
Value Function Loss: 0.00333

Mean KL Divergence: 0.00584
SB3 Clip Fraction: 0.06481
Policy Update Magnitude: 0.46424
Value Function Update Magnitude: 0.42316

Collected Steps per Second: 22,410.21991
Overall Steps per Second: 10,758.67891

Timestep Collection Time: 2.23229
Timestep Consumption Time: 2.41754
PPO Batch Consumption Time: 0.28084
Total Iteration Time: 4.64983

Cumulative Model Updates: 51,674
Cumulative Timesteps: 431,084,920

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 431084920...
Checkpoint 431084920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,205.19657
Policy Entropy: 3.31366
Value Function Loss: 0.00325

Mean KL Divergence: 0.00625
SB3 Clip Fraction: 0.07116
Policy Update Magnitude: 0.46972
Value Function Update Magnitude: 0.43249

Collected Steps per Second: 22,134.87015
Overall Steps per Second: 10,626.69104

Timestep Collection Time: 2.25888
Timestep Consumption Time: 2.44625
PPO Batch Consumption Time: 0.28078
Total Iteration Time: 4.70513

Cumulative Model Updates: 51,680
Cumulative Timesteps: 431,134,920

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,045.16873
Policy Entropy: 3.33658
Value Function Loss: 0.00319

Mean KL Divergence: 0.00606
SB3 Clip Fraction: 0.06950
Policy Update Magnitude: 0.46786
Value Function Update Magnitude: 0.41315

Collected Steps per Second: 22,801.39843
Overall Steps per Second: 10,592.10404

Timestep Collection Time: 2.19311
Timestep Consumption Time: 2.52795
PPO Batch Consumption Time: 0.29501
Total Iteration Time: 4.72106

Cumulative Model Updates: 51,686
Cumulative Timesteps: 431,184,926

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 431184926...
Checkpoint 431184926 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 906.68321
Policy Entropy: 3.33065
Value Function Loss: 0.00315

Mean KL Divergence: 0.00621
SB3 Clip Fraction: 0.07029
Policy Update Magnitude: 0.46131
Value Function Update Magnitude: 0.39322

Collected Steps per Second: 22,503.80580
Overall Steps per Second: 10,505.14390

Timestep Collection Time: 2.22220
Timestep Consumption Time: 2.53813
PPO Batch Consumption Time: 0.29882
Total Iteration Time: 4.76033

Cumulative Model Updates: 51,692
Cumulative Timesteps: 431,234,934

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,200.89851
Policy Entropy: 3.32994
Value Function Loss: 0.00335

Mean KL Divergence: 0.00690
SB3 Clip Fraction: 0.07674
Policy Update Magnitude: 0.45972
Value Function Update Magnitude: 0.38660

Collected Steps per Second: 22,457.62286
Overall Steps per Second: 10,611.44815

Timestep Collection Time: 2.22686
Timestep Consumption Time: 2.48597
PPO Batch Consumption Time: 0.29362
Total Iteration Time: 4.71283

Cumulative Model Updates: 51,698
Cumulative Timesteps: 431,284,944

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 431284944...
Checkpoint 431284944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 739.12259
Policy Entropy: 3.31958
Value Function Loss: 0.00336

Mean KL Divergence: 0.00743
SB3 Clip Fraction: 0.08388
Policy Update Magnitude: 0.46127
Value Function Update Magnitude: 0.40282

Collected Steps per Second: 22,638.40259
Overall Steps per Second: 10,655.57111

Timestep Collection Time: 2.20961
Timestep Consumption Time: 2.48484
PPO Batch Consumption Time: 0.29374
Total Iteration Time: 4.69445

Cumulative Model Updates: 51,704
Cumulative Timesteps: 431,334,966

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,338.18334
Policy Entropy: 3.31213
Value Function Loss: 0.00340

Mean KL Divergence: 0.00667
SB3 Clip Fraction: 0.07455
Policy Update Magnitude: 0.46582
Value Function Update Magnitude: 0.41099

Collected Steps per Second: 22,865.58123
Overall Steps per Second: 10,796.65879

Timestep Collection Time: 2.18783
Timestep Consumption Time: 2.44564
PPO Batch Consumption Time: 0.28156
Total Iteration Time: 4.63347

Cumulative Model Updates: 51,710
Cumulative Timesteps: 431,384,992

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 431384992...
Checkpoint 431384992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 872.71331
Policy Entropy: 3.31245
Value Function Loss: 0.00337

Mean KL Divergence: 0.00599
SB3 Clip Fraction: 0.06710
Policy Update Magnitude: 0.46589
Value Function Update Magnitude: 0.39685

Collected Steps per Second: 22,601.01302
Overall Steps per Second: 10,689.69665

Timestep Collection Time: 2.21247
Timestep Consumption Time: 2.46531
PPO Batch Consumption Time: 0.28577
Total Iteration Time: 4.67778

Cumulative Model Updates: 51,716
Cumulative Timesteps: 431,434,996

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,650.09768
Policy Entropy: 3.32121
Value Function Loss: 0.00322

Mean KL Divergence: 0.00730
SB3 Clip Fraction: 0.08136
Policy Update Magnitude: 0.45971
Value Function Update Magnitude: 0.39531

Collected Steps per Second: 22,029.23542
Overall Steps per Second: 10,496.95625

Timestep Collection Time: 2.27044
Timestep Consumption Time: 2.49437
PPO Batch Consumption Time: 0.29445
Total Iteration Time: 4.76481

Cumulative Model Updates: 51,722
Cumulative Timesteps: 431,485,012

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 431485012...
Checkpoint 431485012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,161.87981
Policy Entropy: 3.31424
Value Function Loss: 0.00314

Mean KL Divergence: 0.00686
SB3 Clip Fraction: 0.07723
Policy Update Magnitude: 0.45152
Value Function Update Magnitude: 0.40839

Collected Steps per Second: 22,015.56577
Overall Steps per Second: 10,622.36299

Timestep Collection Time: 2.27157
Timestep Consumption Time: 2.43642
PPO Batch Consumption Time: 0.27937
Total Iteration Time: 4.70799

Cumulative Model Updates: 51,728
Cumulative Timesteps: 431,535,022

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,383.03934
Policy Entropy: 3.31585
Value Function Loss: 0.00311

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.09889
Policy Update Magnitude: 0.44485
Value Function Update Magnitude: 0.41280

Collected Steps per Second: 22,335.52362
Overall Steps per Second: 10,479.39239

Timestep Collection Time: 2.23894
Timestep Consumption Time: 2.53309
PPO Batch Consumption Time: 0.29408
Total Iteration Time: 4.77203

Cumulative Model Updates: 51,734
Cumulative Timesteps: 431,585,030

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 431585030...
Checkpoint 431585030 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,808.33623
Policy Entropy: 3.31598
Value Function Loss: 0.00320

Mean KL Divergence: 0.01088
SB3 Clip Fraction: 0.11285
Policy Update Magnitude: 0.44422
Value Function Update Magnitude: 0.41833

Collected Steps per Second: 22,195.58043
Overall Steps per Second: 10,589.05638

Timestep Collection Time: 2.25360
Timestep Consumption Time: 2.47014
PPO Batch Consumption Time: 0.28590
Total Iteration Time: 4.72374

Cumulative Model Updates: 51,740
Cumulative Timesteps: 431,635,050

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 810.30399
Policy Entropy: 3.31994
Value Function Loss: 0.00334

Mean KL Divergence: 0.00749
SB3 Clip Fraction: 0.08369
Policy Update Magnitude: 0.44786
Value Function Update Magnitude: 0.41732

Collected Steps per Second: 22,850.89235
Overall Steps per Second: 10,796.14092

Timestep Collection Time: 2.18862
Timestep Consumption Time: 2.44377
PPO Batch Consumption Time: 0.28107
Total Iteration Time: 4.63240

Cumulative Model Updates: 51,746
Cumulative Timesteps: 431,685,062

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 431685062...
Checkpoint 431685062 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,954.46963
Policy Entropy: 3.31748
Value Function Loss: 0.00341

Mean KL Divergence: 0.00609
SB3 Clip Fraction: 0.06688
Policy Update Magnitude: 0.46380
Value Function Update Magnitude: 0.43048

Collected Steps per Second: 22,283.97213
Overall Steps per Second: 10,693.59477

Timestep Collection Time: 2.24421
Timestep Consumption Time: 2.43242
PPO Batch Consumption Time: 0.28136
Total Iteration Time: 4.67663

Cumulative Model Updates: 51,752
Cumulative Timesteps: 431,735,072

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,209.73331
Policy Entropy: 3.32353
Value Function Loss: 0.00340

Mean KL Divergence: 0.00667
SB3 Clip Fraction: 0.07332
Policy Update Magnitude: 0.47462
Value Function Update Magnitude: 0.44302

Collected Steps per Second: 22,741.78677
Overall Steps per Second: 10,684.83599

Timestep Collection Time: 2.19912
Timestep Consumption Time: 2.48153
PPO Batch Consumption Time: 0.29082
Total Iteration Time: 4.68065

Cumulative Model Updates: 51,758
Cumulative Timesteps: 431,785,084

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 431785084...
Checkpoint 431785084 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 891.73436
Policy Entropy: 3.32908
Value Function Loss: 0.00340

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.10322
Policy Update Magnitude: 0.47707
Value Function Update Magnitude: 0.44298

Collected Steps per Second: 22,460.52934
Overall Steps per Second: 10,769.02243

Timestep Collection Time: 2.22631
Timestep Consumption Time: 2.41701
PPO Batch Consumption Time: 0.28138
Total Iteration Time: 4.64332

Cumulative Model Updates: 51,764
Cumulative Timesteps: 431,835,088

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,254.85685
Policy Entropy: 3.34559
Value Function Loss: 0.00345

Mean KL Divergence: 0.01441
SB3 Clip Fraction: 0.13175
Policy Update Magnitude: 0.46721
Value Function Update Magnitude: 0.44633

Collected Steps per Second: 22,818.76409
Overall Steps per Second: 10,564.41471

Timestep Collection Time: 2.19258
Timestep Consumption Time: 2.54332
PPO Batch Consumption Time: 0.30361
Total Iteration Time: 4.73590

Cumulative Model Updates: 51,770
Cumulative Timesteps: 431,885,120

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 431885120...
Checkpoint 431885120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,330.55228
Policy Entropy: 3.35131
Value Function Loss: 0.00358

Mean KL Divergence: 0.01552
SB3 Clip Fraction: 0.14251
Policy Update Magnitude: 0.46677
Value Function Update Magnitude: 0.45431

Collected Steps per Second: 22,339.10413
Overall Steps per Second: 10,529.31448

Timestep Collection Time: 2.23876
Timestep Consumption Time: 2.51102
PPO Batch Consumption Time: 0.28862
Total Iteration Time: 4.74979

Cumulative Model Updates: 51,776
Cumulative Timesteps: 431,935,132

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 982.69577
Policy Entropy: 3.33636
Value Function Loss: 0.00343

Mean KL Divergence: 0.01522
SB3 Clip Fraction: 0.13789
Policy Update Magnitude: 0.46464
Value Function Update Magnitude: 0.46052

Collected Steps per Second: 22,400.91291
Overall Steps per Second: 10,598.62613

Timestep Collection Time: 2.23250
Timestep Consumption Time: 2.48604
PPO Batch Consumption Time: 0.28697
Total Iteration Time: 4.71854

Cumulative Model Updates: 51,782
Cumulative Timesteps: 431,985,142

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 431985142...
Checkpoint 431985142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 827.61341
Policy Entropy: 3.32696
Value Function Loss: 0.00343

Mean KL Divergence: 0.01291
SB3 Clip Fraction: 0.12907
Policy Update Magnitude: 0.46576
Value Function Update Magnitude: 0.44284

Collected Steps per Second: 22,125.56869
Overall Steps per Second: 10,640.98338

Timestep Collection Time: 2.26010
Timestep Consumption Time: 2.43928
PPO Batch Consumption Time: 0.28595
Total Iteration Time: 4.69938

Cumulative Model Updates: 51,788
Cumulative Timesteps: 432,035,148

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,043.91761
Policy Entropy: 3.31579
Value Function Loss: 0.00337

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.10384
Policy Update Magnitude: 0.46948
Value Function Update Magnitude: 0.43313

Collected Steps per Second: 22,489.20113
Overall Steps per Second: 10,653.87730

Timestep Collection Time: 2.22445
Timestep Consumption Time: 2.47112
PPO Batch Consumption Time: 0.29006
Total Iteration Time: 4.69557

Cumulative Model Updates: 51,794
Cumulative Timesteps: 432,085,174

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 432085174...
Checkpoint 432085174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,633.00707
Policy Entropy: 3.32462
Value Function Loss: 0.00344

Mean KL Divergence: 0.00694
SB3 Clip Fraction: 0.07836
Policy Update Magnitude: 0.47303
Value Function Update Magnitude: 0.44822

Collected Steps per Second: 22,227.72712
Overall Steps per Second: 10,549.68999

Timestep Collection Time: 2.24971
Timestep Consumption Time: 2.49033
PPO Batch Consumption Time: 0.29252
Total Iteration Time: 4.74004

Cumulative Model Updates: 51,800
Cumulative Timesteps: 432,135,180

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,540.22998
Policy Entropy: 3.33275
Value Function Loss: 0.00352

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.09502
Policy Update Magnitude: 0.46829
Value Function Update Magnitude: 0.46645

Collected Steps per Second: 22,882.40517
Overall Steps per Second: 10,734.24715

Timestep Collection Time: 2.18543
Timestep Consumption Time: 2.47330
PPO Batch Consumption Time: 0.28664
Total Iteration Time: 4.65873

Cumulative Model Updates: 51,806
Cumulative Timesteps: 432,185,188

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 432185188...
Checkpoint 432185188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,679.11179
Policy Entropy: 3.34492
Value Function Loss: 0.00346

Mean KL Divergence: 0.00747
SB3 Clip Fraction: 0.08383
Policy Update Magnitude: 0.47410
Value Function Update Magnitude: 0.47671

Collected Steps per Second: 22,528.41604
Overall Steps per Second: 10,722.31971

Timestep Collection Time: 2.21995
Timestep Consumption Time: 2.44434
PPO Batch Consumption Time: 0.28008
Total Iteration Time: 4.66429

Cumulative Model Updates: 51,812
Cumulative Timesteps: 432,235,200

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,572.45705
Policy Entropy: 3.32372
Value Function Loss: 0.00350

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.09049
Policy Update Magnitude: 0.47001
Value Function Update Magnitude: 0.47055

Collected Steps per Second: 22,863.09714
Overall Steps per Second: 10,876.09633

Timestep Collection Time: 2.18772
Timestep Consumption Time: 2.41118
PPO Batch Consumption Time: 0.28108
Total Iteration Time: 4.59889

Cumulative Model Updates: 51,818
Cumulative Timesteps: 432,285,218

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 432285218...
Checkpoint 432285218 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,024.32254
Policy Entropy: 3.32275
Value Function Loss: 0.00357

Mean KL Divergence: 0.00738
SB3 Clip Fraction: 0.08210
Policy Update Magnitude: 0.46804
Value Function Update Magnitude: 0.46151

Collected Steps per Second: 21,371.19867
Overall Steps per Second: 10,409.98743

Timestep Collection Time: 2.34053
Timestep Consumption Time: 2.46447
PPO Batch Consumption Time: 0.29012
Total Iteration Time: 4.80500

Cumulative Model Updates: 51,824
Cumulative Timesteps: 432,335,238

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,165.29069
Policy Entropy: 3.32701
Value Function Loss: 0.00351

Mean KL Divergence: 0.00684
SB3 Clip Fraction: 0.07593
Policy Update Magnitude: 0.46838
Value Function Update Magnitude: 0.46523

Collected Steps per Second: 22,487.58706
Overall Steps per Second: 10,714.19118

Timestep Collection Time: 2.22469
Timestep Consumption Time: 2.44463
PPO Batch Consumption Time: 0.28613
Total Iteration Time: 4.66932

Cumulative Model Updates: 51,830
Cumulative Timesteps: 432,385,266

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 432385266...
Checkpoint 432385266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,079.10288
Policy Entropy: 3.33379
Value Function Loss: 0.00342

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.08723
Policy Update Magnitude: 0.46945
Value Function Update Magnitude: 0.46071

Collected Steps per Second: 22,254.03219
Overall Steps per Second: 10,632.45582

Timestep Collection Time: 2.24849
Timestep Consumption Time: 2.45767
PPO Batch Consumption Time: 0.28766
Total Iteration Time: 4.70616

Cumulative Model Updates: 51,836
Cumulative Timesteps: 432,435,304

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 593.64564
Policy Entropy: 3.33994
Value Function Loss: 0.00323

Mean KL Divergence: 0.00675
SB3 Clip Fraction: 0.07589
Policy Update Magnitude: 0.46642
Value Function Update Magnitude: 0.45402

Collected Steps per Second: 22,532.98680
Overall Steps per Second: 10,644.05739

Timestep Collection Time: 2.22012
Timestep Consumption Time: 2.47978
PPO Batch Consumption Time: 0.28954
Total Iteration Time: 4.69990

Cumulative Model Updates: 51,842
Cumulative Timesteps: 432,485,330

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 432485330...
Checkpoint 432485330 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,319.81156
Policy Entropy: 3.31932
Value Function Loss: 0.00354

Mean KL Divergence: 0.00711
SB3 Clip Fraction: 0.07796
Policy Update Magnitude: 0.46697
Value Function Update Magnitude: 0.44074

Collected Steps per Second: 22,509.51586
Overall Steps per Second: 10,534.83825

Timestep Collection Time: 2.22253
Timestep Consumption Time: 2.52629
PPO Batch Consumption Time: 0.29350
Total Iteration Time: 4.74882

Cumulative Model Updates: 51,848
Cumulative Timesteps: 432,535,358

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,671.35284
Policy Entropy: 3.31962
Value Function Loss: 0.00361

Mean KL Divergence: 0.00687
SB3 Clip Fraction: 0.07704
Policy Update Magnitude: 0.47367
Value Function Update Magnitude: 0.43729

Collected Steps per Second: 22,480.20812
Overall Steps per Second: 10,598.80201

Timestep Collection Time: 2.22471
Timestep Consumption Time: 2.49393
PPO Batch Consumption Time: 0.29387
Total Iteration Time: 4.71865

Cumulative Model Updates: 51,854
Cumulative Timesteps: 432,585,370

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 432585370...
Checkpoint 432585370 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,453.88203
Policy Entropy: 3.31165
Value Function Loss: 0.00364

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.08557
Policy Update Magnitude: 0.47686
Value Function Update Magnitude: 0.44499

Collected Steps per Second: 22,753.06749
Overall Steps per Second: 10,880.71183

Timestep Collection Time: 2.19838
Timestep Consumption Time: 2.39874
PPO Batch Consumption Time: 0.27994
Total Iteration Time: 4.59713

Cumulative Model Updates: 51,860
Cumulative Timesteps: 432,635,390

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,162.14098
Policy Entropy: 3.32149
Value Function Loss: 0.00342

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.08602
Policy Update Magnitude: 0.47174
Value Function Update Magnitude: 0.42261

Collected Steps per Second: 22,757.57420
Overall Steps per Second: 10,645.55731

Timestep Collection Time: 2.19821
Timestep Consumption Time: 2.50102
PPO Batch Consumption Time: 0.28945
Total Iteration Time: 4.69924

Cumulative Model Updates: 51,866
Cumulative Timesteps: 432,685,416

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 432685416...
Checkpoint 432685416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,503.49598
Policy Entropy: 3.32935
Value Function Loss: 0.00341

Mean KL Divergence: 0.00728
SB3 Clip Fraction: 0.08250
Policy Update Magnitude: 0.46725
Value Function Update Magnitude: 0.40804

Collected Steps per Second: 22,632.17355
Overall Steps per Second: 10,812.95535

Timestep Collection Time: 2.20977
Timestep Consumption Time: 2.41542
PPO Batch Consumption Time: 0.28138
Total Iteration Time: 4.62519

Cumulative Model Updates: 51,872
Cumulative Timesteps: 432,735,428

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 934.38539
Policy Entropy: 3.33367
Value Function Loss: 0.00355

Mean KL Divergence: 0.00704
SB3 Clip Fraction: 0.07873
Policy Update Magnitude: 0.46938
Value Function Update Magnitude: 0.41780

Collected Steps per Second: 22,718.63691
Overall Steps per Second: 10,724.74780

Timestep Collection Time: 2.20251
Timestep Consumption Time: 2.46315
PPO Batch Consumption Time: 0.29089
Total Iteration Time: 4.66566

Cumulative Model Updates: 51,878
Cumulative Timesteps: 432,785,466

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 432785466...
Checkpoint 432785466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,237.08396
Policy Entropy: 3.32552
Value Function Loss: 0.00363

Mean KL Divergence: 0.00630
SB3 Clip Fraction: 0.06986
Policy Update Magnitude: 0.47789
Value Function Update Magnitude: 0.43060

Collected Steps per Second: 21,367.40819
Overall Steps per Second: 10,452.40950

Timestep Collection Time: 2.34104
Timestep Consumption Time: 2.44465
PPO Batch Consumption Time: 0.28170
Total Iteration Time: 4.78569

Cumulative Model Updates: 51,884
Cumulative Timesteps: 432,835,488

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 914.37884
Policy Entropy: 3.32144
Value Function Loss: 0.00362

Mean KL Divergence: 0.00634
SB3 Clip Fraction: 0.07225
Policy Update Magnitude: 0.48343
Value Function Update Magnitude: 0.44105

Collected Steps per Second: 21,300.57011
Overall Steps per Second: 10,396.52328

Timestep Collection Time: 2.34754
Timestep Consumption Time: 2.46214
PPO Batch Consumption Time: 0.28152
Total Iteration Time: 4.80968

Cumulative Model Updates: 51,890
Cumulative Timesteps: 432,885,492

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 432885492...
Checkpoint 432885492 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 841.04879
Policy Entropy: 3.32343
Value Function Loss: 0.00345

Mean KL Divergence: 0.00640
SB3 Clip Fraction: 0.07215
Policy Update Magnitude: 0.48814
Value Function Update Magnitude: 0.44878

Collected Steps per Second: 21,817.40854
Overall Steps per Second: 10,619.98724

Timestep Collection Time: 2.29294
Timestep Consumption Time: 2.41761
PPO Batch Consumption Time: 0.28122
Total Iteration Time: 4.71055

Cumulative Model Updates: 51,896
Cumulative Timesteps: 432,935,518

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,074.29082
Policy Entropy: 3.32401
Value Function Loss: 0.00328

Mean KL Divergence: 0.00691
SB3 Clip Fraction: 0.07689
Policy Update Magnitude: 0.48069
Value Function Update Magnitude: 0.43752

Collected Steps per Second: 22,399.72749
Overall Steps per Second: 10,585.83119

Timestep Collection Time: 2.23226
Timestep Consumption Time: 2.49122
PPO Batch Consumption Time: 0.29194
Total Iteration Time: 4.72348

Cumulative Model Updates: 51,902
Cumulative Timesteps: 432,985,520

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 432985520...
Checkpoint 432985520 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,557.15599
Policy Entropy: 3.33042
Value Function Loss: 0.00309

Mean KL Divergence: 0.00714
SB3 Clip Fraction: 0.07822
Policy Update Magnitude: 0.46826
Value Function Update Magnitude: 0.42944

Collected Steps per Second: 22,761.58590
Overall Steps per Second: 10,636.88701

Timestep Collection Time: 2.19774
Timestep Consumption Time: 2.50514
PPO Batch Consumption Time: 0.29165
Total Iteration Time: 4.70288

Cumulative Model Updates: 51,908
Cumulative Timesteps: 433,035,544

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,429.03711
Policy Entropy: 3.33180
Value Function Loss: 0.00310

Mean KL Divergence: 0.00691
SB3 Clip Fraction: 0.07813
Policy Update Magnitude: 0.46044
Value Function Update Magnitude: 0.41789

Collected Steps per Second: 22,679.42928
Overall Steps per Second: 10,553.07477

Timestep Collection Time: 2.20596
Timestep Consumption Time: 2.53483
PPO Batch Consumption Time: 0.29169
Total Iteration Time: 4.74080

Cumulative Model Updates: 51,914
Cumulative Timesteps: 433,085,574

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 433085574...
Checkpoint 433085574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,396.14523
Policy Entropy: 3.33337
Value Function Loss: 0.00317

Mean KL Divergence: 0.00635
SB3 Clip Fraction: 0.07185
Policy Update Magnitude: 0.45977
Value Function Update Magnitude: 0.40913

Collected Steps per Second: 22,458.68528
Overall Steps per Second: 10,546.32490

Timestep Collection Time: 2.22649
Timestep Consumption Time: 2.51488
PPO Batch Consumption Time: 0.29442
Total Iteration Time: 4.74137

Cumulative Model Updates: 51,920
Cumulative Timesteps: 433,135,578

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 754.13403
Policy Entropy: 3.32473
Value Function Loss: 0.00344

Mean KL Divergence: 0.00670
SB3 Clip Fraction: 0.07422
Policy Update Magnitude: 0.46967
Value Function Update Magnitude: 0.42961

Collected Steps per Second: 22,529.51728
Overall Steps per Second: 10,569.12086

Timestep Collection Time: 2.21949
Timestep Consumption Time: 2.51165
PPO Batch Consumption Time: 0.29230
Total Iteration Time: 4.73114

Cumulative Model Updates: 51,926
Cumulative Timesteps: 433,185,582

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 433185582...
Checkpoint 433185582 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 807.88304
Policy Entropy: 3.33256
Value Function Loss: 0.00342

Mean KL Divergence: 0.00623
SB3 Clip Fraction: 0.07021
Policy Update Magnitude: 0.48142
Value Function Update Magnitude: 0.45077

Collected Steps per Second: 22,301.49304
Overall Steps per Second: 10,602.29451

Timestep Collection Time: 2.24317
Timestep Consumption Time: 2.47524
PPO Batch Consumption Time: 0.29571
Total Iteration Time: 4.71841

Cumulative Model Updates: 51,932
Cumulative Timesteps: 433,235,608

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,415.23451
Policy Entropy: 3.33781
Value Function Loss: 0.00347

Mean KL Divergence: 0.00694
SB3 Clip Fraction: 0.07802
Policy Update Magnitude: 0.48093
Value Function Update Magnitude: 0.44150

Collected Steps per Second: 22,610.21383
Overall Steps per Second: 10,770.76923

Timestep Collection Time: 2.21192
Timestep Consumption Time: 2.43139
PPO Batch Consumption Time: 0.28225
Total Iteration Time: 4.64331

Cumulative Model Updates: 51,938
Cumulative Timesteps: 433,285,620

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 433285620...
Checkpoint 433285620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 991.80390
Policy Entropy: 3.34951
Value Function Loss: 0.00351

Mean KL Divergence: 0.00772
SB3 Clip Fraction: 0.08451
Policy Update Magnitude: 0.47998
Value Function Update Magnitude: 0.44705

Collected Steps per Second: 22,268.63970
Overall Steps per Second: 10,646.65943

Timestep Collection Time: 2.24657
Timestep Consumption Time: 2.45237
PPO Batch Consumption Time: 0.28645
Total Iteration Time: 4.69894

Cumulative Model Updates: 51,944
Cumulative Timesteps: 433,335,648

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,067.23997
Policy Entropy: 3.34345
Value Function Loss: 0.00344

Mean KL Divergence: 0.00738
SB3 Clip Fraction: 0.08309
Policy Update Magnitude: 0.48268
Value Function Update Magnitude: 0.46377

Collected Steps per Second: 22,139.42643
Overall Steps per Second: 10,521.10867

Timestep Collection Time: 2.25959
Timestep Consumption Time: 2.49523
PPO Batch Consumption Time: 0.29476
Total Iteration Time: 4.75482

Cumulative Model Updates: 51,950
Cumulative Timesteps: 433,385,674

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 433385674...
Checkpoint 433385674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 854.28313
Policy Entropy: 3.35906
Value Function Loss: 0.00321

Mean KL Divergence: 0.00753
SB3 Clip Fraction: 0.08100
Policy Update Magnitude: 0.47948
Value Function Update Magnitude: 0.45986

Collected Steps per Second: 22,289.50935
Overall Steps per Second: 10,607.79474

Timestep Collection Time: 2.24402
Timestep Consumption Time: 2.47120
PPO Batch Consumption Time: 0.29087
Total Iteration Time: 4.71521

Cumulative Model Updates: 51,956
Cumulative Timesteps: 433,435,692

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,029.51736
Policy Entropy: 3.37023
Value Function Loss: 0.00318

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.09358
Policy Update Magnitude: 0.46290
Value Function Update Magnitude: 0.43895

Collected Steps per Second: 22,417.39048
Overall Steps per Second: 10,623.06630

Timestep Collection Time: 2.23175
Timestep Consumption Time: 2.47781
PPO Batch Consumption Time: 0.29051
Total Iteration Time: 4.70956

Cumulative Model Updates: 51,962
Cumulative Timesteps: 433,485,722

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 433485722...
Checkpoint 433485722 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,122.29217
Policy Entropy: 3.37773
Value Function Loss: 0.00338

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.08661
Policy Update Magnitude: 0.46403
Value Function Update Magnitude: 0.43651

Collected Steps per Second: 22,209.93074
Overall Steps per Second: 10,523.56747

Timestep Collection Time: 2.25179
Timestep Consumption Time: 2.50060
PPO Batch Consumption Time: 0.29447
Total Iteration Time: 4.75238

Cumulative Model Updates: 51,968
Cumulative Timesteps: 433,535,734

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,384.99209
Policy Entropy: 3.36138
Value Function Loss: 0.00330

Mean KL Divergence: 0.00751
SB3 Clip Fraction: 0.08544
Policy Update Magnitude: 0.46854
Value Function Update Magnitude: 0.43625

Collected Steps per Second: 22,908.75200
Overall Steps per Second: 10,785.80474

Timestep Collection Time: 2.18345
Timestep Consumption Time: 2.45413
PPO Batch Consumption Time: 0.28173
Total Iteration Time: 4.63758

Cumulative Model Updates: 51,974
Cumulative Timesteps: 433,585,754

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 433585754...
Checkpoint 433585754 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 911.56590
Policy Entropy: 3.35400
Value Function Loss: 0.00328

Mean KL Divergence: 0.00749
SB3 Clip Fraction: 0.08361
Policy Update Magnitude: 0.46593
Value Function Update Magnitude: 0.44741

Collected Steps per Second: 22,476.46785
Overall Steps per Second: 10,654.70546

Timestep Collection Time: 2.22464
Timestep Consumption Time: 2.46831
PPO Batch Consumption Time: 0.29006
Total Iteration Time: 4.69295

Cumulative Model Updates: 51,980
Cumulative Timesteps: 433,635,756

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 777.87630
Policy Entropy: 3.34581
Value Function Loss: 0.00325

Mean KL Divergence: 0.00740
SB3 Clip Fraction: 0.08054
Policy Update Magnitude: 0.46159
Value Function Update Magnitude: 0.44231

Collected Steps per Second: 22,840.82485
Overall Steps per Second: 10,633.02864

Timestep Collection Time: 2.18906
Timestep Consumption Time: 2.51327
PPO Batch Consumption Time: 0.29231
Total Iteration Time: 4.70233

Cumulative Model Updates: 51,986
Cumulative Timesteps: 433,685,756

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 433685756...
Checkpoint 433685756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 835.89957
Policy Entropy: 3.37163
Value Function Loss: 0.00350

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.08430
Policy Update Magnitude: 0.46863
Value Function Update Magnitude: 0.44090

Collected Steps per Second: 22,061.85355
Overall Steps per Second: 10,476.16582

Timestep Collection Time: 2.26726
Timestep Consumption Time: 2.50739
PPO Batch Consumption Time: 0.28928
Total Iteration Time: 4.77465

Cumulative Model Updates: 51,992
Cumulative Timesteps: 433,735,776

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,245.65209
Policy Entropy: 3.36240
Value Function Loss: 0.00363

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.09505
Policy Update Magnitude: 0.48072
Value Function Update Magnitude: 0.44971

Collected Steps per Second: 22,753.32833
Overall Steps per Second: 10,840.92559

Timestep Collection Time: 2.19818
Timestep Consumption Time: 2.41544
PPO Batch Consumption Time: 0.28104
Total Iteration Time: 4.61363

Cumulative Model Updates: 51,998
Cumulative Timesteps: 433,785,792

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 433785792...
Checkpoint 433785792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,110.86631
Policy Entropy: 3.38017
Value Function Loss: 0.00355

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.10134
Policy Update Magnitude: 0.48471
Value Function Update Magnitude: 0.45662

Collected Steps per Second: 22,322.21041
Overall Steps per Second: 10,769.33264

Timestep Collection Time: 2.24118
Timestep Consumption Time: 2.40424
PPO Batch Consumption Time: 0.27944
Total Iteration Time: 4.64541

Cumulative Model Updates: 52,004
Cumulative Timesteps: 433,835,820

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,699.69854
Policy Entropy: 3.36846
Value Function Loss: 0.00346

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.10721
Policy Update Magnitude: 0.47911
Value Function Update Magnitude: 0.47512

Collected Steps per Second: 21,227.16406
Overall Steps per Second: 10,302.43687

Timestep Collection Time: 2.35576
Timestep Consumption Time: 2.49805
PPO Batch Consumption Time: 0.28443
Total Iteration Time: 4.85380

Cumulative Model Updates: 52,010
Cumulative Timesteps: 433,885,826

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 433885826...
Checkpoint 433885826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,650.54735
Policy Entropy: 3.36958
Value Function Loss: 0.00347

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.10477
Policy Update Magnitude: 0.47256
Value Function Update Magnitude: 0.47676

Collected Steps per Second: 21,549.16187
Overall Steps per Second: 10,315.11471

Timestep Collection Time: 2.32065
Timestep Consumption Time: 2.52738
PPO Batch Consumption Time: 0.29578
Total Iteration Time: 4.84803

Cumulative Model Updates: 52,016
Cumulative Timesteps: 433,935,834

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,237.26042
Policy Entropy: 3.35642
Value Function Loss: 0.00352

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.10281
Policy Update Magnitude: 0.47224
Value Function Update Magnitude: 0.47916

Collected Steps per Second: 22,437.36911
Overall Steps per Second: 10,522.78471

Timestep Collection Time: 2.22949
Timestep Consumption Time: 2.52438
PPO Batch Consumption Time: 0.29474
Total Iteration Time: 4.75387

Cumulative Model Updates: 52,022
Cumulative Timesteps: 433,985,858

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 433985858...
Checkpoint 433985858 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,411.11141
Policy Entropy: 3.35846
Value Function Loss: 0.00357

Mean KL Divergence: 0.00741
SB3 Clip Fraction: 0.08172
Policy Update Magnitude: 0.48159
Value Function Update Magnitude: 0.48237

Collected Steps per Second: 22,378.05304
Overall Steps per Second: 10,618.84167

Timestep Collection Time: 2.23433
Timestep Consumption Time: 2.47428
PPO Batch Consumption Time: 0.29107
Total Iteration Time: 4.70861

Cumulative Model Updates: 52,028
Cumulative Timesteps: 434,035,858

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,709.05429
Policy Entropy: 3.37240
Value Function Loss: 0.00336

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.09089
Policy Update Magnitude: 0.49629
Value Function Update Magnitude: 0.50630

Collected Steps per Second: 22,516.05100
Overall Steps per Second: 10,545.85943

Timestep Collection Time: 2.22179
Timestep Consumption Time: 2.52187
PPO Batch Consumption Time: 0.29276
Total Iteration Time: 4.74366

Cumulative Model Updates: 52,034
Cumulative Timesteps: 434,085,884

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 434085884...
Checkpoint 434085884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,069.82062
Policy Entropy: 3.36387
Value Function Loss: 0.00315

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.09761
Policy Update Magnitude: 0.47684
Value Function Update Magnitude: 0.47239

Collected Steps per Second: 22,296.38699
Overall Steps per Second: 10,557.66558

Timestep Collection Time: 2.24323
Timestep Consumption Time: 2.49418
PPO Batch Consumption Time: 0.29476
Total Iteration Time: 4.73741

Cumulative Model Updates: 52,040
Cumulative Timesteps: 434,135,900

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,210.10818
Policy Entropy: 3.36774
Value Function Loss: 0.00300

Mean KL Divergence: 0.00669
SB3 Clip Fraction: 0.07515
Policy Update Magnitude: 0.46466
Value Function Update Magnitude: 0.44134

Collected Steps per Second: 22,823.55330
Overall Steps per Second: 10,769.83913

Timestep Collection Time: 2.19116
Timestep Consumption Time: 2.45237
PPO Batch Consumption Time: 0.28170
Total Iteration Time: 4.64352

Cumulative Model Updates: 52,046
Cumulative Timesteps: 434,185,910

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 434185910...
Checkpoint 434185910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,373.64679
Policy Entropy: 3.37169
Value Function Loss: 0.00301

Mean KL Divergence: 0.00571
SB3 Clip Fraction: 0.06411
Policy Update Magnitude: 0.46480
Value Function Update Magnitude: 0.43228

Collected Steps per Second: 21,479.79767
Overall Steps per Second: 10,408.36092

Timestep Collection Time: 2.32805
Timestep Consumption Time: 2.47636
PPO Batch Consumption Time: 0.29353
Total Iteration Time: 4.80441

Cumulative Model Updates: 52,052
Cumulative Timesteps: 434,235,916

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,337.94573
Policy Entropy: 3.35978
Value Function Loss: 0.00309

Mean KL Divergence: 0.00616
SB3 Clip Fraction: 0.06890
Policy Update Magnitude: 0.47130
Value Function Update Magnitude: 0.42751

Collected Steps per Second: 22,571.58733
Overall Steps per Second: 10,756.35560

Timestep Collection Time: 2.21526
Timestep Consumption Time: 2.43334
PPO Batch Consumption Time: 0.28086
Total Iteration Time: 4.64860

Cumulative Model Updates: 52,058
Cumulative Timesteps: 434,285,918

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 434285918...
Checkpoint 434285918 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,754.79167
Policy Entropy: 3.36030
Value Function Loss: 0.00325

Mean KL Divergence: 0.00619
SB3 Clip Fraction: 0.06926
Policy Update Magnitude: 0.48000
Value Function Update Magnitude: 0.43384

Collected Steps per Second: 22,028.65170
Overall Steps per Second: 10,672.93850

Timestep Collection Time: 2.27013
Timestep Consumption Time: 2.41536
PPO Batch Consumption Time: 0.28025
Total Iteration Time: 4.68549

Cumulative Model Updates: 52,064
Cumulative Timesteps: 434,335,926

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,411.24424
Policy Entropy: 3.34565
Value Function Loss: 0.00334

Mean KL Divergence: 0.00722
SB3 Clip Fraction: 0.07980
Policy Update Magnitude: 0.48854
Value Function Update Magnitude: 0.43888

Collected Steps per Second: 22,792.00617
Overall Steps per Second: 10,686.09832

Timestep Collection Time: 2.19445
Timestep Consumption Time: 2.48602
PPO Batch Consumption Time: 0.28916
Total Iteration Time: 4.68047

Cumulative Model Updates: 52,070
Cumulative Timesteps: 434,385,942

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 434385942...
Checkpoint 434385942 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 768.12437
Policy Entropy: 3.35223
Value Function Loss: 0.00331

Mean KL Divergence: 0.00703
SB3 Clip Fraction: 0.07740
Policy Update Magnitude: 0.48573
Value Function Update Magnitude: 0.44041

Collected Steps per Second: 22,592.45968
Overall Steps per Second: 10,759.58102

Timestep Collection Time: 2.21357
Timestep Consumption Time: 2.43438
PPO Batch Consumption Time: 0.28071
Total Iteration Time: 4.64795

Cumulative Model Updates: 52,076
Cumulative Timesteps: 434,435,952

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 860.53833
Policy Entropy: 3.35227
Value Function Loss: 0.00324

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.08312
Policy Update Magnitude: 0.48749
Value Function Update Magnitude: 0.43425

Collected Steps per Second: 22,760.00776
Overall Steps per Second: 10,686.36975

Timestep Collection Time: 2.19719
Timestep Consumption Time: 2.48242
PPO Batch Consumption Time: 0.29204
Total Iteration Time: 4.67961

Cumulative Model Updates: 52,082
Cumulative Timesteps: 434,485,960

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 434485960...
Checkpoint 434485960 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,309.91880
Policy Entropy: 3.36252
Value Function Loss: 0.00328

Mean KL Divergence: 0.00680
SB3 Clip Fraction: 0.07539
Policy Update Magnitude: 0.48562
Value Function Update Magnitude: 0.43641

Collected Steps per Second: 22,771.80104
Overall Steps per Second: 10,457.81616

Timestep Collection Time: 2.19605
Timestep Consumption Time: 2.58583
PPO Batch Consumption Time: 0.30784
Total Iteration Time: 4.78188

Cumulative Model Updates: 52,088
Cumulative Timesteps: 434,535,968

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,816.97931
Policy Entropy: 3.36542
Value Function Loss: 0.00326

Mean KL Divergence: 0.00722
SB3 Clip Fraction: 0.08037
Policy Update Magnitude: 0.49221
Value Function Update Magnitude: 0.44031

Collected Steps per Second: 22,613.07487
Overall Steps per Second: 10,639.80019

Timestep Collection Time: 2.21235
Timestep Consumption Time: 2.48962
PPO Batch Consumption Time: 0.29244
Total Iteration Time: 4.70197

Cumulative Model Updates: 52,094
Cumulative Timesteps: 434,585,996

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 434585996...
Checkpoint 434585996 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,791.66013
Policy Entropy: 3.36075
Value Function Loss: 0.00319

Mean KL Divergence: 0.00747
SB3 Clip Fraction: 0.08229
Policy Update Magnitude: 0.49095
Value Function Update Magnitude: 0.44488

Collected Steps per Second: 22,876.05656
Overall Steps per Second: 10,889.29954

Timestep Collection Time: 2.18665
Timestep Consumption Time: 2.40703
PPO Batch Consumption Time: 0.28079
Total Iteration Time: 4.59368

Cumulative Model Updates: 52,100
Cumulative Timesteps: 434,636,018

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,346.76858
Policy Entropy: 3.34587
Value Function Loss: 0.00313

Mean KL Divergence: 0.00677
SB3 Clip Fraction: 0.07688
Policy Update Magnitude: 0.49532
Value Function Update Magnitude: 0.42756

Collected Steps per Second: 22,634.85413
Overall Steps per Second: 10,656.07300

Timestep Collection Time: 2.20995
Timestep Consumption Time: 2.48427
PPO Batch Consumption Time: 0.29479
Total Iteration Time: 4.69422

Cumulative Model Updates: 52,106
Cumulative Timesteps: 434,686,040

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 434686040...
Checkpoint 434686040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 996.98005
Policy Entropy: 3.33827
Value Function Loss: 0.00314

Mean KL Divergence: 0.00723
SB3 Clip Fraction: 0.08212
Policy Update Magnitude: 0.49372
Value Function Update Magnitude: 0.41155

Collected Steps per Second: 21,815.62676
Overall Steps per Second: 10,590.23726

Timestep Collection Time: 2.29221
Timestep Consumption Time: 2.42969
PPO Batch Consumption Time: 0.27956
Total Iteration Time: 4.72190

Cumulative Model Updates: 52,112
Cumulative Timesteps: 434,736,046

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 864.61135
Policy Entropy: 3.33525
Value Function Loss: 0.00334

Mean KL Divergence: 0.00672
SB3 Clip Fraction: 0.07762
Policy Update Magnitude: 0.49760
Value Function Update Magnitude: 0.40960

Collected Steps per Second: 22,304.66760
Overall Steps per Second: 10,627.28362

Timestep Collection Time: 2.24240
Timestep Consumption Time: 2.46398
PPO Batch Consumption Time: 0.29087
Total Iteration Time: 4.70638

Cumulative Model Updates: 52,118
Cumulative Timesteps: 434,786,062

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 434786062...
Checkpoint 434786062 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,332.69392
Policy Entropy: 3.34268
Value Function Loss: 0.00341

Mean KL Divergence: 0.00620
SB3 Clip Fraction: 0.06993
Policy Update Magnitude: 0.51075
Value Function Update Magnitude: 0.43100

Collected Steps per Second: 22,269.16858
Overall Steps per Second: 10,634.34061

Timestep Collection Time: 2.24786
Timestep Consumption Time: 2.45934
PPO Batch Consumption Time: 0.28986
Total Iteration Time: 4.70720

Cumulative Model Updates: 52,124
Cumulative Timesteps: 434,836,120

Timesteps Collected: 50,058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,223.49602
Policy Entropy: 3.34290
Value Function Loss: 0.00339

Mean KL Divergence: 0.00616
SB3 Clip Fraction: 0.06997
Policy Update Magnitude: 0.51294
Value Function Update Magnitude: 0.44550

Collected Steps per Second: 22,301.44689
Overall Steps per Second: 10,725.90920

Timestep Collection Time: 2.24246
Timestep Consumption Time: 2.42009
PPO Batch Consumption Time: 0.28007
Total Iteration Time: 4.66254

Cumulative Model Updates: 52,130
Cumulative Timesteps: 434,886,130

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 434886130...
Checkpoint 434886130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,556.17674
Policy Entropy: 3.34400
Value Function Loss: 0.00335

Mean KL Divergence: 0.00590
SB3 Clip Fraction: 0.06552
Policy Update Magnitude: 0.51106
Value Function Update Magnitude: 0.43678

Collected Steps per Second: 22,274.41796
Overall Steps per Second: 10,612.89827

Timestep Collection Time: 2.24527
Timestep Consumption Time: 2.46711
PPO Batch Consumption Time: 0.28728
Total Iteration Time: 4.71238

Cumulative Model Updates: 52,136
Cumulative Timesteps: 434,936,142

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 973.75150
Policy Entropy: 3.34133
Value Function Loss: 0.00324

Mean KL Divergence: 0.00701
SB3 Clip Fraction: 0.07740
Policy Update Magnitude: 0.51176
Value Function Update Magnitude: 0.43161

Collected Steps per Second: 22,794.13503
Overall Steps per Second: 10,537.52632

Timestep Collection Time: 2.19478
Timestep Consumption Time: 2.55283
PPO Batch Consumption Time: 0.29353
Total Iteration Time: 4.74760

Cumulative Model Updates: 52,142
Cumulative Timesteps: 434,986,170

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 434986170...
Checkpoint 434986170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,434.09562
Policy Entropy: 3.33667
Value Function Loss: 0.00326

Mean KL Divergence: 0.00734
SB3 Clip Fraction: 0.08420
Policy Update Magnitude: 0.51115
Value Function Update Magnitude: 0.43236

Collected Steps per Second: 22,723.48346
Overall Steps per Second: 10,564.09270

Timestep Collection Time: 2.20239
Timestep Consumption Time: 2.53498
PPO Batch Consumption Time: 0.29473
Total Iteration Time: 4.73737

Cumulative Model Updates: 52,148
Cumulative Timesteps: 435,036,216

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,104.54826
Policy Entropy: 3.33203
Value Function Loss: 0.00316

Mean KL Divergence: 0.00734
SB3 Clip Fraction: 0.08302
Policy Update Magnitude: 0.50481
Value Function Update Magnitude: 0.44033

Collected Steps per Second: 22,645.32019
Overall Steps per Second: 10,665.26112

Timestep Collection Time: 2.20884
Timestep Consumption Time: 2.48115
PPO Batch Consumption Time: 0.29104
Total Iteration Time: 4.68999

Cumulative Model Updates: 52,154
Cumulative Timesteps: 435,086,236

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 435086236...
Checkpoint 435086236 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,003.57736
Policy Entropy: 3.33670
Value Function Loss: 0.00294

Mean KL Divergence: 0.00700
SB3 Clip Fraction: 0.07959
Policy Update Magnitude: 0.49667
Value Function Update Magnitude: 0.43401

Collected Steps per Second: 22,869.29837
Overall Steps per Second: 10,869.83656

Timestep Collection Time: 2.18765
Timestep Consumption Time: 2.41500
PPO Batch Consumption Time: 0.28172
Total Iteration Time: 4.60265

Cumulative Model Updates: 52,160
Cumulative Timesteps: 435,136,266

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,035.26618
Policy Entropy: 3.33266
Value Function Loss: 0.00294

Mean KL Divergence: 0.00662
SB3 Clip Fraction: 0.07446
Policy Update Magnitude: 0.48700
Value Function Update Magnitude: 0.40795

Collected Steps per Second: 22,989.52554
Overall Steps per Second: 10,821.77429

Timestep Collection Time: 2.17534
Timestep Consumption Time: 2.44590
PPO Batch Consumption Time: 0.28516
Total Iteration Time: 4.62124

Cumulative Model Updates: 52,166
Cumulative Timesteps: 435,186,276

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 435186276...
Checkpoint 435186276 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,693.36707
Policy Entropy: 3.34536
Value Function Loss: 0.00299

Mean KL Divergence: 0.00579
SB3 Clip Fraction: 0.06485
Policy Update Magnitude: 0.48715
Value Function Update Magnitude: 0.40976

Collected Steps per Second: 22,472.69372
Overall Steps per Second: 10,595.81490

Timestep Collection Time: 2.22537
Timestep Consumption Time: 2.49442
PPO Batch Consumption Time: 0.29675
Total Iteration Time: 4.71979

Cumulative Model Updates: 52,172
Cumulative Timesteps: 435,236,286

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,148.08043
Policy Entropy: 3.34920
Value Function Loss: 0.00311

Mean KL Divergence: 0.00694
SB3 Clip Fraction: 0.07732
Policy Update Magnitude: 0.49331
Value Function Update Magnitude: 0.41932

Collected Steps per Second: 22,514.19935
Overall Steps per Second: 10,613.06799

Timestep Collection Time: 2.22109
Timestep Consumption Time: 2.49065
PPO Batch Consumption Time: 0.28873
Total Iteration Time: 4.71174

Cumulative Model Updates: 52,178
Cumulative Timesteps: 435,286,292

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 435286292...
Checkpoint 435286292 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 776.94446
Policy Entropy: 3.34449
Value Function Loss: 0.00311

Mean KL Divergence: 0.00716
SB3 Clip Fraction: 0.08080
Policy Update Magnitude: 0.49061
Value Function Update Magnitude: 0.42476

Collected Steps per Second: 21,930.82063
Overall Steps per Second: 10,588.97518

Timestep Collection Time: 2.28090
Timestep Consumption Time: 2.44307
PPO Batch Consumption Time: 0.28083
Total Iteration Time: 4.72397

Cumulative Model Updates: 52,184
Cumulative Timesteps: 435,336,314

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,029.76150
Policy Entropy: 3.35456
Value Function Loss: 0.00327

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.10281
Policy Update Magnitude: 0.48293
Value Function Update Magnitude: 0.42316

Collected Steps per Second: 22,330.78133
Overall Steps per Second: 10,592.59949

Timestep Collection Time: 2.24032
Timestep Consumption Time: 2.48260
PPO Batch Consumption Time: 0.29484
Total Iteration Time: 4.72292

Cumulative Model Updates: 52,190
Cumulative Timesteps: 435,386,342

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 435386342...
Checkpoint 435386342 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,352.19145
Policy Entropy: 3.34832
Value Function Loss: 0.00349

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.09045
Policy Update Magnitude: 0.49055
Value Function Update Magnitude: 0.42741

Collected Steps per Second: 22,360.93215
Overall Steps per Second: 10,574.13344

Timestep Collection Time: 2.23810
Timestep Consumption Time: 2.49477
PPO Batch Consumption Time: 0.29509
Total Iteration Time: 4.73287

Cumulative Model Updates: 52,196
Cumulative Timesteps: 435,436,388

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,395.30620
Policy Entropy: 3.35102
Value Function Loss: 0.00356

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.09737
Policy Update Magnitude: 0.50406
Value Function Update Magnitude: 0.43344

Collected Steps per Second: 22,911.31849
Overall Steps per Second: 10,637.32288

Timestep Collection Time: 2.18338
Timestep Consumption Time: 2.51931
PPO Batch Consumption Time: 0.29058
Total Iteration Time: 4.70269

Cumulative Model Updates: 52,202
Cumulative Timesteps: 435,486,412

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 435486412...
Checkpoint 435486412 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,524.62818
Policy Entropy: 3.34707
Value Function Loss: 0.00338

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.09254
Policy Update Magnitude: 0.50420
Value Function Update Magnitude: 0.43599

Collected Steps per Second: 22,764.38705
Overall Steps per Second: 10,837.22750

Timestep Collection Time: 2.19720
Timestep Consumption Time: 2.41818
PPO Batch Consumption Time: 0.28112
Total Iteration Time: 4.61539

Cumulative Model Updates: 52,208
Cumulative Timesteps: 435,536,430

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,561.76942
Policy Entropy: 3.34714
Value Function Loss: 0.00330

Mean KL Divergence: 0.00633
SB3 Clip Fraction: 0.07000
Policy Update Magnitude: 0.50721
Value Function Update Magnitude: 0.40988

Collected Steps per Second: 22,627.30551
Overall Steps per Second: 10,684.15963

Timestep Collection Time: 2.21034
Timestep Consumption Time: 2.47080
PPO Batch Consumption Time: 0.29269
Total Iteration Time: 4.68114

Cumulative Model Updates: 52,214
Cumulative Timesteps: 435,586,444

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 435586444...
Checkpoint 435586444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,536.72755
Policy Entropy: 3.34620
Value Function Loss: 0.00314

Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.09111
Policy Update Magnitude: 0.50452
Value Function Update Magnitude: 0.39837

Collected Steps per Second: 22,559.27616
Overall Steps per Second: 10,703.74480

Timestep Collection Time: 2.21771
Timestep Consumption Time: 2.45635
PPO Batch Consumption Time: 0.28964
Total Iteration Time: 4.67407

Cumulative Model Updates: 52,220
Cumulative Timesteps: 435,636,474

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,096.27737
Policy Entropy: 3.33846
Value Function Loss: 0.00337

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.09600
Policy Update Magnitude: 0.49498
Value Function Update Magnitude: 0.39617

Collected Steps per Second: 22,787.92300
Overall Steps per Second: 10,657.25490

Timestep Collection Time: 2.19537
Timestep Consumption Time: 2.49889
PPO Batch Consumption Time: 0.29423
Total Iteration Time: 4.69427

Cumulative Model Updates: 52,226
Cumulative Timesteps: 435,686,502

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 435686502...
Checkpoint 435686502 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 963.60896
Policy Entropy: 3.32674
Value Function Loss: 0.00330

Mean KL Divergence: 0.00641
SB3 Clip Fraction: 0.07294
Policy Update Magnitude: 0.49880
Value Function Update Magnitude: 0.40461

Collected Steps per Second: 22,552.84115
Overall Steps per Second: 10,655.53772

Timestep Collection Time: 2.21826
Timestep Consumption Time: 2.47677
PPO Batch Consumption Time: 0.29342
Total Iteration Time: 4.69502

Cumulative Model Updates: 52,232
Cumulative Timesteps: 435,736,530

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,610.53931
Policy Entropy: 3.31692
Value Function Loss: 0.00323

Mean KL Divergence: 0.00658
SB3 Clip Fraction: 0.07564
Policy Update Magnitude: 0.50148
Value Function Update Magnitude: 0.42119

Collected Steps per Second: 22,073.73709
Overall Steps per Second: 10,531.03089

Timestep Collection Time: 2.26595
Timestep Consumption Time: 2.48363
PPO Batch Consumption Time: 0.29482
Total Iteration Time: 4.74958

Cumulative Model Updates: 52,238
Cumulative Timesteps: 435,786,548

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 435786548...
Checkpoint 435786548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,271.78259
Policy Entropy: 3.31194
Value Function Loss: 0.00321

Mean KL Divergence: 0.00690
SB3 Clip Fraction: 0.07812
Policy Update Magnitude: 0.49448
Value Function Update Magnitude: 0.41486

Collected Steps per Second: 22,369.46846
Overall Steps per Second: 10,560.01817

Timestep Collection Time: 2.23573
Timestep Consumption Time: 2.50025
PPO Batch Consumption Time: 0.29376
Total Iteration Time: 4.73598

Cumulative Model Updates: 52,244
Cumulative Timesteps: 435,836,560

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,275.64152
Policy Entropy: 3.30858
Value Function Loss: 0.00344

Mean KL Divergence: 0.00680
SB3 Clip Fraction: 0.07647
Policy Update Magnitude: 0.49519
Value Function Update Magnitude: 0.41055

Collected Steps per Second: 21,877.76495
Overall Steps per Second: 10,386.84487

Timestep Collection Time: 2.28643
Timestep Consumption Time: 2.52947
PPO Batch Consumption Time: 0.29801
Total Iteration Time: 4.81590

Cumulative Model Updates: 52,250
Cumulative Timesteps: 435,886,582

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 435886582...
Checkpoint 435886582 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,146.03504
Policy Entropy: 3.32079
Value Function Loss: 0.00351

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.09125
Policy Update Magnitude: 0.50176
Value Function Update Magnitude: 0.41799

Collected Steps per Second: 22,190.60233
Overall Steps per Second: 10,668.35484

Timestep Collection Time: 2.25456
Timestep Consumption Time: 2.43501
PPO Batch Consumption Time: 0.28102
Total Iteration Time: 4.68957

Cumulative Model Updates: 52,256
Cumulative Timesteps: 435,936,612

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 818.00074
Policy Entropy: 3.32246
Value Function Loss: 0.00341

Mean KL Divergence: 0.01168
SB3 Clip Fraction: 0.11734
Policy Update Magnitude: 0.49380
Value Function Update Magnitude: 0.42217

Collected Steps per Second: 22,668.44763
Overall Steps per Second: 10,602.91737

Timestep Collection Time: 2.20712
Timestep Consumption Time: 2.51158
PPO Batch Consumption Time: 0.29450
Total Iteration Time: 4.71870

Cumulative Model Updates: 52,262
Cumulative Timesteps: 435,986,644

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 435986644...
Checkpoint 435986644 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,619.01810
Policy Entropy: 3.34183
Value Function Loss: 0.00322

Mean KL Divergence: 0.01175
SB3 Clip Fraction: 0.12127
Policy Update Magnitude: 0.49010
Value Function Update Magnitude: 0.41512

Collected Steps per Second: 22,704.20427
Overall Steps per Second: 10,665.47529

Timestep Collection Time: 2.20303
Timestep Consumption Time: 2.48668
PPO Batch Consumption Time: 0.29233
Total Iteration Time: 4.68971

Cumulative Model Updates: 52,268
Cumulative Timesteps: 436,036,662

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 994.68741
Policy Entropy: 3.32566
Value Function Loss: 0.00314

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.10550
Policy Update Magnitude: 0.48471
Value Function Update Magnitude: 0.42246

Collected Steps per Second: 22,853.99318
Overall Steps per Second: 10,770.46218

Timestep Collection Time: 2.18798
Timestep Consumption Time: 2.45472
PPO Batch Consumption Time: 0.28680
Total Iteration Time: 4.64270

Cumulative Model Updates: 52,274
Cumulative Timesteps: 436,086,666

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 436086666...
Checkpoint 436086666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,605.32842
Policy Entropy: 3.32865
Value Function Loss: 0.00326

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.09223
Policy Update Magnitude: 0.49009
Value Function Update Magnitude: 0.43091

Collected Steps per Second: 21,705.87357
Overall Steps per Second: 10,566.36172

Timestep Collection Time: 2.30472
Timestep Consumption Time: 2.42974
PPO Batch Consumption Time: 0.28137
Total Iteration Time: 4.73446

Cumulative Model Updates: 52,280
Cumulative Timesteps: 436,136,692

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,181.06363
Policy Entropy: 3.32906
Value Function Loss: 0.00324

Mean KL Divergence: 0.00689
SB3 Clip Fraction: 0.07799
Policy Update Magnitude: 0.49181
Value Function Update Magnitude: 0.42884

Collected Steps per Second: 22,877.01946
Overall Steps per Second: 10,669.04197

Timestep Collection Time: 2.18560
Timestep Consumption Time: 2.50086
PPO Batch Consumption Time: 0.29421
Total Iteration Time: 4.68646

Cumulative Model Updates: 52,286
Cumulative Timesteps: 436,186,692

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 436186692...
Checkpoint 436186692 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,308.86778
Policy Entropy: 3.32222
Value Function Loss: 0.00336

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.09215
Policy Update Magnitude: 0.49172
Value Function Update Magnitude: 0.42973

Collected Steps per Second: 22,873.24730
Overall Steps per Second: 10,687.73265

Timestep Collection Time: 2.18701
Timestep Consumption Time: 2.49350
PPO Batch Consumption Time: 0.29073
Total Iteration Time: 4.68051

Cumulative Model Updates: 52,292
Cumulative Timesteps: 436,236,716

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,372.73751
Policy Entropy: 3.33712
Value Function Loss: 0.00337

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.10103
Policy Update Magnitude: 0.49924
Value Function Update Magnitude: 0.44798

Collected Steps per Second: 21,887.04170
Overall Steps per Second: 10,644.40818

Timestep Collection Time: 2.28464
Timestep Consumption Time: 2.41304
PPO Batch Consumption Time: 0.27984
Total Iteration Time: 4.69768

Cumulative Model Updates: 52,298
Cumulative Timesteps: 436,286,720

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 436286720...
Checkpoint 436286720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,631.36284
Policy Entropy: 3.35238
Value Function Loss: 0.00343

Mean KL Divergence: 0.01377
SB3 Clip Fraction: 0.13111
Policy Update Magnitude: 0.49600
Value Function Update Magnitude: 0.46165

Collected Steps per Second: 22,017.38941
Overall Steps per Second: 10,638.69430

Timestep Collection Time: 2.27175
Timestep Consumption Time: 2.42977
PPO Batch Consumption Time: 0.28048
Total Iteration Time: 4.70152

Cumulative Model Updates: 52,304
Cumulative Timesteps: 436,336,738

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,148.85223
Policy Entropy: 3.35586
Value Function Loss: 0.00348

Mean KL Divergence: 0.01200
SB3 Clip Fraction: 0.12337
Policy Update Magnitude: 0.49628
Value Function Update Magnitude: 0.45761

Collected Steps per Second: 22,192.54522
Overall Steps per Second: 10,538.17891

Timestep Collection Time: 2.25427
Timestep Consumption Time: 2.49304
PPO Batch Consumption Time: 0.29540
Total Iteration Time: 4.74731

Cumulative Model Updates: 52,310
Cumulative Timesteps: 436,386,766

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 436386766...
Checkpoint 436386766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,203.09979
Policy Entropy: 3.33652
Value Function Loss: 0.00343

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.10902
Policy Update Magnitude: 0.50035
Value Function Update Magnitude: 0.46654

Collected Steps per Second: 22,205.35363
Overall Steps per Second: 10,601.66055

Timestep Collection Time: 2.25297
Timestep Consumption Time: 2.46591
PPO Batch Consumption Time: 0.28683
Total Iteration Time: 4.71888

Cumulative Model Updates: 52,316
Cumulative Timesteps: 436,436,794

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 774.60043
Policy Entropy: 3.32590
Value Function Loss: 0.00354

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.09529
Policy Update Magnitude: 0.50420
Value Function Update Magnitude: 0.47734

Collected Steps per Second: 22,130.05839
Overall Steps per Second: 10,533.06952

Timestep Collection Time: 2.25991
Timestep Consumption Time: 2.48818
PPO Batch Consumption Time: 0.29457
Total Iteration Time: 4.74809

Cumulative Model Updates: 52,322
Cumulative Timesteps: 436,486,806

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 436486806...
Checkpoint 436486806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,658.49055
Policy Entropy: 3.33156
Value Function Loss: 0.00338

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.08690
Policy Update Magnitude: 0.50575
Value Function Update Magnitude: 0.46215

Collected Steps per Second: 22,319.72119
Overall Steps per Second: 10,629.08413

Timestep Collection Time: 2.24080
Timestep Consumption Time: 2.46459
PPO Batch Consumption Time: 0.28477
Total Iteration Time: 4.70539

Cumulative Model Updates: 52,328
Cumulative Timesteps: 436,536,820

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,480.02873
Policy Entropy: 3.33428
Value Function Loss: 0.00340

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.08911
Policy Update Magnitude: 0.50949
Value Function Update Magnitude: 0.44911

Collected Steps per Second: 22,232.60186
Overall Steps per Second: 10,559.54682

Timestep Collection Time: 2.24949
Timestep Consumption Time: 2.48670
PPO Batch Consumption Time: 0.29113
Total Iteration Time: 4.73619

Cumulative Model Updates: 52,334
Cumulative Timesteps: 436,586,832

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 436586832...
Checkpoint 436586832 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,036.70116
Policy Entropy: 3.34080
Value Function Loss: 0.00329

Mean KL Divergence: 0.00726
SB3 Clip Fraction: 0.08264
Policy Update Magnitude: 0.50115
Value Function Update Magnitude: 0.44749

Collected Steps per Second: 22,815.58638
Overall Steps per Second: 10,662.31370

Timestep Collection Time: 2.19262
Timestep Consumption Time: 2.49923
PPO Batch Consumption Time: 0.28986
Total Iteration Time: 4.69185

Cumulative Model Updates: 52,340
Cumulative Timesteps: 436,636,858

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,731.20059
Policy Entropy: 3.34852
Value Function Loss: 0.00332

Mean KL Divergence: 0.00620
SB3 Clip Fraction: 0.07067
Policy Update Magnitude: 0.49774
Value Function Update Magnitude: 0.45387

Collected Steps per Second: 22,822.89242
Overall Steps per Second: 10,741.35258

Timestep Collection Time: 2.19192
Timestep Consumption Time: 2.46541
PPO Batch Consumption Time: 0.28952
Total Iteration Time: 4.65733

Cumulative Model Updates: 52,346
Cumulative Timesteps: 436,686,884

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 436686884...
Checkpoint 436686884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,368.33929
Policy Entropy: 3.34567
Value Function Loss: 0.00338

Mean KL Divergence: 0.00665
SB3 Clip Fraction: 0.07444
Policy Update Magnitude: 0.49786
Value Function Update Magnitude: 0.45824

Collected Steps per Second: 22,625.83170
Overall Steps per Second: 10,630.22439

Timestep Collection Time: 2.21013
Timestep Consumption Time: 2.49401
PPO Batch Consumption Time: 0.29629
Total Iteration Time: 4.70413

Cumulative Model Updates: 52,352
Cumulative Timesteps: 436,736,890

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 728.96870
Policy Entropy: 3.33662
Value Function Loss: 0.00351

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.08738
Policy Update Magnitude: 0.50145
Value Function Update Magnitude: 0.46041

Collected Steps per Second: 23,020.92508
Overall Steps per Second: 10,887.29660

Timestep Collection Time: 2.17211
Timestep Consumption Time: 2.42076
PPO Batch Consumption Time: 0.28183
Total Iteration Time: 4.59288

Cumulative Model Updates: 52,358
Cumulative Timesteps: 436,786,894

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 436786894...
Checkpoint 436786894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,043.02374
Policy Entropy: 3.34093
Value Function Loss: 0.00342

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.09777
Policy Update Magnitude: 0.50799
Value Function Update Magnitude: 0.47143

Collected Steps per Second: 22,890.46870
Overall Steps per Second: 10,663.89288

Timestep Collection Time: 2.18545
Timestep Consumption Time: 2.50571
PPO Batch Consumption Time: 0.29144
Total Iteration Time: 4.69116

Cumulative Model Updates: 52,364
Cumulative Timesteps: 436,836,920

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 731.43692
Policy Entropy: 3.35211
Value Function Loss: 0.00331

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.09914
Policy Update Magnitude: 0.50807
Value Function Update Magnitude: 0.47904

Collected Steps per Second: 22,078.25611
Overall Steps per Second: 10,449.13655

Timestep Collection Time: 2.26549
Timestep Consumption Time: 2.52132
PPO Batch Consumption Time: 0.29103
Total Iteration Time: 4.78681

Cumulative Model Updates: 52,370
Cumulative Timesteps: 436,886,938

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 436886938...
Checkpoint 436886938 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,494.63269
Policy Entropy: 3.34624
Value Function Loss: 0.00328

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.10098
Policy Update Magnitude: 0.50506
Value Function Update Magnitude: 0.48201

Collected Steps per Second: 22,239.49412
Overall Steps per Second: 10,690.27171

Timestep Collection Time: 2.24951
Timestep Consumption Time: 2.43026
PPO Batch Consumption Time: 0.27979
Total Iteration Time: 4.67977

Cumulative Model Updates: 52,376
Cumulative Timesteps: 436,936,966

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,451.29342
Policy Entropy: 3.33871
Value Function Loss: 0.00330

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.10166
Policy Update Magnitude: 0.49908
Value Function Update Magnitude: 0.48187

Collected Steps per Second: 22,460.04396
Overall Steps per Second: 10,570.16388

Timestep Collection Time: 2.22671
Timestep Consumption Time: 2.50472
PPO Batch Consumption Time: 0.29159
Total Iteration Time: 4.73143

Cumulative Model Updates: 52,382
Cumulative Timesteps: 436,986,978

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 436986978...
Checkpoint 436986978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 974.94932
Policy Entropy: 3.33074
Value Function Loss: 0.00329

Mean KL Divergence: 0.00737
SB3 Clip Fraction: 0.08246
Policy Update Magnitude: 0.50879
Value Function Update Magnitude: 0.46308

Collected Steps per Second: 22,299.89237
Overall Steps per Second: 10,616.91473

Timestep Collection Time: 2.24342
Timestep Consumption Time: 2.46868
PPO Batch Consumption Time: 0.29212
Total Iteration Time: 4.71210

Cumulative Model Updates: 52,388
Cumulative Timesteps: 437,037,006

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 758.89663
Policy Entropy: 3.34140
Value Function Loss: 0.00341

Mean KL Divergence: 0.00752
SB3 Clip Fraction: 0.08359
Policy Update Magnitude: 0.51252
Value Function Update Magnitude: 0.45060

Collected Steps per Second: 21,934.10735
Overall Steps per Second: 10,500.86485

Timestep Collection Time: 2.28065
Timestep Consumption Time: 2.48315
PPO Batch Consumption Time: 0.29096
Total Iteration Time: 4.76380

Cumulative Model Updates: 52,394
Cumulative Timesteps: 437,087,030

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 437087030...
Checkpoint 437087030 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 965.89658
Policy Entropy: 3.34515
Value Function Loss: 0.00328

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.08955
Policy Update Magnitude: 0.50789
Value Function Update Magnitude: 0.44532

Collected Steps per Second: 22,905.11271
Overall Steps per Second: 10,814.25740

Timestep Collection Time: 2.18318
Timestep Consumption Time: 2.44090
PPO Batch Consumption Time: 0.28105
Total Iteration Time: 4.62408

Cumulative Model Updates: 52,400
Cumulative Timesteps: 437,137,036

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,551.29194
Policy Entropy: 3.35785
Value Function Loss: 0.00326

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.09811
Policy Update Magnitude: 0.50113
Value Function Update Magnitude: 0.44184

Collected Steps per Second: 22,968.90504
Overall Steps per Second: 10,587.70439

Timestep Collection Time: 2.17738
Timestep Consumption Time: 2.54621
PPO Batch Consumption Time: 0.28582
Total Iteration Time: 4.72359

Cumulative Model Updates: 52,406
Cumulative Timesteps: 437,187,048

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 437187048...
Checkpoint 437187048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 935.30190
Policy Entropy: 3.36051
Value Function Loss: 0.00323

Mean KL Divergence: 0.00735
SB3 Clip Fraction: 0.08285
Policy Update Magnitude: 0.49904
Value Function Update Magnitude: 0.45377

Collected Steps per Second: 22,854.71924
Overall Steps per Second: 10,717.37164

Timestep Collection Time: 2.18799
Timestep Consumption Time: 2.47789
PPO Batch Consumption Time: 0.29267
Total Iteration Time: 4.66588

Cumulative Model Updates: 52,412
Cumulative Timesteps: 437,237,054

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 930.93972
Policy Entropy: 3.35125
Value Function Loss: 0.00321

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.08710
Policy Update Magnitude: 0.50727
Value Function Update Magnitude: 0.46558

Collected Steps per Second: 22,531.17935
Overall Steps per Second: 10,765.76137

Timestep Collection Time: 2.22003
Timestep Consumption Time: 2.42618
PPO Batch Consumption Time: 0.28220
Total Iteration Time: 4.64621

Cumulative Model Updates: 52,418
Cumulative Timesteps: 437,287,074

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 437287074...
Checkpoint 437287074 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,014.63084
Policy Entropy: 3.34338
Value Function Loss: 0.00332

Mean KL Divergence: 0.00746
SB3 Clip Fraction: 0.08580
Policy Update Magnitude: 0.50450
Value Function Update Magnitude: 0.46909

Collected Steps per Second: 22,875.77619
Overall Steps per Second: 10,710.69309

Timestep Collection Time: 2.18668
Timestep Consumption Time: 2.48361
PPO Batch Consumption Time: 0.29532
Total Iteration Time: 4.67029

Cumulative Model Updates: 52,424
Cumulative Timesteps: 437,337,096

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,117.82903
Policy Entropy: 3.33549
Value Function Loss: 0.00333

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.09146
Policy Update Magnitude: 0.50172
Value Function Update Magnitude: 0.48489

Collected Steps per Second: 23,023.10073
Overall Steps per Second: 10,904.93252

Timestep Collection Time: 2.17173
Timestep Consumption Time: 2.41335
PPO Batch Consumption Time: 0.27966
Total Iteration Time: 4.58508

Cumulative Model Updates: 52,430
Cumulative Timesteps: 437,387,096

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 437387096...
Checkpoint 437387096 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 699.27739
Policy Entropy: 3.35158
Value Function Loss: 0.00327

Mean KL Divergence: 0.00657
SB3 Clip Fraction: 0.07376
Policy Update Magnitude: 0.50057
Value Function Update Magnitude: 0.47973

Collected Steps per Second: 22,226.20341
Overall Steps per Second: 10,615.54747

Timestep Collection Time: 2.25059
Timestep Consumption Time: 2.46156
PPO Batch Consumption Time: 0.28812
Total Iteration Time: 4.71215

Cumulative Model Updates: 52,436
Cumulative Timesteps: 437,437,118

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 950.32214
Policy Entropy: 3.37322
Value Function Loss: 0.00329

Mean KL Divergence: 0.00635
SB3 Clip Fraction: 0.07023
Policy Update Magnitude: 0.50734
Value Function Update Magnitude: 0.49288

Collected Steps per Second: 22,450.04878
Overall Steps per Second: 10,661.83862

Timestep Collection Time: 2.22752
Timestep Consumption Time: 2.46285
PPO Batch Consumption Time: 0.29027
Total Iteration Time: 4.69037

Cumulative Model Updates: 52,442
Cumulative Timesteps: 437,487,126

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 437487126...
Checkpoint 437487126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,277.80369
Policy Entropy: 3.40212
Value Function Loss: 0.00323

Mean KL Divergence: 0.00692
SB3 Clip Fraction: 0.07750
Policy Update Magnitude: 0.50459
Value Function Update Magnitude: 0.48992

Collected Steps per Second: 22,584.38714
Overall Steps per Second: 10,832.40187

Timestep Collection Time: 2.21480
Timestep Consumption Time: 2.40282
PPO Batch Consumption Time: 0.27965
Total Iteration Time: 4.61763

Cumulative Model Updates: 52,448
Cumulative Timesteps: 437,537,146

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,241.37434
Policy Entropy: 3.39353
Value Function Loss: 0.00330

Mean KL Divergence: 0.00719
SB3 Clip Fraction: 0.08302
Policy Update Magnitude: 0.50150
Value Function Update Magnitude: 0.48782

Collected Steps per Second: 22,542.55178
Overall Steps per Second: 10,660.08219

Timestep Collection Time: 2.21883
Timestep Consumption Time: 2.47326
PPO Batch Consumption Time: 0.29146
Total Iteration Time: 4.69208

Cumulative Model Updates: 52,454
Cumulative Timesteps: 437,587,164

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 437587164...
Checkpoint 437587164 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,238.05025
Policy Entropy: 3.38255
Value Function Loss: 0.00339

Mean KL Divergence: 0.00659
SB3 Clip Fraction: 0.07323
Policy Update Magnitude: 0.50429
Value Function Update Magnitude: 0.48326

Collected Steps per Second: 23,104.83545
Overall Steps per Second: 10,670.87171

Timestep Collection Time: 2.16535
Timestep Consumption Time: 2.52312
PPO Batch Consumption Time: 0.29097
Total Iteration Time: 4.68846

Cumulative Model Updates: 52,460
Cumulative Timesteps: 437,637,194

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 854.58283
Policy Entropy: 3.38679
Value Function Loss: 0.00344

Mean KL Divergence: 0.00664
SB3 Clip Fraction: 0.07264
Policy Update Magnitude: 0.50905
Value Function Update Magnitude: 0.47691

Collected Steps per Second: 22,966.21635
Overall Steps per Second: 10,730.57001

Timestep Collection Time: 2.17824
Timestep Consumption Time: 2.48376
PPO Batch Consumption Time: 0.29185
Total Iteration Time: 4.66201

Cumulative Model Updates: 52,466
Cumulative Timesteps: 437,687,220

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 437687220...
Checkpoint 437687220 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,273.18263
Policy Entropy: 3.38445
Value Function Loss: 0.00323

Mean KL Divergence: 0.00745
SB3 Clip Fraction: 0.07656
Policy Update Magnitude: 0.49923
Value Function Update Magnitude: 0.47238

Collected Steps per Second: 22,792.22429
Overall Steps per Second: 10,639.93363

Timestep Collection Time: 2.19443
Timestep Consumption Time: 2.50635
PPO Batch Consumption Time: 0.29535
Total Iteration Time: 4.70078

Cumulative Model Updates: 52,472
Cumulative Timesteps: 437,737,236

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 861.88048
Policy Entropy: 3.38463
Value Function Loss: 0.00316

Mean KL Divergence: 0.00635
SB3 Clip Fraction: 0.07211
Policy Update Magnitude: 0.49319
Value Function Update Magnitude: 0.45437

Collected Steps per Second: 22,749.75133
Overall Steps per Second: 10,858.28169

Timestep Collection Time: 2.19835
Timestep Consumption Time: 2.40753
PPO Batch Consumption Time: 0.28037
Total Iteration Time: 4.60589

Cumulative Model Updates: 52,478
Cumulative Timesteps: 437,787,248

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 437787248...
Checkpoint 437787248 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,517.41409
Policy Entropy: 3.37637
Value Function Loss: 0.00310

Mean KL Divergence: 0.00645
SB3 Clip Fraction: 0.07515
Policy Update Magnitude: 0.48681
Value Function Update Magnitude: 0.44457

Collected Steps per Second: 22,949.06232
Overall Steps per Second: 10,694.82130

Timestep Collection Time: 2.17970
Timestep Consumption Time: 2.49752
PPO Batch Consumption Time: 0.29233
Total Iteration Time: 4.67722

Cumulative Model Updates: 52,484
Cumulative Timesteps: 437,837,270

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,321.46060
Policy Entropy: 3.37248
Value Function Loss: 0.00326

Mean KL Divergence: 0.00664
SB3 Clip Fraction: 0.07611
Policy Update Magnitude: 0.48622
Value Function Update Magnitude: 0.43892

Collected Steps per Second: 22,825.38299
Overall Steps per Second: 10,827.55571

Timestep Collection Time: 2.19116
Timestep Consumption Time: 2.42798
PPO Batch Consumption Time: 0.27945
Total Iteration Time: 4.61914

Cumulative Model Updates: 52,490
Cumulative Timesteps: 437,887,284

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 437887284...
Checkpoint 437887284 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,569.45526
Policy Entropy: 3.36633
Value Function Loss: 0.00340

Mean KL Divergence: 0.00656
SB3 Clip Fraction: 0.07406
Policy Update Magnitude: 0.49129
Value Function Update Magnitude: 0.44664

Collected Steps per Second: 22,423.82208
Overall Steps per Second: 10,700.04475

Timestep Collection Time: 2.23004
Timestep Consumption Time: 2.44340
PPO Batch Consumption Time: 0.27990
Total Iteration Time: 4.67344

Cumulative Model Updates: 52,496
Cumulative Timesteps: 437,937,290

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,479.40556
Policy Entropy: 3.36930
Value Function Loss: 0.00337

Mean KL Divergence: 0.00669
SB3 Clip Fraction: 0.07454
Policy Update Magnitude: 0.49000
Value Function Update Magnitude: 0.44933

Collected Steps per Second: 22,682.18081
Overall Steps per Second: 10,831.77674

Timestep Collection Time: 2.20464
Timestep Consumption Time: 2.41196
PPO Batch Consumption Time: 0.27997
Total Iteration Time: 4.61660

Cumulative Model Updates: 52,502
Cumulative Timesteps: 437,987,296

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 437987296...
Checkpoint 437987296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,057.96151
Policy Entropy: 3.35363
Value Function Loss: 0.00340

Mean KL Divergence: 0.00694
SB3 Clip Fraction: 0.07764
Policy Update Magnitude: 0.48834
Value Function Update Magnitude: 0.44992

Collected Steps per Second: 22,124.37334
Overall Steps per Second: 10,649.60617

Timestep Collection Time: 2.26067
Timestep Consumption Time: 2.43584
PPO Batch Consumption Time: 0.28031
Total Iteration Time: 4.69651

Cumulative Model Updates: 52,508
Cumulative Timesteps: 438,037,312

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 761.74227
Policy Entropy: 3.35869
Value Function Loss: 0.00332

Mean KL Divergence: 0.00745
SB3 Clip Fraction: 0.08399
Policy Update Magnitude: 0.49941
Value Function Update Magnitude: 0.45327

Collected Steps per Second: 21,988.66569
Overall Steps per Second: 10,545.39591

Timestep Collection Time: 2.27426
Timestep Consumption Time: 2.46790
PPO Batch Consumption Time: 0.29024
Total Iteration Time: 4.74216

Cumulative Model Updates: 52,514
Cumulative Timesteps: 438,087,320

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 438087320...
Checkpoint 438087320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 827.44811
Policy Entropy: 3.35901
Value Function Loss: 0.00329

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.08592
Policy Update Magnitude: 0.50462
Value Function Update Magnitude: 0.45290

Collected Steps per Second: 22,591.57045
Overall Steps per Second: 10,656.55200

Timestep Collection Time: 2.21419
Timestep Consumption Time: 2.47982
PPO Batch Consumption Time: 0.29149
Total Iteration Time: 4.69401

Cumulative Model Updates: 52,520
Cumulative Timesteps: 438,137,342

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,051.97003
Policy Entropy: 3.36742
Value Function Loss: 0.00352

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.08519
Policy Update Magnitude: 0.50314
Value Function Update Magnitude: 0.44114

Collected Steps per Second: 23,093.00225
Overall Steps per Second: 10,818.26579

Timestep Collection Time: 2.16568
Timestep Consumption Time: 2.45724
PPO Batch Consumption Time: 0.27957
Total Iteration Time: 4.62292

Cumulative Model Updates: 52,526
Cumulative Timesteps: 438,187,354

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 438187354...
Checkpoint 438187354 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,172.79590
Policy Entropy: 3.36336
Value Function Loss: 0.00342

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.08594
Policy Update Magnitude: 0.49786
Value Function Update Magnitude: 0.43492

Collected Steps per Second: 22,936.57173
Overall Steps per Second: 10,690.99060

Timestep Collection Time: 2.18088
Timestep Consumption Time: 2.49801
PPO Batch Consumption Time: 0.29372
Total Iteration Time: 4.67889

Cumulative Model Updates: 52,532
Cumulative Timesteps: 438,237,376

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 852.01280
Policy Entropy: 3.35368
Value Function Loss: 0.00346

Mean KL Divergence: 0.00783
SB3 Clip Fraction: 0.08595
Policy Update Magnitude: 0.50612
Value Function Update Magnitude: 0.43729

Collected Steps per Second: 22,763.81473
Overall Steps per Second: 10,826.03795

Timestep Collection Time: 2.19735
Timestep Consumption Time: 2.42300
PPO Batch Consumption Time: 0.28135
Total Iteration Time: 4.62034

Cumulative Model Updates: 52,538
Cumulative Timesteps: 438,287,396

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 438287396...
Checkpoint 438287396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,100.11469
Policy Entropy: 3.35406
Value Function Loss: 0.00334

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.09174
Policy Update Magnitude: 0.49826
Value Function Update Magnitude: 0.43165

Collected Steps per Second: 22,982.84133
Overall Steps per Second: 10,747.27360

Timestep Collection Time: 2.17571
Timestep Consumption Time: 2.47700
PPO Batch Consumption Time: 0.29294
Total Iteration Time: 4.65271

Cumulative Model Updates: 52,544
Cumulative Timesteps: 438,337,400

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 595.86144
Policy Entropy: 3.35405
Value Function Loss: 0.00338

Mean KL Divergence: 0.00637
SB3 Clip Fraction: 0.06980
Policy Update Magnitude: 0.50534
Value Function Update Magnitude: 0.44803

Collected Steps per Second: 22,946.02249
Overall Steps per Second: 10,899.90268

Timestep Collection Time: 2.17990
Timestep Consumption Time: 2.40913
PPO Batch Consumption Time: 0.28068
Total Iteration Time: 4.58903

Cumulative Model Updates: 52,550
Cumulative Timesteps: 438,387,420

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 438387420...
Checkpoint 438387420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,036.37461
Policy Entropy: 3.35080
Value Function Loss: 0.00342

Mean KL Divergence: 0.00640
SB3 Clip Fraction: 0.07275
Policy Update Magnitude: 0.51998
Value Function Update Magnitude: 0.46016

Collected Steps per Second: 22,865.38347
Overall Steps per Second: 10,728.20255

Timestep Collection Time: 2.18680
Timestep Consumption Time: 2.47400
PPO Batch Consumption Time: 0.29413
Total Iteration Time: 4.66080

Cumulative Model Updates: 52,556
Cumulative Timesteps: 438,437,422

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,277.98616
Policy Entropy: 3.34677
Value Function Loss: 0.00336

Mean KL Divergence: 0.00588
SB3 Clip Fraction: 0.06556
Policy Update Magnitude: 0.52663
Value Function Update Magnitude: 0.46603

Collected Steps per Second: 22,247.35179
Overall Steps per Second: 10,734.89462

Timestep Collection Time: 2.24773
Timestep Consumption Time: 2.41054
PPO Batch Consumption Time: 0.28110
Total Iteration Time: 4.65827

Cumulative Model Updates: 52,562
Cumulative Timesteps: 438,487,428

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 438487428...
Checkpoint 438487428 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 719.13825
Policy Entropy: 3.34293
Value Function Loss: 0.00331

Mean KL Divergence: 0.00648
SB3 Clip Fraction: 0.07362
Policy Update Magnitude: 0.52424
Value Function Update Magnitude: 0.47093

Collected Steps per Second: 22,321.06004
Overall Steps per Second: 10,674.04200

Timestep Collection Time: 2.24102
Timestep Consumption Time: 2.44530
PPO Batch Consumption Time: 0.28097
Total Iteration Time: 4.68632

Cumulative Model Updates: 52,568
Cumulative Timesteps: 438,537,450

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,395.97682
Policy Entropy: 3.34461
Value Function Loss: 0.00337

Mean KL Divergence: 0.00657
SB3 Clip Fraction: 0.07340
Policy Update Magnitude: 0.50752
Value Function Update Magnitude: 0.46614

Collected Steps per Second: 22,237.27507
Overall Steps per Second: 10,530.20300

Timestep Collection Time: 2.24956
Timestep Consumption Time: 2.50097
PPO Batch Consumption Time: 0.29055
Total Iteration Time: 4.75053

Cumulative Model Updates: 52,574
Cumulative Timesteps: 438,587,474

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 438587474...
Checkpoint 438587474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,230.77672
Policy Entropy: 3.36483
Value Function Loss: 0.00340

Mean KL Divergence: 0.00700
SB3 Clip Fraction: 0.07888
Policy Update Magnitude: 0.50197
Value Function Update Magnitude: 0.46136

Collected Steps per Second: 22,619.36129
Overall Steps per Second: 10,623.66505

Timestep Collection Time: 2.21111
Timestep Consumption Time: 2.49668
PPO Batch Consumption Time: 0.28654
Total Iteration Time: 4.70779

Cumulative Model Updates: 52,580
Cumulative Timesteps: 438,637,488

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,585.20759
Policy Entropy: 3.36532
Value Function Loss: 0.00344

Mean KL Divergence: 0.00665
SB3 Clip Fraction: 0.07469
Policy Update Magnitude: 0.50639
Value Function Update Magnitude: 0.47651

Collected Steps per Second: 22,784.72078
Overall Steps per Second: 10,828.83766

Timestep Collection Time: 2.19586
Timestep Consumption Time: 2.42440
PPO Batch Consumption Time: 0.28080
Total Iteration Time: 4.62026

Cumulative Model Updates: 52,586
Cumulative Timesteps: 438,687,520

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 438687520...
Checkpoint 438687520 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,280.60668
Policy Entropy: 3.36904
Value Function Loss: 0.00335

Mean KL Divergence: 0.00572
SB3 Clip Fraction: 0.06425
Policy Update Magnitude: 0.51564
Value Function Update Magnitude: 0.47773

Collected Steps per Second: 22,852.09388
Overall Steps per Second: 10,721.30258

Timestep Collection Time: 2.18930
Timestep Consumption Time: 2.47711
PPO Batch Consumption Time: 0.29306
Total Iteration Time: 4.66641

Cumulative Model Updates: 52,592
Cumulative Timesteps: 438,737,550

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,978.38978
Policy Entropy: 3.35628
Value Function Loss: 0.00331

Mean KL Divergence: 0.00590
SB3 Clip Fraction: 0.06582
Policy Update Magnitude: 0.51031
Value Function Update Magnitude: 0.47669

Collected Steps per Second: 22,906.63746
Overall Steps per Second: 10,885.38063

Timestep Collection Time: 2.18400
Timestep Consumption Time: 2.41189
PPO Batch Consumption Time: 0.28060
Total Iteration Time: 4.59589

Cumulative Model Updates: 52,598
Cumulative Timesteps: 438,787,578

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 438787578...
Checkpoint 438787578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,080.75015
Policy Entropy: 3.34026
Value Function Loss: 0.00329

Mean KL Divergence: 0.00615
SB3 Clip Fraction: 0.06922
Policy Update Magnitude: 0.50172
Value Function Update Magnitude: 0.46979

Collected Steps per Second: 22,946.34734
Overall Steps per Second: 10,692.25168

Timestep Collection Time: 2.17952
Timestep Consumption Time: 2.49789
PPO Batch Consumption Time: 0.29450
Total Iteration Time: 4.67741

Cumulative Model Updates: 52,604
Cumulative Timesteps: 438,837,590

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 744.84244
Policy Entropy: 3.34968
Value Function Loss: 0.00326

Mean KL Divergence: 0.00658
SB3 Clip Fraction: 0.07553
Policy Update Magnitude: 0.49558
Value Function Update Magnitude: 0.48805

Collected Steps per Second: 22,762.68618
Overall Steps per Second: 10,818.45158

Timestep Collection Time: 2.19684
Timestep Consumption Time: 2.42545
PPO Batch Consumption Time: 0.28078
Total Iteration Time: 4.62229

Cumulative Model Updates: 52,610
Cumulative Timesteps: 438,887,596

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 438887596...
Checkpoint 438887596 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,277.83104
Policy Entropy: 3.36168
Value Function Loss: 0.00326

Mean KL Divergence: 0.00669
SB3 Clip Fraction: 0.07521
Policy Update Magnitude: 0.49960
Value Function Update Magnitude: 0.48015

Collected Steps per Second: 22,428.27392
Overall Steps per Second: 10,715.64480

Timestep Collection Time: 2.22977
Timestep Consumption Time: 2.43723
PPO Batch Consumption Time: 0.28554
Total Iteration Time: 4.66701

Cumulative Model Updates: 52,616
Cumulative Timesteps: 438,937,606

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 970.37188
Policy Entropy: 3.36838
Value Function Loss: 0.00315

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.09405
Policy Update Magnitude: 0.49375
Value Function Update Magnitude: 0.46805

Collected Steps per Second: 22,571.86993
Overall Steps per Second: 10,622.22011

Timestep Collection Time: 2.21577
Timestep Consumption Time: 2.49267
PPO Batch Consumption Time: 0.29189
Total Iteration Time: 4.70843

Cumulative Model Updates: 52,622
Cumulative Timesteps: 438,987,620

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 438987620...
Checkpoint 438987620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,457.70909
Policy Entropy: 3.35316
Value Function Loss: 0.00313

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.09044
Policy Update Magnitude: 0.48422
Value Function Update Magnitude: 0.45642

Collected Steps per Second: 22,779.31412
Overall Steps per Second: 10,837.45922

Timestep Collection Time: 2.19515
Timestep Consumption Time: 2.41885
PPO Batch Consumption Time: 0.27992
Total Iteration Time: 4.61400

Cumulative Model Updates: 52,628
Cumulative Timesteps: 439,037,624

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 943.34790
Policy Entropy: 3.34483
Value Function Loss: 0.00305

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.10757
Policy Update Magnitude: 0.48393
Value Function Update Magnitude: 0.45705

Collected Steps per Second: 22,420.86913
Overall Steps per Second: 10,536.63704

Timestep Collection Time: 2.23007
Timestep Consumption Time: 2.51528
PPO Batch Consumption Time: 0.29263
Total Iteration Time: 4.74535

Cumulative Model Updates: 52,634
Cumulative Timesteps: 439,087,624

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 439087624...
Checkpoint 439087624 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 713.89858
Policy Entropy: 3.33934
Value Function Loss: 0.00316

Mean KL Divergence: 0.00729
SB3 Clip Fraction: 0.08029
Policy Update Magnitude: 0.48795
Value Function Update Magnitude: 0.44792

Collected Steps per Second: 22,432.21384
Overall Steps per Second: 10,642.93335

Timestep Collection Time: 2.22974
Timestep Consumption Time: 2.46990
PPO Batch Consumption Time: 0.28632
Total Iteration Time: 4.69964

Cumulative Model Updates: 52,640
Cumulative Timesteps: 439,137,642

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,953.33349
Policy Entropy: 3.33521
Value Function Loss: 0.00322

Mean KL Divergence: 0.00646
SB3 Clip Fraction: 0.07227
Policy Update Magnitude: 0.49602
Value Function Update Magnitude: 0.44316

Collected Steps per Second: 22,898.66651
Overall Steps per Second: 10,822.36519

Timestep Collection Time: 2.18467
Timestep Consumption Time: 2.43780
PPO Batch Consumption Time: 0.27979
Total Iteration Time: 4.62246

Cumulative Model Updates: 52,646
Cumulative Timesteps: 439,187,668

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 439187668...
Checkpoint 439187668 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,134.25135
Policy Entropy: 3.33617
Value Function Loss: 0.00324

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.09044
Policy Update Magnitude: 0.50095
Value Function Update Magnitude: 0.46024

Collected Steps per Second: 22,742.93309
Overall Steps per Second: 10,700.35405

Timestep Collection Time: 2.19866
Timestep Consumption Time: 2.47446
PPO Batch Consumption Time: 0.28610
Total Iteration Time: 4.67312

Cumulative Model Updates: 52,652
Cumulative Timesteps: 439,237,672

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,212.11791
Policy Entropy: 3.32093
Value Function Loss: 0.00334

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.10269
Policy Update Magnitude: 0.50213
Value Function Update Magnitude: 0.48465

Collected Steps per Second: 22,898.43734
Overall Steps per Second: 10,885.86479

Timestep Collection Time: 2.18373
Timestep Consumption Time: 2.40975
PPO Batch Consumption Time: 0.28088
Total Iteration Time: 4.59348

Cumulative Model Updates: 52,658
Cumulative Timesteps: 439,287,676

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 439287676...
Checkpoint 439287676 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,644.92868
Policy Entropy: 3.32200
Value Function Loss: 0.00334

Mean KL Divergence: 0.01188
SB3 Clip Fraction: 0.11869
Policy Update Magnitude: 0.50887
Value Function Update Magnitude: 0.50058

Collected Steps per Second: 22,782.64318
Overall Steps per Second: 10,674.93643

Timestep Collection Time: 2.19571
Timestep Consumption Time: 2.49041
PPO Batch Consumption Time: 0.29353
Total Iteration Time: 4.68612

Cumulative Model Updates: 52,664
Cumulative Timesteps: 439,337,700

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,039.14797
Policy Entropy: 3.33586
Value Function Loss: 0.00346

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.11412
Policy Update Magnitude: 0.51301
Value Function Update Magnitude: 0.51283

Collected Steps per Second: 23,085.79548
Overall Steps per Second: 10,952.85983

Timestep Collection Time: 2.16696
Timestep Consumption Time: 2.40043
PPO Batch Consumption Time: 0.27883
Total Iteration Time: 4.56739

Cumulative Model Updates: 52,670
Cumulative Timesteps: 439,387,726

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 439387726...
Checkpoint 439387726 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 822.75684
Policy Entropy: 3.34808
Value Function Loss: 0.00335

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.09144
Policy Update Magnitude: 0.51554
Value Function Update Magnitude: 0.50956

Collected Steps per Second: 22,905.36672
Overall Steps per Second: 10,729.93919

Timestep Collection Time: 2.18377
Timestep Consumption Time: 2.47795
PPO Batch Consumption Time: 0.29457
Total Iteration Time: 4.66172

Cumulative Model Updates: 52,676
Cumulative Timesteps: 439,437,746

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,538.92565
Policy Entropy: 3.35338
Value Function Loss: 0.00338

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.10418
Policy Update Magnitude: 0.51279
Value Function Update Magnitude: 0.48751

Collected Steps per Second: 22,140.98941
Overall Steps per Second: 10,583.59626

Timestep Collection Time: 2.25916
Timestep Consumption Time: 2.46702
PPO Batch Consumption Time: 0.28975
Total Iteration Time: 4.72618

Cumulative Model Updates: 52,682
Cumulative Timesteps: 439,487,766

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 439487766...
Checkpoint 439487766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,254.70062
Policy Entropy: 3.35905
Value Function Loss: 0.00329

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.09718
Policy Update Magnitude: 0.50845
Value Function Update Magnitude: 0.46329

Collected Steps per Second: 22,311.15472
Overall Steps per Second: 10,608.47651

Timestep Collection Time: 2.24130
Timestep Consumption Time: 2.47248
PPO Batch Consumption Time: 0.29014
Total Iteration Time: 4.71378

Cumulative Model Updates: 52,688
Cumulative Timesteps: 439,537,772

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 824.30370
Policy Entropy: 3.36130
Value Function Loss: 0.00313

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.10554
Policy Update Magnitude: 0.49904
Value Function Update Magnitude: 0.44892

Collected Steps per Second: 22,737.88093
Overall Steps per Second: 10,756.01632

Timestep Collection Time: 2.19941
Timestep Consumption Time: 2.45008
PPO Batch Consumption Time: 0.28746
Total Iteration Time: 4.64949

Cumulative Model Updates: 52,694
Cumulative Timesteps: 439,587,782

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 439587782...
Checkpoint 439587782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,010.22937
Policy Entropy: 3.36579
Value Function Loss: 0.00299

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.09870
Policy Update Magnitude: 0.49354
Value Function Update Magnitude: 0.43709

Collected Steps per Second: 22,240.91640
Overall Steps per Second: 10,635.60679

Timestep Collection Time: 2.24883
Timestep Consumption Time: 2.45387
PPO Batch Consumption Time: 0.28710
Total Iteration Time: 4.70269

Cumulative Model Updates: 52,700
Cumulative Timesteps: 439,637,798

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 719.72878
Policy Entropy: 3.35215
Value Function Loss: 0.00317

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.09614
Policy Update Magnitude: 0.49021
Value Function Update Magnitude: 0.44202

Collected Steps per Second: 22,393.92039
Overall Steps per Second: 10,634.57697

Timestep Collection Time: 2.23320
Timestep Consumption Time: 2.46939
PPO Batch Consumption Time: 0.28942
Total Iteration Time: 4.70258

Cumulative Model Updates: 52,706
Cumulative Timesteps: 439,687,808

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 439687808...
Checkpoint 439687808 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,653.17171
Policy Entropy: 3.36441
Value Function Loss: 0.00332

Mean KL Divergence: 0.00714
SB3 Clip Fraction: 0.08091
Policy Update Magnitude: 0.50213
Value Function Update Magnitude: 0.46031

Collected Steps per Second: 23,192.14468
Overall Steps per Second: 10,846.06508

Timestep Collection Time: 2.15642
Timestep Consumption Time: 2.45465
PPO Batch Consumption Time: 0.28014
Total Iteration Time: 4.61107

Cumulative Model Updates: 52,712
Cumulative Timesteps: 439,737,820

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,964.82582
Policy Entropy: 3.34852
Value Function Loss: 0.00354

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.08966
Policy Update Magnitude: 0.51173
Value Function Update Magnitude: 0.46794

Collected Steps per Second: 22,397.15191
Overall Steps per Second: 10,656.34901

Timestep Collection Time: 2.23252
Timestep Consumption Time: 2.45971
PPO Batch Consumption Time: 0.28968
Total Iteration Time: 4.69223

Cumulative Model Updates: 52,718
Cumulative Timesteps: 439,787,822

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 439787822...
Checkpoint 439787822 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,443.49659
Policy Entropy: 3.34833
Value Function Loss: 0.00364

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.08945
Policy Update Magnitude: 0.51243
Value Function Update Magnitude: 0.47158

Collected Steps per Second: 23,143.88071
Overall Steps per Second: 11,006.07100

Timestep Collection Time: 2.16161
Timestep Consumption Time: 2.38388
PPO Batch Consumption Time: 0.27901
Total Iteration Time: 4.54549

Cumulative Model Updates: 52,724
Cumulative Timesteps: 439,837,850

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,430.32024
Policy Entropy: 3.33558
Value Function Loss: 0.00355

Mean KL Divergence: 0.00741
SB3 Clip Fraction: 0.08386
Policy Update Magnitude: 0.51599
Value Function Update Magnitude: 0.47014

Collected Steps per Second: 22,926.85519
Overall Steps per Second: 10,818.99367

Timestep Collection Time: 2.18111
Timestep Consumption Time: 2.44095
PPO Batch Consumption Time: 0.28616
Total Iteration Time: 4.62206

Cumulative Model Updates: 52,730
Cumulative Timesteps: 439,887,856

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 439887856...
Checkpoint 439887856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,516.63980
Policy Entropy: 3.35136
Value Function Loss: 0.00347

Mean KL Divergence: 0.00682
SB3 Clip Fraction: 0.07732
Policy Update Magnitude: 0.52055
Value Function Update Magnitude: 0.46671

Collected Steps per Second: 22,831.49210
Overall Steps per Second: 10,643.64336

Timestep Collection Time: 2.19075
Timestep Consumption Time: 2.50858
PPO Batch Consumption Time: 0.29230
Total Iteration Time: 4.69933

Cumulative Model Updates: 52,736
Cumulative Timesteps: 439,937,874

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,486.65263
Policy Entropy: 3.36410
Value Function Loss: 0.00326

Mean KL Divergence: 0.00691
SB3 Clip Fraction: 0.07954
Policy Update Magnitude: 0.51865
Value Function Update Magnitude: 0.46510

Collected Steps per Second: 21,590.58587
Overall Steps per Second: 10,478.56950

Timestep Collection Time: 2.31795
Timestep Consumption Time: 2.45808
PPO Batch Consumption Time: 0.28368
Total Iteration Time: 4.77603

Cumulative Model Updates: 52,742
Cumulative Timesteps: 439,987,920

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 439987920...
Checkpoint 439987920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,079.10895
Policy Entropy: 3.36170
Value Function Loss: 0.00327

Mean KL Divergence: 0.00673
SB3 Clip Fraction: 0.07769
Policy Update Magnitude: 0.51162
Value Function Update Magnitude: 0.46367

Collected Steps per Second: 22,050.72636
Overall Steps per Second: 10,630.98212

Timestep Collection Time: 2.26959
Timestep Consumption Time: 2.43798
PPO Batch Consumption Time: 0.27979
Total Iteration Time: 4.70756

Cumulative Model Updates: 52,748
Cumulative Timesteps: 440,037,966

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,547.97846
Policy Entropy: 3.34963
Value Function Loss: 0.00307

Mean KL Divergence: 0.00688
SB3 Clip Fraction: 0.07641
Policy Update Magnitude: 0.51309
Value Function Update Magnitude: 0.46676

Collected Steps per Second: 22,281.66573
Overall Steps per Second: 10,561.95848

Timestep Collection Time: 2.24489
Timestep Consumption Time: 2.49097
PPO Batch Consumption Time: 0.29405
Total Iteration Time: 4.73586

Cumulative Model Updates: 52,754
Cumulative Timesteps: 440,087,986

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 440087986...
Checkpoint 440087986 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 882.79533
Policy Entropy: 3.35105
Value Function Loss: 0.00319

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.09368
Policy Update Magnitude: 0.51020
Value Function Update Magnitude: 0.45115

Collected Steps per Second: 22,703.40765
Overall Steps per Second: 10,611.16946

Timestep Collection Time: 2.20311
Timestep Consumption Time: 2.51061
PPO Batch Consumption Time: 0.29428
Total Iteration Time: 4.71371

Cumulative Model Updates: 52,760
Cumulative Timesteps: 440,138,004

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 680.69213
Policy Entropy: 3.34144
Value Function Loss: 0.00364

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.10182
Policy Update Magnitude: 0.51797
Value Function Update Magnitude: 0.46453

Collected Steps per Second: 23,021.04795
Overall Steps per Second: 10,821.35588

Timestep Collection Time: 2.17288
Timestep Consumption Time: 2.44964
PPO Batch Consumption Time: 0.28010
Total Iteration Time: 4.62253

Cumulative Model Updates: 52,766
Cumulative Timesteps: 440,188,026

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 440188026...
Checkpoint 440188026 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,501.55349
Policy Entropy: 3.34737
Value Function Loss: 0.00371

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.11156
Policy Update Magnitude: 0.52989
Value Function Update Magnitude: 0.48309

Collected Steps per Second: 22,743.25853
Overall Steps per Second: 10,685.27323

Timestep Collection Time: 2.19854
Timestep Consumption Time: 2.48098
PPO Batch Consumption Time: 0.29251
Total Iteration Time: 4.67952

Cumulative Model Updates: 52,772
Cumulative Timesteps: 440,238,028

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,286.03547
Policy Entropy: 3.35986
Value Function Loss: 0.00356

Mean KL Divergence: 0.01101
SB3 Clip Fraction: 0.11234
Policy Update Magnitude: 0.52244
Value Function Update Magnitude: 0.47603

Collected Steps per Second: 22,846.15153
Overall Steps per Second: 10,848.72140

Timestep Collection Time: 2.18978
Timestep Consumption Time: 2.42164
PPO Batch Consumption Time: 0.27952
Total Iteration Time: 4.61142

Cumulative Model Updates: 52,778
Cumulative Timesteps: 440,288,056

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 440288056...
Checkpoint 440288056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 805.36684
Policy Entropy: 3.36915
Value Function Loss: 0.00333

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.09664
Policy Update Magnitude: 0.50689
Value Function Update Magnitude: 0.47358

Collected Steps per Second: 22,939.75796
Overall Steps per Second: 10,699.77422

Timestep Collection Time: 2.18049
Timestep Consumption Time: 2.49437
PPO Batch Consumption Time: 0.29564
Total Iteration Time: 4.67486

Cumulative Model Updates: 52,784
Cumulative Timesteps: 440,338,076

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,374.33054
Policy Entropy: 3.36054
Value Function Loss: 0.00316

Mean KL Divergence: 0.00766
SB3 Clip Fraction: 0.08737
Policy Update Magnitude: 0.50116
Value Function Update Magnitude: 0.47049

Collected Steps per Second: 22,964.40526
Overall Steps per Second: 10,858.18513

Timestep Collection Time: 2.17728
Timestep Consumption Time: 2.42754
PPO Batch Consumption Time: 0.28038
Total Iteration Time: 4.60482

Cumulative Model Updates: 52,790
Cumulative Timesteps: 440,388,076

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 440388076...
Checkpoint 440388076 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,417.62006
Policy Entropy: 3.33876
Value Function Loss: 0.00325

Mean KL Divergence: 0.00672
SB3 Clip Fraction: 0.07552
Policy Update Magnitude: 0.51160
Value Function Update Magnitude: 0.45988

Collected Steps per Second: 22,831.97907
Overall Steps per Second: 10,725.36214

Timestep Collection Time: 2.19009
Timestep Consumption Time: 2.47213
PPO Batch Consumption Time: 0.29291
Total Iteration Time: 4.66222

Cumulative Model Updates: 52,796
Cumulative Timesteps: 440,438,080

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,359.26930
Policy Entropy: 3.32943
Value Function Loss: 0.00329

Mean KL Divergence: 0.00722
SB3 Clip Fraction: 0.08054
Policy Update Magnitude: 0.51449
Value Function Update Magnitude: 0.46763

Collected Steps per Second: 22,397.25387
Overall Steps per Second: 10,648.47021

Timestep Collection Time: 2.23349
Timestep Consumption Time: 2.46428
PPO Batch Consumption Time: 0.28947
Total Iteration Time: 4.69776

Cumulative Model Updates: 52,802
Cumulative Timesteps: 440,488,104

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 440488104...
Checkpoint 440488104 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 886.90064
Policy Entropy: 3.32235
Value Function Loss: 0.00337

Mean KL Divergence: 0.00701
SB3 Clip Fraction: 0.07819
Policy Update Magnitude: 0.50842
Value Function Update Magnitude: 0.49124

Collected Steps per Second: 22,437.08550
Overall Steps per Second: 10,805.50941

Timestep Collection Time: 2.22863
Timestep Consumption Time: 2.39901
PPO Batch Consumption Time: 0.28075
Total Iteration Time: 4.62764

Cumulative Model Updates: 52,808
Cumulative Timesteps: 440,538,108

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,662.74233
Policy Entropy: 3.32720
Value Function Loss: 0.00353

Mean KL Divergence: 0.00766
SB3 Clip Fraction: 0.08656
Policy Update Magnitude: 0.51738
Value Function Update Magnitude: 0.48407

Collected Steps per Second: 22,544.51738
Overall Steps per Second: 10,663.96199

Timestep Collection Time: 2.21899
Timestep Consumption Time: 2.47214
PPO Batch Consumption Time: 0.29260
Total Iteration Time: 4.69113

Cumulative Model Updates: 52,814
Cumulative Timesteps: 440,588,134

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 440588134...
Checkpoint 440588134 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,440.04036
Policy Entropy: 3.33593
Value Function Loss: 0.00348

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.09064
Policy Update Magnitude: 0.52783
Value Function Update Magnitude: 0.48552

Collected Steps per Second: 22,490.40811
Overall Steps per Second: 10,677.64524

Timestep Collection Time: 2.22326
Timestep Consumption Time: 2.45961
PPO Batch Consumption Time: 0.29107
Total Iteration Time: 4.68287

Cumulative Model Updates: 52,820
Cumulative Timesteps: 440,638,136

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,427.41810
Policy Entropy: 3.33331
Value Function Loss: 0.00356

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.10669
Policy Update Magnitude: 0.52416
Value Function Update Magnitude: 0.47353

Collected Steps per Second: 22,794.38873
Overall Steps per Second: 10,692.71538

Timestep Collection Time: 2.19352
Timestep Consumption Time: 2.48256
PPO Batch Consumption Time: 0.28107
Total Iteration Time: 4.67608

Cumulative Model Updates: 52,826
Cumulative Timesteps: 440,688,136

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 440688136...
Checkpoint 440688136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,315.26504
Policy Entropy: 3.34288
Value Function Loss: 0.00329

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.10369
Policy Update Magnitude: 0.51163
Value Function Update Magnitude: 0.46201

Collected Steps per Second: 22,291.49333
Overall Steps per Second: 10,633.65805

Timestep Collection Time: 2.24435
Timestep Consumption Time: 2.46052
PPO Batch Consumption Time: 0.28046
Total Iteration Time: 4.70487

Cumulative Model Updates: 52,832
Cumulative Timesteps: 440,738,166

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 881.30618
Policy Entropy: 3.36164
Value Function Loss: 0.00329

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.10302
Policy Update Magnitude: 0.50539
Value Function Update Magnitude: 0.45695

Collected Steps per Second: 22,832.88864
Overall Steps per Second: 10,674.22544

Timestep Collection Time: 2.19070
Timestep Consumption Time: 2.49535
PPO Batch Consumption Time: 0.29127
Total Iteration Time: 4.68605

Cumulative Model Updates: 52,838
Cumulative Timesteps: 440,788,186

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 440788186...
Checkpoint 440788186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,618.13599
Policy Entropy: 3.37203
Value Function Loss: 0.00310

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.09444
Policy Update Magnitude: 0.50270
Value Function Update Magnitude: 0.45445

Collected Steps per Second: 22,872.99386
Overall Steps per Second: 10,906.15604

Timestep Collection Time: 2.18607
Timestep Consumption Time: 2.39868
PPO Batch Consumption Time: 0.28035
Total Iteration Time: 4.58475

Cumulative Model Updates: 52,844
Cumulative Timesteps: 440,838,188

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,522.92928
Policy Entropy: 3.36535
Value Function Loss: 0.00310

Mean KL Divergence: 0.00685
SB3 Clip Fraction: 0.07592
Policy Update Magnitude: 0.50089
Value Function Update Magnitude: 0.44500

Collected Steps per Second: 22,801.06454
Overall Steps per Second: 10,614.83667

Timestep Collection Time: 2.19306
Timestep Consumption Time: 2.51771
PPO Batch Consumption Time: 0.29167
Total Iteration Time: 4.71076

Cumulative Model Updates: 52,850
Cumulative Timesteps: 440,888,192

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 440888192...
Checkpoint 440888192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,345.51509
Policy Entropy: 3.34442
Value Function Loss: 0.00312

Mean KL Divergence: 0.00699
SB3 Clip Fraction: 0.07779
Policy Update Magnitude: 0.50140
Value Function Update Magnitude: 0.44148

Collected Steps per Second: 23,047.17295
Overall Steps per Second: 10,918.37679

Timestep Collection Time: 2.17059
Timestep Consumption Time: 2.41123
PPO Batch Consumption Time: 0.28108
Total Iteration Time: 4.58182

Cumulative Model Updates: 52,856
Cumulative Timesteps: 440,938,218

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,340.44208
Policy Entropy: 3.34784
Value Function Loss: 0.00320

Mean KL Divergence: 0.00738
SB3 Clip Fraction: 0.08412
Policy Update Magnitude: 0.49917
Value Function Update Magnitude: 0.44999

Collected Steps per Second: 22,562.57998
Overall Steps per Second: 10,579.05050

Timestep Collection Time: 2.21810
Timestep Consumption Time: 2.51257
PPO Batch Consumption Time: 0.29361
Total Iteration Time: 4.73067

Cumulative Model Updates: 52,862
Cumulative Timesteps: 440,988,264

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 440988264...
Checkpoint 440988264 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,517.24183
Policy Entropy: 3.36070
Value Function Loss: 0.00331

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.08739
Policy Update Magnitude: 0.50771
Value Function Update Magnitude: 0.44920

Collected Steps per Second: 22,425.77882
Overall Steps per Second: 10,578.58956

Timestep Collection Time: 2.23100
Timestep Consumption Time: 2.49855
PPO Batch Consumption Time: 0.29217
Total Iteration Time: 4.72955

Cumulative Model Updates: 52,868
Cumulative Timesteps: 441,038,296

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,615.58189
Policy Entropy: 3.37182
Value Function Loss: 0.00334

Mean KL Divergence: 0.00698
SB3 Clip Fraction: 0.07828
Policy Update Magnitude: 0.50765
Value Function Update Magnitude: 0.46801

Collected Steps per Second: 22,425.00378
Overall Steps per Second: 10,548.99320

Timestep Collection Time: 2.22983
Timestep Consumption Time: 2.51034
PPO Batch Consumption Time: 0.29403
Total Iteration Time: 4.74017

Cumulative Model Updates: 52,874
Cumulative Timesteps: 441,088,300

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 441088300...
Checkpoint 441088300 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 579.73638
Policy Entropy: 3.37052
Value Function Loss: 0.00336

Mean KL Divergence: 0.00743
SB3 Clip Fraction: 0.08555
Policy Update Magnitude: 0.51518
Value Function Update Magnitude: 0.48473

Collected Steps per Second: 22,495.81161
Overall Steps per Second: 10,542.51164

Timestep Collection Time: 2.22317
Timestep Consumption Time: 2.52067
PPO Batch Consumption Time: 0.29428
Total Iteration Time: 4.74384

Cumulative Model Updates: 52,880
Cumulative Timesteps: 441,138,312

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,335.26758
Policy Entropy: 3.35966
Value Function Loss: 0.00324

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.08954
Policy Update Magnitude: 0.51331
Value Function Update Magnitude: 0.48841

Collected Steps per Second: 22,848.85147
Overall Steps per Second: 10,608.43468

Timestep Collection Time: 2.18829
Timestep Consumption Time: 2.52494
PPO Batch Consumption Time: 0.29195
Total Iteration Time: 4.71323

Cumulative Model Updates: 52,886
Cumulative Timesteps: 441,188,312

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 441188312...
Checkpoint 441188312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 845.66570
Policy Entropy: 3.36201
Value Function Loss: 0.00316

Mean KL Divergence: 0.00715
SB3 Clip Fraction: 0.07868
Policy Update Magnitude: 0.50862
Value Function Update Magnitude: 0.48139

Collected Steps per Second: 23,113.87858
Overall Steps per Second: 10,857.03145

Timestep Collection Time: 2.16381
Timestep Consumption Time: 2.44279
PPO Batch Consumption Time: 0.28034
Total Iteration Time: 4.60660

Cumulative Model Updates: 52,892
Cumulative Timesteps: 441,238,326

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 754.03046
Policy Entropy: 3.37463
Value Function Loss: 0.00317

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.09229
Policy Update Magnitude: 0.50160
Value Function Update Magnitude: 0.46457

Collected Steps per Second: 22,767.24826
Overall Steps per Second: 10,611.61399

Timestep Collection Time: 2.19737
Timestep Consumption Time: 2.51709
PPO Batch Consumption Time: 0.29435
Total Iteration Time: 4.71446

Cumulative Model Updates: 52,898
Cumulative Timesteps: 441,288,354

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 441288354...
Checkpoint 441288354 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,007.59367
Policy Entropy: 3.37366
Value Function Loss: 0.00314

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.08870
Policy Update Magnitude: 0.50003
Value Function Update Magnitude: 0.46721

Collected Steps per Second: 23,036.37542
Overall Steps per Second: 10,734.37291

Timestep Collection Time: 2.17074
Timestep Consumption Time: 2.48775
PPO Batch Consumption Time: 0.29127
Total Iteration Time: 4.65849

Cumulative Model Updates: 52,904
Cumulative Timesteps: 441,338,360

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,283.18216
Policy Entropy: 3.38755
Value Function Loss: 0.00325

Mean KL Divergence: 0.00627
SB3 Clip Fraction: 0.06909
Policy Update Magnitude: 0.50505
Value Function Update Magnitude: 0.48275

Collected Steps per Second: 23,126.01222
Overall Steps per Second: 10,740.15043

Timestep Collection Time: 2.16319
Timestep Consumption Time: 2.49466
PPO Batch Consumption Time: 0.29423
Total Iteration Time: 4.65785

Cumulative Model Updates: 52,910
Cumulative Timesteps: 441,388,386

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 441388386...
Checkpoint 441388386 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 740.19220
Policy Entropy: 3.38388
Value Function Loss: 0.00329

Mean KL Divergence: 0.00648
SB3 Clip Fraction: 0.07248
Policy Update Magnitude: 0.51580
Value Function Update Magnitude: 0.49995

Collected Steps per Second: 23,016.11188
Overall Steps per Second: 10,869.79598

Timestep Collection Time: 2.17335
Timestep Consumption Time: 2.42858
PPO Batch Consumption Time: 0.28679
Total Iteration Time: 4.60193

Cumulative Model Updates: 52,916
Cumulative Timesteps: 441,438,408

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 679.22009
Policy Entropy: 3.36876
Value Function Loss: 0.00335

Mean KL Divergence: 0.00664
SB3 Clip Fraction: 0.07344
Policy Update Magnitude: 0.51338
Value Function Update Magnitude: 0.49363

Collected Steps per Second: 22,159.15123
Overall Steps per Second: 10,650.45819

Timestep Collection Time: 2.25767
Timestep Consumption Time: 2.43959
PPO Batch Consumption Time: 0.28074
Total Iteration Time: 4.69726

Cumulative Model Updates: 52,922
Cumulative Timesteps: 441,488,436

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 441488436...
Checkpoint 441488436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 686.18496
Policy Entropy: 3.36139
Value Function Loss: 0.00346

Mean KL Divergence: 0.00708
SB3 Clip Fraction: 0.07787
Policy Update Magnitude: 0.52112
Value Function Update Magnitude: 0.49419

Collected Steps per Second: 22,407.58551
Overall Steps per Second: 10,697.60862

Timestep Collection Time: 2.23264
Timestep Consumption Time: 2.44392
PPO Batch Consumption Time: 0.27878
Total Iteration Time: 4.67656

Cumulative Model Updates: 52,928
Cumulative Timesteps: 441,538,464

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 664.78176
Policy Entropy: 3.35906
Value Function Loss: 0.00341

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.09422
Policy Update Magnitude: 0.52060
Value Function Update Magnitude: 0.51427

Collected Steps per Second: 22,421.26238
Overall Steps per Second: 10,535.38836

Timestep Collection Time: 2.23119
Timestep Consumption Time: 2.51719
PPO Batch Consumption Time: 0.29267
Total Iteration Time: 4.74838

Cumulative Model Updates: 52,934
Cumulative Timesteps: 441,588,490

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 441588490...
Checkpoint 441588490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,714.69727
Policy Entropy: 3.38317
Value Function Loss: 0.00337

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.09369
Policy Update Magnitude: 0.52294
Value Function Update Magnitude: 0.51911

Collected Steps per Second: 22,869.07941
Overall Steps per Second: 10,771.66311

Timestep Collection Time: 2.18776
Timestep Consumption Time: 2.45702
PPO Batch Consumption Time: 0.28823
Total Iteration Time: 4.64478

Cumulative Model Updates: 52,940
Cumulative Timesteps: 441,638,522

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,448.35687
Policy Entropy: 3.38082
Value Function Loss: 0.00332

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.09653
Policy Update Magnitude: 0.51891
Value Function Update Magnitude: 0.50682

Collected Steps per Second: 22,799.53996
Overall Steps per Second: 10,659.37303

Timestep Collection Time: 2.19425
Timestep Consumption Time: 2.49908
PPO Batch Consumption Time: 0.28715
Total Iteration Time: 4.69333

Cumulative Model Updates: 52,946
Cumulative Timesteps: 441,688,550

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 441688550...
Checkpoint 441688550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 965.96546
Policy Entropy: 3.36962
Value Function Loss: 0.00328

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.10937
Policy Update Magnitude: 0.51020
Value Function Update Magnitude: 0.50109

Collected Steps per Second: 23,049.08616
Overall Steps per Second: 10,661.16284

Timestep Collection Time: 2.16989
Timestep Consumption Time: 2.52134
PPO Batch Consumption Time: 0.29456
Total Iteration Time: 4.69123

Cumulative Model Updates: 52,952
Cumulative Timesteps: 441,738,564

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,023.32023
Policy Entropy: 3.36953
Value Function Loss: 0.00340

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.10271
Policy Update Magnitude: 0.51673
Value Function Update Magnitude: 0.50609

Collected Steps per Second: 22,776.75758
Overall Steps per Second: 10,808.18515

Timestep Collection Time: 2.19548
Timestep Consumption Time: 2.43120
PPO Batch Consumption Time: 0.28058
Total Iteration Time: 4.62668

Cumulative Model Updates: 52,958
Cumulative Timesteps: 441,788,570

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 441788570...
Checkpoint 441788570 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,025.90826
Policy Entropy: 3.37642
Value Function Loss: 0.00332

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.08305
Policy Update Magnitude: 0.51589
Value Function Update Magnitude: 0.50224

Collected Steps per Second: 22,649.44321
Overall Steps per Second: 10,800.10645

Timestep Collection Time: 2.20809
Timestep Consumption Time: 2.42261
PPO Batch Consumption Time: 0.27918
Total Iteration Time: 4.63070

Cumulative Model Updates: 52,964
Cumulative Timesteps: 441,838,582

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 708.95494
Policy Entropy: 3.37465
Value Function Loss: 0.00340

Mean KL Divergence: 0.00588
SB3 Clip Fraction: 0.06725
Policy Update Magnitude: 0.51587
Value Function Update Magnitude: 0.49102

Collected Steps per Second: 21,728.71638
Overall Steps per Second: 10,323.45810

Timestep Collection Time: 2.30165
Timestep Consumption Time: 2.54285
PPO Batch Consumption Time: 0.29342
Total Iteration Time: 4.84450

Cumulative Model Updates: 52,970
Cumulative Timesteps: 441,888,594

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 441888594...
Checkpoint 441888594 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 959.31902
Policy Entropy: 3.36292
Value Function Loss: 0.00353

Mean KL Divergence: 0.00684
SB3 Clip Fraction: 0.07672
Policy Update Magnitude: 0.52329
Value Function Update Magnitude: 0.49736

Collected Steps per Second: 22,573.68428
Overall Steps per Second: 10,737.09394

Timestep Collection Time: 2.21621
Timestep Consumption Time: 2.44315
PPO Batch Consumption Time: 0.28717
Total Iteration Time: 4.65936

Cumulative Model Updates: 52,976
Cumulative Timesteps: 441,938,622

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 745.58043
Policy Entropy: 3.34791
Value Function Loss: 0.00358

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.09222
Policy Update Magnitude: 0.53275
Value Function Update Magnitude: 0.49431

Collected Steps per Second: 22,274.83835
Overall Steps per Second: 10,634.06438

Timestep Collection Time: 2.24612
Timestep Consumption Time: 2.45876
PPO Batch Consumption Time: 0.29001
Total Iteration Time: 4.70488

Cumulative Model Updates: 52,982
Cumulative Timesteps: 441,988,654

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 441988654...
Checkpoint 441988654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,510.98745
Policy Entropy: 3.34612
Value Function Loss: 0.00348

Mean KL Divergence: 0.00694
SB3 Clip Fraction: 0.07743
Policy Update Magnitude: 0.53839
Value Function Update Magnitude: 0.48835

Collected Steps per Second: 22,766.13347
Overall Steps per Second: 10,823.90482

Timestep Collection Time: 2.19660
Timestep Consumption Time: 2.42355
PPO Batch Consumption Time: 0.27958
Total Iteration Time: 4.62014

Cumulative Model Updates: 52,988
Cumulative Timesteps: 442,038,662

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,489.34598
Policy Entropy: 3.35051
Value Function Loss: 0.00323

Mean KL Divergence: 0.00737
SB3 Clip Fraction: 0.08244
Policy Update Magnitude: 0.52080
Value Function Update Magnitude: 0.48047

Collected Steps per Second: 22,374.09729
Overall Steps per Second: 10,568.14981

Timestep Collection Time: 2.23580
Timestep Consumption Time: 2.49767
PPO Batch Consumption Time: 0.29410
Total Iteration Time: 4.73347

Cumulative Model Updates: 52,994
Cumulative Timesteps: 442,088,686

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 442088686...
Checkpoint 442088686 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,371.88186
Policy Entropy: 3.35294
Value Function Loss: 0.00314

Mean KL Divergence: 0.00733
SB3 Clip Fraction: 0.08246
Policy Update Magnitude: 0.51003
Value Function Update Magnitude: 0.46533

Collected Steps per Second: 23,012.54508
Overall Steps per Second: 10,600.11982

Timestep Collection Time: 2.17316
Timestep Consumption Time: 2.54471
PPO Batch Consumption Time: 0.29464
Total Iteration Time: 4.71787

Cumulative Model Updates: 53,000
Cumulative Timesteps: 442,138,696

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 980.95960
Policy Entropy: 3.36039
Value Function Loss: 0.00313

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.08849
Policy Update Magnitude: 0.49961
Value Function Update Magnitude: 0.45743

Collected Steps per Second: 22,917.97471
Overall Steps per Second: 10,857.17696

Timestep Collection Time: 2.18265
Timestep Consumption Time: 2.42462
PPO Batch Consumption Time: 0.28019
Total Iteration Time: 4.60728

Cumulative Model Updates: 53,006
Cumulative Timesteps: 442,188,718

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 442188718...
Checkpoint 442188718 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,256.71801
Policy Entropy: 3.36569
Value Function Loss: 0.00317

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.09583
Policy Update Magnitude: 0.50132
Value Function Update Magnitude: 0.47730

Collected Steps per Second: 22,888.73210
Overall Steps per Second: 10,704.72899

Timestep Collection Time: 2.18483
Timestep Consumption Time: 2.48675
PPO Batch Consumption Time: 0.29501
Total Iteration Time: 4.67158

Cumulative Model Updates: 53,012
Cumulative Timesteps: 442,238,726

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 984.54712
Policy Entropy: 3.36786
Value Function Loss: 0.00317

Mean KL Divergence: 0.01086
SB3 Clip Fraction: 0.11038
Policy Update Magnitude: 0.50038
Value Function Update Magnitude: 0.48354

Collected Steps per Second: 23,116.50501
Overall Steps per Second: 10,965.85343

Timestep Collection Time: 2.16425
Timestep Consumption Time: 2.39809
PPO Batch Consumption Time: 0.27921
Total Iteration Time: 4.56234

Cumulative Model Updates: 53,018
Cumulative Timesteps: 442,288,756

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 442288756...
Checkpoint 442288756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,473.72974
Policy Entropy: 3.37515
Value Function Loss: 0.00309

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.09661
Policy Update Magnitude: 0.50281
Value Function Update Magnitude: 0.46888

Collected Steps per Second: 22,857.68091
Overall Steps per Second: 10,645.62021

Timestep Collection Time: 2.18780
Timestep Consumption Time: 2.50972
PPO Batch Consumption Time: 0.29414
Total Iteration Time: 4.69752

Cumulative Model Updates: 53,024
Cumulative Timesteps: 442,338,764

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,380.25643
Policy Entropy: 3.38120
Value Function Loss: 0.00333

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.09292
Policy Update Magnitude: 0.50593
Value Function Update Magnitude: 0.47560

Collected Steps per Second: 22,765.36818
Overall Steps per Second: 10,780.66718

Timestep Collection Time: 2.19693
Timestep Consumption Time: 2.44230
PPO Batch Consumption Time: 0.28079
Total Iteration Time: 4.63923

Cumulative Model Updates: 53,030
Cumulative Timesteps: 442,388,778

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 442388778...
Checkpoint 442388778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,955.40967
Policy Entropy: 3.37876
Value Function Loss: 0.00316

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.08947
Policy Update Magnitude: 0.51168
Value Function Update Magnitude: 0.47967

Collected Steps per Second: 22,520.15699
Overall Steps per Second: 10,773.92539

Timestep Collection Time: 2.22032
Timestep Consumption Time: 2.42070
PPO Batch Consumption Time: 0.27866
Total Iteration Time: 4.64102

Cumulative Model Updates: 53,036
Cumulative Timesteps: 442,438,780

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,309.77774
Policy Entropy: 3.36463
Value Function Loss: 0.00317

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.08866
Policy Update Magnitude: 0.50698
Value Function Update Magnitude: 0.47064

Collected Steps per Second: 22,611.42929
Overall Steps per Second: 10,808.95749

Timestep Collection Time: 2.21180
Timestep Consumption Time: 2.41510
PPO Batch Consumption Time: 0.28054
Total Iteration Time: 4.62690

Cumulative Model Updates: 53,042
Cumulative Timesteps: 442,488,792

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 442488792...
Checkpoint 442488792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 999.28562
Policy Entropy: 3.36306
Value Function Loss: 0.00324

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.08476
Policy Update Magnitude: 0.50558
Value Function Update Magnitude: 0.47236

Collected Steps per Second: 22,541.04641
Overall Steps per Second: 10,697.60024

Timestep Collection Time: 2.21871
Timestep Consumption Time: 2.45636
PPO Batch Consumption Time: 0.28775
Total Iteration Time: 4.67507

Cumulative Model Updates: 53,048
Cumulative Timesteps: 442,538,804

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 925.85054
Policy Entropy: 3.35515
Value Function Loss: 0.00338

Mean KL Divergence: 0.00699
SB3 Clip Fraction: 0.07771
Policy Update Magnitude: 0.51566
Value Function Update Magnitude: 0.47798

Collected Steps per Second: 22,634.47963
Overall Steps per Second: 10,826.48443

Timestep Collection Time: 2.20946
Timestep Consumption Time: 2.40977
PPO Batch Consumption Time: 0.28012
Total Iteration Time: 4.61923

Cumulative Model Updates: 53,054
Cumulative Timesteps: 442,588,814

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 442588814...
Checkpoint 442588814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,938.05827
Policy Entropy: 3.36241
Value Function Loss: 0.00320

Mean KL Divergence: 0.00743
SB3 Clip Fraction: 0.08431
Policy Update Magnitude: 0.51416
Value Function Update Magnitude: 0.46852

Collected Steps per Second: 22,546.04202
Overall Steps per Second: 10,727.20125

Timestep Collection Time: 2.21831
Timestep Consumption Time: 2.44405
PPO Batch Consumption Time: 0.28467
Total Iteration Time: 4.66235

Cumulative Model Updates: 53,060
Cumulative Timesteps: 442,638,828

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 819.25714
Policy Entropy: 3.36551
Value Function Loss: 0.00317

Mean KL Divergence: 0.00650
SB3 Clip Fraction: 0.07418
Policy Update Magnitude: 0.50397
Value Function Update Magnitude: 0.45012

Collected Steps per Second: 22,933.00875
Overall Steps per Second: 10,602.98229

Timestep Collection Time: 2.18096
Timestep Consumption Time: 2.53620
PPO Batch Consumption Time: 0.29117
Total Iteration Time: 4.71716

Cumulative Model Updates: 53,066
Cumulative Timesteps: 442,688,844

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 442688844...
Checkpoint 442688844 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 846.96944
Policy Entropy: 3.38138
Value Function Loss: 0.00304

Mean KL Divergence: 0.00588
SB3 Clip Fraction: 0.06650
Policy Update Magnitude: 0.50090
Value Function Update Magnitude: 0.44314

Collected Steps per Second: 22,977.95912
Overall Steps per Second: 10,825.47071

Timestep Collection Time: 2.17687
Timestep Consumption Time: 2.44372
PPO Batch Consumption Time: 0.28004
Total Iteration Time: 4.62058

Cumulative Model Updates: 53,072
Cumulative Timesteps: 442,738,864

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,723.07508
Policy Entropy: 3.36997
Value Function Loss: 0.00311

Mean KL Divergence: 0.00628
SB3 Clip Fraction: 0.07203
Policy Update Magnitude: 0.50030
Value Function Update Magnitude: 0.45671

Collected Steps per Second: 23,140.61058
Overall Steps per Second: 10,757.17051

Timestep Collection Time: 2.16140
Timestep Consumption Time: 2.48815
PPO Batch Consumption Time: 0.29066
Total Iteration Time: 4.64955

Cumulative Model Updates: 53,078
Cumulative Timesteps: 442,788,880

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 442788880...
Checkpoint 442788880 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,534.76141
Policy Entropy: 3.37350
Value Function Loss: 0.00313

Mean KL Divergence: 0.00622
SB3 Clip Fraction: 0.07067
Policy Update Magnitude: 0.49535
Value Function Update Magnitude: 0.46505

Collected Steps per Second: 23,043.76726
Overall Steps per Second: 10,870.05246

Timestep Collection Time: 2.16987
Timestep Consumption Time: 2.43011
PPO Batch Consumption Time: 0.28151
Total Iteration Time: 4.59998

Cumulative Model Updates: 53,084
Cumulative Timesteps: 442,838,882

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,956.48023
Policy Entropy: 3.35980
Value Function Loss: 0.00320

Mean KL Divergence: 0.00605
SB3 Clip Fraction: 0.06891
Policy Update Magnitude: 0.50195
Value Function Update Magnitude: 0.47046

Collected Steps per Second: 22,894.03190
Overall Steps per Second: 10,681.32660

Timestep Collection Time: 2.18502
Timestep Consumption Time: 2.49829
PPO Batch Consumption Time: 0.28894
Total Iteration Time: 4.68331

Cumulative Model Updates: 53,090
Cumulative Timesteps: 442,888,906

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 442888906...
Checkpoint 442888906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,121.65150
Policy Entropy: 3.37451
Value Function Loss: 0.00328

Mean KL Divergence: 0.00602
SB3 Clip Fraction: 0.06799
Policy Update Magnitude: 0.51091
Value Function Update Magnitude: 0.47746

Collected Steps per Second: 22,735.76834
Overall Steps per Second: 10,801.70637

Timestep Collection Time: 2.19953
Timestep Consumption Time: 2.43011
PPO Batch Consumption Time: 0.28014
Total Iteration Time: 4.62964

Cumulative Model Updates: 53,096
Cumulative Timesteps: 442,938,914

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,185.76538
Policy Entropy: 3.37107
Value Function Loss: 0.00333

Mean KL Divergence: 0.00678
SB3 Clip Fraction: 0.07757
Policy Update Magnitude: 0.51376
Value Function Update Magnitude: 0.48474

Collected Steps per Second: 22,135.15245
Overall Steps per Second: 10,531.51573

Timestep Collection Time: 2.25903
Timestep Consumption Time: 2.48900
PPO Batch Consumption Time: 0.29425
Total Iteration Time: 4.74803

Cumulative Model Updates: 53,102
Cumulative Timesteps: 442,988,918

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 442988918...
Checkpoint 442988918 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,131.63747
Policy Entropy: 3.36395
Value Function Loss: 0.00327

Mean KL Divergence: 0.00707
SB3 Clip Fraction: 0.07928
Policy Update Magnitude: 0.51310
Value Function Update Magnitude: 0.48806

Collected Steps per Second: 22,297.88206
Overall Steps per Second: 10,673.23504

Timestep Collection Time: 2.24461
Timestep Consumption Time: 2.44469
PPO Batch Consumption Time: 0.28880
Total Iteration Time: 4.68930

Cumulative Model Updates: 53,108
Cumulative Timesteps: 443,038,968

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,173.33212
Policy Entropy: 3.37067
Value Function Loss: 0.00336

Mean KL Divergence: 0.00642
SB3 Clip Fraction: 0.07203
Policy Update Magnitude: 0.51307
Value Function Update Magnitude: 0.48177

Collected Steps per Second: 22,402.68807
Overall Steps per Second: 10,776.04962

Timestep Collection Time: 2.23304
Timestep Consumption Time: 2.40930
PPO Batch Consumption Time: 0.28072
Total Iteration Time: 4.64233

Cumulative Model Updates: 53,114
Cumulative Timesteps: 443,088,994

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 443088994...
Checkpoint 443088994 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 944.79481
Policy Entropy: 3.36985
Value Function Loss: 0.00334

Mean KL Divergence: 0.00689
SB3 Clip Fraction: 0.07827
Policy Update Magnitude: 0.51397
Value Function Update Magnitude: 0.47861

Collected Steps per Second: 22,493.61431
Overall Steps per Second: 10,715.98534

Timestep Collection Time: 2.22356
Timestep Consumption Time: 2.44386
PPO Batch Consumption Time: 0.28007
Total Iteration Time: 4.66742

Cumulative Model Updates: 53,120
Cumulative Timesteps: 443,139,010

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,239.06620
Policy Entropy: 3.36767
Value Function Loss: 0.00333

Mean KL Divergence: 0.00698
SB3 Clip Fraction: 0.07980
Policy Update Magnitude: 0.50617
Value Function Update Magnitude: 0.48598

Collected Steps per Second: 22,743.21770
Overall Steps per Second: 10,593.93080

Timestep Collection Time: 2.19890
Timestep Consumption Time: 2.52173
PPO Batch Consumption Time: 0.29304
Total Iteration Time: 4.72063

Cumulative Model Updates: 53,126
Cumulative Timesteps: 443,189,020

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 443189020...
Checkpoint 443189020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,307.75518
Policy Entropy: 3.35003
Value Function Loss: 0.00343

Mean KL Divergence: 0.00701
SB3 Clip Fraction: 0.07995
Policy Update Magnitude: 0.50250
Value Function Update Magnitude: 0.49172

Collected Steps per Second: 23,101.18060
Overall Steps per Second: 10,882.75076

Timestep Collection Time: 2.16491
Timestep Consumption Time: 2.43062
PPO Batch Consumption Time: 0.28136
Total Iteration Time: 4.59553

Cumulative Model Updates: 53,132
Cumulative Timesteps: 443,239,032

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 953.03339
Policy Entropy: 3.34834
Value Function Loss: 0.00339

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.09860
Policy Update Magnitude: 0.51699
Value Function Update Magnitude: 0.50612

Collected Steps per Second: 22,829.93007
Overall Steps per Second: 10,740.36343

Timestep Collection Time: 2.19107
Timestep Consumption Time: 2.46631
PPO Batch Consumption Time: 0.29132
Total Iteration Time: 4.65738

Cumulative Model Updates: 53,138
Cumulative Timesteps: 443,289,054

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 443289054...
Checkpoint 443289054 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,359.42859
Policy Entropy: 3.36011
Value Function Loss: 0.00341

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.10338
Policy Update Magnitude: 0.51673
Value Function Update Magnitude: 0.51241

Collected Steps per Second: 23,274.09072
Overall Steps per Second: 10,894.58183

Timestep Collection Time: 2.14900
Timestep Consumption Time: 2.44191
PPO Batch Consumption Time: 0.28126
Total Iteration Time: 4.59091

Cumulative Model Updates: 53,144
Cumulative Timesteps: 443,339,070

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,468.91603
Policy Entropy: 3.37670
Value Function Loss: 0.00317

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.09845
Policy Update Magnitude: 0.50142
Value Function Update Magnitude: 0.49719

Collected Steps per Second: 22,676.50809
Overall Steps per Second: 10,579.81857

Timestep Collection Time: 2.20545
Timestep Consumption Time: 2.52166
PPO Batch Consumption Time: 0.29475
Total Iteration Time: 4.72711

Cumulative Model Updates: 53,150
Cumulative Timesteps: 443,389,082

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 443389082...
Checkpoint 443389082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,273.52590
Policy Entropy: 3.37566
Value Function Loss: 0.00320

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.10603
Policy Update Magnitude: 0.48698
Value Function Update Magnitude: 0.48243

Collected Steps per Second: 23,097.88574
Overall Steps per Second: 10,756.22760

Timestep Collection Time: 2.16609
Timestep Consumption Time: 2.48536
PPO Batch Consumption Time: 0.29149
Total Iteration Time: 4.65144

Cumulative Model Updates: 53,156
Cumulative Timesteps: 443,439,114

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,391.20440
Policy Entropy: 3.37631
Value Function Loss: 0.00322

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.10677
Policy Update Magnitude: 0.48420
Value Function Update Magnitude: 0.46622

Collected Steps per Second: 22,905.95440
Overall Steps per Second: 10,686.14132

Timestep Collection Time: 2.18389
Timestep Consumption Time: 2.49732
PPO Batch Consumption Time: 0.28985
Total Iteration Time: 4.68120

Cumulative Model Updates: 53,162
Cumulative Timesteps: 443,489,138

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 443489138...
Checkpoint 443489138 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 805.80354
Policy Entropy: 3.38351
Value Function Loss: 0.00316

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.10515
Policy Update Magnitude: 0.48205
Value Function Update Magnitude: 0.46777

Collected Steps per Second: 22,277.11717
Overall Steps per Second: 10,704.43648

Timestep Collection Time: 2.24562
Timestep Consumption Time: 2.42777
PPO Batch Consumption Time: 0.27942
Total Iteration Time: 4.67339

Cumulative Model Updates: 53,168
Cumulative Timesteps: 443,539,164

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,604.12847
Policy Entropy: 3.37609
Value Function Loss: 0.00309

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.10108
Policy Update Magnitude: 0.48306
Value Function Update Magnitude: 0.46601

Collected Steps per Second: 22,458.52104
Overall Steps per Second: 10,588.14302

Timestep Collection Time: 2.22704
Timestep Consumption Time: 2.49674
PPO Batch Consumption Time: 0.29175
Total Iteration Time: 4.72377

Cumulative Model Updates: 53,174
Cumulative Timesteps: 443,589,180

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 443589180...
Checkpoint 443589180 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 897.71288
Policy Entropy: 3.37770
Value Function Loss: 0.00313

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.10390
Policy Update Magnitude: 0.48782
Value Function Update Magnitude: 0.47181

Collected Steps per Second: 22,333.41842
Overall Steps per Second: 10,545.49788

Timestep Collection Time: 2.23925
Timestep Consumption Time: 2.50306
PPO Batch Consumption Time: 0.29437
Total Iteration Time: 4.74231

Cumulative Model Updates: 53,180
Cumulative Timesteps: 443,639,190

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,286.48644
Policy Entropy: 3.36832
Value Function Loss: 0.00314

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.11389
Policy Update Magnitude: 0.48263
Value Function Update Magnitude: 0.47524

Collected Steps per Second: 22,659.28733
Overall Steps per Second: 10,758.60141

Timestep Collection Time: 2.20766
Timestep Consumption Time: 2.44202
PPO Batch Consumption Time: 0.28068
Total Iteration Time: 4.64968

Cumulative Model Updates: 53,186
Cumulative Timesteps: 443,689,214

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 443689214...
Checkpoint 443689214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,181.36672
Policy Entropy: 3.37759
Value Function Loss: 0.00326

Mean KL Divergence: 0.01260
SB3 Clip Fraction: 0.12574
Policy Update Magnitude: 0.48873
Value Function Update Magnitude: 0.47658

Collected Steps per Second: 22,406.35811
Overall Steps per Second: 10,744.52366

Timestep Collection Time: 2.23231
Timestep Consumption Time: 2.42290
PPO Batch Consumption Time: 0.27882
Total Iteration Time: 4.65521

Cumulative Model Updates: 53,192
Cumulative Timesteps: 443,739,232

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,214.86096
Policy Entropy: 3.38561
Value Function Loss: 0.00327

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.10606
Policy Update Magnitude: 0.48687
Value Function Update Magnitude: 0.48125

Collected Steps per Second: 22,863.89486
Overall Steps per Second: 10,796.02787

Timestep Collection Time: 2.18720
Timestep Consumption Time: 2.44487
PPO Batch Consumption Time: 0.28113
Total Iteration Time: 4.63207

Cumulative Model Updates: 53,198
Cumulative Timesteps: 443,789,240

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 443789240...
Checkpoint 443789240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,328.07862
Policy Entropy: 3.39594
Value Function Loss: 0.00352

Mean KL Divergence: 0.00710
SB3 Clip Fraction: 0.08009
Policy Update Magnitude: 0.49857
Value Function Update Magnitude: 0.49897

Collected Steps per Second: 22,441.38601
Overall Steps per Second: 10,730.95136

Timestep Collection Time: 2.22812
Timestep Consumption Time: 2.43149
PPO Batch Consumption Time: 0.28411
Total Iteration Time: 4.65961

Cumulative Model Updates: 53,204
Cumulative Timesteps: 443,839,242

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,043.61505
Policy Entropy: 3.37964
Value Function Loss: 0.00339

Mean KL Divergence: 0.00650
SB3 Clip Fraction: 0.07376
Policy Update Magnitude: 0.50650
Value Function Update Magnitude: 0.50708

Collected Steps per Second: 23,021.21036
Overall Steps per Second: 10,921.48967

Timestep Collection Time: 2.17313
Timestep Consumption Time: 2.40757
PPO Batch Consumption Time: 0.27937
Total Iteration Time: 4.58069

Cumulative Model Updates: 53,210
Cumulative Timesteps: 443,889,270

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 443889270...
Checkpoint 443889270 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,316.72520
Policy Entropy: 3.38513
Value Function Loss: 0.00343

Mean KL Divergence: 0.00637
SB3 Clip Fraction: 0.07186
Policy Update Magnitude: 0.51217
Value Function Update Magnitude: 0.51130

Collected Steps per Second: 22,402.41218
Overall Steps per Second: 10,624.72269

Timestep Collection Time: 2.23306
Timestep Consumption Time: 2.47539
PPO Batch Consumption Time: 0.29187
Total Iteration Time: 4.70845

Cumulative Model Updates: 53,216
Cumulative Timesteps: 443,939,296

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,647.56565
Policy Entropy: 3.39436
Value Function Loss: 0.00335

Mean KL Divergence: 0.00649
SB3 Clip Fraction: 0.07437
Policy Update Magnitude: 0.51494
Value Function Update Magnitude: 0.52028

Collected Steps per Second: 22,570.41952
Overall Steps per Second: 10,703.02706

Timestep Collection Time: 2.21600
Timestep Consumption Time: 2.45707
PPO Batch Consumption Time: 0.28875
Total Iteration Time: 4.67307

Cumulative Model Updates: 53,222
Cumulative Timesteps: 443,989,312

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 443989312...
Checkpoint 443989312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,346.45363
Policy Entropy: 3.41578
Value Function Loss: 0.00337

Mean KL Divergence: 0.00654
SB3 Clip Fraction: 0.07486
Policy Update Magnitude: 0.51725
Value Function Update Magnitude: 0.51838

Collected Steps per Second: 22,196.58077
Overall Steps per Second: 10,514.88071

Timestep Collection Time: 2.25269
Timestep Consumption Time: 2.50267
PPO Batch Consumption Time: 0.29323
Total Iteration Time: 4.75536

Cumulative Model Updates: 53,228
Cumulative Timesteps: 444,039,314

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,713.19781
Policy Entropy: 3.41219
Value Function Loss: 0.00326

Mean KL Divergence: 0.00601
SB3 Clip Fraction: 0.06600
Policy Update Magnitude: 0.51336
Value Function Update Magnitude: 0.48990

Collected Steps per Second: 22,524.03259
Overall Steps per Second: 10,750.13793

Timestep Collection Time: 2.22083
Timestep Consumption Time: 2.43232
PPO Batch Consumption Time: 0.28089
Total Iteration Time: 4.65315

Cumulative Model Updates: 53,234
Cumulative Timesteps: 444,089,336

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 444089336...
Checkpoint 444089336 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,221.27368
Policy Entropy: 3.39829
Value Function Loss: 0.00338

Mean KL Divergence: 0.00613
SB3 Clip Fraction: 0.06904
Policy Update Magnitude: 0.50756
Value Function Update Magnitude: 0.48358

Collected Steps per Second: 22,835.30799
Overall Steps per Second: 10,687.20935

Timestep Collection Time: 2.19047
Timestep Consumption Time: 2.48989
PPO Batch Consumption Time: 0.28911
Total Iteration Time: 4.68036

Cumulative Model Updates: 53,240
Cumulative Timesteps: 444,139,356

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,466.26981
Policy Entropy: 3.37605
Value Function Loss: 0.00337

Mean KL Divergence: 0.00658
SB3 Clip Fraction: 0.07565
Policy Update Magnitude: 0.50883
Value Function Update Magnitude: 0.51070

Collected Steps per Second: 23,140.05217
Overall Steps per Second: 10,866.44949

Timestep Collection Time: 2.16214
Timestep Consumption Time: 2.44213
PPO Batch Consumption Time: 0.28143
Total Iteration Time: 4.60426

Cumulative Model Updates: 53,246
Cumulative Timesteps: 444,189,388

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 444189388...
Checkpoint 444189388 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,696.84247
Policy Entropy: 3.38237
Value Function Loss: 0.00334

Mean KL Divergence: 0.00674
SB3 Clip Fraction: 0.07700
Policy Update Magnitude: 0.51500
Value Function Update Magnitude: 0.51454

Collected Steps per Second: 23,014.79340
Overall Steps per Second: 10,698.61164

Timestep Collection Time: 2.17252
Timestep Consumption Time: 2.50099
PPO Batch Consumption Time: 0.29226
Total Iteration Time: 4.67350

Cumulative Model Updates: 53,252
Cumulative Timesteps: 444,239,388

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 813.04468
Policy Entropy: 3.37009
Value Function Loss: 0.00345

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.08657
Policy Update Magnitude: 0.50891
Value Function Update Magnitude: 0.51275

Collected Steps per Second: 22,705.47586
Overall Steps per Second: 10,667.95435

Timestep Collection Time: 2.20246
Timestep Consumption Time: 2.48522
PPO Batch Consumption Time: 0.28928
Total Iteration Time: 4.68768

Cumulative Model Updates: 53,258
Cumulative Timesteps: 444,289,396

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 444289396...
Checkpoint 444289396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,331.96220
Policy Entropy: 3.37856
Value Function Loss: 0.00338

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.10035
Policy Update Magnitude: 0.51006
Value Function Update Magnitude: 0.51299

Collected Steps per Second: 23,068.64113
Overall Steps per Second: 10,898.74541

Timestep Collection Time: 2.16857
Timestep Consumption Time: 2.42150
PPO Batch Consumption Time: 0.27932
Total Iteration Time: 4.59007

Cumulative Model Updates: 53,264
Cumulative Timesteps: 444,339,422

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,451.28338
Policy Entropy: 3.36882
Value Function Loss: 0.00346

Mean KL Divergence: 0.01230
SB3 Clip Fraction: 0.12221
Policy Update Magnitude: 0.51276
Value Function Update Magnitude: 0.51757

Collected Steps per Second: 22,662.33912
Overall Steps per Second: 10,675.66027

Timestep Collection Time: 2.20701
Timestep Consumption Time: 2.47804
PPO Batch Consumption Time: 0.28808
Total Iteration Time: 4.68505

Cumulative Model Updates: 53,270
Cumulative Timesteps: 444,389,438

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 444389438...
Checkpoint 444389438 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,082.99273
Policy Entropy: 3.38983
Value Function Loss: 0.00310

Mean KL Divergence: 0.01059
SB3 Clip Fraction: 0.11464
Policy Update Magnitude: 0.50214
Value Function Update Magnitude: 0.50594

Collected Steps per Second: 22,088.85700
Overall Steps per Second: 10,642.69018

Timestep Collection Time: 2.26368
Timestep Consumption Time: 2.43457
PPO Batch Consumption Time: 0.28746
Total Iteration Time: 4.69825

Cumulative Model Updates: 53,276
Cumulative Timesteps: 444,439,440

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,146.94892
Policy Entropy: 3.39295
Value Function Loss: 0.00317

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.08666
Policy Update Magnitude: 0.48966
Value Function Update Magnitude: 0.48784

Collected Steps per Second: 22,674.04060
Overall Steps per Second: 10,664.99996

Timestep Collection Time: 2.20561
Timestep Consumption Time: 2.48356
PPO Batch Consumption Time: 0.28702
Total Iteration Time: 4.68917

Cumulative Model Updates: 53,282
Cumulative Timesteps: 444,489,450

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 444489450...
Checkpoint 444489450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,670.88754
Policy Entropy: 3.40619
Value Function Loss: 0.00320

Mean KL Divergence: 0.00757
SB3 Clip Fraction: 0.08750
Policy Update Magnitude: 0.48372
Value Function Update Magnitude: 0.49824

Collected Steps per Second: 22,402.17727
Overall Steps per Second: 10,608.11142

Timestep Collection Time: 2.23237
Timestep Consumption Time: 2.48194
PPO Batch Consumption Time: 0.29171
Total Iteration Time: 4.71432

Cumulative Model Updates: 53,288
Cumulative Timesteps: 444,539,460

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,183.19162
Policy Entropy: 3.39662
Value Function Loss: 0.00333

Mean KL Divergence: 0.00715
SB3 Clip Fraction: 0.08033
Policy Update Magnitude: 0.50146
Value Function Update Magnitude: 0.51286

Collected Steps per Second: 22,157.97045
Overall Steps per Second: 10,566.50457

Timestep Collection Time: 2.25689
Timestep Consumption Time: 2.47581
PPO Batch Consumption Time: 0.29270
Total Iteration Time: 4.73269

Cumulative Model Updates: 53,294
Cumulative Timesteps: 444,589,468

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 444589468...
Checkpoint 444589468 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 858.93778
Policy Entropy: 3.39477
Value Function Loss: 0.00322

Mean KL Divergence: 0.00723
SB3 Clip Fraction: 0.08135
Policy Update Magnitude: 0.51594
Value Function Update Magnitude: 0.51131

Collected Steps per Second: 22,655.60481
Overall Steps per Second: 10,555.48649

Timestep Collection Time: 2.20696
Timestep Consumption Time: 2.52991
PPO Batch Consumption Time: 0.29388
Total Iteration Time: 4.73687

Cumulative Model Updates: 53,300
Cumulative Timesteps: 444,639,468

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,789.57666
Policy Entropy: 3.39987
Value Function Loss: 0.00323

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.09119
Policy Update Magnitude: 0.50967
Value Function Update Magnitude: 0.51824

Collected Steps per Second: 22,873.96405
Overall Steps per Second: 10,645.05818

Timestep Collection Time: 2.18677
Timestep Consumption Time: 2.51213
PPO Batch Consumption Time: 0.28888
Total Iteration Time: 4.69889

Cumulative Model Updates: 53,306
Cumulative Timesteps: 444,689,488

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 444689488...
Checkpoint 444689488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,044.47171
Policy Entropy: 3.39268
Value Function Loss: 0.00315

Mean KL Divergence: 0.00758
SB3 Clip Fraction: 0.08692
Policy Update Magnitude: 0.50101
Value Function Update Magnitude: 0.51074

Collected Steps per Second: 22,917.09652
Overall Steps per Second: 10,789.34698

Timestep Collection Time: 2.18195
Timestep Consumption Time: 2.45262
PPO Batch Consumption Time: 0.28053
Total Iteration Time: 4.63457

Cumulative Model Updates: 53,312
Cumulative Timesteps: 444,739,492

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,690.82983
Policy Entropy: 3.39184
Value Function Loss: 0.00323

Mean KL Divergence: 0.00655
SB3 Clip Fraction: 0.07260
Policy Update Magnitude: 0.49522
Value Function Update Magnitude: 0.50657

Collected Steps per Second: 22,634.62776
Overall Steps per Second: 10,611.82108

Timestep Collection Time: 2.20909
Timestep Consumption Time: 2.50282
PPO Batch Consumption Time: 0.29425
Total Iteration Time: 4.71192

Cumulative Model Updates: 53,318
Cumulative Timesteps: 444,789,494

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 444789494...
Checkpoint 444789494 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,078.13349
Policy Entropy: 3.38982
Value Function Loss: 0.00320

Mean KL Divergence: 0.00676
SB3 Clip Fraction: 0.07669
Policy Update Magnitude: 0.49062
Value Function Update Magnitude: 0.51106

Collected Steps per Second: 23,019.97290
Overall Steps per Second: 10,746.86571

Timestep Collection Time: 2.17333
Timestep Consumption Time: 2.48198
PPO Batch Consumption Time: 0.29221
Total Iteration Time: 4.65531

Cumulative Model Updates: 53,324
Cumulative Timesteps: 444,839,524

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,415.97162
Policy Entropy: 3.40091
Value Function Loss: 0.00332

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.09035
Policy Update Magnitude: 0.49643
Value Function Update Magnitude: 0.50187

Collected Steps per Second: 22,867.05863
Overall Steps per Second: 10,723.43112

Timestep Collection Time: 2.18734
Timestep Consumption Time: 2.47703
PPO Batch Consumption Time: 0.28652
Total Iteration Time: 4.66437

Cumulative Model Updates: 53,330
Cumulative Timesteps: 444,889,542

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 444889542...
Checkpoint 444889542 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,304.32012
Policy Entropy: 3.40160
Value Function Loss: 0.00327

Mean KL Divergence: 0.00662
SB3 Clip Fraction: 0.07533
Policy Update Magnitude: 0.50779
Value Function Update Magnitude: 0.50977

Collected Steps per Second: 22,761.76162
Overall Steps per Second: 10,713.25085

Timestep Collection Time: 2.19755
Timestep Consumption Time: 2.47144
PPO Batch Consumption Time: 0.29446
Total Iteration Time: 4.66898

Cumulative Model Updates: 53,336
Cumulative Timesteps: 444,939,562

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 925.30956
Policy Entropy: 3.39069
Value Function Loss: 0.00329

Mean KL Divergence: 0.00643
SB3 Clip Fraction: 0.07002
Policy Update Magnitude: 0.51730
Value Function Update Magnitude: 0.51007

Collected Steps per Second: 22,298.06203
Overall Steps per Second: 10,638.84530

Timestep Collection Time: 2.24289
Timestep Consumption Time: 2.45800
PPO Batch Consumption Time: 0.28852
Total Iteration Time: 4.70089

Cumulative Model Updates: 53,342
Cumulative Timesteps: 444,989,574

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 444989574...
Checkpoint 444989574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,411.17161
Policy Entropy: 3.39827
Value Function Loss: 0.00321

Mean KL Divergence: 0.00714
SB3 Clip Fraction: 0.08066
Policy Update Magnitude: 0.51018
Value Function Update Magnitude: 0.50098

Collected Steps per Second: 22,375.25749
Overall Steps per Second: 10,810.81572

Timestep Collection Time: 2.23551
Timestep Consumption Time: 2.39134
PPO Batch Consumption Time: 0.27986
Total Iteration Time: 4.62685

Cumulative Model Updates: 53,348
Cumulative Timesteps: 445,039,594

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,562.75040
Policy Entropy: 3.39722
Value Function Loss: 0.00326

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.08946
Policy Update Magnitude: 0.49888
Value Function Update Magnitude: 0.49678

Collected Steps per Second: 22,511.25968
Overall Steps per Second: 10,544.97218

Timestep Collection Time: 2.22209
Timestep Consumption Time: 2.52159
PPO Batch Consumption Time: 0.29376
Total Iteration Time: 4.74368

Cumulative Model Updates: 53,354
Cumulative Timesteps: 445,089,616

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 445089616...
Checkpoint 445089616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,606.09792
Policy Entropy: 3.38111
Value Function Loss: 0.00319

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.09294
Policy Update Magnitude: 0.48860
Value Function Update Magnitude: 0.49963

Collected Steps per Second: 22,807.01090
Overall Steps per Second: 10,599.98753

Timestep Collection Time: 2.19266
Timestep Consumption Time: 2.52508
PPO Batch Consumption Time: 0.29456
Total Iteration Time: 4.71774

Cumulative Model Updates: 53,360
Cumulative Timesteps: 445,139,624

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,197.16422
Policy Entropy: 3.37562
Value Function Loss: 0.00334

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.10109
Policy Update Magnitude: 0.49456
Value Function Update Magnitude: 0.50411

Collected Steps per Second: 23,130.52530
Overall Steps per Second: 10,845.54230

Timestep Collection Time: 2.16260
Timestep Consumption Time: 2.44962
PPO Batch Consumption Time: 0.28006
Total Iteration Time: 4.61222

Cumulative Model Updates: 53,366
Cumulative Timesteps: 445,189,646

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 445189646...
Checkpoint 445189646 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,400.43847
Policy Entropy: 3.37444
Value Function Loss: 0.00329

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.09825
Policy Update Magnitude: 0.49941
Value Function Update Magnitude: 0.49849

Collected Steps per Second: 22,462.54809
Overall Steps per Second: 10,672.17555

Timestep Collection Time: 2.22726
Timestep Consumption Time: 2.46063
PPO Batch Consumption Time: 0.28523
Total Iteration Time: 4.68789

Cumulative Model Updates: 53,372
Cumulative Timesteps: 445,239,676

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 662.62875
Policy Entropy: 3.39210
Value Function Loss: 0.00340

Mean KL Divergence: 0.00741
SB3 Clip Fraction: 0.08416
Policy Update Magnitude: 0.50723
Value Function Update Magnitude: 0.48245

Collected Steps per Second: 22,814.57282
Overall Steps per Second: 10,672.31852

Timestep Collection Time: 2.19298
Timestep Consumption Time: 2.49503
PPO Batch Consumption Time: 0.28796
Total Iteration Time: 4.68802

Cumulative Model Updates: 53,378
Cumulative Timesteps: 445,289,708

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 445289708...
Checkpoint 445289708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,774.95241
Policy Entropy: 3.39449
Value Function Loss: 0.00321

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.09277
Policy Update Magnitude: 0.50740
Value Function Update Magnitude: 0.47800

Collected Steps per Second: 22,947.23687
Overall Steps per Second: 10,856.95028

Timestep Collection Time: 2.17926
Timestep Consumption Time: 2.42682
PPO Batch Consumption Time: 0.28380
Total Iteration Time: 4.60608

Cumulative Model Updates: 53,384
Cumulative Timesteps: 445,339,716

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,301.15810
Policy Entropy: 3.40019
Value Function Loss: 0.00324

Mean KL Divergence: 0.00705
SB3 Clip Fraction: 0.08006
Policy Update Magnitude: 0.50335
Value Function Update Magnitude: 0.48822

Collected Steps per Second: 23,218.04951
Overall Steps per Second: 10,980.15110

Timestep Collection Time: 2.15479
Timestep Consumption Time: 2.40161
PPO Batch Consumption Time: 0.27869
Total Iteration Time: 4.55640

Cumulative Model Updates: 53,390
Cumulative Timesteps: 445,389,746

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 445389746...
Checkpoint 445389746 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,469.39658
Policy Entropy: 3.39115
Value Function Loss: 0.00313

Mean KL Divergence: 0.00678
SB3 Clip Fraction: 0.07628
Policy Update Magnitude: 0.50282
Value Function Update Magnitude: 0.48286

Collected Steps per Second: 22,470.84831
Overall Steps per Second: 10,648.09413

Timestep Collection Time: 2.22644
Timestep Consumption Time: 2.47205
PPO Batch Consumption Time: 0.29414
Total Iteration Time: 4.69849

Cumulative Model Updates: 53,396
Cumulative Timesteps: 445,439,776

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,081.85236
Policy Entropy: 3.38217
Value Function Loss: 0.00335

Mean KL Divergence: 0.00695
SB3 Clip Fraction: 0.07867
Policy Update Magnitude: 0.50374
Value Function Update Magnitude: 0.50454

Collected Steps per Second: 22,676.57170
Overall Steps per Second: 10,816.98139

Timestep Collection Time: 2.20580
Timestep Consumption Time: 2.41841
PPO Batch Consumption Time: 0.28029
Total Iteration Time: 4.62421

Cumulative Model Updates: 53,402
Cumulative Timesteps: 445,489,796

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 445489796...
Checkpoint 445489796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,808.03242
Policy Entropy: 3.36913
Value Function Loss: 0.00337

Mean KL Divergence: 0.00677
SB3 Clip Fraction: 0.07703
Policy Update Magnitude: 0.51433
Value Function Update Magnitude: 0.51262

Collected Steps per Second: 22,262.67634
Overall Steps per Second: 10,652.00804

Timestep Collection Time: 2.24600
Timestep Consumption Time: 2.44814
PPO Batch Consumption Time: 0.28624
Total Iteration Time: 4.69414

Cumulative Model Updates: 53,408
Cumulative Timesteps: 445,539,798

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,012.34452
Policy Entropy: 3.37220
Value Function Loss: 0.00343

Mean KL Divergence: 0.00713
SB3 Clip Fraction: 0.08013
Policy Update Magnitude: 0.52380
Value Function Update Magnitude: 0.51210

Collected Steps per Second: 22,627.68071
Overall Steps per Second: 10,692.38918

Timestep Collection Time: 2.20995
Timestep Consumption Time: 2.46684
PPO Batch Consumption Time: 0.28854
Total Iteration Time: 4.67678

Cumulative Model Updates: 53,414
Cumulative Timesteps: 445,589,804

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 445589804...
Checkpoint 445589804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,171.46576
Policy Entropy: 3.37537
Value Function Loss: 0.00344

Mean KL Divergence: 0.00598
SB3 Clip Fraction: 0.06563
Policy Update Magnitude: 0.52584
Value Function Update Magnitude: 0.50749

Collected Steps per Second: 22,132.47890
Overall Steps per Second: 10,592.77711

Timestep Collection Time: 2.26030
Timestep Consumption Time: 2.46235
PPO Batch Consumption Time: 0.29169
Total Iteration Time: 4.72265

Cumulative Model Updates: 53,420
Cumulative Timesteps: 445,639,830

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,408.72319
Policy Entropy: 3.37335
Value Function Loss: 0.00337

Mean KL Divergence: 0.00615
SB3 Clip Fraction: 0.07012
Policy Update Magnitude: 0.52664
Value Function Update Magnitude: 0.50580

Collected Steps per Second: 23,255.76422
Overall Steps per Second: 10,740.74833

Timestep Collection Time: 2.15095
Timestep Consumption Time: 2.50627
PPO Batch Consumption Time: 0.29046
Total Iteration Time: 4.65722

Cumulative Model Updates: 53,426
Cumulative Timesteps: 445,689,852

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 445689852...
Checkpoint 445689852 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 823.89517
Policy Entropy: 3.37385
Value Function Loss: 0.00347

Mean KL Divergence: 0.00630
SB3 Clip Fraction: 0.07064
Policy Update Magnitude: 0.52427
Value Function Update Magnitude: 0.50058

Collected Steps per Second: 21,761.06478
Overall Steps per Second: 10,628.11176

Timestep Collection Time: 2.29787
Timestep Consumption Time: 2.40702
PPO Batch Consumption Time: 0.28001
Total Iteration Time: 4.70488

Cumulative Model Updates: 53,432
Cumulative Timesteps: 445,739,856

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,255.37308
Policy Entropy: 3.38190
Value Function Loss: 0.00347

Mean KL Divergence: 0.00667
SB3 Clip Fraction: 0.07663
Policy Update Magnitude: 0.52387
Value Function Update Magnitude: 0.50833

Collected Steps per Second: 22,572.49848
Overall Steps per Second: 10,818.92566

Timestep Collection Time: 2.21571
Timestep Consumption Time: 2.40712
PPO Batch Consumption Time: 0.27999
Total Iteration Time: 4.62282

Cumulative Model Updates: 53,438
Cumulative Timesteps: 445,789,870

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 445789870...
Checkpoint 445789870 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 767.79137
Policy Entropy: 3.37602
Value Function Loss: 0.00353

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.08903
Policy Update Magnitude: 0.52113
Value Function Update Magnitude: 0.51816

Collected Steps per Second: 21,990.33748
Overall Steps per Second: 10,659.40955

Timestep Collection Time: 2.27427
Timestep Consumption Time: 2.41755
PPO Batch Consumption Time: 0.27934
Total Iteration Time: 4.69182

Cumulative Model Updates: 53,444
Cumulative Timesteps: 445,839,882

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,542.56788
Policy Entropy: 3.37053
Value Function Loss: 0.00344

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.11050
Policy Update Magnitude: 0.51458
Value Function Update Magnitude: 0.51454

Collected Steps per Second: 22,916.91425
Overall Steps per Second: 10,688.64151

Timestep Collection Time: 2.18275
Timestep Consumption Time: 2.49717
PPO Batch Consumption Time: 0.29164
Total Iteration Time: 4.67992

Cumulative Model Updates: 53,450
Cumulative Timesteps: 445,889,904

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 445889904...
Checkpoint 445889904 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 715.69087
Policy Entropy: 3.35157
Value Function Loss: 0.00361

Mean KL Divergence: 0.01136
SB3 Clip Fraction: 0.11512
Policy Update Magnitude: 0.51953
Value Function Update Magnitude: 0.52151

Collected Steps per Second: 23,017.95106
Overall Steps per Second: 10,878.37875

Timestep Collection Time: 2.17352
Timestep Consumption Time: 2.42551
PPO Batch Consumption Time: 0.28026
Total Iteration Time: 4.59903

Cumulative Model Updates: 53,456
Cumulative Timesteps: 445,939,934

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 962.33047
Policy Entropy: 3.34549
Value Function Loss: 0.00356

Mean KL Divergence: 0.01083
SB3 Clip Fraction: 0.11631
Policy Update Magnitude: 0.52546
Value Function Update Magnitude: 0.52837

Collected Steps per Second: 22,971.04984
Overall Steps per Second: 10,885.11392

Timestep Collection Time: 2.17691
Timestep Consumption Time: 2.41707
PPO Batch Consumption Time: 0.28012
Total Iteration Time: 4.59398

Cumulative Model Updates: 53,462
Cumulative Timesteps: 445,989,940

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 445989940...
Checkpoint 445989940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 807.99910
Policy Entropy: 3.34000
Value Function Loss: 0.00357

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.11279
Policy Update Magnitude: 0.52475
Value Function Update Magnitude: 0.53135

Collected Steps per Second: 22,636.48505
Overall Steps per Second: 10,737.06710

Timestep Collection Time: 2.20900
Timestep Consumption Time: 2.44814
PPO Batch Consumption Time: 0.28761
Total Iteration Time: 4.65714

Cumulative Model Updates: 53,468
Cumulative Timesteps: 446,039,944

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,363.57376
Policy Entropy: 3.33891
Value Function Loss: 0.00350

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.10520
Policy Update Magnitude: 0.52140
Value Function Update Magnitude: 0.53209

Collected Steps per Second: 23,017.01012
Overall Steps per Second: 10,885.19120

Timestep Collection Time: 2.17309
Timestep Consumption Time: 2.42196
PPO Batch Consumption Time: 0.28117
Total Iteration Time: 4.59505

Cumulative Model Updates: 53,474
Cumulative Timesteps: 446,089,962

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 446089962...
Checkpoint 446089962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,288.04012
Policy Entropy: 3.32481
Value Function Loss: 0.00355

Mean KL Divergence: 0.01143
SB3 Clip Fraction: 0.11855
Policy Update Magnitude: 0.52087
Value Function Update Magnitude: 0.52306

Collected Steps per Second: 22,664.10671
Overall Steps per Second: 10,642.37993

Timestep Collection Time: 2.20728
Timestep Consumption Time: 2.49336
PPO Batch Consumption Time: 0.29551
Total Iteration Time: 4.70064

Cumulative Model Updates: 53,480
Cumulative Timesteps: 446,139,988

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,350.04339
Policy Entropy: 3.33376
Value Function Loss: 0.00338

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.11059
Policy Update Magnitude: 0.51859
Value Function Update Magnitude: 0.51752

Collected Steps per Second: 23,040.70061
Overall Steps per Second: 10,947.24233

Timestep Collection Time: 2.17007
Timestep Consumption Time: 2.39729
PPO Batch Consumption Time: 0.27910
Total Iteration Time: 4.56736

Cumulative Model Updates: 53,486
Cumulative Timesteps: 446,189,988

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 446189988...
Checkpoint 446189988 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,458.51392
Policy Entropy: 3.34173
Value Function Loss: 0.00327

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.10069
Policy Update Magnitude: 0.50537
Value Function Update Magnitude: 0.50341

Collected Steps per Second: 22,557.01952
Overall Steps per Second: 10,631.82513

Timestep Collection Time: 2.21660
Timestep Consumption Time: 2.48626
PPO Batch Consumption Time: 0.28995
Total Iteration Time: 4.70286

Cumulative Model Updates: 53,492
Cumulative Timesteps: 446,239,988

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,211.52754
Policy Entropy: 3.33863
Value Function Loss: 0.00331

Mean KL Divergence: 0.00725
SB3 Clip Fraction: 0.08324
Policy Update Magnitude: 0.49522
Value Function Update Magnitude: 0.48880

Collected Steps per Second: 22,272.09966
Overall Steps per Second: 10,521.86817

Timestep Collection Time: 2.24604
Timestep Consumption Time: 2.50825
PPO Batch Consumption Time: 0.29285
Total Iteration Time: 4.75429

Cumulative Model Updates: 53,498
Cumulative Timesteps: 446,290,012

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 446290012...
Checkpoint 446290012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,168.44693
Policy Entropy: 3.33938
Value Function Loss: 0.00341

Mean KL Divergence: 0.01066
SB3 Clip Fraction: 0.11276
Policy Update Magnitude: 0.50439
Value Function Update Magnitude: 0.50677

Collected Steps per Second: 22,414.83204
Overall Steps per Second: 10,612.67625

Timestep Collection Time: 2.23156
Timestep Consumption Time: 2.48167
PPO Batch Consumption Time: 0.29390
Total Iteration Time: 4.71323

Cumulative Model Updates: 53,504
Cumulative Timesteps: 446,340,032

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,396.99668
Policy Entropy: 3.34834
Value Function Loss: 0.00352

Mean KL Divergence: 0.01428
SB3 Clip Fraction: 0.12893
Policy Update Magnitude: 0.50574
Value Function Update Magnitude: 0.51848

Collected Steps per Second: 22,484.84058
Overall Steps per Second: 10,770.62237

Timestep Collection Time: 2.22434
Timestep Consumption Time: 2.41921
PPO Batch Consumption Time: 0.28032
Total Iteration Time: 4.64356

Cumulative Model Updates: 53,510
Cumulative Timesteps: 446,390,046

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 446390046...
Checkpoint 446390046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,389.53415
Policy Entropy: 3.35489
Value Function Loss: 0.00337

Mean KL Divergence: 0.01348
SB3 Clip Fraction: 0.12815
Policy Update Magnitude: 0.50322
Value Function Update Magnitude: 0.50880

Collected Steps per Second: 22,482.47863
Overall Steps per Second: 10,640.01460

Timestep Collection Time: 2.22475
Timestep Consumption Time: 2.47618
PPO Batch Consumption Time: 0.27963
Total Iteration Time: 4.70093

Cumulative Model Updates: 53,516
Cumulative Timesteps: 446,440,064

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 888.31939
Policy Entropy: 3.35195
Value Function Loss: 0.00336

Mean KL Divergence: 0.01277
SB3 Clip Fraction: 0.12266
Policy Update Magnitude: 0.50500
Value Function Update Magnitude: 0.49694

Collected Steps per Second: 22,711.79113
Overall Steps per Second: 10,681.16001

Timestep Collection Time: 2.20247
Timestep Consumption Time: 2.48073
PPO Batch Consumption Time: 0.29050
Total Iteration Time: 4.68320

Cumulative Model Updates: 53,522
Cumulative Timesteps: 446,490,086

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 446490086...
Checkpoint 446490086 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,826.30125
Policy Entropy: 3.36778
Value Function Loss: 0.00322

Mean KL Divergence: 0.01297
SB3 Clip Fraction: 0.12909
Policy Update Magnitude: 0.50211
Value Function Update Magnitude: 0.48063

Collected Steps per Second: 22,955.74285
Overall Steps per Second: 10,913.33564

Timestep Collection Time: 2.17845
Timestep Consumption Time: 2.40383
PPO Batch Consumption Time: 0.28089
Total Iteration Time: 4.58228

Cumulative Model Updates: 53,528
Cumulative Timesteps: 446,540,094

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,039.66864
Policy Entropy: 3.38305
Value Function Loss: 0.00316

Mean KL Divergence: 0.01084
SB3 Clip Fraction: 0.10971
Policy Update Magnitude: 0.50147
Value Function Update Magnitude: 0.50459

Collected Steps per Second: 23,116.54415
Overall Steps per Second: 10,915.35314

Timestep Collection Time: 2.16408
Timestep Consumption Time: 2.41901
PPO Batch Consumption Time: 0.28043
Total Iteration Time: 4.58309

Cumulative Model Updates: 53,534
Cumulative Timesteps: 446,590,120

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 446590120...
Checkpoint 446590120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 815.46058
Policy Entropy: 3.37692
Value Function Loss: 0.00330

Mean KL Divergence: 0.01187
SB3 Clip Fraction: 0.11775
Policy Update Magnitude: 0.50246
Value Function Update Magnitude: 0.51131

Collected Steps per Second: 22,558.80853
Overall Steps per Second: 10,676.65825

Timestep Collection Time: 2.21687
Timestep Consumption Time: 2.46718
PPO Batch Consumption Time: 0.29007
Total Iteration Time: 4.68405

Cumulative Model Updates: 53,540
Cumulative Timesteps: 446,640,130

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,377.57828
Policy Entropy: 3.37804
Value Function Loss: 0.00336

Mean KL Divergence: 0.01293
SB3 Clip Fraction: 0.12669
Policy Update Magnitude: 0.51072
Value Function Update Magnitude: 0.52038

Collected Steps per Second: 23,122.32165
Overall Steps per Second: 10,898.10967

Timestep Collection Time: 2.16276
Timestep Consumption Time: 2.42593
PPO Batch Consumption Time: 0.28129
Total Iteration Time: 4.58869

Cumulative Model Updates: 53,546
Cumulative Timesteps: 446,690,138

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 446690138...
Checkpoint 446690138 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,076.40210
Policy Entropy: 3.36820
Value Function Loss: 0.00334

Mean KL Divergence: 0.01189
SB3 Clip Fraction: 0.12062
Policy Update Magnitude: 0.51675
Value Function Update Magnitude: 0.51040

Collected Steps per Second: 22,060.34326
Overall Steps per Second: 10,659.69319

Timestep Collection Time: 2.26724
Timestep Consumption Time: 2.42483
PPO Batch Consumption Time: 0.28367
Total Iteration Time: 4.69207

Cumulative Model Updates: 53,552
Cumulative Timesteps: 446,740,154

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,210.68457
Policy Entropy: 3.38893
Value Function Loss: 0.00325

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.10145
Policy Update Magnitude: 0.51222
Value Function Update Magnitude: 0.49062

Collected Steps per Second: 22,469.02724
Overall Steps per Second: 10,816.70983

Timestep Collection Time: 2.22546
Timestep Consumption Time: 2.39738
PPO Batch Consumption Time: 0.27987
Total Iteration Time: 4.62285

Cumulative Model Updates: 53,558
Cumulative Timesteps: 446,790,158

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 446790158...
Checkpoint 446790158 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,422.14997
Policy Entropy: 3.38901
Value Function Loss: 0.00323

Mean KL Divergence: 0.00745
SB3 Clip Fraction: 0.08441
Policy Update Magnitude: 0.51027
Value Function Update Magnitude: 0.49097

Collected Steps per Second: 22,225.36809
Overall Steps per Second: 10,670.49886

Timestep Collection Time: 2.24986
Timestep Consumption Time: 2.43633
PPO Batch Consumption Time: 0.28048
Total Iteration Time: 4.68619

Cumulative Model Updates: 53,564
Cumulative Timesteps: 446,840,162

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 964.60927
Policy Entropy: 3.40119
Value Function Loss: 0.00326

Mean KL Divergence: 0.00582
SB3 Clip Fraction: 0.06504
Policy Update Magnitude: 0.51814
Value Function Update Magnitude: 0.49573

Collected Steps per Second: 22,505.60480
Overall Steps per Second: 10,547.92979

Timestep Collection Time: 2.22194
Timestep Consumption Time: 2.51890
PPO Batch Consumption Time: 0.29476
Total Iteration Time: 4.74084

Cumulative Model Updates: 53,570
Cumulative Timesteps: 446,890,168

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 446890168...
Checkpoint 446890168 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,067.13001
Policy Entropy: 3.38176
Value Function Loss: 0.00325

Mean KL Divergence: 0.00564
SB3 Clip Fraction: 0.06379
Policy Update Magnitude: 0.52016
Value Function Update Magnitude: 0.49500

Collected Steps per Second: 22,468.09419
Overall Steps per Second: 10,587.48769

Timestep Collection Time: 2.22662
Timestep Consumption Time: 2.49858
PPO Batch Consumption Time: 0.29507
Total Iteration Time: 4.72520

Cumulative Model Updates: 53,576
Cumulative Timesteps: 446,940,196

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,600.12661
Policy Entropy: 3.38261
Value Function Loss: 0.00335

Mean KL Divergence: 0.00609
SB3 Clip Fraction: 0.06844
Policy Update Magnitude: 0.51698
Value Function Update Magnitude: 0.50785

Collected Steps per Second: 23,129.63734
Overall Steps per Second: 10,844.11332

Timestep Collection Time: 2.16303
Timestep Consumption Time: 2.45054
PPO Batch Consumption Time: 0.28012
Total Iteration Time: 4.61356

Cumulative Model Updates: 53,582
Cumulative Timesteps: 446,990,226

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 446990226...
Checkpoint 446990226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,048.21297
Policy Entropy: 3.37035
Value Function Loss: 0.00347

Mean KL Divergence: 0.00662
SB3 Clip Fraction: 0.07698
Policy Update Magnitude: 0.53081
Value Function Update Magnitude: 0.51503

Collected Steps per Second: 22,760.32025
Overall Steps per Second: 10,710.56228

Timestep Collection Time: 2.19821
Timestep Consumption Time: 2.47307
PPO Batch Consumption Time: 0.28704
Total Iteration Time: 4.67128

Cumulative Model Updates: 53,588
Cumulative Timesteps: 447,040,258

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 963.85261
Policy Entropy: 3.37573
Value Function Loss: 0.00352

Mean KL Divergence: 0.00720
SB3 Clip Fraction: 0.08093
Policy Update Magnitude: 0.53883
Value Function Update Magnitude: 0.52573

Collected Steps per Second: 23,065.55109
Overall Steps per Second: 10,818.30126

Timestep Collection Time: 2.16869
Timestep Consumption Time: 2.45514
PPO Batch Consumption Time: 0.28064
Total Iteration Time: 4.62383

Cumulative Model Updates: 53,594
Cumulative Timesteps: 447,090,280

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 447090280...
Checkpoint 447090280 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 840.86515
Policy Entropy: 3.37681
Value Function Loss: 0.00346

Mean KL Divergence: 0.00734
SB3 Clip Fraction: 0.08365
Policy Update Magnitude: 0.53168
Value Function Update Magnitude: 0.52524

Collected Steps per Second: 22,886.13896
Overall Steps per Second: 10,724.06545

Timestep Collection Time: 2.18552
Timestep Consumption Time: 2.47857
PPO Batch Consumption Time: 0.29218
Total Iteration Time: 4.66409

Cumulative Model Updates: 53,600
Cumulative Timesteps: 447,140,298

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,655.85844
Policy Entropy: 3.37028
Value Function Loss: 0.00321

Mean KL Divergence: 0.00722
SB3 Clip Fraction: 0.08358
Policy Update Magnitude: 0.51633
Value Function Update Magnitude: 0.52391

Collected Steps per Second: 23,004.63755
Overall Steps per Second: 10,832.18218

Timestep Collection Time: 2.17347
Timestep Consumption Time: 2.44240
PPO Batch Consumption Time: 0.28030
Total Iteration Time: 4.61588

Cumulative Model Updates: 53,606
Cumulative Timesteps: 447,190,298

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 447190298...
Checkpoint 447190298 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,237.97879
Policy Entropy: 3.35940
Value Function Loss: 0.00324

Mean KL Divergence: 0.00738
SB3 Clip Fraction: 0.08383
Policy Update Magnitude: 0.50970
Value Function Update Magnitude: 0.51918

Collected Steps per Second: 22,315.54086
Overall Steps per Second: 10,771.16849

Timestep Collection Time: 2.24059
Timestep Consumption Time: 2.40143
PPO Batch Consumption Time: 0.27901
Total Iteration Time: 4.64202

Cumulative Model Updates: 53,612
Cumulative Timesteps: 447,240,298

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 890.25824
Policy Entropy: 3.35205
Value Function Loss: 0.00336

Mean KL Divergence: 0.00622
SB3 Clip Fraction: 0.06917
Policy Update Magnitude: 0.51311
Value Function Update Magnitude: 0.52345

Collected Steps per Second: 22,667.94027
Overall Steps per Second: 10,829.90817

Timestep Collection Time: 2.20717
Timestep Consumption Time: 2.41263
PPO Batch Consumption Time: 0.27996
Total Iteration Time: 4.61980

Cumulative Model Updates: 53,618
Cumulative Timesteps: 447,290,330

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 447290330...
Checkpoint 447290330 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 568.03666
Policy Entropy: 3.34124
Value Function Loss: 0.00355

Mean KL Divergence: 0.00685
SB3 Clip Fraction: 0.07829
Policy Update Magnitude: 0.52825
Value Function Update Magnitude: 0.53750

Collected Steps per Second: 21,998.46452
Overall Steps per Second: 10,672.53942

Timestep Collection Time: 2.27343
Timestep Consumption Time: 2.41261
PPO Batch Consumption Time: 0.28066
Total Iteration Time: 4.68604

Cumulative Model Updates: 53,624
Cumulative Timesteps: 447,340,342

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,316.24015
Policy Entropy: 3.34521
Value Function Loss: 0.00347

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.08571
Policy Update Magnitude: 0.53475
Value Function Update Magnitude: 0.53776

Collected Steps per Second: 22,603.89965
Overall Steps per Second: 10,638.18339

Timestep Collection Time: 2.21289
Timestep Consumption Time: 2.48904
PPO Batch Consumption Time: 0.29103
Total Iteration Time: 4.70193

Cumulative Model Updates: 53,630
Cumulative Timesteps: 447,390,362

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 447390362...
Checkpoint 447390362 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,376.55230
Policy Entropy: 3.33124
Value Function Loss: 0.00344

Mean KL Divergence: 0.00639
SB3 Clip Fraction: 0.07263
Policy Update Magnitude: 0.52818
Value Function Update Magnitude: 0.52749

Collected Steps per Second: 22,312.07034
Overall Steps per Second: 10,499.19841

Timestep Collection Time: 2.24210
Timestep Consumption Time: 2.52264
PPO Batch Consumption Time: 0.29438
Total Iteration Time: 4.76474

Cumulative Model Updates: 53,636
Cumulative Timesteps: 447,440,388

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 614.45934
Policy Entropy: 3.34494
Value Function Loss: 0.00339

Mean KL Divergence: 0.00605
SB3 Clip Fraction: 0.06908
Policy Update Magnitude: 0.52868
Value Function Update Magnitude: 0.51247

Collected Steps per Second: 22,913.87272
Overall Steps per Second: 10,575.88219

Timestep Collection Time: 2.18217
Timestep Consumption Time: 2.54576
PPO Batch Consumption Time: 0.29106
Total Iteration Time: 4.72793

Cumulative Model Updates: 53,642
Cumulative Timesteps: 447,490,390

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 447490390...
Checkpoint 447490390 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 989.85120
Policy Entropy: 3.35008
Value Function Loss: 0.00343

Mean KL Divergence: 0.00686
SB3 Clip Fraction: 0.07846
Policy Update Magnitude: 0.53585
Value Function Update Magnitude: 0.51633

Collected Steps per Second: 22,837.85633
Overall Steps per Second: 10,704.44679

Timestep Collection Time: 2.19049
Timestep Consumption Time: 2.48290
PPO Batch Consumption Time: 0.28942
Total Iteration Time: 4.67338

Cumulative Model Updates: 53,648
Cumulative Timesteps: 447,540,416

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 615.00778
Policy Entropy: 3.35664
Value Function Loss: 0.00338

Mean KL Divergence: 0.00721
SB3 Clip Fraction: 0.08285
Policy Update Magnitude: 0.54047
Value Function Update Magnitude: 0.52648

Collected Steps per Second: 23,314.61936
Overall Steps per Second: 10,696.81822

Timestep Collection Time: 2.14535
Timestep Consumption Time: 2.53062
PPO Batch Consumption Time: 0.29531
Total Iteration Time: 4.67597

Cumulative Model Updates: 53,654
Cumulative Timesteps: 447,590,434

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 447590434...
Checkpoint 447590434 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,438.31038
Policy Entropy: 3.36085
Value Function Loss: 0.00327

Mean KL Divergence: 0.00657
SB3 Clip Fraction: 0.07391
Policy Update Magnitude: 0.54405
Value Function Update Magnitude: 0.53140

Collected Steps per Second: 21,714.97964
Overall Steps per Second: 10,330.02022

Timestep Collection Time: 2.30274
Timestep Consumption Time: 2.53791
PPO Batch Consumption Time: 0.29285
Total Iteration Time: 4.84065

Cumulative Model Updates: 53,660
Cumulative Timesteps: 447,640,438

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,060.10404
Policy Entropy: 3.36249
Value Function Loss: 0.00333

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.10084
Policy Update Magnitude: 0.53098
Value Function Update Magnitude: 0.53132

Collected Steps per Second: 23,108.38496
Overall Steps per Second: 10,754.32753

Timestep Collection Time: 2.16484
Timestep Consumption Time: 2.48687
PPO Batch Consumption Time: 0.29149
Total Iteration Time: 4.65171

Cumulative Model Updates: 53,666
Cumulative Timesteps: 447,690,464

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 447690464...
Checkpoint 447690464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,293.56200
Policy Entropy: 3.36573
Value Function Loss: 0.00336

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.10230
Policy Update Magnitude: 0.52904
Value Function Update Magnitude: 0.51241

Collected Steps per Second: 22,567.69304
Overall Steps per Second: 10,665.73244

Timestep Collection Time: 2.21618
Timestep Consumption Time: 2.47305
PPO Batch Consumption Time: 0.29202
Total Iteration Time: 4.68922

Cumulative Model Updates: 53,672
Cumulative Timesteps: 447,740,478

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,320.88897
Policy Entropy: 3.37195
Value Function Loss: 0.00334

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.10725
Policy Update Magnitude: 0.52486
Value Function Update Magnitude: 0.50791

Collected Steps per Second: 23,072.10471
Overall Steps per Second: 10,861.41132

Timestep Collection Time: 2.16799
Timestep Consumption Time: 2.43731
PPO Batch Consumption Time: 0.27983
Total Iteration Time: 4.60529

Cumulative Model Updates: 53,678
Cumulative Timesteps: 447,790,498

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 447790498...
Checkpoint 447790498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,059.90269
Policy Entropy: 3.37448
Value Function Loss: 0.00321

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.08916
Policy Update Magnitude: 0.52143
Value Function Update Magnitude: 0.52657

Collected Steps per Second: 22,361.36537
Overall Steps per Second: 10,706.66286

Timestep Collection Time: 2.23707
Timestep Consumption Time: 2.43516
PPO Batch Consumption Time: 0.28645
Total Iteration Time: 4.67223

Cumulative Model Updates: 53,684
Cumulative Timesteps: 447,840,522

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,371.85499
Policy Entropy: 3.36918
Value Function Loss: 0.00316

Mean KL Divergence: 0.00664
SB3 Clip Fraction: 0.07295
Policy Update Magnitude: 0.51957
Value Function Update Magnitude: 0.51695

Collected Steps per Second: 22,553.25329
Overall Steps per Second: 10,803.69712

Timestep Collection Time: 2.21848
Timestep Consumption Time: 2.41271
PPO Batch Consumption Time: 0.28062
Total Iteration Time: 4.63119

Cumulative Model Updates: 53,690
Cumulative Timesteps: 447,890,556

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 447890556...
Checkpoint 447890556 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 999.84254
Policy Entropy: 3.36684
Value Function Loss: 0.00321

Mean KL Divergence: 0.00735
SB3 Clip Fraction: 0.08381
Policy Update Magnitude: 0.52109
Value Function Update Magnitude: 0.52222

Collected Steps per Second: 22,412.89187
Overall Steps per Second: 10,727.91835

Timestep Collection Time: 2.23104
Timestep Consumption Time: 2.43007
PPO Batch Consumption Time: 0.28468
Total Iteration Time: 4.66111

Cumulative Model Updates: 53,696
Cumulative Timesteps: 447,940,560

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,644.07649
Policy Entropy: 3.35921
Value Function Loss: 0.00327

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.08855
Policy Update Magnitude: 0.51713
Value Function Update Magnitude: 0.52350

Collected Steps per Second: 22,663.67046
Overall Steps per Second: 10,848.40524

Timestep Collection Time: 2.20697
Timestep Consumption Time: 2.40366
PPO Batch Consumption Time: 0.28003
Total Iteration Time: 4.61063

Cumulative Model Updates: 53,702
Cumulative Timesteps: 447,990,578

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 447990578...
Checkpoint 447990578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,419.83302
Policy Entropy: 3.35912
Value Function Loss: 0.00320

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.10691
Policy Update Magnitude: 0.52448
Value Function Update Magnitude: 0.51406

Collected Steps per Second: 22,512.76115
Overall Steps per Second: 10,635.84094

Timestep Collection Time: 2.22194
Timestep Consumption Time: 2.48121
PPO Batch Consumption Time: 0.28020
Total Iteration Time: 4.70315

Cumulative Model Updates: 53,708
Cumulative Timesteps: 448,040,600

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,140.78514
Policy Entropy: 3.35015
Value Function Loss: 0.00329

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.10174
Policy Update Magnitude: 0.52653
Value Function Update Magnitude: 0.50239

Collected Steps per Second: 22,725.81759
Overall Steps per Second: 10,612.76585

Timestep Collection Time: 2.20067
Timestep Consumption Time: 2.51177
PPO Batch Consumption Time: 0.29243
Total Iteration Time: 4.71244

Cumulative Model Updates: 53,714
Cumulative Timesteps: 448,090,612

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 448090612...
Checkpoint 448090612 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,474.93154
Policy Entropy: 3.36226
Value Function Loss: 0.00335

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.09468
Policy Update Magnitude: 0.53292
Value Function Update Magnitude: 0.50162

Collected Steps per Second: 23,213.24709
Overall Steps per Second: 10,951.00790

Timestep Collection Time: 2.15480
Timestep Consumption Time: 2.41281
PPO Batch Consumption Time: 0.28165
Total Iteration Time: 4.56762

Cumulative Model Updates: 53,720
Cumulative Timesteps: 448,140,632

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,227.99568
Policy Entropy: 3.37642
Value Function Loss: 0.00346

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.10423
Policy Update Magnitude: 0.52531
Value Function Update Magnitude: 0.50485

Collected Steps per Second: 23,199.04591
Overall Steps per Second: 10,920.52181

Timestep Collection Time: 2.15569
Timestep Consumption Time: 2.42376
PPO Batch Consumption Time: 0.28096
Total Iteration Time: 4.57945

Cumulative Model Updates: 53,726
Cumulative Timesteps: 448,190,642

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 448190642...
Checkpoint 448190642 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,188.73828
Policy Entropy: 3.37463
Value Function Loss: 0.00348

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.09592
Policy Update Magnitude: 0.51478
Value Function Update Magnitude: 0.50375

Collected Steps per Second: 22,541.71010
Overall Steps per Second: 10,660.98672

Timestep Collection Time: 2.21873
Timestep Consumption Time: 2.47258
PPO Batch Consumption Time: 0.29159
Total Iteration Time: 4.69131

Cumulative Model Updates: 53,732
Cumulative Timesteps: 448,240,656

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 971.66591
Policy Entropy: 3.35534
Value Function Loss: 0.00360

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.10471
Policy Update Magnitude: 0.52276
Value Function Update Magnitude: 0.52720

Collected Steps per Second: 22,877.81730
Overall Steps per Second: 10,845.95358

Timestep Collection Time: 2.18561
Timestep Consumption Time: 2.42459
PPO Batch Consumption Time: 0.28217
Total Iteration Time: 4.61020

Cumulative Model Updates: 53,738
Cumulative Timesteps: 448,290,658

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 448290658...
Checkpoint 448290658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 972.90596
Policy Entropy: 3.34941
Value Function Loss: 0.00356

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.10021
Policy Update Magnitude: 0.53069
Value Function Update Magnitude: 0.53743

Collected Steps per Second: 22,435.92994
Overall Steps per Second: 10,731.32107

Timestep Collection Time: 2.22857
Timestep Consumption Time: 2.43069
PPO Batch Consumption Time: 0.28530
Total Iteration Time: 4.65926

Cumulative Model Updates: 53,744
Cumulative Timesteps: 448,340,658

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 933.16467
Policy Entropy: 3.34789
Value Function Loss: 0.00368

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.10045
Policy Update Magnitude: 0.53451
Value Function Update Magnitude: 0.53619

Collected Steps per Second: 22,842.21982
Overall Steps per Second: 10,873.57115

Timestep Collection Time: 2.18998
Timestep Consumption Time: 2.41053
PPO Batch Consumption Time: 0.28014
Total Iteration Time: 4.60051

Cumulative Model Updates: 53,750
Cumulative Timesteps: 448,390,682

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 448390682...
Checkpoint 448390682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,985.16313
Policy Entropy: 3.33597
Value Function Loss: 0.00358

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.09259
Policy Update Magnitude: 0.53835
Value Function Update Magnitude: 0.54595

Collected Steps per Second: 22,245.38573
Overall Steps per Second: 10,641.23549

Timestep Collection Time: 2.24856
Timestep Consumption Time: 2.45203
PPO Batch Consumption Time: 0.28778
Total Iteration Time: 4.70058

Cumulative Model Updates: 53,756
Cumulative Timesteps: 448,440,702

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,267.33584
Policy Entropy: 3.34844
Value Function Loss: 0.00354

Mean KL Divergence: 0.00758
SB3 Clip Fraction: 0.08590
Policy Update Magnitude: 0.54300
Value Function Update Magnitude: 0.56527

Collected Steps per Second: 22,727.07140
Overall Steps per Second: 10,829.73006

Timestep Collection Time: 2.20134
Timestep Consumption Time: 2.41835
PPO Batch Consumption Time: 0.28027
Total Iteration Time: 4.61969

Cumulative Model Updates: 53,762
Cumulative Timesteps: 448,490,732

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 448490732...
Checkpoint 448490732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 569.23499
Policy Entropy: 3.35253
Value Function Loss: 0.00347

Mean KL Divergence: 0.00712
SB3 Clip Fraction: 0.08080
Policy Update Magnitude: 0.54716
Value Function Update Magnitude: 0.58047

Collected Steps per Second: 22,261.80648
Overall Steps per Second: 10,706.45568

Timestep Collection Time: 2.24663
Timestep Consumption Time: 2.42476
PPO Batch Consumption Time: 0.28028
Total Iteration Time: 4.67139

Cumulative Model Updates: 53,768
Cumulative Timesteps: 448,540,746

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 779.02824
Policy Entropy: 3.38525
Value Function Loss: 0.00344

Mean KL Divergence: 0.00723
SB3 Clip Fraction: 0.08100
Policy Update Magnitude: 0.54400
Value Function Update Magnitude: 0.56767

Collected Steps per Second: 23,150.73525
Overall Steps per Second: 10,938.12705

Timestep Collection Time: 2.15993
Timestep Consumption Time: 2.41160
PPO Batch Consumption Time: 0.28036
Total Iteration Time: 4.57153

Cumulative Model Updates: 53,774
Cumulative Timesteps: 448,590,750

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 448590750...
Checkpoint 448590750 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,054.30362
Policy Entropy: 3.38230
Value Function Loss: 0.00339

Mean KL Divergence: 0.00699
SB3 Clip Fraction: 0.08116
Policy Update Magnitude: 0.53100
Value Function Update Magnitude: 0.54227

Collected Steps per Second: 22,806.08399
Overall Steps per Second: 10,722.02791

Timestep Collection Time: 2.19310
Timestep Consumption Time: 2.47169
PPO Batch Consumption Time: 0.29433
Total Iteration Time: 4.66479

Cumulative Model Updates: 53,780
Cumulative Timesteps: 448,640,766

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,465.55350
Policy Entropy: 3.37541
Value Function Loss: 0.00343

Mean KL Divergence: 0.00622
SB3 Clip Fraction: 0.07201
Policy Update Magnitude: 0.52155
Value Function Update Magnitude: 0.52402

Collected Steps per Second: 23,217.17843
Overall Steps per Second: 10,840.29214

Timestep Collection Time: 2.15418
Timestep Consumption Time: 2.45953
PPO Batch Consumption Time: 0.28887
Total Iteration Time: 4.61371

Cumulative Model Updates: 53,786
Cumulative Timesteps: 448,690,780

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 448690780...
Checkpoint 448690780 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 962.03658
Policy Entropy: 3.35912
Value Function Loss: 0.00335

Mean KL Divergence: 0.00596
SB3 Clip Fraction: 0.06758
Policy Update Magnitude: 0.52725
Value Function Update Magnitude: 0.52169

Collected Steps per Second: 22,995.02630
Overall Steps per Second: 10,721.00472

Timestep Collection Time: 2.17456
Timestep Consumption Time: 2.48956
PPO Batch Consumption Time: 0.29350
Total Iteration Time: 4.66412

Cumulative Model Updates: 53,792
Cumulative Timesteps: 448,740,784

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,016.32975
Policy Entropy: 3.38272
Value Function Loss: 0.00331

Mean KL Divergence: 0.00581
SB3 Clip Fraction: 0.06401
Policy Update Magnitude: 0.53204
Value Function Update Magnitude: 0.50219

Collected Steps per Second: 23,341.07651
Overall Steps per Second: 10,825.12262

Timestep Collection Time: 2.14257
Timestep Consumption Time: 2.47723
PPO Batch Consumption Time: 0.29225
Total Iteration Time: 4.61981

Cumulative Model Updates: 53,798
Cumulative Timesteps: 448,790,794

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 448790794...
Checkpoint 448790794 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,481.67593
Policy Entropy: 3.38094
Value Function Loss: 0.00337

Mean KL Divergence: 0.00630
SB3 Clip Fraction: 0.07266
Policy Update Magnitude: 0.51979
Value Function Update Magnitude: 0.49038

Collected Steps per Second: 22,363.95499
Overall Steps per Second: 10,664.05783

Timestep Collection Time: 2.23663
Timestep Consumption Time: 2.45389
PPO Batch Consumption Time: 0.28899
Total Iteration Time: 4.69052

Cumulative Model Updates: 53,804
Cumulative Timesteps: 448,840,814

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,160.66016
Policy Entropy: 3.36967
Value Function Loss: 0.00335

Mean KL Divergence: 0.00675
SB3 Clip Fraction: 0.07574
Policy Update Magnitude: 0.51955
Value Function Update Magnitude: 0.49123

Collected Steps per Second: 22,703.27390
Overall Steps per Second: 10,827.36557

Timestep Collection Time: 2.20285
Timestep Consumption Time: 2.41618
PPO Batch Consumption Time: 0.28001
Total Iteration Time: 4.61904

Cumulative Model Updates: 53,810
Cumulative Timesteps: 448,890,826

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 448890826...
Checkpoint 448890826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 983.06033
Policy Entropy: 3.36299
Value Function Loss: 0.00335

Mean KL Divergence: 0.00705
SB3 Clip Fraction: 0.07987
Policy Update Magnitude: 0.52368
Value Function Update Magnitude: 0.49250

Collected Steps per Second: 22,633.03187
Overall Steps per Second: 10,674.80525

Timestep Collection Time: 2.20916
Timestep Consumption Time: 2.47477
PPO Batch Consumption Time: 0.29016
Total Iteration Time: 4.68393

Cumulative Model Updates: 53,816
Cumulative Timesteps: 448,940,826

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,010.75429
Policy Entropy: 3.36509
Value Function Loss: 0.00333

Mean KL Divergence: 0.00741
SB3 Clip Fraction: 0.08221
Policy Update Magnitude: 0.52132
Value Function Update Magnitude: 0.48821

Collected Steps per Second: 22,699.23231
Overall Steps per Second: 10,848.48150

Timestep Collection Time: 2.20307
Timestep Consumption Time: 2.40661
PPO Batch Consumption Time: 0.27993
Total Iteration Time: 4.60968

Cumulative Model Updates: 53,822
Cumulative Timesteps: 448,990,834

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 448990834...
Checkpoint 448990834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,254.29888
Policy Entropy: 3.39681
Value Function Loss: 0.00315

Mean KL Divergence: 0.00642
SB3 Clip Fraction: 0.07367
Policy Update Magnitude: 0.51579
Value Function Update Magnitude: 0.47829

Collected Steps per Second: 22,062.04563
Overall Steps per Second: 10,655.02180

Timestep Collection Time: 2.26697
Timestep Consumption Time: 2.42697
PPO Batch Consumption Time: 0.27959
Total Iteration Time: 4.69394

Cumulative Model Updates: 53,828
Cumulative Timesteps: 449,040,848

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,661.55120
Policy Entropy: 3.38880
Value Function Loss: 0.00330

Mean KL Divergence: 0.00606
SB3 Clip Fraction: 0.06848
Policy Update Magnitude: 0.51105
Value Function Update Magnitude: 0.47134

Collected Steps per Second: 22,985.05714
Overall Steps per Second: 10,718.55201

Timestep Collection Time: 2.17646
Timestep Consumption Time: 2.49078
PPO Batch Consumption Time: 0.28908
Total Iteration Time: 4.66723

Cumulative Model Updates: 53,834
Cumulative Timesteps: 449,090,874

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 449090874...
Checkpoint 449090874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,295.56567
Policy Entropy: 3.38716
Value Function Loss: 0.00328

Mean KL Divergence: 0.00671
SB3 Clip Fraction: 0.07623
Policy Update Magnitude: 0.52525
Value Function Update Magnitude: 0.49696

Collected Steps per Second: 23,039.32066
Overall Steps per Second: 10,840.23711

Timestep Collection Time: 2.17151
Timestep Consumption Time: 2.44371
PPO Batch Consumption Time: 0.28599
Total Iteration Time: 4.61521

Cumulative Model Updates: 53,840
Cumulative Timesteps: 449,140,904

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,640.78185
Policy Entropy: 3.36572
Value Function Loss: 0.00335

Mean KL Divergence: 0.00723
SB3 Clip Fraction: 0.08253
Policy Update Magnitude: 0.53367
Value Function Update Magnitude: 0.49631

Collected Steps per Second: 23,082.02499
Overall Steps per Second: 10,920.96073

Timestep Collection Time: 2.16827
Timestep Consumption Time: 2.41448
PPO Batch Consumption Time: 0.28126
Total Iteration Time: 4.58275

Cumulative Model Updates: 53,846
Cumulative Timesteps: 449,190,952

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 449190952...
Checkpoint 449190952 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 869.04902
Policy Entropy: 3.35780
Value Function Loss: 0.00342

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.09103
Policy Update Magnitude: 0.52953
Value Function Update Magnitude: 0.49413

Collected Steps per Second: 22,626.42476
Overall Steps per Second: 10,695.90408

Timestep Collection Time: 2.21087
Timestep Consumption Time: 2.46606
PPO Batch Consumption Time: 0.29146
Total Iteration Time: 4.67693

Cumulative Model Updates: 53,852
Cumulative Timesteps: 449,240,976

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,294.08626
Policy Entropy: 3.36165
Value Function Loss: 0.00328

Mean KL Divergence: 0.00683
SB3 Clip Fraction: 0.07752
Policy Update Magnitude: 0.52482
Value Function Update Magnitude: 0.49351

Collected Steps per Second: 23,077.41419
Overall Steps per Second: 10,926.60712

Timestep Collection Time: 2.16775
Timestep Consumption Time: 2.41062
PPO Batch Consumption Time: 0.27976
Total Iteration Time: 4.57837

Cumulative Model Updates: 53,858
Cumulative Timesteps: 449,291,002

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 449291002...
Checkpoint 449291002 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,222.53471
Policy Entropy: 3.36254
Value Function Loss: 0.00331

Mean KL Divergence: 0.00724
SB3 Clip Fraction: 0.08249
Policy Update Magnitude: 0.51838
Value Function Update Magnitude: 0.48527

Collected Steps per Second: 22,712.22278
Overall Steps per Second: 10,702.73315

Timestep Collection Time: 2.20251
Timestep Consumption Time: 2.47143
PPO Batch Consumption Time: 0.29373
Total Iteration Time: 4.67395

Cumulative Model Updates: 53,864
Cumulative Timesteps: 449,341,026

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,400.64507
Policy Entropy: 3.36063
Value Function Loss: 0.00321

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.10848
Policy Update Magnitude: 0.50905
Value Function Update Magnitude: 0.48946

Collected Steps per Second: 22,569.80087
Overall Steps per Second: 10,761.72228

Timestep Collection Time: 2.21579
Timestep Consumption Time: 2.43123
PPO Batch Consumption Time: 0.28023
Total Iteration Time: 4.64703

Cumulative Model Updates: 53,870
Cumulative Timesteps: 449,391,036

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 449391036...
Checkpoint 449391036 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,012.38946
Policy Entropy: 3.35537
Value Function Loss: 0.00314

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.10106
Policy Update Magnitude: 0.51668
Value Function Update Magnitude: 0.49837

Collected Steps per Second: 22,303.78303
Overall Steps per Second: 10,717.29259

Timestep Collection Time: 2.24321
Timestep Consumption Time: 2.42514
PPO Batch Consumption Time: 0.28405
Total Iteration Time: 4.66834

Cumulative Model Updates: 53,876
Cumulative Timesteps: 449,441,068

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,098.53327
Policy Entropy: 3.36040
Value Function Loss: 0.00315

Mean KL Divergence: 0.01112
SB3 Clip Fraction: 0.11298
Policy Update Magnitude: 0.51191
Value Function Update Magnitude: 0.50580

Collected Steps per Second: 22,520.01721
Overall Steps per Second: 10,783.27846

Timestep Collection Time: 2.22140
Timestep Consumption Time: 2.41782
PPO Batch Consumption Time: 0.28053
Total Iteration Time: 4.63922

Cumulative Model Updates: 53,882
Cumulative Timesteps: 449,491,094

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 449491094...
Checkpoint 449491094 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,521.17155
Policy Entropy: 3.38313
Value Function Loss: 0.00309

Mean KL Divergence: 0.01076
SB3 Clip Fraction: 0.11494
Policy Update Magnitude: 0.50478
Value Function Update Magnitude: 0.48911

Collected Steps per Second: 22,468.72084
Overall Steps per Second: 10,713.00133

Timestep Collection Time: 2.22656
Timestep Consumption Time: 2.44328
PPO Batch Consumption Time: 0.28071
Total Iteration Time: 4.66984

Cumulative Model Updates: 53,888
Cumulative Timesteps: 449,541,122

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,041.87397
Policy Entropy: 3.38746
Value Function Loss: 0.00316

Mean KL Divergence: 0.00749
SB3 Clip Fraction: 0.08475
Policy Update Magnitude: 0.50555
Value Function Update Magnitude: 0.48060

Collected Steps per Second: 21,452.34144
Overall Steps per Second: 10,465.33394

Timestep Collection Time: 2.33196
Timestep Consumption Time: 2.44820
PPO Batch Consumption Time: 0.28052
Total Iteration Time: 4.78016

Cumulative Model Updates: 53,894
Cumulative Timesteps: 449,591,148

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 449591148...
Checkpoint 449591148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,749.35768
Policy Entropy: 3.37537
Value Function Loss: 0.00316

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.08960
Policy Update Magnitude: 0.51442
Value Function Update Magnitude: 0.50639

Collected Steps per Second: 21,912.49387
Overall Steps per Second: 10,705.15461

Timestep Collection Time: 2.28299
Timestep Consumption Time: 2.39009
PPO Batch Consumption Time: 0.27840
Total Iteration Time: 4.67308

Cumulative Model Updates: 53,900
Cumulative Timesteps: 449,641,174

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,281.00742
Policy Entropy: 3.36645
Value Function Loss: 0.00322

Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.09122
Policy Update Magnitude: 0.52215
Value Function Update Magnitude: 0.50639

Collected Steps per Second: 22,564.93781
Overall Steps per Second: 10,582.58065

Timestep Collection Time: 2.21645
Timestep Consumption Time: 2.50962
PPO Batch Consumption Time: 0.29088
Total Iteration Time: 4.72607

Cumulative Model Updates: 53,906
Cumulative Timesteps: 449,691,188

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 449691188...
Checkpoint 449691188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 722.10493
Policy Entropy: 3.35075
Value Function Loss: 0.00333

Mean KL Divergence: 0.00759
SB3 Clip Fraction: 0.08491
Policy Update Magnitude: 0.52876
Value Function Update Magnitude: 0.50490

Collected Steps per Second: 22,436.90277
Overall Steps per Second: 10,642.10086

Timestep Collection Time: 2.22945
Timestep Consumption Time: 2.47094
PPO Batch Consumption Time: 0.29035
Total Iteration Time: 4.70039

Cumulative Model Updates: 53,912
Cumulative Timesteps: 449,741,210

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,543.59181
Policy Entropy: 3.33481
Value Function Loss: 0.00351

Mean KL Divergence: 0.00751
SB3 Clip Fraction: 0.08690
Policy Update Magnitude: 0.53110
Value Function Update Magnitude: 0.51439

Collected Steps per Second: 23,279.77254
Overall Steps per Second: 10,741.25344

Timestep Collection Time: 2.14847
Timestep Consumption Time: 2.50797
PPO Batch Consumption Time: 0.29482
Total Iteration Time: 4.65644

Cumulative Model Updates: 53,918
Cumulative Timesteps: 449,791,226

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 449791226...
Checkpoint 449791226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 930.13597
Policy Entropy: 3.32411
Value Function Loss: 0.00361

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.09560
Policy Update Magnitude: 0.53571
Value Function Update Magnitude: 0.51642

Collected Steps per Second: 22,706.22815
Overall Steps per Second: 10,684.11278

Timestep Collection Time: 2.20301
Timestep Consumption Time: 2.47890
PPO Batch Consumption Time: 0.29538
Total Iteration Time: 4.68190

Cumulative Model Updates: 53,924
Cumulative Timesteps: 449,841,248

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,144.82122
Policy Entropy: 3.32935
Value Function Loss: 0.00355

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.10420
Policy Update Magnitude: 0.54140
Value Function Update Magnitude: 0.53387

Collected Steps per Second: 22,812.37537
Overall Steps per Second: 10,828.95185

Timestep Collection Time: 2.19302
Timestep Consumption Time: 2.42682
PPO Batch Consumption Time: 0.28183
Total Iteration Time: 4.61984

Cumulative Model Updates: 53,930
Cumulative Timesteps: 449,891,276

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 449891276...
Checkpoint 449891276 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,183.06711
Policy Entropy: 3.35162
Value Function Loss: 0.00345

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.09518
Policy Update Magnitude: 0.54155
Value Function Update Magnitude: 0.53983

Collected Steps per Second: 23,016.45430
Overall Steps per Second: 10,686.42194

Timestep Collection Time: 2.17279
Timestep Consumption Time: 2.50698
PPO Batch Consumption Time: 0.29297
Total Iteration Time: 4.67977

Cumulative Model Updates: 53,936
Cumulative Timesteps: 449,941,286

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,449.67456
Policy Entropy: 3.36820
Value Function Loss: 0.00321

Mean KL Divergence: 0.00732
SB3 Clip Fraction: 0.08460
Policy Update Magnitude: 0.52928
Value Function Update Magnitude: 0.54621

Collected Steps per Second: 22,842.34575
Overall Steps per Second: 10,879.01606

Timestep Collection Time: 2.18962
Timestep Consumption Time: 2.40786
PPO Batch Consumption Time: 0.28035
Total Iteration Time: 4.59747

Cumulative Model Updates: 53,942
Cumulative Timesteps: 449,991,302

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 449991302...
Checkpoint 449991302 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,609.93377
Policy Entropy: 3.35626
Value Function Loss: 0.00323

Mean KL Divergence: 0.00759
SB3 Clip Fraction: 0.08776
Policy Update Magnitude: 0.52507
Value Function Update Magnitude: 0.53383

Collected Steps per Second: 22,791.54715
Overall Steps per Second: 10,698.69860

Timestep Collection Time: 2.19467
Timestep Consumption Time: 2.48066
PPO Batch Consumption Time: 0.28980
Total Iteration Time: 4.67533

Cumulative Model Updates: 53,948
Cumulative Timesteps: 450,041,322

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,398.91657
Policy Entropy: 3.35542
Value Function Loss: 0.00330

Mean KL Divergence: 0.00739
SB3 Clip Fraction: 0.08397
Policy Update Magnitude: 0.52816
Value Function Update Magnitude: 0.51330

Collected Steps per Second: 22,567.54169
Overall Steps per Second: 10,616.99409

Timestep Collection Time: 2.21672
Timestep Consumption Time: 2.49516
PPO Batch Consumption Time: 0.29023
Total Iteration Time: 4.71188

Cumulative Model Updates: 53,954
Cumulative Timesteps: 450,091,348

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 450091348...
Checkpoint 450091348 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,136.19427
Policy Entropy: 3.35011
Value Function Loss: 0.00340

Mean KL Divergence: 0.00753
SB3 Clip Fraction: 0.08350
Policy Update Magnitude: 0.53021
Value Function Update Magnitude: 0.50658

Collected Steps per Second: 22,260.44201
Overall Steps per Second: 10,537.84115

Timestep Collection Time: 2.24695
Timestep Consumption Time: 2.49957
PPO Batch Consumption Time: 0.29363
Total Iteration Time: 4.74651

Cumulative Model Updates: 53,960
Cumulative Timesteps: 450,141,366

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,256.36230
Policy Entropy: 3.35907
Value Function Loss: 0.00336

Mean KL Divergence: 0.00772
SB3 Clip Fraction: 0.08751
Policy Update Magnitude: 0.52421
Value Function Update Magnitude: 0.50876

Collected Steps per Second: 22,634.19401
Overall Steps per Second: 10,746.96659

Timestep Collection Time: 2.21037
Timestep Consumption Time: 2.44489
PPO Batch Consumption Time: 0.28005
Total Iteration Time: 4.65527

Cumulative Model Updates: 53,966
Cumulative Timesteps: 450,191,396

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 450191396...
Checkpoint 450191396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,915.00110
Policy Entropy: 3.34656
Value Function Loss: 0.00328

Mean KL Divergence: 0.00727
SB3 Clip Fraction: 0.08258
Policy Update Magnitude: 0.52217
Value Function Update Magnitude: 0.50307

Collected Steps per Second: 22,309.21071
Overall Steps per Second: 10,794.64450

Timestep Collection Time: 2.24203
Timestep Consumption Time: 2.39156
PPO Batch Consumption Time: 0.27833
Total Iteration Time: 4.63359

Cumulative Model Updates: 53,972
Cumulative Timesteps: 450,241,414

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,146.84722
Policy Entropy: 3.33937
Value Function Loss: 0.00329

Mean KL Divergence: 0.00659
SB3 Clip Fraction: 0.07464
Policy Update Magnitude: 0.52261
Value Function Update Magnitude: 0.50989

Collected Steps per Second: 23,144.73313
Overall Steps per Second: 10,815.78543

Timestep Collection Time: 2.16161
Timestep Consumption Time: 2.46403
PPO Batch Consumption Time: 0.28229
Total Iteration Time: 4.62565

Cumulative Model Updates: 53,978
Cumulative Timesteps: 450,291,444

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 450291444...
Checkpoint 450291444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,331.09305
Policy Entropy: 3.33665
Value Function Loss: 0.00322

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.10088
Policy Update Magnitude: 0.52451
Value Function Update Magnitude: 0.51572

Collected Steps per Second: 22,321.18558
Overall Steps per Second: 10,676.19858

Timestep Collection Time: 2.24137
Timestep Consumption Time: 2.44476
PPO Batch Consumption Time: 0.28622
Total Iteration Time: 4.68612

Cumulative Model Updates: 53,984
Cumulative Timesteps: 450,341,474

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,083.34467
Policy Entropy: 3.34354
Value Function Loss: 0.00332

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.10453
Policy Update Magnitude: 0.51525
Value Function Update Magnitude: 0.50133

Collected Steps per Second: 23,315.20897
Overall Steps per Second: 10,925.29171

Timestep Collection Time: 2.14461
Timestep Consumption Time: 2.43211
PPO Batch Consumption Time: 0.28513
Total Iteration Time: 4.57672

Cumulative Model Updates: 53,990
Cumulative Timesteps: 450,391,476

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 450391476...
Checkpoint 450391476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 827.98437
Policy Entropy: 3.33894
Value Function Loss: 0.00341

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.09756
Policy Update Magnitude: 0.51477
Value Function Update Magnitude: 0.50379

Collected Steps per Second: 21,896.51948
Overall Steps per Second: 10,560.61574

Timestep Collection Time: 2.28411
Timestep Consumption Time: 2.45179
PPO Batch Consumption Time: 0.28144
Total Iteration Time: 4.73590

Cumulative Model Updates: 53,996
Cumulative Timesteps: 450,441,490

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 768.64286
Policy Entropy: 3.33084
Value Function Loss: 0.00338

Mean KL Divergence: 0.01100
SB3 Clip Fraction: 0.11779
Policy Update Magnitude: 0.51266
Value Function Update Magnitude: 0.51800

Collected Steps per Second: 22,983.09428
Overall Steps per Second: 10,700.54039

Timestep Collection Time: 2.17673
Timestep Consumption Time: 2.49855
PPO Batch Consumption Time: 0.29112
Total Iteration Time: 4.67528

Cumulative Model Updates: 54,002
Cumulative Timesteps: 450,491,518

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 450491518...
Checkpoint 450491518 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,678.25833
Policy Entropy: 3.34745
Value Function Loss: 0.00311

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.08981
Policy Update Magnitude: 0.51964
Value Function Update Magnitude: 0.53127

Collected Steps per Second: 22,643.12190
Overall Steps per Second: 10,621.71104

Timestep Collection Time: 2.20826
Timestep Consumption Time: 2.49926
PPO Batch Consumption Time: 0.28924
Total Iteration Time: 4.70753

Cumulative Model Updates: 54,008
Cumulative Timesteps: 450,541,520

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,701.32176
Policy Entropy: 3.34070
Value Function Loss: 0.00317

Mean KL Divergence: 0.00690
SB3 Clip Fraction: 0.07928
Policy Update Magnitude: 0.52965
Value Function Update Magnitude: 0.52582

Collected Steps per Second: 23,418.55259
Overall Steps per Second: 10,848.92220

Timestep Collection Time: 2.13634
Timestep Consumption Time: 2.47518
PPO Batch Consumption Time: 0.29172
Total Iteration Time: 4.61152

Cumulative Model Updates: 54,014
Cumulative Timesteps: 450,591,550

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 450591550...
Checkpoint 450591550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 746.73246
Policy Entropy: 3.34008
Value Function Loss: 0.00329

Mean KL Divergence: 0.00708
SB3 Clip Fraction: 0.08390
Policy Update Magnitude: 0.53785
Value Function Update Magnitude: 0.55511

Collected Steps per Second: 22,272.97069
Overall Steps per Second: 10,587.63939

Timestep Collection Time: 2.24532
Timestep Consumption Time: 2.47811
PPO Batch Consumption Time: 0.29425
Total Iteration Time: 4.72343

Cumulative Model Updates: 54,020
Cumulative Timesteps: 450,641,560

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,189.34047
Policy Entropy: 3.33314
Value Function Loss: 0.00332

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.09653
Policy Update Magnitude: 0.54645
Value Function Update Magnitude: 0.55879

Collected Steps per Second: 22,797.43793
Overall Steps per Second: 10,768.90420

Timestep Collection Time: 2.19349
Timestep Consumption Time: 2.45006
PPO Batch Consumption Time: 0.28049
Total Iteration Time: 4.64356

Cumulative Model Updates: 54,026
Cumulative Timesteps: 450,691,566

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 450691566...
Checkpoint 450691566 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,595.56013
Policy Entropy: 3.35118
Value Function Loss: 0.00328

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.08806
Policy Update Magnitude: 0.53851
Value Function Update Magnitude: 0.56238

Collected Steps per Second: 22,442.14498
Overall Steps per Second: 10,738.17148

Timestep Collection Time: 2.22929
Timestep Consumption Time: 2.42979
PPO Batch Consumption Time: 0.27837
Total Iteration Time: 4.65908

Cumulative Model Updates: 54,032
Cumulative Timesteps: 450,741,596

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 916.77009
Policy Entropy: 3.36479
Value Function Loss: 0.00329

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.08838
Policy Update Magnitude: 0.52817
Value Function Update Magnitude: 0.55549

Collected Steps per Second: 22,136.96956
Overall Steps per Second: 10,465.41703

Timestep Collection Time: 2.26065
Timestep Consumption Time: 2.52119
PPO Batch Consumption Time: 0.29447
Total Iteration Time: 4.78184

Cumulative Model Updates: 54,038
Cumulative Timesteps: 450,791,640

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 450791640...
Checkpoint 450791640 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 938.14657
Policy Entropy: 3.35478
Value Function Loss: 0.00353

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.09434
Policy Update Magnitude: 0.52414
Value Function Update Magnitude: 0.54999

Collected Steps per Second: 22,791.08678
Overall Steps per Second: 10,617.75468

Timestep Collection Time: 2.19516
Timestep Consumption Time: 2.51676
PPO Batch Consumption Time: 0.29369
Total Iteration Time: 4.71192

Cumulative Model Updates: 54,044
Cumulative Timesteps: 450,841,670

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 734.99599
Policy Entropy: 3.33458
Value Function Loss: 0.00361

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.10394
Policy Update Magnitude: 0.52951
Value Function Update Magnitude: 0.56783

Collected Steps per Second: 23,063.76446
Overall Steps per Second: 10,848.03876

Timestep Collection Time: 2.16834
Timestep Consumption Time: 2.44171
PPO Batch Consumption Time: 0.28204
Total Iteration Time: 4.61005

Cumulative Model Updates: 54,050
Cumulative Timesteps: 450,891,680

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 450891680...
Checkpoint 450891680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 891.08345
Policy Entropy: 3.32139
Value Function Loss: 0.00359

Mean KL Divergence: 0.01560
SB3 Clip Fraction: 0.14354
Policy Update Magnitude: 0.53408
Value Function Update Magnitude: 0.56231

Collected Steps per Second: 22,716.90722
Overall Steps per Second: 10,656.14162

Timestep Collection Time: 2.20180
Timestep Consumption Time: 2.49202
PPO Batch Consumption Time: 0.29412
Total Iteration Time: 4.69382

Cumulative Model Updates: 54,056
Cumulative Timesteps: 450,941,698

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,218.81805
Policy Entropy: 3.33032
Value Function Loss: 0.00351

Mean KL Divergence: 0.01459
SB3 Clip Fraction: 0.13497
Policy Update Magnitude: 0.52747
Value Function Update Magnitude: 0.55169

Collected Steps per Second: 22,813.22598
Overall Steps per Second: 10,866.21240

Timestep Collection Time: 2.19303
Timestep Consumption Time: 2.41115
PPO Batch Consumption Time: 0.28047
Total Iteration Time: 4.60418

Cumulative Model Updates: 54,062
Cumulative Timesteps: 450,991,728

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 450991728...
Checkpoint 450991728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,009.85737
Policy Entropy: 3.32330
Value Function Loss: 0.00341

Mean KL Divergence: 0.01761
SB3 Clip Fraction: 0.15753
Policy Update Magnitude: 0.51961
Value Function Update Magnitude: 0.53962

Collected Steps per Second: 22,952.60459
Overall Steps per Second: 10,716.27532

Timestep Collection Time: 2.17910
Timestep Consumption Time: 2.48819
PPO Batch Consumption Time: 0.28694
Total Iteration Time: 4.66729

Cumulative Model Updates: 54,068
Cumulative Timesteps: 451,041,744

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,569.79489
Policy Entropy: 3.32097
Value Function Loss: 0.00339

Mean KL Divergence: 0.01559
SB3 Clip Fraction: 0.14889
Policy Update Magnitude: 0.51999
Value Function Update Magnitude: 0.54182

Collected Steps per Second: 23,023.84496
Overall Steps per Second: 10,804.83791

Timestep Collection Time: 2.17192
Timestep Consumption Time: 2.45619
PPO Batch Consumption Time: 0.28051
Total Iteration Time: 4.62811

Cumulative Model Updates: 54,074
Cumulative Timesteps: 451,091,750

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 451091750...
Checkpoint 451091750 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,383.32620
Policy Entropy: 3.31482
Value Function Loss: 0.00323

Mean KL Divergence: 0.01438
SB3 Clip Fraction: 0.14082
Policy Update Magnitude: 0.51968
Value Function Update Magnitude: 0.52579

Collected Steps per Second: 22,244.46778
Overall Steps per Second: 10,762.87500

Timestep Collection Time: 2.24784
Timestep Consumption Time: 2.39794
PPO Batch Consumption Time: 0.27884
Total Iteration Time: 4.64578

Cumulative Model Updates: 54,080
Cumulative Timesteps: 451,141,752

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,363.83735
Policy Entropy: 3.34519
Value Function Loss: 0.00317

Mean KL Divergence: 0.01323
SB3 Clip Fraction: 0.13099
Policy Update Magnitude: 0.51123
Value Function Update Magnitude: 0.50611

Collected Steps per Second: 22,398.10341
Overall Steps per Second: 10,649.41935

Timestep Collection Time: 2.23322
Timestep Consumption Time: 2.46374
PPO Batch Consumption Time: 0.28884
Total Iteration Time: 4.69697

Cumulative Model Updates: 54,086
Cumulative Timesteps: 451,191,772

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 451191772...
Checkpoint 451191772 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 938.00216
Policy Entropy: 3.34713
Value Function Loss: 0.00345

Mean KL Divergence: 0.01124
SB3 Clip Fraction: 0.12126
Policy Update Magnitude: 0.51563
Value Function Update Magnitude: 0.50494

Collected Steps per Second: 22,352.06850
Overall Steps per Second: 10,808.93693

Timestep Collection Time: 2.23747
Timestep Consumption Time: 2.38945
PPO Batch Consumption Time: 0.27958
Total Iteration Time: 4.62691

Cumulative Model Updates: 54,092
Cumulative Timesteps: 451,241,784

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,680.56896
Policy Entropy: 3.35253
Value Function Loss: 0.00341

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.11149
Policy Update Magnitude: 0.52450
Value Function Update Magnitude: 0.51665

Collected Steps per Second: 23,011.20923
Overall Steps per Second: 10,617.12997

Timestep Collection Time: 2.17294
Timestep Consumption Time: 2.53662
PPO Batch Consumption Time: 0.29269
Total Iteration Time: 4.70956

Cumulative Model Updates: 54,098
Cumulative Timesteps: 451,291,786

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 451291786...
Checkpoint 451291786 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,091.35824
Policy Entropy: 3.33973
Value Function Loss: 0.00352

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.10171
Policy Update Magnitude: 0.53057
Value Function Update Magnitude: 0.52305

Collected Steps per Second: 22,991.13087
Overall Steps per Second: 10,871.61226

Timestep Collection Time: 2.17614
Timestep Consumption Time: 2.42593
PPO Batch Consumption Time: 0.28077
Total Iteration Time: 4.60208

Cumulative Model Updates: 54,104
Cumulative Timesteps: 451,341,818

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,546.38904
Policy Entropy: 3.35151
Value Function Loss: 0.00340

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.09593
Policy Update Magnitude: 0.53222
Value Function Update Magnitude: 0.53876

Collected Steps per Second: 23,016.74793
Overall Steps per Second: 10,805.07739

Timestep Collection Time: 2.17381
Timestep Consumption Time: 2.45679
PPO Batch Consumption Time: 0.28935
Total Iteration Time: 4.63060

Cumulative Model Updates: 54,110
Cumulative Timesteps: 451,391,852

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 451391852...
Checkpoint 451391852 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 986.50558
Policy Entropy: 3.34075
Value Function Loss: 0.00332

Mean KL Divergence: 0.00734
SB3 Clip Fraction: 0.08353
Policy Update Magnitude: 0.52411
Value Function Update Magnitude: 0.53665

Collected Steps per Second: 22,786.02722
Overall Steps per Second: 10,909.58918

Timestep Collection Time: 2.19573
Timestep Consumption Time: 2.39033
PPO Batch Consumption Time: 0.27915
Total Iteration Time: 4.58606

Cumulative Model Updates: 54,116
Cumulative Timesteps: 451,441,884

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,020.10834
Policy Entropy: 3.36005
Value Function Loss: 0.00318

Mean KL Divergence: 0.00737
SB3 Clip Fraction: 0.08391
Policy Update Magnitude: 0.51552
Value Function Update Magnitude: 0.52338

Collected Steps per Second: 22,496.57990
Overall Steps per Second: 10,410.52253

Timestep Collection Time: 2.22398
Timestep Consumption Time: 2.58192
PPO Batch Consumption Time: 0.29391
Total Iteration Time: 4.80591

Cumulative Model Updates: 54,122
Cumulative Timesteps: 451,491,916

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 451491916...
Checkpoint 451491916 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 961.97113
Policy Entropy: 3.35404
Value Function Loss: 0.00317

Mean KL Divergence: 0.00748
SB3 Clip Fraction: 0.08449
Policy Update Magnitude: 0.50911
Value Function Update Magnitude: 0.51051

Collected Steps per Second: 22,240.60464
Overall Steps per Second: 10,633.98305

Timestep Collection Time: 2.24913
Timestep Consumption Time: 2.45485
PPO Batch Consumption Time: 0.27981
Total Iteration Time: 4.70398

Cumulative Model Updates: 54,128
Cumulative Timesteps: 451,541,938

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,774.14354
Policy Entropy: 3.37062
Value Function Loss: 0.00322

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.08919
Policy Update Magnitude: 0.51497
Value Function Update Magnitude: 0.51645

Collected Steps per Second: 22,801.91138
Overall Steps per Second: 10,872.73551

Timestep Collection Time: 2.19332
Timestep Consumption Time: 2.40644
PPO Batch Consumption Time: 0.27983
Total Iteration Time: 4.59976

Cumulative Model Updates: 54,134
Cumulative Timesteps: 451,591,950

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 451591950...
Checkpoint 451591950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,371.44648
Policy Entropy: 3.35795
Value Function Loss: 0.00314

Mean KL Divergence: 0.00727
SB3 Clip Fraction: 0.08356
Policy Update Magnitude: 0.52979
Value Function Update Magnitude: 0.52226

Collected Steps per Second: 22,626.34327
Overall Steps per Second: 10,728.88019

Timestep Collection Time: 2.21043
Timestep Consumption Time: 2.45119
PPO Batch Consumption Time: 0.27846
Total Iteration Time: 4.66162

Cumulative Model Updates: 54,140
Cumulative Timesteps: 451,641,964

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,738.42647
Policy Entropy: 3.37341
Value Function Loss: 0.00315

Mean KL Divergence: 0.00669
SB3 Clip Fraction: 0.07795
Policy Update Magnitude: 0.52799
Value Function Update Magnitude: 0.51965

Collected Steps per Second: 23,093.28477
Overall Steps per Second: 10,822.49466

Timestep Collection Time: 2.16556
Timestep Consumption Time: 2.45537
PPO Batch Consumption Time: 0.28038
Total Iteration Time: 4.62093

Cumulative Model Updates: 54,146
Cumulative Timesteps: 451,691,974

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 451691974...
Checkpoint 451691974 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,221.82043
Policy Entropy: 3.37260
Value Function Loss: 0.00313

Mean KL Divergence: 0.00631
SB3 Clip Fraction: 0.07289
Policy Update Magnitude: 0.52663
Value Function Update Magnitude: 0.52278

Collected Steps per Second: 22,784.72558
Overall Steps per Second: 10,699.05240

Timestep Collection Time: 2.19480
Timestep Consumption Time: 2.47926
PPO Batch Consumption Time: 0.28721
Total Iteration Time: 4.67406

Cumulative Model Updates: 54,152
Cumulative Timesteps: 451,741,982

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,840.95174
Policy Entropy: 3.37283
Value Function Loss: 0.00312

Mean KL Divergence: 0.00613
SB3 Clip Fraction: 0.07183
Policy Update Magnitude: 0.52158
Value Function Update Magnitude: 0.51809

Collected Steps per Second: 22,815.65411
Overall Steps per Second: 10,800.27941

Timestep Collection Time: 2.19174
Timestep Consumption Time: 2.43832
PPO Batch Consumption Time: 0.28028
Total Iteration Time: 4.63007

Cumulative Model Updates: 54,158
Cumulative Timesteps: 451,791,988

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 451791988...
Checkpoint 451791988 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 965.43059
Policy Entropy: 3.36259
Value Function Loss: 0.00331

Mean KL Divergence: 0.00637
SB3 Clip Fraction: 0.07430
Policy Update Magnitude: 0.52069
Value Function Update Magnitude: 0.52053

Collected Steps per Second: 22,674.42422
Overall Steps per Second: 10,755.29983

Timestep Collection Time: 2.20583
Timestep Consumption Time: 2.44453
PPO Batch Consumption Time: 0.28645
Total Iteration Time: 4.65036

Cumulative Model Updates: 54,164
Cumulative Timesteps: 451,842,004

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 812.96291
Policy Entropy: 3.36836
Value Function Loss: 0.00346

Mean KL Divergence: 0.00632
SB3 Clip Fraction: 0.07237
Policy Update Magnitude: 0.53343
Value Function Update Magnitude: 0.55415

Collected Steps per Second: 22,886.95443
Overall Steps per Second: 10,914.44678

Timestep Collection Time: 2.18500
Timestep Consumption Time: 2.39682
PPO Batch Consumption Time: 0.27935
Total Iteration Time: 4.58182

Cumulative Model Updates: 54,170
Cumulative Timesteps: 451,892,012

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 451892012...
Checkpoint 451892012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,169.53211
Policy Entropy: 3.37843
Value Function Loss: 0.00337

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.08856
Policy Update Magnitude: 0.53762
Value Function Update Magnitude: 0.54757

Collected Steps per Second: 22,223.82399
Overall Steps per Second: 10,624.68089

Timestep Collection Time: 2.25029
Timestep Consumption Time: 2.45668
PPO Batch Consumption Time: 0.28815
Total Iteration Time: 4.70696

Cumulative Model Updates: 54,176
Cumulative Timesteps: 451,942,022

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,025.08081
Policy Entropy: 3.38241
Value Function Loss: 0.00327

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.09255
Policy Update Magnitude: 0.52400
Value Function Update Magnitude: 0.53182

Collected Steps per Second: 22,748.45105
Overall Steps per Second: 10,819.53407

Timestep Collection Time: 2.19918
Timestep Consumption Time: 2.42468
PPO Batch Consumption Time: 0.28001
Total Iteration Time: 4.62386

Cumulative Model Updates: 54,182
Cumulative Timesteps: 451,992,050

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 451992050...
Checkpoint 451992050 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,476.68839
Policy Entropy: 3.37905
Value Function Loss: 0.00310

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.09230
Policy Update Magnitude: 0.51810
Value Function Update Magnitude: 0.51471

Collected Steps per Second: 22,269.35029
Overall Steps per Second: 10,760.87828

Timestep Collection Time: 2.24542
Timestep Consumption Time: 2.40141
PPO Batch Consumption Time: 0.27872
Total Iteration Time: 4.64683

Cumulative Model Updates: 54,188
Cumulative Timesteps: 452,042,054

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,707.25348
Policy Entropy: 3.36576
Value Function Loss: 0.00314

Mean KL Divergence: 0.00724
SB3 Clip Fraction: 0.08343
Policy Update Magnitude: 0.51960
Value Function Update Magnitude: 0.50640

Collected Steps per Second: 22,910.82037
Overall Steps per Second: 10,632.34745

Timestep Collection Time: 2.18290
Timestep Consumption Time: 2.52086
PPO Batch Consumption Time: 0.28939
Total Iteration Time: 4.70376

Cumulative Model Updates: 54,194
Cumulative Timesteps: 452,092,066

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 452092066...
Checkpoint 452092066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,326.14145
Policy Entropy: 3.36296
Value Function Loss: 0.00307

Mean KL Divergence: 0.00627
SB3 Clip Fraction: 0.07089
Policy Update Magnitude: 0.51872
Value Function Update Magnitude: 0.50987

Collected Steps per Second: 22,927.16873
Overall Steps per Second: 10,686.36972

Timestep Collection Time: 2.18195
Timestep Consumption Time: 2.49934
PPO Batch Consumption Time: 0.28611
Total Iteration Time: 4.68129

Cumulative Model Updates: 54,200
Cumulative Timesteps: 452,142,092

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 960.86500
Policy Entropy: 3.36658
Value Function Loss: 0.00311

Mean KL Divergence: 0.00650
SB3 Clip Fraction: 0.07407
Policy Update Magnitude: 0.52210
Value Function Update Magnitude: 0.50014

Collected Steps per Second: 23,011.13526
Overall Steps per Second: 10,893.99850

Timestep Collection Time: 2.17303
Timestep Consumption Time: 2.41702
PPO Batch Consumption Time: 0.28097
Total Iteration Time: 4.59005

Cumulative Model Updates: 54,206
Cumulative Timesteps: 452,192,096

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 452192096...
Checkpoint 452192096 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,144.96361
Policy Entropy: 3.36678
Value Function Loss: 0.00323

Mean KL Divergence: 0.00783
SB3 Clip Fraction: 0.08935
Policy Update Magnitude: 0.52145
Value Function Update Magnitude: 0.51270

Collected Steps per Second: 22,716.10201
Overall Steps per Second: 10,702.76213

Timestep Collection Time: 2.20117
Timestep Consumption Time: 2.47071
PPO Batch Consumption Time: 0.29492
Total Iteration Time: 4.67188

Cumulative Model Updates: 54,212
Cumulative Timesteps: 452,242,098

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 828.81220
Policy Entropy: 3.36951
Value Function Loss: 0.00324

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.09581
Policy Update Magnitude: 0.52294
Value Function Update Magnitude: 0.53412

Collected Steps per Second: 23,251.09354
Overall Steps per Second: 10,865.78951

Timestep Collection Time: 2.15147
Timestep Consumption Time: 2.45234
PPO Batch Consumption Time: 0.28306
Total Iteration Time: 4.60381

Cumulative Model Updates: 54,218
Cumulative Timesteps: 452,292,122

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 452292122...
Checkpoint 452292122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,285.40169
Policy Entropy: 3.37492
Value Function Loss: 0.00329

Mean KL Divergence: 0.00758
SB3 Clip Fraction: 0.08434
Policy Update Magnitude: 0.52587
Value Function Update Magnitude: 0.52411

Collected Steps per Second: 22,826.74006
Overall Steps per Second: 10,604.71196

Timestep Collection Time: 2.19138
Timestep Consumption Time: 2.52558
PPO Batch Consumption Time: 0.29296
Total Iteration Time: 4.71696

Cumulative Model Updates: 54,224
Cumulative Timesteps: 452,342,144

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,483.92570
Policy Entropy: 3.36610
Value Function Loss: 0.00336

Mean KL Divergence: 0.00608
SB3 Clip Fraction: 0.06804
Policy Update Magnitude: 0.53279
Value Function Update Magnitude: 0.52427

Collected Steps per Second: 22,964.66687
Overall Steps per Second: 10,877.78979

Timestep Collection Time: 2.17813
Timestep Consumption Time: 2.42023
PPO Batch Consumption Time: 0.28028
Total Iteration Time: 4.59836

Cumulative Model Updates: 54,230
Cumulative Timesteps: 452,392,164

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 452392164...
Checkpoint 452392164 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,077.43320
Policy Entropy: 3.35653
Value Function Loss: 0.00340

Mean KL Divergence: 0.00672
SB3 Clip Fraction: 0.07785
Policy Update Magnitude: 0.53305
Value Function Update Magnitude: 0.54461

Collected Steps per Second: 22,201.38586
Overall Steps per Second: 10,763.06743

Timestep Collection Time: 2.25247
Timestep Consumption Time: 2.39379
PPO Batch Consumption Time: 0.27832
Total Iteration Time: 4.64626

Cumulative Model Updates: 54,236
Cumulative Timesteps: 452,442,172

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,452.82108
Policy Entropy: 3.35886
Value Function Loss: 0.00336

Mean KL Divergence: 0.00749
SB3 Clip Fraction: 0.08632
Policy Update Magnitude: 0.52871
Value Function Update Magnitude: 0.57244

Collected Steps per Second: 22,465.71183
Overall Steps per Second: 10,777.23357

Timestep Collection Time: 2.22606
Timestep Consumption Time: 2.41428
PPO Batch Consumption Time: 0.28062
Total Iteration Time: 4.64034

Cumulative Model Updates: 54,242
Cumulative Timesteps: 452,492,182

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 452492182...
Checkpoint 452492182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,342.01747
Policy Entropy: 3.36439
Value Function Loss: 0.00328

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.09075
Policy Update Magnitude: 0.52241
Value Function Update Magnitude: 0.56403

Collected Steps per Second: 22,281.19434
Overall Steps per Second: 10,683.90906

Timestep Collection Time: 2.24422
Timestep Consumption Time: 2.43609
PPO Batch Consumption Time: 0.28065
Total Iteration Time: 4.68031

Cumulative Model Updates: 54,248
Cumulative Timesteps: 452,542,186

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,437.24927
Policy Entropy: 3.36596
Value Function Loss: 0.00330

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.08912
Policy Update Magnitude: 0.52152
Value Function Update Magnitude: 0.53732

Collected Steps per Second: 22,520.55343
Overall Steps per Second: 10,691.01864

Timestep Collection Time: 2.22126
Timestep Consumption Time: 2.45781
PPO Batch Consumption Time: 0.28864
Total Iteration Time: 4.67907

Cumulative Model Updates: 54,254
Cumulative Timesteps: 452,592,210

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 452592210...
Checkpoint 452592210 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,006.07683
Policy Entropy: 3.36508
Value Function Loss: 0.00333

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.09815
Policy Update Magnitude: 0.52657
Value Function Update Magnitude: 0.53020

Collected Steps per Second: 22,575.37523
Overall Steps per Second: 10,771.37148

Timestep Collection Time: 2.21604
Timestep Consumption Time: 2.42849
PPO Batch Consumption Time: 0.27953
Total Iteration Time: 4.64453

Cumulative Model Updates: 54,260
Cumulative Timesteps: 452,642,238

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,152.57206
Policy Entropy: 3.36160
Value Function Loss: 0.00327

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.10888
Policy Update Magnitude: 0.52765
Value Function Update Magnitude: 0.55225

Collected Steps per Second: 22,901.10867
Overall Steps per Second: 10,763.89803

Timestep Collection Time: 2.18409
Timestep Consumption Time: 2.46274
PPO Batch Consumption Time: 0.28764
Total Iteration Time: 4.64683

Cumulative Model Updates: 54,266
Cumulative Timesteps: 452,692,256

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 452692256...
Checkpoint 452692256 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 736.57805
Policy Entropy: 3.34945
Value Function Loss: 0.00329

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.10886
Policy Update Magnitude: 0.52271
Value Function Update Magnitude: 0.55097

Collected Steps per Second: 23,114.40308
Overall Steps per Second: 10,867.57819

Timestep Collection Time: 2.16376
Timestep Consumption Time: 2.43837
PPO Batch Consumption Time: 0.28464
Total Iteration Time: 4.60213

Cumulative Model Updates: 54,272
Cumulative Timesteps: 452,742,270

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,175.73767
Policy Entropy: 3.35160
Value Function Loss: 0.00337

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.10588
Policy Update Magnitude: 0.52309
Value Function Update Magnitude: 0.54404

Collected Steps per Second: 23,274.43065
Overall Steps per Second: 10,943.50428

Timestep Collection Time: 2.14948
Timestep Consumption Time: 2.42200
PPO Batch Consumption Time: 0.28328
Total Iteration Time: 4.57148

Cumulative Model Updates: 54,278
Cumulative Timesteps: 452,792,298

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 452792298...
Checkpoint 452792298 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 770.74884
Policy Entropy: 3.33757
Value Function Loss: 0.00341

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.08646
Policy Update Magnitude: 0.52539
Value Function Update Magnitude: 0.53474

Collected Steps per Second: 22,625.93594
Overall Steps per Second: 10,676.73922

Timestep Collection Time: 2.21038
Timestep Consumption Time: 2.47382
PPO Batch Consumption Time: 0.29480
Total Iteration Time: 4.68420

Cumulative Model Updates: 54,284
Cumulative Timesteps: 452,842,310

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,420.07386
Policy Entropy: 3.34627
Value Function Loss: 0.00339

Mean KL Divergence: 0.00727
SB3 Clip Fraction: 0.08321
Policy Update Magnitude: 0.52326
Value Function Update Magnitude: 0.52918

Collected Steps per Second: 22,925.12304
Overall Steps per Second: 10,799.48770

Timestep Collection Time: 2.18171
Timestep Consumption Time: 2.44962
PPO Batch Consumption Time: 0.28104
Total Iteration Time: 4.63133

Cumulative Model Updates: 54,290
Cumulative Timesteps: 452,892,326

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 452892326...
Checkpoint 452892326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,815.98501
Policy Entropy: 3.33403
Value Function Loss: 0.00331

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.09303
Policy Update Magnitude: 0.52149
Value Function Update Magnitude: 0.53736

Collected Steps per Second: 22,369.10189
Overall Steps per Second: 10,693.87885

Timestep Collection Time: 2.23737
Timestep Consumption Time: 2.44269
PPO Batch Consumption Time: 0.28552
Total Iteration Time: 4.68006

Cumulative Model Updates: 54,296
Cumulative Timesteps: 452,942,374

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,428.52662
Policy Entropy: 3.34575
Value Function Loss: 0.00323

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.08916
Policy Update Magnitude: 0.52463
Value Function Update Magnitude: 0.52623

Collected Steps per Second: 22,373.40162
Overall Steps per Second: 10,645.97867

Timestep Collection Time: 2.23498
Timestep Consumption Time: 2.46201
PPO Batch Consumption Time: 0.29015
Total Iteration Time: 4.69698

Cumulative Model Updates: 54,302
Cumulative Timesteps: 452,992,378

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 452992378...
Checkpoint 452992378 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,083.94659
Policy Entropy: 3.35003
Value Function Loss: 0.00323

Mean KL Divergence: 0.00705
SB3 Clip Fraction: 0.08059
Policy Update Magnitude: 0.52009
Value Function Update Magnitude: 0.51475

Collected Steps per Second: 22,375.96908
Overall Steps per Second: 10,687.10933

Timestep Collection Time: 2.23499
Timestep Consumption Time: 2.44448
PPO Batch Consumption Time: 0.28832
Total Iteration Time: 4.67947

Cumulative Model Updates: 54,308
Cumulative Timesteps: 453,042,388

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,140.05486
Policy Entropy: 3.35984
Value Function Loss: 0.00320

Mean KL Divergence: 0.00596
SB3 Clip Fraction: 0.06699
Policy Update Magnitude: 0.52478
Value Function Update Magnitude: 0.50823

Collected Steps per Second: 22,727.14983
Overall Steps per Second: 10,646.38858

Timestep Collection Time: 2.20072
Timestep Consumption Time: 2.49722
PPO Batch Consumption Time: 0.28562
Total Iteration Time: 4.69793

Cumulative Model Updates: 54,314
Cumulative Timesteps: 453,092,404

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 453092404...
Checkpoint 453092404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,619.19106
Policy Entropy: 3.36725
Value Function Loss: 0.00345

Mean KL Divergence: 0.00612
SB3 Clip Fraction: 0.06877
Policy Update Magnitude: 0.52946
Value Function Update Magnitude: 0.52311

Collected Steps per Second: 22,811.73411
Overall Steps per Second: 10,674.29202

Timestep Collection Time: 2.19291
Timestep Consumption Time: 2.49349
PPO Batch Consumption Time: 0.28652
Total Iteration Time: 4.68640

Cumulative Model Updates: 54,320
Cumulative Timesteps: 453,142,428

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,673.33848
Policy Entropy: 3.37264
Value Function Loss: 0.00321

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.08552
Policy Update Magnitude: 0.52282
Value Function Update Magnitude: 0.53678

Collected Steps per Second: 23,231.53084
Overall Steps per Second: 10,890.40352

Timestep Collection Time: 2.15242
Timestep Consumption Time: 2.43915
PPO Batch Consumption Time: 0.28498
Total Iteration Time: 4.59157

Cumulative Model Updates: 54,326
Cumulative Timesteps: 453,192,432

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 453192432...
Checkpoint 453192432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,122.31148
Policy Entropy: 3.36954
Value Function Loss: 0.00340

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.10728
Policy Update Magnitude: 0.51915
Value Function Update Magnitude: 0.52835

Collected Steps per Second: 22,671.40301
Overall Steps per Second: 10,637.53167

Timestep Collection Time: 2.20586
Timestep Consumption Time: 2.49542
PPO Batch Consumption Time: 0.29817
Total Iteration Time: 4.70128

Cumulative Model Updates: 54,332
Cumulative Timesteps: 453,242,442

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,282.23357
Policy Entropy: 3.36205
Value Function Loss: 0.00343

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.09862
Policy Update Magnitude: 0.51906
Value Function Update Magnitude: 0.52323

Collected Steps per Second: 23,219.66726
Overall Steps per Second: 10,861.95598

Timestep Collection Time: 2.15369
Timestep Consumption Time: 2.45027
PPO Batch Consumption Time: 0.28166
Total Iteration Time: 4.60396

Cumulative Model Updates: 54,338
Cumulative Timesteps: 453,292,450

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 453292450...
Checkpoint 453292450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,412.42330
Policy Entropy: 3.37544
Value Function Loss: 0.00358

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.09330
Policy Update Magnitude: 0.52363
Value Function Update Magnitude: 0.53719

Collected Steps per Second: 22,783.38146
Overall Steps per Second: 10,677.04661

Timestep Collection Time: 2.19590
Timestep Consumption Time: 2.48985
PPO Batch Consumption Time: 0.28994
Total Iteration Time: 4.68575

Cumulative Model Updates: 54,344
Cumulative Timesteps: 453,342,480

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,248.41533
Policy Entropy: 3.38227
Value Function Loss: 0.00349

Mean KL Divergence: 0.00687
SB3 Clip Fraction: 0.07823
Policy Update Magnitude: 0.52802
Value Function Update Magnitude: 0.53841

Collected Steps per Second: 23,009.66935
Overall Steps per Second: 10,828.99533

Timestep Collection Time: 2.17300
Timestep Consumption Time: 2.44423
PPO Batch Consumption Time: 0.28048
Total Iteration Time: 4.61723

Cumulative Model Updates: 54,350
Cumulative Timesteps: 453,392,480

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 453392480...
Checkpoint 453392480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,311.07856
Policy Entropy: 3.39199
Value Function Loss: 0.00339

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.10069
Policy Update Magnitude: 0.52635
Value Function Update Magnitude: 0.52967

Collected Steps per Second: 21,947.36369
Overall Steps per Second: 10,685.03390

Timestep Collection Time: 2.28036
Timestep Consumption Time: 2.40357
PPO Batch Consumption Time: 0.28052
Total Iteration Time: 4.68393

Cumulative Model Updates: 54,356
Cumulative Timesteps: 453,442,528

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,350.91506
Policy Entropy: 3.39139
Value Function Loss: 0.00328

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.09484
Policy Update Magnitude: 0.51820
Value Function Update Magnitude: 0.50993

Collected Steps per Second: 22,645.14023
Overall Steps per Second: 10,731.37022

Timestep Collection Time: 2.20816
Timestep Consumption Time: 2.45145
PPO Batch Consumption Time: 0.28902
Total Iteration Time: 4.65961

Cumulative Model Updates: 54,362
Cumulative Timesteps: 453,492,532

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 453492532...
Checkpoint 453492532 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 771.19076
Policy Entropy: 3.39241
Value Function Loss: 0.00348

Mean KL Divergence: 0.00724
SB3 Clip Fraction: 0.08205
Policy Update Magnitude: 0.52164
Value Function Update Magnitude: 0.51995

Collected Steps per Second: 22,241.08578
Overall Steps per Second: 10,646.97248

Timestep Collection Time: 2.25043
Timestep Consumption Time: 2.45063
PPO Batch Consumption Time: 0.28769
Total Iteration Time: 4.70105

Cumulative Model Updates: 54,368
Cumulative Timesteps: 453,542,584

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 800.04112
Policy Entropy: 3.39036
Value Function Loss: 0.00345

Mean KL Divergence: 0.00711
SB3 Clip Fraction: 0.08133
Policy Update Magnitude: 0.53487
Value Function Update Magnitude: 0.54711

Collected Steps per Second: 23,115.13360
Overall Steps per Second: 10,694.34770

Timestep Collection Time: 2.16326
Timestep Consumption Time: 2.51248
PPO Batch Consumption Time: 0.29316
Total Iteration Time: 4.67574

Cumulative Model Updates: 54,374
Cumulative Timesteps: 453,592,588

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 453592588...
Checkpoint 453592588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,468.95461
Policy Entropy: 3.39004
Value Function Loss: 0.00333

Mean KL Divergence: 0.00596
SB3 Clip Fraction: 0.06911
Policy Update Magnitude: 0.53892
Value Function Update Magnitude: 0.54040

Collected Steps per Second: 22,545.87949
Overall Steps per Second: 10,616.00665

Timestep Collection Time: 2.21841
Timestep Consumption Time: 2.49297
PPO Batch Consumption Time: 0.29046
Total Iteration Time: 4.71138

Cumulative Model Updates: 54,380
Cumulative Timesteps: 453,642,604

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,237.17831
Policy Entropy: 3.38655
Value Function Loss: 0.00315

Mean KL Divergence: 0.00619
SB3 Clip Fraction: 0.07084
Policy Update Magnitude: 0.52490
Value Function Update Magnitude: 0.52601

Collected Steps per Second: 23,073.45422
Overall Steps per Second: 10,945.89755

Timestep Collection Time: 2.16786
Timestep Consumption Time: 2.40189
PPO Batch Consumption Time: 0.28029
Total Iteration Time: 4.56975

Cumulative Model Updates: 54,386
Cumulative Timesteps: 453,692,624

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 453692624...
Checkpoint 453692624 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,402.18696
Policy Entropy: 3.38360
Value Function Loss: 0.00320

Mean KL Divergence: 0.00564
SB3 Clip Fraction: 0.06382
Policy Update Magnitude: 0.52361
Value Function Update Magnitude: 0.51368

Collected Steps per Second: 22,673.42185
Overall Steps per Second: 10,620.78118

Timestep Collection Time: 2.20575
Timestep Consumption Time: 2.50313
PPO Batch Consumption Time: 0.29037
Total Iteration Time: 4.70888

Cumulative Model Updates: 54,392
Cumulative Timesteps: 453,742,636

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,050.90011
Policy Entropy: 3.38101
Value Function Loss: 0.00316

Mean KL Divergence: 0.00670
SB3 Clip Fraction: 0.07633
Policy Update Magnitude: 0.52414
Value Function Update Magnitude: 0.50901

Collected Steps per Second: 22,979.10220
Overall Steps per Second: 10,924.43152

Timestep Collection Time: 2.17624
Timestep Consumption Time: 2.40139
PPO Batch Consumption Time: 0.27901
Total Iteration Time: 4.57763

Cumulative Model Updates: 54,398
Cumulative Timesteps: 453,792,644

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 453792644...
Checkpoint 453792644 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,462.36736
Policy Entropy: 3.37442
Value Function Loss: 0.00345

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.10550
Policy Update Magnitude: 0.51964
Value Function Update Magnitude: 0.50669

Collected Steps per Second: 22,788.95457
Overall Steps per Second: 10,715.31588

Timestep Collection Time: 2.19510
Timestep Consumption Time: 2.47336
PPO Batch Consumption Time: 0.29251
Total Iteration Time: 4.66846

Cumulative Model Updates: 54,404
Cumulative Timesteps: 453,842,668

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 974.86652
Policy Entropy: 3.36895
Value Function Loss: 0.00345

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.09085
Policy Update Magnitude: 0.52705
Value Function Update Magnitude: 0.51388

Collected Steps per Second: 23,003.42536
Overall Steps per Second: 10,767.01915

Timestep Collection Time: 2.17472
Timestep Consumption Time: 2.47151
PPO Batch Consumption Time: 0.28896
Total Iteration Time: 4.64623

Cumulative Model Updates: 54,410
Cumulative Timesteps: 453,892,694

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 453892694...
Checkpoint 453892694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,241.51313
Policy Entropy: 3.36617
Value Function Loss: 0.00343

Mean KL Divergence: 0.00670
SB3 Clip Fraction: 0.07620
Policy Update Magnitude: 0.53715
Value Function Update Magnitude: 0.53599

Collected Steps per Second: 22,499.74122
Overall Steps per Second: 10,736.92771

Timestep Collection Time: 2.22296
Timestep Consumption Time: 2.43536
PPO Batch Consumption Time: 0.27899
Total Iteration Time: 4.65832

Cumulative Model Updates: 54,416
Cumulative Timesteps: 453,942,710

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,549.86507
Policy Entropy: 3.37420
Value Function Loss: 0.00321

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.08725
Policy Update Magnitude: 0.54346
Value Function Update Magnitude: 0.52653

Collected Steps per Second: 22,688.75031
Overall Steps per Second: 10,749.04327

Timestep Collection Time: 2.20391
Timestep Consumption Time: 2.44804
PPO Batch Consumption Time: 0.28009
Total Iteration Time: 4.65195

Cumulative Model Updates: 54,422
Cumulative Timesteps: 453,992,714

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 453992714...
Checkpoint 453992714 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,524.69638
Policy Entropy: 3.38605
Value Function Loss: 0.00312

Mean KL Divergence: 0.00766
SB3 Clip Fraction: 0.08729
Policy Update Magnitude: 0.53577
Value Function Update Magnitude: 0.51826

Collected Steps per Second: 22,177.82459
Overall Steps per Second: 10,665.00642

Timestep Collection Time: 2.25477
Timestep Consumption Time: 2.43402
PPO Batch Consumption Time: 0.28005
Total Iteration Time: 4.68879

Cumulative Model Updates: 54,428
Cumulative Timesteps: 454,042,720

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 952.54411
Policy Entropy: 3.38260
Value Function Loss: 0.00320

Mean KL Divergence: 0.00723
SB3 Clip Fraction: 0.08407
Policy Update Magnitude: 0.52807
Value Function Update Magnitude: 0.49998

Collected Steps per Second: 22,612.28085
Overall Steps per Second: 10,574.89914

Timestep Collection Time: 2.21190
Timestep Consumption Time: 2.51780
PPO Batch Consumption Time: 0.29357
Total Iteration Time: 4.72969

Cumulative Model Updates: 54,434
Cumulative Timesteps: 454,092,736

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 454092736...
Checkpoint 454092736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,159.80128
Policy Entropy: 3.36941
Value Function Loss: 0.00328

Mean KL Divergence: 0.00710
SB3 Clip Fraction: 0.08046
Policy Update Magnitude: 0.53023
Value Function Update Magnitude: 0.50587

Collected Steps per Second: 22,596.77447
Overall Steps per Second: 10,565.14035

Timestep Collection Time: 2.21288
Timestep Consumption Time: 2.52004
PPO Batch Consumption Time: 0.28889
Total Iteration Time: 4.73292

Cumulative Model Updates: 54,440
Cumulative Timesteps: 454,142,740

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,706.93366
Policy Entropy: 3.36045
Value Function Loss: 0.00333

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.09095
Policy Update Magnitude: 0.53234
Value Function Update Magnitude: 0.51768

Collected Steps per Second: 23,014.30722
Overall Steps per Second: 10,857.29604

Timestep Collection Time: 2.17274
Timestep Consumption Time: 2.43283
PPO Batch Consumption Time: 0.28023
Total Iteration Time: 4.60557

Cumulative Model Updates: 54,446
Cumulative Timesteps: 454,192,744

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 454192744...
Checkpoint 454192744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,061.94983
Policy Entropy: 3.37314
Value Function Loss: 0.00314

Mean KL Divergence: 0.00673
SB3 Clip Fraction: 0.07635
Policy Update Magnitude: 0.53171
Value Function Update Magnitude: 0.52762

Collected Steps per Second: 22,815.06813
Overall Steps per Second: 10,746.64656

Timestep Collection Time: 2.19224
Timestep Consumption Time: 2.46187
PPO Batch Consumption Time: 0.28421
Total Iteration Time: 4.65410

Cumulative Model Updates: 54,452
Cumulative Timesteps: 454,242,760

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,138.21179
Policy Entropy: 3.38350
Value Function Loss: 0.00310

Mean KL Divergence: 0.00670
SB3 Clip Fraction: 0.07669
Policy Update Magnitude: 0.52857
Value Function Update Magnitude: 0.51656

Collected Steps per Second: 22,921.15317
Overall Steps per Second: 10,813.28958

Timestep Collection Time: 2.18261
Timestep Consumption Time: 2.44392
PPO Batch Consumption Time: 0.28048
Total Iteration Time: 4.62653

Cumulative Model Updates: 54,458
Cumulative Timesteps: 454,292,788

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 454292788...
Checkpoint 454292788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,280.63102
Policy Entropy: 3.36458
Value Function Loss: 0.00314

Mean KL Divergence: 0.00727
SB3 Clip Fraction: 0.08298
Policy Update Magnitude: 0.52594
Value Function Update Magnitude: 0.50451

Collected Steps per Second: 22,331.46553
Overall Steps per Second: 10,660.59550

Timestep Collection Time: 2.24016
Timestep Consumption Time: 2.45245
PPO Batch Consumption Time: 0.28152
Total Iteration Time: 4.69261

Cumulative Model Updates: 54,464
Cumulative Timesteps: 454,342,814

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,257.15332
Policy Entropy: 3.37899
Value Function Loss: 0.00318

Mean KL Divergence: 0.00691
SB3 Clip Fraction: 0.07891
Policy Update Magnitude: 0.52232
Value Function Update Magnitude: 0.51170

Collected Steps per Second: 22,836.50318
Overall Steps per Second: 10,686.73763

Timestep Collection Time: 2.19018
Timestep Consumption Time: 2.49002
PPO Batch Consumption Time: 0.29007
Total Iteration Time: 4.68019

Cumulative Model Updates: 54,470
Cumulative Timesteps: 454,392,830

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 454392830...
Checkpoint 454392830 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 857.37269
Policy Entropy: 3.37517
Value Function Loss: 0.00323

Mean KL Divergence: 0.00666
SB3 Clip Fraction: 0.07300
Policy Update Magnitude: 0.53272
Value Function Update Magnitude: 0.51699

Collected Steps per Second: 22,632.99600
Overall Steps per Second: 10,694.51660

Timestep Collection Time: 2.20969
Timestep Consumption Time: 2.46672
PPO Batch Consumption Time: 0.28779
Total Iteration Time: 4.67642

Cumulative Model Updates: 54,476
Cumulative Timesteps: 454,442,842

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,042.74421
Policy Entropy: 3.37187
Value Function Loss: 0.00327

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.09169
Policy Update Magnitude: 0.53346
Value Function Update Magnitude: 0.51769

Collected Steps per Second: 22,333.57350
Overall Steps per Second: 10,663.29272

Timestep Collection Time: 2.23914
Timestep Consumption Time: 2.45059
PPO Batch Consumption Time: 0.28392
Total Iteration Time: 4.68973

Cumulative Model Updates: 54,482
Cumulative Timesteps: 454,492,850

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 454492850...
Checkpoint 454492850 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,314.94716
Policy Entropy: 3.34670
Value Function Loss: 0.00325

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.08471
Policy Update Magnitude: 0.53558
Value Function Update Magnitude: 0.53115

Collected Steps per Second: 22,319.65197
Overall Steps per Second: 10,612.69610

Timestep Collection Time: 2.24143
Timestep Consumption Time: 2.47254
PPO Batch Consumption Time: 0.28457
Total Iteration Time: 4.71398

Cumulative Model Updates: 54,488
Cumulative Timesteps: 454,542,878

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,326.68869
Policy Entropy: 3.35641
Value Function Loss: 0.00309

Mean KL Divergence: 0.00762
SB3 Clip Fraction: 0.08694
Policy Update Magnitude: 0.53101
Value Function Update Magnitude: 0.51628

Collected Steps per Second: 22,480.79058
Overall Steps per Second: 10,592.02008

Timestep Collection Time: 2.22430
Timestep Consumption Time: 2.49661
PPO Batch Consumption Time: 0.29232
Total Iteration Time: 4.72091

Cumulative Model Updates: 54,494
Cumulative Timesteps: 454,592,882

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 454592882...
Checkpoint 454592882 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,087.28765
Policy Entropy: 3.34462
Value Function Loss: 0.00304

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.09741
Policy Update Magnitude: 0.52282
Value Function Update Magnitude: 0.48728

Collected Steps per Second: 22,150.58517
Overall Steps per Second: 10,525.49306

Timestep Collection Time: 2.25737
Timestep Consumption Time: 2.49319
PPO Batch Consumption Time: 0.28959
Total Iteration Time: 4.75056

Cumulative Model Updates: 54,500
Cumulative Timesteps: 454,642,884

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 827.95620
Policy Entropy: 3.35098
Value Function Loss: 0.00324

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.09869
Policy Update Magnitude: 0.52093
Value Function Update Magnitude: 0.48854

Collected Steps per Second: 22,990.05048
Overall Steps per Second: 10,797.42712

Timestep Collection Time: 2.17572
Timestep Consumption Time: 2.45686
PPO Batch Consumption Time: 0.27985
Total Iteration Time: 4.63259

Cumulative Model Updates: 54,506
Cumulative Timesteps: 454,692,904

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 454692904...
Checkpoint 454692904 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,185.13959
Policy Entropy: 3.33120
Value Function Loss: 0.00336

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.09071
Policy Update Magnitude: 0.53170
Value Function Update Magnitude: 0.52057

Collected Steps per Second: 22,679.69976
Overall Steps per Second: 10,764.29578

Timestep Collection Time: 2.20532
Timestep Consumption Time: 2.44115
PPO Batch Consumption Time: 0.27926
Total Iteration Time: 4.64647

Cumulative Model Updates: 54,512
Cumulative Timesteps: 454,742,920

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,002.16096
Policy Entropy: 3.34236
Value Function Loss: 0.00337

Mean KL Divergence: 0.01232
SB3 Clip Fraction: 0.12393
Policy Update Magnitude: 0.53469
Value Function Update Magnitude: 0.51642

Collected Steps per Second: 23,254.05205
Overall Steps per Second: 10,926.42730

Timestep Collection Time: 2.15016
Timestep Consumption Time: 2.42590
PPO Batch Consumption Time: 0.27909
Total Iteration Time: 4.57606

Cumulative Model Updates: 54,518
Cumulative Timesteps: 454,792,920

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 454792920...
Checkpoint 454792920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 947.63316
Policy Entropy: 3.36924
Value Function Loss: 0.00335

Mean KL Divergence: 0.01174
SB3 Clip Fraction: 0.11813
Policy Update Magnitude: 0.52717
Value Function Update Magnitude: 0.52152

Collected Steps per Second: 22,726.79158
Overall Steps per Second: 10,628.18578

Timestep Collection Time: 2.20119
Timestep Consumption Time: 2.50573
PPO Batch Consumption Time: 0.29503
Total Iteration Time: 4.70692

Cumulative Model Updates: 54,524
Cumulative Timesteps: 454,842,946

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,263.32301
Policy Entropy: 3.37402
Value Function Loss: 0.00334

Mean KL Divergence: 0.01141
SB3 Clip Fraction: 0.11368
Policy Update Magnitude: 0.52145
Value Function Update Magnitude: 0.52132

Collected Steps per Second: 23,144.70406
Overall Steps per Second: 10,834.06697

Timestep Collection Time: 2.16084
Timestep Consumption Time: 2.45534
PPO Batch Consumption Time: 0.28141
Total Iteration Time: 4.61618

Cumulative Model Updates: 54,530
Cumulative Timesteps: 454,892,958

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 454892958...
Checkpoint 454892958 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 633.63775
Policy Entropy: 3.35813
Value Function Loss: 0.00348

Mean KL Divergence: 0.01247
SB3 Clip Fraction: 0.13052
Policy Update Magnitude: 0.52443
Value Function Update Magnitude: 0.52419

Collected Steps per Second: 22,769.01534
Overall Steps per Second: 10,696.23337

Timestep Collection Time: 2.19614
Timestep Consumption Time: 2.47877
PPO Batch Consumption Time: 0.28878
Total Iteration Time: 4.67492

Cumulative Model Updates: 54,536
Cumulative Timesteps: 454,942,962

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,144.56326
Policy Entropy: 3.34956
Value Function Loss: 0.00354

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.10738
Policy Update Magnitude: 0.52921
Value Function Update Magnitude: 0.52223

Collected Steps per Second: 22,692.01588
Overall Steps per Second: 10,711.41567

Timestep Collection Time: 2.20518
Timestep Consumption Time: 2.46647
PPO Batch Consumption Time: 0.28750
Total Iteration Time: 4.67165

Cumulative Model Updates: 54,542
Cumulative Timesteps: 454,993,002

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 454993002...
Checkpoint 454993002 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,173.71529
Policy Entropy: 3.34280
Value Function Loss: 0.00348

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.09708
Policy Update Magnitude: 0.53216
Value Function Update Magnitude: 0.51405

Collected Steps per Second: 22,316.85028
Overall Steps per Second: 10,640.72376

Timestep Collection Time: 2.24127
Timestep Consumption Time: 2.45935
PPO Batch Consumption Time: 0.28846
Total Iteration Time: 4.70062

Cumulative Model Updates: 54,548
Cumulative Timesteps: 455,043,020

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,592.93407
Policy Entropy: 3.36175
Value Function Loss: 0.00354

Mean KL Divergence: 0.01085
SB3 Clip Fraction: 0.11304
Policy Update Magnitude: 0.53088
Value Function Update Magnitude: 0.51290

Collected Steps per Second: 22,560.00795
Overall Steps per Second: 10,666.97535

Timestep Collection Time: 2.21720
Timestep Consumption Time: 2.47204
PPO Batch Consumption Time: 0.28660
Total Iteration Time: 4.68924

Cumulative Model Updates: 54,554
Cumulative Timesteps: 455,093,040

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 455093040...
Checkpoint 455093040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 926.70419
Policy Entropy: 3.36657
Value Function Loss: 0.00347

Mean KL Divergence: 0.01066
SB3 Clip Fraction: 0.11367
Policy Update Magnitude: 0.52901
Value Function Update Magnitude: 0.53605

Collected Steps per Second: 22,407.18492
Overall Steps per Second: 10,637.69973

Timestep Collection Time: 2.23250
Timestep Consumption Time: 2.47002
PPO Batch Consumption Time: 0.28670
Total Iteration Time: 4.70252

Cumulative Model Updates: 54,560
Cumulative Timesteps: 455,143,064

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,493.71466
Policy Entropy: 3.36843
Value Function Loss: 0.00343

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.10139
Policy Update Magnitude: 0.52973
Value Function Update Magnitude: 0.55473

Collected Steps per Second: 22,558.21707
Overall Steps per Second: 10,644.36178

Timestep Collection Time: 2.21764
Timestep Consumption Time: 2.48213
PPO Batch Consumption Time: 0.28992
Total Iteration Time: 4.69977

Cumulative Model Updates: 54,566
Cumulative Timesteps: 455,193,090

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 455193090...
Checkpoint 455193090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,556.18355
Policy Entropy: 3.37957
Value Function Loss: 0.00328

Mean KL Divergence: 0.00690
SB3 Clip Fraction: 0.07738
Policy Update Magnitude: 0.52972
Value Function Update Magnitude: 0.53522

Collected Steps per Second: 22,741.35009
Overall Steps per Second: 10,616.44423

Timestep Collection Time: 2.19873
Timestep Consumption Time: 2.51114
PPO Batch Consumption Time: 0.29020
Total Iteration Time: 4.70986

Cumulative Model Updates: 54,572
Cumulative Timesteps: 455,243,092

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,318.79220
Policy Entropy: 3.38453
Value Function Loss: 0.00339

Mean KL Divergence: 0.00719
SB3 Clip Fraction: 0.08139
Policy Update Magnitude: 0.52855
Value Function Update Magnitude: 0.52094

Collected Steps per Second: 23,030.14318
Overall Steps per Second: 10,672.29961

Timestep Collection Time: 2.17168
Timestep Consumption Time: 2.51466
PPO Batch Consumption Time: 0.29035
Total Iteration Time: 4.68634

Cumulative Model Updates: 54,578
Cumulative Timesteps: 455,293,106

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 455293106...
Checkpoint 455293106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,758.41188
Policy Entropy: 3.39821
Value Function Loss: 0.00334

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.08814
Policy Update Magnitude: 0.52258
Value Function Update Magnitude: 0.52127

Collected Steps per Second: 21,407.97075
Overall Steps per Second: 10,234.25519

Timestep Collection Time: 2.33567
Timestep Consumption Time: 2.55008
PPO Batch Consumption Time: 0.29462
Total Iteration Time: 4.88575

Cumulative Model Updates: 54,584
Cumulative Timesteps: 455,343,108

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 825.81832
Policy Entropy: 3.38474
Value Function Loss: 0.00338

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.09584
Policy Update Magnitude: 0.51965
Value Function Update Magnitude: 0.51913

Collected Steps per Second: 23,178.80856
Overall Steps per Second: 10,878.28132

Timestep Collection Time: 2.15714
Timestep Consumption Time: 2.43917
PPO Batch Consumption Time: 0.28185
Total Iteration Time: 4.59631

Cumulative Model Updates: 54,590
Cumulative Timesteps: 455,393,108

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 455393108...
Checkpoint 455393108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 610.18652
Policy Entropy: 3.39613
Value Function Loss: 0.00347

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.09126
Policy Update Magnitude: 0.52373
Value Function Update Magnitude: 0.53329

Collected Steps per Second: 22,570.39820
Overall Steps per Second: 10,665.59476

Timestep Collection Time: 2.21529
Timestep Consumption Time: 2.47268
PPO Batch Consumption Time: 0.28715
Total Iteration Time: 4.68797

Cumulative Model Updates: 54,596
Cumulative Timesteps: 455,443,108

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,421.52063
Policy Entropy: 3.40465
Value Function Loss: 0.00354

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.09045
Policy Update Magnitude: 0.53258
Value Function Update Magnitude: 0.55403

Collected Steps per Second: 23,218.06074
Overall Steps per Second: 10,895.59233

Timestep Collection Time: 2.15358
Timestep Consumption Time: 2.43561
PPO Batch Consumption Time: 0.28040
Total Iteration Time: 4.58920

Cumulative Model Updates: 54,602
Cumulative Timesteps: 455,493,110

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 455493110...
Checkpoint 455493110 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,079.35176
Policy Entropy: 3.40601
Value Function Loss: 0.00338

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.08647
Policy Update Magnitude: 0.53821
Value Function Update Magnitude: 0.56261

Collected Steps per Second: 22,624.87642
Overall Steps per Second: 10,672.54962

Timestep Collection Time: 2.21111
Timestep Consumption Time: 2.47625
PPO Batch Consumption Time: 0.28822
Total Iteration Time: 4.68735

Cumulative Model Updates: 54,608
Cumulative Timesteps: 455,543,136

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,128.88601
Policy Entropy: 3.39888
Value Function Loss: 0.00347

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.09105
Policy Update Magnitude: 0.54022
Value Function Update Magnitude: 0.57858

Collected Steps per Second: 22,636.83366
Overall Steps per Second: 10,639.55648

Timestep Collection Time: 2.21003
Timestep Consumption Time: 2.49205
PPO Batch Consumption Time: 0.28949
Total Iteration Time: 4.70208

Cumulative Model Updates: 54,614
Cumulative Timesteps: 455,593,164

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 455593164...
Checkpoint 455593164 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,223.95989
Policy Entropy: 3.38779
Value Function Loss: 0.00338

Mean KL Divergence: 0.00783
SB3 Clip Fraction: 0.09047
Policy Update Magnitude: 0.53770
Value Function Update Magnitude: 0.59283

Collected Steps per Second: 22,425.32892
Overall Steps per Second: 10,585.57025

Timestep Collection Time: 2.22962
Timestep Consumption Time: 2.49379
PPO Batch Consumption Time: 0.29264
Total Iteration Time: 4.72341

Cumulative Model Updates: 54,620
Cumulative Timesteps: 455,643,164

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 764.28963
Policy Entropy: 3.39977
Value Function Loss: 0.00353

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.09267
Policy Update Magnitude: 0.53311
Value Function Update Magnitude: 0.58430

Collected Steps per Second: 22,311.15766
Overall Steps per Second: 10,685.11400

Timestep Collection Time: 2.24238
Timestep Consumption Time: 2.43984
PPO Batch Consumption Time: 0.28055
Total Iteration Time: 4.68221

Cumulative Model Updates: 54,626
Cumulative Timesteps: 455,693,194

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 455693194...
Checkpoint 455693194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,920.94485
Policy Entropy: 3.38882
Value Function Loss: 0.00351

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.09930
Policy Update Magnitude: 0.53890
Value Function Update Magnitude: 0.56455

Collected Steps per Second: 22,461.92267
Overall Steps per Second: 10,738.53545

Timestep Collection Time: 2.22617
Timestep Consumption Time: 2.43033
PPO Batch Consumption Time: 0.27890
Total Iteration Time: 4.65650

Cumulative Model Updates: 54,632
Cumulative Timesteps: 455,743,198

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 958.45221
Policy Entropy: 3.39382
Value Function Loss: 0.00373

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.09663
Policy Update Magnitude: 0.54940
Value Function Update Magnitude: 0.55688

Collected Steps per Second: 22,969.05794
Overall Steps per Second: 10,841.31697

Timestep Collection Time: 2.17771
Timestep Consumption Time: 2.43612
PPO Batch Consumption Time: 0.28030
Total Iteration Time: 4.61383

Cumulative Model Updates: 54,638
Cumulative Timesteps: 455,793,218

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 455793218...
Checkpoint 455793218 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 728.30457
Policy Entropy: 3.39290
Value Function Loss: 0.00363

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.09128
Policy Update Magnitude: 0.54935
Value Function Update Magnitude: 0.55568

Collected Steps per Second: 22,632.76900
Overall Steps per Second: 10,695.03281

Timestep Collection Time: 2.21016
Timestep Consumption Time: 2.46697
PPO Batch Consumption Time: 0.28862
Total Iteration Time: 4.67712

Cumulative Model Updates: 54,644
Cumulative Timesteps: 455,843,240

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,064.24715
Policy Entropy: 3.39982
Value Function Loss: 0.00378

Mean KL Divergence: 0.00720
SB3 Clip Fraction: 0.08176
Policy Update Magnitude: 0.54864
Value Function Update Magnitude: 0.55351

Collected Steps per Second: 22,867.47051
Overall Steps per Second: 10,906.54815

Timestep Collection Time: 2.18686
Timestep Consumption Time: 2.39827
PPO Batch Consumption Time: 0.27956
Total Iteration Time: 4.58514

Cumulative Model Updates: 54,650
Cumulative Timesteps: 455,893,248

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 455893248...
Checkpoint 455893248 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 985.78437
Policy Entropy: 3.39446
Value Function Loss: 0.00362

Mean KL Divergence: 0.00686
SB3 Clip Fraction: 0.07767
Policy Update Magnitude: 0.54784
Value Function Update Magnitude: 0.55313

Collected Steps per Second: 22,619.46561
Overall Steps per Second: 10,616.24654

Timestep Collection Time: 2.21155
Timestep Consumption Time: 2.50048
PPO Batch Consumption Time: 0.29127
Total Iteration Time: 4.71202

Cumulative Model Updates: 54,656
Cumulative Timesteps: 455,943,272

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,733.41252
Policy Entropy: 3.39502
Value Function Loss: 0.00357

Mean KL Divergence: 0.00751
SB3 Clip Fraction: 0.08604
Policy Update Magnitude: 0.54227
Value Function Update Magnitude: 0.54647

Collected Steps per Second: 22,845.70050
Overall Steps per Second: 10,872.12424

Timestep Collection Time: 2.18956
Timestep Consumption Time: 2.41138
PPO Batch Consumption Time: 0.28047
Total Iteration Time: 4.60094

Cumulative Model Updates: 54,662
Cumulative Timesteps: 455,993,294

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 455993294...
Checkpoint 455993294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,455.39184
Policy Entropy: 3.39469
Value Function Loss: 0.00361

Mean KL Divergence: 0.00743
SB3 Clip Fraction: 0.08489
Policy Update Magnitude: 0.54195
Value Function Update Magnitude: 0.53630

Collected Steps per Second: 22,852.17440
Overall Steps per Second: 10,737.48643

Timestep Collection Time: 2.18798
Timestep Consumption Time: 2.46861
PPO Batch Consumption Time: 0.29443
Total Iteration Time: 4.65658

Cumulative Model Updates: 54,668
Cumulative Timesteps: 456,043,294

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,520.64714
Policy Entropy: 3.39825
Value Function Loss: 0.00350

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.09229
Policy Update Magnitude: 0.55929
Value Function Update Magnitude: 0.53980

Collected Steps per Second: 22,940.49678
Overall Steps per Second: 10,793.30093

Timestep Collection Time: 2.17981
Timestep Consumption Time: 2.45325
PPO Batch Consumption Time: 0.28068
Total Iteration Time: 4.63306

Cumulative Model Updates: 54,674
Cumulative Timesteps: 456,093,300

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 456093300...
Checkpoint 456093300 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 769.97063
Policy Entropy: 3.42227
Value Function Loss: 0.00346

Mean KL Divergence: 0.00678
SB3 Clip Fraction: 0.07674
Policy Update Magnitude: 0.55481
Value Function Update Magnitude: 0.55589

Collected Steps per Second: 22,408.79042
Overall Steps per Second: 10,725.53499

Timestep Collection Time: 2.23225
Timestep Consumption Time: 2.43157
PPO Batch Consumption Time: 0.27894
Total Iteration Time: 4.66382

Cumulative Model Updates: 54,680
Cumulative Timesteps: 456,143,322

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,652.85803
Policy Entropy: 3.42081
Value Function Loss: 0.00315

Mean KL Divergence: 0.00644
SB3 Clip Fraction: 0.07158
Policy Update Magnitude: 0.54454
Value Function Update Magnitude: 0.55414

Collected Steps per Second: 22,821.31859
Overall Steps per Second: 10,797.02218

Timestep Collection Time: 2.19146
Timestep Consumption Time: 2.44056
PPO Batch Consumption Time: 0.27971
Total Iteration Time: 4.63202

Cumulative Model Updates: 54,686
Cumulative Timesteps: 456,193,334

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 456193334...
Checkpoint 456193334 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,207.65480
Policy Entropy: 3.42037
Value Function Loss: 0.00322

Mean KL Divergence: 0.00626
SB3 Clip Fraction: 0.07012
Policy Update Magnitude: 0.53665
Value Function Update Magnitude: 0.53733

Collected Steps per Second: 22,394.60459
Overall Steps per Second: 10,674.96294

Timestep Collection Time: 2.23348
Timestep Consumption Time: 2.45206
PPO Batch Consumption Time: 0.28571
Total Iteration Time: 4.68554

Cumulative Model Updates: 54,692
Cumulative Timesteps: 456,243,352

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,256.02749
Policy Entropy: 3.39185
Value Function Loss: 0.00312

Mean KL Divergence: 0.00607
SB3 Clip Fraction: 0.06963
Policy Update Magnitude: 0.53062
Value Function Update Magnitude: 0.52701

Collected Steps per Second: 22,804.53988
Overall Steps per Second: 10,625.53515

Timestep Collection Time: 2.19342
Timestep Consumption Time: 2.51410
PPO Batch Consumption Time: 0.29153
Total Iteration Time: 4.70753

Cumulative Model Updates: 54,698
Cumulative Timesteps: 456,293,372

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 456293372...
Checkpoint 456293372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,527.81837
Policy Entropy: 3.39654
Value Function Loss: 0.00338

Mean KL Divergence: 0.00717
SB3 Clip Fraction: 0.08368
Policy Update Magnitude: 0.53313
Value Function Update Magnitude: 0.53323

Collected Steps per Second: 23,141.04426
Overall Steps per Second: 10,856.72080

Timestep Collection Time: 2.16170
Timestep Consumption Time: 2.44595
PPO Batch Consumption Time: 0.28052
Total Iteration Time: 4.60765

Cumulative Model Updates: 54,704
Cumulative Timesteps: 456,343,396

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,982.16327
Policy Entropy: 3.38631
Value Function Loss: 0.00345

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.08960
Policy Update Magnitude: 0.54227
Value Function Update Magnitude: 0.52676

Collected Steps per Second: 23,048.84651
Overall Steps per Second: 10,737.99672

Timestep Collection Time: 2.17104
Timestep Consumption Time: 2.48905
PPO Batch Consumption Time: 0.29073
Total Iteration Time: 4.66009

Cumulative Model Updates: 54,710
Cumulative Timesteps: 456,393,436

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 456393436...
Checkpoint 456393436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,602.94004
Policy Entropy: 3.39718
Value Function Loss: 0.00344

Mean KL Divergence: 0.00739
SB3 Clip Fraction: 0.08375
Policy Update Magnitude: 0.54096
Value Function Update Magnitude: 0.52260

Collected Steps per Second: 22,604.85439
Overall Steps per Second: 10,661.94277

Timestep Collection Time: 2.21218
Timestep Consumption Time: 2.47796
PPO Batch Consumption Time: 0.29050
Total Iteration Time: 4.69014

Cumulative Model Updates: 54,716
Cumulative Timesteps: 456,443,442

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,646.81036
Policy Entropy: 3.39260
Value Function Loss: 0.00343

Mean KL Divergence: 0.00753
SB3 Clip Fraction: 0.08535
Policy Update Magnitude: 0.54128
Value Function Update Magnitude: 0.51058

Collected Steps per Second: 23,028.49475
Overall Steps per Second: 10,684.50214

Timestep Collection Time: 2.17209
Timestep Consumption Time: 2.50946
PPO Batch Consumption Time: 0.29186
Total Iteration Time: 4.68155

Cumulative Model Updates: 54,722
Cumulative Timesteps: 456,493,462

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 456493462...
Checkpoint 456493462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,053.79980
Policy Entropy: 3.39350
Value Function Loss: 0.00330

Mean KL Divergence: 0.00703
SB3 Clip Fraction: 0.08037
Policy Update Magnitude: 0.53894
Value Function Update Magnitude: 0.50640

Collected Steps per Second: 22,820.52760
Overall Steps per Second: 10,646.31865

Timestep Collection Time: 2.19162
Timestep Consumption Time: 2.50615
PPO Batch Consumption Time: 0.29285
Total Iteration Time: 4.69777

Cumulative Model Updates: 54,728
Cumulative Timesteps: 456,543,476

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 997.36027
Policy Entropy: 3.38295
Value Function Loss: 0.00331

Mean KL Divergence: 0.00651
SB3 Clip Fraction: 0.07393
Policy Update Magnitude: 0.53953
Value Function Update Magnitude: 0.49641

Collected Steps per Second: 22,932.54400
Overall Steps per Second: 10,839.33151

Timestep Collection Time: 2.18101
Timestep Consumption Time: 2.43330
PPO Batch Consumption Time: 0.28037
Total Iteration Time: 4.61431

Cumulative Model Updates: 54,734
Cumulative Timesteps: 456,593,492

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 456593492...
Checkpoint 456593492 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,888.41676
Policy Entropy: 3.39133
Value Function Loss: 0.00313

Mean KL Divergence: 0.00706
SB3 Clip Fraction: 0.08119
Policy Update Magnitude: 0.52849
Value Function Update Magnitude: 0.48666

Collected Steps per Second: 21,153.93064
Overall Steps per Second: 10,330.77007

Timestep Collection Time: 2.36505
Timestep Consumption Time: 2.47777
PPO Batch Consumption Time: 0.27975
Total Iteration Time: 4.84281

Cumulative Model Updates: 54,740
Cumulative Timesteps: 456,643,522

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 917.26068
Policy Entropy: 3.39803
Value Function Loss: 0.00303

Mean KL Divergence: 0.00691
SB3 Clip Fraction: 0.07924
Policy Update Magnitude: 0.52391
Value Function Update Magnitude: 0.48262

Collected Steps per Second: 21,354.91251
Overall Steps per Second: 10,354.08726

Timestep Collection Time: 2.34251
Timestep Consumption Time: 2.48882
PPO Batch Consumption Time: 0.28211
Total Iteration Time: 4.83133

Cumulative Model Updates: 54,746
Cumulative Timesteps: 456,693,546

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 456693546...
Checkpoint 456693546 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,118.27931
Policy Entropy: 3.41028
Value Function Loss: 0.00300

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.09832
Policy Update Magnitude: 0.51651
Value Function Update Magnitude: 0.50404

Collected Steps per Second: 20,288.72459
Overall Steps per Second: 10,022.79132

Timestep Collection Time: 2.46452
Timestep Consumption Time: 2.52431
PPO Batch Consumption Time: 0.29196
Total Iteration Time: 4.98883

Cumulative Model Updates: 54,752
Cumulative Timesteps: 456,743,548

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,513.24947
Policy Entropy: 3.41384
Value Function Loss: 0.00297

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.09168
Policy Update Magnitude: 0.50469
Value Function Update Magnitude: 0.51444

Collected Steps per Second: 22,605.46260
Overall Steps per Second: 10,742.12400

Timestep Collection Time: 2.21274
Timestep Consumption Time: 2.44370
PPO Batch Consumption Time: 0.28033
Total Iteration Time: 4.65643

Cumulative Model Updates: 54,758
Cumulative Timesteps: 456,793,568

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 456793568...
Checkpoint 456793568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,909.82109
Policy Entropy: 3.41285
Value Function Loss: 0.00305

Mean KL Divergence: 0.00666
SB3 Clip Fraction: 0.07645
Policy Update Magnitude: 0.51122
Value Function Update Magnitude: 0.50496

Collected Steps per Second: 22,076.16967
Overall Steps per Second: 10,625.11640

Timestep Collection Time: 2.26597
Timestep Consumption Time: 2.44212
PPO Batch Consumption Time: 0.28507
Total Iteration Time: 4.70809

Cumulative Model Updates: 54,764
Cumulative Timesteps: 456,843,592

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,002.94106
Policy Entropy: 3.41669
Value Function Loss: 0.00302

Mean KL Divergence: 0.00642
SB3 Clip Fraction: 0.07365
Policy Update Magnitude: 0.51361
Value Function Update Magnitude: 0.49850

Collected Steps per Second: 22,567.71838
Overall Steps per Second: 10,543.12968

Timestep Collection Time: 2.21653
Timestep Consumption Time: 2.52798
PPO Batch Consumption Time: 0.29372
Total Iteration Time: 4.74451

Cumulative Model Updates: 54,770
Cumulative Timesteps: 456,893,614

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 456893614...
Checkpoint 456893614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,662.90984
Policy Entropy: 3.41522
Value Function Loss: 0.00306

Mean KL Divergence: 0.00644
SB3 Clip Fraction: 0.07426
Policy Update Magnitude: 0.51877
Value Function Update Magnitude: 0.49465

Collected Steps per Second: 23,070.86143
Overall Steps per Second: 10,733.17778

Timestep Collection Time: 2.16836
Timestep Consumption Time: 2.49251
PPO Batch Consumption Time: 0.28940
Total Iteration Time: 4.66088

Cumulative Model Updates: 54,776
Cumulative Timesteps: 456,943,640

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,366.56198
Policy Entropy: 3.41130
Value Function Loss: 0.00306

Mean KL Divergence: 0.00597
SB3 Clip Fraction: 0.06728
Policy Update Magnitude: 0.52636
Value Function Update Magnitude: 0.49898

Collected Steps per Second: 22,927.98711
Overall Steps per Second: 10,747.10007

Timestep Collection Time: 2.18153
Timestep Consumption Time: 2.47257
PPO Batch Consumption Time: 0.29147
Total Iteration Time: 4.65409

Cumulative Model Updates: 54,782
Cumulative Timesteps: 456,993,658

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 456993658...
Checkpoint 456993658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,042.62928
Policy Entropy: 3.41500
Value Function Loss: 0.00304

Mean KL Divergence: 0.00632
SB3 Clip Fraction: 0.07160
Policy Update Magnitude: 0.53381
Value Function Update Magnitude: 0.52170

Collected Steps per Second: 22,681.94677
Overall Steps per Second: 10,677.48800

Timestep Collection Time: 2.20484
Timestep Consumption Time: 2.47885
PPO Batch Consumption Time: 0.29551
Total Iteration Time: 4.68369

Cumulative Model Updates: 54,788
Cumulative Timesteps: 457,043,668

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,007.22842
Policy Entropy: 3.40990
Value Function Loss: 0.00292

Mean KL Divergence: 0.00640
SB3 Clip Fraction: 0.07130
Policy Update Magnitude: 0.53176
Value Function Update Magnitude: 0.53884

Collected Steps per Second: 23,344.70555
Overall Steps per Second: 10,862.36968

Timestep Collection Time: 2.14233
Timestep Consumption Time: 2.46182
PPO Batch Consumption Time: 0.28857
Total Iteration Time: 4.60415

Cumulative Model Updates: 54,794
Cumulative Timesteps: 457,093,680

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 457093680...
Checkpoint 457093680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,862.26953
Policy Entropy: 3.42135
Value Function Loss: 0.00283

Mean KL Divergence: 0.00607
SB3 Clip Fraction: 0.06860
Policy Update Magnitude: 0.52150
Value Function Update Magnitude: 0.54585

Collected Steps per Second: 22,683.87802
Overall Steps per Second: 10,632.18711

Timestep Collection Time: 2.20544
Timestep Consumption Time: 2.49989
PPO Batch Consumption Time: 0.29071
Total Iteration Time: 4.70533

Cumulative Model Updates: 54,800
Cumulative Timesteps: 457,143,708

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,445.13900
Policy Entropy: 3.41289
Value Function Loss: 0.00293

Mean KL Divergence: 0.00569
SB3 Clip Fraction: 0.06428
Policy Update Magnitude: 0.51278
Value Function Update Magnitude: 0.54894

Collected Steps per Second: 23,038.36462
Overall Steps per Second: 10,858.37720

Timestep Collection Time: 2.17151
Timestep Consumption Time: 2.43581
PPO Batch Consumption Time: 0.28048
Total Iteration Time: 4.60732

Cumulative Model Updates: 54,806
Cumulative Timesteps: 457,193,736

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 457193736...
Checkpoint 457193736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,012.19495
Policy Entropy: 3.41214
Value Function Loss: 0.00292

Mean KL Divergence: 0.00602
SB3 Clip Fraction: 0.06830
Policy Update Magnitude: 0.51517
Value Function Update Magnitude: 0.54177

Collected Steps per Second: 22,013.98081
Overall Steps per Second: 10,405.65687

Timestep Collection Time: 2.27183
Timestep Consumption Time: 2.53440
PPO Batch Consumption Time: 0.29141
Total Iteration Time: 4.80623

Cumulative Model Updates: 54,812
Cumulative Timesteps: 457,243,748

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,478.31749
Policy Entropy: 3.41165
Value Function Loss: 0.00291

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.09411
Policy Update Magnitude: 0.51839
Value Function Update Magnitude: 0.54316

Collected Steps per Second: 22,704.91897
Overall Steps per Second: 10,776.53757

Timestep Collection Time: 2.20331
Timestep Consumption Time: 2.43881
PPO Batch Consumption Time: 0.28501
Total Iteration Time: 4.64212

Cumulative Model Updates: 54,818
Cumulative Timesteps: 457,293,774

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 457293774...
Checkpoint 457293774 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,818.87735
Policy Entropy: 3.39973
Value Function Loss: 0.00312

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.09463
Policy Update Magnitude: 0.52288
Value Function Update Magnitude: 0.54709

Collected Steps per Second: 22,513.12437
Overall Steps per Second: 10,636.41002

Timestep Collection Time: 2.22226
Timestep Consumption Time: 2.48140
PPO Batch Consumption Time: 0.28860
Total Iteration Time: 4.70365

Cumulative Model Updates: 54,824
Cumulative Timesteps: 457,343,804

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 953.28631
Policy Entropy: 3.40994
Value Function Loss: 0.00319

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.09421
Policy Update Magnitude: 0.53405
Value Function Update Magnitude: 0.55181

Collected Steps per Second: 22,520.31336
Overall Steps per Second: 10,579.71153

Timestep Collection Time: 2.22048
Timestep Consumption Time: 2.50611
PPO Batch Consumption Time: 0.29382
Total Iteration Time: 4.72659

Cumulative Model Updates: 54,830
Cumulative Timesteps: 457,393,810

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 457393810...
Checkpoint 457393810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,172.18147
Policy Entropy: 3.40685
Value Function Loss: 0.00318

Mean KL Divergence: 0.00727
SB3 Clip Fraction: 0.08153
Policy Update Magnitude: 0.53825
Value Function Update Magnitude: 0.55197

Collected Steps per Second: 22,775.76519
Overall Steps per Second: 10,639.01912

Timestep Collection Time: 2.19584
Timestep Consumption Time: 2.50497
PPO Batch Consumption Time: 0.29320
Total Iteration Time: 4.70081

Cumulative Model Updates: 54,836
Cumulative Timesteps: 457,443,822

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,228.37745
Policy Entropy: 3.42695
Value Function Loss: 0.00302

Mean KL Divergence: 0.00753
SB3 Clip Fraction: 0.08430
Policy Update Magnitude: 0.53199
Value Function Update Magnitude: 0.54411

Collected Steps per Second: 23,166.90079
Overall Steps per Second: 10,809.28495

Timestep Collection Time: 2.15834
Timestep Consumption Time: 2.46750
PPO Batch Consumption Time: 0.27924
Total Iteration Time: 4.62584

Cumulative Model Updates: 54,842
Cumulative Timesteps: 457,493,824

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 457493824...
Checkpoint 457493824 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,877.30739
Policy Entropy: 3.39836
Value Function Loss: 0.00303

Mean KL Divergence: 0.00732
SB3 Clip Fraction: 0.08549
Policy Update Magnitude: 0.51588
Value Function Update Magnitude: 0.52254

Collected Steps per Second: 22,703.55469
Overall Steps per Second: 10,501.62086

Timestep Collection Time: 2.20344
Timestep Consumption Time: 2.56020
PPO Batch Consumption Time: 0.29770
Total Iteration Time: 4.76365

Cumulative Model Updates: 54,848
Cumulative Timesteps: 457,543,850

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 852.56798
Policy Entropy: 3.38208
Value Function Loss: 0.00315

Mean KL Divergence: 0.00651
SB3 Clip Fraction: 0.07624
Policy Update Magnitude: 0.52013
Value Function Update Magnitude: 0.51867

Collected Steps per Second: 22,642.19301
Overall Steps per Second: 10,579.15558

Timestep Collection Time: 2.20924
Timestep Consumption Time: 2.51912
PPO Batch Consumption Time: 0.29434
Total Iteration Time: 4.72835

Cumulative Model Updates: 54,854
Cumulative Timesteps: 457,593,872

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 457593872...
Checkpoint 457593872 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,018.71422
Policy Entropy: 3.37853
Value Function Loss: 0.00322

Mean KL Divergence: 0.00758
SB3 Clip Fraction: 0.08830
Policy Update Magnitude: 0.53447
Value Function Update Magnitude: 0.51332

Collected Steps per Second: 22,791.60517
Overall Steps per Second: 10,634.21398

Timestep Collection Time: 2.19397
Timestep Consumption Time: 2.50822
PPO Batch Consumption Time: 0.29540
Total Iteration Time: 4.70218

Cumulative Model Updates: 54,860
Cumulative Timesteps: 457,643,876

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,269.42859
Policy Entropy: 3.38614
Value Function Loss: 0.00313

Mean KL Divergence: 0.00619
SB3 Clip Fraction: 0.06921
Policy Update Magnitude: 0.53527
Value Function Update Magnitude: 0.51470

Collected Steps per Second: 23,036.50694
Overall Steps per Second: 10,849.77825

Timestep Collection Time: 2.17116
Timestep Consumption Time: 2.43870
PPO Batch Consumption Time: 0.28046
Total Iteration Time: 4.60986

Cumulative Model Updates: 54,866
Cumulative Timesteps: 457,693,892

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 457693892...
Checkpoint 457693892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,743.86643
Policy Entropy: 3.38628
Value Function Loss: 0.00308

Mean KL Divergence: 0.00682
SB3 Clip Fraction: 0.08009
Policy Update Magnitude: 0.53167
Value Function Update Magnitude: 0.51949

Collected Steps per Second: 23,034.88183
Overall Steps per Second: 10,672.69716

Timestep Collection Time: 2.17175
Timestep Consumption Time: 2.51554
PPO Batch Consumption Time: 0.29497
Total Iteration Time: 4.68729

Cumulative Model Updates: 54,872
Cumulative Timesteps: 457,743,918

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,102.77973
Policy Entropy: 3.39927
Value Function Loss: 0.00303

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.09621
Policy Update Magnitude: 0.53282
Value Function Update Magnitude: 0.53807

Collected Steps per Second: 22,884.38369
Overall Steps per Second: 10,885.09194

Timestep Collection Time: 2.18638
Timestep Consumption Time: 2.41018
PPO Batch Consumption Time: 0.28039
Total Iteration Time: 4.59656

Cumulative Model Updates: 54,878
Cumulative Timesteps: 457,793,952

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 457793952...
Checkpoint 457793952 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,064.10749
Policy Entropy: 3.40420
Value Function Loss: 0.00316

Mean KL Divergence: 0.00714
SB3 Clip Fraction: 0.08186
Policy Update Magnitude: 0.54698
Value Function Update Magnitude: 0.54234

Collected Steps per Second: 22,501.38222
Overall Steps per Second: 10,724.90965

Timestep Collection Time: 2.22324
Timestep Consumption Time: 2.44123
PPO Batch Consumption Time: 0.28759
Total Iteration Time: 4.66447

Cumulative Model Updates: 54,884
Cumulative Timesteps: 457,843,978

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,703.12743
Policy Entropy: 3.40982
Value Function Loss: 0.00304

Mean KL Divergence: 0.00672
SB3 Clip Fraction: 0.07673
Policy Update Magnitude: 0.53917
Value Function Update Magnitude: 0.52001

Collected Steps per Second: 22,733.95107
Overall Steps per Second: 10,849.51800

Timestep Collection Time: 2.19944
Timestep Consumption Time: 2.40924
PPO Batch Consumption Time: 0.28053
Total Iteration Time: 4.60868

Cumulative Model Updates: 54,890
Cumulative Timesteps: 457,893,980

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 457893980...
Checkpoint 457893980 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,133.19360
Policy Entropy: 3.38545
Value Function Loss: 0.00306

Mean KL Divergence: 0.00603
SB3 Clip Fraction: 0.06945
Policy Update Magnitude: 0.53505
Value Function Update Magnitude: 0.48802

Collected Steps per Second: 22,405.46507
Overall Steps per Second: 10,724.69740

Timestep Collection Time: 2.23160
Timestep Consumption Time: 2.43054
PPO Batch Consumption Time: 0.27871
Total Iteration Time: 4.66214

Cumulative Model Updates: 54,896
Cumulative Timesteps: 457,943,980

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 884.74898
Policy Entropy: 3.40122
Value Function Loss: 0.00299

Mean KL Divergence: 0.00648
SB3 Clip Fraction: 0.07529
Policy Update Magnitude: 0.52797
Value Function Update Magnitude: 0.47435

Collected Steps per Second: 22,151.93561
Overall Steps per Second: 10,578.69167

Timestep Collection Time: 2.25714
Timestep Consumption Time: 2.46934
PPO Batch Consumption Time: 0.29105
Total Iteration Time: 4.72648

Cumulative Model Updates: 54,902
Cumulative Timesteps: 457,993,980

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 457993980...
Checkpoint 457993980 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,006.84737
Policy Entropy: 3.40999
Value Function Loss: 0.00295

Mean KL Divergence: 0.00695
SB3 Clip Fraction: 0.07913
Policy Update Magnitude: 0.52003
Value Function Update Magnitude: 0.48035

Collected Steps per Second: 22,964.90865
Overall Steps per Second: 10,825.06993

Timestep Collection Time: 2.17784
Timestep Consumption Time: 2.44236
PPO Batch Consumption Time: 0.28025
Total Iteration Time: 4.62020

Cumulative Model Updates: 54,908
Cumulative Timesteps: 458,043,994

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,648.16184
Policy Entropy: 3.42047
Value Function Loss: 0.00291

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.09343
Policy Update Magnitude: 0.52476
Value Function Update Magnitude: 0.48770

Collected Steps per Second: 22,982.70988
Overall Steps per Second: 10,889.15172

Timestep Collection Time: 2.17555
Timestep Consumption Time: 2.41618
PPO Batch Consumption Time: 0.28119
Total Iteration Time: 4.59173

Cumulative Model Updates: 54,914
Cumulative Timesteps: 458,093,994

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 458093994...
Checkpoint 458093994 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,044.62000
Policy Entropy: 3.41151
Value Function Loss: 0.00300

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.09394
Policy Update Magnitude: 0.52716
Value Function Update Magnitude: 0.49569

Collected Steps per Second: 22,971.71263
Overall Steps per Second: 10,730.61426

Timestep Collection Time: 2.17659
Timestep Consumption Time: 2.48298
PPO Batch Consumption Time: 0.28844
Total Iteration Time: 4.65957

Cumulative Model Updates: 54,920
Cumulative Timesteps: 458,143,994

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,582.68513
Policy Entropy: 3.40071
Value Function Loss: 0.00294

Mean KL Divergence: 0.00748
SB3 Clip Fraction: 0.08491
Policy Update Magnitude: 0.53772
Value Function Update Magnitude: 0.49795

Collected Steps per Second: 22,593.41277
Overall Steps per Second: 10,835.04722

Timestep Collection Time: 2.21339
Timestep Consumption Time: 2.40200
PPO Batch Consumption Time: 0.28001
Total Iteration Time: 4.61539

Cumulative Model Updates: 54,926
Cumulative Timesteps: 458,194,002

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 458194002...
Checkpoint 458194002 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,754.95770
Policy Entropy: 3.38688
Value Function Loss: 0.00302

Mean KL Divergence: 0.00697
SB3 Clip Fraction: 0.08029
Policy Update Magnitude: 0.54257
Value Function Update Magnitude: 0.50891

Collected Steps per Second: 22,566.49138
Overall Steps per Second: 10,783.24725

Timestep Collection Time: 2.21692
Timestep Consumption Time: 2.42250
PPO Batch Consumption Time: 0.27913
Total Iteration Time: 4.63942

Cumulative Model Updates: 54,932
Cumulative Timesteps: 458,244,030

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,689.98053
Policy Entropy: 3.36608
Value Function Loss: 0.00315

Mean KL Divergence: 0.00672
SB3 Clip Fraction: 0.07792
Policy Update Magnitude: 0.54800
Value Function Update Magnitude: 0.53019

Collected Steps per Second: 23,043.50128
Overall Steps per Second: 10,825.87692

Timestep Collection Time: 2.17042
Timestep Consumption Time: 2.44944
PPO Batch Consumption Time: 0.28038
Total Iteration Time: 4.61986

Cumulative Model Updates: 54,938
Cumulative Timesteps: 458,294,044

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 458294044...
Checkpoint 458294044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,624.44610
Policy Entropy: 3.36503
Value Function Loss: 0.00328

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.08824
Policy Update Magnitude: 0.54885
Value Function Update Magnitude: 0.54815

Collected Steps per Second: 22,074.60321
Overall Steps per Second: 10,636.17107

Timestep Collection Time: 2.26622
Timestep Consumption Time: 2.43716
PPO Batch Consumption Time: 0.28021
Total Iteration Time: 4.70338

Cumulative Model Updates: 54,944
Cumulative Timesteps: 458,344,070

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,576.88100
Policy Entropy: 3.36142
Value Function Loss: 0.00318

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.09306
Policy Update Magnitude: 0.54603
Value Function Update Magnitude: 0.55487

Collected Steps per Second: 22,435.92232
Overall Steps per Second: 10,568.05505

Timestep Collection Time: 2.22866
Timestep Consumption Time: 2.50277
PPO Batch Consumption Time: 0.29365
Total Iteration Time: 4.73143

Cumulative Model Updates: 54,950
Cumulative Timesteps: 458,394,072

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 458394072...
Checkpoint 458394072 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,330.81237
Policy Entropy: 3.36991
Value Function Loss: 0.00304

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.10029
Policy Update Magnitude: 0.53255
Value Function Update Magnitude: 0.53941

Collected Steps per Second: 22,394.58689
Overall Steps per Second: 10,541.82359

Timestep Collection Time: 2.23268
Timestep Consumption Time: 2.51033
PPO Batch Consumption Time: 0.29384
Total Iteration Time: 4.74301

Cumulative Model Updates: 54,956
Cumulative Timesteps: 458,444,072

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,929.58659
Policy Entropy: 3.37273
Value Function Loss: 0.00298

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.10278
Policy Update Magnitude: 0.52672
Value Function Update Magnitude: 0.52518

Collected Steps per Second: 22,574.86786
Overall Steps per Second: 10,837.44557

Timestep Collection Time: 2.21618
Timestep Consumption Time: 2.40022
PPO Batch Consumption Time: 0.27939
Total Iteration Time: 4.61640

Cumulative Model Updates: 54,962
Cumulative Timesteps: 458,494,102

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 458494102...
Checkpoint 458494102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,132.28627
Policy Entropy: 3.37182
Value Function Loss: 0.00299

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.09672
Policy Update Magnitude: 0.53181
Value Function Update Magnitude: 0.52532

Collected Steps per Second: 22,479.56538
Overall Steps per Second: 10,676.49697

Timestep Collection Time: 2.22451
Timestep Consumption Time: 2.45924
PPO Batch Consumption Time: 0.27976
Total Iteration Time: 4.68375

Cumulative Model Updates: 54,968
Cumulative Timesteps: 458,544,108

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,130.03002
Policy Entropy: 3.37259
Value Function Loss: 0.00303

Mean KL Divergence: 0.00738
SB3 Clip Fraction: 0.08432
Policy Update Magnitude: 0.54586
Value Function Update Magnitude: 0.52943

Collected Steps per Second: 22,818.38702
Overall Steps per Second: 10,872.14184

Timestep Collection Time: 2.19148
Timestep Consumption Time: 2.40798
PPO Batch Consumption Time: 0.27978
Total Iteration Time: 4.59946

Cumulative Model Updates: 54,974
Cumulative Timesteps: 458,594,114

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 458594114...
Checkpoint 458594114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,101.12710
Policy Entropy: 3.37166
Value Function Loss: 0.00303

Mean KL Divergence: 0.00733
SB3 Clip Fraction: 0.08439
Policy Update Magnitude: 0.54571
Value Function Update Magnitude: 0.51817

Collected Steps per Second: 22,388.92707
Overall Steps per Second: 10,675.98745

Timestep Collection Time: 2.23441
Timestep Consumption Time: 2.45143
PPO Batch Consumption Time: 0.28150
Total Iteration Time: 4.68584

Cumulative Model Updates: 54,980
Cumulative Timesteps: 458,644,140

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,617.21028
Policy Entropy: 3.36772
Value Function Loss: 0.00307

Mean KL Divergence: 0.00760
SB3 Clip Fraction: 0.08556
Policy Update Magnitude: 0.53753
Value Function Update Magnitude: 0.51971

Collected Steps per Second: 22,983.05918
Overall Steps per Second: 10,683.19657

Timestep Collection Time: 2.17621
Timestep Consumption Time: 2.50553
PPO Batch Consumption Time: 0.28986
Total Iteration Time: 4.68174

Cumulative Model Updates: 54,986
Cumulative Timesteps: 458,694,156

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 458694156...
Checkpoint 458694156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 995.89167
Policy Entropy: 3.35455
Value Function Loss: 0.00303

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.08662
Policy Update Magnitude: 0.52839
Value Function Update Magnitude: 0.53477

Collected Steps per Second: 23,066.74299
Overall Steps per Second: 10,856.03432

Timestep Collection Time: 2.16788
Timestep Consumption Time: 2.43840
PPO Batch Consumption Time: 0.28103
Total Iteration Time: 4.60629

Cumulative Model Updates: 54,992
Cumulative Timesteps: 458,744,162

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,602.32620
Policy Entropy: 3.36225
Value Function Loss: 0.00289

Mean KL Divergence: 0.00744
SB3 Clip Fraction: 0.08743
Policy Update Magnitude: 0.53105
Value Function Update Magnitude: 0.52616

Collected Steps per Second: 17,086.22897
Overall Steps per Second: 7,249.22332

Timestep Collection Time: 2.92797
Timestep Consumption Time: 3.97318
PPO Batch Consumption Time: 0.46185
Total Iteration Time: 6.90115

Cumulative Model Updates: 54,998
Cumulative Timesteps: 458,794,190

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 458794190...
Checkpoint 458794190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,352.30921
Policy Entropy: 3.36990
Value Function Loss: 0.00269

Mean KL Divergence: 0.00682
SB3 Clip Fraction: 0.07775
Policy Update Magnitude: 0.52439
Value Function Update Magnitude: 0.50453

Collected Steps per Second: 15,214.30705
Overall Steps per Second: 8,478.16455

Timestep Collection Time: 3.28717
Timestep Consumption Time: 2.61175
PPO Batch Consumption Time: 0.29872
Total Iteration Time: 5.89892

Cumulative Model Updates: 55,004
Cumulative Timesteps: 458,844,202

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,345.85818
Policy Entropy: 3.38105
Value Function Loss: 0.00280

Mean KL Divergence: 0.00686
SB3 Clip Fraction: 0.07584
Policy Update Magnitude: 0.52447
Value Function Update Magnitude: 0.49245

Collected Steps per Second: 20,000.36462
Overall Steps per Second: 9,958.12575

Timestep Collection Time: 2.50125
Timestep Consumption Time: 2.52238
PPO Batch Consumption Time: 0.29821
Total Iteration Time: 5.02364

Cumulative Model Updates: 55,010
Cumulative Timesteps: 458,894,228

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 458894228...
Checkpoint 458894228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,142.04544
Policy Entropy: 3.37722
Value Function Loss: 0.00294

Mean KL Divergence: 0.00575
SB3 Clip Fraction: 0.06382
Policy Update Magnitude: 0.53986
Value Function Update Magnitude: 0.50930

Collected Steps per Second: 18,793.71130
Overall Steps per Second: 9,626.92981

Timestep Collection Time: 2.66100
Timestep Consumption Time: 2.53381
PPO Batch Consumption Time: 0.28891
Total Iteration Time: 5.19480

Cumulative Model Updates: 55,016
Cumulative Timesteps: 458,944,238

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,287.20077
Policy Entropy: 3.38213
Value Function Loss: 0.00299

Mean KL Divergence: 0.00576
SB3 Clip Fraction: 0.06557
Policy Update Magnitude: 0.54776
Value Function Update Magnitude: 0.54355

Collected Steps per Second: 17,525.25149
Overall Steps per Second: 9,246.89760

Timestep Collection Time: 2.85462
Timestep Consumption Time: 2.55562
PPO Batch Consumption Time: 0.29102
Total Iteration Time: 5.41025

Cumulative Model Updates: 55,022
Cumulative Timesteps: 458,994,266

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 458994266...
Checkpoint 458994266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 841.52470
Policy Entropy: 3.38500
Value Function Loss: 0.00310

Mean KL Divergence: 0.00593
SB3 Clip Fraction: 0.06787
Policy Update Magnitude: 0.54230
Value Function Update Magnitude: 0.54800

Collected Steps per Second: 20,517.31971
Overall Steps per Second: 9,840.69112

Timestep Collection Time: 2.43736
Timestep Consumption Time: 2.64440
PPO Batch Consumption Time: 0.30549
Total Iteration Time: 5.08176

Cumulative Model Updates: 55,028
Cumulative Timesteps: 459,044,274

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,095.17628
Policy Entropy: 3.38846
Value Function Loss: 0.00307

Mean KL Divergence: 0.00620
SB3 Clip Fraction: 0.07157
Policy Update Magnitude: 0.54960
Value Function Update Magnitude: 0.54674

Collected Steps per Second: 17,573.95404
Overall Steps per Second: 9,393.44160

Timestep Collection Time: 2.84660
Timestep Consumption Time: 2.47903
PPO Batch Consumption Time: 0.28235
Total Iteration Time: 5.32563

Cumulative Model Updates: 55,034
Cumulative Timesteps: 459,094,300

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 459094300...
Checkpoint 459094300 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 947.52638
Policy Entropy: 3.38170
Value Function Loss: 0.00328

Mean KL Divergence: 0.00594
SB3 Clip Fraction: 0.06693
Policy Update Magnitude: 0.56135
Value Function Update Magnitude: 0.55438

Collected Steps per Second: 20,959.74449
Overall Steps per Second: 10,313.69149

Timestep Collection Time: 2.38705
Timestep Consumption Time: 2.46398
PPO Batch Consumption Time: 0.28203
Total Iteration Time: 4.85103

Cumulative Model Updates: 55,040
Cumulative Timesteps: 459,144,332

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,159.34604
Policy Entropy: 3.38299
Value Function Loss: 0.00319

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.09149
Policy Update Magnitude: 0.56366
Value Function Update Magnitude: 0.56876

Collected Steps per Second: 19,791.91074
Overall Steps per Second: 9,790.07068

Timestep Collection Time: 2.52740
Timestep Consumption Time: 2.58207
PPO Batch Consumption Time: 0.29879
Total Iteration Time: 5.10946

Cumulative Model Updates: 55,046
Cumulative Timesteps: 459,194,354

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 459194354...
Checkpoint 459194354 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,131.57211
Policy Entropy: 3.38768
Value Function Loss: 0.00312

Mean KL Divergence: 0.00654
SB3 Clip Fraction: 0.07474
Policy Update Magnitude: 0.55352
Value Function Update Magnitude: 0.58917

Collected Steps per Second: 22,439.42217
Overall Steps per Second: 10,624.32503

Timestep Collection Time: 2.22893
Timestep Consumption Time: 2.47875
PPO Batch Consumption Time: 0.29014
Total Iteration Time: 4.70769

Cumulative Model Updates: 55,052
Cumulative Timesteps: 459,244,370

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 764.09780
Policy Entropy: 3.38628
Value Function Loss: 0.00302

Mean KL Divergence: 0.00673
SB3 Clip Fraction: 0.07714
Policy Update Magnitude: 0.55512
Value Function Update Magnitude: 0.59224

Collected Steps per Second: 20,582.38735
Overall Steps per Second: 9,971.26907

Timestep Collection Time: 2.43072
Timestep Consumption Time: 2.58670
PPO Batch Consumption Time: 0.30173
Total Iteration Time: 5.01742

Cumulative Model Updates: 55,058
Cumulative Timesteps: 459,294,400

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 459294400...
Checkpoint 459294400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,232.51170
Policy Entropy: 3.39384
Value Function Loss: 0.00303

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.08959
Policy Update Magnitude: 0.54777
Value Function Update Magnitude: 0.58327

Collected Steps per Second: 21,830.99360
Overall Steps per Second: 10,462.90027

Timestep Collection Time: 2.29050
Timestep Consumption Time: 2.48867
PPO Batch Consumption Time: 0.28841
Total Iteration Time: 4.77917

Cumulative Model Updates: 55,064
Cumulative Timesteps: 459,344,404

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,409.80951
Policy Entropy: 3.37558
Value Function Loss: 0.00318

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.09648
Policy Update Magnitude: 0.55175
Value Function Update Magnitude: 0.59227

Collected Steps per Second: 22,407.69279
Overall Steps per Second: 10,631.13841

Timestep Collection Time: 2.23245
Timestep Consumption Time: 2.47298
PPO Batch Consumption Time: 0.28008
Total Iteration Time: 4.70542

Cumulative Model Updates: 55,070
Cumulative Timesteps: 459,394,428

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 459394428...
Checkpoint 459394428 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,119.13691
Policy Entropy: 3.39203
Value Function Loss: 0.00320

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.10284
Policy Update Magnitude: 0.55792
Value Function Update Magnitude: 0.59642

Collected Steps per Second: 22,417.36823
Overall Steps per Second: 10,665.64923

Timestep Collection Time: 2.23113
Timestep Consumption Time: 2.45832
PPO Batch Consumption Time: 0.27955
Total Iteration Time: 4.68945

Cumulative Model Updates: 55,076
Cumulative Timesteps: 459,444,444

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,805.51877
Policy Entropy: 3.37843
Value Function Loss: 0.00320

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.11642
Policy Update Magnitude: 0.55652
Value Function Update Magnitude: 0.58459

Collected Steps per Second: 22,910.32476
Overall Steps per Second: 10,858.66242

Timestep Collection Time: 2.18356
Timestep Consumption Time: 2.42346
PPO Batch Consumption Time: 0.28132
Total Iteration Time: 4.60701

Cumulative Model Updates: 55,082
Cumulative Timesteps: 459,494,470

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 459494470...
Checkpoint 459494470 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,155.35454
Policy Entropy: 3.38260
Value Function Loss: 0.00318

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.10519
Policy Update Magnitude: 0.55302
Value Function Update Magnitude: 0.58495

Collected Steps per Second: 22,736.97327
Overall Steps per Second: 10,542.50843

Timestep Collection Time: 2.20020
Timestep Consumption Time: 2.54497
PPO Batch Consumption Time: 0.29977
Total Iteration Time: 4.74517

Cumulative Model Updates: 55,088
Cumulative Timesteps: 459,544,496

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,107.86400
Policy Entropy: 3.37633
Value Function Loss: 0.00313

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.10976
Policy Update Magnitude: 0.55401
Value Function Update Magnitude: 0.57664

Collected Steps per Second: 21,406.39089
Overall Steps per Second: 10,378.49829

Timestep Collection Time: 2.33622
Timestep Consumption Time: 2.48240
PPO Batch Consumption Time: 0.28905
Total Iteration Time: 4.81862

Cumulative Model Updates: 55,094
Cumulative Timesteps: 459,594,506

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 459594506...
Checkpoint 459594506 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,451.03899
Policy Entropy: 3.38238
Value Function Loss: 0.00313

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.10359
Policy Update Magnitude: 0.55861
Value Function Update Magnitude: 0.58775

Collected Steps per Second: 21,535.67248
Overall Steps per Second: 10,300.92853

Timestep Collection Time: 2.32359
Timestep Consumption Time: 2.53423
PPO Batch Consumption Time: 0.29615
Total Iteration Time: 4.85781

Cumulative Model Updates: 55,100
Cumulative Timesteps: 459,644,546

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 929.64345
Policy Entropy: 3.39252
Value Function Loss: 0.00326

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.09358
Policy Update Magnitude: 0.55943
Value Function Update Magnitude: 0.58834

Collected Steps per Second: 21,269.92258
Overall Steps per Second: 10,362.51027

Timestep Collection Time: 2.35111
Timestep Consumption Time: 2.47474
PPO Batch Consumption Time: 0.28786
Total Iteration Time: 4.82586

Cumulative Model Updates: 55,106
Cumulative Timesteps: 459,694,554

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 459694554...
Checkpoint 459694554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 936.11890
Policy Entropy: 3.40508
Value Function Loss: 0.00312

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.09070
Policy Update Magnitude: 0.55755
Value Function Update Magnitude: 0.56822

Collected Steps per Second: 22,388.86355
Overall Steps per Second: 10,345.94071

Timestep Collection Time: 2.23459
Timestep Consumption Time: 2.60112
PPO Batch Consumption Time: 0.30909
Total Iteration Time: 4.83571

Cumulative Model Updates: 55,112
Cumulative Timesteps: 459,744,584

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,819.40339
Policy Entropy: 3.40626
Value Function Loss: 0.00313

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.09231
Policy Update Magnitude: 0.55259
Value Function Update Magnitude: 0.56279

Collected Steps per Second: 21,486.79700
Overall Steps per Second: 10,206.19805

Timestep Collection Time: 2.32794
Timestep Consumption Time: 2.57300
PPO Batch Consumption Time: 0.30547
Total Iteration Time: 4.90094

Cumulative Model Updates: 55,118
Cumulative Timesteps: 459,794,604

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 459794604...
Checkpoint 459794604 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,224.21456
Policy Entropy: 3.40446
Value Function Loss: 0.00313

Mean KL Divergence: 0.00675
SB3 Clip Fraction: 0.07715
Policy Update Magnitude: 0.55236
Value Function Update Magnitude: 0.54938

Collected Steps per Second: 19,174.04526
Overall Steps per Second: 9,765.49170

Timestep Collection Time: 2.60811
Timestep Consumption Time: 2.51278
PPO Batch Consumption Time: 0.28055
Total Iteration Time: 5.12089

Cumulative Model Updates: 55,124
Cumulative Timesteps: 459,844,612

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,485.87942
Policy Entropy: 3.39332
Value Function Loss: 0.00322

Mean KL Divergence: 0.00652
SB3 Clip Fraction: 0.07552
Policy Update Magnitude: 0.56261
Value Function Update Magnitude: 0.54809

Collected Steps per Second: 23,106.85716
Overall Steps per Second: 10,670.81487

Timestep Collection Time: 2.16524
Timestep Consumption Time: 2.52343
PPO Batch Consumption Time: 0.29947
Total Iteration Time: 4.68868

Cumulative Model Updates: 55,130
Cumulative Timesteps: 459,894,644

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 459894644...
Checkpoint 459894644 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,324.58450
Policy Entropy: 3.39108
Value Function Loss: 0.00321

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.09083
Policy Update Magnitude: 0.56193
Value Function Update Magnitude: 0.54399

Collected Steps per Second: 19,950.90787
Overall Steps per Second: 10,012.29533

Timestep Collection Time: 2.50655
Timestep Consumption Time: 2.48811
PPO Batch Consumption Time: 0.29344
Total Iteration Time: 4.99466

Cumulative Model Updates: 55,136
Cumulative Timesteps: 459,944,652

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 902.08883
Policy Entropy: 3.39961
Value Function Loss: 0.00332

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.09456
Policy Update Magnitude: 0.55883
Value Function Update Magnitude: 0.54987

Collected Steps per Second: 23,046.31737
Overall Steps per Second: 10,844.76806

Timestep Collection Time: 2.17059
Timestep Consumption Time: 2.44215
PPO Batch Consumption Time: 0.28425
Total Iteration Time: 4.61273

Cumulative Model Updates: 55,142
Cumulative Timesteps: 459,994,676

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 459994676...
Checkpoint 459994676 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,073.03963
Policy Entropy: 3.40913
Value Function Loss: 0.00304

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.09703
Policy Update Magnitude: 0.55316
Value Function Update Magnitude: 0.56758

Collected Steps per Second: 22,564.29783
Overall Steps per Second: 10,652.60496

Timestep Collection Time: 2.21660
Timestep Consumption Time: 2.47859
PPO Batch Consumption Time: 0.29098
Total Iteration Time: 4.69519

Cumulative Model Updates: 55,148
Cumulative Timesteps: 460,044,692

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,195.64343
Policy Entropy: 3.40418
Value Function Loss: 0.00301

Mean KL Divergence: 0.00703
SB3 Clip Fraction: 0.07995
Policy Update Magnitude: 0.54658
Value Function Update Magnitude: 0.55854

Collected Steps per Second: 23,081.66428
Overall Steps per Second: 10,842.39467

Timestep Collection Time: 2.16709
Timestep Consumption Time: 2.44628
PPO Batch Consumption Time: 0.28111
Total Iteration Time: 4.61337

Cumulative Model Updates: 55,154
Cumulative Timesteps: 460,094,712

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 460094712...
Checkpoint 460094712 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,119.83153
Policy Entropy: 3.41395
Value Function Loss: 0.00308

Mean KL Divergence: 0.00610
SB3 Clip Fraction: 0.06837
Policy Update Magnitude: 0.54801
Value Function Update Magnitude: 0.53595

Collected Steps per Second: 21,868.10199
Overall Steps per Second: 10,822.04144

Timestep Collection Time: 2.28662
Timestep Consumption Time: 2.33395
PPO Batch Consumption Time: 0.27941
Total Iteration Time: 4.62057

Cumulative Model Updates: 55,160
Cumulative Timesteps: 460,144,716

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,472.73765
Policy Entropy: 3.40549
Value Function Loss: 0.00310

Mean KL Divergence: 0.00661
SB3 Clip Fraction: 0.07644
Policy Update Magnitude: 0.55274
Value Function Update Magnitude: 0.53547

Collected Steps per Second: 22,848.08313
Overall Steps per Second: 10,773.19225

Timestep Collection Time: 2.18916
Timestep Consumption Time: 2.45367
PPO Batch Consumption Time: 0.28724
Total Iteration Time: 4.64282

Cumulative Model Updates: 55,166
Cumulative Timesteps: 460,194,734

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 460194734...
Checkpoint 460194734 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,315.72820
Policy Entropy: 3.41154
Value Function Loss: 0.00306

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.11005
Policy Update Magnitude: 0.54881
Value Function Update Magnitude: 0.54214

Collected Steps per Second: 22,461.25194
Overall Steps per Second: 10,660.86994

Timestep Collection Time: 2.22712
Timestep Consumption Time: 2.46518
PPO Batch Consumption Time: 0.28522
Total Iteration Time: 4.69230

Cumulative Model Updates: 55,172
Cumulative Timesteps: 460,244,758

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,440.11091
Policy Entropy: 3.41907
Value Function Loss: 0.00290

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.09272
Policy Update Magnitude: 0.53834
Value Function Update Magnitude: 0.53426

Collected Steps per Second: 21,870.41040
Overall Steps per Second: 10,457.39791

Timestep Collection Time: 2.28629
Timestep Consumption Time: 2.49521
PPO Batch Consumption Time: 0.28797
Total Iteration Time: 4.78150

Cumulative Model Updates: 55,178
Cumulative Timesteps: 460,294,760

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 460294760...
Checkpoint 460294760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,440.73586
Policy Entropy: 3.42532
Value Function Loss: 0.00292

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.09062
Policy Update Magnitude: 0.53552
Value Function Update Magnitude: 0.53551

Collected Steps per Second: 21,438.75097
Overall Steps per Second: 10,311.43515

Timestep Collection Time: 2.33325
Timestep Consumption Time: 2.51787
PPO Batch Consumption Time: 0.29197
Total Iteration Time: 4.85112

Cumulative Model Updates: 55,184
Cumulative Timesteps: 460,344,782

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,564.24478
Policy Entropy: 3.42562
Value Function Loss: 0.00303

Mean KL Divergence: 0.00661
SB3 Clip Fraction: 0.07504
Policy Update Magnitude: 0.54251
Value Function Update Magnitude: 0.54751

Collected Steps per Second: 22,826.67755
Overall Steps per Second: 10,793.19564

Timestep Collection Time: 2.19086
Timestep Consumption Time: 2.44262
PPO Batch Consumption Time: 0.28029
Total Iteration Time: 4.63347

Cumulative Model Updates: 55,190
Cumulative Timesteps: 460,394,792

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 460394792...
Checkpoint 460394792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,973.72919
Policy Entropy: 3.42610
Value Function Loss: 0.00296

Mean KL Divergence: 0.00636
SB3 Clip Fraction: 0.07249
Policy Update Magnitude: 0.55153
Value Function Update Magnitude: 0.54518

Collected Steps per Second: 22,556.33875
Overall Steps per Second: 10,766.92604

Timestep Collection Time: 2.21720
Timestep Consumption Time: 2.42776
PPO Batch Consumption Time: 0.27891
Total Iteration Time: 4.64497

Cumulative Model Updates: 55,196
Cumulative Timesteps: 460,444,804

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,878.59158
Policy Entropy: 3.41484
Value Function Loss: 0.00291

Mean KL Divergence: 0.00701
SB3 Clip Fraction: 0.08008
Policy Update Magnitude: 0.53994
Value Function Update Magnitude: 0.53922

Collected Steps per Second: 22,877.84835
Overall Steps per Second: 10,758.71597

Timestep Collection Time: 2.18631
Timestep Consumption Time: 2.46276
PPO Batch Consumption Time: 0.28168
Total Iteration Time: 4.64907

Cumulative Model Updates: 55,202
Cumulative Timesteps: 460,494,822

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 460494822...
Checkpoint 460494822 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,161.43403
Policy Entropy: 3.40576
Value Function Loss: 0.00300

Mean KL Divergence: 0.00724
SB3 Clip Fraction: 0.08229
Policy Update Magnitude: 0.53367
Value Function Update Magnitude: 0.52613

Collected Steps per Second: 22,156.88687
Overall Steps per Second: 10,632.91887

Timestep Collection Time: 2.25745
Timestep Consumption Time: 2.44662
PPO Batch Consumption Time: 0.28117
Total Iteration Time: 4.70407

Cumulative Model Updates: 55,208
Cumulative Timesteps: 460,544,840

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,174.99131
Policy Entropy: 3.39778
Value Function Loss: 0.00320

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.09270
Policy Update Magnitude: 0.53891
Value Function Update Magnitude: 0.53461

Collected Steps per Second: 22,813.75238
Overall Steps per Second: 10,757.97896

Timestep Collection Time: 2.19245
Timestep Consumption Time: 2.45694
PPO Batch Consumption Time: 0.28899
Total Iteration Time: 4.64939

Cumulative Model Updates: 55,214
Cumulative Timesteps: 460,594,858

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 460594858...
Checkpoint 460594858 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,199.63884
Policy Entropy: 3.38446
Value Function Loss: 0.00325

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.10508
Policy Update Magnitude: 0.54779
Value Function Update Magnitude: 0.54678

Collected Steps per Second: 22,982.07948
Overall Steps per Second: 10,806.03158

Timestep Collection Time: 2.17570
Timestep Consumption Time: 2.45154
PPO Batch Consumption Time: 0.28122
Total Iteration Time: 4.62723

Cumulative Model Updates: 55,220
Cumulative Timesteps: 460,644,860

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,510.85096
Policy Entropy: 3.38346
Value Function Loss: 0.00317

Mean KL Divergence: 0.00732
SB3 Clip Fraction: 0.08415
Policy Update Magnitude: 0.54240
Value Function Update Magnitude: 0.53591

Collected Steps per Second: 22,698.99755
Overall Steps per Second: 10,582.39869

Timestep Collection Time: 2.20415
Timestep Consumption Time: 2.52370
PPO Batch Consumption Time: 0.29530
Total Iteration Time: 4.72785

Cumulative Model Updates: 55,226
Cumulative Timesteps: 460,694,892

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 460694892...
Checkpoint 460694892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,269.86075
Policy Entropy: 3.38567
Value Function Loss: 0.00317

Mean KL Divergence: 0.00724
SB3 Clip Fraction: 0.08162
Policy Update Magnitude: 0.55102
Value Function Update Magnitude: 0.54122

Collected Steps per Second: 22,330.03787
Overall Steps per Second: 10,341.96051

Timestep Collection Time: 2.23958
Timestep Consumption Time: 2.59606
PPO Batch Consumption Time: 0.30679
Total Iteration Time: 4.83564

Cumulative Model Updates: 55,232
Cumulative Timesteps: 460,744,902

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,474.56876
Policy Entropy: 3.39071
Value Function Loss: 0.00319

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.10180
Policy Update Magnitude: 0.54987
Value Function Update Magnitude: 0.57539

Collected Steps per Second: 22,755.95089
Overall Steps per Second: 10,738.58880

Timestep Collection Time: 2.19846
Timestep Consumption Time: 2.46025
PPO Batch Consumption Time: 0.28010
Total Iteration Time: 4.65871

Cumulative Model Updates: 55,238
Cumulative Timesteps: 460,794,930

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 460794930...
Checkpoint 460794930 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,077.94333
Policy Entropy: 3.38657
Value Function Loss: 0.00329

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.10356
Policy Update Magnitude: 0.55634
Value Function Update Magnitude: 0.57547

Collected Steps per Second: 22,564.95884
Overall Steps per Second: 10,577.80694

Timestep Collection Time: 2.21662
Timestep Consumption Time: 2.51196
PPO Batch Consumption Time: 0.29206
Total Iteration Time: 4.72858

Cumulative Model Updates: 55,244
Cumulative Timesteps: 460,844,948

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,557.92566
Policy Entropy: 3.37719
Value Function Loss: 0.00318

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.10382
Policy Update Magnitude: 0.55767
Value Function Update Magnitude: 0.56014

Collected Steps per Second: 22,764.44326
Overall Steps per Second: 10,831.20714

Timestep Collection Time: 2.19755
Timestep Consumption Time: 2.42114
PPO Batch Consumption Time: 0.28105
Total Iteration Time: 4.61869

Cumulative Model Updates: 55,250
Cumulative Timesteps: 460,894,974

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 460894974...
Checkpoint 460894974 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,170.42819
Policy Entropy: 3.38256
Value Function Loss: 0.00312

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.08385
Policy Update Magnitude: 0.55520
Value Function Update Magnitude: 0.53930

Collected Steps per Second: 22,319.68506
Overall Steps per Second: 10,662.90195

Timestep Collection Time: 2.24044
Timestep Consumption Time: 2.44927
PPO Batch Consumption Time: 0.28129
Total Iteration Time: 4.68972

Cumulative Model Updates: 55,256
Cumulative Timesteps: 460,944,980

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,053.34212
Policy Entropy: 3.38980
Value Function Loss: 0.00292

Mean KL Divergence: 0.00634
SB3 Clip Fraction: 0.07161
Policy Update Magnitude: 0.55634
Value Function Update Magnitude: 0.52957

Collected Steps per Second: 22,911.89975
Overall Steps per Second: 10,653.81289

Timestep Collection Time: 2.18245
Timestep Consumption Time: 2.51108
PPO Batch Consumption Time: 0.29336
Total Iteration Time: 4.69353

Cumulative Model Updates: 55,262
Cumulative Timesteps: 460,994,984

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 460994984...
Checkpoint 460994984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 791.91977
Policy Entropy: 3.39588
Value Function Loss: 0.00318

Mean KL Divergence: 0.00632
SB3 Clip Fraction: 0.07168
Policy Update Magnitude: 0.56102
Value Function Update Magnitude: 0.52758

Collected Steps per Second: 22,646.54244
Overall Steps per Second: 10,643.72107

Timestep Collection Time: 2.20881
Timestep Consumption Time: 2.49086
PPO Batch Consumption Time: 0.29204
Total Iteration Time: 4.69967

Cumulative Model Updates: 55,268
Cumulative Timesteps: 461,045,006

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,663.22575
Policy Entropy: 3.40154
Value Function Loss: 0.00327

Mean KL Divergence: 0.00746
SB3 Clip Fraction: 0.08622
Policy Update Magnitude: 0.56321
Value Function Update Magnitude: 0.56643

Collected Steps per Second: 22,923.76311
Overall Steps per Second: 10,810.95175

Timestep Collection Time: 2.18140
Timestep Consumption Time: 2.44409
PPO Batch Consumption Time: 0.28009
Total Iteration Time: 4.62549

Cumulative Model Updates: 55,274
Cumulative Timesteps: 461,095,012

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 461095012...
Checkpoint 461095012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,513.47978
Policy Entropy: 3.38736
Value Function Loss: 0.00338

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.09469
Policy Update Magnitude: 0.56554
Value Function Update Magnitude: 0.58059

Collected Steps per Second: 22,530.34740
Overall Steps per Second: 10,600.52913

Timestep Collection Time: 2.21976
Timestep Consumption Time: 2.49812
PPO Batch Consumption Time: 0.29666
Total Iteration Time: 4.71788

Cumulative Model Updates: 55,280
Cumulative Timesteps: 461,145,024

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,163.78564
Policy Entropy: 3.40398
Value Function Loss: 0.00313

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.08965
Policy Update Magnitude: 0.56428
Value Function Update Magnitude: 0.56550

Collected Steps per Second: 23,055.73352
Overall Steps per Second: 10,943.09238

Timestep Collection Time: 2.17005
Timestep Consumption Time: 2.40197
PPO Batch Consumption Time: 0.27902
Total Iteration Time: 4.57202

Cumulative Model Updates: 55,286
Cumulative Timesteps: 461,195,056

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 461195056...
Checkpoint 461195056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,158.69660
Policy Entropy: 3.41096
Value Function Loss: 0.00303

Mean KL Divergence: 0.00758
SB3 Clip Fraction: 0.08488
Policy Update Magnitude: 0.54947
Value Function Update Magnitude: 0.54529

Collected Steps per Second: 22,808.83636
Overall Steps per Second: 10,701.65952

Timestep Collection Time: 2.19257
Timestep Consumption Time: 2.48054
PPO Batch Consumption Time: 0.29543
Total Iteration Time: 4.67311

Cumulative Model Updates: 55,292
Cumulative Timesteps: 461,245,066

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,600.26255
Policy Entropy: 3.41776
Value Function Loss: 0.00309

Mean KL Divergence: 0.00653
SB3 Clip Fraction: 0.07329
Policy Update Magnitude: 0.55483
Value Function Update Magnitude: 0.53614

Collected Steps per Second: 22,847.96790
Overall Steps per Second: 10,780.88440

Timestep Collection Time: 2.18882
Timestep Consumption Time: 2.44995
PPO Batch Consumption Time: 0.28207
Total Iteration Time: 4.63877

Cumulative Model Updates: 55,298
Cumulative Timesteps: 461,295,076

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 461295076...
Checkpoint 461295076 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,351.81846
Policy Entropy: 3.40667
Value Function Loss: 0.00290

Mean KL Divergence: 0.00698
SB3 Clip Fraction: 0.07814
Policy Update Magnitude: 0.55093
Value Function Update Magnitude: 0.53285

Collected Steps per Second: 22,459.90832
Overall Steps per Second: 10,733.64495

Timestep Collection Time: 2.22663
Timestep Consumption Time: 2.43255
PPO Batch Consumption Time: 0.27953
Total Iteration Time: 4.65918

Cumulative Model Updates: 55,304
Cumulative Timesteps: 461,345,086

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,293.43921
Policy Entropy: 3.39309
Value Function Loss: 0.00296

Mean KL Divergence: 0.00697
SB3 Clip Fraction: 0.08019
Policy Update Magnitude: 0.54162
Value Function Update Magnitude: 0.52382

Collected Steps per Second: 22,881.88008
Overall Steps per Second: 10,825.05714

Timestep Collection Time: 2.18627
Timestep Consumption Time: 2.43504
PPO Batch Consumption Time: 0.28026
Total Iteration Time: 4.62132

Cumulative Model Updates: 55,310
Cumulative Timesteps: 461,395,112

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 461395112...
Checkpoint 461395112 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 892.12195
Policy Entropy: 3.38779
Value Function Loss: 0.00294

Mean KL Divergence: 0.00627
SB3 Clip Fraction: 0.07267
Policy Update Magnitude: 0.54373
Value Function Update Magnitude: 0.51539

Collected Steps per Second: 21,995.23130
Overall Steps per Second: 10,468.59711

Timestep Collection Time: 2.27349
Timestep Consumption Time: 2.50327
PPO Batch Consumption Time: 0.29342
Total Iteration Time: 4.77676

Cumulative Model Updates: 55,316
Cumulative Timesteps: 461,445,118

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,593.78282
Policy Entropy: 3.38158
Value Function Loss: 0.00304

Mean KL Divergence: 0.00685
SB3 Clip Fraction: 0.07959
Policy Update Magnitude: 0.54997
Value Function Update Magnitude: 0.53037

Collected Steps per Second: 22,958.56167
Overall Steps per Second: 10,660.69133

Timestep Collection Time: 2.17862
Timestep Consumption Time: 2.51319
PPO Batch Consumption Time: 0.29192
Total Iteration Time: 4.69182

Cumulative Model Updates: 55,322
Cumulative Timesteps: 461,495,136

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 461495136...
Checkpoint 461495136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 982.98164
Policy Entropy: 3.38497
Value Function Loss: 0.00318

Mean KL Divergence: 0.00674
SB3 Clip Fraction: 0.07728
Policy Update Magnitude: 0.56040
Value Function Update Magnitude: 0.55219

Collected Steps per Second: 22,342.11483
Overall Steps per Second: 10,624.11142

Timestep Collection Time: 2.23837
Timestep Consumption Time: 2.46884
PPO Batch Consumption Time: 0.28540
Total Iteration Time: 4.70722

Cumulative Model Updates: 55,328
Cumulative Timesteps: 461,545,146

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,459.41497
Policy Entropy: 3.38547
Value Function Loss: 0.00321

Mean KL Divergence: 0.00717
SB3 Clip Fraction: 0.08145
Policy Update Magnitude: 0.56591
Value Function Update Magnitude: 0.56688

Collected Steps per Second: 22,751.71828
Overall Steps per Second: 10,657.70038

Timestep Collection Time: 2.19904
Timestep Consumption Time: 2.49540
PPO Batch Consumption Time: 0.29197
Total Iteration Time: 4.69445

Cumulative Model Updates: 55,334
Cumulative Timesteps: 461,595,178

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 461595178...
Checkpoint 461595178 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,469.39652
Policy Entropy: 3.39347
Value Function Loss: 0.00325

Mean KL Divergence: 0.00691
SB3 Clip Fraction: 0.07715
Policy Update Magnitude: 0.57248
Value Function Update Magnitude: 0.56144

Collected Steps per Second: 22,722.56850
Overall Steps per Second: 10,656.52080

Timestep Collection Time: 2.20160
Timestep Consumption Time: 2.49280
PPO Batch Consumption Time: 0.29186
Total Iteration Time: 4.69440

Cumulative Model Updates: 55,340
Cumulative Timesteps: 461,645,204

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 872.76671
Policy Entropy: 3.39258
Value Function Loss: 0.00327

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.08544
Policy Update Magnitude: 0.56377
Value Function Update Magnitude: 0.54527

Collected Steps per Second: 23,079.33511
Overall Steps per Second: 10,735.30783

Timestep Collection Time: 2.16670
Timestep Consumption Time: 2.49139
PPO Batch Consumption Time: 0.29488
Total Iteration Time: 4.65809

Cumulative Model Updates: 55,346
Cumulative Timesteps: 461,695,210

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 461695210...
Checkpoint 461695210 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,461.45124
Policy Entropy: 3.39889
Value Function Loss: 0.00328

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.09209
Policy Update Magnitude: 0.56403
Value Function Update Magnitude: 0.55869

Collected Steps per Second: 22,408.21569
Overall Steps per Second: 10,604.59663

Timestep Collection Time: 2.23222
Timestep Consumption Time: 2.48461
PPO Batch Consumption Time: 0.28869
Total Iteration Time: 4.71682

Cumulative Model Updates: 55,352
Cumulative Timesteps: 461,745,230

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 887.04257
Policy Entropy: 3.38374
Value Function Loss: 0.00320

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.08846
Policy Update Magnitude: 0.57422
Value Function Update Magnitude: 0.56836

Collected Steps per Second: 22,532.69431
Overall Steps per Second: 10,594.23438

Timestep Collection Time: 2.21909
Timestep Consumption Time: 2.50065
PPO Batch Consumption Time: 0.29388
Total Iteration Time: 4.71974

Cumulative Model Updates: 55,358
Cumulative Timesteps: 461,795,232

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 461795232...
Checkpoint 461795232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,541.03131
Policy Entropy: 3.38753
Value Function Loss: 0.00320

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.08562
Policy Update Magnitude: 0.57400
Value Function Update Magnitude: 0.57343

Collected Steps per Second: 22,294.60126
Overall Steps per Second: 10,520.79049

Timestep Collection Time: 2.24368
Timestep Consumption Time: 2.51090
PPO Batch Consumption Time: 0.29122
Total Iteration Time: 4.75459

Cumulative Model Updates: 55,364
Cumulative Timesteps: 461,845,254

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 749.65422
Policy Entropy: 3.38589
Value Function Loss: 0.00323

Mean KL Divergence: 0.00662
SB3 Clip Fraction: 0.07697
Policy Update Magnitude: 0.56887
Value Function Update Magnitude: 0.56863

Collected Steps per Second: 22,951.73440
Overall Steps per Second: 10,854.75215

Timestep Collection Time: 2.17892
Timestep Consumption Time: 2.42828
PPO Batch Consumption Time: 0.28176
Total Iteration Time: 4.60720

Cumulative Model Updates: 55,370
Cumulative Timesteps: 461,895,264

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 461895264...
Checkpoint 461895264 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,514.35409
Policy Entropy: 3.39468
Value Function Loss: 0.00329

Mean KL Divergence: 0.00764
SB3 Clip Fraction: 0.08754
Policy Update Magnitude: 0.57207
Value Function Update Magnitude: 0.57240

Collected Steps per Second: 22,124.13262
Overall Steps per Second: 10,688.68312

Timestep Collection Time: 2.26043
Timestep Consumption Time: 2.41835
PPO Batch Consumption Time: 0.28015
Total Iteration Time: 4.67878

Cumulative Model Updates: 55,376
Cumulative Timesteps: 461,945,274

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,392.78273
Policy Entropy: 3.40049
Value Function Loss: 0.00321

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.09183
Policy Update Magnitude: 0.57014
Value Function Update Magnitude: 0.58276

Collected Steps per Second: 23,098.07770
Overall Steps per Second: 10,848.10533

Timestep Collection Time: 2.16537
Timestep Consumption Time: 2.44520
PPO Batch Consumption Time: 0.28101
Total Iteration Time: 4.61057

Cumulative Model Updates: 55,382
Cumulative Timesteps: 461,995,290

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 461995290...
Checkpoint 461995290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,769.59834
Policy Entropy: 3.41244
Value Function Loss: 0.00310

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.09269
Policy Update Magnitude: 0.55748
Value Function Update Magnitude: 0.56907

Collected Steps per Second: 22,620.80380
Overall Steps per Second: 10,689.40528

Timestep Collection Time: 2.21035
Timestep Consumption Time: 2.46717
PPO Batch Consumption Time: 0.28527
Total Iteration Time: 4.67753

Cumulative Model Updates: 55,388
Cumulative Timesteps: 462,045,290

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 825.98400
Policy Entropy: 3.40503
Value Function Loss: 0.00322

Mean KL Divergence: 0.00696
SB3 Clip Fraction: 0.07805
Policy Update Magnitude: 0.55106
Value Function Update Magnitude: 0.56033

Collected Steps per Second: 22,628.08180
Overall Steps per Second: 10,846.05071

Timestep Collection Time: 2.21070
Timestep Consumption Time: 2.40148
PPO Batch Consumption Time: 0.28084
Total Iteration Time: 4.61219

Cumulative Model Updates: 55,394
Cumulative Timesteps: 462,095,314

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 462095314...
Checkpoint 462095314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,764.02752
Policy Entropy: 3.38754
Value Function Loss: 0.00323

Mean KL Divergence: 0.00688
SB3 Clip Fraction: 0.07800
Policy Update Magnitude: 0.56223
Value Function Update Magnitude: 0.56396

Collected Steps per Second: 22,211.48903
Overall Steps per Second: 10,716.53879

Timestep Collection Time: 2.25262
Timestep Consumption Time: 2.41624
PPO Batch Consumption Time: 0.28094
Total Iteration Time: 4.66886

Cumulative Model Updates: 55,400
Cumulative Timesteps: 462,145,348

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,486.35415
Policy Entropy: 3.38276
Value Function Loss: 0.00317

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.09719
Policy Update Magnitude: 0.57122
Value Function Update Magnitude: 0.57216

Collected Steps per Second: 23,017.79027
Overall Steps per Second: 10,929.78225

Timestep Collection Time: 2.17258
Timestep Consumption Time: 2.40281
PPO Batch Consumption Time: 0.27996
Total Iteration Time: 4.57539

Cumulative Model Updates: 55,406
Cumulative Timesteps: 462,195,356

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 462195356...
Checkpoint 462195356 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,160.41938
Policy Entropy: 3.38796
Value Function Loss: 0.00317

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.09636
Policy Update Magnitude: 0.56302
Value Function Update Magnitude: 0.56687

Collected Steps per Second: 22,740.46061
Overall Steps per Second: 10,743.00769

Timestep Collection Time: 2.19899
Timestep Consumption Time: 2.45576
PPO Batch Consumption Time: 0.28702
Total Iteration Time: 4.65475

Cumulative Model Updates: 55,412
Cumulative Timesteps: 462,245,362

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,754.47386
Policy Entropy: 3.39360
Value Function Loss: 0.00311

Mean KL Divergence: 0.00725
SB3 Clip Fraction: 0.08189
Policy Update Magnitude: 0.56245
Value Function Update Magnitude: 0.56800

Collected Steps per Second: 22,952.72383
Overall Steps per Second: 10,807.32679

Timestep Collection Time: 2.17987
Timestep Consumption Time: 2.44976
PPO Batch Consumption Time: 0.28101
Total Iteration Time: 4.62964

Cumulative Model Updates: 55,418
Cumulative Timesteps: 462,295,396

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 462295396...
Checkpoint 462295396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,493.54812
Policy Entropy: 3.39896
Value Function Loss: 0.00315

Mean KL Divergence: 0.00619
SB3 Clip Fraction: 0.07105
Policy Update Magnitude: 0.56703
Value Function Update Magnitude: 0.55414

Collected Steps per Second: 22,441.63137
Overall Steps per Second: 10,697.78230

Timestep Collection Time: 2.22880
Timestep Consumption Time: 2.44674
PPO Batch Consumption Time: 0.28117
Total Iteration Time: 4.67555

Cumulative Model Updates: 55,424
Cumulative Timesteps: 462,345,414

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,120.53011
Policy Entropy: 3.40705
Value Function Loss: 0.00307

Mean KL Divergence: 0.00671
SB3 Clip Fraction: 0.07629
Policy Update Magnitude: 0.56208
Value Function Update Magnitude: 0.55848

Collected Steps per Second: 22,915.81997
Overall Steps per Second: 10,890.20027

Timestep Collection Time: 2.18225
Timestep Consumption Time: 2.40977
PPO Batch Consumption Time: 0.28090
Total Iteration Time: 4.59202

Cumulative Model Updates: 55,430
Cumulative Timesteps: 462,395,422

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 462395422...
Checkpoint 462395422 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,630.72308
Policy Entropy: 3.40626
Value Function Loss: 0.00297

Mean KL Divergence: 0.00748
SB3 Clip Fraction: 0.08449
Policy Update Magnitude: 0.55802
Value Function Update Magnitude: 0.57287

Collected Steps per Second: 22,612.74376
Overall Steps per Second: 10,691.74422

Timestep Collection Time: 2.21123
Timestep Consumption Time: 2.46546
PPO Batch Consumption Time: 0.28597
Total Iteration Time: 4.67669

Cumulative Model Updates: 55,436
Cumulative Timesteps: 462,445,424

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,221.06304
Policy Entropy: 3.41593
Value Function Loss: 0.00290

Mean KL Divergence: 0.00697
SB3 Clip Fraction: 0.07751
Policy Update Magnitude: 0.54965
Value Function Update Magnitude: 0.56510

Collected Steps per Second: 22,839.74880
Overall Steps per Second: 10,680.20820

Timestep Collection Time: 2.19004
Timestep Consumption Time: 2.49339
PPO Batch Consumption Time: 0.28929
Total Iteration Time: 4.68343

Cumulative Model Updates: 55,442
Cumulative Timesteps: 462,495,444

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 462495444...
Checkpoint 462495444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 949.98103
Policy Entropy: 3.40339
Value Function Loss: 0.00294

Mean KL Divergence: 0.00698
SB3 Clip Fraction: 0.07938
Policy Update Magnitude: 0.54832
Value Function Update Magnitude: 0.57925

Collected Steps per Second: 22,902.10906
Overall Steps per Second: 10,909.16112

Timestep Collection Time: 2.18338
Timestep Consumption Time: 2.40029
PPO Batch Consumption Time: 0.27935
Total Iteration Time: 4.58367

Cumulative Model Updates: 55,448
Cumulative Timesteps: 462,545,448

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,363.60042
Policy Entropy: 3.41119
Value Function Loss: 0.00313

Mean KL Divergence: 0.00655
SB3 Clip Fraction: 0.07393
Policy Update Magnitude: 0.55740
Value Function Update Magnitude: 0.57808

Collected Steps per Second: 22,923.33408
Overall Steps per Second: 10,862.32759

Timestep Collection Time: 2.18232
Timestep Consumption Time: 2.42314
PPO Batch Consumption Time: 0.28071
Total Iteration Time: 4.60546

Cumulative Model Updates: 55,454
Cumulative Timesteps: 462,595,474

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 462595474...
Checkpoint 462595474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,084.12722
Policy Entropy: 3.41278
Value Function Loss: 0.00315

Mean KL Divergence: 0.00657
SB3 Clip Fraction: 0.07452
Policy Update Magnitude: 0.57180
Value Function Update Magnitude: 0.58010

Collected Steps per Second: 22,512.32507
Overall Steps per Second: 10,481.58965

Timestep Collection Time: 2.22189
Timestep Consumption Time: 2.55028
PPO Batch Consumption Time: 0.28855
Total Iteration Time: 4.77218

Cumulative Model Updates: 55,460
Cumulative Timesteps: 462,645,494

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,263.84683
Policy Entropy: 3.40187
Value Function Loss: 0.00337

Mean KL Divergence: 0.00722
SB3 Clip Fraction: 0.08165
Policy Update Magnitude: 0.58251
Value Function Update Magnitude: 0.59484

Collected Steps per Second: 20,581.24061
Overall Steps per Second: 9,899.81936

Timestep Collection Time: 2.42979
Timestep Consumption Time: 2.62162
PPO Batch Consumption Time: 0.30841
Total Iteration Time: 5.05141

Cumulative Model Updates: 55,466
Cumulative Timesteps: 462,695,502

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 462695502...
Checkpoint 462695502 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,504.69299
Policy Entropy: 3.40153
Value Function Loss: 0.00336

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.09450
Policy Update Magnitude: 0.59224
Value Function Update Magnitude: 0.58379

Collected Steps per Second: 20,896.67043
Overall Steps per Second: 10,024.50655

Timestep Collection Time: 2.39292
Timestep Consumption Time: 2.59526
PPO Batch Consumption Time: 0.30656
Total Iteration Time: 4.98818

Cumulative Model Updates: 55,472
Cumulative Timesteps: 462,745,506

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 908.04583
Policy Entropy: 3.40915
Value Function Loss: 0.00323

Mean KL Divergence: 0.01059
SB3 Clip Fraction: 0.10985
Policy Update Magnitude: 0.58757
Value Function Update Magnitude: 0.56337

Collected Steps per Second: 22,648.16068
Overall Steps per Second: 10,286.98441

Timestep Collection Time: 2.20892
Timestep Consumption Time: 2.65431
PPO Batch Consumption Time: 0.32002
Total Iteration Time: 4.86323

Cumulative Model Updates: 55,478
Cumulative Timesteps: 462,795,534

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 462795534...
Checkpoint 462795534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,622.61956
Policy Entropy: 3.41115
Value Function Loss: 0.00307

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.09878
Policy Update Magnitude: 0.56891
Value Function Update Magnitude: 0.54275

Collected Steps per Second: 21,033.71753
Overall Steps per Second: 10,026.72691

Timestep Collection Time: 2.37818
Timestep Consumption Time: 2.61068
PPO Batch Consumption Time: 0.31000
Total Iteration Time: 4.98887

Cumulative Model Updates: 55,484
Cumulative Timesteps: 462,845,556

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,343.32440
Policy Entropy: 3.41829
Value Function Loss: 0.00295

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.11726
Policy Update Magnitude: 0.55521
Value Function Update Magnitude: 0.53915

Collected Steps per Second: 20,507.18518
Overall Steps per Second: 9,776.35651

Timestep Collection Time: 2.43846
Timestep Consumption Time: 2.67653
PPO Batch Consumption Time: 0.32227
Total Iteration Time: 5.11499

Cumulative Model Updates: 55,490
Cumulative Timesteps: 462,895,562

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 462895562...
Checkpoint 462895562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 608.98979
Policy Entropy: 3.40994
Value Function Loss: 0.00299

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.11477
Policy Update Magnitude: 0.54658
Value Function Update Magnitude: 0.54498

Collected Steps per Second: 20,607.02832
Overall Steps per Second: 9,895.49481

Timestep Collection Time: 2.42772
Timestep Consumption Time: 2.62792
PPO Batch Consumption Time: 0.31324
Total Iteration Time: 5.05563

Cumulative Model Updates: 55,496
Cumulative Timesteps: 462,945,590

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,318.97085
Policy Entropy: 3.40306
Value Function Loss: 0.00306

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.09442
Policy Update Magnitude: 0.55128
Value Function Update Magnitude: 0.55855

Collected Steps per Second: 21,183.37978
Overall Steps per Second: 10,065.93927

Timestep Collection Time: 2.36166
Timestep Consumption Time: 2.60837
PPO Batch Consumption Time: 0.30248
Total Iteration Time: 4.97003

Cumulative Model Updates: 55,502
Cumulative Timesteps: 462,995,618

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 462995618...
Checkpoint 462995618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,491.93012
Policy Entropy: 3.40088
Value Function Loss: 0.00292

Mean KL Divergence: 0.00707
SB3 Clip Fraction: 0.08212
Policy Update Magnitude: 0.54267
Value Function Update Magnitude: 0.54801

Collected Steps per Second: 21,546.80158
Overall Steps per Second: 10,393.81476

Timestep Collection Time: 2.32174
Timestep Consumption Time: 2.49132
PPO Batch Consumption Time: 0.28370
Total Iteration Time: 4.81305

Cumulative Model Updates: 55,508
Cumulative Timesteps: 463,045,644

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,012.74830
Policy Entropy: 3.41189
Value Function Loss: 0.00296

Mean KL Divergence: 0.00589
SB3 Clip Fraction: 0.06657
Policy Update Magnitude: 0.54371
Value Function Update Magnitude: 0.54024

Collected Steps per Second: 23,043.54391
Overall Steps per Second: 10,901.86050

Timestep Collection Time: 2.17024
Timestep Consumption Time: 2.41705
PPO Batch Consumption Time: 0.28041
Total Iteration Time: 4.58729

Cumulative Model Updates: 55,514
Cumulative Timesteps: 463,095,654

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 463095654...
Checkpoint 463095654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 839.67254
Policy Entropy: 3.42027
Value Function Loss: 0.00301

Mean KL Divergence: 0.00725
SB3 Clip Fraction: 0.08391
Policy Update Magnitude: 0.55304
Value Function Update Magnitude: 0.54082

Collected Steps per Second: 22,697.27358
Overall Steps per Second: 10,627.61561

Timestep Collection Time: 2.20423
Timestep Consumption Time: 2.50332
PPO Batch Consumption Time: 0.29201
Total Iteration Time: 4.70755

Cumulative Model Updates: 55,520
Cumulative Timesteps: 463,145,684

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,542.39090
Policy Entropy: 3.43247
Value Function Loss: 0.00314

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.08921
Policy Update Magnitude: 0.56227
Value Function Update Magnitude: 0.56256

Collected Steps per Second: 22,961.96279
Overall Steps per Second: 10,822.67643

Timestep Collection Time: 2.17769
Timestep Consumption Time: 2.44261
PPO Batch Consumption Time: 0.28088
Total Iteration Time: 4.62030

Cumulative Model Updates: 55,526
Cumulative Timesteps: 463,195,688

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 463195688...
Checkpoint 463195688 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,085.92865
Policy Entropy: 3.43405
Value Function Loss: 0.00316

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.09308
Policy Update Magnitude: 0.56027
Value Function Update Magnitude: 0.57370

Collected Steps per Second: 22,839.31311
Overall Steps per Second: 10,709.49219

Timestep Collection Time: 2.18947
Timestep Consumption Time: 2.47985
PPO Batch Consumption Time: 0.29293
Total Iteration Time: 4.66932

Cumulative Model Updates: 55,532
Cumulative Timesteps: 463,245,694

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,318.95947
Policy Entropy: 3.42968
Value Function Loss: 0.00300

Mean KL Divergence: 0.00673
SB3 Clip Fraction: 0.07726
Policy Update Magnitude: 0.56431
Value Function Update Magnitude: 0.57682

Collected Steps per Second: 23,073.20702
Overall Steps per Second: 10,829.00820

Timestep Collection Time: 2.16710
Timestep Consumption Time: 2.45031
PPO Batch Consumption Time: 0.28116
Total Iteration Time: 4.61741

Cumulative Model Updates: 55,538
Cumulative Timesteps: 463,295,696

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 463295696...
Checkpoint 463295696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,327.76405
Policy Entropy: 3.41671
Value Function Loss: 0.00305

Mean KL Divergence: 0.00645
SB3 Clip Fraction: 0.07360
Policy Update Magnitude: 0.56736
Value Function Update Magnitude: 0.57514

Collected Steps per Second: 22,890.16187
Overall Steps per Second: 10,736.46394

Timestep Collection Time: 2.18513
Timestep Consumption Time: 2.47357
PPO Batch Consumption Time: 0.29228
Total Iteration Time: 4.65870

Cumulative Model Updates: 55,544
Cumulative Timesteps: 463,345,714

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 574.00741
Policy Entropy: 3.41668
Value Function Loss: 0.00300

Mean KL Divergence: 0.00628
SB3 Clip Fraction: 0.07192
Policy Update Magnitude: 0.56767
Value Function Update Magnitude: 0.57429

Collected Steps per Second: 22,981.20780
Overall Steps per Second: 10,903.39661

Timestep Collection Time: 2.17665
Timestep Consumption Time: 2.41110
PPO Batch Consumption Time: 0.28104
Total Iteration Time: 4.58774

Cumulative Model Updates: 55,550
Cumulative Timesteps: 463,395,736

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 463395736...
Checkpoint 463395736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,453.85758
Policy Entropy: 3.41893
Value Function Loss: 0.00302

Mean KL Divergence: 0.00653
SB3 Clip Fraction: 0.07399
Policy Update Magnitude: 0.56257
Value Function Update Magnitude: 0.57112

Collected Steps per Second: 22,382.36937
Overall Steps per Second: 10,680.66300

Timestep Collection Time: 2.23435
Timestep Consumption Time: 2.44795
PPO Batch Consumption Time: 0.28832
Total Iteration Time: 4.68229

Cumulative Model Updates: 55,556
Cumulative Timesteps: 463,445,746

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,072.30743
Policy Entropy: 3.40670
Value Function Loss: 0.00288

Mean KL Divergence: 0.00638
SB3 Clip Fraction: 0.07254
Policy Update Magnitude: 0.55652
Value Function Update Magnitude: 0.54576

Collected Steps per Second: 22,780.46351
Overall Steps per Second: 10,794.11753

Timestep Collection Time: 2.19574
Timestep Consumption Time: 2.43826
PPO Batch Consumption Time: 0.28059
Total Iteration Time: 4.63401

Cumulative Model Updates: 55,562
Cumulative Timesteps: 463,495,766

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 463495766...
Checkpoint 463495766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,222.77199
Policy Entropy: 3.40172
Value Function Loss: 0.00282

Mean KL Divergence: 0.00638
SB3 Clip Fraction: 0.07356
Policy Update Magnitude: 0.55105
Value Function Update Magnitude: 0.53196

Collected Steps per Second: 22,525.47514
Overall Steps per Second: 10,709.96389

Timestep Collection Time: 2.22051
Timestep Consumption Time: 2.44972
PPO Batch Consumption Time: 0.28104
Total Iteration Time: 4.67023

Cumulative Model Updates: 55,568
Cumulative Timesteps: 463,545,784

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,156.44474
Policy Entropy: 3.39296
Value Function Loss: 0.00291

Mean KL Divergence: 0.00662
SB3 Clip Fraction: 0.07456
Policy Update Magnitude: 0.55110
Value Function Update Magnitude: 0.52511

Collected Steps per Second: 22,897.37800
Overall Steps per Second: 10,869.75867

Timestep Collection Time: 2.18453
Timestep Consumption Time: 2.41723
PPO Batch Consumption Time: 0.28016
Total Iteration Time: 4.60176

Cumulative Model Updates: 55,574
Cumulative Timesteps: 463,595,804

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 463595804...
Checkpoint 463595804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 844.92870
Policy Entropy: 3.40179
Value Function Loss: 0.00278

Mean KL Divergence: 0.00680
SB3 Clip Fraction: 0.07746
Policy Update Magnitude: 0.54858
Value Function Update Magnitude: 0.52614

Collected Steps per Second: 22,832.40300
Overall Steps per Second: 10,701.40410

Timestep Collection Time: 2.19066
Timestep Consumption Time: 2.48331
PPO Batch Consumption Time: 0.29535
Total Iteration Time: 4.67397

Cumulative Model Updates: 55,580
Cumulative Timesteps: 463,645,822

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,641.57785
Policy Entropy: 3.40117
Value Function Loss: 0.00286

Mean KL Divergence: 0.00690
SB3 Clip Fraction: 0.07856
Policy Update Magnitude: 0.54426
Value Function Update Magnitude: 0.53761

Collected Steps per Second: 22,996.77778
Overall Steps per Second: 10,824.36631

Timestep Collection Time: 2.17517
Timestep Consumption Time: 2.44607
PPO Batch Consumption Time: 0.28068
Total Iteration Time: 4.62124

Cumulative Model Updates: 55,586
Cumulative Timesteps: 463,695,844

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 463695844...
Checkpoint 463695844 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,024.98356
Policy Entropy: 3.41722
Value Function Loss: 0.00273

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.08877
Policy Update Magnitude: 0.54464
Value Function Update Magnitude: 0.55116

Collected Steps per Second: 22,961.82790
Overall Steps per Second: 10,719.19456

Timestep Collection Time: 2.17831
Timestep Consumption Time: 2.48790
PPO Batch Consumption Time: 0.28673
Total Iteration Time: 4.66621

Cumulative Model Updates: 55,592
Cumulative Timesteps: 463,745,862

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,507.27993
Policy Entropy: 3.40762
Value Function Loss: 0.00293

Mean KL Divergence: 0.01065
SB3 Clip Fraction: 0.11385
Policy Update Magnitude: 0.54586
Value Function Update Magnitude: 0.54617

Collected Steps per Second: 23,133.13274
Overall Steps per Second: 10,953.95949

Timestep Collection Time: 2.16244
Timestep Consumption Time: 2.40431
PPO Batch Consumption Time: 0.27952
Total Iteration Time: 4.56675

Cumulative Model Updates: 55,598
Cumulative Timesteps: 463,795,886

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 463795886...
Checkpoint 463795886 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,565.54058
Policy Entropy: 3.39258
Value Function Loss: 0.00298

Mean KL Divergence: 0.01137
SB3 Clip Fraction: 0.12068
Policy Update Magnitude: 0.54629
Value Function Update Magnitude: 0.58726

Collected Steps per Second: 22,741.37933
Overall Steps per Second: 10,600.12156

Timestep Collection Time: 2.19916
Timestep Consumption Time: 2.51890
PPO Batch Consumption Time: 0.29493
Total Iteration Time: 4.71806

Cumulative Model Updates: 55,604
Cumulative Timesteps: 463,845,898

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,244.98077
Policy Entropy: 3.39182
Value Function Loss: 0.00317

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.10470
Policy Update Magnitude: 0.55279
Value Function Update Magnitude: 0.58468

Collected Steps per Second: 23,057.30855
Overall Steps per Second: 10,956.97079

Timestep Collection Time: 2.16868
Timestep Consumption Time: 2.39499
PPO Batch Consumption Time: 0.27916
Total Iteration Time: 4.56367

Cumulative Model Updates: 55,610
Cumulative Timesteps: 463,895,902

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 463895902...
Checkpoint 463895902 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,899.52180
Policy Entropy: 3.40850
Value Function Loss: 0.00308

Mean KL Divergence: 0.00727
SB3 Clip Fraction: 0.08322
Policy Update Magnitude: 0.55869
Value Function Update Magnitude: 0.56934

Collected Steps per Second: 22,378.94673
Overall Steps per Second: 10,611.79058

Timestep Collection Time: 2.23505
Timestep Consumption Time: 2.47839
PPO Batch Consumption Time: 0.28835
Total Iteration Time: 4.71344

Cumulative Model Updates: 55,616
Cumulative Timesteps: 463,945,920

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,554.81051
Policy Entropy: 3.41101
Value Function Loss: 0.00322

Mean KL Divergence: 0.00766
SB3 Clip Fraction: 0.08731
Policy Update Magnitude: 0.56421
Value Function Update Magnitude: 0.59192

Collected Steps per Second: 23,194.19229
Overall Steps per Second: 10,973.86155

Timestep Collection Time: 2.15675
Timestep Consumption Time: 2.40172
PPO Batch Consumption Time: 0.27926
Total Iteration Time: 4.55847

Cumulative Model Updates: 55,622
Cumulative Timesteps: 463,995,944

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 463995944...
Checkpoint 463995944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,466.72389
Policy Entropy: 3.41725
Value Function Loss: 0.00310

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.10062
Policy Update Magnitude: 0.56254
Value Function Update Magnitude: 0.58929

Collected Steps per Second: 22,996.50270
Overall Steps per Second: 10,938.84993

Timestep Collection Time: 2.17468
Timestep Consumption Time: 2.39710
PPO Batch Consumption Time: 0.28052
Total Iteration Time: 4.57178

Cumulative Model Updates: 55,628
Cumulative Timesteps: 464,045,954

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,123.53643
Policy Entropy: 3.40371
Value Function Loss: 0.00308

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.09095
Policy Update Magnitude: 0.55651
Value Function Update Magnitude: 0.59328

Collected Steps per Second: 22,826.76540
Overall Steps per Second: 10,567.33510

Timestep Collection Time: 2.19155
Timestep Consumption Time: 2.54247
PPO Batch Consumption Time: 0.30402
Total Iteration Time: 4.73402

Cumulative Model Updates: 55,634
Cumulative Timesteps: 464,095,980

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 464095980...
Checkpoint 464095980 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,258.61258
Policy Entropy: 3.41332
Value Function Loss: 0.00311

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.09575
Policy Update Magnitude: 0.54856
Value Function Update Magnitude: 0.58250

Collected Steps per Second: 22,444.06052
Overall Steps per Second: 10,609.09473

Timestep Collection Time: 2.22794
Timestep Consumption Time: 2.48538
PPO Batch Consumption Time: 0.29323
Total Iteration Time: 4.71331

Cumulative Model Updates: 55,640
Cumulative Timesteps: 464,145,984

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 693.29106
Policy Entropy: 3.42336
Value Function Loss: 0.00325

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.09473
Policy Update Magnitude: 0.54845
Value Function Update Magnitude: 0.57970

Collected Steps per Second: 22,699.15644
Overall Steps per Second: 10,632.98534

Timestep Collection Time: 2.20343
Timestep Consumption Time: 2.50042
PPO Batch Consumption Time: 0.29184
Total Iteration Time: 4.70385

Cumulative Model Updates: 55,646
Cumulative Timesteps: 464,196,000

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 464196000...
Checkpoint 464196000 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,156.73236
Policy Entropy: 3.42647
Value Function Loss: 0.00311

Mean KL Divergence: 0.00764
SB3 Clip Fraction: 0.08606
Policy Update Magnitude: 0.54650
Value Function Update Magnitude: 0.57227

Collected Steps per Second: 22,716.26154
Overall Steps per Second: 10,848.79237

Timestep Collection Time: 2.20107
Timestep Consumption Time: 2.40774
PPO Batch Consumption Time: 0.28020
Total Iteration Time: 4.60881

Cumulative Model Updates: 55,652
Cumulative Timesteps: 464,246,000

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,474.33994
Policy Entropy: 3.42879
Value Function Loss: 0.00294

Mean KL Divergence: 0.00722
SB3 Clip Fraction: 0.08184
Policy Update Magnitude: 0.53739
Value Function Update Magnitude: 0.55933

Collected Steps per Second: 22,431.03984
Overall Steps per Second: 10,404.10736

Timestep Collection Time: 2.22986
Timestep Consumption Time: 2.57767
PPO Batch Consumption Time: 0.30699
Total Iteration Time: 4.80752

Cumulative Model Updates: 55,658
Cumulative Timesteps: 464,296,018

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 464296018...
Checkpoint 464296018 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,122.12942
Policy Entropy: 3.41326
Value Function Loss: 0.00280

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.08823
Policy Update Magnitude: 0.53058
Value Function Update Magnitude: 0.53272

Collected Steps per Second: 22,140.13188
Overall Steps per Second: 10,576.78794

Timestep Collection Time: 2.25870
Timestep Consumption Time: 2.46939
PPO Batch Consumption Time: 0.28766
Total Iteration Time: 4.72809

Cumulative Model Updates: 55,664
Cumulative Timesteps: 464,346,026

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,025.09799
Policy Entropy: 3.41672
Value Function Loss: 0.00297

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.09823
Policy Update Magnitude: 0.53169
Value Function Update Magnitude: 0.53099

Collected Steps per Second: 21,767.96974
Overall Steps per Second: 10,288.00107

Timestep Collection Time: 2.29714
Timestep Consumption Time: 2.56328
PPO Batch Consumption Time: 0.29935
Total Iteration Time: 4.86042

Cumulative Model Updates: 55,670
Cumulative Timesteps: 464,396,030

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 464396030...
Checkpoint 464396030 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,649.01923
Policy Entropy: 3.41742
Value Function Loss: 0.00285

Mean KL Divergence: 0.00777
SB3 Clip Fraction: 0.08932
Policy Update Magnitude: 0.53462
Value Function Update Magnitude: 0.54535

Collected Steps per Second: 22,554.26740
Overall Steps per Second: 10,558.02455

Timestep Collection Time: 2.21750
Timestep Consumption Time: 2.51956
PPO Batch Consumption Time: 0.29405
Total Iteration Time: 4.73706

Cumulative Model Updates: 55,676
Cumulative Timesteps: 464,446,044

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,656.65898
Policy Entropy: 3.41035
Value Function Loss: 0.00290

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.08713
Policy Update Magnitude: 0.53463
Value Function Update Magnitude: 0.55733

Collected Steps per Second: 22,467.51899
Overall Steps per Second: 10,533.39640

Timestep Collection Time: 2.22615
Timestep Consumption Time: 2.52218
PPO Batch Consumption Time: 0.29425
Total Iteration Time: 4.74833

Cumulative Model Updates: 55,682
Cumulative Timesteps: 464,496,060

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 464496060...
Checkpoint 464496060 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,269.67241
Policy Entropy: 3.41597
Value Function Loss: 0.00283

Mean KL Divergence: 0.00719
SB3 Clip Fraction: 0.08045
Policy Update Magnitude: 0.53724
Value Function Update Magnitude: 0.55353

Collected Steps per Second: 22,828.21599
Overall Steps per Second: 10,739.64193

Timestep Collection Time: 2.19027
Timestep Consumption Time: 2.46538
PPO Batch Consumption Time: 0.29168
Total Iteration Time: 4.65565

Cumulative Model Updates: 55,688
Cumulative Timesteps: 464,546,060

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,780.45057
Policy Entropy: 3.40722
Value Function Loss: 0.00290

Mean KL Divergence: 0.00758
SB3 Clip Fraction: 0.08674
Policy Update Magnitude: 0.53574
Value Function Update Magnitude: 0.54379

Collected Steps per Second: 22,789.66645
Overall Steps per Second: 10,779.98120

Timestep Collection Time: 2.19424
Timestep Consumption Time: 2.44454
PPO Batch Consumption Time: 0.28003
Total Iteration Time: 4.63878

Cumulative Model Updates: 55,694
Cumulative Timesteps: 464,596,066

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 464596066...
Checkpoint 464596066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,089.56579
Policy Entropy: 3.42750
Value Function Loss: 0.00300

Mean KL Divergence: 0.00725
SB3 Clip Fraction: 0.08342
Policy Update Magnitude: 0.53548
Value Function Update Magnitude: 0.54122

Collected Steps per Second: 22,921.38666
Overall Steps per Second: 10,746.28731

Timestep Collection Time: 2.18137
Timestep Consumption Time: 2.47140
PPO Batch Consumption Time: 0.29285
Total Iteration Time: 4.65277

Cumulative Model Updates: 55,700
Cumulative Timesteps: 464,646,066

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,122.47244
Policy Entropy: 3.42073
Value Function Loss: 0.00297

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.08671
Policy Update Magnitude: 0.53974
Value Function Update Magnitude: 0.53839

Collected Steps per Second: 22,781.88056
Overall Steps per Second: 10,760.16061

Timestep Collection Time: 2.19499
Timestep Consumption Time: 2.45234
PPO Batch Consumption Time: 0.28593
Total Iteration Time: 4.64733

Cumulative Model Updates: 55,706
Cumulative Timesteps: 464,696,072

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 464696072...
Checkpoint 464696072 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,213.68838
Policy Entropy: 3.41908
Value Function Loss: 0.00296

Mean KL Divergence: 0.00740
SB3 Clip Fraction: 0.08484
Policy Update Magnitude: 0.54023
Value Function Update Magnitude: 0.55086

Collected Steps per Second: 22,404.04265
Overall Steps per Second: 10,566.31962

Timestep Collection Time: 2.23228
Timestep Consumption Time: 2.50088
PPO Batch Consumption Time: 0.29298
Total Iteration Time: 4.73315

Cumulative Model Updates: 55,712
Cumulative Timesteps: 464,746,084

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,231.00594
Policy Entropy: 3.40888
Value Function Loss: 0.00300

Mean KL Divergence: 0.00672
SB3 Clip Fraction: 0.07685
Policy Update Magnitude: 0.55001
Value Function Update Magnitude: 0.56116

Collected Steps per Second: 22,578.33375
Overall Steps per Second: 10,585.86217

Timestep Collection Time: 2.21496
Timestep Consumption Time: 2.50927
PPO Batch Consumption Time: 0.29469
Total Iteration Time: 4.72423

Cumulative Model Updates: 55,718
Cumulative Timesteps: 464,796,094

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 464796094...
Checkpoint 464796094 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,012.35376
Policy Entropy: 3.41747
Value Function Loss: 0.00299

Mean KL Divergence: 0.00673
SB3 Clip Fraction: 0.07629
Policy Update Magnitude: 0.56246
Value Function Update Magnitude: 0.56634

Collected Steps per Second: 22,804.89544
Overall Steps per Second: 10,646.70879

Timestep Collection Time: 2.19304
Timestep Consumption Time: 2.50438
PPO Batch Consumption Time: 0.29379
Total Iteration Time: 4.69741

Cumulative Model Updates: 55,724
Cumulative Timesteps: 464,846,106

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,700.44127
Policy Entropy: 3.41122
Value Function Loss: 0.00295

Mean KL Divergence: 0.00652
SB3 Clip Fraction: 0.07465
Policy Update Magnitude: 0.56584
Value Function Update Magnitude: 0.57183

Collected Steps per Second: 22,683.47505
Overall Steps per Second: 10,758.44152

Timestep Collection Time: 2.20513
Timestep Consumption Time: 2.44424
PPO Batch Consumption Time: 0.28084
Total Iteration Time: 4.64937

Cumulative Model Updates: 55,730
Cumulative Timesteps: 464,896,126

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 464896126...
Checkpoint 464896126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,566.12469
Policy Entropy: 3.40726
Value Function Loss: 0.00275

Mean KL Divergence: 0.00681
SB3 Clip Fraction: 0.07954
Policy Update Magnitude: 0.56157
Value Function Update Magnitude: 0.57489

Collected Steps per Second: 22,362.32067
Overall Steps per Second: 10,679.26900

Timestep Collection Time: 2.23590
Timestep Consumption Time: 2.44606
PPO Batch Consumption Time: 0.28125
Total Iteration Time: 4.68197

Cumulative Model Updates: 55,736
Cumulative Timesteps: 464,946,126

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,265.00609
Policy Entropy: 3.40384
Value Function Loss: 0.00283

Mean KL Divergence: 0.00746
SB3 Clip Fraction: 0.08570
Policy Update Magnitude: 0.55826
Value Function Update Magnitude: 0.57584

Collected Steps per Second: 22,853.59379
Overall Steps per Second: 10,853.30946

Timestep Collection Time: 2.18906
Timestep Consumption Time: 2.42040
PPO Batch Consumption Time: 0.28073
Total Iteration Time: 4.60947

Cumulative Model Updates: 55,742
Cumulative Timesteps: 464,996,154

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 464996154...
Checkpoint 464996154 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,023.20648
Policy Entropy: 3.42334
Value Function Loss: 0.00311

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.09214
Policy Update Magnitude: 0.55656
Value Function Update Magnitude: 0.57610

Collected Steps per Second: 22,594.01435
Overall Steps per Second: 10,732.94409

Timestep Collection Time: 2.21395
Timestep Consumption Time: 2.44665
PPO Batch Consumption Time: 0.28685
Total Iteration Time: 4.66060

Cumulative Model Updates: 55,748
Cumulative Timesteps: 465,046,176

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 887.65844
Policy Entropy: 3.43458
Value Function Loss: 0.00321

Mean KL Divergence: 0.00725
SB3 Clip Fraction: 0.08567
Policy Update Magnitude: 0.56046
Value Function Update Magnitude: 0.58201

Collected Steps per Second: 22,597.74621
Overall Steps per Second: 10,783.91752

Timestep Collection Time: 2.21394
Timestep Consumption Time: 2.42538
PPO Batch Consumption Time: 0.28056
Total Iteration Time: 4.63932

Cumulative Model Updates: 55,754
Cumulative Timesteps: 465,096,206

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 465096206...
Checkpoint 465096206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 791.24468
Policy Entropy: 3.43319
Value Function Loss: 0.00321

Mean KL Divergence: 0.00696
SB3 Clip Fraction: 0.08006
Policy Update Magnitude: 0.56161
Value Function Update Magnitude: 0.58753

Collected Steps per Second: 22,524.44554
Overall Steps per Second: 10,729.02983

Timestep Collection Time: 2.22061
Timestep Consumption Time: 2.44132
PPO Batch Consumption Time: 0.27994
Total Iteration Time: 4.66193

Cumulative Model Updates: 55,760
Cumulative Timesteps: 465,146,224

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 739.29321
Policy Entropy: 3.42002
Value Function Loss: 0.00307

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.09974
Policy Update Magnitude: 0.55892
Value Function Update Magnitude: 0.59289

Collected Steps per Second: 21,330.00517
Overall Steps per Second: 10,339.05590

Timestep Collection Time: 2.34412
Timestep Consumption Time: 2.49192
PPO Batch Consumption Time: 0.28867
Total Iteration Time: 4.83603

Cumulative Model Updates: 55,766
Cumulative Timesteps: 465,196,224

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 465196224...
Checkpoint 465196224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,373.32276
Policy Entropy: 3.41194
Value Function Loss: 0.00304

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.09524
Policy Update Magnitude: 0.56629
Value Function Update Magnitude: 0.60974

Collected Steps per Second: 20,119.68999
Overall Steps per Second: 9,691.64908

Timestep Collection Time: 2.48602
Timestep Consumption Time: 2.67492
PPO Batch Consumption Time: 0.31303
Total Iteration Time: 5.16094

Cumulative Model Updates: 55,772
Cumulative Timesteps: 465,246,242

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 917.17245
Policy Entropy: 3.41774
Value Function Loss: 0.00299

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.10232
Policy Update Magnitude: 0.56900
Value Function Update Magnitude: 0.61137

Collected Steps per Second: 21,218.58913
Overall Steps per Second: 10,215.68323

Timestep Collection Time: 2.35784
Timestep Consumption Time: 2.53953
PPO Batch Consumption Time: 0.29020
Total Iteration Time: 4.89737

Cumulative Model Updates: 55,778
Cumulative Timesteps: 465,296,272

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 465296272...
Checkpoint 465296272 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,441.03450
Policy Entropy: 3.41636
Value Function Loss: 0.00291

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.09340
Policy Update Magnitude: 0.56885
Value Function Update Magnitude: 0.60593

Collected Steps per Second: 22,512.10515
Overall Steps per Second: 10,623.07173

Timestep Collection Time: 2.22147
Timestep Consumption Time: 2.48621
PPO Batch Consumption Time: 0.29243
Total Iteration Time: 4.70768

Cumulative Model Updates: 55,784
Cumulative Timesteps: 465,346,282

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,186.05877
Policy Entropy: 3.43168
Value Function Loss: 0.00296

Mean KL Divergence: 0.00728
SB3 Clip Fraction: 0.08601
Policy Update Magnitude: 0.56505
Value Function Update Magnitude: 0.61756

Collected Steps per Second: 20,540.31160
Overall Steps per Second: 9,830.90876

Timestep Collection Time: 2.43570
Timestep Consumption Time: 2.65335
PPO Batch Consumption Time: 0.31921
Total Iteration Time: 5.08905

Cumulative Model Updates: 55,790
Cumulative Timesteps: 465,396,312

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 465396312...
Checkpoint 465396312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,573.47291
Policy Entropy: 3.42485
Value Function Loss: 0.00286

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.10462
Policy Update Magnitude: 0.56134
Value Function Update Magnitude: 0.60353

Collected Steps per Second: 21,974.21846
Overall Steps per Second: 10,613.63656

Timestep Collection Time: 2.27667
Timestep Consumption Time: 2.43689
PPO Batch Consumption Time: 0.27995
Total Iteration Time: 4.71356

Cumulative Model Updates: 55,796
Cumulative Timesteps: 465,446,340

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,877.72863
Policy Entropy: 3.42175
Value Function Loss: 0.00291

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.11786
Policy Update Magnitude: 0.55313
Value Function Update Magnitude: 0.60497

Collected Steps per Second: 21,459.33426
Overall Steps per Second: 10,200.75037

Timestep Collection Time: 2.33101
Timestep Consumption Time: 2.57274
PPO Batch Consumption Time: 0.29148
Total Iteration Time: 4.90376

Cumulative Model Updates: 55,802
Cumulative Timesteps: 465,496,362

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 465496362...
Checkpoint 465496362 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,584.49329
Policy Entropy: 3.43089
Value Function Loss: 0.00303

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.10809
Policy Update Magnitude: 0.55456
Value Function Update Magnitude: 0.60007

Collected Steps per Second: 22,287.99304
Overall Steps per Second: 10,625.60625

Timestep Collection Time: 2.24426
Timestep Consumption Time: 2.46324
PPO Batch Consumption Time: 0.29025
Total Iteration Time: 4.70750

Cumulative Model Updates: 55,808
Cumulative Timesteps: 465,546,382

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 681.82845
Policy Entropy: 3.43000
Value Function Loss: 0.00297

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.09867
Policy Update Magnitude: 0.55926
Value Function Update Magnitude: 0.57925

Collected Steps per Second: 22,167.18079
Overall Steps per Second: 10,721.53830

Timestep Collection Time: 2.25604
Timestep Consumption Time: 2.40840
PPO Batch Consumption Time: 0.27975
Total Iteration Time: 4.66444

Cumulative Model Updates: 55,814
Cumulative Timesteps: 465,596,392

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 465596392...
Checkpoint 465596392 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 940.75320
Policy Entropy: 3.44433
Value Function Loss: 0.00305

Mean KL Divergence: 0.01055
SB3 Clip Fraction: 0.12287
Policy Update Magnitude: 0.55885
Value Function Update Magnitude: 0.57525

Collected Steps per Second: 22,800.39287
Overall Steps per Second: 10,703.02343

Timestep Collection Time: 2.19408
Timestep Consumption Time: 2.47992
PPO Batch Consumption Time: 0.29350
Total Iteration Time: 4.67401

Cumulative Model Updates: 55,820
Cumulative Timesteps: 465,646,418

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,255.17368
Policy Entropy: 3.44432
Value Function Loss: 0.00301

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.11009
Policy Update Magnitude: 0.55700
Value Function Update Magnitude: 0.59331

Collected Steps per Second: 22,191.98015
Overall Steps per Second: 10,677.81433

Timestep Collection Time: 2.25433
Timestep Consumption Time: 2.43090
PPO Batch Consumption Time: 0.28372
Total Iteration Time: 4.68523

Cumulative Model Updates: 55,826
Cumulative Timesteps: 465,696,446

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 465696446...
Checkpoint 465696446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 960.02756
Policy Entropy: 3.43479
Value Function Loss: 0.00317

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.09990
Policy Update Magnitude: 0.56488
Value Function Update Magnitude: 0.62095

Collected Steps per Second: 21,099.86795
Overall Steps per Second: 10,016.80998

Timestep Collection Time: 2.37025
Timestep Consumption Time: 2.62256
PPO Batch Consumption Time: 0.31192
Total Iteration Time: 4.99281

Cumulative Model Updates: 55,832
Cumulative Timesteps: 465,746,458

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,098.99668
Policy Entropy: 3.43092
Value Function Loss: 0.00309

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.10451
Policy Update Magnitude: 0.57281
Value Function Update Magnitude: 0.63901

Collected Steps per Second: 21,611.16882
Overall Steps per Second: 10,143.48466

Timestep Collection Time: 2.31362
Timestep Consumption Time: 2.61565
PPO Batch Consumption Time: 0.31185
Total Iteration Time: 4.92927

Cumulative Model Updates: 55,838
Cumulative Timesteps: 465,796,458

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 465796458...
Checkpoint 465796458 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,217.40787
Policy Entropy: 3.42982
Value Function Loss: 0.00309

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.10370
Policy Update Magnitude: 0.56892
Value Function Update Magnitude: 0.63745

Collected Steps per Second: 22,157.26039
Overall Steps per Second: 10,685.98440

Timestep Collection Time: 2.25777
Timestep Consumption Time: 2.42369
PPO Batch Consumption Time: 0.28646
Total Iteration Time: 4.68146

Cumulative Model Updates: 55,844
Cumulative Timesteps: 465,846,484

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,749.03040
Policy Entropy: 3.41894
Value Function Loss: 0.00309

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.09771
Policy Update Magnitude: 0.56407
Value Function Update Magnitude: 0.63258

Collected Steps per Second: 22,068.91999
Overall Steps per Second: 10,553.33938

Timestep Collection Time: 2.26608
Timestep Consumption Time: 2.47270
PPO Batch Consumption Time: 0.27837
Total Iteration Time: 4.73878

Cumulative Model Updates: 55,850
Cumulative Timesteps: 465,896,494

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 465896494...
Checkpoint 465896494 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 759.38607
Policy Entropy: 3.40447
Value Function Loss: 0.00316

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.09211
Policy Update Magnitude: 0.56621
Value Function Update Magnitude: 0.63311

Collected Steps per Second: 21,616.12045
Overall Steps per Second: 10,387.92668

Timestep Collection Time: 2.31420
Timestep Consumption Time: 2.50139
PPO Batch Consumption Time: 0.29286
Total Iteration Time: 4.81559

Cumulative Model Updates: 55,856
Cumulative Timesteps: 465,946,518

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,672.55548
Policy Entropy: 3.40355
Value Function Loss: 0.00298

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.10405
Policy Update Magnitude: 0.56926
Value Function Update Magnitude: 0.61621

Collected Steps per Second: 22,182.06374
Overall Steps per Second: 10,728.11361

Timestep Collection Time: 2.25507
Timestep Consumption Time: 2.40764
PPO Batch Consumption Time: 0.28137
Total Iteration Time: 4.66270

Cumulative Model Updates: 55,862
Cumulative Timesteps: 465,996,540

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 465996540...
Checkpoint 465996540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,073.58076
Policy Entropy: 3.41159
Value Function Loss: 0.00306

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.09898
Policy Update Magnitude: 0.56513
Value Function Update Magnitude: 0.60846

Collected Steps per Second: 21,330.93850
Overall Steps per Second: 10,419.49388

Timestep Collection Time: 2.34504
Timestep Consumption Time: 2.45576
PPO Batch Consumption Time: 0.29116
Total Iteration Time: 4.80081

Cumulative Model Updates: 55,868
Cumulative Timesteps: 466,046,562

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,256.45554
Policy Entropy: 3.43245
Value Function Loss: 0.00297

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.10537
Policy Update Magnitude: 0.55768
Value Function Update Magnitude: 0.62454

Collected Steps per Second: 22,070.86049
Overall Steps per Second: 10,360.04716

Timestep Collection Time: 2.26661
Timestep Consumption Time: 2.56213
PPO Batch Consumption Time: 0.30070
Total Iteration Time: 4.82874

Cumulative Model Updates: 55,874
Cumulative Timesteps: 466,096,588

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 466096588...
Checkpoint 466096588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,312.60323
Policy Entropy: 3.41689
Value Function Loss: 0.00297

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.10693
Policy Update Magnitude: 0.54201
Value Function Update Magnitude: 0.61323

Collected Steps per Second: 22,296.22397
Overall Steps per Second: 10,501.57415

Timestep Collection Time: 2.24316
Timestep Consumption Time: 2.51936
PPO Batch Consumption Time: 0.29229
Total Iteration Time: 4.76252

Cumulative Model Updates: 55,880
Cumulative Timesteps: 466,146,602

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,084.61527
Policy Entropy: 3.41518
Value Function Loss: 0.00286

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.08805
Policy Update Magnitude: 0.53441
Value Function Update Magnitude: 0.58419

Collected Steps per Second: 22,710.78370
Overall Steps per Second: 10,642.34471

Timestep Collection Time: 2.20257
Timestep Consumption Time: 2.49771
PPO Batch Consumption Time: 0.29395
Total Iteration Time: 4.70028

Cumulative Model Updates: 55,886
Cumulative Timesteps: 466,196,624

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 466196624...
Checkpoint 466196624 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,277.99659
Policy Entropy: 3.39556
Value Function Loss: 0.00309

Mean KL Divergence: 0.00764
SB3 Clip Fraction: 0.08665
Policy Update Magnitude: 0.54449
Value Function Update Magnitude: 0.59115

Collected Steps per Second: 21,142.25946
Overall Steps per Second: 10,216.02770

Timestep Collection Time: 2.36559
Timestep Consumption Time: 2.53005
PPO Batch Consumption Time: 0.29535
Total Iteration Time: 4.89564

Cumulative Model Updates: 55,892
Cumulative Timesteps: 466,246,638

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 976.51402
Policy Entropy: 3.41449
Value Function Loss: 0.00308

Mean KL Divergence: 0.00717
SB3 Clip Fraction: 0.08117
Policy Update Magnitude: 0.56490
Value Function Update Magnitude: 0.62266

Collected Steps per Second: 20,704.65465
Overall Steps per Second: 10,499.96664

Timestep Collection Time: 2.41530
Timestep Consumption Time: 2.34738
PPO Batch Consumption Time: 0.28037
Total Iteration Time: 4.76268

Cumulative Model Updates: 55,898
Cumulative Timesteps: 466,296,646

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 466296646...
Checkpoint 466296646 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,561.03229
Policy Entropy: 3.42602
Value Function Loss: 0.00300

Mean KL Divergence: 0.00642
SB3 Clip Fraction: 0.07322
Policy Update Magnitude: 0.57115
Value Function Update Magnitude: 0.61643

Collected Steps per Second: 22,826.67392
Overall Steps per Second: 10,872.40251

Timestep Collection Time: 2.19165
Timestep Consumption Time: 2.40973
PPO Batch Consumption Time: 0.28091
Total Iteration Time: 4.60137

Cumulative Model Updates: 55,904
Cumulative Timesteps: 466,346,674

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,227.43238
Policy Entropy: 3.43300
Value Function Loss: 0.00280

Mean KL Divergence: 0.00714
SB3 Clip Fraction: 0.08120
Policy Update Magnitude: 0.55791
Value Function Update Magnitude: 0.59795

Collected Steps per Second: 22,365.56178
Overall Steps per Second: 10,517.26257

Timestep Collection Time: 2.23603
Timestep Consumption Time: 2.51901
PPO Batch Consumption Time: 0.29254
Total Iteration Time: 4.75504

Cumulative Model Updates: 55,910
Cumulative Timesteps: 466,396,684

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 466396684...
Checkpoint 466396684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 767.23303
Policy Entropy: 3.41330
Value Function Loss: 0.00291

Mean KL Divergence: 0.00716
SB3 Clip Fraction: 0.08179
Policy Update Magnitude: 0.54615
Value Function Update Magnitude: 0.57155

Collected Steps per Second: 22,541.68086
Overall Steps per Second: 10,637.14102

Timestep Collection Time: 2.21918
Timestep Consumption Time: 2.48359
PPO Batch Consumption Time: 0.28914
Total Iteration Time: 4.70277

Cumulative Model Updates: 55,916
Cumulative Timesteps: 466,446,708

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,280.35291
Policy Entropy: 3.41511
Value Function Loss: 0.00295

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.09588
Policy Update Magnitude: 0.54686
Value Function Update Magnitude: 0.56648

Collected Steps per Second: 22,657.35201
Overall Steps per Second: 10,701.34248

Timestep Collection Time: 2.20776
Timestep Consumption Time: 2.46661
PPO Batch Consumption Time: 0.28887
Total Iteration Time: 4.67437

Cumulative Model Updates: 55,922
Cumulative Timesteps: 466,496,730

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 466496730...
Checkpoint 466496730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,502.70696
Policy Entropy: 3.42356
Value Function Loss: 0.00303

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.09399
Policy Update Magnitude: 0.54869
Value Function Update Magnitude: 0.55985

Collected Steps per Second: 22,859.39683
Overall Steps per Second: 10,866.77351

Timestep Collection Time: 2.18737
Timestep Consumption Time: 2.41399
PPO Batch Consumption Time: 0.28038
Total Iteration Time: 4.60137

Cumulative Model Updates: 55,928
Cumulative Timesteps: 466,546,732

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,088.67697
Policy Entropy: 3.42331
Value Function Loss: 0.00318

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.09812
Policy Update Magnitude: 0.55343
Value Function Update Magnitude: 0.55998

Collected Steps per Second: 22,926.29003
Overall Steps per Second: 10,823.48178

Timestep Collection Time: 2.18221
Timestep Consumption Time: 2.44015
PPO Batch Consumption Time: 0.28050
Total Iteration Time: 4.62236

Cumulative Model Updates: 55,934
Cumulative Timesteps: 466,596,762

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 466596762...
Checkpoint 466596762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,016.51487
Policy Entropy: 3.41375
Value Function Loss: 0.00344

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.09988
Policy Update Magnitude: 0.56604
Value Function Update Magnitude: 0.57570

Collected Steps per Second: 22,715.56782
Overall Steps per Second: 10,788.84101

Timestep Collection Time: 2.20149
Timestep Consumption Time: 2.43367
PPO Batch Consumption Time: 0.27945
Total Iteration Time: 4.63516

Cumulative Model Updates: 55,940
Cumulative Timesteps: 466,646,770

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,694.93964
Policy Entropy: 3.41359
Value Function Loss: 0.00344

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.09741
Policy Update Magnitude: 0.57954
Value Function Update Magnitude: 0.59740

Collected Steps per Second: 22,581.16784
Overall Steps per Second: 10,450.10083

Timestep Collection Time: 2.21441
Timestep Consumption Time: 2.57061
PPO Batch Consumption Time: 0.29754
Total Iteration Time: 4.78503

Cumulative Model Updates: 55,946
Cumulative Timesteps: 466,696,774

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 466696774...
Checkpoint 466696774 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,018.25541
Policy Entropy: 3.42600
Value Function Loss: 0.00338

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.08720
Policy Update Magnitude: 0.58423
Value Function Update Magnitude: 0.60783

Collected Steps per Second: 22,361.69108
Overall Steps per Second: 10,608.52909

Timestep Collection Time: 2.23677
Timestep Consumption Time: 2.47811
PPO Batch Consumption Time: 0.29516
Total Iteration Time: 4.71489

Cumulative Model Updates: 55,952
Cumulative Timesteps: 466,746,792

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,163.64586
Policy Entropy: 3.40739
Value Function Loss: 0.00319

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.11474
Policy Update Magnitude: 0.58098
Value Function Update Magnitude: 0.63020

Collected Steps per Second: 22,702.94770
Overall Steps per Second: 10,656.74088

Timestep Collection Time: 2.20368
Timestep Consumption Time: 2.49100
PPO Batch Consumption Time: 0.28955
Total Iteration Time: 4.69468

Cumulative Model Updates: 55,958
Cumulative Timesteps: 466,796,822

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 466796822...
Checkpoint 466796822 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 830.02326
Policy Entropy: 3.40786
Value Function Loss: 0.00321

Mean KL Divergence: 0.01074
SB3 Clip Fraction: 0.12006
Policy Update Magnitude: 0.58478
Value Function Update Magnitude: 0.62822

Collected Steps per Second: 22,724.20235
Overall Steps per Second: 10,850.44837

Timestep Collection Time: 2.20065
Timestep Consumption Time: 2.40819
PPO Batch Consumption Time: 0.28044
Total Iteration Time: 4.60884

Cumulative Model Updates: 55,964
Cumulative Timesteps: 466,846,830

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 928.28251
Policy Entropy: 3.40514
Value Function Loss: 0.00331

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.11066
Policy Update Magnitude: 0.58094
Value Function Update Magnitude: 0.62812

Collected Steps per Second: 22,823.79647
Overall Steps per Second: 10,644.81375

Timestep Collection Time: 2.19096
Timestep Consumption Time: 2.50673
PPO Batch Consumption Time: 0.29100
Total Iteration Time: 4.69769

Cumulative Model Updates: 55,970
Cumulative Timesteps: 466,896,836

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 466896836...
Checkpoint 466896836 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,216.42324
Policy Entropy: 3.41457
Value Function Loss: 0.00327

Mean KL Divergence: 0.00733
SB3 Clip Fraction: 0.08486
Policy Update Magnitude: 0.57964
Value Function Update Magnitude: 0.61053

Collected Steps per Second: 22,927.13411
Overall Steps per Second: 10,650.46203

Timestep Collection Time: 2.18091
Timestep Consumption Time: 2.51391
PPO Batch Consumption Time: 0.29051
Total Iteration Time: 4.69482

Cumulative Model Updates: 55,976
Cumulative Timesteps: 466,946,838

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,040.96119
Policy Entropy: 3.40200
Value Function Loss: 0.00323

Mean KL Divergence: 0.00644
SB3 Clip Fraction: 0.07448
Policy Update Magnitude: 0.57768
Value Function Update Magnitude: 0.60001

Collected Steps per Second: 22,917.43902
Overall Steps per Second: 10,717.03294

Timestep Collection Time: 2.18218
Timestep Consumption Time: 2.48422
PPO Batch Consumption Time: 0.29276
Total Iteration Time: 4.66640

Cumulative Model Updates: 55,982
Cumulative Timesteps: 466,996,848

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 466996848...
Checkpoint 466996848 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,843.83759
Policy Entropy: 3.40126
Value Function Loss: 0.00315

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.09417
Policy Update Magnitude: 0.56441
Value Function Update Magnitude: 0.60383

Collected Steps per Second: 19,836.58298
Overall Steps per Second: 9,710.37698

Timestep Collection Time: 2.52140
Timestep Consumption Time: 2.62938
PPO Batch Consumption Time: 0.30659
Total Iteration Time: 5.15078

Cumulative Model Updates: 55,988
Cumulative Timesteps: 467,046,864

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,074.69381
Policy Entropy: 3.40389
Value Function Loss: 0.00310

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.09485
Policy Update Magnitude: 0.55882
Value Function Update Magnitude: 0.59639

Collected Steps per Second: 21,604.96614
Overall Steps per Second: 10,474.28802

Timestep Collection Time: 2.31502
Timestep Consumption Time: 2.46010
PPO Batch Consumption Time: 0.28531
Total Iteration Time: 4.77512

Cumulative Model Updates: 55,994
Cumulative Timesteps: 467,096,880

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 467096880...
Checkpoint 467096880 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,105.55435
Policy Entropy: 3.42283
Value Function Loss: 0.00296

Mean KL Divergence: 0.00702
SB3 Clip Fraction: 0.08100
Policy Update Magnitude: 0.55562
Value Function Update Magnitude: 0.58726

Collected Steps per Second: 21,934.83173
Overall Steps per Second: 10,334.32124

Timestep Collection Time: 2.28094
Timestep Consumption Time: 2.56041
PPO Batch Consumption Time: 0.30327
Total Iteration Time: 4.84134

Cumulative Model Updates: 56,000
Cumulative Timesteps: 467,146,912

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,634.21620
Policy Entropy: 3.40413
Value Function Loss: 0.00302

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.09806
Policy Update Magnitude: 0.55386
Value Function Update Magnitude: 0.56942

Collected Steps per Second: 22,691.32735
Overall Steps per Second: 10,736.66824

Timestep Collection Time: 2.20410
Timestep Consumption Time: 2.45414
PPO Batch Consumption Time: 0.28559
Total Iteration Time: 4.65824

Cumulative Model Updates: 56,006
Cumulative Timesteps: 467,196,926

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 467196926...
Checkpoint 467196926 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,449.61570
Policy Entropy: 3.40548
Value Function Loss: 0.00332

Mean KL Divergence: 0.01077
SB3 Clip Fraction: 0.11473
Policy Update Magnitude: 0.55739
Value Function Update Magnitude: 0.57916

Collected Steps per Second: 22,026.24644
Overall Steps per Second: 10,644.41896

Timestep Collection Time: 2.27065
Timestep Consumption Time: 2.42796
PPO Batch Consumption Time: 0.27997
Total Iteration Time: 4.69861

Cumulative Model Updates: 56,012
Cumulative Timesteps: 467,246,940

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,132.14108
Policy Entropy: 3.39280
Value Function Loss: 0.00356

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.10864
Policy Update Magnitude: 0.56702
Value Function Update Magnitude: 0.60246

Collected Steps per Second: 22,657.68236
Overall Steps per Second: 10,560.96557

Timestep Collection Time: 2.20746
Timestep Consumption Time: 2.52847
PPO Batch Consumption Time: 0.29394
Total Iteration Time: 4.73593

Cumulative Model Updates: 56,018
Cumulative Timesteps: 467,296,956

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 467296956...
Checkpoint 467296956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 959.67038
Policy Entropy: 3.38740
Value Function Loss: 0.00345

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.11048
Policy Update Magnitude: 0.56946
Value Function Update Magnitude: 0.60682

Collected Steps per Second: 21,710.28774
Overall Steps per Second: 10,198.22029

Timestep Collection Time: 2.30425
Timestep Consumption Time: 2.60111
PPO Batch Consumption Time: 0.30524
Total Iteration Time: 4.90537

Cumulative Model Updates: 56,024
Cumulative Timesteps: 467,346,982

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,973.45336
Policy Entropy: 3.38324
Value Function Loss: 0.00310

Mean KL Divergence: 0.00751
SB3 Clip Fraction: 0.08615
Policy Update Magnitude: 0.56087
Value Function Update Magnitude: 0.59254

Collected Steps per Second: 21,806.56596
Overall Steps per Second: 10,312.52720

Timestep Collection Time: 2.29298
Timestep Consumption Time: 2.55569
PPO Batch Consumption Time: 0.30032
Total Iteration Time: 4.84867

Cumulative Model Updates: 56,030
Cumulative Timesteps: 467,396,984

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 467396984...
Checkpoint 467396984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,001.83005
Policy Entropy: 3.37898
Value Function Loss: 0.00293

Mean KL Divergence: 0.00624
SB3 Clip Fraction: 0.07180
Policy Update Magnitude: 0.55662
Value Function Update Magnitude: 0.57736

Collected Steps per Second: 18,981.22338
Overall Steps per Second: 9,783.21271

Timestep Collection Time: 2.63534
Timestep Consumption Time: 2.47770
PPO Batch Consumption Time: 0.28745
Total Iteration Time: 5.11304

Cumulative Model Updates: 56,036
Cumulative Timesteps: 467,447,006

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,044.24251
Policy Entropy: 3.38284
Value Function Loss: 0.00289

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.10136
Policy Update Magnitude: 0.54754
Value Function Update Magnitude: 0.56985

Collected Steps per Second: 22,734.75836
Overall Steps per Second: 10,636.83186

Timestep Collection Time: 2.19936
Timestep Consumption Time: 2.50147
PPO Batch Consumption Time: 0.28841
Total Iteration Time: 4.70084

Cumulative Model Updates: 56,042
Cumulative Timesteps: 467,497,008

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 467497008...
Checkpoint 467497008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,001.38434
Policy Entropy: 3.38538
Value Function Loss: 0.00308

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.09279
Policy Update Magnitude: 0.55369
Value Function Update Magnitude: 0.58603

Collected Steps per Second: 22,454.41478
Overall Steps per Second: 10,689.21777

Timestep Collection Time: 2.22762
Timestep Consumption Time: 2.45186
PPO Batch Consumption Time: 0.28055
Total Iteration Time: 4.67948

Cumulative Model Updates: 56,048
Cumulative Timesteps: 467,547,028

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 896.03434
Policy Entropy: 3.38712
Value Function Loss: 0.00334

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.09553
Policy Update Magnitude: 0.56862
Value Function Update Magnitude: 0.62112

Collected Steps per Second: 22,804.34144
Overall Steps per Second: 10,672.98333

Timestep Collection Time: 2.19388
Timestep Consumption Time: 2.49366
PPO Batch Consumption Time: 0.28967
Total Iteration Time: 4.68754

Cumulative Model Updates: 56,054
Cumulative Timesteps: 467,597,058

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 467597058...
Checkpoint 467597058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,347.96839
Policy Entropy: 3.39284
Value Function Loss: 0.00339

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.09271
Policy Update Magnitude: 0.58020
Value Function Update Magnitude: 0.62703

Collected Steps per Second: 22,342.15294
Overall Steps per Second: 10,732.74062

Timestep Collection Time: 2.23900
Timestep Consumption Time: 2.42188
PPO Batch Consumption Time: 0.28397
Total Iteration Time: 4.66088

Cumulative Model Updates: 56,060
Cumulative Timesteps: 467,647,082

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 963.71501
Policy Entropy: 3.38892
Value Function Loss: 0.00331

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.09098
Policy Update Magnitude: 0.57514
Value Function Update Magnitude: 0.62355

Collected Steps per Second: 22,626.33990
Overall Steps per Second: 10,564.11892

Timestep Collection Time: 2.21079
Timestep Consumption Time: 2.52430
PPO Batch Consumption Time: 0.29538
Total Iteration Time: 4.73508

Cumulative Model Updates: 56,066
Cumulative Timesteps: 467,697,104

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 467697104...
Checkpoint 467697104 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,366.69787
Policy Entropy: 3.39834
Value Function Loss: 0.00325

Mean KL Divergence: 0.00716
SB3 Clip Fraction: 0.08404
Policy Update Magnitude: 0.57383
Value Function Update Magnitude: 0.62448

Collected Steps per Second: 22,665.60841
Overall Steps per Second: 10,662.20095

Timestep Collection Time: 2.20678
Timestep Consumption Time: 2.48437
PPO Batch Consumption Time: 0.29181
Total Iteration Time: 4.69115

Cumulative Model Updates: 56,072
Cumulative Timesteps: 467,747,122

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,824.84620
Policy Entropy: 3.40030
Value Function Loss: 0.00305

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.09782
Policy Update Magnitude: 0.56235
Value Function Update Magnitude: 0.60850

Collected Steps per Second: 23,245.72662
Overall Steps per Second: 10,999.69885

Timestep Collection Time: 2.15283
Timestep Consumption Time: 2.39675
PPO Batch Consumption Time: 0.27884
Total Iteration Time: 4.54958

Cumulative Model Updates: 56,078
Cumulative Timesteps: 467,797,166

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 467797166...
Checkpoint 467797166 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,964.00548
Policy Entropy: 3.41168
Value Function Loss: 0.00300

Mean KL Divergence: 0.00727
SB3 Clip Fraction: 0.08650
Policy Update Magnitude: 0.54474
Value Function Update Magnitude: 0.58042

Collected Steps per Second: 22,574.52917
Overall Steps per Second: 10,567.60382

Timestep Collection Time: 2.21524
Timestep Consumption Time: 2.51696
PPO Batch Consumption Time: 0.29495
Total Iteration Time: 4.73220

Cumulative Model Updates: 56,084
Cumulative Timesteps: 467,847,174

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,443.88301
Policy Entropy: 3.40487
Value Function Loss: 0.00294

Mean KL Divergence: 0.00691
SB3 Clip Fraction: 0.08092
Policy Update Magnitude: 0.53988
Value Function Update Magnitude: 0.57109

Collected Steps per Second: 22,604.47529
Overall Steps per Second: 10,544.86831

Timestep Collection Time: 2.21222
Timestep Consumption Time: 2.53000
PPO Batch Consumption Time: 0.29449
Total Iteration Time: 4.74221

Cumulative Model Updates: 56,090
Cumulative Timesteps: 467,897,180

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 467897180...
Checkpoint 467897180 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,200.41937
Policy Entropy: 3.40085
Value Function Loss: 0.00299

Mean KL Divergence: 0.00749
SB3 Clip Fraction: 0.08594
Policy Update Magnitude: 0.54446
Value Function Update Magnitude: 0.57173

Collected Steps per Second: 22,869.37511
Overall Steps per Second: 10,639.19272

Timestep Collection Time: 2.18738
Timestep Consumption Time: 2.51448
PPO Batch Consumption Time: 0.29479
Total Iteration Time: 4.70186

Cumulative Model Updates: 56,096
Cumulative Timesteps: 467,947,204

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,499.94937
Policy Entropy: 3.40492
Value Function Loss: 0.00302

Mean KL Divergence: 0.00777
SB3 Clip Fraction: 0.09045
Policy Update Magnitude: 0.54827
Value Function Update Magnitude: 0.56926

Collected Steps per Second: 23,307.73294
Overall Steps per Second: 10,856.66929

Timestep Collection Time: 2.14641
Timestep Consumption Time: 2.46163
PPO Batch Consumption Time: 0.28994
Total Iteration Time: 4.60804

Cumulative Model Updates: 56,102
Cumulative Timesteps: 467,997,232

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 467997232...
Checkpoint 467997232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,622.88840
Policy Entropy: 3.39161
Value Function Loss: 0.00307

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.09293
Policy Update Magnitude: 0.55565
Value Function Update Magnitude: 0.58198

Collected Steps per Second: 22,949.47454
Overall Steps per Second: 10,784.97684

Timestep Collection Time: 2.17957
Timestep Consumption Time: 2.45836
PPO Batch Consumption Time: 0.29248
Total Iteration Time: 4.63793

Cumulative Model Updates: 56,108
Cumulative Timesteps: 468,047,252

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 904.83460
Policy Entropy: 3.39592
Value Function Loss: 0.00313

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.09434
Policy Update Magnitude: 0.55770
Value Function Update Magnitude: 0.56808

Collected Steps per Second: 23,327.86654
Overall Steps per Second: 10,813.87997

Timestep Collection Time: 2.14507
Timestep Consumption Time: 2.48231
PPO Batch Consumption Time: 0.29458
Total Iteration Time: 4.62739

Cumulative Model Updates: 56,114
Cumulative Timesteps: 468,097,292

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 468097292...
Checkpoint 468097292 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,519.36224
Policy Entropy: 3.38595
Value Function Loss: 0.00313

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.10624
Policy Update Magnitude: 0.55499
Value Function Update Magnitude: 0.55883

Collected Steps per Second: 22,960.18720
Overall Steps per Second: 10,794.19169

Timestep Collection Time: 2.17777
Timestep Consumption Time: 2.45454
PPO Batch Consumption Time: 0.28981
Total Iteration Time: 4.63231

Cumulative Model Updates: 56,120
Cumulative Timesteps: 468,147,294

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,606.05163
Policy Entropy: 3.38654
Value Function Loss: 0.00317

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.09714
Policy Update Magnitude: 0.56450
Value Function Update Magnitude: 0.56049

Collected Steps per Second: 23,387.75056
Overall Steps per Second: 10,878.58899

Timestep Collection Time: 2.13804
Timestep Consumption Time: 2.45851
PPO Batch Consumption Time: 0.29079
Total Iteration Time: 4.59655

Cumulative Model Updates: 56,126
Cumulative Timesteps: 468,197,298

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 468197298...
Checkpoint 468197298 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,097.11268
Policy Entropy: 3.38850
Value Function Loss: 0.00318

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.09756
Policy Update Magnitude: 0.56504
Value Function Update Magnitude: 0.58128

Collected Steps per Second: 22,627.37965
Overall Steps per Second: 10,839.52118

Timestep Collection Time: 2.21077
Timestep Consumption Time: 2.40419
PPO Batch Consumption Time: 0.28109
Total Iteration Time: 4.61496

Cumulative Model Updates: 56,132
Cumulative Timesteps: 468,247,322

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 989.07691
Policy Entropy: 3.38499
Value Function Loss: 0.00324

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.09438
Policy Update Magnitude: 0.56723
Value Function Update Magnitude: 0.58622

Collected Steps per Second: 22,611.39818
Overall Steps per Second: 10,553.99998

Timestep Collection Time: 2.21242
Timestep Consumption Time: 2.52758
PPO Batch Consumption Time: 0.29535
Total Iteration Time: 4.74000

Cumulative Model Updates: 56,138
Cumulative Timesteps: 468,297,348

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 468297348...
Checkpoint 468297348 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 893.32384
Policy Entropy: 3.38216
Value Function Loss: 0.00326

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.08756
Policy Update Magnitude: 0.57306
Value Function Update Magnitude: 0.59527

Collected Steps per Second: 22,793.74925
Overall Steps per Second: 10,726.40004

Timestep Collection Time: 2.19411
Timestep Consumption Time: 2.46840
PPO Batch Consumption Time: 0.29346
Total Iteration Time: 4.66251

Cumulative Model Updates: 56,144
Cumulative Timesteps: 468,347,360

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,475.54565
Policy Entropy: 3.38761
Value Function Loss: 0.00314

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.08872
Policy Update Magnitude: 0.56482
Value Function Update Magnitude: 0.58164

Collected Steps per Second: 22,692.37284
Overall Steps per Second: 10,852.41503

Timestep Collection Time: 2.20462
Timestep Consumption Time: 2.40523
PPO Batch Consumption Time: 0.27969
Total Iteration Time: 4.60985

Cumulative Model Updates: 56,150
Cumulative Timesteps: 468,397,388

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 468397388...
Checkpoint 468397388 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,683.06675
Policy Entropy: 3.39842
Value Function Loss: 0.00329

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.08855
Policy Update Magnitude: 0.55851
Value Function Update Magnitude: 0.56624

Collected Steps per Second: 22,562.35510
Overall Steps per Second: 10,669.19202

Timestep Collection Time: 2.21626
Timestep Consumption Time: 2.47051
PPO Batch Consumption Time: 0.28965
Total Iteration Time: 4.68677

Cumulative Model Updates: 56,156
Cumulative Timesteps: 468,447,392

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,228.41686
Policy Entropy: 3.40150
Value Function Loss: 0.00319

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.08896
Policy Update Magnitude: 0.55798
Value Function Update Magnitude: 0.58984

Collected Steps per Second: 23,151.69387
Overall Steps per Second: 10,968.26556

Timestep Collection Time: 2.16027
Timestep Consumption Time: 2.39961
PPO Batch Consumption Time: 0.27884
Total Iteration Time: 4.55988

Cumulative Model Updates: 56,162
Cumulative Timesteps: 468,497,406

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 468497406...
Checkpoint 468497406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,176.56677
Policy Entropy: 3.40656
Value Function Loss: 0.00321

Mean KL Divergence: 0.00763
SB3 Clip Fraction: 0.08764
Policy Update Magnitude: 0.55377
Value Function Update Magnitude: 0.58769

Collected Steps per Second: 22,789.25105
Overall Steps per Second: 10,759.46192

Timestep Collection Time: 2.19472
Timestep Consumption Time: 2.45384
PPO Batch Consumption Time: 0.29027
Total Iteration Time: 4.64856

Cumulative Model Updates: 56,168
Cumulative Timesteps: 468,547,422

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,520.63677
Policy Entropy: 3.40796
Value Function Loss: 0.00295

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.10499
Policy Update Magnitude: 0.53997
Value Function Update Magnitude: 0.57184

Collected Steps per Second: 23,189.24357
Overall Steps per Second: 10,713.27415

Timestep Collection Time: 2.15617
Timestep Consumption Time: 2.51094
PPO Batch Consumption Time: 0.29259
Total Iteration Time: 4.66711

Cumulative Model Updates: 56,174
Cumulative Timesteps: 468,597,422

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 468597422...
Checkpoint 468597422 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,815.47971
Policy Entropy: 3.39714
Value Function Loss: 0.00285

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.11232
Policy Update Magnitude: 0.53490
Value Function Update Magnitude: 0.56840

Collected Steps per Second: 22,413.36733
Overall Steps per Second: 10,605.04250

Timestep Collection Time: 2.23161
Timestep Consumption Time: 2.48482
PPO Batch Consumption Time: 0.29129
Total Iteration Time: 4.71644

Cumulative Model Updates: 56,180
Cumulative Timesteps: 468,647,440

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,570.82253
Policy Entropy: 3.40346
Value Function Loss: 0.00278

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.09718
Policy Update Magnitude: 0.53741
Value Function Update Magnitude: 0.57442

Collected Steps per Second: 23,002.17577
Overall Steps per Second: 10,914.31525

Timestep Collection Time: 2.17440
Timestep Consumption Time: 2.40820
PPO Batch Consumption Time: 0.28099
Total Iteration Time: 4.58261

Cumulative Model Updates: 56,186
Cumulative Timesteps: 468,697,456

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 468697456...
Checkpoint 468697456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,520.09857
Policy Entropy: 3.39848
Value Function Loss: 0.00285

Mean KL Divergence: 0.00772
SB3 Clip Fraction: 0.08799
Policy Update Magnitude: 0.53857
Value Function Update Magnitude: 0.58237

Collected Steps per Second: 22,899.71027
Overall Steps per Second: 10,634.18812

Timestep Collection Time: 2.18405
Timestep Consumption Time: 2.51909
PPO Batch Consumption Time: 0.29444
Total Iteration Time: 4.70313

Cumulative Model Updates: 56,192
Cumulative Timesteps: 468,747,470

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,601.57967
Policy Entropy: 3.39598
Value Function Loss: 0.00289

Mean KL Divergence: 0.00724
SB3 Clip Fraction: 0.08474
Policy Update Magnitude: 0.53259
Value Function Update Magnitude: 0.58833

Collected Steps per Second: 23,172.23225
Overall Steps per Second: 10,954.74815

Timestep Collection Time: 2.15776
Timestep Consumption Time: 2.40648
PPO Batch Consumption Time: 0.27963
Total Iteration Time: 4.56423

Cumulative Model Updates: 56,198
Cumulative Timesteps: 468,797,470

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 468797470...
Checkpoint 468797470 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,871.04391
Policy Entropy: 3.39968
Value Function Loss: 0.00299

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.09558
Policy Update Magnitude: 0.53170
Value Function Update Magnitude: 0.58572

Collected Steps per Second: 22,653.17292
Overall Steps per Second: 10,614.35764

Timestep Collection Time: 2.20737
Timestep Consumption Time: 2.50360
PPO Batch Consumption Time: 0.29374
Total Iteration Time: 4.71098

Cumulative Model Updates: 56,204
Cumulative Timesteps: 468,847,474

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,631.43990
Policy Entropy: 3.39312
Value Function Loss: 0.00289

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.09112
Policy Update Magnitude: 0.52710
Value Function Update Magnitude: 0.58951

Collected Steps per Second: 23,050.81602
Overall Steps per Second: 10,922.15931

Timestep Collection Time: 2.16938
Timestep Consumption Time: 2.40902
PPO Batch Consumption Time: 0.27958
Total Iteration Time: 4.57840

Cumulative Model Updates: 56,210
Cumulative Timesteps: 468,897,480

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 468897480...
Checkpoint 468897480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,040.58079
Policy Entropy: 3.39702
Value Function Loss: 0.00291

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.08853
Policy Update Magnitude: 0.53081
Value Function Update Magnitude: 0.58794

Collected Steps per Second: 22,925.03726
Overall Steps per Second: 10,754.81960

Timestep Collection Time: 2.18137
Timestep Consumption Time: 2.46845
PPO Batch Consumption Time: 0.29273
Total Iteration Time: 4.64982

Cumulative Model Updates: 56,216
Cumulative Timesteps: 468,947,488

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,696.47350
Policy Entropy: 3.38710
Value Function Loss: 0.00302

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.09111
Policy Update Magnitude: 0.54129
Value Function Update Magnitude: 0.58506

Collected Steps per Second: 22,901.89288
Overall Steps per Second: 10,795.01309

Timestep Collection Time: 2.18427
Timestep Consumption Time: 2.44972
PPO Batch Consumption Time: 0.28910
Total Iteration Time: 4.63399

Cumulative Model Updates: 56,222
Cumulative Timesteps: 468,997,512

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 468997512...
Checkpoint 468997512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,089.47330
Policy Entropy: 3.39413
Value Function Loss: 0.00319

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.10011
Policy Update Magnitude: 0.55513
Value Function Update Magnitude: 0.58773

Collected Steps per Second: 22,491.78317
Overall Steps per Second: 10,604.90075

Timestep Collection Time: 2.22321
Timestep Consumption Time: 2.49197
PPO Batch Consumption Time: 0.28845
Total Iteration Time: 4.71518

Cumulative Model Updates: 56,228
Cumulative Timesteps: 469,047,516

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 932.70542
Policy Entropy: 3.39292
Value Function Loss: 0.00324

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.09312
Policy Update Magnitude: 0.55970
Value Function Update Magnitude: 0.59548

Collected Steps per Second: 22,853.20553
Overall Steps per Second: 10,742.02002

Timestep Collection Time: 2.18858
Timestep Consumption Time: 2.46753
PPO Batch Consumption Time: 0.28842
Total Iteration Time: 4.65611

Cumulative Model Updates: 56,234
Cumulative Timesteps: 469,097,532

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 469097532...
Checkpoint 469097532 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 701.46571
Policy Entropy: 3.39476
Value Function Loss: 0.00326

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.09219
Policy Update Magnitude: 0.56453
Value Function Update Magnitude: 0.61935

Collected Steps per Second: 20,657.24100
Overall Steps per Second: 10,324.56898

Timestep Collection Time: 2.42065
Timestep Consumption Time: 2.42255
PPO Batch Consumption Time: 0.28128
Total Iteration Time: 4.84320

Cumulative Model Updates: 56,240
Cumulative Timesteps: 469,147,536

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 878.79613
Policy Entropy: 3.39602
Value Function Loss: 0.00302

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.10477
Policy Update Magnitude: 0.56326
Value Function Update Magnitude: 0.62398

Collected Steps per Second: 22,783.77423
Overall Steps per Second: 10,618.60702

Timestep Collection Time: 2.19463
Timestep Consumption Time: 2.51427
PPO Batch Consumption Time: 0.29418
Total Iteration Time: 4.70890

Cumulative Model Updates: 56,246
Cumulative Timesteps: 469,197,538

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 469197538...
Checkpoint 469197538 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,291.21096
Policy Entropy: 3.39793
Value Function Loss: 0.00301

Mean KL Divergence: 0.00782
SB3 Clip Fraction: 0.09027
Policy Update Magnitude: 0.56487
Value Function Update Magnitude: 0.62513

Collected Steps per Second: 21,765.19282
Overall Steps per Second: 10,263.22905

Timestep Collection Time: 2.29816
Timestep Consumption Time: 2.57554
PPO Batch Consumption Time: 0.29733
Total Iteration Time: 4.87371

Cumulative Model Updates: 56,252
Cumulative Timesteps: 469,247,558

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,257.35133
Policy Entropy: 3.39316
Value Function Loss: 0.00295

Mean KL Divergence: 0.00701
SB3 Clip Fraction: 0.08096
Policy Update Magnitude: 0.56811
Value Function Update Magnitude: 0.62128

Collected Steps per Second: 21,323.44329
Overall Steps per Second: 10,288.34501

Timestep Collection Time: 2.34709
Timestep Consumption Time: 2.51745
PPO Batch Consumption Time: 0.29566
Total Iteration Time: 4.86453

Cumulative Model Updates: 56,258
Cumulative Timesteps: 469,297,606

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 469297606...
Checkpoint 469297606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,897.60781
Policy Entropy: 3.38033
Value Function Loss: 0.00313

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.10563
Policy Update Magnitude: 0.56842
Value Function Update Magnitude: 0.64197

Collected Steps per Second: 20,905.77422
Overall Steps per Second: 9,892.30558

Timestep Collection Time: 2.39264
Timestep Consumption Time: 2.66381
PPO Batch Consumption Time: 0.30236
Total Iteration Time: 5.05646

Cumulative Model Updates: 56,264
Cumulative Timesteps: 469,347,626

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,027.90074
Policy Entropy: 3.38542
Value Function Loss: 0.00317

Mean KL Divergence: 0.01151
SB3 Clip Fraction: 0.12530
Policy Update Magnitude: 0.56589
Value Function Update Magnitude: 0.63697

Collected Steps per Second: 13,630.09876
Overall Steps per Second: 7,900.38232

Timestep Collection Time: 3.66879
Timestep Consumption Time: 2.66077
PPO Batch Consumption Time: 0.29670
Total Iteration Time: 6.32957

Cumulative Model Updates: 56,270
Cumulative Timesteps: 469,397,632

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 469397632...
Checkpoint 469397632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,793.48121
Policy Entropy: 3.37891
Value Function Loss: 0.00308

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.11052
Policy Update Magnitude: 0.55325
Value Function Update Magnitude: 0.62554

Collected Steps per Second: 19,812.08630
Overall Steps per Second: 9,771.45764

Timestep Collection Time: 2.52391
Timestep Consumption Time: 2.59344
PPO Batch Consumption Time: 0.29647
Total Iteration Time: 5.11735

Cumulative Model Updates: 56,276
Cumulative Timesteps: 469,447,636

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,336.14521
Policy Entropy: 3.39242
Value Function Loss: 0.00294

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.10592
Policy Update Magnitude: 0.54818
Value Function Update Magnitude: 0.61172

Collected Steps per Second: 20,282.67205
Overall Steps per Second: 10,066.22352

Timestep Collection Time: 2.46624
Timestep Consumption Time: 2.50305
PPO Batch Consumption Time: 0.29001
Total Iteration Time: 4.96929

Cumulative Model Updates: 56,282
Cumulative Timesteps: 469,497,658

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 469497658...
Checkpoint 469497658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,080.50752
Policy Entropy: 3.39475
Value Function Loss: 0.00283

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.09556
Policy Update Magnitude: 0.53368
Value Function Update Magnitude: 0.61935

Collected Steps per Second: 21,636.17928
Overall Steps per Second: 10,283.31734

Timestep Collection Time: 2.31178
Timestep Consumption Time: 2.55222
PPO Batch Consumption Time: 0.29167
Total Iteration Time: 4.86399

Cumulative Model Updates: 56,288
Cumulative Timesteps: 469,547,676

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,036.67157
Policy Entropy: 3.40438
Value Function Loss: 0.00298

Mean KL Divergence: 0.00721
SB3 Clip Fraction: 0.08388
Policy Update Magnitude: 0.54055
Value Function Update Magnitude: 0.61254

Collected Steps per Second: 14,129.95300
Overall Steps per Second: 8,071.53571

Timestep Collection Time: 3.54255
Timestep Consumption Time: 2.65900
PPO Batch Consumption Time: 0.29103
Total Iteration Time: 6.20155

Cumulative Model Updates: 56,294
Cumulative Timesteps: 469,597,732

Timesteps Collected: 50,056
--------END ITERATION REPORT--------


Saving checkpoint 469597732...
Checkpoint 469597732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,055.23455
Policy Entropy: 3.40901
Value Function Loss: 0.00307

Mean KL Divergence: 0.00733
SB3 Clip Fraction: 0.08543
Policy Update Magnitude: 0.55539
Value Function Update Magnitude: 0.63457

Collected Steps per Second: 22,198.54413
Overall Steps per Second: 10,343.92860

Timestep Collection Time: 2.25384
Timestep Consumption Time: 2.58301
PPO Batch Consumption Time: 0.31242
Total Iteration Time: 4.83685

Cumulative Model Updates: 56,300
Cumulative Timesteps: 469,647,764

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,318.42166
Policy Entropy: 3.40088
Value Function Loss: 0.00296

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.09359
Policy Update Magnitude: 0.55726
Value Function Update Magnitude: 0.63490

Collected Steps per Second: 19,833.99693
Overall Steps per Second: 9,573.88939

Timestep Collection Time: 2.52213
Timestep Consumption Time: 2.70291
PPO Batch Consumption Time: 0.31425
Total Iteration Time: 5.22504

Cumulative Model Updates: 56,306
Cumulative Timesteps: 469,697,788

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 469697788...
Checkpoint 469697788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,159.48810
Policy Entropy: 3.41079
Value Function Loss: 0.00308

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.09436
Policy Update Magnitude: 0.55335
Value Function Update Magnitude: 0.61320

Collected Steps per Second: 20,662.20794
Overall Steps per Second: 9,945.13826

Timestep Collection Time: 2.42017
Timestep Consumption Time: 2.60802
PPO Batch Consumption Time: 0.30415
Total Iteration Time: 5.02819

Cumulative Model Updates: 56,312
Cumulative Timesteps: 469,747,794

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,431.53736
Policy Entropy: 3.39945
Value Function Loss: 0.00298

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.08998
Policy Update Magnitude: 0.55093
Value Function Update Magnitude: 0.59089

Collected Steps per Second: 21,483.76944
Overall Steps per Second: 10,455.59927

Timestep Collection Time: 2.32771
Timestep Consumption Time: 2.45518
PPO Batch Consumption Time: 0.28195
Total Iteration Time: 4.78289

Cumulative Model Updates: 56,318
Cumulative Timesteps: 469,797,802

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 469797802...
Checkpoint 469797802 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,090.64750
Policy Entropy: 3.40008
Value Function Loss: 0.00287

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.10137
Policy Update Magnitude: 0.54623
Value Function Update Magnitude: 0.57334

Collected Steps per Second: 19,801.14829
Overall Steps per Second: 9,691.14157

Timestep Collection Time: 2.52551
Timestep Consumption Time: 2.63467
PPO Batch Consumption Time: 0.31447
Total Iteration Time: 5.16018

Cumulative Model Updates: 56,324
Cumulative Timesteps: 469,847,810

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,078.40062
Policy Entropy: 3.38528
Value Function Loss: 0.00285

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.10983
Policy Update Magnitude: 0.54067
Value Function Update Magnitude: 0.56832

Collected Steps per Second: 20,732.17306
Overall Steps per Second: 9,959.94631

Timestep Collection Time: 2.41210
Timestep Consumption Time: 2.60881
PPO Batch Consumption Time: 0.30306
Total Iteration Time: 5.02091

Cumulative Model Updates: 56,330
Cumulative Timesteps: 469,897,818

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 469897818...
Checkpoint 469897818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 934.96140
Policy Entropy: 3.38000
Value Function Loss: 0.00302

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.09769
Policy Update Magnitude: 0.55272
Value Function Update Magnitude: 0.57375

Collected Steps per Second: 22,261.06829
Overall Steps per Second: 10,579.63514

Timestep Collection Time: 2.24670
Timestep Consumption Time: 2.48068
PPO Batch Consumption Time: 0.29413
Total Iteration Time: 4.72738

Cumulative Model Updates: 56,336
Cumulative Timesteps: 469,947,832

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,003.20429
Policy Entropy: 3.37762
Value Function Loss: 0.00332

Mean KL Divergence: 0.00740
SB3 Clip Fraction: 0.08516
Policy Update Magnitude: 0.57356
Value Function Update Magnitude: 0.60045

Collected Steps per Second: 22,291.29557
Overall Steps per Second: 10,731.21158

Timestep Collection Time: 2.24348
Timestep Consumption Time: 2.41676
PPO Batch Consumption Time: 0.28072
Total Iteration Time: 4.66024

Cumulative Model Updates: 56,342
Cumulative Timesteps: 469,997,842

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 469997842...
Checkpoint 469997842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,159.91710
Policy Entropy: 3.37983
Value Function Loss: 0.00341

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.10747
Policy Update Magnitude: 0.58101
Value Function Update Magnitude: 0.64285

Collected Steps per Second: 22,258.32485
Overall Steps per Second: 10,699.04820

Timestep Collection Time: 2.24662
Timestep Consumption Time: 2.42725
PPO Batch Consumption Time: 0.28351
Total Iteration Time: 4.67387

Cumulative Model Updates: 56,348
Cumulative Timesteps: 470,047,848

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,439.69066
Policy Entropy: 3.38315
Value Function Loss: 0.00327

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.09750
Policy Update Magnitude: 0.57750
Value Function Update Magnitude: 0.65180

Collected Steps per Second: 22,599.04164
Overall Steps per Second: 10,558.10180

Timestep Collection Time: 2.21266
Timestep Consumption Time: 2.52342
PPO Batch Consumption Time: 0.29418
Total Iteration Time: 4.73608

Cumulative Model Updates: 56,354
Cumulative Timesteps: 470,097,852

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 470097852...
Checkpoint 470097852 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 895.83904
Policy Entropy: 3.37854
Value Function Loss: 0.00321

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.10331
Policy Update Magnitude: 0.57002
Value Function Update Magnitude: 0.63884

Collected Steps per Second: 22,431.41744
Overall Steps per Second: 10,538.81443

Timestep Collection Time: 2.22928
Timestep Consumption Time: 2.51565
PPO Batch Consumption Time: 0.29063
Total Iteration Time: 4.74494

Cumulative Model Updates: 56,360
Cumulative Timesteps: 470,147,858

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 780.10510
Policy Entropy: 3.38751
Value Function Loss: 0.00318

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.09240
Policy Update Magnitude: 0.57054
Value Function Update Magnitude: 0.61673

Collected Steps per Second: 22,314.26812
Overall Steps per Second: 10,577.85837

Timestep Collection Time: 2.24260
Timestep Consumption Time: 2.48822
PPO Batch Consumption Time: 0.29372
Total Iteration Time: 4.73083

Cumulative Model Updates: 56,366
Cumulative Timesteps: 470,197,900

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 470197900...
Checkpoint 470197900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,320.55914
Policy Entropy: 3.37449
Value Function Loss: 0.00316

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.09890
Policy Update Magnitude: 0.56679
Value Function Update Magnitude: 0.58708

Collected Steps per Second: 22,183.42844
Overall Steps per Second: 10,371.19100

Timestep Collection Time: 2.25529
Timestep Consumption Time: 2.56865
PPO Batch Consumption Time: 0.30617
Total Iteration Time: 4.82394

Cumulative Model Updates: 56,372
Cumulative Timesteps: 470,247,930

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,412.71857
Policy Entropy: 3.35553
Value Function Loss: 0.00332

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.10156
Policy Update Magnitude: 0.56761
Value Function Update Magnitude: 0.57085

Collected Steps per Second: 22,790.56374
Overall Steps per Second: 10,591.25882

Timestep Collection Time: 2.19477
Timestep Consumption Time: 2.52799
PPO Batch Consumption Time: 0.29741
Total Iteration Time: 4.72276

Cumulative Model Updates: 56,378
Cumulative Timesteps: 470,297,950

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 470297950...
Checkpoint 470297950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,989.49494
Policy Entropy: 3.34746
Value Function Loss: 0.00330

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.11598
Policy Update Magnitude: 0.56929
Value Function Update Magnitude: 0.57524

Collected Steps per Second: 22,535.71985
Overall Steps per Second: 10,650.88561

Timestep Collection Time: 2.21994
Timestep Consumption Time: 2.47713
PPO Batch Consumption Time: 0.28963
Total Iteration Time: 4.69707

Cumulative Model Updates: 56,384
Cumulative Timesteps: 470,347,978

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,547.26805
Policy Entropy: 3.35232
Value Function Loss: 0.00317

Mean KL Divergence: 0.01368
SB3 Clip Fraction: 0.13324
Policy Update Magnitude: 0.56375
Value Function Update Magnitude: 0.55936

Collected Steps per Second: 21,336.72464
Overall Steps per Second: 10,433.46539

Timestep Collection Time: 2.34450
Timestep Consumption Time: 2.45007
PPO Batch Consumption Time: 0.28158
Total Iteration Time: 4.79457

Cumulative Model Updates: 56,390
Cumulative Timesteps: 470,398,002

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 470398002...
Checkpoint 470398002 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,640.00080
Policy Entropy: 3.37471
Value Function Loss: 0.00301

Mean KL Divergence: 0.01380
SB3 Clip Fraction: 0.14427
Policy Update Magnitude: 0.54829
Value Function Update Magnitude: 0.54094

Collected Steps per Second: 22,442.01250
Overall Steps per Second: 10,727.60619

Timestep Collection Time: 2.22805
Timestep Consumption Time: 2.43301
PPO Batch Consumption Time: 0.27934
Total Iteration Time: 4.66106

Cumulative Model Updates: 56,396
Cumulative Timesteps: 470,448,004

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,653.76216
Policy Entropy: 3.38863
Value Function Loss: 0.00283

Mean KL Divergence: 0.01383
SB3 Clip Fraction: 0.13773
Policy Update Magnitude: 0.52368
Value Function Update Magnitude: 0.52850

Collected Steps per Second: 22,626.32026
Overall Steps per Second: 10,790.03166

Timestep Collection Time: 2.20982
Timestep Consumption Time: 2.42409
PPO Batch Consumption Time: 0.28198
Total Iteration Time: 4.63391

Cumulative Model Updates: 56,402
Cumulative Timesteps: 470,498,004

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 470498004...
Checkpoint 470498004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,343.28814
Policy Entropy: 3.40644
Value Function Loss: 0.00293

Mean KL Divergence: 0.01096
SB3 Clip Fraction: 0.11872
Policy Update Magnitude: 0.51828
Value Function Update Magnitude: 0.52178

Collected Steps per Second: 22,248.54006
Overall Steps per Second: 10,694.37292

Timestep Collection Time: 2.24833
Timestep Consumption Time: 2.42909
PPO Batch Consumption Time: 0.28229
Total Iteration Time: 4.67741

Cumulative Model Updates: 56,408
Cumulative Timesteps: 470,548,026

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,214.90173
Policy Entropy: 3.40433
Value Function Loss: 0.00297

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.11449
Policy Update Magnitude: 0.52757
Value Function Update Magnitude: 0.53958

Collected Steps per Second: 22,010.22786
Overall Steps per Second: 10,356.09933

Timestep Collection Time: 2.27185
Timestep Consumption Time: 2.55661
PPO Batch Consumption Time: 0.29716
Total Iteration Time: 4.82846

Cumulative Model Updates: 56,414
Cumulative Timesteps: 470,598,030

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 470598030...
Checkpoint 470598030 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,370.72658
Policy Entropy: 3.40345
Value Function Loss: 0.00307

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.11930
Policy Update Magnitude: 0.54284
Value Function Update Magnitude: 0.54580

Collected Steps per Second: 21,573.98960
Overall Steps per Second: 10,237.38211

Timestep Collection Time: 2.31890
Timestep Consumption Time: 2.56789
PPO Batch Consumption Time: 0.28683
Total Iteration Time: 4.88680

Cumulative Model Updates: 56,420
Cumulative Timesteps: 470,648,058

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,736.67006
Policy Entropy: 3.39464
Value Function Loss: 0.00321

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.10308
Policy Update Magnitude: 0.55071
Value Function Update Magnitude: 0.55933

Collected Steps per Second: 22,445.10801
Overall Steps per Second: 10,559.75816

Timestep Collection Time: 2.22890
Timestep Consumption Time: 2.50870
PPO Batch Consumption Time: 0.29163
Total Iteration Time: 4.73761

Cumulative Model Updates: 56,426
Cumulative Timesteps: 470,698,086

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 470698086...
Checkpoint 470698086 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 945.63506
Policy Entropy: 3.39599
Value Function Loss: 0.00314

Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.09349
Policy Update Magnitude: 0.55695
Value Function Update Magnitude: 0.58546

Collected Steps per Second: 22,396.91012
Overall Steps per Second: 10,630.43673

Timestep Collection Time: 2.23263
Timestep Consumption Time: 2.47122
PPO Batch Consumption Time: 0.28929
Total Iteration Time: 4.70385

Cumulative Model Updates: 56,432
Cumulative Timesteps: 470,748,090

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,348.97404
Policy Entropy: 3.39688
Value Function Loss: 0.00303

Mean KL Divergence: 0.00729
SB3 Clip Fraction: 0.08584
Policy Update Magnitude: 0.55816
Value Function Update Magnitude: 0.59497

Collected Steps per Second: 22,706.21728
Overall Steps per Second: 10,833.63815

Timestep Collection Time: 2.20327
Timestep Consumption Time: 2.41457
PPO Batch Consumption Time: 0.28125
Total Iteration Time: 4.61784

Cumulative Model Updates: 56,438
Cumulative Timesteps: 470,798,118

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 470798118...
Checkpoint 470798118 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,231.09607
Policy Entropy: 3.39641
Value Function Loss: 0.00292

Mean KL Divergence: 0.00715
SB3 Clip Fraction: 0.08237
Policy Update Magnitude: 0.55540
Value Function Update Magnitude: 0.59372

Collected Steps per Second: 22,592.04510
Overall Steps per Second: 10,729.83148

Timestep Collection Time: 2.21388
Timestep Consumption Time: 2.44752
PPO Batch Consumption Time: 0.28691
Total Iteration Time: 4.66140

Cumulative Model Updates: 56,444
Cumulative Timesteps: 470,848,134

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,298.67363
Policy Entropy: 3.39450
Value Function Loss: 0.00297

Mean KL Divergence: 0.00683
SB3 Clip Fraction: 0.07829
Policy Update Magnitude: 0.55113
Value Function Update Magnitude: 0.59490

Collected Steps per Second: 22,667.42590
Overall Steps per Second: 10,546.32303

Timestep Collection Time: 2.20590
Timestep Consumption Time: 2.53528
PPO Batch Consumption Time: 0.29557
Total Iteration Time: 4.74118

Cumulative Model Updates: 56,450
Cumulative Timesteps: 470,898,136

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 470898136...
Checkpoint 470898136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 998.82967
Policy Entropy: 3.38782
Value Function Loss: 0.00303

Mean KL Divergence: 0.00663
SB3 Clip Fraction: 0.07695
Policy Update Magnitude: 0.55226
Value Function Update Magnitude: 0.60150

Collected Steps per Second: 22,427.19190
Overall Steps per Second: 10,446.53113

Timestep Collection Time: 2.22979
Timestep Consumption Time: 2.55725
PPO Batch Consumption Time: 0.30501
Total Iteration Time: 4.78704

Cumulative Model Updates: 56,456
Cumulative Timesteps: 470,948,144

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,363.57086
Policy Entropy: 3.39782
Value Function Loss: 0.00293

Mean KL Divergence: 0.00715
SB3 Clip Fraction: 0.08378
Policy Update Magnitude: 0.55951
Value Function Update Magnitude: 0.58986

Collected Steps per Second: 22,366.35519
Overall Steps per Second: 10,527.16685

Timestep Collection Time: 2.23604
Timestep Consumption Time: 2.51472
PPO Batch Consumption Time: 0.29592
Total Iteration Time: 4.75076

Cumulative Model Updates: 56,462
Cumulative Timesteps: 470,998,156

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 470998156...
Checkpoint 470998156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,259.10853
Policy Entropy: 3.39663
Value Function Loss: 0.00292

Mean KL Divergence: 0.00691
SB3 Clip Fraction: 0.08051
Policy Update Magnitude: 0.56208
Value Function Update Magnitude: 0.57411

Collected Steps per Second: 22,498.65697
Overall Steps per Second: 10,666.27094

Timestep Collection Time: 2.22351
Timestep Consumption Time: 2.46660
PPO Batch Consumption Time: 0.28992
Total Iteration Time: 4.69011

Cumulative Model Updates: 56,468
Cumulative Timesteps: 471,048,182

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,134.54648
Policy Entropy: 3.39680
Value Function Loss: 0.00290

Mean KL Divergence: 0.00738
SB3 Clip Fraction: 0.08787
Policy Update Magnitude: 0.55797
Value Function Update Magnitude: 0.56105

Collected Steps per Second: 22,398.79833
Overall Steps per Second: 10,610.47133

Timestep Collection Time: 2.23235
Timestep Consumption Time: 2.48016
PPO Batch Consumption Time: 0.29068
Total Iteration Time: 4.71251

Cumulative Model Updates: 56,474
Cumulative Timesteps: 471,098,184

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 471098184...
Checkpoint 471098184 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 925.49015
Policy Entropy: 3.38801
Value Function Loss: 0.00311

Mean KL Divergence: 0.00741
SB3 Clip Fraction: 0.08602
Policy Update Magnitude: 0.55532
Value Function Update Magnitude: 0.55669

Collected Steps per Second: 22,591.89825
Overall Steps per Second: 10,635.42710

Timestep Collection Time: 2.21327
Timestep Consumption Time: 2.48819
PPO Batch Consumption Time: 0.29178
Total Iteration Time: 4.70146

Cumulative Model Updates: 56,480
Cumulative Timesteps: 471,148,186

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,252.28689
Policy Entropy: 3.37877
Value Function Loss: 0.00306

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.09399
Policy Update Magnitude: 0.55586
Value Function Update Magnitude: 0.57040

Collected Steps per Second: 21,098.37976
Overall Steps per Second: 10,199.95755

Timestep Collection Time: 2.37023
Timestep Consumption Time: 2.53254
PPO Batch Consumption Time: 0.30130
Total Iteration Time: 4.90277

Cumulative Model Updates: 56,486
Cumulative Timesteps: 471,198,194

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 471198194...
Checkpoint 471198194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,377.62072
Policy Entropy: 3.37359
Value Function Loss: 0.00309

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.10456
Policy Update Magnitude: 0.55020
Value Function Update Magnitude: 0.56824

Collected Steps per Second: 22,314.23155
Overall Steps per Second: 10,777.95451

Timestep Collection Time: 2.24144
Timestep Consumption Time: 2.39914
PPO Batch Consumption Time: 0.27897
Total Iteration Time: 4.64058

Cumulative Model Updates: 56,492
Cumulative Timesteps: 471,248,210

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,110.21651
Policy Entropy: 3.38542
Value Function Loss: 0.00294

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.10370
Policy Update Magnitude: 0.54502
Value Function Update Magnitude: 0.57082

Collected Steps per Second: 22,425.49086
Overall Steps per Second: 10,592.91804

Timestep Collection Time: 2.22961
Timestep Consumption Time: 2.49053
PPO Batch Consumption Time: 0.29191
Total Iteration Time: 4.72013

Cumulative Model Updates: 56,498
Cumulative Timesteps: 471,298,210

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 471298210...
Checkpoint 471298210 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 868.73620
Policy Entropy: 3.37578
Value Function Loss: 0.00301

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.09053
Policy Update Magnitude: 0.54281
Value Function Update Magnitude: 0.56694

Collected Steps per Second: 19,708.45516
Overall Steps per Second: 9,831.13236

Timestep Collection Time: 2.53749
Timestep Consumption Time: 2.54941
PPO Batch Consumption Time: 0.29590
Total Iteration Time: 5.08690

Cumulative Model Updates: 56,504
Cumulative Timesteps: 471,348,220

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,046.79055
Policy Entropy: 3.36880
Value Function Loss: 0.00300

Mean KL Divergence: 0.00766
SB3 Clip Fraction: 0.09081
Policy Update Magnitude: 0.54773
Value Function Update Magnitude: 0.57242

Collected Steps per Second: 20,856.90061
Overall Steps per Second: 10,158.65741

Timestep Collection Time: 2.39748
Timestep Consumption Time: 2.52482
PPO Batch Consumption Time: 0.29440
Total Iteration Time: 4.92230

Cumulative Model Updates: 56,510
Cumulative Timesteps: 471,398,224

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 471398224...
Checkpoint 471398224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,114.81645
Policy Entropy: 3.35171
Value Function Loss: 0.00310

Mean KL Divergence: 0.00733
SB3 Clip Fraction: 0.08592
Policy Update Magnitude: 0.54974
Value Function Update Magnitude: 0.56748

Collected Steps per Second: 21,527.42779
Overall Steps per Second: 10,213.16429

Timestep Collection Time: 2.32448
Timestep Consumption Time: 2.57508
PPO Batch Consumption Time: 0.30733
Total Iteration Time: 4.89956

Cumulative Model Updates: 56,516
Cumulative Timesteps: 471,448,264

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,419.83226
Policy Entropy: 3.36766
Value Function Loss: 0.00295

Mean KL Divergence: 0.00730
SB3 Clip Fraction: 0.08413
Policy Update Magnitude: 0.55266
Value Function Update Magnitude: 0.56393

Collected Steps per Second: 20,249.68758
Overall Steps per Second: 9,906.62837

Timestep Collection Time: 2.47006
Timestep Consumption Time: 2.57888
PPO Batch Consumption Time: 0.29769
Total Iteration Time: 5.04894

Cumulative Model Updates: 56,522
Cumulative Timesteps: 471,498,282

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 471498282...
Checkpoint 471498282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,458.32202
Policy Entropy: 3.36395
Value Function Loss: 0.00289

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.09569
Policy Update Magnitude: 0.54402
Value Function Update Magnitude: 0.54924

Collected Steps per Second: 22,250.25569
Overall Steps per Second: 10,342.22109

Timestep Collection Time: 2.24842
Timestep Consumption Time: 2.58884
PPO Batch Consumption Time: 0.30451
Total Iteration Time: 4.83726

Cumulative Model Updates: 56,528
Cumulative Timesteps: 471,548,310

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,922.63428
Policy Entropy: 3.37067
Value Function Loss: 0.00296

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.10988
Policy Update Magnitude: 0.53586
Value Function Update Magnitude: 0.55088

Collected Steps per Second: 22,650.40646
Overall Steps per Second: 10,519.19931

Timestep Collection Time: 2.20782
Timestep Consumption Time: 2.54615
PPO Batch Consumption Time: 0.30501
Total Iteration Time: 4.75397

Cumulative Model Updates: 56,534
Cumulative Timesteps: 471,598,318

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 471598318...
Checkpoint 471598318 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,239.81436
Policy Entropy: 3.37979
Value Function Loss: 0.00317

Mean KL Divergence: 0.00770
SB3 Clip Fraction: 0.09145
Policy Update Magnitude: 0.54297
Value Function Update Magnitude: 0.55647

Collected Steps per Second: 22,620.42659
Overall Steps per Second: 10,688.57863

Timestep Collection Time: 2.21119
Timestep Consumption Time: 2.46839
PPO Batch Consumption Time: 0.29022
Total Iteration Time: 4.67957

Cumulative Model Updates: 56,540
Cumulative Timesteps: 471,648,336

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,234.83122
Policy Entropy: 3.39334
Value Function Loss: 0.00308

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.11120
Policy Update Magnitude: 0.55806
Value Function Update Magnitude: 0.56627

Collected Steps per Second: 22,568.04538
Overall Steps per Second: 10,663.18968

Timestep Collection Time: 2.21614
Timestep Consumption Time: 2.47420
PPO Batch Consumption Time: 0.29168
Total Iteration Time: 4.69034

Cumulative Model Updates: 56,546
Cumulative Timesteps: 471,698,350

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 471698350...
Checkpoint 471698350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,533.75894
Policy Entropy: 3.40631
Value Function Loss: 0.00302

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.11271
Policy Update Magnitude: 0.55223
Value Function Update Magnitude: 0.56554

Collected Steps per Second: 22,601.65787
Overall Steps per Second: 10,584.11097

Timestep Collection Time: 2.21302
Timestep Consumption Time: 2.51274
PPO Batch Consumption Time: 0.29421
Total Iteration Time: 4.72576

Cumulative Model Updates: 56,552
Cumulative Timesteps: 471,748,368

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,991.49046
Policy Entropy: 3.38928
Value Function Loss: 0.00287

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.11875
Policy Update Magnitude: 0.54723
Value Function Update Magnitude: 0.56842

Collected Steps per Second: 22,717.70765
Overall Steps per Second: 10,836.47013

Timestep Collection Time: 2.20119
Timestep Consumption Time: 2.41341
PPO Batch Consumption Time: 0.27989
Total Iteration Time: 4.61460

Cumulative Model Updates: 56,558
Cumulative Timesteps: 471,798,374

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 471798374...
Checkpoint 471798374 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,925.40565
Policy Entropy: 3.37134
Value Function Loss: 0.00299

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.11127
Policy Update Magnitude: 0.54175
Value Function Update Magnitude: 0.55893

Collected Steps per Second: 22,631.06385
Overall Steps per Second: 10,659.55984

Timestep Collection Time: 2.21041
Timestep Consumption Time: 2.48246
PPO Batch Consumption Time: 0.29444
Total Iteration Time: 4.69288

Cumulative Model Updates: 56,564
Cumulative Timesteps: 471,848,398

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,268.47693
Policy Entropy: 3.37509
Value Function Loss: 0.00310

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.10508
Policy Update Magnitude: 0.54260
Value Function Update Magnitude: 0.53905

Collected Steps per Second: 21,979.54689
Overall Steps per Second: 10,362.60091

Timestep Collection Time: 2.27575
Timestep Consumption Time: 2.55122
PPO Batch Consumption Time: 0.30511
Total Iteration Time: 4.82697

Cumulative Model Updates: 56,570
Cumulative Timesteps: 471,898,418

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 471898418...
Checkpoint 471898418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,343.96854
Policy Entropy: 3.40185
Value Function Loss: 0.00321

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.09612
Policy Update Magnitude: 0.55336
Value Function Update Magnitude: 0.55296

Collected Steps per Second: 22,264.42883
Overall Steps per Second: 10,735.97182

Timestep Collection Time: 2.24609
Timestep Consumption Time: 2.41189
PPO Batch Consumption Time: 0.27959
Total Iteration Time: 4.65799

Cumulative Model Updates: 56,576
Cumulative Timesteps: 471,948,426

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 922.34190
Policy Entropy: 3.41469
Value Function Loss: 0.00320

Mean KL Divergence: 0.00707
SB3 Clip Fraction: 0.08264
Policy Update Magnitude: 0.55413
Value Function Update Magnitude: 0.56726

Collected Steps per Second: 22,824.25823
Overall Steps per Second: 10,876.05813

Timestep Collection Time: 2.19100
Timestep Consumption Time: 2.40699
PPO Batch Consumption Time: 0.27940
Total Iteration Time: 4.59799

Cumulative Model Updates: 56,582
Cumulative Timesteps: 471,998,434

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 471998434...
Checkpoint 471998434 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,540.10027
Policy Entropy: 3.42148
Value Function Loss: 0.00303

Mean KL Divergence: 0.00678
SB3 Clip Fraction: 0.07972
Policy Update Magnitude: 0.55909
Value Function Update Magnitude: 0.56795

Collected Steps per Second: 22,260.40634
Overall Steps per Second: 10,604.40328

Timestep Collection Time: 2.24695
Timestep Consumption Time: 2.46977
PPO Batch Consumption Time: 0.29028
Total Iteration Time: 4.71672

Cumulative Model Updates: 56,588
Cumulative Timesteps: 472,048,452

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,300.60065
Policy Entropy: 3.41494
Value Function Loss: 0.00302

Mean KL Divergence: 0.00633
SB3 Clip Fraction: 0.07531
Policy Update Magnitude: 0.56000
Value Function Update Magnitude: 0.56331

Collected Steps per Second: 22,587.48951
Overall Steps per Second: 10,657.04842

Timestep Collection Time: 2.21530
Timestep Consumption Time: 2.48000
PPO Batch Consumption Time: 0.29074
Total Iteration Time: 4.69530

Cumulative Model Updates: 56,594
Cumulative Timesteps: 472,098,490

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 472098490...
Checkpoint 472098490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 980.92930
Policy Entropy: 3.41211
Value Function Loss: 0.00300

Mean KL Divergence: 0.00687
SB3 Clip Fraction: 0.08220
Policy Update Magnitude: 0.56230
Value Function Update Magnitude: 0.57068

Collected Steps per Second: 22,505.99560
Overall Steps per Second: 10,642.82923

Timestep Collection Time: 2.22296
Timestep Consumption Time: 2.47785
PPO Batch Consumption Time: 0.29162
Total Iteration Time: 4.70082

Cumulative Model Updates: 56,600
Cumulative Timesteps: 472,148,520

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 932.80035
Policy Entropy: 3.40863
Value Function Loss: 0.00300

Mean KL Divergence: 0.00686
SB3 Clip Fraction: 0.08137
Policy Update Magnitude: 0.56503
Value Function Update Magnitude: 0.58366

Collected Steps per Second: 22,779.45820
Overall Steps per Second: 10,727.30916

Timestep Collection Time: 2.19601
Timestep Consumption Time: 2.46722
PPO Batch Consumption Time: 0.28806
Total Iteration Time: 4.66324

Cumulative Model Updates: 56,606
Cumulative Timesteps: 472,198,544

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 472198544...
Checkpoint 472198544 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,788.60502
Policy Entropy: 3.40584
Value Function Loss: 0.00290

Mean KL Divergence: 0.00646
SB3 Clip Fraction: 0.07636
Policy Update Magnitude: 0.56316
Value Function Update Magnitude: 0.57106

Collected Steps per Second: 22,159.59740
Overall Steps per Second: 10,519.86538

Timestep Collection Time: 2.25672
Timestep Consumption Time: 2.49695
PPO Batch Consumption Time: 0.29806
Total Iteration Time: 4.75367

Cumulative Model Updates: 56,612
Cumulative Timesteps: 472,248,552

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 934.10740
Policy Entropy: 3.40920
Value Function Loss: 0.00291

Mean KL Divergence: 0.00665
SB3 Clip Fraction: 0.07727
Policy Update Magnitude: 0.55222
Value Function Update Magnitude: 0.55206

Collected Steps per Second: 22,478.29874
Overall Steps per Second: 10,562.14872

Timestep Collection Time: 2.22446
Timestep Consumption Time: 2.50962
PPO Batch Consumption Time: 0.29243
Total Iteration Time: 4.73407

Cumulative Model Updates: 56,618
Cumulative Timesteps: 472,298,554

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 472298554...
Checkpoint 472298554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,053.85078
Policy Entropy: 3.40318
Value Function Loss: 0.00289

Mean KL Divergence: 0.00737
SB3 Clip Fraction: 0.08766
Policy Update Magnitude: 0.54688
Value Function Update Magnitude: 0.55633

Collected Steps per Second: 22,273.57224
Overall Steps per Second: 10,592.74122

Timestep Collection Time: 2.24598
Timestep Consumption Time: 2.47669
PPO Batch Consumption Time: 0.28804
Total Iteration Time: 4.72267

Cumulative Model Updates: 56,624
Cumulative Timesteps: 472,348,580

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,537.25910
Policy Entropy: 3.40517
Value Function Loss: 0.00293

Mean KL Divergence: 0.00702
SB3 Clip Fraction: 0.08237
Policy Update Magnitude: 0.55008
Value Function Update Magnitude: 0.56810

Collected Steps per Second: 22,551.46071
Overall Steps per Second: 10,667.98278

Timestep Collection Time: 2.21830
Timestep Consumption Time: 2.47105
PPO Batch Consumption Time: 0.29230
Total Iteration Time: 4.68936

Cumulative Model Updates: 56,630
Cumulative Timesteps: 472,398,606

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 472398606...
Checkpoint 472398606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,368.47466
Policy Entropy: 3.39747
Value Function Loss: 0.00313

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.09272
Policy Update Magnitude: 0.55819
Value Function Update Magnitude: 0.57777

Collected Steps per Second: 22,126.75509
Overall Steps per Second: 10,515.07670

Timestep Collection Time: 2.26088
Timestep Consumption Time: 2.49667
PPO Batch Consumption Time: 0.29526
Total Iteration Time: 4.75755

Cumulative Model Updates: 56,636
Cumulative Timesteps: 472,448,632

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,147.87620
Policy Entropy: 3.37870
Value Function Loss: 0.00314

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.11008
Policy Update Magnitude: 0.56509
Value Function Update Magnitude: 0.59807

Collected Steps per Second: 22,887.12261
Overall Steps per Second: 10,851.12465

Timestep Collection Time: 2.18525
Timestep Consumption Time: 2.42386
PPO Batch Consumption Time: 0.28182
Total Iteration Time: 4.60911

Cumulative Model Updates: 56,642
Cumulative Timesteps: 472,498,646

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 472498646...
Checkpoint 472498646 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,202.80883
Policy Entropy: 3.36012
Value Function Loss: 0.00319

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.10052
Policy Update Magnitude: 0.56873
Value Function Update Magnitude: 0.60584

Collected Steps per Second: 21,764.52017
Overall Steps per Second: 10,379.41732

Timestep Collection Time: 2.29732
Timestep Consumption Time: 2.51991
PPO Batch Consumption Time: 0.29220
Total Iteration Time: 4.81723

Cumulative Model Updates: 56,648
Cumulative Timesteps: 472,548,646

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 836.56981
Policy Entropy: 3.37166
Value Function Loss: 0.00316

Mean KL Divergence: 0.00725
SB3 Clip Fraction: 0.08684
Policy Update Magnitude: 0.57601
Value Function Update Magnitude: 0.59949

Collected Steps per Second: 23,122.26488
Overall Steps per Second: 10,738.61367

Timestep Collection Time: 2.16302
Timestep Consumption Time: 2.49437
PPO Batch Consumption Time: 0.29369
Total Iteration Time: 4.65740

Cumulative Model Updates: 56,654
Cumulative Timesteps: 472,598,660

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 472598660...
Checkpoint 472598660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,526.07675
Policy Entropy: 3.36641
Value Function Loss: 0.00328

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.09898
Policy Update Magnitude: 0.58117
Value Function Update Magnitude: 0.61433

Collected Steps per Second: 22,657.03741
Overall Steps per Second: 10,655.60777

Timestep Collection Time: 2.20700
Timestep Consumption Time: 2.48574
PPO Batch Consumption Time: 0.28940
Total Iteration Time: 4.69274

Cumulative Model Updates: 56,660
Cumulative Timesteps: 472,648,664

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,375.01459
Policy Entropy: 3.38322
Value Function Loss: 0.00324

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.10505
Policy Update Magnitude: 0.57901
Value Function Update Magnitude: 0.64123

Collected Steps per Second: 23,006.96581
Overall Steps per Second: 10,799.24124

Timestep Collection Time: 2.17369
Timestep Consumption Time: 2.45719
PPO Batch Consumption Time: 0.28147
Total Iteration Time: 4.63088

Cumulative Model Updates: 56,666
Cumulative Timesteps: 472,698,674

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 472698674...
Checkpoint 472698674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,486.10910
Policy Entropy: 3.37594
Value Function Loss: 0.00305

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.10391
Policy Update Magnitude: 0.57823
Value Function Update Magnitude: 0.63681

Collected Steps per Second: 22,486.48431
Overall Steps per Second: 10,735.22355

Timestep Collection Time: 2.22480
Timestep Consumption Time: 2.43537
PPO Batch Consumption Time: 0.28105
Total Iteration Time: 4.66017

Cumulative Model Updates: 56,672
Cumulative Timesteps: 472,748,702

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,547.75388
Policy Entropy: 3.39837
Value Function Loss: 0.00297

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.10684
Policy Update Magnitude: 0.56571
Value Function Update Magnitude: 0.62088

Collected Steps per Second: 22,611.37941
Overall Steps per Second: 10,699.71342

Timestep Collection Time: 2.21358
Timestep Consumption Time: 2.46431
PPO Batch Consumption Time: 0.28921
Total Iteration Time: 4.67788

Cumulative Model Updates: 56,678
Cumulative Timesteps: 472,798,754

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


Saving checkpoint 472798754...
Checkpoint 472798754 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,232.06227
Policy Entropy: 3.40755
Value Function Loss: 0.00309

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.11834
Policy Update Magnitude: 0.55322
Value Function Update Magnitude: 0.60244

Collected Steps per Second: 22,703.10043
Overall Steps per Second: 10,852.85775

Timestep Collection Time: 2.20331
Timestep Consumption Time: 2.40580
PPO Batch Consumption Time: 0.28083
Total Iteration Time: 4.60911

Cumulative Model Updates: 56,684
Cumulative Timesteps: 472,848,776

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,976.70543
Policy Entropy: 3.41629
Value Function Loss: 0.00310

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.10141
Policy Update Magnitude: 0.55036
Value Function Update Magnitude: 0.58818

Collected Steps per Second: 22,605.52563
Overall Steps per Second: 10,561.55913

Timestep Collection Time: 2.21318
Timestep Consumption Time: 2.52381
PPO Batch Consumption Time: 0.29263
Total Iteration Time: 4.73699

Cumulative Model Updates: 56,690
Cumulative Timesteps: 472,898,806

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 472898806...
Checkpoint 472898806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,688.55272
Policy Entropy: 3.40399
Value Function Loss: 0.00336

Mean KL Divergence: 0.00738
SB3 Clip Fraction: 0.08696
Policy Update Magnitude: 0.56049
Value Function Update Magnitude: 0.59794

Collected Steps per Second: 22,311.82866
Overall Steps per Second: 10,569.01706

Timestep Collection Time: 2.24123
Timestep Consumption Time: 2.49014
PPO Batch Consumption Time: 0.29095
Total Iteration Time: 4.73138

Cumulative Model Updates: 56,696
Cumulative Timesteps: 472,948,812

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,353.69814
Policy Entropy: 3.40935
Value Function Loss: 0.00331

Mean KL Divergence: 0.00752
SB3 Clip Fraction: 0.09033
Policy Update Magnitude: 0.57196
Value Function Update Magnitude: 0.62641

Collected Steps per Second: 22,892.96858
Overall Steps per Second: 10,850.73324

Timestep Collection Time: 2.18486
Timestep Consumption Time: 2.42478
PPO Batch Consumption Time: 0.28171
Total Iteration Time: 4.60964

Cumulative Model Updates: 56,702
Cumulative Timesteps: 472,998,830

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 472998830...
Checkpoint 472998830 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,487.59761
Policy Entropy: 3.40024
Value Function Loss: 0.00341

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.09638
Policy Update Magnitude: 0.57389
Value Function Update Magnitude: 0.63723

Collected Steps per Second: 22,628.36439
Overall Steps per Second: 10,679.03775

Timestep Collection Time: 2.21006
Timestep Consumption Time: 2.47295
PPO Batch Consumption Time: 0.28607
Total Iteration Time: 4.68301

Cumulative Model Updates: 56,708
Cumulative Timesteps: 473,048,840

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,969.76614
Policy Entropy: 3.40292
Value Function Loss: 0.00332

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.10467
Policy Update Magnitude: 0.57493
Value Function Update Magnitude: 0.64095

Collected Steps per Second: 22,791.05659
Overall Steps per Second: 10,649.56877

Timestep Collection Time: 2.19498
Timestep Consumption Time: 2.50248
PPO Batch Consumption Time: 0.29039
Total Iteration Time: 4.69747

Cumulative Model Updates: 56,714
Cumulative Timesteps: 473,098,866

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 473098866...
Checkpoint 473098866 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,050.23520
Policy Entropy: 3.39916
Value Function Loss: 0.00308

Mean KL Divergence: 0.01119
SB3 Clip Fraction: 0.13000
Policy Update Magnitude: 0.56728
Value Function Update Magnitude: 0.61938

Collected Steps per Second: 21,268.12932
Overall Steps per Second: 10,360.15702

Timestep Collection Time: 2.35197
Timestep Consumption Time: 2.47634
PPO Batch Consumption Time: 0.28937
Total Iteration Time: 4.82831

Cumulative Model Updates: 56,720
Cumulative Timesteps: 473,148,888

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 836.75341
Policy Entropy: 3.41051
Value Function Loss: 0.00302

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.10955
Policy Update Magnitude: 0.55938
Value Function Update Magnitude: 0.60270

Collected Steps per Second: 21,730.64260
Overall Steps per Second: 10,545.22340

Timestep Collection Time: 2.30099
Timestep Consumption Time: 2.44068
PPO Batch Consumption Time: 0.28403
Total Iteration Time: 4.74167

Cumulative Model Updates: 56,726
Cumulative Timesteps: 473,198,890

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 473198890...
Checkpoint 473198890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,319.28089
Policy Entropy: 3.43408
Value Function Loss: 0.00289

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.09390
Policy Update Magnitude: 0.56083
Value Function Update Magnitude: 0.60336

Collected Steps per Second: 22,377.22915
Overall Steps per Second: 10,670.70959

Timestep Collection Time: 2.23504
Timestep Consumption Time: 2.45200
PPO Batch Consumption Time: 0.28750
Total Iteration Time: 4.68704

Cumulative Model Updates: 56,732
Cumulative Timesteps: 473,248,904

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,177.80770
Policy Entropy: 3.43114
Value Function Loss: 0.00299

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.10919
Policy Update Magnitude: 0.55877
Value Function Update Magnitude: 0.60017

Collected Steps per Second: 22,826.40551
Overall Steps per Second: 10,828.57451

Timestep Collection Time: 2.19132
Timestep Consumption Time: 2.42794
PPO Batch Consumption Time: 0.28184
Total Iteration Time: 4.61926

Cumulative Model Updates: 56,738
Cumulative Timesteps: 473,298,924

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 473298924...
Checkpoint 473298924 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,582.90152
Policy Entropy: 3.42030
Value Function Loss: 0.00300

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.09111
Policy Update Magnitude: 0.55769
Value Function Update Magnitude: 0.61430

Collected Steps per Second: 22,353.91699
Overall Steps per Second: 10,757.56616

Timestep Collection Time: 2.23692
Timestep Consumption Time: 2.41134
PPO Batch Consumption Time: 0.27951
Total Iteration Time: 4.64826

Cumulative Model Updates: 56,744
Cumulative Timesteps: 473,348,928

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,816.12356
Policy Entropy: 3.40768
Value Function Loss: 0.00321

Mean KL Divergence: 0.00736
SB3 Clip Fraction: 0.08587
Policy Update Magnitude: 0.56776
Value Function Update Magnitude: 0.65131

Collected Steps per Second: 19,149.93210
Overall Steps per Second: 9,645.85075

Timestep Collection Time: 2.61254
Timestep Consumption Time: 2.57414
PPO Batch Consumption Time: 0.29921
Total Iteration Time: 5.18669

Cumulative Model Updates: 56,750
Cumulative Timesteps: 473,398,958

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 473398958...
Checkpoint 473398958 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,585.28346
Policy Entropy: 3.40976
Value Function Loss: 0.00302

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.09080
Policy Update Magnitude: 0.57813
Value Function Update Magnitude: 0.65696

Collected Steps per Second: 20,472.02840
Overall Steps per Second: 10,114.32699

Timestep Collection Time: 2.44421
Timestep Consumption Time: 2.50303
PPO Batch Consumption Time: 0.28675
Total Iteration Time: 4.94724

Cumulative Model Updates: 56,756
Cumulative Timesteps: 473,448,996

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,267.51694
Policy Entropy: 3.42432
Value Function Loss: 0.00298

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.10660
Policy Update Magnitude: 0.56291
Value Function Update Magnitude: 0.61386

Collected Steps per Second: 21,599.61873
Overall Steps per Second: 10,414.16011

Timestep Collection Time: 2.31606
Timestep Consumption Time: 2.48759
PPO Batch Consumption Time: 0.28810
Total Iteration Time: 4.80365

Cumulative Model Updates: 56,762
Cumulative Timesteps: 473,499,022

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 473499022...
Checkpoint 473499022 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,283.60109
Policy Entropy: 3.43593
Value Function Loss: 0.00290

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.10055
Policy Update Magnitude: 0.55643
Value Function Update Magnitude: 0.60892

Collected Steps per Second: 21,682.69791
Overall Steps per Second: 10,304.36965

Timestep Collection Time: 2.30599
Timestep Consumption Time: 2.54632
PPO Batch Consumption Time: 0.30114
Total Iteration Time: 4.85231

Cumulative Model Updates: 56,768
Cumulative Timesteps: 473,549,022

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,327.69850
Policy Entropy: 3.43412
Value Function Loss: 0.00307

Mean KL Divergence: 0.00723
SB3 Clip Fraction: 0.08467
Policy Update Magnitude: 0.56554
Value Function Update Magnitude: 0.62555

Collected Steps per Second: 21,997.65229
Overall Steps per Second: 10,404.08161

Timestep Collection Time: 2.27379
Timestep Consumption Time: 2.53375
PPO Batch Consumption Time: 0.29928
Total Iteration Time: 4.80754

Cumulative Model Updates: 56,774
Cumulative Timesteps: 473,599,040

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 473599040...
Checkpoint 473599040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,546.84629
Policy Entropy: 3.43667
Value Function Loss: 0.00316

Mean KL Divergence: 0.00746
SB3 Clip Fraction: 0.08682
Policy Update Magnitude: 0.57109
Value Function Update Magnitude: 0.64068

Collected Steps per Second: 17,748.94251
Overall Steps per Second: 9,322.32573

Timestep Collection Time: 2.81865
Timestep Consumption Time: 2.54783
PPO Batch Consumption Time: 0.28185
Total Iteration Time: 5.36647

Cumulative Model Updates: 56,780
Cumulative Timesteps: 473,649,068

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,638.03947
Policy Entropy: 3.43242
Value Function Loss: 0.00330

Mean KL Divergence: 0.00705
SB3 Clip Fraction: 0.08221
Policy Update Magnitude: 0.58355
Value Function Update Magnitude: 0.68673

Collected Steps per Second: 18,214.03675
Overall Steps per Second: 8,905.03057

Timestep Collection Time: 2.74590
Timestep Consumption Time: 2.87047
PPO Batch Consumption Time: 0.33974
Total Iteration Time: 5.61638

Cumulative Model Updates: 56,786
Cumulative Timesteps: 473,699,082

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 473699082...
Checkpoint 473699082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,318.71866
Policy Entropy: 3.43576
Value Function Loss: 0.00318

Mean KL Divergence: 0.00772
SB3 Clip Fraction: 0.08983
Policy Update Magnitude: 0.59079
Value Function Update Magnitude: 0.70990

Collected Steps per Second: 19,287.30094
Overall Steps per Second: 9,119.37421

Timestep Collection Time: 2.59269
Timestep Consumption Time: 2.89080
PPO Batch Consumption Time: 0.34780
Total Iteration Time: 5.48349

Cumulative Model Updates: 56,792
Cumulative Timesteps: 473,749,088

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,161.81082
Policy Entropy: 3.43263
Value Function Loss: 0.00303

Mean KL Divergence: 0.00750
SB3 Clip Fraction: 0.08938
Policy Update Magnitude: 0.58323
Value Function Update Magnitude: 0.68718

Collected Steps per Second: 19,169.66290
Overall Steps per Second: 9,507.20253

Timestep Collection Time: 2.60891
Timestep Consumption Time: 2.65152
PPO Batch Consumption Time: 0.30844
Total Iteration Time: 5.26043

Cumulative Model Updates: 56,798
Cumulative Timesteps: 473,799,100

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 473799100...
Checkpoint 473799100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,195.66641
Policy Entropy: 3.43658
Value Function Loss: 0.00288

Mean KL Divergence: 0.00705
SB3 Clip Fraction: 0.08431
Policy Update Magnitude: 0.57241
Value Function Update Magnitude: 0.65842

Collected Steps per Second: 19,699.60330
Overall Steps per Second: 9,664.79052

Timestep Collection Time: 2.53904
Timestep Consumption Time: 2.63624
PPO Batch Consumption Time: 0.31219
Total Iteration Time: 5.17528

Cumulative Model Updates: 56,804
Cumulative Timesteps: 473,849,118

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,496.81804
Policy Entropy: 3.43541
Value Function Loss: 0.00294

Mean KL Divergence: 0.00689
SB3 Clip Fraction: 0.08120
Policy Update Magnitude: 0.56605
Value Function Update Magnitude: 0.65819

Collected Steps per Second: 20,061.01192
Overall Steps per Second: 10,133.10127

Timestep Collection Time: 2.49250
Timestep Consumption Time: 2.44202
PPO Batch Consumption Time: 0.29072
Total Iteration Time: 4.93452

Cumulative Model Updates: 56,810
Cumulative Timesteps: 473,899,120

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 473899120...
Checkpoint 473899120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 893.68620
Policy Entropy: 3.43363
Value Function Loss: 0.00288

Mean KL Divergence: 0.00697
SB3 Clip Fraction: 0.08227
Policy Update Magnitude: 0.56455
Value Function Update Magnitude: 0.62545

Collected Steps per Second: 19,467.49441
Overall Steps per Second: 9,730.01115

Timestep Collection Time: 2.56972
Timestep Consumption Time: 2.57169
PPO Batch Consumption Time: 0.29108
Total Iteration Time: 5.14141

Cumulative Model Updates: 56,816
Cumulative Timesteps: 473,949,146

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,286.82940
Policy Entropy: 3.41809
Value Function Loss: 0.00299

Mean KL Divergence: 0.00783
SB3 Clip Fraction: 0.09285
Policy Update Magnitude: 0.56024
Value Function Update Magnitude: 0.60425

Collected Steps per Second: 18,874.58638
Overall Steps per Second: 9,250.29105

Timestep Collection Time: 2.65097
Timestep Consumption Time: 2.75816
PPO Batch Consumption Time: 0.31858
Total Iteration Time: 5.40913

Cumulative Model Updates: 56,822
Cumulative Timesteps: 473,999,182

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 473999182...
Checkpoint 473999182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,849.59334
Policy Entropy: 3.41865
Value Function Loss: 0.00308

Mean KL Divergence: 0.00751
SB3 Clip Fraction: 0.08707
Policy Update Magnitude: 0.55773
Value Function Update Magnitude: 0.60844

Collected Steps per Second: 20,993.54209
Overall Steps per Second: 10,421.87874

Timestep Collection Time: 2.38226
Timestep Consumption Time: 2.41649
PPO Batch Consumption Time: 0.28386
Total Iteration Time: 4.79875

Cumulative Model Updates: 56,828
Cumulative Timesteps: 474,049,194

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 962.91715
Policy Entropy: 3.41391
Value Function Loss: 0.00300

Mean KL Divergence: 0.00722
SB3 Clip Fraction: 0.08355
Policy Update Magnitude: 0.56090
Value Function Update Magnitude: 0.61262

Collected Steps per Second: 19,826.64152
Overall Steps per Second: 9,795.57057

Timestep Collection Time: 2.52337
Timestep Consumption Time: 2.58404
PPO Batch Consumption Time: 0.30240
Total Iteration Time: 5.10741

Cumulative Model Updates: 56,834
Cumulative Timesteps: 474,099,224

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 474099224...
Checkpoint 474099224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 750.81721
Policy Entropy: 3.42500
Value Function Loss: 0.00303

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.09204
Policy Update Magnitude: 0.55952
Value Function Update Magnitude: 0.61522

Collected Steps per Second: 19,354.22449
Overall Steps per Second: 9,488.31010

Timestep Collection Time: 2.58393
Timestep Consumption Time: 2.68676
PPO Batch Consumption Time: 0.32172
Total Iteration Time: 5.27070

Cumulative Model Updates: 56,840
Cumulative Timesteps: 474,149,234

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 989.49459
Policy Entropy: 3.41428
Value Function Loss: 0.00289

Mean KL Divergence: 0.00753
SB3 Clip Fraction: 0.08629
Policy Update Magnitude: 0.55073
Value Function Update Magnitude: 0.60788

Collected Steps per Second: 19,281.84571
Overall Steps per Second: 9,107.62220

Timestep Collection Time: 2.59374
Timestep Consumption Time: 2.89749
PPO Batch Consumption Time: 0.34818
Total Iteration Time: 5.49122

Cumulative Model Updates: 56,846
Cumulative Timesteps: 474,199,246

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 474199246...
Checkpoint 474199246 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,069.28696
Policy Entropy: 3.41015
Value Function Loss: 0.00313

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.09580
Policy Update Magnitude: 0.55902
Value Function Update Magnitude: 0.60364

Collected Steps per Second: 20,254.03457
Overall Steps per Second: 9,892.03239

Timestep Collection Time: 2.46874
Timestep Consumption Time: 2.58603
PPO Batch Consumption Time: 0.29615
Total Iteration Time: 5.05478

Cumulative Model Updates: 56,852
Cumulative Timesteps: 474,249,248

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 949.11705
Policy Entropy: 3.40333
Value Function Loss: 0.00333

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.10391
Policy Update Magnitude: 0.56860
Value Function Update Magnitude: 0.61940

Collected Steps per Second: 21,844.82255
Overall Steps per Second: 10,206.01857

Timestep Collection Time: 2.29025
Timestep Consumption Time: 2.61176
PPO Batch Consumption Time: 0.30085
Total Iteration Time: 4.90201

Cumulative Model Updates: 56,858
Cumulative Timesteps: 474,299,278

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 474299278...
Checkpoint 474299278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,268.70506
Policy Entropy: 3.41196
Value Function Loss: 0.00331

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.10499
Policy Update Magnitude: 0.57762
Value Function Update Magnitude: 0.61455

Collected Steps per Second: 20,665.27474
Overall Steps per Second: 9,891.98451

Timestep Collection Time: 2.42000
Timestep Consumption Time: 2.63561
PPO Batch Consumption Time: 0.30464
Total Iteration Time: 5.05561

Cumulative Model Updates: 56,864
Cumulative Timesteps: 474,349,288

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,040.06016
Policy Entropy: 3.40560
Value Function Loss: 0.00335

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.09811
Policy Update Magnitude: 0.58738
Value Function Update Magnitude: 0.61726

Collected Steps per Second: 20,112.45572
Overall Steps per Second: 10,008.14630

Timestep Collection Time: 2.48692
Timestep Consumption Time: 2.51081
PPO Batch Consumption Time: 0.28631
Total Iteration Time: 4.99773

Cumulative Model Updates: 56,870
Cumulative Timesteps: 474,399,306

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 474399306...
Checkpoint 474399306 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 839.05137
Policy Entropy: 3.40928
Value Function Loss: 0.00314

Mean KL Divergence: 0.00738
SB3 Clip Fraction: 0.08654
Policy Update Magnitude: 0.58721
Value Function Update Magnitude: 0.62382

Collected Steps per Second: 18,260.97079
Overall Steps per Second: 9,335.61735

Timestep Collection Time: 2.73874
Timestep Consumption Time: 2.61838
PPO Batch Consumption Time: 0.31271
Total Iteration Time: 5.35712

Cumulative Model Updates: 56,876
Cumulative Timesteps: 474,449,318

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,162.59102
Policy Entropy: 3.40920
Value Function Loss: 0.00307

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.08907
Policy Update Magnitude: 0.57884
Value Function Update Magnitude: 0.63064

Collected Steps per Second: 18,189.57244
Overall Steps per Second: 9,409.64185

Timestep Collection Time: 2.74993
Timestep Consumption Time: 2.56590
PPO Batch Consumption Time: 0.29425
Total Iteration Time: 5.31582

Cumulative Model Updates: 56,882
Cumulative Timesteps: 474,499,338

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 474499338...
Checkpoint 474499338 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 631.44555
Policy Entropy: 3.40939
Value Function Loss: 0.00307

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.11432
Policy Update Magnitude: 0.56263
Value Function Update Magnitude: 0.62663

Collected Steps per Second: 19,822.07352
Overall Steps per Second: 9,899.18264

Timestep Collection Time: 2.52446
Timestep Consumption Time: 2.53050
PPO Batch Consumption Time: 0.29666
Total Iteration Time: 5.05496

Cumulative Model Updates: 56,888
Cumulative Timesteps: 474,549,378

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,575.19513
Policy Entropy: 3.41721
Value Function Loss: 0.00323

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.09790
Policy Update Magnitude: 0.56611
Value Function Update Magnitude: 0.63253

Collected Steps per Second: 21,719.42431
Overall Steps per Second: 10,523.15207

Timestep Collection Time: 2.30264
Timestep Consumption Time: 2.44993
PPO Batch Consumption Time: 0.28366
Total Iteration Time: 4.75257

Cumulative Model Updates: 56,894
Cumulative Timesteps: 474,599,390

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 474599390...
Checkpoint 474599390 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,772.27166
Policy Entropy: 3.40980
Value Function Loss: 0.00331

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.11703
Policy Update Magnitude: 0.57281
Value Function Update Magnitude: 0.63744

Collected Steps per Second: 21,402.90064
Overall Steps per Second: 10,359.20623

Timestep Collection Time: 2.33809
Timestep Consumption Time: 2.49258
PPO Batch Consumption Time: 0.29278
Total Iteration Time: 4.83068

Cumulative Model Updates: 56,900
Cumulative Timesteps: 474,649,432

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,529.77272
Policy Entropy: 3.41267
Value Function Loss: 0.00329

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.10740
Policy Update Magnitude: 0.57215
Value Function Update Magnitude: 0.64940

Collected Steps per Second: 20,356.89724
Overall Steps per Second: 9,591.01847

Timestep Collection Time: 2.45725
Timestep Consumption Time: 2.75825
PPO Batch Consumption Time: 0.33409
Total Iteration Time: 5.21550

Cumulative Model Updates: 56,906
Cumulative Timesteps: 474,699,454

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 474699454...
Checkpoint 474699454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,538.93407
Policy Entropy: 3.41397
Value Function Loss: 0.00327

Mean KL Divergence: 0.00746
SB3 Clip Fraction: 0.08655
Policy Update Magnitude: 0.57757
Value Function Update Magnitude: 0.66195

Collected Steps per Second: 17,146.61960
Overall Steps per Second: 9,138.30644

Timestep Collection Time: 2.91754
Timestep Consumption Time: 2.55678
PPO Batch Consumption Time: 0.29636
Total Iteration Time: 5.47432

Cumulative Model Updates: 56,912
Cumulative Timesteps: 474,749,480

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 912.10534
Policy Entropy: 3.42136
Value Function Loss: 0.00324

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.10883
Policy Update Magnitude: 0.57797
Value Function Update Magnitude: 0.64948

Collected Steps per Second: 19,938.28232
Overall Steps per Second: 9,924.15076

Timestep Collection Time: 2.50784
Timestep Consumption Time: 2.53058
PPO Batch Consumption Time: 0.30860
Total Iteration Time: 5.03842

Cumulative Model Updates: 56,918
Cumulative Timesteps: 474,799,482

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 474799482...
Checkpoint 474799482 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 931.17150
Policy Entropy: 3.42645
Value Function Loss: 0.00326

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.09751
Policy Update Magnitude: 0.58260
Value Function Update Magnitude: 0.65427

Collected Steps per Second: 20,464.33696
Overall Steps per Second: 9,821.05215

Timestep Collection Time: 2.44435
Timestep Consumption Time: 2.64899
PPO Batch Consumption Time: 0.31993
Total Iteration Time: 5.09334

Cumulative Model Updates: 56,924
Cumulative Timesteps: 474,849,504

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,789.61325
Policy Entropy: 3.41357
Value Function Loss: 0.00310

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.09966
Policy Update Magnitude: 0.58170
Value Function Update Magnitude: 0.65013

Collected Steps per Second: 19,368.70821
Overall Steps per Second: 9,258.14423

Timestep Collection Time: 2.58241
Timestep Consumption Time: 2.82018
PPO Batch Consumption Time: 0.33465
Total Iteration Time: 5.40259

Cumulative Model Updates: 56,930
Cumulative Timesteps: 474,899,522

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 474899522...
Checkpoint 474899522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,190.31537
Policy Entropy: 3.40581
Value Function Loss: 0.00310

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.09431
Policy Update Magnitude: 0.57360
Value Function Update Magnitude: 0.64134

Collected Steps per Second: 18,062.42554
Overall Steps per Second: 9,439.83660

Timestep Collection Time: 2.76940
Timestep Consumption Time: 2.52964
PPO Batch Consumption Time: 0.29233
Total Iteration Time: 5.29903

Cumulative Model Updates: 56,936
Cumulative Timesteps: 474,949,544

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,472.60031
Policy Entropy: 3.39298
Value Function Loss: 0.00280

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.09656
Policy Update Magnitude: 0.55889
Value Function Update Magnitude: 0.62357

Collected Steps per Second: 20,072.73226
Overall Steps per Second: 9,655.61032

Timestep Collection Time: 2.49224
Timestep Consumption Time: 2.68879
PPO Batch Consumption Time: 0.30797
Total Iteration Time: 5.18103

Cumulative Model Updates: 56,942
Cumulative Timesteps: 474,999,570

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 474999570...
Checkpoint 474999570 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,929.93706
Policy Entropy: 3.39016
Value Function Loss: 0.00289

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.10259
Policy Update Magnitude: 0.55697
Value Function Update Magnitude: 0.59565

Collected Steps per Second: 21,066.32866
Overall Steps per Second: 10,318.91844

Timestep Collection Time: 2.37469
Timestep Consumption Time: 2.47330
PPO Batch Consumption Time: 0.28510
Total Iteration Time: 4.84799

Cumulative Model Updates: 56,948
Cumulative Timesteps: 475,049,596

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,674.89778
Policy Entropy: 3.39871
Value Function Loss: 0.00287

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.10395
Policy Update Magnitude: 0.55723
Value Function Update Magnitude: 0.59421

Collected Steps per Second: 21,518.26807
Overall Steps per Second: 10,340.66185

Timestep Collection Time: 2.32407
Timestep Consumption Time: 2.51218
PPO Batch Consumption Time: 0.28874
Total Iteration Time: 4.83625

Cumulative Model Updates: 56,954
Cumulative Timesteps: 475,099,606

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 475099606...
Checkpoint 475099606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,536.44049
Policy Entropy: 3.41438
Value Function Loss: 0.00310

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.10419
Policy Update Magnitude: 0.55426
Value Function Update Magnitude: 0.60986

Collected Steps per Second: 19,989.59502
Overall Steps per Second: 9,810.40124

Timestep Collection Time: 2.50130
Timestep Consumption Time: 2.59533
PPO Batch Consumption Time: 0.29496
Total Iteration Time: 5.09663

Cumulative Model Updates: 56,960
Cumulative Timesteps: 475,149,606

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,933.41428
Policy Entropy: 3.41755
Value Function Loss: 0.00316

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.09018
Policy Update Magnitude: 0.56591
Value Function Update Magnitude: 0.61866

Collected Steps per Second: 19,923.16115
Overall Steps per Second: 9,847.60412

Timestep Collection Time: 2.51034
Timestep Consumption Time: 2.56845
PPO Batch Consumption Time: 0.29490
Total Iteration Time: 5.07880

Cumulative Model Updates: 56,966
Cumulative Timesteps: 475,199,620

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 475199620...
Checkpoint 475199620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 888.93826
Policy Entropy: 3.40653
Value Function Loss: 0.00309

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.08644
Policy Update Magnitude: 0.57462
Value Function Update Magnitude: 0.63267

Collected Steps per Second: 21,702.66944
Overall Steps per Second: 10,444.83796

Timestep Collection Time: 2.30479
Timestep Consumption Time: 2.48418
PPO Batch Consumption Time: 0.28572
Total Iteration Time: 4.78897

Cumulative Model Updates: 56,972
Cumulative Timesteps: 475,249,640

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 973.71434
Policy Entropy: 3.39008
Value Function Loss: 0.00311

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.09245
Policy Update Magnitude: 0.58100
Value Function Update Magnitude: 0.62031

Collected Steps per Second: 21,734.76986
Overall Steps per Second: 9,930.34625

Timestep Collection Time: 2.30175
Timestep Consumption Time: 2.73614
PPO Batch Consumption Time: 0.32064
Total Iteration Time: 5.03789

Cumulative Model Updates: 56,978
Cumulative Timesteps: 475,299,668

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 475299668...
Checkpoint 475299668 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 893.89067
Policy Entropy: 3.38784
Value Function Loss: 0.00324

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.09581
Policy Update Magnitude: 0.58383
Value Function Update Magnitude: 0.62977

Collected Steps per Second: 21,922.53919
Overall Steps per Second: 10,346.45932

Timestep Collection Time: 2.28167
Timestep Consumption Time: 2.55283
PPO Batch Consumption Time: 0.29906
Total Iteration Time: 4.83450

Cumulative Model Updates: 56,984
Cumulative Timesteps: 475,349,688

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,070.01005
Policy Entropy: 3.38702
Value Function Loss: 0.00323

Mean KL Divergence: 0.00732
SB3 Clip Fraction: 0.08659
Policy Update Magnitude: 0.58967
Value Function Update Magnitude: 0.64545

Collected Steps per Second: 19,407.62505
Overall Steps per Second: 9,642.71478

Timestep Collection Time: 2.57693
Timestep Consumption Time: 2.60958
PPO Batch Consumption Time: 0.29573
Total Iteration Time: 5.18651

Cumulative Model Updates: 56,990
Cumulative Timesteps: 475,399,700

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 475399700...
Checkpoint 475399700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,614.32751
Policy Entropy: 3.38999
Value Function Loss: 0.00315

Mean KL Divergence: 0.00689
SB3 Clip Fraction: 0.08036
Policy Update Magnitude: 0.58971
Value Function Update Magnitude: 0.63807

Collected Steps per Second: 21,174.64129
Overall Steps per Second: 10,459.87932

Timestep Collection Time: 2.36169
Timestep Consumption Time: 2.41924
PPO Batch Consumption Time: 0.28723
Total Iteration Time: 4.78093

Cumulative Model Updates: 56,996
Cumulative Timesteps: 475,449,708

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,296.95283
Policy Entropy: 3.36728
Value Function Loss: 0.00312

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.09599
Policy Update Magnitude: 0.58418
Value Function Update Magnitude: 0.62819

Collected Steps per Second: 20,867.11478
Overall Steps per Second: 10,340.46856

Timestep Collection Time: 2.39659
Timestep Consumption Time: 2.43974
PPO Batch Consumption Time: 0.28401
Total Iteration Time: 4.83634

Cumulative Model Updates: 57,002
Cumulative Timesteps: 475,499,718

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 475499718...
Checkpoint 475499718 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,533.68048
Policy Entropy: 3.37313
Value Function Loss: 0.00317

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.10683
Policy Update Magnitude: 0.58359
Value Function Update Magnitude: 0.64577

Collected Steps per Second: 22,008.27343
Overall Steps per Second: 10,632.00518

Timestep Collection Time: 2.27224
Timestep Consumption Time: 2.43130
PPO Batch Consumption Time: 0.28264
Total Iteration Time: 4.70353

Cumulative Model Updates: 57,008
Cumulative Timesteps: 475,549,726

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,645.13410
Policy Entropy: 3.38419
Value Function Loss: 0.00318

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.10046
Policy Update Magnitude: 0.58691
Value Function Update Magnitude: 0.64497

Collected Steps per Second: 22,576.85174
Overall Steps per Second: 10,640.00240

Timestep Collection Time: 2.21572
Timestep Consumption Time: 2.48578
PPO Batch Consumption Time: 0.29281
Total Iteration Time: 4.70150

Cumulative Model Updates: 57,014
Cumulative Timesteps: 475,599,750

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 475599750...
Checkpoint 475599750 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,861.52428
Policy Entropy: 3.38837
Value Function Loss: 0.00326

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.10775
Policy Update Magnitude: 0.59026
Value Function Update Magnitude: 0.63538

Collected Steps per Second: 22,319.00563
Overall Steps per Second: 10,580.35397

Timestep Collection Time: 2.24141
Timestep Consumption Time: 2.48679
PPO Batch Consumption Time: 0.29528
Total Iteration Time: 4.72820

Cumulative Model Updates: 57,020
Cumulative Timesteps: 475,649,776

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 963.00317
Policy Entropy: 3.39635
Value Function Loss: 0.00337

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.10267
Policy Update Magnitude: 0.59389
Value Function Update Magnitude: 0.64711

Collected Steps per Second: 22,152.84604
Overall Steps per Second: 10,561.84343

Timestep Collection Time: 2.25723
Timestep Consumption Time: 2.47717
PPO Batch Consumption Time: 0.29141
Total Iteration Time: 4.73440

Cumulative Model Updates: 57,026
Cumulative Timesteps: 475,699,780

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 475699780...
Checkpoint 475699780 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,310.64826
Policy Entropy: 3.39033
Value Function Loss: 0.00326

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.09805
Policy Update Magnitude: 0.59455
Value Function Update Magnitude: 0.65261

Collected Steps per Second: 22,195.56304
Overall Steps per Second: 10,434.33689

Timestep Collection Time: 2.25288
Timestep Consumption Time: 2.53937
PPO Batch Consumption Time: 0.29498
Total Iteration Time: 4.79225

Cumulative Model Updates: 57,032
Cumulative Timesteps: 475,749,784

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,136.99345
Policy Entropy: 3.37984
Value Function Loss: 0.00322

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.10915
Policy Update Magnitude: 0.58856
Value Function Update Magnitude: 0.66030

Collected Steps per Second: 22,802.45562
Overall Steps per Second: 10,657.47016

Timestep Collection Time: 2.19371
Timestep Consumption Time: 2.49990
PPO Batch Consumption Time: 0.29193
Total Iteration Time: 4.69361

Cumulative Model Updates: 57,038
Cumulative Timesteps: 475,799,806

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 475799806...
Checkpoint 475799806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,624.54084
Policy Entropy: 3.38414
Value Function Loss: 0.00314

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.10628
Policy Update Magnitude: 0.58311
Value Function Update Magnitude: 0.66884

Collected Steps per Second: 22,128.74216
Overall Steps per Second: 10,472.56869

Timestep Collection Time: 2.25969
Timestep Consumption Time: 2.51507
PPO Batch Consumption Time: 0.29361
Total Iteration Time: 4.77476

Cumulative Model Updates: 57,044
Cumulative Timesteps: 475,849,810

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,703.99690
Policy Entropy: 3.38343
Value Function Loss: 0.00312

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.10641
Policy Update Magnitude: 0.57985
Value Function Update Magnitude: 0.66714

Collected Steps per Second: 22,624.01287
Overall Steps per Second: 10,811.09722

Timestep Collection Time: 2.21137
Timestep Consumption Time: 2.41629
PPO Batch Consumption Time: 0.28197
Total Iteration Time: 4.62765

Cumulative Model Updates: 57,050
Cumulative Timesteps: 475,899,840

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 475899840...
Checkpoint 475899840 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,066.76642
Policy Entropy: 3.38674
Value Function Loss: 0.00308

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.09398
Policy Update Magnitude: 0.58161
Value Function Update Magnitude: 0.65684

Collected Steps per Second: 22,340.46767
Overall Steps per Second: 10,644.25195

Timestep Collection Time: 2.23917
Timestep Consumption Time: 2.46046
PPO Batch Consumption Time: 0.28186
Total Iteration Time: 4.69963

Cumulative Model Updates: 57,056
Cumulative Timesteps: 475,949,864

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,366.66389
Policy Entropy: 3.38523
Value Function Loss: 0.00306

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.11412
Policy Update Magnitude: 0.57824
Value Function Update Magnitude: 0.63205

Collected Steps per Second: 22,492.45381
Overall Steps per Second: 10,480.42868

Timestep Collection Time: 2.22403
Timestep Consumption Time: 2.54905
PPO Batch Consumption Time: 0.29833
Total Iteration Time: 4.77309

Cumulative Model Updates: 57,062
Cumulative Timesteps: 475,999,888

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 475999888...
Checkpoint 475999888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,666.11048
Policy Entropy: 3.38260
Value Function Loss: 0.00298

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.11071
Policy Update Magnitude: 0.56806
Value Function Update Magnitude: 0.62585

Collected Steps per Second: 21,593.48821
Overall Steps per Second: 10,202.80804

Timestep Collection Time: 2.31607
Timestep Consumption Time: 2.58572
PPO Batch Consumption Time: 0.30609
Total Iteration Time: 4.90179

Cumulative Model Updates: 57,068
Cumulative Timesteps: 476,049,900

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,039.52297
Policy Entropy: 3.39716
Value Function Loss: 0.00297

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.10814
Policy Update Magnitude: 0.55853
Value Function Update Magnitude: 0.59360

Collected Steps per Second: 22,724.25629
Overall Steps per Second: 10,689.73271

Timestep Collection Time: 2.20082
Timestep Consumption Time: 2.47769
PPO Batch Consumption Time: 0.29216
Total Iteration Time: 4.67851

Cumulative Model Updates: 57,074
Cumulative Timesteps: 476,099,912

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 476099912...
Checkpoint 476099912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,507.99029
Policy Entropy: 3.39274
Value Function Loss: 0.00311

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.09364
Policy Update Magnitude: 0.55696
Value Function Update Magnitude: 0.59808

Collected Steps per Second: 22,560.54570
Overall Steps per Second: 10,678.87989

Timestep Collection Time: 2.21688
Timestep Consumption Time: 2.46657
PPO Batch Consumption Time: 0.29082
Total Iteration Time: 4.68345

Cumulative Model Updates: 57,080
Cumulative Timesteps: 476,149,926

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 834.73944
Policy Entropy: 3.40658
Value Function Loss: 0.00331

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.09145
Policy Update Magnitude: 0.57167
Value Function Update Magnitude: 0.61491

Collected Steps per Second: 22,876.98419
Overall Steps per Second: 10,745.29729

Timestep Collection Time: 2.18753
Timestep Consumption Time: 2.46977
PPO Batch Consumption Time: 0.29033
Total Iteration Time: 4.65729

Cumulative Model Updates: 57,086
Cumulative Timesteps: 476,199,970

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 476199970...
Checkpoint 476199970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,887.95061
Policy Entropy: 3.40703
Value Function Loss: 0.00307

Mean KL Divergence: 0.00744
SB3 Clip Fraction: 0.08478
Policy Update Magnitude: 0.57748
Value Function Update Magnitude: 0.62396

Collected Steps per Second: 22,323.10061
Overall Steps per Second: 10,698.14522

Timestep Collection Time: 2.24010
Timestep Consumption Time: 2.43417
PPO Batch Consumption Time: 0.28002
Total Iteration Time: 4.67427

Cumulative Model Updates: 57,092
Cumulative Timesteps: 476,249,976

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,853.39046
Policy Entropy: 3.40884
Value Function Loss: 0.00295

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.09434
Policy Update Magnitude: 0.56622
Value Function Update Magnitude: 0.60695

Collected Steps per Second: 22,281.39213
Overall Steps per Second: 10,485.10071

Timestep Collection Time: 2.24438
Timestep Consumption Time: 2.52505
PPO Batch Consumption Time: 0.29611
Total Iteration Time: 4.76943

Cumulative Model Updates: 57,098
Cumulative Timesteps: 476,299,984

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 476299984...
Checkpoint 476299984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,458.28659
Policy Entropy: 3.39285
Value Function Loss: 0.00278

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.09037
Policy Update Magnitude: 0.54805
Value Function Update Magnitude: 0.59770

Collected Steps per Second: 21,893.89838
Overall Steps per Second: 10,541.86617

Timestep Collection Time: 2.28447
Timestep Consumption Time: 2.46004
PPO Batch Consumption Time: 0.28692
Total Iteration Time: 4.74451

Cumulative Model Updates: 57,104
Cumulative Timesteps: 476,350,000

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,372.01045
Policy Entropy: 3.38952
Value Function Loss: 0.00299

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.08952
Policy Update Magnitude: 0.54954
Value Function Update Magnitude: 0.61320

Collected Steps per Second: 22,464.40811
Overall Steps per Second: 10,598.20941

Timestep Collection Time: 2.22592
Timestep Consumption Time: 2.49223
PPO Batch Consumption Time: 0.29425
Total Iteration Time: 4.71816

Cumulative Model Updates: 57,110
Cumulative Timesteps: 476,400,004

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 476400004...
Checkpoint 476400004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,101.74412
Policy Entropy: 3.40313
Value Function Loss: 0.00305

Mean KL Divergence: 0.00686
SB3 Clip Fraction: 0.07965
Policy Update Magnitude: 0.55986
Value Function Update Magnitude: 0.61249

Collected Steps per Second: 22,437.64543
Overall Steps per Second: 10,747.97583

Timestep Collection Time: 2.22911
Timestep Consumption Time: 2.42442
PPO Batch Consumption Time: 0.28186
Total Iteration Time: 4.65353

Cumulative Model Updates: 57,116
Cumulative Timesteps: 476,450,020

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,268.19419
Policy Entropy: 3.40978
Value Function Loss: 0.00319

Mean KL Divergence: 0.00717
SB3 Clip Fraction: 0.08167
Policy Update Magnitude: 0.56489
Value Function Update Magnitude: 0.60724

Collected Steps per Second: 22,683.12045
Overall Steps per Second: 10,568.79943

Timestep Collection Time: 2.20569
Timestep Consumption Time: 2.52824
PPO Batch Consumption Time: 0.29628
Total Iteration Time: 4.73393

Cumulative Model Updates: 57,122
Cumulative Timesteps: 476,500,052

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 476500052...
Checkpoint 476500052 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,651.53528
Policy Entropy: 3.40642
Value Function Loss: 0.00308

Mean KL Divergence: 0.00713
SB3 Clip Fraction: 0.08325
Policy Update Magnitude: 0.56273
Value Function Update Magnitude: 0.62768

Collected Steps per Second: 22,208.68000
Overall Steps per Second: 10,579.66211

Timestep Collection Time: 2.25254
Timestep Consumption Time: 2.47596
PPO Batch Consumption Time: 0.28664
Total Iteration Time: 4.72851

Cumulative Model Updates: 57,128
Cumulative Timesteps: 476,550,078

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 694.78541
Policy Entropy: 3.39037
Value Function Loss: 0.00317

Mean KL Divergence: 0.00712
SB3 Clip Fraction: 0.08304
Policy Update Magnitude: 0.57091
Value Function Update Magnitude: 0.62570

Collected Steps per Second: 22,564.40340
Overall Steps per Second: 10,650.15582

Timestep Collection Time: 2.21677
Timestep Consumption Time: 2.47988
PPO Batch Consumption Time: 0.29149
Total Iteration Time: 4.69664

Cumulative Model Updates: 57,134
Cumulative Timesteps: 476,600,098

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 476600098...
Checkpoint 476600098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 927.50980
Policy Entropy: 3.40046
Value Function Loss: 0.00309

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.09423
Policy Update Magnitude: 0.58104
Value Function Update Magnitude: 0.63414

Collected Steps per Second: 22,191.08141
Overall Steps per Second: 10,540.32014

Timestep Collection Time: 2.25442
Timestep Consumption Time: 2.49193
PPO Batch Consumption Time: 0.29454
Total Iteration Time: 4.74635

Cumulative Model Updates: 57,140
Cumulative Timesteps: 476,650,126

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,216.68544
Policy Entropy: 3.40573
Value Function Loss: 0.00298

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.10401
Policy Update Magnitude: 0.57194
Value Function Update Magnitude: 0.62967

Collected Steps per Second: 22,113.12186
Overall Steps per Second: 10,329.43426

Timestep Collection Time: 2.26128
Timestep Consumption Time: 2.57964
PPO Batch Consumption Time: 0.30515
Total Iteration Time: 4.84092

Cumulative Model Updates: 57,146
Cumulative Timesteps: 476,700,130

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 476700130...
Checkpoint 476700130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,303.28735
Policy Entropy: 3.41397
Value Function Loss: 0.00283

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.09753
Policy Update Magnitude: 0.55219
Value Function Update Magnitude: 0.61302

Collected Steps per Second: 22,059.68199
Overall Steps per Second: 10,668.39975

Timestep Collection Time: 2.26721
Timestep Consumption Time: 2.42084
PPO Batch Consumption Time: 0.28159
Total Iteration Time: 4.68805

Cumulative Model Updates: 57,152
Cumulative Timesteps: 476,750,144

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 897.39687
Policy Entropy: 3.40859
Value Function Loss: 0.00286

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.10053
Policy Update Magnitude: 0.54561
Value Function Update Magnitude: 0.58888

Collected Steps per Second: 22,521.15924
Overall Steps per Second: 10,627.03547

Timestep Collection Time: 2.22040
Timestep Consumption Time: 2.48514
PPO Batch Consumption Time: 0.29268
Total Iteration Time: 4.70555

Cumulative Model Updates: 57,158
Cumulative Timesteps: 476,800,150

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 476800150...
Checkpoint 476800150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,504.29240
Policy Entropy: 3.40110
Value Function Loss: 0.00308

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.09132
Policy Update Magnitude: 0.55751
Value Function Update Magnitude: 0.59212

Collected Steps per Second: 22,458.22062
Overall Steps per Second: 10,658.53464

Timestep Collection Time: 2.22725
Timestep Consumption Time: 2.46571
PPO Batch Consumption Time: 0.29238
Total Iteration Time: 4.69295

Cumulative Model Updates: 57,164
Cumulative Timesteps: 476,850,170

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 900.44232
Policy Entropy: 3.39789
Value Function Loss: 0.00318

Mean KL Divergence: 0.00758
SB3 Clip Fraction: 0.08615
Policy Update Magnitude: 0.56077
Value Function Update Magnitude: 0.59992

Collected Steps per Second: 22,928.82800
Overall Steps per Second: 10,747.26351

Timestep Collection Time: 2.18179
Timestep Consumption Time: 2.47297
PPO Batch Consumption Time: 0.28918
Total Iteration Time: 4.65477

Cumulative Model Updates: 57,170
Cumulative Timesteps: 476,900,196

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 476900196...
Checkpoint 476900196 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,509.94424
Policy Entropy: 3.40270
Value Function Loss: 0.00324

Mean KL Divergence: 0.00718
SB3 Clip Fraction: 0.08110
Policy Update Magnitude: 0.56939
Value Function Update Magnitude: 0.60383

Collected Steps per Second: 22,181.13980
Overall Steps per Second: 10,597.26130

Timestep Collection Time: 2.25525
Timestep Consumption Time: 2.46522
PPO Batch Consumption Time: 0.28747
Total Iteration Time: 4.72046

Cumulative Model Updates: 57,176
Cumulative Timesteps: 476,950,220

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,462.14112
Policy Entropy: 3.40873
Value Function Loss: 0.00336

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.09779
Policy Update Magnitude: 0.57783
Value Function Update Magnitude: 0.61420

Collected Steps per Second: 22,483.75220
Overall Steps per Second: 10,614.56102

Timestep Collection Time: 2.22516
Timestep Consumption Time: 2.48817
PPO Batch Consumption Time: 0.29369
Total Iteration Time: 4.71334

Cumulative Model Updates: 57,182
Cumulative Timesteps: 477,000,250

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 477000250...
Checkpoint 477000250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,261.98991
Policy Entropy: 3.41367
Value Function Loss: 0.00325

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.09155
Policy Update Magnitude: 0.57975
Value Function Update Magnitude: 0.62824

Collected Steps per Second: 22,440.53445
Overall Steps per Second: 10,614.17903

Timestep Collection Time: 2.22838
Timestep Consumption Time: 2.48287
PPO Batch Consumption Time: 0.29559
Total Iteration Time: 4.71125

Cumulative Model Updates: 57,188
Cumulative Timesteps: 477,050,256

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,829.87281
Policy Entropy: 3.39701
Value Function Loss: 0.00329

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.09518
Policy Update Magnitude: 0.58937
Value Function Update Magnitude: 0.62769

Collected Steps per Second: 22,814.30203
Overall Steps per Second: 10,862.61716

Timestep Collection Time: 2.19161
Timestep Consumption Time: 2.41133
PPO Batch Consumption Time: 0.27961
Total Iteration Time: 4.60294

Cumulative Model Updates: 57,194
Cumulative Timesteps: 477,100,256

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 477100256...
Checkpoint 477100256 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,550.10247
Policy Entropy: 3.38162
Value Function Loss: 0.00323

Mean KL Divergence: 0.00770
SB3 Clip Fraction: 0.08964
Policy Update Magnitude: 0.58744
Value Function Update Magnitude: 0.60511

Collected Steps per Second: 22,385.34146
Overall Steps per Second: 10,596.53722

Timestep Collection Time: 2.23477
Timestep Consumption Time: 2.48621
PPO Batch Consumption Time: 0.29273
Total Iteration Time: 4.72098

Cumulative Model Updates: 57,200
Cumulative Timesteps: 477,150,282

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,361.35305
Policy Entropy: 3.37167
Value Function Loss: 0.00329

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.09416
Policy Update Magnitude: 0.58623
Value Function Update Magnitude: 0.59766

Collected Steps per Second: 22,528.28735
Overall Steps per Second: 10,533.38228

Timestep Collection Time: 2.22067
Timestep Consumption Time: 2.52880
PPO Batch Consumption Time: 0.29518
Total Iteration Time: 4.74947

Cumulative Model Updates: 57,206
Cumulative Timesteps: 477,200,310

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 477200310...
Checkpoint 477200310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,395.99909
Policy Entropy: 3.39247
Value Function Loss: 0.00336

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.08904
Policy Update Magnitude: 0.57704
Value Function Update Magnitude: 0.59913

Collected Steps per Second: 22,040.11429
Overall Steps per Second: 10,576.98708

Timestep Collection Time: 2.26968
Timestep Consumption Time: 2.45983
PPO Batch Consumption Time: 0.28876
Total Iteration Time: 4.72951

Cumulative Model Updates: 57,212
Cumulative Timesteps: 477,250,334

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,065.49137
Policy Entropy: 3.39789
Value Function Loss: 0.00334

Mean KL Divergence: 0.00760
SB3 Clip Fraction: 0.08817
Policy Update Magnitude: 0.57779
Value Function Update Magnitude: 0.61183

Collected Steps per Second: 22,777.20975
Overall Steps per Second: 10,820.96520

Timestep Collection Time: 2.19649
Timestep Consumption Time: 2.42694
PPO Batch Consumption Time: 0.28152
Total Iteration Time: 4.62343

Cumulative Model Updates: 57,218
Cumulative Timesteps: 477,300,364

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 477300364...
Checkpoint 477300364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,271.91571
Policy Entropy: 3.40743
Value Function Loss: 0.00336

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.10277
Policy Update Magnitude: 0.57652
Value Function Update Magnitude: 0.61683

Collected Steps per Second: 21,972.34558
Overall Steps per Second: 10,539.49293

Timestep Collection Time: 2.27741
Timestep Consumption Time: 2.47045
PPO Batch Consumption Time: 0.28675
Total Iteration Time: 4.74786

Cumulative Model Updates: 57,224
Cumulative Timesteps: 477,350,404

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 974.47867
Policy Entropy: 3.40175
Value Function Loss: 0.00339

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.11355
Policy Update Magnitude: 0.56784
Value Function Update Magnitude: 0.62556

Collected Steps per Second: 21,907.46744
Overall Steps per Second: 10,587.99455

Timestep Collection Time: 2.28360
Timestep Consumption Time: 2.44137
PPO Batch Consumption Time: 0.28128
Total Iteration Time: 4.72497

Cumulative Model Updates: 57,230
Cumulative Timesteps: 477,400,432

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 477400432...
Checkpoint 477400432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,897.75770
Policy Entropy: 3.40309
Value Function Loss: 0.00334

Mean KL Divergence: 0.01091
SB3 Clip Fraction: 0.11812
Policy Update Magnitude: 0.57122
Value Function Update Magnitude: 0.63113

Collected Steps per Second: 22,290.36882
Overall Steps per Second: 10,665.05987

Timestep Collection Time: 2.24402
Timestep Consumption Time: 2.44606
PPO Batch Consumption Time: 0.28090
Total Iteration Time: 4.69008

Cumulative Model Updates: 57,236
Cumulative Timesteps: 477,450,452

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,263.62128
Policy Entropy: 3.37502
Value Function Loss: 0.00319

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.09999
Policy Update Magnitude: 0.57620
Value Function Update Magnitude: 0.62975

Collected Steps per Second: 22,756.37036
Overall Steps per Second: 10,710.57070

Timestep Collection Time: 2.19824
Timestep Consumption Time: 2.47228
PPO Batch Consumption Time: 0.28884
Total Iteration Time: 4.67053

Cumulative Model Updates: 57,242
Cumulative Timesteps: 477,500,476

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 477500476...
Checkpoint 477500476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,371.74985
Policy Entropy: 3.37176
Value Function Loss: 0.00299

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.09705
Policy Update Magnitude: 0.58665
Value Function Update Magnitude: 0.61278

Collected Steps per Second: 21,951.04674
Overall Steps per Second: 10,397.53742

Timestep Collection Time: 2.27852
Timestep Consumption Time: 2.53185
PPO Batch Consumption Time: 0.29554
Total Iteration Time: 4.81037

Cumulative Model Updates: 57,248
Cumulative Timesteps: 477,550,492

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 826.08661
Policy Entropy: 3.35622
Value Function Loss: 0.00313

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.09271
Policy Update Magnitude: 0.58278
Value Function Update Magnitude: 0.59632

Collected Steps per Second: 22,451.10316
Overall Steps per Second: 10,519.06600

Timestep Collection Time: 2.22786
Timestep Consumption Time: 2.52712
PPO Batch Consumption Time: 0.29557
Total Iteration Time: 4.75498

Cumulative Model Updates: 57,254
Cumulative Timesteps: 477,600,510

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 477600510...
Checkpoint 477600510 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,602.56117
Policy Entropy: 3.36476
Value Function Loss: 0.00308

Mean KL Divergence: 0.00678
SB3 Clip Fraction: 0.07784
Policy Update Magnitude: 0.59479
Value Function Update Magnitude: 0.60394

Collected Steps per Second: 22,038.85250
Overall Steps per Second: 10,624.54810

Timestep Collection Time: 2.26954
Timestep Consumption Time: 2.43824
PPO Batch Consumption Time: 0.27968
Total Iteration Time: 4.70778

Cumulative Model Updates: 57,260
Cumulative Timesteps: 477,650,528

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,203.55531
Policy Entropy: 3.35973
Value Function Loss: 0.00308

Mean KL Divergence: 0.00756
SB3 Clip Fraction: 0.08756
Policy Update Magnitude: 0.59161
Value Function Update Magnitude: 0.59735

Collected Steps per Second: 22,730.53403
Overall Steps per Second: 10,817.63609

Timestep Collection Time: 2.20074
Timestep Consumption Time: 2.42356
PPO Batch Consumption Time: 0.28120
Total Iteration Time: 4.62430

Cumulative Model Updates: 57,266
Cumulative Timesteps: 477,700,552

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 477700552...
Checkpoint 477700552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,072.35411
Policy Entropy: 3.37705
Value Function Loss: 0.00321

Mean KL Divergence: 0.00682
SB3 Clip Fraction: 0.07890
Policy Update Magnitude: 0.57525
Value Function Update Magnitude: 0.59287

Collected Steps per Second: 22,076.82612
Overall Steps per Second: 10,595.71198

Timestep Collection Time: 2.26618
Timestep Consumption Time: 2.45554
PPO Batch Consumption Time: 0.28219
Total Iteration Time: 4.72172

Cumulative Model Updates: 57,272
Cumulative Timesteps: 477,750,582

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,118.29347
Policy Entropy: 3.37404
Value Function Loss: 0.00339

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.09304
Policy Update Magnitude: 0.58156
Value Function Update Magnitude: 0.61485

Collected Steps per Second: 22,326.07507
Overall Steps per Second: 10,552.01566

Timestep Collection Time: 2.24007
Timestep Consumption Time: 2.49950
PPO Batch Consumption Time: 0.29025
Total Iteration Time: 4.73957

Cumulative Model Updates: 57,278
Cumulative Timesteps: 477,800,594

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 477800594...
Checkpoint 477800594 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,044.73759
Policy Entropy: 3.38075
Value Function Loss: 0.00334

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.09454
Policy Update Magnitude: 0.58527
Value Function Update Magnitude: 0.61096

Collected Steps per Second: 22,319.74358
Overall Steps per Second: 10,699.46616

Timestep Collection Time: 2.24142
Timestep Consumption Time: 2.43432
PPO Batch Consumption Time: 0.27977
Total Iteration Time: 4.67575

Cumulative Model Updates: 57,284
Cumulative Timesteps: 477,850,622

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,127.13365
Policy Entropy: 3.36199
Value Function Loss: 0.00339

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.10907
Policy Update Magnitude: 0.58741
Value Function Update Magnitude: 0.59408

Collected Steps per Second: 22,460.41195
Overall Steps per Second: 10,759.34242

Timestep Collection Time: 2.22703
Timestep Consumption Time: 2.42195
PPO Batch Consumption Time: 0.28193
Total Iteration Time: 4.64898

Cumulative Model Updates: 57,290
Cumulative Timesteps: 477,900,642

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 477900642...
Checkpoint 477900642 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,512.40640
Policy Entropy: 3.35748
Value Function Loss: 0.00334

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.11001
Policy Update Magnitude: 0.58631
Value Function Update Magnitude: 0.58931

Collected Steps per Second: 19,055.56576
Overall Steps per Second: 10,029.00106

Timestep Collection Time: 2.62391
Timestep Consumption Time: 2.36164
PPO Batch Consumption Time: 0.28103
Total Iteration Time: 4.98554

Cumulative Model Updates: 57,296
Cumulative Timesteps: 477,950,642

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,346.91285
Policy Entropy: 3.36472
Value Function Loss: 0.00327

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.11304
Policy Update Magnitude: 0.58361
Value Function Update Magnitude: 0.58682

Collected Steps per Second: 21,199.20413
Overall Steps per Second: 10,215.88740

Timestep Collection Time: 2.36009
Timestep Consumption Time: 2.53738
PPO Batch Consumption Time: 0.28557
Total Iteration Time: 4.89747

Cumulative Model Updates: 57,302
Cumulative Timesteps: 478,000,674

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 478000674...
Checkpoint 478000674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,142.18572
Policy Entropy: 3.37823
Value Function Loss: 0.00314

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.11146
Policy Update Magnitude: 0.57245
Value Function Update Magnitude: 0.56945

Collected Steps per Second: 20,670.19977
Overall Steps per Second: 10,208.57124

Timestep Collection Time: 2.42078
Timestep Consumption Time: 2.48079
PPO Batch Consumption Time: 0.28401
Total Iteration Time: 4.90157

Cumulative Model Updates: 57,308
Cumulative Timesteps: 478,050,712

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,815.35224
Policy Entropy: 3.38545
Value Function Loss: 0.00316

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.10402
Policy Update Magnitude: 0.56200
Value Function Update Magnitude: 0.56369

Collected Steps per Second: 21,809.08858
Overall Steps per Second: 10,482.17173

Timestep Collection Time: 2.29317
Timestep Consumption Time: 2.47798
PPO Batch Consumption Time: 0.28551
Total Iteration Time: 4.77115

Cumulative Model Updates: 57,314
Cumulative Timesteps: 478,100,724

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 478100724...
Checkpoint 478100724 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 901.59918
Policy Entropy: 3.38014
Value Function Loss: 0.00333

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.10276
Policy Update Magnitude: 0.56967
Value Function Update Magnitude: 0.57817

Collected Steps per Second: 21,206.87557
Overall Steps per Second: 10,215.03006

Timestep Collection Time: 2.35867
Timestep Consumption Time: 2.53804
PPO Batch Consumption Time: 0.29701
Total Iteration Time: 4.89671

Cumulative Model Updates: 57,320
Cumulative Timesteps: 478,150,744

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 726.63163
Policy Entropy: 3.37074
Value Function Loss: 0.00352

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.11773
Policy Update Magnitude: 0.58424
Value Function Update Magnitude: 0.60075

Collected Steps per Second: 21,806.91116
Overall Steps per Second: 10,548.05950

Timestep Collection Time: 2.29423
Timestep Consumption Time: 2.44883
PPO Batch Consumption Time: 0.28233
Total Iteration Time: 4.74305

Cumulative Model Updates: 57,326
Cumulative Timesteps: 478,200,774

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 478200774...
Checkpoint 478200774 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,077.67737
Policy Entropy: 3.37785
Value Function Loss: 0.00349

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.10818
Policy Update Magnitude: 0.58537
Value Function Update Magnitude: 0.62099

Collected Steps per Second: 22,048.03177
Overall Steps per Second: 10,600.03906

Timestep Collection Time: 2.26841
Timestep Consumption Time: 2.44987
PPO Batch Consumption Time: 0.28648
Total Iteration Time: 4.71828

Cumulative Model Updates: 57,332
Cumulative Timesteps: 478,250,788

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,433.46248
Policy Entropy: 3.37935
Value Function Loss: 0.00342

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.10613
Policy Update Magnitude: 0.58487
Value Function Update Magnitude: 0.62828

Collected Steps per Second: 22,332.83099
Overall Steps per Second: 10,538.71905

Timestep Collection Time: 2.23930
Timestep Consumption Time: 2.50605
PPO Batch Consumption Time: 0.29639
Total Iteration Time: 4.74536

Cumulative Model Updates: 57,338
Cumulative Timesteps: 478,300,798

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 478300798...
Checkpoint 478300798 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,042.57378
Policy Entropy: 3.38917
Value Function Loss: 0.00337

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.10230
Policy Update Magnitude: 0.58220
Value Function Update Magnitude: 0.64423

Collected Steps per Second: 21,767.65419
Overall Steps per Second: 10,476.32632

Timestep Collection Time: 2.29717
Timestep Consumption Time: 2.47588
PPO Batch Consumption Time: 0.28460
Total Iteration Time: 4.77305

Cumulative Model Updates: 57,344
Cumulative Timesteps: 478,350,802

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,084.57810
Policy Entropy: 3.39690
Value Function Loss: 0.00315

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.09790
Policy Update Magnitude: 0.58232
Value Function Update Magnitude: 0.65091

Collected Steps per Second: 22,183.90015
Overall Steps per Second: 10,544.32151

Timestep Collection Time: 2.25533
Timestep Consumption Time: 2.48959
PPO Batch Consumption Time: 0.29148
Total Iteration Time: 4.74492

Cumulative Model Updates: 57,350
Cumulative Timesteps: 478,400,834

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 478400834...
Checkpoint 478400834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,332.53523
Policy Entropy: 3.41874
Value Function Loss: 0.00337

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.10198
Policy Update Magnitude: 0.57349
Value Function Update Magnitude: 0.65044

Collected Steps per Second: 22,066.53453
Overall Steps per Second: 10,675.26210

Timestep Collection Time: 2.26615
Timestep Consumption Time: 2.41814
PPO Batch Consumption Time: 0.28210
Total Iteration Time: 4.68429

Cumulative Model Updates: 57,356
Cumulative Timesteps: 478,450,840

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,160.48405
Policy Entropy: 3.40938
Value Function Loss: 0.00340

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.10167
Policy Update Magnitude: 0.57542
Value Function Update Magnitude: 0.65710

Collected Steps per Second: 22,436.72729
Overall Steps per Second: 10,591.10568

Timestep Collection Time: 2.22893
Timestep Consumption Time: 2.49295
PPO Batch Consumption Time: 0.29301
Total Iteration Time: 4.72189

Cumulative Model Updates: 57,362
Cumulative Timesteps: 478,500,850

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 478500850...
Checkpoint 478500850 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 819.05347
Policy Entropy: 3.39209
Value Function Loss: 0.00334

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.10386
Policy Update Magnitude: 0.57956
Value Function Update Magnitude: 0.64680

Collected Steps per Second: 21,606.25412
Overall Steps per Second: 10,441.46563

Timestep Collection Time: 2.31461
Timestep Consumption Time: 2.47495
PPO Batch Consumption Time: 0.28950
Total Iteration Time: 4.78956

Cumulative Model Updates: 57,368
Cumulative Timesteps: 478,550,860

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,081.76925
Policy Entropy: 3.38953
Value Function Loss: 0.00339

Mean KL Divergence: 0.00783
SB3 Clip Fraction: 0.09188
Policy Update Magnitude: 0.58403
Value Function Update Magnitude: 0.63901

Collected Steps per Second: 22,601.64037
Overall Steps per Second: 10,648.27468

Timestep Collection Time: 2.21232
Timestep Consumption Time: 2.48347
PPO Batch Consumption Time: 0.29386
Total Iteration Time: 4.69578

Cumulative Model Updates: 57,374
Cumulative Timesteps: 478,600,862

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 478600862...
Checkpoint 478600862 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,299.63801
Policy Entropy: 3.39835
Value Function Loss: 0.00318

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.09175
Policy Update Magnitude: 0.58170
Value Function Update Magnitude: 0.62874

Collected Steps per Second: 21,864.68784
Overall Steps per Second: 10,442.02819

Timestep Collection Time: 2.28844
Timestep Consumption Time: 2.50335
PPO Batch Consumption Time: 0.29134
Total Iteration Time: 4.79179

Cumulative Model Updates: 57,380
Cumulative Timesteps: 478,650,898

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,179.63171
Policy Entropy: 3.38735
Value Function Loss: 0.00325

Mean KL Divergence: 0.00709
SB3 Clip Fraction: 0.08232
Policy Update Magnitude: 0.58051
Value Function Update Magnitude: 0.62756

Collected Steps per Second: 21,902.90091
Overall Steps per Second: 10,495.64767

Timestep Collection Time: 2.28326
Timestep Consumption Time: 2.48157
PPO Batch Consumption Time: 0.29162
Total Iteration Time: 4.76483

Cumulative Model Updates: 57,386
Cumulative Timesteps: 478,700,908

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 478700908...
Checkpoint 478700908 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,485.14292
Policy Entropy: 3.39129
Value Function Loss: 0.00319

Mean KL Divergence: 0.00634
SB3 Clip Fraction: 0.07448
Policy Update Magnitude: 0.57247
Value Function Update Magnitude: 0.60387

Collected Steps per Second: 21,522.63727
Overall Steps per Second: 10,514.97623

Timestep Collection Time: 2.32323
Timestep Consumption Time: 2.43208
PPO Batch Consumption Time: 0.28405
Total Iteration Time: 4.75531

Cumulative Model Updates: 57,392
Cumulative Timesteps: 478,750,910

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,555.58378
Policy Entropy: 3.38312
Value Function Loss: 0.00321

Mean KL Divergence: 0.00675
SB3 Clip Fraction: 0.07745
Policy Update Magnitude: 0.57481
Value Function Update Magnitude: 0.60407

Collected Steps per Second: 21,921.54314
Overall Steps per Second: 10,588.53787

Timestep Collection Time: 2.28132
Timestep Consumption Time: 2.44171
PPO Batch Consumption Time: 0.28272
Total Iteration Time: 4.72303

Cumulative Model Updates: 57,398
Cumulative Timesteps: 478,800,920

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 478800920...
Checkpoint 478800920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,599.64077
Policy Entropy: 3.38592
Value Function Loss: 0.00317

Mean KL Divergence: 0.00758
SB3 Clip Fraction: 0.08568
Policy Update Magnitude: 0.57780
Value Function Update Magnitude: 0.60907

Collected Steps per Second: 21,932.54528
Overall Steps per Second: 10,575.05487

Timestep Collection Time: 2.28026
Timestep Consumption Time: 2.44898
PPO Batch Consumption Time: 0.28415
Total Iteration Time: 4.72924

Cumulative Model Updates: 57,404
Cumulative Timesteps: 478,850,932

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,252.95779
Policy Entropy: 3.39278
Value Function Loss: 0.00324

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.09479
Policy Update Magnitude: 0.57991
Value Function Update Magnitude: 0.63448

Collected Steps per Second: 22,621.17378
Overall Steps per Second: 10,613.80828

Timestep Collection Time: 2.21067
Timestep Consumption Time: 2.50093
PPO Batch Consumption Time: 0.29518
Total Iteration Time: 4.71160

Cumulative Model Updates: 57,410
Cumulative Timesteps: 478,900,940

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 478900940...
Checkpoint 478900940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 990.95387
Policy Entropy: 3.39166
Value Function Loss: 0.00307

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.09289
Policy Update Magnitude: 0.57570
Value Function Update Magnitude: 0.63693

Collected Steps per Second: 21,544.07718
Overall Steps per Second: 10,488.88310

Timestep Collection Time: 2.32203
Timestep Consumption Time: 2.44740
PPO Batch Consumption Time: 0.28475
Total Iteration Time: 4.76943

Cumulative Model Updates: 57,416
Cumulative Timesteps: 478,950,966

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,331.76298
Policy Entropy: 3.38878
Value Function Loss: 0.00303

Mean KL Divergence: 0.00689
SB3 Clip Fraction: 0.08022
Policy Update Magnitude: 0.57506
Value Function Update Magnitude: 0.62881

Collected Steps per Second: 22,473.13969
Overall Steps per Second: 10,559.40287

Timestep Collection Time: 2.22604
Timestep Consumption Time: 2.51154
PPO Batch Consumption Time: 0.29726
Total Iteration Time: 4.73758

Cumulative Model Updates: 57,422
Cumulative Timesteps: 479,000,992

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 479000992...
Checkpoint 479000992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,440.10580
Policy Entropy: 3.37608
Value Function Loss: 0.00296

Mean KL Divergence: 0.00777
SB3 Clip Fraction: 0.09104
Policy Update Magnitude: 0.57129
Value Function Update Magnitude: 0.61403

Collected Steps per Second: 21,935.51233
Overall Steps per Second: 10,533.01308

Timestep Collection Time: 2.28059
Timestep Consumption Time: 2.46885
PPO Batch Consumption Time: 0.28397
Total Iteration Time: 4.74945

Cumulative Model Updates: 57,428
Cumulative Timesteps: 479,051,018

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,101.37801
Policy Entropy: 3.38396
Value Function Loss: 0.00285

Mean KL Divergence: 0.00743
SB3 Clip Fraction: 0.08472
Policy Update Magnitude: 0.56515
Value Function Update Magnitude: 0.60646

Collected Steps per Second: 22,636.24779
Overall Steps per Second: 10,492.30773

Timestep Collection Time: 2.21008
Timestep Consumption Time: 2.55798
PPO Batch Consumption Time: 0.29855
Total Iteration Time: 4.76806

Cumulative Model Updates: 57,434
Cumulative Timesteps: 479,101,046

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 479101046...
Checkpoint 479101046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,350.08030
Policy Entropy: 3.39726
Value Function Loss: 0.00301

Mean KL Divergence: 0.00753
SB3 Clip Fraction: 0.08435
Policy Update Magnitude: 0.56675
Value Function Update Magnitude: 0.60336

Collected Steps per Second: 21,634.94541
Overall Steps per Second: 10,380.85178

Timestep Collection Time: 2.31117
Timestep Consumption Time: 2.50558
PPO Batch Consumption Time: 0.29442
Total Iteration Time: 4.81675

Cumulative Model Updates: 57,440
Cumulative Timesteps: 479,151,048

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 829.76438
Policy Entropy: 3.40017
Value Function Loss: 0.00318

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.10572
Policy Update Magnitude: 0.56799
Value Function Update Magnitude: 0.61010

Collected Steps per Second: 20,333.14202
Overall Steps per Second: 10,137.15626

Timestep Collection Time: 2.45963
Timestep Consumption Time: 2.47390
PPO Batch Consumption Time: 0.28853
Total Iteration Time: 4.93353

Cumulative Model Updates: 57,446
Cumulative Timesteps: 479,201,060

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 479201060...
Checkpoint 479201060 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 565.13503
Policy Entropy: 3.40226
Value Function Loss: 0.00346

Mean KL Divergence: 0.01128
SB3 Clip Fraction: 0.12215
Policy Update Magnitude: 0.57221
Value Function Update Magnitude: 0.63430

Collected Steps per Second: 20,193.77597
Overall Steps per Second: 9,780.46504

Timestep Collection Time: 2.47740
Timestep Consumption Time: 2.63770
PPO Batch Consumption Time: 0.30653
Total Iteration Time: 5.11509

Cumulative Model Updates: 57,452
Cumulative Timesteps: 479,251,088

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,320.73564
Policy Entropy: 3.40914
Value Function Loss: 0.00361

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.09282
Policy Update Magnitude: 0.57806
Value Function Update Magnitude: 0.64601

Collected Steps per Second: 20,501.17107
Overall Steps per Second: 9,740.92152

Timestep Collection Time: 2.43947
Timestep Consumption Time: 2.69475
PPO Batch Consumption Time: 0.32023
Total Iteration Time: 5.13422

Cumulative Model Updates: 57,458
Cumulative Timesteps: 479,301,100

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 479301100...
Checkpoint 479301100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 753.66528
Policy Entropy: 3.39958
Value Function Loss: 0.00351

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.09236
Policy Update Magnitude: 0.58252
Value Function Update Magnitude: 0.64751

Collected Steps per Second: 21,007.16152
Overall Steps per Second: 9,997.56149

Timestep Collection Time: 2.38024
Timestep Consumption Time: 2.62118
PPO Batch Consumption Time: 0.30888
Total Iteration Time: 5.00142

Cumulative Model Updates: 57,464
Cumulative Timesteps: 479,351,102

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,114.63970
Policy Entropy: 3.39860
Value Function Loss: 0.00315

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.09046
Policy Update Magnitude: 0.57717
Value Function Update Magnitude: 0.62572

Collected Steps per Second: 21,842.90494
Overall Steps per Second: 10,583.99187

Timestep Collection Time: 2.29035
Timestep Consumption Time: 2.43641
PPO Batch Consumption Time: 0.28309
Total Iteration Time: 4.72676

Cumulative Model Updates: 57,470
Cumulative Timesteps: 479,401,130

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 479401130...
Checkpoint 479401130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 737.20464
Policy Entropy: 3.38221
Value Function Loss: 0.00317

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.09766
Policy Update Magnitude: 0.57622
Value Function Update Magnitude: 0.60999

Collected Steps per Second: 21,054.24695
Overall Steps per Second: 10,111.98484

Timestep Collection Time: 2.37586
Timestep Consumption Time: 2.57094
PPO Batch Consumption Time: 0.29945
Total Iteration Time: 4.94680

Cumulative Model Updates: 57,476
Cumulative Timesteps: 479,451,152

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 642.88304
Policy Entropy: 3.40276
Value Function Loss: 0.00318

Mean KL Divergence: 0.00764
SB3 Clip Fraction: 0.08870
Policy Update Magnitude: 0.57739
Value Function Update Magnitude: 0.62879

Collected Steps per Second: 21,779.62015
Overall Steps per Second: 10,307.96785

Timestep Collection Time: 2.29683
Timestep Consumption Time: 2.55612
PPO Batch Consumption Time: 0.30137
Total Iteration Time: 4.85294

Cumulative Model Updates: 57,482
Cumulative Timesteps: 479,501,176

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 479501176...
Checkpoint 479501176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,483.32503
Policy Entropy: 3.39568
Value Function Loss: 0.00330

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.09590
Policy Update Magnitude: 0.57759
Value Function Update Magnitude: 0.65279

Collected Steps per Second: 20,854.24580
Overall Steps per Second: 9,731.04918

Timestep Collection Time: 2.39759
Timestep Consumption Time: 2.74060
PPO Batch Consumption Time: 0.32995
Total Iteration Time: 5.13819

Cumulative Model Updates: 57,488
Cumulative Timesteps: 479,551,176

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,258.93077
Policy Entropy: 3.41192
Value Function Loss: 0.00302

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.08768
Policy Update Magnitude: 0.56835
Value Function Update Magnitude: 0.63957

Collected Steps per Second: 21,540.99435
Overall Steps per Second: 10,376.98472

Timestep Collection Time: 2.32153
Timestep Consumption Time: 2.49760
PPO Batch Consumption Time: 0.29527
Total Iteration Time: 4.81913

Cumulative Model Updates: 57,494
Cumulative Timesteps: 479,601,184

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 479601184...
Checkpoint 479601184 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,669.96028
Policy Entropy: 3.39577
Value Function Loss: 0.00299

Mean KL Divergence: 0.00707
SB3 Clip Fraction: 0.08131
Policy Update Magnitude: 0.55445
Value Function Update Magnitude: 0.62408

Collected Steps per Second: 20,775.95646
Overall Steps per Second: 10,042.09168

Timestep Collection Time: 2.40682
Timestep Consumption Time: 2.57262
PPO Batch Consumption Time: 0.29862
Total Iteration Time: 4.97944

Cumulative Model Updates: 57,500
Cumulative Timesteps: 479,651,188

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 954.49633
Policy Entropy: 3.40410
Value Function Loss: 0.00297

Mean KL Divergence: 0.00668
SB3 Clip Fraction: 0.07690
Policy Update Magnitude: 0.55142
Value Function Update Magnitude: 0.62084

Collected Steps per Second: 20,408.53541
Overall Steps per Second: 10,049.38174

Timestep Collection Time: 2.45133
Timestep Consumption Time: 2.52689
PPO Batch Consumption Time: 0.28868
Total Iteration Time: 4.97822

Cumulative Model Updates: 57,506
Cumulative Timesteps: 479,701,216

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 479701216...
Checkpoint 479701216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,064.88506
Policy Entropy: 3.39725
Value Function Loss: 0.00320

Mean KL Divergence: 0.00683
SB3 Clip Fraction: 0.07865
Policy Update Magnitude: 0.56160
Value Function Update Magnitude: 0.62629

Collected Steps per Second: 21,644.04918
Overall Steps per Second: 10,334.89943

Timestep Collection Time: 2.31038
Timestep Consumption Time: 2.52818
PPO Batch Consumption Time: 0.29346
Total Iteration Time: 4.83856

Cumulative Model Updates: 57,512
Cumulative Timesteps: 479,751,222

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,348.84845
Policy Entropy: 3.39066
Value Function Loss: 0.00311

Mean KL Divergence: 0.00783
SB3 Clip Fraction: 0.09336
Policy Update Magnitude: 0.56487
Value Function Update Magnitude: 0.62873

Collected Steps per Second: 22,261.64850
Overall Steps per Second: 10,391.79944

Timestep Collection Time: 2.24611
Timestep Consumption Time: 2.56557
PPO Batch Consumption Time: 0.30177
Total Iteration Time: 4.81168

Cumulative Model Updates: 57,518
Cumulative Timesteps: 479,801,224

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 479801224...
Checkpoint 479801224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,111.01472
Policy Entropy: 3.38999
Value Function Loss: 0.00299

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.09163
Policy Update Magnitude: 0.55966
Value Function Update Magnitude: 0.62153

Collected Steps per Second: 19,916.21394
Overall Steps per Second: 9,678.37274

Timestep Collection Time: 2.51092
Timestep Consumption Time: 2.65607
PPO Batch Consumption Time: 0.31546
Total Iteration Time: 5.16698

Cumulative Model Updates: 57,524
Cumulative Timesteps: 479,851,232

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,972.15407
Policy Entropy: 3.39953
Value Function Loss: 0.00308

Mean KL Divergence: 0.00783
SB3 Clip Fraction: 0.09181
Policy Update Magnitude: 0.55675
Value Function Update Magnitude: 0.61250

Collected Steps per Second: 20,985.71073
Overall Steps per Second: 10,017.18296

Timestep Collection Time: 2.38315
Timestep Consumption Time: 2.60948
PPO Batch Consumption Time: 0.30104
Total Iteration Time: 4.99262

Cumulative Model Updates: 57,530
Cumulative Timesteps: 479,901,244

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 479901244...
Checkpoint 479901244 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,190.72748
Policy Entropy: 3.40388
Value Function Loss: 0.00322

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.09027
Policy Update Magnitude: 0.56158
Value Function Update Magnitude: 0.60432

Collected Steps per Second: 20,776.74839
Overall Steps per Second: 10,188.84576

Timestep Collection Time: 2.40663
Timestep Consumption Time: 2.50089
PPO Batch Consumption Time: 0.29983
Total Iteration Time: 4.90752

Cumulative Model Updates: 57,536
Cumulative Timesteps: 479,951,246

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,012.75282
Policy Entropy: 3.41008
Value Function Loss: 0.00347

Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.09487
Policy Update Magnitude: 0.56312
Value Function Update Magnitude: 0.61271

Collected Steps per Second: 19,432.76858
Overall Steps per Second: 9,459.15132

Timestep Collection Time: 2.57421
Timestep Consumption Time: 2.71422
PPO Batch Consumption Time: 0.32160
Total Iteration Time: 5.28842

Cumulative Model Updates: 57,542
Cumulative Timesteps: 480,001,270

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 480001270...
Checkpoint 480001270 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,461.36144
Policy Entropy: 3.39708
Value Function Loss: 0.00333

Mean KL Divergence: 0.00734
SB3 Clip Fraction: 0.08568
Policy Update Magnitude: 0.57094
Value Function Update Magnitude: 0.60714

Collected Steps per Second: 19,531.86190
Overall Steps per Second: 9,736.13497

Timestep Collection Time: 2.55992
Timestep Consumption Time: 2.57559
PPO Batch Consumption Time: 0.30076
Total Iteration Time: 5.13551

Cumulative Model Updates: 57,548
Cumulative Timesteps: 480,051,270

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,684.30674
Policy Entropy: 3.39950
Value Function Loss: 0.00330

Mean KL Divergence: 0.00717
SB3 Clip Fraction: 0.08397
Policy Update Magnitude: 0.57567
Value Function Update Magnitude: 0.60010

Collected Steps per Second: 22,197.88635
Overall Steps per Second: 10,450.36383

Timestep Collection Time: 2.25301
Timestep Consumption Time: 2.53266
PPO Batch Consumption Time: 0.29441
Total Iteration Time: 4.78567

Cumulative Model Updates: 57,554
Cumulative Timesteps: 480,101,282

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 480101282...
Checkpoint 480101282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,036.28031
Policy Entropy: 3.40094
Value Function Loss: 0.00312

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.09528
Policy Update Magnitude: 0.57576
Value Function Update Magnitude: 0.61914

Collected Steps per Second: 20,849.27868
Overall Steps per Second: 10,238.69146

Timestep Collection Time: 2.39960
Timestep Consumption Time: 2.48676
PPO Batch Consumption Time: 0.29366
Total Iteration Time: 4.88637

Cumulative Model Updates: 57,560
Cumulative Timesteps: 480,151,312

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,386.40958
Policy Entropy: 3.39926
Value Function Loss: 0.00306

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.09940
Policy Update Magnitude: 0.56212
Value Function Update Magnitude: 0.61954

Collected Steps per Second: 22,341.36984
Overall Steps per Second: 10,807.74029

Timestep Collection Time: 2.23872
Timestep Consumption Time: 2.38908
PPO Batch Consumption Time: 0.28858
Total Iteration Time: 4.62779

Cumulative Model Updates: 57,566
Cumulative Timesteps: 480,201,328

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 480201328...
Checkpoint 480201328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,086.11016
Policy Entropy: 3.39707
Value Function Loss: 0.00295

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.09221
Policy Update Magnitude: 0.55509
Value Function Update Magnitude: 0.61572

Collected Steps per Second: 22,425.16510
Overall Steps per Second: 10,712.15189

Timestep Collection Time: 2.23080
Timestep Consumption Time: 2.43923
PPO Batch Consumption Time: 0.28612
Total Iteration Time: 4.67002

Cumulative Model Updates: 57,572
Cumulative Timesteps: 480,251,354

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,932.95375
Policy Entropy: 3.38957
Value Function Loss: 0.00321

Mean KL Divergence: 0.00725
SB3 Clip Fraction: 0.08392
Policy Update Magnitude: 0.56569
Value Function Update Magnitude: 0.61169

Collected Steps per Second: 20,078.34344
Overall Steps per Second: 9,990.64691

Timestep Collection Time: 2.49044
Timestep Consumption Time: 2.51464
PPO Batch Consumption Time: 0.29540
Total Iteration Time: 5.00508

Cumulative Model Updates: 57,578
Cumulative Timesteps: 480,301,358

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 480301358...
Checkpoint 480301358 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,216.52743
Policy Entropy: 3.39776
Value Function Loss: 0.00322

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.10301
Policy Update Magnitude: 0.57259
Value Function Update Magnitude: 0.62359

Collected Steps per Second: 21,115.73201
Overall Steps per Second: 10,336.50684

Timestep Collection Time: 2.36876
Timestep Consumption Time: 2.47021
PPO Batch Consumption Time: 0.28408
Total Iteration Time: 4.83897

Cumulative Model Updates: 57,584
Cumulative Timesteps: 480,351,376

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,655.04671
Policy Entropy: 3.40260
Value Function Loss: 0.00327

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.10300
Policy Update Magnitude: 0.57110
Value Function Update Magnitude: 0.63229

Collected Steps per Second: 20,435.51866
Overall Steps per Second: 10,004.42817

Timestep Collection Time: 2.44760
Timestep Consumption Time: 2.55198
PPO Batch Consumption Time: 0.29518
Total Iteration Time: 4.99959

Cumulative Model Updates: 57,590
Cumulative Timesteps: 480,401,394

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 480401394...
Checkpoint 480401394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,074.03159
Policy Entropy: 3.41221
Value Function Loss: 0.00324

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.10342
Policy Update Magnitude: 0.57250
Value Function Update Magnitude: 0.64753

Collected Steps per Second: 21,846.32449
Overall Steps per Second: 10,275.13004

Timestep Collection Time: 2.28981
Timestep Consumption Time: 2.57864
PPO Batch Consumption Time: 0.30605
Total Iteration Time: 4.86845

Cumulative Model Updates: 57,596
Cumulative Timesteps: 480,451,418

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,109.28260
Policy Entropy: 3.39439
Value Function Loss: 0.00321

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.10299
Policy Update Magnitude: 0.56616
Value Function Update Magnitude: 0.63771

Collected Steps per Second: 20,809.70414
Overall Steps per Second: 10,034.38906

Timestep Collection Time: 2.40407
Timestep Consumption Time: 2.58158
PPO Batch Consumption Time: 0.30486
Total Iteration Time: 4.98565

Cumulative Model Updates: 57,602
Cumulative Timesteps: 480,501,446

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 480501446...
Checkpoint 480501446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,141.58899
Policy Entropy: 3.40485
Value Function Loss: 0.00319

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.09604
Policy Update Magnitude: 0.56099
Value Function Update Magnitude: 0.62698

Collected Steps per Second: 20,989.13106
Overall Steps per Second: 9,892.71320

Timestep Collection Time: 2.38238
Timestep Consumption Time: 2.67225
PPO Batch Consumption Time: 0.32441
Total Iteration Time: 5.05463

Cumulative Model Updates: 57,608
Cumulative Timesteps: 480,551,450

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,336.88515
Policy Entropy: 3.41026
Value Function Loss: 0.00293

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.09220
Policy Update Magnitude: 0.55773
Value Function Update Magnitude: 0.63412

Collected Steps per Second: 20,367.93808
Overall Steps per Second: 9,903.02648

Timestep Collection Time: 2.45592
Timestep Consumption Time: 2.59526
PPO Batch Consumption Time: 0.30117
Total Iteration Time: 5.05118

Cumulative Model Updates: 57,614
Cumulative Timesteps: 480,601,472

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 480601472...
Checkpoint 480601472 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,514.13265
Policy Entropy: 3.42427
Value Function Loss: 0.00283

Mean KL Divergence: 0.00736
SB3 Clip Fraction: 0.08719
Policy Update Magnitude: 0.54881
Value Function Update Magnitude: 0.62652

Collected Steps per Second: 20,812.68599
Overall Steps per Second: 10,334.36188

Timestep Collection Time: 2.40305
Timestep Consumption Time: 2.43653
PPO Batch Consumption Time: 0.27968
Total Iteration Time: 4.83958

Cumulative Model Updates: 57,620
Cumulative Timesteps: 480,651,486

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,223.72694
Policy Entropy: 3.42456
Value Function Loss: 0.00270

Mean KL Divergence: 0.00749
SB3 Clip Fraction: 0.08792
Policy Update Magnitude: 0.54139
Value Function Update Magnitude: 0.60067

Collected Steps per Second: 22,009.87704
Overall Steps per Second: 10,491.71411

Timestep Collection Time: 2.27307
Timestep Consumption Time: 2.49545
PPO Batch Consumption Time: 0.29501
Total Iteration Time: 4.76852

Cumulative Model Updates: 57,626
Cumulative Timesteps: 480,701,516

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 480701516...
Checkpoint 480701516 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,192.38568
Policy Entropy: 3.43191
Value Function Loss: 0.00283

Mean KL Divergence: 0.00735
SB3 Clip Fraction: 0.08563
Policy Update Magnitude: 0.54207
Value Function Update Magnitude: 0.58798

Collected Steps per Second: 21,467.87877
Overall Steps per Second: 10,476.53790

Timestep Collection Time: 2.32915
Timestep Consumption Time: 2.44361
PPO Batch Consumption Time: 0.28147
Total Iteration Time: 4.77276

Cumulative Model Updates: 57,632
Cumulative Timesteps: 480,751,518

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 765.47469
Policy Entropy: 3.44187
Value Function Loss: 0.00304

Mean KL Divergence: 0.00695
SB3 Clip Fraction: 0.08166
Policy Update Magnitude: 0.54420
Value Function Update Magnitude: 0.57884

Collected Steps per Second: 22,030.19081
Overall Steps per Second: 10,249.22328

Timestep Collection Time: 2.26998
Timestep Consumption Time: 2.60922
PPO Batch Consumption Time: 0.30620
Total Iteration Time: 4.87920

Cumulative Model Updates: 57,638
Cumulative Timesteps: 480,801,526

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 480801526...
Checkpoint 480801526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,543.29939
Policy Entropy: 3.44348
Value Function Loss: 0.00307

Mean KL Divergence: 0.00679
SB3 Clip Fraction: 0.07872
Policy Update Magnitude: 0.54973
Value Function Update Magnitude: 0.57583

Collected Steps per Second: 20,986.15811
Overall Steps per Second: 10,436.01926

Timestep Collection Time: 2.38348
Timestep Consumption Time: 2.40954
PPO Batch Consumption Time: 0.28306
Total Iteration Time: 4.79302

Cumulative Model Updates: 57,644
Cumulative Timesteps: 480,851,546

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,201.65907
Policy Entropy: 3.43535
Value Function Loss: 0.00315

Mean KL Divergence: 0.00727
SB3 Clip Fraction: 0.08601
Policy Update Magnitude: 0.55349
Value Function Update Magnitude: 0.58937

Collected Steps per Second: 22,401.56193
Overall Steps per Second: 10,599.85646

Timestep Collection Time: 2.23252
Timestep Consumption Time: 2.48565
PPO Batch Consumption Time: 0.29480
Total Iteration Time: 4.71818

Cumulative Model Updates: 57,650
Cumulative Timesteps: 480,901,558

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 480901558...
Checkpoint 480901558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,568.83867
Policy Entropy: 3.42075
Value Function Loss: 0.00317

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.09980
Policy Update Magnitude: 0.56342
Value Function Update Magnitude: 0.60954

Collected Steps per Second: 22,321.82295
Overall Steps per Second: 10,404.23673

Timestep Collection Time: 2.24130
Timestep Consumption Time: 2.56731
PPO Batch Consumption Time: 0.30159
Total Iteration Time: 4.80862

Cumulative Model Updates: 57,656
Cumulative Timesteps: 480,951,588

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,204.04200
Policy Entropy: 3.40412
Value Function Loss: 0.00300

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.10510
Policy Update Magnitude: 0.56494
Value Function Update Magnitude: 0.60518

Collected Steps per Second: 21,311.71124
Overall Steps per Second: 10,327.43678

Timestep Collection Time: 2.34678
Timestep Consumption Time: 2.49604
PPO Batch Consumption Time: 0.29046
Total Iteration Time: 4.84283

Cumulative Model Updates: 57,662
Cumulative Timesteps: 481,001,602

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 481001602...
Checkpoint 481001602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,210.71655
Policy Entropy: 3.40424
Value Function Loss: 0.00296

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.11042
Policy Update Magnitude: 0.55904
Value Function Update Magnitude: 0.59903

Collected Steps per Second: 22,206.76853
Overall Steps per Second: 10,483.64569

Timestep Collection Time: 2.25175
Timestep Consumption Time: 2.51797
PPO Batch Consumption Time: 0.28989
Total Iteration Time: 4.76971

Cumulative Model Updates: 57,668
Cumulative Timesteps: 481,051,606

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 902.28876
Policy Entropy: 3.39287
Value Function Loss: 0.00326

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.10106
Policy Update Magnitude: 0.56641
Value Function Update Magnitude: 0.58411

Collected Steps per Second: 20,955.22214
Overall Steps per Second: 10,341.33539

Timestep Collection Time: 2.38699
Timestep Consumption Time: 2.44991
PPO Batch Consumption Time: 0.28063
Total Iteration Time: 4.83690

Cumulative Model Updates: 57,674
Cumulative Timesteps: 481,101,626

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 481101626...
Checkpoint 481101626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,445.63059
Policy Entropy: 3.39549
Value Function Loss: 0.00324

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.09259
Policy Update Magnitude: 0.57995
Value Function Update Magnitude: 0.60304

Collected Steps per Second: 21,640.99827
Overall Steps per Second: 10,338.27294

Timestep Collection Time: 2.31117
Timestep Consumption Time: 2.52678
PPO Batch Consumption Time: 0.29569
Total Iteration Time: 4.83795

Cumulative Model Updates: 57,680
Cumulative Timesteps: 481,151,642

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,601.16966
Policy Entropy: 3.38977
Value Function Loss: 0.00308

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.09144
Policy Update Magnitude: 0.57674
Value Function Update Magnitude: 0.62488

Collected Steps per Second: 21,821.17897
Overall Steps per Second: 10,334.56816

Timestep Collection Time: 2.29236
Timestep Consumption Time: 2.54790
PPO Batch Consumption Time: 0.29987
Total Iteration Time: 4.84026

Cumulative Model Updates: 57,686
Cumulative Timesteps: 481,201,664

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 481201664...
Checkpoint 481201664 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,138.48588
Policy Entropy: 3.38888
Value Function Loss: 0.00285

Mean KL Divergence: 0.00718
SB3 Clip Fraction: 0.08479
Policy Update Magnitude: 0.56686
Value Function Update Magnitude: 0.60845

Collected Steps per Second: 21,169.02288
Overall Steps per Second: 10,397.21262

Timestep Collection Time: 2.36194
Timestep Consumption Time: 2.44704
PPO Batch Consumption Time: 0.28129
Total Iteration Time: 4.80898

Cumulative Model Updates: 57,692
Cumulative Timesteps: 481,251,664

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,418.18560
Policy Entropy: 3.38768
Value Function Loss: 0.00312

Mean KL Divergence: 0.00745
SB3 Clip Fraction: 0.08661
Policy Update Magnitude: 0.57063
Value Function Update Magnitude: 0.59209

Collected Steps per Second: 22,497.66333
Overall Steps per Second: 10,633.17756

Timestep Collection Time: 2.22379
Timestep Consumption Time: 2.48130
PPO Batch Consumption Time: 0.29151
Total Iteration Time: 4.70508

Cumulative Model Updates: 57,698
Cumulative Timesteps: 481,301,694

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 481301694...
Checkpoint 481301694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,209.69620
Policy Entropy: 3.38537
Value Function Loss: 0.00319

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.10236
Policy Update Magnitude: 0.57190
Value Function Update Magnitude: 0.60249

Collected Steps per Second: 21,810.26318
Overall Steps per Second: 10,368.40177

Timestep Collection Time: 2.29387
Timestep Consumption Time: 2.53136
PPO Batch Consumption Time: 0.28465
Total Iteration Time: 4.82524

Cumulative Model Updates: 57,704
Cumulative Timesteps: 481,351,724

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 994.69969
Policy Entropy: 3.38872
Value Function Loss: 0.00328

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.10846
Policy Update Magnitude: 0.57442
Value Function Update Magnitude: 0.60491

Collected Steps per Second: 22,703.00388
Overall Steps per Second: 10,629.93841

Timestep Collection Time: 2.20288
Timestep Consumption Time: 2.50194
PPO Batch Consumption Time: 0.29071
Total Iteration Time: 4.70482

Cumulative Model Updates: 57,710
Cumulative Timesteps: 481,401,736

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 481401736...
Checkpoint 481401736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,417.46045
Policy Entropy: 3.38605
Value Function Loss: 0.00306

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.11066
Policy Update Magnitude: 0.56855
Value Function Update Magnitude: 0.60474

Collected Steps per Second: 21,732.23518
Overall Steps per Second: 10,570.95297

Timestep Collection Time: 2.30183
Timestep Consumption Time: 2.43038
PPO Batch Consumption Time: 0.28103
Total Iteration Time: 4.73221

Cumulative Model Updates: 57,716
Cumulative Timesteps: 481,451,760

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,461.05314
Policy Entropy: 3.39333
Value Function Loss: 0.00316

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.10656
Policy Update Magnitude: 0.56301
Value Function Update Magnitude: 0.61599

Collected Steps per Second: 22,810.22605
Overall Steps per Second: 10,449.14533

Timestep Collection Time: 2.19340
Timestep Consumption Time: 2.59474
PPO Batch Consumption Time: 0.30579
Total Iteration Time: 4.78814

Cumulative Model Updates: 57,722
Cumulative Timesteps: 481,501,792

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 481501792...
Checkpoint 481501792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,322.48379
Policy Entropy: 3.39667
Value Function Loss: 0.00305

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.09526
Policy Update Magnitude: 0.56548
Value Function Update Magnitude: 0.62669

Collected Steps per Second: 21,482.09444
Overall Steps per Second: 10,310.39466

Timestep Collection Time: 2.32836
Timestep Consumption Time: 2.52286
PPO Batch Consumption Time: 0.29537
Total Iteration Time: 4.85122

Cumulative Model Updates: 57,728
Cumulative Timesteps: 481,551,810

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,090.15670
Policy Entropy: 3.38642
Value Function Loss: 0.00322

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.09194
Policy Update Magnitude: 0.57147
Value Function Update Magnitude: 0.63639

Collected Steps per Second: 21,215.40956
Overall Steps per Second: 10,084.89958

Timestep Collection Time: 2.35810
Timestep Consumption Time: 2.60259
PPO Batch Consumption Time: 0.30559
Total Iteration Time: 4.96068

Cumulative Model Updates: 57,734
Cumulative Timesteps: 481,601,838

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 481601838...
Checkpoint 481601838 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,460.83880
Policy Entropy: 3.38822
Value Function Loss: 0.00320

Mean KL Divergence: 0.00737
SB3 Clip Fraction: 0.08659
Policy Update Magnitude: 0.57490
Value Function Update Magnitude: 0.63067

Collected Steps per Second: 18,638.00224
Overall Steps per Second: 9,598.36710

Timestep Collection Time: 2.68333
Timestep Consumption Time: 2.52713
PPO Batch Consumption Time: 0.29508
Total Iteration Time: 5.21047

Cumulative Model Updates: 57,740
Cumulative Timesteps: 481,651,850

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,100.70768
Policy Entropy: 3.37630
Value Function Loss: 0.00323

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.08545
Policy Update Magnitude: 0.56789
Value Function Update Magnitude: 0.63065

Collected Steps per Second: 21,499.81203
Overall Steps per Second: 10,071.08264

Timestep Collection Time: 2.32588
Timestep Consumption Time: 2.63942
PPO Batch Consumption Time: 0.31248
Total Iteration Time: 4.96531

Cumulative Model Updates: 57,746
Cumulative Timesteps: 481,701,856

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 481701856...
Checkpoint 481701856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 990.99090
Policy Entropy: 3.38771
Value Function Loss: 0.00334

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.09004
Policy Update Magnitude: 0.56669
Value Function Update Magnitude: 0.63386

Collected Steps per Second: 20,665.30003
Overall Steps per Second: 9,895.22720

Timestep Collection Time: 2.42019
Timestep Consumption Time: 2.63416
PPO Batch Consumption Time: 0.31375
Total Iteration Time: 5.05436

Cumulative Model Updates: 57,752
Cumulative Timesteps: 481,751,870

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,369.61584
Policy Entropy: 3.38501
Value Function Loss: 0.00330

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.11511
Policy Update Magnitude: 0.57153
Value Function Update Magnitude: 0.64875

Collected Steps per Second: 21,169.38756
Overall Steps per Second: 10,061.87715

Timestep Collection Time: 2.36313
Timestep Consumption Time: 2.60871
PPO Batch Consumption Time: 0.30682
Total Iteration Time: 4.97184

Cumulative Model Updates: 57,758
Cumulative Timesteps: 481,801,896

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 481801896...
Checkpoint 481801896 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 801.75714
Policy Entropy: 3.38303
Value Function Loss: 0.00327

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.09389
Policy Update Magnitude: 0.57217
Value Function Update Magnitude: 0.66592

Collected Steps per Second: 19,181.49346
Overall Steps per Second: 9,469.81640

Timestep Collection Time: 2.60699
Timestep Consumption Time: 2.67358
PPO Batch Consumption Time: 0.32121
Total Iteration Time: 5.28057

Cumulative Model Updates: 57,764
Cumulative Timesteps: 481,851,902

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,365.70172
Policy Entropy: 3.37708
Value Function Loss: 0.00309

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.10654
Policy Update Magnitude: 0.56703
Value Function Update Magnitude: 0.66639

Collected Steps per Second: 20,188.48128
Overall Steps per Second: 9,727.23718

Timestep Collection Time: 2.47666
Timestep Consumption Time: 2.66355
PPO Batch Consumption Time: 0.31773
Total Iteration Time: 5.14021

Cumulative Model Updates: 57,770
Cumulative Timesteps: 481,901,902

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 481901902...
Checkpoint 481901902 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,586.10004
Policy Entropy: 3.38505
Value Function Loss: 0.00285

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.10398
Policy Update Magnitude: 0.56024
Value Function Update Magnitude: 0.63881

Collected Steps per Second: 20,389.67552
Overall Steps per Second: 9,791.27370

Timestep Collection Time: 2.45281
Timestep Consumption Time: 2.65500
PPO Batch Consumption Time: 0.30881
Total Iteration Time: 5.10781

Cumulative Model Updates: 57,776
Cumulative Timesteps: 481,951,914

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,202.41132
Policy Entropy: 3.38306
Value Function Loss: 0.00282

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.09159
Policy Update Magnitude: 0.54773
Value Function Update Magnitude: 0.63229

Collected Steps per Second: 20,498.32256
Overall Steps per Second: 9,726.79757

Timestep Collection Time: 2.44137
Timestep Consumption Time: 2.70359
PPO Batch Consumption Time: 0.32299
Total Iteration Time: 5.14496

Cumulative Model Updates: 57,782
Cumulative Timesteps: 482,001,958

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 482001958...
Checkpoint 482001958 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,800.81809
Policy Entropy: 3.40103
Value Function Loss: 0.00282

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.09066
Policy Update Magnitude: 0.54986
Value Function Update Magnitude: 0.62505

Collected Steps per Second: 20,412.59109
Overall Steps per Second: 9,755.06335

Timestep Collection Time: 2.45064
Timestep Consumption Time: 2.67736
PPO Batch Consumption Time: 0.31987
Total Iteration Time: 5.12800

Cumulative Model Updates: 57,788
Cumulative Timesteps: 482,051,982

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,212.63549
Policy Entropy: 3.40066
Value Function Loss: 0.00300

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.09736
Policy Update Magnitude: 0.55118
Value Function Update Magnitude: 0.62030

Collected Steps per Second: 20,464.47106
Overall Steps per Second: 9,827.34894

Timestep Collection Time: 2.44375
Timestep Consumption Time: 2.64511
PPO Batch Consumption Time: 0.31330
Total Iteration Time: 5.08886

Cumulative Model Updates: 57,794
Cumulative Timesteps: 482,101,992

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 482101992...
Checkpoint 482101992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,798.44481
Policy Entropy: 3.39209
Value Function Loss: 0.00318

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.09986
Policy Update Magnitude: 0.55679
Value Function Update Magnitude: 0.62565

Collected Steps per Second: 19,264.95684
Overall Steps per Second: 9,585.04855

Timestep Collection Time: 2.59580
Timestep Consumption Time: 2.62149
PPO Batch Consumption Time: 0.30671
Total Iteration Time: 5.21729

Cumulative Model Updates: 57,800
Cumulative Timesteps: 482,152,000

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,630.62384
Policy Entropy: 3.39336
Value Function Loss: 0.00313

Mean KL Divergence: 0.00777
SB3 Clip Fraction: 0.08813
Policy Update Magnitude: 0.55930
Value Function Update Magnitude: 0.63158

Collected Steps per Second: 19,524.79668
Overall Steps per Second: 9,574.08089

Timestep Collection Time: 2.56167
Timestep Consumption Time: 2.66244
PPO Batch Consumption Time: 0.31297
Total Iteration Time: 5.22410

Cumulative Model Updates: 57,806
Cumulative Timesteps: 482,202,016

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 482202016...
Checkpoint 482202016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 908.54458
Policy Entropy: 3.38777
Value Function Loss: 0.00324

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.09921
Policy Update Magnitude: 0.56600
Value Function Update Magnitude: 0.64152

Collected Steps per Second: 19,184.02887
Overall Steps per Second: 9,273.74954

Timestep Collection Time: 2.60654
Timestep Consumption Time: 2.78545
PPO Batch Consumption Time: 0.33768
Total Iteration Time: 5.39199

Cumulative Model Updates: 57,812
Cumulative Timesteps: 482,252,020

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,534.34578
Policy Entropy: 3.39657
Value Function Loss: 0.00310

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.08884
Policy Update Magnitude: 0.56756
Value Function Update Magnitude: 0.64217

Collected Steps per Second: 20,401.47322
Overall Steps per Second: 9,834.44653

Timestep Collection Time: 2.45110
Timestep Consumption Time: 2.63368
PPO Batch Consumption Time: 0.30828
Total Iteration Time: 5.08478

Cumulative Model Updates: 57,818
Cumulative Timesteps: 482,302,026

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 482302026...
Checkpoint 482302026 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,045.98819
Policy Entropy: 3.39142
Value Function Loss: 0.00322

Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.09098
Policy Update Magnitude: 0.56514
Value Function Update Magnitude: 0.63519

Collected Steps per Second: 20,082.80183
Overall Steps per Second: 9,612.20016

Timestep Collection Time: 2.49168
Timestep Consumption Time: 2.71420
PPO Batch Consumption Time: 0.32322
Total Iteration Time: 5.20588

Cumulative Model Updates: 57,824
Cumulative Timesteps: 482,352,066

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,339.31966
Policy Entropy: 3.40246
Value Function Loss: 0.00312

Mean KL Divergence: 0.00721
SB3 Clip Fraction: 0.08312
Policy Update Magnitude: 0.56212
Value Function Update Magnitude: 0.64319

Collected Steps per Second: 20,601.69759
Overall Steps per Second: 9,823.24117

Timestep Collection Time: 2.42776
Timestep Consumption Time: 2.66384
PPO Batch Consumption Time: 0.31099
Total Iteration Time: 5.09160

Cumulative Model Updates: 57,830
Cumulative Timesteps: 482,402,082

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 482402082...
Checkpoint 482402082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,097.49536
Policy Entropy: 3.40578
Value Function Loss: 0.00307

Mean KL Divergence: 0.00710
SB3 Clip Fraction: 0.08059
Policy Update Magnitude: 0.56064
Value Function Update Magnitude: 0.66188

Collected Steps per Second: 19,847.26450
Overall Steps per Second: 9,457.36255

Timestep Collection Time: 2.51944
Timestep Consumption Time: 2.76787
PPO Batch Consumption Time: 0.33799
Total Iteration Time: 5.28731

Cumulative Model Updates: 57,836
Cumulative Timesteps: 482,452,086

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,385.78906
Policy Entropy: 3.40104
Value Function Loss: 0.00301

Mean KL Divergence: 0.00747
SB3 Clip Fraction: 0.08575
Policy Update Magnitude: 0.55939
Value Function Update Magnitude: 0.64731

Collected Steps per Second: 20,251.56959
Overall Steps per Second: 9,804.34348

Timestep Collection Time: 2.47043
Timestep Consumption Time: 2.63241
PPO Batch Consumption Time: 0.30952
Total Iteration Time: 5.10284

Cumulative Model Updates: 57,842
Cumulative Timesteps: 482,502,116

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 482502116...
Checkpoint 482502116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,495.14056
Policy Entropy: 3.41155
Value Function Loss: 0.00289

Mean KL Divergence: 0.00695
SB3 Clip Fraction: 0.08045
Policy Update Magnitude: 0.55281
Value Function Update Magnitude: 0.61416

Collected Steps per Second: 20,195.13894
Overall Steps per Second: 9,792.39565

Timestep Collection Time: 2.47723
Timestep Consumption Time: 2.63163
PPO Batch Consumption Time: 0.30512
Total Iteration Time: 5.10886

Cumulative Model Updates: 57,848
Cumulative Timesteps: 482,552,144

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,520.32080
Policy Entropy: 3.40406
Value Function Loss: 0.00308

Mean KL Divergence: 0.00700
SB3 Clip Fraction: 0.08067
Policy Update Magnitude: 0.54791
Value Function Update Magnitude: 0.60216

Collected Steps per Second: 19,789.58176
Overall Steps per Second: 9,592.76720

Timestep Collection Time: 2.52699
Timestep Consumption Time: 2.68611
PPO Batch Consumption Time: 0.31441
Total Iteration Time: 5.21309

Cumulative Model Updates: 57,854
Cumulative Timesteps: 482,602,152

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 482602152...
Checkpoint 482602152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,447.97864
Policy Entropy: 3.40603
Value Function Loss: 0.00317

Mean KL Divergence: 0.00703
SB3 Clip Fraction: 0.08197
Policy Update Magnitude: 0.55357
Value Function Update Magnitude: 0.60226

Collected Steps per Second: 19,659.51459
Overall Steps per Second: 9,415.23934

Timestep Collection Time: 2.54493
Timestep Consumption Time: 2.76901
PPO Batch Consumption Time: 0.32842
Total Iteration Time: 5.31394

Cumulative Model Updates: 57,860
Cumulative Timesteps: 482,652,184

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,264.50523
Policy Entropy: 3.39925
Value Function Loss: 0.00326

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.09161
Policy Update Magnitude: 0.56653
Value Function Update Magnitude: 0.62483

Collected Steps per Second: 19,843.77814
Overall Steps per Second: 9,610.65180

Timestep Collection Time: 2.52099
Timestep Consumption Time: 2.68427
PPO Batch Consumption Time: 0.31406
Total Iteration Time: 5.20527

Cumulative Model Updates: 57,866
Cumulative Timesteps: 482,702,210

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 482702210...
Checkpoint 482702210 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,701.02611
Policy Entropy: 3.39386
Value Function Loss: 0.00315

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.09382
Policy Update Magnitude: 0.57302
Value Function Update Magnitude: 0.62613

Collected Steps per Second: 19,683.72676
Overall Steps per Second: 9,622.27426

Timestep Collection Time: 2.54047
Timestep Consumption Time: 2.65643
PPO Batch Consumption Time: 0.30898
Total Iteration Time: 5.19690

Cumulative Model Updates: 57,872
Cumulative Timesteps: 482,752,216

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,000.26913
Policy Entropy: 3.38259
Value Function Loss: 0.00312

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.10027
Policy Update Magnitude: 0.56837
Value Function Update Magnitude: 0.62925

Collected Steps per Second: 20,657.14554
Overall Steps per Second: 9,771.08641

Timestep Collection Time: 2.42279
Timestep Consumption Time: 2.69926
PPO Batch Consumption Time: 0.31533
Total Iteration Time: 5.12205

Cumulative Model Updates: 57,878
Cumulative Timesteps: 482,802,264

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 482802264...
Checkpoint 482802264 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 920.66785
Policy Entropy: 3.37246
Value Function Loss: 0.00319

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.11592
Policy Update Magnitude: 0.57307
Value Function Update Magnitude: 0.62636

Collected Steps per Second: 19,319.90384
Overall Steps per Second: 9,562.35651

Timestep Collection Time: 2.58852
Timestep Consumption Time: 2.64136
PPO Batch Consumption Time: 0.31134
Total Iteration Time: 5.22988

Cumulative Model Updates: 57,884
Cumulative Timesteps: 482,852,274

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,396.98416
Policy Entropy: 3.38595
Value Function Loss: 0.00334

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.10224
Policy Update Magnitude: 0.57532
Value Function Update Magnitude: 0.62916

Collected Steps per Second: 19,892.15970
Overall Steps per Second: 9,585.13451

Timestep Collection Time: 2.51375
Timestep Consumption Time: 2.70307
PPO Batch Consumption Time: 0.31437
Total Iteration Time: 5.21683

Cumulative Model Updates: 57,890
Cumulative Timesteps: 482,902,278

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 482902278...
Checkpoint 482902278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,447.52919
Policy Entropy: 3.39267
Value Function Loss: 0.00326

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.10494
Policy Update Magnitude: 0.58006
Value Function Update Magnitude: 0.62832

Collected Steps per Second: 20,377.09150
Overall Steps per Second: 9,805.41842

Timestep Collection Time: 2.45423
Timestep Consumption Time: 2.64601
PPO Batch Consumption Time: 0.31728
Total Iteration Time: 5.10024

Cumulative Model Updates: 57,896
Cumulative Timesteps: 482,952,288

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 859.21878
Policy Entropy: 3.41223
Value Function Loss: 0.00302

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.09067
Policy Update Magnitude: 0.56887
Value Function Update Magnitude: 0.61926

Collected Steps per Second: 20,379.89779
Overall Steps per Second: 9,793.09871

Timestep Collection Time: 2.45428
Timestep Consumption Time: 2.65319
PPO Batch Consumption Time: 0.31005
Total Iteration Time: 5.10747

Cumulative Model Updates: 57,902
Cumulative Timesteps: 483,002,306

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 483002306...
Checkpoint 483002306 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,679.29137
Policy Entropy: 3.42883
Value Function Loss: 0.00298

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.09482
Policy Update Magnitude: 0.55231
Value Function Update Magnitude: 0.60200

Collected Steps per Second: 19,977.69811
Overall Steps per Second: 9,633.32402

Timestep Collection Time: 2.50409
Timestep Consumption Time: 2.68892
PPO Batch Consumption Time: 0.31848
Total Iteration Time: 5.19302

Cumulative Model Updates: 57,908
Cumulative Timesteps: 483,052,332

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,434.17756
Policy Entropy: 3.43270
Value Function Loss: 0.00298

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.09312
Policy Update Magnitude: 0.54853
Value Function Update Magnitude: 0.59619

Collected Steps per Second: 19,685.52050
Overall Steps per Second: 9,529.89237

Timestep Collection Time: 2.54075
Timestep Consumption Time: 2.70758
PPO Batch Consumption Time: 0.31603
Total Iteration Time: 5.24833

Cumulative Model Updates: 57,914
Cumulative Timesteps: 483,102,348

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 483102348...
Checkpoint 483102348 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,107.52491
Policy Entropy: 3.42727
Value Function Loss: 0.00319

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.10522
Policy Update Magnitude: 0.54698
Value Function Update Magnitude: 0.60558

Collected Steps per Second: 20,479.02640
Overall Steps per Second: 9,877.46617

Timestep Collection Time: 2.44182
Timestep Consumption Time: 2.62082
PPO Batch Consumption Time: 0.30668
Total Iteration Time: 5.06263

Cumulative Model Updates: 57,920
Cumulative Timesteps: 483,152,354

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 996.40384
Policy Entropy: 3.41581
Value Function Loss: 0.00315

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.10557
Policy Update Magnitude: 0.55185
Value Function Update Magnitude: 0.61226

Collected Steps per Second: 20,226.80835
Overall Steps per Second: 9,641.08113

Timestep Collection Time: 2.47226
Timestep Consumption Time: 2.71450
PPO Batch Consumption Time: 0.32011
Total Iteration Time: 5.18676

Cumulative Model Updates: 57,926
Cumulative Timesteps: 483,202,360

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 483202360...
Checkpoint 483202360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,160.83367
Policy Entropy: 3.41412
Value Function Loss: 0.00312

Mean KL Divergence: 0.00764
SB3 Clip Fraction: 0.08886
Policy Update Magnitude: 0.55299
Value Function Update Magnitude: 0.62355

Collected Steps per Second: 20,101.13499
Overall Steps per Second: 9,690.31426

Timestep Collection Time: 2.48842
Timestep Consumption Time: 2.67344
PPO Batch Consumption Time: 0.31285
Total Iteration Time: 5.16186

Cumulative Model Updates: 57,932
Cumulative Timesteps: 483,252,380

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,203.67003
Policy Entropy: 3.41242
Value Function Loss: 0.00314

Mean KL Divergence: 0.00701
SB3 Clip Fraction: 0.08078
Policy Update Magnitude: 0.55611
Value Function Update Magnitude: 0.62530

Collected Steps per Second: 19,226.38641
Overall Steps per Second: 9,430.54591

Timestep Collection Time: 2.60194
Timestep Consumption Time: 2.70273
PPO Batch Consumption Time: 0.32498
Total Iteration Time: 5.30468

Cumulative Model Updates: 57,938
Cumulative Timesteps: 483,302,406

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 483302406...
Checkpoint 483302406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,481.45579
Policy Entropy: 3.42486
Value Function Loss: 0.00325

Mean KL Divergence: 0.00736
SB3 Clip Fraction: 0.08484
Policy Update Magnitude: 0.56787
Value Function Update Magnitude: 0.63206

Collected Steps per Second: 19,858.11795
Overall Steps per Second: 9,697.54121

Timestep Collection Time: 2.51806
Timestep Consumption Time: 2.63830
PPO Batch Consumption Time: 0.31194
Total Iteration Time: 5.15636

Cumulative Model Updates: 57,944
Cumulative Timesteps: 483,352,410

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,092.58732
Policy Entropy: 3.42404
Value Function Loss: 0.00344

Mean KL Divergence: 0.00733
SB3 Clip Fraction: 0.08334
Policy Update Magnitude: 0.58101
Value Function Update Magnitude: 0.65910

Collected Steps per Second: 20,831.09064
Overall Steps per Second: 9,831.06727

Timestep Collection Time: 2.40131
Timestep Consumption Time: 2.68684
PPO Batch Consumption Time: 0.32161
Total Iteration Time: 5.08816

Cumulative Model Updates: 57,950
Cumulative Timesteps: 483,402,432

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 483402432...
Checkpoint 483402432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,066.75796
Policy Entropy: 3.43624
Value Function Loss: 0.00320

Mean KL Divergence: 0.00745
SB3 Clip Fraction: 0.08687
Policy Update Magnitude: 0.57664
Value Function Update Magnitude: 0.66547

Collected Steps per Second: 20,403.14989
Overall Steps per Second: 9,678.35326

Timestep Collection Time: 2.45099
Timestep Consumption Time: 2.71600
PPO Batch Consumption Time: 0.31988
Total Iteration Time: 5.16699

Cumulative Model Updates: 57,956
Cumulative Timesteps: 483,452,440

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,893.31492
Policy Entropy: 3.42438
Value Function Loss: 0.00318

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.08966
Policy Update Magnitude: 0.55932
Value Function Update Magnitude: 0.65088

Collected Steps per Second: 20,214.48953
Overall Steps per Second: 9,719.29243

Timestep Collection Time: 2.47476
Timestep Consumption Time: 2.67232
PPO Batch Consumption Time: 0.31545
Total Iteration Time: 5.14708

Cumulative Model Updates: 57,962
Cumulative Timesteps: 483,502,466

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 483502466...
Checkpoint 483502466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,181.98290
Policy Entropy: 3.43280
Value Function Loss: 0.00310

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.09028
Policy Update Magnitude: 0.55642
Value Function Update Magnitude: 0.64449

Collected Steps per Second: 20,379.31954
Overall Steps per Second: 9,852.58453

Timestep Collection Time: 2.45425
Timestep Consumption Time: 2.62218
PPO Batch Consumption Time: 0.31178
Total Iteration Time: 5.07643

Cumulative Model Updates: 57,968
Cumulative Timesteps: 483,552,482

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,889.29666
Policy Entropy: 3.42643
Value Function Loss: 0.00298

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.08991
Policy Update Magnitude: 0.55315
Value Function Update Magnitude: 0.63666

Collected Steps per Second: 20,590.57991
Overall Steps per Second: 9,785.79912

Timestep Collection Time: 2.42985
Timestep Consumption Time: 2.68287
PPO Batch Consumption Time: 0.31423
Total Iteration Time: 5.11271

Cumulative Model Updates: 57,974
Cumulative Timesteps: 483,602,514

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 483602514...
Checkpoint 483602514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 962.18955
Policy Entropy: 3.43092
Value Function Loss: 0.00316

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.09091
Policy Update Magnitude: 0.54766
Value Function Update Magnitude: 0.62065

Collected Steps per Second: 19,519.92809
Overall Steps per Second: 9,575.22483

Timestep Collection Time: 2.56261
Timestep Consumption Time: 2.66150
PPO Batch Consumption Time: 0.31697
Total Iteration Time: 5.22411

Cumulative Model Updates: 57,980
Cumulative Timesteps: 483,652,536

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,421.43712
Policy Entropy: 3.42545
Value Function Loss: 0.00307

Mean KL Divergence: 0.00763
SB3 Clip Fraction: 0.08697
Policy Update Magnitude: 0.54208
Value Function Update Magnitude: 0.61804

Collected Steps per Second: 20,291.55444
Overall Steps per Second: 9,612.03588

Timestep Collection Time: 2.46418
Timestep Consumption Time: 2.73784
PPO Batch Consumption Time: 0.32970
Total Iteration Time: 5.20202

Cumulative Model Updates: 57,986
Cumulative Timesteps: 483,702,538

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 483702538...
Checkpoint 483702538 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,749.20074
Policy Entropy: 3.41497
Value Function Loss: 0.00308

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.09166
Policy Update Magnitude: 0.54783
Value Function Update Magnitude: 0.60315

Collected Steps per Second: 19,875.74816
Overall Steps per Second: 9,614.55695

Timestep Collection Time: 2.51653
Timestep Consumption Time: 2.68579
PPO Batch Consumption Time: 0.32170
Total Iteration Time: 5.20232

Cumulative Model Updates: 57,992
Cumulative Timesteps: 483,752,556

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,811.60109
Policy Entropy: 3.41566
Value Function Loss: 0.00297

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.09159
Policy Update Magnitude: 0.54625
Value Function Update Magnitude: 0.57398

Collected Steps per Second: 21,008.50394
Overall Steps per Second: 10,044.94725

Timestep Collection Time: 2.38123
Timestep Consumption Time: 2.59899
PPO Batch Consumption Time: 0.30751
Total Iteration Time: 4.98022

Cumulative Model Updates: 57,998
Cumulative Timesteps: 483,802,582

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 483802582...
Checkpoint 483802582 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,715.91034
Policy Entropy: 3.41958
Value Function Loss: 0.00315

Mean KL Divergence: 0.01058
SB3 Clip Fraction: 0.11960
Policy Update Magnitude: 0.54504
Value Function Update Magnitude: 0.57368

Collected Steps per Second: 19,900.67961
Overall Steps per Second: 9,674.01004

Timestep Collection Time: 2.51348
Timestep Consumption Time: 2.65707
PPO Batch Consumption Time: 0.30890
Total Iteration Time: 5.17055

Cumulative Model Updates: 58,004
Cumulative Timesteps: 483,852,602

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 821.02811
Policy Entropy: 3.42812
Value Function Loss: 0.00307

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.10690
Policy Update Magnitude: 0.53946
Value Function Update Magnitude: 0.59461

Collected Steps per Second: 20,118.43293
Overall Steps per Second: 9,750.81645

Timestep Collection Time: 2.48588
Timestep Consumption Time: 2.64313
PPO Batch Consumption Time: 0.31070
Total Iteration Time: 5.12901

Cumulative Model Updates: 58,010
Cumulative Timesteps: 483,902,614

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 483902614...
Checkpoint 483902614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,340.06384
Policy Entropy: 3.43271
Value Function Loss: 0.00307

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.11663
Policy Update Magnitude: 0.53355
Value Function Update Magnitude: 0.60362

Collected Steps per Second: 19,264.94919
Overall Steps per Second: 9,475.02599

Timestep Collection Time: 2.59694
Timestep Consumption Time: 2.68325
PPO Batch Consumption Time: 0.31125
Total Iteration Time: 5.28020

Cumulative Model Updates: 58,016
Cumulative Timesteps: 483,952,644

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,161.69309
Policy Entropy: 3.43074
Value Function Loss: 0.00306

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.10717
Policy Update Magnitude: 0.53117
Value Function Update Magnitude: 0.61200

Collected Steps per Second: 21,582.49915
Overall Steps per Second: 10,364.67292

Timestep Collection Time: 2.31771
Timestep Consumption Time: 2.50849
PPO Batch Consumption Time: 0.29478
Total Iteration Time: 4.82620

Cumulative Model Updates: 58,022
Cumulative Timesteps: 484,002,666

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 484002666...
Checkpoint 484002666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 937.61378
Policy Entropy: 3.44071
Value Function Loss: 0.00301

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.09276
Policy Update Magnitude: 0.53239
Value Function Update Magnitude: 0.61764

Collected Steps per Second: 21,881.44268
Overall Steps per Second: 10,577.81024

Timestep Collection Time: 2.28559
Timestep Consumption Time: 2.44242
PPO Batch Consumption Time: 0.28596
Total Iteration Time: 4.72801

Cumulative Model Updates: 58,028
Cumulative Timesteps: 484,052,678

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,578.32661
Policy Entropy: 3.43514
Value Function Loss: 0.00303

Mean KL Divergence: 0.00762
SB3 Clip Fraction: 0.08970
Policy Update Magnitude: 0.53023
Value Function Update Magnitude: 0.61265

Collected Steps per Second: 22,482.96567
Overall Steps per Second: 10,512.01436

Timestep Collection Time: 2.22391
Timestep Consumption Time: 2.53256
PPO Batch Consumption Time: 0.29509
Total Iteration Time: 4.75646

Cumulative Model Updates: 58,034
Cumulative Timesteps: 484,102,678

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 484102678...
Checkpoint 484102678 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,143.80519
Policy Entropy: 3.43662
Value Function Loss: 0.00300

Mean KL Divergence: 0.00741
SB3 Clip Fraction: 0.08807
Policy Update Magnitude: 0.53272
Value Function Update Magnitude: 0.59367

Collected Steps per Second: 21,814.88539
Overall Steps per Second: 10,558.81392

Timestep Collection Time: 2.29229
Timestep Consumption Time: 2.44366
PPO Batch Consumption Time: 0.28510
Total Iteration Time: 4.73595

Cumulative Model Updates: 58,040
Cumulative Timesteps: 484,152,684

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,678.67157
Policy Entropy: 3.41127
Value Function Loss: 0.00301

Mean KL Divergence: 0.00736
SB3 Clip Fraction: 0.08539
Policy Update Magnitude: 0.53010
Value Function Update Magnitude: 0.58831

Collected Steps per Second: 22,135.06480
Overall Steps per Second: 10,234.05882

Timestep Collection Time: 2.25913
Timestep Consumption Time: 2.62710
PPO Batch Consumption Time: 0.31084
Total Iteration Time: 4.88623

Cumulative Model Updates: 58,046
Cumulative Timesteps: 484,202,690

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 484202690...
Checkpoint 484202690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,742.72962
Policy Entropy: 3.41153
Value Function Loss: 0.00309

Mean KL Divergence: 0.00735
SB3 Clip Fraction: 0.08529
Policy Update Magnitude: 0.53422
Value Function Update Magnitude: 0.59407

Collected Steps per Second: 19,529.85193
Overall Steps per Second: 9,603.61897

Timestep Collection Time: 2.56213
Timestep Consumption Time: 2.64820
PPO Batch Consumption Time: 0.31313
Total Iteration Time: 5.21033

Cumulative Model Updates: 58,052
Cumulative Timesteps: 484,252,728

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 746.74572
Policy Entropy: 3.41841
Value Function Loss: 0.00296

Mean KL Divergence: 0.00748
SB3 Clip Fraction: 0.08677
Policy Update Magnitude: 0.53859
Value Function Update Magnitude: 0.59473

Collected Steps per Second: 22,514.24691
Overall Steps per Second: 10,442.58571

Timestep Collection Time: 2.22215
Timestep Consumption Time: 2.56881
PPO Batch Consumption Time: 0.29534
Total Iteration Time: 4.79096

Cumulative Model Updates: 58,058
Cumulative Timesteps: 484,302,758

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 484302758...
Checkpoint 484302758 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,576.44999
Policy Entropy: 3.43178
Value Function Loss: 0.00288

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.09648
Policy Update Magnitude: 0.53988
Value Function Update Magnitude: 0.57589

Collected Steps per Second: 22,206.52916
Overall Steps per Second: 10,646.49504

Timestep Collection Time: 2.25195
Timestep Consumption Time: 2.44518
PPO Batch Consumption Time: 0.28124
Total Iteration Time: 4.69713

Cumulative Model Updates: 58,064
Cumulative Timesteps: 484,352,766

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,160.14073
Policy Entropy: 3.43691
Value Function Loss: 0.00301

Mean KL Divergence: 0.00747
SB3 Clip Fraction: 0.08535
Policy Update Magnitude: 0.53127
Value Function Update Magnitude: 0.56078

Collected Steps per Second: 22,468.63115
Overall Steps per Second: 10,582.03185

Timestep Collection Time: 2.22666
Timestep Consumption Time: 2.50117
PPO Batch Consumption Time: 0.29580
Total Iteration Time: 4.72783

Cumulative Model Updates: 58,070
Cumulative Timesteps: 484,402,796

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 484402796...
Checkpoint 484402796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,679.26534
Policy Entropy: 3.42917
Value Function Loss: 0.00303

Mean KL Divergence: 0.00752
SB3 Clip Fraction: 0.08686
Policy Update Magnitude: 0.53194
Value Function Update Magnitude: 0.57895

Collected Steps per Second: 22,064.38708
Overall Steps per Second: 10,598.59737

Timestep Collection Time: 2.26646
Timestep Consumption Time: 2.45190
PPO Batch Consumption Time: 0.28468
Total Iteration Time: 4.71836

Cumulative Model Updates: 58,076
Cumulative Timesteps: 484,452,804

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,439.21894
Policy Entropy: 3.42176
Value Function Loss: 0.00316

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.08878
Policy Update Magnitude: 0.54060
Value Function Update Magnitude: 0.58629

Collected Steps per Second: 22,565.81044
Overall Steps per Second: 10,776.48417

Timestep Collection Time: 2.21610
Timestep Consumption Time: 2.42438
PPO Batch Consumption Time: 0.28126
Total Iteration Time: 4.64047

Cumulative Model Updates: 58,082
Cumulative Timesteps: 484,502,812

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 484502812...
Checkpoint 484502812 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,049.34486
Policy Entropy: 3.41854
Value Function Loss: 0.00312

Mean KL Divergence: 0.00741
SB3 Clip Fraction: 0.08734
Policy Update Magnitude: 0.54769
Value Function Update Magnitude: 0.60576

Collected Steps per Second: 21,904.97623
Overall Steps per Second: 10,634.57402

Timestep Collection Time: 2.28359
Timestep Consumption Time: 2.42012
PPO Batch Consumption Time: 0.28159
Total Iteration Time: 4.70371

Cumulative Model Updates: 58,088
Cumulative Timesteps: 484,552,834

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,411.87790
Policy Entropy: 3.42799
Value Function Loss: 0.00320

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.08799
Policy Update Magnitude: 0.55006
Value Function Update Magnitude: 0.60943

Collected Steps per Second: 22,428.40889
Overall Steps per Second: 10,573.68186

Timestep Collection Time: 2.23003
Timestep Consumption Time: 2.50021
PPO Batch Consumption Time: 0.29541
Total Iteration Time: 4.73023

Cumulative Model Updates: 58,094
Cumulative Timesteps: 484,602,850

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 484602850...
Checkpoint 484602850 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,437.50467
Policy Entropy: 3.43870
Value Function Loss: 0.00322

Mean KL Divergence: 0.00717
SB3 Clip Fraction: 0.08417
Policy Update Magnitude: 0.55476
Value Function Update Magnitude: 0.61527

Collected Steps per Second: 22,279.93984
Overall Steps per Second: 10,656.91606

Timestep Collection Time: 2.24561
Timestep Consumption Time: 2.44918
PPO Batch Consumption Time: 0.28755
Total Iteration Time: 4.69479

Cumulative Model Updates: 58,100
Cumulative Timesteps: 484,652,882

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,565.65295
Policy Entropy: 3.43450
Value Function Loss: 0.00323

Mean KL Divergence: 0.00728
SB3 Clip Fraction: 0.08394
Policy Update Magnitude: 0.55090
Value Function Update Magnitude: 0.60537

Collected Steps per Second: 22,631.87228
Overall Steps per Second: 10,816.23594

Timestep Collection Time: 2.21016
Timestep Consumption Time: 2.41437
PPO Batch Consumption Time: 0.28070
Total Iteration Time: 4.62453

Cumulative Model Updates: 58,106
Cumulative Timesteps: 484,702,902

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 484702902...
Checkpoint 484702902 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,071.70943
Policy Entropy: 3.44115
Value Function Loss: 0.00321

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.09499
Policy Update Magnitude: 0.55121
Value Function Update Magnitude: 0.61105

Collected Steps per Second: 21,909.39842
Overall Steps per Second: 10,649.85747

Timestep Collection Time: 2.28240
Timestep Consumption Time: 2.41306
PPO Batch Consumption Time: 0.28189
Total Iteration Time: 4.69546

Cumulative Model Updates: 58,112
Cumulative Timesteps: 484,752,908

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,637.66620
Policy Entropy: 3.44326
Value Function Loss: 0.00316

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.09079
Policy Update Magnitude: 0.55346
Value Function Update Magnitude: 0.62012

Collected Steps per Second: 22,734.97887
Overall Steps per Second: 10,696.56172

Timestep Collection Time: 2.20013
Timestep Consumption Time: 2.47613
PPO Batch Consumption Time: 0.29189
Total Iteration Time: 4.67627

Cumulative Model Updates: 58,118
Cumulative Timesteps: 484,802,928

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 484802928...
Checkpoint 484802928 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 997.75550
Policy Entropy: 3.44832
Value Function Loss: 0.00315

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.09161
Policy Update Magnitude: 0.55858
Value Function Update Magnitude: 0.61872

Collected Steps per Second: 22,378.13665
Overall Steps per Second: 10,645.80266

Timestep Collection Time: 2.23549
Timestep Consumption Time: 2.46364
PPO Batch Consumption Time: 0.29075
Total Iteration Time: 4.69913

Cumulative Model Updates: 58,124
Cumulative Timesteps: 484,852,954

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 828.15352
Policy Entropy: 3.45585
Value Function Loss: 0.00321

Mean KL Divergence: 0.00736
SB3 Clip Fraction: 0.08629
Policy Update Magnitude: 0.56520
Value Function Update Magnitude: 0.62540

Collected Steps per Second: 23,055.37128
Overall Steps per Second: 10,696.67289

Timestep Collection Time: 2.16991
Timestep Consumption Time: 2.50706
PPO Batch Consumption Time: 0.29512
Total Iteration Time: 4.67697

Cumulative Model Updates: 58,130
Cumulative Timesteps: 484,902,982

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 484902982...
Checkpoint 484902982 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 920.85116
Policy Entropy: 3.45394
Value Function Loss: 0.00320

Mean KL Divergence: 0.00750
SB3 Clip Fraction: 0.08695
Policy Update Magnitude: 0.56231
Value Function Update Magnitude: 0.62248

Collected Steps per Second: 21,960.69534
Overall Steps per Second: 10,504.18095

Timestep Collection Time: 2.27789
Timestep Consumption Time: 2.48441
PPO Batch Consumption Time: 0.29390
Total Iteration Time: 4.76229

Cumulative Model Updates: 58,136
Cumulative Timesteps: 484,953,006

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,363.15711
Policy Entropy: 3.45262
Value Function Loss: 0.00332

Mean KL Divergence: 0.00752
SB3 Clip Fraction: 0.08890
Policy Update Magnitude: 0.56927
Value Function Update Magnitude: 0.63648

Collected Steps per Second: 22,520.33449
Overall Steps per Second: 10,600.08789

Timestep Collection Time: 2.22030
Timestep Consumption Time: 2.49683
PPO Batch Consumption Time: 0.29507
Total Iteration Time: 4.71713

Cumulative Model Updates: 58,142
Cumulative Timesteps: 485,003,008

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 485003008...
Checkpoint 485003008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,281.60416
Policy Entropy: 3.43726
Value Function Loss: 0.00328

Mean KL Divergence: 0.00749
SB3 Clip Fraction: 0.08655
Policy Update Magnitude: 0.57032
Value Function Update Magnitude: 0.66865

Collected Steps per Second: 22,310.39112
Overall Steps per Second: 10,656.91564

Timestep Collection Time: 2.24156
Timestep Consumption Time: 2.45117
PPO Batch Consumption Time: 0.28725
Total Iteration Time: 4.69273

Cumulative Model Updates: 58,148
Cumulative Timesteps: 485,053,018

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,510.53998
Policy Entropy: 3.44002
Value Function Loss: 0.00293

Mean KL Divergence: 0.00722
SB3 Clip Fraction: 0.08380
Policy Update Magnitude: 0.56284
Value Function Update Magnitude: 0.66466

Collected Steps per Second: 22,849.19545
Overall Steps per Second: 10,670.26302

Timestep Collection Time: 2.18896
Timestep Consumption Time: 2.49846
PPO Batch Consumption Time: 0.28856
Total Iteration Time: 4.68742

Cumulative Model Updates: 58,154
Cumulative Timesteps: 485,103,034

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 485103034...
Checkpoint 485103034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,538.70346
Policy Entropy: 3.43364
Value Function Loss: 0.00272

Mean KL Divergence: 0.00709
SB3 Clip Fraction: 0.08305
Policy Update Magnitude: 0.54838
Value Function Update Magnitude: 0.63037

Collected Steps per Second: 22,397.96187
Overall Steps per Second: 10,560.41557

Timestep Collection Time: 2.23342
Timestep Consumption Time: 2.50352
PPO Batch Consumption Time: 0.29214
Total Iteration Time: 4.73693

Cumulative Model Updates: 58,160
Cumulative Timesteps: 485,153,058

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,536.17326
Policy Entropy: 3.44653
Value Function Loss: 0.00291

Mean KL Divergence: 0.00673
SB3 Clip Fraction: 0.07836
Policy Update Magnitude: 0.54684
Value Function Update Magnitude: 0.59061

Collected Steps per Second: 22,993.62147
Overall Steps per Second: 10,743.20370

Timestep Collection Time: 2.17495
Timestep Consumption Time: 2.48009
PPO Batch Consumption Time: 0.28460
Total Iteration Time: 4.65504

Cumulative Model Updates: 58,166
Cumulative Timesteps: 485,203,068

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 485203068...
Checkpoint 485203068 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,094.26009
Policy Entropy: 3.43564
Value Function Loss: 0.00316

Mean KL Divergence: 0.00715
SB3 Clip Fraction: 0.08228
Policy Update Magnitude: 0.55829
Value Function Update Magnitude: 0.61344

Collected Steps per Second: 22,550.62552
Overall Steps per Second: 10,656.70399

Timestep Collection Time: 2.21803
Timestep Consumption Time: 2.47554
PPO Batch Consumption Time: 0.29199
Total Iteration Time: 4.69357

Cumulative Model Updates: 58,172
Cumulative Timesteps: 485,253,086

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,262.15485
Policy Entropy: 3.44246
Value Function Loss: 0.00331

Mean KL Divergence: 0.00665
SB3 Clip Fraction: 0.07656
Policy Update Magnitude: 0.56707
Value Function Update Magnitude: 0.62013

Collected Steps per Second: 22,495.08173
Overall Steps per Second: 10,654.28505

Timestep Collection Time: 2.22289
Timestep Consumption Time: 2.47044
PPO Batch Consumption Time: 0.29000
Total Iteration Time: 4.69332

Cumulative Model Updates: 58,178
Cumulative Timesteps: 485,303,090

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 485303090...
Checkpoint 485303090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,081.41993
Policy Entropy: 3.43859
Value Function Loss: 0.00326

Mean KL Divergence: 0.00716
SB3 Clip Fraction: 0.08418
Policy Update Magnitude: 0.56858
Value Function Update Magnitude: 0.62399

Collected Steps per Second: 22,539.68867
Overall Steps per Second: 10,666.17926

Timestep Collection Time: 2.22035
Timestep Consumption Time: 2.47168
PPO Batch Consumption Time: 0.28932
Total Iteration Time: 4.69203

Cumulative Model Updates: 58,184
Cumulative Timesteps: 485,353,136

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,153.48058
Policy Entropy: 3.43079
Value Function Loss: 0.00326

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.09942
Policy Update Magnitude: 0.56468
Value Function Update Magnitude: 0.61824

Collected Steps per Second: 22,831.72229
Overall Steps per Second: 10,691.49169

Timestep Collection Time: 2.19116
Timestep Consumption Time: 2.48807
PPO Batch Consumption Time: 0.29347
Total Iteration Time: 4.67923

Cumulative Model Updates: 58,190
Cumulative Timesteps: 485,403,164

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 485403164...
Checkpoint 485403164 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,152.86549
Policy Entropy: 3.41957
Value Function Loss: 0.00324

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.10202
Policy Update Magnitude: 0.56485
Value Function Update Magnitude: 0.62595

Collected Steps per Second: 22,263.32229
Overall Steps per Second: 10,657.95704

Timestep Collection Time: 2.24585
Timestep Consumption Time: 2.44548
PPO Batch Consumption Time: 0.28639
Total Iteration Time: 4.69133

Cumulative Model Updates: 58,196
Cumulative Timesteps: 485,453,164

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,022.79514
Policy Entropy: 3.41747
Value Function Loss: 0.00318

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.09408
Policy Update Magnitude: 0.56616
Value Function Update Magnitude: 0.63218

Collected Steps per Second: 22,845.82748
Overall Steps per Second: 10,848.95997

Timestep Collection Time: 2.18928
Timestep Consumption Time: 2.42093
PPO Batch Consumption Time: 0.28140
Total Iteration Time: 4.61021

Cumulative Model Updates: 58,202
Cumulative Timesteps: 485,503,180

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 485503180...
Checkpoint 485503180 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,307.23789
Policy Entropy: 3.42981
Value Function Loss: 0.00331

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.09140
Policy Update Magnitude: 0.56851
Value Function Update Magnitude: 0.61799

Collected Steps per Second: 22,302.77513
Overall Steps per Second: 10,681.85469

Timestep Collection Time: 2.24250
Timestep Consumption Time: 2.43964
PPO Batch Consumption Time: 0.28516
Total Iteration Time: 4.68215

Cumulative Model Updates: 58,208
Cumulative Timesteps: 485,553,194

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 863.98572
Policy Entropy: 3.43745
Value Function Loss: 0.00326

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.09493
Policy Update Magnitude: 0.56757
Value Function Update Magnitude: 0.61132

Collected Steps per Second: 22,619.56443
Overall Steps per Second: 10,721.65000

Timestep Collection Time: 2.21136
Timestep Consumption Time: 2.45397
PPO Batch Consumption Time: 0.28824
Total Iteration Time: 4.66533

Cumulative Model Updates: 58,214
Cumulative Timesteps: 485,603,214

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 485603214...
Checkpoint 485603214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 935.96390
Policy Entropy: 3.44028
Value Function Loss: 0.00309

Mean KL Divergence: 0.00743
SB3 Clip Fraction: 0.08789
Policy Update Magnitude: 0.55605
Value Function Update Magnitude: 0.61365

Collected Steps per Second: 22,151.24448
Overall Steps per Second: 10,628.16077

Timestep Collection Time: 2.25739
Timestep Consumption Time: 2.44747
PPO Batch Consumption Time: 0.28918
Total Iteration Time: 4.70486

Cumulative Model Updates: 58,220
Cumulative Timesteps: 485,653,218

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,664.97105
Policy Entropy: 3.43474
Value Function Loss: 0.00301

Mean KL Divergence: 0.00750
SB3 Clip Fraction: 0.09008
Policy Update Magnitude: 0.54531
Value Function Update Magnitude: 0.60828

Collected Steps per Second: 23,203.14876
Overall Steps per Second: 10,784.18743

Timestep Collection Time: 2.15574
Timestep Consumption Time: 2.48253
PPO Batch Consumption Time: 0.29436
Total Iteration Time: 4.63827

Cumulative Model Updates: 58,226
Cumulative Timesteps: 485,703,238

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 485703238...
Checkpoint 485703238 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,320.08756
Policy Entropy: 3.43453
Value Function Loss: 0.00290

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.08960
Policy Update Magnitude: 0.54449
Value Function Update Magnitude: 0.61275

Collected Steps per Second: 22,493.85398
Overall Steps per Second: 10,629.91974

Timestep Collection Time: 2.22416
Timestep Consumption Time: 2.48236
PPO Batch Consumption Time: 0.29483
Total Iteration Time: 4.70653

Cumulative Model Updates: 58,232
Cumulative Timesteps: 485,753,268

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 958.23467
Policy Entropy: 3.43233
Value Function Loss: 0.00295

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.09460
Policy Update Magnitude: 0.54714
Value Function Update Magnitude: 0.62542

Collected Steps per Second: 22,857.38309
Overall Steps per Second: 10,793.69687

Timestep Collection Time: 2.18835
Timestep Consumption Time: 2.44583
PPO Batch Consumption Time: 0.28143
Total Iteration Time: 4.63419

Cumulative Model Updates: 58,238
Cumulative Timesteps: 485,803,288

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 485803288...
Checkpoint 485803288 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,455.15528
Policy Entropy: 3.43421
Value Function Loss: 0.00299

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.09789
Policy Update Magnitude: 0.54790
Value Function Update Magnitude: 0.62441

Collected Steps per Second: 22,226.56975
Overall Steps per Second: 10,650.27786

Timestep Collection Time: 2.25109
Timestep Consumption Time: 2.44682
PPO Batch Consumption Time: 0.28123
Total Iteration Time: 4.69791

Cumulative Model Updates: 58,244
Cumulative Timesteps: 485,853,322

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,179.82561
Policy Entropy: 3.43857
Value Function Loss: 0.00296

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.09501
Policy Update Magnitude: 0.54032
Value Function Update Magnitude: 0.60479

Collected Steps per Second: 22,678.03228
Overall Steps per Second: 10,620.71642

Timestep Collection Time: 2.20601
Timestep Consumption Time: 2.50441
PPO Batch Consumption Time: 0.29249
Total Iteration Time: 4.71042

Cumulative Model Updates: 58,250
Cumulative Timesteps: 485,903,350

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 485903350...
Checkpoint 485903350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,976.58120
Policy Entropy: 3.43059
Value Function Loss: 0.00301

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.09776
Policy Update Magnitude: 0.53381
Value Function Update Magnitude: 0.58001

Collected Steps per Second: 22,069.08432
Overall Steps per Second: 10,498.44261

Timestep Collection Time: 2.26634
Timestep Consumption Time: 2.49780
PPO Batch Consumption Time: 0.29126
Total Iteration Time: 4.76414

Cumulative Model Updates: 58,256
Cumulative Timesteps: 485,953,366

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,381.75542
Policy Entropy: 3.41564
Value Function Loss: 0.00300

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.10690
Policy Update Magnitude: 0.54108
Value Function Update Magnitude: 0.58938

Collected Steps per Second: 22,520.44232
Overall Steps per Second: 10,551.24999

Timestep Collection Time: 2.22171
Timestep Consumption Time: 2.52028
PPO Batch Consumption Time: 0.29442
Total Iteration Time: 4.74200

Cumulative Model Updates: 58,262
Cumulative Timesteps: 486,003,400

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 486003400...
Checkpoint 486003400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,932.35142
Policy Entropy: 3.41402
Value Function Loss: 0.00309

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.10466
Policy Update Magnitude: 0.54475
Value Function Update Magnitude: 0.59870

Collected Steps per Second: 22,337.71559
Overall Steps per Second: 10,555.42550

Timestep Collection Time: 2.23899
Timestep Consumption Time: 2.49923
PPO Batch Consumption Time: 0.29113
Total Iteration Time: 4.73823

Cumulative Model Updates: 58,268
Cumulative Timesteps: 486,053,414

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 685.18625
Policy Entropy: 3.40981
Value Function Loss: 0.00300

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.11222
Policy Update Magnitude: 0.55189
Value Function Update Magnitude: 0.60882

Collected Steps per Second: 22,328.52500
Overall Steps per Second: 10,500.28837

Timestep Collection Time: 2.23956
Timestep Consumption Time: 2.52279
PPO Batch Consumption Time: 0.29476
Total Iteration Time: 4.76235

Cumulative Model Updates: 58,274
Cumulative Timesteps: 486,103,420

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 486103420...
Checkpoint 486103420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 879.98829
Policy Entropy: 3.41934
Value Function Loss: 0.00292

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.10484
Policy Update Magnitude: 0.56147
Value Function Update Magnitude: 0.62525

Collected Steps per Second: 22,794.66783
Overall Steps per Second: 10,605.48573

Timestep Collection Time: 2.19472
Timestep Consumption Time: 2.52246
PPO Batch Consumption Time: 0.29394
Total Iteration Time: 4.71718

Cumulative Model Updates: 58,280
Cumulative Timesteps: 486,153,448

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,138.67180
Policy Entropy: 3.41480
Value Function Loss: 0.00281

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.10761
Policy Update Magnitude: 0.55263
Value Function Update Magnitude: 0.62288

Collected Steps per Second: 22,330.20737
Overall Steps per Second: 10,498.23256

Timestep Collection Time: 2.23957
Timestep Consumption Time: 2.52409
PPO Batch Consumption Time: 0.29474
Total Iteration Time: 4.76366

Cumulative Model Updates: 58,286
Cumulative Timesteps: 486,203,458

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 486203458...
Checkpoint 486203458 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,545.77067
Policy Entropy: 3.41108
Value Function Loss: 0.00282

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.09581
Policy Update Magnitude: 0.54759
Value Function Update Magnitude: 0.61847

Collected Steps per Second: 22,164.41456
Overall Steps per Second: 10,536.83657

Timestep Collection Time: 2.25641
Timestep Consumption Time: 2.48999
PPO Batch Consumption Time: 0.29002
Total Iteration Time: 4.74640

Cumulative Model Updates: 58,292
Cumulative Timesteps: 486,253,470

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,077.97755
Policy Entropy: 3.41932
Value Function Loss: 0.00279

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.09020
Policy Update Magnitude: 0.54575
Value Function Update Magnitude: 0.61373

Collected Steps per Second: 22,471.82129
Overall Steps per Second: 10,554.68975

Timestep Collection Time: 2.22643
Timestep Consumption Time: 2.51383
PPO Batch Consumption Time: 0.29415
Total Iteration Time: 4.74026

Cumulative Model Updates: 58,298
Cumulative Timesteps: 486,303,502

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 486303502...
Checkpoint 486303502 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,121.44156
Policy Entropy: 3.42800
Value Function Loss: 0.00268

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.10121
Policy Update Magnitude: 0.53335
Value Function Update Magnitude: 0.61937

Collected Steps per Second: 22,363.13111
Overall Steps per Second: 10,592.18689

Timestep Collection Time: 2.23672
Timestep Consumption Time: 2.48563
PPO Batch Consumption Time: 0.28958
Total Iteration Time: 4.72235

Cumulative Model Updates: 58,304
Cumulative Timesteps: 486,353,522

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,258.95991
Policy Entropy: 3.42633
Value Function Loss: 0.00320

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.09049
Policy Update Magnitude: 0.54058
Value Function Update Magnitude: 0.65456

Collected Steps per Second: 22,480.35059
Overall Steps per Second: 10,582.42987

Timestep Collection Time: 2.22523
Timestep Consumption Time: 2.50185
PPO Batch Consumption Time: 0.29288
Total Iteration Time: 4.72708

Cumulative Model Updates: 58,310
Cumulative Timesteps: 486,403,546

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 486403546...
Checkpoint 486403546 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,602.27454
Policy Entropy: 3.41252
Value Function Loss: 0.00323

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.09583
Policy Update Magnitude: 0.56554
Value Function Update Magnitude: 0.69144

Collected Steps per Second: 21,383.56495
Overall Steps per Second: 10,471.57217

Timestep Collection Time: 2.33965
Timestep Consumption Time: 2.43805
PPO Batch Consumption Time: 0.28058
Total Iteration Time: 4.77770

Cumulative Model Updates: 58,316
Cumulative Timesteps: 486,453,576

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,870.70612
Policy Entropy: 3.40163
Value Function Loss: 0.00328

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.10108
Policy Update Magnitude: 0.57617
Value Function Update Magnitude: 0.69487

Collected Steps per Second: 22,626.49833
Overall Steps per Second: 10,681.38463

Timestep Collection Time: 2.20989
Timestep Consumption Time: 2.47134
PPO Batch Consumption Time: 0.29153
Total Iteration Time: 4.68123

Cumulative Model Updates: 58,322
Cumulative Timesteps: 486,503,578

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 486503578...
Checkpoint 486503578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 845.70437
Policy Entropy: 3.40668
Value Function Loss: 0.00309

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.09786
Policy Update Magnitude: 0.56991
Value Function Update Magnitude: 0.64952

Collected Steps per Second: 22,577.47992
Overall Steps per Second: 10,605.36068

Timestep Collection Time: 2.21539
Timestep Consumption Time: 2.50090
PPO Batch Consumption Time: 0.29154
Total Iteration Time: 4.71629

Cumulative Model Updates: 58,328
Cumulative Timesteps: 486,553,596

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,804.38339
Policy Entropy: 3.41621
Value Function Loss: 0.00296

Mean KL Divergence: 0.00752
SB3 Clip Fraction: 0.08932
Policy Update Magnitude: 0.56060
Value Function Update Magnitude: 0.61329

Collected Steps per Second: 22,785.15713
Overall Steps per Second: 10,809.40298

Timestep Collection Time: 2.19599
Timestep Consumption Time: 2.43294
PPO Batch Consumption Time: 0.27982
Total Iteration Time: 4.62893

Cumulative Model Updates: 58,334
Cumulative Timesteps: 486,603,632

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 486603632...
Checkpoint 486603632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,548.10250
Policy Entropy: 3.42295
Value Function Loss: 0.00282

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.09504
Policy Update Magnitude: 0.54766
Value Function Update Magnitude: 0.59467

Collected Steps per Second: 22,255.85888
Overall Steps per Second: 10,596.76922

Timestep Collection Time: 2.24669
Timestep Consumption Time: 2.47192
PPO Batch Consumption Time: 0.28729
Total Iteration Time: 4.71861

Cumulative Model Updates: 58,340
Cumulative Timesteps: 486,653,634

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 805.56596
Policy Entropy: 3.42251
Value Function Loss: 0.00291

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.10150
Policy Update Magnitude: 0.54752
Value Function Update Magnitude: 0.60377

Collected Steps per Second: 23,017.40626
Overall Steps per Second: 10,926.00479

Timestep Collection Time: 2.17305
Timestep Consumption Time: 2.40483
PPO Batch Consumption Time: 0.27982
Total Iteration Time: 4.57789

Cumulative Model Updates: 58,346
Cumulative Timesteps: 486,703,652

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 486703652...
Checkpoint 486703652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 831.88606
Policy Entropy: 3.41522
Value Function Loss: 0.00319

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.09728
Policy Update Magnitude: 0.56108
Value Function Update Magnitude: 0.62468

Collected Steps per Second: 22,114.86107
Overall Steps per Second: 10,599.69099

Timestep Collection Time: 2.26119
Timestep Consumption Time: 2.45649
PPO Batch Consumption Time: 0.28854
Total Iteration Time: 4.71768

Cumulative Model Updates: 58,352
Cumulative Timesteps: 486,753,658

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,111.84065
Policy Entropy: 3.40562
Value Function Loss: 0.00328

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.11381
Policy Update Magnitude: 0.56753
Value Function Update Magnitude: 0.65686

Collected Steps per Second: 22,165.82819
Overall Steps per Second: 10,542.63485

Timestep Collection Time: 2.25690
Timestep Consumption Time: 2.48822
PPO Batch Consumption Time: 0.29407
Total Iteration Time: 4.74511

Cumulative Model Updates: 58,358
Cumulative Timesteps: 486,803,684

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 486803684...
Checkpoint 486803684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 996.14962
Policy Entropy: 3.41070
Value Function Loss: 0.00321

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.11623
Policy Update Magnitude: 0.56550
Value Function Update Magnitude: 0.70189

Collected Steps per Second: 22,282.10089
Overall Steps per Second: 10,553.87214

Timestep Collection Time: 2.24476
Timestep Consumption Time: 2.49454
PPO Batch Consumption Time: 0.28974
Total Iteration Time: 4.73930

Cumulative Model Updates: 58,364
Cumulative Timesteps: 486,853,702

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,288.01582
Policy Entropy: 3.42295
Value Function Loss: 0.00299

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.10988
Policy Update Magnitude: 0.54776
Value Function Update Magnitude: 0.67277

Collected Steps per Second: 22,651.99841
Overall Steps per Second: 10,356.01220

Timestep Collection Time: 2.20811
Timestep Consumption Time: 2.62175
PPO Batch Consumption Time: 0.30840
Total Iteration Time: 4.82985

Cumulative Model Updates: 58,370
Cumulative Timesteps: 486,903,720

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 486903720...
Checkpoint 486903720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 995.93076
Policy Entropy: 3.43042
Value Function Loss: 0.00292

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.10294
Policy Update Magnitude: 0.53188
Value Function Update Magnitude: 0.61843

Collected Steps per Second: 21,551.34534
Overall Steps per Second: 10,393.42828

Timestep Collection Time: 2.32134
Timestep Consumption Time: 2.49209
PPO Batch Consumption Time: 0.29190
Total Iteration Time: 4.81343

Cumulative Model Updates: 58,376
Cumulative Timesteps: 486,953,748

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,210.05587
Policy Entropy: 3.42919
Value Function Loss: 0.00303

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.11553
Policy Update Magnitude: 0.52877
Value Function Update Magnitude: 0.58867

Collected Steps per Second: 22,698.01665
Overall Steps per Second: 10,847.84858

Timestep Collection Time: 2.20389
Timestep Consumption Time: 2.40753
PPO Batch Consumption Time: 0.28046
Total Iteration Time: 4.61142

Cumulative Model Updates: 58,382
Cumulative Timesteps: 487,003,772

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 487003772...
Checkpoint 487003772 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,503.71046
Policy Entropy: 3.43483
Value Function Loss: 0.00304

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.10481
Policy Update Magnitude: 0.53255
Value Function Update Magnitude: 0.61520

Collected Steps per Second: 22,386.05272
Overall Steps per Second: 10,690.87051

Timestep Collection Time: 2.23362
Timestep Consumption Time: 2.44345
PPO Batch Consumption Time: 0.28670
Total Iteration Time: 4.67707

Cumulative Model Updates: 58,388
Cumulative Timesteps: 487,053,774

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,199.89691
Policy Entropy: 3.43336
Value Function Loss: 0.00307

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.11491
Policy Update Magnitude: 0.54402
Value Function Update Magnitude: 0.62928

Collected Steps per Second: 22,984.75346
Overall Steps per Second: 10,872.83792

Timestep Collection Time: 2.17553
Timestep Consumption Time: 2.42345
PPO Batch Consumption Time: 0.28115
Total Iteration Time: 4.59898

Cumulative Model Updates: 58,394
Cumulative Timesteps: 487,103,778

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 487103778...
Checkpoint 487103778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,191.10209
Policy Entropy: 3.43634
Value Function Loss: 0.00335

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.09786
Policy Update Magnitude: 0.54845
Value Function Update Magnitude: 0.67057

Collected Steps per Second: 21,927.77805
Overall Steps per Second: 10,614.06603

Timestep Collection Time: 2.28030
Timestep Consumption Time: 2.43061
PPO Batch Consumption Time: 0.28232
Total Iteration Time: 4.71092

Cumulative Model Updates: 58,400
Cumulative Timesteps: 487,153,780

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 586.50512
Policy Entropy: 3.43820
Value Function Loss: 0.00354

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.10329
Policy Update Magnitude: 0.56175
Value Function Update Magnitude: 0.69846

Collected Steps per Second: 22,534.16776
Overall Steps per Second: 10,690.90503

Timestep Collection Time: 2.21894
Timestep Consumption Time: 2.45812
PPO Batch Consumption Time: 0.29065
Total Iteration Time: 4.67706

Cumulative Model Updates: 58,406
Cumulative Timesteps: 487,203,782

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 487203782...
Checkpoint 487203782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 992.19565
Policy Entropy: 3.43281
Value Function Loss: 0.00363

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.09732
Policy Update Magnitude: 0.56676
Value Function Update Magnitude: 0.70719

Collected Steps per Second: 22,629.71638
Overall Steps per Second: 10,817.44814

Timestep Collection Time: 2.21019
Timestep Consumption Time: 2.41345
PPO Batch Consumption Time: 0.28107
Total Iteration Time: 4.62364

Cumulative Model Updates: 58,412
Cumulative Timesteps: 487,253,798

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,106.32215
Policy Entropy: 3.43184
Value Function Loss: 0.00364

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.10554
Policy Update Magnitude: 0.56696
Value Function Update Magnitude: 0.72714

Collected Steps per Second: 22,855.54845
Overall Steps per Second: 10,657.71101

Timestep Collection Time: 2.18765
Timestep Consumption Time: 2.50379
PPO Batch Consumption Time: 0.29308
Total Iteration Time: 4.69144

Cumulative Model Updates: 58,418
Cumulative Timesteps: 487,303,798

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 487303798...
Checkpoint 487303798 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 941.66359
Policy Entropy: 3.43762
Value Function Loss: 0.00340

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.09536
Policy Update Magnitude: 0.56843
Value Function Update Magnitude: 0.71421

Collected Steps per Second: 22,559.14976
Overall Steps per Second: 10,565.83709

Timestep Collection Time: 2.21657
Timestep Consumption Time: 2.51604
PPO Batch Consumption Time: 0.29340
Total Iteration Time: 4.73261

Cumulative Model Updates: 58,424
Cumulative Timesteps: 487,353,802

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,396.84077
Policy Entropy: 3.42835
Value Function Loss: 0.00350

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.09210
Policy Update Magnitude: 0.56913
Value Function Update Magnitude: 0.70250

Collected Steps per Second: 22,470.57251
Overall Steps per Second: 10,596.54165

Timestep Collection Time: 2.22602
Timestep Consumption Time: 2.49439
PPO Batch Consumption Time: 0.28912
Total Iteration Time: 4.72041

Cumulative Model Updates: 58,430
Cumulative Timesteps: 487,403,822

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 487403822...
Checkpoint 487403822 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,586.30922
Policy Entropy: 3.44113
Value Function Loss: 0.00329

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.09133
Policy Update Magnitude: 0.57365
Value Function Update Magnitude: 0.67896

Collected Steps per Second: 22,665.79534
Overall Steps per Second: 10,828.01965

Timestep Collection Time: 2.20676
Timestep Consumption Time: 2.41255
PPO Batch Consumption Time: 0.28073
Total Iteration Time: 4.61931

Cumulative Model Updates: 58,436
Cumulative Timesteps: 487,453,840

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,242.56197
Policy Entropy: 3.43580
Value Function Loss: 0.00336

Mean KL Divergence: 0.00725
SB3 Clip Fraction: 0.08720
Policy Update Magnitude: 0.56522
Value Function Update Magnitude: 0.66564

Collected Steps per Second: 22,679.59208
Overall Steps per Second: 10,670.56495

Timestep Collection Time: 2.20515
Timestep Consumption Time: 2.48176
PPO Batch Consumption Time: 0.29183
Total Iteration Time: 4.68691

Cumulative Model Updates: 58,442
Cumulative Timesteps: 487,503,852

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 487503852...
Checkpoint 487503852 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,869.95109
Policy Entropy: 3.44153
Value Function Loss: 0.00308

Mean KL Divergence: 0.00710
SB3 Clip Fraction: 0.08212
Policy Update Magnitude: 0.55335
Value Function Update Magnitude: 0.65533

Collected Steps per Second: 22,337.79200
Overall Steps per Second: 10,605.00695

Timestep Collection Time: 2.23836
Timestep Consumption Time: 2.47639
PPO Batch Consumption Time: 0.29377
Total Iteration Time: 4.71475

Cumulative Model Updates: 58,448
Cumulative Timesteps: 487,553,852

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 883.50979
Policy Entropy: 3.43643
Value Function Loss: 0.00292

Mean KL Divergence: 0.00735
SB3 Clip Fraction: 0.08566
Policy Update Magnitude: 0.54901
Value Function Update Magnitude: 0.63124

Collected Steps per Second: 21,988.28754
Overall Steps per Second: 10,305.76546

Timestep Collection Time: 2.27476
Timestep Consumption Time: 2.57864
PPO Batch Consumption Time: 0.30528
Total Iteration Time: 4.85340

Cumulative Model Updates: 58,454
Cumulative Timesteps: 487,603,870

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 487603870...
Checkpoint 487603870 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,542.81185
Policy Entropy: 3.43324
Value Function Loss: 0.00303

Mean KL Divergence: 0.00678
SB3 Clip Fraction: 0.07833
Policy Update Magnitude: 0.55378
Value Function Update Magnitude: 0.61205

Collected Steps per Second: 22,092.32024
Overall Steps per Second: 10,713.41956

Timestep Collection Time: 2.26350
Timestep Consumption Time: 2.40410
PPO Batch Consumption Time: 0.27980
Total Iteration Time: 4.66760

Cumulative Model Updates: 58,460
Cumulative Timesteps: 487,653,876

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,469.99132
Policy Entropy: 3.41051
Value Function Loss: 0.00306

Mean KL Divergence: 0.00677
SB3 Clip Fraction: 0.07973
Policy Update Magnitude: 0.56115
Value Function Update Magnitude: 0.63204

Collected Steps per Second: 22,419.16013
Overall Steps per Second: 10,557.33270

Timestep Collection Time: 2.23122
Timestep Consumption Time: 2.50691
PPO Batch Consumption Time: 0.29132
Total Iteration Time: 4.73813

Cumulative Model Updates: 58,466
Cumulative Timesteps: 487,703,898

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 487703898...
Checkpoint 487703898 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,859.21562
Policy Entropy: 3.41248
Value Function Loss: 0.00314

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.09279
Policy Update Magnitude: 0.55624
Value Function Update Magnitude: 0.63694

Collected Steps per Second: 22,272.63159
Overall Steps per Second: 10,469.47477

Timestep Collection Time: 2.24500
Timestep Consumption Time: 2.53098
PPO Batch Consumption Time: 0.29539
Total Iteration Time: 4.77598

Cumulative Model Updates: 58,472
Cumulative Timesteps: 487,753,900

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 821.33448
Policy Entropy: 3.42410
Value Function Loss: 0.00318

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.09335
Policy Update Magnitude: 0.55543
Value Function Update Magnitude: 0.64654

Collected Steps per Second: 22,314.99685
Overall Steps per Second: 10,550.39067

Timestep Collection Time: 2.24091
Timestep Consumption Time: 2.49882
PPO Batch Consumption Time: 0.29395
Total Iteration Time: 4.73973

Cumulative Model Updates: 58,478
Cumulative Timesteps: 487,803,906

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 487803906...
Checkpoint 487803906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 888.32382
Policy Entropy: 3.43493
Value Function Loss: 0.00322

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.09948
Policy Update Magnitude: 0.55169
Value Function Update Magnitude: 0.63300

Collected Steps per Second: 22,667.26350
Overall Steps per Second: 10,700.12153

Timestep Collection Time: 2.20697
Timestep Consumption Time: 2.46830
PPO Batch Consumption Time: 0.29215
Total Iteration Time: 4.67527

Cumulative Model Updates: 58,484
Cumulative Timesteps: 487,853,932

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,054.72203
Policy Entropy: 3.44351
Value Function Loss: 0.00307

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.10502
Policy Update Magnitude: 0.54575
Value Function Update Magnitude: 0.62141

Collected Steps per Second: 22,826.98853
Overall Steps per Second: 10,782.99260

Timestep Collection Time: 2.19109
Timestep Consumption Time: 2.44732
PPO Batch Consumption Time: 0.28532
Total Iteration Time: 4.63842

Cumulative Model Updates: 58,490
Cumulative Timesteps: 487,903,948

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 487903948...
Checkpoint 487903948 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 775.34662
Policy Entropy: 3.45309
Value Function Loss: 0.00308

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.10875
Policy Update Magnitude: 0.53800
Value Function Update Magnitude: 0.62165

Collected Steps per Second: 22,376.68773
Overall Steps per Second: 10,601.45740

Timestep Collection Time: 2.23500
Timestep Consumption Time: 2.48246
PPO Batch Consumption Time: 0.29240
Total Iteration Time: 4.71746

Cumulative Model Updates: 58,496
Cumulative Timesteps: 487,953,960

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,250.90879
Policy Entropy: 3.45332
Value Function Loss: 0.00287

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.10112
Policy Update Magnitude: 0.53655
Value Function Update Magnitude: 0.60497

Collected Steps per Second: 22,427.65988
Overall Steps per Second: 10,628.08601

Timestep Collection Time: 2.23001
Timestep Consumption Time: 2.47582
PPO Batch Consumption Time: 0.29162
Total Iteration Time: 4.70583

Cumulative Model Updates: 58,502
Cumulative Timesteps: 488,003,974

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 488003974...
Checkpoint 488003974 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,351.55033
Policy Entropy: 3.45103
Value Function Loss: 0.00293

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.09860
Policy Update Magnitude: 0.53221
Value Function Update Magnitude: 0.59172

Collected Steps per Second: 22,750.19011
Overall Steps per Second: 10,863.46779

Timestep Collection Time: 2.19831
Timestep Consumption Time: 2.40538
PPO Batch Consumption Time: 0.28092
Total Iteration Time: 4.60369

Cumulative Model Updates: 58,508
Cumulative Timesteps: 488,053,986

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,203.75213
Policy Entropy: 3.45412
Value Function Loss: 0.00295

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.10153
Policy Update Magnitude: 0.53323
Value Function Update Magnitude: 0.59292

Collected Steps per Second: 22,609.96322
Overall Steps per Second: 10,614.68382

Timestep Collection Time: 2.21239
Timestep Consumption Time: 2.50014
PPO Batch Consumption Time: 0.29507
Total Iteration Time: 4.71253

Cumulative Model Updates: 58,514
Cumulative Timesteps: 488,104,008

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 488104008...
Checkpoint 488104008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,367.86511
Policy Entropy: 3.45482
Value Function Loss: 0.00295

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.09097
Policy Update Magnitude: 0.53193
Value Function Update Magnitude: 0.58716

Collected Steps per Second: 22,093.34926
Overall Steps per Second: 10,551.81787

Timestep Collection Time: 2.26312
Timestep Consumption Time: 2.47540
PPO Batch Consumption Time: 0.29130
Total Iteration Time: 4.73852

Cumulative Model Updates: 58,520
Cumulative Timesteps: 488,154,008

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 877.45809
Policy Entropy: 3.45330
Value Function Loss: 0.00284

Mean KL Divergence: 0.00732
SB3 Clip Fraction: 0.08503
Policy Update Magnitude: 0.53108
Value Function Update Magnitude: 0.57934

Collected Steps per Second: 22,905.92298
Overall Steps per Second: 10,861.33303

Timestep Collection Time: 2.18328
Timestep Consumption Time: 2.42113
PPO Batch Consumption Time: 0.28144
Total Iteration Time: 4.60441

Cumulative Model Updates: 58,526
Cumulative Timesteps: 488,204,018

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 488204018...
Checkpoint 488204018 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,121.31277
Policy Entropy: 3.44204
Value Function Loss: 0.00290

Mean KL Divergence: 0.00673
SB3 Clip Fraction: 0.07633
Policy Update Magnitude: 0.52910
Value Function Update Magnitude: 0.57468

Collected Steps per Second: 22,129.56591
Overall Steps per Second: 10,719.62478

Timestep Collection Time: 2.26032
Timestep Consumption Time: 2.40588
PPO Batch Consumption Time: 0.28263
Total Iteration Time: 4.66621

Cumulative Model Updates: 58,532
Cumulative Timesteps: 488,254,038

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,191.78144
Policy Entropy: 3.44995
Value Function Loss: 0.00301

Mean KL Divergence: 0.00671
SB3 Clip Fraction: 0.07835
Policy Update Magnitude: 0.53115
Value Function Update Magnitude: 0.59460

Collected Steps per Second: 22,662.98709
Overall Steps per Second: 10,836.83074

Timestep Collection Time: 2.20659
Timestep Consumption Time: 2.40804
PPO Batch Consumption Time: 0.28114
Total Iteration Time: 4.61463

Cumulative Model Updates: 58,538
Cumulative Timesteps: 488,304,046

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 488304046...
Checkpoint 488304046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,232.18730
Policy Entropy: 3.44499
Value Function Loss: 0.00294

Mean KL Divergence: 0.00718
SB3 Clip Fraction: 0.08439
Policy Update Magnitude: 0.53389
Value Function Update Magnitude: 0.60449

Collected Steps per Second: 22,558.26918
Overall Steps per Second: 10,698.12677

Timestep Collection Time: 2.21737
Timestep Consumption Time: 2.45822
PPO Batch Consumption Time: 0.28783
Total Iteration Time: 4.67558

Cumulative Model Updates: 58,544
Cumulative Timesteps: 488,354,066

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,094.88768
Policy Entropy: 3.44538
Value Function Loss: 0.00313

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.09209
Policy Update Magnitude: 0.53017
Value Function Update Magnitude: 0.60630

Collected Steps per Second: 22,800.58669
Overall Steps per Second: 10,863.91629

Timestep Collection Time: 2.19433
Timestep Consumption Time: 2.41101
PPO Batch Consumption Time: 0.28045
Total Iteration Time: 4.60534

Cumulative Model Updates: 58,550
Cumulative Timesteps: 488,404,098

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 488404098...
Checkpoint 488404098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,481.56693
Policy Entropy: 3.44496
Value Function Loss: 0.00304

Mean KL Divergence: 0.00723
SB3 Clip Fraction: 0.08273
Policy Update Magnitude: 0.53586
Value Function Update Magnitude: 0.62492

Collected Steps per Second: 22,543.32939
Overall Steps per Second: 10,728.81955

Timestep Collection Time: 2.21893
Timestep Consumption Time: 2.44347
PPO Batch Consumption Time: 0.28723
Total Iteration Time: 4.66240

Cumulative Model Updates: 58,556
Cumulative Timesteps: 488,454,120

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 750.84406
Policy Entropy: 3.45554
Value Function Loss: 0.00326

Mean KL Divergence: 0.00747
SB3 Clip Fraction: 0.08568
Policy Update Magnitude: 0.54769
Value Function Update Magnitude: 0.62041

Collected Steps per Second: 22,586.15494
Overall Steps per Second: 10,578.39287

Timestep Collection Time: 2.21401
Timestep Consumption Time: 2.51317
PPO Batch Consumption Time: 0.29234
Total Iteration Time: 4.72718

Cumulative Model Updates: 58,562
Cumulative Timesteps: 488,504,126

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 488504126...
Checkpoint 488504126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,648.12616
Policy Entropy: 3.45535
Value Function Loss: 0.00317

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.09449
Policy Update Magnitude: 0.55879
Value Function Update Magnitude: 0.62023

Collected Steps per Second: 22,246.32077
Overall Steps per Second: 10,552.67338

Timestep Collection Time: 2.24882
Timestep Consumption Time: 2.49197
PPO Batch Consumption Time: 0.29444
Total Iteration Time: 4.74079

Cumulative Model Updates: 58,568
Cumulative Timesteps: 488,554,154

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 879.89341
Policy Entropy: 3.44764
Value Function Loss: 0.00319

Mean KL Divergence: 0.00729
SB3 Clip Fraction: 0.08642
Policy Update Magnitude: 0.56260
Value Function Update Magnitude: 0.62611

Collected Steps per Second: 22,766.30394
Overall Steps per Second: 10,821.39316

Timestep Collection Time: 2.19684
Timestep Consumption Time: 2.42493
PPO Batch Consumption Time: 0.28114
Total Iteration Time: 4.62177

Cumulative Model Updates: 58,574
Cumulative Timesteps: 488,604,168

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 488604168...
Checkpoint 488604168 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,114.03823
Policy Entropy: 3.43309
Value Function Loss: 0.00304

Mean KL Divergence: 0.00691
SB3 Clip Fraction: 0.08099
Policy Update Magnitude: 0.55220
Value Function Update Magnitude: 0.60726

Collected Steps per Second: 22,284.49281
Overall Steps per Second: 10,663.08065

Timestep Collection Time: 2.24497
Timestep Consumption Time: 2.44673
PPO Batch Consumption Time: 0.28104
Total Iteration Time: 4.69170

Cumulative Model Updates: 58,580
Cumulative Timesteps: 488,654,196

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,813.46790
Policy Entropy: 3.42700
Value Function Loss: 0.00311

Mean KL Divergence: 0.00699
SB3 Clip Fraction: 0.08166
Policy Update Magnitude: 0.54964
Value Function Update Magnitude: 0.60663

Collected Steps per Second: 22,712.80233
Overall Steps per Second: 10,614.11134

Timestep Collection Time: 2.20246
Timestep Consumption Time: 2.51051
PPO Batch Consumption Time: 0.29369
Total Iteration Time: 4.71297

Cumulative Model Updates: 58,586
Cumulative Timesteps: 488,704,220

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 488704220...
Checkpoint 488704220 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,375.18335
Policy Entropy: 3.42791
Value Function Loss: 0.00308

Mean KL Divergence: 0.00740
SB3 Clip Fraction: 0.08695
Policy Update Magnitude: 0.55120
Value Function Update Magnitude: 0.60755

Collected Steps per Second: 21,791.58522
Overall Steps per Second: 10,556.40135

Timestep Collection Time: 2.29465
Timestep Consumption Time: 2.44219
PPO Batch Consumption Time: 0.27969
Total Iteration Time: 4.73684

Cumulative Model Updates: 58,592
Cumulative Timesteps: 488,754,224

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,602.62476
Policy Entropy: 3.44497
Value Function Loss: 0.00277

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.09156
Policy Update Magnitude: 0.54424
Value Function Update Magnitude: 0.60117

Collected Steps per Second: 22,668.63462
Overall Steps per Second: 10,819.75488

Timestep Collection Time: 2.20648
Timestep Consumption Time: 2.41636
PPO Batch Consumption Time: 0.28061
Total Iteration Time: 4.62284

Cumulative Model Updates: 58,598
Cumulative Timesteps: 488,804,242

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 488804242...
Checkpoint 488804242 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,337.56286
Policy Entropy: 3.45279
Value Function Loss: 0.00292

Mean KL Divergence: 0.00747
SB3 Clip Fraction: 0.08790
Policy Update Magnitude: 0.52904
Value Function Update Magnitude: 0.57670

Collected Steps per Second: 22,142.90972
Overall Steps per Second: 10,710.66397

Timestep Collection Time: 2.25905
Timestep Consumption Time: 2.41125
PPO Batch Consumption Time: 0.27983
Total Iteration Time: 4.67030

Cumulative Model Updates: 58,604
Cumulative Timesteps: 488,854,264

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,081.96369
Policy Entropy: 3.44967
Value Function Loss: 0.00287

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.09252
Policy Update Magnitude: 0.52666
Value Function Update Magnitude: 0.58124

Collected Steps per Second: 22,779.26010
Overall Steps per Second: 10,546.68932

Timestep Collection Time: 2.19577
Timestep Consumption Time: 2.54676
PPO Batch Consumption Time: 0.29514
Total Iteration Time: 4.74253

Cumulative Model Updates: 58,610
Cumulative Timesteps: 488,904,282

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 488904282...
Checkpoint 488904282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,579.22953
Policy Entropy: 3.44732
Value Function Loss: 0.00320

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.08696
Policy Update Magnitude: 0.53808
Value Function Update Magnitude: 0.59447

Collected Steps per Second: 21,771.37350
Overall Steps per Second: 10,552.02616

Timestep Collection Time: 2.29669
Timestep Consumption Time: 2.44193
PPO Batch Consumption Time: 0.28528
Total Iteration Time: 4.73862

Cumulative Model Updates: 58,616
Cumulative Timesteps: 488,954,284

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,345.30855
Policy Entropy: 3.45318
Value Function Loss: 0.00314

Mean KL Divergence: 0.00702
SB3 Clip Fraction: 0.08125
Policy Update Magnitude: 0.54185
Value Function Update Magnitude: 0.60676

Collected Steps per Second: 23,023.86688
Overall Steps per Second: 10,890.51157

Timestep Collection Time: 2.17175
Timestep Consumption Time: 2.41959
PPO Batch Consumption Time: 0.28034
Total Iteration Time: 4.59134

Cumulative Model Updates: 58,622
Cumulative Timesteps: 489,004,286

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 489004286...
Checkpoint 489004286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,044.15290
Policy Entropy: 3.43209
Value Function Loss: 0.00324

Mean KL Divergence: 0.00695
SB3 Clip Fraction: 0.08054
Policy Update Magnitude: 0.55025
Value Function Update Magnitude: 0.60656

Collected Steps per Second: 22,523.48586
Overall Steps per Second: 10,613.96232

Timestep Collection Time: 2.22106
Timestep Consumption Time: 2.49217
PPO Batch Consumption Time: 0.28842
Total Iteration Time: 4.71323

Cumulative Model Updates: 58,628
Cumulative Timesteps: 489,054,312

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 993.14074
Policy Entropy: 3.43311
Value Function Loss: 0.00309

Mean KL Divergence: 0.00674
SB3 Clip Fraction: 0.07790
Policy Update Magnitude: 0.55100
Value Function Update Magnitude: 0.60809

Collected Steps per Second: 22,514.15475
Overall Steps per Second: 10,569.02733

Timestep Collection Time: 2.22109
Timestep Consumption Time: 2.51028
PPO Batch Consumption Time: 0.29483
Total Iteration Time: 4.73137

Cumulative Model Updates: 58,634
Cumulative Timesteps: 489,104,318

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 489104318...
Checkpoint 489104318 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,737.57418
Policy Entropy: 3.41223
Value Function Loss: 0.00317

Mean KL Divergence: 0.00730
SB3 Clip Fraction: 0.08519
Policy Update Magnitude: 0.55558
Value Function Update Magnitude: 0.59514

Collected Steps per Second: 22,511.07190
Overall Steps per Second: 10,538.70912

Timestep Collection Time: 2.22184
Timestep Consumption Time: 2.52409
PPO Batch Consumption Time: 0.29602
Total Iteration Time: 4.74593

Cumulative Model Updates: 58,640
Cumulative Timesteps: 489,154,334

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,957.86691
Policy Entropy: 3.43101
Value Function Loss: 0.00316

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.11236
Policy Update Magnitude: 0.55078
Value Function Update Magnitude: 0.59290

Collected Steps per Second: 22,530.61191
Overall Steps per Second: 10,688.33205

Timestep Collection Time: 2.21929
Timestep Consumption Time: 2.45889
PPO Batch Consumption Time: 0.28974
Total Iteration Time: 4.67819

Cumulative Model Updates: 58,646
Cumulative Timesteps: 489,204,336

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 489204336...
Checkpoint 489204336 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,092.01899
Policy Entropy: 3.42344
Value Function Loss: 0.00358

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.10824
Policy Update Magnitude: 0.55911
Value Function Update Magnitude: 0.60340

Collected Steps per Second: 22,467.07652
Overall Steps per Second: 10,791.58854

Timestep Collection Time: 2.22646
Timestep Consumption Time: 2.40882
PPO Batch Consumption Time: 0.28061
Total Iteration Time: 4.63528

Cumulative Model Updates: 58,652
Cumulative Timesteps: 489,254,358

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 688.06164
Policy Entropy: 3.42695
Value Function Loss: 0.00359

Mean KL Divergence: 0.01100
SB3 Clip Fraction: 0.11999
Policy Update Magnitude: 0.57431
Value Function Update Magnitude: 0.63571

Collected Steps per Second: 22,811.18848
Overall Steps per Second: 10,769.28569

Timestep Collection Time: 2.19278
Timestep Consumption Time: 2.45191
PPO Batch Consumption Time: 0.28888
Total Iteration Time: 4.64469

Cumulative Model Updates: 58,658
Cumulative Timesteps: 489,304,378

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 489304378...
Checkpoint 489304378 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,208.81129
Policy Entropy: 3.42763
Value Function Loss: 0.00350

Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.09638
Policy Update Magnitude: 0.57081
Value Function Update Magnitude: 0.65239

Collected Steps per Second: 22,312.83253
Overall Steps per Second: 10,761.84376

Timestep Collection Time: 2.24122
Timestep Consumption Time: 2.40557
PPO Batch Consumption Time: 0.28083
Total Iteration Time: 4.64679

Cumulative Model Updates: 58,664
Cumulative Timesteps: 489,354,386

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 785.89581
Policy Entropy: 3.44040
Value Function Loss: 0.00334

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.09755
Policy Update Magnitude: 0.56239
Value Function Update Magnitude: 0.63554

Collected Steps per Second: 22,057.80628
Overall Steps per Second: 10,553.30292

Timestep Collection Time: 2.26677
Timestep Consumption Time: 2.47108
PPO Batch Consumption Time: 0.28862
Total Iteration Time: 4.73785

Cumulative Model Updates: 58,670
Cumulative Timesteps: 489,404,386

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 489404386...
Checkpoint 489404386 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 909.06749
Policy Entropy: 3.43499
Value Function Loss: 0.00317

Mean KL Divergence: 0.00688
SB3 Clip Fraction: 0.08027
Policy Update Magnitude: 0.55993
Value Function Update Magnitude: 0.62251

Collected Steps per Second: 22,495.13526
Overall Steps per Second: 10,666.83838

Timestep Collection Time: 2.22386
Timestep Consumption Time: 2.46600
PPO Batch Consumption Time: 0.29203
Total Iteration Time: 4.68986

Cumulative Model Updates: 58,676
Cumulative Timesteps: 489,454,412

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 910.99801
Policy Entropy: 3.42718
Value Function Loss: 0.00312

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.09061
Policy Update Magnitude: 0.55976
Value Function Update Magnitude: 0.60963

Collected Steps per Second: 23,068.64236
Overall Steps per Second: 10,907.48976

Timestep Collection Time: 2.16796
Timestep Consumption Time: 2.41714
PPO Batch Consumption Time: 0.28003
Total Iteration Time: 4.58511

Cumulative Model Updates: 58,682
Cumulative Timesteps: 489,504,424

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 489504424...
Checkpoint 489504424 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,179.94688
Policy Entropy: 3.43107
Value Function Loss: 0.00311

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.10056
Policy Update Magnitude: 0.55806
Value Function Update Magnitude: 0.59491

Collected Steps per Second: 22,097.04969
Overall Steps per Second: 10,430.74724

Timestep Collection Time: 2.26356
Timestep Consumption Time: 2.53169
PPO Batch Consumption Time: 0.29972
Total Iteration Time: 4.79525

Cumulative Model Updates: 58,688
Cumulative Timesteps: 489,554,442

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,718.70924
Policy Entropy: 3.44477
Value Function Loss: 0.00332

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.10748
Policy Update Magnitude: 0.55745
Value Function Update Magnitude: 0.59404

Collected Steps per Second: 22,770.27062
Overall Steps per Second: 10,574.38283

Timestep Collection Time: 2.19646
Timestep Consumption Time: 2.53327
PPO Batch Consumption Time: 0.30071
Total Iteration Time: 4.72973

Cumulative Model Updates: 58,694
Cumulative Timesteps: 489,604,456

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 489604456...
Checkpoint 489604456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 988.78456
Policy Entropy: 3.44702
Value Function Loss: 0.00349

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.08962
Policy Update Magnitude: 0.55958
Value Function Update Magnitude: 0.60159

Collected Steps per Second: 22,282.49895
Overall Steps per Second: 10,711.42075

Timestep Collection Time: 2.24472
Timestep Consumption Time: 2.42487
PPO Batch Consumption Time: 0.28365
Total Iteration Time: 4.66960

Cumulative Model Updates: 58,700
Cumulative Timesteps: 489,654,474

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,437.66938
Policy Entropy: 3.45258
Value Function Loss: 0.00341

Mean KL Divergence: 0.00758
SB3 Clip Fraction: 0.08560
Policy Update Magnitude: 0.56010
Value Function Update Magnitude: 0.60384

Collected Steps per Second: 22,730.61413
Overall Steps per Second: 10,625.53841

Timestep Collection Time: 2.19968
Timestep Consumption Time: 2.50597
PPO Batch Consumption Time: 0.29106
Total Iteration Time: 4.70564

Cumulative Model Updates: 58,706
Cumulative Timesteps: 489,704,474

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 489704474...
Checkpoint 489704474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 903.48038
Policy Entropy: 3.45015
Value Function Loss: 0.00323

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.08797
Policy Update Magnitude: 0.55425
Value Function Update Magnitude: 0.61097

Collected Steps per Second: 22,509.57557
Overall Steps per Second: 10,801.23389

Timestep Collection Time: 2.22217
Timestep Consumption Time: 2.40879
PPO Batch Consumption Time: 0.28100
Total Iteration Time: 4.63095

Cumulative Model Updates: 58,712
Cumulative Timesteps: 489,754,494

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 818.80344
Policy Entropy: 3.44385
Value Function Loss: 0.00324

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.08788
Policy Update Magnitude: 0.54996
Value Function Update Magnitude: 0.61706

Collected Steps per Second: 22,680.98574
Overall Steps per Second: 10,658.28379

Timestep Collection Time: 2.20546
Timestep Consumption Time: 2.48779
PPO Batch Consumption Time: 0.29377
Total Iteration Time: 4.69325

Cumulative Model Updates: 58,718
Cumulative Timesteps: 489,804,516

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 489804516...
Checkpoint 489804516 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,130.94265
Policy Entropy: 3.43742
Value Function Loss: 0.00324

Mean KL Divergence: 0.00706
SB3 Clip Fraction: 0.08176
Policy Update Magnitude: 0.55915
Value Function Update Magnitude: 0.60520

Collected Steps per Second: 22,613.19565
Overall Steps per Second: 10,647.12169

Timestep Collection Time: 2.21136
Timestep Consumption Time: 2.48530
PPO Batch Consumption Time: 0.29318
Total Iteration Time: 4.69667

Cumulative Model Updates: 58,724
Cumulative Timesteps: 489,854,522

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,850.22143
Policy Entropy: 3.44287
Value Function Loss: 0.00315

Mean KL Divergence: 0.00759
SB3 Clip Fraction: 0.08996
Policy Update Magnitude: 0.55146
Value Function Update Magnitude: 0.58752

Collected Steps per Second: 22,910.98935
Overall Steps per Second: 10,789.22215

Timestep Collection Time: 2.18288
Timestep Consumption Time: 2.45248
PPO Batch Consumption Time: 0.28087
Total Iteration Time: 4.63537

Cumulative Model Updates: 58,730
Cumulative Timesteps: 489,904,534

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 489904534...
Checkpoint 489904534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,896.47876
Policy Entropy: 3.44144
Value Function Loss: 0.00312

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.09506
Policy Update Magnitude: 0.53781
Value Function Update Magnitude: 0.56724

Collected Steps per Second: 22,418.38069
Overall Steps per Second: 10,663.18574

Timestep Collection Time: 2.23147
Timestep Consumption Time: 2.46000
PPO Batch Consumption Time: 0.28445
Total Iteration Time: 4.69147

Cumulative Model Updates: 58,736
Cumulative Timesteps: 489,954,560

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,230.08781
Policy Entropy: 3.44866
Value Function Loss: 0.00298

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.10457
Policy Update Magnitude: 0.52912
Value Function Update Magnitude: 0.55578

Collected Steps per Second: 22,715.47564
Overall Steps per Second: 10,832.07574

Timestep Collection Time: 2.20220
Timestep Consumption Time: 2.41594
PPO Batch Consumption Time: 0.28044
Total Iteration Time: 4.61814

Cumulative Model Updates: 58,742
Cumulative Timesteps: 490,004,584

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 490004584...
Checkpoint 490004584 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,067.45363
Policy Entropy: 3.43773
Value Function Loss: 0.00327

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.10696
Policy Update Magnitude: 0.52935
Value Function Update Magnitude: 0.54234

Collected Steps per Second: 21,873.21136
Overall Steps per Second: 10,598.77732

Timestep Collection Time: 2.28718
Timestep Consumption Time: 2.43299
PPO Batch Consumption Time: 0.28410
Total Iteration Time: 4.72017

Cumulative Model Updates: 58,748
Cumulative Timesteps: 490,054,612

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 752.00572
Policy Entropy: 3.44403
Value Function Loss: 0.00341

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.10908
Policy Update Magnitude: 0.54789
Value Function Update Magnitude: 0.55993

Collected Steps per Second: 22,919.03173
Overall Steps per Second: 10,735.32583

Timestep Collection Time: 2.18264
Timestep Consumption Time: 2.47712
PPO Batch Consumption Time: 0.29280
Total Iteration Time: 4.65976

Cumulative Model Updates: 58,754
Cumulative Timesteps: 490,104,636

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 490104636...
Checkpoint 490104636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 955.58342
Policy Entropy: 3.45146
Value Function Loss: 0.00342

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.09622
Policy Update Magnitude: 0.54961
Value Function Update Magnitude: 0.58657

Collected Steps per Second: 22,417.65505
Overall Steps per Second: 10,611.72358

Timestep Collection Time: 2.23137
Timestep Consumption Time: 2.48248
PPO Batch Consumption Time: 0.29491
Total Iteration Time: 4.71384

Cumulative Model Updates: 58,760
Cumulative Timesteps: 490,154,658

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 925.20466
Policy Entropy: 3.45178
Value Function Loss: 0.00305

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.09417
Policy Update Magnitude: 0.53941
Value Function Update Magnitude: 0.57529

Collected Steps per Second: 23,038.71554
Overall Steps per Second: 10,817.15606

Timestep Collection Time: 2.17043
Timestep Consumption Time: 2.45222
PPO Batch Consumption Time: 0.28762
Total Iteration Time: 4.62266

Cumulative Model Updates: 58,766
Cumulative Timesteps: 490,204,662

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 490204662...
Checkpoint 490204662 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 949.36129
Policy Entropy: 3.45875
Value Function Loss: 0.00307

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.09655
Policy Update Magnitude: 0.52710
Value Function Update Magnitude: 0.56230

Collected Steps per Second: 22,031.44862
Overall Steps per Second: 10,545.20177

Timestep Collection Time: 2.27030
Timestep Consumption Time: 2.47290
PPO Batch Consumption Time: 0.29391
Total Iteration Time: 4.74320

Cumulative Model Updates: 58,772
Cumulative Timesteps: 490,254,680

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,530.05711
Policy Entropy: 3.46263
Value Function Loss: 0.00291

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.09926
Policy Update Magnitude: 0.52775
Value Function Update Magnitude: 0.57467

Collected Steps per Second: 23,029.72817
Overall Steps per Second: 10,925.44570

Timestep Collection Time: 2.17224
Timestep Consumption Time: 2.40662
PPO Batch Consumption Time: 0.28086
Total Iteration Time: 4.57885

Cumulative Model Updates: 58,778
Cumulative Timesteps: 490,304,706

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 490304706...
Checkpoint 490304706 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,108.89794
Policy Entropy: 3.47624
Value Function Loss: 0.00276

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.09518
Policy Update Magnitude: 0.52444
Value Function Update Magnitude: 0.57025

Collected Steps per Second: 22,157.91449
Overall Steps per Second: 10,640.83949

Timestep Collection Time: 2.25689
Timestep Consumption Time: 2.44274
PPO Batch Consumption Time: 0.28141
Total Iteration Time: 4.69963

Cumulative Model Updates: 58,784
Cumulative Timesteps: 490,354,714

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,111.57013
Policy Entropy: 3.47513
Value Function Loss: 0.00272

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.09999
Policy Update Magnitude: 0.51890
Value Function Update Magnitude: 0.56592

Collected Steps per Second: 22,817.84932
Overall Steps per Second: 10,621.47497

Timestep Collection Time: 2.19249
Timestep Consumption Time: 2.51759
PPO Batch Consumption Time: 0.29375
Total Iteration Time: 4.71008

Cumulative Model Updates: 58,790
Cumulative Timesteps: 490,404,742

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 490404742...
Checkpoint 490404742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,590.50833
Policy Entropy: 3.48101
Value Function Loss: 0.00292

Mean KL Divergence: 0.00739
SB3 Clip Fraction: 0.08364
Policy Update Magnitude: 0.51856
Value Function Update Magnitude: 0.58291

Collected Steps per Second: 22,241.31142
Overall Steps per Second: 10,546.88628

Timestep Collection Time: 2.24816
Timestep Consumption Time: 2.49277
PPO Batch Consumption Time: 0.29496
Total Iteration Time: 4.74093

Cumulative Model Updates: 58,796
Cumulative Timesteps: 490,454,744

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,122.92729
Policy Entropy: 3.47827
Value Function Loss: 0.00298

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.08705
Policy Update Magnitude: 0.52676
Value Function Update Magnitude: 0.60175

Collected Steps per Second: 22,845.84835
Overall Steps per Second: 10,799.50472

Timestep Collection Time: 2.18928
Timestep Consumption Time: 2.44204
PPO Batch Consumption Time: 0.28136
Total Iteration Time: 4.63132

Cumulative Model Updates: 58,802
Cumulative Timesteps: 490,504,760

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 490504760...
Checkpoint 490504760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,080.73275
Policy Entropy: 3.49028
Value Function Loss: 0.00310

Mean KL Divergence: 0.00753
SB3 Clip Fraction: 0.08805
Policy Update Magnitude: 0.52607
Value Function Update Magnitude: 0.62950

Collected Steps per Second: 22,104.33518
Overall Steps per Second: 10,677.44973

Timestep Collection Time: 2.26254
Timestep Consumption Time: 2.42135
PPO Batch Consumption Time: 0.28082
Total Iteration Time: 4.68389

Cumulative Model Updates: 58,808
Cumulative Timesteps: 490,554,772

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,044.15463
Policy Entropy: 3.47667
Value Function Loss: 0.00305

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.08957
Policy Update Magnitude: 0.53346
Value Function Update Magnitude: 0.63776

Collected Steps per Second: 23,020.73505
Overall Steps per Second: 10,891.74674

Timestep Collection Time: 2.17265
Timestep Consumption Time: 2.41945
PPO Batch Consumption Time: 0.28098
Total Iteration Time: 4.59210

Cumulative Model Updates: 58,814
Cumulative Timesteps: 490,604,788

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 490604788...
Checkpoint 490604788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,754.70829
Policy Entropy: 3.47777
Value Function Loss: 0.00331

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.08808
Policy Update Magnitude: 0.54589
Value Function Update Magnitude: 0.63131

Collected Steps per Second: 22,334.43326
Overall Steps per Second: 10,714.72958

Timestep Collection Time: 2.23923
Timestep Consumption Time: 2.42836
PPO Batch Consumption Time: 0.28085
Total Iteration Time: 4.66759

Cumulative Model Updates: 58,820
Cumulative Timesteps: 490,654,800

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,496.51999
Policy Entropy: 3.47286
Value Function Loss: 0.00318

Mean KL Divergence: 0.00711
SB3 Clip Fraction: 0.08135
Policy Update Magnitude: 0.54830
Value Function Update Magnitude: 0.64104

Collected Steps per Second: 22,845.25004
Overall Steps per Second: 10,825.49216

Timestep Collection Time: 2.18908
Timestep Consumption Time: 2.43057
PPO Batch Consumption Time: 0.28197
Total Iteration Time: 4.61965

Cumulative Model Updates: 58,826
Cumulative Timesteps: 490,704,810

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 490704810...
Checkpoint 490704810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,604.69701
Policy Entropy: 3.47446
Value Function Loss: 0.00317

Mean KL Divergence: 0.00710
SB3 Clip Fraction: 0.08370
Policy Update Magnitude: 0.54927
Value Function Update Magnitude: 0.63983

Collected Steps per Second: 22,279.00958
Overall Steps per Second: 10,744.07880

Timestep Collection Time: 2.24498
Timestep Consumption Time: 2.41023
PPO Batch Consumption Time: 0.28007
Total Iteration Time: 4.65522

Cumulative Model Updates: 58,832
Cumulative Timesteps: 490,754,826

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,038.36470
Policy Entropy: 3.46983
Value Function Loss: 0.00314

Mean KL Divergence: 0.00692
SB3 Clip Fraction: 0.08129
Policy Update Magnitude: 0.54909
Value Function Update Magnitude: 0.62733

Collected Steps per Second: 23,022.03210
Overall Steps per Second: 10,943.71343

Timestep Collection Time: 2.17218
Timestep Consumption Time: 2.39738
PPO Batch Consumption Time: 0.27914
Total Iteration Time: 4.56956

Cumulative Model Updates: 58,838
Cumulative Timesteps: 490,804,834

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 490804834...
Checkpoint 490804834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 828.62281
Policy Entropy: 3.47100
Value Function Loss: 0.00332

Mean KL Divergence: 0.00700
SB3 Clip Fraction: 0.08237
Policy Update Magnitude: 0.55136
Value Function Update Magnitude: 0.63276

Collected Steps per Second: 22,619.61903
Overall Steps per Second: 10,669.57354

Timestep Collection Time: 2.21153
Timestep Consumption Time: 2.47694
PPO Batch Consumption Time: 0.29396
Total Iteration Time: 4.68847

Cumulative Model Updates: 58,844
Cumulative Timesteps: 490,854,858

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,449.80807
Policy Entropy: 3.46121
Value Function Loss: 0.00327

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.09112
Policy Update Magnitude: 0.55281
Value Function Update Magnitude: 0.63214

Collected Steps per Second: 22,975.24929
Overall Steps per Second: 10,791.94468

Timestep Collection Time: 2.17634
Timestep Consumption Time: 2.45693
PPO Batch Consumption Time: 0.28330
Total Iteration Time: 4.63327

Cumulative Model Updates: 58,850
Cumulative Timesteps: 490,904,860

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 490904860...
Checkpoint 490904860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,049.78815
Policy Entropy: 3.45884
Value Function Loss: 0.00303

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.10911
Policy Update Magnitude: 0.54407
Value Function Update Magnitude: 0.62735

Collected Steps per Second: 21,759.81610
Overall Steps per Second: 10,635.76299

Timestep Collection Time: 2.29827
Timestep Consumption Time: 2.40379
PPO Batch Consumption Time: 0.28155
Total Iteration Time: 4.70206

Cumulative Model Updates: 58,856
Cumulative Timesteps: 490,954,870

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 927.19921
Policy Entropy: 3.45006
Value Function Loss: 0.00295

Mean KL Divergence: 0.01157
SB3 Clip Fraction: 0.12188
Policy Update Magnitude: 0.53803
Value Function Update Magnitude: 0.62935

Collected Steps per Second: 22,437.97760
Overall Steps per Second: 10,633.99994

Timestep Collection Time: 2.22908
Timestep Consumption Time: 2.47433
PPO Batch Consumption Time: 0.29128
Total Iteration Time: 4.70340

Cumulative Model Updates: 58,862
Cumulative Timesteps: 491,004,886

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 491004886...
Checkpoint 491004886 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,233.66948
Policy Entropy: 3.45173
Value Function Loss: 0.00296

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.10629
Policy Update Magnitude: 0.54107
Value Function Update Magnitude: 0.61465

Collected Steps per Second: 22,309.69700
Overall Steps per Second: 10,605.66055

Timestep Collection Time: 2.24136
Timestep Consumption Time: 2.47348
PPO Batch Consumption Time: 0.29310
Total Iteration Time: 4.71484

Cumulative Model Updates: 58,868
Cumulative Timesteps: 491,054,890

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,105.37842
Policy Entropy: 3.44866
Value Function Loss: 0.00298

Mean KL Divergence: 0.01061
SB3 Clip Fraction: 0.11469
Policy Update Magnitude: 0.54496
Value Function Update Magnitude: 0.60528

Collected Steps per Second: 23,224.54178
Overall Steps per Second: 10,768.02024

Timestep Collection Time: 2.15341
Timestep Consumption Time: 2.49108
PPO Batch Consumption Time: 0.28820
Total Iteration Time: 4.64449

Cumulative Model Updates: 58,874
Cumulative Timesteps: 491,104,902

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 491104902...
Checkpoint 491104902 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,244.30553
Policy Entropy: 3.44881
Value Function Loss: 0.00277

Mean KL Divergence: 0.01097
SB3 Clip Fraction: 0.11852
Policy Update Magnitude: 0.53450
Value Function Update Magnitude: 0.57423

Collected Steps per Second: 22,092.20301
Overall Steps per Second: 10,620.88561

Timestep Collection Time: 2.26379
Timestep Consumption Time: 2.44505
PPO Batch Consumption Time: 0.28059
Total Iteration Time: 4.70884

Cumulative Model Updates: 58,880
Cumulative Timesteps: 491,154,914

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,200.35915
Policy Entropy: 3.44533
Value Function Loss: 0.00312

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.10654
Policy Update Magnitude: 0.52535
Value Function Update Magnitude: 0.56785

Collected Steps per Second: 22,681.66276
Overall Steps per Second: 10,714.79607

Timestep Collection Time: 2.20566
Timestep Consumption Time: 2.46340
PPO Batch Consumption Time: 0.28895
Total Iteration Time: 4.66906

Cumulative Model Updates: 58,886
Cumulative Timesteps: 491,204,942

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 491204942...
Checkpoint 491204942 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,788.17285
Policy Entropy: 3.44294
Value Function Loss: 0.00325

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.10152
Policy Update Magnitude: 0.54166
Value Function Update Magnitude: 0.59022

Collected Steps per Second: 22,719.11749
Overall Steps per Second: 10,852.07187

Timestep Collection Time: 2.20132
Timestep Consumption Time: 2.40720
PPO Batch Consumption Time: 0.28064
Total Iteration Time: 4.60852

Cumulative Model Updates: 58,892
Cumulative Timesteps: 491,254,954

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 795.85574
Policy Entropy: 3.43727
Value Function Loss: 0.00327

Mean KL Divergence: 0.00752
SB3 Clip Fraction: 0.08875
Policy Update Magnitude: 0.55781
Value Function Update Magnitude: 0.60348

Collected Steps per Second: 23,047.73490
Overall Steps per Second: 10,885.49251

Timestep Collection Time: 2.17045
Timestep Consumption Time: 2.42502
PPO Batch Consumption Time: 0.28047
Total Iteration Time: 4.59547

Cumulative Model Updates: 58,898
Cumulative Timesteps: 491,304,978

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 491304978...
Checkpoint 491304978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 940.88986
Policy Entropy: 3.44395
Value Function Loss: 0.00301

Mean KL Divergence: 0.00693
SB3 Clip Fraction: 0.08008
Policy Update Magnitude: 0.54893
Value Function Update Magnitude: 0.60513

Collected Steps per Second: 21,967.02549
Overall Steps per Second: 10,595.49422

Timestep Collection Time: 2.27805
Timestep Consumption Time: 2.44490
PPO Batch Consumption Time: 0.28065
Total Iteration Time: 4.72295

Cumulative Model Updates: 58,904
Cumulative Timesteps: 491,355,020

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,187.96099
Policy Entropy: 3.44105
Value Function Loss: 0.00300

Mean KL Divergence: 0.00682
SB3 Clip Fraction: 0.07772
Policy Update Magnitude: 0.54550
Value Function Update Magnitude: 0.60011

Collected Steps per Second: 22,694.86163
Overall Steps per Second: 10,579.39841

Timestep Collection Time: 2.20323
Timestep Consumption Time: 2.52313
PPO Batch Consumption Time: 0.29390
Total Iteration Time: 4.72636

Cumulative Model Updates: 58,910
Cumulative Timesteps: 491,405,022

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 491405022...
Checkpoint 491405022 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 967.07387
Policy Entropy: 3.44343
Value Function Loss: 0.00307

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.09598
Policy Update Magnitude: 0.55181
Value Function Update Magnitude: 0.60120

Collected Steps per Second: 22,349.14162
Overall Steps per Second: 10,576.01092

Timestep Collection Time: 2.23794
Timestep Consumption Time: 2.49125
PPO Batch Consumption Time: 0.28866
Total Iteration Time: 4.72919

Cumulative Model Updates: 58,916
Cumulative Timesteps: 491,455,038

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,091.27791
Policy Entropy: 3.44980
Value Function Loss: 0.00301

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.10249
Policy Update Magnitude: 0.55388
Value Function Update Magnitude: 0.59631

Collected Steps per Second: 22,948.34425
Overall Steps per Second: 10,873.08872

Timestep Collection Time: 2.17959
Timestep Consumption Time: 2.42057
PPO Batch Consumption Time: 0.28145
Total Iteration Time: 4.60016

Cumulative Model Updates: 58,922
Cumulative Timesteps: 491,505,056

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 491505056...
Checkpoint 491505056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 858.94142
Policy Entropy: 3.44459
Value Function Loss: 0.00301

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.09556
Policy Update Magnitude: 0.54941
Value Function Update Magnitude: 0.58726

Collected Steps per Second: 22,318.11738
Overall Steps per Second: 10,468.94488

Timestep Collection Time: 2.24078
Timestep Consumption Time: 2.53621
PPO Batch Consumption Time: 0.29996
Total Iteration Time: 4.77699

Cumulative Model Updates: 58,928
Cumulative Timesteps: 491,555,066

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,026.68516
Policy Entropy: 3.44775
Value Function Loss: 0.00289

Mean KL Divergence: 0.00735
SB3 Clip Fraction: 0.08700
Policy Update Magnitude: 0.54723
Value Function Update Magnitude: 0.55949

Collected Steps per Second: 23,204.79449
Overall Steps per Second: 10,657.82893

Timestep Collection Time: 2.15568
Timestep Consumption Time: 2.53778
PPO Batch Consumption Time: 0.29836
Total Iteration Time: 4.69345

Cumulative Model Updates: 58,934
Cumulative Timesteps: 491,605,088

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 491605088...
Checkpoint 491605088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,295.68025
Policy Entropy: 3.44220
Value Function Loss: 0.00294

Mean KL Divergence: 0.00741
SB3 Clip Fraction: 0.08686
Policy Update Magnitude: 0.53779
Value Function Update Magnitude: 0.53372

Collected Steps per Second: 22,539.95039
Overall Steps per Second: 10,674.81462

Timestep Collection Time: 2.21970
Timestep Consumption Time: 2.46722
PPO Batch Consumption Time: 0.29060
Total Iteration Time: 4.68692

Cumulative Model Updates: 58,940
Cumulative Timesteps: 491,655,120

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,273.12137
Policy Entropy: 3.44566
Value Function Loss: 0.00307

Mean KL Divergence: 0.00715
SB3 Clip Fraction: 0.08349
Policy Update Magnitude: 0.54852
Value Function Update Magnitude: 0.55651

Collected Steps per Second: 22,984.85754
Overall Steps per Second: 10,865.68157

Timestep Collection Time: 2.17648
Timestep Consumption Time: 2.42756
PPO Batch Consumption Time: 0.28121
Total Iteration Time: 4.60404

Cumulative Model Updates: 58,946
Cumulative Timesteps: 491,705,146

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 491705146...
Checkpoint 491705146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,730.14845
Policy Entropy: 3.45104
Value Function Loss: 0.00306

Mean KL Divergence: 0.00676
SB3 Clip Fraction: 0.07822
Policy Update Magnitude: 0.55596
Value Function Update Magnitude: 0.56718

Collected Steps per Second: 22,303.36086
Overall Steps per Second: 10,687.99774

Timestep Collection Time: 2.24181
Timestep Consumption Time: 2.43633
PPO Batch Consumption Time: 0.27952
Total Iteration Time: 4.67814

Cumulative Model Updates: 58,952
Cumulative Timesteps: 491,755,146

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 708.10341
Policy Entropy: 3.45988
Value Function Loss: 0.00314

Mean KL Divergence: 0.00728
SB3 Clip Fraction: 0.08348
Policy Update Magnitude: 0.55663
Value Function Update Magnitude: 0.55895

Collected Steps per Second: 22,656.32395
Overall Steps per Second: 10,619.33303

Timestep Collection Time: 2.20707
Timestep Consumption Time: 2.50170
PPO Batch Consumption Time: 0.29216
Total Iteration Time: 4.70877

Cumulative Model Updates: 58,958
Cumulative Timesteps: 491,805,150

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 491805150...
Checkpoint 491805150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,399.51054
Policy Entropy: 3.46571
Value Function Loss: 0.00320

Mean KL Divergence: 0.00722
SB3 Clip Fraction: 0.08225
Policy Update Magnitude: 0.55907
Value Function Update Magnitude: 0.58094

Collected Steps per Second: 22,475.39827
Overall Steps per Second: 10,695.84089

Timestep Collection Time: 2.22519
Timestep Consumption Time: 2.45065
PPO Batch Consumption Time: 0.28881
Total Iteration Time: 4.67584

Cumulative Model Updates: 58,964
Cumulative Timesteps: 491,855,162

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,343.26696
Policy Entropy: 3.47458
Value Function Loss: 0.00311

Mean KL Divergence: 0.00683
SB3 Clip Fraction: 0.07824
Policy Update Magnitude: 0.55634
Value Function Update Magnitude: 0.58886

Collected Steps per Second: 23,105.35148
Overall Steps per Second: 10,754.07514

Timestep Collection Time: 2.16539
Timestep Consumption Time: 2.48699
PPO Batch Consumption Time: 0.29437
Total Iteration Time: 4.65238

Cumulative Model Updates: 58,970
Cumulative Timesteps: 491,905,194

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 491905194...
Checkpoint 491905194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,611.78055
Policy Entropy: 3.46438
Value Function Loss: 0.00326

Mean KL Divergence: 0.00682
SB3 Clip Fraction: 0.07958
Policy Update Magnitude: 0.55835
Value Function Update Magnitude: 0.58656

Collected Steps per Second: 22,018.63911
Overall Steps per Second: 10,577.65336

Timestep Collection Time: 2.27144
Timestep Consumption Time: 2.45683
PPO Batch Consumption Time: 0.28812
Total Iteration Time: 4.72827

Cumulative Model Updates: 58,976
Cumulative Timesteps: 491,955,208

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,420.56803
Policy Entropy: 3.46738
Value Function Loss: 0.00305

Mean KL Divergence: 0.00634
SB3 Clip Fraction: 0.07282
Policy Update Magnitude: 0.55753
Value Function Update Magnitude: 0.59045

Collected Steps per Second: 23,084.66865
Overall Steps per Second: 10,932.67076

Timestep Collection Time: 2.16620
Timestep Consumption Time: 2.40780
PPO Batch Consumption Time: 0.27896
Total Iteration Time: 4.57400

Cumulative Model Updates: 58,982
Cumulative Timesteps: 492,005,214

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 492005214...
Checkpoint 492005214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,706.14562
Policy Entropy: 3.46166
Value Function Loss: 0.00306

Mean KL Divergence: 0.00724
SB3 Clip Fraction: 0.08378
Policy Update Magnitude: 0.55455
Value Function Update Magnitude: 0.60125

Collected Steps per Second: 22,042.29908
Overall Steps per Second: 10,602.61255

Timestep Collection Time: 2.26936
Timestep Consumption Time: 2.44853
PPO Batch Consumption Time: 0.28528
Total Iteration Time: 4.71789

Cumulative Model Updates: 58,988
Cumulative Timesteps: 492,055,236

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 914.62139
Policy Entropy: 3.45476
Value Function Loss: 0.00296

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.09115
Policy Update Magnitude: 0.54527
Value Function Update Magnitude: 0.59271

Collected Steps per Second: 23,123.29939
Overall Steps per Second: 10,877.88550

Timestep Collection Time: 2.16327
Timestep Consumption Time: 2.43523
PPO Batch Consumption Time: 0.28334
Total Iteration Time: 4.59850

Cumulative Model Updates: 58,994
Cumulative Timesteps: 492,105,258

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 492105258...
Checkpoint 492105258 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,261.59599
Policy Entropy: 3.45209
Value Function Loss: 0.00318

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.09189
Policy Update Magnitude: 0.54476
Value Function Update Magnitude: 0.58125

Collected Steps per Second: 20,642.72119
Overall Steps per Second: 9,806.68620

Timestep Collection Time: 2.42274
Timestep Consumption Time: 2.67704
PPO Batch Consumption Time: 0.31376
Total Iteration Time: 5.09979

Cumulative Model Updates: 59,000
Cumulative Timesteps: 492,155,270

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,988.03806
Policy Entropy: 3.44955
Value Function Loss: 0.00320

Mean KL Divergence: 0.00729
SB3 Clip Fraction: 0.08703
Policy Update Magnitude: 0.55255
Value Function Update Magnitude: 0.59372

Collected Steps per Second: 20,231.79456
Overall Steps per Second: 9,628.96705

Timestep Collection Time: 2.47165
Timestep Consumption Time: 2.72163
PPO Batch Consumption Time: 0.31268
Total Iteration Time: 5.19329

Cumulative Model Updates: 59,006
Cumulative Timesteps: 492,205,276

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 492205276...
Checkpoint 492205276 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 815.49603
Policy Entropy: 3.45732
Value Function Loss: 0.00338

Mean KL Divergence: 0.00710
SB3 Clip Fraction: 0.08235
Policy Update Magnitude: 0.56176
Value Function Update Magnitude: 0.59892

Collected Steps per Second: 21,138.08755
Overall Steps per Second: 10,271.81832

Timestep Collection Time: 2.36616
Timestep Consumption Time: 2.50309
PPO Batch Consumption Time: 0.29623
Total Iteration Time: 4.86924

Cumulative Model Updates: 59,012
Cumulative Timesteps: 492,255,292

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,092.95063
Policy Entropy: 3.45837
Value Function Loss: 0.00324

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.09399
Policy Update Magnitude: 0.56416
Value Function Update Magnitude: 0.60496

Collected Steps per Second: 22,480.14211
Overall Steps per Second: 10,549.37805

Timestep Collection Time: 2.22481
Timestep Consumption Time: 2.51614
PPO Batch Consumption Time: 0.29388
Total Iteration Time: 4.74094

Cumulative Model Updates: 59,018
Cumulative Timesteps: 492,305,306

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 492305306...
Checkpoint 492305306 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,522.35239
Policy Entropy: 3.45415
Value Function Loss: 0.00323

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.11497
Policy Update Magnitude: 0.56030
Value Function Update Magnitude: 0.60746

Collected Steps per Second: 21,929.49770
Overall Steps per Second: 10,527.23798

Timestep Collection Time: 2.28113
Timestep Consumption Time: 2.47074
PPO Batch Consumption Time: 0.28000
Total Iteration Time: 4.75186

Cumulative Model Updates: 59,024
Cumulative Timesteps: 492,355,330

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,246.98382
Policy Entropy: 3.44472
Value Function Loss: 0.00295

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.09956
Policy Update Magnitude: 0.54999
Value Function Update Magnitude: 0.60038

Collected Steps per Second: 22,705.27526
Overall Steps per Second: 10,599.89636

Timestep Collection Time: 2.20284
Timestep Consumption Time: 2.51570
PPO Batch Consumption Time: 0.29201
Total Iteration Time: 4.71854

Cumulative Model Updates: 59,030
Cumulative Timesteps: 492,405,346

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 492405346...
Checkpoint 492405346 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,121.46309
Policy Entropy: 3.45231
Value Function Loss: 0.00309

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.10010
Policy Update Magnitude: 0.54277
Value Function Update Magnitude: 0.57961

Collected Steps per Second: 21,270.38194
Overall Steps per Second: 10,432.50412

Timestep Collection Time: 2.35200
Timestep Consumption Time: 2.44339
PPO Batch Consumption Time: 0.28153
Total Iteration Time: 4.79540

Cumulative Model Updates: 59,036
Cumulative Timesteps: 492,455,374

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,597.99771
Policy Entropy: 3.44771
Value Function Loss: 0.00317

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.09589
Policy Update Magnitude: 0.54062
Value Function Update Magnitude: 0.57491

Collected Steps per Second: 22,447.38633
Overall Steps per Second: 10,522.18461

Timestep Collection Time: 2.22788
Timestep Consumption Time: 2.52494
PPO Batch Consumption Time: 0.29569
Total Iteration Time: 4.75282

Cumulative Model Updates: 59,042
Cumulative Timesteps: 492,505,384

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 492505384...
Checkpoint 492505384 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,365.58000
Policy Entropy: 3.46343
Value Function Loss: 0.00334

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.11050
Policy Update Magnitude: 0.54315
Value Function Update Magnitude: 0.59337

Collected Steps per Second: 21,969.19174
Overall Steps per Second: 10,652.77399

Timestep Collection Time: 2.27664
Timestep Consumption Time: 2.41847
PPO Batch Consumption Time: 0.28004
Total Iteration Time: 4.69512

Cumulative Model Updates: 59,048
Cumulative Timesteps: 492,555,400

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 660.96997
Policy Entropy: 3.46717
Value Function Loss: 0.00343

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.10420
Policy Update Magnitude: 0.54999
Value Function Update Magnitude: 0.62985

Collected Steps per Second: 22,109.18378
Overall Steps per Second: 10,517.74039

Timestep Collection Time: 2.26232
Timestep Consumption Time: 2.49327
PPO Batch Consumption Time: 0.29400
Total Iteration Time: 4.75558

Cumulative Model Updates: 59,054
Cumulative Timesteps: 492,605,418

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 492605418...
Checkpoint 492605418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,170.61318
Policy Entropy: 3.47608
Value Function Loss: 0.00348

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.11176
Policy Update Magnitude: 0.55745
Value Function Update Magnitude: 0.64679

Collected Steps per Second: 21,752.40586
Overall Steps per Second: 10,609.04108

Timestep Collection Time: 2.29961
Timestep Consumption Time: 2.41543
PPO Batch Consumption Time: 0.27998
Total Iteration Time: 4.71504

Cumulative Model Updates: 59,060
Cumulative Timesteps: 492,655,440

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 679.98663
Policy Entropy: 3.47540
Value Function Loss: 0.00342

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.11394
Policy Update Magnitude: 0.55180
Value Function Update Magnitude: 0.64116

Collected Steps per Second: 22,430.43795
Overall Steps per Second: 10,745.79421

Timestep Collection Time: 2.23001
Timestep Consumption Time: 2.42484
PPO Batch Consumption Time: 0.28122
Total Iteration Time: 4.65484

Cumulative Model Updates: 59,066
Cumulative Timesteps: 492,705,460

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 492705460...
Checkpoint 492705460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,061.14989
Policy Entropy: 3.46573
Value Function Loss: 0.00341

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.10377
Policy Update Magnitude: 0.54085
Value Function Update Magnitude: 0.63286

Collected Steps per Second: 21,571.68431
Overall Steps per Second: 10,376.64469

Timestep Collection Time: 2.31841
Timestep Consumption Time: 2.50126
PPO Batch Consumption Time: 0.29502
Total Iteration Time: 4.81967

Cumulative Model Updates: 59,072
Cumulative Timesteps: 492,755,472

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,046.75053
Policy Entropy: 3.46150
Value Function Loss: 0.00329

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.09848
Policy Update Magnitude: 0.54209
Value Function Update Magnitude: 0.63349

Collected Steps per Second: 22,335.97986
Overall Steps per Second: 10,588.45087

Timestep Collection Time: 2.23962
Timestep Consumption Time: 2.48478
PPO Batch Consumption Time: 0.29340
Total Iteration Time: 4.72439

Cumulative Model Updates: 59,078
Cumulative Timesteps: 492,805,496

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 492805496...
Checkpoint 492805496 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,121.09572
Policy Entropy: 3.46125
Value Function Loss: 0.00329

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.10094
Policy Update Magnitude: 0.54769
Value Function Update Magnitude: 0.62354

Collected Steps per Second: 22,228.36641
Overall Steps per Second: 10,557.61300

Timestep Collection Time: 2.25109
Timestep Consumption Time: 2.48843
PPO Batch Consumption Time: 0.29512
Total Iteration Time: 4.73952

Cumulative Model Updates: 59,084
Cumulative Timesteps: 492,855,534

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 980.85176
Policy Entropy: 3.46295
Value Function Loss: 0.00304

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.09409
Policy Update Magnitude: 0.54190
Value Function Update Magnitude: 0.59668

Collected Steps per Second: 22,398.84448
Overall Steps per Second: 10,711.16185

Timestep Collection Time: 2.23235
Timestep Consumption Time: 2.43587
PPO Batch Consumption Time: 0.28187
Total Iteration Time: 4.66821

Cumulative Model Updates: 59,090
Cumulative Timesteps: 492,905,536

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 492905536...
Checkpoint 492905536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,144.81172
Policy Entropy: 3.44709
Value Function Loss: 0.00314

Mean KL Divergence: 0.00745
SB3 Clip Fraction: 0.08810
Policy Update Magnitude: 0.53151
Value Function Update Magnitude: 0.57724

Collected Steps per Second: 19,987.38043
Overall Steps per Second: 10,143.85028

Timestep Collection Time: 2.50278
Timestep Consumption Time: 2.42868
PPO Batch Consumption Time: 0.28872
Total Iteration Time: 4.93146

Cumulative Model Updates: 59,096
Cumulative Timesteps: 492,955,560

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,115.73910
Policy Entropy: 3.44266
Value Function Loss: 0.00301

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.09685
Policy Update Magnitude: 0.52588
Value Function Update Magnitude: 0.57396

Collected Steps per Second: 20,050.42507
Overall Steps per Second: 9,888.72066

Timestep Collection Time: 2.49491
Timestep Consumption Time: 2.56378
PPO Batch Consumption Time: 0.29614
Total Iteration Time: 5.05869

Cumulative Model Updates: 59,102
Cumulative Timesteps: 493,005,584

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 493005584...
Checkpoint 493005584 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,701.86630
Policy Entropy: 3.44254
Value Function Loss: 0.00288

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.09314
Policy Update Magnitude: 0.51883
Value Function Update Magnitude: 0.56129

Collected Steps per Second: 20,949.04275
Overall Steps per Second: 10,263.86572

Timestep Collection Time: 2.38674
Timestep Consumption Time: 2.48471
PPO Batch Consumption Time: 0.29281
Total Iteration Time: 4.87146

Cumulative Model Updates: 59,108
Cumulative Timesteps: 493,055,584

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,845.51962
Policy Entropy: 3.44166
Value Function Loss: 0.00299

Mean KL Divergence: 0.00743
SB3 Clip Fraction: 0.08558
Policy Update Magnitude: 0.52422
Value Function Update Magnitude: 0.57512

Collected Steps per Second: 22,425.66304
Overall Steps per Second: 10,686.05466

Timestep Collection Time: 2.23057
Timestep Consumption Time: 2.45048
PPO Batch Consumption Time: 0.28572
Total Iteration Time: 4.68105

Cumulative Model Updates: 59,114
Cumulative Timesteps: 493,105,606

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 493105606...
Checkpoint 493105606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,256.49582
Policy Entropy: 3.44464
Value Function Loss: 0.00291

Mean KL Divergence: 0.00763
SB3 Clip Fraction: 0.08886
Policy Update Magnitude: 0.52104
Value Function Update Magnitude: 0.60054

Collected Steps per Second: 21,443.83178
Overall Steps per Second: 10,310.07783

Timestep Collection Time: 2.33177
Timestep Consumption Time: 2.51805
PPO Batch Consumption Time: 0.29439
Total Iteration Time: 4.84982

Cumulative Model Updates: 59,120
Cumulative Timesteps: 493,155,608

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,577.99803
Policy Entropy: 3.43761
Value Function Loss: 0.00309

Mean KL Divergence: 0.00735
SB3 Clip Fraction: 0.08506
Policy Update Magnitude: 0.52135
Value Function Update Magnitude: 0.60639

Collected Steps per Second: 22,190.35872
Overall Steps per Second: 10,448.30862

Timestep Collection Time: 2.25350
Timestep Consumption Time: 2.53254
PPO Batch Consumption Time: 0.29469
Total Iteration Time: 4.78604

Cumulative Model Updates: 59,126
Cumulative Timesteps: 493,205,614

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 493205614...
Checkpoint 493205614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,119.57367
Policy Entropy: 3.43908
Value Function Loss: 0.00320

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.09606
Policy Update Magnitude: 0.52598
Value Function Update Magnitude: 0.61135

Collected Steps per Second: 22,033.28704
Overall Steps per Second: 10,557.97739

Timestep Collection Time: 2.27066
Timestep Consumption Time: 2.46794
PPO Batch Consumption Time: 0.28902
Total Iteration Time: 4.73860

Cumulative Model Updates: 59,132
Cumulative Timesteps: 493,255,644

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,316.12751
Policy Entropy: 3.45332
Value Function Loss: 0.00324

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.09441
Policy Update Magnitude: 0.53877
Value Function Update Magnitude: 0.61469

Collected Steps per Second: 22,483.97937
Overall Steps per Second: 10,634.95559

Timestep Collection Time: 2.22443
Timestep Consumption Time: 2.47837
PPO Batch Consumption Time: 0.29025
Total Iteration Time: 4.70279

Cumulative Model Updates: 59,138
Cumulative Timesteps: 493,305,658

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 493305658...
Checkpoint 493305658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 553.28104
Policy Entropy: 3.46787
Value Function Loss: 0.00329

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.08947
Policy Update Magnitude: 0.54449
Value Function Update Magnitude: 0.61057

Collected Steps per Second: 21,949.51208
Overall Steps per Second: 10,490.19839

Timestep Collection Time: 2.27814
Timestep Consumption Time: 2.48860
PPO Batch Consumption Time: 0.29570
Total Iteration Time: 4.76674

Cumulative Model Updates: 59,144
Cumulative Timesteps: 493,355,662

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 739.28801
Policy Entropy: 3.47630
Value Function Loss: 0.00307

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.09083
Policy Update Magnitude: 0.53610
Value Function Update Magnitude: 0.60863

Collected Steps per Second: 22,277.35995
Overall Steps per Second: 10,592.22870

Timestep Collection Time: 2.24452
Timestep Consumption Time: 2.47611
PPO Batch Consumption Time: 0.29152
Total Iteration Time: 4.72063

Cumulative Model Updates: 59,150
Cumulative Timesteps: 493,405,664

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 493405664...
Checkpoint 493405664 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 806.66418
Policy Entropy: 3.47472
Value Function Loss: 0.00310

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.09196
Policy Update Magnitude: 0.52598
Value Function Update Magnitude: 0.60774

Collected Steps per Second: 21,044.95098
Overall Steps per Second: 10,267.77286

Timestep Collection Time: 2.37701
Timestep Consumption Time: 2.49494
PPO Batch Consumption Time: 0.29525
Total Iteration Time: 4.87194

Cumulative Model Updates: 59,156
Cumulative Timesteps: 493,455,688

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,217.06460
Policy Entropy: 3.46539
Value Function Loss: 0.00300

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.10215
Policy Update Magnitude: 0.53281
Value Function Update Magnitude: 0.61312

Collected Steps per Second: 20,850.68702
Overall Steps per Second: 9,526.99175

Timestep Collection Time: 2.39935
Timestep Consumption Time: 2.85184
PPO Batch Consumption Time: 0.33871
Total Iteration Time: 5.25119

Cumulative Model Updates: 59,162
Cumulative Timesteps: 493,505,716

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 493505716...
Checkpoint 493505716 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,185.35830
Policy Entropy: 3.47124
Value Function Loss: 0.00305

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.09855
Policy Update Magnitude: 0.53568
Value Function Update Magnitude: 0.63316

Collected Steps per Second: 21,905.76475
Overall Steps per Second: 10,551.11120

Timestep Collection Time: 2.28342
Timestep Consumption Time: 2.45732
PPO Batch Consumption Time: 0.28608
Total Iteration Time: 4.74073

Cumulative Model Updates: 59,168
Cumulative Timesteps: 493,555,736

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,471.44974
Policy Entropy: 3.46575
Value Function Loss: 0.00307

Mean KL Divergence: 0.00749
SB3 Clip Fraction: 0.08836
Policy Update Magnitude: 0.53338
Value Function Update Magnitude: 0.63334

Collected Steps per Second: 22,260.42228
Overall Steps per Second: 10,441.22124

Timestep Collection Time: 2.24677
Timestep Consumption Time: 2.54328
PPO Batch Consumption Time: 0.29438
Total Iteration Time: 4.79005

Cumulative Model Updates: 59,174
Cumulative Timesteps: 493,605,750

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 493605750...
Checkpoint 493605750 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,030.24655
Policy Entropy: 3.45476
Value Function Loss: 0.00316

Mean KL Divergence: 0.00749
SB3 Clip Fraction: 0.08878
Policy Update Magnitude: 0.53347
Value Function Update Magnitude: 0.63804

Collected Steps per Second: 20,800.60535
Overall Steps per Second: 9,792.82769

Timestep Collection Time: 2.40416
Timestep Consumption Time: 2.70243
PPO Batch Consumption Time: 0.31075
Total Iteration Time: 5.10659

Cumulative Model Updates: 59,180
Cumulative Timesteps: 493,655,758

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,474.51007
Policy Entropy: 3.45719
Value Function Loss: 0.00317

Mean KL Divergence: 0.00678
SB3 Clip Fraction: 0.07955
Policy Update Magnitude: 0.53708
Value Function Update Magnitude: 0.64029

Collected Steps per Second: 20,513.02585
Overall Steps per Second: 9,531.10570

Timestep Collection Time: 2.43757
Timestep Consumption Time: 2.80862
PPO Batch Consumption Time: 0.32629
Total Iteration Time: 5.24619

Cumulative Model Updates: 59,186
Cumulative Timesteps: 493,705,760

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 493705760...
Checkpoint 493705760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,545.17888
Policy Entropy: 3.45225
Value Function Loss: 0.00303

Mean KL Divergence: 0.00716
SB3 Clip Fraction: 0.08445
Policy Update Magnitude: 0.53793
Value Function Update Magnitude: 0.63468

Collected Steps per Second: 19,425.50138
Overall Steps per Second: 9,835.08568

Timestep Collection Time: 2.57548
Timestep Consumption Time: 2.51141
PPO Batch Consumption Time: 0.28522
Total Iteration Time: 5.08689

Cumulative Model Updates: 59,192
Cumulative Timesteps: 493,755,790

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,130.36569
Policy Entropy: 3.45205
Value Function Loss: 0.00274

Mean KL Divergence: 0.00696
SB3 Clip Fraction: 0.08061
Policy Update Magnitude: 0.52919
Value Function Update Magnitude: 0.60993

Collected Steps per Second: 21,826.96762
Overall Steps per Second: 10,531.99079

Timestep Collection Time: 2.29221
Timestep Consumption Time: 2.45827
PPO Batch Consumption Time: 0.28122
Total Iteration Time: 4.75048

Cumulative Model Updates: 59,198
Cumulative Timesteps: 493,805,822

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 493805822...
Checkpoint 493805822 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,012.78128
Policy Entropy: 3.43958
Value Function Loss: 0.00274

Mean KL Divergence: 0.00649
SB3 Clip Fraction: 0.07574
Policy Update Magnitude: 0.52872
Value Function Update Magnitude: 0.60286

Collected Steps per Second: 21,960.57943
Overall Steps per Second: 10,658.08586

Timestep Collection Time: 2.27699
Timestep Consumption Time: 2.41466
PPO Batch Consumption Time: 0.28116
Total Iteration Time: 4.69165

Cumulative Model Updates: 59,204
Cumulative Timesteps: 493,855,826

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,644.20350
Policy Entropy: 3.43000
Value Function Loss: 0.00293

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.09299
Policy Update Magnitude: 0.53406
Value Function Update Magnitude: 0.62323

Collected Steps per Second: 22,188.12668
Overall Steps per Second: 10,510.54562

Timestep Collection Time: 2.25445
Timestep Consumption Time: 2.50477
PPO Batch Consumption Time: 0.29424
Total Iteration Time: 4.75922

Cumulative Model Updates: 59,210
Cumulative Timesteps: 493,905,848

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 493905848...
Checkpoint 493905848 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 993.52046
Policy Entropy: 3.44093
Value Function Loss: 0.00300

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.10162
Policy Update Magnitude: 0.53652
Value Function Update Magnitude: 0.63720

Collected Steps per Second: 21,831.72302
Overall Steps per Second: 10,526.23584

Timestep Collection Time: 2.29162
Timestep Consumption Time: 2.46127
PPO Batch Consumption Time: 0.28449
Total Iteration Time: 4.75289

Cumulative Model Updates: 59,216
Cumulative Timesteps: 493,955,878

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,382.54984
Policy Entropy: 3.45101
Value Function Loss: 0.00314

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.10449
Policy Update Magnitude: 0.54442
Value Function Update Magnitude: 0.63768

Collected Steps per Second: 20,354.25188
Overall Steps per Second: 9,378.82620

Timestep Collection Time: 2.45747
Timestep Consumption Time: 2.87582
PPO Batch Consumption Time: 0.33752
Total Iteration Time: 5.33329

Cumulative Model Updates: 59,222
Cumulative Timesteps: 494,005,898

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 494005898...
Checkpoint 494005898 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,100.93302
Policy Entropy: 3.46939
Value Function Loss: 0.00313

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.09191
Policy Update Magnitude: 0.54744
Value Function Update Magnitude: 0.63061

Collected Steps per Second: 18,932.71997
Overall Steps per Second: 9,166.79962

Timestep Collection Time: 2.64114
Timestep Consumption Time: 2.81376
PPO Batch Consumption Time: 0.33398
Total Iteration Time: 5.45490

Cumulative Model Updates: 59,228
Cumulative Timesteps: 494,055,902

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,806.68351
Policy Entropy: 3.46723
Value Function Loss: 0.00302

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.09675
Policy Update Magnitude: 0.54306
Value Function Update Magnitude: 0.61575

Collected Steps per Second: 18,258.02439
Overall Steps per Second: 9,090.71672

Timestep Collection Time: 2.74115
Timestep Consumption Time: 2.76425
PPO Batch Consumption Time: 0.32105
Total Iteration Time: 5.50540

Cumulative Model Updates: 59,234
Cumulative Timesteps: 494,105,950

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 494105950...
Checkpoint 494105950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,014.05365
Policy Entropy: 3.47407
Value Function Loss: 0.00299

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.09566
Policy Update Magnitude: 0.52612
Value Function Update Magnitude: 0.62593

Collected Steps per Second: 21,853.27346
Overall Steps per Second: 10,361.80594

Timestep Collection Time: 2.28872
Timestep Consumption Time: 2.53824
PPO Batch Consumption Time: 0.29504
Total Iteration Time: 4.82696

Cumulative Model Updates: 59,240
Cumulative Timesteps: 494,155,966

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,140.77341
Policy Entropy: 3.47080
Value Function Loss: 0.00298

Mean KL Divergence: 0.00717
SB3 Clip Fraction: 0.08477
Policy Update Magnitude: 0.52403
Value Function Update Magnitude: 0.63033

Collected Steps per Second: 22,328.57613
Overall Steps per Second: 10,484.24335

Timestep Collection Time: 2.23946
Timestep Consumption Time: 2.52998
PPO Batch Consumption Time: 0.29532
Total Iteration Time: 4.76944

Cumulative Model Updates: 59,246
Cumulative Timesteps: 494,205,970

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 494205970...
Checkpoint 494205970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,307.97594
Policy Entropy: 3.46560
Value Function Loss: 0.00285

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.09611
Policy Update Magnitude: 0.52818
Value Function Update Magnitude: 0.62308

Collected Steps per Second: 22,388.02295
Overall Steps per Second: 10,585.89383

Timestep Collection Time: 2.23387
Timestep Consumption Time: 2.49053
PPO Batch Consumption Time: 0.28903
Total Iteration Time: 4.72440

Cumulative Model Updates: 59,252
Cumulative Timesteps: 494,255,982

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,174.78623
Policy Entropy: 3.47234
Value Function Loss: 0.00286

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.09888
Policy Update Magnitude: 0.52389
Value Function Update Magnitude: 0.61859

Collected Steps per Second: 22,410.14572
Overall Steps per Second: 10,632.53260

Timestep Collection Time: 2.23211
Timestep Consumption Time: 2.47250
PPO Batch Consumption Time: 0.29091
Total Iteration Time: 4.70462

Cumulative Model Updates: 59,258
Cumulative Timesteps: 494,306,004

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 494306004...
Checkpoint 494306004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,538.26348
Policy Entropy: 3.47414
Value Function Loss: 0.00281

Mean KL Divergence: 0.00750
SB3 Clip Fraction: 0.08930
Policy Update Magnitude: 0.52193
Value Function Update Magnitude: 0.62411

Collected Steps per Second: 20,973.86458
Overall Steps per Second: 10,156.53510

Timestep Collection Time: 2.38430
Timestep Consumption Time: 2.53943
PPO Batch Consumption Time: 0.29470
Total Iteration Time: 4.92373

Cumulative Model Updates: 59,264
Cumulative Timesteps: 494,356,012

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,602.62533
Policy Entropy: 3.47855
Value Function Loss: 0.00282

Mean KL Divergence: 0.00733
SB3 Clip Fraction: 0.08619
Policy Update Magnitude: 0.52748
Value Function Update Magnitude: 0.60017

Collected Steps per Second: 22,270.05732
Overall Steps per Second: 10,509.38990

Timestep Collection Time: 2.24651
Timestep Consumption Time: 2.51399
PPO Batch Consumption Time: 0.29633
Total Iteration Time: 4.76050

Cumulative Model Updates: 59,270
Cumulative Timesteps: 494,406,042

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 494406042...
Checkpoint 494406042 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,727.06228
Policy Entropy: 3.46729
Value Function Loss: 0.00298

Mean KL Divergence: 0.00748
SB3 Clip Fraction: 0.08823
Policy Update Magnitude: 0.53777
Value Function Update Magnitude: 0.61541

Collected Steps per Second: 22,027.97907
Overall Steps per Second: 10,393.67969

Timestep Collection Time: 2.27048
Timestep Consumption Time: 2.54149
PPO Batch Consumption Time: 0.30117
Total Iteration Time: 4.81196

Cumulative Model Updates: 59,276
Cumulative Timesteps: 494,456,056

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,047.21563
Policy Entropy: 3.46295
Value Function Loss: 0.00291

Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.09284
Policy Update Magnitude: 0.54137
Value Function Update Magnitude: 0.63129

Collected Steps per Second: 22,269.89155
Overall Steps per Second: 10,547.15162

Timestep Collection Time: 2.24626
Timestep Consumption Time: 2.49663
PPO Batch Consumption Time: 0.29405
Total Iteration Time: 4.74289

Cumulative Model Updates: 59,282
Cumulative Timesteps: 494,506,080

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 494506080...
Checkpoint 494506080 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,136.97910
Policy Entropy: 3.46499
Value Function Loss: 0.00313

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.09426
Policy Update Magnitude: 0.54186
Value Function Update Magnitude: 0.62705

Collected Steps per Second: 21,999.24166
Overall Steps per Second: 10,609.02505

Timestep Collection Time: 2.27417
Timestep Consumption Time: 2.44163
PPO Batch Consumption Time: 0.28098
Total Iteration Time: 4.71580

Cumulative Model Updates: 59,288
Cumulative Timesteps: 494,556,110

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 743.14703
Policy Entropy: 3.45861
Value Function Loss: 0.00316

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.10513
Policy Update Magnitude: 0.55297
Value Function Update Magnitude: 0.64888

Collected Steps per Second: 22,665.00287
Overall Steps per Second: 10,577.19602

Timestep Collection Time: 2.20693
Timestep Consumption Time: 2.52211
PPO Batch Consumption Time: 0.29453
Total Iteration Time: 4.72904

Cumulative Model Updates: 59,294
Cumulative Timesteps: 494,606,130

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 494606130...
Checkpoint 494606130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,346.73906
Policy Entropy: 3.45880
Value Function Loss: 0.00308

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.11401
Policy Update Magnitude: 0.55096
Value Function Update Magnitude: 0.64130

Collected Steps per Second: 22,079.07688
Overall Steps per Second: 10,621.62538

Timestep Collection Time: 2.26586
Timestep Consumption Time: 2.44416
PPO Batch Consumption Time: 0.27977
Total Iteration Time: 4.71001

Cumulative Model Updates: 59,300
Cumulative Timesteps: 494,656,158

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,744.72565
Policy Entropy: 3.45778
Value Function Loss: 0.00290

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.09361
Policy Update Magnitude: 0.53928
Value Function Update Magnitude: 0.62340

Collected Steps per Second: 22,110.70987
Overall Steps per Second: 10,412.30769

Timestep Collection Time: 2.26207
Timestep Consumption Time: 2.54147
PPO Batch Consumption Time: 0.29294
Total Iteration Time: 4.80355

Cumulative Model Updates: 59,306
Cumulative Timesteps: 494,706,174

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 494706174...
Checkpoint 494706174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,095.98125
Policy Entropy: 3.45415
Value Function Loss: 0.00305

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.09006
Policy Update Magnitude: 0.53741
Value Function Update Magnitude: 0.61150

Collected Steps per Second: 21,080.84651
Overall Steps per Second: 10,361.24644

Timestep Collection Time: 2.37239
Timestep Consumption Time: 2.45444
PPO Batch Consumption Time: 0.29152
Total Iteration Time: 4.82683

Cumulative Model Updates: 59,312
Cumulative Timesteps: 494,756,186

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 660.38935
Policy Entropy: 3.45746
Value Function Loss: 0.00311

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.09325
Policy Update Magnitude: 0.54658
Value Function Update Magnitude: 0.59849

Collected Steps per Second: 22,295.42598
Overall Steps per Second: 10,649.15816

Timestep Collection Time: 2.24351
Timestep Consumption Time: 2.45358
PPO Batch Consumption Time: 0.28128
Total Iteration Time: 4.69708

Cumulative Model Updates: 59,318
Cumulative Timesteps: 494,806,206

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 494806206...
Checkpoint 494806206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,481.63730
Policy Entropy: 3.44698
Value Function Loss: 0.00337

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.09883
Policy Update Magnitude: 0.55521
Value Function Update Magnitude: 0.59610

Collected Steps per Second: 21,850.76590
Overall Steps per Second: 10,414.08597

Timestep Collection Time: 2.28944
Timestep Consumption Time: 2.51425
PPO Batch Consumption Time: 0.29533
Total Iteration Time: 4.80369

Cumulative Model Updates: 59,324
Cumulative Timesteps: 494,856,232

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,604.10112
Policy Entropy: 3.43848
Value Function Loss: 0.00322

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.09502
Policy Update Magnitude: 0.55360
Value Function Update Magnitude: 0.60810

Collected Steps per Second: 21,093.23409
Overall Steps per Second: 10,353.61643

Timestep Collection Time: 2.37128
Timestep Consumption Time: 2.45969
PPO Batch Consumption Time: 0.28230
Total Iteration Time: 4.83097

Cumulative Model Updates: 59,330
Cumulative Timesteps: 494,906,250

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 494906250...
Checkpoint 494906250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,126.39836
Policy Entropy: 3.41345
Value Function Loss: 0.00326

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.10953
Policy Update Magnitude: 0.55622
Value Function Update Magnitude: 0.61662

Collected Steps per Second: 21,613.52036
Overall Steps per Second: 10,468.47109

Timestep Collection Time: 2.31475
Timestep Consumption Time: 2.46436
PPO Batch Consumption Time: 0.28617
Total Iteration Time: 4.77911

Cumulative Model Updates: 59,336
Cumulative Timesteps: 494,956,280

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,618.29398
Policy Entropy: 3.40357
Value Function Loss: 0.00316

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.11361
Policy Update Magnitude: 0.55361
Value Function Update Magnitude: 0.64013

Collected Steps per Second: 22,388.74986
Overall Steps per Second: 10,684.71150

Timestep Collection Time: 2.23505
Timestep Consumption Time: 2.44828
PPO Batch Consumption Time: 0.28445
Total Iteration Time: 4.68333

Cumulative Model Updates: 59,342
Cumulative Timesteps: 495,006,320

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 495006320...
Checkpoint 495006320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,358.55867
Policy Entropy: 3.41093
Value Function Loss: 0.00306

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.11887
Policy Update Magnitude: 0.54136
Value Function Update Magnitude: 0.63442

Collected Steps per Second: 21,355.67130
Overall Steps per Second: 10,391.00310

Timestep Collection Time: 2.34158
Timestep Consumption Time: 2.47085
PPO Batch Consumption Time: 0.29175
Total Iteration Time: 4.81243

Cumulative Model Updates: 59,348
Cumulative Timesteps: 495,056,326

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 813.18443
Policy Entropy: 3.41435
Value Function Loss: 0.00316

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.10717
Policy Update Magnitude: 0.53865
Value Function Update Magnitude: 0.59916

Collected Steps per Second: 22,236.23813
Overall Steps per Second: 10,676.83969

Timestep Collection Time: 2.24903
Timestep Consumption Time: 2.43494
PPO Batch Consumption Time: 0.28280
Total Iteration Time: 4.68397

Cumulative Model Updates: 59,354
Cumulative Timesteps: 495,106,336

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 495106336...
Checkpoint 495106336 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,280.83820
Policy Entropy: 3.42050
Value Function Loss: 0.00317

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.10202
Policy Update Magnitude: 0.55323
Value Function Update Magnitude: 0.61551

Collected Steps per Second: 21,688.34070
Overall Steps per Second: 10,555.10328

Timestep Collection Time: 2.30575
Timestep Consumption Time: 2.43205
PPO Batch Consumption Time: 0.28330
Total Iteration Time: 4.73780

Cumulative Model Updates: 59,360
Cumulative Timesteps: 495,156,344

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,808.87838
Policy Entropy: 3.41942
Value Function Loss: 0.00307

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.11177
Policy Update Magnitude: 0.55898
Value Function Update Magnitude: 0.62095

Collected Steps per Second: 22,559.50339
Overall Steps per Second: 10,631.51659

Timestep Collection Time: 2.21645
Timestep Consumption Time: 2.48674
PPO Batch Consumption Time: 0.28752
Total Iteration Time: 4.70319

Cumulative Model Updates: 59,366
Cumulative Timesteps: 495,206,346

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 495206346...
Checkpoint 495206346 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 825.46626
Policy Entropy: 3.43211
Value Function Loss: 0.00317

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.08848
Policy Update Magnitude: 0.56039
Value Function Update Magnitude: 0.61102

Collected Steps per Second: 21,852.02178
Overall Steps per Second: 10,611.06852

Timestep Collection Time: 2.28812
Timestep Consumption Time: 2.42394
PPO Batch Consumption Time: 0.28033
Total Iteration Time: 4.71206

Cumulative Model Updates: 59,372
Cumulative Timesteps: 495,256,346

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,205.98099
Policy Entropy: 3.43639
Value Function Loss: 0.00327

Mean KL Divergence: 0.00760
SB3 Clip Fraction: 0.08647
Policy Update Magnitude: 0.56462
Value Function Update Magnitude: 0.61859

Collected Steps per Second: 22,017.30073
Overall Steps per Second: 10,395.79868

Timestep Collection Time: 2.27140
Timestep Consumption Time: 2.53920
PPO Batch Consumption Time: 0.30094
Total Iteration Time: 4.81060

Cumulative Model Updates: 59,378
Cumulative Timesteps: 495,306,356

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 495306356...
Checkpoint 495306356 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,403.24519
Policy Entropy: 3.43619
Value Function Loss: 0.00330

Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.09881
Policy Update Magnitude: 0.56328
Value Function Update Magnitude: 0.63065

Collected Steps per Second: 21,548.18153
Overall Steps per Second: 10,413.42509

Timestep Collection Time: 2.32150
Timestep Consumption Time: 2.48230
PPO Batch Consumption Time: 0.29077
Total Iteration Time: 4.80380

Cumulative Model Updates: 59,384
Cumulative Timesteps: 495,356,380

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,277.61034
Policy Entropy: 3.43397
Value Function Loss: 0.00320

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.09127
Policy Update Magnitude: 0.56775
Value Function Update Magnitude: 0.64920

Collected Steps per Second: 21,799.62799
Overall Steps per Second: 10,545.97767

Timestep Collection Time: 2.29398
Timestep Consumption Time: 2.44792
PPO Batch Consumption Time: 0.28711
Total Iteration Time: 4.74190

Cumulative Model Updates: 59,390
Cumulative Timesteps: 495,406,388

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 495406388...
Checkpoint 495406388 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,154.51049
Policy Entropy: 3.42424
Value Function Loss: 0.00305

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.10420
Policy Update Magnitude: 0.56619
Value Function Update Magnitude: 0.64802

Collected Steps per Second: 21,648.73162
Overall Steps per Second: 10,414.45919

Timestep Collection Time: 2.30979
Timestep Consumption Time: 2.49161
PPO Batch Consumption Time: 0.29565
Total Iteration Time: 4.80140

Cumulative Model Updates: 59,396
Cumulative Timesteps: 495,456,392

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,173.22238
Policy Entropy: 3.43063
Value Function Loss: 0.00306

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.09385
Policy Update Magnitude: 0.56234
Value Function Update Magnitude: 0.64861

Collected Steps per Second: 22,497.45693
Overall Steps per Second: 10,778.31177

Timestep Collection Time: 2.22398
Timestep Consumption Time: 2.41812
PPO Batch Consumption Time: 0.28168
Total Iteration Time: 4.64210

Cumulative Model Updates: 59,402
Cumulative Timesteps: 495,506,426

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 495506426...
Checkpoint 495506426 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 748.23005
Policy Entropy: 3.42680
Value Function Loss: 0.00303

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.10271
Policy Update Magnitude: 0.56164
Value Function Update Magnitude: 0.63270

Collected Steps per Second: 20,205.32915
Overall Steps per Second: 9,575.03458

Timestep Collection Time: 2.47568
Timestep Consumption Time: 2.74853
PPO Batch Consumption Time: 0.32200
Total Iteration Time: 5.22421

Cumulative Model Updates: 59,408
Cumulative Timesteps: 495,556,448

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 882.72941
Policy Entropy: 3.43330
Value Function Loss: 0.00309

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.09550
Policy Update Magnitude: 0.56271
Value Function Update Magnitude: 0.63455

Collected Steps per Second: 19,938.24412
Overall Steps per Second: 9,714.93701

Timestep Collection Time: 2.50985
Timestep Consumption Time: 2.64119
PPO Batch Consumption Time: 0.31103
Total Iteration Time: 5.15104

Cumulative Model Updates: 59,414
Cumulative Timesteps: 495,606,490

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 495606490...
Checkpoint 495606490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,006.59218
Policy Entropy: 3.43300
Value Function Loss: 0.00315

Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.09351
Policy Update Magnitude: 0.55419
Value Function Update Magnitude: 0.63269

Collected Steps per Second: 19,032.29232
Overall Steps per Second: 9,694.37639

Timestep Collection Time: 2.62859
Timestep Consumption Time: 2.53193
PPO Batch Consumption Time: 0.30239
Total Iteration Time: 5.16052

Cumulative Model Updates: 59,420
Cumulative Timesteps: 495,656,518

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 918.59269
Policy Entropy: 3.44153
Value Function Loss: 0.00308

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.09745
Policy Update Magnitude: 0.55353
Value Function Update Magnitude: 0.65728

Collected Steps per Second: 20,188.00942
Overall Steps per Second: 9,899.18437

Timestep Collection Time: 2.47731
Timestep Consumption Time: 2.57482
PPO Batch Consumption Time: 0.30220
Total Iteration Time: 5.05213

Cumulative Model Updates: 59,426
Cumulative Timesteps: 495,706,530

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 495706530...
Checkpoint 495706530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,437.17925
Policy Entropy: 3.44970
Value Function Loss: 0.00295

Mean KL Divergence: 0.00721
SB3 Clip Fraction: 0.08573
Policy Update Magnitude: 0.54648
Value Function Update Magnitude: 0.63728

Collected Steps per Second: 19,379.44179
Overall Steps per Second: 9,564.98679

Timestep Collection Time: 2.58129
Timestep Consumption Time: 2.64862
PPO Batch Consumption Time: 0.31076
Total Iteration Time: 5.22991

Cumulative Model Updates: 59,432
Cumulative Timesteps: 495,756,554

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,964.37466
Policy Entropy: 3.44975
Value Function Loss: 0.00301

Mean KL Divergence: 0.00690
SB3 Clip Fraction: 0.08105
Policy Update Magnitude: 0.54384
Value Function Update Magnitude: 0.61832

Collected Steps per Second: 21,159.32639
Overall Steps per Second: 10,165.66746

Timestep Collection Time: 2.36444
Timestep Consumption Time: 2.55703
PPO Batch Consumption Time: 0.29449
Total Iteration Time: 4.92147

Cumulative Model Updates: 59,438
Cumulative Timesteps: 495,806,584

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 495806584...
Checkpoint 495806584 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,057.06132
Policy Entropy: 3.44235
Value Function Loss: 0.00324

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.08908
Policy Update Magnitude: 0.55863
Value Function Update Magnitude: 0.61101

Collected Steps per Second: 21,559.50103
Overall Steps per Second: 10,491.72610

Timestep Collection Time: 2.32037
Timestep Consumption Time: 2.44777
PPO Batch Consumption Time: 0.28072
Total Iteration Time: 4.76814

Cumulative Model Updates: 59,444
Cumulative Timesteps: 495,856,610

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 741.25347
Policy Entropy: 3.43846
Value Function Loss: 0.00332

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.09240
Policy Update Magnitude: 0.56242
Value Function Update Magnitude: 0.63254

Collected Steps per Second: 22,467.45992
Overall Steps per Second: 10,499.97077

Timestep Collection Time: 2.22589
Timestep Consumption Time: 2.53698
PPO Batch Consumption Time: 0.30212
Total Iteration Time: 4.76287

Cumulative Model Updates: 59,450
Cumulative Timesteps: 495,906,620

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 495906620...
Checkpoint 495906620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,985.36351
Policy Entropy: 3.45220
Value Function Loss: 0.00331

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.09085
Policy Update Magnitude: 0.56455
Value Function Update Magnitude: 0.65260

Collected Steps per Second: 18,980.68556
Overall Steps per Second: 9,861.42839

Timestep Collection Time: 2.63426
Timestep Consumption Time: 2.43600
PPO Batch Consumption Time: 0.28481
Total Iteration Time: 5.07026

Cumulative Model Updates: 59,456
Cumulative Timesteps: 495,956,620

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,472.93151
Policy Entropy: 3.46007
Value Function Loss: 0.00327

Mean KL Divergence: 0.00759
SB3 Clip Fraction: 0.08837
Policy Update Magnitude: 0.56055
Value Function Update Magnitude: 0.63587

Collected Steps per Second: 22,209.52498
Overall Steps per Second: 10,249.33359

Timestep Collection Time: 2.25246
Timestep Consumption Time: 2.62845
PPO Batch Consumption Time: 0.30894
Total Iteration Time: 4.88090

Cumulative Model Updates: 59,462
Cumulative Timesteps: 496,006,646

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 496006646...
Checkpoint 496006646 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 597.73045
Policy Entropy: 3.47590
Value Function Loss: 0.00347

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.09169
Policy Update Magnitude: 0.56369
Value Function Update Magnitude: 0.65665

Collected Steps per Second: 21,573.16326
Overall Steps per Second: 10,407.43240

Timestep Collection Time: 2.31871
Timestep Consumption Time: 2.48766
PPO Batch Consumption Time: 0.29396
Total Iteration Time: 4.80637

Cumulative Model Updates: 59,468
Cumulative Timesteps: 496,056,668

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,549.21110
Policy Entropy: 3.48210
Value Function Loss: 0.00329

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.10759
Policy Update Magnitude: 0.55658
Value Function Update Magnitude: 0.65633

Collected Steps per Second: 21,494.37114
Overall Steps per Second: 9,845.62889

Timestep Collection Time: 2.32656
Timestep Consumption Time: 2.75265
PPO Batch Consumption Time: 0.32169
Total Iteration Time: 5.07921

Cumulative Model Updates: 59,474
Cumulative Timesteps: 496,106,676

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 496106676...
Checkpoint 496106676 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,312.71977
Policy Entropy: 3.48250
Value Function Loss: 0.00328

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.10650
Policy Update Magnitude: 0.54713
Value Function Update Magnitude: 0.62973

Collected Steps per Second: 18,623.47744
Overall Steps per Second: 9,033.63238

Timestep Collection Time: 2.68521
Timestep Consumption Time: 2.85054
PPO Batch Consumption Time: 0.35137
Total Iteration Time: 5.53576

Cumulative Model Updates: 59,480
Cumulative Timesteps: 496,156,684

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,202.30664
Policy Entropy: 3.47077
Value Function Loss: 0.00314

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.09532
Policy Update Magnitude: 0.54422
Value Function Update Magnitude: 0.61001

Collected Steps per Second: 19,923.28722
Overall Steps per Second: 9,870.85260

Timestep Collection Time: 2.51043
Timestep Consumption Time: 2.55661
PPO Batch Consumption Time: 0.28966
Total Iteration Time: 5.06704

Cumulative Model Updates: 59,486
Cumulative Timesteps: 496,206,700

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 496206700...
Checkpoint 496206700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,567.75184
Policy Entropy: 3.47057
Value Function Loss: 0.00340

Mean KL Divergence: 0.00710
SB3 Clip Fraction: 0.08264
Policy Update Magnitude: 0.55235
Value Function Update Magnitude: 0.62218

Collected Steps per Second: 22,149.25369
Overall Steps per Second: 10,725.12593

Timestep Collection Time: 2.25750
Timestep Consumption Time: 2.40463
PPO Batch Consumption Time: 0.28055
Total Iteration Time: 4.66214

Cumulative Model Updates: 59,492
Cumulative Timesteps: 496,256,702

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,477.45192
Policy Entropy: 3.46813
Value Function Loss: 0.00329

Mean KL Divergence: 0.00684
SB3 Clip Fraction: 0.07884
Policy Update Magnitude: 0.56102
Value Function Update Magnitude: 0.65712

Collected Steps per Second: 22,416.42780
Overall Steps per Second: 10,593.05316

Timestep Collection Time: 2.23077
Timestep Consumption Time: 2.48987
PPO Batch Consumption Time: 0.29116
Total Iteration Time: 4.72064

Cumulative Model Updates: 59,498
Cumulative Timesteps: 496,306,708

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 496306708...
Checkpoint 496306708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,120.33377
Policy Entropy: 3.47560
Value Function Loss: 0.00311

Mean KL Divergence: 0.00683
SB3 Clip Fraction: 0.07781
Policy Update Magnitude: 0.56694
Value Function Update Magnitude: 0.66032

Collected Steps per Second: 22,214.88485
Overall Steps per Second: 10,486.14199

Timestep Collection Time: 2.25209
Timestep Consumption Time: 2.51897
PPO Batch Consumption Time: 0.29538
Total Iteration Time: 4.77106

Cumulative Model Updates: 59,504
Cumulative Timesteps: 496,356,738

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,229.67458
Policy Entropy: 3.47569
Value Function Loss: 0.00296

Mean KL Divergence: 0.00717
SB3 Clip Fraction: 0.08179
Policy Update Magnitude: 0.56024
Value Function Update Magnitude: 0.64132

Collected Steps per Second: 21,601.24301
Overall Steps per Second: 10,405.09969

Timestep Collection Time: 2.31477
Timestep Consumption Time: 2.49075
PPO Batch Consumption Time: 0.29110
Total Iteration Time: 4.80553

Cumulative Model Updates: 59,510
Cumulative Timesteps: 496,406,740

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 496406740...
Checkpoint 496406740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,555.02061
Policy Entropy: 3.47117
Value Function Loss: 0.00336

Mean KL Divergence: 0.00714
SB3 Clip Fraction: 0.08191
Policy Update Magnitude: 0.55818
Value Function Update Magnitude: 0.61573

Collected Steps per Second: 22,088.81684
Overall Steps per Second: 10,673.57266

Timestep Collection Time: 2.26531
Timestep Consumption Time: 2.42272
PPO Batch Consumption Time: 0.28035
Total Iteration Time: 4.68803

Cumulative Model Updates: 59,516
Cumulative Timesteps: 496,456,778

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,038.91054
Policy Entropy: 3.46959
Value Function Loss: 0.00338

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.09490
Policy Update Magnitude: 0.56892
Value Function Update Magnitude: 0.62875

Collected Steps per Second: 22,372.87353
Overall Steps per Second: 10,606.99438

Timestep Collection Time: 2.23583
Timestep Consumption Time: 2.48011
PPO Batch Consumption Time: 0.29175
Total Iteration Time: 4.71594

Cumulative Model Updates: 59,522
Cumulative Timesteps: 496,506,800

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 496506800...
Checkpoint 496506800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,453.91439
Policy Entropy: 3.46598
Value Function Loss: 0.00335

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.10106
Policy Update Magnitude: 0.56294
Value Function Update Magnitude: 0.62984

Collected Steps per Second: 22,027.08920
Overall Steps per Second: 10,411.64626

Timestep Collection Time: 2.27139
Timestep Consumption Time: 2.53400
PPO Batch Consumption Time: 0.29392
Total Iteration Time: 4.80539

Cumulative Model Updates: 59,528
Cumulative Timesteps: 496,556,832

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 799.62528
Policy Entropy: 3.46594
Value Function Loss: 0.00293

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.10219
Policy Update Magnitude: 0.55059
Value Function Update Magnitude: 0.58659

Collected Steps per Second: 22,220.91813
Overall Steps per Second: 10,365.54309

Timestep Collection Time: 2.25103
Timestep Consumption Time: 2.57457
PPO Batch Consumption Time: 0.30111
Total Iteration Time: 4.82560

Cumulative Model Updates: 59,534
Cumulative Timesteps: 496,606,852

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 496606852...
Checkpoint 496606852 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,054.71831
Policy Entropy: 3.46383
Value Function Loss: 0.00294

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.09326
Policy Update Magnitude: 0.54685
Value Function Update Magnitude: 0.58306

Collected Steps per Second: 21,061.79960
Overall Steps per Second: 10,134.85885

Timestep Collection Time: 2.37416
Timestep Consumption Time: 2.55971
PPO Batch Consumption Time: 0.29408
Total Iteration Time: 4.93386

Cumulative Model Updates: 59,540
Cumulative Timesteps: 496,656,856

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,124.90060
Policy Entropy: 3.46485
Value Function Loss: 0.00302

Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.09231
Policy Update Magnitude: 0.55067
Value Function Update Magnitude: 0.59293

Collected Steps per Second: 22,336.89595
Overall Steps per Second: 10,498.90004

Timestep Collection Time: 2.23988
Timestep Consumption Time: 2.52557
PPO Batch Consumption Time: 0.29401
Total Iteration Time: 4.76545

Cumulative Model Updates: 59,546
Cumulative Timesteps: 496,706,888

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 496706888...
Checkpoint 496706888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,094.33300
Policy Entropy: 3.46541
Value Function Loss: 0.00313

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.09672
Policy Update Magnitude: 0.55829
Value Function Update Magnitude: 0.60653

Collected Steps per Second: 21,301.82980
Overall Steps per Second: 10,380.79346

Timestep Collection Time: 2.34722
Timestep Consumption Time: 2.46937
PPO Batch Consumption Time: 0.28903
Total Iteration Time: 4.81659

Cumulative Model Updates: 59,552
Cumulative Timesteps: 496,756,888

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 692.21312
Policy Entropy: 3.46107
Value Function Loss: 0.00312

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.10245
Policy Update Magnitude: 0.55879
Value Function Update Magnitude: 0.60485

Collected Steps per Second: 22,012.28947
Overall Steps per Second: 10,468.52697

Timestep Collection Time: 2.27191
Timestep Consumption Time: 2.50526
PPO Batch Consumption Time: 0.29585
Total Iteration Time: 4.77718

Cumulative Model Updates: 59,558
Cumulative Timesteps: 496,806,898

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 496806898...
Checkpoint 496806898 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 898.17295
Policy Entropy: 3.45176
Value Function Loss: 0.00326

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.08983
Policy Update Magnitude: 0.56425
Value Function Update Magnitude: 0.60456

Collected Steps per Second: 20,839.59324
Overall Steps per Second: 10,201.04268

Timestep Collection Time: 2.40053
Timestep Consumption Time: 2.50348
PPO Batch Consumption Time: 0.28596
Total Iteration Time: 4.90401

Cumulative Model Updates: 59,564
Cumulative Timesteps: 496,856,924

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,908.75818
Policy Entropy: 3.45600
Value Function Loss: 0.00334

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.09419
Policy Update Magnitude: 0.57680
Value Function Update Magnitude: 0.63591

Collected Steps per Second: 22,053.79042
Overall Steps per Second: 10,450.43384

Timestep Collection Time: 2.26836
Timestep Consumption Time: 2.51862
PPO Batch Consumption Time: 0.29550
Total Iteration Time: 4.78698

Cumulative Model Updates: 59,570
Cumulative Timesteps: 496,906,950

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 496906950...
Checkpoint 496906950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,411.46146
Policy Entropy: 3.46927
Value Function Loss: 0.00340

Mean KL Divergence: 0.00709
SB3 Clip Fraction: 0.08294
Policy Update Magnitude: 0.58215
Value Function Update Magnitude: 0.66422

Collected Steps per Second: 21,579.29823
Overall Steps per Second: 10,520.12484

Timestep Collection Time: 2.31852
Timestep Consumption Time: 2.43732
PPO Batch Consumption Time: 0.28252
Total Iteration Time: 4.75584

Cumulative Model Updates: 59,576
Cumulative Timesteps: 496,956,982

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,120.00594
Policy Entropy: 3.47302
Value Function Loss: 0.00329

Mean KL Divergence: 0.00738
SB3 Clip Fraction: 0.08666
Policy Update Magnitude: 0.58198
Value Function Update Magnitude: 0.66349

Collected Steps per Second: 21,982.14286
Overall Steps per Second: 10,636.34245

Timestep Collection Time: 2.27466
Timestep Consumption Time: 2.42639
PPO Batch Consumption Time: 0.28004
Total Iteration Time: 4.70105

Cumulative Model Updates: 59,582
Cumulative Timesteps: 497,006,984

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 497006984...
Checkpoint 497006984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,369.85863
Policy Entropy: 3.48331
Value Function Loss: 0.00322

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.08914
Policy Update Magnitude: 0.57467
Value Function Update Magnitude: 0.65216

Collected Steps per Second: 20,465.69793
Overall Steps per Second: 10,144.34655

Timestep Collection Time: 2.44438
Timestep Consumption Time: 2.48703
PPO Batch Consumption Time: 0.29073
Total Iteration Time: 4.93142

Cumulative Model Updates: 59,588
Cumulative Timesteps: 497,057,010

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,378.08239
Policy Entropy: 3.46785
Value Function Loss: 0.00309

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.10574
Policy Update Magnitude: 0.56105
Value Function Update Magnitude: 0.65990

Collected Steps per Second: 21,252.56447
Overall Steps per Second: 10,375.77874

Timestep Collection Time: 2.35332
Timestep Consumption Time: 2.46695
PPO Batch Consumption Time: 0.28399
Total Iteration Time: 4.82026

Cumulative Model Updates: 59,594
Cumulative Timesteps: 497,107,024

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 497107024...
Checkpoint 497107024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,498.57995
Policy Entropy: 3.46403
Value Function Loss: 0.00287

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.10770
Policy Update Magnitude: 0.55284
Value Function Update Magnitude: 0.63335

Collected Steps per Second: 21,483.42158
Overall Steps per Second: 10,362.66037

Timestep Collection Time: 2.32756
Timestep Consumption Time: 2.49784
PPO Batch Consumption Time: 0.29567
Total Iteration Time: 4.82540

Cumulative Model Updates: 59,600
Cumulative Timesteps: 497,157,028

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,112.20981
Policy Entropy: 3.44698
Value Function Loss: 0.00287

Mean KL Divergence: 0.01061
SB3 Clip Fraction: 0.11492
Policy Update Magnitude: 0.54909
Value Function Update Magnitude: 0.59842

Collected Steps per Second: 21,895.30255
Overall Steps per Second: 10,410.57558

Timestep Collection Time: 2.28497
Timestep Consumption Time: 2.52073
PPO Batch Consumption Time: 0.29448
Total Iteration Time: 4.80569

Cumulative Model Updates: 59,606
Cumulative Timesteps: 497,207,058

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 497207058...
Checkpoint 497207058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,036.17848
Policy Entropy: 3.46031
Value Function Loss: 0.00275

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.10140
Policy Update Magnitude: 0.54451
Value Function Update Magnitude: 0.60111

Collected Steps per Second: 20,034.73141
Overall Steps per Second: 9,672.85114

Timestep Collection Time: 2.49716
Timestep Consumption Time: 2.67504
PPO Batch Consumption Time: 0.31749
Total Iteration Time: 5.17221

Cumulative Model Updates: 59,612
Cumulative Timesteps: 497,257,088

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,129.75023
Policy Entropy: 3.45971
Value Function Loss: 0.00280

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.09150
Policy Update Magnitude: 0.54618
Value Function Update Magnitude: 0.58785

Collected Steps per Second: 21,893.87487
Overall Steps per Second: 10,510.28552

Timestep Collection Time: 2.28548
Timestep Consumption Time: 2.47538
PPO Batch Consumption Time: 0.28158
Total Iteration Time: 4.76086

Cumulative Model Updates: 59,618
Cumulative Timesteps: 497,307,126

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 497307126...
Checkpoint 497307126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,507.13426
Policy Entropy: 3.45942
Value Function Loss: 0.00297

Mean KL Divergence: 0.00716
SB3 Clip Fraction: 0.08327
Policy Update Magnitude: 0.55762
Value Function Update Magnitude: 0.58601

Collected Steps per Second: 21,322.65245
Overall Steps per Second: 10,277.11639

Timestep Collection Time: 2.34567
Timestep Consumption Time: 2.52106
PPO Batch Consumption Time: 0.29645
Total Iteration Time: 4.86673

Cumulative Model Updates: 59,624
Cumulative Timesteps: 497,357,142

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,016.63154
Policy Entropy: 3.45253
Value Function Loss: 0.00309

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.09097
Policy Update Magnitude: 0.56645
Value Function Update Magnitude: 0.60535

Collected Steps per Second: 22,452.52936
Overall Steps per Second: 10,503.40214

Timestep Collection Time: 2.22728
Timestep Consumption Time: 2.53385
PPO Batch Consumption Time: 0.29501
Total Iteration Time: 4.76112

Cumulative Model Updates: 59,630
Cumulative Timesteps: 497,407,150

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 497407150...
Checkpoint 497407150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,355.07171
Policy Entropy: 3.46139
Value Function Loss: 0.00315

Mean KL Divergence: 0.00745
SB3 Clip Fraction: 0.08678
Policy Update Magnitude: 0.57128
Value Function Update Magnitude: 0.61143

Collected Steps per Second: 22,271.99052
Overall Steps per Second: 10,671.02300

Timestep Collection Time: 2.24659
Timestep Consumption Time: 2.44237
PPO Batch Consumption Time: 0.28125
Total Iteration Time: 4.68896

Cumulative Model Updates: 59,636
Cumulative Timesteps: 497,457,186

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 838.03121
Policy Entropy: 3.45354
Value Function Loss: 0.00315

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.09457
Policy Update Magnitude: 0.56879
Value Function Update Magnitude: 0.61327

Collected Steps per Second: 22,244.54730
Overall Steps per Second: 10,462.33591

Timestep Collection Time: 2.24909
Timestep Consumption Time: 2.53282
PPO Batch Consumption Time: 0.29632
Total Iteration Time: 4.78191

Cumulative Model Updates: 59,642
Cumulative Timesteps: 497,507,216

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 497507216...
Checkpoint 497507216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,023.05778
Policy Entropy: 3.46204
Value Function Loss: 0.00290

Mean KL Divergence: 0.00740
SB3 Clip Fraction: 0.08480
Policy Update Magnitude: 0.56339
Value Function Update Magnitude: 0.61000

Collected Steps per Second: 21,693.68686
Overall Steps per Second: 10,315.29954

Timestep Collection Time: 2.30611
Timestep Consumption Time: 2.54377
PPO Batch Consumption Time: 0.30126
Total Iteration Time: 4.84988

Cumulative Model Updates: 59,648
Cumulative Timesteps: 497,557,244

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,049.05749
Policy Entropy: 3.45938
Value Function Loss: 0.00300

Mean KL Divergence: 0.00764
SB3 Clip Fraction: 0.08860
Policy Update Magnitude: 0.54778
Value Function Update Magnitude: 0.58874

Collected Steps per Second: 21,989.11439
Overall Steps per Second: 10,609.39376

Timestep Collection Time: 2.27440
Timestep Consumption Time: 2.43954
PPO Batch Consumption Time: 0.28623
Total Iteration Time: 4.71394

Cumulative Model Updates: 59,654
Cumulative Timesteps: 497,607,256

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 497607256...
Checkpoint 497607256 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,996.44894
Policy Entropy: 3.45950
Value Function Loss: 0.00322

Mean KL Divergence: 0.00762
SB3 Clip Fraction: 0.08727
Policy Update Magnitude: 0.55490
Value Function Update Magnitude: 0.58743

Collected Steps per Second: 22,184.83691
Overall Steps per Second: 10,684.28087

Timestep Collection Time: 2.25424
Timestep Consumption Time: 2.42647
PPO Batch Consumption Time: 0.28158
Total Iteration Time: 4.68071

Cumulative Model Updates: 59,660
Cumulative Timesteps: 497,657,266

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,267.09364
Policy Entropy: 3.45000
Value Function Loss: 0.00331

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.10937
Policy Update Magnitude: 0.56242
Value Function Update Magnitude: 0.59809

Collected Steps per Second: 21,084.90153
Overall Steps per Second: 10,450.13452

Timestep Collection Time: 2.37203
Timestep Consumption Time: 2.41394
PPO Batch Consumption Time: 0.28346
Total Iteration Time: 4.78597

Cumulative Model Updates: 59,666
Cumulative Timesteps: 497,707,280

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 497707280...
Checkpoint 497707280 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,212.50491
Policy Entropy: 3.44564
Value Function Loss: 0.00323

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.09238
Policy Update Magnitude: 0.56162
Value Function Update Magnitude: 0.59654

Collected Steps per Second: 21,938.28320
Overall Steps per Second: 10,396.32853

Timestep Collection Time: 2.27967
Timestep Consumption Time: 2.53088
PPO Batch Consumption Time: 0.29597
Total Iteration Time: 4.81054

Cumulative Model Updates: 59,672
Cumulative Timesteps: 497,757,292

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,192.48834
Policy Entropy: 3.44473
Value Function Loss: 0.00310

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.09123
Policy Update Magnitude: 0.56180
Value Function Update Magnitude: 0.59218

Collected Steps per Second: 22,178.45377
Overall Steps per Second: 10,455.79385

Timestep Collection Time: 2.25525
Timestep Consumption Time: 2.52851
PPO Batch Consumption Time: 0.29402
Total Iteration Time: 4.78376

Cumulative Model Updates: 59,678
Cumulative Timesteps: 497,807,310

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 497807310...
Checkpoint 497807310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,068.41985
Policy Entropy: 3.44871
Value Function Loss: 0.00311

Mean KL Divergence: 0.00739
SB3 Clip Fraction: 0.08490
Policy Update Magnitude: 0.55342
Value Function Update Magnitude: 0.59352

Collected Steps per Second: 21,236.28810
Overall Steps per Second: 9,800.65739

Timestep Collection Time: 2.35503
Timestep Consumption Time: 2.74790
PPO Batch Consumption Time: 0.33076
Total Iteration Time: 5.10292

Cumulative Model Updates: 59,684
Cumulative Timesteps: 497,857,322

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,317.01586
Policy Entropy: 3.45036
Value Function Loss: 0.00289

Mean KL Divergence: 0.00718
SB3 Clip Fraction: 0.08453
Policy Update Magnitude: 0.55321
Value Function Update Magnitude: 0.61189

Collected Steps per Second: 18,852.44638
Overall Steps per Second: 8,983.94822

Timestep Collection Time: 2.65292
Timestep Consumption Time: 2.91412
PPO Batch Consumption Time: 0.34217
Total Iteration Time: 5.56704

Cumulative Model Updates: 59,690
Cumulative Timesteps: 497,907,336

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 497907336...
Checkpoint 497907336 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,073.59143
Policy Entropy: 3.45487
Value Function Loss: 0.00287

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.09227
Policy Update Magnitude: 0.54737
Value Function Update Magnitude: 0.61224

Collected Steps per Second: 18,797.63023
Overall Steps per Second: 8,799.26633

Timestep Collection Time: 2.66151
Timestep Consumption Time: 3.02420
PPO Batch Consumption Time: 0.36060
Total Iteration Time: 5.68570

Cumulative Model Updates: 59,696
Cumulative Timesteps: 497,957,366

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,213.59670
Policy Entropy: 3.45281
Value Function Loss: 0.00287

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.11157
Policy Update Magnitude: 0.54879
Value Function Update Magnitude: 0.61050

Collected Steps per Second: 18,695.04043
Overall Steps per Second: 8,831.82789

Timestep Collection Time: 2.67568
Timestep Consumption Time: 2.98815
PPO Batch Consumption Time: 0.35328
Total Iteration Time: 5.66383

Cumulative Model Updates: 59,702
Cumulative Timesteps: 498,007,388

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 498007388...
Checkpoint 498007388 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,006.06312
Policy Entropy: 3.44479
Value Function Loss: 0.00316

Mean KL Divergence: 0.01081
SB3 Clip Fraction: 0.11585
Policy Update Magnitude: 0.54907
Value Function Update Magnitude: 0.60307

Collected Steps per Second: 19,945.52524
Overall Steps per Second: 9,492.13978

Timestep Collection Time: 2.50773
Timestep Consumption Time: 2.76168
PPO Batch Consumption Time: 0.33331
Total Iteration Time: 5.26941

Cumulative Model Updates: 59,708
Cumulative Timesteps: 498,057,406

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,176.47493
Policy Entropy: 3.44043
Value Function Loss: 0.00326

Mean KL Divergence: 0.01083
SB3 Clip Fraction: 0.11693
Policy Update Magnitude: 0.55597
Value Function Update Magnitude: 0.61109

Collected Steps per Second: 18,814.95356
Overall Steps per Second: 8,965.59116

Timestep Collection Time: 2.65874
Timestep Consumption Time: 2.92082
PPO Batch Consumption Time: 0.33979
Total Iteration Time: 5.57955

Cumulative Model Updates: 59,714
Cumulative Timesteps: 498,107,430

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 498107430...
Checkpoint 498107430 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,131.18989
Policy Entropy: 3.44226
Value Function Loss: 0.00314

Mean KL Divergence: 0.01083
SB3 Clip Fraction: 0.11996
Policy Update Magnitude: 0.55501
Value Function Update Magnitude: 0.61262

Collected Steps per Second: 18,453.18676
Overall Steps per Second: 8,967.63632

Timestep Collection Time: 2.71075
Timestep Consumption Time: 2.86731
PPO Batch Consumption Time: 0.34805
Total Iteration Time: 5.57806

Cumulative Model Updates: 59,720
Cumulative Timesteps: 498,157,452

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,326.90903
Policy Entropy: 3.46017
Value Function Loss: 0.00312

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.09419
Policy Update Magnitude: 0.55561
Value Function Update Magnitude: 0.61946

Collected Steps per Second: 19,126.42115
Overall Steps per Second: 9,154.92035

Timestep Collection Time: 2.61492
Timestep Consumption Time: 2.84816
PPO Batch Consumption Time: 0.34020
Total Iteration Time: 5.46307

Cumulative Model Updates: 59,726
Cumulative Timesteps: 498,207,466

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 498207466...
Checkpoint 498207466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,455.24088
Policy Entropy: 3.44693
Value Function Loss: 0.00315

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.10169
Policy Update Magnitude: 0.56584
Value Function Update Magnitude: 0.64420

Collected Steps per Second: 18,618.30823
Overall Steps per Second: 8,867.39507

Timestep Collection Time: 2.68735
Timestep Consumption Time: 2.95511
PPO Batch Consumption Time: 0.35537
Total Iteration Time: 5.64247

Cumulative Model Updates: 59,732
Cumulative Timesteps: 498,257,500

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 866.56069
Policy Entropy: 3.44454
Value Function Loss: 0.00325

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.09747
Policy Update Magnitude: 0.57380
Value Function Update Magnitude: 0.66462

Collected Steps per Second: 18,178.81078
Overall Steps per Second: 8,654.67592

Timestep Collection Time: 2.75079
Timestep Consumption Time: 3.02713
PPO Batch Consumption Time: 0.35763
Total Iteration Time: 5.77792

Cumulative Model Updates: 59,738
Cumulative Timesteps: 498,307,506

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 498307506...
Checkpoint 498307506 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,148.69591
Policy Entropy: 3.43557
Value Function Loss: 0.00291

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.10088
Policy Update Magnitude: 0.56925
Value Function Update Magnitude: 0.64342

Collected Steps per Second: 18,950.56600
Overall Steps per Second: 8,924.47355

Timestep Collection Time: 2.63950
Timestep Consumption Time: 2.96531
PPO Batch Consumption Time: 0.36296
Total Iteration Time: 5.60481

Cumulative Model Updates: 59,744
Cumulative Timesteps: 498,357,526

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,439.40505
Policy Entropy: 3.44254
Value Function Loss: 0.00302

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.11186
Policy Update Magnitude: 0.55047
Value Function Update Magnitude: 0.61259

Collected Steps per Second: 19,317.95728
Overall Steps per Second: 8,984.90225

Timestep Collection Time: 2.58868
Timestep Consumption Time: 2.97710
PPO Batch Consumption Time: 0.35341
Total Iteration Time: 5.56578

Cumulative Model Updates: 59,750
Cumulative Timesteps: 498,407,534

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 498407534...
Checkpoint 498407534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 863.43743
Policy Entropy: 3.44583
Value Function Loss: 0.00300

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.10281
Policy Update Magnitude: 0.54915
Value Function Update Magnitude: 0.61888

Collected Steps per Second: 18,797.90650
Overall Steps per Second: 9,022.91844

Timestep Collection Time: 2.66115
Timestep Consumption Time: 2.88296
PPO Batch Consumption Time: 0.34331
Total Iteration Time: 5.54410

Cumulative Model Updates: 59,756
Cumulative Timesteps: 498,457,558

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 896.09073
Policy Entropy: 3.46332
Value Function Loss: 0.00306

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.09560
Policy Update Magnitude: 0.55344
Value Function Update Magnitude: 0.61524

Collected Steps per Second: 20,708.71690
Overall Steps per Second: 9,806.19982

Timestep Collection Time: 2.41531
Timestep Consumption Time: 2.68534
PPO Batch Consumption Time: 0.32481
Total Iteration Time: 5.10065

Cumulative Model Updates: 59,762
Cumulative Timesteps: 498,507,576

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 498507576...
Checkpoint 498507576 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,121.83654
Policy Entropy: 3.44959
Value Function Loss: 0.00305

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.10540
Policy Update Magnitude: 0.55510
Value Function Update Magnitude: 0.60313

Collected Steps per Second: 18,230.30480
Overall Steps per Second: 9,787.96186

Timestep Collection Time: 2.74411
Timestep Consumption Time: 2.36686
PPO Batch Consumption Time: 0.28665
Total Iteration Time: 5.11097

Cumulative Model Updates: 59,768
Cumulative Timesteps: 498,557,602

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,731.74076
Policy Entropy: 3.45186
Value Function Loss: 0.00299

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.10240
Policy Update Magnitude: 0.55089
Value Function Update Magnitude: 0.59088

Collected Steps per Second: 18,836.40770
Overall Steps per Second: 9,390.33595

Timestep Collection Time: 2.65465
Timestep Consumption Time: 2.67040
PPO Batch Consumption Time: 0.31494
Total Iteration Time: 5.32505

Cumulative Model Updates: 59,774
Cumulative Timesteps: 498,607,606

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 498607606...
Checkpoint 498607606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,565.95271
Policy Entropy: 3.44157
Value Function Loss: 0.00312

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.11014
Policy Update Magnitude: 0.54847
Value Function Update Magnitude: 0.57633

Collected Steps per Second: 20,468.68708
Overall Steps per Second: 10,415.93017

Timestep Collection Time: 2.44276
Timestep Consumption Time: 2.35758
PPO Batch Consumption Time: 0.28200
Total Iteration Time: 4.80034

Cumulative Model Updates: 59,780
Cumulative Timesteps: 498,657,606

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,265.97726
Policy Entropy: 3.44182
Value Function Loss: 0.00330

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.10609
Policy Update Magnitude: 0.55124
Value Function Update Magnitude: 0.58164

Collected Steps per Second: 22,562.86055
Overall Steps per Second: 10,524.82374

Timestep Collection Time: 2.21674
Timestep Consumption Time: 2.53545
PPO Batch Consumption Time: 0.29549
Total Iteration Time: 4.75219

Cumulative Model Updates: 59,786
Cumulative Timesteps: 498,707,622

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 498707622...
Checkpoint 498707622 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,250.05756
Policy Entropy: 3.44620
Value Function Loss: 0.00333

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.10517
Policy Update Magnitude: 0.55619
Value Function Update Magnitude: 0.59549

Collected Steps per Second: 21,270.33241
Overall Steps per Second: 9,829.28613

Timestep Collection Time: 2.35107
Timestep Consumption Time: 2.73659
PPO Batch Consumption Time: 0.31715
Total Iteration Time: 5.08765

Cumulative Model Updates: 59,792
Cumulative Timesteps: 498,757,630

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,412.97125
Policy Entropy: 3.44492
Value Function Loss: 0.00317

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.10576
Policy Update Magnitude: 0.55515
Value Function Update Magnitude: 0.61207

Collected Steps per Second: 17,246.97558
Overall Steps per Second: 9,098.18660

Timestep Collection Time: 2.89941
Timestep Consumption Time: 2.59685
PPO Batch Consumption Time: 0.29446
Total Iteration Time: 5.49626

Cumulative Model Updates: 59,798
Cumulative Timesteps: 498,807,636

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 498807636...
Checkpoint 498807636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,546.24607
Policy Entropy: 3.45060
Value Function Loss: 0.00301

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.10251
Policy Update Magnitude: 0.54519
Value Function Update Magnitude: 0.60230

Collected Steps per Second: 18,854.81685
Overall Steps per Second: 9,435.98657

Timestep Collection Time: 2.65205
Timestep Consumption Time: 2.64723
PPO Batch Consumption Time: 0.31021
Total Iteration Time: 5.29929

Cumulative Model Updates: 59,804
Cumulative Timesteps: 498,857,640

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 828.39860
Policy Entropy: 3.45748
Value Function Loss: 0.00297

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.08759
Policy Update Magnitude: 0.53924
Value Function Update Magnitude: 0.58476

Collected Steps per Second: 21,739.94873
Overall Steps per Second: 10,409.02737

Timestep Collection Time: 2.30065
Timestep Consumption Time: 2.50441
PPO Batch Consumption Time: 0.29364
Total Iteration Time: 4.80506

Cumulative Model Updates: 59,810
Cumulative Timesteps: 498,907,656

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 498907656...
Checkpoint 498907656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,457.99889
Policy Entropy: 3.46106
Value Function Loss: 0.00309

Mean KL Divergence: 0.00731
SB3 Clip Fraction: 0.08605
Policy Update Magnitude: 0.53714
Value Function Update Magnitude: 0.56606

Collected Steps per Second: 21,137.21960
Overall Steps per Second: 10,398.44829

Timestep Collection Time: 2.36644
Timestep Consumption Time: 2.44389
PPO Batch Consumption Time: 0.28357
Total Iteration Time: 4.81033

Cumulative Model Updates: 59,816
Cumulative Timesteps: 498,957,676

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,180.43856
Policy Entropy: 3.45785
Value Function Loss: 0.00318

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.08962
Policy Update Magnitude: 0.54067
Value Function Update Magnitude: 0.57907

Collected Steps per Second: 21,488.49971
Overall Steps per Second: 10,353.23671

Timestep Collection Time: 2.32720
Timestep Consumption Time: 2.50298
PPO Batch Consumption Time: 0.29222
Total Iteration Time: 4.83018

Cumulative Model Updates: 59,822
Cumulative Timesteps: 499,007,684

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 499007684...
Checkpoint 499007684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 851.17462
Policy Entropy: 3.45904
Value Function Loss: 0.00354

Mean KL Divergence: 0.00739
SB3 Clip Fraction: 0.08562
Policy Update Magnitude: 0.55455
Value Function Update Magnitude: 0.58482

Collected Steps per Second: 19,533.15273
Overall Steps per Second: 10,053.96434

Timestep Collection Time: 2.56108
Timestep Consumption Time: 2.41467
PPO Batch Consumption Time: 0.28749
Total Iteration Time: 4.97575

Cumulative Model Updates: 59,828
Cumulative Timesteps: 499,057,710

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 600.89572
Policy Entropy: 3.46429
Value Function Loss: 0.00368

Mean KL Divergence: 0.00695
SB3 Clip Fraction: 0.08028
Policy Update Magnitude: 0.57269
Value Function Update Magnitude: 0.60314

Collected Steps per Second: 21,107.22592
Overall Steps per Second: 9,829.63447

Timestep Collection Time: 2.37094
Timestep Consumption Time: 2.72019
PPO Batch Consumption Time: 0.31372
Total Iteration Time: 5.09114

Cumulative Model Updates: 59,834
Cumulative Timesteps: 499,107,754

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 499107754...
Checkpoint 499107754 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,402.08750
Policy Entropy: 3.48717
Value Function Loss: 0.00364

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.09593
Policy Update Magnitude: 0.57193
Value Function Update Magnitude: 0.62459

Collected Steps per Second: 17,902.72718
Overall Steps per Second: 9,455.20446

Timestep Collection Time: 2.79455
Timestep Consumption Time: 2.49672
PPO Batch Consumption Time: 0.28656
Total Iteration Time: 5.29127

Cumulative Model Updates: 59,840
Cumulative Timesteps: 499,157,784

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,600.18261
Policy Entropy: 3.47498
Value Function Loss: 0.00334

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.09301
Policy Update Magnitude: 0.56064
Value Function Update Magnitude: 0.63880

Collected Steps per Second: 20,853.23811
Overall Steps per Second: 9,987.68126

Timestep Collection Time: 2.39819
Timestep Consumption Time: 2.60898
PPO Batch Consumption Time: 0.31010
Total Iteration Time: 5.00717

Cumulative Model Updates: 59,846
Cumulative Timesteps: 499,207,794

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 499207794...
Checkpoint 499207794 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 740.35864
Policy Entropy: 3.48697
Value Function Loss: 0.00322

Mean KL Divergence: 0.00733
SB3 Clip Fraction: 0.08553
Policy Update Magnitude: 0.54736
Value Function Update Magnitude: 0.63444

Collected Steps per Second: 21,511.96224
Overall Steps per Second: 10,296.92459

Timestep Collection Time: 2.32429
Timestep Consumption Time: 2.53153
PPO Batch Consumption Time: 0.29431
Total Iteration Time: 4.85582

Cumulative Model Updates: 59,852
Cumulative Timesteps: 499,257,794

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,045.07704
Policy Entropy: 3.47117
Value Function Loss: 0.00324

Mean KL Divergence: 0.00683
SB3 Clip Fraction: 0.07887
Policy Update Magnitude: 0.54620
Value Function Update Magnitude: 0.64979

Collected Steps per Second: 21,316.36480
Overall Steps per Second: 10,537.40380

Timestep Collection Time: 2.34637
Timestep Consumption Time: 2.40015
PPO Batch Consumption Time: 0.28433
Total Iteration Time: 4.74652

Cumulative Model Updates: 59,858
Cumulative Timesteps: 499,307,810

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 499307810...
Checkpoint 499307810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 982.85504
Policy Entropy: 3.48452
Value Function Loss: 0.00321

Mean KL Divergence: 0.00728
SB3 Clip Fraction: 0.08394
Policy Update Magnitude: 0.54832
Value Function Update Magnitude: 0.63583

Collected Steps per Second: 20,757.29215
Overall Steps per Second: 10,268.21688

Timestep Collection Time: 2.40966
Timestep Consumption Time: 2.46149
PPO Batch Consumption Time: 0.28408
Total Iteration Time: 4.87115

Cumulative Model Updates: 59,864
Cumulative Timesteps: 499,357,828

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 745.65081
Policy Entropy: 3.48727
Value Function Loss: 0.00313

Mean KL Divergence: 0.00737
SB3 Clip Fraction: 0.08359
Policy Update Magnitude: 0.54451
Value Function Update Magnitude: 0.61065

Collected Steps per Second: 20,901.09768
Overall Steps per Second: 10,157.99491

Timestep Collection Time: 2.39356
Timestep Consumption Time: 2.53143
PPO Batch Consumption Time: 0.29628
Total Iteration Time: 4.92499

Cumulative Model Updates: 59,870
Cumulative Timesteps: 499,407,856

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 499407856...
Checkpoint 499407856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,225.36492
Policy Entropy: 3.47912
Value Function Loss: 0.00307

Mean KL Divergence: 0.00732
SB3 Clip Fraction: 0.08497
Policy Update Magnitude: 0.54235
Value Function Update Magnitude: 0.61373

Collected Steps per Second: 19,370.53021
Overall Steps per Second: 9,694.29188

Timestep Collection Time: 2.58134
Timestep Consumption Time: 2.57654
PPO Batch Consumption Time: 0.30477
Total Iteration Time: 5.15788

Cumulative Model Updates: 59,876
Cumulative Timesteps: 499,457,858

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,490.48876
Policy Entropy: 3.47297
Value Function Loss: 0.00308

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.09269
Policy Update Magnitude: 0.54671
Value Function Update Magnitude: 0.60937

Collected Steps per Second: 18,447.47654
Overall Steps per Second: 9,202.70663

Timestep Collection Time: 2.71170
Timestep Consumption Time: 2.72409
PPO Batch Consumption Time: 0.32708
Total Iteration Time: 5.43579

Cumulative Model Updates: 59,882
Cumulative Timesteps: 499,507,882

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 499507882...
Checkpoint 499507882 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,165.48342
Policy Entropy: 3.46064
Value Function Loss: 0.00331

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.10389
Policy Update Magnitude: 0.55169
Value Function Update Magnitude: 0.60711

Collected Steps per Second: 15,207.11205
Overall Steps per Second: 8,484.27547

Timestep Collection Time: 3.28820
Timestep Consumption Time: 2.60553
PPO Batch Consumption Time: 0.28983
Total Iteration Time: 5.89373

Cumulative Model Updates: 59,888
Cumulative Timesteps: 499,557,886

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,425.48493
Policy Entropy: 3.46734
Value Function Loss: 0.00329

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.10607
Policy Update Magnitude: 0.55571
Value Function Update Magnitude: 0.60722

Collected Steps per Second: 6,857.31198
Overall Steps per Second: 4,398.93048

Timestep Collection Time: 7.29819
Timestep Consumption Time: 4.07866
PPO Batch Consumption Time: 0.37495
Total Iteration Time: 11.37686

Cumulative Model Updates: 59,894
Cumulative Timesteps: 499,607,932

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 499607932...
Checkpoint 499607932 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,456.95108
Policy Entropy: 3.46815
Value Function Loss: 0.00328

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.09364
Policy Update Magnitude: 0.55614
Value Function Update Magnitude: 0.59117

Collected Steps per Second: 8,764.78780
Overall Steps per Second: 4,333.29208

Timestep Collection Time: 5.71058
Timestep Consumption Time: 5.83999
PPO Batch Consumption Time: 0.73845
Total Iteration Time: 11.55057

Cumulative Model Updates: 59,900
Cumulative Timesteps: 499,657,984

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,132.29148
Policy Entropy: 3.48107
Value Function Loss: 0.00315

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.09812
Policy Update Magnitude: 0.54625
Value Function Update Magnitude: 0.60439

Collected Steps per Second: 12,448.28554
Overall Steps per Second: 5,347.46630

Timestep Collection Time: 4.01742
Timestep Consumption Time: 5.33467
PPO Batch Consumption Time: 0.73293
Total Iteration Time: 9.35209

Cumulative Model Updates: 59,906
Cumulative Timesteps: 499,707,994

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 499707994...
Checkpoint 499707994 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,036.28635
Policy Entropy: 3.48974
Value Function Loss: 0.00317

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.09506
Policy Update Magnitude: 0.53687
Value Function Update Magnitude: 0.62442

Collected Steps per Second: 13,072.03207
Overall Steps per Second: 5,248.99696

Timestep Collection Time: 3.82649
Timestep Consumption Time: 5.70295
PPO Batch Consumption Time: 0.80501
Total Iteration Time: 9.52944

Cumulative Model Updates: 59,912
Cumulative Timesteps: 499,758,014

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 782.24784
Policy Entropy: 3.48570
Value Function Loss: 0.00313

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.09152
Policy Update Magnitude: 0.53480
Value Function Update Magnitude: 0.63978

Collected Steps per Second: 12,958.12294
Overall Steps per Second: 5,146.82716

Timestep Collection Time: 3.86090
Timestep Consumption Time: 5.85965
PPO Batch Consumption Time: 0.82449
Total Iteration Time: 9.72055

Cumulative Model Updates: 59,918
Cumulative Timesteps: 499,808,044

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 499808044...
Checkpoint 499808044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 738.98452
Policy Entropy: 3.49431
Value Function Loss: 0.00331

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.09109
Policy Update Magnitude: 0.54029
Value Function Update Magnitude: 0.64289

Collected Steps per Second: 13,320.22956
Overall Steps per Second: 5,306.42729

Timestep Collection Time: 3.75444
Timestep Consumption Time: 5.66998
PPO Batch Consumption Time: 0.79598
Total Iteration Time: 9.42442

Cumulative Model Updates: 59,924
Cumulative Timesteps: 499,858,054

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,100.50406
Policy Entropy: 3.49193
Value Function Loss: 0.00321

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.09273
Policy Update Magnitude: 0.54313
Value Function Update Magnitude: 0.63279

Collected Steps per Second: 14,001.62439
Overall Steps per Second: 5,444.89226

Timestep Collection Time: 3.57230
Timestep Consumption Time: 5.61392
PPO Batch Consumption Time: 0.79230
Total Iteration Time: 9.18622

Cumulative Model Updates: 59,930
Cumulative Timesteps: 499,908,072

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 499908072...
Checkpoint 499908072 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 810.60643
Policy Entropy: 3.48651
Value Function Loss: 0.00337

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.09084
Policy Update Magnitude: 0.54808
Value Function Update Magnitude: 0.63184

Collected Steps per Second: 13,089.43998
Overall Steps per Second: 5,267.21034

Timestep Collection Time: 3.82064
Timestep Consumption Time: 5.67395
PPO Batch Consumption Time: 0.79280
Total Iteration Time: 9.49459

Cumulative Model Updates: 59,936
Cumulative Timesteps: 499,958,082

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,424.40490
Policy Entropy: 3.48296
Value Function Loss: 0.00348

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.09611
Policy Update Magnitude: 0.56285
Value Function Update Magnitude: 0.65389

Collected Steps per Second: 12,560.21272
Overall Steps per Second: 5,188.36984

Timestep Collection Time: 3.98082
Timestep Consumption Time: 5.65611
PPO Batch Consumption Time: 0.79623
Total Iteration Time: 9.63694

Cumulative Model Updates: 59,942
Cumulative Timesteps: 500,008,082

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 500008082...
Checkpoint 500008082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,047.56191
Policy Entropy: 3.48279
Value Function Loss: 0.00341

Mean KL Divergence: 0.00783
SB3 Clip Fraction: 0.09064
Policy Update Magnitude: 0.56423
Value Function Update Magnitude: 0.67937

Collected Steps per Second: 14,226.01547
Overall Steps per Second: 5,473.19192

Timestep Collection Time: 3.51792
Timestep Consumption Time: 5.62592
PPO Batch Consumption Time: 0.79615
Total Iteration Time: 9.14384

Cumulative Model Updates: 59,948
Cumulative Timesteps: 500,058,128

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 838.64015
Policy Entropy: 3.48043
Value Function Loss: 0.00335

Mean KL Divergence: 0.00728
SB3 Clip Fraction: 0.08405
Policy Update Magnitude: 0.56507
Value Function Update Magnitude: 0.68485

Collected Steps per Second: 14,012.50063
Overall Steps per Second: 5,274.51577

Timestep Collection Time: 3.56881
Timestep Consumption Time: 5.91225
PPO Batch Consumption Time: 0.82667
Total Iteration Time: 9.48106

Cumulative Model Updates: 59,954
Cumulative Timesteps: 500,108,136

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 500108136...
Checkpoint 500108136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,469.60547
Policy Entropy: 3.47471
Value Function Loss: 0.00320

Mean KL Divergence: 0.00678
SB3 Clip Fraction: 0.07661
Policy Update Magnitude: 0.56280
Value Function Update Magnitude: 0.68571

Collected Steps per Second: 13,985.85755
Overall Steps per Second: 5,434.23269

Timestep Collection Time: 3.57618
Timestep Consumption Time: 5.62769
PPO Batch Consumption Time: 0.79205
Total Iteration Time: 9.20388

Cumulative Model Updates: 59,960
Cumulative Timesteps: 500,158,152

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 926.51671
Policy Entropy: 3.46270
Value Function Loss: 0.00332

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.09377
Policy Update Magnitude: 0.56429
Value Function Update Magnitude: 0.67504

Collected Steps per Second: 13,555.27696
Overall Steps per Second: 5,375.46494

Timestep Collection Time: 3.68860
Timestep Consumption Time: 5.61292
PPO Batch Consumption Time: 0.79439
Total Iteration Time: 9.30152

Cumulative Model Updates: 59,966
Cumulative Timesteps: 500,208,152

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 500208152...
Checkpoint 500208152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 756.20685
Policy Entropy: 3.47239
Value Function Loss: 0.00313

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.09362
Policy Update Magnitude: 0.55889
Value Function Update Magnitude: 0.67788

Collected Steps per Second: 12,875.24753
Overall Steps per Second: 5,231.35552

Timestep Collection Time: 3.88560
Timestep Consumption Time: 5.67751
PPO Batch Consumption Time: 0.78987
Total Iteration Time: 9.56310

Cumulative Model Updates: 59,972
Cumulative Timesteps: 500,258,180

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,256.38332
Policy Entropy: 3.47923
Value Function Loss: 0.00329

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.09486
Policy Update Magnitude: 0.55622
Value Function Update Magnitude: 0.67284

Collected Steps per Second: 12,947.93083
Overall Steps per Second: 5,233.45023

Timestep Collection Time: 3.86239
Timestep Consumption Time: 5.69344
PPO Batch Consumption Time: 0.80743
Total Iteration Time: 9.55584

Cumulative Model Updates: 59,978
Cumulative Timesteps: 500,308,190

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 500308190...
Checkpoint 500308190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 944.87330
Policy Entropy: 3.47978
Value Function Loss: 0.00317

Mean KL Divergence: 0.00728
SB3 Clip Fraction: 0.08508
Policy Update Magnitude: 0.54830
Value Function Update Magnitude: 0.64619

Collected Steps per Second: 12,326.92169
Overall Steps per Second: 5,162.59081

Timestep Collection Time: 4.05860
Timestep Consumption Time: 5.63227
PPO Batch Consumption Time: 0.79431
Total Iteration Time: 9.69087

Cumulative Model Updates: 59,984
Cumulative Timesteps: 500,358,220

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,004.94736
Policy Entropy: 3.48201
Value Function Loss: 0.00310

Mean KL Divergence: 0.00750
SB3 Clip Fraction: 0.08746
Policy Update Magnitude: 0.54265
Value Function Update Magnitude: 0.63752

Collected Steps per Second: 13,770.13515
Overall Steps per Second: 5,355.50967

Timestep Collection Time: 3.63235
Timestep Consumption Time: 5.70719
PPO Batch Consumption Time: 0.80894
Total Iteration Time: 9.33954

Cumulative Model Updates: 59,990
Cumulative Timesteps: 500,408,238

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 500408238...
Checkpoint 500408238 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,488.98488
Policy Entropy: 3.49255
Value Function Loss: 0.00307

Mean KL Divergence: 0.00749
SB3 Clip Fraction: 0.08614
Policy Update Magnitude: 0.53692
Value Function Update Magnitude: 0.63823

Collected Steps per Second: 13,901.89989
Overall Steps per Second: 5,415.80109

Timestep Collection Time: 3.59706
Timestep Consumption Time: 5.63629
PPO Batch Consumption Time: 0.79355
Total Iteration Time: 9.23335

Cumulative Model Updates: 59,996
Cumulative Timesteps: 500,458,244

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,126.06956
Policy Entropy: 3.48316
Value Function Loss: 0.00325

Mean KL Divergence: 0.00711
SB3 Clip Fraction: 0.08244
Policy Update Magnitude: 0.54236
Value Function Update Magnitude: 0.64068

Collected Steps per Second: 14,173.17234
Overall Steps per Second: 5,461.20501

Timestep Collection Time: 3.52878
Timestep Consumption Time: 5.62927
PPO Batch Consumption Time: 0.79489
Total Iteration Time: 9.15805

Cumulative Model Updates: 60,002
Cumulative Timesteps: 500,508,258

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 500508258...
Checkpoint 500508258 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 694.96813
Policy Entropy: 3.47848
Value Function Loss: 0.00323

Mean KL Divergence: 0.00709
SB3 Clip Fraction: 0.08374
Policy Update Magnitude: 0.54932
Value Function Update Magnitude: 0.66559

Collected Steps per Second: 13,906.02177
Overall Steps per Second: 5,390.86742

Timestep Collection Time: 3.59729
Timestep Consumption Time: 5.68211
PPO Batch Consumption Time: 0.80827
Total Iteration Time: 9.27940

Cumulative Model Updates: 60,008
Cumulative Timesteps: 500,558,282

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,130.90974
Policy Entropy: 3.46987
Value Function Loss: 0.00315

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.09316
Policy Update Magnitude: 0.55047
Value Function Update Magnitude: 0.65981

Collected Steps per Second: 12,596.28979
Overall Steps per Second: 5,090.87069

Timestep Collection Time: 3.97085
Timestep Consumption Time: 5.85419
PPO Batch Consumption Time: 0.83068
Total Iteration Time: 9.82504

Cumulative Model Updates: 60,014
Cumulative Timesteps: 500,608,300

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 500608300...
Checkpoint 500608300 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,512.17006
Policy Entropy: 3.46810
Value Function Loss: 0.00316

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.09675
Policy Update Magnitude: 0.55256
Value Function Update Magnitude: 0.64320

Collected Steps per Second: 12,839.28626
Overall Steps per Second: 6,214.64042

Timestep Collection Time: 3.89523
Timestep Consumption Time: 4.15222
PPO Batch Consumption Time: 0.54186
Total Iteration Time: 8.04745

Cumulative Model Updates: 60,020
Cumulative Timesteps: 500,658,312

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,430.96149
Policy Entropy: 3.46865
Value Function Loss: 0.00333

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.09899
Policy Update Magnitude: 0.55781
Value Function Update Magnitude: 0.64344

Collected Steps per Second: 14,290.68526
Overall Steps per Second: 5,364.31733

Timestep Collection Time: 3.50032
Timestep Consumption Time: 5.82463
PPO Batch Consumption Time: 0.80334
Total Iteration Time: 9.32495

Cumulative Model Updates: 60,026
Cumulative Timesteps: 500,708,334

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 500708334...
Checkpoint 500708334 saved!
