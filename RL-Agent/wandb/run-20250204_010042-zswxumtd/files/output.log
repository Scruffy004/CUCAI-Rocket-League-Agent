Checkpoint loaded!
Learner successfully initialized!
Press (p) to pause (c) to checkpoint, (q) to checkpoint and quit (after next iteration)

--------BEGIN ITERATION REPORT--------
Policy Reward: 612.50757
Policy Entropy: 2.55805
Value Function Loss: 2.05278

Mean KL Divergence: 0.00454
SB3 Clip Fraction: 0.06046
Policy Update Magnitude: 0.15377
Value Function Update Magnitude: 0.10263

Collected Steps per Second: 7,917.09363
Overall Steps per Second: 3,970.84558

Timestep Collection Time: 6.31873
Timestep Consumption Time: 6.27959
PPO Batch Consumption Time: 2.50344
Total Iteration Time: 12.59832

Cumulative Model Updates: 1,218
Cumulative Timesteps: 10,253,410

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 568.11640
Policy Entropy: 2.52858
Value Function Loss: 2.10978

Mean KL Divergence: 0.01101
SB3 Clip Fraction: 0.12251
Policy Update Magnitude: 0.16319
Value Function Update Magnitude: 0.10681

Collected Steps per Second: 20,319.88291
Overall Steps per Second: 12,843.48488

Timestep Collection Time: 2.46064
Timestep Consumption Time: 1.43238
PPO Batch Consumption Time: 0.32514
Total Iteration Time: 3.89302

Cumulative Model Updates: 1,220
Cumulative Timesteps: 10,303,410

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 10303410...
Checkpoint 10303410 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 494.66678
Policy Entropy: 2.56318
Value Function Loss: 2.02455

Mean KL Divergence: 0.01256
SB3 Clip Fraction: 0.14427
Policy Update Magnitude: 0.39538
Value Function Update Magnitude: 0.36345

Collected Steps per Second: 20,940.39500
Overall Steps per Second: 10,025.45056

Timestep Collection Time: 2.38926
Timestep Consumption Time: 2.60124
PPO Batch Consumption Time: 0.31338
Total Iteration Time: 4.99050

Cumulative Model Updates: 1,226
Cumulative Timesteps: 10,353,442

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 660.71364
Policy Entropy: 2.55190
Value Function Loss: 1.90427

Mean KL Divergence: 0.01231
SB3 Clip Fraction: 0.14527
Policy Update Magnitude: 0.38924
Value Function Update Magnitude: 0.44746

Collected Steps per Second: 20,792.60495
Overall Steps per Second: 10,085.31348

Timestep Collection Time: 2.40470
Timestep Consumption Time: 2.55300
PPO Batch Consumption Time: 0.29508
Total Iteration Time: 4.95770

Cumulative Model Updates: 1,232
Cumulative Timesteps: 10,403,442

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 10403442...
Checkpoint 10403442 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 484.93973
Policy Entropy: 2.57977
Value Function Loss: 1.79088

Mean KL Divergence: 0.01214
SB3 Clip Fraction: 0.14530
Policy Update Magnitude: 0.34585
Value Function Update Magnitude: 0.43902

Collected Steps per Second: 21,310.70964
Overall Steps per Second: 10,189.47804

Timestep Collection Time: 2.34671
Timestep Consumption Time: 2.56130
PPO Batch Consumption Time: 0.30065
Total Iteration Time: 4.90800

Cumulative Model Updates: 1,238
Cumulative Timesteps: 10,453,452

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 510.60252
Policy Entropy: 2.53362
Value Function Loss: 1.73436

Mean KL Divergence: 0.00748
SB3 Clip Fraction: 0.09040
Policy Update Magnitude: 0.38426
Value Function Update Magnitude: 0.48520

Collected Steps per Second: 21,132.03146
Overall Steps per Second: 10,043.13495

Timestep Collection Time: 2.36617
Timestep Consumption Time: 2.61255
PPO Batch Consumption Time: 0.32065
Total Iteration Time: 4.97872

Cumulative Model Updates: 1,244
Cumulative Timesteps: 10,503,454

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 10503454...
Checkpoint 10503454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 440.83786
Policy Entropy: 2.53254
Value Function Loss: 1.72225

Mean KL Divergence: 0.00673
SB3 Clip Fraction: 0.08022
Policy Update Magnitude: 0.45636
Value Function Update Magnitude: 0.54493

Collected Steps per Second: 18,915.47638
Overall Steps per Second: 9,407.60883

Timestep Collection Time: 2.64387
Timestep Consumption Time: 2.67204
PPO Batch Consumption Time: 0.31527
Total Iteration Time: 5.31591

Cumulative Model Updates: 1,250
Cumulative Timesteps: 10,553,464

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 470.04729
Policy Entropy: 2.50390
Value Function Loss: 1.75748

Mean KL Divergence: 0.00632
SB3 Clip Fraction: 0.07499
Policy Update Magnitude: 0.47893
Value Function Update Magnitude: 0.51481

Collected Steps per Second: 20,092.45325
Overall Steps per Second: 9,617.39172

Timestep Collection Time: 2.48870
Timestep Consumption Time: 2.71064
PPO Batch Consumption Time: 0.31708
Total Iteration Time: 5.19933

Cumulative Model Updates: 1,256
Cumulative Timesteps: 10,603,468

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 10603468...
Checkpoint 10603468 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 412.00063
Policy Entropy: 2.50188
Value Function Loss: 1.82527

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.09534
Policy Update Magnitude: 0.48335
Value Function Update Magnitude: 0.40245

Collected Steps per Second: 19,187.86294
Overall Steps per Second: 9,533.93880

Timestep Collection Time: 2.60613
Timestep Consumption Time: 2.63892
PPO Batch Consumption Time: 0.31387
Total Iteration Time: 5.24505

Cumulative Model Updates: 1,262
Cumulative Timesteps: 10,653,474

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 534.14363
Policy Entropy: 2.46860
Value Function Loss: 1.79077

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.12860
Policy Update Magnitude: 0.41486
Value Function Update Magnitude: 0.42845

Collected Steps per Second: 19,508.74981
Overall Steps per Second: 9,570.05065

Timestep Collection Time: 2.56326
Timestep Consumption Time: 2.66200
PPO Batch Consumption Time: 0.30571
Total Iteration Time: 5.22526

Cumulative Model Updates: 1,268
Cumulative Timesteps: 10,703,480

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 10703480...
Checkpoint 10703480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 498.44546
Policy Entropy: 2.48816
Value Function Loss: 1.77755

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.12909
Policy Update Magnitude: 0.35709
Value Function Update Magnitude: 0.39420

Collected Steps per Second: 20,154.31006
Overall Steps per Second: 9,866.06505

Timestep Collection Time: 2.48165
Timestep Consumption Time: 2.58785
PPO Batch Consumption Time: 0.30554
Total Iteration Time: 5.06950

Cumulative Model Updates: 1,274
Cumulative Timesteps: 10,753,496

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 433.00589
Policy Entropy: 2.47317
Value Function Loss: 1.75338

Mean KL Divergence: 0.01108
SB3 Clip Fraction: 0.13279
Policy Update Magnitude: 0.31107
Value Function Update Magnitude: 0.36997

Collected Steps per Second: 20,488.85722
Overall Steps per Second: 10,126.93110

Timestep Collection Time: 2.44074
Timestep Consumption Time: 2.49738
PPO Batch Consumption Time: 0.29872
Total Iteration Time: 4.93812

Cumulative Model Updates: 1,280
Cumulative Timesteps: 10,803,504

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 10803504...
Checkpoint 10803504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 450.00890
Policy Entropy: 2.48325
Value Function Loss: 1.75612

Mean KL Divergence: 0.01164
SB3 Clip Fraction: 0.13367
Policy Update Magnitude: 0.29552
Value Function Update Magnitude: 0.33620

Collected Steps per Second: 20,481.17626
Overall Steps per Second: 9,859.11350

Timestep Collection Time: 2.44332
Timestep Consumption Time: 2.63239
PPO Batch Consumption Time: 0.30361
Total Iteration Time: 5.07571

Cumulative Model Updates: 1,286
Cumulative Timesteps: 10,853,546

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 550.48205
Policy Entropy: 2.47095
Value Function Loss: 1.81306

Mean KL Divergence: 0.00710
SB3 Clip Fraction: 0.07973
Policy Update Magnitude: 0.39046
Value Function Update Magnitude: 0.33505

Collected Steps per Second: 20,760.06241
Overall Steps per Second: 9,950.07147

Timestep Collection Time: 2.41020
Timestep Consumption Time: 2.61850
PPO Batch Consumption Time: 0.29730
Total Iteration Time: 5.02871

Cumulative Model Updates: 1,292
Cumulative Timesteps: 10,903,582

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 10903582...
Checkpoint 10903582 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 501.10197
Policy Entropy: 2.46375
Value Function Loss: 1.80208

Mean KL Divergence: 0.00728
SB3 Clip Fraction: 0.08785
Policy Update Magnitude: 0.45486
Value Function Update Magnitude: 0.34959

Collected Steps per Second: 20,931.87468
Overall Steps per Second: 10,262.71504

Timestep Collection Time: 2.39013
Timestep Consumption Time: 2.48479
PPO Batch Consumption Time: 0.29511
Total Iteration Time: 4.87493

Cumulative Model Updates: 1,298
Cumulative Timesteps: 10,953,612

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 568.45832
Policy Entropy: 2.44512
Value Function Loss: 1.96282

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.11029
Policy Update Magnitude: 0.41129
Value Function Update Magnitude: 0.32065

Collected Steps per Second: 20,864.69104
Overall Steps per Second: 10,097.91668

Timestep Collection Time: 2.39687
Timestep Consumption Time: 2.55563
PPO Batch Consumption Time: 0.29129
Total Iteration Time: 4.95251

Cumulative Model Updates: 1,304
Cumulative Timesteps: 11,003,622

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 11003622...
Checkpoint 11003622 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 500.54963
Policy Entropy: 2.43578
Value Function Loss: 1.84569

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.10818
Policy Update Magnitude: 0.34829
Value Function Update Magnitude: 0.26423

Collected Steps per Second: 19,527.63574
Overall Steps per Second: 9,723.48606

Timestep Collection Time: 2.56201
Timestep Consumption Time: 2.58326
PPO Batch Consumption Time: 0.30149
Total Iteration Time: 5.14527

Cumulative Model Updates: 1,310
Cumulative Timesteps: 11,053,652

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 649.24434
Policy Entropy: 2.40779
Value Function Loss: 1.83178

Mean KL Divergence: 0.01085
SB3 Clip Fraction: 0.12851
Policy Update Magnitude: 0.33558
Value Function Update Magnitude: 0.25676

Collected Steps per Second: 21,726.91870
Overall Steps per Second: 10,111.76056

Timestep Collection Time: 2.30249
Timestep Consumption Time: 2.64482
PPO Batch Consumption Time: 0.32185
Total Iteration Time: 4.94731

Cumulative Model Updates: 1,316
Cumulative Timesteps: 11,103,678

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 11103678...
Checkpoint 11103678 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 521.71075
Policy Entropy: 2.39358
Value Function Loss: 1.77390

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.11430
Policy Update Magnitude: 0.31959
Value Function Update Magnitude: 0.35449

Collected Steps per Second: 20,790.37838
Overall Steps per Second: 10,056.89940

Timestep Collection Time: 2.40698
Timestep Consumption Time: 2.56891
PPO Batch Consumption Time: 0.30047
Total Iteration Time: 4.97589

Cumulative Model Updates: 1,322
Cumulative Timesteps: 11,153,720

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 476.91855
Policy Entropy: 2.38591
Value Function Loss: 1.82021

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.11244
Policy Update Magnitude: 0.33353
Value Function Update Magnitude: 0.36045

Collected Steps per Second: 20,670.76231
Overall Steps per Second: 9,730.43884

Timestep Collection Time: 2.42033
Timestep Consumption Time: 2.72127
PPO Batch Consumption Time: 0.31745
Total Iteration Time: 5.14160

Cumulative Model Updates: 1,328
Cumulative Timesteps: 11,203,750

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 11203750...
Checkpoint 11203750 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 510.39851
Policy Entropy: 2.38365
Value Function Loss: 1.83007

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.10036
Policy Update Magnitude: 0.33982
Value Function Update Magnitude: 0.39531

Collected Steps per Second: 20,757.39600
Overall Steps per Second: 10,284.05815

Timestep Collection Time: 2.41013
Timestep Consumption Time: 2.45449
PPO Batch Consumption Time: 0.29683
Total Iteration Time: 4.86462

Cumulative Model Updates: 1,334
Cumulative Timesteps: 11,253,778

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 576.68631
Policy Entropy: 2.39765
Value Function Loss: 1.81469

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.10774
Policy Update Magnitude: 0.35747
Value Function Update Magnitude: 0.34486

Collected Steps per Second: 22,509.93469
Overall Steps per Second: 10,414.45295

Timestep Collection Time: 2.22169
Timestep Consumption Time: 2.58029
PPO Batch Consumption Time: 0.29725
Total Iteration Time: 4.80198

Cumulative Model Updates: 1,340
Cumulative Timesteps: 11,303,788

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 11303788...
Checkpoint 11303788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 504.31707
Policy Entropy: 2.38605
Value Function Loss: 1.79915

Mean KL Divergence: 0.01078
SB3 Clip Fraction: 0.11424
Policy Update Magnitude: 0.33689
Value Function Update Magnitude: 0.33843

Collected Steps per Second: 20,363.34081
Overall Steps per Second: 9,773.80808

Timestep Collection Time: 2.45677
Timestep Consumption Time: 2.66181
PPO Batch Consumption Time: 0.31286
Total Iteration Time: 5.11858

Cumulative Model Updates: 1,346
Cumulative Timesteps: 11,353,816

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 536.38601
Policy Entropy: 2.36792
Value Function Loss: 1.71960

Mean KL Divergence: 0.01105
SB3 Clip Fraction: 0.12136
Policy Update Magnitude: 0.31879
Value Function Update Magnitude: 0.35121

Collected Steps per Second: 19,917.01364
Overall Steps per Second: 9,966.47855

Timestep Collection Time: 2.51152
Timestep Consumption Time: 2.50750
PPO Batch Consumption Time: 0.29938
Total Iteration Time: 5.01902

Cumulative Model Updates: 1,352
Cumulative Timesteps: 11,403,838

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 11403838...
Checkpoint 11403838 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 458.16430
Policy Entropy: 2.34714
Value Function Loss: 1.75782

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.11132
Policy Update Magnitude: 0.32905
Value Function Update Magnitude: 0.34822

Collected Steps per Second: 21,395.73309
Overall Steps per Second: 10,479.42829

Timestep Collection Time: 2.33832
Timestep Consumption Time: 2.43580
PPO Batch Consumption Time: 0.29199
Total Iteration Time: 4.77412

Cumulative Model Updates: 1,358
Cumulative Timesteps: 11,453,868

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 524.16864
Policy Entropy: 2.33992
Value Function Loss: 1.79329

Mean KL Divergence: 0.01078
SB3 Clip Fraction: 0.11825
Policy Update Magnitude: 0.31074
Value Function Update Magnitude: 0.35127

Collected Steps per Second: 19,815.35615
Overall Steps per Second: 9,747.88860

Timestep Collection Time: 2.52441
Timestep Consumption Time: 2.60717
PPO Batch Consumption Time: 0.30372
Total Iteration Time: 5.13157

Cumulative Model Updates: 1,364
Cumulative Timesteps: 11,503,890

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 11503890...
Checkpoint 11503890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 688.17612
Policy Entropy: 2.36785
Value Function Loss: 1.83700

Mean KL Divergence: 0.00735
SB3 Clip Fraction: 0.08231
Policy Update Magnitude: 0.37476
Value Function Update Magnitude: 0.34242

Collected Steps per Second: 21,590.05699
Overall Steps per Second: 10,078.84059

Timestep Collection Time: 2.31727
Timestep Consumption Time: 2.64659
PPO Batch Consumption Time: 0.31413
Total Iteration Time: 4.96386

Cumulative Model Updates: 1,370
Cumulative Timesteps: 11,553,920

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 584.84339
Policy Entropy: 2.36556
Value Function Loss: 1.78764

Mean KL Divergence: 0.01071
SB3 Clip Fraction: 0.11811
Policy Update Magnitude: 0.39279
Value Function Update Magnitude: 0.32924

Collected Steps per Second: 20,513.40739
Overall Steps per Second: 9,927.05383

Timestep Collection Time: 2.43967
Timestep Consumption Time: 2.60170
PPO Batch Consumption Time: 0.31347
Total Iteration Time: 5.04137

Cumulative Model Updates: 1,376
Cumulative Timesteps: 11,603,966

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 11603966...
Checkpoint 11603966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 548.69442
Policy Entropy: 2.35850
Value Function Loss: 1.84828

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.11205
Policy Update Magnitude: 0.34704
Value Function Update Magnitude: 0.33556

Collected Steps per Second: 20,947.77321
Overall Steps per Second: 9,869.19780

Timestep Collection Time: 2.38708
Timestep Consumption Time: 2.67959
PPO Batch Consumption Time: 0.31914
Total Iteration Time: 5.06667

Cumulative Model Updates: 1,382
Cumulative Timesteps: 11,653,970

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 542.35586
Policy Entropy: 2.35522
Value Function Loss: 1.77813

Mean KL Divergence: 0.01206
SB3 Clip Fraction: 0.14015
Policy Update Magnitude: 0.31782
Value Function Update Magnitude: 0.33095

Collected Steps per Second: 20,867.36085
Overall Steps per Second: 9,826.23522

Timestep Collection Time: 2.39714
Timestep Consumption Time: 2.69352
PPO Batch Consumption Time: 0.32292
Total Iteration Time: 5.09066

Cumulative Model Updates: 1,388
Cumulative Timesteps: 11,703,992

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 11703992...
Checkpoint 11703992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 549.39886
Policy Entropy: 2.38211
Value Function Loss: 1.80220

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.11826
Policy Update Magnitude: 0.31089
Value Function Update Magnitude: 0.34224

Collected Steps per Second: 20,123.53141
Overall Steps per Second: 9,656.87449

Timestep Collection Time: 2.48654
Timestep Consumption Time: 2.69505
PPO Batch Consumption Time: 0.32633
Total Iteration Time: 5.18159

Cumulative Model Updates: 1,394
Cumulative Timesteps: 11,754,030

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 571.42790
Policy Entropy: 2.36881
Value Function Loss: 1.78920

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.11707
Policy Update Magnitude: 0.29744
Value Function Update Magnitude: 0.33286

Collected Steps per Second: 20,731.98146
Overall Steps per Second: 10,085.24608

Timestep Collection Time: 2.41241
Timestep Consumption Time: 2.54672
PPO Batch Consumption Time: 0.30345
Total Iteration Time: 4.95913

Cumulative Model Updates: 1,400
Cumulative Timesteps: 11,804,044

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 11804044...
Checkpoint 11804044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 780.74577
Policy Entropy: 2.36157
Value Function Loss: 1.89035

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.11042
Policy Update Magnitude: 0.35556
Value Function Update Magnitude: 0.33507

Collected Steps per Second: 21,758.71853
Overall Steps per Second: 10,129.86410

Timestep Collection Time: 2.29876
Timestep Consumption Time: 2.63892
PPO Batch Consumption Time: 0.30997
Total Iteration Time: 4.93768

Cumulative Model Updates: 1,406
Cumulative Timesteps: 11,854,062

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 598.50424
Policy Entropy: 2.33902
Value Function Loss: 1.84372

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.12052
Policy Update Magnitude: 0.36450
Value Function Update Magnitude: 0.35691

Collected Steps per Second: 21,345.21789
Overall Steps per Second: 10,181.38369

Timestep Collection Time: 2.34460
Timestep Consumption Time: 2.57084
PPO Batch Consumption Time: 0.31097
Total Iteration Time: 4.91544

Cumulative Model Updates: 1,412
Cumulative Timesteps: 11,904,108

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 11904108...
Checkpoint 11904108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 519.35936
Policy Entropy: 2.35211
Value Function Loss: 1.81927

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.14172
Policy Update Magnitude: 0.34072
Value Function Update Magnitude: 0.38329

Collected Steps per Second: 21,588.28983
Overall Steps per Second: 9,990.06326

Timestep Collection Time: 2.31727
Timestep Consumption Time: 2.69030
PPO Batch Consumption Time: 0.31703
Total Iteration Time: 5.00758

Cumulative Model Updates: 1,418
Cumulative Timesteps: 11,954,134

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 517.93451
Policy Entropy: 2.32113
Value Function Loss: 1.71776

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.11770
Policy Update Magnitude: 0.32754
Value Function Update Magnitude: 0.48394

Collected Steps per Second: 21,228.41880
Overall Steps per Second: 10,203.01059

Timestep Collection Time: 2.35731
Timestep Consumption Time: 2.54732
PPO Batch Consumption Time: 0.29218
Total Iteration Time: 4.90463

Cumulative Model Updates: 1,424
Cumulative Timesteps: 12,004,176

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 12004176...
Checkpoint 12004176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 505.71937
Policy Entropy: 2.32035
Value Function Loss: 1.78338

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.10947
Policy Update Magnitude: 0.33537
Value Function Update Magnitude: 0.47310

Collected Steps per Second: 20,761.82097
Overall Steps per Second: 10,193.16829

Timestep Collection Time: 2.40827
Timestep Consumption Time: 2.49698
PPO Batch Consumption Time: 0.29413
Total Iteration Time: 4.90525

Cumulative Model Updates: 1,430
Cumulative Timesteps: 12,054,176

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 747.62275
Policy Entropy: 2.33526
Value Function Loss: 1.74870

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.11768
Policy Update Magnitude: 0.34354
Value Function Update Magnitude: 0.38302

Collected Steps per Second: 21,394.72258
Overall Steps per Second: 10,595.38933

Timestep Collection Time: 2.33815
Timestep Consumption Time: 2.38315
PPO Batch Consumption Time: 0.29275
Total Iteration Time: 4.72130

Cumulative Model Updates: 1,436
Cumulative Timesteps: 12,104,200

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 12104200...
Checkpoint 12104200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 482.10901
Policy Entropy: 2.32709
Value Function Loss: 1.70164

Mean KL Divergence: 0.01195
SB3 Clip Fraction: 0.13644
Policy Update Magnitude: 0.31737
Value Function Update Magnitude: 0.44415

Collected Steps per Second: 21,214.89783
Overall Steps per Second: 10,099.08062

Timestep Collection Time: 2.35702
Timestep Consumption Time: 2.59432
PPO Batch Consumption Time: 0.30470
Total Iteration Time: 4.95134

Cumulative Model Updates: 1,442
Cumulative Timesteps: 12,154,204

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 720.63410
Policy Entropy: 2.34382
Value Function Loss: 1.62655

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.10690
Policy Update Magnitude: 0.30984
Value Function Update Magnitude: 0.49884

Collected Steps per Second: 21,997.97617
Overall Steps per Second: 10,453.23591

Timestep Collection Time: 2.27312
Timestep Consumption Time: 2.51047
PPO Batch Consumption Time: 0.28877
Total Iteration Time: 4.78359

Cumulative Model Updates: 1,448
Cumulative Timesteps: 12,204,208

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 12204208...
Checkpoint 12204208 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 723.09788
Policy Entropy: 2.35154
Value Function Loss: 1.67495

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.11027
Policy Update Magnitude: 0.31186
Value Function Update Magnitude: 0.38526

Collected Steps per Second: 21,581.38549
Overall Steps per Second: 10,546.37238

Timestep Collection Time: 2.31783
Timestep Consumption Time: 2.42522
PPO Batch Consumption Time: 0.28937
Total Iteration Time: 4.74305

Cumulative Model Updates: 1,454
Cumulative Timesteps: 12,254,230

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 612.75093
Policy Entropy: 2.34346
Value Function Loss: 1.69717

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.10961
Policy Update Magnitude: 0.32075
Value Function Update Magnitude: 0.32307

Collected Steps per Second: 23,044.81203
Overall Steps per Second: 10,526.62015

Timestep Collection Time: 2.17064
Timestep Consumption Time: 2.58131
PPO Batch Consumption Time: 0.30037
Total Iteration Time: 4.75195

Cumulative Model Updates: 1,460
Cumulative Timesteps: 12,304,252

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 12304252...
Checkpoint 12304252 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 512.10775
Policy Entropy: 2.31517
Value Function Loss: 1.70188

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.10128
Policy Update Magnitude: 0.35440
Value Function Update Magnitude: 0.30571

Collected Steps per Second: 20,607.75536
Overall Steps per Second: 9,479.24234

Timestep Collection Time: 2.42753
Timestep Consumption Time: 2.84989
PPO Batch Consumption Time: 0.33967
Total Iteration Time: 5.27743

Cumulative Model Updates: 1,466
Cumulative Timesteps: 12,354,278

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 575.45003
Policy Entropy: 2.31803
Value Function Loss: 1.69638

Mean KL Divergence: 0.00666
SB3 Clip Fraction: 0.07887
Policy Update Magnitude: 0.37204
Value Function Update Magnitude: 0.30131

Collected Steps per Second: 19,956.87769
Overall Steps per Second: 10,023.75209

Timestep Collection Time: 2.50580
Timestep Consumption Time: 2.48315
PPO Batch Consumption Time: 0.29676
Total Iteration Time: 4.98895

Cumulative Model Updates: 1,472
Cumulative Timesteps: 12,404,286

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 12404286...
Checkpoint 12404286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 649.79867
Policy Entropy: 2.31573
Value Function Loss: 1.67556

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.10745
Policy Update Magnitude: 0.37477
Value Function Update Magnitude: 0.28727

Collected Steps per Second: 20,780.18409
Overall Steps per Second: 10,176.85997

Timestep Collection Time: 2.40729
Timestep Consumption Time: 2.50817
PPO Batch Consumption Time: 0.29676
Total Iteration Time: 4.91547

Cumulative Model Updates: 1,478
Cumulative Timesteps: 12,454,310

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 676.61381
Policy Entropy: 2.32916
Value Function Loss: 1.73909

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.10935
Policy Update Magnitude: 0.32578
Value Function Update Magnitude: 0.31417

Collected Steps per Second: 21,239.84416
Overall Steps per Second: 10,185.47655

Timestep Collection Time: 2.35491
Timestep Consumption Time: 2.55580
PPO Batch Consumption Time: 0.29578
Total Iteration Time: 4.91072

Cumulative Model Updates: 1,484
Cumulative Timesteps: 12,504,328

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 12504328...
Checkpoint 12504328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 566.21957
Policy Entropy: 2.31207
Value Function Loss: 1.71311

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.11149
Policy Update Magnitude: 0.29854
Value Function Update Magnitude: 0.31748

Collected Steps per Second: 21,126.49944
Overall Steps per Second: 10,087.99622

Timestep Collection Time: 2.36793
Timestep Consumption Time: 2.59104
PPO Batch Consumption Time: 0.30010
Total Iteration Time: 4.95896

Cumulative Model Updates: 1,490
Cumulative Timesteps: 12,554,354

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 625.98240
Policy Entropy: 2.30355
Value Function Loss: 1.71716

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.10853
Policy Update Magnitude: 0.34863
Value Function Update Magnitude: 0.35594

Collected Steps per Second: 21,526.34469
Overall Steps per Second: 10,265.63764

Timestep Collection Time: 2.32404
Timestep Consumption Time: 2.54931
PPO Batch Consumption Time: 0.29818
Total Iteration Time: 4.87335

Cumulative Model Updates: 1,496
Cumulative Timesteps: 12,604,382

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 12604382...
Checkpoint 12604382 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 582.95583
Policy Entropy: 2.29017
Value Function Loss: 1.67710

Mean KL Divergence: 0.01136
SB3 Clip Fraction: 0.12885
Policy Update Magnitude: 0.36353
Value Function Update Magnitude: 0.39860

Collected Steps per Second: 20,586.87069
Overall Steps per Second: 10,363.58661

Timestep Collection Time: 2.42970
Timestep Consumption Time: 2.39681
PPO Batch Consumption Time: 0.29303
Total Iteration Time: 4.82651

Cumulative Model Updates: 1,502
Cumulative Timesteps: 12,654,402

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 518.84512
Policy Entropy: 2.26916
Value Function Loss: 1.74556

Mean KL Divergence: 0.02326
SB3 Clip Fraction: 0.20367
Policy Update Magnitude: 0.31988
Value Function Update Magnitude: 0.31976

Collected Steps per Second: 20,940.72974
Overall Steps per Second: 10,228.23395

Timestep Collection Time: 2.38912
Timestep Consumption Time: 2.50224
PPO Batch Consumption Time: 0.29412
Total Iteration Time: 4.89136

Cumulative Model Updates: 1,508
Cumulative Timesteps: 12,704,432

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 12704432...
Checkpoint 12704432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 461.18810
Policy Entropy: 2.23662
Value Function Loss: 1.78448

Mean KL Divergence: 0.01248
SB3 Clip Fraction: 0.14335
Policy Update Magnitude: 0.32074
Value Function Update Magnitude: 0.30468

Collected Steps per Second: 21,001.76532
Overall Steps per Second: 10,096.01119

Timestep Collection Time: 2.38218
Timestep Consumption Time: 2.57324
PPO Batch Consumption Time: 0.30402
Total Iteration Time: 4.95542

Cumulative Model Updates: 1,514
Cumulative Timesteps: 12,754,462

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 525.85438
Policy Entropy: 2.21757
Value Function Loss: 1.79811

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.09586
Policy Update Magnitude: 0.35391
Value Function Update Magnitude: 0.32038

Collected Steps per Second: 21,578.49816
Overall Steps per Second: 10,469.59462

Timestep Collection Time: 2.31777
Timestep Consumption Time: 2.45930
PPO Batch Consumption Time: 0.29317
Total Iteration Time: 4.77707

Cumulative Model Updates: 1,520
Cumulative Timesteps: 12,804,476

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 12804476...
Checkpoint 12804476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 521.87879
Policy Entropy: 2.20703
Value Function Loss: 1.71847

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.10882
Policy Update Magnitude: 0.34083
Value Function Update Magnitude: 0.34129

Collected Steps per Second: 21,086.70774
Overall Steps per Second: 10,228.80788

Timestep Collection Time: 2.37239
Timestep Consumption Time: 2.51830
PPO Batch Consumption Time: 0.29546
Total Iteration Time: 4.89070

Cumulative Model Updates: 1,526
Cumulative Timesteps: 12,854,502

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 877.83073
Policy Entropy: 2.19898
Value Function Loss: 1.70574

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.09913
Policy Update Magnitude: 0.35052
Value Function Update Magnitude: 0.34767

Collected Steps per Second: 21,431.94674
Overall Steps per Second: 10,282.30567

Timestep Collection Time: 2.33418
Timestep Consumption Time: 2.53107
PPO Batch Consumption Time: 0.29649
Total Iteration Time: 4.86525

Cumulative Model Updates: 1,532
Cumulative Timesteps: 12,904,528

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 12904528...
Checkpoint 12904528 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 607.09570
Policy Entropy: 2.22409
Value Function Loss: 1.75013

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.11161
Policy Update Magnitude: 0.34272
Value Function Update Magnitude: 0.32705

Collected Steps per Second: 18,920.57764
Overall Steps per Second: 9,365.40155

Timestep Collection Time: 2.64368
Timestep Consumption Time: 2.69725
PPO Batch Consumption Time: 0.32405
Total Iteration Time: 5.34093

Cumulative Model Updates: 1,538
Cumulative Timesteps: 12,954,548

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 612.73778
Policy Entropy: 2.20037
Value Function Loss: 1.78801

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.10932
Policy Update Magnitude: 0.35849
Value Function Update Magnitude: 0.38529

Collected Steps per Second: 21,069.78876
Overall Steps per Second: 10,105.84277

Timestep Collection Time: 2.37335
Timestep Consumption Time: 2.57488
PPO Batch Consumption Time: 0.31205
Total Iteration Time: 4.94823

Cumulative Model Updates: 1,544
Cumulative Timesteps: 13,004,554

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 13004554...
Checkpoint 13004554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 784.62090
Policy Entropy: 2.22673
Value Function Loss: 1.85166

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.11780
Policy Update Magnitude: 0.33498
Value Function Update Magnitude: 0.39386

Collected Steps per Second: 20,958.10303
Overall Steps per Second: 10,217.80364

Timestep Collection Time: 2.38638
Timestep Consumption Time: 2.50841
PPO Batch Consumption Time: 0.30158
Total Iteration Time: 4.89479

Cumulative Model Updates: 1,550
Cumulative Timesteps: 13,054,568

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 684.37345
Policy Entropy: 2.22722
Value Function Loss: 1.83893

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.10842
Policy Update Magnitude: 0.33758
Value Function Update Magnitude: 0.35045

Collected Steps per Second: 21,925.57951
Overall Steps per Second: 10,162.72817

Timestep Collection Time: 2.28181
Timestep Consumption Time: 2.64108
PPO Batch Consumption Time: 0.30819
Total Iteration Time: 4.92289

Cumulative Model Updates: 1,556
Cumulative Timesteps: 13,104,598

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 13104598...
Checkpoint 13104598 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 580.27818
Policy Entropy: 2.21315
Value Function Loss: 1.86761

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.12342
Policy Update Magnitude: 0.32344
Value Function Update Magnitude: 0.35124

Collected Steps per Second: 21,936.67429
Overall Steps per Second: 10,210.75225

Timestep Collection Time: 2.28047
Timestep Consumption Time: 2.61887
PPO Batch Consumption Time: 0.31272
Total Iteration Time: 4.89935

Cumulative Model Updates: 1,562
Cumulative Timesteps: 13,154,624

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 667.77276
Policy Entropy: 2.21174
Value Function Loss: 1.85318

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.10922
Policy Update Magnitude: 0.31204
Value Function Update Magnitude: 0.40327

Collected Steps per Second: 22,838.04115
Overall Steps per Second: 10,547.05089

Timestep Collection Time: 2.19038
Timestep Consumption Time: 2.55256
PPO Batch Consumption Time: 0.29623
Total Iteration Time: 4.74294

Cumulative Model Updates: 1,568
Cumulative Timesteps: 13,204,648

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 13204648...
Checkpoint 13204648 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 697.97839
Policy Entropy: 2.17257
Value Function Loss: 1.79069

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.11550
Policy Update Magnitude: 0.30703
Value Function Update Magnitude: 0.34733

Collected Steps per Second: 21,890.15621
Overall Steps per Second: 9,936.00654

Timestep Collection Time: 2.28495
Timestep Consumption Time: 2.74906
PPO Batch Consumption Time: 0.32947
Total Iteration Time: 5.03401

Cumulative Model Updates: 1,574
Cumulative Timesteps: 13,254,666

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 628.87834
Policy Entropy: 2.17245
Value Function Loss: 1.73332

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.09901
Policy Update Magnitude: 0.37086
Value Function Update Magnitude: 0.45490

Collected Steps per Second: 19,583.47450
Overall Steps per Second: 9,661.39697

Timestep Collection Time: 2.55399
Timestep Consumption Time: 2.62290
PPO Batch Consumption Time: 0.30952
Total Iteration Time: 5.17689

Cumulative Model Updates: 1,580
Cumulative Timesteps: 13,304,682

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 13304682...
Checkpoint 13304682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 556.36112
Policy Entropy: 2.12350
Value Function Loss: 1.62971

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.12150
Policy Update Magnitude: 0.39159
Value Function Update Magnitude: 0.50284

Collected Steps per Second: 21,706.97913
Overall Steps per Second: 10,550.31960

Timestep Collection Time: 2.30405
Timestep Consumption Time: 2.43647
PPO Batch Consumption Time: 0.30327
Total Iteration Time: 4.74052

Cumulative Model Updates: 1,586
Cumulative Timesteps: 13,354,696

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 642.98539
Policy Entropy: 2.15118
Value Function Loss: 1.62852

Mean KL Divergence: 0.02344
SB3 Clip Fraction: 0.23845
Policy Update Magnitude: 0.33183
Value Function Update Magnitude: 0.54859

Collected Steps per Second: 20,263.71601
Overall Steps per Second: 10,018.04342

Timestep Collection Time: 2.46786
Timestep Consumption Time: 2.52393
PPO Batch Consumption Time: 0.29075
Total Iteration Time: 4.99179

Cumulative Model Updates: 1,592
Cumulative Timesteps: 13,404,704

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 13404704...
Checkpoint 13404704 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 576.11514
Policy Entropy: 2.12817
Value Function Loss: 1.61177

Mean KL Divergence: 0.01850
SB3 Clip Fraction: 0.18066
Policy Update Magnitude: 0.27430
Value Function Update Magnitude: 0.49701

Collected Steps per Second: 21,929.74184
Overall Steps per Second: 10,374.97914

Timestep Collection Time: 2.28001
Timestep Consumption Time: 2.53928
PPO Batch Consumption Time: 0.30082
Total Iteration Time: 4.81929

Cumulative Model Updates: 1,598
Cumulative Timesteps: 13,454,704

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 500.72846
Policy Entropy: 2.11107
Value Function Loss: 1.71773

Mean KL Divergence: 0.01879
SB3 Clip Fraction: 0.19268
Policy Update Magnitude: 0.22653
Value Function Update Magnitude: 0.38878

Collected Steps per Second: 21,765.90850
Overall Steps per Second: 10,438.59834

Timestep Collection Time: 2.29763
Timestep Consumption Time: 2.49324
PPO Batch Consumption Time: 0.30053
Total Iteration Time: 4.79087

Cumulative Model Updates: 1,604
Cumulative Timesteps: 13,504,714

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 13504714...
Checkpoint 13504714 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 564.71789
Policy Entropy: 2.11830
Value Function Loss: 1.66702

Mean KL Divergence: 0.01427
SB3 Clip Fraction: 0.14709
Policy Update Magnitude: 0.25599
Value Function Update Magnitude: 0.36439

Collected Steps per Second: 22,658.83778
Overall Steps per Second: 10,601.49317

Timestep Collection Time: 2.20770
Timestep Consumption Time: 2.51088
PPO Batch Consumption Time: 0.29277
Total Iteration Time: 4.71858

Cumulative Model Updates: 1,610
Cumulative Timesteps: 13,554,738

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 579.91651
Policy Entropy: 2.10060
Value Function Loss: 1.66301

Mean KL Divergence: 0.01256
SB3 Clip Fraction: 0.11791
Policy Update Magnitude: 0.29056
Value Function Update Magnitude: 0.43816

Collected Steps per Second: 22,730.38129
Overall Steps per Second: 10,498.11391

Timestep Collection Time: 2.20067
Timestep Consumption Time: 2.56419
PPO Batch Consumption Time: 0.30004
Total Iteration Time: 4.76486

Cumulative Model Updates: 1,616
Cumulative Timesteps: 13,604,760

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 13604760...
Checkpoint 13604760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 515.08332
Policy Entropy: 2.10900
Value Function Loss: 1.60822

Mean KL Divergence: 0.00746
SB3 Clip Fraction: 0.08002
Policy Update Magnitude: 0.33709
Value Function Update Magnitude: 0.33446

Collected Steps per Second: 22,595.96779
Overall Steps per Second: 10,583.32438

Timestep Collection Time: 2.21296
Timestep Consumption Time: 2.51183
PPO Batch Consumption Time: 0.29637
Total Iteration Time: 4.72479

Cumulative Model Updates: 1,622
Cumulative Timesteps: 13,654,764

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 609.76900
Policy Entropy: 2.10998
Value Function Loss: 1.63277

Mean KL Divergence: 0.00652
SB3 Clip Fraction: 0.07630
Policy Update Magnitude: 0.39122
Value Function Update Magnitude: 0.29270

Collected Steps per Second: 22,509.60693
Overall Steps per Second: 10,786.54632

Timestep Collection Time: 2.22181
Timestep Consumption Time: 2.41471
PPO Batch Consumption Time: 0.28603
Total Iteration Time: 4.63652

Cumulative Model Updates: 1,628
Cumulative Timesteps: 13,704,776

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 13704776...
Checkpoint 13704776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 666.59460
Policy Entropy: 2.11442
Value Function Loss: 1.66593

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.10040
Policy Update Magnitude: 0.41885
Value Function Update Magnitude: 0.30508

Collected Steps per Second: 22,588.30364
Overall Steps per Second: 10,594.21727

Timestep Collection Time: 2.21424
Timestep Consumption Time: 2.50682
PPO Batch Consumption Time: 0.29180
Total Iteration Time: 4.72107

Cumulative Model Updates: 1,634
Cumulative Timesteps: 13,754,792

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 707.03642
Policy Entropy: 2.13236
Value Function Loss: 1.63470

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.10810
Policy Update Magnitude: 0.34185
Value Function Update Magnitude: 0.32313

Collected Steps per Second: 23,014.40897
Overall Steps per Second: 10,614.57543

Timestep Collection Time: 2.17299
Timestep Consumption Time: 2.53846
PPO Batch Consumption Time: 0.29543
Total Iteration Time: 4.71145

Cumulative Model Updates: 1,640
Cumulative Timesteps: 13,804,802

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 13804802...
Checkpoint 13804802 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 689.30647
Policy Entropy: 2.12923
Value Function Loss: 1.66911

Mean KL Divergence: 0.00777
SB3 Clip Fraction: 0.08848
Policy Update Magnitude: 0.32346
Value Function Update Magnitude: 0.37305

Collected Steps per Second: 22,807.07706
Overall Steps per Second: 10,635.43865

Timestep Collection Time: 2.19309
Timestep Consumption Time: 2.50986
PPO Batch Consumption Time: 0.29644
Total Iteration Time: 4.70296

Cumulative Model Updates: 1,646
Cumulative Timesteps: 13,854,820

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 544.49478
Policy Entropy: 2.11240
Value Function Loss: 1.69436

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.09008
Policy Update Magnitude: 0.31214
Value Function Update Magnitude: 0.32182

Collected Steps per Second: 23,744.72564
Overall Steps per Second: 10,892.42818

Timestep Collection Time: 2.10632
Timestep Consumption Time: 2.48531
PPO Batch Consumption Time: 0.28623
Total Iteration Time: 4.59163

Cumulative Model Updates: 1,652
Cumulative Timesteps: 13,904,834

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 13904834...
Checkpoint 13904834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 505.40300
Policy Entropy: 2.10954
Value Function Loss: 1.70521

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.09241
Policy Update Magnitude: 0.33857
Value Function Update Magnitude: 0.31674

Collected Steps per Second: 22,381.89281
Overall Steps per Second: 10,605.21496

Timestep Collection Time: 2.23413
Timestep Consumption Time: 2.48091
PPO Batch Consumption Time: 0.28633
Total Iteration Time: 4.71504

Cumulative Model Updates: 1,658
Cumulative Timesteps: 13,954,838

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 453.57911
Policy Entropy: 2.09642
Value Function Loss: 1.72729

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.09064
Policy Update Magnitude: 0.34794
Value Function Update Magnitude: 0.33010

Collected Steps per Second: 22,552.78694
Overall Steps per Second: 10,531.83647

Timestep Collection Time: 2.21702
Timestep Consumption Time: 2.53049
PPO Batch Consumption Time: 0.30072
Total Iteration Time: 4.74751

Cumulative Model Updates: 1,664
Cumulative Timesteps: 14,004,838

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 14004838...
Checkpoint 14004838 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 540.95032
Policy Entropy: 2.11343
Value Function Loss: 1.67026

Mean KL Divergence: 0.00508
SB3 Clip Fraction: 0.05785
Policy Update Magnitude: 0.42629
Value Function Update Magnitude: 0.32246

Collected Steps per Second: 22,596.55186
Overall Steps per Second: 10,672.38341

Timestep Collection Time: 2.21388
Timestep Consumption Time: 2.47355
PPO Batch Consumption Time: 0.29944
Total Iteration Time: 4.68743

Cumulative Model Updates: 1,670
Cumulative Timesteps: 14,054,864

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 686.11655
Policy Entropy: 2.08320
Value Function Loss: 1.64136

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.09070
Policy Update Magnitude: 0.43877
Value Function Update Magnitude: 0.34309

Collected Steps per Second: 22,378.82809
Overall Steps per Second: 10,442.29250

Timestep Collection Time: 2.23551
Timestep Consumption Time: 2.55540
PPO Batch Consumption Time: 0.30025
Total Iteration Time: 4.79090

Cumulative Model Updates: 1,676
Cumulative Timesteps: 14,104,892

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 14104892...
Checkpoint 14104892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 437.80219
Policy Entropy: 2.06791
Value Function Loss: 1.59242

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.12229
Policy Update Magnitude: 0.35153
Value Function Update Magnitude: 0.36487

Collected Steps per Second: 22,547.66725
Overall Steps per Second: 10,571.22276

Timestep Collection Time: 2.21770
Timestep Consumption Time: 2.51250
PPO Batch Consumption Time: 0.29476
Total Iteration Time: 4.73020

Cumulative Model Updates: 1,682
Cumulative Timesteps: 14,154,896

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 525.58685
Policy Entropy: 2.05247
Value Function Loss: 1.65727

Mean KL Divergence: 0.01101
SB3 Clip Fraction: 0.12704
Policy Update Magnitude: 0.30557
Value Function Update Magnitude: 0.36266

Collected Steps per Second: 22,842.66777
Overall Steps per Second: 10,892.48828

Timestep Collection Time: 2.18906
Timestep Consumption Time: 2.40163
PPO Batch Consumption Time: 0.28656
Total Iteration Time: 4.59069

Cumulative Model Updates: 1,688
Cumulative Timesteps: 14,204,900

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 14204900...
Checkpoint 14204900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 641.24523
Policy Entropy: 2.06142
Value Function Loss: 1.66538

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.10521
Policy Update Magnitude: 0.29106
Value Function Update Magnitude: 0.34555

Collected Steps per Second: 22,579.74029
Overall Steps per Second: 10,640.72056

Timestep Collection Time: 2.21561
Timestep Consumption Time: 2.48595
PPO Batch Consumption Time: 0.28679
Total Iteration Time: 4.70156

Cumulative Model Updates: 1,694
Cumulative Timesteps: 14,254,928

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 789.49020
Policy Entropy: 2.06297
Value Function Loss: 1.73111

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.08978
Policy Update Magnitude: 0.33660
Value Function Update Magnitude: 0.38431

Collected Steps per Second: 22,840.43880
Overall Steps per Second: 10,556.05787

Timestep Collection Time: 2.18910
Timestep Consumption Time: 2.54752
PPO Batch Consumption Time: 0.29944
Total Iteration Time: 4.73662

Cumulative Model Updates: 1,700
Cumulative Timesteps: 14,304,928

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 14304928...
Checkpoint 14304928 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 531.23669
Policy Entropy: 2.06585
Value Function Loss: 1.74940

Mean KL Divergence: 0.01081
SB3 Clip Fraction: 0.12357
Policy Update Magnitude: 0.31026
Value Function Update Magnitude: 0.38804

Collected Steps per Second: 22,513.99123
Overall Steps per Second: 10,546.50133

Timestep Collection Time: 2.22155
Timestep Consumption Time: 2.52087
PPO Batch Consumption Time: 0.29611
Total Iteration Time: 4.74243

Cumulative Model Updates: 1,706
Cumulative Timesteps: 14,354,944

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 603.05029
Policy Entropy: 2.06411
Value Function Loss: 1.75767

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.11936
Policy Update Magnitude: 0.32019
Value Function Update Magnitude: 0.42544

Collected Steps per Second: 22,744.49859
Overall Steps per Second: 10,862.63357

Timestep Collection Time: 2.19913
Timestep Consumption Time: 2.40547
PPO Batch Consumption Time: 0.28591
Total Iteration Time: 4.60459

Cumulative Model Updates: 1,712
Cumulative Timesteps: 14,404,962

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 14404962...
Checkpoint 14404962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 592.05370
Policy Entropy: 2.05711
Value Function Loss: 1.72660

Mean KL Divergence: 0.01123
SB3 Clip Fraction: 0.12327
Policy Update Magnitude: 0.35850
Value Function Update Magnitude: 0.42749

Collected Steps per Second: 22,820.48074
Overall Steps per Second: 10,725.86717

Timestep Collection Time: 2.19163
Timestep Consumption Time: 2.47131
PPO Batch Consumption Time: 0.28494
Total Iteration Time: 4.66293

Cumulative Model Updates: 1,718
Cumulative Timesteps: 14,454,976

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 586.81945
Policy Entropy: 2.06398
Value Function Loss: 1.80290

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.10268
Policy Update Magnitude: 0.30894
Value Function Update Magnitude: 0.39970

Collected Steps per Second: 22,535.19604
Overall Steps per Second: 10,454.50752

Timestep Collection Time: 2.21964
Timestep Consumption Time: 2.56490
PPO Batch Consumption Time: 0.29985
Total Iteration Time: 4.78454

Cumulative Model Updates: 1,724
Cumulative Timesteps: 14,504,996

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 14504996...
Checkpoint 14504996 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 572.67877
Policy Entropy: 2.03935
Value Function Loss: 1.77157

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.10859
Policy Update Magnitude: 0.30576
Value Function Update Magnitude: 0.34672

Collected Steps per Second: 22,477.79512
Overall Steps per Second: 10,635.37170

Timestep Collection Time: 2.22504
Timestep Consumption Time: 2.47757
PPO Batch Consumption Time: 0.30066
Total Iteration Time: 4.70261

Cumulative Model Updates: 1,730
Cumulative Timesteps: 14,555,010

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 754.86327
Policy Entropy: 2.05303
Value Function Loss: 1.80830

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.12382
Policy Update Magnitude: 0.31634
Value Function Update Magnitude: 0.34849

Collected Steps per Second: 22,786.00573
Overall Steps per Second: 10,562.89119

Timestep Collection Time: 2.19433
Timestep Consumption Time: 2.53922
PPO Batch Consumption Time: 0.29922
Total Iteration Time: 4.73355

Cumulative Model Updates: 1,736
Cumulative Timesteps: 14,605,010

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 14605010...
Checkpoint 14605010 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 605.23284
Policy Entropy: 2.03604
Value Function Loss: 1.68831

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.11580
Policy Update Magnitude: 0.35157
Value Function Update Magnitude: 0.41994

Collected Steps per Second: 22,650.35514
Overall Steps per Second: 10,402.52285

Timestep Collection Time: 2.20800
Timestep Consumption Time: 2.59968
PPO Batch Consumption Time: 0.30621
Total Iteration Time: 4.80768

Cumulative Model Updates: 1,742
Cumulative Timesteps: 14,655,022

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 705.36554
Policy Entropy: 2.04608
Value Function Loss: 1.65513

Mean KL Divergence: 0.02576
SB3 Clip Fraction: 0.23013
Policy Update Magnitude: 0.31148
Value Function Update Magnitude: 0.40344

Collected Steps per Second: 20,571.92672
Overall Steps per Second: 10,298.70678

Timestep Collection Time: 2.43050
Timestep Consumption Time: 2.42448
PPO Batch Consumption Time: 0.28617
Total Iteration Time: 4.85498

Cumulative Model Updates: 1,748
Cumulative Timesteps: 14,705,022

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 14705022...
Checkpoint 14705022 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 688.53043
Policy Entropy: 2.05920
Value Function Loss: 1.62461

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.11656
Policy Update Magnitude: 0.26396
Value Function Update Magnitude: 0.43233

Collected Steps per Second: 22,443.54274
Overall Steps per Second: 10,645.34679

Timestep Collection Time: 2.22799
Timestep Consumption Time: 2.46927
PPO Batch Consumption Time: 0.29721
Total Iteration Time: 4.69726

Cumulative Model Updates: 1,754
Cumulative Timesteps: 14,755,026

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 600.87344
Policy Entropy: 2.05561
Value Function Loss: 1.68302

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.09828
Policy Update Magnitude: 0.31585
Value Function Update Magnitude: 0.50779

Collected Steps per Second: 22,008.29473
Overall Steps per Second: 10,378.27876

Timestep Collection Time: 2.27296
Timestep Consumption Time: 2.54711
PPO Batch Consumption Time: 0.29937
Total Iteration Time: 4.82007

Cumulative Model Updates: 1,760
Cumulative Timesteps: 14,805,050

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 14805050...
Checkpoint 14805050 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 524.62547
Policy Entropy: 2.03992
Value Function Loss: 1.69928

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.08809
Policy Update Magnitude: 0.32697
Value Function Update Magnitude: 0.49930

Collected Steps per Second: 22,234.82888
Overall Steps per Second: 10,531.46091

Timestep Collection Time: 2.24872
Timestep Consumption Time: 2.49896
PPO Batch Consumption Time: 0.28731
Total Iteration Time: 4.74768

Cumulative Model Updates: 1,766
Cumulative Timesteps: 14,855,050

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 752.03686
Policy Entropy: 2.04603
Value Function Loss: 1.73590

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.09808
Policy Update Magnitude: 0.30658
Value Function Update Magnitude: 0.46730

Collected Steps per Second: 22,134.36160
Overall Steps per Second: 10,472.63903

Timestep Collection Time: 2.25956
Timestep Consumption Time: 2.51612
PPO Batch Consumption Time: 0.29385
Total Iteration Time: 4.77568

Cumulative Model Updates: 1,772
Cumulative Timesteps: 14,905,064

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 14905064...
Checkpoint 14905064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 696.40991
Policy Entropy: 2.04166
Value Function Loss: 1.74598

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.10431
Policy Update Magnitude: 0.29537
Value Function Update Magnitude: 0.43879

Collected Steps per Second: 22,154.97159
Overall Steps per Second: 10,645.34629

Timestep Collection Time: 2.25782
Timestep Consumption Time: 2.44113
PPO Batch Consumption Time: 0.29202
Total Iteration Time: 4.69895

Cumulative Model Updates: 1,778
Cumulative Timesteps: 14,955,086

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 625.68941
Policy Entropy: 2.06118
Value Function Loss: 1.82313

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.09579
Policy Update Magnitude: 0.31320
Value Function Update Magnitude: 0.40286

Collected Steps per Second: 22,499.96031
Overall Steps per Second: 10,477.84533

Timestep Collection Time: 2.22338
Timestep Consumption Time: 2.55107
PPO Batch Consumption Time: 0.29592
Total Iteration Time: 4.77445

Cumulative Model Updates: 1,784
Cumulative Timesteps: 15,005,112

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 15005112...
Checkpoint 15005112 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 664.61956
Policy Entropy: 2.05338
Value Function Loss: 1.87595

Mean KL Divergence: 0.00598
SB3 Clip Fraction: 0.06905
Policy Update Magnitude: 0.41221
Value Function Update Magnitude: 0.40544

Collected Steps per Second: 22,068.06537
Overall Steps per Second: 10,382.78090

Timestep Collection Time: 2.26599
Timestep Consumption Time: 2.55025
PPO Batch Consumption Time: 0.29729
Total Iteration Time: 4.81624

Cumulative Model Updates: 1,790
Cumulative Timesteps: 15,055,118

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 859.95308
Policy Entropy: 2.04005
Value Function Loss: 1.84184

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.10348
Policy Update Magnitude: 0.40314
Value Function Update Magnitude: 0.42054

Collected Steps per Second: 22,687.32066
Overall Steps per Second: 10,683.90196

Timestep Collection Time: 2.20440
Timestep Consumption Time: 2.47666
PPO Batch Consumption Time: 0.29649
Total Iteration Time: 4.68106

Cumulative Model Updates: 1,796
Cumulative Timesteps: 15,105,130

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 15105130...
Checkpoint 15105130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 710.14230
Policy Entropy: 2.04709
Value Function Loss: 1.84731

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.11145
Policy Update Magnitude: 0.33534
Value Function Update Magnitude: 0.39117

Collected Steps per Second: 22,219.57100
Overall Steps per Second: 10,550.83009

Timestep Collection Time: 2.25054
Timestep Consumption Time: 2.48899
PPO Batch Consumption Time: 0.28766
Total Iteration Time: 4.73953

Cumulative Model Updates: 1,802
Cumulative Timesteps: 15,155,136

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 564.65086
Policy Entropy: 2.02803
Value Function Loss: 1.82710

Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.10296
Policy Update Magnitude: 0.31216
Value Function Update Magnitude: 0.35600

Collected Steps per Second: 22,481.78462
Overall Steps per Second: 10,577.03921

Timestep Collection Time: 2.22500
Timestep Consumption Time: 2.50430
PPO Batch Consumption Time: 0.28977
Total Iteration Time: 4.72930

Cumulative Model Updates: 1,808
Cumulative Timesteps: 15,205,158

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 15205158...
Checkpoint 15205158 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 573.07478
Policy Entropy: 2.02390
Value Function Loss: 1.85923

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.09608
Policy Update Magnitude: 0.32852
Value Function Update Magnitude: 0.35938

Collected Steps per Second: 22,131.03947
Overall Steps per Second: 10,594.54996

Timestep Collection Time: 2.26017
Timestep Consumption Time: 2.46112
PPO Batch Consumption Time: 0.28682
Total Iteration Time: 4.72130

Cumulative Model Updates: 1,814
Cumulative Timesteps: 15,255,178

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 601.43061
Policy Entropy: 2.01648
Value Function Loss: 1.84369

Mean KL Divergence: 0.00686
SB3 Clip Fraction: 0.07966
Policy Update Magnitude: 0.36941
Value Function Update Magnitude: 0.32592

Collected Steps per Second: 22,310.93269
Overall Steps per Second: 10,615.22599

Timestep Collection Time: 2.24195
Timestep Consumption Time: 2.47015
PPO Batch Consumption Time: 0.29858
Total Iteration Time: 4.71210

Cumulative Model Updates: 1,820
Cumulative Timesteps: 15,305,198

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 15305198...
Checkpoint 15305198 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 773.74128
Policy Entropy: 2.05814
Value Function Loss: 1.86612

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.09987
Policy Update Magnitude: 0.37286
Value Function Update Magnitude: 0.33226

Collected Steps per Second: 21,947.50661
Overall Steps per Second: 10,615.81287

Timestep Collection Time: 2.27880
Timestep Consumption Time: 2.43247
PPO Batch Consumption Time: 0.28656
Total Iteration Time: 4.71127

Cumulative Model Updates: 1,826
Cumulative Timesteps: 15,355,212

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 681.41479
Policy Entropy: 2.05842
Value Function Loss: 1.83238

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.09904
Policy Update Magnitude: 0.34470
Value Function Update Magnitude: 0.33040

Collected Steps per Second: 22,375.40379
Overall Steps per Second: 10,321.08759

Timestep Collection Time: 2.23540
Timestep Consumption Time: 2.61079
PPO Batch Consumption Time: 0.30468
Total Iteration Time: 4.84619

Cumulative Model Updates: 1,832
Cumulative Timesteps: 15,405,230

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 15405230...
Checkpoint 15405230 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 557.05377
Policy Entropy: 2.08496
Value Function Loss: 1.82046

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.09619
Policy Update Magnitude: 0.35818
Value Function Update Magnitude: 0.43063

Collected Steps per Second: 21,978.82954
Overall Steps per Second: 10,711.71858

Timestep Collection Time: 2.27519
Timestep Consumption Time: 2.39316
PPO Batch Consumption Time: 0.28731
Total Iteration Time: 4.66835

Cumulative Model Updates: 1,838
Cumulative Timesteps: 15,455,236

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 562.98450
Policy Entropy: 2.05749
Value Function Loss: 1.81072

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.10741
Policy Update Magnitude: 0.35984
Value Function Update Magnitude: 0.48800

Collected Steps per Second: 21,693.14154
Overall Steps per Second: 10,742.97963

Timestep Collection Time: 2.30561
Timestep Consumption Time: 2.35008
PPO Batch Consumption Time: 0.28746
Total Iteration Time: 4.65569

Cumulative Model Updates: 1,844
Cumulative Timesteps: 15,505,252

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 15505252...
Checkpoint 15505252 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 493.54317
Policy Entropy: 2.05878
Value Function Loss: 1.81998

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.10450
Policy Update Magnitude: 0.34471
Value Function Update Magnitude: 0.52205

Collected Steps per Second: 22,139.44967
Overall Steps per Second: 10,364.99614

Timestep Collection Time: 2.25877
Timestep Consumption Time: 2.56593
PPO Batch Consumption Time: 0.30164
Total Iteration Time: 4.82470

Cumulative Model Updates: 1,850
Cumulative Timesteps: 15,555,260

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 454.48653
Policy Entropy: 2.06477
Value Function Loss: 1.83797

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.10220
Policy Update Magnitude: 0.32235
Value Function Update Magnitude: 0.55911

Collected Steps per Second: 22,468.64841
Overall Steps per Second: 10,437.98051

Timestep Collection Time: 2.22604
Timestep Consumption Time: 2.56570
PPO Batch Consumption Time: 0.30005
Total Iteration Time: 4.79173

Cumulative Model Updates: 1,856
Cumulative Timesteps: 15,605,276

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 15605276...
Checkpoint 15605276 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 897.29638
Policy Entropy: 2.06777
Value Function Loss: 1.92083

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.10226
Policy Update Magnitude: 0.31563
Value Function Update Magnitude: 0.48217

Collected Steps per Second: 21,874.02336
Overall Steps per Second: 10,531.67436

Timestep Collection Time: 2.28655
Timestep Consumption Time: 2.46255
PPO Batch Consumption Time: 0.28661
Total Iteration Time: 4.74910

Cumulative Model Updates: 1,862
Cumulative Timesteps: 15,655,292

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 661.96006
Policy Entropy: 2.06678
Value Function Loss: 1.92256

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.10147
Policy Update Magnitude: 0.33153
Value Function Update Magnitude: 0.38671

Collected Steps per Second: 22,499.66805
Overall Steps per Second: 10,637.34500

Timestep Collection Time: 2.22323
Timestep Consumption Time: 2.47926
PPO Batch Consumption Time: 0.29891
Total Iteration Time: 4.70249

Cumulative Model Updates: 1,868
Cumulative Timesteps: 15,705,314

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 15705314...
Checkpoint 15705314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 523.57552
Policy Entropy: 2.04399
Value Function Loss: 1.91928

Mean KL Divergence: 0.00770
SB3 Clip Fraction: 0.09144
Policy Update Magnitude: 0.37521
Value Function Update Magnitude: 0.32757

Collected Steps per Second: 22,311.69223
Overall Steps per Second: 10,537.71839

Timestep Collection Time: 2.24169
Timestep Consumption Time: 2.50468
PPO Batch Consumption Time: 0.28738
Total Iteration Time: 4.74638

Cumulative Model Updates: 1,874
Cumulative Timesteps: 15,755,330

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 641.26307
Policy Entropy: 2.04637
Value Function Loss: 1.87299

Mean KL Divergence: 0.00659
SB3 Clip Fraction: 0.07481
Policy Update Magnitude: 0.42469
Value Function Update Magnitude: 0.34700

Collected Steps per Second: 22,576.08254
Overall Steps per Second: 10,459.59245

Timestep Collection Time: 2.21491
Timestep Consumption Time: 2.56577
PPO Batch Consumption Time: 0.29861
Total Iteration Time: 4.78068

Cumulative Model Updates: 1,880
Cumulative Timesteps: 15,805,334

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 15805334...
Checkpoint 15805334 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 587.65509
Policy Entropy: 2.02421
Value Function Loss: 1.85613

Mean KL Divergence: 0.00662
SB3 Clip Fraction: 0.07442
Policy Update Magnitude: 0.47299
Value Function Update Magnitude: 0.38528

Collected Steps per Second: 21,933.21584
Overall Steps per Second: 10,652.91982

Timestep Collection Time: 2.28010
Timestep Consumption Time: 2.41438
PPO Batch Consumption Time: 0.28735
Total Iteration Time: 4.69449

Cumulative Model Updates: 1,886
Cumulative Timesteps: 15,855,344

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 782.07594
Policy Entropy: 2.03062
Value Function Loss: 2.01776

Mean KL Divergence: 0.00552
SB3 Clip Fraction: 0.06209
Policy Update Magnitude: 0.50722
Value Function Update Magnitude: 0.31140

Collected Steps per Second: 22,564.06158
Overall Steps per Second: 10,475.48971

Timestep Collection Time: 2.21733
Timestep Consumption Time: 2.55877
PPO Batch Consumption Time: 0.29628
Total Iteration Time: 4.77610

Cumulative Model Updates: 1,892
Cumulative Timesteps: 15,905,376

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 15905376...
Checkpoint 15905376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 717.25451
Policy Entropy: 2.03577
Value Function Loss: 2.03274

Mean KL Divergence: 0.00563
SB3 Clip Fraction: 0.06344
Policy Update Magnitude: 0.53290
Value Function Update Magnitude: 0.28941

Collected Steps per Second: 22,105.81875
Overall Steps per Second: 10,405.81514

Timestep Collection Time: 2.26293
Timestep Consumption Time: 2.54438
PPO Batch Consumption Time: 0.29690
Total Iteration Time: 4.80731

Cumulative Model Updates: 1,898
Cumulative Timesteps: 15,955,400

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 738.85183
Policy Entropy: 2.01853
Value Function Loss: 1.98102

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.12156
Policy Update Magnitude: 0.43925
Value Function Update Magnitude: 0.30582

Collected Steps per Second: 22,417.36756
Overall Steps per Second: 10,630.26110

Timestep Collection Time: 2.23077
Timestep Consumption Time: 2.47354
PPO Batch Consumption Time: 0.28713
Total Iteration Time: 4.70431

Cumulative Model Updates: 1,904
Cumulative Timesteps: 16,005,408

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 16005408...
Checkpoint 16005408 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 586.75369
Policy Entropy: 2.02651
Value Function Loss: 1.90890

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.10901
Policy Update Magnitude: 0.36362
Value Function Update Magnitude: 0.43370

Collected Steps per Second: 21,814.68757
Overall Steps per Second: 10,475.23928

Timestep Collection Time: 2.29323
Timestep Consumption Time: 2.48242
PPO Batch Consumption Time: 0.29796
Total Iteration Time: 4.77564

Cumulative Model Updates: 1,910
Cumulative Timesteps: 16,055,434

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 645.22928
Policy Entropy: 2.00715
Value Function Loss: 1.80451

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.09553
Policy Update Magnitude: 0.36564
Value Function Update Magnitude: 0.41851

Collected Steps per Second: 22,432.38878
Overall Steps per Second: 10,595.67149

Timestep Collection Time: 2.22892
Timestep Consumption Time: 2.48999
PPO Batch Consumption Time: 0.28685
Total Iteration Time: 4.71891

Cumulative Model Updates: 1,916
Cumulative Timesteps: 16,105,434

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 16105434...
Checkpoint 16105434 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 679.88974
Policy Entropy: 2.01759
Value Function Loss: 1.81032

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.08851
Policy Update Magnitude: 0.38824
Value Function Update Magnitude: 0.33983

Collected Steps per Second: 22,067.91138
Overall Steps per Second: 10,369.25362

Timestep Collection Time: 2.26628
Timestep Consumption Time: 2.55683
PPO Batch Consumption Time: 0.30012
Total Iteration Time: 4.82311

Cumulative Model Updates: 1,922
Cumulative Timesteps: 16,155,446

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 604.45128
Policy Entropy: 1.98152
Value Function Loss: 1.83437

Mean KL Divergence: 0.00700
SB3 Clip Fraction: 0.08456
Policy Update Magnitude: 0.48180
Value Function Update Magnitude: 0.30373

Collected Steps per Second: 22,443.63236
Overall Steps per Second: 10,488.33780

Timestep Collection Time: 2.22869
Timestep Consumption Time: 2.54041
PPO Batch Consumption Time: 0.30027
Total Iteration Time: 4.76911

Cumulative Model Updates: 1,928
Cumulative Timesteps: 16,205,466

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 16205466...
Checkpoint 16205466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,084.97294
Policy Entropy: 1.98276
Value Function Loss: 1.77656

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.11966
Policy Update Magnitude: 0.48014
Value Function Update Magnitude: 0.31460

Collected Steps per Second: 21,876.39226
Overall Steps per Second: 10,518.62283

Timestep Collection Time: 2.28630
Timestep Consumption Time: 2.46869
PPO Batch Consumption Time: 0.28696
Total Iteration Time: 4.75500

Cumulative Model Updates: 1,934
Cumulative Timesteps: 16,255,482

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 741.17815
Policy Entropy: 1.99580
Value Function Loss: 1.84466

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.11489
Policy Update Magnitude: 0.37387
Value Function Update Magnitude: 0.32084

Collected Steps per Second: 23,328.21132
Overall Steps per Second: 10,711.70288

Timestep Collection Time: 2.14401
Timestep Consumption Time: 2.52527
PPO Batch Consumption Time: 0.29500
Total Iteration Time: 4.66929

Cumulative Model Updates: 1,940
Cumulative Timesteps: 16,305,498

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 16305498...
Checkpoint 16305498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 563.37177
Policy Entropy: 2.01645
Value Function Loss: 1.78795

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.10543
Policy Update Magnitude: 0.36536
Value Function Update Magnitude: 0.29430

Collected Steps per Second: 22,196.54624
Overall Steps per Second: 10,421.46358

Timestep Collection Time: 2.25260
Timestep Consumption Time: 2.54519
PPO Batch Consumption Time: 0.29747
Total Iteration Time: 4.79779

Cumulative Model Updates: 1,946
Cumulative Timesteps: 16,355,498

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 821.73490
Policy Entropy: 1.99590
Value Function Loss: 1.86490

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.10721
Policy Update Magnitude: 0.39509
Value Function Update Magnitude: 0.31491

Collected Steps per Second: 22,301.90856
Overall Steps per Second: 10,453.12154

Timestep Collection Time: 2.24232
Timestep Consumption Time: 2.54171
PPO Batch Consumption Time: 0.29583
Total Iteration Time: 4.78403

Cumulative Model Updates: 1,952
Cumulative Timesteps: 16,405,506

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 16405506...
Checkpoint 16405506 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 914.37071
Policy Entropy: 1.97903
Value Function Loss: 1.83819

Mean KL Divergence: 0.00728
SB3 Clip Fraction: 0.08696
Policy Update Magnitude: 0.40246
Value Function Update Magnitude: 0.30422

Collected Steps per Second: 21,744.01727
Overall Steps per Second: 10,396.16629

Timestep Collection Time: 2.30077
Timestep Consumption Time: 2.51139
PPO Batch Consumption Time: 0.29623
Total Iteration Time: 4.81216

Cumulative Model Updates: 1,958
Cumulative Timesteps: 16,455,534

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 849.30311
Policy Entropy: 1.96094
Value Function Loss: 1.87798

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.09446
Policy Update Magnitude: 0.40607
Value Function Update Magnitude: 0.30280

Collected Steps per Second: 22,467.80023
Overall Steps per Second: 10,703.48909

Timestep Collection Time: 2.22648
Timestep Consumption Time: 2.44714
PPO Batch Consumption Time: 0.29166
Total Iteration Time: 4.67362

Cumulative Model Updates: 1,964
Cumulative Timesteps: 16,505,558

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 16505558...
Checkpoint 16505558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 721.67738
Policy Entropy: 1.94883
Value Function Loss: 1.85605

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.11596
Policy Update Magnitude: 0.36773
Value Function Update Magnitude: 0.29177

Collected Steps per Second: 22,067.99446
Overall Steps per Second: 10,419.97120

Timestep Collection Time: 2.26699
Timestep Consumption Time: 2.53417
PPO Batch Consumption Time: 0.29580
Total Iteration Time: 4.80116

Cumulative Model Updates: 1,970
Cumulative Timesteps: 16,555,586

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 864.26431
Policy Entropy: 1.94162
Value Function Loss: 1.82637

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.09013
Policy Update Magnitude: 0.33969
Value Function Update Magnitude: 0.31455

Collected Steps per Second: 22,531.66810
Overall Steps per Second: 10,610.73375

Timestep Collection Time: 2.22034
Timestep Consumption Time: 2.49451
PPO Batch Consumption Time: 0.28655
Total Iteration Time: 4.71485

Cumulative Model Updates: 1,976
Cumulative Timesteps: 16,605,614

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 16605614...
Checkpoint 16605614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 676.69194
Policy Entropy: 1.93418
Value Function Loss: 1.79120

Mean KL Divergence: 0.00735
SB3 Clip Fraction: 0.08875
Policy Update Magnitude: 0.38914
Value Function Update Magnitude: 0.33165

Collected Steps per Second: 21,935.00504
Overall Steps per Second: 10,436.66153

Timestep Collection Time: 2.28083
Timestep Consumption Time: 2.51285
PPO Batch Consumption Time: 0.29763
Total Iteration Time: 4.79368

Cumulative Model Updates: 1,982
Cumulative Timesteps: 16,655,644

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 730.59791
Policy Entropy: 1.93462
Value Function Loss: 1.83673

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.10005
Policy Update Magnitude: 0.35259
Value Function Update Magnitude: 0.32903

Collected Steps per Second: 22,692.50893
Overall Steps per Second: 10,578.27673

Timestep Collection Time: 2.20390
Timestep Consumption Time: 2.52390
PPO Batch Consumption Time: 0.30358
Total Iteration Time: 4.72780

Cumulative Model Updates: 1,988
Cumulative Timesteps: 16,705,656

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 16705656...
Checkpoint 16705656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 572.70008
Policy Entropy: 1.93134
Value Function Loss: 1.93267

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.10083
Policy Update Magnitude: 0.31241
Value Function Update Magnitude: 0.31808

Collected Steps per Second: 22,354.35734
Overall Steps per Second: 10,388.67438

Timestep Collection Time: 2.23670
Timestep Consumption Time: 2.57623
PPO Batch Consumption Time: 0.29834
Total Iteration Time: 4.81293

Cumulative Model Updates: 1,994
Cumulative Timesteps: 16,755,656

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 613.18611
Policy Entropy: 1.90060
Value Function Loss: 1.94628

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.09419
Policy Update Magnitude: 0.29900
Value Function Update Magnitude: 0.33256

Collected Steps per Second: 22,213.15114
Overall Steps per Second: 10,446.95252

Timestep Collection Time: 2.25209
Timestep Consumption Time: 2.53648
PPO Batch Consumption Time: 0.29501
Total Iteration Time: 4.78857

Cumulative Model Updates: 2,000
Cumulative Timesteps: 16,805,682

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 16805682...
Checkpoint 16805682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 828.14661
Policy Entropy: 1.89637
Value Function Loss: 1.84571

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.08908
Policy Update Magnitude: 0.30217
Value Function Update Magnitude: 0.48183

Collected Steps per Second: 21,841.51700
Overall Steps per Second: 10,416.71526

Timestep Collection Time: 2.29004
Timestep Consumption Time: 2.51166
PPO Batch Consumption Time: 0.29600
Total Iteration Time: 4.80171

Cumulative Model Updates: 2,006
Cumulative Timesteps: 16,855,700

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 854.03844
Policy Entropy: 1.89274
Value Function Loss: 1.76660

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.08946
Policy Update Magnitude: 0.31003
Value Function Update Magnitude: 0.57185

Collected Steps per Second: 22,682.53099
Overall Steps per Second: 10,713.70617

Timestep Collection Time: 2.20549
Timestep Consumption Time: 2.46386
PPO Batch Consumption Time: 0.29671
Total Iteration Time: 4.66935

Cumulative Model Updates: 2,012
Cumulative Timesteps: 16,905,726

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 16905726...
Checkpoint 16905726 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 860.63954
Policy Entropy: 1.90448
Value Function Loss: 1.80361

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.09917
Policy Update Magnitude: 0.31194
Value Function Update Magnitude: 0.48981

Collected Steps per Second: 21,164.64264
Overall Steps per Second: 10,357.38807

Timestep Collection Time: 2.36338
Timestep Consumption Time: 2.46603
PPO Batch Consumption Time: 0.29741
Total Iteration Time: 4.82940

Cumulative Model Updates: 2,018
Cumulative Timesteps: 16,955,746

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 692.65399
Policy Entropy: 1.88356
Value Function Loss: 1.86629

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.09140
Policy Update Magnitude: 0.30674
Value Function Update Magnitude: 0.37860

Collected Steps per Second: 22,717.38447
Overall Steps per Second: 10,657.65876

Timestep Collection Time: 2.20096
Timestep Consumption Time: 2.49050
PPO Batch Consumption Time: 0.28714
Total Iteration Time: 4.69146

Cumulative Model Updates: 2,024
Cumulative Timesteps: 17,005,746

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 17005746...
Checkpoint 17005746 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 714.00974
Policy Entropy: 1.88952
Value Function Loss: 1.85878

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.09212
Policy Update Magnitude: 0.29193
Value Function Update Magnitude: 0.34136

Collected Steps per Second: 22,240.67634
Overall Steps per Second: 10,457.89203

Timestep Collection Time: 2.24930
Timestep Consumption Time: 2.53426
PPO Batch Consumption Time: 0.29652
Total Iteration Time: 4.78356

Cumulative Model Updates: 2,030
Cumulative Timesteps: 17,055,772

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 670.64864
Policy Entropy: 1.87055
Value Function Loss: 1.86374

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.09289
Policy Update Magnitude: 0.31345
Value Function Update Magnitude: 0.33059

Collected Steps per Second: 22,609.51629
Overall Steps per Second: 10,681.16164

Timestep Collection Time: 2.21208
Timestep Consumption Time: 2.47037
PPO Batch Consumption Time: 0.28645
Total Iteration Time: 4.68245

Cumulative Model Updates: 2,036
Cumulative Timesteps: 17,105,786

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 17105786...
Checkpoint 17105786 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 733.79114
Policy Entropy: 1.87535
Value Function Loss: 1.82211

Mean KL Divergence: 0.00567
SB3 Clip Fraction: 0.06808
Policy Update Magnitude: 0.38026
Value Function Update Magnitude: 0.34498

Collected Steps per Second: 22,143.10227
Overall Steps per Second: 10,747.44245

Timestep Collection Time: 2.25921
Timestep Consumption Time: 2.39548
PPO Batch Consumption Time: 0.28523
Total Iteration Time: 4.65469

Cumulative Model Updates: 2,042
Cumulative Timesteps: 17,155,812

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 630.16653
Policy Entropy: 1.85520
Value Function Loss: 1.83519

Mean KL Divergence: 0.00671
SB3 Clip Fraction: 0.08264
Policy Update Magnitude: 0.43309
Value Function Update Magnitude: 0.35094

Collected Steps per Second: 22,440.51583
Overall Steps per Second: 10,388.37484

Timestep Collection Time: 2.22820
Timestep Consumption Time: 2.58506
PPO Batch Consumption Time: 0.30127
Total Iteration Time: 4.81326

Cumulative Model Updates: 2,048
Cumulative Timesteps: 17,205,814

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 17205814...
Checkpoint 17205814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 793.09461
Policy Entropy: 1.84658
Value Function Loss: 1.77869

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.10391
Policy Update Magnitude: 0.41986
Value Function Update Magnitude: 0.35549

Collected Steps per Second: 22,082.96806
Overall Steps per Second: 10,361.79170

Timestep Collection Time: 2.26473
Timestep Consumption Time: 2.56185
PPO Batch Consumption Time: 0.29862
Total Iteration Time: 4.82658

Cumulative Model Updates: 2,054
Cumulative Timesteps: 17,255,826

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 671.43400
Policy Entropy: 1.85646
Value Function Loss: 1.77963

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.11781
Policy Update Magnitude: 0.34278
Value Function Update Magnitude: 0.35685

Collected Steps per Second: 22,520.09937
Overall Steps per Second: 10,681.83499

Timestep Collection Time: 2.22051
Timestep Consumption Time: 2.46090
PPO Batch Consumption Time: 0.28653
Total Iteration Time: 4.68141

Cumulative Model Updates: 2,060
Cumulative Timesteps: 17,305,832

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 17305832...
Checkpoint 17305832 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 675.08282
Policy Entropy: 1.81708
Value Function Loss: 1.72249

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.09934
Policy Update Magnitude: 0.29098
Value Function Update Magnitude: 0.38597

Collected Steps per Second: 22,346.10813
Overall Steps per Second: 10,585.27979

Timestep Collection Time: 2.23815
Timestep Consumption Time: 2.48671
PPO Batch Consumption Time: 0.30121
Total Iteration Time: 4.72486

Cumulative Model Updates: 2,066
Cumulative Timesteps: 17,355,846

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 652.41236
Policy Entropy: 1.82478
Value Function Loss: 1.71557

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.10801
Policy Update Magnitude: 0.27944
Value Function Update Magnitude: 0.35723

Collected Steps per Second: 22,320.06180
Overall Steps per Second: 10,407.72814

Timestep Collection Time: 2.24067
Timestep Consumption Time: 2.56460
PPO Batch Consumption Time: 0.29439
Total Iteration Time: 4.80528

Cumulative Model Updates: 2,072
Cumulative Timesteps: 17,405,858

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 17405858...
Checkpoint 17405858 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 715.73629
Policy Entropy: 1.80305
Value Function Loss: 1.70955

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.10219
Policy Update Magnitude: 0.32034
Value Function Update Magnitude: 0.33003

Collected Steps per Second: 21,962.49529
Overall Steps per Second: 10,392.21510

Timestep Collection Time: 2.27697
Timestep Consumption Time: 2.53509
PPO Batch Consumption Time: 0.29451
Total Iteration Time: 4.81206

Cumulative Model Updates: 2,078
Cumulative Timesteps: 17,455,866

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 567.33949
Policy Entropy: 1.79499
Value Function Loss: 1.75312

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.11115
Policy Update Magnitude: 0.28785
Value Function Update Magnitude: 0.33063

Collected Steps per Second: 22,094.15672
Overall Steps per Second: 10,459.48512

Timestep Collection Time: 2.26349
Timestep Consumption Time: 2.51781
PPO Batch Consumption Time: 0.29128
Total Iteration Time: 4.78131

Cumulative Model Updates: 2,084
Cumulative Timesteps: 17,505,876

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 17505876...
Checkpoint 17505876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 535.90629
Policy Entropy: 1.77097
Value Function Loss: 1.70133

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.10320
Policy Update Magnitude: 0.25711
Value Function Update Magnitude: 0.32052

Collected Steps per Second: 21,891.60635
Overall Steps per Second: 10,531.94624

Timestep Collection Time: 2.28489
Timestep Consumption Time: 2.46447
PPO Batch Consumption Time: 0.28638
Total Iteration Time: 4.74936

Cumulative Model Updates: 2,090
Cumulative Timesteps: 17,555,896

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 750.38991
Policy Entropy: 1.78410
Value Function Loss: 1.70595

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.09419
Policy Update Magnitude: 0.30637
Value Function Update Magnitude: 0.33995

Collected Steps per Second: 22,240.34115
Overall Steps per Second: 10,544.19833

Timestep Collection Time: 2.24934
Timestep Consumption Time: 2.49507
PPO Batch Consumption Time: 0.30009
Total Iteration Time: 4.74441

Cumulative Model Updates: 2,096
Cumulative Timesteps: 17,605,922

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 17605922...
Checkpoint 17605922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 747.60804
Policy Entropy: 1.76724
Value Function Loss: 1.67361

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.09403
Policy Update Magnitude: 0.31384
Value Function Update Magnitude: 0.31800

Collected Steps per Second: 22,043.81387
Overall Steps per Second: 10,393.74661

Timestep Collection Time: 2.26839
Timestep Consumption Time: 2.54258
PPO Batch Consumption Time: 0.29664
Total Iteration Time: 4.81097

Cumulative Model Updates: 2,102
Cumulative Timesteps: 17,655,926

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 702.38572
Policy Entropy: 1.76446
Value Function Loss: 1.71585

Mean KL Divergence: 0.00711
SB3 Clip Fraction: 0.08558
Policy Update Magnitude: 0.33061
Value Function Update Magnitude: 0.31499

Collected Steps per Second: 22,570.39316
Overall Steps per Second: 10,626.72208

Timestep Collection Time: 2.21609
Timestep Consumption Time: 2.49072
PPO Batch Consumption Time: 0.28655
Total Iteration Time: 4.70681

Cumulative Model Updates: 2,108
Cumulative Timesteps: 17,705,944

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 17705944...
Checkpoint 17705944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 660.37027
Policy Entropy: 1.73637
Value Function Loss: 1.73141

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.11141
Policy Update Magnitude: 0.32943
Value Function Update Magnitude: 0.33369

Collected Steps per Second: 22,055.76937
Overall Steps per Second: 10,481.91266

Timestep Collection Time: 2.26716
Timestep Consumption Time: 2.50334
PPO Batch Consumption Time: 0.29560
Total Iteration Time: 4.77050

Cumulative Model Updates: 2,114
Cumulative Timesteps: 17,755,948

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 686.33250
Policy Entropy: 1.77306
Value Function Loss: 1.73425

Mean KL Divergence: 0.00772
SB3 Clip Fraction: 0.09035
Policy Update Magnitude: 0.29301
Value Function Update Magnitude: 0.34909

Collected Steps per Second: 22,136.15782
Overall Steps per Second: 10,660.89034

Timestep Collection Time: 2.25875
Timestep Consumption Time: 2.43129
PPO Batch Consumption Time: 0.28758
Total Iteration Time: 4.69004

Cumulative Model Updates: 2,120
Cumulative Timesteps: 17,805,948

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 17805948...
Checkpoint 17805948 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 654.84404
Policy Entropy: 1.76569
Value Function Loss: 1.72924

Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.09406
Policy Update Magnitude: 0.28008
Value Function Update Magnitude: 0.33928

Collected Steps per Second: 22,408.79744
Overall Steps per Second: 10,590.42049

Timestep Collection Time: 2.23225
Timestep Consumption Time: 2.49108
PPO Batch Consumption Time: 0.28653
Total Iteration Time: 4.72333

Cumulative Model Updates: 2,126
Cumulative Timesteps: 17,855,970

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 840.42130
Policy Entropy: 1.76175
Value Function Loss: 1.72718

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.09214
Policy Update Magnitude: 0.31062
Value Function Update Magnitude: 0.34608

Collected Steps per Second: 22,483.95091
Overall Steps per Second: 10,547.64612

Timestep Collection Time: 2.22577
Timestep Consumption Time: 2.51880
PPO Batch Consumption Time: 0.28946
Total Iteration Time: 4.74457

Cumulative Model Updates: 2,132
Cumulative Timesteps: 17,906,014

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 17906014...
Checkpoint 17906014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 601.91027
Policy Entropy: 1.74353
Value Function Loss: 1.71485

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.08358
Policy Update Magnitude: 0.35981
Value Function Update Magnitude: 0.35370

Collected Steps per Second: 22,247.28648
Overall Steps per Second: 10,613.59411

Timestep Collection Time: 2.24764
Timestep Consumption Time: 2.46367
PPO Batch Consumption Time: 0.28715
Total Iteration Time: 4.71132

Cumulative Model Updates: 2,138
Cumulative Timesteps: 17,956,018

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 620.65770
Policy Entropy: 1.74412
Value Function Loss: 1.73487

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.08581
Policy Update Magnitude: 0.36450
Value Function Update Magnitude: 0.33960

Collected Steps per Second: 22,429.65179
Overall Steps per Second: 10,539.00979

Timestep Collection Time: 2.23053
Timestep Consumption Time: 2.51660
PPO Batch Consumption Time: 0.30439
Total Iteration Time: 4.74713

Cumulative Model Updates: 2,144
Cumulative Timesteps: 18,006,048

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 18006048...
Checkpoint 18006048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 581.04268
Policy Entropy: 1.74070
Value Function Loss: 1.69655

Mean KL Divergence: 0.00689
SB3 Clip Fraction: 0.07758
Policy Update Magnitude: 0.37025
Value Function Update Magnitude: 0.34637

Collected Steps per Second: 22,160.26514
Overall Steps per Second: 10,470.03875

Timestep Collection Time: 2.25665
Timestep Consumption Time: 2.51964
PPO Batch Consumption Time: 0.28867
Total Iteration Time: 4.77630

Cumulative Model Updates: 2,150
Cumulative Timesteps: 18,056,056

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 822.35164
Policy Entropy: 1.72672
Value Function Loss: 1.73849

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.09512
Policy Update Magnitude: 0.37883
Value Function Update Magnitude: 0.35045

Collected Steps per Second: 22,573.84936
Overall Steps per Second: 10,588.80173

Timestep Collection Time: 2.21584
Timestep Consumption Time: 2.50802
PPO Batch Consumption Time: 0.28952
Total Iteration Time: 4.72386

Cumulative Model Updates: 2,156
Cumulative Timesteps: 18,106,076

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 18106076...
Checkpoint 18106076 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 919.69696
Policy Entropy: 1.71930
Value Function Loss: 1.71092

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.09847
Policy Update Magnitude: 0.37841
Value Function Update Magnitude: 0.34312

Collected Steps per Second: 22,183.78830
Overall Steps per Second: 10,598.80043

Timestep Collection Time: 2.25426
Timestep Consumption Time: 2.46401
PPO Batch Consumption Time: 0.28704
Total Iteration Time: 4.71827

Cumulative Model Updates: 2,162
Cumulative Timesteps: 18,156,084

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 866.06472
Policy Entropy: 1.69127
Value Function Loss: 1.74272

Mean KL Divergence: 0.00672
SB3 Clip Fraction: 0.07943
Policy Update Magnitude: 0.36521
Value Function Update Magnitude: 0.34657

Collected Steps per Second: 22,338.38500
Overall Steps per Second: 10,488.75699

Timestep Collection Time: 2.23919
Timestep Consumption Time: 2.52972
PPO Batch Consumption Time: 0.29606
Total Iteration Time: 4.76892

Cumulative Model Updates: 2,168
Cumulative Timesteps: 18,206,104

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 18206104...
Checkpoint 18206104 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 602.80002
Policy Entropy: 1.67701
Value Function Loss: 1.71970

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.09486
Policy Update Magnitude: 0.33688
Value Function Update Magnitude: 0.32564

Collected Steps per Second: 22,073.07632
Overall Steps per Second: 10,639.54675

Timestep Collection Time: 2.26566
Timestep Consumption Time: 2.43473
PPO Batch Consumption Time: 0.29128
Total Iteration Time: 4.70039

Cumulative Model Updates: 2,174
Cumulative Timesteps: 18,256,114

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 808.09745
Policy Entropy: 1.68052
Value Function Loss: 1.77298

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.10822
Policy Update Magnitude: 0.27095
Value Function Update Magnitude: 0.33459

Collected Steps per Second: 22,323.89587
Overall Steps per Second: 10,465.03029

Timestep Collection Time: 2.24092
Timestep Consumption Time: 2.53938
PPO Batch Consumption Time: 0.29266
Total Iteration Time: 4.78030

Cumulative Model Updates: 2,180
Cumulative Timesteps: 18,306,140

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 18306140...
Checkpoint 18306140 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 644.33775
Policy Entropy: 1.67364
Value Function Loss: 1.75003

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.10523
Policy Update Magnitude: 0.25362
Value Function Update Magnitude: 0.37937

Collected Steps per Second: 22,380.87283
Overall Steps per Second: 10,610.83191

Timestep Collection Time: 2.23521
Timestep Consumption Time: 2.47940
PPO Batch Consumption Time: 0.28779
Total Iteration Time: 4.71462

Cumulative Model Updates: 2,186
Cumulative Timesteps: 18,356,166

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,139.19143
Policy Entropy: 1.67363
Value Function Loss: 1.74218

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.10295
Policy Update Magnitude: 0.27866
Value Function Update Magnitude: 0.48610

Collected Steps per Second: 22,188.49617
Overall Steps per Second: 10,532.51457

Timestep Collection Time: 2.25378
Timestep Consumption Time: 2.49418
PPO Batch Consumption Time: 0.29084
Total Iteration Time: 4.74796

Cumulative Model Updates: 2,192
Cumulative Timesteps: 18,406,174

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 18406174...
Checkpoint 18406174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 889.32067
Policy Entropy: 1.67113
Value Function Loss: 1.71938

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.10472
Policy Update Magnitude: 0.28607
Value Function Update Magnitude: 0.40296

Collected Steps per Second: 22,064.56428
Overall Steps per Second: 10,645.18431

Timestep Collection Time: 2.26707
Timestep Consumption Time: 2.43195
PPO Batch Consumption Time: 0.29066
Total Iteration Time: 4.69903

Cumulative Model Updates: 2,198
Cumulative Timesteps: 18,456,196

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 822.04428
Policy Entropy: 1.66697
Value Function Loss: 1.70656

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.10376
Policy Update Magnitude: 0.28123
Value Function Update Magnitude: 0.34461

Collected Steps per Second: 22,462.87284
Overall Steps per Second: 10,451.31485

Timestep Collection Time: 2.22723
Timestep Consumption Time: 2.55973
PPO Batch Consumption Time: 0.29790
Total Iteration Time: 4.78696

Cumulative Model Updates: 2,204
Cumulative Timesteps: 18,506,226

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 18506226...
Checkpoint 18506226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,120.52751
Policy Entropy: 1.65644
Value Function Loss: 1.69148

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.08894
Policy Update Magnitude: 0.29186
Value Function Update Magnitude: 0.32040

Collected Steps per Second: 22,255.73358
Overall Steps per Second: 10,565.20153

Timestep Collection Time: 2.24733
Timestep Consumption Time: 2.48670
PPO Batch Consumption Time: 0.28670
Total Iteration Time: 4.73403

Cumulative Model Updates: 2,210
Cumulative Timesteps: 18,556,242

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 865.13858
Policy Entropy: 1.66787
Value Function Loss: 1.63776

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.08859
Policy Update Magnitude: 0.30366
Value Function Update Magnitude: 0.30474

Collected Steps per Second: 22,055.82923
Overall Steps per Second: 10,480.59976

Timestep Collection Time: 2.26779
Timestep Consumption Time: 2.50465
PPO Batch Consumption Time: 0.28729
Total Iteration Time: 4.77244

Cumulative Model Updates: 2,216
Cumulative Timesteps: 18,606,260

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 18606260...
Checkpoint 18606260 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 855.55255
Policy Entropy: 1.66385
Value Function Loss: 1.63972

Mean KL Divergence: 0.00770
SB3 Clip Fraction: 0.08522
Policy Update Magnitude: 0.31483
Value Function Update Magnitude: 0.33363

Collected Steps per Second: 21,634.30247
Overall Steps per Second: 10,162.75683

Timestep Collection Time: 2.31309
Timestep Consumption Time: 2.61097
PPO Batch Consumption Time: 0.31238
Total Iteration Time: 4.92406

Cumulative Model Updates: 2,222
Cumulative Timesteps: 18,656,302

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 630.88705
Policy Entropy: 1.66212
Value Function Loss: 1.65356

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.08932
Policy Update Magnitude: 0.31245
Value Function Update Magnitude: 0.36814

Collected Steps per Second: 22,149.06136
Overall Steps per Second: 10,576.18463

Timestep Collection Time: 2.25761
Timestep Consumption Time: 2.47037
PPO Batch Consumption Time: 0.29552
Total Iteration Time: 4.72798

Cumulative Model Updates: 2,228
Cumulative Timesteps: 18,706,306

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 18706306...
Checkpoint 18706306 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,055.56940
Policy Entropy: 1.66838
Value Function Loss: 1.69903

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.11579
Policy Update Magnitude: 0.28154
Value Function Update Magnitude: 0.34329

Collected Steps per Second: 22,327.68157
Overall Steps per Second: 10,577.76991

Timestep Collection Time: 2.23964
Timestep Consumption Time: 2.48782
PPO Batch Consumption Time: 0.28727
Total Iteration Time: 4.72746

Cumulative Model Updates: 2,234
Cumulative Timesteps: 18,756,312

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 580.53259
Policy Entropy: 1.66150
Value Function Loss: 1.71809

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.12330
Policy Update Magnitude: 0.26486
Value Function Update Magnitude: 0.38220

Collected Steps per Second: 22,316.76247
Overall Steps per Second: 10,575.48027

Timestep Collection Time: 2.24119
Timestep Consumption Time: 2.48825
PPO Batch Consumption Time: 0.28653
Total Iteration Time: 4.72943

Cumulative Model Updates: 2,240
Cumulative Timesteps: 18,806,328

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 18806328...
Checkpoint 18806328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 662.64674
Policy Entropy: 1.66629
Value Function Loss: 1.74048

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.09670
Policy Update Magnitude: 0.34215
Value Function Update Magnitude: 0.35090

Collected Steps per Second: 21,970.59632
Overall Steps per Second: 10,548.61595

Timestep Collection Time: 2.27723
Timestep Consumption Time: 2.46577
PPO Batch Consumption Time: 0.28709
Total Iteration Time: 4.74299

Cumulative Model Updates: 2,246
Cumulative Timesteps: 18,856,360

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 791.82512
Policy Entropy: 1.67097
Value Function Loss: 1.68795

Mean KL Divergence: 0.00725
SB3 Clip Fraction: 0.08736
Policy Update Magnitude: 0.38604
Value Function Update Magnitude: 0.35222

Collected Steps per Second: 22,204.69812
Overall Steps per Second: 10,513.79310

Timestep Collection Time: 2.25214
Timestep Consumption Time: 2.50428
PPO Batch Consumption Time: 0.30112
Total Iteration Time: 4.75642

Cumulative Model Updates: 2,252
Cumulative Timesteps: 18,906,368

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 18906368...
Checkpoint 18906368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 510.67140
Policy Entropy: 1.68231
Value Function Loss: 1.71656

Mean KL Divergence: 0.01276
SB3 Clip Fraction: 0.15141
Policy Update Magnitude: 0.33762
Value Function Update Magnitude: 0.33382

Collected Steps per Second: 22,285.26250
Overall Steps per Second: 10,544.59217

Timestep Collection Time: 2.24417
Timestep Consumption Time: 2.49873
PPO Batch Consumption Time: 0.28712
Total Iteration Time: 4.74291

Cumulative Model Updates: 2,258
Cumulative Timesteps: 18,956,380

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 809.70968
Policy Entropy: 1.68574
Value Function Loss: 1.70496

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.10767
Policy Update Magnitude: 0.29899
Value Function Update Magnitude: 0.35408

Collected Steps per Second: 22,315.54109
Overall Steps per Second: 10,527.90134

Timestep Collection Time: 2.24068
Timestep Consumption Time: 2.50879
PPO Batch Consumption Time: 0.28795
Total Iteration Time: 4.74947

Cumulative Model Updates: 2,264
Cumulative Timesteps: 19,006,382

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 19006382...
Checkpoint 19006382 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 630.62203
Policy Entropy: 1.66947
Value Function Loss: 1.76471

Mean KL Divergence: 0.00715
SB3 Clip Fraction: 0.08748
Policy Update Magnitude: 0.30832
Value Function Update Magnitude: 0.35315

Collected Steps per Second: 22,058.15826
Overall Steps per Second: 10,388.24606

Timestep Collection Time: 2.26800
Timestep Consumption Time: 2.54782
PPO Batch Consumption Time: 0.29715
Total Iteration Time: 4.81583

Cumulative Model Updates: 2,270
Cumulative Timesteps: 19,056,410

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 726.62729
Policy Entropy: 1.66518
Value Function Loss: 1.70989

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.12054
Policy Update Magnitude: 0.29350
Value Function Update Magnitude: 0.39725

Collected Steps per Second: 22,240.70871
Overall Steps per Second: 10,448.54225

Timestep Collection Time: 2.24849
Timestep Consumption Time: 2.53763
PPO Batch Consumption Time: 0.29783
Total Iteration Time: 4.78612

Cumulative Model Updates: 2,276
Cumulative Timesteps: 19,106,418

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 19106418...
Checkpoint 19106418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 754.65433
Policy Entropy: 1.66185
Value Function Loss: 1.64213

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.11463
Policy Update Magnitude: 0.26583
Value Function Update Magnitude: 0.45105

Collected Steps per Second: 22,305.16036
Overall Steps per Second: 10,606.37261

Timestep Collection Time: 2.24199
Timestep Consumption Time: 2.47291
PPO Batch Consumption Time: 0.29933
Total Iteration Time: 4.71490

Cumulative Model Updates: 2,282
Cumulative Timesteps: 19,156,426

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 843.93310
Policy Entropy: 1.66331
Value Function Loss: 1.63206

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.10531
Policy Update Magnitude: 0.28103
Value Function Update Magnitude: 0.35948

Collected Steps per Second: 22,403.16767
Overall Steps per Second: 10,443.25752

Timestep Collection Time: 2.23397
Timestep Consumption Time: 2.55840
PPO Batch Consumption Time: 0.30020
Total Iteration Time: 4.79237

Cumulative Model Updates: 2,288
Cumulative Timesteps: 19,206,474

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 19206474...
Checkpoint 19206474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 659.09849
Policy Entropy: 1.65387
Value Function Loss: 1.62026

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.09578
Policy Update Magnitude: 0.30773
Value Function Update Magnitude: 0.32165

Collected Steps per Second: 22,052.68213
Overall Steps per Second: 10,473.32451

Timestep Collection Time: 2.26848
Timestep Consumption Time: 2.50804
PPO Batch Consumption Time: 0.28695
Total Iteration Time: 4.77652

Cumulative Model Updates: 2,294
Cumulative Timesteps: 19,256,500

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 919.75102
Policy Entropy: 1.63475
Value Function Loss: 1.66012

Mean KL Divergence: 0.00716
SB3 Clip Fraction: 0.07952
Policy Update Magnitude: 0.36394
Value Function Update Magnitude: 0.32835

Collected Steps per Second: 21,808.37825
Overall Steps per Second: 10,369.80266

Timestep Collection Time: 2.29334
Timestep Consumption Time: 2.52970
PPO Batch Consumption Time: 0.29350
Total Iteration Time: 4.82304

Cumulative Model Updates: 2,300
Cumulative Timesteps: 19,306,514

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 19306514...
Checkpoint 19306514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 539.41545
Policy Entropy: 1.63537
Value Function Loss: 1.63232

Mean KL Divergence: 0.00683
SB3 Clip Fraction: 0.07925
Policy Update Magnitude: 0.35999
Value Function Update Magnitude: 0.41825

Collected Steps per Second: 22,109.32567
Overall Steps per Second: 10,410.92085

Timestep Collection Time: 2.26248
Timestep Consumption Time: 2.54228
PPO Batch Consumption Time: 0.30068
Total Iteration Time: 4.80476

Cumulative Model Updates: 2,306
Cumulative Timesteps: 19,356,536

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 964.85422
Policy Entropy: 1.63905
Value Function Loss: 1.58817

Mean KL Divergence: 0.00739
SB3 Clip Fraction: 0.08205
Policy Update Magnitude: 0.35785
Value Function Update Magnitude: 0.39809

Collected Steps per Second: 22,444.86906
Overall Steps per Second: 10,769.57923

Timestep Collection Time: 2.22857
Timestep Consumption Time: 2.41599
PPO Batch Consumption Time: 0.28719
Total Iteration Time: 4.64456

Cumulative Model Updates: 2,312
Cumulative Timesteps: 19,406,556

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 19406556...
Checkpoint 19406556 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 855.95475
Policy Entropy: 1.64008
Value Function Loss: 1.60661

Mean KL Divergence: 0.00746
SB3 Clip Fraction: 0.08692
Policy Update Magnitude: 0.35308
Value Function Update Magnitude: 0.37484

Collected Steps per Second: 22,251.96251
Overall Steps per Second: 10,427.70112

Timestep Collection Time: 2.24708
Timestep Consumption Time: 2.54803
PPO Batch Consumption Time: 0.29727
Total Iteration Time: 4.79511

Cumulative Model Updates: 2,318
Cumulative Timesteps: 19,456,558

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 917.48299
Policy Entropy: 1.62935
Value Function Loss: 1.55181

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.09860
Policy Update Magnitude: 0.33076
Value Function Update Magnitude: 0.38176

Collected Steps per Second: 22,436.74559
Overall Steps per Second: 10,446.23398

Timestep Collection Time: 2.22920
Timestep Consumption Time: 2.55875
PPO Batch Consumption Time: 0.29896
Total Iteration Time: 4.78795

Cumulative Model Updates: 2,324
Cumulative Timesteps: 19,506,574

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 19506574...
Checkpoint 19506574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 862.15042
Policy Entropy: 1.62354
Value Function Loss: 1.51401

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.10930
Policy Update Magnitude: 0.28828
Value Function Update Magnitude: 0.46938

Collected Steps per Second: 21,303.60520
Overall Steps per Second: 10,180.05616

Timestep Collection Time: 2.34843
Timestep Consumption Time: 2.56608
PPO Batch Consumption Time: 0.30075
Total Iteration Time: 4.91451

Cumulative Model Updates: 2,330
Cumulative Timesteps: 19,556,604

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 642.27344
Policy Entropy: 1.61529
Value Function Loss: 1.54174

Mean KL Divergence: 0.01073
SB3 Clip Fraction: 0.11779
Policy Update Magnitude: 0.26473
Value Function Update Magnitude: 0.42766

Collected Steps per Second: 22,523.42926
Overall Steps per Second: 10,522.41289

Timestep Collection Time: 2.22062
Timestep Consumption Time: 2.53266
PPO Batch Consumption Time: 0.29734
Total Iteration Time: 4.75328

Cumulative Model Updates: 2,336
Cumulative Timesteps: 19,606,620

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 19606620...
Checkpoint 19606620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 800.25826
Policy Entropy: 1.61643
Value Function Loss: 1.52762

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.10824
Policy Update Magnitude: 0.27058
Value Function Update Magnitude: 0.39097

Collected Steps per Second: 22,162.00397
Overall Steps per Second: 10,530.73902

Timestep Collection Time: 2.25720
Timestep Consumption Time: 2.49309
PPO Batch Consumption Time: 0.30138
Total Iteration Time: 4.75028

Cumulative Model Updates: 2,342
Cumulative Timesteps: 19,656,644

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,731.92284
Policy Entropy: 1.59807
Value Function Loss: 1.60871

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.09578
Policy Update Magnitude: 0.29829
Value Function Update Magnitude: 0.35674

Collected Steps per Second: 22,598.06451
Overall Steps per Second: 10,461.15848

Timestep Collection Time: 2.21346
Timestep Consumption Time: 2.56803
PPO Batch Consumption Time: 0.30017
Total Iteration Time: 4.78150

Cumulative Model Updates: 2,348
Cumulative Timesteps: 19,706,664

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 19706664...
Checkpoint 19706664 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 776.28863
Policy Entropy: 1.60155
Value Function Loss: 1.57350

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.09230
Policy Update Magnitude: 0.30246
Value Function Update Magnitude: 0.34985

Collected Steps per Second: 21,966.11288
Overall Steps per Second: 10,511.91699

Timestep Collection Time: 2.27751
Timestep Consumption Time: 2.48166
PPO Batch Consumption Time: 0.28606
Total Iteration Time: 4.75917

Cumulative Model Updates: 2,354
Cumulative Timesteps: 19,756,692

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 664.27487
Policy Entropy: 1.56630
Value Function Loss: 1.59101

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.09149
Policy Update Magnitude: 0.31596
Value Function Update Magnitude: 0.34063

Collected Steps per Second: 22,368.04724
Overall Steps per Second: 10,579.03190

Timestep Collection Time: 2.23551
Timestep Consumption Time: 2.49120
PPO Batch Consumption Time: 0.29141
Total Iteration Time: 4.72671

Cumulative Model Updates: 2,360
Cumulative Timesteps: 19,806,696

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 19806696...
Checkpoint 19806696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 957.91760
Policy Entropy: 1.55417
Value Function Loss: 1.50572

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.10703
Policy Update Magnitude: 0.30589
Value Function Update Magnitude: 0.41487

Collected Steps per Second: 22,130.26383
Overall Steps per Second: 10,564.82735

Timestep Collection Time: 2.26170
Timestep Consumption Time: 2.47591
PPO Batch Consumption Time: 0.28711
Total Iteration Time: 4.73761

Cumulative Model Updates: 2,366
Cumulative Timesteps: 19,856,748

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,178.15713
Policy Entropy: 1.56889
Value Function Loss: 1.54623

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.12042
Policy Update Magnitude: 0.29469
Value Function Update Magnitude: 0.45006

Collected Steps per Second: 22,270.39729
Overall Steps per Second: 10,584.05367

Timestep Collection Time: 2.24639
Timestep Consumption Time: 2.48034
PPO Batch Consumption Time: 0.30017
Total Iteration Time: 4.72673

Cumulative Model Updates: 2,372
Cumulative Timesteps: 19,906,776

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 19906776...
Checkpoint 19906776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 688.72155
Policy Entropy: 1.57567
Value Function Loss: 1.59348

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.11016
Policy Update Magnitude: 0.28066
Value Function Update Magnitude: 0.36109

Collected Steps per Second: 21,537.08727
Overall Steps per Second: 10,259.91252

Timestep Collection Time: 2.32158
Timestep Consumption Time: 2.55176
PPO Batch Consumption Time: 0.30083
Total Iteration Time: 4.87334

Cumulative Model Updates: 2,378
Cumulative Timesteps: 19,956,776

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,180.26631
Policy Entropy: 1.57341
Value Function Loss: 1.59238

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.10311
Policy Update Magnitude: 0.30013
Value Function Update Magnitude: 0.35994

Collected Steps per Second: 22,159.75631
Overall Steps per Second: 10,355.16352

Timestep Collection Time: 2.25752
Timestep Consumption Time: 2.57350
PPO Batch Consumption Time: 0.29978
Total Iteration Time: 4.83102

Cumulative Model Updates: 2,384
Cumulative Timesteps: 20,006,802

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 20006802...
Checkpoint 20006802 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 731.49468
Policy Entropy: 1.58389
Value Function Loss: 1.63895

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.10091
Policy Update Magnitude: 0.27773
Value Function Update Magnitude: 0.37808

Collected Steps per Second: 21,945.96831
Overall Steps per Second: 10,529.14812

Timestep Collection Time: 2.27860
Timestep Consumption Time: 2.47070
PPO Batch Consumption Time: 0.28656
Total Iteration Time: 4.74929

Cumulative Model Updates: 2,390
Cumulative Timesteps: 20,056,808

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 731.24822
Policy Entropy: 1.59167
Value Function Loss: 1.58030

Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.09256
Policy Update Magnitude: 0.26378
Value Function Update Magnitude: 0.34731

Collected Steps per Second: 22,468.35150
Overall Steps per Second: 10,668.24047

Timestep Collection Time: 2.22660
Timestep Consumption Time: 2.46283
PPO Batch Consumption Time: 0.29915
Total Iteration Time: 4.68943

Cumulative Model Updates: 2,396
Cumulative Timesteps: 20,106,836

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 20106836...
Checkpoint 20106836 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 830.44726
Policy Entropy: 1.59599
Value Function Loss: 1.57036

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.09869
Policy Update Magnitude: 0.25287
Value Function Update Magnitude: 0.44737

Collected Steps per Second: 22,151.52793
Overall Steps per Second: 10,506.46090

Timestep Collection Time: 2.25817
Timestep Consumption Time: 2.50290
PPO Batch Consumption Time: 0.28713
Total Iteration Time: 4.76107

Cumulative Model Updates: 2,402
Cumulative Timesteps: 20,156,858

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 661.82532
Policy Entropy: 1.56659
Value Function Loss: 1.57895

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.09312
Policy Update Magnitude: 0.25319
Value Function Update Magnitude: 0.39963

Collected Steps per Second: 22,563.62395
Overall Steps per Second: 10,463.29778

Timestep Collection Time: 2.21667
Timestep Consumption Time: 2.56347
PPO Batch Consumption Time: 0.29758
Total Iteration Time: 4.78014

Cumulative Model Updates: 2,408
Cumulative Timesteps: 20,206,874

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 20206874...
Checkpoint 20206874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 870.60342
Policy Entropy: 1.56337
Value Function Loss: 1.54806

Mean KL Divergence: 0.00637
SB3 Clip Fraction: 0.07516
Policy Update Magnitude: 0.29474
Value Function Update Magnitude: 0.37431

Collected Steps per Second: 22,074.59825
Overall Steps per Second: 10,400.09292

Timestep Collection Time: 2.26577
Timestep Consumption Time: 2.54342
PPO Batch Consumption Time: 0.29594
Total Iteration Time: 4.80919

Cumulative Model Updates: 2,414
Cumulative Timesteps: 20,256,890

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 856.98873
Policy Entropy: 1.55974
Value Function Loss: 1.58528

Mean KL Divergence: 0.00751
SB3 Clip Fraction: 0.08556
Policy Update Magnitude: 0.29758
Value Function Update Magnitude: 0.40048

Collected Steps per Second: 22,490.46778
Overall Steps per Second: 10,640.21143

Timestep Collection Time: 2.22459
Timestep Consumption Time: 2.47758
PPO Batch Consumption Time: 0.28748
Total Iteration Time: 4.70216

Cumulative Model Updates: 2,420
Cumulative Timesteps: 20,306,922

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 20306922...
Checkpoint 20306922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 701.20410
Policy Entropy: 1.57047
Value Function Loss: 1.56421

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.11475
Policy Update Magnitude: 0.27140
Value Function Update Magnitude: 0.37873

Collected Steps per Second: 21,951.32455
Overall Steps per Second: 10,658.18763

Timestep Collection Time: 2.27795
Timestep Consumption Time: 2.41366
PPO Batch Consumption Time: 0.28662
Total Iteration Time: 4.69160

Cumulative Model Updates: 2,426
Cumulative Timesteps: 20,356,926

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 734.49554
Policy Entropy: 1.56596
Value Function Loss: 1.69827

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.09969
Policy Update Magnitude: 0.26692
Value Function Update Magnitude: 0.33480

Collected Steps per Second: 22,520.21793
Overall Steps per Second: 10,518.91676

Timestep Collection Time: 2.22138
Timestep Consumption Time: 2.53443
PPO Batch Consumption Time: 0.29411
Total Iteration Time: 4.75581

Cumulative Model Updates: 2,432
Cumulative Timesteps: 20,406,952

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 20406952...
Checkpoint 20406952 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 740.00589
Policy Entropy: 1.57305
Value Function Loss: 1.55687

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.09434
Policy Update Magnitude: 0.29265
Value Function Update Magnitude: 0.29267

Collected Steps per Second: 22,107.69941
Overall Steps per Second: 10,525.41448

Timestep Collection Time: 2.26193
Timestep Consumption Time: 2.48905
PPO Batch Consumption Time: 0.28684
Total Iteration Time: 4.75098

Cumulative Model Updates: 2,438
Cumulative Timesteps: 20,456,958

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 601.97664
Policy Entropy: 1.56808
Value Function Loss: 1.60618

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.10683
Policy Update Magnitude: 0.31361
Value Function Update Magnitude: 0.29512

Collected Steps per Second: 22,466.93402
Overall Steps per Second: 10,592.02340

Timestep Collection Time: 2.22683
Timestep Consumption Time: 2.49654
PPO Batch Consumption Time: 0.29363
Total Iteration Time: 4.72337

Cumulative Model Updates: 2,444
Cumulative Timesteps: 20,506,988

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 20506988...
Checkpoint 20506988 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 726.74806
Policy Entropy: 1.55359
Value Function Loss: 1.58017

Mean KL Divergence: 0.01241
SB3 Clip Fraction: 0.14171
Policy Update Magnitude: 0.27495
Value Function Update Magnitude: 0.30770

Collected Steps per Second: 21,867.13030
Overall Steps per Second: 10,667.39483

Timestep Collection Time: 2.28745
Timestep Consumption Time: 2.40160
PPO Batch Consumption Time: 0.28549
Total Iteration Time: 4.68905

Cumulative Model Updates: 2,450
Cumulative Timesteps: 20,557,008

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 818.66799
Policy Entropy: 1.56043
Value Function Loss: 1.62852

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.09861
Policy Update Magnitude: 0.26358
Value Function Update Magnitude: 0.31670

Collected Steps per Second: 21,692.07369
Overall Steps per Second: 10,431.08593

Timestep Collection Time: 2.30582
Timestep Consumption Time: 2.48927
PPO Batch Consumption Time: 0.30045
Total Iteration Time: 4.79509

Cumulative Model Updates: 2,456
Cumulative Timesteps: 20,607,026

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 20607026...
Checkpoint 20607026 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 635.28587
Policy Entropy: 1.56141
Value Function Loss: 1.57945

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.10973
Policy Update Magnitude: 0.25840
Value Function Update Magnitude: 0.34379

Collected Steps per Second: 21,933.05595
Overall Steps per Second: 10,440.13404

Timestep Collection Time: 2.28094
Timestep Consumption Time: 2.51095
PPO Batch Consumption Time: 0.29293
Total Iteration Time: 4.79189

Cumulative Model Updates: 2,462
Cumulative Timesteps: 20,657,054

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 834.72719
Policy Entropy: 1.53644
Value Function Loss: 1.58292

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.09722
Policy Update Magnitude: 0.24533
Value Function Update Magnitude: 0.36283

Collected Steps per Second: 22,671.86244
Overall Steps per Second: 10,666.17117

Timestep Collection Time: 2.20582
Timestep Consumption Time: 2.48284
PPO Batch Consumption Time: 0.28553
Total Iteration Time: 4.68866

Cumulative Model Updates: 2,468
Cumulative Timesteps: 20,707,064

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 20707064...
Checkpoint 20707064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 622.10428
Policy Entropy: 1.54421
Value Function Loss: 1.56272

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.08767
Policy Update Magnitude: 0.26790
Value Function Update Magnitude: 0.35475

Collected Steps per Second: 21,976.47127
Overall Steps per Second: 10,555.30657

Timestep Collection Time: 2.27616
Timestep Consumption Time: 2.46288
PPO Batch Consumption Time: 0.28596
Total Iteration Time: 4.73904

Cumulative Model Updates: 2,474
Cumulative Timesteps: 20,757,086

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 828.29579
Policy Entropy: 1.55182
Value Function Loss: 1.59588

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.10017
Policy Update Magnitude: 0.28392
Value Function Update Magnitude: 0.32534

Collected Steps per Second: 22,311.39326
Overall Steps per Second: 10,597.92271

Timestep Collection Time: 2.24208
Timestep Consumption Time: 2.47809
PPO Batch Consumption Time: 0.30049
Total Iteration Time: 4.72017

Cumulative Model Updates: 2,480
Cumulative Timesteps: 20,807,110

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 20807110...
Checkpoint 20807110 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,410.17963
Policy Entropy: 1.55251
Value Function Loss: 1.60782

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.10343
Policy Update Magnitude: 0.28516
Value Function Update Magnitude: 0.31688

Collected Steps per Second: 22,332.66892
Overall Steps per Second: 10,600.40971

Timestep Collection Time: 2.24022
Timestep Consumption Time: 2.47941
PPO Batch Consumption Time: 0.28593
Total Iteration Time: 4.71963

Cumulative Model Updates: 2,486
Cumulative Timesteps: 20,857,140

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,002.57453
Policy Entropy: 1.54877
Value Function Loss: 1.59972

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.09048
Policy Update Magnitude: 0.29330
Value Function Update Magnitude: 0.41434

Collected Steps per Second: 22,191.51081
Overall Steps per Second: 10,450.37988

Timestep Collection Time: 2.25483
Timestep Consumption Time: 2.53333
PPO Batch Consumption Time: 0.29224
Total Iteration Time: 4.78815

Cumulative Model Updates: 2,492
Cumulative Timesteps: 20,907,178

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 20907178...
Checkpoint 20907178 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 709.80035
Policy Entropy: 1.53796
Value Function Loss: 1.53968

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.09324
Policy Update Magnitude: 0.31422
Value Function Update Magnitude: 0.51531

Collected Steps per Second: 21,544.53089
Overall Steps per Second: 10,335.48959

Timestep Collection Time: 2.32198
Timestep Consumption Time: 2.51823
PPO Batch Consumption Time: 0.29824
Total Iteration Time: 4.84022

Cumulative Model Updates: 2,498
Cumulative Timesteps: 20,957,204

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,080.11838
Policy Entropy: 1.52662
Value Function Loss: 1.50464

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.08814
Policy Update Magnitude: 0.27862
Value Function Update Magnitude: 0.52010

Collected Steps per Second: 22,510.75565
Overall Steps per Second: 10,666.44832

Timestep Collection Time: 2.22223
Timestep Consumption Time: 2.46762
PPO Batch Consumption Time: 0.28622
Total Iteration Time: 4.68985

Cumulative Model Updates: 2,504
Cumulative Timesteps: 21,007,228

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 21007228...
Checkpoint 21007228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 731.74017
Policy Entropy: 1.53392
Value Function Loss: 1.63351

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.08489
Policy Update Magnitude: 0.27028
Value Function Update Magnitude: 0.39394

Collected Steps per Second: 21,937.88160
Overall Steps per Second: 10,680.16902

Timestep Collection Time: 2.27953
Timestep Consumption Time: 2.40280
PPO Batch Consumption Time: 0.28682
Total Iteration Time: 4.68232

Cumulative Model Updates: 2,510
Cumulative Timesteps: 21,057,236

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,128.91349
Policy Entropy: 1.52085
Value Function Loss: 1.66586

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.08720
Policy Update Magnitude: 0.27544
Value Function Update Magnitude: 0.29821

Collected Steps per Second: 22,435.34438
Overall Steps per Second: 10,527.48653

Timestep Collection Time: 2.22889
Timestep Consumption Time: 2.52115
PPO Batch Consumption Time: 0.29166
Total Iteration Time: 4.75004

Cumulative Model Updates: 2,516
Cumulative Timesteps: 21,107,242

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 21107242...
Checkpoint 21107242 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 920.45935
Policy Entropy: 1.53325
Value Function Loss: 1.71724

Mean KL Divergence: 0.00748
SB3 Clip Fraction: 0.08196
Policy Update Magnitude: 0.29222
Value Function Update Magnitude: 0.24374

Collected Steps per Second: 21,617.58938
Overall Steps per Second: 10,258.24764

Timestep Collection Time: 2.31432
Timestep Consumption Time: 2.56273
PPO Batch Consumption Time: 0.29976
Total Iteration Time: 4.87705

Cumulative Model Updates: 2,522
Cumulative Timesteps: 21,157,272

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 662.56146
Policy Entropy: 1.52337
Value Function Loss: 1.69178

Mean KL Divergence: 0.00578
SB3 Clip Fraction: 0.06830
Policy Update Magnitude: 0.36648
Value Function Update Magnitude: 0.22887

Collected Steps per Second: 22,330.24491
Overall Steps per Second: 10,377.70923

Timestep Collection Time: 2.23965
Timestep Consumption Time: 2.57952
PPO Batch Consumption Time: 0.29805
Total Iteration Time: 4.81918

Cumulative Model Updates: 2,528
Cumulative Timesteps: 21,207,284

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 21207284...
Checkpoint 21207284 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 666.01300
Policy Entropy: 1.51446
Value Function Loss: 1.68880

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.11361
Policy Update Magnitude: 0.34731
Value Function Update Magnitude: 0.23234

Collected Steps per Second: 21,924.17563
Overall Steps per Second: 10,536.20125

Timestep Collection Time: 2.28113
Timestep Consumption Time: 2.46555
PPO Batch Consumption Time: 0.28610
Total Iteration Time: 4.74668

Cumulative Model Updates: 2,534
Cumulative Timesteps: 21,257,296

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 759.22967
Policy Entropy: 1.52062
Value Function Loss: 1.66791

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.08996
Policy Update Magnitude: 0.31188
Value Function Update Magnitude: 0.22165

Collected Steps per Second: 21,684.21498
Overall Steps per Second: 10,571.72231

Timestep Collection Time: 2.30647
Timestep Consumption Time: 2.42445
PPO Batch Consumption Time: 0.28817
Total Iteration Time: 4.73092

Cumulative Model Updates: 2,540
Cumulative Timesteps: 21,307,310

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 21307310...
Checkpoint 21307310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,079.01963
Policy Entropy: 1.49870
Value Function Loss: 1.65345

Mean KL Divergence: 0.00746
SB3 Clip Fraction: 0.08391
Policy Update Magnitude: 0.32059
Value Function Update Magnitude: 0.22027

Collected Steps per Second: 22,256.23123
Overall Steps per Second: 10,528.56544

Timestep Collection Time: 2.24692
Timestep Consumption Time: 2.50282
PPO Batch Consumption Time: 0.28660
Total Iteration Time: 4.74974

Cumulative Model Updates: 2,546
Cumulative Timesteps: 21,357,318

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,097.24848
Policy Entropy: 1.50957
Value Function Loss: 1.67154

Mean KL Divergence: 0.00628
SB3 Clip Fraction: 0.07277
Policy Update Magnitude: 0.39642
Value Function Update Magnitude: 0.24039

Collected Steps per Second: 22,436.56484
Overall Steps per Second: 10,587.15429

Timestep Collection Time: 2.22975
Timestep Consumption Time: 2.49560
PPO Batch Consumption Time: 0.28635
Total Iteration Time: 4.72535

Cumulative Model Updates: 2,552
Cumulative Timesteps: 21,407,346

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 21407346...
Checkpoint 21407346 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 490.44359
Policy Entropy: 1.49482
Value Function Loss: 1.71204

Mean KL Divergence: 0.00528
SB3 Clip Fraction: 0.06122
Policy Update Magnitude: 0.41814
Value Function Update Magnitude: 0.22570

Collected Steps per Second: 22,195.12079
Overall Steps per Second: 10,535.34161

Timestep Collection Time: 2.25302
Timestep Consumption Time: 2.49348
PPO Batch Consumption Time: 0.28716
Total Iteration Time: 4.74650

Cumulative Model Updates: 2,558
Cumulative Timesteps: 21,457,352

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 524.49451
Policy Entropy: 1.50269
Value Function Loss: 1.74093

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.09770
Policy Update Magnitude: 0.36751
Value Function Update Magnitude: 0.22224

Collected Steps per Second: 22,358.26990
Overall Steps per Second: 10,549.87110

Timestep Collection Time: 2.23667
Timestep Consumption Time: 2.50349
PPO Batch Consumption Time: 0.29296
Total Iteration Time: 4.74015

Cumulative Model Updates: 2,564
Cumulative Timesteps: 21,507,360

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 21507360...
Checkpoint 21507360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 775.20773
Policy Entropy: 1.49706
Value Function Loss: 1.69672

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.09866
Policy Update Magnitude: 0.30265
Value Function Update Magnitude: 0.21996

Collected Steps per Second: 21,859.94543
Overall Steps per Second: 10,673.82545

Timestep Collection Time: 2.28857
Timestep Consumption Time: 2.39841
PPO Batch Consumption Time: 0.28556
Total Iteration Time: 4.68698

Cumulative Model Updates: 2,570
Cumulative Timesteps: 21,557,388

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,095.84282
Policy Entropy: 1.51739
Value Function Loss: 1.67919

Mean KL Divergence: 0.00724
SB3 Clip Fraction: 0.08468
Policy Update Magnitude: 0.32315
Value Function Update Magnitude: 0.23682

Collected Steps per Second: 22,490.88660
Overall Steps per Second: 10,395.28222

Timestep Collection Time: 2.22357
Timestep Consumption Time: 2.58727
PPO Batch Consumption Time: 0.30109
Total Iteration Time: 4.81084

Cumulative Model Updates: 2,576
Cumulative Timesteps: 21,607,398

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 21607398...
Checkpoint 21607398 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 811.43307
Policy Entropy: 1.50041
Value Function Loss: 1.69552

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.10869
Policy Update Magnitude: 0.35910
Value Function Update Magnitude: 0.22597

Collected Steps per Second: 22,330.28459
Overall Steps per Second: 10,566.27750

Timestep Collection Time: 2.24046
Timestep Consumption Time: 2.49442
PPO Batch Consumption Time: 0.28690
Total Iteration Time: 4.73487

Cumulative Model Updates: 2,582
Cumulative Timesteps: 21,657,428

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 691.67609
Policy Entropy: 1.51929
Value Function Loss: 1.72722

Mean KL Divergence: 0.01178
SB3 Clip Fraction: 0.13917
Policy Update Magnitude: 0.33442
Value Function Update Magnitude: 0.22004

Collected Steps per Second: 22,167.84961
Overall Steps per Second: 10,604.39295

Timestep Collection Time: 2.25669
Timestep Consumption Time: 2.46079
PPO Batch Consumption Time: 0.28576
Total Iteration Time: 4.71748

Cumulative Model Updates: 2,588
Cumulative Timesteps: 21,707,454

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 21707454...
Checkpoint 21707454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 585.95898
Policy Entropy: 1.50259
Value Function Loss: 1.70255

Mean KL Divergence: 0.01120
SB3 Clip Fraction: 0.12597
Policy Update Magnitude: 0.32217
Value Function Update Magnitude: 0.22120

Collected Steps per Second: 22,294.80297
Overall Steps per Second: 10,645.26293

Timestep Collection Time: 2.24366
Timestep Consumption Time: 2.45533
PPO Batch Consumption Time: 0.28548
Total Iteration Time: 4.69899

Cumulative Model Updates: 2,594
Cumulative Timesteps: 21,757,476

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 703.66051
Policy Entropy: 1.52794
Value Function Loss: 1.70622

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.10828
Policy Update Magnitude: 0.27605
Value Function Update Magnitude: 0.22799

Collected Steps per Second: 22,022.45522
Overall Steps per Second: 10,521.61913

Timestep Collection Time: 2.27050
Timestep Consumption Time: 2.48181
PPO Batch Consumption Time: 0.29858
Total Iteration Time: 4.75231

Cumulative Model Updates: 2,600
Cumulative Timesteps: 21,807,478

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 21807478...
Checkpoint 21807478 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 797.87080
Policy Entropy: 1.51361
Value Function Loss: 1.67321

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.10434
Policy Update Magnitude: 0.27002
Value Function Update Magnitude: 0.24451

Collected Steps per Second: 22,193.95619
Overall Steps per Second: 10,512.06997

Timestep Collection Time: 2.25422
Timestep Consumption Time: 2.50507
PPO Batch Consumption Time: 0.28917
Total Iteration Time: 4.75929

Cumulative Model Updates: 2,606
Cumulative Timesteps: 21,857,508

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 797.06942
Policy Entropy: 1.52246
Value Function Loss: 1.70588

Mean KL Divergence: 0.00702
SB3 Clip Fraction: 0.08240
Policy Update Magnitude: 0.30658
Value Function Update Magnitude: 0.25453

Collected Steps per Second: 22,148.58257
Overall Steps per Second: 10,348.33490

Timestep Collection Time: 2.25802
Timestep Consumption Time: 2.57483
PPO Batch Consumption Time: 0.29275
Total Iteration Time: 4.83285

Cumulative Model Updates: 2,612
Cumulative Timesteps: 21,907,520

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 21907520...
Checkpoint 21907520 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 838.28837
Policy Entropy: 1.51731
Value Function Loss: 1.71978

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.09654
Policy Update Magnitude: 0.35189
Value Function Update Magnitude: 0.28674

Collected Steps per Second: 22,036.40253
Overall Steps per Second: 10,356.55072

Timestep Collection Time: 2.27006
Timestep Consumption Time: 2.56012
PPO Batch Consumption Time: 0.30111
Total Iteration Time: 4.83018

Cumulative Model Updates: 2,618
Cumulative Timesteps: 21,957,544

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,169.01023
Policy Entropy: 1.52649
Value Function Loss: 1.74585

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.11032
Policy Update Magnitude: 0.29597
Value Function Update Magnitude: 0.26393

Collected Steps per Second: 22,377.53500
Overall Steps per Second: 10,462.81302

Timestep Collection Time: 2.23447
Timestep Consumption Time: 2.54455
PPO Batch Consumption Time: 0.30122
Total Iteration Time: 4.77902

Cumulative Model Updates: 2,624
Cumulative Timesteps: 22,007,546

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 22007546...
Checkpoint 22007546 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 756.10082
Policy Entropy: 1.53026
Value Function Loss: 1.71211

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.09495
Policy Update Magnitude: 0.26358
Value Function Update Magnitude: 0.25048

Collected Steps per Second: 22,431.45851
Overall Steps per Second: 10,587.05464

Timestep Collection Time: 2.22955
Timestep Consumption Time: 2.49433
PPO Batch Consumption Time: 0.29111
Total Iteration Time: 4.72388

Cumulative Model Updates: 2,630
Cumulative Timesteps: 22,057,558

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 976.72994
Policy Entropy: 1.52890
Value Function Loss: 1.67109

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.09929
Policy Update Magnitude: 0.26260
Value Function Update Magnitude: 0.25764

Collected Steps per Second: 22,165.02850
Overall Steps per Second: 10,534.87892

Timestep Collection Time: 2.25635
Timestep Consumption Time: 2.49093
PPO Batch Consumption Time: 0.30013
Total Iteration Time: 4.74728

Cumulative Model Updates: 2,636
Cumulative Timesteps: 22,107,570

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 22107570...
Checkpoint 22107570 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 767.36999
Policy Entropy: 1.52173
Value Function Loss: 1.68241

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.09978
Policy Update Magnitude: 0.26165
Value Function Update Magnitude: 0.25497

Collected Steps per Second: 22,327.96522
Overall Steps per Second: 10,555.32956

Timestep Collection Time: 2.23943
Timestep Consumption Time: 2.49770
PPO Batch Consumption Time: 0.28704
Total Iteration Time: 4.73713

Cumulative Model Updates: 2,642
Cumulative Timesteps: 22,157,572

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 660.96777
Policy Entropy: 1.53444
Value Function Loss: 1.65210

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.08352
Policy Update Magnitude: 0.31746
Value Function Update Magnitude: 0.24109

Collected Steps per Second: 22,144.43826
Overall Steps per Second: 10,468.99534

Timestep Collection Time: 2.25908
Timestep Consumption Time: 2.51941
PPO Batch Consumption Time: 0.29184
Total Iteration Time: 4.77849

Cumulative Model Updates: 2,648
Cumulative Timesteps: 22,207,598

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 22207598...
Checkpoint 22207598 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 602.08048
Policy Entropy: 1.53171
Value Function Loss: 1.67818

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.10290
Policy Update Magnitude: 0.32315
Value Function Update Magnitude: 0.24104

Collected Steps per Second: 22,237.25263
Overall Steps per Second: 10,552.32160

Timestep Collection Time: 2.24848
Timestep Consumption Time: 2.48981
PPO Batch Consumption Time: 0.28656
Total Iteration Time: 4.73829

Cumulative Model Updates: 2,654
Cumulative Timesteps: 22,257,598

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,166.80328
Policy Entropy: 1.54411
Value Function Loss: 1.68273

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.10603
Policy Update Magnitude: 0.29032
Value Function Update Magnitude: 0.23589

Collected Steps per Second: 22,074.20687
Overall Steps per Second: 10,590.79386

Timestep Collection Time: 2.26654
Timestep Consumption Time: 2.45757
PPO Batch Consumption Time: 0.28576
Total Iteration Time: 4.72410

Cumulative Model Updates: 2,660
Cumulative Timesteps: 22,307,630

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 22307630...
Checkpoint 22307630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 972.09009
Policy Entropy: 1.56519
Value Function Loss: 1.74266

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.10513
Policy Update Magnitude: 0.28200
Value Function Update Magnitude: 0.24765

Collected Steps per Second: 22,209.51858
Overall Steps per Second: 10,610.92505

Timestep Collection Time: 2.25255
Timestep Consumption Time: 2.46222
PPO Batch Consumption Time: 0.29608
Total Iteration Time: 4.71476

Cumulative Model Updates: 2,666
Cumulative Timesteps: 22,357,658

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 828.09237
Policy Entropy: 1.56823
Value Function Loss: 1.74024

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.09826
Policy Update Magnitude: 0.29395
Value Function Update Magnitude: 0.25355

Collected Steps per Second: 21,687.38883
Overall Steps per Second: 10,429.68061

Timestep Collection Time: 2.30586
Timestep Consumption Time: 2.48892
PPO Batch Consumption Time: 0.29699
Total Iteration Time: 4.79478

Cumulative Model Updates: 2,672
Cumulative Timesteps: 22,407,666

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 22407666...
Checkpoint 22407666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 848.78956
Policy Entropy: 1.55727
Value Function Loss: 1.71731

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.08855
Policy Update Magnitude: 0.29844
Value Function Update Magnitude: 0.24513

Collected Steps per Second: 22,411.13012
Overall Steps per Second: 10,575.45156

Timestep Collection Time: 2.23103
Timestep Consumption Time: 2.49690
PPO Batch Consumption Time: 0.28681
Total Iteration Time: 4.72793

Cumulative Model Updates: 2,678
Cumulative Timesteps: 22,457,666

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 948.66879
Policy Entropy: 1.55876
Value Function Loss: 1.70739

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.09079
Policy Update Magnitude: 0.29095
Value Function Update Magnitude: 0.23897

Collected Steps per Second: 22,240.33970
Overall Steps per Second: 10,515.77035

Timestep Collection Time: 2.24817
Timestep Consumption Time: 2.50660
PPO Batch Consumption Time: 0.28742
Total Iteration Time: 4.75476

Cumulative Model Updates: 2,684
Cumulative Timesteps: 22,507,666

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 22507666...
Checkpoint 22507666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 703.97464
Policy Entropy: 1.56383
Value Function Loss: 1.69903

Mean KL Divergence: 0.00782
SB3 Clip Fraction: 0.08973
Policy Update Magnitude: 0.29150
Value Function Update Magnitude: 0.24657

Collected Steps per Second: 22,107.43101
Overall Steps per Second: 10,585.07006

Timestep Collection Time: 2.26268
Timestep Consumption Time: 2.46303
PPO Batch Consumption Time: 0.28687
Total Iteration Time: 4.72571

Cumulative Model Updates: 2,690
Cumulative Timesteps: 22,557,688

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 755.50628
Policy Entropy: 1.57128
Value Function Loss: 1.68750

Mean KL Divergence: 0.00525
SB3 Clip Fraction: 0.06121
Policy Update Magnitude: 0.37335
Value Function Update Magnitude: 0.22982

Collected Steps per Second: 22,249.18284
Overall Steps per Second: 10,525.89262

Timestep Collection Time: 2.24772
Timestep Consumption Time: 2.50342
PPO Batch Consumption Time: 0.29212
Total Iteration Time: 4.75114

Cumulative Model Updates: 2,696
Cumulative Timesteps: 22,607,698

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 22607698...
Checkpoint 22607698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,146.43289
Policy Entropy: 1.55576
Value Function Loss: 1.66973

Mean KL Divergence: 0.00731
SB3 Clip Fraction: 0.09374
Policy Update Magnitude: 0.39909
Value Function Update Magnitude: 0.22865

Collected Steps per Second: 22,256.31617
Overall Steps per Second: 10,627.52243

Timestep Collection Time: 2.24673
Timestep Consumption Time: 2.45841
PPO Batch Consumption Time: 0.29394
Total Iteration Time: 4.70514

Cumulative Model Updates: 2,702
Cumulative Timesteps: 22,657,702

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,247.18189
Policy Entropy: 1.57112
Value Function Loss: 1.67175

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.09924
Policy Update Magnitude: 0.36382
Value Function Update Magnitude: 0.22467

Collected Steps per Second: 22,342.25871
Overall Steps per Second: 10,482.84103

Timestep Collection Time: 2.23899
Timestep Consumption Time: 2.53300
PPO Batch Consumption Time: 0.29264
Total Iteration Time: 4.77199

Cumulative Model Updates: 2,708
Cumulative Timesteps: 22,707,726

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 22707726...
Checkpoint 22707726 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 875.19243
Policy Entropy: 1.57772
Value Function Loss: 1.68127

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.09691
Policy Update Magnitude: 0.37233
Value Function Update Magnitude: 0.22415

Collected Steps per Second: 22,230.76602
Overall Steps per Second: 10,577.33667

Timestep Collection Time: 2.24959
Timestep Consumption Time: 2.47845
PPO Batch Consumption Time: 0.28631
Total Iteration Time: 4.72803

Cumulative Model Updates: 2,714
Cumulative Timesteps: 22,757,736

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 795.41683
Policy Entropy: 1.58602
Value Function Loss: 1.66596

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.10930
Policy Update Magnitude: 0.37794
Value Function Update Magnitude: 0.23224

Collected Steps per Second: 22,148.92893
Overall Steps per Second: 10,536.36198

Timestep Collection Time: 2.25754
Timestep Consumption Time: 2.48812
PPO Batch Consumption Time: 0.28555
Total Iteration Time: 4.74566

Cumulative Model Updates: 2,720
Cumulative Timesteps: 22,807,738

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 22807738...
Checkpoint 22807738 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,173.00818
Policy Entropy: 1.60984
Value Function Loss: 1.65433

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.09526
Policy Update Magnitude: 0.35228
Value Function Update Magnitude: 0.24731

Collected Steps per Second: 22,206.67270
Overall Steps per Second: 10,632.62572

Timestep Collection Time: 2.25302
Timestep Consumption Time: 2.45250
PPO Batch Consumption Time: 0.28575
Total Iteration Time: 4.70552

Cumulative Model Updates: 2,726
Cumulative Timesteps: 22,857,770

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,017.26272
Policy Entropy: 1.60492
Value Function Loss: 1.62628

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.10773
Policy Update Magnitude: 0.35831
Value Function Update Magnitude: 0.25322

Collected Steps per Second: 22,210.70727
Overall Steps per Second: 10,424.76858

Timestep Collection Time: 2.25234
Timestep Consumption Time: 2.54643
PPO Batch Consumption Time: 0.29932
Total Iteration Time: 4.79876

Cumulative Model Updates: 2,732
Cumulative Timesteps: 22,907,796

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 22907796...
Checkpoint 22907796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 890.61862
Policy Entropy: 1.61287
Value Function Loss: 1.63482

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.10348
Policy Update Magnitude: 0.32417
Value Function Update Magnitude: 0.26127

Collected Steps per Second: 22,211.35430
Overall Steps per Second: 10,683.50375

Timestep Collection Time: 2.25209
Timestep Consumption Time: 2.43008
PPO Batch Consumption Time: 0.29159
Total Iteration Time: 4.68217

Cumulative Model Updates: 2,738
Cumulative Timesteps: 22,957,818

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,163.73928
Policy Entropy: 1.61248
Value Function Loss: 1.62717

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.10256
Policy Update Magnitude: 0.32951
Value Function Update Magnitude: 0.31378

Collected Steps per Second: 22,340.35741
Overall Steps per Second: 10,446.67404

Timestep Collection Time: 2.23936
Timestep Consumption Time: 2.54954
PPO Batch Consumption Time: 0.29641
Total Iteration Time: 4.78889

Cumulative Model Updates: 2,744
Cumulative Timesteps: 23,007,846

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 23007846...
Checkpoint 23007846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 993.57435
Policy Entropy: 1.60397
Value Function Loss: 1.67558

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.10697
Policy Update Magnitude: 0.32304
Value Function Update Magnitude: 0.26709

Collected Steps per Second: 21,978.29140
Overall Steps per Second: 10,524.19770

Timestep Collection Time: 2.27597
Timestep Consumption Time: 2.47707
PPO Batch Consumption Time: 0.28638
Total Iteration Time: 4.75305

Cumulative Model Updates: 2,750
Cumulative Timesteps: 23,057,868

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,131.18703
Policy Entropy: 1.59554
Value Function Loss: 1.68571

Mean KL Divergence: 0.00766
SB3 Clip Fraction: 0.09626
Policy Update Magnitude: 0.34023
Value Function Update Magnitude: 0.24964

Collected Steps per Second: 22,134.01534
Overall Steps per Second: 10,538.67600

Timestep Collection Time: 2.26014
Timestep Consumption Time: 2.48675
PPO Batch Consumption Time: 0.28652
Total Iteration Time: 4.74690

Cumulative Model Updates: 2,756
Cumulative Timesteps: 23,107,894

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 23107894...
Checkpoint 23107894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 950.77858
Policy Entropy: 1.57495
Value Function Loss: 1.72198

Mean KL Divergence: 0.00690
SB3 Clip Fraction: 0.08089
Policy Update Magnitude: 0.33848
Value Function Update Magnitude: 0.25359

Collected Steps per Second: 22,240.42764
Overall Steps per Second: 10,646.00015

Timestep Collection Time: 2.24915
Timestep Consumption Time: 2.44952
PPO Batch Consumption Time: 0.28614
Total Iteration Time: 4.69867

Cumulative Model Updates: 2,762
Cumulative Timesteps: 23,157,916

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,199.84899
Policy Entropy: 1.56996
Value Function Loss: 1.70526

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.10269
Policy Update Magnitude: 0.33614
Value Function Update Magnitude: 0.23455

Collected Steps per Second: 22,175.74383
Overall Steps per Second: 10,477.07508

Timestep Collection Time: 2.25472
Timestep Consumption Time: 2.51761
PPO Batch Consumption Time: 0.29526
Total Iteration Time: 4.77232

Cumulative Model Updates: 2,768
Cumulative Timesteps: 23,207,916

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 23207916...
Checkpoint 23207916 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 652.12246
Policy Entropy: 1.57028
Value Function Loss: 1.70042

Mean KL Divergence: 0.01060
SB3 Clip Fraction: 0.12398
Policy Update Magnitude: 0.30195
Value Function Update Magnitude: 0.23337

Collected Steps per Second: 22,061.12197
Overall Steps per Second: 10,678.28749

Timestep Collection Time: 2.26752
Timestep Consumption Time: 2.41713
PPO Batch Consumption Time: 0.28630
Total Iteration Time: 4.68465

Cumulative Model Updates: 2,774
Cumulative Timesteps: 23,257,940

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 981.11211
Policy Entropy: 1.58430
Value Function Loss: 1.67189

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.10982
Policy Update Magnitude: 0.28180
Value Function Update Magnitude: 0.23772

Collected Steps per Second: 22,319.27445
Overall Steps per Second: 10,443.10189

Timestep Collection Time: 2.24031
Timestep Consumption Time: 2.54774
PPO Batch Consumption Time: 0.29686
Total Iteration Time: 4.78804

Cumulative Model Updates: 2,780
Cumulative Timesteps: 23,307,942

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 23307942...
Checkpoint 23307942 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,179.68413
Policy Entropy: 1.58723
Value Function Loss: 1.63271

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.10599
Policy Update Magnitude: 0.31299
Value Function Update Magnitude: 0.24273

Collected Steps per Second: 22,214.70443
Overall Steps per Second: 10,565.84578

Timestep Collection Time: 2.25184
Timestep Consumption Time: 2.48266
PPO Batch Consumption Time: 0.28699
Total Iteration Time: 4.73450

Cumulative Model Updates: 2,786
Cumulative Timesteps: 23,357,966

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 868.88041
Policy Entropy: 1.58937
Value Function Loss: 1.67602

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.09542
Policy Update Magnitude: 0.31668
Value Function Update Magnitude: 0.24144

Collected Steps per Second: 22,469.86778
Overall Steps per Second: 10,506.43049

Timestep Collection Time: 2.22591
Timestep Consumption Time: 2.53460
PPO Batch Consumption Time: 0.29207
Total Iteration Time: 4.76051

Cumulative Model Updates: 2,792
Cumulative Timesteps: 23,407,982

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 23407982...
Checkpoint 23407982 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 808.37923
Policy Entropy: 1.59730
Value Function Loss: 1.67737

Mean KL Divergence: 0.00557
SB3 Clip Fraction: 0.06676
Policy Update Magnitude: 0.37678
Value Function Update Magnitude: 0.24655

Collected Steps per Second: 22,276.28066
Overall Steps per Second: 10,612.77003

Timestep Collection Time: 2.24535
Timestep Consumption Time: 2.46765
PPO Batch Consumption Time: 0.28700
Total Iteration Time: 4.71300

Cumulative Model Updates: 2,798
Cumulative Timesteps: 23,458,000

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 689.07532
Policy Entropy: 1.59838
Value Function Loss: 1.67344

Mean KL Divergence: 0.00683
SB3 Clip Fraction: 0.08018
Policy Update Magnitude: 0.42629
Value Function Update Magnitude: 0.26261

Collected Steps per Second: 22,330.96233
Overall Steps per Second: 10,612.26829

Timestep Collection Time: 2.23922
Timestep Consumption Time: 2.47268
PPO Batch Consumption Time: 0.29852
Total Iteration Time: 4.71190

Cumulative Model Updates: 2,804
Cumulative Timesteps: 23,508,004

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 23508004...
Checkpoint 23508004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 918.55606
Policy Entropy: 1.60986
Value Function Loss: 1.66701

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.08830
Policy Update Magnitude: 0.38342
Value Function Update Magnitude: 0.25448

Collected Steps per Second: 22,376.40700
Overall Steps per Second: 10,524.50756

Timestep Collection Time: 2.23476
Timestep Consumption Time: 2.51662
PPO Batch Consumption Time: 0.29240
Total Iteration Time: 4.75139

Cumulative Model Updates: 2,810
Cumulative Timesteps: 23,558,010

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,193.96775
Policy Entropy: 1.62010
Value Function Loss: 1.70434

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.10916
Policy Update Magnitude: 0.34409
Value Function Update Magnitude: 0.27921

Collected Steps per Second: 22,467.39053
Overall Steps per Second: 10,428.28624

Timestep Collection Time: 2.22652
Timestep Consumption Time: 2.57044
PPO Batch Consumption Time: 0.29896
Total Iteration Time: 4.79695

Cumulative Model Updates: 2,816
Cumulative Timesteps: 23,608,034

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 23608034...
Checkpoint 23608034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,012.62635
Policy Entropy: 1.64529
Value Function Loss: 1.73221

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.10533
Policy Update Magnitude: 0.29154
Value Function Update Magnitude: 0.25421

Collected Steps per Second: 22,148.42562
Overall Steps per Second: 10,550.50391

Timestep Collection Time: 2.25885
Timestep Consumption Time: 2.48310
PPO Batch Consumption Time: 0.28635
Total Iteration Time: 4.74195

Cumulative Model Updates: 2,822
Cumulative Timesteps: 23,658,064

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 607.77547
Policy Entropy: 1.64540
Value Function Loss: 1.73439

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.10449
Policy Update Magnitude: 0.28467
Value Function Update Magnitude: 0.25146

Collected Steps per Second: 22,326.40118
Overall Steps per Second: 10,590.88969

Timestep Collection Time: 2.23995
Timestep Consumption Time: 2.48203
PPO Batch Consumption Time: 0.28956
Total Iteration Time: 4.72198

Cumulative Model Updates: 2,828
Cumulative Timesteps: 23,708,074

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 23708074...
Checkpoint 23708074 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,113.18372
Policy Entropy: 1.63356
Value Function Loss: 1.68218

Mean KL Divergence: 0.00685
SB3 Clip Fraction: 0.07629
Policy Update Magnitude: 0.34690
Value Function Update Magnitude: 0.24975

Collected Steps per Second: 21,930.07167
Overall Steps per Second: 10,558.79674

Timestep Collection Time: 2.28080
Timestep Consumption Time: 2.45630
PPO Batch Consumption Time: 0.28649
Total Iteration Time: 4.73709

Cumulative Model Updates: 2,834
Cumulative Timesteps: 23,758,092

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 903.53477
Policy Entropy: 1.63363
Value Function Loss: 1.65618

Mean KL Divergence: 0.00638
SB3 Clip Fraction: 0.07462
Policy Update Magnitude: 0.42717
Value Function Update Magnitude: 0.25365

Collected Steps per Second: 22,366.93560
Overall Steps per Second: 10,615.21275

Timestep Collection Time: 2.23660
Timestep Consumption Time: 2.47607
PPO Batch Consumption Time: 0.30019
Total Iteration Time: 4.71267

Cumulative Model Updates: 2,840
Cumulative Timesteps: 23,808,118

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 23808118...
Checkpoint 23808118 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 986.87717
Policy Entropy: 1.62026
Value Function Loss: 1.61055

Mean KL Divergence: 0.00614
SB3 Clip Fraction: 0.07413
Policy Update Magnitude: 0.43170
Value Function Update Magnitude: 0.25083

Collected Steps per Second: 21,774.03585
Overall Steps per Second: 10,541.61582

Timestep Collection Time: 2.29714
Timestep Consumption Time: 2.44767
PPO Batch Consumption Time: 0.29260
Total Iteration Time: 4.74481

Cumulative Model Updates: 2,846
Cumulative Timesteps: 23,858,136

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 623.27953
Policy Entropy: 1.62085
Value Function Loss: 1.60250

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.10145
Policy Update Magnitude: 0.36598
Value Function Update Magnitude: 0.23996

Collected Steps per Second: 22,414.30945
Overall Steps per Second: 10,446.45096

Timestep Collection Time: 2.23152
Timestep Consumption Time: 2.55652
PPO Batch Consumption Time: 0.29492
Total Iteration Time: 4.78804

Cumulative Model Updates: 2,852
Cumulative Timesteps: 23,908,154

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 23908154...
Checkpoint 23908154 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 851.22335
Policy Entropy: 1.62325
Value Function Loss: 1.62037

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.09579
Policy Update Magnitude: 0.32006
Value Function Update Magnitude: 0.24368

Collected Steps per Second: 22,315.84422
Overall Steps per Second: 10,585.88601

Timestep Collection Time: 2.24199
Timestep Consumption Time: 2.48430
PPO Batch Consumption Time: 0.28672
Total Iteration Time: 4.72629

Cumulative Model Updates: 2,858
Cumulative Timesteps: 23,958,186

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 615.69557
Policy Entropy: 1.63504
Value Function Loss: 1.67282

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.09916
Policy Update Magnitude: 0.31160
Value Function Update Magnitude: 0.25071

Collected Steps per Second: 22,268.65372
Overall Steps per Second: 10,530.65010

Timestep Collection Time: 2.24594
Timestep Consumption Time: 2.50344
PPO Batch Consumption Time: 0.28920
Total Iteration Time: 4.74937

Cumulative Model Updates: 2,864
Cumulative Timesteps: 24,008,200

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 24008200...
Checkpoint 24008200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 832.80440
Policy Entropy: 1.62912
Value Function Loss: 1.68327

Mean KL Divergence: 0.00744
SB3 Clip Fraction: 0.08937
Policy Update Magnitude: 0.32963
Value Function Update Magnitude: 0.25712

Collected Steps per Second: 22,032.01349
Overall Steps per Second: 10,559.74884

Timestep Collection Time: 2.26942
Timestep Consumption Time: 2.46554
PPO Batch Consumption Time: 0.28706
Total Iteration Time: 4.73496

Cumulative Model Updates: 2,870
Cumulative Timesteps: 24,058,200

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 945.55760
Policy Entropy: 1.62158
Value Function Loss: 1.69074

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.09267
Policy Update Magnitude: 0.32749
Value Function Update Magnitude: 0.25339

Collected Steps per Second: 22,548.68568
Overall Steps per Second: 10,712.16475

Timestep Collection Time: 2.21867
Timestep Consumption Time: 2.45154
PPO Batch Consumption Time: 0.29597
Total Iteration Time: 4.67020

Cumulative Model Updates: 2,876
Cumulative Timesteps: 24,108,228

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 24108228...
Checkpoint 24108228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,325.20702
Policy Entropy: 1.63252
Value Function Loss: 1.65875

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.10467
Policy Update Magnitude: 0.31376
Value Function Update Magnitude: 0.25282

Collected Steps per Second: 22,444.05866
Overall Steps per Second: 10,475.32110

Timestep Collection Time: 2.22892
Timestep Consumption Time: 2.54669
PPO Batch Consumption Time: 0.29917
Total Iteration Time: 4.77561

Cumulative Model Updates: 2,882
Cumulative Timesteps: 24,158,254

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 719.03006
Policy Entropy: 1.62208
Value Function Loss: 1.70689

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.10159
Policy Update Magnitude: 0.30198
Value Function Update Magnitude: 0.29499

Collected Steps per Second: 22,367.08810
Overall Steps per Second: 10,401.58174

Timestep Collection Time: 2.23632
Timestep Consumption Time: 2.57256
PPO Batch Consumption Time: 0.30305
Total Iteration Time: 4.80888

Cumulative Model Updates: 2,888
Cumulative Timesteps: 24,208,274

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 24208274...
Checkpoint 24208274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 719.01904
Policy Entropy: 1.61574
Value Function Loss: 1.62731

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.09306
Policy Update Magnitude: 0.33992
Value Function Update Magnitude: 0.30047

Collected Steps per Second: 19,100.75447
Overall Steps per Second: 9,765.09417

Timestep Collection Time: 2.61843
Timestep Consumption Time: 2.50328
PPO Batch Consumption Time: 0.28831
Total Iteration Time: 5.12171

Cumulative Model Updates: 2,894
Cumulative Timesteps: 24,258,288

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 617.70110
Policy Entropy: 1.61469
Value Function Loss: 1.64078

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.09180
Policy Update Magnitude: 0.33127
Value Function Update Magnitude: 0.28907

Collected Steps per Second: 20,533.05758
Overall Steps per Second: 10,129.85395

Timestep Collection Time: 2.43666
Timestep Consumption Time: 2.50241
PPO Batch Consumption Time: 0.29672
Total Iteration Time: 4.93906

Cumulative Model Updates: 2,900
Cumulative Timesteps: 24,308,320

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 24308320...
Checkpoint 24308320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 648.38042
Policy Entropy: 1.62587
Value Function Loss: 1.57929

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.10200
Policy Update Magnitude: 0.32136
Value Function Update Magnitude: 0.27787

Collected Steps per Second: 21,263.60789
Overall Steps per Second: 10,445.23187

Timestep Collection Time: 2.35162
Timestep Consumption Time: 2.43563
PPO Batch Consumption Time: 0.28992
Total Iteration Time: 4.78726

Cumulative Model Updates: 2,906
Cumulative Timesteps: 24,358,324

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,274.35762
Policy Entropy: 1.62930
Value Function Loss: 1.61890

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.09948
Policy Update Magnitude: 0.31096
Value Function Update Magnitude: 0.26483

Collected Steps per Second: 21,208.22066
Overall Steps per Second: 10,532.96251

Timestep Collection Time: 2.35833
Timestep Consumption Time: 2.39019
PPO Batch Consumption Time: 0.29134
Total Iteration Time: 4.74852

Cumulative Model Updates: 2,912
Cumulative Timesteps: 24,408,340

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 24408340...
Checkpoint 24408340 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,178.06710
Policy Entropy: 1.63468
Value Function Loss: 1.57206

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.10549
Policy Update Magnitude: 0.30409
Value Function Update Magnitude: 0.26060

Collected Steps per Second: 21,993.92281
Overall Steps per Second: 10,350.54832

Timestep Collection Time: 2.27454
Timestep Consumption Time: 2.55864
PPO Batch Consumption Time: 0.29803
Total Iteration Time: 4.83317

Cumulative Model Updates: 2,918
Cumulative Timesteps: 24,458,366

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 708.24114
Policy Entropy: 1.64844
Value Function Loss: 1.55532

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.11166
Policy Update Magnitude: 0.30997
Value Function Update Magnitude: 0.25166

Collected Steps per Second: 22,311.91589
Overall Steps per Second: 10,758.40100

Timestep Collection Time: 2.24113
Timestep Consumption Time: 2.40677
PPO Batch Consumption Time: 0.28651
Total Iteration Time: 4.64790

Cumulative Model Updates: 2,924
Cumulative Timesteps: 24,508,370

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 24508370...
Checkpoint 24508370 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 755.86042
Policy Entropy: 1.62171
Value Function Loss: 1.50982

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.10305
Policy Update Magnitude: 0.31993
Value Function Update Magnitude: 0.25011

Collected Steps per Second: 22,181.33266
Overall Steps per Second: 10,383.01337

Timestep Collection Time: 2.25415
Timestep Consumption Time: 2.56141
PPO Batch Consumption Time: 0.30123
Total Iteration Time: 4.81556

Cumulative Model Updates: 2,930
Cumulative Timesteps: 24,558,370

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 788.06221
Policy Entropy: 1.62206
Value Function Loss: 1.58443

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.08927
Policy Update Magnitude: 0.34228
Value Function Update Magnitude: 0.26352

Collected Steps per Second: 22,322.60108
Overall Steps per Second: 10,434.05027

Timestep Collection Time: 2.24069
Timestep Consumption Time: 2.55304
PPO Batch Consumption Time: 0.29653
Total Iteration Time: 4.79373

Cumulative Model Updates: 2,936
Cumulative Timesteps: 24,608,388

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 24608388...
Checkpoint 24608388 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 932.10585
Policy Entropy: 1.62724
Value Function Loss: 1.60097

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.10497
Policy Update Magnitude: 0.34314
Value Function Update Magnitude: 0.25545

Collected Steps per Second: 21,843.14355
Overall Steps per Second: 10,539.36617

Timestep Collection Time: 2.28932
Timestep Consumption Time: 2.45537
PPO Batch Consumption Time: 0.28695
Total Iteration Time: 4.74469

Cumulative Model Updates: 2,942
Cumulative Timesteps: 24,658,394

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 743.08200
Policy Entropy: 1.62724
Value Function Loss: 1.63507

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.10996
Policy Update Magnitude: 0.34584
Value Function Update Magnitude: 0.24905

Collected Steps per Second: 22,202.91791
Overall Steps per Second: 10,579.56334

Timestep Collection Time: 2.25304
Timestep Consumption Time: 2.47532
PPO Batch Consumption Time: 0.29717
Total Iteration Time: 4.72836

Cumulative Model Updates: 2,948
Cumulative Timesteps: 24,708,418

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 24708418...
Checkpoint 24708418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 821.97989
Policy Entropy: 1.61761
Value Function Loss: 1.55460

Mean KL Divergence: 0.01186
SB3 Clip Fraction: 0.13658
Policy Update Magnitude: 0.31321
Value Function Update Magnitude: 0.24416

Collected Steps per Second: 22,328.48031
Overall Steps per Second: 10,592.19464

Timestep Collection Time: 2.24046
Timestep Consumption Time: 2.48245
PPO Batch Consumption Time: 0.28664
Total Iteration Time: 4.72291

Cumulative Model Updates: 2,954
Cumulative Timesteps: 24,758,444

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 937.72850
Policy Entropy: 1.58765
Value Function Loss: 1.55918

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.10395
Policy Update Magnitude: 0.28499
Value Function Update Magnitude: 0.24427

Collected Steps per Second: 22,192.10999
Overall Steps per Second: 10,493.03608

Timestep Collection Time: 2.25305
Timestep Consumption Time: 2.51201
PPO Batch Consumption Time: 0.29052
Total Iteration Time: 4.76507

Cumulative Model Updates: 2,960
Cumulative Timesteps: 24,808,444

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 24808444...
Checkpoint 24808444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 975.09011
Policy Entropy: 1.57838
Value Function Loss: 1.56573

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.09632
Policy Update Magnitude: 0.31678
Value Function Update Magnitude: 0.25453

Collected Steps per Second: 21,600.56068
Overall Steps per Second: 10,194.90108

Timestep Collection Time: 2.31503
Timestep Consumption Time: 2.58997
PPO Batch Consumption Time: 0.30862
Total Iteration Time: 4.90500

Cumulative Model Updates: 2,966
Cumulative Timesteps: 24,858,450

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 807.61497
Policy Entropy: 1.57346
Value Function Loss: 1.57645

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.10221
Policy Update Magnitude: 0.31502
Value Function Update Magnitude: 0.25046

Collected Steps per Second: 21,948.32588
Overall Steps per Second: 10,498.09151

Timestep Collection Time: 2.27935
Timestep Consumption Time: 2.48608
PPO Batch Consumption Time: 0.28549
Total Iteration Time: 4.76544

Cumulative Model Updates: 2,972
Cumulative Timesteps: 24,908,478

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 24908478...
Checkpoint 24908478 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 978.51689
Policy Entropy: 1.59409
Value Function Loss: 1.54479

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.10125
Policy Update Magnitude: 0.32330
Value Function Update Magnitude: 0.25670

Collected Steps per Second: 22,124.33425
Overall Steps per Second: 10,576.14194

Timestep Collection Time: 2.26041
Timestep Consumption Time: 2.46816
PPO Batch Consumption Time: 0.28639
Total Iteration Time: 4.72857

Cumulative Model Updates: 2,978
Cumulative Timesteps: 24,958,488

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 734.43742
Policy Entropy: 1.59322
Value Function Loss: 1.53283

Mean KL Divergence: 0.00737
SB3 Clip Fraction: 0.08651
Policy Update Magnitude: 0.35344
Value Function Update Magnitude: 0.26693

Collected Steps per Second: 22,320.53234
Overall Steps per Second: 10,509.85263

Timestep Collection Time: 2.24152
Timestep Consumption Time: 2.51896
PPO Batch Consumption Time: 0.29633
Total Iteration Time: 4.76049

Cumulative Model Updates: 2,984
Cumulative Timesteps: 25,008,520

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 25008520...
Checkpoint 25008520 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,074.98120
Policy Entropy: 1.58971
Value Function Loss: 1.54208

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.10203
Policy Update Magnitude: 0.30411
Value Function Update Magnitude: 0.29803

Collected Steps per Second: 21,990.30021
Overall Steps per Second: 10,644.38424

Timestep Collection Time: 2.27473
Timestep Consumption Time: 2.42465
PPO Batch Consumption Time: 0.29009
Total Iteration Time: 4.69938

Cumulative Model Updates: 2,990
Cumulative Timesteps: 25,058,542

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 958.92496
Policy Entropy: 1.60948
Value Function Loss: 1.54976

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.09042
Policy Update Magnitude: 0.30282
Value Function Update Magnitude: 0.27589

Collected Steps per Second: 22,476.48788
Overall Steps per Second: 10,428.51012

Timestep Collection Time: 2.22570
Timestep Consumption Time: 2.57134
PPO Batch Consumption Time: 0.30018
Total Iteration Time: 4.79704

Cumulative Model Updates: 2,996
Cumulative Timesteps: 25,108,568

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 25108568...
Checkpoint 25108568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,246.85686
Policy Entropy: 1.60003
Value Function Loss: 1.54293

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.10177
Policy Update Magnitude: 0.30282
Value Function Update Magnitude: 0.28746

Collected Steps per Second: 22,676.72160
Overall Steps per Second: 10,914.71437

Timestep Collection Time: 2.20623
Timestep Consumption Time: 2.37749
PPO Batch Consumption Time: 0.28361
Total Iteration Time: 4.58372

Cumulative Model Updates: 3,002
Cumulative Timesteps: 25,158,598

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 874.81999
Policy Entropy: 1.60220
Value Function Loss: 1.50882

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.10388
Policy Update Magnitude: 0.31136
Value Function Update Magnitude: 0.28281

Collected Steps per Second: 23,108.79875
Overall Steps per Second: 10,704.63857

Timestep Collection Time: 2.16437
Timestep Consumption Time: 2.50800
PPO Batch Consumption Time: 0.29094
Total Iteration Time: 4.67237

Cumulative Model Updates: 3,008
Cumulative Timesteps: 25,208,614

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 25208614...
Checkpoint 25208614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 936.70448
Policy Entropy: 1.58559
Value Function Loss: 1.51296

Mean KL Divergence: 0.00685
SB3 Clip Fraction: 0.08289
Policy Update Magnitude: 0.37709
Value Function Update Magnitude: 0.27081

Collected Steps per Second: 22,027.14470
Overall Steps per Second: 10,558.14475

Timestep Collection Time: 2.27065
Timestep Consumption Time: 2.46654
PPO Batch Consumption Time: 0.28369
Total Iteration Time: 4.73720

Cumulative Model Updates: 3,014
Cumulative Timesteps: 25,258,630

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 935.04363
Policy Entropy: 1.60618
Value Function Loss: 1.51661

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.11103
Policy Update Magnitude: 0.38143
Value Function Update Magnitude: 0.25849

Collected Steps per Second: 23,164.18701
Overall Steps per Second: 10,721.66442

Timestep Collection Time: 2.15954
Timestep Consumption Time: 2.50615
PPO Batch Consumption Time: 0.29248
Total Iteration Time: 4.66569

Cumulative Model Updates: 3,020
Cumulative Timesteps: 25,308,654

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 25308654...
Checkpoint 25308654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 966.66998
Policy Entropy: 1.61854
Value Function Loss: 1.51896

Mean KL Divergence: 0.01567
SB3 Clip Fraction: 0.15583
Policy Update Magnitude: 0.30485
Value Function Update Magnitude: 0.25698

Collected Steps per Second: 22,794.27524
Overall Steps per Second: 10,937.17904

Timestep Collection Time: 2.19476
Timestep Consumption Time: 2.37936
PPO Batch Consumption Time: 0.28398
Total Iteration Time: 4.57412

Cumulative Model Updates: 3,026
Cumulative Timesteps: 25,358,682

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,145.40231
Policy Entropy: 1.64969
Value Function Loss: 1.52601

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.10544
Policy Update Magnitude: 0.30777
Value Function Update Magnitude: 0.27081

Collected Steps per Second: 23,076.13445
Overall Steps per Second: 10,789.04170

Timestep Collection Time: 2.16735
Timestep Consumption Time: 2.46828
PPO Batch Consumption Time: 0.28497
Total Iteration Time: 4.63563

Cumulative Model Updates: 3,032
Cumulative Timesteps: 25,408,696

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 25408696...
Checkpoint 25408696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 984.77676
Policy Entropy: 1.65108
Value Function Loss: 1.55598

Mean KL Divergence: 0.00732
SB3 Clip Fraction: 0.08684
Policy Update Magnitude: 0.33127
Value Function Update Magnitude: 0.28511

Collected Steps per Second: 22,552.60143
Overall Steps per Second: 10,685.45561

Timestep Collection Time: 2.21722
Timestep Consumption Time: 2.46242
PPO Batch Consumption Time: 0.28429
Total Iteration Time: 4.67963

Cumulative Model Updates: 3,038
Cumulative Timesteps: 25,458,700

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 805.30558
Policy Entropy: 1.65284
Value Function Loss: 1.55238

Mean KL Divergence: 0.00660
SB3 Clip Fraction: 0.07253
Policy Update Magnitude: 0.35025
Value Function Update Magnitude: 0.30680

Collected Steps per Second: 22,740.69578
Overall Steps per Second: 10,505.25871

Timestep Collection Time: 2.19941
Timestep Consumption Time: 2.56164
PPO Batch Consumption Time: 0.29723
Total Iteration Time: 4.76104

Cumulative Model Updates: 3,044
Cumulative Timesteps: 25,508,716

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 25508716...
Checkpoint 25508716 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 874.36708
Policy Entropy: 1.64639
Value Function Loss: 1.55707

Mean KL Divergence: 0.00641
SB3 Clip Fraction: 0.07505
Policy Update Magnitude: 0.38651
Value Function Update Magnitude: 0.29618

Collected Steps per Second: 22,173.41978
Overall Steps per Second: 10,619.21166

Timestep Collection Time: 2.25603
Timestep Consumption Time: 2.45467
PPO Batch Consumption Time: 0.28251
Total Iteration Time: 4.71071

Cumulative Model Updates: 3,050
Cumulative Timesteps: 25,558,740

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 736.93440
Policy Entropy: 1.64416
Value Function Loss: 1.53056

Mean KL Divergence: 0.00668
SB3 Clip Fraction: 0.07655
Policy Update Magnitude: 0.36886
Value Function Update Magnitude: 0.27244

Collected Steps per Second: 22,728.62264
Overall Steps per Second: 10,649.74836

Timestep Collection Time: 2.20049
Timestep Consumption Time: 2.49578
PPO Batch Consumption Time: 0.29444
Total Iteration Time: 4.69626

Cumulative Model Updates: 3,056
Cumulative Timesteps: 25,608,754

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 25608754...
Checkpoint 25608754 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 735.58751
Policy Entropy: 1.65109
Value Function Loss: 1.47033

Mean KL Divergence: 0.00576
SB3 Clip Fraction: 0.06649
Policy Update Magnitude: 0.42057
Value Function Update Magnitude: 0.32310

Collected Steps per Second: 22,501.18038
Overall Steps per Second: 10,854.41380

Timestep Collection Time: 2.22237
Timestep Consumption Time: 2.38460
PPO Batch Consumption Time: 0.28354
Total Iteration Time: 4.60697

Cumulative Model Updates: 3,062
Cumulative Timesteps: 25,658,760

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 897.65984
Policy Entropy: 1.64597
Value Function Loss: 1.44320

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.10339
Policy Update Magnitude: 0.41035
Value Function Update Magnitude: 0.27815

Collected Steps per Second: 22,267.83962
Overall Steps per Second: 10,659.03491

Timestep Collection Time: 2.24539
Timestep Consumption Time: 2.44547
PPO Batch Consumption Time: 0.29523
Total Iteration Time: 4.69086

Cumulative Model Updates: 3,068
Cumulative Timesteps: 25,708,760

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 25708760...
Checkpoint 25708760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 696.19210
Policy Entropy: 1.63835
Value Function Loss: 1.43851

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.11031
Policy Update Magnitude: 0.35116
Value Function Update Magnitude: 0.27099

Collected Steps per Second: 22,912.89293
Overall Steps per Second: 10,667.99360

Timestep Collection Time: 2.18235
Timestep Consumption Time: 2.50494
PPO Batch Consumption Time: 0.29384
Total Iteration Time: 4.68729

Cumulative Model Updates: 3,074
Cumulative Timesteps: 25,758,764

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 979.03746
Policy Entropy: 1.63333
Value Function Loss: 1.44888

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.09727
Policy Update Magnitude: 0.36547
Value Function Update Magnitude: 0.27143

Collected Steps per Second: 22,983.70938
Overall Steps per Second: 10,734.26452

Timestep Collection Time: 2.17598
Timestep Consumption Time: 2.48312
PPO Batch Consumption Time: 0.28749
Total Iteration Time: 4.65910

Cumulative Model Updates: 3,080
Cumulative Timesteps: 25,808,776

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 25808776...
Checkpoint 25808776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,239.55617
Policy Entropy: 1.62458
Value Function Loss: 1.44760

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.08936
Policy Update Magnitude: 0.35194
Value Function Update Magnitude: 0.26596

Collected Steps per Second: 22,493.92135
Overall Steps per Second: 10,696.38276

Timestep Collection Time: 2.22389
Timestep Consumption Time: 2.45283
PPO Batch Consumption Time: 0.28249
Total Iteration Time: 4.67672

Cumulative Model Updates: 3,086
Cumulative Timesteps: 25,858,800

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,094.76968
Policy Entropy: 1.64073
Value Function Loss: 1.42036

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.10000
Policy Update Magnitude: 0.37385
Value Function Update Magnitude: 0.27832

Collected Steps per Second: 22,774.39417
Overall Steps per Second: 10,761.79900

Timestep Collection Time: 2.19554
Timestep Consumption Time: 2.45071
PPO Batch Consumption Time: 0.28495
Total Iteration Time: 4.64625

Cumulative Model Updates: 3,092
Cumulative Timesteps: 25,908,802

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 25908802...
Checkpoint 25908802 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,225.18831
Policy Entropy: 1.62521
Value Function Loss: 1.43200

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.09161
Policy Update Magnitude: 0.33308
Value Function Update Magnitude: 0.27827

Collected Steps per Second: 22,642.38745
Overall Steps per Second: 10,703.72771

Timestep Collection Time: 2.20825
Timestep Consumption Time: 2.46302
PPO Batch Consumption Time: 0.28806
Total Iteration Time: 4.67127

Cumulative Model Updates: 3,098
Cumulative Timesteps: 25,958,802

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,131.60715
Policy Entropy: 1.62770
Value Function Loss: 1.41919

Mean KL Divergence: 0.00697
SB3 Clip Fraction: 0.07987
Policy Update Magnitude: 0.32490
Value Function Update Magnitude: 0.27978

Collected Steps per Second: 22,912.45746
Overall Steps per Second: 10,960.97787

Timestep Collection Time: 2.18222
Timestep Consumption Time: 2.37942
PPO Batch Consumption Time: 0.28307
Total Iteration Time: 4.56164

Cumulative Model Updates: 3,104
Cumulative Timesteps: 26,008,802

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 26008802...
Checkpoint 26008802 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 692.71281
Policy Entropy: 1.62489
Value Function Loss: 1.44524

Mean KL Divergence: 0.00676
SB3 Clip Fraction: 0.07782
Policy Update Magnitude: 0.32367
Value Function Update Magnitude: 0.26786

Collected Steps per Second: 22,756.60440
Overall Steps per Second: 10,613.72133

Timestep Collection Time: 2.19752
Timestep Consumption Time: 2.51412
PPO Batch Consumption Time: 0.29410
Total Iteration Time: 4.71164

Cumulative Model Updates: 3,110
Cumulative Timesteps: 26,058,810

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,404.48095
Policy Entropy: 1.64852
Value Function Loss: 1.44856

Mean KL Divergence: 0.00633
SB3 Clip Fraction: 0.07587
Policy Update Magnitude: 0.38346
Value Function Update Magnitude: 0.25692

Collected Steps per Second: 23,067.84757
Overall Steps per Second: 10,800.14002

Timestep Collection Time: 2.16856
Timestep Consumption Time: 2.46323
PPO Batch Consumption Time: 0.28398
Total Iteration Time: 4.63179

Cumulative Model Updates: 3,116
Cumulative Timesteps: 26,108,834

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 26108834...
Checkpoint 26108834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,080.47702
Policy Entropy: 1.64051
Value Function Loss: 1.42503

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.08770
Policy Update Magnitude: 0.36180
Value Function Update Magnitude: 0.26639

Collected Steps per Second: 22,799.63982
Overall Steps per Second: 10,543.53994

Timestep Collection Time: 2.19302
Timestep Consumption Time: 2.54922
PPO Batch Consumption Time: 0.29744
Total Iteration Time: 4.74224

Cumulative Model Updates: 3,122
Cumulative Timesteps: 26,158,834

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,021.19277
Policy Entropy: 1.61905
Value Function Loss: 1.42621

Mean KL Divergence: 0.00642
SB3 Clip Fraction: 0.07630
Policy Update Magnitude: 0.34306
Value Function Update Magnitude: 0.27169

Collected Steps per Second: 23,255.68201
Overall Steps per Second: 10,621.34959

Timestep Collection Time: 2.15027
Timestep Consumption Time: 2.55779
PPO Batch Consumption Time: 0.29351
Total Iteration Time: 4.70806

Cumulative Model Updates: 3,128
Cumulative Timesteps: 26,208,840

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 26208840...
Checkpoint 26208840 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 727.41500
Policy Entropy: 1.60169
Value Function Loss: 1.45114

Mean KL Divergence: 0.00654
SB3 Clip Fraction: 0.08083
Policy Update Magnitude: 0.38273
Value Function Update Magnitude: 0.29309

Collected Steps per Second: 22,529.26162
Overall Steps per Second: 10,660.29189

Timestep Collection Time: 2.22013
Timestep Consumption Time: 2.47186
PPO Batch Consumption Time: 0.29004
Total Iteration Time: 4.69199

Cumulative Model Updates: 3,134
Cumulative Timesteps: 26,258,858

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 750.81394
Policy Entropy: 1.61267
Value Function Loss: 1.39471

Mean KL Divergence: 0.00675
SB3 Clip Fraction: 0.08080
Policy Update Magnitude: 0.38909
Value Function Update Magnitude: 0.32018

Collected Steps per Second: 22,805.13564
Overall Steps per Second: 10,803.45817

Timestep Collection Time: 2.19319
Timestep Consumption Time: 2.43644
PPO Batch Consumption Time: 0.28407
Total Iteration Time: 4.62963

Cumulative Model Updates: 3,140
Cumulative Timesteps: 26,308,874

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 26308874...
Checkpoint 26308874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,231.05931
Policy Entropy: 1.63471
Value Function Loss: 1.39235

Mean KL Divergence: 0.00710
SB3 Clip Fraction: 0.08808
Policy Update Magnitude: 0.38281
Value Function Update Magnitude: 0.29557

Collected Steps per Second: 22,488.12185
Overall Steps per Second: 10,731.14147

Timestep Collection Time: 2.22366
Timestep Consumption Time: 2.43623
PPO Batch Consumption Time: 0.29192
Total Iteration Time: 4.65990

Cumulative Model Updates: 3,146
Cumulative Timesteps: 26,358,880

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,717.75445
Policy Entropy: 1.63181
Value Function Loss: 1.34936

Mean KL Divergence: 0.00712
SB3 Clip Fraction: 0.08810
Policy Update Magnitude: 0.38896
Value Function Update Magnitude: 0.28079

Collected Steps per Second: 22,182.11292
Overall Steps per Second: 10,665.20842

Timestep Collection Time: 2.25506
Timestep Consumption Time: 2.43514
PPO Batch Consumption Time: 0.29335
Total Iteration Time: 4.69020

Cumulative Model Updates: 3,152
Cumulative Timesteps: 26,408,902

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 26408902...
Checkpoint 26408902 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,215.10114
Policy Entropy: 1.64127
Value Function Loss: 1.35301

Mean KL Divergence: 0.00720
SB3 Clip Fraction: 0.09448
Policy Update Magnitude: 0.39054
Value Function Update Magnitude: 0.27923

Collected Steps per Second: 22,982.20618
Overall Steps per Second: 10,795.86229

Timestep Collection Time: 2.17603
Timestep Consumption Time: 2.45630
PPO Batch Consumption Time: 0.28410
Total Iteration Time: 4.63233

Cumulative Model Updates: 3,158
Cumulative Timesteps: 26,458,912

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,168.91349
Policy Entropy: 1.63159
Value Function Loss: 1.33242

Mean KL Divergence: 0.00694
SB3 Clip Fraction: 0.09181
Policy Update Magnitude: 0.38030
Value Function Update Magnitude: 0.27518

Collected Steps per Second: 23,073.61582
Overall Steps per Second: 10,658.92724

Timestep Collection Time: 2.16750
Timestep Consumption Time: 2.52453
PPO Batch Consumption Time: 0.29664
Total Iteration Time: 4.69203

Cumulative Model Updates: 3,164
Cumulative Timesteps: 26,508,924

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 26508924...
Checkpoint 26508924 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,304.54076
Policy Entropy: 1.62607
Value Function Loss: 1.35451

Mean KL Divergence: 0.00649
SB3 Clip Fraction: 0.08318
Policy Update Magnitude: 0.42477
Value Function Update Magnitude: 0.29518

Collected Steps per Second: 22,832.55291
Overall Steps per Second: 10,600.51435

Timestep Collection Time: 2.19091
Timestep Consumption Time: 2.52811
PPO Batch Consumption Time: 0.29670
Total Iteration Time: 4.71902

Cumulative Model Updates: 3,170
Cumulative Timesteps: 26,558,948

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,323.48902
Policy Entropy: 1.63555
Value Function Loss: 1.34121

Mean KL Divergence: 0.00718
SB3 Clip Fraction: 0.08963
Policy Update Magnitude: 0.43561
Value Function Update Magnitude: 0.25919

Collected Steps per Second: 22,902.63805
Overall Steps per Second: 10,760.25202

Timestep Collection Time: 2.18377
Timestep Consumption Time: 2.46427
PPO Batch Consumption Time: 0.28372
Total Iteration Time: 4.64803

Cumulative Model Updates: 3,176
Cumulative Timesteps: 26,608,962

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 26608962...
Checkpoint 26608962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,030.19561
Policy Entropy: 1.65820
Value Function Loss: 1.38289

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.09994
Policy Update Magnitude: 0.37309
Value Function Update Magnitude: 0.26651

Collected Steps per Second: 22,423.14939
Overall Steps per Second: 10,659.76770

Timestep Collection Time: 2.23011
Timestep Consumption Time: 2.46099
PPO Batch Consumption Time: 0.28399
Total Iteration Time: 4.69110

Cumulative Model Updates: 3,182
Cumulative Timesteps: 26,658,968

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,330.03393
Policy Entropy: 1.65540
Value Function Loss: 1.34573

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.11712
Policy Update Magnitude: 0.31293
Value Function Update Magnitude: 0.26576

Collected Steps per Second: 22,787.46046
Overall Steps per Second: 10,552.19966

Timestep Collection Time: 2.19586
Timestep Consumption Time: 2.54609
PPO Batch Consumption Time: 0.29825
Total Iteration Time: 4.74195

Cumulative Model Updates: 3,188
Cumulative Timesteps: 26,709,006

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 26709006...
Checkpoint 26709006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,677.35924
Policy Entropy: 1.63656
Value Function Loss: 1.41277

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.11096
Policy Update Magnitude: 0.28469
Value Function Update Magnitude: 0.27235

Collected Steps per Second: 22,696.09230
Overall Steps per Second: 10,588.21853

Timestep Collection Time: 2.20382
Timestep Consumption Time: 2.52011
PPO Batch Consumption Time: 0.29919
Total Iteration Time: 4.72393

Cumulative Model Updates: 3,194
Cumulative Timesteps: 26,759,024

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 999.96107
Policy Entropy: 1.63024
Value Function Loss: 1.40831

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.11578
Policy Update Magnitude: 0.30887
Value Function Update Magnitude: 0.27395

Collected Steps per Second: 22,883.63857
Overall Steps per Second: 10,614.98787

Timestep Collection Time: 2.18584
Timestep Consumption Time: 2.52636
PPO Batch Consumption Time: 0.29685
Total Iteration Time: 4.71221

Cumulative Model Updates: 3,200
Cumulative Timesteps: 26,809,044

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 26809044...
Checkpoint 26809044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,057.42349
Policy Entropy: 1.65471
Value Function Loss: 1.44297

Mean KL Divergence: 0.00695
SB3 Clip Fraction: 0.08279
Policy Update Magnitude: 0.35756
Value Function Update Magnitude: 0.28065

Collected Steps per Second: 22,513.98175
Overall Steps per Second: 10,711.15428

Timestep Collection Time: 2.22093
Timestep Consumption Time: 2.44729
PPO Batch Consumption Time: 0.29730
Total Iteration Time: 4.66822

Cumulative Model Updates: 3,206
Cumulative Timesteps: 26,859,046

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,668.38156
Policy Entropy: 1.64811
Value Function Loss: 1.41562

Mean KL Divergence: 0.00659
SB3 Clip Fraction: 0.08015
Policy Update Magnitude: 0.42524
Value Function Update Magnitude: 0.27715

Collected Steps per Second: 23,212.36197
Overall Steps per Second: 10,646.16662

Timestep Collection Time: 2.15437
Timestep Consumption Time: 2.54291
PPO Batch Consumption Time: 0.29688
Total Iteration Time: 4.69728

Cumulative Model Updates: 3,212
Cumulative Timesteps: 26,909,054

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 26909054...
Checkpoint 26909054 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 870.21187
Policy Entropy: 1.64764
Value Function Loss: 1.42246

Mean KL Divergence: 0.00772
SB3 Clip Fraction: 0.09144
Policy Update Magnitude: 0.41573
Value Function Update Magnitude: 0.28041

Collected Steps per Second: 22,827.47924
Overall Steps per Second: 10,666.84866

Timestep Collection Time: 2.19104
Timestep Consumption Time: 2.49788
PPO Batch Consumption Time: 0.28917
Total Iteration Time: 4.68892

Cumulative Model Updates: 3,218
Cumulative Timesteps: 26,959,070

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,047.04609
Policy Entropy: 1.64109
Value Function Loss: 1.45416

Mean KL Divergence: 0.00737
SB3 Clip Fraction: 0.09221
Policy Update Magnitude: 0.38638
Value Function Update Magnitude: 0.27984

Collected Steps per Second: 22,780.00533
Overall Steps per Second: 10,572.89328

Timestep Collection Time: 2.19491
Timestep Consumption Time: 2.53417
PPO Batch Consumption Time: 0.29706
Total Iteration Time: 4.72907

Cumulative Model Updates: 3,224
Cumulative Timesteps: 27,009,070

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 27009070...
Checkpoint 27009070 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 972.58214
Policy Entropy: 1.65859
Value Function Loss: 1.45509

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.10121
Policy Update Magnitude: 0.33317
Value Function Update Magnitude: 0.30285

Collected Steps per Second: 22,724.64289
Overall Steps per Second: 10,563.34451

Timestep Collection Time: 2.20113
Timestep Consumption Time: 2.53411
PPO Batch Consumption Time: 0.29914
Total Iteration Time: 4.73524

Cumulative Model Updates: 3,230
Cumulative Timesteps: 27,059,090

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,201.38642
Policy Entropy: 1.66900
Value Function Loss: 1.41347

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.09482
Policy Update Magnitude: 0.30211
Value Function Update Magnitude: 0.30424

Collected Steps per Second: 23,116.20129
Overall Steps per Second: 10,853.68287

Timestep Collection Time: 2.16368
Timestep Consumption Time: 2.44453
PPO Batch Consumption Time: 0.28436
Total Iteration Time: 4.60821

Cumulative Model Updates: 3,236
Cumulative Timesteps: 27,109,106

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 27109106...
Checkpoint 27109106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 973.28149
Policy Entropy: 1.68381
Value Function Loss: 1.42394

Mean KL Divergence: 0.00549
SB3 Clip Fraction: 0.06325
Policy Update Magnitude: 0.38269
Value Function Update Magnitude: 0.31478

Collected Steps per Second: 22,626.82467
Overall Steps per Second: 10,715.82105

Timestep Collection Time: 2.21012
Timestep Consumption Time: 2.45662
PPO Batch Consumption Time: 0.29835
Total Iteration Time: 4.66674

Cumulative Model Updates: 3,242
Cumulative Timesteps: 27,159,114

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,362.70532
Policy Entropy: 1.67134
Value Function Loss: 1.40313

Mean KL Divergence: 0.00701
SB3 Clip Fraction: 0.08610
Policy Update Magnitude: 0.41192
Value Function Update Magnitude: 0.30104

Collected Steps per Second: 22,336.31933
Overall Steps per Second: 10,812.11676

Timestep Collection Time: 2.23878
Timestep Consumption Time: 2.38622
PPO Batch Consumption Time: 0.28375
Total Iteration Time: 4.62500

Cumulative Model Updates: 3,248
Cumulative Timesteps: 27,209,120

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 27209120...
Checkpoint 27209120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,295.63598
Policy Entropy: 1.67732
Value Function Loss: 1.38305

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.10917
Policy Update Magnitude: 0.35641
Value Function Update Magnitude: 0.30460

Collected Steps per Second: 22,337.53031
Overall Steps per Second: 10,646.93942

Timestep Collection Time: 2.23883
Timestep Consumption Time: 2.45829
PPO Batch Consumption Time: 0.28420
Total Iteration Time: 4.69712

Cumulative Model Updates: 3,254
Cumulative Timesteps: 27,259,130

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,508.71440
Policy Entropy: 1.65781
Value Function Loss: 1.38536

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.10177
Policy Update Magnitude: 0.29181
Value Function Update Magnitude: 0.29847

Collected Steps per Second: 22,700.12864
Overall Steps per Second: 10,539.27429

Timestep Collection Time: 2.20281
Timestep Consumption Time: 2.54173
PPO Batch Consumption Time: 0.29784
Total Iteration Time: 4.74454

Cumulative Model Updates: 3,260
Cumulative Timesteps: 27,309,134

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 27309134...
Checkpoint 27309134 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,238.25672
Policy Entropy: 1.65916
Value Function Loss: 1.38311

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.09890
Policy Update Magnitude: 0.27051
Value Function Update Magnitude: 0.29516

Collected Steps per Second: 22,774.64541
Overall Steps per Second: 10,600.50343

Timestep Collection Time: 2.19665
Timestep Consumption Time: 2.52275
PPO Batch Consumption Time: 0.29455
Total Iteration Time: 4.71940

Cumulative Model Updates: 3,266
Cumulative Timesteps: 27,359,162

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 812.24054
Policy Entropy: 1.66184
Value Function Loss: 1.40194

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.08986
Policy Update Magnitude: 0.28739
Value Function Update Magnitude: 0.28740

Collected Steps per Second: 22,884.31828
Overall Steps per Second: 10,604.02573

Timestep Collection Time: 2.18525
Timestep Consumption Time: 2.53069
PPO Batch Consumption Time: 0.29608
Total Iteration Time: 4.71594

Cumulative Model Updates: 3,272
Cumulative Timesteps: 27,409,170

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 27409170...
Checkpoint 27409170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,139.30795
Policy Entropy: 1.65320
Value Function Loss: 1.36171

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.08601
Policy Update Magnitude: 0.30070
Value Function Update Magnitude: 0.30758

Collected Steps per Second: 22,751.96316
Overall Steps per Second: 10,653.39873

Timestep Collection Time: 2.19840
Timestep Consumption Time: 2.49662
PPO Batch Consumption Time: 0.29513
Total Iteration Time: 4.69503

Cumulative Model Updates: 3,278
Cumulative Timesteps: 27,459,188

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,931.88934
Policy Entropy: 1.65536
Value Function Loss: 1.34944

Mean KL Divergence: 0.00738
SB3 Clip Fraction: 0.08575
Policy Update Magnitude: 0.32620
Value Function Update Magnitude: 0.30887

Collected Steps per Second: 22,538.21671
Overall Steps per Second: 10,726.06224

Timestep Collection Time: 2.21908
Timestep Consumption Time: 2.44377
PPO Batch Consumption Time: 0.28523
Total Iteration Time: 4.66285

Cumulative Model Updates: 3,284
Cumulative Timesteps: 27,509,202

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 27509202...
Checkpoint 27509202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,184.12808
Policy Entropy: 1.64977
Value Function Loss: 1.34593

Mean KL Divergence: 0.00678
SB3 Clip Fraction: 0.07822
Policy Update Magnitude: 0.33018
Value Function Update Magnitude: 0.30547

Collected Steps per Second: 22,519.91593
Overall Steps per Second: 10,693.00724

Timestep Collection Time: 2.22150
Timestep Consumption Time: 2.45707
PPO Batch Consumption Time: 0.29651
Total Iteration Time: 4.67857

Cumulative Model Updates: 3,290
Cumulative Timesteps: 27,559,230

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 644.43416
Policy Entropy: 1.63780
Value Function Loss: 1.32996

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.11175
Policy Update Magnitude: 0.31641
Value Function Update Magnitude: 0.30139

Collected Steps per Second: 22,981.80621
Overall Steps per Second: 10,820.90802

Timestep Collection Time: 2.17685
Timestep Consumption Time: 2.44642
PPO Batch Consumption Time: 0.28361
Total Iteration Time: 4.62327

Cumulative Model Updates: 3,296
Cumulative Timesteps: 27,609,258

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 27609258...
Checkpoint 27609258 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,342.40075
Policy Entropy: 1.65162
Value Function Loss: 1.31133

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.10285
Policy Update Magnitude: 0.30220
Value Function Update Magnitude: 0.29032

Collected Steps per Second: 22,932.30462
Overall Steps per Second: 10,711.93679

Timestep Collection Time: 2.18059
Timestep Consumption Time: 2.48766
PPO Batch Consumption Time: 0.29044
Total Iteration Time: 4.66825

Cumulative Model Updates: 3,302
Cumulative Timesteps: 27,659,264

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,255.97060
Policy Entropy: 1.62130
Value Function Loss: 1.30570

Mean KL Divergence: 0.01086
SB3 Clip Fraction: 0.11105
Policy Update Magnitude: 0.31661
Value Function Update Magnitude: 0.29649

Collected Steps per Second: 22,549.22434
Overall Steps per Second: 10,541.38664

Timestep Collection Time: 2.21861
Timestep Consumption Time: 2.52725
PPO Batch Consumption Time: 0.29704
Total Iteration Time: 4.74587

Cumulative Model Updates: 3,308
Cumulative Timesteps: 27,709,292

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 27709292...
Checkpoint 27709292 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,004.28131
Policy Entropy: 1.63894
Value Function Loss: 1.30239

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.10369
Policy Update Magnitude: 0.34551
Value Function Update Magnitude: 0.31395

Collected Steps per Second: 22,922.54994
Overall Steps per Second: 10,637.37363

Timestep Collection Time: 2.18143
Timestep Consumption Time: 2.51935
PPO Batch Consumption Time: 0.29689
Total Iteration Time: 4.70078

Cumulative Model Updates: 3,314
Cumulative Timesteps: 27,759,296

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,281.08206
Policy Entropy: 1.62703
Value Function Loss: 1.33498

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.11047
Policy Update Magnitude: 0.34207
Value Function Update Magnitude: 0.32080

Collected Steps per Second: 22,590.88220
Overall Steps per Second: 10,738.79873

Timestep Collection Time: 2.21381
Timestep Consumption Time: 2.44332
PPO Batch Consumption Time: 0.28378
Total Iteration Time: 4.65713

Cumulative Model Updates: 3,320
Cumulative Timesteps: 27,809,308

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 27809308...
Checkpoint 27809308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 841.12124
Policy Entropy: 1.65234
Value Function Loss: 1.27481

Mean KL Divergence: 0.01245
SB3 Clip Fraction: 0.13447
Policy Update Magnitude: 0.32158
Value Function Update Magnitude: 0.35254

Collected Steps per Second: 22,660.08580
Overall Steps per Second: 10,701.52746

Timestep Collection Time: 2.20670
Timestep Consumption Time: 2.46590
PPO Batch Consumption Time: 0.28971
Total Iteration Time: 4.67260

Cumulative Model Updates: 3,326
Cumulative Timesteps: 27,859,312

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,016.30581
Policy Entropy: 1.66537
Value Function Loss: 1.23821

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.09863
Policy Update Magnitude: 0.31211
Value Function Update Magnitude: 0.46198

Collected Steps per Second: 22,989.92774
Overall Steps per Second: 10,818.48783

Timestep Collection Time: 2.17600
Timestep Consumption Time: 2.44812
PPO Batch Consumption Time: 0.28410
Total Iteration Time: 4.62412

Cumulative Model Updates: 3,332
Cumulative Timesteps: 27,909,338

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 27909338...
Checkpoint 27909338 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,505.38553
Policy Entropy: 1.66521
Value Function Loss: 1.18429

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.08366
Policy Update Magnitude: 0.32188
Value Function Update Magnitude: 0.49212

Collected Steps per Second: 22,895.09088
Overall Steps per Second: 10,734.29370

Timestep Collection Time: 2.18518
Timestep Consumption Time: 2.47558
PPO Batch Consumption Time: 0.28943
Total Iteration Time: 4.66076

Cumulative Model Updates: 3,338
Cumulative Timesteps: 27,959,368

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,507.58854
Policy Entropy: 1.64682
Value Function Loss: 1.15824

Mean KL Divergence: 0.00753
SB3 Clip Fraction: 0.08797
Policy Update Magnitude: 0.34967
Value Function Update Magnitude: 0.51163

Collected Steps per Second: 23,048.68687
Overall Steps per Second: 10,878.74647

Timestep Collection Time: 2.17054
Timestep Consumption Time: 2.42816
PPO Batch Consumption Time: 0.28958
Total Iteration Time: 4.59869

Cumulative Model Updates: 3,344
Cumulative Timesteps: 28,009,396

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 28009396...
Checkpoint 28009396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,307.85206
Policy Entropy: 1.65141
Value Function Loss: 1.18379

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.09645
Policy Update Magnitude: 0.33439
Value Function Update Magnitude: 0.52657

Collected Steps per Second: 22,320.53017
Overall Steps per Second: 10,676.93797

Timestep Collection Time: 2.24108
Timestep Consumption Time: 2.44398
PPO Batch Consumption Time: 0.29424
Total Iteration Time: 4.68505

Cumulative Model Updates: 3,350
Cumulative Timesteps: 28,059,418

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,202.55168
Policy Entropy: 1.64956
Value Function Loss: 1.17550

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.10943
Policy Update Magnitude: 0.28994
Value Function Update Magnitude: 0.44826

Collected Steps per Second: 22,775.18729
Overall Steps per Second: 10,601.57443

Timestep Collection Time: 2.19757
Timestep Consumption Time: 2.52343
PPO Batch Consumption Time: 0.29565
Total Iteration Time: 4.72100

Cumulative Model Updates: 3,356
Cumulative Timesteps: 28,109,468

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 28109468...
Checkpoint 28109468 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,294.94971
Policy Entropy: 1.64416
Value Function Loss: 1.15453

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.10180
Policy Update Magnitude: 0.29038
Value Function Update Magnitude: 0.48283

Collected Steps per Second: 22,977.74528
Overall Steps per Second: 10,690.52746

Timestep Collection Time: 2.17698
Timestep Consumption Time: 2.50212
PPO Batch Consumption Time: 0.29420
Total Iteration Time: 4.67910

Cumulative Model Updates: 3,362
Cumulative Timesteps: 28,159,490

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,234.44530
Policy Entropy: 1.63183
Value Function Loss: 1.12234

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.09834
Policy Update Magnitude: 0.30476
Value Function Update Magnitude: 0.51129

Collected Steps per Second: 22,775.52997
Overall Steps per Second: 10,755.49448

Timestep Collection Time: 2.19666
Timestep Consumption Time: 2.45492
PPO Batch Consumption Time: 0.28256
Total Iteration Time: 4.65158

Cumulative Model Updates: 3,368
Cumulative Timesteps: 28,209,520

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 28209520...
Checkpoint 28209520 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,977.10721
Policy Entropy: 1.63400
Value Function Loss: 1.13489

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.10224
Policy Update Magnitude: 0.35194
Value Function Update Magnitude: 0.49823

Collected Steps per Second: 22,784.16109
Overall Steps per Second: 10,618.73275

Timestep Collection Time: 2.19565
Timestep Consumption Time: 2.51546
PPO Batch Consumption Time: 0.29417
Total Iteration Time: 4.71111

Cumulative Model Updates: 3,374
Cumulative Timesteps: 28,259,546

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,129.59480
Policy Entropy: 1.61821
Value Function Loss: 1.11711

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.09263
Policy Update Magnitude: 0.32287
Value Function Update Magnitude: 0.49929

Collected Steps per Second: 23,117.82819
Overall Steps per Second: 10,844.77869

Timestep Collection Time: 2.16396
Timestep Consumption Time: 2.44895
PPO Batch Consumption Time: 0.28435
Total Iteration Time: 4.61291

Cumulative Model Updates: 3,380
Cumulative Timesteps: 28,309,572

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 28309572...
Checkpoint 28309572 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,557.87706
Policy Entropy: 1.63239
Value Function Loss: 1.10309

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.09457
Policy Update Magnitude: 0.29343
Value Function Update Magnitude: 0.60112

Collected Steps per Second: 22,119.26260
Overall Steps per Second: 10,560.86242

Timestep Collection Time: 2.26102
Timestep Consumption Time: 2.47458
PPO Batch Consumption Time: 0.28598
Total Iteration Time: 4.73560

Cumulative Model Updates: 3,386
Cumulative Timesteps: 28,359,584

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,770.06267
Policy Entropy: 1.63719
Value Function Loss: 1.09121

Mean KL Divergence: 0.00623
SB3 Clip Fraction: 0.07546
Policy Update Magnitude: 0.29360
Value Function Update Magnitude: 0.55863

Collected Steps per Second: 22,769.77244
Overall Steps per Second: 10,610.23599

Timestep Collection Time: 2.19686
Timestep Consumption Time: 2.51764
PPO Batch Consumption Time: 0.29803
Total Iteration Time: 4.71450

Cumulative Model Updates: 3,392
Cumulative Timesteps: 28,409,606

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 28409606...
Checkpoint 28409606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,328.09277
Policy Entropy: 1.64441
Value Function Loss: 1.10829

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.11321
Policy Update Magnitude: 0.29505
Value Function Update Magnitude: 0.44865

Collected Steps per Second: 22,822.54884
Overall Steps per Second: 10,846.39715

Timestep Collection Time: 2.19169
Timestep Consumption Time: 2.41998
PPO Batch Consumption Time: 0.29288
Total Iteration Time: 4.61167

Cumulative Model Updates: 3,398
Cumulative Timesteps: 28,459,626

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,673.76501
Policy Entropy: 1.63759
Value Function Loss: 1.11624

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.10031
Policy Update Magnitude: 0.27920
Value Function Update Magnitude: 0.47116

Collected Steps per Second: 22,539.28289
Overall Steps per Second: 10,665.33422

Timestep Collection Time: 2.21941
Timestep Consumption Time: 2.47092
PPO Batch Consumption Time: 0.29708
Total Iteration Time: 4.69034

Cumulative Model Updates: 3,404
Cumulative Timesteps: 28,509,650

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 28509650...
Checkpoint 28509650 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,191.14710
Policy Entropy: 1.63366
Value Function Loss: 1.10038

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.09721
Policy Update Magnitude: 0.28663
Value Function Update Magnitude: 0.51328

Collected Steps per Second: 23,062.50919
Overall Steps per Second: 10,669.18635

Timestep Collection Time: 2.16837
Timestep Consumption Time: 2.51878
PPO Batch Consumption Time: 0.29566
Total Iteration Time: 4.68714

Cumulative Model Updates: 3,410
Cumulative Timesteps: 28,559,658

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,142.73334
Policy Entropy: 1.61764
Value Function Loss: 1.12525

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.09514
Policy Update Magnitude: 0.31986
Value Function Update Magnitude: 0.55230

Collected Steps per Second: 22,939.26701
Overall Steps per Second: 10,682.08008

Timestep Collection Time: 2.17967
Timestep Consumption Time: 2.50107
PPO Batch Consumption Time: 0.29236
Total Iteration Time: 4.68074

Cumulative Model Updates: 3,416
Cumulative Timesteps: 28,609,658

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 28609658...
Checkpoint 28609658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,686.09264
Policy Entropy: 1.62912
Value Function Loss: 1.12331

Mean KL Divergence: 0.01672
SB3 Clip Fraction: 0.16183
Policy Update Magnitude: 0.30095
Value Function Update Magnitude: 0.50986

Collected Steps per Second: 22,982.84563
Overall Steps per Second: 10,830.26542

Timestep Collection Time: 2.17614
Timestep Consumption Time: 2.44184
PPO Batch Consumption Time: 0.28363
Total Iteration Time: 4.61798

Cumulative Model Updates: 3,422
Cumulative Timesteps: 28,659,672

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,184.90006
Policy Entropy: 1.63697
Value Function Loss: 1.15730

Mean KL Divergence: 0.01081
SB3 Clip Fraction: 0.12166
Policy Update Magnitude: 0.29531
Value Function Update Magnitude: 0.52788

Collected Steps per Second: 22,821.11940
Overall Steps per Second: 10,586.92752

Timestep Collection Time: 2.19279
Timestep Consumption Time: 2.53398
PPO Batch Consumption Time: 0.29709
Total Iteration Time: 4.72677

Cumulative Model Updates: 3,428
Cumulative Timesteps: 28,709,714

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 28709714...
Checkpoint 28709714 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,629.50328
Policy Entropy: 1.62947
Value Function Loss: 1.10570

Mean KL Divergence: 0.00683
SB3 Clip Fraction: 0.07993
Policy Update Magnitude: 0.31881
Value Function Update Magnitude: 0.56111

Collected Steps per Second: 22,841.02899
Overall Steps per Second: 10,572.45463

Timestep Collection Time: 2.19027
Timestep Consumption Time: 2.54165
PPO Batch Consumption Time: 0.29880
Total Iteration Time: 4.73192

Cumulative Model Updates: 3,434
Cumulative Timesteps: 28,759,742

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 835.80761
Policy Entropy: 1.63456
Value Function Loss: 1.13768

Mean KL Divergence: 0.00660
SB3 Clip Fraction: 0.08131
Policy Update Magnitude: 0.31435
Value Function Update Magnitude: 0.48297

Collected Steps per Second: 23,038.74423
Overall Steps per Second: 10,859.38777

Timestep Collection Time: 2.17130
Timestep Consumption Time: 2.43522
PPO Batch Consumption Time: 0.28417
Total Iteration Time: 4.60652

Cumulative Model Updates: 3,440
Cumulative Timesteps: 28,809,766

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 28809766...
Checkpoint 28809766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 972.67594
Policy Entropy: 1.62680
Value Function Loss: 1.12900

Mean KL Divergence: 0.00571
SB3 Clip Fraction: 0.06761
Policy Update Magnitude: 0.34744
Value Function Update Magnitude: 0.44298

Collected Steps per Second: 22,535.23107
Overall Steps per Second: 10,706.18107

Timestep Collection Time: 2.21919
Timestep Consumption Time: 2.45194
PPO Batch Consumption Time: 0.29844
Total Iteration Time: 4.67113

Cumulative Model Updates: 3,446
Cumulative Timesteps: 28,859,776

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,777.25882
Policy Entropy: 1.61974
Value Function Loss: 1.16822

Mean KL Divergence: 0.00588
SB3 Clip Fraction: 0.07133
Policy Update Magnitude: 0.39849
Value Function Update Magnitude: 0.45172

Collected Steps per Second: 22,449.11750
Overall Steps per Second: 10,828.10878

Timestep Collection Time: 2.22860
Timestep Consumption Time: 2.39179
PPO Batch Consumption Time: 0.28443
Total Iteration Time: 4.62038

Cumulative Model Updates: 3,452
Cumulative Timesteps: 28,909,806

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 28909806...
Checkpoint 28909806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,169.78805
Policy Entropy: 1.61952
Value Function Loss: 1.13815

Mean KL Divergence: 0.00633
SB3 Clip Fraction: 0.07876
Policy Update Magnitude: 0.37537
Value Function Update Magnitude: 0.42671

Collected Steps per Second: 22,143.99137
Overall Steps per Second: 10,689.83459

Timestep Collection Time: 2.25867
Timestep Consumption Time: 2.42017
PPO Batch Consumption Time: 0.28890
Total Iteration Time: 4.67884

Cumulative Model Updates: 3,458
Cumulative Timesteps: 28,959,822

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,028.88303
Policy Entropy: 1.60159
Value Function Loss: 1.14291

Mean KL Divergence: 0.00606
SB3 Clip Fraction: 0.07361
Policy Update Magnitude: 0.38744
Value Function Update Magnitude: 0.40050

Collected Steps per Second: 23,055.85034
Overall Steps per Second: 10,745.43495

Timestep Collection Time: 2.16908
Timestep Consumption Time: 2.48499
PPO Batch Consumption Time: 0.28866
Total Iteration Time: 4.65407

Cumulative Model Updates: 3,464
Cumulative Timesteps: 29,009,832

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 29009832...
Checkpoint 29009832 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,943.33112
Policy Entropy: 1.59663
Value Function Loss: 1.10693

Mean KL Divergence: 0.00697
SB3 Clip Fraction: 0.08410
Policy Update Magnitude: 0.32577
Value Function Update Magnitude: 0.40533

Collected Steps per Second: 22,715.48005
Overall Steps per Second: 10,746.12756

Timestep Collection Time: 2.20264
Timestep Consumption Time: 2.45336
PPO Batch Consumption Time: 0.28425
Total Iteration Time: 4.65600

Cumulative Model Updates: 3,470
Cumulative Timesteps: 29,059,866

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,559.78149
Policy Entropy: 1.59885
Value Function Loss: 1.12044

Mean KL Divergence: 0.00672
SB3 Clip Fraction: 0.07937
Policy Update Magnitude: 0.29659
Value Function Update Magnitude: 0.38551

Collected Steps per Second: 22,698.68577
Overall Steps per Second: 10,525.68514

Timestep Collection Time: 2.20356
Timestep Consumption Time: 2.54843
PPO Batch Consumption Time: 0.29885
Total Iteration Time: 4.75199

Cumulative Model Updates: 3,476
Cumulative Timesteps: 29,109,884

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 29109884...
Checkpoint 29109884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,210.61077
Policy Entropy: 1.58326
Value Function Loss: 1.10534

Mean KL Divergence: 0.00599
SB3 Clip Fraction: 0.07066
Policy Update Magnitude: 0.33920
Value Function Update Magnitude: 0.39011

Collected Steps per Second: 22,779.32141
Overall Steps per Second: 10,628.18527

Timestep Collection Time: 2.19497
Timestep Consumption Time: 2.50950
PPO Batch Consumption Time: 0.28998
Total Iteration Time: 4.70447

Cumulative Model Updates: 3,482
Cumulative Timesteps: 29,159,884

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,647.43072
Policy Entropy: 1.58798
Value Function Loss: 1.09453

Mean KL Divergence: 0.00692
SB3 Clip Fraction: 0.08348
Policy Update Magnitude: 0.34672
Value Function Update Magnitude: 0.39179

Collected Steps per Second: 22,650.03919
Overall Steps per Second: 10,538.57312

Timestep Collection Time: 2.20883
Timestep Consumption Time: 2.53850
PPO Batch Consumption Time: 0.29740
Total Iteration Time: 4.74732

Cumulative Model Updates: 3,488
Cumulative Timesteps: 29,209,914

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 29209914...
Checkpoint 29209914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,404.04239
Policy Entropy: 1.57577
Value Function Loss: 1.07033

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.09899
Policy Update Magnitude: 0.32106
Value Function Update Magnitude: 0.38091

Collected Steps per Second: 22,909.97766
Overall Steps per Second: 10,680.74031

Timestep Collection Time: 2.18272
Timestep Consumption Time: 2.49917
PPO Batch Consumption Time: 0.29624
Total Iteration Time: 4.68189

Cumulative Model Updates: 3,494
Cumulative Timesteps: 29,259,920

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,459.04119
Policy Entropy: 1.55744
Value Function Loss: 1.05181

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.11053
Policy Update Magnitude: 0.27201
Value Function Update Magnitude: 0.40918

Collected Steps per Second: 22,826.42701
Overall Steps per Second: 10,755.08059

Timestep Collection Time: 2.19114
Timestep Consumption Time: 2.45931
PPO Batch Consumption Time: 0.28510
Total Iteration Time: 4.65045

Cumulative Model Updates: 3,500
Cumulative Timesteps: 29,309,936

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 29309936...
Checkpoint 29309936 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,147.41277
Policy Entropy: 1.56777
Value Function Loss: 1.03741

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.11276
Policy Update Magnitude: 0.25351
Value Function Update Magnitude: 0.38996

Collected Steps per Second: 22,814.35851
Overall Steps per Second: 10,634.13038

Timestep Collection Time: 2.19300
Timestep Consumption Time: 2.51185
PPO Batch Consumption Time: 0.29555
Total Iteration Time: 4.70485

Cumulative Model Updates: 3,506
Cumulative Timesteps: 29,359,968

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,577.72495
Policy Entropy: 1.54674
Value Function Loss: 1.05996

Mean KL Divergence: 0.00664
SB3 Clip Fraction: 0.08059
Policy Update Magnitude: 0.31356
Value Function Update Magnitude: 0.36473

Collected Steps per Second: 22,610.17964
Overall Steps per Second: 10,883.60492

Timestep Collection Time: 2.21201
Timestep Consumption Time: 2.38334
PPO Batch Consumption Time: 0.28453
Total Iteration Time: 4.59535

Cumulative Model Updates: 3,512
Cumulative Timesteps: 29,409,982

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 29409982...
Checkpoint 29409982 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,279.58759
Policy Entropy: 1.53034
Value Function Loss: 1.04085

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.09318
Policy Update Magnitude: 0.35078
Value Function Update Magnitude: 0.41213

Collected Steps per Second: 22,064.92382
Overall Steps per Second: 10,696.08315

Timestep Collection Time: 2.26713
Timestep Consumption Time: 2.40972
PPO Batch Consumption Time: 0.28758
Total Iteration Time: 4.67685

Cumulative Model Updates: 3,518
Cumulative Timesteps: 29,460,006

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,464.37965
Policy Entropy: 1.53129
Value Function Loss: 1.04050

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.09339
Policy Update Magnitude: 0.35422
Value Function Update Magnitude: 0.42182

Collected Steps per Second: 22,639.13019
Overall Steps per Second: 10,540.83161

Timestep Collection Time: 2.20936
Timestep Consumption Time: 2.53581
PPO Batch Consumption Time: 0.29743
Total Iteration Time: 4.74517

Cumulative Model Updates: 3,524
Cumulative Timesteps: 29,510,024

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 29510024...
Checkpoint 29510024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,690.45531
Policy Entropy: 1.51531
Value Function Loss: 1.00297

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.09852
Policy Update Magnitude: 0.30574
Value Function Update Magnitude: 0.39667

Collected Steps per Second: 22,974.27299
Overall Steps per Second: 10,615.36086

Timestep Collection Time: 2.17678
Timestep Consumption Time: 2.53431
PPO Batch Consumption Time: 0.29819
Total Iteration Time: 4.71110

Cumulative Model Updates: 3,530
Cumulative Timesteps: 29,560,034

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,250.15314
Policy Entropy: 1.52471
Value Function Loss: 1.09694

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.09150
Policy Update Magnitude: 0.30285
Value Function Update Magnitude: 0.36579

Collected Steps per Second: 22,648.15274
Overall Steps per Second: 10,536.16142

Timestep Collection Time: 2.20804
Timestep Consumption Time: 2.53828
PPO Batch Consumption Time: 0.29749
Total Iteration Time: 4.74632

Cumulative Model Updates: 3,536
Cumulative Timesteps: 29,610,042

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 29610042...
Checkpoint 29610042 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,234.45182
Policy Entropy: 1.49945
Value Function Loss: 1.09494

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.09897
Policy Update Magnitude: 0.32169
Value Function Update Magnitude: 0.37657

Collected Steps per Second: 22,675.86034
Overall Steps per Second: 10,569.20148

Timestep Collection Time: 2.20543
Timestep Consumption Time: 2.52624
PPO Batch Consumption Time: 0.29221
Total Iteration Time: 4.73167

Cumulative Model Updates: 3,542
Cumulative Timesteps: 29,660,052

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,579.24464
Policy Entropy: 1.49124
Value Function Loss: 1.11827

Mean KL Divergence: 0.00749
SB3 Clip Fraction: 0.08990
Policy Update Magnitude: 0.31150
Value Function Update Magnitude: 0.39741

Collected Steps per Second: 22,408.44445
Overall Steps per Second: 10,599.92754

Timestep Collection Time: 2.23166
Timestep Consumption Time: 2.48611
PPO Batch Consumption Time: 0.29393
Total Iteration Time: 4.71777

Cumulative Model Updates: 3,548
Cumulative Timesteps: 29,710,060

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 29710060...
Checkpoint 29710060 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,105.34508
Policy Entropy: 1.48168
Value Function Loss: 1.02199

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.09362
Policy Update Magnitude: 0.29589
Value Function Update Magnitude: 0.38999

Collected Steps per Second: 23,040.78371
Overall Steps per Second: 10,857.11072

Timestep Collection Time: 2.17093
Timestep Consumption Time: 2.43619
PPO Batch Consumption Time: 0.28358
Total Iteration Time: 4.60712

Cumulative Model Updates: 3,554
Cumulative Timesteps: 29,760,080

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,504.02249
Policy Entropy: 1.47303
Value Function Loss: 1.01902

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.10432
Policy Update Magnitude: 0.28823
Value Function Update Magnitude: 0.37816

Collected Steps per Second: 22,042.50268
Overall Steps per Second: 10,525.42061

Timestep Collection Time: 2.26844
Timestep Consumption Time: 2.48216
PPO Batch Consumption Time: 0.29056
Total Iteration Time: 4.75059

Cumulative Model Updates: 3,560
Cumulative Timesteps: 29,810,082

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 29810082...
Checkpoint 29810082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 954.17100
Policy Entropy: 1.47263
Value Function Loss: 1.03191

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.09762
Policy Update Magnitude: 0.25189
Value Function Update Magnitude: 0.36091

Collected Steps per Second: 22,762.49696
Overall Steps per Second: 10,809.60310

Timestep Collection Time: 2.19774
Timestep Consumption Time: 2.43018
PPO Batch Consumption Time: 0.29483
Total Iteration Time: 4.62792

Cumulative Model Updates: 3,566
Cumulative Timesteps: 29,860,108

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 813.58576
Policy Entropy: 1.47109
Value Function Loss: 1.09794

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.09112
Policy Update Magnitude: 0.26400
Value Function Update Magnitude: 0.38630

Collected Steps per Second: 22,222.79485
Overall Steps per Second: 10,771.29445

Timestep Collection Time: 2.25084
Timestep Consumption Time: 2.39298
PPO Batch Consumption Time: 0.28286
Total Iteration Time: 4.64382

Cumulative Model Updates: 3,572
Cumulative Timesteps: 29,910,128

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 29910128...
Checkpoint 29910128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,673.03548
Policy Entropy: 1.45968
Value Function Loss: 1.07172

Mean KL Divergence: 0.00737
SB3 Clip Fraction: 0.08402
Policy Update Magnitude: 0.25715
Value Function Update Magnitude: 0.38531

Collected Steps per Second: 22,845.30231
Overall Steps per Second: 10,598.39045

Timestep Collection Time: 2.18986
Timestep Consumption Time: 2.53048
PPO Batch Consumption Time: 0.29649
Total Iteration Time: 4.72034

Cumulative Model Updates: 3,578
Cumulative Timesteps: 29,960,156

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 974.89210
Policy Entropy: 1.44909
Value Function Loss: 1.08899

Mean KL Divergence: 0.00735
SB3 Clip Fraction: 0.08560
Policy Update Magnitude: 0.28265
Value Function Update Magnitude: 0.39370

Collected Steps per Second: 22,692.41935
Overall Steps per Second: 10,578.12638

Timestep Collection Time: 2.20391
Timestep Consumption Time: 2.52396
PPO Batch Consumption Time: 0.29706
Total Iteration Time: 4.72787

Cumulative Model Updates: 3,584
Cumulative Timesteps: 30,010,168

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 30010168...
Checkpoint 30010168 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,193.90771
Policy Entropy: 1.45340
Value Function Loss: 1.09882

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.09212
Policy Update Magnitude: 0.30396
Value Function Update Magnitude: 0.49013

Collected Steps per Second: 22,728.56071
Overall Steps per Second: 10,550.22708

Timestep Collection Time: 2.20040
Timestep Consumption Time: 2.53997
PPO Batch Consumption Time: 0.29845
Total Iteration Time: 4.74037

Cumulative Model Updates: 3,590
Cumulative Timesteps: 30,060,180

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,169.03146
Policy Entropy: 1.44538
Value Function Loss: 1.10612

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.09870
Policy Update Magnitude: 0.29937
Value Function Update Magnitude: 0.49296

Collected Steps per Second: 22,917.52838
Overall Steps per Second: 10,627.33262

Timestep Collection Time: 2.18243
Timestep Consumption Time: 2.52392
PPO Batch Consumption Time: 0.29222
Total Iteration Time: 4.70636

Cumulative Model Updates: 3,596
Cumulative Timesteps: 30,110,196

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 30110196...
Checkpoint 30110196 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,693.21527
Policy Entropy: 1.45623
Value Function Loss: 1.08999

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.10216
Policy Update Magnitude: 0.29542
Value Function Update Magnitude: 0.48850

Collected Steps per Second: 22,849.86068
Overall Steps per Second: 10,641.36465

Timestep Collection Time: 2.18898
Timestep Consumption Time: 2.51135
PPO Batch Consumption Time: 0.29316
Total Iteration Time: 4.70034

Cumulative Model Updates: 3,602
Cumulative Timesteps: 30,160,214

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,330.72200
Policy Entropy: 1.40907
Value Function Loss: 1.03958

Mean KL Divergence: 0.01084
SB3 Clip Fraction: 0.11020
Policy Update Magnitude: 0.25441
Value Function Update Magnitude: 0.47053

Collected Steps per Second: 22,765.60594
Overall Steps per Second: 10,727.18899

Timestep Collection Time: 2.19665
Timestep Consumption Time: 2.46515
PPO Batch Consumption Time: 0.28323
Total Iteration Time: 4.66180

Cumulative Model Updates: 3,608
Cumulative Timesteps: 30,210,222

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 30210222...
Checkpoint 30210222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 772.74264
Policy Entropy: 1.40498
Value Function Loss: 1.08115

Mean KL Divergence: 0.01057
SB3 Clip Fraction: 0.10620
Policy Update Magnitude: 0.22579
Value Function Update Magnitude: 0.49155

Collected Steps per Second: 22,395.12890
Overall Steps per Second: 10,623.49558

Timestep Collection Time: 2.23325
Timestep Consumption Time: 2.47461
PPO Batch Consumption Time: 0.29143
Total Iteration Time: 4.70787

Cumulative Model Updates: 3,614
Cumulative Timesteps: 30,260,236

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,262.22797
Policy Entropy: 1.41235
Value Function Loss: 1.05147

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.10113
Policy Update Magnitude: 0.25779
Value Function Update Magnitude: 0.53893

Collected Steps per Second: 22,941.88945
Overall Steps per Second: 10,625.31907

Timestep Collection Time: 2.17959
Timestep Consumption Time: 2.52652
PPO Batch Consumption Time: 0.29833
Total Iteration Time: 4.70612

Cumulative Model Updates: 3,620
Cumulative Timesteps: 30,310,240

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 30310240...
Checkpoint 30310240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,304.23538
Policy Entropy: 1.42838
Value Function Loss: 1.05934

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.10684
Policy Update Magnitude: 0.24204
Value Function Update Magnitude: 0.49576

Collected Steps per Second: 22,832.99688
Overall Steps per Second: 10,642.56213

Timestep Collection Time: 2.19086
Timestep Consumption Time: 2.50951
PPO Batch Consumption Time: 0.29433
Total Iteration Time: 4.70037

Cumulative Model Updates: 3,626
Cumulative Timesteps: 30,360,264

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,325.95317
Policy Entropy: 1.42365
Value Function Loss: 1.04814

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.09659
Policy Update Magnitude: 0.24503
Value Function Update Magnitude: 0.46613

Collected Steps per Second: 22,683.80167
Overall Steps per Second: 10,760.05625

Timestep Collection Time: 2.20439
Timestep Consumption Time: 2.44280
PPO Batch Consumption Time: 0.28245
Total Iteration Time: 4.64719

Cumulative Model Updates: 3,632
Cumulative Timesteps: 30,410,268

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 30410268...
Checkpoint 30410268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,091.50171
Policy Entropy: 1.41389
Value Function Loss: 1.04472

Mean KL Divergence: 0.01332
SB3 Clip Fraction: 0.12483
Policy Update Magnitude: 0.24464
Value Function Update Magnitude: 0.46801

Collected Steps per Second: 22,265.92710
Overall Steps per Second: 10,630.39135

Timestep Collection Time: 2.24648
Timestep Consumption Time: 2.45890
PPO Batch Consumption Time: 0.29812
Total Iteration Time: 4.70538

Cumulative Model Updates: 3,638
Cumulative Timesteps: 30,460,288

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,394.85548
Policy Entropy: 1.39884
Value Function Loss: 1.03169

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.10292
Policy Update Magnitude: 0.22953
Value Function Update Magnitude: 0.44177

Collected Steps per Second: 22,371.27061
Overall Steps per Second: 10,813.58208

Timestep Collection Time: 2.23599
Timestep Consumption Time: 2.38986
PPO Batch Consumption Time: 0.28381
Total Iteration Time: 4.62585

Cumulative Model Updates: 3,644
Cumulative Timesteps: 30,510,310

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 30510310...
Checkpoint 30510310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,654.89790
Policy Entropy: 1.39549
Value Function Loss: 1.02634

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.10108
Policy Update Magnitude: 0.25638
Value Function Update Magnitude: 0.38570

Collected Steps per Second: 22,464.74447
Overall Steps per Second: 10,675.55062

Timestep Collection Time: 2.22598
Timestep Consumption Time: 2.45818
PPO Batch Consumption Time: 0.28367
Total Iteration Time: 4.68416

Cumulative Model Updates: 3,650
Cumulative Timesteps: 30,560,316

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,110.54280
Policy Entropy: 1.37203
Value Function Loss: 1.04230

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.10221
Policy Update Magnitude: 0.23341
Value Function Update Magnitude: 0.37488

Collected Steps per Second: 22,812.44492
Overall Steps per Second: 10,581.16131

Timestep Collection Time: 2.19214
Timestep Consumption Time: 2.53400
PPO Batch Consumption Time: 0.29679
Total Iteration Time: 4.72614

Cumulative Model Updates: 3,656
Cumulative Timesteps: 30,610,324

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 30610324...
Checkpoint 30610324 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,849.60968
Policy Entropy: 1.36743
Value Function Loss: 1.04396

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.08929
Policy Update Magnitude: 0.24326
Value Function Update Magnitude: 0.37362

Collected Steps per Second: 22,706.37942
Overall Steps per Second: 10,548.58684

Timestep Collection Time: 2.20264
Timestep Consumption Time: 2.53866
PPO Batch Consumption Time: 0.29725
Total Iteration Time: 4.74130

Cumulative Model Updates: 3,662
Cumulative Timesteps: 30,660,338

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,716.02308
Policy Entropy: 1.35317
Value Function Loss: 1.01579

Mean KL Divergence: 0.00723
SB3 Clip Fraction: 0.08556
Policy Update Magnitude: 0.25565
Value Function Update Magnitude: 0.38088

Collected Steps per Second: 22,998.39653
Overall Steps per Second: 10,654.21065

Timestep Collection Time: 2.17572
Timestep Consumption Time: 2.52083
PPO Batch Consumption Time: 0.29355
Total Iteration Time: 4.69655

Cumulative Model Updates: 3,668
Cumulative Timesteps: 30,710,376

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 30710376...
Checkpoint 30710376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,066.69398
Policy Entropy: 1.35653
Value Function Loss: 0.98836

Mean KL Divergence: 0.01061
SB3 Clip Fraction: 0.11749
Policy Update Magnitude: 0.24623
Value Function Update Magnitude: 0.44586

Collected Steps per Second: 22,479.13822
Overall Steps per Second: 10,490.38259

Timestep Collection Time: 2.22446
Timestep Consumption Time: 2.54219
PPO Batch Consumption Time: 0.29844
Total Iteration Time: 4.76665

Cumulative Model Updates: 3,674
Cumulative Timesteps: 30,760,380

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,086.73164
Policy Entropy: 1.36294
Value Function Loss: 0.95337

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.09504
Policy Update Magnitude: 0.23029
Value Function Update Magnitude: 0.40610

Collected Steps per Second: 22,919.84212
Overall Steps per Second: 10,772.67183

Timestep Collection Time: 2.18152
Timestep Consumption Time: 2.45986
PPO Batch Consumption Time: 0.28364
Total Iteration Time: 4.64137

Cumulative Model Updates: 3,680
Cumulative Timesteps: 30,810,380

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 30810380...
Checkpoint 30810380 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,211.54831
Policy Entropy: 1.35775
Value Function Loss: 0.96943

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.09642
Policy Update Magnitude: 0.23740
Value Function Update Magnitude: 0.37142

Collected Steps per Second: 22,422.82718
Overall Steps per Second: 10,638.84789

Timestep Collection Time: 2.23094
Timestep Consumption Time: 2.47107
PPO Batch Consumption Time: 0.28317
Total Iteration Time: 4.70201

Cumulative Model Updates: 3,686
Cumulative Timesteps: 30,860,404

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,053.42111
Policy Entropy: 1.34688
Value Function Loss: 0.96436

Mean KL Divergence: 0.01072
SB3 Clip Fraction: 0.10673
Policy Update Magnitude: 0.24702
Value Function Update Magnitude: 0.35983

Collected Steps per Second: 22,709.96742
Overall Steps per Second: 10,523.44624

Timestep Collection Time: 2.20229
Timestep Consumption Time: 2.55033
PPO Batch Consumption Time: 0.29714
Total Iteration Time: 4.75263

Cumulative Model Updates: 3,692
Cumulative Timesteps: 30,910,418

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 30910418...
Checkpoint 30910418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,834.36783
Policy Entropy: 1.34807
Value Function Loss: 0.98089

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.10480
Policy Update Magnitude: 0.26701
Value Function Update Magnitude: 0.35521

Collected Steps per Second: 22,652.35149
Overall Steps per Second: 10,587.01096

Timestep Collection Time: 2.20789
Timestep Consumption Time: 2.51620
PPO Batch Consumption Time: 0.29607
Total Iteration Time: 4.72409

Cumulative Model Updates: 3,698
Cumulative Timesteps: 30,960,432

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,392.97475
Policy Entropy: 1.33552
Value Function Loss: 0.95128

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.10905
Policy Update Magnitude: 0.23040
Value Function Update Magnitude: 0.34216

Collected Steps per Second: 22,337.42420
Overall Steps per Second: 10,633.05978

Timestep Collection Time: 2.23875
Timestep Consumption Time: 2.46431
PPO Batch Consumption Time: 0.29706
Total Iteration Time: 4.70307

Cumulative Model Updates: 3,704
Cumulative Timesteps: 31,010,440

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 31010440...
Checkpoint 31010440 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 773.51544
Policy Entropy: 1.33352
Value Function Loss: 0.98219

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.09042
Policy Update Magnitude: 0.23546
Value Function Update Magnitude: 0.36986

Collected Steps per Second: 22,118.10786
Overall Steps per Second: 10,759.44140

Timestep Collection Time: 2.26059
Timestep Consumption Time: 2.38649
PPO Batch Consumption Time: 0.28625
Total Iteration Time: 4.64708

Cumulative Model Updates: 3,710
Cumulative Timesteps: 31,060,440

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,719.91907
Policy Entropy: 1.33782
Value Function Loss: 0.99991

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.08389
Policy Update Magnitude: 0.23626
Value Function Update Magnitude: 0.43224

Collected Steps per Second: 22,732.25963
Overall Steps per Second: 10,656.84499

Timestep Collection Time: 2.20031
Timestep Consumption Time: 2.49320
PPO Batch Consumption Time: 0.30058
Total Iteration Time: 4.69351

Cumulative Model Updates: 3,716
Cumulative Timesteps: 31,110,458

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 31110458...
Checkpoint 31110458 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,634.92720
Policy Entropy: 1.34749
Value Function Loss: 1.01935

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.10154
Policy Update Magnitude: 0.23878
Value Function Update Magnitude: 0.38086

Collected Steps per Second: 21,490.96837
Overall Steps per Second: 10,540.16957

Timestep Collection Time: 2.32712
Timestep Consumption Time: 2.41778
PPO Batch Consumption Time: 0.28694
Total Iteration Time: 4.74490

Cumulative Model Updates: 3,722
Cumulative Timesteps: 31,160,470

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,877.97906
Policy Entropy: 1.34692
Value Function Loss: 1.02830

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.10161
Policy Update Magnitude: 0.24542
Value Function Update Magnitude: 0.35385

Collected Steps per Second: 21,786.54931
Overall Steps per Second: 10,559.48998

Timestep Collection Time: 2.29573
Timestep Consumption Time: 2.44086
PPO Batch Consumption Time: 0.29091
Total Iteration Time: 4.73659

Cumulative Model Updates: 3,728
Cumulative Timesteps: 31,210,486

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 31210486...
Checkpoint 31210486 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,057.07657
Policy Entropy: 1.35568
Value Function Loss: 0.99174

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.10495
Policy Update Magnitude: 0.25041
Value Function Update Magnitude: 0.35211

Collected Steps per Second: 21,297.81824
Overall Steps per Second: 10,386.31516

Timestep Collection Time: 2.34897
Timestep Consumption Time: 2.46775
PPO Batch Consumption Time: 0.29537
Total Iteration Time: 4.81672

Cumulative Model Updates: 3,734
Cumulative Timesteps: 31,260,514

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,321.24795
Policy Entropy: 1.34303
Value Function Loss: 1.00731

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.11180
Policy Update Magnitude: 0.21903
Value Function Update Magnitude: 0.36859

Collected Steps per Second: 22,450.51960
Overall Steps per Second: 10,584.14866

Timestep Collection Time: 2.22739
Timestep Consumption Time: 2.49723
PPO Batch Consumption Time: 0.28685
Total Iteration Time: 4.72461

Cumulative Model Updates: 3,740
Cumulative Timesteps: 31,310,520

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 31310520...
Checkpoint 31310520 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,630.17425
Policy Entropy: 1.34590
Value Function Loss: 0.95404

Mean KL Divergence: 0.00668
SB3 Clip Fraction: 0.07692
Policy Update Magnitude: 0.26645
Value Function Update Magnitude: 0.40251

Collected Steps per Second: 22,039.52158
Overall Steps per Second: 10,352.67679

Timestep Collection Time: 2.27065
Timestep Consumption Time: 2.56327
PPO Batch Consumption Time: 0.30038
Total Iteration Time: 4.83392

Cumulative Model Updates: 3,746
Cumulative Timesteps: 31,360,564

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,337.42006
Policy Entropy: 1.34251
Value Function Loss: 0.96737

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.08875
Policy Update Magnitude: 0.27142
Value Function Update Magnitude: 0.35569

Collected Steps per Second: 22,108.35588
Overall Steps per Second: 10,421.95627

Timestep Collection Time: 2.26195
Timestep Consumption Time: 2.53638
PPO Batch Consumption Time: 0.29301
Total Iteration Time: 4.79833

Cumulative Model Updates: 3,752
Cumulative Timesteps: 31,410,572

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 31410572...
Checkpoint 31410572 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,129.79445
Policy Entropy: 1.34072
Value Function Loss: 0.97892

Mean KL Divergence: 0.00729
SB3 Clip Fraction: 0.08010
Policy Update Magnitude: 0.25588
Value Function Update Magnitude: 0.33288

Collected Steps per Second: 22,041.89873
Overall Steps per Second: 10,395.98215

Timestep Collection Time: 2.26986
Timestep Consumption Time: 2.54277
PPO Batch Consumption Time: 0.29655
Total Iteration Time: 4.81263

Cumulative Model Updates: 3,758
Cumulative Timesteps: 31,460,604

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,507.65945
Policy Entropy: 1.35152
Value Function Loss: 0.97428

Mean KL Divergence: 0.00748
SB3 Clip Fraction: 0.08743
Policy Update Magnitude: 0.26434
Value Function Update Magnitude: 0.37856

Collected Steps per Second: 22,369.74148
Overall Steps per Second: 10,461.86691

Timestep Collection Time: 2.23552
Timestep Consumption Time: 2.54451
PPO Batch Consumption Time: 0.29545
Total Iteration Time: 4.78003

Cumulative Model Updates: 3,764
Cumulative Timesteps: 31,510,612

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 31510612...
Checkpoint 31510612 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,553.36308
Policy Entropy: 1.34048
Value Function Loss: 0.94283

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.09584
Policy Update Magnitude: 0.25347
Value Function Update Magnitude: 0.39443

Collected Steps per Second: 21,950.92152
Overall Steps per Second: 10,418.80144

Timestep Collection Time: 2.27781
Timestep Consumption Time: 2.52121
PPO Batch Consumption Time: 0.29065
Total Iteration Time: 4.79902

Cumulative Model Updates: 3,770
Cumulative Timesteps: 31,560,612

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,203.72593
Policy Entropy: 1.36479
Value Function Loss: 0.88329

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.10575
Policy Update Magnitude: 0.24283
Value Function Update Magnitude: 0.46474

Collected Steps per Second: 22,006.20701
Overall Steps per Second: 10,469.03513

Timestep Collection Time: 2.27227
Timestep Consumption Time: 2.50410
PPO Batch Consumption Time: 0.29270
Total Iteration Time: 4.77637

Cumulative Model Updates: 3,776
Cumulative Timesteps: 31,610,616

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 31610616...
Checkpoint 31610616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,606.32494
Policy Entropy: 1.36070
Value Function Loss: 0.92311

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.09377
Policy Update Magnitude: 0.24137
Value Function Update Magnitude: 0.47026

Collected Steps per Second: 21,899.00881
Overall Steps per Second: 10,507.84699

Timestep Collection Time: 2.28430
Timestep Consumption Time: 2.47633
PPO Batch Consumption Time: 0.28952
Total Iteration Time: 4.76063

Cumulative Model Updates: 3,782
Cumulative Timesteps: 31,660,640

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,777.61224
Policy Entropy: 1.35571
Value Function Loss: 0.90027

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.10492
Policy Update Magnitude: 0.24199
Value Function Update Magnitude: 0.53077

Collected Steps per Second: 22,501.54066
Overall Steps per Second: 10,580.47022

Timestep Collection Time: 2.22243
Timestep Consumption Time: 2.50402
PPO Batch Consumption Time: 0.29201
Total Iteration Time: 4.72644

Cumulative Model Updates: 3,788
Cumulative Timesteps: 31,710,648

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 31710648...
Checkpoint 31710648 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 939.04273
Policy Entropy: 1.34692
Value Function Loss: 0.93216

Mean KL Divergence: 0.00747
SB3 Clip Fraction: 0.08842
Policy Update Magnitude: 0.25149
Value Function Update Magnitude: 0.50889

Collected Steps per Second: 22,139.84123
Overall Steps per Second: 10,587.29007

Timestep Collection Time: 2.25964
Timestep Consumption Time: 2.46565
PPO Batch Consumption Time: 0.28657
Total Iteration Time: 4.72529

Cumulative Model Updates: 3,794
Cumulative Timesteps: 31,760,676

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,386.99357
Policy Entropy: 1.35826
Value Function Loss: 0.91647

Mean KL Divergence: 0.00634
SB3 Clip Fraction: 0.07491
Policy Update Magnitude: 0.28380
Value Function Update Magnitude: 0.46310

Collected Steps per Second: 22,310.41832
Overall Steps per Second: 10,581.95730

Timestep Collection Time: 2.24182
Timestep Consumption Time: 2.48471
PPO Batch Consumption Time: 0.29984
Total Iteration Time: 4.72654

Cumulative Model Updates: 3,800
Cumulative Timesteps: 31,810,692

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 31810692...
Checkpoint 31810692 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,842.29168
Policy Entropy: 1.36177
Value Function Loss: 0.91428

Mean KL Divergence: 0.00753
SB3 Clip Fraction: 0.09089
Policy Update Magnitude: 0.30223
Value Function Update Magnitude: 0.47847

Collected Steps per Second: 21,271.43145
Overall Steps per Second: 10,485.15929

Timestep Collection Time: 2.35207
Timestep Consumption Time: 2.41962
PPO Batch Consumption Time: 0.28612
Total Iteration Time: 4.77170

Cumulative Model Updates: 3,806
Cumulative Timesteps: 31,860,724

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,074.82543
Policy Entropy: 1.37010
Value Function Loss: 0.88721

Mean KL Divergence: 0.01124
SB3 Clip Fraction: 0.12654
Policy Update Magnitude: 0.30373
Value Function Update Magnitude: 0.41345

Collected Steps per Second: 22,495.87004
Overall Steps per Second: 10,552.05199

Timestep Collection Time: 2.22272
Timestep Consumption Time: 2.51589
PPO Batch Consumption Time: 0.29111
Total Iteration Time: 4.73860

Cumulative Model Updates: 3,812
Cumulative Timesteps: 31,910,726

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 31910726...
Checkpoint 31910726 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,192.27889
Policy Entropy: 1.36449
Value Function Loss: 0.89172

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.11182
Policy Update Magnitude: 0.28750
Value Function Update Magnitude: 0.36301

Collected Steps per Second: 22,150.74348
Overall Steps per Second: 10,534.67854

Timestep Collection Time: 2.25798
Timestep Consumption Time: 2.48977
PPO Batch Consumption Time: 0.28666
Total Iteration Time: 4.74775

Cumulative Model Updates: 3,818
Cumulative Timesteps: 31,960,742

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,648.07193
Policy Entropy: 1.35794
Value Function Loss: 0.90487

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.08966
Policy Update Magnitude: 0.29130
Value Function Update Magnitude: 0.36832

Collected Steps per Second: 22,415.78344
Overall Steps per Second: 10,587.53138

Timestep Collection Time: 2.23191
Timestep Consumption Time: 2.49346
PPO Batch Consumption Time: 0.28855
Total Iteration Time: 4.72537

Cumulative Model Updates: 3,824
Cumulative Timesteps: 32,010,772

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 32010772...
Checkpoint 32010772 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,339.04332
Policy Entropy: 1.35629
Value Function Loss: 0.93566

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.10959
Policy Update Magnitude: 0.25880
Value Function Update Magnitude: 0.37493

Collected Steps per Second: 21,991.15930
Overall Steps per Second: 10,402.26565

Timestep Collection Time: 2.27437
Timestep Consumption Time: 2.53381
PPO Batch Consumption Time: 0.29634
Total Iteration Time: 4.80818

Cumulative Model Updates: 3,830
Cumulative Timesteps: 32,060,788

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,576.20089
Policy Entropy: 1.33218
Value Function Loss: 0.95466

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.09611
Policy Update Magnitude: 0.25049
Value Function Update Magnitude: 0.37970

Collected Steps per Second: 22,451.24975
Overall Steps per Second: 10,592.31790

Timestep Collection Time: 2.22910
Timestep Consumption Time: 2.49565
PPO Batch Consumption Time: 0.28786
Total Iteration Time: 4.72474

Cumulative Model Updates: 3,836
Cumulative Timesteps: 32,110,834

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 32110834...
Checkpoint 32110834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,878.67755
Policy Entropy: 1.33426
Value Function Loss: 0.94157

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.09695
Policy Update Magnitude: 0.24547
Value Function Update Magnitude: 0.35894

Collected Steps per Second: 22,141.05213
Overall Steps per Second: 10,360.98916

Timestep Collection Time: 2.26006
Timestep Consumption Time: 2.56960
PPO Batch Consumption Time: 0.29955
Total Iteration Time: 4.82965

Cumulative Model Updates: 3,842
Cumulative Timesteps: 32,160,874

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,837.59516
Policy Entropy: 1.32158
Value Function Loss: 0.88724

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.10143
Policy Update Magnitude: 0.24765
Value Function Update Magnitude: 0.46989

Collected Steps per Second: 22,317.93185
Overall Steps per Second: 10,433.53262

Timestep Collection Time: 2.24062
Timestep Consumption Time: 2.55220
PPO Batch Consumption Time: 0.30032
Total Iteration Time: 4.79282

Cumulative Model Updates: 3,848
Cumulative Timesteps: 32,210,880

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 32210880...
Checkpoint 32210880 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,136.39908
Policy Entropy: 1.31957
Value Function Loss: 0.88653

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.08854
Policy Update Magnitude: 0.24848
Value Function Update Magnitude: 0.48832

Collected Steps per Second: 22,084.12484
Overall Steps per Second: 10,581.73127

Timestep Collection Time: 2.26552
Timestep Consumption Time: 2.46263
PPO Batch Consumption Time: 0.28599
Total Iteration Time: 4.72815

Cumulative Model Updates: 3,854
Cumulative Timesteps: 32,260,912

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,703.13890
Policy Entropy: 1.31972
Value Function Loss: 0.89969

Mean KL Divergence: 0.00783
SB3 Clip Fraction: 0.08517
Policy Update Magnitude: 0.26071
Value Function Update Magnitude: 0.49428

Collected Steps per Second: 22,489.66642
Overall Steps per Second: 10,627.79309

Timestep Collection Time: 2.22387
Timestep Consumption Time: 2.48210
PPO Batch Consumption Time: 0.29916
Total Iteration Time: 4.70596

Cumulative Model Updates: 3,860
Cumulative Timesteps: 32,310,926

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 32310926...
Checkpoint 32310926 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,329.79368
Policy Entropy: 1.31903
Value Function Loss: 0.93707

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.08439
Policy Update Magnitude: 0.23333
Value Function Update Magnitude: 0.41726

Collected Steps per Second: 21,417.43990
Overall Steps per Second: 10,558.38685

Timestep Collection Time: 2.33539
Timestep Consumption Time: 2.40189
PPO Batch Consumption Time: 0.28569
Total Iteration Time: 4.73728

Cumulative Model Updates: 3,866
Cumulative Timesteps: 32,360,944

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,755.72098
Policy Entropy: 1.31365
Value Function Loss: 0.87913

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.09049
Policy Update Magnitude: 0.22611
Value Function Update Magnitude: 0.35488

Collected Steps per Second: 21,691.71717
Overall Steps per Second: 10,429.23532

Timestep Collection Time: 2.30604
Timestep Consumption Time: 2.49028
PPO Batch Consumption Time: 0.29965
Total Iteration Time: 4.79632

Cumulative Model Updates: 3,872
Cumulative Timesteps: 32,410,966

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 32410966...
Checkpoint 32410966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,252.29120
Policy Entropy: 1.30706
Value Function Loss: 0.85203

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.08478
Policy Update Magnitude: 0.24332
Value Function Update Magnitude: 0.40461

Collected Steps per Second: 21,471.79915
Overall Steps per Second: 10,567.70136

Timestep Collection Time: 2.32947
Timestep Consumption Time: 2.40363
PPO Batch Consumption Time: 0.28527
Total Iteration Time: 4.73310

Cumulative Model Updates: 3,878
Cumulative Timesteps: 32,460,984

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,504.68578
Policy Entropy: 1.30077
Value Function Loss: 0.79084

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.09983
Policy Update Magnitude: 0.27142
Value Function Update Magnitude: 0.44927

Collected Steps per Second: 22,742.87990
Overall Steps per Second: 10,516.09262

Timestep Collection Time: 2.19902
Timestep Consumption Time: 2.55674
PPO Batch Consumption Time: 0.29609
Total Iteration Time: 4.75576

Cumulative Model Updates: 3,884
Cumulative Timesteps: 32,510,996

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 32510996...
Checkpoint 32510996 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,250.20134
Policy Entropy: 1.29767
Value Function Loss: 0.82622

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.10765
Policy Update Magnitude: 0.23829
Value Function Update Magnitude: 0.43199

Collected Steps per Second: 21,743.70915
Overall Steps per Second: 10,297.82853

Timestep Collection Time: 2.30034
Timestep Consumption Time: 2.55680
PPO Batch Consumption Time: 0.29921
Total Iteration Time: 4.85714

Cumulative Model Updates: 3,890
Cumulative Timesteps: 32,561,014

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,606.82774
Policy Entropy: 1.29399
Value Function Loss: 0.86524

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.09184
Policy Update Magnitude: 0.24151
Value Function Update Magnitude: 0.46200

Collected Steps per Second: 22,573.97174
Overall Steps per Second: 10,524.42731

Timestep Collection Time: 2.21538
Timestep Consumption Time: 2.53642
PPO Batch Consumption Time: 0.29668
Total Iteration Time: 4.75180

Cumulative Model Updates: 3,896
Cumulative Timesteps: 32,611,024

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 32611024...
Checkpoint 32611024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,095.98449
Policy Entropy: 1.28598
Value Function Loss: 0.86852

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.10055
Policy Update Magnitude: 0.24219
Value Function Update Magnitude: 0.48438

Collected Steps per Second: 21,968.83916
Overall Steps per Second: 10,523.26335

Timestep Collection Time: 2.27659
Timestep Consumption Time: 2.47612
PPO Batch Consumption Time: 0.28515
Total Iteration Time: 4.75271

Cumulative Model Updates: 3,902
Cumulative Timesteps: 32,661,038

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,070.37908
Policy Entropy: 1.26996
Value Function Loss: 0.84631

Mean KL Divergence: 0.01110
SB3 Clip Fraction: 0.11840
Policy Update Magnitude: 0.22788
Value Function Update Magnitude: 0.47877

Collected Steps per Second: 22,343.74039
Overall Steps per Second: 10,393.53564

Timestep Collection Time: 2.23776
Timestep Consumption Time: 2.57292
PPO Batch Consumption Time: 0.30108
Total Iteration Time: 4.81068

Cumulative Model Updates: 3,908
Cumulative Timesteps: 32,711,038

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 32711038...
Checkpoint 32711038 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,705.10303
Policy Entropy: 1.28194
Value Function Loss: 0.86577

Mean KL Divergence: 0.01116
SB3 Clip Fraction: 0.11608
Policy Update Magnitude: 0.21171
Value Function Update Magnitude: 0.47608

Collected Steps per Second: 22,027.69030
Overall Steps per Second: 10,406.58312

Timestep Collection Time: 2.26987
Timestep Consumption Time: 2.53478
PPO Batch Consumption Time: 0.29592
Total Iteration Time: 4.80465

Cumulative Model Updates: 3,914
Cumulative Timesteps: 32,761,038

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,789.50047
Policy Entropy: 1.27269
Value Function Loss: 0.88179

Mean KL Divergence: 0.01116
SB3 Clip Fraction: 0.11087
Policy Update Magnitude: 0.21965
Value Function Update Magnitude: 0.44808

Collected Steps per Second: 22,638.85257
Overall Steps per Second: 10,631.45393

Timestep Collection Time: 2.20859
Timestep Consumption Time: 2.49443
PPO Batch Consumption Time: 0.28645
Total Iteration Time: 4.70303

Cumulative Model Updates: 3,920
Cumulative Timesteps: 32,811,038

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 32811038...
Checkpoint 32811038 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,104.22543
Policy Entropy: 1.30029
Value Function Loss: 0.92015

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.10432
Policy Update Magnitude: 0.22629
Value Function Update Magnitude: 0.42818

Collected Steps per Second: 22,088.58151
Overall Steps per Second: 10,491.19184

Timestep Collection Time: 2.26425
Timestep Consumption Time: 2.50299
PPO Batch Consumption Time: 0.29443
Total Iteration Time: 4.76724

Cumulative Model Updates: 3,926
Cumulative Timesteps: 32,861,052

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,181.56746
Policy Entropy: 1.29154
Value Function Loss: 0.89697

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.09805
Policy Update Magnitude: 0.23331
Value Function Update Magnitude: 0.43221

Collected Steps per Second: 22,425.51388
Overall Steps per Second: 10,632.25479

Timestep Collection Time: 2.23023
Timestep Consumption Time: 2.47376
PPO Batch Consumption Time: 0.28643
Total Iteration Time: 4.70399

Cumulative Model Updates: 3,932
Cumulative Timesteps: 32,911,066

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 32911066...
Checkpoint 32911066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,586.29722
Policy Entropy: 1.30079
Value Function Loss: 0.91300

Mean KL Divergence: 0.00686
SB3 Clip Fraction: 0.08015
Policy Update Magnitude: 0.27838
Value Function Update Magnitude: 0.37787

Collected Steps per Second: 21,956.57146
Overall Steps per Second: 10,405.28165

Timestep Collection Time: 2.27941
Timestep Consumption Time: 2.53046
PPO Batch Consumption Time: 0.29861
Total Iteration Time: 4.80986

Cumulative Model Updates: 3,938
Cumulative Timesteps: 32,961,114

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 998.94349
Policy Entropy: 1.27293
Value Function Loss: 0.86536

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.09844
Policy Update Magnitude: 0.28801
Value Function Update Magnitude: 0.38580

Collected Steps per Second: 22,399.15710
Overall Steps per Second: 10,659.79347

Timestep Collection Time: 2.23267
Timestep Consumption Time: 2.45879
PPO Batch Consumption Time: 0.28611
Total Iteration Time: 4.69146

Cumulative Model Updates: 3,944
Cumulative Timesteps: 33,011,124

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 33011124...
Checkpoint 33011124 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,243.51138
Policy Entropy: 1.30586
Value Function Loss: 0.84838

Mean KL Divergence: 0.01065
SB3 Clip Fraction: 0.13292
Policy Update Magnitude: 0.25082
Value Function Update Magnitude: 0.44557

Collected Steps per Second: 22,108.02903
Overall Steps per Second: 10,717.63865

Timestep Collection Time: 2.26235
Timestep Consumption Time: 2.40435
PPO Batch Consumption Time: 0.28587
Total Iteration Time: 4.66670

Cumulative Model Updates: 3,950
Cumulative Timesteps: 33,061,140

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,486.52730
Policy Entropy: 1.28668
Value Function Loss: 0.82343

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.11940
Policy Update Magnitude: 0.23719
Value Function Update Magnitude: 0.41575

Collected Steps per Second: 21,582.85553
Overall Steps per Second: 10,445.26236

Timestep Collection Time: 2.31693
Timestep Consumption Time: 2.47050
PPO Batch Consumption Time: 0.29306
Total Iteration Time: 4.78743

Cumulative Model Updates: 3,956
Cumulative Timesteps: 33,111,146

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 33111146...
Checkpoint 33111146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,830.56733
Policy Entropy: 1.28742
Value Function Loss: 0.82108

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.12509
Policy Update Magnitude: 0.24242
Value Function Update Magnitude: 0.37660

Collected Steps per Second: 21,598.95317
Overall Steps per Second: 10,574.74469

Timestep Collection Time: 2.31511
Timestep Consumption Time: 2.41351
PPO Batch Consumption Time: 0.28601
Total Iteration Time: 4.72862

Cumulative Model Updates: 3,962
Cumulative Timesteps: 33,161,150

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,117.73263
Policy Entropy: 1.30772
Value Function Loss: 0.82668

Mean KL Divergence: 0.00750
SB3 Clip Fraction: 0.09262
Policy Update Magnitude: 0.25237
Value Function Update Magnitude: 0.38835

Collected Steps per Second: 22,256.45943
Overall Steps per Second: 10,577.29446

Timestep Collection Time: 2.24681
Timestep Consumption Time: 2.48087
PPO Batch Consumption Time: 0.28545
Total Iteration Time: 4.72767

Cumulative Model Updates: 3,968
Cumulative Timesteps: 33,211,156

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 33211156...
Checkpoint 33211156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,569.07037
Policy Entropy: 1.30801
Value Function Loss: 0.81862

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.11003
Policy Update Magnitude: 0.28291
Value Function Update Magnitude: 0.36440

Collected Steps per Second: 22,328.92480
Overall Steps per Second: 10,627.53416

Timestep Collection Time: 2.24041
Timestep Consumption Time: 2.46679
PPO Batch Consumption Time: 0.28465
Total Iteration Time: 4.70721

Cumulative Model Updates: 3,974
Cumulative Timesteps: 33,261,182

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,363.17219
Policy Entropy: 1.30320
Value Function Loss: 0.84010

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.11360
Policy Update Magnitude: 0.24316
Value Function Update Magnitude: 0.36700

Collected Steps per Second: 22,304.79923
Overall Steps per Second: 10,414.56835

Timestep Collection Time: 2.24284
Timestep Consumption Time: 2.56063
PPO Batch Consumption Time: 0.29680
Total Iteration Time: 4.80346

Cumulative Model Updates: 3,980
Cumulative Timesteps: 33,311,208

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 33311208...
Checkpoint 33311208 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,171.87210
Policy Entropy: 1.30605
Value Function Loss: 0.80655

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.09926
Policy Update Magnitude: 0.22856
Value Function Update Magnitude: 0.43133

Collected Steps per Second: 21,953.69150
Overall Steps per Second: 10,350.47002

Timestep Collection Time: 2.27752
Timestep Consumption Time: 2.55318
PPO Batch Consumption Time: 0.29701
Total Iteration Time: 4.83070

Cumulative Model Updates: 3,986
Cumulative Timesteps: 33,361,208

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,145.53470
Policy Entropy: 1.30061
Value Function Loss: 0.83531

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.09273
Policy Update Magnitude: 0.22075
Value Function Update Magnitude: 0.38991

Collected Steps per Second: 22,233.39285
Overall Steps per Second: 10,408.84904

Timestep Collection Time: 2.24995
Timestep Consumption Time: 2.55596
PPO Batch Consumption Time: 0.29949
Total Iteration Time: 4.80591

Cumulative Model Updates: 3,992
Cumulative Timesteps: 33,411,232

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 33411232...
Checkpoint 33411232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,409.39154
Policy Entropy: 1.29916
Value Function Loss: 0.81908

Mean KL Divergence: 0.00722
SB3 Clip Fraction: 0.08252
Policy Update Magnitude: 0.21269
Value Function Update Magnitude: 0.36907

Collected Steps per Second: 22,181.28903
Overall Steps per Second: 10,559.72721

Timestep Collection Time: 2.25424
Timestep Consumption Time: 2.48092
PPO Batch Consumption Time: 0.28604
Total Iteration Time: 4.73516

Cumulative Model Updates: 3,998
Cumulative Timesteps: 33,461,234

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,422.99054
Policy Entropy: 1.28984
Value Function Loss: 0.83244

Mean KL Divergence: 0.00770
SB3 Clip Fraction: 0.08611
Policy Update Magnitude: 0.22420
Value Function Update Magnitude: 0.38811

Collected Steps per Second: 22,177.74926
Overall Steps per Second: 10,478.91855

Timestep Collection Time: 2.25505
Timestep Consumption Time: 2.51758
PPO Batch Consumption Time: 0.29387
Total Iteration Time: 4.77263

Cumulative Model Updates: 4,004
Cumulative Timesteps: 33,511,246

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 33511246...
Checkpoint 33511246 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,235.37488
Policy Entropy: 1.30118
Value Function Loss: 0.78383

Mean KL Divergence: 0.01182
SB3 Clip Fraction: 0.11997
Policy Update Magnitude: 0.21735
Value Function Update Magnitude: 0.36596

Collected Steps per Second: 20,695.37023
Overall Steps per Second: 10,160.00340

Timestep Collection Time: 2.41697
Timestep Consumption Time: 2.50626
PPO Batch Consumption Time: 0.28724
Total Iteration Time: 4.92323

Cumulative Model Updates: 4,010
Cumulative Timesteps: 33,561,266

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,716.92546
Policy Entropy: 1.29732
Value Function Loss: 0.78142

Mean KL Divergence: 0.00694
SB3 Clip Fraction: 0.07703
Policy Update Magnitude: 0.22299
Value Function Update Magnitude: 0.34592

Collected Steps per Second: 20,557.27533
Overall Steps per Second: 10,082.72872

Timestep Collection Time: 2.43349
Timestep Consumption Time: 2.52806
PPO Batch Consumption Time: 0.28980
Total Iteration Time: 4.96155

Cumulative Model Updates: 4,016
Cumulative Timesteps: 33,611,292

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 33611292...
Checkpoint 33611292 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,151.10929
Policy Entropy: 1.29043
Value Function Loss: 0.79356

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.09149
Policy Update Magnitude: 0.26373
Value Function Update Magnitude: 0.36086

Collected Steps per Second: 20,393.74697
Overall Steps per Second: 10,206.87686

Timestep Collection Time: 2.45301
Timestep Consumption Time: 2.44820
PPO Batch Consumption Time: 0.28722
Total Iteration Time: 4.90121

Cumulative Model Updates: 4,022
Cumulative Timesteps: 33,661,318

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,266.86746
Policy Entropy: 1.29106
Value Function Loss: 0.80197

Mean KL Divergence: 0.00708
SB3 Clip Fraction: 0.07870
Policy Update Magnitude: 0.25227
Value Function Update Magnitude: 0.36060

Collected Steps per Second: 21,747.59923
Overall Steps per Second: 10,562.71583

Timestep Collection Time: 2.29975
Timestep Consumption Time: 2.43521
PPO Batch Consumption Time: 0.28749
Total Iteration Time: 4.73496

Cumulative Model Updates: 4,028
Cumulative Timesteps: 33,711,332

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 33711332...
Checkpoint 33711332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,087.18656
Policy Entropy: 1.29741
Value Function Loss: 0.79749

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.08296
Policy Update Magnitude: 0.25564
Value Function Update Magnitude: 0.35909

Collected Steps per Second: 22,142.49245
Overall Steps per Second: 10,539.51192

Timestep Collection Time: 2.25882
Timestep Consumption Time: 2.48675
PPO Batch Consumption Time: 0.28702
Total Iteration Time: 4.74557

Cumulative Model Updates: 4,034
Cumulative Timesteps: 33,761,348

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,121.84961
Policy Entropy: 1.29605
Value Function Loss: 0.78942

Mean KL Divergence: 0.01170
SB3 Clip Fraction: 0.11785
Policy Update Magnitude: 0.24624
Value Function Update Magnitude: 0.43403

Collected Steps per Second: 22,460.98354
Overall Steps per Second: 10,621.61681

Timestep Collection Time: 2.22733
Timestep Consumption Time: 2.48269
PPO Batch Consumption Time: 0.28545
Total Iteration Time: 4.71002

Cumulative Model Updates: 4,040
Cumulative Timesteps: 33,811,376

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 33811376...
Checkpoint 33811376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,268.13936
Policy Entropy: 1.29410
Value Function Loss: 0.79744

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.09530
Policy Update Magnitude: 0.25810
Value Function Update Magnitude: 0.43302

Collected Steps per Second: 22,309.89187
Overall Steps per Second: 10,624.48978

Timestep Collection Time: 2.24188
Timestep Consumption Time: 2.46574
PPO Batch Consumption Time: 0.28552
Total Iteration Time: 4.70761

Cumulative Model Updates: 4,046
Cumulative Timesteps: 33,861,392

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,033.91057
Policy Entropy: 1.28960
Value Function Loss: 0.81337

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.09818
Policy Update Magnitude: 0.25397
Value Function Update Magnitude: 0.35738

Collected Steps per Second: 21,967.79357
Overall Steps per Second: 10,483.46471

Timestep Collection Time: 2.27679
Timestep Consumption Time: 2.49415
PPO Batch Consumption Time: 0.28582
Total Iteration Time: 4.77094

Cumulative Model Updates: 4,052
Cumulative Timesteps: 33,911,408

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 33911408...
Checkpoint 33911408 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,209.48772
Policy Entropy: 1.28468
Value Function Loss: 0.79577

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.11525
Policy Update Magnitude: 0.25087
Value Function Update Magnitude: 0.45250

Collected Steps per Second: 22,082.41158
Overall Steps per Second: 10,515.05019

Timestep Collection Time: 2.26560
Timestep Consumption Time: 2.49234
PPO Batch Consumption Time: 0.28625
Total Iteration Time: 4.75794

Cumulative Model Updates: 4,058
Cumulative Timesteps: 33,961,438

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,767.44672
Policy Entropy: 1.29203
Value Function Loss: 0.79838

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.09475
Policy Update Magnitude: 0.25259
Value Function Update Magnitude: 0.47769

Collected Steps per Second: 22,191.24703
Overall Steps per Second: 10,562.79425

Timestep Collection Time: 2.25449
Timestep Consumption Time: 2.48194
PPO Batch Consumption Time: 0.28526
Total Iteration Time: 4.73644

Cumulative Model Updates: 4,064
Cumulative Timesteps: 34,011,468

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 34011468...
Checkpoint 34011468 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,594.29465
Policy Entropy: 1.28671
Value Function Loss: 0.80303

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.10658
Policy Update Magnitude: 0.22390
Value Function Update Magnitude: 0.36444

Collected Steps per Second: 22,193.24770
Overall Steps per Second: 10,539.44505

Timestep Collection Time: 2.25294
Timestep Consumption Time: 2.49115
PPO Batch Consumption Time: 0.28590
Total Iteration Time: 4.74408

Cumulative Model Updates: 4,070
Cumulative Timesteps: 34,061,468

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,968.80856
Policy Entropy: 1.28920
Value Function Loss: 0.80008

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.08509
Policy Update Magnitude: 0.22220
Value Function Update Magnitude: 0.33838

Collected Steps per Second: 21,945.23339
Overall Steps per Second: 10,473.02704

Timestep Collection Time: 2.27840
Timestep Consumption Time: 2.49577
PPO Batch Consumption Time: 0.28626
Total Iteration Time: 4.77417

Cumulative Model Updates: 4,076
Cumulative Timesteps: 34,111,468

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 34111468...
Checkpoint 34111468 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,418.04113
Policy Entropy: 1.27721
Value Function Loss: 0.79094

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.09968
Policy Update Magnitude: 0.21981
Value Function Update Magnitude: 0.34012

Collected Steps per Second: 22,282.61942
Overall Steps per Second: 10,635.02900

Timestep Collection Time: 2.24525
Timestep Consumption Time: 2.45902
PPO Batch Consumption Time: 0.28682
Total Iteration Time: 4.70427

Cumulative Model Updates: 4,082
Cumulative Timesteps: 34,161,498

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,129.36414
Policy Entropy: 1.27331
Value Function Loss: 0.79728

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.08909
Policy Update Magnitude: 0.22695
Value Function Update Magnitude: 0.32934

Collected Steps per Second: 22,453.64289
Overall Steps per Second: 10,532.15635

Timestep Collection Time: 2.22699
Timestep Consumption Time: 2.52076
PPO Batch Consumption Time: 0.29519
Total Iteration Time: 4.74775

Cumulative Model Updates: 4,088
Cumulative Timesteps: 34,211,502

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 34211502...
Checkpoint 34211502 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,270.35494
Policy Entropy: 1.27217
Value Function Loss: 0.78494

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.08972
Policy Update Magnitude: 0.24424
Value Function Update Magnitude: 0.32556

Collected Steps per Second: 22,278.60056
Overall Steps per Second: 10,653.30470

Timestep Collection Time: 2.24476
Timestep Consumption Time: 2.44956
PPO Batch Consumption Time: 0.28563
Total Iteration Time: 4.69432

Cumulative Model Updates: 4,094
Cumulative Timesteps: 34,261,512

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,832.47733
Policy Entropy: 1.27436
Value Function Loss: 0.78749

Mean KL Divergence: 0.00681
SB3 Clip Fraction: 0.07717
Policy Update Magnitude: 0.26561
Value Function Update Magnitude: 0.34390

Collected Steps per Second: 21,707.81548
Overall Steps per Second: 10,441.83783

Timestep Collection Time: 2.30359
Timestep Consumption Time: 2.48541
PPO Batch Consumption Time: 0.28913
Total Iteration Time: 4.78900

Cumulative Model Updates: 4,100
Cumulative Timesteps: 34,311,518

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 34311518...
Checkpoint 34311518 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,375.71001
Policy Entropy: 1.26315
Value Function Loss: 0.74445

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.09495
Policy Update Magnitude: 0.24971
Value Function Update Magnitude: 0.36932

Collected Steps per Second: 21,700.34203
Overall Steps per Second: 10,331.30364

Timestep Collection Time: 2.30476
Timestep Consumption Time: 2.53626
PPO Batch Consumption Time: 0.29845
Total Iteration Time: 4.84102

Cumulative Model Updates: 4,106
Cumulative Timesteps: 34,361,532

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,637.06187
Policy Entropy: 1.25005
Value Function Loss: 0.74398

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.09559
Policy Update Magnitude: 0.22001
Value Function Update Magnitude: 0.38307

Collected Steps per Second: 22,264.55146
Overall Steps per Second: 10,468.21053

Timestep Collection Time: 2.24599
Timestep Consumption Time: 2.53095
PPO Batch Consumption Time: 0.29771
Total Iteration Time: 4.77694

Cumulative Model Updates: 4,112
Cumulative Timesteps: 34,411,538

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 34411538...
Checkpoint 34411538 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,011.41199
Policy Entropy: 1.26339
Value Function Loss: 0.75591

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.09400
Policy Update Magnitude: 0.22079
Value Function Update Magnitude: 0.39111

Collected Steps per Second: 22,244.40338
Overall Steps per Second: 10,593.56718

Timestep Collection Time: 2.24866
Timestep Consumption Time: 2.47308
PPO Batch Consumption Time: 0.29921
Total Iteration Time: 4.72173

Cumulative Model Updates: 4,118
Cumulative Timesteps: 34,461,558

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,463.06851
Policy Entropy: 1.26178
Value Function Loss: 0.80924

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.09757
Policy Update Magnitude: 0.24836
Value Function Update Magnitude: 0.37137

Collected Steps per Second: 21,665.39197
Overall Steps per Second: 10,369.30937

Timestep Collection Time: 2.30866
Timestep Consumption Time: 2.51500
PPO Batch Consumption Time: 0.29955
Total Iteration Time: 4.82366

Cumulative Model Updates: 4,124
Cumulative Timesteps: 34,511,576

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 34511576...
Checkpoint 34511576 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,259.91935
Policy Entropy: 1.26414
Value Function Loss: 0.78417

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.11162
Policy Update Magnitude: 0.22432
Value Function Update Magnitude: 0.36363

Collected Steps per Second: 21,271.71413
Overall Steps per Second: 10,531.37445

Timestep Collection Time: 2.35186
Timestep Consumption Time: 2.39852
PPO Batch Consumption Time: 0.28644
Total Iteration Time: 4.75038

Cumulative Model Updates: 4,130
Cumulative Timesteps: 34,561,604

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,774.37111
Policy Entropy: 1.26889
Value Function Loss: 0.77091

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.09837
Policy Update Magnitude: 0.22148
Value Function Update Magnitude: 0.37881

Collected Steps per Second: 21,995.95720
Overall Steps per Second: 10,454.21774

Timestep Collection Time: 2.27387
Timestep Consumption Time: 2.51042
PPO Batch Consumption Time: 0.28707
Total Iteration Time: 4.78429

Cumulative Model Updates: 4,136
Cumulative Timesteps: 34,611,620

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 34611620...
Checkpoint 34611620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,114.02030
Policy Entropy: 1.27797
Value Function Loss: 0.70430

Mean KL Divergence: 0.01129
SB3 Clip Fraction: 0.11386
Policy Update Magnitude: 0.22791
Value Function Update Magnitude: 0.33016

Collected Steps per Second: 22,405.98080
Overall Steps per Second: 10,496.08895

Timestep Collection Time: 2.23280
Timestep Consumption Time: 2.53355
PPO Batch Consumption Time: 0.29454
Total Iteration Time: 4.76635

Cumulative Model Updates: 4,142
Cumulative Timesteps: 34,661,648

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,926.82192
Policy Entropy: 1.27342
Value Function Loss: 0.71011

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.10861
Policy Update Magnitude: 0.22057
Value Function Update Magnitude: 0.30941

Collected Steps per Second: 22,336.65019
Overall Steps per Second: 10,477.66116

Timestep Collection Time: 2.24026
Timestep Consumption Time: 2.53561
PPO Batch Consumption Time: 0.29461
Total Iteration Time: 4.77587

Cumulative Model Updates: 4,148
Cumulative Timesteps: 34,711,688

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 34711688...
Checkpoint 34711688 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,436.74908
Policy Entropy: 1.27214
Value Function Loss: 0.71211

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.10194
Policy Update Magnitude: 0.24175
Value Function Update Magnitude: 0.30605

Collected Steps per Second: 22,367.63880
Overall Steps per Second: 10,433.35634

Timestep Collection Time: 2.23662
Timestep Consumption Time: 2.55838
PPO Batch Consumption Time: 0.29995
Total Iteration Time: 4.79501

Cumulative Model Updates: 4,154
Cumulative Timesteps: 34,761,716

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,051.56111
Policy Entropy: 1.27441
Value Function Loss: 0.73264

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.09363
Policy Update Magnitude: 0.25206
Value Function Update Magnitude: 0.34779

Collected Steps per Second: 22,157.39566
Overall Steps per Second: 10,419.58973

Timestep Collection Time: 2.25731
Timestep Consumption Time: 2.54288
PPO Batch Consumption Time: 0.29389
Total Iteration Time: 4.80019

Cumulative Model Updates: 4,160
Cumulative Timesteps: 34,811,732

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 34811732...
Checkpoint 34811732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,377.79920
Policy Entropy: 1.26863
Value Function Loss: 0.75686

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.08599
Policy Update Magnitude: 0.24130
Value Function Update Magnitude: 0.38386

Collected Steps per Second: 21,900.27596
Overall Steps per Second: 10,349.31621

Timestep Collection Time: 2.28445
Timestep Consumption Time: 2.54969
PPO Batch Consumption Time: 0.29739
Total Iteration Time: 4.83414

Cumulative Model Updates: 4,166
Cumulative Timesteps: 34,861,762

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,351.57084
Policy Entropy: 1.25642
Value Function Loss: 0.74231

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.09467
Policy Update Magnitude: 0.27951
Value Function Update Magnitude: 0.33746

Collected Steps per Second: 22,051.44576
Overall Steps per Second: 10,348.61796

Timestep Collection Time: 2.26824
Timestep Consumption Time: 2.56506
PPO Batch Consumption Time: 0.29947
Total Iteration Time: 4.83330

Cumulative Model Updates: 4,172
Cumulative Timesteps: 34,911,780

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 34911780...
Checkpoint 34911780 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,170.86193
Policy Entropy: 1.24616
Value Function Loss: 0.75191

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.10037
Policy Update Magnitude: 0.26185
Value Function Update Magnitude: 0.32002

Collected Steps per Second: 21,631.70708
Overall Steps per Second: 10,277.33561

Timestep Collection Time: 2.31235
Timestep Consumption Time: 2.55467
PPO Batch Consumption Time: 0.29956
Total Iteration Time: 4.86702

Cumulative Model Updates: 4,178
Cumulative Timesteps: 34,961,800

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,179.54977
Policy Entropy: 1.23828
Value Function Loss: 0.71344

Mean KL Divergence: 0.00750
SB3 Clip Fraction: 0.08393
Policy Update Magnitude: 0.24639
Value Function Update Magnitude: 0.35996

Collected Steps per Second: 22,489.27929
Overall Steps per Second: 10,553.89823

Timestep Collection Time: 2.22453
Timestep Consumption Time: 2.51571
PPO Batch Consumption Time: 0.29661
Total Iteration Time: 4.74024

Cumulative Model Updates: 4,184
Cumulative Timesteps: 35,011,828

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 35011828...
Checkpoint 35011828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,861.95921
Policy Entropy: 1.24146
Value Function Loss: 0.71615

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.09823
Policy Update Magnitude: 0.25930
Value Function Update Magnitude: 0.33358

Collected Steps per Second: 22,127.08346
Overall Steps per Second: 10,443.39823

Timestep Collection Time: 2.26049
Timestep Consumption Time: 2.52895
PPO Batch Consumption Time: 0.29764
Total Iteration Time: 4.78944

Cumulative Model Updates: 4,190
Cumulative Timesteps: 35,061,846

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,070.40451
Policy Entropy: 1.25286
Value Function Loss: 0.71194

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.11836
Policy Update Magnitude: 0.22383
Value Function Update Magnitude: 0.37298

Collected Steps per Second: 22,463.44773
Overall Steps per Second: 10,494.26380

Timestep Collection Time: 2.22691
Timestep Consumption Time: 2.53989
PPO Batch Consumption Time: 0.29996
Total Iteration Time: 4.76679

Cumulative Model Updates: 4,196
Cumulative Timesteps: 35,111,870

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 35111870...
Checkpoint 35111870 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,030.58938
Policy Entropy: 1.25344
Value Function Loss: 0.73756

Mean KL Divergence: 0.01309
SB3 Clip Fraction: 0.13407
Policy Update Magnitude: 0.20616
Value Function Update Magnitude: 0.34549

Collected Steps per Second: 21,891.48583
Overall Steps per Second: 10,541.38242

Timestep Collection Time: 2.28463
Timestep Consumption Time: 2.45991
PPO Batch Consumption Time: 0.28591
Total Iteration Time: 4.74454

Cumulative Model Updates: 4,202
Cumulative Timesteps: 35,161,884

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,322.08852
Policy Entropy: 1.23952
Value Function Loss: 0.72407

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.11386
Policy Update Magnitude: 0.18132
Value Function Update Magnitude: 0.34717

Collected Steps per Second: 22,428.42591
Overall Steps per Second: 10,629.30720

Timestep Collection Time: 2.22940
Timestep Consumption Time: 2.47476
PPO Batch Consumption Time: 0.29915
Total Iteration Time: 4.70416

Cumulative Model Updates: 4,208
Cumulative Timesteps: 35,211,886

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 35211886...
Checkpoint 35211886 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 888.27568
Policy Entropy: 1.22232
Value Function Loss: 0.74059

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.10994
Policy Update Magnitude: 0.19264
Value Function Update Magnitude: 0.34358

Collected Steps per Second: 21,251.96582
Overall Steps per Second: 10,485.40138

Timestep Collection Time: 2.35348
Timestep Consumption Time: 2.41658
PPO Batch Consumption Time: 0.28635
Total Iteration Time: 4.77006

Cumulative Model Updates: 4,214
Cumulative Timesteps: 35,261,902

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,932.56075
Policy Entropy: 1.20614
Value Function Loss: 0.72341

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.09511
Policy Update Magnitude: 0.24800
Value Function Update Magnitude: 0.32258

Collected Steps per Second: 22,726.27718
Overall Steps per Second: 10,518.95126

Timestep Collection Time: 2.20071
Timestep Consumption Time: 2.55394
PPO Batch Consumption Time: 0.29788
Total Iteration Time: 4.75466

Cumulative Model Updates: 4,220
Cumulative Timesteps: 35,311,916

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 35311916...
Checkpoint 35311916 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,943.21602
Policy Entropy: 1.19833
Value Function Loss: 0.77092

Mean KL Divergence: 0.01582
SB3 Clip Fraction: 0.14599
Policy Update Magnitude: 0.24877
Value Function Update Magnitude: 0.32752

Collected Steps per Second: 21,977.50346
Overall Steps per Second: 10,541.62309

Timestep Collection Time: 2.27615
Timestep Consumption Time: 2.46923
PPO Batch Consumption Time: 0.28608
Total Iteration Time: 4.74538

Cumulative Model Updates: 4,226
Cumulative Timesteps: 35,361,940

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,591.03643
Policy Entropy: 1.20797
Value Function Loss: 0.75715

Mean KL Divergence: 0.02025
SB3 Clip Fraction: 0.19036
Policy Update Magnitude: 0.20824
Value Function Update Magnitude: 0.37401

Collected Steps per Second: 22,609.06535
Overall Steps per Second: 10,541.98843

Timestep Collection Time: 2.21283
Timestep Consumption Time: 2.53295
PPO Batch Consumption Time: 0.29278
Total Iteration Time: 4.74578

Cumulative Model Updates: 4,232
Cumulative Timesteps: 35,411,970

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 35411970...
Checkpoint 35411970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,957.70568
Policy Entropy: 1.20907
Value Function Loss: 0.78664

Mean KL Divergence: 0.01639
SB3 Clip Fraction: 0.16514
Policy Update Magnitude: 0.18029
Value Function Update Magnitude: 0.38568

Collected Steps per Second: 21,436.61668
Overall Steps per Second: 10,193.69134

Timestep Collection Time: 2.33376
Timestep Consumption Time: 2.57398
PPO Batch Consumption Time: 0.30034
Total Iteration Time: 4.90774

Cumulative Model Updates: 4,238
Cumulative Timesteps: 35,461,998

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,175.12478
Policy Entropy: 1.19015
Value Function Loss: 0.74056

Mean KL Divergence: 0.01758
SB3 Clip Fraction: 0.16920
Policy Update Magnitude: 0.19238
Value Function Update Magnitude: 0.45588

Collected Steps per Second: 22,299.32215
Overall Steps per Second: 10,478.77507

Timestep Collection Time: 2.24240
Timestep Consumption Time: 2.52953
PPO Batch Consumption Time: 0.29290
Total Iteration Time: 4.77193

Cumulative Model Updates: 4,244
Cumulative Timesteps: 35,512,002

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 35512002...
Checkpoint 35512002 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,680.56011
Policy Entropy: 1.15185
Value Function Loss: 0.74063

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.10219
Policy Update Magnitude: 0.18457
Value Function Update Magnitude: 0.42828

Collected Steps per Second: 21,856.45720
Overall Steps per Second: 10,382.54807

Timestep Collection Time: 2.28820
Timestep Consumption Time: 2.52873
PPO Batch Consumption Time: 0.29601
Total Iteration Time: 4.81693

Cumulative Model Updates: 4,250
Cumulative Timesteps: 35,562,014

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,437.06859
Policy Entropy: 1.14185
Value Function Loss: 0.71513

Mean KL Divergence: 0.00679
SB3 Clip Fraction: 0.07767
Policy Update Magnitude: 0.21626
Value Function Update Magnitude: 0.41823

Collected Steps per Second: 21,864.64287
Overall Steps per Second: 10,320.81518

Timestep Collection Time: 2.28716
Timestep Consumption Time: 2.55819
PPO Batch Consumption Time: 0.29805
Total Iteration Time: 4.84535

Cumulative Model Updates: 4,256
Cumulative Timesteps: 35,612,022

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 35612022...
Checkpoint 35612022 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,115.38072
Policy Entropy: 1.14235
Value Function Loss: 0.73977

Mean KL Divergence: 0.01057
SB3 Clip Fraction: 0.11200
Policy Update Magnitude: 0.24488
Value Function Update Magnitude: 0.43896

Collected Steps per Second: 21,985.43377
Overall Steps per Second: 10,528.05026

Timestep Collection Time: 2.27496
Timestep Consumption Time: 2.47578
PPO Batch Consumption Time: 0.28618
Total Iteration Time: 4.75074

Cumulative Model Updates: 4,262
Cumulative Timesteps: 35,662,038

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,386.15229
Policy Entropy: 1.15188
Value Function Loss: 0.73839

Mean KL Divergence: 0.01098
SB3 Clip Fraction: 0.12103
Policy Update Magnitude: 0.24443
Value Function Update Magnitude: 0.52388

Collected Steps per Second: 22,329.67197
Overall Steps per Second: 10,525.79040

Timestep Collection Time: 2.24016
Timestep Consumption Time: 2.51217
PPO Batch Consumption Time: 0.29173
Total Iteration Time: 4.75233

Cumulative Model Updates: 4,268
Cumulative Timesteps: 35,712,060

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 35712060...
Checkpoint 35712060 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,582.09561
Policy Entropy: 1.14374
Value Function Loss: 0.76970

Mean KL Divergence: 0.01243
SB3 Clip Fraction: 0.13749
Policy Update Magnitude: 0.21482
Value Function Update Magnitude: 0.43188

Collected Steps per Second: 21,940.44068
Overall Steps per Second: 10,535.01813

Timestep Collection Time: 2.27972
Timestep Consumption Time: 2.46807
PPO Batch Consumption Time: 0.28644
Total Iteration Time: 4.74778

Cumulative Model Updates: 4,274
Cumulative Timesteps: 35,762,078

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,540.55458
Policy Entropy: 1.12787
Value Function Loss: 0.77352

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.10011
Policy Update Magnitude: 0.21837
Value Function Update Magnitude: 0.40629

Collected Steps per Second: 22,073.52868
Overall Steps per Second: 10,563.63809

Timestep Collection Time: 2.26606
Timestep Consumption Time: 2.46905
PPO Batch Consumption Time: 0.29602
Total Iteration Time: 4.73511

Cumulative Model Updates: 4,280
Cumulative Timesteps: 35,812,098

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 35812098...
Checkpoint 35812098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,128.36410
Policy Entropy: 1.13242
Value Function Loss: 0.73132

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.10363
Policy Update Magnitude: 0.22973
Value Function Update Magnitude: 0.39280

Collected Steps per Second: 21,400.13974
Overall Steps per Second: 10,532.61538

Timestep Collection Time: 2.33718
Timestep Consumption Time: 2.41150
PPO Batch Consumption Time: 0.28637
Total Iteration Time: 4.74868

Cumulative Model Updates: 4,286
Cumulative Timesteps: 35,862,114

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,714.75962
Policy Entropy: 1.13089
Value Function Loss: 0.77124

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.10124
Policy Update Magnitude: 0.20392
Value Function Update Magnitude: 0.37378

Collected Steps per Second: 21,507.85219
Overall Steps per Second: 10,539.62501

Timestep Collection Time: 2.32613
Timestep Consumption Time: 2.42072
PPO Batch Consumption Time: 0.28686
Total Iteration Time: 4.74685

Cumulative Model Updates: 4,292
Cumulative Timesteps: 35,912,144

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 35912144...
Checkpoint 35912144 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,663.64154
Policy Entropy: 1.12539
Value Function Loss: 0.73936

Mean KL Divergence: 0.00675
SB3 Clip Fraction: 0.07651
Policy Update Magnitude: 0.22458
Value Function Update Magnitude: 0.34003

Collected Steps per Second: 21,996.29889
Overall Steps per Second: 10,405.18639

Timestep Collection Time: 2.27429
Timestep Consumption Time: 2.53350
PPO Batch Consumption Time: 0.29614
Total Iteration Time: 4.80779

Cumulative Model Updates: 4,298
Cumulative Timesteps: 35,962,170

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,063.56034
Policy Entropy: 1.13854
Value Function Loss: 0.74264

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.09015
Policy Update Magnitude: 0.25326
Value Function Update Magnitude: 0.32579

Collected Steps per Second: 22,690.62244
Overall Steps per Second: 10,636.29091

Timestep Collection Time: 2.20443
Timestep Consumption Time: 2.49833
PPO Batch Consumption Time: 0.28634
Total Iteration Time: 4.70277

Cumulative Model Updates: 4,304
Cumulative Timesteps: 36,012,190

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 36012190...
Checkpoint 36012190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,993.53749
Policy Entropy: 1.14327
Value Function Loss: 0.70256

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.10192
Policy Update Magnitude: 0.23002
Value Function Update Magnitude: 0.29875

Collected Steps per Second: 22,004.63782
Overall Steps per Second: 10,387.29628

Timestep Collection Time: 2.27279
Timestep Consumption Time: 2.54193
PPO Batch Consumption Time: 0.29783
Total Iteration Time: 4.81473

Cumulative Model Updates: 4,310
Cumulative Timesteps: 36,062,202

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,711.66821
Policy Entropy: 1.15196
Value Function Loss: 0.72593

Mean KL Divergence: 0.00725
SB3 Clip Fraction: 0.08181
Policy Update Magnitude: 0.27002
Value Function Update Magnitude: 0.32832

Collected Steps per Second: 22,376.85302
Overall Steps per Second: 10,449.57280

Timestep Collection Time: 2.23454
Timestep Consumption Time: 2.55053
PPO Batch Consumption Time: 0.29848
Total Iteration Time: 4.78508

Cumulative Model Updates: 4,316
Cumulative Timesteps: 36,112,204

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 36112204...
Checkpoint 36112204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,467.85520
Policy Entropy: 1.14609
Value Function Loss: 0.70922

Mean KL Divergence: 0.00652
SB3 Clip Fraction: 0.08035
Policy Update Magnitude: 0.28928
Value Function Update Magnitude: 0.33647

Collected Steps per Second: 22,262.57722
Overall Steps per Second: 10,595.51377

Timestep Collection Time: 2.24601
Timestep Consumption Time: 2.47316
PPO Batch Consumption Time: 0.28441
Total Iteration Time: 4.71917

Cumulative Model Updates: 4,322
Cumulative Timesteps: 36,162,206

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,916.38644
Policy Entropy: 1.12566
Value Function Loss: 0.73096

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.10830
Policy Update Magnitude: 0.26728
Value Function Update Magnitude: 0.34917

Collected Steps per Second: 22,358.88969
Overall Steps per Second: 10,408.59393

Timestep Collection Time: 2.23625
Timestep Consumption Time: 2.56748
PPO Batch Consumption Time: 0.29618
Total Iteration Time: 4.80372

Cumulative Model Updates: 4,328
Cumulative Timesteps: 36,212,206

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 36212206...
Checkpoint 36212206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,833.88680
Policy Entropy: 1.12338
Value Function Loss: 0.73596

Mean KL Divergence: 0.01342
SB3 Clip Fraction: 0.13997
Policy Update Magnitude: 0.22274
Value Function Update Magnitude: 0.35349

Collected Steps per Second: 22,084.37026
Overall Steps per Second: 10,511.71092

Timestep Collection Time: 2.26531
Timestep Consumption Time: 2.49395
PPO Batch Consumption Time: 0.28602
Total Iteration Time: 4.75926

Cumulative Model Updates: 4,334
Cumulative Timesteps: 36,262,234

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,013.33354
Policy Entropy: 1.13849
Value Function Loss: 0.73910

Mean KL Divergence: 0.01214
SB3 Clip Fraction: 0.12786
Policy Update Magnitude: 0.20304
Value Function Update Magnitude: 0.38699

Collected Steps per Second: 22,221.44003
Overall Steps per Second: 10,549.71728

Timestep Collection Time: 2.25008
Timestep Consumption Time: 2.48938
PPO Batch Consumption Time: 0.28596
Total Iteration Time: 4.73946

Cumulative Model Updates: 4,340
Cumulative Timesteps: 36,312,234

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 36312234...
Checkpoint 36312234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,464.44096
Policy Entropy: 1.14557
Value Function Loss: 0.75805

Mean KL Divergence: 0.01315
SB3 Clip Fraction: 0.12243
Policy Update Magnitude: 0.19586
Value Function Update Magnitude: 0.32913

Collected Steps per Second: 21,787.19078
Overall Steps per Second: 10,328.44398

Timestep Collection Time: 2.29594
Timestep Consumption Time: 2.54719
PPO Batch Consumption Time: 0.29801
Total Iteration Time: 4.84313

Cumulative Model Updates: 4,346
Cumulative Timesteps: 36,362,256

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,704.47982
Policy Entropy: 1.16156
Value Function Loss: 0.72779

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.11147
Policy Update Magnitude: 0.20178
Value Function Update Magnitude: 0.31287

Collected Steps per Second: 22,344.11628
Overall Steps per Second: 10,517.51716

Timestep Collection Time: 2.23817
Timestep Consumption Time: 2.51675
PPO Batch Consumption Time: 0.29637
Total Iteration Time: 4.75492

Cumulative Model Updates: 4,352
Cumulative Timesteps: 36,412,266

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 36412266...
Checkpoint 36412266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,370.82477
Policy Entropy: 1.14538
Value Function Loss: 0.73226

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.09854
Policy Update Magnitude: 0.19090
Value Function Update Magnitude: 0.31213

Collected Steps per Second: 22,062.52095
Overall Steps per Second: 10,468.39669

Timestep Collection Time: 2.26629
Timestep Consumption Time: 2.50999
PPO Batch Consumption Time: 0.29479
Total Iteration Time: 4.77628

Cumulative Model Updates: 4,358
Cumulative Timesteps: 36,462,266

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,469.35894
Policy Entropy: 1.14782
Value Function Loss: 0.70573

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.09255
Policy Update Magnitude: 0.18611
Value Function Update Magnitude: 0.35474

Collected Steps per Second: 22,260.52507
Overall Steps per Second: 10,442.20735

Timestep Collection Time: 2.24631
Timestep Consumption Time: 2.54233
PPO Batch Consumption Time: 0.29985
Total Iteration Time: 4.78864

Cumulative Model Updates: 4,364
Cumulative Timesteps: 36,512,270

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 36512270...
Checkpoint 36512270 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,151.09447
Policy Entropy: 1.15145
Value Function Loss: 0.72078

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.08492
Policy Update Magnitude: 0.20593
Value Function Update Magnitude: 0.38525

Collected Steps per Second: 21,931.79251
Overall Steps per Second: 10,561.75609

Timestep Collection Time: 2.28107
Timestep Consumption Time: 2.45564
PPO Batch Consumption Time: 0.28590
Total Iteration Time: 4.73671

Cumulative Model Updates: 4,370
Cumulative Timesteps: 36,562,298

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,371.59684
Policy Entropy: 1.13341
Value Function Loss: 0.72552

Mean KL Divergence: 0.01205
SB3 Clip Fraction: 0.11864
Policy Update Magnitude: 0.24306
Value Function Update Magnitude: 0.30974

Collected Steps per Second: 22,150.23381
Overall Steps per Second: 10,503.16932

Timestep Collection Time: 2.25749
Timestep Consumption Time: 2.50336
PPO Batch Consumption Time: 0.29079
Total Iteration Time: 4.76085

Cumulative Model Updates: 4,376
Cumulative Timesteps: 36,612,302

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 36612302...
Checkpoint 36612302 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,105.82199
Policy Entropy: 1.13046
Value Function Loss: 0.71552

Mean KL Divergence: 0.00613
SB3 Clip Fraction: 0.07307
Policy Update Magnitude: 0.24839
Value Function Update Magnitude: 0.29354

Collected Steps per Second: 22,141.48757
Overall Steps per Second: 10,586.06264

Timestep Collection Time: 2.25920
Timestep Consumption Time: 2.46607
PPO Batch Consumption Time: 0.28617
Total Iteration Time: 4.72527

Cumulative Model Updates: 4,382
Cumulative Timesteps: 36,662,324

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,548.85378
Policy Entropy: 1.12262
Value Function Loss: 0.69948

Mean KL Divergence: 0.00630
SB3 Clip Fraction: 0.07487
Policy Update Magnitude: 0.26144
Value Function Update Magnitude: 0.36612

Collected Steps per Second: 22,267.75612
Overall Steps per Second: 10,554.59356

Timestep Collection Time: 2.24585
Timestep Consumption Time: 2.49237
PPO Batch Consumption Time: 0.30013
Total Iteration Time: 4.73822

Cumulative Model Updates: 4,388
Cumulative Timesteps: 36,712,334

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 36712334...
Checkpoint 36712334 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,948.43838
Policy Entropy: 1.12244
Value Function Loss: 0.64550

Mean KL Divergence: 0.00693
SB3 Clip Fraction: 0.08072
Policy Update Magnitude: 0.27135
Value Function Update Magnitude: 0.38490

Collected Steps per Second: 21,497.33065
Overall Steps per Second: 10,576.74995

Timestep Collection Time: 2.32596
Timestep Consumption Time: 2.40158
PPO Batch Consumption Time: 0.28582
Total Iteration Time: 4.72754

Cumulative Model Updates: 4,394
Cumulative Timesteps: 36,762,336

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,867.96728
Policy Entropy: 1.12177
Value Function Loss: 0.66788

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.11603
Policy Update Magnitude: 0.24572
Value Function Update Magnitude: 0.36863

Collected Steps per Second: 21,748.40745
Overall Steps per Second: 10,450.94034

Timestep Collection Time: 2.30021
Timestep Consumption Time: 2.48653
PPO Batch Consumption Time: 0.29690
Total Iteration Time: 4.78675

Cumulative Model Updates: 4,400
Cumulative Timesteps: 36,812,362

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 36812362...
Checkpoint 36812362 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,675.80249
Policy Entropy: 1.11394
Value Function Loss: 0.65890

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.09338
Policy Update Magnitude: 0.19755
Value Function Update Magnitude: 0.39540

Collected Steps per Second: 21,506.71236
Overall Steps per Second: 10,580.19345

Timestep Collection Time: 2.32597
Timestep Consumption Time: 2.40211
PPO Batch Consumption Time: 0.28578
Total Iteration Time: 4.72808

Cumulative Model Updates: 4,406
Cumulative Timesteps: 36,862,386

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,539.41824
Policy Entropy: 1.09921
Value Function Loss: 0.68367

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.09091
Policy Update Magnitude: 0.19292
Value Function Update Magnitude: 0.34785

Collected Steps per Second: 22,517.17654
Overall Steps per Second: 10,573.50137

Timestep Collection Time: 2.22150
Timestep Consumption Time: 2.50938
PPO Batch Consumption Time: 0.29275
Total Iteration Time: 4.73088

Cumulative Model Updates: 4,412
Cumulative Timesteps: 36,912,408

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 36912408...
Checkpoint 36912408 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,618.58302
Policy Entropy: 1.10122
Value Function Loss: 0.65498

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.08673
Policy Update Magnitude: 0.21277
Value Function Update Magnitude: 0.33404

Collected Steps per Second: 22,087.86431
Overall Steps per Second: 10,555.58164

Timestep Collection Time: 2.26504
Timestep Consumption Time: 2.47463
PPO Batch Consumption Time: 0.28591
Total Iteration Time: 4.73967

Cumulative Model Updates: 4,418
Cumulative Timesteps: 36,962,438

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,180.59764
Policy Entropy: 1.09129
Value Function Loss: 0.68932

Mean KL Divergence: 0.00666
SB3 Clip Fraction: 0.07721
Policy Update Magnitude: 0.25425
Value Function Update Magnitude: 0.33728

Collected Steps per Second: 22,362.08364
Overall Steps per Second: 10,514.52425

Timestep Collection Time: 2.23593
Timestep Consumption Time: 2.51940
PPO Batch Consumption Time: 0.29301
Total Iteration Time: 4.75533

Cumulative Model Updates: 4,424
Cumulative Timesteps: 37,012,438

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 37012438...
Checkpoint 37012438 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,535.14631
Policy Entropy: 1.08960
Value Function Loss: 0.71367

Mean KL Divergence: 0.00556
SB3 Clip Fraction: 0.06342
Policy Update Magnitude: 0.30855
Value Function Update Magnitude: 0.36296

Collected Steps per Second: 22,113.56842
Overall Steps per Second: 10,529.59599

Timestep Collection Time: 2.26223
Timestep Consumption Time: 2.48876
PPO Batch Consumption Time: 0.28703
Total Iteration Time: 4.75099

Cumulative Model Updates: 4,430
Cumulative Timesteps: 37,062,464

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,941.23128
Policy Entropy: 1.10483
Value Function Loss: 0.74852

Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.09072
Policy Update Magnitude: 0.29203
Value Function Update Magnitude: 0.34668

Collected Steps per Second: 22,090.14857
Overall Steps per Second: 10,516.66541

Timestep Collection Time: 2.26391
Timestep Consumption Time: 2.49140
PPO Batch Consumption Time: 0.28644
Total Iteration Time: 4.75531

Cumulative Model Updates: 4,436
Cumulative Timesteps: 37,112,474

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 37112474...
Checkpoint 37112474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,894.03911
Policy Entropy: 1.11039
Value Function Loss: 0.71217

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.10726
Policy Update Magnitude: 0.24932
Value Function Update Magnitude: 0.38507

Collected Steps per Second: 21,981.70094
Overall Steps per Second: 10,382.97924

Timestep Collection Time: 2.27489
Timestep Consumption Time: 2.54126
PPO Batch Consumption Time: 0.29850
Total Iteration Time: 4.81615

Cumulative Model Updates: 4,442
Cumulative Timesteps: 37,162,480

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,223.48822
Policy Entropy: 1.09311
Value Function Loss: 0.75163

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.11423
Policy Update Magnitude: 0.21943
Value Function Update Magnitude: 0.36899

Collected Steps per Second: 22,409.38019
Overall Steps per Second: 10,448.07723

Timestep Collection Time: 2.23228
Timestep Consumption Time: 2.55559
PPO Batch Consumption Time: 0.29807
Total Iteration Time: 4.78787

Cumulative Model Updates: 4,448
Cumulative Timesteps: 37,212,504

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 37212504...
Checkpoint 37212504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,119.64283
Policy Entropy: 1.08657
Value Function Loss: 0.74876

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.09662
Policy Update Magnitude: 0.24593
Value Function Update Magnitude: 0.35889

Collected Steps per Second: 22,187.71234
Overall Steps per Second: 10,496.94711

Timestep Collection Time: 2.25494
Timestep Consumption Time: 2.51140
PPO Batch Consumption Time: 0.29044
Total Iteration Time: 4.76634

Cumulative Model Updates: 4,454
Cumulative Timesteps: 37,262,536

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,044.56567
Policy Entropy: 1.09603
Value Function Loss: 0.75007

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.09844
Policy Update Magnitude: 0.25175
Value Function Update Magnitude: 0.34645

Collected Steps per Second: 22,304.14463
Overall Steps per Second: 10,501.35375

Timestep Collection Time: 2.24209
Timestep Consumption Time: 2.51996
PPO Batch Consumption Time: 0.29086
Total Iteration Time: 4.76205

Cumulative Model Updates: 4,460
Cumulative Timesteps: 37,312,544

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 37312544...
Checkpoint 37312544 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,438.55600
Policy Entropy: 1.08282
Value Function Loss: 0.71625

Mean KL Divergence: 0.01258
SB3 Clip Fraction: 0.14492
Policy Update Magnitude: 0.21695
Value Function Update Magnitude: 0.32632

Collected Steps per Second: 22,249.69384
Overall Steps per Second: 10,655.38229

Timestep Collection Time: 2.24749
Timestep Consumption Time: 2.44554
PPO Batch Consumption Time: 0.28487
Total Iteration Time: 4.69303

Cumulative Model Updates: 4,466
Cumulative Timesteps: 37,362,550

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,575.42589
Policy Entropy: 1.09641
Value Function Loss: 0.69398

Mean KL Divergence: 0.01471
SB3 Clip Fraction: 0.15734
Policy Update Magnitude: 0.18015
Value Function Update Magnitude: 0.41599

Collected Steps per Second: 22,287.63247
Overall Steps per Second: 10,429.82194

Timestep Collection Time: 2.24402
Timestep Consumption Time: 2.55126
PPO Batch Consumption Time: 0.30021
Total Iteration Time: 4.79529

Cumulative Model Updates: 4,472
Cumulative Timesteps: 37,412,564

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 37412564...
Checkpoint 37412564 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,455.85489
Policy Entropy: 1.07572
Value Function Loss: 0.67740

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.10690
Policy Update Magnitude: 0.18111
Value Function Update Magnitude: 0.40322

Collected Steps per Second: 21,932.18410
Overall Steps per Second: 10,505.52828

Timestep Collection Time: 2.27985
Timestep Consumption Time: 2.47974
PPO Batch Consumption Time: 0.28587
Total Iteration Time: 4.75959

Cumulative Model Updates: 4,478
Cumulative Timesteps: 37,462,566

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,585.83141
Policy Entropy: 1.07696
Value Function Loss: 0.66847

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.09460
Policy Update Magnitude: 0.17587
Value Function Update Magnitude: 0.34780

Collected Steps per Second: 22,498.37523
Overall Steps per Second: 10,573.38841

Timestep Collection Time: 2.22247
Timestep Consumption Time: 2.50657
PPO Batch Consumption Time: 0.29122
Total Iteration Time: 4.72904

Cumulative Model Updates: 4,484
Cumulative Timesteps: 37,512,568

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 37512568...
Checkpoint 37512568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,655.38876
Policy Entropy: 1.07364
Value Function Loss: 0.68033

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.09349
Policy Update Magnitude: 0.17243
Value Function Update Magnitude: 0.32956

Collected Steps per Second: 21,966.66225
Overall Steps per Second: 10,588.15730

Timestep Collection Time: 2.27718
Timestep Consumption Time: 2.44716
PPO Batch Consumption Time: 0.28568
Total Iteration Time: 4.72433

Cumulative Model Updates: 4,490
Cumulative Timesteps: 37,562,590

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,699.71548
Policy Entropy: 1.05927
Value Function Loss: 0.69421

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.09584
Policy Update Magnitude: 0.18695
Value Function Update Magnitude: 0.29296

Collected Steps per Second: 22,077.95865
Overall Steps per Second: 10,515.20312

Timestep Collection Time: 2.26570
Timestep Consumption Time: 2.49141
PPO Batch Consumption Time: 0.30034
Total Iteration Time: 4.75711

Cumulative Model Updates: 4,496
Cumulative Timesteps: 37,612,612

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 37612612...
Checkpoint 37612612 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,908.47233
Policy Entropy: 1.03886
Value Function Loss: 0.66506

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.09290
Policy Update Magnitude: 0.22986
Value Function Update Magnitude: 0.30112

Collected Steps per Second: 21,517.67103
Overall Steps per Second: 10,274.59403

Timestep Collection Time: 2.32516
Timestep Consumption Time: 2.54433
PPO Batch Consumption Time: 0.29984
Total Iteration Time: 4.86949

Cumulative Model Updates: 4,502
Cumulative Timesteps: 37,662,644

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,498.97681
Policy Entropy: 1.05009
Value Function Loss: 0.69256

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.10470
Policy Update Magnitude: 0.22458
Value Function Update Magnitude: 0.33254

Collected Steps per Second: 22,141.91612
Overall Steps per Second: 10,609.33272

Timestep Collection Time: 2.25924
Timestep Consumption Time: 2.45585
PPO Batch Consumption Time: 0.29504
Total Iteration Time: 4.71509

Cumulative Model Updates: 4,508
Cumulative Timesteps: 37,712,668

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 37712668...
Checkpoint 37712668 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,239.99094
Policy Entropy: 1.05597
Value Function Loss: 0.67039

Mean KL Divergence: 0.00736
SB3 Clip Fraction: 0.07894
Policy Update Magnitude: 0.23168
Value Function Update Magnitude: 0.40468

Collected Steps per Second: 21,578.18496
Overall Steps per Second: 10,415.62877

Timestep Collection Time: 2.31808
Timestep Consumption Time: 2.48432
PPO Batch Consumption Time: 0.29941
Total Iteration Time: 4.80240

Cumulative Model Updates: 4,514
Cumulative Timesteps: 37,762,688

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,241.79436
Policy Entropy: 1.05280
Value Function Loss: 0.69069

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.08986
Policy Update Magnitude: 0.20521
Value Function Update Magnitude: 0.36192

Collected Steps per Second: 21,564.13119
Overall Steps per Second: 10,453.83314

Timestep Collection Time: 2.31931
Timestep Consumption Time: 2.46496
PPO Batch Consumption Time: 0.29375
Total Iteration Time: 4.78427

Cumulative Model Updates: 4,520
Cumulative Timesteps: 37,812,702

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 37812702...
Checkpoint 37812702 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,820.99618
Policy Entropy: 1.04280
Value Function Loss: 0.69436

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.09372
Policy Update Magnitude: 0.18028
Value Function Update Magnitude: 0.33786

Collected Steps per Second: 21,727.17438
Overall Steps per Second: 10,597.85620

Timestep Collection Time: 2.30173
Timestep Consumption Time: 2.41715
PPO Batch Consumption Time: 0.28659
Total Iteration Time: 4.71888

Cumulative Model Updates: 4,526
Cumulative Timesteps: 37,862,712

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,250.69478
Policy Entropy: 1.03258
Value Function Loss: 0.70321

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.09882
Policy Update Magnitude: 0.18260
Value Function Update Magnitude: 0.32526

Collected Steps per Second: 21,891.94578
Overall Steps per Second: 10,505.97903

Timestep Collection Time: 2.28458
Timestep Consumption Time: 2.47594
PPO Batch Consumption Time: 0.29688
Total Iteration Time: 4.76053

Cumulative Model Updates: 4,532
Cumulative Timesteps: 37,912,726

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 37912726...
Checkpoint 37912726 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,408.33279
Policy Entropy: 1.03561
Value Function Loss: 0.71339

Mean KL Divergence: 0.01189
SB3 Clip Fraction: 0.11500
Policy Update Magnitude: 0.21020
Value Function Update Magnitude: 0.32147

Collected Steps per Second: 22,278.54327
Overall Steps per Second: 10,579.45804

Timestep Collection Time: 2.24467
Timestep Consumption Time: 2.48223
PPO Batch Consumption Time: 0.28622
Total Iteration Time: 4.72690

Cumulative Model Updates: 4,538
Cumulative Timesteps: 37,962,734

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,759.50406
Policy Entropy: 1.05274
Value Function Loss: 0.70690

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.09834
Policy Update Magnitude: 0.19886
Value Function Update Magnitude: 0.33510

Collected Steps per Second: 22,307.04517
Overall Steps per Second: 10,489.55924

Timestep Collection Time: 2.24279
Timestep Consumption Time: 2.52672
PPO Batch Consumption Time: 0.29210
Total Iteration Time: 4.76950

Cumulative Model Updates: 4,544
Cumulative Timesteps: 38,012,764

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 38012764...
Checkpoint 38012764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,200.74777
Policy Entropy: 1.06060
Value Function Loss: 0.69188

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.09977
Policy Update Magnitude: 0.19755
Value Function Update Magnitude: 0.35977

Collected Steps per Second: 22,379.07536
Overall Steps per Second: 10,577.62144

Timestep Collection Time: 2.23432
Timestep Consumption Time: 2.49283
PPO Batch Consumption Time: 0.28636
Total Iteration Time: 4.72715

Cumulative Model Updates: 4,550
Cumulative Timesteps: 38,062,766

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,557.35219
Policy Entropy: 1.05486
Value Function Loss: 0.65047

Mean KL Divergence: 0.01236
SB3 Clip Fraction: 0.11489
Policy Update Magnitude: 0.20618
Value Function Update Magnitude: 0.37468

Collected Steps per Second: 22,362.92511
Overall Steps per Second: 10,540.81027

Timestep Collection Time: 2.23593
Timestep Consumption Time: 2.50773
PPO Batch Consumption Time: 0.28973
Total Iteration Time: 4.74366

Cumulative Model Updates: 4,556
Cumulative Timesteps: 38,112,768

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 38112768...
Checkpoint 38112768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,739.64655
Policy Entropy: 1.04253
Value Function Loss: 0.62002

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.08676
Policy Update Magnitude: 0.18269
Value Function Update Magnitude: 0.38420

Collected Steps per Second: 22,065.50254
Overall Steps per Second: 10,541.89074

Timestep Collection Time: 2.26698
Timestep Consumption Time: 2.47809
PPO Batch Consumption Time: 0.28679
Total Iteration Time: 4.74507

Cumulative Model Updates: 4,562
Cumulative Timesteps: 38,162,790

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,388.49090
Policy Entropy: 1.04976
Value Function Loss: 0.64313

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.10197
Policy Update Magnitude: 0.20269
Value Function Update Magnitude: 0.36857

Collected Steps per Second: 22,069.79999
Overall Steps per Second: 10,515.96268

Timestep Collection Time: 2.26581
Timestep Consumption Time: 2.48944
PPO Batch Consumption Time: 0.28633
Total Iteration Time: 4.75525

Cumulative Model Updates: 4,568
Cumulative Timesteps: 38,212,796

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 38212796...
Checkpoint 38212796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,512.88615
Policy Entropy: 1.03774
Value Function Loss: 0.65214

Mean KL Divergence: 0.01074
SB3 Clip Fraction: 0.09379
Policy Update Magnitude: 0.21130
Value Function Update Magnitude: 0.34617

Collected Steps per Second: 22,050.23239
Overall Steps per Second: 10,427.59370

Timestep Collection Time: 2.26764
Timestep Consumption Time: 2.52752
PPO Batch Consumption Time: 0.29601
Total Iteration Time: 4.79516

Cumulative Model Updates: 4,574
Cumulative Timesteps: 38,262,798

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,939.83792
Policy Entropy: 1.04164
Value Function Loss: 0.66261

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.08785
Policy Update Magnitude: 0.23761
Value Function Update Magnitude: 0.33874

Collected Steps per Second: 22,467.26328
Overall Steps per Second: 10,580.28591

Timestep Collection Time: 2.22599
Timestep Consumption Time: 2.50091
PPO Batch Consumption Time: 0.28678
Total Iteration Time: 4.72690

Cumulative Model Updates: 4,580
Cumulative Timesteps: 38,312,810

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 38312810...
Checkpoint 38312810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,400.20668
Policy Entropy: 1.03807
Value Function Loss: 0.66998

Mean KL Divergence: 0.01109
SB3 Clip Fraction: 0.10577
Policy Update Magnitude: 0.22914
Value Function Update Magnitude: 0.33427

Collected Steps per Second: 22,209.38240
Overall Steps per Second: 10,447.49345

Timestep Collection Time: 2.25202
Timestep Consumption Time: 2.53535
PPO Batch Consumption Time: 0.29789
Total Iteration Time: 4.78737

Cumulative Model Updates: 4,586
Cumulative Timesteps: 38,362,826

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,589.23426
Policy Entropy: 1.02477
Value Function Loss: 0.68725

Mean KL Divergence: 0.01572
SB3 Clip Fraction: 0.13900
Policy Update Magnitude: 0.19576
Value Function Update Magnitude: 0.34639

Collected Steps per Second: 22,215.17543
Overall Steps per Second: 10,371.46611

Timestep Collection Time: 2.25098
Timestep Consumption Time: 2.57051
PPO Batch Consumption Time: 0.30030
Total Iteration Time: 4.82150

Cumulative Model Updates: 4,592
Cumulative Timesteps: 38,412,832

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 38412832...
Checkpoint 38412832 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,087.46804
Policy Entropy: 1.01106
Value Function Loss: 0.70284

Mean KL Divergence: 0.01095
SB3 Clip Fraction: 0.11139
Policy Update Magnitude: 0.21205
Value Function Update Magnitude: 0.34566

Collected Steps per Second: 22,226.56597
Overall Steps per Second: 10,549.56770

Timestep Collection Time: 2.25100
Timestep Consumption Time: 2.49156
PPO Batch Consumption Time: 0.28644
Total Iteration Time: 4.74256

Cumulative Model Updates: 4,598
Cumulative Timesteps: 38,462,864

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,056.19233
Policy Entropy: 1.00116
Value Function Loss: 0.65023

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.10354
Policy Update Magnitude: 0.21703
Value Function Update Magnitude: 0.37527

Collected Steps per Second: 22,139.86168
Overall Steps per Second: 10,527.01198

Timestep Collection Time: 2.25882
Timestep Consumption Time: 2.49181
PPO Batch Consumption Time: 0.29313
Total Iteration Time: 4.75064

Cumulative Model Updates: 4,604
Cumulative Timesteps: 38,512,874

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 38512874...
Checkpoint 38512874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,455.74994
Policy Entropy: 1.00887
Value Function Loss: 0.64860

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.09428
Policy Update Magnitude: 0.19862
Value Function Update Magnitude: 0.35128

Collected Steps per Second: 22,291.82201
Overall Steps per Second: 10,656.35433

Timestep Collection Time: 2.24333
Timestep Consumption Time: 2.44945
PPO Batch Consumption Time: 0.28484
Total Iteration Time: 4.69279

Cumulative Model Updates: 4,610
Cumulative Timesteps: 38,562,882

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,140.71454
Policy Entropy: 1.01639
Value Function Loss: 0.64215

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.09138
Policy Update Magnitude: 0.19563
Value Function Update Magnitude: 0.35736

Collected Steps per Second: 22,090.17495
Overall Steps per Second: 10,412.01687

Timestep Collection Time: 2.26463
Timestep Consumption Time: 2.54001
PPO Batch Consumption Time: 0.29814
Total Iteration Time: 4.80464

Cumulative Model Updates: 4,616
Cumulative Timesteps: 38,612,908

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 38612908...
Checkpoint 38612908 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,680.76431
Policy Entropy: 1.02925
Value Function Loss: 0.64585

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.09175
Policy Update Magnitude: 0.18637
Value Function Update Magnitude: 0.31656

Collected Steps per Second: 22,333.80343
Overall Steps per Second: 10,626.81308

Timestep Collection Time: 2.23974
Timestep Consumption Time: 2.46741
PPO Batch Consumption Time: 0.28718
Total Iteration Time: 4.70715

Cumulative Model Updates: 4,622
Cumulative Timesteps: 38,662,930

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,659.43412
Policy Entropy: 1.03247
Value Function Loss: 0.63731

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.08417
Policy Update Magnitude: 0.18869
Value Function Update Magnitude: 0.30177

Collected Steps per Second: 22,162.14791
Overall Steps per Second: 10,503.11571

Timestep Collection Time: 2.25628
Timestep Consumption Time: 2.50459
PPO Batch Consumption Time: 0.29175
Total Iteration Time: 4.76087

Cumulative Model Updates: 4,628
Cumulative Timesteps: 38,712,934

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 38712934...
Checkpoint 38712934 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,361.32639
Policy Entropy: 1.03168
Value Function Loss: 0.63297

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.08733
Policy Update Magnitude: 0.18616
Value Function Update Magnitude: 0.32588

Collected Steps per Second: 22,248.92655
Overall Steps per Second: 10,631.07533

Timestep Collection Time: 2.24766
Timestep Consumption Time: 2.45629
PPO Batch Consumption Time: 0.28534
Total Iteration Time: 4.70395

Cumulative Model Updates: 4,634
Cumulative Timesteps: 38,762,942

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,858.71799
Policy Entropy: 1.03023
Value Function Loss: 0.64074

Mean KL Divergence: 0.00568
SB3 Clip Fraction: 0.06735
Policy Update Magnitude: 0.20464
Value Function Update Magnitude: 0.31961

Collected Steps per Second: 22,142.94512
Overall Steps per Second: 10,428.06852

Timestep Collection Time: 2.25869
Timestep Consumption Time: 2.53741
PPO Batch Consumption Time: 0.29629
Total Iteration Time: 4.79609

Cumulative Model Updates: 4,640
Cumulative Timesteps: 38,812,956

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 38812956...
Checkpoint 38812956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,385.01730
Policy Entropy: 1.01763
Value Function Loss: 0.64813

Mean KL Divergence: 0.00694
SB3 Clip Fraction: 0.08043
Policy Update Magnitude: 0.24216
Value Function Update Magnitude: 0.38615

Collected Steps per Second: 21,944.73318
Overall Steps per Second: 10,644.52318

Timestep Collection Time: 2.27909
Timestep Consumption Time: 2.41948
PPO Batch Consumption Time: 0.28574
Total Iteration Time: 4.69857

Cumulative Model Updates: 4,646
Cumulative Timesteps: 38,862,970

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,311.15971
Policy Entropy: 1.01332
Value Function Loss: 0.64839

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.09660
Policy Update Magnitude: 0.22323
Value Function Update Magnitude: 0.44963

Collected Steps per Second: 21,635.11805
Overall Steps per Second: 10,477.82740

Timestep Collection Time: 2.31124
Timestep Consumption Time: 2.46112
PPO Batch Consumption Time: 0.29444
Total Iteration Time: 4.77236

Cumulative Model Updates: 4,652
Cumulative Timesteps: 38,912,974

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 38912974...
Checkpoint 38912974 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,162.06437
Policy Entropy: 1.01463
Value Function Loss: 0.63710

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.09686
Policy Update Magnitude: 0.20707
Value Function Update Magnitude: 0.45873

Collected Steps per Second: 21,353.01682
Overall Steps per Second: 10,530.04001

Timestep Collection Time: 2.34262
Timestep Consumption Time: 2.40779
PPO Batch Consumption Time: 0.28631
Total Iteration Time: 4.75041

Cumulative Model Updates: 4,658
Cumulative Timesteps: 38,962,996

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,557.48485
Policy Entropy: 1.00398
Value Function Loss: 0.65287

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.09333
Policy Update Magnitude: 0.20519
Value Function Update Magnitude: 0.43753

Collected Steps per Second: 21,628.88273
Overall Steps per Second: 10,581.31776

Timestep Collection Time: 2.31191
Timestep Consumption Time: 2.41378
PPO Batch Consumption Time: 0.28586
Total Iteration Time: 4.72569

Cumulative Model Updates: 4,664
Cumulative Timesteps: 39,013,000

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 39013000...
Checkpoint 39013000 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,018.60974
Policy Entropy: 1.00288
Value Function Loss: 0.64078

Mean KL Divergence: 0.00766
SB3 Clip Fraction: 0.08664
Policy Update Magnitude: 0.22039
Value Function Update Magnitude: 0.33874

Collected Steps per Second: 22,351.81558
Overall Steps per Second: 10,576.24468

Timestep Collection Time: 2.23839
Timestep Consumption Time: 2.49222
PPO Batch Consumption Time: 0.28659
Total Iteration Time: 4.73060

Cumulative Model Updates: 4,670
Cumulative Timesteps: 39,063,032

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,404.54143
Policy Entropy: 1.00815
Value Function Loss: 0.62671

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.08371
Policy Update Magnitude: 0.20688
Value Function Update Magnitude: 0.32717

Collected Steps per Second: 22,545.30427
Overall Steps per Second: 10,515.97227

Timestep Collection Time: 2.21847
Timestep Consumption Time: 2.53773
PPO Batch Consumption Time: 0.29570
Total Iteration Time: 4.75619

Cumulative Model Updates: 4,676
Cumulative Timesteps: 39,113,048

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 39113048...
Checkpoint 39113048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,044.26091
Policy Entropy: 1.00639
Value Function Loss: 0.62037

Mean KL Divergence: 0.00666
SB3 Clip Fraction: 0.07583
Policy Update Magnitude: 0.20878
Value Function Update Magnitude: 0.35939

Collected Steps per Second: 22,296.95461
Overall Steps per Second: 10,598.54728

Timestep Collection Time: 2.24282
Timestep Consumption Time: 2.47557
PPO Batch Consumption Time: 0.28656
Total Iteration Time: 4.71838

Cumulative Model Updates: 4,682
Cumulative Timesteps: 39,163,056

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,896.94043
Policy Entropy: 1.03373
Value Function Loss: 0.66477

Mean KL Divergence: 0.01579
SB3 Clip Fraction: 0.13499
Policy Update Magnitude: 0.20998
Value Function Update Magnitude: 0.31900

Collected Steps per Second: 22,235.87747
Overall Steps per Second: 10,449.48108

Timestep Collection Time: 2.24871
Timestep Consumption Time: 2.53641
PPO Batch Consumption Time: 0.29284
Total Iteration Time: 4.78512

Cumulative Model Updates: 4,688
Cumulative Timesteps: 39,213,058

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 39213058...
Checkpoint 39213058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,327.87531
Policy Entropy: 1.04564
Value Function Loss: 0.65569

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.11443
Policy Update Magnitude: 0.21052
Value Function Update Magnitude: 0.32862

Collected Steps per Second: 22,118.48520
Overall Steps per Second: 10,420.04309

Timestep Collection Time: 2.26164
Timestep Consumption Time: 2.53911
PPO Batch Consumption Time: 0.29566
Total Iteration Time: 4.80075

Cumulative Model Updates: 4,694
Cumulative Timesteps: 39,263,082

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,312.65838
Policy Entropy: 1.04017
Value Function Loss: 0.68168

Mean KL Divergence: 0.01178
SB3 Clip Fraction: 0.11563
Policy Update Magnitude: 0.19423
Value Function Update Magnitude: 0.36346

Collected Steps per Second: 22,428.51332
Overall Steps per Second: 10,608.45661

Timestep Collection Time: 2.22975
Timestep Consumption Time: 2.48441
PPO Batch Consumption Time: 0.28602
Total Iteration Time: 4.71416

Cumulative Model Updates: 4,700
Cumulative Timesteps: 39,313,092

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 39313092...
Checkpoint 39313092 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,554.01966
Policy Entropy: 1.02742
Value Function Loss: 0.62404

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.10108
Policy Update Magnitude: 0.18458
Value Function Update Magnitude: 0.34573

Collected Steps per Second: 21,986.73861
Overall Steps per Second: 10,381.70831

Timestep Collection Time: 2.27555
Timestep Consumption Time: 2.54369
PPO Batch Consumption Time: 0.29989
Total Iteration Time: 4.81925

Cumulative Model Updates: 4,706
Cumulative Timesteps: 39,363,124

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,649.27698
Policy Entropy: 1.02027
Value Function Loss: 0.65117

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.09484
Policy Update Magnitude: 0.18621
Value Function Update Magnitude: 0.41844

Collected Steps per Second: 22,322.05503
Overall Steps per Second: 10,396.16435

Timestep Collection Time: 2.24119
Timestep Consumption Time: 2.57097
PPO Batch Consumption Time: 0.29957
Total Iteration Time: 4.81216

Cumulative Model Updates: 4,712
Cumulative Timesteps: 39,413,152

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 39413152...
Checkpoint 39413152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,526.48263
Policy Entropy: 1.02634
Value Function Loss: 0.64210

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.09428
Policy Update Magnitude: 0.19192
Value Function Update Magnitude: 0.38697

Collected Steps per Second: 22,067.73796
Overall Steps per Second: 10,530.86637

Timestep Collection Time: 2.26657
Timestep Consumption Time: 2.48309
PPO Batch Consumption Time: 0.28614
Total Iteration Time: 4.74966

Cumulative Model Updates: 4,718
Cumulative Timesteps: 39,463,170

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,796.07698
Policy Entropy: 1.02329
Value Function Loss: 0.65195

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.09865
Policy Update Magnitude: 0.20955
Value Function Update Magnitude: 0.34916

Collected Steps per Second: 22,391.83710
Overall Steps per Second: 10,572.36158

Timestep Collection Time: 2.23403
Timestep Consumption Time: 2.49755
PPO Batch Consumption Time: 0.29014
Total Iteration Time: 4.73158

Cumulative Model Updates: 4,724
Cumulative Timesteps: 39,513,194

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 39513194...
Checkpoint 39513194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,332.22199
Policy Entropy: 1.02035
Value Function Loss: 0.61265

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.09654
Policy Update Magnitude: 0.21262
Value Function Update Magnitude: 0.31357

Collected Steps per Second: 22,089.88741
Overall Steps per Second: 10,568.06218

Timestep Collection Time: 2.26448
Timestep Consumption Time: 2.46884
PPO Batch Consumption Time: 0.28650
Total Iteration Time: 4.73332

Cumulative Model Updates: 4,730
Cumulative Timesteps: 39,563,216

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,032.09216
Policy Entropy: 1.02521
Value Function Loss: 0.62837

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.08969
Policy Update Magnitude: 0.19911
Value Function Update Magnitude: 0.28684

Collected Steps per Second: 22,349.37678
Overall Steps per Second: 10,515.85850

Timestep Collection Time: 2.23756
Timestep Consumption Time: 2.51793
PPO Batch Consumption Time: 0.29439
Total Iteration Time: 4.75548

Cumulative Model Updates: 4,736
Cumulative Timesteps: 39,613,224

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 39613224...
Checkpoint 39613224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,268.10443
Policy Entropy: 1.03131
Value Function Loss: 0.60636

Mean KL Divergence: 0.00752
SB3 Clip Fraction: 0.08320
Policy Update Magnitude: 0.21721
Value Function Update Magnitude: 0.28017

Collected Steps per Second: 21,872.20035
Overall Steps per Second: 10,518.39147

Timestep Collection Time: 2.28656
Timestep Consumption Time: 2.46816
PPO Batch Consumption Time: 0.28646
Total Iteration Time: 4.75472

Cumulative Model Updates: 4,742
Cumulative Timesteps: 39,663,236

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,505.88045
Policy Entropy: 1.02304
Value Function Loss: 0.62807

Mean KL Divergence: 0.00694
SB3 Clip Fraction: 0.07567
Policy Update Magnitude: 0.21562
Value Function Update Magnitude: 0.34661

Collected Steps per Second: 22,350.22767
Overall Steps per Second: 10,592.28966

Timestep Collection Time: 2.23756
Timestep Consumption Time: 2.48380
PPO Batch Consumption Time: 0.28935
Total Iteration Time: 4.72136

Cumulative Model Updates: 4,748
Cumulative Timesteps: 39,713,246

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 39713246...
Checkpoint 39713246 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,765.20675
Policy Entropy: 1.02621
Value Function Loss: 0.60039

Mean KL Divergence: 0.00668
SB3 Clip Fraction: 0.07395
Policy Update Magnitude: 0.20824
Value Function Update Magnitude: 0.35514

Collected Steps per Second: 21,837.41864
Overall Steps per Second: 10,280.30479

Timestep Collection Time: 2.29038
Timestep Consumption Time: 2.57484
PPO Batch Consumption Time: 0.29862
Total Iteration Time: 4.86523

Cumulative Model Updates: 4,754
Cumulative Timesteps: 39,763,262

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,829.51323
Policy Entropy: 1.02325
Value Function Loss: 0.61135

Mean KL Divergence: 0.00599
SB3 Clip Fraction: 0.06619
Policy Update Magnitude: 0.21625
Value Function Update Magnitude: 0.39020

Collected Steps per Second: 21,394.00503
Overall Steps per Second: 10,329.80975

Timestep Collection Time: 2.33776
Timestep Consumption Time: 2.50396
PPO Batch Consumption Time: 0.29784
Total Iteration Time: 4.84172

Cumulative Model Updates: 4,760
Cumulative Timesteps: 39,813,276

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 39813276...
Checkpoint 39813276 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,465.84285
Policy Entropy: 1.01867
Value Function Loss: 0.61544

Mean KL Divergence: 0.00705
SB3 Clip Fraction: 0.07489
Policy Update Magnitude: 0.21389
Value Function Update Magnitude: 0.35155

Collected Steps per Second: 21,433.56918
Overall Steps per Second: 10,556.03554

Timestep Collection Time: 2.33391
Timestep Consumption Time: 2.40499
PPO Batch Consumption Time: 0.28650
Total Iteration Time: 4.73890

Cumulative Model Updates: 4,766
Cumulative Timesteps: 39,863,300

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,456.99578
Policy Entropy: 1.02537
Value Function Loss: 0.63777

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.07893
Policy Update Magnitude: 0.21839
Value Function Update Magnitude: 0.30586

Collected Steps per Second: 21,640.39565
Overall Steps per Second: 10,608.14900

Timestep Collection Time: 2.31096
Timestep Consumption Time: 2.40334
PPO Batch Consumption Time: 0.28482
Total Iteration Time: 4.71430

Cumulative Model Updates: 4,772
Cumulative Timesteps: 39,913,310

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 39913310...
Checkpoint 39913310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,173.07215
Policy Entropy: 1.02010
Value Function Loss: 0.65693

Mean KL Divergence: 0.01373
SB3 Clip Fraction: 0.12015
Policy Update Magnitude: 0.20106
Value Function Update Magnitude: 0.29339

Collected Steps per Second: 21,246.56544
Overall Steps per Second: 10,484.03979

Timestep Collection Time: 2.35379
Timestep Consumption Time: 2.41632
PPO Batch Consumption Time: 0.28684
Total Iteration Time: 4.77011

Cumulative Model Updates: 4,778
Cumulative Timesteps: 39,963,320

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,668.49400
Policy Entropy: 1.02270
Value Function Loss: 0.65985

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.09222
Policy Update Magnitude: 0.21587
Value Function Update Magnitude: 0.31863

Collected Steps per Second: 21,693.75276
Overall Steps per Second: 10,546.55986

Timestep Collection Time: 2.30481
Timestep Consumption Time: 2.43607
PPO Batch Consumption Time: 0.28987
Total Iteration Time: 4.74088

Cumulative Model Updates: 4,784
Cumulative Timesteps: 40,013,320

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 40013320...
Checkpoint 40013320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,068.91816
Policy Entropy: 1.03343
Value Function Loss: 0.63821

Mean KL Divergence: 0.01175
SB3 Clip Fraction: 0.11126
Policy Update Magnitude: 0.22353
Value Function Update Magnitude: 0.38049

Collected Steps per Second: 21,729.36841
Overall Steps per Second: 10,319.04009

Timestep Collection Time: 2.30195
Timestep Consumption Time: 2.54540
PPO Batch Consumption Time: 0.29853
Total Iteration Time: 4.84735

Cumulative Model Updates: 4,790
Cumulative Timesteps: 40,063,340

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,536.85566
Policy Entropy: 1.03845
Value Function Loss: 0.61986

Mean KL Divergence: 0.01218
SB3 Clip Fraction: 0.11417
Policy Update Magnitude: 0.21480
Value Function Update Magnitude: 0.38841

Collected Steps per Second: 22,568.11238
Overall Steps per Second: 10,531.28736

Timestep Collection Time: 2.21605
Timestep Consumption Time: 2.53285
PPO Batch Consumption Time: 0.29606
Total Iteration Time: 4.74890

Cumulative Model Updates: 4,796
Cumulative Timesteps: 40,113,352

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 40113352...
Checkpoint 40113352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,700.20505
Policy Entropy: 1.04240
Value Function Loss: 0.59138

Mean KL Divergence: 0.01489
SB3 Clip Fraction: 0.13295
Policy Update Magnitude: 0.19635
Value Function Update Magnitude: 0.35597

Collected Steps per Second: 22,142.54543
Overall Steps per Second: 10,467.01783

Timestep Collection Time: 2.25846
Timestep Consumption Time: 2.51922
PPO Batch Consumption Time: 0.29141
Total Iteration Time: 4.77767

Cumulative Model Updates: 4,802
Cumulative Timesteps: 40,163,360

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,225.45000
Policy Entropy: 1.03729
Value Function Loss: 0.63381

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.10257
Policy Update Magnitude: 0.19933
Value Function Update Magnitude: 0.39554

Collected Steps per Second: 22,301.22039
Overall Steps per Second: 10,451.42692

Timestep Collection Time: 2.24284
Timestep Consumption Time: 2.54292
PPO Batch Consumption Time: 0.29361
Total Iteration Time: 4.78576

Cumulative Model Updates: 4,808
Cumulative Timesteps: 40,213,378

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 40213378...
Checkpoint 40213378 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,445.76835
Policy Entropy: 1.00795
Value Function Loss: 0.62452

Mean KL Divergence: 0.01151
SB3 Clip Fraction: 0.11404
Policy Update Magnitude: 0.20786
Value Function Update Magnitude: 0.33744

Collected Steps per Second: 22,180.44053
Overall Steps per Second: 10,545.76083

Timestep Collection Time: 2.25532
Timestep Consumption Time: 2.48820
PPO Batch Consumption Time: 0.28624
Total Iteration Time: 4.74352

Cumulative Model Updates: 4,814
Cumulative Timesteps: 40,263,402

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,166.61642
Policy Entropy: 1.01500
Value Function Loss: 0.62894

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.10757
Policy Update Magnitude: 0.25020
Value Function Update Magnitude: 0.33860

Collected Steps per Second: 22,474.09824
Overall Steps per Second: 10,593.75906

Timestep Collection Time: 2.22550
Timestep Consumption Time: 2.49578
PPO Batch Consumption Time: 0.28903
Total Iteration Time: 4.72127

Cumulative Model Updates: 4,820
Cumulative Timesteps: 40,313,418

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 40313418...
Checkpoint 40313418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,112.16486
Policy Entropy: 1.00178
Value Function Loss: 0.58808

Mean KL Divergence: 0.01366
SB3 Clip Fraction: 0.12778
Policy Update Magnitude: 0.21984
Value Function Update Magnitude: 0.36368

Collected Steps per Second: 21,775.93872
Overall Steps per Second: 10,357.46275

Timestep Collection Time: 2.29639
Timestep Consumption Time: 2.53163
PPO Batch Consumption Time: 0.29583
Total Iteration Time: 4.82802

Cumulative Model Updates: 4,826
Cumulative Timesteps: 40,363,424

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,511.31802
Policy Entropy: 1.01501
Value Function Loss: 0.62400

Mean KL Divergence: 0.01453
SB3 Clip Fraction: 0.14151
Policy Update Magnitude: 0.19766
Value Function Update Magnitude: 0.42530

Collected Steps per Second: 22,491.37422
Overall Steps per Second: 10,612.52365

Timestep Collection Time: 2.22432
Timestep Consumption Time: 2.48973
PPO Batch Consumption Time: 0.28628
Total Iteration Time: 4.71405

Cumulative Model Updates: 4,832
Cumulative Timesteps: 40,413,452

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 40413452...
Checkpoint 40413452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,612.43908
Policy Entropy: 1.02056
Value Function Loss: 0.60793

Mean KL Divergence: 0.01483
SB3 Clip Fraction: 0.13204
Policy Update Magnitude: 0.19020
Value Function Update Magnitude: 0.35942

Collected Steps per Second: 22,137.40735
Overall Steps per Second: 10,435.73676

Timestep Collection Time: 2.25961
Timestep Consumption Time: 2.53372
PPO Batch Consumption Time: 0.29742
Total Iteration Time: 4.79334

Cumulative Model Updates: 4,838
Cumulative Timesteps: 40,463,474

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,590.05770
Policy Entropy: 1.00207
Value Function Loss: 0.64659

Mean KL Divergence: 0.01191
SB3 Clip Fraction: 0.11998
Policy Update Magnitude: 0.20616
Value Function Update Magnitude: 0.30769

Collected Steps per Second: 22,479.68859
Overall Steps per Second: 10,497.29955

Timestep Collection Time: 2.22539
Timestep Consumption Time: 2.54022
PPO Batch Consumption Time: 0.29629
Total Iteration Time: 4.76561

Cumulative Model Updates: 4,844
Cumulative Timesteps: 40,513,500

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 40513500...
Checkpoint 40513500 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,795.50368
Policy Entropy: 0.98895
Value Function Loss: 0.61059

Mean KL Divergence: 0.01369
SB3 Clip Fraction: 0.13635
Policy Update Magnitude: 0.19631
Value Function Update Magnitude: 0.30960

Collected Steps per Second: 22,069.43069
Overall Steps per Second: 10,479.53236

Timestep Collection Time: 2.26657
Timestep Consumption Time: 2.50673
PPO Batch Consumption Time: 0.28968
Total Iteration Time: 4.77330

Cumulative Model Updates: 4,850
Cumulative Timesteps: 40,563,522

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,678.39417
Policy Entropy: 0.96662
Value Function Loss: 0.62772

Mean KL Divergence: 0.01241
SB3 Clip Fraction: 0.12664
Policy Update Magnitude: 0.17951
Value Function Update Magnitude: 0.30550

Collected Steps per Second: 22,515.61202
Overall Steps per Second: 10,510.91739

Timestep Collection Time: 2.22113
Timestep Consumption Time: 2.53678
PPO Batch Consumption Time: 0.29921
Total Iteration Time: 4.75791

Cumulative Model Updates: 4,856
Cumulative Timesteps: 40,613,532

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 40613532...
Checkpoint 40613532 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,110.26982
Policy Entropy: 0.97033
Value Function Loss: 0.60214

Mean KL Divergence: 0.01145
SB3 Clip Fraction: 0.11648
Policy Update Magnitude: 0.17774
Value Function Update Magnitude: 0.32760

Collected Steps per Second: 22,305.43537
Overall Steps per Second: 10,574.67776

Timestep Collection Time: 2.24286
Timestep Consumption Time: 2.48806
PPO Batch Consumption Time: 0.29005
Total Iteration Time: 4.73092

Cumulative Model Updates: 4,862
Cumulative Timesteps: 40,663,560

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,715.35237
Policy Entropy: 0.96155
Value Function Loss: 0.58724

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.10377
Policy Update Magnitude: 0.18535
Value Function Update Magnitude: 0.34109

Collected Steps per Second: 22,624.17540
Overall Steps per Second: 10,543.70533

Timestep Collection Time: 2.21011
Timestep Consumption Time: 2.53224
PPO Batch Consumption Time: 0.29883
Total Iteration Time: 4.74236

Cumulative Model Updates: 4,868
Cumulative Timesteps: 40,713,562

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 40713562...
Checkpoint 40713562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,852.83525
Policy Entropy: 0.96468
Value Function Loss: 0.58222

Mean KL Divergence: 0.00600
SB3 Clip Fraction: 0.07000
Policy Update Magnitude: 0.23422
Value Function Update Magnitude: 0.34878

Collected Steps per Second: 22,173.62732
Overall Steps per Second: 10,528.67409

Timestep Collection Time: 2.25547
Timestep Consumption Time: 2.49460
PPO Batch Consumption Time: 0.29084
Total Iteration Time: 4.75008

Cumulative Model Updates: 4,874
Cumulative Timesteps: 40,763,574

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,047.90816
Policy Entropy: 0.95999
Value Function Loss: 0.57905

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.10647
Policy Update Magnitude: 0.25457
Value Function Update Magnitude: 0.35950

Collected Steps per Second: 22,271.75062
Overall Steps per Second: 10,527.89716

Timestep Collection Time: 2.24598
Timestep Consumption Time: 2.50539
PPO Batch Consumption Time: 0.30397
Total Iteration Time: 4.75138

Cumulative Model Updates: 4,880
Cumulative Timesteps: 40,813,596

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 40813596...
Checkpoint 40813596 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,951.56568
Policy Entropy: 0.94866
Value Function Loss: 0.55828

Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.08861
Policy Update Magnitude: 0.22384
Value Function Update Magnitude: 0.36844

Collected Steps per Second: 21,522.07532
Overall Steps per Second: 10,541.11263

Timestep Collection Time: 2.32375
Timestep Consumption Time: 2.42072
PPO Batch Consumption Time: 0.28656
Total Iteration Time: 4.74447

Cumulative Model Updates: 4,886
Cumulative Timesteps: 40,863,608

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,389.90767
Policy Entropy: 0.93867
Value Function Loss: 0.53682

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.08515
Policy Update Magnitude: 0.22171
Value Function Update Magnitude: 0.45851

Collected Steps per Second: 21,631.16660
Overall Steps per Second: 10,491.01469

Timestep Collection Time: 2.31213
Timestep Consumption Time: 2.45519
PPO Batch Consumption Time: 0.29046
Total Iteration Time: 4.76732

Cumulative Model Updates: 4,892
Cumulative Timesteps: 40,913,622

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 40913622...
Checkpoint 40913622 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,373.22022
Policy Entropy: 0.94328
Value Function Loss: 0.53659

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.08968
Policy Update Magnitude: 0.21381
Value Function Update Magnitude: 0.41747

Collected Steps per Second: 21,273.85151
Overall Steps per Second: 10,393.11840

Timestep Collection Time: 2.35077
Timestep Consumption Time: 2.46106
PPO Batch Consumption Time: 0.29716
Total Iteration Time: 4.81184

Cumulative Model Updates: 4,898
Cumulative Timesteps: 40,963,632

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,944.52006
Policy Entropy: 0.95673
Value Function Loss: 0.56112

Mean KL Divergence: 0.01173
SB3 Clip Fraction: 0.10858
Policy Update Magnitude: 0.20879
Value Function Update Magnitude: 0.45024

Collected Steps per Second: 22,591.56083
Overall Steps per Second: 10,638.57456

Timestep Collection Time: 2.21437
Timestep Consumption Time: 2.48796
PPO Batch Consumption Time: 0.28655
Total Iteration Time: 4.70232

Cumulative Model Updates: 4,904
Cumulative Timesteps: 41,013,658

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 41013658...
Checkpoint 41013658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,832.41228
Policy Entropy: 0.96490
Value Function Loss: 0.58902

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.08534
Policy Update Magnitude: 0.23885
Value Function Update Magnitude: 0.41162

Collected Steps per Second: 22,346.55737
Overall Steps per Second: 10,533.43329

Timestep Collection Time: 2.23873
Timestep Consumption Time: 2.51071
PPO Batch Consumption Time: 0.29381
Total Iteration Time: 4.74945

Cumulative Model Updates: 4,910
Cumulative Timesteps: 41,063,686

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,224.81300
Policy Entropy: 0.98947
Value Function Loss: 0.56925

Mean KL Divergence: 0.01236
SB3 Clip Fraction: 0.11752
Policy Update Magnitude: 0.20645
Value Function Update Magnitude: 0.43474

Collected Steps per Second: 22,524.90673
Overall Steps per Second: 10,624.68287

Timestep Collection Time: 2.21994
Timestep Consumption Time: 2.48646
PPO Batch Consumption Time: 0.28624
Total Iteration Time: 4.70640

Cumulative Model Updates: 4,916
Cumulative Timesteps: 41,113,690

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 41113690...
Checkpoint 41113690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,787.29139
Policy Entropy: 0.99566
Value Function Loss: 0.56135

Mean KL Divergence: 0.01207
SB3 Clip Fraction: 0.11660
Policy Update Magnitude: 0.18610
Value Function Update Magnitude: 0.44844

Collected Steps per Second: 21,928.13138
Overall Steps per Second: 10,382.51818

Timestep Collection Time: 2.28081
Timestep Consumption Time: 2.53632
PPO Batch Consumption Time: 0.29761
Total Iteration Time: 4.81714

Cumulative Model Updates: 4,922
Cumulative Timesteps: 41,163,704

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,458.37292
Policy Entropy: 0.98880
Value Function Loss: 0.57456

Mean KL Divergence: 0.01101
SB3 Clip Fraction: 0.10919
Policy Update Magnitude: 0.18089
Value Function Update Magnitude: 0.43317

Collected Steps per Second: 22,321.32992
Overall Steps per Second: 10,477.38288

Timestep Collection Time: 2.24001
Timestep Consumption Time: 2.53217
PPO Batch Consumption Time: 0.29634
Total Iteration Time: 4.77218

Cumulative Model Updates: 4,928
Cumulative Timesteps: 41,213,704

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 41213704...
Checkpoint 41213704 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,615.05543
Policy Entropy: 0.97750
Value Function Loss: 0.58395

Mean KL Divergence: 0.00722
SB3 Clip Fraction: 0.07949
Policy Update Magnitude: 0.19538
Value Function Update Magnitude: 0.45352

Collected Steps per Second: 22,184.75617
Overall Steps per Second: 10,485.06521

Timestep Collection Time: 2.25407
Timestep Consumption Time: 2.51519
PPO Batch Consumption Time: 0.29171
Total Iteration Time: 4.76926

Cumulative Model Updates: 4,934
Cumulative Timesteps: 41,263,710

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,142.83686
Policy Entropy: 0.97442
Value Function Loss: 0.57547

Mean KL Divergence: 0.01134
SB3 Clip Fraction: 0.11324
Policy Update Magnitude: 0.18121
Value Function Update Magnitude: 0.41440

Collected Steps per Second: 22,342.81483
Overall Steps per Second: 10,461.57100

Timestep Collection Time: 2.23786
Timestep Consumption Time: 2.54154
PPO Batch Consumption Time: 0.29440
Total Iteration Time: 4.77940

Cumulative Model Updates: 4,940
Cumulative Timesteps: 41,313,710

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 41313710...
Checkpoint 41313710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,257.45272
Policy Entropy: 0.98157
Value Function Loss: 0.57900

Mean KL Divergence: 0.01207
SB3 Clip Fraction: 0.11119
Policy Update Magnitude: 0.19256
Value Function Update Magnitude: 0.37838

Collected Steps per Second: 22,153.33304
Overall Steps per Second: 10,559.40765

Timestep Collection Time: 2.25709
Timestep Consumption Time: 2.47822
PPO Batch Consumption Time: 0.28595
Total Iteration Time: 4.73530

Cumulative Model Updates: 4,946
Cumulative Timesteps: 41,363,712

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,216.68611
Policy Entropy: 0.97539
Value Function Loss: 0.60097

Mean KL Divergence: 0.01090
SB3 Clip Fraction: 0.10919
Policy Update Magnitude: 0.21972
Value Function Update Magnitude: 0.39913

Collected Steps per Second: 22,346.67229
Overall Steps per Second: 10,531.59315

Timestep Collection Time: 2.23774
Timestep Consumption Time: 2.51045
PPO Batch Consumption Time: 0.28915
Total Iteration Time: 4.74819

Cumulative Model Updates: 4,952
Cumulative Timesteps: 41,413,718

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 41413718...
Checkpoint 41413718 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,003.83048
Policy Entropy: 0.99115
Value Function Loss: 0.60379

Mean KL Divergence: 0.02198
SB3 Clip Fraction: 0.17202
Policy Update Magnitude: 0.21849
Value Function Update Magnitude: 0.37617

Collected Steps per Second: 22,198.56017
Overall Steps per Second: 10,525.69909

Timestep Collection Time: 2.25321
Timestep Consumption Time: 2.49878
PPO Batch Consumption Time: 0.28875
Total Iteration Time: 4.75199

Cumulative Model Updates: 4,958
Cumulative Timesteps: 41,463,736

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,752.68971
Policy Entropy: 0.96794
Value Function Loss: 0.62944

Mean KL Divergence: 0.01201
SB3 Clip Fraction: 0.11500
Policy Update Magnitude: 0.17601
Value Function Update Magnitude: 0.32605

Collected Steps per Second: 22,400.37415
Overall Steps per Second: 10,532.16954

Timestep Collection Time: 2.23309
Timestep Consumption Time: 2.51636
PPO Batch Consumption Time: 0.29407
Total Iteration Time: 4.74945

Cumulative Model Updates: 4,964
Cumulative Timesteps: 41,513,758

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 41513758...
Checkpoint 41513758 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,498.47391
Policy Entropy: 0.96009
Value Function Loss: 0.59479

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.09530
Policy Update Magnitude: 0.18798
Value Function Update Magnitude: 0.33743

Collected Steps per Second: 21,932.99537
Overall Steps per Second: 10,567.21805

Timestep Collection Time: 2.28095
Timestep Consumption Time: 2.45332
PPO Batch Consumption Time: 0.28554
Total Iteration Time: 4.73426

Cumulative Model Updates: 4,970
Cumulative Timesteps: 41,563,786

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,608.08335
Policy Entropy: 0.94249
Value Function Loss: 0.60381

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.08164
Policy Update Magnitude: 0.20472
Value Function Update Magnitude: 0.34253

Collected Steps per Second: 21,085.49928
Overall Steps per Second: 10,022.27154

Timestep Collection Time: 2.37168
Timestep Consumption Time: 2.61801
PPO Batch Consumption Time: 0.31441
Total Iteration Time: 4.98969

Cumulative Model Updates: 4,976
Cumulative Timesteps: 41,613,794

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 41613794...
Checkpoint 41613794 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,988.08163
Policy Entropy: 0.92992
Value Function Loss: 0.55016

Mean KL Divergence: 0.00696
SB3 Clip Fraction: 0.07895
Policy Update Magnitude: 0.22064
Value Function Update Magnitude: 0.37273

Collected Steps per Second: 22,600.47463
Overall Steps per Second: 10,745.90104

Timestep Collection Time: 2.21261
Timestep Consumption Time: 2.44089
PPO Batch Consumption Time: 0.28489
Total Iteration Time: 4.65350

Cumulative Model Updates: 4,982
Cumulative Timesteps: 41,663,800

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,158.12336
Policy Entropy: 0.94383
Value Function Loss: 0.54441

Mean KL Divergence: 0.00651
SB3 Clip Fraction: 0.07470
Policy Update Magnitude: 0.24035
Value Function Update Magnitude: 0.42305

Collected Steps per Second: 22,940.49190
Overall Steps per Second: 10,667.17275

Timestep Collection Time: 2.17964
Timestep Consumption Time: 2.50783
PPO Batch Consumption Time: 0.29383
Total Iteration Time: 4.68747

Cumulative Model Updates: 4,988
Cumulative Timesteps: 41,713,802

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 41713802...
Checkpoint 41713802 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,627.02987
Policy Entropy: 0.94715
Value Function Loss: 0.56334

Mean KL Divergence: 0.00725
SB3 Clip Fraction: 0.08091
Policy Update Magnitude: 0.27769
Value Function Update Magnitude: 0.41255

Collected Steps per Second: 22,656.69427
Overall Steps per Second: 10,604.61399

Timestep Collection Time: 2.20712
Timestep Consumption Time: 2.50838
PPO Batch Consumption Time: 0.29509
Total Iteration Time: 4.71549

Cumulative Model Updates: 4,994
Cumulative Timesteps: 41,763,808

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,727.44372
Policy Entropy: 0.94456
Value Function Loss: 0.59584

Mean KL Divergence: 0.00706
SB3 Clip Fraction: 0.07982
Policy Update Magnitude: 0.23203
Value Function Update Magnitude: 0.32182

Collected Steps per Second: 23,009.59040
Overall Steps per Second: 10,779.11352

Timestep Collection Time: 2.17405
Timestep Consumption Time: 2.46678
PPO Batch Consumption Time: 0.29646
Total Iteration Time: 4.64083

Cumulative Model Updates: 5,000
Cumulative Timesteps: 41,813,832

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 41813832...
Checkpoint 41813832 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,879.30746
Policy Entropy: 0.95475
Value Function Loss: 0.58626

Mean KL Divergence: 0.00719
SB3 Clip Fraction: 0.07868
Policy Update Magnitude: 0.20357
Value Function Update Magnitude: 0.30480

Collected Steps per Second: 22,102.54551
Overall Steps per Second: 10,659.18521

Timestep Collection Time: 2.26345
Timestep Consumption Time: 2.42997
PPO Batch Consumption Time: 0.29225
Total Iteration Time: 4.69342

Cumulative Model Updates: 5,006
Cumulative Timesteps: 41,863,860

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,486.54066
Policy Entropy: 0.94570
Value Function Loss: 0.57813

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.10104
Policy Update Magnitude: 0.19528
Value Function Update Magnitude: 0.31067

Collected Steps per Second: 22,103.09968
Overall Steps per Second: 10,572.40119

Timestep Collection Time: 2.26249
Timestep Consumption Time: 2.46756
PPO Batch Consumption Time: 0.29706
Total Iteration Time: 4.73005

Cumulative Model Updates: 5,012
Cumulative Timesteps: 41,913,868

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 41913868...
Checkpoint 41913868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,503.95528
Policy Entropy: 0.95381
Value Function Loss: 0.55537

Mean KL Divergence: 0.00735
SB3 Clip Fraction: 0.08221
Policy Update Magnitude: 0.24267
Value Function Update Magnitude: 0.31851

Collected Steps per Second: 22,067.39884
Overall Steps per Second: 10,593.30739

Timestep Collection Time: 2.26651
Timestep Consumption Time: 2.45496
PPO Batch Consumption Time: 0.29772
Total Iteration Time: 4.72147

Cumulative Model Updates: 5,018
Cumulative Timesteps: 41,963,884

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,335.64745
Policy Entropy: 0.93996
Value Function Loss: 0.55116

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.09514
Policy Update Magnitude: 0.24709
Value Function Update Magnitude: 0.32776

Collected Steps per Second: 21,474.83313
Overall Steps per Second: 10,758.85288

Timestep Collection Time: 2.32831
Timestep Consumption Time: 2.31903
PPO Batch Consumption Time: 0.28369
Total Iteration Time: 4.64734

Cumulative Model Updates: 5,024
Cumulative Timesteps: 42,013,884

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 42013884...
Checkpoint 42013884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,687.22041
Policy Entropy: 0.91937
Value Function Loss: 0.55383

Mean KL Divergence: 0.00561
SB3 Clip Fraction: 0.06557
Policy Update Magnitude: 0.23543
Value Function Update Magnitude: 0.34162

Collected Steps per Second: 22,510.96579
Overall Steps per Second: 10,703.46331

Timestep Collection Time: 2.22132
Timestep Consumption Time: 2.45044
PPO Batch Consumption Time: 0.28307
Total Iteration Time: 4.67176

Cumulative Model Updates: 5,030
Cumulative Timesteps: 42,063,888

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,598.88720
Policy Entropy: 0.92881
Value Function Loss: 0.56698

Mean KL Divergence: 0.00630
SB3 Clip Fraction: 0.07588
Policy Update Magnitude: 0.26523
Value Function Update Magnitude: 0.33634

Collected Steps per Second: 22,690.88140
Overall Steps per Second: 10,579.63466

Timestep Collection Time: 2.20432
Timestep Consumption Time: 2.52344
PPO Batch Consumption Time: 0.29548
Total Iteration Time: 4.72776

Cumulative Model Updates: 5,036
Cumulative Timesteps: 42,113,906

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 42113906...
Checkpoint 42113906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,208.32039
Policy Entropy: 0.92102
Value Function Loss: 0.57554

Mean KL Divergence: 0.01270
SB3 Clip Fraction: 0.13901
Policy Update Magnitude: 0.25239
Value Function Update Magnitude: 0.33792

Collected Steps per Second: 22,633.44212
Overall Steps per Second: 10,554.91585

Timestep Collection Time: 2.21027
Timestep Consumption Time: 2.52932
PPO Batch Consumption Time: 0.29860
Total Iteration Time: 4.73959

Cumulative Model Updates: 5,042
Cumulative Timesteps: 42,163,932

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,319.49606
Policy Entropy: 0.89979
Value Function Loss: 0.58883

Mean KL Divergence: 0.01422
SB3 Clip Fraction: 0.15026
Policy Update Magnitude: 0.21271
Value Function Update Magnitude: 0.33677

Collected Steps per Second: 22,800.60830
Overall Steps per Second: 10,614.68326

Timestep Collection Time: 2.19319
Timestep Consumption Time: 2.51783
PPO Batch Consumption Time: 0.29487
Total Iteration Time: 4.71102

Cumulative Model Updates: 5,048
Cumulative Timesteps: 42,213,938

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 42213938...
Checkpoint 42213938 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,597.90208
Policy Entropy: 0.85591
Value Function Loss: 0.58408

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.09161
Policy Update Magnitude: 0.22055
Value Function Update Magnitude: 0.36740

Collected Steps per Second: 22,483.99848
Overall Steps per Second: 10,461.72952

Timestep Collection Time: 2.22407
Timestep Consumption Time: 2.55583
PPO Batch Consumption Time: 0.30528
Total Iteration Time: 4.77990

Cumulative Model Updates: 5,054
Cumulative Timesteps: 42,263,944

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,399.12736
Policy Entropy: 0.84149
Value Function Loss: 0.57614

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.09902
Policy Update Magnitude: 0.20233
Value Function Update Magnitude: 0.38762

Collected Steps per Second: 22,564.45322
Overall Steps per Second: 10,502.77362

Timestep Collection Time: 2.21650
Timestep Consumption Time: 2.54549
PPO Batch Consumption Time: 0.29777
Total Iteration Time: 4.76198

Cumulative Model Updates: 5,060
Cumulative Timesteps: 42,313,958

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 42313958...
Checkpoint 42313958 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,414.66022
Policy Entropy: 0.84405
Value Function Loss: 0.57800

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.09538
Policy Update Magnitude: 0.18712
Value Function Update Magnitude: 0.34030

Collected Steps per Second: 22,657.23891
Overall Steps per Second: 10,593.85617

Timestep Collection Time: 2.20689
Timestep Consumption Time: 2.51302
PPO Batch Consumption Time: 0.29153
Total Iteration Time: 4.71991

Cumulative Model Updates: 5,066
Cumulative Timesteps: 42,363,960

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,220.60146
Policy Entropy: 0.86248
Value Function Loss: 0.57139

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.09114
Policy Update Magnitude: 0.20732
Value Function Update Magnitude: 0.33974

Collected Steps per Second: 22,893.18235
Overall Steps per Second: 10,615.41489

Timestep Collection Time: 2.18414
Timestep Consumption Time: 2.52618
PPO Batch Consumption Time: 0.29390
Total Iteration Time: 4.71032

Cumulative Model Updates: 5,072
Cumulative Timesteps: 42,413,962

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 42413962...
Checkpoint 42413962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,677.79008
Policy Entropy: 0.86074
Value Function Loss: 0.58835

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.09775
Policy Update Magnitude: 0.20473
Value Function Update Magnitude: 0.35078

Collected Steps per Second: 22,788.19489
Overall Steps per Second: 10,617.31151

Timestep Collection Time: 2.19412
Timestep Consumption Time: 2.51517
PPO Batch Consumption Time: 0.29657
Total Iteration Time: 4.70929

Cumulative Model Updates: 5,078
Cumulative Timesteps: 42,463,962

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,846.65254
Policy Entropy: 0.84601
Value Function Loss: 0.58086

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.09102
Policy Update Magnitude: 0.19743
Value Function Update Magnitude: 0.35853

Collected Steps per Second: 22,789.49778
Overall Steps per Second: 10,709.88359

Timestep Collection Time: 2.19434
Timestep Consumption Time: 2.47499
PPO Batch Consumption Time: 0.28408
Total Iteration Time: 4.66933

Cumulative Model Updates: 5,084
Cumulative Timesteps: 42,513,970

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 42513970...
Checkpoint 42513970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,677.01617
Policy Entropy: 0.84403
Value Function Loss: 0.57649

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.08949
Policy Update Magnitude: 0.20146
Value Function Update Magnitude: 0.34580

Collected Steps per Second: 22,628.72975
Overall Steps per Second: 10,694.26689

Timestep Collection Time: 2.20958
Timestep Consumption Time: 2.46582
PPO Batch Consumption Time: 0.28335
Total Iteration Time: 4.67540

Cumulative Model Updates: 5,090
Cumulative Timesteps: 42,563,970

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,373.75982
Policy Entropy: 0.84696
Value Function Loss: 0.56405

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.08628
Policy Update Magnitude: 0.21852
Value Function Update Magnitude: 0.39796

Collected Steps per Second: 22,660.80119
Overall Steps per Second: 10,654.97894

Timestep Collection Time: 2.20734
Timestep Consumption Time: 2.48718
PPO Batch Consumption Time: 0.29252
Total Iteration Time: 4.69452

Cumulative Model Updates: 5,096
Cumulative Timesteps: 42,613,990

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 42613990...
Checkpoint 42613990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 994.24117
Policy Entropy: 0.84451
Value Function Loss: 0.58717

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.08293
Policy Update Magnitude: 0.22840
Value Function Update Magnitude: 0.38681

Collected Steps per Second: 22,847.49040
Overall Steps per Second: 10,830.26725

Timestep Collection Time: 2.19017
Timestep Consumption Time: 2.43021
PPO Batch Consumption Time: 0.28344
Total Iteration Time: 4.62038

Cumulative Model Updates: 5,102
Cumulative Timesteps: 42,664,030

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,559.37268
Policy Entropy: 0.84186
Value Function Loss: 0.61186

Mean KL Divergence: 0.00704
SB3 Clip Fraction: 0.07472
Policy Update Magnitude: 0.25137
Value Function Update Magnitude: 0.32390

Collected Steps per Second: 22,810.75388
Overall Steps per Second: 10,664.71030

Timestep Collection Time: 2.19274
Timestep Consumption Time: 2.49731
PPO Batch Consumption Time: 0.29459
Total Iteration Time: 4.69005

Cumulative Model Updates: 5,108
Cumulative Timesteps: 42,714,048

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 42714048...
Checkpoint 42714048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,329.34593
Policy Entropy: 0.83666
Value Function Loss: 0.60017

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.08511
Policy Update Magnitude: 0.26425
Value Function Update Magnitude: 0.34092

Collected Steps per Second: 22,593.89007
Overall Steps per Second: 10,607.60310

Timestep Collection Time: 2.21361
Timestep Consumption Time: 2.50131
PPO Batch Consumption Time: 0.29502
Total Iteration Time: 4.71492

Cumulative Model Updates: 5,114
Cumulative Timesteps: 42,764,062

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,424.65200
Policy Entropy: 0.82588
Value Function Loss: 0.65090

Mean KL Divergence: 0.00704
SB3 Clip Fraction: 0.07768
Policy Update Magnitude: 0.23843
Value Function Update Magnitude: 0.37662

Collected Steps per Second: 22,596.37449
Overall Steps per Second: 10,800.33226

Timestep Collection Time: 2.21319
Timestep Consumption Time: 2.41723
PPO Batch Consumption Time: 0.28853
Total Iteration Time: 4.63041

Cumulative Model Updates: 5,120
Cumulative Timesteps: 42,814,072

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 42814072...
Checkpoint 42814072 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,132.12604
Policy Entropy: 0.80476
Value Function Loss: 0.57422

Mean KL Divergence: 0.00764
SB3 Clip Fraction: 0.07933
Policy Update Magnitude: 0.24120
Value Function Update Magnitude: 0.30413

Collected Steps per Second: 22,113.93184
Overall Steps per Second: 10,637.99085

Timestep Collection Time: 2.26192
Timestep Consumption Time: 2.44009
PPO Batch Consumption Time: 0.29406
Total Iteration Time: 4.70202

Cumulative Model Updates: 5,126
Cumulative Timesteps: 42,864,092

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,156.56133
Policy Entropy: 0.81335
Value Function Loss: 0.56411

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.07735
Policy Update Magnitude: 0.22078
Value Function Update Magnitude: 0.30510

Collected Steps per Second: 21,732.28171
Overall Steps per Second: 10,457.83147

Timestep Collection Time: 2.30192
Timestep Consumption Time: 2.48167
PPO Batch Consumption Time: 0.29648
Total Iteration Time: 4.78359

Cumulative Model Updates: 5,132
Cumulative Timesteps: 42,914,118

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 42914118...
Checkpoint 42914118 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,335.05182
Policy Entropy: 0.82599
Value Function Loss: 0.55149

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.08868
Policy Update Magnitude: 0.20462
Value Function Update Magnitude: 0.29381

Collected Steps per Second: 22,369.63641
Overall Steps per Second: 10,637.97652

Timestep Collection Time: 2.23553
Timestep Consumption Time: 2.46536
PPO Batch Consumption Time: 0.28587
Total Iteration Time: 4.70089

Cumulative Model Updates: 5,138
Cumulative Timesteps: 42,964,126

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,254.54848
Policy Entropy: 0.84988
Value Function Loss: 0.55155

Mean KL Divergence: 0.01253
SB3 Clip Fraction: 0.10644
Policy Update Magnitude: 0.21414
Value Function Update Magnitude: 0.33328

Collected Steps per Second: 22,863.57867
Overall Steps per Second: 10,649.85968

Timestep Collection Time: 2.18776
Timestep Consumption Time: 2.50902
PPO Batch Consumption Time: 0.29350
Total Iteration Time: 4.69678

Cumulative Model Updates: 5,144
Cumulative Timesteps: 43,014,146

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 43014146...
Checkpoint 43014146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,731.95205
Policy Entropy: 0.86198
Value Function Loss: 0.55565

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.10132
Policy Update Magnitude: 0.21702
Value Function Update Magnitude: 0.34457

Collected Steps per Second: 22,711.37787
Overall Steps per Second: 10,603.94294

Timestep Collection Time: 2.20268
Timestep Consumption Time: 2.51499
PPO Batch Consumption Time: 0.29422
Total Iteration Time: 4.71768

Cumulative Model Updates: 5,150
Cumulative Timesteps: 43,064,172

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,076.66263
Policy Entropy: 0.86170
Value Function Loss: 0.54839

Mean KL Divergence: 0.00758
SB3 Clip Fraction: 0.07597
Policy Update Magnitude: 0.19808
Value Function Update Magnitude: 0.34953

Collected Steps per Second: 22,838.40012
Overall Steps per Second: 10,746.77866

Timestep Collection Time: 2.19026
Timestep Consumption Time: 2.46435
PPO Batch Consumption Time: 0.28393
Total Iteration Time: 4.65460

Cumulative Model Updates: 5,156
Cumulative Timesteps: 43,114,194

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 43114194...
Checkpoint 43114194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,650.44993
Policy Entropy: 0.84552
Value Function Loss: 0.53572

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.09307
Policy Update Magnitude: 0.21511
Value Function Update Magnitude: 0.35841

Collected Steps per Second: 22,709.80931
Overall Steps per Second: 10,644.14417

Timestep Collection Time: 2.20240
Timestep Consumption Time: 2.49653
PPO Batch Consumption Time: 0.29025
Total Iteration Time: 4.69892

Cumulative Model Updates: 5,162
Cumulative Timesteps: 43,164,210

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,151.87187
Policy Entropy: 0.85173
Value Function Loss: 0.55671

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.10565
Policy Update Magnitude: 0.19958
Value Function Update Magnitude: 0.33507

Collected Steps per Second: 22,729.90299
Overall Steps per Second: 10,553.94581

Timestep Collection Time: 2.19992
Timestep Consumption Time: 2.53802
PPO Batch Consumption Time: 0.29682
Total Iteration Time: 4.73794

Cumulative Model Updates: 5,168
Cumulative Timesteps: 43,214,214

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 43214214...
Checkpoint 43214214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,109.03904
Policy Entropy: 0.85976
Value Function Loss: 0.57884

Mean KL Divergence: 0.00738
SB3 Clip Fraction: 0.07923
Policy Update Magnitude: 0.20642
Value Function Update Magnitude: 0.34796

Collected Steps per Second: 22,743.57492
Overall Steps per Second: 10,534.35057

Timestep Collection Time: 2.19895
Timestep Consumption Time: 2.54857
PPO Batch Consumption Time: 0.29812
Total Iteration Time: 4.74752

Cumulative Model Updates: 5,174
Cumulative Timesteps: 43,264,226

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,590.14997
Policy Entropy: 0.86619
Value Function Loss: 0.57980

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.09391
Policy Update Magnitude: 0.20823
Value Function Update Magnitude: 0.36202

Collected Steps per Second: 22,760.87576
Overall Steps per Second: 10,564.80256

Timestep Collection Time: 2.19772
Timestep Consumption Time: 2.53706
PPO Batch Consumption Time: 0.29655
Total Iteration Time: 4.73478

Cumulative Model Updates: 5,180
Cumulative Timesteps: 43,314,248

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 43314248...
Checkpoint 43314248 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,515.92970
Policy Entropy: 0.86671
Value Function Loss: 0.60262

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.09101
Policy Update Magnitude: 0.19670
Value Function Update Magnitude: 0.32117

Collected Steps per Second: 22,955.64959
Overall Steps per Second: 10,615.91496

Timestep Collection Time: 2.17864
Timestep Consumption Time: 2.53240
PPO Batch Consumption Time: 0.29704
Total Iteration Time: 4.71104

Cumulative Model Updates: 5,186
Cumulative Timesteps: 43,364,260

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,405.23693
Policy Entropy: 0.85292
Value Function Loss: 0.57990

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.08512
Policy Update Magnitude: 0.21130
Value Function Update Magnitude: 0.38540

Collected Steps per Second: 23,029.35333
Overall Steps per Second: 10,768.01443

Timestep Collection Time: 2.17140
Timestep Consumption Time: 2.47254
PPO Batch Consumption Time: 0.28398
Total Iteration Time: 4.64394

Cumulative Model Updates: 5,192
Cumulative Timesteps: 43,414,266

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 43414266...
Checkpoint 43414266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,052.79711
Policy Entropy: 0.85033
Value Function Loss: 0.58048

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.08827
Policy Update Magnitude: 0.24367
Value Function Update Magnitude: 0.39692

Collected Steps per Second: 22,525.74396
Overall Steps per Second: 10,680.39278

Timestep Collection Time: 2.22048
Timestep Consumption Time: 2.46268
PPO Batch Consumption Time: 0.28380
Total Iteration Time: 4.68316

Cumulative Model Updates: 5,198
Cumulative Timesteps: 43,464,284

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,632.50963
Policy Entropy: 0.85772
Value Function Loss: 0.56351

Mean KL Divergence: 0.01204
SB3 Clip Fraction: 0.10743
Policy Update Magnitude: 0.20581
Value Function Update Magnitude: 0.31250

Collected Steps per Second: 22,049.38185
Overall Steps per Second: 10,433.52537

Timestep Collection Time: 2.26818
Timestep Consumption Time: 2.52521
PPO Batch Consumption Time: 0.29115
Total Iteration Time: 4.79339

Cumulative Model Updates: 5,204
Cumulative Timesteps: 43,514,296

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 43514296...
Checkpoint 43514296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,728.77307
Policy Entropy: 0.87367
Value Function Loss: 0.57783

Mean KL Divergence: 0.01532
SB3 Clip Fraction: 0.13139
Policy Update Magnitude: 0.18264
Value Function Update Magnitude: 0.30924

Collected Steps per Second: 22,591.10129
Overall Steps per Second: 10,494.11810

Timestep Collection Time: 2.21370
Timestep Consumption Time: 2.55182
PPO Batch Consumption Time: 0.29342
Total Iteration Time: 4.76553

Cumulative Model Updates: 5,210
Cumulative Timesteps: 43,564,306

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,583.46293
Policy Entropy: 0.87869
Value Function Loss: 0.57951

Mean KL Divergence: 0.01153
SB3 Clip Fraction: 0.10052
Policy Update Magnitude: 0.16464
Value Function Update Magnitude: 0.29929

Collected Steps per Second: 22,889.65099
Overall Steps per Second: 10,673.62586

Timestep Collection Time: 2.18579
Timestep Consumption Time: 2.50165
PPO Batch Consumption Time: 0.29056
Total Iteration Time: 4.68744

Cumulative Model Updates: 5,216
Cumulative Timesteps: 43,614,338

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 43614338...
Checkpoint 43614338 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,604.74178
Policy Entropy: 0.89611
Value Function Loss: 0.56235

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.10054
Policy Update Magnitude: 0.20873
Value Function Update Magnitude: 0.29963

Collected Steps per Second: 22,766.14592
Overall Steps per Second: 10,593.04237

Timestep Collection Time: 2.19624
Timestep Consumption Time: 2.52384
PPO Batch Consumption Time: 0.29845
Total Iteration Time: 4.72008

Cumulative Model Updates: 5,222
Cumulative Timesteps: 43,664,338

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,194.69567
Policy Entropy: 0.89127
Value Function Loss: 0.51211

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.10726
Policy Update Magnitude: 0.21104
Value Function Update Magnitude: 0.31345

Collected Steps per Second: 22,477.45099
Overall Steps per Second: 10,496.60813

Timestep Collection Time: 2.22534
Timestep Consumption Time: 2.54001
PPO Batch Consumption Time: 0.29822
Total Iteration Time: 4.76535

Cumulative Model Updates: 5,228
Cumulative Timesteps: 43,714,358

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 43714358...
Checkpoint 43714358 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,180.77076
Policy Entropy: 0.87448
Value Function Loss: 0.51378

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.11318
Policy Update Magnitude: 0.19299
Value Function Update Magnitude: 0.31949

Collected Steps per Second: 22,596.10382
Overall Steps per Second: 10,609.32235

Timestep Collection Time: 2.21312
Timestep Consumption Time: 2.50047
PPO Batch Consumption Time: 0.29476
Total Iteration Time: 4.71359

Cumulative Model Updates: 5,234
Cumulative Timesteps: 43,764,366

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,239.32447
Policy Entropy: 0.86456
Value Function Loss: 0.50192

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.09773
Policy Update Magnitude: 0.17139
Value Function Update Magnitude: 0.33707

Collected Steps per Second: 22,896.40378
Overall Steps per Second: 10,819.68164

Timestep Collection Time: 2.18436
Timestep Consumption Time: 2.43814
PPO Batch Consumption Time: 0.28312
Total Iteration Time: 4.62250

Cumulative Model Updates: 5,240
Cumulative Timesteps: 43,814,380

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 43814380...
Checkpoint 43814380 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,065.59622
Policy Entropy: 0.85836
Value Function Loss: 0.50866

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.09391
Policy Update Magnitude: 0.18343
Value Function Update Magnitude: 0.37695

Collected Steps per Second: 22,538.93552
Overall Steps per Second: 10,765.27948

Timestep Collection Time: 2.21918
Timestep Consumption Time: 2.42705
PPO Batch Consumption Time: 0.28245
Total Iteration Time: 4.64623

Cumulative Model Updates: 5,246
Cumulative Timesteps: 43,864,398

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,422.73457
Policy Entropy: 0.86595
Value Function Loss: 0.50969

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.08743
Policy Update Magnitude: 0.17690
Value Function Update Magnitude: 0.40916

Collected Steps per Second: 22,815.00008
Overall Steps per Second: 10,782.43280

Timestep Collection Time: 2.19233
Timestep Consumption Time: 2.44651
PPO Batch Consumption Time: 0.28384
Total Iteration Time: 4.63884

Cumulative Model Updates: 5,252
Cumulative Timesteps: 43,914,416

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 43914416...
Checkpoint 43914416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,785.23701
Policy Entropy: 0.85432
Value Function Loss: 0.50324

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.08777
Policy Update Magnitude: 0.18123
Value Function Update Magnitude: 0.32201

Collected Steps per Second: 22,621.55718
Overall Steps per Second: 10,772.38287

Timestep Collection Time: 2.21117
Timestep Consumption Time: 2.43219
PPO Batch Consumption Time: 0.28340
Total Iteration Time: 4.64336

Cumulative Model Updates: 5,258
Cumulative Timesteps: 43,964,436

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,539.28102
Policy Entropy: 0.85893
Value Function Loss: 0.50928

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.09176
Policy Update Magnitude: 0.19104
Value Function Update Magnitude: 0.34556

Collected Steps per Second: 22,637.44166
Overall Steps per Second: 10,751.78936

Timestep Collection Time: 2.20917
Timestep Consumption Time: 2.44215
PPO Batch Consumption Time: 0.28319
Total Iteration Time: 4.65132

Cumulative Model Updates: 5,264
Cumulative Timesteps: 44,014,446

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 44014446...
Checkpoint 44014446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,069.45447
Policy Entropy: 0.86535
Value Function Loss: 0.50754

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.08475
Policy Update Magnitude: 0.22203
Value Function Update Magnitude: 0.29160

Collected Steps per Second: 22,440.77809
Overall Steps per Second: 10,730.55734

Timestep Collection Time: 2.22871
Timestep Consumption Time: 2.43218
PPO Batch Consumption Time: 0.28352
Total Iteration Time: 4.66089

Cumulative Model Updates: 5,270
Cumulative Timesteps: 44,064,460

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,134.15124
Policy Entropy: 0.86699
Value Function Loss: 0.52776

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.09927
Policy Update Magnitude: 0.21283
Value Function Update Magnitude: 0.27850

Collected Steps per Second: 22,685.03236
Overall Steps per Second: 10,612.82023

Timestep Collection Time: 2.20454
Timestep Consumption Time: 2.50769
PPO Batch Consumption Time: 0.29460
Total Iteration Time: 4.71223

Cumulative Model Updates: 5,276
Cumulative Timesteps: 44,114,470

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 44114470...
Checkpoint 44114470 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,379.54176
Policy Entropy: 0.84971
Value Function Loss: 0.50413

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.08613
Policy Update Magnitude: 0.21716
Value Function Update Magnitude: 0.30111

Collected Steps per Second: 22,862.37168
Overall Steps per Second: 10,834.46433

Timestep Collection Time: 2.18744
Timestep Consumption Time: 2.42839
PPO Batch Consumption Time: 0.28411
Total Iteration Time: 4.61583

Cumulative Model Updates: 5,282
Cumulative Timesteps: 44,164,480

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,201.92759
Policy Entropy: 0.84863
Value Function Loss: 0.51008

Mean KL Divergence: 0.00698
SB3 Clip Fraction: 0.07893
Policy Update Magnitude: 0.24819
Value Function Update Magnitude: 0.30146

Collected Steps per Second: 22,602.47668
Overall Steps per Second: 10,457.09211

Timestep Collection Time: 2.21250
Timestep Consumption Time: 2.56971
PPO Batch Consumption Time: 0.30542
Total Iteration Time: 4.78221

Cumulative Model Updates: 5,288
Cumulative Timesteps: 44,214,488

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 44214488...
Checkpoint 44214488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,203.70086
Policy Entropy: 0.85116
Value Function Loss: 0.49010

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.08884
Policy Update Magnitude: 0.25103
Value Function Update Magnitude: 0.29454

Collected Steps per Second: 22,659.93216
Overall Steps per Second: 10,663.14223

Timestep Collection Time: 2.20663
Timestep Consumption Time: 2.48261
PPO Batch Consumption Time: 0.29313
Total Iteration Time: 4.68924

Cumulative Model Updates: 5,294
Cumulative Timesteps: 44,264,490

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,814.37388
Policy Entropy: 0.86264
Value Function Loss: 0.48551

Mean KL Divergence: 0.00772
SB3 Clip Fraction: 0.09289
Policy Update Magnitude: 0.24236
Value Function Update Magnitude: 0.31582

Collected Steps per Second: 22,934.43458
Overall Steps per Second: 10,662.32567

Timestep Collection Time: 2.18065
Timestep Consumption Time: 2.50988
PPO Batch Consumption Time: 0.29481
Total Iteration Time: 4.69053

Cumulative Model Updates: 5,300
Cumulative Timesteps: 44,314,502

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 44314502...
Checkpoint 44314502 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,920.68911
Policy Entropy: 0.87987
Value Function Loss: 0.46788

Mean KL Divergence: 0.00734
SB3 Clip Fraction: 0.08893
Policy Update Magnitude: 0.23898
Value Function Update Magnitude: 0.29669

Collected Steps per Second: 22,867.37053
Overall Steps per Second: 10,669.13478

Timestep Collection Time: 2.18678
Timestep Consumption Time: 2.50019
PPO Batch Consumption Time: 0.29647
Total Iteration Time: 4.68698

Cumulative Model Updates: 5,306
Cumulative Timesteps: 44,364,508

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,033.83193
Policy Entropy: 0.87304
Value Function Loss: 0.47990

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.09740
Policy Update Magnitude: 0.24008
Value Function Update Magnitude: 0.31390

Collected Steps per Second: 22,926.49756
Overall Steps per Second: 10,818.32205

Timestep Collection Time: 2.18158
Timestep Consumption Time: 2.44169
PPO Batch Consumption Time: 0.28289
Total Iteration Time: 4.62327

Cumulative Model Updates: 5,312
Cumulative Timesteps: 44,414,524

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 44414524...
Checkpoint 44414524 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,346.91787
Policy Entropy: 0.86377
Value Function Loss: 0.46506

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.10376
Policy Update Magnitude: 0.19927
Value Function Update Magnitude: 0.38149

Collected Steps per Second: 22,553.65351
Overall Steps per Second: 10,605.94979

Timestep Collection Time: 2.21818
Timestep Consumption Time: 2.49880
PPO Batch Consumption Time: 0.29227
Total Iteration Time: 4.71698

Cumulative Model Updates: 5,318
Cumulative Timesteps: 44,464,552

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,556.66279
Policy Entropy: 0.87977
Value Function Loss: 0.46066

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.11019
Policy Update Magnitude: 0.18418
Value Function Update Magnitude: 0.49722

Collected Steps per Second: 22,785.68115
Overall Steps per Second: 10,880.60214

Timestep Collection Time: 2.19559
Timestep Consumption Time: 2.40232
PPO Batch Consumption Time: 0.28409
Total Iteration Time: 4.59791

Cumulative Model Updates: 5,324
Cumulative Timesteps: 44,514,580

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 44514580...
Checkpoint 44514580 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,892.79154
Policy Entropy: 0.88390
Value Function Loss: 0.46666

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.09527
Policy Update Magnitude: 0.20652
Value Function Update Magnitude: 0.46872

Collected Steps per Second: 21,772.78123
Overall Steps per Second: 10,676.43084

Timestep Collection Time: 2.29764
Timestep Consumption Time: 2.38801
PPO Batch Consumption Time: 0.28333
Total Iteration Time: 4.68565

Cumulative Model Updates: 5,330
Cumulative Timesteps: 44,564,606

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,804.38075
Policy Entropy: 0.90300
Value Function Loss: 0.47641

Mean KL Divergence: 0.01121
SB3 Clip Fraction: 0.10424
Policy Update Magnitude: 0.21515
Value Function Update Magnitude: 0.38934

Collected Steps per Second: 22,296.06385
Overall Steps per Second: 10,680.61244

Timestep Collection Time: 2.24273
Timestep Consumption Time: 2.43903
PPO Batch Consumption Time: 0.29237
Total Iteration Time: 4.68175

Cumulative Model Updates: 5,336
Cumulative Timesteps: 44,614,610

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 44614610...
Checkpoint 44614610 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,763.46162
Policy Entropy: 0.89025
Value Function Loss: 0.50750

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.10706
Policy Update Magnitude: 0.19312
Value Function Update Magnitude: 0.33650

Collected Steps per Second: 21,788.05732
Overall Steps per Second: 10,546.44715

Timestep Collection Time: 2.29566
Timestep Consumption Time: 2.44698
PPO Batch Consumption Time: 0.29605
Total Iteration Time: 4.74264

Cumulative Model Updates: 5,342
Cumulative Timesteps: 44,664,628

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,900.51098
Policy Entropy: 0.87133
Value Function Loss: 0.48100

Mean KL Divergence: 0.01116
SB3 Clip Fraction: 0.10715
Policy Update Magnitude: 0.18724
Value Function Update Magnitude: 0.34774

Collected Steps per Second: 22,327.42842
Overall Steps per Second: 10,788.18680

Timestep Collection Time: 2.24038
Timestep Consumption Time: 2.39636
PPO Batch Consumption Time: 0.28401
Total Iteration Time: 4.63674

Cumulative Model Updates: 5,348
Cumulative Timesteps: 44,714,650

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 44714650...
Checkpoint 44714650 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,115.81920
Policy Entropy: 0.86690
Value Function Loss: 0.48242

Mean KL Divergence: 0.01092
SB3 Clip Fraction: 0.10564
Policy Update Magnitude: 0.17743
Value Function Update Magnitude: 0.35293

Collected Steps per Second: 22,761.19111
Overall Steps per Second: 10,583.87872

Timestep Collection Time: 2.19699
Timestep Consumption Time: 2.52775
PPO Batch Consumption Time: 0.29195
Total Iteration Time: 4.72473

Cumulative Model Updates: 5,354
Cumulative Timesteps: 44,764,656

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,241.48440
Policy Entropy: 0.87693
Value Function Loss: 0.50194

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.09350
Policy Update Magnitude: 0.17041
Value Function Update Magnitude: 0.32779

Collected Steps per Second: 22,596.69534
Overall Steps per Second: 10,513.45431

Timestep Collection Time: 2.21342
Timestep Consumption Time: 2.54391
PPO Batch Consumption Time: 0.29726
Total Iteration Time: 4.75733

Cumulative Model Updates: 5,360
Cumulative Timesteps: 44,814,672

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 44814672...
Checkpoint 44814672 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,947.80949
Policy Entropy: 0.87568
Value Function Loss: 0.46401

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.09133
Policy Update Magnitude: 0.18005
Value Function Update Magnitude: 0.31899

Collected Steps per Second: 22,442.65192
Overall Steps per Second: 10,682.54298

Timestep Collection Time: 2.22844
Timestep Consumption Time: 2.45322
PPO Batch Consumption Time: 0.28290
Total Iteration Time: 4.68166

Cumulative Model Updates: 5,366
Cumulative Timesteps: 44,864,684

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,326.43408
Policy Entropy: 0.88528
Value Function Loss: 0.47666

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.09268
Policy Update Magnitude: 0.20330
Value Function Update Magnitude: 0.31817

Collected Steps per Second: 22,922.28111
Overall Steps per Second: 10,761.00883

Timestep Collection Time: 2.18251
Timestep Consumption Time: 2.46650
PPO Batch Consumption Time: 0.28416
Total Iteration Time: 4.64901

Cumulative Model Updates: 5,372
Cumulative Timesteps: 44,914,712

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 44914712...
Checkpoint 44914712 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,936.87382
Policy Entropy: 0.88002
Value Function Loss: 0.48864

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.09309
Policy Update Magnitude: 0.24085
Value Function Update Magnitude: 0.29900

Collected Steps per Second: 22,603.58171
Overall Steps per Second: 10,692.64373

Timestep Collection Time: 2.21257
Timestep Consumption Time: 2.46466
PPO Batch Consumption Time: 0.28452
Total Iteration Time: 4.67723

Cumulative Model Updates: 5,378
Cumulative Timesteps: 44,964,724

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,408.30216
Policy Entropy: 0.89083
Value Function Loss: 0.47967

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.09840
Policy Update Magnitude: 0.21488
Value Function Update Magnitude: 0.28579

Collected Steps per Second: 22,945.11802
Overall Steps per Second: 10,639.06296

Timestep Collection Time: 2.17981
Timestep Consumption Time: 2.52136
PPO Batch Consumption Time: 0.29628
Total Iteration Time: 4.70117

Cumulative Model Updates: 5,384
Cumulative Timesteps: 45,014,740

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 45014740...
Checkpoint 45014740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,896.47916
Policy Entropy: 0.87538
Value Function Loss: 0.49488

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.09610
Policy Update Magnitude: 0.22170
Value Function Update Magnitude: 0.27549

Collected Steps per Second: 22,543.91144
Overall Steps per Second: 10,520.36554

Timestep Collection Time: 2.21825
Timestep Consumption Time: 2.53520
PPO Batch Consumption Time: 0.29765
Total Iteration Time: 4.75345

Cumulative Model Updates: 5,390
Cumulative Timesteps: 45,064,748

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,505.46412
Policy Entropy: 0.86093
Value Function Loss: 0.48200

Mean KL Divergence: 0.01180
SB3 Clip Fraction: 0.11839
Policy Update Magnitude: 0.20925
Value Function Update Magnitude: 0.26149

Collected Steps per Second: 23,115.01703
Overall Steps per Second: 10,807.60650

Timestep Collection Time: 2.16396
Timestep Consumption Time: 2.46426
PPO Batch Consumption Time: 0.28423
Total Iteration Time: 4.62822

Cumulative Model Updates: 5,396
Cumulative Timesteps: 45,114,768

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 45114768...
Checkpoint 45114768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,251.97900
Policy Entropy: 0.87115
Value Function Loss: 0.48999

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.10634
Policy Update Magnitude: 0.20085
Value Function Update Magnitude: 0.31881

Collected Steps per Second: 22,738.90678
Overall Steps per Second: 10,717.37752

Timestep Collection Time: 2.19887
Timestep Consumption Time: 2.46645
PPO Batch Consumption Time: 0.28418
Total Iteration Time: 4.66532

Cumulative Model Updates: 5,402
Cumulative Timesteps: 45,164,768

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,645.83633
Policy Entropy: 0.88366
Value Function Loss: 0.46896

Mean KL Divergence: 0.01105
SB3 Clip Fraction: 0.11091
Policy Update Magnitude: 0.20853
Value Function Update Magnitude: 0.34607

Collected Steps per Second: 23,031.80767
Overall Steps per Second: 10,678.25422

Timestep Collection Time: 2.17187
Timestep Consumption Time: 2.51261
PPO Batch Consumption Time: 0.29234
Total Iteration Time: 4.68447

Cumulative Model Updates: 5,408
Cumulative Timesteps: 45,214,790

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 45214790...
Checkpoint 45214790 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,549.44133
Policy Entropy: 0.88395
Value Function Loss: 0.46409

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.08933
Policy Update Magnitude: 0.21353
Value Function Update Magnitude: 0.35995

Collected Steps per Second: 22,575.68558
Overall Steps per Second: 10,482.01948

Timestep Collection Time: 2.21539
Timestep Consumption Time: 2.55602
PPO Batch Consumption Time: 0.29818
Total Iteration Time: 4.77141

Cumulative Model Updates: 5,414
Cumulative Timesteps: 45,264,804

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,589.18060
Policy Entropy: 0.88207
Value Function Loss: 0.47200

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.09492
Policy Update Magnitude: 0.22191
Value Function Update Magnitude: 0.35435

Collected Steps per Second: 22,876.63458
Overall Steps per Second: 10,764.96299

Timestep Collection Time: 2.18642
Timestep Consumption Time: 2.45995
PPO Batch Consumption Time: 0.28378
Total Iteration Time: 4.64637

Cumulative Model Updates: 5,420
Cumulative Timesteps: 45,314,822

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 45314822...
Checkpoint 45314822 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,326.23187
Policy Entropy: 0.88640
Value Function Loss: 0.45554

Mean KL Divergence: 0.01151
SB3 Clip Fraction: 0.11262
Policy Update Magnitude: 0.20665
Value Function Update Magnitude: 0.35499

Collected Steps per Second: 22,309.22671
Overall Steps per Second: 10,629.71664

Timestep Collection Time: 2.24131
Timestep Consumption Time: 2.46267
PPO Batch Consumption Time: 0.28409
Total Iteration Time: 4.70398

Cumulative Model Updates: 5,426
Cumulative Timesteps: 45,364,824

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,980.15559
Policy Entropy: 0.90739
Value Function Loss: 0.45061

Mean KL Divergence: 0.01708
SB3 Clip Fraction: 0.14069
Policy Update Magnitude: 0.19540
Value Function Update Magnitude: 0.41717

Collected Steps per Second: 22,836.36682
Overall Steps per Second: 10,476.74819

Timestep Collection Time: 2.18967
Timestep Consumption Time: 2.58319
PPO Batch Consumption Time: 0.30187
Total Iteration Time: 4.77285

Cumulative Model Updates: 5,432
Cumulative Timesteps: 45,414,828

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 45414828...
Checkpoint 45414828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,345.83689
Policy Entropy: 0.89911
Value Function Loss: 0.45362

Mean KL Divergence: 0.01849
SB3 Clip Fraction: 0.15434
Policy Update Magnitude: 0.18529
Value Function Update Magnitude: 0.40005

Collected Steps per Second: 22,071.21581
Overall Steps per Second: 10,503.04839

Timestep Collection Time: 2.26594
Timestep Consumption Time: 2.49573
PPO Batch Consumption Time: 0.29217
Total Iteration Time: 4.76167

Cumulative Model Updates: 5,438
Cumulative Timesteps: 45,464,840

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,493.61156
Policy Entropy: 0.90788
Value Function Loss: 0.49131

Mean KL Divergence: 0.01217
SB3 Clip Fraction: 0.11783
Policy Update Magnitude: 0.20903
Value Function Update Magnitude: 0.32022

Collected Steps per Second: 23,063.23670
Overall Steps per Second: 10,686.77648

Timestep Collection Time: 2.16830
Timestep Consumption Time: 2.51113
PPO Batch Consumption Time: 0.29523
Total Iteration Time: 4.67943

Cumulative Model Updates: 5,444
Cumulative Timesteps: 45,514,848

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 45514848...
Checkpoint 45514848 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,588.75036
Policy Entropy: 0.88835
Value Function Loss: 0.48429

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.09853
Policy Update Magnitude: 0.24540
Value Function Update Magnitude: 0.31444

Collected Steps per Second: 22,542.93563
Overall Steps per Second: 10,636.68026

Timestep Collection Time: 2.21870
Timestep Consumption Time: 2.48352
PPO Batch Consumption Time: 0.29034
Total Iteration Time: 4.70222

Cumulative Model Updates: 5,450
Cumulative Timesteps: 45,564,864

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,230.08495
Policy Entropy: 0.87836
Value Function Loss: 0.48181

Mean KL Divergence: 0.01245
SB3 Clip Fraction: 0.11271
Policy Update Magnitude: 0.22341
Value Function Update Magnitude: 0.32876

Collected Steps per Second: 22,980.44366
Overall Steps per Second: 10,699.46599

Timestep Collection Time: 2.17707
Timestep Consumption Time: 2.49887
PPO Batch Consumption Time: 0.29216
Total Iteration Time: 4.67593

Cumulative Model Updates: 5,456
Cumulative Timesteps: 45,614,894

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 45614894...
Checkpoint 45614894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,865.82217
Policy Entropy: 0.86699
Value Function Loss: 0.46706

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.09765
Policy Update Magnitude: 0.22887
Value Function Update Magnitude: 0.34132

Collected Steps per Second: 22,528.23145
Overall Steps per Second: 10,864.15609

Timestep Collection Time: 2.22033
Timestep Consumption Time: 2.38381
PPO Batch Consumption Time: 0.28392
Total Iteration Time: 4.60413

Cumulative Model Updates: 5,462
Cumulative Timesteps: 45,664,914

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,608.02602
Policy Entropy: 0.87424
Value Function Loss: 0.47643

Mean KL Divergence: 0.01179
SB3 Clip Fraction: 0.10865
Policy Update Magnitude: 0.21358
Value Function Update Magnitude: 0.35149

Collected Steps per Second: 22,512.44545
Overall Steps per Second: 10,821.20047

Timestep Collection Time: 2.22162
Timestep Consumption Time: 2.40024
PPO Batch Consumption Time: 0.28474
Total Iteration Time: 4.62185

Cumulative Model Updates: 5,468
Cumulative Timesteps: 45,714,928

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 45714928...
Checkpoint 45714928 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,233.02316
Policy Entropy: 0.88497
Value Function Loss: 0.48582

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.10892
Policy Update Magnitude: 0.18730
Value Function Update Magnitude: 0.33832

Collected Steps per Second: 21,983.00216
Overall Steps per Second: 10,725.17860

Timestep Collection Time: 2.27539
Timestep Consumption Time: 2.38840
PPO Batch Consumption Time: 0.28382
Total Iteration Time: 4.66379

Cumulative Model Updates: 5,474
Cumulative Timesteps: 45,764,948

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,254.39921
Policy Entropy: 0.88360
Value Function Loss: 0.47669

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.09320
Policy Update Magnitude: 0.18380
Value Function Update Magnitude: 0.34865

Collected Steps per Second: 22,468.24973
Overall Steps per Second: 10,835.00814

Timestep Collection Time: 2.22670
Timestep Consumption Time: 2.39074
PPO Batch Consumption Time: 0.28436
Total Iteration Time: 4.61744

Cumulative Model Updates: 5,480
Cumulative Timesteps: 45,814,978

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 45814978...
Checkpoint 45814978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,272.62040
Policy Entropy: 0.89174
Value Function Loss: 0.45959

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.09370
Policy Update Magnitude: 0.18880
Value Function Update Magnitude: 0.36119

Collected Steps per Second: 22,313.20586
Overall Steps per Second: 10,621.23885

Timestep Collection Time: 2.24172
Timestep Consumption Time: 2.46771
PPO Batch Consumption Time: 0.28401
Total Iteration Time: 4.70943

Cumulative Model Updates: 5,486
Cumulative Timesteps: 45,864,998

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,454.85052
Policy Entropy: 0.89027
Value Function Loss: 0.45669

Mean KL Divergence: 0.01215
SB3 Clip Fraction: 0.11320
Policy Update Magnitude: 0.17779
Value Function Update Magnitude: 0.35363

Collected Steps per Second: 22,942.95164
Overall Steps per Second: 10,616.36017

Timestep Collection Time: 2.18010
Timestep Consumption Time: 2.53130
PPO Batch Consumption Time: 0.29733
Total Iteration Time: 4.71141

Cumulative Model Updates: 5,492
Cumulative Timesteps: 45,915,016

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 45915016...
Checkpoint 45915016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,554.54937
Policy Entropy: 0.90626
Value Function Loss: 0.46273

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.09882
Policy Update Magnitude: 0.17212
Value Function Update Magnitude: 0.38607

Collected Steps per Second: 22,560.53297
Overall Steps per Second: 10,575.80419

Timestep Collection Time: 2.21661
Timestep Consumption Time: 2.51192
PPO Batch Consumption Time: 0.29411
Total Iteration Time: 4.72853

Cumulative Model Updates: 5,498
Cumulative Timesteps: 45,965,024

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,423.12782
Policy Entropy: 0.90546
Value Function Loss: 0.45128

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.09535
Policy Update Magnitude: 0.18435
Value Function Update Magnitude: 0.37855

Collected Steps per Second: 23,181.60643
Overall Steps per Second: 10,821.44831

Timestep Collection Time: 2.15775
Timestep Consumption Time: 2.46456
PPO Batch Consumption Time: 0.28353
Total Iteration Time: 4.62230

Cumulative Model Updates: 5,504
Cumulative Timesteps: 46,015,044

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 46015044...
Checkpoint 46015044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,673.84661
Policy Entropy: 0.90965
Value Function Loss: 0.45022

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.10088
Policy Update Magnitude: 0.18957
Value Function Update Magnitude: 0.33988

Collected Steps per Second: 22,586.45828
Overall Steps per Second: 10,566.46366

Timestep Collection Time: 2.21496
Timestep Consumption Time: 2.51965
PPO Batch Consumption Time: 0.29382
Total Iteration Time: 4.73460

Cumulative Model Updates: 5,510
Cumulative Timesteps: 46,065,072

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,455.41665
Policy Entropy: 0.90749
Value Function Loss: 0.43102

Mean KL Divergence: 0.00664
SB3 Clip Fraction: 0.07167
Policy Update Magnitude: 0.19561
Value Function Update Magnitude: 0.36241

Collected Steps per Second: 23,331.68034
Overall Steps per Second: 10,556.90236

Timestep Collection Time: 2.14318
Timestep Consumption Time: 2.59344
PPO Batch Consumption Time: 0.30517
Total Iteration Time: 4.73662

Cumulative Model Updates: 5,516
Cumulative Timesteps: 46,115,076

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 46115076...
Checkpoint 46115076 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,979.82091
Policy Entropy: 0.89754
Value Function Loss: 0.42810

Mean KL Divergence: 0.00542
SB3 Clip Fraction: 0.06414
Policy Update Magnitude: 0.22838
Value Function Update Magnitude: 0.33739

Collected Steps per Second: 22,630.49763
Overall Steps per Second: 10,713.58734

Timestep Collection Time: 2.21011
Timestep Consumption Time: 2.45835
PPO Batch Consumption Time: 0.28288
Total Iteration Time: 4.66846

Cumulative Model Updates: 5,522
Cumulative Timesteps: 46,165,092

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,330.39187
Policy Entropy: 0.90853
Value Function Loss: 0.41750

Mean KL Divergence: 0.00758
SB3 Clip Fraction: 0.08510
Policy Update Magnitude: 0.24057
Value Function Update Magnitude: 0.36987

Collected Steps per Second: 23,075.83971
Overall Steps per Second: 10,816.44006

Timestep Collection Time: 2.16703
Timestep Consumption Time: 2.45612
PPO Batch Consumption Time: 0.28317
Total Iteration Time: 4.62315

Cumulative Model Updates: 5,528
Cumulative Timesteps: 46,215,098

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 46215098...
Checkpoint 46215098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,138.42367
Policy Entropy: 0.88500
Value Function Loss: 0.43319

Mean KL Divergence: 0.00650
SB3 Clip Fraction: 0.07364
Policy Update Magnitude: 0.23836
Value Function Update Magnitude: 0.41292

Collected Steps per Second: 22,172.52145
Overall Steps per Second: 10,623.98021

Timestep Collection Time: 2.25595
Timestep Consumption Time: 2.45227
PPO Batch Consumption Time: 0.28330
Total Iteration Time: 4.70822

Cumulative Model Updates: 5,534
Cumulative Timesteps: 46,265,118

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,885.24912
Policy Entropy: 0.90280
Value Function Loss: 0.42893

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.09884
Policy Update Magnitude: 0.22554
Value Function Update Magnitude: 0.45894

Collected Steps per Second: 22,645.05594
Overall Steps per Second: 10,515.45984

Timestep Collection Time: 2.20808
Timestep Consumption Time: 2.54702
PPO Batch Consumption Time: 0.29801
Total Iteration Time: 4.75509

Cumulative Model Updates: 5,540
Cumulative Timesteps: 46,315,120

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 46315120...
Checkpoint 46315120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,158.15579
Policy Entropy: 0.91310
Value Function Loss: 0.43446

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.11322
Policy Update Magnitude: 0.19889
Value Function Update Magnitude: 0.42602

Collected Steps per Second: 22,543.87754
Overall Steps per Second: 10,710.49060

Timestep Collection Time: 2.21861
Timestep Consumption Time: 2.45121
PPO Batch Consumption Time: 0.28279
Total Iteration Time: 4.66981

Cumulative Model Updates: 5,546
Cumulative Timesteps: 46,365,136

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,148.51919
Policy Entropy: 0.92436
Value Function Loss: 0.42893

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.10729
Policy Update Magnitude: 0.18949
Value Function Update Magnitude: 0.38088

Collected Steps per Second: 22,893.19201
Overall Steps per Second: 10,771.91024

Timestep Collection Time: 2.18502
Timestep Consumption Time: 2.45873
PPO Batch Consumption Time: 0.28372
Total Iteration Time: 4.64374

Cumulative Model Updates: 5,552
Cumulative Timesteps: 46,415,158

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 46415158...
Checkpoint 46415158 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,566.30097
Policy Entropy: 0.92406
Value Function Loss: 0.48791

Mean KL Divergence: 0.00684
SB3 Clip Fraction: 0.07897
Policy Update Magnitude: 0.21130
Value Function Update Magnitude: 0.36388

Collected Steps per Second: 22,415.37320
Overall Steps per Second: 10,651.08772

Timestep Collection Time: 2.23142
Timestep Consumption Time: 2.46463
PPO Batch Consumption Time: 0.28404
Total Iteration Time: 4.69605

Cumulative Model Updates: 5,558
Cumulative Timesteps: 46,465,176

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,573.93241
Policy Entropy: 0.91757
Value Function Loss: 0.49683

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.09790
Policy Update Magnitude: 0.23555
Value Function Update Magnitude: 0.29740

Collected Steps per Second: 22,753.91628
Overall Steps per Second: 10,549.71735

Timestep Collection Time: 2.19813
Timestep Consumption Time: 2.54285
PPO Batch Consumption Time: 0.29758
Total Iteration Time: 4.74098

Cumulative Model Updates: 5,564
Cumulative Timesteps: 46,515,192

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 46515192...
Checkpoint 46515192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,258.39524
Policy Entropy: 0.92818
Value Function Loss: 0.47764

Mean KL Divergence: 0.01241
SB3 Clip Fraction: 0.13754
Policy Update Magnitude: 0.21261
Value Function Update Magnitude: 0.28231

Collected Steps per Second: 22,764.05376
Overall Steps per Second: 10,605.80437

Timestep Collection Time: 2.19759
Timestep Consumption Time: 2.51926
PPO Batch Consumption Time: 0.29710
Total Iteration Time: 4.71685

Cumulative Model Updates: 5,570
Cumulative Timesteps: 46,565,218

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,771.87924
Policy Entropy: 0.95569
Value Function Loss: 0.45654

Mean KL Divergence: 0.01083
SB3 Clip Fraction: 0.12148
Policy Update Magnitude: 0.18160
Value Function Update Magnitude: 0.31676

Collected Steps per Second: 23,063.77935
Overall Steps per Second: 10,863.42790

Timestep Collection Time: 2.16833
Timestep Consumption Time: 2.43518
PPO Batch Consumption Time: 0.28264
Total Iteration Time: 4.60352

Cumulative Model Updates: 5,576
Cumulative Timesteps: 46,615,228

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 46615228...
Checkpoint 46615228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,736.43113
Policy Entropy: 0.96733
Value Function Loss: 0.44704

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.08798
Policy Update Magnitude: 0.20271
Value Function Update Magnitude: 0.34214

Collected Steps per Second: 22,379.27215
Overall Steps per Second: 10,743.45351

Timestep Collection Time: 2.23501
Timestep Consumption Time: 2.42066
PPO Batch Consumption Time: 0.28178
Total Iteration Time: 4.65567

Cumulative Model Updates: 5,582
Cumulative Timesteps: 46,665,246

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,011.52328
Policy Entropy: 0.95490
Value Function Loss: 0.44982

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.09504
Policy Update Magnitude: 0.19315
Value Function Update Magnitude: 0.34469

Collected Steps per Second: 23,070.63392
Overall Steps per Second: 10,844.68426

Timestep Collection Time: 2.16734
Timestep Consumption Time: 2.44339
PPO Batch Consumption Time: 0.28382
Total Iteration Time: 4.61074

Cumulative Model Updates: 5,588
Cumulative Timesteps: 46,715,248

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 46715248...
Checkpoint 46715248 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,501.81432
Policy Entropy: 0.95229
Value Function Loss: 0.42216

Mean KL Divergence: 0.00718
SB3 Clip Fraction: 0.08145
Policy Update Magnitude: 0.23361
Value Function Update Magnitude: 0.35147

Collected Steps per Second: 22,313.55172
Overall Steps per Second: 10,562.48753

Timestep Collection Time: 2.24097
Timestep Consumption Time: 2.49314
PPO Batch Consumption Time: 0.29376
Total Iteration Time: 4.73411

Cumulative Model Updates: 5,594
Cumulative Timesteps: 46,765,252

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,428.57896
Policy Entropy: 0.95013
Value Function Loss: 0.43970

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.10385
Policy Update Magnitude: 0.23151
Value Function Update Magnitude: 0.34003

Collected Steps per Second: 22,708.31322
Overall Steps per Second: 10,649.47398

Timestep Collection Time: 2.20254
Timestep Consumption Time: 2.49403
PPO Batch Consumption Time: 0.29726
Total Iteration Time: 4.69657

Cumulative Model Updates: 5,600
Cumulative Timesteps: 46,815,268

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 46815268...
Checkpoint 46815268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,729.20712
Policy Entropy: 0.95222
Value Function Loss: 0.41065

Mean KL Divergence: 0.01572
SB3 Clip Fraction: 0.15984
Policy Update Magnitude: 0.18924
Value Function Update Magnitude: 0.35561

Collected Steps per Second: 22,433.59056
Overall Steps per Second: 10,527.40967

Timestep Collection Time: 2.22898
Timestep Consumption Time: 2.52091
PPO Batch Consumption Time: 0.29871
Total Iteration Time: 4.74989

Cumulative Model Updates: 5,606
Cumulative Timesteps: 46,865,272

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,999.16813
Policy Entropy: 0.91762
Value Function Loss: 0.43903

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.11392
Policy Update Magnitude: 0.20861
Value Function Update Magnitude: 0.34196

Collected Steps per Second: 22,746.28886
Overall Steps per Second: 10,614.43406

Timestep Collection Time: 2.19957
Timestep Consumption Time: 2.51401
PPO Batch Consumption Time: 0.29481
Total Iteration Time: 4.71358

Cumulative Model Updates: 5,612
Cumulative Timesteps: 46,915,304

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 46915304...
Checkpoint 46915304 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,227.23404
Policy Entropy: 0.88828
Value Function Loss: 0.44155

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.10499
Policy Update Magnitude: 0.25405
Value Function Update Magnitude: 0.34129

Collected Steps per Second: 22,669.96593
Overall Steps per Second: 10,644.22186

Timestep Collection Time: 2.20627
Timestep Consumption Time: 2.49262
PPO Batch Consumption Time: 0.29564
Total Iteration Time: 4.69889

Cumulative Model Updates: 5,618
Cumulative Timesteps: 46,965,320

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,279.34837
Policy Entropy: 0.87518
Value Function Loss: 0.44800

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.10574
Policy Update Magnitude: 0.20077
Value Function Update Magnitude: 0.36526

Collected Steps per Second: 23,106.62230
Overall Steps per Second: 10,724.01604

Timestep Collection Time: 2.16431
Timestep Consumption Time: 2.49905
PPO Batch Consumption Time: 0.29308
Total Iteration Time: 4.66336

Cumulative Model Updates: 5,624
Cumulative Timesteps: 47,015,330

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 47015330...
Checkpoint 47015330 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,943.27444
Policy Entropy: 0.88559
Value Function Loss: 0.44660

Mean KL Divergence: 0.00724
SB3 Clip Fraction: 0.07620
Policy Update Magnitude: 0.21908
Value Function Update Magnitude: 0.37545

Collected Steps per Second: 22,446.59542
Overall Steps per Second: 10,663.03176

Timestep Collection Time: 2.22804
Timestep Consumption Time: 2.46218
PPO Batch Consumption Time: 0.29840
Total Iteration Time: 4.69022

Cumulative Model Updates: 5,630
Cumulative Timesteps: 47,065,342

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,707.13211
Policy Entropy: 0.89316
Value Function Loss: 0.42687

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.09354
Policy Update Magnitude: 0.21344
Value Function Update Magnitude: 0.36847

Collected Steps per Second: 22,221.22798
Overall Steps per Second: 10,626.18922

Timestep Collection Time: 2.25073
Timestep Consumption Time: 2.45594
PPO Batch Consumption Time: 0.29453
Total Iteration Time: 4.70667

Cumulative Model Updates: 5,636
Cumulative Timesteps: 47,115,356

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 47115356...
Checkpoint 47115356 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,422.15680
Policy Entropy: 0.89922
Value Function Loss: 0.45687

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.09083
Policy Update Magnitude: 0.18727
Value Function Update Magnitude: 0.34045

Collected Steps per Second: 22,367.54181
Overall Steps per Second: 10,700.83492

Timestep Collection Time: 2.23547
Timestep Consumption Time: 2.43725
PPO Batch Consumption Time: 0.29187
Total Iteration Time: 4.67272

Cumulative Model Updates: 5,642
Cumulative Timesteps: 47,165,358

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,135.55588
Policy Entropy: 0.90530
Value Function Loss: 0.43855

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.10431
Policy Update Magnitude: 0.17875
Value Function Update Magnitude: 0.31612

Collected Steps per Second: 22,360.99036
Overall Steps per Second: 10,727.59412

Timestep Collection Time: 2.23729
Timestep Consumption Time: 2.42620
PPO Batch Consumption Time: 0.28877
Total Iteration Time: 4.66349

Cumulative Model Updates: 5,648
Cumulative Timesteps: 47,215,386

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 47215386...
Checkpoint 47215386 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,544.24493
Policy Entropy: 0.90457
Value Function Loss: 0.46018

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.09202
Policy Update Magnitude: 0.18127
Value Function Update Magnitude: 0.34305

Collected Steps per Second: 21,850.83423
Overall Steps per Second: 10,624.24320

Timestep Collection Time: 2.28962
Timestep Consumption Time: 2.41943
PPO Batch Consumption Time: 0.28998
Total Iteration Time: 4.70904

Cumulative Model Updates: 5,654
Cumulative Timesteps: 47,265,416

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,296.97429
Policy Entropy: 0.88502
Value Function Loss: 0.42807

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.09565
Policy Update Magnitude: 0.19127
Value Function Update Magnitude: 0.34747

Collected Steps per Second: 22,822.50577
Overall Steps per Second: 10,618.29709

Timestep Collection Time: 2.19213
Timestep Consumption Time: 2.51954
PPO Batch Consumption Time: 0.29441
Total Iteration Time: 4.71168

Cumulative Model Updates: 5,660
Cumulative Timesteps: 47,315,446

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 47315446...
Checkpoint 47315446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,249.49357
Policy Entropy: 0.87383
Value Function Loss: 0.42039

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.09831
Policy Update Magnitude: 0.19724
Value Function Update Magnitude: 0.37361

Collected Steps per Second: 22,121.86058
Overall Steps per Second: 10,643.22304

Timestep Collection Time: 2.26111
Timestep Consumption Time: 2.43859
PPO Batch Consumption Time: 0.29266
Total Iteration Time: 4.69970

Cumulative Model Updates: 5,666
Cumulative Timesteps: 47,365,466

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,110.87764
Policy Entropy: 0.88066
Value Function Loss: 0.41291

Mean KL Divergence: 0.00737
SB3 Clip Fraction: 0.07921
Policy Update Magnitude: 0.21649
Value Function Update Magnitude: 0.35007

Collected Steps per Second: 23,033.02731
Overall Steps per Second: 10,744.61058

Timestep Collection Time: 2.17149
Timestep Consumption Time: 2.48349
PPO Batch Consumption Time: 0.28330
Total Iteration Time: 4.65498

Cumulative Model Updates: 5,672
Cumulative Timesteps: 47,415,482

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 47415482...
Checkpoint 47415482 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,545.27836
Policy Entropy: 0.87994
Value Function Loss: 0.44391

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.10066
Policy Update Magnitude: 0.21864
Value Function Update Magnitude: 0.33203

Collected Steps per Second: 22,436.48290
Overall Steps per Second: 10,650.66205

Timestep Collection Time: 2.22923
Timestep Consumption Time: 2.46682
PPO Batch Consumption Time: 0.28782
Total Iteration Time: 4.69605

Cumulative Model Updates: 5,678
Cumulative Timesteps: 47,465,498

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,970.95217
Policy Entropy: 0.88014
Value Function Loss: 0.47759

Mean KL Divergence: 0.01328
SB3 Clip Fraction: 0.12599
Policy Update Magnitude: 0.19066
Value Function Update Magnitude: 0.33632

Collected Steps per Second: 21,430.51402
Overall Steps per Second: 10,406.97034

Timestep Collection Time: 2.33415
Timestep Consumption Time: 2.47244
PPO Batch Consumption Time: 0.28441
Total Iteration Time: 4.80659

Cumulative Model Updates: 5,684
Cumulative Timesteps: 47,515,520

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 47515520...
Checkpoint 47515520 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,522.60887
Policy Entropy: 0.87116
Value Function Loss: 0.46150

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.10307
Policy Update Magnitude: 0.19756
Value Function Update Magnitude: 0.36288

Collected Steps per Second: 22,709.72274
Overall Steps per Second: 10,673.22232

Timestep Collection Time: 2.20267
Timestep Consumption Time: 2.48401
PPO Batch Consumption Time: 0.28854
Total Iteration Time: 4.68668

Cumulative Model Updates: 5,690
Cumulative Timesteps: 47,565,542

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,205.29229
Policy Entropy: 0.86777
Value Function Loss: 0.45027

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.08520
Policy Update Magnitude: 0.19336
Value Function Update Magnitude: 0.35673

Collected Steps per Second: 22,913.51014
Overall Steps per Second: 10,654.04062

Timestep Collection Time: 2.18238
Timestep Consumption Time: 2.51124
PPO Batch Consumption Time: 0.29415
Total Iteration Time: 4.69362

Cumulative Model Updates: 5,696
Cumulative Timesteps: 47,615,548

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 47615548...
Checkpoint 47615548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,513.86496
Policy Entropy: 0.85391
Value Function Loss: 0.41778

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.09808
Policy Update Magnitude: 0.19061
Value Function Update Magnitude: 0.34874

Collected Steps per Second: 22,733.38695
Overall Steps per Second: 10,632.37130

Timestep Collection Time: 2.20090
Timestep Consumption Time: 2.50491
PPO Batch Consumption Time: 0.29318
Total Iteration Time: 4.70582

Cumulative Model Updates: 5,702
Cumulative Timesteps: 47,665,582

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,602.48871
Policy Entropy: 0.85464
Value Function Loss: 0.42920

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.09434
Policy Update Magnitude: 0.21274
Value Function Update Magnitude: 0.32523

Collected Steps per Second: 22,810.43664
Overall Steps per Second: 10,717.89148

Timestep Collection Time: 2.19233
Timestep Consumption Time: 2.47351
PPO Batch Consumption Time: 0.28439
Total Iteration Time: 4.66584

Cumulative Model Updates: 5,708
Cumulative Timesteps: 47,715,590

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 47715590...
Checkpoint 47715590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,038.75768
Policy Entropy: 0.84815
Value Function Loss: 0.40466

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.09686
Policy Update Magnitude: 0.19400
Value Function Update Magnitude: 0.36536

Collected Steps per Second: 22,496.41376
Overall Steps per Second: 10,673.02997

Timestep Collection Time: 2.22329
Timestep Consumption Time: 2.46292
PPO Batch Consumption Time: 0.28352
Total Iteration Time: 4.68620

Cumulative Model Updates: 5,714
Cumulative Timesteps: 47,765,606

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,940.79471
Policy Entropy: 0.86266
Value Function Loss: 0.39690

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.09513
Policy Update Magnitude: 0.18131
Value Function Update Magnitude: 0.41428

Collected Steps per Second: 22,677.86574
Overall Steps per Second: 10,547.82375

Timestep Collection Time: 2.20603
Timestep Consumption Time: 2.53694
PPO Batch Consumption Time: 0.29637
Total Iteration Time: 4.74297

Cumulative Model Updates: 5,720
Cumulative Timesteps: 47,815,634

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 47815634...
Checkpoint 47815634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,953.78828
Policy Entropy: 0.85283
Value Function Loss: 0.39463

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.09236
Policy Update Magnitude: 0.17509
Value Function Update Magnitude: 0.47919

Collected Steps per Second: 22,580.74216
Overall Steps per Second: 10,626.85257

Timestep Collection Time: 2.21490
Timestep Consumption Time: 2.49148
PPO Batch Consumption Time: 0.28821
Total Iteration Time: 4.70638

Cumulative Model Updates: 5,726
Cumulative Timesteps: 47,865,648

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,700.58771
Policy Entropy: 0.84826
Value Function Loss: 0.38279

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.08701
Policy Update Magnitude: 0.19468
Value Function Update Magnitude: 0.40698

Collected Steps per Second: 22,903.52930
Overall Steps per Second: 10,565.80731

Timestep Collection Time: 2.18359
Timestep Consumption Time: 2.54979
PPO Batch Consumption Time: 0.29808
Total Iteration Time: 4.73338

Cumulative Model Updates: 5,732
Cumulative Timesteps: 47,915,660

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 47915660...
Checkpoint 47915660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,437.61234
Policy Entropy: 0.84142
Value Function Loss: 0.38449

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.09020
Policy Update Magnitude: 0.20300
Value Function Update Magnitude: 0.43132

Collected Steps per Second: 22,978.66599
Overall Steps per Second: 10,739.12601

Timestep Collection Time: 2.17602
Timestep Consumption Time: 2.48004
PPO Batch Consumption Time: 0.29331
Total Iteration Time: 4.65606

Cumulative Model Updates: 5,738
Cumulative Timesteps: 47,965,662

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,674.35799
Policy Entropy: 0.85320
Value Function Loss: 0.39030

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.09893
Policy Update Magnitude: 0.19894
Value Function Update Magnitude: 0.40342

Collected Steps per Second: 23,018.06076
Overall Steps per Second: 10,708.96358

Timestep Collection Time: 2.17308
Timestep Consumption Time: 2.49778
PPO Batch Consumption Time: 0.29227
Total Iteration Time: 4.67085

Cumulative Model Updates: 5,744
Cumulative Timesteps: 48,015,682

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 48015682...
Checkpoint 48015682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,110.57337
Policy Entropy: 0.85646
Value Function Loss: 0.39838

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.09699
Policy Update Magnitude: 0.18961
Value Function Update Magnitude: 0.45097

Collected Steps per Second: 22,620.53394
Overall Steps per Second: 10,495.03822

Timestep Collection Time: 2.21056
Timestep Consumption Time: 2.55398
PPO Batch Consumption Time: 0.30183
Total Iteration Time: 4.76454

Cumulative Model Updates: 5,750
Cumulative Timesteps: 48,065,686

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,622.80606
Policy Entropy: 0.85712
Value Function Loss: 0.42182

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.08585
Policy Update Magnitude: 0.19607
Value Function Update Magnitude: 0.39860

Collected Steps per Second: 22,455.80672
Overall Steps per Second: 10,592.24771

Timestep Collection Time: 2.22704
Timestep Consumption Time: 2.49434
PPO Batch Consumption Time: 0.29431
Total Iteration Time: 4.72138

Cumulative Model Updates: 5,756
Cumulative Timesteps: 48,115,696

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 48115696...
Checkpoint 48115696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,645.10675
Policy Entropy: 0.85940
Value Function Loss: 0.41675

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.08772
Policy Update Magnitude: 0.19265
Value Function Update Magnitude: 0.33485

Collected Steps per Second: 22,726.03962
Overall Steps per Second: 10,640.63395

Timestep Collection Time: 2.20065
Timestep Consumption Time: 2.49945
PPO Batch Consumption Time: 0.29144
Total Iteration Time: 4.70010

Cumulative Model Updates: 5,762
Cumulative Timesteps: 48,165,708

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,403.29514
Policy Entropy: 0.86044
Value Function Loss: 0.43242

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.09012
Policy Update Magnitude: 0.19626
Value Function Update Magnitude: 0.31927

Collected Steps per Second: 22,971.58747
Overall Steps per Second: 10,697.82064

Timestep Collection Time: 2.17747
Timestep Consumption Time: 2.49825
PPO Batch Consumption Time: 0.29488
Total Iteration Time: 4.67572

Cumulative Model Updates: 5,768
Cumulative Timesteps: 48,215,728

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 48215728...
Checkpoint 48215728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,853.48018
Policy Entropy: 0.86646
Value Function Loss: 0.40029

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.09433
Policy Update Magnitude: 0.19242
Value Function Update Magnitude: 0.35113

Collected Steps per Second: 22,929.26994
Overall Steps per Second: 10,731.47786

Timestep Collection Time: 2.18123
Timestep Consumption Time: 2.47927
PPO Batch Consumption Time: 0.29127
Total Iteration Time: 4.66050

Cumulative Model Updates: 5,774
Cumulative Timesteps: 48,265,742

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,610.76568
Policy Entropy: 0.86444
Value Function Loss: 0.40657

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.08936
Policy Update Magnitude: 0.18392
Value Function Update Magnitude: 0.34603

Collected Steps per Second: 23,173.15128
Overall Steps per Second: 10,699.24743

Timestep Collection Time: 2.15862
Timestep Consumption Time: 2.51666
PPO Batch Consumption Time: 0.29773
Total Iteration Time: 4.67528

Cumulative Model Updates: 5,780
Cumulative Timesteps: 48,315,764

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 48315764...
Checkpoint 48315764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,382.18893
Policy Entropy: 0.87044
Value Function Loss: 0.41065

Mean KL Divergence: 0.01070
SB3 Clip Fraction: 0.10155
Policy Update Magnitude: 0.19859
Value Function Update Magnitude: 0.35309

Collected Steps per Second: 22,917.43250
Overall Steps per Second: 10,374.06556

Timestep Collection Time: 2.18253
Timestep Consumption Time: 2.63892
PPO Batch Consumption Time: 0.31743
Total Iteration Time: 4.82145

Cumulative Model Updates: 5,786
Cumulative Timesteps: 48,365,782

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 48365782...
Checkpoint 48365782 saved!
